{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88fbe7f5",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b85bf6",
   "metadata": {},
   "source": [
    "1. Central Idea\n",
    "    - Idea: We analyze ~18,000 research papers related to Large Language Models and modern AI (LLMs, agentic AI, RAG, foundation models, transformers), downloaded from OpenAlex.\n",
    "        Our goal is to reveal how ideas evolve in this field, and identify:\n",
    "        - which topics dominate the field,\n",
    "        - which papers are most influential,\n",
    "        - which authors and institutions drive the research.\n",
    "    - Why interesting? \n",
    "    LLMs are evolving extremely fast—every month there is a new architecture, agent framework, or RAG improvement. The public sees hype; we want to see the actual scientific movement.We want to know:\n",
    "        - Are today's buzzwords (agents, reasoning, RAG) actually backed by science?\n",
    "        - Who are the “idea hubs” (top-cited papers, institutions)?\n",
    "        - Which topics are emerging vs. declining?\n",
    "    - What datasets were explored? How did I download them? We are exploring a dataset of 20000 papers downloaded from OpenAlex. We used the query with parameters large language model|language model|pretrained language model|foundation model|transformer|LLM|agentic AI|AI agent|tool use|retrieval augmented generation|retrieval-augmented|model context protocol), later than 2000 and must have some references. \n",
    "2. Total Size of the Data. 17891 json files\n",
    "    - Papers Citation Graph: 17891 nodes and 54295 edges\n",
    "    - Co-autors graph: 65931 nodes, 285288 edges\n",
    "    - Author Citation network: 55431 nodes, 2206140 edges\n",
    "3. What is the network? - the oens rpesented above \n",
    "4. What is the text? The text is the actual text of the papers, and if that is absent we will use the abstract\n",
    "5. How will text and networks be tied together? The text will be used to determine the most popular terms in the network, build communities and identify which authors defined popular technologies. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ffbd21",
   "metadata": {},
   "source": [
    "## Papers Citation Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf6e808",
   "metadata": {},
   "source": [
    "#### Network construction\n",
    "Taking all the json representations of the papers that were queried from OpenAlex.\n",
    "\n",
    "A node consists from:\n",
    "- paper_id\n",
    "- title\n",
    "- url\n",
    "- year  \n",
    "- authors  \n",
    "- abstract\n",
    "- topics\n",
    "- topic\n",
    "- concepts\n",
    "- institutions\n",
    "\n",
    "After analyzing the original network briefly, it was identified that there are a few isolated nodes (they are not cited by anopne and do not cite anyone from the network). It was decided to leave these nodes out and focus on the part of the network that is actually connected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "426d990c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JSON files...\n",
      "Loaded 17891 papers\n",
      "Building graph...\n",
      "Graph completed.\n",
      "Nodes: 17891\n",
      "Edges: 54295\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import networkx as nx\n",
    "\n",
    "FOLDER = \"papers_full\"\n",
    "\n",
    "Graph = nx.DiGraph()\n",
    "\n",
    "def extract_id(url):\n",
    "    if not url:\n",
    "        return None\n",
    "    return url.strip().split(\"/\")[-1]\n",
    "\n",
    "# Load all papers once into memory {paper_id: json_data}\n",
    "paper_data = {}\n",
    "\n",
    "print(\"Loading JSON files...\")\n",
    "\n",
    "for filename in os.listdir(FOLDER):\n",
    "    if not filename.endswith(\".json\"):\n",
    "        continue\n",
    "\n",
    "    paper_id = filename.replace(\".json\", \"\")\n",
    "\n",
    "    with open(os.path.join(FOLDER, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    paper_data[paper_id] = data\n",
    "\n",
    "print(f\"Loaded {len(paper_data)} papers\")\n",
    "\n",
    "print(\"Building graph...\")\n",
    "\n",
    "for paper_id, data in paper_data.items():\n",
    "\n",
    "    # Convert authors from list -> single string\n",
    "    authors = \", \".join([a.get(\"name\") for a in data.get(\"authors\", [])])\n",
    "    # concepts = \", \".join([c.get(\"name\") for c in data.get(\"concepts\", [])])\n",
    "    concepts = [c.get(\"name\") for c in data.get(\"concepts\", []) if c.get(\"name\")]\n",
    "\n",
    "\n",
    "\n",
    "    institution_list = \", \".join(\n",
    "        i.get(\"name\") \n",
    "        for i in data.get(\"institutions\", [])\n",
    "        if i.get(\"name\")\n",
    "        )\n",
    "\n",
    "\n",
    "    Graph.add_node(\n",
    "        paper_id,\n",
    "        title=str(data.get(\"title\") or \"\"),\n",
    "        url = str(data.get(\"url\") or \"\"),\n",
    "        year=str(data.get(\"year\") or \"\"),\n",
    "        authors=authors,\n",
    "        abstract=str(data.get(\"abstract\") or \"\"),  \n",
    "        topic=str(data.get(\"topic\")),\n",
    "        concepts = concepts,\n",
    "        institutions_flat = institution_list\n",
    "        # full_text removed (too big + not needed for graph format)\n",
    "    )\n",
    "\n",
    "    for ref_url in data.get(\"references\", []):\n",
    "        ref_id = extract_id(ref_url)\n",
    "        if ref_id in paper_data:\n",
    "            Graph.add_edge(paper_id, ref_id)\n",
    "\n",
    "\n",
    "print(\"Graph completed.\")\n",
    "print(f\"Nodes: {Graph.number_of_nodes()}\")\n",
    "print(f\"Edges: {Graph.number_of_edges()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf3c3e",
   "metadata": {},
   "source": [
    "### Export the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "42443efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.write_gexf(Graph, \"papers_citation_graph.gexf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833f419b",
   "metadata": {},
   "source": [
    "### General Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5d4be508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Papers per Topic ===\n",
      "Computer science: 5831\n",
      "Transformer: 1151\n",
      "Medicine: 285\n",
      "Perplexity: 176\n",
      "None: 143\n",
      "Automatic summarization: 140\n",
      "Artificial intelligence: 128\n",
      "Foundation (evidence): 125\n",
      "Preprint: 110\n",
      "Interpretability: 103\n",
      "Generative grammar: 80\n",
      "Psychology: 76\n",
      "Segmentation: 76\n",
      "Dissolved gas analysis: 75\n",
      "Closed captioning: 65\n",
      "Biology: 64\n",
      "Health care: 64\n",
      "Readability: 63\n",
      "Context (archaeology): 62\n",
      "Chatbot: 62\n",
      "Hyperspectral imaging: 58\n",
      "Materials science: 57\n",
      "Question answering: 56\n",
      "Benchmark (surveying): 53\n",
      "Convolutional neural network: 53\n",
      "Inference: 50\n",
      "Inrush current: 49\n",
      "Benchmarking: 49\n",
      "Workflow: 46\n",
      "Reliability engineering: 45\n",
      "Partial discharge: 45\n",
      "Machine translation: 44\n",
      "Nanofluid: 40\n",
      "Transformative learning: 39\n",
      "Leverage (statistics): 39\n",
      "Converters: 38\n",
      "Task (project management): 38\n",
      "Reinforcement learning: 36\n",
      "Discriminative model: 35\n",
      "Linguistics: 34\n",
      "Zhàng: 33\n",
      "Encoder: 33\n",
      "Natural language processing: 33\n",
      "Adversarial system: 31\n",
      "Transformer oil: 30\n",
      "Electromagnetic coil: 29\n",
      "Support vector machine: 29\n",
      "Leakage inductance: 28\n",
      "Mineral oil: 28\n",
      "Mental health: 28\n",
      "Generalizability theory: 28\n",
      "Embedding: 28\n",
      "Photovoltaic system: 27\n",
      "Conversation: 27\n",
      "Robustness (evolution): 27\n",
      "Consistency (knowledge bases): 27\n",
      "Harmonics: 26\n",
      "Usability: 26\n",
      "Electrical engineering: 26\n",
      "Overfitting: 26\n",
      "Sentiment analysis: 26\n",
      "Security token: 26\n",
      "Misinformation: 26\n",
      "Physics: 25\n",
      "Artificial neural network: 25\n",
      "Distribution transformer: 25\n",
      "Cognition: 25\n",
      "Sentence: 24\n",
      "Point cloud: 24\n",
      "Autoregressive model: 24\n",
      "Current transformer: 23\n",
      "Language model: 23\n",
      "Social media: 23\n",
      "Debiasing: 23\n",
      "Perspective (graphical): 22\n",
      "Modular design: 21\n",
      "Genome: 21\n",
      "Softmax function: 21\n",
      "Chen: 21\n",
      "Medical diagnosis: 21\n",
      "Cluster analysis: 20\n",
      "Transparency (behavior): 20\n",
      "Foraging: 19\n",
      "Treebank: 19\n",
      "Narrative: 19\n",
      "Electroencephalography: 19\n",
      "Coronavirus disease 2019 (COVID-19): 19\n",
      "Computational biology: 18\n",
      "Annotation: 18\n",
      "Systematic review: 18\n",
      "Bengali: 18\n",
      "Offensive: 18\n",
      "Sequence (biology): 18\n",
      "Inductor: 17\n",
      "Finite element method: 17\n",
      "Business: 17\n",
      "Creativity: 17\n",
      "Quality (philosophy): 17\n",
      "Generalization: 17\n",
      "Autoencoder: 17\n",
      "Computer security: 17\n",
      "Triage: 17\n",
      "Test (biology): 17\n",
      "Geospatial analysis: 17\n",
      "Bushing: 16\n",
      "Tap changer: 16\n",
      "Software deployment: 16\n",
      "Gesture: 15\n",
      "Reliability (semiconductor): 15\n",
      "German: 15\n",
      "Embodied cognition: 15\n",
      "Perception: 15\n",
      "Personalization: 15\n",
      "Microgrid: 15\n",
      "Paraphrase: 15\n",
      "Residual: 15\n",
      "Computer vision: 15\n",
      "Grading (engineering): 15\n",
      "Troglodytes: 14\n",
      "Smart grid: 14\n",
      "Correctness: 14\n",
      "Pressboard: 14\n",
      "Adaptation (eye): 14\n",
      "Parsing: 14\n",
      "Decoding methods: 14\n",
      "Architecture: 14\n",
      "Adapter (computing): 14\n",
      "SemEval: 14\n",
      "Deep learning: 14\n",
      "Workload: 14\n",
      "Phishing: 14\n",
      "Empathy: 14\n",
      "Robot: 13\n",
      "Automation: 13\n",
      "Affordance: 13\n",
      "Relevance (law): 13\n",
      "Bridging (networking): 13\n",
      "Audit: 13\n",
      "Python (programming language): 13\n",
      "End-to-end principle: 13\n",
      "Disinformation: 13\n",
      "Scale (ratio): 13\n",
      "Machine learning: 13\n",
      "Key (lock): 13\n",
      "Popularity: 13\n",
      "CLARITY: 13\n",
      "Drone: 12\n",
      "Control theory (sociology): 12\n",
      "ENCODE: 12\n",
      "Renewable energy: 12\n",
      "Identification (biology): 12\n",
      "Speedup: 12\n",
      "Counterfactual thinking: 12\n",
      "Concordance: 12\n",
      "Dialog box: 12\n",
      "Sarcasm: 12\n",
      "Metadata: 12\n",
      "Memorization: 12\n",
      "Pooling: 12\n",
      "Spectrogram: 12\n",
      "Arabic: 12\n",
      "Politics: 12\n",
      "Shot (pellet): 12\n",
      "Emergency department: 12\n",
      "Geomagnetically induced current: 11\n",
      "Magnetostriction: 11\n",
      "Process (computing): 11\n",
      "Ferroresonance in electricity networks: 11\n",
      "Ontology: 11\n",
      "Modalities: 11\n",
      "Brain–computer interface: 11\n",
      "Current (fluid): 11\n",
      "Drug discovery: 11\n",
      "Machining: 11\n",
      "Epitope: 11\n",
      "Training (meteorology): 11\n",
      "Ultra high frequency: 11\n",
      "Vocabulary: 11\n",
      "Ranking (information retrieval): 11\n",
      "Discriminator: 11\n",
      "Initialization: 11\n",
      "Hyperparameter: 11\n",
      "Negation: 11\n",
      "Distillation: 11\n",
      "Domain (mathematical analysis): 11\n",
      "Backdoor: 11\n",
      "Breast cancer: 11\n",
      "Modal: 11\n",
      "RNA: 11\n",
      "Coding (social sciences): 11\n",
      "Medical education: 11\n",
      "Biomedicine: 11\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "### papers per topic\n",
    "topic_counter = Counter()\n",
    "\n",
    "for node, attrs in Graph.nodes(data=True):\n",
    "    topic = attrs.get(\"topic\")\n",
    "    if topic:\n",
    "        topic_counter[topic] += 1\n",
    "\n",
    "print(\"\\n=== Papers per Topic ===\")\n",
    "for topic, count in topic_counter.most_common():\n",
    "    if count > 10:\n",
    "        print(f\"{topic}: {count}\")\n",
    "\n",
    "### papers per concept\n",
    "# concept_counter = Counter()\n",
    "\n",
    "# for node, attrs in G.nodes(data=True):\n",
    "#     for c in attrs.get(\"concepts\", []):\n",
    "#         concept_counter[c] += 1\n",
    "\n",
    "# print(\"\\n=== Papers per Concept ===\")\n",
    "# for concept, count in concept_counter.most_common():\n",
    "#     print(f\"{concept}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e98939",
   "metadata": {},
   "source": [
    "### Network-Centered Analysis\n",
    "\n",
    "Constructing a WCC (weakly connected component) in order to keep the directed structure of the network.\n",
    "\n",
    "Doing this, the nodes that are not conencted to the rest of the graph are eliminated.\n",
    "\n",
    "What is left is a graph with 14079 nodes out of the original 17891. \n",
    "\n",
    "Notice, that this does not mean that the nodes that have been removed do not have any citations at all - they do not have any citations in the network that was constructed here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d7bb7c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes in GCC: 14079\n",
      "Nodes total: 17891\n"
     ]
    }
   ],
   "source": [
    "wcc = list(nx.weakly_connected_components(Graph))\n",
    "\n",
    "gcc_nodes = max(wcc, key=len)\n",
    "\n",
    "G = Graph.subgraph(gcc_nodes).copy()\n",
    "\n",
    "print(\"Nodes in GCC:\", len(G))\n",
    "print(\"Nodes total:\", len(Graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "170f53f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most cited papers (by indegree):\n",
      "W3094502228, https://openalex.org/W3094502228\n",
      "title: An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\n",
      "year: 2022\n",
      "abstract length: 854, topic: Image (mathematics),\n",
      "concepts: ['Image (mathematics)', 'Artificial intelligence', 'Transformer', 'Computer science', 'Computer vision', 'Scale (ratio)', 'Engineering', 'Cartography', 'Electrical engineering', 'Geography', 'Voltage']\n",
      "institutions: Google (United States), German Research Centre for Artificial Intelligence\n",
      "abstract: While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.\n",
      "cites: 7\n",
      "(897 citations)\n",
      "____________________________________________________________________________________________________________________________________\n",
      "W4221143046, https://openalex.org/W4221143046\n",
      "title: Chain-of-Thought Prompting Elicits Reasoning in Large Language Models\n",
      "year: 2022\n",
      "abstract length: 863, topic: Computer science,\n",
      "concepts: ['Computer science', 'Language model', 'Benchmark (surveying)', 'Chain (unit)', 'Cognitive science', 'Artificial intelligence', 'Word (group theory)', 'Natural language processing', 'Commonsense reasoning', 'Range (aeronautics)', 'Simple (philosophy)', 'Theoretical computer science', 'Psychology', 'Linguistics', 'Epistemology', 'Philosophy', 'Composite material', 'Geodesy', 'Astronomy', 'Materials science', 'Geography', 'Physics']\n",
      "institutions: \n",
      "abstract: We explore how generating a chain of thought -- a series of intermediate reasoning steps -- significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a 540B-parameter language model with just eight chain of thought exemplars achieves state of the art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.\n",
      "cites: 1\n",
      "(669 citations)\n",
      "____________________________________________________________________________________________________________________________________\n",
      "W2979826702, https://openalex.org/W2979826702\n",
      "title: Transformers: State-of-the-Art Natural Language Processing\n",
      "year: 2020\n",
      "abstract length: 436, topic: Art history,\n",
      "concepts: ['Art history', 'Art', 'Transformer', 'Natural (archaeology)', 'Computer science', 'History', 'Engineering', 'Archaeology', 'Electrical engineering', 'Voltage']\n",
      "institutions: Hugging Face\n",
      "abstract: Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, Alexander Rush. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. 2020.\n",
      "cites: 7\n",
      "(586 citations)\n",
      "____________________________________________________________________________________________________________________________________\n",
      "W2911489562, https://openalex.org/W2911489562\n",
      "title: BioBERT: a pre-trained biomedical language representation model for biomedical text mining\n",
      "year: 2019\n",
      "abstract length: 1860, topic: Biomedical text mining,\n",
      "concepts: ['Biomedical text mining', 'Computer science', 'Artificial intelligence', 'Natural language processing', 'Language model', 'Named-entity recognition', 'Relationship extraction', 'Text mining', 'Text corpus', 'Representation (politics)', 'F1 score', 'Domain (mathematical analysis)', 'Source code', 'Information extraction', 'Law', 'Economics', 'Task (project management)', 'Operating system', 'Politics', 'Management', 'Mathematical analysis', 'Political science', 'Mathematics']\n",
      "institutions: Korea University, Naver (South Korea)\n",
      "abstract: Abstract Motivation Biomedical text mining is becoming increasingly important as the number of biomedical documents rapidly grows. With the progress in natural language processing (NLP), extracting valuable information from biomedical literature has gained popularity among researchers, and deep learning has boosted the development of effective biomedical text mining models. However, directly applying the advancements in NLP to biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora. In this article, we investigate how the recently introduced pre-trained language model BERT can be adapted for biomedical corpora. Results We introduce BioBERT (Bidirectional Encoder Representations from Transformers for Biomedical Text Mining), which is a domain-specific language representation model pre-trained on large-scale biomedical corpora. With almost the same architecture across tasks, BioBERT largely outperforms BERT and previous state-of-the-art models in a variety of biomedical text mining tasks when pre-trained on biomedical corpora. While BERT obtains performance comparable to that of previous state-of-the-art models, BioBERT significantly outperforms them on the following three representative biomedical text mining tasks: biomedical named entity recognition (0.62% F1 score improvement), biomedical relation extraction (2.80% F1 score improvement) and biomedical question answering (12.24% MRR improvement). Our analysis results show that pre-training BERT on biomedical corpora helps it to understand complex biomedical texts. Availability and implementation We make the pre-trained weights of BioBERT freely available at https://github.com/naver/biobert-pretrained, and the source code for fine-tuning BioBERT available at https://github.com/dmis-lab/biobert.\n",
      "cites: 1\n",
      "(495 citations)\n",
      "____________________________________________________________________________________________________________________________________\n",
      "W4384071683, https://openalex.org/W4384071683\n",
      "title: Large language models encode clinical knowledge\n",
      "year: 2023\n",
      "abstract length: 0, topic: Computer science,\n",
      "concepts: ['Computer science', 'Benchmark (surveying)', 'Language model', 'Comprehension', 'Artificial intelligence', 'Harm', 'Key (lock)', 'Unified Medical Language System', 'Data science', 'Precision medicine', 'Machine learning', 'Natural language processing', 'Medicine', 'Psychology', 'Computer security', 'Pathology', 'Social psychology', 'Geodesy', 'Programming language', 'Geography']\n",
      "institutions: Google (United States), United States National Library of Medicine, DeepMind (United Kingdom)\n",
      "abstract: \n",
      "cites: 11\n",
      "(450 citations)\n",
      "____________________________________________________________________________________________________________________________________\n",
      "Top 5 least cited papers (by ind-degree)\n",
      "W107376459, https://openalex.org/W107376459\n",
      "title: Electromagnetic Modelling of Power Transformers with DC Magnetization\n",
      "year: 2012\n",
      "abstract length: 2270, topic: Transformer,\n",
      "concepts: ['Transformer', 'Electrical engineering', 'Electric power transmission', 'Power transmission', 'Physics', 'Power flow', 'Electromagnetic coil', 'Engineering', 'Power (physics)', 'Voltage', 'Electric power system', 'Quantum mechanics']\n",
      "institutions: \n",
      "abstract: DC currents that flow through the ground can be injected to the star windings of power transformers from their grounded neutral points and close their path with transmission lines. The geomagnetically induced currents (GICs) and AC/DC convertors of high voltage direct current (HVDC) systems are the sources of such DC currents. These currents may cause saturation of the core in power transformers that leads to destruction in the transformer performance. This phenomenon results in unwanted influences on power transformers and the power system. Very asymmetric magnetization current, increasing losses and creation of hot spots in the core, in the windings, and the metallic structural parts are adverse effects that occur in transformers. Also, increasing demand of reactive power and misoperation of protective relays menaces the power network. Damages in large power transformers and blackouts in networks have occurred due to this phenomenon Hence, studies regarding this subject have taken the attention of researchers during the last decades. However, a gap of a comprehensive analysis still remains. Thus, the main aim of this project is to reach to a deep understanding of the phenomena and to come up with a solution for a decrease of the undesired effects of GIC. Achieving this goal requires an improvement of the electromagnetic models of transformers which include a hysteresis model, numerical techniques, and transient analysis. In this project until now, a new algorithm for digital measurement of the core materials is developed and implemented. It enhances the abilities of accurate measurements and an improved hysteresis model has been worked out. Also, a novel differential scalar hysteresis model is suggested that easily can be implemented in numerical methods. Three dimensional finite element models of various core types of power transformers are created to study the effect on them due to DC magnetization. In order to enhance the numerical tools for analysis of low frequency transients related to power transformers and the network, a distributed reluctance network method has been outlined. In this thesis a method for solving such a network problem with coupling to an electrical circuit and taking hysteresis into account is suggested.\n",
      "cites: 1\n",
      "(0 citations)\n",
      "____________________________________________________________________________________________________________________________________\n",
      "W128830652, https://openalex.org/W128830652\n",
      "title: Superconducting Transformer Design and Construction\n",
      "year: 2020\n",
      "abstract length: 2647, topic: Transformer,\n",
      "concepts: ['Transformer', 'Electrical engineering', 'Computer science', 'Engineering', 'Voltage']\n",
      "institutions: \n",
      "abstract: This thesis first outlines the testing undertaken on a partial core superconducting transformer under open circuit, short circuit, full load and endurance test conditions. During the endurance test, a failure occurred after 1 minute and 35 seconds. During the failure, voltage dipping and rapid liquid nitrogen boil off was observed. This prompted a failure investigation which concluded that the lack of cooling in the windings was the most probable cause to the failure. Full core transformer and superconductor theories are then introduced. A copper winding transformer model, based on a Steinmetz equivalent circuit and a reverse design method, is described. A superconductor loss model which outlines the different types of losses experienced under AC conditions is used to determine the resistance of the windings in the Steinmetz equivalent circuit. This resistance changes with the magnitude of current and the strength of the magnetic field that is present in the gaps between each layer of the windings. An alternative leakage flux model is then presented, where the flux is modelled based on the combination of the reluctance of the core and the air surrounding the windings. Based on these theories, an iterative algorithm to calculate the resistance of the superconductor is developed. A new design of a 15kVA single phase full core superconducting transformer, operating in liquid nitrogen, is presented. The issues with building the superconducting transformer are outlined. First, a copper mockup of the superconducting transformer was designed where the mockup would have the same tape and winding dimensions as the superconducting transformer, which means the same core can be used for two different sets of windings. This led to designing a core that could be easily taken apart as well as reassembled. Construction of the core, the copper windings and the superconductor windings ensued. The process of cutting the core laminations, insulating the copper and superconductor tapes, and making the steel fasteners and terminations are described. The copper mockup and superconducting transformers was then tested under open circuit, short circuit, different load and endurance conditions at both liquid nitrogen and room temperatures. These test results were then compared with the those from two models. The comparison showed a significant inaccuracy in the reactances in the models. This introduced a correction factor into the superconductor model which ii made it more accurate. However, further work is required to explain and quantify the correction factors for the copper transformer model under different load conditions.\n",
      "cites: 4\n",
      "(0 citations)\n",
      "____________________________________________________________________________________________________________________________________\n",
      "W137288188, https://openalex.org/W137288188\n",
      "title: Use Of Hidden Markov Models And Factored Language Models For Automatic Chord Recognition.\n",
      "year: 2018\n",
      "abstract length: 25, topic: Hidden Markov model,\n",
      "concepts: ['Hidden Markov model', 'Viterbi algorithm', 'Chord (peer-to-peer)', 'Computer science', 'Speech recognition', 'Language model', 'Artificial intelligence', 'Sequence labeling', 'Viterbi decoder', 'Pattern recognition (psychology)', 'Markov chain', 'Natural language processing', 'Task (project management)', 'Decoding methods', 'Machine learning', 'Algorithm', 'Distributed computing', 'Management', 'Economics']\n",
      "institutions: Fondazione Bruno Kessler\n",
      "abstract: [TODO] Add abstract here.\n",
      "cites: 1\n",
      "(0 citations)\n",
      "____________________________________________________________________________________________________________________________________\n",
      "W1486723856, https://openalex.org/W1486723856\n",
      "title: Combining Language and Vision with a Multimodal Skip-gram Model\n",
      "year: 2015\n",
      "abstract length: 914, topic: n-gram,\n",
      "concepts: ['n-gram', 'Computer science', 'Natural language processing', 'Artificial intelligence', 'Question answering', 'Set (abstract data type)', 'Variety (cybernetics)', 'Word (group theory)', 'Language model', 'Test set', 'Gram', 'Linguistics', 'Programming language', 'Biology', 'Bacteria', 'Genetics', 'Philosophy']\n",
      "institutions: \n",
      "abstract: We extend the SKIP-GRAM model of Mikolov et al. (2013a) by taking visual information into account. Like SKIP-GRAM, our multimodal models (MMSKIP-GRAM) build vector-based word representations by learning to predict linguistic contexts in text corpora. However, for a restricted set of words, the models are also exposed to visual representations of the objects they denote (extracted from natural images), and must predict linguistic and visual features jointly. The MMSKIP-GRAM models achieve good performance on a variety of semantic benchmarks. Moreover, since they propagate visual information to all words, we use them to improve image labeling and retrieval in the zero-shot setup, where the test concepts are never seen during model training. Finally, the MMSKIP-GRAM models discover intriguing visual properties of abstract words, paving the way to realistic implementations of embodied theories of meaning.\n",
      "cites: 1\n",
      "(0 citations)\n",
      "____________________________________________________________________________________________________________________________________\n",
      "W1492428145, https://openalex.org/W1492428145\n",
      "title: Disentangling the Social and the Pedagogical in Infants' Learning about Tool‐Use\n",
      "year: 2011\n",
      "abstract length: 1116, topic: Psychology,\n",
      "concepts: ['Psychology', 'Developmental psychology', 'Context (archaeology)', 'Cognitive psychology', 'Task (project management)', 'Action (physics)', 'Social environment', 'Law', 'Management', 'Biology', 'Paleontology', 'Political science', 'Physics', 'Economics', 'Quantum mechanics']\n",
      "institutions: \n",
      "abstract: Abstract We investigated infants' response to pedagogy in the domain of tool use. In experiment 1, infants viewed a causally relevant tool‐use demonstration presented identically in either a social/pedagogical or social/non‐pedagogical context. Infants exposed to pedagogical cues displayed superior production of the tool‐use sequence. This was so despite infants displaying equivalent attention to the demonstration across conditions. In contrast, pedagogical cues had no systematic impact on infants' discrimination between causally possible vs. impossible tool‐use sequences in a looking‐time task. Interestingly, however, older infants across both conditions displayed a preference for looking toward the causally possible display. Experiment 2 documented that social cues of any sort (regardless of pedagogy) accompanying the demonstration triggered older infants to discriminate the causally possible vs. impossible events whereas a non‐social demonstration did not. Together, the two experiments implicate ‘social gating’ as well as a pedagogical stance in infants' processing and execution of causal action.\n",
      "cites: 1\n",
      "(0 citations)\n",
      "____________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Example centrality measures\n",
    "pagerank = nx.pagerank(G)\n",
    "degree = dict(G.out_degree())\n",
    "\n",
    "# Sorted most cited (high indegree)\n",
    "most_cited = sorted(G.in_degree(), key=lambda x: x[1], reverse=True)[:5]\n",
    "print(\"Top 5 most cited papers (by indegree):\")\n",
    "for paper_id, indeg in most_cited:\n",
    "    title = G.nodes[paper_id].get(\"title\", \"N/A\")\n",
    "    year = G.nodes[paper_id].get(\"year\", \"N/A\")\n",
    "    url = G.nodes[paper_id].get(\"url\", \"N/A\")\n",
    "    abstract_len = len(G.nodes[paper_id].get(\"abstract\"))\n",
    "    topic = G.nodes[paper_id].get(\"topic\")\n",
    "    concepts = G.nodes[paper_id].get(\"concepts\")\n",
    "    insitutions = G.nodes[paper_id].get(\"institutions_flat\")\n",
    "    abstract = G.nodes[paper_id].get(\"abstract\")\n",
    "    cites = G.out_degree(paper_id)\n",
    "    print(f\"{paper_id}, {url}\\ntitle: {title}\\nyear: {year}\\nabstract length: {abstract_len}, topic: {topic},\\nconcepts: {concepts}\\ninstitutions: {insitutions}\\nabstract: {abstract}\\ncites: {cites}\\n({indeg} citations)\")\n",
    "    print(\"____________________________________________________________________________________________________________________________________\")\n",
    "\n",
    "least_cited = sorted(G.in_degree(),key = lambda x: x[1], reverse=False)[:5]\n",
    "print(\"Top 5 least cited papers (by ind-degree)\")\n",
    "for paper_id, indeg in least_cited:\n",
    "    title = G.nodes[paper_id].get(\"title\", \"N/A\")\n",
    "    year = G.nodes[paper_id].get(\"year\", \"N/A\")\n",
    "    url = G.nodes[paper_id].get(\"url\", \"N/A\")\n",
    "    abstract_len = len(G.nodes[paper_id].get(\"abstract\"))\n",
    "    topic = G.nodes[paper_id].get(\"topic\")\n",
    "    concepts = G.nodes[paper_id].get(\"concepts\")\n",
    "    insitutions = G.nodes[paper_id].get(\"institutions_flat\")\n",
    "    abstract = G.nodes[paper_id].get(\"abstract\")\n",
    "    cites = G.out_degree(paper_id)\n",
    "    print(f\"{paper_id}, {url}\\ntitle: {title}\\nyear: {year}\\nabstract length: {abstract_len}, topic: {topic},\\nconcepts: {concepts}\\ninstitutions: {insitutions}\\nabstract: {abstract}\\ncites: {cites}\\n({indeg} citations)\")\n",
    "    print(\"____________________________________________________________________________________________________________________________________\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ef3adf",
   "metadata": {},
   "source": [
    "A pre-emptive analysis into most cited and least cited papers was done. \n",
    "The most cited papers (with the highest in-degree) in the network that is being analyzed include such titles as \n",
    "- \"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\" from Google (United States) and German Research Centre for Artificial Intelligence from 2022 with the topic of Image (mathematics) analysis. It has 897 citations, being the most cited paper in this network.\n",
    "- \"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models\" from 2022 with the topic of Computer Science and 669 citations. It discusses a popular topic in today's AI discussion about Chain-of-Thought\n",
    "- \"Transformers: State-of-the-Art Natural Language Processing\" from 2020 with the Art History topic of all things? with 586 citations. The topic assignment seems unusual, but looking into the concepts discussed in the paper it can be seen that it actuyally discusses transformers, computer science, as well as art, natural (archaeology), history, electrical engineering.\n",
    "- \"BioBERT: a pre-trained biomedical language representation model for biomedical text mining\" from 2019 from Korea University, Naver (South Korea) with the topic of Biomedical text mining and 495 citations in this network. \n",
    "- \"Large language models encode clinical knowledge\" from 2023 from Google (United States), United States National Library of Medicine, DeepMind (United Kingdom) with the topic of Computer Science and 450 citations. \n",
    "\n",
    "The least cited papers in this network have as few as 0 citations. In addition, these papers have very few papers in the ntwork they cite themselves. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebac00f",
   "metadata": {},
   "source": [
    "### General Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fe7077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Papers per Topic ===\n",
      "Computer science: 5831\n",
      "Transformer: 1151\n",
      "Medicine: 285\n",
      "Perplexity: 176\n",
      "None: 143\n",
      "Automatic summarization: 140\n",
      "Artificial intelligence: 128\n",
      "Foundation (evidence): 125\n",
      "Preprint: 110\n",
      "Interpretability: 103\n",
      "Generative grammar: 80\n",
      "Psychology: 76\n",
      "Segmentation: 76\n",
      "Dissolved gas analysis: 75\n",
      "Closed captioning: 65\n",
      "Biology: 64\n",
      "Health care: 64\n",
      "Readability: 63\n",
      "Context (archaeology): 62\n",
      "Chatbot: 62\n",
      "Hyperspectral imaging: 58\n",
      "Materials science: 57\n",
      "Question answering: 56\n",
      "Benchmark (surveying): 53\n",
      "Convolutional neural network: 53\n",
      "Inference: 50\n",
      "Inrush current: 49\n",
      "Benchmarking: 49\n",
      "Workflow: 46\n",
      "Reliability engineering: 45\n",
      "Partial discharge: 45\n",
      "Machine translation: 44\n",
      "Nanofluid: 40\n",
      "Transformative learning: 39\n",
      "Leverage (statistics): 39\n",
      "Converters: 38\n",
      "Task (project management): 38\n",
      "Reinforcement learning: 36\n",
      "Discriminative model: 35\n",
      "Linguistics: 34\n",
      "Zhàng: 33\n",
      "Encoder: 33\n",
      "Natural language processing: 33\n",
      "Adversarial system: 31\n",
      "Transformer oil: 30\n",
      "Electromagnetic coil: 29\n",
      "Support vector machine: 29\n",
      "Leakage inductance: 28\n",
      "Mineral oil: 28\n",
      "Mental health: 28\n",
      "Generalizability theory: 28\n",
      "Embedding: 28\n",
      "Photovoltaic system: 27\n",
      "Conversation: 27\n",
      "Robustness (evolution): 27\n",
      "Consistency (knowledge bases): 27\n",
      "Harmonics: 26\n",
      "Usability: 26\n",
      "Electrical engineering: 26\n",
      "Overfitting: 26\n",
      "Sentiment analysis: 26\n",
      "Security token: 26\n",
      "Misinformation: 26\n",
      "Physics: 25\n",
      "Artificial neural network: 25\n",
      "Distribution transformer: 25\n",
      "Cognition: 25\n",
      "Sentence: 24\n",
      "Point cloud: 24\n",
      "Autoregressive model: 24\n",
      "Current transformer: 23\n",
      "Language model: 23\n",
      "Social media: 23\n",
      "Debiasing: 23\n",
      "Perspective (graphical): 22\n",
      "Modular design: 21\n",
      "Genome: 21\n",
      "Softmax function: 21\n",
      "Chen: 21\n",
      "Medical diagnosis: 21\n",
      "Cluster analysis: 20\n",
      "Transparency (behavior): 20\n",
      "Foraging: 19\n",
      "Treebank: 19\n",
      "Narrative: 19\n",
      "Electroencephalography: 19\n",
      "Coronavirus disease 2019 (COVID-19): 19\n",
      "Computational biology: 18\n",
      "Annotation: 18\n",
      "Systematic review: 18\n",
      "Bengali: 18\n",
      "Offensive: 18\n",
      "Sequence (biology): 18\n",
      "Inductor: 17\n",
      "Finite element method: 17\n",
      "Business: 17\n",
      "Creativity: 17\n",
      "Quality (philosophy): 17\n",
      "Generalization: 17\n",
      "Autoencoder: 17\n",
      "Computer security: 17\n",
      "Triage: 17\n",
      "Test (biology): 17\n",
      "Geospatial analysis: 17\n",
      "Bushing: 16\n",
      "Tap changer: 16\n",
      "Software deployment: 16\n",
      "Gesture: 15\n",
      "Reliability (semiconductor): 15\n",
      "German: 15\n",
      "Embodied cognition: 15\n",
      "Perception: 15\n",
      "Personalization: 15\n",
      "Microgrid: 15\n",
      "Paraphrase: 15\n",
      "Residual: 15\n",
      "Computer vision: 15\n",
      "Grading (engineering): 15\n",
      "Troglodytes: 14\n",
      "Smart grid: 14\n",
      "Correctness: 14\n",
      "Pressboard: 14\n",
      "Adaptation (eye): 14\n",
      "Parsing: 14\n",
      "Decoding methods: 14\n",
      "Architecture: 14\n",
      "Adapter (computing): 14\n",
      "SemEval: 14\n",
      "Deep learning: 14\n",
      "Workload: 14\n",
      "Phishing: 14\n",
      "Empathy: 14\n",
      "Robot: 13\n",
      "Automation: 13\n",
      "Affordance: 13\n",
      "Relevance (law): 13\n",
      "Bridging (networking): 13\n",
      "Audit: 13\n",
      "Python (programming language): 13\n",
      "End-to-end principle: 13\n",
      "Disinformation: 13\n",
      "Scale (ratio): 13\n",
      "Machine learning: 13\n",
      "Key (lock): 13\n",
      "Popularity: 13\n",
      "CLARITY: 13\n",
      "Drone: 12\n",
      "Control theory (sociology): 12\n",
      "ENCODE: 12\n",
      "Renewable energy: 12\n",
      "Identification (biology): 12\n",
      "Speedup: 12\n",
      "Counterfactual thinking: 12\n",
      "Concordance: 12\n",
      "Dialog box: 12\n",
      "Sarcasm: 12\n",
      "Metadata: 12\n",
      "Memorization: 12\n",
      "Pooling: 12\n",
      "Spectrogram: 12\n",
      "Arabic: 12\n",
      "Politics: 12\n",
      "Shot (pellet): 12\n",
      "Emergency department: 12\n",
      "Geomagnetically induced current: 11\n",
      "Magnetostriction: 11\n",
      "Process (computing): 11\n",
      "Ferroresonance in electricity networks: 11\n",
      "Ontology: 11\n",
      "Modalities: 11\n",
      "Brain–computer interface: 11\n",
      "Current (fluid): 11\n",
      "Drug discovery: 11\n",
      "Machining: 11\n",
      "Epitope: 11\n",
      "Training (meteorology): 11\n",
      "Ultra high frequency: 11\n",
      "Vocabulary: 11\n",
      "Ranking (information retrieval): 11\n",
      "Discriminator: 11\n",
      "Initialization: 11\n",
      "Hyperparameter: 11\n",
      "Negation: 11\n",
      "Distillation: 11\n",
      "Domain (mathematical analysis): 11\n",
      "Backdoor: 11\n",
      "Breast cancer: 11\n",
      "Modal: 11\n",
      "RNA: 11\n",
      "Coding (social sciences): 11\n",
      "Medical education: 11\n",
      "Biomedicine: 11\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2192ae1f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cc52637",
   "metadata": {},
   "source": [
    "### Degree Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48ef9f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "in_degrees = [d for _, d in G.in_degree()]\n",
    "out_degrees = [d for _, d in G.out_degree()]\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(in_degrees, bins=50, density=False)\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"In-Degree Distribution (log scale)\")\n",
    "plt.xlabel(\"In-degree (# times cited by others)\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(out_degrees, bins=50, density=False)\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Out-Degree Distribution (log scale)\")\n",
    "plt.xlabel(\"Out-degree (# of citations)\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d903e4",
   "metadata": {},
   "source": [
    "### Co-authorship network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d6bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# import itertools\n",
    "# import json\n",
    "# import os\n",
    "\n",
    "# G = nx.Graph()  # undirected co-authorship network\n",
    "\n",
    "# for file in os.listdir(\"papers_full\"):\n",
    "#     if not file.endswith(\".json\"):\n",
    "#         continue\n",
    "\n",
    "#     with open(os.path.join(\"papers_full\", file), encoding=\"utf-8\") as f:\n",
    "#         data = json.load(f)\n",
    "\n",
    "#     # Extract only valid author IDs\n",
    "#     authors = [a.get(\"id\") for a in data.get(\"authors\", []) if a.get(\"id\")]\n",
    "\n",
    "#     # Skip papers with fewer than 2 authors (no collaboration)\n",
    "#     if len(authors) < 2:\n",
    "#         continue\n",
    "\n",
    "#     # Add authors as nodes\n",
    "#     for author in authors:\n",
    "#         G.add_node(author)\n",
    "\n",
    "#     # Add undirected edges between co-authors\n",
    "#     for a1, a2 in itertools.combinations(authors, 2):\n",
    "#         G.add_edge(a1, a2)\n",
    "\n",
    "# print(\"Nodes:\", G.number_of_nodes())\n",
    "# print(\"Edges:\", G.number_of_edges())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0faec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Degree distribution of co-authors\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# degrees = [d for _, d in G.degree()]\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.hist(degrees, bins=50, density=False)\n",
    "# plt.yscale(\"log\")\n",
    "# plt.title(\"Co-authorship Network Degree Distribution (log scale)\")\n",
    "# plt.xlabel(\"Degree\")\n",
    "# plt.ylabel(\"Count\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834961c3",
   "metadata": {},
   "source": [
    "### Author Citation Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e3c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Author citation network built\n",
      "Nodes: 55431\n",
      "Edges: 2206140\n"
     ]
    }
   ],
   "source": [
    "# import networkx as nx\n",
    "# import os\n",
    "# import json\n",
    "\n",
    "# G = nx.DiGraph()\n",
    "\n",
    "# # Preload all paper data\n",
    "# papers = {\n",
    "#     fname[:-5]: json.load(open(\"papers_full/\" + fname, encoding=\"utf-8\"))\n",
    "#     for fname in os.listdir(\"papers_full\")\n",
    "#     if fname.endswith(\".json\")\n",
    "# }\n",
    "\n",
    "# for paper_id, data in papers.items():\n",
    "\n",
    "#     # Extract only valid author IDs\n",
    "#     authors = [a.get(\"id\") for a in data.get(\"authors\", []) if a.get(\"id\")]\n",
    "\n",
    "#     for ref_url in data.get(\"references\", []):\n",
    "#         ref_id = ref_url.split(\"/\")[-1]\n",
    "#         ref_paper = papers.get(ref_id)\n",
    "\n",
    "#         if not ref_paper:\n",
    "#             continue\n",
    "\n",
    "#         # Extract referenced paper's author IDs (filter out None)\n",
    "#         ref_authors = [a.get(\"id\") for a in ref_paper.get(\"authors\", []) if a.get(\"id\")]\n",
    "\n",
    "#         # Create directed edges author → referenced_author\n",
    "#         for a in authors:\n",
    "#             for b in ref_authors:\n",
    "#                 if a and b:  # prevent invalid edges\n",
    "#                     G.add_edge(a, b)\n",
    "\n",
    "# print(\"✅ Author citation network built\")\n",
    "# print(f\"Nodes: {G.number_of_nodes()}\")\n",
    "# print(f\"Edges: {G.number_of_edges()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e4baa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Degree distribution of authors citing each other\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# in_degrees = [d for _, d in G.in_degree()]\n",
    "# out_degrees = [d for _, d in G.out_degree()]\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.hist(in_degrees, bins=50, density=False)\n",
    "# plt.yscale(\"log\")\n",
    "# plt.title(\"Author Citation Network In-Degree Distribution (log scale)\")\n",
    "# plt.xlabel(\"In-degree (# times cited by other authors)\")\n",
    "# plt.ylabel(\"Count\")\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.hist(out_degrees, bins=50, density=False)\n",
    "# plt.yscale(\"log\")\n",
    "# plt.title(\"Author Citation Network Out-Degree Distribution (log scale)\")\n",
    "# plt.xlabel(\"Out-degree (# times citing other authors)\")\n",
    "# plt.ylabel(\"Count\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# nx.write_gexf(G, \"author_citation_network.gexf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
