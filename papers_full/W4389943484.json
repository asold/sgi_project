{
  "title": "Timeshifting strategies for carbon-efficient long-running large language model training",
  "url": "https://openalex.org/W4389943484",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A3205506805",
      "name": "Akshaya Jagannadharao",
      "affiliations": [
        "Intel (United States)",
        "Mission College"
      ]
    },
    {
      "id": "https://openalex.org/A3214613612",
      "name": "Nicole Beckage",
      "affiliations": [
        "Intel (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2048036251",
      "name": "Dawn Nafus",
      "affiliations": [
        "Intel (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2337472769",
      "name": "Scott Chamberlin",
      "affiliations": [
        "Mission College",
        "Intel (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A3205506805",
      "name": "Akshaya Jagannadharao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3214613612",
      "name": "Nicole Beckage",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2048036251",
      "name": "Dawn Nafus",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2337472769",
      "name": "Scott Chamberlin",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3037032032",
    "https://openalex.org/W2963809228",
    "https://openalex.org/W3106369401",
    "https://openalex.org/W4283704460",
    "https://openalex.org/W2176769801",
    "https://openalex.org/W3177201695",
    "https://openalex.org/W6629340653",
    "https://openalex.org/W6780161852",
    "https://openalex.org/W3213101878",
    "https://openalex.org/W3157788795",
    "https://openalex.org/W6601439449",
    "https://openalex.org/W3106171539",
    "https://openalex.org/W4283157527",
    "https://openalex.org/W3175111539"
  ],
  "abstract": "Abstract Language models play a vital role in various natural language processing tasks, but their training can be computationally intensive and lead to significant carbon emissions. In this study, we explore the effectiveness of timeshifting strategies to mitigate the environmental impact of long-running large language models (LLMs). We develop a simulation tool that estimates carbon emissions for LLMs, enabling developers to make informed decisions prior to running their workloads. By leveraging historical carbon intensity data from WattTime, we investigate the potential benefits and limitations of timeshifting in different locations, considering diverse energy profiles. Our findings demonstrate that timeshifting can substantially reduce emissions, but it is highly dependent on the region’s carbon intensity and energy mix. We present insights into the trade-offs between emissions reduction and workload runtime, acknowledging the need for further advancements in carbon-aware computing practices. Our research contributes to the growing field of sustainable computing and encourages developers to adopt environmentally conscious strategies in language model training.",
  "full_text": "Innovations in Systems and Software Engineering (2025) 21:517–531\nhttps://doi.org/10.1007/s11334-023-00546-x\nORIGINAL PAPER\nTimeshifting strategies for carbon-efﬁcient long-running large\nlanguage model training\nAkshaya Jagannadharao 1 · Nicole Beckage 2 · Dawn Nafus 2 · Scott Chamberlin 1\nReceived: 1 August 2023 / Accepted: 18 November 2023 / Published online: 19 December 2023\n© The Author(s) 2023\nAbstract\nLanguage models play a vital role in various natural language processing tasks, but their training can be computationally\nintensive and lead to signiﬁcant carbon emissions. In this study, we explore the effectiveness of timeshifting strategies\nto mitigate the environmental impact of long-running large language models (LLMs). We develop a simulation tool that\nestimates carbon emissions for LLMs, enabling developers to make informed decisions prior to running their workloads. By\nleveraging historical carbon intensity data from WattTime, we investigate the potential beneﬁts and limitations of timeshifting\nin different locations, considering diverse energy proﬁles. Our ﬁndings demonstrate that timeshifting can substantially reduce\nemissions, but it is highly dependent on the region’s carbon intensity and energy mix. We present insights into the trade-\noffs between emissions reduction and workload runtime, acknowledging the need for further advancements in carbon-aware\ncomputing practices. Our research contributes to the growing ﬁeld of sustainable computing and encourages developers to\nadopt environmentally conscious strategies in language model training.\nKeywords Large language model (LLM) · Energy consumption · Carbon-awareness · Timeshifting\n1 Introduction\nWith the rapid growth of Large Language Models (LLMs)\nfollowing the release of GPT-3, their transformative impact\non various natural language processing tasks is undeni-\nable. However, their development has been plagued by a\ncritical challenge: the extraordinary amount of hardware,\nenergy resources (and associated CO\n2 emissions to gen-\nerate this energy), and time required for training. Despite\ntheir impressive performance, the training of LLMs comes\nB Akshaya Jagannadharao\nakshaya.jagannadharao@intel.com\nNicole Beckage\nnicole.beckage@intel.com\nDawn Nafus\ndawn.nafus@intel.com\nScott Chamberlin\nscott.chamberlin@intel.com\n1 Software and Advanced Technology Group (SA TG), Intel\nCorporation, Mission College Blvd, Santa Clara, CA 95054,\nUSA\n2 Sociotechnical Systems, Intel Labs, Jones Farms, Hillsboro,\nOR 97124, USA\nat a substantial cost to our environment. The massive energy\nconsumption directly contributes to a signiﬁcant increase in\nCO2-eq emissions, potentially exacerbating the ongoing cli-\nmate crisis. Further, this increase of CO 2-eq emissions in\nrelation to Natural Language Processing (NLP) models is\nexpected to grow exponentially over time [ 1, 2]. One appli-\ncable technique, which hasn’t yet been deployed at scale\nfor large-scale machine learning (ML) training, is carbon-\nawareness. Carbon-awareness can be deﬁned as modifying\nthe behavior of your software to do more work (i.e., consume\nmore energy) when higher amounts of renewable energy are\naccessible, thereby lessening the burden on the power grid.\nOn the other hand, it also involves reducing energy consump-\ntion during periods of lower availability to renewable, which\nsupports the grid in managing workloads more effectively,\nensuring that tasks are scheduled in line with the grid’s gener-\nation capacity [3]. The purpose of using WattTime’s Marginal\nOperating Emissions rate (MOER) is not to do with load per\nse, but speciﬁcally managing the load in ways that avoid the\nuse of ’peaker plants’—plants that are turned on only to deal\nwith peak load—which in turn contributes to carbon intensity.\nAs the world grapples with the urgent need to address carbon\nemissions, there is a unique opportunity to embed carbon-\nawareness in the development and deployment of large-scale\n123\n518 A. Jagannadharao et al.\nML algorithms. Introducing carbon-awareness into the train-\ning and deployment of LLMs provides a path for sustainable\ninnovation.\nThe primary objective of this paper is to explore the con-\ncept of carbon-awareness in LLMs and propose a novel\nsimulation toolkit using temporal shifting. For this paper,\nwe consider temporal shifting to be a tool that optimizes the\ntraining of the model to the current power grid, taking advan-\ntage of the dynamic nature of renewable energy resources.\nBy developing simulations to estimate the total training\ntime of an LLM under different timeshifting assumptions,\nwe demonstrate how timeshifting can signiﬁcantly reduce\nthe carbon footprint of LLMs. Leveraging the dynamic nature\nof the grid with the batchable workloads of LLM training,\nwe are able to see a meaningful trade-off between emissions\nsavings and time. Beyond our exploration of timeshifting,\nwe also consider the variability across and within different\npower grids and simulate emission estimates for different\nworkloads relative to where and when these workloads are\nrun.\nIn the subsequent sections of this paper, we will lay\nthe groundwork for developing simulations to explore the\neffects of timeshifting on training LLMs. Our methodol-\nogy will involve constructing realistic training scenarios and\nevaluating the impact on model performance and how we\ncan improve on existing techniques to build more carbon-\nawareness into existing applications. We build on generic\ntimeshifting strategies to create a two-threshold timeshifting\nmethodology. We believe this research expands the strategies\navailable to researchers to decarbonize LLM research.\n2 Background and previous work\nThere is a growing community of researchers focusing on the\nneed for sustainability in deep neural network development.\nFrom this body of work, it has become clear that energy efﬁ-\nciency, particularly performance per watt, is not a complete\nview of the carbon cost of training algorithms. Optimizing for\nperformance per watt neglects the complexity of the energy\ngrid which can vary both in time and space. Figure 2 shows\nhow the energy grid is dynamic. There is clear location, sea-\nsonal, and time variability. For example, an energy grid in\nCalifornia has diurnal variability: solar power is only avail-\nable when the sun is shining. Further, overall grid usage can\nvary based on changing demands which can be difﬁcult to\nestimate.\nAs more renewables come online, and as battery technol-\nogy lags in its ability to stabilize the grid, this intermittency\nis only going to grow in the future. Being “carbon-aware,”\nthen, means being aware of, and resilient to, this intermit-\ntency. We focus on one solution to build resilience and adapt\nto grid intermittency: timeshifting model training.\nThere is also increased societal and regulatory pressure\nto improve carbon reporting in general, and for assessments\nof AI emissions speciﬁcally [ 4]. LLMs have become a rep-\nutational issue for the technology industry as a whole [ 5].\nWhile there is a belief that ML models will plateau in size and\nthen reduce [ 6], there is no shortage of innovation in model-\ning that considers bigger architectures and more parameters\nto be the easiest solution for more predictive and accurate\nmodels. If model efﬁciency is not inevitable, and efﬁciency\nefforts in the technology industry tend to lead to more emis-\nsions in the long term, not less, due to Jevon’s paradox [ 7],\ndecarbonization—and even just foregoing work that does not\nneed to be done—must play a stronger role in developer deci-\nsions than it does currently.\nMuch of the work to improve the carbon footprint of\nmodels has been directly tied to improving efﬁciency and\nperformance of models, relating improvement in efﬁciency\nto sustainability. Some of these techniques for improving efﬁ-\nciency directly try to reduce the number of model parameters\nthrough methods such as distillation, e.g., [ 8], sparsity, e.g.,\n[9], reducing space and/or time complexity, e.g., [ 10]o re v e n\nintroducing lighter weight LM models for training data selec-\ntion [11]. There is a body of work describing and categorizing\nthese efﬁciency improvements (e.g., [ 12] for transformers or\n[13] for foundation models and their respective references)\nbut efﬁciency is not the same thing as sustainability. Sus-\ntainability requires a broader view of the problem, beyond\nsimply ensuring the code, architecture, and model parameter\nsize is correctly scaled to the application of a model.\nOther approaches to sustainability considerations in the\ndevelopment, training and deployment of models have been\nemerging across the literature. Some of these works include\nresources and models to estimate carbon emissions, e.g.,\n[14–16], while others focus on and quantify the effect of\noptimizing speciﬁc aspects of the algorithms to lower car-\nbon cost, e.g., [ 17] via grid and resource consideration. Other\nfocus on the need for data and accurate reporting [ 18, 19],\nsuggesting various tools such as leaderboards to incentivize\nthe larger ML community [ 19] These efforts collectively cap-\nture a growing change in perspective in the community. We\ncapitalize on this growing interest and perspective to focus on\nthe usefulness and applicability of deﬁning and exploring the\nuse of algorithms that dynamically adapt to the current energy\nand grid environment. Speciﬁcally, we focus on timeshifting\nthe workload to start, pause, resume and end with carbon cost\nin mind.\nPrevious work in the timeshifting domain has primarily\nfocused on smaller language models with relatively short\ntraining times [ 20]. Dodge et al. demonstrated that timeshift-\ning can lead to an 80% reduction in carbon emissions when\napplied to these models within a 6–24 h window [ 20]. How-\n123\nTimeshifting strategies for carbon-efﬁcient long-running large… 519\never, LLMs present a unique challenge as their training can\nextend over several months. Meta AI, for example, estimates\nthat it took 5 months to train their LLaMa (Large Language\nModel Meta AI) LLM model [ 21]. To address this challenge,\nwe have developed a simulation tool that estimates emissions\nfor larger models without the need to physically run the work-\nload. The tool also incorporates the cost of system idle time\nto gain insights into the overall cost of timeshifting. By pro-\nviding developers with this tool, we aim to empower them\nto make informed decisions in reducing carbon emissions\nbefore writing a line of code.\n3 Challenges\nCalculating carbon emissions for a piece of software, such as\nan LLM, presents a multifaceted and intricate task. Follow-\ning the Software Carbon Intensity Speciﬁcation detailed by\nthe Green Software Foundation [ 22], we break down emis-\nsions into two components: operational carbon emissions and\nembodied carbon emissions. The sum of these components\nmakes up the carbon emissions for a particular workload.\nThe complexity arises primarily due to several interrelated\nchallenges:\n1. Carbon Intensity: Obtaining precise carbon intensity val-\nues corresponding to different energy sources requires\naccess to a comprehensive and up-to-date database. In our\nresearch, we utilize WattTime to retrieve carbon inten-\nsity values from the grid [ 23], similar to other work in\ntimeshifting [ 20]. WattTime makes predictions of carbon\nintensity values up to 72 h into the future. Our timeshifting\napproach uses these predictions to schedule work in a way\nthat reduces overall carbon emissions. However, these are\nonly predictions and the actual associated emissions may\ndiffer widely from the predicted values.\nIn addition, WattTime reports MOER carbon intensity\nvalues. MOER values represent the impact of adding\nan additional load to the grid. In comparison, average\nemissions represent the overall sustainability of the sys-\ntem. The ﬂexibility of our simulation allows us to switch\nbetween MOER and average emissions. However, con-\nsidering resource constraints, we have made a deliberate\nchoice to concentrate our efforts on MOER values for\nour calculations. This decision is driven by the desire to\ncomprehensively explore the effects of timeshifting on\nimmediate carbon emissions and its alignment with grid\ndynamics.\nCarbon intensity information is notoriously inconsistent\nacross sources, often due to scoping issues [ 20]. Even\nunits suffer inconsistencies. For example, Dodge et al\n[20] also used WattTime, and indicated that WattTime\nuses carbon dioxide equivalent (CO\n2e), which includes\nall greenhouse gasses converted to the equivalent amount\nof global warming potential of carbon dioxide. Yet Watt-\nTime’s documentation suggests their data refers to CO\n2\nonly. Data from the US Environmental Protection Agency\n[24] suggest that this might ultimately make little practical\ndifference numerically, but it demonstrates the inconsis-\ntencies that are commonplace in this area.\nHence, we refrain from attempting to make our estimates\ncomparable across data sources by choosing only one\nsource: WattTime. This ensures that there is a level of\nconsistency as we do our calculations.\n2. LLM-Speciﬁc Challenges: LLMs, with their immense\ncomputational demands and prolonged training times,\nexacerbate the complexities of measuring carbon emis-\nsions compared to conventional software applications.\nThe distributed and parallel nature of LLM training fur-\nther complicates the assessment of energy consumption\nand carbon impact. We address this issue by assuming the\nworkload uses all available compute resources. However,\nthis assumption may introduce some level of uncertainty.\n3. Data center management: Similar to maintaining a power\ngrid to always have electricity available, data centers are\ntasked with keeping computing resources at the ready for\ncustomers. However, this means that systems remain in\nan idle state until work is scheduled. Maintaining large\namounts of compute resources, even in idle states, requires\na large amount of power (and thus releases a large amount\nof carbon).\nOur simulation attempts to consider the cost of leaving the\nsystem idle by using the idle power of the device in our\ncalculations; however, this is a simpliﬁed estimation of\nidle power and it does not take into account the dynamic\nnature of idle such as when the system switches between\nstandby mode and background tasks.\nThere is a growing need to understand how idle systems\ncontribute to carbon cost and how scheduling when and\nhow many servers are available at any given time impacts\nthe overall carbon cost of LLM compute. Further, under-\nstanding different system states and their impact on carbon\nemissions may provide simple strategies to lowering the\ncarbon emissions of systems at rest.\n4 Power grid analysis\nUnderstanding the intricacies of the power grid is essential for\nsufﬁciently accurate carbon calculations and effective work-\nload planning. In this paper, we focus on a few speciﬁc grids,\nnamely a relatively ’green’ grid run by the California ISO\nNorth balancing authority (CAISO_NORTH), a grid with a\nlarge amount of variability run by SPP Western Nebraska\n(SPP_WESTNE), and a fairly ’dirty’ grid run by W APA\nRocky Mountain Region (W ACM). Our default grid for anal-\n123\n520 A. Jagannadharao et al.\nFig. 1 Marginal Operating Emissions Rate (MOER) of three different\ngrids across different years and months\nyses is California ISO North, 1 but as can be seen in Fig. 1,\nthere is a lot of variability in marginal emissions across dif-\nferent grids and across different times of the year.\nEach grid also has different mixes of fossil fuels and\nrenewable energy. While the MOER values take into account\nthe carbon cost of the fuel source, it can be helpful to know\nmore information about the grid. For example. California’s\nenergy mix exhibits a signiﬁcant dependence on fossil fuels,\nconstituting about 66% of its energy consumption in 2021\n[25]. Conversely, renewable energy sources contribute only\n33% to the state’s energy supply, with solar contributing 14%\nand wind contributing 11%. The disparity between these ﬁg-\nures underscores the importance of addressing the carbon\nfootprint of software workloads, as they signiﬁcantly con-\ntribute to greenhouse gas emissions in regions like California\n(Fig. 2).\nGraphing the emissions reported by WattTime over the\nyear for these three test locations, we see a similar global\npattern where certain grids have more overall marginal emis-\nsions but also that there is variability in day-to-day on some\ngrids more than others.\nInsights gained from this power grid analysis are invalu-\nable for effective workload planning and carbon-aware\nalgorithm design. It is obvious that choosing a grid with\noverall lower marginal carbon emissions can greatly affect\nthe overall carbon impact of the model. However, by under-\nstanding the temporal variations in marginal carbon intensity,\nwe can go one step further and build training schedules and\nsoftware execution that can capitalize on the temporal vari-\n1 We choose California ISO North as our default grid as the MOER\ndata is accessible to all via WattTime without a subscription.\nFig. 2 Marginal Operating Emissions Rate (MOER) for our three grids\nduring the week of June 1, 2022\nability in the grid. We can, for example, align training with\nperiods of lower carbon emissions, contributing to a greener\nand more sustainable software development approach.\n5 Approach\n5.1 System and energy estimation\nOur simulation tool kit allows for quick and easy estimations\nof the overall carbon cost of a particular large-scale training\nprocedure. The simulation breaks down the problem of esti-\nmating the carbon cost of training a large-scale model into\nthree main components: the system, carbon emission estima-\ntion, and the time shift. We begin by deﬁning the number of\nnodes and devices in the system. Using the idle and Ther-\nmal Design Power (TDP) characteristics of the hardware, we\nestimate the system’s idle and max power consumption.\nFor this simulation, we assume that each node in the sys-\ntem is running at the same rate and either in idle or max state.\nThe idle state for a node is the product of the CPU/GPU power\nusage at rest multiplied by the number of CPUs/GPUs used\nin each node. The node max is similarly deﬁned as the TDP\nvalue associated with the speciﬁc hardware. Thus the system\nidle/max is just the number of nodes multiplied by the calcu-\nlated node level idle or max power. We obtain TDP and idle\npower values from the manufacturer’s product speciﬁcations.\nIn our system deﬁnition, we approximate a system with\na generic CPU and GPU. Our estimation tool needs only an\nestimate of each component’s Thermal Design Power (TDP)\nand idle power consumption. TDP estimation is publicly\navailable from many different sources. Idle power, however,\nis more difﬁcult to estimate, as this information is not read-\nily publicly available and can vary signiﬁcantly based on\nindividual system conﬁguration and hardware. We use TDP\n123\nTimeshifting strategies for carbon-efﬁcient long-running large… 521\nestimates from CodeCarbon [ 26] and use ballpark estima-\ntions of CPU idle at 10 watts and GPU idle at 15 watts. We\nleave this discussion of power usage estimation for the future\nwork section in favor of focusing on our calculations for esti-\nmating carbon costs.\nFor simplicity, we currently consider only these two\nsystem states. Still, future work could incorporate more gran-\nularity by using power curves distributed by manufacturers\nand better-characterizing hardware utilization as the work-\nload runs. There is also the potential to add more devices\nlike accelerators and memory to the system deﬁnition.\n5.2 Carbon estimation\nTo calculate carbon emissions, we utilize historical data\nobtained from WattTime. WattTime data is available as part\nof an API where registered users can access location-speciﬁc\nmarginal carbon emissions. The MOER is computed using\nthe EPA CAMPD data [ 27] which provides hourly electricity\ngeneration and emissions of major fossil-fuel power plants\nin the United States. These values are derived by apply-\ning a regression model to the fossil-fuel emissions reported\nby power plants and are supplemented with additional data\nabout renewable energy sources [ 28]. WattTime reports the\ncarbon intensity of the grid as MOER values at 5-minute\nintervals. The location granularity of WattTime is dictated\nby the region’s power balancing authority which is respon-\nsible for grid balancing. In total, WattTime has 100 unique\npower grid locations, covering the full United States and parts\nof Canada. While access to this API requires a subscription\nor data request from WattTime, individuals can replicate our\nwork with free access from WattTime to historical data from\nCalifornia ISO North’s MOER values over time.\nWhile WattTime has some predictive models focused on\nestimating grid usage in the future, the time horizon for these\npredictions is only 72 h, meaning most of our workloads are\nbeyond the prediction time frame. Thus we turn to historical\ndata.\nTo align with our system-level assumptions in which\npower measurements are computed in hours, we down-\nsample the data to derive hourly MOER values. As previ-\nously mentioned, MOER values represent the impact of an\nadditional load on the grid. To ensure the accuracy and con-\nsistency of our data, and to account for potential changes in\nmethodologies and energy sources over time, we have chosen\nto speciﬁcally utilize WattTime’s model version 3.2 (referred\nto as MOER version 3.2 in the data) for our investigation. To\ncalculate MOER for a speciﬁc workload, we take a subset of\nthat dataset starting from when the workload is scheduled to\nbegin and calculate the hypothesized end time. We then mul-\ntiply the MOER values (sampled hourly) by our estimated\nsystem power to calculate the MOER cost for the entire run-\ntime.\n5.3 Replication study\nTo ensure the representativeness of our calculations for real-\nworld workloads, we closely replicate the setup of Meta AI’s\nlong-running LLM model named LLaMa [ 21]. By replicating\nthe overall carbon cost of training a long-running LLM, we\nvalidate our simulated power consumption of the underlying\nsystem on which long-running LLMs are trained. This allows\nus to rely on our simulated power consumption model instead\nof measuring the power consumption directly via training. By\nshowing we have a reliable estimate of power consumption,\nwe can then explore algorithms that adapt to the grid without\nhaving to train any LLMs directly.\nLLaMa required 2048 GPUs and a training time of\napproximately 5 months, resulting in an estimated energy\nconsumption by the original authors of around 2,638 MWh.\nNo information was provided about CPU usage. The authors\nestimated the carbon emission of LLaMa at 1015 tons of\nCOe\n2. This is equivalent to 128 homes’ energy for 1 year\naccording to the United States Environmental Protection\nAgency [ 29]. They mention their utilization of the GPU’s\nThermal Design Power (TDP) of 400W to approximate the\npower consumption of the workload.\nAssuming the same number of GPUs and runtime for the\npurposes of synthetic analysis, our estimation tool projected\nthe system to consume about 2949.12 MWh of energy dur-\ning training. The discrepancy is relatively modest at 12%.\nThis suggests that while models, hardware, hardware utiliza-\ntion, system conﬁguration will vary, our synthetic analysis\ncan reasonably approximate a realistic LLM scenario. Esti-\nmating carbon emissions, especially retrospectively, can be\nvery difﬁcult. Our goal is not absolute precision, but rather\naccuracy sufﬁcient to enable developers to make a ballpark\nestimate prior to training a large-scale production model.\nMaking such an estimate requires very little emissions, and\nsupports the ability to optimize training time for sustainabil-\nity.\nCarbon emissions depend heavily on the location where\nthe workload runs. While LLaMa assumes the US national\ncarbon intensity of 0.385 kg CO\n2-eq/kWh, in this study, we\nspeciﬁcally use carbon intensity data from California ISO\nNorth. This allows us to explore the beneﬁts of timeshifting\n(below) while considering the region’s actual carbon foot-\nprint and providing more accurate insights into the potential\nenvironmental impact.\nIf the energy source were restricted to California ISO\nNorth, we estimate that this model or a similar model would\nhave released 1099 tons of CO\n2. This is approximately an 8%\ndifference, which might be accounted for by the location, the\ndifference in emissions data sources, or a combination of\nboth.\nWhereas the approximation of the carbon emissions esti-\nmate of LLaMa from the original paper [ 21] uses the national\n123\n522 A. Jagannadharao et al.\nFig. 3 Heatmap of marginal emissions of training LLaMa on different\ngrids (y-axis) with different start times as months in 2022 (x-axis).\nWe exclude W APA Rocky Mountain Region (W ACM) from this ﬁgure\nbecause the estimated carbon cost was between 2883 and 3039 tons,\nmasking the seasonal variability of the other locations\naverage, we can easily test what the carbon emissions would\nlook like at varying locations. Figure 3 shows our estimation\nof carbon emissions for training LLaMa on different grids\nand starting training at different times of the year. We choose\nto look at 3 different grids California ISO North (our original\nestimation), California ISO Palm Springs, and SSP Western\nNebraska. We choose California ISO Palm Springs because\nit has historically been one of the greenest grids on average.\nSSP Western Nebraska is a grid with high variability both in\nthe short term and across seasonality and thus offers insight\ninto how a highly variable grid may impact and alter the\namount of carbon emissions training a large-scale model.\nWe note that the similarity in estimating both the power\nusage as well as the overall carbon cost of LLaMa with such\nminimal information related to carbon training costs veriﬁes\nthe need, and use, for such tools as ours that allow individuals\nto do a back of envelop calculation to understand how training\na model of this size would impact the environment. Addition-\nally, the ease of adjusting which grid the model is trained on,\nand when training starts, empowers users to make more sus-\ntainable decisions with low overhead cost (see Fig. 3).\n5.4 Introduction to timeshifting\nTimeshifting is a largely effective strategy to reduce car-\nbon emissions of software in data centers, including major\nplayers like Google [ 30]. Timeshifting refers to the strate-\ngic scheduling of computing tasks and processes to align\nwith periods of lower energy demand or higher availability\nof renewable energy sources. For instance, data centers can\nanalyze historical data and predictions on future renewable\nenergy availability to dynamically shift resource-intensive\nworkloads, such as data processing, computational tasks, and\nserver operations, to periods when the energy grid relies more\nheavily on sustainable energy generation [ 30].\n5.5 Two-threshold timeshifting\nSimply modeling the system and linking it to location-\nspeciﬁc MOER measurements allows us to approximate the\noverall carbon cost of training a model at various times of\nyears and various locations. As can be seen, by Fig. 2, both\nseasonality and location play a large role in the overall car-\nbon emissions cost. Noting the difference that can be made\nby choosing a different time of year to train a large-scale\nmodel, we incorporate a basic timeshifting algorithm into\nour simulation. The idea is to automatically place the system\ninto idle when the grid is detected to be ’too dirty’. We can\nthen decide when the grid is ’clean enough’ to start training\nthe model again.\nTo illustrate the usefulness of timeshifting and its impact\non carbon, we investigate the impact on emissions by consid-\nering a cutoff to stop training and a separate cutoff to restart\ntraining. How these thresholds are chosen can quickly get\ncomplicated and be directly related to the various temporal\nchanges a speciﬁc grid undergoes. While one could imag-\nine optimizing these cutoffs for the grid and time in which\nthe model will be trained, we instead deﬁne a very naive\nand simple cutoff procedure in order to isolate the effect of\ntimeshifting speciﬁcally. We deﬁne these thresholds to be\nbased on a percentile MOER usage averaged over the last\nfew years for a speciﬁc grid location. This allows our carbon-\naware algorithm to adapt to the speciﬁc location (allowing\nfor cross-location comparisons) without making assumptions\nabout future grid utilization. We then explore various cut-\noffs for stopping and separately resuming training. Such a\ntimeshifting procedure is clearly not deﬁned when the restart\ncutoff is less than the stop cutoff as the system would simply\ninstantly restart. Figure 9 shows two cutoffs we considered\nin exploring the use of timeshifting.\nUtilizing these thresholds, we explore various permu-\ntations by pausing and resuming the workload based on\nthe speciﬁc MOER values at the identiﬁed percentiles. For\ninstance, we can pause the workload when MOER values\ncross the 95th percentile (985.33 lbs CO\n2/MWh for Califor-\nnia ISO North’s power grid) and resume the workload when\nthe carbon intensity drops below the 75th percentile (949.0\nlbs CO 2/MWh for California ISO North’s power grid).\nOf note, in our approach, we calculate the MOER thresh-\nolds over the course of several years. This methodology could\nintroduce biases in the model due to systematic over/under\nestimation of normal grid use at the current time. This bias\ncould be due to changes in the energy mix (e.g., introduction\nof more green energy sources resulting in lower MOER esti-\n123\nTimeshifting strategies for carbon-efﬁcient long-running large… 523\nFig. 4 Heatmap of timeshifted emission costs for LLaMa normalized\nby the non-timeshifted workload starting in January 2022. X-axis rep-\nresents the carbon intensity percentile we pause running the workload;\nY -axis represents the carbon intensity percentile we resume the work-\nload. The emissions are represented by the color of the cells, where\nlighter cells indicate lower emissions. Percent carbon savings can be\nestimated as 1 minus the cell value\nmates over time) or due to a growing demand and utilization\non the overall grid. Thus, if we are using our timeshifting\nmodel to minimize carbon cost, we can expect to see larger\ncarbon savings in January than in July. However, we can also\nexpect a longer runtime for the timeshifted January mod-\nels than the July models. The longer runtime cuts into the\npotential carbon savings since the system cannot be made\ntotally carbon neutral and must wait in idle until it can be\nresumed. Such biases arise due to the inclusion of emis-\nsions data from various seasons and periods with different\nenergy usage patterns. To mitigate this effect, users of this\ntool should carefully consider how to deﬁne the stop-training\nand resume-training cutoffs. Because there are strong sea-\nsonal patterns within grids, there may be an advantage to\nconsidering seasonal adjustments along with realistic time\nexpectations. Careful consideration and sensitivity analysis\nare necessary to account for the seasonal variations in emis-\nsions and ensure the robustness of our simulation results.\n5.6 Further exploration: timeshifting\nAfter employing our two-threshold approach, we present a\nheatmap of our ﬁndings (Fig. 4). For a 5-month-long work-\nload initiated in January within California ISO North, our\nstrategy yields minimal carbon savings. In fact, we can only\nprevent approximately 32 tons of CO\n2 emissions (Fig. 5),\nwhile extending the runtime by 780 h (equivalent to 32.5\ndays) (Figs. 6, 7).\nUpon rescheduling the workload to run one month later,\nwe observe that the emissions worsen. While commencing\nFig. 5 Histogram of CO 2 savings for timeshifted LLaMa workload\nstarting in January\nFig. 6 Histogram of runtime costs for timeshifted LLaMa workload\nstarting in January\nthe workload in January 2022 could have potentially pre-\nvented the emission of up to 32 tons of CO 2 (Fig. 8), shifting\nthe start to February only offers a maximum reduction of\n13 tons of CO\n2. Consequently, timeshifting the workload\nintroduces no signiﬁcant beneﬁts and, in turn, extends the\nworkload’s run time.\nThese results likely stem from initiating the workload dur-\ning the grid’s peak emissions period. However, this highlights\nthe signiﬁcance of our simulation tool. By having the capa-\nbility to simulate the timing and execution of long-running\nworkloads before their actual implementation, we can avoid\npotentially costly errors. Such foresight empowers us to opti-\nmize workload scheduling and minimize the environmental\n123\n524 A. Jagannadharao et al.\nFig. 7 Heatmap of timeshifted emission costs for LLaMa normalized\nby the non-timeshifted workload starting in February 2022\nFig. 8 Histogram of CO 2 savings for timeshifted LLaMa workload\nstarting in February\nimpact, making the tool indispensable for responsible and\nefﬁcient computing practices.\n5.7 Exploring other workloads\nIn this section, we delve into the realm of other workloads,\nexpanding the scope of our investigation beyond the pre-\nviously examined scenarios. As we venture into diverse\napplications of timeshifting, we explore how this innova-\ntive approach can be adapted to various types of workloads,\neach presenting unique challenges and opportunities. By\ndelving into these different workloads, we aim to unlock\nvaluable insights into the potential beneﬁts and limitations\nof timeshifting strategies, fostering a deeper understanding\nof their applicability in real-world computing scenarios.\nFig. 9 Grid emissions for California ISO North in January\nWe examine a system made up of 1000 nodes where each\nnode contains 2 CPUs and 8 GPUs. We assume, for the sake\nof this exploration that each CPU consumes 10 watts in idle\nand 271 watts when fully utilized. Each GPU consumes 15\nwatts in idle and 700 watts when fully utilized. Our system\nis located in California ISO North and we would like to run\nthe workload in January 2023.\nThe grid emissions in January are fairly consistent with\nthe 95th percentile of emissions at 985 lbs/MWh and the 75th\npercentile emissions at 949 lbs/MWh (Fig. 9).\nWe have two workloads that we need to run at this time.\nOne workload takes 300 h to run and the other takes 720 h.\nWhen simulating the 300-hour workload in this setting,\nthe heatmap reveals intriguing data points. In Fig. 10,w e\nobserve that the highest emissions occur when we pause the\nworkload at the 95th percentile and resume it at the 85th\npercentile of carbon intensity. We attribute this phenomenon\nto the fact that the energy mix at the 85th percentile could\ncomprise both fossil fuels and renewable energy, leading to\nincreased uncertainty when the system relies on renewable\nsources.\nSimulating the 720-hour workload, on the other hand,\nreveals a more intuitive heatmap (Fig. 11) where the lower we\nset the threshold, the less emissions we have. In our experi-\nment, the 720-hour workload has more than a 50% reduction\nin emissions at the 75th percentile of emissions.\nThese ﬁndings suggest that the effectiveness of timeshift-\ning strategies can vary signiﬁcantly depending on the dura-\ntion of the workload. Workloads, such as the 720-hour\none, seem to offer greater potential for emissions reduc-\ntion through timeshifting, while shorter workloads may have\nlimited gains. This observation underscores the importance\nof carefully tailoring timeshifting approaches to the speciﬁc\ncharacteristics and duration of workloads. By understand-\ning these nuances, we can optimize the implementation of\ntimeshifting techniques. We note that other papers (namely\n123\nTimeshifting strategies for carbon-efﬁcient long-running large… 525\nFig. 10 300-hour workload heatmap of emissions relative to non-\ntimeshifted workload\nFig. 11 720-hour workload heatmap of emissions relative to non-\ntimeshifted workload\n[20]) have found an advantage to timeshifting, especially for\nsmall workloads. We believe this discrepancy between our\nﬁndings and theirs comes from the fact that we account for\nidle power consumption even when delaying the start time\nof the model. If the model has a short runtime, the energy\nsavings for running at cleaner times is offset by the carbon\ncost of maintaining the idle system.\nHowever, to get the lowest possible emissions out of both\nworkloads, we extend the runtime by a nontrivial amount.\nFor the 300-hour workload, the runtime increases by a fac-\ntor of 7x (Fig. 12), resulting in only a 30% reduction in CO\n2\nemissions (Fig. 10). On the other hand, the 720-hour work-\nload performs better, achieving over a 50% reduction in CO 2\nemissions (Fig. 11) with a runtime extension of 4.3x (Fig. 13).\nThe two-threshold simulation offers valuable insights into\nthe workload’s behavior over time. Both the 300-hour work-\nload (Fig. 14) and the 720-hour workload (Fig. 15) exhibit\nFig. 12 Histogram of runtimes for timeshifting the 300-hour workload\nFig. 13 Histogram of runtimes for timeshifting the 720-hour workload\nfrequent bursts of activity, contributing to longer runtimes.\nHowever, it’s essential to note that the simulation has not yet\naccounted for the cost of caching memory frequently. Future\nwork aims to reﬁne our calculations by incorporating MOER\nthresholds that more accurately correspond to the renewable-\nto-non-renewable energy supply mix.\n5.8 Exploring other locations\nWhile our earlier analyses focused on California ISO North,\nwe expanded our investigation to include other regions with\ndistinctive energy proﬁles. By doing so, we aimed to unveil\n123\n526 A. Jagannadharao et al.\nFig. 14 A comparison of running the 300-hour workload with different\nthresholds. Each subplot represents the emissions over the course of the\nworkload when the pause and resume thresholds are the same values\nFig. 15 A comparison of running the 720-hour workload with different\nthresholds. Each subplot represents the emissions over the course of the\nworkload when the pause and resume thresholds are the same values\nFig. 16 Carbon intensity of California ISO North (CAISO_NORTH),\nSPP West Nebraska (SPP_WESTNE), and W APA Rocky Mountain\nRegion (W ACM) grid regions from June 1, 12 AM–June 13, 12 PM\n(300 h)\nthe inﬂuence of varying carbon intensities on the effective-\nness of timeshifting strategies.\nKeeping the same system deﬁnition and assuming that\nthe data our workload needs is already present at the\nnew locations, we compare the CO\n2 savings when running\nworkloads in June 2022 in regions covered by the power\ngrids California ISO North (CAISO_NORTH), SPP West-\nern Nebraska (SPP_WESTNE), and W APA Rocky Mountain\nRegion (W ACM).\nFigure 16 depicts the grid intensity patterns of the respec-\ntive areas during a 300-hour period from June 1, 12 AM to\nJune 13, 12 PM. In the case of California ISO North, there is\na noticeable level of variability, with MOER values ﬂuctuat-\ning between 0 and approximately 1000 lbs CO\n2/MWh. SPP\nWest Nebraska exhibits even greater variability, with grid\nintensity ranging between 0 and 1400 lbs CO 2/MWh. On the\nother hand, W APA Rocky Mountain Region demonstrates\ncomparatively lower variability but higher MOER values,\nspanning from 1700 to 2200 lbs CO\n2/MWh. Based on the\ngrid intensity insights, it seems probable that California ISO\nNorth will encounter more occurrences of timeshifting com-\npared to the W APA Rocky Mountain Region.\nRunning our simulation, we generate histograms of\nthe amount of carbon saved in each region for vari-\nous pause/resume thresholds (CAISO_NORTH—Fig. 17,\nSPP_WESTNE—Fig. 18, W ACM—Fig. 19). Interestingly,\nwe see that no matter how you implement timeshifting in\nCAISO_NORTH, there will be some carbon savings. In the\ncase of SPP_WESTNE, signiﬁcant carbon savings appear\nonly upon reaching the 85th percentile of carbon intensity in\nthe region. However, this region presents ample potential for\ncurbing carbon emissions, particularly at lower carbon inten-\nsity thresholds. When juxtaposed with the CAISO_NORTH\nresults, there is a 25% reduction in carbon emissions. Con-\n123\nTimeshifting strategies for carbon-efﬁcient long-running large… 527\nFig. 17 Histogram of tons of carbon not emitted compared to non-\ntimeshifted workload in California ISO North (CAISO_NORTH)\nstarting in June 2022\nFig. 18 Histogram of tons of carbon not emitted compared to non-\ntimeshifted workload in SPP West Nebraska (SPP_WESTNE) starting\nin June 2022\nversely, there is minimal inﬂuence of timeshifting on carbon\nreduction in W ACM.\nLooking closer at how the workload is paused and resumed\nover the course of time (Figs. 20, 21, 22), we see some\ninteresting patterns. CAISO_NORTH has more sporadic\ntimeshifted segments; in fact, the pauses are hard to distin-\nguish from the natural ﬂuctuations in the grid. Furthermore,\nfor each percentile we examined, there is a consistent upward\ntrend in the duration of the workload resulting in it extending\nits runtime.\nWe also see that the workload does not get timeshifted\nafter a while in W ACM. This observation challenges the\nFig. 19 Histogram of tons of carbon not emitted compared to non-\ntimeshifted workload in W APA Rocky Mountain Region (W ACM)\nstarting in June 2022\nFig. 20 Time series of the workload running in California ISO\nNorth (CAISO_NORTH) starting in June 2022. From top to bottom:\nnon-timeshifted, pause/resume=0.95, pause/resume = 0.9, pause/re-\nsume = 0.85, pause/resume = 0.8, pause/resume = 0.75\nthresholds selected based on historical data, suggesting that\nthey may not accurately capture this speciﬁc period. Conse-\nquently, W ACM necessitates a more sophisticated approach\nto implementing carbon-aware applications. A timeshifting\ntechnique is probably not the right solution for this region as\nthere is no good time to pause/resume the workload.\n123\n528 A. Jagannadharao et al.\nFig. 21 Time series of the workload running in SPP West Nebraska\n(SPP_WESTNE) starting in June 2022. From top to bottom:\nnon-timeshifted, pause/resume = 0.95, pause/resume = 0.9, pause/re-\nsume = 0.85, pause/resume = 0.8, pause/resume = 0.75\nFig. 22 Time series of the workload running in W APA Rocky Moun-\ntain Region (W ACM) starting in June 2022. From top to bottom:\nnon-timeshifted, pause/resume = 0.95, pause/resume = 0.9, pause/re-\nsume = 0.85, pause/resume = 0.8, pause/resume = 0.75\nFrom our observations, timeshifting involves more than\nmerely selecting an optimal time for running a workload; it\nrequires a thorough comprehension of the energy mix in the\nsupplying power grid of that region. Running a carbon-aware\napplication that utilizes timeshifting in a region with limited\nrenewable energy will inadvertently increase carbon emis-\nsions. As more data becomes available about the energy mix\nfrom the power grid, it is important to align our timeshifting\nstrategies with the local energy landscape. Only then can we\nmaximize the carbon-reducing potential of our applications.\n6 Future work\nThere are several avenues for extending and enhancing the\ncapabilities of our estimation tool and simulation to provide\nmore comprehensive insights into the carbon emissions of\nlong-running workloads.\n1. Utilizing Power Curves: Currently, our estimation tool\nrelies on the Thermal Design Power (TDP) values pro-\nvided by hardware manufacturers. In future work, we\ncan enhance the accuracy of our energy consumption\nestimates by incorporating power curves distributed by\nmanufacturers. Power curves offer a more detailed repre-\nsentation of a hardware component’s power consumption\nacross various utilization levels, enabling a more ﬁne-\ngrained estimation of energy usage during workload\nexecution.\n2. Scaling Hardware and Networking Costs: To capture\na more realistic and complete view of energy con-\nsumption, we can expand our simulation to account for\nlarger-scale hardware conﬁgurations. Including various\nhardware components and networking costs will provide\na more comprehensive analysis of the energy require-\nments and carbon emissions associated with different\nworkload setups. This extension will be particularly useful\nfor understanding the impact of workloads in distributed\ncomputing environments.\n3. Cost of Idle Power: In our early exploration of the\ntimeshifting work, we found that idle power consumption\nhas a large impact on carbon savings especially with an\noptimized timeshifting strategy. While we have shed some\nlight on the impact of idle power, there remains an oppor-\ntunity to delve deeper into this phenomenon. Exploring\nhow idle power varies across different times of the day,\nworkload types, and hardware utilization and conﬁgura-\ntions can help us design better software and systems.\n4. Fidelity and Access of Data from the Power Grid: While\nour current framework integrates valuable insights into\ncarbon emissions and energy intensity, there exists an\nopportunity to delve deeper into the intricacies of power\ngrid dynamics. Different regions and organizations may\n123\nTimeshifting strategies for carbon-efﬁcient long-running large… 529\nadopt different calculation methods, leading to inconsis-\ntencies that can impact the accuracy of our simulation.\nUnderstanding the variations in calculations can help us\nincrease the accuracy and reliability of our simulation.\nAdditionally, data from the power grid in relation to car-\nbon emissions from renewable resources is not widely\navailable or reported. Global coverage of emissions data\nis poor, access to information on power usage and source\nbehind the meter is limited, and geographic smoothing\noften makes access to individual emissions impossible.\nIncreasing access to data around power, and increasing\ngranularity of where power comes from, could result in\nmore attention to and potential solutions for how to effec-\ntively minimize carbon contributions of AI workloads.\nFuture work must consider how the role of timeshifting is\nimpacted by differences in grid variability and intermittent\naccess to renewable workloads. We saw many cases where\ntimeshifting a workload would reduce the amount of carbon\nreleased into the atmosphere, but we also saw cases in which\ntimeshifting was not helpful in minimizing emissions. We\nbelieve the usefulness of timeshifting is directly related to\ngrid variability. This suggests two future directions for this\nwork. One direction is to characterize the types of grids where\ntimeshifting is most amenable and the second direction is\nto develop adaptive algorithms similar in their adaptability\nto the timeshifting algorithm presented here that effectively\nwork to reduce carbon emissions on grids where timeshifting\nis not applicable.\nBeyond extending our system estimation tool or additional\nalgorithms that adapt to the variability of emissions, we also\nmust consider extending our estimations to include more\nthan just the cost of training these LLMs, as there are many\nother important aspects of the development and deployment\nof LLMs that can substantially contribute to carbon emis-\nsions. Inference has its own carbon contribution that can\nvary greatly by how LLMs are integrated with other types of\nsystems and marketed to end users. Further, we neglect the\ncarbon contribution of model development and research that\nlead to, for example, the development and success of Meta\nAI’s LLaMa model. To fully understand the impact and role\nof LLMs in contributing to greenhouse gas emissions, we\nneed a uniﬁed way of calculating carbon emissions at these,\nand many other, stages. Beyond simply considering the car-\nbon cost of development and deployment of LLMs, we also\nneed to consider the emissions released in the production of\nthe hardware used to train these LLMs.\n7 Conclusion\nOur work provides a back-of-the-envelope calculation of the\nenergy cost of training a long-running LLM . We enhance\nthis calculation by grounding it in power-grid data to esti-\nmate the carbon cost of model training. We also propose a\ntimeshifting algorithm that pauses training of the model dur-\ning times when the grid is particularly dirty and resumes\nwhen the carbon cost of the grid is below a given threshold.\nWe show how the computational requirements of the model,\nthe location where the model is trained, and even when the\nmodel is trained all have a dramatic inﬂuence on the carbon\ncost of LLMs.\nSpeciﬁcally, this paper highlights the signiﬁcance of\ntimeshifting for long-running workloads in LLMs, present-\ning a promising avenue for reducing carbon emissions. Our\nsimulation offers valuable insights into the potential and\nlimitations of timeshifting, revealing intriguing patterns that\ninﬂuence model performance and model runtime. Acknowl-\nedging the need for further advancements in carbon-aware\nmodel training, we envision incorporating more comprehen-\nsive system deﬁnitions and exploring energy mix dynamics to\nreﬁne our approach as an area of future research. As we move\nforward, prioritizing carbon-aware algorithms and sustain-\nable computing practices will play a pivotal role in mitigating\nthe environmental impact of LLMs and other workloads, fos-\ntering a greener and more sustainable computing landscape.\nAcknowledgements We extend our gratitude to WattTime for their\nsupport and collaboration. Their dedication to advancing carbon trans-\nparency has been instrumental in shaping the research presented in this\npaper.\nAuthor Contributions AJ coded timeshifting. AJ and NB wrote the\nmain text, reviewed the code, and generated images. DN provided\nbackground and history for the paper, and a portion of the editing.\nSC provided the initial idea and direction for the paper. All authors\nreviewed the text.\nFunding Not applicable.\nAvailability of data and materials This paper extensively uses Watt-\nTime to access the carbon intensity of the power grids. Access to this\nAPI requires a subscription or data requests from WattTime. However,\nindividuals can replicate our work with free access to historical data\nfrom California ISO North. Upon completion of the necessary review\nprocess at Intel, we intend to release our estimation tool as an interactive\nJupyter notebook through GitHub following this publication.\nDeclarations\nConﬂict of interest The authors of this paper are full-time employees\nof Intel Corporation. The research project received no external sources\nof funding.\nEthical Approval Not applicable.\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing, adap-\ntation, distribution and reproduction in any medium or format, as\nlong as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons licence, and indi-\n123\n530 A. Jagannadharao et al.\ncate if changes were made. The images or other third party material\nin this article are included in the article’s Creative Commons licence,\nunless indicated otherwise in a credit line to the material. If material\nis not included in the article’s Creative Commons licence and your\nintended use is not permitted by statutory regulation or exceeds the\npermitted use, you will need to obtain permission directly from the copy-\nright holder. To view a copy of this licence, visit http://creativecomm\nons.org/licenses/by/4.0/.\nAppendix A: Pseudocode for two-threshold\nMOER value selection\n# Define the thresholds for pausing\n# and resuming the workload\nt 1 := pause_threshold\nt 2 := resume_threshold\npaused := False\n# Loop through the M O E R values\nfor M in MOER_vals :\nif M > t 1 :\npaused = True\nelif n o t p a u s e d a n d M < t 1 :\npaused = False\ne l i f paused and M > t 2 :\npaused = True\ne l i f paused and M < t 2 :\npaused = False\nReferences\n1. Strubell E, Ganesh A, McCallum A (2020) Energy and policy con-\nsiderations for modern deep learning research. In: Proceedings of\nthe AAAI conference on artiﬁcial intelligence, VOL 34(09), PP\n13,693–13,696\n2. Strubell E, Ganesh A, McCallum A (2019) Energy and pol-\nicy considerations for deep learning in NLP . arXiv preprint\narXiv:1906.02243\n3. Green Software Foundation, Green Software Practitioner: Car-\nbon Awareness. [Online]. Available: https://learn.greensoftware.\nfoundation/carbon-awareness\n4. Tiple V (2020) Recommendations on the European commission’s\nwhite paper on artiﬁcial intelligence-a European approach to excel-\nlence and trust, com (2020) 65 ﬁnal (the’AI white paper)\n5. Stokel-Walker C (2023) Turns out there’s another problem\nwith AI—its environmental toll. The Guardian. [Online]. Avail-\nable: https://www.theguardian.com/technology/2023/aug/01/\ntechscape-environment-cost-ai-artiﬁcial-intelligence\n6. Patterson D, Gonzalez J, Hölzle U, Le Q, Liang C, Munguia L-M,\nRothchild D, So DR, Texier M, Dean J (2022) The carbon footprint\nof machine learning training will plateau, then shrink. Computer\n55(7):18–28\n7. Galvin R (2015) The ICT/electronics question: structural change\nand the rebound effect. Ecol Econ 120:23–31\n8. Sanh V , Debut L, Chaumond J, Wolf T (2019) DistilBERT, a dis-\ntilled version of BERT: smaller, faster, cheaper and lighter. arXiv\npreprint arXiv:1910.01108\n9. Fedus W, Zoph B, Shazeer N (2022) Switch transformers: scaling\nto trillion parameter models with simple and efﬁcient sparsity. J\nMach Learn Res 23(1):5232-5270\n10. Choromanski K, Likhosherstov V , Dohan D, Song X, Gane\nA, Sarlos T, Hawkins P , Davis J, Mohiuddin A, Kaiser L\net al (2020) Rethinking attention with performers. arXiv preprint\narXiv:2009.14794\n11. Antonello R, Beckage N, Turek J, Huth A (2021) Selecting\ninformative contexts improves language model ﬁnetuning. In:\nProceedings of the 59th annual meeting of the association for com-\nputational linguistics and the 11th international joint conference on\nnatural language processing, pp 1072–1085\n12. Tay Y , Dehghani M, Bahri D, Metzler D (2020) Efﬁcient trans-\nformers: a survey. arXiv preprint arXiv:2009.06732\n13. Bommasani R, Hudson DA, Adeli E, Altman R, Arora S, von Arx\nS, Bernstein MS, Bohg J, Bosselut A, Brunskill E et al (2021) On\nthe opportunities and risks of foundation models. arXiv preprint\narXiv:2108.07258\n14. Bannour N, Ghannay S, Névéol A, Ligozat A-L (2021) Evaluating\nthe carbon footprint of NLP methods: a survey and analysis of\nexisting tools. In: Proceedings of the second workshop on simple\nand efﬁcient natural language processing, pp 11–21\n15. Lacoste A, Luccioni A, Schmidt V , Dandres T (2019) Quanti-\nfying the carbon emissions of machine learning. arXiv preprint\narXiv:1910.09700\n16. Lannelongue L, Grealey J, Inouye M (2021) Green algo-\nrithms: quantifying the carbon footprint of computation. Adv Sci\n8(12):2100707\n17. Patterson D, Gonzalez J, Le Q, Liang C, Munguia L-M, Rothchild\nD, So D, Texier M, Dean J (2021) Carbon emissions and large\nneural network training. arXiv preprint arXiv:2104.10350\n18. Cao Q, Balasubramanian A, Balasubramanian N (2020) Towards\naccurate and reliable energy measurement of NLP models. arXiv\npreprint arXiv:2010.05248\n19. Henderson P , Hu J, Romoff J, Brunskill E, Jurafsky D, Pineau J\n(2020) Towards the systematic reporting of the energy and carbon\nfootprints of machine learning. J Mach Learn Res 21(1):10 039-10\n081\n20. Dodge J, Prewitt T, Tachet Des Combes R, Odmark E, Schwartz\nR, Strubell E, Luccioni AS, Smith NA, DeCario N, Buchanan W\n(2022) Measuring the carbon intensity of ai in cloud instances.\nIn: 2022 ACM conference on fairness, accountability, and trans-\nparency, pp 1877–1894\n21. Touvron H, Lavril T, Izacard G, Martinet X, Lachaux M-A, Lacroix\nT, Rozière B, Goyal N, Hambro E, Azhar F, Rodriguez A, Joulin A,\nGrave E, Lample G (2023) LLaMA: open and efﬁcient foundation\nlanguage models. arXiv:2302.13971\n22. Green Software Foundation, Green Software Practioner: Measure-\nment. [Online]. Available: https://learn.greensoftware.foundation/\nmeasurement\n23. WattTime, The Power to Choose Clean Energy. [Online]. Available:\nhttps://www.watttime.org/\n24. O. US EPA, Download data. May 2022. [Online]. Available: https://\nwww.epa.gov/egrid/download-data\n25. California Energy Commission, 2021 Total System Electric\nGeneration. [Online]. Available: https://www.energy.ca.gov/data-\nreports/energy-almanac/california-electricity-data/2021-total-\nsystem-electric-generation\n26. “CodeCarbon.” [Online]. Available: https://mlco2.github.io/\ncodecarbon/\n27. EPA Clean Air Markes Program Data (CAMPD), Power plant emis-\nsions, compliance, and allowance data. [Online]. Available: https://\ncampd.epa.gov\n28. WattTime, Marginal Emissions Methodology. [Online]. Available:\nhttps://www.watttime.org/marginal-emissions-methodology/\n123\nTimeshifting strategies for carbon-efﬁcient long-running large… 531\n29. EPA Ofﬁce of Air and Radiation (OAR), Greenhouse Gas Equiv-\nalencies Calculator. 2015. [Online]. Available: https://www.epa.\ngov/energy/greenhouse-gas-equivalencies-calculator\n30. Radovanovi´ c A, Koningstein R, Schneider I, Chen B, Duarte A,\nRoy B, Xiao D, Haridasan M, Hung P , Care N, Talukdar S, Mullen\nE, Smith K, Cottman M, Cirne W (2023) Carbon-aware computing\nfor datacenters. IEEE Trans Power Syst 38(2):1270-1280\nPublisher’s Note Springer Nature remains neutral with regard to juris-\ndictional claims in published maps and institutional afﬁliations.\n123",
  "topic": "Workload",
  "concepts": [
    {
      "name": "Workload",
      "score": 0.645282506942749
    },
    {
      "name": "Computer science",
      "score": 0.6303383111953735
    },
    {
      "name": "Environmental economics",
      "score": 0.4825812876224518
    },
    {
      "name": "Greenhouse gas",
      "score": 0.46967965364456177
    },
    {
      "name": "Training (meteorology)",
      "score": 0.46365153789520264
    },
    {
      "name": "Sustainable development",
      "score": 0.45713672041893005
    },
    {
      "name": "Ecology",
      "score": 0.10184550285339355
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Meteorology",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1343180700",
      "name": "Intel (United States)",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210128612",
      "name": "Mission College",
      "country": "US"
    }
  ]
}