{
    "title": "Awakening Latent Grounding from Pretrained Language Models for Semantic Parsing",
    "url": "https://openalex.org/W3175013773",
    "year": 2021,
    "authors": [
        {
            "id": "https://openalex.org/A2100110296",
            "name": "Qian Liu",
            "affiliations": [
                "Beihang University"
            ]
        },
        {
            "id": "https://openalex.org/A2157693139",
            "name": "Dejian Yang",
            "affiliations": [
                "Xi'an Jiaotong University"
            ]
        },
        {
            "id": "https://openalex.org/A2097111355",
            "name": "Zhang Jiahui",
            "affiliations": [
                "Beihang University"
            ]
        },
        {
            "id": "https://openalex.org/A2123950015",
            "name": "Jiaqi Guo",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2096634937",
            "name": "Bin Zhou",
            "affiliations": [
                "Beihang University"
            ]
        },
        {
            "id": "https://openalex.org/A4212328323",
            "name": "Jian-Guang Lou",
            "affiliations": [
                "Xi'an Jiaotong University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W1496189301",
        "https://openalex.org/W2963899988",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W2964303116",
        "https://openalex.org/W3103801878",
        "https://openalex.org/W2979826702",
        "https://openalex.org/W2302963717",
        "https://openalex.org/W3042795397",
        "https://openalex.org/W2970862333",
        "https://openalex.org/W2946359678",
        "https://openalex.org/W2101317480",
        "https://openalex.org/W3034835156",
        "https://openalex.org/W2963403868",
        "https://openalex.org/W2968101724",
        "https://openalex.org/W2945102109",
        "https://openalex.org/W2964078224",
        "https://openalex.org/W2962749469",
        "https://openalex.org/W2908510526",
        "https://openalex.org/W2970172141",
        "https://openalex.org/W3116855718",
        "https://openalex.org/W2896675016",
        "https://openalex.org/W3034503989",
        "https://openalex.org/W2962713807",
        "https://openalex.org/W3103611182",
        "https://openalex.org/W2948947170",
        "https://openalex.org/W2970476646",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W2912624765",
        "https://openalex.org/W2163274265",
        "https://openalex.org/W2971323043",
        "https://openalex.org/W2953044594",
        "https://openalex.org/W2964044040",
        "https://openalex.org/W2947354947",
        "https://openalex.org/W3035529900",
        "https://openalex.org/W4288601872",
        "https://openalex.org/W3155682407",
        "https://openalex.org/W2240067561",
        "https://openalex.org/W2971377618",
        "https://openalex.org/W2161002933",
        "https://openalex.org/W2890431379",
        "https://openalex.org/W3004346089",
        "https://openalex.org/W3118485687",
        "https://openalex.org/W2606920173",
        "https://openalex.org/W3104616515",
        "https://openalex.org/W3104196282",
        "https://openalex.org/W3104200808",
        "https://openalex.org/W2970971581",
        "https://openalex.org/W2561412020",
        "https://openalex.org/W3098903812",
        "https://openalex.org/W3035044096",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W3098824823",
        "https://openalex.org/W2973154008",
        "https://openalex.org/W2971126690",
        "https://openalex.org/W4287688861",
        "https://openalex.org/W4288351520",
        "https://openalex.org/W4295312788"
    ],
    "abstract": "Recent years pretrained language models (PLMs) hit a success on several downstream tasks, showing their power on modeling language.To better understand and leverage what PLMs have learned, several techniques have emerged to explore syntactic structures entailed by PLMs.However, few efforts have been made to explore grounding capabilities of PLMs, which are also essential.In this paper, we highlight the ability of PLMs to discover which token should be grounded to which concept, if combined with our proposed erasingthen-awakening approach.Empirical studies on four datasets demonstrate that our approach can awaken latent grounding which is understandable to human experts, even if it is not exposed to such labels during training.More importantly, our approach shows great potential to benefit downstream semantic parsing models.Taking text-to-SQL as a case study, we successfully couple our approach with two off-the-shelf parsers, obtaining an absolute improvement of up to 9.8%.",
    "full_text": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 1174‚Äì1189\nAugust 1‚Äì6, 2021. ¬©2021 Association for Computational Linguistics\n1174\nAwakening Latent Grounding from Pretrained Language Models\nfor Semantic Parsing\nQian Liu‚Ä†‚àó , Dejian Yang¬ß, Jiahui Zhang‚Ä†‚àó, Jiaqi Guo‚ô¶‚àó, Bin Zhou‚Ä†, Jian-Guang Lou¬ß\n‚Ä†Beihang University, Beijing, China\n¬ßMicrosoft Research, Beijing, China\n‚ô¶Xi‚Äôan Jiaotong University, Xi‚Äôan, China\n‚Ä†{qian.liu, 17231043, zhoubin}@buaa.edu.cn; ‚ô¶jasperguo2013@stu.xjtu.edu.cn\n¬ß{dejian.yang, jlou}@microsoft.com\nAbstract\nRecent years pretrained language models\n(PLMs) hit a success on several downstream\ntasks, showing their power on modeling lan-\nguage. To better understand and leverage\nwhat PLMs have learned, several techniques\nhave emerged to explore syntactic structures\nentailed by PLMs. However, few efforts have\nbeen made to explore grounding capabilities of\nPLMs, which are also essential. In this paper,\nwe highlight the ability of PLMs to discover\nwhich token should be grounded to which con-\ncept, if combined with our proposed erasing-\nthen-awakening approach. Empirical studies\non four datasets demonstrate that our approach\ncan awaken latent grounding which is under-\nstandable to human experts, even if it is not\nexposed to such labels during training. More\nimportantly, our approach shows great poten-\ntial to beneÔ¨Åt downstream semantic parsing\nmodels. Taking text-to-SQL as a case study,\nwe successfully couple our approach with two\noff-the-shelf parsers, obtaining an absolute im-\nprovement of up to 9.8%.\n1 Introduction\nRecent breakthroughs of Pretrained Language\nModels (PLMs) such as BERT (Devlin et al., 2019)\nand GPT3 (Brown et al., 2020) have demonstrated\nthe effectiveness of self-supervised learning for a\nrange of downstream tasks. Without being guided\nby structural information in training, PLMs show\nthe potential for learning implicit syntactic struc-\ntures and language semantic, which can be trans-\nferred to other tasks. To better understand and\nleverage what PLMs have learned, several work\nhas emerged to probe or induce syntactic structures\nfrom PLMs. According to prior studies (Rogers\net al., 2020), most existing work focuses on syn-\ntactic structures such as part of speech (Liu et al.,\n‚àóWork done during an internship at Microsoft Research.\nThe Ô¨Årst three authors contributed equally.\nReign Monarchs\n1789-1802 George\n1802-1826 John I\n1826-1845 Andrew\n George   \nWashington\nwhat war was george washington associated with?\nU.S. President\nColonial Beach\n(a). Structured Table (b). Knowledge Base\nFigure 1: Typical scenarios for grounding, here the lin-\nguistic tokens ‚Äúgeorge washington‚Äù can be grounded\ninto different real-world concepts.\n2019), constituency tree (Wu et al., 2020) and de-\npendency tree (Hewitt and Manning, 2019; Jawahar\net al., 2019), paying much less attention on lan-\nguage semantics (Tenney et al., 2019). However,\nas well known, semantic information is essential\nfor high-level tasks like machine reading compre-\nhension (Wang and Jiang, 2019).\nRegarding to language semantics, an impor-\ntant branch is grounding, which is overlooked by\nmost previous work. Broadly speaking, grounding\nmeans ‚Äúconnecting linguistic symbols to real-world\nperception or actions‚Äù (Roy, 2005). It is generally\nthought to be important for a variety of tasks, such\nas video descriptions (Zhou et al., 2019), visual\nquestion answering (Zhu et al., 2016) and semantic\nparsing (Guo et al., 2019). In this paper, we focus\non single-modal scenarios, where grounding refers\nmore speciÔ¨Åcally to mapping linguistic tokens into\na real-world concept described in natural language.\nAs shown in Figure 1, ‚Äúgeorge washington‚Äù can\nbe grounded into either a cell value in a structured\ntable, or an entity in knowledge bases.\nIn single-modal scenarios, grounding is espe-\ncially important for semantic parsing, the task of\ntranslating a natural language sentence into its cor-\nresponding executable logic form. For earlier work,\ngrounding is essential since earlier work almost\nconceptualized semantic parsing as grounding an\n1175\nHow many total games were at braly stadium [SEP][CLS] Venue\nQuestion Concept\nPLM\n0.14 0.10 0.21 0.01 0.14 0.18 0.06 0.16 Latent Grounding\ngeorge\nPLM\n0.02 0.03 0.05 0.12 0.04 0.11 0.08 0.27 Pseudo Alignment\nConcept Prediction Confidence\n0.92\n0.65\nErasingHow many total games were at braly [SEP][CLS] Venue\nGrounding Module\nCP\nCP\nAwakening\nFigure 2: The illustration of E TA, which consists of a PLM module, a Concept Prediction (CP) module and a\ngrounding module. Two models (gray and blue) are drawn here for illustration purposes, and they are indeed\nthe same. The model training involves three steps: (1) The concept prediction module is trained to predict the\nconÔ¨Ådence of any concept occurring in a given question ( Left). (2) The erasing mechanism erases tokens in the\nquestion sequentially, feeds them into CP, and obtains the conÔ¨Ådence differences (e.g.,0.92 ‚àí0.65 = 0.27) as the\npseudo alignment. Here we only demonstrate the process related to ‚Äústadium‚Äù ( Bottom Right). (3) The pseudo\nalignment is employed to awaken the latent grounding, i.e., to supervise the grounding module ( Top Right). We\nshow only one concept ‚ÄúVenue‚Äù for the sake of brevity, which in practice is a sequence of concepts.\nutterance to a task-speciÔ¨Åc meaning representation\n(Zelle and Mooney, 1996; Zettlemoyer and Collins,\n2005; Liang et al., 2013; Cheng et al., 2017). As for\nmodern approaches based on the encoder-decoder\narchitecture, grounding also plays an important\nrole and considerable work has demonstrated the\npositive effect of it (Guo et al., 2019; Dong et al.,\n2019; Liu et al., 2020a; Wang et al., 2020b; Chen\net al., 2020). Despite its success, existing ground-\ning methods mainly relied on heavy manual efforts\nlike high-quality lexicons (Reddy et al., 2016) or ad-\nhoc heuristic rules like n-gram matching (Guo et al.,\n2019), suffering from poor Ô¨Çexibility. To explore\nmore Ô¨Çexible methods, researchers recently tried a\ndata-driven way: they collected grounding annota-\ntions as supervision to train grounding models (Li\net al., 2020a; Lei et al., 2020; Shi et al., 2020). How-\never, this modeling Ô¨Çexibility in their approaches\nrequires expensive annotations of grounding, which\nmost of the time are not available.\nTo alleviate the above issues, we present a novel\napproach Erasing-then-Awakening (ETA)1. It is in-\nspired by recent advances in interpretable machine\nlearning (Samek et al., 2017), where the impor-\ntance of individual pixels can be quantiÔ¨Åed with\nrespect to the classiÔ¨Åcation decision. Similarly, our\napproach Ô¨Årstly quantiÔ¨Åes the contribution of each\nword with respect to each concept, by erasing it\nand probing the variation of concept prediction de-\n1Our code is available at https://github.com/\nmicrosoft/ContextualSP\ncisions (elaborated later). Then it employs these\ncontributions as pseudo labels to awaken latent\ngrounding from PLMs. In contrast to prior work,\nour approach only needs supervision of concept pre-\ndiction, which can be easily derived by downstream\ntasks (e.g., text-to-SQL) instead of full grounding\nsupervision. Empirical studies on four datasets\ndemonstrate that our approach can awaken latent\ngrounding which is understandable to human ex-\nperts. It is highly non-trivial because our approach\nis not exposed to any human-annotated grounding\nlabel in training. More importantly, we Ô¨Ånd that the\ngrounding can be easily coupled with downstream\nmodels to boost their performance, and the abso-\nlute improvement is up to 9.8%. In summarization,\nour contribution is as three-fold:\n1. To the best of our knowledge, we are the Ô¨Årst\none to highlight and demonstrate the possibil-\nity of awakening latent grounding from PLMs.\n2. We propose a novel weakly supervised ap-\nproach erasing-then-awakening, to awaken la-\ntent grounding from PLMs. Empirical stud-\nies on four datasets demonstrate that our ap-\nproach can awaken latent grounding which is\nunderstandable to human experts.\n3. Taking text-to-SQL as a case study, we suc-\ncessfully couple our approach with two off-\nthe-shelf parsers. Experimental results on two\nbenchmarks show the effectiveness of our ap-\nproach on boosting downstream performance.\n1176\n2 Method: Erasing-then-Awakening\nIn the task of grounding, we are given a ques-\ntion x = ‚ü®x1,¬∑¬∑¬∑ ,xN ‚ü©and a concept set C =\n{c1,¬∑¬∑¬∑ ,cK}, where each concept consists of sev-\neral tokens. The goal of grounding is to Ô¨Ånd out\ntokens (also known as mentions) in x which are\nrelevant to concepts in C. Generally, the grounding\nprocedure learns to create a N√óK matrix, which\nwe call latent grounding. In some cases, a set of\npairs is needed, of which each one explicitly shows\na token and a concept is grounded. We call this\nkind of pairs as grounding pairs below.\nAs illustrated in Figure 2, our model consists\nof a PLM module, a CP module and a grounding\nmodule. In this section, we Ô¨Årst present the training\nprocedure of ETA, which at a high-level involves\nthree steps: (1) Train an auxiliary concept predic-\ntion module. (2) Erase tokens in a question to ob-\ntain the concept prediction conÔ¨Ådence differences\nas pseudo alignment. (3) Awaken latent ground-\ning from PLMs by applying pseudo alignment as\nsupervision. Then we introduce the procedure to\nproduce grounding pairs in inference.\n2.1 Training a Concept Prediction Module\nGiven x and C, the goal of the concept prediction\nmodule is to identify if each concept ck ‚àà Cis\nmentioned or not in the question x. Although it\ndoes not seem to be directly related to grounding, it\nis a pre-requisite for the erasing mechanism, which\nwill be elaborated later. As for ck‚Äôs supervision\nlk ‚àà {0,1}, it is the weak supervision ETA re-\nlies on, and can be readily obtained through down-\nstream task signals. Taking text-to-SQL as an illus-\ntration, each database schema (i.e., table, column\nand cell value) in an annotated SQL can be consid-\nered as mentioned in the question ( lk = 1), with\nothers as negative examples (lk = 0).\nOnce the supervision is prepared, the CP module\nis trained to conduct binary classiÔ¨Åcation over the\nrepresentation of each concept. As done in previ-\nous work (Hwang et al., 2019), we Ô¨Årst concatenate\nthe question and all concepts into a sequence as\ninput to the PLM module. As illustrated in Fig-\nure 2, the input sequence starts with [CLS], with\nthe question and each concept being separated by\n[SEP]. Then, the sequence is fed into the PLM\nmodule to produce deep contextual representations\nover each position. Denoting ‚ü®q1,q2,..., qN ‚ü©and\n‚ü®e1,e2,..., eK‚ü©as the token representations and\nconcept representations, they can be obtained by:\n{qn}N\nn= 1, {ek}K\nk= 1=PLM\n(\n[CLS],x,{[SEP], ck}K\nk= 1\n)\n, (1)\nwhere qn and ek correspond to the representations\nat the position of n-th question token and the Ô¨Årst\ntoken in ck respectively. Finally, each concept rep-\nresentation ek is passed to a classiÔ¨Åer to predict if\nit is mentioned in x as:\npk = Sigmoid(Wl ek), (2)\nwhere Wl is a learnable parameter. pk is the prob-\nability of ck mentioned in the question, which is\nreferred to by concept prediction conÔ¨Ådence below.\n2.2 Erasing Question Tokens\nOnce the concept prediction module is converged,\nwe apply an erasing mechanism to assist in the\nfollowing awakening phase. It follows a similar\nidea from the interpretable document classiÔ¨Åcation\n(Arras et al., 2016), where a word is considered im-\nportant for the document classiÔ¨Åcation if removing\nit and classifying the modiÔ¨Åed document results\nin a strong decrease of the classiÔ¨Åcation score. In\nour case, a token is considered highly relevant to\ncertain concepts if there is a large drop in these con-\ncept prediction conÔ¨Ådences after erasing the token.\nTherefore, we need the above mentioned concept\nprediction module to provide a reasonable concept\nprediction conÔ¨Ådence.\nConcretely, as shown in Figure 2, the eras-\ning mechanism erases the input sequentially, and\nfeeds each erased input into the PLM module\nand the subsequent CP module. For exam-\nple, with xn being substituted by a special to-\nken [UNK], we can obtain an erased input as\n[CLS],x1,¬∑¬∑¬∑ ,xn‚àí1,[UNK],xn+1,¬∑¬∑¬∑ ,cK. De-\nnoting ÀÜpn,k the concept prediction conÔ¨Ådence for\nck after erasing xn, we believe the difference be-\ntween ÀÜpn,k and pk reveals ck‚Äôs relevance toxn from\na PLM‚Äôs view. The conÔ¨Ådence difference‚àÜn,k can\nbe obtained by ‚àÜn,k = lk¬∑max(0,pk ‚àíÀÜpn,k). Re-\npeating the above procedure on the input question\nsequentially, ‚àÜ ‚ààRN√óK is Ô¨Ålled completely.\n2.3 Awakening Latent Grounding\nAs mentioned above, we believe ‚àÜ reÔ¨Çects the\nrelevance between each token and each concept\nfrom a PLM‚Äôs view. Therefore, we could directly\nuse ‚àÜ as ETA‚Äôs output. However, according to our\npreliminary study, the method performs poorly and\n1177\ncannot produce high-quality alignment2. Different\nfrom directly using ‚àÜ, we employ it to ‚Äúawaken‚Äù\nthe latent grounding. To be speciÔ¨Åc, we introduce\na grounding module upon representations of the\nPLM module and train it using ‚àÜ as pseudo labels\n(i.e., pseudo alignment). The grounding module\nÔ¨Årst obtains grounding scores gn,k between each\nquestion token xn and each concept ck based on\ntheir deep contextual representations qn and ek as:\ngn,k = Week ¬∑(Wqqn)T\n‚àö\nd\n, (3)\nwhere We,Wq are learnable parameters and dis\nthe dimension ofek. Then it normalizes the ground-\ning scores into latent grounding Œ± as:\nŒ±n,k = exp(gn,k)‚àë\ni exp(gi,k). (4)\nFinally, the grounding module is trained to maxi-\nmize the likelihood with ‚àÜ as the weight:\n‚àë\nn\n‚àë\nk\n‚àÜn,k ¬∑log Œ±n,k. (5)\n2.4 Producing Grounding Pair\nRepeating erasing and awakening iteratively for\nepochs until the grounding module converges, we\ncan readily produce grounding pairs. Formally,\nwe aim to obtain a set of pairs, where each pair\n‚ü®xn,ck‚ü©indicates that xn is grounded to ck. Notic-\ning ck may contain several tokens, we keep all\nprobabilities in Œ±¬∑,k which exceeds œÑ/|ck|, where\nœÑ is a threshold and |ck|is the number of tokens\nin ck. Also, taking into account that xn should be\ngrounded to only one concept, we keep only the\nhighest probability over Œ±n,¬∑. Finally, for each pair\n‚ü®xn,ck‚ü©, it is thought to be a grounding pair ifŒ±n,k\nis kept and pk ‚â•0.5, otherwise it is not.\n3 Experiments\nIn this section, we conduct experiments to evaluate\nif the latent grounding awakened by ETA is under-\nstandable to human experts. Here we accomplish\nthe evaluation by comparing the grounding pairs\nproduced by ETA with human annotations.\n3.1 Experimental Setup\nDatasets We select two representative ground-\ning tasks where human annotations are available:\nschema linking and entity linking. Schema linking\n2More experimental results can be found in ¬ß3.3.\nis to ground questions into database schemas, while\nentity linking is to ground questions into entities\nof knowledge bases. For schema linking, we select\nSPIDER -L (Lei et al., 2020) andSQUALL (Shi et al.,\n2020) as our evaluation benchmarks. As mentioned\nin ¬ß2.1, the supervision for our model is obtained\nfrom SQL queries. As for entity linking, we select\nWebQSPELand GraphQEL(Sorokin and Gurevych,\n2018). The supervision for our model is obtained\nfrom SPARQL queries in a similar way.\nEvaluation For schema linking, as done in pre-\nvious work (Lei et al., 2020), we report the micro-\naverage precision, recall and F1-score for both\ncolumns ( ColP , ColR, ColF ) and tables ( TabP ,\nTabR, TabF ). For entity linking, we report the\nweak matching precision, recall and F1-score for\nentities (EntP , EntR, EntF ). The weak matching\nmetric is a commonly used metric in previous work\n(Sorokin and Gurevych, 2018), which considers a\nprediction as correct whenever the correct entity\nis identiÔ¨Åed and the predicted mention boundary\noverlaps with the ground truth boundary. More\ndetails can be seen in ¬ßA.\nBaselines For schema linking, we consider four\nstrong baselines. (1) N-gram Matching enumer-\nates all n-gram ( n ‚â§5) phrases in a natural lan-\nguage question, and links them to database schemas\nby fuzzy string matching. (2) SIM computes the\ndot product similarity between each question to-\nken and schema using their PLM representations\nwithout Ô¨Åne-tuning, to explore grounding capaci-\nties of unawakened PLMs. (3) CONTRAST learns\nby comparing the aggregated grounding scores of\nmentioned schemas with unmentioned ones in a\ncontrastive learning style, as done in Liu et al.\n(2020b). Concretely, in training, CONTRAST is\ntrained to accomplish the same concept prediction\ntask as our approach. With a similar architecture\nto the Receiver used in Liu et al. (2020b), it Ô¨Årst\ncomputes the similarity score between each token\nand each concept, and then uses max pooling to\naggregate the similarity scores of a concept over\nan utterance into a concept prediction score. Fi-\nnally, a margin-based loss is used to encourage the\nbaseline to give higher concept prediction scores\non mentioned concepts than unmentioned concepts.\n(4) SLSQLL & ALIGNL. SLSQLL (ALIGNL) is\na learnable schema linking module 3 proposed in\n3SLSQL and ALIGN use multi-task learning to simultane-\nously learn schema linking and SQL generation.\n1178\nModel SPIDER -L S QUALL\nColP ColR ColF TabP TabR TabF ColP ColR ColF\nN-gram Matching 61.4 69 .1 65 .1 78 .2 69 .6 73 .6 71 .6 50 .8 59 .4\nSIM + BERT 16.6 8 .0 10 .8 8 .5 11 .6 9 .8 13 .9 18 .0 15 .7\nCONTRAST + BERT 83.7 68 .4 75 .3 84.0 76.9 80 .3 47 .9 31 .2 37 .8\nETA + BERT 86.1 79 .3 82 .5 81.1 85.3 83 .1 77 .3 62 .4 69 .0\nSLSQLL + BERT‚ô•(Lei et al., 2020) 82.6 82 .0 82 .3 80 .6 84 .0 82 .2 ‚Äì ‚Äì ‚Äì\nALIGNL + BERT‚ô•(Shi et al., 2020) ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì 79.2 72 .8 75 .8\nTable 1: Experimental results on schema linking dev sets. ‚ô• means the model uses schema linking supervision,\nwhile other learnable models use weak supervision. +BERT means using BERT as encoder, the same for Table 2.\nModel WebQSPEL GraphQEL(zero-shot)\nEntP EntR EntF EntP EntR EntF\nHeuristic (Sorokin and Gurevych, 2018) 30.2 60 .8 40 .4 - - -\nETA + BERT 76.6 72 .5 74 .5 43 .1 42 .1 42 .7\nVCG‚ô•(Sorokin and Gurevych, 2018) 82.4 68 .3 74 .7 54 .1 30 .6 39 .0\nELQ + BERT‚ô•(Li et al., 2020a) 90.0 85 .0 87 .4 60 .1 57 .2 58 .6\nTable 2: Experimental results on entity linking test sets. ‚ô• means the model uses entity linking supervision from\nWebQSPEL, while E TA uses the weak supervision derived from WebQSP. Following previous work (Sorokin and\nGurevych, 2018), we use GraphQELonly in the evaluation phase to test the generalization ability of our model.\nSLSQL (ALIGN). Unlike our method, these two\nmethods are trained with the full schema linking\nsupervision. Please refer to Shi et al. (2020) and\nLei et al. (2020) for more details. Notably, for\nbaselines which require a threshold, we tuned their\nthresholds based on dev sets for fair comparison.\nFor entity linking, we compare ETA with three\npowerful methods. (1) Heuristic picks the most\nfrequent entity among the candidates found by\nstring matching over Wikidata. (2) VCG (Sorokin\nand Gurevych, 2018) aggregates and mixes con-\ntexts of different granularities to perform en-\ntity linking. (3) ELQ (Li et al., 2020a) uses\na bi-encoder to perform entity linking in one\npass, achieving state-of-the-art performance on\nWebQSPELand GraphQEL. VCG and ELQ utilize\nentity linking supervision in training, while ETA\ndoes not.\nImplementation For schema linking we follow\nthe procedure in ¬ß2.4 to produce grounding pairs\nto evaluate, while for entity linking we further\nmerge adjacent grounding pairs to produce span-\nlevel grounding pairs. We implement ETA in Py-\ntorch (Paszke et al., 2019). With respect to PLMs\nin experiments, we use the uncased BERT-base\n(BERT)4 and BERT-large (BERTL) from Trans-\n4Our approach is theoretically applicable to different\nPLMs. In this paper, we chose BERT as a representative\nand we leave exploration of different PLMs for future work.\nformers library (Wolf et al., 2020). As for the opti-\nmizer, we employ AdamW (Loshchilov and Hutter,\n2019). More details (e.g., learning rate) of each\nexperiment can be found in ¬ßC.1.\n3.2 Experimental Results\nTable 1 shows the experimental results on the\nschema linking task. As shown, our method outper-\nforms all weakly supervised methods and heuristic-\nbased methods by a large margin. For example,\non SPIDER -L, ETA + BERT achieves an absolute\nimprovement of 7.2% ColF and 2.8% TabF over\nthe best baseline CONTRAST . The same conclu-\nsion can be drawn from the experimental results\non the entity linking task shown in Table 2. For\ninstance, ETA + BERT can obtain a highEntF up\nto 74.5% on WebQSPEL, which is a satisfying per-\nformance for downstream tasks. All results above\ndemonstrate the superiority of our approach on\nawakening latent grounding from PLMs. With\nrespect to the reason that PLMs work well on\nboth schema linking and entity linking, it may be\nbecause both schema linking and entity linking\nrequire text-based semantic matching (e.g., syn-\nonyms), which PLMs excel at.\nFurthermore, it is very surprising that although\nnot trained under Ô¨Åne-grained grounding supervi-\nsion, our model is comparable with or slightly\nworse than the fully supervised models across\n1179\nError Type Example Error\nMissed Grounding (43.1%) How many points did arnaud demare receive?\nGOLD: points‚Üí‚ÄúUCI world tour points‚Äù PRED:\nTechnically Correct (21.0%) Total population of millbrook Ô¨Årst nation?\nGOLD: population‚Üí‚ÄúPopulation‚Äù\nPRED: population‚Üí‚ÄúPopulation‚Äù; nation‚Üí‚ÄúCommunity‚Äù\nPartially Correct (15.8%) Who was the Ô¨Årst winning captain?\nGOLD: the Ô¨Årst‚Üí‚ÄúYear‚Äù; winning captain‚Üí‚ÄúWinning Captain‚Äù\nPRED: Ô¨Årst‚Üí‚ÄúYear‚Äù; winning captain‚Üí‚ÄúWinning Captain‚Äù\nWrong Grounding (10.1%) Were the matinee and evening performances held earlier than the 8th anniversary?\nGOLD: earlier‚Üí‚ÄúDate‚Äù\nPRED: matinee‚Üí‚ÄúPerformance‚Äù; earlier‚Üí‚ÄúDate‚Äù\nTable 3: Four main error types made by ETA along with their proportions on SQUALL dataset.\ndatasets. For instance, on SPIDER -L, our model ex-\nceeds the fully supervised baseline SLSQLL by 0.9\npoints on TabF . On SQUALL , our model holds a\nslightly worse performance than the fully super-\nvised baseline ALIGN L. It is highly nontrivial\nsince CONTRAST , the best weakly supervised base-\nline on SPIDER -L, is far from the fully supervised\nmodel on SQUALL , while our model has only a\nsmall drop. Besides, on WebQSPELand GraphQEL,\nalthough our model is inferior to the state-of-the-\nart model ELQ, it also achieves a comparable per-\nformance with the fully supervised baseline VCG.\nThese results provide strong evidence that PLMs\ndo have very good grounding capabilities, and our\napproach can awaken them from PLMs.\n3.3 Model Analysis\nIn this section, we try to answer four interesting\nresearch questions via a thorough analysis: RQ1.\nDoes the grounding capability come mainly from\nthe PLM? RQ2. Is the awakening phase neces-\nsary? RQ3. Do larger PLMs have better grounding\ncapabilities? RQ4. What are the remaining errors?\nRQ1 There is a long term debate in literature\nabout if knowledge is primarily learned by PLMs,\nwhen extra parameters are employed in analysis\n(Hewitt and Liang, 2019). Similarly, since our ap-\nproach depends on extra modules (e.g., grounding\nmodule), it faces the same dilemma: how can we\nknow whether the latent grounding is learnt from\nPLMs or extra modules? Therefore, we apply our\napproach to a randomly initialized Transformer en-\ncoder (Vaswani et al., 2017), to probe the ground-\ning capability of a model that has not been pre-\ntrained. To make it comparable, the encoder has\nthe same architecture as BERT. However, it only\ngets a 40% ColF on SQUALL , not even as good\n0 5 10 15 20 25\n15\n30\n45\n60\n75\nAwakeningPseudo AlignmentPseudo w/SoftmaxPseudo w/Sum\nFigure 3: Col F score on the dev set of S QUALL at dif-\nferent training epochs. ‚ÄúPseudo w/ Softmax‚Äù means\nnormalizing pseudo alignment with Softmax, while\n‚ÄúPseudo w/ Sum‚Äù means normalizing through dividing\neach number by the sum of them.\nas the N-gram baseline. Considering it contains\nthe same extra modules as ETA + BERT, the huge\ngap between it and ETA + BERT supports the opin-\nion that the latent grounding is mainly learnt from\nPLMs. Meanwhile, one concern shared by our re-\nviewers is the risk of supervision exposure during\ntraining of the concept prediction module. In other\nwords, our approach may ‚Äústeal‚Äù some supervision\nin the concept prediction module to achieve good\nperformance on grounding. However, the above ex-\nperiment demonstrates that a non-pretrained model\nis far from strong grounding capability even with\nthe same concept prediction module. We hope the\nÔ¨Ånding will alleviate the concern.\nRQ2 As mentioned in¬ß2.3, the pseudo alignment\n‚àÜ can also be employed as the model prediction.\nTherefore, we conduct experiments to verify if our\nproposed awakening phase is necessary. As shown\nin Figure 3, even with various normalization meth-\nods (e.g., Softmax), ‚àÜ does not produce satisfac-\ntory alignment. In contrast, our model consistently\nperforms well. To investigate deeper, we conduct\na careful analysis on ‚àÜ, and we are surprised to\n1180\nPLMs\n[CLS]  Find  the  average , maximum and ‚ãØ movies before 2002 . [SEP] Movie [SEP] budget ‚ãØ[SEP] Year\nDecoder\n‚ãØ\n‚ãØ\nETA\nùëû1 ùëû1 ùëûùëõ‚àí1 ùëûùëõ ùëí1 ùëíùëö‚ãØ ‚ãØ\nEncoder\n‚äïùëì\n0.14 0.16 ‚ãØ 0.18 0.06\n‚ãÆ ‚ãÆ ‚ã± ‚ãÆ ‚ãÆ\n0.11 0.33 ‚ãØ 0.48 0.55\nSELECT Avg(budget), Max(budget), Min(budget) FROM movie WHERE year < 2020\nQuestion Schema\nSQL\nFigure 4: The illustration of the solution to couple ETA\nwith downstream text-to-SQL parsers.\nÔ¨Ånd that values of ‚àÜ are generally small and not as\nsigniÔ¨Åcantly different with each other as we would\nexpect. Therefore, we believe the success of our\napproach stems from the fact that it encourages the\ngrounding module to capture subtle differences and\nstrength them.\nRQ3 We apply our approach on BERT-large\n(BERTL) and conduct experiments on SPIDER -L.\nThe results show BERTL brings an improvement\nof 2.5% ColF and 0.5% TabF , suggesting the pos-\nsibility of awakening better latent grounding from\nlarger PLMs. Nevertheless, the improvement may\nalso come from more parameters, so the conclusion\nneeds further investigation.\nRQ4 We manually examine 20% of our model‚Äôs\nerrors on the SQUALL dataset and summarize four\nmain error types: (1) missed grounding - where our\nmodel did not ground any token to a concept, (2)\ntechnically correct - where our model was techni-\ncally correct but the annotation was missing, (3)\npartially correct - where our model did not Ô¨Ånd all\ntokens of a concept, (4) wrong grounding - where\nthe model produced incorrect grounding. As shown\nin Table 3, only a small fraction of errors are wrong\ngrounding, indicating that the main challenge of\nour approach is recall rather than precision.\n4 Case Study: Text-to-SQL\nThe ETA model is proposed for general-purpose\nuses and intends to enhance different downstream\nsemantic parsing models. To verify it, we take the\ntext-to-SQL task as a case study. In this section, we\nÔ¨Årst present a general solution to couple ETA with\ndifferent text-to-SQL parsers. Then, we conduct\nexperiments on two off-the-shelf parsers to verify\nthe effectiveness of ETA.\n4.1 Coupling with Text-to-SQL Parsers\nInspired by Lei et al. (2020), we present a general\nsolution to couple ETA with downstream parsers in\nModel Dev Test\nEx.Match Ex.Acc Ex.Acc\nALIGNP 37.8 ¬±0.6 56 .9 ¬±0.7 46 .6 ¬±0.5\nALIGNP + BERT 44.7 ¬±2.1 63 .8 ¬±1.1 51 .8 ¬±0.4\nETA + BERT 47.6 ¬±2.5 66.6 ¬±1.7 53.8 ¬±0.3\nALIGN‚ô• 42.2 ¬±1.5 61 .3 ¬±0.8 49 .7 ¬±0.4\nALIGN + BERT‚ô• 47.2 ¬±1.2 66 .5 ¬±1.2 54 .1 ¬±0.2\nTable 4: Ex.Match and Ex.Acc results on the dev and\ntest set of WTQ. + BERT means using BERT to en-\nhance encoder. ‚ô• means the model uses extra schema\nlinking supervision. Both are the same for Table 5.\nFigure 4. As shown, we Ô¨Årst obtain a schema-aware\nrepresentation for each question token, by fusing\nthe token representation and its related schema\nrepresentation according to the latent grounding\nŒ±‚ààRN√óK (gray matrix in Figure 4). SpeciÔ¨Åcally,\ngiven a token representation qn and all schema\nrepresentations ‚ü®e1,e2,..., eK‚ü©, the schema-aware\nrepresentation Àúqn for qn can be computed as:\nÀúqn = qn‚äï\n‚àë\nk\nŒ±n,k ek. (6)\nThen we feed every Àúqn into a question encoder to\ngenerate hidden states, which are attended by a\ndecoder to decode the SQL query. By contributing\nto the schema-aware representation, ETA is able to\nprompt the decoder to predict appropriate schemas\nduring decoding. Notably, the encoder and decoder\nare not limited to speciÔ¨Åc modules, and we follow\nthe paper settings in subsequent experiments.\n4.2 Experimental Setup\nDatasets and Evaluation We conduct experi-\nments on two text-to-SQL benchmarks: WikiTable-\nQuestions(WTQ) (Pasupat and Liang, 2015)5 and\nSpider (Yu et al., 2018b). Following previous work,\nwe employ three kinds of evaluation metrics:Exact\nMatch (Ex.Match), Exact Set Match (Ex.Set) and\nExecution Accuracy (Ex.Acc). Ex.Match evaluates\nthe predicted SQL correctness by checking if it\nis equal to the ground-truth, while Ex.Set evalu-\nates the structural correctness by checking the set\nmatch of each SQL clause in the predicted query\nwith respect to the ground-truth. Ex.Acc evaluates\nthe functional correctness of the predicted SQL by\nchecking whether it yields the ground-truth answer.\n5Note that the original WTQ only contains answer anno-\ntations, and here we use the version with SQL annotations\nprovided by Shi et al. (2020). Our training data is a subset of\nthe original train set, while the test data keeps the same.\n1181\nModel Dev Test\nGlobalGNN + BERT (Bogin et al., 2019) 52.7 47 .4\nEditSQL + BERT (Zhang et al., 2019) 57.6 53 .4\nIRNet + BERT (Guo et al., 2019) 61.9 54 .7\nIRNet v2 + BERT (Guo et al., 2019) 63.9 55 .0\nBRIDGE + BERT (Lin et al., 2020) 65.5 59 .2\nBRIDGE + BERTL (Lin et al., 2020) 70.0 65 .0\nRATSQL + BERTL (Wang et al., 2020a) 69.7 65.6\nSLSQLP + BERT 57.4 -\nSLSQLP + BERTL 61.0 -\nETA + BERT 64.5 59 .5\nETA + BERTL 70.8 65.3\nSLSQL + BERT‚ô• 60.8 55 .7\nSLSQL + BERTL\n‚ô• 65.1 -\nSLSQL + BERT (Oracle)‚ô• 72.4 -\nTable 5: Ex.Set results on the dev and test set of Spider.\nBaselines On WTQ, our baselines include\nALIGNP and ALIGN, where the former is a vanilla\nattention based sequence to sequence model and\nthe latter enhances ALIGN P with an additional\nschema linking task (Shi et al., 2020). Similarly,\non Spider, our main baselines are SLSQL P and\nits schema linking enhanced version SLSQL (Lei\net al., 2020). SLSQL P is made up of a question\nencoder and a two-step SQL decoder. In the Ô¨Årst\ndecoding step, a coarse SQL (i.e., without aggre-\ngation functions) is generated. Then the coarse\nSQL is used to synthesize the Ô¨Ånal SQL in the\nsecond decoding step. Here we also report the per-\nformance of SLSQL + BERT (Oracle), where the\nlearnable schema linking module is replaced with\nhuman annotations in inference. It represents the\nmaximum potential beneÔ¨Åt of schema linking for\nthe text-to-SQL task. Meanwhile, for a comprehen-\nsive comparison, we also compare our model with\nstate-of-the-art models on the Spider benchmark6.\nWe refer readers to their papers for details.\nImplementation As for our approach, on WTQ,\nwe employ ALIGNP7 as our base parser, while on\nSpider we select SLSQLP8 as our base parser. For\nboth parsers, we try to follow the same hyperpa-\nrameters as described in the paper to reduce other\nfactors that may affect the performance. More im-\nplementation details can be found in ¬ßC.2.\n4.3 Experimental Results\nTable 4 and Table 5 show the experimental re-\nsults of several methods on WTQ and Spider re-\nspectively. As observed, introducing ETA dra-\n6https://yale-lily.github.io/spider\n7https://github.com/tzshi/squall\n8https://github.com/WING-NUS/slsql\nwhere\nis the\nyoungest teacher from\n?\nteacher\nteacher.age\nteacher.hometown\n0.00 0.00 0.00 0.00 1.00 0.00 0.00\n0.01 0.00 0.00 0.83 0.15 0.01 0.00\n0.56 0.01 0.00 0.01 0.31 0.11 0.00\nFigure 5: The latent grounding produced by\nETA + BERTL for the question ‚ÄúWhere is the youngest\nteacher from?‚Äù.\nmatically improves the performance of both base\nparsers, demonstrating its effectiveness on down-\nstream tasks. Taking Spider as an illustration, our\nmodel ETA + BERT boosts SLSQLP + BERT by\nan absolute improvement 7.1% on the Ex.Set met-\nric. As the PLM becomes larger (e.g., BERT L),\nthe improvement becomes more signiÔ¨Åcant, up to\n9.8%. Compared with state-of-the-art methods,\nour model ETA + BERTL also obtains a competi-\ntive performance, which is extremely impressive\nsince it is based on a simple parser.\nMore interestingly, on both datasets, our model\ncan achieve similar even better performance com-\npared to methods which employ extra grounding\nsupervision. For instance, in comparison with\nSLSQL + BERT on Spider, ourETA + BERT out-\nperforms it by 3.7%. Taking into account that\nSLSQL utilizes additional supervision, the perfor-\nmance gain is very surprising. We attribute the\ngain to two possible reasons: (1) The PLMs already\nlearn latent grounding which is understandable to\nhuman experts. (2) Compared with training with\nstrong schema linking supervision, training with\nweak supervision alleviates the issue of exposure\nbias, and thus enhance the generalization ability of\nETA.\nTable 6 presents the model predictions of\nETA + BERTL on three real cases. As observed,\nETA has learned the grounding about adjec-\ntive (e.g., oldest ‚Üíage), entity (e.g., where ‚Üí\nhometown) and semantic matching (e.g.,registered\n‚Üístudent enrolment). Meanwhile, grounding\npairs provide us a useful guide to better understand\nthe model predictions. Figure 5 visualizes the latent\ngrounding for Q2 in Table 6, and more visualiza-\ntion can be found in ¬ßD.\n5 Related Work\nThe most related work to ours is the line of inducing\nor probing knowledge in pretrained language mod-\n1182\nQuestion with Alignment SQL with Alignment\n1. Show name1, country2, age3 for all singers4\nordered by age3 from the oldest3 to the youngest.\nSELECT name1, country2, age3 FROM singer4\nORDER BY age3 DESC\n2. Where1 is the youngest2 teacher3 from? SELECT hometown 1 FROM teacher3 ORDER BY age2 ASC LIMIT 1\n3. For each semester1, what is the name2 and id3\nof the one with the most students registered4?\nSELECT semester name2, semester id3 FROM semesters1 JOIN\nstudent enrolment4 ON semesters.semester id =\nstudent enrolment.semester id GROUP BY semester id3\nORDER BY COUNT(*) DESC LIMIT 1\nTable 6: The predicted grounding pairs and SQLs of our best model on three real cases from the Spider dev set.\nThe question token and the schema with the same subscript are grounded.\nels. According to the knowledge category, there\nare mainly two kinds of methods: one focuses on\nsyntactic knowledge and the other pays attention to\nsemantic knowledge. Under the category of syntac-\ntic knowledge, several work showed that BERT em-\nbeddings encoded syntactic information in a struc-\ntural form and can be recovered (Lin et al., 2019b;\nWarstadt and Bowman, 2020; Hewitt and Manning,\n2019; Wu et al., 2020). However, recent work also\nshowed that BERT did not rely on syntactic infor-\nmation for downstream task performance, and thus\ndoubted the role of syntactic knowledge (Ettinger,\n2020; Glavas and Vulic, 2020). As for semantic\nknowledge, although it is less explored than syntac-\ntic knowledge, previous work showed that BERT\ncontained some semantic information, such as en-\ntity types (Ettinger, 2020), semantic roles (Tenney\net al., 2019) and factual knowledge (Petroni et al.,\n2019). Different from the above work, we focus on\nthe grounding capability, an under-explored branch\nof language semantics.\nOur work is also closely related to entity link-\ning and schema linking, which can be viewed as\nsubareas of grounding on speciÔ¨Åc scenarios. Given\nan utterance, entity linking aims at Ô¨Ånding all men-\ntioned entities in it using a knowledge base as can-\ndidate pool (Tan et al., 2017; Chen et al., 2018; Li\net al., 2020a), while schema linking tries to Ô¨Ånd\nall mentioned schemas related to speciÔ¨Åc databases\n(Dong et al., 2019; Lei et al., 2020; Shi et al., 2020).\nPrevious work generally either employed full su-\npervision to train linking models (Li et al., 2020a;\nLei et al., 2020; Shi et al., 2020), or treated linking\nas a minor pre-processing(Yu et al., 2018a; Guo\net al., 2019; Lin et al., 2019a) and used heuristic\nrules to obtain the result. Our work is different\nfrom them since we optimize the linking model\nwith weak supervision from downstream signals,\nwhich is Ô¨Çexible and practicable. Similarly, Dong\net al. (2019) utilized downstream supervision to\ntrain their linking model. Compared with them us-\ning policy gradient, our method is more efÔ¨Åcient\nsince it directly learns the grounding module using\npseudo alignment as supervision.\n6 Conclusion & Future Work\nIn summary, we propose a novel weakly super-\nvised approach to awaken latent grounding from\npretrained language models via erasing. Only with\ndownstream signals, our approach can induce latent\ngrounding from pretrained language models which\nis understandable to human experts. More impor-\ntantly, we demonstrate that our approach could be\napplied to off-the-shelf text-to-SQL parsers and\nsigniÔ¨Åcantly improve their performance. For fu-\nture work, we plan to extend our approach to more\ndownstream tasks such as visual question answer-\ning. We also plan to utilize our approach to improve\nthe error locator module in existing interactive se-\nmantic parsing systems (Li et al., 2020b).\nAcknowledgement\nWe would like to thank all the anonymous review-\ners for their constructive feedback and useful com-\nments. We also thank Tao Yu and Bo Pang for\nevaluating our submitted models on the test set\nof Spider. The Ô¨Årst author Qian is supported by\nthe Academic Excellence Foundation of Beihang\nUniversity for PhD Students.\nEthical Considerations\nThis paper conducts experiments on several exist-\ning datasets covering the areas of entity linking,\nschema entity and text-to-SQL. All claims in this\npaper are based on the experimental results. Ev-\nery experiment can be conducted on a single Tesla\nP100 or P40 GPU. No demographic or identity\ncharacteristics information is used in this paper.\n1183\nReferences\nLeila Arras, Franziska Horn, Gr ¬¥egoire Montavon,\nKlaus-Robert M ¬®uller, and Wojciech Samek. 2016.\n‚Äùwhat is relevant in a text document?‚Äù: An in-\nterpretable machine learning approach. CoRR,\nabs/1612.07843.\nBen Bogin, Matt Gardner, and Jonathan Berant. 2019.\nGlobal reasoning over database structures for text-\nto-SQL parsing. In Proceedings of the 2019 Con-\nference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Confer-\nence on Natural Language Processing (EMNLP-\nIJCNLP), pages 3659‚Äì3664, Hong Kong, China. As-\nsociation for Computational Linguistics.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen,\nEric Sigler, Mateusz Litwin, Scott Gray, Benjamin\nChess, Jack Clark, Christopher Berner, Sam Mc-\nCandlish, Alec Radford, Ilya Sutskever, and Dario\nAmodei. 2020. Language models are few-shot learn-\ners. In Advances in Neural Information Processing\nSystems 33: Annual Conference on Neural Informa-\ntion Processing Systems 2020, NeurIPS 2020, De-\ncember 6-12, 2020, virtual.\nLihan Chen, Jiaqing Liang, Chenhao Xie, and Yanghua\nXiao. 2018. Short text entity linking with Ô¨Åne-\ngrained topics. In Proceedings of the 27th ACM In-\nternational Conference on Information and Knowl-\nedge Management, CIKM ‚Äô18, page 457‚Äì466, New\nYork, NY , USA. Association for Computing Machin-\nery.\nSanxing Chen, Aidan San, Xiaodong Liu, and\nYangfeng Ji. 2020. A tale of two linkings: Dy-\nnamically gating between schema linking and struc-\ntural linking for text-to-SQL parsing. In Proceed-\nings of the 28th International Conference on Com-\nputational Linguistics, pages 2900‚Äì2912, Barcelona,\nSpain (Online). International Committee on Compu-\ntational Linguistics.\nJianpeng Cheng, Siva Reddy, Vijay Saraswat, and\nMirella Lapata. 2017. Learning structured natural\nlanguage representations for semantic parsing. In\nProceedings of the 55th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers), pages 44‚Äì55, Vancouver, Canada. As-\nsociation for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 4171‚Äì4186, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\nZhen Dong, Shizhao Sun, Hongzhi Liu, Jian-Guang\nLou, and Dongmei Zhang. 2019. Data-anonymous\nencoding for text-to-SQL generation. In Proceed-\nings of the 2019 Conference on Empirical Methods\nin Natural Language Processing and the 9th Inter-\nnational Joint Conference on Natural Language Pro-\ncessing (EMNLP-IJCNLP), pages 5405‚Äì5414, Hong\nKong, China. Association for Computational Lin-\nguistics.\nAllyson Ettinger. 2020. What BERT is not: Lessons\nfrom a new suite of psycholinguistic diagnostics for\nlanguage models. Transactions of the Association\nfor Computational Linguistics, 8:34‚Äì48.\nGoran Glavas and Ivan Vulic. 2020. Is supervised syn-\ntactic parsing beneÔ¨Åcial for language understanding?\nan empirical investigation. CoRR, abs/2008.06788.\nJiaqi Guo, Zecheng Zhan, Yan Gao, Yan Xiao,\nJian-Guang Lou, Ting Liu, and Dongmei Zhang.\n2019. Towards complex text-to-SQL in cross-\ndomain database with intermediate representation.\nIn Proceedings of the 57th Annual Meeting of the\nAssociation for Computational Linguistics , pages\n4524‚Äì4535, Florence, Italy. Association for Compu-\ntational Linguistics.\nJohn Hewitt and Percy Liang. 2019. Designing and\ninterpreting probes with control tasks. In Proceed-\nings of the 2019 Conference on Empirical Methods\nin Natural Language Processing and the 9th Inter-\nnational Joint Conference on Natural Language Pro-\ncessing (EMNLP-IJCNLP), pages 2733‚Äì2743, Hong\nKong, China. Association for Computational Lin-\nguistics.\nJohn Hewitt and Christopher D. Manning. 2019. A\nstructural probe for Ô¨Ånding syntax in word repre-\nsentations. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 4129‚Äì4138, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\nWonseok Hwang, Jinyeung Yim, Seunghyun Park, and\nMinjoon Seo. 2019. A comprehensive exploration\non wikisql with table-aware word contextualization.\nCoRR, abs/1902.01069.\nGanesh Jawahar, Beno ÀÜƒ±t Sagot, and Djam ¬¥e Seddah.\n2019. What does BERT learn about the structure\nof language? In Proceedings of the 57th Annual\nMeeting of the Association for Computational Lin-\nguistics, pages 3651‚Äì3657, Florence, Italy. Associa-\ntion for Computational Linguistics.\nWenqiang Lei, Weixin Wang, Zhixin Ma, Tian Gan,\nWei Lu, Min-Yen Kan, and Tat-Seng Chua. 2020.\nRe-examining the role of schema linking in text-to-\nSQL. In Proceedings of the 2020 Conference on\n1184\nEmpirical Methods in Natural Language Process-\ning (EMNLP) , pages 6943‚Äì6954, Online. Associa-\ntion for Computational Linguistics.\nBelinda Z. Li, Sewon Min, Srinivasan Iyer, Yashar\nMehdad, and Wen-tau Yih. 2020a. EfÔ¨Åcient one-\npass end-to-end entity linking for questions. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 6433‚Äì6441, Online. Association for Computa-\ntional Linguistics.\nYuntao Li, Bei Chen, Qian Liu, Yan Gao, Jian-\nGuang Lou, Yan Zhang, and Dongmei Zhang. 2020b.\n‚Äúwhat do you mean by that?‚Äù a parser-independent\ninteractive approach for enhancing text-to-SQL. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 6913‚Äì6922, Online. Association for Computa-\ntional Linguistics.\nPercy Liang, Michael I. Jordan, and Dan Klein. 2013.\nLearning dependency-based compositional seman-\ntics. Computational Linguistics, 39(2):389‚Äì446.\nKevin Lin, Ben Bogin, Mark Neumann, Jonathan Be-\nrant, and Matt Gardner. 2019a. Grammar-based neu-\nral text-to-sql generation. CoRR, abs/1905.13326.\nXi Victoria Lin, Richard Socher, and Caiming Xiong.\n2020. Bridging textual and tabular data for cross-\ndomain text-to-SQL semantic parsing. In Findings\nof the Association for Computational Linguistics:\nEMNLP 2020 , pages 4870‚Äì4888, Online. Associa-\ntion for Computational Linguistics.\nYongjie Lin, Yi Chern Tan, and Robert Frank. 2019b.\nOpen sesame: Getting inside BERT‚Äôs linguistic\nknowledge. In Proceedings of the 2019 ACL Work-\nshop BlackboxNLP: Analyzing and Interpreting Neu-\nral Networks for NLP , pages 241‚Äì253, Florence,\nItaly. Association for Computational Linguistics.\nNelson F. Liu, Matt Gardner, Yonatan Belinkov,\nMatthew E. Peters, and Noah A. Smith. 2019. Lin-\nguistic knowledge and transferability of contextual\nrepresentations. In Proceedings of the 2019 Confer-\nence of the North American Chapter of the Associ-\nation for Computational Linguistics: Human Lan-\nguage Technologies, Volume 1 (Long and Short Pa-\npers), pages 1073‚Äì1094, Minneapolis, Minnesota.\nAssociation for Computational Linguistics.\nQian Liu, Bei Chen, Jiaqi Guo, Jian-Guang Lou, Bin\nZhou, and Dongmei Zhang. 2020a. How far are\nwe from effective context modeling? an exploratory\nstudy on semantic parsing in context twitter. In IJ-\nCAI, pages 3580‚Äì3586.\nQian Liu, Yihong Chen, Bei Chen, Jian-Guang Lou,\nZixuan Chen, Bin Zhou, and Dongmei Zhang.\n2020b. You impress me: Dialogue generation via\nmutual persona perception. In Proceedings of the\n58th Annual Meeting of the Association for Compu-\ntational Linguistics, pages 1417‚Äì1427, Online. As-\nsociation for Computational Linguistics.\nIlya Loshchilov and Frank Hutter. 2019. Decou-\npled weight decay regularization. In 7th Inter-\nnational Conference on Learning Representations,\nICLR 2019, New Orleans, LA, USA, May 6-9, 2019 .\nOpenReview.net.\nPanupong Pasupat and Percy Liang. 2015. Compo-\nsitional semantic parsing on semi-structured tables.\nIn Proceedings of the 53rd Annual Meeting of the\nAssociation for Computational Linguistics and the\n7th International Joint Conference on Natural Lan-\nguage Processing (Volume 1: Long Papers) , pages\n1470‚Äì1480, Beijing, China. Association for Compu-\ntational Linguistics.\nAdam Paszke, Sam Gross, Francisco Massa, Adam\nLerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca\nAntiga, Alban Desmaison, Andreas Kopf, Edward\nYang, Zachary DeVito, Martin Raison, Alykhan Te-\njani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang,\nJunjie Bai, and Soumith Chintala. 2019. Pytorch:\nAn imperative style, high-performance deep learn-\ning library. In Advances in Neural Information Pro-\ncessing Systems, volume 32, pages 8026‚Äì8037. Cur-\nran Associates, Inc.\nFabio Petroni, Tim Rockt ¬®aschel, Sebastian Riedel,\nPatrick Lewis, Anton Bakhtin, Yuxiang Wu, and\nAlexander Miller. 2019. Language models as knowl-\nedge bases? In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Confer-\nence on Natural Language Processing (EMNLP-\nIJCNLP), pages 2463‚Äì2473, Hong Kong, China. As-\nsociation for Computational Linguistics.\nSiva Reddy, Oscar T ¬®ackstr¬®om, Michael Collins, Tom\nKwiatkowski, Dipanjan Das, Mark Steedman, and\nMirella Lapata. 2016. Transforming dependency\nstructures to logical forms for semantic parsing.\nTransactions of the Association for Computational\nLinguistics, 4:127‚Äì140.\nAnna Rogers, Olga Kovaleva, and Anna Rumshisky.\n2020. A primer in bertology: What we know about\nhow bert works. Transactions of the Association for\nComputational Linguistics, 8:842‚Äì866.\nDeb Roy. 2005. Grounding words in perception and\naction: computational insights. Trends in Cognitive\nSciences, 9(8):389 ‚Äì 396.\nW. Samek, A. Binder, G. Montavon, S. Lapuschkin,\nand K. M ¬®uller. 2017. Evaluating the visualization\nof what a deep neural network has learned. IEEE\nTransactions on Neural Networks and Learning Sys-\ntems, 28(11):2660‚Äì2673.\nTianze Shi, Chen Zhao, Jordan Boyd-Graber, Hal\nDaum¬¥e III, and Lillian Lee. 2020. On the poten-\ntial of lexico-logical alignments for semantic pars-\ning to SQL queries. In Findings of the Association\nfor Computational Linguistics: EMNLP 2020, pages\n1849‚Äì1864, Online. Association for Computational\nLinguistics.\n1185\nDaniil Sorokin and Iryna Gurevych. 2018. Mixing\ncontext granularities for improved entity linking on\nquestion answering data across entity categories. In\nProceedings of the Seventh Joint Conference on Lex-\nical and Computational Semantics , pages 65‚Äì75,\nNew Orleans, Louisiana. Association for Computa-\ntional Linguistics.\nChuanqi Tan, Furu Wei, Pengjie Ren, Weifeng Lv,\nand Ming Zhou. 2017. Entity linking for queries\nby searching Wikipedia sentences. In Proceed-\nings of the 2017 Conference on Empirical Meth-\nods in Natural Language Processing , pages 68‚Äì77,\nCopenhagen, Denmark. Association for Computa-\ntional Linguistics.\nIan Tenney, Patrick Xia, Berlin Chen, Alex Wang,\nAdam Poliak, R. Thomas McCoy, Najoung Kim,\nBenjamin Van Durme, Samuel R. Bowman, Dipan-\njan Das, and Ellie Pavlick. 2019. What do you\nlearn from context? probing for sentence structure\nin contextualized word representations. In 7th Inter-\nnational Conference on Learning Representations,\nICLR 2019, New Orleans, LA, USA, May 6-9, 2019 .\nOpenReview.net.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems 30: Annual Conference on Neural\nInformation Processing Systems 2017, December 4-\n9, 2017, Long Beach, CA, USA, pages 5998‚Äì6008.\nBailin Wang, Richard Shin, Xiaodong Liu, Oleksandr\nPolozov, and Matthew Richardson. 2020a. RAT-\nSQL: Relation-aware schema encoding and linking\nfor text-to-SQL parsers. In Proceedings of the 58th\nAnnual Meeting of the Association for Computa-\ntional Linguistics, pages 7567‚Äì7578, Online. Asso-\nciation for Computational Linguistics.\nChao Wang and Hui Jiang. 2019. Explicit utilization\nof general knowledge in machine reading compre-\nhension. In Proceedings of the 57th Annual Meet-\ning of the Association for Computational Linguis-\ntics, pages 2263‚Äì2272, Florence, Italy. Association\nfor Computational Linguistics.\nKai Wang, Weizhou Shen, Yunyi Yang, Xiaojun Quan,\nand Rui Wang. 2020b. Relational graph attention\nnetwork for aspect-based sentiment analysis. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 3229‚Äì\n3238, Online. Association for Computational Lin-\nguistics.\nAlex Warstadt and Samuel R. Bowman. 2020. Can\nneural networks acquire a structural bias from raw\nlinguistic data? CoRR, abs/2007.06761.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art natural language process-\ning. In Proceedings of the 2020 Conference on Em-\npirical Methods in Natural Language Processing:\nSystem Demonstrations, pages 38‚Äì45, Online. Asso-\nciation for Computational Linguistics.\nZhiyong Wu, Yun Chen, Ben Kao, and Qun Liu. 2020.\nPerturbed masking: Parameter-free probing for ana-\nlyzing and interpreting BERT. In Proceedings of the\n58th Annual Meeting of the Association for Compu-\ntational Linguistics, pages 4166‚Äì4176, Online. As-\nsociation for Computational Linguistics.\nTao Yu, Zifan Li, Zilin Zhang, Rui Zhang, and\nDragomir Radev. 2018a. TypeSQL: Knowledge-\nbased type-aware neural text-to-SQL generation. In\nProceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for Compu-\ntational Linguistics: Human Language Technolo-\ngies, Volume 2 (Short Papers), pages 588‚Äì594, New\nOrleans, Louisiana. Association for Computational\nLinguistics.\nTao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga,\nDongxu Wang, Zifan Li, James Ma, Irene Li,\nQingning Yao, Shanelle Roman, Zilin Zhang,\nand Dragomir Radev. 2018b. Spider: A large-\nscale human-labeled dataset for complex and cross-\ndomain semantic parsing and text-to-SQL task. In\nProceedings of the 2018 Conference on Empirical\nMethods in Natural Language Processing , pages\n3911‚Äì3921, Brussels, Belgium. Association for\nComputational Linguistics.\nJohn M. Zelle and Raymond J. Mooney. 1996. Learn-\ning to parse database queries using inductive logic\nprogramming. In Proceedings of the Thirteenth\nNational Conference on ArtiÔ¨Åcial Intelligence and\nEighth Innovative Applications of ArtiÔ¨Åcial Intelli-\ngence Conference, AAAI 96, IAAI 96, Portland, Ore-\ngon, USA, August 4-8, 1996, Volume 2, pages 1050‚Äì\n1055. AAAI Press / The MIT Press.\nLuke Zettlemoyer and Michael Collins. 2005. Learn-\ning to map sentences to logical form: Structured\nclassiÔ¨Åcation with probabilistic categorial grammars.\nIn UAI ‚Äô05, Proceedings of the 21st Conference\nin Uncertainty in ArtiÔ¨Åcial Intelligence, Edinburgh,\nScotland, July 26-29, 2005 , pages 658‚Äì666. AUAI\nPress.\nRui Zhang, Tao Yu, Heyang Er, Sungrok Shim,\nEric Xue, Xi Victoria Lin, Tianze Shi, Caim-\ning Xiong, Richard Socher, and Dragomir Radev.\n2019. Editing-based SQL query generation for\ncross-domain context-dependent questions. In Pro-\nceedings of the 2019 Conference on Empirical Meth-\nods in Natural Language Processing and the 9th In-\nternational Joint Conference on Natural Language\nProcessing (EMNLP-IJCNLP) , pages 5338‚Äì5349,\nHong Kong, China. Association for Computational\nLinguistics.\n1186\nLuowei Zhou, Yannis Kalantidis, Xinlei Chen, Jason J.\nCorso, and Marcus Rohrbach. 2019. Grounded\nvideo description. In IEEE Conference on Computer\nVision and Pattern Recognition, CVPR 2019, Long\nBeach, CA, USA, June 16-20, 2019 , pages 6578‚Äì\n6587. Computer Vision Foundation / IEEE.\nYuke Zhu, Oliver Groth, Michael S. Bernstein, and\nLi Fei-Fei. 2016. Visual7w: Grounded question an-\nswering in images. In 2016 IEEE Conference on\nComputer Vision and Pattern Recognition, CVPR\n2016, Las Vegas, NV , USA, June 27-30, 2016, pages\n4995‚Äì5004. IEEE Computer Society.\n1187\nA Evaluation Details\nA.1 Schema Linking\nLet ‚Ñ¶col be a set {(c,q)i|1 ‚â§i‚â§N}which con-\ntains N gold (column-question token) tuples. Let\n‚Ñ¶col be a set {(c,q)j|1 ‚â§j ‚â§M}which con-\ntains M predicted (column-question token) tuples.\nWe deÔ¨Åne the precision( ColP ), recall(ColR), F1-\nscore(ColF ) as:\n|Œìcol|‚èê‚èê‚Ñ¶col\n‚èê‚èê,|Œìcol|\n|‚Ñ¶col|, 2ColP ColR\nColP + ColR\nwhere Œìcol = ‚Ñ¶col\n‚ãÇ‚Ñ¶col. The deÔ¨Ånitions of TabP ,\nTabR, TabF are similar. Note that the result re-\nported in Table 8 of Shi et al. (2020) use a different\nevaluation metrics. Here we re-evaluate their model\nby the above mentioned metrics for fair compari-\nson.\nA.2 Entity Linking\nLet ‚Ñ¶ = {(e,[qs,qe])i|1 ‚â§i ‚â§N}be the gold\nentity-mention set and ‚Ñ¶ = {(e,[qs,qe])j|1 ‚â§j ‚â§\nM}be the predicted entity-mention set, where e\nis the entity, qe,qs are the mention boundaries in\nthe question q. In the weak matching setting, a\nprediction is correct only if the ground-truth entity\nis identiÔ¨Åed and the predicted mention boundaries\noverlap with the ground-truth boundaries. There-\nfore, the True-Positive prediction set is deÔ¨Åned as:\nŒì = {e|(e,[qs,qe]) ‚àà‚Ñ¶,(e,[qs,qe]) ‚àà‚Ñ¶,\n[qs,qe]\n‚ãÇ\n[qs,qe] Ã∏= ‚àÖ}.\nThe corresponding precision( EntP ), recall(EntR)\nand F1(EntF ) are:\n|Œì|‚èê‚èê‚Ñ¶\n‚èê‚èê,|Œì|\n|‚Ñ¶|, 2EntP EntR\nEntP + EntR\nB Dataset Statistic\nAll details of datasets used in this paper are shown\nin Table 7.\nC Implementation Details\nFor all experiments, we employ the AdamW opti-\nmizer and the default learning rate schedule strat-\negy provided by Transformers library (Wolf et al.,\n2020).\nC.1 Experiments on Grounding\nSQUALL We use uncased BERT-base as the en-\ncoder. The learning rate is 3 √ó10‚àí5. The training\nepoch is 50 with a batch size of 16. The dropout\nrate and the threshold œÑ are set to 0.3 and 0.2 re-\nspectively. The training process lasts 6 hours on a\nsingle 16GB Tesla P100 GPU.\nSPIDER -L We implement two versions: uncased\nBERT-base and uncased BERT-large. For both ver-\nsions, the learning rate is 5 √ó10‚àí5 and the training\nepoch is 50. For BERT-base (BERT-large) version,\nthe batch size and gradient accumulation step are\nset to 12 (6) and 6 (4). The dropout rate and the\nthreshold œÑ are set to 0.3 and 0.2 respectively. As\nfor training time, BERT-base (BERT-large) version\nis trained on a 24GB Tesla P40 and it takes about\n16 (48) hours to Ô¨Ånish the training process.\nWebQSPEL& GraphQ EL Due to the large\namount of entity candidates, we Ô¨Årst use the can-\ndidate retrieval method proposed in (Sorokin and\nGurevych, 2018) to reduce the number of candi-\ndates. After that, we still can not feed all candidates\nalong with the question due to the maximum encod-\ning length of BERT. Therefore, we divide the can-\ndidates into multiple chunks and feed each chunk\n(along with the question) into BERT sequentially.\nIn implementation, we use uncased BERT-base\nas the encoder. The learning rate is 1 √ó10‚àí5 The\ntraining epoch is 50 with a batch size of 16. The\ndropout rate and the threshold œÑ are set to 0.3 and\n0.3 respectively. The training procedure Ô¨Ånishes\nwithin 10 hours on a single Tesla M40 GPU.\nC.2 Experiments on Text-to-SQL\nFor experiments of the text-to-SQL task, we em-\nploy the ofÔ¨Åcial code released along with Shi et al.\n(2020) (on WTQ) and Lei et al. (2020) (on Spi-\nder). When coupling ETA with these models, we\nÔ¨Årst produce a one-hot grounding matrix derived\nby grounding pairs and then feed it into them as\ndescribed in ¬ß4.\nWTQ We use uncased BERT-base as the encoder.\nThe training epoch is 50 with a batch size of 8. The\nlearning rate is 1 √ó10‚àí5 for the BERT module and\n1 √ó10‚àí3 for other modules. The dropout rate is\nset to 0.2. The training process Ô¨Ånishes within 16\nhours on a single 16GB Tesla P100 GPU.\nMeanwhile, we follow the previous work (Shi\net al., 2020) to employ 5-fold cross-validation, and\n1188\nDataset Train Dev Test\n#Q #C #Q #C #Q #C\nSQUALL 9,030 19 ,185 2 ,246 4 ,774 ‚Äì ‚Äì\nSPIDER -L 7,000 28 ,848 1 ,034 4 ,360 ‚Äì ‚Äì\nWTQ 9,030 ‚Äì 2,246 ‚Äì 4,344 ‚Äì\nSpider 7,000 ‚Äì 1,034 ‚Äì 2,147 ‚Äì\nWebQSPEL 2,974 3 ,242 ‚Äì ‚Äì 1,603 1 ,806\nGraphQEL 2,089 2 ,253 ‚Äì ‚Äì 2,075 2 ,229\nTable 7: Statistics for all datasets used in our experiments. For S QUALL and WTQ, we only show the size of\nSplit-0, and details of other splits can be found in Table 8. #Q represents the number of questions, #C represents\nthe number of concepts.\nSplit Train Dev\n0 9 ,030 2 ,246\n1 9 ,032 2 ,244\n2 9 ,028 2 ,248\n3 8 ,945 2 ,331\n4 9 ,069 2 ,207\nTable 8: The size of train set and dev set of Ô¨Åve splits\non SQUALL and WTQ.\nSplit Dev Test\nEx.Match Ex.Acc Ex.Acc\n0 45 .10 64 .43 53 .57\n1 47 .39 67 .01 54 .17\n2 47 .24 65 .93 53 .61\n3 45 .99 65 .72 53 .41\n4 52 .38 69 .73 52 .41\nTable 9: The experimental results of all splits on WTQ.\nexperimental results of all Ô¨Åve splits on WTQ using\nETA + BERT are shown in Table 9.\nSpider We implement two versions: uncased\nBERT-base and uncased BERT-large. For BERT-\nbase (BERT-large), the learning rate is1.25√ó10‚àí5\n(6.25 √ó10‚àí6) for the BERT module and 1 √ó10‚àí4\n(5 √ó10‚àí5) for other modules. The batch size and\ngradient accumulation step are set to 10 (6) and\n5 (4) for BERT-base (BERT-large) version. The\ndropout rate is set to 0.3. As for training time,\nBERT-base (BERT-large) version is trained on a\n24GB Tesla P40 and it takes about36 (56) hours to\nÔ¨Ånish the training process.\nD Latent Grounding Visualization\nFigure 6 and Figure 7 show the latent grounding\nvisualization corresponding to examples in Table 6.\n1189\nshowname\n,\ncountry\n, age for all\nsingersordered\nby age from the oldest\nto the\nyoungest\n.\nsinger\nsinger.name\nsinger.country\nsinger.age\n0.00 0.01 0.00 0.02 0.00 0.00 0.00 0.00 0.97 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n0.01 0.37 0.05 0.19 0.00 0.00 0.00 0.00 0.36 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n0.00 0.02 0.04 0.89 0.00 0.01 0.00 0.00 0.03 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n0.00 0.00 0.00 0.00 0.00 0.31 0.00 0.00 0.01 0.00 0.00 0.35 0.00 0.00 0.22 0.00 0.00 0.10 0.00\nFigure 6: The latent grounding produced by E TA + BERTL for the question ‚Äú Show name, country, age for all\nsingers ordered by age from the oldest to the youngest.‚Äù.\nfor each\nsemester\n,\nwhat\nis the nameand id of the one with the most\nstudentsregistered\n?\nsemesters\nstudent enrolment\nsemesters.semester id\nsemesters.semester name\n0.00 0.00 0.88 0.00 0.00 0.00 0.00 0.05 0.01 0.02 0.00 0.00 0.01 0.00 0.00 0.00 0.01 0.01 0.00\n0.00 0.00 0.04 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.07 0.87 0.00\n0.01 0.02 0.39 0.01 0.01 0.01 0.01 0.05 0.06 0.30 0.02 0.02 0.05 0.01 0.00 0.00 0.01 0.03 0.00\n0.00 0.01 0.73 0.00 0.00 0.00 0.01 0.14 0.02 0.05 0.00 0.01 0.01 0.00 0.00 0.00 0.00 0.00 0.00\nFigure 7: The latent grounding produced by E TA + BERTL for the question ‚ÄúFor each semester, what is the name\nand id of the one with the most students registered?‚Äù."
}