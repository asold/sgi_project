{
  "title": "Improving Zero-Shot Cross-Lingual Hate Speech Detection with Pseudo-Label Fine-Tuning of Transformer Language Models",
  "url": "https://openalex.org/W4312527798",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2782137510",
      "name": "Haris Bin Zia",
      "affiliations": [
        "Queen Mary University of London"
      ]
    },
    {
      "id": "https://openalex.org/A2100258248",
      "name": "Ignacio Castro",
      "affiliations": [
        "Queen Mary University of London"
      ]
    },
    {
      "id": "https://openalex.org/A2045838850",
      "name": "Arkaitz Zubiaga",
      "affiliations": [
        "Queen Mary University of London"
      ]
    },
    {
      "id": "https://openalex.org/A2097861471",
      "name": "Gareth Tyson",
      "affiliations": [
        "Queen Mary University of London"
      ]
    },
    {
      "id": "https://openalex.org/A2782137510",
      "name": "Haris Bin Zia",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2905749056",
    "https://openalex.org/W3155025376",
    "https://openalex.org/W3032882625",
    "https://openalex.org/W2595653137",
    "https://openalex.org/W2906979176",
    "https://openalex.org/W3115397159",
    "https://openalex.org/W2889438178",
    "https://openalex.org/W6754527574",
    "https://openalex.org/W3189422672",
    "https://openalex.org/W3124917515",
    "https://openalex.org/W3140418309",
    "https://openalex.org/W2781310980",
    "https://openalex.org/W3174882277",
    "https://openalex.org/W3135855479",
    "https://openalex.org/W3197986154",
    "https://openalex.org/W2952629768",
    "https://openalex.org/W3155638757",
    "https://openalex.org/W3091315987",
    "https://openalex.org/W2990188683",
    "https://openalex.org/W6695661434",
    "https://openalex.org/W2805551365",
    "https://openalex.org/W2740168486",
    "https://openalex.org/W3014487746",
    "https://openalex.org/W2473555522",
    "https://openalex.org/W3013027210",
    "https://openalex.org/W6763483474",
    "https://openalex.org/W2916719435",
    "https://openalex.org/W2887782043",
    "https://openalex.org/W2973088264",
    "https://openalex.org/W3023443524",
    "https://openalex.org/W3115903740",
    "https://openalex.org/W4299574851",
    "https://openalex.org/W3114950584",
    "https://openalex.org/W3185293939",
    "https://openalex.org/W2954226438",
    "https://openalex.org/W3035390927",
    "https://openalex.org/W2949089361",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W2516809705",
    "https://openalex.org/W3008110149",
    "https://openalex.org/W3180918883",
    "https://openalex.org/W2962977603"
  ],
  "abstract": "Hate speech has proliferated on social media platforms in recent years. While this has been the focus of many studies, most works have exclusively focused on a single language, generally English. Low-resourced languages have been neglected due to the dearth of labeled resources. These languages, however, represent an important portion of the data due to the multilingual nature of social media. This work presents a novel zero-shot, cross-lingual transfer learning pipeline based on pseudo-label fine-tuning of Transformer Language Models for automatic hate speech detection. We employ our pipeline on benchmark datasets covering English (source) and 6 different non-English (target) languages written in 3 different scripts. Our pipeline achieves an average improvement of 7.6% (in terms of macro-F1) over previous zero-shot, cross-lingual models. This demonstrates the feasibility of high accuracy automatic hate speech detection for low-resource languages. We release our code and models at https://github.com/harisbinzia/ZeroshotCrosslingualHateSpeech.",
  "full_text": "Improving Zero-Shot Cross-Lingual Hate Speech Detection with Pseudo-Label\nFine-Tuning of Transformer Language Models\nHaris Bin Zia, Ignacio Castro, Arkaitz Zubiaga, Gareth Tyson\nQueen Mary University of London\nh.b.zia@qmul.ac.uk, i.castro@qmul.ac.uk, a.zubiaga@qmul.ac.uk, g.tyson@qmul.ac.uk\nAbstract\nHate speech has proliferated on social media platforms in\nrecent years. While this has been the focus of many stud-\nies, most works have exclusively focused on a single lan-\nguage, generally English. Low-resourced languages have\nbeen neglected due to the dearth of labeled resources. These\nlanguages, however, represent an important portion of the\ndata due to the multilingual nature of social media. This\nwork presents a novel zero-shot, cross-lingual transfer learn-\ning pipeline based on pseudo-label fine-tuning of Trans-\nformer Language Models for automatic hate speech detec-\ntion. We employ our pipeline on benchmark datasets cov-\nering English (source) and 6 different non-English (tar-\nget) languages written in 3 different scripts. Our pipeline\nachieves an average improvement of 7.6% (in terms of\nmacro-F1) over previous zero-shot, cross-lingual models.\nThis demonstrates the feasibility of high accuracy automatic\nhate speech detection for low-resource languages. We re-\nlease our code and models at https://github.com/harisbinzia/\nZeroshotCrosslingualHateSpeech.\nIntroduction\nDespite its benefits, social media has also been used to dis-\nseminate hateful material at an unprecedented scale (M¨uller\nand Schwarz 2018). The sheer volume of hateful content\nposes a challenge for timely and effective human modera-\ntion. Hence, automatic hate speech detection has received\nsignificant attention from the Natural Language Processing\n(NLP) research community (Schmidt and Wiegand 2017).\nStill, much of this research focuses on a single language,\ngenerally English (Fortuna and Nunes 2018; Poletto et al.\n2020; Vidgen and Derczynski 2020), and lesser-resourced\nlanguages have been rarely studied. To tackle this limitation,\nwe study zero-shot, cross-lingual transfer learning (Artetxe\nand Schwenk 2019) i.e. training on a high-resource (source)\nlanguage and testing on a low-resource (target) language.\nExisting methods for zero-shot, cross-lingual hate speech\ndetection leverage language-agnostic sentence representa-\ntions to embed training data in the high-resource language\n(mostly English) or multilingual transformer language mod-\nels fine-tuned on a high-resource language (again mostly En-\nglish) (Pelicon et al. 2021). However, recent research sug-\ngests that these methods struggle with taboo interjections in\nCopyright © 2022, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\nthe target language (Nozza 2021), i.e. common language-\nspecific hateful expressions e.g. puta (meaning bitch) in\nSpanish. Since English does not necessarily use equiva-\nlent words in the same way, zero-shot, cross-lingual mod-\nels trained/ fine-tuned on English fail to capture the context\nof these expressions. Consequently, they consider them hate\nspeech regardless of their use in context. To address this\nlimitation, we propose a novel pipeline based on pseudo-\nlabel fine-tuning of transformer language models for zero-\nshot, cross-lingual hate speech detection. We experiment\nwith benchmark datasets in 6 languages written in 3 differ-\nent scripts, outperforming previous zero-shot, cross-lingual\nresults, with preliminary proof of improvement on taboo ex-\npressions. Our contributions include:\n1. We propose a novel model to use pseudo-labeled in-\ndomain data in the target language, in addition to gold-\nlabeled data in English to fine-tune transformer language\nmodels for zero-shot, cross-lingual hate speech detection.\n2. Our method consistently outperforms the previous state-\nof-the-art zero-shot, cross-lingual models and improves\nthe comprehension of taboo interjections by 11.1% (av-\nerage macro-F1 improvement over different datasets).\nRelated Work\nThe vast majority of research in hate speech detection is\nmonolingual, with English being the most prevalent lan-\nguage due to the availability of resources (Waseem and\nHovy 2016; Wulczyn, Thain, and Dixon 2017; Davidson\net al. 2017; Zampieri et al. 2019). There has been lim-\nited research on non-English hate speech detection too,\ne.g. for Italian (Sanguinetti et al. 2018), and French (Chiril\net al. 2020). Lately, several shared tasks have helped in-\ncrease the coverage of non-English hate speech datasets,\ne.g. AMIEvalita 2018 (Fersini, Nozza, and Rosso 2018),\nAMIIberEval 2018 (Fersini, Rosso, and Anzovino 2018)\nand AMIEvalita 2020 (Fersini, Nozza, and Rosso 2020).\nThese covered misogyny detection in Italian, Spanish and\nEnglish. GermEval 2018 (Wiegand, Siegel, and Ruppen-\nhofer 2018) explored identification of offensiveness in Ger-\nman tweets, HatEval 2019 (Basile et al. 2019) covered\nhate speech against immigrants and women in Spanish and\nEnglish. HASOC 2019 (Mandl et al. 2019) and HASOC\n2020 (Mandl et al. 2020) introduced resources for hate\nProceedings of the Sixteenth International AAAI Conference on Web and Social Media (ICWSM2022)\n1435\nspeech detection in Hindi, German and English. OffensE-\nval 2020 (Zampieri et al. 2020) featured offensive language\nidentification datasets in Arabic, Danish, Greek, Turkish and\nEnglish. We direct interested readers to relevant surveys for\nfurther information (Schmidt and Wiegand 2017; Fortuna\nand Nunes 2018; Poletto et al. 2020; Vidgen and Derczynski\n2020; Pamungkas, Basile, and Patti 2021b).\nOnly a handful of studies have investigated zero-shot\ncross-lingual transfer learning for hate speech detection.\nBoth Pamungkas and Patti (2019) and Jiang and Zubiaga\n(2021) proposed hybrid approaches with neural models and\na multilingual lexicon to cross-domain and cross-lingual de-\ntection of abusive content. A novel attention-based classi-\nfication block for zero-shot, cross-lingual learning was pro-\nposed by Stappen, Brunn, and Schuller (2020). They demon-\nstrated highly competitive results on the Spanish and English\nsubsets of HatEval 2019 (Basile et al. 2019). Bigoulaeva,\nHangya, and Fraser (2021) used bilingual word embedding-\nbased classifiers to transfer learn hate speech detection for\nGerman from English. Pamungkas, Basile, and Patti (2021a)\nexperimented with traditional and recent neural architec-\ntures, and proposed two joint-learning hate speech detec-\ntion models, using different multilingual language represen-\ntations to transfer knowledge between pairs of languages.\nClosest to our work is Pelicon et al. (2021) and Nozza\n(2021). The former use a multilingual Bidirectional Encoder\nRepresentations from Transformers (mBERT) (Devlin et al.\n2018) and Language Agnostic SEntence Representations\n(LASER) (Artetxe and Schwenk 2019) with multilayer per-\nceptron classifier to generalize hate speech detection from\nEnglish to other languages. In contrast, the latter only fine-\ntuned mBERT on English for hate speech detection and\ndemonstrated that zero-shot, cross-lingual models were not\nable to capture target language specific taboo interjections.\nOur work is different in that we exploit pseudo-labeled in-\ndomain data in target language along with gold-labeled data\nin English to fine-tune transformer language models that\novercome the limitation of taboo expressions highlighted\nby Nozza (2021) and significantly enhances their perfor-\nmance in zero-shot, cross-lingual settings.\nMethodology\nWe propose to use the cross-lingual hate speech classifier\ntrained on high-resource (source) language data as a teacher\nto obtain pseudo-labels for training monolingual hate speech\nmodel on the low-resource (target) language. The pipeline is\nshown in Figure 1 and consists of three main steps:\n1. First, we fine-tune a pre-trained multilingual transformer\nlanguage model on gold-labeled source language data.\nThis gives us our zero-shot, cross-lingual teacher.\n2. Next, we perform inference with the zero-shot, cross-\nlingual teacher on in-domain target language data to pre-\ndict labels. This generates a new psuedo-labeled dataset\nin the target language.\n3. Finally, we use the in-domain target language data and\nits predicted (pseudo) labels to fine-tune a monolingual\ntransformer language model pre-trained on the target lan-\nFigure 1: Our proposed zero-shot, cross-lingual transfer\nlearning pipeline for hate speech detection.\nguage. This gives us our final classifier (zero-shot, mono-\nlingual student).\nOur approach provides two main benefits: (i) it circum-\nvents the need for gold-labels in the target language; (ii) it\nallows the final zero-shot classifier to better capture the hate-\nful expressions (including taboo interjections) in target lan-\nguage.\nExperimental Setup\nDatasets\nWe use English as the source and 6 other target lan-\nguages: Spanish, Italian, German, Arabic, Greek and\nTurkish. We use HatEval 2019 (Basile et al. 2019),\nAMIEvalita 2018 (Fersini, Nozza, and Rosso 2018), Ger-\nmEval 2018 (Wiegand, Siegel, and Ruppenhofer 2018) and\nOffensEval 2020 (Zampieri et al. 2020) datasets (see Ta-\nble 1). To ensure consistency in experiments, we use source\nand target language data pertaining to the same shared task.1\nFor each dataset, we treat the English subset as the source\nlanguage and non-English as target language. We keep the\noriginal splits2 for comparability with previous work.\nPre-trained Language Models\nFor pre-trained language models, we rely on community-\ndriven Hugging Face’s Model Hub. 3 Specifically, we use\nXLM-Rlarge (Conneau et al. 2019) as zero-shot, cross-\nlingual teacher, RoBERTa for Spanish (Guti ´errez-Fandi˜no\net al. 2021) & Greek (Papaevagelou 2021) and BERT for\nItalian (Polignano et al. 2019), German (Chan, Schweter,\nand M¨oller 2020), Arabic (Antoun, Baly, and Hajj 2020) &\nTurkish (Schweter 2020). All models are fine-tuned using\nHugging Face’s Transformers (Wolf et al. 2020) with input\nsequence length of 128, batch size of 32 and learning rate of\n2e-5 for 3 epochs.\n1Except for GermEval 2018 dataset used in combination with\nOffensEval 2020 in line with previous studies.\n2Note: we do not use gold-labels from non-English train and\nvalid splits (so as to ensure zero-shot settings) but use their text to\nobtain pseudo-labels.\n3https://huggingface.co/models\n1436\nDataset Task Labels Lang. Train Valid Test PIR\nHatEval Hate Speech\nDetection\n1 - hateful\n0 - non hateful\nEN\nES\n9000\n4500\n1000\n500\n3000\n1600\n0.42\n0.41\nAMIEvalita Automatic Misogyny\nIdentification\n1 - misogynous\n0 - non misogynous\nEN\nIT\n3600\n3600\n400\n400\n1000\n1000\n0.44\n0.46\nGermEval Offensive Language\nIdentification\n1 - offensive\n0 - non offensive\nDE 4508 501 3532 0.33\nOffensEval Offensive Language\nIdentification\n1 - offensive\n0 - non offensive\nEN\nAR\nEL\nTR\n11916\n7055\n7868\n28149\n1324\n784\n875\n3128\n860\n2000\n1544\n3528\n0.32\n0.19\n0.26\n0.19\nTable 1: Dataset Statistics. PIR is Positive Instance Rate.\nBaselines\nWe compare three strong baselines, following Pelicon et al.\n(2021): (i) Pre-trained XLM-R large fine-tuned only on la-\nbeled data in source (English) language (i.e. our zero-shot,\ncross-lingual teacher); (ii) Logistic Regression trained on\nlanguage agnostic sentence embeddings LASER (Artetxe\nand Schwenk 2019) and LaBSE (Feng et al. 2020) using la-\nbeled data in source (English) language; and (iii) the previ-\nous best zero-shot, cross-lingual results for each dataset.\nResults\nThe results (macro-F1 scores) are given in Table 2. The\npseudo-label fine-tuned model outperforms its teacher in\nall settings. The largest improvement is for OffensEval-\nEL, where the macro-F1 increases from 0.67 to 0.72\n(7.46%). The smallest improvement (2.08%) is observed in\nAMIEvalita-IT. This may be attributed to the uniqueness of\nthe task for which the Italian model was trained (i.e. auto-\nmatic misogyny identification) as language models are less\nlikely to capture such features during pre-training. On aver-\nage, the proposed method achieves 4.5% macro-F1 improve-\nment over its teacher, 20.5% over logistic regression classi-\nfiers and 7.6% over previous state-of-the-art models.\nAnalysis of Taboo Expressions.We next seek to understand\nwhy our approach outperforms prior baselines. Nozza (2021)\ndemonstrated that zero-shot, cross-lingual models fine-tuned\nonly on source (English) language data fail to capture target\nlanguage specific taboo expressions such as puta (meaning\nbitch) in Spanish and porca (meaning slut) in Italian. While\nderogatory for women, these words are often used as inten-\nsifiers in non-hateful contextse.g. hijo de puta(meaning son\nof a bitch) and porca puttana (meaning holy shit).\nFollowing (Nozza 2021), we also analyze the perfor-\nmance of our proposed pseudo-label fine-tuned model on\ntexts containing taboo expressions and compare it with zero-\nshot, cross-lingual teacher that is fine-tuned on English only.\nSpecifically, we examine expressions puta and porca in the\ntest subsets of HatEval-ES and AMIEvalita-IT.4\nFigure 2 shows the LIME (Ribeiro, Singh, and Guestrin\n2016) explanation of an example non-hateful Spanish tweet\n4The reason we restrict our analysis to HatEval-ES and\nAMIEvalita-IT is because remaining datasets are tagged for of-\nfensive language identification task thus any occurrence of taboo\nexpression must be in the positive class irrespective of the context.\nwrongly classified by zero-shot, cross-lingual teacher and\ncorrectly classified by our zero-shot, monolingual student\nmodel. The teacher model gives high hateful importance to\nterm like puta regardless of its context as it considers the lit-\neral meaning of individual words. On the contrary, our pro-\nposed method teach the model thatputa is a taboo expression\nand does not imply hatefulness in this particular context. The\nexplanation also reveal our model’s ability to assign correct\nimportance to non-hateful words e.g. teacher model consid-\ners the wordestudiar (meaning study) as hateful whereas our\nmodel correctly identifies it as non-hateful.\nFigure 2: LIME explanations of predictions of a non-hateful\nSpanish tweet by (a) zero-shot, cross-lingual teacher and (b)\nzero-shot, monolingual student. English translation: “shut\nup and study son of a bitch”.\nTo further exemplify this finding, in Table 3 we report the\nmacro-F1 of zero-shot, monolingual student and its teacher\nin predicting the labels of tweets containing taboo expres-\nsions puta and porca in the test subsets of HatEval-ES and\nAMIEvalita-IT respectively. On average, the student model\nincreases the macro-F1 by 11.1%. These numbers show that\nour proposed method understands these general exclama-\ntions with much better accuracy and thus limits the number\n1437\nDataset Previous zero-shot,\ncross-lingual results\nEmbeddings Zero-shot,\ncross-lingual\nteacher\nZero-shot,\nmonolingual\nstudentLaBSE LASER\nHatEval-ES 0.65 (Nozza 2021) 0.63 0.67 0.70 0.73\nAMIEvalita-IT 0.48 (Pamungkas and Patti 2019) 0.47 0.32 0.48 0.49\nGermEval-DE 0.70 (Pelicon et al. 2021) 0.64 0.64 0.72 0.76\nOffensEval-AR - 0.68 0.70 0.77 0.81\nOffensEval-EL - 0.58 0.56 0.67 0.72\nOffensEval-TR - 0.62 0.58 0.70 0.72\nTable 2: Experiment results (macro-F1) for all proposed and baseline models.\nTerm Frequency Zero-shot\nteacher\nZero-shot\nstudent\nputa 565 (35.3%) 0.68 0.75\nporca 306 (30.6%) 0.25 0.28\nTable 3: Macro-F1 on tweets with taboo expressions.\nof false positives.\nConclusion & Future Work\nThis paper proposes a novel pipeline based on pseudo-\nlabel fine-tuning of transformer language models for zero-\nshot, cross-lingual hate speech detection. Experimenting on\nbenchmark datasets containing English and 6 different non-\nEnglish languages, our approach not only outperforms pre-\nvious zero-shot, cross-lingual models but also overcomes\ntheir limitation by improving detection of taboo expressions.\nAs part of future steps, we plan to expand our work to\nother low-resource languages such as Urdu, Indonesian etc.,\nas well as other task types such as toxicity and racism de-\ntection. We would also like to analyze the performance of\nrecently released larger multilingual transformer language\nmodels XLM-RXL and XLM-RXXL (Goyal et al. 2021) as\na zero-shot, cross-lingual teacher. Finally, we plan to investi-\ngate the primacy of English as source language in zero-shot,\ncross-lingual hate speech detection.\nReferences\nAntoun, W.; Baly, F.; and Hajj, H. 2020. Arabert:\nTransformer-based model for arabic language understand-\ning. arXiv preprint arXiv:2003.00104.\nArtetxe, M.; and Schwenk, H. 2019. Massively multilin-\ngual sentence embeddings for zero-shot cross-lingual trans-\nfer and beyond. Transactions of the Association for Compu-\ntational Linguistics, 7: 597–610.\nBasile, V .; Bosco, C.; Fersini, E.; Debora, N.; Patti, V .;\nPardo, F. M. R.; Rosso, P.; Sanguinetti, M.; et al. 2019.\nSemeval-2019 task 5: Multilingual detection of hate speech\nagainst immigrants and women in twitter. In 13th Interna-\ntional Workshop on Semantic Evaluation, 54–63. Associa-\ntion for Computational Linguistics.\nBigoulaeva, I.; Hangya, V .; and Fraser, A. 2021. Cross-\nLingual Transfer Learning for Hate Speech Detection. In\nProceedings of the First Workshop on Language Technology\nfor Equality, Diversity and Inclusion, 15–25.\nChan, B.; Schweter, S.; and M¨oller, T. 2020. German’s Next\nLanguage Model. arXiv preprint arXiv:2010.10906.\nChiril, P.; Moriceau, V .; Benamara, F.; Mari, A.; Origgi,\nG.; and Coulomb-Gully, M. 2020. An annotated corpus\nfor sexism detection in French tweets. In Proceedings of\nThe 12th Language Resources and Evaluation Conference ,\n1397–1403.\nConneau, A.; Khandelwal, K.; Goyal, N.; Chaudhary, V .;\nWenzek, G.; Guzm ´an, F.; Grave, E.; Ott, M.; Zettle-\nmoyer, L.; and Stoyanov, V . 2019. Unsupervised cross-\nlingual representation learning at scale. arXiv preprint\narXiv:1911.02116.\nDavidson, T.; Warmsley, D.; Macy, M.; and Weber, I. 2017.\nAutomated hate speech detection and the problem of offen-\nsive language. In Proceedings of the International AAAI\nConference on Web and Social Media.\nDevlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2018.\nBert: Pre-training of deep bidirectional transformers for lan-\nguage understanding. arXiv preprint arXiv:1810.04805.\nFeng, F.; Yang, Y .; Cer, D.; Arivazhagan, N.; and Wang, W.\n2020. Language-agnostic bert sentence embedding. arXiv\npreprint arXiv:2007.01852.\nFersini, E.; Nozza, D.; and Rosso, P. 2018. Overview of\nthe evalita 2018 task on automatic misogyny identification\n(ami). EVALITA Evaluation of NLP and Speech Tools for\nItalian, 12: 59.\nFersini, E.; Nozza, D.; and Rosso, P. 2020. AMI@\nEV ALITA2020: Automatic Misogyny Identification. In\nEVALITA.\nFersini, E.; Rosso, P.; and Anzovino, M. 2018. Overview of\nthe Task on Automatic Misogyny Identification at IberEval\n2018. IberEval@ SEPLN, 2150: 214–228.\nFortuna, P.; and Nunes, S. 2018. A survey on automatic\ndetection of hate speech in text. ACM Computing Surveys\n(CSUR), 51(4): 1–30.\nGoyal, N.; Du, J.; Ott, M.; Anantharaman, G.; and Con-\nneau, A. 2021. Larger-Scale Transformers for Mul-\ntilingual Masked Language Modeling. arXiv preprint\narXiv:2105.00572.\nGuti´errez-Fandi˜no, A.; Armengol-Estap ´e, J.; P `amies, M.;\nLlop-Palao, J.; Silveira-Ocampo, J.; Carrino, C. P.;\n1438\nGonzalez-Agirre, A.; Armentano-Oller, C.; Rodriguez-\nPenagos, C.; and Villegas, M. 2021. Spanish language mod-\nels. arXiv preprint arXiv:2107.07253.\nJiang, A.; and Zubiaga, A. 2021. Cross-lingual Capsule Net-\nwork for Hate Speech Detection in Social Media. In Pro-\nceedings of the 32nd ACM Conference on Hypertext and So-\ncial Media, 217–223.\nMandl, T.; Modha, S.; Kumar M, A.; and Chakravarthi, B. R.\n2020. Overview of the hasoc track at fire 2020: Hate speech\nand offensive language identification in tamil, malayalam,\nhindi, english and german. In Forum for Information Re-\ntrieval Evaluation, 29–32.\nMandl, T.; Modha, S.; Majumder, P.; Patel, D.; Dave, M.;\nMandlia, C.; and Patel, A. 2019. Overview of the hasoc\ntrack at fire 2019: Hate speech and offensive content identi-\nfication in indo-european languages. In Proceedings of the\n11th forum for information retrieval evaluation, 14–17.\nM¨uller, K.; and Schwarz, C. 2018. Fanning the flames of\nhate: Social media and hate crime. Journal of the European\nEconomic Association.\nNozza, D. 2021. Exposing the limits of Zero-shot Cross-\nlingual Hate Speech Detection. In Proceedings of the 59th\nAnnual Meeting of the Association for Computational Lin-\nguistics. Online: Association for Computational Linguistics.\nPamungkas, E. W.; Basile, V .; and Patti, V . 2021a. A joint\nlearning approach with knowledge injection for zero-shot\ncross-lingual hate speech detection. Information Processing\n& Management, 58(4): 102544.\nPamungkas, E. W.; Basile, V .; and Patti, V . 2021b. Towards\nmultidomain and multilingual abusive language detection: a\nsurvey. Personal and Ubiquitous Computing, 1–27.\nPamungkas, E. W.; and Patti, V . 2019. Cross-domain and\ncross-lingual abusive language detection: A hybrid approach\nwith deep learning and a multilingual lexicon. In Proceed-\nings of the 57th annual meeting of the association for com-\nputational linguistics: Student research workshop, 363–370.\nPapaevagelou, D. 2021. Greek RoBERTa. https://\nhuggingface.co/cvcio/roberta-el-uncased-twitter-v1. Ac-\ncessed: 2022-04-24.\nPelicon, A.; Shekhar, R.; Martinc, M.; ˇSkrlj, B.; Purver, M.;\nand Pollak, S. 2021. Zero-shot Cross-lingual Content Fil-\ntering: Offensive Language and Hate Speech Detection. In\nProceedings of the EACL Hackashop on News Media Con-\ntent Analysis and Automated Report Generation, 30–34. On-\nline: Association for Computational Linguistics.\nPoletto, F.; Basile, V .; Sanguinetti, M.; Bosco, C.; and Patti,\nV . 2020. Resources and benchmark corpora for hate speech\ndetection: a systematic review. Language Resources and\nEvaluation, 1–47.\nPolignano, M.; Basile, P.; De Gemmis, M.; Semeraro, G.;\nand Basile, V . 2019. Alberto: Italian BERT language under-\nstanding model for NLP challenging tasks based on tweets.\nIn 6th Italian Conference on Computational Linguistics,\nCLiC-it 2019, volume 2481, 1–6. CEUR.\nRibeiro, M. T.; Singh, S.; and Guestrin, C. 2016. ” Why\nshould i trust you?” Explaining the predictions of any clas-\nsifier. In Proceedings of the 22nd ACM SIGKDD interna-\ntional conference on knowledge discovery and data mining,\n1135–1144.\nSanguinetti, M.; Poletto, F.; Bosco, C.; Patti, V .; and\nStranisci, M. 2018. An italian twitter corpus of hate speech\nagainst immigrants. In Proceedings of the Eleventh Interna-\ntional Conference on Language Resources and Evaluation\n(LREC 2018).\nSchmidt, A.; and Wiegand, M. 2017. A survey on hate\nspeech detection using natural language processing. In Pro-\nceedings of the fifth international workshop on natural lan-\nguage processing for social media, 1–10.\nSchweter, S. 2020. BERTurk. https://huggingface.co/\ndbmdz/bert-base-turkish-128k-uncased. Accessed: 2022-\n04-24.\nStappen, L.; Brunn, F.; and Schuller, B. 2020. Cross-lingual\nzero-and few-shot hate speech detection utilising frozen\ntransformer language models and AXEL. arXiv preprint\narXiv:2004.13850.\nVidgen, B.; and Derczynski, L. 2020. Directions in abu-\nsive language training data, a systematic review: Garbage\nin, garbage out. PloS one, 15(12): e0243300.\nWaseem, Z.; and Hovy, D. 2016. Hateful symbols or hate-\nful people? predictive features for hate speech detection on\ntwitter. In Proceedings of the NAACL student research work-\nshop, 88–93.\nWiegand, M.; Siegel, M.; and Ruppenhofer, J. 2018.\nOverview of the germeval 2018 shared task on the identi-\nfication of offensive language. Overview of the germeval\n2018 shared task on the identification of offensive language.\nWolf, T.; Chaumond, J.; Debut, L.; Sanh, V .; Delangue, C.;\nMoi, A.; Cistac, P.; Funtowicz, M.; Davison, J.; Shleifer, S.;\net al. 2020. Transformers: State-of-the-art natural language\nprocessing. In Proceedings of the 2020 Conference on Em-\npirical Methods in Natural Language Processing: System\nDemonstrations, 38–45.\nWulczyn, E.; Thain, N.; and Dixon, L. 2017. Ex machina:\nPersonal attacks seen at scale. In Proceedings of the 26th\ninternational conference on world wide web, 1391–1399.\nZampieri, M.; Malmasi, S.; Nakov, P.; Rosenthal, S.; Farra,\nN.; and Kumar, R. 2019. Predicting the Type and Target of\nOffensive Posts in Social Media. In Proceedings of NAACL.\nZampieri, M.; Nakov, P.; Rosenthal, S.; Atanasova, P.;\nKaradzhov, G.; Mubarak, H.; Derczynski, L.; Pitenis, Z.; and\nC ¸¨oltekin, c. 2020. SemEval-2020 Task 12: Multilingual Of-\nfensive Language Identification in Social Media (OffensEval\n2020). In Proceedings of SemEval.\n1439",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7970744371414185
    },
    {
      "name": "Transformer",
      "score": 0.7243937849998474
    },
    {
      "name": "Scripting language",
      "score": 0.6536547541618347
    },
    {
      "name": "Pipeline (software)",
      "score": 0.5597375631332397
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5308985114097595
    },
    {
      "name": "Natural language processing",
      "score": 0.5296247601509094
    },
    {
      "name": "Focus (optics)",
      "score": 0.5215592384338379
    },
    {
      "name": "Speech recognition",
      "score": 0.4287784993648529
    },
    {
      "name": "Macro",
      "score": 0.42826375365257263
    },
    {
      "name": "Social media",
      "score": 0.4193089008331299
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.4114648699760437
    },
    {
      "name": "Programming language",
      "score": 0.09180134534835815
    },
    {
      "name": "World Wide Web",
      "score": 0.0868491530418396
    },
    {
      "name": "Geodesy",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Optics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Geography",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I166337079",
      "name": "Queen Mary University of London",
      "country": "GB"
    }
  ],
  "cited_by": 20
}