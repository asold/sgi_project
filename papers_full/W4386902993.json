{
    "title": "Extracting structured seed-mediated gold nanorod growth procedures from scientific text with LLMs",
    "url": "https://openalex.org/W4386902993",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A1982222761",
            "name": "Nicholas Walker",
            "affiliations": [
                "Lawrence Berkeley National Laboratory"
            ]
        },
        {
            "id": "https://openalex.org/A2124393352",
            "name": "Sang-Hoon Lee",
            "affiliations": [
                "Lawrence Berkeley National Laboratory",
                "University of California, Berkeley"
            ]
        },
        {
            "id": "https://openalex.org/A2546941172",
            "name": "John Dagdelen",
            "affiliations": [
                "University of California, Berkeley",
                "Lawrence Berkeley National Laboratory"
            ]
        },
        {
            "id": "https://openalex.org/A3112057972",
            "name": "Kevin Cruse",
            "affiliations": [
                "University of California, Berkeley",
                "Lawrence Berkeley National Laboratory"
            ]
        },
        {
            "id": "https://openalex.org/A2427292961",
            "name": "Samuel Gleason",
            "affiliations": [
                "University of California, Berkeley",
                "Lawrence Berkeley National Laboratory"
            ]
        },
        {
            "id": "https://openalex.org/A2096959900",
            "name": "Alexander Dunn",
            "affiliations": [
                "Lawrence Berkeley National Laboratory",
                "University of California, Berkeley"
            ]
        },
        {
            "id": "https://openalex.org/A1970654099",
            "name": "Gerbrand Ceder",
            "affiliations": [
                "University of California, Berkeley",
                "Lawrence Berkeley National Laboratory"
            ]
        },
        {
            "id": "https://openalex.org/A2048996377",
            "name": "A. Paul Alivisatos",
            "affiliations": [
                "University of California, Berkeley",
                "Kavli Energy NanoScience Institute",
                "Lawrence Berkeley National Laboratory"
            ]
        },
        {
            "id": "https://openalex.org/A2133845934",
            "name": "Kristin A. Persson",
            "affiliations": [
                "Kavli Energy NanoScience Institute",
                "University of California, Berkeley",
                "Lawrence Berkeley National Laboratory"
            ]
        },
        {
            "id": "https://openalex.org/A2333800602",
            "name": "Anubhav Jain",
            "affiliations": [
                "Lawrence Berkeley National Laboratory"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W6818113687",
        "https://openalex.org/W4292566469",
        "https://openalex.org/W2781823357",
        "https://openalex.org/W2333578679",
        "https://openalex.org/W2560348876",
        "https://openalex.org/W2062504376",
        "https://openalex.org/W1995734581",
        "https://openalex.org/W1999364829",
        "https://openalex.org/W2151399844",
        "https://openalex.org/W2052934350",
        "https://openalex.org/W3002708158",
        "https://openalex.org/W1851687338",
        "https://openalex.org/W4214955825",
        "https://openalex.org/W2077863403",
        "https://openalex.org/W2765658424",
        "https://openalex.org/W2981077120",
        "https://openalex.org/W2024412447",
        "https://openalex.org/W2947875091",
        "https://openalex.org/W2809619304",
        "https://openalex.org/W2327403201",
        "https://openalex.org/W4243760125",
        "https://openalex.org/W2080712991",
        "https://openalex.org/W2781547419",
        "https://openalex.org/W2623026738",
        "https://openalex.org/W2020916955",
        "https://openalex.org/W3127365350",
        "https://openalex.org/W2980932864",
        "https://openalex.org/W2166468803",
        "https://openalex.org/W2904867915",
        "https://openalex.org/W2945095420",
        "https://openalex.org/W2991567677",
        "https://openalex.org/W3166508187",
        "https://openalex.org/W2964864162",
        "https://openalex.org/W3036481679",
        "https://openalex.org/W3045594475",
        "https://openalex.org/W3115677442",
        "https://openalex.org/W1821430800",
        "https://openalex.org/W2065832194",
        "https://openalex.org/W2127239015",
        "https://openalex.org/W2610394652",
        "https://openalex.org/W2101553882",
        "https://openalex.org/W2149369282",
        "https://openalex.org/W2169491861",
        "https://openalex.org/W2800079696",
        "https://openalex.org/W2044085028",
        "https://openalex.org/W4224442790",
        "https://openalex.org/W4319996831",
        "https://openalex.org/W2788500979",
        "https://openalex.org/W2000009216",
        "https://openalex.org/W3127425306",
        "https://openalex.org/W3165475162",
        "https://openalex.org/W3026511954",
        "https://openalex.org/W4281559792",
        "https://openalex.org/W3215319246",
        "https://openalex.org/W6977617475",
        "https://openalex.org/W2031768387",
        "https://openalex.org/W2383957696",
        "https://openalex.org/W1977284464",
        "https://openalex.org/W1964564038",
        "https://openalex.org/W2152701363",
        "https://openalex.org/W2322811648",
        "https://openalex.org/W2044597029",
        "https://openalex.org/W2488834605",
        "https://openalex.org/W3138960112",
        "https://openalex.org/W6902053678",
        "https://openalex.org/W2043701535",
        "https://openalex.org/W4311409687",
        "https://openalex.org/W3168867926",
        "https://openalex.org/W4388979610",
        "https://openalex.org/W4365597205",
        "https://openalex.org/W2130942839",
        "https://openalex.org/W4365211638",
        "https://openalex.org/W4256293432",
        "https://openalex.org/W4322718191",
        "https://openalex.org/W4384918448",
        "https://openalex.org/W2944997455",
        "https://openalex.org/W2981040094"
    ],
    "abstract": "The synthesis of gold nanorods remains largely heuristically understood. Large language models provide a route for extracting their structured synthesis procedures from scientific articles to accelerate investigation into synthesis pathways.",
    "full_text": "Extracting structured seed-mediated gold nanorod\ngrowth procedures from scientiﬁc text with LLMs†\nNicholas Walker, *a Sanghoon Lee,ad John Dagdelen,ad Kevin Cruse,bd\nSamuel Gleason,ae Alexander Dunn, ad Gerbrand Ceder,bd A. Paul Alivisatos,bdef\nKristin A. Persson cdf and Anubhav Jain*a\nAlthough gold nanorods have been the subject of much research, the pathways for controlling their shape\nand thereby their optical properties remain largely heuristically understood. Although it is apparent that the\nsimultaneous presence of and interaction between various reagents during synthesis control these\nproperties, computational and experimental approaches for exploring the synthesis space can be either\nintractable or too time-consuming in practice. This motivates an alternative approach leveraging the\nwealth of synthesis information already embedded in the body of scientiﬁc literature by developing tools\nto extract relevant structured data in an automated, high-throughput manner. To that end, we present\nan approach using the powerful GPT-3 language model to extract structured multi-step seed-mediated\ngrowth procedures and outcomes for gold nanorods from unstructured scientiﬁc text. GPT-3 prompt\ncompletions are ﬁne-tuned to predict synthesis templates in the form of JSON documents from\nunstructured text input with an overall accuracy of 86% aggregated by entities and 76% aggregated by\npapers. The performance is notable, considering the model is performing simultaneous entity\nrecognition and relation extraction. We present a dataset of 11 644 entities extracted from 1137 papers,\nresulting in 268 papers with at least one complete seed-mediated gold nanorod growth procedure and\noutcome for a total of 332 complete procedures.\n1 Introduction\nGold nanoparticles have been synthesized for centuries due to\ntheir interesting optical properties, dating back to the Lycurgus\nCup from 4th century Rome,\n1 as well as imperial bowls and\ndecorated dishes from the Qing dynasty.2 However, scientic\ninterest did not develop until the work of Michael Faraday in the\nmid-19th century, when he accidentally synthesized colloidal\ngold while investigating the interaction between light and\nmatter.\n3 In the last three decades, chemists have developed the\nability to synthesize anisotropic metal nanoparticles in\na controllable and reproducible fashion.\n4 Around the turn of the\nmillennium, multi-step seed-mediated growth methods were\ndeveloped to prepare gold nanorods with aspect ratios ranging\nfrom 8 to 20.4–6 This generated a great deal of interest in\nanisotropic gold nanoparticles due to a combination of the\nconvenience of the wet-chemistry approach, as well as the\nability to tune the shape of the synthesized nanorods. The\nanisotropic gold nanoparticles, in turn, provide access to shape-\ndependent optical phenomena not observed with spherical gold\nnanoparticles.\n7–10 Their applications are widespread across\nmany domains, including semiconductor technology, 11,12\nbiomedicine,13,14 and cosmetics.15 The suitability of a nano-\nparticle for a particular application depends on its morphology\nand size, which correspond to di ﬀerent plasmonic\nproperties.\n16–18\nDespite the popularity of anisotropic gold nanoparticles,\nsystematic investigation of the control of these properties has\nonly recently been approached.\n19 Although some theories and\nmodels do exist for identifying and explaining the mechanisms\nof synthesis that determine nanoparticle morphology, 4,20–22\nmost synthesis exploration is still guided by heuristics based on\ndomain knowledge.\nFor gold nanorods, it is clear that the simultaneous presence\nof various reagents during the synthesis aﬀects the character-\nistics of the resulting gold nanoparticles.4 To better understand\nthese eﬀects, computational simulation and analysis of the\naEnergy Technologies Area, Lawrence Berkeley National Laboratory, 1 Cyclotron Road,\nBerkeley, CA, USA. E-mail: walkernr@lbl.gov; ajain@lbl.gov\nbMaterials Sciences Division, Lawrence Berkeley National Laboratory, 1 Cyclotron\nRoad, Berkeley, CA, USA\ncMolecular Foundry, Lawrence Berkeley National Laboratory, 1 Cyclotron Road,\nBerkeley, CA, USA\ndDepartment of Materials Science and Engineering, University of California Berkeley,\n210 Hearst Memorial Mining Building, Berkeley, CA, USA\neDepartment of Chemistry, University of California Berkeley, 419 Latimer Hall,\nBerkeley, CA, USA\nfKavli Energy NanoScience Institute, University of California Berkeley, 101C Campbell\nHall, Berkeley, CA, USA\n† Electronic supplementary information (ESI) available. See DOI:\nhttps://doi.org/10.1039/d3dd00019b\nCite this:Digital Discovery,2 0 2 3 ,2,\n1768\nReceived 23rd February 2023\nAccepted 15th September 2023\nDOI: 10.1039/d3dd00019b\nrsc.li/digitaldiscovery\n1768 | Digital Discovery,2 0 2 3 ,2,1 7 6 8–1782 © 2023 The Author(s). Published by the Royal Society of Chemistry\nDigital\nDiscovery\nPAPER\nOpen Access Article. Published on 20 September 2023. Downloaded on 11/5/2025 5:44:06 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nView Journal\n | View Issue\nformation energetics of the nanoparticles or the nucleation and\ngrowth steps can be used. Density functional theory (DFT) can\nbe used to investigate the energetic landscape of potential gold\nnanoparticle morphologies, including the e ﬀects of surface\nligands that are vital for the solution-phase synthesis of noble\nmetal nanoparticles.\n23–25 However, this approach does not\naccount for the nuances of nucleation and growth competition\nin solution-based nanoparticle syntheses. These aspects can be\naddressed by modeling real-time growth and dispersity\ndynamics with continuum-level model, though this sacrices\naccess to small-scale energetics granted by DFT.\n26 Alternatively,\ndirect experimentation can be used to explore the synthesis\nspace by varying precursor amounts over many experiments,\nthough this is impractical due to the both the number of\nexperiments required to sample the synthesis space and the\ncondition that a single experiment can take many hours to\ncomplete. Automated labs may address this problem in the\nfuture, though most are still in their infancy.\nA third approach seeks to leverage the wealth of information\ncontained in scientic literature. Many seed-mediated gold\nnanorod recipes have been published in the materials science\nand chemistry literature, but parsing them requires domain\nexperts to manually read these articles to retrieve the relevant\nprecursors, procedures, laboratory conditions, and target\ncharacterizations. This comes with its own complications,\nhowever, as over time, the body of materials science literature\nhas grown to an unwieldy extent, preventing researchers from\nabsorbing the full breadth of information contained in estab-\nlished literature or even reasonably following research progress\nas it emerges.\n27 Thus, it is unreasonable to expect domain\nexperts in gold nanoparticle synthesis to manually read and\nparse the complete existing synthesis literature e ﬃciently,\nmotivating the development of high-throughput text-mining\nmethods to extract this information.\nThe resulting databases built with these methods are the\nrst steps toward developing data-driven approaches to under-\nstanding synthesis, which are being developed at an acceler-\nating pace as a rapidly emerging third paradigm of scientic\ninvestigation. Generally speaking, these approaches involve the\nuse of both conventional and machine learning methods to\nboth build large databases and perform downstream analysis\nand inference over said databases. Natural language processing\n(NLP) has been successfully applied in the chemical, medical,\nand materials sciences to produce structured data from\nunstructured text using methods and models such as pattern\nrecognition, recurrent neural networks, and language\nmodels.\n28,28–52\nFor applications specically related to materials synthesis,\ndata-driven approaches have been successful for tasks such as\nmaterials discovery, synthesis protocol querying, and simula-\ntion and interpretation of characterization results.53–57 However,\nthese approaches are fundamentally limited by the quality of\nthe data, such as the completeness and substance of the data\nsource. To address this, careful data curation is necessary, as\nseen with the construction and maintenance of large databases\nof characteristic features of nanostructures.\n58\nRecently, the wealth of unstructured information about gold\nnanoparticle synthesis and characterization in literature has\nbeen directly tapped through the combination of various NLP\nmodels and other text-mining techniques to produce a dataset\nof over ve thousand codi ed gold nanoparticle synthesis\nprotocols and outcomes.\n59 This general dataset contains\na wealth of information, including detected materials, material\nquantities, morphologies, synthesis actions, and synthesis\nconditions, as well as tags for seed-mediated synthesis,\nsynthesis paragraph classications, and characterization para-\ngraph classications.\nDespite the breadth of accurate information provided, the\ngeneral dataset still suﬀers from a few pitfalls: (i) the inability to\ndistinguish between seed and growth solution procedures in\nseed-mediated growth synthesis; (ii) the inability to detect\nreferences to materials that do not contain specic formulae or\nchemical names ( e.g. “AuNP seed solution ”); and (iii) the\ninability to detect target morphologies as opposed to inciden-\ntally mentioned morphologies. To address these issues, this\nwork intends to use a large sequence-to-sequence language\nmodel to extract full synthesis procedures and outcomes in\na single-step inference. Generally speaking, a sequence-to-\nsequence model in NLP maps an input sequence to an output\nsequence by learning to produce the most likely completion of\nthe input by conditioning the output on the input.\n60\nIn this work, we leverage the capabilities of the latest\nlanguage model in the Generative Pre-trained Transformer\n(GPT) family, GPT-3,\n61 to build a dataset of highly structured\nsynthesis templates for seed-mediated gold nanorod growth. A\nsimilar approach using GPT-3 to build materials science data-\nsets has been applied to extracting dopant-host material pairs,\ncataloging metal–organic frameworks, and extracting general\nchemistry/phase/morphology/application information for\nmaterials.\n62 We extracted these templates for seed-mediated\ngold nanorod growth from 2969 paragraphs across 1137\nltered papers, starting with using a question-answering\nframework aided by the zero-shot performance of GPT-3 to\nconstruct a small initial dataset. We thenne-tuned GPT-3 to\nproduce complete synthesis templates for input paragraphs.\nFine-tuning GPT-3 consists of using multiple examples of\nparagraph and synthesis template pairs to train GPT-3 to\nperform this specic task. Each synthesis template in thenal\ndataset contains information on relevant synthesis precursors,\nprecursor amounts, synthesis conditions, and characterization\nresults, all structured in a JSON format. This dataset provides\nreproducible summaries of procedures and outcomes, explicitly\nestablishing the relationships between the components of the\nrecipe (e.g. accurately linking the correct volumes and concen-\ntrations with the correct precursors in the correct solution).\nHowever, this specicity comes at the cost of generality, as the\ndataset focuses on seed-mediated gold nanorod growth. The\nnal dataset consists of 11 644 entities extracted from 1137\nltered papers, 268 of which contain least one complete seed-\nmediated gold nanorod growth procedure and outcome for\na total of 332 complete procedures.\nWhile our primary focus revolved around the application of\na ne-tuned GPT-3 Davinci model, we further extended our\n© 2023 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 3 ,2,1 7 6 8–1782 | 1769\nPaper Digital Discovery\nOpen Access Article. Published on 20 September 2023. Downloaded on 11/5/2025 5:44:06 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nresearch horizon by employing 13 billion parameter variant of\nLlama-2 (ref. 63) to undertake the same task for benchmark.\nLlama-2, an acronym for“Large Language Model Meta AI– 2′′,\nemerges from a lineage of language models that have been re-\nported to exceed performance of much larger models (such as\nGPT-3 Davinci) on many NLP benchmarks.\n64 Compared to GPT-\n3, Llama utilizes diﬀerent approaches to architecture including\nthe use of SwiGLU activations instead of ReLU,65 rotary position\nembeddings instead of absolute position embeddings,66 and\nRMS layer-normalization67 instead of standard layer normali-\nzation.68 Additionally, Llama-2 boasts a 4192 token context\nwindow instead of the 2048 token context window provided by\nGPT-3.\n2 Dataset\nThe relevant data for constructing the training, testing, and\nprediction data for this model was collected using the database\nof gold nanoparticle synthesis protocols and outcomes devel-\noped by Cruseet al.\n59 from the full-text database developed by\nKononova et al.28 through text- and data-mining agreements\nwith several major scientic journal publishers. The original\nfull-text database contains more than 4.9 million materials\nscience articles, and the pipeline for identifying and extracting\ngold nanoparticle synthesis articles consists of progressively\nner-meshed ltering steps using text-mining tools adapted\nfrom Kononova et al.\n28 and Wang et al.69 These steps include\nregular expression matching to identify nanomaterial papers,\ndocument and vocabulary vectorization using term frequency-\ninverse document frequency (TF-IDF) to reveal papers related\nmore to gold than other noble metals, BERT-based binary\nclassiers to identify paragraphs related to gold nanoparticle\nsynthesis or characterization (particularly morphological\ninformation), a combination of BiLSTM-based named entity\nrecognition (NER) and rules-based methods to extract synthesis\nprocedure details from synthesis paragraphs, and MatBERT\n49\nNER to extract morphology and size information from charac-\nterization paragraphs.\nUsing the extracted information, 5145 papers were identied\nto contain gold nanoparticle synthesis protocols,70 of which 1137\nltered papers were found to contain seed-mediated recipes\nusing the“seed_mediated” ag as well as rod-like morphologies\n(“rod or “NR” in “morphologies” under “morphologica-\nl_information”) or aspect ratio measurements (“aspect” or “AR”\nin “measurements” under “morphological_information”). This\nwas done tolter the total papers down to only those likely to\ncontain seed-mediated synthesis recipes for gold nanorods.\n3 Methods\nAt the core of the GPT-1 model was a focus on improving\nlanguage understanding by generative pre-training involving\nthe use of a large language model in conjunction with a very\nlarge and diverse pre-training corpus with long stretches of\ncontiguous text, which greatly facilitated the model's ability to\nlearn “world knowledge” alongside its ability to process long-\nrange dependencies.\n71 For a sequence-to-sequence generative\nmodel, outputs are generated by maximizing the log probability\nof p(outputjinput).60 To further improve zero-shot performance\nfor both learning and task transfer, GPT-2 modied the training\nobjective to include task conditioning, p(outputjinput, task),\nthus establishing the model as an unsupervised multitask\nlearner.\n72 With GPT-3, more extensions of the model size and\nthe pre-training corpus have produced a model with consider-\nable capacity for few-shot learning that is capable of producing\ntext that is diﬃcult to distinguish from human-written text or\nperforming tasks it was not explicitly trained on, such as writing\ncode or summing numbers.\n61 We employed the 175 billion\nparameter variant of GPT-3 (OpenAI Davinci) for this work.\nOf the 1137ltered papers identied to contain information\nabout seed-mediated gold nanorod synthesis, 240 (consisting of\n661 relevant paragraphs) were randomly sampled and fully\nannotated with JSON-formatted recipes by a single annotator with\nmachine assistance to serve as a training set. An additional 40\nltered papers (consisting of 117 relevant paragraphs) were\nannotated to serve as a testing set. Each relevant paragraph was\nseparately annotated due to length constraints imposed by GPT-3,\nwhich limits the capability to process an entire article at once. A\nlimit of 2048 tokens is shared between the input prompt and the\noutput completion, corresponding to approximately 1500 words.\n61\n3.1 Overall procedure\nA diagram outlining the general process for producing thenal\nne-tuned model for template-lling is shown in Fig. 1. In the\ninitial stage (orange), a simple question-answering framework\nis used to individually ll in templates for an initial set of\nparagraphs. These results are then corrected according to the\ndescribed annotation procedure and used as an initial training\nset forne-tuning GPT-3 to produce complete templates in the\nsecond stage (green). The nal stage (blue) is an iterative\ntraining process in which new templates are predicted, cor-\nrected, and added to the training set to update thene-tuned\nmodel, thus improving its performance with each iteration.\nDefault settings through the OpenAI API (v0.13.0) are used for\nall ne-tunes of the GPT-3 Davinci model, and a temperature of\nzero is used for all model predictions with a double line break as\nthe stop sequence. By using a temperature of zero, the results\nshould be deterministic assuming thatoating point errors in\nthe GPU calculations are smaller than the diﬀerences between\nthe log probabilities of the next token prediction candidates.\nTo assess Llama-2-13B's eﬃcacy in extracting two-step seed-\nmediated gold nanorod synthesis procedures, we adopted\na ne-tuning approach using Low-Rank Adaptation (LoRA) as\ndescribed in ref. 73, facilitated by the Parameter-Eﬃcient Fine-\nTuning library.\n74 The base model of Llama-2-13B75 with 8 bit\nquantization wasne-tuned with the identical training data on\na single GPU (NVIDIA A100). Some of thene-tuning parameters\nwe used are as follows: 4 epochs, batch size of 1, learning rate of\n0.0001, LoRA r of 8, LoRA alpha of 32 and LoRA dropout of 0.05.\n3.2 Template structure and annotation scheme\nThe structure and content of the synthesis templates are shown\nin Fig. 2. The synthesis templates are stored as JSON\n1770 | Digital Discovery,2 0 2 3 ,2,1 7 6 8–1782 © 2023 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 20 September 2023. Downloaded on 11/5/2025 5:44:06 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\ndocuments, which contain three components: the seed solu-\ntion, the growth solution, and the resulting nanorods. For the\nseed and growth solutions, the precursors and their associated\nvolumes (vol), concentrations (concn), and/or masses are\nrecorded, as well as the ages of the respective mixed solutions at\nthe time of use and the temperatures (temp) at which they are\naged. Furthermore, the stirring rates when adding sodium\nborohydride (NaBH\n4) to the seed solution and when adding the\nseed solution to the growth solution are recorded. The shape\nand size of the gold seeds in the seed solution are also noted.\nFor the gold nanorods (AuNR), the aspect ratios (ar), lengths (l),\nwidths (w), and longitudinal/transverse surface plasmon reso-\nnances (SPRs) are recorded. The JSON documents have identical\nstructures and thus contain an entry for every value that can be\nrequested; any values not present in a given paragraph arelled\nwith an empty string.\nWhen available, numerical quantities with units are extracted.\nFor precursor volumes, the units are provided in variations of\nliters, though the concentrations may be measured in either\nmolarity, molality, or weight percentage. In some cases, the total\nvolume of a collection of precursors may be specied instead of\nthe individual volumes of the precursors. In this case, the explicit\nvolume is associated with therst precursor and the volumes for\nthe remaining precursors refer to the name of therst precursor,\nimplicitly communicating a shared volume. For temperatures,\ndegrees Celsius are most commonly provided, though more\nqualitative descriptions such as“room temperature” will still be\nrecorded if the explicit temperature is not provided in the text but\na qualitative description is. Similarly, for solution ages, minutes\nor hours are most common, but sometimes only descriptions like\n“overnight” are provided and recorded. For stirring rates, the\nrevolutions per minute (rpm) is preferred, but many papers will\ninstead provide descriptions such as“gentle” or “vigorous” that\nare recorded. For the gold nanorod properties, aspect ratios are\nunitless while the other quantities (length, width, SPRs) are\nprovided in units of length, with the exception of some cases\nwhere the LSPR is only provided as “NIR” (near-infrared).\nThroughout all stages of the annotation process, three addi-\ntional researchers were consulted to reach a consensus on the\nFig. 1 A diagram illustrating the overall procedural approach for\nextracting synthesis templates from text with GPT-3 is shown. All\nunstructured text paragraphs were drawn from the seed-mediated\ngold nanorod growth dataset of 1137ﬁltered papers (purple). Theﬁrst\nstage involves ﬁlling initial templates using a zero-shot question/\nanswer framework with GPT-3, which is then corrected (orange). The\nplus sign indicates a combination of the texts and queries used as\ninput. Template correction is done through manual editing of the\ntemplates according to the described annotation procedure. These\nannotated templates are used toﬁne-tune an initial GPT-3 model,\nwhich produces complete templates in a single prediction (green).\nFrom there, the process of iteratively predicting more templates with\na ﬁne-tuned model, correcting them, adding them to the training set,\nand then ﬁne-tuning the model again is then performed (blue). The\nplus signs for these stages indicate that text-template pairs are used as\ninput forﬁne-tuning.\nFig. 2 A diagram representing the structure of the seed-mediated\ngold nanorod growth JSON template. From left to right, the structure\nis divided into three components, the seed solution, the growth\nsolution, and the resulting gold nanorods. For the seed and growth\nsolution components, there are entries for the precursors and their\nassociated quantities, as well as entries for experimental conditions\nsuch as the age and aging temperatures of the solutions and stir rates\nwhen adding the reducing agent (for the seed solution) or the seed\nsolution (for the growth solution). For the gold nanorod component,\nthere are entries for the characterization information that may be\npresent, including the aspect ratio (ar), length (l), and longitudinal/\ntransverse surface plasmon resonances (l/tspr).© 2023 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 3 ,2,1 7 6 8–1782 | 1771\nPaper Digital Discovery\nOpen Access Article. Published on 20 September 2023. Downloaded on 11/5/2025 5:44:06 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nappropriate annotations for various edge cases caused by unclear\nwording or other ambiguities.\n3.3 Question answering completions\nUnfortunately, the standard pre-trained GPT-3 Davinci model is\nnot capable of providing consistent completed templates of\nhigh quality in one request. However, the model is capable of\nanswering simple questions about synthesis paragraphs\nwithout any ne-tuning, which allows for the elds of the\nsynthesis templates to be individuallylled using answers from\na simple question-answering framework using GPT-3. An\nexample is shown in Fig. 3.\n76 This machine-assisted annotation\napproach avoids the laborious process of manuallylling in\neach eld of the templates by hand, as an annotator only needs\nto verify and correct the provided answers as-needed. However,\nthis approach does not scale well to large numbers of papers, as\neach query is a separate model request, meaning that each\nparagraph in each paper would require a large number of\nrequests in order to ll a single template. Therefore, this\napproach is used to construct an initial dataset consisting of\nsynthesis templates for paragraphs from a small number of\npapers. Due to the small number of papers used, this initial\ndataset does not necessarily capture the variety of precursors or\nmanners in which critical data can be communicated in text. As\nsuch, only information known to be commonly present in seed-\nmediated gold nanorod synthesis (e.g. the common precursor\nvolumes/concentrations) were queried. Nevertheless, these\ninitial templates, when corrected, provide a suitable starting\npoint for ne-tuning GPT-3 to provide complete synthesis\ntemplates in single requests for each paragraph. Through an\niterative process of ne-tuning GPT-3 on the available\ntemplates, predicting new templates, correcting them, andne-\ntuning a new model using all of the corrected templates con-\nstructed thus far, anal ne-tuned model can be obtained.\nThe initial synthesis template dataset was constructed using\nthe zero-shot question-answering framework with 40 randomly\nsampled ltered papers. If a relevant precursor, condition, or\ncharacterization was identied with regular expression pattern\nmatching in the paragraph, the framework would be to request\nthe information using GPT-3. For example, if“ascorbic acid”,\n“AA”, “vitamin C”,o r“C\n6H8O6” appeared in the paragraph, the\nframework would request the volume, concentration, and mass\nof ascorbic acid. This initial dataset only requested information\nabout the eight most common precursors, including“HAuCl4”,\n“CTAB”, and “NaBH4” for the seed solution, and “HAuCl4”,\n“CTAB”, “AgNO3”, “AA”, and “seed solution” for the growth\nsolution. To capture di ﬀerent ways of expressing each\nprecursor, multiple aliases were checked to include variations\non chemical names as well as the chemical formulae. Addi-\ntionally, the framework requested information about the stir\nrate when adding NaBH\n4 to the seed solution, the age of the\nseed solution, the temperature of the seed solution during\naging, the size and shape of the seeds, the stir rate when adding\nthe seed solution to the growth solution, the age of the growth\nsolution, and the temperature of the growth solution during\naging. All request completions for each paragraph were aggre-\ngated into a single JSON entry according to the synthesis\ntemplate scheme shown in Fig. 2.\nThe approach of using zero-shot GPT-3 question answering\nrequests toll the templates tended to produce poor results, but\nit oﬀered an acceptable starting point for collecting structured\nrecipes. Most of the templates only required correcting the\nincorrect entries, rather than lling them in manually from\nscratch, which greatly accelerated the creation of the initial\ndataset. However, some entries had to be added from scratch\ndue to recipes including precursors outside the initial set of\neight common precursors. Note that the static nature of the\nsynthesis templates across all paragraphs means that when one\nparagraph requires the addition of a new precursor to the\ntemplate, this is applied to all templates for all paragraphs.\nAdditionally, annotation was done strictly, requiring that the\nsynthesis method must be seed-mediated growth and the target\ngold nanoparticle morphology must be nanorods. This provides\nan important test for the model, as the diﬀerence between\nrecipes that produce very similar morphologies can sometimes\nbe subtle.\n3.4 Fine-tuning procedure and dataset construction\nThese corrected templates derived from the question answering\ncompletions provided an initial training set forne-tuning GPT-\n3 to produce the desiredlled templates. From there, templates\nfor paragraphs from 40 more randomly sampledltered papers\nwere iteratively predicted, corrected (adding new precursors as\nnecessary), and added to the training set until templates for\nparagraphs from 240ltered papers had been corrected in total.\nWith each iteration, the correction process became much easier\nand faster. Initially, templates for information-dense para-\ngraphs took approximately 4 minutes to validate and correct,\nwhereas, by the end of the process, they took around a minute\neach. This is because GPT-3 largely predictedlled templates\nwith high accuracy. The testing dataset was composed of para-\ngraphs from an additional random sampling of 40 papers. Not\nall of the papersltered from the original dataset were guar-\nanteed to contain information that should be placed into\nsynthesis templates. For example, seed-mediated growth or\nnanorod measurements and morphologies may only be inci-\ndentally mentioned in a given paragraph that is otherwise not\nFig. 3 An example of a question answering completion using GPT-3.\nThe input is bounded by a purple box containing the prompt (orange),\nparagraph text (green), and query (blue). The output is bounded by\na red box.\n1772\n| Digital Discovery,2 0 2 3 ,2,1 7 6 8–1782 © 2023 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 20 September 2023. Downloaded on 11/5/2025 5:44:06 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nrelevant to a speci c seed-mediated gold nanorod growth\nprocedure. Of the 240ltered papers in the training set and the\n40 ltered papers in the testing set, 141 and 23 papers respec-\ntively contained at least one paragraph with information that\ncould be placed into a synthesis template. The following\ncommand was used to perform thene-tuning:\n.\n4 Results\nThe described training dataset of synthesis templates was used\nto ne-tune a GPT-3 model to reproduce said synthesis\ntemplates from the unstructured text. Default parameters for\nthe ne-tuning process were employed, incurring a cost of 85.30\nUSD (191 069 prompt tokens and 522 649 completion tokens).\nThe predictions over the testing dataset (40 papers composed of\n117 paragraphs) took around eighty minutes to complete and\nincurred a cost of 14.39 USD (27 327 prompt tokens and 92 126\ncompletion tokens). The performance of thene-tuned model\nwas then evaluated using the testing dataset.\n4.1 Error evaluation examples and denitions\nAn example prediction is depicted in Fig. 4.\n77 Errors are high-\nlighted in red. For this example, two errors were made. First, the\nquantities for“Borohydride” in the seed solution were instead\nplaced under“NaBH\n4” in the seed solution. Arguably, this is not\ntruly an error since sodium borohydride is oen conventionally\nreferred to as “borohydride”, possibly indicating “world\nknowledge” exhibited by GPT-3. However, there are technically\nother borohydrides, such as potassium borohydride, that can be\nused as a reducing agent for seed-mediated gold nanorod\ngrowth,\n78 so this was still marked as incorrect due to possible\nambiguity. The second error was the failure to extract the HCl\nvolume. Note the rather complex relationship in the growth\nsolution precursor volumes, where CTAB, HAuCl 4, ascorbic\nacid, AgNO3, and HCl all share the same 25 mL volume. To\navoid confusion, the volume is explicitly associated with the\nrst-mentioned precursor in the mixture, and the following\nprecursors refer back to thatrst precursor. This ensures that\ndownstream applications can unambiguously process the data\nto mean that the precursors are sharing a single volume. Other\nthan these two errors, the model performs very well at extracting\nquantities in this example.\nFor the 117 testing paragraphs, two types of errors are\ntracked: placement errors and transcription errors. This is done\nin order to evaluate the model's capability for separately iden-\ntifying which elds of the synthesis templates should contain\ninformation, as well as how accurate the appropriately placed\ninformation is. To evaluate information placement, only the\nexistence of information in the elds of the prediction and\nground truth synthesis templates are considered. For example,\nif the same eld contains information (as opposed to being\nempty) in both templates, that is considered a true positive\nprediction regardless of whether the information explicitly\nmatches. If bothelds are empty, then that is a true negative. If\nthe prediction eld contains information while the ground\ntruth eld is empty, then that is a false positive, while the\nreverse is a false negative. These categories of placement errors\nare used to calculate the precision, recall, and F1-score for\ninformation placement. Examples of these evaluations are\nshown in Fig. 5.\nFor evaluating transcription accuracy, only the agreement\nbetween the prediction and the annotation for true positive\nplacements are considered, as the other types of errors are\naccounted for by the evaluations of information placement. For\nnumerical values with units, the units must be exactly correct\nand the quantitative relative error was calculated according to\nthe functions(p, q) = 2$min(p, q)/(p + q), which is derived from\nthe absolute proportional diﬀerence r(p, q) = jp − qj/(p + q) and\nis bounded on [0,1] for non-negative numerical values p\nFig. 4 A model prediction example is shown, with empty entries\nomitted. The original unstructured text is shown on the top, and the\ncomponents of the predicted synthesis template in JSON form are\nshown on the bottom. The important information from the unstruc-\ntured text is colored in orange (for precursors) and green (for quan-\ntities), while any errors are highlighted in red.\n© 2023 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 3 ,2,1 7 6 8–1782 | 1773\nPaper Digital Discovery\nOpen Access Article. Published on 20 September 2023. Downloaded on 11/5/2025 5:44:06 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\n(predicted numerical value) andq (annotated numerical value).\nSome values may have modiers attached, such as“>3 h”. If the\nprediction misses this information, e.g., gives “3h ”, the\nprediction is considered half-correct even if the quantity and\nunit are both correct. Some quantities will additionally be\nexpressed as a range or list of values. In these cases, the range\nboundaries are split into a list as necessary, and the transcrip-\ntion accuracies are scored and aggregated across the values in\nthe list with proper ordering enforced. For non-numerical\npredictions such as stir rates described as“vigorous” or gold\nseed morphologies, an exact string match is required for the\nprediction to be marked as correct. The combined accuracy\n(adjusted F1-score) is presented as the product of the F1-score\nfor information placement and the transcription accuracy.\nThis is the most meaningful metric to evaluate the overall\nperformance of the model.\n4.2 Model performance\nThe total performance of the model aggregated over each recipe\ncomponent as well as all entries is shown in Table 1. The model\nappears to be procient at generally identifying which infor-\nmation should belled in the template based on the content of\nthe text, with a rather high F1-score of 90% that favors neither\nprecision nor recall. It additionally performs exceptionally at\naccurately transcribing the information with an accuracy of\n95%. By taking the product of the placement F1-score and the\ntranscription accuracy, this provides an impressive overall\nadjusted F1-score of 86%. This indicates a signi cant\nimprovement over comparable eﬀorts in solid-state synthesis\ntext-mining, which report an overall accuracy of 51% for\nextracting all recipe items (chemistry, operations, and attributes\nof the operations).\n28 Direct comparison is, however, rather\nchallenging, as some aspects of the two-step, seed-mediated\ngrowth synthesis are more complicated, such as the presence\nof two solutions with distinct precursor sets and a greater\namount of precursor information needed due to the solution-\nbased format. On the other hand, solid-state synthesis extrac-\ntion carries its own challenges, considering the greater variation\nin procedural steps and conditions that must be considered.\nIt is clear that the adjusted F1-scores for the recipe entities\nassociated with the seed and growth solutions are very prom-\nising, indicating that the model is reliable for extracting the\nnecessary information from the text for the component solu-\ntions to the synthesis procedure. However, the performance is\nworse overall for the gold nanorod properties, with an adjusted\nF1-score of approximately 72%. This is still an improvement\nover similar results, as the gold nanoparticle synthesis\nprotocol and outcome database developed by Cruse et al.\n59\nextracts morphology measurements, sizes, and units with F1-\nscores of 70%, 69%, and 91% via NER with MatBERT.\nHowever, these entities are not linked together, so while doing\nso would inevitably introduce additional sources of error and\nperformance would be additionally constrained by the lowest\nFig. 5 A diagram depicting the diﬀerent types of prediction errors\nmade by the model is presented. Generally, two categories of errors\nexist: placement errors and transcription errors. Placement errors refer\nto whether the prediction has placed any information, correct or\nincorrect, into the appropriate ﬁelds as determined by the ground\ntruth. These are indicated with the lines connecting theﬁelds in the\nground truth and the prediction templates. A false positive prediction\noccurs when the prediction places information in aﬁeld that is empty,\nwhile a false negative prediction is the reverse. A true negative\nprediction is when aﬁeld is empty in both the ground truth and the\nprediction, and a true positive prediction is when aﬁeld is non-empty\nin both the ground truth and the prediction. Since the placement\nevaluations do not consider whether the predicted value in aﬁeld is\nactually correct for true positives, an additional transcription evalua-\ntion is used to measure how well the predicted value explicitly matches\nthe ground truth value. These are indicated with boxes encapsulating\nthe ﬁelds. The transcription evaluation is only applied to true positive\nplacements.\nTable 1 Model F1-scores and accuracies for recipe entities aggregated by recipe component. The support numbers in parentheses account for\nonly the true positives used for the accuracy calculation\nPlacement Transcription Combined\nSupportPrecision Recall F1 Accuracy Adj. F1\nSeed solution GPT-3 0.97 0.92 0.94 0.95 0.90 159 (142)\nLlama-2 0.90 0.91 0.91 0.94 0.85 169 (140)\nGrowth solution GPT-3 0.90 0.94 0.92 0.96 0.88 244 (206)\nLlama-2 0.88 0.92 0.90 0.94 0.84 247 (202)\nAuNR GPT-3 0.79 0.74 0.76 0.95 0.72 96 (59)\nLlama-2 0.75 0.70 0.72 0.97 0.70 99 (56)\nOverall GPT-3 0.90 0.90 0.90 0.96 0.86 499 (407)\nLlama-2 0.87 0.88 0.87 0.94 0.82 515 (398)\n1774 | Digital Discovery,2 0 2 3 ,2,1 7 6 8–1782 © 2023 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 20 September 2023. Downloaded on 11/5/2025 5:44:06 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nperforming extractions, a direct quantitative comparison is not\napplicable.\nTable 2 shows the model performance for detecting precur-\nsors in the seed and growth solutions. Precursor detection is\ncalculated implicitly based on which precursors the extracted\nvolumes, concentrations, and masses are associated with. This\nis a clear improvement over the results in the gold nanoparticle\nsynthesis protocol and outcome database developed by Cruse\net al.\n59 The prior work detected precursorsvia a BiLSTM-based\nNER model with an F1-score of 90%. However, as mentioned\nearlier, this does not distinguish between seed and growth\nsolution precursors and cannot detect precursors that do not\ncontain specic formulae or chemical names, such as the seed\nsolution that is added to the growth solution. This means that\ndirect quantitative comparison is not applicable. Thene-tuned\nGPT-3 model missed cases where cationic surfactant, PP, BH\n4,\nand AuCl3 were used as well as a case where HCl was used in the\nseed solution. None of these cases occurred in the training set.\nNotably, the model correctly normalized“AsA” to “AA”, despite\n“AsA” never appearing in the training data.\nThe adjusted F1-scores aggregated over extracted entities for\nthe paragraph-wise and paper-wise predictions are shown in\nFig. 6. Instances in which there were no entities present in either\nthe ground truths or the predictions are omitted from the results,\ngiving a total of 66 paragraphs and 26 papers. For the para-\ngraphs, the average adjusted F1-score was approximately 64%\nwith 22 (33%) perfect predictions and 32 (48%) predictions with\n>90% adjusted F1-score. For the papers, the average adjusted F1-\nscore was approximately 76% with 4 (15%) perfect predictions\nand 16 (62%) predictions with >90% adjusted F1-score.\nComparative performance of Llama-2-13B against GPT-3\nDavinci is also detailed in Tables 1 and 2. Although Llama-2\nexhibits comparatively diminished performance, its viability is\ncontext-dependent. Its value arises from being a smaller model,\namenable for non-commercial on-premise deployment without\nrelying on an API. Moreover, its reduced size compared to GPT-3\nDavinci makes it an economical choice from a computational\nstandpoint.\n4.3 Full ltered dataset\nThe ne-tuned GPT-3 model was applied to the full ltered\ndataset of 1137ltered papers (2969 paragraphs) at a total cost\nof 384.31 USD (838 901 prompt tokens and 2 332 796 comple-\ntion tokens) over 33 hours. In total, 11 644 entities were\nextracted from the paragraphs that contained information of\ninterest. The dataset is presented as a JSONle containing a list\nwith each element corresponding to a single article. Table 3\nsummarizes the structure of the JSON documents for each\npaper alongside a breakdown of how the total extracted entities\nacross the entire dataset are distributed across the entity types.\nWhile the template extractions were performed paragraph-by-\nparagraph, the templates have been merged by article for\nconvenience. However, this does mean that some conicts and\nrepetitions are present in the dataset. A conict arises when\na particular entity type in a paper (e.g. the volume of a particular\nprecursor) is specied with diﬀerent values across multiple\nparagraphs and a repetition arises when it is specied with the\nsame value across multiple paragraphs. Of the 11 644 extracted\nentities, 10 098 (∼87%) are uniquely identied, meaning there\nare no conicts or repetitions (the associated value is extracted\nfrom exactly one paragraph). An additional 353 entries present\nat least one conict without any repetitions, 251 with at least\none repetition and no conicts, and 57 with both conicts and\nrepetitions. Repetitions do not need to be manually resolved\nsince this arises from the specication of identical information\nacross multiple paragraphs (e.g. mentioning the gold nanorod\naspect ratios in paragraphs about both the synthesis procedure\nas well as the nanorod characterization), but conicts can be\nchallenging to resolve in a consistent manner without manual\ninspection. For instance, if two separate volumes for a particular\nprecursor are provided in two separate paragraphs, it can be\nambiguous whether the volumes are part of the same synthesis\nTable 2 Model performance for precursor detection in the seed and growth solution information\nSeed solution Growth solution\nPrecision Recall F1 Support Precision Recall F1 Support\nPrecursor GPT-3 0.98 0.90 0.94 61 0.93 0.92 0.92 118\nLlama-2 0.95 0.90 0.92 63 0.91 0.91 0.91 120\nFig. 6 Histograms showing the adjusted F1-score performances for\nthe (a) paragraphs and (b) papers.\n© 2023 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 3 ,2,1 7 6 8–1782 | 1775\nPaper Digital Discovery\nOpen Access Article. Published on 20 September 2023. Downloaded on 11/5/2025 5:44:06 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nprocedure or distinct synthesis procedures in the same paper\ndue to the lack of cross-paragraph context. With this in mind, of\nthe 11 644 extracted entities, 10 349 (∼89%) can be safely\nextracted by automatically resolving repetitions and discarding\nentities with conicts. Of the entities with conicts, 341 have\ntwo distinct values, 47 have three, 12 haveve, 9 have four, and\n1 hasve.\nWith post-processing applied (as was done for evaluation of\nthe testing dataset), splitting lists of extracted values into\ndistinct entities and resolving repetitions of identical informa-\ntion extracted across di ﬀerent paragraphs within the same\npapers results in a total of 11 770 unique entities. In the post-\nprocessed version of the dataset, each property contains a list\nof dictionaries with structures indicated in Table 4.\n4.4 Full ltered dataset analysis\n4.4.1 Procedure completeness analysis. An ideal database\nof gold nanorod growth procedures should contain fully-\nspecied, reproducible procedures alongside their outcomes.\nThis is desirable because missing information could inhibit\ndownstream applications that need complete information\nabout the synthesis procedure. For instance, if a scientist wants\nto reproduce an experiment that produces gold nanorods of\nTable 3 A table depicting the format of each data record for each article in the dataset is presented (constructed by merging paragraph\ntemplates)a\nRoot key First subkey Second subkey Third subkey Description Total\ndoi Article DOI 1137\ntext <integer> Paragraph text for <integer>th paragraph 2969\nseed prec <precursor name> volume Seed solution precursor volume 1347\nconcentration Seed solution precursor concentration 1385\nmass Seed solution precursor mass 6\nseed size Seed solution seed size 137\nshape Seed solution seed shape 24\nstir Seed solution reducing agent stir rate 266\ntemp Seed solution aging temperature 284\nage Seed solution aging time 352\ngrowth prec <precursor name> volume Growth solution precursor volume 2664\nconcentration Growth solution precursor concentration 2178\nmass Growth solution precursor mass 65\nstir Growth solution reducing agent stir rate 134\ntemp Growth solution aging temperature 322\nage Growth solution aging time 464\nAuNR ar Gold nanorod aspect ratio 587\nl Gold nanorod length 443\nw Gold nanorod width 452\nlspr Gold nanorod LSPR 357\ntspr Gold nanorod TSPR 177\na The “doi” key contains the article DOI and the“text” key contains index keys of the relevant paragraphs within that article which in turn contain\nthe paragraph text. The“seed” and “growth” keys respectively contain the keys for the seed and growth solution information, including the“prec”\nkey for precursors, the“stir” key for stir rates (when adding the reducing agent for the seed solution and when adding the seed solution for the\ngrowth solution), the“temp” key for the aging temperature, and the“age” key for the solution aging time. The“seed” key has an additional\n“seed” key that contains the“size” and “shape” keys for the size and shape of the seeds in the seed solution. The“prec” key for each solution\ncontains multiple keys for each precursor in each solution, anonymized as“<precursor name>” in the table. For each precursor, there are three\nkeys: “vol”, “concn”, and “mass” for the precursor volume, concentration, and mass, respectively. The “AuNR” key contains keys for\nmeasurements of gold nanorod dimensions:“ar”, “l”, “w”, “lspr”, and “tspr” for the aspect ratio, length, width, LSPR, and TSPR, respectively.\nEach extracted value is additionally stored as a key with a corresponding list of the paragraph indices that the value was extracted from in order\nto preserve information about entity sources. Thenal column displays the total number of entities extracted for each key (with no subkeys).\nTable 4 A table depicting the format of each extracted value in the post-processed version of the dataset\nKey Structure Description\nmod <modi er> A string indicating if a value is a range, approximate, bounding, or unprocessed\nval [<value>, ., <value>] A list of the extracted values. Ranges will consist of two values for the range boundaries.\nProcessed values will be numbers while unprocessed values will be strings\nunit <unit> The units for the extracted values, if applicable, as a string\nsrc [[<index>, ., <index>],\n.,[ .]]\nA list of lists of paragraph indices to indicate the source for the extracted information\nindex [[<index>, ., <index>],\n.,[ .]]\nA list of lists of positional indices to retain ordering for values that were split from a list\nduring post-processing\n1776\n| Digital Discovery,2 0 2 3 ,2,1 7 6 8–1782 © 2023 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 20 September 2023. Downloaded on 11/5/2025 5:44:06 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\na particular aspect ratio, they would at the very least need to\nknow all of the relevant seed and growth solution precursors\nwith their amounts. Similarly, a data science project that\nintends to investigate the relationship between procedures and\noutcomes will need complete information for the seed and\ngrowth solutions in addition to the gold nanorod measure-\nments in order to produce reliable predictions. To evaluate the\ncompleteness of the information this dataset contains, we\nexamined 1137 ltered papers in the full ltered prediction\ndataset. Of these, 701 (62%) contained at least one paragraph\nwith a non-empty synthesis template. Of these 701 papers, 678\n(97%) fully specied at least one synthesis component: the seed\nsolution, the growth solution, or the gold nanorod dimensions.\nThis is encouraging since the vast majority of the papers that\ncontain information at least fully specify one component of the\nprocedure or the outcome.\nIn order to evaluate the completeness of the components of\nthe procedure and the outcome, for seed and growth solutions,\nonly fully specied precursors were considered necessary for\nreproducibility. Auxiliary information, such as stirring rates,\naging times, aging temperatures, and seed particle morphol-\nogies and sizes, while useful, was not considered necessary. The\nprecursor information was considered to be full specied for\na given paper if all of the precursor quantities were fully spec-\nied with either volume and concentration, mass, or a specic\nconcentration within another solution for each precursor with\nextracted quantities. Exceptions were made for water and the\nseed solution that is added to the growth solution, which both\nonly needed a reported volume or mass. Additionally, seed\nsolution in the growth solution precursors was required for the\ngrowth solution precursors to be considered complete. For the\ngold nanorod dimensions to be considered complete, either the\naspect ratio, length, or LSPR measurement had to be specied,\nwith the latter two at least providing an avenue for estimation of\nthe aspect ratio if reported alone.\nFig. 7 shows how the papers in the fullltered prediction\ndataset are distributed across fully-specied synthesis proce-\ndure and outcome components according to these criteria. The\nvast majority of the papers reported gold nanorod dimensions,\nwith 80% of the 678 papers with at least one fully specied\nsynthesis component containing fully-specied gold nanorod\ndimensions. Additionally, the majority of the papers fully-\nspecied the seed and growth solutions (respectively 61% and\n67%). However, they are distributed such that 40% (268) of the\npapers fully specied all three components. This is a reasonable\nresult considering that many papers will directly report the\nrelevant gold nanorod dimensions without specifying\na synthesis procedure, opting instead to reference the estab-\nlished recipe that the researchers used to produce the gold\nnanorods. Additionally, some researchers will opt to purchase\ngold seed solution instead of producing their own, which\naccounts for cases where some papers are missing information\nabout seed solution preparation. Most of the papers with fully-\nspecied synthesis procedures and outcomes (162) used the\ntypical 8-precursor synthesis and an additional 49 use the same\nsynthesis precursors with the addition of HCl in the growth\nsolution. In the post-processed version of the dataset, it is\ndetermined that of the 268 papers that fully specied all three\ncomponents, 233 contained exactly one procedure. An addi-\ntional 16 contained two, 13 contained three, 3 contained four, 2\ncontained ve, and 1 contained six for a total of 332 complete\nprocedures. This nal dataset should be suitable for down-\nstream analysis and inference, given the overall model perfor-\nmance for extracting complete synthesis procedures and\noutcomes from the literature.\n4.4.2 Data consistency analysis. Fig. 8 shows the relation-\nship between various measurements extracted from text\ncompared to the aspect ratios extracted from the text. Only co-\noccurring measurements explicitly present within the extrac-\nted information from a given paragraph are considered data\npoints for comparison. No derived measurements were used. As\na sanity check, the rst diagram (a) shows the relationship\nbetween the ratios of the explicit lengths and widths present in\nthe text (excluding ranges) and the reported aspect ratios.\nIdeally, the relationship should be an identity as shown with the\ndashed line. However, while the vast majority of the data\napproximately complies with this trend, there are several\noutliers that produce deviation from the ideal trend in the\nregression of the text-mined data. This is primarily caused by\ntwo papers with mismatches in measurements extracted from\nthree-step seed-mediated gold nanorod overgrowth procedures\nwhere the dimensions of the nanorod seeds used for overgrowth\ninto nanowires are confused with the dimensions of the\nFig. 7 A diagram showing the proportional overlaps of papers with\ncomplete synthesis procedure and outcome components. Each vertex\nof the triangle corresponds to the labeled recipe component. The\nareas of the circles are proportional to the corresponding number of\npapers inscribed. The circles on the midpoints of the edges corre-\nspond to papers with complete recipe components corresponding to\nthe bounding vertices. The center circle corresponds to the papers\nwith complete recipes and complete characterizations.\n© 2023 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 3 ,2,1 7 6 8–1782 | 1777\nPaper Digital Discovery\nOpen Access Article. Published on 20 September 2023. Downloaded on 11/5/2025 5:44:06 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nnanowires themselves. With all outliers removed via outlier\ndetection using an elliptic envelope80,81 followed by manual\nverication, the linear regression almost exactly matches the\nideal relationship. The most common errors were caused by\nnanorod overgrowth measurements taken from three-step seed\nmediated growth procedures and cases in which the ordering of\nthe aspect ratios and the lengths and widths were mismatched\n(e.g. the lengths and widths are listed while the aspect ratios are\npresented as a range). Only 8 of the 78 data points were iden-\ntied as outliers. For the comparison between the LSPR peaks\nand the aspect ratios (b), a strong linear trend is similarly\npresent. However, for this relationship, there is an additional\ncomparison to a relationship derived from simulation using\na set refractive index for gold nanorods shown in blue, which is\nin general agreement with the relationship derived from text-\nmined empirical data.\n79 The deviations can be explained by\nmultiple factors including deviations from ideal conditions\nshiing the LSPR peaks such as deviation from spherical end-\ncap geometries, low nanorod yields, or impurities in the gold\nnanorod solution or the nanorods themselves that change the\nrefractive index (including poor cleaning or high concentrations\nof silver in procedures using AgNO\n3).79,82 While there are\nextraction errors present, outlier removal using an elliptic\nenvelope followed by manual verication does not signicantly\nchange the linear regression. Outliers were most commonly\ncaused by extraction errors that swapped the LSPR and TSPR\nmeasurements provided in the text. Only 9 of the 86 data points\nwere identied as outliers. Deviation from the theory in such\na manner is to be expected when considering empirical data\nfrom real-world experiments. Still, the LSPR for spheres should\nbe around 520 nm while the text-mined trend line points\ntowards a value closer to 580–590 nm. However, for larger aspect\nratios, the text-mined trend line is more representative of the\ntext-mined empirical data than the trend line derived from\nsimulation. The major outlier present in the text-mined data is\nonce again explained by a mismatch in measurements from\na three-step seed-mediated gold nanorod overgrowth\nprocedure.\n4.4.3 Gold nanorod aspect ratio distribution analysis.\nFig. 9 shows the distributions of the aspect ratios extracted from\nfully-specied experiments using precursor sets found in more\nthan 10 papers in the fullltered prediction database (Fig. 9a\nand b), in addition to the complete set of papers (Fig. 9c). For\nmany of the papers, the aspect ratios were directly reported.\nHowever, there are multiple diﬀerent ways that they are re-\nported that must be addressed in order to properly construct the\ndistributions. If the aspect ratio is provided as a range of values,\nthe distribution across that range was taken to be a normal\ndistribution with a mean and standard deviation determined by\nthe midpoint and endpoints of the range, respectively. For\npapers that did not report aspect ratios directly, length and\nwidth information was used instead. In cases where the lengths\nand widths were presented as ranges, they were similarly cast as\nnormal distributions, and the distributions of the aspect ratios\nwere calculated as ratio distributions. For cases where only the\nLSPR was provided, the text-mined linear relationship with\noutliers removed shown in Fig. 8 was used to estimate the\naspect ratios. In cases where any quantities were accompanied\nby an approximation modier (e.g. ∼), the values were cast as\nuniform distributions over the range of±10% of the value. Any\ncalculated aspect ratios that fell below 1 (e.g. due to overlaps in\nlength and width distributions for gold nanorods with small\naspect ratios) were inverted.\nFrom the distribution of the standard recipe, it is readily\napparent that the median nanorod aspect ratio is 3.3 with\nrespective rst and third quartiles of 2.75 and 3.98. Comparing\nwith experiments reporting that varying the concentration of\nAgNO\n3 in the growth solution varies the resulting nanorod\naspect ratios from 1.83 to 5.04, 83 the distribution of gold\nnanorod aspect ratios text-mined from the literature is consis-\ntent with this range, though it is narrower. Notably, there is\na non-negligible amount of samples with aspect ratios greater\nthan 5 in the distribution for the standard procedure. This is\nnot consistent with heuristic knowledge of the limitations of the\nstandard procedure for producing large aspect ratio gold\nnanorods, usually due to shorter growth times compared to\nprocedures that adjust the pH of the growth solution to retard\nFig. 8 A diagram showing the relationships between the gold nanorod\naspect ratios and other gold nanorod measurements extracted from\nthe literature including the (a) ratio between length and width and (b)\nthe LSPR peak. The inlier datapoints are shown in purple and the outlier\ndatapoints in red. The linear regressions derived from the text-mined\ndata using all of the available data and only the inlier data are\nrespectively shown in red and purple on each sub-diagram. For the\ncomparison to the ratio between length and width (a), the ideal relation\nis shown with a dashed black line and for the LSPR comparison (b),\na simulated relationship is shown with a dashed black line.\n79\n1778 | Digital Discovery,2 0 2 3 ,2,1 7 6 8–1782 © 2023 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 20 September 2023. Downloaded on 11/5/2025 5:44:06 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nthe nanorod growth.84,85 This is primarily due to erroneous\nextractions of nanowire measurements from overgrowth\nexperiments or missed precursors based on manual inspection\nof the data. However, the statistics are still dominated by the\nlower aspect ratios. Compared to the distribution for experi-\nments using HCl in the growth solution, it is apparent that the\naddition produces a distribution shied towards larger aspect\nratios. This is consistent with experiments that have deter-\nmined that the use of HCl in the growth solution grants broader\ntunability of the gold nanorod aspect ratios, allowing for more\ncontrolled growth of longer nanorods relative to the standard\nprocedure.\n86,87 Notably, ∼7% of the procedures using the stan-\ndard procedure and∼9% of the procedures using HCl in the\ngrowth solution provide nanorods with aspect ratios of 5 or\nhigher. However, when all recipes are considered, it is clear that\neven longer nanorods can be synthesized, though these recipes\nare not as popular in the literature.\n5 Discussion\nOverall, the model performs well at identifying and extracting\nrelevant information specic to seed-mediated gold nanorod\ngrowth procedures in the literature. The model achieves an\noverall adjusted F1-score of 86% on the testing dataset, indi-\ncating that it performs rather well at the task of simultaneous\nentity recognition and relation extraction. However, due to the\nstatic nature of the relations provided by the synthesis template\nand the single inference step, the entity recognition and rela-\ntion extraction tasks are not easily disentangled, which limits\ndirect comparison with conventional two-step approaches.\nInstead, the model performance for information retrieval is\nevaluated according to its ability to place information intoelds\nof the template where information should exist and then the\naccuracy of the information that is correctly placed. For infor-\nmation placement, the precision, recall, and F1-score are\nbalanced at 90%, indicating notable performance with no\npreference for false positives or false negatives. Of the infor-\nmation that is correctly placed in the templates, the model\npredicts the speci c values with 96% accuracy. Thus, the\nprimary source of error is the accurate placement of informa-\ntion into the template rather than the accurate prediction of\ncorrectly placed information. However, the template model\nstruggles with identifying new precursors that were not present\nin the training set.\nThe dataset produced by the model provides a wealth of\ninformation about seed-mediated gold nanorod growth experi-\nments and, to our knowledge, constitutes the largest structured\ndatabase with this level of depth and completeness. The\nmodel's ability to distinguish between precursors in the seed\nand growth solutions provides an example of very useful\ninformation. The simultaneous identi cation of precursors\nalongside linking them to the appropriate solutions in the two-\nstep seed-mediated procedure had proven di ﬃcult using\nestablished methods due to the propagation of errors intro-\nduced by the reliance on separate models for entity extraction\nand relation. However, with this model, if a researcher wants to\nquickly nd papers that used a particular precursor in the seed\nsolution for seed-mediated growth of gold nanorods, this task\ncan be accomplished with high delity using the predicted\ntemplates. Access to this information can be expected to greatly\nimprove tools for scientic literature searches, as conventional\nsimple keyword searches do not oﬀer this specic relational\ndependence for complicated multi-step procedures.\nFor a more ambitious goal, the full synthesis procedure data\ncan be leveraged for multiple downstream tasks, which would\nrequire the creation of additional models for inference. One\nexample would be a model that predicts gold nanorod dimen-\nsions conditioned on a specic synthesis procedure:p(proper-\ntiesjprocedure). Such a model may be leveraged to predict the\noutcomes of proposed procedures without the need to perform\nthem explicitly. Building on this, the inverse problem,p(pro-\ncedurejproperties), can also be modeled. This would be very\nuseful for streamlining synthesis experiments, as the necessary\nprocedures for synthesizing gold nanorods with the desired\nproperties can be inferred to provide a starting point that\nreduces the number of experiments that must be conducted to\nsynthesize the desired gold nanorods. However, in the most\nlikely case, any model trained on literature data alone will be\nincomplete and require further data generation andne tuning.\nFurthermore, it is worth considering how these templatest\ninto a larger project for downstream synthesis outcome\npredictions and synthesis procedure recommendations. The\ndata extracted from literature can be used to pre-train models\nused for these purposes, while explicit experimental data can be\nused to further train the models to produce better predictions.\nThe new templates provided by the experimental results are\nFig. 9 A diagram showing the distributions of gold nanorod aspect\nratios resulting from diﬀerent precursor sets including the (a) standard\nprocedure, (b) the addition of HCl in the growth solution, and (c) all\ncomplete precursor sets. Negligible contributions for aspect ratios\nlarger than 20 are not shown (P(AR > 12) < 0.02). In each sub-diagram,\nthe median is shown with a solid black line and theﬁrst and third\nquartiles are shown with dashed black lines.\n© 2023 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 3 ,2,1 7 6 8–1782 | 1779\nPaper Digital Discovery\nOpen Access Article. Published on 20 September 2023. Downloaded on 11/5/2025 5:44:06 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nexpected to be of extremely high quality, which will mitigate the\nerrors present in the pre-training data from literature over time\nas more experimental results are added to the template\ndatabase.\nWhile this dataset is restricted to seed-mediated gold\nnanorod growth, the exibility and performance of the tem-\nplating approach using GPT-3 motivates application to other\ntasks for structured information retrieval from unstructured\nscientic text as has been shown in recent literature.\n62 To this\nend, the dataset can be extended to accommodate seed-\nmediated growth of other gold nanoparticle morphologies,\nwhich may even improve overall model performance, as many\nerrors were caused by the model erroneously extracting infor-\nmation from procedures that mentioned nanorod morphol-\nogies, but synthesized a diﬀerent morphology. Additionally,\nmore complex synthesis methods, such as three-step processes\nin which nanorods are rst synthesized via seed-mediated\ngrowth to be used as seeds in a growth solution for over-\ngrowth into nanowires, as well as other synthesis methods, such\nas citrate reduction, may require the creation of new templates\nand ne-tuning a separate model for each synthesis method to\nimprove overall performance. Generally, it can be expected that\nmore complex templates will require more examples forne-\ntuning.\n6 Conclusions\nThe presented model for static structured templating of seed-\nmediated gold nanorod growth procedures extracted from\nunstructured text using GPT-3 is demonstrated to be a prom-\nising approach for constructing high-quality structured data-\nbases of information from the scienti c literature. This\napproach for extracting seed-mediated gold nanorod proce-\ndures and outcomes achieves an impressive adjusted F1-score\nof 86% for the simultaneous identi cation and linking of\nsynthesis procedure components. We present anal dataset of\n11 644 entities extracted from 1137ltered papers, resulting in\n268 papers with at least one complete seed-mediated gold\nnanorod growth procedure and outcome for a total of 332\ncomplete procedures. This method can potentially be utilized\nfor many downstream applications including procedure\nsearches oriented around specic features, statistical analysis of\nsynthesis outcomes, synthesis outcome predictions condi-\ntioned on procedures, and synthesis procedure recommenda-\ntions conditioned on outcomes among others given the wealth\nof structured information present. Overall, we present this\napproach as aexible candidate for general-purpose structured\ndata extraction from unstructured scientic text and contribute\na dataset that may serve as a useful tool for investigating\nsynthesis pathways beyond heuristics.\nData and code availability\nThe data composed of DOIs and associated structured JSON\noutputs can be found online at https://doi.org/10.6084/\nm9.gshare.19719310.v4.\n88 The texts for the paragraphs in\neach paper are excerpted due to copyright restrictions.\nAuthor contributions\nA. J., G. C., and K. A. P. supervised the research. K. C. wrote the\ndata collection infrastructure, performed the data collection,\nand wrote and applied the initial gold nanoparticle article\nclassication and information extraction models. S. G. provided\nexperimental domain knowledge necessary for the template\ndesign. J. D. introduced the GPT-3 sequence-to-sequence\ninformation extraction methodology and prepared the graphic\nrepresentation of the extraction template. N. W. co-developed\nthe GPT-3 sequence-to-sequence information extraction meth-\nodology, designed the extraction templates, wrote the code for\ninterfacing with GPT-3, performed all annotations, performed\nall GPT-3 experiments, and prepared all results. S. L. performed\nne-tuning on Llama-2 for the benchmark and provided addi-\ntional result validation. All authors contributed to the discus-\nsion and writing of the manuscript.\nConﬂicts of interest\nThere are no conicts to declare.\nAcknowledgements\nThis work was funded and intellectually led by the U.S.\nDepartment of Energy, Oﬃce of Science, Oﬃce of Basic Energy\nSciences, Materials Sciences and Engineering Division under\nContract No. DE-AC02-05CH11231 (D2S2 program KCD2S2).\nAdditional funding used for data set generationvia the OpenAI\nAPI was provided by Toyota Research Institute through the\nAccelerated Materials Design and Discovery program. This\nresearch used resources of the National Energy Research\nScientic Computing Center (NERSC), a U.S. Department of\nEnergy Oﬃce of Science User Facility operated under Contract\nNo. DE-AC02-05CH11231. This work also used the Extreme\nScience and Engineering Discovery Environment (XSEDE) GPU\nresources, speci cally the Bridges-2 supercomputer at the\nPittsburgh Supercomputing Center, through allocation TG-\nDMR970008S.\n89\nNotes and references\n1 S. Mohan Bhagyaraj and O. S. Oluwafemi, Synthesis of\nInorganic Nanomaterials, Woodhead Publishing, 2018, pp.\n1–18.\n2 P. Colomban, M. Gironda, G. Simsek Franci and\nP. d’Abrigeon, Materials, 2022,15(16), 5747.\n3 S. Szunerits and R. Boukherroub,Encyclopedia of Interfacial\nChemistry, Elsevier, Oxford, 2018, pp. 500–510.\n4 S. E. Lohse and C. J. Murphy,Chem. Mater., 2013,25, 1250–\n1261.\n5 N. D. Burrows, S. Harvey, F. A. Idesis and C. J. Murphy,\nLangmuir, 2017,33, 1891–1907.\n6 L. Gou and C. J. Murphy,Chem. Mater., 2005,17, 3668–3672.\n7 P. K. Jain, X. Huang, I. H. El-Sayed and M. A. El-Sayed,Acc.\nChem. Res., 2008,41, 1578–1586.\n1780 | Digital Discovery,2 0 2 3 ,2,1 7 6 8–1782 © 2023 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 20 September 2023. Downloaded on 11/5/2025 5:44:06 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\n8 E. C. Dreaden, A. M. Alkilany, X. Huang, C. J. Murphy and\nM. A. El-Sayed,Chem. Soc. Rev., 2011,41, 2740–2779.\n9 S. Eustis and M. A. El-Sayed,Chem. Soc. Rev., 2006,35, 209–\n217.\n10 J. C. Hulteen and C. R. Martin,J. Mater. Chem., 1997,7, 1075–\n1087.\n11 K. Sandeep, B. Manoj and K. G. Thomas,J. Chem. Phys., 2020,\n152, 044710.\n12 M. Lau, A. Ziefuss, T. Komossa and S. Barcikowski,Phys.\nChem. Chem. Phys., 2015,17, 29311–29318.\n13 L. A. Dykman and N. G. Khlebtsov,Acta Nat., 2011,3,3 4–55.\n14 X. Huang and M. A. El-Sayed,J. Adv. Res., 2010,1,1 3–28.\n15 S. Kaul, N. Gulati, D. Verma, S. Mukherjee and U. Nagaich,J.\nPharm., 2018,2018, 3420204.\n16 K. I. Requejo, A. V. Liopo, P. J. Derry and E. R. Zubarev,\nLangmuir, 2017,33, 12681–12688.\n17 Y. C. Dong, M. Hajfathalian, P. S. N. Maidment, J. C. Hsu,\nP. C. Naha, S. Si-Mohamed, M. Breuilly, J. Kim, P. Chhour,\nP. Douek, H. I. Litt and D. P. Cormode,Sci. Rep., 2019, 9,\n14912.\n18 S. A. Ng, K. A. Razak, A. A. Aziz and K. Y. Cheong,J. Exp.\nNanosci., 2014,9,6 4–77.\n19 C. Daruich De Souza, B. Ribeiro Nogueira and\nM. E. C. Rostelato,J. Alloys Compd., 2019,798, 714–740.\n20 E. Agunloye, L. Panariello, A. Gavriilidis and L. Mazzei,\nChem. Eng. Sci., 2018,191, 318–331.\n21 M. L. Personick and C. A. Mirkin,J. Am. Chem. Soc., 2013,\n135, 18238–18247.\n22 M. Grzelczak, J. P´erez-Juste, P. Mulvaney and L. M. Liz-\nMarz´an, Colloidal Synth. Plasmonic Nanomet., 2020, 197–220.\n23 D. F. Mukhamedzyanova, N. K. Ratmanova, D. A. Pichugina\nand N. E. Kuz'menko,J. Phys. Chem. C, 2012, 116, 11507–\n11518.\n24 M. Domingo, M. Shahrokhi, I. N. Remediakis and N. Lopez,\nTop. Catal., 2018,61, 412–418.\n25 I. Chakraborty and T. Pradeep,Chem. Rev., 2017,117, 8208–\n8271.\n26 D. V. Talapin, A. L. Rogach, M. Haase and H. Weller,J. Phys.\nChem. B, 2001,105, 12278–12285.\n27 O. Kononova, T. He, H. Huo, A. Trewartha, E. A. Olivetti and\nG. Ceder,iScience, 2021,24, 102155.\n28 O. Kononova, H. Huo, T. He, Z. Rong, T. Botari, W. Sun,\nV. Tshitoyan and G. Ceder,Sci. Data, 2019,6, 203.\n29 S. Eltyeb and N. Salim,J. Cheminf., 2014,6, 17.\n30 P. Corbett and J. Boyle,J. Cheminf., 2018,10, 59.\n31 Z. Liang, J. Chen, Z. Xu, Y. Chen and T. Hao,Front. Artif.\nIntell., 2019,2,1 .\n32 A. Sniegula, A. Poniszewska-Maranda and L. Chomatek,\nProcedia Comput. Sci., 2019,160, 260–265.\n33 K. r. Kanakarajan, B. Kundumani and M. Sankarasubbu,\nProceedings of the 20th Workshop on Biomedical Language\nProcessing, 2021, pp. 143–154.\n34 L. Weston, V. Tshitoyan, J. Dagdelen, O. Kononova,\nA. Trewartha, K. Persson, G. Ceder and A. Jain,J. Chem.\nInf. Model., 2019,59, 3692–3702.\n35 T. He, W. Sun, H. Huo, O. Kononova, Z. Rong, V. Tshitoyan,\nT. Botari and G. Ceder,Chem. Mater., 2020,32, 7861–7873.\n36 K. Hatakeyama-Sato and K. Oyaizu,Commun. Mater., 2020,1,\n49.\n37 O. Kononova, T. He, H. Huo, A. Trewartha, E. A. Olivetti and\nG. Ceder,iScience, 2021,24, 102155.\n38 E. A. Olivetti, J. M. Cole, E. Kim, O. Kononova, G. Ceder,\nT. Y.-J. Han and A. M. Hiszpanski,Applied Physics Reviews,\n2020, 7, 041317.\n39 T. Dieb, M. Yoshioka, S. Hara and M. Newton,Beilstein J.\nNanotechnol., 2015,6, 1872–1882.\n40 M. Gaultois, T. Sparks, C. Borg, R. Seshadri, W. Bonicio and\nD. Clarke,Chem. Mater., 2013,25, 2911–2920.\n41 N. Pang, L. Qian, W. Lyu and J.-D. Yang,Transfer Learning for\nScientic Data Chain Extraction in Small Chemical Corpus with\nBERT-CRF Model, 2019.\n42 P. Corbett and A. Copestake,BMC Bioinf., 2008,9, S4.\n43 M. Krallinger, O. Rabal, A. Lourenço, J. Oyarzabal and\nA. Valencia,Chem. Rev., 2017,117, 7673–7761.\n44 T. Rockt¨aschel, M. Weidlich and U. Leser, Bioinformatics,\n2012, 28, 1633–1640.\n45 M. Krallinger, O. Rabal, F. Leitner, M. Vazquez, D. Salgado,\net al., J. Cheminformatics, 2015,7, S2.\n46 R. Leaman, C.-H. Wei and Z. Lu,J. Cheminformatics, 2015,7,\nS3.\n47 I. Korvigo, M. Holmatov, A. Zaikovskii and M. Skoblov,J.\nCheminformatics, 2018,10, 28.\n48 M. Garc´ıa-Remesal, A. Garc´ıa-Ruiz, D. P´erez-Rey, D. De La\nIglesia and V. Maojo,Biomed Res. Int., 2013,2013, 410294.\n49 A. Trewartha, N. Walker, H. Huo, S. Lee, K. Cruse,\nJ. Dagdelen, A. Dunn, K. A. Persson, G. Ceder and A. Jain,\nPatterns, 2022,3, 100488.\n50 A. M. Bran, S. Cox, A. D. White and P. Schwaller,\nChemCrow:\nAugmenting large-language models with chemistry tools, 2023,\nhttps://arxiv.org/abs/2304.05376.\n51 M. C. Ramos, S. S. Michtavy, M. D. Porosoﬀ and A. D. White,\nBayesian Optimization of Catalysts With In-context Learning,\n2023, https://arxiv.org/abs/2304.05341.\n52 A. D. White, G. M. Hocky, H. A. Gandhi, M. Ansari, S. Cox,\nG. P. Wellawatte, S. Sasmal, Z. Yang, K. Liu, Y. Singh and\nW. J. Peña Ccoa,Digital Discovery, 2023,2, 368–376.\n53 F. Ren, L. Ward, T. Williams, K. J. Laws, C. Wolverton,\nJ. Hattrick-Simpers and A. Mehta, Sci. Adv. , 2018, 4,\neaaq1566.\n54 C. C. Fischer, K. J. Tibbetts, D. Morgan and G. Ceder,Nat.\nMater., 2006,5, 641–646.\n55 L. Weston, V. Tshitoyan, J. Dagdelen, O. Kononova,\nA. Trewartha, K. A. Persson, G. Ceder and A. Jain,J. Chem.\nInf. Model., 2019,59, 3692–3702.\n56 X. Wang, J. Li, H. D. Ha, J. C. Dahl, J. C. Ondry, I. Moreno-\nHernandez, T. Head-Gordon and A. P. Alivisatos,JACS Au,\n2021, 1, 316–327.\n57 N. J. Szymanski, C. J. Bartel, Y. Zeng, Q. Tu and G. Ceder,\nChem. Mater., 2021,33, 4204–4215.\n58 X. Yan, A. Sedykh, W. Wang, B. Yan and H. Zhu, Nat.\nCommun., 2020,11, 2519.\n59 K. Cruse, A. Trewartha, S. Lee, Z. Wang, H. Huo, T. He,\nO. Kononova, A. Jain and G. Ceder,Sci. Data, 2022,9, 234.\n© 2023 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 3 ,2,1 7 6 8–1782 | 1781\nPaper Digital Discovery\nOpen Access Article. Published on 20 September 2023. Downloaded on 11/5/2025 5:44:06 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\n60 I. Sutskever, O. Vinyals and Q. V. Le,Sequence to Sequence\nLearning with Neural Networks, 2014, https://arxiv.org/abs/\n1409.3215.\n61 T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan,\nP. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell,\net al., Adv. Neural Inf. Process. Syst., 2020,33, 1877–1901.\n62 A. Dunn, J. Dagdelen, N. Walker, S. Lee, A. S. Rosen,\nG. Ceder, K. Persson and A. Jain, Structured information\nextraction from complex scientic text with ne-tuned large\nlanguage models, 2022,https://arxiv.org/abs/2212.05238.\n63 H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi,\nY. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale,\nD. Bikel, L. Blecher, C. C. Ferrer, M. Chen, G. Cucurull,\nD. Esiobu, J. Fernandes, J. Fu, W. Fu, B. Fuller, C. Gao,\nV. Goswami, N. Goyal, A. Hartshorn, S. Hosseini, R. Hou,\nH. Inan, M. Kardas, V. Kerkez, M. Khabsa, I. Kloumann,\nA. Korenev, P. S. Koura, M.-A. Lachaux, T. Lavril, J. Lee,\nD. Liskovich, Y. Lu, Y. Mao, X. Martinet, T. Mihaylov,\nP. Mishra, I. Molybog, Y. Nie, A. Poulton, J. Reizenstein,\nR. Rungta, K. Saladi, A. Schelten, R. Silva, E. M. Smith,\nR. Subramanian, X. E. Tan, B. Tang, R. Taylor, A. Williams,\nJ. X. Kuan, P. Xu, Z. Yan, I. Zarov, Y. Zhang, A. Fan,\nM. Kambadur, S. Narang, A. Rodriguez, R. Stojnic,\nS. Edunov and T. Scialom,Llama 2: Open Foundation and\nFine-Tuned Chat Models, 2023.\n64 H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux,\nT. Lacroix, B. Rozi `ere, N. Goyal, E. Hambro, F. Azhar,\nA. Rodriguez, A. Joulin, E. Grave and G. Lample,LLaMA:\nOpen and Eﬃcient Foundation Language Models, 2023.\n65 J. Su, Y. Lu, S. Pan, A. Murtadha, B. Wen and Y. Liu,\nRoFormer: Enhanced Transformer with Rotary Position\nEmbedding, 2022.\n66 J. Su, Y. Lu, S. Pan, A. Murtadha, B. Wen and Y. Liu,\nRoFormer: Enhanced Transformer with Rotary Position\nEmbedding, 2022.\n67 B. Zhang and R. Sennrich, Root Mean Square Layer\nNormalization, 2019.\n68 J. L. Ba, J. R. Kiros and G. E. Hinton,Layer Normalization,\n2016.\n69 Z. Wang, O. Kononova, K. Cruse, T. He, H. Huo, Y. Fei,\nY. Zeng, Y. Sun, Z. Cai, W. Sun and G. Ceder,Dataset of\nSolution-based Inorganic Materials Synthesis Recipes\nExtracted from the Scientic Literature, 2021, DOI:10.48550/\narXiv.2111.10874.\n70 K. Cruse, A. Trewartha, S. Lee, Z. Wang, H. Huo, T. He,\nO. Kononova, A. Jain and G. Ceder, Text-mined AuNP\nSynthesis Recipes Dataset , gshare, 2021, DOI: 10.6084/\nm9.gshare.16614262.v3.\n71 A. Radford, K. Narasimhan, T. Salimans and I. Sutskever,\nOpenAI Assets Research Covers , 2018, https://s3-us-west-\n2.amazonaws.com/openai-assets/research-covers/language-\nunsupervised/language_understanding_paper.pdf.\n72 A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever,\net al., OpenAI blog, 2019, vol. 1, p. 9.\n73 E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang,\nL. Wang and W. Chen,LoRA: Low-Rank Adaptation of Large\nLanguage Models, 2021.\n74 S. Mangrulkar, S. Gugger, L. Debut, Y. Belkada and S. Paul,\nPEFT: State-of-the-art Parameter-E\nﬃcient Fine-Tuning\nmethods, https://github.com/huggingface/pe, 2022.\n75 https://huggingface.co/meta-llama/Llama-2-13b-hf.\n76 M. Ma, H. Chen, Y. Chen, X. Wang, F. Chen, X. Cui and J. Shi,\nBiomaterials, 2012,33, 989–998.\n77 K. W. Smith, H. Zhao, H. Zhang, A. S ´anchez-Iglesias,\nM. Grzelczak, Y. Wang, W.-S. Chang, P. Nordlander,\nL. M. Liz-Marz´an and S. Link, ACS Nano, 2016, 10, 6180–\n6188.\n78 M. Zareie, X. Xu and M. Cortie,Small, 2007,3, 139–145.\n79 X. Huang, S. Neretina and M. A. El-Sayed,Adv. Mater., 2009,\n21, 4880–4910.\n80 P. J. Rousseeuw,J. Am. Stat. Assoc., 1984,79, 871–880.\n81 F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,\nB. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss,\nV. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau,\nM. Brucher, M. Perrot and E. Duchesnay,J. Mach. Learn.\nRes., 2011,12, 2825–2830.\n82 L. Vigderman and E. R. Zubarev,Chem. Mater., 2013, 25,\n1450–1457.\n83 L. Feng, Z. Xuan, J. Ma, J. Chen, D. Cui, C. Su, J. Guo and\nY. Zhang,J. Exp. Nanosci., 2015,10, 258–267.\n84 N. D. Burrows, S. Harvey, F. A. Idesis and C. J. Murphy,\nLangmuir, 2017,33, 1891–1907.\n85 Y. Wang, Y. Guo, Y. Shen, R. Chen, F. Wang, D. Zhou and\nD. Zhou,J. Nanosci. Nanotechnol., 2016,16, 1194–1201.\n86 Y. Wang, Y. Guo, Y. Shen, R. Chen, F. Wang, D. Zhou and\nS. Guo,J. Nanosci. Nanotechnol., 2016,16, 1194–1201.\n87 M.-Z. Wei, T.-S. Deng, Q. Zhang, Z. Cheng and S. Li,ACS\nOmega, 2021,6, 9188–9195.\n88 N. Walker, S. Leee, J. Dagdelen, K. Cruse, S. Gleason,\nA. Dunn, G. Ceder, A. P. Alivisatos, K. A. Persson and\nA. Jain, Seed-mediated AuNR Synthesis Extraction Dataset,\ngshare, 2023, DOI:10.6084/m9.gshare.19719310.v4.\n89 J. Towns, T. Cockerill, M. Dahan, I. Foster, K. Gaither,\nA. Grimshaw, V. Hazlewood, S. Lathrop, D. Li a,\nG. D. Peterson, R. Roskies, J. R. Scott and N. Wilkins-\nDiehr, Comput. Sci. Eng., 2014,16,6 2–74.\n1782 | Digital Discovery,2 0 2 3 ,2,1 7 6 8–1782 © 2023 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 20 September 2023. Downloaded on 11/5/2025 5:44:06 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online"
}