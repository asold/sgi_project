{
    "title": "Process Model Generation from Natural Language Text",
    "url": "https://openalex.org/W207431025",
    "year": 2011,
    "authors": [
        {
            "id": "https://openalex.org/A1976490793",
            "name": "Fabian Friedrich",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1983458687",
            "name": "Jan Mendling",
            "affiliations": [
                "Humboldt-Universität zu Berlin"
            ]
        },
        {
            "id": "https://openalex.org/A10948935",
            "name": "Frank Puhlmann",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1976490793",
            "name": "Fabian Friedrich",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1983458687",
            "name": "Jan Mendling",
            "affiliations": [
                "Humboldt-Universität zu Berlin"
            ]
        },
        {
            "id": "https://openalex.org/A10948935",
            "name": "Frank Puhlmann",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W1995020124",
        "https://openalex.org/W4300443083",
        "https://openalex.org/W2110233627",
        "https://openalex.org/W2491184078",
        "https://openalex.org/W2094061585",
        "https://openalex.org/W4213168938",
        "https://openalex.org/W2081580037",
        "https://openalex.org/W1977690542",
        "https://openalex.org/W1591454593",
        "https://openalex.org/W2018548278",
        "https://openalex.org/W1546067594",
        "https://openalex.org/W2115913160",
        "https://openalex.org/W3138806801",
        "https://openalex.org/W2113667150",
        "https://openalex.org/W2097031422",
        "https://openalex.org/W2000192013",
        "https://openalex.org/W2115097704",
        "https://openalex.org/W1508868039",
        "https://openalex.org/W1976528411",
        "https://openalex.org/W1571053548",
        "https://openalex.org/W2502872610",
        "https://openalex.org/W2042759024",
        "https://openalex.org/W1552362697",
        "https://openalex.org/W2160076849",
        "https://openalex.org/W1572567744",
        "https://openalex.org/W199397999",
        "https://openalex.org/W2294105941",
        "https://openalex.org/W2914605928",
        "https://openalex.org/W2489317052",
        "https://openalex.org/W1535626946",
        "https://openalex.org/W139524057",
        "https://openalex.org/W1501915067",
        "https://openalex.org/W2115792525",
        "https://openalex.org/W2466582251",
        "https://openalex.org/W2070712885",
        "https://openalex.org/W613770862",
        "https://openalex.org/W2142708806",
        "https://openalex.org/W1632114991",
        "https://openalex.org/W2063680323",
        "https://openalex.org/W1510500055"
    ],
    "abstract": null,
    "full_text": "Process Model Generation from\nNatural Language Text\nFabian Friedrich1, Jan Mendling2, and Frank Puhlmann1\n1 inubit AG, Sch¨oneberger Ufer 89-91, 10785 Berlin, Germany\n{Fabian.Friedrich,Frank.Puhlmann}@inubit.com\n2 Humboldt-Universit¨at zu Berlin, Unter den Linden 6, 10099 Berlin, Germany\njan.mendling@wiwi.hu-berlin.de\nAbstract. Business process modeling has become an important tool for\nmanaging organizational change and for capturing requirements of soft-\nware. A central problem in this area is the fact that the acquisition of as-is\nmodels consumes up to 60% of the time spent on process management\nprojects. This is paradox as there are often extensive documentations\navailable in companies, but not in a ready-to-use format. In this pa-\nper, we tackle this problem based on an automatic approach to generate\nBPMN models from natural language text. We combine existing tools\nfrom natural language processing in an innovative way and augmented\nthem with a suitable anaphora resolution mechanism. The evaluation of\nour technique shows that for a set of 47 text-model pairs from industry\nand textbooks, we are able to generate on average 77% of the models\ncorrectly.\n1 Introduction\nBusiness process management is a discipline which seeks to increase the eﬃ-\nciency and eﬀectiveness of companies by holistically analyzing and improving\nbusiness processes across departmental boundaries. In order to be able to ana-\nlyze a process, a thorough understanding of it is required ﬁrst. The necessary\nlevel of insight can be obtained by creating a formal model for a given business\nprocess.\nThe required knowledge for constructing process models has to be made ex-\nplicit by actors participating in the process [1]. However, these actors are usually\nnot qualiﬁed to create formal models themselves [2]. For this reason, modeling\nexperts are employed to iteratively formalize and validate process models in col-\nlaboration with the domain experts. This traditional procedure of extracting\nprocess models involves interviews, m eetings, or workshops [3]. It entails con-\nsiderable time and costs due to ambiguities or misunderstandings between the\ninvolved participants [4]. Therefore, the initial elicitation of conceptual models\nis considered to be a knowledge acquisition bottleneck [5]. According to Herbst\n[1] the acquisition of the as-is model in a workﬂow project requires 60% of the\ntotal time spent. Accordingly, substantial savings are possible by providing ap-\npropriate tool support to speed up the acquisition phase.\nH. Mouratidis and C. Rolland (Eds.): CAiSE 2011, LNCS 6741, pp. 482–496, 2011.\nc⃝ Springer-Verlag Berlin Heidelberg 2011\nProcess Model Generation from Natural Language Text 483\nIn this context, it is a paradox that acquisition is costly although detailed\ninformation about processes is often already available in the form of informal\ntextual speciﬁcations. Such textual documents can be policies, reports, forms,\nmanuals, content of knowledge management systems, and e-mail messages. Con-\ntent management professionals estimated that 85% of the information in com-\npanies is stored in such an unstructured format [6]. Moreover, the amount of\nunstructured text is growing at a much faster rate than structured data [7]. It\nseems reasonable to assume that these texts are relevant sources of information\nfor the construction of conceptual models.\nIn this paper, we develop an approach to directly extract business process\nmodels from textual descriptions. Our contribution is a corresponding technique\nthat does not make any assumptions about the structure of the provided text. We\ncombine an extensive set of tools from natural language processing (NLP) in an\ninnovative way and augment it with an anaphora resolution mechanism, which\nwas particularly developed for our approach. The evaluation of our technique\nwith a set of 47 text-model pairs from industry and textbooks reveals that on\naverage 77% of the model is correctly generated. We furthermore discuss current\nlimitations and directions of improvement.\nThe paper is structured as follows. Section 2 introduces the foundations of\nour approach, namely BPMN process models and natural language processing\ntechniques. Section 3 identiﬁes a set of l anguage processing requirements, and\nillustrates how they are tackled in the various steps of our generation approach.\nSection 4 presents our evalua t i o nr e s u l t sb a s e do nas a m p l eo ft e x t - m o d e lp a i r s .\nSection 5 discusses related work before Section 6 concludes the paper.\n2 Background\nGenerating models builds on understanding the essential concepts of BPMN\nprocess models and of state-of-the-art techniques for natural language processing.\nIn this section, we introduce BPMN and then natural language processing tools.\nThe Business Process Model and Notation (BPMN) is a standard for process\nmodeling that has been recently published in its version 2.0 [8]. It includes four\ncategories of elements, namely Flow Objects (Activities, Events and Gateways),\nSwimlanes (Pools and Lanes), Artifacts (e.g. Data Objects, Text Annotations\nor Groups), and Connecting Objects (Sequence Flows, Message Flows and Asso-\nciations). The ﬁrst three are nodes, the latter ones are edges. Figure 1 shows a\nBPMN example of a claims handling process provided by QUT. The process is\nsubdivided into three pools (one with two lanes) capturing the actors of the pro-\ncess. Activities are depicted as rounded boxes. Diﬀerent events (round elements\nwith icons) for sending and receiving messages aﬀect the execution of the process.\nThe diamond-shaped elements deﬁne speciﬁc routing behavior as gateways.\nA BPMN process model is typically the res ult of analyzing textual descrip-\ntions of a process. A claims handling process provided by QUT is described as\nfollows: “The process starts when a cu stomer submits a claim by sending in\nrelevant documentation. The Notiﬁcation department at the car insurer checks\n484 F. Friedrich, J. Mendling, and F. Puhlmann\nFig. 1. Example of a claims handling process in BPMN\nthe documents upon completeness and registers the claim. Then, the Handling\ndepartment picks up the claim and checks the insurance. Then, an assessment\nis performed. If the assessment is positive, a garage is phoned to authorise the\nrepairs and the payment is scheduled (in this order). Otherwise, the claim is re-\njected. In any case (whether the outcomeis positive or negative), a letter is sent\nto the customer and the process is considered to be complete.” Such information\nis usually provided by people working in the process and then formalized as a\nmodel by system analysts [2].\nFor our model generation approach, we will employ methods from compu-\ntational linguistics and natural language processing. This branch of artiﬁcial\nintelligence deals with analyzing and extracting useful information from natural\nlanguage texts or speech. For our approach, three concepts are of vital impor-\ntance: syntax parsing, which is the determination of a syntax tree and the gram-\nmatical relations between the parts of th e sentence; semantic analysis, which\nis the extraction of the meaning of words or phrases; and anaphora resolution,\nwhich involves the identiﬁcation of the concepts which are references using pro-\nnouns (“we”,“he”,“it”) and certain articles (“this”, “that”). For syntax parsing\nand semantic analysis, there are standard tools available.\nThe Stanford Parser is a syntax parsing tool for determining a syntax tree.\nThis tree shows the dependencies between the words of the sentence through the\ntree structure [10]. Additionally, each word and phrase is labeled with an appro-\npriate part-of-speech and phrase tag. The tags of the Stanford Parser are the\nsame which can be found in thePenn Tree Bank [11]. The Stanford Parser also\nproduces 55 diﬀerentStanford Dependencies [12]. These dependencies reﬂect the\ngrammatical relationships between the words. Such grammatical relations pro-\nvide an abstraction layer to the pure syntax tree. They also contain information\nabout the syntactic role of all elements.\nProcess Model Generation from Natural Language Text 485\nThere are also tools available for semantic analysis. They provide semantic\nrelations on diﬀerent levels of deta il. We use FrameNet [13] and the lexical\ndatabase WordNet[14]. WordNet provides various links to synonyms, homonyms,\nand hypernyms for a particular class of meaning associated with a synonym-set.\nFrameNet deﬁnes semantic relations thatare expected for speciﬁc words. These\nrelations are useful, e.g., to recognize that a verb “send” would usually go with\na particular object being sent. Syntax parsers and semantic analysis are used in\nour transformation approach, augmented with anaphora resolution.\n3 Transformation Approach\nThe most important issue we are facing when trying to build a system for gener-\nating models is the complexity of natural language. We collected issues related\nto the structure of natural language texts from the scientiﬁc literature and an-\nalyzed the test data, which is described in section 4. Thereby, we were able to\nidentify four broad categories of issues which we have to solve in order to ana-\nlyze natural language process descr iptions successfully (see Table 1). Syntactic\nLeeway relates to the fact that there is a mismatch between the semantic and\nsyntactic layer of a text. Atomicity deals with the question of how to construct\na proper phrase-activity mapping. Relevance has to check whether parts of the\ntext might be irrelevant for the generated process model. Finally, Referencing\naddresses the question of how to resolve relative references between words and\nbetween sentences.\nTable 1. References in the literature to the analyzed issues\nIssue Refs.\n Issue Refs.\n1 Syntactic Leeway\n 3 Relevance\n1.1 Active-Passive [15]\n 3.1 Relative Clause Importance [16]\n1.2 Rewording/Order [17,18]\n 3.2 Example Sentences [19]\n1.3 Implicit Conditions [20,21]\n 3.3 Meta-Sentences [16]\n2A t o m i c i t y\n 4 Referencing\n2.1 Complex Sentences [16,18]\n 4.1 Anaphora [22,23]\n2.2 Action Split over Sentences [22]\n 4.2 Textual Links [24]\n2.3 Relative Clauses [16]\n 4.3 End-of-block Recognition [19,16]\nDiﬀerent solution strategies were applied in the works listed in Table 1 to\novercome the stated problems, e.g. by constricting the format of the textual input\n[17], but no study considers all mentioned problems and oﬀers a comprehensive\nsolution strategy. Another interesting fact is that none of the works using a\nshallow parser shows how they deal with passive voice [15,22,23,17]. We solved\nthis problem by using the grammatical relations of the Stanford Parser.\nTo obtain a structured representation of the knowledge we extract from the\ntext, we decided to store it in a World Model, as opposed to a direct straight\n486 F. Friedrich, J. Mendling, and F. Puhlmann\nthrough model generation. This approach was also taken by most of the other\nworks which built a similar system [17,22,18,23]. The data structure used by the\napproach of the University of Rio de Janeiro [23] was taken from the CREWS\nproject [15]. The authors argue that it is suited well for this task as a scenario\ndescription corresponds to the description of a process model. Therefore, we also\nuse the CREWS scenario metamodel as s tarting point. However, we modiﬁed\nseveral parts as, e.g., we explicitly represent connections between the elements\nusing the class “Flow”. Additionally, we explicitly considered traceability as a\nrequirement. Thus, attributes relati ng an object to a sentence or a word are\nadded to the World Model. The four main elements of our World Model are\nActor, Resource, Action, and Flow. This World Model will be used throughout\nall phases of our transformation procedure to capture syntactic and semantic\nanalysis results. Each phase is allowed to access, modify and add data.\nThe rest of this section is dedicated to analyzing and discussing the issues\ncollected in Table 1. We will then seize thedeveloped suggestions and reference\nthese issues during the description of our transformation approach. Section 3.1\ndiscusses sentence level analysis for ﬁnding actions. Section 3.2 investigates text\nlevel analysis for enriching the data stored in the world model. Finally, Sec-\ntion 3.3 describes the generation o f a BPMN model. While we focus on the\ngeneral procedure here, we documented details of all algorithms in [25].\n3.1 Sentence Level Analysis\nThe ﬁrst step of our transformation procedure is a sentence level analysis. The\nextraction procedure consists of the steps that are outlined as a BPMN model\nin Figure 2. This overview also shows the diﬀerent components upon which our\ntransformation procedure builds and their usage of Data Sources.\nThe text is processed in several stages. First, a tokenization splits up the text\ninto individual sentences. The challenge here is to distinguish a period used for\nan abbreviation (e.g. M.Sc.) from a period marking the end of a sentence.\nFig. 2. Structural overview of the steps of the Sentence Level Analysis\nProcess Model Generation from Natural Language Text 487\nAfterwards, each sentence is parsed by theStanford Parser using the factored\nmodel for English [11]. We utilize the factored model and not the pure proba-\nbilistic context free grammar, because it provides better results in determining\nthe dependencies between markers as “ if” or “then”, which are important for\nthe process model generation. Next, complex sentences are split into individual\nphrases. This is accomplished by scanning for sentence tags on the top level of\nthe Parse Tree and within nested prepositional, adverbial, and noun phrases.\nOnce the sentence is broken down into individual constituent phrases, actions\ncan be extracted. First, w e determine whether the parsedSentence is in active\nor passive voice by searching for the appropriate grammatical relations (Issue\n1.1). Then, all Actors and Actions are extracted by analyzing the grammatical\nrelations. To overcome the problem of example sentences mentioned earlier (Issue\n3.2) the actions are also ﬁltered. This ﬁltering method simply checks whether the\nsentence contains a word of a stop word list calledexample indicators. Then, we\nextract all objects from the phrase and each Action is combined with each Object.\nThe same is done with all Actors. This procedure is necessary as an Action\nis supposed to be atomic according to the BPMN speciﬁcation [8] and Issue\n2.1. Therefore, a new Action has to be created for each piece of information as\nillustrated in the following example sentences. In each sentence the conjunction\nrelation which causes the extraction of several Actors, Actions or Resources is\nhighlighted. As a last step, all extracted Actions are added to the World Model.\n◦ “Likewise the old supplier creates and sends the ﬁnal billing to the cus-\ntomer.” (Action)\n◦ “It is given either bya sales representative or by a pre-sales employee\nin case of a more technical presentation.” (Actor)\n◦ “At this point, the Assistant Registry Manager puts the receipt and\ncopied documents into an envelope and posts it to the party.” (Resource)\n3.2 T ext Level Analysis\nThis section describes the text level an alysis. It analyzes the sentences taking\ntheir relationships into account. The structural overview of this phase is shown\nin Figure 3. We use the Stanford Parser and WordNet here, and also an anaphora\nresolution algorithm. During each of the ﬁve steps, the Actions previously added\nto the World Model are augmented with additional information.\nAn important part of the algorithm presented here is the determination heuris-\ntic for resolving relative references within the text (Issue 4.1). Existing libraries\nare not seamlessly integrateable with the output provided by the Stanford Parser.\nTherefore, we implemented a simple anaphora resolution technique for the reso-\nlution of determiner and pronouns. This procedure is described in detail in [25].\nAn experimental evaluation using our test data set showed that this approach\nachieved a good accuracy of 63.06%.\nThe second step in our analysis is the detection of conditional markers. These\nmarkers can either be a single word like “if”, “then”, “meanwhile” or “other-\nwise”, or a short phrase like “in the meantime” or “in parallel”. All of these\n488 F. Friedrich, J. Mendling, and F. Puhlmann\nFig. 3. Structural overview of the steps of the Text Level Analysis\nmarkers have speciﬁc characteristic s and can be mapped to diﬀerent BPMN\nconstructions. In order to capture this semantic information we compiled four\nlists, namely ConditionIndicators (exclusive gateway), ParallelIndicators (paral-\nlel gateway), ExceptionIndicators (for Error Intermediate Events), and Sequen-\nceIndicators (for the continuation of a branch of a gateway). These lists do not\nclaim completeness and can be extended by the user, if necessary.\nWe can use the information gathered so far to combine the information con-\ntained in two diﬀerent Actions. This pro cedure tackles the problem of Actions\nwhich are split up over several sentences(Issue 2.2). To consider two Actions as\na candidate for a merger, a reference had to be established between them during\nthe anaphora resolution phase. This reference can either directly point from the\nActor or from the Object of this Action. But, for the case that the Object points\nto another Actor or Resource we also consider the Action which contains it as\na possible candidate. Next, it is checked whether the objects can be merged by\nchecking various characteristics of bothActions. If the actions truly complement\neach other, they can be merged and form one single action. When both Actions\ncomplement each other except for the negation modiﬁer we can still enhance the\ninformation content of one action by copying information, as the initiating Actor,\nthe Object, and/or the copula attribute. An example for such a case are these\nsentences: “Of course, asking the customer whether he is generally interested is\nalso important.” and “If this is not the case, we leave him alone, [...]”\nFor Issue 4.2, we deﬁned three types of textual references: forward, backward,\nand jump references. In order to identify those links in the text automatically,\nwe start by comparing all actions within our World Model to one another. It\nis then determined whether the select ed actions can be linked or not. Within\nthis method, we compare the following characteristics of both Actions: Copula\nSpeciﬁer, Negation Status, the initiating Actor (ActorFrom), the Object, the\nopen clausal complement, and the Prepositional Speciﬁers, whose head word is\n“to” or “about”. The elements are compared using their root form provided by\nWordNet. If the elements diﬀer or an element is deﬁned for one Action, but\nnot for the other, the Actions cannot be merged. Otherwise, the Actions are\nconsidered equal and a link relationship can be established. Additionally, the\ntype of the link relationship is determined and saved along with the link.\nProcess Model Generation from Natural Language Text 489\nThe last step of the text level analysis is the generation of Flows. A ﬂow\ndescribes how activities are interacti ng with each other. Therefore, during the\nprocess model generation such Flows c an be translated to BPMN connecting\nobjects. When creating the Flows we build upon the assumption that a process\nis described sequentially and upon the information gathered in the previous steps.\nThe word, which connected the items isimportant to determine how to proceed\nand what type of gateway we have to create. So far we support a distinction\nbetween “or”, “and/or”, and “and”. Other conjunctions are skipped.\n3.3 Process Model Generation\nIn the last phase of our approach the information contained in the World Model\nis transformed into its BPMN representation. We follow a nine step procedure, as\ndepicted in Figure 3.3. The ﬁrst 4 steps: creation of nodes, building of Sequence\nFlows, removal of dummy elements, the ﬁnishing of open ends, and the processing\nof meta activities are used to create an initial and complete model. Optionally,\nthe model can be augmented by creating Black Box Pools and Data Objects.\nFinally, the model is laid out to achieve a human-readable representation.\nFig. 4. Structural overview of the steps of the Process Model Generation phase\nThe ﬁrst step required for the model creation is the construction of all nodes\nof the model. After the Flow Object was g enerated, we create a Lane Element\nrepresenting the Actor initiating the Action. If no Lane was determined for an\nAction, it is added to the last Lane which was created successfully as we assume\nthat the process is described in a seque ntial manner. The second step required\nduring the model creation is the construction of all edges. Due to the deﬁni-\ntion of Flows within our World Model, this transformation is straight-forward.\nWhenever a Flow which is not of the type “Sequence” is encountered, a Gate-\nway appropriate for the type of the ﬂow is created. An exception to that is the\n490 F. Friedrich, J. Mendling, and F. Puhlmann\ntype “Exception”. If the World Model contains a ﬂow of this type, an exception\nintermediate event is attached to the task which serves as a source and this In-\ntermediate Event is connected to the target instead of the node itself. We then\nskip dummy actions, which were inserte d between gateways directly following\neach other.\nStep four is concerned with open ends. So far, no Start and End Events\nwere created. This is accomplished in this step. The procedure is also straight\nforward. We create a preceding Start event to all Tasks which do not have any\npredecessors (in-ﬂow = 0) and succeeding End Events to all Tasks which do\nnot have any successors (out-ﬂow = 0). Additionally, Gateways whose in- and\nout-ﬂow is one receive an additional branch ending in an End Event.\nThe last step in the model creation phase handles Meta-Activities (Issue 3.3).\nWe search and remove redundant nodes directly adjacent to Start or End Events.\nThis is required as several texts contain sentences like “[...] the process ﬂow at\nthe customer also ends.” or “The process of “winning” a new customer ends\nhere.” If such sentences are not ﬁltered, we might ﬁnd tasks labeled “process\nends” right in front of an end event or “start workﬂow” following a start event.\nWe remove nodes whose verb is contained in the hypernym tree of “end” or\n“start” in WordNet if they are adjacent to a Start or End Event.\nThe execution of these ﬁve steps yields a full BPMN model. As the elements of\nthis model do not contain any position information yet, our generation procedure\nconcludes with an automated layout algorithm. We utilize a simple grid layout\napproach similar to [26], enhanced with standard layout graph layout algorithms\nas Sugiyama [27] and the topology-shape-metric approach [28]. For the example\ntext of the claims handling process from Section 2 we generated the model given\nin Figure 5. The question of how far this result can be considered to be accurate\nis discussed in the following section.\n4 Evaluation of Generated Process Models\nFor the validation of our approach, we co llected a test data set consisting of\n47 of those text-model pairs, each including a textual process description and\na corresponding BPMN models created b y a human modeler. Diﬀerent sources\nfrom research and practice were incorporated into our test data set: Academic\n(15 models), Industry (9 models), Textbook (9 models), and Public Sector (14\nmodels), see Table 2. While the academic pairs were provided by our university\npartners, the industry models are taken from two main sources. First, we gath-\nered four models from the websites of t hree BPM tool vendors, namely Active\nVOS, Oracle, and BizAgi. Four models stem from training material of inubit\nAG, another one from a German BPM practitioner, and further ones from two\nBPMN textbooks [29,9]. Finally, we included the deﬁnition of switch processes\nof the Federal Network Agencyof Germany in its semi-structured tabular format\nand the corresponding model.\nTo avoid unintended eﬀects while parsing, minor corrections were applied\nto the texts. Some models were translated, some were converted from other\nProcess Model Generation from Natural Language Text 491\nFig. 5. The claims handling model as generated by our system\nmodeling languages to BPMN in order to compare them. Table 2 lists character-\nistics of the texts and models of our data set. The table captures the following\ndata: a unique ID, the number of models (M), the number of sentences (n), the\naverage length of sentences (∅l), the size of the models in terms of nodes (|N |),\ngateways (|G|), and edges (|E|). All our material is published in [25].\nThe evaluation results are based on the similarity (sim) between the manually\nand automatically created models. We employ the metric ofGraph Edit Distance.\nTo compute the Graph Edit Distance, the graph representation of the process\nmodels is analyzed. The labels, attributes, the structural context, and behavior\nare compared [32]. Afterwards a greedy graph matching heuristic [33] is employed\nTable 2. Characteristics of the test data set by source (average values)\nID Source M Type n ∅l |N|| G|| E|\n1 HU Berlin 4 academic 10.00 18.14 25.75 6.00 24.50\n2 TU Berlin [30] 2 academic 34.00 21.17 71.00 9.50 79.50\n3 QUT 8 academic 6.13 18.26 14.88 1.88 16.00\n4 TU Eindhoven [31] 1 academic 40.00 18.45 38.00 8.00 37.00\n5 Vendor Tutorials 4 industry 9.00 18.20 14.00 2.25 11.50\n6 inubit AG 4 industry 11.50 18.38 24.00 4.25 21.25\n7 BPM Practicioners 1 industry 7.00 9.71 13.00 1.00 9.00\n8 BPMN Prac. Handbook [9] 3 textbook 4.67 17.03 13.00 1.33 14.67\n9 BPMN M&R Guide [29] 6 textbook 7.00 20.77 23.83 3.00 23.67\n10 FNA - Metrology Processes 14 public sector 6.43 13.95 24.43 3.14 25.93\nTotal 47 9.19 17.16 23.21 3.38 23.64\n\n492 F. Friedrich, J. Mendling, and F. Puhlmann\nto create pairs of nodes and edges. We use the greedy heuristic as it showed the\nbest performance without considerable accuracy trade-oﬀs. After the mapping\nis created, a Graph Edit Distance value can be calculated given:\n◦ Ni - set of nodes in model i\n◦ Ei - set of edges of model i\n◦\n Ni - the set of nodes in model i which were not mapped\n◦\n Ei - the set of edges in model i which were not mapped\n◦ M - The mapping between the nodes of model 1 and 2\nAn indicator for the diﬀerence between the models can be calculated as:\nm∗ =\n{ ∑ |M |\ni=1 1 − sim(Mi)i f |M | > 0\n1.0o t h e r w i s e (1)\nAs a last step weights for the importance of the diﬀerences ( wmap), the un-\nmapped Nodes (wuN), and the unmapped Edges (wuE) have to be deﬁned. For\nour experiments we gave the diﬀerence a slightly higher importance and assigned\nwmap =0 .4a n dwuN = wuE =0 .3. The overall graph edit distance then becomes:\nsim(m1,m 2)=1 − (wmap ∗ m∗\n|M | + wuN ∗\n |N1| +\n |N2|\n|N1| + |N2| + wuE ∗\n |E1| +\n |E2|\n|E1| + |E2|)( 2 )\nThis value ranges between 0 and 1. For the case that all nodes could be mapped\nwith a similarity of 1.0 the terms will also become 1.0. If the mapping is not\noptimal, the term in parenthesis will grow steadily and the similarity decreases.\nIf no nodes are mapped at all, the similarity will be 0.\nFor our evaluation, we generated the model for each text and calculated the\nsimilarity metric between it and the original BPMN model. The results are\nshown in Table 3. Columns 2-4 show that the concepts of meta sentences, relative\nreferences, and textual jumps are important for almost all elements within our\ntest data. The following six columns show the average values of nodes, gateways,\nTable 3. Result of the application of the evaluation metrics to the test data set\nID m r j |Ngen| Δ|Ngen|| Ggen| Δ|Ggen|| Egen| Δ|Egen| sim\n1 3 5,25 0 30,25 14,88% 5,50 -9,09% 28,75 14,78% 77,94%\n2 7,50 7,50 2,50 91,50 22,40% 13,00 26,92% 94,00 15,43% 70,79%\n3 0,50 1,38 0,00 20,25 26,54% 2,63 28,57% 20,13 20,50% 78,78%\n4 8,00 4,00 1,00 63,00 39,68% 1,00 -700,00% 52,00 28,85% 41,54%\n5 1,25 1,75 1,75 24,75 43,43% 4,25 47,06% 23,00 50,00% 63,63%\n6 2,25 8,00 0,50 29,75 19,33% 2,75 -54,55% 25,25 15,84% 60,93%\n7 0,00 5,00 0,00 14,00 7,14% 2,00 50,00% 11,00 18,18% 74,35%\n8 0,00 5,00 0,33 13,33 2,50% 1,00 -33,33% 10,33 -41,94% 77,49%\n9 0,83 1,50 0,33 22,33 -6,72% 3,33 10,00% 20,83 -13,60% 71,77%\n10 0,00 0,21 0,36 25,29 3,39% 3,71 15,38% 27,29 4,97% 89,81%\nTotal 1,23 2,60 0,49 27,43 15,36% 3,72 9,14% 26,77 11,69% 76,98%\n\nProcess Model Generation from Natural Language Text 493\nand edges within the generated models. We can see that the transformation\nprocedure tends to produce models which are on average 9-15% larger in size\nthen what a human would create. This can be partially explained by noise and\nmeta sentences which were not ﬁltered appropriately. On the other hand, humans\ntend to abstract during the process of modeling. Therefore, we often ﬁnd more\ndetail of the text also in the generated model. The results are highly encouraging\nas our approach is able to correctly recreate 77% of the model in average. On\na model level up to 96% of similarity ca n be reached, which means that only\nminor corrections by a human modeler are required.\nDuring the detailed analysis we determined diﬀerent sources of failure, which\nresulted in a decreased metric value. These are noise, diﬀerent levels of abstrac-\ntions, and processing problems within our system. Noise includes sentences or\nphrases that are not part of the process description, as for instance “This ob-\nject consists of data elements such as the customers name and address and the\nassigned power gauge.” While such information can be important for the under-\nstanding of a process, it leads to unwanted Activities within the generated model.\nTo tackle this problem, further ﬁltering mechanisms are required. Low similarity\nalso results from diﬀerence in the level of granularity. To solve this problem, we\ncould apply automated abstraction techniques like [34] on the generated model.\nFinally, the employed natural language processing components failedduring the\nanalysis. At stages, the Stanford Parser failed at correctly classifying verbs. For\ninstance, the parser classiﬁed “the seco nd activity checks and conﬁgures” as a\nnoun phrase, such that the verbs “check” and “conﬁgure” cannot be extracted\ninto Actions. Furthermore, important verbs related to business processes are\nnot contained in FrameNet, as “report”. Therefore, no message ﬂow is created\nbetween report activities and a Black Box Pool. We expect this problem to\nbe solved in the future as the FrameNet database grows. With WordNet, for\ninstance, there is a problem with times like “2:00 pm”, where pm as an abbre-\nviation for “Prime Minister” is classiﬁed as an Actor. To solve this problem a\nreliable sense disambiguation has to be conducted. Nevertheless, overall good\nresults were achieved by using WordNet as a general purpose Ontology.\n5 Related Work\nRecently, there is an increasing interest in the derivation of conceptual models\nfrom text. This research is mainly conducted by six diﬀerent groups.\nTwo approaches generate UML models. The Klagenfurt Conceptual Pre-design\nModel and a corresponding tool are used to parse German text and ﬁll instances\nof a generic meta-model [35]. The stored information can be transformed to UML\nactivity diagrams and class diagrams [18]. The transformation from text to the\nmeta-model requires the user to make d ecisions about the relevant parts of a\nsentence. In contrast to that, the approach described in [36] is fully automated.\nIt uses use-case descriptions in a format called RUCM to generate activity di-\nagrams and class diagrams [17]. Yet, the system is not able to parse free-text.\nThe RUCM input is required to be in a restricted format allowing only 26 types\n494 F. Friedrich, J. Mendling, and F. Puhlmann\nof sentence structures, which rely on keywords like “VALIDATES THAT” or\n“MEANWHILE”. Therefore, it can hardly be used in the initial process deﬁni-\ntion phase as it would require rewriting of process-relevant documents.\nThe University of Rio de Janeiro focuses on the derivation of BPMN models\nfrom group stories provided in Portuguese [23]. The approach was tested with\na course enrollment process modeled by students. The examples in their paper\nshow that process models can be created s uccessfully, but a couple of their ex-\nhibits show that syntactical problems can occur, e.g. implicit conditions, which\nwe explicitly tackle with our approach. The R-BPD toolkit from the Univer-\nsity of Wollongong uses a syntax parser to identify verb-object phrases [21]. It\nalso identiﬁes textual patterns like “If<condition/event>,[ t h e n ]<action>”[ 2 0 ] .\nThe result are rather BPMN snippets thanfully connected models. Nevertheless,\nthis toolkit is able to take existing models into account for cross validation.\nA ﬁfth approach is the one of Policy-Driven Process Mapping [37]. First, a\nprocedure was developed which creates a BPMN diagram, given that data items,\ntasks, resources (actors), and constraints are identiﬁed in an input text document.\nAlthough the approach does not require a process description to be sequential,\nit does not support Pools, Data Objects, and Gateways other than an exclusive\nsplit. Furthermore, user-interaction is required at several stages.\nThe approach by Sinha et al. builds on a linguistic analysis pipeline [22,38].\nFirst, text is preprocessed with a part-of-speech tagger. Next, words are anno-\ntated with dictionary concepts, which classify verbs using a domain ontology.\nThen, an anaphora resolution algorithm and a context annotator are applied.\nThe resulting information is then transferred to a Use Case Description meta-\nmodel and later into a BPMN process model. The dictionary concepts, which\nare a vital part of their approach, rely on a domain ontology which has to be\nhand-crafted. This imposes a manual eﬀort when transferring the system to other\ntypes of texts or languages. Instead, our approach builds on the free WordNet\nand FrameNet lexical databases, which are available for diﬀerent languages.\n6C o n c l u s i o n\nIn this paper, we presented an automatic approach to generate BPMN mod-\nels from natural language text. We have combined existing tools from natural\nlanguage processing in an innovative way and augmented them with a suitable\nanaphora resolution mechanism. The evaluation of our technique shows that for\na set of 47 text-model pairs from industry and textbooks, we are able to generate\non average 77% of the models correctly.\nDespite these encouraging results, we still require empirical user studies. Such\nstudies should investigate whether humans ﬁnd the generated models useful and\neasy to adapt towards a fully accurate model. Furthermore, our system is able to\nread process descriptions consisting of full sentences. Furthermore, we assumed\nthe description to be sequential and to contain no questions and little process-\nirrelevant information. Another prerequisite is that the text is grammatically\ncorrect and constituent. Thus, the parsing of structured input, like tables or\nProcess Model Generation from Natural Language Text 495\ntexts making use of indentions, or texts which are of low quality is not possible\nat the moment and presents opportunities for further research.\nWhile the evaluation conducted in this thesis evinced encouraging results\ndiﬀerent lines of research could be pursued in order to enhance the quality or\nscope of our process model generation procedure. As shown the occurrence of\nmeta-sentences or noise in general is one of the severest problems aﬀecting the\ngeneration results. Therefore, we coul d improve the quality of our results by\nadding further rules and heuristics to identify such noise. Another major source\nof problems was the syntax parser we employed. As an alternative, semantic\nparsers like [39] could be investigated.\nReferences\n1. Herbst, J., Karagiannis, D.: An inductive approach to the acquisition and adapta-\ntion of workﬂow models. In: Proceedings of the IJCAI, pp. 52–57 (1999)\n2. Frederiks, P., Van der Weide, T.: Information modeling: the process and the\nrequired competencies of its participant s. Data & Knowledge Engineering 58(1),\n4–20 (2006)\n3. Scheer, A.: ARIS-business process modeling. Springer, Heidelberg (2000)\n4. Reijers, H., Limam, S., Van Der Aalst, W.: Product-based workﬂow design. Journal\nof Management Information Systems 20(1), 229–262 (2003)\n5. Gruber, T.: Automated knowledge acquisition for strategic knowledge. Machine\nLearning 4(3), 293–336 (1989)\n6. Blumberg, R., Atre, S.: The problem with unstructured data. DM Review 13, 42–49\n(2003)\n7. White, M.: Information overlook. EContent(26:7) (2003)\n8. OMG, eds.: Business Process Model and Notation (BPMN) Version 2.0 (June 2010)\n9. Freund, J., R¨ucker, B., Henninger, T.: Praxishandbuch BPMN. Hanser (2010)\n10. Melˇcuk, I.: Dependency syntax: theory and practice, New York (1988)\n11. Marcus, M., Marcinkiewicz, M., Santorini, B.: Building a large annotated corpus\nof English: The Penn Treebank. Computational Linguistics 19(2), 330 (1993)\n12. de Marneﬀe, M., Manning, C.: The Stanford typed dependencies representation.\nIn: Workshop on Cross-Framework and Cross-Domain Parser Evaluation, pp. 1–8\n(2008)\n13. Baker, C., Fillmore, C., Lowe, J.: The berkeley framenet project. In: 17th Int. Conf.\non Computational Linguistics, pp. 86–90 (1998)\n14. Miller, G.A.: Wordnet: A lexical database for english. CACM 38(11), 39–41 (1995)\n15. Achour, C.B.: Guiding scenario authoring. In: 8th European-Japanese Conference\non Information Modelling and Knowledge Bases, pp. 152–171. IOS Press, Amster-\ndam (1998)\n16. Li, J., Wang, H., Zhang, Z., Zhao, J.: A policy-based process mining framework:\nmining business policy texts for discovering process models. ISEB 8(2), 169–188\n17. Yue, T., Briand, L., Labiche, Y.: An Automated Approach to Transform Use Cases\ninto Activity Diagrams. Modelling Foundations and Appl., 337–353 (2010)\n18. Fliedl, G., Kop, C., Mayr, H., Salbrechter, A., V¨ohringer, J., Weber, G., Winkler,\nC.: Deriving static and dynamic concepts from software requirements using sophis-\nticated tagging. Data & Knowledge Engineering 61(3), 433–448 (2007)\n19. Kop, C., Mayr, H.: Conceptual predesign–bridging the gap between requirements\nand conceptual design. In: 3rd Int. Conf. on Requirements Eng. p. 90 (1998)\n496 F. Friedrich, J. Mendling, and F. Puhlmann\n20. Ghose, A., Koliadis, G., Chueng, A.: Process Discovery from Model and Text Arte-\nfacts. In: 2007 IEEE Congress on Services, pp. 167–174 (2007)\n21. Ghose, A.K., Koliadis, G., Chueng, A.: Rapid business process discovery (R-BPD).\nIn: Parent, C., Schewe, K.-D., Storey, V.C., Thalheim, B. (eds.) ER 2007. LNCS,\nvol. 4801, pp. 391–406. Springer, Heidelberg (2007)\n22. Sinha, A., Paradkar, A., Kumanan, P., Boguraev, B.: An Analysis Engine for\nDependable Elicitation on Natural Language Use Case Description and its Ap-\nplication to Industrial Use Cases. Technical report, IBM (2008)\n23. de AR Gon¸calves, J.C., Santoro, F.M., Bai˜ao, F.A.: A case study on designing pro-\ncesses based on collaborative and mining approaches. In: Int. Conf. on Computer\nSupported Cooperative Work in Design, Shanghai, China (2010)\n24. Fliedl, G., Kop, C., Mayr, H.: From textual scenarios to a conceptual schema. Data\n& Knowledge Engineering 55(1), 20–37 (2005)\n25. Friedrich, F.: Automated generation of business process models from natural\nlanguage input. Master’s thesis, Humboldt-Universit¨at zu Berlin (November 2010)\n26. Kitzmann, I., Konig, C., Lubke, D., Singer, L.: A Simple Algorithm for Automatic\nLayout of BPMN Processes. In: IEEE Conf. CEC, pp. 391–398 (2009)\n27. Seemann, J.: Extending the sugiyama algorithm for drawing UML class diagrams:\nTowards automatic layout of object-oriented software diagrams. In: Graph Drawing,\npp. 415–424. Springer, Heidelberg (1997)\n28. Eiglsperger, M., Kaufmann, M., Siebenhaller, M.: A topology-shape-metrics\napproach for the automatic layout of UML class diagrams. In: Proceedings of the\n2003 ACM Symposium on Software Visualization, p. 189. ACM, New York (2003)\n29. White, S., Miers, D.: BPMN Modeling and Reference Guide: Understanding and\nUsing BPMN. Future Strategies Inc. (2008)\n30. Holschke, O.: Impact of granularity on adjustment behavior in adaptive reuse of\nbusiness process models. In: Hull, R., Mendling, J., Tai, S. (eds.) BPM 2010. LNCS,\nvol. 6336, pp. 112–127. Springer, Heidelberg (2010)\n31. Reijers, H.: Design and control of workﬂow processes: business process management\nfor the service industry. Eindhoven University Press (2003)\n32. Dijkman, R., Dumas, M., van Dongen, B., K¨a¨arik, R., Mendling, J.: Similarity of\nbusiness process models: Metrics and evaluation. Inf. Sys. 36, 498–516 (2010)\n33. Dijkman, R., Dumas, M., Garcıa-Banuelos, L., K¨ a¨arik, R.: Graph Matching\nAlgorithms for Business Process Model Similarity Search. In: Dayal, U., Eder, J.,\nKoehler, J., Reijers, H.A. (eds.) BPM 2009. LNCS, vol. 5701, pp. 48–63. Springer,\nHeidelberg (2009)\n34. Polyvyanyy, A., Smirnov, S., Weske, M.: On application of structural decomposi-\ntion for process model abstraction. In: 2nd Int. Conf. BPSC, pp. 110–122 (March\n2009)\n35. Kop, C., V¨ohringer, J., H¨olbling, M., Horn, T., Irrasch, C., Mayr, H.: Tool Sup-\nported Extraction of Behavior Models. In: Proc. 4th Int. Conf. ISTA (2005)\n36. Yue, T., Briand, L., Labiche, Y.: Automatically Deriving a UML Analysis Model\nfrom a Use Case Model. Technical report, Carleton University (2009)\n37. Wang, H.J., Zhao, J.L., Zhang, L.J.: Policy-Driven Process Mapping (PDPM):\nDiscovering process models from business policies. DSS 48(1), 267–281 (2009)\n38. Sinha, A., Paradkar, A.: Use Cases to Process Speciﬁcations in Business Process\nModeling Notation. In: 2010 IEEE Int. Conf. on Web Services, pp. 473–480 (2010)\n39. Shi, L., Mihalcea, R.: Putting Pieces Together: Combining FrameNet, VerbNet and\nWordNet for Robust Semantic Parsing. In: Proceedings of the 6th Int. Conf. on\nComputational Linguistics and Intelligent Text Processing, p. 100 (2005)"
}