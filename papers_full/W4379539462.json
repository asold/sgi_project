{
  "title": "Graph Transformer for Recommendation",
  "url": "https://openalex.org/W4379539462",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2123803761",
      "name": "chaoliu li",
      "affiliations": [
        "South China University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A3034975406",
      "name": "Lianghao Xia",
      "affiliations": [
        "University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A2502377052",
      "name": "Xubin Ren",
      "affiliations": [
        "University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A2805891746",
      "name": "Yaowen Ye",
      "affiliations": [
        "University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A2096026659",
      "name": "Yong Xu",
      "affiliations": [
        "South China University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2101072704",
      "name": "Chao Huang",
      "affiliations": [
        "University of Hong Kong"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2998431760",
    "https://openalex.org/W4312262772",
    "https://openalex.org/W4313156423",
    "https://openalex.org/W3045200674",
    "https://openalex.org/W2605350416",
    "https://openalex.org/W4290876361",
    "https://openalex.org/W3035287707",
    "https://openalex.org/W2054141820",
    "https://openalex.org/W6600297362",
    "https://openalex.org/W4220909642",
    "https://openalex.org/W3116239416",
    "https://openalex.org/W1720514416",
    "https://openalex.org/W4225109328",
    "https://openalex.org/W3153106544",
    "https://openalex.org/W4284688665",
    "https://openalex.org/W2945827670",
    "https://openalex.org/W3044311607",
    "https://openalex.org/W3093563174",
    "https://openalex.org/W4212799635",
    "https://openalex.org/W3094605801",
    "https://openalex.org/W4224983022",
    "https://openalex.org/W3177890934",
    "https://openalex.org/W3154113024",
    "https://openalex.org/W3208338073",
    "https://openalex.org/W2807021761",
    "https://openalex.org/W2970155250",
    "https://openalex.org/W2963115613",
    "https://openalex.org/W2966750432",
    "https://openalex.org/W3156939347",
    "https://openalex.org/W6820618299",
    "https://openalex.org/W3065542300",
    "https://openalex.org/W3095746859",
    "https://openalex.org/W2916106175",
    "https://openalex.org/W3100278010",
    "https://openalex.org/W4221146190",
    "https://openalex.org/W3153325943",
    "https://openalex.org/W4321277058",
    "https://openalex.org/W3100260481",
    "https://openalex.org/W4353115442",
    "https://openalex.org/W3004578093",
    "https://openalex.org/W3207682456",
    "https://openalex.org/W3100324210",
    "https://openalex.org/W4321593910",
    "https://openalex.org/W3173682066",
    "https://openalex.org/W3100848837",
    "https://openalex.org/W2964015378",
    "https://openalex.org/W3154503084",
    "https://openalex.org/W4327671700",
    "https://openalex.org/W4283065718",
    "https://openalex.org/W3167553825",
    "https://openalex.org/W2952575904"
  ],
  "abstract": "This paper presents a novel approach to representation learning in\\nrecommender systems by integrating generative self-supervised learning with\\ngraph transformer architecture. We highlight the importance of high-quality\\ndata augmentation with relevant self-supervised pretext tasks for improving\\nperformance. Towards this end, we propose a new approach that automates the\\nself-supervision augmentation process through a rationale-aware generative SSL\\nthat distills informative user-item interaction patterns. The proposed\\nrecommender with Graph TransFormer (GFormer) that offers parameterized\\ncollaborative rationale discovery for selective augmentation while preserving\\nglobal-aware user-item relationships. In GFormer, we allow the rationale-aware\\nSSL to inspire graph collaborative filtering with task-adaptive invariant\\nrationalization in graph transformer. The experimental results reveal that our\\nGFormer has the capability to consistently improve the performance over\\nbaselines on different datasets. Several in-depth experiments further\\ninvestigate the invariant rationale-aware augmentation from various aspects.\\nThe source code for this work is publicly available at:\\nhttps://github.com/HKUDS/GFormer.\\n",
  "full_text": "Graph Transformer for Recommendation\nChaoliu Li\nchaoliuli66@gmail.com\nSouth China University of Technology\nGuangzhou, China\nLianghao Xia\naka_xia@foxmail.com\nUniversity of Hong Kong\nHong Kong SAR, China\nXubin Ren\nxubinrencs@gmail.com\nUniversity of Hong Kong\nHong Kong SAR, China\nYaowen Ye\nelwin@connect.hku.hk\nUniversity of Hong Kong\nHong Kong SAR, China\nYong Xu\nyxu@scut.edu.cn\nSouth China University of Technology\nGuangzhou, China\nChao Huangâˆ—\nchaohuang75@gmail.com\nUniversity of Hong Kong\nHong Kong SAR, China\nABSTRACT\nThis paper presents a novel approach to representation learning\nin recommender systems by integrating generative self-supervised\nlearning with graph transformer architecture. We highlight the\nimportance of high-quality data augmentation with relevant self-\nsupervised pretext tasks for improving performance. Towards this\nend, we propose a new approach that automates the self-supervision\naugmentation process through a rationale-aware generative SSL\nthat distills informative user-item interaction patterns. The pro-\nposed recommender with Graph TransFormer (GFormer) that of-\nfers parameterized collaborative rationale discovery for selective\naugmentation while preserving global-aware user-item relation-\nships. In GFormer, we allow the rationale-aware SSL to inspire\ngraph collaborative filtering with task-adaptive invariant rational-\nization in graph transformer. The experimental results reveal that\nour GFormer has the capability to consistently improve the per-\nformance over baselines on different datasets. Several in-depth\nexperiments further investigate the invariant rationale-aware aug-\nmentation from various aspects. The source code for this work is\npublicly available at: https://github.com/HKUDS/GFormer.\nCCS CONCEPTS\nâ€¢ Information systems â†’Recommender systems.\nKEYWORDS\nRecommendation, Graph Transformer, Masked Autoencoder\nACM Reference Format:\nChaoliu Li, Lianghao Xia, Xubin Ren, Yaowen Ye, Yong Xu, and Chao Huang.\n2023. Graph Transformer for Recommendation. In Proceedings of the 46th\nInternational ACM SIGIR Conference on Research and Development in Infor-\nmation Retrieval (SIGIR â€™23), July 23â€“27, 2023, Taipei, Taiwan. ACM, New\nYork, NY, USA, 10 pages. https://doi.org/10.1145/3539618.3591723\nâˆ—Chao Huang is the corresponding author. This work was completed when Chaoliu Li\nwas a research intern under the supervision of Chao Huang.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nSIGIR â€™23, July 23â€“27, 2023, Taipei, Taiwan\nÂ© 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-9408-6/23/07. . . $15.00\nhttps://doi.org/10.1145/3539618.3591723\n1 INTRODUCTION\nSelf-supervised learning (SSL) has become a popular solution for\naddressing the label scarcity issue in recommender systems by\ngenerating auxiliary supervision signals from unlabeled data [23,\n41]. By integrating with graph neural network (GNN) architecture\nfor collaborative filtering, SSL-enhanced graph augmentation has\nproven effective in modeling user-item interactions with limited\ntraining labels. Among contemporary methods, graph contrastive\nlearning (GCL) [35, 42] is one of the most widely used augmentation\nparadigms for recommendation [1, 16, 25]. The key insight behind\nGCL-based recommendation models is to obtain supervision signals\nfrom auxiliary learning tasks, which aim to supplement the main\nrecommendation objective via SSL-enhanced co-training.\nExisting graph contrastive methods aim to maximize mutual\ninformation by achieving representation consistency between gen-\nerated positive samples (e.g., user self-discrimination), and minimiz-\ning similarity between negative pairs (e.g., different users). Recent\nefforts have attempted to contrast different structural views of the\nuser-item interaction graph with heuristic-based data augmentors,\nfollowing the principle of mutual information maximization. For\ninstance, SGL [35] proposes to corrupt graph structures by ran-\ndomly removing user and item nodes as well as their connections\nto construct topological contrastive views. However, blindly cor-\nrupting graph topological structures can lead to the loss of crucial\nrelations between users and items, such as unique user interac-\ntion patterns or limited labels of long-tail items (as illustrated in\nFigure 1.(a)). Therefore, it is crucial to explicitly provide essential\nself-supervision signals for learning informative representations,\nwhich requires invariant rationales in the designed augmentors.\nFrom the perspective of aligning local-level and global-level em-\nbeddings for augmentation, some research studies obtain semantic-\nrelated subgraph representations through various information ag-\ngregation techniques, such as hypergraph-based message passing\nin HCCF [28] and EM algorithm-based node clustering in NCL [13].\nHowever, due to their hand-crafted nature, the quality of augmenta-\ntion is likely to be influenced by manually constructed hypergraph\nstructures and user cluster settings. As a result, these augmentation\nschemes are insufficient to regularize the training process with\nuseful self-supervised signals (e.g., truly negative pairs and hard\naugmented instances). Moreover, these manually designed con-\ntrastive methods can be easily misled by commonly existing noise\n(e.g., misclick behaviors [ 18], popularity bias [ 39]) (as shown in\nFigure 1.(b)). Introducing augmented SSL information from biased\narXiv:2306.02330v1  [cs.IR]  4 Jun 2023\nSIGIR â€™23, July 23â€“27, 2023, Taipei, Taiwan Chaoliu Li, Lianghao Xia, Xubin Ren, Yaowen Ye, Yong Xu, & Chao Huang\nmask\nmisclick\nGFormerSGL\nğ‘¢!\nğ‘\"\nlong-tail â†’isolated \nHCCF / NCL\nğ‘¢!\nğ‘\"ğ‘#\n noisy nodeğ‘¢!\nStructural neighbor Sematic neighbor\nNCL LearningHCCF Learningnoisy signal\nHypergraph-based node\n(a) (b) (c)\nFigure 1: Illustration for the graph augmentations generated\nby different self-supervised recommendation models.\ndata can amplify the noisy effects, which dilutes the learning of\ntrue user-item interaction patterns. Therefore, existing solutions\nmay fall short in adapting the self-supervision process to changing\npractical recommendation environments.\nDespite the advancements in SSL-enhanced recommender sys-\ntems, a fundamental question remains poorly understood: What\ninformation is crucial and should be preserved for self-supervised\naugmentation in recommendation? Motivated by the recent suc-\ncess of masked autoencoding (MAE) techniques in advancing self-\nsupervised learning [3, 4, 7], this work explores the above ques-\ntion from the perspective of generative self-supervised augmenta-\ntion with rationale-aware invariant representation learning. Unlike\ncontrastive learning, the masked autoencoder paradigm directly\nadopts the reconstruction objective as the principled pretext task for\ndata augmentation. It naturally avoids the limitations of manually-\ngenerated contrastive views for data augmentation discussed above.\nPresent Work. In this work, we propose a new recommender\nsystem with Graph TransFormer to automatically distill masked\nself-supervised signals with invariant collaborative rationales. We\ntake inspiration from rationale discovery [26, 40] to bridge the gap\nbetween the graph masked autoencoder with adaptive augmen-\ntation. Our GFormer makes full use of the power of Transformer\nin explicitly encoding pairwise relations to discover useful self-\nsupervised signals benefiting the downstream recommendation\ntask, with their own rationales explained. Specifically, we develop\na topology-aware graph transformer to integrate into the user-item\ninteraction modeling, enabling automated collaborative rationale\ndiscovery. In GFormer, the topological information of the user-item\nrelation graph is treated as the global context in the form of graph\npositional encoding. To adapt GFormer to diverse recommendation\nenvironments, it learns to form appropriate interaction patterns as\nself-supervision signals, guided by task-adaptive collaborative ra-\ntionale discovery. Our contributions can be summarized as follows:\nâ€¢This work revisits the self-supervised recommendation by explor-\ning augmentation schemes from SSL-enhanced collaborative ra-\ntionalization. We not only realize the automated data augmentors\nin SSL, but also provide rationale-aware understanding behind\nthe self-supervised augmentation to improve model robustness.\nâ€¢We propose a principled approach for discovering invariant ra-\ntionales with collaborative relations over the graph transformer.\nTask-aware adaptation is introduced to alleviate the issue of\ndata-level variance. Then, the graph autoencoder is required to\nreconstruct the masked user-item interactions for augmentation.\nâ€¢We validate the effectiveness of our GFormer on several datasets.\nCompared with a variety of strong compared methods, our method\nconsistently gains improvements across different settings.\n2 PRELIMINARIES AND RELATED WORK\nGraph-based Collaborative Filtering . Many recent studies have\nexplored the use of graph representation learning in building graph-\nenhanced collaborative filtering (CF) models to capture high-order\ncollaborative relations [2, 5, 27]. In this scenario, we assume that\nthere are ğ¼users U= {ğ‘¢1,ğ‘¢2,...,ğ‘¢ ğ¼}and ğ½ items P= {ğ‘1,ğ‘2,...,ğ‘ ğ½}\nin our recommendation system. The observed user behaviors are\nrepresented by an interaction matrix A âˆˆRğ¼Ã—ğ½, where ğ‘ğ‘–,ğ‘— = 1 if\nan interaction between userğ‘¢ğ‘– and item ğ‘ğ‘— is observed, and ğ‘ğ‘–,ğ‘— = 0\notherwise. To transform the interaction matrix into an interaction\ngraph for graph-based CF, we define a graph G= {V,E}, where\nV= UâˆªP forms the node set, and E= {ğ‘’ğ‘–,ğ‘— |ğ‘ğ‘–,ğ‘— = 1}denotes\nthe edge set corresponding to user-item interactions. Using these\ndefinitions, the graph-based CF can be abstracted as a prediction\nfunction over user-item interactions: Ë†ğ‘¦ğ‘–,ğ‘— = ğ‘“(G; Î˜), where Ë†ğ‘¦ğ‘–,ğ‘— is\nthe predicted score for the unknown interaction between user ğ‘¢ğ‘–\nand item ğ‘ğ‘—, and Î˜ represents the model parameters.\nGNN-enhanced CF Models . Graph neural networks (GNNs) [9,\n24] have become effective components for modeling user-item rela-\ntionships in recommender systems. Typically, a GNN encoder is ap-\nplied to generate user/item embeddings based on recursive message\npassing operations on the generated graph structures from user-\nitem interactions [22, 31]. Earlier efforts adopt graph convolutional\nnetworks to map the interaction graph into latent embeddings, such\nas NGCF [19] and Star-GCN [38]. To simplify the graph message\npassing algorithm, recent approaches such as LightGCN [ 5] and\nGCCF [2] propose removing the non-linear transformation and\nactivation for embedding propagation. Additionally, inspired by\ndisentangled representation learning, latent intent disentanglement\nhas been used to enhance graph neural networks for fine-grained\nuser preference modeling, as demonstrated in DGCF [20] and Disen-\nHAN [21]. Hyperbolic representation space has been introduced to\nimprove graph collaborative filtering for user embedding, as shown\nin HGCF [17]. Recent studies have also aimed to capture interaction\nheterogeneity for graph collaborative filtering, with approaches\nsuch as MBGCN [8] and MBGMN [29] designed to enable multiplex\nGNNs for learning multi-behavior interaction patterns.\nSelf-Supervised Learning for Recommendation . Recently, data\naugmentation with self-supervised learning (SSL) has emerged as a\npromising approach for mitigating the label scarcity and noise issue\nin recommender systems [30, 32]. One important SSL paradigm is\ncontrastive learning-based augmentation, where semantic-relevant\ninstances are aligned with sampled positive pairs, while unrelated\nsamples as negative pairs are pushed away. For example, random\ncorruptions are performed on graph structures in SGL [ 25] and\nnode embeddings in SLRec [ 32]. In addition, pre-defined embed-\nding alignment methods are used to create views for embedding\ncontrasting with heuristics, such as hypergraph construction in\nHCCF [28] and user clustering in NCL [13].\n3 METHODOLOGY\n3.1 Graph Invariant Rationale Learning\nTo eliminate the impact of noisy features and enhance model inter-\npretability, representation learning with rationalization has been\nexplored to identify a subset of important features (e.g., language\nGraph Transformer for Recommendation SIGIR â€™23, July 23â€“27, 2023, Taipei, Taiwan\nğ–!Position-awareAggregation\nğ‡=#ğ‡+ğ‡\nAnchornodesTopological embeddingsGlobal Topology Information Injection\nğ‘\",\"!=1 ()!#()/ğ–!\" ğ–#\" ğ‘‘/ğ»()!#()/ğ–!\" ğ–#\" ğ‘‘/ğ»()!#()/ğ–!\" ğ–#\" ğ‘‘/ğ»ğ»\n()!#()/ğ–!\" ğ–#\" ğ‘‘/ğ»Multi-head self-attention\nAttention Weights\nPooling#\n +\nTopology-aware Multi-Head Aggregation\nRationale Graph\nlow high\nCollaborative Rationale Discovery with Graph Transformer\nTask-AdaptiveRationaleDiscovery\nReconstruction\nRecommendation\nRationale Inspires Graph Masked Autoencoding\nComplement Independence RegularizationRationale-aware Self-Augmentation\nğ–$\"\nFigure 2: Overall framework illustration of the proposed GFormer model. i) The collaborative rationale discovery is built upon\nthe topology-aware graph transformer for interaction rationalization. ii) Position-aware message passing is enabled to encode\npairwise user-item dependency with the global graph context enhancement. iii) Graph autoencoder aims at reconstructing\nthe discovered collaborative rationales, with informative user-item interaction patterns for augmentation. iv) Task-adaptive\nself-supervision is realized with the awareness of main optimized objective derived from the target recommendation task.\nwords [36], image pixels [37]) that guide the model prediction re-\nsults. Recently, rationalization learning techniques have been intro-\nduced into graph representation learning by discovering invariant\nrationales for important graph structural information to benefit\ndownstream graph mining tasks [11, 12, 26]. In our graph-based CF\nscenario, our invariant rationale discovery scheme is designed to\nfind a subset of graph structures that best guide the self-supervised\naugmentation for the downstream recommendation task with ratio-\nnalization. Our invariant rationale discovery with graph collabora-\ntive relationships aims to optimize the following objective from two\nviewpoints: performance sufficiency and complement independence .\nThis objective is formally given as:\nmin ğ·(ğ‘“(ğ‘…(G)),ğ‘“ (G))+ğ¼ (ğ‘…(G),ğ¶(ğ‘…(G))) (1)\nğ‘“(Â·)denotes the predictive function, while ğ‘…(Â·)and ğ¶(Â·)denote\nthe rationale and complement of the rationale for the input graph\nG, respectively. Specifically, for achieving performance sufficiency,\nthe first term aims to minimize the performance difference be-\ntween using the rationale ğ‘…(G)and the entire graph G. Here, ğ·(Â·)\nrepresents the difference measurement function. By doing so, im-\nportant structural information of graph collaborative relations is\nwell-preserved in our learned rationale ğ‘…(G). Additionally, in pur-\nsuit of complement independence by mitigating noisy signals, the\nsecond term seeks to minimize the dependency of the complement\ngraph structures ğ¶(ğ‘…(G))and rationale ğ‘…(G). With this objective,\nthe complement of our discovered rationales has little influence\non the label prediction. Hence, our graph rationale discovery can\nexploit the invariant relationships between users and items while\nalleviating the noisy effects of spurious interactions.\n3.1.1 Graph Collaborative Rationale Discovery. To enable\nnoise-resistant self-supervision for augmentations, our GFormer\naims at automatically distilling important graph structures over the\ninteraction graph G, i.e., the collaborative rationales. To generate\nthe informative interaction subgraph structure, our collaborative\nrationale discovery is designed to estimate the following probability\nof subgraph Gğ‘… being the rationale of interaction graph G:\nğ‘(ğ‘…(G)= Gğ‘…)=\nÃ–\nğ‘’âˆˆEğ‘…\nğ‘(ğ‘’|G)\nÃ–\nğ‘’â€²âˆˆEğ¶\n(1 âˆ’ğ‘(ğ‘’ğ‘˜â€²|G))\nGğ‘… = {V,Eğ‘…}, Gğ‘… âˆ¼ğ‘(ğ‘…(G)= Gğ‘…), |Eğ‘…|= ğœŒğ‘… Â·|E|\nGğ¶ = {V,Eğ¶}, Eğ¶ = {ğ‘’â€²|ğ‘’â€² âˆˆE,ğ‘’â€² âˆ‰ Eğ‘…} (2)\nwhere ğœŒğ‘… denotes the proportion of interaction edges selected as\nthe collaborative rationales Gğ‘…, and Gğ¶ is defined as the subgraph\ncontaining the edges that are not part of Gğ‘…. Here, we define ğ‘’ and\nğ‘’â€² to denote user-item interactions in the rationale and complement\nsubgraphs, respectively. To estimate the distribution probability\ndescribed above, our GFormer proposes to infer the probability of\nindividual edge ğ‘(ğ‘’|G)and ğ‘(ğ‘’â€²|G)being identified as part of the\nrationale. With a graph encoder for node embeddings, the parame-\nterized rationale generator is formally generalized as follows:\nğ‘(ğ‘’|G)â† GT (G,TE(H; Î˜TE); Î˜GT); arg max\nÎ˜TE,Î˜GT\nLRD (3)\nInspired by the design of dependency rationalization of self-attention\nin Transformer, our graph encoder GT(Â·)is built upon a Graph\nTransformer architecture, which will be elaborated on in Section 3.1.3.\nTo inject the global topological context into the invariant rationale\ndiscovery process, we design the graph topology embedding module\nTE(Â·)to capture the collaborative effects across the entire graph, as\ndetailed in Section 3.1.2. Specifically, H âˆˆR(ğ¼+ğ½)Ã—ğ‘‘ represents the\nembedding table containing the representations of all ğ¼ user nodes\nand ğ½ item nodes. The learnable parameters of the embedding func-\ntions GT(Â·)and TE(Â·)are denoted by Î˜GT and Î˜TE, respectively.\nIn our learning process, Î˜GT and Î˜TE are inferred by optimizing\nthe BPR-based objective function Lğ‘…ğ· for the collaborative filter-\ning task. This enables task-adaptive rationale discovery for SSL\naugmentation in our GFormer model.\n3.1.2 Global Topology Information Injection. Motivated by\nthe power of position-aware graph neural networks [ 34] in cap-\nturing global relational information, our GFormer proposes to en-\nhance collaborative rationale discovery by preserving high-order\nuser/item dependencies. We begin by sampling a set of anchor\nnodes Vğ´ âŠ‚V from the user-item interaction graph G= {V,E}.\nTo represent the global topological embeddings of users and items\nbased on their connectivities with anchor nodes, we calculate the\ndistance ğ‘‘ğ‘˜,ğ‘ between the target node ğ‘£ğ‘˜ and each anchor node ğ‘£ğ‘,\nwhere distance is defined as the minimum number of edges that\nmust be traversed to go from ğ‘£ğ‘˜ to ğ‘£ğ‘ in G. Given the calculated\ndistances, we derive the correlation weight ğœ”ğ‘˜,ğ‘ for each pair of\ntarget-anchor nodes (ğ‘˜,ğ‘)as follows:\nğœ”ğ‘˜,ğ‘ =\n( 1\nğ‘‘ğ‘˜,ğ‘+1 ğ‘–ğ‘“ ğ‘‘ ğ‘˜,ğ‘ â©½ ğ‘\n0 ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’ (4)\nSIGIR â€™23, July 23â€“27, 2023, Taipei, Taiwan Chaoliu Li, Lianghao Xia, Xubin Ren, Yaowen Ye, Yong Xu, & Chao Huang\nğ‘represents the maximum value allowed for the correlation weight\nbetween any target and anchor node, which is used for normaliza-\ntion purposes. The node correlation weights are then normalized\nto the range of [0,1]. With the weight ğœ”ğ‘˜,ğ‘, we refine the target\nnode embedding by considering the correlation weights between\nthe target node ğ‘˜ and each anchor node ğ‘£ğ‘ âˆˆVğ´:\nËœh\nğ‘™\nğ‘˜ =\nâˆ‘ï¸\nğ‘£ğ‘âˆˆVğ´\nWğ‘™ Â·ğœ”ğ‘˜,ğ‘ Â·[Ëœh\nğ‘™âˆ’1\nğ‘˜ ||Ëœh\nğ‘™âˆ’1\nğ‘ ]/|Vğ´| (5)\nHere, Ëœh\nğ‘™\nğ‘˜, Ëœh\nğ‘™âˆ’1\nğ‘˜ âˆˆRğ‘‘ denote the embeddings of node ğ‘£ğ‘˜ in the ğ‘™-th\nand (ğ‘™âˆ’1)-th graph propagation layer, respectively. To represent the\nglobal topological context based on anchor nodes, we define Hğ‘™ğ‘‡\nto denote the global topological embedding matrix in the ğ‘™-th layer.\nWğ‘™ âˆˆRğ‘‘Ã—2ğ‘‘ is a learnable transformation matrix. [Â·||Â·] denotes\nvector concatenation. After ğ¿graph information propagation steps,\nthe embeddings in ËœHğ¿ preserve the high-order topological infor-\nmation. We then inject this information into the id-corresponding\nembeddings to obtain the topological embeddings, as follows:\nÂ¯H = TE(H; {Wğ‘™ğ‘‡\nğ‘‡ }) (6)\nIn this way, our parameterized rationale generator can capture\nglobal collaborative relationships and identify informative patterns\nof interactions between users and items for SSL augmentation.\n3.1.3 Rationale Discovery with Graph Transformer. Our ra-\ntionale discovery aims to extract informative patterns of user-\nitem interactions that can be used for self-supervised augmen-\ntation in changing recommendation environments with limited\nsupervision labels. To address this challenge, we draw inspira-\ntion from the Transformer architecture and its core self-attention\nmechanisms. Specifically, we propose a novel approach to learning\nenvironment-invariant user preference information as generative\nself-supervision signals with selective augmentation. This design\nallows our GFormer to mitigate the noise induced by observational\nbehavior data, which is prone to contain biases and confounding\nfactors that can negatively affect recommendation performance.\nOur parameterized rationale discovery module is built over graph\ntransformer framework to encode implicit label-invariant node-\nwise relations as selected rationales. To incorporate the positional\ninformation of user and item nodes into the topology learning\nprocess, we feed the global topology-aware node embeddings Â¯H\ninto the multi-head self-attention mechanism for rationalization.\nSpecifically, we learn the correlation between node ğ‘£ğ‘˜ and ğ‘£ğ‘˜â€² with\nrespect to the â„-th attention head as follows:\nğ›¼â„\nğ‘˜,ğ‘˜â€² =\nexp Ëœğ›¼â„\nğ‘˜,ğ‘˜â€²\nÃ\nğ‘˜â€²exp Ëœğ›¼â„\nğ‘˜,ğ‘˜â€²\n; Ëœğ›¼â„\nğ‘˜,ğ‘˜â€² =\n(Wâ„\nğ‘„ Â·Â¯hğ‘˜)âŠ¤Â·(Wâ„\nğ¾ Â·Â¯hğ‘˜â€²)\nâˆšï¸\nğ‘‘/ğ»\n(7)\nHere, Wâ„\nğ‘„ and Wâ„\nğ¾ âˆˆR\nğ‘‘\nğ» Ã—ğ‘‘ represent the transformations used to\nobtain the query and key embeddings for calculating the attention\nscores. Since the attention scores encoded by our graph transformer\ncapture the strength of node-wise dependencies, we aggregate the\nmulti-head scores to obtain the probability scores, ğ‘((ğ‘£ğ‘˜,ğ‘£ğ‘˜â€²)|G),\nof graph edges, such as ğ‘£ğ‘˜â€“ğ‘£ğ‘˜â€², being selected as rationales. These\nrationales correspond to the subset of important user-item inter-\naction patterns that best illuminate the user preference learning\nprocess with invariant representations, which is presented as:\nğ‘((ğ‘£ğ‘˜,ğ‘£ğ‘˜â€²)|G) = Â¯ğ›¼ğ‘˜,ğ‘˜â€²\nÃ\n(ğ‘£ğ‘˜,ğ‘£ğ‘˜â€²)âˆˆE Â¯ğ›¼ğ‘˜,ğ‘˜â€²\n; Â¯ğ›¼ğ‘˜,ğ‘˜â€² =\nğ»âˆ‘ï¸\nâ„=1\nğ›¼â„\nğ‘˜,ğ‘˜â€²/ğ» (8)\nTo sample a rationale estimated by our topology-aware graph trans-\nformer, we individually sample ğœŒğ‘… Â·|E| edges from the edge set\nEaccording to their probability scores, ğ‘((ğ‘£ğ‘˜,ğ‘£ğ‘˜â€²)|G). Here, the\nhyperparameter ğœŒğ‘… âˆˆR controls the size of the subset of important\nedges that are selected for rationalization.\n3.1.4 Task-Adaptive Rationale Discovery. To perform task-\nlevel adaptation in our rationale discovery, our GFormer is a task-\nadaptive rationale discovery paradigm that can perform task-specific\nrationalization to provide customized recommendations. Specifi-\ncally, our model leverages the embeddings and the distilled ratio-\nnales from the graph transformer to generate predictions for usersâ€™\npreferences over items. This process is formally given as follows:\nÂ¯ğ‘¦ğ‘–,ğ‘— = zğ¿âŠ¤\nğ‘– Â·zğ¿\nğ‘—; zğ¿\nğ‘˜ =\nâˆ‘ï¸\n(ğ‘£ğ‘˜,ğ‘£ğ‘˜â€²)âˆˆEğ‘…\nğ›½ğ‘˜,ğ‘˜â€² Â·zğ‘™âˆ’1\nğ‘˜â€² ;\nZ0 = GT(G,TE(H))=\n\f\f\f\n\f\f\f\nğ»\nâ„=1\nâˆ‘ï¸\nğ‘˜â€²ğ›¼â„\nğ‘˜,ğ‘˜â€²Wâ„\nğ‘‰ Â¯hğ‘˜â€² +Â¯hğ‘˜ (9)\nÂ¯ğ‘¦ğ‘–,ğ‘— âˆˆR denotes the predicted probability of user ğ‘¢ğ‘– adopting item\nğ‘ğ‘—. The embeddingszğ¿\nğ‘– and zğ‘— âˆˆRğ‘‘ are used to make predictions on\nuser-item interactions, while zğ¿\nğ‘˜ for a vertex ğ‘£ğ‘˜ is obtained through\nan ğ¿-layer LightGCN [5]. Here Eğ‘… denotes the edge set of the sam-\npled rationale graph Gğ‘…. ğ›½ğ‘˜,ğ‘˜â€² = 1/\nâˆšï¸\nğ‘‘ğ‘˜ğ‘‘ğ‘˜â€² denotes the Lapalacian\nnormalization with degrees ğ‘‘ğ‘˜ and ğ‘‘ğ‘˜â€² of node ğ‘£ğ‘˜ and ğ‘£ğ‘˜â€². The 0-\norder embeddings Z0 are obtained through multi-head embedding\naggregation in the topology-aware graph transformer, where ğ»\nis the number of attention heads, and Wâ„\nğ‘‰ âˆˆRğ‘‘/ğ»Ã—ğ‘‘ denotes the\nvalue transformation in the self-attention. We employ a residual\nconnection to also use the topology-aware embeddingsÂ¯hğ‘˜â€² as input.\nWith the predicted probability score for each (ğ‘¢ğ‘–,ğ‘¦ğ‘—)interaction,\nwe apply the following BPR loss to guide the rationale discovery\nprocess and optimize the objective of the downstream task:\nLRD =\nâˆ‘ï¸\n(ğ‘¢ğ‘–,ğ‘+\nğ‘—,ğ‘âˆ’\nğ‘— )\nâˆ’log sigm(Â¯ğ‘¦ğ‘–,ğ‘—+ âˆ’Â¯ğ‘¦ğ‘–,ğ‘—âˆ’) (10)\nA pair-wise training triplet is formed by sampling a user and\nitems such that ğ‘¢ğ‘– âˆˆU and ğ‘£+\nğ‘—,ğ‘£âˆ’\nğ‘— âˆˆP, and the triplet satisfies\n(ğ‘¢ğ‘–,ğ‘+\nğ‘—)âˆˆE and (ğ‘¢ğ‘–,ğ‘âˆ’\nğ‘— )âˆ‰ E. The sigmoid function is represented\nby sigm(Â·). To incorporate task-specific knowledge, a topology-\naware graph transformer is employed. This transformer provides\ntask-aware parameter learning to customize the collaborative ra-\ntionale discovery for different recommendation scenarios. As a\nresult, the collaborative rationale discovery satisfies the sufficiency\nprinciple [36] with the objective of ğ‘“(ğ‘…(G))= ğ‘“(G).\n3.2 Rationale-Aware Self-Augmentation\n3.2.1 Rationales Inspire Graph Masked Autoencoding. Our\nproposed self-distillation paradigm for discovering collaborative\nrationales involves performing self-augmentation over the distilled\ninformative user-item interaction patterns through graph masked\nautoencoding. To achieve this, we configure our GFormer with the\nGraph Transformer for Recommendation SIGIR â€™23, July 23â€“27, 2023, Taipei, Taiwan\nrationale-aware mask autoencoder, which masks identified ratio-\nnables from the interaction graph for autoencoding-based recon-\nstruction. To sample the masked graph structure Gğ‘€ = {V,Eğ‘€},\nwe use the reciprocal of the rationale scores. This allows us to mask\nthe most important rationale structures, as shown below:\nEğ‘€ âˆ¼ğ‘ğ‘€(Eğ‘€|G)=\nÃ–\n(ğ‘£ğ‘˜,ğ‘£ğ‘˜â€²)âˆˆEğ‘€\nğ›¼ğ‘€\nğ‘˜,ğ‘˜â€²\nÃ–\n(ğ‘£ğ‘˜,ğ‘£ğ‘˜â€²)âˆˆE\\Eğ‘€\nğ›¼ğ‘€\nğ‘˜,ğ‘˜â€²\n|Eğ‘€|= ğœŒğ‘€|E|; ğ›¼ğ‘€\nğ‘˜,ğ‘˜â€² =\nÂ¯ğ›¼ğ‘€\nğ‘˜,ğ‘˜â€²\nÃ\n(ğ‘£ğ‘˜,ğ‘£ğ‘˜â€²)âˆˆE\nÂ¯ğ›¼ğ‘€\nğ‘˜,ğ‘˜â€²\n; Â¯ğ›¼ğ‘€\nğ‘˜,ğ‘˜â€² = 1\nÂ¯ğ›¼ğ‘˜,ğ‘˜â€² +ğœ– (11)\nğ‘ğ‘€(Â·)is the probability of sampling edges in the masked graph.\nğ›¼ğ‘€\nğ‘˜,ğ‘˜â€² is the probability of selecting an edge between nodes ğ‘£ğ‘˜ and\nğ‘£ğ‘˜â€²in the mask generator.Â¯ğ›¼ğ‘€\nğ‘˜,ğ‘˜â€²is the un-normalized attention score\ncalculated using the reciprocal of the weights ğ›¼ğ‘˜,ğ‘˜â€². A small value\nğœ– is added to avoid a zero denominator. The masked graph has a\nhigher edge density than the rationale graph to only remove the\nmost important rationale edges for noise-resistant autoencoding.\nThe masked graph Gğ‘€ with edge set Eğ‘€ is then used as input for\nthe autoencoder network, which is presented as follows:\nS = GT(Gğ‘€,TE(Â¯Sğ¿)); Â¯ sğ‘™ =\nâˆ‘ï¸\n(ğ‘£ğ‘˜,ğ‘£ğ‘˜â€²)âˆˆEğ‘€\nğ›½ğ‘˜,ğ‘˜â€² Â·Â¯sğ‘™1\nğ‘˜â€² (12)\nS âˆˆR(ğ¼+ğ½)Ã—ğ‘‘ represents the final embeddings in the autoencoder.\nGT(Â·)and TE(Â·)denote our graph transformer network and the\ntopological information encoder, respectively. We enhance the ini-\ntial embeddings with ğ¿-order local node embeddings Â¯Sğ¿, encoded\nfrom LightGCN. Â¯S0 is initialized with the id-corresponding embed-\ndings H. The embeddings S are used for training the reconstruction\nof the masked user-item interactions. This can be expressed as:\nLMAE =\nâˆ‘ï¸\n(ğ‘£ğ‘˜,ğ‘£ğ‘˜â€²)âˆˆE\\Eğ‘€\nâˆ’Ëœğ‘¦ğ‘˜,ğ‘˜â€²; Ëœğ‘¦ğ‘˜,ğ‘˜â€² = sâŠ¤\nğ‘˜sğ‘˜â€² (13)\nLMAE is the training objective for reconstructing the masked in-\nteraction patterns. Ëœğ‘¦ğ‘˜,ğ‘˜â€² represents the predicted scores for edge\n(ğ‘£ğ‘˜,ğ‘£ğ‘˜â€²)on graph G. Inspired by our collaborative rationale discov-\nery, our graph masked autoencoder is trained to reconstruct im-\nportant interaction patterns that are adaptable to downstream rec-\nommendation tasks. Our rationale-aware augmentation approach\nprevents our generative SSL from being influenced by noisy edges.\n3.2.2 Complement Independence Modeling. To achieve com-\nplement independence in rationale discovery (as discussed in Sec-\ntion 3.1), we introduce a learning component to encourage inde-\npendence between the distilled collaborative rationales and their\ncorresponding complements, thereby reducing information redun-\ndancy. This is done through contrastive regularization, where we\nminimize the mutual information between the rationale graph Gğ‘…\nand a sampled complement graph Gğ¶. The complement graph is\nsampled in a manner similar to graph masking, but with a different\nsampling rate ğœŒğ¶ << ğœŒğ‘€ to identify noisy edges. The complement\ngraph Gğ¶ = {V,Eğ¶}is generated as follows:\nEğ¶ âˆ¼ğ‘ğ¶(Eğ¶|G)= ğ‘ğ‘€(Eğ¶|G); |Eğ¶|= ğœŒğ¶ Â·|E| (14)\nTo ensure that the complement graph Gğ¶ does not contain non-\nnoise edges that could affect the independence regularization, we\nuse a low sampling rate ğœŒğ¶. We then apply the following loss to\nTable 1: Statistics of the experimental datasets.\nDataset #Users #Items #Interactions Density\nYelp 42,712 26,822 182,357 1.6 ğ‘’âˆ’4\nIfashion 31,668 38,048 618,629 5.1 ğ‘’âˆ’4\nLastFM 1,889 15,376 51,987 1.8 ğ‘’âˆ’3\nminimize the similarities between the rationale graph Gğ‘… and the\ncomplement graph Gğ¶ in high-order representations:\nLCIR = log\nâˆ‘ï¸\nğ‘£ğ‘˜âˆˆV\nexp cos(eğ‘…\nğ‘˜,eğ¶\nğ‘˜)/ğœ\nEğ‘… =L-GCNğ¿(H,Gğ‘…); Eğ¶ = L-GCNğ¿(H,Gğ¶) (15)\nL-GCNğ¿(Â·)represents the stacking of ğ¿ graph layers in Light-\nGCN [5] for recursively passing messages over the input graph\n(Gğ‘… and Gğ¶). ğœ is the hyperparameter for the temperature coeffi-\ncient. The contrastive independence regularizationLCIR pushes the\nembeddings of the rationale embeddings eğ‘…\nğ‘˜ and the complement\nembeddings eğ¶\nğ‘˜ away from each other for all nodes. This enhances\nthe modelâ€™s ability to encourage independence between the dis-\ncovered rationales and complements, thereby improving the noise\nmitigation ability in our GFormer for SSL-based augmentation.\n3.2.3 SSL-Augmented Model Optimization. During the train-\ning phase, we use the embeddingsS âˆˆR(ğ¼+ğ½)Ã—ğ‘‘ to make predictions\nfor training the recommender. The following point-wise loss func-\ntion is minimized for model training:\nLRec =\nâˆ‘ï¸\nğ‘ğ‘–,ğ‘—=1\nâˆ’log\nexp sâŠ¤\nğ‘– sğ‘—\nÃ\nğ‘ğ‘—â€²âˆˆPexp sâŠ¤\nğ‘– sğ‘—â€²\n(16)\nGFormer maximizes the predictions for all positive user-item in-\nteractions and minimizes the predictions for all negative user-item\ninteractions as a contrast. During the testing phase, we replace\nthe masked graph Gğ‘€ in GFormer with the observed interaction\ngraph Gand predict the relations between user ğ‘¢ğ‘– and item ğ‘ğ‘— by\nË†ğ‘¦ğ‘–,ğ‘— = sâŠ¤\nğ‘– sğ‘—. By combining the multiple training objectives, our\nGFormer is optimized to minimize the following overall objective:\nL= LRec +LRCS +ğœ†1 Â·LRD +ğœ†2 Â·LCIR +ğœ†3 Â·âˆ¥Î˜âˆ¥2\nF (17)\nğœ†1,ğœ†2,and ğœ†3 are hyperparameters used for loss balancing. The last\nterm is the Frobenius-norm regularization for the parameters.\n3.3 Discussion of Time and Space Complexity\nTime Complexity. Our GFormer employs graph transformer for\ncollaborative rationale discovery and LightGCN as our graph en-\ncoder for rationale subgraph structures. The former takes O(ğ¿ğ‘‡ Ã—\n(ğ¼+ğ½)Ã—ğ‘‘2)complexity for embedding transformation and O(ğ¿ğ‘‡ Ã—\n(ğœŒğ‘… +ğœŒğ‘€)Ã—|E|Ã— ğ‘‘)for information propagation and aggregation.\nLightGCN requires O((ğ¿ğ¶ğœŒğ‘… +ğ¿ğ´ğœŒğ‘€ +ğ¿ğ¼ğœŒğ‘…)Ã—|E|Ã— ğ‘‘)cost.\nSpace Complexity . Our collaborative rationale discovery mod-\nule is built directly upon the graph encoderâ€“Graph Transformer,\nwhich means that no additional rationale learning parameters are\nneeded compared to other rationale graph structure learning meth-\nods (e.g. [12, 14]). As a result, our GFormer model requires a smaller\nspace cost (i.e., O((ğ¼ +ğ½)Ã—ğ‘‘+ğ‘‘2)) than these methods.\nSIGIR â€™23, July 23â€“27, 2023, Taipei, Taiwan Chaoliu Li, Lianghao Xia, Xubin Ren, Yaowen Ye, Yong Xu, & Chao Huang\nTable 2: Performance comparison between our proposed GFormer and all baselines on Ifashion, Yelp, LastFM datasets.\nDatasets Metric BiasMF NCF AutoRec PinSage NGCF GCCF LightGCN EGLN SLRec NCL HCCF SGL GFormer p-val.\nYelp\nRecall@10 0.0122 0.0166 0.0230 0.0278 0.0438 0.0484 0.0422 0.0458 0.0418 0.0493 0.0518 0.0522 0.0562 2.8e-6\nNDCG@10 0.0070 0.0101 0.0133 0.0171 0.0269 0.0296 0.0254 0.0278 0.0258 0.0301 0.0318 0.0319 0.0350 9.8e-9\nRecall@20 0.0198 0.0292 0.0410 0.0454 0.0678 0.0754 0.0761 0.0726 0.0650 0.0806 0.0789 0.0815 0.0878 5.2e-8\nNDCG@20 0.0090 0.0138 0.0186 0.0224 0.0340 0.0378 0.0373 0.0360 0.0327 0.0402 0.0391 0.0410 0.0442 1.6e-6\nRecall@40 0.0303 0.0442 0.0678 0.0712 0.1047 0.1163 0.1031 0.1121 0.1026 0.1192 0.1244 0.1249 0.1328 8.3e-11\nNDCG@40 0.0117 0.0167 0.0253 0.0287 0.0430 0.0475 0.0413 0.0456 0.0418 0.0485 0.0510 0.0517 0.0551 7.8e-9\nIfashion\nRecall@10 0.0302 0.0268 0.0309 0.0291 0.0375 0.0373 0.0437 0.0473 0.0373 0.0474 0.0489 0.0512 0.0542 6.3e-7\nNDCG@10 0.0281 0.0253 0.0264 0.0276 0.0350 0.0352 0.0416 0.0438 0.0353 0.0446 0.0464 0.0487 0.0520 2.0e-6\nRecall@20 0.0523 0.0451 0.0537 0.0505 0.0636 0.0639 0.0751 0.0787 0.0633 0.0797 0.0815 0.0845 0.0894 1.5e-7\nNDCG@20 0.0360 0.0306 0.0351 0.0352 0.0442 0.0445 0.0528 0.0549 0.0444 0.0558 0.0578 0.0603 0.0635 6.3e-5\nRecall@40 0.0858 0.0785 0.0921 0.0851 0.1062 0.1047 0.1207 0.1277 0.1043 0.1283 0.1306 0.1354 0.1424 9.0e-9\nNDCG@40 0.0474 0.0423 0.0483 0.0470 0.0585 0.0584 0.0677 0.0715 0.0582 0.0723 0.0744 0.0773 0.0818 9.9e-8\nLastFM\nRecall@10 0.0609 0.0574 0.0543 0.0899 0.1257 0.1230 0.1490 0.1133 0.1175 0.1491 0.1502 0.1496 0.1573 5.8e-7\nNDCG@10 0.0696 0.0645 0.0599 0.1046 0.1489 0.1452 0.1739 0.1263 0.1384 0.1745 0.1773 0.1775 0.1831 1.8e-6\nRecall@20 0.0980 0.0956 0.0887 0.1343 0.1918 0.1816 0.2188 0.1823 0.1747 0.2196 0.2210 0.2236 0.2352 5.0e-8\nNDCG@20 0.0860 0.0800 0.0769 0.1229 0.1759 0.1681 0.2018 0.1557 0.1613 0.2021 0.2047 0.2070 0.2145 1.7e-8\nRecall@40 0.1450 0.1439 0.1550 0.1990 0.2794 0.2649 0.3156 0.2747 0.2533 0.3130 0.3184 0.3194 0.3300 4.3e-7\nNDCG@40 0.1067 0.1055 0.1031 0.1515 0.2146 0.2049 0.2444 0.1966 0.1960 0.2437 0.2458 0.2498 0.2567 4.2e-7\n4 EVALUATION\nIn this section, we conduct extensive experiments for model evalu-\nation to answer the following key research questions:\nâ€¢RQ1: How effective is our GFormer compared to various state-\nof-the-art (SOTA) recommendation models?\nâ€¢RQ2: How does the model performance change if we substitute\nkey modules of GFormer with different naive implementations?\nâ€¢RQ3: How does our rationale-aware graph transformer perform\nagainst data noise and data scarcity issues?\nâ€¢RQ4: What is the training efficiency of the proposed GFormer?\nâ€¢RQ5: How do key parameters affect the model performance?\nâ€¢RQ6: How does our collaborative rationale discovery paradigm\nrealize the interpretability of user-item interaction patterns?\n4.1 Experimental Setup\n4.1.1 Datasets. We conduct experiments on three widely-used\nreal-world datasets for evaluating recommender systems: Yelp,\nIfashion, and LastFM. The Yelp dataset is used for recommend-\ning businesses venues to users, and it is collected from the well-\nknown Yelp platform. Ifashion is a fashion outfit dataset collected\nby Alibaba, while LastFM is a dataset that tracks user interaction\nactivities in music applications and internet radio sites. Table 1\nsummarizes the statistics of the three experimental datasets.\n4.1.2 Evaluation Protocols. We split the observed interactions\nof each dataset into training set, validation set, and test set using a\nratio of 0.70 : 0.05 : 0.25. To measure the recommendation accuracy\nfor each user over the whole item set, we adopted the all-rank proto-\ncol, following [25, 28]. This protocol helps alleviate the evaluation\nbias introduced by negative sampling. We evaluate all models using\ntwo representative metrics: Recall Ratio (Recall@K) and Normalized\nDiscounted Cumulative Gain (NDCG@K), with ğ¾ = 10,20,40.\n4.1.3 Baseline Methods. To comprehensively study the perfor-\nmance of GFormer, we compare it with many baseline methods\ncovering various techniques for collaborative filtering.\nNon-GNN Collaborative Filtering Approaches . We first include\nseveral conventional CF methods as benchmarks for comparison.\nâ€¢BiasMF [10]: This is a method based on matrix factorization\nwhich maps users and items to vector representations in the\nlatent space and takes their bias score into consideration.\nâ€¢NCF [6]: This method uses neural networks with multiple layers\nto encode non-linear features of user-item interactions.\nâ€¢AutoRec [15]: This model adopts the autoencoder structure and\nlearns embeddings through reconstructing observed interactions.\nGNN-based Recommendation Methods without SSL . Graph\nneural networks (GNNs) have shown their effectiveness in injecting\nhigh-order collaborative signals into user and item embeddings. For\nthis research line, we compared our GFormer with representative\nGNN-enhanced recommendation models that use various message\npassing schemes for performance evaluation.\nâ€¢PinSage [33]: This model leverages graph convolutional net-\nworks with random-walk-based message passing to encode the\nuser-item interaction graph with high efficiency.\nâ€¢NGCF [19]: This model captures high-order collaborative infor-\nmation through multiple layers of graph neural networks.\nâ€¢LightGCN [5]: This approach simplifies the architecture of NGCF\nand employs a light-weighted convolutional graph encoder for\nbetter representation learning and model training.\nâ€¢GCCF [2]: This model also introduces several improvements\nto GCN-based CF methods, including omitting the non-linear\ntransformation and applying residual connections.\nSSL-enhanced Recommendation Models . For comprehensive\nmodel evaluation, we included many recent SSL-enhanced recom-\nmender systems as baselines. In these models, different augmenta-\ntion strategies are designed to provide self-supervision signals.\nâ€¢EGLN [31]: This model incorporates a node embedding learning\nmodule and a graph structure learning module, and encourages\nthem to learn from each other for better representations.\nGraph Transformer for Recommendation SIGIR â€™23, July 23â€“27, 2023, Taipei, Taiwan\n0.070\n0.075\n0.080\n0.085\n0.090Recall@20\n0.033\n0.037\n0.041\n0.045NDCG@20\n/uni0000000b/uni00000044/uni0000000c/uni00000003/uni0000003c/uni00000048/uni0000004f/uni00000053/uni00000003/uni00000027/uni00000044/uni00000057/uni00000044\nRD\n MM RM -TE Ours\n0.050\n0.060\n0.070\n0.080\n0.090Recall@20 0.040\n0.050\n0.060NDCG@20\n/uni0000000b/uni00000045/uni0000000c/uni00000003/uni0000002c/uni00000049/uni00000044/uni00000056/uni0000004b/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000027/uni00000044/uni00000057/uni00000044\nFigure 3: Performance of ablated models on Yelp and Ifashion\ndatasets in terms of Recall@20 and NDCG@20.\nâ€¢SLRec [32]: This approach conducts contrastive learning be-\ntween node features to regularize the recommendation learning.\nâ€¢NCL [13]: This model first uses an EM algorithm to perform\nclustering over users, and then conducts neighborhood-enriched\ncontrastive learning within each cluster.\nâ€¢SGL [25]: This model uses random data augmentation operators\n(e.g., edge dropping, node dropping, and random walks) to con-\nstruct views over interaction structures for contrastive learning.\nâ€¢HCCF [28]: This is a state-of-the-art model that conducts con-\ntrastive learning through constructing hypergraph-based global\nand local views for modeling global relations.\n4.1.4 Hyperparameter Settings. We implement our GFormer\nusing PyTorch. We use the Adam optimizer for parameter learning\nwith a learning rate of 1ğ‘’âˆ’3 and no learning rate decay. For model\nhyperparameters of GFormer, we set the embedding size to ğ‘‘ = 32\nby default, the size of the anchor node set to |Vğ´|= 32, and tuned\nthe graph rationale keep rate ğœŒğ‘… in {0.5,0.6,0.7,0.8,0.9}. For coeffi-\ncients of different loss terms, we search for ğœ†1 in {0.5,1,2,4,8},\nğœ†2 in the range {1,1ğ‘’âˆ’1,1ğ‘’âˆ’2,1ğ‘’âˆ’3,1ğ‘’âˆ’4}, and ğœ†3 in the range\n{1ğ‘’âˆ’3,1ğ‘’âˆ’4,1ğ‘’âˆ’5,1ğ‘’âˆ’6,1ğ‘’âˆ’7,1ğ‘’âˆ’8}respectively. We chose the num-\nber of graph transformer layers in the range of {1,2,3,4,5,6}, and\nthe number of graph convolutional layers in {1,2,3,4,5}.\n4.2 Overall Performance Comparison (RQ1)\nWe report the overall performance of GFormer and all compared\nbaselines in terms of Recall@K and NDCG@K under top-10, top-20,\nand top-40 settings in Table 2. To validate the superiority of our\nmodel compared to the strongest baselines, we conduct the test of\nsignificance where ğ‘-val< 0.05 suggests a statistically significant\nimprovement achieved by GFormer. From the experimental results\nin Table 2, we mainly have the following observations:\nâ€¢GFormer consistently outperformed all baselines, including the\nstrong SSL-enhanced methods (e.g., SGL, HCCF) by a large mar-\ngin. We ascribe this superiority to our rationale-aware SSL aug-\nmentation, which automatically derived informative self-supervision\nsignals from the learned collaborative rationale. In contrast, mod-\nels with stochastic SSL augmentations ( e.g., Dropout in SGL)\nperformed much worse due to the possible loss of important\ngraph structural information of sparse users and long-tail items\nin their randomized contrastive views. Moreover, although HCCF\nand NCL both adopted carefully-designed hand-crafted CL tasks,\nthey may not be able to provide accurate self-supervision sig-\nnals (e.g., hard augmented instance) compared to GFormer. In\n0.0 0.1 0.2 0.3 0.4 0.5\nNoise Ratio\n0.88\n0.90\n0.92\n0.94\n0.96\n0.98\n1.00Decrease of Recall@20\nGFormer\nSGL\nLightGCN\n0.0 0.1 0.2 0.3 0.4 0.5\nNoise Ratio\n0.875\n0.900\n0.925\n0.950\n0.975\n1.000Decrease of NDCG@20\nGFormer\nSGL\nLightGCN\n(a) Yelp Dataset\n0.0 0.1 0.2 0.3 0.4 0.5\nNoise Ratio\n0.850\n0.875\n0.900\n0.925\n0.950\n0.975\n1.000Decrease of Recall@20\nGFormer\nSGL\nLightGCN\n0.0 0.1 0.2 0.3 0.4 0.5\nNoise Ratio\n0.85\n0.90\n0.95\n1.00Decrease of NDCG@20\nGFormer\nSGL\nLightGCN\n(b) LastFM Dataset\nFigure 4: Performance on Yelp and LastFM datasets with noise\nperturbation in terms of Recall@20 and NDCG@20.\nthe face of interaction noise, their pretext tasks are easily mis-\nguided by the noisy information contained in the augmented\ndata. Our GFormer tackled these limitations of existing CL mod-\nels by introducing rationale-aware self-augmentation via masked\nautoencoding and thus achieved better performance.\nâ€¢Despite the disadvantages of existing CL methods mentioned\nabove, we observed that baseline models with SSL augmentation\ngenerally performed better than those without (e.g., NGCF, Light-\nGCN). This could be due to the labeled data scarcity problem of\nthe recommendation task, while SSL can mitigate this problem\nby introducing additional self-supervision signals from limited\nobserved interactions. Also, incorporating SSL can also alleviate\nthe over-fitting issue of GNNs for user representations, which\nis used in most strong baselines, on such sparse data and help\nlearn better embeddings for the recommendation.\n4.3 Ablation Study (RQ2)\nTo study the effectiveness of the key components of GFormer, we\nperformed an ablation study over several variants, i.e., -TE, RM,\nMM, and âˆ’LRD. Results in terms of Recall@20 and NDCG@20 are\nplotted in Figure 3, from which we had the following discussions.\n4.3.1 Effect of Global Topology Information Injection. In the\nvariant -TE, we replace the topological embedding with pure id-\ncorresponding embedding to disable topology information injection.\nThe results show that the ablated model has a worse performance\non both datasets. This is because the injection of global topology\ninformation enables our GFormer to capture high-order collabora-\ntive relationships for our graph Transformer to encode informative\ninteraction patterns, so that better graph rationale can be provided\nfor both the recommendation task and the reconstruction task to\nultimately boost the overall performance.\n4.3.2 Effect of Rationale-Aware Self-Augmentation. To study\nthe influence of the key module of GFormer,i.e., the rationale-aware\nself-augmentation module, we replace it with random masking in\nvariant RM and an MLP-based masking strategy in variant MM.\nSpecifically, for an edge (ğ‘¢,ğ‘£), the MM variant first feeds the em-\nbeddings Â¯hğ‘¢,Â¯hğ‘£ into a multi-layer perceptron (MLP) to compute\nSIGIR â€™23, July 23â€“27, 2023, Taipei, Taiwan Chaoliu Li, Lianghao Xia, Xubin Ren, Yaowen Ye, Yong Xu, & Chao Huang\n0.1 0.2 0.3\nDrop Rate\n0.04\n0.05\n0.06\n0.07\n0.08Recall@20\n0.1 0.2 0.3\nDrop Rate\n0.020\n0.025\n0.030\n0.035\n0.040NDCG@20\n/uni0000000b/uni00000044/uni0000000c/uni00000003/uni0000003c/uni00000048/uni0000004f/uni00000053/uni00000003/uni00000027/uni00000044/uni00000057/uni00000044\nGFormer SGL HCCF LightGCN\n0.1 0.2 0.3\nDrop Rate\n0.10\n0.15\n0.20Recall@20\n0.1 0.2 0.3\nDrop Rate\n0.100\n0.125\n0.150\n0.175\n0.200NDCG@20\n/uni0000000b/uni00000045/uni0000000c/uni00000003/uni0000002f/uni00000044/uni00000056/uni00000057/uni00000029/uni00000030/uni00000003/uni00000027/uni00000044/uni00000057/uni00000044\nFigure 5: Performance on Yelp and LastFM datasets under\ndifferent sparsity level in terms of Recall@20 and NDCG@20.\nthe importance score of nodes ğ‘¢,ğ‘£, and then obtains the mask prob-\nability of the edge by dot product of node importance score, i.e.,\nMLP(Â¯hğ‘¢)Â· MLP(Â¯hğ‘¢). The results show that both variants have a\nsignificant performance drop, suggesting that random masking and\ntrivial adaptive masking through MLPs are both unable to discover\nimportant graph structures. Instead, they may corrupt informative\nstructures of the interaction graph and introduce additional noise\nto the SSL task. In contrast, our GFormer avoids these disadvan-\ntages by incorporating meaningful self-supervision signals from\nthe learned graph rationale ğ‘…(G)and utilizing the complement\nğ¶(ğ‘…(G))for model denoising, resulting in better performance.\n4.3.3 Effect of Adaptive Rationale Learning. The downstream\nrecommendation loss LRD (Eq. 10) plays a crucial role in GFormer\nby guiding graph invariant rationale learning with adaptive su-\npervision signals. To verify its contribution, we remove LRD in\nthe variant âˆ’LRD, which leads to severe performance degradation.\nThis is because LRD allows our GFormer to discover relevant graph\nrationale that captures graph structures specifically useful for the\nrecommendation task. Different SSL modules in GFormer can then\nbe optimized in a better-aligned way. Furthermore, we observe that\nthe degradation caused by removing LRD is larger on the Ifashion\ndataset. This may be due to the larger amount and denser inter-\naction data of Ifashion compared to Yelp, which provides the loss\nLRD with more supervision signals and higher importance.\n4.4 Model Robustness Study (RQ3)\nIn this section, we study the robustness of our model against data\nnoise and data scarcity by testing the model performance on manu-\nally damaged training data from the corresponding two dimensions,\nin comparison to representative baseline methods.\n4.4.1 Robustness against Data Noise. To study the robustness\nof GFormer against noise perturbation, we randomly inject different\nproportions (10%,20%,30%,40%,50%) of edges with artificial noise\non the original interaction graph and evaluate the performance\nof GFormer and representative strong baseline methods on these\nnoisy datasets. As shown by the results illustrated in Figure 4, our\nGFormer consistently achieves the lowest performance degradation\nunder all noise levels. Under lower levels of noise (e.g., 10% to 40%),\nwe observe that SSL-enhanced methods (SGL) have a degradation\nratio similar to LightGCN, suggesting that stochastic SSL augmen-\ntation does not significantly improve robustness against data noise.\nIn contrast, our GFormer adopts an automated SSL paradigm that is\nrationale-aware, making it possible to discover latent informative\nstructures in a noisy dataset for representation.\n0 30 60 90\nepoch\n0.03\n0.04\n0.05\n0.06\n0.07\n0.08\n0.09Recall@20 GFormer\nHCCF\nLightGCN\n0 30 60 90\nepoch\n0.015\n0.020\n0.025\n0.030\n0.035\n0.040\n0.045NDCG@20 GFormer\nHCCF\nLightGCN\nFigure 6: Test results in terms of Recall@20 and NDCG@20\nw.r.t training epochs on Yelp dataset. The stars represent\npoints of convergence. Compared with baselines, the faster\nconvergence rate of our GFormer can be observed.\n0 100 200 300 400 500\nDimension of Embeddings\n0.20\n0.21\n0.22\n0.23\n0.24Recall@20\n0 100 200 300 400 500\nDimension of Embeddings\n0.200\n0.205\n0.210\n0.215\n0.220\n0.225NDCG@20\nFigure 7: Performance in terms of Recall@20 and NDCG@20\nunder different embedding dimensionality.\n4.4.2 Robustness against Data Sparsity. We also conduct exper-\niments to evaluate the performance of GFormer on various sparsity\nlevels. Specifically, we drop a certain proportion (10%,20%,30%) of\ninteractions in the dataset and run GFormer as well as represen-\ntative baseline methods on the sparsified datasets. As shown by\nthe results in Figure 5, our GFormer outperforms all other models\nunder all sparsity levels, suggesting that our rationale-enhanced\nSSL framework enables GFormer to generate more meaningful\nself-supervision signals than common SSL models on sparse data,\nthereby increasing the modelâ€™s robustness against data sparsity.\nAdditionally, we observe that the performance degradation with\nrespect to the drop rate is more significant on the Yelp dataset com-\npared to the LastFM dataset. This may be caused by the relatively\nhigher interaction sparsity of the Yelp dataset, such that dropping\nmore interactions severely hinders effective CF modeling.\n4.5 Model Convergence Study (RQ4)\nTo analyze the training efficiency of our proposed GFormer, we\nplot the convergence curve (i.e., test metric values with respect to\ntraining epochs) of GFormer and three strong baseline methods,\nincluding SSL-enhanced methods (e.g., HCCF), in Figure 6. It can\nbe observed from the stars indicating convergence that GFormer\nonly takes fewer than 30 epochs to converge, which is much faster\ncompared to other models. We attribute this superiority to the help-\nful task-adaptive self-supervision signals derived from our learned\ngraph rationale. Stochastic data augmentation strategies cannot ac-\ntively discover important graph structures for the recommendation\ntask and may provide misleading self-supervision signals during\nthe training stage, thus the baseline models are naturally optimized\nin a slower manner. Our proposed SSL augmentation focuses on the\nrecommendation task and adapts fast, enabling GFormer to achieve\nthe best performance in an early stage. The faster performance im-\nprovement of SSL-based methods compared to LightGCN is likely\ncaused by the low-temperature contrastive learning.\nGraph Transformer for Recommendation SIGIR â€™23, July 23â€“27, 2023, Taipei, Taiwan\n0.5 0.8 0.9 0.98\nKeep Ratio R\n0.082\n0.083\n0.084\n0.085Recall@20\n0.5 1 2 4\nRationale Discovery Weight 1\n0.0865\n0.0870\n0.0875\n0.0880\n0.0885\n0.0890Recall@20\n0 1 3 6\nNumber of Layers L\n0.085\n0.086\n0.087\n0.088\n0.089Recall@20\n0.5 0.8 0.9 0.98\nKeep Ratio R\n0.0410\n0.0415\n0.0420\n0.0425NDCG@20\n0.5 1 2 4\nRationale Discovery Weight 1\n0.0435\n0.0440\n0.0445\n0.0450NDCG@20\n0 1 3 6\nNumber of Layers L\n0.0425\n0.0430\n0.0435\n0.0440\n0.0445\n0.0450NDCG@20\nFigure 8: Performance under different hyperparameter set-\ntings in terms of Recall@20 and NDCG@20 on Yelp dataset.\n4.6 Hyperparameter Study (RQ5)\nTo study the effect of various hyperparameters on the model per-\nformance, we present experiment results in terms of Recall@20 and\nNDCG@20 on the LastFM dataset in Figure 7 and 8. The following\nobservations corresponding to different hyperparameters are made:\nâ€¢Dimension of latent space ğ‘‘: We tune the size of user and item\nembeddings from 8 to 512. As shown in Figure 7, an increase\nin the embedding dimension leads to significant performance\nimprovement at the beginning. This is because a larger dimen-\nsionality allows our topological embedding to capture richer\ninformation about the global user-item topology and provide\nuseful representations for other modules in GFormer. However,\ntoo large sizes ( e.g., ğ‘‘ > 256) only bring subtle improvement,\nsince this may cause the over-fitting problem of GNNs.\nâ€¢Keep ratio ğœŒğ‘…: This hyperparameter controls the proportion of\ninteraction edges to be selected and form the graph rationale Gğ‘….\nResults show that a low keep ratio harms model performance\nsince insufficient collaborative relations are obtained in the graph\nrationale for representation learning. However, setting the keep\nratio close to 1 also leads to a performance drop, because noisy\ninteractions in the original graph cannot be adequately dropped.\nâ€¢Collaborative rationale discovery weight ğœ†1: This hyperpa-\nrameter controls the regularization strength of the objective from\nthe downstream recommendation task. LRD is used to guide the\ngraph rationale discovery in our masked graph transformer par-\nadigm. From the results, we observe that applying large enough\nweights greatly improves the model performance due to the ben-\nefits brought by the discovery of task-relevant graph rationale\nfor augmentation. However, setting the weight forLRD too large\nmay be counterproductive due to the overfitting effect.\nâ€¢Number of layers ğ¿ in Global Information Injection : In\nour GFormer, the designed global information injection module\ncan achieve competitive results with one iteration. We found\nin our experiments that global information encoding with too\nmany layers results in serious damage to performance. Such over-\nsmoothed representations may adversely affect the discovery\nof rationale-aware augmentation with indistinguishable embed-\ndings. Additionally, setting ğ¿= 0, i.e. removing global topology\ninformation injection (Section 3.1.2), leads to even worse perfor-\nmance due to insufficient modeling of high-order relations.\nğ‘¢à¬½à¬·ğ‘à¬½à¬´à¬¼ğ‘à¬½à¬´à¬¶ğ‘à¬½à¬¶à¬½Review for (ğ‘¢à¬½à¬·, ğ‘à¬½à¬´à¬¼)It's a lovely store and ... Customer service was very friendlyâ€¦Review for (ğ‘¢à¬½à¬·, ğ‘à¬½à¬¶à¬½)I'm not impressed with this ... women's clothing selection is not that great ...0.80.570.4\nğ‘¢à¬ºà¬»ğ‘à¬¹à¬¹à¬µğ‘à¬¹à¬¸à¬µğ‘à¬¹à¬ºà¬´Review for (ğ‘¢à¬ºà¬», ğ‘à¬¹à¬¸à¬µ)The combination was great! ... the cashier was friendly. ...Review for (ğ‘¢à¬ºà¬», ğ‘à¬¹à¬ºà¬´)The rice that came with my food had no flavor and it tasted like boxed rice ...0.671.30.57\nğ‘¢à¬µà¬µà¬¼ğ‘à¬µà¬¶à¬¸à¬¹ğ‘à¬µà¬¶à¬¼à¬´ğ‘à¬µà¬¶à¬·à¬¶Review for (ğ‘¢à¬µà¬µà¬¼, ğ‘à¬µà¬¶à¬·à¬¶)â€¦ The service, drinks, and food was excellent... What a wonderfulâ€¦ !Review for (ğ‘¢à¬µà¬µà¬¼, ğ‘à¬µà¬¶à¬¼à¬´)â€¦ my box was only half full and it wasn't filling enough for a lunch meal â€¦0.81.30.28\nğ›¼à´¤ (Eq. 8)ğ‘¢à¬½à¬·\nğ‘¢à¬·à¬µà¬·à¬ºğ‘à¬½à¬´à¬¼ğ‘à¬½à¬´à¬¶ğ‘à¬½à¬¶à¬½4334rating score (0~5)Review for (ğ‘¢à¬·à¬µà¬·à¬º, ğ‘à¬½à¬´à¬¼)This target is pretty big and has a grocery selection, which is awesomebecause I can do all my shopping here! They also price match on video games. They have a pharmacy and even a Starbucks in this location. The staff seems nice.0.80.570.40.44ğ›¼à´¤ (Eq. 8)\nFigure 9: Case study of collaborative rationale discovery for\ndistilling informative knowledge from noisy interactions.\n4.7 Case Study (RQ6)\nTo study the interpretation ability of GFormer, a case study is per-\nformed over several representative users sampled from the Yelp\ndataset. Specifically, we inspect the corresponding reviews and\nratings given by a user to their interacted items, which are not\nused for model training, and see whether they match our corre-\nlation score Â¯ğ›¼ for collaborative rationale discovery. As illustrated\nin Figure 9, the items with the highest correlation scores for users\nğ‘¢93,ğ‘¢67,ğ‘¢118 all match the items they gave positive feedback, while\nedges to items with unsatisfying reviews are generally given lower\nscores. These results suggest that GFormer can emphasize learning\non informative user-item correlations and utilize these interaction\ndata to enhance the model learning through the reconstruction SSL.\nFurthermore, when we investigate the specific ratings given byğ‘¢93,\nwe observe that the edge with the highest correlation score ( i.e.,\n(ğ‘¢93,ğ‘908)) corresponds to the userâ€™s highest rating. Meanwhile,\nalthough ğ‘¢3136 gives a higher rating (4) than ğ‘¢93 (3) to item ğ‘929,\nthe edge (ğ‘¢3136,ğ‘929)is given a low correlation score similar to\n(ğ‘¢93,ğ‘929). This could be due to the fact that user ğ‘¢3136 is very\nlikely to provide many high ratings (36 out of 47 of all ratings given\nby ğ‘¢3136 are 4 or 5). Our rationale discovery module successfully\nidentifies such bias and adaptively adjusts the correlation score\nwith respect to different user behaviors.\n5 CONCLUSION\nThis paper aims to uncover useful user-item interaction patterns\nas rationales for augmenting collaborative filtering with the learn-\ning of invariant rationales for SSL. Our proposed GFormer model\nprovides guidance to distill semantically informative graph con-\nnections with the integration of global topology embedding and\ntask-adaptation. Our work opens avenues for constructing rationale-\naware general augmentation through masked graph autoencoding.\nOur empirical results suggest that SSL-based augmentation with\neffective rationalization can facilitate user preference learning, and\nthus significantly boost recommendation performance. While our\nnew model already endows adaptive augmentation with task-aware\nrationale discovery, it is an interesting open question on how to\nadapt it to other recommendation scenarios, such as social-aware\nrecommendation and knowledge graph-enhanced recommenders.\nSIGIR â€™23, July 23â€“27, 2023, Taipei, Taiwan Chaoliu Li, Lianghao Xia, Xubin Ren, Yaowen Ye, Yong Xu, & Chao Huang\nREFERENCES\n[1] Xuheng Cai, Chao Huang, Lianghao Xia, and Xubin Ren. 2023. LightGCL: Simple\nYet Effective Graph Contrastive Learning for Recommendation. In The Eleventh\nInternational Conference on Learning Representations (ICLR) .\n[2] Lei Chen, Le Wu, Richang Hong, Kun Zhang, and Meng Wang. 2020. Revisiting\ngraph based collaborative filtering: A linear residual graph convolutional network\napproach. In AAAI Conference on Artificial Intelligence (AAAI) , Vol. 34. 27â€“34.\n[3] Yabo Chen, Yuchen Liu, Dongsheng Jiang, Xiaopeng Zhang, Wenrui Dai, Hongkai\nXiong, and Qi Tian. 2022. Sdae: Self-distillated masked autoencoder. In European\nConference on Computer Vision (ECCV) . Springer, 108â€“124.\n[4] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr DollÃ¡r, and Ross Girshick.\n2022. Masked autoencoders are scalable vision learners. In IEEE/CVF Conference\non Computer Vision and Pattern Recognition (CVPR) . 16000â€“16009.\n[5] Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng\nWang. 2020. Lightgcn: Simplifying and powering graph convolution network\nfor recommendation. In International Conference on Research and Development in\nInformation Retrieval (SIGIR) . 639â€“648.\n[6] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua.\n2017. Neural collaborative filtering. In The Web Conference (WWW) . 173â€“182.\n[7] Zhenyu Hou, Xiao Liu, Yukuo Cen, Yuxiao Dong, Hongxia Yang, Chunjie Wang,\nand Jie Tang. 2022. Graphmae: Self-supervised masked graph autoencoders. In\nInternational Conference on Knowledge Discovery and Data Mining (KDD) .\n[8] Bowen Jin, Chen Gao, Xiangnan He, Depeng Jin, and Yong Li. 2020. Multi-\nbehavior recommendation with graph convolutional networks. In International\nConference on Research and Development in Information Retrieval (SIGIR) . 659â€“668.\n[9] Thomas N Kipf and Max Welling. 2017. Semi-Supervised Classification with\nGraph Convolutional Networks. In International Conference on Learning Repre-\nsentations (ICLR) .\n[10] Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix factorization tech-\nniques for recommender systems. Computer 42, 8 (2009), 30â€“37.\n[11] Haoyang Li, Ziwei Zhang, Xin Wang, and Wenwu Zhu. 2022. Learning invari-\nant graph representations for out-of-distribution generalization. In Advances in\nNeural Information Processing Systems (NeurIPS) .\n[12] Sihang Li, Xiang Wang, An Zhang, Yingxin Wu, Xiangnan He, and Tat-Seng\nChua. 2022. Let invariant rationale discovery inspire graph contrastive learning.\nIn International Conference on Machine Learning (ICML) . PMLR, 13052â€“13065.\n[13] Zihan Lin, Changxin Tian, Yupeng Hou, and Wayne Xin Zhao. 2022. Improving\ngraph collaborative filtering with neighborhood-enriched contrastive learning.\nIn The Web Conference (WWW) . 2320â€“2329.\n[14] Dongsheng Luo, Wei Cheng, Wenchao Yu, Bo Zong, Jingchao Ni, Haifeng Chen,\nand Xiang Zhang. 2021. Learning to drop: Robust graph neural network via\ntopological denoising. In International Conference on Web Search and Data Mining\n(WSDM). 779â€“787.\n[15] Suvash Sedhain, Aditya Krishna Menon, Scott Sanner, and Lexing Xie. 2015.\nAutorec: Autoencoders meet collaborative filtering. In Proceedings of the 24th\ninternational conference on World Wide Web . 111â€“112.\n[16] Jie Shuai, Kun Zhang, Le Wu, Peijie Sun, Richang Hong, Meng Wang, and Yong Li.\n2022. A review-aware graph contrastive learning framework for recommendation.\nIn International Conference on Research and Development in Information Retrieval\n(SIGIR). 1283â€“1293.\n[17] Jianing Sun, Zhaoyue Cheng, Saba Zuberi, Felipe PÃ©rez, and Maksims Volkovs.\n2021. Hgcf: Hyperbolic graph convolution networks for collaborative filtering.\nIn The Web Conference (WWW) . 593â€“601.\n[18] Changxin Tian, Yuexiang Xie, Yaliang Li, Nan Yang, and Wayne Xin Zhao. 2022.\nLearning to Denoise Unreliable Interactions for Graph Collaborative Filtering. In\nInternational Conference on Research and Development in Information Retrieval\n(SIGIR). 122â€“132.\n[19] Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019.\nNeural graph collaborative filtering. In International Conference on Research and\nDevelopment in Information Retrieval (SIGIR) . 165â€“174.\n[20] Xiang Wang, Hongye Jin, An Zhang, Xiangnan He, Tong Xu, and Tat-Seng Chua.\n2020. Disentangled graph collaborative filtering. In International Conference on\nResearch and Development in Information Retrieval (SIGIR) . 1001â€“1010.\n[21] Yifan Wang, Suyao Tang, Yuntong Lei, Weiping Song, Sheng Wang, and Ming\nZhang. 2020. Disenhan: Disentangled heterogeneous graph attention network\nfor recommendation. In International Conference on Information & Knowledge\nManagement (CIKM). 1605â€“1614.\n[22] Zhenyi Wang, Huan Zhao, and Chuan Shi. 2022. Profiling the Design Space for\nGraph Neural Networks based Collaborative Filtering. InInternational Conference\non Web Search and Data Mining (WSDM) . 1109â€“1119.\n[23] Wei Wei, Chao Huang, Lianghao Xia, and Chuxu Zhang. 2023. Multi-Modal\nSelf-Supervised Learning for Recommendation. In The Web Conference (WWW) .\n790â€“800.\n[24] Felix Wu, Amauri Souza, Tianyi Zhang, Christopher Fifty, Tao Yu, and Kilian\nWeinberger. 2019. Simplifying graph convolutional networks. In International\nConference on Machine Learning (ICML) . PMLR, 6861â€“6871.\n[25] Jiancan Wu, Xiang Wang, Fuli Feng, Xiangnan He, Liang Chen, Jianxun Lian,\nand Xing Xie. 2021. Self-supervised graph learning for recommendation. In\nInternational Conference on Research and Development in Information Retrieval\n(SIGIR). 726â€“735.\n[26] Yingxin Wu, Xiang Wang, An Zhang, Xiangnan He, and Tat-Seng Chua. 2022.\nDiscovering Invariant Rationales for Graph Neural Networks. In International\nConference on Learning Representations (ICLR) .\n[27] Lianghao Xia, Chao Huang, Jiao Shi, and Yong Xu. 2023. Graph-less Collaborative\nFiltering. In ACM Web Conference (WWW) . 17â€“27.\n[28] Lianghao Xia, Chao Huang, Yong Xu, Jiashu Zhao, Dawei Yin, and Jimmy Huang.\n2022. Hypergraph contrastive collaborative filtering. In International Conference\non Research and Development in Information Retrieval (SIGIR) . 70â€“79.\n[29] Lianghao Xia, Yong Xu, Chao Huang, Peng Dai, and Liefeng Bo. 2021. Graph\nmeta network for multi-behavior recommendation. In International Conference\non Research and Development in Information Retrieval . 757â€“766.\n[30] Yuhao Yang, Chao Huang, Lianghao Xia, Chunzhen Huang, Da Luo, and Kangyi\nLin. 2023. Debiased Contrastive Learning for Sequential Recommendation. In\nThe Web Conference (WWW) . 1063â€“1073.\n[31] Yonghui Yang, Le Wu, Richang Hong, Kun Zhang, and Meng Wang. 2021. En-\nhanced graph learning for collaborative filtering via mutual information maxi-\nmization. In International Conference on Research and Development in Information\nRetrieval (SIGIR) . 71â€“80.\n[32] Tiansheng Yao, Xinyang Yi, Derek Zhiyuan Cheng, Felix Yu, Ting Chen, Aditya\nMenon, Lichan Hong, Ed H Chi, Steve Tjoa, Jieqi Kang, et al. 2021. Self-supervised\nlearning for large-scale item recommendations. In International Conference on\nInformation & Knowledge Management (CIKM) . 4321â€“4330.\n[33] Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton,\nand Jure Leskovec. 2018. Graph convolutional neural networks for web-scale\nrecommender systems. In Proceedings of the 24th ACM SIGKDD international\nconference on knowledge discovery & data mining . 974â€“983.\n[34] Jiaxuan You, Rex Ying, and Jure Leskovec. 2019. Position-aware graph neural\nnetworks. In International Conference on Machine Learning (ICML) . PMLR, 7134â€“\n7143.\n[35] Yuning You, Tianlong Chen, Yang Shen, and Zhangyang Wang. 2021. Graph\ncontrastive learning automated. In International Conference on Machine Learning\n(ICML). PMLR, 12121â€“12132.\n[36] Mo Yu, Shiyu Chang, Yang Zhang, and Tommi S Jaakkola. 2019. Rethinking\ncooperative rationalization: Introspective extraction and complement control.\nInternational Conference on Empirical Methods in Natural Language Processing\n(EMNLP).\n[37] Rowan Zellers, Yonatan Bisk, Ali Farhadi, and Yejin Choi. 2019. From recogni-\ntion to cognition: Visual commonsense reasoning. In IEEE/CVF Conference on\nComputer Vision and Pattern Recognition (CVPR) . 6720â€“6731.\n[38] Jiani Zhang, Xingjian Shi, Shenglin Zhao, and Irwin King. 2019. Star-gcn: Stacked\nand reconstructed graph convolutional networks for recommender systems. In\nAAAI Conference on Artificial Intelligence (AAAI) .\n[39] Yang Zhang, Fuli Feng, Xiangnan He, Tianxin Wei, Chonggang Song, Guohui\nLing, and Yongdong Zhang. 2021. Causal intervention for leveraging popularity\nbias in recommendation. InInternational Conference on Research and Development\nin Information Retrieval (SIGIR) . 11â€“20.\n[40] Zhenyu Zhang, Bowen Yu, Xiaobo Shu, Xue Mengge, Tingwen Liu, and Li Guo.\n2021. From What to Why: Improving Relation Extraction with Rationale Graph.\nIn Association for Computational Linguistics (ACL) . 86â€“95.\n[41] Kun Zhou, Hui Wang, Wayne Xin Zhao, Yutao Zhu, Sirui Wang, Fuzheng Zhang,\nZhongyuan Wang, and Ji-Rong Wen. 2020. S3-rec: Self-supervised learning for\nsequential recommendation with mutual information maximization. In Interna-\ntional Conference on Information & Knowledge Management (CIKM) . 1893â€“1902.\n[42] Yanqiao Zhu, Yichen Xu, Feng Yu, Qiang Liu, Shu Wu, and Liang Wang. 2021.\nGraph contrastive learning with adaptive augmentation. In The Web Conference\n(WWW). 2069â€“2080.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8334632515907288
    },
    {
      "name": "Recommender system",
      "score": 0.5700545907020569
    },
    {
      "name": "Collaborative filtering",
      "score": 0.5333006381988525
    },
    {
      "name": "Transformer",
      "score": 0.4915846288204193
    },
    {
      "name": "Machine learning",
      "score": 0.4889308512210846
    },
    {
      "name": "Graph",
      "score": 0.46949198842048645
    },
    {
      "name": "Generative grammar",
      "score": 0.4407280683517456
    },
    {
      "name": "Artificial intelligence",
      "score": 0.36663803458213806
    },
    {
      "name": "Theoretical computer science",
      "score": 0.3231821060180664
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ]
}