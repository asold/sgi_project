{
  "title": "Debiasing the Cloze Task in Sequential Recommendation with Bidirectional Transformers",
  "url": "https://openalex.org/W4290874879",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5050164663",
      "name": "Khalil Damak",
      "affiliations": [
        "University of Louisville"
      ]
    },
    {
      "id": "https://openalex.org/A5075136071",
      "name": "Sami Khenissi",
      "affiliations": [
        "University of Louisville"
      ]
    },
    {
      "id": "https://openalex.org/A5049581991",
      "name": "Olfa Nasraoui",
      "affiliations": [
        "University of Louisville"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2112430581",
    "https://openalex.org/W6600213211",
    "https://openalex.org/W2998673651",
    "https://openalex.org/W2912967843",
    "https://openalex.org/W2157331557",
    "https://openalex.org/W3187508330",
    "https://openalex.org/W2077927809",
    "https://openalex.org/W2219888463",
    "https://openalex.org/W2340502990",
    "https://openalex.org/W2626454364",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2101409192",
    "https://openalex.org/W2963367478",
    "https://openalex.org/W1992380306",
    "https://openalex.org/W1886704267",
    "https://openalex.org/W2027731328",
    "https://openalex.org/W2023603028",
    "https://openalex.org/W2124187902",
    "https://openalex.org/W3026347803",
    "https://openalex.org/W2998534896",
    "https://openalex.org/W2984100107",
    "https://openalex.org/W2945357717",
    "https://openalex.org/W2783272285",
    "https://openalex.org/W2270070752",
    "https://openalex.org/W2144807535",
    "https://openalex.org/W3011809564",
    "https://openalex.org/W2892888989",
    "https://openalex.org/W2624617553",
    "https://openalex.org/W3035539704",
    "https://openalex.org/W2937556626",
    "https://openalex.org/W3119551859",
    "https://openalex.org/W3100917752",
    "https://openalex.org/W1598796236",
    "https://openalex.org/W1928278792",
    "https://openalex.org/W4310228395",
    "https://openalex.org/W3106445281",
    "https://openalex.org/W3049332778",
    "https://openalex.org/W3185693672",
    "https://openalex.org/W4293876646",
    "https://openalex.org/W2187424591",
    "https://openalex.org/W1547531277",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W3200608657",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3102619277",
    "https://openalex.org/W2176263492",
    "https://openalex.org/W4299286960"
  ],
  "abstract": "Bidirectional Transformer architectures are state-of-the-art sequential recommendation models that use a bi-directional representation capacity based on the Cloze task, a.k.a. Masked Language Modeling. The latter aims to predict randomly masked items within the sequence. Because they assume that the true interacted item is the most relevant one, an exposure bias results, where non-interacted items with low exposure propensities are assumed to be irrelevant. The most common approach to mitigating exposure bias in recommendation has been Inverse Propensity Scoring (IPS), which consists of down-weighting the interacted predictions in the loss function in proportion to their propensities of exposure, yielding a theoretically unbiased learning. In this work, we argue and prove that IPS does not extend to sequential recommendation because it fails to account for the temporal nature of the problem. We then propose a novel propensity scoring mechanism, which can theoretically debias the Cloze task in sequential recommendation. Finally we empirically demonstrate the debiasing capabilities of our proposed approach and its robustness to the severity of exposure bias.",
  "full_text": "Debiasing the Cloze Task in Sequential Recommendation with\nBidirectional Transformers\nKhalil Damakâˆ—\nkhalil.damak@louisville.edu\nKnowledge Discovery & Web Mining\nLab, Dept. of Computer Science &\nEngineering, University of Louisville\nLouisville, Kentucky, USA\nSami Khenissiâˆ—\nsami.khenissi@louisville.edu\nKnowledge Discovery & Web Mining\nLab, Dept. of Computer Science &\nEngineering, University of Louisville\nLouisville, Kentucky, USA\nOlfa Nasraoui\nolfa.nasraoui@louisville.edu\nKnowledge Discovery & Web Mining\nLab, Dept. of Computer Science &\nEngineering, University of Louisville\nLouisville, Kentucky, USA\nABSTRACT\nBidirectional Transformer architectures are state-of-the-art sequen-\ntial recommendation models that use a bi-directional representation\ncapacity based on the Cloze task, a.k.a. Masked Language Model-\ning. The latter aims to predict randomly masked items within the\nsequence. Because they assume that the true interacted item is the\nmost relevant one, an exposure bias results, where non-interacted\nitems with low exposure propensities are assumed to be irrelevant.\nThe most common approach to mitigating exposure bias in rec-\nommendation has been Inverse Propensity Scoring (IPS), which\nconsists of down-weighting the interacted predictions in the loss\nfunction in proportion to their propensities of exposure, yielding a\ntheoretically unbiased learning. In this work, we argue and prove\nthat IPS does not extend to sequential recommendation because it\nfails to account for the temporal nature of the problem. We then\npropose a novel propensity scoring mechanism, which can theoret-\nically debias the Cloze task in sequential recommendation. Finally\nwe empirically demonstrate the debiasing capabilities of our pro-\nposed approach and its robustness to the severity of exposure bias.\nCCS CONCEPTS\nâ€¢ Information systems â†’Collaborative filtering; Recommender\nsystems; Information retrieval; â€¢ Computing methodologies\nâ†’Machine learning.\nKEYWORDS\nexposure bias; cloze task; sequential recommender system; trans-\nformers\nACM Reference Format:\nKhalil Damak, Sami Khenissi, and Olfa Nasraoui. 2022. Debiasing the Cloze\nTask in Sequential Recommendation with Bidirectional Transformers. In\nProceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery\nand Data Mining (KDD â€™22), August 14â€“18, 2022, Washington, DC, USA. ACM,\nNew York, NY, USA, 10 pages. https://doi.org/10.1145/3534678.3539430\nâˆ—This work was performed while KD and SK were PhD students at University of\nLouisville. Currently, KD is affiliated with Amazon, and SK is affiliated with Meta.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior specific permission and/or a\nfee. Request permissions from permissions@acm.org.\nKDD â€™22, August 14â€“18, 2022, Washington, DC, USA\nÂ© 2022 Association for Computing Machinery.\nACM ISBN 978-1-4503-9385-0/22/08. . . $15.00\nhttps://doi.org/10.1145/3534678.3539430\n1 INTRODUCTION\nSequential recommendation is a recommendation setting in which\nthe goal is to predict the next best interaction or interactions given a\nsequence of previous interactions through time [36]. Most success-\nful recent work relies on deep learning models including Recurrent\nNeural Networks (RNNs) [5, 13â€“15, 21], Convolutional Neural Net-\nworks (CNNs) [18, 32], and more recently, self-attention modules\n[7, 17, 30, 35]. Recent research has also addressed different biases\nin recommendation [ 2]. In particular, exposure bias stems from\nthe partial exposure of items to the users [2], making items with\nrelatively low exposure often considered to be irrelevant in building\npredictive models. Ideally, recommender systems should capture\nthe true relevance of the items to the users, regardless of their\npropensities of exposure. However, this is far from true on real life\nrecommendation platforms. Exposure bias can be mitigated during\nthe training of recommender systems [2], mainly by making the\nmodels aware of the itemsâ€™ exposure propensities. One of the most\ncommon approaches consists of building propensity-weighted loss\nfunctions that are unbiased estimates of the desirable relevance-\nbased objectives [27, 28]. This approach, called Inverse Propensity\nScoring (IPS), showed success in recommendation settings with\nuser profiles [31]. Despite the progress in this area, to the extent\nof our knowledge, no previous work has addressed the problem\nof exposure bias in sequential recommendation. In this paper, we\nmitigate exposure bias in bi-directional transformer-based recom-\nmender systems, which are considered state-of-the-art sequential\nrecommender systems [30], and more specifically, the widely-used\nBERT4Rec model [ 30]. More broadly however, our work covers\nany sequential recommender system that is trained to optimize the\nCloze task [7, 33]. Our contributions are summarized as follows:\nâ€¢We theoretically formulate the problem of exposure bias in\nthe Cloze task, and argue and prove that traditional Inverse\nPropensity Scoring (IPS) based debiasing frameworks do not\nextend to sequential recommendation.\nâ€¢We propose an ideal Cloze task loss function that aims to\ncapture the relevance of items within a sequence context.\nâ€¢We propose a novel framework for debiasing the Cloze\ntask in sequential recommendation, called Inverse Temporal\nPropensity Scoring (ITPS), and use it to propose a novel loss\nfunction that produces an unbiased estimator for the ideal\nCloze task loss.\nâ€¢We make our implementation available to the public1.\n1https://github.com/KhalilDMK/DebiasedBERT4Rec\narXiv:2301.09210v1  [cs.LG]  22 Jan 2023\nKDD â€™22, August 14â€“18, 2022, Washington, DC, USA Khalil Damak, Sami Khenissi, & Olfa Nasraoui\nâ€¢We conduct experiments that demonstrate the debiasing\ncapabilities of our ITPS-based estimator, and empirically\nvalidate our theoretically proven claims.\n2 BACKGROUND\nExposure bias occurs when user interactions are dependent upon\nthe exposure of the items. Thus, recommender systems trained on\ncollected data would assume that interaction represents relevance;\nand hence, non-interacted items would be considered irrelevant\nregardless of whether they had a chance to be exposed or not. Pre-\nvious work addressing exposure bias varied in whether they treat\nbias during the training or evaluation [2]. The common approach\nto mitigating exposure bias in the evaluation of recommender sys-\ntems relies on incorporating Inverse Propensity Scoring (IPS) in\nthe ranking evaluation metrics. More specifically, items are down-\nweighted by their popularities in the evaluation metrics [38]. On\nthe other hand, a variety of techniques were introduced to mitigate\nexposure bias in the training phase. Some of these techniques are\nbased on integrating a measure of confidence into the unobserved\ninteractions when considering them as irrelevant. Among these\ntechniques, a few [8, 16] considered a uniform weight for all neg-\native items that is lower than one; while others [ 23, 24] utilized\nuser activity, such as the number of interacted items, to weight\nthe negative interactions. Other approaches used item popularity\n[12, 39] and user-item similarity [19] instead. Another line of work\nproposed IPS-based unbiased estimators for the ideal pointwise\n[28] and pairwise [6, 27] losses, and estimated the propensity of an\ninteraction using the relative item popularity. Departing from the\npreviously mentioned methods, some methods proposed new nega-\ntive sampling processes to mitigate exposure bias during training.\nThis is usually performed by exploiting side information such as\nsocial network information [4] or item-based knowledge graphs\n[37]. Another approach consists of integrating the ability to learn\nthe exposure probability within the model by making assumptions\non the probability distribution of exposure [3, 4, 20].\nThe above methods share the limitation of recommendation with\nuser profiles, where the goal is to predict items to users regardless\nof the temporal context of the previous interactions. To the extent\nof our knowledge, no previous work has validated these techniques\nin sequential recommendation. Furthermore, only a few studies [26,\n41] have addressed exposure bias in sequential recommendation.\nHowever, these approaches treated sequential recommendation in\na seq2seq adversarial setting, and use a different formulation of\nexposure bias which consists of a discrepancy between the training\ndata distribution and the data distribution generated by the model\n[25], rather than a discrepancy between relevance and interaction.\nWe address the aforementioned gaps by first studying the limita-\ntions of Inverse Propensity Scoring for mitigating exposure bias in\nsequential recommender systems, and then proposing a debiasing\nframework that is tailored to sequential recommendation.\n3 PROBLEM FORMULATION AND\nMOTIVATION\nWe start by formulating the sequential recommendation setting\nbefore presenting the Cloze task in bidirectional transformer-based\nmodels. Next, we discuss the exposure bias problem in the Cloze\ntask, and how the traditional Inverse Propensity Scoring (IPS) frame-\nwork does not generalize to sequential recommendation.\n3.1 Sequential Recommendation\nLet ğ‘† be a sequential recommendation dataset comprised of |ğ‘†|\nsequences. Each sequence ğ‘†ğ‘  is a succession of consecutive item\ninteractions by a user during a certain period of time. An interaction\ncould be defined as a click, rating, review, or consumption, and the\ntime span of the sequence could be short or long. Also, consider\na set of items ğ¼. The sequence ğ‘†ğ‘  can be represented by its item\ninteractions, for example ğ‘†ğ‘  = [ğ¼1,ğ¼5,ğ¼9,ğ¼2,ğ¼3]. We assume that all\nthe sequences are normalized to the same number of time steps ğ‘‡\nto fit the input requirements of transformer-based models. To do\nso, sequences that are longer than ğ‘‡ time steps are truncated to\nthe most recent ğ‘‡ interactions, and sequences that are shorter than\nğ‘‡ time steps are padded with a padding item 0 at the beginning.\nHence, the dataset ğ‘† is converted to a matrix ğ‘† âˆˆğ¼ âˆª{0}|ğ‘†|Ã—ğ‘‡,\nwhere element ğ‘†ğ‘ ,ğ‘¡ represents the item, belonging to ğ¼, in sequence\nğ‘†ğ‘  at time step ğ‘¡. The goal of sequential recommendation is to build\na model that is able to accurately predict the next item interaction\ngiven a context of previous interactions in a sequence. We represent\nthe trained model by the function ğ‘“Î©, with parameters Î©, such that\nğ‘“Î© : [1,|ğ‘†|]Ã—[1,ğ‘‡]Ã—[1,|ğ¼|]â†’ R; (ğ‘ ,ğ‘¡,ğ‘– )â†¦â†’ ğ‘“Î©(ğ‘†ğ‘ ,ğ‘¡,ğ¼ğ‘–). The model\nğ‘“Î© outputs a prediction of the relevance of item ğ¼ğ‘– for sequence\nğ‘†ğ‘ ,ğ‘¡ at time step ğ‘¡. More specifically, in our work, ğ‘“Î© is the bi-\ndirectional transformer-based model BERT4Rec [30]. Because the\nuse of Transformers has become common, and because our focus\nis on debiasing the Cloze task rather than the model itself, we omit\nan exhaustive background description of transformers, and the\nBERT4Rec model architecture. Instead, we refer the reader to [30].\nThat said, we note that all the findings described in this paper are\nmodel-agnostic, as long as the model is trained for the Cloze task,\nand is capable of modeling sequential data.\n3.2 The Cloze Task in Sequential\nRecommendation\nThe Cloze task [ 33] consists of randomly masking a percentage\nğœŒ of the tokens, in our case items in the sequence, and training\nthe machine learning model to predict those masked tokens. This\napproach, also called â€œMasked Language Modeling\" (MLM) [ 7],\nallows for learning a bidirectional context in the training sequence\nwithout any information leakage [30] from the future. This ability of\nmodeling a bidirectional context through the Cloze objective is what\ngives BERT4Rec its prediction power compared to other models,\nsuch as uni-directional self-attention based recommender systems\n[35]. Consider a training datasetğ‘†ğ‘š âˆˆğ¼ âˆª{0,âŸ¨ğ‘šğ‘ğ‘ ğ‘˜âŸ©}|ğ‘†|Ã—ğ‘‡. ğ‘†ğ‘š is a\nmasked version of the ground truth dataset ğ‘† where a fraction ğœŒ of\nthe items is replaced with the token âŸ¨ğ‘šğ‘ğ‘ ğ‘˜âŸ©in each sequence. The\ngoal of the Cloze task is to train the hypothesis ğ‘“Î© to reconstruct\nthe ground truth dataset ğ‘† from the masked training dataset ğ‘†ğ‘š.\nHence, the loss function associated with the Cloze task is defined as\nthe negative log-likelihood of the predicted probability of correctly\npredicting the masked tokens, which we formulate as follows:\nDebiasing the Cloze Task in Sequential Recommendation with Bidirectional Transformers KDD â€™22, August 14â€“18, 2022, Washington, DC, USA\nDefinition 1 (Cloze Task Loss Function).\nğ¿ğ¶ğ‘™ğ‘œğ‘§ğ‘’ = âˆ’1\n|ğ‘†||ğ¼|ğ‘‡\n|ğ‘†|âˆ‘ï¸\nğ‘ =1\nğ‘‡âˆ‘ï¸\nğ‘¡=1\n|ğ¼|âˆ‘ï¸\nğ‘–=1\n1{ğ‘†ğ‘š\nğ‘ ,ğ‘¡=âŸ¨ğ‘šğ‘ğ‘ ğ‘˜âŸ©}ğ‘Œğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡\nÃ—ğ‘™ğ‘œğ‘”ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ (ğ‘“Î©(ğ‘†ğ‘š\nğ‘ ,ğ‘¡,ğ¼ğ‘–))\n(1)\nwhere ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ (ğ‘“Î©(ğ‘†ğ‘š\nğ‘ ,ğ‘¡,ğ¼ğ‘–)) = ğ‘’ğ‘“Î© (ğ‘†ğ‘šğ‘ ,ğ‘¡,ğ¼ğ‘–)\nÃ|ğ¼|\nğ‘˜=1 ğ‘’ğ‘“Î© (ğ‘†ğ‘šğ‘ ,ğ‘¡,ğ¼ğ‘˜) approximates the\npredicted probability ğ‘ƒ(ğ‘†ğ‘ ,ğ‘¡ = ğ¼ğ‘–|ğ‘†ğ‘šğ‘  )of the ground truth item in\nsequence ğ‘†ğ‘  at timeğ‘¡being ğ¼ğ‘– given the masked sequenceğ‘†ğ‘šğ‘  . ğ‘Œğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡\nis a binary random variable that equals 1 when ğ¼ğ‘– âˆˆğ¼ is interacted\nwith in sequence ğ‘†ğ‘  âˆˆğ‘† at time step ğ‘¡ âˆˆ[1,ğ‘‡], and 0 otherwise.\n3.3 Exposure Bias in the Cloze Task\nThe Cloze loss function, in Definition 1, considers the interacted\nground truth item ğ‘†ğ‘ ,ğ‘¡ as the desirable and relevant target item\nfor the input ğ‘†ğ‘š\nğ‘ ,ğ‘¡. However, as shown in [27â€“29], interaction does\nnot necessarily signify relevance. In other words, an item could\nbe interacted because it was the most relevant item among the\nitems that the user was exposed to within the item sequence at\nthe corresponding time step. Moreover, non-interacted items could\nbe relevant to some extent, and it could be that the user did not\ninteract with them because they were not exposed to the user. It\nis this estimation of the relevance of an item with the interaction\nthat engenders the exposure bias. Hence, we can define the ideal\nCloze task loss by replacing the interaction random variable ğ‘Œğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡\nby the relevance of the item that the user chose to interact with in\nsequence ğ‘†ğ‘  at time step ğ‘¡, assuming that the user is aware of all\nitems. The awareness of the user of all items completely eliminates\nthe exposure bias because it infers that all items were exposed to the\nuser. Moreover, weighting the interaction by the relevance allows\nthe loss to capture the true relevance of the item. Hence, we consider\na Bernoulli random variable ğ‘…ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ âˆ¼ğµğ‘’ğ‘Ÿ(ğ›¾ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡), where ğ›¾ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ =\nğ‘ƒ(ğ‘…ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ = 1)represents the probability of item ğ¼ğ‘– being relevant\nin sequence ğ‘†ğ‘  at time step ğ‘¡ (i.e., ğ‘…ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ equals 1). Moreover, we\ndefine a Choice random variable that simulates the user behaviour\nwhen choosing to interact with item ğ¼ğ‘– within sequence ğ‘†ğ‘  at time\nstep ğ‘¡. We assume that this choice is contingent upon its relevance\ncompared to all the other items given the sequence context. Hence,\nwe can model the Choice random variable ğ¶ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ by a Categorical\n(Generalized Bernoulli) distribution as follows:\nğ¶ğ‘†ğ‘ ,ğ‘¡ âˆ¼ğ¶ğ‘ğ‘¡(|ğ¼|,[ğ›¾ğ‘†ğ‘ ,ğ¼1,ğ‘¡,..,ğ›¾ ğ‘†ğ‘ ,ğ¼|ğ¼|,ğ‘¡]). (2)\nThe outcome of the random variable is a vector of |ğ¼|zeroes\nexcept for a 1 for the item the user chooses to interact with. This\nmeans that the user chooses one of the |ğ¼|items based on their\nrelevance to the context ğ‘†ğ‘ ,ğ‘¡. We denote the outcome of ğ¶ğ‘†ğ‘ ,ğ‘¡ for\nitem ğ¼ğ‘– by ğ¶ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ and define the ideal Cloze task loss as follows:\nDefinition 2 (Ideal Cloze Task Loss Function).\nğ¿ğ‘–ğ‘‘ğ‘’ğ‘ğ‘™\nğ¶ğ‘™ğ‘œğ‘§ğ‘’ = âˆ’1\n|ğ‘†||ğ¼|ğ‘‡\n|ğ‘†|âˆ‘ï¸\nğ‘ =1\nğ‘‡âˆ‘ï¸\nğ‘¡=1\n|ğ¼|âˆ‘ï¸\nğ‘–=1\n1{ğ‘†ğ‘š\nğ‘ ,ğ‘¡=âŸ¨ğ‘šğ‘ğ‘ ğ‘˜âŸ©}ğ¶ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡\nÃ—ğ›¾ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ğ‘™ğ‘œğ‘”ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ (ğ‘“Î©(ğ‘†ğ‘š\nğ‘ ,ğ‘¡,ğ¼ğ‘–)).\n(3)\nThe discrepancy between the interaction random variableğ‘Œğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡\nand the product ğ¶ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ ğ›¾ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ causes the Cloze task loss to be\nbiased against the ideal loss, as stated in the following Proposition:\nProposition 1 (Exposure Bias of the Cloze Task Loss Func-\ntion). The Cloze task loss function is biased against the ideal Cloze\ntask loss, such that E[ğ¿ğ¶ğ‘™ğ‘œğ‘§ğ‘’]â‰  ğ¿ğ‘–ğ‘‘ğ‘’ğ‘ğ‘™\nğ¶ğ‘™ğ‘œğ‘§ğ‘’.See Appendix A.1 for proof.\n3.4 Inverse Propensity Scoring in the Cloze\nTask and Its Limitations\nThe common solution to debiasing a maximum likelihood-based\nloss function for recommendation is Inverse Propensity Scoring\n(IPS) where an IPS-based estimator of the ideal pointwise loss is\nobtained by weighting every item prediction for a user by the\nreciprocal of its exposure propensity for that user [ 28]. The IPS\nframework is suitable for debiasing loss functions for recommenda-\ntion with user profiles. However, we argue that it does not extend\nto sequential recommendation for the following two reasons:\n(1) Inadequacy of the interaction random variable repre-\nsentation: The IPS-based framework for recommendation with\nuser profiles [28] models the interaction random variable ğ‘Œğ‘¢,ğ‘–, that\nrepresents whether user ğ‘¢ interacted with item ğ‘–, by the product\nof the relevance and the exposure of the item to the user. The\nframework relies on two random variables, ğ‘‚ğ‘¢,ğ‘– âˆ¼ğµğ‘’ğ‘Ÿ(ğœƒğ‘¢,ğ‘–)and\nğ‘…ğ‘¢,ğ‘– âˆ¼ğµğ‘’ğ‘Ÿ(ğ›¾ğ‘¢,ğ‘–), of exposure and relevance respectively, and mod-\nels the interaction using ğ‘Œğ‘¢,ğ‘– = ğ‘‚ğ‘¢,ğ‘–ğ‘…ğ‘¢,ğ‘–. This means that an item is\ninteracted with by a user if and only if it is both observed by, and\nrelevant to the user. If we extend this modeling of the interaction to\nsequential recommendation by mapping users to sequences and in-\ntroducing the temporal component, we would obtain for a sequence\nğ‘†ğ‘ , an itemğ¼ğ‘– and a time stepğ‘¡: ğ‘Œğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ = ğ‘‚ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ğ‘…ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡, whereğ‘…ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡\nis the relevance random variable and ğ‘‚ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ is a Bernoulli expo-\nsure random variable that takes value 1 if item ğ¼ğ‘– was exposed in\nsequence ğ‘†ğ‘  at time step ğ‘¡, such that ğ‘‚ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ âˆ¼ğµğ‘’ğ‘Ÿ(ğœƒğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡). ğœƒ is\nthe probability of exposure such that ğœƒğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ = ğ‘ƒ(ğ‘‚ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ = 1). This\nmodeling of the interaction random variable is inadequate for se-\nquential recommendation. In fact, in traditional recommendation, it\nis safe to assume that any item that is exposed and relevant to a user\nis interacted. However, when introducing the temporal component\ninto the equation, the assumption does not hold anymore. This is\nbecause a user can only interact with one item at a time. Multiple\nitems can be relevant for the same sequence at the same time step,\nbut only one of them can be interacted with. For this reason, the\nIPS-based framework for recommendation with user profiles does\nnot extend to sequential recommendation.\n(2) Ignoring the temporal component: The IPS estimator for\nthe ideal pointwise loss function down-weights every interaction\nğ‘Œğ‘¢,ğ‘– by the propensity of exposure of item ğ‘–to user ğ‘¢, ğœƒğ‘¢,ğ‘–. In order\nto define an IPS-based Cloze loss for sequential recommendation,\nwe assimilate the users to sequences and consider the propensity\nof exposure of an item ğ¼ğ‘– in a sequence ğ‘†ğ‘  as ğœƒğ‘†ğ‘ ,ğ¼ğ‘– = ğ‘ƒ(ğ‘‚ğ‘†ğ‘ ,ğ¼ğ‘– = 1),\nwhere ğ‘‚ğ‘†ğ‘ ,ğ¼ğ‘– âˆ¼ğµğ‘’ğ‘Ÿ(ğœƒğ‘†ğ‘ ,ğ¼ğ‘–)is a Bernoulli random variable that takes\nthe value 1 when item ğ¼ğ‘– is exposed in sequence ğ‘†ğ‘ . We define the\nIPS-based Cloze loss as follows:\nDefinition 3 (Inverse Propensity Scoring-based Cloze Loss\nFunction).\nğ¿ğ¼ğ‘ƒğ‘†\nğ¶ğ‘™ğ‘œğ‘§ğ‘’ = âˆ’1\n|ğ‘†||ğ¼|ğ‘‡\n|ğ‘†|âˆ‘ï¸\nğ‘ =1\nğ‘‡âˆ‘ï¸\nğ‘¡=1\n|ğ¼|âˆ‘ï¸\nğ‘–=1\n1{ğ‘†ğ‘š\nğ‘ ,ğ‘¡=âŸ¨ğ‘šğ‘ğ‘ ğ‘˜âŸ©}\nğ‘Œğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡\nğœƒğ‘†ğ‘ ,ğ¼ğ‘–\nÃ—ğ‘™ğ‘œğ‘”ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ (ğ‘“Î©(ğ‘†ğ‘š\nğ‘ ,ğ‘¡,ğ¼ğ‘–)).\n(4)\nKDD â€™22, August 14â€“18, 2022, Washington, DC, USA Khalil Damak, Sami Khenissi, & Olfa Nasraoui\nFigure 1: Boxplots of the interaction timesteps for \"The God-\nfather\" and \"Back to the Future\" trilogies. The interaction\ndistributions vary through time, meaning that the exposure\npropensities must not be considered static.\nThe IPS-based Cloze loss function can only be completely unbi-\nased if the propensity of every item ğ¼ğ‘– in every sequence ğ‘†ğ‘  at time\nstep ğ‘¡, ğœƒğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡, is equal to the â€œstatic\" propensity, ğœƒğ‘†ğ‘ ,ğ¼ğ‘–, of item ğ¼ğ‘– in\nsequence ğ‘†ğ‘ . We state this in the following proposition:\nProposition 2 (Unbiasedness condition of the IPS-based\nCloze loss function).\nE[ğ¿ğ¼ğ‘ƒğ‘†\nğ¶ğ‘™ğ‘œğ‘§ğ‘’]= ğ¿ğ‘–ğ‘‘ğ‘’ğ‘ğ‘™\nğ¶ğ‘™ğ‘œğ‘§ğ‘’ â‡”ğœƒğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ = ğœƒğ‘†ğ‘ ,ğ¼ğ‘–,âˆ€(ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡)âˆˆ ğ‘†Ã—ğ¼ Ã—[1..ğ‘‡].\n(5)\nThe proof is in Appendix A.2. This unbiasedness condition of\nthe IPS estimator is unlikely and hard to satisfy as the propensities\nof exposure tend to vary with the temporal context. We demon-\nstrate this in Figure 1 where we show boxplots of the interaction\ntime steps for two movie trilogies in the Movielens 1M dataset [11].\nThe boxplots show that there are movies that tend to be watched\nlater than others in the sequence; for instance, sequels tend to be\nwatched after the original movies. We chose movies that are older\nthan the dataset to ensure that the differences in observation time\nare not related to the release dates of the movies, but rather to\nthe temporal context within the trilogies. Hence, given that the\ninteraction distribution tends to vary with time, it is safe to assume\nthat the exposure propensities also vary with time. Thus, in con-\ntrast to the IPS framework, they should not be considered static\nin sequential recommendation. The latter observation additionally\nshows how the IPS framework does not extend to sequential recom-\nmendation. This consequently calls for proposing a new framework\nthat is specifically tailored for debiasing the Cloze task in sequential\nrecommendation, which is the subject of the next section.\n4 INVERSE TEMPORAL PROPENSITY\nSCORING FOR AN UNBIASED CLOZE TASK\nThe Inverse Propensity Scoring technique fails to capture the tem-\nporal component of the sequential recommendation setting, and\nhence fails to provide an unbiased estimation of the ideal Cloze\ntask loss. We propose a debiasing framework that is tailored to the\nCloze task in sequential recommendation, and that we callInverse\nTemporal Propensity Scoring (ITPS) . In ITPS, we address the\ntwo main limitations of IPS that prevent it from generalizing to\nsequential recommendation. First, to address the issue of the in-\nadequacy of the interaction random variable representation, we\ninclude the outcome of the Choice random variable for item ğ¼ğ‘– in\nthe interaction model for the following formulation:\nDefinition 4 (Interaction Random Variable Representa-\ntion in the ITPS Framework).\nğ‘Œğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ = ğ¶ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ ğ‘‚ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ ğ‘…ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ (6)\nThe latter formulation of the interaction allows for only one\nitem to be interacted within a sequence at a given time step, which\nis adequate for sequential recommendation. Now, an item ğ¼ğ‘– is\ninteracted by a user (ğ‘Œğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ = 1) in a sequenceğ‘†ğ‘  at time stepğ‘¡if and\nonly if the item is exposed (ğ‘‚ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ = 1), relevant (ğ‘…ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ = 1), and\nchosen by the user based on its relevance (ğ¶ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ = 1). Finally, to\naccount for the temporal component in sequential recommendation\nin ITPS, we weight the prediction of every itemğ¼ğ‘– in every sequence\nğ‘†ğ‘  at every time stepğ‘¡by the temporal propensityğœƒğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡, as opposed\nto the static propensityğœƒğ‘†ğ‘ ,ğ¼ğ‘– of IPS. Thus, we define the ITPS-based\nCloze task loss function as follows:\nDefinition 5 (Inverse Temporal Propensity Scoring-based\nCloze Loss Function).\nğ¿ğ¼ğ‘‡ğ‘ƒğ‘†\nğ¶ğ‘™ğ‘œğ‘§ğ‘’ = âˆ’1\n|ğ‘†||ğ¼|ğ‘‡\n|ğ‘†|âˆ‘ï¸\nğ‘ =1\nğ‘‡âˆ‘ï¸\nğ‘¡=1\n|ğ¼|âˆ‘ï¸\nğ‘–=1\n1{ğ‘†ğ‘š\nğ‘ ,ğ‘¡=âŸ¨ğ‘šğ‘ğ‘ ğ‘˜âŸ©}\nğ‘Œğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡\nğœƒğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡\nÃ—ğ‘™ğ‘œğ‘”ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ (ğ‘“Î©(ğ‘†ğ‘š\nğ‘ ,ğ‘¡,ğ¼ğ‘–))\n(7)\nThis new ITPS-based loss is an unbiased estimator of the ideal\nCloze task loss, as stated in the following proposition:\nProposition 3. The ITPS-based Cloze task loss is unbiased for the\nideal Cloze task loss, meaning that E[ğ¿ğ¼ğ‘‡ğ‘ƒğ‘†\nğ¶ğ‘™ğ‘œğ‘§ğ‘’]= ğ¿ğ‘–ğ‘‘ğ‘’ğ‘ğ‘™\nğ¶ğ‘™ğ‘œğ‘§ğ‘’.\nThe proof is in Appendix A.3.\n5 EXPERIMENTAL EVALUATION\nWe perform experiments to assess the validity of our theoretical\nclaims of unbiasedness and the applicability of our approach in real\nrecommendation settings. We use semi-synthetic and real world\ndatasets. The semi-synthetic data, used in Section 5.1, provides\na full visibility of the data properties, allowing us to evaluate the\ndebiasing capabilities of our proposed approach. Moreover, it allows\nus to control the data properties in order to evaluate the robustness\nof our approach to varying bias levels. The real datasets, used in\nSection 5.2, allow us to evaluate the applicability of our approach in\nreal recommendation settings. Additionally, we simulate a feedback\nloop to evaluate the longitudinal effects of the proposed debiasing.\n5.1 Experiments on Semi-Synthetic Data\nWe perform experiments to answer three research questions:\nRQ1: How well does the proposed ITPS estimator capture the\ntrue relevance?\nRQ2: How robust is the proposed ITPS estimator to increasing\nlevels of exposure bias?\nRQ3: How important is an unbiased evaluation in assessing\nexposure debiasing?\n5.1.1 Data. Semi-synthetic experiments are necessary due to the\nunavailability of any open or public unbiased sequential recommen-\ndation dataset. In fact, only an exposure-unbiased testing dataset\nwould allow us to truly compare the debiasing capabilities of the\ndifferent approaches - a claim that we validate in RQ3. We use\nDebiasing the Cloze Task in Sequential Recommendation with Bidirectional Transformers KDD â€™22, August 14â€“18, 2022, Washington, DC, USA\nTable 1: Statistics of the real (ml-100k) and semi-synthetic\n(ss-ml-100k) Movielens 100K datasets.\nDataset # sequences # items # ratings Avg. length Sparsity\nml-100k 943 1,349 99,287 105.28 92.19%\nss-ml-100k 943 229 94,104 99.79 56.42%\nthe Movielens 100K (ml-100k)2 dataset because it is a benchmark\ndataset that can be used for sequential recommendation since it\nincludes interaction timestamps. This data is described in the first\nrow of Table 1. The choice of this dataset is justified due to its\nrelatively low number of sequences (users) and items, compared to\nother sequential datasets. In fact, our first task is to generate all data\nproperties, including relevance, exposure, and interaction for all se-\nquence, item and timestep tuples; a task that is resource-expensive,\nespecially in memory requirements. Considering a dataset with |ğ‘†|\nsequences, |ğ¼|items and ğ‘‡ time steps, the number of parameters\nthat need to be predicted and kept into memory for each controlled\nproperty is |ğ‘†|Ã—|ğ¼|Ã—ğ‘‡. Hence, given the ml-100k dataset statistics,\nwe would be predicting over 127 Million values for every property.\nFor this reason, using other benchmark datasets with tens of thou-\nsands of sequences or items, is simply prohibitive with our current\nresources. Moreover, similar conclusions could be drawn regardless\nof the dataset, assuming a high reconstruction quality. Our goal is\nto use the available ratings to infer all the data properties, namely\nthe relevance, exposure, and interaction of all items ğ¼ğ‘– âˆˆğ¼, in all\nsequences ğ‘†ğ‘  âˆˆğ‘†, and at all time steps ğ‘¡ âˆˆ[1,ğ‘‡]. This is done in\nthe following steps:\n(1) We normalize the dataset toğ‘‡ = 100 time steps.\n(2) We train a Tensor Factorization (TF) model [ 1, 40] on the\navailable (sequence, item, timestep, rating) tuples to reconstruct\nthe missing ratings. We train the model on the Mean Squared Er-\nror (MSE) loss for rating prediction. Finally, we use the trained TF\nmodel to reconstruct the rating tensor by predicting the missing\nratings. Given that the rating represents an explicit measure of sat-\nisfaction of a user with an item, we can approximate the probability\nof relevance of an item ğ¼ğ‘– in a sequence ğ‘†ğ‘  at a time step ğ‘¡ by nor-\nmalizing the predicted rating with the sigmoid function as follows:\nğ›¾ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ â‰ˆğœ(Ë†ğ‘Ÿğ‘ ,ğ‘–,ğ‘¡). Here, Ë†ğ‘Ÿğ‘ ,ğ‘–,ğ‘¡ = Ãğ‘‘\nğ‘˜=1 ğ‘ƒğ‘ ,ğ‘˜ğ‘„ğ‘–,ğ‘˜ğ‘Šğ‘¡,ğ‘˜ is the predicted\nrating, where ğ‘ƒ, ğ‘„, and ğ‘Š are respectively the sequence, item, and\ntime latent factor matrices, which all have ğ‘‘ latent features.\n(3) We train another Tensor Factorization model to predict the\nprobabilities of exposure. We convert every rating in the dataset to a\npositive exposure, and sample a portion of non-interacted tuples as\nnegative exposures. We assume that an item has a higher probabil-\nity of not being exposed than of being exposed, which is a realistic\nassumption given the abundance of items in recommendation plat-\nforms. Thus, we sample 3 negative exposure tuples for every posi-\ntive exposure tuple. We train the TF model using the Binary Cross\nEntropy loss for exposure classification. Similarly to step (2), we ap-\nproximate the propensity of exposure of an itemğ¼ğ‘– in a sequence ğ‘†ğ‘ \nat a time step ğ‘¡ by the predicted exposure as follows: ğœƒğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ â‰ˆË†ğ‘œğ‘ ,ğ‘–,ğ‘¡.\nHere, Ë†ğ‘œğ‘ ,ğ‘–,ğ‘¡ is the predicted exposure probability of item ğ‘– in se-\nquence ğ‘  at time step ğ‘¡, obtained by: Ë†ğ‘œğ‘ ,ğ‘–,ğ‘¡ = ğœ(Ãğ‘‘\nğ‘˜=1 ğ‘ƒğ‘ ,ğ‘˜ğ‘„ğ‘–,ğ‘˜ğ‘Šğ‘¡,ğ‘˜).\n2https://grouplens.org/datasets/movielens/100k/\n(4) Following [28], we introduce a hyperparameter ğ‘ that con-\ntrols the skewness of the exposure distribution, and hence the level\nof exposure bias, as follows:\nğœƒğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ â‰ˆË†ğ‘œğ‘\nğ‘ ,ğ‘–,ğ‘¡. (8)\nThe higher the value of ğ‘, the higher the level of exposure bias\nintroduced. We will control the value of ğ‘ to study RQ2.\n(5) We generate the interaction random variable for every se-\nquence ğ‘†ğ‘ , item ğ¼ğ‘–, and timestep ğ‘¡ combination by following the\nprobabilistic model presented in Equation 6, such that:\nğ‘‚ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ âˆ¼ğµğ‘’ğ‘Ÿ(ğœƒğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡) (9)\nğ‘…ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ âˆ¼ğµğ‘’ğ‘Ÿ(ğ›¾ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡) (10)\nğ¶ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ âˆ¼ğ¶ğ‘ğ‘¡(|ğ¼|,[ğ›¾ğ‘†ğ‘ ,ğ¼1,ğ‘¡,..,ğ›¾ ğ‘†ğ‘ ,ğ¼|ğ¼|,ğ‘¡]) (11)\nğ‘Œğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ = ğ¶ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ ğ‘‚ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ ğ‘…ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡. (12)\nIn our experiments, we obtain ğ¶ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ by considering a rational\nuser interacting with the exposed item (ğ‘‚ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ = 1) with highest\nrelevance ğ›¾ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡.\n(6) Finally, we filter the interacted instances to construct the semi-\nsynthetic sequential dataset. The statistics of a sample generated\nsemi-synthetic dataset are presented in the second row of Table 1.\n5.1.2 Evaluation Process. Our estimators should be evaluated in\nterms of their capacity to capture the true relevance of the test\ninteractions. However, our sequence interactions are obtained with\nthe interaction probabilistic model in Equation 6, which requires all\ninteractions to be exposed. Hence, sampling the test and validation\ninteractions from the semi-synthetic sequences would not allow\nfor an evaluation in terms of the true relevance. This is because\nthe most relevant items are not necessarily exposed to the user. We\ncope with this issue using the following evaluation process: We\nstart by splitting the data into training, validation and test sets by\nconsidering the last item interaction in each sequence for testing\nand the second to last for validation. Then, we replace every item\ninteraction in the validation and test sets by the item ğ¼ğ‘– with the\nhighest relevance ğ›¾ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ in the corresponding sequence ğ‘†ğ‘  and at\nthe corresponding timestep ğ‘¡. This way, the model is evaluated on\nits ability to predict the most relevant item, which translates to\nits ability to capture the true relevance of the items. This being\ndone, we compare the ranking of the test and validation instances\nto 100 randomly sampled items. Note that negative sampling does\nnot introduce any bias because, regardless of their exposure, all the\nnegative items are less relevant than the test and validation items.\nThus, our evaluation process is unbiased and evaluates the models\nin terms of their capacity to capture the true relevance of the items.\nWe use Normalized Discounted Cumulative Gain (ğ‘ğ·ğ¶ğº@ğ‘˜) and\nRecall (ğ‘…@ğ‘˜) for the ranking evaluation.\n5.1.3 Models Compared. We compare the following models:\nâ€¢BERT4Rec: This is the original BERT4Rec model trained\nto optimize the Cloze task loss in Equation 1. It relies solely\non the interaction information and does not incorporate any\nexposure debiasing.\nâ€¢IPS-BERT4Rec: This is the BERT4Rec model trained with\nthe IPS-based Cloze loss function in Equation 4. We estimate\nKDD â€™22, August 14â€“18, 2022, Washington, DC, USA Khalil Damak, Sami Khenissi, & Olfa Nasraoui\nTable 2: Model comparison in terms of capturing the true\nrelevance: Average Recall@k and NDCG@k results over 5\nreplicates. The best results are in bold and second to best\nresults are underlined . A value with * is significantly higher\nthan the next best value (p-value < 0.05).\nModel R@10 NDCG@10 R@5 NDCG@5\nBERT4Rec 0.7992 0.6065 0.6917 0.5716\nIPS-BERT4Rec 0.7890 0.5961 0.6868 0.5628\nITPS-BERT4Rec 0.8027* 0.6110 * 0.6997 * 0.5777 *\nOracle 0.8218* 0.6247* 0.7083* 0.5880*\nthe â€œstatic\" exposure propensities by averaging the temporal\nexposures, such that ğœƒğ‘†ğ‘ ,ğ¼ğ‘– = 1\nğ‘‡\nÃğ‘‡\nğ‘¡=1 ğœƒğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡,âˆ€(ğ‘†ğ‘ ,ğ¼ğ‘–)âˆˆ ğ‘†Ã—ğ¼.\nâ€¢ITPS-BERT4Rec: This is the BERT4Rec model trained with\nour ITPS-based Cloze task loss in Equation 7. The loss relies\non the temporal propensities ğœƒğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ to provide an unbiased\nestimation of the ideal Cloze task loss.\nâ€¢Oracle: This is the BERT4Rec model trained with the ideal\nCloze task loss in Equation 3. The loss has access to the true\nrelevance of the items ğ›¾ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ in the training, and hence, is\nable to provide a completely unbiased representation of the\nuser preferences. Hence, this model provides an upper bound\non capturing the true relevance.\nBecause the goal of the experiments is to assess the impact of\nthe different debiasing frameworks, we leave the comparison to\nadditional baselines for future work.\n5.1.4 Hyperparameter Tuning. We tune all the models presented in\nSection 5.1.3, along with the Tensor Factorization models presented\nin steps 2 and 3 of Section 5.1.1 as described below.\nTuning the BERT4Rec models: Using random search, we tune\nthe number of hidden units within the set {8, 16, 32, 64}, the number\nof transformer blocks within {1, 2}, the number of attention heads\nwithin {1, 2}, the batch size within {8, 16, 32}, the dropout rate within\n{0, 0.1, 0.2, 0.4}, and finally, the masking probability ğœŒ of the Cloze\ntask within {0.1, 0.15, 0.2, 0.4, 0.6}. We try 30 random combinations,\nand compare the average ğ‘ğ·ğ¶ğº@10 results over 3 replicates on\nthe validation set.\nTuning the Tensor Factorization models: We randomly split\nthe data into training, validation and test sets with the respective\nratios 80%, 10% and 10%. We adopt a grid search by trying all com-\nbinations of number of latent features within {50, 100, 200}, and\nbatch size within {64, 128, 256}. We replicate every experiment 3\ntimes and compare the average performances on the validation set.\nThe rating-based TF model from step 2 is tuned in terms of Mean\nSquared Error (MSE) for rating prediction, while the exposure-based\nTF-model from step 3 is tuned in terms of Area Under the ROC\nCurve (AUC) for exposure classification.\n5.1.5 RQ1: How well does the proposed ITPS estimator capture the\ntrue relevance? To answer this research question, we evaluate the\nmodels in terms of their capacity to capture the true relevance using\nthe evaluation process described in Section 5.1.2. We summarize\nthe results in Table 2. The best performer on all metrics is the Or-\nacle model, owing to its explicit optimization using the relevance\nFigure 2: Robustness of the ranking performance of the dif-\nferent models to increasing levels of exposure bias. All the\nvalues are averages over 5 replicates and the 90% confidence\nintervals are highlighted. ITPS-BERT4Rec was the best in\nwithstanding increasing levels of exposure bias overall.\nlevels. The ITPS-BERT4Rec model was second-to-best in all config-\nurations, outperforming the naive BERT4Rec and IPS-BERT4Rec.\nThese findings demonstrate the power of the ITPS debiasing frame-\nwork and validate the theoretical claims of exposure debiasing of\nthe proposed estimator. Finally and interestigly, IPS-BERT4Rec per-\nformed worse than the naive BERT4Rec. This is probably due to the\nfact that it is trained on estimated static propensities, obtained by\naveraging the temporal propensities, rather than true propensities.\n5.1.6 RQ2: How robust is the proposed ITPS estimator to increasing\nlevels of exposure bias?To answer this research question, we train\nand evaluate the models on semi-synthetic datasets generated with\nincreasing levels of exposure bias. The level of exposure bias is\ncontrolled by the power ğ‘ that governs the propensities ğœƒğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ in\nEquation 8. We increaseğ‘from 1 to 4 with an increment of 1, where\nthe higher the value of ğ‘, the stronger the exposure bias introduced\nin the data, and show the evolution of the ranking metrics in Fig-\nure 2. All the modelsâ€™ performances decrease with increasing levels\nof exposure bias, however with different slopes. The IPS-BERT4Rec\nmodel shows the worst performance in handling increasing expo-\nsure bias. Its performance quickly degrades starting fromğ‘ = 2. This\nshows the inability of the IPS framework to mitigate exposure bias\nin sequential recommendation. On the other hand, ITPS-BERT4Rec\nshows the best performance overall in approximating the Oracle.\nThese findings validate the robustness of the proposed ITPS es-\ntimator in handling even extreme levels of exposure bias, and in\ncapturing the true relevance of the items in a sequence and tem-\nporal context. Finally, as opposed to IPS-BERT4Rec which shows a\nsignificantly high and increasing variance, ITPS-BERT4Rec shows\na relatively low and steady variance that compares to the vari-\nance of BERT4Rec. This further demonstrates the robustness of our\nproposed approach to increasing levels of exposure bias.\nDebiasing the Cloze Task in Sequential Recommendation with Bidirectional Transformers KDD â€™22, August 14â€“18, 2022, Washington, DC, USA\nTable 3: Average R@k and NDCG@k over 5 replicates ob-\ntained with a standard evaluation process. â†‘means the rank-\ning increased and â†“means the ranking decreased compared\nto the unbiased results from section 5.1.5. Best results are in\nbold and second to best are underlined . A value with * is sig-\nnificantly higher than the next best value (p-value < 0.05).\nModel R@10 NDCG@10 R@5 NDCG@5\nBERT4Rec 0.7782 â†“ 0.5851 â†“ 0.6655 â†“ 0.5486\nIPS-BERT4Rec 0.7835 â†‘ 0.5854 â†‘ 0.6665 â†‘ 0.5475\nITPS-BERT4Rec 0.7873* 0.5909 * 0.6754 * 0.5545\nOracle 0.8000 0.5983 0.6795 0.5593\n5.1.7 RQ3: How important is an unbiased evaluation in assessing ex-\nposure debiasing? In this research question, we aim to demonstrate\nthe importance of the unbiased evaluation process, explained in\nSection 5.1.2, in evaluating the capacity of the models in capturing\nthe true preferences of the users. To do so, we try to re-evaluate\nthe tuned models using a standard Leave One Out (LOO) evalua-\ntion process, in which we compare the interacted test items to 100\nrandomly sampled items. This evaluation process is biased because\nthe test items are not necessarily the most relevant items due to\ntheir exposure requirement. This results in an overestimation of\nthe performance of the biased models, and their capacity to capture\nthe true relevance. We summarize the results obtained with the\nstandard LOO evaluation process in Table 3. We notice a discrep-\nancy between the results obtained with the standard and unbiased\nevaluation processes. In fact, with the standard evaluation process,\nIPS-BERT4Rec outperformed BERT4Rec in almost all the settings,\nwhich reflects an over-estimation of the debiasing capabilities of the\nIPS framework and its ability to capture the relevance of items given\nthe sequence context. The ITPS-BERT4Rec model was nonetheless\nstill the top performer following the Oracle. These findings validate\nthe necessity of relying on the unbiased evaluation setting, as it\nallows us to truly evaluate the properties of the different estimators.\n5.2 Experiments on Real Data\nWe perform offline experiments on real recommendation datasets\nthat aim to answer the following research questions:\nRQ4: How well does our proposed ITPS estimator perform in\nterms of ranking accuracy?\nRQ5: How well does our proposed ITPS estimator help mitigate\npopularity bias in the short and long terms?\n5.2.1 Data. We rely on three datasets that are commonly used in\nsequential recommendation research [30], which are: the Movielens\n1M (ml-1m)3 [11], Movielens 20M (ml-20m) 3 [11], and Amazon\nBeauty (beauty)4 [22]. For each of the datasets, we consider any\nrating, regardless of its value, as a positive interaction, then, we\nfilter out users with less than 5 interactions to reduce the data\nsparsity. The dataset statistics are summarized in Table 4.\n5.2.2 Evaluation and Propensity Estimation.Previously (Section 5.1),\nwe were able to train our models using the true (temporal) exposure\n3https://grouplens.org/datasets/movielens\n4https://nijianmo.github.io/amazon/index.html\nTable 4: Real dataset statistics.\nDataset Task Sequences Items Interactions Avg. length Sparsity\nml-1m Movie rec. 6,040 3,416 999,611 165.49 95.15%\nml-20m Movie rec. 138,493 18,345 19,984,024 144.29 99.21%\nbeauty Product rec. 40,226 54,542 353,962 8.79 99.98%\npropensities and evaluate their ability to model the relevance using\nthe temporal relevance levels, which were available through the\nuse of semi-synthetic data. However, in real-world data, neither\nthe (temporal) exposure propensities, nor the temporal relevance\nlevels are available. This causes the following two issues: (1) We\ncannot evaluate the modelsâ€™ ability to learn the true relevance of\nthe items to the users because we do not know the true temporal\nrelevance levels; and (2) we cannot train the IPS-BERT4Rec and\nITPS-BERT4Rec models as they rely on the exposure and temporal\nexposure propensities. To solve the first issue, we propose an evalu-\nation process that is based on popularity-based negative sampling.\nIn fact, the main issue with the standard LOO evaluation process\nis that some of the randomly sampled negative items to which we\nare comparing our test and validation items may be as relevant,\nor possibly more relevant, than the test and validation items. We\npropose to sample the negative items for every sequence based on\ntheir popularities, meaning the higher the popularity of an item,\nthe higher the probability that it will be sampled as a negative item.\nThe idea is that more popular items have a higher likelihood that\nthey have been exposed to the user and have not been interacted\nwith because of their irrelevance to the user. The latter popularity-\nbased negative sampling does not completely eliminate exposure\nbias in the evaluation. However, it is intended to mitigate it. Note\nthat using popularity-based sampling to mitigate exposure bias was\nused in previous work [10] in the training phase. We are extending\nit to evaluation. To solve the second issue, we build on previous\nwork [6, 27] and estimate the temporal exposure propensity of an\nitem to a user by the temporal popularity of the item such that:\nË†ğœƒğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ =\nÃ|ğ‘†|\nğ‘—=1 ğ‘Œğ‘†ğ‘—,ğ¼ğ‘–,ğ‘¡\nÃğ‘‡\nğ‘˜=1\nÃ|ğ¼|\nğ‘™=1\nÃ|ğ‘†|\nğ‘—=1 ğ‘Œğ‘†ğ‘—,ğ¼ğ‘™,ğ‘˜\n. (13)\nSimilarly, we estimate the static exposure propensity of an item\nin a sequence with the itemâ€™s popularity, which corresponds to the\nsum of the estimated temporal exposure propensities expressed\nas follows: Ë†ğœƒğ‘†ğ‘ ,ğ¼ğ‘– = Ãğ‘‡\nğ‘¡=1 Ë†ğœƒğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡.Thus, we train the IPS-BERT4Rec\nand ITPS-BERT4Rec models, presented in section 5.1.3, using the\nestimated exposure propensities and estimated temporal exposure\npropensities, respectively.\n5.2.3 Hyperparameter Tuning. For the beauty and ml-1m datasets,\nwe perform the same hyperparameter tuning process described in\nSection 5.1.4 on the semi-synthetic dataset. However, for the ml-\n20m dataset, we increase the ranges of some of the hyperparameters\ngiven the relatively higher size and complexity of the dataset. Hence,\nthe number of hidden units is tuned within {64, 128, 256}, the number\nof transformer blocks within {1, 2, 3}, the number of attention heads\nwithin {1, 2, 4, 8}, the batch size within {64, 128, 256}, and the dropout\nrate within {0, 0.01, 0.1, 0.2}.\nKDD â€™22, August 14â€“18, 2022, Washington, DC, USA Khalil Damak, Sami Khenissi, & Olfa Nasraoui\n5.2.4 RQ4: How well does the proposed ITPS estimator perform in\nterms of ranking accuracy?To measure the ranking capabilities of\nthe proposed approach, we evaluate the tuned models using the\nevaluation process presented in Section 5.2.2 which ensures that ex-\nposure bias is mitigated. Thus, the ranking accuracy results should\nprovide a good approximation of how well the models capture the\ntrue relevance of the items to the users. We summarize the results on\nthe three datasets in Table 5. Our proposed ITPS-BERT4Rec model\nwas the best performer in all the settings, showing significantly\nsuperior performance than the BERT4Rec and the IPS-BERT4Rec\nmodels in all the metrics and on all the datasets. This validates the\nability of the proposed ITPS debiasing framework to learn the true\nrelevance of the items to the users, in addition to its applicability in\nreal recommendation settings. Moreover, interestingly, the ranking\nperformance was not consistent for the second to best model. In\nfact, IPS-BERT4Rec outperformed BERT4Rec overall on both the\nml-1m and beauty datasets but not on the ml-20m dataset.\n5.2.5 RQ5: How well does the proposed ITPS estimator help mit-\nigate popularity bias in the short and long terms?To answer this\nquestion, we implement a feedback loop which simulates a real\nrecommendation environment. The feedback loop consists of con-\nsecutive recommendation iterations where at each iteration, the\nrecommender system is re-trained and generates top 10 recommen-\ndations for every user in the dataset. Each user then interacts with\none of the recommended items and the interactions are added to\nthe dataset for training future iterations. We simulate the userâ€™s\nchoice with a uniform distribution, meaning that the interacted\nitem is chosen at random from the recommendation list. Moreover,\nthe choice of re-training the model at each iteration is related to the\nnature of our training datasets. In fact, we assume that an iteration\ncorresponds to one day and that users interact with at most one\nmovie or beauty product per day. This setting could be extended to\nother types of recommendation datasets in the future. Finally, we\nassume that all the users interact with one item at every iteration.\nAs was discussed in [9], this assumption is meant to speed-up the\nfeedback loop process and should not alter the general character-\nistics of the emerging phenomena. Thus, no conclusions will be\naltered. We evaluate the popularity debiasing capabilities by look-\ning at the novelty of the top 10 recommendations. The novelty is\nassessed using the Expected Free Discovery (EFD) [34], which is a\nmeasure of the ability of a system to recommend relevant long-tail\nitems [34] and is calculated as follows\nğ¸ğ¹ğ·@K(ğ‘‡ğ‘œğ‘ğ¾)= âˆ’1\n|ğ‘†|\n|ğ‘†|âˆ‘ï¸\nğ‘ =1\n1\nK\nâˆ‘ï¸\nğ‘–âˆˆğ‘‡ğ‘œğ‘ğ¾ (ğ‘†ğ‘ )\nğ‘™ğ‘œğ‘”2 Ë†ğœƒğ‘†ğ‘ ,ğ‘–, (14)\nwhere ğ‘‡ğ‘œğ‘ğ¾ is the top Krecommendation matrix in which every\nrow represents the Top Krecommendations in a sequence.\nWe summarize the evolution of ğ¸ğ¹ğ·@10 for 10 feedback loop\niterations on the three datasets in Figure 3. On both the ml-20m\nand beauty datasets, our proposed ITPS-BERT4Rec model showed\nthe best results in all iterations. The difference in performance com-\npared to the other two models was significant in all the iterations\nfor the beauty dataset and in most iterations for the ml-20m dataset.\nHowever, we notice a change in trend in the ml-1m dataset where\nFigure 3: Evolution of EFD@10 with respect to feedback\nloop iterations. All values are averages over 5 replicates and\n90% confidence intervals are highlighted. ITPS-BERT4Rec\nshowed the best short and long-term popularity debiasing\ncapabilities on the ml-20m and beauty datasets.\nIPS-BERT4Rec and ITPS-BERT4Rec showed a relatively similar pop-\nularity debiasing performance, that still outperformed BERT4Rec.\nWe believe that the difference in trend in the ml-1m dataset is due to\nthe relatively low number of items and low sparsity of the dataset\nmaking the popularity bias problem less prominent compared to the\nother datasets. Moreover and interestingly, the vanilla BERT4Rec\noutperformed IPS-BERT4Rec on the beauty dataset. The overall su-\nperior performance of our proposed ITPS-BERT4Rec model shows\nthe impact of exposure debiasing on popularity debiasing, where\nmodeling the true preferences of the user results in more diverse\nand novel recommendations yielding a higher item discovery by\nthe user. Moreover, the ml-20m and beauty datasets showed, over-\nall, decreasing trends for ğ¸ğ¹ğ· with respect to the feedback loop\niterations for all the models. This means that the issue of popu-\nlarity bias tends to worsen with time. However, the relatively low\nslope of ITPS-BERT4Rec demonstrates the importance of mitigating\nexposure bias to mitigate long-term popularity bias.\n6 CONCLUSION\nWe studied the problem of exposure bias in sequential recommen-\ndation within the scope of bidirectional transformers trained to\noptimize the Cloze task, and proposed an ideal Cloze task loss that\ncaptures the true relevance. Then, we argued and proved that IPS\nestimators do not extend to sequential recommendation. In addition,\nwe proposed a theoretically unbiased estimator for the ideal Cloze\ntask loss, and formulated a framework that allows for an unbiased\ntraining and evaluation of sequential recommender systems. Our\nexperiments empirically validated our claims of debiasing of the\nproposed ITPS-BERT4Rec estimator, and demonstrated its robust-\nness to increasing levels of exposure bias, along with its longitudinal\nimpact on popularity debiasing. Future work should validate and\nchallenge the assumptions on which our theory is based.\nACKNOWLEDGMENTS\nThis work was supported in part by National Science Foundation\ngrants IIS-1549981, DRL-2026584, and CNS-1828521.\nREFERENCES\n[1] Gediminas Adomavicius, Ramesh Sankaranarayanan, Shahana Sen, and Alexan-\nder Tuzhilin. 2005. Incorporating contextual information in recommender sys-\ntems using a multidimensional approach. ACM Transactions on Information\nSystems (TOIS) 23, 1 (2005), 103â€“145.\n[2] Jiawei Chen, Hande Dong, Xiang Wang, Fuli Feng, Meng Wang, and Xiangnan He.\n2020. Bias and Debias in Recommender System: A Survey and Future Directions.\narXiv preprint arXiv:2010.03240 (2020).\nDebiasing the Cloze Task in Sequential Recommendation with Bidirectional Transformers KDD â€™22, August 14â€“18, 2022, Washington, DC, USA\nTable 5: Average Recall (R) and NDCG (N) results over 5 replicates on the three real interaction datasets. The best results are in\nbold and second to best results are underlined . A value with * is significantly higher than the next best value (p-value < 0.05).\nDataset ml-1m ml-20m beauty\nModel N@5 R@5 N@10 R@10 N@5 R@5 N@10 R@10 N@5 R@5 N@10 R@10\nBERT4Rec 0.2820 0.4086 0.3262 0.5454 0.4205* 0.5583 * 0.4624 * 0.6876 * 0.1056 0.1516 0.1260 0.2148\nIPS-BERT4Rec 0.3416* 0.4751 * 0.3801 * 0.5940 * 0.4004 0.5389 0.4434 0.6715 0.1053 0.1528 0.1268 0.2195\nITPS-BERT4Rec 0.3451* 0.4796 0.3844 * 0.6007* 0.4295* 0.5674* 0.4709* 0.6952* 0.1197* 0.1745* 0.1444* 0.2510*\n[3] Jiawei Chen, Can Wang, Sheng Zhou, Qihao Shi, Jingbang Chen, Yan Feng, and\nChun Chen. 2020. Fast Adaptively Weighted Matrix Factorization for Recom-\nmendation with Implicit Feedback.. In AAAI. 3470â€“3477.\n[4] Jiawei Chen, Can Wang, Sheng Zhou, Qihao Shi, Yan Feng, and Chun Chen. 2019.\nSamwalker: Social recommendation with informative sampling strategy. In The\nWorld Wide Web Conference . 228â€“239.\n[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau,\nFethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning Phrase\nRepresentations using RNN Encoderâ€“Decoder for Statistical Machine Translation.\nIn Proceedings of the 2014 Conference on Empirical Methods in Natural Language\nProcessing (EMNLP) (Doha, Qatar). Association for Computational Linguistics,\n1724â€“1734. https://doi.org/10.3115/v1/D14-1179\n[6] Khalil Damak, Sami Khenissi, and Olfa Nasraoui. 2021. Debiased Explainable\nPairwise Ranking from Implicit Feedback. In Fifteenth ACM Conference on Rec-\nommender Systems . 321â€“331.\n[7] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert:\nPre-training of deep bidirectional transformers for language understanding.arXiv\npreprint arXiv:1810.04805 (2018).\n[8] Robin Devooght, Nicolas Kourtellis, and Amin Mantrach. 2015. Dynamic matrix\nfactorization with priors on unknown values. In Proceedings of the 21th ACM\nSIGKDD international conference on knowledge discovery and data mining . 189â€“\n198.\n[9] Andres Ferraro, Dietmar Jannach, and Xavier Serra. 2020. Exploring Longitudinal\nEffects of Session-based Recommendations. In Fourteenth ACM Conference on\nRecommender Systems . 474â€“479.\n[10] Zeno Gantner, Lucas Drumond, Christoph Freudenthaler, and Lars Schmidt-\nThieme. 2012. Personalized ranking for non-uniformly sampled items. In Pro-\nceedings of KDD Cup 2011 . PMLR, 231â€“247.\n[11] F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History\nand Context. ACM Trans. Interact. Intell. Syst. 5, 4, Article 19 (dec 2015), 19 pages.\nhttps://doi.org/10.1145/2827872\n[12] Xiangnan He, Hanwang Zhang, Min-Yen Kan, and Tat-Seng Chua. 2016. Fast ma-\ntrix factorization for online recommendation with implicit feedback. In Proceed-\nings of the 39th International ACM SIGIR conference on Research and Development\nin Information Retrieval . 549â€“558.\n[13] BalÃ¡zs Hidasi and Alexandros Karatzoglou. 2018. Recurrent neural networks with\ntop-k gains for session-based recommendations. In Proceedings of the 27th ACM\ninternational conference on information and knowledge management . 843â€“852.\n[14] BalÃ¡zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk.\n2015. Session-based recommendations with recurrent neural networks. arXiv\npreprint arXiv:1511.06939 (2015).\n[15] Sepp Hochreiter and JÃ¼rgen Schmidhuber. 1997. Long Short-Term Memory.\nNeural Comput. 9, 8 (Nov. 1997), 1735â€“1780. https://doi.org/10.1162/neco.1997.9.\n8.1735\n[16] Yifan Hu, Yehuda Koren, and Chris Volinsky. 2008. Collaborative filtering for\nimplicit feedback datasets. In 2008 Eighth IEEE International Conference on Data\nMining. Ieee, 263â€“272.\n[17] Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recom-\nmendation. In 2018 IEEE International Conference on Data Mining (ICDM) . IEEE,\n197â€“206.\n[18] Yann LeCun, Patrick Haffner, LÃ©on Bottou, and Yoshua Bengio. 1999. Object\nrecognition with gradient-based learning. In Shape, contour and grouping in\ncomputer vision . Springer, 319â€“345.\n[19] Yanen Li, Jia Hu, ChengXiang Zhai, and Ye Chen. 2010. Improving one-class\ncollaborative filtering by incorporating rich user information. In Proceedings of\nthe 19th ACM international conference on Information and knowledge management .\n959â€“968.\n[20] Dawen Liang, Laurent Charlin, James McInerney, and David M Blei. 2016. Mod-\neling user exposure in recommendation. In Proceedings of the 25th international\nconference on World Wide Web . 951â€“961.\n[21] Zachary Chase Lipton. 2015. A Critical Review of Recurrent Neural Networks\nfor Sequence Learning. CoRR abs/1506.00019 (2015).\n[22] Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel.\n2015. Image-based recommendations on styles and substitutes. In Proceedings\nof the 38th international ACM SIGIR conference on research and development in\ninformation retrieval. 43â€“52.\n[23] Rong Pan and Martin Scholz. 2009. Mind the gaps: weighting the unknown\nin large-scale one-class collaborative filtering. In Proceedings of the 15th ACM\nSIGKDD international conference on Knowledge discovery and data mining . 667â€“\n676.\n[24] Rong Pan, Yunhong Zhou, Bin Cao, Nathan N Liu, Rajan Lukose, Martin Scholz,\nand Qiang Yang. 2008. One-class collaborative filtering. In 2008 Eighth IEEE\nInternational Conference on Data Mining . IEEE, 502â€“511.\n[25] Marcâ€™Aurelio Ranzato, Sumit Chopra, Michael Auli, and Wojciech Zaremba.\n2015. Sequence level training with recurrent neural networks. arXiv preprint\narXiv:1511.06732 (2015).\n[26] Ruiyang Ren, Zhaoyang Liu, Yaliang Li, Wayne Xin Zhao, Hui Wang, Bolin\nDing, and Ji-Rong Wen. 2020. Sequential recommendation with self-attentive\nmulti-adversarial network. In Proceedings of the 43rd International ACM SIGIR\nConference on Research and Development in Information Retrieval . 89â€“98.\n[27] Yuta Saito. 2019. Unbiased Pairwise Learning from Implicit Feedback. In NeurIPS\n2019 Workshop on Causal Machine Learning .\n[28] Yuta Saito, Suguru Yaginuma, Yuta Nishino, Hayato Sakata, and Kazuhide Nakata.\n2020. Unbiased recommender learning from missing-not-at-random implicit\nfeedback. In Proceedings of the 13th International Conference on Web Search and\nData Mining . 501â€“509.\n[29] Tobias Schnabel, Adith Swaminathan, Ashudeep Singh, Navin Chandak, and\nThorsten Joachims. 2016. Recommendations as treatments: Debiasing learning\nand evaluation. In international conference on machine learning . PMLR, 1670â€“\n1679.\n[30] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang.\n2019. BERT4Rec: Sequential recommendation with bidirectional encoder rep-\nresentations from transformer. In Proceedings of the 28th ACM international\nconference on information and knowledge management . 1441â€“1450.\n[31] Wenlong Sun, Sami Khenissi, Olfa Nasraoui, and Patrick Shafto. 2019. Debiasing\nthe human-recommender system feedback loop in collaborative filtering. In\nCompanion Proceedings of The 2019 World Wide Web Conference . 645â€“651.\n[32] Jiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommenda-\ntion via convolutional sequence embedding. In Proceedings of the Eleventh ACM\nInternational Conference on Web Search and Data Mining . 565â€“573.\n[33] Wilson L Taylor. 1953. â€œCloze procedureâ€: A new tool for measuring readability.\nJournalism quarterly 30, 4 (1953), 415â€“433.\n[34] SaÃºl Vargas and Pablo Castells. 2011. Rank and relevance in novelty and diversity\nmetrics for recommender systems. In Proceedings of the fifth ACM conference on\nRecommender systems . 109â€“116.\n[35] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,\nAidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. arXiv preprint arXiv:1706.03762 (2017).\n[36] Shoujin Wang, Longbing Cao, Yan Wang, Quan Z Sheng, Mehmet Orgun, and\nDefu Lian. 2019. A survey on session-based recommender systems.arXiv preprint\narXiv:1902.04864 (2019).\n[37] Xiang Wang, Yaokun Xu, Xiangnan He, Yixin Cao, Meng Wang, and Tat-Seng\nChua. 2020. Reinforced Negative Sampling over Knowledge Graph for Recom-\nmendation. In Proceedings of The Web Conference 2020 . 99â€“109.\n[38] Longqi Yang, Yin Cui, Yuan Xuan, Chenyang Wang, Serge Belongie, and Debo-\nrah Estrin. 2018. Unbiased offline recommender evaluation for missing-not-at-\nrandom implicit feedback. In Proceedings of the 12th ACM Conference on Recom-\nmender Systems . 279â€“287.\n[39] Hsiang-Fu Yu, Mikhail Bilenko, and Chih-Jen Lin. 2017. Selection of negative\nsamples for one-class matrix factorization. In Proceedings of the 2017 SIAM Inter-\nnational Conference on Data Mining . SIAM, 363â€“371.\n[40] Jianli Zhao, Shangcheng Yang, Huan Huo, Qiuxia Sun, and Xijiao Geng. 2021.\nTBTF: an effective time-varying bias tensor factorization algorithm for recom-\nmender system. Applied Intelligence (2021), 1â€“12.\n[41] Pengyu Zhao, Tianxiao Shui, Yuanxing Zhang, Kecheng Xiao, and Kaigui Bian.\n2020. Adversarial Oracular Seq2seq Learning for Sequential Recommendation.\nIn Proceedings of the Twenty-Ninth International Joint Conference on Artificial\nIntelligence, IJCAI. 1905â€“1911.\nKDD â€™22, August 14â€“18, 2022, Washington, DC, USA Khalil Damak, Sami Khenissi, & Olfa Nasraoui\nA SUPPLEMENTAL MATERIAL\nA.1 Proof of Proposition 1\nProof.\nE[ğ¿ğ¶ğ‘™ğ‘œğ‘§ğ‘’]= E[ âˆ’1\n|ğ‘†||ğ¼|ğ‘‡\n|ğ‘†|âˆ‘ï¸\nğ‘ =1\nğ‘‡âˆ‘ï¸\nğ‘¡=1\n|ğ¼|âˆ‘ï¸\nğ‘–=1\n1{ğ‘†ğ‘š\nğ‘ ,ğ‘¡=âŸ¨ğ‘šğ‘ğ‘ ğ‘˜âŸ©}ğ‘Œğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡\nÃ—ğ‘™ğ‘œğ‘”ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ (ğ‘“Î©(ğ‘†ğ‘š\nğ‘ ,ğ‘¡,ğ¼ğ‘–))]\n= âˆ’1\n|ğ‘†||ğ¼|ğ‘‡\n|ğ‘†|âˆ‘ï¸\nğ‘ =1\nğ‘‡âˆ‘ï¸\nğ‘¡=1\n|ğ¼|âˆ‘ï¸\nğ‘–=1\n1{ğ‘†ğ‘š\nğ‘ ,ğ‘¡=âŸ¨ğ‘šğ‘ğ‘ ğ‘˜âŸ©}\nÃ—ğ¶ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ ğœƒğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ ğ›¾ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ğ‘™ğ‘œğ‘”ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ (ğ‘“Î©(ğ‘†ğ‘š\nğ‘ ,ğ‘¡,ğ¼ğ‘–))\nGiven that the temporal propensities ğœƒğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ cannot always be\nequal to 1, âˆ€(ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡)âˆˆ ğ‘†Ã—ğ¼Ã—[1..ğ‘‡]. Thus, E[ğ¿ğ¶ğ‘™ğ‘œğ‘§ğ‘’]â‰  ğ¿ğ‘–ğ‘‘ğ‘’ğ‘ğ‘™\nğ¶ğ‘™ğ‘œğ‘§ğ‘’. â–¡\nNote that the proof relies on the probabilistic model of the inter-\naction random variable that is proposed later in Definition 4.\nA.2 Proof of Proposition 2\nProof.\nE[ğ¿ğ¼ğ‘ƒğ‘†\nğ¶ğ‘™ğ‘œğ‘§ğ‘’]= ğ¿ğ‘–ğ‘‘ğ‘’ğ‘ğ‘™\nğ¶ğ‘™ğ‘œğ‘§ğ‘’\nâ‡”E[ âˆ’1\n|ğ‘†||ğ¼|ğ‘‡\n|ğ‘†|âˆ‘ï¸\nğ‘ =1\nğ‘‡âˆ‘ï¸\nğ‘¡=1\n|ğ¼|âˆ‘ï¸\nğ‘–=1\n1{ğ‘†ğ‘š\nğ‘ ,ğ‘¡=âŸ¨ğ‘šğ‘ğ‘ ğ‘˜âŸ©}\nğ‘Œğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡\nğœƒğ‘†ğ‘ ,ğ¼ğ‘–\nÃ—ğ‘™ğ‘œğ‘”ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ (ğ‘“Î©(ğ‘†ğ‘š\nğ‘ ,ğ‘¡,ğ¼ğ‘–))]\n= âˆ’1\n|ğ‘†||ğ¼|ğ‘‡\n|ğ‘†|âˆ‘ï¸\nğ‘ =1\nğ‘‡âˆ‘ï¸\nğ‘¡=1\n|ğ¼|âˆ‘ï¸\nğ‘–=1\n1{ğ‘†ğ‘š\nğ‘ ,ğ‘¡=âŸ¨ğ‘šğ‘ğ‘ ğ‘˜âŸ©}ğ¶ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡\nÃ—ğ›¾ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ğ‘™ğ‘œğ‘”ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ (ğ‘“Î©(ğ‘†ğ‘š\nğ‘ ,ğ‘¡,ğ¼ğ‘–))\nâ‡”E[ âˆ’1\n|ğ‘†||ğ¼|ğ‘‡\n|ğ‘†|âˆ‘ï¸\nğ‘ =1\nğ‘‡âˆ‘ï¸\nğ‘¡=1\n|ğ¼|âˆ‘ï¸\nğ‘–=1\n1{ğ‘†ğ‘š\nğ‘ ,ğ‘¡=âŸ¨ğ‘šğ‘ğ‘ ğ‘˜âŸ©}\nğ¶ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ ğ‘‚ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ ğ‘…ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡\nğœƒğ‘†ğ‘ ,ğ¼ğ‘–\nÃ—ğ‘™ğ‘œğ‘”ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ (ğ‘“Î©(ğ‘†ğ‘š\nğ‘ ,ğ‘¡,ğ¼ğ‘–))]\n= âˆ’1\n|ğ‘†||ğ¼|ğ‘‡\n|ğ‘†|âˆ‘ï¸\nğ‘ =1\nğ‘‡âˆ‘ï¸\nğ‘¡=1\n|ğ¼|âˆ‘ï¸\nğ‘–=1\n1{ğ‘†ğ‘š\nğ‘ ,ğ‘¡=âŸ¨ğ‘šğ‘ğ‘ ğ‘˜âŸ©}ğ¶ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡\nÃ—ğ›¾ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ğ‘™ğ‘œğ‘”ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ (ğ‘“Î©(ğ‘†ğ‘š\nğ‘ ,ğ‘¡,ğ¼ğ‘–))\nâ‡” âˆ’1\n|ğ‘†||ğ¼|ğ‘‡\n|ğ‘†|âˆ‘ï¸\nğ‘ =1\nğ‘‡âˆ‘ï¸\nğ‘¡=1\n|ğ¼|âˆ‘ï¸\nğ‘–=1\n1{ğ‘†ğ‘š\nğ‘ ,ğ‘¡=âŸ¨ğ‘šğ‘ğ‘ ğ‘˜âŸ©}\nğ¶ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ ğœƒğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ ğ›¾ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡\nğœƒğ‘†ğ‘ ,ğ¼ğ‘–\nÃ—ğ‘™ğ‘œğ‘”ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ (ğ‘“Î©(ğ‘†ğ‘š\nğ‘ ,ğ‘¡,ğ¼ğ‘–))\n= âˆ’1\n|ğ‘†||ğ¼|ğ‘‡\n|ğ‘†|âˆ‘ï¸\nğ‘ =1\nğ‘‡âˆ‘ï¸\nğ‘¡=1\n|ğ¼|âˆ‘ï¸\nğ‘–=1\n1{ğ‘†ğ‘š\nğ‘ ,ğ‘¡=âŸ¨ğ‘šğ‘ğ‘ ğ‘˜âŸ©}ğ¶ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡\nÃ—ğ›¾ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ğ‘™ğ‘œğ‘”ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ (ğ‘“Î©(ğ‘†ğ‘š\nğ‘ ,ğ‘¡,ğ¼ğ‘–))\nâ‡”ğœƒğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ = ğœƒğ‘†ğ‘ ,ğ¼ğ‘–,âˆ€(ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡)âˆˆ ğ‘†Ã—ğ¼ Ã—[1..ğ‘‡]. â–¡\nNote that the proof also relies on the probabilistic model of the\ninteraction random variable that is proposed later in Definition 4.\nA.3 Proof of Proposition 3\nProof.\nE[ğ¿ğ¼ğ‘‡ğ‘ƒğ‘†\nğ¶ğ‘™ğ‘œğ‘§ğ‘’]= E[ âˆ’1\n|ğ‘†||ğ¼|ğ‘‡\n|ğ‘†|âˆ‘ï¸\nğ‘ =1\nğ‘‡âˆ‘ï¸\nğ‘¡=1\n|ğ¼|âˆ‘ï¸\nğ‘–=1\n1{ğ‘†ğ‘š\nğ‘ ,ğ‘¡=âŸ¨ğ‘šğ‘ğ‘ ğ‘˜âŸ©}\nÃ—ğ¶ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ ğ‘‚ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ ğ‘…ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡\nğœƒğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡\nğ‘™ğ‘œğ‘”ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ (ğ‘“Î©(ğ‘†ğ‘š\nğ‘ ,ğ‘¡,ğ¼ğ‘–))]\n= âˆ’1\n|ğ‘†||ğ¼|ğ‘‡\n|ğ‘†|âˆ‘ï¸\nğ‘ =1\nğ‘‡âˆ‘ï¸\nğ‘¡=1\n|ğ¼|âˆ‘ï¸\nğ‘–=1\n1{ğ‘†ğ‘š\nğ‘ ,ğ‘¡=âŸ¨ğ‘šğ‘ğ‘ ğ‘˜âŸ©}\nÃ—ğ¶ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ ğœƒğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ ğ›¾ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡\nğœƒğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡\nğ‘™ğ‘œğ‘”ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ (ğ‘“Î©(ğ‘†ğ‘š\nğ‘ ,ğ‘¡,ğ¼ğ‘–))\n= âˆ’1\n|ğ‘†||ğ¼|ğ‘‡\n|ğ‘†|âˆ‘ï¸\nğ‘ =1\nğ‘‡âˆ‘ï¸\nğ‘¡=1\n|ğ¼|âˆ‘ï¸\nğ‘–=1\n1{ğ‘†ğ‘š\nğ‘ ,ğ‘¡=âŸ¨ğ‘šğ‘ğ‘ ğ‘˜âŸ©}ğ¶ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡ ğ›¾ğ‘†ğ‘ ,ğ¼ğ‘–,ğ‘¡\nÃ—ğ‘™ğ‘œğ‘”ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ (ğ‘“Î©(ğ‘†ğ‘š\nğ‘ ,ğ‘¡,ğ¼ğ‘–))= ğ¿ğ‘–ğ‘‘ğ‘’ğ‘ğ‘™\nğ¶ğ‘™ğ‘œğ‘§ğ‘’ â–¡\nNote that the proof assumes independence between exposure\nand relevance. Also, it assumes that the outcome of the choice model\nfor an item is deterministic, which is reasonable if we assume a\nrational user who tends to choose the most relevant item among\nthe exposed items.",
  "topic": "Debiasing",
  "concepts": [
    {
      "name": "Debiasing",
      "score": 0.9224063754081726
    },
    {
      "name": "Computer science",
      "score": 0.7599666118621826
    },
    {
      "name": "Robustness (evolution)",
      "score": 0.5862089395523071
    },
    {
      "name": "Weighting",
      "score": 0.5774483680725098
    },
    {
      "name": "Task (project management)",
      "score": 0.46957844495773315
    },
    {
      "name": "Artificial intelligence",
      "score": 0.45276063680648804
    },
    {
      "name": "Transformer",
      "score": 0.41032078862190247
    },
    {
      "name": "Machine learning",
      "score": 0.36586815118789673
    },
    {
      "name": "Psychology",
      "score": 0.11266550421714783
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Cognitive science",
      "score": 0.0
    },
    {
      "name": "Medicine",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Radiology",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I142740786",
      "name": "University of Louisville",
      "country": "US"
    }
  ],
  "cited_by": 9
}