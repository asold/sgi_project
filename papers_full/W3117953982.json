{
  "title": "An analysis of language models for metaphor recognition",
  "url": "https://openalex.org/W3117953982",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A3113624891",
      "name": "Arthur Neidlein",
      "affiliations": [
        "Association for Computational Linguistics",
        "Heidelberg University"
      ]
    },
    {
      "id": "https://openalex.org/A3115173847",
      "name": "Philip Wiesenbach",
      "affiliations": [
        "Heidelberg University",
        "Association for Computational Linguistics"
      ]
    },
    {
      "id": "https://openalex.org/A2090985251",
      "name": "Katja Markert",
      "affiliations": [
        "Association for Computational Linguistics",
        "Heidelberg University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2739977789",
    "https://openalex.org/W2470413457",
    "https://openalex.org/W2181830759",
    "https://openalex.org/W56200336",
    "https://openalex.org/W2773022604",
    "https://openalex.org/W2962748048",
    "https://openalex.org/W3045533700",
    "https://openalex.org/W3046209160",
    "https://openalex.org/W3045699325",
    "https://openalex.org/W2962739339",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W4232967690",
    "https://openalex.org/W2739510089",
    "https://openalex.org/W1949881471",
    "https://openalex.org/W4238760794",
    "https://openalex.org/W4388152766",
    "https://openalex.org/W2293155194",
    "https://openalex.org/W2971350424",
    "https://openalex.org/W2126530744",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2787894787",
    "https://openalex.org/W2798651446",
    "https://openalex.org/W2515845560",
    "https://openalex.org/W2515860461",
    "https://openalex.org/W1561412240",
    "https://openalex.org/W2115340919",
    "https://openalex.org/W2252273035",
    "https://openalex.org/W2560778841",
    "https://openalex.org/W2947509090",
    "https://openalex.org/W1614298861",
    "https://openalex.org/W2890545641",
    "https://openalex.org/W2806273110",
    "https://openalex.org/W2963272610",
    "https://openalex.org/W2107482851",
    "https://openalex.org/W2949442961",
    "https://openalex.org/W2988982968",
    "https://openalex.org/W2252218513",
    "https://openalex.org/W2965373594"
  ],
  "abstract": "We conduct a linguistic analysis of recent metaphor recognition systems, all of which are based on language models. We show that their performance, although reaching high F-scores, has considerable gaps from a linguistic perspective. First, they perform substantially worse on unconventional metaphors than on conventional ones. Second, they struggle with handling rarer word types. These two findings together suggest that a large part of the systems' success is due to optimising the disambiguation of conventionalised, metaphoric word senses for specific words instead of modelling general properties of metaphors. As a positive result, the systems show increasing capabilities to recognise metaphoric readings of unseen words if synonyms or morphological variations of these words have been seen before, leading to enhanced generalisation beyond word sense disambiguation.",
  "full_text": "Proceedings of the 28th International Conference on Computational Linguistics, pages 3722–3736\nBarcelona, Spain (Online), December 8-13, 2020\n3722\nAn analysis of language models for metaphor recognition\nArthur Neidlein, Philipp Wiesenbachand Katja Markert\nInstitute of Computational Linguistics\nHeidelberg University\n{neidlein|wiesenbach|markert}@cl.uni-heidelberg.de\nAbstract\nWe conduct a linguistic analysis of recent metaphor recognition systems, all of which are based\non language models. We show that their performance, although reaching high F-scores, has\nconsiderable gaps from a linguistic perspective. First, they perform substantially worse on un-\nconventional metaphors than on conventional ones. Second, they struggle with handling rarer\nword types. These two ﬁndings together suggest that a large part of the systems’ success is due\nto optimising the disambiguation of conventionalised, metaphoric word senses for speciﬁc words\ninstead of modelling general properties of metaphors. As a positive result, the systems show\nincreasing capabilities to recognise metaphoric readings of unseen words if synonyms or mor-\nphological variations of these words have been seen before, leading to enhanced generalisation\nbeyond word sense disambiguation.\n1 Introduction\nMetaphor is a type of ﬁgurative language where meaning transfer occurs via similarity between two\nconceptual domains. In Examples 1 to 3, the metaphors attacked, bashed and ceaseﬁre stem from a\ntransfer from the domain W AR (or FIGHT) to the domain ARGUMENT (Lakoff and Johnson, 1980).1\n(1) He attacked my argument.\n(2) He bashed my argument.\n(3) We declared a ceaseﬁre during dinner.\nMetaphoric instances can stem from such regular metaphoric patterns equating two domains habitually\nor conventionally.2 However, they can also be novel/unconventional such as the famous Emily Dickin-\nson metaphor Hope is the thing with feathers, which does not correspond to a well-known metaphorical\npattern. Even within a metaphorical pattern such as Argument is War, there are degrees of conven-\ntionality with Example 1 being more conventional than Examples 2 and 3. To a human, unconventional\nmetaphors tend to be more noticeable.\nMetaphor detection has been studied extensively in NLP in recent years (see (Veale et al., 2016;\nShutova et al., 2017) for overviews). State-of-the-art approaches in metaphor detection build strongly\non language models and word embeddings, with more than half of the participants in the 2020 Shared\nTask on Metaphor Detection (Leong et al., 2020) using a variant of BERT language models (Devlin et\nal., 2019). Evaluations on the standard metaphor recognition test sets report scores that creep up steadily,\nusing such methods. We investigate whether these models really are able to learn general properties of\nmetaphor. To do so and to go beyond word sense disambiguation, they should be able to (i) recognise\nconventional and unconventional metaphors (ii) be able to perform well on rarer word types that often\nThis work is licensed under a Creative Commons Attribution 4.0 International Licence. Licence details: http://\ncreativecommons.org/licenses/by/4.0/.\n1In our examples, metaphoric words are marked in italics.\n2Lakoff and Johnson (1980) call these patterns conceptual metaphors. We will mainly use the term metaphoric patterns to\ndistinguish those clearly from speciﬁc metaphoric instances, which we simply call metaphors.\n3723\nfollow the same metaphoric patterns as frequently seen ones and (iii) be able to generalise across syn-\nonyms and morphological variations of word types (such as making the inference from Example 1 to\n2).\nOur contributions are as follows:\n• We conduct a systematic comparison of different sequential metaphor recognition systems on the\ntwo most frequently used datasets. Although the two datasets contain different token sets of the\nsame underlying corpus (Steen, 2010), we show that one is substantially easier to do well on than\nthe other. We therefore call on future research to stop comparing their results across these two\ndifferent datasets as this leads to unfair system comparisons.\n• We show that the systems behave counter-intuitively by having lower performance on unconven-\ntional metaphors than on conventional ones. However, unconventional metaphors are the ones that\nare particularly relevant as conventional ones can potentially be interpreted with standard word\nsense disambiguation techniques.\n• We show that metaphor recognition systems are strongly dependent on the frequency of word types\nin the training data.\n• As a positive result, we show that the systems have increasing generalisation capabilities in that they\nperform better on unknown word types if synonyms or morphological variations have been seen in\nthe training data.\n2 Models and Datasets\n2.1 Models\nWe report on the following models, all except the baseline being based on a sequence of progressively\nstronger language models.\nLex-BL is a baseline suggested by Gao et al. (2018) that assigns metaphoric if the word has been\nannotated as metaphoric more often than literal in the training set, and literal otherwise (including for\nword types unseen in training).\nWu (Wu et al., 2018) is a system based on skip-gram word2vec (Mikolov et al., 2013), POS tags and\nword clusters with a CNN and BiLSTM plus ensemble learning, and is the winner of the 2018 Metaphor\nDetection Shared Task (Leong et al., 2018). As code or system output is not available, we report only\nthe results in their paper and leave it out of ﬁne-grained analysis.\nGao (Gao et al., 2018) uses concatenated GLOVE (Pennington et al., 2014) and ELMO embeddings\n(Peters et al., 2018) and a BiLSTM.\nMao (Mao et al., 2019) build on Gao et al. (2018) but explicitly model two linguistically-motivated\nfactors that might indicate metaphoricity: ﬁrstly, the potential clash between contextual and literal mean-\ning of the word to be labeled, and secondly, the possible conﬂict between the literal meaning of the word\nto be labeled and its context.\nDankers (Dankers et al., 2019) enhance a ﬁne-tuned BERT model (Dankers-BERT) with a multi-\ntask setup that learns metaphor and emotion labels jointly (Dankers). As code or system output is not\navailable, we report only the results in their paper and leave it out of ﬁne-grained analysis.\nStowe (Stowe et al., 2019) use the ELMO model of Gao et al. (2018) but show that additional, lin-\nguistically motivated training data enhances performance. As code or system output is not available, we\nreport only the results in their paper and leave it out of ﬁne-grained analysis.\nBERT is a ﬁne-tuned BERT model we implemented. Parameter details are in the Supplement.\nILLI (Gong et al., 2020) is one of the 3 best-performing systems on the 2020 Metaphor Detection\nShared Task (Leong et al., 2020). Its most basic form is a simple ﬁne-tuned RoBERTa (Liu et al.,\n2019) language model (ILLI-ROB). Its most sophisticated version (ILLI-F-ENS) adds a wide variety of\nlinguistic features and an ensemble based on 3 different runs on different train/dev splits. The system\ncode is available but at too short notice for us to conduct a ﬁne-grained analysis of this system yet.\n3724\nDM is the 2020 Shared Task winner (Su et al., 2020). It uses RoBERTa enriched with POS features\nand two transformers, one focusing on the whole sentence context and one on a more local context.\nDM-ENS builds an ensemble across nine different runs of DM. Their system output is available. 3 Our\nanalysis is based on the DM outputs in their submit folder, more speciﬁcally answer9 for DM as well\nas ensemble3 for DM-ENS (both for the VUA-ALL-POS task). The results vary only marginally from\nthe reported best results in their paper.\n2.2 Datasets\nThe VUA Metaphor Corpus 4 (Steen, 2010) consists of 115 texts of four different genres: academic,\nconversation, ﬁction and news. Each word, including function words, is annotated as metaphoric or\nliteral, using guidelines based on literal meanings being the more basic or concrete meanings of a word\n(Group, 2007). Metaphoric readings can still be highly frequent. Example 4 from the corpus contains\nthree conventional, frequent metaphoric readings, including the non-spatial meaning of in.\n(4) But Nicholas’s grand design collapsed in 1918\nThe corpus was used in the 2018 and 2020 VUA Metaphor Detection Shared Task (Leong et al., 2018;\nLeong et al., 2020). 5 The shared tasks include the VUA-ALL-POS task where all content words in a\nsentence (adjectives, verbs without have, do, be , nouns, adjectives) have to be labeled. Although the\noriginal corpus also labels function words for metaphoricity, the VUA-ALL-POS task does not evaluate\nsystems on function words. Therefore in Example 4, four tokens ( Nicholas,grand,design,collapsed)\nwould have to be labeled as metaphoric or literal.6\nFour other papers that did not participate in the shared task (Gao et al., 2018; Mao et al., 2019; Dankers\net al., 2019; Stowe et al., 2019) also use the VUA corpus but use quite different subsets of the corpus\nthan the shared task VUA-ALL-POS does. In the VUA-ALL-POS task all sentences in the VUA texts\nare used whereas Gao et al. (2018), Mao et al. (2019), Dankers et al. (2019) and Stowe et al. (2019) use\na much smaller subset of sentences, for reasons unknown. In addition, these four papers also evaluate on\nfunction words in this smaller subset, which makes a substantial difference.\nWe handle these two setups in two separate tasks: ﬁrstly, the original VUA-ALL-POS Shared Task\ndata7 and secondly, VUA-SEQ which uses the data in (Gao et al., 2018) 8, subsequently used by (Mao\net al., 2019; Dankers et al., 2019; Stowe et al., 2019). Statistics on these datasets are given in Table 1.\nUsing only content words means that VUA-ALL-POS evaluates on fewer tokens although it has more\nsentences and that it contains fewer metaphors per sentence.\n3 Results\nWe use the standard VUA-ALL-POS and VUA-SEQ training/test splits. Evaluation measures are pre-\ncision, recall and F1 for the metaphoric class as well as accuracy on all target tokens. Table 2 shows\noverall results. For Lex-BL, Gao, Mao and BERT we had working code and ran that on both datasets as\nwell as reporting original results from the Gao and Mao papers. For DM and DM-ENS we report and\nanalyse output from their Github repository, for others we report only original results from their papers.\nDataset comparison. Results on VUA-ALL-POS are overall considerably lower than on VUA-SEQ\nfor equivalent models. For example, our BERT model achieves F1 of 77.5 on VUA-SEQ but only 69.7\non VUA-ALL-POS. Similarly our rerun of Mao et al. (2019) achieves 74.3 on VUA-SEQ (identical to\ntheir reported results) but only 65.5 on VUA-ALL-POS. This is because VUA-SEQ also evaluates on\nfunction word metaphors that are easier to classify. Therefore, comparisons in various papers that do\n3https://github.com/YU-NLPLab/DeepMet\n4http://ota.ahds.ac.uk/headers/2541.xml\n5The 2020 Task has also used newly annotated essay data for metaphor recognition in sequences. As the VUA data is\nup-to-now the by far most frequently used data, we assess the state-of-the art on this dataset.\n6The label ALL-POS is slightly confusing given that function words are excluded but mainly serves to distinguish from yet\nanother version of the shared task which looks at verbs only.\n7https://github.com/EducationalTestingService/metaphor/tree/master/VUA-shared-task\n8https://github.com/gao-g/metaphor-in-context\n3725\nVUA Data #tokens % M #S #M/S\n-SEQall 205,425 11.6 10,567 3.4\n-SEQtrn 116,622 11.2 6,323 3.3\n-SEQdev 38,628 11.6 1,550 4.0\n-SEQtst 50,175 12.4 2,694 3.4\n-ALL-POSall 94,807 15.8 16,202 2.4\n-ALL-POStrn 72,611 15.2 12,122 2.3\n-ALL-POStest 22,196 17.9 4,080 2.5\nTable 1: Statistics for the VUA Datasets, including the number of target tokens to be classiﬁed, the\npercentage of metaphors among all target tokens, the number of sentences and the average number of\nmetaphors in sentences with at least one metaphoric word.\nResults on VUA-SEQ Results on VUA-ALL-POS\nSystem P R F1 Acc\nLex-BL 68.3 43.6 53.2 90.5\nGao 71.6 73.6 72.6 93.1\nGao Rerun 76.0 69.2 72.4 93.4\nMao 73.0 75.7 74.3 93.8\nMao Rerun 76.2 72.6 74.3 93.8\nDankers-BERT – – 76.3 –\nDankers – – 76.9 –\nStowe – – 73.8 –\nBERT 78.0 76.9 77.5 94.4\nSystem P R F1 Acc\nLex-BL 65.6 35.7 46.2 85.1\nWu 60.8 70.0 65.1 -\nGao Rerun 68.4 59.7 63.8 87.8\nMao Rerun 71.7 60.2 65.5 88.6\nBERT 75.4 64.7 69.7 89.9\nILLI-ROB 75.6 68.6 72.0 –\nILLI-F-ENS 74.6 71.5 73.0\nDM 72.8 72.6 72.7 90.2\nDM-ENS 76.5 76.8 76.6 91.6\nTable 2: Results on VUA-SEQ test (50,175 tokens, including function words) and VUA-ALL-POS test\n(22,196 tokens)\nnot distinguish the two setups are inherently unfair and this widespread practice should not be continued.\nThus, for example, the Gao model is not better than the 2018 Shared Task winner Wu as claimed in Gao et\nal. (2018), when compared on the same dataset and the same kind of part-of-speech; and the ILLINIMET\npaper (Gong et al., 2020) disadvantages itself by comparing their results on VUA-ALL-POS negatively\nto Mao et al. (2019), which they clearly beat when looking at the right dataset comparison.\nLanguage model improvements. The gains achieved by exploiting state-of-the-art language models\nare usually higher than the ones achieved by additional linguistic modeling or insights. For example,\non VUA-SEQ, the gain in moving from ELMO (Gao et al., 2018) to a ﬁne-tuned BERT model with an\notherwise similar setup was 4.9 F-measure points, whereas the gain from ELMO (Gao et al., 2018) to the\ninclusion of more complex linguistic modelling (Mao et al., 2019) is only 1.7 F-measure points. The gain\nwhen moving from Dankers-BERT to a multi-task model on top of BERT is only 0.6 F-measure points\n(Dankers et al., 2019). On VUA-ALL-POS, we again see a steady improvement with better language\nmodels, from ELMO in Gao/Mao (F1 65.5) to BERT (F1 69.7) to RoBERTa in ILLI-ROB (F1 72.0).\nHere again more sophisticated features (from ILLI-ROB’s F1 72.0 to ILLI-F-Ens F1 73.0) yield less\nof an improvement than better language models, although part-of-speech features play a positive role\nin both ILLI-F-ENS and in DM. Especially important is reducing performance variation by extensive\nensemble modeling (from DM’s 72.7 F1 to DM-ENS 76.6 F1).\nDoes this mean that standard language models indeed learn metaphor properties and generalise within\nmetaphorical patterns? We will now conduct further linguistic analysis to adress this question.\n3726\n4 Analysis\nWe will now investigate (i) how well the current systems handle conventional vs. novel metaphors, (ii)\nif they can handle frequent and less frequent word types and (iii) what the inﬂuence of morphology as\nwell as semantic similarity is on their capability to handle metaphoric usage of word types not seen in\ntraining. In our opinion, frequency and conventionality analysis are crucial to test whether the system\nmainly recognises frequently seen, word-speciﬁc meanings that might also be speciﬁed in dictionary\nentries (see the metaphors in Example 4 in Section 2.2) or whether it is able to generalise the concept of\nmetaphor to word types not seen in training or newly occurring metaphoric transfers.\nWe conduct the analysis on our reruns of Gao and Mao as well as BERT on VUA-SEQ and extend\nthe analysis with the DM models on VUA-ALL-POS. This includes the state-of-the art systems on both\ndatasets as well as 3 different language models (and extensions).\n4.1 Novel vs. Conventional Metaphors.\nMetaphors can be conventional (Example 4) or novel (see goose-step in Example 5 from the VUA cor-\npus).\n(5) Ron Todd [...] warned that party leaders could not expect everybody to ’goose-step’in the same\ndirection [...]\nConventional metaphors are frequent word usages that often have their own dictionary entries whereas\nnovel readings are rare and cannot be found in standard lexical resources. Other aspects also contribute\nto a metaphor’s conventionality, such as whether they do follow a metaphoric pattern. Recognising\nnovel metaphors is important: Shutova (2015) argues ”that NLP applications do not necessarily need to\naddress highly conventional and lexicalized metaphors that can be interpreted using standard word sense\ndisambiguation techniques”.\nDo Dinh et al. (2018) have extended the VUA corpus with reliable novelty scores for content word\nmetaphors. Their annotation guidelines deﬁne conventionality and novelty based on frequency of use\n(often used in everyday language vs. not usually used in everyday language ). The scores range from\n−1 indicating conventional metaphors to 1 for the most novel metaphors. For example, the metaphor in\nExample 5 has the score 0.765.\nWhereas Do Dinh et al. (2018) and Simpson et al. (2019) tackle novelty scoring given gold standard\nmetaphoric/literal information, we investigate how the novelty of a metaphor affects automatic methods\nfor ﬁnding metaphors in the ﬁrst place. Figure 1a and 1b show performance on conventionalised vs.\nnovel metaphors for all systems on metaphoric content words with novelty scores. The x-axis shows the\nconventionality threshold t and the y-axis shows accuracy/recall. The graphs depict results for conven-\ntional metaphors with a novelty score below t and for novel metaphors with a novelty score abovet. For\nexample, on VUA-SEQ, our BERT model achieves an accuracy just below 0.6 on the 828 metaphoric\ncontent words with a novelty score higher than 0.2. In contrast, it achieves an accuracy of over 70% on\nthe 2876 metaphoric content words with a novelty score lower than 0.2, indicating a substantially better\nperformance on conventional metaphors.\nWithin each model, the curve for conventionalised metaphors is consistently above the curve for novel\nmetaphors as long as the buckets have a reasonable size. 9 Conventionalised metaphors are therefore\nrecognized much more easily than novel ones. This is interesting as, from a human perspective, novel\nmetaphors are easier to ”notice”, and suggests that the algorithms might mainly learn different word\nsenses instead of general properties of metaphor, such as the fact that many metaphoric readings show a\ncontrast to their dictionary sense(s) or a contrast to the surrounding context.\n9DM and DM-ENS perform well for novel metaphors in VUA-ALL-POS from the threshold of 0.6 onwards, a bucket\nwhich contains only 25 novel metaphors — classiﬁcation changes for 3-4 novel items look like very large differences in the\ngraph. It would be interesting to see whether this performance on novel metaphors would hold for (non-existent) larger datasets\nannotated for novel metaphors.\n3727\n(a) VUA-SEQ (3704 tokens)\n (b) VUA-ALL-POS (3862 tokens)\nFigure 1: Accuracy of all models on metaphoric content words with novelty scores, measured separately\nfor novel and conventionalised metaphors for different thresholds. Novelty thresholds are shown on the\nx-axes. The number of instances is shown at the top of the graph with the number of items above the\ncorresponding novelty threshold ﬁrst and the number of items below the threshold second.\n4.2 Frequent vs Infrequent Word Types.\nTo further investigate how far the algorithms generalise across different word types and their speciﬁc\nmeanings, we show the performance of the systems on word types grouped by frequency in the training\nset in Tables 3 and 4.\nfr. in Train #tok Test #types Test Lex-BL Gao Mao Bert\n0 4847 2807 – (86.4) 45.1 (86.4) 48.3 (87.3) 53.5 (87.3)\n1-10 7631 3349 49.4 (83.1) 63.0 (86.3) 65.1 (86.4) 70.3 (88.6)\n11-50 6895 833 55.6 (86.5) 73.9 (90.8) 74.3 (90.7) 79.5 (93.5)\n51-100 2805 86 66.7 (90.5) 79.5 (93.6) 80.7 (93.7) 85.7 (95.3)\n101 - ∞ 27,997 125 60.04 (94.2) 83.2 (97.2) 85.3 (97.5) 86.0 (97.6)\nall 50,175 7200 53.2 (90.5) 72.4 (93.4) 74.3 (93.8) 77.5 (94.4)\nTable 3: F-measure (accuracy in parenthesis) on different frequency buckets in VUA-SEQ. The fre-\nquency buckets are given in the ﬁrst column, the number of tokens in the test set that belong to each\nbucket in the second column and the number of types in the test set belonging to each bucket in the third\ncolumn. For example, there are 2807 word types in the test set that have never been seen in the training\nset. 125 word types in the test set have been seen over 100 times in training, making up 27,997 tokens of\nall test tokens.\nOverall, F-measure and accuracy increases with the number of times the word type has been seen\nin training for all models. For example, the best-performing model, BERT, on VUA-SEQ (Table 3)\nachieves an F-measure of 53.5 on words whose type has not been seen in training, but already 70.3 on\nwords whose type has been seen 1-10 times in training. The one exception is a drop in performance on\nF-measure for all models on the highest frequency bucket in VUA-ALL-POS (Table 4). Investigation\nshowed that this bucket included only 46 word types, including also word types such as Yes, Mm, er,\nalso which were rarely used metaphorically.10 Thus, the percentage of metaphors in this bucket is much\nsmaller than in the remainder of the corpus, making F-measure more volatile. This is not true for the\nhigh frequency bucket in VUA-SEQ which includes many prepositions which are frequently annotated\nas metaphors (see the non-spatial meaning of in in Example 4).\nMao et al. (2019) explicitly encode clashes between literal word meaning and contextual meaning as\n10Given that the evaluation on VUA-ALL-POS is normally restricted to content words this seems to be a small number of\nnoise words included in the test tokens.\n3728\nfr. in Train #tok Test #types Test Lex-BL Gao Mao Bert DM DM-Ens\n0 4050 2583 – (85.6) 45.8 (84.3) 46.1 (86.1) 53.3 (87.2) 61.1 (88.7) 64.9 (89.9)\n1-10 7094 3329 49.5 (82.7) 59.0 (85.0) 61.7 (86.2) 67.4 (87.9) 71.8 (88.4) 76.4 (90.0)\n11-50 6449 1069 51.1 (86.0) 72.0 (90.6) 73.1 (90.9) 75.3 (91.8) 76.9 (91.8) 81.8 (93.2)\n51-100 2180 109 64.6 (85.0) 77.9 (90.1) 77.4 (89.7) 81.6 (92.0) 81.7 (91.8) 84.8 (92.9)\n101 - ∞ 2423 46 27.6 (88.9) 67.2 (92.5) 68.6 (92.8) 71.1 (93.2) 69.4 (92.4) 75.7 (93.7)\nall 22,196 7036 46.2 (85.1) 63.8 (87.8) 65.6 (88.6) 69.7 (89.9) 72.7 (90.2) 76.6 (91.6)\nTable 4: F-measure (accuracy in parenthesis) on different frequency buckets in VUA-ALL-POS (all test\ntokens). Columns correspond to the columns in Table 3.\na metaphoricity indicator on top of Gao’s Elmo model, leading to some performance improvements also\nfor word types not seen in training when compared to Gao et al. (2018) (improving from an F1 of 45.1 to\n48.3 on unseen word types on VUA-SEQ, Table 3). These improvements are dwarfed by just moving to\na stronger language model such as BERT (F1 53.5 on unseen types in VUA-SEQ) but it is possible that\nthe improvements would also carry over when the additional linguistic modelling would be stacked on\ntop of BERT.\nIt might not seem surprising that all algorithms perform better on word types more often seen in train-\ning, but we believe that this type of analysis should be given regularly to check the model’s dependence\non word-speciﬁc labeled data and its ability to generalise.\n4.3 The impact of morphology and lexical relations\nAll models are still able to recognise some metaphors for word types not seen in training (henceforth,\nunseen types). We now investigate when the models are able to generalise to such unseen types.\nFirst, we look at whether performance on unseen word types whose morphological variants have been\nseen in training is higher than on other unseen word types. This would be plausible as morphological\nvariants will often be close in embedding space and also often undergo the same metaphoric pattern\nshifts. For example, the AFFECTION IS WARMTH metaphoric pattern is instantiated by warm greet-\ning, warmer greeting as well as the warmth of his greeting. We also hypothesized that inﬂectional vari-\nations probably behave more similarly than derivational variations. We therefore distinguished between\nexact word type seen, word type not seen but an inﬂectional variation seen and neither word type nor in-\nﬂectional variation seen but derivational variant seen. Potential derivational variations were extracted via\nWordNet (Miller et al., 1990). Tables 5 and 6 show that unseen types where morphological variations\nhad been seen are indeed easier than other unseen types for all systems. For example, on VUA-SEQ\nF-measure for BERT gradually gets worse from seen types (F1 of 80.3) to 63.8 for word types that have\nonly an inﬂectional variant seen in training to 54.9 for word types that have only a derivational variant\nseen in training to 47.4 for word types that have neither itself, nor an inﬂectional or derivational variant\nseen in training (Table 5). For all systems but DM-ENS, performance on word types where inﬂectional\nvariations have been seen is higher than if only derivational variations have been seen. For Gao, Mao\nand BERT, performance on types where no variation has been seen in training might actually not be\nbetter than just assigning literal as Lex-BL does for the unseen cases — we see a drop in accuracy com-\npared to Lex-BL for these models (last column in Tables 5 and 6) as well as low precision for metaphor\nrecognition (precision not shown in the tables).\ntype seen inﬂ.var. seen deriv.var seen no var seen\nLex-BL 56.9 (90.9) – (76.0) – (80.7) – (89.3)\nGao 75.5 (94.2) 57.0 (80.1) 41.9 (79.0) 39.5 (88.5)\nMao 77.2 (94.5) 56.7 (79.5) 43.1 (80) 43.9 (89.7)\nBert 80.3 (95.2) 63.8 (81.9) 54.9 (82.4) 47.4 (89.0)\n#tok test 45,328 879 290 3678\n#types test 4393 603 196 2013\nTable 5: F-Measure (accuracy) on VUA-SEQ with regard to morphological variants seen in training\n3729\ntype seen inﬂ. var. seen deriv. var seen no var seen\nLex-BL 51.0 (85.0) – (78.5) – (84.4) – (88.0)\nGao 67.1 (88.6) 55.1 (80.6) 41.5 (82.6) 41.0 (85.6)\nMao 68.7 (89.2) 53.7 (81.6) 42.1 (84.1) 42.0 (87.8)\nBert 72.6 (90.5) 60.5 (83.3) 55.2 (85.9) 48.7 (88.6)\nDM 74.7 (90.6) 65.3 (84.7) 64.3 (89.1) 58.1 (89.9)\nDM-ENS 78.7 (92.0) 68.8 (86.1) 71.7 (90.6) 60.9 (91.0)\n#tok test 18, 146 918 276 2856\n#types test 4553 622 187 1777\nTable 6: F-measure (accuracy) on VUA-ALL-POS with regard to morphological variants seen in training\nIn a second study, we look at the performance on unseen word types when synonyms have been seen\nin training. Synonyms also are close in embedding spaces and also often share metaphorical patterns\n(see attack and bash in Example 1 and 2 in the Introduction). Therefore, language models might fare\nbetter when a synonym has been seen. We extract synonyms of a word from WordNet. Table 7 shows\nunseen word types where synonyms have been seen before are indeed easier than unseen word types\nwhere synonyms have not been seen. This holds for all systems without exception. For example, on\nVUA-ALL-POS, performance of the Shared Task Winner DM-ENS has an F1 of 78.8 for seen word\ntypes, falling to 68.3 for unseen word types where a synonym has been seen and to 56.8 for unseen word\ntypes where no synonym has been seen.\nVUA-SEQ VUA-ALL-POS\ntype seen syn seen no syn seen type seen syn seen no syn seen\nLex-BL 56.9 (90.9) – (76.1) – (92.4) 51.0 (85.0) – (77.7) – (91.4)\nGao 75.5 (94.2) 52.7 (79.3) 30.5 (90.6) 67.1 (88.6) 52.9 (79.3) 33.1 (87.9)\nMao 77.2 (94.5) 53.6 (79.4) 37.8 (91.9) 68.7 (89.2) 53.5 (82.0) 33.0 (89.2)\nBert 80.3 (95.2) 58.4 (79.9) 44.2 (91.7) 72.6 (90.5) 56.1 (81.2) 47.9 (91.6)\nDM – – – 74.7 (90.6) 65.1 (84.2) 53.1 (92.0)\nDM-ENS – – – 78.7 (92.0) 68.3 (85.6) 56.8 (93.0)\n#tok test 45,328 1792 2055 18,146 1713 2337\n#types test 4393 1238 1574 4553 1199 1387\nTable 7: F-measure (accuracy in parenthesis) with regard to synonyms seen in training.\nIn conclusion, current models seem to be able to generalise to a certain degree to unseen word types as\nlong as they are synonyms or morphological variations of seen ones. We give two examples of metaphors\nin the test set of VUA-ALL-POS (i) that all or most systems identiﬁed correctly, (ii) the type of which\nhas not been seen in training and (iii) for which morphological variations or synonyms have been seen.\nThe test example comes ﬁrst and a similar metaphor from the training set second after an arrow.\n(6) . . . to . . .punctuate aspects of Holly’s life←stressed different facets of Kahlo’s public persona\n(7) the richness of their exquisitely-sculpted decoration ←the colours were rich\nOf course, due to the black box nature of the language models, the extensive pretraining they undergo\nbefore ﬁne-tuning and other interferences such as context similarity, we cannot claim that these were\nthe actual examples that the models generalised from. However, the quantitative data shows that some\ngeneralisations do take place.\n4.4 The interaction of word frequency and unconventionality\nThere is a moderate inverse correlation between metaphoric novelty and word frequency (Do Dinh et al.,\n2018). High frequency words tend to have many conventionalised metaphoric senses; however, low fre-\nquency is not necessarily an indication of novel metaphor usage as low frequency words can also follow\n3730\nthe metaphoric patterns of their high frequency synonyms (such astussle being used for non-physical ar-\nguments just like attack). We therefore investigate the interaction between novelty and word frequency,\nin particular whether for low frequency word types performance still depends on novelty/conventionality.\nFigure 2 shows a heatmap that displays the interaction between frequency count in training on the\nx-axis and conventionality scores on the y-axis for the 3704 VUA-SEQ content word metaphors with\nnovelty scores in the test set. Similar to the analysis in Do Dinh et al. (2018), we see that metaphors using\nhigh frequency words normally do not have high novelty scores (right-most column): of 262 metaphoric\ntest tokens whose type has been seen more than 100 times in training, 222 have a novelty score equal or\nbelow zero.\nWe enhance this analysis by showing the accuracy/recall of the BERT model on these subgroups in the\nﬁelds of the heatmap. We see that even for low frequency words (two left-most columns), convention-\nality still matters and unconventional metaphors tend to be harder to recognise than conventional ones.\nFor example, even for unseen word types (left-most column), performance on conventional metaphors\nwith novelty scores below 0 is 66%, and then gradually decreases to 53%, 52%, 50% and 38% for less\nconventional metaphors. Therefore word type frequency does not account for all variation in classiﬁer\nperformance.\nThe picture is not always completely clear for all models and across both datasets. Especially, small\nbucket sizes for some ﬁelds in the heatmap do not allow ﬁrm conclusions. However, the general message\nholds. Further heatmap examples for other systems on VUA-ALL-POS can be found in the supplemen-\ntary material.\nFigure 2: Heatmap showing the interaction between frequency and conventionality as well as classiﬁer\nperformance for the 3704 metaphors with a conventionality score in the VUA-SEQ test set. On the x-axis,\nwe ﬁnd how often a word type was seen in training. On the y-axis, we have buckets of conventionality\nscores. In the ﬁelds we see the number of test tokens in the bucket as well as accuracy/recall of the BERT\nmodel on this bucket.\n3731\n5 Related Work\nDatasets. In some datasets, each word is labeled for metaphoricity (VUA Metaphor corpus, (Steen,\n2010)) whereas in others only one target word in a bigram or a sentence is labeled (Mohammad et al.,\n2016; Shutova et al., 2016; Birke and Sarkar, 2006; Tsvetkov et al., 2014; Turney et al., 2011, among\nothers). We concentrate on datasets where each word is labeled as (i) these are highly appropriate for the\nsequence labeling tasks that language models excel at and (ii) the 2018 and 2020 Metaphor Shared Tasks\n(Leong et al., 2018; Leong et al., 2020) use such corpora. We have shown that it matters substantially\nwhich dataset partition and setup within the VUA corpus you use and encourage future work to not\ncompare systems working on the two different setups anymore.\nMost datasets include only a binary metaphor/literal annotation per word, making it hard to assess sys-\ntem capabilities for the recognition of various metaphor types, such as conventional vs. novel metaphors,\ndeliberately used vs. unintentional metaphors (Steen, 2008) or different domain mappings. Some excep-\ntions exist, such as the conventionality annotation in (Do Dinh et al., 2018; Dunn, 2014), an annotation\nakin to deliberateness in (Klebanov and Flor, 2013) and annotated domain mappings in (Shutova and\nTeufel, 2010). However, most of these were small scale and/or are not publically available, the exception\nbeing the conventionality ratings by Do Dinh et al. (2018), which we use in this paper.\nMetaphor recognition. Data-driven approaches to metaphor recognition (Turney et al., 2011;\nTsvetkov et al., 2014; Shutova et al., 2016; Shutova et al., 2017; Bulat et al., 2017; Rei et al., 2017;\nK¨oper and im Walde, 2017; Wu et al., 2018; Gao et al., 2018; Gutierrez et al., 2016; Mao et al., 2018;\nMao et al., 2019; Dankers et al., 2019; Stowe et al., 2019; Su et al., 2020; Gong et al., 2020, among\nothers) use a variety of information sources such as abstractness/concreteness features, semantic class\ninformation, part-of-speech tags, property norms and outside lexical databases as well as multimodal\nand multilingual information. The recent state of the art models we discuss (Gao et al., 2018; Wu et al.,\n2018; Mao et al., 2019; Dankers et al., 2019; Stowe et al., 2019; Gong et al., 2020; Su et al., 2020) use\nsequence labeling and build on embeddings and/or language models. Leong et al. (2020) state that more\nthan half of participants in the 2020 Shared Task use a variation of BERT. We investigate their proper-\nties and performance levels in more detail than previously done, including analysis for conventionality,\nfrequency and generalisation via morphology and semantic similarity.\nNovel vs. conventionalized metaphors. We investigated how conventionality impacts metaphor\nrecognition. Recent work (Dunn, 2014; Do Dinh et al., 2018; Parde and Nielsen, 2018; Simpson et\nal., 2019) has assigned novelty scores to (given) metaphors. However, they have either not investigated\nthe inﬂuence of novelty on metaphor detection per se or not worked in a sequence labeling, full-text\nparadigm. We have shown that assigning metaphor novelty scores assuming that metaphors have already\nbeen reliably detected is currently somewhat unrealistic as a metaphor’s novelty has a strong inﬂuence\non being detected in the ﬁrst place by current models.\n6 Conclusion and Future Work\nWe compared several recent models for metaphor recognition, which all build on language models and/or\nembeddings. We cast doubt on the capability of these models to actually learn general properties of\nmetaphor as the models do not perform well on non-conventionalised metaphors and rarer word types.\nThey excel on frequently seen word types with conventionalised metaphoric meanings, which is more\nakin to word sense disambiguation. However, they do show generalisation capabilities beyond word\nsense disambiguation for words unseen in training if morphological variations or synonyms have been\nseen in training.\nThe latter ﬁnding suggests that metaphoric patterns that hold across morphological variations and\nsynonyms might to a degree be learnt by current systems. To follow this up, in the future, we will extend\ncurrent metaphor corpora by annotating them for metaphorical patterns (or what Lakoff and Johnson\n(1980) call conceptual metaphors) as well as existence of annotated metaphorical meanings in WordNet.\n3732\nReferences\nJulia Birke and Anoop Sarkar. 2006. A clustering approach for nearly unsupervised recognition of nonliteral\nlanguage. In 11th Conference of the European Chapter of the Association for Computational Linguistic (EACL).\nLuana Bulat, Stephen Clark, and Ekaterina Shutova. 2017. Modelling metaphor with attribute-based semantics.\nIn Proceedings of the 15th Conference of the EACL: Volume 2, Short Papers, pages 523–528.\nVerna Dankers, Marek Rei, Martha Lewis, and Ekaterina Shutova. 2019. Modelling the interplay of metaphor and\nemotion through multitask learning. In Proceedings of the 2019 Conference on Empirical Methods in Natural\nLanguage Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-\nIJCNLP), pages 2218–2229.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. Bert: Pre-training of deep bidirec-\ntional transformers for language understanding. In Proceedings of the 2019 Conference of the North American\nChapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and\nShort Papers), pages 4171–4186.\nErik-Lˆan Do Dinh, Hannah Wieland, and Iryna Gurevych. 2018. Weeding out conventionalized metaphors: A\ncorpus of novel metaphor annotations. In Proceedings of the 2018 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP), pages 1412–1424.\nJonathan Dunn. 2014. Measuring metaphoricity. In Proceedings of the 52nd Annual Meeting of the ACL (Volume\n2: Short Papers), pages 745–751.\nGe Gao, Eunsol Choi, Yejin Choi, and Luke Zettlemoyer. 2018. Neural metaphor detection in context. In\nProceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 607–613.\nHongyu Gong, Kshitij Gupta, Akriti Jain, and Suma Bhat. 2020. Illinimet: Illinois system for metaphor detection\nwith contextual and linguistic information. In Proceedings of the Second Workshop on Figurative Language\nProcessing, pages 146–153.\nPragglejazz Group. 2007. Mip: a method for identifying metaphorically used words in discourse. Metaphor and\nsymbol, 22(1):1–39.\nE Dario Gutierrez, Ekaterina Shutova, Tyler Marghetis, and Benjamin Bergen. 2016. Literal and metaphorical\nsenses in compositional distributional semantic models. In Proceedings of the 54th Annual Meeting of the ACL\n(Volume 1: Long Papers), pages 183–193.\nDiederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint\narXiv:1412.6980.\nBeata Beigman Klebanov and Michael Flor. 2013. Argumentation-relevant metaphors in test-taker essays. In\nProceedings of the First Workshop on Metaphor in NLP, pages 11–20.\nMaximilian K ¨oper and Sabine Schulte im Walde. 2017. Improving verb metaphor detection by propagating\nabstractness to words, phrases and individual senses. In Proceedings of the 1st Workshop on Sense, Concept\nand Entity Representations and their Applications, pages 24–30.\nGeorge Lakoff and Mark Johnson. 1980. Conceptual metaphor in everyday language. The journal of Philosophy,\n77(8):453–486.\nChee Wee Ben Leong, Beata Beigman Klebanov, and Ekaterina Shutova. 2018. A report on the 2018 vua metaphor\ndetection shared task. In Proceedings of the Workshop on Figurative Language Processing, pages 56–66.\nChee Wee Leong, Beata Beigman Klebanov, Chris Hamill, Egon Stemle, Rutuja Ubale, and Xianyang Chen. 2020.\nA report on the 2020 vua and toeﬂ metaphor detection shared task. In Proceedings of the Second Workshop on\nFigurative Language Processing, pages 18–29.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke\nZettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. arXiv\npreprint arXiv:1907.11692.\nRui Mao, Chenghua Lin, and Frank Guerin. 2018. Word embedding and wordnet based metaphor identiﬁcation\nand interpretation. In Proceedings of the 56th Annual Meeting of the ACL . Association for Computational\nLinguistics (ACL).\n3733\nRui Mao, Chenghua Lin, and Frank Guerin. 2019. End-to-end sequential metaphor identiﬁcation inspired by\nlinguistic theories. In Proceedings of the 57th Conference of the ACL, pages 3888–3898.\nTomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efﬁcient estimation of word representations in\nvector space. arXiv preprint arXiv:1301.3781.\nGeorge A Miller, Richard Beckwith, Christiane Fellbaum, Derek Gross, and Katherine J Miller. 1990. Introduction\nto wordnet: An on-line lexical database. International journal of lexicography, 3(4):235–244.\nSaif Mohammad, Ekaterina Shutova, and Peter Turney. 2016. Metaphor as a medium for emotion: An empirical\nstudy. In Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics, pages 23–33.\nNatalie Parde and Rodney D Nielsen. 2018. Exploring the terrain of metaphor novelty: A regression-based\napproach for automatically scoring metaphors. In Thirty-Second AAAI Conference on Artiﬁcial Intelligence.\nJeffrey Pennington, Richard Socher, and Christopher Manning. 2014. Glove: Global vectors for word represen-\ntation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP),\npages 1532–1543.\nMatthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettle-\nmoyer. 2018. Deep contextualized word representations. In Proceedings of NAACL-HLT, pages 2227–2237.\nMarek Rei, Luana Bulat, Douwe Kiela, and Ekaterina Shutova. 2017. Grasping the ﬁner point: A supervised\nsimilarity network for metaphor detection. In Proceedings of the 2017 Conference on Empirical Methods in\nNatural Language Processing, pages 1537–1546.\nEkaterina Shutova and Simone Teufel. 2010. Metaphor corpus annotated for source-target domain mappings. In\nLREC, volume 2.\nEkaterina Shutova, Douwe Kiela, and Jean Maillard. 2016. Black holes and white rabbits: Metaphor identiﬁcation\nwith visual features. In Proceedings of the 2016 Conference of the NAACL: Human Language Technologies ,\npages 160–170.\nEkaterina Shutova, Lin Sun, Elkin Dar ´ıo Guti´errez, Patricia Lichtenstein, and Srini Narayanan. 2017. Multi-\nlingual metaphor processing: Experiments with semi-supervised and unsupervised learning. Computational\nLinguistics, 43(1):71–123.\nEkaterina Shutova. 2015. Design and evaluation of metaphor processing systems. Computational Linguistics,\n41(4):579–623.\nEdwin Simpson, Erik-L ˆan Do Dinh, Tristan Miller, and Iryna Gurevych. 2019. Predicting humorousness and\nmetaphor novelty with gaussian process preference learning. In Proceedings of the 57th Conference of the ACL,\npages 5716–5728.\nGerard Steen. 2008. The paradox of metaphor: Why we need a three-dimensional model of metaphor. Metaphor\nand Symbol, 23(4):213–241.\nGerard Steen. 2010. A method for linguistic metaphor identiﬁcation: From MIP to MIPVU , volume 14. John\nBenjamins Publishing.\nKevin Stowe, Sarah Moeller, Laura Michaelis, and Martha Palmer. 2019. Linguistic analysis improves neural\nmetaphor detection. In Proceedings of the 23rd Conference on Computational Natural Language Learning\n(CoNLL), pages 362–371.\nChuandong Su, Fumiyo Fukumoto, Xiaoxi Huang, Jiyi Li, Rongbo Wang, and Zhiqun Chen. 2020. Deepmet: A\nreading comprehension paradigm for token-level metaphor detection. In Proceedings of the Second Workshop\non Figurative Language Processing, pages 30–39.\nYulia Tsvetkov, Leonid Boytsov, Anatole Gershman, Eric Nyberg, and Chris Dyer. 2014. Metaphor detection with\ncross-lingual model transfer. In Proceedings of the 52nd Annual Meeting of the ACL (Volume 1: Long Papers),\npages 248–258.\nPeter D Turney, Yair Neuman, Dan Assaf, and Yohai Cohen. 2011. Literal and metaphorical sense identiﬁcation\nthrough concrete and abstract context. In Proceedings of the Conference on EMNLP, pages 680–690. Associa-\ntion for Computational Linguistics.\nTony Veale, Ekaterina Shutova, and Beata Beigman Klebanov. 2016. Metaphor: A computational perspective.\nSynthesis Lectures on Human Language Technologies, 9(1):1–160.\n3734\nChuhan Wu, Fangzhao Wu, Yubo Chen, Sixing Wu, Zhigang Yuan, and Yongfeng Huang. 2018. Neural metaphor\ndetecting with cnn-lstm model. In Proceedings of the Workshop on Figurative Language Processing , pages\n110–114.\n7 Supplement to: An analysis of language models for metaphor recognition\n7.1 BERT Parameter Details\nWe use BERT with a dropout and a linear classiﬁcation layer stacked on top of BERT.\nSince BERT has a ﬁxed vocabulary of 30,522 words, we use the standard BERT-tokenizer. Start of\nsentence and end of sentence markup tokens are prepended and appended to each sentence. We use the\nuncased base version of BERT (12 Layers, hidden size of 768, 12 heads) since it offers more compact\nmeaning representations than the large version (1024) and is more stable when ﬁne-tuning on small\ndatasets according to Devlin et al. (2019). All hyperparameters are set to standard values. Dropout\nprobability is 0.1. The learning rate is 5e-5 for the Adam optimizer (Kingma and Ba, 2014) after a\nlinear warmup on the ﬁrst 10% of the training steps. Weight decay is 0.01, where bias vectors and\nnormalization layers are excluded from the decay. The training batch size is set to 16 instances. When\nfacing GPU memory issues this value is decreased to 12. Following Devlin et al. (2019) we use only 3\ntraining epochs. If words in the input sentence get tokenized to multiple sub-tokens, we only use the ﬁrst\nsub-token for sequence labeling evaluation.\n7.2 Results by POS Tag and genre\nIt is standard to give the results for the 4 genres in the corpus as well as on different POS. Results for\nVUA-ALL-POS can be found in the 2018 and 2020 Shared Task reports The corresponding table for\nVUA-SEQ is given below. We do not observe any differences in tendencies to what has been previously\nreported: adjectives and nouns are harder than verbs and adverbs; conversational texts are the most\ndifﬁcult genre.\n# Test Tokens BERT Gao et al (2018) Mao et al (2019)\nVERB 9,872 74.1 68.4 69.8\nNOUN 8,588 68.6 60.0 64.1\nADJ 3,965 64.2 61.9 60.9\nADV 3,393 76.2 60.3 63.6\nADP 5,300 90.9 88.0 89.5\nPART 1,463 61.6 56.6 61.2\nNews 12,324 76.6 72.0 74.3\nConv. 13,270 69.6 64.4 66.1\nFict. 10,966 73.0 66.1 69.6\nAcad. 13,615 83.4 78.9 80.3\nTable 8: F-measures on VUA-SEQ measured for PoS-tags and Genres.\n7.3 Heatmap Examples for VUA-ALL-POS\nAll heatmaps below show the interaction between frequency and novelty for the 3862 metaphors with a\nnovelty score in VUA-ALL-POS. On the x-axis we ﬁnd how often a word type was seen in training, on\nthe y-axis we have buckets of novelty scores. In the ﬁelds we see the number of test tokens in the bucket\nas well as accuracy/recall on this bucket. We show heatmaps for the three best-performing models.\n3735\nFigure 3: BERT on VUA-ALL-POS\nFigure 4: DM on VUA-ALL-POS\n3736\nFigure 5: DM-ENS on VUA-ALL-POS",
  "topic": "Metaphor",
  "concepts": [
    {
      "name": "Metaphor",
      "score": 0.7949963212013245
    },
    {
      "name": "Computer science",
      "score": 0.7365888357162476
    },
    {
      "name": "Natural language processing",
      "score": 0.5993468165397644
    },
    {
      "name": "Linguistics",
      "score": 0.41821905970573425
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4145282506942749
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I223822909",
      "name": "Heidelberg University",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I2802799214",
      "name": "Association for Computational Linguistics",
      "country": "US"
    }
  ]
}