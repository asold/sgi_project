{
  "title": "Hierarchical label-wise attention transformer model for explainable ICD coding",
  "url": "https://openalex.org/W4224541024",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2152438523",
      "name": "Leibo Liu",
      "affiliations": [
        "UNSW Sydney"
      ]
    },
    {
      "id": "https://openalex.org/A1989184110",
      "name": "Óscar Pérez Concha",
      "affiliations": [
        "UNSW Sydney"
      ]
    },
    {
      "id": "https://openalex.org/A2046956051",
      "name": "Anthony Nguyen",
      "affiliations": [
        "Commonwealth Scientific and Industrial Research Organisation",
        "Australian e-Health Research Centre"
      ]
    },
    {
      "id": "https://openalex.org/A2116657651",
      "name": "Vicki Bennett",
      "affiliations": [
        "Australian Institute of Health and Welfare"
      ]
    },
    {
      "id": "https://openalex.org/A220057491",
      "name": "Louisa Jorm.",
      "affiliations": [
        "UNSW Sydney"
      ]
    },
    {
      "id": "https://openalex.org/A2152438523",
      "name": "Leibo Liu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1989184110",
      "name": "Óscar Pérez Concha",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2046956051",
      "name": "Anthony Nguyen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2116657651",
      "name": "Vicki Bennett",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A220057491",
      "name": "Louisa Jorm.",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W6647368776",
    "https://openalex.org/W2260168650",
    "https://openalex.org/W3015148313",
    "https://openalex.org/W3121194378",
    "https://openalex.org/W6761570917",
    "https://openalex.org/W6647971942",
    "https://openalex.org/W1974957625",
    "https://openalex.org/W6763531446",
    "https://openalex.org/W2964142373",
    "https://openalex.org/W3035294872",
    "https://openalex.org/W2963912736",
    "https://openalex.org/W6782540692",
    "https://openalex.org/W3091309561",
    "https://openalex.org/W6770221138",
    "https://openalex.org/W3134691471",
    "https://openalex.org/W4212985363",
    "https://openalex.org/W2396881363",
    "https://openalex.org/W3175985785",
    "https://openalex.org/W6798342717",
    "https://openalex.org/W3103901889",
    "https://openalex.org/W3202283490",
    "https://openalex.org/W3132259035",
    "https://openalex.org/W3167829962",
    "https://openalex.org/W2911489562",
    "https://openalex.org/W2963716420",
    "https://openalex.org/W2971258845",
    "https://openalex.org/W6781031682",
    "https://openalex.org/W2096664202",
    "https://openalex.org/W6672367657",
    "https://openalex.org/W3038012435",
    "https://openalex.org/W3099750501",
    "https://openalex.org/W2798935874",
    "https://openalex.org/W6723408873",
    "https://openalex.org/W2977522001",
    "https://openalex.org/W6781533629",
    "https://openalex.org/W6779440454",
    "https://openalex.org/W6801930474",
    "https://openalex.org/W2970726176",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W3135427446",
    "https://openalex.org/W4287704453",
    "https://openalex.org/W2006348601",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3101475827",
    "https://openalex.org/W3096784882",
    "https://openalex.org/W3015468748",
    "https://openalex.org/W4238846128",
    "https://openalex.org/W3174340663",
    "https://openalex.org/W4205976114",
    "https://openalex.org/W2997050424",
    "https://openalex.org/W3211566171",
    "https://openalex.org/W2086294181",
    "https://openalex.org/W4240030094",
    "https://openalex.org/W3037422790",
    "https://openalex.org/W3046375318",
    "https://openalex.org/W4287718305",
    "https://openalex.org/W2937845937",
    "https://openalex.org/W2799321649",
    "https://openalex.org/W3167343366",
    "https://openalex.org/W4362219827",
    "https://openalex.org/W2948042116",
    "https://openalex.org/W2943552823",
    "https://openalex.org/W2941736751",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4293582125",
    "https://openalex.org/W4301697967",
    "https://openalex.org/W3102523151",
    "https://openalex.org/W1614298861",
    "https://openalex.org/W2925863688",
    "https://openalex.org/W4250316874",
    "https://openalex.org/W1988558550",
    "https://openalex.org/W2899014158",
    "https://openalex.org/W1989568037",
    "https://openalex.org/W2951025380",
    "https://openalex.org/W3212490246",
    "https://openalex.org/W2768948924",
    "https://openalex.org/W2493343568",
    "https://openalex.org/W3073296745"
  ],
  "abstract": "International Classification of Diseases (ICD) coding plays an important role in systematically classifying morbidity and mortality data. In this study, we propose a hierarchical label-wise attention Transformer model (HiLAT) for the explainable prediction of ICD codes from clinical documents. HiLAT firstly fine-tunes a pretrained Transformer model to represent the tokens of clinical documents. We subsequently employ a two-level hierarchical label-wise attention mechanism that creates label-specific document representations. These representations are in turn used by a feed-forward neural network to predict whether a specific ICD code is assigned to the input clinical document of interest. We evaluate HiLAT using hospital discharge summaries and their corresponding ICD-9 codes from the MIMIC-III database. To investigate the performance of different types of Transformer models, we develop ClinicalplusXLNet, which conducts continual pretraining from XLNet-Base using all the MIMIC-III clinical notes. The experiment results show that the F1 scores of the HiLAT + ClinicalplusXLNet outperform the previous state-of-the-art models for the top-50 most frequent ICD-9 codes from MIMIC-III. Visualisations of attention weights present a potential explainability tool for checking the face validity of ICD code predictions.",
  "full_text": null,
  "topic": "Transformer",
  "concepts": [
    {
      "name": "Transformer",
      "score": 0.7589287161827087
    },
    {
      "name": "Computer science",
      "score": 0.7292115688323975
    },
    {
      "name": "Coding (social sciences)",
      "score": 0.5469690561294556
    },
    {
      "name": "Artificial neural network",
      "score": 0.5100842118263245
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5060059428215027
    },
    {
      "name": "Machine learning",
      "score": 0.4771784842014313
    },
    {
      "name": "ICD-10",
      "score": 0.45537835359573364
    },
    {
      "name": "Neural coding",
      "score": 0.4319758713245392
    },
    {
      "name": "Data mining",
      "score": 0.3681929409503937
    },
    {
      "name": "Natural language processing",
      "score": 0.3394734263420105
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.33691245317459106
    },
    {
      "name": "Medicine",
      "score": 0.12417709827423096
    },
    {
      "name": "Engineering",
      "score": 0.06280019879341125
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Psychiatry",
      "score": 0.0
    },
    {
      "name": "Statistics",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ]
}