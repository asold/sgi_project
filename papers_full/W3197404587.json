{
  "title": "Biomedical Data-to-Text Generation via Fine-Tuning Transformers",
  "url": "https://openalex.org/W3197404587",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A3197635987",
      "name": "Ruslan Yermakov",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2331035586",
      "name": "Nicholas Drago",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1626417758",
      "name": "Angelo Ziletti",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3034999214",
    "https://openalex.org/W2168041406",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2154652894",
    "https://openalex.org/W3082274269",
    "https://openalex.org/W2964006684",
    "https://openalex.org/W2739046565",
    "https://openalex.org/W2786660442",
    "https://openalex.org/W3098824823",
    "https://openalex.org/W3022814719",
    "https://openalex.org/W3117367489",
    "https://openalex.org/W2936695845",
    "https://openalex.org/W2963532001",
    "https://openalex.org/W2963592583",
    "https://openalex.org/W3037109418",
    "https://openalex.org/W3173561451",
    "https://openalex.org/W2963672599",
    "https://openalex.org/W3035252911",
    "https://openalex.org/W4287703745",
    "https://openalex.org/W2970785793",
    "https://openalex.org/W3115264425",
    "https://openalex.org/W3007523830",
    "https://openalex.org/W3026997957",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W2963091658",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W2996403597",
    "https://openalex.org/W2963912046",
    "https://openalex.org/W2786672974",
    "https://openalex.org/W3098495697",
    "https://openalex.org/W2982399380",
    "https://openalex.org/W2891732163"
  ],
  "abstract": "Data-to-text (D2T) generation in the biomedical domain is a promising - yet mostly unexplored - field of research. Here, we apply neural models for D2T generation to a real-world dataset consisting of package leaflets of European medicines. We show that fine-tuned transformers are able to generate realistic, multi-sentence text from data in the biomedical domain, yet have important limitations. We also release a new dataset (BioLeaflets) for benchmarking D2T generation models in the biomedical domain.",
  "full_text": "Proceedings of the 14th International Conference on Natural Language Generation (INLG), pages 364–370,\nAberdeen, Scotland, UK, 20-24 September 2021. ©2021 Association for Computational Linguistics\n364\nBiomedical Data-to-Text Generation via Fine-Tuning Transformers\nRuslan Yermakov\nDecision Science\n& Advanced Analytics\nBayer AG\nyermakovruslan@gmail.com\nNicholas Drago\nRegulatory Policy\nand Intelligence\nBayer AG\nAngelo Ziletti*\nDecision Science\n& Advanced Analytics\nBayer AG\nangelo.ziletti@bayer.com\nAbstract\nData-to-text (D2T) generation in the biomed-\nical domain is a promising - yet mostly unex-\nplored - ﬁeld of research. Here, we apply neu-\nral models for D2T generation to a real-world\ndataset consisting of package leaﬂets of Euro-\npean medicines. We show that ﬁne-tuned trans-\nformers are able to generate realistic, multi-\nsentence text from data in the biomedical do-\nmain, yet have important limitations. We also\nrelease a new dataset (BioLeaﬂets) for bench-\nmarking D2T generation models in the biomed-\nical domain.\n1 Introduction\nData-to-text (D2T) systems are attracting consid-\nerable interest due to their ability to automate\nthe time-consuming writing of data-driven reports.\nThere is a hitherto largely untapped potential for\ntext generation in the biomedical domain. Poten-\ntial applications of natural language generation of\npatient-friendly biomedical text include prepara-\ntion of the ﬁrst draft of package leaﬂets, patient\neducation materials, or direct-to-consumer promo-\ntional materials in countries where this is permitted.\nHere we focus on a D2T task aiming to generate\nﬂuent and fact-based descriptions from biomedical\ndata.\n2 Related Work\nRecently, neural D2T models have signiﬁcantly im-\nproved the quality of short text generation (usu-\nally one sentence long) from input data com-\npared to multi-stage pipelined or template-based\napproaches. Examples include biographies from\nWikipedia fact tables (Lebret et al., 2016), restau-\nrant descriptions from meaning representations\n(Novikova et al., 2017b), and basketball game sum-\nmaries from statistical tables (Wiseman et al.,\n2017). Still, neural D2T approaches have major\nchallenges, as outlined by Wiseman et al. (2017)\nand Parikh et al. (2020) which hinder their applica-\ntion to many real-world applications. These include\nhallucination effects (generated phrases not sup-\nported or contradictory to the source data), missing\nfacts (generated text does not include input informa-\ntion), intersentence incoherence, and repetitiveness\nin the generated text. Following the success of\nleveraging pre-trained large-scale language models\nfor a large variety of tasks, Kale and Rastogi (2020)\nﬁne-tuned T5 models (Raffel et al., 2020) for D2T\ngeneration. This strategy achieved state-of-the-art\nperformance on task-oriented dialogue (MultiWoz)\n(Budzianowski et al., 2018), tables-to-text (ToTTo)\n(Parikh et al., 2020) and graph-to-text (WebNLG)\n(Gardent et al., 2017).\nTo the best of our knowledge, recent neural\napproaches and transfer learning strategies have\nnot been applied to multi-sentence generation\nfrom input data, nor have they been applied in the\nbiomedical domain. Our contribution is two-fold:\nwe introduce a real-world biomedical dataset\nBioLeaﬂets, and demonstrate that transformers\ncan generate high-quality multi-sentence text from\ndata in the biomedical domain. The BioLeaﬂets\ndataset, ﬁne-tuned models, code, and gener-\nated samples are available at https://github.\ncom/bayer-science-for-a-better-life/\ndata2text-bioleaflets.\n3 The BioLeaﬂets Dataset\nWe introduce a new biomedical dataset for D2T\ngeneration - BioLeaﬂets, a corpus of 1336 package\nleaﬂets of medicines authorised in Europe, which\nwe obtain by scraping the European Medicines\nAgency (EMA) website. This dataset comprises\nthe large majority (∼ 90%) of medicinal products\nauthorised through the centralised procedure in Eu-\nrope as of January 2021.\nPackage leaﬂets are published for medicinal\nproducts approved in the European Union (EU).\nThey are included in the packaging of medicinal\n365\n(a)\nOriginal\nsection\ncontent\nnovonorm is an oral antidiabetic medicine containing repaglinide which helps your pancreas produce more\ninsulin and thereby lower your blood sugar (glucose). type 2 diabetes is a disease in which your pancreas\ndoes not make enough insulin to control the sugar in your blood or where your body does not respond normally\nto the insulin it produces. novonorm is used to control type 2 diabetes in adults as an add-on to diet and\nexercise: treatment is usually started if diet, exercise and weight reduction alone have not been able to control\n(or lower) your blood sugar. novonorm can also be given with metformin, another medicine for diabetes.\nnovonorm has been shown to lowerthe blood sugar, which helps to prevent complications from your diabetes.\n(b)\nInput:\nentities as a\nﬂat string\n<PRODUCT_NAME> novonorm </PRODUCT_NAME> <TREATMENT>\nan_oral_antidiabetic_medicine </TREATMENT> <GENERIC_NAME> repaglinide\n</GENERIC_NAME> <SYSTEM_ORGAN_SITE> pancreas </SYSTEM_ORGAN_SITE>\n<GENERIC_NAME> insulin </GENERIC_NAME> <TEST> your_blood_sugar </TEST>\n. . .<TEST> the_blood_sugar </TEST> <DX_NAME> complications </DX_NAME>\n<PROBLEM> your_diabetes </PROBLEM>\n(c)\nT5 gener-\nated section\nnovonorm is an oral antidiabetic medicine containing repaglinide which helps your pancreas produce more\ninsulin and thereby lower your blood sugar (glucose). type 2 diabetes is a disease in which your panccreases\ndoes not make enough insulin to control the sugar in your blood or where your body does not respond normally\nto the insulin it produces. novonourm is used to control type 2 diabetic patients who still have their diabetes\nand who are still unable to respond normally despite treatment, exercise and weight reduction, which have\nnot helped to control your blood glucose. there is also a test that novonorgm can be given in combination\nwith metformin, another medicine for diabetes. it is important that you continue to follow the advice on diet,\nexercising and diet that your nurse or doctor has given you.\n(d)\nBART gen-\nerated sec-\ntion\nnovondorm is an oral antidiabetic medicine containing repaglinide which helps your pancreas produce more\ninsulin and thereby lower your blood sugar (glucose). type 2 diabetes is a disease in which your pancrea does\nnot make enough insulin to control the sugar in your blood or where your body does not respond normally to\nthe insulin it produces. novonorm is used to treat type 2 diabetic in adults. treatment is usually started with\ndiet and exercise and weight reduction. your blood glucose may be increased when you start to take novonor\non its own or in combination with metformin. if you have diabetes, no\n(e)\nContent\nplanner\ngenerated\nsection\nnovonorm contains the active substance repaglinide which helps to lower your blood sugar (glucose). type\n2 diabetes is a disease where your body does not make enough insulin to control the sugar in your blood\nor where your body does not respond normally to the insulin it produces. repaglinide krka is used to control\ntype 2 diabetes in adults as type 2 diabetes. type 2 diabetes is also called non - insulin - dependent diabetes\nmellitus. type 2 diabetes is also a condition in which your body does not make enough insulin or the insulin\nthat your body produces does not work as well as it should. your body can also make too much sugar. when this\nhappens, sugar (glucose) builds up in the blood. this can lead to serious medical problems like heart disease,\nkidney disease, 2 and 2.\nTable 1: Example of text generations. Entities are highlighted in bold, typos are underlined, and hallucinations are\nshown in red.\nproducts and contain information to help patients\nuse the product safely and appropriately, under the\nguidance of their healthcare professional. Package\nleaﬂets are required to be written in a way that is\nclear and understandable (EU, 2001). Each docu-\nment contains six sections (see Table 2).The main\nchallenges of this dataset for D2T generation are\nmulti-sentence and multi-section target text, small\nsample size, specialized medical vocabulary and\nsyntax.\n3.1 Dataset Construction\nThe content of each section is not standardized,\nyet it is still well-structured. Thus, we identify\nsections via heuristics such as regular expressions\nand word overlap. The content of each section is\nlower-cased and tokenized by treating all special\ncharacters as separate tokens. Duplicates are also\nremoved. We randomly split the dataset into train-\ning (80%), development (10%), and test (10%) set.\nTable 2 summarizes dataset statistics.\n3.2 Dataset Annotations\nWe do not have annotations available for the pack-\nage leaﬂet text. To create the required input for\nD2T generation, we augment each document by\nleveraging named entity recognition (NER). Parikh\net al. (2020) indicated it is important that target\nsummaries contain information that can be inferred\nfrom the input data to avoid dataset-induced hallu-\ncinations. To this end, we combine two NER frame-\nworks: Amazon Comprehend Medical (ACM)\n(Bhatia et al., 2019) and Stanford Stanza (Qi\net al., 2020; Zhang et al., 2021). ACM and Stanza\nachieved entity micro-averaged test F1 of 85.5%\nand 88.13% respectively on the 2010 i2b2/V A clin-\nical dataset (Uzuner et al., 2011). We further lever-\nage ACM to detect medical conditions from ICD-\n10 (WHO, 2004) and medications from RxNorm.\nAdditionally, we treat all digits as entities, and add\nthe medicine name as ﬁrst entity. In case of overlap-\nping entities from different sources, we favor longer\nentities over shorter ones. As a result of the NER\n366\nSection type No.\nsamples\nAverage\nlength\n(characters)\nAverage\nlength\n(tokens)\nAverage no.\nentities per\nsection\nNo. unique\nentities\n1. What the product is and\nwhat it is used for 1 314 963 174 29 .3 9 641\n2. What you need to know\nbefore you take the product 1 309 4 560 849 127 .7 23 278\n3. How to take the product 1 313 2 300 458 50 .5 11 640\n4. Possible side effects 1 295 3 453 651 135 .2 27 945\n5. How to store the product 1 172 631 123 6 .3 2 041\n6. Content of the pack and\nother information 1 311 982 196 38 .4 9 932\nTable 2: BioLeaﬂets dataset statistics grouped by section type.\nprocess, we obtain 26 unique entity types. Exam-\nples are: problem: (’active chronic hepatitis’, ’mi-\ngraine pain’), system-organ-site: (’blood vessel’,\n’kidneys’, ’surrounding tissue’),treatment: (’rou-\ntine dental care’, ’a vaccination’, ’a chemotherapy\nmedicinal product’), or procedure: (’injections’,\n’spinal or epidural anaesthesia’, ’surgical interven-\ntion’, ’bone marrow or stem cell transplant’).\nBioLeaﬂets proposes a conditional generation\ntask: given an ordered set of entities as source, the\ngoal is to produce a multi-sentence section. Since\nonly the entities are provided as input, the struc-\ntured data is underspeciﬁed. A human without\nspecialized knowledge would likely be unable to\nproduce satisfactory text. However, we expect that\na labeling expert with profound knowledge of pack-\nage leaﬂets would be able to generate (with some\ndifﬁculty) satisfactory text in the large majority\nof cases. Successful generation thus requires the\nmodel to learn speciﬁc syntax, terminology, and\nwriting style from the corpus (e.g., via ﬁne-tuning).\n4 Experiments\nFollowing Kale and Rastogi (2020), we represent\nthe structured data (i.e., detected entities) as a ﬂat\nstring (linearization). The entities are kept in their\norder of appearance (Table1b). The models are\nthen trained to predict - starting from these entities\n- the corresponding published leaﬂet text.\nWe present baseline results on BioLeaﬂets\ndataset by employing the following state-of-the-\nart approaches:\n• Content Planner: two stages neural architec-\nture (content selection and planning) based\non LSTM (Puduppully et al., 2019). Since\nonly relevant entities are provided as input to\nthe model, we solely use the content planning\nstage (encoder-decoder architecture with an\nattention mechanism). We train one model for\neach section, and use the same hyperparame-\nters reported by Puduppully et al. (2019).\n• T5: a text-to-text transfer transformer model\n(Raffel et al., 2020). Kale and Rastogi (2020):\nshowed that T5 outperforms alternatives like\nBERT (Devlin et al., 2019) and GPT-2 (Rad-\nford et al., 2019). After hyperparameter\nsearch on the development dataset, the fol-\nlowing parameters (yielding the best ROUGE-\nL score (Lin, 2004)) are selected: constant\nlearning rate of 0.001, batch size of 32, 20\nepochs, greedy search as a decoding method.\n• BART: denoising autoencoder for pretraining\nsequence-to-sequence models with transform-\ners (Lewis et al., 2020). For computational\nreasons, we use the same hyperparameters as\nper T5 ﬁne-tuning.\n• BART and T5 with conditioning: we add the\npreﬁx “section n” (n = 1, . . .6) to the (lin-\nearized) input data. This explicitly gives the\nmodel information on the section number and\nthus enforces a conditioning on the section\ntype for text generation.\nBART and T5 ﬁne-tuning are performed via Hug-\ngingFace (Wolf et al., 2020).\n5 Evaluation\nTable 1 shows the generated text for one test sam-\nple as illustrative example. All generated text is\n367\nModel Word-overlap metrics Semantic equivalence metrics\nSacreBLEU ROUGE-L BERTScore BLEURT MoverScore-2l\nContent Planner 27.78 39.32 0.214 -0.072 0.591\nBART-base 8.76 ± 0.02 42.73 ± 0.11 0.370 ± 0.001 0.268 ± 0.002 0.609 ± 0.0004\nBART-base + cond 8.73 ± 0.02 42.60 ± 0.12 0.369 ± 0.001 0.268 ± 0.003 0.608 ± 0.0004\nT5-base 18.68 ± 0.07 47.22 ± 0.17 0.363 ± 0.001 0.255 ± 0.008 0.620 ± 0.0005\nT5-base + cond 18.63 ± 0.14 47.31 ± 0.22 0.364 ± 0.002 0.256 ± 0.006 0.621 ± 0.0008\nTable 3: Results on the BioLeaﬂets test set (averaged over all sections). T5 and BART models are ﬁne-tuned with\nseven different random seeds: average and standard deviation are reported. BLEURT-large-128 is used.\nModel Adequacy Hallucination\npresence\nEntity\ninclusion Fluency\nContent Planner annotator 1 4.1 ± 3.0 6.8 ± 3.2 4.8 ± 3.2 5.1 ± 3.3\nannotator 2 3.7 ± 2.6 6.4 ± 2.5 5.1 ± 2.5 5.4 ± 2.3\nBART-base annotator 1 7.5 ± 2.1 3.1 ± 2.6 7.4 ± 2.3 8.6 ± 1.8\nannotator 2 6.6 ± 2.2 3.3 ± 2.1 8.1 ± 1.8 8.0 ± 1.3\nT5-base annotator 1 7.8 ± 1.8 3.0 ± 2.4 7.6 ± 2.1 9.0 ± 1.4\nannotator 2 6.5 ± 2.2 3.5 ± 1.9 7.8 ± 1.7 8.2 ± 1.2\nTable 4: Human evaluation of test samples. Values on a scale from one to ten; average and standard deviation\nare reported. The higher the better for all quantities, expect for “Hallucination presence”. Adequacy estimates the\noverall generation quality, taking into consideration ﬂuency, amount of hallucination, and entities included in the\ngenerated text.\nmade available1. After a thorough inspection of\nthe samples, we conclude that generated text is\ngenerally ﬂuent and coherent. Text produced by\nT5 and BART is more ﬂuent, factually and gram-\nmatically correct than those by Content Planner.\nTable 3 illustrates the performance of state-of-the-\nart models quantiﬁed by automatic metrics. Word-\noverlap metrics such as (Sacre)BLUE (Post, 2018)\nand ROUGE (Lin, 2004) have been shown to per-\nform poorly in evaluation of natural language gen-\neration (Novikova et al., 2017a), and thus we re-\nport them here only for completeness. Conversely,\ncontextual embedding based metrics BERTScore\n(Zhang* et al., 2020), BLEURT (Sellam et al.,\n2020), and MoverScore-2 (Zhao et al., 2019) cor-\nrelate with human judgment on sentence-level and\nsystem-level evaluation. They adequately capture\nsemantic equivalence between generated and target\ntext as well as ﬂuency and overall quality. T5 and\nBART outperform Content Planner, as measured by\nBERTscore, BLEURT, and MoverScore-2. T5 and\nBART show similar performance. These results\nshow that transformer-based models and transfer\nlearning strategies achieve state-of-the-art perfor-\n1https://github.com/\nbayer-science-for-a-better-life/\ndata2text-bioleaflets\nmance on data-to-text tasks, generalizing the ﬁnd-\nings in Kale and Rastogi (2020) to multi-sentence\nand multi-section generation, biomedical text, and\nlow-data setting.\nTo conﬁrm these ﬁndings, human evaluation is\nperformed for Section 1 of the test set by two anno-\ntators. Results are shown in Table 4. Similarly to\nManning et al. (2020), we design a survey which in-\ncludes adequacy (estimate of overall quality), pres-\nence of hallucinations, entity inclusion, and ﬂuency.\nT5 and BART have similar performance, and they\nproduce more adequate text than Content Planner.\nT5 and BART performance is more stable across\nsamples (lower standard deviation). These conclu-\nsions coincide with the ones drawn from Table 3,\nthus conﬁrming the usefulness of semantic equiva-\nlence metrics for automatic evaluation of text gen-\neration.\nInterestingly, specifying the section type in the\ninput records (i.e., explicit conditioning) did not\nimprove model performances (Table 3). To ratio-\nnalize this result, we analyze T5 internal repre-\nsentations. Speciﬁcally, for each test sample, we\nextract the (average) last encoder hidden-state for\nboth pre-trained (not ﬁne-tuned) and ﬁne-tuned\nT5 (ﬁne-tuned on BioLeaﬂets but without explicit\n368\nFigure 1: Two-dimensional projections of T5 internal representations (average of the last encoder hidden-states) for\npre-trained (not ﬁne-tuned) (left) and ﬁne-tuned T5 model on BioLeaﬂets dataset (right). T5 implicitly learns to\ncondition on section type during ﬁne-tuning.\nconditioning). We then project these vectors into\ntwo-dimensions using the non-linear dimension-\nality reduction method UMAP (McInnes et al.,\n2020). The results are depicted in Fig. 1. In Fig. 1\n(right), we can identify six well-separated clusters,\nwhich correspond to (the internal representations of\nsamples belonging to) the six document sections in\nthe BioLeaﬂets dataset. Thus, after ﬁne-tuning, T5\nmaps input data belonging to different sections to\ndifferent parts of the internal representation space.\nThe cluster separation is much less pronounced for\nthe pre-trained (not-ﬁne-tuned) T5 model (Fig. 1,\nleft). This shows that during the ﬁne-tuning pro-\ncess, T5 implicitly learns to condition on section\ntype, thus learning to generate different sections,\neven despite the small dataset. Since condition-\ning is learned automatically, explicitly passing the\nsection type as input does not increase model per-\nformance.\n6 Error Analysis and Limitations\nAfter thorough qualitative evaluation of numerous\ngenerated samples, the following general issues\nappear:\n• Typos: Even though models largely utilize\nthe input entities correctly, typos appear in\ngenerated text by T5 and BART for out-of-\nvocabulary words, e.g. Table 1 (c, d). Content\nPlanner does not seem to have this problem.\n• Hallucinations are present for all models.\nLoss functions like maximum likelihood do\nnot directly minimize hallucinations, thus hin-\ndering consistent fact-based text generation.\n• Repetitiveness: Content Planner produce rep-\netitions (e.g. Table 1 (e)), whereas T5 and\nBART language models do not.\n• Difﬁculties in producing coherent long text:\nIn the BioLeaﬂets dataset, models perform\nwell in generating section 1, which is 962 char-\nacters long on average. However, the quality\nof section 4 ”Possible side effects” (3 453 char-\nacters long on average) generation is poor.\nPossible improvements to our work are: analysis\nof the impact of shufﬂing of entities for the input\ndata generation, introduction of loss functions that\nexplicitly favor factual correctness, usage of spe-\ncialized biomedical embeddings, inclusion of more\nsource input data (e.g. part-of-speech, dependency\ntag), generation of longer text (beyond the 512 to-\nkens generated here).\n7 Conclusion\nIn this study, we introduce a new biomedical\ndataset (BioLeaﬂets), which could serve as a bench-\nmark for biomedical text generation models. We\ndemonstrate the feasibility of generating coher-\nent multi-sentence biomedical text using patient-\nfriendly language, based on input consisting of\nbiomedical entities. These results show the poten-\ntial of text generation for real-world biomedical\napplications. Nevertheless, human evaluation is\nstill a required step to validate the generated sam-\nples. Application of the methodology and models\nused here to different sets of biomedical text (e.g.,\ngeneration of selected sections of clinical study\nreports) could be an area for further research.\n369\nReferences\nParminder Bhatia, Busra Celikkaya, Mohammed\nKhalilia, and Selvan Senthivel. 2019. Comprehend\nmedical: A named entity recognition and relation-\nship extraction web service. In 2019 18th IEEE In-\nternational Conference On Machine Learning And\nApplications (ICMLA), pages 1844–1851.\nPaweł Budzianowski, Tsung-Hsien Wen, Bo-Hsiang\nTseng, I ˜nigo Casanueva, Stefan Ultes, Osman Ra-\nmadan, and Milica Gaˇsi´c. 2018. MultiWOZ - a large-\nscale multi-domain Wizard-of-Oz dataset for task-\noriented dialogue modelling. In Proceedings of the\n2018 Conference on Empirical Methods in Natural\nLanguage Processing, pages 5016–5026, Brussels,\nBelgium. Association for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nEuropean Union EU. 2001. Directive 2001/83/ec of the\neuropean parliament and of the council of 6 november\n2001 on the community code relating to medicinal\nproducts for human use. Brussels, Belgium.\nClaire Gardent, Anastasia Shimorina, Shashi Narayan,\nand Laura Perez-Beltrachini. 2017. The WebNLG\nchallenge: Generating text from RDF data. In Pro-\nceedings of the 10th International Conference on\nNatural Language Generation, pages 124–133, San-\ntiago de Compostela, Spain. Association for Compu-\ntational Linguistics.\nMihir Kale and Abhinav Rastogi. 2020. Text-to-text\npre-training for data-to-text tasks. In Proceedings of\nthe 13th International Conference on Natural Lan-\nguage Generation, pages 97–102, Dublin, Ireland.\nAssociation for Computational Linguistics.\nR´emi Lebret, David Grangier, and Michael Auli. 2016.\nNeural text generation from structured data with ap-\nplication to the biography domain. In Proceedings of\nthe 2016 Conference on Empirical Methods in Natu-\nral Language Processing, pages 1203–1213, Austin,\nTexas. Association for Computational Linguistics.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVeselin Stoyanov, and Luke Zettlemoyer. 2020.\nBART: Denoising sequence-to-sequence pre-training\nfor natural language generation, translation, and com-\nprehension. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 7871–7880, Online. Association for Computa-\ntional Linguistics.\nChin-Yew Lin. 2004. ROUGE: A package for auto-\nmatic evaluation of summaries. In Text Summariza-\ntion Branches Out, pages 74–81, Barcelona, Spain.\nAssociation for Computational Linguistics.\nEmma Manning, Shira Wein, and Nathan Schneider.\n2020. A human evaluation of amr-to-english gen-\neration systems. In Proceedings of the 28th Inter-\nnational Conference on Computational Linguistics,\nCOLING 2020, Barcelona, Spain (Online), Decem-\nber 8-13, 2020, pages 4773–4786. International Com-\nmittee on Computational Linguistics.\nLeland McInnes, John Healy, and James Melville. 2020.\nUmap: Uniform manifold approximation and projec-\ntion for dimension reduction.\nJekaterina Novikova, Ond ˇrej Du ˇsek, Amanda Cer-\ncas Curry, and Verena Rieser. 2017a. Why we need\nnew evaluation metrics for NLG. In Proceedings of\nthe 2017 Conference on Empirical Methods in Natu-\nral Language Processing, pages 2241–2252, Copen-\nhagen, Denmark. Association for Computational Lin-\nguistics.\nJekaterina Novikova, Ondˇrej Duˇsek, and Verena Rieser.\n2017b. The E2E dataset: New challenges for end-\nto-end generation. In Proceedings of the 18th An-\nnual SIGdial Meeting on Discourse and Dialogue ,\npages 201–206, Saarbr¨ucken, Germany. Association\nfor Computational Linguistics.\nAnkur P Parikh, Xuezhi Wang, Sebastian Gehrmann,\nManaal Faruqui, Bhuwan Dhingra, Diyi Yang, and\nDipanjan Das. 2020. ToTTo: A controlled table-to-\ntext generation dataset. In Proceedings of the 2020\nConference on Empirical Methods in Natural Lan-\nguage Processing, EMNLP 2020, Online, November\n16-20, 2020, pages 1173–1186. Association for Com-\nputational Linguistics.\nMatt Post. 2018. A call for clarity in reporting BLEU\nscores. In Proceedings of the Third Conference on\nMachine Translation: Research Papers, pages 186–\n191, Brussels, Belgium. Association for Computa-\ntional Linguistics.\nRatish Puduppully, Li Dong, and Mirella Lapata. 2019.\nData-to-text generation with content selection and\nplanning. Proceedings of the AAAI Conference on\nArtiﬁcial Intelligence, 33(01):6908–6915.\nPeng Qi, Yuhao Zhang, Yuhui Zhang, Jason Bolton, and\nChristopher D. Manning. 2020. Stanza: A python\nnatural language processing toolkit for many human\nlanguages. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics:\nSystem Demonstrations, pages 101–108, Online. As-\nsociation for Computational Linguistics.\nAlec Radford, Jeff Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners.\n370\nColin Raffel, Noam Shazeer, Adam Roberts, Kather-\nine Lee, Sharan Narang, Michael Matena, Yanqi\nZhou, Wei Li, and Peter J. Liu. 2020. Exploring the\nlimits of transfer learning with a uniﬁed text-to-text\ntransformer. Journal of Machine Learning Research,\n21(140):1–67.\nThibault Sellam, Dipanjan Das, and Ankur Parikh. 2020.\nBLEURT: Learning robust metrics for text genera-\ntion. In Proceedings of the 58th Annual Meeting of\nthe Association for Computational Linguistics, pages\n7881–7892, Online. Association for Computational\nLinguistics.\n¨Ozlem Uzuner, Brett R South, Shuying Shen, and\nScott L DuVall. 2011. 2010 i2b2/V A challenge on\nconcepts, assertions, and relations in clinical text.\nJournal of the American Medical Informatics Associ-\nation, 18(5):552–556.\nWHO WHO. 2004. Icd-10 : international statistical\nclassiﬁcation of diseases and related health problems\n: tenth revision.\nSam Wiseman, Stuart Shieber, and Alexander Rush.\n2017. Challenges in data-to-document generation.\nIn Proceedings of the 2017 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n2253–2263, Copenhagen, Denmark. Association for\nComputational Linguistics.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art natural language processing.\nIn Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: System\nDemonstrations, pages 38–45, Online. Association\nfor Computational Linguistics.\nTianyi Zhang*, Varsha Kishore*, Felix Wu*, Kilian Q.\nWeinberger, and Yoav Artzi. 2020. Bertscore: Eval-\nuating text generation with bert. In International\nConference on Learning Representations.\nYuhao Zhang, Yuhui Zhang, Peng Qi, Christopher D\nManning, and Curtis P Langlotz. 2021. Biomedical\nand clinical English model packages for the Stanza\nPython NLP library. Journal of the American Medi-\ncal Informatics Association.\nWei Zhao, Maxime Peyrard, Fei Liu, Yang Gao, Chris-\ntian M. Meyer, and Steffen Eger. 2019. MoverScore:\nText generation evaluating with contextualized em-\nbeddings and earth mover distance. In Proceedings\nof the 2019 Conference on Empirical Methods in\nNatural Language Processing and the 9th Interna-\ntional Joint Conference on Natural Language Pro-\ncessing (EMNLP-IJCNLP), pages 563–578, Hong\nKong, China. Association for Computational Lin-\nguistics.",
  "topic": "Benchmarking",
  "concepts": [
    {
      "name": "Benchmarking",
      "score": 0.7878366708755493
    },
    {
      "name": "Computer science",
      "score": 0.6859767436981201
    },
    {
      "name": "Transformer",
      "score": 0.6713923215866089
    },
    {
      "name": "Sentence",
      "score": 0.5146909356117249
    },
    {
      "name": "Artificial intelligence",
      "score": 0.48987501859664917
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.48641204833984375
    },
    {
      "name": "Data modeling",
      "score": 0.45309287309646606
    },
    {
      "name": "Text generation",
      "score": 0.4307054281234741
    },
    {
      "name": "Field (mathematics)",
      "score": 0.4106607437133789
    },
    {
      "name": "Natural language processing",
      "score": 0.32458239793777466
    },
    {
      "name": "Engineering",
      "score": 0.14226946234703064
    },
    {
      "name": "Database",
      "score": 0.09810790419578552
    },
    {
      "name": "Electrical engineering",
      "score": 0.08058950304985046
    },
    {
      "name": "Voltage",
      "score": 0.07604050636291504
    },
    {
      "name": "Business",
      "score": 0.0
    },
    {
      "name": "Pure mathematics",
      "score": 0.0
    },
    {
      "name": "Marketing",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I67348948",
      "name": "Bayer (Germany)",
      "country": "DE"
    }
  ]
}