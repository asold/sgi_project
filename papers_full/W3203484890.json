{
    "title": "AuGPT: Auxiliary Tasks and Data Augmentation for End-To-End Dialogue with Pre-Trained Language Models",
    "url": "https://openalex.org/W3203484890",
    "year": 2021,
    "authors": [
        {
            "id": "https://openalex.org/A5038140870",
            "name": "Jonáš Kulhánek",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2474487673",
            "name": "Vojtech Hudecek",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4284391290",
            "name": "Tomáš Nekvinda",
            "affiliations": [
                "Charles University"
            ]
        },
        {
            "id": "https://openalex.org/A4225451068",
            "name": "Ondřej Dušek",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W3035068109",
        "https://openalex.org/W2983381967",
        "https://openalex.org/W3098826124",
        "https://openalex.org/W3098807778",
        "https://openalex.org/W2808093377",
        "https://openalex.org/W2964116568",
        "https://openalex.org/W2987395887",
        "https://openalex.org/W3156697766",
        "https://openalex.org/W2891732163",
        "https://openalex.org/W2917565325",
        "https://openalex.org/W2965373594",
        "https://openalex.org/W2763421725",
        "https://openalex.org/W2963491014",
        "https://openalex.org/W2971737394",
        "https://openalex.org/W3100110884",
        "https://openalex.org/W3034533785",
        "https://openalex.org/W2051593977",
        "https://openalex.org/W2965998974",
        "https://openalex.org/W3153104176",
        "https://openalex.org/W2963216553",
        "https://openalex.org/W2996287690",
        "https://openalex.org/W3033401723",
        "https://openalex.org/W2997771882",
        "https://openalex.org/W3005912270",
        "https://openalex.org/W2949888546",
        "https://openalex.org/W2889326796",
        "https://openalex.org/W2951796662",
        "https://openalex.org/W3030754432",
        "https://openalex.org/W2101105183",
        "https://openalex.org/W3016625483",
        "https://openalex.org/W2807186566",
        "https://openalex.org/W2970971581",
        "https://openalex.org/W2943737083",
        "https://openalex.org/W2988647680",
        "https://openalex.org/W3034634284",
        "https://openalex.org/W2951176429",
        "https://openalex.org/W3103753314",
        "https://openalex.org/W2963789888",
        "https://openalex.org/W3035301094",
        "https://openalex.org/W2995404354",
        "https://openalex.org/W2798914047",
        "https://openalex.org/W2626778328",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W2154652894",
        "https://openalex.org/W3114038149",
        "https://openalex.org/W1975244201",
        "https://openalex.org/W2908510526"
    ],
    "abstract": "Attention-based pre-trained language models such as GPT-2 brought considerable progress to end-to-end dialogue modelling. However, they also present considerable risks for task-oriented dialogue, such as lack of knowledge grounding or diversity. To address these issues, we introduce modified training objectives for language model finetuning, and we employ massive data augmentation via back-translation to increase the diversity of the training data. We further examine the possibilities of combining data from multiples sources to improve performance on the target dataset. We carefully evaluate our contributions with both human and automatic methods. Our model substantially outperforms the baseline on the MultiWOZ data and shows competitive performance with state of the art in both automatic and human evaluation.",
    "full_text": "Proceedings of the Third Workshop on Natural Language Processing for Conversational AI, pages 198–210\nNovember 10, 2021. ©2021 Association for Computational Linguistics\n198\nAuGPT: Auxiliary Tasks and Data Augmentation for End-To-End\nDialogue with Pre-Trained Language Models\nJonáš Kulhánek,1,2,3 Vojtˇech Hudeˇcek,1 Tomáš Nekvinda1 and Ondˇrej Dušek1\n1Charles University, Faculty of Mathematics and Physics, Prague, Czechia\n2Czech Technical University in Prague, Czech Institute of Informatics, Robotics and Cybernetics\n3Czech Technical University in Prague, Faculty of Electrical Engineering\njonas.kulhanek@cvut.cz, {hudecek,nekvinda,odusek}@ufal.mff.cuni.cz\nAbstract\nAttention-based pre-trained language models\nsuch as GPT-2 brought considerable progress\nto end-to-end dialogue modelling. However,\nthey also present considerable risks for task-\noriented dialogue, such as lack of knowledge\ngrounding or diversity. To address these is-\nsues, we introduce modiﬁed training objec-\ntives for language model ﬁnetuning, and we\nemploy massive data augmentation via back-\ntranslation to increase the diversity of the train-\ning data. We further examine the possibilities\nof combining data from multiples sources to\nimprove performance on the target dataset. We\ncarefully evaluate our contributions with both\nhuman and automatic methods. Our model\nsubstantially outperforms the baseline on the\nMultiWOZ data and shows competitive perfor-\nmance with state of the art in both automatic\nand human evaluation.\n1 Introduction\nUnlike traditional task-oriented systems based on\nmodularized pipelines (Young et al., 2013; Gao\net al., 2019), end-to-end dialogue systems inte-\ngrate nearly all functionality required to hold a\ndialogue into a single neural network (Wen et al.,\n2017; Eric et al., 2017; Lei et al., 2018), reduc-\ning error-propagation and data annotation require-\nments. While these systems are not yet ready for\nproduction use, they made considerable progress\nin recent years, especially with the advent of pre-\ntrained neural language models (LMs) (Devlin\net al., 2019; Radford et al., 2019; Zhang et al.,\n2020c). Systems such as GPT-2 ﬁnetuned by\nBudzianowski and Vuli ´c (2019) show that with\nan LM pre-trained on a large number of general-\ndomain dialogues without annotation, only small\namounts of data are required to perform well in a\ngiven task-oriented domain.\nOn the other hand, the pre-trained LMs run enor-\nmous risks. First, solely training for response\ngeneration may result in a lack of grounding for\nthe responses, where the LM hallucinates words\nwithout any relation to the database. This has\nbeen addressed by multi-task training and auxil-\niary training objectives (Peng et al., 2021) to an\nextent. Second, ﬁnetuning on small datasets may\nreduce response diversity and ﬂuency due to neural\nnetworks’ known propensity for catastrophic for-\ngetting (Greco et al., 2019) – the model overﬁts\nthe ﬁnetuning dataset too tightly, “forgetting” the\npre-trained language modeling capabilities.\nThis paper presents an end-to-end model for\nmulti-domain task-oriented response generation on\nthe MultiWOZ data (Budzianowski et al., 2018),1\nwhere we address the above problems with pre-\ntrained LMs. AuGPT is based on the GPT-2 LM\nand Peng et al. (2021)’s basic approach. Our con-\ntributions can be summarized as follows:\n• We introduce a new dialogue consistency classi-\nﬁcation task based on subtle changes to the dia-\nlogue state (instead of fully random resampling)\nused as an auxiliary training objective, and we\ndemonstrate its performance improvements.\n• We present a novel application of token un-\nlikelihood loss (Welleck et al., 2020) in task-\noriented dialogue to further improve diversity of\nour model’s responses.\n• We apply pre-training on additional datasets\nand massive data augmentation using back-\ntranslation via multiple languages (Sennrich\net al., 2016) and demonstrate that both markedly\nimprove task-oriented dialogue performance.\n• We compare our model to multiple baselines\non MultiWOZ in a corpus-based and simulated\nevaluation. We also include human evaluation\nresults from a shared task competition, as well\nas detailed manual error analysis.\nWe publish our augmented training data, source\ncode, and pre-trained models on GitHub.2\n1https://convlab.github.io\n2https://github.com/ufal/augpt\n199\n2 Related Work\nWhile the ﬁrst attempts to build generative end-\nto-end task-oriented systems mimicked the tradi-\ntional dialogue system components (Wen et al.,\n2017), the task was soon recast as a sequence pre-\ndiction problem in a two-stage setup. A sequence-\nto-sequence (seq2seq) model ﬁrst generates the be-\nlief state based on dialogue context, then generates\nthe system response based on the context and the\nbelief state (Sequicity; Lei et al., 2018).\nRecently, large-scale multi-domain task-oriented\ndatasets were proposed (Budzianowski et al., 2018;\nByrne et al., 2019; Rastogi et al., 2020). To ad-\ndress multiple domains, Zhang et al. (2020a) intro-\nduce the LABES-S2S model that – in addition to a\ntwo-stage seq2seq approach – models belief states\nas discrete latent variables. Zhang et al. (2020b)\npresent DAMD, a three-stage seq2seq architecture\nwhich explicitly decodes the system action. They\noptimize for multiple good actions given a single\nbelief state. Qin et al. (2020) investigate sharing of\ndomain knowledge and performance on unseen do-\nmains. Lubis et al. (2020)’s LA V A model employs\nreinforcement learning over latent system actions\ninitialized using a variational autoencoder.\nThe line of research closest to our work makes\nuse of large pre-trained LMs based on the trans-\nformer architecture (Vaswani et al., 2017) such as\nGPT-2 (Radford et al., 2019) or BERT (Devlin\net al., 2019). For example, Wu et al. (2020) pro-\npose ﬁnetuning BERT (Devlin et al., 2019) for task-\noriented dialogue, Zhang et al. (2020c) extended\nthe GPT-2 LM to model open-domain chit-chat.\nWe follow research initiated by Budzianowski\nand Vuli´c (2019), who use GPT-2 to model multi-\ndomain task-oriented dialogues. Recently, three\nsimilar modiﬁcations to their model were proposed,\nnamely SOLOIST (Peng et al., 2021), SimpleTOD\n(Hosseini-Asl et al., 2020), and the approach by\nHam et al. (2020). Our work extends these models\nand proposes a novel training approach and data\naugmentation strategies based on back-translation\n(Edunov et al., 2018; Federmann et al., 2019). Ear-\nlier works used a single pivot language (Jin et al.,\n2018; Einolghozati et al., 2019), whereas our work\napplies 10 languages to increase variability.\n3 Method\nThe task-oriented setting requires the dialogue sys-\ntem to respond adequately to the user’s input and\nfulﬁll its goal, e.g., booking a train or request-\ning restaurant details. The system must process\nthe user’s input, keep track of the belief state\n(user preferences regarding individual slots, i.e., in-\ndomain attributes) and generate a relevant response\nin natural language. It must also interact with a\ndatabase to incorporate external information into\nits responses (see Figure 1 for an example). Fol-\nlowing Budzianowski and Vuli´c (2019), we choose\nthe GPT-2 LM as our backbone and use the LM to\nmodel both the belief state and the response.\n3.1 Model Representation\nThe training instances for an LM-based task-\noriented dialogue system can be considered as tu-\nples (c, b, d, r), where c is the context (i.e., a con-\ncatenation of all previous utterances in the dialogue\n– both system’s and user’s),b is the system’s be-\nlief state (used to query the database), d are the\ndatabase results, and r is the system’s response.\nIn our case, the dialogue system handles mul-\ntiple domains and the belief state is a set of pairs\n(domain name, domain belief ), where the domain\nbelief is an assignment of values into slots, i.e.,\na set of pairs (slot name, value) (see Example 1).\nSimilarly, the database results d are a set of pairs\n(domain name, domain database results), where\nthe domain database results are an ordered list of\nentities returned by the database. We further deﬁne\nthe database result counts dc denoting the number\nof results in d for each domain.\nIdeally, we would like our system to model the\nprobability distribution over possible responses\nconditioned on the contextp(r|c). To simplify com-\nputation and model external database queries, we\nfactorize this distribution as follows:\np(r|c) =∑\nd\np(r|d, c)p(d|c)\n= ∑\nd\n∑\nb\np(r|d, b, c)p(d|b)p(b|c)\n= ∑\nb\np(r|Query(b), b, c)p(b|c),\n(1)\nwhere p(d|b) is a deterministic distribution over the\ndatabase results, and Query is a function returning\ndatabase results.\nUsing this factorization allows the model to pro-\ncess the context, query the database and generate\na response based on database results. However,\ngenerating responses directly would result in data\nsparsity issues with rare tokens (e.g., venue names\nor reference numbers). To maximally reuse the\ntraining samples, we choose to train our model\n200\nGPT-2 GPT-2\nBS: train {destination = Cambridge}\nDB: train 1113 matches \nBelief / response\nSystem action (BCE)\nUser intent (BCE)\nBelief prediction (CE) \nResponse prediction (CE)\n1\n3\nnone\nﬁnd_restaurant\nﬁnd_train\nbook_train\n01\nConsistency (BCE)\ngoodbye\nreq_more\nnotify_success\nnotify_failure\n01\n+\n-\ngreedy decoding\nCambridge\n =\ndestination\n{ } arrive by\n0\n1\n2\nAuxiliary\ntasks\nUser: Hi!, System: Hello sir., User: I'm looking for a train to Cambridge. \nsampling\ntrain\ntherehello\n0\n1\nThere are over 1,000 trains to [destination]. \nWhere will you be departing from? \nnucleus\n0\n1\nunlikelihood training\n01\npositive\nnegative\ntrain\ntherehello\nFigure 1: The architecture of AuGPT. The pipeline runs in two stages. First, a ﬁnetuned GPT-2 LM is used to\npredict a belief. Then the database results are obtained and everything is passed to the GPT-2 again to predict a\nﬁnal delexicalized response, along with possible auxiliary tasks (belief consistency, intent classiﬁcation, system\naction classiﬁcation). Unlikelihood loss is used for response prediction training.\non delexicalized responses denoted ¯r, where slot\nvalues are replaced with placeholders (Wen et al.,\n2015). During inference, the responses are lexical-\nized back deterministically using the belief state\nand the database results. We assume perfect lexi-\ncalization, i.e., always being able to lexicalize the\nresponse ¯r back based on d and b.3\nBoth the database lookup and the lexicalization\nare deterministic, and the delexicalized response\n¯r does not depend on the database results d, but\nonly on their counts dc. Therefore, the distribution\np(r|d, b, c) is equal to the distribution p(¯r|dc, b, c),\nand by maximizing its likelihood we are achieving\nthe goal of maximizing the likelihood of p(r|c).\nWe use the same language model ˆp to model\nthe belief state and to generate the delexicalized\nprediction. That is,\np(¯r|dc, b, c) ≈ ˆp(¯r|dc, b, c, θ) (2)\np(b|c) ≈ ˆp(b|/ 0, / 0, c, θ), (3)\nwhere we denote the model’s parameters asθ.\nIn the MultiWOZ dataset (Budzianowski et al.,\n2018; Eric et al., 2020, see Section 4), responses\nare delexicalized by replacing concrete values with\nplaceholder tokens of the form domain_slot. For\nbetter generalization across domains, we chose to\nonly use slot instead as responses rarely involve\nmore than one domain. We train our model to pre-\ndict the active domain by outputting it ﬁrst in the\n3We found in our experiments on the MultiWOZ data (see\nSection 4) that this assumption was almost always fulﬁlled.\nbelief state (remaining domains follow in lexico-\ngraphical order). The predicted active domain is\nthen used during lexicalization.4\nBelief state: train { leave at=15:30,\narrive by=17:15 },\nhotel { price range = cheap }\nDB: train 23 matches, hotel no match\nExample 1: String format for AuGPT’s belief state and\ndatabase result count.\nTo fully exploit natural language pre-training of\nour LM, we represent the belief state and database\nresult counts as strings containing as few special\ntokens as possible (see Example 1).\n3.2 Model Training\nAlthough parameters are shared for the belief state\npredictor and the delexicalized response predictor,\nthe training objectives differ slightly. We use cross-\nentropy loss for both; response prediction uses un-\nlikelihood loss (Welleck et al., 2020; Li et al., 2020)\nas an additional objective. Unlikelihood loss penal-\nizes repeated tokens, which helps the model avoid\nrepetitions and increases output diversity.\nTo help the model learn a better internal rep-\nresentation from the data, we employ additional\nauxiliary tasks. Similarly to Devlin et al. (2019)\n4A disadvantage of this approach is that we cannot deter-\nmine the active domain if the belief state is empty. However,\nin such a case the lexicalization would fail anyway, so the\nsystem’s performance is not affected by this decision.\n201\nand Peng et al. (2021), we train a binary classiﬁer\nto detect dialogue inconsistencies. In each training\nbatch, we corrupt half of the samples by randomly\napplying one or more of the following changes with\nthe same probability:\n1. We replace the belief state b with another be-\nlief state, sampled uniformly randomly from\nthe training data.\n2. We replace the delexicalized response¯r with a\ndifferent randomly chosen one. If this change\nis applied in combination with the ﬁrst one,\nthe delexicalized response and the belief state\nare taken from the same random sample.\n3. A different valid value is uniformly sampled\nfor each slot in the belief state. In this case,\nthe domain names and domain order are un-\nchanged (i.e., the active domain is the same).\nThe ﬁrst two changes are identical to Peng et al.\n(2021). The third one is a new one which we ﬁnd\nvery useful – it is much more challenging to detect\nif the belief state was changed when the domain\nstays the same. Consistency detection employs an\nafﬁne binary classiﬁer on top of last response token\nlogits, trained using binary cross-entropy (BCE).\nWe also experiment with additional two clas-\nsiﬁers predicting the user intent and the system\naction. These are implemented as two fully-\nconnected layers attached to the last context token\nand the last database result token logits, respec-\ntively. However, based on our experimental results\n(see Table 4), we decided not to use these tasks in\nthe ﬁnal model.\nWe train the whole pipeline by optimizing the\nnon-weighted sum of individual component losses,\ni.e., cross-entropy for belief state and response pre-\ndiction, unlikelihood loss for the response, and\nBCE for consistency detection.\n3.3 Response Generation\nFor each user input, the system goes through sev-\neral stages (see Figure 1): (1) Previous dialogue\ncontext is passed to the LM, which greedily gener-\nates the string representation of the belief state. (2)\nThe belief state is parsed and passed to the database\nhandler. (3) The database handler returns a set of\nresults for each domain. (4) A string representation\nof database result counts is created (see Example 1).\n(5) The context, belief state and database results are\nconcatenated and passed again to the LM. We use\nnucleus sampling (Holtzman et al., 2020) to gener-\nate the delexicalized response.5 (6) Placeholders in\nthe delexicalized response are replaced by values\nfrom the database results and the belief state.\n3.4 Data Augmentation\nFollowing its successful usage in other NLP tasks,\n(Konstas et al., 2017; Elder et al., 2020), we exper-\niment with data augmentation using paraphrases.\nIn our setup, we generate multiple paraphrases for\neach training utterance and use them to augment\nthe training data. This way, we effectively increase\nthe variability of the data.\nVarious data-driven approaches for paraphrasing\nwere proposed, the majority of them corpora-based\n(Madnani and Dorr, 2010). Recently, machine\ntranslation systems showed strong performance\nin generating paraphrases using back-translation\n(Sennrich et al., 2016; Edunov et al., 2018; Fed-\nermann et al., 2019), i.e., translating an English\ntext into an intermediate language and then trans-\nlating the result back into English. We use two\ndifferent Transformer-based machine translation\nsystems to paraphrase our data. We used Edunov\net al. (2018)’s system with French and the system\nof Machá ˇcek et al. (2020); Zouhar et al. (2021)\nwith additional 40 pivot languages. Based on em-\npirical analysis of translation quality, we chose 10\npivot languages for our data – we obtain 10 differ-\nent paraphrases for each input utterance. 6 When\ntraining, we choose the input user utterance uni-\nformly at random from the set of all 10+1 variants\nof the utterance (backtranslation outputs and the\noriginal one).\n4 Experiments\n4.1 Datasets\nAs our primary dataset, we use MultiWOZ 2.1, a\nde-noised version of MultiWOZ 2.0 (Budzianowski\net al., 2018). We also used the 2.0 version to\ncompare to previous works. The dataset contains\n7 distinct domains (all related to tourist informa-\ntion, e.g., hotels, restaurants) and 10,438 dialogues,\n7,032 of which are multi-domain.\nWe experiment with pre-training our model on\nadditional datasets. For the pre-training phase, we\nuse Taskmaster-1 (Byrne et al., 2019) and Schema-\n5We found nucleus sampling useful for generating the\nresponse since it increases diversity, but we prefer greedy\ndecoding for the belief state with a ﬁxed structure.\n6Pivot languages used: Albanian, Arabic, Bulgarian,\nBosnian, French, German, Russian, Spanish, Slovak, Swedish.\n202\nMultiWOZ 2.0 MultiWOZ 2.1\nmethod inform success BLEU inform success BLEU\nHuman 91.0 82.7 – 86.3 79.1 –\nAuGPT 83.1 70.1 17.2 83.5 67.3 17.2\nSOLOIST (Peng et al., 2021) 85.5 72.9 16.5 – – –\nSimpleTOD (Hosseini-Asl et al., 2020) 84.4 70.1 15.1 85.0 70.5 15.2\nLABES-S2S (Zhang et al., 2020a) – – – 78.1 67.1 18.3\nDAMD (Zhang et al., 2020b) 76.3 60.4 16.6 – – –\nMD-Sequicity (Zhang et al., 2020b) 86.6 71.6 16.8 – – –\nLA V A (Lubis et al., 2020) 91.8 81.8 12.0 – – –\nTable 1: Comparison with previous works on the MultiWOZ dataset (see Section 4.4 for a description of the\nmetrics). MD-Sequicity is a variant of Lei et al. (2018)’s model, extended for a multi-domain setting.\ninform turn\nmethod complete success book P R F1 succ all\nAuGPT 89.4 60.1 85.7 64.5 82.1 70.3 12.7 14.6\nDAMD (Zhang et al., 2020b) 39.5 34.3 51.4 60.4 59.8 56.3 15.8 29.8\nSequicity (Lei et al., 2018) 23.1 9.8 4.1 33.0 32.7 29.9 12.2 32.6\nTable 2: ConvLab evaluation comparison with other works (see Section 4.5 for a description of the metrics).\nGuided Dialogue (Rastogi et al., 2020). 7 Both\nTaskmaster-1 and Schema-Guided Dialogue are\nmulti-domain, task-oriented, large dialogue cor-\npora consisting of 12,215 and 22,825 dialogues,\nrespectively. Taskmaster-1 was obtained using the\nWizard-of-Oz and self-dialogue methods, while the\ncollection of Schema-Guided Dialogue is some-\nwhat artiﬁcial – humans are only employed to para-\nphrase machine-generated utterances.\n4.2 Data Preprocessing\nAlthough the MultiWOZ 2.1 dataset was collected\nby humans, it contains a lot of inconsistencies. We\nhypothesize that when using only clean samples\nwhich are consistent with the database, the bene-\nﬁt of using higher quality training data outweighs\nthe decrease in the number of training samples.\nThis claim is further supported by experiments (see\nSection 6). To ﬁlter the training data, we choose\nonly those dialogues where the annotated dialogue\ngoal corresponds with the turn-level annotated data.\nWhen using the clean samples, we omit about 30%\nof the training data.\nTo effectively combine all our datasets, we\nuniﬁed the data ontologies. Since the datasets\nuse different naming conventions (e.g., leaveAt\nvs. leave_at) and different domain and slot\nnames to describe the same concepts (e.g.,\nrestaurant-food vs. restaurant-type), we\n7There are also other large-sized task-oriented datasets\nsuch as MetalWOZ (Lee et al., 2019), however, their annota-\ntion is not detailed enough for our setup.\nmanually designed a mapping between domain and\nslot names. Notably, we decided to rename some\nslots so they use natural language tokens, as we\nbase our model on the GPT-2 LM which is pre-\ntrained on natural language texts (e.g. “leaveAt”\n→“leave at”). Our ﬁnal ontology that uniﬁes all\nthree datasets contains 22 domains and 135 slots.\nWe use our own implementation of delexicaliza-\ntion, which directly produces our belief state string\nrepresentation (see Section 3.1 and Example 1).\n4.3 Training Details\nWe implement our model in PyTorch (Paszke et al.,\n2019), based on GPT-2- small. It uses 12 layers\nwith a size of 768. For all auxiliary tasks, we use\na dropout of 0.1 with label smoothing 0.1. We\nuse the AdamW optimizer (Loshchilov and Hutter,\n2019). The ﬁnetuning runs for 8 epochs on the\nMultiWOZ 2.1 data when all the training examples\nare used, and for the same number of minibatches\nwhen using only clean samples. The training takes\nless than one day when using 4 GPUs.\n4.4 Corpus-based Evaluation\nTo compare with previous results on MultiWOZ,\nwe evaluate the model performance with a set of\ncorpus-based intrinsic metrics on both versions of\nthe data. For MultiWOZ 2.0, we use the origi-\nnal delexicalization used by compared baselines\n(Peng et al., 2021; Hosseini-Asl et al., 2020; Zhang\net al., 2020b). For MultiWOZ 2.1, we use our own\ndelexicalization. We employ the original evalua-\n203\nAverage Success Success NLU Response\nMethod Success w/ DB w/o DB score appropriateness Turns\nBaseline 69.6 56.8 82.4 4.34 4.18 18.5\nWinner 74.8 70.2 79.4 4.54 4.47 18.5\nOur submission 72.3 62.0 82.6 4.53 4.41 17.1\nTable 3: Human evaluation results obtained during the DSTC9 shared task using Amazon Mechanical Turk. Note\nthat only 4 out of 10 submissions outperformed the Baseline according to the average success metric.\ntion scheme by Budzianowski et al. (2018), which\nprovides two metrics – the inform rate and the suc-\ncess rate. The inform rate is the percentage of\ndialogues in which the system mentioned a name\nor ID of an entity which does not contradict the\ncurrent dialogue state and the user’s goal, whereas\nthe success rate is the percentage of dialogues in\nwhich the system outputted all the requested infor-\nmation. Moreover, we compute BLEU (Papineni\net al., 2002) between the generated system utter-\nances and the ground truth to get an approximation\nof the output ﬂuency.\n4.5 ConvLab 2 Evaluation\nWe use the ConvLab 2 platform (Zhu et al., 2020)\nfor automatic evaluation with a simulated user\nagent. We run the evaluation component 1,000\ntimes, i.e. on 1,000 simulated conversations. The\nagent mimics user behavior, interacts with the sys-\ntem under evaluation, and computes multiple met-\nrics: The complete rate reﬂects the ratio of dia-\nlogues that are completed, i.e. all the user requests\nhave been met. The success rate computes the per-\ncentage of dialogues which are successful, meaning\nthe system captures correct informed entities and\nprovides a valid booking if requested. Finally, the\nbook rate is the proportion of dialogues where the\nsystem was able to book the correct entity (hotel,\nrestaurant, train) if it was asked to. We also com-\npute precision, recalland F1 score for the informed\nentities and the average number of turns in the dia-\nlogue.\n4.6 Human Evaluation and Error Analysis\nThanks to our participation in the DSTC9 task-\noriented dialogue shared task (Gunasekara et al.,\n2020; Li et al., 2021), a variant of our model (with-\nout pre-training on additional dialogue datasets,\nsee Table 4) was selected for evaluation by human\njudges on the Amazon Mechanical Turk platform.8\n8The selection was done based on ConvLab 2 performance,\nbut probably used a different version of the tool and thus\narrived at different results – the chosen variant is not the best\nThe judges communicated with the agent in natu-\nral language and rated the system afterward with\nrespect to the success/failure of the dialogue, lan-\nguage understanding score, and response appro-\npriateness. Information provided by the system\nwas additionally checked for consistency with the\ndatabase, and the average of success rates given by\nthe judges and by database grounding is used as\nthe main metric.\nIn addition to the crowdsourced evaluation, we\nperform a detailed in-house error analysis based\non human interactions with our ﬁnal system. Ex-\npert annotators followed randomly chosen dialogue\ngoals accompanying the MultiWOZ test set and\nrecorded any incorrect system behavior.\n5 Results\nWe ﬁrst discuss quantitative results for both corpus-\nbased and crowdsourced human evaluation, then\ninclude a qualitative analysis of the model behavior.\n5.1 Corpus-based Evaluation on MultiWOZ\nTable 1 shows a comparison between our meth-\nods and current state-of-the-art systems (cf. Sec-\ntion 2). Since some of the compared methods do\nnot provide results with on MultiWOZ 2.1, we re-\nport results on both MultiWOZ 2.0 and MultiWOZ\n2.1. As we can see, AuGPT compares favorably\nto other approaches. The chosen variant of our\nmodel is not the best-scoring variant on corpus-\nbased metrics (see Table 4). It was chosen based\non the ConvLab evaluation, which may not be op-\ntimal for corpus-based evaluation. LABES-S2S\nproduces higher BLEU scores, which would indi-\ncate a better ﬂuency of the model, but scores lower\non inform and success rates. LA V A, SOLOIST,\nSimpleTOD, and MD-Sequicity, on the other hand,\nprovide slightly higher inform and success scores\nwhile doing worse in terms of ﬂuency.\nTable 2 shows a comparison with two other mod-\nels in the ConvLab evaluation scheme with a sim-\nulated user. The compared systems were chosen\none according to our own measurements.\n204\n[...]\nuser: I want to make a booking at sitar tandoori\nbelief: restaurant {name = sitar tandoori}\ntrain {arrive by = 18:00, day = sunday, depar-\nture = cambridge, destination = london liverpool\nstreet, people = 1}\nsystem: What day would you like the booking for?\nuser: the same day, 13:30\nbelief: restaurant {day = sunday, name = sitar tandoori,\npeople = 1, time = 13:30}\ntrain {arrive by = 18:00, day = sunday, depar-\nture = cambridge, destination = london liverpool\nstreet, people = 1}\nsystem: Booking was successful. The table will be re-\nserved for 15 minutes. Reference number is:\n00000200.\nExample 2: A dialogue where the system did not ask\nfor necessary information. The user previously booked\na train trip for one person (cf. the belief state in the ﬁrst\nturn shown). When they went on to book a restaurant,\nthe system took over the number of persons from the\ntrain ride and did not ask again.\nbecause they both implement fully trainable end-to-\nend methods. Our system outperforms both com-\npared systems by a wide margin. Our model is\nable to perform well not just in a single-turn re-\nsponse generation scenario, but over the course of\nthe whole dialogue. As the example of DAMD\nshows, this is not always guaranteed.\n5.2 Human Evaluation\nWe show the DSTC9 human evaluation results in\nTable 3. Our model outperformed the baseline on\nthe main average success metric (along with only\n3 other submissions out of 10). We did not match\nthe winning submission on average success, but\nwe achieved the best overall success rate based on\nhuman judgments (without checking consistency\nwith the database). This suggests that the main\ndrawback of our model lies in database grounding.\nThis could have been caused by our new delexical-\nization (Section 4.2). Finally, our model needed the\nsmallest number of turns on average to complete\nthe dialogues.\nNote that the model variant chosen for human\nevaluation did not include pre-training on addi-\ntional data (cf. Section 4.6 and Footnote 8), which\ncould improve performance in human evaluation.\n5.3 Error Analysis\nOur expert annotators evaluated 130 dialogues in\ntotal, 50 of which contained at least one error. How-\never, in most cases, the system was able to recover\nfrom the errors, resulting in an overall success rate\nuser : I am looking for a cheap chinse restaurant.\nbelief: restaurant {food = chinese, price range = cheap}\nsystem: I have 4 cheap chinese restaurants. What area of\ntown would you like to dine in?\nuser: downtown\nbelief: restaurant {area = centre, food = chinese, price\nrange = cheap}\nsystem: I have 3 cheap chinese restaurants in the centre.\nWould you like to book at Charlie Chan?\n...\nExample 3: A snippet from a challenging but suc-\ncessful dialogue. The system deals with input noise\n(“chinse”) as well as with paraphrases (“downtown”).\nof 86.9% (i.e., 17 unsuccessful dialogues). The\npurpose of this analysis was to identify different\ntypes of errors occurring during full dialogues.\nBy far the most common error (21 counts) were\nhallucinated values , i.e., lack of grounding for\nsome of the information provided (see the end of\nExample 2). Another frequent error type is missing\ninformation (5 counts), i.e., not asking for informa-\ntion that is required (and e.g. reusing information\nfrom a different domain without user conﬁrmation).\nExample 2 also demonstrates another common er-\nror type, which is bad domain (4 counts). Here,\nthe system does not react to the user’s request for a\ndifferent search (hotels instead of attractions in the\nexample). This might be caused by a less frequent\nwording of the request in the given context, and\nusually gets resolved by rephrasing the request.\nThe analysis also found many examples of cor-\nrect system behavior in non-trivial cases. As il-\nlustrated in Example 3, the model is able to deal\nwith paraphrases and is robust to a certain amount\nof noise in the data. Speciﬁcally, it handles typos,\nvarious time formats, etc. Interaction between do-\nmains is also successful in most cases – the system\nis able to resolve references to another domain’s be-\nlief state (e.g., make a booking for the same group\nof people as done before in a different venue).\n6 Ablation Study\nWe tested many variants of our method with differ-\nent combinations of components to evaluate their\ncontributions. The results are presented in Table 4.\nNamely, we are interested in the following compo-\nnents: (1) unlikelihood loss, (2) auxiliary tasks, (3)\ndata augmentation, (4) modiﬁed consistency task\nand (5) unclean data ﬁltering.\nWe can see that all proposed contributions which\nare a part of our ﬁnal system, except for the un-\nlikelihood training, have a positive effect on the\n205\nMultiWOZ 2.1 ConvLab 2\ninform\nmethod inf suc BLEU comp suc book P R F1 turns\nAuGPT 83.5 67.3 17.2 89.4 60.1 85.7 64.5 82.1 70.3 14.6\nw/o. unlikelihood 84.1 66.9 17.1 89.2 59.3 90.8 63.9 81.6 69.5 14.6\nw/o. clean 81.9 64.0 15.8 85.0 57.7 85.6 65.6 79.1 69.6 14.5\nw/o. unlikelihood, w/o. clean 86.5 69.1 17.5 85.9 58.4 81.3 62.2 79.8 67.5 14.1\nw. all auxiliary 83.1 66.2 17.0 88.7 59.2 86.0 64.6 81.1 69.9 14.4\nw/o. pre-training 81.0 62.7 15.1 88.1 59.8 83.7 68.1 80.9 72.1 15.6\nw/o. back-translations 79.8 61.7 15.2 88.9 58.2 87.4 68.0 81.6 72.2 14.9\nw. old consistency 81.4 65.8 17.0 85.5 57.8 86.0 65.2 80.0 69.8 14.6\nw/o. consistency 81.9 64.5 16.3 86.4 57.1 84.1 66.3 81.2 70.9 14.6\nTable 4: Ablation study (inf = inform, suc = success, book = book rate; see Section 4.4). The model version with the\nbest ConvLab 2 success rate is chosen as our best model. Variants are denoted with their respective modiﬁcations\ncompared to the default: “w/o. unlikelihood” = unlikelihood loss was not used; “w/o. clean” uses all training\nsamples as opposed to using only the ones consistent with the database; “w/o. pre-training” = Taskmaster-1 and\nSchema-Guided datasets were not used for training (this variant was selected for human evaluation); “all auxiliary”\n= using two additional auxiliary tasks (see the Method section); “w/o. consistency” = dialogue consistency task is\nnot used; “old consistency” refers to the consistency task by Peng et al. (2021) (see the Section 3.2).\nsystem performance. In the ConvLab evaluation,\nour ﬁnal system performs best. Removing either\npre-training or back-translations decreases BLEU,\ninform and success rates substantially. Further-\nmore, we notice the positive effect of using our\nimproved consistency detection task over the one\nused in SOLOIST (Peng et al., 2021), which in turn\nscores better than no consistency detection.\nTraining on all data as opposed to using only\n“clean” samples clearly reduces performance. On\nthe other hand, unlikelihood training improves per-\nformance only in ConvLab while causing a per-\nformance drop in corpus-based metrics. This can\nbe caused by the fact that the unlikelihood train-\ning promotes diversity and reduces repetitions on\nthe token level, and thus does not play well with\ncorpus-based evaluation. We did not notice any\nincrease in performance when the user intent pre-\ndiction and system action prediction auxiliary tasks\nwere used (cf. Section 3.2). The reason for this\nbehavior could be that the model learns to repre-\nsent the actions well enough implicitly, without\nthe need for these additional objectives. Therefore,\nthese tasks are not a part of our ﬁnal model.\n7 Conclusions & Future Work\nWe present a dialogue modeling pipeline based on\nthe pre-trained GPT-2 language model. AuGPT\nuses modiﬁed training objectives and employs data\naugmentation to increase the diversity of gener-\nated utterances. Our experiments show that the\nproposed approach outperforms baselines and is\ncompetitive with state of the art on the MultiWOZ\ndataset. We also run a series of ablation exper-\niments to assess the individual contributions of\nthe modiﬁcations. According to our detailed abla-\ntion study, training data augmentation using back-\ntranslation via multiple languages and a modiﬁed\nauxiliary training objective for dialogue consis-\ntency detection are the features that contribute most\nto our system’s performance. Additionally, we per-\nform a qualitative analysis of the outputs to give a\nbetter insight into our model behavior.\nIn the future, we plan to construct a latent repre-\nsentation of the belief state and optimize it jointly\nwith the language model. We will replace the deter-\nministic lexicalization with a trainable alternative,\nand possibly even integrate the database module\ninto the model. To improve the transfer to new do-\nmains, we will learn a domain embedding and opti-\nmize it jointly with the model, unifying all datasets.\nAcknowledgments\nThis work was supported by the Charles Univer-\nsity GAUK grant No. 302120, the SVV project\nNo. 260575, and the Charles University project\nPRIMUS/19/SCI/10. Jonáš Kulhánek was sup-\nported by the European Regional Development\nFund under the project Robotics for Industry 4.0\n(reg. no. CZ.02.1.01/0.0/0.0/15_003/0000470). Ad-\nditional computational resources were supplied\nby the project “e-Infrastruktura CZ” (e-INFRA\nLM2018140) provided within the program Projects\nof Large Research, Development and Innovations\nInfrastructures.\n206\nReferences\nPaweł Budzianowski and Ivan Vuli´c. 2019. Hello, it’s\nGPT-2 - how can I help you? Towards the use of pre-\ntrained language models for task-oriented dialogue\nsystems. In Proceedings of the 3rd Workshop on\nNeural Generation and Translation , pages 15–22,\nHong Kong.\nPaweł Budzianowski, Tsung-Hsien Wen, Bo-Hsiang\nTseng, Iñigo Casanueva, Stefan Ultes, Osman Ra-\nmadan, and Milica Gaši ´c. 2018. MultiWOZ - a\nlarge-scale multi-domain Wizard-of-Oz dataset for\ntask-oriented dialogue modelling. In Proceedings of\nthe 2018 Conference on Empirical Methods in Nat-\nural Language Processing, pages 5016–5026, Brus-\nsels, Belgium.\nBill Byrne, Karthik Krishnamoorthi, Chinnadhurai\nSankar, Arvind Neelakantan, Ben Goodrich, Daniel\nDuckworth, Semih Yavuz, Amit Dubey, Kyu-Young\nKim, and Andy Cedilnik. 2019. Taskmaster-1: To-\nward a realistic and diverse dialog dataset. In\nProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP) , pages 4516–\n4525, Hong Kong, China.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota.\nSergey Edunov, Myle Ott, Michael Auli, and David\nGrangier. 2018. Understanding back-translation at\nscale. In Proceedings of the 2018 Conference on\nEmpirical Methods in Natural Language Processing,\npages 489–500, Brussels, Belgium.\nArash Einolghozati, Sonal Gupta, Mrinal Mohit, and\nRushin Shah. 2019. Improving robustness of task\noriented dialog systems. In 3rd Conversational AI\nWorkshop at 33rd Conference on Neural Information\nProcessing Systems (NeurIPS 2019).\nHenry Elder, Robert Burke, Alexander O’Connor, and\nJennifer Foster. 2020. Shape of synth to come: Why\nwe should use synthetic data for English surface re-\nalization. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 7465–7471, Online.\nMihail Eric, Rahul Goel, Shachi Paul, Abhishek Sethi,\nSanchit Agarwal, Shuyang Gao, Adarsh Kumar,\nAnuj Goyal, Peter Ku, and Dilek Hakkani-Tur. 2020.\nMultiWOZ 2.1: A consolidated multi-domain dia-\nlogue dataset with state corrections and state track-\ning baselines. In Proceedings of the 12th Language\nResources and Evaluation Conference , pages 422–\n428, Marseille, France.\nMihail Eric, Lakshmi Krishnan, Francois Charette, and\nChristopher D. Manning. 2017. Key-value retrieval\nnetworks for task-oriented dialogue. In Proceedings\nof the 18th Annual SIGdial Meeting on Discourse\nand Dialogue, pages 37–49, Saarbrücken, Germany.\nChristian Federmann, Oussama Elachqar, and Chris\nQuirk. 2019. Multilingual whispers: Generating\nparaphrases with translation. In Proceedings of\nthe 5th Workshop on Noisy User-generated Text (W-\nNUT 2019), pages 17–26, Hong Kong, China.\nJianfeng Gao, Michel Galley, and Lihong Li. 2019.\nNeural approaches to conversational AI: Question\nanswering, task-oriented dialogues and social chat-\nbots. volume 13 of Foundations and Trends in Infor-\nmation Retrieval.\nClaudio Greco, Barbara Plank, Raquel Fernández, and\nRaffaella Bernardi. 2019. Psycholinguistics meets\ncontinual learning: Measuring catastrophic forget-\nting in visual question answering. In Proceedings of\nthe 57th Annual Meeting of the Association for Com-\nputational Linguistics, pages 3601–3605, Florence,\nItaly.\nChulaka Gunasekara, Seokhwan Kim, Luis Fernando\nD’Haro, Abhinav Rastogi, Yun-Nung Chen, Mi-\nhail Eric, Behnam Hedayatnia, Karthik Gopalakrish-\nnan, Yang Liu, Chao-Wei Huang, Dilek Hakkani-\nTür, Jinchao Li, Qi Zhu, Lingxiao Luo, Lars Li-\nden, Kaili Huang, Shahin Shayandeh, Runze Liang,\nBaolin Peng, Zheng Zhang, Swadheen Shukla, Min-\nlie Huang, Jianfeng Gao, Shikib Mehri, Yulan Feng,\nCarla Gordon, Seyed Hossein Alavi, David Traum,\nMaxine Eskenazi, Ahmad Beirami, Eunjoon, Cho,\nPaul A. Crook, Ankita De, Alborz Geramifard,\nSatwik Kottur, Seungwhan Moon, Shivani Poddar,\nand Rajen Subba. 2020. Overview of the ninth di-\nalog system technology challenge: DSTC9. arXiv\npreprint arXiv:2011.06486.\nDonghoon Ham, Jeong-Gwan Lee, Youngsoo Jang,\nand Kee-Eung Kim. 2020. End-to-end neural\npipeline for goal-oriented dialogue systems using\nGPT-2. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 583–592, Online.\nAri Holtzman, Jan Buys, Li Du, Maxwell Forbes, and\nYejin Choi. 2020. The curious case of neural text\ndegeneration. In 8th International Conference on\nLearning Representations, ICLR 2020, Addis Ababa,\nEthiopia, April 26-30, 2020.\nEhsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu,\nSemih Yavuz, and Richard Socher. 2020. A sim-\nple language model for task-oriented dialogue. In\nAdvances in Neural Information Processing Systems\n33: Annual Conference on Neural Information Pro-\ncessing Systems 2020, NeurIPS 2020, December 6-\n12, 2020, virtual.\nLifeng Jin, David King, Amad Hussein, Michael White,\nand Douglas Danforth. 2018. Using paraphrasing\n207\nand memory-augmented models to combat data spar-\nsity in question interpretation with a virtual patient\ndialogue system. In Proceedings of the Thirteenth\nWorkshop on Innovative Use of NLP for Building Ed-\nucational Applications, pages 13–23, New Orleans,\nLouisiana.\nIoannis Konstas, Srinivasan Iyer, Mark Yatskar, Yejin\nChoi, and Luke Zettlemoyer. 2017. Neural AMR:\nSequence-to-sequence models for parsing and gener-\nation. In Proceedings of the 55th Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers) , pages 146–157, Vancouver,\nCanada.\nSungjin Lee, Hannes Schulz, Adam Atkinson, Jianfeng\nGao, Kaheer Suleman, Layla El Asri, Mahmoud\nAdada, Minlie Huang, Shikhar Sharma, Wendy Tay,\nand Xiujun Li. 2019. Multi-domain task-completion\ndialog challenge.\nWenqiang Lei, Xisen Jin, Min-Yen Kan, Zhaochun\nRen, Xiangnan He, and Dawei Yin. 2018. Sequicity:\nSimplifying task-oriented dialogue systems with sin-\ngle sequence-to-sequence architectures. In Proceed-\nings of the 56th Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Pa-\npers), pages 1437–1447, Melbourne, Australia.\nJinchao Li, Qi Zhu, Lingxiao Luo, Lars Liden, Kaili\nHuang, Shahin Shayandeh, Runze Liang, Baolin\nPeng, Zheng Zhang, Swadheen Shukla, Ryuichi\nTakanobu, Minlie Huang, and Jianfeng Gao. 2021.\nMulti-domain task completion dialog challenge II at\nDSTC9. In DSTC9 Workshop at AAAI, Online.\nMargaret Li, Stephen Roller, Ilia Kulikov, Sean\nWelleck, Y-Lan Boureau, Kyunghyun Cho, and Ja-\nson Weston. 2020. Don’t say that! Making inconsis-\ntent dialogue unlikely with unlikelihood training. In\nProceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 4715–\n4728, Online.\nChin-Yew Lin. 2004. Rouge: A package for automatic\nevaluation of summaries. In Text Summarization\nBranches Out, pages 74–81, Barcelona, Spain.\nIlya Loshchilov and Frank Hutter. 2019. Decou-\npled weight decay regularization. In 7th Inter-\nnational Conference on Learning Representations,\nICLR 2019, New Orleans, LA, USA, May 6-9, 2019.\nNurul Lubis, Christian Geishauser, Michael Heck,\nHsien-chin Lin, Marco Moresi, Carel van Niekerk,\nand Milica Gasic. 2020. LA V A: Latent action spaces\nvia variational auto-encoding for dialogue policy\noptimization. In Proceedings of the 28th Inter-\nnational Conference on Computational Linguistics ,\npages 465–479, Barcelona, Spain (Online).\nDominik Machá ˇcek, Jonáš Kratochvíl, Sangeet Sagar,\nMatúš Žilinec, Ondˇrej Bojar, Thai-Son Nguyen, Fe-\nlix Schneider, Philip Williams, and Yuekun Yao.\n2020. ELITR non-native speech translation at\nIWSLT 2020. In Proceedings of the 17th Interna-\ntional Conference on Spoken Language Translation,\npages 200–208, Online.\nNitin Madnani and Bonnie J. Dorr. 2010. Generat-\ning phrasal and sentential paraphrases: A survey\nof data-driven methods. Computational Linguistics,\n36(3):341–387.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. BLEU: a method for automatic eval-\nuation of machine translation. In Proceedings of\nthe 40th Annual Meeting of the Association for Com-\nputational Linguistics, pages 311–318, Philadelphia,\nPennsylvania, USA.\nAdam Paszke, Sam Gross, Francisco Massa, Adam\nLerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca\nAntiga, Alban Desmaison, Andreas Köpf, Edward\nYang, Zachary DeVito, Martin Raison, Alykhan Te-\njani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang,\nJunjie Bai, and Soumith Chintala. 2019. Py-\nTorch: An imperative style, high-performance deep\nlearning library. In Advances in Neural Informa-\ntion Processing Systems 32: Annual Conference\non Neural Information Processing Systems 2019,\nNeurIPS 2019, December 8-14, 2019, Vancouver,\nBC, Canada, pages 8024–8035.\nBaolin Peng, Chunyuan Li, Jinchao Li, Shahin Shayan-\ndeh, Lars Liden, and Jianfeng Gao. 2021. Soloist:\nBuilding task bots at scale with transfer learning and\nmachine teaching. Transactions of the Association\nfor Computational Linguistics, 9:807–824.\nLibo Qin, Xiao Xu, Wanxiang Che, Yue Zhang, and\nTing Liu. 2020. Dynamic fusion network for multi-\ndomain end-to-end task-oriented dialog. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 6344–\n6354, Online.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. Techni-\ncal report, OpenAI.\nAbhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara,\nRaghav Gupta, and Pranav Khaitan. 2020. Towards\nscalable multi-domain conversational agents: The\nschema-guided dialogue dataset. In Proceedings\nof the AAAI Conference on Artiﬁcial Intelligence ,\npages 8689–8696, New York, NY , USA.\nRico Sennrich, Barry Haddow, and Alexandra Birch.\n2016. Improving neural machine translation mod-\nels with monolingual data. In Proceedings of the\n54th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), pages\n86–96, Berlin, Germany.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\n208\nyou need. In Advances in Neural Information Pro-\ncessing Systems 30: Annual Conference on Neural\nInformation Processing Systems 2017, December 4-\n9, 2017, Long Beach, CA, USA, pages 5998–6008.\nSean Welleck, Ilia Kulikov, Stephen Roller, Emily Di-\nnan, Kyunghyun Cho, and Jason Weston. 2020. Neu-\nral text generation with unlikelihood training. In\n8th International Conference on Learning Represen-\ntations, ICLR 2020, Addis Ababa, Ethiopia, April\n26-30, 2020.\nTsung-Hsien Wen, Milica Gaši´c, Dongho Kim, Nikola\nMrkši´c, Pei-Hao Su, David Vandyke, and Steve\nYoung. 2015. Stochastic language generation in di-\nalogue using recurrent neural networks with convo-\nlutional sentence reranking. In Proceedings of the\n16th Annual Meeting of the Special Interest Group\non Discourse and Dialogue, pages 275–284, Prague,\nCzech Republic.\nTsung-Hsien Wen, David Vandyke, Nikola Mrkši ´c,\nMilica Gaši´c, Lina M. Rojas-Barahona, Pei-Hao Su,\nStefan Ultes, and Steve Young. 2017. A network-\nbased end-to-end trainable task-oriented dialogue\nsystem. In Proceedings of the 15th Conference of\nthe European Chapter of the Association for Compu-\ntational Linguistics: Volume 1, Long Papers , pages\n438–449, Valencia, Spain.\nChien-Sheng Wu, Steven Hoi, Richard Socher, and\nCaiming Xiong. 2020. ToD-BERT: Pre-trained nat-\nural language understanding for task-oriented dia-\nlogues. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP), page 917–929, Online.\nS. Young, M. Gaši´c, B. Thomson, and J. D. Williams.\n2013. POMDP-based statistical spoken dialog\nsystems: A review. Proceedings of the IEEE ,\n101(5):1160–1179.\nYichi Zhang, Zhijian Ou, Min Hu, and Junlan Feng.\n2020a. A probabilistic end-to-end task-oriented di-\nalog model with latent belief states towards semi-\nsupervised learning. In Proceedings of the 2020\nConference on Empirical Methods in Natural Lan-\nguage Processing (EMNLP), pages 9207–9219, On-\nline.\nYichi Zhang, Zhijian Ou, and Zhou Yu. 2020b. Task-\noriented dialog systems that consider multiple ap-\npropriate responses under the same context. In Pro-\nceedings of the AAAI Conference on Artiﬁcial Intel-\nligence, pages 9604–9611, New York, NY , USA.\nYizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen,\nChris Brockett, Xiang Gao, Jianfeng Gao, Jingjing\nLiu, and Bill Dolan. 2020c. DIALOGPT : Large-\nscale generative pre-training for conversational re-\nsponse generation. In Proceedings of the 58th An-\nnual Meeting of the Association for Computational\nLinguistics: System Demonstrations , pages 270–\n278, Online.\nQi Zhu, Zheng Zhang, Yan Fang, Xiang Li, Ryuichi\nTakanobu, Jinchao Li, Baolin Peng, Jianfeng Gao,\nXiaoyan Zhu, and Minlie Huang. 2020. ConvLab-\n2: An open-source toolkit for building, evaluating,\nand diagnosing dialogue systems. In Proceedings\nof the 58th Annual Meeting of the Association for\nComputational Linguistics: System Demonstrations,\npages 142–149, Online.\nVilém Zouhar, Michal Novák, Matúš Žilinec, Ond ˇrej\nBojar, Mateo Obregón, Robin L. Hill, Frédéric\nBlain, Marina Fomicheva, Lucia Specia, and Lisa\nYankovskaya. 2021. Backtranslation feedback im-\nproves user conﬁdence in MT, not quality. In Pro-\nceedings of the 2021 Conference of the North Amer-\nican Chapter of the Association for Computational\nLinguistics: Human Language Technologies , pages\n151–161, Online.\n209\nA Additional Results\nA.1 Detailed Error Analysis\nOur expert annotators evaluated 130 dialogues in\ntotal, 50 of which contained at least one error. How-\never, in most cases, the system was able to recover\nfrom the errors, resulting in an overall success rate\nof 86.9% (i.e., 17 unsuccessful dialogues). The\npurpose of this analysis was to identify different\ntypes of errors occurring during full dialogues. The\nannotators were familiar with the model architec-\nture and were instructed to categorize the errors\naccording to the cause of the problem. Speciﬁcally,\nthey identiﬁed which component caused the respec-\ntive error and annotators categorized the errors into\nmore speciﬁc types.\nThe overall results are given in Table 5. We\nobserve that the most common reason for a failed\ndialogue is an error related to the belief state (30\nerrors, 10 failed dialogues). Also, although policy\nerrors happen relatively often (21x), they rarely\ncause the whole dialogue to fail (2 dialogues). We\nobserve that we have a slightly higher number of\nsuccessful dialogues compared to the 82.6% suc-\ncess rate (without checking database consistency)\nfound in human evaluation (cf. Table 3). The most\nlikely cause is that our expert annotators were more\nmotivated to recover from erroneous system behav-\nior and ﬁnish the dialogue.\nFine-grained error types identiﬁed by annotators\nare given in Table 6 and Examples 2, 4 and 3. To\nextend the analysis from Section 5.3, we include\nanother frequent error type – missing information\n(5 counts), i.e., not asking for information that is\nrequired (Example 4). In this case, the system uses\ninformation from a different domain without the\nuser explicitly conﬁrming this. A most probable\ncause of this is that most instances of the training\ndata carry over the information.\nA.2 Individual Component Analysis\nWe have conducted additional tests to obtain a\ndeeper insight into each component’s performance\n– DST and NLG. We have evaluated the accuracy\nof the generated belief states. Joint accuracy, slot\naccuracy, and F1 score were used. Joint accuracy\ngives the percentage of successfully generated be-\nlief states – with no error. Slot accuracy, on the\nother hand, is the average accuracy of correctly\npredicting the value for a domain-slot pair. To eval-\nuate NLG, we compared the end-to-end system\nwhere the generated belief state is used to query\nuser: I’m looking for a theatre in Cambridge\nbelief: attraction {type = theatre}\nsystem: There are 5 theatres in Cambridge. Is there an\narea of town you prefer?\nuser: no I don’t care\nbelief: attraction {type = theatre}\nsystem: I recommend Adc Theatre in the centre. Would\nyou like more information?\nuser: no, I’m also looking for some place to stay\nbelief: attraction {type = theatre}\nsystem: I have 5 theatres in the centre. Do you have a\nprice range?\nuser: I’m looking for a place to stay\nbelief: attraction {type = theatre}\nsystem: There are 5 theatres in the centre. Do you have a\npreference for area?\nuser: I’m looking for a hotel\nbelief: hotel {type = hotel}\nattraction {type = theatre}\nsystem: There are 9 hotels in the north. Do you have a\nprice range?\nExample 4: Dialogue sample with a bad domain focus\nand a hallucination. First, the system ignores that the\nuser switched from searching for a theater to searching\nfor a hotel. After accepting the new domain, the system\nreplies with hotels “in the north” even though the user\ndid not specify.\nthe database and generate the response with a vari-\nant of the pipeline, where the ground-truth belief\nstate and/or ground-truth database result counts\nwere used. The BLEU (Papineni et al., 2002) and\nROUGE-L (Lin, 2004) scores were used for evalu-\nation.\nIn Table 7, we can see the performance of each\nindividual component of the system. One can no-\ntice that the performance of NLG is not decreased\nwhen we use the generated belief state instead of\nthe oracle belief state. Since the belief state pre-\ndiction is not perfect, this suggests that the model\ndoes not actually need belief states for generating\nthe delexicalized response. However, when the real\ndatabase result counts are used instead of oracle\ndatabase result counts, the performance decreases,\nwhich implies that the database result counts are\nimportant for NLG.\n210\nErroneous BS DB Policy Other\nDialogues Error Error Error Error\nAll dialogues 50 30 4 21 6\nUnsuccessful dialogues 17 10 3 2 2\nTable 5: Interactive analysis performed by human evaluators using 130 prepared dialogue goals. 17 of these\ndialogues contained an error that caused the dialogue to fail. We show summary statistics regarding the number of\nrespective error sources (BS = belief state, DB = database). Note that some of the dialogues contain more than one\nerror.\nType Count Source Description\nHallucinated values 21 BS/Policy Used a slot value in the reply that is not grounded in the DB nor in the\ncontext\nWrong lexicalization 6 Policy Repeats the same value in a list of choices during lexicalization\nMissing information 5 Policy Makes booking while not all information is speciﬁed\nIgnored input 5 BS Keeps asking for information that was provided\nBad domain 4 BS Fails to focus on the correct domain\nFalse response 4 Policy States a different value of a slot than the value stored in DB\nRepeated output 3 Policy Repeats the same slot twice on the output\nFailed booking 3 DB/Policy Booking was unsuccessful due to DB mismatch\nOther 10 BS/DB/P/Oth (Various rare errors that could not be categorized)\nTable 6: Distribution of the most common error types encountered during the human evaluation of 130 dialogues.\nAbsolute counts of errors in the 50 erroneous dialogues are shown. The total error count is 61 as some dialogues\ncontained multiple errors. The most likely source of the error (cf. Table 5) and a short description are given for\neach type.\noracle DST NLG\nﬁne-tuned on bs db joint acc. slot acc. F1 BLEU ROUGE-L\nMW 2.0\n\u0017 \u0017\n54.1 97.2 90.0\n17.2 39.0\n\u0017 \u0013 17.4 39.3\n\u0013 \u0013 17.4 39.2\nMW 2.1\n\u0017 \u0017\n56.5 97.2 90.6\n17.4 38.6\n\u0017 \u0013 17.6 38.8\n\u0013 \u0013 17.6 38.8\nTable 7: Performance of DST and NLG components. Joint and slot accuracies, as well as slot values F1 score, are\nused to evaluate DST. For NLG, BLEU and ROUGE-L metrics are used. Apart from using the generated belief\nstates and database counts, we also evaluate the components with oracle values. Note that models were pre-trained\non Taskmaster-1 and Schema-Guided Dialogue datasets."
}