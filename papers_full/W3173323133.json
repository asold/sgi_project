{
    "title": "A comparison of two assessment tools used in overviews of systematic reviews: ROBIS versus AMSTAR-2",
    "url": "https://openalex.org/W3173323133",
    "year": 2021,
    "authors": [
        {
            "id": "https://openalex.org/A2034450245",
            "name": "R. Perry",
            "affiliations": [
                "University Hospitals Bristol NHS Foundation Trust",
                "University of Bristol",
                "National Institute for Health Research"
            ]
        },
        {
            "id": "https://openalex.org/A2337898168",
            "name": "A. Whitmarsh",
            "affiliations": [
                "University of Bristol",
                "University Hospitals Bristol NHS Foundation Trust",
                "National Institute for Health Research"
            ]
        },
        {
            "id": "https://openalex.org/A2183537920",
            "name": "V. Leach",
            "affiliations": [
                "National Institute for Health Research",
                "University Hospitals Bristol NHS Foundation Trust"
            ]
        },
        {
            "id": "https://openalex.org/A2023964093",
            "name": "P Davies",
            "affiliations": [
                "National Institute for Health Research",
                "University Hospitals Bristol NHS Foundation Trust",
                "University of Bristol"
            ]
        },
        {
            "id": "https://openalex.org/A2034450245",
            "name": "R. Perry",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2337898168",
            "name": "A. Whitmarsh",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2183537920",
            "name": "V. Leach",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2023964093",
            "name": "P Davies",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2475260156",
        "https://openalex.org/W2119790985",
        "https://openalex.org/W2073644162",
        "https://openalex.org/W2341555490",
        "https://openalex.org/W2756578555",
        "https://openalex.org/W600840809",
        "https://openalex.org/W2905251737",
        "https://openalex.org/W2947531909",
        "https://openalex.org/W2616033665",
        "https://openalex.org/W2986252881",
        "https://openalex.org/W2164777277",
        "https://openalex.org/W6635207271",
        "https://openalex.org/W2061381729",
        "https://openalex.org/W2068685355",
        "https://openalex.org/W2127148383",
        "https://openalex.org/W4255300974",
        "https://openalex.org/W2044864709",
        "https://openalex.org/W2124919160",
        "https://openalex.org/W2046021362",
        "https://openalex.org/W2153845460",
        "https://openalex.org/W2093749419",
        "https://openalex.org/W2017480535",
        "https://openalex.org/W2048627859",
        "https://openalex.org/W2097334672",
        "https://openalex.org/W1506340264",
        "https://openalex.org/W2117914517",
        "https://openalex.org/W2116540885",
        "https://openalex.org/W3023760278",
        "https://openalex.org/W2081604356",
        "https://openalex.org/W2214564377",
        "https://openalex.org/W2777907776",
        "https://openalex.org/W2000710385",
        "https://openalex.org/W2788293180",
        "https://openalex.org/W2792570303",
        "https://openalex.org/W2610300231",
        "https://openalex.org/W2105001422",
        "https://openalex.org/W1963600002",
        "https://openalex.org/W2094499027",
        "https://openalex.org/W2234740317",
        "https://openalex.org/W2324460417",
        "https://openalex.org/W2588877828",
        "https://openalex.org/W2778074450",
        "https://openalex.org/W1975879668",
        "https://openalex.org/W613277099",
        "https://openalex.org/W3205130411",
        "https://openalex.org/W2126212706",
        "https://openalex.org/W2132606563",
        "https://openalex.org/W2185723647",
        "https://openalex.org/W3144735061",
        "https://openalex.org/W3205515925",
        "https://openalex.org/W1588513110"
    ],
    "abstract": "Abstract Background AMSTAR-2 is a 16-item assessment tool to check the quality of a systematic review and establish whether the most important elements are reported. ROBIS is another assessment tool which was designed to evaluate the level of bias present within a systematic review. Our objective was to compare, contrast and establish both inter-rater reliability and usability of both tools as part of two overviews of systematic reviews. Strictly speaking, one tool assesses methodological quality (AMSTAR-2) and the other assesses risk of bias (ROBIS), but there is considerable overlap between the tools in terms of the signalling questions. Methods Three reviewers independently assessed 31 systematic reviews using both tools. The inter-rater reliability of all sub-sections using each instrument (AMSTAR-2 and ROBIS) was calculated using Gwet’s agreement coefficient (AC 1 for unweighted analysis and AC 2 for weighted analysis). Results Thirty-one systematic reviews were included. For AMSTAR-2, the median agreement for all questions was 0.61. Eight of the 16 AMSTAR-2 questions had substantial agreement or higher (&gt; 0.61). For ROBIS, the median agreement for all questions was also 0.61. Eleven of the 24 ROBIS questions had substantial agreement or higher. Conclusion ROBIS is an effective tool for assessing risk of bias in systematic reviews and AMSTAR-2 is an effective tool at assessing quality. The median agreement between raters for both tools was identical (0.61). Reviews that included a meta-analysis were easier to rate with ROBIS; however, further developmental work could improve its use in reviews without a formal synthesis. AMSTAR-2 was more straightforward to use; however, more response options would be beneficial.",
    "full_text": "Perry et al. Syst Rev          (2021) 10:273  \nhttps://doi.org/10.1186/s13643-021-01819-x\nMETHODOLOGY\nA comparison of two assessment tools \nused in overviews of systematic reviews: ROBIS \nversus AMSTAR-2\nR. Perry1* , A. Whitmarsh1, V. Leach2 and P . Davies2,3 \nAbstract \nBackground: AMSTAR-2 is a 16-item assessment tool to check the quality of a systematic review and establish \nwhether the most important elements are reported. ROBIS is another assessment tool which was designed to evalu-\nate the level of bias present within a systematic review. Our objective was to compare, contrast and establish both \ninter-rater reliability and usability of both tools as part of two overviews of systematic reviews. Strictly speaking, one \ntool assesses methodological quality (AMSTAR-2) and the other assesses risk of bias (ROBIS), but there is considerable \noverlap between the tools in terms of the signalling questions.\nMethods: Three reviewers independently assessed 31 systematic reviews using both tools. The inter-rater reliability \nof all sub-sections using each instrument (AMSTAR-2 and ROBIS) was calculated using Gwet’s agreement coefficient \n (AC1 for unweighted analysis and  AC2 for weighted analysis).\nResults: Thirty-one systematic reviews were included. For AMSTAR-2, the median agreement for all questions was \n0.61. Eight of the 16 AMSTAR-2 questions had substantial agreement or higher (> 0.61). For ROBIS, the median agree-\nment for all questions was also 0.61. Eleven of the 24 ROBIS questions had substantial agreement or higher.\nConclusion: ROBIS is an effective tool for assessing risk of bias in systematic reviews and AMSTAR-2 is an effective \ntool at assessing quality. The median agreement between raters for both tools was identical (0.61). Reviews that \nincluded a meta-analysis were easier to rate with ROBIS; however, further developmental work could improve its use \nin reviews without a formal synthesis. AMSTAR-2 was more straightforward to use; however, more response options \nwould be beneficial.\nKeywords: AMSTAR-2, ROBIS, Systematic reviews, Methodological quality, Risk of bias\n© The Author(s) 2021. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which \npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the \noriginal author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or \nother third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line \nto the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory \nregulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this \nlicence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/. The Creative Commons Public Domain Dedication waiver (http:// creat iveco \nmmons. org/ publi cdoma in/ zero/1. 0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data.\nBackground\nSystematic reviews have become a fundamental part of \nevidence-based medicine; they are considered the high -\nest form of evidence as they synthesise all available evi -\ndence on a given topic [1]. Many will also combine data \nto give an overall effect estimate using a meta-analysis. \nHowever, the quality and standard of reviews varies con -\nsiderably. If this is not understood, or in some way estab -\nlished, the results of many reviews might be overstated. \nQuality assessment tools have been developed to assess \nsuch variation in standards.\nOne previously heavily cited tool is the Assessment of \nMultiple Systematic Reviews (AMSTAR) scale [2] which \nhas been widely used since its development in 2007. This \nscale was shown to be both reliable and valid [3]. How -\never, it came under criticism for some issues with its \ndesign. It was argued by Burda et  al. [4] that AMSTAR \nwas lacking in some key constructs, in particular, the \nOpen Access\n*Correspondence:  Rachel.Perry@bristol.ac.uk\n1 National Institute for Health Research Bristol Biomedical Research \nCentre, University Hospitals Bristol and Weston NHS Foundation Trust \nand University of Bristol, Bristol, UK\nFull list of author information is available at the end of the article\nPage 2 of 20Perry et al. Syst Rev          (2021) 10:273 \nconfidence in the estimates of effect. It also lacks an \nitem to assess subgroup and sensitivity analysis. Further \ncriticisms include issues such as the inclusion of foreign \nlanguage papers as “grey literature” and the idea that \nthe items can often partially but not fully meet the cri -\nteria was highlighted. Also, each item was not weighted \nevenly and there is a lack of overall score, which became \nproblematic when trying to compare scores. Thus, an \nupgraded version (AMSTAR-2) was developed in 2017. \nThe new version promised to simplify the response cate -\ngories, align the definition of research questions with the \nPICO (population, intervention, control group, outcome) \nframework, seek justification for the review authors’ \nselection of different study designs (randomised and non-\nrandomised) and included numerical rating scales for \ninclusion in systematic reviews, seek reasons for exclu -\nsion of studies from the review, and determine whether \nthe review authors had made a sufficiently detailed \nassessment of risk of bias for the included studies and \nwhether risk of bias was considered adequately during \nstatistical pooling and when interpreting the results [5].\nA second novel assessment tool that has undergone rig-\norous development was published in 2016 (Risk of Bias \nin Systematic reviews [ROBIS [6]]). It aimed to provide \na thorough and robust assessment of the level of bias \nwithin the systematic review.\nDescription of the assessment tools\nAssessment of multiple systematic reviews (AMSTAR‑2)\nThe main aim of the AMSTAR-2 is a tool to assess the \nmethodological quality of the review. It is made up of 16 \nitems in total and has simpler response categories than \nthe original AMSTAR version. Some sections are con -\nsidered by the authors to be critical domains, which can \nbe used for determining an overall score (see Appendix , \nTable 12 for more information on the critical domains). \nAMSTAR-2 is intended for assessing effectiveness. The \ntool can also be applied to reviews of both randomised \nand non-randomised studies.\nROBIS tool\nThe main aim of the ROBIS tool is to evaluate the level of \nbias present within a systematic review. The tool is made \nup of three distinct phases. Firstly, there is an optional \nfirst phase to assess the applicability of the review to the \nresearch question of interest. The second phase is made \nup of 20-items within four main domains: study eligibility \ncriteria, identification and selection of studies, data col -\nlection and study appraisal, synthesis and findings. This \nphase is to identify concerns about the review conduct. \nEach domain has signalling questions and ends with \na judgement of concerns of each domain (low, high or \nunclear). There is also a third phase consisting of three \nsignalling questions to enable an overall assessment of \nbias rating to be given. ROBIS has a wide application and \nis intended for assessing effectiveness, diagnostic test \naccuracy, prognosis and aetiology [6].\nPrevious research\nDue to the novelty of both tools, there is limited available \nliterature comparing them; however, some work has been \nrecently published.\nOne review team [7, 8] compared all three tools \n(AMSTAR, AMSTAR-2 and ROBIS), applying them to \nreviews that reported both randomised and non-ran -\ndomised trials. The inter-rater reliability between four \nraters’ across 30 systematic reviews was analysed. Minor \ndifferences were found between AMSTAR-2 and ROBIS \nin the assessment of systematic reviews including a mix \nof study type. On average, the inter-rater reliability (IRR) \nwas higher for AMSTAR-2 compared to ROBIS. They \nassumed that scoring ROBIS would take more time in \ngeneral, and it was always applied after AMSTAR-2, but \nin fact the mean time for scoring AMSTAR-2 was slightly \nhigher than for ROBIS (18 vs. 16 min), with huge varia -\ntion between the reviewers. They also reported that some \nsignalling questions in ROBIS were judged to be very dif -\nficult to assess.\nAim\nThe overarching aim of our work is to add to the litera -\nture and make a further comparison of both assessment \ntools in two overviews of reviews. Our team had previ -\nously completed two overviews on complementary and \nalternative medicine (CAM) therapies for two hard-to-\ntreat conditions. One overview evaluated systematic \nreviews of various CAM therapies for fibromyalgia (FM) \n[9], and the other evaluated systematic reviews of CAM \ntherapies for infantile colic [10].\nObjectives\nDue to some of the challenges we had using both tools \nin our overview of reviews work, we planned a formal \nassessment of both tools by completing the following \ncomparisons and evaluations:\n1. To compare the content of the tools\n2. To compare the percentage agreement (IRR)\n3. To assess the useability/user experience of both tools.\nMethods\nTwo overviews of reviews were conducted by our team \n[9, 10]. The first reviewed CAM for fibromyalgia and \nassessed the included reviews using both the origi -\nnal AMSTAR tool [2 ] and ROBIS [6 ]. This review was \nPage 3 of 20\nPerry et al. Syst Rev          (2021) 10:273 \n \npublished in 2016, prior to the development and pub -\nlication of AMSTAR-2 [5 ]. Here, we reported on 15 \nsystematic reviews of CAM for fibromyalgia, published \nbetween 2003 and 2014 which assessed several CAM \ntherapies. Eight of the reviews included a quantitative \nsynthesis.\nWe subsequently completed a second overview of \nreviews of CAM for infantile colic published in 2019 \n[10]. Here, we used the new AMSTAR-2 tool along -\nside ROBIS. We reported on 16 systematic reviews \nof CAM for colic, published between 2011 and 2018. \nThe reviews investigated several CAM therapies, 12 of \nwhich included a quantitative synthesis.\nWe later returned to the fibromyalgia review papers \nand reassessed them all using the AMSTAR-2 scale, \nfor consistency. This results in a total comparison of 31 \nreviews. The reviewers were not strict about the order \nof ratings.\nAssessment of methodological quality/bias of the included \nreviews\nThree reviewers (RP , VL, PD) independently assessed \neach systematic review using both tools. Any reported \nmeta-analyses were checked by a statistician experi -\nenced in meta-analyses (CP). The final score was agreed \nafter discussion between the authors.\nData‑analysis\nGwet’s AC statistic was used to calculate inter-rater \nreliability (IRR) [11]. Gwet’s AC2 is a weighted statistic \nwhich allows for “partial agreement” between ordinal \ncategories. Therefore, Gwet’s AC2 was used to calculate \nIRR (using linear weights) for AMSTAR-2 questions \nwith options “no” , “partial yes” and “yes” (questions 2, \n4, 7, 8, 9). Gwet’s AC1 is an unweighted statistic which \nmeasures full agreement only. Gwet’s AC1 was used for \nall other AMSTAR-2 questions.\nAll signalling questions for ROBIS were analysed \nusing Gwet’s AC2 with linear weights where “no” , “prob-\nably no” , “probably yes” and “yes” were recoded as 1–4. \nAs mentioned above, Gwet’s AC2 is a weighted statistic \nwhich allows for “partial agreement” between ordinal \ncategories. Ratings of “no information” were treated \nas missing. Gwet’s AC1 was used for ROBIS domains. \nAgreement for AMSTAR-2 and ROBIS was classified as \n“poor” (≤  0.00), “slight” (0.01–0.20), “fair” (0.21–0.40), \n“moderate” (0.41–0.60), “substantial” (0.61–0.80), and \n“almost perfect” (0.81–1.00), following accepted cri -\nteria [12]. All analyses were completed using Stata 16 \n(StataCorp. 2019; Stata Statistical Software).\nResults\nOur first objective was to compare the content of the \ntools (see Table  1). Any overlaps and discrepancies \nbetween the two scales are identified. Overall, we found \nconsiderable overlap on the signalling questions. How -\never, ROBIS does not assess whether there is a compre -\nhensive list of studies (both included and excluded) or \nwhether any conflicts of interest were declared (both at \nthe individual trial level and for the reviews), as these \nare considered issues of methodology quality rather \nthan bias. AMSTAR-2 also assessed possible conflicts of \ninterest, which is not assessed in ROBIS, despite being a \npotential risk of bias. However, the section on synthesis \nwas given more in-depth consideration in ROBIS tool.\nSection 2: Comparison of the inter‑rater reliability \nof the tools\nAMSTAR‑2\nThe consensus results for AMSTAR-2 of both fibromy -\nalgia and colic overviews can be found in Table  2. We \nreport on 15 systematic reviews of CAM for fibromyalgia \nand found all but one review [13] rated as having critically \nlow confidence in the results (see Appendix , Table 15 for \nscoring information). This was the only Cochrane review \nincluded in the FM overview. We also report on 16 sys -\ntematic reviews of CAM for colic. Most were rated as \nhaving critically low confidence in the results, 4 were \nrated as low and 1 (a Cochrane review) was considered \nto have high confidence in the results. The comparison of \nthe ratings for each review can be found in the Appen-\ndix (see Tables  9, 10, 13, and 14). There were a greater \nnumber of discrepancies between the overall risk of bias \nand quality ratings in the fibromyalgia reviews. The over -\nall risk of bias/quality ratings was more consistent in the \ncolic reviews.\nResults of inter‑rater reliability analysis for \nAMSTAR‑2 A summary of the inter-rater reliability \n[IRR] for AMSTAR-2 can be found in Table  3. Seven \nquestions that relate to critical domains were identified \nby Shea et al. [5]; more information about these domains \ncan be found in Appendix (Table 15).\nSummary of the findings on Inter‑rater reliability In \ntotal, 460 comparisons were included in the analysis for \nAMSTAR-2. The median agreement for all questions \nwas 0.61. Eight of the 16 AMSTAR-2 questions had sub -\nstantial agreement or higher. There was almost perfect \nagreement for questions 2 (did the report of the review \ncontain an explicit statement that the review methods \nwere established prior to the conduct of the review and \nPage 4 of 20Perry et al. Syst Rev          (2021) 10:273 \nTable 1 A comparison of the content of the two tools (AMSTAR-2 and ROBIS)\nSignalling questions are in a different order to line up the criteria from both tools. N/A not assessed\nCriteria AMSTAR‑2 ROBIS\nEligibility criteria 1. Did the research questions and inclusion criteria for the review include the compo-\nnents of PICO?\n2. Did the report of the review contain an explicit statement that the review methods \nwere established prior to the conduct of the review and did the report justify any signifi-\ncant deviations from the protocol?\n3. Did the review authors explain their selection of the study designs for inclusion in the \nreview?\n1.1 Did the review adhere to pre-defined objectives and eligibility criteria?\n1.2 Were the eligibility criteria appropriate for the review question?\n1.3 Were eligibility criteria unambiguous?\n1.4 Were all restrictions in eligibility criteria based on study characteristics appropriate (e.g., \ndate, sample size, study quality, outcomes measured)?\n1.5 Were any restrictions in eligibility criteria based on sources of information appropriate \n(e.g., publication status or format, language, availability of data)?\nStudy selection and Data extraction 5. Did the review authors perform study selection in duplicate?\n6. Did the review authors perform data extraction in duplicate?\n2.5 Were efforts made to minimise error in selection of studies?\n3.1 Were efforts made to minimise error in data collection?\n3.3 Were all relevant study results collected for use in the synthesis?\nLiterature search 4. Did the review authors use a comprehensive literature search strategy? 2.1 Did the search include an appropriate range of databases/electronic sources for pub-\nlished and unpublished reports?\n2.3 Were the terms and structure of the search strategy likely to retrieve as many eligible \nstudies as possible?\n2.4 Were restrictions based on date, publication format, or language appropriate?\nGrey literature NA 2.2 Were methods additional to database searching used to identify relevant reports?\nList of studies 7. Did the review authors provide a list of excluded studies and justify the exclusions? N/A\nCharacteristics of studies 8. Did the review authors describe the included studies in adequate detail? 3.2 Were sufficient study characteristics available for both review authors and readers to be \nable to interpret the results?\nQuality assessment 9. Did the review authors use a satisfactory technique for assessing the risk of bias (RoB) \nin individual studies that were included in the review?\n3.4 Was risk of bias (or methodological quality) formally assessed using appropriate criteria?\n3.5 Were efforts made to minimise error in risk of bias assessment?\nSynthesis of the findings N/A\nN/A\n11. If meta-analysis was performed did the review authors use appropriate methods for \nstatistical combination of results?\n12. If meta-analysis was performed, did the review authors assess the potential impact of \nRoB in individual studies on the results of the meta-analysis or other evidence synthesis?\n4.1 Did the synthesis include all studies that it should?\n4.2 Were all pre-defined analyses reported or departures explained?\n4.3 Was the synthesis appropriate given the nature and similarity in the research questions, \nstudy designs and outcomes across included studies?\n4.6 Were biases in primary studies minimal or addressed in the synthesis?\nHeterogeneity 14. Did the review authors provide a satisfactory explanation for, and discussion of, any \nheterogeneity observed in the results of the review? 15. If they performed quantitative \nsynthesis did the review authors carry out an adequate investigation of publication bias \n(small study bias) and discuss its likely impact on the results of the review?\n4.4 Was between-study variation (heterogeneity) minimal or addressed in the synthesis?\n4.5 Were the findings robust, e.g., as demonstrated through funnel plot or sensitivity \nanalyses?\nInterpretation 13. Did the review authors account for RoB in individual studies when interpreting/ \ndiscussing the results of the review?\nA. Did the interpretation of findings address all of the concerns identified in Domains 1 to \n4?\nB. Was the relevance of identified studies to the review’s research\nquestion appropriately considered?\nC. Did the reviewers avoid emphasising results on the basis of their statistical significance?\nConflict of interest 10. Did the review authors report on the sources of funding for the studies included in \nthe review?\n16. Did the review authors report any potential sources of conflict of interest, including \nany funding they received for conducting the review?\nN/A\nN/A\nPage 5 of 20\nPerry et al. Syst Rev          (2021) 10:273 \n \nTable 2 Agreed results of AMSTAR-2 for fibromyalgia\nAuthor (date), \nCAM\n1. Were PICO \ncomponents \nlisted?\n2. Protocol \nreported? Any \ndeviations \njustified?\n3. Study design \njustified?\n4. Comprehensive \nliterature search?\n5. Was study \nselection \nperformed in \nduplicate?\n6. Was data \nextraction \nperformed in \nduplicate?\n7. List of excluded \nstudies? Were \nthese justified?\n8. Characteristics of \nstudies provided in \ndetail?\nFibromyalgia\n Multiple cam therapies\n  Holdcraft 2003 \n[14]\nNo No No No No No No No\n  Baronowsky \n2009 [15]\nNo No Yes No No No No No\n  Terhorst 2011, \n2012 [16, 17]\nYes No No No Yes No No No\n  De Silva 2010 \n[18]\nNo No No No Yes Yes No No\n Homoeopathy\n  Perry 2010 [19] Yes No No PY Yes Yes No PY\n  Boehm 2014 \n[20]\nNo No No PY Yes Yes No Yes\n Chiropractic treatment\n  Ernst 2009 [21] Yes No No No No Yes No No\n Acupuncture\n  Mayhew and \nErnst 2007 [22]\nNo No No PY No Yes No PY\n  Daya 2007 [23] No No No PY No No No PY\n  Langhorst 2010 \n[24]\nYes No No PY Yes Yes No Yes\n  Martin-Sanchez \n2009 [25]\nYes No No PY No No No No\n  Cao 2013 [26] Yes No No PY yes Yes No Yes\n  Deare 2013 \n[13]\nYes Yes No Yes Yes Yes Yes Yes\n  Yang 2014 [27] Yes No No PY Yes Yes No No\n Herbal medicines\n  de Souza Nas-\ncimento 2013 [28]\nYes No yes No No Yes No PY\nColic\n Multiple cam therapies\n  Perry 2011 [29] Yes PY No PY PY Yes No Yes\n  Bruyas-Bertho -\nlon 2012 [30]\nNo No No No No No No PY\nPage 6 of 20Perry et al. Syst Rev          (2021) 10:273 \nTable 2 (continued)\nAuthor (date), \nCAM\n1. Were PICO \ncomponents \nlisted?\n2. Protocol \nreported? Any \ndeviations \njustified?\n3. Study design \njustified?\n4. Comprehensive \nliterature search?\n5. Was study \nselection \nperformed in \nduplicate?\n6. Was data \nextraction \nperformed in \nduplicate?\n7. List of excluded \nstudies? Were \nthese justified?\n8. Characteristics of \nstudies provided in \ndetail?\n  Harb 2016 [31] Yes No No No Yes Yes No PY\n  Gutierrez-Cas-\ntrellon 2017 [32]\nYes No No No No No No No\n Manipulation therapies\n  Dobson 2012 \n[33]\nYes Yes No Yes Yes Yes Yes Yes\n  Gleberzon \n2012 [34]\nNo No No PY No Yes No PY\n  Carnes 2017 \n[35]\nNo PY No PY Yes Yes No PY\n Acupuncture\n  Skejeie 2018 \n[36]\nYes PY No Yes Yes Yes No Yes\n Herbal medicines\n  Anheyer 2017 \n[37]\nNo No No No No Yes No Yes\n Probiotics\n  Sung 2013 [38] Yes No No No Yes Yes Yes PY\n  Anabrees 2013 \n[39]\nYes PY No PY No Yes No Yes\n  Urbanska 2014 \n[40]\nYes No No PY No No No PY\n  Xu 2015 [41] No No No PY Yes Yes No Yes\n  Schreck Bird \n2017 [42]\nYes No No No Yes No No Yes\n  Dryl 2018 [43] Yes No No No No No No PY\n  Sung 2018 [44] Yes PY No PYb No No No No\nPage 7 of 20\nPerry et al. Syst Rev          (2021) 10:273 \n \nTable 2 (continued)\n9. Risk of bias \nassessed?\n10. Sources \nof funding of \nincluded studies?\n11. Methods used \nto combine the \nfindings of studies \nappropriate? Test \non heterogeneity?\n12. If meta‑\nanalysis \nperformed was \nRoB accounted \nfor?\n13. Was RoB \ndiscussed in \nindividual studies?\n14. Was there \ndiscussion of any \nheterogeneity \nobserved in the \nresults?\n15. If a quantitative \nsynthesis, was \npublication bias \ninvestigated \nand discussed in \nrelation to the \nresults?\n16. Reviewers’ \nconflict of \ninterests stated?\nConfidence in the \nreview\nFibromyalgia\n Multiple cam therapies\nPY No No MA No MA Yes No MA No CL\nNo No No MA No MA Yes No No MA No CL\nYes No No No No No No Yes CL\nNo No No MA No MA Yes Yes No MA Yes CL\n Homoeopathy\nYes No No MA No MA Yes Yes No MA Yes CL\nYes No Yes No No Yes No Yes CL\n Chiropractic treatment\nNo No No MA No MA Yes No No MA Yes CL\n Acupuncture\nNo NO No MA No MA Yes Yes No MA Yes CL\nPY No No MA No MA No No No MA No CL\nYes No Yes Yes Yes Yes No No CL\nNo No No No No Yes No Yes CL\nYes No Yes No Yes Yes Yes Yes CL\nYes Yes Yes Yes Yes Yes No Yes Low\nYes No No No No Noa Yes No CL\n Herbal medicines\nYes No No MA No MA No No No MA Yes CL\nColic\n Multiple cam therapies\nYes No No MA No MA Yes No No MA Yes Low\nPY No No MA No MA No No No MA No CL\nYes No Yes Yes Yes No Yes Yes CL\nNo No No No Yes No Yes No CL\n Manipulation therapies\nYes No Yes Yes Yes Noa Yes Yes High\nNo No No MA No MA Yes No No MA No CL\nPage 8 of 20Perry et al. Syst Rev          (2021) 10:273 \nTable 2 (continued)\n9. Risk of bias \nassessed?\n10. Sources \nof funding of \nincluded studies?\n11. Methods used \nto combine the \nfindings of studies \nappropriate? Test \non heterogeneity?\n12. If meta‑\nanalysis \nperformed was \nRoB accounted \nfor?\n13. Was RoB \ndiscussed in \nindividual studies?\n14. Was there \ndiscussion of any \nheterogeneity \nobserved in the \nresults?\n15. If a quantitative \nsynthesis, was \npublication bias \ninvestigated \nand discussed in \nrelation to the \nresults?\n16. Reviewers’ \nconflict of \ninterests stated?\nConfidence in the \nreview\nYes No No No No No No No CL\n Acupuncture\nYes No Yes Yes Yes Yes No Nod Low\n Herbal medicines\nYes No No MA No MA No No No MA Yes CL\n Probiotics\nYes No Yes No Yes No No Yes CL\nYes No Yes No Yes Yes No Yes Low\nYes Yes No No No No No No CL\nYes No Yes No No No No Yes CL\nYes No No No No No No No CL\nYes No No No No No No No CL\nYes No Yes Yes Yes Yes Yes Noc Low\nCL critically low, PY partial yes, MA meta-analysis, PICO participants, intervention, comparator, outcomes, RoB risk of bias\na Too few studies to perform a test of heterogeneity\nb Not fully searched and search conducted Dec 2014\nc Conflict of interest occurred but no indication of how it was dealt with\nd All included studies were by the author team but did not indicate how this was dealt with\nItalicised columns represent the critical domains (see Appendix, Table 15)\nPage 9 of 20\nPerry et al. Syst Rev          (2021) 10:273 \n \ndid the report justify any significant deviations from \nthe protocol?), 7 (did the review authors provide a list \nof excluded studies and justify the exclusions?) and 10 \n(did the review authors report on the sources of fund -\ning for the studies included in the review?). The lowest \nagreement was for question 14 (did the review authors \nprovide a satisfactory explanation for, and discussion of, \nany heterogeneity observed in the results of the review?). \nRatings were missing in 35 cases. The results are dis -\nplayed in Fig. 1.\nThe AMSTAR-2 critical questions, in particular, seemed \nto have good agreement compared to the other ques -\ntions. There was at least substantial agreement for all \ncritical questions except question 13 which had moder -\nate agreement. Questions 2 and 7 both had almost per -\nfect agreement and had the highest agreement of all \nAMSTAR-2 questions.\nGwet’s AC2 statistic was used for questions 2, 4, 7, 8 and \n9. Gwet’s AC1 statistic was used for all other questions. \nThe markers represent the Gwet’s statistic and the error \nbars represent the 95% confidence intervals. The itali -\ncised data represent the median value for all questions.\nFurther information on the separate reviews can be found \nin the Appendix (Tables  7 and 11). The overall median \nIRR agreement for AMSTAR-2 questions for fibromyal -\ngia is 0.65 and for colic is 0.60.\nROBIS\nSummary of the ROBIS results The consensus results \nfor ROBIS for both fibromyalgia and colic overviews can \nbe found in Table  4. With regard to the ROBIS results, \ndomain 1 (which assessed any concerns regarding spec -\nification of study eligibility criteria), 9 fibromyalgia \nTable 3 The inter-rater agreement between the three raters for \nAMSTAR-2\nItalicised questions are considered critical by the tool authors\nQuestion Number of \nstudies\nGwet’s AC1/Gwet’s \nAC2\n95% CI\n1 31 0.69 0.48, 0.91\n2 31 0.93 0.85, 1.00\n3 31 0.55 0.30, 0.80\n4 31 0.66 0.51, 0.81\n5 31 0.70 0.47, 0.94\n6 31 0.60 0.35, 0.86\n7 31 0.97 0.94, 1.00\n8 31 0.39 0.21, 0.56\n9 31 0.65 0.46, 0.84\n10 31 0.84 0.67, 1.00\n11 19 0.54 0.19, 0.89\n12 19 0.40 0.05, 0.75\n13 31 0.52 0.27, 0.78\n14 31 0.19 -0.08, 0.47\n15 19 0.61 0.28, 0.94\n16 31 0.34 0.06, 0.63\nFig. 1 Gwet’s statistic for the inter-rater agreement for AMSTAR-2 questions\nPage 10 of 20Perry et al. Syst Rev          (2021) 10:273 \nTable 4 Tabular presentation for agreement of ROBIS results\nFibromyalgia review Phase 2 Phase 3\n1. Study eligibility criteria 2. Identifica‑\ntion and \nselection of \nstudies\n3. Data \ncollection \nand study \nappraisal\n4. Synthesis  and findings 5. Risk of bias in the review\n Homoeopathy\n  1. Perry Low Low Low Unclear Low\n  2. Boehm High Low Low High High\n Acupuncture\n  3. Mayhew Low High High Low Low\n  4. Daya Low High High Low Low\n  5. Langhorst Low High High Low Low\n  6. Martin-Sanchez Low High High High High\n  7. Cao Low High Low Low Low\n  8. Deare Low Low Low Low Low\n  9. Yang Low Low High High High\n Chiropractic\n  10. Ernst High Unclear High Unclear Unclear\n Herbal Medicine\n  11. Nascimento Low Low Low High Low\n Multiple CAM reviews\n  12. Holdcraft Low Low Low High Low\n  13. Baronowsky Low Low Unclear High Low\n  14. Terhorst Low High Low High High\n  15. De Silva High High High Unclear Low\nColic review Phase 2 Phase 3\n1. Study eligibility criteria 2. Identifica‑\ntion and \nselection of \nstudies\n3. Data \ncollection \nand study \nappraisal\n4. Synthesis and findings 5. Risk of bias in the review\n Multiple CAM therapies\n  1. Perry Low Unclear Low Low Low\n  2. Bruyas-Bertholon High High Unclear High High\n  3. Harb High High Low High High\n  4. Gutierrez-Castrellon Unclear High High High High\n Manipulation therapies\n  5. Dobson Low Low Low Low Low\n  6. Gleberzon High High Unclear Unclear High\n  7. Carne Low Low Low High Unclear\n Acupuncture\n  8. Skejeie Low Low Low Low Unclear\n Herbal medicine\n  9. Anheyer Unclear High Low High High\n Probiotics\n  10. Sung 2013 Unclear Low Low High Unclear\n  11. Anabrees Low Low Low High Low\n  12. Urbansk Low High High High High\n  13. Xu Unclear Low Low Unclear Low\n  14. Shreck Bird High High Low High High\n  15. Dryl High High Unclear High High\n  16. Sung 2018 High Unclear Unclear Unclear Unclear\nPage 11 of 20\nPerry et al. Syst Rev          (2021) 10:273 \n \nreviews achieved a low risk of bias rating overall and 6 \ncolic reviews achieved a low risk of bias rating overall. \nIn domain 2 (which assessed concerns regarding meth -\nods used to identify and/or select studies), 7 fibromyalgia \nreviews achieved a low risk of bias rating overall and 6 \ncolic reviews achieved a low risk of bias rating overall.\nDomain 3 assessed concerns regarding methods used to \ncollect data and appraise studies; 7 fibromyalgia studies \nand 10 colic reviews achieved a low risk of bias rating \noverall.\nWith regard to domain 4 (which assessed concerns \nregarding the synthesis and findings), more variation in \nthe fibromyalgia scores was found, whereas most colic \nreviews were rated as high risk of bias in this domain. The \nreviews that did not conduct a meta-analysis were hard \nto assess using ROBIS.\nThe final section provides a rating for the overall risk of \nbias of the reviews; 7 fibromyalgia reviews achieved a low \nrating; 6, a high rating; and 2, were rated as unclear. Four \ncolic reviews achieved a low rating; 4, an unclear rating; \nand 8, a high rating.\nResults of inter‑rater reliability analysis for ROBIS A \nsummary of the inter-rater reliability for ROBIS can be \nfound in Table 5.\nTable 5 Inter-rater agreement\nROBIS question No. of studies Gwet’s AC1/\nGwet’s AC2\n95% CI\nDomain 1: study eligibility criteria\n 1.1 30 0.62 0.38, 0.85\n 1.2 31 0.70 0.56, 0.84\n 1.3 31 0.69 0.56, 0.82\n 1.4 31 0.61 0.48, 0.74\n 1.5 31 0.56 0.37, 0.74\n Domain 1 Concerns regarding specification of study eligibility criteria 31 0.45 0.22, 0.67\nDomain 2: identification and selection of studies\n 2.1 31 0.53 0.41, 0.65\n 2.2 30 0.53 0.35, 0.71\n 2.3 31 0.62 0.47, 0.77\n 2.4 31 0.41 0.20, 0.62\n 2.5 29 0.59 0.30, 0.88\n Domain 2 Concerns regarding methods used to identify and/or select studies 31 0.36 0.17, 0.55\nDomain 3: data collection and study appraisal\n 3.1 29 0.88 0.68, 1.00\n 3.2 31 0.66 0.51, 0.82\n 3.3 31 0.65 0.51, 0.78\n 3.4 31 0.77 0.61, 0.93\n 3.5 30 0.73 0.48, 0.98\n Domain 3 Concerns regarding methods used to collect data and appraise studies 31 0.55 0.35, 0.76\nDomain 4: synthesis and findings\n 4.1 31 0.60 0.46, 0.74\n 4.2 29 0.48 0.28, 0.68\n 4.3 31 0.77 0.66, 0.88\n 4.4 31 0.18 − 0.02, 0.37\n 4.5 30 0.22 0.02, 0.43\n 4.6 31 0.39 0.17, 0.62\n Domain 4 Concerns regarding the synthesis and findings 31 0.17 − 0.03, 0.37\nRisk of bias in the review\n A 31 0.28 0.09, 0.47\n B 31 0.64 0.54, 0.75\n C 31 0.45 0.31, 0.60\n ROB 31 0.45 0.24, 0.66\nPage 12 of 20Perry et al. Syst Rev          (2021) 10:273 \nSummary of the findings on Inter‑rater reliability For \nROBIS, there were 734 comparisons considered for the \n24 questions. The median agreement for all questions \nwas 0.61. Eleven of the 24 ROBIS questions had substan -\ntial agreement or higher. Ratings were missing in 9 cases. \nAt least one rater said “no information” in 159 compari -\nsons. Rater 1 used “no information” 73 times; rater 2, 50 \ntimes; and rater 3, 93 times. In 107 comparisons only \none rater said “no information” and the raters all agreed \nonly in 10 comparisons. “No information” was used most \nfrequently for question 1.1 (did the review adhere to pre-\ndefined objectives and eligibility criteria? 23 studies), \nquestion 4.2 (were all pre-defined analyses reported or \ndepartures explained? 22 studies) and question 4.5 (were \nthe findings robust, e.g., as demonstrated through funnel \nplot or sensitivity analyses? 16 studies). The agreement \nwas “moderate” for domains 1 (0.45) and 3 (0.36) and for \nthe overall risk of bias (0.45). The agreement for domains \n2 and 4 were “fair” (0.36) and “slight” (0.17), respectively. \nThe results are summarised in Fig. 2.\nGwet’s AC2 statistic was used for the ROBIS questions \n(filled markers) and Gwet’s AC1 statistic was used for the \nROBIS domains (hollow markers). The error bars repre -\nsent the 95% confidence intervals. The italicised data rep-\nresent the median value for all ROBIS questions.\nFurther information on the separate reviews can be \nfound in the appendix (Tables 8 and 12). The median IRR \nagreement for all ROBIS questions for FM is 0.55 and for \ncolic is 0.63.\nSection 3: Usability of the tools\nAll three raters felt AMSTAR-2 was more straightforward \nand user-friendly than ROBIS. This might be because \nit does not require expertise in systematic reviewing to \ncomplete this tool, just knowledge of trial design.\nSeveral issues arose from using the ROBIS tool as it \nrequired more consideration to complete. Within each \ndomain, each question had five possible responses (yes, \nprobably yes, probably no, no, no information), although \nat times it was difficult to distinguish between yes/proba -\nbly yes and no/probably no. It also might be more helpful \nto have a choice of “no concerns/minor concerns/ major \nconcerns/considerable concerns” , instead of “low/high/\nunclear” judgements that are currently at the end of each \ndomain when assessing the overall judgement of con -\ncerns. Although there were perceived differences in the \nindividual answers to each signalling question between \nreviewers, the overall rating of the domains was more \nconsistent. Overall, domains 1–3 were easier to follow \nand score.\nThe most difficult domain to score was domain 4 which \ncovers “synthesis of evidence” . This was reflected in the \nlowest agreement between raters (0.17). We found that \nthis domain is currently better designed for a review with \na meta-analysis, rather than a narrative synthesis. The \nFig. 2 Gwet’s statistic for the inter-rater agreement for ROBIS questions and domains\nPage 13 of 20\nPerry et al. Syst Rev          (2021) 10:273 \n \nguidance document that accompanies the tool is long \nand difficult to navigate. On the plus side, despite having \nsubjective opinions (within each domain there was vari -\nation between the reviewers’ responses to the signalling \nquestions), you can still end with a moderately consistent \noverall result (0.45).\nThe ROBIS tool provides an overall sense of risk of \nbias of the review. There is better coverage overall than \nAMSTAR-2 and more precision with the use of a final \nrating. From our observations only, higher quality \nreviews were quicker to appraise. In our analysis, the “no \ninformation” rating for ROBIS questions was treated as \nmissing. The raters rarely agreed on when to use this rat -\ning. In most cases, when one rater reported “no informa -\ntion” for a ROBIS question, the other two raters gave a \ndifferent rating.\nSeveral issues arose from using AMSTAR-2. Some -\ntimes, the raters would have opted for a “partially yes” \noption when only a binary option (yes/no) was available \n(Q13, Q14, Q16). Also, some questions were ambigu -\nous; in particular, Q3 asks if authors explain their selec -\ntion of study design (e.g., use of RCTs/non RCTs); some \nreviews merely report they included RCTs rather than \njustifying their selection, which caused discrepancies \nbetween raters.\nAlso, some questions might elicit a different response \ndepending on the outcome, e.g., Q13 (whether risk of \nbias was discussed/interpreted within the results), which \nmay vary depending on whether there were multiple \noutcomes, and thus, which outcome is being referred to.\nThe raters also felt it would be helpful to have a for -\nmal space to add comments to justify their decision \nto help with discussions, as in the more ambiguous \nreviews; decisions were more open to interpretation. \nROBIS, on the other hand, has a large section where \nthe reviewer is expected to add selected text to support \ntheir decision.\nRegarding completion timings, we were able to estab -\nlish how long it took to complete both tools for one of \nthe overviews (colic). There was little difference in tim -\nings between rater 1 and 2 to complete both tools; in fact, \nit took rater 2 slightly longer to complete AMSTAR-2 \nthan ROBIS which is surprising, considering the issues \nreported above. However, rater 3 took considerably \nlonger to complete ROBIS than AMSTAR-2 (see Table 6).\nRater 3 was the most experienced reviewer and helped \ndevelop the ROBIS tool. They spent longer on bringing \nthe evidence forward from the individual reviews into the \nROBIS extraction form as recommended by the guidance \ndocument, whereas the other two raters only wrote cur -\nsory notes.\nIt is important to highlight that it is advised in the ROBIS \nguidance document that it is a tool aimed at experienced \nsystematic reviewers and methodologists. We would agree \nwith this recommendation but recognise that this is not \noften the case in many groups undertaking reviews.\nDiscussion\nSummary of findings\nThe median inter-rater reliability (IRR) agreement for \nboth AMSTAR-2 and ROBIS questions was substan -\ntial: 50% of AMSTAR-2 questions and 46% of ROBIS \nquestions had substantial agreement or higher. For \nAMSTAR-2, 460 comparisons were included in the \nanalysis. The median agreement for all questions was \n0.61. For ROBIS, there were 734 comparisons consid -\nered for the 24 questions. The median agreement for all \nTable 6 Mean (SD) completion time (in minutes) for colic paper\nRater 1 Rater 2 Rater 3\nn Mean (SD) n Mean (SD) n Mean (SD)\nAMSTAR‑2 14 13.0 (5.2) 15 18.7 (6.6) 16 11.1 (4.2)\nROBIS 9 14.1 (6.5) 10 15.7 (5.3) 15 43.3 (23.3)\nTable 7 Results of AMSTAR-2 for CAM for fibromyalgia reviews\nTwenty missing ratings. Italicised areas are considered the critical questions\nQuestion No. of studies Gwet’s AC1/\nGwet’s AC2\n95% CI p‑value\n1 15 0.66 0.32, 1.00 0.001\n2 15 1.00\n3 15 0.39 − 0.08, 0.86 0.096\n4 15 0.74 0.55, 0.93 < 0.001\n5 15 0.69 0.33, 1.00 0.001\n6 15 0.65 0.26, 1.00 0.003\n7 15 1.00\n8 15 0.20 0.02, 0.38 0.031\n9 15 0.37 0.16, 0.59 0.002\n10 15 1.00 0.85, 1.00 < 0.001\n11 7 0.66 0.01, 1.00 0.047\n12 7 0.52 − 0.11, 1.00 0.091\n13 15 0.62 0.26, 0.98 0.002\n14 15 0.20 − 0.17, 0.57 0.270\n15 7 0.70 0.10, 1.00 0.029\n16 15 0.55 0.14, 0.96 0.013\nPage 14 of 20Perry et al. Syst Rev          (2021) 10:273 \nquestions was also 0.61. It is interesting that the median \nIRR agreement for both tools was 0.61, demonstrating a \nsimilar level of rating between the two scales.\nResults were similar when conducting the analysis for \nfibromyalgia and colic reviews separately (see appendix  \nfor independent overview results). For fibromyalgia, the \nmedian IRR value was 0.66 for the AMSTAR-2 ques -\ntions compared to 0.56 for the ROBIS questions. For the \ncolic studies both AMSTAR-2 and ROBIS had a similar \nmedian (0.60 for AMSTAR-2 and 0.63 for ROBIS).\nIt must also be considered that the ROBIS questions \ninclude more categories than most of the AMSTAR-2 \nquestions. Most AMSTAR-2 questions are binary. Inter-\nrater agreement tends to be lower when there are more \ncategories, as there are more possibilities for disagree -\nment. Similarly, ROBIS includes more questions than \nAMSTAR-2 which can also result in more disagree -\nment. However, despite these differences, the median \nagreement was the same for the AMSTAR-2 and ROBIS \nquestions.\nTable 8 Inter-rater agreement\nSix ratings missing\nROBIS question No. of studies Gwet’s AC1/\nGwet’s AC2\n95% CI p‑value\nDomain 1: study eligibility criteria\n 1.1 14 0.73 0.46, 1.00 < 0.001\n 1.2 15 0.70 0.45, 0.95 < 0.001\n 1.3 15 0.62 0.39, 0.84 < 0.001\n 1.4 15 0.54 0.32, 0.76 < 0.001\n 1.5 15 0.64 0.40, 0.88 < 0.001\n Domain 1Concerns regarding specification of study eligibility criteria 15 0.61 0.29, 0.92 0.001\nDomain 2: identification and selection of studies\n 2.1 15 0.53 0.36, 0.69 < 0.001\n 2.2 14 0.42 0.16, 0.69 0.005\n 2.3 15 0.72 0.53, 0.92 < 0.001\n 2.4 15 0.31 − 0.08, 0.70 0.110\n 2.5 15 0.56 0.14, 0.99 0.013\n Domain 2Concerns regarding methods used to identify and/or select studies 15 0.29 0.03, 0.55 0.031\nDomain 3: data collection and study appraisal\n 3.1 15 0.95 0.66, 1.00 < 0.001\n 3.2 15 0.65 0.47, 0.84 < 0.001\n 3.3 15 0.57 0.40, 0.74 < 0.001\n 3.4 15 0.55 0.23, 0.88 0.003\n 3.5 15 0.81 0.51, 1.00 < 0.001\n Domain 3Concerns regarding methods used to collect data and appraise studies 15 0.52 0.19, 0.83 0.004\nDomain 4: synthesis and findings\n 4.1 15 0.55 0.33, 0.77 < 0.001\n 4.2 13 0.55 0.29, 0.81 0.001\n 4.3 15 0.80 0.62, 0.98 < 0.001\n 4.4 15 0.13 − 0.19, 0.45 0.405\n 4.5 14 − 0.10 − 0.52, 0.33 0.633\n 4.6 15 0.23 − 0.17, 0.64 0.235\n Domain 4Concerns regarding the synthesis and findings 15 0.18 − 0.08, 0.44 0.154\nRisk of bias in the review\n A 15 0.10 − 0.25, 0.44 0.552\n B 15 0.61 0.40, 0.83 < 0.001\n C 15 0.39 0.01, 0.76 0.009\n ROB 15 0.43 0.10, 0.77 0.015\nPage 15 of 20\nPerry et al. Syst Rev          (2021) 10:273 \n \nUsability of the tools\nSeveral issues arose when using the ROBIS tool as it \nrequired more consideration to complete, which could \nbecome problematic in a large review. All three raters felt \nAMSTAR-2 was more straightforward and user-friendly \nthan ROBIS. This might be because it does not require \nexpertise in systematic reviewing to complete this tool, \njust knowledge of trial design.\nAMSTAR-2 was considered quicker to work through \nthan ROBIS, yet the median timings demonstrated only \na slight increase in timing on AMSTAR-2 than ROBIS \nin two raters, although one rater did take considerably \nlonger on ROBIS than AMSTAR-2. All raters felt domain \n4 of ROBIS was particularly difficult to complete if there \nwas no meta-analysis. Domain 4 would benefit from fur -\nther development in order to assess reviews without a \nmeta-analysis, as in some ways it is biassed against these \ntypes of reviews.\nRelationship to background research\nPrevious research [7 , 8] compared four raters’ assess -\nments across 30 systematic reviews. They calculated \nthe IRR using the Fleiss’ k  [45]. The IRR for scoring the \noverall confidence in the SRs with AMSTAR-2 was fair \n(AMSTAR-2: κ = 0.30; 95% [confidence interval] CI, 0.17 \nto 0.43). The overall domain in ROBIS was fair (ROBIS: κ \n= 0.28; 95% CI, 0.13 to 0.42). Interestingly, for the over -\nall rating, AMSTAR-2 showed a high concordance with \nROBIS and a lower concordance with AMSTAR.\nWe were unable to directly compare our results \nagainst Pieper’s work, as the Fleiss’ kappa ignores the \norder of the categories (when there are more than two \ncategories), which is why we used Gwet’s as it takes \nthe order into account and allows for “partial agree -\nment” . Also, Gwet scores tend to be higher than Fleiss \nscores in general, which makes comparisons difficult to \nconduct.\nIn Pieper et  al. ’s [7] study, ROBIS was always applied \nafter AMSTAR-2, and the mean time for scoring \nAMSTAR-2 was slightly higher than for ROBIS (18 vs. \n16 min), with huge variation between the reviewers, \nwhereas in our study, the overall mean time (calculated \nfor colic reviews only) was slightly higher for ROBIS \nTable 9 The risk of bias and study quality for each fibromyalgia \nreview\nWhen AMSTAR-2 is low, this should correspond to ROBIS being of high risk of \nbias. The italicised reviews show discrepancies between the overall rating of \nquality/bias\nFibromyalgia AMSTAR‑2 ROBIS\nMultiple CAM therapies\n Holdcraft 2003 [14] CL Low\n Baronowsky 2009 [15] CL High\n Terhorst 2011, 2012 [16, 17] CL High\n De Silva 2010 [18] CL High\nHomoeopathy\n Perry 2010 [19] CL Low\n Boehm 2014 [20] CL High\nChiropractic treatment\n Ernst 2009 [21] CL Unclear\nAcupuncture\n Mayhew and Ernst 2007 [22] CL Low\n Daya 2007 [23] CL Low\n Langhorst 2010 [24] CL Low\n Martin-Sanchez 2009 [25] CL High\n Cao 2013 [26] CL Low\n Deare 2013 [13] LOW Low\n Yang 2014 [27] CL High\nHerbal medicines\n de Souza Nascimento 2013 [28] CL Low\nTable 10 To compare the distribution of risk of bias and study \nquality for the fibromyalgia reviews\nROBIS\nAMSTAR‑2 High Low Unclear\nHigh 0 0 0\nModerate 0 0 0\nLow 0 1 0\nCritical 6 7 1\nTable 11 Inter-rater agreement\nFifteen missing ratings. Italicised areas are considered the critical questions\nQuestion No. of studies Gwet’s AC1/\nGwet’s AC2\n95% CI p‑value\n1 16 0.73 0.43, 1.00 < 0.001\n2 16 0.83 0.64, 1.00 < 0.001\n3 16 0.68 0.40, 0.96 < 0.001\n4 16 0.58 0.34, 0.83 < 0.001\n5 16 0.72 0.38, 1.00 < 0.001\n6 16 0.56 0.18, 0.95 0.006\n7 16 0.91 0.81, 1.00 < 0.001\n8 16 0.61 0.35, 0.87 < 0.001\n9 16 0.87 0.69, 1.00 < 0.001\n10 16 0.67 0.36, 0.97 < 0.001\n11 12 0.49 0.02, 0.96 0.042\n12 12 0.34 − 0.12, 0.80 0.133\n13 16 0.43 0.03, 0.84 0.038\n14 16 0.22 − 0.23, 0.66 0.321\n15 12 0.58 0.16, 0.99 0.011\n16 16 0.15 − 0.25, 0.55 0.444\nPage 16 of 20Perry et al. Syst Rev          (2021) 10:273 \nthan for AMSTAR-2 (24.4 min compared to 14.3 min), \nalthough the mean ROBIS result was largely influenced \nby one rater.\nPotential bias in the overview process\nOne author evaluated their own work using \nAMSTAR-2 and ROBIS (RP: [19, 29]), although this \nwork was also independently assessed by two other \nreviewers (VL, PD). In addition, one of the develop -\ners of ROBIS (PD) applied the ROBIS tool to assess the \nincluded reviews.\nWe had not planned to complete an IRR assessment \nof the two scales whilst completing these two overviews \nof reviews; therefore, we did not apply strict criteria to \nour assessment schedule, i.e., we did not apply the tools \nin any particular order. We also did not complete tim -\nings for some of our assessments in a systematic way.\nAnother issue is we compared our ratings over time, \ni.e., a batch of five papers were discussed before the \nnext batch was assessed; this is likely to have led to \ngreater consistency between the raters over time, but \nour numbers were too small to check this.\nTable 12 Inter-rater agreement\nThree ratings missing\nROBIS question No. of studies Gwet’s AC1/\nGwet’s AC2\n95% CI p‑value\nDomain 1: study eligibility criteria\n 1.1 16 0.57 0.17, 0.96 0.008\n 1.2 16 0.71 0.55, 0.87 < 0.001\n 1.3 16 0.76 0.61, 0.91 < 0.001\n 1.4 16 0.71 0.54, 0.87 < 0.001\n 1.5 16 0.49 0.20, 0.77 0.002\n Domain 1Concerns regarding specification of study eligibility criteria 16 0.30 − 0.03, 0.63 0.072\nDomain 2: identification and selection of studies\n 2.1 16 0.54 0.34, 0.73 < 0.001\n 2.2 16 0.64 0.37, 0.92 < 0.001\n 2.3 16 0.57 0.34, 0.81 < 0.001\n 2.4 16 0.50 0.27, 0.73 < 0.001\n 2.5 14 0.61 0.18, 1.00 < 0.001\n Domain 2Concerns regarding methods used to identify and/or select studies 16 0.43 0.13, 0.73 0.008\nDomain 3: data collection and study appraisal\n 3.1 14 0.82 0.51, 1.00 < 0.001\n 3.2 16 0.70 0.44, 0.96 < 0.001\n 3.3 16 0.72 0.52, 0.92 < 0.001\n 3.4 16 0.92 0.83, 1.00 < 0.001\n 3.5 15 0.66 0.21, 1.00 0.007\n Domain 3Concerns regarding methods used to collect data and appraise studies 16 0.61 0.32, 0.89 < 0.001\nDomain 4: synthesis and findings\n 4.1 16 0.65 0.45, 0.86 < 0.001\n 4.2 16 0.42 0.11, 0.73 0.011\n 4.3 16 0.73 0.58, 0.88 < 0.001\n 4.4 16 0.23 − 0.02, 0.48 0.072\n 4.5 16 0.40 0.22, 0.57 < 0.001\n 4.6 16 0.55 0.32, 0.77 < 0.001\n Domain 4Concerns regarding the synthesis and findings 16 0.17 − 0.17, 0.50 0.305\nRisk of bias in the review\n A 16 0.47 0.28, 0.65 0.015\n B 16 0.69 0.55, 0.82 < 0.001\n C 16 0.54 0.37, 0.72 < 0.001\n ROB 16 0.47 0.17, 0.77 0.004\nPage 17 of 20\nPerry et al. Syst Rev          (2021) 10:273 \n \nConclusion\nIn terms of quality assessment, ROBIS is an effective \ntool for assessing risk of bias in a systematic review but \nis more difficult to use compared to AMSTAR-2. It is \nmore complex to work through, which might be prob -\nlematic in a large review. As suggested by the develop -\ners of ROBIS; it is best used by experienced systematic \nreviewers/methodologists. Reviews that included a \nmeta-analysis were easier to rate, however, further \ndevelopmental work could improve its use in sys -\ntematic reviews without a meta-analysis. AMSTAR-2 \nwas more user-friendly and was effective at measur -\ning quality of a review but was a less sophisticated \ntool. Both tools could do with minor changes to help \nimprove their useability for people conducting system -\natic reviews.\nAppendix\nResults of AMSTAR‑2 for CAM for fibromyalgia reviews\nThe inter-rater agreement between the three raters is \nshown in Table 7 .\nResults of ROBIS: CAM for fibromyalgia\nThe summary of results of ROBIS for fibromyalgia can \nbe seen in Table 8 .\nInter‑rater agreement for fibromyalgia\nFor AMSTAR-2, 10 out of 16 (62.5%) questions had \nsubstantial agreement or higher between reviewers. \nThere was perfect agreement for questions 2 (did the \nreport of the review contain an explicit statement that \nthe review methods were established prior to the con -\nduct of the review and did the report justify any signifi -\ncant deviations from the protocol?), 7 (did the review \nauthors provide a list of excluded studies and justify \nthe exclusions?) and 10 (did the review authors report \nTable 13 The risk of bias and study quality for each colic review\nWhen AMSTAR-2 is low, this should correspond to ROBIS being of high risk of \nbias. The italicised reviews show discrepancies between the overall rating of \nquality/bias\nColic AMSTAR‑2 ROBIS\nMultiple CAM therapies\n Perry 2011 [29] Low Low\n Bruyas-Bertholon 2012 [30] CL High\n Harb 2016 [31] CL High\n Gutierrez-Castrellon 2017 [32] CL High\nManipulation therapies\n Dobson 2012 [33] High Low\n Gleberzon 2012 [34] CL High\n Carnes 2017 [35] CL Unclear\nAcupuncture\n Skejeie 2018 [36] Low Unclear\nHerbal medicine\n Anheyer 2017 [37] CL High\nProbiotics\n Sung 2013 [38] CL Unclear\n Anabrees 2013 [39] Low Low\n Urbanska 2014 [40] CL High\n Xu 2015 [41] CL Low\n Schreck Bird 2017 [42] CL High\n Dryl 2018 [43] CL High\n Sung 2018 [44] LOW Unclear\nTable 14 To compare the distribution of risk of bias and study \nquality for the fibromyalgia reviews\nROBIS\nAMSTAR‑2 High Low Unclear\nHigh 0 1 0\nModerate 0 0 0\nLow 0 2 1\nCritical 8 1 3\nTable 15 Criteria for assessing confidence in AMSTAR-2 (Shea et al. [20])\n*Multiple non-critical weaknesses may diminish confidence in the review and it may be appropriate to move the overall appraisal down from moderate to low \nconfidence\nRating overall confidence in the results of the review\n    1. High\n        (a) No or one non-critical weakness. The systematic review provides an accurate and comprehensive summary of the results of the available studies \nthat address the question of interest\n    2. Moderate\n        (a) More than one non-critical weakness*. The systematic review has more than one weakness but no critical flaws. It may provide an accurate sum-\nmary of the results of the available studies that were included in the review\n    3. Low\n        (a) One critical flaw with or without non-critical weaknesses. The review has a critical flaw and may not provide an accurate and comprehensive \nsummary of the available studies that address the question of interest\n    4. Critically low\n        (a) More than one critical flaw with or without non-critical weaknesses. The review has more than one critical flaw and should not be relied on to \nprovide an accurate and comprehensive summary of the available studies\nPage 18 of 20Perry et al. Syst Rev          (2021) 10:273 \non the sources of funding for the studies included in \nthe review?). The median agreement for all questions \nwas 0.65. Ratings from a reviewer were missing in 20 \ninstances overall.\nTen out of 24 (41.7%) questions for ROBIS had \nat least substantial agreement. Questions 3.1 (were \nefforts made to minimise error in data collection?) \nand 3.5 (were efforts made to minimise error in risk \nof bias assessment?) had almost perfect agreement. \nThe median agreement for all questions was 0.55. The \nagreement was different for each ROBIS domain with \nsubstantial being the highest agreement (for missing \nin 6 instances). The raters gave a rating of “no infor -\nmation” in 93 cases. In most of these cases (65), the \nother two raters gave a different rating. There were 5 \ninstances where all reviewers reported “no informa -\ntion” . The most common questions for “no information” \nwere questions 1.1 (did the review adhere to pre-\ndefined objectives and eligibility criteria? 13 times), 4.2 \n(were all pre-defined analyses reported or departures \nexplained? 13 times) and 4.5 (were the findings robust, \ne.g. as demonstrated through funnel plot or sensitivity \nanalyses? 11 times) .\nTables 9 and 10\nResults of AMSTAR‑2: CAM for colic\nThe inter-rater agreement between the three raters is \nshown in Table 11.\nResults of ROBIS: CAM for colic\nThe inter-rater agreement between the three raters is \nshown in Table 12\nInter‑rater agreement for colic\nEight of 16 (50%) AMSTAR-2 questions had substan -\ntial agreement or higher. There was almost perfect \nagreement for questions 2 (did the report of the review \ncontain an explicit statement that the review methods \nwere established prior to the conduct of the review and \ndid the report justify any significant deviations from \nthe protocol?), 7 (did the review authors provide a list \nof excluded studies and justify the exclusions?) and \n9 (did the review authors use a satisfactory technique \nfor assessing the risk of bias (RoB) in individual studies \nthat were included in the review?). The median score \nfor all questions was 0.60. Ratings from a reviewer were \nmissing in 15 instances overall.\nThirteen of 24 (54.2%) ROBIS questions had sub -\nstantial agreement or higher. There was almost per -\nfect agreement for questions 3.1 (were efforts made to \nminimise error in data collection?) and 3.4 (was risk \nof bias (or methodological quality) formally assessed \nusing appropriate criteria?). The median score for all \nquestions was 0.63. The agreement was different for \neach ROBIS domain with substantial being the highest \nagreement (for domain 3). The agreement for the risk \nof bias was moderate. Ratings from a reviewer were \nmissing in 3 instances. There were 66 ratings of “no \ninformation” . There were 3 instances where the review -\ners were in agreement. In 42 cases, only one reviewer \nsaid “no information” . The most common questions \nwere questions 1.1 (did the review adhere to pre-\ndefined objectives and eligibility criteria? 10 times), \n3.5 (were efforts made to minimise error in risk of \nbias assessment? 8 times) and 4.2 (were all pre-defined \nanalyses reported or departures explained? 9 times).\nTables 13, 14 and 15\nAbbreviations\nCAM: Complementary and alternative medicine; AMSTAR : Assessment of \nMultiple Systematic Reviews; PICO: Population, intervention, control group, \noutcome; ROBIS: Risk of Bias in Systematic reviews; IRR: Inter-rater reliability.\nAcknowledgements\nWe thank Professor Rachel Churchill for the initial idea to compare the two \nassessment tools and Dr Chris Penfold for checking domain 4 in the ROBIS \ntool.\nAuthors’ contributions\nRP assessed all papers using AMSTAR-2 and ROBIS and contributed to the \npaper. PD assessed all papers using AMSTAR-2 and ROBIS and contributed to \nthe paper. VL assessed all papers using AMSTAR-2 and ROBIS and contributed \nto the paper. AW conducted the inter-rater reliability analyses and contributed \nto the paper. The authors read and approved the final manuscript.\nFunding\nThe work of RP and AW was funded by National Institutes of Health Research \n(NIHR) Biomedical Research Centre at the University Hospitals Bristol and \nWeston NHS Foundation Trust. Philippa Davies’ time was supported by the \nNational Institute for Health Research Applied Research Collaboration West \n(NIHR ARC West) at University Hospitals Bristol NHS Foundation Trust.\nThe views expressed are those of the authors and not necessarily those of the \nNHS, the NIHR or the Department of Health.\nAvailability of data and materials\nNot relevant.\nDeclarations\nEthics approval and consent to participate\nNot relevant.\nCompeting interests\nRachel Perry was an author on two of the papers under review. Philippa Davies \nwas involved in the development of ROBIS. The other authors declare that \nthey have no competing interests.\nAuthor details\n1 National Institute for Health Research Bristol Biomedical Research Centre, \nUniversity Hospitals Bristol and Weston NHS Foundation Trust and University \nof Bristol, Bristol, UK. 2 The National Institute for Health Research Applied \nResearch Collaboration West (NIHR ARC West) at University Hospitals Bristol \nNHS Foundation Trust, Bristol, UK. 3 Population Health Sciences, Bristol Medical \nSchool, University of Bristol, Bristol, UK. \nPage 19 of 20\nPerry et al. Syst Rev          (2021) 10:273 \n \nReceived: 8 March 2021   Accepted: 16 September 2021\nReferences\n 1. Murad H, Asi N, Alsawas M. New evidence pyramid. BMJ Evid Based Med. \n2016;21:125–7.\n 2. Shea BJ, Grimshaw JM, Wells GA, Boers M, Andersson N, Hamel C, et al. \nDevelopment of AMSTAR: a measurement tool to assess the meth-\nodological quality of systematic reviews. BMC Med Res Methodol. \n2007;15(7):10.\n 3. Shea BJ, Hamel C, Wells GA, Bouter LM, Kristjansson E, Grimshaw J, et al. \nAMSTAR is a reliable and valid measurement tool to assess the methodo-\nlogical quality of systematic reviews. J Clin Epidemiol. 2009;62:1013–20.\n 4. Burda BU, Holmer HK, Norris SL. Limitations of A Measurement Tool to \nAssess Systematic Reviews (AMSTAR) and suggestions for improvement. \nSyst Rev. 2016;5:58.\n 5. Shea BJ, Reeves BC, Wells G, Thuku M, Hamel C, Moran J, et al. AMSTAR 2: \na critical appraisal tool for systematic reviews that include randomised \nor non-randomised studies of healthcare interventions, or both. BMJ. \n2017;358:j4008.\n 6. Whiting P , Savović J, Higgins JP , Caldwell DM, Reeves BC, Shea B, et al. \nROBIS group. ROBIS: a new tool to assess risk of bias in systematic reviews \nwas developed. J Clin Epidemiol. 2016;69:225–34.\n 7. Pieper D, Puljak L, González-Lorenzo M, Minozzi S. Minor differences were \nfound between AMSTAR 2 and ROBIS in the assessment of systematic \nreviews including both randomized and nonrandomized studies. J Clin \nEpidemiol. 2019;108:26–33.\n 8. Lorenz RC, Matthias K, Pieper D, Wegewitz U, Morche J, Nocon M, et al. A \npsychometric study found AMSTAR-2 to be a valid and moderately reli-\nable appraisal tool. J Clin Epidemiol. 2019;114:133–40.\n 9. Perry R, Leach V, Davies P , Penfold C, Ness A, Churchill R. An overview \nof systematic reviews of complementary and alternative therapies for \nfibromyalgia using both AMSTAR and ROBIS as quality assessment tools. \nSyst Rev. 2017;6(1):97.\n 10. Perry R, Leach V, Penfold C, Davies P . An overview of systematic reviews \nof complementary and alternative therapies for infantile colic. Syst Rev. \n2019;8(1):271.\n 11. Gwet KL. Handbook of inter-rater reliability: The definitive guide to \nmeasuring the extent of agreement among raters. 4th ed. Gaithersburg: \nAdvanced Analytics, LLC; 2014.\n 12. Landis JR, Koch GG. The measurement of observer agreement for cat-\negorical data. Biometrics. 1977;33:159–74.\n 13. Deare JC, Zheng Z, Xue CC, Liu JP , Shang J, Scott SW, et al. Acupuncture \nfor treating fibromyalgia. Cochrane Database Syst Rev. 2013;5:CD007070.\n 14. Holdcraft LC, Assefi N, Buchwald D. Complementary and alternative \nmedicine in fibromyalgia and related syndromes. Best Pract Res Clin \nRheumatol. 2003;17(4):667–83.\n 15. Baronowsky J, Klose P , Musial F, Haeuser W, Dobos G, Langhorst J. Qualita-\ntive systematic review of randomised controlled trials on complementary \nand alternative medicine treatments in fibromyalgia. Rhuematol Int. \n2009;30:1–21.\n 16. Terhorst L, Schneider MJ, Kim KH, Goozdich LM, Stilley CS. Complemen-\ntary and alternative medicine in the treatment of pain in fibromyalgia: \na systematic review of randomized controlled trials. J Manipulative \nPhysiol Ther. 2011;34(7):483–96.\n 17. Terhorst L, Schneider M. Complementary and alternative medicine \nin the treatment of pain in fibromyalgia: a systematic review of \nrandomized controlled trials. Portland: From International Research \nCongress on Integrative Medicine and Health; 2012. 15-18 May 2012\n 18. De Silva V, El-Metwally A, Ernst E, Lewith G, Macfarlane GJ. Evidence \nfor the efficacy of complementary and alternative medicines in the \nmanagement of fibromyalgia: a systematic review. Rheumatology. \n2010;49(6):1063–8.\n 19. Perry R, Terry R, Ernst E. A systematic review of homoeopathy for the \ntreatment of fibromyalgia. Clin Rheumatol. 2010;29(5):457–64.\n 20. Boehm K, Raak C, Cramer H, Lauche R, Ostermann T. Homeopathy in \nthe treatment of fibromyalgia--a comprehensive literature-review and \nmeta-analysis. Complement Ther Med.  2014;22(4):731–42.\n 21. Ernst E. Chiropractic treatment for fibromyalgia: a systematic review. Clin \nRheumatol. 2009;28(10):1175–8.\n 22. Mayhew E, Ernst E. Acupuncture for fibromyalgia--a systematic review of \nrandomized clinical trials. Rheumatology (Oxford). 2007;46(5):801–4.\n 23. Daya S. The efficacy of acupuncture in the treatment of fibromyalgia \nsyndrome. J Acupunct Assoc Chartered Physiother. 2007;(3):35–46.\n 24. Langhorst J, Häuser W, Bernardy K, Lucius H, Settan M, Winkelmann A, \net al. Komplementäre und alternative Verfahren beim Fibromyalgiesyn-\ndrom. Systematische Übersicht, Metaanalyse und Leitlinie. Schwerpunkt. \nSchmerz. 2012;26:311–7.\n 25. Martin-Sanchez E, Torralba E, Díaz-Domínguez E, Barriga A, Martin JL. \nEfficacy of acupuncture for the treatment of fibromyalgia: systematic \nreview and meta-analysis of randomized trials. Open Rheumatol J. \n2009;16(3):25–9.\n 26. Cao H, Li X, Han M, Liu J. Acupoint stimulation for fibromyalgia: a sys-\ntematic review of randomised controlled trials. Evid Based Complement \nAltern Med. 2013;2013:ID 362831.\n 27. Yang B, Yi G, Hong W, Bo C, Zhankui W, Yangyang L, et al. Efficacy of acu-\npuncture on fibromyalgia syndrome: a meta-analysis. J Tradit Chin Med. \n2014;34(4):381–91.\n 28. de Souza Nascimento S, Desantana JM, Nampo FK, et al. Efficacy and \nsafety of medicinal plants or related natural products for fibromy-\nalgia: a systematic review. Evid Based Complement Altern Med. \n2013;2013:10.\n 29. Perry R, Hunt K, Ernst E. Nutritional supplements and other comple-\nmentary medicines for infantile colic: a systematic review. Pediatrics. \n2011;127:720–33.\n 30. Bruyas-Bertholo V, Lachaux A, Dubois J-P , Fourneret P , Letrilliart L. \nQuels traitements pour les coliques du nourrisson. Presse Med. \n2012;41:e404–10.\n 31. Harb T, Matsuyama M, David M, Hill RJ. Infant colic—what works: a \nsystematic review of interventions for breast-fed infants. J Pediatr Gastro-\nenterol Nutr. 2016;62(5):668–86.\n 32. Gutiérrez-Castrellón P , Indrio F, Bolio-Galvis A, et al. Efficacy of Lactobacil-\nlus reuteri DSM 17938 for infantile colic. Systematic review with network \nmeta-analysis. Medicine. 2017;96(51):e9375.\n 33. Dobson D, Lucassen PLBJ, Miller JJ, Vlieger AM, Prescott P , Lewith G. \nManipulative therapies for infantile colic. Cochrane Database Syst Rev. \n2012;(Issue 12):CD004796. https:// doi. org/ 10. 1002/ 14651 858. CD004 796. \npub2.\n 34. Gleberzon BJ, Arts J, Mei A, McManus EL. The use of spinal manipula-\ntive therapy for pediatric health conditions: a systematic review of the \nliterature. J Can Chiropr Assoc. 2012;56(2):128–41.\n 35. Carnes D, Plunkett A, Ellwood J, et al. Manual therapy for unsettled, \ndistressed and excessively crying infants: a systematic review and meta-\nanalyses. BMJ Open. 2018;8:e019040.\n 36. Skjeie H, Skonnord T, Brekke M, Klovning A, Fetveit A, Landgren K, et al. \nAcupuncture treatments for infantile colic: a systematic review and indi-\nvidual patient data meta-analysis of blinding test validated randomised \ncontrolled trials. Scand J Prim Health Care. 2018;36(1):56–69.\n 37. Anheyer D, Frawley J, Koch AK, Lauche R, Langhorst J, Dobos G, et al. \nHerbal medicines for gastrointestinal disorders in children and adoles-\ncents: a systematic review. Pediatrics. 2017;139(6):e20170062.\n 38. Sung V, Collett S, de Gooyer T, et al. Probiotics to prevent or treat exces-\nsive infant crying. JAMA Pediatr. 2013;167(12):1150–7.\n 39. Anabrees J, Indrio F, Paes B, AlFaleh K. Probiotics for infantile colic: a \nsystematic review. BMC Pediatr. 2013;13:186.\n 40. Urbanska M, Szajewska H. The efficacy of Lactobacillus reuteri DSM 17938 \nin infants and children: a review of the current evidence. Eur J Pediatr. \n2014;173:1327–37.\n 41. Xu M, Wang J, Wang N, Sun F, Wang L, Liu XH. The efficacy and safety of \nthe probiotic bacterium Lactobacillus reuteri DSM 17938 for infan-\ntile colic: a meta-analysis of randomized controlled trials. PLoS One. \n2015;10(10):e0141445.\n 42. Schreck Bird A, Gregory PJ, Jalloh MA, Risoldi Cochrane Z, Hein DJ. \nProbiotics for the treatment of infantile colic: a systematic review. J Pharm \nPract. 2017;30(3):366–74.\n 43. Dryl R, Szajewska H. Probiotics for management of infantile colic: \na systematic review of randomized controlled trials. Arch Med Sci. \n2018;14(5):1137–43.\nPage 20 of 20Perry et al. Syst Rev          (2021) 10:273 \n•\n \nfast, convenient online submission\n •\n  \nthorough peer review by experienced researchers in your ﬁeld\n• \n \nrapid publication on acceptance\n• \n \nsupport for research data, including large and complex data types\n•\n  \ngold Open Access which fosters wider collaboration and increased citations \n \nmaximum visibility for your research: over 100M website views per year •\n  At BMC, research is always in progress.\nLearn more biomedcentral.com/submissions\nReady to submit y our researc hReady to submit y our researc h  ?  Choose BMC and benefit fr om: ?  Choose BMC and benefit fr om: \n 44. Sung V, D’Amico F, Cabana MD, Chau K, Koren G, Savino F, et al. \nLactobacillus reuteri to Treat Infant Colic: A Meta-analysis. Pediatrics. \n2017;141(1):e20171811.\n 45. Fleiss JL. Measuring nominal scale agreement among many raters. Psy-\nchol Bull. 1971;76(5):378.\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in pub-\nlished maps and institutional affiliations."
}