{
    "title": "Language Model is Suitable for Correction of Handwritten Mathematical Expressions Recognition",
    "url": "https://openalex.org/W4389523906",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A5046855147",
            "name": "Zui Chen",
            "affiliations": [
                null,
                "ShanghaiTech University"
            ]
        },
        {
            "id": "https://openalex.org/A5029027880",
            "name": "Jiaqi Han",
            "affiliations": [
                null,
                "ShanghaiTech University"
            ]
        },
        {
            "id": "https://openalex.org/A5110612901",
            "name": "Chaofan Yang",
            "affiliations": [
                "ShanghaiTech University"
            ]
        },
        {
            "id": "https://openalex.org/A5058838634",
            "name": "Yi Zhou",
            "affiliations": [
                "University of Science and Technology of China"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3158196282",
        "https://openalex.org/W3201757274",
        "https://openalex.org/W4283803766",
        "https://openalex.org/W2963637207",
        "https://openalex.org/W3046591412",
        "https://openalex.org/W4321276329",
        "https://openalex.org/W4312868947",
        "https://openalex.org/W3181186176",
        "https://openalex.org/W2071291967",
        "https://openalex.org/W3200656485",
        "https://openalex.org/W6908809",
        "https://openalex.org/W4313125865",
        "https://openalex.org/W2623860192",
        "https://openalex.org/W3034447740",
        "https://openalex.org/W1978799108",
        "https://openalex.org/W3212092655",
        "https://openalex.org/W3002575754",
        "https://openalex.org/W1998768285",
        "https://openalex.org/W2806717845",
        "https://openalex.org/W2905413777",
        "https://openalex.org/W2912792574",
        "https://openalex.org/W3013224334",
        "https://openalex.org/W4387294588",
        "https://openalex.org/W4313124688",
        "https://openalex.org/W2157331557",
        "https://openalex.org/W3158751621",
        "https://openalex.org/W1810641085",
        "https://openalex.org/W3198957252",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W3034537864",
        "https://openalex.org/W3004194266",
        "https://openalex.org/W4310335763",
        "https://openalex.org/W3034799230",
        "https://openalex.org/W4200635795",
        "https://openalex.org/W3110178865",
        "https://openalex.org/W4304015090",
        "https://openalex.org/W2757121784",
        "https://openalex.org/W2963446712",
        "https://openalex.org/W2072449446",
        "https://openalex.org/W2965373594",
        "https://openalex.org/W2005079280",
        "https://openalex.org/W2963626623",
        "https://openalex.org/W2626873800"
    ],
    "abstract": "Handwritten mathematical expression recognition (HMER) is a multidisciplinary task that generates LaTeX sequences from images. Existing approaches, employing tree decoders within attention-based encoder-decoder architectures, aim to capture the hierarchical tree structure, but are limited by CFGs and pre-generated triplet data, hindering expandability and neglecting visual ambiguity challenges. This article investigates the distinctive language characteristics of LaTeX mathematical expressions, revealing two key observations: 1) the presence of explicit structural symbols, and 2) the treatment of symbols, particularly letters, as minimal units with context-dependent semantics, representing variables or constants. Rooted in these properties, we propose that language models have the potential to synchronously and complementarily provide both structural and semantic information, making them suitable for correction of HMER. To validate our proposition, we propose an architecture called Recognize and Language Fusion Network (RLFN), which integrates recognition and language features to output corrected sequences while jointly optimizing with a string decoder recognition model. Experiments show that RLFN outperforms existing state-of-the-art methods on the CROHME 2014/2016/2019 datasets.",
    "full_text": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 4057–4068\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nLanguage Model is Suitable for Correction of Handwritten Mathematical\nExpressions Recognition\nZui Chen1,2, Jiaqi Han1,2, Chaofan Yang1, Yi Zhou3\n1Shanghaitech University,\n2Shanghai Innovation Center for Processor Technologies\n3University of Science and Technology of China\n1{chenzui, hanjq2022, yangchf}@shanghaitech.edu.cn\n3yi_zhou@ustc.edu.cn\nAbstract\nHandwritten mathematical expression recogni-\ntion (HMER) is a multidisciplinary task that\ngenerates LaTeX sequences from images. Ex-\nisting approaches, employing tree decoders\nwithin attention-based encoder-decoder archi-\ntectures, aim to capture the hierarchical tree\nstructure, but are limited by CFGs and pre-\ngenerated triplet data, hindering expandabil-\nity and neglecting visual ambiguity challenges.\nThis article investigates the distinctive lan-\nguage characteristics of LaTeX mathematical\nexpressions, revealing two key observations:\n1) the presence of explicit structural symbols,\nand 2) the treatment of symbols as minimal\nunits, each directly assigned specific seman-\ntics. Rooted in these properties, we propose\nthat language models have the potential to syn-\nchronously and complementarily provide both\nstructural and semantic information, making\nthem suitable for correction of HMER. To val-\nidate our proposition, we propose an architec-\nture called Recognition and Language Fusion\nNetwork (RLFN), which integrates recognition\nand language features to output corrected se-\nquences while jointly optimizing with a string\ndecoder recognition model. Experiments show\nthat RLFN outperforms existing state-of-the-\nart methods on the CROHME 2014/2016/2019\ndatasets.1\n1 Introduction\nHandwritten Mathematical Expression Recognition\n(HMER), a demanding subsection of optical char-\nacter recognition (OCR), constitutes an interdisci-\nplinary crossroad of computer vision, pattern recog-\nnition, and natural language processing (NLP). The\nunfolding of deep learning advancements has no-\ntably enhanced the effectiveness of HMER, ush-\nering its adoption in diverse arenas, including in-\ntelligent education. Nonetheless, the precision of\nthese technologies is continuously challenged by\n1https://github.com/Zui-C/RLFN\ninherent ambiguities in handwritten characters and\nthe complexity of mathematical formulas. These\nhurdles underscore the pivotal role that NLP could\nplay in enhancing the robustness of current visual\nmodels grappling with these issues.\nThe encoder-decoder architecture is the preva-\nlent method for HMER, which recasts the prob-\nlem as an image-to-sequence translation task, con-\nverting a handwritten formula image into a LaTeX\nmarkup sequence. In contrast to traditional OCR\ntasks, the two-dimensional structure of handwritten\nformulas necessitates an approach that doesn’t rely\non direct segmentation. Since Zhang et al. (2017)\nintroduces a decoder using RNN with attention,\nsubsequent work has concentrated on enhancing\nthe accuracy of the visual attention (Zhao et al.,\n2021; Bian et al., 2022; Li et al., 2022). Currently,\nvarious tree decoders and methods of syntactic anal-\nysis, such as Zhang et al. (2020) and Yuan et al.\n(2022), are employed to focus on analyzing the\nexpression structure and the relations of symbols.\nWhile structure-focused methods have undeni-\nably enriched recognition model capabilities, they\nhave also precipitated two notable challenges: 1)\nThey rely on complex Context-Free Grammars\n(CFGs), necessitating the pre-transformation of the\nLaTeX markup sequence into specific tuple rep-\nresentations, which limits their extensibility. 2)\nThe issue of visual ambiguity is left behind. Tree\ndecoders pay less attention to context when predict-\ning triples, often unable to distinguish differences\nsuch as ‘2’ and ‘z’. Ung et al. (2021) try to em-\nploy a language model (LM) for post-correction,\nbut Gupta et al. (2021) underline the inherent risk\nof wholly depending on a LM for the correction\nof low-redundancy information, such as numbers,\nwhich is particularly susceptible to biases intro-\nduced by probabilistic skewing.\nHowever, as a formal language designed for\nmathematical structures, LaTeX mathematical ex-\npressions possess unique language characteristics.\n4057\nWe believe that advance structural analysis sepa-\nrately following normal NLP methods may not be\na prerequisite to catch complicated structures of\nLaTeX mathematical expressions.\nTwo key characteristics of LaTeX mathematical\nexpressions are: 1) They have explicit structural\nsymbols. 2) Minimal units are symbols, and they\nare directly assigned specific semantics. Based on\nthis, we propose that LMs can proffer both struc-\ntural and semantic information, making them suit-\nable for correction of HMER. An in-depth theoreti-\ncal and statistical exploration of this perspective is\narticulated in Section 3.\nSpecifically, regarding the current limitations of\nstructure-focused methods, we believe that: 1) The\nstructural information can be represented by struc-\ntural symbols’ semantic with the context provided\nby mathematical notations. This circumvents the\nnecessity for complex CFGs to generate triplet data.\n2) Character ambiguity between different types can\nbe rectified with contexts provided by structural\nsymbols and mathematical notations.\nWe substantiate our propositions through exper-\niments on HMER correction. Specifically, we de-\nploy a math LM to rectify an HMER model reliant\non unstructured-based methods, demonstrating the\nsuitability of LM in addressing current limitations.\nAdditionally, we argue against the sole reliance on\nLMs in a post-correction method. By leveraging\ninformation from the recognition model, we can\nconstrict the correction space.\nFinally, we propose our architecture called\nRecognition and Language Fusion Network\n(RLFN), which integrates recognition and language\nfeature to output correct sequences and optimizes\njointly with the recognition model. Experiments\nshow that RLFN outperforms existing state-of-the-\nart methods and achieves expression recognition\nrates (ExpRate)s of 57.00/54.23/54.13% on the\nCROHME 2014/2016/2019 datasets.\n2 Related works\n2.1 HMER\nMany traditional methods utilize specially designed\ngrammars, including Chan and Yeung (2001) that\nemploy definite clause grammar, MacLean and\nLabahn (2013) that propose a fuzzy relational gram-\nmar for handling ambiguous and non-linear inputs,\nÁlvaro et al. (2014) that apply hidden Markov mod-\nels to CFG, and Noya et al. (2021) that integrate\nhypergraph into CFG prediction. While the above\nmethods treat symbol recognition and structure\nanalysis separately, several global methods aim to\ntackle them simultaneously. Awal et al. (2014) con-\nsider HMER as a simultaneous optimization prob-\nlem encompassing expression recognition, symbol\nrecognition, and structure analysis. Then Álvaro\net al. (2016) further extend the methodology by\nincorporating a 2D-PCFG to integrate stochastic\ninformation from multiple sources.\nEncoder-Decoder based methods are led by\nDeng et al. (2017) and Zhang et al. (2017). Based\non CNN encoder and RNN decoder, Deng et al.\n(2017) design a coarse-to-fine process, while Zhang\net al. (2017) design coverage attention to avoid\nover-parsing and under-parsing. Zhang et al. (2018)\nuse DenseNet (Huang et al., 2017) as encoder and\nintroduce a decoder with multi-scale attention. Wu\net al. (2020) integrate left-to-right attention to sim-\nulate the progressive nature of human perception.\nWang et al. (2019) use multi-modal attention aim\nto fully utilize both online and offline information.\nZhao et al. (2021) replace RNN-based decoder with\na bidirectionally trained transformer, leading to en-\nhance global coverage and parallelization capabil-\nities. Bian et al. (2022) apply mutual learning to\nenhance bidirectional learning and design a multi-\nscale coverage attention for longer expressions.\nSeveral works focus on the tree structure of math\nexpressions. Zhang et al. (2020) regarded the ex-\npression as a tree represented by triples that include\nparent, children, and relation; then designed a tree\ndecoder to predict each triple. Based on this work,\nZhong et al. (2022) expanded prediction of sym-\nbols into attribute prediction and position predic-\ntion, then purposed a transformer-based decoder to\npredict triples. Yuan et al. (2022) utilized grammar\nconstrained attention to transform the whole image\ninto a parse tree. Wu et al. (2022a) added thinking\nattention to tree decoder, assisted by pixel-level\nauxiliary loss to improve recognition of complex\nexpressions. Wu et al. (2022b) designed a structural\nstring representation, attempting to utilize both lan-\nguage model and tree structure. These structured\nrepresentations are specifically designed, limiting\ntheir extensibility.\n2.2 HMER & OCR Correction\nLimited research are done on HMER correction.\nChan and Yeung (2001) detect and correct errors\nbased on grammar and heuristics rules. Ung et al.\n(2021) train and apply a language model for post-\n4058\ncorrection tasks.\nMore correction works are done on OCR. Litman\net al. (2020) repetitively correct recurrent block out-\nputs by fusing it with visual features each step in\ntraining. Other works use LM to assist correction.\nNguyen et al. (2020) use BERT for error detection,\nand then use neural machine translator to correct er-\nrors. Qiao et al. (2020) use the pre-trained FastText\n(Joulin et al., 2017) to supervise the generation of\nsemantic features, fusing it with encoder visual fea-\ntures to capture global semantic information. Gupta\net al. (2021) utilize perplexity of language model\nto choose output among multiple aligned models,\nand stress that correction of numbers requires extra\nreliable information source. Yasunaga et al. (2021)\nadopt unsupervised correction by comparing log-\nits of LM output with local perturbations of the\ntext. Fang et al. (2021, 2023) explicitly use built-in\nbidirectional LM to iteratively correct the output.\nSeveral math LMs are pretrained jointly with\ntext and LaTeX expressions, potentially beneficial\nfor HMER. Novotný and Štefánik (2022) design\nMathBERTa based on RoBERTa (Liu et al., 2019),\nwith a soft vector space model to capture the seman-\ntic similarity between tokens. Peng et al. (2021)\nis designed to improve the prediction of masked\nformula substructures extracted from the Operator\nTree (OPT). Scarlatos and Lan (2023) conduct mul-\ntiple modifications on the GPT-2 (Radford et al.,\n2019) model, resulting in MathGPT, which exhibits\nstrong performance in generating mathematical ex-\npressions. Our method utilizes MathBERTa to pro-\nvide auxiliary information for correction.\n3 Why LM is Suitable for HMER\nCorrection?\n3.1 Theoretical Analysis\nAs a formal language designed specifically for the\nrepresentation of complex mathematical symbols\nand formulas, symbols in LaTeX mathematical ex-\npressions can be broadly divided into four distinct\ncategories: 1) Structural symbols _, ^, {, }, \\{, \\}\n2) Mathematical notations (e.g., \\frac, \\sqrt, +,\n-), 3) Latin and Greek alphabets (e.g., A, a, α), and\n4) Numbers. The key differences from English can\nbe summarized in the following two points:\n1) The structural symbols in LaTeX mathemat-\nical expressions explicitly convey their structure,\nand certain mathematical notions serve to assist in\nthis structural representation. This mechanism of\nstructural representation shares fundamental simi-\nFigure 1: Cases of structural symbols explicitly convey\ntheir structure in the context of mathematical notations.\nLike in English, the same word has different semantics\nin different contexts.\nFigure 2: Cases of the semantic problems within dif-\nferent types of symbols can be found with the structure\nand mathematical notation. Like in English, given the\nsemantic relationship in WordNet, whether these types\nof words are correct or incorrect.\nlarities with the mechanism of how words within\nphrases in English explicitly communicate their se-\nmantics. And this characteristic enables math LMs\nto synchronously provide structural information\njust as they provide semantic information.\nAs figure 1 shows, ‘ \\frac’ and ‘\\sqrt’ repre-\nsent the fraction line and radical symbol itself while\nproviding context. Then the following ‘{’ respec-\ntively represent the beginning of the numerator and\nradicand. In the English case, ‘ parse’ relies on\ndifferent context to express different semantics in\nsentence ‘parse a sentence’ and ‘parse words’.\n2) LaTeX mathematical expressions treat sym-\nbols as minimal semantic units. And based on\ncontextual semantics, visual ambiguities between\ncategories can be corrected. Though using ‘x’ or ‘y’\nas unknown variables has no difference, the seman-\ntic distinction between an unknown variable and\na number is significant. For instance, 2√xis rea-\nsonable, but z√xis not in line with convention. We\nwill represent it as x1/z instead. Similarly, when\nwe trust z, we tend to believe that the expression is\nnot a radical expression.\nFrom the perspective of analogy with English,\nFigure 2 illustrates why different category sym-\nbols in LaTeX mathematical expressions have\nsemantic differences when given structural rela-\ntionships. In English, sentence semantic errors\n4059\ncaused by certain types of words can be detected\nthrough semantic relationships. According to\nWordNet (Fellbaum, 2005) of ‘wheeled vehicle’,\n‘wagon’ and ‘ vehicle’ have an ‘ is-a’ relation\nwith it. While given ‘ has-part’ relationship,\nsemantic errors in sentence ‘ wheeled vehicle\nhas a vehicle ’ can be discovered. Similarly,\nthe symbol ‘[ ]’ represents the ‘root-index’ in\nthe case of ‘ \\sqrt[2]{x}’ and ‘ \\sqrt[3]{x}’.\n‘\\sqrt[z]{x}’ uses an unknown variable as the\n‘root-index’ which is generally unconventional.\nMoreover, words that represent semantic relation-\nships, such as ‘multiply’ and ‘multiplied’, are\nnot explicitly stated in the case of ‘xyz’ and ‘xyx’.\nIn general, given the multiplicand (the left term of\nmultiplication), it’s expected to use an unknown\nnumber as the multiplier, or semantic errors may\noccur in the case of ‘xy2’.\nIn addition to language characteristic that make\nLM suitable for HMER correction, the task itself\nis also suitable. While OCR employs letters as\nthe smallest unit for correcting words, HMER uti-\nlizes symbols as the minimum unit for amending\nexpressions. The former represents morphological\ncorrection, while the latter is semantic correction.\n3.2 Statistical Analysis\nWe conducted statistical analysis as collateral evi-\ndence on the CROHME dataset (Mouchère et al.,\n2014). The CROHME dataset, a byproduct of the\nCompetition on Recognition of Online Handwrit-\nten Mathematical Expressions (CROHME), is uni-\nversally recognized as the principal public dataset\nwithin HMER field. A comprehensive collection,\nthe CROHME training set comprises 8835 hand-\nwritten mathematical expressions. In addition,\nit includes three distinct testing subsets, namely\nCROHME 2014, 2016, and 2019, containing 986,\n1147, and 1199 handwritten mathematical expres-\nsions respectively. Noteworthy is the inclusion of\na total of 111 symbol classes, which encompasses\nthe \"sos\" and \"eos\" symbols.\nThe explicit structural symbols do express\ntheir semantics.This is affirmed via an application\nof the Math-aware BERT model (Reusch et al.,\n2022), where the calculated perplexity acts as an\nindex for semantic strength, applied to those four\ncategories of symbols in CROHME training set.\nIn detail, we engage an individualized masking\noperation, followed by a model prediction of the\nobfuscated symbol. The outcome is a probability\nType SS MN LGA Num Total\nPerplexity 2.905 3.396 3.723 3.282 3.262\nCounts 51030 35112 28275 22267 136684\nCategories 6 39 54 10 109\nTable 1: Perplexity, counts and categories of structural\nsymbols (SS), mathematical notations (MN), latin and\ngreek alphabets (LGA), and numbers (Num).\nType z ↔2 9 ↔q 0 ↔o 9 ↔g 5 ↔s Top 5\ns1→s2 1.926% 2.627% 1.226% 1.576% 0.876% 8.231%\ns2→s1 1.226% 0 1.226% 0.350% 0 2.803%\nTotal 3.152% 2.627% 2.452% 1.927% 0.876% 11.034%\nTable 2: Percentage of top 5 alphabet-number mis-\nrecognition pairs among all SUB1 cases. s1 → s2\nindicates that symbol s1 is mis-recognized as s2.\ndistribution, the reciprocal of which, corresponding\nto the actual word, signifies its perplexity. Subse-\nquently, the mean perplexity, according to category,\nis designated as the perplexity of this particular\ncategory of symbols.\nResults in Table 1 reveal that among the four\ntypes of symbols, the structural symbols exhibit the\nlowest perplexity. This finding aligns with our the-\noretical analysis that the explicit structural symbols\nsuggest a comparatively robust semantic signal.\nThe visual ambiguity between numbers and\nalphabets do exist. We conducted an analysis\nof the results from the string decoder recogni-\ntion model, DWAP (Zhang et al., 2018), using\nthe CROHME 2014/2016/2019 datasets. During\nthis analysis, we employed a reliable metric called\nSubstitute-by-One (SUB1), which identifies cases\nwhere the model’s predictions deviate from the\nground truth by only one substitution. Within the\nSUB1 cases, the mis-recognition of one character\nas another is verified, avoiding character substitu-\ntion indeterminacy in evaluation.\nThe outcomes are shown in Table 2. Among all\nSUB1 instances, the top 5 pairs of mis-recognition\nbetween numbers and alphabets contribute to 11%\nof the total mis-recognition, while the overall mis-\nrecognition between numbers and alphabets con-\ntribute to 26%. These statistical findings highlight\nthat mis-recognition between numbers and letters\nnot only exists considerably but also tends to con-\ncentrate on visual ambiguity. Thus overcoming the\nvisual ambiguity issues as mentioned in theoretical\nanalysis is significant.\n4060\n4 Method\nIn an endeavor to empirically corroborate our\nhypotheses, we propose a novel architecture,\nthe Recognition and Language Fusion Network\n(RLFN), engineered specifically to address the\ndual challenge of visual ambiguity and the com-\nplex structural issues that are inherent to string de-\ncoder recognition models. The RLFN is built with\na string decoder recognition module, a language\nmodule that extracts language information, and a\nfusion module to refine the recognition output by\nutilizing the language information.\n4.1 Recognition Module\nOur recognition module basically follows DWAP\n(Zhang et al., 2018), using DenseNet (Huang et al.,\n2017) to extract visual feature F ∈RH′×W′×D\nfrom the single-channel input image.\nAs shown in Figure 3, each step tin the decoder,\nwe iteratively update two state weights: the GRU\n(Cho et al., 2014) hidden state ht and the coverage\nattention (cumulative attention map) At.\nht = GRU(Eγt−1,ht−1) (1)\net = Wetanh(Fp + WAAt−1 + Whht−1) (2)\nαi,j;t = exp(ei,j;t −maxi,j(ei,j;t))∑\ni,j\nexp(ei,j;t −maxi,j(ei,j;t)) (3)\nAt = At−1 + αt (4)\nHere, et represents the attention score which pro-\nduces the attention map αt, where i,j denote the\ncoordinate on the feature map. Eγt−1 represents\nthe embedding of the last symbol, Fp corresponds\nto the position encoded feature (Parmar et al.,\n2018). We, WA, and Wh represent the trainable\nweights. After that, we generate the content vector\nct with element-wise multiplication of αt with vi-\nsual features F. Then ct is combined with ht and\nembedding of γt−1 to obtain the symbol state st\nand the recognition prediction symbol γt.\nst = Wcct + WγEγt−1 + W′\nhht (5)\nγt = softmax(w⊤st + b) (6)\nWc,Wγ,W′\nh,w,b are trainable weights. Lastly,\nrecognition module outputs the total symbol states\nsas recognition feature FR, along with the recog-\nnition prediction sequence γ.\nFigure 3: Recognition module\n4.2 Language Module\nWe utilize MathBERTa (Novotný and Štefánik,\n2022) to extract language information, which is\na RoBERTa (Liu et al., 2019) model specifically\nfine-tuned on LaTeX expressions.\nAs a variant of BERT (Devlin et al., 2019),\nRoBERTa solely focuses on masked language mod-\neling (MLM) task, uses larger mini-batches and\nemploys dynamic masking, which all contribute to\nimprove bidirectional semantic language modeling.\nBuilding upon RoBERTa, MathBERTa further\nfocuses on language processing of LaTeX expres-\nsions. It undergoes fine-tuning on an extensive\ndataset containing both text and LaTeX expressions.\nThis specialized training enhances MathBERTa’s\ncomprehension of semantic and syntactical proper-\nties of LaTeX mathematical expressions.\nConsidering that our recognition output does not\nneed tokenization, and LaTeX mathematical nota-\ntions are prone to problems, we manually associate\nthe vocabulary with the one-hot encoding in Math-\nBERTa instead of using the tokenizer. Then given\nthe recognition prediction sequence γ, MathBERTa\noutputs the language feature FL.\n4.3 RLFN\nAs shown in Figure 4, in RLFN, the input image is\nsent to recognition module to extract recognition\nfeature and the prediction sequence. The latter\nis passed to language module to form language\nfeature. Both features are fused in fusion module\nto output the corrected prediction sequence.\nThe main objective of the fusion module is to\nintegrate the information from the recognition mod-\nule with the semantic information obtained through\n4061\nFigure 4: Architecture of Recognition and Language\nFusion Network (RLFN)\nthe language module, so as to generate the cor-\nrected prediction sequence.\nIn the fusion module, the recognition feature FR\nand language feature FL are first dimensionally\naligned through linear operation. Then we follow\nYao et al. (2017) to incorporate a gating neuron, de-\nnoted as σ. This neuron allows us to assign weights\nbased on contributions of two features during the\ncalculation of output. Within the gating neuron, the\ntwo aligned features are horizontally concatenated.\nThe resulting concatenated vector is then adjusted\nto match the size of the aligned features. Subse-\nquently, the resized vector is fed into a sigmoid\nfunction to generate weights. These weights are\nthen utilized to modulate the output of the aligned\nfeatures, which are first processed through tanh\nactivation function.\nThe process of generating the corrected sequence\nyin the fusion module is as follows:\nxR = WRFR, x L = WLFL (7)\nz= σ(WF[xR,xL]) (8)\nhR = tanh(xR), h L = tanh(xL) (9)\nh= z·hR + (1−z) ·hL (10)\ny= softmax(w′⊤h+ b′) (11)\nwhere σ refers to sigmoid activation function,\nWR,WL,WF,w′,b′are weights to be learned.\n4.4 Parameter Learning\nWe jointly optimize our RCFN with the recognition\nmodule through a linear classification layer, and\nthe loss function is as follows:\nL= LR + LF (12)\nwhere LR and LF are the cross-entropy loss of the\nrecognition prediction sequence probability and\nthe corrected prediction sequence probability with\nrespect to the ground-truth.\nLR aims to guide the the recognition module and\nthe additional linear classification layer, while LF\nfocus on guiding the fusion of the two features. To\nmitigate the influence of the training set’s proba-\nbility bias and the large number of parameters, we\nhave frozen the language model’s parameters. Fur-\nthermore, gradient separation has been employed\nto enhance the focus of the loss functions on their\nrespective optimization goals within the recogni-\ntion model. Nevertheless, joint optimization still\naffects each other’s updates of problematic parts\nthrough the optimizers and other means.\n5 Experiments\n5.1 Implement Details\nOur RCFN is implemented in PyTorch with a sin-\ngle NVIDIA GeForce RTX 3090. We use Adadelta\noptimizer (Zeiler, 2012) with the learning rate in-\ncreases from 0 to 1 at the first epoch and decays\nto 0 following the cosine schedules (Zhang et al.,\n2019b). No data augmentation for fair compari-\nson. The batch size is set to 8. All images within a\nbatch are filled in the upper left corner of the canvas\nof the same size. Due to memory limitations, the\ncanvas size does not exceed 1280 * 280, and any\nexcess images will be discarded. The total training\nepoch is set to 200 epochs taking around 16 hours.\n4062\nMethod\nCROHME 2014 CROHME 2016 CROHME 2019\nExpRate↑ ≤1 ↑ ≤2 ↑ ExpRate↑ ≤1 ↑ ≤2 ↑ ExpRate↑ ≤1 ↑ ≤2 ↑\nUPV (Mouchère et al., 2014) 37.22 44.22 47.26 - - - - - -\nW AP (Zhang et al., 2017) 46.55 61.16 65.21 44.55 57.10 61.55 - - -\nPAL (Wu et al., 2019) 39.66 56.80 65.11 - - - - - -\nTAP (Zhang et al., 2019a) 48.47 63.28 67.34 44.81 59.72 62.77 - - -\nDW AP (Zhang et al., 2018) 50.10 - - 47.50 - - - - -\nMAN (Wang et al., 2019) 54.05 68.76 72.21 50.56 64.78 67.13 - - -\nPAL-V2 (Wu et al., 2020) 48.88 64.50 69.78 49.61 64.08 70.27 - - -\nRBR (Truong et al., 2020) 53.40 65.20 70.30 52.10 63.20 69.40 53.10 63.90 68.50\nDLA (Le, 2020) 49.85 - - 47.34 - - - - -\nDW AP-TD (Zhang et al., 2020) 49.10 64.20 67.80 48.50 62.30 65.30 51.40 66.10 69.10\nWS-W AP (Truong et al., 2020) 53.65 - - 51.96 64.34 70.10 - - -\nBTTR (Zhao et al., 2021) 53.96 66.02 70.28 52.31 63.90 68.61 52.96 65.97 69.14\nABM (Bian et al., 2022) 56.85 73.73 81.24 52.92 69.66 78.73 53.96 71.06 78.65\nSAN (Yuan et al., 2022) 56.20 72.60 79.20 53.60 69.60 76.80 53.50 69.30 70.10\nGPT-4V (Yang et al., 2023) 31.85 49.09 60.45 - - - - - -\nDW AP (Baseline)† 51.72 69.47 77.99 48.82 67.13 75.41 50.79 69.64 76.81\nRLFN-DW AP (Ours) 57.00 72.01 80.73 54.23 70.10 78.47 54.13 72.56 80.07\nTable 3: Results on the CROHME dataset without any data augmentation. †indicates that we reproduce DW AP as\nshown in figure 3. RLFN-DW AP represents we take the reproduced DW AP as our recognition module.\n5.2 Evaluation\nThe metric of expression recognition rate (Ex-\npRate) is utilized, defined as the proportion of accu-\nrately recognized expressions. Additional measure-\nments, denoted as ≤1 and ≤2, are also employed,\nwhere the ExpRate accommodates at most one or\ntwo symbol-level errors, respectively.\nWe experiment on CROHME datasets mentioned\nin Section 3.1. Consistent with previous methods,\nwe use CROHME 2014 as the validation set and\ntest on CROHME 2016 and 2019 to compare with\nprevious state-of-the-art (SOTA) methods.\nAs shown in Table 3, we take the reconstructed\nDWAP as our baseline. And our RLFN-DWAP\nusing it as the recognition module achieves SOTA\non the ExpRate indicator. In addition, it can be ob-\nserved that the improvement of model on ExpRate\nis higher than on ≤1 or ≤2, which is consistent\nwith the intuition that sentences with fewer errors\nhave more complete semantics information.\nInspired by the LaTeX code generation capa-\nbility reported in (Yang et al., 2023), we conduct\nan experiment using GPT-4V on CROHME 2014\ndataset with the the prompt ‘generate latex code\nand output without compile.’ The outputs are post-\nprocessed to align CROHME vocabulary, and the\nExpRate of GPT-4V is 31.85. Given that it is not\nfinetuned on the CROHME dataset, its performance\nis acceptable.\n5.3 Ablation Study\nIn this subsection, we perform a ablation study to\nanalyze the impact of the language module and the\nMethod ExpRate↑ ≤ 1 ↑ ≤ 2 ↑\nDW AP (Baseline) 51.72 69.47 77.99\n+ Language Module 53.96 70.18 78.80\n+ Fusion Module 57.00 72.01 80.73\nTable 4: Ablation study on CROHME 2014\nfusion module. To separate the impact of the lan-\nguage module, we did not use the fusion module in\nRLFN. Instead, in order to generate the corrected\nprediction sequence, we treat it as a translation task\nand add a decoder with two transformer layers in\nthe language module. Other settings are all identi-\ncal to RLFN. Results on CROHME 2014 are shown\nin table 4, we can only tell that the language module\nand the fusion module both have their impact.\n5.4 Improvement Study\nIn this section, we explore whether the improve-\nment comes from the correction of complex struc-\nture and visual ambiguity to validate our propo-\nsition that LM do obtain semantic and structural\ninformation synchronously and complementarily.\nWe conduct an incremental comparison on struc-\ntural complexity to assess the improvement of our\nmodel on complex expressions across all datasets.\nWe define the structural complexity of an expres-\nsion as the count of six structural symbols men-\ntioned in Section 3.1. The results are presented in\nTable 5. Models perform worse when facing more\ncomplex expressions, suggesting they are more\nchallenging to recognize. Interestingly, the rela-\ntive improvement becomes progressively higher\nfor more complex expressions. The improvement\n4063\nDWAP RLFN RI\nComplex\n25%\nExpRate 0.2965 0.3469 17.00%\n≤1 0.4454 0.4766 7.01%\n≤2 0.5378 0.5954 10.71%\n≤3 0.6074 0.6543 7.71%\nComplex\n50%\nExpRate 0.3908 0.4322 10.60%\n≤1 0.5672 0.6014 6.03%\n≤2 0.6507 0.6963 7.01%\n≤3 0.7209 0.7539 4.58%\nTotal\nExpRate 0.5039 0.5501 9.17%\n≤1 0.6873 0.7155 4.10%\n≤2 0.7668 0.7971 3.95%\n≤3 0.8235 0.8457 2.70%\nTable 5: Incremental examination of the Top 25%, 50%,\nand total expressions based on structural complexity\nin the unified CROHME 2014/2016/2019 dataset. RI\ndenotes the relative improvement from DW AP to RLFN.\nz↔2 g ↔9 q ↔9 o ↔0 b ↔6 Top-5\n-44% -19% 0% -24% 10% -21%\nTable 6: Relative change of top 5 mis-recognition.\nfor the top 25% most complex expressions is nearly\ntwice that of the improvement among all expres-\nsions. These observations indicate that RLFN out-\nperforms our baseline especially in recognizing\ncomplex structures which might be because our\nRLFN can extract explicit structural information\nthrough LM, serving the similar role to tree de-\ncoders.\nRegarding RLFN’s performance in handling vi-\nsual ambiguity, we conduct a replicated analysis\nsame to the one described in Section 3.1. Specifi-\ncally, we compare the frequency of top 5 number-\nalphabet pairs of mis-recognition with our baseline\nand study the difference, which is shown in Table\n6. We observe that RLFN effectively reduces the\noccurrence of the top-5 mis-recognition by 21%\ncompared to our baseline. This shows the capabil-\nity of RLFN to reduce visual ambiguity between\nalphabets and numbers using contextual informa-\ntion provided by language modeling.\n5.5 Case Study\nAs shown in Figure 5, we present two complex\nstructure cases in group A, along with another two\nvisual ambiguity cases in group B.\nIn group A, the baseline model recognizes an\nadditional structure symbol ‘\\}’in one case and\nmisplaces ‘\\}’ to the wrong position in the other.\nIn contrast, RLFN gets both expressions correctly.\nThis is not a symbol recognition problem, which\nindicates that RLFN has learned the semantics of\nstructure symbols and gained the ability of struc-\nFigure 5: Cases with complex structure (A) and visual\nambiguity (B) that RLFN outperforms our baseline.\nFigure 6: Visualization of top-5 probability\nture modeling.\nIn group B, cases possess visual ambiguity be-\ntween variables and numbers. The baseline model\nrelies solely on visual appearance and cannot distin-\nguish visually resemble symbols. This is likely due\nto its lack of architecture to effectively utilize and\ncomprehend contextual and structural information.\nRLFN, on the contrary, can correctly recognize\n‘\\times’ with surrounding numbers and recognize\n‘1’ and ‘0’ based on their superscript and subscript\nstructural relations. This indicates that RLFN can\ncomplement each other’s semantic and structural\ninformation when recognizing visually ambiguous\nsymbols.\nAs depicted in Figure 6, we delve into a particu-\nlar case about its top-5 probability. The probability\nderived from the baseline demonstrates visual ambi-\nguity concerning the symbols ‘x’, ‘X’, and ‘\\times’\nwithout understanding their semantics. After deter-\nmining that this may be a multiplication structure,\nRLFN reduces the probability associated with ‘x’\nand ‘X’, while recognizing the correct \\times sym-\nbol with high confidence.\n6 Conclusion\nIn this research, we have examined the unique lan-\nguage characteristics intrinsic to LaTeX mathemat-\nical expressions, with a keen focus on the minimal\nsemantic unit and explicit structural symbols. Our\ninvestigation underscores that these characteristics\ngive HMER systems the potential to obtain both se-\n4064\nmantic and structural information through language\nmodels. We subsequently propose an innovative ar-\nchitecture that harmoniously integrates recognition\nand language features to yield corrected sequences.\nThis framework eliminates the requirement to con-\nstruct complex CFGs for resolving structural issues,\nand serves to ameliorate the challenge of visual am-\nbiguities. This integrative approach offers fresh\ninsights and promising theoretical groundwork for\nthe development of HMER and related mathemati-\ncal endeavors.\nLimitations\nThe limitations of our theoretical assessment war-\nrant acknowledgment. In our analysis, we scruti-\nnized the language characteristics of LaTeX math-\nematical expressions, drawing parallels between\ntheir expression mechanisms and those of the En-\nglish language. This led us to posit that a LM adept\nat handling English semantics should, in theory,\nbe equally proficient with LaTeX mathematical\nexpressions. However, our methodology, rooted\nin inferential analogy, is weaker than directly an-\nalyzing how LMs handles LaTeX mathematical\nexpressions and cannot be further extended, such\nas customizing a LM suitable for LaTeX mathemat-\nical expressions.\nOur proposed model architecture is not devoid\nof certain limitations. The architectural design\nbroadly follows a late fusion strategy, which, when\ncontrasted with the early fusion approach seen in\nsemantic modeling and modal fusion during the\ndecoding phase of the recognition module, exhibits\na lack of thorough information interaction. This\nshortfall is exemplified by our model’s disregard\nfor the prediction probability of the recognition se-\nquence input to the language module, resulting in\nsome information loss.\nBesides, given the current state of the field,\nwhere most existing recognition models rely heav-\nily on tree decoders and bidirectional training ar-\nchitectures, triplet data and reverse sequences are\nnot suitable for language modeling. This limitation\nconfines the range of selectable baseline models.\nNotwithstanding, one of our overarching goals in\nthis endeavor is to maneuver around this intrinsic\nconstraint that inherently stifles expansion.\nFurthermore, as the formidable capabilities of\nLLM and LMM/MLLM are widely researched,\nsome methods can even achieve an OCR-free un-\nderstanding of text images. This casts doubt on\nthe significance of excavating model architectures\nfor specific tasks. However, is there a real need\nfor the involvement of a general large model in a\nspecific task? When the accuracy requirements are\nstringent, how do the upper limits of a general large\nmodel compare with that of a small model tailored\nfor a specific task? Or is it the case that data is\ntruly everything? These questions still require deep\nconsideration.\nAcknowledgements\nThis work was supported in part by the National\nNatural Science Foundation of China under Grant\nNo.62250057.\nReferences\nAhmad-Montaser Awal, Harold Mouchère, and Chris-\ntian Viard-Gaudin. 2014. A global learning approach\nfor an online handwritten mathematical expression\nrecognition system. Pattern Recognition Letters ,\n35:68–77. Frontiers in Handwriting Processing.\nXiaohang Bian, Bo Qin, Xiaozhe Xin, Jianwu Li, Xue-\nfeng Su, and Yanfeng Wang. 2022. Handwritten\nmathematical expression recognition via attention ag-\ngregation based bi-directional mutual learning. Pro-\nceedings of the AAAI Conference on Artificial Intelli-\ngence, 36(1):113–121.\nKam-Fai Chan and Dit-Yan Yeung. 2001. Error detec-\ntion, error correction and performance evaluation in\non-line mathematical expression recognition. Pattern\nRecognition, 34(8):1671–1684.\nKyunghyun Cho, Bart van Merriënboer, Caglar Gul-\ncehre, Dzmitry Bahdanau, Fethi Bougares, Holger\nSchwenk, and Yoshua Bengio. 2014. Learning\nphrase representations using RNN encoder–decoder\nfor statistical machine translation. In Proceedings\nof the 2014 Conference on Empirical Methods in\nNatural Language Processing (EMNLP), pages 1724–\n1734, Doha, Qatar. Association for Computational\nLinguistics.\nYuntian Deng, Anssi Kanervisto, Jeffrey Ling, and\nAlexander M. Rush. 2017. Image-to-markup genera-\ntion with coarse-to-fine attention. In Proceedings of\nthe 34th International Conference on Machine Learn-\ning, volume 70 of Proceedings of Machine Learning\nResearch, pages 980–989. PMLR.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\n4065\nShancheng Fang, Zhendong Mao, Hongtao Xie, Yuxin\nWang, Chenggang Yan, and Yongdong Zhang. 2023.\nAbinet++: Autonomous, bidirectional and iterative\nlanguage modeling for scene text spotting. IEEE\nTransactions on Pattern Analysis and Machine Intel-\nligence, 45(6):7123–7141.\nShancheng Fang, Hongtao Xie, Yuxin Wang, Zhendong\nMao, and Yongdong Zhang. 2021. Read like hu-\nmans: Autonomous, bidirectional and iterative lan-\nguage modeling for scene text recognition. In 2021\nIEEE/CVF Conference on Computer Vision and Pat-\ntern Recognition (CVPR), pages 7094–7103.\nChristiane Fellbaum. 2005. Wordnet and wordnets. In\nAlex Barber, editor, Encyclopedia of Language and\nLinguistics, pages 2–665. Elsevier.\nHarsh Gupta, Luciano Del Corro, Samuel Broscheit,\nJohannes Hoffart, and Eliot Brenner. 2021. Unsu-\npervised multi-view post-OCR error correction with\nlanguage models. In Proceedings of the 2021 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing, pages 8647–8652, Online and Punta Cana,\nDominican Republic. Association for Computational\nLinguistics.\nGao Huang, Zhuang Liu, Laurens van der Maaten, and\nKilian Q. Weinberger. 2017. Densely connected con-\nvolutional networks. In 2017 IEEE Conference on\nComputer Vision and Pattern Recognition (CVPR),\npages 2261–2269.\nArmand Joulin, Edouard Grave, Piotr Bojanowski, and\nTomas Mikolov. 2017. Bag of tricks for efficient\ntext classification. In Proceedings of the 15th Con-\nference of the European Chapter of the Association\nfor Computational Linguistics: Volume 2, Short Pa-\npers, pages 427–431, Valencia, Spain. Association\nfor Computational Linguistics.\nAnh Duc Le. 2020. Recognizing handwritten mathe-\nmatical expressions via paired dual loss attention net-\nwork and printed mathematical expressions. In 2020\nIEEE/CVF Conference on Computer Vision and Pat-\ntern Recognition Workshops (CVPRW), pages 2413–\n2418.\nBohan Li, Ye Yuan, Dingkang Liang, Xiao Liu, Zhilong\nJi, Jinfeng Bai, Wenyu Liu, and Xiang Bai. 2022.\nWhen counting meets hmer: Counting-aware network\nfor handwritten mathematical expression recognition.\nIn Computer Vision – ECCV 2022, pages 197–214.\nRon Litman, Oron Anschel, Shahar Tsiper, Roee Lit-\nman, Shai Mazor, and R. Manmatha. 2020. Scatter:\nSelective context attentional scene text recognizer. In\n2020 IEEE/CVF Conference on Computer Vision and\nPattern Recognition (CVPR), pages 11959–11969.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized BERT pretraining\napproach. CoRR, abs/1907.11692.\nScott MacLean and George Labahn. 2013. A new ap-\nproach for recognizing handwritten mathematics us-\ning relational grammars and fuzzy sets. International\nJournal on Document Analysis and Recognition (IJ-\nDAR), 16(2):139–163.\nH. Mouchère, C. Viard-Gaudin, R. Zanibbi, and\nU. Garain. 2014. Icfhr 2014 competition on recogni-\ntion of on-line handwritten mathematical expressions\n(crohme 2014). In 2014 14th International Confer-\nence on Frontiers in Handwriting Recognition, pages\n791–796.\nThi Tuyet Hai Nguyen, Adam Jatowt, Nhu-Van Nguyen,\nMickael Coustaty, and Antoine Doucet. 2020. Neu-\nral machine translation with bert for post-ocr error\ndetection and correction. In Proceedings of the A\nCM/IEEE Joint Conference on Digital Libraries in\n2020, JCDL ’20, pages 333–336, New York, NY ,\nUSA. Association for Computing Machinery.\nVít Novotný and Michal Štefánik. 2022. Combining\nsparse and dense information retrieval. In Proceed-\nings of the Working Notes of CLEF 2022 - Conference\nand Labs of the Evaluation Forum, pages 104–118,\nBologna. CEUR-WS.\nErnesto Noya, Joan Andreu Sánchez, and José Miguel\nBenedí. 2021. Generation of hypergraphs from\nthe n-best parsing of 2d-probabilistic context-free\ngrammars for mathematical expression recognition.\nIn 2020 25th International Conference on Pattern\nRecognition (ICPR), pages 5696–5703.\nNiki Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz\nKaiser, Noam Shazeer, Alexander Ku, and Dustin\nTran. 2018. Image transformer. In Proceedings of\nthe 35th International Conference on Machine Learn-\ning, volume 80 of Proceedings of Machine Learning\nResearch, pages 4055–4064. PMLR.\nShuai Peng, Ke Yuan, Liangcai Gao, and Zhi Tang. 2021.\nMathbert: A pre-trained model for mathematical for-\nmula understanding. CoRR, abs/2105.00377.\nZhi Qiao, Yu Zhou, Dongbao Yang, Yucan Zhou, and\nWeiping Wang. 2020. Seed: Semantics enhanced\nencoder-decoder framework for scene text recogni-\ntion. In 2020 IEEE/CVF Conference on Computer\nVision and Pattern Recognition (CVPR), pages 13525–\n13534.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, Ilya Sutskever, et al. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog, 1(8):9.\nAnja Reusch, Maik Thiele, and Wolfgang Lehner. 2022.\nTransformer-encoder and decoder models for ques-\ntions on math. Proceedings of the Working Notes of\nCLEF 2022, pages 5–8.\nAlexander Scarlatos and Andrew Lan. 2023. Tree-based\nrepresentation and generation of natural and mathe-\nmatical language. CoRR, abs/2302.07974.\n4066\nThanh-Nghia Truong, Cuong Tuan Nguyen,\nKhanh Minh Phan, and Masaki Nakagawa.\n2020. Improvement of end-to-end offline handwrit-\nten mathematical expression recognition by weakly\nsupervised learning. In 2020 17th International\nConference on Frontiers in Handwriting Recognition\n(ICFHR), pages 181–186.\nHuy Quang Ung, Cuong Tuan Nguyen, Hung Tuan\nNguyen, Thanh-Nghia Truong, and Masaki Naka-\ngawa. 2021. A transformer-based math language\nmodel for handwritten math expression recognition.\nIn Document Analysis and Recognition – ICDAR\n2021 Workshops, pages 403–415, Cham. Springer\nInternational Publishing.\nJiaming Wang, Jun Du, Jianshu Zhang, and Zi-Rui\nWang. 2019. Multi-modal attention network for hand-\nwritten mathematical expression recognition. In 2019\nInternational Conference on Document Analysis and\nRecognition (ICDAR), pages 1181–1186.\nChangjie Wu, Jun Du, Yunqing Li, Jianshu Zhang, Chen\nYang, Bo Ren, and Yiqing Hu. 2022a. Tdv2: A novel\ntree-structured decoder for offline mathematical ex-\npression recognition. Proceedings of the AAAI Con-\nference on Artificial Intelligence, 36(3):2694–2702.\nJiajia Wu, Jinshui Hu, Mingjun Chen, Lirong Dai, Xue-\njing Niu, and Ning Wang. 2022b. Structural string de-\ncoder for handwritten mathematical expression recog-\nnition. In 2022 26th International Conference on\nPattern Recognition (ICPR), pages 3246–3251.\nJin-Wen Wu, Fei Yin, Yan-Ming Zhang, Xu-Yao Zhang,\nand Cheng Lin Liu. 2019. Image-to-markup gen-\neration via paired adversarial learning. In Machine\nLearning and Knowledge Discovery in Databases ,\npages 18–34, Cham. Springer International Publish-\ning.\nJin-Wen Wu, Fei Yin, Yan-Ming Zhang, Xu-Yao Zhang,\nand Cheng-Lin Liu. 2020. Handwritten mathemat-\nical expression recognition via paired adversarial\nlearning. International Journal of Computer Vision,\n128(10):2386–2401.\nZhengyuan Yang, Linjie Li, Kevin Lin, Jianfeng Wang,\nChung-Ching Lin, Zicheng Liu, and Lijuan Wang.\n2023. The dawn of lmms: Preliminary explorations\nwith gpt-4v(ision).\nLili Yao, Yaoyuan Zhang, Yansong Feng, Dongyan\nZhao, and Rui Yan. 2017. Towards implicit content-\nintroducing for generative short-text conversation sys-\ntems. In Proceedings of the 2017 Conference on\nEmpirical Methods in Natural Language Processing,\npages 2190–2199, Copenhagen, Denmark. Associa-\ntion for Computational Linguistics.\nMichihiro Yasunaga, Jure Leskovec, and Percy Liang.\n2021. Lm-critic: Language models for unsu-\npervised grammatical error correction. CoRR,\nabs/2109.06822.\nYe Yuan, Xiao Liu, Wondimu Dikubab, Hui Liu, Zhi-\nlong Ji, Zhongqin Wu, and Xiang Bai. 2022. Syntax-\naware network for handwritten mathematical expres-\nsion recognition. In 2022 IEEE/CVF Conference on\nComputer Vision and Pattern Recognition (CVPR),\npages 4543–4552.\nMatthew D. Zeiler. 2012. ADADELTA: an adaptive\nlearning rate method. CoRR, abs/1212.5701.\nJianshu Zhang, Jun Du, and Lirong Dai. 2018. Multi-\nscale attention with dense encoder for handwritten\nmathematical expression recognition. In 2018 24th\nInternational Conference on Pattern Recognition\n(ICPR), pages 2245–2250.\nJianshu Zhang, Jun Du, and Lirong Dai. 2019a. Track,\nattend, and parse (tap): An end-to-end framework for\nonline handwritten mathematical expression recogni-\ntion. IEEE Transactions on Multimedia, 21(1):221–\n233.\nJianshu Zhang, Jun Du, Yongxin Yang, Yi-Zhe Song,\nSi Wei, and Lirong Dai. 2020. A tree-structured\ndecoder for image-to-markup generation. In Pro-\nceedings of the 37th International Conference on\nMachine Learning, volume 119 of Proceedings of\nMachine Learning Research , pages 11076–11085.\nPMLR.\nJianshu Zhang, Jun Du, Shiliang Zhang, Dan Liu, Yu-\nlong Hu andJ inshui Hu, Si Wei, and Lirong Dai.\n2017. Watch, attend and parse: An end-to-end neural\nnetwork based approach to handwritten mathematical\nexpression recognition. Pattern Recognition, 71:196–\n206.\nZhi Zhang, Tong He, Hang Zhang, Zhongyue Zhang,\nJunyuan Xie, and Mu Li. 2019b. Bag of freebies\nfor training object detection neural networks. CoRR,\nabs/1902.04103.\nWenqi Zhao, Liangcai Gao, Zuoyu Yan, Shuai Peng,\nLin Du, and Ziyin Zhang. 2021. Handwritten mathe-\nmatical expression recognition with bidirectionally\ntrained transformer. In Document Analysis and\nRecognition – ICDAR 2021, pages 570–584, Cham.\nSpringer International Publishing.\nShuhan Zhong, Sizhe Song, Guanyao Li, and S.-H. Gary\nChan. 2022. A tree-based structure-aware trans-\nformer decoder for image-to-markup generation. In\nProceedings of the 30th ACM International Confer-\nence on Multimedia, MM ’22, page 5751–5760, New\nYork, NY , USA. Association for Computing Machin-\nery.\nFrancisco Álvaro, Joan-Andreu Sánchez, and José-\nMiguel Benedí. 2014. Recognition of on-line hand-\nwritten mathematical expressions using 2d stochastic\ncontext-free grammars and hidden markov models.\nPattern Recognition Letters, 35:58–67. Frontiers in\nHandwriting Processing.\n4067\nFrancisco Álvaro, Joan-Andreu Sánchez, and José-\nMiguel Benedí. 2016. An integrated grammar-based\napproach for mathematical expression recognition.\nPattern Recognition, 51:135–147.\n4068"
}