{
    "title": "Instructing and Prompting Large Language Models for Explainable Cross-domain Recommendations",
    "url": "https://openalex.org/W4403220999",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A5099381253",
            "name": "Alessandro Petruzzelli",
            "affiliations": [
                "University of Bari Aldo Moro"
            ]
        },
        {
            "id": "https://openalex.org/A2136910177",
            "name": "Cataldo Musto",
            "affiliations": [
                "University of Bari Aldo Moro"
            ]
        },
        {
            "id": null,
            "name": "Lucrezia Laraspata",
            "affiliations": [
                "University of Bari Aldo Moro"
            ]
        },
        {
            "id": "https://openalex.org/A2509283043",
            "name": "Ivan Rinaldi",
            "affiliations": [
                "University of Bari Aldo Moro"
            ]
        },
        {
            "id": "https://openalex.org/A258572996",
            "name": "Marco de Gemmis",
            "affiliations": [
                "University of Bari Aldo Moro"
            ]
        },
        {
            "id": "https://openalex.org/A260754163",
            "name": "Pasquale Lops",
            "affiliations": [
                "University of Bari Aldo Moro"
            ]
        },
        {
            "id": "https://openalex.org/A176830254",
            "name": "Giovanni Semeraro",
            "affiliations": [
                "University of Bari Aldo Moro"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4226171023",
        "https://openalex.org/W2097638479",
        "https://openalex.org/W6778883912",
        "https://openalex.org/W2057171152",
        "https://openalex.org/W3119682123",
        "https://openalex.org/W4296591867",
        "https://openalex.org/W3008007459",
        "https://openalex.org/W2969262604",
        "https://openalex.org/W2987219395",
        "https://openalex.org/W2726396866",
        "https://openalex.org/W4389520387",
        "https://openalex.org/W3094484861",
        "https://openalex.org/W85627550",
        "https://openalex.org/W4386193073",
        "https://openalex.org/W2740605635",
        "https://openalex.org/W2027731328",
        "https://openalex.org/W2855803919",
        "https://openalex.org/W149687307",
        "https://openalex.org/W4399913588",
        "https://openalex.org/W2981852735",
        "https://openalex.org/W2341865734",
        "https://openalex.org/W4226280022",
        "https://openalex.org/W4386728930",
        "https://openalex.org/W2117420919",
        "https://openalex.org/W4386728733",
        "https://openalex.org/W4381163968",
        "https://openalex.org/W4386729681",
        "https://openalex.org/W4288269198",
        "https://openalex.org/W4304080519",
        "https://openalex.org/W2965442184",
        "https://openalex.org/W4288089799",
        "https://openalex.org/W2908054697"
    ],
    "abstract": "In this paper, we present a strategy to provide users with explainable cross-domain recommendations (CDR) that exploits large language models (LLMs). Generally speaking, CDR is a task that is hard to tackle, mainly due to data sparsity issues. Indeed, CDR models require a large amount of data labeled in both source and target domains, which are not easy to collect. Accordingly, our approach relies on the intuition that the knowledge that is already encoded in LLMs can be used to more easily bridge the domains and seamlessly provide users with personalized cross-domain suggestions. To this end, we designed a pipeline to: (a) instruct a LLM to handle a CDR task; (b) design a personalized prompt, based on the preferences of the user in a source domain, and a list of items to be ranked in target domain; (c) feed the LLM with the prompt, in both zero-shot and one-shot settings, and process the answer in order to extract the recommendations and a natural language explanation. As shown in the experimental evaluation, our approach beats several established state-of-the-art baselines for CDR in most of the experimental settings, thus showing the effectiveness of LLMs also in this novel and scarcely investigated scenario.",
    "full_text": null
}