{
    "title": "Path to Medical AGI: Unify Domain-specific Medical LLMs with the Lowest Cost",
    "url": "https://openalex.org/W4382517509",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A3013334361",
            "name": "Juexiao Zhou",
            "affiliations": [
                "King Abdullah University of Science and Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2109115853",
            "name": "xiuying chen",
            "affiliations": [
                "King Abdullah University of Science and Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2103988188",
            "name": "Xin Gao",
            "affiliations": [
                "King Abdullah University of Science and Technology"
            ]
        },
        {
            "id": "https://openalex.org/A3013334361",
            "name": "Juexiao Zhou",
            "affiliations": [
                "King Abdullah University of Science and Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2109115853",
            "name": "xiuying chen",
            "affiliations": [
                "King Abdullah University of Science and Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2103988188",
            "name": "Xin Gao",
            "affiliations": [
                "King Abdullah University of Science and Technology"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2017561954",
        "https://openalex.org/W4360836968",
        "https://openalex.org/W4313451803",
        "https://openalex.org/W4361282369",
        "https://openalex.org/W4323030608",
        "https://openalex.org/W4321459182",
        "https://openalex.org/W4324387439",
        "https://openalex.org/W4321018175",
        "https://openalex.org/W6851467109",
        "https://openalex.org/W4317878668",
        "https://openalex.org/W4205164650",
        "https://openalex.org/W4220791724",
        "https://openalex.org/W4321781611",
        "https://openalex.org/W4321444413",
        "https://openalex.org/W4318718936",
        "https://openalex.org/W4367628410",
        "https://openalex.org/W4367367040",
        "https://openalex.org/W4366850747",
        "https://openalex.org/W4379918953",
        "https://openalex.org/W4376312115",
        "https://openalex.org/W6852776751",
        "https://openalex.org/W4376122449",
        "https://openalex.org/W4225323055",
        "https://openalex.org/W4312884055",
        "https://openalex.org/W6850503672",
        "https://openalex.org/W4322718246",
        "https://openalex.org/W4319165821",
        "https://openalex.org/W6851592950",
        "https://openalex.org/W6853040936",
        "https://openalex.org/W4375958083",
        "https://openalex.org/W6851813333",
        "https://openalex.org/W6853127500",
        "https://openalex.org/W4375869712",
        "https://openalex.org/W6852447913",
        "https://openalex.org/W4386071707",
        "https://openalex.org/W4379259189",
        "https://openalex.org/W4378468467",
        "https://openalex.org/W4380480626",
        "https://openalex.org/W4378373365",
        "https://openalex.org/W4380715596",
        "https://openalex.org/W4377232689",
        "https://openalex.org/W4309137644",
        "https://openalex.org/W2995225687",
        "https://openalex.org/W4221151773",
        "https://openalex.org/W2970641574"
    ],
    "abstract": "Abstract Medical artificial general intelligence (AGI) is an emerging field that aims to develop systems specifically designed for medical applications that possess the ability to understand, learn, and apply knowledge across a wide range of tasks and domains. Large language models (LLMs) represent a significant step towards AGI. However, training cross-domain LLMs in the medical field poses significant challenges primarily attributed to the requirement of collecting data from diverse domains. This task becomes particularly difficult due to privacy restrictions and the scarcity of publicly available medical datasets. Here, we propose Medical AGI (MedAGI), a paradigm to unify domain-specific medical LLMs with the lowest cost, and suggest a possible path to achieve medical AGI. With an increasing number of domain-specific professional multimodal LLMs in the medical field being developed, MedAGI is designed to automatically select appropriate medical models by analyzing users’ questions with our novel adaptive expert selection algorithm. It offers a unified approach to existing LLMs in the medical field, eliminating the need for retraining regardless of the introduction of new models. This characteristic renders it a future-proof solution in the dynamically advancing medical domain. To showcase the resilience of MedAGI, we conducted an evaluation across three distinct medical domains: dermatology diagnosis, X-ray diagnosis, and analysis of pathology pictures. The results demonstrated that MedAGI exhibited remarkable versatility and scalability, delivering exceptional performance across diverse domains. Our code is publicly available to facilitate further research at https://github.com/JoshuaChou2018/MedAGI .",
    "full_text": "1\nPath to Medical AGI: Unify Domain-specific\nMedical LLMs with the Lowest Cost\nJuexiao Zhou1,2,#, Xiuying Chen1,2,#, Xin Gao1,2,∗\nAbstract—Medical artificial general intelligence (AGI) is an emerging field that aims to develop systems specifically designed for\nmedical applications that possess the ability to understand, learn, and apply knowledge across a wide range of tasks and domains.\nLarge language models (LLMs) represent a significant step towards AGI. However, training cross-domain LLMs in the medical field\nposes significant challenges primarily attributed to the requirement of collecting data from diverse domains. This task becomes\nparticularly difficult due to privacy restrictions and the scarcity of publicly available medical datasets. Here, we propose Medical AGI\n(MedAGI), a paradigm to unify domain-specific medical LLMs with the lowest cost, and suggest a possible path to achieve medical AGI.\nWith an increasing number of domain-specific professional multimodal LLMs in the medical field being developed, MedAGI is designed\nto automatically select appropriate medical models by analyzing users’ questions with our novel adaptive expert selection algorithm. It\noffers a unified approach to existing LLMs in the medical field, eliminating the need for retraining regardless of the introduction of new\nmodels. This characteristic renders it a future-proof solution in the dynamically advancing medical domain. To showcase the resilience\nof MedAGI, we conducted an evaluation across three distinct medical domains: dermatology diagnosis, X-ray diagnosis, and analysis\nof pathology pictures. The results demonstrated that MedAGI exhibited remarkable versatility and scalability, delivering exceptional\nperformance across diverse domains. Our code is publicly available to facilitate further research at\nhttps://github.com/JoshuaChou2018/MedAGI.\nIndex Terms—Healthcare, Deep learning, Large language model, Artificial general intelligence\n✦\n1 I NTRODUCTION\nArtificial General Intelligence (AGI) [1] refers to highly\nautonomous systems that possess the ability to understand,\nlearn, and apply knowledge across a wide range of tasks and\ndomains. These systems are designed to match or even ex-\nceed human competencies in intellectual tasks. Essentially,\nAGI represents the pinnacle objective within the field of\nartificial intelligence (AI) [2]. Within this realm, Medical AGI\nis an emerging field that aims to develop Artificial General\nIntelligence systems specifically designed for medical ap-\nplications, encompassing tasks such as disease diagnosis,\ntreatment planning, and patient care optimization. Large\nlanguage models (LLMs) [3] represent a significant step to-\nwards AGI by showcasing the power of language processing\nand understanding. During the past few months, significant\nprogress has been made in the field of LLMs, revolutioniz-\ning language comprehension and enabling complex linguis-\ntic tasks [4], [5]. Among the highly anticipated models, Chat-\n1Computer Science Program, Computer, Electrical and Mathematical Sciences\nand Engineering Division, King Abdullah University of Science and Technol-\nogy (KAUST), Thuwal 23955-6900, Kingdom of Saudi Arabia\n2Computational Bioscience Research Center, King Abdullah University of\nScience and Technology (KAUST), Thuwal 23955-6900, Kingdom of Saudi\nArabia\n#These authors contributed equally.\n∗Corresponding author. e-mail: xin.gao@kaust.edu.sa\nGPT, developed by OpenAI, has garnered attention for its\nexceptional capabilities. This model is especially proficient\nin generating human-like text based on the input it receives,\ndemonstrating an impressive understanding of nuanced\ncontexts and varied linguistic styles. Specifically, ChatGPT\nshows great potential in Medical AGI by assisting with\nmedical disease diagnosis through patients conversations,\nsuch as ophthalmic diagnosis [6], pathology diagnosis [7],\nand health care discussion [8].\nOne limitation of ChatGPT is its exclusive reliance on\ntext input, with no support for direct image input. This\nabsence of multimodal capabilities narrows its applicability\nin medical diagnosis, a field that often depends signifi-\ncantly on image-based data. [9] tries to solve this problem\nin ChatCAD by integrating multiple image-text networks\nto transform medical imaging data, including X-rays, CT\nscans, and MRIs to textual description. These transformed\ndescriptions can subsequently be used as input for ChatGPT.\nHowever, the separation of the image-to-text transformation\nprocess from the LLMs process not only underutilizes the\nfull potential of LLMs but can also lead to compromised\nperformance if the quality of the image-to-text model is\nlacking. Furthermore, it is crucial to address the potential\ndata privacy concerns associated with ChatGPT’s API for\nuploading text descriptions, as both medical images and\ntextual patient information are highly sensitive [5], [10], [11].\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 29, 2023. ; https://doi.org/10.1101/2023.06.23.23291802doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\n2\nMedAGI\nViT\n&\nQ-Former\nImage\nEmbedding\nExpert \nAlignment Layer\nAlpaca\nLLM\nVarious Domains of \nMedical Images\nThis could be a skin disease image of acne.\nWhat is wrong with my skin?\nHow should I treat it?\nDermatology\nX-ray\nPathology\nAdaptive Model\nSelection\nDatabase of\nExpert Layers\nDomain-generic Interactive Medical Chatbot\nWhat anomalies can you see in my x-ray?\n...\nVicuna\n...\nSkinGPT-4 is a revolutionary dermatology diagnostic \nsystem that utilizes an advanced vision-based large \nlanguage model to assess skin conditions... \nXrayChat is a cutting-edge system that enables \ninteractive, multi-turn conversations about chest \nX-ray images. Users simply upload a X-ray ...\nPathologyChat is a cutting-edge system that enables \ninteractive, multi-round conversations about stained \npathology images. Users simply upload ...\nUser’s Questions\nWhat is wrong with my skin and how should I treat \nthis skin condition?\nWhat anomalies can you see in my x-ray?\nPlease describe this pathology picture in detail.\nWhat is cardiopulmonary disease?\n...\n...\n...\nThe treatment of acne should include a combination of topical and oral treatments. Topical therapy \nincludes the use of retinoids, benzoyl peroxide, and salicylic acid. Oral antibiotics such as doxycycline, \nminocycline, and erythromycin may be used for moderate to severe acne. Isotretinoin may be used for \nsevere recalcitrant nodular acne. Combination therapy with both topical and oral antibiotics may be \nmore effective in treating acne. The treatment plan should be tailored to the individual patient and the \nseverity of their acne. It is important to follow up with a dermatologist or healthcare provider for proper \nevaluation and treatment.\nPain and shortness of breath. Cardiac and mediastinal size normal. The lungs are clear. The aortic \ncurved is exaggerated. There is no evidence of pneumonia, effusion, or pneumothorax. No acute \ncardiopulmonary disease.\nCardiopulmonary disease refers to any condition affecting the heart and lungs, such as pneumonia, \npulmonary edema, congestive heart failure, or a pulmonary embolism. These conditions can result in \nsymptoms such as shortness of breath, chest pain, and cough. They can also lead to complications \nsuch as respiratory failure, acute exacerbation of chronic obstructive pulmonary disease (COPD).\nPlease describe this pathology picture in detail.\nIn the superficial epithelium, tumor tissue that invades by forming medium-sized to small, irregular \nducts is observed. moderately differentiated tubular adenocarcinoma.\nWhat is tubular adenocarcinoma?\nTubular adenocarcinoma is a type of gastric cancer that is characterized by the growth of tumor cells \nthat form small, irregular gland-like structures called glandular ducts. These tumors typically infiltrate \nthe lamina propria, which is the middle layer of the stomach’s mucosa, and can invade the submucosa, \nthe layer of tissue that lines the inside of the stomach. Tubular adenocarcinoma is considered to be a\n moderately differentiated form of adenocarcinoma\u000f\nDermatology\nX-ray\nPathology\nFig. 1. Illustration of MedAGI.MedAGI is a paradigm to unify domain-specific medical LLMs with the lowest cost. Users could upload images from\nany domain, such as dermatology, X-ray and pathology, and ask questions regarding the image. Then, MedAGI could automatically select the most\nsuitable expert layer from the database by analyzing users’ questions to provide the best response in the interactive diagnosis.\nTo ensure the protection of patient confidentiality, careful\nconsideration should be given to implementing robust pri-\nvacy protection measures [12], [13], [14], [15].\nTo solve the above two challenges, a number of open-\nsource multimodal LLMs were proposed [16], [17], [18], [19],\n[20], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30],\n[31], [32], [33], [34], [35], [36], [37]. In the medical field,\nthere are two main approaches being adopted. The first\ninvolves training an end-to-end large multimodal model\nthat combines a vision encoder and an LLM for visual\nand language understanding, such as LLaVA-Med [38] and\nPathAsst [39]. This strategy often faces challenges due to\nthe need to gather data from various domains, which is\nespecially challenging in medicine due to privacy issues\nand the lack of open-source datasets. The second approach\nseeks to bridge the gap between LLMs and pre-trained\nimage encoders using an additional alignment layer, which\nis then fine-tuned using domain-specific data. This method,\nas employed in models such as SkinGPT-4 [40], ProteinChat\n[41], XrayGPT [42] and XrayChat [43], is more feasible due\nto the requirement of fewer instances to fine-tune fewer\nparameters.\nIt’s optimistic to envision that, in the future, an increas-\ning number of domain-specific professional multimodal\nLLMs in the medical field will be developed. However,\nhaving them dispersed across various platforms, each with\ntheir own instructions, and leaving it up to users to find\nthe model that fits their specific needs could be quite costly.\nIt is also costly in terms of storage and loading resources\nto repeatedly store and load the same image encoder and\nlanguage models for different multimodal LLMs. Merging\nthese models to form a universal medical model by using\nall the collected data is also unrealistic, given that medical\ndata is typically non-public and not shared. As an alter-\nnative, integrating these models into a unified platform\ncould prove to be a powerful solution. Hence, in this work,\nwe propose Medical AGI (MedAGI), a paradigm to unify\ndomain-specific medical LLMs with the lowest cost, and\nsuggest a possible path to achieve medical AGI. Specifically,\nour MedAGI system is designed to automatically select\nappropriate medical models by analyzing users’ questions.\nThis selection process leverages the detailed descriptions of\ndifferent medical models provided in their respective intro-\nductions, ensuring the best fit for the user’s requirements.\nIn addition to saving space and being user-friendly, our\nmodel also boasts extendability. It doesn’t require retraining,\nregardless of the number of new models proposed, making\nit a future-proof solution in the rapidly evolving field of\nmedical AI. To demonstrate the robustness of MedAGI, we\nevaluated it in three medical domains, including dermatol-\nogy diagnosis, X-ray diagnosis, and analysis of pathology\npictures. Our experiments revealed that MedAGI is profi-\ncient at selecting the appropriate models to match various\nuser requirements. In conclusion, MedAGI stands out as\na versatile and easily scalable solution. As the community\ncontinues to develop and increase the number of alignment\nlayers trained on various domains, MedAGI only needs to\nmanage these alignment layers to deliver a domain-generic\nperformance, making it a promising tool for the future.\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 29, 2023. ; https://doi.org/10.1101/2023.06.23.23291802doi: medRxiv preprint \n3\nCould you describe the skin disease in this image for me?\nMedAGI\nSkinGPT -4\nXrayChat\nPathologyChat\nMiniGPT -4\nThis could be a skin disease image of acne.\nThis could be a skin disease image of acne pustular. \nI’m sorry, but I am unable to see the image you are referring to. \nPlease provide an image or describe the skin disease in more \ndetail so I can better assist you.\nThe image shows an individual’s face with irregularly shaped \nlesions covering the forehead and cheek, with some lesions \ngrowing in size. The lesions appear to be solid, and some have \nbroken open, releasing their contents.\nI am sorry, but as an AI language model, I am not able to see \nany image that is not explicitly provided to me. Can you please \nprovide me with the image?\nHow should I treat it? \nThis could be a skin condition called acne. It can be treated \nwith topical retinoids, benzoyl peroxide, or oral antibiotics, or \nisotretinoin in severe cases \nThis could be a skin disease image of acne. Treatment \noptions include topical retinoids, antibiotics, and isotretinoin. \nWithout visual examination, I am unable to make an accurate \ndiagnosis. I would recommend consulting a healthcare \nprovider or dermatologist for further evaluation and treatment \nrecommendations \nFrom the image, it appears to be a case of congenital \nichthyosiform erythroderma (Harlequin syndrome). Treatment \nmay include phototherapy and skin grafting. However, it is \nrecommended to consult with a dermatologist for further \nevaluation and specific treatment recommendations \nThe best way to treat pimples is to avoid them altogether. \nHere are some tips to prevent pimples from appearing on \nyour face:\n1. Keep your face clean: Regularly washing your face with a \nmild soap or face wash can help to prevent the formation of \npimples.\n2. Avoid touching your face: Touching your face with dirty \nhands can transfer bacteria, causing pimples.\n3. Use non-comedogenic products: Use only non-\ncomedogenic products on your face, as these will not clog \npores and cause pimples.\n4. Avoid using too much makeup: Using too much makeup \ncan clog pores and cause pimples.\n5. Avoid stress: Stress can cause hormonal changes in your \nbody that can lead to pimples.\n6. Avoid certain foods: Foods high in sugar, fat, and dairy can \ncontribute to the formation of pimples.\nIf you do get a pimple, you can try the following treatments:\n1. Apply warm or cold compresses: This can help to reduce \nswelling and redness.\n2. Use a spot treatment: There are many over-the-counter \nspot treatments available that can help to reduce the size and \nredness of a pimple. \nMedAGI\nSkinGPT -4\nXrayChat\nPathologyChat\nMiniGPT -4\nCould you describe the skin disease in this image for me?\nMedAGI\nSkinGPT -4\nXrayChat\nPathologyChat\nMiniGPT -4\nThis could be a skin disease image of melanocytic nevi. \nThis could be a skin disease image of atypical nevi. \nThe image is not available for me to view, so I cannot give a \ndetailed description. Overall, it appears that the individual is \nhaving a diffuse interstitial lung disease, possibly pulmonary \nfibrosis. \nThe image shows a tumor in the ductal cell layer. The tumor \nhas a large, irregular and irregularly shaped shape and is \ninfiltrating the surrounding tissue. Some tumor cells have \ninvaded the adjacent tissue microvessels and are partially \nsurrounded by lymphocytes. It is a sign of aggressive and \ninvasive behavior of the tumor. \nUnfortunately, I cannot see the image as it is not provided. Can \nyou please provide the image so that I can describe the skin \ndisease?\nHow should I treat it? \nThe treatment of cutaneous melanocytic nevi depends on the \nsize, location, and potential for malignant transformation. \nGenerally, the management of common nevi is by \nobservation, while surgical excision is recommended for \natypical nevi, which have features suspicious for malignancy. \nThe patient should be informed of the signs and symptoms of \nmalignant transformation, such as changes in size, shape, \ncolor, or symptoms such as bleeding, itching, or pain. It is \nimportant to monitor the nevi periodically for any changes. \nTreatment options for atypical nevi include shave excision, \ncryotherapy, or surgical excision. The choice of treatment \ndepends on the size, location, and severity of the atypical \nnevus. It is important to monitor for changes in the nevus, as \nit may transform into a malignant melanoma. \nA diffuse interstitial lung disease, possibly pulmonary fibrosis, \nshould be evaluated by a pulmonologist. They will be able to \nprovide further treatment options depending on the severity \nand progression of the disease. This could include \nmedications, oxygen therapy, or other interventions. A \nmultidisciplinary approach \nThe treatment for this type of tumor depends on several \nfactors, including the size and location of the tumor, the \npatient’s overall health, and whether the tumor has spread to \nother parts of the body. For ductal adenocarcinoma of the \npancreas, surgery is usually the primary treatment, with or \nwithout adjuvant chemotherapy and/or radiation therapy. \nTo treat this skin disease, it is important to understand the \nunderlying cause. Based on the image, it appears to be a \nskin infection caused by bacteria. To treat it, the following \nsteps can be taken:\n1. Clean the affected area thoroughly with warm water and \nantiseptic soap to remove any bacteria or debris.\n2. Apply a topical antibiotic cream or ointment to the affected \narea. This will help to kill the bacteria and reduce \ninflammation. Examples of antibiotic creams include \nerythromycin, clindamycin, or fusidic acid.\nMedAGI\nSkinGPT -4\nXrayChat\nPathologyChat\nMiniGPT -4\nCould you describe the skin disease in this image for me?\nMedAGI\nSkinGPT -4\nXrayChat\nPathologyChat\nMiniGPT -4\nThis could be a skin disease image of tinea foot webs. \nThis could be a skin disease image of tinea foot webs. \nI’m sorry, but without an image to reference, I’m unable to \ndescribe the skin disease in the patient. It’s important to \nconsult with a dermatologist or other medical professional for \nproper diagnosis and treatment of any skin condition.\nThe image shows a close-up view of a person’s foot with a \nlarge wart-like growth on the sole. The growth has a white, \nwaxy appearance and appears to be attached to the skin. It \nappears to be an example of a plantar wart. \nThe image shows a close up view of a person’s foot with white, \nscaly patches on the skin. The patches appear to be on the \nbottom of the foot, near the toes. The skin looks dry and flaky, \nwith some areas appearing more scaly than others. There is \nno visible swelling or redness in the area. \nHow should I treat it? \nThe treatment for tinea foot webs involves topical and oral \nantifungal therapy. Topical antifungal creams or ointments, \nsuch as clotrimazole or miconazole, can be applied to the \naffected areas. Oral antifungal medications, such as \nitraconazole or fluconazole, may be prescribed if the infection \nis severe or does not respond to topical treatment. The foot \nshould be kept clean and dry, and occlusive dressings may \nbe used over the affected area to improve efficacy of \ntreatment. \nTinea foot webs should be treated with topical antifungals \nsuch as clotrimazole, ketoconazole, or terbinafine. The feet \nshould be washed with soap and water, then dried \nthoroughly before applying the cream or ointment. The \ncream or ointment should be applied to all affected areas, \nincluding in between the toes, and the soles of the feet. The \ntreatment should be continued for at least 2 weeks after the \nsymptoms have cleared. Oral antifungals may be required if \nthe infection is severe or there is no improvement with \ntopical therapy. Proper hygiene and drying the feet \nthoroughly after washing can help prevent tinea infections. \nIt’s important to consult with a dermatologist or other medical \nprofessional for proper diagnosis and treatment of any skin \ncondition. Without an image to reference, I cannot make a \ndefinitive recommendation for treatment. Treatment options \nmay vary depending on the specific diagnosis and severity of \nthe condition. \nPlantar warts are typically treated with a combination of \nmethods, including cryotherapy (freezing the wart with liquid \nnitrogen), laser surgery, or removal by a dermatologist. At -\nhome treatments for plantar warts include using over-the-\ncounter wart treatments.\nThe treatment for this skin condition will depend on the \nunderlying cause. If the patches are caused by a fungal \ninfection, such as athlete’s foot, it is important to treat the \ninfection with antifungal medication. This can be in the form \nof creams, ointments, or oral medication. It is also important \nto keep the feet clean and dry, and to wear shoes that allow \nfor good air circulation\nMedAGI\nSkinGPT -4\nXrayChat\nPathologyChat\nMiniGPT -4\nFig. 2. Comparison of MedAGI, SkinGPT-4, XrayChat, PathologyChat, and MiniGPT-4 on three skin disease cases.The green tick indicates\nthat the answer is correct.\n2 R ESULTS\n2.1 Design of MedAGI\nMedAGI is a paradigm to unify domain-specific medical\nLLMs with the lowest cost and a possible path to achieving\nmedical AGI (Figure 1). By taking the user-uploaded image\nand user question as inputs, the system is capable of answer-\ning questions pertaining to different domains, including\ndermatology, X-ray analysis, and pathology, regarding the\nprovided image.\nConcretely, the uploaded image is first processed by the\nVision Transformer (VIT) [44] and Q-Transformer models\n[19] for comprehensive understanding. The VIT model par-\ntitions the image into smaller patches and extracts crucial\nfeatures. The Q-Transformer model then generates an em-\nbedding of the image by leveraging a transformer-based\narchitecture, enabling the model to consider the image’s\ncontextual information. Then MedAGI leverages the de-\ntailed descriptions of different medical models provided in\ntheir respective introductions stored in the database and\nselects the adaptive expert alignment layer in the domain-\nspecific model that matches the user’s intention the most.\nThe layer is then used to align the visual representation from\nQ-Transformer with the user question, enabling a coherent\nanalysis of the image. Finally, the LLM utilizes the aligned\ninformation to generate a text-based diagnosis, providing a\nclear and concise description of the image corresponding\nto the user’s question. Thus, MedAGI achieves AGI-like\ncapability for medical diagnosis purposes, where users no\nlonger need to care about which domain their input image\nbelongs to.\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 29, 2023. ; https://doi.org/10.1101/2023.06.23.23291802doi: medRxiv preprint \n4\nDescribe this chest X-ray in a short paragraph. \nMedAGI\nSkinGPT -4\nXrayChat\nPathologyChat\nMiniGPT -4\nBoth lungs are clear and expanded. Heart and mediastinum \nnormal. No active disease.\nThis could be a image of t cell large cell lymphoma.\nClear lungs bilaterally. No pneumothorax or pleural effusion. \nNo acute osseous abnormalities. Stable chest with no acute \ncardiopulmonary findings.\nThe image shows a tumor tissue consisting of large cells with \nlarge nuclei growing into the epithelium. The tumor is growing \nin a three-dimensional manner, with some cells growing into \nthe gastric mucosa. The neoplastic cells are large, with a \nlarge hyperchromatic nucleus and moderate to heavy \nnucleolar chromatin. There are no mitotic figures observed. \nThere is no lymphocyte infiltration observed.\nThis chest X-ray shows the lungs and heart of a person. The \nlungs are two large, spongy organs located in the chest that \nhelp to exchange oxygen and carbon dioxide. The heart is a \nmuscular organ located in the chest that pumps blood \nthroughout the body. The X-ray also shows the bones of the \nspine and ribs, as well as the diaphragm, which separates the \nchest from the abdomen. Overall, this X-ray provides important \ninformation about the health of the lungs and heart. \nWhat disease is it? \nThe patient’s chest x-ray appears normal. \nThe disease is not specified. \nNo acute cardiopulmonary disease is identified. \nIt appears to be a malignant tumor of the epithelial cell type. It \nmay be a tumor of the gastrointestinal or respiratory system. \nI’m sorry, but I don’t have enough information to accurately \ndiagnose a disease based on this X-ray. A chest X-ray can \nprovide important information about the health of the lungs, \nheart, and other structures in the chest, but it is not sufficient \nto diagnose a specific disease. A diagnosis requires a \nthorough medical evaluation, including a physical \nexamination, medical history, and other diagnostic tests.\nIt is important to consult with a qualified medical professional \nfor an accurate diagnosis and treatment plan. \nMedAGI\nSkinGPT -4\nXrayChat\nPathologyChat\nMiniGPT -4\nDescribe this chest X-ray in a short paragraph. \nMedAGI\nSkinGPT -4\nXrayChat\nPathologyChat\nMiniGPT -4\nHeart size and pulmonary vascularity appear within normal \nlimits. No consolidation, pleural effusion or pneumothorax \nidentified. The visualized osseous structures appear intact. \nNo acute cardiopulmonary abnormalities \nThis could be a image of large cell calicivirus. \nHeart size is normal and lungs are clear. No abnormality. \nThe image shows a large tumor that originates in the right \nlung and invades the mediastinum. The tumor infiltrates the \nparietal pleura and adheres to the diaphragm. A large, \ncomplex tumor with a large infiltrative component is \nobserved. The tumor shows a large amount of heterogeneity, \nand some regions show necrosis. \nThe chest X-ray shows a large mass in the left lung field, with \nareas of consolidation and air bronchograms. The right lung \nappears normal. There is no pleural effusion or mediastinal \nlymphadenopathy. The heart appears normal in size and \nposition, with no evidence of pericardial effusion or cardiac \npathology. The aortic arch and superior vena cava are patent. \nThe trachea and main bronchi are patent, with no \nendobronchial lesions or dilatation. The esophagus is patent, \nwith no mucosal abnormalities. The stomach and small bowel \nare patent, with no abnormalities. The large bowel is patent, \nwith no inflammatory or mucosal abnormalities. The kidneys \nare not visualiz ed. The bladder is patent, with no abnorm alities. \nThe urinary tract is patent, with no obstruction or abnormalities.\nWhat disease is it? \nNo acute cardiopulmonary abnormalities are identified \nThe disease is not specified. \nThere is no evidence of disease. \nIt looks like it could be a tumor in the lung or chest wall, \npossibly metastatic in nature. It’s difficult to determine the \nspecific type of tumor without more information, such as a \nbiopsy or additional imaging. \nBased on the information provided in the chest X-ray report, it \nis difficult to determine a specific disease without additional \nclinical information. The chest X-ray shows a large mass in \nthe left lung field, with areas of consolidation and air \nbronchograms, which could be indicative of lung cancer or \npulmonary inflammation or infection. However, the absence \nof pleural effusion or mediastinal lymphadenopathy is a \npositive finding, as it suggests that there is no evidence of \npleural effusion or mediastinal lymphadenopathy, which \ncould be indicative of other conditions such as pleural \neffusion or mediastinal nodules.\nMedAGI\nSkinGPT -4\nXrayChat\nPathologyChat\nMiniGPT -4\nDescribe this chest X-ray in a short paragraph. \nMedAGI\nSkinGPT -4\nXrayChat\nPathologyChat\nMiniGPT -4\nThe heart and pulmonary, mediastinum, and pleura are \nwithin normal limits. The lungs are clear. No acute or active \ndisease.\nThis could be a image of a person with large cell transformation of \nbone marrow. \nHeart size within normal limits. Aorta is enlarged. Prominent \nbilateral hilar lymph nodes. No focal consolidation, \npneumothorax, or pleural effusion. \nIn the superficial epithelium, a solid tumor is growing in which \nlarge, round or irregular ducts are formed. Some tumor cells \nhave mitotic figures in the form of small, round, irregular nuclei. \nLarge tumor cells have an epithelial morphology and are grown \nin glands or ducts. \nThe chest X-ray shows a mass in the right lung, which is \nlikely to be a tumor. The mass is well defined, with a \nhomogeneous, moderately dense appearance. The mass is \nlocated in the upper lobe of the right lung, with no evidence \nof extrathoraxial invasion. The surrounding lung parenchyma \nappears normal. There is no evidence of pleural effusion or \npneumonia. There are no other significant findings on this \nchest X-ray.\nWhat disease is it? \nNo acute or active disease. \nThe disease is not specified. \nNo focal consolidation, pneumothorax, or pleural effusion. \nIt appears to show a tumor that is growing in the epithelial \ntissue of the body, poss ibly in the lung or gastrointestinal tract. \nThe tumor cells appear to be growing in a disorganized or \nanaplastic manner, which can indicate a malignant and \naggressive tumor. Further evaluation and analysis of the \ntumor is needed to determine the specific type of tumor and \nthe appropriate treatment. \nI’m sorry, but I cannot determine the disease from the \nprovided image. The image is not clear enough for me to \nmake any conclusions about the disease. Can you please \nprovide a clearer and larger image? \nMedAGI\nSkinGPT -4\nXrayChat\nPathologyChat\nMiniGPT -4\nFig. 3. Comparison of MedAGI, SkinGPT-4, XrayChat, PathologyChat, and MiniGPT-4 on three X-ray cases.The green tick indicates that the\nanswer is correct.\n2.2 MedAGI Automatically Selects the Most Suitable\nExpert Layer\nIn the absence of MedAGI, users are required to manu-\nally select the appropriate multimodal LLMs based on the\nspecific image type and the manner in which they pose\ntheir questions. For example, they might have to choose\nbetween SkinGPT-4 for dermatology diagnosis, XrayChat\nfor X-ray analysis, or PathologyChat for pathology image\nanalysis, which adds complexity and necessitates domain-\nspecific considerations.\nHerein, MedAGI offers a unified interface that eliminates\nthe need for users to worry about the specific domain to\nwhich a particular task belongs. It provides a seamless\nexperience by integrating various domain-specific models\ninto a single framework. To illustrate this, we conducted\na comparative study involving MedAGI, SkinGPT-4, Xray-\nChat, PathologyChat, and MiniGPT-4 across three domains,\nwith three cases per domain, as depicted in Figure 2-4.\nAs expected, SkinGPT-4, XrayChat, and PathologyChat\nperformed well within their respective domains. SkinGPT-4\nexcelled in dermatology diagnosis, XrayChat showed profi-\nciency in X-ray analysis, and PathologyChat demonstrated\neffectiveness in pathology image analysis. However, when\nfaced with cross-domain scenarios, these domain-specific\nmodels exhibited limitations due to their lack of cross-\ndomain knowledge and expertise.\nIn contrast, MedAGI proved capable of providing ac-\ncurate and appropriate answers to user queries, even in\ncross-domain situations. This highlights MedAGI’s domain-\nagnostic nature and its ability to handle a wide range of\nmedical tasks, transcending specific domains.\n2.3 Scalability of MedAGI\nThe scalability of MedAGI extends beyond the domains\nof dermatology diagnosis, X-ray analysis, and pathology\nimage analysis. MedAGI’s design allows for easy extension\nto a wide range of medical domains, making it a scalable\nsolution for various healthcare applications. For instance,\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 29, 2023. ; https://doi.org/10.1101/2023.06.23.23291802doi: medRxiv preprint \n5\nPlease provide a detailed description of the pathology picture. \nMedAGI\nSkinGPT -4\nXrayChat\nPathologyChat\nMiniGPT -4\nIn the superficial epithelium, tumor tissue that invades by \nforming medium-sized to small, irregular ducts is observed. \nmoderately differentiated tubular adenocarcinoma. \nThis could be a disease image of metastasis. \nI’m sorry, there is no image for me to describe. Please give a \ndetailed description of the image. \nIn the superficial epithelium, tumor tissue that invades by \nforming medium-sized to small, irregular ducts is observed. \nmoderately differentiated tubular adenocarcinoma. \nThe image shows a section of tissue that has been stained \nwith a purple dye, which highlights the cells and structures \nwithin the tissue. The tissue appears to be from a lung or \nrespiratory system, as it contains many small, branching blood \nvessels and airways. There are also areas of inflammation and \ncongestion visible in the image, which are likely the result of an \ninfection or other disease process. Overall, the image shows \nthe structure and function of the respiratory system.\nWhat disease is it? \nModerately differentiated tubular adenocarcinoma is a type of \ncancer that affects the gastrointestinal tract. It is also known \nas adenocarcinoma with differentiated tubular morphology. \nThis could be a disease image of metastasis. \nBased on the description you have given me, this could be a \nchronic case of prostatitis or epididymitis. Without a specific \nimage, it is difficult to determine if there is any inflammation \npresent. \nIt is moderately differentiated tubular adenocarcinoma. \nIt is difficult to determine the specific disease based on the \nprovided image alone. The image shows a section of tissue \nthat has been stained with a purple dye, which highlights the \ncells and structures within the tissue. The tissue appears to \nbe from a lung or respiratory system, as it contains many \nsmall, branching blood vessels and airways. There are also \nareas of inflammation and congestion visible in the image, \nwhich are likely the result of an infection or other disease \nprocess. Without additional information, it is not possible to \ndetermine the specific disease. \nMedAGI\nSkinGPT -4\nXrayChat\nPathologyChat\nMiniGPT -4\nPlease provide a detailed description of the pathology picture. \nMedAGI\nSkinGPT -4\nXrayChat\nPathologyChat\nMiniGPT -4\nIn the superficial epithelium, tumor tissue that invades by \nforming medium-sized to small, irregular ducts is observed. \nmoderately differentiated tubular adenocarcinoma. \nThis could be a brownish black color. \nAnterior right perihilar patchy airspace disease, a chronic \ngranulomatous pneumonia. There is an irregular airspace \ninfiltrate involving the right upper lobe and lingula, consistent \nwith a granulomatous process. There is a subtle left mid lobe \npatchy airspace disease, with a few bilateral airspace \nopacities as well. \nThe superficial epithelium shows a large sheet-like shape, \nand some tumor tissue infiltrates with small irregular ducts. \nPoorly differentiated adenocarcinoma. \nThis image shows a histopathological section of a liver lobe, \nstained with hematoxylin and eosin (H&E) stain. The section \nshows a normal liver lobe with well-defined bile ducts and \nportal veins. The bile ducts are lined with columnar epithelium \nand contain bile, while the portal veins contain blood. There is \nno evidence of any abnormality or disease in this section.\nHematoxylin is a basic dye that binds to nucleic acids, while \neosin is a acidic dye that binds to acidic substances such as \nproteins. When combined, they stain the different cellular \ncomponents of a tissue in different colors, making it easier to \nidentify and study the various cell types and structures. In this \nimage, the nuclei of the cells are stained blue, the cytoplasm is \nstained pink, and the bile and blood are stained green and red, \nrespectively.\nOverall, this image provides a clear representation of the \nnormal structure and cellular composition of a liver lobe.\nWhat disease is it? \nIt is moderately differentiated tubular adenocarcinoma. \nThis could be a brownish black color. \nThe image demonstrates bilateral mild patchy airspace \ndisease, consistent with granulomatous disease. The image \nalso shows patchy airspace disease in the mid right lobe and \nlingula. This may be consistent with pulmonary tuberculosis. \nIt is poorly differentiated adenocarcinoma. \nThis image does not show any evidence of disease or \nabnormality. It is a normal histopathological section of a liver \nlobe. \nMedAGI\nSkinGPT -4\nXrayChat\nPathologyChat\nMiniGPT -4\nPlease provide a detailed description of the pathology picture. \nMedAGI\nSkinGPT -4\nXrayChat\nPathologyChat\nMiniGPT -4\nTumor tissue consisting of cord-like or small, irregular glandular \nducts fused and infiltrated is observed in the superficial \nepithelium. Poorly differentiated adenocarcinoma, non-solid \ntype\nThis could be a artwork impression of bodys fabric, textures.\nThis image is a right-sided chest radiograph. \nCardiomediastinal silhouette is centralized. Right lower lobe \nlung appears hyperexpanded with mildly nodular opacity, \nsuggestive of pneumonia. The left lung appears clear. No \neffusions or nodules are identified. No mediastinal or hilar \nlymphadenopathy identified. No large pleural effusion, \npneumothorax, or other large central lung lesion is present. \nOld healed rib fractures are present. \nThe superficial epithelium shows small cord-like infiltrating \ntumor tissue. In the superficial epithelium, tumor tissue is \nformed in the form of small, irregular glandular cavities. Some \ntumor tissues infiltrate in a diffuse manner.\nThe image shows a tissue section of a lung, which has been \nstained with hematoxylin and eosin (H&E) stain. The section \nshows the structure of the lung tissue, including the airways, \nalveoli, and blood vessels. The alveoli are small, round \nstructures that are visible in the lower left corner of the image. \nThese structures are responsible for exchanging oxygen and \ncarbon dioxide between the lungs and the bloodstream.\nWhat disease is it? \nAdenocarcinoma \nThis could be a artwork im pression of bodys fabric, textures. \nThe image shows chronic small airways disease, also known \nas COPD. There is mildly nodular opacity in the right lower \nlobe, suggestive of pneumonia. The left lung appears clear. \nNo pleural or subpleural consolidation are seen. No \nsignificant mediastinal or hilar adenopathy\nIn the superficial epithelium, tumors infiltrating in a diffuse \nmanner are observed. It is difficult to determine the \nhistological type of the tumor because the biopsy specimen is \nnot available. However, based on the macroscopic \nappearance of the tumor infiltrating in a diffuse manner, the \npossibility of a poorly differentiated adenocarcinoma, such as \nscirrhated type (poorly differentiated adenocarcinoma with \nmucinous differentiation), should be considered. \nThe image shows a tissue section of a lung, which has been \nstained with hematoxylin and eosin (H&E) stain. The section \nshows the structure of the lung tissue, including the airways, \nalveoli, and blood vessels.\nMedAGI\nSkinGPT -4\nXrayChat\nPathologyChat\nMiniGPT -4\nFig. 4. Comparison of MedAGI, SkinGPT-4, XrayChat, PathologyChat, and MiniGPT-4 on three stained pathology cases.The green tick\nindicates that the answer is correct.\nMedAGI could be seamlessly applied to domains such\nas cardiology, neurology, radiology, oncology, and many\nothers. By leveraging domain-specific medical LLMs and\nincorporating them into the MedAGI framework, the sys-\ntem could analyze and interpret data from diverse medical\nspecialities. This scalability enables healthcare professionals\nto access MedAGI’s domain-generic capabilities across a\nbroader spectrum of medical disciplines.\n3 M ETHODS\n3.1 Data processing and model training\nTo demonstrate the robustness of MedAGI, we evaluated\nit in three medical domains, including dermatology diag-\nnosis, X-ray diagnosis, and analysis of pathology pictures\nby implementing SkinGPT-4, XrayChat, and PathologyChat\nwith MiniGPT-4 as the backbone, and gathering the expert\nalignment layer from them.\nTo implement SkinGPT-4, we followed the procedures\ndemonstrated in [40] and used two public datasets (SKIN-\nCON [45] and Dermnet) and a private in-house dataset,\nwhere the public datasets were used for the step 1 training,\nand the second public dataset and our in-house dataset were\nused for the step 2 training.\nTo implement XrayChat, we followed the procedures\ndemonstrated in [43] and used 400K chest X-ray images and\ninstructions, from Open-i and MIMIC CXR [46].\nTo implement PathologyChat, we collected 262,777\npatches extracted from 991 H&E-stained gastric slides with\nAdenocarcinoma subtypes paired with captions extracted\nfrom medical reports [47].\nDuring the training of both steps, the max number of\nepochs was fixed to 5, the iteration of each epoch was set\nto 5000, the warmup step was set to 5000, batch size was\nset to 2, the learning rate was set to 1e-4, and max text\nlength was set to 160. The entire fine-tuning process re-\nquired approximately 9 hours to complete and utilized two\nNVIDIA V100 (32GB) GPUs. The training was conducted on\na workstation equipped with 252 GB RAM, 112 CPU cores,\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 29, 2023. ; https://doi.org/10.1101/2023.06.23.23291802doi: medRxiv preprint \n6\nand two NVIDIA V100 GPUs.\n3.2 Algorithm for Adaptive Selection of Expert Align-\nment Layers\nOur expert alignment layer selection considers both the\nuser question and different model instructions. The model\ndescription is derived from the abstract of the correspond-\ning paper. Formally, we represent the user input as q =\n{wq\n1, ··· , wq\nLq }, where wq\ni is the i-th word, and Lq is the\ninput length. Similarly, the j-th model description is de-\nnoted as d = {wd,j\n1 , ··· , wd,j\nLd }. We employ a BERT model\npre-trained on 215M question-answering pairs from diverse\nsources [48] to encode each word sequence:\nn\nhq\ni , ··· , hq\nLq\no\n= Enc\n\u0010\nwq\n1, ··· , wq\nLq\n\u0011\n,\nn\nhd,j\ni , ··· , hd,j\nLd\no\n= Enc\n\u0010\nwd,j\n1 , ··· , wd,j\nLd\n\u0011\n.\n(1)\nwhere Enc is the encoder module in BERT which outputs\nthe vector representation hq\ni of each input token wq\n1 in user\ninput and hd,j\ni of each input token wd,j\n1 in the j-th model\ndescription. To obtain a vector representation of the user\ninput, we apply the mean-pooling operation to the hidden\nstates of tokens:\nu = Mean-pooling\n\u0010n\nhd\ni , ··· , hd\nLd\no\u0011\n. (2)\nThe j-th model description is obtained as similarly vj. At\ninference, when predicting similarities between the two\ninputs, only the sentence embeddings u and vj are used\nin combination with cosine-similarity:\nsj = similarity(u, vj). (3)\nThe model that obtains the highest s score will be selected\nas the answering model.\nThe descriptions of SkinGPT-4, XrayChat, and Patholo-\ngyChat in MedAGI were set as below:\nSkinGPT-4: SkinGPT is a revolutionary dermatology diag-\nnostic system that utilizes an advanced vision-based large lan-\nguage model to assess skin conditions. By uploading personal skin\nphotos to the system, users receive an autonomous analysis that\ncan identify and categorize various skin conditions, and provide\ntreatment recommendations.\nXrayChat: XrayChat is a cutting-edge system that enables\ninteractive, multi-turn conversations about chest X-ray images.\nUsers simply upload a chest X-ray image, ask any question\nabout it, and XrayChat generates informed responses. The system\nutilizes an X-ray encoder, a large language model, and an adaptor\nto comprehend the X-ray image and produce accurate and helpful\nanswers.\nPathologyChat: PathologyChat is a cutting-edge system\nthat enables interactive, multi-round conversations about stained\npathology images. Users simply upload a pathology image, ask\nany question about it, and PathologyChat generates informed\nresponses.\n4 C ONCLUSION AND DISCUSSION\nWith the increasing number of domain-specific professional\nmultimodal LLMs in the medical field, combining these\nmodels into a unified platform could prove to be a mean-\ningful task. MedAGI is one of the possible solutions to unify\ndomain-specific medical LLMs with the lowest cost.\nIn conclusion, MedAGI presents a promising paradigm\nfor unifying domain-specific medical large language mod-\nels (LLMs). By automatically selecting appropriate medi-\ncal models based on users’ questions, MedAGI eliminates\nthe need for users to navigate multiple platforms and in-\nstructions, reducing costs and improving user experience.\nMedAGI represents a significant step towards the realiza-\ntion of medical artificial general intelligence. Its unified\napproach, scalability, and adaptability make it a compelling\nsolution for the future of medical AI.\n5 A CKNOWLEDGEMENTS\nFunding: Juexiao Zhou, Xiuying Chen, and Xin Gao were\nsupported in part by grants from the Office of Research\nAdministration (ORA) at King Abdullah University of\nScience and Technology (KAUST) under award number\nFCC/1/1976-44-01, FCC/1/1976-45-01, REI/1/5202-01-01,\nREI/1/5234-01-01, REI/1/4940-01-01, RGC/3/4816-01-01,\nand REI/1/0018-01-01.\nCompeting Interests: The authors have declared no\ncompeting interests.\nAuthor Contribution Statements: J.Z., X.C. and X.G.\nconceived of the presented idea. J.Z. and X.C. designed\nthe computational framework and analysed the data. X.G.\nsupervised the findings of this work. J.Z., X.C. and X.G. took\nthe lead in writing the manuscript. All authors discussed\nthe results and contributed to the final manuscript.\nData availability: The data for pathology can\nbe accessed at https://github.com/masatsuneki/\nhistopathology-image-caption. The data for XrayChat can\nbe accessed at https://github.com/UCSD-AI4H/xraychat.\nThe SKINCON dataset can be accessed at\nhttps://skincon-dataset.github.io/. The Dermnet dataset\ncan be accessed at https://www.kaggle.com/datasets/\nshubhamgoel27/dermnet. The restricted in-house skin\ndisease images of SkinGPT-4 are not publicly available due\nto restrictions in the data-sharing agreement.\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 29, 2023. ; https://doi.org/10.1101/2023.06.23.23291802doi: medRxiv preprint \n7\nCode availability: The code proposed by MedAGI is\npublicly available at https://github.com/JoshuaChou2018/\nMedAGI.\nREFERENCES\n[1] B. Goertzel, “Artificial general intelligence: concept, state of the\nart, and future prospects,” Journal of Artificial General Intelligence ,\n2014.\n[2] P . H. Winston, Artificial intelligence. Addison-Wesley Longman\nPublishing Co., Inc., 1984.\n[3] S. Bubeck, V . Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz,\nE. Kamar, P . Lee, Y. T. Lee, Y. Li, S. Lundberg et al., “Sparks of\nartificial general intelligence: Early experiments with gpt-4,” arXiv\npreprint arXiv:2303.12712, 2023.\n[4] T. H. Kung, M. Cheatham, A. Medenilla, C. Sillos, L. De Leon,\nC. Elepa ˜no, M. Madriaga, R. Aggabao, G. Diaz-Candido,\nJ. Maningo et al., “Performance of chatgpt on usmle: Potential for\nai-assisted medical education using large language models,” PLoS\ndigital health, 2023.\n[5] M. Sallam, N. Salim, M. Barakat, and A. Al-Tammemi, “Chat-\ngpt applications in medical, dental, pharmacy, and public health\neducation: A descriptive study highlighting the advantages and\nlimitations,” Narra J, 2023.\n[6] M. Balas and E. B. Ing, “Conversational ai models for ophthalmic\ndiagnosis: Comparison of chatgpt and the isabel pro differential\ndiagnosis generator,” JFO Open Ophthalmology, 2023.\n[7] R. K. Sinha, A. D. Roy, N. Kumar, H. Mondal, and R. Sinha, “Ap-\nplicability of chatgpt in assisting to solve higher order problems\nin pathology,” Cureus, 2023.\n[8] R. Vaishya, A. Misra, and A. Vaish, “Chatgpt: Is this version\ngood for healthcare and research?” Diabetes & Metabolic Syndrome:\nClinical Research & Reviews, 2023.\n[9] S. Wang, Z. Zhao, X. Ouyang, Q. Wang, and D. Shen, “Chatcad:\nInteractive computer-aided diagnosis on medical image using\nlarge language models,” arXiv preprint arXiv:2302.07257, 2023.\n[10] H. Li, D. Guo, W. Fan, M. Xu, and Y. Song, “Multi-step jailbreaking\nprivacy attacks on chatgpt,” arXiv preprint arXiv:2304.05197, 2023.\n[11] B. Lund and D. Agbaji, “Information literacy, data literacy, privacy\nliteracy, and chatgpt: Technology literacies align with perspectives\non emerging technology adoption within communities,” Data Lit-\neracy, Privacy Literacy, and ChatGPT: Technology Literacies Align with\nPerspectives on Emerging Technology Adoption within Communities\n(January 14, 2023), 2023.\n[12] P . Rajpurkar, E. Chen, O. Banerjee, and E. J. Topol, “Ai in health\nand medicine,” Nature medicine, 2022.\n[13] J. Zhou, S. Chen, Y. Wu, H. Li, B. Zhang, L. Zhou, Y. Hu, Z. Xiang,\nZ. Li, N. Chen et al., “Ppml-omics: a privacy-preserving federated\nmachine learning system protects patients’ privacy from omic\ndata,” bioRxiv, 2022.\n[14] J. Zhou, L. Zhou, D. Wang, X. Xu, H. Li, Y. Chu, W. Han, and\nX. Gao, “Personalized and privacy-preserving federated heteroge-\nneous medical image analysis with pppml-hmi,” medRxiv, 2023.\n[15] J. Zhou, H. Li, X. Liao, B. Zhang, W. He, Z. Li, L. Zhou, and X. Gao,\n“Audit to forget: A unified method to revoke patients’ private data\nin intelligent healthcare,” bioRxiv, 2023.\n[16] J. Li, D. Li, S. Savarese, and S. Hoi, “Blip-2: Bootstrapping\nlanguage-image pre-training with frozen image encoders and\nlarge language models,” arXiv preprint arXiv:2301.12597, 2023.\n[17] P . Gao, J. Han, R. Zhang, Z. Lin, S. Geng, A. Zhou, W. Zhang, P . Lu,\nC. He, X. Yue et al., “Llama-adapter v2: Parameter-efficient visual\ninstruction model,” arXiv preprint arXiv:2304.15010, 2023.\n[18] Q. Ye, H. Xu, G. Xu, J. Ye, M. Yan, Y. Zhou, J. Wang,\nA. Hu, P . Shi, Y. Shi et al., “mplug-owl: Modularization empow-\ners large language models with multimodality,” arXiv preprint\narXiv:2304.14178, 2023.\n[19] D. Zhu, J. Chen, X. Shen, X. Li, and M. Elhoseiny, “Minigpt-4:\nEnhancing vision-language understanding with advanced large\nlanguage models,” arXiv preprint arXiv:2304.10592, 2023.\n[20] H. Zhang, X. Li, and L. Bing, “Video-llama: An instruction-tuned\naudio-visual language model for video understanding,” arXiv\npreprint arXiv:2306.02858, 2023.\n[21] W. Dai, J. Li, D. Li, A. M. H. Tiong, J. Zhao, W. Wang, B. Li,\nP . Fung, and S. Hoi, “Instructblip: Towards general-purpose\nvision-language models with instruction tuning,” arXiv preprint\narXiv:2305.06500, 2023.\n[22] K. Li, Y. He, Y. Wang, Y. Li, W. Wang, P . Luo, Y. Wang, L. Wang,\nand Y. Qiao, “Videochat: Chat-centric video understanding,”arXiv\npreprint arXiv:2305.06355, 2023.\n[23] T. Gong, C. Lyu, S. Zhang, Y. Wang, M. Zheng, Q. Zhao, K. Liu,\nW. Zhang, P . Luo, and K. Chen, “Multimodal-gpt: A vision\nand language model for dialogue with humans,” arXiv preprint\narXiv:2305.04790, 2023.\n[24] J.-B. Alayrac, J. Donahue, P . Luc, A. Miech, I. Barr, Y. Hasson,\nK. Lenc, A. Mensch, K. Millican, M. Reynolds et al., “Flamingo:\na visual language model for few-shot learning,” Proc. of NeurIPS,\n2022.\n[25] Y.-L. Sung, J. Cho, and M. Bansal, “Vl-adapter: Parameter-efficient\ntransfer learning for vision-and-language tasks,” in Proc. of CVPR,\n2022.\n[26] D. Driess, F. Xia, M. S. Sajjadi, C. Lynch, A. Chowdhery, B. Ichter,\nA. Wahid, J. Tompson, Q. Vuong, T. Yuet al., “Palm-e: An embod-\nied multimodal language model,” arXiv preprint arXiv:2303.03378,\n2023.\n[27] S. Huang, L. Dong, W. Wang, Y. Hao, S. Singhal, S. Ma, T. Lv,\nL. Cui, O. K. Mohammed, Q. Liu et al., “Language is not all you\nneed: Aligning perception with language models,” arXiv preprint\narXiv:2302.14045, 2023.\n[28] Z. Zhang, A. Zhang, M. Li, H. Zhao, G. Karypis, and A. Smola,\n“Multimodal chain-of-thought reasoning in language models,”\narXiv preprint arXiv:2302.00923, 2023.\n[29] J. Y. Koh, R. Salakhutdinov, and D. Fried, “Grounding language\nmodels to images for multimodal generation,” arXiv preprint\narXiv:2301.13823, 2023.\n[30] H. Liu, C. Li, Q. Wu, and Y. J. Lee, “Visual instruction tuning,”\narXiv preprint arXiv:2304.08485, 2023.\n[31] J. Y. Koh, D. Fried, and R. Salakhutdinov, “Generating images with\nmultimodal language models,” arXiv preprint arXiv:2305.17216,\n2023.\n[32] F. Chen, M. Han, H. Zhao, Q. Zhang, J. Shi, S. Xu, and\nB. Xu, “X-llm: Bootstrapping advanced large language models\nby treating multi-modalities as foreign languages,” arXiv preprint\narXiv:2305.04160, 2023.\n[33] B. Li, Y. Zhang, L. Chen, J. Wang, J. Yang, and Z. Liu, “Otter:\nA multi-modal model with in-context instruction tuning,” arXiv\npreprint arXiv:2305.03726, 2023.\n[34] Z. Wang, G. Zhang, K. Yang, N. Shi, W. Zhou, S. Hao, G. Xiong,\nY. Li, M. Y. Sim, X. Chen, Q. Zhu, Z. Yang, A. Nik, Q. Liu, C. Lin,\nS. Wang, R. Liu, W. Chen, K. Xu, D. Liu, Y. Guo, and J. Fu,\n“Interactive natural language processing,” 2023.\n[35] Y. Li, B. Hu, X. Chen, L. Ma, and M. Zhang, “Lmeye: An interactive\nperception network for large language models,” arXiv preprint\narXiv:2305.03701, 2023.\n[36] Y. Su, T. Lan, H. Li, J. Xu, Y. Wang, and D. Cai, “Pandagpt:\nOne model to instruction-follow them all,” arXiv preprint\narXiv:2305.16355, 2023.\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 29, 2023. ; https://doi.org/10.1101/2023.06.23.23291802doi: medRxiv preprint \n8\n[37] R. Girdhar, A. El-Nouby, Z. Liu, M. Singh, K. V . Alwala, A. Joulin,\nand I. Misra, “Imagebind: One embedding space to bind them all,”\nin Proc. of CVPR, 2023.\n[38] C. Li, C. Wong, S. Zhang, N. Usuyama, H. Liu, J. Yang, T. Nau-\nmann, H. Poon, and J. Gao, “Llava-med: Training a large language-\nand-vision assistant for biomedicine in one day,” arXiv preprint\narXiv:2306.00890, 2023.\n[39] Y. Sun, C. Zhu, S. Zheng, K. Zhang, Z. Shui, X. Yu, Y. Zhao, H. Li,\nY. Zhang, R. Zhao et al., “Pathasst: Redefining pathology through\ngenerative foundation ai assistant for pathology,” arXiv preprint\narXiv:2305.15072, 2023.\n[40] J. Zhou, X. He, L. Sun, J. Xu, X. Chen, Y. Chu, L. Zhou, X. Liao,\nB. Zhang, and X. Gao, “Skingpt-4: An interactive dermatology\ndiagnostic system with visual large language model,” medRxiv,\n2023.\n[41] H. Guo, M. Huo, R. Zhang, and P . Xie, “Proteinchat: Towards\nachieving chatgpt-like functionalities on protein 3d structures,”\n2023.\n[42] O. Thawkar, A. Shaker, S. S. Mullappilly, H. Cholakkal, R. M.\nAnwer, S. Khan, J. Laaksonen, and F. S. Khan, “Xraygpt: Chest\nradiographs summarization using medical vision-language mod-\nels,” arXiv preprint arXiv:2306.07971, 2023.\n[43] Y. Liang, H. Guo, and P . Xie, “Xraychat: Towards enabling chatgpt-\nlike capabilities on chest x-ray images,” 2023.\n[44] Y. Fang, W. Wang, B. Xie, Q. Sun, L. Wu, X. Wang, T. Huang,\nX. Wang, and Y. Cao, “Eva: Exploring the limits of masked visual\nrepresentation learning at scale,” arXiv preprint arXiv:2211.07636,\n2022.\n[45] R. Daneshjou, M. Yuksekgonul, Z. R. Cai, R. Novoa, and J. Y. Zou,\n“Skincon: A skin disease dataset densely annotated by domain\nexperts for fine-grained debugging and analysis,” Proc. of NeurIPS,\n2022.\n[46] A. E. Johnson, T. J. Pollard, S. J. Berkowitz, N. R. Greenbaum, M. P .\nLungren, C.-y. Deng, R. G. Mark, and S. Horng, “Mimic-cxr, a de-\nidentified publicly available database of chest radiographs with\nfree-text reports,” Scientific data, 2019.\n[47] M. Tsuneki and F. Kanavati, “Inference of captions from\nhistopathological patches,” in International Conference on Medical\nImaging with Deep Learning, 2022.\n[48] N. Reimers and I. Gurevych, “Sentence-bert: Sentence embeddings\nusing siamese bert-networks,” in Proc. of EMNLP, 2019.\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 29, 2023. ; https://doi.org/10.1101/2023.06.23.23291802doi: medRxiv preprint "
}