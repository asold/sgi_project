{
  "title": "Analysing Utterances in LLM-Based User Simulation for Conversational Search",
  "url": "https://openalex.org/W4392471527",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5049735488",
      "name": "Ivan Sekulić",
      "affiliations": [
        "Università della Svizzera italiana"
      ]
    },
    {
      "id": "https://openalex.org/A5113134376",
      "name": "Mohammad Alinannejadi",
      "affiliations": [
        "Amsterdam University of the Arts",
        "University of Amsterdam"
      ]
    },
    {
      "id": "https://openalex.org/A5012367814",
      "name": "Fábio Crestani",
      "affiliations": [
        "Università della Svizzera italiana"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3131173775",
    "https://openalex.org/W2156958921",
    "https://openalex.org/W2988647680",
    "https://openalex.org/W1970548730",
    "https://openalex.org/W4231332297",
    "https://openalex.org/W2944069152",
    "https://openalex.org/W3153046263",
    "https://openalex.org/W2084437982",
    "https://openalex.org/W6817407411",
    "https://openalex.org/W819437299",
    "https://openalex.org/W4284695140",
    "https://openalex.org/W3047936157",
    "https://openalex.org/W3193746305",
    "https://openalex.org/W1719347172",
    "https://openalex.org/W3102854726",
    "https://openalex.org/W2590822507",
    "https://openalex.org/W3156287428",
    "https://openalex.org/W2964112275",
    "https://openalex.org/W2339852062",
    "https://openalex.org/W4229022629",
    "https://openalex.org/W3179890742",
    "https://openalex.org/W3104405162",
    "https://openalex.org/W3100591766"
  ],
  "abstract": "Clarifying underlying user information needs by asking clarifying questions is an important feature of modern conversational search systems. However, evaluation of such systems through answering prompted clarifying questions requires significant human effort, which can be time-consuming and expensive. In our recent work, we proposed an approach to tackle these issues with a user simulator, USi . Given a description of an information need, USi is capable of automatically answering clarifying questions about the topic throughout the search session. However, while the answers generated by USi are both in line with the underlying information need and in natural language, a deeper understanding of such utterances is lacking. Thus, in this work, we explore utterance formulation of large language model (LLM)–based user simulators. To this end, we first analyze the differences between USi , based on GPT-2, and the next generation of generative LLMs, such as GPT-3. Then, to gain a deeper understanding of LLM-based utterance generation, we compare the generated answers to the recently proposed set of patterns of human-based query reformulations. Finally, we discuss potential applications as well as limitations of LLM-based user simulators and outline promising directions for future work on the topic.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.9316747784614563
    },
    {
      "name": "Natural language processing",
      "score": 0.5232124328613281
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4792878031730652
    },
    {
      "name": "Speech recognition",
      "score": 0.4634546935558319
    },
    {
      "name": "Human–computer interaction",
      "score": 0.41369134187698364
    },
    {
      "name": "Information retrieval",
      "score": 0.3619783818721771
    }
  ]
}