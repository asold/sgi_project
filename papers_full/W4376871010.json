{
    "title": "Supervised deep learning with vision transformer predicts delirium using limited lead EEG",
    "url": "https://openalex.org/W4376871010",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A3025119602",
            "name": "Malissa A Mulkey",
            "affiliations": [
                "University of South Carolina"
            ]
        },
        {
            "id": "https://openalex.org/A2920477220",
            "name": "Huyunting Huang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2288208475",
            "name": "Thomas Albanese",
            "affiliations": [
                "East Carolina University"
            ]
        },
        {
            "id": "https://openalex.org/A2111879947",
            "name": "Sunghan Kim",
            "affiliations": [
                "East Carolina University"
            ]
        },
        {
            "id": "https://openalex.org/A2126001540",
            "name": "Baijian Yang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A3025119602",
            "name": "Malissa A Mulkey",
            "affiliations": [
                "University of South Carolina"
            ]
        },
        {
            "id": "https://openalex.org/A2920477220",
            "name": "Huyunting Huang",
            "affiliations": [
                "Purdue University West Lafayette"
            ]
        },
        {
            "id": "https://openalex.org/A2288208475",
            "name": "Thomas Albanese",
            "affiliations": [
                "East Carolina University"
            ]
        },
        {
            "id": "https://openalex.org/A2111879947",
            "name": "Sunghan Kim",
            "affiliations": [
                "East Carolina University"
            ]
        },
        {
            "id": "https://openalex.org/A2126001540",
            "name": "Baijian Yang",
            "affiliations": [
                "Purdue University West Lafayette"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4247665917",
        "https://openalex.org/W2749370990",
        "https://openalex.org/W2807158197",
        "https://openalex.org/W2885896746",
        "https://openalex.org/W2581138085",
        "https://openalex.org/W2999188445",
        "https://openalex.org/W3130495671",
        "https://openalex.org/W2007071015",
        "https://openalex.org/W3203940729",
        "https://openalex.org/W2066148935",
        "https://openalex.org/W4292101337",
        "https://openalex.org/W3216412661",
        "https://openalex.org/W2922348724",
        "https://openalex.org/W2055513188",
        "https://openalex.org/W2090773675",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W3177342940",
        "https://openalex.org/W3128513378",
        "https://openalex.org/W4321349946",
        "https://openalex.org/W4311414773",
        "https://openalex.org/W2947933227",
        "https://openalex.org/W2123098876",
        "https://openalex.org/W2138141660",
        "https://openalex.org/W2004284087",
        "https://openalex.org/W2149407814",
        "https://openalex.org/W2162800060",
        "https://openalex.org/W4288063384",
        "https://openalex.org/W3118861534",
        "https://openalex.org/W4226252250",
        "https://openalex.org/W4226542072"
    ],
    "abstract": null,
    "full_text": "1\nVol.:(0123456789)Scientific Reports |         (2023) 13:7890  | https://doi.org/10.1038/s41598-023-35004-y\nwww.nature.com/scientificreports\nSupervised deep learning \nwith vision transformer predicts \ndelirium using limited lead EEG\nMalissa A. Mulkey 1*, Huyunting Huang 2, Thomas Albanese 3, Sunghan Kim 3 & Baijian Yang 2\nAs many as 80% of critically ill patients develop delirium increasing the need for institutionalization \nand higher morbidity and mortality. Clinicians detect less than 40% of delirium when using a validated \nscreening tool. EEG is the criterion standard but is resource intensive thus not feasible for widespread \ndelirium monitoring. This study evaluated the use of limited-lead rapid-response EEG and supervised \ndeep learning methods with vision transformer to predict delirium. This proof-of-concept study used a \nprospective design to evaluate use of supervised deep learning with vision transformer and a rapid-\nresponse EEG device for predicting delirium in mechanically ventilated critically ill older adults. Fifteen \ndifferent models were analyzed. Using all available data, the vision transformer models provided \n99.9%+ training and 97% testing accuracy across models. Vision transformer with rapid-response EEG \nis capable of predicting delirium. Such monitoring is feasible in critically ill older adults. Therefore, \nthis method has strong potential for improving the accuracy of delirium detection, providing greater \nopportunity for individualized interventions. Such an approach may shorten hospital length of stay, \nincrease discharge to home, decrease mortality, and reduce the financial burden associated with \ndelirium.\nDelirium is an acute syndrome manifested by a change in global cognitive function that includes either disorgan-\nized thinking or an altered level of  consciousness1. Delirium occurs in as many as 80% of critically ill older adults \nand is associated with worse long term cognitive  outcomes2,3. For more than 20 years, at least 10 national and \ninternational health care professional organizations have included routine delirium screening in clinical practice \n guidelines4–6. Despite these recommendations and the availability of more than 40 validated screening tools, less \nthan 10% of clinicians report routinely screening for  delirium4,7. In the ICU environment, many patients are \nunable to participate in delirium screening, such as those in a comatose or deeply sedated state, and are there -\nfore, untestable. Even when these tools are used, delirium remains difficult to recognize and therefore frequently \nunderdiagnosed and undertreated. As the duration and severity of delirium increases it becomes increasingly \nmore difficult to treat. As a result, delirium is associated with a one-year increase in economic burden of more \nthan $44 K/patient, making it a global public health  crisis8.\nThe electroencephalogram (EEG) is a representative signal with information describing the condition of \nthe brain. The shape, amplitude, and oscillation speed of EEG waveforms help describe the condition and assist \nwith diagnostics as shown in Fig. 1. Use of EEG for delirium detection was first identified in the 1940’s. Romano \nand Engel identified slowing of EEG with increases in sleep and decreases in awake waves when delirium was \n present9,10. Thus, delirium has been reliably identified by examining changes in neural activity using the EEG. \nUnfortunately, the significant cost associated with technological set up and the need for expert analysis has \nprevented the use of EEG for delirium detection in the clinical  environment11,12.\nStep 1 Extract subsets from the data, each subset has record t sec. Split these subsets into training/testing set.\nStep 2 Transform subsets into ‘images’ (*).\nStep 3 Use these ‘images’ to feed ViT model.\nMore recently, user friendly handheld EEG devices with recording accuracy equivalent to traditional EEG that \nare programmed with rapid response analytic methods such as machine learning have become  available13. These \ndevices offer rapid setup by anyone with limited training, thus providing rapid EEG data (thus rapid response \nEEG) within minutes, unlike traditional EEG that can take up to an hour to setup and requires specially trained \nstaff. To evaluate EEG waveforms, signal parameters are extracted and analyzed using computer based statistical \nalgorithms. For example, nonlinear time series analysis offers insight into the dynamic nature and variability \nOPEN\n1College of Nursing, University of South Carolina, Columbia, SC, USA. 2Department of Computer and Information \nTechnology, Purdue University, Lafayette, IN, USA. 3Department of Engineering, University of East Carolina, \nGreenville, NC, USA. *email: malissam@mailbox.sc.edu\n2\nVol:.(1234567890)Scientific Reports |         (2023) 13:7890  | https://doi.org/10.1038/s41598-023-35004-y\nwww.nature.com/scientificreports/\nof brain  signals14. With the development of an algorithm capable of accurate predictive detection, newer EEG \ndevices may provide a feasible physiologic method to support clinicians with delirium detection.\nThe most widely used machine learning technique in current research and practice is called supervised \nmachine learning where the ground truth is known to the researchers and is labeled in the training dataset. \nSophisticated deep neural networks are often adopted and optimized to fit the needs of specific learning tasks in \nreal world scenarios. While deep-learning-based approach often outperforms the traditional statistical machine \nlearning algorithms in prediction accuracy, its Blackbox nature often makes the model impractical to use in the \nmedical field. Additional modules are often needed to help explain why or how the decision was made by the \ndeep learning algorithms.\nThe supervised deep learning model used in this study was Vision Transformer (ViT)15–17. The ViT model lev-\neraged the cutting-edge Transformer architecture that has revolutionized the field of Natural Language Processing \n(NLP). It should be noted that EEG data are typically sequential in nature. Therefore, sequential models, such as \n BERT18 and Fractional Dynamics Foster Deep Learning were often applied in the literature. However, EEG data \nin tabular format comprises a combination of waves with varying frequencies, which makes the conventional \nsequential approaches less  effective19. The EEG data in wave image format contains both temporal data and visual \npatterns. Due to its outstanding performance in computer vision related problems, ViT has been applied in \nrecent image classification tasks and improvements in performance have been seen over traditional CNN based \n frameworks20. In this work, we investigate how ViT can be used to gain intelligence from EEG data. We show \nthat applying ViT in time domain wave image format is much better than applying ViT in frequency domain.\nTo make the Transform model work for image classification tasks, the core idea is to slice an image into \na matrix of n × n sub-images. These sub-images are then treated as sequential data so that the self-attention \nmechanism can be applied to measure the relationship between pairs of sub-images. The benefit of ViT is the \nability to maintain spatial information as well as temporal information. EEG data are sequential and have a spatial \nrelationship, making the ViT an ideal model for this analysis. This paper describes how machine learning using \nVision Transformer can serve as an electronic means for detection of delirium, at minimal risk and low cost.\nMethods\nThis is the first prospective proof-of-concept pilot study using a rapid response EEG device providing data from \nall cerebral lobes, and a supervised deep learning method (Vision Transformer) to evaluate EEG for the presence \nof delirium in critically ill patients.\nThe study (UMCIRB 17-001900 MIND) was reviewed and approved by the East Carolina and Vidant Medical \nCenter Institutional Review Board (UMCIRB) on March 13, 2018. Written informed consent was obtained from \nthe participant’s legally authorized representative prior to any research activities. All research procedures were \nconducted in accordance with the ethical standards set by the UMCIRB IRB and the Helsinki Declaration of 1975.\nFigure 1.  Our working pipeline.\n3\nVol.:(0123456789)Scientific Reports |         (2023) 13:7890  | https://doi.org/10.1038/s41598-023-35004-y\nwww.nature.com/scientificreports/\nSetting/sample. The protocol for this study was previously published in  RINAH21. In brief, patients meet-\ning inclusion and exclusion criteria were recruited from three intensive care units (cardiac, medical, and surgical \nICU) in a large rural academic medical center in North Carolina between March 2019 and March 2020. All par-\nticipants were at least 50 years old and required mechanical ventilation for greater than 12 h who were English \nspeaking for whom written informed consent from the legally authorized representative was obtained. Exclusion \ncriteria included acute brain injury, seizures, or condition preventing participation in the delirium screening. \nConsent was obtained prior to enrollment from the legally authorized representative because participants were \nunable to self-consent.\nEach day, the patient was assessed for the ability to participate in a delirium screening determined using the \nRichmond Agitation Sedation Scale (RASS) 22,23. The RASS is a 10 level scale (+  4 “combative” to − 5 “unarous-\nable”) with excellent inter-rater reliability (r = 0.956, lower 90% confidence limit = 0.948; κ = 0.73, 95% confidence \ninterval = 0.71, 0.75)22,23. A RASS score of − 2 or higher (able to open eyes for > 10 s to voice) met eligibility.\nDemographic and clinical characteristics were obtained from the electronic medical record (EMR).\nMeasures. Bedside behavioral assessment for delirium. The Confusion Assessment Method for the Intensive \nCare Unit (CAM-ICU) is a modified version of the CAM that was developed to assess mechanically ventilated \nand non-verbal patients in the  ICU24,25. The CAM-ICU is based on the gold standard for delirium identification, \nthe Diagnostic and Statistical Manual for Mental Disorder IV (DSM-IV) and one of two delirium screening tools \nrecommended for use by the Society of Critical Care Medicine (SCCM) 1,4,26. The CAM-ICU requires patient \nparticipation to identify four key features of delirium including an (a) acute onset or fluctuation in mental status \nwithin the previous 24 h., (b) inattention, (c) altered level of consciousness [Richmond Agitation Sedation Scale \n(RASS) ≠ 0], and (d) disorganized  thinking24,25. When used in research the CAM-ICU has high sensitivity and \nspecificity, 93 and 98% respectively and high inter-rater reliability at k.0.79.\nPhysiologic assessment for delirium. Rapid response EEG headbands that circumscribe the head were applied \nto each participant daily. Accuracy of placement is based on location of the headband fastener in the center of \nthe forehead, electrodes are numbered 1–10, headband connects to the recorder at the hairline on the back of \nthe head, EEG waveforms are immediately visualized on the EEG recorder and the recorder identifies quality of \nconnection (e.g., impedance) using a color-coded diagram (green = low impedance/red = high impedance) of the \nheadband. EEG monitoring occurred for 2 h each evening between 5 pm and 9 pm (1700–2100) for four days \nor ICU discharge. After one hour of EEG monitoring, the participant was assessed for delirium by the research \nteam using the Confusion Assessment Method for the ICU (CAM-ICU). To be considered delirium positive \nusing the CAM-ICU the participant must have at least three of the core components of delirium including an \nacute change in baseline mental status, exhibit inattention, and have either an altered level of consciousness or \ndisorganized thinking.\nProcessing the EEG data. Prior to analysis, EEG data were processed to remove artifacts such as muscle move-\nment in the face and interference from nearby devices such as ventilators and cardiac monitors. To do this, high \nand low frequencies are removed using filters. Data are then re-referenced to estimate physiological noise and \ndivided into multiple discrete time periods called epochs. After pre-processing, EEG data is further “cleaned” \nusing Individual component analysis (IDA) to remove noises and generate features needed for machine learn-\ning algorithms. Component analysis is a widely accepted method to clean data by separating artifact from data \nderived from cortical  processes14,27. The benefit of independent component analysis with higher order statistics \nis the ability to simply subtract artifacts by directly examining the independent components of the data.\nMachine learning. EEG analytic techniques across studies have varied. Therefore, both traditional and three \nmachine learning methods were used initially to analyze these data, specifically random forest (series of decision \ntrees), stepwise linear discriminant analysis (removes variables that do not help classify the data, in this case \ndelirium−/delirium+), and support vector machine (computer builds a model to provide the greatest difference \nbetween categories, in this case delirium−/delirium+). Due to challenges with feature selection, a supervised \ndeep learning method, i.e., Vision Transformer, was primarily used in this analysis. It is observed in many deep \nlearning applications that sophisticated data processing techniques and feature engineering are often not needed \nbecause the deep neural networks can learn those subtle features directly from the input data. Two types of data \nwere therefore studied. The first type of input data was preprocessed (muscle movement and device interference \nremoval) and IDA cleaned while and the second type of input received only preprocessing with no IDA cleaning. \nData were extracted every 4 ms from the EEG devices and each data sample contains the reading of eight sensors.\nA continues of number of rows of data is organized into a data slice, which is an  8 × n array, where n rep-\nresents the number of rows. These arrays are resized to 224 × 224 using Bilinear interpolate and are treated as \nimages to feed into the ViT model, as shown in Fig. 2.\nOur main objective was to identify the frequency range within the wave images that has the most effect on \nthe classification results. Our assumption is that if an image segment does not contain a complete cycle of waves \nat a particular frequency, then the effect of this frequency is unlikely to be significant in the classification results. \nControlling the length of data slices can control the range of frequencies the image will include. For example, if \nn = 25 , then the time span of that wave image is 0.1s and the corresponding frequency is f > 10 Hz . In short, \nn determines the lowest frequency that an image would include. To study the impact of partial frequencies at \ndifferent phases and to augment the data size, we partitioned the wave images with overlapping segments. Such \ntreatment can better reflect the relationship of waves with different frequencies.\n4\nVol:.(1234567890)Scientific Reports |         (2023) 13:7890  | https://doi.org/10.1038/s41598-023-35004-y\nwww.nature.com/scientificreports/\nTo understand how the results are related to the sizes of the slices, five different lengths were chosen: twenty-\nfive rows (0.1 s), 125 rows (0.5 s), 250 rows (1 s), 400 rows (1.6 s), and 1250 rows (5 s). Due to the small size of \npopulation, data is augmented using an overlapping window scheme, where the starting row of the next data slice \nis found somewhere in the current data slice, rather than after the last row of the current data slice. An example \nof 30% overlapping data slice of one second (250 rows) is shown in Fig. 3. Relevant signals in EEG study include \nthe alpha (8–12 Hz), beta (15–30 Hz), delta (0.5–3 Hz), gamma (> 30 Hz), and theta (4–7 Hz) waves. If we use T \nto represent the time span of each data slice, then the frequency an image can detect is f = 1\nT  . In the study, the \nhighest minimum frequency it can detect is 10 Hz  when T = 0.1s , and the lowest minimum frequency it can \ndetect is 0.2 Hz  , when T = 5s . The data slices are randomly split into testing and training sets while avoiding \nFigure 2.  The confusion matrix for the experiment.\nFigure 3.  Working pipeline for models trained under frequency domain in comparison experiment.\n5\nVol.:(0123456789)Scientific Reports |         (2023) 13:7890  | https://doi.org/10.1038/s41598-023-35004-y\nwww.nature.com/scientificreports/\nputting all the data from any one subject into one (training + testing) set. Positive cases and negatives in both \nthe training sets and the testing sets are relatively balanced, with a ratio close to one.\nThe default hyper-parameters of the model were used in this study: batch size = 64, learning rate = 0.001, \ndepth = 12, and heads = 8. Overlapping ratio of 75%, 90%, and 95% were studied. Since no major differences \nwere discovered among these different overlapping ratios, 90% windows overlapping ratio was used to report \nthe results. EGG data converges very quickly when using ViT model. In most situations, training accuracies \nachieved more than 99% in as little as three epochs. To avoid overfitting, model trained after 5 epochs were used \nto evaluate the testing datasets.\nThe reason for using ViT, a transformer-based CV model instead of transformer-based language model is \nthat the data are a mix of waves of different frequencies. Given that waves are recurring periodically, an image \nsegment containing at least one full cycle of a particular frequency may not provide sufficient information to \nanalyze its data. This study investigated the image segments that contain a collection of waves with different \nfrequencies. Since EEG data are best presented in wave image format, the Transformer based NLP model is not \nthe best suited model to analyze EEG wave images. As such, we decided to employ ViT rather than Transformer \nto analyze the data.\nNote also that it is a customary practice to transfer time series data into spectral images via transformation \ntechniques like fast Fourier transformation (FFT). We argue such transformation is not well suited for the ViT \nmodel. In this work, we also studied the effect of adding FFT to the process. The workflow is shown in Fig. 3.\nTo better understand the value of ViT model in EEG data analyses, a public  dataset28 were also used to perform \na binary classification task. The data slice of 1250 rows was adopted and the overlapping ratio was set to 90%. The \nmodel achieved testing accuracy of 86.33%, which is better than state-of-the-art algorithms SleepEEGNet at the \naccuracy of 80.03%. The pilot results show that ViT is a better fit to analyze EEG data than existing algorithms.\nResults\nFifteen different treatments (5 data slice sizes × 3 overlapping rate) were used to evaluate the performance of \nViT model. Since overlapping rates did not affect the accuracy results, only findings of over lapping rate = 90% \nwere reported, see Table 1.\nThe model reached best testing accuracy of 97.58% when data slice has a size of 1250 rows (5 s). Figure  4 \nillustrates the impact of data slices on prediction accuracy.\nWhen data slice is as little as twenty-five rows, it contains full cycles of waves that are higher than 10 Hz  . The \nprediction accuracy was merely 51.86%, suggesting the ViT did not learn anything useful from the data. The bad \nresults could suggest that waves with higher frequencies are less important when predicting delirium. It could \nalso because the sizes of the data slides were too small to be resized to a 224 × 224 images. When a data slice \ncontains at least a full cycle of 2 Hz waves (0.5 s, or 125 rows), the accuracy increased to 72.82%. When a data \nslice contains at least a full cycle of 1 Hz waves (1 s, or 250 rows), the accuracy is further increased to around 95%. \nTable 1.  Results of IDA cleaned data (overlapping rate = 90%). Significant values are in bold.\nTime (# of rows in a data slice) Training accuracy (%) Testing accuracy (%)\n0.1 s (25 rows) 99.99 51.86\n0.5 s (125 rows) 99.99 72.82\n1 s (250 ross) 99.99 94.99\n1.6 s (400 rows) 99.99 95.14\n5 s (1250 rows) 99.99 97.58\nFigure 4.  The confusion matrix for the comparison experiment, with the left portion showing the matrix for \nthe model trained in the frequency domain and the right portion depicting the matrix for the model trained in \nthe time domain.\n6\nVol:.(1234567890)Scientific Reports |         (2023) 13:7890  | https://doi.org/10.1038/s41598-023-35004-y\nwww.nature.com/scientificreports/\nBetter results are associated with waves with lower frequency. Further investigation is needed to fully understand \nif long wave signals, such as delta waves, are truly the predictors for delirium. In most of the experiments, the \nmodels converged in three epochs. Accuracies did not improve from epoch six to epoch ten.\nTo study the results of analyzing EEG data in frequency domain, we compared its confusion matrix against \nthe data in time domain. The experiment parameters were t = 5s , overlapping rate = 50% , and epochs were set \nto 4. Figure 4 presents the results of this contrastive study. It demonstrates that the model’s performance under \nthe time domain outperforms its performance under the frequency domain. These findings align with our discus-\nsion and further support the effectiveness of our feature extraction approach in time the domain and selection \nof the ViT model to analyze EEG data in wave image format.\nSince ViT worked well on data cleaned using IDA, it begs for the question: would ViT provide good predic-\ntion results on datasets that are not cleaned by IDA? To answer this question, uncleaned data were also fed to \nthe ViT model to evaluate the results. Data slices of 1250 were chosen with an overlapping rate of 90%. To our \nsurprises, both training and testing accuracies reached more than 99.99%. This may suggest that deep learning \ntechniques like ViT probably do not need any additional feature engineering techniques to achieve impressive \nresults. Because the dataset is small, it is too soon to make such a claim. Additional studies are needed to validate \nthis hypothesis.\nThe datasets collected by the researchers were limited to only twelve subjects and were used only on delirium \npredictions. What about other EEG datasets? We did another experiment to understand if ViT is still applicable. \nWe also applied ViT in a public EEG data  set28 to do a binary classification task. Under windows size of 1250 \npoints, the model reached 86.33% test accuracy.\nDiscussion\nThis is the first prospective pilot study using a 10-electrode rapid response EEG device providing data from all \nlobes in the cerebrum, supervised deep learning and ViT to evaluate EEG for the presence of delirium. This pilot \nestablished that such monitoring is feasible in critically ill older adults across medical, surgical, and cardiac ICUs. \nThe principal finding is that using supervised deep learning and a ViT platform, patients were accurately classified \nas delirium positive or delirium negative based on identifiable characteristics in EEG thus predicting the presence \nof delirium. These results were replicated using three methods of machine learning, supervised learning methods \nincluded stepwise linear discriminant analysis and support vector machines and supervised deep learning was \nconducted using ViT. Compared to prior studies using various machine learning and preprocessing methods, \nthe ViT model using the hyperparameters mentioned above has provided greater accuracy. For example, van \nSleuwen and  Sun29 used a 3-channel limited lead device to measure physiologically based methods using the \nConfusion Assessment Method-Severity Score. To obtain three channels or waveforms, they used 6-s EEG strips \nobtained from a 4-electrode frontal montage. Using this montage on 252 delirious and 121 non-delirious patients, \nthey obtained accuracies of 0.63–0.73 on the ROC curve meaning the model accurately predicted 63–70% of \ntrue positives for every possible decision threshold of the model. Similarly, Y amanashi and  Kajitani30 was able \nto obtain AUCs of 63–76% using a bispectral EEG with two channels. As a result, they recommended further \nstudies may benefit from deep learning models such as the one used in this pilot study.\nThe merit of this handheld rapid response EEG is its objectiveness compared to currently available bedside \nscreening methods. Additionally, this method does not require the use of a large EEG machine and specialized \ntechnicians for electrode placement that frequently limit large volume mass screening such as that needed to \nscreen for delirium in critical care units. Rapid response EEG is easy to use by busy hospital staff with minimal \ntraining. Use of pre-programmed algorithms, such as the one described here, limits the need for skilled inter -\npretation required when using traditional EEG. Therefore, this method of detection is not limited by subjectivity \nand rationalizing of results associated with bedside screening.\nWhile the ViT model used above has satisfactory performance there are still opportunities to improve predic-\ntion. For example, using a window of 10–60 s instead of the 1–5 s windows typically used in this type of analysis \nmay have provided more data points. During the pre-processing phase, our study used sequence extraction \nmeaning samples are obtained in a chronological sequential order and finite length. It is possible that constant \ncorrection or interpolation (removing data obtained from lead electrode that is bad) may provide a cleaner data \nset for analysis.\nLimitations. Limitations of this study include the small sample of thirteen participants with seven expe-\nriencing delirium during the monitoring period as determined by the CAM-ICU. EEG changes occur prior to \nsymptom onset and therefore, some of the participants may have had subsyndromal delirium detected using \nEEG that were not detected using bedside screening (CAM-ICU). Delirium assessments were conducted by the \nresearcher rather than using clinician assessments providing stronger reliability of delirium status. Heterogene-\nity of the sample with varying etiologies and medication exposures could have resulted in some EEG changes \nbeing reflected more than others in a subset of patients, thus minimizing generalizability. While this study has \nlimitations, consistent results have been obtained across methods of analysis (frequency ratios, supervised learn-\ning, and deep learning) providing strength to the findings.\nConclusions\nIn this analysis, we trained a ViT model to analyze EEG data under the constraint of a small sample and therefore \nlimited amount of data. Despite the use of a sequence extraction method for preprocessing, 97% accuracy is sig-\nnificantly better than the ~ 40% accuracy of clinician derived CAM-ICU assessments. Therefore, this method has \nstrong potential for improving accuracy of delirium detection, providing greater opportunity to implement and \nevaluate individualized interventions. Once early detection of brain dysfunction associated with poor outcomes \n7\nVol.:(0123456789)Scientific Reports |         (2023) 13:7890  | https://doi.org/10.1038/s41598-023-35004-y\nwww.nature.com/scientificreports/\nsuch as the need for institutionalization and higher mortality are readily available, it will be possible to identify \nreversible causes, followed by early intervention and close monitoring to avoid preventable complications. Hav-\ning a physiologic method for delirium detection may provide an opportunity to provide interventions when \ndelirium is more amenable to treatment Earlier intervention may shorten the hospital length of stay, increase a \npatient’s chance to go home after hospital discharge, decrease mortality rates, and reduce the financial burden \nassociated with delirium.\nData availability\nThe datasets generated and/or analyzed during the current study are not publicly available but are available from \nthe corresponding author on reasonable request.\nReceived: 11 October 2022; Accepted: 11 May 2023\nReferences\n 1. American Psychiatric Association. Diagnostic and Statistical Manual of Mental Disorders: DSM-5 (American Psychiatric Associa-\ntion, 2013).\n 2. Bashar, F. R. et al. Post-ICU psychological morbidity in very long ICU stay patients with ARDS and delirium. J. Crit. Care  43, \n88–94 (2018).\n 3. Mulkey, M. A. et al. Pathophysiology review: Seven neurotransmitters associated with delirium. Clin. Nurse Spec. 32(4), 195–211 \n(2018).\n 4. Devlin, J. W . et al. Clinical practice guidelines for the prevention and management of pain, agitation/sedation, delirium, immobility, \nand sleep disruption in adult patients in the ICU. Crit. Care Med. 46(9), e825–e873 (2018).\n 5. National Institute for Health and Care Excellence: Clinical Guidelines, in Rehabilitation for adults with complex psychosis . 2020, \nNational Institute for Health and Care Excellence (UK) Copyright ¬© NICE 2020.: London.\n 6. American Geriatric Society. American Geriatrics Society abstracted clinical practice guideline for postoperative delirium in older \nadults. J. Am. Geriatr. Soc. 63(1), 142–150 (2015).\n 7. Hunter, A. et al. Delirium screening in the intensive care unit using emerging QEEG techniques: A pilot study. AIMS Neurosci.  \n7(1), 1–16 (2020).\n 8. Gou, R. Y . et al. One-year medicare costs associated with delirium in older patients undergoing major elective surgery. JAMA Surg. \n156, 430–442 (2021).\n 9. Engel, G. L. & Romano, J. Delirium: Ii. reversibility of the electroencephalogram with experimental procedures. Arch. Neurol. \nPsychiatry 51(4), 378–392 (1944).\n 10. Romano, J. & Engel, G. L. Delirium: I. electroencephalographic data. Arch. Neurol. Psychiatry 51(4), 356–377 (1944).\n 11. van der Kooi, A. W . et al. Delirium detection using EEG: What and how to measure. Chest 147(1), 94–101 (2015).\n 12. Mulkey, M. A. et al. Rapid handheld continuous electroencephalogram (EEG) has the potential to detect delirium in older adults. \nDimens. Crit. Care Nurs. 41(1), 29–35 (2022).\n 13. Kamousi, B. et al. Comparing the quality of signals recorded with a rapid response EEG and conventional clinical EEG systems. \nClin. Neurophysiol. Pract. 4, 69–75 (2019).\n 14. Kannathal, N. et al. Characterization of EEG—A comparative study. Comput. Methods Programs Biomed. 80(1), 17–23 (2005).\n 15. Dosovitskiy, A., et al., An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv: 2010. 11929, \n2020.\n 16. Vaswani, A., et al. Attention is all you need. In Advances in Neural Information Processing Systems. 2017.\n 17. Kostas, D., Aroca-Ouellette, S. & Rudzicz, F . BENDR: Using transformers and a contrastive self-supervised learning task to learn \nfrom massive amounts of EEG data. Front. Hum. Neurosci. 15, 653659 (2021).\n 18. Acheampong, F . A., Nunoo-Mensah, H. & Chen, W . Transformer models for text-based emotion detection: A review of BERT-\nbased approaches. Artif. Intell. Rev. 54(8), 5789–5829 (2021).\n 19. Yin, C. et al. Fractional dynamics foster deep learning of COPD stage prediction. Adv. Sci. 10, 2203485 (2023).\n 20. Xue, F . et al. Vision transformer with attentive pooling for robust facial expression recognition. IEEE Trans. Affect. Comput. (2022).\n 21. Mulkey, M. A. et al. Methods of identifying delirium: A research protocol. Res. Nurs. Health 42(4), 246–255 (2019).\n 22. Sessler, C. N. et al. The Richmond Agitation-Sedation Scale: validity and reliability in adult intensive care unit patients. Am. J. \nRespir. Crit. Care Med. 166(10), 1338–1344 (2002).\n 23. Sessler, C. N. et al. Validity and reliability of a new agitation-sedation scale in a medical ICU population. Chest  118(Supplement \n4), 95S (2000).\n 24. Ely, E. W . et al. Delirium in mechanically ventilated patients: Validity and reliability of the Confusion Assessment Method for the \nIntensive Care Unit (CAM-ICU). JAMA 286(21), 2703–2710 (2001).\n 25. Ely, E. W . et al. Evaluation of delirium in critically ill patients: Validation of the Confusion Assessment Method for the Intensive \nCare Unit (CAM-ICU). Crit. Care Med. 29(7), 1370–1379 (2001).\n 26. American Psychiatric Association. Diagnostic and Statistical Manual of Mental Disorders: DSM-IV , 4th [rev.] ed (American Psy-\nchiatric Association, 1998).\n 27. Delorme, A., Sejnowski, T. & Makeig, S. Enhanced detection of artifacts in EEG data using higher-order statistics and independent \ncomponent analysis. Neuroimage 34(4), 1443–1449 (2007).\n 28. Goldberger, A. L. et al. PhysioBank, PhysioToolkit, and PhysioNet: components of a new research resource for complex physiologic \nsignals. Circulation 101(23), e215–e220 (2000).\n 29. van Sleuwen, M. et al. Physiological assessment of delirium severity: The electroencephalographic confusion assessment method \nseverity score (E-CAM-S). Crit. Care Med. 50(1), e11–e19 (2022).\n 30. Y amanashi, T. et al. Topological data analysis (TDA) enhances bispectral EEG (BSEEG) algorithm for detection of delirium. Sci. \nRep. 11(1), 304 (2021).\nAuthor contributions\nM.M. was responsible for conceptualizing the study design, interpreting the results of the analyses, drafting the \nmanuscript and agreeing to accuracy and integrity of the work. T.A. was responsible for designing and conduct-\ning the analysis, interpreting results, drafting the article and agreeing to the accuracy and integrity. H.H. was \nresponsible for designing the analysis, interpreting results, drafting the article and agreeing to the accuracy and \nintegrity. B.Y . was responsible for designing the analysis, interpreting results, drafting the article and agreeing to \nthe accuracy and integrity. S.K. was responsible for designing and conducting the analysis, interpreting results, \n8\nVol:.(1234567890)Scientific Reports |         (2023) 13:7890  | https://doi.org/10.1038/s41598-023-35004-y\nwww.nature.com/scientificreports/\ndrafting the article and agreeing to the accuracy and integrity. All authors have reviewed and approved the final \nversion.\nFunding\nMalissa Mulkey was funded by a NRSA T32 NR018407 from the National Institute of Nursing Research. This \nresearch study was funded by the American Association of Critical Care Nurses.\nCompeting interests \nThe authors declare no competing interests.\nAdditional information\nCorrespondence and requests for materials should be addressed to M.A.M.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\nOpen Access  This article is licensed under a Creative Commons Attribution 4.0 International \nLicense, which permits use, sharing, adaptation, distribution and reproduction in any medium or \nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the \nCreative Commons licence, and indicate if changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the \nmaterial. If material is not included in the article’s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from \nthe copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\n© The Author(s) 2023"
}