{
  "title": "A Recipe for Arbitrary Text Style Transfer with Large Language Models",
  "url": "https://openalex.org/W3197754201",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2011782780",
      "name": "Emily Reif",
      "affiliations": [
        "Google (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2799006035",
      "name": "Daphne Ippolito",
      "affiliations": [
        "Google (United States)",
        "University of Pennsylvania"
      ]
    },
    {
      "id": "https://openalex.org/A2111895186",
      "name": "Ann Yuan",
      "affiliations": [
        "Google (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2948422585",
      "name": "Andy Coenen",
      "affiliations": [
        "Google (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A4207984947",
      "name": "Chris Callison-Burch",
      "affiliations": [
        "University of Pennsylvania"
      ]
    },
    {
      "id": "https://openalex.org/A2324760462",
      "name": "Jason Wei",
      "affiliations": [
        "Google (United States)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2996287690",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W2170240176",
    "https://openalex.org/W2952335829",
    "https://openalex.org/W2963667126",
    "https://openalex.org/W2970562804",
    "https://openalex.org/W2938704169",
    "https://openalex.org/W2964008635",
    "https://openalex.org/W2963366196",
    "https://openalex.org/W3092144570",
    "https://openalex.org/W3160638507",
    "https://openalex.org/W3172642864",
    "https://openalex.org/W4226399820",
    "https://openalex.org/W3093908736",
    "https://openalex.org/W3115753579",
    "https://openalex.org/W3100727892",
    "https://openalex.org/W2963250244",
    "https://openalex.org/W2963034998",
    "https://openalex.org/W2927085091",
    "https://openalex.org/W3186097548",
    "https://openalex.org/W4205635927",
    "https://openalex.org/W2970480900",
    "https://openalex.org/W4297801719",
    "https://openalex.org/W2998659916",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2109802560",
    "https://openalex.org/W2897820187",
    "https://openalex.org/W2965033324",
    "https://openalex.org/W2963012544",
    "https://openalex.org/W2963096510",
    "https://openalex.org/W3034917202",
    "https://openalex.org/W3098824823",
    "https://openalex.org/W4241699713",
    "https://openalex.org/W3133702157",
    "https://openalex.org/W2995335514",
    "https://openalex.org/W3100452485",
    "https://openalex.org/W3034319502",
    "https://openalex.org/W3157144868",
    "https://openalex.org/W2964321064",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2963631950",
    "https://openalex.org/W3030163527"
  ],
  "abstract": "Emily Reif, Daphne Ippolito, Ann Yuan, Andy Coenen, Chris Callison-Burch, Jason Wei. Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). 2022.",
  "full_text": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\nVolume 2: Short Papers, pages 837 - 848\nMay 22-27, 2022c⃝2022 Association for Computational Linguistics\nA Recipe For Arbitrary Text Style Transfer with Large Language Models\nEmily Reif1∗ Daphne Ippolito1,2* Ann Yuan1 Andy Coenen1\nChris Callison-Burch2 Jason Wei1\n1Google Research 2University of Pennsylvania\n{ereif, annyuan, andycoenen, jasonwei}@google.com\n{daphnei, ccb}@seas.upenn.edu\nAbstract\nIn this paper, we leverage large language mod-\nels (LMs) to perform zero-shot text style trans-\nfer. We present a prompting method that\nwe call augmented zero-shot learning , which\nframes style transfer as a sentence rewriting\ntask and requires only a natural language in-\nstruction, without model ﬁne-tuning or exem-\nplars in the target style. Augmented zero-shot\nlearning is simple and demonstrates promising\nresults not just on standard style transfer tasks\nsuch as sentiment, but also on natural language\ntransformations such as “make this melodra-\nmatic” or “insert a metaphor.”\n1 Introduction\nText style transfer is the task of rewriting text to\nincorporate additional or alternative stylistic ele-\nments while preserving the overall semantics and\nstructure. Although style transfer has garnered in-\ncreased interest due to the success of deep learn-\ning, these approaches usually require a substantial\namount of labeled training examples, either as par-\nallel text data (Zhu et al., 2010; Rao and Tetreault,\n2018) or non-parallel text data of a single style. (Li\net al., 2018; Jin et al., 2019; Liu et al., 2020; Kr-\nishna et al., 2020). Even bleeding-edge approaches\nthat tackle the challenging problem of label-free\nstyle transfer are limited in that they require at least\nseveral exemplar sentences that dictate a given tar-\nget style (Xu et al., 2020; Riley et al., 2021). Hence,\nrecent survey papers have identiﬁed a need for new\nmethods that both reduce the training data require-\nments and expand the scope of styles supported\n(Jin et al., 2020; Hu et al., 2020).\nIn this work, we present augmented zero-shot\nlearning, a prompting method that allows large\nlanguage models to perform text style transfer to\narbitrary styles, without any exemplars in the target\nstyle. Our method builds on prior work showing\n∗Equal contribution\nHere is some text: {That is an ugly dress}. Here is \na rewrite of the text, which is more positive: {\nHere is some text: {I was really sad about the \nloss}. Here is a rewrite of the text, which is more \npositive: {I was able to accept and work through \nthe loss to move on.} \nHere is some text: {The eggnog was tasteless}. Here \nis a rewrite of the text, which is more positive: \n{The eggnog had a great, festive taste to it.} \n… \nHere is some text: {That is an ugly dress}. Here is \na rewrite of the text, which is more positive: {\nHere is some text: {When the doctor asked Linda to \ntake the medicine, he smiled and gave her a \nlollipop}. Here is a rewrite of the text, which is \nmore scary: {When the doctor told Linda to take the \nmedicine, there had been a malicious gleam in her \neye that Linda didn't like at all} \nHere is some text: {They asked loudly, over the \nsound of the train}. Here is a rewrite of the text, \nwhich is more intense: {They yelled aggressively, \nover the clanging of the train} \n… \nHere is some text: {That is an ugly dress}. Here is \na rewrite of the text, which is more positive: {\nZero-shot learning prompt\nFew-shot learning prompt\nAugmented zero-shot learning prompt (ours)\nmore melodramatic  includes a metaphor  include the word “balloon”   \n(a)\n(b)\n(c)\nFigure 1: Zero-shot, few-shot, and augmented zero-\nshot prompts for style transfer. The boldface text is\nthe zero-shot prompt, and the plain text is the addi-\ntional priming sequence. The full prompts used in\nthis paper are shown in Table 7. We encourage read-\ners to examine the outputs of our model at https:\n//bit.ly/3fLDuci.\nthat sufﬁciently large LMs such as GPT-3 can per-\nform various tasks ranging from classiﬁcation to\ntranslation, simply by choosing a clever prompt to\nprepend to the input text for which the model is\nasked to continue (Brown et al., 2020; Branwen,\n2020). Using a single prompt that provides sev-\neral demonstrations of sentences being “rewritten”\nto meet a desired condition, language models can\nextrapolate and rewrite text in unseen styles. We\nare thus able to perform style transfer to arbitrary\nstyles such as “make this sentence more comic” or\n“include the word balloon.”\nAugmented zero-shot learning is simple and fa-\ncilitates the application of style transfer to a wider\n837\nrange of styles than existing work. Our contribu-\ntions are the following.\n1. We propose a recipe for style transfer using large\nLMs that is label-free, training-free, and intu-\nitively controllable.\n2. Via human evaluation, we ﬁnd that our method\nachieves strong performance on both standard\nand non-standard style transfer tasks. We also\ncompare our approach for sentiment transfer\nwith prior methods using automatic evaluation.\n3. We explore real-world desired style transfers\ngenerated from users of a text editing UI that\nimplements our method.\n2 Augmented zero-shot prompting\nAlthough large LMs are trained only for continua-\ntion, recent work has shown that they can perform\na variety of NLP tasks by expressing the task as\na prompt that encourages the model to output the\ndesired answer as the continuation (Puri and Catan-\nzaro, 2019; Weller et al., 2020; Brown et al., 2020;\nSchick and Schütze, 2021, inter alia; see Liu et al.\n(2021a) for a survey). The simplest approach, zero-\nshot prompting, directly uses natural language to\nask the large LM to perform a task, as shown in\nFigure 1a. Zero-shot prompting, however, can be\nprone to failure modes such as not returning well-\nformatted or logical outputs (see §6). Few-shot\nprompting, as shown in Figure 1b, has been shown\nto achieve higher performance, but requires exem-\nplars for the exact task that we want the model to\nperform. Such few-shot examples can be easily ob-\ntained if the desired style transformation is known\nahead of time, but this ultimately limits style trans-\nfer to a set of pre-speciﬁed style tasks.\nTo remove the need for these labeled exemplars\nfor each style transfer task, we propose augmented\nzero-shot learning, a method for performing multi-\ntask style transfer using a single set of exemplars.\nInstead of prompting the model with exemplars\nspeciﬁc to the exact style transfer task we wish\nto perform, we prompt the model with examples\nof a variety of sentence rewriting operations, as\nshown in Figure 1c. This intuition is inspired by\nReynolds and McDonell (2021)’s observation that\nsuccessful prompts constrain the behavior of the\nlarge LM away from failure modes—in our case,\nwe aim to preserve the ﬂexibility of a zero shot\nprompt while encouraging the model to produce\noutputs of a speciﬁc template. We keep the the\nformat of the exemplars constant and insert the de-\nOriginal There, in the middle of the street,\nstood an old man in a weatherbeaten\nbrown coat.\nMore\ndescriptive\nThe man’s brown trenchcoat was\ncoated with snow, and as he leaned\nagainst the telephone booth, he cast\na long shadow across the road in the\nlate afternoon sun.\nInclude a\nmetaphor\nThere, in the middle of the street,\nstood an old man whose face\nresembled the weatherworn bark of\na gnarled tree.\nInclude the\nword “park”\nThere, in the middle of Central Park,\nstood an old man in a weatherbeaten\nbrown coat.\nInclude the\nword “balloon”\nThere, in the middle of the street,\nstood an old man with several\ncolourful balloons tied to the\nstraps of his coat.\nMore comic There, in the middle of the street,\nstood an old man in a raggedy brown\ncoat that was much too big for him.\nMore melodra-\nmatic\nThere, in the middle of the road,\nstood a grizzled old man, the light\nof life faded from his sunken eyes.\nTable 1: Example style transfer outputs from aug-\nmented zero-shot learning for non-standard styles.\nsired sentence transformation into the same format.\nIn this way, the augmented zero-shot formulation\nsupports arbitrary sentence rewriting tasks without\nthe need to write any task-speciﬁc exemplars. Thus,\nit works for a wide range of styles, including modi-\nfying the text to be “more melodramatic,” “insert\na metaphor,” or “include the word balloon.”\n3 Experimental Setup\nStyle transfer tasks. We consider six style trans-\nfer tasks that we deem non-standard, listed in Table\n1. These styles were chosen to be representative of\nmost frequent style adjustments made by users of\nan AI-assisted text editor that employs our method\n(discussed further in §5). As source sentences, we\nuse 50 sentences randomly drawn from the Reddit\nWriting Prompts validation set (Fan et al., 2018),\nexcluding those that already clearly exhibited one\nof the styles or were ungrammatical/incoherent.\nWe use human evaluation for these styles, since not\nall styles have readily available classiﬁers.\nWe also evaluate our method on two standard\nstyle transfer tasks: sentiment and formality. We\nuse the Yelp polarity dataset (Zhang et al., 2015)\nfor sentiment and Grammarly’s Yahoo Answers\nFormality Corpus (GYAFC) dataset for formality\n(Rao and Tetreault, 2018).1 These datasets allow\nus to evaluate performance of augmented zero-shot\nlearning in the context of prior supervised methods\nwhich have been used on these tasks.\n1Hosted by Luo et al. (2019).\n838\nModel. Augmented zero-shot learning requires a\nlarge language model. We primarily use LaMDA,\na left-to-right decoder-only transformer language\nmodel (Vaswani et al., 2017) with a non-embedding\nparameter count of 137B (Thoppilan et al., 2022).\nThe pre-trained LaMDA model, which we refer to\nas LLM, was trained on a corpus comprising 1.95B\npublic web documents, including forum and dialog\ndata and Wikipedia. The dataset was tokenized into\n2.49T BPE tokens with a SentencePiece vocabulary\nsize of 32K (Kudo and Richardson, 2018). We also\nuse LLM-Dialog, the ﬁnal LaMDA model which\nwas ﬁnetuned on a curated, high-quality subset of\ndata identiﬁed to be in a conversational format.\nDecoding was done with top-k=40. To show that\nthe success of augmented zero-shot learning is not\nrestricted to these two large LMs, we also perform\nexperiments with GPT-3 (Table 8). For GPT-3,\ndecoding was done with nucleus sampling using\np=0.6 (Holtzman et al., 2019).\nThe prompts used forLLM and GPT-3 are shown\nin Figure 1. For LLM-Dialog, the prompt was in-\nstead formulated as a conversation between one\nagent who is requesting rewrites and another who\nis performing the rewrites. See Table 7 in the Ap-\npendix for the full non-abbreviated prompts.\n4 Results\n4.1 Non-Standard Styles\nFor our six non-standard styles, we asked six pro-\nfessional raters to assess <input sentence, target\nstyle, output sentence> tuples. These raters are\nﬂuent in English, live in India, and work full time\nlabeling and evaluating data. To decrease inter-rater\ndiscrepancy and ensure that our instructions were\nclear, we had an initial calibration session where\nthey test-rated a small portion of the data (around\n10 datapoints which were then omitted from the\nresults) and asked us any clarifying questions. For\neach style, we compare outputs from our method\nplus the three baselines for 50 sentences.\nEach tuple was scored by three raters (3,600 rat-\nings total) on the following three axes which are\nstandard to textual style transfer (Mir et al., 2019):\n(1) transfer strength (the amount that the output\nactually matches the target style), (2) semantic\npreservation (whether the underlying meaning of\nthe output text, aside from style, matches that of the\ninput), and (3) ﬂuency (whether the text is coherent\nand could have been written by a proﬁcient English\nspeaker). Following Sakaguchi and Van Durme\nAll Styles\n(Mean)\nmore\ncomic\nmore\nmelodramatic\ninclude the\nword\n\"park\"\ninclude \nthe word\n\"balloon\"\ninclude a\nmetaphor\nmore\ndescriptive\n0\n25\n50\n75\n100\nStyle Strength\nAll Styles\n(Mean)\nmore\ncomic\nmore\nmelodramatic\ninclude the\nword\n\"park\"\ninclude \nthe word\n\"balloon\"\ninclude a\nmetaphor\nmore\ndescriptive\n0\n25\n50\n75\n100\nSemantic Similarity\nParaphrase\nZero\nAug. Zero\nHuman\nFigure 2: Human evaluation of style transfer for six\natypical styles. Our method is rated comparably to the\nhuman-written ground truth. Error bars show Standard\nError of the Mean. Evaluation of ﬂuency is shown in\nFigure 4 in the Appendix.\n(2018), transfer strength and semantic preservation\nwere rated on a scale from 1–100. A screenshot\nof the evaluation UI is shown in Figure 5 in the\nAppendix. Note that the guidelines for semantic\npreservation are not standardized in prior literature\n(Briakou et al., 2021); while some evaluations are\nstrict that the outputs cannot contain any more infor-\nmation than the inputs, we asked the annotators not\nto penalize for meaning transformations which are\nnecessary for the speciﬁed transformation. We use\ndialog-LLM, and compare it with three other meth-\nods: (1) zero-shot (a baseline), (2) paraphrase\n(our normal augmented zero shot prompt, but with\nthe target style of “paraphrased”, as a control) and\n(3) human (ground-truth transformations written\nby the authors).\nFigure 2 shows these results. We found that the\noutputs of our method were rated almost as highly\nas the human-written ground truth for all three\nevaluations. The zero-shot baseline performed the\nworst in all categories: 25.4% of the time, it did not\nreturn a valid response at all (see §6), compared\nwith 0.6% for augmented zero shot. The strong\nperformance of the paraphrase baseline at ﬂuency\nand semantic similarity shows that large LMs are\ncapable of generating high quality text that remains\ntrue to the input sentence’s meaning. Overall, the\naverage length of the input sentences was 66 char-\nacters, whereas the average length of augmented\nzero-shot outputs was 107 characters. For context,\nhuman paraphrase outputs were 82 characters.\nFor a subset of the tasks, some automatic evalua-\ntion was also possible. We found that the “balloon”\nand “park” transformations successfully inserted\n839\nthe target word 85% of the time. For “more descrip-\ntive” and “include a metaphor ” the transformed\ntext was, as expected, longer than the original (by\n252% and 146% respectively, compared with 165%\nand 146% for human baselines).\n4.2 Standard Styles\nTo better contextualize the performance of our\nmethod with prior methods, we also generated out-\nputs for two standard style transfer tasks: sentiment\nand formality. Figure 3 shows human evaluations\n(same setup as before) for our outputs as well as\nthe outputs from two popular prior style transfer\nmethods, Unsup MT (Prabhumoye et al., 2018) and\nDual RL (Luo et al., 2019). The outputs from our\nmethod were rated comparably to both human gen-\nerated responses and the two prior methods, using\nthe same rating setup as the non-standard styles,\nwith six outputs and baselines for four styles across\n50 sentences, rated independently by three raters,\ntotalling 3,000 total ratings.\nFurthermore, following Li et al. (2018) and Sud-\nhakar et al. (2019), we perform automatic evalu-\nation for sentiment style transfer since there are\nclassiﬁers available for these styles. We note that\nalthough automatic evaluations can diverge from\nhuman ratings, they can still be a good proxy as\nwe could not perform human evaluation against\nevery prior method due to time and resource con-\nstraints. We automatically evaluate (1) transfer\nstrength using a sentiment classiﬁer from Hug-\ngingFace Transformers (Wolf et al., 2020),(2) se-\nmantic similarity to human examples provided by\nLuo et al. (2019) via BLEU score, and (3) ﬂuency\nvia perplexity, as measured by GPT-2 (117M).\nTable 2 shows these automatic evaluations, with\nfour main takeaways. First, augmented zero-shot\nprompting achieves high accuracy and low perplex-\nity compared with baselines. The BLEU scores,\nhowever, are low, which we believe is because it\ntends to add additional information to generated\nsentences (see Appendix B for a deeper analysis).\nSecond, we apply augmented zero-shot learning to\nGPT-3 175B; these results indicate that augmented\nzero-shot learning generalizes to another large lan-\nguage model. Third, we vary model size for GPT-3\nmodels, ﬁnding that larger size greatly improves\nstyle transfer. Fourth, for LLM and LLM-dialog,\nwe ﬁnd that augmented zero-shot learning substan-\ntially outperforms vanilla zero-shot learning and\nalmost reaches the accuracy of ﬁve-shot learning.\nAll Styles\n(Mean)\nmore\nformal\nmore\ninformal\nmore\npositive\nmore\nnegative\n0\n25\n50\n75\n100\nStyle Strength\nAll Styles\n(Mean)\nmore\nformal\nmore\ninformal\nmore\npositive\nmore\nnegative\n0\n25\n50\n75\n100\nSemantic Similarity\nParaphrase\nZero\nUnsup. MT\nDual RL\nAug. Zero\nHuman\nFigure 3: Human evaluation of sentiment and formality\ntransfer. Our method is rated comparably to human-\nwritten ground truth as well as prior methods. Error\nbars show Standard Error of the Mean. Unsup. MT is\nPrabhumoye et al. (2018); Dual RL is Luo et al. (2019).\n5 Potential of Arbitrary Styles\nOne promising application of augmented zero-shot\nlearning is an AI-powered writing assistant that\ncan allow writers to transform their text in arbitrary\nways that the writer deﬁnes and controls. As a qual-\nitative case study to explore what arbitrary re-write\nstyles may be requested, we built an AI-assisted\nstory-writing editor with a “rewrite as” feature that\nuses our augmented few-shot method. Our edi-\ntor has a freeform text box for users to specify\nhow they would like a selection of their story to be\nrewritten (see Figure 6 in the Appendix). We asked\n30 people from a creative writing group to use our\nUI to write a 100-300 word story, collecting 333\nrewrite requests in total. Table 3 shows a subset of\nthese, which were as diverse as asking for the text\n“to be about mining” or “to be less diabolical.”\n6 Limitations and Failure Modes\nThis section details several qualitative limitations\nwith our method.\nUnparsable answers A frequent problem that\narises when using large LMs for other NLP tasks\nis their outputs cannot be automatically parsed into\nusable answers. For example, when given a prompt\nlike “Here is some text: that is an ugly\ndress. Here is a rewrite of the text,\nwhich is more positive” LLM-Dialog might\nreturn something like “Sounds like you are a\ngreat writer!” Similar error modes exist for\nLLM, which might output something like “Here\nare more writing tips and tricks.” Other\n840\nAcc BLEU PPL\nSUPERVISED METHODS\nCross-alignment (Shen et al., 2017) 73.4 17.6 812\nBacktrans (Prabhumoye et al., 2018) 90.5 5.1 424\nMultidecoder (Fu et al., 2018) 50.3 27.7 1,703\nDelete-only (Li et al., 2018) 81.4 28.6 606\nDelete-retrieve (Li et al., 2018) 86.2 31.1 948\nUnpaired RL (Xu et al., 2018) 52.2 37.2 2,750\nDual RL (Luo et al., 2019) 85.9 55.1 982\nStyle transformer (Dai et al., 2019) 82.1 55.2 935\nINFERENCE -ONLY METHODS\nGPT-3 ada, aug zero-shot 31.5 39.0 283\nGPT-3 curie, aug zero-shot 53.0 48.3 207\nGPT-3 da vinci, aug zero-shot 74.1 43.8 231\nLLM: zero-shot 69.7 28.6 397\nLLM: ﬁve-shot 83.2 19.8 240\nLLM: aug zero-shot 79.6 16.1 173\nLLM-dialog: zero-shot 59.1 17.6 138\nLLM-dialog: ﬁve-shot 94.3 13.6 126\nLLM-dialog: aug zero-shot 90.6 10.4 79\nTable 2: Comparing augmented zero-shot prompting\nwith supervised style transfer methods on the Yelp sen-\ntiment style transfer dataset using automatic evaluation.\nAcc: accuracy; PPL: perplexity. The inference-only ta-\nble shows our method applied to 3 different sizes of\nGPT-3, plus our own LLM.\nto be a little less angsty • to be about mining • to be better\nwritten • to be less diabolical • to be more absurd • to be more\nadventurous • to be more Dickensian • to be more emotional\n• to be more magical • to be more melodramatic • to be\nmore philosophical • to be more revolutionary • to be more\nsurprising • to be more suspenseful • to be more technical • to\nbe more whimsical• to be warmer• to ﬁt better grammatically\nwith the rest of the story • to make more sense\nTable 3: Requests in the form of “Rewrite this...” made\nby real users to a large LM-powered text editor. For the\nfull set of unique requests, see Table 5 in the Appendix.\ntimes, the response contains correct information,\nbut it cannot be automatically parsed (e.g., “a\ngood rewrite might be to say that the\ndress is pretty.” ) In hindsight, these outputs\nmake a lot of sense: most of the training data of\nlarge LMs is not well-formatted pairs of inputs and\noutputs (Reynolds and McDonell, 2021). See §A\nfor how we dealt with these issues.\nHallucinations Large LMs are known to halluci-\nnate text content; we saw this happen frequently for\nstyle transfer. While this is an advantage in some\ncontexts like creative writing, it is undesirable for\napplications like summarization.\nInherent style trends We also noticed that even\nour “paraphrase” baseline, where the model was\nsimply asked to rewrite the input sentence, was\nrated highly for style strength for a few styles, in-\ncluding “more formal” and “more melodramatic”.\nThis implies that our method’s generations gen-\nerally trend toward these styles. A direction for\nfuture work would be to see what styles and quali-\nties of text our method (and large LMs in general)\nare inherently more likely to produce.\nLess reliable than trained methods For style\ntransfer tasks that have available training data, prior\nmethods that either train or ﬁnetune on that data are\ngoing to be inherently more reliable at producing\ntext that looks like their training data. This can be\nobserved in the lower BLEU scores our method\nachieves than trained methods, despite comparable\ntransfer accuracy (Section B). Thus, augmented\nzero-shot learning offers less ﬁne-grained control-\nlability in the properties of the style-transferred text\nthan methods which see task-speciﬁc training data.\nLarge LM safety concerns Large LMs them-\nselves come with their own host of difﬁculties,\nbarriers to entry, and potential safety concerns as\ndiscussed by Bender et al. (2021), which are also\nvalid for this style transfer method. However, we\nalso think that this method can be a useful tool in\nexploring and exposing the safety and boundaries\nof these models themselves: what happens if we try\nto force the large LM to make a text “more racist”,\n“more sexist”, or “more incendiary”? It is important\nto keep pushing these models to their boundaries to\nsee where they fail and where problems arise, and\nspeciﬁc use cases that show a broader range of the\nmodel’s capabilities also show a broader range of\nits failure modes.\n7 Conclusions\nWe introduced augmented zero-shot learning,\nwhich we ﬁnd shows shows strikingly promis-\ning performance considering its simplicity. This\nprompting paradigm moves the needle in text style\ntransfer by expanding the range of possible styles\nbeyond the currently limited set of styles for which\nannotated data exists. More broadly, we also hope\nthat the strategy of prompting a large LM with non-\ntask speciﬁc examples can inspire new inference-\nonly methods for other NLP tasks.\nReferences\nEmily M. Bender, Timnit Gebru, Angelina McMillan-\nMajor, and Shmargaret Shmitchell. 2021. On the\ndangers of stochastic parrots: Can language models\n841\nbe too big? In Proceedings of the 2021 ACM Confer-\nence on Fairness, Accountability, and Transparency,\nFAccT ’21, page 610–623, New York, NY , USA. As-\nsociation for Computing Machinery.\nGwern Branwen. 2020. GPT-3 creative ﬁction.\nEleftheria Briakou, Sweta Agrawal, Ke Zhang, Joel R.\nTetreault, and Marine Carpuat. 2021. A review\nof human evaluation for style transfer. CoRR,\nabs/2106.04747.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen,\nEric Sigler, Mateusz Litwin, Scott Gray, Benjamin\nChess, Jack Clark, Christopher Berner, Sam Mc-\nCandlish, Alec Radford, Ilya Sutskever, and Dario\nAmodei. 2020. Language models are few-shot learn-\ners. CoRR, abs/2005.14165.\nNing Dai, Jianze Liang, Xipeng Qiu, and Xuanjing\nHuang. 2019. Style transformer: Unpaired text\nstyle transfer without disentangled latent represen-\ntation. In Proceedings of the 57th Annual Meet-\ning of the Association for Computational Linguis-\ntics, pages 5997–6007, Florence, Italy. Association\nfor Computational Linguistics.\nAngela Fan, Mike Lewis, and Yann Dauphin. 2018. Hi-\nerarchical neural story generation. In Proceedings\nof the 56th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 889–898, Melbourne, Australia. Association\nfor Computational Linguistics.\nZhenxin Fu, Xiaoye Tan, Nanyun Peng, Dongyan Zhao,\nand Rui Yan. 2018. Style transfer in text: Explo-\nration and evaluation. In Proceedings of the AAAI\nConference on Artiﬁcial Intelligence.\nAri Holtzman, Jan Buys, Li Du, Maxwell Forbes, and\nYejin Choi. 2019. The curious case of neural text de-\ngeneration. In International Conference on Learn-\ning Representations.\nZhiqiang Hu, Roy Ka-Wei Lee, and Charu C. Aggar-\nwal. 2020. Text style transfer: A review and experi-\nment evaluation. CoRR, abs/2010.12742.\nDi Jin, Zhijing Jin, Zhiting Hu, Olga Vechtomova, and\nRada Mihalcea. 2020. Deep learning for text style\ntransfer: A survey. CoRR, abs/2011.00416.\nZhijing Jin, Di Jin, Jonas Mueller, Nicholas Matthews,\nand Enrico Santus. 2019. IMaT: Unsupervised text\nattribute transfer via iterative matching and transla-\ntion. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP), pages\n3097–3109, Hong Kong, China. Association for\nComputational Linguistics.\nKalpesh Krishna, John Wieting, and Mohit Iyyer. 2020.\nReformulating unsupervised style transfer as para-\nphrase generation. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language\nProcessing (EMNLP), pages 737–762, Online. Asso-\nciation for Computational Linguistics.\nTaku Kudo and John Richardson. 2018. Sentencepiece:\nA simple and language independent subword tok-\nenizer and detokenizer for neural text processing.\nCoRR, abs/1808.06226.\nJuncen Li, Robin Jia, He He, and Percy Liang. 2018.\nDelete, retrieve, generate: a simple approach to sen-\ntiment and style transfer. In Proceedings of the 2018\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, Volume 1 (Long Papers) ,\npages 1865–1874, New Orleans, Louisiana. Associ-\nation for Computational Linguistics.\nDayiheng Liu, Jie Fu, Yidan Zhang, Chris Pal, and\nJiancheng Lv. 2020. Revision in continuous space:\nUnsupervised text style transfer without adversarial\nlearning. In Proceedings of the AAAI Conference on\nArtiﬁcial Intelligence, volume 34, pages 8376–8383.\nPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang,\nHiroaki Hayashi, and Graham Neubig. 2021a. Pre-\ntrain, prompt, and predict: A systematic survey of\nprompting methods in natural language processing.\narXiv preprint arXiv:2107.13586.\nRuibo Liu, Chenyan Jia, and Soroush V osoughi. 2021b.\nA transformer-based framework for neutralizing and\nreversing the political polarity of news articles.Proc.\nACM Hum.-Comput. Interact., 5(CSCW1).\nFuli Luo, Peng Li, Jie Zhou, Pengcheng Yang, Baobao\nChang, Xu Sun, and Zhifang Sui. 2019. A dual rein-\nforcement learning framework for unsupervised text\nstyle transfer. In Proceedings of the Twenty-Eighth\nInternational Joint Conference on Artiﬁcial Intelli-\ngence, IJCAI 2019, Macao, China, August 10-16,\n2019, pages 5116–5122. ijcai.org.\nAman Madaan, Amrith Setlur, Tanmay Parekh, Barn-\nabas Poczos, Graham Neubig, Yiming Yang, Ruslan\nSalakhutdinov, Alan W Black, and Shrimai Prabhu-\nmoye. 2020. Politeness transfer: A tag and generate\napproach. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 1869–1881, Online. Association for Computa-\ntional Linguistics.\nRemi Mir, Bjarke Felbo, Nick Obradovich, and Iyad\nRahwan. 2019. Evaluating style transfer for text.\nCoRR, abs/1904.02295.\nShrimai Prabhumoye, Yulia Tsvetkov, Ruslan Salakhut-\ndinov, and Alan W Black. 2018. Style transfer\nthrough back-translation. In Proceedings of the\n56th Annual Meeting of the Association for Com-\nputational Linguistics (Volume 1: Long Papers) ,\npages 866–876, Melbourne, Australia. Association\nfor Computational Linguistics.\n842\nRaul Puri and Bryan Catanzaro. 2019. Zero-shot\ntext classiﬁcation with generative language models.\narXiv preprint arXiv:1912.10165.\nSudha Rao and Joel Tetreault. 2018. Dear sir or\nmadam, may I introduce the GY AFC dataset: Cor-\npus, benchmarks and metrics for formality style\ntransfer. In Proceedings of the 2018 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long Papers) , pages 129–140,\nNew Orleans, Louisiana. Association for Computa-\ntional Linguistics.\nLaria Reynolds and Kyle McDonell. 2021. Prompt pro-\ngramming for large language models: Beyond the\nfew-shot paradigm.\nParker Riley, Noah Constant, Mandy Guo, Girish Ku-\nmar, David C. Uthus, and Zarana Parekh. 2021.\nTextsettr: Label-free text style extraction and tun-\nable targeted restyling. Proceedings of the Annual\nMeeting of the Association of Computational Lin-\nguistics (ACL).\nKeisuke Sakaguchi and Benjamin Van Durme. 2018.\nEfﬁcient online scalar annotation with bounded sup-\nport. In Proceedings of the 56th Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers) , pages 208–218, Melbourne,\nAustralia. Association for Computational Linguis-\ntics.\nTimo Schick and Hinrich Schütze. 2021. It’s not just\nsize that matters: Small language models are also\nfew-shot learners. In Proceedings of the 2021 Con-\nference of the North American Chapter of the Asso-\nciation for Computational Linguistics: Human Lan-\nguage Technologies, pages 2339–2352, Online. As-\nsociation for Computational Linguistics.\nTianxiao Shen, Tao Lei, Regina Barzilay, and Tommi\nJaakkola. 2017. Style transfer from non-parallel text\nby cross-alignment. In Advances in Neural Informa-\ntion Processing Systems , volume 30. Curran Asso-\nciates, Inc.\nAkhilesh Sudhakar, Bhargav Upadhyay, and Arjun Ma-\nheswaran. 2019. “Transforming” delete, retrieve,\ngenerate approach for controlled text style transfer.\nIn Proceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP) , pages 3269–\n3279, Hong Kong, China. Association for Computa-\ntional Linguistics.\nRomal Thoppilan, Daniel De Freitas, Jamie Hall,\nNoam Shazeer, Apoorv Kulshreshtha, Heng-Tze\nCheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du,\net al. 2022. Lamda: Language models for dialog\napplications. arXiv preprint arXiv:2201.08239.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. CoRR, abs/1706.03762.\nOrion Weller, Nicholas Lourie, Matt Gardner, and\nMatthew E. Peters. 2020. Learning from task de-\nscriptions. In Proceedings of the 2020 Conference\non Empirical Methods in Natural Language Process-\ning (EMNLP) , pages 1361–1375, Online. Associa-\ntion for Computational Linguistics.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Rémi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander M. Rush. 2020.\nTransformers: State-of-the-art natural language pro-\ncessing. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Processing:\nSystem Demonstrations, pages 38–45, Online. Asso-\nciation for Computational Linguistics.\nJingjing Xu, Xu Sun, Qi Zeng, Xiaodong Zhang, Xu-\nancheng Ren, Houfeng Wang, and Wenjie Li. 2018.\nUnpaired sentiment-to-sentiment translation: A cy-\ncled reinforcement learning approach. In Proceed-\nings of the 56th Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Pa-\npers), pages 979–988, Melbourne, Australia. Asso-\nciation for Computational Linguistics.\nPeng Xu, Yanshuai Cao, and Jackie Chi Kit Cheung.\n2020. On variational learning of controllable repre-\nsentations for text without supervision. Proceedings\nof the International Conference on Machine Learn-\ning (ICML), abs/1905.11975.\nXiang Zhang, Junbo Zhao, and Yann LeCun. 2015.\nCharacter-level convolutional networks for text clas-\nsiﬁcation. Proceedings of the Conference on Neural\nInformation Processing Systems.\nZhemin Zhu, Delphine Bernhard, and Iryna Gurevych.\n2010. A monolingual tree-based translation model\nfor sentence simpliﬁcation. In Proceedings of the\n23rd International Conference on Computational\nLinguistics (COLING 2010), pages 1353–1361, Bei-\njing, China. Coling 2010 Organizing Committee.\n843\nAppendix\nA Prompt Selection\nA promising new area of prompt engineering has\narisen to address the failure modes discussed above,\nspeciﬁcally the invalid or unparseable answers.\nReynolds and McDonell (2021) ﬁnd that prompt-\ning a model for a task is more akin to locating an\nalready-learned task than truly learning a new one.\nMoreover, they emphasize that prompt engineer-\ning is mostly about avoiding various failure cases\nsuch as those described above. In this work, we\nuse delimiters (“{” and “}”) to help avoid these\ntypes of errors, giving scores of zero when there\nwas no valid responses with such delimiters. There\nare other delimiters that could be used (e.g., quotes,\n“(” and “)”, “<” and “>”, newlines with a colon (as\nused by GPT-3), etc. We chose curly braces as they\nwere 1) likely to occur in the training data as delim-\niters in other contexts and 2) not frequently part of\nthe input sentence itself. We also use a second per-\nson prompt template for the dialog, which yielded\nbetter results as it was more similar to the training\ndata. Exploring these options more quantitatively\nwould be an interesting direction for future work.\nBecause the performance of prompting can vary\ndepending on the exact language of the prompt\n(Reynolds and McDonell, 2021), we compare\nfour variations of prompts for sentiment: “ more\npositive/negative,” “happier/sadder,” “more opti-\nmistic/pessimistic,” and “more cheerful/miserable.”\nAs shown in Table 4 in the Appendix, performance\ndiffered across the four prompts, but we found them\ncomparable.\nModel / prompt wording Acc Bleu PPL\nLLM\n“more positive/negative” 76.3 14.8 180\n“happier/sadder” 62.6 15.5 173\n“more optimistic/pessimistic” 69.7 14.1 143\n“more cheerful/miserable” 74.5 15.7 186\nLLM-Dialog\n“more positive/negative” 90.5 10.4 79\n“happier/sadder” 85.9 9.6 90\n“more optimistic/pessimistic” 85.8 10.2 79\n“more cheerful/miserable” 88.8 11.4 93\nTable 4: Comparing variations of augmented zero-shot\nlearning prompt wording for sentiment style transfer.\nB Low BLEU for LLM Outputs\nAs we saw in Table 2, the outputs of our model\nhad low BLEU scores with respect to human gen-\ninto paragraphs • to be a bit clearer • to be a little less\nangsty • to be a word for a song • to be about mining\n• to be about vegetables • to be better written • to be\nless descriptive • to be less diabolical • to be more\nabsurd • to be more adventurous • to be more angry\n• to be more cheerful • to be more descriptive • to be\nmore Dickensian • to be more emotional • to be more\nfancy • to be more ﬂowery • to be more interesting •\nto be more joyful • to be more magical • to be more\nmelodramatic • to be more philosophical • to be more\nrevolutionary • to be more scary • to be more subtle\n• to be more surprising • to be more suspenseful • to\nbe more technical • to be more violent • to be more\nwhimsical • to be warmer • to ﬁt better grammatically\nwith the rest of the story • to make more sense • to use\na more interesting word • with a few words\nTable 5: Full results for requests in the form of\n“Rewrite this...” made by users to a large LM-powered\ntext editor.\nerated outputs, while simultaneously having high\nsemantic similarity in human evaluations. Based on\nqualitative examination of outputs, we believe that\nthis is because model outputs often, despite having\nhigh semantic similarity with the source sentence,\nused different language from human annotations.\nFor instance, for transferring the sentiment of “ever\nsince joes has changed hands it’s just gotten worse\nand worse” to positive sentiment, our augmented\nzero-shot learning model outputted “the establish-\nment has continued to provide excellent service,\nimproving steadily since its change of ownership.”\nThis will have low BLEU with the ground truth\nwith respect to human references, which is simply\n“ever since joes has changed hands it’s just gotten\nbetter and better.”\nThough we do not see this as an inherent prob-\nlem, increasing the BLEU for the purposes of com-\nparison can be done in an easy way via candidate\nselection, as our model returns sixteen possible\ncontinuations. In applications for which we prefer\nmodel outputs to have high lexical similarity to the\nsource sentence, we could select the candidate of\nthe sixteen with the highest BLEU score compared\nwith the original source sentence. We ﬁnd that\nthis candidate selection step can substantially im-\nprove the BLEU score with the ground truth target\nsentences, as we show in Table 8.\nC Further Related Work\nStyle transfer has gained increasing attention in the\nNLP landscape, for which neural models have been\ntrained to perform style transfer for styles including\nsentiment, formality, politeness, gender, and politi-\n844\nInput Model suggestion\nYou honor me,” said Bruno. As he spoke, he began\nto laugh. His laugh was merry sounding and melodic.\nHe took a deep breath. When he spoke again, his\nvoice was low and strong. “I take this great task on\nand with my brothers shall lead us on to victory!\nRewrite it to be about mining.\nYou honor me, said Bruno. As he spoke, he began to laugh.\nHis laugh was deep and gravely, as if from the bowels of\nthe earth. He took a deep breath. When he spoke again,\nhis voice was deep and dark.‘I take this great task on and\nwith my brothers shall delve into the mines!”\nI reckon,’ smiled Toe, ’you’d have to say the same\nfor icicles, wouldn’t you?\nRewrite it to be more interesting.\n‘I reckon,’ smiled Toe, ‘you’d have to say the same for\nicicles, wouldn’t you?’ These words were barely out of\nhis mouth before the others realized exactly what they\nmeant.\nwith its southern perfume\nRewrite it to be more descriptive\nA mixture of sweet honeysuckles and jasmine with a hint\nof tobacco and warm mesquite smoke. It was his southern\nperfume, with a hint of a memory of simpler times.\nBut Sally remained unmoved–and lonely.\nRewrite it to be more emotional\nHer tears rolled and rolled down her cheek, mixing with\nthe saltwater around her, until the water was a rich mixture\nof the two. She wanted her poem to be cheerful like it\nused to be, but couldn’t ﬁnd the right words.\nTable 6: Examples of users’ arbitrary style transfer requests for which the model suggestion was accepted.\ncal slant (Prabhumoye et al., 2018; Madaan et al.,\n2020; Liu et al., 2021b). We will brieﬂy summarize\nthe primary approaches to style transfer here, and\nrefer the involved reader to either (Jin et al., 2020)\nor (Hu et al., 2020) for a survey.\nMost text style transfer approaches fall in two\ncategories. Early approaches tend to require par-\nallel text data (Zhu et al., 2010; Rao and Tetreault,\n2018), where every input in the source style has a\ncorresponding output in the target style. Though\nthis formulation elegantly ﬁts the standard encoder–\ndecoder paradigm, the availability of a parallel\ntext corpus is a stringent requirement. Hence, re-\ncent text style transfer approaches have instead\nused non-parallel monostyle data (no one-to-one-\nmapping between instances in the source and target\nstyles). Such methods include latent representation\nmanipulation (Liu et al., 2020), prototype-based\ntext editing (Li et al., 2018), and pseudo-parallel\ncorpus construction (Jin et al., 2019). However,\neven non-parallel monostyle data can be hard to\ncollect for arbitrary styles. As such, surveys have\ncalled for more research on approaches that expand\nthe scope of supported styles and reduce the train-\ning data requirements for style transfer systems (Jin\net al., 2020; Hu et al., 2020).\nSeveral new methods tackle the challenging\nproblem of label-free style transfer, which does\nnot require a full corpus of labeled data, but rather\njust a few exemplars that deﬁne a style. Xu et al.\n(2020) use variational autoencoders for unsuper-\nvised learning of controllable representations for\nAll Styles\n(Mean)\nmore\ncomic\nmore\nmelodramatic\ninclude the\nword\n\"park\"\ninclude \nthe word\n\"balloon\"\ninclude a\nmetaphor\nmore\ndescriptive\n0.00\n0.25\n0.50\n0.75\n1.00\nFluency\nParaphrase\nZero\nAug. Zero\nHuman\nAll Styles\n(Mean)\nmore\nformal\nmore\ninformal\nmore\npositive\nmore\nnegative\n0.00\n0.25\n0.50\n0.75\n1.00\nFluency\nParaphrase\nZero\nUnsup. MT\nDual RL\nAug. Zero\nHuman\nFigure 4: Human evaluation of ﬂuency for style trans-\nfer for six atypical styles. Error bars show standard\nerror of the mean.\ntext. Riley et al. (2021) extract a style vector from\na set of target texts and use this vector to condition\nthe decoder to perform style transfer to a target\nstyle. These approaches have a similar goal to ours\nin terms of expanding the scope of possible style\ntransfers. However, they are different in two main\nways. First, they require a fully specialized model,\nwhere our method can be applied out-of-the-box\nwith something like GPT-3. This can either be a\nstrength or weakness, depending on the availability\nof such a model. Second, they require exemplars\nto deﬁne a style rather than a plain text description.\n845\nAugmented Zero-shot Prompt: LLM\nHere is some text: {When the doctor asked Linda to take the medicine, he smiled and gave her a lollipop.}. Here\nis a rewrite of the text, which is more scary. {When the doctor told Linda to take the medicine, there had been\na malicious gleam in her eye that Linda didn’t like at all.} Here is some text: {they asked loudly, over the\nsound of the train.}. Here is a rewrite of the text, which is more intense. {they yelled aggressively, over the\nclanging of the train.} Here is some text: {When Mohammed left the theatre, it was already dark out}. Here is\na rewrite of the text, which is more about the movie itself. {The movie was longer than Mohammed had expected,\nand despite the excellent ratings he was a bit disappointed when he left the theatre.} Here is some text: {next\nto the path}. Here is a rewrite of the text, which is about France. {next to la Siene} Here is some text: {The\nman stood outside the grocery store, ringing the bell.}. Here is a rewrite of the text, which is about clowns.\n{The man stood outside the circus, holding a bunch of balloons.} Here is some text: {the bell ringing}. Here is\na rewrite of the text, which is more flowery. {the peales of the jangling bell} Here is some text: {against the\ntree}. Here is a rewrite of the text, which is include the word \"snow\". {against the snow-covered bark of the\ntree} Here is some text: {That is an ugly dress}. Here is a rewrite of the text, which is more positive.\"\nAugmented Zero-shot Prompt: LLM-dialog\n> Here is some text: {When the doctor asked Linda to take the medicine, he smiled and gave her a lollipop.}.\nRewrite it to be more scary.\n> {When the doctor told Linda to take the medicine, there had been a malicious gleam in her eye that Linda didn’t\nlike at all.}\n> Here is some text: {they asked loudly, over the sound of the train.}. Rewrite it to be more intense.\n> {they yelled aggressively, over the clanging of the train.}\n> Here is some text: {When Mohammed left the theatre, it was already dark out}. Rewrite it to be more about the\nmovie itself.\n> {The movie was longer than Mohammed had expected, and despite the excellent ratings he was a bit disappointed\nwhen he left the theatre.}\n> Here is some text: {next to the path}. Rewrite it to be about France.\n> {next to la Siene}\n> Here is some text: {The man stood outside the grocery store, ringing the bell.}. Rewrite it to be about\nclowns.\n> {The man stood outside the circus, holding a bunch of balloons.}\n> Here is some text: {the bell ringing}. Rewrite it to be more flowery.\n> {the peals of the jangling bell}\n> Here is some text: {against the tree}. Rewrite it to be include the word \"snow\".\n> {against the snow-covered bark of the tree}\n> Here is some text: {That is an ugly dress}. Rewrite it to be more positive.\"\nTable 7: In black, we show the exact augmented-zero shot prompts used in our experiments, for LLM and GPT-\n3 (top), and for LLM-Dialog (bottom). As shown, for LLM-Dialog, we replaced “ Here is a rewrite of\nthe text, which is” with “Rewrite it to be”. Each line starting with “>\"\" above was passed in\nas an individual dialog turn. The blue shows how an input text and goal style are concatenated to the few-shot\nprompt in order to produce ﬁnal model output. Note that we can achieve high accuracy even though the prompt\nformulation resulted in some minor grammatical errors for some styles (e.g., “rewrite it to be include\nthe word ’snow’”). Text versions of these prompts can be downloaded athttps://bit.ly/3fLDuci.\nAcc BLEU PPL\nLLM-128B\nZero-shot 69.7 28.6 397\n+ cand. select. 31.4 61.5 354\nFive-shot 83.2 19.8 240\n+ cand. select. 61.5 55.6 306\nAugmented zero-shot 79.6 16.1 173\n+ cand. select. 65.0 49.3 292\nLLM-128B-dialog\nZero-shot 59.1 17.6 138\n+ cand. select. 46.8 24.2 166\nFive-shot 94.3 13.6 126\n+ cand. select. 81.3 47.6 345\nAugmented zero-shot 90.6 10.4 79\n+ cand. select. 73.7 40.6 184\nTable 8: Sentiment style transfer results with candidate\nselection (cand. select.). Candidate selection means\nthat of the sixteen examples returned by our model, we\nchoose the one with the highest BLEU with the source\nsentence.\n846\nFigure 5: The rating UI used for human evaluation. The user may be shown a number of blue squares at once with\nthe same original text and different outputs.\n847\nFigure 6: Screenshot AI-assisted editor with ‘Rewrite as’ feature.\nStyle Inputs Aug. Zero Zero Human Paraphrase\nmore comic 75 116 63 97 87\nmore melodromatic 75 124 88 116 87\ninclude the word “park” 75 124 72 94 87\ninclude the word “balloon” 75 135 86 98 87\ninclude a metaphor 75 110 74 110 87\nmore descriptive 75 190 105 124 87\nOverall 75 133 81 107 87\nTable 9: The mean length in characters of the inputs and outputs for our six atypical styles.\n848",
  "topic": "Recipe",
  "concepts": [
    {
      "name": "Recipe",
      "score": 0.8398231267929077
    },
    {
      "name": "Style (visual arts)",
      "score": 0.7306931018829346
    },
    {
      "name": "Computer science",
      "score": 0.5337487459182739
    },
    {
      "name": "Linguistics",
      "score": 0.4800899624824524
    },
    {
      "name": "Natural language processing",
      "score": 0.4671729505062103
    },
    {
      "name": "Association (psychology)",
      "score": 0.4134070873260498
    },
    {
      "name": "Artificial intelligence",
      "score": 0.36951103806495667
    },
    {
      "name": "Programming language",
      "score": 0.3243919610977173
    },
    {
      "name": "Art",
      "score": 0.2632659673690796
    },
    {
      "name": "Philosophy",
      "score": 0.2583077549934387
    },
    {
      "name": "History",
      "score": 0.18433204293251038
    },
    {
      "name": "Literature",
      "score": 0.11563006043434143
    },
    {
      "name": "Archaeology",
      "score": 0.06806695461273193
    },
    {
      "name": "Epistemology",
      "score": 0.05559864640235901
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1291425158",
      "name": "Google (United States)",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I79576946",
      "name": "University of Pennsylvania",
      "country": "US"
    }
  ]
}