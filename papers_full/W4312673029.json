{
  "title": "Sentiment Analysis Using Pre-Trained Language Model With No Fine-Tuning and Less Resource",
  "url": "https://openalex.org/W4312673029",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4315204771",
      "name": "Yuheng Kit",
      "affiliations": [
        "University of Technology Malaysia"
      ]
    },
    {
      "id": "https://openalex.org/A1966354269",
      "name": "Musa Mohd Mokji",
      "affiliations": [
        "University of Technology Malaysia"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3035431747",
    "https://openalex.org/W2963026768",
    "https://openalex.org/W2962739339",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W6755207826",
    "https://openalex.org/W6763701032",
    "https://openalex.org/W6767997687",
    "https://openalex.org/W6769627184",
    "https://openalex.org/W2997049449",
    "https://openalex.org/W6769318315",
    "https://openalex.org/W3095850336",
    "https://openalex.org/W3088886232",
    "https://openalex.org/W3184161195",
    "https://openalex.org/W3023470214",
    "https://openalex.org/W3108501093",
    "https://openalex.org/W3154224177",
    "https://openalex.org/W3007007518",
    "https://openalex.org/W3108020107",
    "https://openalex.org/W2971544482",
    "https://openalex.org/W6801215954",
    "https://openalex.org/W3120655260",
    "https://openalex.org/W3160512619",
    "https://openalex.org/W3119467012",
    "https://openalex.org/W2970854433",
    "https://openalex.org/W3102425047",
    "https://openalex.org/W2915128308",
    "https://openalex.org/W6771606970",
    "https://openalex.org/W6727690538",
    "https://openalex.org/W2506743715",
    "https://openalex.org/W3127432888",
    "https://openalex.org/W6691459498",
    "https://openalex.org/W2973727699",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W2525778437",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4286984556",
    "https://openalex.org/W3105886168",
    "https://openalex.org/W2896457183"
  ],
  "abstract": "Sentiment analysis has become popular when Natural Language Processing algorithms were proven to be able to process complex sentences with good accuracy. Recently, pre-trained language models such as BERT and mBERT, have been shown to be effective for improving language tasks. Most of the work in implementing the models focuses on fine-tuning BERT to achieve desirable results. However, this approach is resource-intensive and requires a long training time, up to a few hours on a GPU, depending on the dataset. Hence, this paper proposes a less complex system with less training time using the BERT model without the fine-tuning process and adopting a feature reduction algorithm to reduce sentence embeddings. The experimental results show that with 50&#x0025; fewer sentence embeddings, the proposed system improves the accuracy by 1-2&#x0025; with 71&#x0025; less training time and 89&#x0025; less memory usage. The proposed approach has also been proven to work for multilingual tasks by using a single mBERT model.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.9039332866668701
    },
    {
      "name": "Sentence",
      "score": 0.7499443292617798
    },
    {
      "name": "Language model",
      "score": 0.6039270162582397
    },
    {
      "name": "Sentiment analysis",
      "score": 0.6015702486038208
    },
    {
      "name": "Process (computing)",
      "score": 0.5808232426643372
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5742017030715942
    },
    {
      "name": "Feature (linguistics)",
      "score": 0.512213408946991
    },
    {
      "name": "Machine learning",
      "score": 0.4933566153049469
    },
    {
      "name": "Natural language processing",
      "score": 0.481187641620636
    },
    {
      "name": "Fine-tuning",
      "score": 0.4542730748653412
    },
    {
      "name": "Programming language",
      "score": 0.07286614179611206
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Linguistics",
      "score": 0.0
    }
  ]
}