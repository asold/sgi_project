{
  "title": "DeepTextMark: A Deep Learning-Driven Text Watermarking Approach for Identifying Large Language Model Generated Text",
  "url": "https://openalex.org/W4392745757",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5055006423",
      "name": "Travis Munyer",
      "affiliations": [
        "University of Nebraska at Omaha"
      ]
    },
    {
      "id": "https://openalex.org/A5011092437",
      "name": "Abdullah All Tanvir",
      "affiliations": [
        "University of Nebraska at Omaha"
      ]
    },
    {
      "id": "https://openalex.org/A3204271835",
      "name": "Arjon Das",
      "affiliations": [
        "University of Nebraska at Omaha"
      ]
    },
    {
      "id": "https://openalex.org/A2101733746",
      "name": "Xin Zhong",
      "affiliations": [
        "University of Nebraska at Omaha"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4381952928",
    "https://openalex.org/W4390590975",
    "https://openalex.org/W4380201950",
    "https://openalex.org/W4220726338",
    "https://openalex.org/W4304092681",
    "https://openalex.org/W6848955896",
    "https://openalex.org/W6749879876",
    "https://openalex.org/W4294170691",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W6848670183",
    "https://openalex.org/W6851663954",
    "https://openalex.org/W2790136966",
    "https://openalex.org/W2960225463",
    "https://openalex.org/W2240884068",
    "https://openalex.org/W6631190155",
    "https://openalex.org/W2081580037",
    "https://openalex.org/W4214851787",
    "https://openalex.org/W4353007481",
    "https://openalex.org/W1521626219",
    "https://openalex.org/W2794557536"
  ],
  "abstract": "The rapid advancement of Large Language Models (LLMs) has significantly enhanced the capabilities of text generators. With the potential for misuse escalating, the importance of discerning whether texts are human-authored or generated by LLMs has become paramount. Several preceding studies have ventured to address this challenge by employing binary classifiers to differentiate between human-written and LLM-generated text. Nevertheless, the reliability of these classifiers has been subject to question. Given that consequential decisions may hinge on the outcome of such classification, it is imperative that text source detection is of high caliber. In light of this, the present paper introduces DeepTextMark, a deep learning-driven text watermarking methodology devised for text source identification. By leveraging Word2Vec and Sentence Encoding for watermark insertion, alongside a transformer-based classifier for watermark detection, DeepTextMark epitomizes a blend of blindness, robustness, imperceptibility, and reliability. As elaborated within the paper, these attributes are crucial for universal text source detection, with a particular emphasis in this paper on text produced by LLMs. DeepTextMark offers a viable &#x201C;add-on&#x201D; solution to prevailing text generation frameworks, requiring no direct access or alterations to the underlying text generation mechanism. Experimental evaluations underscore the high imperceptibility, elevated detection accuracy, augmented robustness, reliability, and swift execution of DeepTextMark.",
  "full_text": "Received 22 February 2024, accepted 7 March 2024, date of publication 13 March 2024, date of current version 21 March 2024.\nDigital Object Identifier 10.1 109/ACCESS.2024.3376693\nDeepTextMark: A Deep Learning-Driven Text\nWatermarking Approach for Identifying\nLarge Language Model Generated Text\nTRAVIS MUNYER\n , ABDULLAH ALL TANVIR\n, ARJON DAS\n , AND XIN ZHONG\nDepartment of Computer Science, University of Nebraska Omaha, Omaha, NE 68182, USA\nCorresponding author: Xin Zhong (xzhong@unomaha.edu)\nABSTRACT The rapid advancement of Large Language Models (LLMs) has significantly enhanced the\ncapabilities of text generators. With the potential for misuse escalating, the importance of discerning whether\ntexts are human-authored or generated by LLMs has become paramount. Several preceding studies have\nventured to address this challenge by employing binary classifiers to differentiate between human-written\nand LLM-generated text. Nevertheless, the reliability of these classifiers has been subject to question. Given\nthat consequential decisions may hinge on the outcome of such classification, it is imperative that text source\ndetection is of high caliber. In light of this, the present paper introduces DeepTextMark, a deep learning-\ndriven text watermarking methodology devised for text source identification. By leveraging Word2Vec\nand Sentence Encoding for watermark insertion, alongside a transformer-based classifier for watermark\ndetection, DeepTextMark epitomizes a blend of blindness, robustness, imperceptibility, and reliability.\nAs elaborated within the paper, these attributes are crucial for universal text source detection, with a particular\nemphasis in this paper on text produced by LLMs. DeepTextMark offers a viable ‘‘add-on’’ solution to\nprevailing text generation frameworks, requiring no direct access or alterations to the underlying text\ngeneration mechanism. Experimental evaluations underscore the high imperceptibility, elevated detection\naccuracy, augmented robustness, reliability, and swift execution of DeepTextMark.\nINDEX TERMS Text source detection, large language model text detection, text watermarking, deep\nlearning.\nI. INTRODUCTION\nLarge Language Models (LLMs), such as ChatGPT [1],\nhave recently achieved notable success. The advancements\nin LLMs can be advantageous across various domains, yet\nthere also lies the potential for inappropriate applications.\nA prevailing concern regarding publicly accessible LLMs is\nthe challenge in distinguishing between machine-generated\nand human-written text, a difficulty that persists even in\ninstances of misuse [2]. For instance, students might utilize\nautomatically generated texts as their own submissions for\nassignments, evading conventional ‘‘plagiarism’’ detection.\nThe high fidelity of the text generated by LLMs exacerbates\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Maria Chiara Caschera\n.\nthe challenge of detection, marking a significant hurdle.\nAgain, there exist advanced text augmentation methods\ncapable of effortlessly modifying any given text [3], [4] [5],\n[6]. Therefore, devising a method to ascertain the origin of\ntext could serve as a valuable approach to curtail similar\nmisapplications of LLMs.\nVarious classifiers have been developed to differentiate\nbetween LLM-generated text and human-written text [2], [7].\nHowever, the efficacy of these classifiers remains somewhat\nconstrained at present. Numerous studies have explored\nthe accuracy of these classifiers [8], along with techniques\nto circumvent classifier detection [9]. A reliable source\ndetection mechanism that is challenging to bypass is crucial,\ngiven its potential applications in identifying plagiarism and\nmisuse. Therefore, employing text watermarking for text\n40508\n\n 2024 The Authors. This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License.\nFor more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/ VOLUME 12, 2024\nT. Munyer et al.: DeepTextMark: A Deep Learning-Driven Text Watermarking Approach\nFIGURE 1. Overall idea of DeepTextMark.\nsource detection appears to be a prudent approach, as it is\nboth reliable and challenging to circumvent.\nText watermarking entails the covert embedding of infor-\nmation (i.e., the watermark) into cover texts, such that the\nwatermark is only discernible by authorized detectors. While\nwatermarking is more conventionally applied to images [10],\nits application to text can enable the identification of text\noriginating from specific sources, such as an LLM (refer\nto figure 1 for the proposed source detection mechanism).\nHowever, conventional text watermarking techniques often\nnecessitate manual intervention by linguists, exhibit a lack\nof robustness, and do not possess the blindness property.\nSpecifically, these traditional techniques are prone to minor\nmodifications of the watermarked text (lacking robustness),\nand necessitate the original text for the extraction or\ndetection of the watermark (lacking blindness). For a\nwatermarking technique to be practically viable in detecting\nLLM-generated text, the method should be scalable (i.e.,\nautomatic). Moreover, since the watermark detector may not\nhave access to the original text at the time of detection,\nit should not require it (i.e., blind). Additionally, the\ndetection process should be highly reliable, aiming to achieve\nsuperior classification accuracy. Ideally, the watermarked\ntext should remain imperceptible, ensuring the natural\npreservation of the text’s meaning. Lastly, the classification\nmechanism should be resilient to minor alterations of the text\n(i.e., robust).\nA nascent method has been proposed for embedding\nwatermarks into LLMs [11]. However, a notable limitation\nof this method is its requisite access to the text generation\nphase of the LLMs, a requirement that may not be practical in\nreal-world applications, particularly when the source models\nof the LLMs are not open-source. This dependency poses\na significant challenge as many LLMs are proprietary or\ntheir internals are not publicly disclosed, thereby restricting\nthe applicability of such watermarking techniques. Moreover,\nwithout the requisite access to the text generation phase,\nimplementing watermark-based source detection mecha-\nnisms becomes inherently challenging. This highlights the\nnecessity for developing alternative watermarking techniques\nthat are both effective and adaptable to varying levels of\naccess to the LLMs’ internal workings.\nThis paper introduces DeepTextMark, a robust and blind\ndeep learning-based text watermarking method principally\naimed at detecting LLM-generated text. DeepTextMark\nemploys word substitution, utilizing a pre-trained amalgam\nof Universal Sentence Encoder embeddings [12] and\nWord2Vec [13] to identify semantically congruent substi-\ntution words. The inserted watermark is invisible to the\nnaked eye, and the alterations made to the text, such\nas substituting words with synonyms while keeping the\ngrammatical structure intact, are designed to ensure that\nthe watermark remains undetectable to readers. Therefore,\nit preserves the imperceptible nature of the watermark within\nthe text. Moreover, we propose a novel classifier, grounded\nin transformer architecture [14], to discern watermarked\ntext, enhancing detection accuracy and robustness. This\nclassifier can accurately differentiate between marked and\nunmarked sentences based solely on the content and features\nextracted from the text, without altering its appearance\nor readability in any noticeable way. This imperceptibility\nensures that the watermark remains covert and undetectable\nto human observers, thereby preserving its effectiveness\nfor authentication or tracking purposes without alerting\npotential infringers to its existence. This amalgam of\npre-trained models for substitution word selection and the\ntransformer-based watermark detector underscore the novel\ncontributions of this paper. Being deep learning-driven, the\nwatermarking and detection techniques are scalable and fully\nautomatic. The classifier necessitates only the watermarked\ntext for highly accurate classification, epitomizing the\ntechnique’s blindness. Furthermore, the paper elucidates an\nextension of this technique to multiple sentences, like essays,\naccentuating a primary application. Empirical evidence is\nprovided demonstrating near-perfect accuracy as text length\nincreases, enriching the method’s reliability, especially with\na modest sentence count.\nThe primary contributions encapsulate: (1) an ‘‘add-\non’’ text watermarking method for detecting generated text\nwithout necessitating access to the LLMs’ generation phase;\n(2) an automatic and imperceptible watermark insertion\nmethod; and (3) a robust, high-accuracy deep learning-\nbased text watermark detection method, rendering Deep-\nTextMark a valuable asset in the realm of text authenticity\nverification.\nThe rest of this paper is organized as follows. We discuss\nrelated works in section II. The watermark insertion and\ndetection process is discussed in section III. Experiments\nshowing the reliability, imperceptibility, robustness, and\nempirical runtime are shown in section IV followed by a\nconclusion of the work in section V.\nII. RELATED WORK\nOur contributions are summarized as robust detection of\nLLM-generated text, a novel method for text watermarking\ninsertion, and a novel approach for text watermarking\ndetection; the following sections provide a review of related\nwork in these domains. Section II-A offers a concise review\nof state-of-the-art methods for LLM-generated text detection,\nwhile Section II-B delves into classical text watermarking\ntechniques.\nVOLUME 12, 2024 40509\nT. Munyer et al.: DeepTextMark: A Deep Learning-Driven Text Watermarking Approach\nA. TEXT SOURCE DETECTION FOR LARGE LANGUAGE\nMODELS\nRecent endeavors have been directed towards developing\nclassifiers aimed at differentiating between LLM-generated\ntext and human-written text. The prevailing approach entails\nthe collection and labeling of LLM-generated and human-\nwritten texts, followed by the training of a binary clas-\nsifier through supervised learning. Although the efficacy\nof these classifiers has yet to be fully established, some\npreliminary analyses have been reported [8], [9]. One\nstudy [9] elucidated three distinct methods, substantiated with\nexamples, to circumvent the GPTZero [7] classifier detection.\nAnother investigation [8] conducted a direct assessment\nof GPTZero’s accuracy, uncovering inconsistencies in its\nability to detect human-written text. Moreover, classifier-\nbased LLM-generated text detectors commonly necessitate\na substantial character count to perform detection accu-\nrately. For instance, GPTZero [7] required a minimum\nof 250 characters to initiate detection. Looking ahead,\nOpenAI is planning a cryptography-based watermarking\nsystem for ChatGPT-generated text detection [15], although\nno definitive work has been disclosed as of yet. Zero-\nshot learning-based methods have also demonstrated some\nadvancement. For example, Mitchell et al. [16] reported\nan increment in AUROC from 1% to 14% compared to\nother zero-shot detection strategies across various datasets;\nhowever, the accuracy might still fall short in real-world\napplications concerning text generated by models.\nA method has been proposed for detecting LLM-generated\ntexts based on text watermarking [11], which involves\nwatermarking the text by modifying the LLMs (sensitive\ntokens are defined and excluded from the output of the\nLLMs). In contrast, our proposed DeepTextMark does not\nnecessitate access to or modifications of the LLM. Distinct\nfrom model-dependent methods, DeepTextMark exhibits a\nmodel-independent feature, enabling its application to any\ntext. Moreover, DeepTextMark employs a substantially more\ncompact architecture with about 50 million parameters,\nwhereas the method in [11] necessitates billions of param-\neters to implement the watermarking process.\nA pertinent topic in text watermarking for identify-\ning generated text is the potential use of paraphrasing\nattacks to bypass AI-detectors, as elaborated in a study by\nSadasivan et al. [17]. This concern is not relevant to our\ntarget scenario, as DeepTextMark focuses solely on the\ndetection of text output by an LLM. Should a human writer\nmeticulously rewrite the text generated by an LLM, the\nresultant paraphrased text may not be subject to ‘‘plagiarism’’\ndetection in our scenario.\nRelative to existing state-of-the-art methods, our pro-\nposal exhibits several advantages: (1) Our watermarking\nmethod renders detection bypass challenging unless the\nLLM-generated text is rewritten, as the watermark is\nembedded in undisclosed locations, necessitating a rewrite\nfor its removal. Once rewritten, the text is deemed as\ndistinct human-written text; (2) The method demonstrates\nhigh detection accuracy, nearing 100%, which significantly\nelevates with an increasing number of sentences, substanti-\nated through binomial distribution analysis. Even on a single\nsentence, a reliable detection rate of 86.52% is achieved;\n(3) To our knowledge, this is the inaugural LLM-independent,\ndeep learning-based general text watermarking method;\n(4) Unlike some methods necessitating access to text\ngeneration processes, our approach requires no access to the\nLLM’s original text generation, allowing our watermarker to\nfunction as an ‘‘add-on’’ to the LLM system (see Figure 1).\nB. TRADITIONAL TEXT WATERMARKING\nCommon classical text watermarking methods can be cate-\ngorized into open space, syntactic, semantic, linguistic, and\nstructural techniques. A brief summary of each of these\ntechniques is provided below.\n1) OPEN SPACE\nThe open space method embeds a watermark into text data\nby adding extra white space characters or spaces at specific\nlocations in the text [18]. For instance, extra white space\nbetween words or lines could be encoded as a 1, while normal\nwhite space could encode as a 0. The strategy for adding extra\nwhite space and its encoding is subject to the implementation.\nAlthough the open space method can be simple to implement\nand automate, it may be susceptible to watermark removal\nwithout altering the text’s meaning, as an individual could\neasily eliminate the extra white space.\n2) SYNTACTIC\nCertain word orders can be altered without changing the\nmeaning or grammatical correctness of a sentence. The\nsyntactic method watermarks text by modifying the order\nof words in sentences [19]. For example, ‘‘this and that’’\ncould encode to 1, and ‘‘that and this’’ could encode to\n0. However, this method may not scale well since many\nsentences do not have sequences of words that qualify\nfor reordering. Additionally, this method might necessitate\nmanual intervention by a linguist, as developing an automated\nsystem to detect reorderable words could be challenging.\n3) SEMANTIC\nSemantic text watermarking techniques embed the watermark\nby substituting words with synonyms [19]. While the\nsemantic method can be automated, as briefly discussed\nin this paper, classical implementation requires the original\ntext to detect the watermark (i.e., classical semantic text\nwatermarking is non-blind). Moreover, determining which\nword to replace, and selecting an appropriate synonym,\npresents a non-trivial challenge.\n4) LINGUISTIC\nThe linguistic category of text watermarking amalgamates\nsemantic and syntactic techniques, embedding watermarks\n40510 VOLUME 12, 2024\nT. Munyer et al.: DeepTextMark: A Deep Learning-Driven Text Watermarking Approach\nFIGURE 2. Watermark insertion details.\ninto text through a blend of word rearrangement and synonym\nreplacement [19].\n5) STRUCTURAL\nThe structural technique replaces certain symbols with\nvisually similar letters and punctuation, albeit with different\nUnicode representations [20]. It may be relatively straight-\nforward to detect these symbols either manually due to\nminor visual differences, or automatically by identifying\ncharacters from uncommon Unicode sets. Reverting the\nwatermarking without altering the text’s meaning could\nalso be straightforward. Due to these limitations, structural\ntechniques do not align with our primary objective of\nwatermarking text generated by LLMs.\nContrastingly, we employ word2vec [13] and the Universal\nSentence Encoder [12] for watermark insertion, and devise\na transformer-based model for watermark detection. This\napproach aligns well with our target application of text\nsource detection, as it facilitates blindness while enhancing\nimperceptibility, robustness, and reliability. Our watermark\ninsertion and detection methodology is rooted in deep\nlearning, distinguishing our method from traditional text\nwatermarking techniques.\nIII. THE PROPOSED DEEPTEXTMARK\nThis section presents the details of DeepTextMark. The\nproposed watermark insertion and detection schemes are\nrespectively discussed in Sections III-A and III-B. This\ndiscussion shows the automatic and blindness traits achieved\nby DeepTextMark. Section III-C analyzes the application\nscenario of DeepTextMark to multiple sentences.\nA. WATERMARK INSERTION\nIn contemporary settings, individuals employ extensive\nlanguage models to produce textual content and subsequently\nrephrase it using synonymous words as a strategy to\ncircumvent plagiarism. This serves as the rationale behind\nour introduced watermark insertion model, aiming to detect\nalterations in text even when someone attempts to paraphrase\ncontent generated by large language models in order to evade\nplagiarism detection. The watermark insertion process is\npresented in Figure 2.\n1) WORD SELECTION\nGiven a sentence, we initially segregate candidate words from\npunctuation, stopwords [21], and whitespace, preserving\nthese elements to retain the original sentence structure.\nEach candidate word is then transposed to an embedding\nvector utilizing a pre-trained Word2Vec model [13]. A roster\nof replacement words is engendered by identifying the n\nnearest vectors to the candidate word vector in the Word2Vec\nembedding space, where n is a pre-defined integer, and\nreconverting these vectors back into words. We engender\na list of sentence proposals by substituting each candidate\nword with its list of replacement words, thereby fabricating\nunique sentence variations. The loci of the watermark in each\nsentence proposal are indirectly ascertained by Word2Vec.\nEach unique variation is deemed a sentence proposal,\nrepresenting a potential watermarked sentence. Empirically,\nemploying a larger corpus of nearest vectors allows for\nthe consideration of an augmented set of replacement\nwords and consequently more sentence proposals, potentially\nameliorating imperceptibility albeit at the expense of elevated\nprocessing time. We also delved into various word-level\nwatermarking techniques. Initially, a sole word within each\nsentence was substituted with its synonyms which we\ndenote as single word synonym substitution. This scope\nwas subsequently broadened to encompass multiple-word\nreplacements within each sentence which is denoted by\nmultiple word synonyms substitution. In the terminal phase\nof our experimentation, we embraced a flexible approach,\npermitting the substitution of any candidate word with an\navailable synonym in a sentence.\n2) SENTENCE ENCODING\nAt this juncture, each sentence proposal is evaluated solely\nbased on word-level quality. We ascertain that the qual-\nity of the watermarked sentence is enhanced when the\narchitecture is allowed to consider sentence-level quality.\nTo facilitate this, we employ a pretrained Universal Sentence\nEncoder [12] to score the quality of each sentence proposal.\nVOLUME 12, 2024 40511\nT. Munyer et al.: DeepTextMark: A Deep Learning-Driven Text Watermarking Approach\nTABLE 1. Example sentence candidates of correct and incorrect synonym\nselections.\nTABLE 2. Example sentence candidates with varied synonyms.\nThis encoder transposes a sentence into a high-dimensional\nvector representation. Initially, both the original sentence\nand each sentence proposal are transposed into vector\nrepresentations using the Universal Sentence Encoder. Sub-\nsequently, we compute the similarity score for each sentence\nproposal by measuring the cosine similarity between the\nvector representation of the original sentence and that of\nthe sentence proposal. The sentence proposal exhibiting\nthe highest similarity score is identified as the potential\nwatermarked sentence. Given that the watermarking process\nnecessitates no human intervention, the methodology is\nrendered automatic.\n3) GRAMMATICAL ADJUSTMENT\nIn pursuit of mitigating grammatical inaccuracies, essential\nmeasures have been undertaken. Our methodology encom-\npasses word substitution with synonymous counterparts,\nwhilst steadfastly preserving the original sentence structure.\nIn this vein, we have eschewed the elimination of stopwords\nor the alteration of punctuation, thereby safeguarding sen-\ntence integrity.\nThe process of synonym selection is meticulously designed\nto favor optimal replacements. Nevertheless, challenges\nemerge in instances where the most apt synonym diverges\nin grammatical structure or meaning. For instance, replacing\nthe term ‘elections,’ a plural noun, with ‘election,’ its sin-\ngular counterpart, could engender grammatical incongruity.\nTo forestall such scenarios, a preliminary determination\nof the grammatical number of the target word is initiated\nwith a class engine [22] which employs diverse methods to\nfacilitate plural and singular inflections, the selection of ‘‘a’’\nor ‘‘an’’ for English words based on pronunciation, and the\nmanipulation of numbers represented as words. This module\ncomprehensively provides plural forms for nouns, most\nverbs, and select adjectives, including ‘‘classical’’ variants\nAlgorithm 1 Watermark Insertion\n1: function WatermarkInsertion(input_text)\n2: word_embedder ← Word2Vec\n3: sentence_encoder ← SentenceEncoder\n4: input_embeddings ← Encode(word_embedder,\ninput_text)\n5: sentence_proposals ← GeneratePropos-\nals(input_text)\n6: proposals_embeddings ←\nEncode(sentence_encoder, sentence_proposals)\n7: best_proposal ← ComputeCosineSimilar-\nity(input_embeddings, proposals_embeddings)\n8: marked_text ← GrammaticalAdjust-\nment(best_proposal)\n9: return marked_text\nlike transforming ‘‘brother’’ to ‘‘brethren’’ or ‘‘dogma’’ to\n‘‘dogmata.’’ Singular forms of nouns are also available,\nallowing the choice of gender for singular pronouns, such\nas transforming ‘‘they’’ to ‘‘it,’’ ‘‘she,’’ ‘‘he,’’ or ‘‘they.’’\nPronunciation-based ‘‘a’’ or ‘‘an’’ selection is extended to\nall English words and most initialisms. It is crucial to note\nthat when using plural inflection methods, the word to be\ninflected should be the first argument, expecting the singular\nform; passing a plural form may yield undefined and likely\nincorrect results. Similarly, the singular inflection method\nanticipates the plural form of the word. The plural inflection\nmethods also offer an optional second argument indicating\nthe grammatical ‘‘number’’ of the word or another word\nfor agreement. Subsequently, synonyms congruent with the\ngrammatical form of the original word are curated.\nA few examples of sentence candidates with correct\nand incorrect synonym selections are presented in Table 1.\nIt is imperative to note that when we scrutinize the word\nterm, we encounter the closest synonyms, some of which\ncontravene the grammatical criteria due to their distinct\ngrammatical numbers, with one being singular and the other\nplural. Consequently, given that our initial word is in the\nsingular form, our consideration is limited exclusively to\nsynonyms in the singular form. Consequently, in lieu of\nemploying terms, we opt to substitute it with condition.\nAnalogous complexities arise concerning parts of speech,\nas certain words harbor synonyms across diverse lexical\ncategories. To adeptly navigate this intricacy, integration of\nthe classic POS (Part of Speech) tagger [23] has been effected.\nPost identification of the word’s grammatical number, the\nendeavor to pinpoint synonyms aligning with its specific part\nof speech is undertaken. This bifurcated approach underpins\nboth syntactic and grammatical consistency in our synonym\nsubstitution process.\nA few examples of sentence candidates with varied syn-\nonyms selections are presented in Table 2. An analysis of the\nterm primary reveals that the closest synonyms are typically\nadverbs like first, thereby deviating from the grammatical\n40512 VOLUME 12, 2024\nT. Munyer et al.: DeepTextMark: A Deep Learning-Driven Text Watermarking Approach\nFIGURE 3. Watermark detection details.\ncondition, as the original term is a proper noun (NNP). Given\nthe categorical distinction that our original word falls into\nthe proper noun category (NNP), our focus is exclusively on\nsynonyms that share this grammatical property. This rationale\ninforms our decision to replace the word primary with\nleading instead of first. We have implemented the type of\nparts of speech by using the POS-tagger provided by the\nNLTK [23]. Specifically, we employed the Penn Treebank\nPOS tagger. The tagging process involved tokenization of\ninput text, breaking it into individual words or sentences,\nand subsequently assigning part-of-speech tags to each word.\nThe POS tagging was conducted using a Hidden Markov\nModel (HMM), trained on a large annotated corpus, such as\nthe Penn Treebank corpus, wherein the model learned the\nprobabilities of transitions between different POS tags and the\nprobabilities of observing specific words given a certain POS\ntag. The Viterbi algorithm was employed during the tagging\nof new text to identify the most likely sequence of POS\ntags given the observed words and the learned probabilities.\nThis approach proved effective for obtaining accurate and\ncontextually relevant part-of-speech annotations in diverse\ntextual datasets. Algorithm 1 outlines the entire operational\nprocess.\nB. WATERMARK DETECTION\nThe watermark detector operates as a binary classifier\ncategorizing inputs into ‘‘watermarked’’ and ‘‘unmarked’’\nclasses, leveraging network architectures inherent in trans-\nformers [14]. We have used the Bidirectional Encoder Rep-\nresentations from Transformers (BERT) pre-trained model\nwhich is capable of capturing the contextual meaning of\nwords in a sentence. Unlike traditional methods that treat\neach word as independent, BERT considers the entire context\nof the sentence, including the relationships between words.\nHence, it will possess the capability to recognize sentence\nmodifications and distinguish between marked and unmarked\nsentences. Furthermore, BERT serves as a powerful fea-\nture extractor, automatically extracting high-dimensional\nrepresentations of text at various levels of granularity. It’s\nscalability and generalization capabilities enable it to handle\ndiverse datasets and adapt to different domains and languages\nwith minimal additional training. The architecture of this\nclassifier is delineated in Figure 3.\nThe watermark detection classifier endeavors to minimize\nthe ensuing binary cross-entropy loss:\nL = yi · log(p(yi)) + (1 − yi) · log(1 − p(yi)), (1)\nwhere yi denotes the label, and p(yi) represents the predicted\nprobability. The parameters of the BERT encoder are initially\nfrozen, allowing the loss to converge with the transformer\nblock being trainable. Upon convergence of the loss with\na frozen BERT, the parameters of BERT are unfrozen, the\nlearning rate of Adam is attenuated, and training is recom-\nmenced until loss convergence is reattained. This iterative\ntraining paradigm can precipitate a notable enhancement in\nprediction performance training solely the transformer block.\nThe outcomes of the training regimen are elaborated in\nsection IV-B. This architecture, post convergence, embodies\nthe watermark detector. Given that the detector necessitates\nno access to the original data for prediction execution, the\nmethodology is characterized as blind.\nC. WATERMARK DETECTION FOR MULTIPLE SENTENCES\nA prominent application scenario for the proposed water-\nmarking technique is its deployment on a collection of\nsentences. Consequently, the classification outcome is con-\ntingent on the majority classification rendered for each\nindividual sentence. Employing the binomial distribution,\nit can be demonstrated that the likelihood of accurately\nclassifying a sentence collection converges to near perfection\nas the volume of sentences in the collection escalates,\nprovided the probability of accurately classifying a single\nsentence is reasonably high (> 85%). Notwithstanding,\na superior probability of correct classification for a single\nsentence implies a reduced sentence count is requisite to\nattain near-perfect accuracy. Algorithm 2 comprehensively\noutlines the entire working procedure.\nThe proof underpinning this claim is articulated as follows:\nPresume the probability of accurately classifying a sentence\nas watermarked or not is denoted by p, and remains consistent\nacross all sentences. In a scenario where at least half of the\nsentences in a text comprising n sentences are accurately\nVOLUME 12, 2024 40513\nT. Munyer et al.: DeepTextMark: A Deep Learning-Driven Text Watermarking Approach\nAlgorithm 2 Watermark Detection\n1: function WatermarkDetection(test_text)\n2: embeddings ← BERT_Encode(test_text)\n3: decoder_output ← TransformerDe-\ncoderBlock(embeddings)\n4: pooled_output ← Pooling(decoder_output)\n5: dropout_output ← Dropout(pooled_output)\n6: fc_20_output ← FullyConnected(dropout_output,\n20)\n7: dropout_fc ← Dropout(fc_20_output)\n8: watermark_score ← FullyConnected(dropout_fc, 1)\n9: return watermark_score\nclassified, the entire text is deemed correctly classified. It can\nbe substantiated that the probability of accurately classifying\nexactly x sentences can be encapsulated by the binomial\nprobability, denoted as P(x). Hence, the probability P(x >\n⌈n/2⌉) can be formulated as the summation in Equation (2):\nP(x > ⌈n/2⌉) =\nn∑\ni=⌈n/2⌉\n(n\ni\n)\n× pi × (1 − p)n−i. (2)\nIV. EXPERIMENTS\nThis section illustrates the effectiveness of DeepTextMark\nby analyzing its properties in regard of text watermarking.\nDataset preparation is explained in section IV-A. The relia-\nbility of the watermark detection is shown in section IV-B.\nSection IV-C explains the ablation study. Section IV-D\nprovides a summary of the imperceptibility, and the imper-\nceptibility and detection accuracy trade-off. Comparisons\nare made between DeepTextMark and traditional text water-\nmarking methods. Section IV-E provides an analysis of\nthe experiments used to test robustness, which is followed\nby an evaluation of the empirically observed runtime in\nsection IV-G.\nA. DATASET\n1) TRAINING DATA\nA dataset comprising 34,489 sentences was assembled from\nthe Dolly ChatGPT Dataset [24]. This approach aims to\nunderscore the generalization capability of the proposed\nDeepTextMark. Robust performance across diverse textual\ngenres exemplifies the model’s aptitude for generalizing to\narbitrary text. Evaluations have been also conducted on texts\nengendered by expansive language models such as ChatGPT,\nas depicted in an instance in Figure 4. Within the training\nset, half of the sentences are watermarked employing the\nmethodology delineated in section III-A, whilst the remainder\nare retained unaltered. This yields a dataset encompassing\nnearly 17,000 watermarked samples and approximately\n17,000 unmarked samples. The corpus of watermarked and\nunmarked sentence samples are randomly amalgamated, with\n75% earmarked for training, and the residual 25% allocated\nfor validation—this composition underpins the training of the\ndetector. To facilitate the assessment of imperceptibility in\nTABLE 3. Sentence count on detection accuracy (%) (single synonym).\nTABLE 4. Sentence count on detection accuracy(%) (multiple synonyms).\nTABLE 5. Ablation study.\nsection IV-D, a dataset encapsulating all 34,489 sentences as\noriginal and watermarked pairs is retained.\n2) TESTING DATA\nWe assessed the performance of our model by subjecting it to\ntesting using C4 datasets [25] containing multiple sentences.\nTo evaluate its performance, we systematically extracted\n100 tokens at a time, aggregating them into a unified dataset\nfeaturing numerous sentences. This process yielded a total of\n8,800 datasets. Subsequently, we conducted rigorous testing\non these datasets, incorporating both single and multiple\nsynonym substitutions to gauge the model’s adaptability and\neffectiveness.\nB. WATERMARK DETECTION ACCURACY\nThe proposed watermark detection classifier is trained\nusing the dataset discussed in Section III-B. We train the\narchitecture with the parameters of the pre-trained BERT\nencoder frozen for 6 epochs, with an Adam learning rate set to\n0.0001. Then, we unfreeze the pre-trained BERT architecture,\nreduce the learning rate of Adam [26] to 0.000001, and\ntrain for 50 more epochs. In our training model, 148 million\nparameters have been used. The result validation accuracy,\nwhich represents the sentence-level detection accuracy on\nthe dolly validation dataset, is 86.52% for single synonyms\nand 94.87% for multiple synonyms. And for C4 datasets,\nits 76.30% for single synonyms and 95.72% for multiple\nsynonyms substitution.\nAdditionally, we conduct this training process on several\nversions of the dataset, each with an increasing number of\n40514 VOLUME 12, 2024\nT. Munyer et al.: DeepTextMark: A Deep Learning-Driven Text Watermarking Approach\nFIGURE 4. A watermarked example from ChatGPT with prompt ‘‘Give me\na short essay about deep learning’’ .\nsentences. We observe that as we continually increase the\nsize of the dataset, the validation accuracy improves. Training\nwith an increasing number of sentences could further\nimprove the sentence-level prediction accuracy. We find that\nthe current training is balanced on table 3, table 4 and\nSection IV-D, as this validation yields near-perfect prediction\naccuracy with only a small collection of sentences.\nAs elucidated by the binomial distribution in Section III-C,\nthe probability of accurately classifying a collection of\nsentences markedly increases with the augmentation of the\nsentence count in the text, attributable to our sentence-level\ninsertion process. Assuming the likelihood of accurately\nclassifying a single sentence aligns closely with the validation\naccuracy computed during training, and that this likelihood\nremains consistent across all sentences, we can forecast\nthe probability of accurately classifying a collection of\nsentences utilizing the summation outlined in Eq. (2).\nUnder this assumption, the probability of correct prediction\ncorresponding to varying sentence counts is tabulated in\nTable 3 and Table 4. Table 3 and Table 4 underscore the\nreliability of the method, highlighting an increased likelihood\nof accurate detection as the number of sentences rises. This\ntrend is observed for both single and multiple synonyms\nsubstitution, encompassing both dolly and C4 datasets.\nC. ABLATION STUDY\nTo evaluate the effectiveness of our proposed method,\nwe conducted an ablation study by systematically removing\ncomponents from our model and observing their impact on\nperformance. Specifically, we conducted four experiments\ndenoted as A, B, C, and D, each representing a variant of\nour model with varying degrees of complexity. Experiment D,\nwhich incorporates all proposed enhancements, achieved the\nhighest accuracy among the tested configurations. This result\nTABLE 6. A few example sentences: 1. the original text; 2. watermarked\ntext by the traditional method; 3. watermarked text by the DeepTextMark.\nwith single synonym substitution; and 4. watermarked text by the\nDeepTextMark with multiple synonyms substitution.\nsuggests that the additional components in experiment D\ncontribute positively to the overall performance of the model.\nFurthermore, by comparing the accuracy of experiment D\nwith those of experiments A, B, and C, as shown in Table 5,\nwe can pinpoint the specific contributions of each component\nto the model’s effectiveness. Our findings underscore the\nimportance of the incorporated enhancements and highlight\nthe significance of their inclusion in our proposed approach.\nD. IMPERCEPTIBILITY OF WATERMARK INSERTION\nA sentence bearing an imperceptible watermark should\nmaintain grammatical correctness and retain the same\nmeaning as the original sentence. Thus, the imperceptibility\nof text watermarking should be gauged by sentence meaning\nsimilarity. The Universal Sentence Encoder [12] encapsulates\nthe semantic meaning of sentences into an embedding vector,\nenabling the measurement of sentence meaning similarity\nthrough the computation of cosine similarity between two\nsentence embeddings. Hence, we propose to quantify the\nimperceptibility of text watermarking using the Sentence\nMeaning Similarity (SMS):\nSMS = S(encode(o), encode(m)), (3)\nwhere o denotes the original text, m denotes the watermarked\ntext, encode(·) represents a neural network that computes a\nsemantic embedding (e.g., the Universal Sentence Encoder),\nand S is a function that computes the similarity between\nthe vectors (cosine similarity is utilized in this paper).\nComputing the mean SMS (mSMS) over a dataset provides\nan average measure of text watermark imperceptibility.\nWe have performed our experiment for the test dataset\ndiscussed in Section III-B and we are able to achieve 0.9765\nmSMS for single synonyms and 0.9892 mSMS for multiple\nsynonyms while the traditional method provides 0.9794\nmSMS. The high mSMS value exemplifies the imperceptible\nwatermarking of texts by DeepTextMark. An illustration\nof watermarking a text produced by ChatGPT is presented\nin Figure 4, with additional examples of original and\nwatermarked paragraphs available in the supplementary\ndocuments.\nVOLUME 12, 2024 40515\nT. Munyer et al.: DeepTextMark: A Deep Learning-Driven Text Watermarking Approach\nTABLE 7. Remove sentences attack.\nTABLE 8. Add sentences attack.\nFor analytical purposes, we implement traditional text\nwatermarking and test the proposed watermark detection\nnetwork at a single-sentence level. Specifically, we create\nan implementation of semantic watermarking using Word-\nNet [27] to select synonyms. Although this traditional method\nachieved some success, the replacement word occasionally\nrendered the sentence nonsensical, as this method did not\naccount for sentence structure. Some sentence examples are\nillustrated in Table 6 (additional sentence examples can be\nfound in the supplementary documents). While the traditional\nmethod can be effectively detected by our detection network\nfor a single sentence, as depicted in Table 10, the mSMS on the\ncollected dataset significantly improves with DeepTextMark\nmultiple synonyms and not that much far from single\nsynonyms as well.\nE. ROBUSTNESS\nRobustness in the domain of image watermarking implies\nthat the watermark must remain invariant to malicious attacks\nor unintentional modifications [28]. Translating this notion\nof robustness to text watermarking is fairly straightforward.\nA robust text watermarking method should ensure that\nremoving the watermark is challenging, whether the removal\nattempts are unintentional, arising from normal processing,\nor intentional attacks targeting the watermark. For watermark\ndetection to fail, the watermarked text should need to be\naltered beyond recognition.\nGiven that this is an emerging area, no standard method\nexists to measure robustness for text watermarking [19].\nTherefore, we propose a metric named Mean Impact of\nAttack (mIOA) to measure robustness. The IOA is defined as\nfollows:\nIOA(x, y) = (1−|detect (x)−y|)−(1−|detect (xa)−y|), (4)\nwhere x represents the target data (text of one or more\nsentences in this paper), xa denotes the attacked data\nobtained by arbitrarily attacking x, y signifies the label for\nx (watermarked or unmarked), and detect(·) denotes the\nTABLE 9. Replace sentences attack.\nTABLE 10. Comparative analysis in terms ofmSMS and detection\naccuracy.\nutilization of the detection network to output the predicted\nlabel of the input. IOA gauges the change in accuracy\nfollowing an attack on the data. A positive IOA indicates\na detrimental effect on prediction performance due to the\nattack, while a negative IOA indicates improved prediction\nperformance post-attack (which should be rare). An IOA\nfurther from 0 (either less than or greater than) signifies a\nhigher impact from the attack. An IOA of 0 indicates the\nattack did not affect the prediction accuracy. Calculating the\nmean IOA over a dataset yields the mIOA.\n1) DATA FOR ROBUSTNESS TEST\nWe have prepared two sets of data: one with watermarked\ntext and one with unmarked text. Each set contains 1000 col-\nlections, with each collection comprising 20 sentences.\nThese sentences are randomly selected from the testing set\ndescribed in Section III-B.\nWe then define several attacks and compute the mIOA for\neach attack to gauge the robustness of our watermarking\ntechnique. These attacks are designed to progressively\nmodify the text, with the severity of each attack increasing the\ndissimilarity between the modified and original texts. Each\nattack also represents a common interaction with the text.\nBy attacking both watermarked and unmarked data, we aim to\nevaluate the detection accuracy for both types of data, which\nhelps ensure that our system is equally effective at detecting\nwatermarks and identifying unmarked data.\n2) REMOVE SENTENCES ATTACK\nWe remove a selected number of n sentences from the text.\nThis action reduces the watermark presence in the text, thus\nchallenging the robustness of the detection. Table 7 presents\nthe mIOA on both watermarked and unmarked datasets for\nseveral values of n. In all cases, the total number of sentences\nis 20.\nThe results show that the mIOA increases as the severity\nof the attack intensifies (i.e., more sentences are removed),\nyet the performance remains commendable as the mIOA stays\nclose to 0. Interestingly, the mIOA is consistently higher on\nthe watermarked data.\n40516 VOLUME 12, 2024\nT. Munyer et al.: DeepTextMark: A Deep Learning-Driven Text Watermarking Approach\nFIGURE 5. Sample generation process for testing and comparing\nwatermark detection accuracy of DeepTextMark and WLP.\nTABLE 11. Detection accuracy of DeepTextMark and WLP with smaller\ndatasets.\n3) ADD SENTENCES ATTACK\nIn this attack, a specified number of sentences (represented\nby n) with the opposite label are randomly added to the text.\nFor instance, watermarked sentences are added to unmarked\ntext. Increasing the value of n challenges the robustness of the\ndetection, as it dilutes the percentage of text that corresponds\nto the expected label. Table 8 illustrates the mIOA on the\nwatermarked and unmarked datasets for several values of n.\nThe data shows that the mIOA increases as n increases.\nDeepTextMark maintains a high performance, as the mIOA\nremains close to 0 for a reasonable n.\n4) REPLACE SENTENCES ATTACK\nThis attack adopts a similar data dilution approach as the\nadd sentences attack. It distorts the text data by replacing\nn existing sentences in the text with randomly selected\nsentences of the opposite type, where n is a specified integer.\nTable 9 presents the watermarked and unmarked mIOA for\nseveral values of n.\nThe mIOA increases as n increases, and DeepTextMark\nremains close to 0, indicating a minimal impact on detection\nperformance. Since the modified text becomes increasingly\ndissimilar to the original text post-attack, an escalating\nperformance impact is expected and acceptable as the severity\nof each attack intensifies. These experiments affirm that\nDeepTextMark is robust to text modifications stemming from\ncommon text interactions.\nF. COMPARATIVE ANALYSIS\nTo start our comparative analysis, we have used three\nmethods and their combinations. The first approach is the\nTraditional method, involving a simple single-word modifica-\ntion without any components of the proposed DeepTextMark.\nFollowing that, we introduce DeepTextMark, which encom-\npasses both single and multiple synonym substitutions while\nrectifying grammatical errors. We perform the comparison\nTABLE 12. Robustness comparison of DeepTextMark and WLP.\nin terms of imperceptibility and detection accuracy which\nhas been shown in table 10 where we can see that our\nDeepTextMark with multiple synonyms performed very well\nin terms of both imperceptibility and detection accuracy.\nWe have also performed a deeper comparative analy-\nsis between our approach and the method proposed by\nKirchenbauer et al. [11]. For clarity within the context of\nthis paper, we will refer to their method as the Watermark\nLogit Processor (WLP) method, to prevent any naming\nconfusion. It’s important to highlight that the WLP method\nnecessitates access to LLMs, specifically utilizing them as\na logit processor to favor the selection of ‘‘green’’ tokens\nduring text generation. On the other hand, our proposed\nmethod operates independently and does not require access\nto LLMs.\nTo ensure a fair comparison, it is imperative that both\nmethods are evaluated using the same source of text, specif-\nically an LLM. Consequently, for text generation, we have\nemployed the Open Pre-trained Transformer (OPT-2.7B).\nThe primary objective of this experiment is to apply our\nmethod, alongside the WLP method, to watermark the\ncontent generated by OPT-2.7B and subsequently evaluate\nthe detection accuracy for comparison purposes. To generate\na substantial amount of text content, we utilized a subset of\nthe C4 dataset, comprising 22k text samples, as the source\nof prompts for the LLM in a seeded environment to yield\ndeterministic outputs with a set of 500 sequences of length\nT = 200 token sequences which is similar to the WLP paper.\nThe authors of WLP papers proposed two different methods\nwhich we denote WLP-multinomial sampling and WLP-\nbeam search to avoid confusion. With this setup, upon\ninputting text (prompt) samples from the C4 dataset into\nthe base LLM, we obtain blocks of text, which we term\nthe ‘‘Original Generated Content.’’ Subsequently, we apply\nour proposed method to the ‘‘Original Generated Content’’\nto produce the DeepTextMark-based watermarked content.\nConversely, when we incorporate the WLP logit processor\nwith the base LLM, the identical input text samples yield\nthe WLP Watermarked Content. Figure 5 illustrates the text\ngeneration methodology employed for the comparative evalu-\nation between DeepTextMark and WLP. In this configuration,\nour model demonstrates a notable detection rate of 90.66%.\nThis outcome, achieved despite training on the distinct Dolly\ndataset, underlines the robust generalization capability of our\napproach, affirming its effectiveness across diverse datasets.\nVOLUME 12, 2024 40517\nT. Munyer et al.: DeepTextMark: A Deep Learning-Driven Text Watermarking Approach\nFIGURE 6. TPR and FNR trade-offs.\nTABLE 13. DeepTextMark Runtime on a single CPU core.\nIn our experimental evaluation, we utilized a subset of\n500 data points to assess the watermark detection perfor-\nmance of both models. Despite the distinct datasets employed\nin training our model DeepTextMark, it demonstrates a\ncommendable detection rate, only marginally lower than\nthat reported in the WLP paper. Specifically, DeepTextMark\nachieved an accuracy of 90.74%, closely approaching the\n92.42% accuracy of the WLP model. This proximity in\nperformance is noteworthy, considering the differences in\ntraining datasets. Table 11 presents a detailed comparative\nanalysis of the watermark detection accuracies between\nDeepTextMark and WLP.\nWe conducted a robustness comparison between the\ntwo models, considering three attack types: text insertion,\ndeletion, and substitution. Text insertion attacks add extra\ntokens post-generation, while text deletion removes tokens\nfrom the generated output, potentially diminishing text\nquality by reducing the effective language model (LM)\ncontext width. Text substitution attacks involve replacing\none token with another, which can be automated through\ndictionary or LM techniques but may degrade text quality.\nOur comparative analysis, summarized in Table 12, reveals\nthe robustness of DeepTextMark and WLP. The WLP study\ninvolved meticulous parameter adjustments to optimize their\nmodel’s performance. Despite being trained on the Dolly\nDataset, our model exhibited superior performance when\ntested on the C4 dataset produced by the LLM, outperforming\nin most scenarios for watermark detection accuracy. For\nrobustness evaluation, we introduced new metrics while also\nusing the True Positive Rate (TPR) and False Negative\nRate (FNR) metrics from the WLP paper to ensure a fair\nassessment.\nThe Area Under the Receiver Operating Characteristic\n(AUC) curve and True Positive Rate (TPR) are key metrics in\nbinary classification. AUC illustrates the trade-off between\nsensitivity (TPR) and 1 - specificity (False Positive Rate)\nacross different thresholds, ranging from 0 to 1. A value\nof 0.5 implies no discriminative ability, whereas 1 indicates\nperfect classification. Higher AUC values denote superior\nmodel performance. TPR, or sensitivity/recall, is the ratio\nof correctly identified positive instances to all actual pos-\nitives, defined as: TPR = TruePositives/(TruePositives+\nFalseNegatives). Conversely, the False Negative Rate (FNR)\nquantifies the proportion of positives incorrectly classi-\nfied as negatives: FNR = FalseNegatives/(Positives +\nFalseNegatives)\nA superior TPR, signifying DeepTextMark’s proficiency\nin correctly identifying positive instances while minimizing\nfalse negatives, underscores its efficacy in capturing the\nmajority of actual positive cases. Concurrently, the smaller\nFNR suggests a reduced probability of overlooking posi-\ntive instances, highlighting DeepTextMark’s competence in\naverting false negatives and precisely identifying positive\ncases. In light of our model’s outperformance compared to\nWLP, it can be inferred that DeepTextMark demonstrates a\nheightened capability in detecting watermarked sentences,\nsurpassing the performance of WLP in this regard. This\nsubstantiates the conclusion that our model excels in\ndiscerning watermarked content more effectively.\nFigure 6 delineates the interplay between TPR and FNR\nfor our proposed method about the established method, WLP.\nEach data point on the plot encapsulates the performance\nof a method at distinct decision thresholds. The visual\nexamination of the scatter plot underscores that our method\ndoes not lag behind WLP in terms of TPR and FNR\ncharacteristics across various operational points. This obser-\nvation is crucial in establishing the efficacy of our method,\naligning it favorably with the performance benchmarks set\nby WLP.\nG. EMPERICAL RUNNING SPEED\nThis section evaluates the running speed of DeepTextMark.\nThe experiments concerning running speed are conducted\non an Intel i9-13900k CPU. We measure the time taken\nfor watermark insertion across 1000 unmarked sentences\nand compute the sentence-level average watermark insertion\ntime. Similarly, we time the watermark detection process\non 1000 watermarked sentences and compute the average\ndetection time. The average times for watermark insertion\nand detection, in seconds, are provided in Table 13.\nAs demonstrated, both the insertion and detection pro-\ncesses run quickly, serving as efficient ‘‘add-on’’ components\nfor text source detection. The insertion process incurs a\nhigher overhead compared to the detection process. It is\nimportant to note that these experiments were conducted\nusing only a single core of the CPU. By parallelizing the\nimplementation, the overhead from the insertion process\ncould be significantly reduced, especially on server-level\n40518 VOLUME 12, 2024\nT. Munyer et al.: DeepTextMark: A Deep Learning-Driven Text Watermarking Approach\nmachines, which are typically employed to implement LLMs\nin our target application scenario.\nV. CONCLUSION\nRecently, the use of LLMs has surged significantly in\nboth industry and academia, mainly for text generation\ntasks. Nevertheless, in certain scenarios, it is crucial to\nascertain the source of text—whether it is generated by an\nLLM or crafted by a human. Addressing this requirement,\nwe introduce a deep learning-based watermarking technique\ndesigned for text source identification, which can seamlessly\nintegrate with existing LLM-driven text generators. Our\nproposed method, DeepTextMark, stands out due to its blind,\nrobust, reliable, automatic, and imperceptible characteristics.\nUnlike common direct classification techniques [7] for source\ndetection that demand a substantial amount of characters for\naccurate prediction, our watermarking technique enables both\nwatermark insertion and detection at the sentence level. Our\nfindings demonstrate that with the insertion of watermarks,\nthe accuracy of our detection classifier can approach\nnear-perfection with merely a small set of sentences. Given\nthat the watermark is embedded in each sentence individually,\nthe robustness and reliability of the watermark enhance with\nan increasing number of sentences. The core advantages of\nour work include: an ‘‘add-on’’ text watermarking method\nfacilitating the detection of generated text without requiring\naccess to the LLMs’ generation phase; an automatic and\nimperceptible method for watermark insertion; and a robust,\nhigh-accuracy, deep learning-based text watermark detection\nmethodology.\nWhile DeepTextMark introduces a significant advance-\nment in text watermarking using deep learning, we recognize\na few areas where future enhancements could be beneficial.\nFirst, the effectiveness of DeepTextMark is closely tied to the\nrepresentativeness of the training data. Efforts to diversify this\ndata could further improve its applicability across various text\nstyles and languages. Second, as DeepTextMark functions in\na ‘plug-in’ manner, its utility is contingent on the initial water-\nmarking of the generated text. Without pre-watermarking,\ndetection capabilities are limited, pointing to a dependency\nthat may affect its applicability in certain scenarios. Lastly,\nwhile the method currently shows promising results in\nwatermarking texts of standard lengths, we are exploring\nways to adapt it more effectively for very short or stylistically\ndiverse texts. These limitations represent opportunities for\nongoing research and underscore the potential for continuous\nimprovement in the field of AI-driven text watermarking.\nIn conclusion, our study has successfully introduced Deep-\nTextMark, a novel deep learning-driven approach for text\nwatermarking, offering a robust solution for distinguishing\nbetween human-authored texts and those generated by large\nlanguage models. As we look toward the future, several\npromising directions can further enhance and expand the\nutility of our approach. We envision enhancing the robustness\nof DeepTextMark against more advanced text manipulation\ntechniques, especially those using AI-based rewriting tools,\nto maintain its effectiveness in increasingly sophisticated\ndigital environments. Moreover, exploring scalability to\nmanage larger and more diverse datasets will be crucial\nin adapting our method for big data applications. Another\nsignificant direction involves extending the compatibility\nof DeepTextMark with various large language models,\nbroadening its applicability across different AI-generated\ntext scenarios. Developing real-time applications, such as\ncontent management system plugins, will also be pivotal in\ndynamically detecting and managing AI-generated content.\nLastly, we acknowledge the importance of addressing the\nethical and legal implications surrounding text watermarking,\nparticularly in terms of privacy and data security in the age of\nAI. This aspect is critical to ensuring that our methodologies\nalign with societal norms and legal standards. As we continue\nto build upon the foundation laid by DeepTextMark, these\nfuture endeavors will undoubtedly contribute to the evolving\nlandscape of text watermarking and AI-generated content\ndetection, reinforcing the importance of authenticity and\nintegrity in digital communications.\nREFERENCES\n[1] (2023). ChatGPT. Accessed: Jul. 10, 2023. [Online]. Available:\nhttps://openai.com/blog/chatgpt\n[2] (2023). New AI Classifier for Indicating AI-Written Text. Accessed: May 2,\n2023. [Online]. Available: https://openai.com/blog/new-ai-classifier-for-\nindicating-ai-written-text\n[3] A. Onan, ‘‘GTR-GA: Harnessing the power of graph-based neural\nnetworks and genetic algorithms for text augmentation,’’ Exp. Syst. Appl.,\nvol. 232, Dec. 2023, Art. no. 120908.\n[4] A. Onan and K. Filiz Balbal, ‘‘Improving Turkish text sentiment classifi-\ncation through task-specific and universal transformations: An ensemble\ndata augmentation approach,’’ IEEE Access, vol. 12, pp. 4413–4458,\n2024.\n[5] A. Onan, ‘‘SRL-ACO: A text augmentation framework based on semantic\nrole labeling and ant colony optimization,’’ J. King Saud Univ.-Comput.\nInf. Sci., vol. 35, no. 7, Jul. 2023, Art. no. 101611.\n[6] A. Onan, ‘‘Bidirectional convolutional recurrent neural network archi-\ntecture with group-wise enhancement mechanism for text sentiment\nclassification,’’ J. King Saud Univ.-Comput. Inf. Sci., vol. 34, no. 5,\npp. 2098–2117, May 2022.\n[7] (2023). GPTZero. Accessed: Jul. 10, 2023. [Online]. Available:\nhttps://gptzero.me/\n[8] (2023). Is Gptzero Accurate? Can It Detect Chatgpt? Here’s What\nOur Tests Revealed. Accessed: Jul. 10, 2023. [Online]. Available:\nhttps://nerdschalk.com/is-gptzero-accurate-detect-chat-gpt-detector-\ntested/\n[9] (2023). Testing Gptzero: A Trending CHATGPT Detection Tool.\nAccessed: Jul. 10, 2023. [Online]. Available: https://michaelsheinman.\nmedium.com/testing-gptzero-a-trending-chatgpt-detection-tool-\n3ee14a056543\n[10] H. Fang, Z. Jia, Z. Ma, E.-C. Chang, and W. Zhang, ‘‘PIMoG: An\neffective screen-shooting noise-layer simulation for deep-learning-based\nwatermarking network,’’ in Proc. 30th ACM Int. Conf. Multimedia ,\nOct. 2022, pp. 2267–2275.\n[11] J. Kirchenbauer, J. Geiping, Y . Wen, J. Katz, I. Miers, and T. Goldstein,\n‘‘A watermark for large language models,’’ in Proc. 40th Int. Conf. Mach.\nLearn., vol. 202, A. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato,\nand J. Scarlett, Eds. Jul. 2023, pp. 17061–17084.\n[12] D. Cer, Y . Yang, S. Yi Kong, N. Hua, N. Limtiaco, R. S. John, N. Constant,\nM. Guajardo-Cespedes, S. Yuan, C. Tar, Y .-H. Sung, B. Strope,\nand R. Kurzweil, ‘‘Universal sentence encoder,’’ 2018, arXiv:1803.\n11175.\n[13] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean, ‘‘Distributed\nrepresentations of words and phrases and their compositionality,’’ in Proc.\nAdv. Neural Inf. Process. Syst., vol. 26, 2013, pp. 1–9.\nVOLUME 12, 2024 40519\nT. Munyer et al.: DeepTextMark: A Deep Learning-Driven Text Watermarking Approach\n[14] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nL. Kaiser, and I. Polosukhin, ‘‘Attention is all you need,’’ in Proc. 31st Int.\nConf. Neural Inf. Process. Syst. Red Hook, NY , USA: Curran Associates,\n2017, pp. 6000–6010.\n[15] (2023). How the ChatGPT Watermark Works and Why It Could\nBe Defeated. Accessed: Jul. 10, 2023. [Online]. Available:\nhttps://www.searchenginejournal.com/chatgpt-watermark/475366#close\n[16] E. Mitchell, Y . Lee, A. Khazatsky, C. D. Manning, and C. Finn,\n‘‘DetectGPT: Zero-shot machine-generated text detection using probabil-\nity curvature,’’ in Proc. Int. Conf. Mach. Learn., 2023, pp. 24950–24962.\n[17] V . S. Sadasivan, A. Kumar, S. Balasubramanian, W. Wang, and S. Feizi,\n‘‘Can AI-generated text be reliably detected?’’ 2023, arXiv:2303.11156.\n[18] C. Ou, ‘‘Text watermarking for text document copyright protection,’’\nComput. Sci., vol. 725, Jun. 2003. [Online]. Available: https://www.\ncs.auckland.ac.nz/courses/compsci725s2c/archive/termpapers/725ou.pdf\n[19] N. Shamimi Kamaruddin, A. Kamsin, L. Yee Por, and H. Rahman,\n‘‘A review of text watermarking: Theory, methods, and applications,’’IEEE\nAccess, vol. 6, pp. 8011–8028, 2018.\n[20] S. G. Rizzo, F. Bertini, and D. Montesi, ‘‘Fine-grain watermarking for\nintellectual property protection,’’ EURASIP J. Inf. Secur., vol. 2019, no. 1,\np. 10, Jul. 2019, doi: 10.1186/s13635-019-0094-2.\n[21] K. V . Ghag and K. Shah, ‘‘Comparative analysis of effect of stopwords\nremoval on sentiment classification,’’ in Proc. Int. Conf. Comput.,\nCommun. Control (IC), Sep. 2015, pp. 1–6.\n[22] P. Dyson. Inflect. Accessed: Mar. 10, 2024. [Online]. Available:\nhttps://pypi.org/project/inflect/\n[23] S. Bird, E. Klein, and E. Loper, Natural Language Processing With\nPython. Sebastopol, CA, USA: O’Reilly Media, 2009. [Online]. Available:\nhttps://www.nltk.org/book/\n[24] Databrickslab. (2023). Dolly 15k Dataset. [Online]. Available:\nhttps://github.com/databrickslabs/dolly/tree/master/data\n[25] Hugging Face. Hugging Face Datasets. Accessed: Mar. 10, 2024. [Online].\nAvailable: https://huggingface.co/datasets/c4\n[26] D. P. Kingma and J. Ba, ‘‘Adam: A method for stochastic optimization,’’\nin Proc. 3rd Int. Conf. Learn. Represent., Y . Bengio and Y . LeCun, Eds.\nSan Diego, CA, USA, 2015, pp. 1–15.\n[27] G. A. Miller, ‘‘WordNet: A lexical database for English,’’ Commun. ACM,\nvol. 38, no. 11, pp. 39–41, Nov. 1995, doi: 10.1145/219717.219748.\n[28] W. Wan, J. Wang, Y . Zhang, J. Li, H. Yu, and J. Sun,\n‘‘A comprehensive survey on robust image watermarking,’’\nNeurocomputing, vol. 488, pp. 226–247, Jun. 2022. [Online]. Available:\nhttps://www.sciencedirect.com/science/article/pii/S0925231222002533\nTRAVIS MUNYER received the B.S. degree in\ncomputer science and cybersecurity from the\nUniversity of Nebraska Omaha, in May 2023. He is\ncurrently pursuing the M.S. degree in computer\nscience from Georgia Institute of Technology, with\na specialization in interactive intelligence.\nFrom 2020 to 2023, he was an Undergraduate\nResearcher with the Machine Learning and Com-\nputer Vision Group, University of Nebraska\nOmaha. He is a Software Engineer with a\nwell-known tech company headquartered in Olathe, KS, USA. His research\ninterests include computer vision, natural language processing, image and\ntext watermarking, and applications of machine learning to cybersecurity.\nMr. Munyer was a recipient of the Outstanding Cybersecurity Graduate\nAward from the University of Nebraska Omaha.\nABDULLAH ALL TANVIRis currently pursuing\nthe Ph.D. degree with the University of Nebraska\nOmaha, in the research area of machine learning\nand computer vision.\nPrior to the Ph.D. pursuits, he applied his exper-\ntise as a Machine Learning Engineer in a renowned\nIT company. In this role, he actively contributed\nto the development of innovative solutions and\nleveraging machine learning techniques to solve\ncomplex problems. His practical experience in\nindustry has complemented his academic endeavors, providing him with a\nholistic perspective on the application of theoretical concepts in real-world\nscenarios. His research interests include artificial intelligence, machine\nlearning, computer vision, and natural language processing.\nMr. Tanvir was awarded the GRACA Fund in recognition of his\nexceptional research achievements at the University of Nebraska Omaha.\nARJON DASreceived the B.S. degree in computer\nscience and engineering from Chittagong Univer-\nsity of Engineering and Technology, Bangladesh,\nin 2018, and the M.S. degree in computer science\nfrom the University of Nebraska Omaha, Omaha,\nNE, USA, in 2023.\nFrom 2021 to 2023, he was a Research Assistant\nwith the RNA Laboratory, University of Nebraska\nOmaha. His research interests include computer\nvision, self-supervised learning, and image and\ntext watermarking.\nXIN ZHONG received the Ph.D. degree from\nNew Jersey Institute of Technology, Newark, NJ,\nUSA, in 2018. He is currently an Assistant Pro-\nfessor with the Department of Computer Science,\nUniversity of Nebraska Omaha. His research inter-\nests include digital image processing and analysis,\ncomputer vision, pattern recognition, computa-\ntional intelligence, machine learning, deep learn-\ning, and image watermarking.\n40520 VOLUME 12, 2024",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8159533739089966
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6629794836044312
    },
    {
      "name": "Natural language processing",
      "score": 0.607322096824646
    },
    {
      "name": "Digital watermarking",
      "score": 0.6053924560546875
    },
    {
      "name": "Deep learning",
      "score": 0.4954797029495239
    },
    {
      "name": "Language model",
      "score": 0.4507286250591278
    },
    {
      "name": "Language identification",
      "score": 0.41346535086631775
    },
    {
      "name": "Natural language",
      "score": 0.2639005184173584
    },
    {
      "name": "Image (mathematics)",
      "score": 0.0901285707950592
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I122266389",
      "name": "University of Nebraska at Omaha",
      "country": "US"
    }
  ]
}