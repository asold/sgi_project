{
  "title": "Exploring the possibilities and limitations of customized large language model to support and improve cervical cancer screening",
  "url": "https://openalex.org/W4411848621",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5094236304",
      "name": "Viola Angyal",
      "affiliations": [
        "Semmelweis University"
      ]
    },
    {
      "id": "https://openalex.org/A5095821065",
      "name": "Ádám Bertalan",
      "affiliations": [
        "Semmelweis University"
      ]
    },
    {
      "id": "https://openalex.org/A5094236303",
      "name": "Péter Domján",
      "affiliations": [
        "Semmelweis University"
      ]
    },
    {
      "id": "https://openalex.org/A5062802031",
      "name": "Elek Dinya",
      "affiliations": [
        "Semmelweis University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4319777976",
    "https://openalex.org/W4387394602",
    "https://openalex.org/W4391069573",
    "https://openalex.org/W4402050919",
    "https://openalex.org/W4390300209",
    "https://openalex.org/W4394858800",
    "https://openalex.org/W4377091487",
    "https://openalex.org/W4387412164",
    "https://openalex.org/W4388502894",
    "https://openalex.org/W4362521774",
    "https://openalex.org/W4385667171",
    "https://openalex.org/W4323050332",
    "https://openalex.org/W4319341091",
    "https://openalex.org/W4388370035",
    "https://openalex.org/W4386867830",
    "https://openalex.org/W4402407635",
    "https://openalex.org/W4393193944",
    "https://openalex.org/W4379598302",
    "https://openalex.org/W4280540868",
    "https://openalex.org/W4311836156",
    "https://openalex.org/W4306742418",
    "https://openalex.org/W2929198708",
    "https://openalex.org/W4390918905",
    "https://openalex.org/W3118080279",
    "https://openalex.org/W3045996770",
    "https://openalex.org/W4285492447",
    "https://openalex.org/W4312220843",
    "https://openalex.org/W3009656456",
    "https://openalex.org/W4387965813",
    "https://openalex.org/W4292482499",
    "https://openalex.org/W2000734655",
    "https://openalex.org/W4383104680",
    "https://openalex.org/W4323971802",
    "https://openalex.org/W2047076785",
    "https://openalex.org/W2027980838",
    "https://openalex.org/W4367052098",
    "https://openalex.org/W4288191513",
    "https://openalex.org/W4401730835",
    "https://openalex.org/W4309702579",
    "https://openalex.org/W3120759169",
    "https://openalex.org/W1866291412",
    "https://openalex.org/W2144701752",
    "https://openalex.org/W2001549555",
    "https://openalex.org/W4321496193",
    "https://openalex.org/W4213420057",
    "https://openalex.org/W4396834505",
    "https://openalex.org/W4220922406",
    "https://openalex.org/W4408750876",
    "https://openalex.org/W4403880728",
    "https://openalex.org/W4409919018",
    "https://openalex.org/W4401715493",
    "https://openalex.org/W4405281710",
    "https://openalex.org/W4321748146",
    "https://openalex.org/W3200742808",
    "https://openalex.org/W3028484854",
    "https://openalex.org/W4407135263",
    "https://openalex.org/W4403982217",
    "https://openalex.org/W4388014051",
    "https://openalex.org/W4399984863",
    "https://openalex.org/W4366989525"
  ],
  "abstract": null,
  "full_text": "RESEARCH Open Access\n© The Author(s) 2025. Open Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, \nsharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and \nthe source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included \nin the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a copy of this licence, visit  h t t p  : / /  c r e a  t i  v e c  o m m  o n s .  o r  g / l i c e n s e s / b y / 4 . 0 /.\nAngyal et al. BMC Medical Informatics and Decision Making          (2025) 25:242 \nhttps://doi.org/10.1186/s12911-025-03088-3\nBMC Medical Informatics \nand Decision Making\n*Correspondence:\nViola Angyal\nangyal.viola@phd.semmelweis.hu\nFull list of author information is available at the end of the article\nAbstract\nBackground The rapid advancement of artificial intelligence, driven by Generative Pre-trained Transformers (GPT), \nhas transformed natural language processing. Prompt engineering plays a key role in guiding model outputs \neffectively. Our primary objective was to explore the possibilities and limitations of a custom GPT, developed via \nprompt engineering, as a patient education tool, which delivers publicly available information through a user-friendly \ndesign that facilitates more effective access to cervical cancer screening knowledge.\nMethod The system was developed using the OpenAI GPT-4 model and Python programming language, with the \ninterface built on Streamlit for cloud-based accessibility and testing. It initially presented questions to testers for \npreliminary assessment. For cervical cancer-related information, we referenced medical guidelines. Iterative testing \noptimized the prompts for quality and relevance; techniques like context provision, question chaining, and prompt-\nbased constraints were used. Human-in-the-loop and two independent medical doctor evaluations were employed. \nAdditionally, system performance metrics were measured.\nResult The web application was tested 115 times over a three-week period in 2024, with 87 female (76%) and 28 \nmale (24%) participants. A total of 112 users completed the user experience questionnaire. Statistical analysis showed \na significant association between age and perceived personalization (p = 0.047) and between gender and system \ncustomization (p = 0.037). Younger participants reported higher engagement, though not significantly. Females \nvalued guidance on screening schedules and early detection, while males highlighted the usefulness of information \nregarding HPV vaccination and its role in preventing HPV-related cancers. Independent evaluations by medical \ndoctors demonstrated consistent assessments of the system’s responses in terms of accuracy, clarity, and usefulness.\nDiscussion While the system demonstrates potential to enhance public health awareness and promote preventive \nbehaviors, encouraging individuals to seek information on cervical cancer screening and HPV vaccination, its \nconversational capabilities remain constrained by the inherent limitations of current language model technology.\nExploring the possibilities and limitations \nof customized large language model \nto support and improve cervical cancer \nscreening\nViola Angyal1*, Ádám Bertalan1, Péter Domján2 and Elek Dinya1\nPage 2 of 16\nAngyal et al. BMC Medical Informatics and Decision Making           (2025) 25:242 \nBackground\nThe rapid advancement of artificial intelligence (AI) \nhas led to significant breakthroughs in natural language \nprocessing (NLP), with transformer-based models such \nas Generative Pre-trained Transformers (GPT) at the \nforefront [ 1–3]. GPTs have evolved from generalized \nlanguage models designed for various tasks into more \nspecialized models known as custom GPTs. These mod -\nels are tailored to meet specific needs across various \ndomains, including healthcare and other industries. The \nproliferation of custom GPTs is transforming how organi-\nzations harness AI, enabling them to leverage the power \nof large language models (LLMs) while fine-tuning them \nto address their unique challenges and data requirements \n[4–6]. Custom GPTs, distinguished from their general -\nized counterparts by their domain-specific training and \ndeployment, offer several advantages [ 7–11]. They can \nimprove task performance by reducing irrelevant infor -\nmation processing, enhancing accuracy, and delivering \noutputs more aligned with specific contexts or industry \nnorms, such as in healthcare prevention [12–14].\nPrompt engineering techniques are one option for cre -\nating custom GPT models to disseminate information on \nspecific topics effectively. It represents a less resource-\nintensive method of customizing GPTs, focusing on \nrefining input prompts to guide the model’s responses \nwithout further training [15, 16]. This approach leverages \nthe existing capabilities of a general LLM by carefully \ncrafting the prompts that are fed into the model, enabling \nit to deliver domain-relevant outputs with minimal \ncomputational overhead [ 17]. In this method, domain-\nspecific knowledge was encoded into the prompts them -\nselves. Through iterative testing, the prompts can be \noptimized to improve the quality and relevance of the \nresponses. Techniques such as context provision, ques -\ntion chaining, and prompt-based constraints can be \nemployed to guide the model’s output toward desired \noutcomes [18]. Zero-shot and few-shot learning methods \nare essential in prompt engineering for LLMs, enabling \ntask performance without the need for specific train -\ning data, particularly when labeled data is scarce. Zero-\nshot learning guides the model using a single prompt \nwithout examples, optimized through techniques like \nexplicit instructions or structured templates. Approaches \nsuch as “chain-of-thought” prompting enhance model \naccuracy by promoting step-by-step reasoning in zero-\nshot scenarios. In contrast, few-shot learning incorpo -\nrates a small number of task-specific examples within \nthe prompt, helping the model recognize patterns and \nimprove responses for complex tasks [ 19]. Coherence, \nrelevance, and domain-specific accuracy can be used to \ncompare the results across different prompts. A human-\nin-the-loop (HILT) evaluation process can also be con -\nducted to assess the quality of the system’s responses, as \nwell as different questionnaires can be used to evaluate \nuser experience [20–25].\nOnce a system is developed, the custom GPT can be \nintegrated into a cloud-based interface, such as Streamlit, \nto provide users with seamless access to its capabilities. \nStreamlit’s cloud-based platform allows for easy deploy -\nment, enabling real-time interaction and scalability, \nwhile facilitating a user-friendly experience for access -\ning tailored information generated by the custom GPT. \nStreamlit is an open-source Python framework designed \nto simplify the development and deployment of machine \nlearning models and data-driven applications. It allows \ndevelopers to create intuitive and interactive web applica-\ntions with minimal coding effort. When integrated with \na cloud-based infrastructure, Streamlit enables real-time \naccess to custom GPT models, allowing users to interact \nwith the model via a web browser without needing spe -\ncialized software. Streamlit supports a wide range of fea -\ntures, including dynamic widgets, interactive charts, and \nreal-time updates, which enhance user experience.\nCervical cancer screening can be categorized as sec -\nondary prevention, and this is one of the earliest rec -\nommended screening tests, which is recommended by \nthe American Cancer Society and many other guide -\nlines, including the WHO recommendation [ 26–28]. By \nenabling early detection of precancerous changes and \ntimely intervention, it significantly reduces the inci -\ndence and mortality associated with cervical cancer \n[29]. This screening test saves lives and is recognized as \none of the most essential and widely implemented pre -\nventive healthcare measures globally [ 30–35]. Despite \nthe proven effectiveness of cervical cancer screening in \nreducing incidence and mortality, significant disparities \npersist across different countries and population groups. \nLow- and middle-income countries (LMICs) face major \nchallenges due to limited healthcare infrastructure, while \nConclusions Although custom GPTs can not substitute a healthcare consultations, these tools can streamline \nworkflows, expedite information access, and support personalized care. Further research should focus on conducting \nwell-designed randomized controlled trials to establish definitive conclusions regarding its impact and reliability.\nClinical trial number Not applicable.\nKeywords Custom GPT, Artificial intelligence, Cervical cancer, Prevention, Prompt engineering, Natural language \nprocessing\nPage 3 of 16\nAngyal et al. BMC Medical Informatics and Decision Making           (2025) 25:242 \neven high-income countries struggle with inequities \nin screening access among marginalized communities, \nimmigrants, and individuals with low socioeconomic \nstatus. Language barriers, financial constraints, mistrust \nin healthcare systems, and inadequate referral pathways \ncontribute to lower screening uptake and delayed diagno-\nses, ultimately reducing the effectiveness of early detec -\ntion efforts. Cultural beliefs, stigma, and geographic \nbarriers further exacerbate these disparities, preventing \nmany individuals from accessing timely screening and fol-\nlow-up care. To bridge this gap, innovative multi-faceted \napproaches are needed, including the integration of digi -\ntal health solutions. Custom GPT-based conversational \nagents can enhance personalized awareness and patient \neducation, addressing both informational and emotional \nbarriers. These AI-driven tools can provide women with \naccessible information on screening opportunities and \nrisk factors while also educating men on human papil -\nlomavirus (HPV) transmission and the benefits of vac -\ncination. HPV vaccination plays a crucial role in cervical \ncancer prevention by protecting against the high-risk \nstrains of HPV that are responsible for the majority of \ncervical cancer cases, significantly reducing the incidence \nof this disease [ 36–38]. By improving health literacy and \nengagement, custom GPTs have the potential to increase \nscreening participation and contribute to more equitable \ncervical cancer prevention efforts. A further advantage \nof cervical cancer screening tests is their applicability to \nyounger populations, who are generally more receptive \nto and engaged with digital healthcare solutions, such as \ninternet-based platforms and AI-driven language models \n[39–41]. This screening test is recommended to begin at \nthe age of 30, while certain guidelines suggest initiation \neven earlier, from 25  years old [ 42]. This demographic’s \nfamiliarity with technology may enhance the uptake and \nacceptance of such innovations in healthcare. Based on \nthese advantages, we selected the topic of cervical can -\ncer prevention to develop a custom GPT model aimed at \nimproving patient education and preventive measures. \nThe goal was to enhance the dissemination of informa -\ntion, guiding patients on what actions they should take or \nconsider in relation to cervical cancer screening and pre -\nvention strategies. Even though this tool cannot replace \nconsultations with healthcare professionals, it could \nserve as a complement to traditional prevention pro -\ncesses [43, 44].\nThis paper explores the possibilities and limitations of \ncreating a custom GPT, developed via prompt engineer -\ning, as a patient education tool, which delivers publicly \navailable information through a user-friendly design that \nfacilitates more effective access to cervical cancer screen -\ning knowledge. The objective of this study was to inves -\ntigate whether a customized GPT-based model could \nenhance access to relevant cervical cancer prevention \ninformation by delivering personalized advice tailored \nto individual user needs. Our hypothesis posited that \na custom GPT model enhances the accessibility, com -\nprehensibility, and adherence to cervical cancer guide -\nlines, thereby improving patient education and assisting \npatients in accessing specific information. The system \nwas designed to generate empathetic and supportive \nresponses, fostering adherence to cervical cancer screen -\ning protocols and promoting awareness of HPV vaccina -\ntion and prevention strategies. A HILT evaluation was \nemployed to capture an overview of patient needs and to \nestablish a clear direction for future development. Addi -\ntionally, two independent medical doctors evaluated the \nsystem’s responses for frequently asked questions.\nMethods\nSystem architecture and components\nInitial question flow\nMedical guidelines and recommendations related to cer -\nvical cancer, including HPV vaccination and prevention, \nwere gathered to develop prompts and a question flow for \nour web application. The guidelines processed included \nthose from the American Cancer Society and WHO for \ncervical cancer screening and treatment of pre-cancer -\nous lesions, as well as relevant scientific publications. \nAdditionally, two Hungarian guidelines—the Hungarian \nMinistry of Health’s Professional Protocol and recom -\nmendations from the Hungarian National Public Health \nand Pharmaceutical Center—were incorporated, as the \nsystem was tested in Hungary [ 26–28, 45–49]. Draw -\ning from the literature and the feedback received during \nthe drafting process, we developed a question flow that \nenables the system to present prompted questions for an \nanonymous preliminary assessment. The final param -\neters, assessed through questions, are shown below \n(Fig.  1). The survey questions initially asked by the sys -\ntem were developed specifically for our own custom GPT \n(Supplementary 1). Participants were informed about the \npurpose of the research and the use of their responses via \ninformed consent. The completion of the questionnaire, \nwhich was anonymous and voluntary, implied their con -\nsent. Respondents were assured of their confidentiality, \nand participation was restricted to individuals who were \nat least 18 years old.\nThe system was designed in accordance with data mini-\nmization principles. It did not store any data, tailored \nresponses based on the patient’s gender and age, divid -\ning users into three groups: males (Male), females under \n25 (Female < 25), and females over 25 (Female > 25), as per \nHungarian screening guidelines. This allowed the system \nto provide personalized, context-specific information, \nalong with emotional and informational support, encour-\naging users to ask further questions and take appropriate \nnext steps in cervical cancer prevention.\nPage 4 of 16\nAngyal et al. BMC Medical Informatics and Decision Making           (2025) 25:242 \nIntegration of OpenAI’s GPT-4 API\nThe system was developed using OpenAI’s (San Fran -\ncisco, CA, USA) GPT-4 model and Python programming \nlanguage. We utilized OpenAI’s Application Program -\nming Interface (API) for the GPT integration [ 50]. On \nthe backend, the OpenAI API facilitated communication \nwith OpenAI’s language models, enabling the system to \nprocess user inputs and generate appropriate responses. \nTo integrate OpenAI’s API into the web application, an \nAPI key was obtained from the OpenAI API dashboard \nfollowing user registration. Depending on the technology \nstack, the appropriate OpenAI library must be installed \nin the application’s Python environment. Since Python \nwas used in our system, the integration was implemented \nusing the OpenAI Python library, installed via pip install \nopenai. To interact with OpenAI’s models, such as GPT-\n4, we used code in which our API key is assigned to the \nOpenAI object’s api_key argument (Fig. 2).\nUser interface\nThe user interface (UI) was developed using Streamlit, \nproviding an interactive platform where users can input \nqueries and receive responses efficiently. Streamlit is spe-\ncifically designed for building web-based user interfaces \nusing only Python code. To leverage its functionality, the \nstreamlit library must be installed and imported into the \napplication’s Python environment ( import streamlit as \nst.). We opted for its cloud-based deployment feature, \nFig. 2 OpenAI GPT-4 model API integration into the system\n \nFig. 1 Question flow\n \nPage 5 of 16\nAngyal et al. BMC Medical Informatics and Decision Making           (2025) 25:242 \nensuring broad accessibility and sufficient computational \nresources for the application. This approach enabled \nremote user access and large-scale usability testing.\nPrompt engineering\nDuring the prompt engineering process, we developed \ntext-based instructions to optimize the LLM for generat -\ning more accurate and relevant outputs concerning cer -\nvical cancer prevention, and after every iteration smaller \ngroup of the developers (3–5 people) tested the outputs. \nThe prompts were designed to provide structured guid -\nance, regulating and refining the model’s responses. This \napproach ensures that the LLM remains contextually \naligned with the intended informational goals, enhanc -\ning the precision and reliability of the generated con -\ntent. Domain-specific prompts were refined iteratively \nto optimize the model’s accuracy and relevance. System, \ninstructive, and contextual prompts were applied, with \ncontext provision used to embed cervical cancer screen -\ning information directly into the prompts. During the \ninitial phase, the LLM’s task was defined via an initial \nprompt, a predefined instruction embedded in the code \nto guide response generation. This prompt establishes the \ncontext and domain, enabling the model to produce rel -\nevant outputs. The prompt given was: „ You are a health -\ncare assistant providing information on cervical cancer \nscreening” . We employed the zero-shot learning mode, \nwhich involves using simple instructions as prompts \nwithout providing any examples (Fig.  3). This approach \neffectively elicits the expected responses from the LLM. \nThe methodology aims to leverage the cognitive patterns \ndeveloped by the LLM during its pre-training phase, \nenhancing its ability to generalize and produce accurate \noutputs in novel contexts. By utilizing zero-shot tech -\nniques, we optimized the model’s performance across \nvarious tasks, particularly in scenarios where labeled \ndata is limited, thereby maximizing the model’s utility in \ndiverse applications.\nThe number of iterations performed in prompt opti -\nmization depends on the complexity of the task, user \nfeedback, and the initial performance of the model. In \nthe case of the AI-based custom GPT for the cervical \ncancer screening web application, the optimization pro -\ncess involved approximately 3–7 iterations in case of each \nprompt before reaching an optimal prompt structure \n(Fig. 4).\nQuestion chaining guided the model through a logi -\ncal series of queries, covering screening guidelines and \nprevention strategies, while prompt-based constraints \nensured a focus on relevant content. Each iteration \nwas evaluated for coherence and adherence, with con -\ntinuous adjustments made to improve performance. To \nFig. 3 Optimizing prompts with zero-shot technique\n \nPage 6 of 16\nAngyal et al. BMC Medical Informatics and Decision Making           (2025) 25:242 \nFig. 4 Example for the iteration process\n \nPage 7 of 16\nAngyal et al. BMC Medical Informatics and Decision Making           (2025) 25:242 \nfacilitate transparency, both the publicly available link to \nthe GitHub repository for the system and the full list of \napplied prompts are included in Supplementary 2.\nVisual elements\nAdditionally, external resources, including image assets, \nwere incorporated to enhance user engagement. Visual \nelements such as banners and logos were utilized to \nimprove the interface’s accessibility and usability.\nUser experience questionnaire\nParticipants tested the web application by interacting \nwith the custom GPT model for cervical cancer screen -\ning. Afterward, they completed an anonymous online \nsurvey with 10 questions. The questionnaire was spe -\ncifically designed for the web application developed in \nthis study. During the development phase, we reviewed \nestablished user experience questionnaires, such as the \nChatbot Usability Questionnaire (CUQ) [ 20] and the \nUser Experience Questionnaire (UEQ), to inform its \ndesign. However, to obtain more detailed data relevant \nto the specific requirements of our web application and \nsupport future development, the questions were tai -\nlored accordingly. A pre-test was conducted with a \ngroup of 4 researchers from the study team to evaluate \nthe clarity, relevance, and effectiveness of the question -\nnaire. Feedback from this initial assessment was used to \nrefine the questions and ensure they accurately captured \nuser experience and usability aspects specific to the web \napplication. A four-point scaled response format was \nimplemented to systematically capture user feedback. For \nall questions, testers were able to select from four pre -\ndefined answers, which included options ranging from \nthe most positive to the most negative. To simplify the \nevaluation process, we used a numbered scale: 1 (totally \nagree), 2 (mostly agree), 3 (barely agree), and 4 (do not \nagree). This scale provided a clear visual representation, \nmaking the results easier to interpret and understand. To \nenhance the representativeness of the evaluation data in \nthe tables, we categorized testers into three distinct sub -\ngroups based on age and gender. The first subgroup con -\nsists of female testers under the age of 25 (Female < 25). \nThe second subgroup includes female testers aged 25 and \nabove (Female > 25), while the third subgroup comprises \nall male testers (Male). This stratification allows for a \nmore nuanced analysis of responses across demographic \nvariables. We gathered feedback during 3 weeks in April \n2024. The HITL evaluation collected feedback on rel -\nevance, customization, usability, and accuracy.\nDescriptive statistics were used to characterize the sys -\ntem tester population. Continuous variables, such as age, \nwere summarized using the mean and standard devia -\ntion, while testers were subsequently categorized into age \ngroups, with percentage distributions calculated to estab-\nlish a comprehensive demographic profile.\nTo assess the relationship between age groups and \nuser experience parameters, the Chi-Square test was \nemployed. This test was selected because both age group \nclassifications and questionnaire responses are categori -\ncal variables. It is well-suited for determining whether \nthe observed frequency distributions differ significantly \nfrom those expected under the null hypothesis (p < 0.05), \nthereby directly addressing age-related variations in user \nexperience.\nFurthermore, to evaluate potential differences in user \nexperience parameters concerning gender, the non-para -\nmetric Mann–Whitney U test was applied. This test is \nappropriate for comparing two independent groups, such \nas male and female, especially when the data do not con -\nform to a normal distribution or when the response vari -\nables are ordinal.\nIndependent evaluation of the system’s responses by \nmedical doctors\nTo further evaluate our custom GPT in responding to \ncervical cancer-related inquiries, we conducted an inde -\npendent evaluation by two medical doctors. Thirty of \nthe most frequently asked questions on cervical cancer \nscreening were selected from the websites of the Hun -\ngarian National Public Health Center, PennMedicine, \nand the Mayo Clinic (Supplementary 3). The system was \nasked to provide answers to these questions, and both the \nquestions and the generated responses were distributed \nto two independent medical doctors for evaluation. The \nevaluators were instructed to review each question along \nwith the corresponding response and to rate the system’s \nanswer based on three dimensions:\nAccuracy: Does the answer align with current medical \nknowledge and practice guidelines?\nClarity: Is the answer easily understandable and logi -\ncally structured?\nUsefulness: Does the answer offer practical information \nor value for clinical use or patient education?\nFor each question, the evaluators provided a separate \nscore for each dimension on a scale from 1 (Strongly \nDisagree/Not Accurate), 2 (Disagree), 3 (Agree) and 4 \n(Strongly Agree/Very Accurate). Additionally, the evalu -\nators were invited to include brief written comments to \nelaborate on their ratings if necessary. To assess the inde-\npendent evaluations of the system’s responses by two \nmedical doctors (MD1 and MD2), we employed descrip -\ntive statistics and the Wilcoxon Signed Ranks Test.\nResults\nCharacteristic of the system tester population\nData collection was carried out over a three-week period \nduring which the application was tested by a total of 115 \nPage 8 of 16\nAngyal et al. BMC Medical Informatics and Decision Making           (2025) 25:242 \ntesters (87 female (76%), 28 male (24%). The mean age \nwas 41.2 (±SD 13.5), ranging from 18 to 74  years, and \nthe majority of testers were female. The age distribution \nof the two biological genders is presented in Figs.  5 and \n6. The age distribution among 87 female participants \nrevealed that 16 (18%) were under the age of 25, while 71 \n(82%) were 25 years or older. Among all participants, we \nidentified three subgroups. The first subgroup consisted \nof female testers under 25  years old (Female < 25), the \nsecond subgroup included female testers over 25  years \nold (Female > 25), and the third subgroup comprised male \ntesters (Male).\nIn each subgroup, the majority of testers reported \nbeing sexually active, yet only 46.15% in the Female < 25 \nsubgroup and 50% in the Female > 25 subgroup reported \nusing protection during sexual activity (Table  1). These \nfindings highlight potential risk factors for sexually trans-\nmitted infections, including HPV, which is directly linked \nto cervical cancer risk.\nBased on participant responses, only 10.81% of females \nover 25 and 10.71% of males reported being HPV vac -\ncinated. These findings highlight the need for targeted \nefforts to improve vaccination rates, particularly among \nmales, who are often less engaged in HPV prevention \nstrategies. In contrast, 69.23% of females under 25 years \nold reported being vaccinated, likely due to government \nfinancial support, as HPV vaccination has been provided \nfree of charge since 2014 for 12-year-old children in 7th \ngrade in Hungary. The introduction of new government \nfinancial support has led to a notable increase in HPV \nvaccination rates among young women, as reflected in \nthe responses from our application testers.\nRegarding risk factors and screening history among \nfemale participants, 46.15% reported at least one recog -\nnized risk factor for cervical cancer in the Female < 25 \nsubgroup, and 21.62% in the Female > 25 subgroup, such \nas smoking. Importantly, 97.3% of females aged 25 and \nolder reported having undergone cervical cancer screen -\ning at least once in their lives, with 77.03% having had a \nscreening within the past three years. These screening \nTable 1 Characteristic of the system tester population\nn Parameters TRUE FALSE\nn % n %\nFemale < 25 13 Sexually active 11 84.62% 2 15.38%\nUse protection during sexual activity 6 46.15% 5 38.46%\nRisk factor 6 46.15% 7 53.85%\nHPV vaccinated 9 69.23% 4 30.77%\nFemale > 25 74 Sexually active 60 81.08% 14 18.92%\nUse protection during sexual activity 37 50.00% 23 31.08%\nRisk factor 16 21.62% 58 78.38%\nHPV vaccinated 8 10.81% 66 89.19%\nFamily history of occurrence 20 27.03% 54 72.97%\nScreened 72 97.30% 2 2.70%\nScreened within the last 3 years 57 77.03% 17 22.97%\nExperience abnormal symptoms 8 10.81% 66 89.19%\nMale 28 Sexually active 24 85.71% 4 14.29%\nHPV vaccinated 3 10.71% 25 89.29%\nFig. 6 Age distribution of system tester population (Female)\n \nFig. 5 Age distribution of system tester population (Male)\n \nPage 9 of 16\nAngyal et al. BMC Medical Informatics and Decision Making           (2025) 25:242 \nrates reflect adherence to current cervical cancer screen -\ning guidelines, although gaps remain in reaching the full \npopulation. The Female > 25 subgroup was asked whether \nthey had a family history of cervical cancer and if they \nhad experienced any abnormal symptoms recently. Only \n27.03% reported being aware of a family history of occur -\nrence, and 10.81% indicated experiencing abnormal \nsymptoms.\nPerformance metrics\nResponse time was measured using the Python module \n(datetime.now), based on 11 tests. In these tests, we mea -\nsured the interval between receiving OpenAI’s response \nand its display on the Streamlit interface. It is impor -\ntant to note that our system was deployed via a Stream -\nlit cloud-based service, meaning that speed metrics are \ninfluenced by internet speed and browser performance \nas well in addition to the underlying model. In general, \nOpenAI’s API responded within 500 milliseconds to \n3  seconds; however, this range varied with factors such \nas query complexity, network bandwidth, and the user’s \nbrowser environment. Our results indicate that the mean \nresponse time increased with each interaction, likely \ndue to the system reprocessing the entire context from \nthe beginning (Fig.  7). No API failures, timeouts, or user \ninput errors were observed during testing. Regarding \nscalability, leveraging Streamlit and OpenAI’s API inher -\nently supports flexible scaling, provided that API rate \nlimits and cloud resources are effectively managed.\nResults of the user experience questionnaire\nAmong the 115 web application testers, 112 participants \ncompleted the feedback form, providing data critical to \nevaluating the application’s performance and overall user \nexperience (Table  2). Initial impressions were largely \npositive, with 81.25% of participants indicating a posi -\ntive experience (“mostly agree”), and 15.18% expressing a \nhighly favorable impression (“totally agree”). In contrast, \n3.57% reported a more negative first impression (“barely \nagree”). These findings underscore the importance of \nenhancing positive user engagement while identifying \nfactors that may lead to negative initial responses.\nIn terms of system customization, 55.36% of partici -\npants mostly agreed, and 33.93% barely agreed, that the \napplication was tailored to individual needs. The user \ninterface was regarded as entirely intuitive by 51.79% of \ntesters, who felt it was clear without requiring pretraining \nor guidance, while an additional 38.39% mostly agreed it \nwas accessible. However, 8.93% only barely agreed with \nit, and 0.89% did not find the interface straightforward. \nThese findings suggest a need for continued optimiza -\ntion in system customization to better meet individual \nrequirements while ensuring the interface remains user-\nfriendly and accessible. Most participants found the sys -\ntem easy to navigate, with 40.18% totally agreeing and \n54.45% mostly agreeing that it was simple to use; 4.46% \nonly barely agreed, and 0.89% did not find it user-friendly. \nThese findings emphasize the importance of maintain -\ning ease of navigation to support a seamless user experi -\nence for diverse users. Feedback on interactivity revealed \nthat 12.5% of respondents totally agreed the system was \nengaging, 70.54% mostly agreed, 16.07% barely agreed, \nand 0.89% disagreed. These findings highlight the value \nTable 2 User experience questionnaire responses\n1 2 3 4\ntotally agree mostly agree barely agree do not agree\nn % n % n % n %\nPositive first impression 17 15.18% 91 81.25% 4 3.57% 0 0.00%\nCustomization of the system 9 8.04% 62 55.36% 38 33.93% 3 2.68%\nClarity of the interface usability 58 51.79% 43 38.39% 10 8.93% 1 0.89%\nSimplicity of system usage 45 40.18% 61 54.46% 5 4.46% 1 0.89%\nSystem interactivity level 14 12.50% 79 70.54% 18 16.07% 1 0.89%\nRelevance of responses 25 22.32% 83 74.11% 4 3.57% 0 0.00%\nPersonalization of advice 14 12.50% 70 62.50% 15 13.39% 13 11.61%\nAdaptability to personal needs 25 22.32% 71 63.39% 13 11.61% 3 2.68%\nFuture reuse 7 6.25% 41 36.61% 47 41.96% 17 15.18%\nRecommend to others 23 20.54% 71 63.39% 14 12.50% 4 3.57%\nFig. 7 System response time\n \nPage 10 of 16\nAngyal et al. BMC Medical Informatics and Decision Making           (2025) 25:242 \nof increasing the interactive elements of the system to \nenhance user engagement and satisfaction.\nThe relevance of system-generated responses was rated \nhighly, with 22.32% describing responses as entirely rel -\nevant and 74.11% as mostly relevant; only 3.57% barely \nagreed with this, and none found responses irrelevant. \nThese findings underscore the need to maintain a high \nstandard for response relevance to ensure the system \nmeets user’s expectations for meaningful interaction. \nParticipants also assessed personalization, with 12.4% \ntotally agreeing that the system’s answers were custom -\nized to their specific queries, while 62.5% mostly agreed, \n13.39% barely agreed, and 11.62% felt the responses \nwere too general. On adaptability to user needs, 22.32% \nindicated the system completely adjusted to individual \nrequirements, 63.39% mostly agreed, 11.61% barely \nagreed, and 2.68% found it unresponsive to personal \nneeds. These findings highlight the need to further refine \nthe system’s capacity for generating personalized content \nwhile maintaining its usability to ensure broad accessibil-\nity and user satisfaction.\nParticipants were also asked whether they would use \nthe system in the future and if they would recommend it \nto others. Only 6.25% would certainly use it again, while \n36.61% mostly agreed, 41.96% barely agreed, and 15.18% \nstated they would not return to the system. In terms of \nrecommendations, 2.54% would definitely suggest the \napplication to others, with 63.39% mostly agreeing, 12.5% \nbarely agreeing, and 3.57% not endorsing it. These find -\nings indicate the importance of improving features that \ncould enhance long-term usability and encourage posi -\ntive user recommendations.\nAnalyzing further the data, we noticed that younger \nparticipants, mean age of under 40  years, generally \nreported a higher level of engagement with the interface, \ndescribing it as more interactive and user-friendly com -\npared to testers over 40  years (Fig.  8). This trend may \nbe attributed to younger individuals’ greater familiarity \nwith digital platforms and their comfort in navigating \nAI-driven tools. In contrast, older users, while still able \nto use the application, often perceived it as less intui -\ntive. The overall user participants mean age, who com -\npleted the user experience questionnaire, was 39.69 years \nold. The tester’s mean age, who found the user interface \nreally interactive, was 37.64, and interactive was 39.22. \nThe tester’s mean age was 42.06, who found the applica -\ntion not too interactive, and 63  years old, who found it \nnot interactive at all. However, testing the results with the \nChi-Square Test, the relationship between age and sys -\ntem interactivity was not significant in the different age \ngroups (p = 0.91). This might highlight the need for user \ninterface adaptations to ensure accessibility and ease of \nuse across different age groups, ensuring that healthcare \ntools such as this custom large language model are effec -\ntive for a broad demographic. However, it is also notable \nthat not only can age influence how interactive a person \nfinds a user interface, but other sociological factors may \nalso have an impact, such as location, education level, \nlocal infrastructure, income, etc., which were not mea -\nsured by our user experience questionnaire.\nRegarding the parameters assessed in the user experi -\nence questionnaire, we identified a statistically significant \nassociation with the Chi-Square Test (p < 0.05) between \nage groups and the perceived personalization of the \nresponses, with a p-value of 0.047 (Table  3). However, no \nsignificant associations were found for the other 9 vari -\nables assessed. Additionally, concerning gender and the \nexamined variables, we observed a significant association \n(p = 0.037) with Mann–Whitney U test between gender \nand the perceived customization of the system. Further -\nmore, an almost significant (p = 0.069) association was \nnoted for the variable “intention for future reuse, ” though \nthe p-value did not reach the conventional threshold for \nstatistical significance (Table 4).\nTable 3 Personalization of advice with Chi-Square Test\nPersonalization of advice\nAge groups N % Mean SD P value\n18–24 22 19.64% 2.18 0.64 0.047\n25–34 21 18.75% 2.25 1.00\n35–44 25 22.32% 2.20 0.83\n45–54 28 25.00% 2.17 0.83\n55 + 16 14.29% 2.55 0.93\nTable 4 Customization of the system and future reuse with \nmann–whitney U test\nGender N Mean SD P value\nCustomization of the system Male 35 2.51 0.66 0.037\nFemale 77 2.22 0.64\nTotal 112\nFuture reuse Male 35 2.86 0.73 0.069\nFemale 77 2.57 0.83\nTotal 112\nFig. 8  Web application interactivity perceived by different age groups \nwith 95% confidence interval\n \nPage 11 of 16\nAngyal et al. BMC Medical Informatics and Decision Making           (2025) 25:242 \nIt is also notable that both male and female testers \nreported that the information provided by the system \nregarding cervical cancer screening was highly relevant \nand informative (Fig.  9). From male testers, 22.9% and \nfrom female testers, 22.1% found the information really \nrelevant, while 68.6% of male testers and 76.6% of female \ntesters found it relevant. Only 8.6% of the male group and \n1.3% of the female group found the information not rel -\nevant, and nobody reported that it was not relevant at all.\nResults of the system’s response evaluation by medical \ndoctors\nFor each evaluation dimension (Accuracy, Clarity, and \nUsefulness), we computed the mean score and standard \ndeviation across all questions. The mean scores were high \nfor both MD1 and MD2 (all > 3.5), and the standard devi-\nations were low, particularly in the Clarity and Usefulness \ndimensions, suggesting a concentrated response distribu-\ntion. Due to the extremely low variability in the ratings, \nwhere the standard deviation was minimal and, in some \ncases, zero, it was not possible to compute a reliable \ncorrelation coefficient. Specifically, the Intraclass Cor -\nrelation Coefficient (ICC) could not be calculated. Con -\nsequently, we employed the Wilcoxon Signed Ranks Test, \nwhich is designed to assess whether the median differ -\nence between two paired sets of observations is statisti -\ncally indistinguishable from zero. For Accuracy, although \nthe p-value was 0.059—very close to the conventional \nsignificance threshold of 0.05—it did not reach statisti -\ncal significance. This indicates that there is insufficient \nevidence to conclude that the Accuracy ratings differ \nbetween MD1 and MD2. Similarly, in the case of Clar -\nity (p = 0.063) and Usefulness (p = 0.317), the differences \nwere not statistically significant. The lack of statistically \nsignificant differences in Accuracy, Clarity, and Useful -\nness indicates that the responses evaluated by MD1 and \nMD2 are essentially equivalent. This alignment supports \nthe conclusion that the evaluations are coherent, with \nboth sets of answers yielding very similar assessments \nand demonstrating consistency in the system’s responses \nacross independent evaluators (Table 5).\nDiscussion\nOur hypothesis posited that a custom GPT model \nenhances the accessibility, comprehensibility, and adher -\nence to cervical cancer guidelines, thereby improving \npatient education and assisting patients in accessing spe -\ncific information. According to our results, both male \nand female participants found the information provided \nby the system to be relevant and informative. Female par-\nticipants particularly valued the guidance on screening \nschedules and the importance of early detection. Male \nparticipants noted the usefulness of the information \nprovided on HPV vaccination and its role in preventing \nHPV-related cancers, a key area of concern given that \nmales are often less engaged in HPV prevention efforts. \nParticipants highlighted the user-friendly interface \nand the empathetic responses generated by the system, \nwhich made the experience more engaging. This feed -\nback is crucial, as it demonstrates the application’s poten-\ntial in supporting public health efforts by encouraging \nTable 5 Descriptive statistics and wilcoxon signed-rank test \nresults for independent evaluations on accuracy, clarity, and \nusefulness\nMean SD Wilcoxon Signed Ranks Test\nP-value\nAccuracy MD_1 3.83 0.38 0.059\nAccuracy MD_2 3.57 0.50\nClarity MD_1 3.80 0.55 0.063\nClarity MD_2 4.00 0\nUsefulness MD_1 3.97 0.18 0.317\nUsefulness MD_2 4 0\nFig. 9 Tester perception of the relevance of information provided by the application on cervical cancer screening\n \nPage 12 of 16\nAngyal et al. BMC Medical Informatics and Decision Making           (2025) 25:242 \nindividuals to engage in preventive measures such as \nscreening and HPV vaccination. We could only identify \na statistically significant association between age groups \nand the perceived personalization of the responses. We \nalso observed a significant association between gender \nand the perceived customization of the system. Further -\nmore, an association was noted for the variable “inten -\ntion for future reuse, ” though the p-value did not reach \nthe conventional threshold for statistical significance. All \nthe other results for other variables were not significant. \nAnother notable finding was the higher level of engage -\nment reported by younger participants. They described \nthe interface as more interactive and user-friendly com -\npared for users over 40 years old. Although the correla -\ntion between age and system interactivity level was not \nstatistically significant, it is essential to explore tools and \ndesign strategies that can enhance the accessibility and \ninteractivity of custom GPT systems. Such observations \nunderscore the importance of considering age-related \npreferences in the design and optimization of digital \nhealth applications. Our current sample primarily com -\nprises participants aged 25–54 in accordance with the \nmost recent World Health Organization (WHO) guid -\nance on cervical cancer prevention and control. Rou -\ntine screening is prioritized for women aged 30–49 and \nremains applicable up to the age of 65. Although screen -\ning can still be important for women over 65, we believe \nthat developing a digital patient education tool about \ncervical cancer screening is most critical for women aged \n25–49, the group that constituted the majority of our \nparticipants. Moreover, younger individuals are gener -\nally more attracted to digital tools, which was a key rea -\nson for selecting cervical cancer screening as the focus \nfor our custom GPT model. In contrast, other screening \ntests, such as mammography and colorectal screening, \ntypically commence later in a patient’s life and are more \nrelevant for older populations. It is also important to note \nthat the study was conducted in Hungary. The generaliz -\nability of the findings to other populations and healthcare \nsystems should be further examined in future studies.\nTo the best of our knowledge, while several AI-based \ntools have been developed for cervical cancer screen -\ning, the majority of these focus on image analysis for \ndiagnostic support [ 51–54]. In contrast, our solution is \nan LLM-based patient education tool designed to pro -\nvide information about cervical cancer and enhance \naccess to publicly available knowledge. We believed that \nthis approach would address a critical gap in healthcare \naccess, as many individuals miss out on potentially life-\nsaving screening tests due to insufficient information.\nIn comparison to other health chatbot tools, it is pri -\nmarily concluded that AI chatbots have proven effective \nin promoting health behavior changes across large and \ndiverse populations, just as shown in our results. Studies \nhave shown that LLMs are capable of generating accu -\nrate, readable, and contextually relevant responses to \npatient queries, making them valuable tools for improv -\ning health literacy and supporting doctor-patient com -\nmunication. Scoping reviews highlight their use in \ncreating patient education materials, simplifying complex \nmedical information, and enhancing accessibility [ 55–\n57]. Specifically in the context of cervical cancer screen -\ning, research has demonstrated that LLMs generally \nprovide responses aligned with established clinical guide-\nlines. They show potential in supporting patient under -\nstanding of screening procedures, risks, and follow-up \ncare [ 58, 59]. However, future research should focus on \nconducting rigorous randomized controlled trials to \ndraw definitive conclusions [60, 61]. The studies generally \nshowed positive or mixed results regarding the effective -\nness, usability, and user satisfaction of the conversational \nagents examined, although qualitative user feedback was \nmore varied, just as in our results. Many of the studies \nhad limitations in quality, highlighting the need for bet -\nter study design and reporting to more accurately assess \nthe agents’ usefulness in healthcare and pinpoint areas \nfor improvement. Future research should also focus on \nevaluating the cost-effectiveness, privacy, and security of \nthese agents [62]. As the clinical use of LLMs grows, ethi-\ncal, regulatory, and patient safety concerns will become \nincreasingly important [63].\nDespite the advantages of creating a custom LLM for \na specific healthcare area, several limitations must be \nconsidered. While it demonstrates potential in pro -\nmoting awareness and encouraging individuals to seek \ninformation about cervical cancer screening and HPV \nvaccination, its conversational capabilities are subject to \nthe inherent limitations of current language model tech -\nnology, specifically in this case, the GPT-4 model. This \nmodel relies on advanced statistical methods to gener -\nate responses based on patterns in data rather than true \ncomprehension or reasoning. Consequently, its ability \nto address user inquiries with complete accuracy and \nnuance may be limited, highlighting the importance of \ncomplementing AI-generated information with profes -\nsional medical advice. Prompt engineering is integral to \nguiding large language models in specialized domains \nsuch as healthcare. However, managing ambiguous user \nqueries remains a key challenge; uncertain or incomplete \ninputs can lead to imprecise responses, underscoring the \nneed for dynamic query refinement and interactive clari -\nfications. Moreover, even when a system relies exclusively \non prompt engineering and is not further fine-tuned, it \ninherits biases or limitations embedded in the model’s \npretraining corpus; these cannot be fully mitigated by \nprompt design alone. Consequently, routine data audits, \nbroader data sources, and structured bias detection strat-\negies are essential, particularly in clinical contexts where \nPage 13 of 16\nAngyal et al. BMC Medical Informatics and Decision Making           (2025) 25:242 \nequity and reliability are paramount. An iterative process \nof prompt refinement, enhanced by user feedback loops, \nensures alignment with evolving medical guidelines and \nreal-world needs.\nAI hallucination refers to the phenomenon wherein \nartificial intelligence systems, particularly LLMs, gener -\nate outputs that are factually inaccurate, logically incon -\nsistent, or fabricated. This phenomenon arises from the \nprobabilistic nature of LLMs, which predict responses \nbased on statistical patterns within training data rather \nthan genuine comprehension. This issue presents signifi -\ncant challenges, particularly in high-stakes domains such \nas healthcare and scientific research, where precision and \nreliability are paramount. However, its performance can \nbe enhanced through various techniques, although this \nrequires extensive testing and continuous refinement. \nThere are many options and approaches to address these \nchallenges [ 64–66]. In our paper, we employed HITL \nevaluation and two independent medical doctors evalu -\nations. Further strategies for bias detection and mitiga -\ntion can be explored in future studies, including gender, \ncultural, and socioeconomic biases, which may affect \nboth the accuracy and fairness of their outputs. Informed \nconsent is another critical ethical consideration. Users \nmust be fully informed about how their data will be \ncollected, stored, and used, as well as the limitations of \nAI-generated recommendations. Clear and accessible \nconsent forms should outline users’ rights, including the \noption to withdraw their data at any time. Additionally, \nusers should be made aware that AI systems are designed \nto assist rather than replace healthcare professionals, \nemphasizing the importance of consulting qualified \nexperts for personalized medical advice.\nThe user experience was evaluated using a question -\nnaire tailored specifically for this study. In this prelimi -\nnary study, our primary goal was to gather early insights \ninto user needs and directions for system refinement, \nto best serve this goal, we employed a brief, customized \nquestionnaire. Although this instrument captured key \nusability metrics, its scope was limited. Future research \nwould benefit from integrating standardized instruments \nsuch as the System Usability Scale (SUS) or the Post-\nStudy System Usability Questionnaire (PSSUQ) to gather \nimmediate post-task usability feedback. These additional \nmeasures may offer a more comprehensive assessment of \nthe system’s performance and user satisfaction.\nThe widespread adoption of custom GPTs in health -\ncare systems also raises new challenges, including ethi -\ncal considerations, security concerns, and the need for \ntransparent governance in their application. The devel -\nopment of such a model requires a significant initial \ninvestment of time, expertise, and resources, including \nprocessing official medical guidelines and even collabora-\ntion with healthcare professionals to ensure accuracy and \nclinical relevance. Ensuring the model’s ability to handle \nthe complexities of medical information across diverse \npatient profiles is another challenge. Ethical concerns \narise around data privacy, security, and the potential for \nmisuse, particularly if patients overly rely on automated \nsystems rather than seeking direct care from healthcare \nprofessionals. Ensuring robust data privacy and security \nmeasures is essential when developing AI-driven sys -\ntems, particularly in healthcare. A potential solution is \nthe implementation of data minimization techniques, \nwhich limit the collection and processing of personal \ninformation to only what is strictly necessary. In this \nstudy, the system was designed to respond to general \nquestions regarding cervical cancer screening, tailored \nto the tester’s individual needs, while ensuring that no \nsensitive or identifiable data was collected or used. This \napproach enhances privacy by reducing the risk of unau -\nthorized access and ensures compliance with data pro -\ntection regulations.\nConclusion\nIn conclusion, we successfully developed a custom GPT \nmodel focused on cervical cancer screening by process -\ning medical guidelines and utilizing prompt engineering \ntechniques, the OpenAI GPT-4 model, and Python pro -\ngramming language. The system was integrated into the \nStreamlit framework, allowing for seamless deployment \nand beta testing with 115 participants during a three-\nweek period. A total of 112 testers filled out the user \nexperience questionnaire and provided feedback on vari -\nous aspects of the system. Additionally, two independent \nmedical doctors evaluated the answers for the 30 most \nfrequently asked questions.\nThis study highlights the potential of AI-driven sys -\ntems to enhance cervical cancer screening coverage and \nmitigate healthcare resource shortages, particularly in \nresource-constrained settings. By delivering interactive, \npersonalized health information, tailored to individual \nneeds, such systems can improve public awareness and \nencourage greater participation in preventive healthcare. \nThe effectiveness of such an AI-driven approach lies in its \nability to simplify complex medical information, making \nit both accessible and actionable for a diverse population. \nMoreover, the system’s capability to generate empathetic \nand motivational responses—simulating a conversation \nwith a supportive and knowledgeable entity—fosters user \nengagement and trust. These findings underscore the \nbroader applicability of AI-powered conversational mod -\nels in advancing health communication and promoting \nevidence-based preventive healthcare strategies.\nAccording to our results and a comparison with find -\nings in the literature, we concluded that while AI will \nnever fully substitute healthcare professionals, it can \nserve as a valuable complement, enhancing the efficiency \nPage 14 of 16\nAngyal et al. BMC Medical Informatics and Decision Making           (2025) 25:242 \nof healthcare delivery. AI systems can streamline work -\nflows, assist in routine tasks, and provide patients with \nquicker access to information, ultimately improving the \noverall healthcare experience. By alleviating some of the \nadministrative and informational burdens on healthcare \nproviders, AI enables professionals to focus more on crit-\nical decision-making and personalized patient care.\nLong-term user engagement and satisfaction are criti -\ncal for the effectiveness of digital health tools. Future \nwork will investigate strategies such as enhanced per -\nsonalization, user-centered design improvements, and \nthe integration of interactive educational features to pro -\nmote sustained use and increase the likelihood of user \nrecommendations. Future iterations and testing will also \nfocus on broadening the system’s conversational scope to \ninclude critical preventive screening examinations, such \nas those for breast and colorectal cancer.\nAbbreviations\nAPI  Application Programming Interface\nAI  Artificial Intelligence\nGPT  Generative Pre-Trained Transformer\nLLM  Large Language Model\nNLP  Natural Language Processing\nHITL  Human-in-the-Loop\nHPV  Human Papillomavirus\nLMIC  Low- and middle-income countries\nUI  User Interface\nPSSUQ  Post-Study System Usability Questionnaire\nUEQ  User Experience Questionnaire\nCUQ  Chatbot Usability Questionnaire\nSUS  System Usability Scale\nSupplementary Information\nThe online version contains supplementary material available at  h t t p s :   /  / d o  i .  o r  \ng  /  1 0  . 1 1   8 6  / s 1 2  9 1 1 -  0 2 5 - 0  3 0 8 8 - 3.\nSupplementary Material 1\nSupplementary Material 2\nSupplementary Material 3\nAcknowledgements\nWe would like to highlight the contributions of BSc students from the Digital \nHealth Sciences Institute at Semmelweis University in distributing the user \nexperience questionnaire and supporting the development process. We also \nwish to acknowledge our colleagues from the Health Sciences Division for \ntheir valuable advice and constant support throughout the development \nphase and data evaluation.\nAuthor contributions\nAll authors participated in the conception and design of the study. VA \nsupported the user experience questionnaire preparation, gathered \nmedical guidelines for the logic of the web application, participated in the \nweb application development process, performed all statistical analyses, \nand drafted the manuscript. ÁB made available the web application, did \nPython programming, implemented the GPT-4 API and supported the user \nexperience questionnaire preparation. PD advised on the web application \nlogic. ED supervised and advised on all aspects of the study. All authors read \nand approved the final manuscript.\nFunding\nOpen access funding provided by Semmelweis University. Open access \nfunding provided by Semmelweis University. This research was conducted \nwith the institutional support of Semmelweis University, which includes \nPhD scholarships (PD, ÁB and VA) and faculty salary (ED). The research was \nalso supported by the 2024-2.1.2-EKÖP-KDP-2024-00002 university research \nscholarship. Supported by the 2024–2.1.2-EKÖP-KDP-2024-00002 university \nresearch scholarship programme of the ministry for culture and innovation \nfrom the sources of the national research, development and innovation fund\nData availability\nAll data generated or analysed during this study are included in this \npublished article and its supplementary information files. [User_experience_\nquestionaire_data] [Webapplication_data].\nDeclarations\nEthics approval and consent to participate\nAll methods were carried out in accordance with relevant guidelines and \nregulations, including adherence to the principles outlined in the guidelines \nof the World Health Organization (WHO), Ethics and governance of artificial \nintelligence for health: Guidance on large multi-modal models. In accordance \nwith the Hungarian Act CLIV of 1997, §157 “Medical research conducted on \nhumans” , ethical approval was deemed unnecessary. The study tested a web \napplication and its user experience; therefore, no personally identifiable \ninformation or clinical data from the respondents were collected or used. Due \nto that and the below details, it was not submitted to and approved by, a local \nethics committee or institutional review board. Our research is following the \nWorld Medical Association’s Declaration of Helsinki and the requirements of \nall applicable local and international standards. This study included two main \nelements: testing the custom GPT model and measuring the user experience.\nConsent for publication\nNot applicable\nTesting the custom GPT model\nA question flow (Table 1 and Supplementary 1) was applied to beta test the \ncustom GPT model. An informed consent was deemed unnecessary for the \ntesting as it only utilized anonymized, non-sensitive data that adhered to \nthe General Data Protection Regulation (GDPR), including Regulation (EU) \n2016/679 Article 9. It is only aimed to customize the custom GPT model’s \nanswers for individual needs. Participants voluntarily engaged in the process, \nindicating their agreement to use the custom GPT model. An English version \nof the survey is provided as a supplementary file.\nMeasuring the user experience of the custom GPT\nParticipants who tested the custom GPT model had the chance to voluntarily \nand anonymously complete a user experience questionnaire. Informed \nconsent was obtained here, and respondents aged 18 and above were \nincluded. The user experience questionnaire model did not collect any \npersonally identifiable healthcare data as well.\nRelevant guidelines and regulations\n- World Helath Organization Ethics and governance of artificial intelligence for \nhealth: Guidance on large multi-modal models\n- Hungarian Act CLIV of 1997, §157 “Medical research conducted on humans”\n- GDPR, including Regulation (EU) 2016/679 Article 9.\n- World Medical Association’s Declaration of Helsinki\nCompeting interests\nThe authors declare no competing interests.\nAuthor details\n1Semmelweis University Doctoral College, Health Sciences Division, \nInstitute of Digital Health Sciences, Budapest, Hungary\n2Semmelweis University, Doctoral College, Health Sciences Division \nInterdisciplinary Applied Health Sciences Program, Budapest, Hungary\nReceived: 17 November 2024 / Accepted: 23 June 2025\n\nPage 15 of 16\nAngyal et al. BMC Medical Informatics and Decision Making           (2025) 25:242 \nReferences\n1. De Angelis L, et al. ChatGPT and the Rise of Large Language Models: The \nNew AI-driven Infodemic Threat in Public Health. Front. Public Health. \n2023;11:1166120.\n2. Bhargava DC, et al. ChatGPT in medical research: challenging time ahead. \nMed Leg J. 2023;91:223–25.\n3. Li J, et al. ChatGPT in healthcare: a taxonomy and systematic review. Comput \nMethods Programs Biomed. 2024;245:108013.\n4. Liu CL, Ho CT, Wu TC. Custom GPTs enhancing performance and evidence \ncompared with GPT-3.5, GPT-4, and GPT-4o? A study on the emergency \nmedicine specialist examination. Healthcare (Basel). 2024;12(17).\n5. Fisher AD, Fisher G. Evaluating performance of custom GPT in anesthesia \npractice. J Clin Anesth. 2023;93:111371.\n6. Sathe TS, et al. How I GPT It: development of Custom Artificial Intelligence (AI) \nchatbots for surgical education. J Surg Educ. 2024;81:772–75.\n7. Darkhabani M, et al. ChatGPT and autoimmunity - A new weapon in the \nbattlefield of knowledge. Autoimmun Rev. 2023;22:103360.\n8. Sun H, et al. An AI dietitian for type 2 diabetes mellitus management based \non large language and image recognition models: preclinical concept valida-\ntion study. J Med Internet Res. 2023;25:e51300.\n9. Spallek S, et al. Can we use ChatGPT for mental health and substance use \neducation? examining its quality and potential harms. JMIR Med Educ. \n2023;9:e51243.\n10. Haver HL, et al. Appropriateness of breast cancer prevention and screening \nrecommendations provided by ChatGPT. Radiology. 2023;307:e230424.\n11. Zheng Y, et al. Enhancing diabetes self-management and education: a critical \nanalysis of ChatGPT’s role. Ann Biomed Eng. 2023.\n12. Cascella M, et al. Evaluating the feasibility of chatgpt in healthcare: an analysis \nof multiple clinical and research scenarios. J Med Syst. 2023;47:33.\n13. Rao A, et al., Evaluating ChatGPT as an Adjunct for Radiologic Decision-\nMaking. 2023, Cold Spring Harbor Laboratory.\n14. Mondal H, et al. ChatGPT in answering queries related to lifestyle-related \ndiseases and disorders. Cureus. 2023;15:e48296.\n15. Meskó B. Prompt engineering as an important emerging skill for medical \nprofessionals: tutorial. J Med Internet Res. 2023;25:e50638.\n16. Zaghir J, et al. Prompt engineering paradigms for medical applications: scop-\ning review. J Med Internet Res. 2024;26:e60501.\n17. Chen JS, Granet DB. Prompt engineering: helping ChatGPT respond better to \npatients and parents. J Pediatr Ophthalmol Strabismus. 2024;61(2):148–49.\n18. Giray L. Prompt Engineering with ChatGPT: a guide for academic writers. Ann \nBiomed Eng. 2023;51(12):2629–33.\n19. Li Y. A Practical Survey on Zero-shot prompt design for in-context learning. \n2023.\n20. Larbi D, Denecke K, Gabarron E. Usability Testing of a social media chatbot \nfor increasing physical activity behavior. Journal of Personalized Medicine. \n2022;12:828.\n21. Cheah WH, et al. Mobile technology in medicine: development and valida-\ntion of an adapted system usability scale (sus) questionnaire and modified \ntechnology acceptance model (TAM) to evaluate user experience and \nacceptability of a mobile application in MRI safety screening. Indian J Radiol \nImaging. 2023;33:36–45.\n22. Zhu D, et al. User Interface (UI) design and user experience questionnaire \n(UEQ) evaluation of a to-do list mobile application to support day-to-day life \nof older adults. Healthcare (Basel). 2022;10(10).\n23. Zhou L, et al. The mHealth app usability questionnaire (MAUQ): development \nand validation study. JMIR Mhealth Uhealth. 2019;7:e11500.\n24. Holderried F, et al. A generative pretrained transformer (GPT)-powered \nchatbot as a simulated patient to practice history taking: prospective, mixed \nmethods study. JMIR Med Educ. 2024;10:e53961.\n25. Miguel Cruz A, et al. Acceptance, adoption, and usability of information and \ncommunication technologies for people living with dementia and their care \npartners: a systematic review. Disabil Rehabil Assist Technol. 2023;18:443–57.\n26. Fontham ETH, et al. Cervical cancer screening for individuals at average risk: \n2020 guideline update from the american cancer society. CA Cancer J Clin. \n2020;70:321–46.\n27. WHO Guidelines approved by the guidelines review committee, in WHO \nguideline for screening and treatment of cervical pre-cancer lesions for cervi-\ncal cancer prevention: use of mRNA tests for human papillomavirus (HPV) \nWorld Health Organization World Health Organization 2021 Geneva.\n28. Sultanov M, et al. Investigating feasibility of 2021 WHO protocol for cervical \ncancer screening in underscreened populations: pREvention and SCReening \ninnovation project toward elimination of cervical cancer (PRESCRIP-TEC). \nBMC Public Health. 2022;22(1).\n29. WHO Guidelines approved by the guidelines review committee, in WHO \nguideline for screening and treatment of cervical pre-cancer lesions for \ncervical cancer prevention: use of dual-stain cytology to triage women after \na positive test for human papillomavirus (HPV) World Health Organization \nWorld Health Organization 2024 Geneva.\n30. Gavinski K, DiNardo D. Cervical Cancer screening. Med Clin North Am. \n2023;107(2):259–69.\n31. Bhatla N, Singhal S. Primary HPV screening for cervical cancer. best pract res clin \nobstet gynaecol. 2020;65:98–108.\n32. Voelker RA. Cervical cancer screening. Jama. 2023;330(20):2030.\n33. Popalis ML, et al. Improving cervical cancer screening rates: a scoping review \nof resources and interventions. Cancer Causes Control. 2022;33:1325–33.\n34. Varatharajan S, et al. Cervical cancer in Malaysia: can we improve our screen-\ning and preventive practice? BMC Public Health. 2012;12:A17.\n35. Vidrine JI, et al. Enhancing long-term smoking abstinence among individu-\nals with a history of cervical intraepithelial neoplasia or cervical cancer \n(Project ACCESS): protocol for a randomized clinical trial. BMC Public Health. \n2023;23(1).\n36. Nishimura Y, et al. Mailing human papillomavirus self-sampling kits to \nwomen under-screened for cervical cancer improved detection in cervical \ncancer screening in a general population study in Japan. BMC Public Health. \n2023;23(1).\n37. Tao L, et al. Prevalence and risk factors for cervical neoplasia: a cervical cancer \nscreening program in Beijing. BMC Public Health. 2014;14:1185.\n38. Hong Y, et al. HPV and cervical cancer related knowledge, awareness and \ntesting behaviors in a community sample of female sex workers in China. \nBMC Public Health. 2013;13:696.\n39. Scott Duncan T, et al. Empowered patients and informal care-givers as \npartners?-a survey study of healthcare professionals’ perceptions. BMC Health \nServ Res. 2023;23:404.\n40. Girasek E, et al. E-páciensek Magyarországon: digitális egészséggel kapcsola-\ntos ismeretek, szokások egy országos reprezentatív felmérés tükrében. Orvosi \nHetilap 2022;163:1159–65.\n41. Chen P , et al. The acceptability and effectiveness of artificial intelligence-\nbased chatbot for hypertensive patients in community: protocol for a mixed-\nmethods study. BMC Public Health. 2024;24(1).\n42. Péter Dr. Bôsze, G.p.d. Hernádi Zoltán Dr, Károly Dr Pap. Ungár László DR, A \nméhnyakrák szûrésének szempontjai: hazai irányelvek. Nőgyógyászati Onkoló-\ngia. 2009;14:11–17.\n43. Fisher S, Rosella LC. Priorities for successful use of artificial intelligence by \npublic health organizations: a literature review. BMC Public Health. 2022;22(1).\n44. Morgenstern JD, et al. “AI’s gonna have an impact on everything in society, so \nit has to have an impact on public health”: a fundamental qualitative descrip-\ntive study of the implications of artificial intelligence for public health. BMC \nPublic Health. 2021;21(1).\n45. Gynecology PCOOA. The professional protocol of the hungarian ministry of \nhealth - cervical cancer. 2005.\n46. Green J, et al. Concomitant chemotherapy and radiation therapy for cancer \nof the uterine cervix. Cochrane Database Syst Rev 2005;2005:Cd002225.\n47. Shueng PW, et al. Neoadjuvant chemotherapy followed by radiotherapy \nshould not be a standard approach for locally advanced cervical cancer. Int J \nRadiat Oncol Biol Phys. 1998;40:889–96.\n48. Einhorn N, et al. A systematic overview of radiation therapy effects in cervical \ncancer (cervix uteri). Acta Oncol 2003;42:546–56.\n49. Center HNPHAP , Cervical Cancer Screening\n50. OpenAI, OpenAI API Reference. 2024.\n51. Viñals R, et al. artificial intelligence-based cervical cancer screening on \nimages taken during visual inspection with acetic acid: a systematic review. \nDiagnostics (Basel). 2023;13(5).\n52. Kanavati F, et al. A Deep learning model for cervical cancer screening on \nliquid-based cytology specimens in whole slide images. Cancers (Basel). \n2022;14(5).\n53. Mathivanan SK, et al. Enhancing cervical cancer detection and robust clas-\nsification through a fusion of deep learning models. Sci Rep. 2024;14:10812.\n54. Hou X, et al. Artificial intelligence in cervical cancer screening and diagnosis. \nFront Oncol. 2022;12:851367.\n55. AlSammarraie A, Househ M.The use of large language models in gener-\nating patient education materials: a scoping review. Acta Inform Med. \n2025;33(1):4–10.\nPage 16 of 16\nAngyal et al. BMC Medical Informatics and Decision Making           (2025) 25:242 \n56. Aydin S, et al. Large language models in patient education: a scoping review \nof applications in medicine. Front Med (Lausanne). 2024;11:1477898.\n57. Lin C, Kuo CF. Roles and potential of large language models in healthcare: a \ncomprehensive review. Biomed J. 2025;100868.\n58. Reicher L, et al. Exploring the role of artificial intelligence, large language \nmodels: comparing patient-focused information and clinical decision sup-\nport capabilities to the gynecologic oncology guidelines. Int J Gynaecol \nObstet. 2025;168:419–27.\n59. Kuerbanjiang W, et al. Performance evaluation of large language models in \ncervical cancer management based on a standardized questionnaire: com-\nparative study. J Med Internet Res. 2025;27:e63626.\n60. Aggarwal A, et al. Artificial intelligence-based chatbots for promoting health \nbehavioral changes: systematic review. J Med Internet Res. 2023;25:e40789.\n61. Xu L, et al. Chatbot for health care and oncology applications using \nartificial intelligence and machine learning: systematic review. JMIR Cancer. \n2021;7:e27850.\n62. Milne-Ives M, et al. The effectiveness of artificial intelligence conversational \nagents in health care: systematic review. J Med Internet Res. 2020;22:e20346.\n63. Huo B, et al. Large language models for chatbot health advice studies: a \nsystematic review. JAMA Netw Open. 2025;8:e2457879.\n64. Chen X, et al. EyeGPT for patient inquiries and medical education: develop-\nment and validation of an ophthalmology large language model. J Med \nInternet Res. 2024;26:e60063.\n65. Wilhelm TI, Roos J, Kaczmarczyk R. Large language models for therapy recom-\nmendations across 3 clinical specialties: comparative study. J Med Internet \nRes. 2023;25:e49324.\n66. Zhu L, et al. Testing and validation of a custom retrained large language \nmodel for the supportive care of hn patients with external knowledge base. \nCancers (Basel). 2024;16(13).\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in \npublished maps and institutional affiliations.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6270301342010498
    },
    {
      "name": "Health informatics",
      "score": 0.525981605052948
    },
    {
      "name": "Personalization",
      "score": 0.48047178983688354
    },
    {
      "name": "Cervical cancer",
      "score": 0.44914865493774414
    },
    {
      "name": "Context (archaeology)",
      "score": 0.4440041482448578
    },
    {
      "name": "SNOMED CT",
      "score": 0.4208134412765503
    },
    {
      "name": "Medicine",
      "score": 0.3264962136745453
    },
    {
      "name": "World Wide Web",
      "score": 0.2591380774974823
    },
    {
      "name": "Cancer",
      "score": 0.19751277565956116
    },
    {
      "name": "Public health",
      "score": 0.1814051866531372
    },
    {
      "name": "Nursing",
      "score": 0.0
    },
    {
      "name": "Linguistics",
      "score": 0.0
    },
    {
      "name": "Internal medicine",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Terminology",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I101202996",
      "name": "Semmelweis University",
      "country": "HU"
    }
  ]
}