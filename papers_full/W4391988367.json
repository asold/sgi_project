{
  "title": "LLM-Assisted Crisis Management: Building Advanced LLM Platforms for Effective Emergency Response and Public Collaboration",
  "url": "https://openalex.org/W4391988367",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5093734226",
      "name": "Hakan T. Otal",
      "affiliations": [
        "University at Albany, State University of New York"
      ]
    },
    {
      "id": "https://openalex.org/A1991512662",
      "name": "Eric Stern",
      "affiliations": [
        "University at Albany, State University of New York"
      ]
    },
    {
      "id": "https://openalex.org/A2609780347",
      "name": "M. Abdullah Canbaz",
      "affiliations": [
        "University at Albany, State University of New York"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4386489061",
    "https://openalex.org/W2944796298",
    "https://openalex.org/W2946008786",
    "https://openalex.org/W2154424391",
    "https://openalex.org/W4210695394",
    "https://openalex.org/W3207296788",
    "https://openalex.org/W3048040671",
    "https://openalex.org/W3040452049",
    "https://openalex.org/W2917110949",
    "https://openalex.org/W4376107459",
    "https://openalex.org/W3176635617",
    "https://openalex.org/W3158429731",
    "https://openalex.org/W4309651064",
    "https://openalex.org/W3005073185",
    "https://openalex.org/W3163411042",
    "https://openalex.org/W4312302819",
    "https://openalex.org/W2998269827",
    "https://openalex.org/W4247051858",
    "https://openalex.org/W4205891021",
    "https://openalex.org/W6980156385",
    "https://openalex.org/W3113534778",
    "https://openalex.org/W4283071006",
    "https://openalex.org/W4387573385",
    "https://openalex.org/W4322763581",
    "https://openalex.org/W6854866820",
    "https://openalex.org/W761267035",
    "https://openalex.org/W4310809133",
    "https://openalex.org/W6857502649",
    "https://openalex.org/W6854308872",
    "https://openalex.org/W2600522727",
    "https://openalex.org/W2990648591",
    "https://openalex.org/W4390414389",
    "https://openalex.org/W4322736917",
    "https://openalex.org/W4389959972",
    "https://openalex.org/W4381572755"
  ],
  "abstract": "Emergencies and critical incidents often unfold rapidly, necessitating a\\nswift and effective response. In this research, we introduce a novel approach\\nto identify and classify emergency situations from social media posts and\\ndirect emergency messages using an open source Large Language Model, LLAMA2.\\nThe goal is to harness the power of natural language processing and machine\\nlearning to assist public safety telecommunicators and huge crowds during\\ncountrywide emergencies. Our research focuses on developing a language model\\nthat can understand users describe their situation in the 911 call, enabling\\nLLAMA2 to analyze the content and offer relevant instructions to the\\ntelecommunicator, while also creating workflows to notify government agencies\\nwith the caller's information when necessary. Another benefit this language\\nmodel provides is its ability to assist people during a significant emergency\\nincident when the 911 system is overwhelmed, by assisting the users with simple\\ninstructions and informing authorities with their location and emergency\\ninformation.\\n",
  "full_text": "arXiv:2402.10908v1  [cs.CL]  12 Jan 2024\nLLM-Assisted Crisis Management: Building\nAdvanced LLM Platforms for Effective Emergency\nResponse and Public Collaboration\nHakan T . Otal and M. Abdullah Canbaz\nDepartment of Information Sciences and T echnology\nCollege of Emergency Preparedness, Homeland Security, and Cybersecurity\nUniversity at Albany, SUNY\nAlbany, NY , United States\nhotal, mcanbaz [at] albany [dot] edu\nAbstract—Emergencies and critical incidents often unfold\nrapidly, necessitating a swift and effective response. In t his\nresearch, we introduce a novel approach to identify and clas sify\nemergency situations from social media posts and direct eme r-\ngency messages using an open source Large Language Model,\nLLAMA2. The goal is to harness the power of natural language\nprocessing and machine learning to assist public safety tel ecom-\nmunicators and huge crowds during countrywide emergencies .\nOur research focuses on developing a language model that can\nunderstand users describe their situation in the 911 call, e nabling\nLLAMA2 to analyze the content and offer relevant instructio ns\nto the telecommunicator , while also creating workﬂows to no tify\ngovernment agencies with the caller’s information when nec es-\nsary . Another beneﬁt this language model provides is its abi lity\nto assist people during a signiﬁcant emergency incident whe n the\n911 system is overwhelmed, by assisting the users with simpl e\ninstructions and informing authorities with their locatio n and\nemergency information.\nIndex T erms—llama2, mistral, LLM, emergency management,\nemergency response, public safety, 911\nI. I N T RO D U CT IO N\nUrban centers like New Y ork City pulsate with vibrant life,\ninnovation, and economic might. Y et, beneath their dynamis m\nlies a vulnerability woven into the fabric of their complexi ty:\na susceptibility to large-scale disruptions. The United St ates\nalone grapples with an average of 50 major disasters annuall y,\nimpacting millions and inﬂicting billions in damages [1].\nThese emergencies, from natural disasters to infrastructu re\nfailures, hold the potential to devastate, as Hurricane San dy\ntragically demonstrated in New Y ork City, damaging over\n69,000 residential units, leading to the temporary displac e-\nment of thousands of New Y orkers, and incurring immense\neconomic losses [2]–[5].\nTraditional emergency response systems face hurdles in\nnavigating the rapids of such crises. Information overload ,\ncommunication bottlenecks, and the need for rapid, coordi-\nnated action within dynamic, often chaotic environments po se\nsigniﬁcant challenges [6]–[8]. These difﬁculties are ampl iﬁed\nin densely populated urban settings, where a single event\ncan ripple through critical infrastructure and impact mill ions\ninstantly [9], [10]. Additionally, the linguistic diversi ty in\nurban areas, such as New Y ork City, adds another layer of\ncomplexity. With a signiﬁcant portion of 911 callers being\nnon-native English speakers, the risk of miscommunication\nincreases, further challenging the efﬁciency and effectiv eness\nof emergency response systems [11]–[13].\nIntegrating AI into the ﬁrst responders’ ecosystem holds im -\nmense promise, but navigating its intricacies demands care ful\nconsideration of sub-cuyltural and ethical currents [14]– [16].\nConcerns from ﬁrst responders, the FCC, and other stake-\nholders center around four critical pillars: generational techno-\nscepticism, potential biases, data privacy vulnerabiliti es, and\nthe delicate balance of human oversight [17]–[19].\nThe ﬁrst obstacle to be overcome when planning the in-\ntroduction of new technology to ﬁrst responders is a culture\nthat traditionally has been skeptical of technology [20]. M any\nolder ﬁrst responder leaders have grown up in a socio-\ntechnical culture in which ”hoses and irons”, street smarts and\ncommand intuition loomed larger than big data and advanced\ncomputational capabilities. Even those ﬁrst responders wh o\nare digitally savvy or even digitally native may be wary of\nalgorithmic biases creeping into AI-powered tools, potent ially\nskewing data analysis or leading to discriminatory decisio n-\nmaking in critical situations [9].\nThe FCC’s main role during emergencies is to regulate\ntelecommunications carriers, ensuring reliable and resil ient\ncommunication services. This includes mandating carriers to\noffer text-to-911 services and promptly inform Public Safe ty\nAnswering Points (PSAPs) of service impairments [21]. The\nFCC also enforces outage reporting, strengthens e-911 con-\nnections, and convenes groups to develop best practices for\nemergency communications. Though not directly overseeing\nPSAPs, the FCC aids carriers in service restoration, like\nfacilitating fuel supply for backup generators during cris es.\nAdditionally, the FCC regulates Wireless Emergency Alerts ,\nfocusing on message details and coverage accuracy [22].\nFinally, stakeholders across the board acknowledge the cru -\ncial role of human expertise in guiding AI, advocating for\nclear oversight mechanisms to ensure responsible technolo gy\napplication and maintain human accountability in life-or- death\nscenarios [23], [24].\nAlthough these challenges are signiﬁcant, they are not nec-\nessarily prohibitive. Other technologies have been succes sfully\nintroduced to ﬁrst responders and good practices for so doin g\nfrom this and other realms are known. Achieving ethical AI\nintegration is possible with careful data management, ongo ing\nefforts to reduce bias, and strong privacy protection metho ds\n[25]. Additionally, creating clear and transparent guidel ines for\nhuman-AI interaction is crucial for building trust and ensu ring\nthat both emergency responders and technology can function\neffectively in this sensitive environment [23], [24]. By gi ving\npriority to ethical issues and encouraging open communica-\ntion, we can utilize AI not only to enhance efﬁciency but also\nto ensure responsible and equitable crisis management.\nIn the context of evolving technology, LLMs and generative\nAI mark a signiﬁcant shift in crisis response capabilities.\nTheir advanced language processing skills, developed thro ugh\nextensive parameterization and deep learning, go beyond ba sic\ncontent generation to address complex challenges in real-t ime\nemergency management [26]. Consider the case of Hurricane\nSandy, where the use of social media, particularly T witter,\nwas just the beginning for people seeking help and guidance.\nNow , LLMs have the potential to handle such situations more\nsystematically. If designed and deployed with care, they ca n\noffer substantial beneﬁts to all involved parties.\nRecent events have further highlighted the need for ad-\nvanced emergency response systems [27]–[29]. A poignant\nexample is the earthquake in Turkey on February 6, 2023,\nwhich was a signiﬁcant event with a profound impact on\nthe country and its people [30]. This earthquake, with a\nmagnitude of 7.5, caused widespread destruction to buildin gs\nand infrastructure, leading to considerable loss of life an d\ninjuries. In the aftermath of the disaster, millions of peop le\ntook to social media to tweet about the earthquake. Among\nthem were individuals directly affected by the emergency\nand their relatives seeking help by explaining their situat ion\nwith providing contact and location information. This surg e\nin social media activity highlighted the urgent need for a\nmore effective emergency response system capable of swiftl y\nidentifying and responding to such crises.\nT o this end, social media feeds and individual messages,\npreviously a dense mass of information, can be converted\ninto actionable insights by AI. LLMs can sift through large\namounts of unstructured data to identify crucial informati on,\nsuch as distress signals hidden in digital chatter. This cap acity\nto understand human language as it happens dramatically\nenhances situational awareness, aiding ﬁrst responders in\ncutting through confusion with greater effectiveness. Thi s is\nthe real promise of AI in crisis management: transforming\ndisparate calls for assistance into a clear picture of needs ,\ndirecting response efforts with focused accuracy in challe nging\nsituations.\nIn this paper, we explore the transformative potential of\nfoundation Large Language Models (LLMs) like LLAMA2\n[31] and Mixtral 8x7B [32] into emergency response systems.\nOur approach is to employ these AI models to interpret and act\nupon data from emergency calls and social media in real-time .\nHence, we ﬁne-tuned these open-source models to optimize th e\nspeed and effectiveness of crisis management, offering a du al\nbeneﬁt: enhancing the decision-support capabilities of ﬁr st\nresponders and providing real-time guidance to those affec ted\nby a huge crisis.\nAs a means to this goal, leveraging the linguistic and ana-\nlytical capacities of LLMs, we present the development of tw o\nframeworks: ’Enhancing 911 Dispatch Efﬁciency with Large\nLanguage Model Integration’ and ’LLMs for Collective Crisis\nResolution: Public Collaboration’ . These frameworks, multi-\nmodal and data-aware, focus on responsive and interactive\nemergency response. In the following sections, we elaborat e\non the technical speciﬁcations of the proposed systems, off er\ncomparisons with various open-source models, address the\nchallenges faced, and evaluate the potential of AI-driven s olu-\ntions in managing emergencies within complex urban setting s.\nII. E N H A N CIN G 911 D IS PAT CH EFFICIE N CY W IT H LLM\nIN T E G RAT IO N\nThe proposed framework integrates Large Language Mod-\nels (LLMs) into critical communication systems, speciﬁcal ly\ntailoring this integration to enhance the 911 dispatch proc ess.\nCentral to this system is the real-time processing and analy sis\nof emergency calls using LLMs, which operate alongside hu-\nman dispatchers to improve response efﬁciency. This approa ch\nembodies a vision of synergistic collaboration between AI a nd\nhuman expertise, designed to bridge technological innovat ion\nand practical emergency management.\nFigure 1 illustrates the proposed system for integrating a\nLarge Language Model (LLM) into the emergency response\ncommunication process, focusing on supporting the 911 dis-\npatch process. The workﬂow begins when a 911 caller places\nan emergency call, which is received by a 911 dispatcher.\nSimultaneously, the call is also processed through an LLM,\nbut it is crucial to note that the LLM does not interact direct ly\nwith the caller.\n!\"\"#$%&&'( \n!\"\"#)*+,%-./'( \n01'(2'3.4#5%3%2'1'3-# \n62'3.*'+#%37#8'(9*.'+ \n:'%&-*1'# \n;(%3+.(*,-*<3 \n01'(2'3.4 \n$<<11=3*.%-*<3 \n$<3-%.-#)'-%*&+> \n?<.%-*<3#@3A<> \n01'(2'3.4#?'9'&> \n01'(2'3.4# \n$%-'2<(4 \n?%(2'#?%32=%2'# \n5<7'& \n6++*+-*9'# \n@3+-(=.-*<3+ \n@3A<(1%-*<3# \n8/%(*32 \nFig. 1. Framework Design: Enhancing 911 Dispatch Efﬁciency with LLM\nIntegration\nWithin the LLM pathway, an existing AI model performs\nreal-time transcription of emergency calls, converting sp oken\nlanguage into text and conducting text segmentation for nam ed\nentity recognition (NER). This NER process is crucial for\nidentifying critical information such as emergency types, emer-\ngency levels, contact details, and other relevant data. Thi s pro-\ncess includes multi-lingual support, a critical feature in diverse,\npopulous cities such as New Y ork City or Los Angeles. The\ntranscribed text enables the LLM’s analysis, leading to the\ngeneration of assistive instructions for the 911 responder or\ndispatcher. Additional details on LLMs used in this framewo rk,\nincluding multi-lingual capabilities and performance com par-\nisons, are provided in Section IV. Moreover, the LLM analyze s\nthe transcribed text to extract vital information, includi ng\ncontact details, location, emergency level, and category. This\ninformation, marked by a dashed line in the documentation,\nindicates its suitability for forwarding to decision suppo rt\nsystems. It assists dispatchers in ﬁlling out necessary for ms,\nincident records, and facilitates communication with othe r\nparties involved in emergency management.\nSubstantial Advantages\nThe integration of LLMs into emergency response work-\nﬂows enhances the accuracy and efﬁciency of incident man-\nagement. The LLMs serve as a vital intermediary, improving\ncommunication between the caller and dispatcher and ensuri ng\nthat critical information is promptly relayed to emergency\nmanagement agencies. This demonstrates AI’s potential in\naugmenting current emergency systems. Moreover, the pro-\ngression of this technology involves integrating context a nd\nexperiential learning. Unlike traditional computing syst ems,\nadvanced models like ChatGPT , Bard, LLAMA, or Mixtral\nstore information semantically, correlating language, co ncepts,\nand past events. This method resembles reinforcement learn -\ning, using historical experiences as a guide. For instance,\ndispatcher interactions with the LLMs, such as disregard-\ning their recommendations, provide valuable feedback. Thi s\nfeedback teaches the LLMs about the relevance of their\nﬁndings, prompting them to adjust future responses toward\nmore meaningful and contextually appropriate directions.\nAnother dimension where LLMs can contribute signiﬁcantly\nin the context of emergency response is in addressing the\nincreasing challenges posed by language barriers. Between\n1980 and 2019, the number of people in the U.S. who speak\na language other than English at home nearly tripled [33].\nConsider a scenario where a dispatcher faces a language\nbarrier with a caller. In such instances, LLMs can translate\nthe caller’s speech into the dispatcher’s language. Furthe rmore,\nthey can generate a set of straightforward questions in spok en\nlanguage for the dispatcher to ask, thereby aiding in gather ing\nmore detailed information about the incident. LLMs, equipp ed\nwith massively multilingual speech knowledge, can detect a nd\noperate in a wide range of languages, including those with\nlimited data. This feature is particularly valuable in emer gency\nsituations where clear communication can be a matter of life\nand death. By integrating multilingual support, LLMs not on ly\novercome language barriers but also ensure inclusivity and\naccessibility in crisis response.\nFurthermore, LLMs can analyze transcribed calls and pre-\nvious incidents to offer call-takers various response opti ons\nfor current situations, harnessing collective experience as the\nnumber of veteran call-takers may decline. Positioned as a\nvirtual institutional memory, LLMs can be accessible to cal l-\ntakers from day one. Additionally, as call-takers secure cr itical\ninformation about unfolding emergencies, LLMs can simul-\ntaneously develop a new workﬂow around this information,\nensuring integration with other relevant law enforcement u nits,\nsuch as dispatch. This approach can further facilitate the m ore\nefﬁcient and rapid mobilization of resources for emergency\nmanagement.\nIII. LLM S F O R CO L L E CT IV E CRIS IS RE S O L U T IO N :\nPU BL IC CO L L A BO RAT IO N\nTraditional emergency systems often face challenges in\nlarge-scale crises and emergencies, struggling to manage t he\nhigh demand for assistance and information [34]. During maj or\nincidents like natural disasters or public health emergenc ies,\nthe volume and complexity of requests can overwhelm these\nsystems, causing response delays and miscommunications,\nsometimes leading to breakdowns in emergency management.\nNotable examples include Hurricane Sandy in 2012 and the\nTurkey Earthquake in 2023, which exposed the limitations\nof existing emergency systems. Consequently, people incre as-\ningly turn to social media to seek help and share information ,\nmaking it a vital communication tool in distress situations .\nThe use of social media in emergencies, while transforming\ninto a vital tool for reporting crises and seeking informati on,\npresents signiﬁcant challenges. The public nature of these\nposts raises serious privacy and security issues, as sensit ive\npersonal information can become exposed in widely acces-\nsible public domains. This situation underscores the need\nfor controlled and expertly managed use of such platforms,\npotentially enhanced by the integration of Large Language\nModels (LLMs) for more effective emergency communication\nwhile safeguarding personal privacy.\n!\"#$%&'())' \n*+))\",-&.'#/' \n01,2&'0132+12&'!\".&% \n45&,2&36/'!1312&5&3-'(2&36$&* 13.' \n7&,8$6&* \n(**$*-$8&' \n93*-,+6-$\"3* !&**12& \n!\"#$%&'#(\")*%+,-.- \n:\"3-16-';&-1$%*< \n0\"61-$\"3'93=\"< \n45&,2&36/'0&8&%< \n45&,2&36/':1-&2\",/ \n;$,&6-$8&* \n93*-,+6-$\"3* \n>&*\"+,6&* \n/0#$1*%2*+3\"-456 \n?@,&1-*<' \nA1B1,.*<' \n;$*,+)-$\"3*<' \n7\"6$1%'C+%3&,1#$%$-$&* \n93=,1*-,+6-+,1%'C+%3&,1#$%$-$&* \n'7.8*46 \nFig. 2. LLM-Assisted Public Collaboration System Design\nT o address these challenges, in our second framework, we\npropose an innovative system design, as illustrated in Figu re\n2, that leverages LLMs to assist the public during major\nemergencies. The system revolves around an LLM-enhanced\nmobile app, aiming to deliver AI-driven, real-time instruc tions\nand information to those impacted by crises. Managed by loca l\nemergency response centers, this app is tailored to establi sh\na communication channel with ﬁrst responders and offer\nimmediate, pertinent advice to the crowds during emergenci es.\nIn pursuit of this, the LLM-enhanced mobile app, backed by\nthe analytical intelligence of LLMs, can offer guidance on\ncritical aspects such as safe shelter locations, provision s such\nas food and water, and where to wait for help. It can also\nprovide personalized instructions based on the user’s spec iﬁc\nsituation and location, which are automatically collected in\nusers’ messages via the application.\nSubstantial Advantages\nConsidering large-scale emergencies involving extensive\npopulations, the primary functionality of the proposed fra me-\nwork is its capacity to systematically categorize various e mer-\ngency types under authoritative oversight. For example, th is\nsystem can classify incidents into groups, such as medical\nemergencies, ﬁres, or infrastructure damage, and then rela y\nthis classiﬁed information to the corresponding local emer -\ngency response agencies. This systematic categorization e n-\nables a more structured and effective response from emergen cy\nresponse agencies.\nAs highlighted in the previously mentioned framework, the\nintegration of multilingual support in LLMs not only helps\novercome language barriers but also reinforces inclusivit y and\naccessibility in crisis response.\nFurthermore, the integration of LLMs into public emergency\nresponse systems offers a promising avenue for enhancing\nthe efﬁciency and effectiveness of crisis management. By\nleveraging the power of AI to analyze the vast amount of\ndata in seconds, categorize, and delegate the information\nof the emergency incidents to the corresponding authoritie s\nin a reverse crowd-sourcing manner, this framework can\nsigniﬁcantly improve the capacity of emergency services to\nhandle large-scale crises. Moreover, by providing real-ti me,\naccurate information to the public, it empowers individual s\nto make informed decisions during emergencies, ultimately\ncontributing to a more resilient and responsive emergency\nmanagement ecosystem.\nPlease note that there exists a T ext-to-911 service that\nenables text message communication with 911 emergency call\ntakers, which is crucial for those with hearing or speech\ndisabilities. It offers a critical alternative in scenario s where\nvoice calls are impractical or unsafe. However, depending o n\nthe policies and decisions made by each individual emergenc y\ncall center within the respective counties, the availabili ty of\nthis service may vary at the county level. Our proposed LLM-\nassisted framework is designed not to replace but to supple-\nment and improve this existing communication infrastructu re.\nIV . M E T H O D O L O G Y\nThe methodology of this paper focuses on choosing and\nreﬁning a suitable AI model with the help of a reliable, top-\nnotch dataset. Crucial to training the LLM is a dataset that\nis diverse and accurately annotated, especially in the cont ext\nof emergency response, where precision is paramount. The AI\nmodel must strike a balance between computational efﬁcienc y\nand nuanced language understanding to interpret various sc e-\nnarios accurately. This synergy of a carefully curated data set\nand an effective model is fundamental to achieving both\naccuracy and promptness in emergency response scenarios.\nA. Model Selection\nIn our investigation to identify the most suitable LLM for\nanalyzing emergency situations, we focused on the LLAMA2\n[31] and Mistral [32] models. The LLAMA2 model, with its\nvariants of 7B, 13B, and 70B, offers a scalable approach to\nlanguage processing, capable of handling complex linguist ic\ntasks with varying degrees of computational resources. The\nMistral models, including the 7B and 8x7B versions, are also\nnoteworthy open-source options known for being relatively\nsmaller compared to LLAMA2 but proven to be effective in\nlanguage understanding and processing tasks. These models\nwere chosen for their proven performance and adaptability i n\ncomplex language analysis.\nB. Datasets\nOur research utilized two distinct datasets for ﬁne-tuning\nthe selected models. The ﬁrst, the Turkey Earthquake X Corp.\nDataset, comprises 500 tweets about the Turkey earthquake.\nThese tweets are classiﬁed into two categories: Class 1, wit h\n300 tweets from individuals directly affected by the earth-\nquake seeking help and sharing location and contact details ,\nand Class 0, including 200 tweets - 150 containing similar\nkeywords to Class 1 such as ”earthquake, ” ”food, ” ”blanket, ”\netc., and 50 unrelated to the earthquake.\nThe second dataset, the Emergency-Disaster Messages\nDataset, encompasses over 25,000 social media messages\nlinked to various disasters, including the 2010 Haiti earth -\nquake, the 2010 Chile earthquake, the 2010 Pakistan ﬂoods,\nand the 2012 Hurricane Sandy in the U.S.A. It covers a\nbroad range of events and years, with non-English messages\ntranslated into English for uniformity. Please be aware tha t the\ndata provider did the translation of these messages.\nIn Figure 3, we chart the distribution of different types\nof emergency-related messages. The most common cate-\ngories, ’emergency’ and ’aid\nrelated, ’ account for 76.47% and\n41.71% of messages, respectively, indicating a high freque ncy\nof requests for immediate aid. Following this are the catego ries\n’weather related’ and ’direct report, ’ which indicate that a siz-\nable portion of messages are about weather-related issues a nd\nﬁrsthand accounts of emergencies. Less frequent categorie s\ninclude requests for food, reports of earthquakes, and stor m\ninformation. The least mentioned categories are related to\noffers of help, situations involving children alone, and in quiries\nabout shops, indicating these are not as commonly discussed\nin emergency-related communications.\nFig. 3. Class Distribution in the Emergency-Disaster Messa ges Dataset\nThe data distribution highlights a signiﬁcant imbalance,\nreﬂecting the complexity and challenge in curating emergen cy\nresponse datasets that require expert validation for messa ge\nclassiﬁcation. This difﬁculty underscores the need for ex-\npanded and focused dataset development in future work. Our\ncollection of earthquake-related data from Turkey’s recen t seis-\nmic event is a step towards addressing this gap, recognizing the\ncrucial role of accurately labeled datasets by knowledgeab le\nexperts in improving emergency response systems.\nC. Additional Resources\nIn addition to the datasets, we incorporated training ma-\nterials such as the FEMA handbooks, emergency response\nguidelines, and 911 dispatcher training manuals. These re-\nsources provide the LLM with context and guidelines for\ngenerating assistive advice, ensuring that the responses a re\nnot only accurate but also practical and in line with standar d\nemergency response protocols.\nD. Preprocessing & Prompt Engineering\nThe effectiveness of the LLMs in emergency response\ndepends signiﬁcantly on the preprocessing of the datasets\nand the engineering of prompts used for model training. The\ndatasets, including the Turkey Earthquake X Corp. Dataset\nand the Emergency-Disaster Messages Dataset, underwent a\nthorough cleaning process. This involved removing special\ncharacters and emojis, ﬁltering out irrelevant informatio n, and\ndiscarding very short messages that lacked sufﬁcient conte xt.\nSuch preprocessing ensures that the data fed into the LLM\nis relevant and clean, thus improving the model’s learning\nefﬁciency and accuracy.\nPrompt engineering is crucial in our approach, involving\nthe craft of prompts that lead the model to effectively parse\nand classify emergency communications. W e experimented\nwith various prompt structures to reﬁne both LLAMA2 and\nMistral models’ performances, using both multiclassiﬁcat ion\nand binary classiﬁcation techniques to determine the rele-\nvance and category of emergency messages. This process is\ninstrumental in teaching the model to discern and accuratel y\nlabel emergency situations. The cleaned input texts, expec ted\nresponses, and system prompts were combined to generate a\ncomprehensive dataset suitable for ﬁne-tuning LLAMA2. By\nreﬁning the input data and crafting precise prompts, we aime d\nto enhance the model’s ability to provide accurate, relevan t,\nand rapid assistance in crisis scenarios.\nE. Supervised Fine-T uning\nSupervised Fine-Tuning (SFT) is integral to training mod-\nels like LLAMA2 and Mistral, particularly for models with\nextensive parameters. The pre-trained foundation models ﬁ ne-\ntuned using the curated dataset to enhance their precision\nfor emergency communication. W e also utilized LoRA, a\ntechnique that allows only a small portion of the model to\nbe trainable, thus reducing the number of learned parameter s\nsigniﬁcantly. This allowed for efﬁcient training by modify ing a\nfraction of the models, thus reducing the number of paramete rs\nsigniﬁcantly and enabling the model to handle the intricaci es\nof emergency scenarios.\nThe model’s size and computational load are further opti-\nmized using Quantized Low-Rank Adapters (QLoRA), which\nsit atop a quantized, frozen model, preserving the base mode l’s\nrobustness. This ﬁne-tuning process, which involves preci se\nquantization, leads to a compact model without signiﬁcantl y\naffecting performance. The resulting model, which require s\nsaving only the modiﬁcations, is compatible with various da ta\ntypes and retains the original model’s integrity.\nIn enhancing the training process, techniques like NEFTune\nnoise [35] and Flash Attention 2 [36] were incorporated to pr e-\nvent overﬁtting and improve attention mechanism efﬁciency .\nBy applying these methodologies to speciﬁc settings, the\nmodels are ﬁne-tuned to efﬁciently and accurately process\nemergency communications, resulting in streamlined model s\nadept at crisis response.\nF . Hardware Requirements\nTraining and deploying the LLAMA2 and Mistral mod-\nels involved signiﬁcant computational resources, leverag ing\nthe NVIDIA Base Command Cloud System for necessary\nprocessing capacity. W e utilized NVIDIA A100 GPUs with\n80GB VRAM for training the Llama2 13B model on over\n20,000 texts. These GPUs facilitated quicker training and d ata\nmanagement, essential for the real-time analysis required by\nour emergency response system. With methods like parallel\nprocessing, quantization and Flash Attention 2, training w as\nexpedited, culminating in a model that responds within two\nseconds, a critical factor for emergency scenarios.\nV . E X P E RIM E N TA L RE S U LT S\nIn our search for the ideal large language model for\nanalyzing emergency situations, we assessed the LLAMA2\nvariants with 7B, 13B, and 70B parameters, alongside the\nMistral models with 7B and 8x7B parameters. Our initial\nﬁndings indicated that the 7B models, being smaller, provid ed\nquick processing times and handled simpler queries with hig h\nefﬁciency. Their compact size, however, did present limita tions\nin complex understanding and contextual comprehension.\nThe training losses, as illustrated in ﬁgure 4, reveal how\neach model learns to minimize errors over epochs. All models\nshow a downward trend in training loss, indicating that lear n-\ning is taking place effectively. Notably, LLAMA2-70B exhib its\nthe steepest decline in training loss, suggesting a superio r\nlearning capacity likely due to its larger parameter count,\nwhich enables a deeper understanding of complex patterns in\nthe data. However, it is also observed that the LLAMA2-70B\nmodel begins to plateau after epoch 4, which could indicate\nthe beginning of overﬁtting or reaching its learning capaci ty.\nIn ﬁgure 5, validation losses can be observed. Generally,\nLLAMA2 models initially perform better for 2 epochs, but\nas epochs increase, their losses rise, indicating potentia l over-\nﬁtting to the training data. This highlights the challenge o f\nﬁnding a balance between model complexity and generaliz-\nability to new data. In contrast, Mistral 7B and 8x7B models\nshow more stability in validation losses, suggesting bette r\ngeneralization despite their smaller size and indicating t hat\nthey can be trained for more epochs.\nT ABLE I\nME T R I C S O F T H E T E S T E D MO D E L S\nModel Prec. Recall F1 ROC-A UC Acc.\nLLAMA2-7B-chat 0.79 0.75 0.77 0.87 0.48\nLLAMA2-13B-chat 0.78 0.78 0.78 0.88 0.50\nLLAMA2-70B-chat 0.82 0.88 0.85 0.93 0.69\nMistral-7B-instruct 0.80 0.69 0.74 0.84 0.41\nMixtral-8x7B-instruct 0.68 0.72 0.70 0.84 0.35\nIn our study, we prioritized the multi-classiﬁcation task f or\nanalyzing emergency situations, categorizing messages in to\nspeciﬁc emergency classes. W e navigated the task’s com-\nplexity due to the subtle and overlapping nature of class\ncharacteristics. For example, a user’s message might perta in to\n’ﬁre, ’ ’electricity, ’ and ’shelter’ simultaneously. W e me asured\nthe models’ performance using metrics such as accuracy, F1-\nscore, and ROC-A UC, drawing from 1000 samples across all\nmodels. These metrics, detailed in T able I, are vital for a\ndetailed evaluation of the models’ capabilities in emergen cy\ncontext analysis.\nIn the domain of emergency classiﬁcation, it is imperative t o\nconsider the importance of correctly identifying true emer gen-\ncies (true positives) over incorrectly labeling non-emerg encies\nas emergencies (false positives). Given the potentially li fe-\nthreatening nature of missed or delayed emergency response s,\nthe cost of false negatives is signiﬁcantly higher than that\nof false positives. In such a context, Micro averaging is a\ncrucial evaluation method, especially when dealing with cl ass\nimbalances in multi-classiﬁcation tasks. It combines the t rue\npositives, false positives, and false negatives across all classes\nby treating every prediction equally to compute metrics suc h\nas accuracy, F1 score, and ROC-A UC. This approach ensures\nthat the metrics are not skewed by the overrepresentation\nof any single class, providing a more reliable measure of a\nmodel’s effectiveness in classifying emergency situation s, and\ntherefore, all metrics we presented are micro-averaged.\nAccuracy, the simplest metric, represents the percentage o f\ncorrect predictions. However, in a multi-class context wit h an\nunbalanced dataset, accuracy can be misleading. T o address\nthis, additional metrics were considered. The F1-score, us ed\nin binary classiﬁcation, balances recall and precision. It is\nthe harmonic mean of these two measures, providing a com-\nprehensive assessment of the model’s ability to identify ea ch\nclass. The Receiver Operating Characteristic (ROC) curve, cru-\ncial for binary classiﬁers, depicts performance across dif ferent\ndiscrimination thresholds. The Area Under the Curve (A UC)\nquantiﬁes discriminative power, with higher values indica ting\nsuperior performance. A UC values near 1 signify a perfect\nclassiﬁer, while 0.5 suggests random guessing. This metric\nis valuable for evaluating classiﬁers on imbalanced datase ts,\nensuring a thorough assessment in multi-classiﬁcation tas ks.\nThe LLAMA2 models, as illustrated in T able I, display\na strong performance across accuracy, F1-score, and ROC-\nA UC, indicating their robust ability in emergency situatio n\nclassiﬁcation. The LLAMA2-70B model, in particular, excel s,\nshowcasing its strength in nuanced language processing. Co n-\nversely, the Mistral models, despite lower accuracy, show h igh\nF1 and ROC-A UC scores, suggesting effectiveness in iden-\ntifying true positives over various thresholds. The LLAMA2\nmodels also demonstrate superior capability in classifyin g non-\nEnglish messages, providing accurate emergency analysis w ith\nefﬁcient processing across multiple languages.\nBased on our experimental outcomes, we have determined\nthe LLAMA2 13B chat model to be well-suited for our ob-\njectives. This model stands out with its 13 billion paramete rs,\nstriking an optimal balance between size and performance.\nIt excels in deciphering the subtleties of language, which i s\nparamount for analyzing social media communications durin g\nemergencies. Its architecture, ﬁne-tuned for conversatio nal AI,\nenables the delivery of coherent and context-aware respons es,\naligning perfectly with the critical need for precise and pr ompt\ninterpretation of emergency-related data in our project.\nVI. P OT E N T IA L PRO BL E M S\nThe integration of artiﬁcial intelligence (AI) in emergenc y\nresponse services like 911 operations and healthcare has th e\npotential to signiﬁcantly enhance efﬁciency and predictiv e\nabilities. However, this integration requires careful con sidera-\ntion of various challenges. Misinformation in crisis situa tions\nis a primary concern, where AI can help identify and counter\nfalse information through data analysis and collaboration with\nfact-checking systems. Public awareness campaigns, suppo rted\nby AI-generated content, are also vital for educating the pu blic\nabout misinformation.\nAnother signiﬁcant issue is the potential for AI systems to\nexhibit societal biases, such as slower response times in ce rtain\ndemographic areas or misidentiﬁcation in facial recogniti on\ntechnologies. This could lead to discriminatory practices . The\nreliability and accuracy of AI in high-stakes situations, l ike\nﬁreﬁghting, are crucial, as AI systems based on imperfect\nFig. 4. Training losses of different models over epochs\n Fig. 5. V alidation losses of different models over epochs\ndata can make erroneous decisions. The vulnerability of the se\nsystems to cyberattacks adds to the risk.\nThe dilemma of balancing human judgment with AI\ndecision-making is also critical, especially since AI lack s nu-\nanced understanding of human emotions and ethical consider a-\ntions. This could lead to AI systems prioritizing efﬁciency over\ncompassionate responses. Additionally, issues of accessi bility\nand equity arise, as the unequal distribution of technology can\nexacerbate social disparities.\nThe paramount importance in the application of AI within\nemergency settings lies in addressing privacy concerns, gi ven\nthe frequent processing of sensitive personal data. Ensuri ng\ndata privacy while leveraging AI for public safety is a compl ex\nbut essential task. Lastly, the transparency and explainab ility of\nAI systems are key to maintaining public trust and account-\nability, necessitating the development of AI models that ar e\nnot only effective but also transparent in their decision-m aking\nprocesses.\nVII. A D D RE S S IN G TE CH N ICA L CH A L L E N G E S : D ATA A N D\nMO D E L PO IS O N IN G IN AI S Y S T E M S\nIn the realm of AI-driven emergency response systems,\naddressing the technical challenges posed by data and model\npoisoning is paramount for ensuring system integrity and\nreliability.\nA. Data P oisoning: Threats and Mitigation Strategies\nData poisoning presents a formidable challenge to the\nintegrity of AI models, notably LLMs. This phenomenon\noccurs when malicious entities intentionally introduce co r-\nrupted, misleading, or biased data into the training datase t.\nThe objective is to manipulate the model’s learning traject ory,\nresulting in outputs that are inaccurate, biased, or inappr opri-\nate. In emergency response scenarios, the ramiﬁcations of d ata\npoisoning can be profound, potentially leading to misdirec tion\nof services, erroneous interpretation of emergencies, or f ailure\nto recognize legitimate distress signals.\nT o counteract data poisoning, implementing stringent data\nvalidation and ﬁltration protocols is essential [37]. This ap-\nproach encompasses comprehensive scrutiny of data origins ,\ncontinuous surveillance of incoming data for signs of ma-\nnipulation, and the enforcement of rigorous data governanc e\nprinciples. Also, using adversarial training methods, whi ch\nexpose the model to made-up attack vectors while it is being\ntrained, can make it much more resistant to these kinds of\nthreats.\nB. Model P oisoning: Identiﬁcation and Countermeasures\nModel poisoning poses another signiﬁcant threat but op-\nerates by targeting the AI model’s learning mechanism or\noutput directly. Attackers may employ tactics such as backd oor\nattacks, wherein speciﬁc inputs are engineered to trigger\naberrant or detrimental model behaviors, or they might ex-\nploit vulnerabilities inherent in the model’s architectur e or its\noperational framework.\nT o safeguard against model poisoning, it is vital to conduct\nthorough audits of the model’s architecture and deployment\nenvironment [38], [39]. This includes identifying potenti al\nbackdoors and vulnerabilities that could be exploited by at -\ntackers. Regular updates and patches to the model’s frame-\nwork, along with continuous monitoring for unusual model\nbehavior, are crucial steps in maintaining the security and\nintegrity of AI systems in emergency response scenarios.\nAdditionally, leveraging advanced defensive techniques, such\nas anomaly detection algorithms and reinforced learning en vi-\nronments, can provide an additional layer of protection aga inst\nmodel poisoning attacks.\nVIII. C O N CL U S IO N & F U T U RE RE S E A RCH\nIn the realm of emergency response, LLMs, such as\nLLAMA2 and Mistral, can be transformative tools. Their\nintegration into crisis management systems exempliﬁes the\npivotal role of AI in enhancing efﬁciency and effectiveness .\nIn this paper, we developed two advanced frameworks for\noptimizing 911 dispatch operations and encouraging pub-\nlic cooperation , both of which underscore the remarkable\ncapabilities of LLMs. T o this end, we have ﬁne-tuned 5\ndifferent models: the LLAMA2 models 7B, 13B, 70B and\nthe Mistral models 7B and 8x7B. After careful consideration\nof the available options, we ultimately chose LLAMA2 13B\nas our preferred solution. These models excel in their abili ty\nto process complex, multilingual communications, providi ng\ncontext-aware responses. This feature not only fosters inc lusiv-\nity but also bridges language gaps, ensuring that diverse vo ices\nare heard and valued in challenging situations. However, it\nis crucial to acknowledge and address potential issues such\nas bias and privacy concerns in AI applications. The ethical\nand responsible deployment of AI is imperative in sensitive\ndomains like crisis management.\nIn summary, generative AI stands at the forefront of\nrevolutionizing emergency response strategies. The ongoi ng\nreﬁnement and evaluation of these models are crucial to\nenhance their effectiveness. Future research endeavors sh ould\nconcentrate on the ethical integration of AI, with a focus on\nfostering collaborative, equitable, and efﬁcient crisis m anage-\nment practices. This approach is essential for safeguardin g\npublic well-being in times of crisis.\nRE F E RE N CE S\n[1] A. T eam, “Climate change and infrastructure, urban syst ems, and vul-\nnerabilities: T echnical report for the u.s. department of e nergy in support\nof the national climate assessment, ” National Climate Assessment , 2014.\n[2] New Y ork City Government, “Hurricane sandy , ”\nhttps://www .nyc.gov/site/cdbgdr/hurricane-sandy/hurricane- sandy.page ,\n2023.\n[3] N. Pourebrahim, S. Sultana, J. Edwards, A. Gochanour, an d S. Mohanty ,\n“Understanding communication dynamics on twitter during n atural\ndisasters: A case study of hurricane sandy , ” International journal of\ndisaster risk reduction , vol. 37, p. 101176, 2019.\n[4] Z. W ang, N. S. Lam, N. Obradovich, and X. Y e, “ Are vulnerab le\ncommunities digitally left behind in social responses to na tural disasters?\nan evidence from hurricane sandy with twitter data, ” Applied geography ,\nvol. 108, pp. 1–8, 2019.\n[5] A. L. Hughes, L. A. St. Denis, L. Palen, and K. M. Anderson, “Online\npublic communications by police & ﬁre services during the 20 12\nhurricane sandy , ” in Proceedings of the SIGCHI conference on human\nfactors in computing systems , 2014, pp. 1505–1514.\n[6] S. Loreti, E. Ser-Giacomi, A. Zischg, M. Keiler, and M. Ba rthelemy ,\n“Local impacts on road networks and access to critical locat ions during\nextreme ﬂoods, ” Scientiﬁc reports , vol. 12, no. 1, p. 1552, 2022.\n[7] R. Grace, “Overcoming barriers to social media use throu gh multisensor\nintegration in emergency management systems, ” International Journal\nof Disaster Risk Reduction , vol. 66, p. 102636, 2021.\n[8] S. Misra, P . Roberts, and M. Rhodes, “Information overlo ad, stress, and\nemergency managerial thinking, ” International Journal of Disaster Risk\nReduction, vol. 51, p. 101762, 2020.\n[9] N. Andreassen, O. J. Borch, and A. K. Sydnes, “Informatio n sharing and\nemergency response coordination, ” Safety Science , vol. 130, p. 104895,\n2020.\n[10] Z. El Khaled and H. Mcheick, “Case studies of communicat ions systems\nduring harsh environments: A review of approaches, weaknes ses, and\nlimitations to improve quality of service, ” International journal of\ndistributed sensor networks , vol. 15, no. 2, 2019.\n[11] S. E. Clayman and H. Kevoe-Feldman, “Dispatching ﬁrst r esponders:\nLanguage practices and the dispatcher’ s operational role i n radio en-\ncounters with police ofﬁcers, ” Discourse & Society , 2023.\n[12] A. Dimou, D. G. Kogias, P . Trakadas, F . Perossini, M. W el ler, O. Balet,\nC. Z. Patrikakis, T . Zahariadis, and P . Daras, “Faster: Firs t responder\nadvanced technologies for safe and efﬁcient emergency resp onse, ” in\nT echnology Development for Security Practitioners . Springer, 2021,\npp. 447–460.\n[13] T . Mondal, S. Pramanik, P . Pramanik, K. N. Datta, P . S. Pa ul, S. Saha,\nand S. Nandi, “Emergency communication and use of ict in disa ster\nmanagement, ” Emerging technologies for disaster resilience: Practical\ncases and theories , pp. 161–197, 2021.\n[14] H. Adam, A. Balagopalan, E. Alsentzer, F . Christia, and M. Ghassemi,\n“Mitigating the impact of biased artiﬁcial intelligence in emergency\ndecision-making, ” Communications Medicine , vol. 2, no. 1, p. 149, 2022.\n[15] H. Lakkaraju and O. Bastani, “”how do i fool you?”: Manip ulating\nuser trust via misleading black box explanations, ” in Proceedings of the\nAAAI/ACM Conference on AI, Ethics, and Society . Association for\nComputing Machinery , 2020, p. 79–85.\n[16] F . Poursabzi-Sangdeh, D. G. Goldstein, J. M. Hofman, J. W . W ort-\nman V aughan, and H. W allach, “Manipulating and measuring mo del\ninterpretability , ” in Proceedings of the 2021 CHI conference on human\nfactors in computing systems , 2021, pp. 1–52.\n[17] J. W . W eiss, Business ethics: A stakeholder and issues management\napproach. Berrett-Koehler Publishers, 2021.\n[18] N. R. Council et al. , Improving disaster management: the role of IT in\nmitigation, preparedness, response, and recovery . National Academies\nPress, 2007.\n[19] P . R. Buchanan and C. Sparagowski, “The role of emerging technologies\nand social justice in emergency management practice: The go od, the\nbad, and the future, ” Justice, Equity , and Emergency Management , pp.\n175–199, 2022.\n[20] S. Pilemalm, “Barriers to digitalized co-production: the case of volunteer\nﬁrst responders, ” in 19th International Conference on Information Sys-\ntems for Crisis Response and Management, T arbes, France, Ma y 22-25,\n2022, 2022.\n[21] F . C. Commission, “Emergency communications, ”\nhttps://www .fcc.gov/general/emergency-communications , 2023.\n[22] Federal Communications Commission, “Wireless emerge ncy alerts\n(wea), ” https://www .fcc.gov/emergency-alert-system , 2 023.\n[23] J. Sutton, Y . Rivera, T . K. Sell, M. B. Moran, D. Bennett G ayle,\nM. Schoch-Spana, E. K. Stern, and D. Turetsky , “Longitudina l risk\ncommunication: A research agenda for communicating in a pan demic, ”\nHealth Security , vol. 19, no. 4, pp. 370–378, 2021.\n[24] E. Stern and B. Nussbaum, “Critical infrastructure dis ruption and crisis\nmanagement, ” in Oxford Research Encyclopedia of P olitics , 2022.\n[25] K. Harrison, “Improving information sharing in the nyc emergency\nresponse community , ” Homeland Security Affairs , 2018.\n[26] N. L. Rane, A. T awde, S. P . Choudhary , and J. Rane, “Contr ibution\nand performance of chatgpt and other large language models ( llm) for\nscientiﬁc and research advancements: a double-edged sword , ” Interna-\ntional Research Journal of Modernization in Engineering T e chnology\nand Science , vol. 5, no. 10, pp. 875–899, 2023.\n[27] Centers for Disease Control and Prevention, “W orking t ogether to\nachieve improved emergency response around the world, ” 202 3.\n[28] Department of Homeland Security , “Dhs prepares and equ ips commu-\nnities to address increased risk of ﬁres, ” 2023.\n[29] Online Masters in Public Health, “Innovative emergenc y management\nand response, ” USC Online MPH Program , November 2023.\n[30] W . Chen, G. Rao, D. Kang, Z. W an, and D. W ang, “Early repor t of the\nsource characteristics, ground motions, and casualty esti mates of the\n2023 m w 7.8 and 7.5 turkey earthquakes, ” Journal of Earth Science ,\n2023.\n[31] H. T ouvron, L. Martin, K. Stone, P . Albert, A. Almahairi , Y . Babaei,\nN. Bashlykov , S. Batra, P . Bhargava, S. Bhosale et al. , “Llama\n2: Open foundation and ﬁne-tuned chat models, ” arXiv preprint\narXiv:2307.09288, 2023.\n[32] Mistral AI, “Mixtral 8x7b, ” https://mistral.ai/ .\n[33] U.S. Census Bureau, “Language use in the united states: 2019, ” Amer-\nican Community Survey , 2019.\n[34] J. P . W elch, “The challenges of public service organiza tions in emer-\ngency , crisis, and disaster management, ” in Crisis Management , 2022.\n[35] N. Jain, P . yeh Chiang, Y . W en, J. Kirchenbauer, H.-M. Ch u,\nG. Somepalli, B. R. Bartoldson, B. Kailkhura, A. Schwarzsch ild,\nA. Saha, M. Goldblum, J. Geiping, and T . Goldstein, “Neftune : Noisy\nembeddings improve instruction ﬁnetuning, ” 2023.\n[36] T . Dao, “Flashattention-2: Faster attention with bett er parallelism and\nwork partitioning, ” 2023.\n[37] A. E. Cin` a, K. Grosse, A. Demontis, S. V ascon, W . Zellin ger, B. A.\nMoser, A. Oprea, B. Biggio, M. Pelillo, and F . Roli, “Wild pat terns\nreloaded: A survey of machine learning security against tra ining data\npoisoning, ” ACM Computing Surveys , 2023.\n[38] M. Aljanabi, “Safeguarding connected health: Leverag ing trustworthy ai\ntechniques to harden intrusion detection systems against d ata poisoning\nthreats in iomt environments, ” Babylonian Journal of Internet of Things ,\n2023.\n[39] J. M ¨ okander, J. Schuett, H. R. Kirk, and L. Floridi, “ Au diting large\nlanguage models: a three-layered approach, ” AI and Ethics , pp. 1–31,\n2023.",
  "topic": "Crisis management",
  "concepts": [
    {
      "name": "Crisis management",
      "score": 0.7083256840705872
    },
    {
      "name": "Emergency response",
      "score": 0.660264790058136
    },
    {
      "name": "Crisis response",
      "score": 0.6569759845733643
    },
    {
      "name": "Emergency management",
      "score": 0.5613054633140564
    },
    {
      "name": "Business",
      "score": 0.5184480547904968
    },
    {
      "name": "Engineering management",
      "score": 0.3384366035461426
    },
    {
      "name": "Process management",
      "score": 0.3348483443260193
    },
    {
      "name": "Public administration",
      "score": 0.32131505012512207
    },
    {
      "name": "Public relations",
      "score": 0.31013113260269165
    },
    {
      "name": "Political science",
      "score": 0.30441170930862427
    },
    {
      "name": "Medical emergency",
      "score": 0.2706536054611206
    },
    {
      "name": "Engineering",
      "score": 0.23804232478141785
    },
    {
      "name": "Medicine",
      "score": 0.22470954060554504
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ]
}