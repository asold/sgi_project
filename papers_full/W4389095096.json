{
  "title": "Diagram-based Input for Large Language Models to Support Accessible STEM Learning",
  "url": "https://openalex.org/W4389095096",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A273867387",
      "name": "Sarah E. Wegwerth",
      "affiliations": [
        "Dow Chemical (Canada)"
      ]
    },
    {
      "id": "https://openalex.org/A2936446112",
      "name": "Alexa Urrea",
      "affiliations": [
        "Dow Chemical (Canada)"
      ]
    },
    {
      "id": "https://openalex.org/A2114300131",
      "name": "Julia Winter",
      "affiliations": [
        "Dow Chemical (Canada)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2632014367",
    "https://openalex.org/W4387373567",
    "https://openalex.org/W4285209642",
    "https://openalex.org/W2099473180"
  ],
  "abstract": "To meet the accessibility needs of students who are blind or have low vision (BLV), detailed textual descriptions of STEM diagrams within interactive learning tools are cre-ated in real-time and correspond to the configurations of the interactive software system. The descriptions are read by screen readers as alternative (alt) text to provide infor-mation for BLV students to compose mental representa-tions of the diagram. These descriptions provide a unique bridge from the visual language of STEM diagrams to natural language of Large Language Models (LLMs). By interfacing with an LLM, these descriptions are used for personalized exploration by the BLV user and to guide all learners through a defined pedagogical pathway. Results from a usability study with four BLV adults are reported.",
  "full_text": "Diagram-based Input for Large Language Models to Support Accessible \nSTEM Learning \nSarah E. Wegwerth, Alexa Urrea, and Julia E. Winter* \nAlchemie Solutions, Inc., Bloomfield Hills, MI  \n \n \nAbstract  \nTo meet the accessibility needs of students who are blind or \nhave low vision (BLV), detailed textual descriptions of \nSTEM diagrams within interactive learning tools are created \nin real-time and correspond to the configurations of the inter-\nactive software system. The descriptions are read by screen \nreaders as alternative (alt) text to provide information for \nBLV students to compose mental representations of the dia-\ngram. These d escriptions provide a unique bridge from the \nvisual language of STEM diagrams to natural language of \nLarge Language Models (LLMs). By interfacing with an \nLLM, these descriptions are u sed for personalized explora-\ntion by the BLV user and to guide all learners through a de-\nfined pedagogical pathway. Results from a usability study \nwith four BLV adults are reported.  \nIntroduction \nEducational publishers have moved to delivering content \nthrough digital methods. As they ramp up investment in \nproviding interactive and visually engaging content that has \nbeen shown to improve learning (Cooper, Stieff, and DeSut-\nter 2017) and proven to be wanted by students (Martin- Sa-\nmer, Casada, Gomez-Pozeulo 2023), publishers face the dif-\nficult technical problem of making new digital content ac-\ncessible to students who are blind or have low vision (BLV) \n(Lieberman 2019). For STEM content, which relies heavily \non diagrams, a BLV student depends on alternative (alt) text \ndescriptions to access diagrams in the digital content. Alt \ntext is added to the meta-data of an image, and then a screen \nreader delivers that description and other textual infor-\nmation to the BLV student, usually through an audio inter-\nface. Current solutions for automatically generated alt text \nfor STEM diagrams do not produce enough pedagogical de-\ntail to provide a BLV student detail sufficient for creating \nthe mental representation of the diagram. To create accessi-\nble and usable STEM interactives requires both dynamic alt \ntext for diagrams that change with user input as well as an \ninterface that can be accessed by a screen reader user (SRU).  \nAn accessibility system for STEM interactives \nAn accessibility system was developed for five STEM inter-\nactives: three for chemistry, one for physics, and one for \nearly math. This paper provides details on one of the chem-\nistry interactives, the Lewis Structure interactive drawing \ntool. The accessibility system has three parts: \n• An alt text generation engine to compose standard-\nized descriptions in real-time \n• A menu-based keyboard-accessible control panel \n• An accessible AI-driven learning assistant. \nEach interactive has configuration data that captures com-\nponents within the diagram and tags each component's  iden-\ntity, position, and other pertinent details. These configura-\ntions were matched to a systematic method for describing \nthe components within the context of specific learning ob-\njectives.  \nTo illustrate the difference in detail between the alt text \nautomatically generated by current word -processing soft-\nware (in this case, Microsoft Word) and this new systematic \nmethod for creating real-time alt text, the alt text for the car-\nbonate ion (Figure 1) is given below:  \nAuto-generated alt text: “A picture of a molecule.” \nAlt text generated with the accessibility system: “A Lewis \nstructure of a molecule of carbonate with the chemical for-\nmula CO3 2-. The central atom is carbon. Carbon is single \nbonded to 2 oxygens, and double bonded to 1 oxygen. The \nsingle bonded oxygens have 3 lone pairs and a formal \ncharge of -1 each. The double bonded oxygen has 2 lone \npairs.” \n Alt text descriptions for STEM diagrams are difficult to \nauthor because they provide communication of abstract \nideas that are not easily explained with words. Effective alt \ntext for STEM diagrams is currently constructed by special-\nized authors who have subject matter expertise, a knowledge \nof the learning context for the diagram, and who have been \ntrained in composing alt text descriptions. Though required \nFigure 1: The diagram of a carbonate ion \nhttps://doi.org/10.26434/chemrxiv-2023-r1qn9 ORCID: https://orcid.org/0000-0002-2774-796X Content not peer-reviewed by ChemRxiv. License: CC BY-NC-ND 4.0\nto meet Web Content Accessibility Guidelines in educa-\ntional content (W3.org n.d.), there is no standardization for \nalt text authoring. Often SRUs don't know if the alt text they \nare accessing is complete and relevant , and p oorly crafted \nalt text can be more detrimental  than not having alt text at \nall (McCall and Chagnon 2022). \n Typically, when a description is given, it is a long linear \nsequence of words with no standardized organization or  \nmethod for navigation to the information of interest. Users  \ninteract differently with alt text descriptions. Some need \nmore repetition; others need more context. We wanted to \nprovide an interactive method for a SRU to personalize the \nbuilding of the mental representation of the diagram. \n To meet these individual needs, it was hypothesized that \nthat we could use available Large Language Models (LLMs) \nto create an interactive learning assistant whereby the SRU \ncould ask for specific details regarding the alt text descrip-\ntions. We tested this concept by integrating the Lewis Struc-\nture (chemical drawings) interactive with the OpenAI GPT  \nAPI.  \nInitial tests included a prompt to instruct the LLM that it \nwas working with a BLV student studying Lewis structures \nand its job was to answer the student’s questions based on \nthe given description of the molecule, which was provided \nby the dynamically generated alt text. The LLM was then \nasked questions like “what is bonded to carbon?” or “what \nis the charge on nitrogen?” With the short alt text, the learn-\ning assistant showed prom ising results, but there were still \nerrors. Providing more detailed descriptions and context al-\nlowed for more complex questions to be asked and answered \naccurately as shown in Figure 2. Finally, a knowledge base \nthat included information like “the oxygen atom is a red cir-\ncle” was incorporated into the LLM so that SRUs could also \nask aesthetic questions. Through the learning assistant, the \nextra details can be accessed in a straightforward  manner \nthat reflects how a BLV user would interact with a sighted \nperson when asking for  assistance in understanding a dia-\ngram. \nUsability Study with BLV adults \nFour BLV adults who regularly use a screen reader and \nrely on alt text to access non-text information in digital me-\ndia were recruited for a usability study of the accessibility \nsystem. This number of participants was deemed sufficient \nas prior research on usability testing demonstrated it appro-\npriate for detecting most usability problems (Neilson and \nLandauer 1993). Prior to recruitment, all procedures were \nreviewed and approved for ethical human subjects research \nby HML IRB (study #2146). The three-part study gathered \nfeedback on the alt text descriptions, the use of the learning \nassistant, and the keyboard accessible control panel. With \nrespect to the alt text descriptions and the control panel, all \nparticipants used the dynamically generated alt text to \nidentify the correct tactile diagram from three choices and \ncould readily navigate with the control panel to draw \nchemical structures.  \n Of the four participants, three used the LLM-driven \nlearning assistant while reviewing the alt text descriptions. \nThe fourth was satisfied with the alt text descriptions pro-\nvided. One participant preferred to use the learning assis-\ntant over listening to the alt text numerous times and ex-\nplained, “I liked it because then I could ask the questions \nwithout having to arrow through all the information… get-\nting the stuff I wanted answered and then asking follow up \nquestions to get the other things I wanted answered was \neasier for me.” \nExpansion beyond accessibility \nThe systematic, textual descriptions of the alt text genera-\ntion system provided a unique bridge between the natural \nlanguage of LLMs and the visual language of STEM dia-\ngrams. The next step in the project was to create a pedagog-\nical rubric system for the Lewis Structure interactive, in \nwhich the learning objective (creating a structure from a \ngiven molecular formula) was divided into a structured set \nof requisite skills (such as  counting valence electrons and \nadding bonds) to produce a defined learning pathway. This \nrubric was added to the knowledge base in the LLM inter-\nface and connected through the alt text descriptions with ad-\nditional context.  \n With this expanded learning assistant, both sighted and \nBLV users, could either draw the Lewis structure to obtain  \nfeedback on where they were along the learning pathway or \nask specific text -based questions about the structure they \nhad drawn. The development of this diagram-based learning \nassistant has created a use case where all users benefit from \nthe inclusion of alt text.  This diagram-based input method \nfor LLMs has potential to deliver inclusive and accessible \npersonalized learning for STEM subjects from elementary \nthrough higher education, and into workforce training.  \n \nFigure 2: The Lewis Structure for BF3NH3 and an example \nof the alt text learning assistant dialog  \nhttps://doi.org/10.26434/chemrxiv-2023-r1qn9 ORCID: https://orcid.org/0000-0002-2774-796X Content not peer-reviewed by ChemRxiv. License: CC BY-NC-ND 4.0\nAcknowledgments \nThe authors wish to thank Nicole Kada for her assistance in \nfeedback on design from her perspective as  a recent BLV \nSTEM graduate, and Deb Nischikfor her interview support \nin the usability study. Funding for this project was provided \nby a grant from the National Science Foundation, #2221722. \n \nReferences \nCooper, M.M., Stieff, M. and DeSutter, D. 2017. Sketching the In-\nvisible to Predict the Visible: From Drawing to Modeling in Chem-\nistry. Topics in Cognitive Science, 9: 902-920. \nhttps://doi.org/10.1111/tops.12285. \nLieberman, M. Inside Higher Ed, Helping Institutions Reach Ac-\ncessibility Goals . 2019. https://www.insidehighered.com/digital-\nlearning/article/2019/02/20/guide-accessibility-practices-aims-\nhelp-institutions-develop. Accessed: 2023-11-25.  \nMartin-Samer, M., Casada, C., Gomez-Pozeulo, G. 2023. Utilising \nInteractive Applications as Educational Tools in Higher Education: \nPerspectives from Teachers and Students, and an Analysis of Aca-\ndemic Outcomes. Education for Chemical Engineers . 46, 1-9.   \n10.1016/j.ece.2023.10.001. \nMcCall, K., Chagnon, B. 2022. Rethinking Alt Text to Improve Its \nEffectiveness. In: Miesenberger, K., Kouroupetroglou, G., \nMavrou, K., Manduchi, R., Covarrubias Rodriguez, M., Penáz, P. \n(eds) Computers Helping People with Special Needs. ICCHP -\nAAATE 2022. L ecture Notes in Computer Science, vol 13342. \nSpringer, Cham. https://doi.org/10.1007/978-3-031-08645-8_4. \nNielsen, J.; Landauer, T. K. 1993. A Mathematical Model of the \nFinding of Usability Problems. In Proceedings of the INTERACT \n’93 and CHI ’93 Conference on Human Factors in Computing Sys-\ntems; CHI ’93; Association for Computing Machinery: New York, \nNY, USA, 1993; pp 206–213. \nW3.org, Web Content Accessibility Guidelines 2.0, W3C World \nWide Web Consortium , (http://www.w3.org/TR/WCAG20/). Ac-\ncessed: 2023-11-25. \n \nhttps://doi.org/10.26434/chemrxiv-2023-r1qn9 ORCID: https://orcid.org/0000-0002-2774-796X Content not peer-reviewed by ChemRxiv. License: CC BY-NC-ND 4.0",
  "topic": "Interfacing",
  "concepts": [
    {
      "name": "Interfacing",
      "score": 0.7634718418121338
    },
    {
      "name": "Computer science",
      "score": 0.6766396760940552
    },
    {
      "name": "Usability",
      "score": 0.6585433483123779
    },
    {
      "name": "Diagram",
      "score": 0.4227980971336365
    },
    {
      "name": "Human–computer interaction",
      "score": 0.3684578537940979
    },
    {
      "name": "Programming language",
      "score": 0.32746267318725586
    },
    {
      "name": "Database",
      "score": 0.09218603372573853
    },
    {
      "name": "Computer hardware",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210119736",
      "name": "Dow Chemical (Canada)",
      "country": "CA"
    }
  ]
}