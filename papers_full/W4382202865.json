{
  "title": "TransPath: Learning Heuristics for Grid-Based Pathfinding via Transformers",
  "url": "https://openalex.org/W4382202865",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A4314136775",
      "name": "Daniil Kirilenko",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2551323365",
      "name": "Anton Andreychuk",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2117635438",
      "name": "Aleksandr Panov",
      "affiliations": [
        "Feed Control (Norway)"
      ]
    },
    {
      "id": "https://openalex.org/A2160972284",
      "name": "Konstantin Yakovlev",
      "affiliations": [
        "Institute of Chemistry, Komi Science Center"
      ]
    },
    {
      "id": "https://openalex.org/A4314136775",
      "name": "Daniil Kirilenko",
      "affiliations": [
        "Russian Academy of Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2551323365",
      "name": "Anton Andreychuk",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2117635438",
      "name": "Aleksandr Panov",
      "affiliations": [
        "Russian Academy of Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2160972284",
      "name": "Konstantin Yakovlev",
      "affiliations": [
        "Russian Academy of Sciences"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6740990346",
    "https://openalex.org/W3094502228",
    "https://openalex.org/W6859670669",
    "https://openalex.org/W6799166919",
    "https://openalex.org/W1969483458",
    "https://openalex.org/W6687483927",
    "https://openalex.org/W4281398962",
    "https://openalex.org/W4313034700",
    "https://openalex.org/W2891230096",
    "https://openalex.org/W6679896305",
    "https://openalex.org/W2793998795",
    "https://openalex.org/W6660982047",
    "https://openalex.org/W2992827186",
    "https://openalex.org/W6772987847",
    "https://openalex.org/W6766742000",
    "https://openalex.org/W3037270982",
    "https://openalex.org/W2964568892",
    "https://openalex.org/W6692405165",
    "https://openalex.org/W2946948417",
    "https://openalex.org/W6783625674",
    "https://openalex.org/W4310997257",
    "https://openalex.org/W2977840129",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2042872950",
    "https://openalex.org/W4213019189",
    "https://openalex.org/W4320930577",
    "https://openalex.org/W2194775991",
    "https://openalex.org/W2955425717",
    "https://openalex.org/W3086529737",
    "https://openalex.org/W3173651597",
    "https://openalex.org/W4300900294",
    "https://openalex.org/W3021208093",
    "https://openalex.org/W4293658271",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W4390204239",
    "https://openalex.org/W2995194170",
    "https://openalex.org/W2135835974"
  ],
  "abstract": "Heuristic search algorithms, e.g. A*, are the commonly used tools for pathfinding on grids, i.e. graphs of regular structure that are widely employed to represent environments in robotics, video games, etc. Instance-independent heuristics for grid graphs, e.g. Manhattan distance, do not take the obstacles into account, and thus the search led by such heuristics performs poorly in obstacle-rich environments. To this end, we suggest learning the instance-dependent heuristic proxies that are supposed to notably increase the efficiency of the search. The first heuristic proxy we suggest to learn is the correction factor, i.e. the ratio between the instance-independent cost-to-go estimate and the perfect one (computed offline at the training phase). Unlike learning the absolute values of the cost-to-go heuristic function, which was known before, learning the correction factor utilizes the knowledge of the instance-independent heuristic. The second heuristic proxy is the path probability, which indicates how likely the grid cell is lying on the shortest path. This heuristic can be employed in the Focal Search framework as the secondary heuristic, allowing us to preserve the guarantees on the bounded sub-optimality of the solution. We learn both suggested heuristics in a supervised fashion with the state-of-the-art neural networks containing attention blocks (transformers). We conduct a thorough empirical evaluation on a comprehensive dataset of planning tasks, showing that the suggested techniques i) reduce the computational effort of the A* up to a factor of 4x while producing the solutions, whose costs exceed those of the optimal solutions by less than 0.3% on average; ii) outperform the competitors, which include the conventional techniques from the heuristic search, i.e. weighted A*, as well as the state-of-the-art learnable planners. The project web-page is: https://airi-institute.github.io/TransPath/.",
  "full_text": "TransPath: Learning Heuristics For Grid-Based Pathfinding via Transformers\nDaniil Kirilenko1, Anton Andreychuk2, Aleksandr Panov1, 2, Konstantin Yakovlev1, 2\n1 Federal Research Center for Computer Science and Control of Russian Academy of Sciences, Moscow, Russia\n2 AIRI, Moscow, Russia\nanedanman@gmail.com, andreychuk@airi.net, panov@airi.net, yakovlev@isa.ru\nAbstract\nHeuristic search algorithms, e.g. A*, are the commonly used\ntools for pathfinding on grids, i.e. graphs of regular struc-\nture that are widely employed to represent environments in\nrobotics, video games, etc. Instance-independent heuristics\nfor grid graphs, e.g. Manhattan distance, do not take the ob-\nstacles into account, and thus the search led by such heuristics\nperforms poorly in obstacle-rich environments. To this end,\nwe suggest learning the instance-dependent heuristic prox-\nies that are supposed to notably increase the efficiency of the\nsearch. The first heuristic proxy we suggest to learn is the cor-\nrection factor, i.e. the ratio between the instance-independent\ncost-to-go estimate and the perfect one (computed offline at\nthe training phase). Unlike learning the absolute values of\nthe cost-to-go heuristic function, which was known before,\nlearning the correction factor utilizes the knowledge of the\ninstance-independent heuristic. The second heuristic proxy is\nthe path probability, which indicates how likely the grid cell\nis lying on the shortest path. This heuristic can be employed\nin the Focal Search framework as the secondary heuristic,\nallowing us to preserve the guarantees on the bounded sub-\noptimality of the solution. We learn both suggested heuristics\nin a supervised fashion with the state-of-the-art neural net-\nworks containing attention blocks (transformers). We conduct\na thorough empirical evaluation on a comprehensive dataset\nof planning tasks, showing that the suggested techniques i)\nreduce the computational effort of the A* up to a factor of4x\nwhile producing the solutions, whose costs exceed those of\nthe optimal solutions by less than0.3% on average;ii) outper-\nform the competitors, which include the conventional tech-\nniques from the heuristic search, i.e. weighted A*, as well as\nthe state-of-the-art learnable planners.\nThe project web-page is: https://airi-institute.github.io/\nTransPath/.\nIntroduction\nPath planning for a mobile agent in the static environment\nis a fundamental problem in AI that is often framed as a\ngraph search problem. Within this approach, first, an agent’s\nworkspace is discretized to a graph. Second, a search algo-\nrithm is invoked on this graph to find a path from start to\ngoal. Arguably, 2k-connected grids (Rivera et al. 2020) are\nthe most widely used graphs for path planning in a variety\nof applications (robotics, video games, etc.).\nCopyright © 2023, Association for the Advancement of Artificial\nMap A*\nPath probability map \n(PPM)\nFocal search \nwith PPM\nS\nG\nFigure 1: The difference between A* and our approach. The\nexpanded nodes are shown in green, while the path is high-\nlighted in red. Blue regions are predicted by the neural net-\nwork to contain path cells with high probability.\nPath planning on a grid is commonly accomplished by\na heuristic search algorithm, e.g. A* (Hart, Nilsson, and\nRaphael 1968) or one of its numerous modifications. Per-\nformance of such algorithms is heavily dependent on the in-\nput heuristic that comes in the form of a function that esti-\nmates the cost of the path to the goal for each node of the\ngraph (cost-to-go heuristic). If the heuristic is perfect, i.e.,\nfor every node its value equals the cost of the shortest path,\na search algorithm explores only the nodes that lie on one of\nthe minimum-cost paths. However, such a perfect heuristic\nis instance-dependent and cannot be encoded in the closed-\nloop form. In practice, instance-independent heuristics, e.g.\nManhattan distance, are typically used for grid-based path\nplanning. These heuristics do not take obstacles into account\nIntelligence (www.aaai.org). All rights reserved.\nThe Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI-23)\n12436\nand, consequently, perform poorly in obstacle-rich environ-\nments.\nOne of the recent and promising approaches to auto-\nmated construction of the instance-dependent heuristics (and\nfor path planning in general) is utilizing machine learning,\nspecifically, deep learning (Speck et al. 2021; Janner et al.\n2022). As grids can be viewed as the binary images, it is ap-\npealing to utilize the recent advances in convolutional neu-\nral networks (CNNs) (Ramachandran, Zoph, and Le 2017;\nTan and Le 2019) to extract the informative features from\nthe image representations of the pathfinding problems and\nembed these features into the heuristic search algorithm.\nFor example, in (Takahashi et al. 2019) it was suggested to\nlearn perfect cost-to-go heuristic in a supervised fashion. In\na more recent study (Yonetani et al. 2021), a more involved\napproach was introduced when a matrix-based A* was pro-\nposed and used for learning. Consequently, the deep neural\nnetwork model was trained end-to-end. That paper did not\npredict the conventional cost-to-go heuristic, but rather as-\nsigned the additional cost to each grid cell with the intuition\nthat unpromising nodes would be assigned a high cost by\nthe neural network. Thus, at the planning phase, the search\nwould avoid the cells with the high costs.\nIn this work, we follow the described paradigm and fur-\nther examine the ways of how heuristic search can benefit\nfrom state-of-the-art deep learning techniques in the context\nof the grid-based path planning. The distinguishable features\nof our work are as follows. We consider 8-connected grids\nwith non-uniform costs (i.e., diagonal moves cost more than\nthe cardinal ones), unlike the previous works that considered\nunit cost domains. We suggest learning the novel heuristic\nproxies for the problem at hand. Instead of learning to pre-\ndict the values of the perfect cost-to-go heuristic, we sug-\ngest learning the correction factor of the heuristic function,\nwhich is the ratio between the instance-independent heuris-\ntic and the perfect heuristic. Thus, a correction factor em-\nbeds information about both of these heuristics. Our empir-\nical evaluation confirms that learning the correction factor\nleads to a notably better performance than learning the ab-\nsolute values of the conventional cost-to-go heuristic.\nWe also suggest learning thepath probability map, which\nassigns to each grid cell the probability of belonging to the\nshortest path. This can be used as a secondary heuristic in the\nbounded sub-optimal search algorithm: Focal Search (Pearl\nand Kim 1982). Thus, we are able to preserve the theoreti-\ncal guarantees on a sub-optimality bound of the constructed\nsolution while speeding up the search, as our experiments\nshow.\nTo learn the correction factor and path probabilities, we\nutilize supervised deep learning. In doing so, We employ a\nneural network model, that is a combination of the convo-\nlutional encoder-decoder with the attention blocks (Vaswani\net al. 2017) (the so-called transformers). Such a combina-\ntion allows the neural network to capture and “reason about”\nboth the local features of a given map (corners of obstacles,\npassages etc.) and the relations between them, e.g. “there is\na passage between the two regions of interest”.\nTo evaluate the suggested techniques, a comprehensive\ndataset of the challenging planning tasks has been created\nthat extends the dataset previously used in closely related\nworks (Yonetani et al. 2021). We compare our approach with\nthose of the competitors that include both the deep learning\ntechniques and the traditional ones, and demonstrate its su-\nperiority in terms of the computational effort and solution\ncost. Overall, we have been able to reduce the computational\neffort compared to A* up to a factor of 4x while producing\nthe solutions, which costs exceed the costs of the optimal\nsolutions by less than 0.3% on average.\nRelated Work\nUtilizing machine learning for graph search in general and\ngrid-based pathfinding, in particular, has been getting in-\ncreased attention recently. In (Pogan ˇci´c et al. 2020) an ap-\nproach was presented that allows one to combine a learnable\nmodule with a non-learnable (classic) solver of a combinato-\nrial problem and train the pipeline end-to-end. The approach\nwas evaluated on several problems including pathfinding on\nthe grids, represented as images, where the transition costs\nare not known apriori. In (Li, Chen, and Koltun 2018), a\nlearning-based approach for solving certain NP-hard prob-\nlems was presented that exploited a graph convolutional net-\nwork to estimate the likelihood of whether a certain vertex\nof the graph is a part of the optimal solution. In (P ´andy\net al. 2022), a framework was proposed that suggests imita-\ntion learning-based heuristic search paradigm with a learn-\nable explored graph memory. In brief, it learns a repre-\nsentation that captures the structure of the so far explored\ngraph, so that it can then better select what node to explore\nnext. Such an approach can be viewed as solving a sequen-\ntial decision-making problem. Similar approaches were in-\ntroduced in (Tamar et al. 2016; Bhardwaj, Choudhury, and\nScherer 2017; Panov, Yakovlev, and Suvorov 2018). Special\ncare to the properties of the learned heuristics, i.e. admissi-\nbility, is given in (Li et al. 2022). Additionally, this work in-\ntroduces a version of A* search (Hart, Nilsson, and Raphael\n1968) that leverages parallel execution on graphical pro-\ncessing units (GPUs) that are widespread in machine learn-\ning computations. Analogous batch-handling techniques for\nheuristic search were considered in (Greco et al. 2022).\nThe papers that are especially relevant to this one\nare (Soboleva and Yakovlev 2019; Takahashi et al. 2019; Yo-\nnetani et al. 2021) as they all suggest specific machine learn-\ning techniques tailored to grid-based pathfinidng. In the for-\nmer a generative adversarial (neural) network is proposed to\ngenerate the solutions of the pathfinding instances. In (Taka-\nhashi et al. 2019) a convolutional neural network is used to\npredict the values of the cost-to-go heuristic. In (Yonetani\net al. 2021) Neural A* is introduced, which is a combination\nof the encoder-decoder predictor and a differentiable mod-\nule that imitates A* search on grids. The predictor is a neu-\nral network, which estimates the transition costs on the grid\nwith the intuition that transitions to unpromising parts of the\nmap should cost more. The presence of the differentiable A*\nmodule allows training the pipeline end-to-end. Neural A*\nwas empirically shown to consistently outperform a range of\ncompetitors for grid-based pathfinding. In this work, we use\nNeural A* as a baseline to compare with.\n12437\nBackground\nPathfinding Problem\nConsider a grid, Gr, composed of the blocked and free cells\nand two distinct free grid cells,start and goal. Being at any\nfree cell, an agent is allowed to move to one of its cardinally-\nor diagonally-adjacent neighboring cells, provided the latter\nis free. The cardinal moves incur the cost of 1, while the di-\nagonal ones incur the cost of\n√\n2. This setting can be referred\nto as the 8-connected grid with non-uniform costs.\nA path, π(start, goal), is a sequence of the adjacent cells,\nstarting with start and ending with goal: π = ( c0 =\nstart, c1, c2, . . . , cn = goal). A path is valid iff all the cells\nforming this path are free. The cost of the valid path is the\nsum of costs associated with the transitions between the cells\ncomprising the path: cost(π) = Pi=n−1\ni=0 cost(ci, ci+1).\nDenote a set of all valid paths connecting start and goal\nas Π. The least cost (shortest) path from start to goal is\nπ∗ ∈ Π, s.t. ∀π ∈ Π : cost(π∗) ≤ cost(π).\nThe pathfinding problem is a tuple (Gr, start, goal),\nwhich asks to find a valid path from start to goal on Gr.\nThe shortest path is said to be the optimal solution. Given a\npositive real number, w > 1, the bounded sub-optimal so-\nlution is a valid path whose cost exceeds that of the shortest\npath by no more than a factor ofw: cost(πw) ≤ w·cost(π∗).\nIn this work, we are specifically interested in obtaining\ni) valid paths; ii) bounded sub-optimal paths. The problem\nof obtaining optimal solutions is beyond the scope of this\npaper.\nA* Search\nA* is a heuristic search algorithm with strong theoretical\nguarantees that is widely used to solve the pathfinding prob-\nlems stated above. A* incrementally builds a search tree of\nnodes, where each node corresponds to a grid cell and bears\nthe additional search-related data. This data includes the g-\nvalue of the node, which is the cost of the path to the node\nfrom the root of the tree. h-value of the node is the heuristic\nestimate of the cost of the path from the current node to the\ngoal one. The sum of g- and h-values is called the f-value\nof the node.\nNodes are generated and added to the A* search tree via\nthe iterativeexpansions. To expand a node means to generate\nall of its valid successors, i.e., the successors that correspond\nto the valid moves on a grid, to compute their g-values (as\nthe sum of the g-value of the expanded node plus the transi-\ntion cost), and to add certain successors to the tree. A succes-\nsor is added to the tree only if it is not yet present in the tree\nor, alternatively, if the same node (i.e. the one corresponding\nto the same grid cell) exists, but itsg-value is greater than the\nnewly computed one.\nA* performs expansions in the systematic fashion (start-\ning with the start node). It maintains a list of nodes that\nhave been generated but not yet expanded. This list is typi-\ncally referred to as OPEN , while the list of the expanded\nnodes is designated as CLOSED . At each iteration, a node\nwith the minimal f-value is chosen from OPEN for the\nexpansion. A* stops when the goal node is extracted from\nOPEN . At this point, the sought path can be reconstructed\nusing the backpointers in the search tree.\nThe performance of the algorithm, i.e. the number of the\niterations before termination and the guarantees on the cost\nof the found path, is largely dependent on the used heuristic.\nHeuristics The heuristic is called perfect, denoted ash∗, if\nfor every node, its value equals the true cost-to-go:h∗(n) =\ncost(π∗(n, goal)). The heuristic is called admissible if it\nnever overestimates the true cost-to-go: h(n) ≤ h∗(n). The\nheuristic is said to be consistent or monotone if ∀n, n′ :\nh(n) ≤ h(n′) + cost(π∗(n, n′)).\nA range of consistent and admissible instance-\nindependent heuristics are known for the 8-connected\ngrids, e.g. Chebyshev distance, Euclidean distance, or\nOctile distance. They all can be efficiently computed in\nthe closed-loop form for any grid cell. Without the loss of\ngenerality, in this work, we assume that the Octile distance\nis used as the heuristic function.\nIt is known that A* with an admissible heuristic is guaran-\nteed to find the optimal solution. Moreover, if the heuristic is\nconsistent (as is in our case) it is not possible to find a better\npath to any of the expanded nodes, which infers that no node\ncan be expanded more than once. Still, the number of such\nexpansions can be significantly large as depicted in Fig. 1.\nThe reason is that the Octile distance, being an instance-\nindependent heuristic, is unaware of the blocked cells and\ndrives the search toward the obstacle via the lowf-values of\nthe nodes residing in its vicinity.\nWeighted A* and Focal Search\nWeighted A* One of the widespread ways to trade off\noptimality for the computational efficiency in grid-based\npathfinding is to employ a weighted heuristic, i.e. to order\nnodes in OPEN not by their g + h values, but rather by\ng + w · h values, where w ≥ 1. Such a modification of A*,\ntypically referred to as W A* (Weighted A*), is known to\nprovide bounded sup-optimal solutions w.r.t.w.\nFocal Search Focal Search (FS) (Pearl and Kim 1982) is\nanother technique tailored to lower the number of search\niterations while providing the bound on the optimally of\nthe resultant solution. In FS, an additional list of nodes is\nmaintained called FOCAL . It is formed of the nodes re-\nsiding in OPEN , whose f-values do not exceed the min-\nimum f-value in OPEN , fmin, by a factor of w (given\nthe sub-optimality bound). FOCAL is ordered in accor-\ndance with the secondary heuristic, hFOCAL , which does\nnot have to be consistent or even admissible. The node to be\nexpanded is chosen from FOCAL in accordance with the\nordering imposed by hFOCAL (and removed from OPEN\nas well). In case OPEN is updated as a result of the expan-\nsion, FOCAL is modified accordingly. The stop criterion is\nthe same as in A*. FS is guaranteed to obtain bounded sup-\noptimal solutions. Indeed, the number of search iterations\nand, thus, the computational efficiency of FS is strongly de-\npendent on hFOCAL .\nFig. 2 shows the pseudocode of a generic heuristic search\nalgorithm. Different colors correspond to different variants\nof the algorithm as explained in the caption.\n12438\nAlgorithm 1:A generic search algorithm.\nInput: Grid Gr, start node, goal node,\nheuristic functionh, sub-optimality\nfactor w, hFOCAL – secondary heuristic\nfor Focal Search\nOutput: path π\n1 g(start) := 0;∀n̸= start g(n) :=∞\n2 OPEN := {start}; CLOSED := ∅\n3 while OPEN ̸= ∅do\n4 n:= GetBestNode(OPEN , FOCAL,\nhFOCAL )\n5 remove n from OPEN and FOCAL\n6 insert n into CLOSED\n7 if fmin has changed then\n8 update FOCAL\n9 if n is goal then\n10 return ReconstructPath(n)\n11 for each n’ in GetSuccessors(Gr,n)do\n12 if g(n′) >g(n) +cost(n,n′) then\n13 g(n′) :=g(n) +cost(n,n′)\n14 f(n′) :=g(n′)+w·h(n′)/w(n′)\n15 update or insertn′ in OPEN\n16 if f(n′) ≤w·fmin then\n17 update or insertn′ in FOCAL\n18 return path not found\nFigure 2: A generic search algorithm. A* executes black\nparts only. W A* is shown in black and red, Focal Search\nin black and purple, our variant of W A* in black and blue.\nMethod\nRecall that we are interested in two variants of the pathfind-\ning problem. The first variant asks to find a valid path on a\ngrid, without specifying any constraints on the cost of the\npath, VP- PROBLEM . The second variant assumes that a sub-\noptimality bound, w ≥ 1, is specified and the task is to find\na path whose cost does not exceed the cost of the optimal\npath by more than a factor of w, BSP- PROBLEM .\nThe solvers that we suggest for both problems share their\nstructure. Each of them is composed of the two building\nblocks. First, a deep neural network is used to process the\ninput grid and to predict the values of the heuristic function\nthat will be used later. Second, a heuristic search algorithm\nis invoked that utilizes the heuristic data from the neural net-\nwork. The neural network used for VP-PROBLEM and BSP-\nPROBLEM has the same architecture; however, in each case,\nthe output heuristic is different. The heuristic search algo-\nrithm is also different. For solving VP-PROBLEM , we utilize\nW A*, while for BSP-PROBLEM , Focal Search (FS) is used.\nHeuristics Learned\nThe first type of the heuristic is the correction factor (cf),\nwhich is defined as the ratio of the value of the avail-\nable instance-independent heuristicto the value of the per-\nfect heuristic: cf(n) = h(n)/h∗(n). We suggest plugging\nthe predicted cf-values into the W A* algorithm as shown in\nFig. 2 (black + blue code fragments). I.e., the f-value of a\nnode is computed as f(n) = g(n) + h(n)/cf(n). This can\nbe thought of as running W A* that uses individual weights\nfor the search nodes. As there is no theoretical bound on the\nerror of predicting cf-values, the resultant search algorithm\nprovides no guarantees on the resultant cost.\nIn general, predicting cf-values may seem similar to pre-\ndicting the values of the perfect cost-to-go heuristic as was\nproposed in (Takahashi et al. 2019). However, there exists a\ncrucial difference, which is twofold. First, when learning the\ncost-to-go heuristic, an additional technical step is needed\nthat transfers the range of the heuristic to the range typi-\ncally employed in deep learning, e.g. [0, 1]. Meanwhile, the\nrange of the introduced correction factor is [0, 1] by design;\nthus, no auxiliary transformations are required. Second, the\ncorrection factor encompasses more heuristic data, as it\nis a combination of both instance-dependent and instance-\nindependent heuristics. As confirmed by our experiments,\nlearning cf-values instead of h∗-values leads to a notable\nboost in the performance.\nThe second suggested heuristic is tailored to serve as\nthe secondary heuristic for the FS, hFOCAL , which is em-\nployed to solve the BSP- PROBLEM . Intuitively, we want\nfrom hFOCAL to distinguish the nodes that are likely to\nyield rapid progress toward the goal. To this end, we suggest\nassigning (and learning to predict) a value to each grid cell\nthat tells us how likely it is that this cell lies on the shortest\npath between start and goal. We call this value apath prob-\nability, pp-value, and, by design, its range is within [0, 1].\nLearning to correctly predict pp − values may be thought\nof as attempting to learn to solve the pathfinding queries di-\nrectly. I.e., if we were able to obtain such predictions for\nwhere pp-values of 1 were assigned to the cells lying on the\nshortest path, while the other cells were assigned pp-values\nof 0, then we would not need to run the search algorithm at\nall. However, in practice, this is not realistic, and thus, we\nuse the predicted pp-values as hFOCAL values in the FS.\nLearning Supervision\nAn evident approach to learning the suggested heuristics is\nto create a rich dataset of pathfinding instances with the an-\nnotated ground-truth cf- and pp-values and to train the neu-\nral network to minimize the error between its predictions and\nthe ground-truth values. Using the techniques introduced\nin (Pogan ˇci´c et al. 2020; Yonetani et al. 2021), one might\nconsider another option of learning, i.e. including the search\nalgorithm in the learning pipeline and to back-propagating\nthe search error through it. This option is especially useful\nwhen it is hard or impossible to create ground-truth sam-\nples (like in planning on images when the cost of the tran-\nsition is unknown). We have experimented with both types\nof learning and found that for our setting, the first option is\npreferable for the following reasons. First, there is no prob-\nlem to create ground-truth samples for cf- and pp-values\n(technical details on this will follow shortly). Second, learn-\ning without differentiable planner is much faster (up to 4x in\nour setup). Third and not least of all, our experiments have\nshown that learning the suggested model with the supervi-\nsion from the ground-truth values leads to a consistently bet-\nter performance.\n12439\nConv2D ResNet\nBlock Downsample\n× 3 times\nTransformer \nBlock\n× 4 \ntimes\n+ Positional \nEmbeddings\nResNet\nBlockUpsample\n× 3 times\nConv2D\ninput map\n(H, W, 2)\noutput PPM\n(H, W, 1)\n(H/8, W/8, 64)\n+ Positional \nEmbeddings\nGroupNorm\nSwish \nactivation\nConv2D\n× 2 \ntimes\nLayerNorm\nMulti-Head \nSelfAttention\nLayerNorm\nFeed-Forward \nLayer\n× 2 \ntimesa) c)b)\n(H, W, 64)\nEncoder\nDecoder\nFigure 3: Overview of the neural network architecture. a) Design of the whole model. CNN encoder is used to produce local\nfeatures which are further fed into the transformer blocks to catch the long-range dependencies between the features. The\nresulting representation is passed through the CNN decoder to produce output values. b) Architecture of the ResNet block. c)\nArchitecture of the Transformer block.\nTo create ground-truth cf-values, we utilized uninformed\nsearch that starts backwards from the goal and computes\ntrue distances to it from any cell (which are straightfor-\nwardly converted to the cf-values). Creating the ground-\ntruth samples of pp-values (we refer to such samples as\npath probability maps, or PPMs) is more involved. Recall\nthat in PPMs, we need to have values of 1 for the cells ly-\ning on the shortest path while all other cells should have\nsmaller values. However, numerous shortest paths on 8-\nconnected grids might exist, which differ only in the order\nof the cardinal/diagonal moves. To break the symmetry we\nran Theta* (Nash et al. 2007), an any-angle search algorithm\nthat can be thought of as A* with online path smoothing.\nTheta* paths are formed of the way points (cells) located at\nthe corners of the obstacles and cells that lie on the straight-\nline segments connecting the way points. In the resultant\nPPM, we assigned the values of 1 for such paths. For all\nother cells, we computed the value that tells us how close\nthe cost of the path through cell n to the one of Theta* is:\ncost(π(s, g)/(cost(π(s, n)+cost(π(n, g)). If this value was\ngreater than or equal to 0.95, we used it as the pp-value; if\nnot, the pp-value was set to0. As a result, we obtained PPMs\nthat contain paths from start to goal and narrow tunnels\n(with lower pp-values) around them (see Fig. 1).\nNeural Network Architecture\nThe neural network for learningcf-values and pp-values has\nthe same architecture; however, the input is slightly differ-\nent. For pp-values, the input contains the grid (as binary im-\nage) and the start-goal matrix of the same dimensions, which\ncontains the values of 1 only for start and goal, while all\nother pixels are zeroes. For cf-values, this matrix contains\nonly one non-zero element: the goal one.\nThe architecture has three main blocks (see Fig. 3): a\nconvolutional encoder, a spatial transformer, and a convolu-\ntional decoder. The convolutional encoder utilizes the well-\nknown ResNet blocks (He et al. 2016) and is aimed at ex-\ntracting the local features of the pathfidning instance such\nas corners of the obstacles, narrow passages etc. The trans-\nformer leverages the mechanism of self-attention (Vaswani\net al. 2017) to establish the global relations between these\nfeatures (how important is one feature w.r.t. the other). An\nexample may be how important it is that there is a narrow\npassage in between start and goal. Transformers were orig-\ninally suggested for text sequences that lack 2D structure.\nHowever, in the considered case, this structure is impor-\ntant. To this end, we utilize the positional embedding tech-\nnique from Visual Transformers (Dosovitskiy et al. 2021;\nHan et al. 2022). This technique re-arranges 2D feature maps\ninto vectors (before the transformer block) and vice versa\n(afterward), while preserving the spatial structure. Finally,\nthe transformed feature maps are processed by the convolu-\ntional decoder, which provides the final output.\nTraining and Evaluation\nDataset\nWe have adopted the TMP (Tiled Motion Planning) dataset\nthat was used in (Yonetani et al. 2021) for empirical eval-\nuation. This dataset is a modification of the MP dataset\nused in (Bhardwaj, Choudhury, and Scherer 2017). The lat-\nter consists of maps with various challenging topologies,\nsuch as bugtraps, gaps, etc. Each map in the TMP dataset\nis composed of the four MP maps. In total, 4, 000 maps of\nsize 64 × 64 were present in TMP. We further increased\nthe size of the dataset to 64, 000 maps via the augmen-\ntation by mirroring and rotating each of the four parts of\nthe TMP maps. Examples are shown in Fig. 4. For each\nmap, we generated 10 problem instances. The goal was cho-\nsen randomly, the start was chosen randomly out of the\n1/3 of the reachable nodes that have the highest cost of\n12440\nA* WA* A* + HL WA* + CF predicted PPMFS + PPM (w=2) GBFS + PPM\nNeuralA*\nFigure 4: Several examples of the pathfinding results. The expanded nodes are shown in green, and the path in red. The last\ncolumn shows the predicted PPMs.\nthe path from the goal. Overall, we generated 640, 000 in-\nstances. They were divided in the proportion of 8:1:1 for\ntrain, validation, and test subsets in such a way that all aug-\nmented versions of the same map were presented only in\none of the subsets. Similarly to (Takahashi et al. 2019),\nwe have excluded from the test part of the dataset the in-\nstances that are extremely easy to solve, formally, the ones\nthat have hardness less than 1.05. Here hardness is defined\nas cost(π∗(start, goal))/h(start), where h is the conven-\ntional cost-to-go heuristic. The closer this value is to1.0, the\neasier the instance is, meaning that there is almost no need to\nbypass the obstacles and the path resembles a straight line.\nPlanners\nWe denote the planners1 proposed in this work as W A*+CF\n(Weighted A* with the correction factor), FS+PPM (Focal\nSearch with Path Probability Map). We also evaluated a\ncombination of the Greedy Best First Search with PPM, de-\nnoted as GBPS+PPM. This planner greedily selects nodes\nby their pp-values (preferring the ones with the smaller f-\nvalues to break ties) and, thus, does not guarantee bounded\nsupoptimality of the solution.\nThe baselines that we compare against include both stan-\ndard heuristic search algorithms, A* and W A*, as well\nas the learnable ones. The latter are represented by the\ntwo planners. The first one is Neural A* (Yonetani et al.\n2021), the state-of-the-art planner that was shown to no-\ntably outperform a range of competitors including the ap-\nproaches presented in (Bhardwaj, Choudhury, and Scherer\n2017; Poganˇci´c et al. 2020) The second is the planner from\n(Takahashi et al. 2019), which predicts the perfect cost-to-go\nheuristic and use it in A*. We denote it as A*+HL.\nWe used the official code of Neural A* and modified it\nto handle non-uniform move costs. Moreover, we employed\nour neural network model in Neural A* to provide a fairer\ncomparison (the performance of Neural A* with the origi-\nnal neural network was significantly worse). Similarly, we\nused our neural network for predicting cost-to-go heuristic\nin A*+HL. For bounded sub-optimal planners, i.e. W A* and\n1The source code of our planners is publicly available at https:\n//www.github.com/AIRI-Institute/TransPath\nOptimal F\nound Cost Expansions\nRatio (\n%) ↑ Ratio (%) ↓ Ratio (%) ↓\nA* 100 100 100\nW\nA* 40.66 103.52 ±4.85\n44.43 ±25.92\nNeural A* 29.82 104.90 ±6.56\n52.30 ±30.47\nA*+HL 79.11 100.27 ±0.62\n80.50 ±74.40\nW A*+CF 85.40 100.25 ±1.13 36.98 ±21.18\nFS+PPM 82.97 100.24 ±0.74 26.36 ±21.08\nGBFS+PPM 83.02 100.25 ±0.90 23.60 ±18.34\nTable\n1: Experimental results. Values before ± indicate the\naverage, while after ± – the standard deviation.\nFS+PPM, we set the sub-optimality factor as w = 2, as this\nvalue provided the best trade-off between path length and\ncomputation time for W A*.\nTraining Setup\nTo train the neural networks predictingcf-values, pp-values\nand cost-to-go estimates (for A*+HL), we use the same\nsetup. We train each model using Adam optimizer (Kingma\nand Ba 2014) for 35 epochs with a batch size of 512\nand OneCycleLR learning rate scheduler (Smith and Topin\n2018) at a maximum learning rate of 4 × 10−4. We use L2\nloss for cf-values, pp-values and L1 loss for the cost-to-go\nestimates following (Takahashi et al. 2019). It took us 3.5\nhours to train each model on NVIDIA A100 80GB GPU.\nWe trained Neural A* on our training data with the same\ntraining setup as in the original work. It took us 16 hours to\nlearn the model on our hardware, four times more compared\nto cf-/pp-values. This is expected, as Neural A* is trained\nwith the differentiable A* in the loop.\nResults\nWe were primarily interested in the following performance\nmetrics: Expansions Ratio – the ratio of the number of ex-\npansions performed by the planner to the number of A* ex-\npansions; Cost Ratio – the same ratio but for the solution\ncost; and Optimal Found Ratio – the ratio of instances opti-\nmally solved by the planner.\nTable 1 shows the average values and standard error of\nthese indicators for the test dataset, while Fig. 4 highlights\n12441\nFS+PPM (\nw = 4) w/ T\nrans w/o Trans\nOptimal F\nound Ratio (%) 85.22 61.74\nA\nverage Cost Ratio (%) 100.31 ± 1.58 101.12 ± 2.19\nA\nverage Expansions Ratio (%) 16.06 ± 11.57 19.65 ± 17.03\nMSE ×10−3 3.2 5.3\nTable\n2: Ablation study results. Values before± indicate the\naverage, while after ± – the standard deviation.\nseveral test instances with the solutions obtained by the eval-\nuated algorithms and the nodes they expand. Clearly, all the\nlearning-based planners are able to generalize to the un-\nseen instances solving them near-optimally while reducing\nthe search effort. In terms of Cost Ratio, the best results\nwere demonstrated by FS+PPM, while the other our planner,\nW A*+CF, turned out to outperform the competitors in terms\nof number of the instances solved optimally. The number\nof reduced expansions varied significantly for all algorithms\n(see the third column after the± sign), and, evidently, in cer-\ntain cases one of the learnable planners, i.e. A*+HL, man-\naged to expand more nodes than A*. Still, the techniques\nsuggested in this work, in particular, predicting pp-values\nin combination with FS and GBFS, managed to reduce the\nnumber of the expansions significantly (up to four times ap-\nproximately) in numerous cases, as the average value of the\nExpansions Ratio tells us.\nRuntime breakdown We measured the runtime of the\ncompared methods, though it is heavily dependent on the im-\nplementation and the hardware. E.g. Neural A* is fully im-\nplemented in Python, while our planners feature both Python\nfor neural networks’ machinery and C++ for the search.\nThus, it is not correct to directly compare their runtimes. To\nthis end, we do not report the runtime of Neural A*. As for\nthe other methods (implemented solely by us), the break-\ndown of their runtimes are as follows. The prediction step\nfor the batch size of 64 and the native torch float32 type\nrequired 9.5ms on Tesla A100 GPU (and 40ms on GTX\n1660S). The average CPU time required for further solving\nthis batch of 64 tasks: A* – 155ms, W A* – 77ms, W A*+CF\n– 60ms, A*+HL – 96ms, FS+PPM – 37ms, GBFS+PPM –\n31ms.\nEvaluation on Out-of-the-Distribution Dataset\nWe additionally evaluated all the considered planners on a\nrange of maps that differ significantly in topology and size\nfrom the maps of TMP dataset (without any additional train-\ning). For extra details and results of this experiment, see the\narXiv version of the paper 2. Overall, the results are simi-\nlar to the ones reported above: our methods outperform the\ncompetitors.\nAblation Study\nTo demonstrate the importance of using the Transformer\nblock in the neural network, we created a version of the lat-\nter that omits this block and is composed only of the con-\nvolutional layers (CNN model). We trained this neural net-\nwork similarly to the baseline model. To compare them, we\n2https://arxiv.org/abs/2212.11730\nCNN model Transformer\nPath probability mapSearch results\nFigure 5: An example showing the difference between the\nCNN (only) model and the one with the Transformer block.\nselected tasks with the hardness exceeding 1.5 as we hy-\npothesize that utilizing transformer is especially useful for\nnon-trivial instances. Quantitative results are presented in\nTable 2, while qualitative results are given in Fig. 5 (for the\nsake of space we demonstrate the results for FS+PPM only,\nas the results for W A*+CF are similar).\nClearly, the usage of Tansformer block notably increases\nthe performance across all of the considered metrics, as Ta-\nble 2 tells us. The last row reports the mean squared error\n(MSE) between the predictions of the neural network and\nthe ground-truth values.\nAs Fig. 5 shows, transformer allows us to capture the\nlong-range dependencies between the regions of interest on\nthe map and, consequently, to form a complex and accu-\nrate PPM, which aids the search algorithm substantially. The\nPPM of the CNN model is, however, fragmented, and, as\na result, a less natural-looking path is produced while the\nnumber of expansions is higher.\nConclusion\nIn this work, we have explored how state-of-the-art deep\nlearning techniques may aid heuristic search planners in\nsolving grid-based pathfinding problems. We have suggested\nutilizing a deep neural network composed of both convolu-\ntional and attention layers to predict several novel heuristics\nthat can be used in combination with Weighed A* and Focal\nSearch. We have shown empirically that the suggested plan-\nners were able to successfully solve challenging problems\n(unseen at the training phase) and outperform the competi-\ntors that include both traditional heuristic search techniques\nas well as the state-of-the-art learnable approaches.\nThe avenues for future research include, but are not lim-\nited to, planning in 3D, planning with kinodynamic con-\nstraints (including sample-based planning), etc.\n12442\nAcknowledgments\nWe would like to thank anonymous reviewers for their\nthoughtful comments that contributed to improving the pa-\nper. We would also like to thank Natalia Soboleva, Alexei\nArtemov, and Vasilii Davydov for their involvement in the\npreliminary studies on the topic of the paper.\nReferences\nBhardwaj, M.; Choudhury, S.; and Scherer, S. 2017. Learn-\ning heuristic search via imitation. In Proceedings of The 1st\nConference on Robot Learning (CoRL 2017), 271–280.\nDosovitskiy, A.; Beyer, L.; Kolesnikov, A.; Weissenborn,\nD.; Zhai, X.; Unterthiner, T.; Dehghani, M.; Minderer, M.;\nHeigold, G.; Gelly, S.; Uszkoreit, J.; and Houlsby, N. 2021.\nAn Image is Worth 16x16 Words: Transformers for Im-\nage Recognition at Scale. In Proceedings of The 9th In-\nternational Conference on Learning Representations (ICLR\n2021).\nGreco, M.; Toro, J.; Hern ´andez-Ulloa, C.; and Baier, J. A.\n2022. K-Focal Search for Slow Learned Heuristics. In Pro-\nceedings of The 15th International Symposium on Combina-\ntorial Search (SoCS 2015), 279–281.\nHan, K.; Wang, Y .; Chen, H.; Chen, X.; Guo, J.; Liu, Z.;\nTang, Y .; Xiao, A.; Xu, C.; Xu, Y .; Yang, Z.; Zhang, Y .; and\nTao, D. 2022. A Survey on Vision Transformer.IEEE Trans-\nactions on Pattern Analysis and Machine Intelligence, 1–1.\nHart, P. E.; Nilsson, N. J.; and Raphael, B. 1968. A for-\nmal basis for the heuristic determination of minimum cost\npaths. IEEE transactions on Systems Science and Cybernet-\nics, 4(2): 100–107.\nHe, K.; Zhang, X.; Ren, S.; and Sun, J. 2016. Deep Residual\nLearning for Image Recognition. InProceedings of The 29th\nIEEE Conference on Computer Vision and Pattern Recogni-\ntion (CVPR 2016), 770–778.\nJanner, M.; Du, Y .; Tenenbaum, J.; and Levine, S. 2022.\nPlanning with Diffusion for Flexible Behavior Synthesis. In\nProceedings of The 39th International Conference on Ma-\nchine Learning (ICML 2022), 9902–9915.\nKingma, D. P.; and Ba, J. 2014. Adam: A method for\nstochastic optimization. arXiv preprint arXiv:1412.6980.\nLi, T.; Chen, R.; Mavrin, B.; Sturtevant, N. R.; Nadav, D.;\nand Felner, A. 2022. Optimal Search with Neural Networks:\nChallenges and Approaches. In Proceedings of The 15th\nInternational Symposium on Combinatorial Search (SoCS\n2015), 109–117.\nLi, Z.; Chen, Q.; and Koltun, V . 2018. Combinatorial Op-\ntimization with Graph Convolutional Networks and Guided\nTree Search. Proceedings of The 32nd Conference on Neu-\nral Information Processing System (NeurIPS 2018).\nNash, A.; Daniel, K.; Koenig, S.; and Felner, A. 2007.\nTheta*: Any-Angle Path Planning on Grids. In Proceed-\nings of The 22nd AAAI Conference on Artificial Intelligence\n(AAAI 2007), 1177–1183.\nP´andy, M.; Qiu, W.; Corso, G.; Veli ˇckovi´c, P.; Ying, Z.;\nLeskovec, J.; and Lio, P. 2022. Learning Graph Search\nHeuristics. In Proceedings of The 1st Learning on Graphs\nConference (LoG 2022), 10:1–10:13.\nPanov, A. I.; Yakovlev, K. S.; and Suvorov, R. 2018. Grid\npath planning with deep reinforcement learning: Preliminary\nresults. Procedia computer science, 123: 347–353.\nPearl, J.; and Kim, J. H. 1982. Studies in semi-admissible\nheuristics. IEEE transactions on pattern analysis and ma-\nchine intelligence, (4): 392–399.\nPoganˇci´c, M. V .; Paulus, A.; Musil, V .; Martius, G.; and Ro-\nlinek, M. 2020. Differentiation of blackbox combinatorial\nsolvers. In Proceedings of The 8th International Conference\non Learning Representations (ICLR 2020).\nRamachandran, P.; Zoph, B.; and Le, Q. V . 2017. Searching\nfor activation functions. arXiv preprint arXiv:1710.05941.\nRivera, N.; Hern´andez, C.; Hormaz´abal, N.; and Baier, J. A.\n2020. The 2ˆ k Neighborhoods for Grid Path Planning.Jour-\nnal of Artificial Intelligence Research, 67: 81–113.\nSmith, L. N.; and Topin, N. 2018. Super-Convergence: Very\nFast Training of Residual Networks Using Large Learning\nRates. arXiv preprint arXiv:1708.07120.\nSoboleva, N.; and Yakovlev, K. 2019. GAN Path Finder:\nPreliminary Results. In Proceedings of the 42nd German\nConference on AI (KI 2019), 316–324.\nSpeck, D.; Biedenkapp, A.; Hutter, F.; Mattm ¨uller, R.; and\nLindauer, M. 2021. Learning Heuristic Selection with Dy-\nnamic Algorithm Configuration. In Proceedings of The\n31st International Conference on Automated Planning and\nScheduling (ICAPS 2021), 597–605.\nTakahashi, T.; Sun, H.; Tian, D.; and Wang, Y . 2019. Learn-\ning heuristic functions for mobile robot path planning using\ndeep neural networks. In Proceedings of The 29th Interna-\ntional Conference on Automated Planning and Scheduling\n(ICAPS 2019), 764–772.\nTamar, A.; Wu, Y .; Thomas, G.; Levine, S.; and Abbeel, P.\n2016. Value iteration networks. In Proceedings of The 30th\nInternational Conference on Neural Information Processing\nSystems (NeurIPS 2016), 2154–2162.\nTan, M.; and Le, Q. 2019. Efficientnet: Rethinking model\nscaling for convolutional neural networks. In Proceedings\nof The 36th International conference on machine learning\n(ICML 2019), 6105–6114.\nVaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones,\nL.; Gomez, A. N.; Kaiser, Ł.; and Polosukhin, I. 2017. At-\ntention is all you need. In Proceedings of the 31st Confer-\nence on Neural Information Processing Systems (NeurIPS\n2017).\nYonetani, R.; Taniai, T.; Barekatain, M.; Nishimura, M.; and\nKanezaki, A. 2021. Path Planning Using Neural A* Search.\nIn Proceedings of The 38th International Conference on Ma-\nchine Learning (ICML 2021), 12029–12039.\n12443",
  "topic": "Pathfinding",
  "concepts": [
    {
      "name": "Pathfinding",
      "score": 0.7525852918624878
    },
    {
      "name": "Heuristics",
      "score": 0.748304545879364
    },
    {
      "name": "Computer science",
      "score": 0.6645545363426208
    },
    {
      "name": "Consistent heuristic",
      "score": 0.6360979080200195
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5868500471115112
    },
    {
      "name": "Heuristic",
      "score": 0.5783637762069702
    },
    {
      "name": "Grid",
      "score": 0.5249894857406616
    },
    {
      "name": "Incremental heuristic search",
      "score": 0.4909837543964386
    },
    {
      "name": "Null-move heuristic",
      "score": 0.4863441586494446
    },
    {
      "name": "Machine learning",
      "score": 0.48315519094467163
    },
    {
      "name": "Shortest path problem",
      "score": 0.43694180250167847
    },
    {
      "name": "Mathematical optimization",
      "score": 0.39608049392700195
    },
    {
      "name": "Theoretical computer science",
      "score": 0.2698666453361511
    },
    {
      "name": "Algorithm",
      "score": 0.2647184729576111
    },
    {
      "name": "Beam search",
      "score": 0.26169633865356445
    },
    {
      "name": "Search algorithm",
      "score": 0.24091914296150208
    },
    {
      "name": "Mathematics",
      "score": 0.20906871557235718
    },
    {
      "name": "Graph",
      "score": 0.10567641258239746
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Geometry",
      "score": 0.0
    }
  ]
}