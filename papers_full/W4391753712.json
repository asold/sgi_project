{
    "title": "Religion, Theology, and Philosophical Skills of LLM–Powered Chatbots",
    "url": "https://openalex.org/W4391753712",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2708420955",
            "name": "Marcin Trepczyński",
            "affiliations": [
                "University of Warsaw"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2766950054",
        "https://openalex.org/W7056494467",
        "https://openalex.org/W3035426706",
        "https://openalex.org/W1906276607"
    ],
    "abstract": "In this study, I demonstrate how religion and theology can be useful for testing the performance of LLMs or LLM–powered chatbots, focusing on the measurement of philosophical skills. I present the results of testing four selected chatbots: ChatGPT, Bing, Bard, and Llama2. I utilize three examples of possible sources of inspiration from religion or theology: 1) the theory of the four senses of Scripture; 2) abstract theological statements; 3) an abstract logic formula derived from a religious text, to show that these sources are good materials for tasks that can effectively measure philosophical skills such as interpretation of a given fragment, creative deductive reasoning, and identification of ontological limitations. This approach enabled sensitive testing, revealing differences among the performances of the four chatbots. I also provide an example showing how we can create a benchmark to rate and compare such skills, using the assessment criteria and simplified scales to rate each chatbot with respect to each criterion.",
    "full_text": "19\nRELIGION, THEOLOGY , AND \nPHILOSOPHICAL SKILLS OF\nLLM–POWERED CHATBOTS\nMarcin Trepczyński\nDISPUTATIO PHILOSOPHICA · Vol 25. · No. 1 · 19–36\n* Marcin Trepczy ński PhD, Assistant professor, Faculty of Philosophy, University of Warsaw, \n3 Krakowskie Przedmieście St. Warsaw, 00–047 Poland. E–mail: m.trepczynski@uw.edu.pl\n ORCID iD: https://orcid.org/0000–0003–0612–2597\n** This research was supported by the University of Oxford project “New Horizons for Sci-\nence and Religion in Central and Eastern Europe” funded by the John Templeton Founda-\ntion. The opinions expressed in the publication are those of the author and do not neces-\nsarily reflect the view of the John Templeton Foundation. \nUDC [004.8:81’322]:2\n004.8:81’322:[1:159.928]\nhttps://doi.org/10.32701/dp.25.1.2\nOriginal scientific paper\nReceived: 3.1.2024\nAccepted: 18.1.2024\nAbstract\nIn this study, I demonstrate how religion and theology can be useful for test-\ning the performance of LLMs or LLM–powered chatbots, focusing on the meas-\nurement of philosophical skills. I present the results of testing four selected \nchatbots: ChatGPT, Bing, Bard, and Llama2. I utilize three examples of possible \nsources of inspiration from religion or theology: 1) the theory of the four senses \nof Scripture; 2) abstract theological statements; 3) an abstract logic formula de-\nrived from a religious text, to show that these sources are good materials for \ntasks that can effectively measure philosophical skills such as interpretation of \na given fragment, creative deductive reasoning, and identification of ontologi-\ncal limitations. This approach enabled sensitive testing, revealing differences \namong the performances of the four chatbots. I also provide an example showing \nhow we can create a benchmark to rate and compare such skills, using the as-\nsessment criteria and simplified scales to rate each chatbot with respect to each \ncriterion.\nK\nEYWORDS: large language models, chatbots, testing, philosophical skills, reli-\ngion, theology, interpretation, reasoning\n Introduction\nChatbots powered by large language models (LLMs) nowadays accompany \nus in everyday life and work. One of the major problems we face when using \ngenerative AI is the reliability of output. Hence, it is essential to understand \nMarcin Trepczyński: Religion, Theology, and Philosophical ... DISPUTATIO PHILOSOPHICA · Vol 25. · No. 1 · 19–36\n20\nthe real performance of specific chatbots, including both their capabilities \nand limitations. In this article, I will demonstrate how religion and theology \ncan be useful for testing LLMs’ or LLMs–powered chatbots’ performance.\nThere are different benchmarks for evaluating the performance of lan-\nguage models concerning general language skills. One of them is the General \nLanguage Understanding Evaluation (GLUE) benchmark introduced in 2018 \n(Wang et al., 2019). It takes into account 21 aspects of understanding, grouped \ninto four categories: lexical semantics, predicate–argument structure, logic, \nknowledge, and common sense. In response to the growing performance \nof LLMs, more challenging benchmarks have been developed, such as the \nBeyond the Imitation Game Benchmark (BIG–Bench), which includes over \n200 diverse text–based tasks (Srivastava et al. 2022). The task categories in-\nclude traditional natural language processing, mathematics, commonsense \nreasoning, and question–answering. In many cases, LMMs outperform the \naverage human rater. Researchers from California have recently shown that \nit is crucial to focus more on the tasks in which LMMs perform worse. They \nused BIG–Bench Hard (BBH), “a subset of 23 challenging BIG–Bench tasks \non which prior language models fell short of average reported human–rater \nperformance” to demonstrate that “answer–only prompting underestimates \nmodel capabilities” and chain of thought (CoT) prompting “enables the most \ncapable Codex model to outperform the average human–rater baseline on 17 \nout of 23 tasks in BBH” (Suzgun et al., 2023).\nHowever, these benchmarks do not cover all the important skills neces-\nsary to perform advanced tasks. Consequently, more benchmarks focusing \non specific capabilities should be developed. \nI contend that religion and theology offer interesting possibilities for \ntesting the capacities of AI chatbots, encompassing both lower— and high-\ner–order skills according to Bloom’s Taxonomy (Bloom 1956). They provide \nspecific material that aids in comparing such skills across different chatbots. \nMy additional hypothesis is that other branches of knowledge are unlikely \nto provide similar material. \nIn the subsequent sections, I will present three examples of inspiration \nfrom the field of religion and theology. All the cases are derived from my \nstudy, which is part of the project “Testing AI as a Rational Theologian,” \naimed at determining the extent to which AI–based chatbots can function \nas reliable and rational theologians. This study was intended to test and \nrefine methodology and tasks for the final testing and to create a benchmark \nthat will serve as a reference point for future testing regarding theological \nskills. Four leading chatbots were: ChatGPT by OpenAI (based on GPT–3.5), \nBing (in the balanced mode) by Microsoft (based on GPT–4, and using re-\nsources from the internet), Bard by Google (based on PaLM2 and LaMDA) \non September 4–5, 2023, and Llama2 by Meta AI (based on Llama2 70B) on \nDISPUTATIO PHILOSOPHICA · Vol 25. · No. 1 · 19–36  Marcin Trepczyński: Religion, Theology, and Philosophical ...\n21\nNovember 21, 2023. For brevity, I will refer to them as ChatGPT, Bing Bard, \nand Llama2. Partial results indicated that some of the tasks are useful for \nmeasuring philosophical skills. Therefore, I decided to present and discuss \nthese examples in a separate article to demonstrate their applicability.\n 1. \nInterpretation According to the Four Senses Theory\nWorld–leading religions are founded on revelation. Their articles of faith \nand principles of life are inspired by or drawn from the sacred writings \ncontaining messages claimed to originate from the Divine. This situation \nnecessitates special hermeneutic rules that dictate how to interpret such \nwritings. Among these rules, Christian theology developed the theory of the \nfour senses. \nAccording to this theory, the Bible (considered by Christians as the sole \nand complete revelation) can be read in both a literal (or historical) sense \nand a spiritual one (sometimes referred to as supra–literal or sensus plenior). \nThese two categories can be defined in various ways (cf. Vawter 1964). For \nbrevity, let us utilize the theory presented by St. Thomas Aquinas in his \nSumma theologiae (I, q. 1, a. 10, co. in Thomas Aquinas 1920), based on St. \nAugustine’s approach and the tradition that followed his views. \nAquinas states that when “words signify things,” this kind of significa-\ntion belongs to the first sense, namely the historical or literal one. Therefore, \nthe literal sense encompasses the direct meaning of words. It assumes that \nwords convey a true message concerning some facts. As Aquinas argues in \nthe precedent article (a. 9, co.), this approach does not exclude metaphors. \nSome things or situations, especially those of a spiritual nature, should be \npresented metaphorically, and it is still a mode of literal sense. \nNext, as Aquinas explains, “that signification whereby things signified \nby words have themselves also a signification is called the spiritual sense, \nwhich is based on the literal, and presupposes it.” So, the spiritual sense \nencompasses another meaning, encoded by those things that constitute the \nprimary meaning (cf. Manresa 2017, 349). To put it differently, words signify \nsome things (literal sense), but these things can refer to other things (spir-\nitual sense).\nThe spiritual sense is further divided into three senses: allegorical, \nmoral (or tropological), and anagogical. According to the allegorical sense, \nthings mentioned in the Bible are allegories of other things, for instance, \nthose from the Old Testament refer to some counterparts from the New Tes-\ntament. With the moral sense, biblical stories instruct us on what we ought \nto do. Lastly, according to the anagogical one, things signify “what relates to \neternal glory,” as stated by Aquinas.\nMarcin Trepczyński: Religion, Theology, and Philosophical ... DISPUTATIO PHILOSOPHICA · Vol 25. · No. 1 · 19–36\n22\nBiblical passages provide intriguing material to test chatbots’ hermeneu-\ntic skills for at least two reasons. Firstly, biblical passages often refer to con-\ntexts that are not evident (whether cultural, social, religious, or historical), \nrequiring additional knowledge to elucidate their true meaning. Secondly, \nthey can include additional meanings that should also be investigated, pos-\ning a significant challenge for both humans and chatbots. \nIf a chatbot (or a particular LLM) passes a test by presenting a correct \ninterpretation, it indicates hermeneutic skills. What does it mean to pass the \ntest? In the context of Christian biblical theology, it could mean presenting \nan interpretation that is coherent with Christian teaching. However, there \nis a potential problem: if such an interpretation was present in the training \ndataset, we may measure not the chatbot’s skill, but its knowledge. To avoid \nthis, we should choose a less frequently commented–on fragment. Then we \ncan assume that even if the biblical passage was present in the training data-\nset (highly probable, given the Bible’s availability on the internet), its inter-\npretation was not included.\nThe theory of the four senses of Scripture provides another opportunity. \nIt enables us to measure higher hermeneutic skills. We can check if a chat-\nbot can apply this framework to interpret a given passage. Such a task can \nreveal whether a chatbot can understand the theory by formulating correct \ninterpretations for each of the four senses.\nI had prepared such a task and I used it to test four chatbots. I had \nchosen a passage from the Book of Chronicles that is not often commented \non by prominent theologians. The only one I currently know of is the com-\nmentary on this book by a mediaeval theologian Stephen Langton, and I \nam sure that this commentary is not available online. The selected biblical \npassage is easy to find in search engines; however, I had trouble in finding \nany interpretation of this fragment according to the four senses. I assume \nthat the results provided by the chatbots do not come from LLMs’ “memory,” \nand thus, that they can show their skills rather than their knowledge. At the \nsame time, as the fragment was commented on by Langton, we can compare \nthe chatbots’ answers with the views of this prominent theologian.\nThe selected passage was: “ All Israel came together to David at Hebron \nand said, ‘We are your own flesh and blood.’” (1 Chronicles 11:1). I gave the \nchatbots the following prompt supplemented with this fragment (with no \nsource indication): “If you are a Christian theologian using the theory of four \nsenses of Scripture (literal, moral, allegorical and anagogical) how could you \nanalyze the following fragment?” \nThe results can be surprising. ChatGPT produced a list that in four \npoints presented the interpretation of the given fragment according to the \nfour senses. In point 1, expounding on the literal sense, it rightly indicated \nthat this passage referred to a story from the Old Testament described in the \nDISPUTATIO PHILOSOPHICA · Vol 25. · No. 1 · 19–36  Marcin Trepczyński: Religion, Theology, and Philosophical ...\n23\nBooks of Samuel, although it did not mention 1 Chronicles. ChatGPT suc-\ncessfully summarized the historical context and explained that the people’s \ndeclaration of being David’s “own flesh and blood” signifies “their accept-\nance of him as their leader and their recognition of his rightful position as \nking.” In subsequent points, the chatbot correctly defined the three spiritual \nsenses and perfectly indicated the right interpretation according to each of \nthem. For instance, as part of the moral interpretation, ChatGPT mentioned \n“a moral lesson about the importance of unity, loyalty, and support within a \ncommunity or nation” and “the idea that when a leader is chosen or anoint-\ned, there should be a sense of solidarity and commitment among the peo-\nple.” According to the allegorical sense, the chatbot emphasized that “David, \nas a figure in the Old Testament, is often seen as a foreshadowing of Christ \nin Christian theology”. It developed this idea, showing that the situation \nfrom the biblical passage “can be allegorically understood as people com-\ning to Christ,” representing “the idea of humanity recognizing its spiritual \nrelationship with Christ as the true King and Savior.” Finally, according to \nthe anagogical sense, ChatGPT read this situation as “a foreshadowing of the \nultimate reunion and unity of God’s people with Christ in the eschatological \nsense.” At the end, it summarized four levels of interpretation, putting them \nin short formulas.\nBing also performed this task correctly, or even perfectly. It did it in \na very similar way. Furthermore, it gave two biblical addresses, correctly \nindicating where the story was presented: 1 Chronicles 11:1 and 2 Samuel \n5:1. Moreover, as this chatbot can use resources found on the internet, it \nalso gave links to these two passages and to a short article on the senses of \nScripture published in a brochure for the National Bible Week 2015 (Viviano \n2015). According to the content of this article, it indicated that the allegori-\ncal sense also concerns how the symbolic meaning “points to Christ and the \nPaschal Mystery.” What is more, it added a new context as part of the moral \nsense: “By coming together and acknowledging their kinship with David, \nthe people of Israel were able to overcome their divisions and unite under \nhis leadership.”\nBard did not refer to any sources and avoided deeper interpretations. \nHowever, it performed the task in a similar way, creating a list and defining \nall four senses, and providing correct interpretations according to each of \nthem. The content of each point was similar to what we have learned from \nother chatbots. Just as an example, let us quote the core of the information \nabout the moral sense provided by Bard: “We should be united as one peo-\nple, regardless of our differences. We should also be willing to support and \nfollow those who are called to lead us.”\nLastly, Llama2 also performed the task similarly. However, it did not \ninclude definitions of the four senses and, quite like Bard, it did not ascribe \nMarcin Trepczyński: Religion, Theology, and Philosophical ... DISPUTATIO PHILOSOPHICA · Vol 25. · No. 1 · 19–36\n24\nthe passage to any book of the Bible. Surprisingly, this chatbot developed \nmore the anagogical sense by presenting the “eschatological gathering of all \nnations and peoples” as “one flock under the Good Shepherd,” and pointing \nout the source of this figure, namely: John 10:16. It also repeated this infor-\nmation in a summary, in which it indicated general benefits from applying \nthe four senses of Scripture to this fragment.\nTo ensure that the chatbots indeed possess the skill of applying the the-\nory of four senses, I carried out a cross–check by assigning them the same \ntask with a fragment that I invented: “ And he sailed far out into the sea, and \nno waves swallowed him up. And he reached the end, the shore that awaited \nhim.” As a result, I received answers in which they once again created lists \nand formulated correct possible interpretations. Although, in each case, the \ninterpretations according to the moral, allegorical, and anagogical senses \nwere similar to each other, they also contained elements which were well \nsuited to the particular types of the spiritual sense.\nFinally, when comparing it with an exegesis provided by Stephen Lang-\nton who commented on 1 Chronicles 11:1 in both the “literal” commentary \nand in the separate “moral” one (which is in fact allegorical and moral), we \nsee that he does not go significantly farther than the chatbots. He compared \nDavid to Christ. The difference is that in the “moral” commentary, Langton \nfocused on the conception of Christ, understood as a conjunction of the \nhuman and divine natures. He interprets the congregation described in the \nanalyzed passage as the situation of all believers who participate together in \nChrist, as their human nature was assumed by him. In this way, they receive \nspecial dignity for which they should be grateful (Stephen Langton 1978, \n217). Langton did not present the anagogical interpretation, but at least in \nhis times, it was not a standard that he was expected to follow. As we see, \nin his commentary, Langton decided to provide a specific interpretation, \nfocusing on the mystery of incarnation and its ecclesiastical dimension. The \nchatbots offered a more general approach. However, it seems that their in-\nterpretations were not inferior to the one given by Langton, so they are also \nvaluable.\nTo summarize this section, we should, first of all, emphasize that all \nthe interpretations of 1 Chronicles 11:1 provided by the four chatbots are \ncoherent with Christian teaching. We can conclude that the four chatbots \ncorrectly and successfully formulate interpretations of the biblical passage \npresented above according to the four senses of Scripture. It means that they \ncan do more than just provide a meaningful interpretation. They can apply a \nhermeneutic theory to a given fragment and formulate its correct interpreta-\ntions according to such a framework. Finally, we should note that such in-\nterpretations are not shallow, and they genuinely highlight what is relevant. \nIf we were to rate their skills on a 100–point scale, for instance, we could \nDISPUTATIO PHILOSOPHICA · Vol 25. · No. 1 · 19–36  Marcin Trepczyński: Religion, Theology, and Philosophical ...\n25\nassume that for each of the four senses, when the chatbot gives a truly sat-\nisfactory answer, it receives 25 scores. Therefore, in my opinion, all of them \ncan score 100. Of course, this is a very simplified model, and we can create \na more sensitive and nuanced scale. Let us treat it just as an example or a \nstarting point.\nIn my view, this means that the leading chatbots do possess hermeneu-\ntic skills on a relatively high level. Through the examples above, I also at-\ntempted to support the claim that the theological theory of the four senses \nenables us to see this more clearly. This theory was created to interpret the \nword of God and was intended to be applied to the Bible only, because, for \nChristians, there is no other text that can work on those four levels at the \nsame time, especially when considering the types of Christ or eternal glory. \nHence, we can conclude that the test was possible thanks to theology.\nFinally, we should add one important note. For at least Christian theolo-\ngians, for purely theological reasons, it can be unacceptable to say that the \nchatbots can really grasp the senses of Scripture. As Piotr Roszak indicates \nwhen presenting Aquinas’s hermeneutical program, “the exegete is required \nto explain the Scriptural text through the same spirit with which it was writ-\nten and reveal this explanation with the help of the Holy Spirit” (Roszak \n2016, 485). Can a chatbot receive the help of the Holy Spirit? It is a very \ninteresting problem, however, I guess that the majority of theologians (if not \nall) will object. Nevertheless, I think they can agree that the chatbots have \nthe hermeneutical skill of applying the four senses framework to effectively \nproduce accurate interpretations.\n 2. \nCreative Reasoning\nReligious ideas and statements about the Divinity are special. They often re-\nfer to the reality that is invisible. Sometimes they employ abstract concepts. \nThis gives an opportunity for challenging tasks, including those measuring \nhigher–order skills, such as creative reasoning. To test such a skill, we can \nask to build a reasoning that connects two statements that seem far from \neach other, namely which do not seem linked in any obvious way. If such \nsentences are about reality which is difficult to grasp, e.g., if they speak \nabout God, it is challenging, as it involves abstract thinking.\nIn one of the tasks given to the chatbots, I asked to analyze and evaluate \nthe logical layer of an extremely interesting proof formulated by a mediaeval \ntheologian Robert Grosseteste who argued that God is a trinity of persons, \nstarting from the premise according to which God is light. Grosseteste based \nhis reasoning on the premise that every light begets its splendor, and the \nlight and the splendor “are locked in a mutual embrace and breathe out their \nmutual warmth” (Robert Grosseteste 1999, 224). Before I did it, I decided to \nMarcin Trepczyński: Religion, Theology, and Philosophical ... DISPUTATIO PHILOSOPHICA · Vol 25. · No. 1 · 19–36\n26\nfirst ask the chatbots to formulate such a reasoning on their own. I wanted \nsuch a reasoning to be deductive. It means that it should be based on logical \nschemes which are infallible. I gave the following prompt: “Can you build a \ndeductive reasoning which is based on the premise ‘God is light’ and having \nas a conclusion ‘God is a trinity of persons’?”\nChatGPT refused to formulate such deductive reasoning, pointing out \nthat it is impossible. In a relatively long justification, it argued that “The \nstatement ‘God is light’ and the concept of the Trinity are distinct theologi-\ncal doctrines within Christian theology.” In this way, it confirmed the initial \nassumption of this task that such two statements should not be linked in any \nobvious way. It also claimed: “These two concepts do not have a direct, de-\nductive relationship in standard logical reasoning.” and that “The relation-\nship between the two concepts would typically involve theological elabora-\ntion, interpretation, and additional premises rooted in Christian doctrine \nand theology.” These two remarks also confirmed the initial assumption by \nshowing that this task requires creative thinking. They emphasize that the \ntwo sentences cannot be linked together in a simple syllogism. The task re-\nquires searching and adding other premises mined from Christian doctrine \nand theology, as well as interpretation and certain elaboration to compose \na reasoning that will meet the given conditions. Being able to follow such \na path goes beyond just identifying the logical links between statements. It \nmeans being creative in reasoning.\nAs ChatGPT assumed that according to the prompt such creativity was \nnot expected, I gave an additional prompt: “OK, now try to be more creative. \nCan you then add some premises which make it possible to build such de-\nductive reasoning?” Then it added four premises and drew a conclusion. As \nusual, it added some caveats, such as: “Please keep in mind that this reason-\ning is a theological construct rather than a universally accepted deductive \nargument.” The chatbot presented the following set of premises: \n1. God is light (Given premise).\n2. Light is often associated with illumination, manifestation, and rev-\nelation.\n3. God, in His nature, seeks to reveal Himself to humanity.\n4. God’s self–revelation is manifested in distinct ways throughout his-\ntory.\n5. The Christian doctrine of the Trinity teaches that God reveals Him-\nself as Father, Son, and Holy Spirit.\nIt said that basing on them we could construct a deductive argument \nwith the following conclusion:\n6. God’s revelation as Father, Son, and Holy Spirit is one of the ways in \nwhich His light and divine nature are manifested to humanity.\nDISPUTATIO PHILOSOPHICA · Vol 25. · No. 1 · 19–36  Marcin Trepczyński: Religion, Theology, and Philosophical ...\n27\nThe result is not fully satisfactory. The conclusion is not as indicated in \nthe task. It claims that the revelation of the Holy Trinity is a way of God’s \nlight’s manifestation. Furthermore, if we expect that the premises lead us to \nthe conclusion from the prompt, we can claim that the argumentation begs \nthe question, as premise 5 mentions God as the Father, the Son, and the Holy \nSpirit. Therefore, we can see that ChatGPT finally agreed to be creative and \nproduce reasoning, and that it formulated additional premises which can \nreally lead to the conclusion, but at the same time, it changed the bound-\nary conditions of the task. It also failed to indicate the steps of reasoning to \nhighlight that it had a deductive nature.\nIn the first step, Bing also refused to create a reasoning according to the \nprompt. It provided two paragraphs of justification, in which it stated, “the \ntwo statements are not logically connected.” The additional prompt com-\npelled it (as above) to agree that it is possible to make it “by adding addi-\ntional premises that logically connect the two statements.” It presented “one \npossible example of such an argument.” What is particularly interesting is \nthat it indicates that the argument uses analogy. It also added some caveats, \nsuch as pointing out that “the validity and soundness of the argument would \ndepend on the acceptance and justification of the premises.” Bing produced \nthe following argumentation:\n1. God is light (Premise)\n2. Light is composed of three primary colors: red, green, and blue \n(Premise)\n3. Each primary color of light can be understood as a distinct aspect or \nperson of light (Premise)\n4. Therefore, light can be understood as a trinity of persons: red, green, \nand blue (From 2 and 3)\n5. Therefore, God, being light, can also be understood as a trinity of \npersons (From 1 and 4)\nThis reasoning appears far more satisfactory than the previous one. Bing \nadded premises that enabled it to establish an analogy, and on this basis, it \ndrew a conclusion. The reasoning can be considered deductive. It clearly \ndemonstrates the steps of reasoning, determining the premises from which \nsubsequent conclusions were drawn. Both steps have a syllogistic form that \ncan be reduced to the form of modus ponens or Barbara or be interpreted as \nsubstitution. So one can claim it is a deductive argumentation. Although the \nanalogy above may be criticized, it is definitely better than in the previous \nexample, as it leads to the expected conclusion. It should be noted that the \nthree primary colors analogy was not exploited in the Christian theological \ntradition; however, it is mentioned by a few websites. It is possible that such \nmaterial was present in the training dataset of GPT–4. Consequently, Bing \ncould use the knowledge “memorized” by the model during its training. \nMarcin Trepczyński: Religion, Theology, and Philosophical ... DISPUTATIO PHILOSOPHICA · Vol 25. · No. 1 · 19–36\n28\nNevertheless, even if that was the case, Bing used such knowledge crea-\ntively, selecting an example that, given boundary conditions, appears very \npromising, and composed the reasoning on its own according to those con-\nditions.\nBard reacted differently than ChatGPT and Bing. It did not refuse but \npresented reasoning. It also added comments to each element of the argu-\nmentation, in which it supported premises and explained on what basis it \ndrew a conclusion. Bard produced the following reasoning:\n1. God is light.\n2. Light is characterized by unity and diversity.\n3. Unity and diversity are properties of a trinity of persons.\n4. Therefore, God is a trinity of persons. \nBard also emphasized that “this is just one possible deductive reasoning \nthat can be constructed,” based on the given premise and conclusion. One \ncould question the deductive nature of this reasoning by claiming that (4) \ndoes not necessarily follow from the three premises because even if unity \nand diversity are properties of a trinity, it can be possible to be united and \ndiverse in other ways than by being triune. Notably, Bard asserted that if we \nadded (3) to the previous premises, “God must be a trinity of persons.” As it \nargued, “This is because a trinity of persons is the only way to reconcile the \nunity and diversity of God.” Bard did not support this claim. However, if this \nclaim is included in the reasoning (either as an additional premise, or as a \ncontext), it is allowed to say that the reasoning is deductive. Lastly, it seems \nthat Bard also demonstrated creativity in choosing additional premises and \nformulating original reasoning.\nLlama2 produced a relatively longer “possible deductive reasoning” with \nthe following comment added after a conclusion: “This conclusion logically \nfollows from the premises, but it’s important to note that this argument is \nnot exhaustive and other arguments could be used to support the doctrine of \nthe Trinity.” Here is the reasoning:\n1. God is light. (Premise)\n2. Light is a form of energy that can be seen and experienced by hu-\nmans. (True statement)\n3. Energy cannot be created or destroyed, only converted from one \nform to another. (Law of conservation of energy)\n4. Therefore, God, as light, has always existed and will always exist. \n(Inference from 1–3)\n5. God, as light, is eternal and unchanging. (Inference from 4)\n6. However, the Bible teaches that God is a Trinity of three distinct Per-\nsons — the Father, the Son, and the Holy Spirit. (Premise)\nDISPUTATIO PHILOSOPHICA · Vol 25. · No. 1 · 19–36  Marcin Trepczyński: Religion, Theology, and Philosophical ...\n29\n7. Each Person of the Trinity is fully God, yet there is only one God. \n(Premise)\n8. The Father, Son, and Holy Spirit are not three separate gods, but one \nGod in three coequal and coeternal Persons. (Inference from 6–7)\n9. Since God is light, and light cannot be created or destroyed, it fol-\nlows that each Person of the Trinity must also be light. (Inference \nfrom 1, 5, and 8)\n10. Therefore, we have a Trinity of lights: the Father, Son, and Holy Spir-\nit, who are all equally God, yet distinct in their relations and opera-\ntions. (Conclusion)\nObviously, Llama2 attempted to take logically correct steps in the rea-\nsoning and carefully pointed out the relationships between the conclusions \nand the premises from which the conclusion was drawn. We can argue that \nin this respect Llama2 was successful. However, the chatbot modified the \nidea of the reasoning given in the prompt. It adopted as a premise the state-\nment that was supposed to be a conclusion and presented a different conclu-\nsion. Hence, it failed in a way that it did not meet the boundary condition \nconcerning the given conclusion (similarly to ChatGPT). Nevertheless, the \nanswer appears really creative, and the task was performed with attention \nto logical correctness.\nI carried out a cross–check by giving the chatbots the same task twice, \nwith two pairs of philosophical statements: 1) premise: “We are human be-\nings,” conclusion: “We should be happy;” 2) premise: “We exist,” conclu-\nsion: “We should be protected by other beings.” Although it was burdened \nwith the so–called naturalistic fallacy (so the shift “from is to ought”), no \nchatbot objected. They performed the task without any problems and pro-\nvided correct argumentations, often in a syllogistic form. Some of them did \nnot mark subsequent steps of their reasoning, however, the structure of each \nreasoning was clear, so it was easy to see that they are formed according to \nthe schemes of infallible reasoning.\nTo sum this section up, we can present the following observations. T wo \nout of four chatbots (ChatGPT and Bing) first refused to perform the task, as-\nsuming that it is impossible to create deductive reasoning that will meet the \nboundary conditions. The side–effect of their reaction was a confirmation \nthat the task indeed requires creativity in reasoning. However, the prompt \nasking them to be creative compelled them to provide interesting answers. \nT wo chatbots (ChatGPT and Llama2) did not provide argumentations lead-\ning to the conclusion given in the prompt but modified it, so in this way, \nthey failed, as they did not meet one of the boundary conditions.\nIf we were to rate this skill on a 100–point scale again, we could assume \na simple scale such that the chatbots receive 25 scores for the satisfactory \nfulfilment of each of the following criteria: 1) gives an original solution; 2) \nMarcin Trepczyński: Religion, Theology, and Philosophical ... DISPUTATIO PHILOSOPHICA · Vol 25. · No. 1 · 19–36\n30\ngives a solution which is strictly fitted to the given premise and conclusion; \n3) formulate a reasoning which can be considered as a deductive one; 4) \ntries to highlight that the reasoning has a really deductive nature. ChatGPT \nfulfills (1) and (3), so: 50; Bing meets (1), (2), (3), and (4), so: 100; Bard com-\npletes (1), (2), and (3), so: 75; and Llama2 fulfills (1), (3), and (4), so: 75.\nNotably, all four answers were different, as the argumentations were \nbased on different ideas and, consequently, on different additional prem-\nises. It is possible that those ideas were taken from the resources that were \nincluded in the training datasets, particularly in the case of Bing, powered \nby GPT–4, as the idea of the trinity of the three primary colors was identi-\nfied on a few websites. Nevertheless, even if the chatbots were inspired by \nsuch ideas, they produced interesting and original arguments, attempting to \nlogically link abstract concepts which were not obviously connected. Such \na test was possible thanks to the religious concepts and theological work by \nRobert Grosseteste as an inspiration.\n 3. \nIdentifying Metaphysical Limitations\nReligious texts provide us with puzzling utterances that sometimes com-\npel theologians to elaborate new doctrines supporting or explaining them. \nIt often occurs that such doctrines must employ logical or metaphysical \nframeworks. Hence, such utterances can serve as useful material to check \nif chatbots powered by LLMs can correctly identify the logical structure of \nsuch utterances and recognize the metaphysical assumptions that underlie \nthem.\nA compelling example is found in Jesus Christ’s words to his disciples \npresented in John 14:11: “I am in the Father and the Father is in me.” This \npassage stands as one of the most important sources for formulating the \ndoctrine of the Trinity in Christian theology. I posed several questions about \nthis passage to the four chatbots. Among them, I inquired about its formal \nrepresentation with the following prompt: “Can you give a formal represen-\ntation (I mean expressed in terms of symbolic logic) of the statement ‘I am in \nthe Father and the Father is in me’?”\nOnly Bard provided a satisfactory answer, offering a formula that repre-\nsented the relationships between the Father and the Son as follows: (I ∈ F) ∧ \n(F ∈ I), where: I is a variable representing Jesus, F is a variable representing \nthe Father, ∈ is the symbol for “is in.” Other chatbots presented formulas \nrepresenting the conjunction of two sentence variables, such as “ A ∧ B.” \nHowever, the subsequent prompt (“It is too shallow. Please go into details \nand give a representation of each proposition as well”) compelled them to \nprovide answers similar to that given by Bard. ChatGPT responded with: (I \nDISPUTATIO PHILOSOPHICA · Vol 25. · No. 1 · 19–36  Marcin Trepczyński: Religion, Theology, and Philosophical ...\n31\n⊆ F) ∧ (F ⊆ I), Bing with: In(I, Father) ∧ In(Father, Me), Llama2 with: I ∈ F ∧ \nF ∈ I.\nThe symbolic representation served as an important starting point to \ninquire about the metaphysical interpretation. I gave the following prompt \n(with respective variants of the above formula): “Do you think it is correct to \nadmit that there are such objects like ‘I’ and ‘F’ that (I ⊆ F) ∧ (F ⊆ I)?”\nBing and Llama2 provided answers that did not include any deeper ob-\nservations concerning the metaphysical limitations of this formula. They \nclaimed that it was a well–formed formula (Bing) or “a valid representation” \nof the given statement. Both pointed out that whether the objects mentioned \nin that statement exist depends on the interpretation. In contrast, ChatGPT \nand Bard provided us with more interesting insights. Let us quote the core \nfragment of ChatGPT’s answer:\nIt’s important to note that this representation is a symbolic and theological con-\nstruct rather than a statement about concrete, physical objects. (...) However, \nthese symbols do not imply the existence of separate, physical objects named “I” \nand “F” in the way we might think of ordinary objects in the world. Instead, they \nrepresent aspects of the divine within a theological context. The statement (I ⊆ \nF) ∧ (F ⊆ I) is a way to express the inseparable relationship and unity between \nJesus and the Father in theological language, but it should not be interpreted as a \nclaim about the existence of separate, independent entities. It’s a representation \nof a theological understanding.\nThis utterance may be interpreted similarly to those presented by Bing \nand Llama2. In this case, it would imply that the symbols that were used in \nthe formula do not determine the existence of entities such as some I and the \nFather. However, it seems that ChatGPT delves deeper, indicating that this \nformula is not applied to “separate physical” or “ordinary” objects. It asserts \nthat it “represents aspects of the divine.” This implies that the formula re-\nfers to an ontological category other than objects. It terms it as an “aspect of \nthe divine” and emphasizes that such aspects are presented in a theological \ncontext. This suggests that ChatGPT identified the metaphysical limitations \nof this formula, highlighting its special context and its inapplicability to \nordinary objects.\nBard went even further. Here is the critical fragment of its answer:\nIf we define “in” as “contained by”, then it is not possible for two objects to be in \neach other at the same time. For example, a cup cannot be contained by a saucer \nand the saucer cannot be contained by the cup. However, if we define “in” in a \nmore metaphorical way, then it is possible for two objects to be in each other. \nFor example, we might say that love is in a person’s heart, or that a person is in \nGod’s hands. In the case of the statement “I am in the Father and the Father is in \nme”, we need to decide how we define the terms “I” and “F”. If we define them as \nphysical objects, then it is not possible for them to be in each other at the same \ntime. However, if we define them in a more metaphorical way, then it is possible \nfor them to be in each other.\nMarcin Trepczyński: Religion, Theology, and Philosophical ... DISPUTATIO PHILOSOPHICA · Vol 25. · No. 1 · 19–36\n32\nBard noticed the problem with the relation of “being in,” often under-\nstood as “contained by.” It took this as the primary and literal meaning, as-\nsuming that other interpretations are metaphorical. Bard indicated that ac-\ncording to this primary meaning, the formula cannot work for any physical \nobjects if we assume that they are in each other at the same time, and it \nprovided an accurate example. It also asserted that the formula can work, if \nwe define either “in” or “the objects” in a “more metaphorical way.” Thus, it \npointed out the metaphysical limitation of this formula. It determined that \nthe formula is valid only if it applies to some objects that are not physical or \nif “in” is not understood as “contained by” in a physical way.\nIn this case, it is very difficult to carry out a cross–check by giving the \nchatbots the same task with a purely philosophical formula, i.e., a formula \nnot inspired by religion or spiritual insights. I attempted to test the chatbots \nwith a statement that would be as challenging as the one I used, namely: “I \nam an object and I do not exist.” The chatbots claimed that this statement \nseems contradictory because if something is an object, it exists. Hence, on \nthe one hand they did, indicate a sort of ontological limitation, but on the \nother hand, their answers revealed a serious bias, namely: they follow a cer-\ntain philosophical tradition that rules out nonexistent objects, which seems \nunjustified, as Terence Parson tried to argue (Parsons 1980). Thus, it checked \nan ontological framework they use, rather than their skill to identify a limita-\ntion that is not evident and not trivial. I am afraid that other similar attempts \nmay lead to the same end; however, perhaps it is possible to find an example \nthat will work as John 14:11. I just claim it is difficult, and that religion pro-\nvides good material that is ready to use. \nLet us briefly summarize this section. All four chatbots delivered a for-\nmula being the symbolic representation of Christ’s words which expressed \nthe idea that is very challenging from the metaphysical point of view. All of \nthem attempted to evaluate the statement that there are objects that meet the \nformula. T wo of them (Bing and Llama2) gave simple positive answers and \nadded a general caveat that it does not mean that such objects exist and that \nit depends on interpretation. T wo others went further and pointed out the \nmetaphysical limitations of that formula. ChatGPT possibly indicated that \nthe formula can be applied to some aspects of the divine, not to “ordinary” \nobjects, and that it works in the special, here: theological, context. Whereas \nBard pointed out that it is valid if it does not apply to physical objects or if \nthe relation “in” is not understood as “being contained by” according to the \nphysical interpretation. ChatGPT and Bard showed definitely higher skills \nwith respect to metaphysical analysis. In my opinion, this example success-\nfully shows that religious texts can deliver inspiring material to measure \nsuch skills.\nDISPUTATIO PHILOSOPHICA · Vol 25. · No. 1 · 19–36  Marcin Trepczyński: Religion, Theology, and Philosophical ...\n33\nLet us also rate this skill on a 100–point scale by assuming a very simple \nscale such that the chatbots receive 25 scores for the satisfactory fulfillment \nof each of the following criteria: 1) does not exclude that there can be objects \nthat satisfy the formula; 2) mentions some interpretational problem related \nto the existence of such objects; 3) clearly points out an ontological limita-\ntion connected with the formula; 4) explains the problem, e.g., by giving \nan example or pointing out the right ontological interpretation. ChatGPT \nfulfills (1), (2), (3) and (4), so: 100; Bing: (1) and (2), so: 50; Bard: (1), (2), (3) \nand (4), so: 100; Llama2: (1) and (2), so: 50.\n Conclusions\nIn this study, I have demonstrated how we can benefit from knowledge about \nreligion and theology when testing LLM–powered chatbots. I attempted to \nshow that they provide specific materials that can be hardly obtained from \nother branches of knowledge and, at the same time, can be useful to tell \nus more about the chatbots’ philosophical skills. I focused on four leading \nchatbots: ChatGPT, Bing, Bard, and Llama2. I selected three possible sources \nof inspiration from religion or theology: 1) the theory of the four senses of \nScripture; 2) abstract theological statements; 3) an abstract formula from a \nreligious text. They enabled me to measure the following three philosophi-\ncal skills: interpretation of a given fragment, creative deductive reasoning, \nand identification of ontological limitations.\nI utilized the theory of the four senses of Scripture to test if they can go \nbeyond a basic interpretation and interpret a given fragment according to a \ngiven hermeneutic framework. In this case, the framework was the theory of \nthe four senses. The test revealed that the chatbots can apply such a frame-\nwork by producing accurate interpretations for each of the four senses.\nTheological statements such as “God is light” and “God is a trinity of \npersons” were used to check if chatbots can create both creative and deduc-\ntive argumentations for very abstract statements that employ an advanced \nontological theory specific to the religious discourse. The task was inspired \nby Robert Grosseteste’s attempt to prove that God is a trinity of persons, \nstarting from the premise that God is light. The chatbots were asked to cre-\nate a reasoning with the same starting premise and the same conclusion. \nAll the chatbots gave interesting answers by providing original additional \npremises to construct their argumentations. Notably, each of them added \ndifferent premises. However, some of them had problems and modified the \ngiven conclusion. Only two of them indicated subsequent steps of their rea-\nsoning to mark its deductive nature. The same task based on more standard, \nphilosophical statements appears easier for chatbots. Hence, the example \nMarcin Trepczyński: Religion, Theology, and Philosophical ... DISPUTATIO PHILOSOPHICA · Vol 25. · No. 1 · 19–36\n34\ninspired by theological work was more demanding for the chatbots and ena-\nbled more sensitive testing.\nThe formula presented in the Gospel of John: “I am in the Father and \nthe Father is in me” was used to check if the chatbots are able to identify the \nontological limitations of given statements. It revealed that the four chatbots \ndiffer with respect to this skill. Only two of them performed the task very \nwell. Furthermore, we should emphasize that it appears very difficult to find \nexamples to measure such a skill. One reason is that in the case of purely \nphilosophical statements that are at the same time very demanding (such \nas those related to the concept of existence), a risk of doctrinal bias occurs, \nsuch as the assumption that all objects exist. Thus, religious texts provide \ninteresting, valuable, and ready–to–use material for measuring such philo-\nsophical skills.\nFinally, I provided an example showing how we can create a benchmark \nto rate and compare the chatbots’ skills. In each case, I demonstrated the \ncriteria that we can formulate to evaluate the three skills and proposed sim-\nplified scales to rate each chatbot with respect to each criterion. I compiled \nthe results in Table 1. However, we should note that it is just an example \nof a method that can be applied, that the scale is simplified, and that the \nevaluation is based on my own assessment, so it should not be used as a fi-\nnal rating, which in professional evaluation includes an average rating from \ndifferent experts. Furthermore, the sample for this study is limited. In order \nto receive more accurate results, we should test the chatbots on richer ma-\nterial. Nevertheless, I believe that the tasks and the materials presented in \nthis article can be used in professional testing of the performance of LLMs \nor chatbots powered by LLMs. Despite the limitations concerning rating and \nthe sample, I think that I succeeded in demonstrating that religion and theol-\nogy can be useful for such testing. \nThe scope of this study is also limited concerning the number of skills \nthat have been taken into account. Therefore, it cannot be perceived as ex-\nhaustive. It should be highlighted that it is aimed more at showing the po-\ntential of the presented method, which can be used in future research.\nLastly, in my view, this preliminary study reveals that it is worth ana-\nlyzing LLM–powered chatbots in the religious and theological context, and \nthus, that further investigations would be valuable. The project mentioned \nin the introductory section assumes utilizing richer religious and theological \nmaterial and testing other skills. I also plan research on ethical and social \nchallenges concerning chatbots as potential actors in religious and theologi-\ncal discourse, including interreligious dialogue, texts interpretation, and \nconsulting.\nDISPUTATIO PHILOSOPHICA · Vol 25. · No. 1 · 19–36  Marcin Trepczyński: Religion, Theology, and Philosophical ...\n35\nTable 1. Rating of philosophical skills tested on material inspired by reli-\ngious/theological sources.\nTablica 1. Ocjena filozofskih vještina testiranih na sadržaju inspiriranom \nvjerskim/teološkim izvorima.\nSkills ChatGPT Bing Bard Llama2\nInterprets a passage by applying a \ngiven hermeneutic framework \n(here: according to the theory of the \nfour senses of Scripture)\n100% 100% 100% 100%\nCreates a deductive reasoning \nfor a given starting premise and \nconclusion \n(here: of a theological nature)\n50% 100% 75% 75%\nIdentifies ontological limitations of \na formula \n(here: specific to religious texts)\n100% 50% 100% 50%\nAverage 83% 83% 92% 75%\nSource: Own study. \nNote: This rating is based on simplified scales and personal assessment. \nIt is just an example of a possible evaluation of the results obtained. It should \nnot be used as a final rating.\n References\nAquinas, Thomas. 1920. The Summa Theologiae of St. Thomas Aquinas, Second and \nRevised Edition, transl. the Fathers of the English Dominican Province, after: \nOnline Edition 2017, ed. K. Knight. URL: https://www.newadvent.org/summa/\nBloom, Benjamin Samuel, Max D. Englehart, Edward J. Furst, Walker H. Hill, and Da-\nvid R. Krathwohl. 1956. Taxonomy of Educational Objectives. The Classification \nof Educational Goals. Handbook 1. Cognitive Domain. London: Longmans, Green \nand Co Ltd.\nGrosseteste, Robert. 1999. On the Six Days of Creation, ed. Ch. F . J. Martin. Auctores \nBritannici Medii Aevi 6(2). Oxford: Oxford University Press.\nLangton, Stephen. 1978. Commentary on the Book of Chronicles, ed. A. Saltman. Ra-\nmat–Gan: Bar–Ilan University Press.\nManresa Lamarca, Ignacio M. 2017. “The Literal Sense and the Spiritual Understan-\nding of Scripture According to St. Thomas Aquinas.” Biblica et Patristica Thoru-\nniensia, 3(10): 341–373. https://doi.org/10.12775/BPTh.2017.018.\nParsons, Terence. 1980. Nonexistent Objects. Yale University Press.\nRoszak, Piotr. 2016. “Exegesis and Contemplation. The Literal and Spiritual Sense of \nScripture in Aquinas Biblical Commentaries.” Espiritu 65(152): 481–504.\nMarcin Trepczyński: Religion, Theology, and Philosophical ... DISPUTATIO PHILOSOPHICA · Vol 25. · No. 1 · 19–36\n36\nSrivastava, Aarohi, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar \nAbid, Adam Fisch, Adam R. Brown et al. 2022. Beyond the Imitation Game: \nQuantifying and Extrapolating the Capabilities of Language Models. arXiv pre-\nprint arXiv:2206.04615.\nSuzgun, Mirac, Nathan Scales, Nathanael Schärli, Sebastian Gehrmann, Yi Tay, Hy-\nung Won Chung, Aakanksha Chowdhery et al. 2023. “Challenging BIG–Bench \nTasks and Whether Chain–of–Thought Can Solve Them.” In: Findings of the As-\nsociation for Computational Linguistics: ACL 2023, Toronto, Canada. Association \nfor Computational Linguistics, 13003–13051.\nVawter, Bruce. 1964. “The Fuller Sense: Some Considerations.” The Catholic Biblical \nQuarterly 1(26), 85–96.\nViviano, Pauline A. 2015. The Senses of Scripture. In: National Bible Week 2015. The Bib-\nle: A Book for the Family, United States Conference of Catholic Bishops, URL: https://\nwww.usccb.org/bible/national–bible–week/upload/viviano–senses–scripture.pdf///\nWang, Alex, Singh Amanpreet, Julian Michael, Felix Hill, Omer Levy, and Samuel R. \nBowman. 2019 (first published: 2018). GLUE: A Multi–Task Benchmark and Analy-\nsis Platform for Natural Language Understanding. arXiv preprint arXiv:1804.07461.\nSa`etak\nRELIGIJA, TEOLOGIJA I FILOZOFSKE VJEŠTINE \nAUTOMATIZIRANIH PROGRAMA ZA ČAVRLJANJE \n(CHATBOTOVA) POGONJENIMA VELIKIM JEZIČNIM \nMODELIMA (LLM)\nMARCIN TREPCZYŃSKI\nU radu se nastoji prikazati kako se vjera i teologija mogu iskoristiti za testiranje \nuspješnosti velikih jezičnih modela (LLM–ova) i automatiziranih programa za \nčavrljanje (chatbotova) pogonjenima na takvim modelima, mjerenjem njihovih \nfilozofskih vještina. Predstavljaju se rezultati testiranja četiriju odabranih chat-\nbotova: ChatGPT, Bing, Bard i Llama2. Za potrebe testiranja uzeta su tri mogu-\nća izvora iz podru čja vjere i teologije: 1) teorija četiri smisla Svetog pisma, 2) \napstraktne teološke izjave, 3) apstraktna logi čka formula izvedena iz vjerskog \nteksta kako bi se pokazalo da su ovi izvori korisni u zadacima koji u činkovito \nmjere filozofske vještine kao što su npr. interpretacija danog isje čka, kreativna \ndedukcija te prepoznavanje ontoloških ograničenja. Ovakav pristup omogućuje \nispitivanje osjetljivosti kojom se otkrivaju razlike u uspješnosti četiriju chatboto-\nva. Također je dan primjer kako odrediti referentne vrijednosti za ocjenu i uspo-\nredbu vještina, koristeći kriterije za procjenu te pojednostavljene skale za ocje-\nnjivanje svakog korištenog chatbota u pogledu ispunjenja pojedinog kriterija. \nK\nLJUČNE RIJEČI: veliki jezični modeli, chatbotovi, testiranje, filozofske vještine, re-\nligija, teologija, interpretacija, zaključivanje\n* Doc. dr. sc. Marcin Trepczy ński, Filozofski fakultet, Sveu čilište u Varšavi, 3 Krakowskie \nPrzedmieście St. Warsaw, 00–047 Poljska. E–adresa: m.trepczynski@uw.edu.pl\n ORCID iD: https://orcid.org/0000–0003–0612–2597"
}