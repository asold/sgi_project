{
    "title": "Large Language Model Guided Reinforcement Learning Based Six-Degree-of-Freedom Flight Control",
    "url": "https://openalex.org/W4399425864",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2575160466",
            "name": "Yanqiao Han",
            "affiliations": [
                "Sichuan University"
            ]
        },
        {
            "id": "https://openalex.org/A2303008584",
            "name": "Menglong Yang",
            "affiliations": [
                "Sichuan University"
            ]
        },
        {
            "id": "https://openalex.org/A2138259234",
            "name": "Yang Ren",
            "affiliations": [
                "Sichuan University"
            ]
        },
        {
            "id": "https://openalex.org/A2167523659",
            "name": "Weizheng Li",
            "affiliations": [
                "Sichuan University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4246233237",
        "https://openalex.org/W6610526735",
        "https://openalex.org/W2586878774",
        "https://openalex.org/W4280581922",
        "https://openalex.org/W1982446614",
        "https://openalex.org/W3103383006",
        "https://openalex.org/W1968358796",
        "https://openalex.org/W1993428686",
        "https://openalex.org/W2155955827",
        "https://openalex.org/W1515980150",
        "https://openalex.org/W2171499307",
        "https://openalex.org/W3087187818",
        "https://openalex.org/W2765770996",
        "https://openalex.org/W2058820300",
        "https://openalex.org/W2239110452",
        "https://openalex.org/W2733312032",
        "https://openalex.org/W4385656117",
        "https://openalex.org/W4313854672",
        "https://openalex.org/W3216090517",
        "https://openalex.org/W6756203324",
        "https://openalex.org/W2769037371",
        "https://openalex.org/W4375929017",
        "https://openalex.org/W4327662927",
        "https://openalex.org/W6857752217",
        "https://openalex.org/W6849861922",
        "https://openalex.org/W6638088447",
        "https://openalex.org/W6772383348",
        "https://openalex.org/W2023857055",
        "https://openalex.org/W3190154035",
        "https://openalex.org/W6854897375",
        "https://openalex.org/W4387560733",
        "https://openalex.org/W2914789275",
        "https://openalex.org/W2183892736",
        "https://openalex.org/W3001279689",
        "https://openalex.org/W4385473649",
        "https://openalex.org/W298183222"
    ],
    "abstract": "As artificial intelligence (AI) technology advances rapidly, its increasing involvement in military defense fosters intelligent air combat domain development. The Intelligent Flight Controller (IFC) is a crucial technology and foundation for intelligent air combat decision-making systems. Controlling 6 Degree-of-freedom (DOF) aircraft in close-to-real-world environments requires an adaptable and dynamic decision-making controller. Most IFC researches focus on simplistic flight trajectory design and validation, while air combat requires aircraft that can perform complex tactical maneuvers. Deep reinforcement learning (DRL) provides a suitable technical paradigm. However, DRL suffers from sparse rewards, insufficient supervisory signals, low sampling efficiency, and slow convergence. In contrast, Large Language Model (LLM) possesses abundant knowledge about the real world, contextual understanding, and reasoning capabilities. By leveraging this, LLM can serve as prior knowledge for DRL, thereby reducing DRL training time. This paper proposes an LLM-guided deep reinforcement learning framework for IFC, which utilizes LLM-guided deep reinforcement learning to achieve intelligent flight control under limited computational resources. LLM provides direct guidance during training based on local knowledge, which improves the quality of data generated in agent-environment interaction within DRL, expedites training, and offers timely feedback to agents, thereby partially mitigating sparse reward issues. Additionally, we present an effective reward function to comprehensively balance the aircraft coupling control to ensure stable, flexible control. Finally, simulations and experiments show that the proposed techniques have good performance, robustness, and adaptability across various flight tasks, laying a foundation for future research in the intelligent air combat decision-making domain.",
    "full_text": null
}