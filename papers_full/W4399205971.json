{
  "title": "Landscape of Large Language Models in Global English News: Topics, Sentiments, and Spatiotemporal Analysis",
  "url": "https://openalex.org/W4399205971",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2156997173",
      "name": "Lu Xian",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A2096161695",
      "name": "Lingyao Li",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A2168027384",
      "name": "Yiwei Xu",
      "affiliations": [
        "University of Washington"
      ]
    },
    {
      "id": "https://openalex.org/A3201475675",
      "name": "Ben Zefeng Zhang",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A2115451055",
      "name": "Libby Hemphill",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A2156997173",
      "name": "Lu Xian",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2096161695",
      "name": "Lingyao Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2168027384",
      "name": "Yiwei Xu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3201475675",
      "name": "Ben Zefeng Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2115451055",
      "name": "Libby Hemphill",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4210764005",
    "https://openalex.org/W4390117685",
    "https://openalex.org/W4283318215",
    "https://openalex.org/W3048664136",
    "https://openalex.org/W3099215402",
    "https://openalex.org/W2956996388",
    "https://openalex.org/W4229011615",
    "https://openalex.org/W4285190530",
    "https://openalex.org/W2970641574",
    "https://openalex.org/W1728842521",
    "https://openalex.org/W2786672974",
    "https://openalex.org/W4377981900",
    "https://openalex.org/W4389911900",
    "https://openalex.org/W3036644138",
    "https://openalex.org/W150292108",
    "https://openalex.org/W2043455807",
    "https://openalex.org/W4221142221",
    "https://openalex.org/W2961130995",
    "https://openalex.org/W3024647474",
    "https://openalex.org/W2522133792"
  ],
  "abstract": "Generative AI has exhibited considerable potential to transform various industries and public life. The role of news media coverage of generative AI is pivotal in shaping public perceptions and judgments about this significant technological innovation. This paper provides in-depth analysis and rich insights into the temporal and spatial distribution of topics, sentiment, and substantive themes within global news coverage focusing on the latest emerging technology—generative AI. We collected a comprehensive dataset of English news articles (January 2018 to November 2023, N = 24,827) through ProQuest databases. For topic modeling, we employed the BERTopic technique and combined it with qualitative coding to identify semantic themes. Subsequently, sentiment analysis was conducted using the RoBERTa-base model. Analysis of temporal patterns in the data reveals notable variability in coverage across key topics—business, corporate technological development, regulation and security, and education—with spikes in articles coinciding with major AI developments and policy discussions. Sentiment analysis shows a predominantly neutral to positive media stance, with the business-related articles exhibiting more positive sentiment, while regulation and security articles receive a reserved, neutral to negative sentiment. Our study offers a valuable framework to investigate global news discourse and evaluate news attitudes and themes related to emerging technologies.",
  "full_text": "Landscape of Large Language Models in Global English News: Topics,\nSentiments, and Spatiotemporal Analysis\nLu Xian 1*, Lingyao Li 1*, Yiwei Xu 2, Ben Zefeng Zhang 1, Libby Hemphill 1\n1School of Information, University of Michigan\n2Information School, University of Washington\nxianl@umich.edu, lingyaol@umich.edu, yiweixu@uw.edu, bzfzhang@umich.edu, libbyh@umich.edu\nAbstract\nLarge language models (LLMs) have exhibited considerable\npotential to transform various industries and public life. The\nrole of news media coverage of LLMs is pivotal in shaping\npublic perceptions and judgments about this significant tech-\nnological innovation. This paper provides in-depth analysis\nand rich insights into the temporal and spatial distribution of\ntopics, sentiment, and substantive themes within global news\ncoverage, focusing on the latest emerging AI technology —\nLLMs. We collected a comprehensive dataset of news arti-\ncles (January 2018 to November 2023, N = 24,827) from\nProQuest. For topic modeling, we employed the BERTopic\ntechnique and combined it with qualitative coding to identify\nsemantic themes. Subsequently, sentiment analysis was con-\nducted using the RoBERTa-base model. Analysis of tempo-\nral patterns in the data reveals notable variability in coverage\nacross key topics—business, corporate technological devel-\nopment, regulation and security, and education—with spikes\nin articles coinciding with major AI developments and policy\ndiscussions. Our sentiment analysis shows a predominantly\nneutral to positive media stance, with the business-related\narticles exhibiting more positive sentiment, while regulation\nand security articles receive a reserved, neutral to negative\nsentiment. This study offers a valuable framework to inves-\ntigate global news discourse and evaluate news attitudes and\nthemes related to emerging technologies.\nIntroduction\nMedia plays an important role in disseminating information\nto the public and shaping their perceptions of emerging tech-\nnologies (Brossard 2013). News reporting on artificial intel-\nligence (AI)-related content can help foster essential tech-\nnology literacy among the general public (Nguyen and Hek-\nman 2022). Studying large language models is crucial, not\nonly for their advanced capabilities and applications beyond\ntraditional machine learning technologies but also due to\nthe emerging challenges and societal implications, which\nrequire specialized understanding and careful scrutiny. De-\nspite the significant potential of LLMs to transform various\nindustries and aspects of public life (Marr 2023), public un-\nderstanding of this emerging technology remains nascent.\nBy analyzing news media coverage of LLMs, researchers\ncan understand how the public is exposed to media interpre-\n*These authors contributed equally.\ntations of data and events related to this innovative technol-\nogy, and how this may form public opinions or judgments\nabout generative AI broadly.\nIn the realm of AI-related news, prior research has inves-\ntigated the broader context of AI news, often emphasizing\nWestern mainstream media outlets. However, the investiga-\ntion into the reporting of LLMs-related news remains un-\nderstudied, particularly from a global perspective (Sun et al.\n2020; Chuan, Tsai, and Cho 2019). As a result, the global\nmedia’s response to the rapidly evolving generative AI in-\ndustry remains unclear. Our work aims to bridge these gaps\nby analyzing a large corpus of global AI-related news cov-\nerage. We also seeks to illuminate the general public’s expo-\nsure, sentiment, and perceptions toward the latest advance-\nments in innovative technology.\nOur analysis is based on a large-scale dataset consisting\nof English-language news articles about LLMs published by\na total of 703 US national, US local, and international news\noutlets. This dataset includes over 24,827 articles collected\nover a period of 70 months, from January 2018 to November\n2023, allowing for a comprehensive analysis of the evolu-\ntion and impact of LLMs since their conception. To the best\nof our knowledge, our dataset represents the most compre-\nhensive and current news resource available, capturing the\nglobal discourse surrounding LLMs. In this paper, we ad-\ndress the following research questions:\nRQ1: After the emergence of LLMs, what topics do news\narticles about it focus on, and how does the quantity of news\narticles on these topics vary temporally and spatially?\nRQ2: How does the sentiment of news articles about\nLLMs vary across topics and the different categories of news\noutlets?\nRQ3: What are the most popular topics covered by LLMs\nnews with positive sentiment?\nWe found that after the introduction of ChatGPT in late\n2022, news coverage of LLMs has been marked by tempo-\nral and spatial variabilities in the number of news articles.\nThose trends coincide with major events regarding techno-\nlogical development and specific interests. Our sentiment\nanalysis reveals that LLMs are predominantly portrayed in a\nneutral to positive light, echoing the optimistic tone towards\nemerging technologies consistently documented in prior re-\nsearch (Garvey and Maskal 2020; Fast and Horvitz 2017).\nHowever, in the context of LLMs, our analysis uncovers a\nProceedings of the Eighteenth International AAAI Conference on Web and Social Media (ICWSM2024)\n1661\nmore reserved sentiment in reports focusing on regulation\nand security reporting.\nThis work makes the following contributions:\n1. First, we gathered a diverse range of global news arti-\ncles spanning various types of news outlets, countries,\nand time. This collection extends from the initial release\nof BERT in 2018 to November 2023, allowing a com-\nprehensive understanding of the global news coverage\nand perspectives on the rapidly evolving generative AI\ntechnologies since the inception of LLMs. This dataset\ncan also be used to continue exploring the global news\ndiscourse around generative AI and other emerging tech-\nnologies.\n2. Second, we constructed an extensive codebook for the\ntopics of LLMs news articles, which builds on both quan-\ntitative topic modeling and qualitative manual coding re-\nsults. This codebook encompasses applications of LLMs\nacross sectors, such as business and education, as well\nas responses to LLMs like regulation and security. Our\nmethodology and the developed codebook offer a valu-\nable framework for future researchers to capture and as-\nsess the news coverage of future emerging technologies.\n3. Third, we utilized two approaches, sentiment and seman-\ntic analysis, to further capture the attitudes and themes\npresent in global news coverage of LLMs. Aligning with\nthe overall optimistic views of emerging technologies in\nearly studies, our analysis also reveals a reserved tone\nin coverage related to regulatory and security aspects\nof LLMs. This dichotomy highlights the complexity of\nglobal media coverage in terms of integrating LLMs into\nvarious industries and the social fabric, emphasizing the\nnuanced nature of its reception across diverse contexts.\nRelated Works\nThe media public discourse is witnessing a growing trend\nin the coverage of LLMs, such as ChatGPT (Delellis et al.\n2023). While most other prior research has not explicitly fo-\ncused on analyzing news coverage of LLMs, several studies\nhave delved into the broader context of AI news coverage\nand provided nuanced insights into the specific themes and\nsentiment analysis over time.\nOne study analyzed five major American newspapers (i.e.,\nUSA Today, The New York Times (NYT),Los Angeles Times,\nNew York Post, and Washington Post) from 2009 to 2018\nand found that business and technology were the predom-\ninant subjects in AI news coverage (Chuan, Tsai, and Cho\n2019). Another study analyzed the New York Times, Wash-\nington Post, the Guardian, and USA Today from 1977 to\n2019, identified fourteen major topics, including research\nand education, media products, health care, jobs, economy,\nand others (Sun et al. 2020).\nPrevious research found mixed sentiment analysis evi-\ndence for AI news reporting. An automated content analy-\nsis reveals the rapid emergence of AI’s ubiquity in the mid-\n2010s and demonstrates a growing critical tone in news dis-\ncourse over time among The NYT, The Guardian, Wired,\nand Gizmodo (Nguyen and Hekman 2022). However, oth-\ners found that the majority of AI news reporting was posi-\ntive over six decades (1956 to 2018) among The NYT, As-\nsociated Press, The International Herald Tribune, Reuters,\nCNBC, International NYT, andInternet Video Archive) (Gar-\nvey and Maskal 2020). Similarly, the analysis of a 30-year\nnews report from the New York Times also revealed over-\nall consistently optimistic tones for AI news coverage (Fast\nand Horvitz 2017). In addition, mainstream media tend to\ndownplay the controversy of AI (Dandurand, McKelvey, and\nRoberge 2023).\nWhile discussions about the benefits of AI were more fre-\nquent than its risks, the discussions on AI risks were gener-\nally more specific (Chuan, Tsai, and Cho 2019). News re-\nporting of AI showed growing concerns about loss of con-\ntrol, ethical issues, and negative impacts on work in recent\nyears, despite increasing hopes for AI in healthcare and ed-\nucation (Fast and Horvitz 2017). Leading English-speaking\nglobal media outlets reported concerns include privacy in-\nvasion, data bias, cybersecurity, and information disorder,\nunderscoring the importance of interventions to clarify the\ndetrimental impacts of datafication and automation on cit-\nizens (Nguyen 2023). Journalists portrayed AI as sophisti-\ncated, powerful, and value-laden, but the perspectives of or-\ndinary citizens were notably absent in media discourses (Sun\net al. 2020).\nData\nData Preparation\nWe collected news data from ProQuest TDM (ProQuest\n2023c), a platform encompassing multiple databases across\ndisciplines, including newspapers, magazines, dissertations,\nand other primary sources. To collect relevant news, we\nconducted a search based on the following conditions as\npresented in Table 1: date, search terms, and ProQuest\nnewsstream databases. Each ProQuest newsstream database\ncovers an array of news outlets. For example, North Cen-\ntral Newsstream databases curate news articles published\nby state-level news outlets in Colorado, Iowa, Kansas, Min-\nnesota, Missouri, Montana, North Dakota, Nebraska, South\nDakota, and Wyoming (ProQuest 2023c).\nWe established our search time frame from January 2018\nto November 2023, aligning with the initial release of the\nwidely acclaimed Bidirectional Encoder Representations\nfrom Transformers (BERT) in 2018. The search terms in-\ncluded “large language model,” along with popular LLMs\nsuch as BERT, OpenAI’s GPT, Google’s PaLM, and Meta’s\nLlaMa. In addition, we included a list of popular ProQuest\nnewsstream databases worldwide (ProQuest 2023a). Collec-\ntively, these criteria resulted in a total of 38,199 news arti-\ncles.\nWe refined the acquired dataset in several ways. First, af-\nter detecting the language of news articles, we included only\narticles written in English for later analysis, which is the pre-\ndominant language (63.9%) in our dataset. Second, we re-\nmoved duplicated news articles based on their title, content,\nand publisher.\nAfter reading 100 randomly selected copies of news ar-\nticles, we found that the content of many articles was not\nrelated to LLMs but was included in our dataset. This is\n1662\nSearch Category Search Conditions\nDate 2018-01-01 to 2023-11-18\nSearch terms Large language model, LLM, ChatGPT, BERT, GPT, PaLM, LLaMA\nNewsstream African Newsstream, Asian Newsstream, Australia Newsstream, New Zealand Newsstream, Cana-\ndian Newsstream, European Newsstream, Latin American Newsstream, Middle East Newsstream, U.S.\nHispanic Newsstream, U.S. Midwest Newsstream, U.S. North Central Newsstream, U.S. Northeast\nNewsstream, U.S. South Central Newsstream, U.S. Southeast Newsstream, U.S. West Newsstream\nTable 1: Search conditions to collect related news articles from ProQuest.\nbecause common names of popular LLMs (e.g., “PaLM”)\noverlap with regular expressions (e.g., “palm”). Thus, we\nimplemented a third filtration requiring the mention of pop-\nular LLMs alongside their respective company names. For\ninstance, “PaLM” needed to be paired with “Google.” Im-\nplementing these conditions resulted in a final dataset com-\nprising 24,827 news articles for subsequent analysis.\nPrior to topic modeling, we further cleaned the text. This\nprocess included removing short URLs, digits, emojis, and\npunctuation from news. Additionally, non-informative stop-\nwords like “the,” “is,” and “and” were eliminated from the\ntext. Subsequently, we tokenized each piece of news into\nindividual words and characters and then lemmatized to\ntheir base or stemming forms. The resulting dataset contains\n24,827 English news articles, with their full text, title, au-\nthor, publication date, publication country, and publication\naddress.\nData Profiling\nOur dataset, sourced from the ProQuest Newsstream\ndatabase, comprises 24,827 English-language news articles\nfrom a diverse array of publications. To give an overview\nof the dataset, we categorized these news outlets into\nthree groups, based on the categorization used by Pro-\nQuest Newsstream databases, such as (ProQuest 2023b),\nand corroborated by existing literature, such as (Shearer and\nMitchell 2021). The groups are US national news outlets, US\nlocal and specialized news outlets, and international news\noutlets. The categorization details are provided in Table 2.\nWithin the US national news outlets category, our dataset\nincludes publications like the Wall Street Journal, which\nalone contributes 607 articles and accounts for 60% of the\narticles in this category. Other major US national news out-\nlets in our dataset include USA Today (228, 22%) and The\nNew York Times (128, 13%). These outlets are generally\nrecognized for their national presence and have a significant\nimpact on shaping public opinion and national discourse.\nPopular US local and specialized news outlets and pub-\nlishers in our dataset include: PR Newswire (1921, 24%),\nBusiness Wire (1155, 15%), Targeted News Service (1124,\n14%), University Wire (723, 10%), Politico (348, 4%), and\nBoston Globe (111 2%). Publishers like PR Newswire and\nBusiness Wire usually disseminate press releases and cor-\nporate news, while specialized news outlets like Politico fo-\ncus on political journalism and in-depth coverage of Wash-\nington D.C. and policy, and local news outlets like Boston\nGlobe cater to specific local or regional audiences with news\nthat resonates with their immediate geographical and cul-\ntural context.\nWithin the international news outlets category, top out-\nlets in our dataset are: India’s The Times of India (753,\n5%), Indian Express (645, 4%), Mint (4%), IANS English\n(471, 3%), and Financial Express (448, 3%); UK’s Tele-\ngraph.co.uk (393, 2%) and The Guardian (369, 2%); and\nThailand’s Asia News Monitor (286, 2%). These outlets rep-\nresent a rich source of international English news coverage\nand contribute to the geographical diversity of our dataset,\nespecially in Asia.\nMethodology\nBERT Topic Modeling\nTopic modeling allows us to identify semantic themes in a\nlarge volume of textual data (Vayansky and Kumar 2020).\nTo mine the themes from the collected news data, we ap-\nplied the BERTopic technique, which involves using BERT\nword embedding to extract semantically relevant sentence\nembeddings from documents. We chose BERTopic over La-\ntent Dirichlet Allocation (LDA) for topic modeling due to its\ndistinct advantage in understanding the semantic meanings\nof words with contextualized representation (Reimers and\nGurevych 2019). Prior research has also demonstrated that\nBERTopic outperforms both LDA and Top2Vec (Egger and\nYu 2022) and exhibits comparable efficacy to prompt LLMs\n(Wang et al. 2023) in identifying topics extracted from on-\nline posts.\nDue to the high dimensionality of the vectors generated\nby the BERT embedding from news text that presents a chal-\nlenge for machine processing, we utilized a dimensionality\nreduction technique called Uniform Manifold Approxima-\ntion and Projection (UMAP) proposed by McInnes et al.\n(McInnes, Healy, and Melville 2018). The UMAP method\ncan help to mitigate high dimensionality issues while retain-\ning the local and global structure of the dataset (McInnes,\nHealy, and Melville 2018).\nSubsequently, we used the elbow method in conjunction\nwith K-means to determine the optimal number of clusters\nfor topic modeling. The elbow method is a graphical method\nthat allows us to find the best K clusters by assessing the\nWithin-Cluster Sum of Squares (WCSS) — the summation\nof squared distances between cluster points and their cen-\ntroids. We implemented the experimentation using numbers\nranging from 2 to 300 clusters, as depicted in Figure 1. This\nfigure shows a significant reduction in WCSS, around 50\nclusters. For a more refined clustering result, we chose to use\n1663\nNews outlet Pub title Count Sampled news title\nUS national news Wall Street Journal 607 “OpenAI to Offer ChatGPT Subscription Plan for $20 a Month;”\n“How Worried Should We Be About AI’s Threat to Humanity?\nEven Tech Leaders Can’t Agree”\nUS national news\nUSA Today 176 “Why Elon Musk wants to build ChatGPT competitor: AI chatbots\nare too ‘woke’;” “Sears pioneered the modern prefab house in the\nearly 20th century: Look back at ‘kit homes”’\nUS national news\nThe New York Times 128 “Microsoft Says New A.I. Shows Signs of Human Reasoning;”\n“Google Tests an A.I. Assistant That Offers Life Advice”\nUS local and spe-\ncialized news\nPR Newswire 1921 “Pioneering Real-World AI: Wecover Platforms Brings Genera-\ntive AI Experience to MBA Students at Georgia State University;”\n“Treehouse Adopts AI to Help Students Prepare for the Next Great\nTechnology Wave”\nUS local and spe-\ncialized news\nBusiness Wire 1155 “Folloze AI, Powered by ChatGPT, adds Critical Layer of Buyer\nEngagement Insights to Drive Increased Revenue;” “Flatiron\nSchool Launches New Artificial Intelligence Training Programs”\nUS local and spe-\ncialized news\nBarron’s 431 “$90 Billion Valuation for Open AI? Tech’s New Star Is Red Hot;”\n“AI to Pick Stocks? JPMorgan’s Move Hints at Banks Following\nBig Tech’s Lead”\nInternational news\nThe Times of India 753 “Google to launch new chatbots for advertisers and YouTube con-\ntent creators;” “Samsung bans use of ChatGPT and other AI tools\nfor employees”\nInternational news\nThe Guardian 369 “Monday briefing: What the AI boom really means for your job\n(and mine);” “Everything you wanted to know about AI but were\nafraid to ask”\nInternational news\nSouth China Morning\nPost\n275 “Baidu’s ChatGPT alternative gets positive reviews for handling\nof Chinese translations as search giant’s stock jumps;” “Alibaba\ntests ChatGPT rival as Chinese tech giants like Baidu race to build\ncountry’s best AI chatbot”\nTable 2: Representative examples of categorization of news outlets.\n100 clusters to manage our collected news data. This han-\ndling enhances granularity and precision while allowing the\nresearch team to use a bottom-up approach (i.e., manually\nannotating each of the 100 clusters into categories) to vali-\ndate these clusters. With the determined optimal K = 100,\nwe applied K-Means clustering (Buitinck et al. 2013) to\ngroup articles in the dataset into 100 clusters. Specifically,\nwe applied the model to the main text of news articles, given\nthat it holds richer information than news titles.\nThe final stage of our topic modeling process involves the\nrepresentation of topics. We used a count vectorizer tech-\nnique called the class-based Term Frequency-Inverse Docu-\nment Frequency (c-TF-IDF) within the Scikit-learn Python\npackage (Grootendorst 2022) to tokenize the topics. This\nmethod can help to extract the topical keywords and rep-\nresentative documents from each cluster.\nQualitative Coding\nUsing BERTopic to cluster news articles prompted a subse-\nquent need to categorize the topics of the clusters of news\narticles. To do so, we first employed an iterative approach\nthat combined both top-down and bottom-up processes to\nidentify the potential topics. For consistency, we used the\nterm “cluster” to refer to the clusters returned by BERTopic\nand the term “topic” to refer to the manually identified topic\nFigure 1: Result of the Elbow method to determine the opti-\nmal K clusters in BERTopic modeling.\ninformation from each cluster. In the top-down phase, we\nreferenced relevant papers, such as the work by (Sun et al.\n2020), which identified 14 key topics in news articles re-\nlated to emerging AI technologies. These encompassed ed-\nucation, healthcare, job market, life science, business, risk\nassessment, art and creation, regulation and policy, gaming,\nsoftware, transportation, robotics, and algorithms. Drawing\ninsights from prior research enabled us to collect potential\ngeneral topics the news articles cover regarding emerging AI\n1664\ntechnology. For the bottom-up process, we reviewed a ran-\ndom sample of 100 collected articles and manually assigned\ntopics to each article based on our understanding and exper-\ntise on the subject. This bottom-up process ensured that the\ncollected topics aligned with our specific context and con-\ntributed to the completeness of our compiled list.\nUpon collecting candidate topics, the first four authors of\nthe research team engaged in a brainstorming session to dis-\ncuss and refine the identified topics. Following three itera-\ntions, we finalized the topics into a set of 10 topics, including\neducation, business, labor and work, corporate technologi-\ncal development, regulation and security, content creation,\nhealthcare, politics, finance, and a “miscellaneous” category\ncovering areas like engineering applications and robot de-\nvelopment. We removed articles that are tangentially related\nto LLMs in this process, which amounts to about 10% of the\nentire dataset.\nNext, we employed a “paired-coding” method to label\neach cluster output by BERTopic. That is, each cluster was\nguaranteed to be labeled by two authors. During the label-\ning process, each author first examined the representative\nword list generated through the c-TF-IDF method in the\nBERTopic model. Then, we reviewed a sample of news ar-\nticles within each cluster. Next, each author independently\nlabeled the cluster and assigned it to one of the ten predeter-\nmined topics. During this labeling process, we also observed\na few clusters that were unrelated to LLMs settings, which\nwere excluded from subsequent analysis.\nAfter each author completed the labeling, we employed\nKrippendorff’s α (Krippendorff 2018), an inter-coder reli-\nability index, to quantify the level of agreement between\nindependent annotators. In our experiment, the calculated\nKrippendorff’s α is 0.88. As suggested, a Krippendorff’s α\nabove 0.8 is generally indicative of good agreement (Krip-\npendorff 2018). For clusters that received different labels,\nwe conducted an additional brainstorming session. Through\nthe discussion, all authors reached a consensus on the anno-\ntation for each cluster. The results of the topic annotation are\nlisted in the table below.\nSentiment analysis\nWith each news article categorized into a topic, we em-\nployed sentiment analysis to identify whether the new ar-\nticle carries a positive, neutral, or negative sentiment. This\nallowed us to further make the comparative analysis from\nboth temporal and spatial perspectives regarding the sen-\ntiment. We used the RoBERTa-base model (Barbieri et al.\n2020; Loureiro et al. 2022) to implement the sentiment anal-\nysis.\nRoBERTa is a robustly optimized Bidirectional Encoder\nRepresentations (BERT) pre-training approach based on\nBERT embedding. BERT embedding is built on trans-\nformer’s architecture and attention mechanisms to create\ncontextualized representations from the text. The RoBERTa-\nbased sentiment model was fine-tuned for sentiment analy-\nsis using the TweetEval benchmark. (Barbieri et al. 2020)\nalso enhanced the model by integrating a dense layer to re-\nduce the dimensions in the last layer to match the number of\nclassifications in the sentiment task. This model has been\ndemonstrated to outperform FastText and Support Vector\nMachine (SVM)-based models employing n-gram features.\nSpecifically, it achieved an accuracy of about 72% on the\nTweetEval testing dataset, as compared to the 63% accuracy\nachieved by SVM and FastText (Barbieri et al. 2020).\nLoureiro et al. further enhanced the model using an ex-\npanded training corpus of social media postings, consisting\nof 123.86 million tweets collected until the end of 2021,\na notable increase from its predecessor’s 58 million tweets\n(Loureiro et al. 2022). This update resulted in an improved\nperformance of sentiment analysis, demonstrating an accu-\nracy of 73.7% on the TweetEval dataset (Loureiro et al.\n2022).\nFindings\nManually coding the news articles by a variety of themes\ngave us the following distribution of news: there are 4798 ar-\nticles (19%) on corporate technological development, 4031\narticles (16%) on regulation and security, 3177 articles\n(13%) on business, 2710 articles (10%) on education, 1925\narticles (10%) on labor and work, 1117 articles (8%) on\ncontent creation, 1049 articles (6%) on finance, 1043 arti-\ncles (4%) on healthcare, and 1008 articles (4%) on politics.\nAbout 6% articles cover other miscellaneous topics. Table 3\npresents the codebook used in qualitative coding and the re-\nlationship between topics of articles and BERTopic clusters\nin more detail, with examples of representative BERTopic\nclusters for each topic.\nRQ1: When were news articles of different topics\npublished and where?\nTemporal distribution of articles by topic. Based on\ntopic modeling and qualitative coding results, we analyzed\nthe temporal distribution of article topics, centering on ar-\nticles published following the introduction of ChatGPT in\nNovember 2022. Figure 2 shows a time series of the num-\nber of articles across different topics. The dominant top-\nics throughout this period–business, corporate technologi-\ncal development, regulation and security, and education–\nunderscore the impact of LLMs across these topics. Over the\nspan of a year, from November 2022 to November 2023, we\nobserved notable variability in the volume of articles across\ntopics. The moments of high news coverage may be related\nto key developments or product releases of LLMs, the shift-\ning focus areas in news coverage, as well as the news’ re-\nsponsiveness to specific events in the course of new technol-\nogy development.\nFor example, the topic of corporate technological devel-\nopment shows a significant spike in articles in the weeks of\nFebruary 12, 2023, and February 19, 2023. This could indi-\ncate a surge of interest or events related to the introduction\nof Bard by Google on February 6 and Microsoft’s launch of\nan updated version of its Bing search engine on February\n7. In another example, the topic of regulation and security\nsees a surge in the week of May 7, 2023, which might be\nrelated to the White House’s meeting with CEOs of large\ntechnology companies on advancing responsible AI innova-\ntion on May 4. The variability and volume of coverage for\n1665\nTopic Explanation #Clusters #Articles Representative clusters (keywords)\nCorporate\ntechnological\ndevelopment\nDevelopment and innovation of\nLLMs led by corporate\ncompanies\n17 4798 chatgpt-language-model-user,\nbard-google-search-pichai,\nmicrosoft-copilot-openai-bing,\nuser-image-content\nRegulation and\nsecurity\nRisks, ethical issues, and\npolicies of AI, including AI\nregulation in global context\n15 4031 ai-congress-agency-government,\nattack-cybersecurity-cyber-phishing,\nsecurity-cybersecurity-data-threat,\neu-european-act-parliament\nBusiness\nImpact on customer service\nand user experience, product\nmanagement, marketing, and\nretail\n9 3177 data-cloud-customer-enterprise,\ncustomer-business-solution-data,\ngenerative-ai-business-customer,\nbrand-customer-retailer-consumer\nEducation\nLLMs’ applications in the\nschool context, and its impact\non students, teachers, and\nprofessors\n8 2710 student-school-teacher-education,\nstudent-college-professor-university,\nscience-research-university-student,\ntext-chatgpt-write-paper\nLabor and work\nLLMs’ impact on labor force\nand job market\n6 1925 job-worker-ai-work,\njob-hr-employee-skill,\nnews-journalist-journalism-medium\nContent creation\nThe use of LLMs in creative\nfields, including writing,\nmusic, and art\n5 1117 writer-film-actor-strike,\nmusic-song-artist-elvis,\nart-image-artist-create\nFinance\nLLMs’ impact on investment,\nstock, cryptocurrency, or\ncompany revenue\n4 1049 investor-stock-investment-fund,\nfinancial-company-investment-investor,\ncrypto-cryptocurrency-worldcoin-\nblockchain\nHealthcare\nLLMs’ applications in\nanalyzing biomedical\ninformation and healthcare\n6 1043 health-patient-healthcare-care,\nmedical-patient-doctor-health,\ndrug-protein-cell-disease\nPolitics LLMs’ impact on US politics\nand elections, and global\npolitics of AI\n5 1008 trump-republican-ramaswamy-debate,\nlabour-political-conservative,\njapan-kishida-minister-japanese\nMiscellaneous\nLLMs’ applications in other\nareas such as food and\nenvironment\n7 1371 energy-water-carbon-climate,\nfood-restaurant-recipe-eat\nTable 3: Topic identification and examples of representative clusters within each topic.\neach topic would indicate their relevance and newsworthi-\nness.\nSpatial distribution of articles by topic. We found dis-\ntinct patterns reflective of regional focus and interests by ex-\namining the spatial distribution of news articles by topic. For\nthis analysis, we focused on the top five countries by article\ncount (US, India, UK, Australia, and Canada), as illustrated\nin Figure 3.\nIn the US, the topic of business constitutes the largest seg-\nment of articles (2013 articles, 21% of all articles in this\ncountry), followed closely by corporate technological de-\nvelopment (1725, 18%) and education (1477, 16%). The\nprominence of news coverage on those topics may reflect\nthe country’s news attention on business-related technolog-\nical implications, technological advancements by corporate\ncompanies, and the widespread impact of LLMs on educa-\ntional frameworks. India’s news distribution shows that an\noverwhelming majority of articles concentrated on corpo-\nrate technological development (1605, 38%). This focus in-\ndicates the country’s burgeoning tech industry and the rapid\ndevelopment of technology that drives media attention. The\nUK exhibits a more balanced distribution, with a substan-\ntial portion of articles dedicated to regulation and security\n(734, 31%), followed by corporate technological develop-\nment (452, 19%). This could suggest heightened awareness\nand engagement with LLMs regarding governance and the\nimplications for security frameworks within the region. In\nAustralia, similar to the UK, a significant share of coverage\nis directed at regulation and security (267, 22%), suggesting\na national focus on LLMs’ governance and ethical impli-\ncations. This is closely followed by education (249, 21%),\nwhich might reflect the country’s prioritization of educa-\ntional initiatives in LLMs. Canada’s news articles display\na strong emphasis on regulation and security (320, 35%),\nwhich is the most prominent topic, overshadowing corpo-\nrate technological development (135, 15%) and other topics.\n1666\nFigure 2: Temporal trends of news articles across topics.\nThis might suggest Canada’s proactive stance in addressing\nthe complexities of AI governance and the associated secu-\nrity challenges.\nComparing the news coverage across countries reveals\ndistinct national interests and priorities in investing in and\ncoping with LLMs. For instance, corporate technological de-\nvelopment and business are leading topics in the US and\nIndia, which could reflect their positions as major hubs of\ntechnological innovation. In contrast, the UK, Australia, and\nCanada show a heightened interest in regulation and secu-\nrity, pointing to a more cautious and governance-oriented\napproach. Australia’s focus on education suggests an invest-\nment in developing human capital to navigate and leverage\ntechnological advancements.\nRQ2: What is the sentiment of articles?\nWe utilized a RoBERTa-based model to determine the sen-\ntiment of each article, which categorized them into nega-\ntive, neutral, and positive sentiments. The overall discourse\nin the news articles on LLMs is neutral and positive, with\n66% neutral and 28% positive sentiment articles. The ten-\ndency towards positive sentiment across diverse topics may\nreflect an overall optimistic or progressive narrative in media\nreporting or a trend in the media towards focusing on pos-\nitive aspects or developments within these areas, which has\nbeen documented by prior scholarship (Garvey and Maskal\n2020). In this section, we delve deeper into the news articles\nby looking into the topic, type of news outlet, and content to\ncapture the nuances behind the predominance of neutral and\npositive sentiments.\na.\nb.\nFigure 3: Collected English news articles (a) Spatial distri-\nbution across countries and regions. (b) Count and percent-\nage of news articles of the top five countries across topics.\nWe show the distributions of the top five countries in terms\nof the count of English news articles in this plot.\nTemporal sentiment of articles by topic For each of the\ntop four topics (business, corporate technological develop-\nment, regulation and security, and education), we computed\nweekly sentiment scores for articles within the topic from\nNovember 2022 to November 2023. The sentiment scores\nwere calculated using a scale where positive sentiment was\nassigned a value of 1, negative sentiment a value of -1, and\nneutral sentiment a value of 0. These values were then aver-\naged on a weekly basis to produce a score ranging from -1\nto 1 to normalize for comparison.\nFigure 4 presents a weekly sentiment analysis trend of\narticles across four topics: corporate technological devel-\nopment, regulation and security, business, and education.\nThere are observable differences in sentiment across the four\ntopics. Business and corporate technological development\ngenerally show more positive sentiment scores compared to\nthe other topics, indicating news articles on these topics are\noften reported with a positive tone. The topic of education\nalso trends positively, though with some variation, suggest-\ning a generally favorable portrayal in the news. Regulation\nand security articles exhibit a markedly lower sentiment, of-\nten hovering around the neutral to negative areas. This trend\n1667\nFigure 4: Weekly sentiment scores from November 2022 to\nNovember 2023, for the top four topics: corporate techno-\nlogical development, regulation and security, business, and\neducation.\nmay reflect the inherently critical nature of news related to\nregulatory measures and security issues, which often involve\nreporting on conflicts, debates, and challenges within the\nrealm of AI governance. As such, the sentiment of news ar-\nticles may influence public perception and discourse around\nthese aspects of LLMs.\nSentiment of articles by news outlet. Sentiment towards\nLLMs varies significantly across different types of news out-\nlets. For each of the three news outlet categories, we obtain\na list of sentiment scores using the same scale as before,\nwhere positive sentiment was assigned a value of 1, negative\nsentiment a value of -1, and neutral sentiment a value of 0.\nWe performed the non-parametric Kruskal-Wallis H-test\ntest on sentiment scores of three groups of news outlets: US\nnational, US local and specialized, and international news\noutlets. With a test statistic of 141.12 and a significant p-\nvalue (≤ 0.001), there is a statistically significant difference\nin sentiment scores among these groups. This result is fur-\nther substantiated by the pairwise comparisons of Dunn’s\ntest in Table 4 that accounted for multiple comparisons.\nSpecifically, international news outlets are more neutral\ncompared to US national news outlets, while US local and\nspecialized news outlets show a tendency towards more pos-\nitive sentiment. This may imply that US local and special-\nized outlets are experiencing more positive impacts or are\nmore optimistic about the potential of LLMs. Additionally,\nthe prevalence of positive sentiment in US local and spe-\ncialized news might be related to their sourcing strategies,\nwhich could include a higher proportion of press releases\nfrom news wire services. Conversely, US national news out-\nlets may adopt a more cautious or critical stance, reflect-\ning their broader audience and perhaps a responsibility to\npresent a more balanced view of the developments in LLMs.\nRQ3: What are the articles about?\nIn this section, we delved into the substantive themes within\nLLMs news discourse. Building on the spatiotemporal and\nsentiment analysis conducted in RQ1 and RQ2, which indi-\ncated a predominantly positive media perspective across var-\nType 1 Type 2 Mean Diff Adj. p-value\nInternational US national -0.069 0.0***\nInternational US local 0.0813 0.0***\nUS national US local 0.1503 0.0***\n*p ≤ 0.05, **p ≤ 0.01, ***p ≤ 0.001\nTable 4: Dunn’s test for multiple pairwise comparisons of\nnews outlet types, as well as the mean difference in senti-\nment scores between news outlet types.\nious topics, RQ3 seeks to elucidate the content that charac-\nterizes these discussions. Considering the scope of the paper,\nwe focused on the four primary topics in news coverage of\nLLMs: business, corporate technological development, reg-\nulation and security, and education.\nThrough semantic network analysis—a method that vi-\nsualizes the associative relationships between terms in a\ngiven discourse (Van Eck and Waltman 2014; Jung and\nLee 2020)—we synthesized the common narratives and\nterminologies prevalent in the positively-toned news arti-\ncles within these domains. Utilizing the VOSviewer tool\n(Van Eck and Waltman 2013), we aimed to unearth the fre-\nquent sub-themes resonating in optimistic news narratives.\nThe results are presented in Figure 5.\nWithin the semantic network of topic business (Figure\n5(a)), the green cluster centers around LLMs solutions and\ntheir applications at an enterprise level. The interplay of\nterms like “enterprise”, “ai solutions”, and “efficiency” sug-\ngests a focus on the pragmatic application of LLMs in en-\nhancing business processes and reflects an optimistic nar-\nrative that appreciates the integration of LLMs, and NLP\napplications in business settings. A separate but equally\ncompelling narrative emerges in the blue cluster: “startup”,\n“technology”, “workforce”, “skill”, and “creativity”. The\nlexicon of innovation illustrates a dialogue on AI’s role\nin redefining professional landscapes and fostering creative\neconomies. In addition, the yellow-hued cluster emerges on\nthe top of this network, centering on the topics of company\nrevenues, stock shares, and financial statements.\nCorporate technological development stands out as an-\nother prominent topic in the news discussions, and Figure\n5(b) shows the semantic network for this topic. One sig-\nnificant cluster within this network underscores the con-\ntributions of technology giants like “NVIDIA”, “Google”,\n“Microsoft”, “Amazon”, “Meta”, and “Apple” to advanc-\ning LLM products. This cluster underlines the tech indus-\ntry’s focus on corporate growth, technological innovation,\nand infrastructure. It also reflects the significance of LLMs\nand their role in the current tech ecosystem. The other ma-\njor cluster, represented by the green segment, focuses on\nhow LLM products can elevate knowledge, drive design\ninnovation, and benefit users. Prime examples of such ad-\nvancements include tools like “Copilot”, “Bard” and “Bing”\nSearch. Additionally, prominent figures frequently featured\nin the news, such as Elon Musk and Sam Altman, are asso-\nciated with these discussions.\nWithin the semantic network of regulation and secu-\n1668\nFigure 5: Semantic network for the most discussed four topics covered by news articles, (a) Business, (b) Corporate technolog-\nical development, (c) Regulation and security, and (d) Education.\nrity (Figure 5(c)), the green cluster emphasizing “security,”\n“team,” and “solution,” which indicates a discourse centered\naround cybersecurity and collaborative approaches to safe-\nguarding digital ecosystems. This narrative is complemented\nby national and global “governance” hinting at the regula-\ntory and ethical dimensions of AI technologies. The blue\ncluster highlights the discussion of whether to embrace cur-\nrent LLMs trends. These discussions emphasize the ongoing\ndevelopment of LLMs as a prevailing trend. While the pro-\ngression has revolutionized knowledge and skills, enabling\nbots to engage in interactive conversations with users, arti-\ncles within this cluster advocate for regulating AI use for the\nbetterment of humanity.\nLast, the education network reveals three distinct clus-\nters (Figure 5(d)). The green cluster spotlights the imple-\nmentation of LLMs within academic institutions and in-\ndustry, encompassing terms like “college”, “institute”, “fac-\nulty”, “staff”, “professor”, and “professional”. This suggests\na significant emphasis on AI’s role in personalizing learning\nexperiences and managing educational resources. The blue\ncluster hints at a narrative surrounding “answer”, “home-\nwork”, “assignment”, “teacher”, “parent”, and “creativity”,\nindicating a focus on the human elements of education, in-\ncluding the impact on students and educators. The overall\ndiscourse explores the potential of AI to support or trans-\nform traditional educational roles and outcomes. In the yel-\nlow cluster, a more technical discussion is illustrated by the\npresence of terms like “large language model”, “gpt”, “out-\ncome”, “platform”, and “tool”, suggesting an examination\nof specific AI tools and their implications for educational\ntechnology.\nDiscussion and Conclusions\nKey findings. Our findings provide a comprehensive por-\ntrayal of LLMs’ reception in global news media based on an\nin-depth descriptive analysis of news articles after the intro-\nduction of BERT in 2018. This paper offers rich empirical\ninsights into the temporal and spatial distribution of topics,\nsentiment, and substantive themes in major topics of news\narticles on LLMs.\nTemporal patterns reveal variabilities in coverage across\nkey topics—business, corporate technological development,\n1669\nregulation and security, and education—with spikes in ar-\nticles coinciding with major AI developments and policy\ndiscussions, such as the release of Google’s Bard and Mi-\ncrosoft’s Bing in early 2023, and the White House’s AI\nmeeting in May 2023. Spatially, there’s a clear delineation of\nfocus, with the US and India leading in business and tech de-\nvelopment coverage, whereas the UK, Australia, and Canada\nare more attuned to regulation and security. Notably, Aus-\ntralia exhibits a unique concentration on education.\nSentiment analysis via a RoBERTa-based model indicates\na predominantly neutral to positive media stance, with 66%\nof articles being neutral and 28% positive. News articles\non topics like business and corporate technological develop-\nment show a more positive sentiment, and articles on regu-\nlation and security show a more reserved, neutral to negative\nsentiment, reflective of the critical nature of the discourse in\nthese areas. This finding underscores the intricate nature of\nglobal media’s portrayal of LLMs’ integration into different\nindustries and societies, reflecting the diverse responses it\nreceives in different contexts.\nIn terms of content, business-related articles focus on the\npragmatic application of LLMs at an enterprise level, with\na parallel narrative on AI’s influence on reshaping profes-\nsional spheres and fostering creative economies. News about\ncorporate technological development is marked by the con-\ntributions of tech giants to generative AI products and their\nimplications for user benefit and industry innovation. Reg-\nulation and security discussions pivot around cybersecurity,\ncollaborative solutions, and the balancing act between em-\nbracing innovation and establishing governance for AI’s eth-\nical use. Education-related news coverage unveils three nar-\nratives: the integration of AI in academic and professional\ndevelopment, the impact on traditional educational roles,\nand a technical exploration of AI tools in educational set-\ntings.\nLimitations and opportunities for future work. Our\nstudy presents several limitations, which in turn illuminate\npotential paths for more comprehensive and detailed re-\nsearch in future endeavors. Firstly, our data collection was\nrestricted to English articles, which could result in biased\nanalysis for those non-English-speaking countries, particu-\nlarly in the global south. Future efforts could involve col-\nlecting news articles in diverse languages, which would pro-\nvide a more comprehensive global perspective. Limitations\nin data collection also stem from our access to ProQuest’s\nnewsstream databases, which is contingent on our univer-\nsity’s subscription policies, as well as from ProQuest’s own\nmanagement and curation of these resources. Although full-\ntext access to the US major dailies newsstream database is\nunavailable through our portal, we accessed full-text articles\nfrom these outlets via other ProQuest newsstream databases.\nWhile we cross-validated these articles by consulting the\noriginal news outlets, this approach may not capture the full\nspectrum of US national news coverage. To address this gap,\nfuture research could focus specifically on US national news\noutlets to ensure a more comprehensive analysis of such\nnews articles.\nSecondly, the topic modeling approach presents two lim-\nitations. First, the assumption that each document contains\nonly a single topic doesn’t always align with the complex-\nity of news articles, potentially leading to suboptimal rep-\nresentations by BERTopic. In addition, we observed in-\nstances where clusters encompassed news articles from dif-\nferent topics. This is possibly because BERTopic clusters\nrely solely on textual similarity for clustering. Particularly,\nthose clusters with a significant number of news articles are\nmore likely to have diverse topics. To overcome this limita-\ntion, future research could explore LLMs, such as integrat-\ning GPT-based models into the topic modeling process, al-\nlowing for the generation of multiple topics for a single news\narticle. Future work could also consider designing prompts\nto interact with LLMs (Wang et al. 2023) to improve the\nperformance of topic modeling.\nThirdly, future work could consider improving sentiment\nanalysis based on more granular units (e.g., paragraph-level\nor sentence-level) for news articles. Our current sentiment\nanalysis provides a singular classification for each news\nitem, regardless of the potential for conflicting sentiments\nwithin an article. This could affect our analysis, especially\nwhen a news article covers some topics that might be unre-\nlated to LLMs. To overcome this, one future direction could\ninvolve a more nuanced analysis, such as sentiment exam-\nination at the paragraph level in news articles. Moreover,\nthe accuracy of sentiment analysis relies on the RoBERTa-\nbase model’s capabilities, which was specifically trained on\nTweetEval benchmark for sentiment analysis rather than the\nnews context, possibly leading to inaccuracies. Another av-\nenue for future work could explore other sentiment tools,\nespecially those using LLMs trained on news data. Analyses\nand interpretations of news articles’ content and sentiment\ncould be further enhanced by taking into account the poten-\ntial biases of news outlets that may influence the portrayal\nof technological advancements.\nLastly, future research could also potentially involve inte-\ngrating additional types of generative AI models, such as vi-\nsual generative models like DALL-E and SORA. The inclu-\nsion of diverse technologies will allow for an investigation\ninto the variation in the coverage and portrayal of different\ntypes of generative models across various domains in news\nreports. With a more holistic understanding of news cover-\nage related to generative AI, future research may better cap-\nture evolving trends and facilitate the broader discussion on\nthe ethics of generative AI.\nAcknowledgments\nWe would like to thank Shevon Desai at the University\nof Michigan Library for recommending relevant databases,\nBrandon Williams at ProQuest for assisting us in accessing\ndata from ProQuest TDM Studio, and the anonymous re-\nviewers for their thoughtful feedback.\nReferences\nBarbieri, F.; Camacho-Collados, J.; Neves, L.; and Espinosa-\nAnke, L. 2020. Tweeteval: Unified benchmark and com-\nparative evaluation for tweet classification. arXiv preprint\narXiv:2010.12421.\n1670\nBrossard, D. 2013. New media landscapes and the sci-\nence information consumer. Proceedings of the National\nAcademy of Sciences, 110(supplement 3): 14096–14101.\nBuitinck, L.; Louppe, G.; Blondel, M.; Pedregosa, F.;\nMueller, A.; Grisel, O.; Niculae, V .; Prettenhofer, P.; Gram-\nfort, A.; Grobler, J.; et al. 2013. API design for machine\nlearning software: experiences from the scikit-learn project.\narXiv preprint arXiv:1309.0238.\nChuan, C.-H.; Tsai, W.-H. S.; and Cho, S. Y . 2019. Framing\nArtificial Intelligence in American Newspapers. InProceed-\nings of the 2019 AAAI/ACM Conference on AI, Ethics, and\nSociety, AIES ’19, 339–344. New York, NY , USA: Associ-\nation for Computing Machinery. ISBN 9781450363242.\nDandurand, G.; McKelvey, F.; and Roberge, J. 2023. Freez-\ning out: Legacy media’s shaping of AI as a cold controversy.\nBig Data & Society, 10(2): 20539517231219242.\nDelellis, N. S.; Chen, Y .; Cornwell, S. E.; Kelly, D.; May-\nhew, A.; Onaolapo, S.; and Rubin, V . L. 2023. ChatGPT\nMedia Coverage Metrics; Initial Examination. Proceedings\nof the Association for Information Science and Technology,\n60(1): 935–937.\nEgger, R.; and Yu, J. 2022. A topic modeling comparison\nbetween lda, nmf, top2vec, and bertopic to demystify twitter\nposts. Frontiers in sociology, 7: 886498.\nFast, E.; and Horvitz, E. 2017. Long-term trends in the pub-\nlic perception of Artificial Intelligence. Proceedings of the\nAAAI Conference on Artificial Intelligence, 31(1).\nGarvey, C.; and Maskal, C. 2020. Sentiment Analysis of\nthe News Media on Artificial Intelligence Does Not Sup-\nport Claims of Negative Bias Against Artificial Intelligence.\nOMICS: A Journal of Integrative Biology, 24(5): 286–299.\nPMID: 31313979.\nGrootendorst, M. 2022. BERTopic: Neural topic model-\ning with a class-based TF-IDF procedure. arXiv preprint\narXiv:2203.05794.\nJung, H.; and Lee, B. G. 2020. Research trends in text min-\ning: Semantic network and main path analysis of selected\njournals. Expert Systems with Applications, 162: 113851.\nKrippendorff, K. 2018. Content analysis: An introduction to\nits methodology. Sage publications.\nLoureiro, D.; Barbieri, F.; Neves, L.; Anke, L. E.; and\nCamacho-Collados, J. 2022. Timelms: Diachronic language\nmodels from twitter. arXiv preprint arXiv:2202.03829.\nMarr, B. 2023. The difference between generative AI and\ntraditional AI: An easy explanation for anyone. Forbes.\nMcInnes, L.; Healy, J.; and Melville, J. 2018. Umap: Uni-\nform manifold approximation and projection for dimension\nreduction. arXiv preprint arXiv:1802.03426.\nNguyen, D. 2023. How news media frame data risks in their\ncoverage of big data and AI. Internet Policy Review, 12(2).\nNguyen, D.; and Hekman, E. 2022. The news framing of ar-\ntificial intelligence: a critical exploration of how media dis-\ncourses make sense of automation. AI & SOCIETY, 1–15.\nProQuest. 2023a. ProQuest newsstream databases.\nProQuest. 2023b. ProQuest U.S. Major Dailies.\nProQuest. 2023c. TDM Studio.\nReimers, N.; and Gurevych, I. 2019. Sentence-bert: Sen-\ntence embeddings using siamese bert-networks. arXiv\npreprint arXiv:1908.10084.\nShearer, E.; and Mitchell, A. 2021. Broad agreement in US–\neven among partisans–on which news outlets are part of the\n‘mainstream media’.\nSun, S.; Zhai, Y .; Shen, B.; and Chen, Y . 2020. Newspaper\ncoverage of artificial intelligence: A perspective of emerging\ntechnologies. Telematics and Informatics, 53: 101433.\nVan Eck, N. J.; and Waltman, L. 2013. VOSviewer manual.\nLeiden: Univeristeit Leiden, 1(1): 1–53.\nVan Eck, N. J.; and Waltman, L. 2014. Visualizing biblio-\nmetric networks. In Measuring scholarly impact: Methods\nand practice, 285–320. Springer.\nVayansky, I.; and Kumar, S. A. 2020. A review of topic\nmodeling methods. Information Systems, 94: 101582.\nWang, H.; Prakash, N.; Hoang, N. K.; Hee, M. S.; Naseem,\nU.; and Lee, R. K.-W. 2023. Prompting Large Language\nModels for Topic Modeling. In 2023 IEEE International\nConference on Big Data (BigData), 1236–1241. IEEE.\n1671\nPaper Checklist\n1. For most authors...\n(a) Would answering this research question advance sci-\nence without violating social contracts, such as violat-\ning privacy norms, perpetuating unfair profiling, exac-\nerbating the socio-economic divide, or implying disre-\nspect to societies or cultures? Yes, and answering the\nresearch questions will contribute to understandings of\ndifferent societies and countries and their interaction\nwith emerging technologies.\n(b) Do your main claims in the abstract and introduction\naccurately reflect the paper’s contributions and scope?\nYes\n(c) Do you clarify how the proposed methodological ap-\nproach is appropriate for the claims made? Yes\n(d) Do you clarify what are possible artifacts in the\ndata used, given population-specific distributions?No,\nbecause our data is not about human subjects. We\ndid provide temporal and spatial distributions of our\ndataset.\n(e) Did you describe the limitations of your work? Yes,\nsee the opportunities for future work section\n(f) Did you discuss any potential negative societal im-\npacts of your work?No, because our work aims to pro-\nvide a comprehensive overview of the news coverage\nof large language models and positively contributes to\nthe general public’s understanding of emerging tech-\nnologies.\n(g) Did you discuss any potential misuse of your work?\nNo, because our work is a descriptive analysis of a spe-\ncific dataset.\n(h) Did you describe steps taken to prevent or mitigate po-\ntential negative outcomes of the research, such as data\nand model documentation, data anonymization, re-\nsponsible release, access control, and the reproducibil-\nity of findings? Yes, we described data documentation\nin detail in the data section.\n(i) Have you read the ethics review guidelines and en-\nsured that your paper conforms to them? Yes, our pa-\nper conforms to them.\n2. Additionally, if your study involves hypotheses testing...\n(a) Did you clearly state the assumptions underlying all\ntheoretical results? Yes\n(b) Have you provided justifications for all theoretical re-\nsults? Yes\n(c) Did you discuss competing hypotheses or theories that\nmight challenge or complement your theoretical re-\nsults? Yes, and we complement hypothesis testing with\npost-hoc analysis.\n(d) Have you considered alternative mechanisms or expla-\nnations that might account for the same outcomes ob-\nserved in your study? Yes, we provided multiple ex-\nplanations for the observation\n(e) Did you address potential biases or limitations in your\ntheoretical framework? No, because we don’t have a\ntheoretical framework.\n(f) Have you related your theoretical results to the existing\nliterature in social science? Yes\n(g) Did you discuss the implications of your theoretical\nresults for policy, practice, or further research in the\nsocial science domain? Yes, see the opportunities for\nfuture work section.\n3. Additionally, if you are including theoretical proofs...\n(a) Did you state the full set of assumptions of all theoret-\nical results? NA\n(b) Did you include complete proofs of all theoretical re-\nsults? NA\n4. Additionally, if you ran machine learning experiments...\n(a) Did you include the code, data, and instructions\nneeded to reproduce the main experimental results (ei-\nther in the supplemental material or as a URL)? NA\n(b) Did you specify all the training details (e.g., data splits,\nhyperparameters, how they were chosen)? NA\n(c) Did you report error bars (e.g., with respect to the ran-\ndom seed after running experiments multiple times)?\nNA\n(d) Did you include the total amount of compute and the\ntype of resources used (e.g., type of GPUs, internal\ncluster, or cloud provider)? NA\n(e) Do you justify how the proposed evaluation is suffi-\ncient and appropriate to the claims made? NA\n(f) Do you discuss what is “the cost“ of misclassification\nand fault (in)tolerance? NA\n1672\n5. Additionally, if you are using existing assets (e.g., code,\ndata, models) or curating/releasing new assets, without\ncompromising anonymity...\n(a) If your work uses existing assets, did you cite the cre-\nators? NA\n(b) Did you mention the license of the assets? NA\n(c) Did you include any new assets in the supplemental\nmaterial or as a URL? NA\n(d) Did you discuss whether and how consent was ob-\ntained from people whose data you’re using/curating?\nNA\n(e) Did you discuss whether the data you are using/cu-\nrating contains personally identifiable information or\noffensive content? NA\n(f) If you are curating or releasing new datasets, did you\ndiscuss how you intend to make your datasets FAIR\n(see ?)? NA\n(g) If you are curating or releasing new datasets, did you\ncreate a Datasheet for the Dataset (see ?)? NA\n6. Additionally, if you used crowdsourcing or conducted\nresearch with human subjects, without compromising\nanonymity...\n(a) Did you include the full text of instructions given to\nparticipants and screenshots? NA\n(b) Did you describe any potential participant risks, with\nmentions of Institutional Review Board (IRB) ap-\nprovals? NA\n(c) Did you include the estimated hourly wage paid to\nparticipants and the total amount spent on participant\ncompensation? NA\n(d) Did you discuss how data is stored, shared, and dei-\ndentified? NA\n1673",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.52399080991745
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I27837315",
      "name": "University of Michigan",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I201448701",
      "name": "University of Washington",
      "country": "US"
    }
  ]
}