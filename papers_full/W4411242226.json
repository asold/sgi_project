{
  "title": "Primer on large language models: an educational overview for intensivists",
  "url": "https://openalex.org/W4411242226",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5114338995",
      "name": "Daphna Idan",
      "affiliations": [
        "Ben-Gurion University of the Negev"
      ]
    },
    {
      "id": "https://openalex.org/A2181063413",
      "name": "Sharon Einav",
      "affiliations": [
        "Hebrew University of Jerusalem"
      ]
    },
    {
      "id": "https://openalex.org/A5114338995",
      "name": "Daphna Idan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2181063413",
      "name": "Sharon Einav",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4394598267",
    "https://openalex.org/W4316174545",
    "https://openalex.org/W4323655724",
    "https://openalex.org/W2515351093",
    "https://openalex.org/W3144293453",
    "https://openalex.org/W4389520445",
    "https://openalex.org/W4401445967",
    "https://openalex.org/W4401970104",
    "https://openalex.org/W3009486139",
    "https://openalex.org/W4400187039",
    "https://openalex.org/W4398183427",
    "https://openalex.org/W4393156327",
    "https://openalex.org/W4381309002",
    "https://openalex.org/W4401653419",
    "https://openalex.org/W4400315390",
    "https://openalex.org/W4390745503",
    "https://openalex.org/W4404800377",
    "https://openalex.org/W4387440167",
    "https://openalex.org/W4404547031",
    "https://openalex.org/W4391656025",
    "https://openalex.org/W4389505505",
    "https://openalex.org/W4400456285",
    "https://openalex.org/W4406421457",
    "https://openalex.org/W4388730844",
    "https://openalex.org/W4401514353",
    "https://openalex.org/W4400689087",
    "https://openalex.org/W4398201391",
    "https://openalex.org/W2462432627",
    "https://openalex.org/W4221121652",
    "https://openalex.org/W2999710344",
    "https://openalex.org/W4214662755",
    "https://openalex.org/W4395660483",
    "https://openalex.org/W4321366933",
    "https://openalex.org/W4388870338",
    "https://openalex.org/W4396775553",
    "https://openalex.org/W4390776874",
    "https://openalex.org/W4403420208",
    "https://openalex.org/W4378782408",
    "https://openalex.org/W4400324908",
    "https://openalex.org/W4392077003",
    "https://openalex.org/W3159250634",
    "https://openalex.org/W4389947931",
    "https://openalex.org/W4403813762",
    "https://openalex.org/W4406152263",
    "https://openalex.org/W4401084424"
  ],
  "abstract": "The integration of artificial intelligence (AI) and machine learning-enabled medical technologies into clinical practice is expanding at an unprecedented pace. Among these, large language models (LLMs) represent a subset of machine learning designed to comprehend linguistic patterns, semantics, and contextual meaning by processing vast amounts of textual data. This educational primer aims to inform intensivists on the foundational concepts of LLMs and how to approach emerging literature in this area. In critical care, LLMs have the potential to enhance various aspects of patient management, from triage and clinical documentation to diagnostic support and prognostic assessment of patient deterioration. They have also demonstrated high appropriateness in addressing critical care-related clinical inquiries and are increasingly recognized for their role in post-ICU rehabilitation and as educational resources for patients' families and caregivers. Despite these promising applications, LLMs still have significant limitations, and integrating LLMs into clinical workflows presents inherent challenges, particularly concerning bias, reliability, and transparency. Given their emerging role as decision-support tools and potential collaborative partners in medicine, LLMs must adhere to rigorous validation and quality assurance standards. As the trajectory toward AI-driven healthcare continues, responsible and evidence-based integration of LLMs into critical care practice is imperative to optimize patient outcomes while ensuring ethical and equitable deployment.",
  "full_text": "REVIEW Open Access\n© The Author(s) 2025. Open Access  This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 \nInternational License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you \ngive appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the \nlicensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or \nother third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the \nmaterial. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or \nexceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit  h t t p  : / /  c r e a  t i  \nv e c  o m m  o n s .  o r  g / l  i c e  n s e s  / b  y - n c - n d / 4 . 0 /.\nIdan and Einav Critical Care          (2025) 29:238 \nhttps://doi.org/10.1186/s13054-025-05479-4\nArtificial intelligence (AI) is broadly defined as the \nseeming ability of a device to perform tasks that typically \nrequire human cognitive skills, such as reasoning, learn -\ning, and decision-making. At its core, AI is intended to \nembody the capacity to “do the right thing” in a given \ncontext by employing logic-based methods efficiently and \nsafely.\nEarly AI systems were designed to achieve specific \noutcomes for well-defined tasks and are therefore often \nreferred to as task-specific AIs. Typical examples are the \nearly customer service chatbots, which relied on rigid \nrules to recognize specific keywords and generate pre-\nprogrammed responses to these words. These simple sys -\ntems relied on algorithms - mathematical constructs first \nformalized in the ninth century by the Persian mathema -\ntician Muhammad ibn Musa al-Khwarizmi. Algorithms \nIntroduction\nIn 2022, the US Food and Drug Administration (FDA) \napproved 139 medical devices incorporating artificial \nintelligence (AI) [ 1]. By August 2024, this number had \nsurged to 950 AI or machine learning-enabled medical \ndevices [ 2], highlighting the exponential growth of AI \nintegration into medicine in general and clinical practice \nin particular [3].\nCritical Care\n*Correspondence:\nDaphna Idan\ndaphnaid@post.bgu.ac.il\n1Ben-Gurion Faculty of Health Sciences, Beer-Sheva, Israel\n2Hebrew University Faculty of Medicine and Regional Medical Director \nat Maccabi Healthcare and Chief Scientist, Medint Medical Intelligence, \nHebrew University, Jerusalem, Israel\nAbstract\nThe integration of artificial intelligence (AI) and machine learning-enabled medical technologies into clinical \npractice is expanding at an unprecedented pace. Among these, large language models (LLMs) represent a subset \nof machine learning designed to comprehend linguistic patterns, semantics, and contextual meaning by processing \nvast amounts of textual data. This educational primer aims to inform intensivists on the foundational concepts of \nLLMs and how to approach emerging literature in this area. In critical care, LLMs have the potential to enhance \nvarious aspects of patient management, from triage and clinical documentation to diagnostic support and \nprognostic assessment of patient deterioration. They have also demonstrated high appropriateness in addressing \ncritical care-related clinical inquiries and are increasingly recognized for their role in post-ICU rehabilitation and \nas educational resources for patients’ families and caregivers. Despite these promising applications, LLMs still \nhave significant limitations, and integrating LLMs into clinical workflows presents inherent challenges, particularly \nconcerning bias, reliability, and transparency. Given their emerging role as decision-support tools and potential \ncollaborative partners in medicine, LLMs must adhere to rigorous validation and quality assurance standards. As the \ntrajectory toward AI-driven healthcare continues, responsible and evidence-based integration of LLMs into critical \ncare practice is imperative to optimize patient outcomes while ensuring ethical and equitable deployment.\nKeywords Large language models, Critical care, Artificial intelligence\nPrimer on large language models: an \neducational overview for intensivists\nDaphna Idan1* and Sharon Einav2\nPage 2 of 13\nIdan and Einav Critical Care          (2025) 29:238 \ndefine specific rules for specific outcomes and have been \nthe foundation of decision-making models for centuries \n[4].\nMore recently, AI has gained an additional layer of \nsophistication - the ability to learn from vast datasets \n(i.e., big data). This progress has given rise to neural net -\nworks, which mimic the interconnected pathways of the \nbrain to model complex relationships. Neural networks \nevaluate multiple possible pathways and select the most \nprobable outcome (probabilistic reasoning). Bayesian \nstatistics comprise a critical component of this process. \nBayesian methods may be applied to all types of data, and \nthey are typically used to calculate outcome likelihoods \nbased on prior probabilities and new evidence. The resul -\ntant outputs of these methods are ranges of confidence \nrelated to the likelihood of the outcome (i.e., confidence \nintervals) rather than a definitive answer (i.e., cutoff lev -\nels). While highly effective, Bayesian approaches to data \nhighlight a fundamental AI challenge - the need to bal -\nance statistical precision with uncertainty. Or, in other \nwords, creative problem-solving.\nHere enters generative AI, whose emergence marked \nanother milestone in AI development. Generative AI \nmodels differ from earlier models in the production of \noutputs for new inputs, based on learned patterns rather \nthan solely following predefined pathways. Generative AI \nmodels introduce an element of creativity, as they gener -\nate predictions (often also called insights) by synthesizing \nprior information that is frequently not overt. For exam -\nple, AI systems trained on extensive imaging datasets can \nidentify new patterns and diagnose novel cases [ 5]. Such \nadvancements fuel ongoing debates regarding the limits \nof AI and the delicate balance between creativity, trans -\nparency, and replicability.\nOf particular relevance to critical care is the AI field \nof machine learning (ML) that leverages vast datasets to \ntrain algorithms that infer logic and adapt to new scenar -\nios. Using electronic health records (EHRs) as the data \nsource, granular and diverse clinical data are aggregated \nto enable predictive modeling using ML. As discussed \nbelow, these datasets can be leveraged to empower AI \nsystems to anticipate clinical decisions, optimize patient \ncare pathways, and improve medical decision-making. \nThis educational primer aims to teach intensivists the \nfoundational concepts of large language models and how \nto approach emerging literature in this area.\nThe building blocks of large language models\nLarge language models (LLMs) are a type of machine \nlearning specifically designed to understand the relation -\nships between words and phrases [ 6]. LLMs learn the \ngrammar, semantics, and contextual use of human lan -\nguage by processing vast amounts of data from diverse \nsources. A key component of this learning involves \ncreating embeddings, mathematical representations of \nwords. These allow the model to group words with simi -\nlar meaning close together in a kind of language map [ 7]. \nFor example, the words “heart rate” , “blood pressure” , \n“temperature” , and ”respiratory rate” would be grouped \nin the map as “vital signs” . These relationships help \nthe model understand how words are used in different \ncontexts.\nThese models originate from natural language process -\ning (NLP), a field that employs computational techniques \nto represent text using algorithmic structures based on \nword co-occurrence frequencies within a given dataset \n[8]. Unlike traditional NLP models, which rely strictly \non the data provided within a specific dataset, LLMs \ncan incorporate contextual information and generate \nresponses based on learned patterns. Table  1 presents \nkey terms related to augmented intelligence and large \nlanguage models.\nA key distinction for understanding how LLM algo -\nrithms function is the model distinction between words \nand tokens. Words are linguistic units that convey mean -\ning, while tokens are discrete symbols that comprise or \nrepresent these units (e.g., sub-words or even punctua -\ntion marks). For instance, a simple word like “note” may \nbe represented by a single token, while a longer or com -\npound word such as “hospitalization” might be broken \ninto two tokens (e.g., “hospital”, “ization”). Each token \nis assigned a probability of appearing next in a sequence \nbased on the tokens that preceded it. The model employs \na mechanism called self-attention to evaluate all parts of \nthe input simultaneously, allowing it to determine con -\ntextual relationships and generate coherent output. In \nother words, this mechanism is designed to evaluate the \nrelevance of different parts of the input when generating \na response. For example, when a physician prompts an \nLLM to generate an admission or discharge summary, the \nmodel may refer to the patient using both “the patient” \nand the pronoun “his/her. ” In the sentence, “The patient \nwas given his medications, ” the model is able to associ -\nate “his” with “the patient” because it considers the entire \nsentence holistically, not just word by word. This process \nultimately results in an output reflecting the most likely \nand contextually appropriate sequence of tokens [ 9] - a \n“predictive language assembly” that enables the model \nto form medically coherent and grammatically accurate \nresponses (Fig. 1).\nTranslating words into tokens is called encoding, and \ntranslating these tokens back into text is called decoding. \nEmbeddings are a critical component of LLM formula -\ntion of the context, nuance, and subtle meanings of words \nand phrases that undergo decoding and encoding. These \nembeddings represent each token’s place in the map of \nlanguage space. LLM inputs are first transformed into \ntokens and embeddings, and after being processed as a \nPage 3 of 13\nIdan and Einav Critical Care          (2025) 29:238 \nseries of layers in the model architecture, the output is \ncreated using the reverse process. This multi-layer archi -\ntecture, known as a transformer encoder-decoder, allows \nthe representations of tokens to be progressively refined. \nEach successive layer helps the model learn increasingly \ncomplex patterns, from basic grammar to more abstract \nsemantic relationships. Statistical strategies are applied in \nthe decoding process when the model selects one token \nover another based on learned probabilities - the likeli -\nhood of each token appearing in a given context based \non training data. As a result of this selection process, the \nmodel generates text. Figure  2 presents a simplified large \nlanguage model processing algorithm.\nLarge language models in critical care\nLLMs are still in their infancy concerning use in criti -\ncal care, with very few clinically validated applications \nand a glaring lack of scientific consensus on their actual \nuse. Today’s truths may be rapidly swept away by expo -\nnentially improving technology. Yet, considering how \nthese tools might be integrated into critical care could \nhelp frame the essential discussion on their future role in \nclinical decision-making. LLMs will likely be used across \nthe critical care continuum to assist in triage and docu -\nmentation, diagnosis and prediction of patient deteriora -\ntion, and patient management. LLMs have demonstrated \na high median score for appropriateness in addressing \nclinical questions related to critical care [ 10] and have \nalso been proposed to support patient rehabilitation after \ndischarge from the ICU [11, 12].\nAs of this writing, at least six additional papers are \nunder review in prepublication databases that propose \nusing LLMs in critical care for treatment planning, \npatient care management, and prediction of deterioration \nand mortality.\nTriage\nEarly identification of patients at risk of rapid clini -\ncal deterioration can improve triage and enable early \nresponse, including ICU admission and implementation \nof care interventions, which machine learning models \naim to predict. Efforts are being made to improve the \nTable 1 Key terms related to artificial intelligence and large language models\nApplication Pro-\ngramming Interface \n(API)\nA framework that facilitates communication and data exchange between software applications, enabling integration of \nfeatures and functionalities.\nArtificial Intelligence \n(AI)\nComputer systems that are designed to perform tasks that usually require human intelligence. These may be classified into \nnarrow AIs focused on specific tasks like language translation or playing chess and general AIs capable of broader functions \nlike learning, reasoning, and problem-solving.\nArtificial Neural \nNetwork\nInterconnected layers of computational units (neurons) that process information.\nBayesian Statistic A statistical framework that applies Bayes’ theorem to update probabilities based on new evidence. It is particularly suited for \ndecision-making in circumstances of uncertainty, providing a probabilistic approach to data analysis and model inference.\nBig Data Large datasets, distinguished by their size, diversity, and processing speed, that may facilitate advanced data analysis and \npattern recognition essential for machine learning and AI applications.\nDeep learning A subset of machine learning that uses artificial neural networks with multiple layers to model complex patterns. The term \n“deep” refers to the number of layers in the network, with deeper networks enabling the execution of more intricate tasks.\nEmbedding A mathematical representation of data (such as words, sentences, or images) in a dense, low-dimensional space. Embeddings \ncapture semantic relationships between items, allowing AI systems to analyze similarity and contextual meaning efficiently.\nEncoding and \nDecoding\nProcesses in machine learning and AI that transform input data into structured formats (encoding) and convert structured \nrepresentations back into human-readable formats (decoding).\nGenerative Artificial \nIntelligence\nA technology that produces content by identifying patterns within large datasets. Depending on the model, outputs may \ninclude text, images, music, and more.\nIntelligence \nAugmentation\nThe ability of computer systems to enhance human capabilities and improve performance rather than merely automating \ntasks.\nLarge Language \nModel\nA type of neural network-based AI capable of performing diverse linguistic tasks by analyzing large volumes of text data. \nLLMs identify relationships between token sequences and compute probabilities, enabling the performance of a variety of \ntasks such as language translation, summarization, and content generation.\nMachine Learning \n(ML)\nA practical subfield of computer science and AI based on statistical models. ML utilizes algorithms that allow systems to learn \npatterns from data without explicit programming. Through iterative learning from experience, these systems may improve \nperformance over time.\nNatural Language \nProcessing\nA field that employs computational techniques to represent text using algorithmic structures based on word co-occurrence \nfrequencies within a given dataset.\nRetrieval Augment-\ned Generation (RAG)\nA framework that enhances LLMs by incorporating relevant and updated data from appropriate sources to produce more \ninformed responses.\nTokens Discrete units of text (such as words, subwords, or characters) that are used by language models to process and analyze lan-\nguage. Tokens are the building blocks for the computational understanding of text, allowing models to generate or interpret \nlanguage.\nPage 4 of 13\nIdan and Einav Critical Care          (2025) 29:238 \naccuracy of ICU admission predictions, including inte -\ngrating NLP technology to enhance the quality of the \ndata used for model development [13].\nRetrieval-augmented generation (RAG) is a frame -\nwork that augments a Large Language Model (LLM) \nwith updated data to generate more informed responses. \nThe retrieval model accesses, selects, and prioritizes the \nmost relevant documents and data from appropriate \nsources, transforms these into an enriched contextual \nprompt, and invokes the LLM through an application \nprogramming interface (API, see Table 1) to generate the \nresponse. This type of machine learning is comparable to \nstock traders’ use of publicly available historical financial \ninformation and live market data feeds to make decisions. \nNumerous approaches to integrating LLMs for patient \ntriage into clinical practice are being explored, including \na RAG approach. Yazaki et al. used Chat-GPT3.5 with \nRAG to enhance contextual understanding and achieved \na 70% accuracy rate in triaging emergency cases from the \nJapanese National Examination for Emergency Medical \nTechnicians [14]. A retrospective study used real-world \ndata from seven hospitals to evaluate ChatGPT-4’s accu -\nracy in predicting hospital admissions after Department \nof Emergency Medicine visits. When RAG was incorpo -\nrated, the prediction accuracy was 81.3% [15].\nDocumentation\nDocumentation is essential to any clinical care process, \nstarting from patient intake. LLMs have been proposed \nfor creating clinical notes based on the assumption that \nsuch use may reduce physician burnout [ 16]. In the \ndemanding field of critical care, where clinicians face sig -\nnificant workload pressures, yet daily notetaking must \ncover most physiological systems, such use may be par -\nticularly beneficial.\nMadden et al. highlighted the transformative potential \nof ChatGPT in processing and synthesizing real-time \nsummaries from the daily free-text entries from ICU \nFig. 1 Token-based processing of a large language model in a Clinical Context\n \nPage 5 of 13\nIdan and Einav Critical Care          (2025) 29:238 \nelectronic health records [ 17]. These entries, authored \nby doctors, nurses, and allied health professionals, often \ncontain critical information but are typically infor -\nmal, abbreviated, and poorly structured. In their study, \nChatGPT-4 generated concise, actionable summaries \nand responded to queries (e.g., provided timelines of \nadministered medications). A pilot feasibility study also \ndemonstrated the ability of LLMs to generate concise \nsummaries of ICU admissions for discharge documenta -\ntion [18]. Another single-blind trial found that the quality \nof discharge letters generated by Chat-GPT4 was compa -\nrable to those written by junior clinicians [19].\nZ codes (Z55-Z65) are the International Classifica -\ntion of Diseases, Tenth Revision Clinical (ICD-10)\nModification diagnosis codes used to document social \ndeterminants of health data (e.g., housing, food insecu -\nrity, transportation, etc.). Guevara et al. investigated the \npotential use of LLMs for extracting six social determi -\nnants of health categories from narrative text in elec -\ntronic health records, including employment, housing, \ntransportation, and parental status. The best-perform -\ning models accurately identified 95.7% of patients with \nat least one mention of an SDoH category, compared to \njust 2.0% identified through structured Z-codes in the \nelectronic health record during the same timeframe [ 20]. \nEarly identification of poor social determinants of health \ncould be invaluable for the prevention of ICU admissions \nas well as for planning for post-ICU rehabilitation, partic-\nularly in patients with complex medical conditions that \nare subsequently more likely to require such admission. \nAnother study found that LLMs outperformed human \ncoders in extracting ICD-10 codes from patient notes \n[21].\nInformed consent is another critical domain of docu -\nmentation. A cross-sectional study of surgical procedures \nrevealed that LLM-based, chatbot-generated presenta -\ntions of risk, benefit, and possible alternatives to sur -\ngery outperformed those presented by surgeons in both \ncomposite completeness and accuracy scores, based on \nexpert evaluation and readability assessments, compared \nto presentations by surgeons. Based on these results, the \nauthors suggested that LLMs be integrated into elec -\ntronic health records to provide personalized risk and \nbenefit assessments before performing invasive proce -\ndures [22].\nMedication prescription and clinical documentation \nshare similarities, requiring precise and detailed writing. \nGiven the burden of work imposed on physicians, errors \ncan occur in both processes. The “Healthy Technology \nAct of 2025, ” a bill introduced in the 119 th Congress of \nthe US House of Representatives (H.R.238), proposes \npermitting the use of AI for medication prescribing \n(albeit with precautions) [ 23]. This development intro -\nduces a new dimension to the potential role of AI, includ-\ning LLMs, in this domain.\nFinally, LLMs are used to summarize doctor-patient \nconversations during palliative care teleconsultations \nperformed almost similarly in medical conversation sum-\nmarization. Chat-GPT4 balanced content understand -\ning and preserved structural similarity to the source \nFig. 2 A simplified large language model processing algorithm\n \nPage 6 of 13\nIdan and Einav Critical Care          (2025) 29:238 \nsomewhat better than other models, suggesting clinicians \ncould use this LLM to generate medical summaries of \nsuch meetings. These summaries could then be given to \nthe patient and/or their family, who may need to reflect \non the content of the meeting [24].\nDiagnostic support\nDiagnostics is another field where LLMs can play a role \nin critical care. A randomized, double-blind crossover \nstudy compared the performance of the LLM tool AMIE \n(Articulate Medical Intelligence Explorer) to that of \ntwenty primary care physicians during text-based con -\nsultations modeled after an Objective Structured Clini -\ncal Examination (OSCE). The study included 149 clinical \nvignettes evaluated by specialist physicians and patient \nactors. AMIE showed greater diagnostic accuracy and \nsuperior performance on 28 of the 32 axes assessed by \nthe specialist physicians and 24 of the 26 axes evaluated \nby the patient actors [25].\nAnother retrospective cohort study conducted in a \n40-bed PICU demonstrated the capability of domain-\nspecific LLMs, such as those trained on specific medi -\ncal data, to generate differential diagnoses. While their \nperformance was inferior to that of human clinicians in \nterms of quality, pediatric critical care specialists gave \nthem high evaluation scores [26].\nIn the complex diagnostic landscape of the ICU, the \nperspectives of family members and caregivers are \noften fraught with misinterpretations and unanswered \nquestions. Scquizzato et al. evaluated the accuracy of \nChatGPT in responding to non-professional questions \nabout cardiac arrest. ChatGPT provided highly accurate \nanswers, as assessed by clinicians and researchers spe -\ncializing in out-of-hospital cardiac arrest, as well as by \nlaypersons. Given the emotionally charged nature of sce -\nnarios such as cardiac arrest, which are integral to daily \ncritical care practice, this suggests that leveraging the \ncapabilities of LLMs to help address and clarify clinical \nsituations for families has significant potential [27].\nImaging\nThe last decades have seen a surge in the use of diagnos -\ntic imaging with a related increase in the need for an effi -\ncient image interpretation and reporting process. This \nrising workload has led to concerns regarding decreased \nefficacy and a higher likelihood of mistakes due to system \noverload and radiology staff burnout. Radiologists are \nexpected to handle substantial textual information - from \ndiagnostic request forms, medical charts and summa -\nries, information from prior or other examinations, and \nthe most updated medical literature. LLMs may be used \nto ameliorate this burden if used wisely. While this use \nmay improve the efficiency of radiology services overall, \nthose most likely to benefit are critically ill patients who \noften require frequent testing and rapid results. Medi -\ncal imaging of critically ill patients poses unique chal -\nlenges, including the need to meet stringent time frames \nand minimize complications stemming from redundant \npatient transfers. LLMs may be used to improve radiol -\nogy service efficacy and effectiveness in ways that may be \nparticularly relevant for critically ill patients.\nA study comparing human radiologists to Chat-GPT-4 \nV and Gemini Pro Vision concluded that human radiolo -\ngists still outperform these LLMs in diagnostic accuracy \nacross various subspecialties (neuroradiology, gastro -\nintestinal, genitourinary) but concluded that LLMs may \npotentially be used to support clinical decision-making \n[28]. Another model, CXR-LLaVa, which integrates an \nLLM with an image encoder, demonstrated 81% diag -\nnostic accuracy in identifying six common clinical con -\nditions from test sets of X-ray images using the Medical \nInformation Mart for Intensive Care (MIMIC) database \n[29].\nThese findings have been supported by an additional \nstudy that showed that ClotCatcher, a natural language \nmodel with data augmentation, can rapidly and accu -\nrately identify venous thromboembolism (VTE) from \nradiology reports. The authors concluded that the model \nmay improve the efficiency and accuracy of incident VTE \nadjudication in large databases [30].\nMonitoring and early prediction of patient deterioration\nCritically ill patients may rapidly deteriorate, a situa -\ntion that requires early diagnosis and effective treatment \ndecisions in complex clinical situations. Additional diffi -\ncult decisions that typically need to be addressed in the \ncritical care environment are those relating to patient \npreferences that must be made in conjunction with the \nfamilies, often on behalf of patients unable to make deci -\nsions themselves. Time constraints, cultural reluctance \nto address end-of-life issues, and clinician burdens may \nlimit the ability to elucidate individual patients’ value \njudgments and preferences. A proof-of-concept study \nexplored the potential of LLMs to integrate patient val -\nues into critical care decision-making for incapacitated \npatients. Automated extractions of the treatment in ques-\ntion were accurate in 88% of scenarios. LLM treatment \nrecommendations were rated by adjudicators with an \naverage Likert score of 3.92 out of 5.00 for being medi -\ncally plausible and reasonable and 3.58 out of 5.00 for \nreflecting documented patient values [31].\nThe possible use of LLMs to predict patient deteriora -\ntion has also been explored in the context of respiratory \nfailure and support. A machine learning model integrated \nwith natural language processing, ARDSFlag, demon -\nstrated an overall accuracy of 89.0% in identifying ARDS \ncases [ 32]. Another small, prospective study found that \nChat-GPT4 demonstrated an accuracy comparable to \nPage 7 of 13\nIdan and Einav Critical Care          (2025) 29:238 \nthat of specialized physicians in predicting the need for \nendotracheal intubation in patients receiving high-flow \nnasal cannula therapy for 48 h [ 33]. A third study used \nnatural language processing to identify under-documen -\ntation of ARDS in ICU discharge notes [34]. Such use has \nmore than just research implications - it can also serve as \nan educational tool.\nSepsis remains a leading cause of ICU mortality [ 35], \nyet remains a significant diagnostic challenge in the ICU. \nThe SERA algorithm is an AI-enabled tool that uses natu-\nral language processing of physicians’ clinical notes using \nstructured electronic medical records (EMR) data. SERA \nhad a high predictive accuracy for identifying sepsis 12 h \nbefore its onset, with an AUC of 94%. Compared to phy -\nsician predictions, the SERA algorithm increased early \ndetection of sepsis by as much as 32% while reducing \nfalse positives by 17% [36].\nAcute kidney injury (AKI) affects 30–57% of critically \nill patients and is associated with high morbidity and \nmortality [37]. Among patients discharged from the ICU \nwith normal renal function after AKI, almost one in three \nwill relapse into renal failure within 5 years [ 38]. One \nstudy evaluated the effectiveness of Chat-GPT4 in teach -\ning patients about AKI and continuous renal replacement \ntherapy (CRRT). The model demonstrated a 97–98% \noverall accuracy, consistent performance across question \ntypes, and no significant differences between AKI and \nCRRT responses [39].\nManagement of treatment\nCritical care involves providing a broad spectrum of \ntreatment regimens tailored to diverse clinical scenarios. \nIntegrating LLMs into this process may optimize time \nand efficiency in care delivery. Howard et al. explored \nwhether ChatGPT (version unspecified) may be used to \nprovide antimicrobial treatment recommendations in \neight hypothetical infection scenarios. While limitations \nwere noted in addressing complex cases, ChatGPT dem -\nonstrated an overall ability to suggest appropriate anti -\nmicrobial spectra and regimens for the diagnoses and \nrecognized the implications of clinical responses [40].\nDelirium occurs in approximately 30% of ICU patients, \nwith rates rising to 90% among mechanically ventilated \npatients [41]. Delirium is also associated with increased \nmortality after ICU admission. One of the studies still \nin preprint, suggests that DeLLirium - an LLM-based \nprediction model - achieved better results than other \ndeep-learning models in predicting delirium from elec -\ntronic health records [ 42]. Although this tool is primar -\nily intended for critical care research rather than clinical \npractice, its potential for detecting delirium through con-\nversations with patients or relatives may enable early \nidentification of at-risk individuals. Alternative models \nmay be developed for predicting post-ICU depression \namong patients and caregivers.\nLLMs may also become an essential educational \nresource for families and caregivers after discharge \nfrom the ICU. For example, non-professional caregiv -\ners rarely have the training or preparation required for \nthis challenging role. The quality of post-ICU care and \nthe degree of caregiver strain may both be affected by \npoor preparation. The CaLM (caregiver large language \nmodel) has been proposed as a tool for teaching caregiv -\ners. The developers of this model aimed to provide care -\ngivers with at least some of the knowledge they require \nto undertake this challenging role. They showed that by \nincorporating retrieval-augmented generation (a method \nused for improving model performance through connec -\ntion with external knowledge bases), a valuable support \ntool tailored to specific caregiver scenarios could be cre -\nated [43].\nPatients recovering from ICU admission often require \na lengthy and multidisciplinary rehabilitation process. \nA study that evaluated individualized exercise recom -\nmendations generated by an AI chatbot found them to \nbe 41.2% comprehensive and 90.7% accurate. The chat -\nbot could not provide complete and precise recommen -\ndations. Still, chatbots are early precursors of the LLMs \nexisting at the time of this writing, and this study repre -\nsents the potential for supporting rehabilitation efforts \nthrough such tools [44].\nFigure 3 shows a timeline of patient management in the \nICU with the potential application of LLMs at each treat -\nment point.\nWhile the examples presented illustrate potential \ndirections for integrating LLMs into critical care daily \npractice, these remain exploratory. Figure  4 offers one \npossible roadmap from model development to clinical \nintegration.\nThe challenges and limitations of large Language \nmodels\nSince the introduction of ChatGPT by OpenAI in \nNovember 2022, the public adoption of virtual assistants \npowered by large language models (LLMs) has grown \nrapidly. The interest in their application in healthcare, \nincluding critical care settings, highlights their potential, \nas shown above. This article summarizes a rapidly evolv -\ning technology whose clinical impact remains hypotheti -\ncal. LLMs are still at the stage of isolated experiments in \nexploratory studies (for assessment of the studies pre -\nsented above, refer to Table 2) with limited incorporation \nof real-world patient care data; a recent systematic review \nby Bedi et al. found that only 5% of studies use such data \n[45]. There is no robust clinical validation, and the wide -\nspread use of these tools has also brought attention to \ntheir limitations and associated challenges [46, 47].\nPage 8 of 13\nIdan and Einav Critical Care          (2025) 29:238 \nA critical consideration in incorporating LLMs into \nclinical practice is their susceptibility to various biases, \namong them sycophancy bias, which may lead to out -\nputs reinforcing clinicians’ preexisting beliefs, potentially \nincreasing errors [ 48]. Our knowledge of such biases \nhighlights the need to recognize and address how they \nmay influence outputs and the importance of ongoing \nvigilance when integrating LLM-generated recommenda-\ntions into clinical decision-making.\nAnother broader concern regarding the use of AI in \ngeneral (not limited to LLMs alone) is the phenomenon \nof overreliance. Clinicians may trust AI-generated diag -\nnoses even when the model produces inaccurate results \n(Supplementary A) [ 49]. One study investigated whether \nproviding explanations alongside model-generated diag -\nnoses could help clinicians discern and disregard incor -\nrect outputs. Paradoxically, adding explanations did not \nimprove decision-making accuracy, and reliance on the \nAI model persisted [50].\nFinally, the hurdle of integrating LLMs into clini -\ncal workflows remains. These models often function \nas “black boxes, ” with limited transparency regarding \ntheir internal decision-making processes - a challenge \nthat extends even to their developers and is particularly \npronounced among clinicians without even the basic \nappropriate training. This lack of clarity, coupled with \ninsufficient familiarity among physicians regarding the \nknown capabilities and limitations of these tools, impairs \ntheir ability to engage with LLMs in a safe, informed, \nand clinically meaningful manner. Physicians in family \nmedicine, internal medicine, and emergency medicine \nexhibited better diagnostic performance on their own \ncompared to when assisted by an LLM. This was assessed \nbased on the accuracy of differential diagnoses, the rel -\nevance of supporting and opposing clinical factors, and \nthe appropriateness of the diagnostic evaluation process. \nThe authors interpreted this finding as highlighting “the \nneed for technology and workforce development to real -\nize the potential of physician-artificial intelligence col -\nlaboration in clinical practice“ [51].\nAI tools are rapidly transitioning from simple tools to \nassistants and potentially even collaborative partners in \nmedicine. They should, therefore, be upheld to similarly \nrigorous quality assurance standards. The Transparent \nReporting of a Multivariable Model for Individual Prog -\nnosis Or Diagnosis for LLMs (TRIPOD-LLM) framework \nhas recently been proposed for reporting clinical predic -\ntion models developed using large language models [ 52]. \nSeveral critical care leaders have also called for action on \nAI technologies, emphasizing the need to address tech -\nnical, ethical, social, and practical issues posed by these \ntools. Their call highlighted the importance of ensuring \nthat AIs, who may someday be viewed as equal partners \nto physicians, meet the same ethical and professional \nstandards expected of humans. LLMs must uphold integ-\nrity, foster trust in clinical environments, and support \nFig. 3 A timeline of patient management in the ICU with the potential application of LLMs at each treatment point\n \nPage 9 of 13\nIdan and Einav Critical Care          (2025) 29:238 \nFig. 4 Proposed LLM implementation pathway\n \nPage 10 of 13\nIdan and Einav Critical Care          (2025) 29:238 \nAuthors Study Design Healthcare Context and \nIntended Use\nSource of Data Objective Evaluation - \nMetrics and Assessors\nSubjective Evalua-\ntion - Metrics and \nAssessors\nPerformance \nComparators \n(other LLMs, humans, other \nbenchmarks, or standards)\nValidation Approach \n(internal, exter-\nnal, or no formal \nvalidation)\nAkhondi-Asl \net al., 2024 \n[26]\nSingle-center \nretrospective \ncohort study\nGenerating differential diag-\nnoses from the admission \nnotes of PICU patients\nAdmission notes from 10 \nyears period for model devel-\nopment, 130 notes randomly \nselected for evaluation\nNone A 5-point Likert scale \nof overall quality\nClinicians vs. general LLMs \n(BioGPT-Large, LLaMa-65B), \nfine-tuned LLMs (fine-tuned \nBioGPT-Large, fine-tuned \nLLaMa-7B)\nInternal\nChen et al., \n2024 [24]\nPilot study Summarization of palliative \ncare teleconsultation\nSummary of a simulated \ndoctor–patient conversation \nduring teleconsultation\nStandardized metrics for \nprecision and similar-\nity to reference text \n(e.g., ROUGE, BLEU, \nBERTScore)\nNone GPT-3.5, GPT-4, LLaMA-\n2-7B, LLaMA-2-13B, and \nLLaMA-2-70B\nNo formal validation\nContreras et \nal., 2024 [42] \n(preprint)\nMulti-center \nstudy\nIntroducing LLM-based \nDelirium prediction model \nin the ICU\neICU Collaborative Research \nDatabase, MIMIC-IV and the \nUniversity of Florida Health’s \nIntegrated Data Repository\nStandard statistical \nmetrics of AUC\nNone None Internal and external\nGlicksberg et \nal., 2024 [15]\nRetrospective \nstudy\nPredicting the admission of \npatients arriving at the ED\nElectronic health records \nfrom seven hospitals\nStandard statistical \nmetrics of AUC, AUPRC, \nand accuracy\nNone ML models vs. GPT-4 Internal and external\nGuevara et \nal., 2024 [20]\nComparative \nstudy\nIdentify SDoH in EHRs Electronic health records Automated evaluation \nusing macro-F1 score\nNone General LLMs (GPT-3.5 and \nGPT-4) vs. fine tuned LLM \n(BERT-base and Flan-T5)\nInternal and external\nBalta et al., \n2024 [10]\nCross-sectional \ncomparative \nstudy\nEvaluation of critical care \nrecommendations\n50 Clinical critical care ques-\ntions synthesized by the \nauthors\nFlesch-Kincaid Grade \nLevel (objective read-\nability assessment)\nA 5-point Likert scale \nfor appropriateness \nand consistency\nGPT-3.5 vs. GPT-4 No formal validation\nLiu et al., \n2024 [33]\nProspective \nmulticenter \ncohort study\nPredicting efficacy of high-\nflow oxygen therapy\nElectronic health records of \n71 patients\nStandard statistical met-\nrics of AUC, sensitivity, \nspecificity, and precision\nNone LLMs (GPT-3.5, GPT-4.0) vs. \nrespiratory and critical care \nspecialist physicians and non-\nspecialist physicians\nInternal\nMadden et \nal., 2023 [17]\nLetter to the \neditor\nQuery and summarize medi-\ncal notes in ICU\nNone None Clinician feedback on \nthe usefulness and \nclarity of generated \nsummaries\nNone No formal validation\nNolan et al., \n2024 [31]\nProof-of-cocn-\ncept study\nIntegrate patient values \ninto clinical decision-\nmaking processes in critical \ncare for patients who are \nincapacitated\n50 Text-based scenarios of \ndecisionally incapacitated \npatients\nNone A 5-point Likert scales \nfor medical plausibility \nand alignment with \npatient values\nNone No formal validation\nParmanto et \nal., 2024 [43]\nExploratory \nstudy\nDevelop a new model for \ncaregivers’ questions\nCargiving knowledge bases, \nincluding journal articles, care \nguidelines, and forums\nStandardized metrics for \nprecision and similarity \nto reference text (e.g., \nROUGE, BLEU)\nNone New LLM (CaLM) and GPT-3.5 Internal\nTable 2 Qualitative assessment of LLM studies based on the transparent reporting of a multivariable model for individual prognosis or diagnosis (TRIPOD)-LLM recommendations \n[52]\nPage 11 of 13\nIdan and Einav Critical Care          (2025) 29:238 \nAuthors Study Design Healthcare Context and \nIntended Use\nSource of Data Objective Evaluation - \nMetrics and Assessors\nSubjective Evalua-\ntion - Metrics and \nAssessors\nPerformance \nComparators \n(other LLMs, humans, other \nbenchmarks, or standards)\nValidation Approach \n(internal, exter-\nnal, or no formal \nvalidation)\nSheikh et al., \n2024 [39]\nNot specified \nby the authors\nAssessing accuracy in \nresponding to patient edu-\ncation questions\n89 questions from the Mayo \nClinic Handbook for educat-\ning patients on AKI and CRRT\nNone Subjective accuracy \nrating\nNone Internal\nTommaso et \nal., 2024 [27]\nNot specified \nby the authors\nAddress public inquiries \nrelated to cardiac arrest and \nCPR\n40 questions Readability assessed \nusing the Flesch Reading \nEase score\nA 5-point Likert scales \nfor accuracy, clarity, \nrelevance, comprehen-\nsiveness, and overall \nvalue\nNone Internal\nUrquhart et \nal., 2024 [18]\nPilot study Synthesize discharge sum-\nmary of ICU patients\nText from five ICU episodes None Subjective evaluation \nby staff intensivists\nChatGPT, GPT-4 API, and \nLlama 2\nInternal\nYazaki et al., \n2024 [14]\nNot specified \nby the authors\nTriaging ED patients 100 simulated triage \nscenarios\nStandard statistical met-\nrics of triage accuracy\nNone GPT-3.5 with RAG, GPT-3.5 \nwithout RAG, and GPT-4 with-\nout RAG vs. emergency medi-\ncal technicians and emergency \nphysicians\nInternal\nZaleski et al., \n2024 [44]\nMix methods \nstudy\nProviding individualized \nexercise recommendations\n26 queries on exercise advice Flesch-Kincaid Grade \nLevel (objective read-\nability assessment)\nSubjective assessment \nof comprehensiveness \nand factual accuracy\nNone Internal\nAKI: Acute kidney injury; AUC: Area under the receiver operating characteristic curve; AUPRC: Area under the precision-recall curve; BERT: bert large uncased whole word masking finetuned squad; BERTScore: Bidirectional \nencoder representations from transformers score; BLEU: Bilingual evaluation understudy; CPR: Cardiopulmonary resuscitation; CRRT: Continous renal replacement therapy; ED: Emergency department; EHRs: Electronic \nhealth records; GPT: Generative Pre-trained Transformer; ICD: International classification of diseases; ICU: Intensive care unit; MIMIC-IV: Medical Information Mart for Intensive Care; ML: machine learning; PICU: Pediatrics \nintensive care unit; RAG: Retrieval augmented generation; ROUGE-L: Recall-oriented understudy for gisting evaluation; SDoH: Social determinants of health; VS: versus\nTable 2 (continued)\n \nPage 12 of 13\nIdan and Einav Critical Care          (2025) 29:238 \ntheir physician colleagues while maintaining the highest \nstandards of care [53].\nConclusion\nThe integration of LLMs into critical care is an evolving \nprocess that may become transformative in the future. As \nthese models may increasingly permeate various aspects \nof patient management, it is imperative to avoid over-\noptimism by emphasising that current results are still \nfar from actual application. That said, if developed and \nimplemented correctly, these models could potentially \nimprove clinical decision-making, alleviate the cognitive \nand administrative burdens on healthcare professionals, \nand improve patient and caregiver comprehension of the \ncomplexities associated with critical illness during and \nafter hospitalization. The trajectory towards leveraging \nLLMs for improving patient care and possibly outcomes \nis increasingly evident, highlighting the need for respon -\nsible and evidence-based integration of these tools into \ncritical care practice.\nSupplementary Information\nThe online version contains supplementary material available at  h t t p  s : /  / d o i  . o  r \ng /  1 0 .  1 1 8 6  / s  1 3 0 5 4 - 0 2 5 - 0 5 4 7 9 - 4.\nSupplementary Material 1\nAcknowledgements\nWe are grateful to Leehee Barak, Medint Data Analyst, for her valuable \nassistance in verifying the accuracy of the figures and terminology. We \nalso extend our sincere thanks to Prof. Leo Anthony Celi for his insightful \ncontributions to the conceptual development and overall flow of the paper.\nAuthor contributions\nD.I. and S.E. were responsible for the conceptualization of the manuscript idea, \ndrafted the main manuscript text, and prepared Figs. 1, 2 and 3. All authors \nreviewed and approved the final manuscript.\nFunding\nNone.\nData availability\nNo datasets were generated or analysed during the current study.\nDeclarations\nCompeting interests\nDaphna Idan is a medical student and data analyst and has no relevant \nconflict of interests to disclose. Sharon Einav is a Cochrane Editor and is \ninvolved in developing an LLM for use by clinicians.\nReceived: 2 March 2025 / Accepted: 30 May 2025\nReferences\n1. Nestor Maslej L, Fattorini R, Perrault V, Parli A, Reuel E, Brynjolfsson J, \nEtchemendy K, Ligett T, Lyons J, Manyika JC, Niebles Y, Shoham R, Wald, Clark \nJ. The AI Index 2024 Annual Report, AI Index Steering Committee, Institute for \nHuman-Centered AI, Stanford University, Stanford, CA, April 2024.\n2. Health C, for D. and R. Artificial Intelligence and Machine Learning (AI/ML)-\nEnabled Medical Devices. FDA [Internet]. 2021; Available from:  h t t p  s : /  / w w w  . f  \nd a .  g o v  / m e d  i c  a l -  d e v  i c e s  / s  o f t  w a r  e - m e  d i  c a l  - d e  v i c e  - s  a m d  / a r  t i fi    c i  a l -  i n t  e l l i  g e  n c \ne  - a n  d - m a  c h  i n e  - l e  a r n i  n g  - a i m l - e n a b l e d - m e d i c a l - d e v i c e s\n3. Silcox C, Zimlichmann E, Huber K, Rowen N, Saunders R, McClellan M et al. \nThe potential for artificial intelligence to transform healthcare: perspectives \nfrom international health leaders. NPJ Digital Medicine [Internet]. 2024;7(1):1–\n3. Available from:  h t t p  s : /  / w w w  . n  a t u  r e .  c o m /  a r  t i c  l e s  / s 4 1  7 4  6 - 0 2 4 - 0 1 0 9 7 - 6\n4. Russell SJ, Norvig P . Artificial intelligence: A modern approach, global edition.\n5. Rockall AG, Shelmerdine SC, Chen M. AI and ML in radiology: Making prog-\nress. Clinical radiology [Internet]. 2023;78(2):81–2. Available from:  h t t p  s : /  / p u b  \nm e  d . n  c b i  . n l m  . n  i h . g o v / 3 6 6 3 9 1 7 4 /\n6. Kasneci E, Sessler K, Küchemann S, Bannert M, Dementieva D, Fischer F et \nal. ChatGPT for good? On opportunities and challenges of large language \nmodels for education. Learning and Individual Differences [Internet]. \n2023;103(102274). Available from:  h t t p  s : /  / w w w  . s  c i e  n c e  d i r e  c t  . c o  m / s  c i e n  c e  / a r  \nt i c  l e / a  b s  / p i  i / S  1 0 4 1  6 0  8 0 2 3 0 0 0 1 9 5\n7. Zamani H. W. Bruce Croft. Embedding-based Query Language Models; 2016.\n8. Chowdhary KR. Natural Language processing. Fundamentals Artif Intell. \n2020;603–49.\n9. Avijit Thawani S, Ghanekar, Zhu X, Pujara J. Learn Your Tokens: Word-Pooled \nTokenization for Language Modeling [Internet]. OpenReview. 2023. Available \nfrom:  h t t p  s : /  / o p e  n r  e v i  e w .  n e t /  f o  r u m ? i d = O 9 z r G 7 N B 3 X\n10. Balta KY, Javidan AP , Walser E, Arntfield R, Prager R. Evaluating the appropri-\nateness, consistency, and readability of ChatGPT in critical care recommenda-\ntions. J Intensive Care Med. 2024;40(2):184–90.\n11. Haw Hwai, Ho YJ, Wang CH, Huang CH. Large Language model application in \nemergency medicine and critical care. J Formos Med Assoc. 2024.  h t t p  s : /  / d o i  . \no  r g /  1 0 .  1 0 1 6  / j  . j f m a . 2 0 2 4 . 0 8 . 0 3 2\n12. Find and participate in clinical trials and research. studies happening around \nthe world | TrialScreen [Internet]. Trialscreen.org. 2025 [cited 2025 Feb 14]. \nAvailable from:  h t t p  s : /  / a p p  . t  r i a  l s c  r e e n  . o  r g /  t r i  a l s /  a s  s e s  s i n  g - i n  t e  n s i  v e -  c a r e  - u  n i \nt  - i c  u - i n  d i  c a t  i o n  s - h u  m a  n - v  s - c  h a t g  p t  - 4 o  - p r  e d i c  t i  o n s - s t u d y - n c t 0 6 7 2 6 7 3 3\n13. Fernandes M, Mendes R, Vieira SM, Leite F, Palos C, Johnson A et al. Predicting \nIntensive Care Unit admission among patients presenting to the emergency \ndepartment using machine learning and natural language processing. PLoS \nONE [Internet]. 2020 Mar 3 [cited 2023 Mar 25];15(3):e0229331. Available \nfrom:  h t t p  s : /  / w w w  . n  c b i  . n l  m . n i  h .  g o v  / p m  c / a r  t i  c l e s / P M C 7 0 5 3 7 4 3 /\n14. Megumi Yazaki, Maki S, Furuya T, Inoue K, Nagai K, Nagashima Y et al. \nEmergency Patient Triage Improvement through a Retrieval-Augmented \nGeneration Enhanced Large-Scale Language Model. Prehospital Emergency \nCare [Internet]. 2024;1–7. Available from:  h t t p  s : /  / p u b  m e  d . n  c b i  . n l m  . n  i h . g o v / 3 \n8 9 5 0 1 3 5 /\n15. Glicksberg BS, Timsina P , Patel D, Sawant A, Vaid A, Raut G et al. Evaluating \nthe accuracy of a state-of-the-art large language model for prediction of \nadmissions from the emergency room. Journal of the American Medical \nInformatics Association: JAMIA [Internet]. 2024;ocae103. Available from:  h t t p  s : \n/  / p u b  m e  d . n  c b i  . n l m  . n  i h . g o v / 3 8 7 7 1 0 9 3 /\n16. Miao J, Charat Thongprayoon WC. Should Artificial Intelligence Be Used for \nPhysician Documentation to Reduce Burnout? Kidney360 [Internet]. 2024 \nMar 25 [cited 2024 Aug 18];5(5):765–7. Available from:  h t t p  s : /  / w w w  . n  c b i  . n l  m . \nn i  h .  g o v  / p m  c / a r  t i  c l e s / P M C 1 1 1 4 6 6 4 5 /\n17. Madden MG, McNicholas BA, Laffey JG. Assessing the usefulness of a large \nLanguage model to query and summarize unstructured medical notes in \nintensive care. Intensive Care Med. 2023;49(8):1018–20.\n18. Urquhart E, Ryan J, Hartigan S, Nita C, Hanley C, Moran P et al. A pilot feasibil-\nity study comparing large Language models in extracting key information \nfrom ICU patient text records from an Irish population. Intensive Care Med \nExperimental. 2024;12:17.\n19. Yi J, Gill SR, Gui G, Yan D, Ke Y, Ting F, Tan et al. Comparison of the Quality of \nDischarge Letters Written by Large Language Models and Junior Clinicians: \nSingle-Blinded Study. Journal of Medical Internet Research [Internet]. 2024 \nJul 24 [cited 2024 Sep 9];26:e57721–1. Available from:  h t t p  s : /  / w w w  . j  m i r  . o r  g / 2 \n0  2 4  / 1 / e 5 7 7 2 1 /\n20. Guevara M, Chen S, Thomas S, Chaunzwa TL, Franco I, Kann BH et al. Large \nlanguage models to identify social determinants of health in electronic \nhealth records. NPJ Digital Medicine [Internet]. 2024;7(1):1–14. Available from:  \nh t t p  s : /  / w w w  . n  a t u  r e .  c o m /  a r  t i c  l e s  / s 4 1  7 4  6 - 0 2 3 - 0 0 9 7 0 - 0\n21. Simmons A, Takkavatakarn K, McDougal M, Dilcher B, Pincavitch J, \nMeadows L et al. Extracting international classification of diseases codes \nfrom clinical Documentation using large Language models. Appl Clin Inf. \n2024;16(2):337–44.\nPage 13 of 13\nIdan and Einav Critical Care          (2025) 29:238 \n22. Decker H, Trang K, Ramirez J, Colley A, Pierce L, Coleman M et al. Large \nLanguage Model – Based Chatbot vs Surgeon-Generated Informed Consent \nDocumentation for Common Procedures. JAMA Network Open [Internet]. \n2023 Oct 9 [cited 2023 Nov 29];6(10):e2336997. Available from:  h t t p  s : /  / j a m  a n  \ne t w  o r k  . c o m  / j  o u r  n a l  s / j a  m a  n e t  w o r  k o p e  n /  a r t  i c l  e - a b  s t  r a c t / 2 8 1 0 3 6 4\n23. R-AZ-1 D. Text - H.R.238–119th Congress (2025–2026): To amend the \nFederal Food, Drug, and Cosmetic Act to clarify that artificial intelligence \nand machine learning technologies can qualify as a practitioner eligible to \nprescribe drugs if authorized by the State involved and approved, cleared, \nor authorized by the Food and Drug Administration, and for other purposes. \n[Internet]. Congress.gov. 2025. Available from:  h t t p  s : /  / w w w  . c  o n g  r e s  s . g o  v /  b i l  l / \n1  1 9 t h  - c  o n g  r e s  s / h o  u s  e - b i l l / 2 3 8 / t e x t\n24. Chen X, Zhou W, Hoda R, Li A, Bain C, Poon P . Exploring the opportunities of \nlarge language models for summarizing palliative care consultations: A pilot \ncomparative study. Digital health [Internet]. 2024;10:20552076241293932. \nAvailable from:  h t t p  s : /  / p u b  m e  d . n  c b i  . n l m  . n  i h . g o v / 3 9 5 6 9 3 9 5 /\n25. Tu T, Anil Palepu, Schaekermann M, Saab K, Freyberg J, Tanno R, Towards \nConversational Diagnostic AI., arXiv et al. (Cornell University). 2024.\n26. Yang AA-A, Luchette Y, Burns M, Mehta JP , Alon Geva. Comparing the quality \nof Domain-Specific versus general Language models for artificial Intelli-\ngence-Generated differential diagnoses in PICU patients**. Pediatr Crit Care \nMed. 2024;25(6):e273–82.\n27. Tommaso Scquizzato, Semeraro F, Swindell P , Simpson R, Angelini M, Gazzato \nA, et al. Testing ChatGPT ability to answer laypeople questions about cardiac \narrest and cardiopulmonary resuscitation. Resuscitation. 2024;194:110077–7.\n28. Suh PS, Shim WH, Suh CH, Heo H, Park CR, Eom HJ et al. Comparing diagnos-\ntic accuracy of radiologists versus GPT-4V and gemini pro vision using image \ninputs from diagnosis please cases. Radiology. 2024;312(1):e240273.\n29. Lee S, Youn J, Kim H, Kim M, Yoon SH. CXR-LLaVA: a multimodal large Lan-\nguage model for interpreting chest X-ray images. Eur Radiol. 2025.  h t t p  s : /  / d o i  \n. o  r g /  1 0 .  1 0 0 7  / s  0 0 3 3 0 - 0 2 4 - 1 1 3 3 9 - 6\n30. Wang J, Joao, Gupta S, Upadhyaya P , Lisboa FA, Schobel SA et al. ClotCatcher: \na novel natural Language model to accurately adjudicate venous thrombo-\nembolism from radiology reports. BMC Med Inf Decis Mak. 2023;23(1):262.\n31. Nolan VJ, Balch JA, Baskaran NP , Shickel B, Efron PA, Upchurch GR et al. \nIncorporating Patient Values in Large Language Model Recommendations \nfor Surrogate and Proxy Decisions. Critical Care Explorations [Internet]. \n2024;6(8):e1131–1. Available from:  h t t p  s : /  / p u b  m e  d . n  c b i  . n l m  . n  i h . g o v / 3 9 1 3 2 9 \n8 0 /\n32. Gandomi A, Wu P , Clement DR, Xing J, Aviv R, Federbush M et al. ARDSFlag: \nan NLP/machine learning algorithm to visualize and detect high-probability \nARDS admissions independent of provider recognition and billing codes. \nBMC medical informatics and decision making [Internet]. 2024 Win-\nter;24(1):195. Available from:  h t t p  s : /  / p u b  m e  d . n  c b i  . n l m  . n  i h . g o v / 3 9 0 1 4 4 1 7 /\n33. Liu T, Duan Y, Li Y, Hu Y, Su L, Zhang A. ChatGPT achieves comparable accu-\nracy to specialist physicians in predicting the efficacy of high-flow oxygen \ntherapy. Heliyon [Internet]. 2024;10(11):e31750. Available from:  h t t p  s : /  / w w w  . s  \nc i e  n c e  d i r e  c t  . c o  m / s  c i e n  c e  / a r  t i c  l e / p  i i  / S 2 4 0 5 8 4 4 0 2 4 0 7 7 8 1 8\n34. Weissman GE, Harhay MO, Lugo RM, Fuchs BD, Halpern SD, Mikkelsen ME. \nNatural Language processing to assess Documentation of features of critical \nillness in discharge documents of acute respiratory distress syndrome survi-\nvors. Annals Am Thorac Soc. 2016;13(9):1538–45.\n35. Society of Critical Care Medicine. Critical care statistics [Internet]. Society of \nCritical Care Medicine (SCCM). 2024. Available from:  h t t p  s : /  / w w w  . s  c c m  . o r  g / C \no  m m  u n i  c a t  i o n s  / C  r i t  i c a  l - C a  r e  - S t a t i s t i c s\n36. De Corte T, Van Hoecke S, De Waele J. Artificial intelligence in infection man-\nagement in the ICU. Crit Care. 2022;26(1):79.\n37. Melo F, AF de, Macedo E, Fonseca Bezerra AC, de Melo WAL, Mehta RL, de \nA Burdmann E et al. G Remuzzi editor 2020 A systematic review and meta-\nanalysis of acute kidney injury in the intensive care units of developed and \ndeveloping countries. PLoS ONE 15 1 e0226325.\n38. Orieux A, Prezelin-Reydit M, Prevel R, Combe C, Gruson D, Boyer A et al. Clini-\ncal trajectories and impact of acute kidney disease after acute kidney injury \nin the intensive care unit: a 5-year single-centre cohort study. Nephrology, \ndialysis, transplantation: official publication of the European Dialysis and \nTransplant Association - European Renal Association [Internet]. 2023 \nAutumn;38(1):167–76. Available from:  h t t p  s : /  / p u b  m e  d . n  c b i  . n l m  . n  i h . g o v / 3 5 2 3 \n8 9 2 2 /\n39. Sheikh MS, Thongprayoon C, Suppadungsuk S, Miao J, Qureshi F, Kashani K et \nal. Evaluating ChatGPT’s Accuracy in Responding to Patient Education Ques-\ntions on Acute Kidney Injury and Continuous Renal Replacement Therapy. \nBlood Purification [Internet]. 2024 Apr 26 [cited 2024 Jul 20];1–7. Available \nfrom:  h t t p  s : /  / p u b  m e  d . n  c b i  . n l m  . n  i h . g o v / 3 8 6 7 9 0 0 0 /\n40. Howard A, Hope W, Gerada A. ChatGPT and antimicrobial advice: the end of \nthe consulting infection doctor? Lancet Infect Dis. 2023;23(4):405–6\n41. Miranda F, Gonzalez F, Plana MN, Zamora J, Quinn TJ, Seron P . Confusion \nAssessment Method for the Intensive Care Unit (CAM-ICU) for the diagnosis \nof delirium in adults in critical care settings. The Cochrane Database of \nSystematic Reviews [Internet]. 2023;11(11):CD013126. Available from:  h t t p  s : /  / \np u b  m e  d . n  c b i  . n l m  . n  i h . g o v / 3 7 9 8 7 5 2 6 /\n42. Contreras M, Kapoor S, Zhang J, Davidson A, Ren Y, Guan Z et al. DeLLiriuM: A \nlarge language model for delirium prediction in the ICU using structured EHR \n[Internet]. arXiv.org. 2024 [cited 2025 Feb 14]. Available from:  h t t p  s : /  / a r x  i v  . o r  g \n/ a  b s / 2  4 1  0 . 1 7 3 6 3\n43. Parmanto B, Aryoyudanta B, Soekinto TW, Setiawan IMA, Wang Y, Hu H et al. A \nReliable and Accessible Caregiving Language Model (CaLM) to Support Tools \nfor Caregivers: Development and Evaluation Study. JMIR Formative Research \n[Internet]. 2024 Jul 31 [cited 2024 Oct 14];8:e54633. Available from:  h t t p  s : /  / w \nw w  . n  c b i  . n l  m . n i  h .  g o v  / p m  c / a r  t i  c l e s / P M C 1 1 3 2 5 1 0 0 /\n44. Zaleski AL, Berkowsky R, Jean K, Pescatello LS. Comprehensiveness, accuracy, \nand readability of exercise recommendations provided by an AI-Based chat-\nbot: mixed methods study. JMIR Med Educ. 2024;10:e51308–8.\n45. Bedi S, Liu Y, Orr-Ewing L, Dash D, Koyejo S, Callahan A, et al. Testing and \nevaluation of health care applications of large Language models: A system-\natic review. JAMA. 2025;333(4):319–28.\n46. Komorowski M, Del M, Chang AC. How could ChatGPT impact my practice \nas an intensivist? An overview of potential applications, risks and limitations. \nIntensive Care Med. 2023;49:844–7.\n47. Hager P , Jungmann F, Holland R, Bhagat K, Hubrecht I, Knauer M, et al. Evalu-\nation and mitigation of the limitations of large Language models in clinical \ndecision-making. Nat Med. 2024;30(9):2613–22.\n48. Roberts J, Baker M, Andrew J. Artificial intelligence and qualitative research: \nThe promise and perils of large language model (LLM) assistance. Critical \nPerspectives on Accounting [Internet]. 2024;99:102722. Available from:  h t t p  s : \n/  / w w w  . s  c i e  n c e  d i r e  c t  . c o  m / s  c i e n  c e  / a r  t i c  l e / p  i i  / S 1 0 4 5 2 3 5 4 2 4 0 0 0 2 1 2\n49. Buçinca Z, Malaya MB, Gajos KZ. To Trust or to Think: Cognitive Forcing Func-\ntions Can Reduce Overreliance on AI in AI-assisted Decision-making. Pro-\nceedings of the ACM on Human-Computer Interaction. 2021;5(CSCW1):1–21.\n50. Jabbour S, Fouhey D, Shepard S, Valley TS, Kazerooni EA, Banovic N et al. Mea-\nsuring the Impact of AI in the Diagnosis of Hospitalized Patients: A Random-\nized Clinical Vignette Survey Study. JAMA [Internet]. 2023;330(23):2275–84. \nAvailable from:  h t t p  s : /  / j a m  a n  e t w  o r k  . c o m  / j  o u r  n a l  s / j a  m a  / a r  t i c  l e - a  b s  t r a c t / 2 8 1 \n2 9 0 8\n51. Goh E, Gallo R, Hom J, Strong E, Weng Y, Kerman H, et al. Large Lan-\nguage model influence on diagnostic reasoning. JAMA Netw Open. \n2024;7(10):e2440969.\n52. Gallifant J, Afshar M, Ameen S, Yindalon Aphinyanaphongs, Chen S, Cac-\nciamani G et al. The TRIPOD-LLM reporting guideline for studies using large \nlanguage models. Nature Medicine [Internet]. 2025;31. Available from:  h t t p s :   /  \n/ w w  w .  n a t  u r  e  . c  o  m /  a r t  i c l   e s / s  4 1   5 9 1 -  0 2 4 - 0  3 4 2 5 - 5\n53. Cecconi M, Greco M, Shickel B, Vincent JL, Azra Bihorac. Artificial intelligence \nin acute medicine: a call to action. Crit Care. 2024;28:258.\nPublisher’s note\nSpringer Nature remains neutral with regard to jurisdictional claims in \npublished maps and institutional affiliations.",
  "topic": "Medicine",
  "concepts": [
    {
      "name": "Medicine",
      "score": 0.9241714477539062
    },
    {
      "name": "Primer (cosmetics)",
      "score": 0.5139874815940857
    },
    {
      "name": "Intensive care medicine",
      "score": 0.3778560757637024
    },
    {
      "name": "Medical emergency",
      "score": 0.35196271538734436
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Organic chemistry",
      "score": 0.0
    }
  ]
}