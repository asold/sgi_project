{
    "title": "An open-source fine-tuned large language model for radiological impression generation: a multi-reader performance study",
    "url": "https://openalex.org/W4402926611",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A4321188182",
            "name": "Adrian Serapio",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2770880433",
            "name": "Gunvant Chaudhari",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2990465406",
            "name": "Cody Savage",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2190349507",
            "name": "Yoo Jin Lee",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2212491338",
            "name": "Maya Vella",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2214074111",
            "name": "Shravan Sridhar",
            "affiliations": []
        },
        {
            "id": null,
            "name": "Jamie Lee Schroeder",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2098251169",
            "name": "Jonathan Liu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2512552713",
            "name": "Adam Yala",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2146337925",
            "name": "Jae Ho Sohn",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W3089474066",
        "https://openalex.org/W1913339316",
        "https://openalex.org/W4233624763",
        "https://openalex.org/W2559874490",
        "https://openalex.org/W4362522726",
        "https://openalex.org/W1484393529",
        "https://openalex.org/W4376640725",
        "https://openalex.org/W4380423243",
        "https://openalex.org/W4382182493",
        "https://openalex.org/W4387472906",
        "https://openalex.org/W4307079201",
        "https://openalex.org/W2981852735",
        "https://openalex.org/W4295312788",
        "https://openalex.org/W2980282514",
        "https://openalex.org/W2908510526",
        "https://openalex.org/W1972978214",
        "https://openalex.org/W2136148671",
        "https://openalex.org/W3003257820",
        "https://openalex.org/W2901906577",
        "https://openalex.org/W3035965352",
        "https://openalex.org/W4366330426",
        "https://openalex.org/W2129514346",
        "https://openalex.org/W4385381606",
        "https://openalex.org/W4367186868",
        "https://openalex.org/W4318069287",
        "https://openalex.org/W3099878876",
        "https://openalex.org/W3103145119"
    ],
    "abstract": "Abstract Background The impression section integrates key findings of a radiology report but can be subjective and variable. We sought to fine-tune and evaluate an open-source Large Language Model (LLM) in automatically generating impressions from the remainder of a radiology report across different imaging modalities and hospitals. Methods In this institutional review board-approved retrospective study, we collated a dataset of CT, US, and MRI radiology reports from the University of California San Francisco Medical Center (UCSFMC) ( n = 372,716) and the Zuckerberg San Francisco General (ZSFG) Hospital and Trauma Center ( n = 60,049), both under a single institution. The Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score, an automatic natural language evaluation metric that measures word overlap, was used for automatic natural language evaluation. A reader study with five cardiothoracic radiologists was performed to more strictly evaluate the model’s performance on a specific modality (CT chest exams) with a radiologist subspecialist baseline. We stratified the results of the reader performance study based on the diagnosis category and the original impression length to gauge case complexity. Results The LLM achieved ROUGE-L scores of 46.51, 44.2, and 50.96 on UCSFMC and upon external validation, ROUGE-L scores of 40.74, 37.89, and 24.61 on ZSFG across the CT, US, and MRI modalities respectively, implying a substantial degree of overlap between the model-generated impressions and impressions written by the subspecialist attending radiologists, but with a degree of degradation upon external validation. In our reader study, the model-generated impressions achieved overall mean scores of 3.56/4, 3.92/4, 3.37/4, 18.29 s,12.32 words, and 84 while the original impression written by a subspecialist radiologist achieved overall mean scores of 3.75/4, 3.87/4, 3.54/4, 12.2 s, 5.74 words, and 89 for clinical accuracy, grammatical accuracy, stylistic quality, edit time, edit distance, and ROUGE-L score respectively. The LLM achieved the highest clinical accuracy ratings for acute/emergent findings and on shorter impressions. Conclusions An open-source fine-tuned LLM can generate impressions to a satisfactory level of clinical accuracy, grammatical accuracy, and stylistic quality. Our reader performance study demonstrates the potential of large language models in drafting radiology report impressions that can aid in streamlining radiologists’ workflows.",
    "full_text": null
}