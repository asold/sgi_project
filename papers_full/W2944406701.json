{
    "title": "Learning with computers: Generating insights into the development of cognitive tools using cultural historical activity theory",
    "url": "https://openalex.org/W2944406701",
    "year": 2019,
    "authors": [
        {
            "id": "https://openalex.org/A5003655639",
            "name": "Seng Chee Tan",
            "affiliations": [
                "Nanyang Technological University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W1981272632",
        "https://openalex.org/W7042970625",
        "https://openalex.org/W2180834469",
        "https://openalex.org/W57779773",
        "https://openalex.org/W7027563279",
        "https://openalex.org/W2018130849",
        "https://openalex.org/W2139894798",
        "https://openalex.org/W2337837417",
        "https://openalex.org/W2582244108",
        "https://openalex.org/W1979343245",
        "https://openalex.org/W2171616164",
        "https://openalex.org/W1947644038",
        "https://openalex.org/W2059921058",
        "https://openalex.org/W1589065569",
        "https://openalex.org/W2020781346",
        "https://openalex.org/W226995632",
        "https://openalex.org/W2075919688",
        "https://openalex.org/W6629454943",
        "https://openalex.org/W2135979820",
        "https://openalex.org/W6608252198",
        "https://openalex.org/W6631392369",
        "https://openalex.org/W2615752180",
        "https://openalex.org/W2907186152",
        "https://openalex.org/W6745972751",
        "https://openalex.org/W1519058456",
        "https://openalex.org/W2058745229",
        "https://openalex.org/W2063898208",
        "https://openalex.org/W2172137538",
        "https://openalex.org/W6948509072",
        "https://openalex.org/W1551289443",
        "https://openalex.org/W4231350832",
        "https://openalex.org/W2097228681",
        "https://openalex.org/W2133052656",
        "https://openalex.org/W2152597554",
        "https://openalex.org/W2340539079",
        "https://openalex.org/W6640151826",
        "https://openalex.org/W2149491422",
        "https://openalex.org/W2040127838",
        "https://openalex.org/W2617950425",
        "https://openalex.org/W7082574851",
        "https://openalex.org/W2135943618",
        "https://openalex.org/W2949082359",
        "https://openalex.org/W2789328589",
        "https://openalex.org/W2944406701",
        "https://openalex.org/W4240106162",
        "https://openalex.org/W2734795052",
        "https://openalex.org/W1511437566",
        "https://openalex.org/W2496167650",
        "https://openalex.org/W1544649311",
        "https://openalex.org/W1525489180",
        "https://openalex.org/W2444324277",
        "https://openalex.org/W205168037",
        "https://openalex.org/W2120346511",
        "https://openalex.org/W2116199508",
        "https://openalex.org/W1494822611",
        "https://openalex.org/W2057864840",
        "https://openalex.org/W10833075",
        "https://openalex.org/W2774272969",
        "https://openalex.org/W2021536722",
        "https://openalex.org/W4247964035",
        "https://openalex.org/W1575362237"
    ],
    "abstract": "Using computers as cognitive tools or mindtools has created impact in education since their introduction in the 1990s. One main characteristic is the notion of learning with computers as intellectual partners: engaging learners in higher level thinking while taking away the lower level cognitive load such as computing and digital storage. In recent years, the element of social interactions has been integrated, leading to the development of social cognitive tools or social mindtools. However, the differences between and underlying values of these applications may not be apparent. This article applies cultural historical activity theory (CHAT) to analyse these developments so as to generate insights into the nuanced differences among various applications, including the roles of computers in distributed cognition within an activity system. CHAT can be applied to analyse contradictions within and beyond an activity system, which can help to identify opportunities for innovation and enhancement to the system.",
    "full_text": "Australasian Journal of Educational Technology, 2019, 35(2).   \n \n \n25 \nLearning with computers: Generating insights into the \ndevelopment of cognitive tools using cultural historical activity \ntheory \nSeng-Chee Tan \nNational Institute of Education, Nanyang Technological University \n \nUsing computers as cognitive tools or mindtools has created impact in education since their \nintroduction in the 1990s. One main characteristic is the notion of learning with computers \nas intellectual partners: engaging learners in  higher level thinking while taking away the \nlower level cognitive load such as computing and digital storage. In recent years, the element \nof social interactions has been integrated, leading to the development of social cognitive tools \nor social mindtools . However, the differences between and underlying values of these \napplications may not be apparent. This article  applies cultural historical activity theory \n(CHAT) to analyse these developments so as to generate insights into the nuanced differences \namong various applications, including the roles of computers in distributed cognition within \nan activity system. CHAT can be applied to anal yse contradictions within and beyond an \nactivity system, which can help to identify opportunities for innovation and enhancement to \nthe system. \n \nIntroduction \n \nThis article aims to clarify the characteristics and values of various ways of learning with computers, using \ncultural historical activity theory (CHAT) ( Cole & Engeström, 1993; Engeström, 1987)  as an analytical \nlens. CHAT provides an appropriate framework to analyse an activity system that depicts how a group of \nparticipants work on a common goal, the tools used and the rules and division of roles. Details of CHAT \nwill be provided in the Methods section. \n \nUsing computers as a tutor (Taylor, 1980) to mimic the roles of an instructor, as in the case of various \ncomputer-assisted instruction programs, has been a predominant approach in  integrating technologies into \neducation. Typically, a computer -assisted inst ruction program starts with a set of predefined learning \nobjectives and pre-programmed sequences of instructional activities, coupled with assessment of a learner’s \nprogress, which aims at helping learners acquire knowledge. With the advancement in compute r \ntechnologies and cognitive sciences, intelligent tutoring systems (ITSs) were developed to provide flexible \nand customised learning pathway s based on learners’ performance and behaviours. In recent years, the \ndevelopment of massive open online courses (M OOCs) (Li, Sun, & Sun, 2018) has  gained popularity \namong educators and learners for their accessibility. Regardless of the advancement in technologies, ITS s \nand most MOOCs are still functioning in their similar mode of using computers as a tutor, focusing on \nstudents’ learning from computers; that is,  computers play the role of instructors , and computing \nintelligence is invested in making these roles more human like, for example, in optim ising learning \npathways for learners. \n \nHowever, using computers as tutors has its fair share of criticism s, for example, for neglecting design for \nsocial interactions among learners and lacking attention to the social presence of tutor and peers (Stahl, \nKoschmann, & Suthers, 2015). Using computers as tutors is also operating with the assumption that \nknowledge can be chunked into discrete units of facts and that learning means acquiring these facts; in other \nwords, treating learning as acquisition of knowledge (Sfard, 1998) . In this regard, using computers as \ncognitive tools or mindtools offers refreshing alternative approaches that help educators break away from \nthe tyranny of computers controlling learners and replacing tutors. Just like a physical tool that helps \nhumans do work, computers can aid humans in t hinking. Various terms have been used for these related \napplications, such as cognitive technologies (Pea, 1985), technologies of the mind (Salomon, Perkins, &  \nGloberson, 1991), cognitive tools (Kommers, Jonassen, & Mayes, 1992), and mindtool s (Jonassen, 1996, \n2000). Among these tools, a sub- category known as social cognitive tools (e.g., Scardamalia & Bereiter, \n1996) or social mindtools (e.g., Nuutinen, Sutinen, Botha & Kommers, 2010) has also emerged.  \n \nDespite the fact that the concept of cognitive tools or mindtools emerged in the late 1980s, more than two \ndecades later, M. C. Kim (2012), in revisiting the use of cognitive tools for science education, raised three \nAustralasian Journal of Educational Technology, 2019, 35(2).   \n \n \n26 \nissues concerning research on cognitive tools. First, there is a need to clearly define what  a cognitive tool \nis; second, there should be research examining the distribution of knowledge mediated with cognitive tools; \nthird, more research could be devoted to examining the contextual applications of cognitive tools. These \nissues, including the need to clarify the definition of cognitive tools, could be an indication of the continual \nevolution of the field and the emergence of new concepts and tools that redefine the notion of learning with \ncomputers. How do we make sense of these developments? What  are their values and how do we further \nadvance the research and development of these tools and their applications? This article aims to address \nsome of these issues, focusing on the overarching research question: “ What are the characteristics of the \nactivity systems related to learning with computers, including the use of computers as mindtools, as \ncognitive tools, and as social mindtools or social cognitive tools ?” The analyses were guided by the \nfollowing sub-questions: \n \nFor each type of application, \n \n(1) What does a typical activity system look like? \n(2) What are the underlying motives and theories about learning? \n(3) What are the tools used? What roles do the tools play? \n(4) Are there differences among the use of computers as mindtools, computers as cognitive tools, and \ncomputers as social mindtools or social cognitive tools? \n \nIn addition to these analytical questions, how do we innovate and improve these applications? \n \nMethods \n \nThis article, a synthesis of published academic works , aims to clarify the concepts and development of \nlearning with computers , epitom ised by using computers as cognitive tools or mindtools. It is not a \nsystematic review of empirical studies; rather, it is aligned to the research synthesis method called \nqualitative synthesis of research (Suri & Clarke, 2009). This synthesis method uses a more inclusive lens \nwith which to analyse various types of academic publications, including non-research papers. This method \nis relevant to this article, which has a specific focus on the major developments in and theoretical discussion \nof learning with computers, which are also presented in non-empirical studies. \n \nA search was conducted via EBSCO Discovery service, which includes several databases (e.g., PsyArticles \nand ProQuest ), using the search terms ( TI “ cognitive tool ?” or “mindtool?”) and “education” and \n(computer? or technology or software), limited to scholarly peer-reviewed articles in the English language. \nThere were 143 articles identified; each article was reviewed focusing on those that provide theoretical \nbases for the use of the tools. Snowball method was used to identify other relevant articles. The References \nsection (57 items) lists the articles selected, including some empirical studies that were used to provide \nexamples of the applications. \n \nMethodologically, to make sense of the various applications and developments in the evolution of learning \nwith computers, this article adopted CHAT (Cole & Engeström, 1993; Engeström, 1987) as a framework \nfor the analysis. CHAT is a framework that examines the human activities of individuals in an associated \nsocial community. An activity is an object-oriented structure that is shaped by a culture (Engeström, 1999); \nit is a conscious process driven by a motive (Engeström, 1999; Kozulin, 1986); and it consists of chains of \nactions directed at some goals, which, in turn, are made up of a series of operations (specific acts) that are \nafforded by the available conditions in the environment. For example, a classroom activity using a concept \nmapping tool could be driven by the goal of enhancing students’ critical thinking; the use of the concept \nmapping tool  also reflects the beliefs and values of the te achers using this pedagogical approach. The \nteachers could implement a series of actions (e.g., teaching how to use a concept map, providing examples, \nsetting a concept mapping assignment) as short -term goals that aim at achieving the outcome of learning \nwith constructing a concept map. The teacher then performs a series of operations (e.g., communicating \ninstructions). \n \nEngeström (1987) proposed an activity system that has six core components depicted as nodes of a triangle \n(see Figure 1) . The top three el ements show how a subject (or an actor) acting on an object (a focused \nentity) to achieve the desired outcome that is mediated by the tool(s). Tools can be physical (e.g., a \nwhiteboard) or conceptual cultural artefacts (e.g., language, protocols) . For example, a student (subject) \nAustralasian Journal of Educational Technology, 2019, 35(2).   \n \n \n27 \nuses a tool (a computer-based tutorial) to learn about a topic (object) to achieve deeper understanding of a \ntopic (outcome). The fourth component is the community, comprising others who share a common interest \nin working on the object. Mediating between the subject and the community are rules that regulate how the \nsubject relates to or works with other participants in the community. Division of labour describes the roles \nof members in the community when working on the obj ect. Figure 1 shows an example of the activity \nsystem depicting learning from computers using a computer-based tutorial program. \n \n \nFigure 1. An activity system of using a computer-based tutorial (adapted from Engeström, 2001, p. 135) \n \nCHAT was chosen as the framework for analysing various applications of learning with computers because \nit directs one’s attention to the main actors in an activit y system, the mediating tools used, and the objects \nthe actors are working on. It also helps us in identifying the underlying rules and division of roles. Given \nthat the distribution of roles (between machines and people and among people) is an important \nconsideration in the applications of mindtools or cognitive tools, CHAT is an appropriate framework for \nthe purpose of this article. \n \nAnalysis of mindtools, cognitive tools, and social mindtools or social cognitive tools using \nCHAT \n \nIn this section,  CHAT is used to analyse three major ways of using computers as tools in the following \norder: computers as mindtools, as cognitive tools, and as social mindtools or social cognitive tools.  \n \nActivity systems of using computers as mindtools \nMindtools are “computer-based tools and learning environments that have been adapted or developed to \nfunction as intellectual partners with the learner in order to engage and facilitate thinking and higher order \nlearning” ( Jonassen, 2000, p. 9) , for example, using a semantic netwo rking tool (e.g., CMap , \nhttps://cmap.ihmc.us/) for concept mapping. Concept mapping , a technique developed by Novak and \nGowin (1984), requires a learner to identify the key concepts of a topic, represent the concepts with the \ncorrect concept labels, link a concept with related concepts, label the relationships between pairs of \nconcepts, and sometimes arrange the concepts in hierarchical order. Although concept mapping can be done \nusing the paper-and-pencil method, a semantic networking tool provides digital storage and retrieval; ease \nof addition, revision and expansion; ease of cross -linking; ease of collaboration; and machine calculations \nof metrics related to the maps for feedback. \n \nFigure 2 shows the typical activity system of an application of mindtools in a classroom, represented by the \nuse of a concept mapping tool. Underpinning the use of computers as mindtools are distributed cognition \nand Vygotsky’s (1978) social constructivist theory, particularly mediation of cognition by cultural artefacts \nor tools. Following Vygotsky’s theory, the partnership with tools or cultural artefacts to achieve what an \nindividual would otherwise not be able to achieve is but a step towards individuals internalising the thinking \nand developing the competency to carry out the intellectual activity independently. Pea (1993) suggested \nthat most of our intellectual activities are enacted through some extent of distribution between the person \nand cultural artefacts or tools (e.g., use of the paintbrush by a painter) such that it is sometimes impossible \nto separate our cognition as activities independent from cultural artefacts and tools.  \n \nTools (computer-based tutorial) \nSubject (e.g., \nstudents) \n Object (learning a topic) \nDivision of labour (e.g., the teacher selects \ntutorial and provides support; students use the \ncomputer tutorial and answer quizzes) \n \nRules (e.g., rules about \nlearning in a computer \nlab) \nOutcomes (content mastery) \nCommunity \n(e.g.,teacher & \nstudents) \nAustralasian Journal of Educational Technology, 2019, 35(2).   \n \n \n28 \nApplying the lens of distributed cognition , B. Kim and Reeves (2007) suggested that mindtools mediate \nbetween the subject (a learner) and the object , and there is a distribution of roles between computers as \ntools and learners. \n \nThe value of mindtools can be illustrated by contrasting them with the use of computer-assisted instruction. \nIn computer-assisted instruction  programs, the computers are programmed to mimic instructors by \nproviding instruction and assessing learners. Content for learning has to be hard-coded into the system, and \nsome forms of intelligence can be embedded to reveal the content in bite sizes, in different modalities, and \ndifferent sequences. The learners’ roles are to follow the instructions, perform the learning activities, and \nanswer the quizzes. Mindtool s, however, work differently. The computer provide s the digital tool or \nenvironment, stores the data, and uses programmed algorithms for calculations (e.g., metrics for a concept \nmap); the learners, on the other hand, have to do the hard work of cognitive activities like critical thinking. \nJonassen (2000) argued that using computers as mindtools engages learners in the most crucial aspects of \nlearning (critical thinking and meaningful learning), while computers perform the parts that co mputing \ndevices are designed for (i.e., computing). It is an intellectual partnership that focuses on learning. In short, \nthe critical difference between a mindtool and a computer-assisted instruction program is that a mindtool \nacts as an intellectual partner to engage learners in thinking, while the latter is a teaching  tool that helps to \ndeliver instruction  (an efficiency tool) . Pea (1985) further elaborated the roles of computer tools in \nrestructuring a learner’s thinking. A concept mapping tool, for example, constrains the way the knowledge \nis represented (e.g., a user should use concept labels) and engages  the learners in critical thinking (e.g., \nidentify relationships) which will not occur naturally. In this sense, mindtools are not fingertip tools  \n(Perkins, 1985) that learners use effortlessly; they actually make the learners think harder. \n \nMost mindtools used are domain general tools (B. Kim & Reeves, 2007) that can be applied for learning of \nvarious subject disciplines (e .g., sciences and humanities). However, not all domain general tools are \nmindtools. Jonassen (2000) differentiated between a mindtool (e.g., a concept mapping tool) and a \nproductivity tool (e.g., word processing  software) in that the productivity tool help s us in doing work \nefficiently, but not necessarily engaging us  in thinking. Thus, productivity tools that increase work \nefficiency are not mindtools. \n \nUnderpinning the use of computers as mindtools is the constructivist philosophy of learning. Duffy and \nJonassen (1992) explained the differences between objectivist and constructivist epistemologies and how \nthey affect the way technologies are used in education. In computer -assisted instruction programs, there is \nan assumption that learning is a process of achieving complete understanding of the correct structure, \nproperties, and relationships of the world out there. The goal of instruction is to transmit this objective \ntruth, and objective tests can be set to assess the extent of knowledge gain ed by the lear ners. Different \ninterpretations of the objective knowledge mean partial or biased understanding. In contrast, constructivist \nepistemology (Bednar, Cunningham, Duffy, & Perry, 1992) acknowledge s the existence of the external \nworld, but the structure, proper ties, and relations hips are subject to interpretation, which can vary in \ndifferent cultures and contexts. Learning is helping learners to get to know the socially constructed and \nsanctioned knowledge in a community. Thus, experience and meaning making are a critical part of the \nlearning process. Getting learners to represent their knowledge using mindtools is one of the ways of \nengaging them in the critical process of meaning making. \n \n \nFigure 2. An example of an activity system of using CMap as a mindtool \n \nTools (e.g., CMap) \nLearners \n Concept mapping of \na topic \n \nTeacher designs learning activities with \nmindtools; learners use mindtools to complete \nassigned learning tasks \nTeacher & \nstudents \nClassroom rules \nestablished by the \nteacher \n \nCritical thinking \n \nMotive: Develop critical thinking through constructivist learning \nAustralasian Journal of Educational Technology, 2019, 35(2).   \n \n \n29 \nActivity systems of using computers as cognitive tools \nPursuing a similar line of argument of using tools to support learning, another group of researchers proposed \nthe use of computers as cognitive tools. The concepts of mindtools and cognitive tools are similar but with \nsome minor differences in research tradition and implementation approach.  While Jonassen (1996, 2000) \ncame from the tradition of instructional design, using computers as cognitive tools (see Lajoie, 2000; Lajoie \n& Derry, 1993) was initiated by researchers in the field of artificial intelligence and cognitive science.  \nUsing computers as cognitive tools (Lajoie, 2000; Lajoie & Derry, 1993) was proposed as an alternative to \nmodelling students’ thinking processes as in the case ITSs. Lajoie and Derry (1993) saw the limitations of \nITSs, such as the impossibility of modelling all possible thinking processes. Critically, using computers as \nan intelligent tutor  deprives the students agency in  setting their own goals and assess ing their own \nperformance. Thus, the proponents of using computers as cognitive tools follow similar cognitive task \nanalyses of thinking processes, just like the researchers in ITSs, but they use the analyses for unintelligent \ntutoring systems that scaffold (rather than diagnose and prescribe) students’ thinking. One example of using \ncomputers as cognitive tools is the Writing Partner (Salomon, 1993). Building on the analyses of the \npsychology and procedures of composition writing by Bereiter and Scardamalia (1987), the Writing Partner \noffers four kinds of support by providing a planning and outline tool, guiding questions during the writing \nprocess, a pull-down menu for assistance when a learner is stuck in the writing, and memory support in \nterms of retrieving the key ideas and outlines. Another example is HERON (Reusser, 1993), which focused \non helping elementary school children solve mathematics word problems  (a type of mathematics exercise \nwith a substantial part of the background information of the problem presented as text). Based on cognitive \ntask analyses of solving word problems, HERON  was developed as a graphical  interface tool that helps a \nlearner identify relevant quantitative values and units in a word problem, relate these quantitative variables \naccording to the text description of the word problem, and finally translate them into appropriate equations. \n \nSalomon (1993) articulated the twin goals of using computers as cognitive tools : (a) to take over the low \nlevel, tedious, and laborious processes, so as to ( b) free up the learners’ cognitive sources to engage in \nhigher order thinking with the goal of fostering independent thinkers. Computers  help learners engage in \nconstructive thinking and provide scaffold ing for cognitive operations that learners would not be  able to \nperform independently. Salomon diff erentiated between performance -oriented tools and pedagogic tools. \nPerformance-oriented tools enhance the performance of a learner (effect with technology), although the \nultimate goal is that the learner would develop the cognition without the aid of the tool (effect of  \ntechnology). In this way, performance -oriented tools could have learning value and are differ ent from the \nproductivity tools referred to by Jonassen (2000). \n \nIt is noteworthy that cognitive tools – for example, Salomon’s (1993) Writing Partner and Reusser’s (1993) \nHERON – focus on specific cognitive activities (e.g., writing or mathematics problem -solving) whereas \nJonassen’s (1996, 2000) mindtool s are more generic tools for thinking (e.g., semantic networking tools) \nthat focus on knowledge re presentation applicable for various subject domains.  Thus, cognitive tools are \ndomain specific tools (B. Kim & Reeves, 2007), such as HERON for solving mathematics word problems. \nIn some cases, cognitive tools can be developed to support thinking in a doma in (e.g., writing) but not \nspecific skills. B. Kim and Reeves (2007) called these domain generic tools. \n \nFrom the above description, it is apparent that the underlying motive for using computers as cognitive tools \nis to scaffold specific thinking processes , so as to help novices develop expertise in a specific domain. \nWhile most mindtools (e.g., concept mapping tools) are domain general tools, cognitive tools are usually \nthe outcome of a development process by researchers for a specific purpose (see Figure 3), which involve \ntwo closely interlinked activity systems. The tools developed by one community are used by learners in \nlearning contexts. \n \nTo achieve the goal of developing expertise among learners, guidance provided in using the tools is critical. \nThe underpinning philosophy is that of neo -Piagetian psychology of developing metacognitive self -\nregulation ( Lajoie & Derry, 1993), which refers to the ability to consciously reflect on one’s problem -\nsolving strategy or knowledge model. Cognitive tools make the abstract strategies concrete for examination \nand discussion, and thus afford the opportunity for metacognitive regulation. A good tutor or mentor can \nguide the students in using cognitive tools appropriately for metacognitive regulation. \n \nAustralasian Journal of Educational Technology, 2019, 35(2).   \n \n \n30 \n \nFigure 3. Activity systems of developing and using computers as cognitive tools \n \nActivity system of using computers as social cognitive tools or social mindtools \nWhile much research on using computers as cognitive tools or mindtools has focused on individual learners, \nthere are research and development efforts to extend this to learning contexts involving social interactions. \nFor example, using online conferencing tools can support  learning as “a process of enculturation into a \ncommunity of learners or practitioners” (Jonassen, 2000, p. 238). \n \nA review of literature shows that studies that featured social cognitive tools or social mindtools in the titles \nfall into two broad categories: (a) social interactions designed and supported by instructors, and ( b) social \ninteractions supported or scaffolded through computers.  The first category is exemplified by Hwang, Shi , \nand Chu (2011) , who  used m obile technologies and RFID (radio -frequency identification)  to support \nstudents in context-sensitive learning in a butterfly ecology garden. The elementary school students in the \ntreatment group had to first construct concept maps using a cognitive tool called CMap after learning about \necology in the classroom. The students then visited an ecology garden and edited their concept maps and \nshared them with their classmates. Although CMap supports collaborative construction of concept maps, \nthis study reporte d sharing, rather than co -construction, of the concept maps. This category bears strong \nsimilarities to the use of cognitive apprenticeship to develop learners ’ expertise described in the previous \nsection (Activity systems of using computers as cognitive  tools). For the second category  of supporting \ninteractions via computer tools , Kirschner and Wopereis  (2003) reported the use of conversation tools to \nsupport teachers’ conversation with the goal of building a community of practice (Lave & Wenger, 1991). \nThe value of the conversation tools is demonstrated in a project called ICT-E-NET(Kirschner & Wopereis, \n2003), which offered four spaces that help to build a professional community (Publication space for \nreferences and guidelines, Reflection space for sharin g of experiences, Discussion space for conversation, \nand Construction space for developing new documents). \n \nIn terms of scaffolding roles, computer-based cognitive tools that support or scaffold social interactions are \nmerging with a parallel development known as computer-supported collaborative learning (CSCL). CSCL \nis a rapidly evolving field of study that concerns the design, analysis, and implementation of computer \nsupport and collaborative learning (Stahl, Koschmann, & Suthers, 2015). Considering the broad inclusive \nnature of the field of CSCL, social cognitive tools or social mindtools can be considered a subset of CSCL \ntools with a strong emphasis on scaffolding the cognitive processes of learning. According to Stahl  et al. \n(2015), since the beginning  of 1990s, CSCL has emerged as a field that highlights the use of networked \ncomputers to support collaborative learning, as opposed to predominant e-learning delivery that focuses on \ntransmission of information (learning from computers). Collaborative lear ning focuses on “individuals \nnegotiat[ing] and shar[ing] meanings relevant to the problem-solving task at hand” through “a coordinated, \nsynchronous activity that is the result of a continued attempt to construct and maintain a shared conception \nof a problem (Roschelle & Teasley, 1995, p. 70). \n \nOne example of a CSCL tool is Knowledge Forum, which is the brainchild of Scardamalia and Bereiter \n(1996, 2014), who developed the platform in tandem with their development of knowledge building theory \nCognitive tools (e.g., Writing Partner) \nLearners \n Compose essays \nTutor designs and mentors learning activities with \ncognitive tools and provides guidance; learners use \ncognitive tools to complete assigned learning tasks \n \nTutor or mentor \n \nClassroom rules \nestablished by the tutor \n \nCompetence in essay \nwriting \n \nMotive: Developing expertise through cognitive apprenticeship \nResearchers \nCognitive task \nanalysis \nExpert \nperformers \nDevelop cognitive \ntools \n\nAustralasian Journal of Educational Technology, 2019, 35(2).   \n \n \n31 \nand pedagogy. Knowledge building is an idea-centric and dialogic approach. It leverages a student’s natural \ncuriosity in asking questions and develops that into collaborative inquiry. As students pursue their inquiry, \nthey represent their ideas (e.g., explanations, theory) on Knowledge Forum as notes; through collaborative \nmeaning making, investigation, and learning from authoritative sources of knowledge, they improve their \nideas (e.g., developing increasingly better explanations). In this way, the trajectory of collaborative idea \nimprovement is reified in the knowledge artefacts (notes). This approach can be considered dialogic (Wells, \n1999) in that it engages the students in dialogues and meaning making, and also empowers them with their \nvoice and choice  of inquiry  – which is radically different from the predominant teacher -directed \npedagogical approaches (e.g., lecture and recitation). \n \nSocial cognitive tools or social mindtools are employed to support an activity system in many ways. Like \nmindtools or cognitive tools, they can scaffold the cognitive processes mediating between subject and \nobject. For example, in Knowledge Forum (Scardamalia & Bereiter, 1996, 2014), cognit ive cues such as \n“my theory is” and “I need to understand” are often  used to support learners in proposing ideas and in \nthinking deeply about a topic to improve tho se ideas. Social cognitive tools can also be used to support \ncommunity rules and division of labour (Nuutinen et al., 2010). \n \nA new class of tools, known as cognitive group awar eness tools (Janssen & Bodemer, 2013), are \nincreasingly being developed. From the perspective of cognitive load theory (Sweller, 2010) , group \nawareness tools help users in reducing the cognitive burden of coordinating and communicating with other \ngroup members (Dillenbourg & Bétrancourt, 2006). The tools work by providing information that may not \nbe apparent to the participating members who are immersed in the interaction process (Janssen & Bodemer, \n2013). In Knowledge Forum, for example, engagement rules a re scaffolded by various features. For \ninstance, the Promising Idea tool (Chen, Scardamalia, & Bereiter, 2015) enables users to highlight ideas \nthat are likely to lead to more fruitful discussion. Learners can build on (reply to) one another’s notes but \nnot edit or change the content of others’ notes; in cases when more than one author is assigned to a note, \nall authors can edit the note.  \n \nComputers are used as social cognitive tools or social mindtools to integrate social interactions and \ncognitive scaffolding in learning. In terms of a theoretical underpinning, this use is aligned to a participatory \napproach to learning (Sfard, 1998) and learning by enculturation into a community (Lave & Wenger, 1991). \nLearning through participation entails knowing and building expertise through dialogues with peers and \nexperts in a community, rather than trying to acquire objective knowledge through transmission. In a \ncommunity of practice, a member starts at the periphery of the community. Participation in the community’s \nactivities provides opportunities for members to socially construct meanings and create and appropriate \nsocial cultural norms. Over time, a new member begins to appropriate implicit and explicit knowledge, and \nat the same time, develops expertise and an identity within the community. Much like an apprentice learning \nfrom the master, the development of skills, values, norms, and rules held by the core members within the \ncommunity of practice is a participatory process. A member journeys from the peripher y to the centre of \nthe community as he or she develops expertise. The i dentity of the person gradually develops through the \nappropriation of the beliefs, values, and skills required in a practice. \n \nIn the case of a social cognitive tool (e.g., Scardamalia & Bereiter, 1996, 2014) or social mindtool (e.g., \nHwang, Shi, et al., 2011), if an existing tool is used, t he activity system of a social mindtool is similar to \nthat of a mindtool (Figure 2). In some cases like the use of Knowledge Forum, through the use o f various \nresearch and development methods, a community of researchers has been formed that continue to improve \nthe tool (Knowledge Forum) and the knowledge building pedagogy (rules of engagement and division of \nlabour); consequently, the activity system a s depicted in Figure 4, is more complex than that of Figure 3 \nbecause the outcomes of the research activity system have impact on the tools, the rules, and division of \nlabour of the application activity system. \nAustralasian Journal of Educational Technology, 2019, 35(2).   \n \n \n32 \n \nFigure 4. Activity systems of using computers as social cognitive tools or mindtools \n \nUsing CHAT analysis for improvement \n \nCHAT provides a framework for analysing the underlying motives of using computers as tools and how \ncomputers can contribute to the various components within an activity system. In addition, an analysis of \nthe contradictions within an activity system can provide critical information for improving the  system. \nContradictions refers to “historically accumulating structural tensions within and between activity systems” \nwhich serve as “sources of change and development” (Engeström, 2001, p. 137). According to Engeström \n(1987), there are four levels of cont radictions: primary, secondary, tertiary, and quaternary. A primary \ncontradiction happens internally within a single node of an activity system where there are “two opposing \nforces whose interplay leads to a necessity to choose one element of the contradiction over the other” (Holt \n& Morris, 1993, p. 100).  For example, a teacher who is keen to use Knowledge Forum but still holds the \nview of learning as acquisition (Sfard, 1998) may use the forum to disseminate information instead of \nengaging students in collaborative idea improvement (Tan & Tan, 2006). A secondary contradiction occurs \nbetween a pair of nodes. For example, using Knowledge Forum, students found that there are many ideas \ngenerated in the initial phase and have challenges prioritising which idea s to work on (Lee & Tan, 2017a, \n2017b). A tertiary contradiction happens when a new object (e.g., a culturally more advanced form of the \ncentral activity) is introduced into the system (Engeström, 1987). For example, when introduced to a new \ntool like Idea  Thread Mapper (Zhang et al., 2018), the teacher and students may experience this \ncontradiction of what to work on (object) in order to enhance the knowledge building process. A quaternary \ncontradiction is one that occurs between the central activity and i ts neighbouring activities that run \nconcurrently and could impact any one component of the activity system. For example, researchers of a \nknowledge building community could also be members in a learning analytics research community, who \ncan see immediate gaps in the Knowledge Forum tool. \n \nTo elaborate on the application of CHAT for improvement, an analysis of some innovations in learning \nwith computers is presented. For example, as mentioned in the preceding paragraph, using CHAT helped \nto identify the prob lem of a teacher who used knowledge building pedagogy but still held the view of \nlearning as acquisition , a type of primary contradiction  (Tan & Tan, 2006) . With the problem identified, \nwe could then design and evaluate methods to tackle this problem. One way is to get expert teachers to \nwork with novice teachers in a professional learning community to design knowledge building lessons \n(Tan, Chue, & Teo 2016). Within the research community of knowledge building, one challenge that has \nbeen identified is, given the many ideas generated by students in the initial phase of the process, what can \nwe do to help students proceed to have a more productive discussion? One of the issues is identifying ideas \nthat are more promising (Chen  et al., 2015) in bringing the discourse forward. This is an example of a \nsecondary contradiction, where the subjects face challenges in working on the object. More specifically, \nKnowledge Forum as a CSCL \n \nLearners \n Discussion on a topic \n \nKnowledge Forum supports division of \nlabour; Teacher facilitates and guide \ndiscussion; students engage in knowledge \nbuilding \nTeacher \nPrinciples of engagement according \nto knowledge building principles \n \n \nCollaborative idea \nimprovement \n \nMotive: Integrating social interactions and cognitive thinking; participatory \napproach and dialogic inquiry \nResearcher\ns \nResearch & \nDevelopment methods \nCommunity of \nKnowledge \nBuilding \nDevelop \nKnowledge Forum \nand knowledge \nbuilding pedagogy \nAustralasian Journal of Educational Technology, 2019, 35(2).   \n \n \n33 \nreferring to the activity system on the lower right side of Figure 4, how do learners achieve a more fruitful  \ndiscussion on a topic? To deal with this challenge, Chen et al. (2015) developed a tool for students to \nhighlight and identify promising ideas. To deal with the same problem, Lee and Tan  (2017a, 2017b ) \ndeveloped learning analytics solutions for data in Knowledge Forum to help identify ideas that are deemed \npromising to the community. It uses several techniques, including text mining using the software SOBEK \nto identify keywords in students’ discourse; feeding the keywords into network analysis tools called KBDex \n(Oshima, Oshima, & Matsuzawa, 2012); from the results of network analysis, comput ing betweenness \ncentrality (BC) indices of all the notes in the forum; and finally plotting the BC trends over turns of talk. \nBy examining the BC trends, notes that play the mediating roles in the discourse (connecting ideas) can be \nidentified. The outcome is the analytic framework and processes (Lee & Tan, 2017a, 2017b) for promising \nideas that researchers could use to advance a knowledge building process. \n \nA tertiary c ontradiction could lead to the development of new tools and methods. For example, Hwang, \nShi, et al. (2011) found that advancement in wireless technologies affords new opportunities for context -\nsensitive ubiquitous learning (u-learning). They saw opportunities for projected new forms of learning with \ncognitive tools by integrating various tools and methods. One example is the use of the repertory grid \nmethod (cf. expert systems by Jonassen, 2000) and concept mapping tools to engage students in field-based \nlearning (Hwang, Chu, & Tsai, 2011; Hwang, Hung, Chen, & Liu, 2014) supported by mobile technologies \nunder a Taiwanese national project called MAIL (mindtool -assisted in-field learning). Students are asked \nto collect data in real-world environments (e.g., ecology gardens) and classify the data using the repertory \ngrid method or construct concept maps based on the data. \n \nAn example of innovation that can be prompted by quaternary contradiction  is the development of \nconnectivist massive open online courses or cMOOCs, pioneered by Siemens (2005) and Downes (2012). \nIt is a quaternary contradiction in that cMOOCs present a parallel development (activity system) which \nintegrates learning with computers and learning from computers. In their inaugural cMOOC  course called \nConnectivism and Connective Knowledge (CCK), offered at the University of Manitoba in 2008, about \n2300 students took the class for free compared with only 25 registered fee -paying students. The course \nleveraged various technologies, particul arly the connectivity afforded by the Internet and Web 2.0 tools , \nincluding curation of information through RSS feeds, Second Life, blog posts in Moodle, and synchronous \nonline meetings. These technologies supported various processes for learning; for example, the aggregation \nof resources using curation tools helped learners to gain access to a wide range of resources ; learners used \nWeb 2.0 tools (e.g., YouTube, blogs, Flickr) both as consumer s of resources as well as creator s of \ninformation (blogs to write  reflections). However, some Web 2.0 tools such as Moodle act ed more like a \nlearning management system, rather than a mindtool or a cognitive tool.  Underpinning cMOOC s is the \ntheory of connectivism (Downes, 2012; Siemens, 2005), which views the Internet as  the foundation \ntechnology that helps to host knowledge in a distributed and new form of learning entailing the ability to \ntraverse the networks and integrate the distributed knowledge. It is apparent that a cMOOC is aligned to \ndistributed learning ( cf. distributed cognition by Pea, 1993) and it departs from learning solely through \nacquisition. Participatory learning is likely to be a mechanism operating in a cMOOC environment. It is, \nhowever, different from most social cognitive tools in terms of scale and  open structure; that is, it is not \nconfined to a small group of formal registered students, but open to large number s of participants who \nattend for free. In this way, the potential richness of resources and interaction opportunities are manifold, \nand the  empowerment of the students’ voice and choice of inquiry can be fully realised. Beyond \nparticipatory learning, connectivist learning also emphas ises the process of connecting various nodes of \ninformation, the ability to see connections among ideas and con cepts that may not be apparent at first \nglance, and the currency of information. With the autonomy given to learners, they will also need to be able \nto differentiate relevant from irrelevant information, integrate  ideas from diverse opinions, and make \ndecisions. \n \nIn the above examples, the researchers did not use CHAT explicitly in their analyses. The post-hoc analyses \npresented above serve to illustrate how CHAT could be used as a lens to identify contradictions so as to \nreveal areas for improvement. If researchers scan the environment and look beyond the immediate research \ncommunity, they may find parallel communities that could inspire new ways of learning with computers. \nOne example is learning with computers involving the emotions of learning. The A merican Psychological \nAssociation (1997), in the proposed framework for school reform, listed several key learning principles that \nhighlighted the cognitive, social, and emotional factors of learning. Given the cognitive and social cognitive \ntools that hav e emerged, researchers could explore tools that support emotional factors. While much \nAustralasian Journal of Educational Technology, 2019, 35(2).   \n \n \n34 \neducational research has focus ed on the cognitive and social aspects of learning, research on emotional \ndevelopment among students is only slowly gaining traction (Weissberg, Durlak, Domitrovich, & Gullotta, \n2015). Research has shown that students do experience a range of emotions in academic settings (Pekrun, \nGoetz, Titz, & Perry, 2002), which could affect their motivation, learning strategies, cognitive resources, \nself-regulation, and academic achievement. Practically, neurotechnology, such as electroencephalography \n(EEG) devices, has been shown to be promising in assessing emotions by analysing the frequency bands of \ngamma, beta, alpha, theta, and delta (Hu et al., 2017) . Researchers have found the combination of gamma \nand alpha bands to be sensitive to valence and the arousal of emotions (Guzel Aydin, Kaya, & Guler, 2016). \nEEG signals can thus be used to collect emotions data from students. This opens the doors to assessing \nmoment-to-moment emotions, and the resulting data  can be applied in learning contexts. It can overcome \nthe methodological limitations of measuring students’ emotions by retrospective reporting and self -\nperception of emotional experience after an  instructional event is over. Wearable EEG devices (e.g., \nMUSE) can be used in an unobtrusive and non-threatening manner to collect emotions data in a continuous \nmanner. Potentially, the data can be captured in a way that enables students to monitor their own emotions \nin learning, as and when they are engaging in learning activities. Apostolidis and Stylianidis  (2014), for \nexample, suggested the design for a biofeedback system that could provide feedback on stress levels to \nstudents for their self -regulation in a learning context. This could lead to the development of an emotion \npartner tool in learning. \n \nConclusion: Insights into the evolution of learning with computers \n \nThis article set out to review the notion of learning with computers, epitomised by using computers as \ncognitive or mindtool s. A common theme in  using these tools is the fundamental idea of lear ning with \ncomputers, rather than learning from computers. A tool helps learners to achieve what they would otherwise \nbe unable to achieve (effect with technology), with the ultimate goal that they develop the competency \nwithout the aid of the computers (ef fect of technology). Underpinned by constructivist epistemology  \n(Bednar, Cunningham, Duffy, & Perry, 1992), such applications also help to develop agency in the learners. \nWith rapid advances in technologies such as CSCL tools and analytics, new affordances and roles of tools \nbecome possible (e.g., supporting collaboration and interactions). These changes are accompanied by \nchanges in underpinning theories, extending beyond constructivist theory to social -constructivist, social \ncultural theory, distributed cognition, and situated cognition. \n \nUsing CHAT as an analytical lens, insights into using computers as mindtools, cognitive tools, and social \ncognitive tools or social mindtools  could be generated. CHAT provides the framework and directs our \nattention to the critical components of activity systems, and how these components work in concert with \nunderlying motives. Consequently, the differences in activity systems can be clarified,  as summarised in \nTable 1. The activity systems for learning from computers are included in this comparison.  \n \nRevisiting M. C. Kim’s (2012) call to clarify the concept of cognitive tools, this paper article has shown \nthat the concept is indeed evolving. Th is is not surprising given that in knowledge creation enterprise like \neducational research communities, new concepts are always emerging. Even a socially agreed definition at \na certain point in time is subject to change and advancement. As the analyses presented in this article show, \nmindtools and cognitive tools, although similar in many ways, have emerged from different communities \nand are underpinned by different theories. In addition, the evolution of mindtools and cognitive tools to \nsocial mindtools or social cognitive tools and the melding into CSCL tools is seen as a progression of how \nnew knowledge develops. They share that the issues of interactions, dialogues, meaning making, and the \ndistributed nature of knowing are part of the research agenda in CSCL among many researchers.  \n \n  \nAustralasian Journal of Educational Technology, 2019, 35(2).   \n \n \n35 \nTable 1  \nMain differences in activity systems of computer-assisted instruction, computers as mindtools, computers \nas cognitive tools, and computers as social mindtools or social cognitive tools  \n Computer-\nassisted \ninstruction \nComputers as \nmindtools \nComputers as \ncognitive tools \nComputers as social \nmindtools or social \ncognitive tools \nUnderlying \nmotives and \nintended learning \noutcomes and  \nEffective \ndelivery and \nacquisition of \ncontent (content \nmastery) \nDevelop critical \nthinking through \nconstructivist \nlearning \nDevelop specific \nexpertise through \ncognitive \napprenticeship \nIntegrate social \ninteractions and \ncognitive thinking for \ncollaborative idea \nimprovement \nTools Computers \nmimic expert \ninstructors  \nComputers act as \nintellectual \nlearning \npartners; provide \nthe environment \nand store data. \nMostly general \ntools that work \nacross subject \ndomains \nComputers act as \nintellectual \nlearning partners; \nprovide the \nenvironment and \nstore data. Mainly \ndomain generic or \ndomain specific to \ndevelop specific \nexpertise. \nComputers act as \nintellectual learning \npartners; provide the \nenvironment and store \ndata. Could be general \ntools, domain generic \nor domain specific \ntools. Include support \nfor collaboration, \nrules or division of \nlabours \nCommunity  Teacher and \nstudents (using \ntools developed \nby others) \nTeacher and \nstudents (using \ntools developed \nby others) \nResearcher \ncommunity \nworking in \ntandem with \nexperts, teachers, \nand students \nResearcher \ncommunity working \nin tandem with \nexperts, teachers, and \nstudents \nUnderlying \ntheories \nObjectivist Constructivist \nlearning \nSocial \nconstructivist; \ndistributed \ncognition \nParticipatory learning; \ncommunity of \npractice; learning \nthrough knowledge \ncreation \n \nUsing CHAT as an analytical lens, this article contributes to the field by clarifying the nuanced differences \nbetween various applications of learning with computers, including the roles of tools, the distribution of \nroles among members, the overlapping activity systems involved in the innovation, and the underlying \ntheories and motives of the communities. Indeed, the various applications of learning with computers, rather \nthan from computers, have withstood the test of time over the past few decades. R ecent advancements in \ntechnologies offer new promis es, such as the use of learning analytics to  afford self- assessment \nopportunities, integration of various tools to provide hybrid learning environment s, and the possibility of \ndeveloping emotion tools for learning. This article has also proposed using CHAT  as the framework to \nanalyse the contradictions within and beyond an activity system, so that these contradictions can reveal \nopportunities for improvement or innovation. It is hoped that such as an approach will propel this line of \nresearch and development to a greater height. \n \nReferences \n \nAmerican Psychological Association. (1997). Learner-centred psychological principles: A framework for \nschool reform and redesign. Washington, DC: Center for Psychology in Schools and Education. \nApostolidis, H., & Stylianidia, P. (2014). Designing a mobile bio-feedback device to support learning \nactivities. In IMCL2014. Proceedings of the 2014 International Conference on Interactive Mobile \nCommunication Technologies and Learning (pp. 189–194). IEEE. \nhttps://doi.org/10.1109/IMCTL.2014.7011129 \nBednar, A. K., Cunningham, D., Duffy, T. M., & Perry, J. D. (1992). Theory into practice: How do we \nlink? In T. M. Duffy & D. H. Jonassen (Eds.), Constructivism and the technology of instruction: A \nconversation (pp. 17–34). Hillsdale, NJ: Lawrence Erlbaum Associates. \nAustralasian Journal of Educational Technology, 2019, 35(2).   \n \n \n36 \nBereiter, C., & Scardamalia, M. (1987). The psychology of written composition. Hillsdale, NJ: Lawrence \nErlbaum Associates. \nChen, B., Scardamalia, M., & Bereiter, C. (2015). Advancing knowledge: building discourse through \njudgments of promising ideas. International Journal of Computer-Supported Collaborative Learning, \n10(4), 345–366. https://doi.org/10.1007/s11412-015-9225-z \nCole, M., & Engeström, Y. (1993). A cultural-historical approach to distributed cognition. In G. Salomon \n(Ed.), Distributed cognition: Psychological and educational considerations (pp. 1–46). New York, \nNY: Cambridge University Press. \nDillenbourg, P., & Bétrancourt, M. (2006). Collaboration load. In J. Elen & R. E. Clark (Eds.), Handling \ncomplexity in learning environments: Research and theory (pp. 142–163). Amsterdam, The \nNetherlands: Elsevier. \nDownes, S. (2012). Connectivism and connective knowledge: Essays on meaning and learning network.  \nOttawa, Canada: National Research Council. Retrieved from \nhttps://oerknowledgecloud.org/sites/oerknowledgecloud.org/files/Connective_Knowledge -\n19May2012.pdf \nDuffy, T. M., & Jonassen, D. H. (Eds.). (1992). Constructivism and the technology of instruction: A \nconversation. Hillsdale, NJ: Lawrence Erlbaum Associates. \nEngeström, Y. (1987). Learning by expanding: An activity-theoretical approach to developmental \nresearch. Helsinki, Finland: Orienta-Konsultit. \nEngeström, Y. (1999). Communication, discourse and activity. The Communication Review, 3(1-2), 165–\n185. https://doi.org/10.1080/10714429909368577 \nEngeström, Y. (2001). Expansive learning at work: Toward an activity-theoretical conceptualization. \nJournal of Education and Work, 14(1), 133–156. https://doi.org/10.1080/13639080020028747 \nGuzel Aydin, S., Kaya, T., & Guler, H. (2016). Wavelet-based study of valence-arousal model of \nemotions on EEG signals with LabVIEW. Brain Inform, 3(2), 109–117. \nhttps://doi.org/10.1007/s40708-016-0031-9 \nHolt, G. R., & Morris, A. W. (1993). Activity theory and the analysis of organizations. Human \nOrganization, 52(1), 97–109. https://doi.org/10.17730/humo.52.1.u305r18277724374 \nHu, X., Yu, J., Song, M., Yu, C., Wang, F., Sun, P., … Zhang, D. (2017). EEG correlates of ten positive \nemotions. Frontier in Human Neuroscience, 11. https://doi.org/10.3389/fnhum.2017.00026 \nHwang, G.-J., Chu, H.-C., & Tsai, C.-C. (2011). A knowledge acquisition approach to developing \nmindtools for organizing and sharing differentiating knowledge in a ubiquitous learning environment. \nComputers & Education, 57(1), 1368–1377. https://doi.org/10.1016/j.compedu.2010.12.013 \nHwang, G.-J., Hung, P.-H., Chen, N.-S, Liu, G.-Z. (2014). Mindtool-assisted in-field learning (MAIL): \nAn advanced ubiquitous learning project in Taiwan. Educational Technology & Society , 17(2), 4–16. \nRetrieved from http://www.jstor.org/stable/jeductechsoci.17.2.4 \nHwang, G-J., Shi, Y-R., Chu, H-C. (2011). A concept map approach to developing collaborative \nMindtools for context-aware ubiquitous learning. British Journal of Educational Technology, 42 (5), \n778–789. https://doi.org/10.1111/j.1467-8535.2010.01102.x \nJanssen, J., & Bodemer, D. (2013). Coordinated computer-supported collaborative learning: Awareness \nand awareness tools. Educational Psychologist, 48(1), 40–55. \nhttps://doi.org/10.1080/00461520.2012.749153 \nJonassen, D. H. (1996). Computers in the classroom: Mindtools for critical thinking.  Columbus, OH: \nMerrill/Prentice Hall. \nJonassen, D. H. (2000). Computers as mindtools for schools: Engaging critical thinking (2nd ed.). Upper \nSaddle River, NJ: Prentice Hall. \nKim, B., & Reeves, T. (2007). Reframing research on learning with technology: In search of the meaning \nof cognitive tools. Instructional Science, 35(3), 207–256. https://doi.org/10.1007/s11251-006-9005-2 \nKim, M. C. (2012). Revisiting cognitive tools: Shifting the focus to tools-in-use. Educational Technology, \n52(4), 14–24. Retrieved from https://www-jstor-org.libproxy.nie.edu.sg/stable/44430054 \nKirschner, P., & Wopereis, I. G. J. H. (2003). Mindtools for teacher communities: a European \nperspective. Technology, Pedagogy and Education, 12(1), 105–124. \nhttps://doi.org/10.1080/14759390300200148 \nKommers, P. A. M., Jonassen, D. H., & Mayes, T. (Eds.). (1992). Cognitive tools for learning. Berlin, \nGermany: Springer. \nKozulin, A. (1986). The concept of activity in Soviet psychology: Vygotsky, his disciples and critics, \nAmerican Psychologist, 41, 264–274. https://doi.org/10.1037/0003-066X.41.3.264 \nAustralasian Journal of Educational Technology, 2019, 35(2).   \n \n \n37 \nLajoie, S. P. (Ed.). (2000). Computers as cognitive tools: No more walls. Mahwah, NJ: Lawrence \nErlbaum Associates. \nLajoie, S. P., & Derry, S. J. (Eds.). (1993). Computers as cognitive tools. Mahwah, NJ: Lawrence \nErlbaum Associates. \nLave, J., & Wenger, E. (1991): Situated learning: Legitimate peripheral participation. Cambridge, \nEngland: Cambridge University Press. \nLee, A. V. Y., & Tan, S. C. (2017a). Promising ideas for collective advancement of communal \nknowledge using temporal analytics and cluster analysis. Journal of Learning Analytics, 4(3), 76–101. \nhttps://doi.org/10.18608/jla.2017.43.5 \nLee, V. Y. A., & Tan, S. C. (2017b). Understanding idea flow: Applying learning analytics in discourse. \nLearning: Research & Practice, 3(1), 12–29. https://doi.org/10.1080/23735082.2017.1283437 \nLi, Y., Sun, J., & Sun, M. Y. (2018). Analysis of the development status and impact of MOOCs in \nAmerican higher education. Educational Sciences: Theory & Practice, 18(6), 3442–3448. \nhttps://doi.org/10.12738/estp.2018.6.251 \nNovak, J. D., & Gowin, D. B. (1984). Learning how to learn. New York, NY: Cambridge University \nPress. \nNuutinen, J., Sutinen, E., Botha, A., & Kommers, P. (2010). From mindtools to social mindtools: \nCollaborative writing with Woven Stories. British Journal of Educational Technology, 41(5), 753–\n775. https://doi.org/10.1111/j.1467-8535.2009.00973.x \nOshima, J., Oshima, R., & Matsuzawa, Y. (2012). Knowledge Building Discourse Explorer: A  social \nnetwork analysis application for knowledge building discourse. Educational Technology Research \nand Development, 60(5), 903–921. https://doi.org/10.1007/s11423-012-9265-2 \nPea. R. D. (1985). Beyond amplification: Using the computer to reorganize mental functioning. \nEducational Psychologist, 20, 167–182. https://doi.org/10.1207/s15326985ep2004 \nPea, R. D. (1993). Practices of distributed intelligences and design for education. In G. Solomon (Ed.), \nDistributed cognitions: Psychological and educational considerations (pp. 47–87). Cambridge, \nEngland: Cambridge University Press. \nPekrun, R., Goetz, T., Titz, W., & Perry, R. P. (2002). Academic emotions in students’ self -regulated \nlearning and achievement: A program of qualitative and quantitative research. Educational \nPsychologist, 37, 91–106. https://doi.org/10.1207/S15326985EP3702_4 \nPerkins, D. N. (1985). The fingertip effects: How information-processing technology shapes thinking. \nEducational Researcher, 14(7), 11–17. https://doi.org/10.3102/0013189X014007011 \nReusser, K. (1993). Tutoring systems and pedagogical theory: Representational tools for understanding, \nplanning and reflection in problem solving. In S. P. Lajoie & S. J. Derry (Eds.), Computer as \ncognitive tools (pp. 143–178). Hillsdale, NJ: Lawrence Erlbaum Associates. \nRoschelle, J., & Teasley, S. (1995). The construction of shared knowledge in collaborative problem \nsolving. In C. O’Malley (Ed.), Computer-supported collaborative learning (pp. 69–197). Berlin, \nGermany: Springer Verlag. \nSalomon, G. (1993). On the nature of pedagogic computer tools: The case of Writing Partner. In S. P. \nLajoie & S. J. Derry (Eds.), Computer as cognitive tools (pp. 179–196). Hillsdale, NJ: Lawrence \nErlbaum Associates. \nSalomon, G., Perkins, D. N., & Globerson, T. (1991). Partners in cognition: Extending human \nintelligence with intelligent technologies. Educational Researcher, 20(3), 2–9. \nhttps://doi.org/10.3102/0013189X020003002\n \nScardamalia, M., & Bereiter, C. (1996). Computer support for knowledge-building communities. In T. \nKoschmann (Ed.), CSCL: Theory and practice of an emerging paradigm (pp. 249-268). Mahwah, NJ: \nLawrence Erlbaum Associates. \nScardamalia, M., & Bereiter, C. (2014). Knowledge building: Theory, pedagogy, and technology. In \nSawyer, R. K. (Ed.). The Cambridge handbook of the learning sciences (2nd ed., pp. 397–417). New \nYork, NY: Cambridge University Press. \nSfard, A. (1998). On two metaphors for learning and the dangers of choosing just one. Educational \nResearcher, 27(2), 4–13. https://doi.org/10.3102/0013189X027002004 \nSiemens, G. (2005). Connectivism: A learning theory for the digital age. International Journal of \nInstructional Technology and Distance Learning, 2(1), 3–10. \nhttps://doi.org/10.3109/0142159X.2016.1173661 \nStahl, G., Koschmann, T., & Suthers, D. (2015). Computer-supported collaborative learning. In Sawyer, \nR. K. (Ed.). The Cambridge handbook of the learning sciences (2nd ed., pp. 479–500). New York, \nNY: Cambridge University Press. \nAustralasian Journal of Educational Technology, 2019, 35(2).   \n \n \n38 \nSuri, H., & Clarke, D. (2009). Advancements in research synthesis methods: From a methodologically \ninclusive perspective. Review of Educational Research, 79(1), 359–430. \nhttps://doi.org/10.3102/0034654308326349 \nSweller, J. (2010). Element interactivity and intrinsic, extraneous and germane cognitive load. \nEducational Psychology Review, 22, 123–138. https://doi.org/10.1007/s10648-010-9128-5 \nTan, S. C., Chue, S., & Teo, C. L. (2016). Teacher learning in a professional learning community: \nPotential for a dual-layer knowledge building. In C. K. Looi, J. Polman, U. Cress, & P. Reimann \n(Eds.), Transforming Learning, Empowering Learners. Proceedings of the 12th International \nConference of the Learning Sciences (Vol. 1, pp. 178–185). Singapore: International Society of the \nLearning Sciences, Inc. Retrieved from \nhttps://www.isls.org/icls/2016/docs/ICLS2016_Volume_1_30June2016.pdf \nTan, A. L., & Tan, S. C. (2006). 'But I have not started teaching!': Knowledge building perils. In Y. J. \nLee, A. L. Tan, & B. T. Ho (Eds.), Proceedings of the International Science Education Conference \n(pp. 840–848). Singapore: National Institute of Education. \nTaylor, R. P. (Ed.). (1980). The computer in school: Tutor, tool, tutee. New York, NY: Teachers College \nPress. \nVygotsky, L. (1978). Mind in society: The development of higher psychological processes . Cambridge, \nMA: Harvard University Press. \nWeissberg, R. P., Durlak, J. A., Domitrovich, C. E., & Gullotta, T. P. (2015). Social and emotional \nlearning: Past, present, and future. In J. A. Durlak, R. P. Weissberg, & T. P. Gullotta (Eds.), \nHandbook of social and emotional learning: Research and practice (pp. 3–19). New York, NY: \nGuilford. \nWells, G. (1999). Dialogic inquiry: Toward a sociocultural practice and theory of education. Cambridge, \nEngland: Cambridge University Press. \nZhang, J., Tao, D., Chen, M.-H., Sun, Y., Judson, D., & Naqvi, S. (2018). Co-organizing the collective \njourney of inquiry with Idea Thread Mapper. Journal of the Learning Sciences , 27(3), 390–430. \nhttps://doi.org/10.1080/10508406.2018.1444992\n \n \n \nCorresponding author: Seng-Chee Tan, sengchee.tan@nie.edu.sg\n \n \nPlease cite as: Tan, S. C. (2019). Learning with computers: Generating insights into the development of \ncognitive tools using cultural historical activity theory. Australasian Journal of Educational \nTechnology, 35(2), 25–38. https://doi.org/10.14742/ajet.4848\n "
}