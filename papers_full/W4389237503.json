{
    "title": "Scalable Incident Detection via Natural Language Processing and Probabilistic Language Models",
    "url": "https://openalex.org/W4389237503",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A5064356374",
            "name": "Colin G. Walsh",
            "affiliations": [
                "Vanderbilt University Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A5065870778",
            "name": "Drew Wilimitis",
            "affiliations": [
                "Vanderbilt University Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A5011155701",
            "name": "Qingxia Chen",
            "affiliations": [
                "Vanderbilt University Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A5084108623",
            "name": "Aileen P. Wright",
            "affiliations": [
                "Vanderbilt University Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A5063777845",
            "name": "Jhansi Kolli",
            "affiliations": [
                "Vanderbilt University Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A5091688910",
            "name": "Katelyn Robinson",
            "affiliations": [
                "Vanderbilt University Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A5037204536",
            "name": "Michael Ripperger",
            "affiliations": [
                "Vanderbilt University Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A5051551743",
            "name": "Kevin B. Johnson",
            "affiliations": [
                "University of Pennsylvania"
            ]
        },
        {
            "id": "https://openalex.org/A5041212198",
            "name": "David Carrell",
            "affiliations": [
                "Kaiser Permanente Washington Health Research Institute"
            ]
        },
        {
            "id": "https://openalex.org/A5009688412",
            "name": "Rishi Desai",
            "affiliations": [
                "Pharmac",
                "Brigham and Women's Hospital",
                "Harvard University"
            ]
        },
        {
            "id": "https://openalex.org/A5047552324",
            "name": "Andrew D. Mosholder",
            "affiliations": [
                "Food and Drug Administration",
                "Center for Drug Evaluation and Research"
            ]
        },
        {
            "id": "https://openalex.org/A5078385822",
            "name": "Sai Dharmarajan",
            "affiliations": [
                "Food and Drug Administration",
                "Center for Drug Evaluation and Research"
            ]
        },
        {
            "id": "https://openalex.org/A5026537297",
            "name": "Sruthi Adimadhyam",
            "affiliations": [
                "Harvard Pilgrim Health Care",
                "Harvard University"
            ]
        },
        {
            "id": "https://openalex.org/A5029954233",
            "name": "Daniel Fabbri",
            "affiliations": [
                "Vanderbilt University Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A5102905653",
            "name": "Danijela Stojanović",
            "affiliations": [
                "Food and Drug Administration",
                "Center for Drug Evaluation and Research"
            ]
        },
        {
            "id": "https://openalex.org/A5011689338",
            "name": "Michael E. Matheny",
            "affiliations": [
                "Vanderbilt University Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A5054117089",
            "name": "Cosmin A. Bejan",
            "affiliations": [
                "Vanderbilt University Medical Center"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2209559096",
        "https://openalex.org/W2092970016",
        "https://openalex.org/W1554437664",
        "https://openalex.org/W2902452806",
        "https://openalex.org/W2916722198",
        "https://openalex.org/W2910326837",
        "https://openalex.org/W2984942011",
        "https://openalex.org/W2283198404",
        "https://openalex.org/W116606925",
        "https://openalex.org/W3048905614",
        "https://openalex.org/W2074289946",
        "https://openalex.org/W2996216496",
        "https://openalex.org/W4220726160",
        "https://openalex.org/W3017277899",
        "https://openalex.org/W3183848791",
        "https://openalex.org/W2137407193",
        "https://openalex.org/W3119911952",
        "https://openalex.org/W2966351171",
        "https://openalex.org/W2169275665",
        "https://openalex.org/W2729968666",
        "https://openalex.org/W2972879529",
        "https://openalex.org/W4200121889",
        "https://openalex.org/W4308184843",
        "https://openalex.org/W4294992665",
        "https://openalex.org/W2120411377",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W2984989671",
        "https://openalex.org/W2972207715",
        "https://openalex.org/W4324284865",
        "https://openalex.org/W2980023705",
        "https://openalex.org/W3191085759",
        "https://openalex.org/W3087670258",
        "https://openalex.org/W2980913398",
        "https://openalex.org/W4205661472",
        "https://openalex.org/W2149269919",
        "https://openalex.org/W3102251128"
    ],
    "abstract": "Abstract Post marketing safety surveillance depends in part on the ability to detect concerning clinical events at scale. Spontaneous reporting might be an effective component of safety surveillance, but it requires awareness and understanding among healthcare professionals to achieve its potential. Reliance on readily available structured data such as diagnostic codes risk under-coding and imprecision. Clinical textual data might bridge these gaps, and natural language processing (NLP) has been shown to aid in scalable phenotyping across healthcare records in multiple clinical domains. In this study, we developed and validated a novel incident phenotyping approach using unstructured clinical textual data agnostic to Electronic Health Record (EHR) and note type. It’s based on a published, validated approach (PheRe) used to ascertain social determinants of health and suicidality across entire healthcare records. To demonstrate generalizability, we validated this approach on two separate phenotypes that share common challenges with respect to accurate ascertainment: 1) suicide attempt; 2) sleep-related behaviors. With samples of 89,428 records and 35,863 records for suicide attempt and sleep-related behaviors, respectively, we conducted silver standard (diagnostic coding) and gold standard (manual chart review) validation. We showed Area Under the Precision-Recall Curve of ∼ 0.77 (95% CI 0.75-0.78) for suicide attempt and AUPR ∼ 0.31 (95% CI 0.28-0.34) for sleep-related behaviors. We also evaluated performance by coded race and demonstrated differences in performance by race were dissimilar across phenotypes and require algorithmovigilance and debiasing prior to implementation.",
    "full_text": "1 \n \nScalable Incident Detection via Natural Language Processing and Probabilistic Language \nModels \n \n \nColin G. Walsh,1,2,3 Drew Wilimitis,1 Qingxia Chen,1,2 Aileen Wright,1 Jhansi Kolli,1 Katelyn \nRobinson,1 Michael A. Ripperger,1 Kevin B. Johnson,6,7,8 David Carrell,9 Rishi J. Desai,10 Andrew \nMosholder,4,5 Sai Dharmarajan,4,12 Sruthi Adimadhyam,11 Daniel Fabbri,1 Danijela Stojanovic,4,5  \nMichael E. Matheny,1 Cosmin A. Bejan1 \n \nAffiliations:  \n1Department of Biomedical Informatics, Vanderbilt University Medical Center, Nashville, TN, \nUSA \n2Department of Medicine, Vanderbilt University Medical Center, Nashville, TN, USA \n3Department of Psychiatry and Behavioral Sciences, Vanderbilt University Medical Center, \nNashville, TN, USA \n4Center for Drug Evaluation and Research, Food and Drug Administration \n5Office of Surveillance and Epidemiology, Food and Drug Administration \n6Department of Biostatistics, Epidemiology and Informatics, and Pediatrics, University of \nPennsylvania \n7Department of Computer and Information Science, Bioengineering, University of Pennsylvania \n8Department of Science Communication, University of Pennsylvania \n9Washington Health Research Institute, Kaiser Permanente Washington \n10Division of Pharmacoepidemiology and Pharmacoeconomics, Department of Medicine, \nBrigham and Women’s Hospital/Harvard Medical School \n11Department of Population Medicine, Harvard Medical School and Harvard Pilgrim Health Care \nInstitute \n12Office of Translational Science, Food and Drug Administration \n \nCorresponding Author: Colin G. Walsh \n \n  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\n2 \n \nAbstract \nPost marketing safety surveillance depends in part on the ability to detect concerning clinical \nevents at scale. Spontaneous reporting might be an effective component of safety surveillance, \nbut it requires awareness and understanding among healthcare professionals to achieve its \npotential. Reliance on readily available structured data such as diagnostic codes risk under-\ncoding and imprecision. Clinical textual data might bridge these gaps, and natural language \nprocessing (NLP) has been shown to aid in scalable phenotyping across healthcare records in \nmultiple clinical domains. In this study, we developed and validated a novel incident \nphenotyping approach using unstructured clinical textual data agnostic to Electronic Health \nRecord (EHR) and note type. It’s based on a published, validated approach (PheRe) used to \nascertain social determinants of health and suicidality across entire healthcare records. To \ndemonstrate generalizability, we validated this approach on two separate phenotypes that \nshare common challenges with respect to accurate ascertainment: 1) suicide attempt; 2) sleep-\nrelated behaviors. With samples of 89,428 records and 35,863 records for suicide attempt and \nsleep-related behaviors, respectively, we conducted silver standard (diagnostic coding) and gold \nstandard (manual chart review) validation. We showed Area Under the Precision-Recall Curve \nof ~ 0.77 (95% CI 0.75-0.78) for suicide attempt and AUPR ~ 0.31 (95% CI 0.28-0.34) for sleep-\nrelated behaviors. We also evaluated performance by coded race and demonstrated \ndifferences in performance by race were dissimilar across phenotypes and require \nalgorithmovigilance and debiasing prior to implementation.  \n \n \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n3 \n \n \nBackground \nIncident detection refers to identifying new occurrence of relevant events from existing data \nassets and systems. Clinical examples of incident events include myocardial infarction, overdose \nfrom substance use, or suicide attempt. Precise detection at enterprise- or system-scale from \nhealthcare records remains a major challenge. Once a product is Food and Drugs \nAdministration (FDA) approved, post marketing safety surveillance for this medication includes \nboth active processes like Sentinel and passive processes like the FDA Adverse Event Reporting \nSystem (FAERS).1–4 Identifying adverse drug events (ADEs) or new onset diseases that might \nrelate to those new medications remains paramount.5,6 Outside of FDA regulatory processes, \npopulation health requires ascertainment of clinical incidents to allocate resources and \nproperly support frontline staff, e.g., at triage in emergency settings.7 Precision medicine and \npredictive modeling initiatives (e.g., Clinical Decision Support [CDS]) also depend strongly on \ncomprehensive ascertainment of phenotypes across biobanks and healthcare data repositories \nto power studies appropriately and minimize type I error.8,9 \nSignificant attention has been given in guiding processes around reporting in post market \nsurveillance,10 but gaps remain. Spontaneous reporting might be effective but requires \nawareness and understanding among healthcare professionals.11 It also has known limitations \nincluding under-reporting, duplication, and vulnerability to media attention or other trends in \nreporting such as sampling variation and errors or bias in reporting.12 Novel systems that \nleverage computational automation to achieve scalability might improve incident detection in \nhealthcare broadly and post market surveillance specifically. \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n4 \n \nAnother challenge for incident detection relates to the ability to determine whether the event \nstarted in the past, or prevalent, or whether it is a new occurrence, or incident. Many prevalent \nchronic conditions might have acute incident exacerbations, e.g., chronic obstructive \npulmonary disease exacerbations, or be punctuated by incident clinical events, e.g., suicide \nattempts. Even when structured diagnostic codes exist for such events, differentiating whether \nthose codes describe a new incident remains difficult. Current incident detection systems \ndepend on structured data though efforts to expand inputs to unstructured data are \nunderway.13 Coding data are driven by billing processes and are prioritized by clinical relevance \nand reimbursement rates. Codes are often linked to conduct of procedures or diagnostic \ntesting, are not deterministic for the coded condition, and still might not always captured.14–16 \nRestrictions or rules in patients’ insurance that impact coding practices may also complicate \nincident assessment. \nTemporality stands as another major obstacle to accurate incident detection.17 Many events \nhave sequelae that result in similar or identical new data inputs.18–20 Sequencing healthcare \nevents or, more importantly, evaluating potential causal links depends on establishing temporal \norder. Further, healthcare data might be recorded for a given patient at a later date (e.g., \nclinical documentation after billing) or outside of a “healthcare encounter”, as defined by most \nmajor vendor Electronic Health Records (EHRs).  \nA final challenge – most open healthcare systems do not have broad interoperability or data \nsharing to enable incident detection. Efforts to ameliorate this concern include national or \npayor systems, e.g., Veterans Health Administration or Kaiser Permanente, state-supported \ninteroperability, e.g., New York’s Healthix,21,22 and vendor-led tools for common users of EHRs, \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n5 \n \ne.g., EPIC Systems CareEverywhere. But while a patient suffering, e.g., a myocardial infarction \n(MI), at one health system might not have billing codes recorded in EHRs at another, that \npatient or their family would likely report the event to providers of care in another health \nsystem to ensure optimal clinical decision-making and healthcare communication. However, \nwhile providers are expected to obtain and summarize relevant patient care leading up to an \nencounter or interaction, structured codes from prior care are not generally imported. A \nsummary of outside care might be reliably documented in unstructured clinical text in the \nroutine practice of medicine.   \nNatural language processing (NLP) permits extraction and detection of incidents from \nunstructured textual data, and has been used in event detection and disease onset before.16,19 \nIt has also been applied to accurately identify social determinants of health to better \nunderstand the prevalence of these problems both within23 and across24 health systems \nincluding in FDA-linked initiatives like Sentinel.25,26 In work motivating this study, NLP has been \napplied to suicidal ideation and suicide attempt yielding accurate and precise ascertainment \nfrom unstructured text data agnostic to source data or EHR.27   \nTo improve scalable incident detection using unstructured healthcare data, we developed and \nvalidated a novel incident phenotyping approach using unstructured clinical textual data \nagnostic to EHR and note type. It’s based on a published, validated approach used to ascertain \nsocial determinants of health and suicidality across entire healthcare records (prevalence). To \ndemonstrate generalizability, we validated this approach on two separate phenotypes that \nshare common challenges with respect to accurate ascertainment: 1) suicide attempt; 2) sleep-\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n6 \n \nrelated behaviors. They have the additional rationale that identifying them might warrant \nfurther investigation and/or have regulatory relevance. \n \nMethods \nCohort generation \nData were extracted from the Vanderbilt Research Derivative, an EHR repository including \nProtected Health Information (PHI), for those receiving care at Vanderbilt University Medical \nCenter (VUMC).28 PHI were necessary to link to ongoing operational efforts to predict and \nprevent suicide pursuant to the suicidality phenotypic work here.29,30 Patient records were \nconsidered for years ranging from 1998 to 2022. For both suicide attempt and sleep-related \nbehaviors, we focused on adult patients aged over 18 years at the time of healthcare \nencounters with any clinical narrative data in the EHR.  \nWhile the technical details of the Phenotypic Retrieval (PheRe) system adapted here have been \npublished elsewhere,23,27 the algorithm's retrieval method determined which records were \nincluded in this study. In brief, after query formulation to establish key terms for each \nphenotype (see \"Automatic extraction...\" below), this algorithm assigned scores to every adult \npatient record. To be included in this study, those records with any non-zero NLP score, i.e., any \nsingle term in the query lists, were included in subsequent analyses. \nPhenotype Definitions \nOur team has published extensively in the suicide informatics literature on developing, \nvalidating, and deploying scalable predictive models of suicide risk into practice. As a result, \nsuicide attempt was defined based on prior work using published diagnostic code sets for the \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n7 \n \nsilver standard27 and domain knowledge-driven definitions for the gold standard annotation \n(see below for details on both). \nFor sleep-related behaviors, our team reviewed the literature on methods to ascertain such \nbehaviors from structured diagnostic codes. We also consulted with clinical experts in sleep-\nrelated behaviors and sleep disorders in the Department of Otolaryngology at VUMC (see \nAcknowledgement). This expertise informed both the silver and gold standards for this \nphenotype. These standards will be detailed below; in brief, the silver standard was \nhypothesized to be less specific and less rigorous a performance test than the gold standard yet \neasier to implement since it relied on structured data. \nTemporality \nA major difference between our prior published NLP to ascertain phenotypes from EHRs relates \nto prevalence versus incidence.23 In prior work, we applied NLP to ascertain evidence of any \nsuicide attempt or record of suicidal ideation from EHRs across entire healthcare records.27 In \nthis work, the intent was to ascertain evidence of new, clinically distinct incidents of these \nphenotypes. The team discussed numerous potential temporal windows to focus the NLP \nincluding: i) healthcare visit episodes; ii) set time-windows, e.g., twenty-four-hour periods; iii) \ncombinations of those two, e.g., clinical episodes plus/minus a time-window to capture \ndocumentation lag.  \nAfter discussion and preliminary analyses, we selected a twenty-four-hour period, midnight to \nthe next midnight,  as the window for this incident detection NLP approach. This window was \nchosen for clinical utility, simplicity, and agnosticism to vendor EHR or documentation schema. \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n8 \n \nOperationally, this meant that we considered all the notes of a patient on a given day to encode \na potential incident phenotype. \nAutomatic extraction of phenotypic profiles from clinical notes \nWe developed a data-driven method to extract relevant text expressions for each phenotype of \ninterest (see Figure 1). The method involved processing large collections of clinical notes from \nEHRs (including tokenization and extraction of n-gram representations such as unigrams and \nbigrams) and unsupervised training of Google’s word2vec31 and transformer-based NLP models \nsuch as Bidirectional Encoder Representations from Transformers (BERT)32 to learn context-\nindependent and context-sensitive word embeddings. The extraction of phenotypic profiles \nconsisted of iteratively expanding an initial set of high-relevant expressions (also called ‘seeds’) \nsuch as ‘suicide’ as follows. First, we ranked the learned embeddings by their similarity to the \nseed embeddings. Then, we manually reviewed the top ranked expressions and selected the \nrelevant ones as new seed expressions. The final sets of text expressions corresponding to each \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n9 \n \nphenotype of interest are listed in eSupplement. \n \nFigure 1: Overview of Automatic Extraction Process Enabling Incident Detection, Steps Numbered and Legend Shown \nLarge-scale retrieval of incident phenotypes \nWe implemented a search engine to identify incident phenotypes in all the notes from the \nVanderbilt Research Derivative and to rank them by relevance to their profile. In this context, \neach phenotypic profile corresponds to an input query for the search engine while each meta-\ndocument comprising of all the notes of a patient on a given day encodes a potential incident \nphenotype. In the implementation framework, we represented the meta-documents and input \nqueries as multidimensional vectors, where each vector element is associated with a single- or \nmulti-word expression from their corresponding phenotypic profile. The relevance of a patient \nmeta-document to a phenotype was measured as the similarity between their meta-document \nand input query vectors using the standard term frequency-inverse document frequency (TF-\nIDF) weighted cosine metric. The final NLP-based score was a continuous value ranging from \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n10 \n \nlow single digits (< 10) to hundreds (< 500 typically). Higher scores indicated more similarity and \ntherefore more evidence of the phenotype. \nTo further improve the performance of our search engine, we performed query reformulation \nbased on relevance feedback by iterative assessment of the top 20 retrieved incident \nphenotypes of each run.23 The selection and ranking of the incident phenotypes was performed \nusing the Phenotype Retrieval (PheRe) software package in Java, which is available at \nhttps://github.com/bejanlab/PheRe.git. \nSilver standard generation \nA silver standard represents a source of truth that might be less precise or more error-prone \nthan ground truth, a gold standard. An advantage to silver standards remains their relative \nefficiency to generate and validate compared to more labor-intensive gold standards. To \ngenerate silver standards for sample size calculations for all phenotypes, we used ICD9CM \n(Clinical Modification) and ICD10CM diagnostic code sets to generate preliminary performance \nfor the NLP to identify presence/absence of structured phenotypic data (i.e., International \nClassification of Disease [ICD] codes).33 For suicide attempt, we used validated code sets from \npublished literature.29,34 For sleep-related behaviors, we reviewed the literature and adapted \ncode sets from the literature with clinical experts in Sleep Medicine at VUMC. Codesets for all \nphenotypes used in this project are available in the eSupplement.  \nTo evaluate preliminary performance, we used presence/absence of a single ICD code from the \nvalidated lists within thirty days of the date of NLP score calculation as a positive label (label = \n1) and the absence as a negative label (label = 0). Thirty days was chosen as a common time \nperiod in which clinical risk is close enough to warrant documentation and intervention but not \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n11 \n \nso close as to be imminent and required emergent care. The continuous NLP scores were a \nunivariate ‘predictor’ of presence/absence. Performance was measured with typical \ninformation retrieval and model discrimination metrics: Area Under the Receiver Operating \nCharacteristic (AUROC), Precision (P), Recall (R), P-R Curves, and F-measures (F1-score). \nGold standard generation \nThe intent in gold standard generation was to generate corpora of charts across all NLP score \nbins (e.g., NLP scores from 5-10, 10-15, 15-20, …) to evaluate performance of the NLP incident \ndetection system. Unlike top-K precision used in information retrieval, we sought insight into \nperformance with confidence intervals across score spectra to plan for downstream CDS \napplications. \n \nFor sample size calculation, we used preliminary performance from the silver standards to \ncalculate numbers of chart-days to extract for multi reviewer chart validation. The rationale for \nthis key step was the need for 1) efficient chart review within a selected marginal error and 2) \nintent to understand NLP performance for all possible scores - not simply performance in the \nhighest ranked charts, aka \"top-K\" performance typical in this literature where K is some \nfeasible number of highly ranked records, e.g., K=200. To determine the number of encounters \nfor chart review, we used the marginal error method which involves the half-width of the 95% \nconfidence interval for the performance metrics in the investigated cohort. The process \ninvolved the following steps: (1) dividing the predicted risk scores into 5-point intervals and \ncalculating the number of encounters in each interval; (2) estimating the precision and recall for \neach interval using ICD9/ICD10 codes; and (3) computing the sample size by setting the \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n12 \n \nmarginal error for the probability estimate in the individual interval to 0.05. We assumed that \nthe number of positive encounters selected for chart review approximates a normal \ndistribution and follows a hypergeometric distribution. The larger sample size between the \ncalculated sample sizes for precision and recall estimates determines the required sample size \nfor chart review. \nTo conduct chart review, annotation guides were developed and revised after initial chart \nvalidation training (fifty chart-days for each phenotype). These guides included instruction on \nlabeling and factors contributing to label decisions. All reviewers (K.R., J.K., C.W. [adjudicator]) \nwere trained on the required annotation and participated in a Training phase using fifty chart-\nday examples for each phenotype. Chart labels included: Positive – phenotype documented in \nnotes “reports suicidal ideation”; Negative - phenotype documented as not present, e.g., \n“denied suicidal ideation”; Unknown – insufficient evidence to determine labels. In subsequent \nanalysis after the third reviewer adjudicated disagreement and unknown labels, these three \nlabels were collapsed into two: Positive; Negative. Annotation guides are available as \neSupplements. \nEvaluation Metrics \nMetrics to evaluate NLP performance mirrored those used in preliminary analyses above \nincluding P-R Metrics and curves; F1-score. We also calculated error by score bin to understand \nhow well the NLP score performed across all thresholds. The intent was to replicate a common \nclinical implementation challenge – discretizing a continuous output from an algorithm into a \nbinary event, e.g., a decision or an intervention that cannot be discretized in practice. \nResults \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n13 \n \nBaseline patient characteristics by phenotype \nAcross both suicide attempt and sleep-related behaviors, the study cohorts included 89,428 and \n35,863 patients, respectively. As outlined in Cohort generation above, these numbers included \nany records with at least one query term match in the day of notes for that patient. Baseline \nstudy characteristics at each patient's first documented visit are shown (Table 1). \nCharacteristic Suicide Attempt \nPhenotype  \nSleep-related Behaviors \nPhenotype (N, %) \nTotal Individuals 89,428 35,863 \nAge, median, years 43.2 (95% CI 43, 43.4) 57.7 (95% CI 57.5, 57.9) \nSex at birth, coded in EHR \nWoman \nMan \nUnknown \n \n                  N                     % \n      52,386                    58.6 \n       37,003                   41.4 \n                 9                    <1 \n \n                  N                     % \n       18,850                52.6 \n       17,007                47.4 \n                 6                    <1 \n \nRace, coded in EHR  \nWhite \nBlack \nUnknown  \nAsian \nOther* \nAlaskan/Native American \n \n*Other includes all combinations \nof coded race categories and a \ndistinct category labeled \"Other\" \nin source EHR documentation \n \n \n                   N                     % \n71113 79.5 \n11173 12.5 \n4329 4.8 \n1756 2.0 \n901 1.0 \n156 0.2 \n \n                   N                    %  \n28719 80.1 \n4341 12.1 \n1880 5.2 \n446 1.2 \n414 1.2 \n63 0.2 \n \nEthnicity, coded in EHR  \nNon-Hispanic/Latinx \nHispanic/Latinx \nUnknown  \n \n                  N                     % \n       80,698                90.2 \n         2,564                  2.9 \n         6,166                  6.9 \n \n                  N                     % \n       32,832                91.5 \n             692                  1.9 \n         2,339                   6.5  \n \nTable 1: Baseline Study Characteristics \nSilver standard performance (diagnostic code classification) \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n14 \n \nFrom prior work and multiple validation studies of the silver standard diagnostic coding for \nsuicide attempt, we used 58% PPV for ICD9 and 85% for ICD10 versions of these codes as the \ninitial benchmarks.  \nFor sleep-related behaviors, we had no similar benchmarks from prior work or the published \nliterature. Using the presence of an ICD9 or ICD10 code for sleep-related behaviors, we note \nthe NLP algorithm had a PPV of 60% to predict the silver standard and establish a benchmark \nfor sample size calculation and chart review.  \nGold standard performance (chart validation) \nPrecision-recall performances of the NLP incident detection systems are shown including \nAUPR~ 0.77 (95% CI 0.75-0.78) for suicide attempt and AUPR ~ 0.31 (95% CI 0.28-0.34) for \nsleep-related behaviors.  \nP-R curves are shown with respect to coded race and smaller differences are noted for suicide \nattempt by coded race compared to sleep-related behaviors (Figure 2). Notably, the confidence \nintervals in the legend also overlap for both phenotypes (Figure 3).  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n15 \n \n \nFigure 2: Precision-Recall of Suicide Attempt NLP Incident Detection by coded race\n \nFigure 3: Precision-Recall of Sleep-related Behaviors NLP Incident Detection by coded race \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n16 \n \nThreshold Selection, Steps toward Implementation \nSelecting a threshold for a hypothetical implementation where precision matters more than \nrecall, we use the maximum F1-score. For suicide attempt NLP-based detection, for example, \nand our overall P-R performance above, an NLP score of 25 and higher would have an F1-score \nof 0.75 associated with a recall of 0.93 and a precision of 0.63.  \nSimilarly calculated for sleep-related behaviors, the optimal F1-score-based threshold is 35 or \nabove in which the F1-score would be 0.42, precision 0.33, recall 0.57. We note that this score, \nwhile the optimal model performance, might not represent an acceptable or optimal \nperformance for specific applications e.g., defining an endpoint of interest in medical product \nsafety surveillance. \nDiscussion \nIn this study, an NLP-based incident detection system was developed and validated across two \nchallenging and disparate phenotypes. Such detection was feasible to conduct using a twenty-\nfour-hour period of documentation, agnostic to EHR architecture or data standard, or to \nunderlying textual source systems. The implications of this system for initiatives like FDA \nSentinel indicate scalable detection would be achievable with appropriate evaluation and \nmilestones in the implementation path. For example, in these two phenotypes, gold standard \nmanual chart review was necessary and would remain necessary for novel phenotypes on a \nsubset of charts in development sites. But here as in many phenotypic examples, prior work \nfacilitated the sample size calculation and chart review itself.  Moreover, silver standard \nvalidation permitted efficient sample size calculation and error estimation across all possible \nNLP scores, not solely those highest ranked \"top-K\" records as in traditional information \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n17 \n \nretrieval. Generally, teams experienced with these phenotypes would be well-suited to \ncontribute to evaluating their accuracy before deployment. Even with imperfect coded race \nvariables, performance differences were easily identifiable here. Algorithmovigilance35 to \nperpetuating or worsening disparities remains paramount in the evolution of systems like this \none – not solely at initial algorithm validation but throughout the life cycle.36  \nPerformance varied by phenotype with better performance with a phenotype that was more \ncommon and with a clearly defined clinically observable set of attributes in suicide attempt, \nthough it remains challenging as a common label for a clinical event that takes many different \nforms at the individual level. Sleep-related behaviors, even when focused on sleepwalking, -\neating, -driving, are still a group of diagnoses that may or may not be documented clearly in \nevery visit even when present. That is, these selected phenotypes differ in clinical specificity \nand in the degree to which care will focus on them if observed. However, both might be \nassociated with regulatory action if a new medication or device were shown to cause them. \nIncidence rates of a target phenotype remain key factors informing the development of \npredictive models like these.  \nActive efforts including a recent National Academy of Science, Engineering, and Medicine \n(NASEM) report suggest excluding race from genetic and genomic studies.37 Race remains a \nsocial construct with potential to reflect or worsen healthcare disparities if not handled \nappropriately. Use of clinical language does vary by race and this usage remains an important \nlimitation of studies like this one. Here, coded race was used as a means of testing these NLP \nalgorithms for disparate performance as an early checkpoint in model validation. Our findings \nare hypothesis-generating with respect to reasons for performance differences and more \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n18 \n \ndetailed analyses with better quality race data are indicated in any case. A parallel effort in \nreplicating an approach like this one in new phenotypes would necessitate careful \nconsideration of factors like demographics, clinical attributes or other that might undermine \nthe successes of an incident detection system at scale. \nSilver standard evaluation alone was not sufficient to estimate final NLP performance observed \nhere. Both sleep-related behaviors and suicide attempt were associated with ~ 60% PPV in \nsilver standard, ICD-based, performance but suicide attempt as a phenotype was much better \nidentified in this method than sleep-related behaviors. Thus, some manner of gold standard \nevaluation is indicated for adding new phenotypes to this system. To that end, annotation \nguides and annotator training facilitated rigorous multireviewer chart validation as did sample \nsize calculation of numbers of required charts to review based on the silver standard. \nThis work builds on the work of others by adding to understanding of unstructured data-based \nphenotyping algorithms in neuropsychiatric phenotypes with emphasis on temporality and \nincident detection. Determining temporal onset of symptoms with NLP has been attempted in \nclinical areas including psychosis,38 perinatal health,39 and hematology.40 Deep learning has \nbeen used with NLP-based features to identify acute on chronic exacerbations of chronic \ndiseases such as hypoglycemic events in diabetes.41 While phenotyping in suicidality has \nincluded NLP in numerous studies including those of this team, phenotyping in sleep disorders \nhas been less commonly reported.42,43 This study adds to evidence that sleep-related behaviors \nmight be less well-coded and well-documented than other neuropsychiatric phenotypes and \ntherefore NLP-based algorithms to detect them were more challenging to develop. \n \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n19 \n \nAcknowledgements \nOur team thanks Dr. David Kent in the Department of Otolaryngology at VUMC for expertise in \nsleep-related behaviors and insight into phenotypic definitions and acceptable silver standard \ndiagnostic codes used here. \nWe thank Dr. Patricia Bright for reviewing our manuscript prior to submission. \nFunding  \n \nAll investigators were supported on FDA WO2006. Dr. Walsh is also supported in part by NIMH \nR01MH121455 and R01MH116269. \n \nFunders played no role in design and conduct of the study; collection, management, analysis, \nand interpretation of the data; preparation, review, or approval of the manuscript; and decision \nto submit the manuscript for publication. \n \nAuthor Contributions: \nDesign and conduct of the study (all authors)  \nData collection, management, analysis (CW, DW, QC, CB) \nChart validation (JK, KR, CW) \nInterpretation of the data (all authors)  \nPreparation, review, or approval of the manuscript (all authors) \n  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n20 \n \nReferences \n1. Ball, R., Robb, M., Anderson, S. & Dal Pan, G. The FDA’s sentinel initiative—A \ncomprehensive approach to medical product surveillance. Clin. Pharmacol. Ther. 99, 265–\n268 (2016). \n2. Behrman, R. E. et al. Developing the Sentinel System — A National Resource for Evidence \nDevelopment. N. Engl. J. Med. 364, 498–499 (2011). \n3. Robb, M. A. et al. The US Food and Drug Administration’s Sentinel Initiative: Expanding the \nhorizons of medical product safety. Pharmacoepidemiol. Drug Saf. 21, 9–11 (2012). \n4. Platt, R. et al. The FDA Sentinel Initiative — An Evolving National Resource. N. Engl. J. Med. \n379, 2091–2093 (2018). \n5. Feng, C., Le, D. & McCoy, A. B. Using Electronic Health Records to Identify Adverse Drug \nEvents in Ambulatory Care: A Systematic Review. Appl. Clin. Inform. 10, 123–128 (2019). \n6. Liu, F., Jagannatha, A. & Yu, H. Towards Drug Safety Surveillance and Pharmacovigilance: \nCurrent Progress in Detecting Medication and Adverse Drug Events from Electronic Health \nRecords. Drug Saf. 42, 95–97 (2019). \n7. Fernandes, M. et al. Clinical Decision Support Systems for Triage in the Emergency \nDepartment using Intelligent Systems: a Review. Artif. Intell. Med. 102, 101762 (2020). \n8. Panahiazar, M., Taslimitehrani, V., Pereira, N. L. & Pathak, J. Using EHRs for Heart Failure \nTherapy Recommendation Using Multidimensional Patient Similarity Analytics. Stud. Health \nTechnol. Inform. 210, 369–373 (2015). \n9. Zhang, P., Wang, F., Hu, J. & Sorrentino, R. Towards personalized medicine: leveraging \npatient similarity and drug similarity analytics. AMIA Jt. Summits Transl. Sci. Proc. AMIA Jt. \nSummits Transl. Sci. 2014, 132–136 (2014). \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n21 \n \n10. Health, C. for D. and R. Postmarket Surveillance Under Section 522 of the Federal Food, \nDrug, and Cosmetic Act. U.S. Food and Drug Administration \nhttps://www.fda.gov/regulatory-information/search-fda-guidance-documents/postmarket-\nsurveillance-under-section-522-federal-food-drug-and-cosmetic-act (2022). \n11. Alomar, M., Tawfiq, A. M., Hassan, N. & Palaian, S. Post marketing surveillance of suspected \nadverse drug reactions through spontaneous reporting: current status, challenges and the \nfuture. Ther. Adv. Drug Saf. 11, 2042098620938595 (2020). \n12. Bate, A. & Evans, S. J. W. Quantitative signal detection using spontaneous ADR reporting. \nPharmacoepidemiol. Drug Saf. 18, 427–436 (2009). \n13. Methods | Sentinel Initiative. https://www.sentinelinitiative.org/methods-data-\ntools/methods. \n14. Banerji, A. et al. Natural Language Processing Combined with ICD-9-CM Codes as a Novel \nMethod to Study the Epidemiology of Allergic Drug Reactions. J. Allergy Clin. Immunol. \nPract. 8, 1032-1038.e1 (2020). \n15. Bayramli, I. et al. Predictive structured-unstructured interactions in EHR models: A case \nstudy of suicide prediction. NPJ Digit. Med. 5, 15 (2022). \n16. Borjali, A. et al. Natural language processing with deep learning for medical adverse event \ndetection from free-text medical narratives: A case study of detecting total hip replacement \ndislocation. Comput. Biol. Med. 129, 104140 (2021). \n17. Xie, F. et al. Deep learning for temporal data representation in electronic health records: A \nsystematic review of challenges and methodologies. J. Biomed. Inform. 126, 103980 (2022). \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n22 \n \n18. Sun, W., Rumshisky, A. & Uzuner, O. Evaluating temporal relations in clinical text: 2012 i2b2 \nChallenge. J. Am. Med. Inform. Assoc. 20, 806–813 (2013). \n19. Viani, N. et al. A natural language processing approach for identifying temporal disease \nonset information from mental healthcare text. Sci. Rep. 11, 757 (2021). \n20. Sheikhalishahi, S. et al. Natural Language Processing of Clinical Notes on Chronic Diseases: \nSystematic Review. JMIR Med. Inform. 7, e12239 (2019). \n21. Zech, J., Husk, G., Moore, T., Kuperman, G. J. & Shapiro, J. S. Identifying homelessness using \nhealth information exchange data. J. Am. Med. Inform. Assoc. JAMIA 22, 682–687 (2015). \n22. Moore, T. et al. Event detection: a clinical notification service on a health information \nexchange platform. AMIA Annu. Symp. Proc. AMIA Symp. 2012, 635–642 (2012). \n23. Bejan, C. A. et al. Mining 100 million notes to find homelessness and adverse childhood \nexperiences: 2 case studies of rare and severe social determinants of health in electronic \nhealth records. J. Am. Med. Inform. Assoc. JAMIA 25, 61–71 (2018). \n24. Dorr, D. et al. Identifying Patients with Significant Problems Related to Social Determinants \nof Health with Natural Language Processing. Stud. Health Technol. Inform. 264, 1456–1457 \n(2019). \n25. Desai, R. J. et al. Broadening the reach of the FDA Sentinel system: A roadmap for \nintegrating electronic health record data in a causal analysis framework. NPJ Digit. Med. 4, \n170 (2021). \n26. Carrell, D. S. et al. Improving Methods of Identifying Anaphylaxis for Medical Product Safety \nSurveillance Using Natural Language Processing and Machine Learning. Am. J. Epidemiol. \n192, 283–295 (2023). \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n23 \n \n27. Bejan, C. A. et al. Improving ascertainment of suicidal ideation and suicide attempt with \nnatural language processing. Sci. Rep. 12, 15146 (2022). \n28. Danciu, I. et al. Secondary use of clinical data: the Vanderbilt approach. J. Biomed. Inform. \n52, 28–35 (2014). \n29. Walsh, C. G. et al. Prospective Validation of an Electronic Health Record–Based, Real-Time \nSuicide Risk Model. JAMA Netw. Open 4, e211428 (2021). \n30. Wilimitis, D. et al. Integration of Face-to-Face Screening With Real-time Machine Learning \nto Predict Risk of Suicide Among Adults. JAMA Netw. Open 5, e2212095 (2022). \n31. Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S. & Dean, J. Distributed Representations of \nWords and Phrases and their Compositionality. in Advances in Neural Information \nProcessing Systems vol. 26 (Curran Associates, Inc., 2013). \n32. Devlin, J., Chang, M.-W., Lee, K. & Toutanova, K. BERT: Pre-training of Deep Bidirectional \nTransformers for Language Understanding. Preprint at \nhttps://doi.org/10.48550/arXiv.1810.04805 (2019). \n33. WHO | International Classification of Diseases. WHO \nhttp://www.who.int/classifications/icd/en/ (2017). \n34. Swain, R. S. et al. A systematic review of validated suicide outcome classification in \nobservational studies. Int. J. Epidemiol. 48, 1636–1649 (2019). \n35. Embi, P. J. Algorithmovigilance—Advancing Methods to Analyze and Monitor Artificial \nIntelligence–Driven Health Care for Effectiveness and Equity. JAMA Netw. Open 4, e214622 \n(2021). \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint \n24 \n \n36. Lenert, M. C., Matheny, M. E. & Walsh, C. G. Prognostic models will be victims of their own \nsuccess, unless…. J. Am. Med. Inform. Assoc. 26, 1645–1650 (2019). \n37. Using Population Descriptors in Genetics and Genomics Research: A New Framework for an \nEvolving Field. (National Academies Press, 2023). doi:10.17226/26902. \n38. Viani, N. et al. Annotating Temporal Relations to Determine the Onset of Psychosis \nSymptoms. Stud. Health Technol. Inform. 264, 418–422 (2019). \n39. Ayre, K. et al. Developing a Natural Language Processing tool to identify perinatal self-harm \nin electronic healthcare records. PloS One 16, e0253809 (2021). \n40. Fu, J. T., Sholle, E., Krichevsky, S., Scandura, J. & Campion, T. R. Extracting and classifying \ndiagnosis dates from clinical notes: A case study. J. Biomed. Inform. 110, 103569 (2020). \n41. Jin, Y., Li, F., Vimalananda, V. G. & Yu, H. Automatic Detection of Hypoglycemic Events from \nthe Electronic Health Record Notes of Diabetes Patients: Empirical Study. JMIR Med. Inform. \n7, e14340 (2019). \n42. Cade, B. E. et al. Sleep apnea phenotyping and relationship to disease in a large clinical \nbiobank. JAMIA Open 5, ooab117 (2022). \n43. Chen, W., Kowatch, R., Lin, S., Splaingard, M. & Huang, Y. Interactive Cohort Identification \nof Sleep Disorder Patients Using Natural Language Processing and i2b2. Appl. Clin. Inform. 6, \n345–363 (2015). \n \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted December 1, 2023. ; https://doi.org/10.1101/2023.11.30.23299249doi: medRxiv preprint "
}