{
  "title": "Emotion-Aware Transformer Encoder for Empathetic Dialogue Generation",
  "url": "https://openalex.org/W4205518380",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2229450605",
      "name": "Raman Goel",
      "affiliations": [
        "Delhi Technological University"
      ]
    },
    {
      "id": "https://openalex.org/A2302749399",
      "name": "Seba Susan",
      "affiliations": [
        "Delhi Technological University"
      ]
    },
    {
      "id": "https://openalex.org/A3157841942",
      "name": "Sachin Vashisht",
      "affiliations": [
        "Delhi Technological University"
      ]
    },
    {
      "id": "https://openalex.org/A3159379395",
      "name": "Armaan Dhanda",
      "affiliations": [
        "Delhi Technological University"
      ]
    },
    {
      "id": "https://openalex.org/A2229450605",
      "name": "Raman Goel",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2302749399",
      "name": "Seba Susan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3157841942",
      "name": "Sachin Vashisht",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3159379395",
      "name": "Armaan Dhanda",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W6601784809",
    "https://openalex.org/W2972557612",
    "https://openalex.org/W2963088785",
    "https://openalex.org/W2102953093",
    "https://openalex.org/W2158943324",
    "https://openalex.org/W2787186880",
    "https://openalex.org/W3093544698",
    "https://openalex.org/W3016547601",
    "https://openalex.org/W2793761508",
    "https://openalex.org/W2950242852",
    "https://openalex.org/W2146334809",
    "https://openalex.org/W2895615590",
    "https://openalex.org/W2952088495",
    "https://openalex.org/W2172140247",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2613904329",
    "https://openalex.org/W3009428740",
    "https://openalex.org/W2133564696",
    "https://openalex.org/W3119002294",
    "https://openalex.org/W1902237438",
    "https://openalex.org/W2911109671",
    "https://openalex.org/W2922256442",
    "https://openalex.org/W2998563994",
    "https://openalex.org/W3157556620",
    "https://openalex.org/W3037611961",
    "https://openalex.org/W6631190155",
    "https://openalex.org/W2941526521",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W2964199361",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2951583236",
    "https://openalex.org/W43346191",
    "https://openalex.org/W2936412271",
    "https://openalex.org/W2964110616",
    "https://openalex.org/W3003338281",
    "https://openalex.org/W3157299599",
    "https://openalex.org/W2963686995"
  ],
  "abstract": "Modern day conversational agents are trained to emulate the manner in which\\nhumans communicate. To emotionally bond with the user, these virtual agents\\nneed to be aware of the affective state of the user. Transformers are the\\nrecent state of the art in sequence-to-sequence learning that involves training\\nan encoder-decoder model with word embeddings from utterance-response pairs. We\\npropose an emotion-aware transformer encoder for capturing the emotional\\nquotient in the user utterance in order to generate human-like empathetic\\nresponses. The contributions of our paper are as follows: 1) An emotion\\ndetector module trained on the input utterances determines the affective state\\nof the user in the initial phase 2) A novel transformer encoder is proposed\\nthat adds and normalizes the word embedding with emotion embedding thereby\\nintegrating the semantic and affective aspects of the input utterance 3) The\\nencoder and decoder stacks belong to the Transformer-XL architecture which is\\nthe recent state of the art in language modeling. Experimentation on the\\nbenchmark Facebook AI empathetic dialogue dataset confirms the efficacy of our\\nmodel from the higher BLEU-4 scores achieved for the generated responses as\\ncompared to existing methods. Emotionally intelligent virtual agents are now a\\nreality and inclusion of affect as a modality in all human-machine interfaces\\nis foreseen in the immediate future.\\n",
  "full_text": "2021 9th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW) \nDOI: 10.1109/ACIIW52867.2021.9666315 \n \nEmotion-Aware Transformer Encoder for \nEmpathetic Dialogue Generation \nRaman Goel, Seba Susan, Sachin Vashisht and Armaan Dhanda  \nDepartment of Information Technology, Delhi Technological University,  \nNew Delhi, India-110042 \nseba_406@yahoo.in \nAbstract—Modern day conversational agents are trained to \nemulate the manner in which humans communicate. To \nemotionally bond with the user, these virtual agents need to be \naware of the affective state of the u ser. Transformer s are the \nrecent state of the art in sequence -to-sequence learning that \ninvolves training an encoder -decoder model with word \nembeddings from utterance-response pairs. We propose an \nemotion-aware transformer encoder for capturing the \nemotional quotient in the user utterance in order to generate \nhuman-like empathetic responses. The contributions of our \npaper are as follows: 1) An emotion detector module trained on \nthe input utterances determines the affective state of the user in \nthe initial phase 2) A novel transformer encoder is proposed that \nadds and normalizes the  word embedding with emotion \nembedding thereby integrating the semantic and affective \naspects of the input utterance 3) The encoder and decoder stacks \nbelong to the Transformer-XL architecture which is the recent \nstate of the art in language modeling. Experimentation on the \nbenchmark Facebook AI empathetic dialogue dataset confirms \nthe efficacy of our model from the higher BLEU -4 scores \nachieved for the generated responses as compar ed to existing \nmethods. Emotionally intelligent virtual agents are now a reality \nand inclusion of affect as a modality in all human -machine \ninterfaces is foreseen in the immediate future. \nIndex T erms—Transformer-XL, Empathetic dialogue  \ngeneration, Affective state, Encoder-decoder model \nI. INTRODUCTION \nVirtual assistants such as Cortana, Alexa and Siri, are now \nan integral part of modern life. Their services range from \nfacilitating simple financial transactions to conducting a \nfriendly conv ersation with the user. The latter is a more \nchallenging task since the virtual agent needs to emulate the \nmanner in which a human listener empathizes with the \nemotions of the speaker and generates an appropriate response \nthat syncs with  the emotional state of the speaker. To \nempathize with a human, the machine needs to be emotionally \nintelligent and needs to be trained on the emotion metadata \navailable in modern dialogue corpora.  \nVirtual conversational agents generally have at their core \na sequence -to-sequence (Seq2Seq) model trained on input -\noutput sentence pairs [1]. In order to generate an appropriate \nresponse to a user utterance, the contextual information in the \ninput sentence needs to be capture d [2]. Language and \nsequence modelling tasks require lon g-term dependencies to \nbe captured effectively from sequential data in order to make \nsense of the context and identify the meaning conveyed by the \nsentence. Practically, it is not possible to learn long -term \ndependencies from an infinitely long time window. Instead, \nthe effort is to learn a long dependency from a time-step that \nis as large as possible. Recurrent Neural Networks (RNN) \nsuch as  Long Short -Term Memory (LSTM ) [3]  and Gated \nRecurrent Unit (GRU) [4] capture long-term dependencies in \nsequential data. The standard vanilla RNN suffers from \nproblems like vanishing gradient and exploding gradient. \nDespite contributing to improvements in machine translation \ntasks, their performance dropped when the length of the input \nsentence is increased [4]. Attention mechanism [5] was \nincorporated into the encoder -decoder architecture for \ncapturing context in the encoder output. Alternatives to purely \nrecurrent encoder -decoder architectures  [4, 5]  are purely \nconvolutional [6] and convolutional -recurrent architectures  \n[7]. A convolutional encoder was preferred in [7] to better \ncapture the context information in the input sentence in order \nto generate semantically meaningful responses.  \nThe advent of transformers brought ab out a revolution in \nthe field of sequence modeling that was mainly dominated by \nRNNs. The transformer architecture was proposed by \nVaswani et al. in 2017 [8] for machine translation tasks, that \nallowed for significant parallel computations and is based \nentirely on self-attention which was further improved with the \n“multi-head” attention mechanism.  Self-attention allows for \nbetter word encoding as each word is processed by the model \nby looking at the other words in the input sentence which helps \nin getting better clues/hints about the context in which the \ncurrent word is being used. The transformer architecture also \nuses positional encoding by making changes to the original \ninput embedding such that the model learns the position of \neach word and meaningful distances between different words \nin the sentence. However, the transformer works with a fixed-\nlength context. This restricts its ability to model dependencies \nbeyond a segment . There is also  the problem of context \nfragmentation which arises due to fixed -length segments not \nrespecting the sentence boundaries leading to a loss of context \nof the original sentence due to semantic boundaries of the \nsentence being ignored. \n The Transformer-XL model [9] was introduced by Dai et \nal. in 2019 as an improvement over the vanilla transformer \nwith much faster evaluation speeds and much longer \ndependency learning capability. Transformer -XL (XL for \nextra-long) overcomes the shortcomings of the vanilla \ntransformer of Al-Rfou et al.  (2019) [10] by incorporating \nrecurrence mechanism and relative positional encoding. In \nthis paper, we propose a Transformer -XL architecture for \nempathetic response generation by adding and normalizing  \nthe word embedding from the input utterance with the emotion \nembedding. An emotion detection module forms the first stage \nin our learning framework. The result is an emotionally \nintelligent conversational agent that can understand the \nemotions of the user and generates empathetic response s \naccordingly. The rest of the paper is organized as follows: \nsection II presents related work, the proposed model is \ndescribed in section III, the experimental setup and the results \nare discussed in sections IV and V respectively, and the paper \nis concluded in section VI. \nII. RELATED WORK \nMost of the contemporary work on conversational agents \nfocus on improving language understanding. Recent works \nadvocate the incorporation of contextual knowledge through \nattention mechanisms [2, 5]. However, such models are \nunaware of the emotions of the user , and the generated \nresponses may sometimes reveal the lack of personality or \ncharacter of the virtual agent. Incorporation of affect as a \nmodality in human-machine interactions is now regarded as a \nmeans for gaining human trust. U nderstanding the affective \nstate of the user is useful for generating emotive responses that \nimproves the overall quality of the human machine interaction \nand increases customer satisfaction [30].  In two separate \nworks, Lee et al. (2005) and Devillers and Vidrascu  (2006) \npresented some initial work on emot ion recognition from \nconversations using audio and lexicon -based methods  [11, \n12]. Emotion classification using raw audio features is already \nwell explored in literature [13]. Inclusion of text cues \nimproved the classification scores in [14].  \nSome of the earliest attempts to create  emotionally \nintelligent conversational agents was based on selecting  an \nemotional response using manually crafted rules [31] that \nrequired expertise and was not scalable to larger datasets. The \nintroduction of the encode r-decoder model for sequence -to-\nsequence learning [4] changed the drift of research with most \nof the researchers adopting this methodology for mapping the \ninput utterance to a suitable output response which is predicted \non a word-by-word basis using neural networks. LSTM which \nis a recurrent neural network captures the temporal \ninformation in the words in a sentence effectively [15], hence \nmost of the sequence-to-sequence models have LSTM as the \nencoder and the decoder. Hu et al. , (2018) proposed an \nencoder-decoder architecture with LSTM to develop a tone -\naware chatbot meant for social media customer care  [16]. \nMost of the corpora for dialogue systems, till recently, did not \ninclude meta-data such as topic of discussion, speaker-name, \npersonality or emotions. Now, there are available datasets, that \nare emotionally annotated, like the Facebook AI Empathetic \nDialogue (ED) dataset introduced by Rashkin et al. in 2019 \n[17]. There are also datasets based on textual and acoustic \nfeatures [18, 19] from which models have been developed for \nsentiment classification and emotion recognition. Zhou et al. \n(2020) used a Seq2Seq GRU -RNN model to develop an \nempathetic social chatbot which takes into consideration  the \nEmotional Quotient (EQ) and Intelligence Quotient (IQ) for \ngenerating responses  with proper emotions  [20]. Li et al.  \n(2019) develop ed a conversational agent that generate d \nmeaningful emotional replies using Reinforcement Learning \nand emotional editing constraints [21].  \nAn empathetic response-based chatbot called CARO was \nintroduced in [22] that was capable of engaging in empathetic \nconversations and providing medical advice for people \nsuffering with major depression ; it  generated responses by \nappending emotions as a prefix for each utterance . A \nclassification stage forms the first stage of this chatbot that \ndecided whether the user ut terance belonged to the category \nof medical question answering or an empathetic dialogue. The \nmodel was trained using both the datasets in this case. Ma et \nal. (2020), has presented a systematic review of chatbots that \ngenerate empathetic responses to user utterances; these were \ntermed as Emotionally Aware Chatbots (EAC)  [23]. LSTM \nwith attention mechanism has proved to generate more \nempathetic responses than the LSTM sans attention, as proved \nby researchers in [24] who experimented on the Facebook AI \nED dataset.  Likewise, transformer models have proved to \noutperform LSTM with attention for empathetic dialogue \ngeneration, as proved in [17]. The details of our model, which \nis based on one of the latest advancements in transformer \narchitectures, are described in the next section. \nIII. PROPOSED MODEL \nMotivated by the work on transformer based empathetic \ndialogue generation in [17], we propose a novel technique for \nrendering the virtual agent emotionally intelligent. Assuming \nthat the dialogue dataset has emotion annotations, a separate \nclassifier is trained on the emotion meta -data, apart from the \nusual training on utterance-response pairs. Fig. 1 shows the \nbasic blocks of our model. To make the dialogue generator \nemotionally intelligent, we incorporate an emotional bias in \nthe input embedding. The transformer encoder that encodes \nthe input utterance is made emotion aware by incorporating \nthe emotion information in the form of an embedding vector. \nUnlike [17] that prepends the emotion information along with \nthe utterance embedding as a separate piece of information, \nwe add and normalize each word embedding in the input \nutterance with the embedding vector of the predicted emotion; \nthe result is provided as input to the transformer encoder. The \nKeras word embedding is used, that yields better results than \nthe conventional bag -of-words representation used for text \nclassification [25].  \nOur learnin g model, therefore, comprises of two \nindependent models that are trained separately on the same \ndataset; one is the Emotion Classifier and the other is the \nGenerative Chatbot , as shown in Fig. 1 . The Emotion \nClassifier uses the utterance to detect the emotion in the \nutterance, while the Generative Chatbot provides the utterance \nand detected emotion as the inputs to the transformer encoder \nin order to generate the empathetic response. The result is an \nemotionally intelligent conversational agent that can detect \nand respond to the emotional state of the user.  The details of \nEmotion Classifier and the Generative Chatbot are given next. \n \n           \nFig. 1. Basic outline of the proposed model \nA. Emotion Classifier \nThe first stage of our learning framework comprises of an \nemotion detection module. Fig. 2(a) shows the distribution of \n32 emotions in the ED dataset. We have divided the total \nnumber of emotions into eight groups by grouping similar \nemotions together, as shown in Fig. 2 (b). We used the same \ncoarse grouping of emotions as in [22]. \n\n \n               (a) \n \n                 \n              (b) \nFig. 2. (a) Frequency Distribution of emotions in the Facebook AI ED dataset (b) Grouping of emotions in the ED dataset into eight categories (Harilal et al. \n2020) [22]\nThe Emotion Classifier that we have used for predicting the \ncontext of the given utterance consists of an LSTM unit of \n300 cells and a 100 -unit dense layer. The softmax layer \nconsists of eight units corresponding to the eight emotion \ngroups. The highest probability in the output layer determines \nthe emotion. The pipeline for our emotion prediction module \nis shown in Fig. 3.                                         \n \n          \n \nFig. 3. Emotion classifier  \n    The model uses the dropout regularization technique, in \norder to prevent model overfitting. The classifier uses the \nCategorical Cross -Entropy Loss function along with Adam \nOptimizer [26] for model training. \nB. Generative Chatbot \nFor the Generative Chatbot, we make use of the Transformer-\nXL (XL for extra -long) architecture proposed by Dai et al. \n(2019) [9] to model long -term dependencies, which is a \nrecently introduced transformer architecture  for language \nmodelling. Transformer-XL has a similar base as that of the \nvanilla Transformer in [10] . The ability of the Transformer -\nXL model to handle long-term dependencies in a much better \nway than the vanilla transformer makes the Transformer -XL \nmuch more prefera ble. In the Transformer -XL architecture, \nthe output of the hidden layer of the last segment is also passed \nwith the present segment’s hidden layer output which helps to \ncapture the long term dependencies in a better manner. Also, \nto capture the long -term dependencies more effectively , \npositional encoding is introduced in each part of the attention \nmodule.  \nThe Generative Chatbot  model consists of two parts i.e. \nencoder and decoder. The encoder receives as its input the \nword embedding of the utterance augmented by the emotion \nembedding, as shown in Fig. 4. The embedding vector we get \nafter adding and normalizing the two components has the \ninformation about both the word s and the emotional context \nin the input utterance, which will be further processed to \ngenerate suitable empathetic responses.  The normalization \nprocedure comprises of subtracting the mean and dividing by \nthe standard deviation.  An emotional bias is, therefore, \nintroduced in the embedding stage, that makes the transformer \nencoder emotion aware. \n \n\n                \n \nFig. 4. Augmentation of word embedding with emotion embedding for the \ntransformer encoder \nAdding and normalizing embedded feature vectors was found \nto improve accuracy in several Seq2Seq models due to the \ninduced bias that makes the model sensitive to context [7]. The \ntransformer encoder consists of several layers, each consisting \nof multi-head attention layer and feed-forward network. The \ndecoder receives the hidden representation from the encoder \nand decodes it to probabilistically generate the target response, \none word at a time.  The output sequence obtained from the \ntransformer decoder is the generated response. The responses \ngenerated by our model are evaluated for their correctness, as \nper procedure explained in sections IV and V. \n \nIV. EXPERIMENTAL SETUP \nA. Dataset \nThe Facebook AI Empathetic Dialogue (ED) dataset [17] \nis used for the experimentation. The training dataset comprises \nof a total of 79189 entries with 8 columns consisting of non -\nnull values of prompt and utterance, associating a prescribed \nemotion in the context value. A total of 32 unique emotions \nhave been classified in t he dialogues that are grouped into 8 \nemotion categories, as previously shown in Fig. 2. Also, it is \nquite evident that the 32 different emotions need not \nspecifically highlight unique emotions in real life. For \nexample, ‘ afraid’ and ‘ terrified’ can relate to the same \nemotion type in all practical scenarios. We use the grouping \nfollowed by [22] for the ED dataset. A total of 5242 entries \nare present in the test dataset. It was observed that the relative \ncount of emotions in the train and test dataset is almo st the \nsame.  \nB. Training setup \nThe standard text pre-processing steps were performed \nsuch as tokenization, converting to lower case . This was \nfollowed by lemmatization to standardize the vocabulary. The \nsoftware implementation was done in Python. We have made \nour code available online1. We use an 8-head Transformer-XL \nencoder with inner-size dimensionality of 256 and the hidden-\nlayer size is 100. The training process consisted of 50 epochs \nwith a batch size of 64 and a learning rate of 0.001 , and the \ndropout regularization parameter was set to 0.1. Sparse \nCategorical Cross Entropy loss function was used along with \nAdam optimizer with the hyperparameters β1= 0.9, β2=0.98 \n \n1 https://github.com/r9729104234/Emotion-Aware-Transformer-\nEncoder-for-Empathetic-Dialogue-Generation \nand Ɛ = 10−9. The loss value was reduced to 0.6054 at the end \nof 50 epochs.  \nV. RESULTS AND DISCUSSIONS \n  The Emotion Classifier in the first stage of our learning \nframework achieved a test accuracy of 95%. The predicted \nemotion was mapped into a 256 -dimensional embedded \nvector, that was added and normalized with the word \nembedding of the same size. Keras word embedding was used. \nWe used the BLEU-4 score [27] metric to evaluate the quality \nof the generated responses. This is a value between 0 to 1 that \nmatches the machine generated response with the human \nresponse (ground-truth). A value of 1 means a perfect match \nwith the human annotated response. The higher the score, the \ncloser is the machine generated response to the ground-truth. \nThe BLEU-4 scores of all the ground tru ths available for an \ninput utterance were averaged.  \nWe have considered seven models for comparison, the first is \nthe one proposed by Facebook AI [17] based on the \ntransformer architecture. This model prepends the emotion \nwith the user utterance. The second is the baseline Seq2Seq \nencoder-decoder model based on LSTM with Attention \nMechanism [24]. The third is an other LSTM-based \nconversational agent  called CARO [22]. The fourth is the \nvanilla transformer model proposed by Vaswani et al. (2017) \n[8]. The fifth method EmoDS is that of Song et al. (2019) [28], \nthat plugs emotional words at certain time -steps in between \nwords to make the system emotion  aware. The sixth method \nis EmpTransfo  [29], a multi -head transformer model  that \npredicts the next emotion and utterance  given the current \nemotion and utterance . The BLEU scores for the responses \ngenerated by all models are summarized in Table I. \nTABLE I.  BLEU SCORES FOR DIFFERENT MODELS \nModels BLEU Score \nFacebook AI Model 0.08 \nSeq2Seq with Attention Model 0.137 \nCARO Model 0.179 \nTransformer Model 0.173 \nEmoDS Seq2Seq model 0.173 \nEmpTransfo 0.1592 \nProposed Model 0.225 \n \nAs observed, the B LEU score for the proposed model is the \nhighest (0.225), thus, this model generates the most \nempathetic responses among all methods. However, i t was \nobserved that substitution of Keras word embedding with \nGloVe word embedding reduced the BLEU score of our \nmodel from 0.225 to 0.213.  A comparison of the responses \ngenerated by our model vs. the standard transformer model is \nshown for a set of utterance-response pairs of the ED dataset \nin Table II. From the empathetic responses generated by our \nmodel, it is evident that it is more emotionally intelligent than \nthe vanilla transformer model. For example, the model is \naware of the happy occasion being that of a job, in the first \ninstance, and that the user is going to be a parent, in the second \ncase. The vanilla transformer, on the other ha nd, generates a \ngeneric complimentary response, that has no bearing on the \nparticular situation of the user. The limitation of our model is \nhighlighted in the third case in Table II, where the symbolic \nnotation of math test is not comprehended by both the \n \n\ntransformer models and a generic response is generated in \nboth cases that conveys the hope that the problem w ill be \nsorted out and that it can happen with anybody.  \nThere are also cases where multiple emotions can be \nassociated with a user utterance. A notable instance is the \nfourth case in Table II, where the emotion associated with the \nuser statement on skydivi ng is decoded by our model as \n“terrified” and a suitable response is generated  accordingly. \nThough the predicted emotion did not match with the dataset \nannotation (“excited”), the generated response yet was found \nto sync with some of the ground truth responses that expressed \nfear and apprehension in regard of skydiving. This leads to the \nobservation that more than one affective state may be involved \nin human -machine dialogue systems . Identification of \ncompatible human emotions   can lead to the development of \nmore emotionally -sensitive human -machine interfaces.  \nExploration of dynamically evolving emotions in human -\nmachine conversations forms the future scope of our work. \n \nTABLE II.  RESPONSES GENERATED BY THE VANILLA TRANSFORMER MODEL VS. THE PROPOSED MODEL FOR SAMPLES FROM THE ED DATASET \nUtterance \n(user input) \nGround Truth (Human \nannotations) \n(Gray highlighted regions \nintroduced to distinguish \nbetween ground truths)  \nOriginal \nemotion \nDetected \nEmotion \n(Coarse \nclassification) \nVanilla \nTransformer \nresponse \n \nProposed \nModel \nresponse \nI was very \nhappy to get \nmy new job \noh wow. we're practically \nneighbors. \nexcited joyful \n(excited) \n \nThat is huge. Congratulations. \nWhat do you do? \n I started a new job about a \nmonth ago and it's going really \nwell. \n \n I work in I.T. for the \nprovincial government in \nCanada \n \nMy first baby \nis on the way. \nI'm going to \nmake sure they \nhave a great life. \nOh wow! Congratulations! \n \nI do not yet but hope to one day. \nI think you will be a great parent!  \n \nThank you. We have been \ntrying for a year. \ngrateful hopeful  \n(grateful) \nCongratulations! \nThat is wonderful. \nOh wow! I think \nyou will be a great \nparent \nI was hoping \nthat I would \ndo better on a \nmath test. \nMy math teacher told the class I \nneeded to do better on my next \ntest. \nWell you should try to study more \nand see what happens \nWell maybe you should talk about \ngetting a tutor or something \n \n \ngrateful hopeful  \n(grateful) \nIt surely can be \nsorted. \nIt can happen to \nanyone. \nI'm going \nskydiving this \nweekend. \nOh my! That sounds exciting for \nsure! I couldn't do it, I don't think. \n \nI would say that you're an \nadventurous person. Me, I'm more \nlaid back and mellow. Kudos to you \nand have fun! \n \nThat's i'm so scared but it will be \nworth it. You only have one life so \ndon't hold back. \n \nI'm going skydiving this weekend. \nI'm afraid of heights and freaking \nout a little. \n \nexcited \n \nterrified  \n(afraid) \n \nHave a great \nweekend. It’s \nfun. \nHave you ever \ndone anything \nelse so \nfrightening? \n                                   \nVI. CONCLUSIONS \n In this paper, we have presented an emotionally intelligent \nconversational agent that is capable of conducting empathetic \nconversations with users. The proposed model integrates both \nthe semantic and affective aspects of the input utterance. The \ntwo embeddings (semantic, affective) are added and \nnormalized and fed as input to the transformer encoder. For \nthe same set of utterances, the BLEU score improved from \n0.173 to 0.225 as we moved from the standard transformer to \nthe advanced Transformer-XL architecture, which is also \nreflected in the difference in the quality of the responses \ngenerated by the two models. The proposed conversational \nagent successfully emulates a human agent that can perceive \nuser emotion and respond empathetically to the user input. \nEmotionally intelligent virtual agents are now a reality and the \ninclusion of affect as a modality in all human -machine \ninterfaces is foreseen in the immediate future. \nREFERENCES \n[1] Hussain, Shafquat, Omid Ameri Sianaki, and Nedal Ababneh. \"A \nsurvey on conversati onal agents/chatbots classification and design \ntechniques.\" In  Workshops of the International Conference on \nAdvanced Information Networking and Applications , pp. 946 -956. \nSpringer, Cham, 2019. \n[2] Luong, Minh -Thang, Hieu Pham, and Christopher D. Manning. \n\"Effective Approaches to Attention -based Neural Machine \nTranslation.\" In  Proceedings of the 2015 Conference on Empirical \nMethods in Natural Language Processing, pp. 1412-1421. 2015. \n[3] Hochreiter, Sepp, and Jürgen Schmidhuber. \"Long short -term \nmemory.\" Neural computation 9, no. 8 (1997): 1735-1780. \n[4] Cho, Kyunghyun, Bart van Merriënboer, Dzmitry Bahdanau, and \nYoshua Bengio. \"On the Properties of Neural Machine Translation: \nEncoder–Decoder Approaches.\" In  Proceedings of SSST -8, Eighth \nWorkshop on Syntax,  Semantics and Structure in Statistical \nTranslation, pp. 103-111. 2014. \n[5] Bahdanau, Dzmitry, Kyung Hyun Cho, and Yoshua Bengio. \"Neural \nmachine translation by jointly learning to align and translate.\" In  3rd \nInternational Conference on Learning Representatio ns, ICLR 2015 . \n2015. \n[6] Gehring, Jonas, Michael Auli, David Grangier, Denis Yarats, and Yann \nN. Dauphin. \"Convolutional sequence to sequence learning.\" \nIn International Conference on Machine Learning , pp. 1243 -1252. \nPMLR, 2017. \n[7] Mallick, Ritam, Seba Susan, Vaibhaw Agrawal, Rizul Garg, and \nPrateek Rawal. \"Context-and sequence-aware convolutional recurrent \nencoder for neural machine translation.\" In  Proceedings of the 36th \nAnnual ACM Symposium on Applied Computing, pp. 853-856. 2021. \n[8] Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion \nJones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin. \n\"Attention is all you need.\" In Advances in neural information \nprocessing systems , pp. 5998-6008. 2017. \n[9] Dai, Zihang, Zhilin Yang, Yiming Yang, Jaime G. Carbonell, Quoc Le, \nand Ruslan Salakhutdinov. \"Transformer -XL: Attentive Language \nModels beyond a Fixed -Length Context.\" In Proceedings of the 57th \nAnnual Meeting of the Association for Computational Linguistics, pp. \n2978-2988. 2019. \n[10] Al-Rfou, Rami, Dokook Choe, Noah Constant, Mandy Guo, and Llion \nJones. \"Character-level language modeling with deeper self-attention.\" \nIn Proceedings of the AAAI Conference on Artificial Intelligence, vol. \n33, no. 01, pp. 3159-3166. 2019. \n[11]  Chul Min Lee, Shrikanth S Nar ayanan, et al. 2005.Toward detecting \nemotions in spoken dialogs.IEEE transactions on speech and audio \nprocessing,13(2):293–303. \n[12] Devillers, Laurence, and Laurence Vidrascu. \"Real -life emotions \ndetection with lexical and paralinguistic cues on human -human ca ll \ncenter dialogs.\" In  Ninth International Conference on Spoken \nLanguage Processing. 2006. \n[13] Susan, Seba, and Amandeep Kaur. \"Measuring the randomness of \nspeech cues for emotion recognition.\" In  2017 Tenth International \nConference on Contemporary Computing (IC3), pp. 1-6. IEEE, 2017. \n[14] Vashishtha, Srishti, and Seba Susan. \"Unsupervised Fuzzy Inference \nSystem for Speech Emotion Recognition using audio and text cues \n(Workshop Paper).\" In 2020 IEEE Sixth International Conference on \nMultimedia Big Data (BigMM), pp. 394-403. IEEE, 2020. \n[15] Vashishtha, Srishti, and Seba Susan. \"Sentiment cognition from words \nshortlisted by fuzzy entropy.\"  IEEE Transactions on Cognitive and \nDevelopmental Systems 12, no. 3 (2019): 541-550. \n[16] Hu, Tianran, Anbang Xu, Zhe Liu, Quanzeng You, Yufan Guo, Vibha \nSinha, Jiebo Luo, and Rama Akkiraju. \"Touch your heart: A tone -\naware chatbot for customer care on social media.\" In Proceedings of \nthe 2018 CHI conference on human factors in computing systems , pp. \n1-12. 2018. \n[17] Rashkin, Hannah, Eric Michael Sm ith, Margaret Li, and Y -Lan \nBoureau. \"Towards Empathetic Open-domain Conversation Models: A \nNew Benchmark and Dataset.\" In  Proceedings of the 57th Annual \nMeeting of the Association for Computational Linguistics , pp. 5370 -\n5381. 2019. \n[18] Busso, Carlos, Murtaza Bulut, Chi-Chun Lee, Abe Kazemzadeh, Emily \nMower, Samuel Kim, Jeannette N. Chang, Sungbok Lee, and Shrikanth \nS. Narayanan. \"IEMOCAP: Interactive emotional dyadic motion \ncapture database.\" Language resources and evaluation  42, no. 4 \n(2008): 335-359. \n[19] Poria, Soujanya, Devamanyu Hazarika, Navonil Majumder, Gautam \nNaik, Erik Cambria, and Rada Mihalcea. \"MELD: A Multimodal \nMulti-Party Dataset for Emotion Recognition in Conversations.\" \nIn Proceedings of the 57th Annual Meeting of the Associa tion for \nComputational Linguistics, pp. 527-536. 2019. \n[20] Zhou, Li, Jianfeng Gao, Di Li, and Heung -Yeung Shum. \"The design \nand implementation of xiaoice, an empathetic social chatbot.\" \nComputational Linguistics 46, no. 1 (2020): 53-93. \n[21] Li, Jia, Xiao Sun, Xing  Wei, Changliang Li, and Jianhua Tao. \n\"Reinforcement learning based emotional editing constraint \nconversation generation.\" arXiv preprint arXiv:1904.08061 (2019). \n[22] Harilal, Nidhin, Rushil Shah, Saumitra Sharma, and Vedanta Bhutani. \n\"CARO: an empathetic heal th conversational chatbot for people with \nmajor depression.\" In  Proceedings of the 7th ACM IKDD CoDS and \n25th COMAD, pp. 349-350. 2020. \n[23] Ma, Yukun, Khanh Linh Nguyen, Frank Z. Xing, and Erik Cambria. \n\"A survey on empathetic dialogue systems.\"  Information Fu sion 64 \n(2020): 50-70. \n[24] Goel, Raman, Sachin Vashisht, Armaan Dhanda, and Seba Susan. \"An \nEmpathetic Conversational Agent with Attentional Mechanism.\" \nIn 2021 International Conference on Computer Communication and \nInformatics (ICCCI), pp. 1-4. IEEE, 2021. \n[25] Susan, Seba, and Juli Keshari. \"Finding significant keywords for \ndocument databases by two -phase Maximum Entropy \nPartitioning.\" Pattern Recognition Letters 125 (2019): 195-205. \n[26] Kingma, Diederik P., and Jimmy Ba. \"Adam: A Method for Stochastic \nOptimization.\" In ICLR (Poster). 2015. \n[27] Papineni, Kishore, Salim Roukos, Todd Ward, and Wei -Jing Zhu. \n\"Bleu: a method for automatic evaluation of machine translation.\" In \nProceedings of the 40th annual meeting of the Association for \nComputational Linguistics, pp. 311-318. 2002. \n[28] Song, Zhenqiao, Xiaoqing Zheng, Lu Liu, Mu Xu, and Xuan -Jing \nHuang. \"Generating responses with a specific emotion in dialog.\" \nIn Proceedings of the 57th Annual Meeting of the Association for \nComputational Linguistics, pp. 3685-3695. 2019. \n[29] Zandie, Rohola, and Mohammad H. Mahoor. \"Emptransfo: A multi -\nhead transformer architecture for creating empathetic dialog systems.\" \nIn The Thirty-Third International Flairs Conference. 2020. \n[30] Dino, Francesca, Rohola Zandie, Hojjat Abdollahi, Sarah Schoeder,  \nand Mohammad H. Mahoor. \"Delivering cognitive behavioral therapy \nusing a conversational social robot.\" In  2019 IEEE/RSJ International \nConference on Intelligent Robots and Systems (IROS), pp. 2089-2095. \nIEEE, 2019. \n[31] Polzin, Thomas S., and Alexander Waibel. \"Emotion-sensitive human-\ncomputer interfaces.\" In ISCA tutorial and research workshop (ITRW) \non speech and emotion. 2000. \n    ",
  "topic": "Encoder",
  "concepts": [
    {
      "name": "Encoder",
      "score": 0.8024941682815552
    },
    {
      "name": "Transformer",
      "score": 0.6601736545562744
    },
    {
      "name": "Computer science",
      "score": 0.6003984212875366
    },
    {
      "name": "Human–computer interaction",
      "score": 0.33956238627433777
    },
    {
      "name": "Electrical engineering",
      "score": 0.2886284291744232
    },
    {
      "name": "Engineering",
      "score": 0.14396080374717712
    },
    {
      "name": "Voltage",
      "score": 0.1356588900089264
    },
    {
      "name": "Operating system",
      "score": 0.06584951281547546
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I863896202",
      "name": "Delhi Technological University",
      "country": "IN"
    }
  ],
  "cited_by": 15
}