{
  "title": "Application and technology of an open source AI large language model in the medical field",
  "url": "https://openalex.org/W4389253043",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2630862912",
      "name": "Tairui Zhang",
      "affiliations": [
        "University of Birmingham"
      ]
    },
    {
      "id": "https://openalex.org/A2281390956",
      "name": "Tianyi Feng",
      "affiliations": [
        "China Academy of Information and Communications Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4308081867",
    "https://openalex.org/W3200638744",
    "https://openalex.org/W6800751262",
    "https://openalex.org/W4321472314",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W6851775633",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W3185341429",
    "https://openalex.org/W6800875267",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W4367365458",
    "https://openalex.org/W2975059944",
    "https://openalex.org/W2965210982",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W3033187248",
    "https://openalex.org/W6847076894",
    "https://openalex.org/W4285294723",
    "https://openalex.org/W6846002521",
    "https://openalex.org/W2950813464",
    "https://openalex.org/W6811129797",
    "https://openalex.org/W6810081322",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W6849941170",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2938830017",
    "https://openalex.org/W2981852735",
    "https://openalex.org/W2982399380",
    "https://openalex.org/W4378718543",
    "https://openalex.org/W4366198844",
    "https://openalex.org/W2004060645",
    "https://openalex.org/W4308760226",
    "https://openalex.org/W6852746770",
    "https://openalex.org/W4365600514",
    "https://openalex.org/W6850614898",
    "https://openalex.org/W4324319985",
    "https://openalex.org/W3133825286",
    "https://openalex.org/W6852909395",
    "https://openalex.org/W4311000453",
    "https://openalex.org/W4367061106",
    "https://openalex.org/W6853163053",
    "https://openalex.org/W4367000491",
    "https://openalex.org/W4366341216",
    "https://openalex.org/W6796581206",
    "https://openalex.org/W4366330426",
    "https://openalex.org/W4376312383",
    "https://openalex.org/W4361866031",
    "https://openalex.org/W4390874575",
    "https://openalex.org/W4297253404",
    "https://openalex.org/W4365143687",
    "https://openalex.org/W4376167329",
    "https://openalex.org/W4320005767",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4303443398",
    "https://openalex.org/W3122890974",
    "https://openalex.org/W4362515116",
    "https://openalex.org/W4385572464",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W4286987939",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2997200074",
    "https://openalex.org/W3168867926",
    "https://openalex.org/W4307079201",
    "https://openalex.org/W4386071707",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W2996428491",
    "https://openalex.org/W4311642023",
    "https://openalex.org/W4378105483",
    "https://openalex.org/W3195577433",
    "https://openalex.org/W4226399820"
  ],
  "abstract": "To explore the application prospects of an open source artificial intelligence (AI) large language model (LLM) in the medical field, we conducted an analysis from multiple dimensions, including the introduction of LLM, the classification of model types, and the status quo of the open source ecosystem development. The development of an open source LLM is currently in the rapid expansion phase, and there are many types of models and related tools. After analyzing the advantages and disadvantages of the models, we expounded feasible technical solutions for the application of an LLM in the medical field and made corresponding predictions. At present, LLMs in the medical field are still in the early stages, and there are still many problems related to ethics, technology, legal issues, and medical use.",
  "full_text": "Original Research\nRadiology \nScience\n96   Radiology Science 2023, Volume 2, Issue 1, p. 96-104\n© 2023 The Authors. Attribution-NonCommercial-NoDerivatives 4.0 International\nhttp://doi.org/10.15212/RADSCI-2023-0007\nAuthors\nTairui Zhang, Tianyi Feng\nCorrespondence\nfengtianyi@caict.ac.cn (T. Feng)\nApplication and technology of an open source \nAI large language model in the medical field\nGraphical abstract\nKey points\n•\t Detailed comparison of the advantages and disadvantages of \nopen-source LLM applied in the medical field.\n•\t Listed three technical solutions for deploying large models in \nmedical scenarios.\n•\t Analyzed the potential application scenarios of large models in \nthe medical field.\nOriginal Research\nRadiology \nScience\nRadiology Science 2023, Volume 2, Issue 1, p. 96-104   97 \n© 2023 The Authors. Attribution-NonCommercial-NoDerivatives 4.0 International\nApplication and technology of an open source \nAI large language model in the medical field\nTairui Zhanga, Tianyi Fengb,*\naSchool of Computer Science, College of Engineering and Physical Sciences, University of Birmingham, Birmingham, B15 2TT, UK\nbChina Academy of Information and Communications Technology, Beijing 100191, China\n*Correspondence: fengtianyi@caict.ac.cn (T. Feng)\nReceived: 16 July 2023; Revised: 4 October 2023; Accepted: 10 October 2023\nPublished online: 1 December 2023\nDOI 10.15212/RADSCI-2023-0007\nAbstract\nTo explore the application prospects of an open source artificial intelligence (AI) large language model (LLM) in \nthe medical field, we conducted an analysis from multiple dimensions, including the introduction of LLM, the \nclassification of model types, and the status quo of the open source ecosystem development. The development of \nan open source LLM is currently in the rapid expansion phase, and there are many types of models and related tools. \nAfter analyzing the advantages and disadvantages of the models, we expounded feasible technical solutions for \nthe application of an LLM in the medical field and made corresponding predictions. At present, LLMs in the medical \nfield are still in the early stages, and there are still many problems related to ethics, technology, legal issues, and \nmedical use.\nKeywords: open source, large language model, artificial intelligence, medical application\n1. INTRODUCTION\nMedical and healthcare are important parts of China’s \nnational economy and key industries that protect peo-\nple’s lives and health. Given the spread of the coro-\nnavirus and other diseases, numerous countries have \nencountered many problems, such as a shortage of \nmedical resources and medical personnel. Combining \nartificial intelligence (AI) with medical care can assist \nphysicians in virus screening [1] and disease diagnosis \n[2], thereby reducing the misdiagnosis rate and improv-\ning the efficiency of diagnosis and treatment. Recently, \nlarge language models represented by ChatGPT [3] and \nGPT-4 [4] have attracted attention from academia and \nindustry. Many Chinese technology companies have also \nlaunched large language models (LLMs) to compete \ninternationally at an advanced level. With powerful \ncommunication fluency, semantic understanding, induc-\ntive reasoning, and other abilities, LLMs have rapidly \npenetrated all walks of life.\nIn this context, the combination of LLM and med-\nicine has established a new direction in the medical \nfield. Because ChatGPT, GPT-4, and other models require \nhigh computing power and labor costs, many compa-\nnies and research teams have launched a variety of \nopen source LLMs. Indeed, the initiative promotes the \nrapid development of LLMs. In the current study we \n analyzed and discussed the advantages and disadvan-\ntages,  technical solutions, and application scenarios of \nopen source LLMs in the medical field by sorting out the \ntechnological development status, therefore aiming to \npromote the mutual integration and development of \nopen source models and medicine.\n2. AI LLMS\nAI LLMs are also referred to as foundation models [5]. \nAI LLMs are trained on massive, diverse datasets and can \nhandle a variety of downstream tasks [6]. The LLMs have \nmultiple rounds of dialogue and the ability to under -\nstand user intentions. The LLMs have better versatility \nand generalization, which overcomes the traditional \nmodel problem of poor versatility.\nTransformer was proposed by Vaswani et al. [7] in \n2017. With excellent scalability and parallel comput-\ning capabilities, Transformer quickly replaced recurrent \nneural network (RNN) and long short-term memory \n(LSTM) to become the mainstream architecture in natu-\nral language processing (NLP). It also has been extended \nto the computer vision (CV). It is possible to design and \ntrain a model with a parameter scale exceeding 100 bil-\nlion based on Transformer, and the models have good \nOriginal Research\nRadiology \nScience\n98   Radiology Science 2023, Volume 2, Issue 1, p. 96-104 \n© 2023 The Authors. Attribution-NonCommercial-NoDerivatives 4.0 International\ngeneralization. Figure 1 shows the AI LLMs with param-\neters > 10 billion that have emerged since 2019.\nWith the release of GPT-3 [ 9], ChatGPT, and GPT-4, \nprompt learning [10], instruction learning [11], reinforce-\nment learning from human feedback (RLHF) [ 12] have \nbecome common training methods. Prompt learning uni-\nfies downstream tasks into pre-training tasks and converts \ndownstream tasks into natural language with specific \ntemplates. Instruction learning can better motivate model \ncomprehension ability compared to prompt learning. \nInstruction learning uses instructions to guide the model \nto take the correct action, which makes model generaliza-\ntion ability stronger. RLHF refers to evaluating the output \nof the models in the form of human feedback and using \nthe feedback as a loss to optimize the model. Indeed, this \napproach can make the output more innocuous.\nLLMs be divided into decoder-only, encoder-only, \nand decoder-encoder structures [13]. Models with dif-\nferent structures are suitable for different downstream \ntasks (Table 1). Most of the early LLMs are open source, \nsuch as BERT [28], ERNIE [29], T5 [30], and BART [31]. \nThese models use encoder or encoder-decoder as the \nmain structure and have better encoding capabilities. In \nrecent years, GPT-3, ChatGPT, and GPT-4 have adopted \nthe decoder-only structure. Indeed, decoder-only is \nthe most popular structure due to its excellent genera-\ntion ability. With the high research cost of LLMs, many \ndecoder-only models are not open source.\nAlthough ChatGPT and GPT-4 can be used at no cost \nto the user, many companies have not announced the \nimplementation details of the models. There are insur -\nmountable technical barriers. It is difficult for individual \nFigure 1 | Large models with parameters greater than 10 billion since 2019 [8].\nTable 1 | Summary of mainstream large language models.\nStructure Publisher Model\nEncoder-only Google BERT, ALBERT [14]\nBaidu ERNIE, ERNIE2.0 [15]\nMeta RoBERTa [16]\nMicrosoft DeBERTa [17]\nEncoder-decoder Google T5, Flan-T5 [18]\nTsinghua University GLM [19], GLM-130B [20]\nDecoder-only OpenAI GPT-1 [21], GPT-2 [22], GPT-3, InstructGPT, ChatGPT, GPT-4\nGoogle XLNet [23], LaMDA [24], Bard, PaLM [25]\nMeta LLaMA [26], Galactica [27]\nOriginal Research\nRadiology \nScience\nRadiology Science 2023, Volume 2, Issue 1, p. 96-104   99 \n© 2023 The Authors. Attribution-NonCommercial-NoDerivatives 4.0 International\ndevelopers, small companies, and research institutions \nto develop more innovative models, and the technical \nbarriers hinder the promotion and application of LLMs \nin more fields.\nIn February 2023, Meta open sourced the LLaMA. The \nLLaMA derivatives, Alpaca [32] and Vicuna [ 33], can be \ntrained at a lower cost. These models can even achieve \nthe ability of ChatGPT, which promotes the wave of a \nLLM open source. At present, a number of open source \nLLMs for the medical field have been released. BioMedLM \nis a domain-specific LLM for biomedical text released \nby the Center for Research on Foundation Models \n(CRFM) in January 2023. BioMedLM uses a dataset that \nincludes 16 million medical abstracts and 5 million stud-\nies. BioMedLM achieved state of the art results on the \nUSMLE medical question and answer test. In April 2023, \nTsinghua University open-sourced BioMedGPT [34]. The \ntraining data includes multi-scale and cross-modal bio-\nmedical data. The BioMedGPT model has the ability to \npredict drug properties and natural language processing. \nVisual Med-Alpaca, which was released in April 2023 by \nthe Language Technology Laboratory at the University \nof Cambridge, recognizes and analyzes chest X-rays, and \ngenerates diagnostic conclusions. The research team of \nhealth intelligence (HIT) constructed a Chinese medical \ninstruction dataset based on the knowledge map and \napplication programming interface (API) of InstructGPT. \nThe research team of HIT trained HuaTuo, a LLM of intel-\nligent consultation based on LLaMA [35], which overcame \nthe LLM limited language problem in the Chinese context.\nTechnology open source promotes the rapid develop-\nment of LLMs in the vertical field, medical models with \nlow deployment costs, high professionalism, and a strong \nunderstanding ability. Compared with traditional medi-\ncal models, the capabilities of the LLMs have improved.\n3. SUMMARY OF LLM OPEN SOURCE ECOSYSTEM\nThe term, open source, was officially proposed by the \nopen system interconnect in 1988. After decades of \ndevelopment, open source has become the main driving \nforce for innovation in emerging technologies. Open \nsource can  minimize repetitive labor, save development \nresources, promote technological breakthroughs, lower \ndevelopment thresholds, and accelerate the promotion \nand application of new technologies. The term, ecosys-\ntem, originated from the field of biology and refers to \nthe natural system formed by organisms and the envi-\nronment [36]. We believe that the LLM open source \necosystem is centered on open source models, and sup-\nported by AI technology, training platforms, and data-\nsets. Together, the open source model support elements \nconstitute a technical ecosystem.\n3.1 Classification\nThe LLMs are classified based on different modalities \nand fine-tuning methods. We will introduce the devel-\nopment of two new LLMs.\nWhen classified based on modality, open source LLMs \ncan be divided into single modality, bimodal, and mul-\ntimodal models. Single modality models can only han-\ndle NLP, CV, or audio tasks, such as Alpaca, BLOOM [37], \nChatGLM, and GPT-2. The language model can be subdi-\nvided according to the output or the language, such as \nthe code generation model (StarCoder [38]), the Chinese \ndialogue model (Chinese-Vicuna), the multilingual dia-\nlogue model (ChatGLM-6B), and the medical advice gen-\neration models (MedicalGPT-zh and Chat Doctor [39]). \nThe bimodal models can handle two types of data and \ncan be divided into text-to-image (CogView [40] and \nconsistency models [41]), text-image mutual generation \n(UniDiffuser [42]), image-text matching (BriVL [43]), \ntext-to-speech (Massively Multilingual Speech [44]), \nspeech-to-text (Whisper [45]), and text-speech mutual \ngeneration (AudioGPT [46]) models. The multimodal \nLLMs can process data involving three or more modal-\nities (text, image, and speech). For example, ImageBind \ncan achieve an arbitrary understanding and conver -\nsion between six modalities (text, image, audio, depth, \n inertial measurement unit and thermal) [47].\nFine-tuning models can also be divided into models \nthat have not been fine-tuned (LLaMA), models that \nhave been fine-tuned by instructions (WizardLM [48], \nDolly2.0, and Chinese-LLaMA-Alpaca) and RLHF models \n(StableVicuna, ChatYuan-large-v2, and OpenAssistant \n[49]). Fine-tuning refers to initializing the target net-\nwork with the obtained parameters and training the \ntarget network with a dedicated dataset. Instruction \ntuning uses supervisory signals to guide the model to \nperform tasks described in the form of instructions so \nthat the models can respond correctly to new tasks. \nWizardLM-7B uses the evol-instruct to automatically \ngenerate open-domain instructions with various levels \nof difficulty and skill ranges. A part of the WizardLM-7B \noutput content achieves an effect similar to ChatGPT. \nRLHF relies on manually labeled data and the support \nof open source frameworks. StableVicuna uses Vicuna \nas the basic model, follows the three-stage RLHF \ntraining proposed by OpenAI, and has the ability to \ncommunicate.\nIn addition to the above types of LLMs, autonomous \nAI and large language models with plug-in systems are \ntwo new types of AI products. Autonomous AI is repre-\nsented by AutoGPT, AgentGPT, and BabyAGI. This prod-\nuct can use the GPT-4 interface and other models to \nindependently complete tasks given by humans, making \nup for the GPT-4 shortcomings that cannot be searched \nonline. The NLP Group at Fudan University released \nthe MOSS in April 2023, which can use plug-ins, such \nas search engines and calculators, to complete specific \ntasks. The plug-in system makes the models more flexi-\nble, enhances the expertise, and improves model inter -\npretability and robustness.\nAfter several years of development, open source \nLLMs have shown the advantages derived from differ -\nent types, comprehensive functions, and wide usage \nOriginal Research\nRadiology \nScience\n100   Radiology Science 2023, Volume 2, Issue 1, p. 96-104 \n© 2023 The Authors. Attribution-NonCommercial-NoDerivatives 4.0 International\nscenario coverage. Fine-tuning based on the above \nmodels has become the most popular method for devel-\noping large language models in the medical field. For \nexample, Huatuo, PMC-LLaMA [50], and ChatDoctor \nare based on LLaMA for fine-tuning, MedicalGPT-zh, \nDoctorGLM, and ChatGLM-Med are based on ChatGLM, \nand BioMedLM are based on GPT-2. While open sourc-\ning the model code, most research institutions also pro-\nvide models with different parameter scales to assist \ndevelopers in reproducing the model under different \nhardware resources and publish relevant training data, \nwhich lowers the entry threshold for LLMs.\n3.2 Open source framework\nThe open source framework encapsulates the commonly \nused training paradigms (instruction tuning and RLHF) \ninto services or interfaces, which greatly reduces the \namount of manually written code and saves graphics \nmemory. The open source framework decreases the dif-\nficulty of training and achieves the unity of high effi-\nciency and economy.\nInstruction tuning frameworks include OpenGPT \nand LMFlow. OpenGPT can create samples based on \ndomain data and the NHS-LLM trained with this frame-\nwork has achieved more accurate results than ChatGPT \nbased oseveral tests. The RLHF frameworks include trlX, \nDeepSpeed-Chat, ColossalAI, and Lamini. This type of \nframework realizes the popularization of RLHF training. \nFor example, DeepSpeed-Chat can train a model with \nmore than 13 billion parameters under the support of \na single GPU, which enables researchers to create more \npowerful models under limited conditions. Lamini can \npackage time-consuming and complex fine-tuning as a \nservice.\nIn addition to optimizing, integrating, and encapsu-\nlating the training process of LLMs in the framework, \nthere are also a number of new research projects. The \nself-instruct released by the University of Washington \ngenerates instructions autonomously by the models. \nThis method effectively reduces the cost of manually \nlabeled data and improves the ability of the model to \nfollow instructions [51]. LoRA is a fine-tuning method \nproposed by Microsoft the can reduce the trainable \nparameters of the model without sacrificing perfor -\nmance [52]. The Alpaca-Lora uses this method to fine-\ntune the LLaMA 7B and achieves the same effect as \nAlpaca with few training parameters.\nWith the support of open source frameworks and \nnew methods, the hardware resource requirements \nand development difficulties have been continuously \nreduced, and model performance has continued to \nimprove.\n3.3 Open source dataset\nThe capabilities of LLMs arise from datasets. LLM train-\ning relies on sufficiently large and complex training \ndata. For example, GPT-1 is trained with BookCorpus (a \ncorpus of unpublished free books by the authors). The \nmodel has acquired important world knowledge and \nthe ability to manage long-term dependencies. When \ninstitutions open source their models, institutions usu-\nally open source the training data as well. For example, \nCRFM released the self-instruct dataset generated by \ntext-davinci-003 while open sourcing Alpaca. Dataset \nopen sourcing improves the utilization rate of resources \nand has a positive impact on academic research pertain-\ning to LLMs.\nThe medical data include clinical datasets (MIMIC-II \nClinical Database), doctor-patient dialogue datasets \n(HealthCareMagic-100k, icliniq-10k, GenMedGPT-5k, \nand alpaca-52k used in ChatDoctor training), Chinese \nmedical dialogue datasets (data used by DoctorGLM), \nand self-built datasets consisting of medical paper \nabstracts and texts, and medical image datasets (DDSM, \nMIAS, and MURA). Medical open source datasets in the \nChinese field are relatively scarce and rely on the instruc-\ntions generated by ChatGPT, but this method is inaccu-\nrate and uncertain. To build a healthy and high-qual-\nity Chinese medical open source model field, there is \nan urgent to gather real and reliable medical data at a \nhigher level to improve data quality. At the same time, \nevaluation sets that assess the capabilities of LLMs are \nalso necessary.\nIn summary, the open-source ecologic development \nof LLMs is in a rapid growth phase. Various models, \nframeworks, and methods emerge in an endless stream, \nwhich provides a broad range of models and technol-\nogy selection for the researcher to use. A highly ver -\nsatile model comparable to GPT-4, however, is lacking. \nThe limitation of a model’s capability remains a problem \nthat cannot be dismissed, and the gap between close \nand open source models still exists. There is also a lack \nof a unified framework that simultaneously integrates \ninstruction tuning and RLHF. There are no professional \nand systematic evaluation indicators in the construction \nof datasets. An open source ecosystem of LLMs needs \nto develop in the direction of generalization, specializa-\ntion, and systematization.\n4. OPEN SOURCE LLMS IN THE MEDICAL FIELD\nThe following will describe the application of open \nsource LLMs in the medical field from three aspects: \nadvantages and disadvantages analysis, feasible techni-\ncal solutions, and application scenarios.\n4.1 Advantages of open source models in the \nmedical field\nThe advantages of open source LLMs in the medical field \ncan be summarized as low-cost deployment, variety of \nfunctions, and diverse interactions.\nFirst, LLMs usually perform reasoning tasks in clusters. \nThe WebLLM project move the reasoning process to the \nclient and runs in the browser, which minimizes server \noverhead and is more friendly to users (i.e., no need to \nuse the complex command to run the model). Localized \nOriginal Research\nRadiology \nScience\nRadiology Science 2023, Volume 2, Issue 1, p. 96-104   101 \n© 2023 The Authors. Attribution-NonCommercial-NoDerivatives 4.0 International\ndeployment is also more suitable for application scenar-\nios, such as hospitals with limited hardware resources \nand high data security levels.\nSecond, the open source LLMs have a wide variety \nof functions and there are mature open source prod-\nucts in medical image processing and text generation. \nChatDocter can conduct consultations in text form and \nImpressionGPT can summarize and optimize radiology \nreports [53]. To eliminate the defect of LLM informa-\ntion lag, WebCPM was released by Tsinghua University \nin May 2023 and can interact with search engines and \ncollect answers [54]; the generated content is more \nreal-time.\nThird, as the most common application scenario for \nLLMs, online medical consultation requires the model \nto have a high level of Chinese dialogue ability. Linly-\nChinese-LLAMA, BELLE, Chinese-Vicuna, and Bai Ze are \ntrained on Chinese datasets and have reached a high \nlevel in Chinese communication.\n4.2 Disadvantages of open source models in the \nmedical field\nDue to the low-fault tolerance of the healthcare indus-\ntry, most open source models are trained based on the \ncommunity open corpus, and the content was not man-\nually corrected. At the same time, open source models \nare limited by parameter scale and hardware resources. \nThe model may generate biased, toxic, and inaccu-\nrate content, which will pose a threat to the safety of \npatients. Beaver, a highly modular RLHF training frame-\nwork open sourced by the Peking University team, sig-\nnificantly reduces the biased and discriminatory content \noutput of the model through constrained value align-\nment (CVA). This type of method is currently still in the \ndevelopment stage. In medical scenarios, physicians are \nalso required to evaluate and give feedback on the pro-\nfessionalism of the output to reduce the errors and inac-\ncurate information.\n4.3 Feasible technical solutions\nDeploying LLMs in medical scenarios can be divided into \nthe following three technical solutions: 1) The capa-\nbilities of ChatGPT and GPT-4 should be used to solve \nprofessional tasks in the medical field with API. This \napproach is similar to the AutoGPT and HuggingGPT \ntechnical solutions [55]. Medical institutions can use the \ninterface provided by LangChain or similar frameworks \nto effectively utilize the capabilities of multiple models \nto complete a large number of tasks. This method is eas-\nier to develop and easy to deploy. The disadvantage is \nthat frequent usage of the ChatGPT and GPT-4 API may \nincur a large amount of expenses. Moreover, the degree \nof customization of the model is low, and the risk of \ndata security is high. 2) Due to the sensitivity of med-\nical data, it is difficult for cloud services to guarantee \ndata security. Medical institutions or teams can rely on \nopen source or medical field datasets to independently \ndevelop medical LLMs. The advantage of this solution \nis that the model fits perfectly with medical purposes \nand has a high level of customization. The disadvan-\ntage is that the independent development of LLMs will \nconsume a lot of manpower and financial costs, which \nonly the top institutions can afford. 3) Pre-training and \nfine-tuning for the medical use on the open source mod-\nels is a compromise between the above two solutions. \nResearchers can choose the more popular decoder-only \nstructure, which has stronger generation capabili-\nties. The steps of pre-training, supervised fine-tuning, \nand RLHF should be followed. The datasets include \nopen source data, artificially generated data, and self- \ninstruct data. The open source model can be customized \nand developed at a controllable cost; however, some \n popular models (LLaMA and Alpaca) do not support \ncommercial use, and it is necessary to avoid the risk of \ninfringement when using models. Currently, the power-\nful open source models that allow commercial applica-\ntions include ChatGLM2, Baichuan2, and LLaMA2, each \nof which has different parameter sizes.\nFaced with so many models, frameworks, and tech-\nnologies, some basic steps for building a medical large \nmodel are provided for reference: 1. Clarify the types \nof model users, including patients, medical institutions, \nphysicians, and medical regulatory departments. 2. \nClarify the requirements and objectives based on the \nfirst step. For example, the requirements and objec-\ntives can be divided according to the breadth of cov-\nerage (functional enhancement, process intelligence, \nand intelligence across multiple processes). The require-\nments and objectives are also divided into single modal \nand multimodal requirements. 3. Collect, filter, and \nstandardize training data to form a high-quality super -\nvised fine-tuning (SFT) dataset, including a high- quality \nphysician-patient dialogue dataset, medical knowledge \nquestion and answer-related data, and a human prefer-\nence dataset. The second and third steps interact with \neach other, such as generally clarifying the requirements \nof the current stage by considering the available data. \n4. Select model versions of different sizes based on \nthe range of data trained by the model and the pre-\npared data, hardware resources, and funding situation \namong many open source models. 5. Train or fine tune \nthe model. 6. Evaluate the capability of the new model \nbased on the publicly available dataset.\n4.4 Potential application\nThe development of medical AI began in 1972 with the \nAAPHelp system released by the University of Leeds \n[56]. Entering the era of LLMs, the computing power \nand comprehensive performance of models have been \ncontinuously improved and have reached the same level \nas humans in many fields. LLMs will play an increasingly \nimportant role in the medical field. Some typical appli-\ncation scenarios are as follows: 1. In scenario 1, open \nsource LLMs can be used as analytic tools for medical \nimages. Unlike traditional CV models that can only label \nand recognize images in a single domain, LLMs are more \nOriginal Research\nRadiology \nScience\n102   Radiology Science 2023, Volume 2, Issue 1, p. 96-104 \n© 2023 The Authors. Attribution-NonCommercial-NoDerivatives 4.0 International\nversatile. The SAM has strong generalization ability and \ncan achieve zero-shot transfer on new tasks [57]. At the \nsame time, the LLMs can also output the disease infor -\nmation of the medical image in the form of text, which \ncan achieve a rapid diagnosis. 2. In scenario 2, open \nsource LLMs can be used as daily medical assistants that \nprovide medical consultation and drug recommenda-\ntion services for patients. Patients can input their symp-\ntoms and medical history into the models, and it can \nsearch and summarize based on existing medical knowl-\nedge or search engines to form diagnostic recommen-\ndations. Finally, based on medical and clinical data, the \nbest treatment drugs are recommended. 3. In scenario 3, \nusing open source LLMs to generate or retrieve medical \nreports can reduce physician workload. The generation \nof medical reports is often performed manually by phy-\nsicians. Because the reports are highly formatted with \nsystematic text, the LLM has a strong ability to gener -\nate the reports. 4. In scenario 4, open source LLMs can \nbe applied to clinical research to improve the efficiency \nof data analysis and problem investigation. Researchers \ncan use autonomous AI products, such as AutoGPT, to \ncomplete preliminary research work by independently \ngenerating tasks and searching online. For text writing, \nresearchers can use BioGPT [58] or similar tools to com-\nplete the classification, summarizing, and text genera-\ntion. 5. In scenario 5, using a small amount of data or \neven no labeled data for training will comprise a gen-\neral medical model capable of various medical tasks in \nfuture research. Generalist medical artificial intelligence \n(GMAI) was proposed by Topol and Rajpurkar in 2022 \n[59]. Idealized GMAI can be trained on large and diverse \ndatasets, and the model can flexibly handle multimodal \ntasks. GMAI will have advanced medical reasoning abil-\nities that can support clinical decision-making and gen-\nerate protein amino acid sequences.\nThe various capabilities currently displayed by the \nLLMs have many potential applications in the medical \nfield; however, the risks in multiple dimensions (ethics, \nharmlessness, and public acceptance) need to be consid-\nered. We need more mature technical support to contin-\nuously improve the reliability of the models.\n5. SUMMARY\nAs one of the most important technical branches of \nAI, LLMs have penetrated all aspects of our society in \n< 1 year, but we need to be cautious when applying \nthis technology in the medical field. The laws and reg-\nulations in China related to medical AI have not been \nwell-established and the LLM open source ecosystem is \nstill in the early stage. Medical LLMs should be based \non open source products, and continuously deepen the \nresearch on the professionalism, humanistic care, and \naccuracy of model output. We also need to complement \nthe supporting tools and promote the healthy develop-\nment of this field. In the current study, by sorting out \nand analyzing the status quo of open source ecosystem \ndevelopment in LLMs, we hope to provide reference for \npromoting the application of LLMs in the medical field.\nACKNOWLEDGEMENTS\nThis study did not receive any specific grants from funding \nagencies in the public, commercial, or non-profit sectors.\nCONFLICT OF INTEREST\nNone.\nABBREVIATIONS\nAI, artificial intelligence; LLM, large language model; GPT, \ngenerative pre-trained transformer; RNN, recurrent neural \nnetwork; LSTM, long short-term memory; NLP, natural language \nprocessing; CV, computer vision; RLHF, reinforcement learning \nfrom human feedback.\nREFERENCES\n[1] Gao X, Khan MHM, Hui R, Tian Z, Qian Y, et al. COVID-VIT: \nClassification of Covid-19 from 3D CT chest images based \non vision transformer model. 2022 3rd International \nConference on Next Generation Computing Applications \n(NextComp); 2022. Pp. 1-4.\n[2] Costa GSS, Paiva AC, Junior GB, Ferreira MM. COVID-19  \nautomatic diagnosis with CT images using the novel \nTransformer architecture. Anais do XXI simpósio brasileiro \nde computação aplicada à saúde 2021;293-301.\n[3] Liu Y, Han T, Ma S, Zhang J, Yang Y, et al. Summary \nof ChatGPT/GPT-4 research and perspective towards \nthe future of large language models. Meta Radiol \n2023;1:100017. [DOI: 10.1016/j.metrad.2023.100017]\n[4] Open AI. GPT-4 Technical Report. arXiv preprint arXiv \n2023;2303.08774.\n[5] Bommasani R, Hudson DA, Adeli E, Altman R, Arora \nS, et al. On the opportunities and risks of foundation \nmodels. arXiv preprint arXiv 2021;2108.07258.\n[6] Zhou C, Li Q, Li C, Yu J, Liu Y, et al. A comprehensive survey \non pretrained foundation models: A history from BERT \nto ChatGPT. arXiv preprint arXiv 2023;2302.09419. [DOI: \n10.48550/arXiv.2302.09419]\n[7] Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, \net al. Attention is all you need. Adv Neural Inf Process Syst \n2017;30.\n[8] Zhao WX, Zhou K, Li JY, Tang T, Wang X, et al. A \nsurvey of large language models. arXiv preprint arXiv \n2023;2303.18223.\n[9] Brown T, Mann B, Ryder N, Subbiah M, Kaplan J, et al. \nLanguage models are few-shot learners. Adv Neural Inf \nProcess Sys 2020;1877-901.\n[10] Liu P, Yuan W, Fu J, Jiang Z, Hayashi H, et al. Pre-train, \nprompt, and predict: A systematic survey of prompting \nmethods in natural language processing. ACM Comput \nSurv 2023;55:1-35. [DOI: 10.1145/3560815]\n[11] Wei J, Bosma M, Zhao VY, Guu K, Yu AW, et al. Finetuned \nlanguage models are zero-shot learners. arXiv preprint \narXiv 2021;2109.01652.\n[12] Ouyang L, Wu J, Jiang X, Almeida D, Wainwright C, \net al. Training language models to follow instructions \nwith human feedback. Adv Neural Inf Process Sys \n2022;27730-44.\nOriginal Research\nRadiology \nScience\nRadiology Science 2023, Volume 2, Issue 1, p. 96-104   103 \n© 2023 The Authors. Attribution-NonCommercial-NoDerivatives 4.0 International\n[13] Yang J, Jin H, Tang R, Han X, Feng Q, et al. Harnessing \nthe power of llms in practice: a survey on chatgpt and \nbeyond. arXiv preprint arXiv 2023;2304.13712.\n[14] Lan Z, Chen M, Goodman S, Gimpel K, Sharma P, et al. \nALBERT: a lite BERT for self-supervised learning of \nlanguage representations. arXiv preprint arXiv 2019; \n1909.11942.\n[15] Sun Y, Wang S, Li Y, Feng S, Tian H, et al. ERNIE 2.0: \na continual pre-training framework for language \nunderstanding. Proceedings of the AAAI Conference on \nArtificial Intelligence; 2020. Pp. 8968-75.\n[16] Liu Y, Ott M, Goyal N, Du J, Joshi M, et al. RoBERTa: a \nrobustly optimized BERT pretraining approach. arXiv \npreprint arXiv 2019;1907.11692.\n[17] He P, Liu X, Gao J, Chen W. DeBERTa: decoding-enhanced \nBERT with disentangled attention. arXiv preprint arXiv \n2020; 2006.03654.\n[18] Chung HW, Hou L, Longpre S, Zoph B, Tay Y, et al. Scaling \ninstruction-finetuned language models. arXiv preprint \narXiv 2022;2210.11416.\n[19] Du Z, Qian Y, Liu X, Ding M, Qiu J, et al. GLM: General \nlanguage model pretraining with autoregressive blank \ninfilling. Proceedings of the 60\nth Annual Meeting of \nthe Association for Computational Linguistics; 2022. Pp. \n320-35.\n[20] Zeng A, Liu X, Du Z, Wang Z, Lai H, et al. GLM-130B: an \nopen bilingual pre-trained model. arXiv preprint arXiv \n2022;2210.02414.\n[21] Radford A, Narasimhan K, Salimans T, Sutskever I. \nImproving language understanding by generative pre-\ntraining. 2018.\n[22] Radford A, Wu J, Child R, Luan D, Amodei D, et al. \nLanguage models are unsupervised multitask learners. \nOpenAI Blog 2019;9.\n[23] Yang Z, Dai Z, Yang Y, Carbonell J, Salakhutdinov R, \net al. XLNet: generalized autoregressive pretraining \nfor language understanding. Adv Neural Inf Process Sys \n2019;32.\n[24] Thoppilan R, De Freitas D, Hall J, Shazeer N, Kulshreshtha \nA, et al. LaMDA: language models for dialog applications. \narXiv preprint arXiv 2022;2201.08239.\n[25] Chowdhery A, Narang S, Devlin J, Bosma M, Mishra G, \net al. PaLM: Scaling language modeling with pathways. \narXiv preprint arXiv 2022;2204.02311.\n[26] Touvron H, Lavril T, Izacard G, Martinet X, Lachaux MA, \net al. LLaMA: open and efficient foundation language \nmodels. arXiv preprint arXiv 2023; 2302.13971.\n[27] Taylor R, Kardas M, Cucurull G, Scialom T, Hartshorn A, \net al. Galactica: a large language model for science. arXiv \npreprint arXiv 2022;2211.09085.\n[28] Devlin J, Chang MW, Lee K, Toutanova K. BERT: pre-\ntraining of deep bidirectional transformers for language \nunderstanding. arXiv preprint arXiv 2018;1810.04805.\n[29] Sun Y, Wang S, Li Y, Feng S, Chen X, et al. ERNIE: enhanced \nrepresentation through knowledge integration. arXiv \npreprint arXiv 2019;1904.09223.\n[30] Raffel C, Shazeer N, Roberts A, Lee K, Narang S, et al. \nExploring the limits of transfer learning with a unified \ntext-to-text transformer. J Mach Learn Res 2020; \n21:5485-551.\n[31] Lewis M, Liu Y, Goyal N, Ghazvininejad M, Mohamed A, \net al. BART: Denoising sequence-to-sequence pre-training \nfor natural language generation, translation, and \ncomprehension. arXiv preprint arXiv 2019;1910.13461.\n[32] Taori R, Gulrajani I, Zhang T, Dubois Y, Li X, et al. Alpaca: \na strong, replicable instruction-following model. Stanford \nCenter for Research on Foundation Models 2023;7. Available \nfrom https://crfm.stanford.edu/2023/03/13/alpaca.html.\n[33] Chiang WL, Li Z, Lin Z, Sheng Y, Wu Z, et al. Vicuna: \nan open-source Chatbot impressing GPT-4 with 90%* \nChatGPT quality. Available from https://vicuna.lmsys.org \n[Accessed on 14 Apr 2023] 2023.\n[34] Zhang K, Yu J, Yan Z, Liu Y, Adhikarla E, et al. BiomedGPT: \na unified and generalist biomedical generative pre-\ntrained transformer for vision, language, and multimodal \ntasks. arXiv preprint arXiv 2023;2305.17100.\n[35] Wang H, Liu C, Xi N, Qiang Z, Zhao S, et al. HuaTuo: tuning \nLLaMA model with Chinese medical knowledge. arXiv \npreprint arXiv 2023;2304.06975.\n[36] Tansley AG. The use and abuse of vegetational concepts \nand terms. Ecology 1935;16:284-307.\n[37] Scao TL, Fan A, Akiki C, Pavlick E, Ilic S, et al. BLOOM: \na 176B-parameter open-access multilingual language \nmodel. arXiv preprint arXiv 2022;2211.05100.\n[38] Li R, Allal LB, Zi Y, Muennighoff N, Kocetkov D, et al. \nStarCoder: may the source be with you. arXiv preprint \narXiv 2023;2305.06161.\n[39] Yunxiang L, Zihan L, Kai Z, Dan R, Zhang Y, et al. \nChatdoctor: a medical chat model fine-tuned on LLaMA \nmodel using medical domain knowledge. arXiv preprint \narXiv 2023;2303.14070.\n[40] Xu J, Liu X, Wu Y, Tong Y, Li Q, et al. ImageReward: \nlearning and evaluating human preferences for text-to-\nimage generation. arXiv preprint arXiv 2023;2304.05977.\n[41] Song Y, Dhariwal P, Chen M, Sutskever I. Consistency \nmodels. arXiv preprint arXiv 2023;2303.01469.\n[42] Bao F, Nie S, Xue K, Li C, Pu S, et al. One transformer fits \nall distributions in multi-modal diffusion at scale. arXiv \npreprint arXiv 2023;2303.06555.\n[43] Huo Y, Zhang M, Liu G, Lu H, Gao Y, et al. WenLan: \nbridging vision and language by large-scale multi-modal \npre-training. arXiv preprint arXiv 2021;2103.06561.\n[44] Pratap V, Tjandra A, Shi B, Tomasello P, Babu A, et al. \nScaling speech technology to 1,000+ languages. arXiv \npreprint arXiv 2023;2305.13516.\n[45] Radford A, Kim JW, Xu T, Brockman G, McLeavey C, \net al. Robust speech recognition via large-scale weak \nsupervision. arXiv preprint arXiv 2022;2212.04356.\n[46] Huang R, Li M, Yang D, Shi J, Chang X, et al. AudioGPT: \nunderstanding and generating speech, music, sound, and \ntalking head. arXiv preprint arXiv 2023;2304.12995.\n[47] Girdhar R, El-Nouby A, Liu Z, Singh M, Alwala VA, et al. \nImageBind: one embedding space to bind them all. \nProceedings of the IEEE/CVF Conference on Computer \nVision and Pattern Recognition 2023. Pp. 15180-15190.\n[48] Xu C, Sun Q, Zheng K, Geng X, Zhao P, et al. WizardLM: \nempowering large language models to follow complex \ninstructions. arXiv preprint arXiv 2023;2304.12244.\n[49] Köpf A, Kilcher Y, von Rütte D, Anagnostidis S, Tam \nZR, et al. OpenAssistant conversations–democratizing \nlarge language model alignment. arXiv preprint arXiv \n2023;2304.07327.\n[50] Wu C, Zhang X, Zhang Y, Wang Y, Xie W. PMC-LLaMA: \nFurther finetuning LLaMA on medical papers. arXiv \npreprint arXiv 2023;2304.14454.\n[51] Wang Y, Kordi Y, Mishra S, Liu A, Smith NA, et al. Self-\nInstruct: aligning language model with self generated \ninstructions. arXiv preprint arXiv 2022;2212.10560.\nOriginal Research\nRadiology \nScience\n104   Radiology Science 2023, Volume 2, Issue 1, p. 96-104 \n© 2023 The Authors. Attribution-NonCommercial-NoDerivatives 4.0 International\n[52] Hu EJ, Shen Y, Wallis P, Zhu ZA, Li Y, et al. LoRA: low-rank \nadaptation of large language models. arXiv preprint \narXiv 2021; 2106.09685.\n[53] Ma C, Wu Z, Wang J, Xu S, Wei Y, et al. ImpressionGPT: \nan iterative optimizing framework for radiology report \nsummarization with chatGPT. arXiv preprint arXiv \n2023;2304.08448.\n[54] Qin Y, Cai Z, Jin D, Yan L, Liang S, et al. WebCPM: \ninteractive web search for chinese long-form question \nanswering. arXiv preprint arXiv 2023;2305.06849.\n[55] Shen Y, Song K, Tan X, Li D, Lu W, et al. HuggingGPT: \nSolving AI tasks with ChatGPT and its friends in \nhuggingface. arXiv preprint arXiv 2023;2303.17580.\n[56] EY. Artificial Intelligence in Europe, Outlook for 2019 and \nBeyond. 2018.\n[57] Kirillov A, Mintun E, Ravi N, Mao H, Rolland C, \net al. Segment anything. arXiv preprint arXiv 2023; \n2304.02643.\n[58] Luo R, Sun L, Xia Y, Qin T, Zhang S, et al. BioGPT: \ngenerative pre-trained transformer for biomedical text \ngeneration and mining. Brief Bioinform 2022;23:bbac409. \n[DOI: 10.1093/bib/bbac409]\n[59] Moor M, Banerjee O, Abad ZSH, Krumholz HM, Leskovec \nJ, et al. Foundation models for generalist medical artificial \nintelligence. Nature 2023;616:259-65. [DOI: 10.1038/\ns41586-023-05881-4]",
  "topic": "Field (mathematics)",
  "concepts": [
    {
      "name": "Field (mathematics)",
      "score": 0.6900440454483032
    },
    {
      "name": "Status quo",
      "score": 0.6735283136367798
    },
    {
      "name": "Open source",
      "score": 0.634338915348053
    },
    {
      "name": "Computer science",
      "score": 0.5686754584312439
    },
    {
      "name": "Data science",
      "score": 0.46699658036231995
    },
    {
      "name": "Engineering ethics",
      "score": 0.43084293603897095
    },
    {
      "name": "Management science",
      "score": 0.4305548667907715
    },
    {
      "name": "Engineering",
      "score": 0.23407191038131714
    },
    {
      "name": "Political science",
      "score": 0.16417250037193298
    },
    {
      "name": "Software",
      "score": 0.08187803626060486
    },
    {
      "name": "Law",
      "score": 0.07470431923866272
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Pure mathematics",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    }
  ]
}