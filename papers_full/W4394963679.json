{
  "title": "Can Large Language Models Provide Emergency Medical Help Where There Is No Ambulance? A Comparative Study on Large Language Model Understanding of Emergency Medical Scenarios in Resource-Constrained Settings",
  "url": "https://openalex.org/W4394963679",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5094357008",
      "name": "Paulina Boadiwaa Mensah",
      "affiliations": [
        "Aerospace Medical Association"
      ]
    },
    {
      "id": null,
      "name": "Nana Serwaa Quao",
      "affiliations": [
        "Korle Bu Teaching Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2944798381",
      "name": "Sesinam Dagadu",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Cohort 2, Project Genie Clinician Evaluation Group",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5094357008",
      "name": "Paulina Boadiwaa Mensah",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Nana Serwaa Quao",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4389508559",
    "https://openalex.org/W4389895211",
    "https://openalex.org/W4393862353",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W4392616695",
    "https://openalex.org/W4235401421",
    "https://openalex.org/W4389989133",
    "https://openalex.org/W4323835279",
    "https://openalex.org/W4391973028",
    "https://openalex.org/W4384024640",
    "https://openalex.org/W4393948619",
    "https://openalex.org/W1999353256",
    "https://openalex.org/W4389156617",
    "https://openalex.org/W4200514127",
    "https://openalex.org/W3207900783",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4366823941",
    "https://openalex.org/W4391750754",
    "https://openalex.org/W4391259883",
    "https://openalex.org/W4392193048",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W4388014051",
    "https://openalex.org/W4323076364"
  ],
  "abstract": "Abstract The capabilities of Large Language Models (LLMs) have advanced since their popularization a few years ago. The healthcare sector operates on, and generates a large volume of data annually and thus, there is a growing focus on the applications of LLMs within this sector. There are a few medicine-oriented evaluation datasets and benchmarks for assessing the performance of various LLMs in clinical scenarios; however, there is a paucity of information on the real-world usefulness of LLMs in context-specific scenarios in resourceconstrained settings. In this study, 16 iterations of a decision support tool for medical emergencies using 4 distinct generalized LLMs were constructed, alongside a combination of 4 Prompt Engineering techniques: In-Context Learning with 5-shot prompting (5SP), chain-of-thought prompting (CoT), self-questioning prompting (SQP), and a stacking of self-questioning prompting and chain-of-thought (SQCT). In total 428 model responses were quantitatively and qualitatively evaluated by 22 clinicians familiar with the medical scenarios and background contexts. Our study highlights the benefits of In-Context Learning with few-shot prompting, and the utility of the relatively novel self-questioning prompting technique. We also demonstrate the benefits of combining various prompting techniques to elicit the best performance of LLMs in providing contextually applicable health information. We also highlight the need for continuous human expert verification in the development and deployment of LLM-based health applications, especially in use cases where context is paramount.",
  "full_text": " \n \nPrep rint: Unde r Revi ew [V OL UME # TB D]: 1 – 21 , 2 0 24  Machin e Le a rning f o r H ealth care  \nCan Large Language Models Pro vide Emergency Medical  \nHelp Where Ther e Is No Ambulance? A Comparati v e Stud y on \nLarge Language Model Understanding of Emergency  \nMedical Scenarios in Resource-Constrained Settings \nPaulina Boadiwaa Mensah  \nSnooCODE Red Development Team SnooCODE  \nAccra, Ghana  \nORCID: 0000-0002-0570-5662  \n \nNana Serwaa Quao  \nAccident and Emergency Centre Korle Bu Teaching Hospital  \nSnooCODE  \nAccra, Ghana \nORCID: 0000-0001-8476-5999 \n \nSesinam Dagadu  \nSnooCODE Red SnooCODE Accra, Ghana  \ns.dagadu@snoocode.com\n  \n \nCohort 2, \nProject Genie Clinician Evaluation Group \nGhana  \nprojectgenie314@gmail.com  \n \n  \nAbstract  \nThe capabil it ies of Large Lan guage M odels (LLMs) ha v e ad v anced sin ce their po pulari zation  \na f ew y ears ago. The healthcar e se ct or op er ates on, and gener ates a lar ge v olu me o f data  \nannuall y and thus, ther e is a gr owing f o cu s on the applicat ions of LL Ms wi thin t his sect or .  \nTher e ar e  a few medicine -or iente d e v aluation datasets and bench mar ks f or assessi ng the \nperf orman ce of v ari ous L LMs in clin ical s ce narios; how e v er , ther e is a pauc ity of inf or mati on  \non the r eal-w orld usefulness of L LMs  in c onte xt -spec if ic s cenari os in r eso ur cec onst r ained  \nsettin gs. In this stud y , 16 iter at ion s of a de c isi on supp ort to ol f or med ical e mergen cies  usin g  \n4 dist inct gener alized LLMs w er e cons t ruc ted, alongs ide a co mb inat ion of 4 P r ompt  \nEngineer ing tec hni ques : In- C onte xt Learni ng wit h 5 -sh ot pr om ptin g (5 SP), cha in- of -t hou gh t  \npr omp tin g (Co T), self-ques ti onin g pr o m pting (S Q P), and a stacking of self -que s tion ing  \npr omp tin g and chain -o f-t ho u ght (S Q CT). In total 428 model r espon ses w er e quantit ati v el y  \nand qualitat i v el y e v aluated b y 22 cl ini c ians f amil iar wit h the medi cal scenari o s and \nbackgr oun d c on te xts. O ur stu d y h i ghl i ghts the benef its of In - Con te xt Learn ing w ith  f ew-sh o t  \npr omp tin g, and the utility of the r elati v el y  no v el self-quest ion in g pr om ptin g te chn iq ue. W e  \nalso de monstr a te t he benef its of co m bin in g v ari ous  pr o mpt ing  te chn iq ues t o el ic it t h e best  \nperf orman ce of LLM s in pr o vid ing con t e xtuall y applicable health inf or mati on. W e also  \nhi ghl i ght t he need f or c ontin uo us hu ma n e xpert v erifi cati on in t he de v elop ment and  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 19, 2024. ; https://doi.org/10.1101/2024.04.17.24305971doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\nSho rt T itl e  \n2  \ndeplo yment of L LM - based health ap pli cations, espe ciall y in use cases w her e c on te xt i s  \npar amoun t .  \n1.  Introduction \nIn a pr e vious  stud y , it w as observ ed that the outputs of gener alized Large La nguage Models  \n(LLMs) v aried signi ficantl y w hen pro mpt ed t o p r o vide first  aid instruction s f or  managing  \nmedical emergencies, depending on whether backgr ound con t e xt  w as  included or  e x cluded. \nMensah et al. ( 2024). F or e x ample, k eeping pr ompt instructions, m odel type and model \npar amet ers constant , the addition or e x clusion of  background cont ext as simple as:  \n“ Loc ation: busy mark et in rur al A tebubu, Ghana. Ther e  is a  maternit y home 5km a way , a  \nc hemist ,  20 km away ,  a CHP S c ompound 39. 8km a way , and a ho spital 5 0km aw ay ” ,  c h a n g e s  a t  \nleast one of the f ollowing parts o f the r esponse: the possi ble diagnoses gi v en, the or der of  \nthe possible diagnoses  gi v en, the or der of  fir st aid instructions gi v en, and the cont ent of  fi rst  \naid instructions gi v en. In managing me dical emergencies, a lt ering the sequence of  pot ential \ndiagnoses and  fir st aid instructions,  e v en if the con t ent r emains unchang ed, can impact  \npatient out comes. This is because he althcar e pr o viders oft en addr ess issu es in the or der \nsuggest ed, and timel y int erv ention is cr ucial f or addr es sing the mo st critical problems ef-  \n© 2 024  .  \nf ecti v el y . In int ernal e xperiments , this patt ern w as consist ent acr o ss se v er al popular LLMs \nt est ed, with a n otable dif f er ence in  s emantic similarity betw een model ou tputs, r anging \nfr om 20% to 30% , w hen backgr ound  cont e xt w as omitt ed v s included in t he pr ompt . In  \nbuilding LLM-based t ools f o r clinical applications, tha t loss can be clinicall y costl y . Th e  \nimplication is that t o deri v e genuine c l inical utili ty fr om LLMs, it is insufficie nt f or them t o  \nmeet standar d medical benchmarks;  their per f ormance i n di v erse c onte xts must be  \nassessed. Otherwise, r esponses deeme d beneficial in certain situations ma y not onl y pr o v e \nineff ecti v e in others but could also p os e pot ential harm. \nUnf ortunat el y , amongst the popular biomedical Natur al Language Pr ocessing (NLP)  \ndatasets f or e v aluating LLMs , none of them ha v e been specificall y  pr epar ed f or  \nr esour ceconstr ained  settings as  f ound  in Lo w-and Low -Middle-Income cou ntries (LMICs)  \nZhou et al. ( 2023). Thus, thoug h a f ew models achie v e high scor es w hen e v aluat ed on these \ndatasets, th eir tr anslational v al ue in e v ery da y clinica l scenarios in r esource-constr ained  \ncannot be r eadil y ascertained. \nMor eo v er , in  r e sour ce-co nstr ained s ettings, the ability t o  o btain, cr eat e, o r utilize  \nspecialized , domain-specific models i s gr eatl y limit ed b y f act ors  such as cost . Pr e vious \nr esear ch has  demonstr at ed  that emplo ying ad v anced pr ompting  str at egies  wi th gener alized \nLLMs can yield out comes surpassi ng those of  specialized medical LLMs , as e videnced b y  \nMedPr ompt . Nori et a l. ( 20 23). If gener alized mode ls, w hich ar e oft en more accessible t o \nbr oader  populations, can be optimized t o  achie v e compar able o r superior  perf o rmance t o  \nspecialized medica l LLMs thr ough sim pler pr ompt engineerin g t echniques, t hen de v elopers \nin r es our ce-con str ained settings  can l e v er age this opp ortunity t o  cr eat e  ef fecti v e y e t cost-\nefficient applications tailor ed t o  their e n vir onments. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 19, 2024. ; https://doi.org/10.1101/2024.04.17.24305971doi: medRxiv preprint \nSho rt T itl e  \n3  \nIn this stud y , our  o bjecti v e is to  contri but e to the scant kno w ledge ba se r eg a r ding LLM  \napplications f or  clinical scenarios in lo w- and middle-income countries (LMI Cs), w hile also  \nserving as a  r e f er ence f or  futur e, mo r e compr ehensi v e r esear ch. Specificall y , w e aim t o  \nassess the suitability of certain select ed gener alized LLMs as clinical de cision support t o ols  \nf or  managing medical emergencies in LMICs. This stud y f orms  part o f a b r o ader r esear ch  \nand de v elopment ini tiati v e aim ed at  e v entual l y i mplem enting such t ools in r esour ce-\nconstr ained settings. \nGeneralizable Insights about Machine Learning in the Context of Healthcare \n1.\n T o the best o f our know ledge, this is the fir st compar ati v e stud y with clinician \ne v alua tion t o  in v estig at e the ef f ecti v eness o f stat e-of -the-art gener alized LLMs in \npr o viding first aid in structions f or  r es our ce-limit ed settings with di v erse prompting \nstr at egies. \n2.\n W e t est and c ompar e two uncommon  pr ompting str at egies, namel y self-questioning  \npr ompting: w hich elicits inf ormati v e questions pertinent t o the clinical sce narios at \nhand t o impr o v e the model’s r espone,  and a stacking of self- questioning prompting  \nand the mor e popular chain-o f-thought pr ompting t echnique(SQCT ). \n3.\n W e demonstr at e that pr ompting t ec hniques ar e not o ne-size-fits-all, i.e. diff er ent  \npr ompting t echniques might elicit bett er r espon ses in  dif f er ent models. \n4.  Our findings emphasize the need f or continuous human e xpert v erific ation in \ne v alua ting the clinical uti lity of LLM-based health appli cations. \n2.  Related W ork \nIn this section, w e r e view the r ele v ant l it er atur e on large language models app lied t o clinical \nlanguage understanding tasks in health car e, as w ell as existing p r ompting str at egies. \n2.1.  LLMs in Healthcare for Resource-Constrained Regions \nPrior studies ha v e shown  that though ther e ar e vital concerns  to  be  addr ess ed, the gener al \nconsensus i s that LLMs hold immense pot ential in impr o ving  healthcar e del i v ery w hen the y \nar e inco rpor at ed  in  v arious  capacities s uch as: in  aut omation  of  administr ati v e  tasks, clinical \ndecision support t o ols, virtual he alt h  assistants, scr eening t ools, health tr ack ers, clinical  \nlanguage tr anslation t ools, medical r esear ch and health educ ation t ools Goodman et al. \n( 2023) T ripathi et al. ( 2024) Sallam ( 2023) Abu-Je yy ab et al. ( 2023). These  functions  can \naugment the li mit ed financial, logi stical and human r esour ces a v aila ble in LMICs  \nGang a v ar apu ( 2023). Initial studies on  clinician per ception  on  the u sefulness o f  a \ncombination of  OpenAI’s “gpt-3.5-turbo  / “gpt-4”  and R etrie v al A ugment ed Gener ation  \n(RA G), as  a health education t ool in In dia, an LMIC, r e v ealed tha t though clin icians belie v ed \nthe t ool held po t ential, the y w er e gene r all y not satisfied with its per formance Al Ghadban  et  \nal. ( 2023). In that stud y , the authors identified the need  t o  enhance the cont e xtual and  \ncultur a l r ele v ance of the models r esponses. Another c ompar ati v e stud y  of a clinician  \ne v alua tion of  Almanac, an LLM fr amew ork  based  on  OpenAI’S “t ext-da vinci-003” combined  \nwith RA G, v ersus ChatGPT r e v eals that though clinicians r at ed Almanac’s an sw ers as  sa f er  \nand mor e f actual, the y sti ll pr ef err ed ChatGPT’s answ ers Zakka et a l. ( 2024) . How e v er , this  \nstud y does not  r e v eal w hether the clinicians shar ed their per specti v e on th e usefulness of  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 19, 2024. ; https://doi.org/10.1101/2024.04.17.24305971doi: medRxiv preprint \nSho rt T itl e  \n4  \nan y of the models f or  e v ery da y clinical scenarios, neither does it captur e the p erspecti v es of \nclinicians w ho p r actice in LMICs. \n2.2.  Prompting strategies \nF ew-shot prompting: F ew-shot  pr om pting in v ol v es gi ving the model demonstr ations o f the \ntask at hand usual l y in the f ormat of “User:” follow ed b y an ex ample user input and \n“Model/Assistant: ” follow ed b y an  e xp ect ed model r esponse. When onl y one demonstr ation  \nis gi v en, it is  t ermed one -shot p r ompting B r own  et al. ( 2020). When fi v e demonstr ations  ar e  \ngi v en, it is t ermed fi v e shot  pr omptin g (5SP),  and w hen n o demo nstr ations  ar e gi v en it is  \nt ermed zer o-shot p r ompting. \nA stud y assessing the perf ormance o f a n LLM on health-r elat e d tasks f ound that f ew shot  \npr ompting led t o g r eat er incr eases i n the model’s accur ac y and decr eases in err o r as  \ncompar ed to  zer o-sh ot p r ompting, and  e v en  f ew -shot  supervised  tr aining  Liu et al. ( 2023a). \nA stud y comparing the perf ormance of a combination of v arious gener alized LLMs and  \npr ompting t echniques on  questions  in  the thor acic  surgery d omain r e v ealed that f e w-shot  \npr ompting outperformed zer o -shot  pr ompting. F urthermor e, fi v e-shot pr ompting  \nconsist entl y outperf o rmed one-sh ot p r ompting Li et al. ( 2023) . A n o t h e r  s t u d y  c o m p a r i n g  \nzer oshot prompting t o  fi v e-shot p r omp ting acr oss  v arious clinical and bi omedical tasks, also \nf ound that o v er all, fi v e-shot pr ompting e x ceeded zer o-shot prompting Labr ak  et al. ( 2023). \nChain-of-thought prompting: Chain- of-thought prompting (CO T)  in v ol v es leading the \nmodel t o  b r eak down  c omple x  tasks i nt o i nt ermediat e st eps,  so  it  can f ollo w a  st ep- b y st ep  \nappr oach t o a rri v e at its r espon se. This appr oach has been t out ed to i mpr o v e model  \nr easoning  and per f ormance W ei et al. ( 2022) . A  s t u d y  c o m p a r i n g  C O T  w i t h  t h e  f e w - s h o t  \npr ompting str at egy  using  the Flan-P aL M 540B model across  a r an ge o f  benc hmark medical  \nquestion-answ ering tasks, did not fin d substantial impr o v ement o v er f ew-shot pr ompting  \nSinghal et al. ( 2023). \nSelf-questioning: Self -questioning  prompting (SQP), is  a r elati v el y new strat egy w hich \nelicits impr o v ed questions based on  t he original user input to gener at e  additional cont e xt  \nf or  the original i nput , with the aim of  g ener ating a bett er model  r espon se. Thi s approach has  \nbeen shown  to  elicit bett er m odel p erf o rmance compar ed  t o  5SP  acr o ss  a f ew  clinical \nlanguage understanding tasks Wa n g  e t  a l . ( 2023). How e v er , this appr oach  has not been \nt est ed in multiple end-user scenarios. \n2.3.\n Model selection and parameters \nA compar ati v e stud y on clinical t e xt s ummarization acr oss eight LLMs and v arious model \nt emper atur es r e v ealed tha t GPT-4 and the low est t emper atur e (0.1) yielded t he best r esults \nV an V een et al. ( 2024). In anoth er compar ati v e L LM stud y on v arious clini cal benchmark \ndatasets spanning multip le tasks , GPT-4 outperf ormed GPT-3.5 and Bar d [ K]. Another stud y  \ncomparing the per f ormance of  Claude-instant-v1.0 , GPT-3.5-T urbo, Command xlarge-nightl y ,  \nand Bloomz, in thr ee clinical specialti es found that diff er ent models per f o r med bett er on \ndiff er ent  metrics  Wilhelm et al. ( 2023) . A n o t h e r  s t u d y  c o m p a r i n g  t h e  p e r f o r m a n c e  o f  G P T -\n3.5, P aLM-2 , Claude-2, and LLaMA-2 o n 6  biomedical tasks  found that the b est performing  \nLLM v aried acr oss v arious  tasks Jahan et al. ( 2024). \n2.4.\n Methods F or Evaluating the P erformance of LLMs in clinical tasks \nA stud y e v alu ating the perf ormance of v arious LLMs on ans w ering clinic al questions in  \nRadiology measur ed their perf orma nce ag ainst two datasets in Radiol ogy and using  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 19, 2024. ; https://doi.org/10.1101/2024.04.17.24305971doi: medRxiv preprint \nSho rt T itl e  \n5  \nR ecall@1 , R ecal l@2 and R ecall@L as  metrics Liu et al. ( 2023b ). This ca n be  a useful  \ne v alua tion rubric  but ma y n ot be  applicable t o clinical domains/scenari os  in w hich dif f er ent  \ncont e xts  might necessitat e diff e r ent appr oaches t o  diagnosi s and manage ment . Another  \npublication pr oposes  “ Artificial-int elligence Structur ed Clinical Ex amina tions” as an  \ne v alua tion fr amew ork that uses agent-based simulations t o mimic r eal w orld clinical  \nscenarios Mehandru et al. ( 2023). Though pr omising, this fr amework has not been  \nthor oughl y studied or implement ed . In another stud y e v alua ting a r adiological vision-\nlanguage model’s output, the au thors emplo y ed both aut omat ed e v alua tion via the popular \nNLP metrics such as BLEU sco r e and Rouge-L, and human e xpert e v aluation, noting that the  \nf ormer  could not p r operl y assess  for  factual corr ectness and consi st ency – pr operties that \nar e vital for  clinical utility T anno  et al. ( 2024). Another  stud y on  LLM outputs f or  medical \ne vidence summarization tasks a lso emplo y ed both aut omatic and hu man e v alu ation. The y  \ndefined summary quality based on coher ence, f actual consist ency , compr eh ensi v eness, and  \nharmfulness Ta n g  e t  a l . ( 2023). The r esear chers concluded that aut omatic m etrics oft en  do  \nnot str o ngl y corr elat e with the quality of summaries. Another stud y on  the p erf o rmance on  \nmedical LLMs on clinical application tasks also emphasized the limitations o f aut omat ed \nmetrics t o measur e clinical u tilit y and emplo y ed hu man e xperts t o r at e mod el answ ers on:  \nagr eement with scientific and clinical consensus, the pr esence of  incor r ect cont ent , the  \nomission  o f co nt ent , the e xt ent o f po ssi ble harm, the lik eli hood of  harm, and p ossible bias in  \nansw ers Singhal et al. ( 2023). A p r op o sed e v aluation fr amew ork  f o r the impl ementation of \nArtificial Int elligence sy st ems int o healthc ar e settings pr oposes  that AI applications be \nassessed on thr ee main compone nts: adoption, capability , and uti l ity , with 15  \nsubcomponents  such as  saf ety an d quality , non-maleficence, gener al izability and \ncont e xtualization R edd y et al. ( 2021). In a r ecent stud y , r esear chers asses sed the output of a  \nmedical LLM b y asking  human exper ts t o  asses s  the model’s r espo nses  o n a  17-metric \ne v alua tion rubric along fi v e ax es: accur acy , saf ety , f airness, int erpr etation and \ncommunication Bosselut et al. ( 202 4 ) . A n o t h e r  s t u d y  o n  c l i n i c a l  t e x t  s u m m a r i z a t i o n  \ncompar ed LLM summaries to  summaries b y medical e xperts  on  co rr ectnes s, conciseness  \nand complet eness and f ound that NLP metrics corr elat ed poorl y with clinician pr ef er ences, \nemphasizing that NLP metrics ar e ina dequat e in as sessing  clinical r eadines s o f  LLMs Va n  \nV een et al. ( 2024). \n3.  Methods \nIn this section, w e detail our  e xperime ntal setup and anal y tical t echniques. \n3.1.  Selection of medical scenarios and clinician evaluators \nW e simulat ed 10 common emergency medical scenarios in Ghana c ollabor ation with a panel  \nof  12 clinicians led b y an  emergency medicine specialist with 12+ y ears of  pr actice \ne xperience in  Ghana. The clinical sc enarios  f eatur ed a  di v erse r ange of  demogr aphic  \nchar act eristics with patient ages spann ing f r om 5 m onths t o  50 y ears and f eatur ed an equal \ndistribution o f  male and f emale patients. The clinical scenarios  also cut across  major  clinical \nspecialties inclu ding Int ernal Medicin e, Obst etrics and G ynaecology , Gener al Surgery and \nP aediatrics . These scenarios w er e then incorpo r at ed int o prompt t emplat es that w er e f ed \nint o models and e v aluat ed b y a dif f er ent set of 22 clinicians. Clinician e valuat ors w er e  \nselect ed via a local  clinician network , from di v erse  pr actice locations  within Ghana  and \nbased on their f amiliarity with the lo cations, cont e xts, and clinical scenarios. All clinician  \ne v aluat ors had at least 2 y ears of c linical pr actice e xperience in r esource-constr ained \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 19, 2024. ; https://doi.org/10.1101/2024.04.17.24305971doi: medRxiv preprint \nSho rt T itl e  \n6  \nsettings in Ghana, specificall y as the fi rst point- of-call in the hospital in  managing medical \nemergencies in Ghana. It is expect ed that the y possess su fficient kno w ledg e and skills to \ndeli v er , at a minimum, first aid in the se lect ed medical scenarios. \n3.2.\n Model selection \nW e t es t ed Open AI’s  GPT-4-0125 Pre view , via the OpenAI Assistants Platf om, Gemini 1.5 Pr o  \nvia Google AI Studio, and both Claude Sonnet and Opus  via the Anthr opic C onsole. These  \nmodels w er e  select ed based on  per f or mance on  popular  benchmarks, their ranking on  the \nLMS Y S Chatbot Ar ena Leaderboar d  as of 13th April 2024, a v ailability of API, ease of  access  \nand for  further  cost- benefit r atio c o mpar ati v e ana l y sis Zhou et  al. ( 2023) Chiang  et al. \n( 2024). W e did not select similarl y- r ank ed open-sour ce medical LLMs b ecause of the \ncomputational r esour ces r e quir ed t o  r un/access them, f or ex ample, ad v anced  GPUs. \n3.3.\n Parameter Tuning \nThe GPT-4-0125 Pr e view model w as  s et t o the def ault t emper atur e of 1  due to the difficulty \nin tw eaking the t emper atur e at t he tim e of running  the t ests (r ef e r ence documentation w as \nonl y r ecentl y upd at ed t o mak e this option r eadil y accessible). Similarl y , t he Gemini 1.5 Pr o  \nmodel w as t est ed at its def ault t emper atur e of 2 as  this could not be easil y modified. The \nClaude Sonnet and Claude Opus mo dels w er e b oth t est ed at a  t emper atur e of  0. This  \nappr oach w as  to gener at e det erminist ic r esp onses  as  o ft en  as  possi ble due t o the c ritical \nnatur e of the use case and w as guided b y findings  from int ernal t ests and  findings from \nr esear ch studies detailed in Section 2.3 abo v e. \n3.4.\n Prompt Engineering \nF our pr ompt engineering t echnique s w er e t es t ed: In-C ont ext Learning  with 5-shot \npr ompting (5SP), chain-of -thought pr ompting (CoT), self- questioning p r ompting (SQP), and  \na stacking of self -questioning p r ompt ing and chain-of-thought (SQCT ). A g ener al pr ompt  \nstructur e w as pr o vided, and the pr ompt modified t o suit the t echnique being t est ed. The \ngener al pr ompt structur e co nsist ed of  the sy st em message/instruction a nd the clinical \nscenario. The last pa rt o f  the pr omp t consis t ed o f  a modi fication based on the p r ompt  \nt echnique being t est ed. Figur e 1 show s the gener al pr ompt structur e, an d an e x ample \npr ompt acr o ss the f our  t echniques t ested. The pr ompt modifications  ar e highlight ed.  \n3.5.\n Distribution of Prompt-Response Pairs to Evaluators \nEach of  the  four  models t est ed w as  pair ed with  each o f  the f our  prompt t ech niques yielding  \n16 model-pr ompt combi nations. Eight model-pr ompt combi nations w er e r un twice, and \neight model-pr ompt combinations  w ere run thrice, this p r oduced 40 t e st ru ns. F or each of  \nthe 10 clinical scenarios, f our model-p r ompt combination s w er e t est ed, and t heir r esponses  \npr esent ed for e v aluation. Each clinic ian w as assigned  t o blindl y e v aluat e 20 pr ompt-\nr esponse pairs with a t otal of 440 complet e e v al uations e xpect ed. Figur e 2 show s a  \nvisualiza tion of the e x act model-prompt t echnique pairs and the number of ti mes the y w er e \nrun. \n3.6.\n Response Evaluation \nClinicians w er e t old the y w er e r ankin g AI models but w er e not t old w hich  models w er e \nbeing r ank ed and  w hich r esp onse  w as gener at ed  b y  w hich model. Eac h pr ompt  w as  \nf ollow ed  b y  4  r espo nses  and  each r esp onse  w as  gr aded  on  accur acy , conciseness,  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 19, 2024. ; https://doi.org/10.1101/2024.04.17.24305971doi: medRxiv preprint \nSho rt T itl e  \n7  \nhelpfulness and then an o v er all scor e. Gr ading w as  done  on  a 10-p oint Lik er t scale, with 0 \nr epr esenting “T otall y Unsatisf act ory ” and “T otall y Satisf act ory ” . A t the e nd of  the f our  \nr esponses  t o each prompt , a comment box w as p r o vided, and e v aluat ors ask e d t o input an y \nadditional comments the y had ab out the prompt and  r espo nses. An  ex am ple e v aluation  \nf orm  is shown in  the Appendix A. \n3.7.\n Collection and Anal ysis of Evaluation Reports \nE v alu ation r eports w er e collect ed via an online f orm. Data p r epar ation, quantitati v e anal y sis \nand associat ed data visualizations w e r e performed in  Micr os oft E x cel V ersion 16.83 and \nwith Python 3.11 Pyt . The R eal Statistic s R esour ce P ack 14 w a s used f o r Int errat er \n \nFigur e 1: Di ff e r ences in p r ompt based on prompt t echnique \nR eliabilit y Anal y sis re a . F or  qualitati v e anal y sis, e v aluat ors’ comments w er e  compiled as t e x t  \nin a document and coding w as per f or med using T aguett e 1.4.1-40-gf ea8597 15 Rampin and \nRampin ( 2021). Subsequent l y , thema ti c anal y sis and data visua liza tion w er e perf o rmed in  \nPython 3.11. F or the data wr angling process 12  entries had n o r atings  across  the e v alu ation  \nrubric and w er e tak en out lea ving a t otal of  428 entries for the sub seq uent anal y sis. \nF urthermor e for  the co rr elation anal ysis, 2  r atings  with n o  o v er all sco r es  wer e tak en out . \nMean imputation w as  then per f ormed  f or  the following mis sing  v alues: 3 missing r atings  \nunder ”Concisenes s” , 1 under ” Accur acy ” 2 under ”Sa f ety ” and 1 under ”Helpfulness” . \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 19, 2024. ; https://doi.org/10.1101/2024.04.17.24305971doi: medRxiv preprint \nSho rt T itl e  \n8  \n4.  Results \nIn this section, w e p r esent a  compr ehe nsi v e quantitati v e anal y sis of  the per f o rmance o f  the \nLLMs, the pr ompts and the LLM-pr om pt pairs ba sed on  clinician e v aluation. W e  beg an  b y  \ncomparing the per f o rmance o f  the models, in t erms  of  accur acy , concisene ss, helpfulness \nand the o v er all scor e of  their r esp onse s. Ne xt , w e c ompar ed the v arious p r o mpt t echniques \nalso on accur acy , conciseness, helpful ness and the o v er all scor e. Then w e compar ed the \nmodelpr ompt t echnique pairs based  on  the same rubric. Next , w e in vestig at ed the  \ncorr elation betw een accur acy , concise ness and  helpfulness of  r esp onses  wi th the o v er all \nscor e. Ne xt , \n \nFigur e 2: Model-Pr ompt T echnique Co mbinations P er Number of  R uns  \nw e assessed  int err at er  r eliability . Fin all y , w e pr o vided a qualitati v e anal y s is o f clinician  \ncomments. \n4.1.\n Comparison of Model Performance Based on Clinician Rating \nThe f our LLMs: GPT-4-0125-Pr e view , Gemini 1.5 Pr o, Claude Sonnet and Claude Opus w er e  \ncompar ed based on r espon se concisen ess, accur acy , saf ety , helpfulness and o v er all scor e as \ngr aded b y e v aluat ors. The mean r atings w as  calculat ed f or  each model a cr oss  the four  \ndiff er ent  pr ompt  t echniques t es t ed. All the LLMs had the low est sc or e s in  r esp onse  \nconciseness  and the highest scor es  i n r esp onse helpfulness a s c ompar ed t o  the other  \ncat egories. Claude S onnet scor ed  the highest scor es  acr os s  the e v aluation r ubric. T able  1 \nshow s  the mean r ating sco r es with the highest in each cat egory highlight ed in bold. \nT able 1: Mean Clinician Rating o f Select ed LLMs on a  10-point Lik ert scale  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 19, 2024. ; https://doi.org/10.1101/2024.04.17.24305971doi: medRxiv preprint \nSho rt T itl e  \n9  \n \nGPT-4-0 1 25-P REV IEW v ia O p enAI Assi stant  5.2 3  6.7 9  7.0 9  7.2 6  6.9 4 (1. 5 8)  \nGEMI NI 1 .5 P R O  7.1 1  6.9 8  7.0 6  7.1 8  7.1 5 (1. 5 8)  \nCLA U DE SONN ET  7.48  7.49  7.7  7.74  7.7 (1. 3)  \nCLA UDE OPUS  6.3 5  7  7.1 5  7.2 2  7.2 8 (1. 7 6)  \n \n4.2.  Comparison of Prompt T echniques Based on Mean Clinician Rating \nThe f our p r ompt t echniques t est ed wer e also compar ed based on the r ating of  the model \nr esponses  gener at ed  b y  the prompts. The mean  r atings  f or  each prompt technique w er e  \ncalcul at ed acr oss all the f our models t est ed. Ag ain, the low est scor es w ere f or r espon se \nconciseness and  the highest f o r r e spo nse helpfulness. R esponse sa f ety w as  almost at par \nwith r espon se helpfulness. T a ble 2 sh ow s  the mean r ating sc or es  with  the highest in each  \ncat egory highlight ed in bold. \nT able 2: C omparison  o f Prompt T echni ques P er R esponse  Rating \n \nPr ompt T ech niqu e  Conc is en es s  A ccur ac y  Safety  Helpfulnes s  Ov er all Scor e (s.d. )  \n \n5SP  6.62  7.4  7.6  7.67  7.47 (1.43)  \nCoT  6.32  6.74  6.83  6.83  7.06 (1.74)  \nSQ P  6.88  7.1  7.36  7.36  7.25 (1.4)  \nSQ CT  6.36 7.05 7.1 7.1 7.23 (1.76)  \n \n4.3.  Comparison of Model-Prompt T echnique Combinations based on MeanClinician \nRating \nThe 16 model-pr ompt t echnique c omb inations w e r e compar ed  acr os s the e valuation rubric \nand the findings summarized in T able  3 and T able 4 . Claude Sonnet + SQC T  pr oduced the  \nbest r at ed r esp onses gener all y , w her ea s Gemini 1.5 Pr o + Co T o r GPT-4 -0125 Pr e view + Co T  \npr oduced the least-r at ed r esponses  across the e v aluation rubric. \nT able 3: Best-P er f ormin g Model-Pr omp t T echnique Co bination P er E v aluation Metric  \nE v alu at ion R ub ri c  High es t -R ank ed Mod el-Pr omp t T e c hniqu e  Me an Sc or e (s.d .)  \nCon cis ene ss  Claud e Sonn et +  SQP  8.24 ( 1.51 )  \nAc c urac y  Claud e Sonn et +  SQ CT  7.95 ( 1.29 )  \nSaf et y  Claud e Sonn et +  SQ CT  7.9 (1 .34 )  \nHelpfulness  Claud e Sonn et +  SQ CT  8.14 ( 1.28 )  \nOv er all Sc or e  Claud e Sonn et +  SQ CT  8.05 ( 1.17 )  \nT able 4: W or st-P erf o rming M odel-Pr o mpt T echnique Cobinatio n P er E v aluati on Metric \nE v alu at ion R ub ri c  Low es t -R ank ed Mod el-Pr omp t T e ch niqu e  Me an Sc or e (s.d .)  \nCon cis ene ss  GPT-4-0125- Previ e w +  C oT  4.63 ( 2.52 )  \nAc c urac y  GPT-4-0125- Previ e w +  C oT  6.28 ( 2.29 )  \nMod el  Concisene ss  A ccur ac y  Safet y  Hel p fu l n e ss  Ov e r allScor e ( s. d. )  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 19, 2024. ; https://doi.org/10.1101/2024.04.17.24305971doi: medRxiv preprint \nSho rt T itl e  \n10  \nSaf et y  Gem ini 1 .5 Pro +  C oT  6.43 ( 1.7 )  \nHelpfulness  Gem ini 1 .5 Pro +  C oT  6.61 ( 1.85 )  \nOv er all Sc or e  Gem ini 1 .5 Pro +  C oT  6.5 (1 .62 )  \n \nFigur e 3: R egr ession  anal y sis o f O v er all Scor e v s C onciseness, Accur acy , Saf ety and \nHelpfulness \n4.4.  Correlation between Response Conciseness, Accuracy , Safety andHelpfulness \nwith Overall Score \nA linear r egr essi on  model w as  fitted t o  det ermine the r elation between r espon se  \nconciseness, accur acy , saf ety and hel pfulness t o the o v er all scor e to det er mine w hich of  \nthese f act ors w as closel y r elat ed with t he o v er all scor e. As shown in Figur e 3 t he helpfu lness \nof the r esp onse had the highest corr el ation with the o v er all scor e. The r esp o nse saf ety had \nthe second highest corr elation. Appen dix B sho w s the suitability of the linear r egr essi on  \nmodel f or  the cor r elation anal y sis. \n4.5.\n Interrater Reliability \nT o measur e the agr eement betw een e v aluat ors on the o v er all scor e, w e u se Gw et’s A C2  \ncoefficient Gw e t  ( 2014). Gw et’s AC2 s cor e across  all the r atings  f or  o v er all scor e  w as  0.79 \ncorr espo nding t o  a moder at e t o str on g  agr eement betw een r at ers Gw et ( 201 4). Appendix C \nshow s  the full r esults of  the Int err at er R eliabilit y Anal y sis. \n4.6.  Qualitati ve Anal ysis \nMajority o f clinician c omments af firm ed the clinical accur acy of the r esp ons es. The second  \nmost common theme in the comments w as ab out clinicians adding first aid st eps the y  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 19, 2024. ; https://doi.org/10.1101/2024.04.17.24305971doi: medRxiv preprint \nShor t T itl e  \n11  \nper cei v ed as missing fr om  the model’s r esp onse.  Clinicians also  shar ed a few comments  \nabout diagnosis the y w er e expecting t o see that w er e missing f r om the responses.  F ew \ncomments e xpr es sed displeasur e or  di ssatisf action i n the r espo nses a ffirmin g the r elati v e l y  \nhigh r ating scor e s gi v en b y clinicians.  T able 5 d e s c r i b e s  t h e  c o d e s  u s e d  t o  e n c a p s u l a t e  t h e  \nthemes of clinician comments and Figur e 4 show s  the fr equency o f code s in all of the \ncomments left b y clinicians.  Figur e 5 i s  a  w o r d  c l o u d  t h a t  g i v e s  a n  o v e r v i e w  o f  t h e  m o s t  \ncommon wor ds and phr ases in the additional first aid instructions pr o vided by clinicians t o \nmake the r espon ses  bett er .  The  mo r e fr equentl y occurring  a  w or d  or  phr as e is,  the m or e  \npr ominent it is  in the wor d cloud.  \nT able 5: C oding of  E v aluat ors’  Commen ts \n \nFigur e 4: F r equency o f Codes  in E v aluat ors’  comments with the most f r eque ntl y occurring \ncode highlight ed . \no de  Description  Ex ampl e comment  \nm phasisO nMed icalExpertise E v aluator empha sizes  a need to seek fu rther  medic al \nmanageme nt b y an e xpert .  \n“Medical ev aluation is  r ecommen ded”  \nc cur ateRespo nse  E v aluator commen ds the  clinical accu r acy of the  \nr espo nse  \n“ All r e sponde rs  w e r e quite accur ate with  their  dif fer ential s a n\ndeli v ering  fi rst a id. ”  \naccur ateRe spon se  E v aluator comment s that  the r espo nse  is not clinic all y \naccur ate\n \n“Responde r B2  ho w ev er deviated”  \nu ickT r ans port  E v aluator empha sizes  the need o f quick t r ans porta tion  “arr an ge a  quick tr a nspo rtation ”  \nd ditionalFi rst AidStep  E v aluator added  at least  one a ddition al fi rst a id ste p.  “Some othe r mea su r es will include  shouti ng f o r he lp f r om o n l\ni sdia gnosi s  E v aluator disa gr ee s with at  least o ne of  the top  5 medical \ndiagnos is gi v en.\n \n“meningiti s an d diabetic  k etoacidosis  in m y opi nio n should  n\ntopmost dia gnose s. ”\n \no spitalP r ep  The ev aluator emphasi zes  in f or ming  the ho spital b ef o r e \npatient i s t r ans ported.\n \n“Immediate comm unication  with  the ho spital i s n e cessary to \npr epa r ation ”\n \na tis f actoryResp onse  E v aluator is pleased with  r e spon se.  “Good r es ponse s so  f a r . ”  \ne tting-Dea f Re spon se  The r e spon se is  not  app r op riate f or  the sett ing  “it is quite un r eali stic f or  a la yman  to ha v e o xy gen  and A ED a t\nRespon der  C”  \ni ssi ngDia gnos is  E v aluator empha sizes  that some e xpected dia gnosi s w a s \nmissin g i n r esp onse.\n \n“In a cou ntry  lik e Ghana  and  es peciall y in  ru r al settings,  m\ndiff e r e ntial dia gnosi s f or  this  scena rio ”  \nn d  t h e i r  ways  o\nl ook ers”  \no t be  amon g t h\ne nsu r e adequ a\nt  home as st at e\nm alaria  shoul d\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 19, 2024. ; https://doi.org/10.1101/2024.04.17.24305971doi: medRxiv preprint \nSho rt T itl e  \n12  \n \nFigur e 5: Visualization of  E v aluat ors’ comments under the AdditionalFirstAid St ep code  \nClinician Opinion on LLMs in First Aid Decicion Support T ools Clinicians w er e ask ed  \nt o shar e their opinion  on  LLMs being  used in first  aid decision  suppo rt tool s b y answ eri ng \nY e s / N o  t o  t h e  f o l l o w i n g  q u e s t i o n ,  a n d  t o  l e a v e  a n y  a d d i t i o n a l  c o m m e n t s  i n  a  t e x t b o x  \npr o vided beneath it: A first aid tool is being dev eloped for c all c entr es . B ystan ders/laypersons  \nc an c a ll  the c entr e  and  be dir ected  b y  a  r esponder on w hat  to do  in the  interim as they  wait  for \nEMS.  Do  you think  at  least  one  of t he models  you have a ssessed  today  will be  useful  if \ninc orpor ated into this tool?  All 22 clinicians r esponded Ye s  without an y additional  \ncomments. \n5.  Discussion \nThe r esults fr om both quantitati v e an d qualitati v e ana l y sis show that clinician e v aluat ors \nw e r e  g e n e r a l l y  s a t i s f i e d  w i t h  t h e  d i a g n o s i s  a n d  f i r s t  a i d  i n s t r u c t i o n s  o u t p u t t e d  b y  t h e  b e s t  \nperf o rming gener alized LLMs. This perf o rmance b y the LLMs is n otable considering that  \nthe y w er e neither speciall y built medi cal LLMs nor  had the y had an y  prior  pr etr aining o r  \nfinetuning f or  the tasks. Also, the prompting str at egies  t est ed w er e r elati v el y simple as \ncompar ed t o  mo r e s ophisticat ed state-of-the-art t echniques  lik e MedPr om pt Nori et  al. \n( 2023). The best perf o rming model-prompt t echnique combination in our st ud y , ac hie v ed a  \nmean r anking sco r e o f 8.05/10 w hi ch is pr omi sing. This is  a promisin g finding  for  \nde v elopers of  LLM-based health appl ications in r esour ce-c onstr ained settings w her e the  \nability t o cr eat e mor e specialized, do main-specific models and/or t o run them is gr eatl y  \nlimit ed. App lications of this natur e ha v e t he pot ential t o r educe g laring disparities in \nhealt hcar e deli v ery in countries lik e  Ghana. F or ex ample in  Ghana, per  es timat es b y  the  \nW orld Health Org anization (WHO), f or  e v ery t en cases r ef err ed b y the national ambulance  \nservice in Ghana in 2022, one did n ot r ecei v e eme rgency support either due t o lack of \nambulances or  bed  space  in  r ecei ving h ospitals fo r  A f r i c a  ( 2023). F or  those  who r ecei v e car e  \nat the hospitals, the r eport ed doc t or  t o  patient r atio i s 1:6500, w a y belo w the WHO’s  \nr ecommendation o f 1:1000 for  Africa  ( 2022) Mullan and Bry ant ( 1984). T o  e x acerbat e the \npr oblem, 81.3% of d oct or s ar e in  onl y 5 r egions, and o v er 60% of d oct or s  ar e in o nl y 5 \nt eaching hospitals in the country f o r Af rica ( 2022). If  LLM-based applications can be  \nde v eloped t o of f er  dependable fi rst aid  guidance tailor ed t o  the local co nt e xt , t hen in r egions  \nof  Ghana with limit ed ambulances and f ew  clinicians, as sistance can  b e e xt ended  t o  \nemergency victims b y la ypersons and  minimall y tr ained first aid  pr o viders. This assistance \ncan be p r o vided w hile ef f orts  ar e  made t o  access the services  o f m or e  qualif ied personnel. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 19, 2024. ; https://doi.org/10.1101/2024.04.17.24305971doi: medRxiv preprint \nSho rt T itl e  \n13  \nAn e x ample of such an application is the SnooCODE R ed app being de v eloped in Ghana. \nFigur e 6 sho w s a  v ersion of  the app in de v elopment. \n \nFigur e 6: A Scr eenshot of  the SnooCO D E RED  app under de v elopment \nAnother int er esting finding i s that more e xpensi v e LLMs ma y not necessaril y ha v e bett er  \nperf o rmance than less  e xpen si v e models, at least for  clinical tasks. In the same v ein, higher-\nr ank ed models on  popular  leaderboards ma y not  necessaril y perform  bett er f or  clinical use. \nThough leaderboar ds and model scor e s on  con v entional benchmarks ma y gu ide de v elopers \nin choo sing  models, f or  de v elopers  o f LLM-ba sed health applications, it is  important t o  \ncontinuousl y and thor oughl y t est models for the int ended use case  an d not r el y on  \nmainstr eam inf o rmation onl y . \nIt w as also int er esting to see the r esults from the t esting of  the Self-Questioning Pr ompt  \nt echnique. Its authors n ot ed that it  elicit ed bett er  model r esp onses  compar e d t o  the mo r e  \npopular Chain-o f-Thought pr ompting  t echnique and our findings  seemed to con firm  this \nclaim Wa n g  e t  a l . ( 2023). W e also  sugg est combining  Self-Questioning  and Ch ain-ofThought  \npr ompting t echniques and  t esting both  appr oaches to see w hich per f orm s bet t er . \nIt w as int er esting to see that some prompting t echniques elicit bett er r espo nses w hen  \npair ed with some models but not w hen  pair ed with others. E v en thoug h fi v e-shot pr ompting \nseemed t o be the best  pr ompting  t ec hnique o v er all, f or  Claude Sonnet , the stack ed Self-\nQuestioning and Chain-o f-Thought prompting t echnique seemed t o yield bett er r esponses  \nf or  the model. F urther e xperiments need t o be  performed to see i f this  beha viour is  \nc o n s i s t e n t  a n d  w h y  t h a t  m i g h t  b e  t h e  c a s e . I f  t h i s  b e h a v i o u r  p r o v e s  c o n s i s t e n t ,  i t  m i g h t  b e  \nw elcoming new s  in cases w her e as fi v e-shot pr ompting ma y use mor e tok ens than the oth er \npr ompting t echniques. \nThe r esults fr om  the qualitati v e anal y sis gi v e the impr essi on  that clinicians w er e  in  \nf a v our of  the LLMs being used  as first  aid decision support  t o ols. It w as  impressi v e that the  \ne v aluat ors unanimousl y affirmed the u sefulness of LLMS as first aid decision support t ools. \nHow e v er , as n ot ed b y the fr e quent additional first aid st eps gi v en b y clinici ans, thor ough \nw ork  has t o  be  done  befor e  such a  t o o l is  t est ed in  r eal-w orld settings. It w a s int er e sting to  \nanal yze t he common phr ases  in the a dditional first aid  st eps  gi v en b y clinic ians. The most  \ncommonl y occurring w o r d “w at er”  is  not surp rising  gi v en how clean w ater is vital for  \nsustaining lif e. Access  to clean, potable  w at er  can  be  a challenge in  the r es ource-constr ained \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 19, 2024. ; https://doi.org/10.1101/2024.04.17.24305971doi: medRxiv preprint \nSho rt T itl e  \n14  \nsettings simulat ed in this e xperiment . Ot her common phr ases lik e “consciousness ” , \n“ b r e a t h i n g ”  a n d  “ l i m b ”  a p p e a r  i n  a l m o s t  t h e  e x a c t  o r d e r  i n  w h i c h  t h e y  a r e  t o  b e  a s s e s s e d  i n  \nthe Ad v anced T r auma Lif e Support pro t ocol used b y emergency r esponder s a nd ph y sicians. \nTheir prominence in  clinician  comments show  the imp ortance of  asses sing  and cor r ecting  \ndef ects in  these ar eas  during  fir st aid pr o vision. It is  clear that an app r oach  o f c ontinuous  \nit er ation and collabor ation with user s and medical e xperts must be adopt ed in building \nLLM-based applications f or healthc ar e. As mor e AI r esear chers de vis e methods t o \naut omatical l y assess model per f orman ce, caution must be e x er cised, particularl y f or c ritical \nuses lik e this one. F or applica tions in LMICs especiall y , con v entiona l LLMS ma y f all short in \ncapturing the nuances of r esou r ce-co nstr ained settings and thus it is impo rtant t o in v ol v e  \nstak eholders from such settings in  t he de v elopment pr ocess  t o  ensur e  that LLM-based \nhealt h applications f or  such settings ca n ha v e r eal tr anslational v a lue . \nNext Steps Ne xt st eps include impr o ving model r esponses based on the fin dings from the \nstud y and fr om clinician f eedback. Also, a similar stud y is being conduct ed in v ol ving mor e \ne xperienced clinician  e v aluat ors, and  subsequentl y a larger  cohort  o f  clinicians. W e  hope  \nthat the findings from this  stud y can pr o vide s ome dir ection  f o r m or e  e xt e nsi v e r esear ch  \nthat w ould help alle v iat e the r esear ch g ap on  LLM applications in LMICs. lti mat el y , our goal \nis t o  de v elop LLM-based solutions t hat hold clinical v a lue f or low - and  middle-income  \ncountries (LMICs). \nLimitations Though our  stud y pr o v ides some insight on  clinician per ce ption of  LLM \nusefulness in  fi rst aid  decision  supp o rt t o ols for  r es our ce-con str ained settings, ther e ar e  \nob vious  limitations with this  stud y . Firstl y , a larger cohort  o f clinical scenari os w ould ha v e \npr o vided a  bett er as sessment of  the per f ormance of  the v arious  models  and p r ompt \nt echniques. Also, speciall y tr ained medical LLMs might ha v e pr o vided bett er r esp onses  as  \ncompar ed t o  gener alized LLMs f or  ou r use case. A g ain, it  would be helpful t o ha v e gott en  \nannotations fr om  mo r e experienced clinicians, e.g. fr om  emergency medicine specialists \nwith man y y ears  o f  pr actice in  Ghana. Ag ain, the experiment c ould ha v e been  conduct ed  f or  \nv arious r es our ce-constr ained  ar eas ou tside of  Ghana to  enhance the gener alizability of the \nfindings. F urthermor e, ethical and leg al consider ations o f using  the LLMs for pro vision  o f  \nfirst aid  ad vice ar e  not  addr essed in  th is stud y . F utur e w ork  sh ould e xplo r e t hese aspects t o  \ne xpedit e the application of LLMs  in r es our ce-constr ained settings. \nReferences \nPr oject Genie Clinician E v aluation G r oup (Ap ril, 2024) https://bit .l y/clinici an-e v aluat ors-\npr oject-genie  \nR eal statistics r esour ce pack. R etrie v ed Mar ch 19, 2024. URL h t tps://r eal-sta tistics. \nc om/fr eedownload/real-sta tistics-r esou rcepack/ . \nMohammad Abu-Je yy ab, Sall am Alr osan, and Ibr aheem Alkha w aldeh. Ha rnessing large  \nlanguage models in medical r esear ch and scientific writing: A  closer lo ok to the futur e:  \nLlms in medical r esear ch and scientific writing. High Y ield Medi c al  R eviews , 1( 2), 2023. \nY asmina Al Ghadban, Huiqi Y v onne Lu,  Uda y Ada vi , Ankita Sharma, Sride vi Gar a, Neelanjana  \nDas, Bhaskar K umar , R enu John, Pr a v een De v arsetty , and Jane E Hirst . T r ansformin g  \nhealt hcar e education: Harnessing  large language models for  f r ontline he alth w ork er  \ncapacity building using r etrie v al-augment ed gener ation. medRxiv, pages 2023–12, 2023 . \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 19, 2024. ; https://doi.org/10.1101/2024.04.17.24305971doi: medRxiv preprint \nSho rt T itl e  \n15  \nA B osselut et al. Meditr on:  Open  med ical f oundation  models  adapt ed f o r cli nical pr actice.  \nh ttps://doi.or g /10.21203/r s.3 .r s-4139743/v1 , 202 4. \nT .B. Br own, B. Mann, N . R y der , M. Subbiah, J. Kaplan, P . Dhari w al, A. Nee lakan ta n, P . Sh y am , G. \nSastry , A. Ask ell, et al. Language models ar e f ew-shot  learners. Ar X i v , a bs/ 2005.14 165,  \n2020. \nW ei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nik olas Angelop o ulos, Tianle Li,  \nDacheng Li, Hao Zhang, Banghua Zh u, Michael Jor dan, Joseph E. Gonzalez , an d Ion Stoica.  \nChatbot ar ena: An open platf o rm f or  e v aluating ll ms b y human pr e f er ence, 2024. \nW orld Health Org anization R egional Office f or  Af rica. Stak eholders urged t o tak e action t o  \nimpr o v e the distribution  o f  do ct ors  in  ghana, No v ember 7 2022. URL \nh ttps://www .afr o. who.int/ c ou n tri es/ ghana/new s/ s t ak eh older s-u r g ed- t ak e-ac t ion-impr ove-\ndis tribu tion-doc t or s-ghana . \nW orld Health Org anization R egional O ffice f or A frica. Basic emergency car e sa ving li v es in \nghana, June 2 6 2023. UR L h t tps://www .afr o. who.i n t/pho t o-st o ry/ basic-emer g ency-c a r e-\nsa ving-liv es-ghana . \nAg asth y a Gang a v ar apu. Llms: A pr omis ing new t ool  for imp r o ving  healthcar e i n lowr esou r ce  \nnations. In  20 23 IEEE Global Humanitarian T ec hnology C onfer enc e (GHT C) ,  p a g es 252–255. \nIEEE, 2023. \nRache l S G oodman, J  Randall P atrine l y Jr , T r a vis  Ost erman, Lee Wheless, a nd D ouglas B  \nJohnson. On  the cusp: C onsidering  the impact of arti ficial int elligence language models in  \nhealt hcar e. Med , 4(3):139–140 , 2023 . \nKilem L Gw et . Handbook of inter -r ater r eliabilit y: The definitive guide to measuring the extent \nof agr eement among r aters . Ad v anced Anal ytics, L LC, 2014 .  \nI. Jahan, M.T .R . Laskar , C. P eng, and J.X. Huang. A compr ehensi v e e v aluation of  large language  \nmodels on benchmark biomedical t e xt pr ocessi ng tasks. C omputers in Biology and  \nMedicine , 171:108 189, 202 4. URL h t tps ://doi.or g /10.1016/j.c ompbiome d.2024. 108189 . \nY Labr ak et  al. A zero-shot  and f ew -shot stud y o f  instruction- finetuned large language \nmodels applied t o clinical and biomedi cal tasks. Ar X i v , abs/2307.12 114, 202 3.  \nI Li et al. Unleashing the pow er of  language models in clinical settings:  A tr ailblazing \ne v alua tion un v eiling no v el t est design. medRxiv, 2023. \nH Liu et al. Large language models a r e f ew -shot health learners. Ar X i v , abs/2305.155 25,  \n2023a. \nZ Liu et al. E v alua ting large language  models f or  r adiolo gy natur al language pr oces sing.  \nAr X i v , abs/2307.13693 , 2023b.  \nN Mehandru et al. Large language m odels as  agents  in  the clinic. Ar X i v , a bs/2309.10895 , \n2023. \nP aulina Boadi w aa Mensah , Nana Serw aa Quao, Sesinam Dag adu, and Pr oject Genie Clinician \nE v alu ation Gr oup. All y ou need i s c onte xt: Clinician e v aluations of  v arious iter ations o f a  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 19, 2024. ; https://doi.org/10.1101/2024.04.17.24305971doi: medRxiv preprint \nSho rt T itl e  \n16  \nlarge language mode l-based first aid decision support tool in ghana. medRxiv, 2024. doi: \n10.1101 /2024 .04. 03.2 430527 6.  \nF r ed Mullan and John  H. B ry ant . Doct ors —bar e f o ot and  otherwise:  The  world health \norg anization, the unit ed stat es, and  global primary  medical car e. JA M A , 25 2(22):3146– \n3148, 1984 . doi: 10.1001/jama .1984 .0 33502200 52030 .  \nH a r s h a  N o r i ,  Y i n  T a t  L e e ,  S h e n g  Z h a n g ,  D e a n  C a r i g n a n ,  R i c h a r d  E d g a r ,  N i c o l o  F u s i ,  N i c h o l a s  \nKing, Jonathan Larson, Y uanzhi Li, W eishung Liu, et al . Can gener alist f ounda tion models  \nout compet e special-purpose tuning? case stud y in me dicine. ar Xiv pr eprint  \narXiv:2311.1 6452 , 2023. \nP ython Language R efer enc e, version 3 .11 . Python Softw ar e F oundation. URL h ttp://www . \npython.o r g . \nR.  Rampin and V . Rampin . T aguett e: open-sour ce qualitati v e dat a anal y sis. Jou rnal of  Open \nSour c e Soft war e , 6(68):3522, 2021. URL h ttps://doi.o r g /10.21105/joss.03522 . \nS.  R edd y , W . R ogers, V .P . Makinen , E. Coier a, P . Br own, M. W enzel , E. W eick en,  S. Ansari,P .  \nMathur , A. Case y , and B. K ell y . E v a lu ation fr amework to guide implementation of  ai \nsy st ems int o healthcar e settings. BMJ Health C ar e Inform. , 28(1):e10044 4,  2021. URL  \nh ttps://doi.or g /10.1136/bmjhci-2021-10 0444 . \nMalik Sallam . Chatgpt utili ty in healt hcar e education, r esear ch, and pr actice: sy st ematic  \nr e view on  the promising  perspecti v es and v alid concerns. In  H e a l t h ca re , v olu me 11, page  \n887. MDPI, 2023 .  \nK.\n Singhal, S. Azi zi, T . T u, et al. Large la nguage models encode clinical know l edge. Natur e , \n620:172– 180, 202 3. URL h t tps://doi.o rg /10.1038/ s41586-023 -06291-2 . \nL.  T a n g ,  Z . S u n ,  B . I d n a y ,  J .G . N e s t o r ,  A . S o r o u s h ,  P .A . E l i a s ,  Z . X u ,  Y . D i n g , G . D u r r e t t ,  J .  \nR ousseau, C. W eng, and  Y . P eng. E v alu ating large language models on medic al e vidence  \nsummarization. medRxiv,  2023.04 .22 .2328 8967 , 2023. URL  \nh ttps://doi.or g /10.1101/2023.04.22 .232 88967 . \nO .R . T anno, D . Barr ett , A. Sellergr en,  et al. Consensus, dissensus  and synergy betw een  \nclinicians and specialist f oundation models in r adiology r eport gener ation. Re s e a rc h  \nSquar e, 3(rs-3940387), 2024. URL h t tp s://doi.or g /10.21203/r s.3.r s-3940387/v1 . \nSatvik T ripathi, Rith vik Suk umar an, and T essa  S  Co ok. E fficient  healthca r e with  large \nlanguage models: optimizing clinical w orkflo w and enhancing patient car e. Journal of the \nA meric an Medic a l Informatics Asso ciation , page ocad258, 2024 . \nD . V an V een, C. V an Uden , L. Blank emeier , et a l. A dapt ed la rge languag e models can \noutperf orm  medical e xperts  in  clinic al t e xt  summarization. Nat Med, 20( 4):543–545 , \n2024. URL h t tps://doi.or g /10.1038/ s41591-024-02855-5 . \nY W ang  et  al. Ar e large  language mo dels r ead y for  healthcar e? a compar a ti v e stud y on \nclinical language understanding. Ar X i v , abs/2304.05368 , 2023 .  \nJ. W ei, X. W ang, D . Schu urmans, M. Bosma, F . Xi a, E. Chi , et al . Chain-of-thought pr ompting \nelicits r easoning  in  large language models. A dvanc es in neur al information pr oc es sing \nsystems , 35:24824–24 837, 202 2. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 19, 2024. ; https://doi.org/10.1101/2024.04.17.24305971doi: medRxiv preprint \nSho rt T itl e  \n17  \nT . Wilhelm, J. R oos, and R.  Kac zmar czy k. Large language models for  ther ap y \nr ecommendations acr o ss 3  clinical specialties: Compar ati v e stud y . J Med Inter net R es , \n25(10), 2023. URL h t tps://www .jmir .or g /2023/10/ e49324 . \nC yril Zakka, R ohan Shad, Akash Chaur a sia, Ale x R Dalal, Jennif er L Kim, Michael Moor , R o b yn \nF ong, Curr an Phillips, K e vin Ale x ander , Euan Ashle y , et al . Almanac—r etrie v a la ugment ed \nlanguage models f or  clinical medicine. NEJM AI , 1(2):AIoa2300068, 2024. \nHongjian Zhou, Bo y ang Gu, Xin yu Zou,  Yiru Li, Sam S Chen, P ei lin Zhou, Junl ing Liu, Yining \nHua, Chengf eng  Mao, Xian  W u, et al. A  surv e y of  large language models  in medicine:  \nPr ogr ess, application, and challenge. arXiv pr eprint arXiv:231 1.05 112 , 2023. \nAppendix A.  \nA sample f orm for c ollection of clinician r espon ses can be  found at this link: . It also how s  a  \nsection o f the clinical scenarios simulat ed. \nAppendix B.  \nThe figur es below demon str at e the suitability t ests performed f or  the linear r e gr ession. \n.1. Regression Anal ysis: Ov erall Score vs Accuracy \n \nFigur e 7: T est f o r Hom oscedasticity: Linear R egr essio n o f Ov er all Scor e  v s  Accur acy \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 19, 2024. ; https://doi.org/10.1101/2024.04.17.24305971doi: medRxiv preprint \nSho rt T itl e  \n18  \n \nFigur e 8: Distri bution of  R esiduals: Linear R egr ession  o f Ov er all Scor e  v s Accu r acy \n.2. Regression Anal ysis: Ov erall Score vs Safety \n \nFigur e 9: T est f o r Hom oscedasticity: Linear R egr essio n o f Ov er all Scor e  v s  Safety  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 19, 2024. ; https://doi.org/10.1101/2024.04.17.24305971doi: medRxiv preprint \nSho rt T itl e  \n19  \n \nFigur e 10: Distri bution o f R esiduals: Li near R egr essio n o f Ov er all Scor e  v s  Safety  \n.3. Regression Anal ysis: Ov erall Score vs Helpfulness \n \nT est for H omoscedasticity: Linear R egression of  Ov er all Scor e v s  Helpfulness \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 19, 2024. ; https://doi.org/10.1101/2024.04.17.24305971doi: medRxiv preprint \nSho rt T itl e  \n20  \n \nFigur e 11: Distri bution o f R esiduals: Li near R egr essio n o f Ov er all Scor e  v s  Helpfulness \nAppendix C.  \nT able 6: Int err at er  R eliability Anal y sis R esults  \nGw et’s A C2 Anal y si s   \nCoef fi cient  0.787107 29\nStandar ed err or (subje ct)  0.025558 62\nConf iden ce in terv al (low er bor der)  0.732630 39\nConf iden ce in terv al (upper bor der)  0.841584 2  \nStandar ed err or (to tal)  0.054777 84\nConf iden ce in terv al (low er bor der)  0.670351 09\nConf iden ce in terv al (upper bor der)  0.903863 5  \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 19, 2024. ; https://doi.org/10.1101/2024.04.17.24305971doi: medRxiv preprint ",
  "topic": "Medical emergency",
  "concepts": [
    {
      "name": "Medical emergency",
      "score": 0.5239020586013794
    },
    {
      "name": "Computer science",
      "score": 0.5017344951629639
    },
    {
      "name": "Resource (disambiguation)",
      "score": 0.496662437915802
    },
    {
      "name": "Medicine",
      "score": 0.2773120403289795
    },
    {
      "name": "Computer network",
      "score": 0.056196361780166626
    }
  ]
}