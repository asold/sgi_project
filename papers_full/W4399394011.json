{
  "title": "Knowledge Graphs as Context Sources for LLM-Based Explanations of Learning Recommendations",
  "url": "https://openalex.org/W4399394011",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2955785884",
      "name": "Hasan Abu-Rasheed",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2031392306",
      "name": "Christian Weber",
      "affiliations": [
        "University of Siegen"
      ]
    },
    {
      "id": "https://openalex.org/A2126101128",
      "name": "Madjid Fathi",
      "affiliations": [
        "University of Siegen"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4220699816",
    "https://openalex.org/W4385632485",
    "https://openalex.org/W4287964718",
    "https://openalex.org/W4320913703",
    "https://openalex.org/W3004035003",
    "https://openalex.org/W2951048068",
    "https://openalex.org/W4206183212",
    "https://openalex.org/W4297183943",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W4386265921",
    "https://openalex.org/W2154652894",
    "https://openalex.org/W4399452982",
    "https://openalex.org/W4236796914",
    "https://openalex.org/W4386203924",
    "https://openalex.org/W4380993239",
    "https://openalex.org/W4387322659",
    "https://openalex.org/W2982550454",
    "https://openalex.org/W4387162221"
  ],
  "abstract": "In the era of personalized education, the provision of comprehensible explanations for learning recommendations is of a great value to enhance the learner's understanding and engagement with the recommended learning content. Large language models (LLMs) and generative AI in general have recently opened new doors for generating human-like explanations, for and along learning recommendations. However, their precision is still far away from acceptable in a sensitive field like education. To harness the abilities of LLMs, while still ensuring a high level of precision towards the intent of the learners, this paper proposes an approach to utilize knowledge graphs (KG) as a source of factual context, for LLM prompts, reducing the risk of model hallucinations, and safeguarding against wrong or imprecise information, while maintaining an application-intended learning context. We utilize the semantic relations in the knowledge graph to offer curated knowledge about learning recommendations. With domain-experts in the loop, we design the explanation as a textual template, which is filled and completed by the LLM. Domain experts were integrated in the prompt engineering phase as part of a study, to ensure that explanations include information that is relevant to the learner. We evaluate our approach quantitatively using Rouge-N and Rouge-L measures, as well as qualitatively with experts and learners. Our results show an enhanced recall and precision of the generated explanations compared to those generated solely by the GPT model, with a greatly reduced risk of generating imprecise information in the final learning explanation.",
  "full_text": "Knowledge Graphs as Context Sources for LLM-Based\nExplanations of Learning Recommendations‚ãÜ\nHasan A. Rasheed1,*, Christian Weber 1 and Madjid Fathi 1\n1University of Siegen, Siegen, Germany\nAbstract\nIn the era of personalized education, the provision of comprehensible explanations for learning recommendations is of a great\nvalue to enhance the learner‚Äôs understanding and engagement with the recommended learning content. Large language models\n(LLMs) and generative AI in general have recently opened new doors for generating human-like explanations, for and along learning\nrecommendations. However, their precision is still far away from acceptable in a sensitive field like education. To harness the abilities\nof LLMs, while still ensuring a high level of precision towards the intent of the learners, this paper proposes an approach to utilize\nknowledge graphs (KG) as a source of factual context, for LLM prompts, reducing the risk of model hallucinations, and safeguarding\nagainst wrong or imprecise information, while maintaining an application-intended learning context. We utilize the semantic relations\nin the knowledge graph to offer curated knowledge about learning recommendations. With domain-experts in the loop, we design the\nexplanation as a textual template, which is filled and completed by the LLM. Domain experts were integrated in the prompt engineering\nphase as part of a study, to ensure that explanations include information that is relevant to the learner. We evaluate our approach\nquantitatively using Rouge-N and Rouge-L measures, as well as qualitatively with experts and learners. Our results show an enhanced\nrecall and precision of the generated explanations compared to those generated solely by the GPT model, with a greatly reduced risk of\ngenerating imprecise information in the final learning explanation.\nKeywords\nLarge language models (LLMs), Knowledge graphs, ChatGPT, Generative AI (GenAI), Learning recommendations, explainable AI (XAI)\n1. Introduction\nIn personalized education, the provision of precise and com-\nprehensible explanations for learning recommendations is\nboth important and challenging. Explainability of learn-\ning recommendations has been found to enhance the stu-\ndent acceptance of the recommended content [1]. However,\nthe precision of the textual and visual explanations faces\nseveral limitations when these are generated semi- or full-\nautomatically. This is due to the level of knowledge, un-\nderstanding, and reflection, that the learner needs from the\ngenerated explanation, which an automatic system may not\nbe capable to offer. The recent research on LLMs opened\nnew possibilities for solutions to generate explanations for\nlearning recommendations on a deeper linguistic and se-\nmantic level. The massive datasets used to train such LLMs,\nand the high number of features considered by the model,\nenables generating more informative texts for the explain-\nability task. However, they face serious concerns about their\nability to generate a sufficiently precise text to reflect the\nlearning intent from the recommendation, especially in sen-\nsitive domains. On the one hand, the technology readiness\nlevel (TRL) of the majority of LLMs still does not exceed\nthe level TRL-2 [2]. From an ethical perspective, the trans-\nparency of LLMs is rarely more than Tier-1 [ 2], based on\nthe classification of transparency by Chaudhry et al. [ 3].\nThis apprehension aligns with the observations of Fullan et\nal. [4], who also expressed concerns about various adverse\neffects of ChatGPT in education. They highlighted issues\nsuch as the lack of originality in its responses, potentially\nleading to answers that lack meaning and fail to stimulate\nAccepted in the IEEE Global Engineering Education Conference 2024\n(EDUCON24), Kos, Greece\n‚ãÜ\nYou can use this document as the template for preparing your publica-\ntion. We recommend using the latest version of the ceurart style.\n*Corresponding author.\n/envel‚å¢pe-‚å¢penhasan.abu.rasheed@uni-siegen.de (H. A. Rasheed);\nchristian.weber@uni-siegen.de (C. Weber)\n/orcid0000-0002-2921-4809 (H. A. Rasheed); 0000-0001-6606-5577\n(C. Weber); 0000-0002-7602-9593 (M. Fathi)\n¬© 2024 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribu-\ntion 4.0 International (CC BY 4.0).\nexploration or imagination due to their linearity or flatness\n[5]. Despite these drawbacks, Hargreaves [6] underscored\nthat utilizing such technology in education exhibits promise,\nadvocating against its outright rejection.\nOur research addresses this challenge by combining the\nstrengths of KGs and Generative Pre-Trained Transformers\n(GPT) models, aiming to enhance the precision, and thus\nreliability, of the explanations they generate for learning\nrecommendations. We utilize the features of KGs to enhance\nthe querying process of LLMs, through extracting contextual\nknowledge from the KG and then performing an informed\nprompt engineering process that is supported by pedagogy\nexperts‚Äô inputs. The resulting LLM prompt is then used\nto guide the model away from generating wrong or irrele-\nvant information and limit the scope of answers it provides\nto the curated information provided from the knowledge\ngraph. This ensures more precise answers, while still uti-\nlizing the model‚Äôs ability to combine pieces of information\nand phrase a human-like explanation, which learners can\neasily comprehend\n2. Background\nKnowledge Graphs are structured representations of knowl-\nedge, composed of entities and the relationships between\nthem [7]. They serve as powerful tools for organizing infor-\nmation, capturing semantic connections, and providing a\nfoundation for contextual understanding. A KG is defined as\nin (1). In educational contexts, KGs can be constructed from\ncurated educational materials, forming a reliable source of\nfactual knowledge [8].\nùêæùê∫ = (‚Ñé, ùëü, ùë°)|‚Ñé, ùë°‚àà ùê∏, ùëü‚àà ùëÖ, (1)\nWhere h is the head entity, t is the tale entity, and r is the\nrelation between h and t. E is the entity group and R is the\nrelation group.\nThe use of KGs to support LLMs is gaining an increased\nfocus recently [9, 10, 11], which can be traced back to: 1)\nthe new breakthroughs of LLMs, 2) the growing concerns\nabout their risks and limitations [2], and 3) the effective role\nKGs can play in reducing LLM hallucinations and enhancing\ntheir accuracy [12]. Sequeda et al. show that KGs-based\nquerying enhanced the results of a one-shot question an-\nswering task in comparison to SQL-querying, when a KG\nrepresentation of the SQL database was used [ 12]. KGs\nhave also been well utilized for explainability tasks in the\nliterature. This is due to their potential to provide causal\nreasoning [13], factual knowledge [11], and interpretable\nsemantic relations [10, 14, 15]. To that end, KGs not only\nenhance the reasoning of the LLM with facts, but also offer\nmore information, which influences the precision of the\nautomatically generated text. This information is parsed\nto the LLM in form of a prompt context that is designed\nduring the prompt engineering phase. Depending on the\nLLM used, contextual parts of the prompt act as guidelines\nthat steer the model to generate more relevant outputs. We\nbuild on the concepts in [14] and [9] to utilize KG‚Äôs structure\nand semantic relations for enriching the contextual part of\nOpenAI‚Äôs GPT-4 model prompt [ 16], thus enhancing the\nprecision of its explanations of a learning recommendation.\n3. Methodology\nTo utilize the GPT-4 potentials while reducing the amount\nof irrelevant and imprecise text it generates for the learning\nrecommendation, we propose a strategy for constructing\nthe data structures and the LLM prompt to maximize the\namount of factual and contextual information that the model\nreceives before generating an explanation for the recommen-\ndation, see Fig. 1. Contextual information that KG provides\nis acquired from the structural relations and the metadata\nof the learning content connected to the recommended ele-\nments. Both types of information are then translated into\ntextual strings that are inserted as prompt context in the\nLLM query.\n3.1. Knowledge Graph Structure\nWe create the KG from educational materials, aligning with a\npre-defined taxonomy, to ensure comprehensive coverage of\nrelevant topics. Our taxonomy includes four levels: 1) Learn-\ning goals, 2) Courses, 3) Topics, and 4) Open educational\nresources (OER). For simplicity, we use the term learning\nobject (LO) as defined in [17] hereafter to refer to any of the\nlast three taxonomy levels, unless they are explicitly named.\nLearning goals and LOs are represented by graph nodes,\nwho‚Äòs properties include their titles and descriptions among\nother metadata. We focus on textual properties of the LOs\nto search for semantic relations amongst them. Semantic\nrelations are extracted because the educational content in\nour database is created by different experts over time. A\ncustomized text mining pipeline is utilized to extract the\nmain topics covered each LO and compare them to topics\ncovered by other LOs in the graph [8]. A relation is created\nbetween the two LOs if the semantic similarity is above a\npredefined threshold. Relations extracted between LOs are\nused to enhance the coverage and composition of context,\nwhich is provided to the LLM for generating an explanation\nof the connected materials in the learning recommendation.\nThe recommendation algorithm we use is a graph explo-\nration and path weighing algorithm [18], based on Markov\ndecision process (MDP) to identify an optimal learning path\nfor each learner. Recommended learning path is explained\nFigure 1:Structural information added to the LLM context from\nthe KG. Top: learning path as an output of the recommendation\nsystem. Bottom: recommended path as it appears in the KG.\nArea (A): hierarchical structure of the learning goal. Area (B)\nKG community around LO3 and LO4. Connection (C): semantic\nrelation extracted by the relation extraction algorithm.\nin terms of its content selection (why each node is recom-\nmended), as well as its relation to the learning goal (how\na node supports achieving the desired learning goal). To\nexplain the recommended path, we extract four main types\nof information from the KG, see Fig.1:\n1. the hierarchical structure of the LO based on the pre-\ndefined taxonomy: this structure informs the LLM\nabout the placement of a recommended LO within its\noriginal curriculum, which is defined by the human\ncontent-curator of the corresponding learning goal,\nsee Fig. 1 area (A).\n2. Semantic relations to similar LOs in the KG : which\nis discovered by the relation extraction algorithm\nbased on the textual content and the semantic simi-\nlarity between the LOs, see Fig. 1 connection (C).\n3. KG communities around LOs: : which are areas on\ndensely connected LOs in the KG. These communi-\nties reflect in our KG fields of application, in which\nseveral LOs are usually required together as a group,\nsee Fig. 1 area (B).\n4. Supporting metadata from connected LOs in the KG:\nwhere not only the relations to semantically similar\nLOs are utilized, but also the textual content of the\nrelated LOs‚Äô metadata, which sheds an additional\nlight on the context of the recommended LO.\nUsing this additional information from the KG, we con-\nstruct the GPT-4 prompt on the task level, as well as on the\ncontext one.\n3.2. GPT-4 Prompt and Explanation\nConstruction\nThe extended explanations for recommended learning paths\nare generated using the ‚ÄúGPT4-1106-preview‚Äù model, which\nwe will refer to here as GPT-4 for simplicity. This model is\nthe most capable model offered by OpenAI at the time of\nconducting this research, with training data that is updated\ntill April 2023. To use the model, we utilize OpenAI‚Äôs API,\nwhich allows parsing the prompt to the GPT-4 model with\nadditional data, information, and instructions, in order to\nguide the model output generation. We design our pomp\nto include a main body and a contextual part, see Fig. 2.\nPrompt‚Äôs body represents the direct query from the user. It\nis constructed as a set of tasks that the model ha to perform.\nThis is to enhance the focus of the query and ensure less\ndeviation from the user intent.\nThe contextual part of the prompt is extracted directly\nfrom the KG, based on a search strategy that integrates the\nfour types of information discussed in 3.1, into the prompt‚Äôs\ncontext. The context is designed to include: 1) The role\nthat the model assumes when answering a user‚Äôs query,\ne.g., answering as a teacher. 2) Required definitions that\nare needed to understand the terminology, especially in\nthe cases where the domain-specific meaning of a word\ndiffers from its general meaning. 3) The information from\nsemantically connected LOs in the KG, which is provided to\nthe model in the form of ‚Äúsupporting content‚Äù in the query‚Äôs\ncontext. The model‚Äôs role and terminology definitions are\nalso influenced by a direct input from the domain experts,\nwho can set the pedagogical and domain related guidelines\nfor the model.\nThe response of the GPT-4 model is used to fill the in-\nformation gaps in an explanation template. The design of\nexplanations for the learning recommendations is tightly\nconnected to the pedagogical value of the explanation, to\nensure an improved learning outcome. For that reason, each\ntemplate includes specific information spaces or slots, which\nare filled by the LLM, guided by the data of the KG. It is\nimportant to mention here that parts of the explanation tem-\nplate can also be filled with a direct input from the experts.\nIn this paper, however, we limit the scope of information\nin the explanation to that generated automatically by the\nGPT-4 model, in order to evaluate its performance against a\ngolden standard, which is extracted from the expert‚Äôs input.\n3.3. Chatbot-based interaction with the\nexplanations\nOnce the explanation is complete, it is provided to the user\nthrough an interactive interface element, which represents\nthe chat features that LLMs offer. We refer to this approach\nas ‚Äúconversational explainability‚Äù, which differs from regu-\nlar textual and visual explanations by its ability to provide\nthe explanation through a multi-step interaction with the\nuser, taking into account previous chat messages to influ-\nence the following model output. The ability of GPT models\nto respond to individual questions, as well as to engage in\na multi-step chat with the user, means that explanations\ncan be extended with additional information based on user\ninputs and requests. This, however, would induce the risk\nof deviating from the main point of the explanations. There-\nfore, we limit the chatting feature of GPT-4 in this paper to\na first response with confirmation. This approach stands for\na one-shot query that is supported by a confirmation step\nfrom the model, to ensure that the chatbot understands the\nuser request correctly. With this approach, a learner has\nthe option to ask about the learning material itself, i.e., its\ncontent or why it is relevant for their learning goal, as well\nas the relationships between the learning materials are in\nthe recommended path.\nFigure 2:Proposed approach for constructing the GPT-4 prompt,\nwith KG-based contextualization, as well as the Chatbot-based\nuser interaction, and the expert roles in the design for context\nand explanation-templates.\n4. Evaluation and Results\nTo evaluate our proposed approach, we devise a hybrid\nquantitative/qualitative evaluation strategy. The quanti-\ntative evaluation utilizes Rouge-based measures, namely\nRouge-N, Rouge-L and Rouge-Lsum. Qualitative evaluation\nis conducted through a questionnaire-based user feedback\non the explanation approach and is outcomes. It involved do-\nmain experts and learners, who were asked to evaluate the\ngenerated explanations and their relevance to the learning\nmaterials and learning goal.\nThrough Rouge metric, we aim to measure the amount\nof text in the generated explanation, which offers precise\ninformation, against the amount of irrelevant text, which is\neither wrong, or simply a filler text that is task-related but\nhas low relevance to the goal of the explanation.\n4.1. Experiment Set-up\nRouge (Recall-Oriented Understudy for Gisting Evaluation)\n[19] is an evaluation metric commonly used in natural lan-\nguage processing (NLP) to assess the quality of automated\ntext summarization and machine translation systems. It\nemploys both recall and precision to compare the overlap of\nn-grams (contiguous sequences of words) between model-\nFigure 3:Recall, precision, and f1-measure values of the Rouge metric, for both explanation types: 1) with KG-based contextualization\n(blue), and 2) without contextualization (gray).\ngenerated summaries and human-generated ones. We utilize\nthis metric to measure the overlap between reference ex-\nplanations from a human text and each of the explanations\ngenerated automatically by the GPT-4 model, i.e., with a\nKG-based contextualization, and without it. To ensure a\nfair comparison between the two explanation approaches,\nwe fix the length of the text generated by the GPT-4 model.\nThis is because Rouge measures take into consideration the\ntotal amount of n-grams in the model generated text.\nThe reference text is composed from human defined de-\nscriptions and reflection information in the LO‚Äôs metadata.\nIn this paper, we do not account for the phrasing of the ex-\nplanation, i.e., sentence structures and writing styles, since\nthere is no certain phrasing or writing style that can be\nconsidered as ‚Äúcorrect‚Äù or ‚Äúreferential‚Äù. Instead, we focus\non the word choice and word patterns that appear in the\ngenerated text and match the patterns in the reference text.\n4.2. Dataset\nTo calculate Rouge values, we construct a reference data set\nof reference explanations. 52 samples of human-generated\ntexts were collected from clarifications of the recommended\ncontent of 10 different learning-path recommendations. For\neach reference explanation, we generate two candidate ex-\nplanations, one through the proposed KG-based contextual-\nization approach, and one without the context.\n4.3. Results and Discussion\nWe calculate the recall, precision, and f1-measure from four\nRouge measures: Rouge-1, which is the measure used to for\nthe overlap between single words, i.e., unigrams, Rouge-2\nthat accounts for two-word patterns, i.e., bigrams, Rouge-L\nthat takes into account the longest matching patterns be-\ntween the reference text and the candidate one, and Rouge-\nLsum which is a variant of Rouge-L that calculates the over-\nlap on the sentence level, not the complete text. Calculated\nvalues of the different measures, see Fig. 3, show a clear\nenhancement of the precision, recall, and thus f1-measure\nof the explanations generated with KG-based context. The\nresults also show that recall scores are best with Rouge-\nLsum measure, while the precision and f1-measure values\nare better with Rouge-1. With a domain expert support, we\nevaluate that none of the automatic explanation samples\nwas wrong or misleading, which leads to the conclusion that\nthe amount of less irrelevant text in the non-contextualized\nexplanations was considerably higher than the one in the\ncontextualized explanations, since both have comparable\nlengths.\nQualitatively, the explanations were provided in a user\nstudy to a group of eight learners and five domain experts.\nParticipants included two PhD holders, four PhD candidates\nand seven graduate students. We surveyed the participants\nfor their perception on the explanation quality, and the\noverall impressions, remarks, and limitations of the two\nexplanation approaches. The survey evaluation revealed an\nenhanced acceptance of the explanations when it is gener-\nated with KG-based context. On a Likert scale, the quality of\nthe contextualized explanation reached 4.7/5. The amount of\nirrelevant text, which was correct in general but not related\nto the user intent from the explanation, was also reported\nto be less in the contextualized explanations, which aligns\nwith quantitative results. Participants also highlighted im-\nportant limitations that the LLM revealed when generation\nthe explanation. Three out of five domain experts pointed\nout that not only the word selection, but also the phrasing\nof the explanation plays an important role in determining\nits meaning. Four experts also emphasized that the explana-\ntion is not only a task of answering a user question, but also\nincludes high-level reflection information, which enables\nthe learner to understand how the learning content can\naffect their own context, e.g., their daily work. This level\nof reflection exceeds the ability of the LLM and requires a\nhuman mentor to provide it based on their understanding\nof the learner‚Äôs context.\nThis feedback shows a limitation in our valuation ap-\nproach, which should also include the effect of the explana-\ntion phrasing to the comparison with reference explanations.\nThe nature of LLMs and the complexity of evaluating what\na correct phrasing is, challenges this evaluation, and defines\nat the same time several prospects for continuing this on-\ngoing research. Other limitations that we address in our\nstudy include: 1) The limited sample sizes in the experiment,\nwhich is used to provide a proof-of-concept and set the start-\ning point for a larger scale test. 2) The comparison between\nGPT-4 and other LLMs is required to measure LLM-based\nperformance deviations. 3) We do not include user-specific\ndate in our contextualization approach, to comply with the\nGDPR, since GPT-4 is provided by a third party. A local\nLLM is intended to be used for further evaluating the role\nof user data in enhancing the relevance of the explanation\nto user contexts, as well as materials contexts.\n5. Conclusion\nIn this paper, we proposed an evaluated an approach for\nutilizing KGs as a source of contextual information that\nsupports LLMs in generating more relevant explanations\nof learning recommendations. Our approach extracts dif-\nferent types of information from the KG and constructs a\ncontextual part of a GPT-4 model‚Äôs prompt accordingly. The\ndesign of the prompt‚Äôs context is conducted with experts-\nin-the-loop to ensure the fulfillment of the pedagogical re-\nquirements from the explanation. Experts also participated\nin the design of the final explanation shape and content,\nwhich was offered to the learners as a textual template filled\nby the GPT-4 model. A chatbot-based interaction with the\nuser is used to provide the explanations as answers to user\nquestions. We evaluate the proposed approach qualitatively\nand quantitatively using Rouge measures. Evaluation re-\nsults provided a proof of the proposed concept, showing a\nreduced amount of less-relevant text in the generated ex-\nplanation. The results of the evaluation also pointed out\nlimitations of the LLM‚Äôs performance which defines a start-\ning point for future work to further evaluate the role of the\nexplanation phrasing and the use of user-data for further\npersonalization of the explanation text.\nReferences\n[1] J. Ooge, S. Kato, K. Verbert, Explaining Recommen-\ndations in E-Learning: Effects on Adolescents‚Äô Trust,\nin: 27th International Conference on Intelligent User\nInterfaces, ACM, Helsinki Finland, 2022, pp. 93‚Äì105.\ndoi:10.1145/3490099.3511140.\n[2] L. Yan, L. Sha, L. Zhao, Y. Li, R. Martinez-Maldonado,\nG. Chen, X. Li, Y. Jin, D. Ga≈°eviƒá, Practical and Ethical\nChallenges of Large Language Models in Education:\nA Systematic Scoping Review, British Journal of Edu-\ncational Technology (2023) bjet.13370. doi:10.1111/\nbjet.13370, arXiv:2303.13379 [cs].\n[3] M. A. Chaudhry, M. Cukurova, R. Luckin, A Trans-\nparency Index Framework for AI in Education, in:\nM. M. Rodrigo, N. Matsuda, A. I. Cristea, V. Dimitrova\n(Eds.), Artificial Intelligence in Education. Posters\nand Late Breaking Results, Workshops and Tutori-\nals, Industry and Innovation Tracks, Practitioners‚Äô\nand Doctoral Consortium, volume 13356, Springer\nInternational Publishing, Cham, 2022, pp. 195‚Äì198.\ndoi:10.1007/978-3-031-11647-6_33 , series Ti-\ntle: Lecture Notes in Computer Science.\n[4] M. Fullan, C. Azor√≠n, A. Harris, M. Jones, Artificial\nintelligence and school leadership: challenges, oppor-\ntunities and implications, School Leadership & Man-\nagement (2023) 1‚Äì8. doi:10.1080/13632434.2023.\n2246856.\n[5] K. Dana, H. Harouni, ChatGPT Is Unoriginal‚Äîand\nExactly What Humans Need, 2023. URL: https://www.\nwired.com/story/chatgpt-education-originality/.\n[6] S. Hargreaves, ‚ÄòWords Are Flowing Out Like Endless\nRain Into a Paper Cup‚Äô: ChatGPT &amp; Law School\nAssessments, SSRN Electronic Journal (2023). doi:10.\n2139/ssrn.4359407.\n[7] D. Fensel, U. ≈ûim≈üek, K. Angele, E. Huaman,\nE. K√§rle, O. Panasiuk, I. Toma, J. Umbrich,\nA. Wahler, Introduction: What Is a Knowledge\nGraph?, in: Knowledge Graphs, Springer In-\nternational Publishing, Cham, 2020, pp. 1‚Äì10.\ndoi:10.1007/978-3-030-37439-6_1 .\n[8] H. Abu-Rasheed, M. Dornh√∂fer, C. Weber, G. Kismih√≥k,\nU. Buchmann, M. Fathi, Building Contextual Knowl-\nedge Graphs for Personalized Learning Recommenda-\ntions Using Text Mining and Semantic Graph Comple-\ntion, in: 2023 IEEE International Conference on Ad-\nvanced Learning Technologies (ICALT), IEEE, Orem,\nUT, USA, 2023, pp. 36‚Äì40. doi:10.1109/ICALT58122.\n2023.00016.\n[9] S. Pan, L. Luo, Y. Wang, C. Chen, J. Wang, X. Wu, Uni-\nfying Large Language Models and Knowledge Graphs:\nA Roadmap, 2023. ArXiv:2306.08302 [cs].\n[10] L. Luo, Y.-F. Li, G. Haffari, S. Pan, Reasoning on Graphs:\nFaithful and Interpretable Large Language Model Rea-\nsoning, 2023. URL: http://arxiv.org/abs/2310.01061,\narXiv:2310.01061 [cs].\n[11] R. Logan, N. F. Liu, M. E. Peters, M. Gardner, S. Singh,\nBarack‚Äôs Wife Hillary: Using Knowledge Graphs for\nFact-Aware Language Modeling, in: Proceedings\nof the 57th Annual Meeting of the Association for\nComputational Linguistics, Association for Computa-\ntional Linguistics, Florence, Italy, 2019, pp. 5962‚Äì5971.\ndoi:10.18653/v1/P19-1598.\n[12] J. Sequeda, D. Allemang, B. Jacob, A Benchmark to\nUnderstand the Role of Knowledge Graphs on Large\nLanguage Model‚Äôs Accuracy for Question Answering\non Enterprise SQL Databases, 2023. ArXiv:2311.07509\n[cs].\n[13] M. Munch, J. Dibie-Barth√©lemy, P.-H. Wuillemin,\nC. Manfredotti, Interactive Causal Discovery in Knowl-\nedge Graphs, in: E. Demidova, S. Dietze, J. Breslin,\nS. Gottschalk, P. Cimiano, B. Ell, A. Lawrynowicz,\nL. Moss, A.-C. N. Ngomo (Eds.), Joint Proceedings of\nthe 6th International Workshop on Dataset PROFlLing\nand Search & the 1st Workshop on Semantic Explain-\nability, volume 2465 of CEUR Workshop Proceedings,\nCEUR, Auckland, New Zealand, 2019, pp. 78‚Äì93. ISSN:\n1613-0073.\n[14] H. Abu-Rasheed, C. Weber, J. Zenkert, M. Dorn-\nh√∂fer, M. Fathi, Transferrable Framework Based\non Knowledge Graphs for Generating Explainable\nResults in Domain-Specific, Intelligent Information\nRetrieval, Informatics 9 (2022) 6. doi: 10.3390/\ninformatics9010006, number: 1 Publisher: Mul-\ntidisciplinary Digital Publishing Institute.\n[15] E. Rajabi, K. Etminani, Knowledge-graph-based ex-\nplainable AI: A systematic review, Journal of Informa-\ntion Science (2022) 01655515221112844. doi:10.1177/\n01655515221112844, publisher: SAGE Publications\nLtd.\n[16] OpenAI, GPT-4 Technical Report, 2023. doi: 10.\n48550/arXiv.2303.08774, arXiv:2303.08774 [cs].\n[17] IEEE Standard for Learning Object Metadata, IEEE Std\n1484.12.1-2020 (2020) 1‚Äì50. doi: 10.1109/IEEESTD.\n2020.9262118.\n[18] H. Abu-Rasheed, C. Weber, M. Dornh√∂fer, M. Fathi,\nPedagogically-Informed Implementation of Reinforce-\nment Learning on Knowledge Graphs for Context-\nAware Learning Recommendations, in: O. Viberg,\nI. Jivet, P. Mu√±oz-Merino, M. Perifanou, T. Pa-\npathoma (Eds.), Responsive and Sustainable Edu-\ncational Futures, volume 14200, Springer Nature\nSwitzerland, Cham, 2023, pp. 518‚Äì523. doi:10.1007/\n978-3-031-42682-7_35 , series Title: Lecture\nNotes in Computer Science.\n[19] C.-Y. Lin, ROUGE: A Package for Automatic Evalua-\ntion of Summaries, in: ACL 2004, 2004.",
  "topic": "Context (archaeology)",
  "concepts": [
    {
      "name": "Context (archaeology)",
      "score": 0.6491612792015076
    },
    {
      "name": "Computer science",
      "score": 0.45208966732025146
    },
    {
      "name": "Data science",
      "score": 0.38297560811042786
    },
    {
      "name": "History",
      "score": 0.1562265157699585
    },
    {
      "name": "Archaeology",
      "score": 0.06440618634223938
    }
  ]
}