{
  "title": "A Transformer-based Model to Detect Phishing URLs",
  "url": "https://openalex.org/W3196743042",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2191129609",
      "name": "Xu Pingfan",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2046603953",
    "https://openalex.org/W2789273141",
    "https://openalex.org/W3096615602",
    "https://openalex.org/W149487318",
    "https://openalex.org/W2545557236",
    "https://openalex.org/W2497564007",
    "https://openalex.org/W2498543205",
    "https://openalex.org/W3082867473",
    "https://openalex.org/W2134750673",
    "https://openalex.org/W1930835045",
    "https://openalex.org/W2147495097",
    "https://openalex.org/W2917600487",
    "https://openalex.org/W1975909792",
    "https://openalex.org/W24863754",
    "https://openalex.org/W2020645183",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2909737018",
    "https://openalex.org/W1995554356",
    "https://openalex.org/W2517538529",
    "https://openalex.org/W2521519773",
    "https://openalex.org/W1522768299",
    "https://openalex.org/W83428783",
    "https://openalex.org/W1147066959",
    "https://openalex.org/W2999300566",
    "https://openalex.org/W2896457183"
  ],
  "abstract": "Phishing attacks are among emerging security issues that recently draws significant attention in the cyber security community. There are numerous existing approaches for phishing URL detection. However, malicious URL detection is still a research hotspot because attackers can bypass newly introduced detection mechanisms by changing their tactics. This paper will introduce a transformer-based malicious URL detection model, which has significant accuracy and outperforms current detection methods. We conduct experiments and compare them with six existing classical detection models. Experiments demonstrate that our transformer-based model is the best performing model from all perspectives among the seven models and achieves 97.3 % of detection accuracy.",
  "full_text": "A Transformer-based Model to Detect Phishing\nURLs\nPingfan Xu\nSchool of Computer Science\nUniversity of Guelph\nGuelph, Canada\npingfan@uoguelph.ca\nAbstract—Phishing attacks are among emerging security issues\nthat recently draws signiﬁcant attention in the cyber security\ncommunity. There are numerous existing approaches for phishing\nURL detection. However, malicious URL detection is still a\nresearch hotspot because attackers can bypass newly introduced\ndetection mechanisms by changing their tactics. This paper will\nintroduce a transformer-based malicious URL detection model,\nwhich has signiﬁcant accuracy and outperforms current detection\nmethods. We conduct experiments and compare them with six\nexisting classical detection models. Experiments demonstrate that\nour transformer-based model is the best performing model from\nall perspectives among the seven models and achieves 97.3% of\ndetection accuracy.\nIndex Terms—Transformer, Phishing URL Detection, Machine\nLearning, Deep Learning\nI. I NTRODUCTION\nPhishing is a type of attack leveraged by cyber criminals\nwhich impersonate some legitimate organizations’ websites\nor URL to deceive the victims [1]. The attackers will use\nsomebody or some company’s identity that the people trust\nto send them spam emails or messages embedded with those\nphishing links [2]. The count of phishing-related cyber crimes\nincidents proliferation in the last several decade. It was men-\ntioned in Verizon Data Breach Investigation Report (DBIR)\nthat phishing attacks caused more than 22% of the breaches\nin 2020 [3]. The consequent ransomware was estimated to cost\nover 8 billion USD all over the world [4]. Among the 22% of\nthe breaches in 2020 caused by phishing attack, 99% of them\nwere delivered through emails or websites. In December 2013,\n42890 unique phishing websites were recorded and reported\nworldwide [5]. Since phishing emails and website both may\ninvolve malicious URLs, the exploration of malicious URL\ndetection has double beneﬁts for both anti-email-phishing and\nanti-website-phishing.\nIn order to mitigate phishing attacks, there are already\nnumerous anti-phishing solutions in practice. As for modern\nweb browsers, there are indicators as built-in countermeasures\nfor a phishing website. For instance, browsers would validate\nthe website’s SSL certiﬁcate and provide the result by dis-\nplaying a special indicator icon on the address bar for users’\nreferences. Unfortunately, this validation process could be\neasily bypassed if the attacker used an URL visually similar to\nthe original site’s address. Studies showed that these indicators\nmight be ineffective and even put the users into a higher-\nrisk situation [6]–[8]. Another commonly employed method\nagainst phishing is two-factor authentication. It introduces an\nextra security layer. One of the widely used techniques for\ntwo-factor authentication (2FA) is sending real-time generated\nveriﬁcation code via SMS [9]. Even though 2FA may protect\nagainst phishing attacks, it typically requires a different device.\nAdditionally, there are researches found possible ways to\nbypass 2FA as well [10]. Therefore, it would be critical to\ndiscover reliable and lightweight malicious URLs detection\nsolutions to identify malicious URLs on time to prevent severe\nconsequences and potential losses.\nThis paper’s contributions are as following:\n• We reviewed and categorized the typical existing ap-\nproaches for phishing URL detection.\n• We proposed an innovative transformer-based model as a\nlight-weight but high performance solution for malicious\nURL prediction.\n• We evaluated our proposed model by comparing its\nperformance with six other existing classical models’. We\nproved that our model has better performance competing\nwith these other models.\nIn this paper, Section II provides a background introduction\nand literature reviews of the existing anti-phishing solutions\nin practice. Then, our proposed solution and its design details\nwill be illustrated at Section III. Afterwards Section IV will\nexplain how we train our Transformer model. The experiment\nsection will be followed by the model evaluation section\nwhere we mainly compare the performance of six machine\nlearning models (Decision Tree, Random Forest, Multi-layer\nPerceptrons, XGBoost, Support Vector Machine, Auto En-\ncoder) implemented by Sundari and her team [11] to our\ntransformer model. Finally, we will provide some suggestions\nto improve our proposed solution further at Section VI.\nII. L ITERATURE REVIEW AND BACKGROUND\nIn recent years, researchers have explored a massive amount\nof possible solutions for phishing website detection. We\nroughly categorized the existing detection techniques into\ncontent-based, property-based, and URL-based approaches tar-\ngeting different websites. Each approach has its advantages\nand disadvantages. Several typical pieces of research under\narXiv:2109.02138v1  [cs.CR]  5 Sep 2021\neach approach category will be reviewed in this section.\nAdditionally, as one innovative solution under URL-based\napproaches, the transformer model will be demonstrated with\nits background.\nA. Literature Review\nContent-based phishing website detection may be one of the\nmost intuitive techniques among the three. It might also be the\nmethod closest to how the average person gets to determine\nphishing sites. Firstly, people would visually identify the iden-\ntity that the images and texts on the website suggested. With\nthe identiﬁed site identity, they could query the corresponding\nURL of the identity through a trusted source. The website\nwould be considered a benign one only when the queried\nURL matches the URL shown on the address bar. The logic\nbehind content-based phishing website detection techniques\nwas the same. For example, Chiew et al. utilized the website\nlogo for phishing site detection [12]. The researchers employed\nGoogle image search on extracted logos from the website to\nget the portrayed site identity. The phishing detection result\nwas determined through the consistency check of the portrayed\nsite identity and the actual domain of the testing website.\nTheir proposed solution provided an outstanding performance\nwith 99.8% true positive rate and 87.0% true negative rate.\nAdditionally, the texts shown on a site could also be used for\nphishing detection. Yang et al. proposed a multidimensional\nfeature-based detection technique that included vectorizing\ntexts on the page for determine the possibility that the vec-\ntorized text was from a phishing site [13]. Their approach\nachieved 98.99% in its accuracy. Similarly, there was another\napproach using the same methodology and the website favicon\nfor phishing detection [14] where its true positive rate reached\n96.93%.\nIn addition to visual and literal contents on a web page,\nother properties or meta-data information hidden to every-\nday users could also be employed for phishing detection.\nThe property-based approach generally pays attention to the\nabnormal behaviors of a website. For example, Pan and\nDing used six abnormal properties, including Abnormal URL,\nAbnormal DNS record, Abnormal Anchors, Server-Form-\nHandler, Abnormal cookie, and Abnormal Secure Sockets\nLayer(SSL)-certiﬁcate, to conduct phishing checking [15].\nTheir proposed model gives an average false positive rate as\nlow as 4%. Since studies suggested the number of redirect\npages contained in malicious sites is between 2 to 4 [16],\nthe count of redirecting times was proposed as one possible\ndetecting approach. To avoid being easily identiﬁed by end-\nusers inspecting source code, attackers may use JavaScript to\ndisable the mouse right-click function [17]. Hence, uncommon\ndisabling of browser functionalities could be another standard\nfor detection. Furthermore, other website properties related\nto its domain information can be utilized. Properties like the\ndomain age, domain name, and IP address were also proven\nto have positive contributions to phishing detection in recent\nresearches [18], [19].\nBesides content-based and property-based approaches, the\nURL-based method is also a hot research topic in the ﬁeld\nof phishing detection. URL-based approaches take advantage\nof URL analysis to conduct phishing predictions. Researchers\nhave tried different URL-based techniques to detect malicious\nURLs. Most of them utilize hand-crafted features extracted\nfrom the URLs. Ma et al. proposed a detection method from\nthe lexical and host-based features in 2011, which detects ma-\nlicious Web sites from a balanced dataset with 99% accuracy\n[20]. Choi et al. identiﬁed malicious URLs with six manually\nextracted class features from URLs: lexical, link popularity,\nwebpage content, DNS, DNS ﬂuxiness, and Network [21].\nTheir solution was capable of malicious URL detection with\nover 98% of accuracy. In 2012, Zhang and Wang developed an\naccurate, real-time, and language-independent malicious URL\nclassiﬁer with hosted and lexical features of target URLs [22].\nA model based on word n-gram and Markov Chains that could\ngenerate proactive blacklists of malicious URLs was designed\nby Marchal et al. in 2012 [23]. Their approach to preventing\nphishing scams could be considered the opposite of traditional\ndetections. Pao et al. proposed a detection method that uti-\nlizes the estimation of conditional Kolmogorov complexity of\nURLs [24]. Their approach could independently handle large\namounts of input URLs very efﬁciently with high accuracy.\nAdditionally, their model could be used in conjunction with\nother URL-feature-based detection techniques to improve the\nprediction accuracy further.\nSince URLs are essentially pieces of texts, researchers\nstarted exploring the possibilities of utilizing Natural Lan-\nguage Processing (NLP) techniques for URL-based phishing\ndetection. As one of the most innovative NLP models in\nrecent years, the transformer model has also been applied to\nphishing site detection. Researches applied transformer model\non malicious URL detection turn out to have outstanding ac-\ncuracy. It was proven that the novel transformer model would\nhave comparably good performance to the more traditional\napproaches [25].\nB. Background\nIn recent years, Transformer is a hot research topic in\nhandling tasks closely related to characters. One of the most\ncrucial concepts in the transformer model is called attention.\nIn 2017, the Google machine translation team published a\nresearch paper, “Attention Is All You Need.” [26] It completely\nsubverted some traditional network structures such as RNN\nand CNN and only applied the attention mechanism to perform\nmachine translation tasks. The transformer model had a better\nperformance than other machine learning models, and this\nlet the attention technique became a research hotspot. Later,\nDevlin et al. introduced an improved language processing\nmodel, Bidirectional Encoder Representations from Trans-\nformers (BERT) [27], based on the Transformer. It is different\nfrom the standard language representative models because\nBERT is used to pre-train deep bidirectional representations\nto produce an encoder with hidden states that can be used for\nvarious NLP ﬁne-tuning tasks. In 2018, Radford et al. from\nOpenAI came up with the Generative Pre-trained Transformer\n(GPT) series models [28]. Their approach is similar to BERT\nbut utilizes L - R masked modeling. The decoder stack per-\nforms a prediction on the following elements of the sequence\nfrom the previous token.\nFigure 1: The Transformer - model architecture.\n3.1 Encoder and Decoder Stacks\nEncoder: The encoder is composed of a stack ofN =6 identical layers. Each layer has two\nsub-layers. The ﬁrst is a multi-head self-attention mechanism, and the second is a simple, position-\nwise fully connected feed-forward network. We employ a residual connection [11] around each of\nthe two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is\nLayerNorm(x +S u b l a y e r (x)), whereSublayer(x) is the function implemented by the sub-layer\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\nlayers, produce outputs of dimensiondmodel = 512.\nDecoder: The decoder is also composed of a stack ofN =6 identical layers. In addition to the two\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\npredictions for positioni can depend only on the known outputs at positions less thani.\n3.2 Attention\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\nof the values, where the weight assigned to each value is computed by a compatibility function of the\nquery with the corresponding key.\n3\nFig. 1. Standard structure of Transformer.\nA typical transformer model contains two stacks: the en-\ncoder and the decoder. Each stack of it includes an embedding\nlayer, positional encoding, multi-headed attention layers, feed-\nforward layers, residual connections, and masks (as depicted\nin Fig. 1). The encoder takes the input text and makes\nit model-readable through input embedding and positional\nencoding. The encoder then applied several tensors to the\nprocessed input. The tensors are made of multi-head attention\nlayers connected to feed-forward layers, which provides the\nself-attention feature to the model as a combination. The\nmulti-head attention layers are the collection of identical\nself-attention mechanisms. Each self-attention mechanism (as\ndepicted in Fig. 2) can be described as a mapping:\nAttention(Q, K, V) =softmax(QKT\n√dk\n) (1)\nwhere query (Q), key (K), value(V) and output are all matrices\nand dk is the dimension of input queries and keys.\nScaled Dot-Product Attention\n Multi-Head Attention\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\nattention layers running in parallel.\n3.2.1 Scaled Dot-Product Attention\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\nqueries and keys of dimensiondk, and values of dimensiondv. We compute the dot products of the\nquery with all keys, divide each bypdk, and apply a softmax function to obtain the weights on the\nvalues.\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\ninto a matrixQ. The keys and values are also packed together into matricesK and V . We compute\nthe matrix of outputs as:\nAttention(Q, K, V) = softmax(QKT\npdk\n)V (1)\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\nof 1pdk\n. Additive attention computes the compatibility function using a feed-forward network with\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\nmuch faster and more space-efﬁcient in practice, since it can be implemented using highly optimized\nmatrix multiplication code.\nWhile for small values ofdk the two mechanisms perform similarly, additive attention outperforms\ndot product attention without scaling for larger values ofdk [3]. We suspect that for large values of\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\nextremely small gradients4. To counteract this effect, we scale the dot products by1pdk\n.\n3.2.2 Multi-Head Attention\nInstead of performing a single attention function withdmodel-dimensional keys, values and queries,\nwe found it beneﬁcial to linearly project the queries, keys and valuesh times with different, learned\nlinear projections todk, dk and dv dimensions, respectively. On each of these projected versions of\nqueries, keys and values we then perform the attention function in parallel, yieldingdv-dimensional\noutput values. These are concatenated and once again projected, resulting in the ﬁnal values, as\ndepicted in Figure 2.\n4To illustrate why the dot products get large, assume that the components ofq and k are independent random\nvariables with mean0 and variance1. Then their dot product,q · k = Pdk\ni=1 qiki, has mean0 and variancedk.\n4\nFig. 2. Self-attention mechanism.\nThe multi-head attention (as depicted in Fig. 3) can then be\ndescribed as:\nMultiHead (Q, K, V) =Concat(head1, ..., headh)WO\n(2)\nwhere\nheadi = Attention(QWi\nQ, KWi\nK, V Wi\nV ),\nWi\nQ ∈Rdmodel×dk ,\nWi\nK ∈Rdmodel×dk ,\nWi\nV ∈Rdmodel×dv ,\nWO ∈Rhdv×dmodel .\nScaled Dot-Product Attention\n Multi-Head Attention\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\nattention layers running in parallel.\n3.2.1 Scaled Dot-Product Attention\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\nqueries and keys of dimensiondk, and values of dimensiondv. We compute the dot products of the\nquery with all keys, divide each bypdk, and apply a softmax function to obtain the weights on the\nvalues.\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\ninto a matrixQ. The keys and values are also packed together into matricesK and V . We compute\nthe matrix of outputs as:\nAttention(Q, K, V) = softmax(QKT\npdk\n)V (1)\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\nof 1pdk\n. Additive attention computes the compatibility function using a feed-forward network with\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\nmuch faster and more space-efﬁcient in practice, since it can be implemented using highly optimized\nmatrix multiplication code.\nWhile for small values ofdk the two mechanisms perform similarly, additive attention outperforms\ndot product attention without scaling for larger values ofdk [3]. We suspect that for large values of\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\nextremely small gradients4. To counteract this effect, we scale the dot products by1pdk\n.\n3.2.2 Multi-Head Attention\nInstead of performing a single attention function withdmodel-dimensional keys, values and queries,\nwe found it beneﬁcial to linearly project the queries, keys and valuesh times with different, learned\nlinear projections todk, dk and dv dimensions, respectively. On each of these projected versions of\nqueries, keys and values we then perform the attention function in parallel, yieldingdv-dimensional\noutput values. These are concatenated and once again projected, resulting in the ﬁnal values, as\ndepicted in Figure 2.\n4To illustrate why the dot products get large, assume that the components ofq and k are independent random\nvariables with mean0 and variance1. Then their dot product,q · k = Pdk\ni=1 qiki, has mean0 and variancedk.\n4\nFig. 3. Multi-head attention.\nThen, the result from multi-head attention is passed to a\nfully connected feed-forward network (FFN) containing two\nlinear transformations with a Rectiﬁed Linear Unit (ReLU) as\nactivation function in between:\nFFN (x) =ReLU(W1x + b1)W2 + b2 (3)\nThe output of FFN is considered the encoder’s output and is\npassed to the decoder for an intermediate tensor operation. The\ndecoder has a similar structure as the encoder. The primary\ndifferences are the masking operation and an additional multi-\nhead attention layer on each tensor. The masking operation is\napplied on the ﬁrst multi-head attention layer, which takes\nthe processed input of the decoder. The additional multi-\nhead attention layer is the one next to the masked multi-head\nattention layer. Also, the extra layer is where the output of the\nencoder is taken into the decoding operation.\nThe above usage based on the network architecture of the\ntransformer is most frequently applied to NLP problems. It\ncan be seen that the transformer model has certain advantages\ncompared with other models in processing language semantics.\nHowever, using the transformer in the information security\narea, especially the prediction and classiﬁcation of URLs, is\na relatively new attempt. Rudd and Abdallah from FireEye\nInc. came up with the idea of using a transformer model\nfor malicious URL prediction [25]. They split each URL\ninto single-character tokens and append a classiﬁcation token\n“CLS” at the end. To solve the different lengths of each\nURL, padding tokens “PAD” will be added to normalize the\ninput to a ﬁxed length for training. The preprocessed URLs\nwill be projected into an embedding area with a stack of\nattention layers and feed-forward neural network layers. Like\nthe transformer’s basic idea, each input token has an essential\nrelation with other tokens no matter how long the distance\nis. Meanwhile, the feed-forward layers allow learning the\ncombination of the input tokens’ relationship and their context.\nThe training process utilized over a million labeled malicious\nand benign URLs. For the evaluation, they compared their\ntransformer model with four other models: Random Forest,\nCNN, and LSTM. Finally, they concluded that the transformer\nmodel had the highest accuracy score. Our model that will be\nlater introduced in this paper is inspired by their design.\nIII. P ROPOSED MODEL\nBased on the existing solutions and approaches of phishing\nor malicious URL detection, our group has proposed and\nimplemented an innovative solution mainly based on the\ntransformer model. The design and implementation details of\nour approach will be introduced in this section.\nOur approach to the transformer model design is not iden-\ntical to the standard structure. The model design of Rudd and\nAbdallah from FireEye Inc. inspires the transformer model\ndesign of our approach [25]. In our solution, the transformer\nmodel is very similar to the design of OpenAI’s GPT model,\none of the famous variants of the Transformer model. Our\nTransformer model applied left to right (L-R) modeling and\nonly contained the encoder part from the standard transformer\nmodel. There are mainly two parts included in our solution:\nthe input text pre-processing part and the classiﬁer model part.\nSpeciﬁcally for the input text pre-processing part, we\ntokenize the input URL ﬁrst by splitting it into single-character\ntokens. The most frequently appeared single-character tokens\nin the URLs of the training dataset are used to form the\ntoken repository, which is also known as the vocabulary of\nthe tokenizer. The maximum vocabulary size is designed to\nbe 256 is corresponding to a 256-character embedding space\nfrom index 0 to 255. Any characters contained in the input\nURL out of the most frequently appeared 256 characters\nwill be replaced by a unique character < OOV >. For the\nrelatively shorter input URLs, they will be padded to the max\nlength of 256. On the other hand, the input URLs that are\nlonger than 256 characters will be truncated to the length of\n256. Therefore, after the input text pre-processing operations,\neach input URL will be tokenized to an array of length 256.\nFor example, given an input URL\nhttps : //www.google.com/\nthe tokenized array will be 1:\n[15, 2, 2, 13, 9, 31, 4, 4, 33, 33, 33, 18, 26, 5, 5, 26, 17,\n3, 18, 12, 5, 16, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0]\nFor the classiﬁer model part of our Transformer model,\nthere are eight main layers connected sequentially. The ﬁrst\nlayer is the input layer that takes the pre-processed input\nURL as an array 256. The input layer passes the tokenized\ninput URL to a token and position embedding layer. The\ndimension of this layer is equal to the vocabulary size of the\ndataset gotten after the input text pre-processing operations.\nThus, the dimension of this layer is up to 256. This token\nand position embedding layer consists of two sub-layers\nwhich are both embedding layers. One of these two separate\nembedding layers is for tokens, while the other is for token\nindex (positions). The layer next to the token and position\nembedding layer is a transformer block. The transformer block\nis the same as the encoder layer of the standard transformer\nmodel, which consists of sublayers: multi-head attention and\npoint-wise feed-forward networks. The transformer block has\nthe same embedding dimension as the token and position\nembedding layer. There are four attention heads included in\nthe Transformer block. The relationship of model dimension\n(dmodel), key dimension ( dk), and value dimension ( dv) is:\ndk = dv = dmodel/4 = 64.\n1Note: A character’s corresponding sequence number representation may\ndiffer depending on the character’s appearance frequency in the given\ndataset. Furthermore, 0 is the padding’s corresponding sequence number\nrepresentation.\nThus, the multi-head attention sublayer can be described very\nsimilar to (2) as:\nMultiHead(Q, K, V) =Concat(head1, head2, head3, head4)WO\n(4)\nwhere\nheadi = Attention(QWi\nQ, KWi\nK, V Wi\nV ),\nWi\nQ ∈R256×64,\nWi\nK ∈R256×64,\nWi\nV ∈R256×64,\nWO ∈R4×64×256.\nInside the transformer block, the hidden layer size in the\nfeed-forward network is 128. The transformer layer outputs\none vector for each time step of our tokenized input URL. We\ntake the mean across all time steps and use a feed-forward\nnetwork on top of it to classify text. Also, the dropout rate\nof 0.1 is employed to help with preventing overﬁtting. At the\nend of our classiﬁer model, a softmax function is employed to\ngenerate the ﬁnal prediction result of whether the input URL\nis malicious or benign.\nIV. E XPERIMENT\nA. Dataset\nOur dataset is a combination of two resources: PhishTank\n[29], and the University of New Brunswick (UNB) [30].\nPhishTank provides hourly updated phishing URLs sets in\nvarious formats including .json, .csv etc. The phishing URLs\non PhishTank are veriﬁed as valid by the community, which\ngives better quality on the original dataset. PhishTank is a\nwidely used source of phishing URLs for researches related\nto phishing detection [31]–[33]. The other dataset from UNB\nhas a collection of benign URLs, spam URLs, phishing URLs,\nmalware URLs, and defacement URLs. Researches like [34]\nused this dataset as part of its input URL feeding source. Since\nwe only focus on phishing and legitimate URLs, we pulled\nmalicious URLs from PhishTank and benign URLs from UNB.\nWe randomly selected 20000 URLs with 10000 benign URLs\nfrom UNB’s dataset and 10000 malicious from PhishTank’s\ndataset for training and testing purposes. All selected URLs are\nlabeled with 0 or 1 for benign or malicious correspondingly.\nWe separate 80% (16000 URLs) for training and 20% of the\ndata (4000 URLs) for testing. Before the training process,\nwe also shufﬂed our labeled dataset to improve our model’s\nrobustness.\nB. Training Process\nInitially, we used a batch size of 512 and 20 epochs for\ntest training to get the appropriate epoch number to avoid\noverﬁtting. After each training epoch, a checkpoint would be\nsaved for referring back at the model ﬁnalization stage. Based\non the initial training experiment, we found that both the\ntraining and testing accuracy were kept on a high (over 95%)\nand steady level between the 3rd and 13th (as depicted in Fig.\n4). Additionally, the validation accuracy of our transformer\nmodel started dropping dramatically after the 13th epoch\nof training (as depicted in Fig. 4). At the same time, the\ntransformer model’s loss began increasing signiﬁcantly (as\ndepicted in Fig. 5). According to this ﬁnding, it suggested\nthat the checkpoint saved immediately after the 13th epoch\nof training could be considered as a good balance between\npursuing high accuracy and avoiding model overﬁtting. Thus,\nthe checkpoint saved after the 13th epoch of training were\ntaken as the ﬁnalized training result of our model.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20\nEpoch\n0.75\n0.80\n0.85\n0.90\n0.95Accuracy\nModel Accuracy\ntrain\ntest\nFig. 4. Transformer model accuracy during training & validation.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20\nEpoch\n0.1\n0.2\n0.3\n0.4\n0.5Loss\nModel Loss\ntrain\ntest\nFig. 5. Transformer model loss during training & validation.\nV. EVALUATION\nAs mentioned in the previous section, the checkpoint after\nthe 13th epoch of training was chosen as the ﬁnalized model\nbased on the 20-epoch experimental training results of model\naccuracy and model loss. Thus, the evaluation analysis in this\nsection would be conducted on top of the transformer model’s\ncheckpoint after the 13th epoch of training.\nA. Model Evaluation\nWe ran the prediction on the validation dataset that includes\n4000 records combined with benign and malicious URLs to\nevaluate our model. Then, we used the prediction results and\nthe original labels to generate the confusion matrix. In our\nexperiment, True Negative (TN) is the number of benign URLs\nclassiﬁed as benign, False Positive (FP) is the number of\nbenign URLs misclassiﬁed as malicious, False Negative (FN)\nis the number of malicious URLs misclassiﬁed as benign, and\nTrue Positive (TP) is the number of malicious URLs classiﬁed\nas malicious. Fig. 6 shows the confusion matrix.\nIn terms of confusion matrix results, the ideal situation\nis that it contains a large number of TP and TN and a\nsmall number of FP and FN. From Fig. 6, we have a large\nnumber of TP (1896). And we also have a high value for\nTN (2028). These two numbers indicates our model is capa-\nble of accurately predict both malicious and benign URLs.\nAdditionally, we can also ﬁnd that neither FP (36) nor FN\n(40) is a large number. These two numbers suggest there is\nhigher chance that the input URL is actually benign when our\ntransformer model made predictions incorrectly. Even though\nour transformer model may make mistakes while predicting,\nits overall performance is outstanding based on the results that\nits confusion matrix shows.\nTo further evaluate our Transformer model, we utilized the\nfollowing indicators: accuracy (5), precision (6), recall (7),\nand F1-score (8). Accuracy is the most intuitive metric that\ncalculates correct predicted results over all the predictions.\nPrecision measures the ratio of precise positive prediction\noverall positive prediction. Recall shows the correct positive\nprediction over the value of a speciﬁc class. Furthermore, F1-\nscore calculates the weighted average of the precision and\nrecall. According to the confusion matrix, the accuracy is\n0.981, the precision is 0.981, the recall is 0.979, and the F1-\nscore is 0.980. These values all together indicate the high-\nquality performance of our model.\nAccuracy = TP + TN\nTP + FN + TN + FP (5)\nPrecision = TP\nTP + FP (6)\nRecall = TP\nTP + FN (7)\nF1 −score = 2∗Precision ∗Recall\nPrecision + Recall (8)\nB. Model Comparison\nIn addition, to evaluate our Transformer model by its valida-\ntion performance, we also compared our model’s performance\nwith other typical classiﬁer models. We employed six extra\ntrained models from Sundari, and her team [11]’s work. Their\nproposed approach could be considered as a hybrid solution\nof property-based and URL-based approaches. They mainly\nextracted 17 features from each URL that belongs to three\nmain categories: Address-Bar-based Features, Domain-based\nFeatures, and HTML-&-Javascript-based Features. Our Trans-\nformer model is comparable with their six models because\n0 1\nPredicted Label\n01\nTrue Label\n2028.0 36.0\n40.0 1896.0\nConfusion Matrix\n250\n500\n750\n1000\n1250\n1500\n1750\n2000\nFig. 6. Confusion matrix of Transformer model.\ntheir models were also trained on the datasets from PhishTank\nand UNB.\nTo compare the performance of all seven models (Deci-\nsion Tree, Random Forest, Multi-layer Perceptrons, XGBoost,\nSupport Vector Machine, Auto Encoder, Transformer), we\nrandomly select 1000 new URLs other than the training and\nvalidation dataset. Half of these 1000 URLs are malicious\nURLs, and the other half are benign ones. All of these\n1000 URLs are labeled. We used the 1000 URLs to conduct\npredictions with each one of the seven models. After the\nexperimental prediction process, we compared the predicted\nresults and the actual labels concerning each model. Each\nmodel’s performance in the experiment was reﬂected by its\ncorresponding test accuracy, precision, recall, and F1-score\nvalues. The result is in Table I. According to the performance\nresult table, we can ﬁnd that our Transformer models got\nthe highest values across all the four calculated metrics. For\nall these four metrics, the higher value suggests the better\nperformance of the model from a speciﬁc aspect. We also\nsorted the models by the F1-score in descending order to\nreﬂect a model’s all-around performance. The F1-score (8)\nis the harmonic mean of precision (6) and recall (7). It takes\nthe contribution of both, so the higher the F1 score, the better.\nA model does well in the F1 score if the positive predicted\nare positives (precision), does not miss out on positives,\nand predicts them negative (recall). Therefore, in terms of\noverall performance or performance from a speciﬁc aspect,\nour Transformer model presents the best performance among\nall seven models involved in the performance comparison\nexperiment.\nTABLE I\nMODEL PERFORMANCE COMPARISON\nML Model Test AccuracyTest PrecisionTest RecallTest F1-Score\nTransformer 0.973 0.984 0.962 0.973\nRandom Forest 0.849 0.973 0.718 0.826\nAutoencoder 0.843 0.934 0.738 0.825\nXGBoost 0.825 0.831 0.816 0.823\nSupport Vector Machines 0.845 0.978 0.706 0.820\nDecision Tree 0.841 0.975 0.700 0.815\nMultilayer Perceptrons 0.778 0.747 0.840 0.791\nVI. C ONCLUSION AND FUTURE WORK\nIn this paper, we reviewed literature about different ap-\nproaching trends on malicious URL prediction. Based on the\nexisting researches in this ﬁeld, we introduced our construction\nof a Transformer classiﬁer model for predicting the malicious\nURL. Additionally, we demonstrated our training dataset and\nthe corresponding training processes. Also, we evaluated our\nﬁnalized model by its performance upon the validation dataset\nand its quality compared to the other six machine learning or\ndeep learning-based models. Comparing to the performance of\nthe other six models (Decision Tree, Random Forest, Multi-\nlayer Perceptrons, XGBoost, Support Vector Machine, and\nAuto Encoder), we concluded that our transformer model is\nthe best performing model from all perspectives among the\ntotal seven models when conducting predictions using our\nmodel comparison dataset. Future training based on the current\nﬁnalized model with a large dataset may improve our robust-\nness. The performance and robustness could be pushed onto a\nhigher level, especially when using a huge dataset, including a\nlarge portion of short URLs. Even with the ﬁnalized version,\nour transformer model still provides an innovative idea of\na low-cost but good-performing solution for malicious URL\nprediction. Also, our current ﬁndings and implementations of\nour transformer model veriﬁed that transformer technology\nis useful in malicious URL prediction and is worth future\nresearch and even productizations.\nREFERENCES\n[1] E. Rzeszut and D. Bachrach, 10 Don’ts on Your Digital Devices.\nBerkeley, CA: Apress L. P, 2014. [Online]. Available: https://\nebookcentral.proquest.com/lib/[SITE ID]/detail.action?docID=1964915\n[2] M. Jakobsson and S. Myers, Phishing and countermeasures. Newy\nYork: WILEY , 2006. [Online]. Available: http://portal.igpublish.com/\niglibrary/search/WILEYB0009517.html\n[3] “Verizon: Data breach investigations report 2020,” Computer fraud &\nsecurity, vol. 2020, no. 6, pp. 4–4, 2020.\n[4] H. Shahbaznezhad, F. Kolini, and M. Rashidirad, “Employees’ behavior\nin phishing attacks: What individual, organizational, and technological\nfactors matter?” The Journal of computer information systems , vol.\nahead-of-print, no. ahead-of-print, pp. 1–12, October 29, 2020. [Online].\nAvailable: http://www.tandfonline.com/doi/abs/10.1080/08874417.2020.\n1812134\n[5] A. APWG, “Phishing activity trends report: 4th quarter 2016,” Anti-\nPhishing Working Group. Retrieved December, vol. 12, p. 2017, 2017.\n[6] T. Whalen and K. M. Inkpen, “Gathering evidence: use of visual security\ncues in web browsers,” in Proceedings of Graphics Interface 2005.\nCiteseer, 2005, pp. 137–144.\n[7] E. Lin, S. Greenberg, E. Trotter, D. Ma, and J. Aycock, “Does domain\nhighlighting help people identify phishing sites?” in Proceedings of the\nSIGCHI Conference on Human Factors in Computing Systems, 2011,\npp. 2075–2084.\n[8] S. Egelman, “Trust me: Design patterns for constructing trustworthy trust\nindicators,” CARNEGIE-MELLON UNIV PITTSBURGH PA SCHOOL\nOF COMPUTER SCIENCE, Tech. Rep., 2009.\n[9] S. H. Apandi, J. Sallim, and R. M. Sidek, “Types of anti-\nphishing solutions for phishing attack,” IOP conference series.\nMaterials Science and Engineering, vol. 769, no. 1, p. 12072, Feb\n1, 2020. [Online]. Available: https://iopscience.iop.org/article/10.1088/\n1757-899X/769/1/012072\n[10] A. Dmitrienko, C. Liebchen, C. Rossow, and A.-R. Sadeghi, On\nthe (In)Security of Mobile Two-Factor Authentication, ser. Financial\nCryptography and Data Security. Berlin, Heidelberg: Springer\nBerlin Heidelberg, Nov 9, 2014, pp. 365–383. [Online]. Available:\nhttp://link.springer.com/10.1007/978-3-662-45472-5 24\n[11] S. G. Sundari, “Phishing website detec-\ntion by machine learning techniques,” May 10,\n2020. [Online]. Available: https://github.com/shreyagopal/\nPhishing-Website-Detection-by-Machine-Learning-Techniques/\n[12] K. L. Chiew, E. H. Chang, S. N. Sze, and W. K. Tiong,\n“Utilisation of website logo for phishing detection,” Computers\n& security , vol. 54, pp. 16–26, Oct 2015. [Online]. Available:\nhttp://dx.doi.org/10.1016/j.cose.2015.07.006\n[13] P. Yang, G. Zhao, and P. Zeng, “Phishing website detection\nbased on multidimensional features driven by deep learning,”\nIEEE access, vol. 7, pp. 15 196–15 209, 2019. [Online]. Available:\nhttps://ieeexplore.ieee.org/document/8610190\n[14] K. L. Chiew, J. S.-F. Choo, S. N. Sze, and K. S. C. Yong,\n“Leverage website favicon to detect phishing websites,” Security and\ncommunication networks, vol. 2018, pp. 1–11, Mar 6, 2018. [Online].\nAvailable: https://dx.doi.org/10.1155/2018/7251750\n[15] Y . Pan and X. Ding, “Anomaly based web phishing page detection.”\nIEEE, Dec 2006, pp. 381–392. [Online]. Available: https://ieeexplore.\nieee.org/document/4041183\n[16] R. M. Mohammad, F. Thabtah, and L. McCluskey, “An assessment\nof features related to phishing websites using an automated\ntechnique.” IEEE, Dec 2012, pp. 492–497. [Online]. Available:\nhttps://ieeexplore.ieee.org/document/6470857\n[17] G. H. Lokesh and G. BoreGowda, “Phishing website detection\nbased on effective machine learning approach,” Journal of cyber\nsecurity, vol. 5, no. 1, pp. 1–14, Jan 2, 2021. [Online]. Available:\nhttp://www.tandfonline.com/doi/abs/10.1080/23742917.2020.1813396\n[18] I. Fette, N. Sadeh, and A. Tomasic, “Learning to detect phishing\nemails,” ser. WWW ’07. ACM, May 8, 2007, pp. 649–656. [Online].\nAvailable: http://dl.acm.org/citation.cfm?id=1242660\n[19] A. Zamir, H. U. Khan, T. Iqbal, N. Yousaf, F. Aslam, A. Anjum,\nand M. Hamdani, “Phishing web site detection using diverse machine\nlearning algorithms,” Electronic library, vol. 38, no. 1, pp. 65–80,\n2020. [Online]. Available: https://www.emerald.com/insight/content/doi/\n10.1108/EL-05-2019-0118/full/html\n[20] J. Ma, L. K. Saul, S. Savage, and G. M. V oelker, “Learning to\ndetect malicious urls,” ACM Transactions on Intelligent Systems and\nTechnology (TIST), vol. 2, no. 3, pp. 1–24, 2011.\n[21] H. Choi, B. B. Zhu, and H. Lee, “Detecting malicious web links and\nidentifying their attack types.” WebApps, vol. 11, no. 11, p. 218, 2011.\n[22] J. Zhang and Y . Wang, “A real-time automatic detection of phishing\nurls,” inProceedings of 2012 2nd International Conference on Computer\nScience and Network Technology. IEEE, 2012, pp. 1212–1216.\n[23] S. Marchal, J. Franc ¸ois, T. Engel et al., “Proactive discovery of phishing\nrelated domain names,” in International Workshop on Recent Advances\nin Intrusion Detection. Springer, 2012, pp. 190–209.\n[24] H.-K. Pao, Y .-L. Chou, and Y .-J. Lee, “Malicious url detection based\non kolmogorov complexity estimation,” ser. WI-IAT ’12, vol. 1. IEEE\nComputer Society, Dec 4, 2012, pp. 380–387. [Online]. Available:\nhttp://dl.acm.org/citation.cfm?id=2457619\n[25] E. M. Rudd and A. Abdallah, “Training transformers for information\nsecurity tasks: A case study on malicious url prediction,” Nov 5, 2020.\n[Online]. Available: https://arxiv.org/abs/2011.03040\n[26] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.\nGomez, L. Kaiser, and I. Polosukhin, “Attention is all you need,” Jun\n12, 2017. [Online]. Available: https://arxiv.org/abs/1706.03762\n[27] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training\nof deep bidirectional transformers for language understanding,” 2019,\n1810.04805.\n[28] A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever, “Improving\nlanguage understanding by generative pre-training,” 2018.\n[29] “Phishtank,” August 2021. [Online]. Available: http://data.phishtank.\ncom/data/online-valid.csv\n[30] “Url dataset (iscx-url2016),” 2016. [Online]. Available: https://www.\nunb.ca/cic/datasets/url-2016.html\n[31] S. W. Liew, N. F. M. Sani, M. T. Abdullah, R. Yaakob, and M. Y .\nSharum, “An effective security alert mechanism for real-time phishing\ntweet detection on twitter,” Computers & security, vol. 83, pp. 201–207,\nJun 2019. [Online]. Available: https://dx.doi.org/10.1016/j.cose.2019.\n02.004\n[32] P. A. Barraclough, M. A. Hossain, M. A. Tahir, G. Sexton, and\nN. Aslam, “Intelligent phishing detection and protection scheme\nfor online transactions,” Expert systems with applications , vol. 40,\nno. 11, pp. 4697–4706, Sep 1, 2013. [Online]. Available: https:\n//dx.doi.org/10.1016/j.eswa.2013.02.009\n[33] G. Varshney, M. Misra, and P. K. Atrey, “A phish detector using\nlightweight search features,” Computers & security , vol. 62, pp.\n213–228, Sep 2016. [Online]. Available: https://dx.doi.org/10.1016/j.\ncose.2016.08.003\n[34] M. S. I. Mamun, M. A. Rathore, A. H. Lashkari, N. Stakhanova,\nand A. A. Ghorbani, Detecting Malicious URLs Using Lexical\nAnalysis, ser. Network and System Security. Cham: Springer\nInternational Publishing, Sep 21, 2016, pp. 467–482. [Online].\nAvailable: http://link.springer.com/10.1007/978-3-319-46298-1 30",
  "topic": "Phishing",
  "concepts": [
    {
      "name": "Phishing",
      "score": 0.8781764507293701
    },
    {
      "name": "Computer science",
      "score": 0.7347877621650696
    },
    {
      "name": "Transformer",
      "score": 0.6179026365280151
    },
    {
      "name": "Hotspot (geology)",
      "score": 0.5567928552627563
    },
    {
      "name": "Computer security",
      "score": 0.4325385093688965
    },
    {
      "name": "Data mining",
      "score": 0.38345324993133545
    },
    {
      "name": "World Wide Web",
      "score": 0.20760774612426758
    },
    {
      "name": "Engineering",
      "score": 0.12865474820137024
    },
    {
      "name": "The Internet",
      "score": 0.12830960750579834
    },
    {
      "name": "Geology",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Geophysics",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I79817857",
      "name": "University of Guelph",
      "country": "CA"
    }
  ],
  "cited_by": 6
}