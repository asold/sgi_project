{
    "title": "Combining Knowledge Hunting and Neural Language Models to Solve the Winograd Schema Challenge",
    "url": "https://openalex.org/W2951034424",
    "year": 2019,
    "authors": [
        {
            "id": "https://openalex.org/A2916326615",
            "name": "Ashok Prakash",
            "affiliations": [
                "Arizona State University"
            ]
        },
        {
            "id": "https://openalex.org/A2111467095",
            "name": "Arpit Sharma",
            "affiliations": [
                "Arizona State University"
            ]
        },
        {
            "id": "https://openalex.org/A2402781779",
            "name": "Arindam Mitra",
            "affiliations": [
                "Arizona State University"
            ]
        },
        {
            "id": "https://openalex.org/A2010516145",
            "name": "Chitta Baral",
            "affiliations": [
                "Arizona State University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2905122125",
        "https://openalex.org/W2604710187",
        "https://openalex.org/W4386506836",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W1599016936",
        "https://openalex.org/W2251411386",
        "https://openalex.org/W2963854351",
        "https://openalex.org/W2081580037",
        "https://openalex.org/W2279996368",
        "https://openalex.org/W2890894339",
        "https://openalex.org/W92973652",
        "https://openalex.org/W1495981708",
        "https://openalex.org/W2251199578",
        "https://openalex.org/W2291406294",
        "https://openalex.org/W2740418058",
        "https://openalex.org/W2251158365",
        "https://openalex.org/W2806710540",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W2575843997",
        "https://openalex.org/W2413794162",
        "https://openalex.org/W2890693705",
        "https://openalex.org/W2805206884",
        "https://openalex.org/W1990989925",
        "https://openalex.org/W2963983586",
        "https://openalex.org/W2794325560"
    ],
    "abstract": "Winograd Schema Challenge (WSC) is a pronoun resolution task which seems to require reasoning with commonsense knowledge. The needed knowledge is not present in the given text. Automatic extraction of the needed knowledge is a bottleneck in solving the challenge. The existing state-of-the-art approach uses the knowledge embedded in their pre-trained language model. However, the language models only embed part of the knowledge, the ones related to frequently co-existing concepts. This limits the performance of such models on the WSC problems. In this work, we build-up on the language model based methods and augment them with a commonsense knowledge hunting (using automatic extraction from text) module and an explicit reasoning module. Our end-to-end system built in such a manner improves on the accuracy of two of the available language model based approaches by 5.53% and 7.7% respectively. Overall our system achieves the state-of-the-art accuracy of 71.06% on the WSC dataset, an improvement of 7.36% over the previous best.",
    "full_text": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 6110–6119\nFlorence, Italy, July 28 - August 2, 2019.c⃝2019 Association for Computational Linguistics\n6110\nCombining Knowledge Hunting and Neural Language Models to Solve the\nWinograd Schema Challenge\nAshok Prakash, Arpit Sharma, Arindam Mitra, Chitta Baral\nArizona State University\nTempe, USA\n{apraka23,asharm73,amitra7,chitta}@asu.edu\nAbstract\nWinograd Schema Challenge (WSC) is a pro-\nnoun resolution task which seems to require\nreasoning with commonsense knowledge. The\nneeded knowledge is not present in the given\ntext. Automatic extraction of the needed\nknowledge is a bottleneck in solving the chal-\nlenge. The existing state-of-the-art approach\nuses the knowledge embedded in their pre-\ntrained language model. However, the lan-\nguage models only embed part of the knowl-\nedge, the ones related to frequently co-existing\nconcepts. This limits the performance of such\nmodels on the WSC problems. In this work,\nwe build-up on the language model based\nmethods and augment them with a common-\nsense knowledge hunting (using automatic ex-\ntraction from text) module and an explicit rea-\nsoning module. Our end-to-end system built\nin such a manner improves on the accuracy\nof two of the available language model based\napproaches by 5.53% and 7.7% respectively.\nOverall our system achieves the state-of-the-\nart accuracy of 71.06% on the WSC dataset, an\nimprovement of 7.36% over the previous best.\n1 Introduction\nReasoning with commonsense knowledge is an in-\ntegral component of human behavior. It is due to\nthis capability that people know that they should\ndodge a stone that is thrown towards them. It has\nbeen a long standing goal of the Artiﬁcial Intelli-\ngence community to simulate such commonsense\nreasoning abilities in machines. Over the years,\nmany advances have been made and various chal-\nlenges have been proposed to test their abilities\n(Clark et al., 2018; Mihaylov et al., 2018; Mishra\net al., 2018). The Winograd Schema Challenge\n(WSC) (Levesque et al., 2011) is one such natu-\nral language understanding challenge. It is made\nup of pronoun resolution problems of a particu-\nlar kind. The main part of each WSC problem is\na set of sentences containing a pronoun. In ad-\ndition, two deﬁnite noun phrases, called “answer\nchoices” are also given. The answer choices are\npart of the input set of sentences. The goal is to\ndetermine which answer provides the most natural\nresolution for the pronoun. Below is an example\nproblem from the WSC.\nSentences (S1):The ﬁsh ate the worm. It was\ntasty.\nPronoun to resolve:It\nAnswer Choices:a) ﬁsh b) worm\nA WSC problem also speciﬁes a “special word”\nthat occurs in the sentences, and an “alternate\nword.” Replacing the former by the latter changes\nthe resolution of the pronoun. In the example\nabove, the special word is tasty and the alternate\nword is hungry.\nThe resolution of the pronoun is difﬁcult be-\ncause the commonsense knowledge that is re-\nquired to perform the resolution is not explicitly\npresent in the input text. The above example re-\nquires the commonsense knowledge that ‘some-\nthing that is eaten may be tasty’ . There have\nbeen attempts (Sharma et al., 2015b; Emami et al.,\n2018a) to extract such knowledge from text repos-\nitories. Those approaches ﬁnd the sentences which\nare similar to the sentences in a WSC problem but\nwithout the co-reference ambiguity. For example a\nsentence (which contains knowledge without am-\nbiguity) corresponding to the above WSC problem\nis ‘John ate a tasty apple’. Such an approach to\nextract and use sentences which contain evidence\nfor co-reference resolution is termed as Knowl-\nedge Hunting (Sharma et al., 2015b; Emami et al.,\n2018b). There are two main modules in the knowl-\nedge hunting approach, namely a knowledge ex-\ntraction module and a reasoning module. To be\nable to use the extracted knowledge, the reason-\ning module puts several restrictions on the struc-\nture of the knowledge. If the knowledge extrac-\ntion module could not ﬁnd any knowledge pertain-\n6111\ning to those restrictions, the extracted knowledge\nwould probably be of no use.\nSometimes the needed knowledge are embed-\nded in the pre-trained language models. Let us\nconsider the WSC example mentioned below.\nS2: The painting in Mark’s living room shows\nan oak tree. It is to the right of a house.\nPronoun to resolve:It\nAnswer Choices:a) painting b) tree\nHere, the knowledge that ‘a tree is to the right\nof a house’is more likely than ‘a painting is to the\nright of a house’ is needed. With recent develop-\nments in neural network architectures for language\nmodeling, it is evident that they are able to cap-\nture such knowledge by predicting that ‘a tree is\nto the right of a house’ is a more probable phrase\nthan ‘a painting is to the right of a house’ . This\nis because language models are trained on huge\namounts of text and they are able to learn the fre-\nquently co-occurring concepts from that text. Al-\nthough the knowledge from language models is\nhelpful in many examples, it is not suitable for\nseveral others. For example, the language models\nin (Trinh and Le, 2018) predict that ‘ﬁsh is tasty’\nis a more probable than ‘worm is tasty’. This is\nbecause the words ‘ﬁsh’and ‘tasty’occur in the\nsame context more often than the words ‘worm’\nand ‘tasty’.\nSo, considering the beneﬁts and limitations of\nthe above mentioned approaches, in this work,\nwe combine the knowledge hunting and neural\nlanguage models to solve the Winograd Schema\nChallenge (WSC). The main contribution of this\nwork is to tackle the WSC by:\n•developing and utilizing an automated\nknowledge hunting approach to extract the\nneeded knowledge and reason with it without\nrelying on a strict formal representation,\n•utilizing the knowledge that is embedded in\nthe language models, and\n•combining the knowledge extracted from\nknowledge hunting and the knowledge in lan-\nguage models.\nAs a result, our approach improves on the exist-\ning state-of-the-art accuracy by 7.36% and solves\n71.06% of the WSC problems correctly.\n2 Related Work\nThe Winograd Schema Challenge is a co-reference\nresolution problem. The problem of co-reference\nresolution has received large amount of atten-\ntion in the ﬁeld of Natural Language Processing\n(Raghunathan et al., 2010; Carbonell and Brown,\n1988; Ng, 2017). However the requirement to\nuse commonsense knowledge makes the Wino-\ngrad Schema Challenge hard and the other ap-\nproaches that are trained on their respective cor-\npora do not perform well in the Winograd Schema\nproblems.\nThe Winograd Schema Challenge was ﬁrst pro-\nposed in 2011 and since then various works have\nbeen proposed to address it. These approaches can\nbe broadly categorized into two types:\n1. The approaches which use explicit com-\nmonsense knowledge and reasoning with the\nknowledge. Such approaches can further be\ndivided into two types.\n(a) The approaches which provide a rea-\nsoning theory (Bailey et al., 2015; Sch ¨uller,\n2014; Sharma et al., 2015b) with respect to\na few speciﬁc types of commonsense knowl-\nedge and takes question speciﬁc knowledge\nwhile solving a Winograd Schema problem.\nOne of the major shortcomings of such ap-\nproaches is that they work only for the spe-\nciﬁc knowledge types and hence their cov-\nerage is restricted. Another shortcoming of\nsuch approaches is that they rely on strict for-\nmal representations of natural language text.\nThe automatic development of such represen-\ntations boils down to the well known com-\nplex problem of translating a natural lan-\nguage text into its formal meaning represen-\ntation. Among these works, only the work\nof (Sharma et al., 2015b) accepts natural lan-\nguage knowledge sentences which it auto-\nmatically converts into their required graphi-\ncal representation (Sharma et al., 2015a). The\nremaining two (Bailey et al., 2015; Sch ¨uller,\n2014) requires the knowledge to be provided\nin a logical form.\n(b) These approaches (Isaak and Michael,\n2016) also answer a Winograd Schema prob-\nlem with formal reasoning but use an existing\nknowledge base of facts and ﬁrst-order rules\nto do that.\n6112\n2. These approaches (Liu et al., 2017; Trinh and\nLe, 2018) utilize the recent advancement in\nthe ﬁeld of neural networks, particularly the\nbeneﬁts of word embedding and neural lan-\nguage model. The work of (Liu et al., 2017)\nuses ConceptNet and raw texts to train word\nembeddings which they later use to solve a\nWinograd Schema problem by a simple infer-\nence algorithm. The work of (Trinh and Le,\n2018) on the other hand uses majority vot-\ning from several language models to resolve\nthe co-reference. In layman terms, the sys-\ntem in (Trinh and Le, 2018) replaces the pro-\nnoun with the two answer choices to obtain\ntwo different sentences and then use the lan-\nguage models to ﬁnd out which of the two\nreplacement is more probable.\n3 Our Method\nIn this section we ﬁrst explain how our knowledge\nhunting approach and the neural language mod-\nels are used to generate respective intermediate re-\nsults. Then we explain the details of a Probabilis-\ntic Soft Logic (PSL) module which combines the\nintermediate results and predicts the conﬁdence\nfor each of the answer choices in a WSC example.\n3.1 Knowledge Hunting Approach\nThere are two main modules in the Knowledge\nHunting approach. The ﬁrst module extracts a\nset of sentences corresponding to a WSC problem\nsuch that the extracted sentences may contain the\nneeded commonsense knowledge. We call such\na set of sentences, a knowledge text. The second\nmodule uses a knowledge text and generates a cor-\nrespondence between the answer choices and the\npronoun in a WSC text, and the entities in aknowl-\nedge text. We call such a correspondence as entity\nalignment. Such an entity alignment is an interme-\ndiate result from the knowledge hunting module.\nIn the following we provide the details of knowl-\nedge text extraction and entity alignment modules.\n3.1.1 Knowledge Extraction\nThe goal of the knowledge extraction module is\nto automatically extract a set of knowledge texts\nfor a given WSC problem. Ideally, a knowledge\ntext should be able to justify the answer of the as-\nsociated WSC problem. In this vein, we aim to\nextract the texts that depict a scenario that is sim-\nilar to that of the associated WSC problem. We\nroughly characterize a WSC scenario in terms of\nthe events (verb phrases) and the properties of the\nentities that are associated with the scenario. The\ncharacterization of a scenario optionally includes\nthe discourse connectives between the events and\nproperties of the scenario. For example, in the\nWSC sentence “The city councilmen refused the\ndemonstrators a permit because they feared vio-\nlence . ”, the scenario is mainly characterized by\nthe verb phrases “refused” and “feared”, and the\ndiscourse connective “because”.\nIn this work, we use this abstract notion of a\nscenario to extract knowledge texts which depict\nsimilar scenarios. The following are the steps in\nthe extraction module.\n1. First, the module identiﬁes the verb phrases,\nproperties and discourse connectives in a\ngiven WSC scenario. For example the one-\nword verb phrases “refused” and “feared”,\nand the discourse connective “because” in\nthe example mentioned above.\n2. Secondly, the module automatically gener-\nates a set of search queries by using the key-\nwords extracted in the previous step. The ﬁrst\nquery in the set is an ordered combination (as\nper the WSC sentence) of the keywords ex-\ntracted in the previous step. For example the\nquery “* refused * because * feared * ”is the\nﬁrst query for the problem mentioned above.\nAfterwards the following set of modiﬁcations\nare performed with respect to the ﬁrst query\nand the results are added to the set of queries.\n•The verb phrases are converted to their\nbase form. For example, “ * refuse *\nbecause * fear * ”.\n•The discourse connectives are omitted.\nFor example, “* refuse * fear * ”.\n•The verbs in verb phrases and the adjec-\ntives are replaced with their synonyms\nfrom the WordNet KB (Miller, 1995).\nThe top ﬁve synonyms from the top\nsynset of the same part of speech are\nconsidered. An example query gener-\nated after this step is “* decline * be-\ncause * fear * ”.\n3. Thirdly, the module uses the generated\nqueries to search and extract text snippets,\nof length up to 30 words, from a search en-\ngine. The top 10 results (urls) from the search\nengine are retrieved for each query and text\n6113\nsnippets from those results are scraped. Out\nof the extracted texts, the 10 text snippets\nwhich are most similar to the WSC text are\nﬁltered and passed to the alignment module.\nWe used a natural language inference model\n(Parikh et al., 2016) to ﬁnd the most simi-\nlar sentences. Since we also do not want to\nextract the snippets which contain the corre-\nsponding WSC sentences (because of ambi-\nguity), this module removes the results with\nWSC sentences in them. We ﬁltered out\nthe knowledge texts which contained 80% or\nmore words from the sentences in any of the\nWSC problems.\nAn example knowledge text extracted by using\nthe query “ * refused * because * feared * ”via the\nsteps mentioned above is,“He also refused to give\nhis full name because he feared for his safety. ”\n3.1.2 Entity Alignment\nA total of up to 10 knowledge texts are extracted\nwith respect to each WSC problem. Each of them\nis processed individually along with the WSC\nproblem to produce a corresponding intermediate\nresult from the knowledge hunting module.\nLet W = ⟨S, A1, A2, P, K⟩be a modiﬁed WSC\nproblem such that S be a set of WSC sentences,\nA1 and A2 be the answer choices one and two re-\nspectively,P be the pronoun to be resolved, andK\nbe a knowledge text. The existing solvers (Sharma\net al., 2015b) that use explicit knowledge to solve\na WSC problem of the formW ﬁrst convert K and\nS into a logical form and then use a set of axioms\nto compute the answer. However, it is a daunting\ntask to convert free form text into a logical repre-\nsentation. Thus these methods often produce low\nrecall. In this work, we take a detour from this\napproach and aim to build an “alignment” func-\ntion. Informally, the task of the alignment func-\ntion is to align the answer choices ( A1 and A2)\nand the pronoun to be resolved ( P) in S with the\ncorresponding entities (noun/pronoun phrases) in\nK. These alignments are the intermediate results\nof the knowledge hunting module.\nBy the choice of knowledge extraction ap-\nproach, the knowledge texts are similar to the\nWSC sentences in terms of events, i.e., they con-\ntain similar verb phrases, properties and discourse\nconnectives. So, in an ideal situation we will have\nentities in K corresponding to each one of the\nconcerned entities ( A1, A2 and P) in W respec-\ntively. The goal of the alignment algorithm is to\nﬁnd that mapping. The mapping result is gen-\nerated in the form of a aligned with predicate of\narity three. The ﬁrst argument represents an en-\ntity (an answer choice or the pronoun) from S, the\nsecond argument represents an entity from K and\nthe third argument is an identiﬁer of the knowl-\nedge text used. We deﬁne an entity (noun phrase)\nEj from a knowledge text K to be aligned with to\nan entity Aj from a WSC text S if the following\nholds:\n1. There exists a verb v in S and v′ in K such\nthat either v = v′ or v is a synonym of v′.\n2. The “semantic role” of Aj with respect to v\nis same as the “semantic role” of Ej with re-\nspect to v′.\nWe use the semantic role labelling function,\ncalled QASRL (He et al., 2015) to compute the\nsemantic roles of each entity. QASRL repre-\nsents the semantic roles of an entity, in terms\nof question-answer pairs. Figure 1 shows the\nQASRL representation of the knowledge text “He\nalso refused to give his full name because he\nfeared for his safety.” It involves three verbs “re-\nfused”, “feared” and “give”. The questions repre-\nsent the roles of the participating entities.\nAn example alignment generated for the WSC\nsentence,\nS = “The city councilmen refused the demonstra-\ntors a permit because they feared violence. ”\nand the knowledge text,\nK = “He also refused to give his full name be-\ncause he feared for his safety. ”\nis,\naligned with(city councilmen,He,K)\naligned with(they,he,K)\nThere are three relevant entities in an input\nWSC problem, i.e., A1, A2 and P. Based on the\nexistence of the entities corresponding to the en-\ntities in the WSC problem there are 28 possible\ncases. For example, the case {True True True},\nabbreviated as {TTT}, represents that each of the\nentities A1, A2 and P are aligned with correspond-\ning entities in a knowledge text.\nThe intuition behind the alignment approach is\nto ﬁnd a common entity in a knowledge text such\nthat it aligns with one of the answer choices (say\nAi) and also with the pronoun to be resolved ( P).\n6114\nFigure 1: QASRL output for the sentence “He also refused to give his full name because he feared for his safety. ”\nCase Details Example\nTTT\nEach entity (amongA1, A2 andP) in the WSC\nsentencesW have corresponding entities in the\ncorrespondingknowledge textK\nWSC Sentence:JimcomfortedKevinbecausehewas so up-\nset . Knowledge Text (K):She saysI comfortedher, be-\ncauseshewas so upsetAlignments: alignswith(Jim,I,K),\nalignswith(Kevin,her,K), alignswith(he,she,K)\nTFT\nOnly the entity representing the answer choice\none (A1) and the pronoun to be resolved (P) have\ncorresponding entities in theknowledge textK\nWSC Sentence:Thetrophydoes not ﬁt into the brownsuitcase\nbecauseitis too large .Knowledge Text (K):installed CPU and\nfanwould not ﬁt in because thefanwas too largeAlignments:\nalignswith(trophy,fan,K), alignswith(it,fan,K)\nFTT\nOnly the entity representing the answer choice 2\n(A2) and the pronoun to be resolved (P) have cor-\nresponding entities in theknowledge textK\nWSC Sentence:JamesaskedRobertfor a favor buthe re-\nfused . Knowledge Text (K):He asked theLORDwhat he\nshould do, but theLORDrefused to answer him, either by\ndreams or by sacred lots or by the prophets.Alignments:\nalignswith(Robert,LORD,K) and alignswith(he,LORD,K)\nTable 1: Alignment Cases in the Knowledge Hunting Approach. A1 and A2 are answer choices one and two, P is\npronoun to resolve, Ek1, Ek2 and Ek3 are entities in a knowledge text (K)\nThen we can say that both Ai and P refer to same\nentity and hence they refer to each other. An im-\nportant aspect of such a scenario is the existence of\nthe entities in a knowledge text which align with at\nleast one of the answer choices and the pronoun\nto be resolved. In other words the cases {TTT},\n{TFT}and {FTT}. So we consider the alignments\ngenerated only with respect to these three cases\nas an output of the alignment module. The three\ncases and their details are shown in the Table 1\nalong with examples from the dataset.\n3.2 Using the Knowledge from Language\nModels\nIn recent years, deep neural networks have\nachieved great success in the ﬁeld of natural lan-\nguage processing (Liu et al., 2019; Chen et al.,\n2018). With the recent advancements in the neural\nnetwork architectures and availability of powerful\nmachine it is possible to train unsupervised lan-\nguage models and use them in various tasks (De-\nvlin et al., 2018; Trinh and Le, 2018). Such lan-\nguage models are able to capture the knowledge\nwhich is helpful in solving many WSC problems.\nLet us consider the WSC problem shown below.\nS3: I put the heavy book on the table and it\nbroke.\nPronoun to resolve:it\nAnswer Choices:a) table b) book\nA knowledge that, “ table broke is more likely\nthan book broke” is sufﬁcient to solve the above\nWSC problem. Such a knowledge is easily learned\nby the language models because they are trained\non huge amounts of text snippets which are tran-\nscribed by people. Furthermore, these models are\ngood at learning the frequently occurring patterns\n6115\nfrom data.\nIn this work, we aim to utilize such knowl-\nedge that is embedded in the neural language mod-\nels. We replace the pronoun to be resolved in\nthe WSC text with the two answer choices, one\nat a time, generating two possible texts. For ex-\nample the two texts generated in the above WSC\nexample are, S3(a) = I put the heavy book on\nthe table and table broke. , S3(b) = I put the\nheavy book on the table and book broke. Then\na pre-trained language model is used to predict\nthe probability of each of the generated texts.\nLet Pa be the probability of S3(a) and Pb be\nthe probability of S3(b). To be able to use the\nresult of language models in Probabilistic Soft\nLogic (PSL) (Kimmig et al., 2012), the output\nof this step contains coref(P,A1):PROB 1 and\ncoref(P,A2):PROB 2, where P is the pronoun to\nbe resolved, A1 and A2 are answer choices one\nand two respectively, and PROB 1 and PROB 2\nare the probabilities of the texts generated by re-\nplacing P with A1 and A2 in the WSC text re-\nspectively, i.e., Pa and Pb in the example above.\n3.3 Combining Knowledge Hunting and\nLanguage Models\nIn this step, the alignment results generated\nfrom the knowledge hunting module and the co-\nreference probabilities generated from the lan-\nguage models are combined in a Probabilistic Soft\nLogic (PSL) (Kimmig et al., 2012) framework to\ninfer the conﬁdence for each of the answer choices\nin a WSC problem.\nPSL is a probabilistic logic framework designed\nto have efﬁcient inference. A key distinguishing\nfeature of PSL is that ground atoms have soft, con-\ntinuous truth values in the interval [0, 1] rather\nthan binary truth values as used in Markov Logic\nNetworks and most other kinds of probabilistic\nlogic. Given a set of weighted logical formulas,\nPSL builds a graphical model deﬁning a probabil-\nity distribution over the continuous space of val-\nues of the random variables in the model. A PSL\nmodel is deﬁned using a set of weighted if-then\nrules in ﬁrst-order logic, as in the following exam-\nple:\n0.7 :∀x, y, z.spouse(x, y) ∧isChildOf (z, x)\n→isChildOf (z, y)\n(1)\nHere, x, y and z represent variables. The above\nrule states that a person’s child is also a child of\nhis/her spouse. The weight (0.7) associated with\nthe rule encodes the strength of the rule.\nEach grounded atom, in a rule of a PSL model\nhas a soft truth value in the interval [0, 1], which\nis denoted by I(a). Following formulas are used to\ncompute soft truth values for the conjunctions (∧),\ndisjunctions (∨) and negations ( ¬) in the logical\nformulas.\nI(l1 ∧l2) =max{0, I(l1) +I(l2) −1}\nI(l1 ∨l2) =min{I(l1) +I(l2), 1}\nI(¬l1) = 1−I(l1)\n(2)\nThen, a given rule r ≡rbody →rhead, it is\nsaid to be satisﬁed (i.e. I(r) = 1) iff I( rbody)\n≤ I(rhead). Otherwise, PSL deﬁnes a dis-\ntance to satisfaction d(r) which captures how far\na rule r is from being satisﬁed: d(r) = max {0,\nI(rbody) - I( rhead)}. For example, assume we\nhave the set of evidence: I( spouse(B, A)) = 1,\nI(isChildOf (P, B)) = 0.9, I( isChildOf (P, A))\n= 0.7, and that r is the resulting ground\ninstance of rule (1). Then I( spouse(B, A)\n∧isChildOf (P, B))=max{0,1+0.9-1}=0.9, and\nd(r)=max{0,0.9-0.6}=0.3\nPSL is primarily designed to support Most\nProbable Explanation (MPE) inference. MPE in-\nference is the task of ﬁnding the overall interpre-\ntation (combination of grounded atoms) with the\nmaximum probability given a set of evidence. In-\ntuitively, the interpretation with the highest proba-\nbility is the interpretation with the lowest distance\nto satisfaction. In other words, it is the interpreta-\ntion that tries to satisfy all rules as much as possi-\nble.\nWe used the PSL framework to combine the re-\nsults from the other modules in our approach and\ngenerate the conﬁdence scores for each of the an-\nswer choices. The conﬁdence scores are generated\nfor the predicatecoref(p,ai) where p is the variable\nrepresenting a pronoun to be resolved in a WSC\nproblem and ai is a variable representing an an-\nswer choice in the WSC problem.\nTo be able to use the alignment information\nfrom the knowledge hunting approach, following\nPSL rule was written. It is used to generate the\ncoref predicate and its truth value for the answer\n6116\nchoices.\nw : {∀a, e1, e2, k, p.\naligned with(a, e1, k)∧\naligned with(p, e2, k)∧\nsimilar(e1, e2)∧\n→coref(p, a)}\n(3)\nHere w is the weight of the rule, a, p, e1, e2\nand k are variables such that a is an answer choice\nin a WSC problem, p is the pronoun to be re-\nsolved in a WSC problem, and e1 and e2 are en-\ntities in a knowledge text k. The groundings of\nthe aligned with predicate are generated from the\nknowledge hunting module and the groundings of\nthe similar predicate encode the similar entities\nin k. The truth value of a grounding of similar\npredicate is used to represent how similar the two\nentities, i.e., e1 and e2, are to each other. Al-\nthough any kind of semantic similarity calculation\nalgorithm may be used for producing the similar\npredicate, we used BERT (Devlin et al., 2018) to\ncalculate the similarity between two entities. In\ncase the values of e1 and e2 are same (say E) the\ntruth value of the grounded atom similar(E, E)\nbecomes 1.\nIntuitively, the above rule means that if an an-\nswer choice and the pronoun to be resolved in\na WSC problem align with similar entities in a\nknowledge text corresponding to the WSC prob-\nlem then the pronoun refers to the answer choice.\nThe above rule applies to all the three cases\nmentioned in the Table 1.\nThe neural language models approach produces\ntwo groundings of the atom deﬁned by the binary\npredicate coref as its result (see section 3.2). The\ntwo groundings refer to the co-reference between\nthe pronoun to be resolved and the two answer\nchoices respectively. The groundings are accom-\npanied with their probabilities which we used as\ntheir truth values. These grounded coref atoms\nare directly entered as input to the PSL framework\nalong with the output from knowledge hunting ap-\nproach to infer the truth values for thecoref atom\nwith respect to each of the answer choices. Finally,\nthe answer choice with higher truth value is con-\nsidered as the correct co-referent of the pronoun to\nbe resolved and hence the ﬁnal answer.\n4 Experiments\n4.1 Dataset\nThe Winograd Schema Challenge corpus1 consists\nof pronoun resolution problems where a set of sen-\ntences is given along with a pronoun in the sen-\ntences and two possible answer choices such that\nonly one choice is correct. There are 285 prob-\nlems in the WSC dataset. From this point on-\nward, we will call this dataset as WSC 285. The\ngeneration of the original WSC dataset itself is\nan ongoing work. Hence the dataset keeps get-\nting updated. This is why the works earlier than\nours, used a smaller dataset containing 273 prob-\nlems. All the problems in it are also present in\nWSC 285. From this point onward, we will call\nthis subset of WSC 285 as WSC 273. For a fair\ncomparison between our work and others’, we\nperformed our experiments with respect to both\nWSC 285 and WSC 273. The core to reproduce\nthe results of this paper is available at https:\n//github.com/Ashprakash/CKLM.\n4.2 Experimental Setup and Results\nFirst, we compared the results of our system with\nthe previous works in terms of the number of cor-\nrect predictions. The language models based com-\nponent of our approach relies on pre-trained lan-\nguage models. Here we compared two different\nlanguage models. First we used the ensemble of\n14 pre-trained language models which are used in\n(Trinh and Le, 2018). Secondly, we used BERT\n(Devlin et al., 2018) pre-trained model. Based\non the language model used, in the following ex-\nperiments we use OUR METHODT2018 to repre-\nsent our approach which uses models from (Trinh\nand Le, 2018) and OUR METHODBERT to rep-\nresent our approach which uses the BERT lan-\nguage model. We compared our method with\nﬁve other methods (two language models based\nand three others). The comparison results are as\nshown in the Table 2. The ﬁrst two, (Sharma\net al., 2015b) and (Liu et al., 2017) hereafter called\nS2015 and L2017 respectively, address a subset\nof WSC problems (71 problems). Both of them\nare able to exploit only causal knowledge. This\nexplains their low coverage over the entire cor-\npus. We overcome this issue by using any form\nof knowledge text making predictions for each of\n1Available at https://cs.nyu.edu/\nfaculty/davise/papers/WinogradSchemas/\nWSCollection.xml\n6117\nthe problems in the dataset. More recently, two\napproaches on solving the WSC 273 dataset have\nbeen proposed. The ﬁrst work (Emami et al.,\n2018a) (hereafter called E2018) extract knowl-\nedge in form of sentences to ﬁnd evidences to sup-\nport each of the possible answer choices. A com-\nparison between their results and our is present in\nthe Table 2. Another work (Trinh and Le, 2018)\n(hereafter called T2018) uses a neural network\narchitecture to learn language models from huge\ndata sources to predict the probability of choos-\ning one answer over the other is also compared as\nshown in the Table 2.\nWe performed a second set of experiments to\nfurther investigate the robustness of our method as\ncompared to the state-of-the-art system (T2018).\nEach problem in the WSC has a sister problem in\nthe WSC such that the texts in the two problems\ndiffer only by a word or two but the same pronoun\nrefers to different entities. The two answer choices\nfor both the problems in the pair are also same. For\nexample, consider the following pair of problems.\nS4: The ﬁremen arrived after the police be-\ncause they were coming from so far away.\nPronoun to resolve:they\nAnswer Choices:a) ﬁremen b) police\nS5: The ﬁremen arrived before the police be-\ncause they were coming from so far away .\nPronoun to resolve:they\nAnswer Choices:a) ﬁremen b) police\nIn the above problems, only changing one word\n(before/after) in the sentence changes the answer\nto the problem. Due to this property of the dataset,\na system can achieve an accuracy of 50% by just\nanswering choice 1 as the correct answer for every\nproblem. To make sure that this is not the case in\nour system, we performed the following two ex-\nperiments.\n1. Experiment to Evaluate Pairwise Accu-\nracy: In this experiment we evaluate our\nmethod and the other methods to ﬁnd out\nhow many of the problem pairs were cor-\nrectly solved. The table 3 shows the re-\nsults of the experiment. It can be seen\nfrom the results that our best performing\nmethod(OUR METHODBERT on WSC 273)\nsolves 57 pairs correctly, which is signiﬁ-\ncantly more than its baseline ‘BERT Only’\nmethod. Similar pattern for the other meth-\nods can be seen in the Table 3.\n2. Experiment to Evaluate System Bias:In\nthis experiment we evaluate our method and\nthe others to ﬁnd out if the methods are biased\nto chose the answer choice which is closer to\nthe pronoun in a WSC sentence. We found\nthat usually the answer choice 2 in the prob-\nlem is closer to the pronoun to be resolved.\nHence the experiments were performed to\nﬁgure out how many times a method answers\nchoice 2 as the ﬁnal answer. The results of\nthe experiments are as shown in the Table 3.\nAs seen from the results, both, the language\nmodel based methods and our methods are\nnot particularly biased towards one of the an-\nswer choices.\n4.3 Remarks\nOur best performing setting\n(OUR METHODBERT on WSC 273) correctly\nanswers 26 problems which are incorrectly\nanswered by the baseline language model (BERT\nOnly on WSC273). We found that the main reason\nfor such a behavior is the addition of the suitable\nknowledge from the knowledge hunting module.\nIt helps in generating the support for the correct\nanswer to the extent that it overturns the decision\nof the language model. For example, we observed\nthat for the WSC sentence ‘The woman held the\ngirl against her will’ the BERT language model\npredicted that ‘her’refers to ‘The woman’ with\nthe probability score of 0.513, which is incorrect,\nand to ‘the girl’ with the probability score of\n0.486. But the knowledge hunting approach alone\nwithin the PSL framework predicted the answer\nto be ‘the girl’with the probability score of 0.966,\nwhich is correct, and the answer ‘the woman’\nwith the probability score of 0.034. Overall the\nPSL inference engine combined scores from both\nthe approaches and corrected the decision made\nby the language model by predicting ‘the girl’as\nthe correct answer with the probability score of\n0.967.\nOn the other hand ﬁve problems were found to\nbe incorrectly answered by our approach which\nwere correctly answered by the language model.\nIn all such cases the probabilities corresponding\nto the answer choices were found to be very close\nto each other and inclining towards the incor-\n6118\n#correct % Correct\nS2015 49 18.0\nL2017 43 15.0\nE2018 119 44.0\nT2018 ( WSC 273 ) 174 63.70\nT2018 ( WSC 285 ) 180 63.15\nBERT Only ( WSC 273 ) 173 63.36\nBERT Only ( WSC 285 ) 179 62.80\nOUR METHOD T 2018 (WSC 273 ) 189 69.23\nOUR METHOD T 2018 (WSC 285 ) 195 68.42\nOUR METHOD BERT (WSC 273 ) 194 71.06\nOUR METHOD BERT (WSC 285 ) 200 70.17\nTable 2: Evaluation Results\nCorrect Pairs Incorrect Pairs #Times Choice2 is Chosen\nT2018 (WSC 273) 42 89 142\nT2018 (WSC 285) 44 97 146\nBERT Only (WSC 273) 36 94 129\nBERT Only (WSC 285) 37 101 131\nOUR METHODT2018 (WSC 273) 60 71 143\nOUR METHODT2018 (WSC 285) 61 80 148\nOUR METHODBERT (WSC 273) 57 74 130\nOUR METHODBERT (WSC 285) 58 83 134\nTable 3: Additional Experiments\nrect answer. The difference between language\nmodel probabilities generally being very small, the\ncombined approach answered incorrectly in such\ncases. The main reason for such a behavior is the\navailability of unsuitable knowledge text. For ex-\nample the knowledge text for the WSC sentence\n‘The man lifted the boy onto his shoulders . ’ was\n‘If she scores I’ll feel really bad!’ New documen-\ntary lifts the lid on life for female stars who are\npartners but line up for rival clubs’. A similar pat-\ntern was found in the other settings as well.\n5 Conclusion\nAutomatic extraction of the needed commonsense\nknowledge is a major obstacle in solving the\nWinograd Schema Challenge. We observed that\nsometimes the needed knowledge can be retrieved\nfrom the pre-trained neural language models. At\nother times a more involved knowledge about ac-\ntions and properties is needed. So, in this work\nwe utilized the knowledge embedded in the pre-\ntrained language models and developed a tech-\nnique to automatically extract the more involved\ncommonsense knowledge from text repositories.\nThen we deﬁned an approach to combine the two\nkinds of knowledge in a probabilistic soft logic\nbased framework to solve the Winograd Schema\nChallenge (WSC). The experimental results show\nthat the combined approach possesses the beneﬁts\nof both the approaches and achieves the state-of-\nthe-art accuracy on the WSC.\nThis work presents an approach to combine the\nideas of knowledge hunting and language model-\ning to perform commonsense reasoning. It is a\ngeneral approach may be applied to other com-\nmonsense reasoning tasks which require the both\nthe knowledge embedded in the pre-trained lan-\nguage models and more involved knowledge about\nactions and properties.\nAcknowledgement\nSupport from DARPA and NSF grant 1816039 is\nacknowledged.\n6119\nReferences\nDan Bailey, Amelia Harrison, Yuliya Lierler, Vladimir\nLifschitz, and Julian Michael. 2015. The winograd\nschema challenge and reasoning about correlation.\nIn In Working Notes of the Symposium on Logical\nFormalizations of Commonsense Reasoning.\nJaime G Carbonell and Ralf D Brown. 1988. Anaphora\nresolution: a multi-strategy approach. In Pro-\nceedings of the 12th conference on Computational\nlinguistics-Volume 1, pages 96–101. Association for\nComputational Linguistics.\nYongrui Chen, Huiying Li, and Zejian Xu. 2018. Con-\nvolutional neural network-based question answer-\ning over knowledge base with type constraint. In\nChina Conference on Knowledge Graph and Seman-\ntic Computing, pages 28–39. Springer.\nPeter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot,\nAshish Sabharwal, Carissa Schoenick, and Oyvind\nTafjord. 2018. Think you have solved question an-\nswering? try arc, the ai2 reasoning challenge. arXiv\npreprint arXiv:1803.05457.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. arXiv preprint arXiv:1810.04805.\nAli Emami, Noelia De La Cruz, Adam Trischler, Ka-\nheer Suleman, and Jackie Chi Kit Cheung. 2018a.\nA knowledge hunting framework for common sense\nreasoning. In Proceedings of the 2018 Conference\non Empirical Methods in Natural Language Pro-\ncessing, pages 1949–1958.\nAli Emami, Adam Trischler, Kaheer Suleman, and\nJackie Chi Kit Cheung. 2018b. A generalized\nknowledge hunting framework for the winograd\nschema challenge. In Proceedings of the 2018 Con-\nference of the North American Chapter of the Asso-\nciation for Computational Linguistics: Student Re-\nsearch Workshop, pages 25–31.\nLuheng He, Mike Lewis, and Luke Zettlemoyer. 2015.\nQuestion-answer driven semantic role labeling: Us-\ning natural language to annotate natural language.\nIn Proceedings of the 2015 conference on empirical\nmethods in natural language processing, pages 643–\n653.\nNicos Isaak and Loizos Michael. 2016. Tackling the\nwinograd schema challenge through machine logical\ninferences. In STAIRS, volume 284, pages 75–86.\nAngelika Kimmig, Stephen H Bach, Matthias\nBroecheler, Bert Huang, and Lise Getoor. 2012.\nA short introduction to probabilistic soft logic. In\nNIPS Workshop on probabilistic programming:\nFoundations and applications, volume 1, page 3.\nHector J Levesque, Ernest Davis, and Leora Morgen-\nstern. 2011. The winograd schema challenge. In\nAAAI Spring Symposium: Logical Formalizations of\nCommonsense Reasoning, volume 46, page 47.\nQuan Liu, Hui Jiang, Andrew Evdokimov, Zhen-Hua\nLing, Xiaodan Zhu, Si Wei, and Yu Hu. 2017.\nCause-effect knowledge acquisition and neural asso-\nciation model for solving a set of winograd schema\nproblems. In Proceedings of the Twenty-Sixth Inter-\nnational Joint Conference on Artiﬁcial Intelligence\n(IJCAI), pages 2344–2350.\nXiaodong Liu, Pengcheng He, Weizhu Chen, and Jian-\nfeng Gao. 2019. Multi-task deep neural networks\nfor natural language understanding. arXiv preprint\narXiv:1901.11504.\nTodor Mihaylov, Peter Clark, Tushar Khot, and Ashish\nSabharwal. 2018. Can a suit of armor conduct elec-\ntricity? a new dataset for open book question an-\nswering. arXiv preprint arXiv:1809.02789.\nGeorge A Miller. 1995. Wordnet: a lexical database for\nenglish. Communications of the ACM , 38(11):39–\n41.\nBhavana Dalvi Mishra, Lifu Huang, Niket Tandon,\nWen-tau Yih, and Peter Clark. 2018. Tracking state\nchanges in procedural text: A challenge dataset and\nmodels for process paragraph comprehension. arXiv\npreprint arXiv:1805.06975.\nVincent Ng. 2017. Machine learning for entity corefer-\nence resolution: A retrospective look at two decades\nof research. In AAAI, pages 4877–4884.\nAnkur P Parikh, Oscar T ¨ackstr¨om, Dipanjan Das, and\nJakob Uszkoreit. 2016. A decomposable attention\nmodel for natural language inference. arXiv preprint\narXiv:1606.01933.\nKarthik Raghunathan, Heeyoung Lee, Sudarshan Ran-\ngarajan, Nathanael Chambers, Mihai Surdeanu, Dan\nJurafsky, and Christopher Manning. 2010. A multi-\npass sieve for coreference resolution. In Proceed-\nings of the 2010 Conference on Empirical Methods\nin Natural Language Processing , pages 492–501.\nAssociation for Computational Linguistics.\nPeter Sch ¨uller. 2014. Tackling winograd schemas by\nformalizing relevance theory in knowledge graphs.\nIn Fourteenth International Conference on the Prin-\nciples of Knowledge Representation and Reasoning.\nArpit Sharma, Nguyen V o, Somak Aditya, and Chitta\nBaral. 2015a. Identifying various kinds of event\nmentions in k-parser output. In Proceedings of the\nThe 3rd Workshop on EVENTS: Deﬁnition, Detec-\ntion, Coreference, and Representation, pages 82–88.\nArpit Sharma, Nguyen Ha V o, Somak Aditya, and\nChitta Baral. 2015b. Towards addressing the wino-\ngrad schema challenge-building and using a seman-\ntic parser and a knowledge hunting module. In IJ-\nCAI, pages 1319–1325.\nTrieu H Trinh and Quoc V Le. 2018. A simple\nmethod for commonsense reasoning. arXiv preprint\narXiv:1806.02847."
}