{
    "title": "Keep CALM and Explore: Language Models for Action Generation in Text-based Games",
    "url": "https://openalex.org/W3091858927",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2357025878",
            "name": "Yao Shunyu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4288511183",
            "name": "Rao, Rohan",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4225232215",
            "name": "Hausknecht, Matthew",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4221425244",
            "name": "Narasimhan, Karthik",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2465628802",
        "https://openalex.org/W2130942839",
        "https://openalex.org/W2972936639",
        "https://openalex.org/W2998557583",
        "https://openalex.org/W2963771109",
        "https://openalex.org/W3121541553",
        "https://openalex.org/W2962776342",
        "https://openalex.org/W2153579005",
        "https://openalex.org/W2902391430",
        "https://openalex.org/W2912937857",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W2970252402",
        "https://openalex.org/W2954579883",
        "https://openalex.org/W2963626623",
        "https://openalex.org/W2903394565",
        "https://openalex.org/W7542544",
        "https://openalex.org/W2952222085",
        "https://openalex.org/W3000752281",
        "https://openalex.org/W3101555782",
        "https://openalex.org/W2997475283",
        "https://openalex.org/W2964199361",
        "https://openalex.org/W2594726847",
        "https://openalex.org/W2539809671",
        "https://openalex.org/W3024893463"
    ],
    "abstract": "Text-based games present a unique challenge for autonomous agents to operate in natural language and handle enormous action spaces. In this paper, we propose the Contextual Action Language Model (CALM) to generate a compact set of action candidates at each game state. Our key insight is to train language models on human gameplay, where people demonstrate linguistic priors and a general game sense for promising actions conditioned on game history. We combine CALM with a reinforcement learning agent which re-ranks the generated action candidates to maximize in-game rewards. We evaluate our approach using the Jericho benchmark, on games unseen by CALM during training. Our method obtains a 69% relative improvement in average game score over the previous state-of-the-art model. Surprisingly, on half of these games, CALM is competitive with or better than other models that have access to ground truth admissible actions. Code and data are available at https://github.com/princeton-nlp/calm-textgame.",
    "full_text": "Keep CALM and Explore:\nLanguage Models for Action Generation in Text-based Games\nShunyu Yao†, Rohan Rao†, Matthew Hausknecht‡, Karthik Narasimhan†\n†Princeton University ‡Microsoft Research\n{shunyuy, rohanr, karthikn}@princeton.edu\nmatthew.hausknecht@microsoft.com\nAbstract\nText-based games present a unique challenge\nfor autonomous agents to operate in natural\nlanguage and handle enormous action spaces.\nIn this paper, we propose the Contextual Ac-\ntion Language Model (CALM) to generate a\ncompact set of action candidates at each game\nstate. Our key insight is to train language mod-\nels on human gameplay, where people demon-\nstrate linguistic priors and a general game\nsense for promising actions conditioned on\ngame history. We combine CALM with a re-\ninforcement learning agent which re-ranks the\ngenerated action candidates to maximize in-\ngame rewards. We evaluate our approach us-\ning the Jericho benchmark (Hausknecht et al.,\n2019a), on games unseen by CALM during\ntraining. Our method obtains a 69% relative\nimprovement in average game score over the\nprevious state-of-the-art model. Surprisingly,\non half of these games, CALM is competitive\nwith or better than other models that have ac-\ncess to ground truth admissible actions.*\n1 Introduction\nText-based games have proven to be useful testbeds\nfor developing agents that operate in language. As\ninteractions in these games (input observations, ac-\ntion commands) are through text, they require solid\nlanguage understanding for successful gameplay.\nWhile several reinforcement learning (RL) models\nhave been proposed recently (Narasimhan et al.,\n2015; He et al., 2015; Hausknecht et al., 2019a;\nAmmanabrolu and Riedl, 2019), combinatorially\nlarge action spaces continue to make these games\nchallenging for these approaches.\nThe action space problem is exacerbated by the\nfact that only a tiny fraction of action commands\nare admissible in any given game state. An admis-\nsible action is one that is parseable by the game\n*Code and data are available at https://github.\ncom/princeton-nlp/calm-textgame.\nObservation: You are in the living room.\nThere is a doorway to the east, a wooden door\nwith strange gothic lettering to the west, which\nappears to be nailed shut, a trophy case, and\na large oriental rug in the center of the room.\nYou are carrying: A brass lantern . . .\nRandom Actions:\nclose door, north a, eat troll with egg, . . .\nCALM (n-gram) Actions:\nenter room, leave room, lock room,\nopen door, close door, knock on door, . . .\nCALM (GPT-2) Actions:\neast, open case, get rug, turn on lantern,\nmove rug, unlock case with key, . . .\nNext Observation: With a great effort, the rug\nis moved to one side of the room, revealing\nthe dusty cover of a closed trap door...\nFigure 1: Sample gameplay from Z ORK 1 along with\naction sets generated by two variants of CALM. The\ngame recognizes a vocabulary size of 697, resulting in\nmore than 6974 ≈200 billion potential 4-word actions.\n‘move rug’ is the optimal action to take here and is gen-\nerated by our method as a candidate.\nengine and changes the underlying game state. For\nexample, in Figure 1, one can observe that ran-\ndomly sampling actions from the game vocabulary\nleads to several inadmissible ones like ‘ north a’\nor ‘eat troll with egg’. Thus, narrowing down the\naction space to admissible actions requires both\nsyntactic and semantic knowledge, making it chal-\nlenging for current systems.\nFurther, even within the space of admissible ac-\ntions, it is imperative for an autonomous agent to\nknow which actions are most promising to advance\nthe game forward, and explore them ﬁrst. Hu-\nman players innately display such game-related\ncommon sense. For instance in Figure 1, players\narXiv:2010.02903v1  [cs.CL]  6 Oct 2020\nmight prefer the command “move rug” over “knock\non door” since the door is nailed shut. However,\neven the state-of-the-art game-playing agents do\nnot incorporate such priors, and instead rely on\nrule-based heuristics (Hausknecht et al., 2019a)\nor handicaps provided by the learning environ-\nment (Hausknecht et al., 2019a; Ammanabrolu and\nHausknecht, 2020) to circumvent these issues.\nIn this work, we propose the Contextual Action\nLanguage Model (CALM) to alleviate this chal-\nlenge. Speciﬁcally, at each game step we use\nCALM to generate action candidates, which are\nfed into a Deep Reinforcement Relevance Network\n(DRRN) (He et al., 2015) that uses game rewards\nto learn a value function over these actions. This al-\nlows our model to combine generic linguistic priors\nfor action generation with the ability to adaptively\nchoose actions that are best suited for the game.\nTo train CALM, we introduce a novel dataset of\n426 human gameplay transcripts for 590 different\ntext-based games. While these transcripts are noisy\nand actions are not always optimal, they contain\na substantial amount of linguistic priors and game\nsense. Using this dataset, we train a single instance\nof CALM and deploy it to generate actions across\nmany different downstream games. Importantly,\nin order to demonstrate the generalization of our\napproach, we do not use any transcripts from our\nevaluation games to train the language model.\nWe investigate both n-gram and state-of-the-art\nGPT-2 (Radford et al., 2019) language models and\nﬁrst evaluate the quality of generated actions in\nisolation by comparing against ground-truth sets of\nadmissible actions. Subsequently, we evaluate the\nquality of CALM in conjunction with RL over 28\ngames from the Jericho benchmark (Hausknecht\net al., 2019a). Our method outperforms the previ-\nous state-of-the-art method by 69% in terms of aver-\nage normalized score. Surprisingly, on 8 games our\nmethod even outperforms competing methods that\nuse the admissible action handicap – for example,\nin the game of INHUMANE , we achieve a score of\n25.7 while the state-of-the-art KG-A2C agent (Am-\nmanabrolu and Hausknecht, 2020) achieved 3.\nIn summary, our contributions are two-fold.\nFirst, we propose a novel learning-based approach\nfor reducing enormous action spaces in text-based\ngames using linguistic knowledge. Second, we\nintroduce a new dataset of human gameplay tran-\nscripts, along with an evaluation scheme to measure\nthe quality of action generation in these games.\n2 Related Work\nReinforcement Learning for Text-based Games\nEarly work on text-based games (Narasimhan et al.,\n2015; He et al., 2015) developed RL agents on\nsynthetic environments with small, pre-deﬁned text\naction spaces. Even with small actions spaces (e.g.\n< 200 actions), approaches to ﬁlter inadmissible\nactions (Zahavy et al., 2018; Jain et al., 2019) led to\nfaster learning convergence. Recently, Hausknecht\net al. (2019a) introduced Jericho – a benchmark of\nchallenging man-made text games. These games\ncontain signiﬁcantly greater linguistic variation and\nlarger action spaces compared to frameworks like\nTextWorld (Cˆot´e et al., 2018).\nTo assist RL agents, Jericho provides a handicap\nthat identiﬁes admissible actions at each game state.\nThis has been used by approaches like DRRN (He\net al., 2015) as a reduced action space. Other RL\nagents like TDQN (Hausknecht et al., 2019a) and\nKGA2C (Ammanabrolu and Hausknecht, 2020)\nrely on the handicap for an auxiliary training loss.\nIn general, as these RL approaches lack linguistic\npriors and only learn through in-game rewards, they\nare reliant on the admissible-action handicap to\nmake the action space tractable to explore.\nLinguistic Priors for Text-based GamesA dif-\nferent line of work has explored various linguistic\npriors for generating action commands. Fulda et al.\n(2017) used Word2vec (Mikolov et al., 2013) em-\nbeddings to infer affordance properties (i.e. verbs\nsuitable for an object). Other approaches (Kostka\net al., 2017; Hausknecht et al., 2019b) trained sim-\nple n-gram language models to learn affordances\nfor action generation. Perhaps most similar to\nour work is that of Tao et al. (2018), who trained\nseq2seq (Sutskever et al., 2014) models to produce\nadmissible actions in synthetic TextWorld (C ˆot´e\net al., 2018) games. In a slightly different setting,\nUrbanek et al. (2019) trained BERT (Devlin et al.,\n2018) to generate contextually relevant dialogue\nutterances and actions in fantasy settings. However,\nthese approaches are game-speciﬁc and do not use\nany reinforcement learning to optimize gameplay.\nIn contrast, we combine strong linguistic priors\nwith reinforcement learning, and use a modern lan-\nguage model that can generate complex actions and\nﬂexibly model the dependency between actions and\ncontexts. We also train on multiple games and gen-\neralize to unseen games.\nCALM\nConcat\nGRU !!\nGRU !\" Softmax SampleDRRN\n##,%open mailbox##,*unlock case##,+go east\n\"#$%“You are south of house...”##$%“go north”\"# “You see a locked case…”Context$#=(\"#$%,##$%,\"#)\nObservation\"#\n……\nAction Candidates)&'($#)\n!!(\"#)\n!\"(##,))\nMLP*+(\"#,##,))\n##“unlock case”\nFigure 2: CALM combined with an RL agent – DRRN (He et al., 2015) – for gameplay. CALM is trained on\ntranscripts of human gameplay for action generation. At each state, CALM generates action candidates conditioned\non the game context, and the DRRN calculates the Q-values over them to select an action. Once trained, a single\ninstance of CALM can be used to generate actions for any text-based game.\nGeneration in Text-based Games and Interac-\ntive Dialog Besides solving games, researchers\nhave also used language models to create text-\nbased games. Ammanabrolu et al. (2019) used\nMarkov chains and neural language models to pro-\ncedurally generate quests for TextWorld-like games.\nAI Dungeon 2 (Walton, 2019) used GPT-2 to gen-\nerate narrative text in response to arbitrary text ac-\ntions, but lacked temporal consistency over many\nsteps.\nMore broadly, the concept of generating can-\ndidates and re-ranking has been studied in other\ninteractive lanugage tasks such as dialogue (Zhao\nand Eskenazi, 2016; Williams et al., 2017; Song\net al., 2016; Chen et al., 2017) and communication\ngames (Lazaridou et al., 2020). These approaches\noften focus on improving aspects like ﬂuency and\naccuracy of the generated utterances, whereas our\nre-ranking approach only aims to maximize future\nrewards in the task. Also, our CALM pre-trained\nmodel generalizes to new environments without\nrequiring any re-training.\n3 Method\n3.1 Background\nA text-based game can be formally speciﬁed as\na partially observable Markov decision process\n(POMDP) (S,T,A,O,R,γ ), where a player issues\ntext actions a∈Aand receives text observations\no ∈O and scalar rewards r = R(s,a) at each\nstep. Different games have different reward de-\nsigns, but typically provide sparse positive rewards\nfor solving key puzzles and advancing the story,\nand negative rewards for dying. γ ∈[0,1] is the\nreward discount factor. Latent state s∈Scontains\nthe current game information (e.g. locations of the\nplayer and items, the player’s inventory), which is\nonly partially reﬂected in o. The transition function\ns′= T(s,a) speciﬁes how action ais applied on\nstate s, and ais admissible at state sif T(s,a) ̸= s\n(i.e. if it is parseable by the game and changes the\nstate). S, T and Rare not provided to the player.\nReinforcement Learning One approach to de-\nveloping text-based game agents is reinforcement\nlearning (RL). The Deep Reinforcement Rele-\nvance Network (DRRN) (He et al., 2015) is an\nRL algorithm that learns a Q-network Qφ(o,a)\nparametrized by φ. The model encodes the ob-\nservation oand each action candidate ausing two\nseparate encoders fo and fa (usually recurrent neu-\nral networks such as GRU (Cho et al., 2014)), and\nthen aggregates the representations to derive the\nQ-value through a decoder g:\nQφ(o,a) =g(fo(o),fa(a)) (1)\nFor learning φ, tuples (o,a,r,o ′) of observation,\naction, reward and the next observation are sampled\nfrom an experience replay buffer and the following\ntemporal difference (TD) loss is minimized:\nLTD(φ) = (r+γmax\na′∈A\nQφ(o′,a′)−Qφ(o,a))2 (2)\nDuring gameplay, a softmax exploration policy is\nused to sample an action:\nπφ(a|o) = exp(Qφ(o,a))∑\na′∈Aexp(Qφ(o,a′)) (3)\nWhile the above equation contains only a single\nobservation, this can also be extended to a pol-\nicy π(a|c) conditioned on a longer context c =\n(o1,a1,...,o t) of previous observations and actions\ntill current time step t. Note that when the action\nspace Ais large, (2) and (3) become intractable.\n3.2 Contextual Action Language Model\n(CALM)\nTo reduce large action spaces and make learning\ntractable, we train language models to generate\ncompact sets of actions candidates. Consider a\ndataset Dof N trajectories of human gameplay\nacross different games, where each trajectory of\nlength lconsists of interleaved observations and ac-\ntions (o1,a1,o2,a2,··· ,ol,al). The context ct at\ntimestep tis deﬁned as the history of observations\nand actions, i.e. ct = (o1,a1,...,a t−1,ot). In prac-\ntice, we ﬁnd that a window size of 2 works well, i.e.\nct = (ot−1,at−1,ot). We train parametrized lan-\nguage models pθ to generate actions aconditioned\non contexts c. Speciﬁcally, we use all N trajecto-\nries and minimize the following cross-entropy loss:\nLLM(θ) =−E(a,c)∼Dlog pθ(a|c) (4)\nSince each action ais typically a multi-word phrase\nconsisting of mtokens a1,a2,··· ,am, we can fur-\nther factorize the right hand side of (4) as:\npθ(a|c) =\nm∏\ni=1\npθ(ai|a<i,c) (5)\nThus, we can simply use the cross-entropy loss\nover each token ai in action aduring training. We\ninvestigate two types of language models:\n1. n-gram : This model simply uses n-gram\ncounts from actions in Dto model the following\nprobability:\np(n,α)(ai|a<i) = cnt(ai−n+1,··· ,ai) +α\ncnt(ai−n+1,··· ,ai−1) +α|V|\n(6)\nwhere cnt(ai,··· ,aj) counts the number of occur-\nrences of the action sub-sequence (ai,··· ,aj) in\nthe training set, α is a smoothing constant, and\nV is the token vocabulary. Note that this model\nis trained in a context-independent way and only\ncaptures basic linguistic structure and common af-\nfordance relations observed in human actions. We\noptimize the parameters (n,α) to minimize the per-\nplexity on a held-out validation set of actions.\nTo generate top actions given contextc, we con-\nstruct a restricted action spaceAc = V×Bc, where\nVis the set of verb phrases (e.g. open, knock on)\ncollected from training actions, and Bc is the set\nof nouns (e.g. door) detected in cusing spaCy’s†\nnoun-phrase detection. Then we calculate p(n,α)(a)\nfor each a∈Ac and choose the top ones.\n2. GPT-2(Radford et al., 2019): We use a pre-\ntrained GPT-2 and train it on Daccording to (4)\nand (5). Unlike the previous n-gram model, GPT-2\nhelps model dependencies between the context and\nthe action in a ﬂexible way, relying on minimal\nassumptions about the structure of actions. We use\nbeam search to generate most likely actions.\n3.3 Reinforcement Learning with CALM\nThough language models learn to generate useful\nactions, they are not optimized for gameplay perfor-\nmance. Therefore, we use CALM to generate top-k\naction candidates ALM(c,k) ⊂Agiven context c,\nand train a DRRN to learn a Q-function over this\naction space. This can be done by simply replac-\ning Awith ALM(c,k) in equations (2) and (3). In\nthis way, we combine the CALM’s generic action\npriors with the ability of RL to learn policies opti-\nmized for the gameplay. We choose not to ﬁne-tune\nCALM in RL so as to avoid overﬁtting to a speciﬁc\ngame and invalidate the general priors present in\nCALM.\nTo summarize, we employ CALM for providing\na reduced action space for text adventure agents to\nexplore efﬁciently. Even though we choose a spe-\nciﬁc RL agent (DRRN) in our experiments, CALM\nis simple and generic, and can be combined with\nany RL agent.\n4 Experimental Setup\nWe perform empirical studies to 1) evaluate the\nquality of actions generated by CALM in isolation\nfrom the complexities of RL, 2) evaluate CALM\ncombined with an RL agent for gameplay, and 3)\nanalyze what factors contribute to the effectiveness\nof our method. We describe our setup in this section\nand provide results in Section 5.\n4.1 Data and Environment\nClubFloyd Dataset We collect data from\nClubFloyd‡, which archives transcripts of hu-\nmans cooperatively playing text-based games. We\n†https://spacy.io/\n‡http://www.allthingsjacq.com/\ninteractive_fiction.html#clubfloyd\n0 100 200\nNumber of Tokens\n0\n10000\n20000\n30000\nObservation Length\n2 4 6\nNumber of Tokens\n0\n20000\n40000\n60000\n80000\n100000Frequency\nAction Length\nFigure 3: Distributions of actions and observations in\nthe ClubFloyd Dataset, in terms of the number of to-\nkens. Actions more than 7 tokens ( <0.5%) and obser-\nvations more than 256 tokens (<2%) are trimmed.\ncrawl 426 transcripts covering 590 games (in\nsome transcripts people play more than one game),\nand build a dataset of 223,527 context-action\npairs {((ot−1,at−1,ot),at)}. We pre-process\nthe data by removing samples with meta-actions\n(e.g. ‘save’,’restore’) or observations with over 256\ntokens. Figure 3 visualizes the action and observa-\ntion length distributions. We also note that a few\ncommon actions (e.g. ‘north’, ‘take all’, ‘examine’)\nmake up a large portion of the data. More details\non the dataset are in the supplementary material.\nGame Environment To test our RL agents, we\nuse 28 man-made text games from the Jericho\nframework (Hausknecht et al., 2019a). We aug-\nment state observations with location and inven-\ntory descriptions by issuing the ‘look’ and ‘inven-\ntory’ commands, following the standard practice\ndescribed in Hausknecht et al. (2019a).\nThe Jericho framework implements an admissi-\nble action handicapby enumerating all combina-\ntions of game verbs and objects at each state, and\ntesting each action’s admissibility by accessing the\nunderlying simulator states and load-and-save func-\ntions. As a result, the handicap runs no faster than a\nGPT-2 inference pass, and could in fact be unavail-\nable for games outside Jericho. Jericho also pro-\nvides an optimalwalkthrough trajectory to win each\ngame. Table 1 provides statistics of the ClubFloyd\nDataset and the Jericho walkthroughs. We observe\nthat ClubFloyd has a much larger vocabulary and\na diverse set of games, which makes it ideal for\ntraining CALM. We utilize Jericho walkthroughs\nin our standalone evaluation of CALM in § 5.1.\n4.2 CALM Setup\nTraining For training CALM (n-gram), we con-\ndition only on the current observation, i.e. ct = ot\nClubFloyd Jericho\nDataset Walkthroughs\n# unique games 590 28\nVocab size 39,670 9,623\nVocab size (game avg.)2,363 1,037\nAvg. trajectory length360 98\nAction Quality Non-optimal Optimal\nTable 1: Statistics of the ClubFloyd Dataset and Jericho\nwalkthrough trajectories.\ninstead of ct = (ot−1,at−1,ot), since ot−1 and\nat−1 may contain irrelevant objects to the current\nstate. We split the dataset into 90% training set\nand 10% validation set, and choose nand αbased\non the validation set perplexity. We ﬁnd a bi-gram\nmodel n= 2,α = 0.00073 works best, achieving a\nper-action perplexity of 863,808 on the validation\nset and 17,181 on the training set.\nFor CALM (GPT-2), we start with a 12-layer,\n768-hidden, 12-head, 117M parameter GPT-2\nmodel pre-trained on the WebText corpus (Radford\net al., 2019). The implementation and pretrained\nweights of this model are obtained from Wolf et al.\n(2019). We then train it on the ClubFloyd tran-\nscripts for 3 epochs to minimize (4). We split the\ndataset into 90% training set and 10% validation\nset and we obtain a training loss of 0.25 and a vali-\ndation loss of 1.98. Importantly, both models are\ntrained only on transcripts that do not overlap with\nthe 28 Jericho games we evaluate on.\nGenerating Top Actions For every unique state\nof each game, we generate the top k = 30 ac-\ntions. For CALM (n-gram), we enumerate all ac-\ntions in Ac plus 13 one-word directional actions\n(e.g. ‘north’, ‘up’, ‘exit’). To encourage action di-\nversity, at most 4 actions are generated for each\nobject b∈Bc. For CALM (GPT-2), we use beam\nsearch with a beam size of 40, and then choose the\ntop 30 actions.\n4.3 RL Agent Setup\nTraining We use DRRN (He et al., 2015) to es-\ntimate Q-Values over action candidates generated\nby CALM. Following Hausknecht et al. (2019a),\nwe use a FastText model (Joulin et al., 2017) to\npredict the admissibility of an action based on the\ngame’s textual response and ﬁlter out candidate ac-\ntions that are found to be inadmissible. We train\nthe DRRN asynchronously on 8 parallel instances\nof the game environment for 106 steps in total. Fol-\nlowing Narasimhan et al. (2015), we use a separate\n0 10 20 30 40\n0.2\n0.4\n0.6\n0.8\nrecall (gold)\n0 10 20 30 40\nk\nrecall (admissible)\n0 10 20 30 40\nprecision (admissible)\nCALM (n-gram)\nCALM (GPT-2)\nFigure 4: Precision and recall of gold and admissible actions generated by CALM, evaluated on walkthrough\ntrajectories of 28 games provided by Jericho. k is the number of actions generated by CALM. Shaded areas\nrepresent standard deviation.\nexperience replay buffer to store trajectories with\nthe best score at any point of time. The ﬁnal score\nof a training run is taken to be the average score\nof the ﬁnal 100 episodes during training. For each\ngame, we train ﬁve independent agents with differ-\nent random seeds and report the average score. For\nmodel variants in § 5.3 we only run one trail.\nBaselines We compare with three baselines:\n1. NAIL (Hausknecht et al., 2019b): Uses hand-\nwritten rules to act and explore, therefore requires\nno reinforcement learning or oracle access to ad-\nmissible actions.\n2. DRRN (He et al., 2015): This RL agent de-\nscribed in § 3.1 uses ground-truth admissible ac-\ntions provided by the Jericho handicap.\n3. KG-A2C (Ammanabrolu and Hausknecht,\n2020): This RL agent constructs a game knowl-\nedge graph to augment the state space as well as\nconstrain the types of actions generated. During\nlearning, it requires the admissible action handicap\nto guide its exploration of the action space.\nOf these methods, DRRN and KG-A2C require\nground-truth admissible actions, which our model\ndoes not use, but we add them as reference compar-\nisons for completeness.\n5 Results\n5.1 Evaluating CALM on walkthroughs\nMetrics like validation loss or accuracy on valida-\ntion set of our ClubFloyd data are not sufﬁcient to\nevaluate CALM (see supplementary material for\ndetails on these metrics). This is because: 1) there\ncan be multiple admissible actions in each state,\nand 2) the human actions in the trajectories are\nnot guaranteed to be optimal or even admissible.\nTherefore, we use the walkthroughs provided in\nJericho to provide an additional assessment on the\nquality of actions generated by CALM.\nConsider a walkthrough to be an optimal trajec-\ntory (o1,a1,··· ,ol,al) leading to the maximum\nscore achievable in the game. At step t(1 ≤t≤l),\nthe context ct is (ot−1,at−1,ot), the gold action is\nat and the full set of admissible actions At is ob-\ntained from the Jericho handicap. Suppose the gen-\nerated set of top-kactions at step tis ALM(ct,k).\nWe then calculate the average precision of admis-\nsible actions (preca), recall of admissible actions\n(reca), and recall of gold actions (recg) as follows:\npreca(k) =1\nl\nl∑\nt=1\n|At ∩ALM(ct,k)|\nk (7)\nreca(k) =1\nl\nl∑\nt=1\n|At ∩ALM(ct,k)|\n|At| (8)\nrecg(k) =1\nl\nl∑\nt=1\n|{at}∩ALM(ct,k)| (9)\nWe calculate these metrics on each of the 28\ngames and present the averaged metrics as a func-\ntion of kin Figure 4. The reca curve shows that the\ntop k= 15actions of CALM (GPT-2 and n-gram)\nare both expected to contain around 30% of all\nadmissible actions in each walkthrough state. How-\never, when kgoes from 15 to 30, CALM (GPT-2)\ncan come up with 10% more admissible actions,\nwhile the gains are limited for CALM (n-gram).\nWhen k is small, CALM (n-gram) beneﬁts from\nits strong action assumption of one verb plus one\nobject. However, this assumption also restricts\nCALM (n-gram) from generating more complex ac-\ntions (e.g. ‘open case with key’) that CALM (GPT-\n2) can produce. This can also be seen in the recg\ncurve, where the top-30 actions from CALM (GPT-\n2) contain the gold action in 20% more game states\nthan CALM (n-gram). This gap is larger when it\ncomes to gold actions, because they are more likely\nto be complex actions that the CALM (n-gram) is\nWithout HandicapWith Handicap\nGameCALM CALM NAILKG-A2C DRRNMax(GPT-2) (n-gram) Score\n905 0 0 0 0 0 1acorncourt0 0 0 0.3 10 30advland0 0 0 0 20.6 100advent36 36 36 36 36 350anchor0 0 0 0 0 100awaken0 0 0 0 0 50balances9.1 8.9 10 10 10 51deephome1.0 1.0 13.3 1.0 1.0 300detective289.7 284.3 136.9 207.9 197.8 360dragon0.1 0.0 0.6 0 -3.5 25\nenchanter19.1 0 0 12.1 20 400inhumane25.7 1.7 0.6 3.0 0.7 90jewel0.3 0 1.6 1.8 1.6 90karn2.3 0 1.2 0 2.1 170library9.0 5.1 0.9 14.3 17.0 30ludicorp10.1 5.4 8.4 17.8 13.8 150moonlit0 0 0 0 0 1omniquest6.9 4.5 5.6 3.0 16.8 50pentari0 0 0 50.7 27.2 70snacktime19.4 0 0 0 9.7 50sorcerer6.2 5.0 5.0 5.8 20.8 400spellbrkr40 39.9 40 21.3 37.8 600\nspirit1.4 0.6 1.0 1.3 0.8 250\ntemple0 0 7.3 7.6 7.9 35zenon0 0 0 3.9 0 20zork130.4 24.8 10.3 34.0 32.6 350zork30.5 0 1.8 0.0 0.5 7ztuu3.7 0 0 9.2 21.6 100\navg. norm9.4% 5.5% 5.6% 10.8% 13.0%\nTable 2: Performance of our models (CALM (GPT-2)\nand CALM (n-gram)) compared to baselines (NAIL,\nKG-A2C, DRRN) on Jericho. We report raw scores\nfor individual games as well as average normalized\nscores (avg. norm). Advent and Deephome’s initial\nscores are 1 and 36, respectively. Underlined games\nrepresent those where CALM outperforms handicap-\nassisted methods KGA2C and DRRN.\nunable to model.\nFurther, we note that as k increases, the aver-\nage quality of the actions decreases (preca curve),\nwhile they contain more admissible actions (reca\ncurve). Thus, kplays an important role in balanc-\ning exploration (more admissible actions) with ex-\nploitation (a larger ratio of admissible actions) for\nthe RL agent, which we demonstrate empirically\nin § 5.3. We provide several examples of gener-\nated actions from both models in the supplementary\nmaterial.\n5.2 Evaluating gameplay on Jericho\nWe provide scores of our CALM-augmented\nDRRN agent on individual games in Table 2. To\ntake into account different score scales across\ngames, we consider both the raw score and the\nnormalized score (raw score divided by maximum\nscore), and only report the average normalized\nscore across games.\nOf the handicap-free models, CALM (n-gram)\nVariant avg. norm\nCALM (default) 9.4%\nCALM (20%) 8.1%\nCALM (50%) 8.4%\nCALM (w/ Jericho) 10.9%\nCALM (w/o PT) 6.8%\nCALM (k = 10) 5.6%\nCALM (k = 20) 9.6%\nCALM (k = 40) 9.2%\nCALM (random agent) 1.8%\nTable 3: Average normalized scores on Jericho for dif-\nferent variants of CALM (GPT-2). CALM (default) is\nthe CALM (GPT-2) model used for results in Table 2.\nachieves similar performance to NAIL, while\nCALM (GPT-2) outperforms CALM (n-gram) and\nNAIL by 4.4% and 3.8% on absolute normalized\nscores, respectively. Relatively, this represents al-\nmost a 69% improvement over NAIL. Figure 5\npresents a game-wise comparison between CALM\n(GPT-2) and NAIL.\nSurprisingly, even when compared to handicap-\nassisted models, CALM (GPT-2) performs quite\nwell. On 8 out of 28 games (underlined in Table 2),\nCALM (GPT-2) outperforms both DRRN and KG-\nA2C despite the latter having access to ground-\ntruth admissible actions. This improvement is es-\npecially impressive on games like DETECTIVE , IN-\nHUMANE and SNACKTIME , where our normalized\nscore is higher by more than 20%. We hypothesize\nCALM excludes some non-useful admissible ac-\ntions like “throw egg at sword” that humans never\nissue, which can speed up exploration. Also, it is\npossible that CALM sometimes discover admissi-\nble actions even the handicap cannot (due to the\nimperfection of state change detection).\n5.3 Analysis\nWhat Factors Contribute to Gameplay? We\nnow analyze various components and design\nchoices made in CALM (GPT-2). First, we in-\nvestigate how much of the model’s performance\nis due to pre-training on text corpora as opposed\nto training on our ClubFloyd data. Then, we vary\nthe number of actions (k) generated by the model.\nWe also consider combing CALM with a random\nagent instead of RL. This leads us to the following\nvariants:\n1. CALM (X%): These variants are trained\nwith only X% of the transcripts from ClubFloyd.\nX = 0 is equivalent to using a pre-trained GPT-\n-25%\n0%\n25%\n50%\ndetective snacktime inhumane  \nlibrary zork1  \nenchanter \nztuu \nomniquest ludicorp  \nkarn  \nsorcerer \nspirit  905\nacorncouradv'land  adventanchor  awaken moonlit  pentari  zenon  \nspellbrkr  \njewel  \nbalances dragon  \ndeephome  \nzork3  temple  \nFigure 5: Difference in normalized scores achieved by CALM (GPT-2) and NAIL, in decreasing order.\n0.00%\n25.00%\n50.00%\n75.00%\n100.00%\n905\nacorncourt  adv'land  adventanchor  awaken balances deephome  detective dragon  \nenchanter inhumane  \njewel  karn  library ludicorp  moonlit  \nomniquest \npentari  \nsnacktime sorcerer spellbrkr  \nspirit  temple  zenon  zork1  zork3  ztuu \nmax score seen final score\nFigure 6: Final scores (blue) and maximum scores (normalized) seen during exploration (red) for CALM (GPT-2).\nThere is a lot of potential for developing better algorithms to learn from high-scoring trajectories.\n2 model off-the-shelf – we ﬁnd that this fails to\nproduce actions that are even parseable by the game\nengine and therefore is not reported in the table.\n2. CALM (w/ Jericho): This variant is trained\non additional ClubFloyd data that includes 8 scripts\nfrom games contained in Jericho.\n3. CALM (w/o PT): This is a randomly initial-\nized GPT-2 model, instead of a pre-trained one,\ntrained on ClubFloyd data. We train this model for\n10 epochs until the validation loss converges, unlike\nprevious models which we train for 3 epochs.\n4. CALM (k= Y): This is a model variant that\nproduces action sets of size Y.\n5. CALM (random agent): This model variant\nreplaces DRRN by a random agent that samples\nuniformly from CALM top-30 actions at each state.\nAs shown in Table 3, the signiﬁcant drop in\nscore for CALM without pretraining shows that\nboth pre-training and ClubFloyd training are im-\nportant for gameplay performance. Pre-training\nprovides general linguistic priors that regularize\naction generation while the ClubFloyd data condi-\ntions the model towards generating actions useful\nin text-based games.\nAdding heldout transcripts from Jericho evalua-\ntion games (CALM w/ Jericho) provides additional\nbeneﬁt as expected, even surpassing handicap-\nassisted KG-A2C in terms of the average normal-\nized score. Counter-intuitively, we ﬁnd that the\ngreatest performance gains aren’t on games fea-\ntured in the heldout transcripts. See supplementary\nmaterial for more details.\nFor the models with different kvalues, CALM\n(k= 10) is much worse than other choices, but sim-\nilar to CALM (n-gram) in Table 2. Note that in Fig-\nure 4 the recall of admissible actions is similar be-\ntween GPT-2 and n-gram whenk≤10. We believe\nit is because top-10 GPT-2 actions are usually sim-\nple actions that occur a lot in ClubFloyd (e.g. ‘east’,\n‘get object’), which is also what n-gram can cap-\nture. It is really the complex actions captured when\nk > 10 that makes GPT-2 much better than n-\ngram. On the other hand, though k = 20,30,40\nachieve similar overall performance, they achieve\ndifferent results for different games. So potentially\nthe CALM overall performance can be further im-\nproved by choosing different kfor different games.\nFinally, CALM (random agent) performs a poor\nscore of 1.8%, and clearly shows the importance of\ncombining CALM with an RL agent to adaptively\nchoose actions.\nIs CALM limiting RL? A natural question to\nask is whether reducing the action space using\nCALM results in missing key actions that may\nhave led to higher scores in the games. To an-\nswer this, we also plot the maximum scores seen\nby our CALM (GPT-2) agent during RL in Fig-\nure 6. Some games (e.g. 905 , ACORNCOURT ) are\nintrinsically hard to achieve any score. However,\non other games with non-zero scores, DRRN is\nunable to stably converge to the maximum score\nseen in RL exploration. If RL can fully exploit and\nlearn from the trajectories experienced under the\nCALM action space for each game, the average\nnormalized score would be 14.7%, higher than any\nmodel in Table 2, both with and without handicaps.\n6 Conclusion\nIn this paper, we proposed the Contextual Action\nLanguage Model (CALM), a language model ap-\nproach to generating action candidates for rein-\nforcement learning agents in text-based games. Our\nkey insight is to use language models to capture lin-\nguistic priors and game sense from humans game-\nplay on a diverse set of games. We demonstrated\nthat CALM can generate high-quality, contextually-\nrelevant actions even for games unseen in its train-\ning set, and when paired with a DRRN agent, out-\nperforms previous approaches on the Jericho bench-\nmark (Hausknecht et al., 2019a) by as much as 69%\nin terms of average normalized score. Remarkably,\non many of these games, our approach is compet-\nitive even with models that use ground truth ad-\nmissible actions, implying that CALM is able to\ngenerate high-quality actions across diverse games\nand contexts.\nFrom the results in Table 2, it is safe to con-\nclude that text-based games are still far from being\nsolved. Even with access to ground truth admissi-\nble actions, sparse rewards and partial observability\npose daunting challenges for current agents. In the\nfuture, we believe that strong linguistic priors will\ncontinue to be a key ingredient for building next-\nlevel learning agents in these games. By releasing\nour dataset and code we hope to provide a solid\nfoundation to accelerate work in this direction.\nAcknowledgement\nGracious thanks to Jacqeline Ashwell for running\nClubFloyd and agreeing to our use of the collected\ntranscripts. We thank Danqi Chen, Jimmy Yang,\nJens Tuyls, and other colleagues from Princeton\nNLP group for proofreading and discussion. We\nalso thank reviewers for constructive feedbacks.\nThis research was partially funded by the Center\nfor Statistics and Machine Learning at Princeton\nUniversity through support from Microsoft.\nReferences\nPrithviraj Ammanabrolu, William Broniec, Alex\nMueller, Jeremy Paul, and Mark O Riedl. 2019. To-\nward automated quest generation in text-adventure\ngames. arXiv preprint arXiv:1909.06283.\nPrithviraj Ammanabrolu and Matthew Hausknecht.\n2020. Graph constrained reinforcement learning\nfor natural language action spaces. arXiv preprint\narXiv:2001.08837.\nPrithviraj Ammanabrolu and Mark Riedl. 2019. Play-\ning text-adventure games with graph-based deep re-\ninforcement learning. In Proceedings of the 2019\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, Volume 1 (Long and Short\nPapers), pages 3557–3565.\nHongshen Chen, Xiaorui Liu, Dawei Yin, and Jiliang\nTang. 2017. A survey on dialogue systems: Re-\ncent advances and new frontiers. Acm Sigkdd Ex-\nplorations Newsletter, 19(2):25–35.\nKyunghyun Cho, Bart van Merri ¨enboer, Dzmitry Bah-\ndanau, and Yoshua Bengio. 2014. On the properties\nof neural machine translation: Encoder–decoder ap-\nproaches. In Proceedings of SSST-8, Eighth Work-\nshop on Syntax, Semantics and Structure in Statisti-\ncal Translation, pages 103–111, Doha, Qatar. Asso-\nciation for Computational Linguistics.\nMarc-Alexandre Cˆot´e, ´Akos K´ad´ar, Xingdi Yuan, Ben\nKybartas, Tavian Barnes, Emery Fine, James Moore,\nMatthew Hausknecht, Layla El Asri, Mahmoud\nAdada, et al. 2018. Textworld: A learning environ-\nment for text-based games. In Workshop on Com-\nputer Games, pages 41–75. Springer.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. arXiv preprint arXiv:1810.04805.\nNancy Fulda, Daniel Ricks, Ben Murdoch, and David\nWingate. 2017. What can you do with a rock? af-\nfordance extraction via word embeddings. CoRR,\nabs/1703.03429.\nMatthew Hausknecht, Prithviraj Ammanabrolu, Marc-\nAlexandre C ˆot´e, and Xingdi Yuan. 2019a. Interac-\ntive ﬁction games: A colossal adventure. CoRR,\nabs/1909.05398.\nMatthew Hausknecht, Ricky Loynd, Greg Yang, Adith\nSwaminathan, and Jason D Williams. 2019b. Nail:\nA general interactive ﬁction agent. arXiv preprint\narXiv:1902.04259.\nJi He, Jianshu Chen, Xiaodong He, Jianfeng Gao, Li-\nhong Li, Li Deng, and Mari Ostendorf. 2015. Deep\nreinforcement learning with a natural language ac-\ntion space. arXiv preprint arXiv:1511.04636.\nVishal Jain, William Fedus, Hugo Larochelle, Doina\nPrecup, and Marc G. Bellemare. 2019. Algorithmic\nimprovements for deep reinforcement learning ap-\nplied to interactive ﬁction. CoRR, abs/1903.03094.\nArmand Joulin, Edouard Grave, Piotr Bojanowski, and\nTomas Mikolov. 2017. Bag of tricks for efﬁcient\ntext classiﬁcation. In Proceedings of the 15th Con-\nference of the European Chapter of the Association\nfor Computational Linguistics: Volume 2, Short Pa-\npers, pages 427–431. Association for Computational\nLinguistics.\nDaniel Jurafsky and James H. Martin. 2009. Speech\nand Language Processing (2nd Edition). Prentice-\nHall, Inc., USA.\nBartosz Kostka, Jaroslaw Kwiecien, Jakub Kowal-\nski, and Pawel Rychlikowski. 2017. Text-based\nadventures of the golovin AI agent. CoRR,\nabs/1705.05637.\nAngeliki Lazaridou, Anna Potapenko, and Olivier\nTieleman. 2020. Multi-agent communication meets\nnatural language: Synergies between functional\nand structural language learning. arXiv preprint\narXiv:2005.07064.\nTomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-\nrado, and Jeff Dean. 2013. Distributed representa-\ntions of words and phrases and their composition-\nality. In C. J. C. Burges, L. Bottou, M. Welling,\nZ. Ghahramani, and K. Q. Weinberger, editors, Ad-\nvances in Neural Information Processing Systems\n26, pages 3111–3119. Curran Associates, Inc.\nKarthik Narasimhan, Tejas D. Kulkarni, and Regina\nBarzilay. 2015. Language understanding for text-\nbased games using deep reinforcement learning. In\nEMNLP, pages 1–11.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nBlog, 1(8):9.\nYiping Song, Rui Yan, Xiang Li, Dongyan Zhao, and\nMing Zhang. 2016. Two are better than one: An en-\nsemble of retrieval-and generation-based dialog sys-\ntems. arXiv preprint arXiv:1610.07149.\nIlya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.\nSequence to sequence learning with neural networks.\nIn Advances in neural information processing sys-\ntems, pages 3104–3112.\nRuo Yu Tao, Marc-Alexandre Cˆot´e, Xingdi Yuan, and\nLayla El Asri. 2018. Towards solving text-based\ngames by producing adaptive action spaces. arXiv\npreprint arXiv:1812.00855.\nJack Urbanek, Angela Fan, Siddharth Karamcheti,\nSaachi Jain, Samuel Humeau, Emily Dinan, Tim\nRockt¨aschel, Douwe Kiela, Arthur Szlam, and Jason\nWeston. 2019. Learning to speak and act in a fantasy\ntext adventure game. CoRR, abs/1903.03094.\nNick Walton. 2019. Ai dungeon 2: Creating inﬁnitely\ngenerated text adventures with deep learning lan-\nguage models.\nJason D. Williams, Kavosh Asadi, and Geoffrey Zweig.\n2017. Hybrid code networks: practical and efﬁcient\nend-to-end dialog control with supervised and rein-\nforcement learning. In Proceedings of the 55th An-\nnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 665–\n677, Vancouver, Canada. Association for Computa-\ntional Linguistics.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, R’emi Louf, Morgan Funtow-\nicz, and Jamie Brew. 2019. Huggingface’s trans-\nformers: State-of-the-art natural language process-\ning. ArXiv, abs/1910.03771.\nTom Zahavy, Matan Haroush, Nadav Merlis, Daniel J\nMankowitz, and Shie Mannor. 2018. Learn what\nnot to learn: Action elimination with deep rein-\nforcement learning. In S. Bengio, H. Wallach,\nH. Larochelle, K. Grauman, N. Cesa-Bianchi, and\nR. Garnett, editors, Advances in Neural Information\nProcessing Systems 31, pages 3562–3573. Curran\nAssociates, Inc.\nTiancheng Zhao and Maxine Eskenazi. 2016. To-\nwards end-to-end learning for dialog state tracking\nand management using deep reinforcement learning.\nIn Proceedings of the 17th Annual Meeting of the\nSpecial Interest Group on Discourse and Dialogue,\npages 1–10, Los Angeles. Association for Computa-\ntional Linguistics.\nA ClubFloyd Dataset\nThe ClubFloyd transcripts we collected are game-\nplay logs generated by a group of people that reg-\nularly meet to play interactive ﬁction games. The\nparticipants are experienced at playing text-based\ngames, however they may not be familiar with the\ngame that’s being played, and do make several mis-\ntakes. We include a snippet of a transcript in Figure\n7. We crawled the ClubFloyd website to acquire\n426 transcripts, spanning over 500 games.\nTo process a transcript, we clean the data and\nextract observations and actions. The data contains\nseveral sources of noise, which we remove: the ﬁrst\nis non-game information such as chat logs between\nthe humans playing the games; second are meta-\nactions that humans use to save and load games\nand navigate menus; and ﬁnally, we remove typos,\nexpand common abbreviations (“n” to “north”, “x”\nto “examine”, etc.), and ﬁlter out any actions that\nweren’t recognized by the game parsers.\nOnce we have our cleaned observations and ac-\ntions, we group observations and actions into the\nFigure 7: Selection from a raw ClubFloyd Transcript\nof the game 9:05\n[OBS] [That object is either not here or not important.] [ACTION] south [OBS]\nYou’ll have to get out of the car ﬁrst. [ACTION]put car in reverse\n[OBS] You’ll have to get out of the car ﬁrst. [ACTION] put car in reverse [OBS]\n[That object is either not here or not important.] [ACTION] drive\n[OBS] [That object is either not here or not important.] [ACTION] drive [OBS]\n(the car) Driving Ah, scenic Las Mesas. Man, this place is an absolute toilet. Soon\nyou’ll be able to afford to get the hell out of here – provided you can avoid making\nany more slip-ups on the job. As you cruise down the road, you notice a freeway\nonramp approaching. Would you like to get on? >> [ACTION] yes\nFigure 8: Cleaned section of Figure 7\nform (oj−1,aj−1,oj),aj. For the very ﬁrst obser-\nvation and action, we pad the beginning of the\nexample with the observation ”You are at the start\nof your journey” and the action ”begin journey”.\nAfter this entire pre-processing, the dataset con-\ntains 223,527 examples.\nB CALM Training\nIn this section, we will provide training details\nof CALM (GPT-2), CALM (n-gram), and their\nvariants.\nB.1 CALM (GPT-2)\nWe ﬁrst discuss the CALM (GPT-2) models, and\nbegin with the portion of the ClubFloyd data that\nthey are trained on. We begin with a 12-layer, 768-\nhidden, 12-head, 117M parameter pretrained Ope-\nnAI GPT-2 model.\nWe note that the number of samples we train\non, even in the CALM (GPT-2) model + Jericho\ngames variant, is less than the total samples in\nthe dataset. This is because we do not train on\nincomplete batches of data, and we omit samples\nthat exceed 256 tokens.\nCALM (GPT-2) To train CALM (GPT-2), we\ntake transcripts from ClubFloyd (excluding Jeri-\ncho games) and order the samples based on the\ntranscript number they came from. This yields a\ndataset of 193,588 samples. We select the ﬁrst 90%\nof the samples as train data, and the last 10% of the\nsamples as validation data.\nCALM (GPT-2) 50%, 20%, (+) Jericho To\ntrain the 50% and 20% variants, we select with-\nout replacement 212 transcripts (94,609 samples),\nand 85 transcripts (38,334 samples) respectively\nfrom the ClubFloyd transcripts (excluding Jericho\ngames). We order the samples based on the tran-\nscript they come from, choose the ﬁrst 90% of the\ndata as our training data and last 10% as validation\ndata.\nFor the CALM (GPT-2) variant including Jericho\ngames, we include every ClubFloyd transcript, we\nrandomly order the transcripts, order the samples\nbased on the order of the transcripts, and then we\nselect the ﬁrst 90% of the data as our training data,\nand the last 10% of the data as validation data. This\nsplit contains 206,286 samples.\nCALM (GPT-2) Random InitializationFor the\nCALM (GPT-2) variant with random initialization,\nwe begin with a GPT-2 model that has not been pre-\ntrained. We only use the transcripts in ClubFloyd\nthat do not correspond to any Jericho game we test\non. We randomly order the transcripts, and order\nthe samples based on the order of the transcripts.\nWe select the ﬁrst 90% of the data as our training\ndata, and the last 10% of the data as validation data.\nParameter Optimization In order to train GPT-\n2, we minimize the cross-entropy between GPT-2’s\ndistribution over actions and the action taken in the\nClubFloyd example. We use Adam to optimize the\nweights of our model with learning rate = 2e-5 and\nAdam epsilon = 1e-8. For the learning rate we use\na linear schedule with warmup. Finally, we clip\ngradients allowing a max gradient norm of 1.\nWe include the loss on the train and validation\nset, as well as the accuracy (deﬁned as the percent-\nage of examples on which the action assigned the\nModel Metric 1 2 3 4 5 9 10\nMain Train Loss 0.32 0.27 0.25 0.23 0.22 n/a n/aTrain Acc0.11 0.14 0.16 0.18 0.19 n/a n/aVal Loss 2.14 2.04 1.98 1.96 1.96 n/a n/aVal Acc 0.13 0.15 0.16 0.17 0.18 n/a n/a\n50% Train Loss 0.66 0.55 0.49 0.46 0.43 n/a n/aTrain Acc0.11 0.14 0.17 0.19 0.21 n/a n/aVal Loss 2.19 2.09 2.06 2.04 2.05 n/a n/aVal Acc 0.14 0.15 0.15 0.16 0.16 n/a n/a\n20% Train Loss 0.37 0.29 0.26 0.25 0.24 n/a n/aTrain Acc0.08 0.11 0.13 0.15 0.16 n/a n/aVal Loss 2.32 2.17 2.12 2.09 2.08 n/a n/aVal Acc 0.10 0.12 0.13 0.14 0.15 n/a n/a\nJericho Train Loss 0.62 0.53 0.48 0.45 0.43 n/a n/aTrain Acc0.12 0.16 0.19 0.21 0.23 n/a n/aVal Loss 2.10 2.00 1.97 1.96 1.98 n/a n/aVal Acc 0.16 0.17 0.17 0.18 0.18 n/a n/a\nRandom Init Train Loss0.36 0.33 0.31 0.29 0.27 0.23 0.23Train Acc0.05 0.07 0.08 0.10 0.11 0.15 0.15Val Loss 4.96 4.60 4.35 4.16 4.01 3.73 3.73Val Acc 0.06 0.08 0.09 0.10 0.10 0.12 0.12\nTable 4: Training Metrics for CALM Variants\nhighest probability by GPT-2 was the ClubFloyd\naction) in Table 4.\nB.2 CALM (n-gram)\nIn order to train the CALM n-gram model, we\nconsider the set of transcripts in ClubFloyd (ex-\ncluding Jericho games). Next, we take the set of\nactions that appear in these transcripts, and train\nan n-gram model with Laplace α smoothing to\nmodel these sequences (Jurafsky and Martin, 2009).\nWe order actions by the transcript they appear in\nand take the ﬁrst 70% of the actions as train data\nand leave the remaining 30% as validation data.\nFor each n, we choose alpha that minimizes per-\nplexity per word on the validation data. We also\ntried a linear interpolation of these estimates (Ju-\nrafsky and Martin, 2009) although we did not ob-\nserve an improvement over our bigram model. In\nthis model, we estimate p(ai|ai−3,ai−2,ai−1) =\nw1p∗(ai|ai−3,ai−2,ai−1)+w2p∗(ai|ai−2,ai−1)+\nw3p∗(ai|ai−1) + w4p∗(ai) where ∑\niwi =\n1, and p∗ indicates our m-gram estimate for\np(ai|ai−m+1,...,a i−1).\nC Walkthrough Evaluation\nIn Figure 10, we provide a piece of walkthrough\ntrajectory of Zork1, with GPT-2 and n-gram gener-\nated actions at each state. Note that n-gram actions\nare mostly limited to be no more than two tokens,\nwhile GPT-2 can generate more complex actions\nlike “put sword in case”.\nIn Figure 9, we provide game-speciﬁc metric\ncurves for Zork1 and Detective. On harder games\nlike Zork1, there is signiﬁcant gap between GPT-2\nand n-gram, while easy games like Detective the\ngap is very small.\nD Gameplay Evaluation\nOn Zork1, we provide learning curves for CALM\n(GPT-2) (Figure 11) and CALM (n-gram) (Fig-\nure 12). We also provide trail curves for CALM\n(GPT-2) on Zork3 (Figure 14), a game we are\nbehind NAIL, and trails using different top- k ∈\n{10,20,30,40}actions by CALM (GPT-2) on\nZork1 (Figure 13).\nWe provide per-game results for model variants\nin Table 5. It is interesting that CALM (w/ Jericho)\nis signiﬁcantly better than CALM (GPT-2) on the\ngames of Temple and Deephome (non-trivial scores\nachieved), which are not the games with ClubFloyd\nscripts added. On the other hand, games like 905\nand moonlit have scripts added, but do not get im-\nproved.\nIn the end, we append one example trajectory\npiece of DRRN + CALM (GPT-2) on Zork1 (Fig-\nure 15), where CALM generated action candidates\nand their Q-values are shown along with observa-\ntions, actions and scores.\nGameCALM (GPT-2)CALM (ngram)CALM (w/o PT) CALM (20%) CALM (50%) CALM (w/ Jericho) CALM (k=10) CALM (k=20) CALM (k=40) CALM (random agent)Max Score9050.00 (±0.00)0.00 (±0.00)0.00 0.00 0.00 0.00 ( ±0.00) 0.00 0.00 0.00 0.00 1acorncourt0.00 (±0.00)0.00 (±0.00)0.00 0.00 0.00 0.00 ( ±0.00) 0.00 0.00 0.00 0.00 30adv’land0.00 (±0.00)0.00 (±0.00)0.00 0.00 0.00 0.00 ( ±0.00) 0.00 0.00 0.00 0.00 100advent36.00 (±0.00)36.00 (±0.00)36.00 36.00 36.00 36.00 ( ±0.00) 36.00 36.00 36.00 36.00 350anchor0.00 (±0.00)0.00 (±0.00)0.00 0.00 0.00 0.00 ( ±0.00) 0.00 0.00 0.00 0.00 100awaken0.00 (±0.00)0.00 (±0.00)0.00 0.00 0.00 0.00 ( ±0.00) 0.00 0.00 0.00 0.00 50balances9.15 (±0.08)8.86 (±0.04)6.00 7.89 9.43 4.05 ( ±0.15) 0.00 9.17 8.07 1.70 51deephome1.00 (±0.00)1.00 (±0.00)1.00 1.00 1.00 6.95 ( ±5.43) 1.00 1.00 1.00 1.05 300detective289.71 (±0.20)284.33 (±11.04)288.21 289.30 289.58 289.87 (±0.11) 289.75 289.51 290.04 40.00 360dragon0.13 (±0.05)0.05 (±0.03)0.00 0.27 0.25 0.19 ( ±0.03) 0.32 0.12 0.18 -0.19 25enchanter19.09 (±0.59)0.00 (±0.00)0.00 0.00 0.00 19.92 ( ±0.06) 0.00 15.33 20.00 0.00 400inhumane25.73 (±2.93)1.72 (±0.93)0.00 20.15 22.38 28.16 ( ±3.32) 8.38 30.03 21.73 0.00 90jewel0.27 (±0.01)0.00 (±0.00)0.00 0.00 0.00 0.38 ( ±0.05) 0.00 0.20 0.46 0.00 90karn2.30 (±0.05)0.00 (±0.00)0.00 3.19 1.73 2.19 ( ±0.08) 0.14 2.63 1.71 0.00 170library9.02 (±5.07)5.07 (±0.28)13.77 12.31 11.84 12.47 ( ±0.35) 3.22 10.40 10.46 1.74 30ludicorp10.09 (±0.60)5.44 (±0.04)11.39 11.40 9.87 10.64 ( ±0.90) 10.93 11.72 9.00 6.72 150moonlit0.00 (±0.00)0.00 (±0.00)0.00 0.00 0.00 0.00 ( ±0.00) 0.00 0.00 0.00 0.00 1omniquest6.88 (±0.10)4.53 (±0.09)4.80 7.08 5.79 6.87 ( ±0.15) 4.98 6.20 6.55 3.10 50pentari0.00 (±0.00)0.00 (±0.00)0.00 0.00 0.00 0.00 ( ±0.00) 0.00 0.00 0.00 0.00 70snacktime19.40 (±0.29)0.00 (±0.00)0.00 0.00 7.84 31.75 ( ±8.62) 0.00 19.25 20.14 0.50 50sorcerer6.18 (±1.80)5.00 (±0.00)5.00 5.03 5.73 5.65( ±1.45) 11.57 5.00 5.00 5.00 400spellbrkr39.99 (±0.01)39.92 (±0.03)39.94 39.97 39.86 40.00 ( ±0.00) 40.00 39.96 40.00 36.20 600spirit1.36 (±0.03)0.64 (±0.07)1.78 1.23 1.32 1.23 ( ±0.05) 1.85 1.51 1.21 0.20 250temple0.00 (±0.00)0.00 (±0.00)0.00 0.00 0.00 3.52 ( ±1.99) 0.00 0.00 0.00 0.00 35zenon0.00 (±0.00)0.00 (±0.00)0.00 0.00 0.00 0.00 ( ±0.00) 0.00 0.00 0.00 0.00 20zork130.39 (±3.01)24.76 (±0.52)11.30 22.75 27.44 32.17 ( ±4.39) 12.70 31.36 29.10 2.40 350zork30.53 (±0.08)0.02 (±0.01)0.89 0.79 0.34 0.46 ( ±0.06) 0.97 0.49 0.26 0.07 7ztuu3.74 (±0.30)0.00 (±0.00)0.00 5.66 4.85 3.93 ( ±0.07) 0.00 3.73 4.38 0.55 100\nTable 5: Raw scores for variants of CALM (GPT-2) on each game. Games in bold are those with ClubFloyd scripts.\nNote that some scores are only based on one trial. CALM (GPT-2), CALM (ngram) and CALM (w/ Jericho) are\nbased on ﬁve trails and the standard deviation is given.\n0 10 20 30\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0zork1\nrecall_gold\n0 10 20 30\nrecall_valid\n0 10 20 30\nprec_valid\nngram\ngpt2\n0 10 20 30\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0detective\nrecall_gold\n0 10 20 30\nrecall_valid\n0 10 20 30\nprec_valid\nFigure 9: Walkthrough evaluation for Zork1 and Detective.\ns t e p 22\ns t a t e : [ CLS ] l i v i n g room above t h e t r o p h y c a s e hangs an e l v i s h sword o f g r e a t a n t i q u i t y . [ SEP ] g e t sword [ SEP ] t a k e n . you\na r e c a r r y i n g : a sword a n a s t y k n i f e a r o p e a b r a s s l a n t e r n a c l o v e o f g a r l i c a j e w e l − e n c r u s t e d egg l i v i n g\nroom you a r e i n t h e l i v i n g room . t h e r e i s a doorway t o t h e e a s t , a wooden door w i t h s t r a n g e g o t h i c l e t t e r i n g t o t h e west\n, which a p p e a r s t o be n a i l e d s h u t , a t r o p h y case , and a l a r g e o r i e n t a l rug i n t h e c e n t e r o f t h e room . [ SEP ]\ng p t 2 a c t s : [ ’ e a s t ’ , ’ west ’ , ’ n o r t h ’ , ’ s o u t h ’ , ’ up ’ , ’ down ’ , ’ drop sword ’ , ’ open t r o p h y case ’ , ’ open door ’ , ’ s o u t h e a s t ’ , ’ wait\n’ , ’ s o u t h w e s t ’ , ’ n o r t h w e s t ’ , ’ wear sword ’ , ’ n o r t h e a s t ’ , ’ out ’ , ’ t a k e sword ’ , ’ knock on door ’ , ’ g e t s t a t u e ’ , ’ open\nt r o p h y ’ , ’ g e t rug ’ , ’ c l o s e door ’ , ’ t a k e rug ’ , ’ g e t a l l ’ , ’ g e t sword ’ , ’ open case ’ , ’ t a k e a l l ’ , ’ p u t sword i n case ’ , ’\ng e t t r o p h y ’ , ’ open g o t h i c ’ ]\nn g r a m a c t s : [ ’ n o r t h ’ , ’ e a s t ’ , ’ s o u t h ’ , ’ west ’ , ’ open door ’ , ’ examine door ’ , ’ t a k e a l l ’ , ’ u n l o c k door ’ , ’ g e t a l l ’ , ’ c l o s e door\n’ , ’ drop a l l ’ , ’ p u t a l l ’ , ’ t i e rope ’ , ’ examine k n i f e ’ , ’ t a k e k n i f e ’ , ’ examine case ’ , ’ examine sword ’ , ’ open case ’ , ’\nexamine rug ’ , ’ examine rope ’ , ’ examine west ’ , ’ t a k e rope ’ , ’ t a k e sword ’ , ’ examine l a n t e r n ’ , ’ p u t k n i f e ’ , ’ p u l l rope ’ , ’\nt a k e l a n t e r n ’ , ’ examine egg ’ , ’ t a k e rug ’ , ’ l o o k u n d e r rug ’ ]\nv a l i d a c t s : [ ’ e a s t ’ , ’ open egg w i t h l a n t e r n ’ , ’ throw r o p e a t egg ’ , ’ throw egg a t k n i f e ’ , ’ throw sword a t egg ’ , ’ throw g a r l i c\na t egg ’ , ’ throw l a n t e r n a t egg ’ , ’ throw k n i f e a t egg ’ , ’ throw k n i f e a t l a n t e r n ’ , ’ push rug ’ , ’ p u t down a l l ’ , ’ p u t down\nrope ’ , ’ p u t down egg ’ , ’ p u t down sword ’ , ’ p u t down g a r l i c ’ , ’ p u t down l a n t e r n ’ , ’ p u t down k n i f e ’ , ’ t a k e on egg ’ , ’ open\ncase ’ , ’ t u r n on l a n t e r n ’ ]\ng o l d a c t : [ ’ push rug ’ ]\ns c o r e : 15\ns t e p 23\ns t a t e : [ CLS ] t a k e n . [ SEP ] move rug [ SEP ] w i t h a g r e a t e f f o r t , t h e rug i s moved t o one s i d e o f t h e room , r e v e a l i n g t h e d u s t y\nc o v e r o f a c l o s e d t r a p door . you a r e c a r r y i n g : a sword a n a s t y k n i f e a r o p e a b r a s s l a n t e r n a c l o v e o f g a r l i c\na j e w e l − e n c r u s t e d egg l i v i n g room you a r e i n t h e l i v i n g room . t h e r e i s a doorway t o t h e e a s t , a wooden door w i t h\ns t r a n g e g o t h i c l e t t e r i n g t o t h e west , which a p p e a r s t o be n a i l e d s h u t , a t r o p h y case , and a c l o s e d t r a p door a t your\nf e e t . [ SEP ]\ng p t 2 a c t s : [ ’ e a s t ’ , ’ west ’ , ’ open door ’ , ’ n o r t h ’ , ’ open t r a p door ’ , ’ s o u t h ’ , ’ open case ’ , ’ down ’ , ’ up ’ , ’ wait ’ , ’ open t r a p ’ ,\n’ p u l l rug ’ , ’ move cover ’ , ’ knock on door ’ , ’ s o u t h e a s t ’ , ’ push rug ’ , ’ s e a r c h cover ’ , ’ open cover ’ , ’ out ’ , ’ c l o s e t r a p ’ ,\n’ s o u t h w e s t ’ , ’ move rug ’ , ’ e n t e r t r a p ’ , ’ open g o t h i c ’ , ’ drop sword ’ , ’ s e a r c h rug ’ , ’ n o r t h w e s t ’ , ’ c l o s e t r a p door ’ , ’ t a k e\nrug ’ , ’ t a k e a l l ’ ]\nn g r a m a c t s : [ ’ n o r t h ’ , ’ e a s t ’ , ’ s o u t h ’ , ’ west ’ , ’ open door ’ , ’ examine door ’ , ’ t a k e a l l ’ , ’ u n l o c k door ’ , ’ g e t a l l ’ , ’ c l o s e door\n’ , ’ drop a l l ’ , ’ p u t a l l ’ , ’ t i e rope ’ , ’ examine k n i f e ’ , ’ t a k e k n i f e ’ , ’ examine case ’ , ’ examine sword ’ , ’ open case ’ , ’\nexamine rug ’ , ’ examine rope ’ , ’ examine west ’ , ’ t a k e rope ’ , ’ t a k e sword ’ , ’ examine l a n t e r n ’ , ’ p u t k n i f e ’ , ’ p u l l rope ’ , ’\nt a k e l a n t e r n ’ , ’ examine egg ’ , ’ t a k e rug ’ , ’ l o o k u n d e r rug ’ ]\nv a l i d a c t s : [ ’ e a s t ’ , ’ open egg w i t h l a n t e r n ’ , ’ throw r o p e a t egg ’ , ’ throw egg a t k n i f e ’ , ’ throw sword a t egg ’ , ’ throw g a r l i c\na t egg ’ , ’ throw l a n t e r n a t egg ’ , ’ throw k n i f e a t egg ’ , ’ throw k n i f e a t l a n t e r n ’ , ’ p u t down a l l ’ , ’ p u t down rope ’ , ’ p u t\ndown egg ’ , ’ p u t down sword ’ , ’ p u t down g a r l i c ’ , ’ p u t down l a n t e r n ’ , ’ p u t down k n i f e ’ , ’ t a k e on egg ’ , ’ open t r a p ’ , ’ open\ncase ’ , ’ t u r n on l a n t e r n ’ ]\ng o l d a c t : [ ’ open t r a p ’ ]\ns c o r e : 15\ns t e p 24\ns t a t e : [ CLS ] w i t h a g r e a t e f f o r t , t h e rug i s moved t o one s i d e o f t h e room , r e v e a l i n g t h e d u s t y c o v e r o f a c l o s e d t r a p door .\n[ SEP ] open t r a p d o o r [ SEP ] t h e door r e l u c t a n t l y opens t o r e v e a l a r i c k e t y s t a i r c a s e d e s c e n d i n g i n t o d a r k n e s s . you a r e\nc a r r y i n g : a sword a n a s t y k n i f e a r o p e a b r a s s l a n t e r n a c l o v e o f g a r l i c a j e w e l − e n c r u s t e d egg l i v i n g room\nyou a r e i n t h e l i v i n g room . t h e r e i s a doorway t o t h e e a s t , a wooden door w i t h s t r a n g e g o t h i c l e t t e r i n g t o t h e west ,\nwhich a p p e a r s t o be n a i l e d s h u t , a t r o p h y case , and a rug l y i n g b e s i d e an open t r a p door . [ SEP ]\ng p t 2 a c t s : [ ’ e a s t ’ , ’ west ’ , ’ down ’ , ’ up ’ , ’ n o r t h ’ , ’ s o u t h ’ , ’ open t r o p h y case ’ , ’ wait ’ , ’ knock on door ’ , ’ t a k e rug ’ , ’\ns o u t h e a s t ’ , ’ e n t e r t r a p d o o r ’ , ’ out ’ , ’ drop sword ’ , ’ t a k e rope ’ , ’ in ’ , ’ s o u t h w e s t ’ , ’ n o r t h w e s t ’ , ’ g e t rope ’ , ’ open case\n’ , ’ g e t rug ’ , ’ s e a r c h rug ’ , ’ e n t e r t r a p ’ , ’ c l i m b rope ’ , ’ n o r t h e a s t ’ , ’ t a k e sword ’ , ’ move rug ’ , ’ t a k e a l l ’ , ’ p u t sword\ni n t r a p d o o r ’ , ’ c l o s e t r a p d o o r ’ ]\nn g r a m a c t s : [ ’ n o r t h ’ , ’ e a s t ’ , ’ s o u t h ’ , ’ west ’ , ’ open door ’ , ’ examine door ’ , ’ t a k e a l l ’ , ’ u n l o c k door ’ , ’ g e t a l l ’ , ’ c l o s e door\n’ , ’ drop a l l ’ , ’ p u t a l l ’ , ’ t i e rope ’ , ’ examine k n i f e ’ , ’ t a k e k n i f e ’ , ’ examine case ’ , ’ examine sword ’ , ’ open case ’ , ’\nexamine rope ’ , ’ examine west ’ , ’ t a k e rope ’ , ’ t a k e sword ’ , ’ examine l a n t e r n ’ , ’ p u t k n i f e ’ , ’ p u l l rope ’ , ’ t a k e l a n t e r n ’ ,\n’ examine egg ’ , ’ p u t sword ’ , ’ g e t sword ’ , ’ p u t egg ’ ]\nv a l i d a c t s : [ ’ e a s t ’ , ’ open egg w i t h l a n t e r n ’ , ’ throw r o p e a t egg ’ , ’ throw egg a t k n i f e ’ , ’ throw sword a t egg ’ , ’ throw g a r l i c\na t egg ’ , ’ throw l a n t e r n a t egg ’ , ’ throw k n i f e a t egg ’ , ’ throw k n i f e a t l a n t e r n ’ , ’ p u t down a l l ’ , ’ p u t down rope ’ , ’ p u t\ndown egg ’ , ’ p u t down sword ’ , ’ p u t down g a r l i c ’ , ’ p u t down l a n t e r n ’ , ’ p u t down k n i f e ’ , ’ c l o s e t r a p ’ , ’ t a k e on egg ’ , ’\nopen case ’ , ’ t u r n on l a n t e r n ’ , ’ down ’ ]\ng o l d a c t : [ ’ down ’ ]\ns c o r e : 15\ns t e p 25\ns t a t e : [ CLS ] t h e door r e l u c t a n t l y opens t o r e v e a l a r i c k e t y s t a i r c a s e d e s c e n d i n g i n t o d a r k n e s s . [ SEP ] down [ SEP ] you have\nmoved i n t o a d a r k p l a c e . t h e t r a p door c r a s h e s s h u t , and you h e a r someone b a r r i n g i t . i t i s p i t c h b l a c k . you a r e l i k e l y\nt o be e a t e n by a g r u e . your sword i s glowing w i t h a f a i n t b l u e glow . you a r e c a r r y i n g : a sword a n a s t y k n i f e a\nr o p e a b r a s s l a n t e r n a c l o v e o f g a r l i c a j e w e l − e n c r u s t e d egg i t i s p i t c h b l a c k . you a r e l i k e l y t o be e a t e n by a\ng r u e . [ SEP ]\ng p t 2 a c t s : [ ’ down ’ , ’ west ’ , ’ e a s t ’ , ’ n o r t h ’ , ’ wait ’ , ’ s o u t h ’ , ’ up ’ , ’ open door ’ , ’ s o u t h e a s t ’ , ’ l i s t e n ’ , ’ s o u t h w e s t ’ , ’ out ’ , ’\nn o r t h e a s t ’ , ’ open t r a p door ’ , ’ n o r t h w e s t ’ , ’ e n t e r t r a p ’ , ’ drop sword ’ , ’ s l e e p ’ , ’ c l o s e door ’ , ’ knock on door ’ , ’ g e t\nrope ’ , ’ open t r a p ’ , ’ t u r n o f f lamp ’ , ’ s i n g ’ , ’ s t a n d ’ , ’ t a k e rope ’ , ’ forward ’ , ’ s h o u t ’ , ’ p u l l rope ’ , ’ sound ’ ]\nn g r a m a c t s : [ ’ n o r t h ’ , ’ e a s t ’ , ’ s o u t h ’ , ’ west ’ , ’ open door ’ , ’ examine door ’ , ’ t a k e a l l ’ , ’ u n l o c k door ’ , ’ g e t a l l ’ , ’ c l o s e door\n’ , ’ drop a l l ’ , ’ p u t a l l ’ , ’ t i e rope ’ , ’ examine k n i f e ’ , ’ t a k e k n i f e ’ , ’ examine case ’ , ’ examine sword ’ , ’ open case ’ , ’\nexamine rope ’ , ’ examine west ’ , ’ t a k e rope ’ , ’ t a k e sword ’ , ’ examine l a n t e r n ’ , ’ p u t k n i f e ’ , ’ p u l l rope ’ , ’ t a k e l a n t e r n ’ ,\n’ examine egg ’ , ’ p u t sword ’ , ’ g e t sword ’ , ’ p u t egg ’ ]\nv a l i d a c t s : [ ’ s o u t h ’ , ’ n o r t h ’ , ’ open egg w i t h l a n t e r n ’ , ’ throw r o p e a t egg ’ , ’ throw egg a t sword ’ , ’ throw g a r l i c a t egg ’ , ’\nthrow l a n t e r n a t egg ’ , ’ throw k n i f e a t egg ’ , ’ throw sword a t egg ’ , ’ throw sword a t l a n t e r n ’ , ’ p u t down a l l ’ , ’ p u t down\nrope ’ , ’ p u t down egg ’ , ’ p u t down g a r l i c ’ , ’ p u t down l a n t e r n ’ , ’ p u t down k n i f e ’ , ’ p u t down sword ’ , ’ t a k e on egg ’ , ’ t u r n\non l a n t e r n ’ , ’ e a s t ’ ]\ng o l d a c t : [ ’ t u r n on l a n t e r n ’ ]\ns c o r e : 40\nFigure 10: A piece of walkthrough evaluation in Zork1.\nFigure 11: CALM (GPT-2) learning Zork1. Results show the ﬁve independent training runs.\nFigure 12: CALM (n-gram) learning Zork1. Results show the ﬁve independent training runs.\nFigure 13: CALM (GPT-2) on Zork1 when decoding variable numbers of top-kactions (k= 10,20,30,40).\nFigure 14: CALM (GPT-2) learning curves on Zork3.\nS t a t e 62235: [ CLS ] North o f House You a r e f a c i n g t h e n o r t h s i d e o f a w h i t e house . There i s no door here , and a l l t h e windows\na r e b o a r d e d up . To t h e n o r t h a narrow p a t h winds t h r o u g h t h e t r e e s . [ SEP ] n o r t h [ SEP ] F o r e s t P a t h T h i s i s a p a t h\nwinding t h r o u g h a dimly l i t f o r e s t . The p a t h h e a d s n o r t h s o u t h h e r e . One p a r t i c u l a r l y l a r g e t r e e w i t h some low b r a n c h e s\ns t a n d s a t t h e edge o f t h e p a t h . You a r e empty handed . F o r e s t P a t h T h i s i s a p a t h winding t h r o u g h a dimly l i t f o r e s t .\nThe p a t h h e a d s n o r t h s o u t h h e r e . One p a r t i c u l a r l y l a r g e t r e e w i t h some low b r a n c h e s s t a n d s a t t h e edge o f t h e p a t h . [ SEP\n]\nA c t i o n s 6 2 2 3 5 : [ ’ c l i m b t r e e ’ , ’ up ’ , ’ s ’ , ’ n ’ , ’ n o r t h ’ , ’ s o u t h ’ , ’ e a s t ’ , ’ west ’ ]\nQvalues62235 : [ 1 5 . 3 8 , 1 5 . 2 9 , 1 2 . 4 , 1 2 . 3 4 , 1 1 . 9 9 , 1 1 . 7 3 , 1 1 . 1 3 , 1 0 . 5 7 ]\n> >Action62235 : up\nReward62235 : 0 , S c o r e 0 , Done F a l s e\nS t a t e 62236: [ CLS ] F o r e s t P a t h T h i s i s a p a t h winding t h r o u g h a dimly l i t f o r e s t . The p a t h h e a d s n o r t h s o u t h h e r e . One\np a r t i c u l a r l y l a r g e t r e e w i t h some low b r a n c h e s s t a n d s a t t h e edge o f t h e p a t h . [ SEP ] up [ SEP ] Up a Tree You a r e a b o u t\n10 f e e t above t h e ground n e s t l e d among some l a r g e b r a n c h e s . The n e a r e s t b r a n c h above you i s above your r e a c h . B e s i d e you\non t h e b r a n c h i s a s m a l l b i r d ’ s n e s t . I n t h e b i r d ’ s n e s t i s a l a r g e egg e n c r u s t e d w i t h p r e c i o u s j e w e l s , a p p a r e n t l y\ns c a v e n g e d by a c h i l d l e s s s o n g b i r d . The egg i s c o v e r e d w i t h f i n e g o l d i n l a y , and ornamented i n l a p i s l a z u l i and mother o f\np e a r l . U n l i k e most eggs , t h i s one i s h i n g e d and c l o s e d w i t h a d e l i c a t e l o o k i n g c l a s p . The egg a p p e a r s e x t r e m e l y f r a g i l e\n. You a r e empty handed . Up a Tree You a r e a b o u t 10 f e e t above t h e ground n e s t l e d among some l a r g e b r a n c h e s . The\nn e a r e s t b r a n c h above you i s above your r e a c h . B e s i d e you on t h e b r a n c h i s a s m a l l b i r d ’ s n e s t . I n t h e b i r d ’ s n e s t i s a\nl a r g e egg e n c r u s t e d w i t h p r e c i o u s j e w e l s , a p p a r e n t l y s c a v e n g e d by a c h i l d l e s s s o n g b i r d . The egg i s c o v e r e d w i t h f i n e\ng o l d i n l a y , and ornamented i n l a p i s l a z u l i and mother o f p e a r l . U n l i k e most eggs , t h i s one i s h i n g e d and c l o s e d w i t h a\nd e l i c a t e l o o k i n g c l a s p . The egg a p p e a r s e x t r e m e l y f r a g i l e . [ SEP ]\nA c t i o n s 6 2 2 3 6 : [ ’ g e t egg ’ , ’ t a k e egg ’ , ’ e a t egg ’ , ’ down ’ , ’ t a k e a l l ’ , ’ g e t n e s t ’ , ’ t a k e n e s t ’ ]\nQvalues62236 : [ 1 7 . 0 3 , 1 7 . 0 2 , 1 6 . 9 9 , 1 3 . 2 2 , 1 1 . 7 5 , 1 1 . 0 5 , 1 0 . 6 8 ]\n> >Action62236 : e a t egg\nReward62236 : 5 , S c o r e 5 , Done F a l s e\nS t a t e 62237: [ CLS ] Up a Tree You a r e a b o u t 10 f e e t above t h e ground n e s t l e d among some l a r g e b r a n c h e s . The n e a r e s t b r a n c h\nabove you i s above your r e a c h . B e s i d e you on t h e b r a n c h i s a s m a l l b i r d ’ s n e s t . I n t h e b i r d ’ s n e s t i s a l a r g e egg\ne n c r u s t e d w i t h p r e c i o u s j e w e l s , a p p a r e n t l y s c a v e n g e d by a c h i l d l e s s s o n g b i r d . The egg i s c o v e r e d w i t h f i n e g o l d i n l a y ,\nand ornamented i n l a p i s l a z u l i and mother o f p e a r l . U n l i k e most eggs , t h i s one i s h i n g e d and c l o s e d w i t h a d e l i c a t e\nl o o k i n g c l a s p . The egg a p p e a r s e x t r e m e l y f r a g i l e . [ SEP ] e a t egg [ SEP ] ( Taken ) I don ’ t t h i n k t h a t t h e j e w e l e n c r u s t e d\negg would a g r e e w i t h you . You a r e c a r r y i n g : A j e w e l e n c r u s t e d egg Up a Tree You a r e a b o u t 10 f e e t above t h e ground\nn e s t l e d among some l a r g e b r a n c h e s . The n e a r e s t b r a n c h above you i s above your r e a c h . B e s i d e you on t h e b r a n c h i s a s m a l l\nb i r d ’ s n e s t . [ SEP ]\nA c t i o n s 6 2 2 3 7 : [ ’ down ’ , ’ jump ’ , ’ p u t egg i n n e s t ’ , ’ drop egg ’ , ’ throw egg a t n e s t ’ , ’ e a t n e s t ’ , ’ g e t n e s t ’ , ’ t a k e n e s t ’ ]\nQvalues62237 : [ 1 2 . 9 3 , 1 2 . 9 3 , 1 1 . 4 9 , 1 1 . 2 2 , 1 1 . 1 , 9 . 4 9 , 9 . 4 1 , 9 . 3 6 ]\n> >Action62237 : down\nReward62237 : 0 , S c o r e 5 , Done F a l s e\nS t a t e 62238: [ CLS ] ( Taken ) I don ’ t t h i n k t h a t t h e j e w e l e n c r u s t e d egg would a g r e e w i t h you . [ SEP ] down [ SEP ] F o r e s t P a t h\nYou a r e c a r r y i n g : A j e w e l e n c r u s t e d egg F o r e s t P a t h T h i s i s a p a t h winding t h r o u g h a dimly l i t f o r e s t . The p a t h h e a d s\nn o r t h s o u t h h e r e . One p a r t i c u l a r l y l a r g e t r e e w i t h some low b r a n c h e s s t a n d s a t t h e edge o f t h e p a t h . [ SEP ]\nA c t i o n s 6 2 2 3 8 : [ ’ s o u t h ’ , ’ c l i m b t r e e ’ , ’ drop egg ’ , ’ drop a l l ’ , ’ up ’ , ’ throw egg a t t r e e ’ , ’ e a s t ’ , ’ n o r t h ’ , ’ west ’ ]\nQvalues62238 : [ 1 4 . 2 6 , 1 1 . 7 8 , 1 1 . 4 6 , 1 1 . 4 1 , 1 1 . 0 3 , 1 1 . 0 3 , 1 0 . 8 5 , 1 0 . 7 2 , 1 0 . 5 ]\n> >Action62238 : s o u t h\nReward62238 : 0 , S c o r e 5 , Done F a l s e\nS t a t e 62239: [ CLS ] F o r e s t P a t h [ SEP ] s o u t h [ SEP ] North o f House You a r e c a r r y i n g : A j e w e l e n c r u s t e d egg North o f House\nYou a r e f a c i n g t h e n o r t h s i d e o f a w h i t e house . There i s no door here , and a l l t h e windows a r e b o a r d e d up . To t h e n o r t h\na narrow p a t h winds t h r o u g h t h e t r e e s . [ SEP ]\nA c t i o n s 6 2 2 3 9 : [ ’ e a s t ’ , ’ s o u t h e a s t ’ , ’ west ’ , ’ n o r t h ’ , ’ s o u t h w e s t ’ , ’ drop a l l ’ , ’ drop egg ’ ]\nQvalues62239 : [ 1 5 . 9 6 , 1 5 . 8 2 , 1 2 . 9 4 , 1 2 . 8 6 , 1 2 . 6 8 , 1 2 . 3 2 , 1 2 . 2 6 ]\n> >Action62239 : s o u t h e a s t\nReward62239 : 0 , S c o r e 5 , Done F a l s e\nS t a t e 62240: [ CLS ] North o f House [ SEP ] s o u t h e a s t [ SEP ] Behind House You a r e b e h i n d t h e w h i t e house . A p a t h l e a d s i n t o t h e\nf o r e s t t o t h e e a s t . I n one c o r n e r o f t h e house t h e r e i s a s m a l l window which i s s l i g h t l y a j a r . You a r e c a r r y i n g : A\nj e w e l e n c r u s t e d egg Behind House You a r e b e h i n d t h e w h i t e house . A p a t h l e a d s i n t o t h e f o r e s t t o t h e e a s t . I n one\nc o r n e r o f t h e house t h e r e i s a s m a l l window which i s s l i g h t l y a j a r . [ SEP ]\nA c t i o n s 6 2 2 4 0 : [ ’ drop egg ’ , ’ drop a l l ’ , ’ n o r t h w e s t ’ , ’ n o r t h ’ , ’ open window ’ , ’ s o u t h ’ , ’ s o u t h w e s t ’ , ’ e a s t ’ ]\nQvalues62240 : [ 1 7 . 9 , 1 7 . 8 9 , 1 4 . 7 1 , 1 4 . 5 , 1 3 . 5 9 , 1 3 . 5 1 , 1 2 . 9 7 , 1 2 . 8 ]\n> >Action62240 : drop a l l\nReward62240 : 0 , S c o r e 5 , Done F a l s e\nS t a t e 62241: [ CLS ] Behind House You a r e b e h i n d t h e w h i t e house . A p a t h l e a d s i n t o t h e f o r e s t t o t h e e a s t . I n one c o r n e r o f\nt h e house t h e r e i s a s m a l l window which i s s l i g h t l y a j a r . [ SEP ] drop a l l [ SEP ] j e w e l e n c r u s t e d egg : Dropped . You a r e\nempty handed . Behind House You a r e b e h i n d t h e w h i t e house . A p a t h l e a d s i n t o t h e f o r e s t t o t h e e a s t . I n one c o r n e r o f\nt h e house t h e r e i s a s m a l l window which i s s l i g h t l y a j a r . There i s a j e w e l e n c r u s t e d egg h e r e . [ SEP ]\nA c t i o n s 6 2 2 4 1 : [ ’ open window ’ , ’ t a k e i t ’ , ’ g e t egg ’ , ’ g e t e n c r u s t e d egg ’ , ’ e a t egg ’ , ’ t a k e egg ’ , ’ g e t i t ’ , ’ t a k e a l l ’ , ’ g e t a l l\n’ , ’ n o r t h ’ , ’ n o r t h w e s t ’ , ’ s o u t h ’ , ’ e a s t ’ , ’ s o u t h w e s t ’ ]\nQvalues62241 : [ 1 9 . 9 1 , 1 6 . 5 2 , 1 6 . 4 4 , 1 6 . 4 , 1 6 . 2 6 , 1 6 . 2 5 , 1 4 . 9 , 1 4 . 2 5 , 1 4 . 0 3 , 1 3 . 8 6 , 1 3 . 1 7 , 1 2 . 4 9 , 1 2 . 4 5 , 1 2 . 1 ]\n> >Action62241 : open window\nReward62241 : 0 , S c o r e 5 , Done F a l s e\nS t a t e 62242: [ CLS ] j e w e l e n c r u s t e d egg : Dropped . [ SEP ] open window [ SEP ] With g r e a t e f f o r t , you open t h e window f a r enough\nt o a l l o w e n t r y . You a r e empty handed . Behind House You a r e b e h i n d t h e w h i t e house . A p a t h l e a d s i n t o t h e f o r e s t t o\nt h e e a s t . I n one c o r n e r o f t h e house t h e r e i s a s m a l l window which i s open . There i s a j e w e l e n c r u s t e d egg h e r e . [ SEP ]\nA c t i o n s 6 2 2 4 2 : [ ’ west ’ , ’ in ’ , ’ e n t e r window ’ , ’ n o r t h ’ , ’ n o r t h w e s t ’ , ’ e a s t ’ , ’ e a t egg ’ , ’ t a k e egg ’ , ’ g e t egg ’ , ’ down ’ , ’ g e t a l l\n’ , ’ s o u t h ’ , ’ s o u t h w e s t ’ , ’ up ’ ]\nQvalues62242 : [ 2 2 . 4 2 , 2 0 . 5 3 , 1 8 . 4 6 , 1 6 . 6 2 , 1 5 . 9 3 , 1 5 . 1 7 , 1 4 . 3 , 1 4 . 1 3 , 1 4 . 1 , 1 3 . 8 2 , 1 3 . 7 4 , 1 3 . 6 8 , 1 3 . 5 6 , 1 1 . 5 9 ]\n> >Action62242 : west\nReward62242 : 10 , S c o r e 15 , Done F a l s e\nS t a t e 62243: [ CLS ] With g r e a t e f f o r t , you open t h e window f a r enough t o a l l o w e n t r y . [ SEP ] west [ SEP ] K i t c h e n You a r e i n\nt h e k i t c h e n o f t h e w h i t e house . A t a b l e seems t o have been used r e c e n t l y f o r t h e p r e p a r a t i o n o f food . A p a s s a g e l e a d s t o\nt h e west and a d a r k s t a i r c a s e can be s e e n l e a d i n g upward . A d a r k chimney l e a d s down and t o t h e e a s t i s a s m a l l window\nwhich i s open . On t h e t a b l e i s an e l o n g a t e d brown sack , s m e l l i n g o f h o t p e p p e r s . A b o t t l e i s s i t t i n g on t h e t a b l e . The\ng l a s s b o t t l e c o n t a i n s : A q u a n t i t y o f w a t e r You a r e empty handed . K i t c h e n You a r e i n t h e k i t c h e n o f t h e w h i t e house .\nA t a b l e seems t o have been used r e c e n t l y f o r t h e p r e p a r a t i o n o f food . A p a s s a g e l e a d s t o t h e west and a d a r k s t a i r c a s e\ncan be s e e n l e a d i n g upward . A d a r k chimney l e a d s down and t o t h e e a s t i s a s m a l l window which i s open . On t h e t a b l e i s\nan e l o n g a t e d brown sack , s m e l l i n g o f h o t p e p p e r s . A b o t t l e i s s i t t i n g on t h e t a b l e . The g l a s s b o t t l e c o n t a i n s : A\nq u a n t i t y o f w a t e r [ SEP ]\nA c t i o n s 6 2 2 4 3 : [ ’ open sack ’ , ’ e a t sack ’ , ’ open b o t t l e ’ , ’ t a k e sack ’ , ’ g e t sack ’ , ’ out ’ , ’ e n t e r window ’ , ’ e a s t ’ , ’ west ’ , ’ g e t\nb o t t l e ’ , ’ t a k e b o t t l e ’ , ’ t a k e a l l ’ , ’ g e t a l l ’ , ’ up ’ ]\nQvalues62243 : [ 1 3 . 7 4 , 1 3 . 6 8 , 1 2 . 3 8 , 1 1 . 5 3 , 1 1 . 4 , 1 1 . 2 5 , 1 1 . 1 3 , 1 1 . 0 6 , 1 0 . 3 6 , 1 0 . 2 3 , 1 0 . 1 5 , 9 . 6 3 , 9 . 6 1 , 6 . 5 4 ]\n> >Action62243 : open s a c k\nReward62243 : 0 , S c o r e 15 , Done F a l s e\nS t a t e 62244: [ CLS ] K i t c h e n You a r e i n t h e k i t c h e n o f t h e w h i t e house . A t a b l e seems t o have been used r e c e n t l y f o r t h e\np r e p a r a t i o n o f food . A p a s s a g e l e a d s t o t h e west and a d a r k s t a i r c a s e can be s e e n l e a d i n g upward . A d a r k chimney l e a d s\ndown and t o t h e e a s t i s a s m a l l window which i s open . On t h e t a b l e i s an e l o n g a t e d brown sack , s m e l l i n g o f h o t p e p p e r s .\nA b o t t l e i s s i t t i n g on t h e t a b l e . The g l a s s b o t t l e c o n t a i n s : A q u a n t i t y o f w a t e r [ SEP ] open s a c k [ SEP ] Opening t h e\nbrown s a c k r e v e a l s a lunch , and a c l o v e o f g a r l i c . You a r e empty handed . K i t c h e n You a r e i n t h e k i t c h e n o f t h e w h i t e\nhouse . A t a b l e seems t o have been used r e c e n t l y f o r t h e p r e p a r a t i o n o f food . A p a s s a g e l e a d s t o t h e west and a d a r k\ns t a i r c a s e can be s e e n l e a d i n g upward . A d a r k chimney l e a d s down and t o t h e e a s t i s a s m a l l window which i s open . A\nb o t t l e i s s i t t i n g on t h e t a b l e . The g l a s s b o t t l e c o n t a i n s : A q u a n t i t y o f w a t e r There i s a brown s a c k h e r e . The brown\ns a c k c o n t a i n s : A l u n c h A c l o v e o f g a r l i c [ SEP ]\nA c t i o n s 6 2 2 4 4 : [ ’ t a k e sack ’ , ’ g e t sack ’ , ’ e a t sack ’ , ’ t a k e bag ’ , ’ t a k e g a r l i c ’ , ’ out ’ , ’ c l o s e sack ’ , ’ g e t g a r l i c ’ , ’ t a k e lunch\n’ , ’ t a k e c l o v e ’ , ’ e a t g a r l i c ’ , ’ e a s t ’ , ’ west ’ , ’ t a k e b o t t l e ’ , ’ g e t a l l ’ , ’ t a k e a l l ’ , ’ up ’ ]\nQvalues62244 : [ 1 5 . 3 2 , 1 5 . 2 5 , 1 5 . 2 3 , 1 4 . 9 5 , 1 2 . 1 6 , 1 2 . 1 2 , 1 1 . 9 , 1 1 . 8 9 , 1 1 . 8 4 , 1 1 . 7 , 1 1 . 6 6 , 1 1 . 6 5 , 1 1 . 1 8 , 1 0 . 9 5 , 1 0 . 4 4 , 1 0 . 3 9 ,\n9 . 4 6 ]\n> >Action62244 : g e t s a c k\nReward62244 : 0 , S c o r e 15 , Done F a l s e\nS t a t e 62245: [ CLS ] Opening t h e brown s a c k r e v e a l s a lunch , and a c l o v e o f g a r l i c . [ SEP ] g e t s a c k [ SEP ] Taken . You a r e\nc a r r y i n g : A brown s a c k The brown s a c k c o n t a i n s : A l u n c h A c l o v e o f g a r l i c K i t c h e n You a r e i n t h e k i t c h e n o f\nt h e w h i t e house . A t a b l e seems t o have been used r e c e n t l y f o r t h e p r e p a r a t i o n o f food . A p a s s a g e l e a d s t o t h e west and\na d a r k s t a i r c a s e can be s e e n l e a d i n g upward . A d a r k chimney l e a d s down and t o t h e e a s t i s a s m a l l window which i s open .\nA b o t t l e i s s i t t i n g on t h e t a b l e . The g l a s s b o t t l e c o n t a i n s : A q u a n t i t y o f w a t e r [ SEP ]\nA c t i o n s 6 2 2 4 5 : [ ’ g e t c l o v e ’ , ’ t a k e c l o v e ’ , ’ g e t g a r l i c ’ , ’ t a k e g a r l i c ’ , ’ west ’ , ’ p u t g a r l i c on t a b l e ’ , ’ drop g a r l i c ’ , ’ open\nb o t t l e ’ , ’ p u t s a c k on t a b l e ’ , ’ g e t food ’ , ’ drop a l l ’ , ’ drop sack ’ , ’ out ’ , ’ e a s t ’ , ’ g e t b o t t l e s ’ , ’ t a k e b o t t l e ’ , ’ g e t\nb o t t l e ’ , ’ t a k e g l a s s ’ , ’ g e t a l l ’ , ’ up ’ ]\nQvalues62245 : [ 1 6 . 2 5 , 1 6 . 1 9 , 1 6 . 0 1 , 1 5 . 9 4 , 1 4 . 5 3 , 1 4 . 1 8 , 1 4 . 0 4 , 1 3 . 8 3 , 1 2 . 3 9 , 1 1 . 7 7 , 1 1 . 6 2 , 1 1 . 5 6 , 1 1 . 0 5 , 1 0 . 8 6 , 1 0 . 2 6 , 1 0 . 2 1 ,\n1 0 . 0 8 , 9 . 4 , 9 . 3 , 7 . 8 4 ]\n> >Action62245 : t a k e c l o v e\nReward62245 : 0 , S c o r e 15 , Done F a l s e\nS t a t e 62246: [ CLS ] Taken . [ SEP ] t a k e c l o v e [ SEP ] Taken . You a r e c a r r y i n g : A c l o v e o f g a r l i c A brown s a c k The brown\ns a c k c o n t a i n s : A l u n c h K i t c h e n You a r e i n t h e k i t c h e n o f t h e w h i t e house . A t a b l e seems t o have been used r e c e n t l y\nf o r t h e p r e p a r a t i o n o f food . A p a s s a g e l e a d s t o t h e west and a d a r k s t a i r c a s e can be s e e n l e a d i n g upward . A d a r k chimney\nl e a d s down and t o t h e e a s t i s a s m a l l window which i s open . A b o t t l e i s s i t t i n g on t h e t a b l e . The g l a s s b o t t l e c o n t a i n s\n: A q u a n t i t y o f w a t e r [ SEP ]\nA c t i o n s 6 2 2 4 6 : [ ’ west ’ , ’ open b o t t l e ’ , ’ drop c l o v e ’ , ’ p u t g a r l i c on t a b l e ’ , ’ drop g a r l i c ’ , ’ p u t c l o v e on t a b l e ’ , ’ p u t c l o v e i n\nsack ’ , ’ p u t g a r l i c i n sack ’ , ’ e a s t ’ , ’ out ’ , ’ t a k e b o t t l e ’ , ’ g e t b o t t l e ’ , ’ g e t a l l ’ , ’ up ’ , ’ g e t g l a s s ’ , ’ t a k e g l a s s ’ ]\nQvalues62246 : [ 1 7 . 5 9 , 1 6 . 0 9 , 1 4 . 8 , 1 4 . 6 9 , 1 4 . 6 6 , 1 4 . 4 7 , 1 3 . 3 7 , 1 3 . 2 6 , 1 2 . 4 5 , 1 2 . 1 2 , 1 1 . 8 2 , 1 1 . 5 1 , 1 0 . 6 7 , 1 0 . 4 8 , 1 0 . 4 8 , 1 0 . 3 8 ]\n> >Action62246 : west\nReward62246 : 0 , S c o r e 15 , Done F a l s e\nS t a t e 62247: [ CLS ] Taken . [ SEP ] west [ SEP ] L i v i n g Room You a r e i n t h e l i v i n g room . There i s a doorway t o t h e e a s t , a\nwooden door w i t h s t r a n g e g o t h i c l e t t e r i n g t o t h e west , which a p p e a r s t o be n a i l e d s h u t , a t r o p h y case , and a l a r g e\no r i e n t a l rug i n t h e c e n t e r o f t h e room . Above t h e t r o p h y c a s e hangs an e l v i s h sword o f g r e a t a n t i q u i t y . A b a t t e r y\npowered b r a s s l a n t e r n i s on t h e t r o p h y c a s e . You a r e c a r r y i n g : A c l o v e o f g a r l i c A brown s a c k The brown s a c k\nc o n t a i n s : A l u n c h L i v i n g Room You a r e i n t h e l i v i n g room . There i s a doorway t o t h e e a s t , a wooden door w i t h\ns t r a n g e g o t h i c l e t t e r i n g t o t h e west , which a p p e a r s t o be n a i l e d s h u t , a t r o p h y case , and a l a r g e o r i e n t a l rug i n t h e\nc e n t e r o f t h e room . Above t h e t r o p h y c a s e hangs an e l v i s h sword o f g r e a t a n t i q u i t y . A b a t t e r y powered b r a s s l a n t e r n i s\non t h e t r o p h y c a s e . [ SEP ]\nA c t i o n s 6 2 2 4 7 : [ ’ l i g h t l a n t e r n ’ , ’ g e t l a n t e r n ’ , ’ t a k e l a n t e r n ’ , ’ t u r n o f f l a n t e r n ’ , ’ open case ’ , ’ open t r o p h y case ’ , ’ t u r n on\nl a n t e r n ’ , ’ e a s t ’ , ’ t a k e a l l ’ , ’ g e t sword ’ , ’ g e t a l l ’ , ’ t a k e sword ’ , ’ drop a l l ’ ]\nQvalues62247 : [ 2 0 . 0 4 , 1 9 . 1 , 1 8 . 9 6 , 1 8 . 9 5 , 1 8 . 3 5 , 1 8 . 3 5 , 1 7 . 7 6 , 1 5 . 0 8 , 1 4 . 4 1 , 1 4 . 2 3 , 1 4 . 1 2 , 1 3 . 9 7 , 1 2 . 2 5 ]\n> >Action62247 : l i g h t l a n t e r n\nReward62247 : 0 , S c o r e 15 , Done F a l s e\nS t a t e 62248: [ CLS ] L i v i n g Room You a r e i n t h e l i v i n g room . There i s a doorway t o t h e e a s t , a wooden door w i t h s t r a n g e g o t h i c\nl e t t e r i n g t o t h e west , which a p p e a r s t o be n a i l e d s h u t , a t r o p h y case , and a l a r g e o r i e n t a l rug i n t h e c e n t e r o f t h e\nroom . Above t h e t r o p h y c a s e hangs an e l v i s h sword o f g r e a t a n t i q u i t y . A b a t t e r y powered b r a s s l a n t e r n i s on t h e t r o p h y\nc a s e . [ SEP ] l i g h t l a n t e r n [ SEP ] ( Taken ) The b r a s s l a n t e r n i s now on . You a r e c a r r y i n g : A b r a s s l a n t e r n ( p r o v i d i n g\nl i g h t ) A c l o v e o f g a r l i c A brown s a c k The brown s a c k c o n t a i n s : A l u n c h L i v i n g Room You a r e i n t h e l i v i n g room\n. There i s a doorway t o t h e e a s t , a wooden door w i t h s t r a n g e g o t h i c l e t t e r i n g t o t h e west , which a p p e a r s t o be n a i l e d\ns h u t , a t r o p h y case , and a l a r g e o r i e n t a l rug i n t h e c e n t e r o f t h e room . Above t h e t r o p h y c a s e hangs an e l v i s h sword o f\ng r e a t a n t i q u i t y . [ SEP ]\nA c t i o n s 6 2 2 4 8 : [ ’ t a k e sword ’ , ’ g e t sword ’ , ’ t u r n o f f l a n t e r n ’ , ’ drop sack ’ , ’ drop a l l ’ , ’ drop l a n t e r n ’ , ’ e a s t ’ ]\nQvalues62248 : [ 2 2 . 6 4 , 2 2 . 4 6 , 1 9 . 8 9 , 1 7 . 2 6 , 1 5 . 6 6 , 1 5 . 5 7 , 1 4 . 9 9 ]\n> >Action62248 : g e t sword\nReward62248 : 0 , S c o r e 15 , Done F a l s e\nS t a t e 62249: [ CLS ] ( Taken ) The b r a s s l a n t e r n i s now on . [ SEP ] g e t sword [ SEP ] Taken . You a r e c a r r y i n g : A sword A\nb r a s s l a n t e r n ( p r o v i d i n g l i g h t ) A c l o v e o f g a r l i c A brown s a c k The brown s a c k c o n t a i n s : A l u n c h L i v i n g Room\nYou a r e i n t h e l i v i n g room . There i s a doorway t o t h e e a s t , a wooden door w i t h s t r a n g e g o t h i c l e t t e r i n g t o t h e west ,\nwhich a p p e a r s t o be n a i l e d s h u t , a t r o p h y case , and a l a r g e o r i e n t a l rug i n t h e c e n t e r o f t h e room . [ SEP ]\nA c t i o n s 6 2 2 4 9 : [ ’ move rug ’ , ’ drop sword ’ , ’ t u r n o f f l a n t e r n ’ , ’ e a s t ’ , ’ p u t l a n t e r n i n case ’ , ’ up ’ ]\nQvalues62249 : [ 2 5 . 3 3 , 1 5 . 0 3 , 1 3 . 9 3 , 1 1 . 9 9 , 1 1 . 1 7 , 1 0 . 4 5 ]\n> >Action62249 : move rug\nReward62249 : 0 , S c o r e 15 , Done F a l s e\nS t a t e 62250: [ CLS ] Taken . [ SEP ] move rug [ SEP ] With a g r e a t e f f o r t , t h e rug i s moved t o one s i d e o f t h e room , r e v e a l i n g\nt h e d u s t y c o v e r o f a c l o s e d t r a p door . You a r e c a r r y i n g : A sword A b r a s s l a n t e r n ( p r o v i d i n g l i g h t ) A c l o v e o f\ng a r l i c A brown s a c k The brown s a c k c o n t a i n s : A l u n c h L i v i n g Room You a r e i n t h e l i v i n g room . There i s a doorway\nt o t h e e a s t , a wooden door w i t h s t r a n g e g o t h i c l e t t e r i n g t o t h e west , which a p p e a r s t o be n a i l e d s h u t , a t r o p h y case ,\nand a c l o s e d t r a p door a t your f e e t . [ SEP ]\nA c t i o n s 6 2 2 5 0 : [ ’ open t r a p door ’ , ’ open t r a p d o o r ’ , ’ open cover ’ , ’ drop l a n t e r n ’ , ’ e a s t ’ ]\nQvalues62250 : [ 2 7 . 9 7 , 2 7 . 9 4 , 2 7 . 9 1 , 2 1 . 0 5 , 2 0 . 4 1 ]\n> >Action62250 : open c o v e r\nReward62250 : 0 , S c o r e 15 , Done F a l s e\nS t a t e 62251: [ CLS ] With a g r e a t e f f o r t , t h e rug i s moved t o one s i d e o f t h e room , r e v e a l i n g t h e d u s t y c o v e r o f a c l o s e d t r a p\ndoor . [ SEP ] open c o v e r [ SEP ] The door r e l u c t a n t l y opens t o r e v e a l a r i c k e t y s t a i r c a s e d e s c e n d i n g i n t o d a r k n e s s . You\na r e c a r r y i n g : A sword A b r a s s l a n t e r n ( p r o v i d i n g l i g h t ) A c l o v e o f g a r l i c A brown s a c k The brown s a c k c o n t a i n s\n: A l u n c h L i v i n g Room You a r e i n t h e l i v i n g room . There i s a doorway t o t h e e a s t , a wooden door w i t h s t r a n g e g o t h i c\nl e t t e r i n g t o t h e west , which a p p e a r s t o be n a i l e d s h u t , a t r o p h y case , and a rug l y i n g b e s i d e an open t r a p door . [ SEP ]\nA c t i o n s 6 2 2 5 1 : [ ’ down ’ , ’ c l o s e t r a p door ’ , ’ e a s t ’ , ’ drop sack ’ , ’ drop l a n t e r n ’ , ’ p u t s a c k i n case ’ ]\nQvalues62251 : [ 3 0 . 8 8 , 2 5 . 4 5 , 2 2 . 2 1 , 2 1 . 9 6 , 2 0 . 7 , 2 0 . 6 2 ]\n> >Action62251 : down\nReward62251 : 25 , S c o r e 40 , Done F a l s e\nFigure 15: Last episode of game trajectory of DRRN + CALM (GPT-2) on Zork 1, from start until 40 is scored.\nExample 1 : ”You s e e t h e m o n s t e r s t u m b l e from i t s cave . You a r e c a r r y i n g a bow and t h r e e a r r o w s ”\nCALM (GPT−2) Top 10 G e n e r a t e d A c t i o n s : [ ’ s o u t h ’ ,\n’ h i t m o n s t e r w i t h bow ’ ,\n’ up ’ ,\n’ s h o o t m o n s t e r w i t h bow ’ ,\n’ down ’ ,\n’ e a s t ’ ,\n’ west ’ ,\n’ n o r t h ’ ,\n’ k i l l monster ’ ,\n’ s h o o t monster ’ ]\nExample 2 : ”Tom l o o k e d c o n c e r n e d . The p a n e l o f l e v e r s and d i a l s c l e a r l y was c o n f u s i n g him ”\nCALM (GPT−2) Top 10 G e n e r a t e d A c t i o n s : [ ’ s o u t h ’ ,\n’ p u l l l e v e r ’ ,\n’ t a l k t o tom ’ ,\n’ open p a n e l ’ ,\n’ e a s t ’ ,\n’ west ’ ,\n’ t u r n d i a l s ’ ,\n’ n o r t h ’ ,\n’ push b u t t o n ’ ,\n’ p u l l l e v e r s ’ ]\nExample 3 : ” Your body f e e l s c o l d a s you p l u n g e i n t o t h e r i v e r ”\nCALM (GPT−2) Top 10 G e n e r a t e d A c t i o n s : [ ’ s o u t h ’ ,\n’ wait ’ ,\n’ up ’ ,\n’ e n t e r r i v e r ’ ,\n’ down ’ ,\n’ e a s t ’ ,\n’ west ’ ,\n’ swim ’ ,\n’ d r i n k water ’ ,\n’ n o r t h ’ ]\nFigure 16: Some handpicked example observations and top 10 action predictions for CALM (GPT-2). The top\nnon-directional actions demonstrate some understanding of the objects present in the observations, and some com-\nmonsense actions involving those objects."
}