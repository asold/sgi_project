{
  "title": "Face It Yourselves: An LLM-Based Two-Stage Strategy to Localize Configuration Errors via Logs",
  "url": "https://openalex.org/W4393924258",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5069822997",
      "name": "Shiwen Shan",
      "affiliations": [
        null,
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A5080873193",
      "name": "Yintong Huo",
      "affiliations": [
        null,
        "Chinese University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A5101500798",
      "name": "Yuxin Su",
      "affiliations": [
        null,
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A5100426730",
      "name": "Yichen Li",
      "affiliations": [
        null,
        "Chinese University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A5100380723",
      "name": "Dan Li",
      "affiliations": [
        null,
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A5000582109",
      "name": "Zibin Zheng",
      "affiliations": [
        null,
        "Sun Yat-sen University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4394946189",
    "https://openalex.org/W2096017373",
    "https://openalex.org/W2767094836",
    "https://openalex.org/W2102632804",
    "https://openalex.org/W2754665629",
    "https://openalex.org/W2883560233",
    "https://openalex.org/W2155072926",
    "https://openalex.org/W2102436656",
    "https://openalex.org/W4205965165",
    "https://openalex.org/W3181779015",
    "https://openalex.org/W3099780882",
    "https://openalex.org/W2962200727",
    "https://openalex.org/W4388502417",
    "https://openalex.org/W1966143594",
    "https://openalex.org/W2151502039",
    "https://openalex.org/W1978365593",
    "https://openalex.org/W2384902034",
    "https://openalex.org/W4364302701",
    "https://openalex.org/W1970017388",
    "https://openalex.org/W2041783719",
    "https://openalex.org/W2261611353",
    "https://openalex.org/W2990630613",
    "https://openalex.org/W2029039689",
    "https://openalex.org/W4389162066",
    "https://openalex.org/W2997961747",
    "https://openalex.org/W4242838928",
    "https://openalex.org/W2096761130",
    "https://openalex.org/W1975413145",
    "https://openalex.org/W2947815220",
    "https://openalex.org/W6849240911",
    "https://openalex.org/W4384347367",
    "https://openalex.org/W4250049051",
    "https://openalex.org/W4319736431",
    "https://openalex.org/W3216780594",
    "https://openalex.org/W4388505012",
    "https://openalex.org/W2912109778",
    "https://openalex.org/W4391558518",
    "https://openalex.org/W4388240174",
    "https://openalex.org/W4244800048",
    "https://openalex.org/W4238623774",
    "https://openalex.org/W4239805804"
  ],
  "abstract": "Configurable software systems are prone to configuration errors, resulting in\\nsignificant losses to companies. However, diagnosing these errors is\\nchallenging due to the vast and complex configuration space. These errors pose\\nsignificant challenges for both experienced maintainers and new end-users,\\nparticularly those without access to the source code of the software systems.\\nGiven that logs are easily accessible to most end-users, we conduct a\\npreliminary study to outline the challenges and opportunities of utilizing logs\\nin localizing configuration errors. Based on the insights gained from the\\npreliminary study, we propose an LLM-based two-stage strategy for end-users to\\nlocalize the root-cause configuration properties based on logs. We further\\nimplement a tool, LogConfigLocalizer, aligned with the design of the\\naforementioned strategy, hoping to assist end-users in coping with\\nconfiguration errors through log analysis.\\n To the best of our knowledge, this is the first work to localize the\\nroot-cause configuration properties for end-users based on Large Language\\nModels~(LLMs) and logs. We evaluate the proposed strategy on Hadoop by\\nLogConfigLocalizer and prove its efficiency with an average accuracy as high as\\n99.91%. Additionally, we also demonstrate the effectiveness and necessity of\\ndifferent phases of the methodology by comparing it with two other variants and\\na baseline tool. Moreover, we validate the proposed methodology through a\\npractical case study to demonstrate its effectiveness and feasibility.\\n",
  "full_text": "Face It Yourselves: An LLM-Based Two-Stage Strategy to Localize\nConfiguration Errors via Logs\nShiwen Shan\nSun Yat-sen University\nZhuhai City, China\nshanshw@mail2.sysu.edu.cn\nYintong Huo\nChinese University of Hong Kong\nHong Kong, China\nythuo@cse.cuhk.edu.hk\nYuxin Suâˆ—\nSun Yat-sen University\nZhuhai City, China\nsuyx35@mail.sysu.edu.cn\nYichen Li\nChinese University of Hong Kong\nHong Kong, China\nycli21@cse.cuhk.edu.hk\nDan Li\nSun Yat-sen University\nZhuhai City, China\nlidan263@mail.sysu.edu.cn\nZibin Zheng\nSun Yat-sen University\nZhuhai City, China\nzhzibin@mail.sysu.edu.cn\nABSTRACT\nConfigurable software systems are prone to configuration errors,\nresulting in significant losses to companies. However, diagnosing\nthese errors is challenging due to the vast and complex configura-\ntion space. These errors pose significant challenges for both experi-\nenced maintainers and new end-users, particularly those without\naccess to the source code of the software systems. Given that logs\nare easily accessible to most end-users, we conduct a preliminary\nstudy to outline the challenges and opportunities of utilizing logs in\nlocalizing configuration errors. Based on the insights gained from\nthe preliminary study, we propose an LLM-based two-stage strategy\nfor end-users to localize the root-cause configuration properties\nbased on logs. We further implement a tool, LogConfigLocalizer,\naligned with the design of the aforementioned strategy, hoping to\nassist end-users in coping with configuration errors through log\nanalysis.\nTo the best of our knowledge, this is the first work to localize\nthe root-cause configuration properties for end-users based on\nLarge Language Models (LLMs) and logs. We evaluate the proposed\nstrategy on Hadoop by LogConfigLocalizer and prove its efficiency\nwith an average accuracy as high as 99.91%. Additionally, we also\ndemonstrate the effectiveness and necessity of different phases of\nthe methodology by comparing it with two other variants and a\nbaseline tool. Moreover, we validate the proposed methodology\nthrough a practical case study to demonstrate its effectiveness and\nfeasibility.\nCCS CONCEPTS\nâ€¢ Software and its engineering ;\nKEYWORDS\nConfiguration Errors, Log Analysis, Large Language Model\nâˆ—corresponding author\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nISSTA â€™24, September 16â€“20, 2024, Vienna, Austria\nÂ© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 979-8-4007-0612-7/24/09\nhttps://doi.org/10.1145/3650212.3652106\nACM Reference Format:\nShiwen Shan, Yintong Huo, Yuxin Su, Yichen Li, Dan Li, and Zibin Zheng.\n2024. Face It Yourselves: An LLM-Based Two-Stage Strategy to Localize\nConfiguration Errors via Logs. In Proceedings of the 33rd ACM SIGSOFT\nInternational Symposium on Software Testing and Analysis (ISSTA â€™24), Sep-\ntember 16â€“20, 2024, Vienna, Austria. ACM, New York, NY, USA, 13 pages.\nhttps://doi.org/10.1145/3650212.3652106\n1 INTRODUCTION\nConfiguration errors, also known as misconfigurations, are com-\nmon and notorious anomalies in configurable software systems. The\nterm refers to the unexpected behavior resulting from mistakenly\nsetting an inappropriate value for a configuration property [49] ,\nwhich poses a significant risk to software reliability. The Open Web\nApplication Security Project (OWASP) [34], a community commit-\nted to trustworthy applications, identified configuration errors as\na major vulnerability, ranking the fifth among the top ten in both\n2021 [30] and 2022 [31] . Configuration errors can significantly dis-\nrupt user experiences; for example, Sweden faced domain paralysis\n(.se) due to DNS configuration errors [ 36], causing widespread\ninconvenience. Moreover, high-profile companies like Facebook,\nMicrosoft Azure, and Amazon EC2 have reported setbacks due to\nsuch errors [46], indicating a widespread occurrence of configura-\ntion errors in the high-tech industries.\nConfiguration errors are common software system anomalies,\nwhich are troublesome and particularly difficult to diagnose, even\nfor experienced maintenance engineers, leading to significant side\neffects for companies, maintainers, and end-users [44, 46, 54]. For\nend-users unfamiliar with configurable software, comprehending\nand addressing these issues could be even more daunting. However,\nexisting strategies, tackling configuration errors via program anal-\nysis, are predominantly designed for software developers rather\nthan end-users who do not have access to source code [1, 45, 54, 55].\nOn the other hand, even in cases with full access to source code,\npinpointing and resolving the root-cause configuration settings\nremains a challenging and time-consuming task for end-users. This\nchallenge is posed by the extensive and intricate configuration\nspace, exacerbated when there are dependencies or conflicts among\nthe configuration properties [44, 49, 58].\nLogs with software runtime information are easily accessible\nfor both software developers and end-users, serving as a valuable\nresource for various software monitoring and failure diagnosis ap-\nplications [3, 10, 11]. However, previous research has primarily\narXiv:2404.00640v2  [cs.SE]  2 Apr 2024\nISSTA â€™24, September 16â€“20, 2024, Vienna, Austria Shiwen Shan, Yintong Huo, Yuxin Su, Yichen Li, Dan Li, and Zibin Zheng\nfocused on utilizing logs for system analysis [24, 56], neglecting the\npotential of logs in pinpointing configuration errors. In this paper,\nwe aim to bridge this gap by exploring how logs can be leveraged\nto automatically pinpoint configuration issues. To achieve this, we\nconduct a preliminary investigation into the relationship between\nthe configuration errors and logs. Through analyzing the 100 en-\ntries of posted configuration setting-related problems of Hadoop [8]\ncollected on Jira [18] and StackOverflow [29], we identify opportu-\nnities to pinpoint the root-cause configuration properties by exam-\nining two types of anomaly symptoms present in the logs.\nIn the preliminary investigation, we identify two types of log\nsymptoms that indicate configuration errors. The direct symptom\ndirectly presents the name or value of the root-cause configuration\nproperty, but matching such properties with logs requires fine-\ngrained matching algorithms. The indirect symptom involves a\nlack of direct information about the root-cause configuration prop-\nerty but pointing to other states of the system due to the invisible\nlogic within the code. While both of the aforementioned symp-\ntoms cannot be directly utilized to localize root-cause configuration\nproperties, they also bring opportunities. For the direct symptom,\nonce the critical information is captured, we can directly localize\nthe root-cause configuration property. For the indirect symptom,\nwe can infer the suspected root-cause configuration property by\ncomprehending and interpreting the related log messages.\nBased on the insights from the preliminary study, we introduce\nan LLM-based two-stage strategy to localize the root-cause con-\nfiguration property via logs. The proposed methodology involves\ntwo stages, the Anomaly Identification Stage and the Anomaly In-\nference Stage . Given a set of logs and user-defined configuration\nsettings, we first identify and select the log messages indicating\nconfiguration-related errors in the Anomaly Identification Stage .\nThen we localize the suspected root-cause configuration properties\nbased on the selected log messages and the offered configuration\nsettings by introducing the rule-based phase and the LLM-based\nphases in theAnomaly Inference Stage. To the best of our knowledge,\nit is the first work to locate configuration errors based on LLMs\nand logs.\nWe demonstrate the performance of the proposed methodology\nby implementing a tool â€“ LogConfigLocalizer. In addition, we es-\ntablish a log benchmark containing various configuration errors\nby dynamically running five types of workloads with different con-\nfiguration settings on Hadoop [8]. We show the high effectiveness\nof LogConfigLocalizer on the established benchmark, achieving an\naverage accuracy of 99.91%. Furthermore, we compare LogConfigLo-\ncalizer with two variants and a baseline tool, and all experiments\ndemonstrate the superior performance of LogConfigLocalizer. We\nfurther conduct a practical case study to localize the root-cause\nconfiguration properties of 33 cases involved in the preliminary\nstudy and demonstrate LogConfigLocalizerâ€™s feasibility with a high\naccuracy of 93.94% (31/33).\nTo conclude, our main contributions are listed as follows:\nâ™¦ We conduct a preliminary study to explore the challenges\nand opportunities associated with localizing configuration errors\nthrough log analysis.\nâ™¦ We introduce a two-stage strategy based on LLMs for end-users\nwho are new to the software systems to localize the configuration\nerrors.\nâ™¦ We implement a tool, LogConfigLocalizer, to assist end-users\nin localizing configuration errors. The source code is publicly avail-\nable1 to benefit future research.\nâ™¦ We demonstrate the effectiveness of LogConfigLocalizer with\nan average accuracy as high as 99.91% in evaluations and show its\nfeasibility through a practical case study.\n2 BACKGROUND\n2.1 Problem Definition\nIn this paper, we formulate the log-based configuration error local-\nization task as follows. Given a set of logs ğ¿with ğ‘›log messages\nğ¿= {ğ‘™1,ğ‘™2,...,ğ‘™ ğ‘› }, and user-defined configuration settings ğ¶ğ‘¢ with\nğ‘šentries ğ¶ğ‘¢ = {ğ‘’1,ğ‘’2,...,ğ‘’ ğ‘š }, where an entryğ‘’ğ‘– = (ğ‘ğ‘–,ğ‘£ğ‘– )indicates\na specific configuration property ğ‘ğ‘– and value ğ‘£ğ‘– , the output is for-\nmatted as a key-value set ğ‘† with ğ‘¡ entries containing the suspected\nconfiguration error triggers ğ‘’ğ‘  ğ‘— = (ğ‘ğ‘  ğ‘—,ğ‘£ğ‘  ğ‘—), ğ‘† = {ğ‘’ğ‘ 1,ğ‘’ğ‘ 2,...,ğ‘’ ğ‘ ğ‘¡ }.\nMoreover, we clarify the frequently used terms in the paper.\nâ€¢May-Fault Logs : Logs offered by end-users that may contain\nconfiguration errors.\nâ€¢Fault-Free Logs : Logs generated with conventional configuration\nsettings, namely the minimum configuration settings for an ap-\nplication to run. Fault-Free is short for Configuration-Fault-Free.\nâ€¢Configuration Error Triggers : The most likely configuration set-\ntings to trigger a configuration error.\nNotably, the core idea of our methodology is similar to the signature-\nbased approaches, which attempt to localize the configuration er-\nrors by comparison between the offered signature and the reference\nsignature [47]. A signature refers to the runtime information of\nsystems, such as system call traces [51]. The offered signature is\ngenerally considered to record the target failure information and\nthe reference signature can record either normal or known failure\ninformation [47]. In this case, the input log files containing config-\nuration errors (i.e., may-fault logs) can be regarded as the offered\nsignature and fault-free logs can be seen as the reference signature.\n2.2 Preliminary Study\nWe conduct a preliminary study to consider the possibilities of\nusing logs to localize configuration errors by investigating the\nrelationship between configuration errors and logs.\nTo begin with, we select the distributed big data framework,\nHadoop [8], as our study system, collecting 100 configuration error\nreports submitted to Jira [18] or StackOverflow [29], which contain\nnumerous technical discussions on software system runtime errors.\nFor selection, we initially search for reports using keywords (e.g.,\n\"configuration\", \"error\", \"failure\" and the names of configuration\nproperties). We then select the top 100 cases returned by the web-\nsites, upon confirming they are related to configuration errors. Such\na decision is made by reviewing their comments and descriptions.\nIf the error is resolved by adjusting the configuration settings, we\nconsider this report highly relevant.\nThe reports record detailed failure information, including con-\nfiguration error triggers, the inappropriately-set values, the data\ntype of the values, and logs. Table 1 shows the statistics of these\nreports.\n1https://github.com/shanshw/LogConfigLocalizer/\nFace It Yourselves: An LLM-Based Two-Stage Strategy to Localize Configuration Errors via Logs ISSTA â€™24, September 16â€“20, 2024, Vienna, Austria\nTable 1: Statistics of the Preliminary Study. #w/ Log shows the number of problems posted with logs, #S-* indicates the two\nsymptoms in reported logs, and #T-* denotes the configuration error type. Some posted problems cover all the configuration\nproperties, thus not included in the configuration error type measurement.\n#w/ Log #S-Direct #S-Indirect #T-Path #T-Numeric #T-Classpath #T-Boolean #T-String # Total\nJira 41 13 28 10 30 4 9 13 68\nStackOverflow 23 0 23 9 4 6 2 5 32\nPercentage / / / 20.65% 36.96% 10.87% 11.96% 19.57% 100%\nA. How many configuration error reports contain logs?We\nmanually count the number of reports containing logs to examine\nwhether they play an important role in configuration error diag-\nnostics. According to Table 1, more than half (64%) of end-users\nshare application logs to detail configuration errors. Additionally,\nsome (5/100) developers in StackOverflow [29] further request logs\nfrom users to pinpoint anomalies if the initial logs are insufficient.\nNotably, some end-users describe the systemâ€™s unexpected behavior\nin natural language, leading to reports lacking logs.\nFinding 1\nThe majority (64%) of end-users attach logs in their anom-\naly reports, revealing the value of logs for diagnosing con-\nfiguration errors.\nB. How do logs reflect configuration errors?We conduct a\ndetailed analysis of anomaly symptoms inside end-user logs and\nclassify them into two categories: direct and indirect. The direct\nsymptom specifies the name or value of the root-cause configura-\ntion property. In contrast, indirect symptoms lack explicit informa-\ntion about the root-cause configuration property, but instead reveal\nadditional system run-time behaviors, such as the stack statements.\nAmong 64 reports with logs examined, 20% (13/64) logs exhibit\nthe direct symptoms and the others show the indirect symptoms.\nHowever, we believe that the direct symptoms shall occur more\noften in practice, given that it is convenient for end-users to inspect\nlog records and use the identified information (e.g., the name or\nthe value of the root cause configuration property) to rectify their\nerrors directly.\nFinding 2\nLogs reveal anomaly symptoms in two ways: direct and\nindirect. The direct symptom indicates the root-cause con-\nfiguration properties while the indirect one lacks explicit\ninformation. They occupy 20% and 80% of cases in our\nstudy, respectively.\nFigure 1 shows examples of the two symptoms. Specifically, the\nupper two boxes are examples of the direct symptoms, and the\nlower two indicate the indirect symptoms.\nThe direct symptoms present the explicit information of the con-\nfiguration error triggers. The content enclosed in the orange box2\nrepresents the direct symptom showing the full name of the configu-\nration error trigger highlighted in red log (i.e.,mapred.local.dir).\n2Original report: https://issues.apache.org/jira/browse/HADOOP-134.\n4\n060413 160702 Lost connection to JobTracker [kry1040/72.30.116.100:50020]. Retrying...\njava.io.IOException: No valid local directories in property: mapred.local.dir\nat org.apache.hadoop.conf.Configuration.getFile(Configuration.java:282)\nat org.apache.hadoop.mapred.JobConf.getLocalFile(JobConf.java:127)\nat org.apache.hadoop.mapred.TaskTracker$TaskInProgress.localizeTask(TaskTracker.java:391)\nat org.apache.hadoop.mapred.TaskTracker$TaskInProgress.<init>(TaskTracker.java:383)\nat org.apache.hadoop.mapred.TaskTracker.offerService(TaskTracker.java:270)\nat org.apache.hadoop.mapred.TaskTracker.run(TaskTracker.java:336)\nat org.apache.hadoop.mapred.TaskTracker.main(TaskTracker.java:756)\n13/10/28 18:49:52 ERROR security.UserGroupInformation: PriviledgedActionException as:root\ncause:org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: \nfile:/F:/Workspaces/Test/Hadoop/test\njava.lang.RuntimeException: java.io.IOException: ViewFs: Cannot initialize: Invalid entry in Mount \ntable in config: name.key\nat org.apache.hadoop.fs.FileContext.getFileContext(FileContext.java:470)\nat org.apache.hadoop.fs.viewfs.ViewFsTestSetup.setupForViewFsLocalFs(ViewFsTestSetup.java:88)\nâ€¦\njava.lang.NullPointerException\nat org.apache.hadoop.security.LdapGroupsMapping.goUpGroupHierarchy(LdapGroupsMapping.java:612)\nat org.apache.hadoop.security.LdapGroupsMapping.lookupGroup(LdapGroupsMapping.java:489)\nat org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:552)\nat org.apache.hadoop.security.LdapGroupsMapping.getGroups(LdapGroupsMapping.java:365)\nFigure 1: Two Types of Anomaly Symptoms in Logs\nIn this case, end-users can localize the configuration error triggers\nby directly matching the presented name or value. However, some\nconfiguration error triggers in direct symptoms lack their fully\nqualified names, leading to a matching challenge. This deficiency in\ninformation potentially stems from the complexity of long property\nnames. The pink box3 exemplifies this challenge. Instead of display-\ning the full name of the propertyfs.viewfs.mounttable.default.\nname.key, only partial fragments like name.key are presented in\nthe red log. One potential approach to tackling this challenge in-\nvolves devising fuzzy matching strategies. By breaking down the\nfull name into sub-names (name, key) and utilizing these compo-\nnents to match corresponding keywords in the logs, there remains\na possibility of identifying the configuration error trigger.\nFinding 3\nThe direct symptoms pose an insufficient information chal-\nlenge, which requires a fine-grained matching algorithm\nto address it.\nIndirect symptoms provide no specific details about configura-\ntion error triggers but offer alternative insights into the runtime\nbehavior of software systems. The orange text within the green\nbox4 indicates job submission failures without explicit configura-\ntion error triggers. However, the blue-highlighted text indicates the\nanomalyâ€™s manifestation â€“ a nonexistent path. This observation\nsuggests a potential connection between the configuration error\n3Original report: https://issues.apache.org/jira/browse/HADOOP-18802.\n4Original report: https://stackoverflow.com/questions/19636220/exception-while-\nsubmitting-a-mapreduce-job-from-remote-system.\nISSTA â€™24, September 16â€“20, 2024, Vienna, Austria Shiwen Shan, Yintong Huo, Yuxin Su, Yichen Li, Dan Li, and Zibin Zheng\ntriggers and directories/path settings. Notably, the presented path\nis not part of the user-defined configurations and the absence of a\nvalue for mapred.local.dir introduces this anomaly.\nThe case within the blue box 5 displays the value of stack state-\nments in logs. Following the NullPointerException, these stack\nstatements provide clues about the root-cause configuration prop-\nerty6. By tracing a sequence within LdapGroups Mapping, these\nstatements suggest that the security settings related to LdapGroups\nMapping might be the root cause.\nThe indirect symptoms manifest the anomaly without explicitly\nidentifying the culprits. It presents a challenge for end-users to in-\ntuitively correlate these anomalies with their configuration settings\nvia logs. Such a challenge arises due to the discrepancy between\nthe natural language used in logs and the structured configuration\nsettings. However, we can still infer configuration error triggers\nby comprehending and interpreting the alternative information\nin the indirect symptoms. Besides, the stack statements recording\nmethod invocation sequences, offer an alternative view to identify\nconfiguration error triggers.\nFinding 4\nThe discrepancy between the natural language used in logs\nand structured configuration settings presents challenges\nwith indirect symptoms, requiring deeper comprehension\nof alternative information.\nC. Whatâ€™s the most error-prone data types?New users of soft-\nware systems often make configuration mistakes due to complicated\nconfiguration properties with unclear or absent descriptions [44, 49].\nTo better understand what configuration properties confuse end-\nusers the most, we further explore the types of incorrectly con-\nfigured values. The statistical results, presented in Table 1 with\ncolumns prefixed by \"#T-\", review five distinct types of values in\nthe examined cases: \"Path\", \"Numeric\", \"Classpath\", \"Booleanâ€ and\nâ€œStringâ€. \"Path\" includes paths to existing directories and IP ad-\ndresses with specified ports; \"Numeric\" represents numerical values;\n\"Boolean\" indicates true or false states; \"String\" denotes the system-\nrecognizable names of components; and \"Classpath\" signifies the\nfully qualified name of a Java class.\nFinding 5\nConcerning the misconfigured data types, numeric values\nnotably trigger common configuration errors by making\nup 37%, while path and string types each represent 20%.\nBoolean accounts for 12%, and Classpath comprises 11%.\n3 CONFIGURATION BUG LOCALIZATION\n3.1 Overview\nInspired by the value of logs from the preliminary study, we in-\ntroduce an LLM-based two-stage strategy. Figure 2 illustrates the\nframework of the two-stage strategy for configuration-related error\nlocalization through log analysis.\n5Original report: https://issues.apache.org/jira/browse/HADOOP-18821.\n6hadoop.security.group.mapping.ldap.search.group.hierarchy.levels\nThe first stage is theAnomaly Identification Stage . The stage aims\nto identify the log messages related to configuration errors. To begin\nwith, we parse end-usersâ€™ logs into log templates. These templates\nbecome the basis to identify the specific templates in may-fault logs,\nby comparing them with fault-free logs stored in our database. We\nthen compute the anomaly degree for each specific log in may-fault\nlogs. The logs, whose templates receive an anomaly degree greater\nthan zero, will be identified as â€œkey log messagesâ€ and progress to\nthe next stage. Otherwise, these may-fault logs are identified as\nconfiguration-fault-free, concluding the localization process.\nFor the Anomaly Inference stage , the key log messages will pro-\nceed to the Direct Inference Phase initially, attempting to directly\nlocalize the configuration error triggers based on rules. If success-\nful, the inferred configuration error triggers will be passed to the\nLLM-powered Verification Phase for verification. However, failures\nin either the Direct Inference Phase or the Verification phase will\nredirect the flow of the second stage towards theLLM-based Indirect\nInference Phase . A diagnosis report will be generated for end-users\nat the end of the localization procedure. The following sections\nprovide illustrations for each stage.\n3.2 Anomaly Identification Stage\nThe extensive logs hold information revealing configuration errors,\nbut they also include additional runtime information, involving\nthe software resource utilization and the states of running jobs.\nTherefore, we devise a rule-based strategy with four phases in\nthe stage to identify anomalous may-fault logs and distinguish\nconfiguration error-related logs from other operation logs.\n3.2.1 Log Parsing. Run-time logs are semi-structured data, con-\nsisting of constant strings and run-time variables. Parsing these\nlogs involves extracting constant strings, known as log templates,\nand replacing run-time variables with placeholder symbols [ 5, 6,\n15, 25, 57]. Leveraging log templates as representative patterns can\nalleviate the subsequent analysis workload and reduce associated\ncosts [5, 10, 11, 14].\nIn the early phase, we adopt log parsing to turn the may-fault logs\ninto log templates. However, run-time variables provide valuable\nresources, allowing us to explore software system status further [16,\n21]. Therefore, we preserve the filtered run-time variables for the\nfollowing recovery phase. To illustrate, in Figure 2, the gray dashed\narrow from the Log Parsing Phase to the Log Template Recovery\nPhase represents the flow of the stored run-time variables.\n3.2.2 Specific Templates Extraction. Assuming that fault-free logs\ndo not contain configuration errors, we leverage the distinct hash\ncodes of fault-free log templates and extract them from may-fault\nlog templates. Any template whose hash code does not match those\nin our database is considered specific, ensuring both speed and\nprecision in identifying unique log templates.\n3.2.3 Anomaly Degree Calculation. Merely identifying logs with\nspecific templates as anomalies can be overly simplistic and may\nlead to numerous false positives. To mitigate the problem, we incor-\nporate a heuristic anomaly degree calculation algorithm to further\ndiscern the anomalous log templates. Algorithm 1 demonstrates the\nanomaly degree calculation procedure. To calculate the anomaly\ndegree on a given log template, we have a weighted token set ğ‘†,\nFace It Yourselves: An LLM-Based Two-Stage Strategy to Localize Configuration Errors via Logs ISSTA â€™24, September 16â€“20, 2024, Vienna, Austria\nLog Files\n Diagnosis\nReport\nLog \nParsing\nAnomaly Identification Stage\nAnomaly \nDegree \nCalculation\nKey Log \nMessages \nAnomaly Infernce Stage\nDirect \nInference\nVerification\nLarge \nLanguage\nModel\nIndirect\nInference\nDatabase\nConfiguration \nSettings\nLog\nTemplate\nRecovery\nSpecific \nTemplates\nExtraction\nConfiguration \nSettings\nFigure 2: Overview of the LLM-based Two-Stage Strategy\ncontaining key tokens ğ‘¡ revealing anomalous and erroneous infor-\nmation. Each token weights differently during the calculation. Both\nthe selection of tokens and their assigned weights are customiz-\nable, accommodating the diverse characteristics of various software\nsystems.\nAlgorithm 1: Anomaly Degree Calculation Algorithm\nData: Log Template ğ¿, Weighted Token Setğ‘†\nResult: Anomaly Degree ğ· of ğ¿\n1 Initialize ğ· to zero;\n2 for each token ğ‘¡ in ğ‘† do\n3 if ğ‘¡ exists in ğ¿then\n4 ğ· += weight of ğ‘¡;\n5 end\n6 end\n7 return ğ·;\nIn this phase, we designate may-fault logs as anomalous based\non the anomaly degree of each log template. A higher anomaly\ndegree (greater than zero) associated with a log template implies\nthe presence of at least one log message offering additional anomaly\ndetails. Therefore, if any specific log template exhibits an anomaly\ndegree beyond zero, the corresponding may-fault logs are identified\nas anomalous. As this phase concludes, for may-fault logs identi-\nfied as configuration-error-free, the localization procedure ends\nwith a diagnosis report indicating no configuration error occurs.\nConversely, logs marked as anomalous progress to the subsequent\nphase for further examination.\n3.2.4 Log Template Recovery. A specific log template may corre-\nspond to numerous log messages, which could potentially increase\nthe complexity of the subsequent stage. Therefore, we recover the\nfiltered log templates to the log messages with the highest anomaly\ndegree, referred to as \"key log messages\".\nAs previously emphasized, run-time variables are significant.\nHence, to calculate the highest anomaly degree of a log message,\nwe take the anomaly degree of the run-time variables into account.\nTo be detailed, for a given filtered log template, we retain the corre-\nsponding log message whose run-time variables score the highest\nanomaly degree. These recovered log messages (i.e., key log mes-\nsages) will be passed to the Anomaly Inference Stage for configura-\ntion error localization.\n3.3 Anomaly Inference Stage\nWe propose a tri-phase strategy to localize the configuration error\ntriggers with the set of key log messages generated in the Anomaly\nIdentification Stage .\n3.3.1 Direct Inference. From Finding 2 and Finding 3, we recognize\nan opportunity for a direct search within logs for property names\nor values. This leads us to propose the Direct Inference Phase .\nGiven a set of key log messages, theDirect Inference Phase is pro-\nposed to pinpoint configuration error triggers by directly matching\nproperty names or values. Intuitively, we leverage two methods:\none focusing on property names and the other on property values.\nWhen dealing with property name matching, a challenge lies in\ndirectly matching the entire name. To address this, we segment\nproperty names into distinct items based on the period (i.e., .), uti-\nlizing these segments for an exact match algorithm across logs.\nMoreover, we exclude certain commonly used terms specifying\ncomponents, such as \"hadoop\" for Hadoop [8], to reduce false pos-\nitives. To achieve this, we extract configuration properties from\nthe official-provided user manuals and documentation and break\nthem into individual items. Subsequently, we count the occurrences\nof each item and form the filter set consisting of the top 20 items.\nRegarding property value matching, we directly search the value\nin the logs, following practices in previous works [24, 56].\nThe Direct Inference Phase is sound when logs exhibit indica-\ntors, namely the information regarding the full or partial property\nname and the corresponding value. However, false positives may\nstill occur despite the exclusion of hot terms. For instance, in the\nvalue matching strategy, a numeric value within a log message\ncan represent various entities such as an IP address, a port, retry\nattempts, and so forth. The matched values do not always stand\nfor the property value. To alleviate it, the following LLM-powered\nVerification Phase is introduced.\n3.3.2 LLM-powered Verification. We present theLLM-powered Veri-\nfication Phase to address false positives introduced during theDirect\nInference Phase and ensure a second chance in case of a slip-up in\nthe Direct Inference Phase . It guarantees the overall accuracy of the\nAnomaly Inference Stage .\nLogs, presented in natural language, are crafted for human read-\nability. However, comprehending logs can be challenging for end-\nusers and even experts in some cases. Therefore, we utilize Large\nLanguage Models (LLMs) for verification, aiming to harness the\nISSTA â€™24, September 16â€“20, 2024, Vienna, Austria Shiwen Shan, Yintong Huo, Yuxin Su, Yichen Li, Dan Li, and Zibin Zheng\nrobust comprehension capabilities inherent in LLMs. We formu-\nlate a binary classification task for LLMs. Specifically, we furnish\nit with paired entries from the Direct Inference Phase , such as the\nmatched log message along with the corresponding matched con-\nfiguration property and its value. In addition, for each matched\nproperty, we simultaneously provide its descriptions to LLMs for\nbetter performance. The description of each property is accessible\nin the documentation and the user manual. Next, we outline the\nbinary classification task for the LLM, instructing it to generate\noutput in a predefined format. If there is at least one configuration\nerror trigger deemed plausible, we consider the results from Direct\nInference Phase to pass the Verification Phase, concluding the work-\nflow by generating a diagnostic report for end-users. Otherwise,\nit proceeds to the LLM-based Indirect Inference Phase for a second\nattempt.\n3.3.3 LLM-based Indirect Inference. The capability of the Direct\nInference Phase is limited to the direct symptoms, while it requires\nexpertise and log-understanding ability to utilize the indirect symp-\ntoms as Finding 4 shows. Recently, LLMs have shown their strong\npower in natural language understanding and processing, hence we\nintroduce the LLM-based Indirect Inference Phase to grasp a second\nopportunity to localize the configuration error triggers.\nSpecifically, the localization procedure enters the Indirect In-\nference Phase in two cases. The first case occurs when the Direct\nInference Phase fails, resulting in no matched entry being generated,\nprompting the workflow to skip the Verification Phase and proceed\ndirectly to the Indirect Inference Phase . It is referred to as a direct\nflow. The second case arises from a failure in the Verification Phase,\nindicating the localization procedure will go through all the phases\nin this stage, hence termed a complete flow . In the direct flow , no\nprior judgment is made, while in the complete flow, failure in the\nVerification Phase suggests a lack of trustworthiness in the Direct\nInference Phase . Therefore, it is reasonable to leave out information\nfrom the previous phases and utilize the logs, configuration set-\ntings, and descriptions instead. We delegate the task of identifying\nconfiguration error triggers to LLMs. We provide them with details\non key log messages, complete configuration settings, and related\ndescriptions. To ensure effectiveness, We limit the number of the\nsuspected configuration error triggers inferred by the LLMs. In ad-\ndition, we request LLMs to provide explanations for each selected\nsuspected configuration error trigger. We design the strategy to in-\ncrease the reliability of LLMsâ€™ judgments and to provide end-users\nwith additional information about the configuration errors.\n4 IMPLEMENTATION\nWe implement LogConfigLocalizer based on the design of the pro-\nposed methodology. The following sections show the details.\n4.1 Log Parsing\nWe use Drain [9], a prominent log parsing algorithm, which uses a\nfixed depth parse tree to expedite the parsing process for log parsing.\nIt typically skips unrelated log file lines, including stack statements,\nwhich are crucial in theAnomaly Inference Stage. Thus, we introduce\nan enhanced version of Drain [9] that includes stack statements. In\nthe Direct Inference Phase , we exclude stack statements to minimize\nfalse positives, reserving them for use in theIndirect Inference Phase\nto provide more detailed information to LLMs.\nVerification Phase\nYou are an expert in the filed of logs and software systems. \nYou receive information in the following format: \n<log content> \nroot-cause configuration option: \n<name:<> value:<> desc:<> >\nPlease output a probability value of the given configuration property on \nhow likely it can trigger the offered log message. \nThe standard are as follows:\n1. The semanatic correlationship between them are strong and direct,\noutput more than 90. \n2. For others, output 30. \nPlease output a single value in the following format: \nProbability is x.\nFigure 3: System Prompt in the Verification Phase\nYou are an expert in the filed of logs and software systems. \nWhen offered log and the configuration settings, please point out the \nanomaly of the logs and localize the most likely root-cause configuration \nproperties. \nThe offered information presents as follows: \nConfiguration: name:<> value:<> des:<> Log:<> \nThe value and des could be \"<missing>\", meaning that no value is set for \nthe property.\nPlease output the information in the following format: \nname:<> value:<> relevant log:<index>-<> explanation:<> \nfor each suspected configuration property. \nThe <index> indicates the line number. \nSplitting the logs within the same index is not allowed. The given logs \nmay contain stack statements, please take them as reference. \nPlease obey the rules: \n1. If some of the offered configuration properties seem to be irrelevant, \nplease don't output them. \n2. Donâ€™t output the same configuration property more than twice. At \nmost 3 suspected properties while at least one required.\n3. Please obey the aforementioned output format, no other words \nshould be output. \nIndirect Inference Phase\n \n \n \n \n \n \n \n \n \nFigure 4: System Prompt in the Indirect Inference Phase\n4.2 Anomaly Degree Calculation\nItâ€™s intuitive to consider diagnostic information when selecting\ntokens. Therefore, we establish the setğ‘†with tokens:error, exception,\ninvalid, failure, disable, false, fault, warn, because and exit. By default,\neach token is assigned an equal weight of 0.1, adhering to an equal\nallocation strategy. This approach ensures the process remains\ndomain-agnostic, requiring no specific domain knowledge for its\nimplementation.\n4.3 LLM Selection\nFollowing prior research [17, 22, 26], we choose GPT-4 Model [7]\n(specifically, the fixed version, gpt-4-0613, to reproduce our results)\nas the default Large Language Model (LLM). GPT-4 Model [ 7] is\nselected as the model for both theVerification Phase and the Indirect\nInference Phase , following the precedent set by these previous stud-\nies. To ensure the model consistently generates identical output\nfor the same queries, thus guaranteeing reproducibility, we adjust\nthe temperature setting to 0. The system prompts designed for the\ntwo phases are demonstrated in Figure 3 and Figure 4. For these\nprocesses, we utilize the public APIs provided by OpenAI [7].\n4.4 Diagnosis Report Generation\nAt the end of the localization procedure, we generate diagnosis\nreports for end-users. The report contains details about the con-\nfiguration error triggers, including related log messages. We also\nFace It Yourselves: An LLM-Based Two-Stage Strategy to Localize Configuration Errors via Logs ISSTA â€™24, September 16â€“20, 2024, Vienna, Austria\ndemonstrate the explanations for the configuration error triggers\nto offer sufficient guidance to end-users. The explanation will show\ndifferent messages if generated in different phases. Generated in\nthe Verification Phase , the explanation will show \"value hits\" or\n\"name hits\". While generated in the Indirect Inference Phase , the\nexplanation presents the illustration of GPT-4 Model [ 7] on the\nsuspected configuration error triggers.\n5 EVALUATION\nTo demonstrate the performance of our methodology, we follow\nfour research questions to carry out our experiments. In particular,\nall the experiments are done on one single server equipped with\nIntel (R) Xeon (R) Gold 5218R CPU (2.1GHz) under the Ubuntu 22.04\nLTS environment with 440GB physical memory.\nRQ1: How accurate is the proposed methodology?\nRQ2: How effective of LogConfigLocalizer compared with other\ntechniques?\nRQ3: How effective of the Verification Phase?\nRQ4: How effective of the two parts of LLM interactions?\n5.1 Experiment Setup\n5.1.1 Subject Software Systems. We select Hadoop [8], a famous\ndistributed big data framework, as the subject software system\nfor several reasons: (1) Maturity: It has a matured configuration\nmechanism with a history spanning over fifteen years from version\n0.10.1 to 3.3.6, [ 4]; (2) Complexity: Its evolution into a complex\necosystem with over 100 related systems and numerous config-\nuration properties makes its configuration space both large and\nintricate [4, 28, 35, 41]; (3) Popularity: It is widely used in academia\nand industry [28, 35]. Therefore, Hadoop [8] is representative for\nevaluating our methodology.\n5.1.2 Benchmark Establishment. As there is no existing log bench-\nmark containing configuration errors for Hadoop [8], we establish\nsuch a benchmark using fuzzing technology on top of JQF [32], a\ncoverage-guided fuzzer for Java programs. We also introduce muta-\ntions to configurations to simulate various real-time scenarios.\n(a) Sampling. Due to the abundance of configuration properties in\nHadoop [8], we randomly sample numeric configuration properties\naccording to Finding 5. Particularly, the configuration properties\nare selected from the default configuration files. The overall number\nof the sampled configuration properties is 685 out of 1452.\n(b) Mutation Strategies. We develop two types of strategies for\nthe value-level mutation: one adheres to the datatype specification,\nwhile the other deliberately violates it, as illustrated in Table 2.\nUnlike previous research centered on Configuration Error Injection\nTesting (i.e., CEIT) [20, 23, 24], we donâ€™t intend to inject specific\ntypes of configuration errors but to imitate the behaviors of end-\nusers, for example, accidentally turn a positive value into a negative\none without considering specific constraints of configuration prop-\nerties.\nRegarding the property-level mutation strategy, we randomly\nselect one configuration property in the configuration space to\nreplace the previous one in the former execution. This requires\nno effort to localize configuration error triggers in the Anomaly\nInference Stage since the configuration settings are accessed in\nboth the direct and indirect inference phases. Therefore, we main-\ntain the property-level mutation strategy unchanged but fabricate\nan additional configuration file for access. This involves injecting\nnine other configuration properties from the sampled configura-\ntion space with mutated values based on the same value mutation\nstrategies.\nTable 2: Strategies of Value Mutation\nData Type Mutate Type Value Type Range\nNumeric\nCompliance\nPositive (0,ğ‘€ğ´ğ‘‹ _ğ¹ğ¿ğ´ğ‘‚ğ‘‡)\nNegative (ğ‘€ğ¼ğ‘ _ğ¹ğ¿ğ‘‚ğ´ğ‘‡, 0)\nZero {0}\nViolation String charset with 5 letters\nEmpty âˆ…\n(c) Test Cases. We utilize five workloads from HiBench [ 12], a\nbenchmark suite for big data framework, as test cases for log gener-\nation to simulate more realistic scenarios where the end-users run\ntheir application code within the software systems. For each work-\nload, we manually implement the test driver programs to activate\nthe execution of fuzzing.\n(d) Execution. There are two modes to activate the fuzzing loop.\nThe default mode utilizes the conventional configuration settings\nto generate fault-free logs and the mutation mode executes with the\nmutated configuration settings (i.e., randomly select one configura-\ntion property with mutated value) to generate may-fault logs. The\ndefault mode runs for one hour, which is enough to generate multi-\nple fault-free log files. We merge these fault-free log files into an\nintegrated log file, parse it, and store the parsed log templates in the\ndatabase. The mutated mode runs for eight hours to generate log\nfiles with a higher occurrence of configuration errors. The details of\nthe benchmark are presented in Table 3. Concretely, we manually\ninspect each generated log file to determine if it is related to config-\nuration errors. The statistics in the \"C-Anomaly\" column indicate\nthe count of log files identified as related to configuration errors,\nwhile \"w/o C-Anomaly\" denotes those identified as configuration\nerror-free.\n5.2 RQ1: How accurate is the proposed\nmethodology?\nTo explore the accuracy of the proposed strategy, we apply LogCon-\nfigLocalizer on the established benchmark. Accuracy is calculated\nby the following formula for each test case:\nğ‘ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ = ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘ _ğ‘œğ‘“ _ğ‘ğ‘œğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘¡ğ‘™ğ‘¦ _ğ‘–ğ‘‘ğ‘’ğ‘›ğ‘¡ğ‘–ğ‘“ğ‘–ğ‘’ğ‘‘ _ğ‘¡ğ‘’ğ‘ ğ‘¡_ğ‘ğ‘ğ‘ ğ‘’ğ‘ \nğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘ _ğ‘œğ‘“ _ğ‘¡ğ‘’ğ‘ ğ‘¡_ğ‘ğ‘ğ‘ ğ‘’ğ‘ _ğ‘“ğ‘™ğ‘œğ‘¤ _ğ‘–ğ‘›ğ‘¡ğ‘œ_ğ‘¡â„ğ‘’_ğ‘â„ğ‘ğ‘ ğ‘’(ğ‘ ğ‘¡ğ‘ğ‘”ğ‘’)\nTable 4 demonstrates the average accuracy statistics.\nThe proposed strategy achieves an average accuracy of 100% in\nthe Anomaly Identification Stage across the five workloads, indicat-\ning the remarkable performance of Anomaly Identification Stage to\nidentify configuration-error-related cases. Additionally, the Anom-\naly Inference Stage attains an average accuracy of 99.91%. Both the\ndirect and indirect inference phases exhibit high accuracy, with\n98.37% and 97.78%, respectively. This high accuracy underscores\nISSTA â€™24, September 16â€“20, 2024, Vienna, Austria Shiwen Shan, Yintong Huo, Yuxin Su, Yichen Li, Dan Li, and Zibin Zheng\nTable 3: Benchmark. A single job executing the pagerank workload and kmeans workload produces two and four log files,\nrespectively. We consider the log files generated in a job as a unified whole log file. The numbers in the brackets indicate the\ncounts of these unified whole log files.\nMode Gen-Log Files FuzzDuration LogTemplate C-Anomaly w/o C-Anomaly\nwordcount default 132 1.000 128 0 132\nmutated 1028 8.000 233 65 963\nsort default 109 1.001 137 0 109\nmutated 459 8.000 201 151 308\nterasort default 129 1.020 128 0 129\nmutated 730 8.006 215 227 503\npagerank default 92(46) 1.582 130 0 92(46)\nmutated 202(121) 8.198 171 41 80\nkmeans default 162(27) 1.690 133 0 162(27)\nmutated 226(48) 8.186 157 14 34\nTable 4: Accuracy. x-A denotes the accuracy of the x phase,\nfor example, S1-A indicates the accuracy of the first stage and\nS2-D-A denotes the accuracy of the direct inference phase in\nthe second stage.\nS1-A S2-D-A S2-I-A S2-A\nwordcount 100% 92.31% 100% 100%\nsort 100% 100% 100% 100%\nterasort 100% 99.56% 100% 99.56%\npagerank 100% 100% 100% 100%\nkmeans 100% 100% 88.89% 100%\nthe reliability of the proposed strategy in localizing configuration\nerrors.\nIn summary, LogConfigLocalizer excels in accurately pinpointing\nconfiguration error triggers in both theAnomaly Identification Stage\nand the Anomaly Inference Stage . The sole unsuccessful case in\nterasort workload results from a failure in the Verification Phase,\nthus failing to proceed to the Indirect Inference Phase . Nonetheless,\nwhen tested in the Indirect Inference Phase , it effectively localizes\nthe configuration error trigger.\nAnswer to RQ1: The proposed methodology attains a\nmean accuracy of up to 99.91%, affirming its feasibility and\nefficacy as a practical strategy for end-users to address\nconfiguration errors.\n5.3 RQ2: How effective of LogConfigLocalizer\ncompared with other techniques?\nWe compare LogConfigLocalizer with ConfDiagDetector [56], which\nidentifies a provided log message as diagnostic during a text anal-\nysis. The text analysis involves identifying the direct symptom\nwithin the message and gauging the semantic similarity between\nthe message and the descriptions of the root-cause configuration\nproperties, utilizing Natural Language Processing (NLP) techniques.\nIt was not originally designed for localizing the configuration error\ntriggers, however, its text analysis can be viewed as an approach to\nlocalizing the configuration error triggers.\nWe utilize Hit Count as the metric to compare the performance\nof the tools. There are four Hit Counts: Name-Hit Counts, Value-Hit\nCounts, NLP-Hit Counts, and LLM-Hit Counts. The metrics rep-\nresent the count of successfully identified log files. The Name-Hit\nCount metric refers to detecting errors based on property names and\nthe Value-Hit Count metric is based on property values. The NLP-\nHit Counts are employed for ConfDiagDetector, and the LLM-Hit\nCounts are used for LogConfigLocalizer. For instance, the LLM-Hit\nCounts indicate the count when the configuration error triggers\nare successfully localized in the Indirect Inference Phase . The count-\ning numbers are employed to assess the performance difference\nbetween LogConfigLocalizer and ConfDiagDetector.\nWe introduce the TotalCases Bar (Red-colored bars) in Figure 5,\nrepresenting the total number of test cases in a workload, to demon-\nstrate the accurate localization capabilities of the two tools. To as-\nsess the efficacy in localizing configuration errors, one can readily\ndiscern from Figure 5 by comparing the Total-Hit Bar with the\nTotalCases Bar. LogConfigLocalizer nearly achieved hits for every\ntest case across the five workloads, except for one in the terasort\nworkload. In contrast, ConfDiagDetectorâ€™s performance is inferior\nto LogConfigLocalizer, with accuracy on the five workloads below\nthat of LogConfigLocalizer, especially with a significantly poorer\nperformance in three of them. For each test case in every work-\nload, both LogConfigLocalizer and ConfDiagDetector successfully\nidentify property values as their Value-Hit Counts remain constant\nacross all workloads. However, LogConfigLocalizer can capture\nboth property names and values, whereas ConfDiagDetector con-\nsistently shows zero Name-Hit Counts across all workloads, as\nillustrated in Figure 5. Additionally, ConfDiagDetector performs\npoorly when comparing the NLP-Hit Counts with the LLM-Hit\nCounts of LogConfigLocalizer. The ineffectiveness of the NLP tech-\nnique in ConfDiagDetector may be attributed to the fact that even\nwhen log messages provide specific information indicating configu-\nration error triggers, they often lack sufficient details regarding the\ncorresponding descriptions. In contrast, LogConfigLocalizer excels\nat extracting key log messages and interpreting the underlying\ninformation within the logs.\nAnswer to RQ2: LogConfigLocalizer outperforms Conf-\nDiagLocalizer in terms of accuracy and exhibits a more\nversatile capability to localize configuration error triggers\nacross different dimensions.\nFace It Yourselves: An LLM-Based Two-Stage Strategy to Localize Configuration Errors via Logs ISSTA â€™24, September 16â€“20, 2024, Vienna, Austria\nName-Hit Value-Hit Other-Hit T otal-Hit\n0\n10\n20\n30\n40\n50\n60Hit Counts\nWordcount\nName-Hit Value-Hit Other-Hit T otal-Hit\n0\n20\n40\n60\n80\n100\n120\n140Hit Counts\nSort\nName-Hit Value-Hit Other-Hit T otal-Hit\n0\n50\n100\n150\n200Hit Counts\nT erasort\nName-Hit Value-Hit Other-Hit T otal-Hit\n0\n5\n10\n15\n20\n25\n30\n35\n40 Hit Counts\nPagerank\nName-Hit Value-Hit Other-Hit T otal-Hit\n0\n2\n4\n6\n8\n10\n12\n14 Hit Counts\nKmeans\nConfDiagDetector\nLogConfigLocalizer\nT otalCases\nFigure 5: Comparison with ConfDiagDetector based on five workloads, the metric, Other-Hit, denotes LLM-Hit Counts for\nLogConfigLocalizer and NLP-Hit Counts for ConfDiagDetector respectively.\n5.4 RQ3: How effective of the Verification\nPhase?\nTo assess the effectiveness of the Verification Phase, we introduce a\nvariant, nv-LogConfigLocalizer (nv is short for no-verification), for\ncomparison with the original version, o-LogConfigLocalizer. The\nvariant removes the Verification Phase and considers configuration\nerror triggers inferred in the Direct Inference Phase as correct. In\nother words, the localization procedure enters the Indirect Infer-\nence Phase only when the Direct Inference Phase fails to identify\nany suspected configuration properties. We utilize the accuracy\nmetric to demonstrate the effectiveness of the Verification Phase in\nensuring the overall accuracy of the Anomaly Inference Stage . The\nmeasurement is the same as that adopted in RQ1.\nTable 5: Comparison with nv-LogConfigLocalizer. The sym-\nbol \"/\" denotes no test cases flow into the specific phase.\nS2-D-A nv-S2-I-A o-S2-I-A nv-S2-A o-S2-A\nwordcount 92.31% / 100% 92.31% 100%\nsort 100% / 100% 100% 100%\nterasort 99.56% 100% 100% 99.56% 99.56%\npagerank 100% / 100% 100% 100%\nkmeans 100% / 88.89% 100% 100%\nTable 5 demonstrates the results. The \"nv-\" column presents\nstatistics from nv-LogConfigLocalizer, while the \"o-\" column repre-\nsents the original version of LogConfigLocalizer. The unprefixed\ncolumn shows identical statistics for both versions of LogConfigLo-\ncalizer. In nv-LogConfigLocalizer and o-LogConfigLocalizer, the\naccuracy remains the same in the Direct Inference Phase , as there\nare no changes in this phase. However, the absence of the Verifi-\ncation Phase has an impact because, without it, there is no second\nopportunity to localize configuration error triggers if the Direct\nInference Phase fails. In theterasort workload, a test case proceeds\ndirectly to the Indirect Inference Phase , resulting in successful local-\nization by both o-LogConfigLocalizer and nv-LogConfigLocalizer.\nYet, in five test cases from the wordcount workload, the verifica-\ntion failure prompts the localization procedure to enter the Indirect\nInference Phase , yielding higher accuracy ( 100% vs. 92.31%) in o-\nLogConfigLocalizer. Consequently, the lack of theVerification Phase\nleads to an overall accuracy reduction.\nAnswer to RQ3: The Verification Phase is effective and\nessential for achieving higher accuracy in the Anomaly In-\nference Stage. Without the Verification Phase, the overall ac-\ncuracy drops from100% to 92.31% in the case ofwordcount\nworkload.\n5.5 RQ4: How effective of the two parts of LLM\ninteractions?\nTo comprehensively evaluate the effectiveness of LLM-interacted\ncomponents, we introduce another variant, nl-LogConfigLocalizer\n(nl is short for no-LLM), to compare with the original version,\no-LogConfigLocalizer. The variant excludes the LLM interaction\ncomponents from the Verification Phase and the Indirect Inference\nPhase. It utilizes a heuristic algorithm for the Verification Phase and\neliminates Indirect Inference Phase . The heuristic algorithm posits\nthat the configuration property matching with most anomalous log\nmessages is the configuration error trigger. In this experiment, we\ntake two metrics, the accuracy, and the false positive rate for our\nISSTA â€™24, September 16â€“20, 2024, Vienna, Austria Shiwen Shan, Yintong Huo, Yuxin Su, Yichen Li, Dan Li, and Zibin Zheng\ncomparison. The false positive rate for each test case is calculated\nby the formula:\nğ¹ğ‘ƒ = ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘ _ğ‘œğ‘“ _ğ‘ ğ‘¢ğ‘ ğ‘ğ‘’ğ‘ğ‘¡ğ‘’ğ‘‘ _ğ‘ğ‘œğ‘›ğ‘“ğ‘–ğ‘”ğ‘¢ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘› _ğ‘ğ‘Ÿğ‘œğ‘ğ‘’ğ‘Ÿğ‘¡ğ‘–ğ‘’ğ‘  âˆ’1\nğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘ _ğ‘œğ‘“ _ğ‘ ğ‘¢ğ‘ ğ‘ğ‘’ğ‘ğ‘¡ğ‘’ğ‘‘ _ğ‘ğ‘œğ‘›ğ‘“ğ‘–ğ‘”ğ‘¢ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘› _ğ‘ğ‘Ÿğ‘œğ‘ğ‘’ğ‘Ÿğ‘¡ğ‘–ğ‘’ğ‘ \n1 in the formula indicates the count of the ground truth. Table 6\ndisplays the outcomes.\nA comparison between the third and fourth columns indicates\nthat o-LogConfigLocalizer excels in minimizing the false positive\nrate in the Direct Inference Phase , exhibiting a lower average false\npositive rate across all five workloads. Additionally, the incorpora-\ntion of theLLM-based Indirect Inference Phase in o-LogConfigLocalizer\ncontributes to high accuracy.\nTable 6: Comparison with nl- variant\nS2-D-FP nl-S2-V-FP o-S2-V-FP nl-S2-A o-S2-A\nwordcount 70.03% 53.39% 3.50% 92.31% 100%\nsort 72.52% 17.58% 2.94% 100% 100%\nterasort 71.75% 17.23% 2.00% 99.56% 99.56%\npagerank 75.03% 14.10% 0 100% 100%\nkmeans 75.29% 14.67% 10.0% 100% 100%\nAnswer to RQ4: The introduction of LLMs guarantees the\noptimal effectiveness to reduce false positives and maintain\na high overall accuracy.\n6 PRACTICAL CASE STUDY\nWe additionally perform a practical case study to demonstrate the\nfeasibility of our methodology by localizing the configuration trig-\ngers on cases identified in the preliminary study.\nFor test case selection, we manually select 33 studied cases in the\npreliminary study to construct the practical benchmark. We employ\nthree criteria for consideration: user-defined configuration settings,\nrun-time logs under the user-defined configuration settings, and\nconfirmed or resolved configuration settings that trigger the error.\nFor the first two criteria, we manually review the content of the\nreport to see if there is relevant information. As for the third crite-\nrion, we search for reports marked with confirmed or resolved flags.\nThe practical benchmark covers path errors (6/33), classpath errors\n(4/33), boolean errors (5/33), numeric errors (10/33), and string er-\nrors (8/33). The practical case study achieves an accuracy of 93.94%\n(31/33), which demonstrates the feasibility of our methodology.\nTo further demonstrate the effectiveness of our methodology, we\ncategorize the correctly identified cases into three types, expanding\nupon the two aforementioned cases (i.e., the direct flow and the\ncomplete flow) described in Section 3.3.3. The three types include the\nfast flow, direct flow, and complete flow. The fast flow indicates a case\nsuccessfully proceeding through the Direct Inference Phase , passing\nthe Verification Phase , and skipping the Indirect Inference Phase .\nApproximately 71% (22/31) of the cases belong to either thefast flow\nor the complete flow type. This indicates that the Direct Inference\nPhase effectively performs its intended function to pinpoint the\nsuspected configuration error triggers, in the majority of cases.\nHowever, about 73% (16/22) of them fail to pass the Verification\nPhase, consequently diverting the localization procedure towards\nthe Indirect Inference Phase . This indicates that additional noise is\nThe NullPointerException at LdapGroupsMapping.goUpGroupHierarchy\nindicates that there might be an issue with the LDAP group hierarchy mapping. \nThe configuration option \n'hadoop.security.group.mapping.ldap.search.group.hierarchy.levels' is directly \nrelated to this functionality and could be the root cause of the error\nThe NullPointerException at LdapGroupsMapping.goUpGroupHierarchy\nindicates that there might be an issue with the LDAP group hierarchy mapping.\nTh fi ti tiThe configuration option \n'hadoop.security.group.mapping.ldap.search.group.hierarchy.levels' is directly \nrelated to this functionality and could be the root cause of the error\nFigure 6: GPT-4 Model Explanation for Configuration Error\nTrigger\nintroduced in real-world scenarios, highlighting the significance\nand necessity of introducing the Verification Phase to ensure the\noverall accuracy of theAnomaly Inference Stage . Moreover, the false\npositive ratio decreased from 0.43 to 0.08 due to the inclusion of the\nVerification Phase. In addition, about 27% of the cases belong to the\ndirect flow type. This indicates the limitation of the Direct Inference\nPhase in more realistic scenarios. However, we can leverage the\nIndirect Inference Phase to localize the configuration error triggers.\nIn addition, we take the first case and the last case shown in Fig-\nure 1 to exemplify the proposed strategy. The first case shown in the\norange box7 belongs to thefast flow type. During theDirect Inference\nPhase, six entries are generated. The culprit,mapred.local.dir, is\none of them due to the property name matching strategy, while the\nother five false positives are identified through value matching. For\nexample, the fabricated property,dfs.datanode.du.reserved.pct\nmutated with a value 0, matches the \"[kry1040/72.30.116.100:50020]\"\nstring inside the log messages. When the accordingly entries of the\nfalse positives are passed to the GPT-4 Model [7], it outputs 30 for\neach of them while offering a relatively high score, 95, to the entry\nof mapred.local.dir. The case in the blue box8 falls into thedirect\nflow, indicating no entry is generated during the Direct Inference\nPhase. In the Direct Inference Phase , we minimize false positives by\nexcluding the analysis of stack statements. Consequently, in this\ncase, the Direct Inference Phase only receives the content \"Error\njava.lang.NullPointerException, \" without any numeric values or\nother informative items. In the Indirect Inference Phase , the GPT-4\nModel [7] identifies three potential configuration error triggers. It\naccurately identifies the most likely one, and the corresponding\nexplanation is provided in Figure 6.\n7 RELATED WORK\n7.1 Configuration Error Diagnosis\nConfiguration errors are notorious and troublesome anomalies,\nprompting the proposal of numerous tools and methodologies to ad-\ndress them [35, 37, 39â€“41, 45, 52, 54, 56, 59]. In general, approaches\nto solving the problem can be categorized into two types: one that\nleverages machine learning techniques and another that exploits\nprogram analysis techniques.\nRecent years have seen the rapid development of machine learn-\ning techniques. Xia et al. [ 39] utilized various text mining tech-\nniques to dig into the bug reports to tell whether a given bug report\ncontains configuration errors or not. Similarly, Xu et al. proposed\nEFSPredictor [40], a tool equipped with various feature selection\napproaches, to build a prediction model for the same target. Zhang\net al. [56] adopted the NLP technique to diagnose whether the out-\nput of the software systems implied the configuration error triggers.\nItâ€™s also a feasible way to explore deep into the source code. Ariel\n7Original report: https://issues.apache.org/jira/browse/HADOOP-134.\n8Original report: https://issues.apache.org/jira/browse/HADOOP-18821.\nFace It Yourselves: An LLM-Based Two-Stage Strategy to Localize Configuration Errors via Logs ISSTA â€™24, September 16â€“20, 2024, Vienna, Austria\net al. [35] used static analysis to extract the configuration options\nfor configuration debugging. Xu et al. introduced PCHECK [45] to\nautomatically analyze the source code and generate configuration\nchecking code to prevent configuration errors in advance. Zhang\net al. presented ConfDiagnoser [54] using static analysis, dynamic\nprofiling, and statistical analysis to localize the configuration error\ntriggers.\nBeyond the aforementioned work, there are also associated re-\nsearch endeavors leveraging logs as auxiliary tools for diagnosing\nconfiguration errors. Similar to ConfigDiagDetector [56], Zhou et\nal. [59] utilized NLP technique to capture the NLP Patterns from\nofficial documents of software systems with log messages captured\nfrom source code and applied a pattern matching task to capture\nconfiguration constraints. Yuan et al. proposed SherLog [ 52] to\ndiagnose a production run failure by utilizing run-time logs and\nsource code to infer the control and data flow of a failed execu-\ntion. Xu et al. put forward a real-time configuration error diagnosis\nmethod for software of AI server infrastructure [41]. The proposed\nframework requires source code to construct Abstract Syntax Trees\nand System Dependency Graphs to match the structured log tem-\nplates extracted from real-time logs. Besides, Wang et al. presented\nMisconfDocotor [37], a tool utilizing exception log features ex-\ntracted from misconfiguration injection to identify configuration\nerrors. The cited studies necessitate both source code and run-time\nlogs to diagnose configuration errors, with a focus on run-time\nlogs for control flow information, neglecting semantic content.\nConversely, LogConfigLocalizer requires no access to source code,\nidentifying abnormal logs and pinpointing configuration errors\nsolely through semantic information extraction. Moreover, instead\nof solely focusing on exception logs as MisconfDocotor [37] does,\nLogConfigLocalizer takes advantage of anomaly degree calculation\nfor informative logs selection.\nThe proposed LLM-based two-stage strategy neither requires\nthe source code of the software systems nor calls for data mining\ntechniques or NLP techniques to dig into the logs. Meanwhile, it\nrequires no misconfiguration error injection efforts. Therefore, itâ€™s\nmore resource-saving and time-saving for end-users to adopt when\nencountering configuration errors.\n7.2 Log Analysis\nLogs are valuable and informative outputs of software systems,\nhence, there is an abundance of research work targeted log analy-\nsis [5, 13, 14, 16, 48, 57, 60].\nTo begin with, logging statement generation is crucial for the\ndownstream log analysis task. Li et al. presented SCLogger [27] to\ngenerate contextualized logging statements with static contexts.\nYuan et al. put forward LogEnhancer [53] to enhance log messages\nbased on source code for failure diagnosis. Prior to log analysis, it\nis often necessary to utilize log parsing technologies to preprocess\nthe raw log messages [ 57]. Huo et al. proposed Semparser [ 15],\na semantic-based parser to extract both explicit and implicit se-\nmantics of logs. Yu et al. introduced Log3T [50] to support new log\ntypes inside new-coming logs based on a transformer encoder-based\nmodel. Logs have been utilized for anomaly detection for long. Du\net al. proposed DeepLog [5], a deep neural network model exploit-\ning Long Short-Term Memory (LSTM) to detect anomalies based on\nthe recognized log patterns. Zhang et al. introduced LogRobust [57],\nutilizing an attention-based Bi-LSTM model for unstable log events\nand sequences to detect anomalies. Yang et al. presented nLSA-\nlog [48], an anomaly detection framework taking log sequences as\nsources to detect anomalies in Intelligent Transportation Systems\nbased on the LSTM model and the self-attention mechanism. Previ-\nous research highlights the reliance on anomaly detection in log\nanalysis on deep learning models, which require high-quality pre-\ncollected and labeled datasets. The effectiveness of these methods\nhinges on dataset quality, a time-consuming process. Thus, a user-\nfriendly and time-efficient anomaly identification stage, integrating\nrule-based strategies to assist end-users in detecting configuration\nerrors, offers a novel approach compared to traditional methods.\nLLMs have demonstrated significant capabilities in various do-\nmains, including fuzzing, type inference, and more [2, 19, 27, 33, 38,\n43]. The integration of LLMs with log analysis is also a growing\narea of research. Li et al. [26] explored the performance of LLMs on\nthe automated logging statement generation practice. Xu et al. [42]\nproposed UniLog to automatically decide where and what to log\nbased on the in-context learning paradigm utilized in LLMs. Le et\nal. [22] investigated the power of ChatGPT in automated log pars-\ning, and Jiang et al. [17] introduced LLMParser, an LLM-based log\nparsing framework to achieve better performance on log parsing.\nHowever, many existing works primarily concentrate on automated\nlogging practice and log parsing, neglecting the capability of LLMs\nto enhance log analysis for anomaly identification and inference.\nIn summary, the LLM-based two-stage strategy for localizing\nconfiguration errors through logs is user-friendly compared to ex-\nisting works using log analysis for anomaly detection. Additionally,\nwe make a significant advancement by employing the robust natu-\nral language understanding capabilities of LLMs to interpret logs,\nthereby facilitating the localization of configuration errors.\n8 CONCLUSION\nConfiguration error remains a challenging problem for both experi-\nenced maintainers and novice end-users, especially in the scenario\nof inaccessible source code. Given that logs are an easily accessible\nresource for most end-users, we conduct a preliminary study and\noutline the challenges and opportunities to apply log analysis to\nlocalize configuration errors. We present an LLM-based two-stage\nstrategy via log analysis based on the insights from the prelimi-\nnary study. To our knowledge, this is the first work to localize the\nroot-cause configuration properties for end-users based on LLMs\nand logs. We implement LogConfigLocalizer based on the design\nof the strategy and show its effectiveness, accuracy, and feasibility\nvia evaluations and a practical case study. We believe our work can\nalleviate the burden of end-users and facilitate a more streamlined\nuse of configurable software systems.\nACKNOWLEDGEMENTS\nWe appreciate all the anonymous reviewers for their valuable and\npractical comments. We also extend our gratitude to Zhuhan Dai,\nWeifeng Hu, Chengpeng Hu, Jiahao Cui, and Biao Zhu for their\ninvaluable early feedback on the draft of this work. The work de-\nscribed in this paper was supported by the National Natural Science\nFoundation of China (No. 62202511) and the Guangdong Basic and\nApplied Basic Research Foundation (2022A1515011713).\nISSTA â€™24, September 16â€“20, 2024, Vienna, Austria Shiwen Shan, Yintong Huo, Yuxin Su, Yichen Li, Dan Li, and Zibin Zheng\nREFERENCES\n[1] Mona Attariyan and Jason Flinn. 2010. Automating configuration troubleshooting\nwith dynamic information flow analysis. In 9th USENIX Symposium on Operating\nSystems Design and Implementation (OSDI 10) .\n[2] Yinfang Chen, Huaibing Xie, Minghua Ma, Yu Kang, Xin Gao, Liu Shi, Yunjie\nCao, Xuedong Gao, Hao Fan, Ming Wen, et al. 2023. Empowering Practical Root\nCause Analysis by Large Language Models for Cloud Incidents. arXiv preprint\narXiv:2305.15778 (2023).\n[3] Marcello Cinque, Domenico Cotroneo, and Antonio Pecchia. 2012. Event logs\nfor the analysis of software failures: A rule-based approach. IEEE Transactions\non Software Engineering 39, 6 (2012), 806â€“821.\n[4] Zhen Dong, Artur Andrzejak, David Lo, and Diego Costa. 2016. Orplocator:\nIdentifying read points of configuration options via static analysis. In 2016 IEEE\n27th International Symposium on Software Reliability Engineering (ISSRE) . IEEE,\n185â€“195.\n[5] Min Du, Feifei Li, Guineng Zheng, and Vivek Srikumar. 2017. Deeplog: Anomaly\ndetection and diagnosis from system logs through deep learning. In Proceedings\nof the 2017 ACM SIGSAC conference on computer and communications security .\n1285â€“1298.\n[6] Qiang Fu, Jian-Guang Lou, Yi Wang, and Jiang Li. 2009. Execution Anomaly\nDetection in Distributed Systems through Unstructured Log Analysis. In 2009\nNinth IEEE International Conference on Data Mining . 149â€“158. https://doi.org/10.\n1109/ICDM.2009.60\n[7] GPT-4. 2023. gpt-4. https://openai.com/gpt-4. Accessed: 2023-11-23.\n[8] Apache Hadoop. 2023. Apache Hadoop. https://hadoop.apache.org/. Accessed:\n2023-11-23.\n[9] Pinjia He, Jieming Zhu, Zibin Zheng, and Michael R. Lyu. 2017. Drain: An\nOnline Log Parsing Approach with Fixed Depth Tree. In 2017 IEEE International\nConference on Web Services (ICWS) . 33â€“40. https://doi.org/10.1109/ICWS.2017.13\n[10] Shilin He, Pinjia He, Zhuangbin Chen, Tianyi Yang, Yuxin Su, and Michael R\nLyu. 2021. A survey on automated log analysis for reliability engineering. ACM\ncomputing surveys (CSUR) 54, 6 (2021), 1â€“37.\n[11] Shilin He, Qingwei Lin, Jian-Guang Lou, Hongyu Zhang, Michael R Lyu, and\nDongmei Zhang. 2018. Identifying impactful service system problems via log\nanalysis. In Proceedings of the 2018 26th ACM joint meeting on European software\nengineering conference and symposium on the foundations of software engineering .\n60â€“70.\n[12] Shengsheng Huang, Jie Huang, Jinquan Dai, Tao Xie, and Bo Huang. 2010. The\nHiBench benchmark suite: Characterization of the MapReduce-based data anal-\nysis. In 2010 IEEE 26th International Conference on Data Engineering Workshops\n(ICDEW 2010) . 41â€“51. https://doi.org/10.1109/ICDEW.2010.5452747\n[13] Yintong Huo, Cheryl Lee, Yuxin Su, Shiwen Shan, Jinyang Liu, and Michael R\nLyu. 2023. EvLog: Identifying Anomalous Logs over Software Evolution. In 2023\nIEEE 34th International Symposium on Software Reliability Engineering (ISSRE) .\nIEEE, 391â€“402.\n[14] Yintong Huo, Yichen Li, Yuxin Su, Pinjia He, Zifan Xie, and Michael R Lyu. 2023.\nAutolog: A log sequence synthesis framework for anomaly detection. In2023 38th\nIEEE/ACM International Conference on Automated Software Engineering (ASE) .\nIEEE, 497â€“509.\n[15] Yintong Huo, Yuxin Su, Cheryl Lee, and Michael R Lyu. 2023. Semparser: A\nsemantic parser for log analytics. In 2023 IEEE/ACM 45th International Conference\non Software Engineering (ICSE) . IEEE, 881â€“893.\n[16] Yintong Huo, Yuxin Su, and Michael Lyu. 2022. LogVm: Variable Semantics Miner\nfor Log Messages. In 2022 IEEE International Symposium on Software Reliability\nEngineering Workshops (ISSREW) . IEEE, 124â€“125.\n[17] Zhihan Jiang, Jinyang Liu, Zhuangbin Chen, Yichen Li, Junjie Huang, Yintong\nHuo, Pinjia He, Jiazhen Gu, and Michael R Lyu. 2023. LLMParser: A LLM-based\nLog Parsing Framework. arXiv preprint arXiv:2310.01796 (2023).\n[18] Jira. 2023. Jira. https://www.atlassian.com/software/jira. Accessed: 2023-11-23.\n[19] Sungmin Kang, Gabin An, and Shin Yoo. 2023. A Preliminary Evaluation of\nLLM-Based Fault Localization. arXiv preprint arXiv:2308.05487 (2023).\n[20] Lorenzo Keller, Prasang Upadhyaya, and George Candea. 2008. ConfErr: A tool\nfor assessing resilience to human configuration errors. In 2008 IEEE International\nConference on Dependable Systems and Networks With FTCS and DCC (DSN) .\n157â€“166. https://doi.org/10.1109/DSN.2008.4630084\n[21] Van-Hoang Le and Hongyu Zhang. 2021. Log-based Anomaly Detection Without\nLog Parsing. In 2021 36th IEEE/ACM International Conference on Automated Soft-\nware Engineering (ASE) . 492â€“504. https://doi.org/10.1109/ASE51524.2021.9678773\n[22] Van-Hoang Le and Hongyu Zhang. 2023. Log Parsing: How Far Can ChatGPT\nGo?. In 2023 38th IEEE/ACM International Conference on Automated Software\nEngineering (ASE). IEEE Computer Society, 1699â€“1704.\n[23] Junqiang Li, Senyi Li, Keyao Li, Falin Luo, Hongfang Yu, Shanshan Li, and Xiang\nLi. 2024. ECFuzz: Effective Configuration Fuzzing for Large-Scale Systems. In\nProceedings of the 46th IEEE/ACM International Conference on Software Engineering .\n1â€“12.\n[24] Wang Li, Zhouyang Jia, Shanshan Li, Yuanliang Zhang, Teng Wang, Erci Xu,\nJi Wang, and Xiangke Liao. 2021. Challenges and Opportunities: An in-Depth\nEmpirical Study on Configuration Error Injection Testing. In Proceedings of the\n30th ACM SIGSOFT International Symposium on Software Testing and Analysis\n(Virtual, Denmark) (ISSTA 2021). Association for Computing Machinery, New\nYork, NY, USA, 478â€“490. https://doi.org/10.1145/3460319.3464799\n[25] Xiaoyun Li, Pengfei Chen, Linxiao Jing, Zilong He, and Guangba Yu. 2020. Swiss-\nLog: Robust and Unified Deep Learning Based Log Anomaly Detection for Diverse\nFaults. In 2020 IEEE 31st International Symposium on Software Reliability Engi-\nneering (ISSRE) . 92â€“103. https://doi.org/10.1109/ISSRE5003.2020.00018\n[26] Yichen Li, Yintong Huo, Zhihan Jiang, Renyi Zhong, Pinjia He, Yuxin Su, and\nMichael R Lyu. 2023. Exploring the effectiveness of llms in automated logging\ngeneration: An empirical study. arXiv preprint arXiv:2307.05950 (2023).\n[27] Yichen Li, Yintong Huo, Renyi Zhong, Zhihan Jiang, Jinyang Liu, Junjie Huang,\nJiazhen Gu, Pinjia He, and Michael R Lyu. 2024. Go Static: Contextualized Logging\nStatement Generation. arXiv preprint arXiv:2402.12958 (2024).\n[28] Yuhao Liu, Wei Wang, Yan Jia, Sihan Xu, and Zheli Liu. 2023. CRSExtractor: Auto-\nmated configuration option read sites extraction towards IoT cloud infrastructure.\nHeliyon 9, 4 (2023).\n[29] Stack Overflow. 2023. Stack Overflow. https://stackoverflow.com/. Accessed:\n2023-11-23.\n[30] OWASP. 2021. A05:2021 â€“ Security Misconfiguration . https://owasp.org/Top10/\nA05_2021-Security_Misconfiguration/ Accessed: November 23, 2023.\n[31] OWASP. 2022. OWASP Top 10 Vulnerabilities in 2022 . https:\n//www.spiceworks.com/it-security/vulnerability-management/articles/owasp-\ntop-ten-vulnerabilities/#_001 Accessed: November 23, 2023.\n[32] Rohan Padhye, Caroline Lemieux, and Koushik Sen. 2019. JQF: Coverage-Guided\nProperty-Based Testing in Java. In Proceedings of the 28th ACM SIGSOFT Inter-\nnational Symposium on Software Testing and Analysis (Beijing, China) (ISSTA\n2019). Association for Computing Machinery, New York, NY, USA, 398â€“401.\nhttps://doi.org/10.1145/3293882.3339002\n[33] Yun Peng, Chaozheng Wang, Wenxuan Wang, Cuiyun Gao, and Michael R Lyu.\n2023. Generative Type Inference for Python. arXiv preprint arXiv:2307.09163\n(2023).\n[34] The Open Web Application Security Project. 2023. The Open Web Application\nSecurity Project. https://owasp.org/. Accessed: 2023-11-23.\n[35] Ariel Rabkin and Randy Katz. 2011. Static extraction of program configuration\noptions. InProceedings of the 33rd International Conference on Software Engineering .\n131â€“140.\n[36] CircleID Reporter. 2009. Misconfiguration Brings Down Entire .SE Domain in\nSweden. https://circleid.com/posts/misconfiguration_brings_down_entire_se_\ndomain_in_sweden/ Accessed: November 23, 2023.\n[37] Teng Wang, Xiaodong Liu, Shanshan Li, Xiangke Liao, Wang Li, and Qing Liao.\n2018. MisconfDoctor: diagnosing misconfiguration via log-based configuration\ntesting. In 2018 IEEE International Conference on Software Quality, Reliability and\nSecurity (QRS) . IEEE, 1â€“12.\n[38] Chunqiu Steven Xia, Matteo Paltenghi, Jia Le Tian, Michael Pradel, and Ling-\nming Zhang. 2023. Universal fuzzing via large language models. arXiv preprint\narXiv:2308.04748 (2023).\n[39] Xin Xia, David Lo, Weiwei Qiu, Xingen Wang, and Bo Zhou. 2014. Automated\nConfiguration Bug Report Prediction Using Text Mining. In2014 IEEE 38th Annual\nComputer Software and Applications Conference . 107â€“116. https://doi.org/10.1109/\nCOMPSAC.2014.17\n[40] Bowen Xu, David Lo, Xin Xia, Ashish Sureka, and Shanping Li. 2015. EFSPredictor:\nPredicting Configuration Bugs with Ensemble Feature Selection. In 2015 Asia-\nPacific Software Engineering Conference (APSEC) . 206â€“213. https://doi.org/10.\n1109/APSEC.2015.38\n[41] Guangquan Xu, Xinru Ding, Sihan Xu, Yan Jia, Shaoying Liu, Shicheng Feng, and\nXi Zheng. 2023. Real-Time Diagnosis of Configuration Errors for Software of AI\nServer Infrastructure. IEEE Transactions on Dependable and Secure Computing\n(2023).\n[42] Junjielong Xu, Ziang Cui, Yuan Zhao, Xu Zhang, Shilin He, Pinjia He, Liqun Li, Yu\nKang, Qingwei Lin, Yingnong Dang, et al. 2023. UniLog: Automatic Logging via\nLLM and In-Context Learning. In 2024 IEEE/ACM 46th International Conference\non Software Engineering (ICSE) . IEEE Computer Society, 129â€“140.\n[43] Junjielong Xu, Ruichun Yang, Yintong Huo, Chengyu Zhang, and Pinjia He.\n2024. DivLog: Log Parsing with Prompt Enhanced In-Context Learning. In 2024\nIEEE/ACM 46th International Conference on Software Engineering (ICSE) . IEEE\nComputer Society, 983â€“983.\n[44] Tianyin Xu, Long Jin, Xuepeng Fan, Yuanyuan Zhou, Shankar Pasupathy, and\nRukma Talwadker. 2015. Hey, you have given me too many knobs!: Understanding\nand dealing with over-designed configuration in system software. In Proceedings\nof the 2015 10th Joint Meeting on Foundations of Software Engineering . 307â€“319.\n[45] Tianyin Xu, Xinxin Jin, Peng Huang, Yuanyuan Zhou, Shan Lu, Long Jin, and\nShankar Pasupathy. 2016. Early detection of configuration errors to reduce\nfailure damage. In 12th USENIX Symposium on Operating Systems Design and\nImplementation (OSDI 16) . 619â€“634.\n[46] Tianyin Xu, Jiaqi Zhang, Peng Huang, Jing Zheng, Tianwei Sheng, Ding Yuan,\nYuanyuan Zhou, and Shankar Pasupathy. 2013. Do not blame users for miscon-\nfigurations. In Proceedings of the Twenty-Fourth ACM Symposium on Operating\nSystems Principles . 244â€“259.\nFace It Yourselves: An LLM-Based Two-Stage Strategy to Localize Configuration Errors via Logs ISSTA â€™24, September 16â€“20, 2024, Vienna, Austria\n[47] Tianyin Xu and Yuanyuan Zhou. 2015. Systems approaches to tackling configu-\nration errors: A survey. ACM Computing Surveys (CSUR) 47, 4 (2015), 1â€“41.\n[48] Ruipeng Yang, Dan Qu, Ying Gao, Yekui Qian, and Yongwang Tang. 2019. nL-\nSALog: An Anomaly Detection Framework for Log Sequence in Security Man-\nagement. IEEE Access 7 (2019), 181152â€“181164. https://doi.org/10.1109/ACCESS.\n2019.2953981\n[49] Zuoning Yin, Xiao Ma, Jing Zheng, Yuanyuan Zhou, Lakshmi N Bairavasundaram,\nand Shankar Pasupathy. 2011. An empirical study on configuration errors in\ncommercial and open source systems. In Proceedings of the Twenty-Third ACM\nSymposium on Operating Systems Principles . 159â€“172.\n[50] Siyu Yu, Yifan Wu, Zhijing Li, Pinjia He, Ningjiang Chen, and Changjian Liu. 2023.\nLog Parsing with Generalization Ability under New Log Types. In Proceedings of\nthe 31st ACM Joint European Software Engineering Conference and Symposium on\nthe Foundations of Software Engineering . 425â€“437.\n[51] Chun Yuan, Ni Lao, Ji-Rong Wen, Jiwei Li, Zheng Zhang, Yi-Min Wang, and\nWei-Ying Ma. 2006. Automated known problem diagnosis with event traces.\nACM SIGOPS Operating Systems Review 40, 4 (2006), 375â€“388.\n[52] Ding Yuan, Haohui Mai, Weiwei Xiong, Lin Tan, Yuanyuan Zhou, and Shankar\nPasupathy. 2010. Sherlog: error diagnosis by connecting clues from run-time logs.\nIn Proceedings of the fifteenth International Conference on Architectural support\nfor programming languages and operating systems . 143â€“154.\n[53] Ding Yuan, Jing Zheng, Soyeon Park, Yuanyuan Zhou, and Stefan Savage. 2012.\nImproving software diagnosability via log enhancement. ACM Transactions on\nComputer Systems (TOCS) 30, 1 (2012), 1â€“28.\n[54] Sai Zhang and Michael D Ernst. 2013. Automated diagnosis of software con-\nfiguration errors. In 2013 35th International Conference on Software Engineering\n(ICSE). IEEE, 312â€“321.\n[55] Sai Zhang and Michael D Ernst. 2014. Which configuration option should I\nchange?. InProceedings of the 36th international conference on software engineering .\n152â€“163.\n[56] Sai Zhang and Michael D Ernst. 2015. Proactive detection of inadequate diagnostic\nmessages for software configuration errors. InProceedings of the 2015 International\nSymposium on Software Testing and Analysis . 12â€“23.\n[57] Xu Zhang, Yong Xu, Qingwei Lin, Bo Qiao, Hongyu Zhang, Yingnong Dang,\nChunyu Xie, Xinsheng Yang, Qian Cheng, Ze Li, et al. 2019. Robust log-based\nanomaly detection on unstable log data. In Proceedings of the 2019 27th ACM\nJoint Meeting on European Software Engineering Conference and Symposium on\nthe Foundations of Software Engineering . 807â€“817.\n[58] Zenong Zhang, George Klees, Eric Wang, Michael Hicks, and Shiyi Wei. 2023.\nFuzzing configurations of program options. ACM Transactions on Software Engi-\nneering and Methodology 32, 2 (2023), 1â€“21.\n[59] Shulin Zhou, Xiaodong Liu, Shanshan Li, Zhouyang Jia, Yuanliang Zhang, Teng\nWang, Wang Li, and Xiangke Liao. 2021. Confinlog: Leveraging software logs to\ninfer configuration constraints. In 2021 IEEE/ACM 29th International Conference\non Program Comprehension (ICPC) . IEEE, 94â€“105.\n[60] Jieming Zhu, Shilin He, Pinjia He, Jinyang Liu, and Michael R Lyu. 2023. Loghub:\nA large collection of system log datasets for ai-driven log analytics. In 2023 IEEE\n34th International Symposium on Software Reliability Engineering (ISSRE) . IEEE,\n355â€“366.\nReceived 16-DEC-2023; accepted 2024-03-02",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7710050344467163
    },
    {
      "name": "Root cause analysis",
      "score": 0.6676622629165649
    },
    {
      "name": "Root cause",
      "score": 0.6228254437446594
    },
    {
      "name": "Baseline (sea)",
      "score": 0.6176056265830994
    },
    {
      "name": "Software",
      "score": 0.5626885890960693
    },
    {
      "name": "Code (set theory)",
      "score": 0.42968082427978516
    },
    {
      "name": "Face (sociological concept)",
      "score": 0.41935697197914124
    },
    {
      "name": "Design space exploration",
      "score": 0.4138898253440857
    },
    {
      "name": "Software engineering",
      "score": 0.4096866250038147
    },
    {
      "name": "Data mining",
      "score": 0.3522185683250427
    },
    {
      "name": "Reliability engineering",
      "score": 0.33960965275764465
    },
    {
      "name": "Embedded system",
      "score": 0.250690221786499
    },
    {
      "name": "Programming language",
      "score": 0.1723099946975708
    },
    {
      "name": "Engineering",
      "score": 0.11430534720420837
    },
    {
      "name": "Social science",
      "score": 0.0
    },
    {
      "name": "Geology",
      "score": 0.0
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.0
    },
    {
      "name": "Sociology",
      "score": 0.0
    },
    {
      "name": "Oceanography",
      "score": 0.0
    }
  ]
}