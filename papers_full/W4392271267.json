{
  "title": "A Piece of Theatre: Investigating How Teachers Design LLM Chatbots to Assist Adolescent Cyberbullying Education",
  "url": "https://openalex.org/W4392271267",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A4224905600",
      "name": "Hedderich, Michael A.",
      "affiliations": [
        "Cornell University"
      ]
    },
    {
      "id": null,
      "name": "Bazarova, Natalie N.",
      "affiliations": [
        "Cornell University"
      ]
    },
    {
      "id": "https://openalex.org/A2370163752",
      "name": "Zou Wen-ting",
      "affiliations": [
        "Pennsylvania State University"
      ]
    },
    {
      "id": null,
      "name": "Shim, Ryun",
      "affiliations": [
        "Cornell University"
      ]
    },
    {
      "id": "https://openalex.org/A2746817217",
      "name": "Ma Xinda",
      "affiliations": [
        "Cornell University"
      ]
    },
    {
      "id": "https://openalex.org/A2099849166",
      "name": "Yang Qian",
      "affiliations": [
        "Cornell University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4309798353",
    "https://openalex.org/W2339590251",
    "https://openalex.org/W4221159410",
    "https://openalex.org/W1527608753",
    "https://openalex.org/W1989450733",
    "https://openalex.org/W2136925099",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W2887143927",
    "https://openalex.org/W2597369567",
    "https://openalex.org/W1999311677",
    "https://openalex.org/W2796346703",
    "https://openalex.org/W3040716366",
    "https://openalex.org/W3143917600",
    "https://openalex.org/W4382619745",
    "https://openalex.org/W2088028234",
    "https://openalex.org/W2983714615",
    "https://openalex.org/W4366549000",
    "https://openalex.org/W2091127757",
    "https://openalex.org/W2978701910",
    "https://openalex.org/W2051844321",
    "https://openalex.org/W2094914455",
    "https://openalex.org/W1737811870",
    "https://openalex.org/W4366420437",
    "https://openalex.org/W1270658374",
    "https://openalex.org/W2766418545",
    "https://openalex.org/W1922947386",
    "https://openalex.org/W3046246174",
    "https://openalex.org/W4363671832",
    "https://openalex.org/W4307475457",
    "https://openalex.org/W2115193326",
    "https://openalex.org/W2138067375",
    "https://openalex.org/W3205068155",
    "https://openalex.org/W3023945813",
    "https://openalex.org/W4378499085",
    "https://openalex.org/W3186515451",
    "https://openalex.org/W3214472660",
    "https://openalex.org/W2529427724",
    "https://openalex.org/W3185342386",
    "https://openalex.org/W4283170666",
    "https://openalex.org/W3052520363",
    "https://openalex.org/W4225911013",
    "https://openalex.org/W3203321135",
    "https://openalex.org/W4225001918",
    "https://openalex.org/W2933377349",
    "https://openalex.org/W4383679928",
    "https://openalex.org/W4366548330"
  ],
  "abstract": "Cyberbullying harms teenagers' mental health, and teaching them upstanding\\nintervention is crucial. Wizard-of-Oz studies show chatbots can scale up\\npersonalized and interactive cyberbullying education, but implementing such\\nchatbots is a challenging and delicate task. We created a no-code chatbot\\ndesign tool for K-12 teachers. Using large language models and prompt chaining,\\nour tool allows teachers to prototype bespoke dialogue flows and chatbot\\nutterances. In offering this tool, we explore teachers' distinctive needs when\\ndesigning chatbots to assist their teaching, and how chatbot design tools might\\nbetter support them. Our findings reveal that teachers welcome the tool\\nenthusiastically. Moreover, they see themselves as playwrights guiding both the\\nstudents' and the chatbot's behaviors, while allowing for some improvisation.\\nTheir goal is to enable students to rehearse both desirable and undesirable\\nreactions to cyberbullying in a safe environment. We discuss the design\\nopportunities LLM-Chains offer for empowering teachers and the research\\nopportunities this work opens up.\\n",
  "full_text": "A Piece of Theatre: Investigating How Teachers Design\nLLM Chatbots to Assist Adolescent Cyberbullying Education\nMichael A. Hedderich\nCornell University\nUSA\nmah499@cornell.edu\nNatalie N. Bazarova\nCornell University\nUSA\nbazarova@cornell.edu\nWenting Zou\nThe Pennsylvania State University\nUSA\nwpz5135@psu.edu\nRyun Shim\nCornell University\nUSA\nrs2279@cornell.edu\nXinda Ma\nCornell University\nUSA\nxm238@cornell.edu\nQian Yang\nCornell University\nUSA\nqianyang@cornell.edu\nFigure 1: Our prototyping platform for students learning upstanding against cyberbullying on social media. The\neducator can build a chatbot based on LLM-Chains that converses with the student about their bystander actions.\nWe utilize this system as a probe to understand what levers teachers need to build chatbots that are helpful teaching\ntools for adolescent cyberbullying education.\nABSTRACT\nCyberbullying harms teenagers‚Äô mental health, and teaching them\nupstanding intervention is crucial. Wizard-of-Oz studies show chat-\nbots can scale up personalized and interactive cyberbullying educa-\ntion, but implementing such chatbots is a challenging and delicate\ntask. We created a no-code chatbot design tool for K-12 teachers.\nUsing large language models and prompt chaining, our tool allows\nteachers to prototype bespoke dialogue flows and chatbot utter-\nances. In offering this tool, we explore teachers‚Äô distinctive needs\nwhen designing chatbots to assist their teaching, and how chat-\nbot design tools might better support them. Our findings reveal\nthat teachers welcome the tool enthusiastically. Moreover, they\nsee themselves as playwrights guiding both the students‚Äô and the\nchatbot‚Äôs behaviors, while allowing for some improvisation. Their\ngoal is to enable students torehearse both desirable and undesirable\nreactions to cyberbullying in a safe environment. We discuss the\ndesign opportunities LLM-Chains offer for empowering teachers\nand the research opportunities this work opens up.\nCCS CONCEPTS\n‚Ä¢ Human-centered computing ‚ÜíEmpirical studies in HCI ; ‚Ä¢\nComputing methodologies ‚ÜíArtificial intelligence.\nKEYWORDS\nlarge language models, chatbot, cyberbullying, education, teachers\narXiv:2402.17456v1  [cs.HC]  27 Feb 2024\nHedderich et al.\n1 INTRODUCTION\nMany adolescents have experienced cyberbullying, such as offen-\nsive name-calling, purposeful embarrassment, physical threats,\nand sexual harassment [ 28, 69]. Instances of cyberbullying are\nassociated with youth depression, self-harm, and even suicide at-\ntempts [31, 33, 41, 51, 58]. Large language models (LLMs) pose\nthe risk of increasing the level of toxic online interactions even\nmore [70], further jeopardizing youth‚Äôs online safety and digital\nwell-being. The intervention of bystanders, so-called upstanding,\nis an effective approach to support the victims [ 18, 74], but ado-\nlescents struggle in taking this role [2, 15, 78]. It is, therefore, an\nimportant skill to learn and practice for digital interactions. Faced\nwith a wide teacher shortage [14], especially in subjects that teach\nupstanding to cyberbullying like technology or health class [65], it\nis doubtful that students can receive enough personal attention to\nlearn how to be upstanders.\nTeacher-built chatbots could scale up personalized instruction\nabout how to upstand to cyberbullying [11, 24, 43, 50, 64]. While\npromising, previous research findings were limited to primarily\nWizard-of-Oz studies. Translating them into actual chatbots that\nhave an impact in the classroom requires solving technical issues\naround lack of data [32, 75] and necessitates that the chatbot fits\ninto the wider curriculum [25, 32, 34]. Giving teachers control of\nLLM-based chatbots could solve both.\nLLM-Chains give non-AI-experts the ability to build LLM ap-\nplications with fine-grained control, but it is unknown if and how\nthey can address the teachers‚Äô needs. LLMs drastically reduce train-\ning data requirements and with LLM-Chains, non-AI-experts can\ndesign a flow of individually configured LLMs to solve a larger\ntask [72]. It is thus a promising approach for teacher-built chatbots.\nFor chatbots, LLM-Chains have, however, only been evaluated on\nsimple toy tasks so far and it is unclear if they can enable teachers\nto build complex chatbots that teach teens upstanding skills.\nIn this work, we investigate to what extend LLM-Chains are a\nsuitable approach to empower teachers to build chatbots that fit into\ntheir upstanding-to-cyberbullying education and what other kinds\nof support (or \"levers\") they need. We have developed a prototyping\nplatform to evaluate conversational AI interventions that cultivate\nteen upstanding behaviors (Figure 1). Leveraging this platform, we\nbuilt a system as a probe and invited 13 middle school teachers to\nexplore building a chatbot, collecting their experiences through\nthink-aloud and interviews, which allowed us to gain their in-depth\nperspectives. With our probe, the teachers could gain hands-on\nexperience building and interacting with the chatbot, thus providing\ndeeper insights into their needs than discussing purely hypothetical\nsituations.\nOur findings show that teachers‚Äô needs for levers reflect their\nlarger chatbot design goal: To construct a piece of educational the-\natre, where teens learn by rehearsing different upstanding behaviors\nin the social situation surrounding concrete instances of cyberbully-\ning. Teachers perceive their role as \"playwrights\" wanting to write\na script for role-play social situations, ensuring that the chatbot\nguides students to specific behaviors while allowing students to\nexplore different perspectives. This mindset shapes their needs for\nlevers to further personalized instruction. To give just one example,\nLLM-Chains enable teachers to customize the chatbot to their class.\nHowever, new levers are necessary to allow for more controlled im-\nprovisations so students can practice upstanding more concretely,\napplying their knowledge to commonly encountered situations.\nWe discuss the implications of these findings for designing levers\nthat enhance the instructional value of chatbots for cyberbullying\ninterventions and identify new research questions that still need to\nbe answered in the context of chatbot use for classroom instruction.\nThis paper makes two contributions. First, it presents a rare\ndescription of how teachers envision using chatbots in their class-\nrooms for K-12 prosocial online behavior education and furthers\nour understanding of what design and technical components can\nhelp them reach their goals. Second, it identifies new research and\ndesign opportunities about how LLMs and chatbot design tools\ncan deliver on teachers‚Äô needs and ensure that chatbots can have\nan actual impact in the classroom. While LLMs are often seen as\ndisruptive to teachers‚Äô educational and evaluative work [6, 39], our\nwork offers a complimentary perspective on how LLMs can aug-\nment it by delivering teacher-orchestrated and student-improvised\npersonalized instruction.\n2 RELATED WORK\nThis section discusses the importance and difficulties of teaching\nabout cyberbullying, as well as the current state of teacher-designed\nchatbots for this purpose.\n2.1 Teaching Adolescents about Cyberbullying\nand Bystander Intervention\nCyberbullying is a form of online aggression intentionally and\nrepeatedly carried out against victims who are unable to defend\nthemselves [66]. In contrast to offline bullying, cyberbullying can\nexhibit more complex social dynamics [36] and incorporate, as part\nof their attacks, a rich array of media, such as texts, photos and\nvideos [37], and include manipulated imagery and deepfakes [ 9,\n63]. Because the power imbalance is at its heart, cyberbullying is\nknown to further existing social inequalities and deplete the mental\nhealth of children and adolescents, especially those from minority\ngroups [31, 33, 41, 51, 58]. Addressing the needs of the adolescent\nvictims goes beyond content moderation on social media platforms\nand requires a consideration of emotional impacts, victimization,\nand the involvement of social circles [74].\nBystander intervention is widely recognized as a crucial antidote\nto cyberbullying and its disastrous effects on youth (see review\n[18]). Many U.S. students experience bullying online [28], but only\na small minority tell an adult or a school teacher [49]. In this con-\ntext, whether bystanders choose to reinforce a bully, stay silent on\nthe sidelines, or support the victim becomes especially important.\nBystander actions can be public or private, subtle or direct, ranging\nfrom flagging the problematic comment to publicly defending the\nvictim or confronting the bully [17, 55].\nTo understand the problem of bystander inaction, researchers\nhave conducted surveys [ 49] and qualitative studies such as in-\nterviews, focus groups, and controlled experiments [15, 16]. Most\nstudies have drawn on Darley and Latane‚Äôs Five Stages of Bystander\nIntervention framework [13, 35]. According to this framework by-\nstanders must first 1) notice the event, 2) appraise it as an emer-\ngency, 3) accept responsibility, 4) have the knowledge and skills\nA Piece of Theatre\non how to intervene, and 5) act. A related theoretical approach ‚Äì\nthe situational-cognitive model of bystander behavior [ 10] ‚Äì ex-\ntends the bystander intervention model by accounting for addi-\ntional cognitive influences (e.g., attitudes toward intervening and\nperceived norms for intervening), group affiliation factors, and\ntarget/perpetrator factors. These additional factors capture the in-\nfluence of the social environment, which poses many perceived\nbarriers to intervening in the eyes of adolescent bystanders.\nIndeed, previous research has shown that adolescent bystanders\nface challenges at almost every step leading to the bystander inter-\nvention action [2, 78]. For example, they do not always appraise\nbullying as an emergency because the consequences of the inci-\ndent for the victim, the offender, and other witnesses are often not\ninstantly visible [4, 5]. Adolescent bystanders receive little encour-\nagement from their social environment to be upstanders [18, 45].\nMoreover, strong evidence indicates that their actions are highly\ndependent on contextual factors, such as social cues from peers and\nadult figures, that they are expected to act prosocially [15, 16]. In\ncontrast to offline bullying, specific aspects of online interactions,\nsuch as its asynchronous nature and large community sizes, might\nfurther inhibit upstanding behavior [2]. Finally, youth often lack the\nskills to execute bystander intervention strategies in practice [15].\nConsidering the need for intervention and the difficulty the youth\nface in performing it, it is crucial that adolescents learn strategies for\nupstanding. Midgett et al. [42], e.g., created STAC, an educational\nprogram that teaches middle schoolers to develop knowledge of\nspecific strategies to act as peer advocates. For example:\n‚Ä¢‚ÄúAccompany others ‚Äù: Reaching out to and supporting students\nwho were the target of bullying;\n‚Ä¢‚ÄúCoaching compassion ‚Äù: Gently confronting the bully to foster\nempathy toward the victim and communicating that the bullying\nbehavior is unacceptable.\nThese speech acts exemplify how conversations can simultane-\nously provide knowledge and social guidance, thereby effectively\nimproving bystander skills and behaviors. Further, by guiding the\nyouth bystander through these steps, teachers could help the youth\nbystander practice multiple upstanding skills as the conversation\nunfolds. What strategy to use, however, depends on the student,\nand training activities are instrumental in helping students learn\nand practice appropriate strategies [42].\n2.2 Teachers Creating Chatbots for Teaching\nTo scale up successful conversational guidance like STAC, chatbots\ncould become impactful educational tools. Conversational AI tech-\nnology has the potential to provide personalized and empathetic\nguidance to adolescents, helping them become more effective proso-\ncial bystanders. Just as one bystander‚Äôs response to cyberbullying\ncould empower others and help curb online aggression [1, 2, 5], a\nthoughtfully designed conversational AI system likewise has the\npotential to mobilize young people to intervene safely and effec-\ntively.\nResearchers have started creating proof-of-concept chatbots\nthat teach youth bystander intervention strategies [11, 24, 43, 50,\n64]. These works, largely based on Wizard-of-Oz, have repeatedly\nshown that chatbots have the potential to guide youth bystanders\nto action, although none of the proposed chatbots have been imple-\nmented or evaluated with real users after a period of use. Despite\nits promises, bringing such conversation AI agents to the classroom\nstill faces both conceptual and technical barriers.\nTo achieve an impact in schools, chatbots need to fit into the\nlarger curriculum and become part of the educational process. Re-\nsearchers have been advocating for the inclusion of teachers in\nthe design process of learning tools [68]. A chatbot alone cannot\nreplace a teacher, rather, it can enhance their teaching practice and\nshould be seen as a new tool that supports teachers [ 25, 32, 34].\nFurthermore, involving teachers in the design process has the po-\ntential to elevate their adoption of new technologies [ 19]. Thus,\nit is crucial that the viewpoint of the teacher is considered in the\ndesign and adoption process and that teachers are given control\nover the chatbots. The individual teacher needs to be able to adapt\nthe chatbot so that it fits into their curriculum and becomes a useful\naid to them.\nBuilding a chatbot to help youth upstand to cyberbullying is also\nchallenging from an AI perspective. Adolescent cyberbullying is\noften characterized by relational aggression (e.g., ‚ÄúYou are not one of\nus!‚Äù) rather than explicit language [52, 71], making it harder to build\nAI to detect, much less respond to it appropriately. Moreover, the\nAI needs to be empathetic, engaging, and responsive to the teen‚Äôs\nbehaviors. It also needs to monitor and regulate the escalation of\nemotions, considering the sensitive nature of a conversation about\ncyberbullying. Furthermore, lack of data, limited ML performance,\nand canned responses have been a longstanding issue for chatbot\ninterfaces [32, 75], and this is likely also limiting the advancement\nin chatbots for youth bystander intervention.\n2.3 Creating Controllable LLM Chatbots\nTeacher-built chatbots based on large language models could ad-\ndress both of the aforementioned issues, providing better chatbots\nfrom a technical perspective while ensuring that the chatbot fits\ninto the classroom.\nLLMs have revolutionized the field of Natural Language Process-\ning (NLP) and could help overcome the aforementioned technical\nchatbot challenges. LLMs can better generalize to new domains\nrequiring only a small set of instructions and examples of desired\ninteractions, so-called prompts [8]. Prompting LLMs thus offers an\nexciting new approach to chatbot development, shifting the focus\nfrom a data question to a design question.\nWhile prompted LLMs advance the field of chatbot design, they\nalso bring new challenges. A core issue is controlling the chat-\nbot‚Äôs behavior, where prompting seems even less reliable than the\nprevious ML-based design approaches [38]. While guidelines for\ndesigning effective prompting exist [ 3, 59], understanding how\nprompts impact the output of LLMs remains an open research area\nin NLP [38, 56]. Particularly, non-AI-experts struggle when design-\ning chatbots, suffering from both the fickleness of the prompting\nmechanisms [76] and misunderstanding the prompting capabilities,\nsuch as overgeneralizing from a single example [77].\nLLM-Chains can make LLM-based chatbots more controllable but\nthey need further evaluation. By chaining independently prompted\nLLM components together, the users feel more in control of the\nsystem [73]. With PromptChainer [72] non-AI-experts can visually\nHedderich et al.\ndesign LLM-Chains, connecting LLM components in a structured\nflow and specifying the functionality of each component with ex-\namples. Participants in the PromptChainer study successfully built\nsuch chains, including those for a chatbot. This promising evidence\nsuggests the utility of this approach for giving teachers control over\nLLM-based chatbots. However, the previous study only considered\na simple music chatbot that processed one step of user interaction.\nWhat is currently missing is an evaluation of complex conversa-\ntions, as one would expect from a dialogue about cyberbullying.\nThe advancements in LLMs might make educational chatbots\nthat help youth learn and practice upstanding skills a reality from\na technical perspective, and LLM-Chains could potentially give\nteachers control over the chatbots so that they could use them in a\nway that fits their individual teaching and curriculum needs. This\nraises the question of how they want to utilize and control the\nchatbots for teaching about cyberbullying, how far LLM-Chains\ncan already fulfill these requirements and what additional levers\nteachers need to make chatbots effective tools in their classroom.\nAnswering these questions is our aim in this work.\n3 METHOD\nThe goal of this study is to understand how teachers want to use\nchatbots for teaching youth to upstand to cyberbullying and to\nidentify what technical and design levers they need to accomplish\nthis task. Our aim is to guide the future development of chatbot tools\nto ensure that they can become implementable in the classroom.\nWith this goal in mind, we developed a chatbot building and\ntesting tool for educational social media settings, which we call\nCo-Pilot. We use this tool as a design probe [7] and conducted a\nuser study incorporating components of think-aloud, contextual\ninquiry and interviews. We chose this approach as our goal was\nto deeply understand the teachers‚Äô needs for instructional chatbot\ndesign, usage, and implementation, as well as to uncover new op-\nportunities through teachers‚Äô perspectives. Given that LLM-based\nchatbots are a recent technique and chatbots in general are a novel\ntool in education, few teachers have experience using them. There-\nfore, we opted for a probe so that the teachers can gain hands-on\nexperience building and interacting with the chatbot. We decided to\nlet the teacher build their own chatbot from scratch as this gives the\nteacher a better understanding of how the chatbot works, remov-\ning some of the blackbox character of AI systems. Providing the\nteachers with more experience with and understanding of chatbots\nhelps us gain deeper insights than conducting interviews about\nonly hypothetical scenarios. Our collected data is a combination\nof observations of participants‚Äô interactions with the probe, their\nself-reported views, as well as opinions elicited through interview\nquestions.\nWe will now give details on the probe (Section 3.1), the user\nstudy (3.2) and the data analysis process (3.3).\n3.1 Designing a Chatbot Building and Testing\nTool as a Probe\nThis subsection presents the design and implementation of the\nprobe, which consists of a chatbot builder and a chatbot tester.\nDesign goals. Three goals are at the foundation of our probe:\n(1) Without prior experience, the teacher should gain an un-\nderstanding of how the chatbot system works and be able\nto shape the chatbot behavior.\n(2) The teacher should be able to evaluate their chatbot, testing\nit with their own assumptions while also being confronted\nwith external inputs.\n(3) The technical burden and workload should be minimized\nfor the teacher so that they can focus on the ideas rather\nthan the process details. This enables us to observe more\nintuitive behavior and open-ended thought processes.\nWith these goals in mind, we designed Co-Pilot to have two\ncore parts that teachers will use:\n(1) Chatbot Builder: The teacher can design a chatbot without\nwriting code or prompts. Instead, they connect graphical\nelements to shape the dialogue flow and provide example\ntexts to define specifics.\n(2) Chatbot Tester: The teacher can take the role of a student\nand interact with the built chatbot on a cyberbullying sce-\nnario on social media. The teacher is also presented with\npossible student answers to the chatbot from different stu-\ndent simulations to assist them with the testing process.\nThe teacher can use those answers instead of their own.\nDesign of the Chatbot Builder.The Chatbot Builder facilitates\nthe creation of chatbots for educational purposes, allowing the\nteacher to operate at two levels of abstraction [75]. Firstly, at the\ndialogue flow level, the Chatbot Builder consists of two types of\ncomponents: a) The student behavior components where the teacher\noutlines the possible behaviors they expect from a student at each\nconversation step. b) The chatbot reaction components where they\nspecify how the chatbot should react to each of these behaviors.\nConnecting these components results in a dialogue tree, like in Fig-\nure 2, which defines the back-and-forth chat conversation between\nchatbot and student. This structure allows the teacher to define\ncontrolled conversation strategies over multiple turns.\nSecondly, is theutterance level. The teachers define example texts\nfor each of the above-introduced components. For a student behav-\nior component, the teacher provides examples of what a student\nwith a specific behavior (like bullying, agreeing, or questioning)\nmight write in this particular situation. For the chatbot reaction\ncomponent, the teacher crafts a set of texts that are exemplary for\nhow they want the chatbot to answer.\nThis two-level design for LLM-chains, as well as the abstrac-\ntion of the prompts, are based on the PromptChainer approach by\nWu et al. [72]. There, predefined LLM components can be visually\nconnected to a chain or tree structure. Their work encompasses\neditable LLM components which include input, transformation,\noutput and branching/classifier components. For our setting, we\nadapted their approach to support multi-turn conversations where\nuser inputs (by future students) occur multiple times. To ease the\nbuilding process for teachers, we also significantly simplified their\ndesign while still being functional for our chatbot use case. We re-\nduced the number of components from eight to the aforementioned\ntwo. We merged their input and classifier components into a single\nstudent behavior component, and our reaction component could\nbe seen as a specialized version of their \"Generic LLM. \" We also\nA Piece of Theatre\nFigure 2: Co-Pilot ChatbotBuilder interface showing the beginning of a dialogue flow for the cyberbullying scenario. Teachers\ndefine the possible behaviors of their students in each situation (green components) and the reaction the chatbot should give\n(yellow components). The teacher specifies example utterances for both types of components (chip elements).\nremoved the tracking of incoming and outgoing texts across com-\nponents, letting the teacher define independent examples. Last but\nnot least, the user interface (UI) design of our components provides\nspecific guidance on the type of input requested from the teacher.\nThe system uses the dialogue flow and utterances that the teacher\ndesigned and converts them into an interactive chatbot. It builds\nprompt-based classifiers based on the student behavior components\nthat identify at each split point of the dialogue tree, given a student\ninput, what path to take. The system uses the chatbot reaction com-\nponents as few-shot examples for a prompt-based text generator\nthat creates the chatbot‚Äôs answer. Note that this process, includ-\ning the specific prompts, is not visible to the teacher so they can\nconcentrate on the chatbot‚Äôs design.\nDesign of the Chatbot Tester. The Chatbot Tester gives the\nteacher the opportunity to test how the chatbot they have built\nwould interact with students by playing the role of a student by-\nstander. We use a social media scenario to guide the conversation\ntoward the cyberbullying setting, as visualized in Figure 1. The by-\nstander is presented with a social media post featuring an exchange\nbetween a victim and a bully, and the bystander can comment\non this post. The chatbot starts the conversation based on the by-\nstander‚Äôs comment on the social media post. It opens a chat window,\nmimicking how the bystander student might receive a personal\nmessage (a ‚ÄúDM‚Äù) on a social media platform. The bystander can\nanswer the chatbot, and the conversation between the chatbot and\nthe bystander unfolds.\nIn our study, the teacher took the perspective of the student\nbystander to test the chatbot. They could write comments on the\nsocial media post, as well as direct answers to the chatbot. Their\ninputs and the chatbot‚Äôs reactions allowed them to examine how\ntheir design would be reflected in the realized chatbot. It also en-\nabled them to test the limits of the chatbot and try out new ideas,\nthus gaining a better understanding of its behavior and possible\nimpact on learning.\nTo enable teachers to experience less strictly designed inter-\nactions, the conversation could continue even after the chatbot\nreached the end of the dialogue flow created by the teacher. When\nHedderich et al.\nthe system reached a leaf component in the dialogue tree, it contin-\nued to respond to further messages. The LLM-based chatbot gener-\nated new responses by taking into account the teacher‚Äôs instructions\ndefined in the last component as well as the new bystander message\ninputs.\nAdditionally, we provided student simulations as an external\ninput to the teacher that might challenge their assumptions. These\nstudent simulations were shown to the teacher as suggested stu-\ndent comments and responses. The teacher could use them instead\nof their own texts. The text suggestions were generated by LLMs,\nwhich were prompted to represent a specific student behavior. In\ncontrast to the chatbot the teacher built, LLM-generated sugges-\ntions did not use any controls from our side. Instead, the LLM\ngenerated a text solely based on a short behavior description and\nthe conversation history thus far. We implemented three student\nbehaviors, namely, a student attacking the bully, a student sup-\nporting the victim (upstander), and a student ignoring the bullying\n(passive bystander). Although we considered using answers created\nby real students during the study design, we opted not to because\npresenting only pre-collected student answers might not match\nthe conversation flow designed by the teacher. Using live student\nresponses would have also been sub-optimal because it would have\nmoved the study‚Äôs focus away from the empirical evaluation of the\nteacher‚Äôs exploration.\nWe aimed to provide a realistic-looking social media scenario\nin both design and content. We based the social media post and\nthe bully‚Äôs comment on the ballet scenario from [ 61] translated\ninto English and using gender-neutral names. Throughout the de-\nsign stage, we consulted with two teenagers and integrated their\nfeedback into the study design.\nCo-Pilot Implementation. We implemented Co-Pilot as a\nReact-based web application with a Python Flask backend and re-\nlied on OpenAI‚ÄôsGPT-3.5 models as LLMs. For the chatbot, we used\nText-Davinci-003, as it mimicked the teachers‚Äô examples more\nclosely without requiring additional prompting in pilot tests. For\nthe student simulations, we used GPT-3.5-Turbo (ChatGPT) for its\nmore adaptive answering behavior. We give further implementation\ndetails in the Supplementary Material. At the time of implemen-\ntation, the more recent GPT-4 and LLaMA2 models were not yet\navailable to us. However, we argue that our approach is generally\nindependent of the latest large language model as we are interested\nin the teacher‚Äôs needs and not the exact system performance.\n3.2 User Study Design.\nTo understand teacher‚Äôs needs concerning chatbots and how they\nwant to use them as tools for teaching teenagers about cyberbully-\ning, we invited 13 teachers to use Co-Pilot and think-aloud.\nParticipants All recruited participants (ùëÅ = 13) had experience\nteaching in middle school. To avoid excluding participants based\non coding or prompting experience, the probe did not require any\ntechnical experience from the participants. Our sample size was\nchosen in line with prior work [22, 57].\nAll participants except P1 had experience in teaching digital\ncitizenship. Our participant pool thus contained teachers who were\ninvested in teaching about bystander interventions and cyberbully-\ning. Cyberbullying and upstanding intervention are taught as part\nof different subjects, like health, technology or digital citizenship.\nParticipants had, therefore, diverse teaching backgrounds and roles.\nTable 1 lists these as well as the teachers‚Äô experience levels. We\nobtained IRB approval before starting the study. All participants\nreceived a $25 voucher for their time.\nTask Participants (teachers) were shown a social media scenario\nfeaturing a case of cyberbullying. They were asked to create a\nchatbot that would engage in one-on-one interactions with students\nwho were exposed to the cyberbullying situation as bystanders. The\ninteraction would be triggered by the bystander‚Äôs comment to the\ncyberbullying social media post, and the teacher‚Äôs task was to create\na chatbot who would initiate and carry on the conversation with\nthe student (bystander). We asked the teachers to design the student\nbehavior components according to how they would expect their\nstudents to behave. They were free to specify how the chatbot\nshould react in each situation and how long the dialogue flow\nshould be.\nAfter building the chatbot, we asked the participants to test it,\ntaking the student‚Äôs bystander perspective. Participants had full\nrange in exploring how the chatbot reacts. They could input their\nown comments on the social media post and their own answers to\nthe chatbot. Alternatively, they could use the suggested texts by the\nstudent simulations or a mixture of both. Participants could switch\nfreely between the student simulations and reset the conversation\nat any time to the start point. Participants had the option to go back\nto the Chatbot Builder and modify their chatbot if they desired.\nInterview Protocol The interview started with the participant\npresenting their teaching background and how they teach their\nstudents about cyberbullying.\nWe then gave the participant an introduction to Co-Pilot. To\navoid biasing the participants with a pre-existing chatbot design\non cyberbullying, the topic of the introduction was on fake news, a\ndifferent digital citizenship topic. Each participant was first shown\nthe social media scenario for fake news (i.e., the Chatbot Tester) fol-\nlowed by an exemplary chatbot design within the Chatbot Builder,\nhighlighting the two levels of abstraction (dialogue flow and utter-\nances).\nWe then asked the participant to build their chatbot. The inter-\nviewer showed the participant an example of a social media post\nfor cyberbullying and suggested starting with defining possible\nbehaviors they would expect from their students in this situation\nand how the chatbot should react. The participant was then given\ncomplete control of Co-Pilot and asked to think out loud while\nbuilding the chatbot. The interviewer further advised participants\nonly when they asked for assistance. The advice was limited to\nhelping with UI questions (such as how to move components on\nthe screen) and the suggestion to use their teaching experience for\ndesigning the chatbot.\nOnce the participant indicated that they had finished building\nthe chatbot (or after 45 minutes had expired since the start), the\ninterviewer suggested switching to the Chatbot Tester. Again, the\nparticipant had the freedom to explore and was asked to comment\non their testing. The testing continued until the participant indi-\ncated that they had finished (or after the 60-minute interview mark\nwas reached).\nA Piece of Theatre\nTable 1: Interview Participants. All participants had experience teaching in middle school. Depending on the school, cyberbul-\nlying was covered in different subjects, like technology, health or digital citizenship. ICT facilitators were teachers who also\ntaught other teachers about digital citizenship methods and coordinated corresponding programs.\nID Role Current Class on\nCyberbullying\nYears\nTeaching Region\nP1 Teacher N/A >30 US\nP2 Teacher Info Technology >10 US\nP3 Teacher Health >10 Canada\nP4 Teacher STEM Program >5 US\nP5 ICT Facilitator Digital Citizenship >5 US\nP6 ICT Facilitator Digital Citizenship >5 US\nP7 Head ICT Facilitator Digital Citizenship >10 Southeast Asia\nP8 Teacher Computer Science >20 US\nP9 Teacher Health >10 US\nP10 Teacher Leadership Character >10 US\nP11 Librarian Technology >30 US\nP12 Teacher Digital Citizenship >10 US\nP13 Head ICT Facilitator Digital Citizenship >5 US\nWe informed the participants that the session‚Äôs goal was to un-\nderstand how to teach teenagers about upstanding to cyberbullying\nand if or how chatbots could potentially play a role there. We clari-\nfied that the probe was an early prototype and we emphasized our\ninterest in receiving their honest opinions. During the session, we\nobserved how the participants used and explored theCo-Pilot and\nrecorded their comments. When the participants mentioned aspects\nrelevant to the research question during their thinking-aloud pro-\ncess, the interviewer asked them to elaborate. These elaborations\nconstituted the most significant part of the collected interview data.\nAfter the exploration phase with the Co-Pilot, the interviewer\nasked the participant a set of questions if these had not been ad-\ndressed by the participant already. Specifically, we asked i) if or\nhow they would use a chatbot in their class when teaching about\ncyberbullying, ii) if or how they would like to build or customize\na chatbot for cyberbullying, and iii) if they could wish for new\nfunctionality or support, what would that be.\nWe performed the user study remotely over Zoom. The Co-\nPilot was hosted on a server so participants could access it on their\nbrowser during the interview. For two participants whose schools‚Äô\nfirewall blocked access to our probe website, the interviewer shared\ntheir screen, and the participant gave them instructions on what to\ndo during the building and testing of the chatbot.\n3.3 Data Analysis\nWe recorded and transcribed the user study. For each participant,\ntwo authors independently reviewed the transcript and distilled\nimportant insights from it. The union of these emergent insights\nwas used to create affinity diagrams to synthesize and organize\nobservations across the interviews. The inspection and labeling of\naffinity diagrams, which were discussed with all authors, revealed\nkey themes and patterns. Their contents were further analyzed to\ncategorize and prioritize the themes, as well as to merge or remove\noverlapping clusters. After finalizing the diagrams, two authors\nindependently verified all findings against the original transcripts\nand found no discrepancies.\nWe chose affinity diagrams instead of grounded theory for sev-\neral reasons. This method is often used in HCI and interaction\ndesign practice [ 27, 40]. Furthermore, our objective was not to\nbuild up a theoretical account of how teachers designed chatbots\nwith existing tools. Instead, we followed a more practice-based ap-\nproach to inform the design and application of new resources and\ntools by directly engaging teachers in the chatbot building and test-\ning. The observations, combined with interview insights, revealed\nteachers‚Äô preferences for the design and deployment of chatbots\nas an instructional tool for teaching bystander intervention in the\nclassroom.\n4 FINDINGS\nIn line with previous work, our interviews showed the potential\nof chatbots in scaling up personalized and interactive teaching of\nbystander intervention. P11 described bystanders as individuals\nthat \"just sit and watch, \" emphasizing that many \"really want to\nsay something, but just stand there. \" The introduction of chatbots\nchallenges this passive tendency often exhibited in cyberbullying\ncases, urging students to take on a more proactive role.\nOne of the key advantages of chatbots over traditional teaching\nmethods is the capacity to deliver immediate and individualized\nfeedback. This quality distinguishes chatbots from conventional\nlessons, where several participants reported difficulties in address-\ning the needs of every student due to time constraints and class size.\nP2 praised the impact of this feature, stating \"I don‚Äôt think it‚Äôs going\nto have the same effect if I wait until tomorrow to [correct] them or\nafter I grade a paper. [The chatbot] keeps those wheels turning. \"\nA teacher‚Äôs task, however, is not purely instructional, with P8,\ne.g., describing her role ‚Äúnot [as] a knowledge-giver but a moderator. \"\nThis sentiment is reflected in the teachers‚Äô needs for the chatbots as\nwell. Our findings from teachers building and testing chatbots with\nCo-Pilot reveal that they did not perceive their goal as prescribing\nHedderich et al.\na conversation that the student would loyally carry out with the\nbot. Rather, we found that\n(1) teachers wanted to design chatbots that are part of multi-\nparticipant role-plays that enable students to take on dif-\nferent perspectives, and\n(2) by allowing the chatbot to improvise within the limits of\nthe teacher‚Äôs guidance, teachers wanted to create scenarios\nwhere students can explore and practice socio-emotional\nskills in a safe environment.\nWe unite these needs under the larger theme of teachers wanting\nto be playwrights: the teacher‚Äôs role resembles a modern playwright\nin that they develop characters, and create role-play scenarios or\nplots that align with the (educational) goals. The actors (learners)\nare allowed to rehearse and improvise within the framework of\ntheir characters to deepen their understanding of the impact of\ntheir role‚Äôs actions.\nIn Section 4.1, we unpack the teachers‚Äô perspectives on using\nchatbots for teaching about bystander interventions to cyberbul-\nlying and the goals they want to achieve. Section 4.2 describes\nhow existing LLM-Chains support these goals, while Section 4.3\nuncovers needs that are not yet met and what additional levers the\nteachers require.\n4.1 The Teacher as a Playwright\nThis section details the teachers‚Äô needs with regard to using chat-\nbots for bystander intervention education.\nLearning Socio-Emotional Skills Teachers are not merely in-\nterested in instructing intervention steps; instead, they aspire to\ncultivate socio-emotional skills within their students in order to bet-\nter navigate cyberbullying situations. P8 described current teaching\nof social media education as ‚Äúhand slapping lesson ‚Äù just focusing on\nteaching students prescriptive rules. P6 identified the importance of\nmoving beyond this form of teaching, stating that students needed\nto first understand the underlying issues and the harm caused by\ncyberbullying before teachers could address student interventions.\nA more holistic approach aims to guide students in develop-\ning broader skills, such as perspective-taking and empathy, and\napproach intricate nuances of such situations with sensitivity. P1\noffered insight into this perspective, noting that social situations\ninvolving cyberbullying are complex and multifaceted as ‚Äúnot 100\npercent [of blame should] be placed on one person only. [...] There are\nat least factors from all parties that lead to this situation. ‚Äù Similarly,\nP11 highlighted the importance of instilling empathy amongst stu-\ndents, stating that ‚Äúeveryone today really needs to understand where\nthe other person is coming from and have some empathy for others. ‚Äù\nLearning Through Multi-Participant Role-PlayTo help stu-\ndents understand the perspectives of the various stakeholders in-\nvolved in cyberbullying situations, many participants suggested\ninvolving multiple chatbots and the student in a role-play scenario.\nThe teachers saw their task in preparing these scenarios and in\ndefining the different roles, including the bully, victim, and by-\nstanders. The chatbots and the student would then play their roles\nby commenting and messaging on the social media scenario.\nThis role-playing approach offers a unique opportunity for stu-\ndents to grasp the impact of their actions in an empathetic manner.\nAs P5 pointed out, ‚ÄúUsually, you just ask [students] to reflect on\nit and pose some questions and ask them well, how did this make\nsomeone so feel? [...] [Role-play] would be a quicker way for them\nto grasp the impact of their actions on someone else. ‚Äù P11 echoed\nthis sentiment, highlighting that this approach enables students\nto empathize with various roles, including that of the victim, the\nbystander, and even the bully, stating,‚ÄúThis is giving someone a way\nof stepping in someone else‚Äôs shoes in social media. \"\nIn contrast to traditional classroom role-plays, chatbots provide\na safe space for role-playing without the fear of judgment. P13\nhighlighted that this chatbot ‚Äúallows kids to do things that they\nmay not feel comfortable with in front of a whole group. ‚Äù Likewise,\nP10 pointed out that in their previous experience, students often\nfelt compelled to clarify that their assigned role-play behavior did\nnot necessarily reflect their real-life actions. Similarly, P11 saw the\nchatbot as an avenue for students to explore ‚Äúwhat ifs‚Äù in a private\nsetting.\nCatalyzing Learning Through Repetition, Exploration &\nGuided Improvisation Many participants wanted the chatbot to\nempower students to practice and make corrections in a safe space,\nproviding a learning experience they could fall back on while navi-\ngating the world around them. For that, they wanted the chatbot to\nimprovise on their instructions so that students could extensively\nexplore challenging cyberbullying situations and try out different\nroles.\nThe chatbot gives students a platform to explore different behav-\niors in a safe environment. P8 and P11 acknowledged the impor-\ntance of making mistakes and learning from them, mirroring the\ndevelopmental stage and learning style of middle school students.\nSimilarly, P11 recognized the impulsive nature of middle school\nstudents who are still learning how to express themselves. She saw\nthe chatbot as an opportunity for the student to ‚Äú write inappro-\npriate things [to] see what the chatbot responds [...] to do what they\nmight be impulsive to do. ‚Äù P3 even expressed a desire to encour-\nage this and for students to experiment with different behaviors,\nboth ‚Äúconfrontationally‚Äù and ‚Äúnicely, ‚Äùto observe how the chatbot\nresponds. P9 saw the chatbot interaction also as an opportunity for\nthe student to vent in a cathartic fashion. The teachers emphasized\nthat the chatbot provides a safe environment for exploration, with\nP8 stating ‚ÄúWe‚Äôre learning; we‚Äôre supposed to make mistakes. And\n[students] have a safe environment here. ‚Äù\nP6 and P8 believed that students should also encounter situations\nthat can go awry. For instance, P6 envisioned a scenario where a\nstudent exhibits the desired upstanding behavior as taught in school,\nhowever, the bully persists. P6 elaborated stating, ‚ÄúMaybe the co-\npilot creates fake responses to continue the bullying [...] to help kids\nrealize [...] sometimes it doesn‚Äôt go smoothly. Sometimes you can say\nstop, and [bullies] don‚Äôt always stop. And I think getting the kids to\nrealize that and [...] help them realize that your first attempt may not\nalways pan out and help them practice that. ‚Äù This approach aims to\nprepare students for real-life conflicts, in which their actions may\nnot yield straightforward or predictable outcomes.\nThe teachers stressed the importance of repetition within this\nexploration and the need for the chatbot to improvise within their\nguidelines to support the student‚Äôs practice. P9 highlighted the\nvalue of having the chatbot reiterate statements using different\nphrasing. This approach is particularly beneficial because, as P9\nA Piece of Theatre\npointed out, the students in that age group best absorb information\nthrough repeated exposure. P4 and P13 also stated that they want\nstudents to repeatedly try again, with P4 saying that they want to\ndesign the chatbot in order to ‚Äúhave [students] try over and over\nagain, to recognize, what is [the students‚Äô] responsibility here‚Äù .\nThe value of this approach is further underscored by P10, point-\ning out that compared to traditional teaching methods, the ‚Äúhands-\non‚Äù role-play approach is‚Äúno longer memorization. . . [and is] becom-\ning muscle memory. ‚Äù This experiential learning allows students to\ntransform their conceptual understanding into practical, real-world\napplications.\nAdapting the ChatbotTo align the chatbot with specific aspects\nof their school, address unique situations in their class, and match\ntheir own teaching style, teachers emphasized the importance of\ncustomizing the chatbots.\nParticipants wanted the chatbot to be reflective of their school\nand class. P5 and P9 both remarked that when they were teaching\nthese topics, they adapted their scenarios to specific situations that\nhappened to their students in real life to make the experience more\nengaging and realistic. P6 and P11 wanted to integrate references\nto personnel at their school so that their students could get advice\ntailored to them and have a more personalized experience. P8 noted\nthe need to adapt to differing terminology between schools. P11\nadditionally referenced their school‚Äôs foundational principles, while\nP7 wanted the chatbot to provide links to additional resources.\nP2 noted that the chatbot‚Äôs language should align with that of\nthe students. A similar viewpoint was shared by P8, who empha-\nsized the importance of adapting the wording to match the way\nstudents speak, considering the fast-evolving nature of their slang\nand its unique local forms. P9 argued that this representation of\nthe students‚Äô language is important to increase engagement.\nTeachers emphasized that it is not merely about having a stan-\ndalone chatbot; it needs to be an integral part of their teaching\napproach and match their personal teaching style. P9 underlined\nthe individuality of teaching styles. They state that ‚ÄúEvery teacher\nhas a different style in the classroom, ‚Äù therefore, it is important to\nallow teachers to tailor the chatbot to align with their unique teach-\ning styles. P9 described their own gentle approach to redirection\nwhere, e.g., P11 noted the need to send clear stop signals in cer-\ntain situations, and P8 remarked that they usually added material\nbeyond the standardized curriculum to push their students further.\n4.2 Existing Levers: LLM-Chains For Teachers\nas Playwrights\nUnderstanding the teachers‚Äô perspective as playwrights helps to\nevaluate to what extent LLM-Chains can empower teachers to build\nchatbots that are useful teaching aids to them. We find that the\nLLM-Chains ability to adapt based on few examples while being\ncontrolled with the chain-structure and the flexibility of LLMs to\nreformulate answers are useful levers to the teachers.\nAdapting the ChatbotTeachers wanted to adapt the chatbot to\ntheir school, and this custom adaptation was made possible by the\nLLM-Chains. P11 added, e.g., a specific reference to their principal\nnaming him in the example answers of the chatbot. This allowed\nthe chatbot to refer to the principal during the bystander chat.\nThe teachers also used the LLM-Chains to integrate their own\nteaching style. P6, e.g., wanted the chatbot to acknowledge positive\nstudent behavior and redirect student actions if they encouraged\ncyberbullying. When testing the chatbot they had built, they com-\nmented: ‚ÄúI‚Äôm pretty happy with the way this chat is going, especially\nconsidering how little I put on the chatbot side. ‚Äù P11 also expressed\nthat it accurately conveyed what they intended to communicate\nand, likewise, P8 saw how the chatbot mirrored and reflected ‚Äúthe\nsame tone but in different words. ‚Äù P8 continued stating, ‚Äú It really\nreflects [me]. That‚Äôs really amazing. Even in those few examples ‚Äì\nwow.‚Äù\nP8 advocated for this level of customization, commenting on the\nresult: ‚ÄúI care about the kids, and I want them to know that. [The\nchatbot builder] can help take what makes me special as a teacher\nand put it into a tool like this‚Äù .\nCatalyzing Learning Through RepetitionTeachers highlighted\nthe importance of repetition when students are learning about\nbystander interventions to cyberbullying. The LLM-Chains allowed\nthe teachers to define chatbots that could reformulate their example\nanswers. The students would then be presented every time with\nnew answers that still followed the teacher‚Äôs guidance.\nWhen testing the chatbot, teachers remarked positively about\nthe chatbot‚Äôs rephrasing. P7 stated that having ‚Äúalways the same\nquestions, the same answers [is] boring ‚Äù and that the chatbot was use-\nful because it answered in different ways, rephrasing the teacher‚Äôs\nmessage that one should be more respectful and caring. P8 com-\nmented that the chatbot ‚Äúdoesn‚Äôt sound like a machine ‚Äù and that it\ncorrectly rephrased their examples. P9 was surprised by the chat-\nbot‚Äôs ability to answer the student in repeated and rephrased form\nand expressed that ‚Äúevery one of those responses is awesome for [the\nstudents] to hear. ‚Äù They expanded on this point stating, ‚Äú[The chat-\nbot] is good, because every one of these responses is different [and the\nstudents are] going to read every one of those. \" .\n4.3 New Levers Needed By Teachers as\nPlaywrights\nWhile LLM-Chains provide some of the functionality to enable\nteachers to become successful playwrights, our participants also\nreached the limitations of this approach in several aspects, which\nsuggests the need for new levers discussed in Section 5.\nLevers That Support PlaywritingAs a playwright, the teacher\nis tasked with narrating the behavior of students and chatbots.\nAmong the participants in the study, there was a noticeable varia-\ntion in their ability to generate examples of their behaviors. Some\nparticipants found the process of designing student behaviors and\nchatbot responses to be relatively easy and intuitive. P6, in particu-\nlar, demonstrated a swift ability to generate responses, stating that\nthe reason is \"lots of experience working with kids and teaching, and\nnavigating social media\" .\nHowever, some participants faced significant challenges. P2, P8\nand P13 indicated signs of struggling when trying to verbalize exam-\nples for the student behavior components. P10 found it particularly\ndifficult to adopt the mindset of a middle school student, stating,\n‚ÄúPutting yourself in the middle school age, I think makes it a little\ndifficult because as an adult, obviously, my brain is going to work\ndifferently.‚Äù P12 similarly noted that they need to get back into\nHedderich et al.\nthe mind of their students. Meanwhile, P3 and P6 found it difficult\nto identify all possible student behaviors, with the latter stating:\n‚ÄúSo the student joins the bullying, ignores the bullying [...] I feel like\nthere‚Äôs one more option. ‚Äù\nIn selected cases, the struggle of comprehensively describing the\nstudent behaviors was also reflected during the testing phase. For\nP3, the passive bystander behavior of one of the student simulations\ndid not match any of the behaviors they had defined, resulting in the\nchatbot being unable to respond appropriately. Seeing the chatbot‚Äôs\nreaction to the student simulation, they realized what they had\nmissed, commenting ‚ÄúOh, why didn‚Äôt I think of that? ‚Äù\nThe teachers know what socio-emotional skills they want to\nconvey to their students with the chatbot, but they struggle with\ncreating a script for the parts of middle schoolers. Many of them\nwould benefit from supplementary support to address the challenge\nof accommodating students with diverse behaviors.\nAn LLM could be used as a lever to provide writing support\nwhen building the chatbot. P8 requested a resource where they\ncould pull examples from, while P2, P3 and P12 wanted sugges-\ntions automatically provided while they built the chatbot. With\nthe right prompting, the LLM could propose student behaviors or\nutterances for each situation. The teacher could get inspired by\nthese suggestions for their own writing or use them directly if they\nagree with them. P2 commented on the LLM output during testing\nthat ‚ÄúSomebody else [the LLM] is way more creative with our words\nthan me. ‚Äù This suggests that an LLM-based writing assistant could\nassist teachers with the script-writing process.\nBesides collaborating with an AI, teachers also want to work\ntogether with their colleagues. Cooperation among teachers in the\ncontext of curricula is familiar to them, as highlighted by P5. In their\nschool, a common planning time exists to plan lessons together,\ndistribute tasks, obtain feedback, and share results. They expressed\nthe desire for a similar collaboration in chatbot design. P2 also\nwanted to collaboratively develop the chatbot with fellow teachers,\nwhile P6, P8 and P12 emphasized the sharing of chatbots with other\nteachers.\nSuch collaboration is not limited to only teachers but could also\ninvolve students. P11 stated that the students already contributed\nto the teaching process by sharing their own cyberbullying experi-\nences, and P10 emphasized that this allows them ‚Äúkeeping a pulse of\nwhat‚Äôs going on in our school. ‚Äù P8 argued that the students‚Äô input is\nespecially valuable as social media is not P8‚Äôs world. They all, along\nwith P7 and P12, wanted to leverage students‚Äô experience and in-\nsights by involving their students as feedback-givers or co-writers\nof the chatbot.\nNew levers that support the teacher in playwrighting could thus\nbe either of technical nature, benefiting from LLM suggestions, or\ntransfer collaborative structures already existing at schools into the\nchatbot-building process.\nLevers to Guide Chatbot ImprovisationThe teachers also wanted\nthe chatbot to improvise so students could explore different behav-\niors in-depth. Rather than strictly adhering to scripted responses,\nthe LLM-Chains could create a chatbot guided by the examples pro-\nvided by teachers while having a degree of improvisation built-in\nin its interactions.\nSeveral teachers commented positively on the chatbot taking\nthese liberties. P6 stated, ‚ÄúThey‚Äôre good responses. Especially because\nthere are so many answers the student could give [...] I think it‚Äôs\ngood that the chatbot is able to take over and recognize the different\nresponses and continue having that discussion [...] without me needing\nto pre-program everything into it. ‚Äù P7 and P9 were surprised by the\ndepth of the chatbot‚Äôs follow-ups.\nSome participants also encountered, however, limitations in the\nchatbot‚Äôs ability to improvise. If the student continued the conver-\nsation beyond the last component defined by the teacher in the flow\nof the LLM-Chain, our probe proceeded to use the last teacher‚Äôs\ninstruction as guidance. For P8 and P9, this process resulted in the\nchatbot ending up in a conversational loop, always rephrasing the\nsame type of answer. The teachers asked for an option to define\nwhen the chatbot should switch to a new conversational topic in\nsuch a situation. They suggested that the switch should occur once\nthe student shows understanding of the chatbot‚Äôs message or after\na predefined number of repetitions.\nP6 also emphasized the importance of the chatbot adhering to\nthe predefined guidelines, expressing concerns that the chatbot\nmight deviate too much from the intended educational path: ‚Äú I\nwould worry that the chatbot started agreeing with the [bullying]\nstudent [...] or started veering in the wrong direction and [I would]\njust make sure that it stays positive. ‚Äù\nWhile LLM-Chains are a lever that gives teachers control over\nthe chatbot, the guidance the teachers provide is bound to the\ndialogue flow structure. The chatbot can improvise within this\nstructure but struggles to go beyond it. The LLM-Chains can give\nthe teacher fine-grained controls, but new levers are needed so that\nteachers can better guide the improvisation more abstractly. These\nnew levers should allow teachers to define higher-level chatbot\nbehaviors, such as when to move to a new conversational topic. At\nthe same time, these new levers still need to let teachers enforce\ntheir guidelines, ensuring that the playwright stays in control.\nLevers That Enable Multi-Participant Role-PlayFurthermore,\nteachers want to design role-plays with multiple participants. Sup-\nporting such interactions adds a new dimension to the chatbot\ndesign. Chatbot interactions are usually 1:1 conversations between\na user and a chatbot. However, teachers were interested in having\ntheir students explore social situations that simulate interactions\nof multiple participants, including the victim, the bully, and other\nbystanders. This requires multiple chatbot participants interacting\nwith each other and the student.\nWhile teachers could use separate LLM-Chains to build differ-\nent conversation participants, the chatbots must be aware of the\nother participants, their roles in the social environment, and their\nactions. This will require connecting the chatbots and updating\ntheir information about each other and the student while the con-\nversation progresses. New technical levers are needed to support\nsuch interactions.\nMulti-participant role-plays are also a design challenge. In our\nprobe, teachers only needed to conceptualize the possible actions of\na student and how their chatbot should react to each of them. Even\nthen, P12 explained how they preferred to map out such branching\nsystems first on paper. Adding multiple active roles to the scenario\nwould require the teacher to define how each chatbot should react\nA Piece of Theatre\nto the other chatbots and the possible student behaviors. Some\nroles might also change their behavior over time (e.g., a passive\nbystander becoming an upstander) and might, therefore, also adapt\ntheir interactions with the other participants. Building chatbots\nadept at navigating an increasingly spiraling complexity of multi-\nrole conversations would burden the playwriting teacher. Therefore,\nnew design levers are necessary that will enable teachers to guide\nchatbots in such multi-participant role-plays.\n5 DISCUSSION\nIn this section, we will first discuss our findings on teaching by-\nstander interventions to cyberbullying through role-playing with\nchatbots. While teachers see their role in this context as playwrights,\nour findings showed that new levers are necessary to enable teach-\ners to succeed in this role. In the following subsections, we will\ndiscuss the design and system opportunities ensuing from these\nfindings, as well as outline future research directions to address ex-\nisting research gaps in the instructional use of chatbots for teaching\nprosocial behaviors to adolescents.\n5.1 Teaching Prosocial Behaviors With Chatbots\nIn line with previous research, our findings show that teachers\nwant to provide personalized ways to teach bystander intervention\nand that chatbots have the potential to provide such teaching at\nscale. We also show, however, that the teachers want to go beyond\nproviding an interactive way to learn about conversational guidance\nlike STAC. Instead, they want to build chatbot-based role-play\nscenarios where students can actively explore bystander behavior.\nWhile chatbots have been previously explored as effective in-\nstructional tools for enabling role-playing for situated, authentic,\nand safe learning in dialogic-centric settings [ 46], our findings\nprovide unique insights into teachers‚Äô role as playwrights in a role-\nplaying learning process. When teachers are playwrights, chatbots\ncan be effective classroom aids and resources, assisting teachers in\ntraining students in prosocial behaviors necessary for upstanding\nagainst cyberbullying and confronting other digital risks. The teach-\ners in our study, by and large, embraced the role of playwrights,\nviewing student-chatbot role-play as an effective tool for students\nto learn and practice perspective-taking, empathy, and nuanced\nconsideration of their own and others‚Äô actions necessary for by-\nstander interventions to cyberbullying. What emerged from our\nfindings is the collaborative role-playing orchestrated by the teach-\ners but leaving room for student improvisation and experimentation\nin a safe conversational space. Through conversational planning\nand regulation, a teacher can create scripts that allow students to\npractice upstanding behaviors and other prosocial communication\nstrategies in a realistic conversational exchange. Furthermore, the\nplaywright role allows teachers to customize the learning process\nand learning outcomes to satisfy current and emergent student\nneeds and connect role-playing to the curriculum goals and the rest\nof the school experience.\nInstead of structuring the student training mechanistically by\ngiving students \"recipes\" for how to act as an upstander, the teach-\ners emphasized the importance of developing contextual and so-\ncial awareness so youth can read a cyberbullying situation in a\ncontextually-sensitive way and respond with appropriate communi-\ncation strategies. Their guidance went beyond the prescriptive chain\nof actions outlined in the bystander intervention model [13, 35] (i.e.,\nnotice an emergency, recognize it as such, take responsibility, know\nhow to intervene, and act). Instead, teachers used scripts as oppor-\ntunities to help youth develop communication and socio-emotional\nskills, such as social awareness [54], which can be seen as overarch-\ning competencies instrumental for each stage of the bystander inter-\nvention process. In this respect, the approach taken by the teachers\nin our study was more consistent with the situational-cognitive\nmodel of adolescent bystander behavior [ 10], which emphasizes\nthe embeddedness of a cyberbullying episode within social and\npeer contexts, and the entanglement of bystanders‚Äô actions with\ninterpersonal relationships, social group affinities, status hierar-\nchy, and community climate. As a result of these entanglements,\nbystanders experience high uncertainty about which options are\nsocially appropriate and safe and have to contend with possible\nfallout from intervening. To overcome this uncertainty, bystander\ntheorists recommend \"the need for skill practice across a range\nof scenarios, using a variety of possible bystander responses\" [10,\np. 18]. Chatbot roleplaying enables this multifaceted practice rec-\nommended by theorists, and the teachers‚Äô scriptwriting approach\nguided by their practical experience working with adolescents was\nwell-aligned with this recommendation.\nBelow, we discuss the opportunities that LLM-Chains offer to the\ndesign of teacher-built chatbots and identify crucial pedagogical\nand technological research gaps.\n5.2 LLMs Supporting Teachers in Playwriting\nAlthough teachers viewed their role as playwrights, writing the\n‚Äúscript\" that prompts youth interventions to cyberbullying can be dif-\nficult and might require help that LLMs could provide. We identified\nthat writing in the style of students and anticipating their possi-\nble behaviors can be a challenge for teachers, and some of them\nrequested additional support. For the writing style, researchers\nhave shown that LLMs can adopt different text styles, including\nslang and chatty forms [ 53, 60]. To help teachers define various\npossible behaviors that reflect students‚Äô uncertainty and hesitation\naround bystander interventions, they could utilize LLM suggestions.\nH√§m√§l√§inen et al. [26] used LLMs for generating synthetic user data.\nAn LLM system might similarly be able to generate behavioral data\nfor student exchanges, suggesting student reactions to the teacher.\nThe teacher could then validate these synthetic data according to\ntheir experience, quickening the chatbot creation process and filling\ngaps the teacher might have missed.\nOne needs to be, however, keenly aware of LLMs‚Äô limitations and\nthe biases they can introduce. Language models reflect the textual\ndata they are trained on and thus only represent the pool of existing\ndata. Depending on the training timepoint, it is unclear if they can\nkeep up with rapid-moving trends of teenagers, for example, with\nteenage slang, pop culture shifts, and social media interactions.\nWhen considering subjective opinions, researchers have already\nshown that LLMs are biased towards specific ideologies [ 23, 44]\nand populations [21, 67]. It is thus essential to understand if LLM\nsuggestions for teachers can support them in building chatbots with\nHedderich et al.\na broader student representation or if the LLM causes the opposite,\nbiasing and narrowing their design.\nFurthermore, while LLM suggestions may reflect a broader stu-\ndent representation, further adaptation may be needed to reflect\nspecific geographical, socio-cultural, developmental, and other sub-\ngroup identities of students in a particular classroom. Teachers\nmay even consider running chatbot suggestions by student helpers\nto ascertain their relevance, typicality, and realism. In this case,\nscriptwriting would become a collaborative process, with teachers\norchestrating the script, but LLM and student helpers supplying\nand reforming textual data, as we discuss in more detail next.\n5.3 Collaborative Chatbot Design With\nTeachers And Students\nCollaboratively designing the chatbot could result in learning tools\nthat are pedagogically more inclusive and effective. Recognizing\nthe benefits of human-centered design, researchers have been ar-\nguing for the inclusion of learners and teachers in the design pro-\ncess of learning tools that are pedagogically inclusive and effec-\ntive [19, 20, 32, 34, 68]. Our findings reflected these arguments\nshowing that teachers value the input from other teachers as well\nas from their students. They repeatedly voiced their wish to seek\nout their colleagues and students when building the chatbot. Sys-\ntems that support collaborative workflows where teachers can ask\nfor feedback or share their work could support the adoption of\neducational chatbots as shared tools in the classroom.\nA promising solution might be to use collaborative exercises\nwith a teacher and their students working together to create a\nchatbot-based role-play. This kind of collaborative storytelling has\nbeen previously used in creating stories for role-playing games\nin classroom spaces [29]. Like choose-your-own-adventure books,\nparticipants can narrate different action possibilities depending on\nthe story characters‚Äô steps. Furthermore, students‚Äô involvement in\nthis process can also serve as an exercise in perspective-taking,\ncritical reflection, and engagement skills [12]. Critically, bringing\nin student voices and perspectives will ensure that the actions and\ncontexts created through collaborative storytelling will accommo-\ndate the actual concerns and experiences of youth involved in the\nprocess, which is critical for fostering engagement and adoption.\n5.4 Teachers Guiding Chatbot Improvisation\nTeachers seek chatbot improvisation while maintaining control.\nWhile previous work showed that LLM-Chains offer some control to\nnon-AI-experts [72], our findings revealed their shortcomings when\ndesigning chatbots for cyberbullying education. Overcoming these\nlimitations will require addressing them from multiple directions.\nOn the individual response level, such as when dealing with a\nspecific chatbot reply, there are existing LLM techniques that can\naid in controlling the generated text. One such technique involves\nadjusting the \"temperature\" parameter of an LLM, which serves\nas a rudimentary yet established means to regulate the variability\nof the generated text. A higher temperature value results in more\n\"creative\" output. One can also restrict text generation to predefined\nuser concepts [62]. This could ensure that the chatbot improvises\nfreely while remaining within a positive context, like P6 requested.\nIncorporating control codes can further facilitate the enforcement\nof specific text generation patterns [30]. While these approaches\nhave been evaluated from an NLP perspective, future work must\naddress their integration into the chatbot design process.\nWhen it comes to shaping the flow of a conversation, various ap-\nproaches are available. Prior research has indicated that prompting\ncan guide a conversation to some extent, but it remains challenging\nto provide precise guidance, especially for non-AI-experts [76, 77].\nOur findings showed that LLM-Chains with predefined dialogue\nflows grant teachers more detailed control, albeit limiting the guid-\nance on a more abstract level. For instance, our participants could\nnot specify that a chatbot should dwell on a topic for a certain dura-\ntion before transitioning to a new subject, all while considering the\nstudent‚Äôs behavior. It is an open question how a system should be\ndesigned to enable teachers to steer the chatbot while preserving\nits capacity for improvisation within predefined guidelines.\nThe concept of guided improvisation also raises the broader\nquestion of how much control teachers are willing to relinquish\nin favor of encouraging improvisation. Our study demonstrated\nthat current tools empower teachers to construct chatbots that can\nimprovise, and teachers expressed a desire for variability in the\nchatbot‚Äôs responses to catalyze educational outcomes. However, it\nis essential to recognize that granting the chatbot more flexibility\nincreases the risk of unintended behavior. This issue is particularly\nrelevant when teaching sensitive subjects like bystander interven-\ntions to cyberbullying. Further research is necessary to understand\nwhere teachers should draw the line between improvisation and\ncontrol.\nBesides the additional \"levers\" needed in LLMs to achieve more\ncontrolled improvisation, additional pedagogical solutions should\nbe considered to address LLMs‚Äô limitations and ensure students‚Äô\nemotional well-being while handling sensitive topics like cyber-\nbullying: 1) Scaffolding: guiding students on how to interact with\nthe chatbot, offering hints or prompts when needed, and providing\nframeworks or structures to prevent the conversations from going\nawry. 2) Monitoring: observing how students engage with the chat-\nbot, making sure the language being used is age-appropriate and\naligns with teens‚Äô emotional and cognitive development stages. 3)\nDebriefing: conducting debriefing sessions to help students process\nwhat they have learned, discuss their experiences, and address the\nemotional and psychological impacts of the chatbot intervention.\n5.5 Multi-Participant Role-Play with Chatbots\nWhile the concept of multi-player improvisation theatre has been\nexplored in role-playing games [29], the guided improvisation could\nopen up room for multi-participant role-play where one or multiple\nstudents could interact with a single or multiple chatbots playing\ndifferent roles. This kind of rich environment with multi-participant\ninteractions and interpretations would resemble interactions on\nsocial media platforms where cyberbullying exchanges are played\nout in front of other users who can attenuate (e.g., by supporting a\nvictim) or amplify (e.g., by staying silent or resharing an offensive\nmessage) the effects of cyberbullying through their actions [ 17].\nBlending real participants and imagined identities enacted by chat-\nbots could help youth practice socio-emotional skills in various\nrelational and situational contexts, e.g., involving social circles of\nA Piece of Theatre\nfriends and peers, being part of a group or a sole upstander, in-\nteracting with people of similar or diverse views and identities,\netc. As mentioned earlier, bystanders‚Äô sense-making, reading of\ncontextual cues, emotional reactions, and anticipated consequences\nof their actions are tethered to social and peer contexts in which\nthey reside [10], and multi-participant interactions could provide\nopportunities for collaborative role-playing practices and learning.\nFrom a technical standpoint, LLMs have been used to stage social\nsimulacra [47, 48]. These social interactions of multiple participants\nare reminiscent of the role-play scenarios our teachers envisioned.\nLLM-based social simulacra could, therefore, be an opportunity for\nbringing teachers‚Äô role-play ideas to life. It is, however, still an open\nquestion how teachers can keep control of the simulations and how\nthe students can interact with the simulated roles.\nFrom the instructional perspective, chatbot role-playing sessions\nwith multiple student participants would need to be carefully im-\nplemented and build on skills previously practiced in single-user\nchatbot interactions. In other words, the teachers would have to as-\nsess whether and when students are ready to move from single-user\nto multi-user interactions. Furthermore, because of greater auton-\nomy and improvisation afforded in multi-participant interactions,\nteachers would need to be more closely involved through monitor-\ning, moderation, and debriefing of these exchanges. Thus, there is\na trade-off between improvisation and control, and greater impro-\nvisation in chatbot interactions would have to be counterbalanced\nby teachers‚Äô involvement in other ways.\n6 CONCLUSION\nIn this work, we explore what technical and design components\nteachers need to build chatbots that assist in bystander education\nthrough Co-Pilot, an LLM-Chain based, no-code chatbot design\ntool. To create chatbot tools that fulfill teachers‚Äô needs, tool de-\nsigners will want to consider the teachers‚Äô goal of constructing\nrole-play scenarios and their perception of being playwrights of\nthese social interactions. Teachers want to control and adapt the\nchatbot while at the same time allowing the chatbot enough impro-\nvisation so that students can explore different bystander actions\nand scenarios and practice socio-emotional skills. This view helps\nto understand how far current language model technology can be\nutilized for chatbot building and what new solutions still need to\nbe found. We hope that researchers and designers of future tools\nwill consider these factors to ensure that chatbots for adolescent\ncyberbullying education have a successful impact in the classroom.\nACKNOWLEDGMENTS\nThe authors would like to thank all participating teachers for their\nvaluable time and insights, the research assistants Ashley Yu, George\nGu, Jade Yang, Jerry Guo, Kyle Lou, Morgan Cupp, and Tony Yang\nfor their help in developing the probe, as well as Dominic DiFranzo\nand Winice Hui for their contributions to the study. This work is\nsupported by National Science Foundation under grants IIS-2313077\nand IIS-2302977. Qian Yang is also supported by Schmidt Futures‚Äô\nAI2050 Early Career Fellowship.\nREFERENCES\n[1] Ana Aleksandric, Mohit Singhal, Anne Groggel, and Shirin Nilizadeh. 2022.\nUnderstanding the Bystander Effect on Toxic Twitter Conversations. https:\n//doi.org/10.48550/ARXIV.2211.10764\n[2] Kimberley R Allison and Kay Bussey. 2016. Cyber-bystanding in context: A\nreview of the literature on witnesses‚Äô responses to cyberbullying. Children and\nYouth Services Review 65 (2016), 183‚Äì194.\n[3] Stephen H. Bach, Victor Sanh, Zheng-Xin Yong, Albert Webson, Colin Raffel,\nNihal V. Nayak, Abheesht Sharma, Taewoon Kim, M Saiful Bari, Thibault Fevry,\nZaid Alyafeai, Manan Dey, Andrea Santilli, Zhiqing Sun, Srulik Ben-David, Can-\nwen Xu, Gunjan Chhablani, Han Wang, Jason Alan Fries, Maged S. Al-shaibani,\nShanya Sharma, Urmish Thakker, Khalid Almubarak, Xiangru Tang, Dragomir\nRadev, Mike Tian-Jian Jiang, and Alexander M. Rush. 2022. PromptSource: An\nIntegrated Development Environment and Repository for Natural Language\nPrompts. https://doi.org/10.48550/ARXIV.2202.01279\n[4] Julia Barli≈Ñska, Anna Szuster, and Miko≈Çaj Winiewski. 2013. Cyberbullying\namong adolescent bystanders: Role of the communication medium, form of\nviolence, and empathy. Journal of Community & Applied Social Psychology 23, 1\n(2013), 37‚Äì51.\n[5] Sara Bastiaensens, Heidi Vandebosch, Karolien Poels, Katrien Van Cleemput,\nAnn DeSmet, and Ilse De Bourdeaudhuij. 2015. ‚ÄòCan I afford to help?‚ÄôHow\naffordances of communication modalities guide bystanders‚Äô helping intentions\ntowards harassment on social network sites.Behaviour & Information Technology\n34, 4 (2015), 425‚Äì435.\n[6] Menucha Birenbaum. 2023. The Chatbots‚Äô Challenge to Education: Disruption\nor Destruction? Education Sciences 13, 7 (2023), 711.\n[7] Kirsten Boehner, Janet Vertesi, Phoebe Sengers, and Paul Dourish. 2007. How\nHCI Interprets the Probes. In Proceedings of the SIGCHI Conference on Human\nFactors in Computing Systems (San Jose, California, USA) (CHI ‚Äô07) . Association\nfor Computing Machinery, New York, NY, USA, 1077‚Äì1086. https://doi.org/10.\n1145/1240624.1240789\n[8] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,\nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot learners. Advances in neural\ninformation processing systems 33 (2020), 1877‚Äì1901.\n[9] Angela Busacca and Melchiorre Alberto Monaca. 2023. Deepfake: Creation,\nPurpose, Risks. In Innovations and Economic and Social Changes due to Artificial\nIntelligence: The State of the Art . Springer, 55‚Äì68.\n[10] Erin A Casey, Taryn Lindhorst, and Heather L Storer. 2017. The situational-\ncognitive model of adolescent bystander behavior: Modeling bystander decision-\nmaking in the context of bullying and teen dating violence.Psychology of violence\n7, 1 (2017), 33.\n[11] Robin Cohen, Nivedha Mathiarasu, R Aarif, S Ansari, D Fraser, M Hegde, J\nHenderson, I Kajic, A Khan, Z Liao, et al. 2018. An education-based approach to\naid in the prevention of cyberbullying. Acm Sigcas Computers and Society 47, 4\n(2018), 17‚Äì28.\n[12] Mike P Cook, Matthew Gremo, and Ryan Morgan. 2017. We‚Äôre just playing: The\ninfluence of a modified tabletop role-playing game on ELA students‚Äô in-class\nreading. Simulation & Gaming 48, 2 (2017), 199‚Äì218.\n[13] John M Darley and Bibb Latan√©. 1968. Bystander intervention in emergencies:\ndiffusion of responsibility. Journal of personality and social psychology 8, 4p1\n(1968), 377.\n[14] Thomas S Dee and Dan Goldhaber. 2017. Understanding and addressing teacher\nshortages in the United States. The Hamilton Project 5 (2017), 1‚Äì28.\n[15] Ann DeSmet, Sara Bastiaensens, Katrien Van Cleemput, Karolien Poels, Heidi\nVandebosch, and Ilse De Bourdeaudhuij. 2012. Mobilizing bystanders of cyber-\nbullying: an exploratory study into behavioural determinants of defending the\nvictim. Annual review of cybertherapy and telemedicine 10 (2012), 58‚Äì63.\n[16] Ann DeSmet, Charlene Veldeman, Karolien Poels, Sara Bastiaensens, Katrien\nVan Cleemput, Heidi Vandebosch, and Ilse De Bourdeaudhuij. 2014. Determi-\nnants of self-reported bystander behavior in cyberbullying incidents amongst\nadolescents. Cyberpsychology, Behavior, and Social Networking 17, 4 (2014), 207‚Äì\n215.\n[17] Dominic DiFranzo, Samuel Hardman Taylor, Franccesca Kazerooni, Olivia D\nWherry, and Natalya N Bazarova. 2018. Upstanding by design: Bystander inter-\nvention in cyberbullying. In Proceedings of the 2018 CHI conference on human\nfactors in computing systems . 1‚Äì12.\n[18] Fernando Dom√≠nguez-Hern√°ndez, Lars Bonell, and Alejandro Mart√≠nez-Gonz√°lez.\n2018. A systematic literature review of factors that moderate bystanders‚Äô actions\nin cyberbullying. Cyberpsychology: Journal of Psychosocial Research on Cyberspace\n12, 4 (2018).\n[19] Eva Durall and Evangelos Kapros. 2020. Co-design for a competency self-\nassessment chatbot and survey in science education. In Learning and Collabora-\ntion Technologies. Human and Technology Ecosystems: 7th International Conference .\nSpringer, 13‚Äì24.\n[20] Eva Durall, Marjo Virnes, Teemu Leinonen, and Bego√±a Gros. 2020. Ownership\nof learning in monitoring technology: Design case of self-monitoring tech in\nindependent study. Interaction Des. Architecture (s) J 45 (2020), 133‚Äì154.\n[21] Esin Durmus, Karina Nyugen, Thomas I. Liao, Nicholas Schiefer, Amanda\nAskell, Anton Bakhtin, Carol Chen, Zac Hatfield-Dodds, Danny Hernandez,\nNicholas Joseph, Liane Lovitt, Sam McCandlish, Orowa Sikder, Alex Tamkin,\nHedderich et al.\nJanel Thamkul, Jared Kaplan, Jack Clark, and Deep Ganguli. 2023. Towards\nMeasuring the Representation of Subjective Global Opinions in Language Mod-\nels. CoRR abs/2306.16388 (2023). https://doi.org/10.48550/arXiv.2306.16388\narXiv:2306.16388\n[22] Laura Faulkner. 2003. Beyond the five-user assumption: Benefits of increased\nsample sizes in usability testing. Behavior Research Methods, Instruments, &\nComputers 35 (2003), 379‚Äì383.\n[23] Virginia K. Felkner, Ho-Chun Herbert Chang, Eugene Jang, and Jonathan May.\n2023. WinoQueer: A Community-in-the-Loop Benchmark for Anti-LGBTQ+\nBias in Large Language Models. In Proceedings of the 61st Annual Meeting of\nthe Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023,\nToronto, Canada, July 9-14, 2023 . Association for Computational Linguistics,\n9126‚Äì9140. https://doi.org/10.18653/v1/2023.acl-long.507\n[24] Silvia Gabrielli, Silvia Rizzi, Sara Carbone, Valeria Donisi, et al. 2020. A chatbot-\nbased coaching intervention for adolescents to promote life skills: pilot study.\nJMIR Human Factors 7, 1 (2020), e16762.\n[25] Norma Ghamrawi, Tarek Shal, and Najah AR Ghamrawi. 2023. Exploring the\nimpact of AI on teacher leadership: regressing or expanding? Education and\nInformation Technologies (2023), 1‚Äì19.\n[26] Perttu H√§m√§l√§inen, Mikke Tavast, and Anton Kunnari. 2023. Evaluating Large\nLanguage Models in Generating Synthetic HCI Research Data: A Case Study. In\nProceedings of the 2023 CHI Conference on Human Factors in Computing Systems\n(Hamburg, Germany) (CHI ‚Äô23) . Association for Computing Machinery, New\nYork, NY, USA, Article 433, 19 pages. https://doi.org/10.1145/3544548.3580688\n[27] Gunnar Harboe and Elaine M. Huang. 2015. Real-World Affinity Diagramming\nPractices: Bridging the Paper-Digital Gap. In Proceedings of the 33rd Annual ACM\nConference on Human Factors in Computing Systems (Seoul, Republic of Korea)\n(CHI ‚Äô15) . Association for Computing Machinery, New York, NY, USA, 95‚Äì104.\nhttps://doi.org/10.1145/2702123.2702561\n[28] V√©ronique Irwin, Ke Wang, Jiashan Cui, Jizhi Zhang, and Alexandra Thompson.\n2021. Report on Indicators of School Crime and Safety: 2020. (2021). https:\n//nces.ed.gov/pubsearch/pubsinfo.asp?pubid=2021092\n[29] Karis Jones, Scott Storm, Jennifer Castillo, and Sasha Karbachinskiy. 2021. Chas-\ning New Worlds: Stories of Roleplaying in Classroom Spaces.Journal of language\nand literacy education 17, 1 (2021), n1.\n[30] Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney, Caiming Xiong, and\nRichard Socher. 2019. CTRL: A Conditional Transformer Language Model for\nControllable Generation. CoRR abs/1909.05858 (2019). arXiv:1909.05858 http:\n//arxiv.org/abs/1909.05858\n[31] DV Kiriukhina. 2019. Cyberbullying among young users of social networks.\nJournal of Modern Foreign Psychology 8, 3 (2019), 53‚Äì59.\n[32] Vasiliy Kolchenko. 2018. Can modern AI replace teachers? Not so fast! Artificial\nintelligence and adaptive learning: Personalized education in the AI age. HAPS\neducator 22, 3 (2018), 249‚Äì252.\n[33] Robin M Kowalski and Cristin Fedina. 2011. Cyber bullying in ADHD and\nAsperger Syndrome populations. Research in Autism Spectrum Disorders 5, 3\n(2011), 1201‚Äì1208.\n[34] Joel Kupperstein. 2023. AI Can‚Äôt Replace High-quality Teaching: Using the\nTechnology as a Tool. (2023).\n[35] Bibb Latan√© and John M Darley. 1970. The unresponsive bystander: Why doesn‚Äôt\nhe help? Prentice Hall.\n[36] Danielle M. Law, Jennifer D. Shapka, Shelley Hymel, Brent F. Olson, and Terry\nWaterhouse. 2012. The changing face of bullying: An empirical comparison\nbetween traditional and internet bullying and victimization.Computers in Human\nBehavior 28, 1 (2012), 226‚Äì232. https://doi.org/10.1016/j.chb.2011.09.004\n[37] Qing Li. 2007. Bullying in the new playground: Research into cyberbullying and\ncyber victimisation. Australasian Journal of Educational Technology 23, 4 (2007).\n[38] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and\nGraham Neubig. 2021. Pre-train, Prompt, and Predict: A Systematic Survey of\nPrompting Methods in Natural Language Processing. arXiv:2107.13586 [cs.CL]\n[39] Chung Kwan Lo. 2023. What is the impact of ChatGPT on education? A rapid\nreview of the literature. Education Sciences 13, 4 (2023), 410.\n[40] Andr√©s Lucero. 2015. Using affinity diagrams to evaluate interactive prototypes.\nIn Human-Computer Interaction‚ÄìINTERACT 2015: 15th IFIP TC 13 International\nConference, Bamberg, Germany, September 14-18, 2015, Proceedings, Part II 15 .\nSpringer, 231‚Äì248.\n[41] Katja Machmutow, Sonja Perren, Fabio Sticca, and Francoise D Alsaker. 2012.\nPeer victimisation and depressive symptoms: Can specific coping strategies\nbuffer the negative impact of cybervictimisation? Emotional and Behavioural\nDifficulties 17, 3-4 (2012), 403‚Äì420.\n[42] Aida Midgett, Diana M Doumas, April Johnston, Rhiannon Trull, and Raissa\nMiller. 2018. Rethinking bullying interventions for high school students: A\nqualitative study. Journal of Child and Adolescent Counseling 4, 2 (2018), 146‚Äì\n163.\n[43] Tijana Milosevic, Kanishk Verma, Michael Carter, Samantha Vigil, Derek Laffan,\nBrian Davis, and James O‚ÄôHiggins Norman. 2023. Effectiveness of Artificial\nIntelligence‚ÄìBased Cyberbullying Interventions From Youth Perspective. Social\nMedia+ Society 9, 1 (2023), 20563051221147325.\n[44] Fabio Motoki, Valdemar Pinho Neto, and Victor Rodrigues. 2023. More human\nthan human: Measuring ChatGPT political bias. Public Choice (2023), 1‚Äì21.\n[45] Dorit Olenik-Shemesh, Tali Heiman, and Sigal Eden. 2017. Bystanders‚Äô behavior\nin cyberbullying episodes: Active and passive patterns in the context of personal‚Äì\nsocio-emotional factors. Journal of interpersonal violence 32, 1 (2017), 23‚Äì48.\n[46] Julia Othlinghaus-Wulhorst and H Ulrich Hoppe. 2020. A technical and concep-\ntual framework for serious role-playing games in the area of social skill training.\nFrontiers in Computer Science 2 (2020), 28.\n[47] Joon Sung Park, Joseph C. O‚ÄôBrien, Carrie J. Cai, Meredith Ringel Morris, Percy\nLiang, and Michael S. Bernstein. 2023. Generative Agents: Interactive Simulacra\nof Human Behavior. CoRR abs/2304.03442 (2023). https://doi.org/10.48550/arXiv.\n2304.03442 arXiv:2304.03442\n[48] Joon Sung Park, Lindsay Popowski, Carrie Cai, Meredith Ringel Morris, Percy\nLiang, and Michael S. Bernstein. 2022. Social Simulacra: Creating Populated\nPrototypes for Social Computing Systems. InProceedings of the 35th Annual ACM\nSymposium on User Interface Software and Technology (Bend, OR, USA) (UIST ‚Äô22).\nAssociation for Computing Machinery, New York, NY, USA, Article 74, 18 pages.\nhttps://doi.org/10.1145/3526113.3545616\n[49] Justin W Patchin and Sameer Hinduja. 2012. Cyberbullying prevention and\nresponse: Expert perspectives . Routledge.\n[50] Lara Schibelsky Godoy Piccolo, Pinelopi Troullinou, and Harith Alani. 2021.\nChatbots to support children in coping with online threats: Socio-technical\nrequirements. In Designing Interactive Systems Conference 2021 . 1504‚Äì1517.\n[51] Megan Price and John Dalgleish. 2010. Cyberbullying: Experiences, impacts\nand coping strategies as described by Australian young people. Youth studies\naustralia 29, 2 (2010), 51‚Äì59.\n[52] Rhiarne E Pronk and Melanie J Zimmer-Gembeck. 2010. It‚Äôs ‚Äúmean, ‚Äù but what does\nit mean to adolescents? Relational aggression described by victims, aggressors,\nand their peers. Journal of Adolescent research 25, 2 (2010), 175‚Äì204.\n[53] Emily Reif, Daphne Ippolito, Ann Yuan, Andy Coenen, Chris Callison-Burch,\nand Jason Wei. 2022. A Recipe for Arbitrary Text Style Transfer with Large\nLanguage Models. In Proceedings of the 60th Annual Meeting of the Association\nfor Computational Linguistics (Volume 2: Short Papers), ACL 2022, Dublin, Ireland,\nMay 22-27, 2022 , Smaranda Muresan, Preslav Nakov, and Aline Villavicencio\n(Eds.). Association for Computational Linguistics, 837‚Äì848. https://doi.org/10.\n18653/v1/2022.acl-short.94\n[54] Sara E Rimm-Kaufman. 2020. SEL from the Start: Building Skills in K-5 (Social\nand Emotional Learning Solutions) . WW Norton & Company.\n[55] Christina Salmivalli, Kirsti Lagerspetz, Kaj Bj√∂rkqvist, Karin √ñsterman, and\nAri Kaukiainen. 1996. Bullying as a group process: Participant roles and their\nrelations to social status within the group. Aggressive Behavior: Official Journal\nof the International Society for Research on Aggression 22, 1 (1996), 1‚Äì15.\n[56] Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika,\nZaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja,\nManan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma,\nEliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta,\nJonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen,\nZheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj,\nJos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries,\nRyan Teehan, Tali Bers, Stella Biderman, Leo Gao, Thomas Wolf, and Alexander M.\nRush. 2021. Multitask Prompted Training Enables Zero-Shot Task Generalization.\nhttps://doi.org/10.48550/ARXIV.2110.08207\n[57] Jeff Sauro and James R Lewis. 2016. Quantifying the user experience: Practical\nstatistics for user research . Morgan Kaufmann.\n[58] Shari Kessel Schneider, Lydia O‚Äôdonnell, Ann Stueve, and Robert WS Coulter.\n2012. Cyberbullying, school bullying, and psychological distress: A regional\ncensus of high school students. American journal of public health 102, 1 (2012),\n171‚Äì177.\n[59] Jessica Shieh. 2023. Best practices for prompt engineering with openai\nAPI. https://help.openai.com/en/articles/6654000-best-practices-for-prompt-\nengineering-with-openai-api\n[60] Lei Shu, Liangchen Luo, Jayakumar Hoskere, Yun Zhu, Canoee Liu, Simon Tong,\nJindong Chen, and Lei Meng. 2023. RewriteLM: An Instruction-Tuned Large\nLanguage Model for Text Rewriting. CoRR abs/2305.15685 (2023). https://doi.\norg/10.48550/arXiv.2305.15685 arXiv:2305.15685\n[61] Rachele Sprugnoli, Stefano Menini, Sara Tonelli, Filippo Oncini, and Enrico\nPiras. 2018. Creating a WhatsApp Dataset to Study Pre-teen Cyberbullying. In\nProceedings of the 2nd Workshop on Abusive Language Online (ALW2) . Association\nfor Computational Linguistics, Brussels, Belgium, 51‚Äì59. https://doi.org/10.\n18653/v1/W18-5107\n[62] Kevin Stowe, Debanjan Ghosh, and Mengxuan Zhao. 2022. Controlled Language\nGeneration for Language Learning Items. In Proceedings of the 2022 Conference\non Empirical Methods in Natural Language Processing: EMNLP 2022 - Industry\nTrack, Abu Dhabi, UAE, December 7 - 11, 2022 . Association for Computational\nLinguistics, 294‚Äì305. https://doi.org/10.18653/v1/2022.emnlp-industry.30\n[63] Seda G√∂k√ße Turan. 2021. Deepfake and digital citizenship: A long-term protection\nmethod for children and youth. In Deep fakes, fake news, and misinformation in\nonline teaching and learning technologies . IGI Global, 124‚Äì142.\nA Piece of Theatre\n[64] Tomoyuki Ueda, Junya Nakanishi, Itaru Kuramoto, Jun Baba, Yuichiro Yoshikawa,\nand Hiroshi Ishiguro. 2021. Cyberbullying Mitigation by a Proxy Persuasion of\na Chat Member Hijacked by a Chatbot. In Proceedings of the 9th International\nConference on Human-Agent Interaction . 202‚Äì208.\n[65] U.S. Department of Education. 2023. Teacher Shortage Areas. https://tsa.ed.gov\n[66] Kathleen Van Royen, Karolien Poels, Heidi Vandebosch, and Philippe Adam. 2017.\n‚ÄúThinking before posting?‚Äù Reducing cyber harassment on social networking\nsites through a reflective message. Computers in human behavior 66 (2017),\n345‚Äì352.\n[67] Pranav Narayanan Venkit, Sanjana Gautam, Ruchi Panchanadikar, Ting-Hao K.\nHuang, and Shomir Wilson. 2023. Nationality Bias in Text Generation. InProceed-\nings of the 17th Conference of the European Chapter of the Association for Compu-\ntational Linguistics, EACL 2023, Dubrovnik, Croatia, May 2-6, 2023 . Association for\nComputational Linguistics, 116‚Äì122. https://aclanthology.org/2023.eacl-main.9\n[68] Sofia Villatoro Moral and Barbara de Benito. 2021. An Approach to Co-Design\nand Self-Regulated Learning in Technological Environments. Systematic Review.\nJournal of New Approaches in Educational Research 10, 2 (2021), 234‚Äì250.\n[69] Emily Vogels. 2022. Teens and Cyberbullying 2022. Pew Research Center (2022).\n[70] Laura Weidinger, Jonathan Uesato, Maribeth Rauh, Conor Griffin, Po-Sen Huang,\nJohn Mellor, Amelia Glaese, Myra Cheng, Borja Balle, Atoosa Kasirzadeh, Court-\nney Biles, Sasha Brown, Zac Kenton, Will Hawkins, Tom Stepleton, Abeba\nBirhane, Lisa Anne Hendricks, Laura Rimell, William Isaac, Julia Haas, Sean\nLegassick, Geoffrey Irving, and Iason Gabriel. 2022. Taxonomy of Risks Posed\nby Language Models. In Proceedings of the 2022 ACM Conference on Fairness,\nAccountability, and Transparency (Seoul, Republic of Korea) (FAccT ‚Äô22) . As-\nsociation for Computing Machinery, New York, NY, USA, 214‚Äì229. https:\n//doi.org/10.1145/3531146.3533088\n[71] Thilini Wijesiriwardene, Hale Inan, Ugur Kursuncu, Manas Gaur, Valerie L\nShalin, Krishnaprasad Thirunarayan, Amit Sheth, and I Budak Arpinar. 2020.\nAlone: A dataset for toxic behavior among adolescents on twitter. InInternational\nConference on Social Informatics . Springer, 427‚Äì439.\n[72] Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina,\nMichael Terry, and Carrie J Cai. 2022. PromptChainer: Chaining Large Language\nModel Prompts through Visual Programming. https://doi.org/10.48550/ARXIV.\n2203.06566\n[73] Tongshuang Wu, Michael Terry, and Carrie J Cai. 2022. AI Chains: Transparent\nand Controllable Human-AI Interaction by Chaining Large Language Model\nPrompts. In Proceedings of the 2022 CHI conference on human factors in computing\nsystems.\n[74] Sijia Xiao, Coye Cheshire, and Niloufar Salehi. 2022. Sensemaking, Support,\nSafety, Retribution, Transformation: A Restorative Justice Approach to Under-\nstanding Adolescents‚Äô Needs for Addressing Online Harm. In Proceedings of the\n2022 CHI Conference on Human Factors in Computing Systems (New Orleans,\nLA, USA) (CHI ‚Äô22) . Association for Computing Machinery, New York, NY, USA,\nArticle 146, 15 pages. https://doi.org/10.1145/3491102.3517614\n[75] Qian Yang, Justin Cranshaw, Saleema Amershi, Shamsi T Iqbal, and Jaime Teevan.\n2019. Sketching nlp: A case study of exploring the right things to design with\nlanguage intelligence. InProceedings of the 2019 CHI Conference on Human Factors\nin Computing Systems . 1‚Äì12.\n[76] J.D. Zamfirescu-Pereira, Heather Wei, Amy Xiao, Kitty Gu, Grace Jung,\nMatthew G Lee, Bjoern Hartmann, and Qian Yang. 2023. Herding AI Cats:\nLessons from Designing a Chatbot by Prompting GPT-3. In Proceedings of the\n2023 ACM Designing Interactive Systems Conference (Pittsburgh, PA, USA) (DIS\n‚Äô23). Association for Computing Machinery, New York, NY, USA, 2206‚Äì2220.\nhttps://doi.org/10.1145/3563657.3596138\n[77] JD Zamfirescu-Pereira, Richmond Y Wong, Bjoern Hartmann, and Qian Yang.\n2023. Why Johnny can‚Äôt prompt: how non-AI experts try (and fail) to design\nLLM prompts. In Proceedings of the 2023 CHI Conference on Human Factors in\nComputing Systems . 1‚Äì21.\n[78] Izabela Zych, Anna C Baldry, David P Farrington, and Vicente J Llorent. 2019.\nAre children involved in cyberbullying low on empathy? A systematic review\nand meta-analysis of research on empathy versus different cyberbullying roles.\nAggression and violent behavior 45 (2019), 83‚Äì97.\nHedderich et al.\nA STUDENT SIMULATIONS\nThe student simulations used GPT-3.5-Turbo to generate student\nanswers when testing the chatbot. Prompts were used that con-\ntained the context along with a description of the student type.\nWe defined three student types: an aggressive student bullying the\nbully, an upstander student supporting the victim, and a passive\nbystander student that ignores the bullying. All prompts had the\nsame structure and only replaced parts that related to the student\ntype. A separate prompt was used to generate the comment and\nany answers to the chatbot.\nA.1 Aggressive student\nYou are John, an aggressive student, and you see the\nfollowing on Instagram: {general_context}\n----\nGive a comment that the student John would post under the\nInstagram post in which John insults the bully. Be\naggressive. Answer in the language style of a teenager.\nGive an answer that is no longer than 10 words.\n----\nYou commented under this Instagram post the following\ncomment {comment}.\nBased on your comment, a chatbot is trying to teach you\nhow to best act with a cyberbullying situation. This is\nyour conversation so far: {messages}.\nGive the next answer of the student to this conversation\nwhere you tend to not agree with the chatbot.\nAnswer in the language style of a teenager. Give an answer\nthat is no longer than 10 words.\\nJohn:\nA.2 Upstanding student\nYou are John, a supportive student, and you see the\nfollowing on Instagram: {general_context}\n----\nGive a comment that the student John would post under the\nInstagram post in which John comforts and supports Alex\n(the victim). Be gentle and sweet. Answer in the language\nstyle of a teenager. Give an answer that is no longer\nthan 10 words.\n----\nYou commented under this Instagram post the following\ncomment {comment}.\nBased on your comment, a chatbot is trying to teach you\nhow to best act with a cyberbullying situation. This is\nyour conversation so far: {messages}.\nGive the next answer of the student to this conversation\nwhere you tend to agree with the chatbot.\nAnswer in the language style of a teenager. Give an answer\nthat is no longer than 10 words.\\nJohn:\nA.3 Passive bystander student\nYou are John, a student who ignores the bullying and\njust comments on the original post, and you see the\nfollowing on Instagram: {general_context}\n----\nGive a comment that the student John would post under\nthe Instagram post in which John is looking forward\nto seeing the ballet recital. Be gentle and sweet.\nAnswer in the language style of a teenager. Give an\nanswer that is no longer than 10 words.\n----\nYou commented under this Instagram post the following\ncomment {comment}. Based on your comment, a chatbot is\ntrying to teach you how to best act with a cyberbullying\nsituation. This is your conversation so far: {messages}.\nGive the next answer of the student to this conversation\nwhere you tend to agree with the chatbot.\nAnswer in the language style of a teenager. Give an\nanswer that is no longer than 10 words.\\nJohn:\nB STUDENT BEHAVIOR COMPONENTS\nThe structure and examples provided by the teacher were used\nto build few-shot classifiers of the student behavior. All behavior\ncomponents that had the same parent component were used as\nclasses in a classifier. The following prompt was used with a loop\nover all examples:\nVictim's name is Alex. Bully's name is Leslie.\nClassify the user inputs into one of the following\ncategories:\n{prompt_classes}\nOnly give the name of the category. If none of these\ncategories match, output 'none' as category'.\nInput {example_num}: {example}\nCategory {example_num}: {class_name}\nInput {example_num}: {student_message_to_classify}\nCategory {example_num}:\nWe usedText-Davinci-003 and parsed its answer to determine\nthe predicted class (and therefore the conversational path to take\nin the dialogue structure).\nC CHATBOT REACTION COMPONENT\nThe response examples provided by the teacher were used to gener-\nate the chatbot‚Äôs answer in each situation. As example contexts, the\nbehavior examples from the parent student behavior component\nA Piece of Theatre\nwere used. We prompted Text-Davinci-003 for the generation\nwith a loop over all teacher-defined examples.\nThe student sees a cyberbully on social media.\nThe bully's name is Leslie and the victim's name is\nAlex.\nThe student makes a comment in response to the post.\nYou are talking to that student whose name is not Alex\nor Leslie so don't call him/her Alex or Leslie.\nTeach that student to counteract cyberbullies based on\nthe following examples:\"\nExample: {example_num}\nContext: {context_example}\nResponse: {response}\"\nNow fill in a new response based on the examples.\nGive answers very similar to the examples:\nContext: {student_message_to_answer}\nResponse:",
  "topic": "Chatbot",
  "concepts": [
    {
      "name": "Chatbot",
      "score": 0.9204713702201843
    },
    {
      "name": "Bespoke",
      "score": 0.8188351392745972
    },
    {
      "name": "Wizard",
      "score": 0.6538861989974976
    },
    {
      "name": "Chaining",
      "score": 0.5713810324668884
    },
    {
      "name": "Computer science",
      "score": 0.4939876198768616
    },
    {
      "name": "Wizard of oz",
      "score": 0.4450311064720154
    },
    {
      "name": "Psychology",
      "score": 0.4074234366416931
    },
    {
      "name": "Human‚Äìcomputer interaction",
      "score": 0.3580479025840759
    },
    {
      "name": "Multimedia",
      "score": 0.34759658575057983
    },
    {
      "name": "World Wide Web",
      "score": 0.24475079774856567
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Psychotherapist",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ],
  "institutions": []
}