{
  "title": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
  "url": "https://openalex.org/W3123811550",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2141851547",
      "name": "Liu, Shangqing",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2085177164",
      "name": "Chen Yu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2364446491",
      "name": "Xie, Xiaofei",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4227454722",
      "name": "Siow, Jingkai",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2102234800",
      "name": "Liu Yang",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3086449553",
    "https://openalex.org/W2104301886",
    "https://openalex.org/W3091730360",
    "https://openalex.org/W2018844270",
    "https://openalex.org/W2996028985",
    "https://openalex.org/W2964308564",
    "https://openalex.org/W2979792666",
    "https://openalex.org/W2963804140",
    "https://openalex.org/W2884276923",
    "https://openalex.org/W1992114977",
    "https://openalex.org/W2519887557",
    "https://openalex.org/W2890585661",
    "https://openalex.org/W2950898568",
    "https://openalex.org/W2796167946",
    "https://openalex.org/W2971590890",
    "https://openalex.org/W2963015915",
    "https://openalex.org/W2728773317",
    "https://openalex.org/W2963935794",
    "https://openalex.org/W2023925487",
    "https://openalex.org/W2990045899",
    "https://openalex.org/W2798749466",
    "https://openalex.org/W2807964941",
    "https://openalex.org/W2970862273",
    "https://openalex.org/W2963499994",
    "https://openalex.org/W2888557792",
    "https://openalex.org/W2971008324",
    "https://openalex.org/W2133333349",
    "https://openalex.org/W2034209539",
    "https://openalex.org/W2516621648",
    "https://openalex.org/W2964322208",
    "https://openalex.org/W2963532541",
    "https://openalex.org/W1902237438",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2962767366",
    "https://openalex.org/W2194775991",
    "https://openalex.org/W3034689979",
    "https://openalex.org/W648786980",
    "https://openalex.org/W2138756793",
    "https://openalex.org/W2887364112"
  ],
  "abstract": "Source code summarization aims to generate natural language summaries from structured code snippets for better understanding code functionalities. However, automatic code summarization is challenging due to the complexity of the source code and the language gap between the source code and natural language summaries. Most previous approaches either rely on retrieval-based (which can take advantage of similar examples seen from the retrieval database, but have low generalization performance) or generation-based methods (which have better generalization performance, but cannot take advantage of similar examples). This paper proposes a novel retrieval-augmented mechanism to combine the benefits of both worlds. Furthermore, to mitigate the limitation of Graph Neural Networks (GNNs) on capturing global graph structure information of source code, we propose a novel attention-based dynamic graph to complement the static graph representation of the source code, and design a hybrid message passing GNN for capturing both the local and global structural information. To evaluate the proposed approach, we release a new challenging benchmark, crawled from diversified large-scale open-source C projects (total 95k+ unique functions in the dataset). Our method achieves the state-of-the-art performance, improving existing methods by 1.42, 2.44 and 1.29 in terms of BLEU-4, ROUGE-L and METEOR.",
  "full_text": "Published as a conference paper at ICLR 2021\nRETRIEVAL -AUGMENTED GENERATION FOR CODE\nSUMMARIZATION VIA HYBRID GNN\nShangqing Liu1∗, Yu Chen2†, Xiaofei Xie1†, Jingkai Siow1, Yang Liu1\n1 Nanyang Technology University\n2 Rensselaer Polytechnic Institute\nABSTRACT\nSource code summarization aims to generate natural language summaries from\nstructured code snippets for better understanding code functionalities. However, au-\ntomatic code summarization is challenging due to the complexity of the source code\nand the language gap between the source code and natural language summaries.\nMost previous approaches either rely on retrieval-based (which can take advantage\nof similar examples seen from the retrieval database, but have low generalization\nperformance) or generation-based methods (which have better generalization per-\nformance, but cannot take advantage of similar examples). This paper proposes\na novel retrieval-augmented mechanism to combine the beneﬁts of both worlds.\nFurthermore, to mitigate the limitation of Graph Neural Networks (GNNs) on\ncapturing global graph structure information of source code, we propose a novel\nattention-based dynamic graph to complement the static graph representation of the\nsource code, and design a hybrid message passing GNN for capturing both the local\nand global structural information. To evaluate the proposed approach, we release\na new challenging benchmark, crawled from diversiﬁed large-scale open-source\nC projects (total 95k+ unique functions in the dataset). Our method achieves the\nstate-of-the-art performance, improving existing methods by 1.42, 2.44 and 1.29\nin terms of BLEU-4, ROUGE-L and METEOR.\n1 I NTRODUCTION\nWith software growing in size and complexity, developers tend to spend nearly 90% (Wan et al.,\n2018) effort on software maintenance ( e.g., version iteration and bug ﬁx) in the completed life\ncycle of software development. Source code summary, in the form of natural language, plays a\ncritical role in the comprehension and maintenance process and greatly reduces the effort of reading\nand comprehending programs. However, manually writing code summaries is tedious and time-\nconsuming, and with the acceleration of software iteration, it has become a heavy burden for software\ndevelopers. Hence, source code summarization which automates concise descriptions of programs is\nmeaningful.\nAutomatic source code summarization is a crucial yet far from the settled problem. The key challenges\ninclude: 1) the source code and the natural language summary are heterogeneous, which means\nthey may not share common lexical tokens, synonyms, or language structures and 2) the source\ncode is complex with complicated logic and variable grammatical structure, making it hard to learn\nthe semantics. Conventionally, information retrieval (IR) techniques have been widely used in\ncode summarization (Eddy et al., 2013; Haiduc et al., 2010; Wong et al., 2015; 2013). Since code\nduplication (Kamiya et al., 2002; Li et al., 2006) is common in “big code” (Allamanis et al., 2018),\nearly works summarize the new programs by retrieving the similar code snippet in the existing code\ndatabase and use its summary directly. Essentially, the retrieval-based approaches transform the code\nsummarization to the code similarity calculation task, which may achieve promising performance on\nsimilar programs, but are limited in generalization, i.e. they have poorer performance on programs\nthat are very different from the code database.\n∗Contact:shangqin001@e.ntu.edu.sg\n†Corresponding authors\n1\narXiv:2006.05405v5  [cs.LG]  13 May 2021\nPublished as a conference paper at ICLR 2021\nTo improve the generalization performance, recent works focus on generation-based approaches.\nSome works explore Seq2Seq architectures (Bahdanau et al., 2014; Luong et al., 2015) to generate\nsummaries from the given source code. The Seq2Seq-based approaches (Iyer et al., 2016; Hu et al.,\n2018a; Alon et al., 2018) usually treat the source code or abstract syntax tree parsed from the source\ncode as a sequence and follow a paradigm of encoder-decoder with the attention mechanism for\ngenerating a summary. However, these works only rely on sequential models, which are struggling\nto capture the rich semantics of source code e.g., control dependencies and data dependencies. In\naddition, generation-based approaches typically cannot take advantage of similar examples from the\nretrieval database, as retrieval-based approaches do.\nTo better learn the semantics of the source code, Allamanis et al. (Allamanis et al., 2017) lighted\nup this ﬁeld by representing programs as graphs. Some follow-up works (Fernandes et al., 2018)\nattempted to encode more code structures (e.g., control ﬂow, program dependencies) into code graphs\nwith graph neural networks (GNNs), and achieved the promising performance than the sequence-\nbased approaches. Existing works (Allamanis et al., 2017; Fernandes et al., 2018) usually convert\ncode into graph-structured input during preprocessing, and directly consume it via modern neural\nnetworks (e.g., GNNs) for computing node and graph embeddings. However, most GNN-based\nencoders only allow message passing among nodes within a k-hop neighborhood (where kis usually\na small number such as 4) to avoid over-smoothing (Zhao & Akoglu, 2019; Chen et al., 2020a), thus\ncapture only local neighborhood information and ignore global interactions among nodes. Even\nthere are some works (Li et al., 2019) that try to address this challenging with deep GCNs (i.e., 56\nlayers) (Kipf & Welling, 2016) by the residual connection (He et al., 2016), however, the computation\ncost cannot endure in the program especially for a large and complex program.\nTo address these challenges, we propose a framework for automatic code summarization, namely\nHybrid GNN (HGNN). Speciﬁcally, from the source code, we ﬁrst construct a code property graph\n(CPG) based on the abstract syntax tree (AST) with different types of edges (i.e., Flow To, Reach). In\norder to combine the beneﬁts of both retrieval-based and generation-based methods, we propose a\nretrieval-based augmentation mechanism to retrieve the source code that is most similar to the current\nprogram from the retrieval database (excluding the current program itself), and add the retrieved code\nas well as the corresponding summary as auxiliary information for training the model. In order to\ngo beyond local graph neighborhood information, and capture global interactions in the program,\nwe further propose an attention-based dynamic graph by learning global attention scores (i.e., edge\nweights) in the augmented static CPG. Then, a hybrid message passing (HMP) is performed on both\nstatic and dynamic graphs. We also release a new code summarization benchmark by crawling data\nfrom popular and diversiﬁed projects containing 95k+ functions in C programming language and\nmake it public 1. We highlight our main contributions as follows:\n• We propose a general-purpose framework for automatic code summarization, which combines the\nbeneﬁts of both retrieval-based and generation-based methods via a retrieval-based augmentation\nmechanism.\n• We innovate a Hybrid GNN by fusing the static graph (based on code property graph) and dynamic\ngraph (via structure-aware global attention mechanism) to mitigate the limitation of the GNN on\ncapturing global graph information.\n• We release a new challenging C benchmark for the task of source code summarization.\n• We conduct an extensive experiment to evaluate our framework. The proposed approach achieves\nthe state-of-the-art performance and improves existing approaches by 1.42, 2.44 and 1.29 in terms\nof BLEU-4, ROUGE-L and METEOR metrics.\n2 H YBRID GNN F RAMEWORK\nIn this section, we introduce the proposed framework Hybrid GNN (HGNN), as shown in Figure 1,\nwhich mainly includes four components: 1) Retrieval-augmented Static Graph Construction (c.f.,\nSection 2.2), which incorporates retrieved code-summary pairs to augment the original code for\nlearning. 2) Attention-based Dynamic Graph Construction (c.f., Section 2.3), which allows message\npassing among any pair of nodes via a structure-aware global attention mechanism. 3) HGNN, (c.f.,\n1https://github.com/shangqing-liu/CCSD-benchmark-for-code-summarization\n2\nPublished as a conference paper at ICLR 2021\nRetrievedSummary\nSourceCode\nRetrievalCPG\nAug\n Static Message Passing\nAX(     +     …     +      )       \nDynamic Message PassingHybrid\nDecoder\nGeneratedSummary\nHybrid GNNRetrieval-augmentedGraph\nSummaryEncoding GraphEmbedding\nGRU Updates\nNode Embeddings\nAttention-basedGraph\nRetrievalDatabaseSourceCPG\nAggregation\nFigure 1: The overall architecture of the proposed HGNN framework.\nSection 2.4), which incorporates information from both static graphs and dynamic graphs with Hybrid\nMessage Passing. 4) Decoder (c.f., Section 2.5), which utilizes an attention-based LSTM (Hochreiter\n& Schmidhuber, 1997) model to generate a summary.\n2.1 P ROBLEM FORMULATION\nIn this work, we focus on generating natural language summaries for the given functions (Wan et al.,\n2018; Zhang et al., 2020). A simple example is illustrated in Listing 1, which is crawled from Linux\nKernel. Our goal is to generate the best summary “set the time of day clock” based on the given source\ncode. Formally, we deﬁne a dataset as D= {(c,s)|c∈C,s ∈S}, where cis the source code of a\nfunction in the function set Cand srepresents its targeted summary in the summary setS. The task of\ncode summarization is, given a source code c, to generate the best summary consisting of a sequence\nof tokens ˆs= (t1,t2,...,t T ) that maximizes the conditional likelihood ˆs= argmaxsP(s|c).\nSource Code:\nint pdc_tod_set(unsigned long sec, unsigned long usec){\nint retval; unsigned long flags;\nspin_lock_irqsave(&pdc_lock, flags);\nretval = mem_pdc_call(PDC_TOD, PDC_TOD_WRITE, sec, usec);\nspin_unlock_irqrestore(&pdc_lock, flags);\nreturn retval;\n}\nGround-Truth: set the time of day clock\nListing 1: An example in our dataset crawled from Linux Kernel.\n2.2 R ETRIEVAL -AUGMENTED STATIC GRAPH\n2.2.1 G RAPH INITIALIZATION\nThe source code of a function can be represented as Code Property Graph (CPG) (Yamaguchi et al.,\n2014), which is built on the abstract syntax tree (AST) with different type of edges (i.e., Flow To,\nControl, Deﬁne/Use, Reach). Formally, one raw function ccould be represented by a multi-edged\ngraph g(V,E), where Vis the set of AST nodes, (v,u) ∈E denotes the edge between the node vand\nthe node u. A node vconsists of two parts: the node sequence and the node type. An illustrative\nexample is shown in Figure 2. For example, in the red node, a%2 == 0is the node sequence and\nConditionis the node type. An edge (v,u) has a type, named edge type, e.g., AST type and Flow\nTo type. For more details about the CPG, please refer to Appendix A.\nInitialization Representation.Given a CPG, we utilize a BiLSTM to encode its nodes. We represent\neach token of the node sequence and each edge type using the learned embedding matrix Eseqtoken\nand Eedgetype, respectively. Then nodes and edges of the CPG can be encoded as:\nh1, ...,hl = BiLSTM(Eseqtoken\nv,1 , ...,Eseqtoken\nv,l )\nencode_node(v) = [h→\nl ; h←\n1 ]\nencode_edge(v, u) =Eedgetype\nv,u if (v, u) ∈ Eelse 0\n(1)\n3\nPublished as a conference paper at ICLR 2021\nEntry\nCFGEntryNode\nexample()\nFunctionDef\nint a = rand( )\nIdentiﬁerDeclStatement\na % 2 == 0\nCondition\nint b = a ++\nIdentiﬁerDeclStatement\nEXIT\nCFGExitNode\ncall(b)\nExpressionStatement\n \nParameterList\nvoid\nReturnType\nint\nIdentiﬁerDeclType\na\nIdentiﬁer\na = rand ( )\nAssignmentExpr\nrand ( )\nCallExpression\na % 2 == 0\nEqualityExpression\na % 2\nMultiplicativeExpression\na\nIdentiﬁer\n2\nPrimaryExpression\n0\nPrimaryExpression\nint\nIdentiﬁerDeclType\nb\nIdentiﬁer\nb = a ++\nAssignmentExpr\na ++\nIncDecOp\n++\nIncDec\na\nIdentiﬁer\na\nSymbol\ncall\nCallee\nb\nArgument\nb\nIdentiﬁerb\nSymbol\nb\nIdentiﬁer\nAST Flow  To Control Deﬁne/Use Reach\nvoid example ( )\n{\n   int a = rand( );\n   if ( a % 2 == 0 )\n   {\n        int b = a++;\n        call(b);\n   }\n}\nA simple code example\nparse\nFigure 2: An example of Code Property Graph (CPG).\nwhere lis the number of tokens in the node sequence ofv. For the sake of simplicity, in the following\nsection, we use hv and ev,u to represent the embedding of the nodevand the edge (v,u), respectively,\ni.e., encode_node(v) and encode_edge(v,u). Given the source code cof a function as well as the\nCPG g(V,E), Hc ∈Rm×d denotes the initial node matrix of the CPG, where mis the total number\nof nodes in the CPG and dis the dimension of the node embedding.\n2.2.2 R ETRIEVAL -BASED AUGMENTATION\nWhile retrieval-based methods can perform reasonably well on examples that are similar to those\nexamples from a retrieval database, they typically have low generalization performance and might\nperform poorly on dissimilar examples. On the contrary, generation-based methods usually have better\ngeneralization performance, but cannot take advantage of similar examples from the retrieval database.\nIn this work, we propose to combine the beneﬁts of the two worlds, and design a retrieval-augmented\ngeneration framework for the task of code summarization.\nIn principle, the goal of code summarization is to learn a mapping from source code cto the natural\nlanguage summary s= f(c). In other words, for any source code c′, a code summarization system\ncan produce its summary s′ = f(c′). Inspired by this observation, conceptually, we can derive\nthe following formulation s = f(c) −f(c′) +s′. This tells us that we can actually compute the\nsemantic difference between cand c′, and further obtain the desired summary sfor cby considering\nboth the above semantic difference and s′which is the summary for c′. Mathmatically, our goal\nbecomes to learn a function which takes as input (c,c′,s′), and outputs the summary sfor c, that\nis, s = g(c,c′,s′). This motivates us to design our Retrieval-based Augmentation mechanism, as\ndetailed below.\nStep 1: Retrieving.For each sample (c,s) ∈D, we retrieve the most similar sample: (c′,s′) =\nargmax(c′,s′)∈D′ sim(c,c′), where c̸= c′, D′is a given retrieval database and sim(c,c′) is the text\nsimilarity. Following Zhang et al. (2020), we utilize Lucene for retrieval and calculate the similarity\nscore z between the source code cand the retrieved code c′via dynamic programming (Bellman,\n1966), namely, z= 1− dis(c,c′)\nmax(|c|,|c′|) , where dis(c,c′) is the text edit distance.\nStep 2: Retrieved Code-based Augmentation.Given the retrieved source code c′for the current\nsample c, we adopt a fusion strategy to inject retrieved semantics into the current sample. The fusion\nstrategy is based on their initial graph representations (Hc and Hc′ ) with an attention mechanism:\n• To capture the relevance betweencand c′, we design an attention function, which computes the\nattention score matrix Aaug based on the embeddings of each pair of nodes in CPGs of cand c′:\nAaug ∝exp(ReLU(HcWC)ReLU(Hc′ WQ)T ) (2)\nwhere WC,WQ ∈Rd×d is the weight matrix with d-dim embedding size and ReLU is the\nrectiﬁed linear unit.\n• We then multiply the attention matrix Aaug with the retrieved representation Hc′ to inject the\nretrieved features into Hc:\nH′\nc = zAaugHc′ (3)\nwhere z∈[0,1] is the similarity score and computed from Step 1, which is introduced to weaken\nthe negative impact of c′on the original training data c, i.e., when the similarity of cand c′is low.\n• Finally, we merge H′\nc and the original Hc to get the ﬁnal representation of c.\ncomp = Hc + H′\nc (4)\n4\nPublished as a conference paper at ICLR 2021\nwhere comp is the augmented node representation additionally encoding the retrieved semantics.\nStep 3: Retrieved Summary-based Augmentation.We further encode the retrieved summary s′\nwith another BiLSTM model. We represent each token t′\ni of s′using the learned embedding matrix\nEseqtoken. Then s′can be encoded as:\nht′\n1 ,..., ht′\nT\n= BiLSTM(Eseqtoken\nt′\n1\n,..., Eseqtoken\nt′\nT\n) (5)\nwhere ht′\ni\nis the hidden state of the BiLSTM model for the token t′\ni in s′and T is the length of\ns′. We multiply [ht′\n1 ; ...; ht′\nT\n] with the similarity score z, computed from Step 1, and concatenate\nit with the graph encoding results (i.e., the GNN encoder outputs) to obtain the input, namely,\n[GNNoutput; zht′\n1 ; ...; zht′\nT\n], to the decoder.\n2.3 A TTENTION -BASED DYNAMIC GRAPH\nDue to that GNN-based encoders usually consider the k-hop neighborhood, the global relation among\nnodes in the static graph (see Section 2.2.1) may be ignored. In order to better capture the global\nsemantics of source code, based on the static graph, we propose to dynamically construct a graph via\nstructure-aware global attention mechanism, which allows message passing among any pair of nodes.\nThe attention-based dynamic graph can better capture the global dependency among nodes, and thus\nsupplement the static graph.\nStructure-aware Global Attention.The construction of the dynamic graph is motivated by the\nstructure-aware self-attention mechanism proposed in Zhu et al. (2019). Given the static graph, we\ncompute a corresponding dense adjacency matrix Adyn based on a structure-aware global attention\nmechanism, and obtain the constructed graph, namely, attention-based dynamic graph.\nAdyn\nv,u = ReLU(hT\nv WQ)(ReLU(hT\nu WK) + ReLU(eT\nv,uWR))T\n√\nd\n(6)\nwhere hv,hu ∈comp are the augmented node embedding for any node pair(v,u) in the CPG. Note\nthat the global attention considers each pair of nodes of the CPG, regardless of whether there is an\nedge between them. ev,u ∈Rde is the edge embedding and WQ,WK ∈Rd×d, WR ∈Rde×d are\nparameter matrices, de and dare the dimensions of edge embedding and node embedding, respectively.\nThe adjacency matrix Adyn will be further row normalized to obtain ˜Adyn, which will be used to\ncompute dynamic message passing (see Section 2.4).\n˜Adyn = softmax(Adyn) (7)\n2.4 H YBRID GNN\nTo better incorporate the information of the static graph and the dynamic graph, we propose the\nHybrid Message Passing (HMP), which are performed on both retrieval-augmented static graph and\nattention-based dynamic graph.\nStatic Message Passing.For every node vat each computation hop kin the static graph, we apply\nan aggregation function to calculate the aggregated vector hk\nv by considering a set of neighboring\nnode embeddings computed from the previous hop.\nhk\nv = SUM({hk−1\nu |∀u∈N(v)}) (8)\nwhere N(v) is a set of the neighboring nodes which are directly connected with v. For each node v,\nh0\nv is the initial augmented node embedding of v, i.e., hv ∈comp.\nDynamic Message Passing. The node information and edge information are propagated on the\nattention-based dynamic graph with the adjacency matrices ˜Adyn, deﬁned as\nh\n′k\nv =\n∑\nu\n˜Adyn\nv,u (WV h\n′k−1\nu + WF ev,u) (9)\nwhere vand uare any pair of nodes, WV ∈Rd×d, WF ∈Rd×de are learned matrices, and ev,u\nis the embedding of the edge connecting v and u. Similarly, h\n′0\nv is the initial augmented node\nembedding of vin comp.\n5\nPublished as a conference paper at ICLR 2021\nHybrid Message Passing. Given the static/dynamic aggregated vectors hk\nv/h\n′k\nv for static and\ndynamic graphs, we fuse both vectors and feed the resulting vector to a Gated Recurrent Unit (GRU)\nto update node representations.\nfk\nv = GRU(fk−1\nv , Fuse(hk\nv, h\n′k\nv )) (10)\nwhere f0\nv is the augmented node initialization in comp. The fusion function Fuse is designed as a\ngated sum of two inputs.\nFuse(a,b) =z ⊙a + (1−z) ⊙b z = σ(Wz[a; b; a ⊙b; a −b] +bz) (11)\nwhere Wz and bz are learnable weight matrix and vector, ⊙is the component-wise multiplication, σ\nis a sigmoid function and z is a gating vector. After nhops of GNN computation, we obtain the ﬁnal\nnode representation fn\nv and then apply max-pooling over all nodes {fn\nv |∀v ∈V} to get the graph\nrepresentation.\n2.5 D ECODER\nThe decoder is similar with other state-of-the-art Seq2seq models (Bahdanau et al., 2014; Luong\net al., 2015) where an attention-based LSTM decoder is used. The decoder takes the input of the\nconcatenation of the node representation and the representation of the retrieved summary s′, namely,\n[fn\nv1 ; ...; fn\nvm; zht′\n1 ; ...; zht′\nT\n], where mis the number of nodes in the input CPG graph. The initial\nhidden state of the decoder is the fusion (Eq. 11) of the graph representation and the weighted (i.e.,\nmultiply similarity score z) ﬁnal state of the retrieved summary BiLSTM encoder.\nWe train the model with the cross-entropy loss, deﬁned as L= ∑\nt −logP(s∗\nt |c,s∗\n<t), where s∗\nt is\nthe word at the t-th position of the ground-truth output and cis the source code of the function. To\nalleviate the exposure bias, we utilize schedule teacher forcing (Bengio et al., 2015). During the\ninference, we use beam search to generate ﬁnal results.\n3 E XPERIMENTS\n3.1 S ETUP\nWe evaluate our proposed framework against a number of state-of-the-art methods. Speciﬁcally,\nwe classify the selected baseline methods into three groups: 1) Retrieval-based approaches: TF-\nIDF (Haiduc et al., 2010) and NNGen (Liu et al., 2018), 2) Sequence-based approaches: CODE-\nNN (Iyer et al., 2016; Barone & Sennrich, 2017), Transformer (Ahmad et al., 2020), Hybrid-\nDRL (Wan et al., 2018), Rencos (Zhang et al., 2020) and Dual model (Wei et al., 2019), 3) Graph-\nbased approaches: SeqGNN (Fernandes et al., 2018). In addition, we implemented two another\ngraph-based baselines: GCN2Seq and GAT2Seq, which respectively adopt the Graph Convolution\n(Kipf & Welling, 2016) and Graph Attention (Velickovic et al., 2018) as the encoder and a LSTM as\nthe decoder for generating summaries. Note that Rencos (Zhang et al., 2020) combines the retrieval\ninformation into Seq2Seq model, we classify it into Sequence-based approaches. More detailed\ndescription about baselines and the conﬁguration of HGNN can be found in the Appendix B and C.\nExisting benchmarks (Barone & Sennrich, 2017; Hu et al., 2018b) are all based on high-level\nprogramming language i.e., Java, Python. Furthermore, they have been conﬁrmed to have extensive\nduplication, making the model overﬁt to the training data that overlapped with the testset (Fernandes\net al., 2018; Allamanis, 2019). We are the ﬁrst to explore neural summarization on C programming\nlanguage, and make our C Code Summarization Dataset (CCSD) public to beneﬁt academia and\nindustry. We crawled from popular C repositories on GitHub and extracted function-summary pairs\nbased on the documents of functions. After a deduplication process, we kept 95k+ unique function-\nsummary pairs. To further test the model generalization ability, we construct in-domain functions\nand out-of-domain functions by dividing the projects into two sets, denoted as aand b. For each\nproject in a, we randomly select some of the functions in this project as the training data and the\nunselected functions are the in-domain validation/test data. All functions in projects bare regarded as\nout-of-domain test data. Finally, we obtain 84,316 training functions, 4,432 in-domain validation\nfunctions, 4,203 in-domain test functions and 2,330 out-of-domain test functions. For the retrieval\naugmentation, we use the training set as the retrieval database, i.e., D′= D(see Step 1 in Section\n2.2.2). For more details about data processing, please refer to Appendix D.\n6\nPublished as a conference paper at ICLR 2021\nTable 1: Automatic evaluation results (in %) on the CCSD test set.\nIn-domain Out-of-domain OverallMethods BLEU-4 ROUGE-L METEOR BLEU-4 ROUGE-L METEOR BLEU-4 ROUGE-L METEOR\nTF-IDF 15.20 27.98 13.74 5.50 15.37 6.84 12.19 23.49 11.43\nNNGen 15.97 28.14 13.82 5.74 16.33 7.18 12.76 23.93 11.58\nCODE-NN 10.08 26.17 11.33 3.86 15.25 6.19 8.24 22.28 9.61\nHybrid-DRL 9.29 30.00 12.47 6.30 24.19 10.30 8.42 28.64 11.73\nTransformer 12.91 28.04 13.83 5.75 18.62 9.89 10.69 24.65 12.02\nDual Model 11.49 29.20 13.24 5.25 21.31 9.14 9.61 26.40 11.87\nRencos 14.80 31.41 14.64 7.54 23.12 10.35 12.59 28.45 13.21\nGCN2Seq 9.79 26.59 11.65 4.06 18.96 7.76 7.91 23.67 10.23\nGAT2Seq 10.52 26.17 11.88 3.80 16.94 6.73 8.29 22.63 10.00\nSeqGNN 10.51 29.84 13.14 4.94 20.80 9.50 8.87 26.34 11.93\nHGNN w/o augment & static 11.75 29.59 13.86 5.57 22.14 9.41 9.98 26.94 12.05\nHGNN w/o augment & dynamic 11.85 29.51 13.54 5.45 21.89 9.59 9.93 26.80 12.21\nHGNN w/o augment 12.33 29.99 13.78 5.45 22.07 9.46 10.26 27.17 12.32\nHGNN w/o static 15.93 33.67 15.67 7.72 24.69 10.63 13.44 30.47 13.98\nHGNN w/o dynamic 15.77 33.84 15.67 7.64 24.72 10.73 13.31 30.59 14.01\nHGNN 16.72 34.29 16.25 7.85 24.74 11.05 14.01 30.89 14.50\nSimilar to previous works (Zhang et al., 2020; Wan et al., 2018; Fernandes et al., 2018; Iyer et al.,\n2016), BLEU (Papineni et al., 2002), METEOR (Banerjee & Lavie, 2005) and ROUGE-L (Lin, 2004)\nare used as our automatic evaluation metrics. These metrics are popular for evaluating machine\ntranslation and text summarization tasks. Except for these automatic metrics, we also conduct a\nhuman evaluation study. We invite 5 PhD students and 10 master students as volunteers, who have\nrich C programming experiences. The volunteers are asked to rank summaries generated from\nthe anonymized approaches from 1 to 5 ( i.e., 1: Poor, 2: Marginal, 3: Acceptable, 4: Good, 5:\nExcellent) based on the relevance of the generated summary to the source code and the degree of\nsimilarity between the generated summary and the actual summary. Speciﬁcally, we randomly choose\n50 functions for each model with the corresponding generated summaries and ground-truths. We\ncalculate the average score and the higher the score, the better the quality.\n3.2 C OMPARISON WITH THE BASELINES\nTable 1 shows the evaluation results including two parts: the comparison with baselines and the\nablation study. Consider the comparison with state-of-the-art baselines, in general, we ﬁnd that\nour proposed model outperforms existing methods by a signiﬁcant margin on both in-domain and\nout-of-domain datasets, and shows good generalization performance. Compared with others, on\nin-domain dataset, the retrieval-based approaches could achieve competitive performance on BLEU-4,\nhowever ROUGE-L and METEOR are fare less than ours. Moreover, they do not perform well on\nthe out-of-domain dataset. Compared with the graph-based approaches (i.e., GCN2Seq, GAT2Seq\nand SeqGNN), even without augmentation (HGNN w/o augment), our approach still outperforms\nthem, which further demonstrates the effectiveness of Hybrid GNN for additionally capturing global\ngraph information. Compared with Rencos that also considers the retrieved information in the\nSeq2Seq model, its performance is still lower than HGNN. On the overall dataset including both\nof in-domain and out-of-domain data, our model achieves 14.01, 30.89 and 14.50, outperforming\ncurrent state-of-the-art method Rencos by 1.42, 2.44 and 1.29 in terms of BLEU-4, ROUGE-L and\nMETEOR metrics.\n3.3 A BLATION STUDY\nWe also conduct an ablation study to evaluate the impact of different components of our framework,\ne.g., retrieval-based augmentation, static graph and dynamic graph in the last row of Table 1. Overall,\nwe found that 1) retrieval-augmented mechanism could contribute to the overall model performance\n(HGNN vs. HGNN w/o augment). Compared with HGNN, we see that the performance of HGNN w/o\nstatic and HGNN w/o dynamic decreases, which demonstrates the effectiveness of the Hybrid GNN\nand 2) the performance without static graph is worse than the performance without dynamic graph in\nROUGE-L and METEOR, however, BLEU-4 is higher than the performance without dynamic graph.\nTo further understand the impact of the static graph and dynamic graph, we evaluate the performance\nwithout augmentation and static graph/dynamic graph (see HGNN w/o augment& static and HGNN\nw/o augment& dynamic ). Compared with HGNN w/o augment , the results further conﬁrm the\neffectiveness of the Hybrid GNN (i.e., static graph and dynamic graph).\n7\nPublished as a conference paper at ICLR 2021\nTable 2: Human evaluation results on the CCSD test set.\nMetrics NNGen Transformer Rencos SeqGNN HGNN\nRelevance 3.23 3.17 3.48 3.09 3.69\nSimilarity 3.18 3.02 3.32 3.06 3.51\nTable 3: Examples of generated summaries on the CCSD test set.\nExample Example 1 Example 2\nSource Code\nstatic void strInit(Str *p){\np->z = 0;\np->nAlloc = 0;\np->nUsed = 0;\n}\nvoid ReleaseCedar(CEDAR *c){\nif (c == NULL)\nreturn;\nif (Release(c->ref) == 0)\nCleanupCedar(c);\n}\nGround-Truth initialize a str object release reference of the cedar\nNNGen free the string release the virtual host\nTransformer reset a string release of the cancel object\nRencos append a raw string to the json string release of the cancel object\nSeqGNN initialize the string release cedar communication mode\nHGNN initialize a string object release reference of cedar\nWe also conduct experiments to investigate the impact of code-based augmentation and summary-\nbased augmentation. Overall, we found that the summary-based augmentation could contribute more\nthan the code-based augmentation. For example, after adding the code-based augmentation, the\nperformance can be 10.22, 27.54 and 12.49 in terms of BLUE-4, ROUGE-L and METEOR on the\noverall dataset. With the summary-based augmentation, the results can reach to 13.76, 30.59 and\n14.11. Compared with the results without augmentation (i.e., 10.26. 27.17, 12.32 with HGNN w/o\naugment), we can see that code-based augmentation could have some improvement, but the effect\nis not signiﬁcant compared with summary-based augmentation. We conjecture that, due to that the\ncode and summary are heterogeneous, the summary-based augmentation has a more direct impact on\nthe code summarization task. When combining both code-based augmentation and summary-based\naugmentation, we can achieve the best results (i.e., 14.01, 30.89, 14.50). We plan to explore more\ncode-based augmentation (e.g., semantic-equivalent code transformation) in our future work.\n3.4 H UMAN EVALUATION\nAs shown in Table 2, we perform a human evaluation on the overall dataset to assess the quality\nof the generated summaries by our approach, NNGen, Transformer, Rencos and SeqGNN in terms\nof relevance and similarity. As depicted in Table 1, NNGen, Rencos and SeqGNN are the best\nretrieval-based, sequence-based, and graph-based approaches, respectively. We also compare with\nTransformer as it has been widely used in natural language processing. The results show that our\nmethod can generate better summaries which are more relevant with the source code and more similar\nwith the ground-truth summaries.\n3.5 C ASE STUDY\nTo perform qualitative analysis, we present two examples with generated summaries by different\nmethods from the overall data set, shown in Table 3. We can see that, in the ﬁrst example, our\napproach can learn more code semantics, i.e., p is a self-deﬁned struct variable. Thus, we could\ngenerate a token object for the variable p. However, other models can only produce string. Example 2\nis a more difﬁcult function with the functionality to “release reference of cedar”, as compared to other\nbaselines, our approach effectively captures the functionality and generates a more precise summary.\n3.6 E XTENSION ON THE PYTHON DATASET\nWe conducted additional experiments on a public dataset, i.e., the Python Code Summarization\nDataset (PCSD), which was also used in Rencos (the most competitive baseline in our paper). We\nfollow the setting of Rencos and split PCSD into the training set, validation set and testing set with\nfractions of 60%, 20% and 20%. We construct the static graph based on AST. The decoding step\nis set to 50, followed by Rencos, and the other settings are the same with CCSD. We compare our\nmethods on PCSD against various competitive baselines, i.e., NNGen, CODE-NN, Rencos and\n8\nPublished as a conference paper at ICLR 2021\nTable 4: Automatic evaluation results (in %) on the PCSD test set.\nMethods BLEU-4 ROUGE-L METEOR\nNNGen 21.60 31.61 15.96\nCODE-NN 16.39 28.99 13.68\nTransformer 17.06 31.16 14.37\nRencos 24.02 36.21 18.07\nHGNN w/o static 24.06 38.28 18.66\nHGNN w/o dynamic 24.13 38.64 18.93\nHGNN 24.42 39.91 19.48\nTransformer, which are either retrieval-based, generation-based or hybrid methods. The results are\nshown in Table 4. The results indicate that, compared with the best results from NNGen, CODE-NN,\nRencos and Transformer, our method can improve the performance by 0.40, 3.70 and 1.41 in terms of\nBLEU-4, ROUGE-L and METEOR. We also conduct the ablation study on PCSD to demonstrate\nthe usefulness of the static graph (i.e., HGNN w/o dynamic) and dynamic graph (i.e., HGNN w/o\nstatic). The results also demonstrate that both static graph and dynamic graph can contribute to our\nframework. In summary, the results on both our released benchmark (CCSD) and existing benchmark\n(PCSD) demonstrate the effectiveness and the scalability of our method.\n4 R ELATED WORK\nSource Code SummarizationEarly works (Eddy et al., 2013; Haiduc et al., 2010; Wong et al., 2015;\n2013) for code summarization focused on using information retrieval to retrieve summaries. Later\nworks attempted to employ attentional Seq2Seq model on the source code (Iyer et al., 2016; Siow\net al., 2020) or some variants, i.e., AST (Hu et al., 2018a; Alon et al., 2018; Liu et al., 2020) for\ngeneration. However, these works are based on sequential models, ignoring rich code semantics.\nSome latest attempts (LeClair et al., 2020; Fernandes et al., 2018) embedded program semantics into\nGNNs. but they mainly rely on simple representations, which are limited to learn full semantics.\nGraph Neural NetworksOver the past few years, GNNs (Li et al., 2015; Hamilton et al., 2017;\nKipf & Welling, 2016; Chen et al., 2020b) have attracted increasing attention with many successful\napplications in computer vision (Norcliffe-Brown et al., 2018), natural language processing (Xu et al.,\n2018a; Chen et al., 2020d;c;e). Because by design GNNs can model graph-structured data, recently,\nsome works have extended the widely used Seq2Seq architectures to Graph2Seq architectures for\nvarious tasks including machine translation (Beck et al., 2018), and graph (e.g., AMR, SQL)-to-text\ngeneration (Zhu et al., 2019; Xu et al., 2018b). Some works have also attempted to encode programs\nwith graphs for diverse tasks e.g., V ARNAMING/V ARMISUSE (Allamanis et al., 2017), Source\nCode Vulnerability Detection (Zhou et al., 2019). As compared to these works, we innovate a hybrid\nmessage passing GNN performed on both static graph and dynamic graph for message fusion.\n5 C ONCLUSION AND FUTURE WORK\nIn this paper, we proposed a general-purpose framework for automatic code summarization. A novel\nretrieval-augmented mechanism is proposed for combining the beneﬁts of both retrieval-based and\ngeneration-based approaches. Moreover, to capture global semantics among nodes, we develop a\nhybrid message passing GNN based on both static and dynamic graphs. The evaluation shows that\nour approach improves state-of-the-art techniques substantially. Our future work includes: 1) we plan\nto introduce more information such as API knowledge to learn the better semantics of programs, 2)\nwe explore more code-based augmentation techniques to improve the performance and 3) we plan to\nadopt the existing techniques such as (Du et al., 2019; Xie et al., 2019a;b; Ma et al., 2018) to evaluate\nthe robustness of the trained model.\n6 A CKNOWLEDGEMENT\nThis research is supported by the National Research Foundation, Singapore under its AI Singapore\nProgramme (AISG Award No: AISG2-RP-2020-019), the National Research Foundation under its\nNational Cybersecurity R&D Program (Award No. NRF2018NCR-NCR005-0001), the Singapore\nNational Research Foundation under NCR Award Number NRF2018NCR-NSOE003-0001 and NRF\nInvestigatorship NRFI06-2020-0022.\n9\nPublished as a conference paper at ICLR 2021\nREFERENCES\nWasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang. A transformer-based\napproach for source code summarization. arXiv preprint arXiv:2005.00653, 2020.\nMiltiadis Allamanis. The adverse effects of code duplication in machine learning models of code. In\nProceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms,\nand Reﬂections on Programming and Software, pp. 143–153, 2019.\nMiltiadis Allamanis, Marc Brockschmidt, and Mahmoud Khademi. Learning to represent programs\nwith graphs. arXiv preprint arXiv:1711.00740, 2017.\nMiltiadis Allamanis, Earl T Barr, Premkumar Devanbu, and Charles Sutton. A survey of machine\nlearning for big code and naturalness. ACM Computing Surveys (CSUR), 51(4):1–37, 2018.\nUri Alon, Shaked Brody, Omer Levy, and Eran Yahav. code2seq: Generating sequences from\nstructured representations of code. arXiv preprint arXiv:1808.01400, 2018.\nDzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\nlearning to align and translate. arXiv preprint arXiv:1409.0473, 2014.\nSatanjeev Banerjee and Alon Lavie. Meteor: An automatic metric for mt evaluation with improved\ncorrelation with human judgments. In Proceedings of the acl workshop on intrinsic and extrinsic\nevaluation measures for machine translation and/or summarization, pp. 65–72, 2005.\nAntonio Valerio Miceli Barone and Rico Sennrich. A parallel corpus of python functions and\ndocumentation strings for automated code documentation and code generation. arXiv preprint\narXiv:1707.02275, 2017.\nDaniel Beck, Gholamreza Haffari, and Trevor Cohn. Graph-to-sequence learning using gated graph\nneural networks. arXiv preprint arXiv:1806.09835, 2018.\nRichard Bellman. Dynamic programming. Science, 153(3731):34–37, 1966.\nSamy Bengio, Oriol Vinyals, Navdeep Jaitly, and Noam Shazeer. Scheduled sampling for sequence\nprediction with recurrent neural networks. In Advances in Neural Information Processing Systems,\npp. 1171–1179, 2015.\nDeli Chen, Yankai Lin, Wei Li, Peng Li, Jie Zhou, and Xu Sun. Measuring and relieving the over-\nsmoothing problem for graph neural networks from the topological view. In AAAI, pp. 3438–3445,\n2020a.\nYu Chen, Lingfei Wu, and Mohammed Zaki. Iterative deep graph learning for graph neural networks:\nBetter and robust node embeddings. Advances in Neural Information Processing Systems , 33,\n2020b.\nYu Chen, Lingfei Wu, and Mohammed J. Zaki. Graphﬂow: Exploiting conversation ﬂow with\ngraph neural networks for conversational machine comprehension. In Proceedings of the Twenty-\nNinth International Joint Conference on Artiﬁcial Intelligence, pp. 1230–1236. International Joint\nConferences on Artiﬁcial Intelligence Organization, 2020c.\nYu Chen, Lingfei Wu, and Mohammed J. Zaki. Reinforcement learning based graph-to-sequence\nmodel for natural question generation. In Proceedings of the 8th International Conference on\nLearning Representations, Apr. 26-30, 2020d.\nYu Chen, Lingfei Wu, and Mohammed J Zaki. Toward subgraph guided knowledge graph question\ngeneration with graph neural networks. arXiv preprint arXiv:2004.06015, 2020e.\nXiaoning Du, Xiaofei Xie, Yi Li, Lei Ma, Yang Liu, and Jianjun Zhao. Deepstellar: Model-based\nquantitative analysis of stateful deep learning systems. In Proceedings of the 2019 27th ACM Joint\nMeeting on European Software Engineering Conference and Symposium on the Foundations of\nSoftware Engineering, pp. 477–487, 2019.\n10\nPublished as a conference paper at ICLR 2021\nBrian P Eddy, Jeffrey A Robinson, Nicholas A Kraft, and Jeffrey C Carver. Evaluating source code\nsummarization techniques: Replication and expansion. In 2013 21st International Conference on\nProgram Comprehension (ICPC), pp. 13–22. IEEE, 2013.\nPatrick Fernandes, Miltiadis Allamanis, and Marc Brockschmidt. Structured neural summarization.\narXiv preprint arXiv:1811.01824, 2018.\nSonia Haiduc, Jairo Aponte, Laura Moreno, and Andrian Marcus. On the use of automated text\nsummarization techniques for summarizing source code. In 2010 17th Working Conference on\nReverse Engineering, pp. 35–44. IEEE, 2010.\nWill Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs. In\nAdvances in neural information processing systems, pp. 1024–1034, 2017.\nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image\nrecognition. In Proceedings of the IEEE conference on computer vision and pattern recognition,\npp. 770–778, 2016.\nSepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation, 9(8):\n1735–1780, 1997.\nXing Hu, Ge Li, Xin Xia, David Lo, and Zhi Jin. Deep code comment generation. In Proceedings of\nthe 26th Conference on Program Comprehension, pp. 200–210, 2018a.\nXing Hu, Ge Li, Xin Xia, David Lo, Shuai Lu, and Zhi Jin. Summarizing source code with transferred\napi knowledge. 2018b.\nSrinivasan Iyer, Ioannis Konstas, Alvin Cheung, and Luke Zettlemoyer. Summarizing source code\nusing a neural attention model. In Proceedings of the 54th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers), pp. 2073–2083, 2016.\nSiyuan Jiang, Ameer Armaly, and Collin McMillan. Automatically generating commit messages\nfrom diffs using neural machine translation. In 2017 32nd IEEE/ACM International Conference on\nAutomated Software Engineering (ASE), pp. 135–146. IEEE, 2017.\nToshihiro Kamiya, Shinji Kusumoto, and Katsuro Inoue. Ccﬁnder: a multilinguistic token-based code\nclone detection system for large scale source code. IEEE Transactions on Software Engineering,\n28(7):654–670, 2002.\nThomas N Kipf and Max Welling. Semi-supervised classiﬁcation with graph convolutional networks.\narXiv preprint arXiv:1609.02907, 2016.\nAlexander LeClair, Sakib Haque, Linfgei Wu, and Collin McMillan. Improved code summarization\nvia a graph neural network. arXiv preprint arXiv:2004.02843, 2020.\nGuohao Li, Matthias Müller, Ali K. Thabet, and Bernard Ghanem. Deepgcns: Can gcns go as deep\nas cnns? In 2019 IEEE/CVF International Conference on Computer Vision, ICCV 2019, Seoul,\nKorea (South), October 27 - November 2, 2019, pp. 9266–9275. IEEE, 2019. doi: 10.1109/ICCV .\n2019.00936. URL https://doi.org/10.1109/ICCV.2019.00936.\nYujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. Gated graph sequence neural\nnetworks. arXiv preprint arXiv:1511.05493, 2015.\nZhenmin Li, Shan Lu, Suvda Myagmar, and Yuanyuan Zhou. Cp-miner: Finding copy-paste and\nrelated bugs in large-scale software code. IEEE Transactions on software Engineering, 32(3):\n176–192, 2006.\nChin-Yew Lin. ROUGE: A package for automatic evaluation of summaries. In Text Summarization\nBranches Out, pp. 74–81. Association for Computational Linguistics, July 2004.\nShangqing Liu, Cuiyun Gao, Sen Chen, Nie Lun Yiu, and Yang Liu. Atom: Commit message\ngeneration based on abstract syntax tree and hybrid ranking. IEEE Transactions on Software\nEngineering, 2020.\n11\nPublished as a conference paper at ICLR 2021\nZhongxin Liu, Xin Xia, Ahmed E Hassan, David Lo, Zhenchang Xing, and Xinyu Wang. Neural-\nmachine-translation-based commit message generation: how far are we? In Proceedings of the\n33rd ACM/IEEE International Conference on Automated Software Engineering , pp. 373–384,\n2018.\nMinh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-based\nneural machine translation. arXiv preprint arXiv:1508.04025, 2015.\nLei Ma, Felix Juefei-Xu, Fuyuan Zhang, Jiyuan Sun, Minhui Xue, Bo Li, Chunyang Chen, Ting Su,\nLi Li, Yang Liu, et al. Deepgauge: Multi-granularity testing criteria for deep learning systems. In\nProceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering,\npp. 120–131, 2018.\nWill Norcliffe-Brown, Stathis Vafeias, and Sarah Parisot. Learning conditioned graph structures for\ninterpretable visual question answering. In Advances in Neural Information Processing Systems,\npp. 8344–8353, 2018.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic\nevaluation of machine translation. In Proceedings of the 40th annual meeting on association for\ncomputational linguistics, pp. 311–318. Association for Computational Linguistics, 2002.\nJing Kai Siow, Cuiyun Gao, Lingling Fan, Sen Chen, and Yang Liu. Core: Automating review\nrecommendation for code changes. In 2020 IEEE 27th International Conference on Software\nAnalysis, Evolution and Reengineering (SANER), pp. 284–295. IEEE, 2020.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information\nprocessing systems, pp. 5998–6008, 2017.\nPetar Velickovic, Guillem Cucurull, A. Casanova, A. Romero, P. Liò, and Yoshua Bengio. Graph\nattention networks. ArXiv, abs/1710.10903, 2018.\nYao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu, and Philip S Yu. Improving\nautomatic source code summarization via deep reinforcement learning. In Proceedings of the 33rd\nACM/IEEE International Conference on Automated Software Engineering, pp. 397–407, 2018.\nBolin Wei, Ge Li, Xin Xia, Zhiyi Fu, and Zhi Jin. Code generation as a dual task of code summariza-\ntion. In Advances in Neural Information Processing Systems, pp. 6563–6573, 2019.\nEdmund Wong, Jinqiu Yang, and Lin Tan. Autocomment: Mining question and answer sites for\nautomatic comment generation. In 2013 28th IEEE/ACM International Conference on Automated\nSoftware Engineering (ASE), pp. 562–567. IEEE, 2013.\nEdmund Wong, Taiyue Liu, and Lin Tan. Clocom: Mining existing source code for automatic\ncomment generation. In 2015 IEEE 22nd International Conference on Software Analysis, Evolution,\nand Reengineering (SANER), pp. 380–389. IEEE, 2015.\nXiaofei Xie, Lei Ma, Felix Juefei-Xu, Minhui Xue, Hongxu Chen, Yang Liu, Jianjun Zhao, Bo Li,\nJianxiong Yin, and Simon See. Deephunter: a coverage-guided fuzz testing framework for deep\nneural networks. In Proceedings of the 28th ACM SIGSOFT International Symposium on Software\nTesting and Analysis, pp. 146–157, 2019a.\nXiaofei Xie, Lei Ma, Haijun Wang, Yuekang Li, Yang Liu, and Xiaohong Li. Diffchaser: Detecting\ndisagreements for deep neural networks. In IJCAI, pp. 5772–5778, 2019b.\nKun Xu, Lingfei Wu, Zhiguo Wang, and Vadim Sheinin. Graph2seq: Graph to sequence learning\nwith attention-based neural networks. arXiv preprint arXiv:1804.00823, 2018a.\nKun Xu, Lingfei Wu, Zhiguo Wang, Mo Yu, Liwei Chen, and Vadim Sheinin. Sql-to-text generation\nwith graph-to-sequence model. arXiv preprint arXiv:1809.05255, 2018b.\nFabian Yamaguchi, Nico Golde, Daniel Arp, and Konrad Rieck. Modeling and discovering vulnera-\nbilities with code property graphs. In 2014 IEEE Symposium on Security and Privacy, pp. 590–604.\nIEEE, 2014.\n12\nPublished as a conference paper at ICLR 2021\nJian Zhang, Xu Wang, Hongyu Zhang, Hailong Sun, and Xudong Liu. Retrieval-based neural\nsource code summarization. In Proceedings of the 42nd International Conference on Software\nEngineering. IEEE, 2020.\nLingxiao Zhao and Leman Akoglu. Pairnorm: Tackling oversmoothing in gnns. arXiv preprint\narXiv:1909.12223, 2019.\nYaqin Zhou, Shangqing Liu, Jingkai Siow, Xiaoning Du, and Yang Liu. Devign: Effective vulnera-\nbility identiﬁcation by learning comprehensive program semantics via graph neural networks. In\nAdvances in Neural Information Processing Systems, pp. 10197–10207, 2019.\nJie Zhu, Junhui Li, Muhua Zhu, Longhua Qian, Min Zhang, and Guodong Zhou. Modeling graph\nstructure in transformer for better amr-to-text generation. arXiv preprint arXiv:1909.00136, 2019.\n13\nPublished as a conference paper at ICLR 2021\nAppendices\nA D ETAILS ON CODE PROPERTY GRAPH\nCode Property Graph (CPG) (Yamaguchi et al., 2014), which is constructed on abstract syntax tree\n(AST), combines different edges (i.e., Flow to, Control) to represent the semantics of the program.\nWe describe each representation combining with Figure 2 as follows:\n• Abstract Syntax Tree (AST).AST contains syntactic information for a program and omits irrele-\nvant details that have no effect on the semantics. Figure 2 shows the completed AST nodes on the\nleft simple program and each node has a code sequence in the ﬁrst line and type attribute in the\nsecond line. The black arrows represent the child-parent relations among ASTs.\n• Control Flow Graph (CFG).Compared with AST highlighting the syntactic structure, CFG\ndisplays statement execution order, i.e., the possible order in which statements may be executed\nand the conditions that must be met for this to happen. Each statement in the program is treated as\nan independent node as well as a designated entry and exit node. Based on the keywords if, for,\ngoto, break and continue, control ﬂow graphs can be easily built and “Flow to” with green dashed\narrows in Figure 2 represents this ﬂow order.\n• Program Dependency Graph (PDG).PDG includes data dependenciesand control dependen-\ncies: 1) data dependencies are described as the deﬁnition of a variable in a statement reaches the\nusage of the same variable at another statement. In Figure 2, the variable “ b” is deﬁned in the\nstatement “int b = a++” and used in “call (b)”. Hence, there is a “Reach” edge with blue arrows\npoint from “int b = a++” to “call (b)”. Furthermore, Deﬁne/Use edge with orange double arrows\ndenotes the deﬁnition and usage of the variable. 2) different from CFG displaying the execution\nprocess of the complete program, control dependencies deﬁne the execution of a statement may be\ndependent on the value of a predicate, which more focus on the statement itself. For instance, the\nstatements “int b = a++” and “call(b)” are only performed “if a is even”. Therefore, a red double\narrow “Control” points from “if (a % 2) == 0” to “int b = a++” and “call(b)”.\nB D ETAILS ON BASELINE METHODS\nWe compare our approach with existing baselines. They can be divided into three groups: Retrieval-\nbased approaches, Sequence-based approaches and Graph-based approaches. For papers that provide\nthe source code, we directly reproduce their methods on CCSD dataset. Otherwise, we reimplement\ntheir approaches with reference to the papers.\nB.1 R ETRIEVAL -BASED APPROACHES\nTF-IDF (Haiduc et al., 2010) is the abbreviation of Term Frequency-Inverse Document Frequency,\nwhich is adopted in the early code summarization (Haiduc et al., 2010). It transforms programs\ninto weight vectors by calculating term frequency and inverse document frequency. We retrieve the\nsummary of the most similar programs by calculating the cosine similarity on the weighted vectors.\nNNGen (Liu et al., 2018) is a retrieved-based approach to produce commit messages for code changes.\nWe reproduce such an algorithm on code summarization. Speciﬁcally, we retrieve the most similar\ntop-k code snippets on a bag-of-words model and prioritizes the summary in terms of BLEU-4 scores\nin top-k code snippets.\nB.2 S EQUENCE -BASED APPROACHES\nCODE-NN (Iyer et al., 2016; Barone & Sennrich, 2017) adopts an attention-based Seq2Seq model\nto generate summaries on the source code.\nTransformer (Ahmad et al., 2020) adopts the transformer architecture (Vaswani et al., 2017) with\nself-attention to capture long dependency in the code for source code summrization.\n14\nPublished as a conference paper at ICLR 2021\nHybrid-DRL (Wan et al., 2018) is a reinforcement learning-based approach, which incorporates AST\nand sequential code snippets into a deep reinforcement learning framework and employ evaluation\nmetrics e.g., BLEU as the reward.\nDual Model(Wei et al., 2019) propose a dual training framework by training code summarization\nand code generation tasks simultaneously to boost each task performance.\nRencos (Zhang et al., 2020) is the retrieval-based Seq2Seq model for code summarization. it utilized\na pretrained Seq2Seq model during the testing phase by computing a joint probability conditioned on\nboth the original source code and retrieved the most similar source code for the summary generation.\nCompared with Rencos, we propose a novel retrieval-augmented mechanism for the similar source\ncode and use it at the model training phase.\nB.3 G RAPH -BASED APPROACHES\nWe also compared with some latest GNN-based works, employing graph neural network for source\ncode summarization.\nGCN2Seq, GAT2Seq modify Graph Convolution Network (Kipf & Welling, 2016) and Graph\nAttention Network (Velickovic et al., 2018) to perform convolution operation and attention operation\non the code property graph for learning and followed by a LSTM to generate summaries. We\nimplement the related code from scratch.\nSeqGNN (Fernandes et al., 2018) combines GGNNs and standard sequence encoders for summa-\nrization. They take the code and relationships between elements of the code as input. Specially, a\nBiLSTM is employed on the code sequence to learn representations and each source code token is\nmodelled as a node in the graph, and employed GGNN for graph-level learning. Since our node\nsequences are sub-sequence of source code rather than individual token, we adjust to slice the output\nof BiLSTM and sum each token representation in node sequences as node initial representation for\nsummarization. Furthermore, we implement the related code from scratch.\nC M ODEL SETTINGS\nWe embed the most frequent 40,000 words in the training set with 512-dims and set the hidden size\nof BiLSTM to 256 and the concatenated state size for both directions is 512. The dropout is set to 0.3\nafter the word embedding layer and BiLSTM. We set GNN hops to 1 for the best performance. The\noptimizer is selected with Adam with an initial learning rate of 0.001. The batch size is set to 64 and\nearly stop for 10. The beam search width is set to 5 as usual. All experiments are conducted on the\nDGX server with four Nvidia Graphics Tesla V100 and each epoch takes 6 minutes averagely. All\nhyperparameters are tuned with grid search on the validation set.\nD D ETAILS ON DATA PREPARATION\nIt is non-trivial to obtain high-quality datasets for code summarization. We noticed that despite some\nprevious works (Barone & Sennrich, 2017; Hu et al., 2018b) released their datasets, however, they\nare all based on high-level programming languages i.e. Java, Python. We are the ﬁrst to explore\nsummarization on C programming language. Speciﬁcally, we crawled from popular C repositories\n(e.g., Linux and QEMU) on GitHub, and then extracted separate function-summary pairs from these\nprojects. Speciﬁcally, we extracted functions and associated comments marked by special characters\n\"/**\" and \"*/\" over the function declaration. These comments can be considered as explanations of\nthe functions. We ﬁltered out functions with line exceeding 1000 and any other comments inside\nthe function, and the ﬁrst sentence was selected as the summary. A similar practice can be found\nin (Jiang et al., 2017). Totally, we collected 500k+ raw function-summary pairs. Furthermore,\nfunctions with token size greater than 150 were removed for computational efﬁciency and there\nwere 130k+ functions left. Since duplication is very common in existing datasets (Fernandes et al.,\n2018), followed by Allamanis (2019), we performed a de-duplication process and removed functions\nwith similarity over 80%. Speciﬁcally, we calculated the cosine similarity by encoding the raw\nfunctions into vectors with sklearn. Finally, we kept 95k+ unique functions. We name this dataset C\nCode Summarization Dataset (CCSD). To testify model generalization ability, we randomly selected\n15\nPublished as a conference paper at ICLR 2021\nTable 5: More Examples of generated summaries on the CCSD test set.\nExample Example 1 Example 2\nSource Code\nstatic void counterMutexFree\n(sqlite3_mutex *p){\nassert(g.isInit);\ng.m.xMutexFree(p->pReal);\nif( p->eType==SQLITE_MUTEX_FAST\n|| p->eType==\nS QLITE_MUTEX_RECURSIVE)\n{\nfree(p);\n}\n}\nstatic void __exit wimax_subsys_exit(void)\n{\nwimax_id_table_release();\ngenl_unregister_family\n(&wimax_gnl_family);\n}\nGround-Truth free a countable mutex shutdown the wimax stack\nNNGen enter a countable mutex unregisters pmcraid event family return value none\nTransformer leave a mutex de initialize wimax driver\nRencos try to enter a mutex unregister the wimax device subsystem\nSeqGNN free a mutex allocated by sqlite3 mutex this function is called when the driver is not held\nHGNN release a mutex free the wimax stack\nRetrieved_code\nstatic int counterMutexTry\n(sqlite3_mutex *p){\nassert( g.isInit );\nassert( p->eType>=0 );\nassert( p->eType<MAX_MUTEXES );\ng.aCounter[p->eType]++;\nif( g.disableTry )\nreturn SQLITE_BUSY;\nreturn g.m.xMutexTry(p->pReal);\n}\nstatic int __init wimax_subsys_init(void){\nint result; d_fnstart(4, NULL, \"()\\n\");\nd_parse_params(D_LEVEL, D_LEVEL_SIZE,\nwimax_debug_params, \"wimax.debug\");\nresult = genl_register_family\n(&wimax_gnl_family);\nif (unlikely(result < 0)) {\npr_err(\"cannot register generic\nnetlink family: %d\\n\", result);\ngoto error_register_family;}\nd_fnend(4, NULL, \"() = 0\\n\");\nreturn 0;\nerror_register_family:\nd_fnend(4, NULL, \"() = %d\\n\", result);\nreturn result;\n}\nRetrieved_summary try to enter a mutex shutdown the wimax stack\nExample Example 3 Example 4\nSource Code\nstatic void udc_dd_free(\nstruct lpc32xx_udc *udc,\nstruct lpc32xx_usbd_dd_gad *dd)\n{\ndma_pool_free(udc->dd_cache,\ndd, dd->this_dma);\n}\nvoid ReleaseSockEvent(SOCK_EVENT *event) {\nif (event == NULL)\n{\nreturn;\n}\nif (Release(event->ref) == 0)\n{\nCleanupSockEvent(event);\n}\n}\nGround-Truth free a dma descriptor release of the socket event\nNNGen allocate a dma descriptor clean up of the socket event\nTransformer free the usb device set the event\nRencos allocate a dma descriptor set of the sock event\nSeqGNN free dma buffers release of the socket\nHGNN free a dma descriptor release the sock event\nRetrieved_code\nstatic struct lpc32xx_usbd_dd_gad\n*udc_dd_alloc(struct\nlpc32xx_udc *udc) {\ndma_addr_t dma;\nstruct lpc32xx_usbd_dd_gad *dd;\ndd = dma_pool_alloc(udc->dd_cache,\nGFP_ATOMIC | GFP_DMA, &dma);\nif (dd)\ndd->this_dma = dma;\nreturn dd;\n}\nvoid SetL2TPServerSockEvent(\nL2TP_SERVER *l2tp,SOCK_EVENT *e){\nif (l2tp == NULL) {\nreturn;}\nif (e != NULL){\nAddRef(e->ref);}\nif (l2tp->SockEvent != NULL){\nReleaseSockEvent(l2tp->SockEvent);\nl2tp->SockEvent = NULL;}\nl2tp->SockEvent = e;}\nRetrieved_summary allocate a dma descriptor set a sock event to the l2tp server\nsome projects as the out-of-domain test set with 2,330 examples and the remaining were randomly\nsplit into train/validation/test with 84,316/4,432/4,203 examples. The open-source code analysis\nplatform Joern (Yamaguchi et al., 2014) was applied to construct the code property graph.\nE M ORE EXAMPLES\nWe show more examples along with the retrieved code and summary by dynamic programming in\nTable 5 and we can ﬁnd that HGNN can generate more high-quality summries based on our approach.\n16",
  "topic": "Automatic summarization",
  "concepts": [
    {
      "name": "Automatic summarization",
      "score": 0.9194777011871338
    },
    {
      "name": "Code (set theory)",
      "score": 0.62642502784729
    },
    {
      "name": "Computer science",
      "score": 0.6065835952758789
    },
    {
      "name": "Information retrieval",
      "score": 0.3904048204421997
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3245888650417328
    },
    {
      "name": "Programming language",
      "score": 0.18781155347824097
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I172675005",
      "name": "Nanyang Technological University",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I2252078561",
      "name": "Meta (Israel)",
      "country": "IL"
    }
  ]
}