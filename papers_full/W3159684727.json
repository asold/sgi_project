{
  "title": "Mechanisms for handling nested dependencies in neural-network language models and humans",
  "url": "https://openalex.org/W3159684727",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A4282320463",
      "name": "Lakretz, Yair",
      "affiliations": [
        "CEA Paris-Saclay",
        "Inserm",
        "Commissariat à l'Énergie Atomique et aux Énergies Alternatives",
        "Université Paris-Saclay",
        "Cognitive Neuroimaging Lab"
      ]
    },
    {
      "id": "https://openalex.org/A4201025914",
      "name": "Hupkes, Dieuwke",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Vergallito, Alessandra",
      "affiliations": [
        "University of Milano-Bicocca"
      ]
    },
    {
      "id": "https://openalex.org/A2754549769",
      "name": "Marelli, Marco",
      "affiliations": [
        "University of Milano-Bicocca"
      ]
    },
    {
      "id": "https://openalex.org/A2230649300",
      "name": "Baroni, Marco",
      "affiliations": [
        "Institució Catalana de Recerca i Estudis Avançats"
      ]
    },
    {
      "id": "https://openalex.org/A1964523432",
      "name": "Dehaene, Stanislas",
      "affiliations": [
        "Commissariat à l'Énergie Atomique et aux Énergies Alternatives",
        "Collège de France",
        "CEA Paris-Saclay",
        "Université Paris-Saclay",
        "Cognitive Neuroimaging Lab",
        "Inserm"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2062163528",
    "https://openalex.org/W6630145886",
    "https://openalex.org/W6746113314",
    "https://openalex.org/W2049139371",
    "https://openalex.org/W2104820986",
    "https://openalex.org/W2055457833",
    "https://openalex.org/W4245765565",
    "https://openalex.org/W4239114023",
    "https://openalex.org/W2146715051",
    "https://openalex.org/W2506660467",
    "https://openalex.org/W2165036621",
    "https://openalex.org/W2915130814",
    "https://openalex.org/W6743596144",
    "https://openalex.org/W1985086416",
    "https://openalex.org/W1906221854",
    "https://openalex.org/W2138017345",
    "https://openalex.org/W2090807592",
    "https://openalex.org/W2110485445",
    "https://openalex.org/W2087946919",
    "https://openalex.org/W2171045029",
    "https://openalex.org/W6756620716",
    "https://openalex.org/W6833865973",
    "https://openalex.org/W2118373646",
    "https://openalex.org/W6624287392",
    "https://openalex.org/W2121824250",
    "https://openalex.org/W2100520417",
    "https://openalex.org/W2171967745",
    "https://openalex.org/W6760695106",
    "https://openalex.org/W1970745658",
    "https://openalex.org/W2117823388",
    "https://openalex.org/W6754333775",
    "https://openalex.org/W6750153154",
    "https://openalex.org/W2119708162",
    "https://openalex.org/W2152633481",
    "https://openalex.org/W2165545766",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2120164466",
    "https://openalex.org/W2129191002",
    "https://openalex.org/W6767801764",
    "https://openalex.org/W2121853833",
    "https://openalex.org/W6750475462",
    "https://openalex.org/W2169882231",
    "https://openalex.org/W3016825020",
    "https://openalex.org/W6764458381",
    "https://openalex.org/W2919115771",
    "https://openalex.org/W2107265154",
    "https://openalex.org/W2549835527",
    "https://openalex.org/W6753745870",
    "https://openalex.org/W2069376821",
    "https://openalex.org/W6754744501",
    "https://openalex.org/W2058877549",
    "https://openalex.org/W6680890276",
    "https://openalex.org/W2009294721",
    "https://openalex.org/W6785674869",
    "https://openalex.org/W2127118940",
    "https://openalex.org/W2111534506",
    "https://openalex.org/W1995672192",
    "https://openalex.org/W2028994331",
    "https://openalex.org/W6726320248",
    "https://openalex.org/W2952022350",
    "https://openalex.org/W2013494846",
    "https://openalex.org/W1968415269",
    "https://openalex.org/W2128863839",
    "https://openalex.org/W2005098917",
    "https://openalex.org/W2021289841",
    "https://openalex.org/W1990526545",
    "https://openalex.org/W2127610235",
    "https://openalex.org/W2122236285",
    "https://openalex.org/W6754203526",
    "https://openalex.org/W2125001590",
    "https://openalex.org/W2922523190",
    "https://openalex.org/W1503689224",
    "https://openalex.org/W3118674731",
    "https://openalex.org/W4244285526",
    "https://openalex.org/W4210984920",
    "https://openalex.org/W2768794963",
    "https://openalex.org/W2986889180",
    "https://openalex.org/W2015797056",
    "https://openalex.org/W4253001367",
    "https://openalex.org/W2798727047",
    "https://openalex.org/W4289552613",
    "https://openalex.org/W2964222268",
    "https://openalex.org/W2167543949",
    "https://openalex.org/W2952208026",
    "https://openalex.org/W2786786057",
    "https://openalex.org/W203060610",
    "https://openalex.org/W4254816979",
    "https://openalex.org/W1974525874",
    "https://openalex.org/W2962961857",
    "https://openalex.org/W918755251",
    "https://openalex.org/W1708874574",
    "https://openalex.org/W2886663262",
    "https://openalex.org/W2963751529",
    "https://openalex.org/W4252108260",
    "https://openalex.org/W2582743722",
    "https://openalex.org/W4300749827",
    "https://openalex.org/W2891399254",
    "https://openalex.org/W1507098069",
    "https://openalex.org/W2324269035",
    "https://openalex.org/W1594217986",
    "https://openalex.org/W2963347649",
    "https://openalex.org/W79667300",
    "https://openalex.org/W2753093910",
    "https://openalex.org/W3103912370",
    "https://openalex.org/W2063915530",
    "https://openalex.org/W2971031791",
    "https://openalex.org/W2612690371",
    "https://openalex.org/W4248107482",
    "https://openalex.org/W1652505363",
    "https://openalex.org/W2144499799",
    "https://openalex.org/W3036699898",
    "https://openalex.org/W2141599568",
    "https://openalex.org/W2963614302",
    "https://openalex.org/W4298742451",
    "https://openalex.org/W182831726",
    "https://openalex.org/W2921890305",
    "https://openalex.org/W4248358431",
    "https://openalex.org/W2606089314",
    "https://openalex.org/W1993750641",
    "https://openalex.org/W2888922637"
  ],
  "abstract": null,
  "full_text": "NESTED DEPENDENCIES IN NLMS AND HUMANS 1\nMechanisms for Handling Nested Dependencies in Neural-Network Language Models\nand Humans\nYair Lakretz\nCognitive Neuroimaging Unit, NeuroSpin center, 91191, Gif-sur-Yvette, France\nDieuwke Hupkes\nILLC, University of Amsterdam, Amsterdam, Netherlands\nAlessandra Vergallito\nUniversity of Milano-Bicocca, Milan, Italy\nMarco Marelli\nUniversity of Milano-Bicocca, Milan, Italy\nNeuroMI, Milan Center for Neuroscience, Milan, Italy\nMarco Baroni ∗\nFacebook AI Research, Paris, France\nCatalan Institute for Research and Advanced Studies, Barcelona, Spain, 08010\nDepartament de Traducció i Ciències del Llenguatge, Universitat Pompeu Fabra, Spain,\n08018\nStanislas Dehaene ∗\nCognitive Neuroimaging Unit, NeuroSpin center, 91191, Gif-sur-Yvette, France\nCollege de France, 11 Place Marcelin Berthelot, 75005 Paris, France\n* Equal senior contribution.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 2\nAbstract\nRecursive processing in sentence comprehension is considered a hallmark of human\nlinguistic abilities. However, its underlying neural mechanisms remain largely unknown.\nWe studied whether a modern artiﬁcial neural network trained with “deep learning”\nmethods mimics a central aspect of human sentence processing, namely the storing of\ngrammatical number and gender information in working memory and its use in\nlong-distance agreement (e.g., capturing the correct number agreement between subject\nand verb when they are separated by other phrases). Although the network, a recurrent\narchitecture with Long Short-Term Memory units, was solely trained to predict the\nnext word in a large corpus, analysis showed the emergence of a very sparse set of\nspecialized units that successfully handled local and long-distance syntactic agreement\nfor grammatical number. However, the simulations also showed that this mechanism\ndoes not support full recursion and fails with some long-range embedded dependencies.\nWe tested the model’s predictions in a behavioral experiment where humans detected\nviolations in number agreement in sentences with systematic variations in the\nsingular/plural status of multiple nouns, with or without embedding. Human and\nmodel error patterns were remarkably similar, showing that the model echoes various\neﬀects observed in human data. However, a key diﬀerence was that, with embedded\nlong-range dependencies, humans remained above chance level, while the model’s\nsystematic errors brought it below chance. Overall, our study shows that exploring the\nways in which modern artiﬁcial neural networks process sentences leads to precise and\ntestable hypotheses about human linguistic performance.\nKeywords:Grammatical agreement, Long-Range Dependencies, Recursion,\nRecurrent Neural Networks, Language Models, Syntactic processing, Relative Clauses.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 3\nMechanisms for Handling Nested Dependencies in Neural-Network Language Models\nand Humans\nIntroduction\nAccording to a popular view in linguistics, the rich expressiveness and open-ended\nnature of language rest onrecursion, the possibly uniquely human ability to process\nnested structures (Chomsky, 1957; Dehaene, Meyniel, Wacongne, Wang, & Pallier,\n2015; Hauser, Chomsky, & Fitch, 2002). We currently know very little about how such\nability is implemented in the brain, and consequently about its scope and limits.\nIn recent years, artiﬁcial neural networks, rebranded as “deep learning” (LeCun,\nBengio, & Hinton, 2015), made tremendous advances in natural language processing\n(Goldberg, 2017). Typically, neural networks are not provided with any explicit\ninformation regarding grammar or other types of linguistic knowledge. Neural Language\nModels (NLMs) are commonly initialized as “tabula rasa” and are solely trained to\npredict the next word in a sentence given the previous words (Mikolov, 2012). Yet,\nthese models achieve impressive performance, not far below that of humans, in tasks\nsuch as question answering or text summarization (Radford et al., 2019).\nUnlike their connectionist progenitors (Rumelhart, McClelland, & PDP Research\nGroup, 1986a, 1986b), modern NLMs are not intended as cognitive models of human\nbehaviour. They are instead developed to be deployed in applications such as\ntranslation systems or online content organizers. Nevertheless,recurrentNLMs (Elman,\n1990; Hochreiter & Schmidhuber, 1997), at least, do share some relevant attributes with\nthe human processing system, such as the property that they receive input\nincrementally and process it in a parallel and distributed way. Furthermore, their\nsuccess in applied natural language processing strongly suggests that they must infer\nnon-trivial linguistic knowledge from the raw data they are exposed to. Combined,\nthese two facts make NLMs akin to an interesting ‘animal model’, whose way to address\na linguistic task might provide insight into how the human processing system tackles\nsimilar challenges (see also McCloskey, 1991).\nHere, we perform an in-depth analysis of nested sentence processing in NLMs, focusing\nNESTED DEPENDENCIES IN NLMS AND HUMANS 4\nin particular on the case of grammatical agreement. Long-distance agreement has\ntraditionally been studied as one of the best indices of online syntactic processing in\nhumans, as it is ruled by hierarchical structures rather than by the linear order of words\nin a sentence (Bock & Miller, 1991; Franck, Vigliocco, & Nicol, 2002). Consider for\nexample the sentence: “Theboysunder the tree knowthe farmers”, where the number\nof the verb (‘know’) depends on its linearly distant subject (‘boys’), and not on the\nimmediately preceding noun ‘tree’ .\nAnalogously, number agreement has also become a standard way to probe grammatical\ngeneralization in NLMs (Bernardy & Lappin, 2017; Giulianelli, Harding, Mohnert,\nHupkes, & Zuidema, 2018; Gulordava, Bojanowski, Grave, Linzen, & Baroni, 2018;\nLinzen, Dupoux, & Goldberg, 2016). Very recently, some steps were taken towards a\nmechanistic understanding of how NLMs perform agreement. Speciﬁcally, Lakretz et al.\n(2019) showed that NLMs trained on a large corpus with English sentences developed a\nnumber-propagation mechanism for long-range dependencies. The core circuit of this\nmechanism is extremely sparse, in the sense that it is comprised of an exceptionally\nsmall number of units. Here, we further investigate this circuitry, test how robust this\nﬁnding is across languages and grammatical features and, importantly, if this knowledge\nabout the mechanism in recurrent NLMs can be useful to learn more abouthuman\nlanguage processing.\nOur starting point is the sparsity of the mechanism found by Lakretz et al. (2019), in\nwhich number information is carried only in two single units (a plural and a singular\none). The recursive power of language allows the construction of sentences with multiple\nnested agreement dependencies – as in: “Theboysthat thefatherunder the tree\nwatchesknowthe farmers” . Lakretz et al. (2019) showed that the NLM’s mechanism is\nrobust to the intervention of such nested hierarchical structures, across several diﬀerent\nsyntactic structure. In sentences like the example above, it could correctly percolate the\nnumber across the outermost long-distance dependency (‘boy/knows’). However, the\nsparsity of the mechanism suggests that the NLM should not be able to process two\nlong-distance dependencies simultaneously: once the mechanism is “ﬁlled” by the\nNESTED DEPENDENCIES IN NLMS AND HUMANS 5\noutermost long-distance dependency (‘boy/knows’) it is not anymore able to also track\nthe number information of the inner long-distance dependency (‘father/watches’). In\nother words, it predicts a failure of the model to handle theinner-mostlong-distance\ndependency in doubly nested sentences. In this paper, we test this prediction and then\nuse our mechanistic understanding of agreement in NLMs as a “hypothesis generator\"\n(Cichy & Kaiser, 2019) about nested agreement processing in humans.\nWe start our current study by conﬁrming that the emergence of a sparse agreement\nmechanism is a stable and robust phenomenon in recurrent NLMs, by replicating the\nﬁndings of Lakretz et al. (2019) with a new language (Italian) and grammatical feature\n(gender). Next, we investigate how the sparsity of the agreement mechanism aﬀects\nrecursive agreement processing, conﬁrming our predictions that the mechanism supports\noutermost agreement across nested structures, but not the inner dependency in multiple\nembedded agreements.\nIn the next part of our study, we test if this pattern is also observed in humans:\nsuppose that humans also use a relatively small fraction of specialized units to store and\nrelease agreement features across long-distance syntactic structures. Then, we might\nobserve a similar asymmetry in handling outer- and innermost dependencies in recursive\nstructures. We run a behavioural experiment with Italian subjects to test this\nhypothesis. The results are intriguing. On the one hand, humans do not display the\nsame dramatic failure to process embedded dependencies we observed in NLMs. On the\nother hand, they are indeed more prone to errors in embedded dependencies than in the\nlonger-range outer ones, in accordance with our predictions. Moreover, a comparison\nbetween NLM and human performance reveals a remarkable degree of similarity.\nOur results thus indicate that NLMs do not achieve genuine recursive processing of\nnested long-range agreements. However, they also show how some degree of hierarchical\nprocessing can be performed by a device, such as the NLM, that did not develop full\nrecursive capabilities. Furthermore, the similarity between the error patterns of humans\nand the model illustrate how a detailed understanding of emergent mechanisms in\nNLMs leads to hypotheses about hierarchical structure processing that are relevant to\nNESTED DEPENDENCIES IN NLMS AND HUMANS 6\nhuman language parsing.\n1 Number Agreement in Neural Language Models\nIn the classic number agreement task (NA-task), subjects are presented with the\nbeginning of a sentence (aka, ‘preamble’) that contains a long-range subject-verb\nrelation, such as: “Thekeysto the cabinet . . . ”, and are asked to predict the verb to\nfollow (e.g., “are”). Human subjects make more agreement errors (e.g., continuing the\npreamble above with “is” instead of “are”) when the intervening noun (aka, ‘attractor’)\nhas a diﬀerent grammatical number than the main subject (as in the preamble above,\nwith plural subject “keys” and singular attractor “cabinet”) (Bock & Miller, 1991).\nBehavioral measures collected during agreement tasks, such as error rates, vary as a\nfunction of the syntactic environment of the long-range dependency. This has provided\nrich data to test hypotheses regarding online syntactic processing in humans (e.g.,\nFranck, Frauenfelder, & Rizzi, 2007; Franck, Lassi, Frauenfelder, & Rizzi, 2006; Franck\net al., 2002).\nStarting with the inﬂuential work of Linzen et al. (2016), a growing literature (e.g.,\nBernardy & Lappin, 2017; Giulianelli et al., 2018; Gulordava et al., 2018; Jumelet,\nZuidema, & Hupkes, 2019; Kuncoro et al., 2018; Linzen & Leonard, 2018) has tested\nNLMs on the NA-task at the behavioural level, showing that these models have\nperformance and error patterns partially resembling those of humans. Recently, Lakretz\net al. (2019) investigated the underlying mechanism of an English NLM during the\nprocessing of a long-range dependency. They identiﬁed a neural circuit in the network\nthat encodes and carries grammatical number across long-range dependencies, showing\nalso that processing in NLMs is sensitive to the structure of the subject-verb\ndependency. We now describe the mainﬁndings in this previous study, followed by a\nreplication of the results in an NLM trained on Italian (Section 2).\n1.1 The NounPP Number-Agreement Task\nThe main NA-task used by Lakretz et al. (2019) contains sentences with a subject-verb\ndependency separated by a prepositional phrase containing an attractor (e.g., “Theboy\nNESTED DEPENDENCIES IN NLMS AND HUMANS 7\nnear the car smiles”), referred to as the ‘NounPP’ task. This task comprises four\nconditions, which correspond to the four possible assignments of grammatical number\nto the main subject and attractor (SS, SP, PS and PP; S-singular, P-plural). A NLM\nwhose weights were optimized on the generic objective of predicting the next word in a\nWikipedia-based corpus was presented with preambles of sentences from this task. The\npredictions of the model for the next word were then extracted, from which error rates\nwere computed.\n1.2 Long-Range Number Units\nHaving veriﬁed that the network could predict the correct number with high accuracy,\nLakretz et al. (2019) tested whether there are units in the network that are crucial to\ncarry grammatical number across long-range dependencies. To identify such units, they\nconducted an ablation study, ablating one unit of the NLM at a time, and re-evaluating\nits performance on the NounPP task. These ablation studies showed that two (out of\n1300) units in the NLM cause a reduction in long-distance agreement performance\ntowards chance level when ablated (short-distance agreement in other NA-tasks was not\naﬀected). One of these units only aﬀects performance when the main subject of the\nsentence is singular, and was therefore called the ‘singular unit’ . The other unit has an\neﬀect with plural subjects only, hence, the ‘plural unit’ . No other unit has a comparable\neﬀect on network performance when ablated. A visualization of state dynamics of the\nsingular and plural units conﬁrmed their role in encoding and carrying through\ngrammatical number across long-range dependency, robustly also in the presence of an\nattractor (Figure 1 in Lakretz et al., 2019).\n1.3 Syntax Units\nSince the activities of the long-range number units follow the structure of the syntactic\nlong-range dependency, Lakretz et al. (2019) tested whether other units in the network\nencode syntactic structure, letting the long-range number units know when to store and\nrelease number information in their encoding. Several units were found to have activity\nthat is predictive about transient syntactic properties of the sentence. In particular, the\nNESTED DEPENDENCIES IN NLMS AND HUMANS 8\nLSTM LSTMLSTM\nLSTM LSTMLSTM\nﬁglio\nLSTM\nLSTM\nil vicino alla\nﬁglio allavicino\nLSTM\nLSTM\nLSTM\nLSTM\nama\namadonna\ndonna\nFigure 1\nGraphical description of a two-layer recurrent neural language model with LSTM cells\n(not discussed here; see, e.g., Goldberg, 2017). At each timestep, the model processes an\ninput word and outputs a probability distribution over potential next words in the\nsentence. The prediction of the output word depends on both the input word and on the\nprevious state of the model, which serves as longer-term context (horizontal arrows in\ntheﬁgure represent therecurrentconnections carrying the previous state through).\nactivation of one of these ‘syntax’ units followed the structure of the main subject-verb\ndependency, consistently across various sentence constructions (Figure 3 in Lakretz et\nal., 2019).\n1.4 Short-Range Number Units\nLakretz et al. (2019) further found that grammatical number information is also\nencoded by other units in the network in a distributed way. Number information can\nstill be decoded from network activity even when the long-range number units are\nremoved. However, the information encoded in these other units is short-lived.\nWhenever a new grammatical number is introduced (e.g., upon encountering a noun or\na verb), activity in these units abruptly switches to represent this last encountered\nnumber. These ‘Short-Range Number Units’ can therefore only support\nnumber-agreement dependencies that do not enfold attractors (e.g., “Theboygracefully\nsmiles”). The presence of short-range number units explains why ablating the\nlong-range circuit only aﬀects agreement in long-distance dependencies.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 9\n2 Processing of a Single Subject-Verb Dependency in the Italian NLM\nWe focus here on Italian instead of English for three reasons. First, we aimed to\nreplicate the English results on another language. Second, the Italian NLM made\navailable by Gulordava et al. (2018) achieves better performance than the English NLM\non nested constructions, which are computationally more demanding compared to\nsentences in the NounPP task explored in Lakretz et al. (2019), and which will\nconstitute the main object of our study. This might be explained by the fact that\nItalian is morpho-syntactically richer than English, making it more important for the\nNLM to pick up grammatical information. Third, in English, the plural is identical to\nthe unmarked form of the verb, which can occur as inﬁnitive, inﬁrst and second person,\nand often as a noun. This makes the occurrence statistics extremely unbalanced in favor\nof plural. *\nFurthermore, agreement in Italian can also occur with respect to gender, for instance, in\nsentences containing predicative adjectives: “ilbambinoaccanto alla madre èbello”\n(“The (m.)boynear the (f.) mother is pretty (m.)”), in which subject and predicate\nagree with respect to both number and gender. This allowed us to test whether the\nprevious results in English hold for another grammatical feature. We hypothesized that\nthere should also exist long-range ‘gender’ units in the network, with dynamics that are\nrobust to possible attractors (e.g., to “madre” above, which is feminine).\nIn this experiment, we followed the same steps described in the previous section for\nEnglish–an ablation study, visualization of unit dynamics and a connectivity analysis. *\n* Gulordava et al. (2018) made available models in English, Italian, Hebrew and Russian, which were\noptimized by conducting a grid search on the language modeling objective, and became since a subject\nof research in several subsequent studies (Futrell et al., 2019; Giulianelli et al., 2018; Jumelet et al.,\n2019; Wilcox, Levy, Morita, & Futrell, 2018). We directly use their model without any further tuning.\n* Due to lack of relevant resources, we do not attempt to track down syntax units. The very fact that\nthe Italian NLM handles various long-distance agreement tasks correctly, as shown here and in the next\nsection, suggests that similar units must control the dynamics of its long-range number units. Proving\ntheir presence is in any case not crucial to our main predictions.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 10\n2.1 Materials and Methods\n2.1.1 Agreement Tasks\nFor the ablation studies, we constructed twoagreement taskswith a single long-range\ndependency across a prepositional phrase (Lakretz et al., 2019): NounPP-number and\nNounPP-gender. In the NounPP-number task, the main subject and verb agree on\ngrammatical number, and a second noun (attractor) can interfere during sentence\nprocessing. This task was used to identify long-range number units. In the\nNounPP-gender task, the main subject and a predicative adjective agree on gender, and\nan attractor having an opposite gender can interfere in the middle. This task was used\nto identify long-range gender units. Table 1 (top) describes the two tasks.\n2.1.2 Neural Language Model\nIn computational linguistics, alanguage modeldeﬁnes a probability distribution over\nsequences of words (Jurafsky & Martin, 2020). A Neural Language Model (NLM) is\nsimply a language model implemented by a neural network. The recurrent NLM we use\nhere, schematically illustrated in Figure 1, factorizes the probability of a sentence into a\nmultiplication of the conditional probabilities of all words in the sentence, given the\nwords that precede them:\nP(w 1w2 · · ·w n) =\nn�\ni=1\np(wi|w1 · · ·w i−1) (1)\nThis type of language model can thus be used asnext-word predictor: given the\npreamble of a sentence, it outputs a probability distribution over potential next words.\nWe exploit this fact in our experiments.\n2.1.3 Model Description\nThe speciﬁc NLM we used in our experiments is the Italian NLM made available by\nGulordava et al. (2018). * It is a recurrent LSTM language model (Graves, 2012),\nconsisting of two layers, each with 650 Long-Short Term Memory units (Hochreiter &\n* https://github.com/facebookresearch/colorlessgreenRNNs\nNESTED DEPENDENCIES IN NLMS AND HUMANS 11\nAgreement tasks for ablation experiments\nNounPP-numberNP a prep NP b Va\nIlragazzoaccanto alla donna conosce\n(Theboynext to the woman knows)\nNounPP-genderNP a prep NP b BEa ADJa\nIlragazzoaccanto alla donna èbasso\n(Theboynext to the woman isshort-m )\nNumber-agreement tasks for nesting experiments\nShort-SuccessiveNP a Va che NP b Vb\nIlﬁglio diceche ilragazzo ama\nTheson saysthat theboy loves\nLong-SuccessiveNP a Va che NP b P NP c Vb\nIlﬁglio diceche l’amicoaccanto al ragazzo conosce\nTheson saysthat thefriendnext to the boy knows\nShort-NestedNP a che NP b Vb Va\nIlﬁglioche ilragazzo osservaevita\nThesonthat theboy observesavoids\nLong-NestedNP a che NP b P NP c Vb Va\nIlﬁglioche laragazzaaccanto ai padri amaevita\nThesonthat thegirlnext to the fathers lovesavoids\nTable 1\nAgreement tasks for the ablation and nesting experiments.Theﬁrst column denotes\nthe name of the task, the second shows the sentence templates, whereNPis used as an\nabbreviation ofDet N. The indicesa,bmark the subject-verb dependencies in the\ntemplates. Note that forLong-andShort-Nested, we test performance on both the\nembeddedverbV b and themainverbV a. The last column contains an example of a\nsentence in the corresponding agreement task, along with its English translation. Bold\nand italic face highlight the dependencies marked by the indices in the templates. For\neach agreement task, we systematically vary thenumber(or gender, inNounPP-gender)\nof all nouns in the template, resulting in four diﬀerent conditions (SS, SP, PS and PP)\nfor the number-agreement tasks with two nouns (NounPP-number,NounPP-gender,\nShort-SuccessiveandShort-Nested) and eight diﬀerent conditions (SSS, SSP, SPS,\nSPP, PSS, PSP, PPS and PPP) for the number-agreement tasks with three nouns\n(Long-SuccessiveandLong-Nested). The examples shown are all SS and SSS\nconditions. ForNounPP-gender, singular (S) and plural (P) are replaced by masculine\nand feminine.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 12\nSchmidhuber, 1997), input and output embedding layers of 650 units and input and\noutput layers of size 50000 (the size of the vocabulary). The weights of the input and\noutput embedding layers are not shared (Press & Wolf, 2016). The last layer of the\nmodel is a softmax layer, whose activations sum up to 1 and as such corresponds to a\nprobability distribution over all words in the NLM’s vocabulary.\n2.1.4 Model Training\nThe weights of a NLM are typically tuned by presenting it with large amounts of data\n(atraining corpus) and providing feedback on how well it can predict each next word in\nthe running text. This allows it to adjust their weights to maximize the probabilities of\nthe sentences in the corpus. Our NLM was trained on a sample of the Italian Wikipedia\ntext, containing 80M word tokens and 50K word types. Further details can be found in\nGulordava et al. (2018).\n2.1.5 Model Evaluation\nFollowing Linzen et al. (2016), we computed the model’s accuracy for the diﬀerent\nNA-tasks by considering whether the model prefers the correct verb or adjective form\n(for the NounPP-number and NounPP-gender tasks, respectively) given the context.\nWe did so by presenting the preamble of each sentence to the NLM and then comparing\nthe output probabilities assigned to the plural and singular forms of the verb for the\nNounPP task and the probabilities of the masculine and feminine forms of the adjective\nfor the NounPP-gender task. On each sentence, the model was scored 1 if the\nprobability of the correct verb (or adjective)p correct was higher than that of the wrong\nonep wrong , and else 0. The model’s accuracy was then deﬁned as the average of these\nscores across all sentences in the NA-task.\nWe repeat the above also for another measure, which unlike accuracy, preserves the\ndegree of diﬀerence between the two probabilities for the two verb forms. Speciﬁcally,\nwe calculate thesuccess−probability= pcorrect\n(pcorrect+pwrong ) , which results in values in the\nrange [0,1], where 0.5 corresponds to chance-level performance.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 13\n2.1.6 Ablations: single-unit and top-k studies\nTo identify units that play an important role in encoding number or gender, we\nconducted a series of ablation experiments. In these ablation tests, we assessed the\nimpact of speciﬁc units on model performance by setting their activations to zero and\nthen recomputed the performance of the model on the NounPP-noun and\nNounPP-gender NA-tasks. We conducted two types of ablation studies: single- and\nmulti-unit ablation studies. Theﬁrst estimated the impact of each unit on model\nperformance, and the latter further assessed the joint impact of groups of units. In the\nsingle-unit studies, we separately ablated each of the recurrent units in the network,\nresulting in 1300 ablation studies per task. For the multi-unit ablations, to avoid the\ncombinatorial divergence implied by ablating all possible unit pairs, triplets, etc., we\nselected groups of units based on the results from the single-unit study. Speciﬁcally, we\nranked all 1300 units based on their impact on model performance on the NA-task\nwhen ablated in isolation. Then, each time, we selected the topkunits from the\nresulting order, ablated them, and re-assessed model performance on the NA-task. We\nconducted the multi-unit ablations fork= 1, ...,10. In what follows, we refer to these\ntwo studies as thesingle-unitandtop-k ablation study, respectively, and to the units\nordered based on their impact in the single-unit study as thetop-k units.\n2.2 Results\n2.2.1 Ablation Studies Reveal a Sparse Mechanism for Long-Range Number\nAgreement\nWe conducted the top-k ablation study with the Gulordava Italian network and with 19\nadditional NLMs that we trained on the same corpus and using the same\nhyperparameters, varying random initializations only. In this study, (1) the number of\nunits jointly ablated was incrementally increased, and (2) units were selected for\nablation based on their rank in the single-unit ablation results (Figure A3). That is,\nunits with a larger eﬀect on model performance were selectedﬁrst (Methods). Figure 2\nshows the results for all 20 models. We highlight three mainﬁndings: First, a\nNESTED DEPENDENCIES IN NLMS AND HUMANS 14\nsigniﬁcant diﬀerence was found between the ablation eﬀects in the SP and PS\nconditions (continuous vs. dashed lines, respectively), for both the full and the ablated\nmodels (p−value <0.001, for allk≥0; t-test). This diﬀerence was consistent across\nall 20 models, with better performance on the SP compared to the PS condition.\nSecond, for the PS condition, in all cases, model performance dropped to chance level\nafter the ablation of less than 4 units, and the average performance across models\nreached chance-level performance atk= 2 (black dashed line). The mean sparsity of\nplural encoding for long-range agreements is therefore<0.2%. Last, for all models,\nmodel performance further decreased below chance level for largerk’s. This shows that\nthe ablation of a relatively small number of units caused the models to predict the\noppositegrammatical number (singular) in the majority of the trials. All models have\ntherefore developed a ‘default bias’ towards singular and a sparse mechanism for\nnumber propagation across long-range dependencies, mainly dedicated to plural.\n2.2.2 The Dynamics of the Long-Range Units Consistently Emerge Across Models\nTo conﬁrm that the top-k units are long-range number units, similar to the ones\nidentiﬁed in the English Gulordava network, we visualized their dynamics during the\nprocessing of the long-range dependency, by extracting their activations during the\nprocessing of all sentences in the NounPP NA-task. Figure 3A describes the resulting\naverage cell-state activations for unit 815 from the Gulordava Italian network. Unit 815\nhad the largest eﬀect (k= 1) in the single-unit ablation study (Figure A1). Cell-state\ndynamics show that number information is robustly encoded throughout the\nsubject-verb dependency, also in the presence of an attractor (dashed lines). The\ndynamics indicate that unit 815 encodes both singular and plural number, using\n‘bi-polar’ encoding, with negative and positive cell activations, respectively. This is\ndiﬀerent from the English NLM, that developed two separate ‘uni-polar’ long-range\nunits specialized on singular and plural, respectively.\nFigure B1 further shows unit dynamics for the top units (k= 1) from four other\nmodels, for both the forget and input gates, as well as for their cell-state activations. In\nall four examples, the models converged to a similar mechanism with only two variants:\nNESTED DEPENDENCIES IN NLMS AND HUMANS 15\nnumber can be encoded by either bi- (top panel) and uni-polar (bottom) long-range\nunits. The long-range number-encoding dynamics identiﬁed in English (Lakretz et al.\n2019; Figure 1) thus consistently emerged also in the Italian models, with the same\nmain characteristics: (1) The input-gate activation rises towards its maximal value after\nthe presentation of the main subject. The input gate then resets to zero until the\npresentation of the verb, thus inhibiting interference from the following attractor; (2)\nThe forget gate maintains high activation throughout the long-range dependency, which\nis required for storing and propagating the grammatical number of the subject up to the\nverb; (3) given the input- and forget-gate dynamics, cell-state activation robustly\nencodes and carries the grammatical number of the subject across the subject-verb\ndependency. In total, across all models, 19 out of the 20 models show the above\ndynamics, 7 of which use a bi-polar encoding scheme. *\nThe long-range number-encoding dynamics are also observed in lower-impact units\n(k >1 in the ablation ranking), showing similar gate and cell-state dynamics. Figure\nB2 describes gate and state dynamics for the top three units from Gulordava’s\nnetwork.* The second top unit (k= 2) is a uni-polar unit (middle panel), showing\nsimilar long-range plural encoding, however, less robustly – interference from the article\nbefore the embedded attractor aﬀects the hidden state. For the third top unit (k= 3),\nlong-range number propagation across nested constructions is not observed (right\npanel). Similarly, in other models, the occurrence of the long-range number-encoding\ndecreases as a function ofk, and as we show next, unit contribution to verb prediction\nalso decreases as a function of the rankk.\n* Gate and cell-state dynamics for all 20 models are available at the repository of the study:\nhttps://github.com/yairlak/Nested_Dependencies_in_Humans_and_NLMs/tree/master/figures/\ntop_k_ablation_study/unit_activations/PS\n* See repository for all models.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 16\n2.2.3 Long-Range Number Units show a Diminishing Impact on Verb Prediction as\na Function of their Rank\nWe extracted the eﬀerent weights of the topkunits, which project onto the output\nlayer. Figure C1A shows an example for the eﬀerent weights of unit 815 from the\nGulordava Italian network. It shows that the eﬀerent weights diﬀerentially aﬀect unit\nactivations in the output layer, depending on whether they represent singular or plural\nforms of the verb, which is consistent with its role as a number unit.\nWe next tested whether the topkunits from the Gulordava Italian network have a\nsimilar or varying impact on verb prediction at the output layer. For fair comparison,\nweﬁrst multiplied each eﬀerent weight by the mean activity of the unit, computed one\nstep before verb prediction (recall that unit activity at the output layer is a function of\nthis product). We refer to this product as theeﬀective eﬀerent weight. Figure C2A\nshows the eﬀective eﬀerent weight for the top ten units identiﬁed for the PS condition,\nfrom the Gulordava Italian network. In accordance with the top-k ablation results, only\nthe fourﬁrst units showed strong separation between the two sets of weights, to singular\nand plural units in the output layer. Importantly, the mean eﬀective eﬀerent weight\ndecreased as a function of the rankk, suggesting that the impact on verb prediction\ndiminishes as a function ofk. *\nFinally, we repeated the above analysis for all models. Figure C2B shows the mean\neﬀerent weight across models as a function ofk. A monotonic decrease of the mean\n* In a related analysis, we visualized the input and output word embeddings of all target words used in\nour stimuli. Figures C3 shows these word embeddings represented along two of their principal\ncomponents (PCs), for the Gulordava’s Italian network. Panels A&B show that both number and\ngender information are encoded at the output word embeddings, separating between the target words of\nthe GA and NA tasks (adjectives and verbs, respectively) with respect to gender and number. Panels\nC&D show that number and gender information of the main subject of the sentence is separable already\nat the input word embeddings, although at higher PCs. This suggests that singular and plural forms of\nthe subject, and its masculine and feminine forms, are encoded already at this early processing stage of\nthe network. In the next stage, at the recurrent layers, the long-range mechanism propagate this\ninformation across long-range agreements, through possible intervening attractors, as was shown above.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 17\neﬀerent weight as a function ofkis observed.\n2.2.4 Ablation Studies Further Reveal a Sparse Mechanism for Long-Range Gender\nAgreement\nWe conducted the single-unit and top-k ablation experiments also for gender encoding,\nusing the gender-agreement task (Table 1). Figure A4 shows the results for all 20\nmodels. On average, for both incongruent conditions (MF and FM), mean model\nperformance sharply drops after the ablation of a single unit, reaching near chance-level\nperformance after the ablation of three units (MF:0.56±0.04; FM: 0.52±0.02). This\nshows that similarly to grammatical number, gender information for long-range\nagreement is also sparsely encoded, consistently across all models. Figure 3B further\nshows inner-state dynamics of the top unit from the Gulordava’s network. As for the\nNA-task, the long-range gender unit shows robust encoding across the subject-adjective\ndependency, also in the presence of attractors (dashed lines). Connectivity analysis\nfurther conﬁrmed that the eﬀerent weights of the long-range gender unit are clustered\nwith respect to whether they project to masculine or feminine adjective words in the\noutput layer (Figure C1B). Finally, we note that unlike the case of grammatical\nnumber, we did not observe below-chance performance in the top-k ablation study, for\none of the incongruent conditions. While on average there’s a diﬀerence between the\ntwo incongruent conditions (compare dashed vs continuous black lines), we did not\nobserve a ‘default’ bias towards one of the values of gender.\n2.2.5 Short-Range Number Units are also Found in Gulordava’s Network\nAs was shown for the English NLM, long-range number units are not the only\nnumber-carrying units in the network. ‘Short-Range’ number units also encode\ngrammatical number. However, their activation is not robust to intervening attractors.\nWe therefore tested for the presence of short-range number units in the Italian models,\nfocusing on Gulordava’s network. We found 10 more number units, which encode\ngrammatical number in separate values, and whose eﬀerent weights are clustered with\nrespect to number (Figure C1A).\nNESTED DEPENDENCIES IN NLMS AND HUMANS 18\nIn sum, these results replicate and extend previousﬁndings to another language and\nanother grammatical feature. Similarly to English, only a few long-range number units\nemerged in the Italian NLMs during training. The NLMs have developed a similar\nencoding scheme for both grammatical number and gender, independently. Taken\ntogether, this shows that sparse long-rangegrammatical-featureunits consistently\nemerge in NLMs.\n3 Processing of Two Subject-Verb Dependencies in the Italian NLM and in Italian\nNative Speakers\nThe core mechanism to carry agreement information across long-range dependencies in\nNLMs involves a very small number of long-range units. This mechanism can robustly\nprocess sentences having a single long-range dependency. However, since the long-range\nagreement mechanism is sparse, and its small number of units show diminishing impact\non model performance, the model is likely to have diﬃculties to process more then a\nsingle number feature at a time due to limited resources. Speciﬁcally, we ask: Can the\nNLM processtwolong-range dependencies that are active at once?\nTwo simultaneously active long-range dependencies occur in various constructions in\nnatural language, such as center-embedded nested dependencies, a prototypical example\nof recursion. In nested dependencies, once the long-range agreement mechanism is\nengaged in tracking the main dependency, there may be no more available resources to\nprocess theembeddedagreement. For example, in the sentence “Theboythat the\nfarmernear the fathers watchesknowsthe daughters”, there are two grammatical\nnumbers that need to be carried across a long-range dependency: (1) that of the main\nsubject ‘boy’, and (2) that of the embedded subject ‘farmer’ . Once the NLM encounters\nthe main subject, its grammatical number can be stored through the long-range\nagreement mechanism up to the main verb ‘knows’ . However, during this period, since\nthe mechanism is already taken up, once the embedded subject ‘farmer’ is presented to\nthe network, there is no robust way to encode and carry its number up to the embedded\nverb ‘watches’ . The NLM is thus predicted to fail to process the embedded dependency\nNESTED DEPENDENCIES IN NLMS AND HUMANS 19\nin nested structures.\nWe emphasize two conditions for this predicted failure:\n•The two dependencies aresimultaneouslyactive at some point: if this is not the case,\ni.e., the dependencies are successive (e.g., “Theboynear the cars saysthat thefarmer\nnear the fathers watchesthe daughters”), the long-range mechanism canﬁrst complete\nprocessing theﬁrst dependency, and then reset before encoding the next one.\n•Both dependencies arelong-range: in the case of a short-range dependency nested\nwithin a long-range one (e.g., “Theboythat thefarmer watchesknowsthe\ndaughters”), the embedded short-range dependency can still be processed by the\nshort-range units we described above, although possibly in a less robust way compared\nto the main dependency.\nWe next present the experimental design we used to conﬁrm these predictions about the\nNLM, as well as to test whether they also extend to human subjects, which would\nsuggest that the agreement processing system of the latter bears similarities to the one\nwe uncovered in NLMs.\n3.1 Experimental Design\nTo test the hypothesis that the sparsity of the long-range mechanism can lead to a\nsigniﬁcant processing diﬃculty at the embedded dependency, we created a two-by-two\ndesign that manipulates the above two conditions: (1) whether the two dependencies\naresuccessiveornested, and (2) whether the embedded dependency isshortorlong\nrange. Figure 4 describes the resulting four NA-tasks: Short-Successive,\nLong-Successive, Short-Nested and Long-Nested (‘Short’ and ‘Long’ therefore refer to\nthe length of the embedded dependency only).\nThe successive tasks serve as control. They minimally diﬀer from the nested ones up to\nthe embedded verb, by only a single word (‘dice’ (‘says’) in Figure 4). Note also that\ntasks that have a long embedded dependency have a third noun, which functions as a\npossible attractor, inside the embedded dependency. We will refer to this most-deeply\nembedded noun as the ‘(inner) attractor’, although note that the subjects of the main\nNESTED DEPENDENCIES IN NLMS AND HUMANS 20\nand nested clauses can also act as attractors on each others’ verbs.\nFor each NA-task, we generated variousconditionsby varying the number of the main\nand embedded subject noun, and that of the attractor. Short-Successive and\nShort-Nested have each four conditions corresponding to the possible assignments of\nnumber to the main and embedded subjects - SS, SP, PS and PP. Similarly,\nLong-Successive and Long-Nested have eight conditions, based on the possible numbers\nof the main, embedded subject and attractor - SSS, SSP, SPS, etc. In what follows, by\ncongruent subjectswe refer to conditions in which the main and embedded subjects\nshare grammatical number (SS, PP, SSS, SSP, PPS and PPP), and byincongruent\nsubjectsto the rest (SP, PS, SPS, etc.). Bycongruent attractor, we refer to conditions\nin which the embedded subject and the third noun share grammatical number (SSS,\nSPP, PSS and PPP), and byincongruent attractorto conditions in which they diﬀer\n(SSP, SPS, PSP, PPS) (Table 1).\nSeveral studies reported markedness eﬀects in agreement, whereby humans make more\nerrors when the grammatical number of the attractor is plural. This eﬀect was reported\nin several languages and in both comprehension and production (English: Bock and\nMiller (1991); Eberhard (1997); Wagers, Lau, and Phillips (2009);Italian: Vigliocco,\nButterworth, and Semenza (1995);Spanish: Bock, Carreiras, and Meseguer (2012);\nLago, Shalom, Sigman, Lau, and Phillips (2015);French: Franck et al. (2002);Russian:\nLorimor, Bock, Zalkind, Sheyman, and Beard (2008)). Since we use error rates as an\nindex of processing diﬃculties across various conditions, we strove to increase their\noverall signal. Therefore, weﬁrst present all analyses on contrasts with a plural\nattractor. Results for the full set of conditions, with both singular and plural attractors,\nare reported in Appendix D. Also, to facilitate the interpretation of the results, we\ngrouped conditions by whether the main and embedded subjects were congruent or not.\nTable 2 summarizes our predictions for each task and structure, while ignoring for now,\nfor ease of presentation, diﬀerences among speciﬁc conditions. For Short- and\nLong-Successive, no signiﬁcant processing diﬃculties are predicted, since the long-range\nmechanism can encode the main and nested grammatical numbers sequentially. For\nNESTED DEPENDENCIES IN NLMS AND HUMANS 21\nShort- and Long-Nested, the long-range mechanism is predicted to successfully process\nthe main dependency and therefore no signiﬁcant diﬃculties are predicted on the main\nverb (beyond the relative diﬃculty to process center-embeddings reported for both\nhumans (Traxler, Morris, & Seely, 2002) and NLMs (Marvin & Linzen, 2018)). In\ncontrast, the embedded dependency in Short-Nested cannot rely on the long-range\nagreement mechanism, as it is recruited by the main dependency. Consequently, the\nprocessing of the embedded dependency can only rely on short-range mechanisms,\nwhich might not be as robust as the long-range ones. We are thus agnostic about\nsuccess in this case. Finally, in Long-Nested, the performance on the embedded verb is\npredicted to be signiﬁcantly low, given that the long-range mechanism can process only\na single agreement, as described above.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 22\nFigure 2\nEvidence from ablation about the sparsity of the long-range mechanism and its bias\ntowards singular:To determine the number of recurrent units that participate in the\nlong-range mechanism, we conducted the top-k ablation study (Methods). For all 20\nItalian NLMs, model performance on the NA-task was re-evaluated after the ablation of\nthe topkunits from the single-unit ablation study (k= 1, ..10;k= 0corresponds to the\nfull, non-ablated, model). Model performance is shown separately for the SP\n(continuous) and PS (dashed lines) conditions. Black lines indicate the average\nperformance across all models, and the shaded grey area represents the corresponding\nSEM. For the PS condition, mean model performance drops below chance after the\nablation of only 2 units (out of 1300 units in the network). The ablation of more units\nfurther reduced mean model performance to around 0.1. That is, the removal of a few\nunits caused the models to predict the opposite number (singular) in most trials. This\nshows that (1) long-range number agreement for plural is sparsely encoded, by less than\n0.4%of the recurrent units in the network; and (2) all models developed a ‘default bias’\ntowards the singular value.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 23\nFigure 3\nRobust propagation of number (panel A) and gender (panel B) information during\nthe processing of a single long-range dependency across a prepositional phrase.An\nexample sentence for a speciﬁc condition (SS in A, masculine-masculine in B) is shown\nunder each diagram, but the plotted cell-state activations are averaged across all stimuli\nof each condition. (A) Number unit: four conditions are presented, corresponding to\nwhether the main subject of the sentence is singular (red curves) or plural (blue), and to\nwhether the main subject (‘bambino’) and the attractor (‘contadino’) have the same\n(congruent case; continuous lines) or opposite number (incongruent; dashed). Activity\nof the number unit depends on the grammatical number of the main subject - positive\n(negative) for plural (singular) value. Activity is stable throughout the subject-verb\ndependence, also in the presence of an intervening attractor (dashed lines). (B) Gender\nunit: four conditions corresponding to whether the main subject is masculine (magenta)\nor feminine (cyan), and to whether the attractor is congruent (continuous) or\nincongruent (dashed). Activity of the gender unit depends on the gender of the main\nsubject - positive (negative) for feminine (masculine). Activity is stable from the main\nsubject up until the corresponding adjective, also in the presence of an intervening\nattractor (dashed line).\nNESTED DEPENDENCIES IN NLMS AND HUMANS 24\nFigure 4\nA full-factorial design for two subject-verb dependencies. Human subjects and Neural\nLanguage Models were presented with sentences from four diﬀerent syntactic structures,\nwhich all have two subject-verb dependencies: a main dependency (continuous lines) and\nan embedded dependency (dashed). Theﬁrst factor of the design determines whether the\ntwo dependencies are successive (top structures) or nested (bottom), depending on\nwhether the structure has a sentential complement or an object-extracted relative clause,\nrespectively. The second factor determines whether the embedded dependency is short\n(left side) or long (right). We refer to the four resulting structures as: Short-Successive,\nLong-Successive, Short-Nested and Short-Long.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 25\nSentence Type Main Verb Embedded Verb\nSuccessive-Short Good Good\nSuccessive-Long Good Good\nNested-Short Good -\nNested-Long Good Poor\nTable 2\nA summary of the predictions of model performance on successive and nested\ndependencies based on the sparsity of the long-range mechanism. Cell values represent\nthe degree of predicted performance on the agreement task. Due to possible\ncompensation mechanisms carried by the short-range number units, we make no precise\npredictions regarding performance on the embedded verb of Nested-Short.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 26\n3.2 Methods and Materials for Simulations with the NLM\nWe used four diﬀerent Number-Agreement tasks (NA-tasks, bottom, Table 1). All tasks\ncontain two subject-verb dependencies, which diﬀer in terms of whether they are\nsuccessiveornestedand whether the embedded dependency isshort-orlong-range.\nTwo subject-verb dependencies aresuccessivewhen the second subject occurs only after\ntheﬁrst subject-verb dependency has been established. Such dependencies occur, for\ninstance, in declarative sentences with a sentential complement, such as “Ilragazzo dice\nche ladonna conosceil cane” (“Theboy saysthat thewoman knowsthe dog”). In this\nexample, the subject and verb are directly adjacent in both dependencies. We thus call\nthese dependenciesshort-range, and the above sentence is an example of a sentence that\ncould occur in theShort-SuccessiveNA-task. To create sentences that have a successive\nbutlong-rangesubject-verb relationship, we increase the distance between the second\nnoun and its corresponding verb by inserting a prepositional phrase in between: “Il\nragazzo diceche ladonnaaccanto alﬁglio conosceil cane’ ’(“Theboy saysthat the\nwomannext to the son knowsthe dog”). For nested dependencies, we consider\nsentences with object-relative clauses, such as “Ilragazzoche laﬁglia amaconosceil\ncontadino” (“Theboywho thedaughter lovesknowsthe farmer”). As the nested\ndependency in this sentence is short range, we call the corresponding number-agreement\ntaskShort-Nested(note however that the main-clause dependency is long range). For\nLong-Nested, we again use prepositional phrases to increase the distance between the\nsubject and verb of the nested dependency: “Ilragazzoche laﬁgliavicino alla donna\namaconosceil contadino” (“Theboywho thedaughternear the woman lovesknows\nthe farmer”).\nFor each NA-task, we generated 4096 sentences that were randomly sampled from a\nﬁxed lexicon (Table E). The performance of the model on each condition was then\nevaluated in the same way as described in section 2.1.5.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 27\nFigure 5\nSequential processing of successive dependencies and robust encoding of the outer\ndependency of nested constructions by the long-range number unit.Averaged\nnumber-unit activity is presented for the four structures in the design: Short-Successive\n(panel A), Long-Successive (B), Short-Nested (C) and Long-Nested (D). For each\nstructure, results are presented for four conditions, corresponding to whether the main\nsubject of the sentence is singular (red curves) or plural (blue), and to whether the main\nand embedded subjects have the same grammatical number (congruent; continuous lines)\nor not (incongruent; dashed lines) (example sentences are for singular/congruent\nconditions in all cases). (A) Short-Successive: the number unit processes the two\nsuccessive dependencies sequentially. After the encoding of theﬁrst subject (’bambino’),\nactivity return to baseline (around zero) before encoding the embedded subject\n(’contadino’). (B) Long-Successive: a similar sequential encoding is observed also when\nthe embedded dependency is long-range. (C) Short-Nested: the number unit carries the\ngrammatical number of the main subject (’bambino’) up to the main verb (’evita’), also\nin conditions in which the embedded subject and verb carry opposite grammatical\nnumber (dashed lines). (D) Long-Nested: encoding of the grammatical number of the\nmain subject is robust also when the embedded dependency is long-range.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 28\n3.3 Results for the Italian NLM\n3.3.1 The Number Unit Shows Sequential Processing of Two Successive\nDependencies and Robust Encoding of the Main Dependency in Nested\nConstructions\nWeﬁrst simulated NLM dynamics for all NA-tasks and conditions, by presenting all\nsentences from each condition to the NLM. Figure 5 presents hidden-state dynamics of\nthe top (K= 1) long-range number unit during the processing of all conditions from the\nfour NA-tasks. We note that, consistent with results on a single dependency, the\ngrammatical number of the main subject is encoded with the same polarity as found in\nthe NounPP task - positive for plural (blue) and negative for singular (red). Second, in\nsuccessive NA-tasks, the activation of the number unit returns to baseline after\nencountering the main verb (‘dice’), and then rises back once the embedded subject is\nencountered. This shows that the number unit can sequentially encode two grammatical\nnumbers in two successive dependencies, also when the two numbers are opposite. In\nparticular, note that in Long-Successive, the grammatical number of the embedded\nsubject is robustly carried across the attractor (‘fratello’) in the incongruent conditions\n(dashed lines). Finally, in both Short- and Long-Nested, the grammatical number of the\nmain subject is robustly carried across the main dependency up to the main verb\n(‘osserva’), and in particular, across the embedded subject and verb that carry an\nopposite number in some conditions (dashed lines). Figure B2 further shows mean unit\ndynamics of the next two top units (k= 2,3), during the processing of sentences from\nLong-Nested. The second unit shows long-range number encoding of only the main\ndependency, similarly to the top unit. However, its functioning is less robust and shows\nmore susceptibility to interference before the embedded attractor. Last, the third top\nunit does not show long-range number encoding, consistently with the results about the\nhigh sparsity of long-range number encoding in the model.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 29\n3.3.2 NLM Performance on Successive Dependencies\nSince no signiﬁcant processing diﬃculty is predicted in the successive tasks, we\nconducted the experiments on the embedded agreement only, which is expected to be\nthe more diﬃcult one. This allowed us to reduce experimental duration in the parallel\nstudy with human participants.\nFigure 6A presents the resulting NLM error rates for the Gulordava network (Figure D1\nshows the full error-rate distribution across all conditions). Figure D3 further provides\nthe mean error-rates across all models. Several eﬀects are observed in the results, for\nboth the Gulordava’s network and across models:\n•Near perfect performance on all conditions: Overall, for both Short- and\nLong-Successive, the performance of the NLM was found to be almost error free, with\nslightly more errors in the Long-Successive case (p <0.001)\n•Subject-congruence eﬀect: We next tested for asubject-congruence eﬀect, i.e.,\nwhether incongruent subjects elicited more errors compared to congruent ones. We\nfound a signiﬁcant subject-congruence eﬀect in both Short- and Long-Successive\n(Short-Nested:p <0.001; Long-Nested:p <0.001). Note that the variance in network\nperformance is very low, which renders this eﬀect signiﬁcant, although the error rate is\nnear zero in both congruent and incongruent cases.\n3.3.3 NLM Performance on Nested Dependencies\nFigure 6B presents the corresponding error rates in the case of nested dependencies\n(Figure D1 further provides the full error-rate distribution across all conditions).\nSeveral eﬀects are observed in the results:\n•Incongruent conditions elicit more errors: a signiﬁcant subject-congruence eﬀect was\nfound on both the embedded and main verbs, in both Short- and Long-Nested\n(Short-Nested main:p <0.001; Short-Nested embedded:p <0.001; Long-Nested main:\np <0.001; Long-Nested embedded:p <0.001). In all cases, incongruent subjects\nelicited more errors compared to congruent subjects.\n•Processing of embedded verbs is more error-prone: for both Short- and\nNESTED DEPENDENCIES IN NLMS AND HUMANS 30\nFigure 6\nComparison of error ratespredicted by the Neural Language Model (top, panels A & B)\nand observed in human participants (bottom, panels C & D). Blue and red colors\ncorrespond to whether the main and embedded subjects agree on number (congruent\nsubjects) or not (incongruent), respectively. Error bars represent the 95% conﬁdence\nlevel. Error rates for NLMs were computed based on the output probabilities predicted by\nthe network for the two possible values of grammatical number. For each trial, if the\npredicted probability of the wrong grammatical number was higher than that of the\ncorrect one, the NLM was considered as making an error. Error rates for humans were\ncomputed based on the fraction of missed violations in ungrammatical trials.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 31\nLong-Nested, a signiﬁcant interaction was found between subject-congruence and\nverb-position (embedded/main), with a larger increase of error rate due to incongruent\nsubjects on the embedded compared to the main verb (Short-Nested:p <0.001;\nLong-Nested:p <0.001).\n•A longer embedded dependency is more error prone: for errors made on the\nembedded verb, we found a signiﬁcant interaction between subject-congruence and the\nlength of the embedded dependency (Short/Long-Nested), with a larger increase of\nerror rate due to incongruent subjects in Long-Nested (p <0.001).\n3.3.4 Discussion of NLM results\nFocusing on cases with incongruent subjects, the error patterns of the NLM are overall\nconsistent with the predictions summarized in Table 2. First, successive dependencies\nare relatively easy for the model. This is consistent with the sequential encoding\nobserved in the dynamics of the number unit (Figure 5), which shows a robust encoding\nof grammatical number of embedded subjects, also in the presence of an attractor.\nSecond, the main dependency in both Short- and Long-Nested was successfully\nprocessed (i.e., signiﬁcantly better than chance level), although with more overall errors\ncompared to successive dependencies. Third, the NLM made an exceptionally large\nnumber of errors on the embedded verb in Long-Nested, as predicted by the sparsity of\nthe long-range mechanism. This is prominent in the case of incongruent-subject, since\nonly then the grammatical number of the main subject encoded in the long-range\nmechanism can interfere. Finally, the NLM made a relatively large number of errors on\nthe embedded verb in Short-Nested but was signiﬁcantly better than chance level (error\nrate =0.5;p <0.001). The reduced number of errors in Short- compared to\nLong-Nested is consistent with theﬁndings about a less sophisticated short-range\nmechanism that can process the embedded dependency, compensating for the\nmomentary recruitment of the long-range mechanism for the main one.\nTaken together, this points to a capacity limitation to process nested long-range\nagreements in NLMs (Lakretz, Dehaene, & King, 2020). We note that a similar\nNESTED DEPENDENCIES IN NLMS AND HUMANS 32\ncapacity limitation was also identiﬁed in NLMs trained on artiﬁcial data that contained\ndeep nested constructions, with more than two nested long-range dependencies (Lakretz\net al., 2021). Speciﬁcally, models that were trained on a corpus that contained nested\nstructures up to depthﬁve, failed to generalize to unseen test sentences having a nested\nstructure of greater depth. Therefore, for both natural data and artiﬁcial data that\ncontain deep nested structures, NLMs develop a capacity limitation which reﬂects the\ncorpus on which they were trained.\nFinally, we note that in the case of natural language, the capacity limitation observed in\nthe models cannot be simply explained by a limited training corpus if compared to the\nlanguage input available to humans during language acquisition, as suggested by a\nreviewer. First, the Wikipedia training corpus contained approximately 80M tokens.\nTherefore, a single presentation of the corpus to the model involves more tokens than\nthose available to children during theirﬁrst three years of life (<30M tokens, Hart &\nRisley, 1995). Second, the vocabulary size of the model (50K token), which was\nextracted from the training corpus, is of the same order as that of humans (e.g.,\nBrysbaert, Stevens, Mandera, & Keuleers, 2016). Third, long-nested constructions are\nrare in our training corpus, but that is also the case for natural language (Karlsson,\n2007); this makes the human-model comparison fair, ensuring that the obtained results\ndo not depend on diﬀerent information available to the model vis-à-vis human\nparticipants. Last, training on this corpus led to state-of-the-art results on language\nmodelling, and high, human-like, performance on the canonical noun-PP task, on which\nthe models were not explicitly trained.\n3.4 Methods and Materials for the Behavioral Experiment with Humans\n3.4.1 Participants\n61 psychology students from the University of Milano-Bicocca (males = 11; Age =\n23.3±4.9; Education = 14.6±1.5) took part in the experiment in exchange for course\ncredits. Participants were Italian native speakers and were naive with respect to the\nexperiment purpose. The study was approved by the ethical committee of the\nNESTED DEPENDENCIES IN NLMS AND HUMANS 33\nDepartment of Psychology, and ethical treatment was in accordance with the principles\nstated in the Declaration of Helsinki.\n3.4.2 Stimuli\nStimuli comprised i) acceptable sentences; ii) violation trials, which contained a number\nviolation on the verb of one of the subject-verb agreements; iii)ﬁller sentences,\ncomprising several syntactic and semantic violations. As for the NLM, acceptable\nsentences were created using a pool of 10 nouns, 19 verbs, 4 prepositions (Table E), for\nall four main constructions (Table 1, bottom). Starting from the acceptable sentences,\nnumber-violation trials were created by replacing either the main or embedded verb by\nthe opposite form of the verb with respect to number. For example, “ilfratelloche lo\nstudente *accolgonoamai contadini” (“thebrotherthat thestudent *welcomelovesthe\nfarmers”). Filler trials were based on the same template and they could contain either a\nsemantic or syntactic violation that does not concern number (for further details, see\nAppendix E). In total, 540 sentences were presented to each participant, randomly\nsampled from a larger pool. Of these, 180 sentences were acceptable, 180 had a number\nviolation, and 180 wereﬁllers.\n3.4.3 Paradigm\nThe experiment was conducted in two sessions of 270 trials each, which were performed\nby participants in diﬀerent days. Each session lasted around 45 minutes. The two\nsessions took place at the same time of the day at a maximum temporal distance of two\nweeks. After receiving information about the experimental procedure, participants were\nasked to sign a written informed consent.\nStimuli were presented on a 17” computer screen in a light-grey, 30-point Courier New\nfont on a dark background. Sentences were presented using Rapid Serial Visual\nPresentation (RSVP). Each trial started with aﬁxation cross appearing at the center of\nthe screen for 600 ms, then single words were presented with SOA=500 ms, 250 ms\npresentation followed by 250 ms of black screen. At the end of each sentence, a blank\nscreen was presented for 1500 ms, then a response panel appeared, with two labels\nNESTED DEPENDENCIES IN NLMS AND HUMANS 34\n‘correct’ and ‘incorrect’, on two sides of the screen (in random order each time) for a\nmaximal duration of 1500 ms. Aﬁnal screen, showing accuracy feedback was presented\nfor 500 ms.\nParticipants were informed that they would be presented with a list of sentences which\ncould be acceptable or containing a syntactic or semantic violation. They were\ninstructed to press the “M” key of the Italian keyboard as fast as possible once they\ndetected a violation. Sentences were presented up to their end even if a button press\noccurred before. When the response panel appeared with the two labels\n(‘correct’/‘incorrect’) at the end of the sentence, participants were instructed to press\neither the “X” or “M” key for choosing the label from the left or right side of the screen,\nrespectively. During the entire session, participants were asked to keep their left index\nover “X” and their right index over “M” . After each trial, participants received feedback\nconcerning their response: “Bravo!” (“Good!”) in case the response was correct,\n“Peccato. . . ” (“Too bad. . . ”) when it was incorrect. At the beginning of each session,\nparticipants performed a training block comprising 40 trials. The training section\nincluded all stimulus types, which were constructed from a diﬀerent lexicon than that\nused for the main experiment.\n3.4.4 Data and Statistical Analysis\nIn ungrammatical trials, a violation occurred on either the main or embedded verb.\nErrors therefore correspond to trials in which a violation was missed. Note that since in\nungrammatical trials a violation occurred on only one of the two verbs, the error can be\nassociated with either the main or embedded dependency. In grammatical trials, errors\ncorrespond to trials in which participants reported a violation despite its absence. In\ncontrast to ungrammatical trials, in which the violation marks the dependency, in\ngrammatical trials it is not possible to associate an error with one of the two\ndependencies. Moreover, given the presence ofﬁller trials, the false detection of a\nviolation could be unrelated to grammatical agreement (for example, it could be a false\ndetection of a semantic violation). Agreement errors were therefore estimated from\nungrammatical trials only (error rates on grammatical trials are reported in Figure D2).\nNESTED DEPENDENCIES IN NLMS AND HUMANS 35\nStatistical analyses were carried out using R (Team et al., 2013). For each hypothesis to\nbe tested, weﬁtted a mixed-eﬀects logistic regression model (Jaeger, 2008), with\nparticipant and item as random factors, using thelme4package for linear mixed eﬀects\nmodels (D. Bates, Maechler, Bolker, & Walker, 2015). Following Baayen, Davidson, and\nBates (2008), we report the results from the model with the maximal random-eﬀects\nstructure that converged for all experiments.\n3.5 Results for Humans\nSection 3.3 showed that the NLM cannot robustly encode two simultaneously active\nlong-range dependencies. The NLM: (1) made more errors on the embedded verb in\nboth Short- and Long-Nested, and (2) had an exceptionally high error rate in the latter\ncase, when the embedded dependency was long range.\nSuppose that a similarly sparse mechanism is also used by humans to carry number\nfeatures through long-distance agreement structures. We derive the following\npredictions:\n•Prediction 1: humans will make more agreement errors on the embedded compared\nto the main dependency in the incongruent conditions of Long-Nested.\n•Prediction 2: humans will make more errors on the incongruent conditions of the\nembedded verb when the embedded dependency is long- compared to short-range.\nPrediction 1 derives from the robustness of the agreement mechanism in processing the\nmain but not the embedded dependency, as was observed in the NLM performance.\nThe prediction is particularly interesting because, structurally, the main dependency\nwill always be longer-range than the embedded one. Prediction 2 derives from the\nsparsity of the agreement mechanism and the dramatic failure of the model to process\nthe embedded dependency in Long- but not Short-Nested. Note that we do not make\nprecise predictions regarding Short-Nested, due to possible short-range compensation\nmechanisms in humans.\nIn what follows, we describe agreement-error patterns in humans, to be compared to\nthose of the NLM in Section 4.2.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 36\n3.5.1 Human Performance on Successive Dependencies\nHuman error rates appear in Figure 6C (Figure D1 further provides the full error-rate\ndistribution across all conditions). Several eﬀects were observed:\n•Relatively low error rate: humans made relatively few errors on successive\nconstructions, although signiﬁcantly above zero. Note that, in comparison to the Italian\nNLM, humans had a higher error baseline, probably due to unrelated factors such as\noccasional lapses of attention.\n•No subject-congruence eﬀect: we found no signiﬁcant subject-congruence eﬀect in\nShort-Successive, and a marginally signiﬁcant subject-congruence eﬀect in\nLong-Successive (p= 0.06).\n3.5.2 Human Performance on Nested Dependencies\nFigure 6D presents the resulting human error rates (Figure D1 further provides the full\nerror-rate distribution across all conditions). Several eﬀects are observed in the results:\n•Subject-congruence eﬀect on embedded and main verbs: for both main and\nembedded verbs in both Short- and Long-Nested, incongruent subjects elicited more\nerrors–a signiﬁcant subject-congruence eﬀect was found in all cases (Short-Nested main:\np= 0.003; Short-Nested embedded:p <0.001; Long-Nested mainp <0.001;\nLong-Nested embedded:p <0.001).\n•Processing of embedded verbs is more error-prone: for both Short- and\nLong-Nested, the increase in error rate due to incongruent subjects was larger for\nembedded compared to main verbs. A signiﬁcant interaction was found between subject\ncongruence and verb position in both cases (Short-Nested:p= 0.02, Long-Nested:\np= 0.008).\n•A longer embedded dependency is not signiﬁcantly more error prone: for embedded\nverbs, the increase in error rate due to incongruent subjects was comparable when the\nembedded long-range dependency was compared to the short one. No signiﬁcant\ninteraction was found between subject-congruence and length of the embedded\ndependency (Short- vs. Long-Nested).\nNESTED DEPENDENCIES IN NLMS AND HUMANS 37\n3.5.3 Discussion of Human Results\nOverall, as expected, successive dependencies were relatively easy for humans compared\nto nested ones. The subject-congruence eﬀect was not found, or was marginally\nsigniﬁcant, which is consistent with sequential processing of grammatical number in\nNLMs. The results conﬁrmPrediction 1–the main dependency in both Short- and\nLong-Nested was less error prone than the embedded one, as conﬁrmed by a signiﬁcant\ninteraction between subject-congruence and verb position. However, although humans\nmade more errors on the embedded dependency when it was long range, we did notﬁnd\na signiﬁcant interaction between subject-congruence and the length of the embedded\ndependency. Prediction 2 was therefore not conﬁrmed by the results.\n4 General Discussion\nWe investigated how recursive processing of number agreement is performed by Neural\nLanguage Models (NLMs), treating them as ‘hypothesis generators’ for understanding\nhuman natural language processing. To this end, we contrasted how NLMs process\nsuccessive and nested constructions, and tested resulting predictions about human\nperformance.\n4.1 A Sparse Agreement Mechanism Consistently Emerges in NLMs Across\nLanguages and Grammatical Features\nUsing agreement tasks with a single subject-predicate dependency, weﬁrst replicated in\nItalian previousﬁndings reported for an English NLM, and extended theseﬁndings to\nanother grammatical feature, namely, gender. We found that for both number and\ngender agreement a sparse mechanism emerged in an Italian NLM during training.\nTheseﬁndings suggest that the emergence of a sparse agreement mechanism in the type\nof NLMs explored in this study is a robust phenomenon across languages and\ngrammatical features *.\n* Note that in other types of NLMs, e.g., with another type of units (not LSTM), a diﬀerent\nmechanism might emerge. The NLM explored in this study is, however, a standard model extensively\nNESTED DEPENDENCIES IN NLMS AND HUMANS 38\nThe results are moreover consistent with the recentﬁnding that a sparse agreement\nmechanism emerged in an NLM trained on an artiﬁcial language with deep nested\nstructures (i.e., with more than two levels of nesting), suggesting that the sparsity\nproperty is not due to the rare occurrence of deep nested structures in natural language\n(Lakretz et al., 2021).\nThe top-k ablation study further revealed a default bias towards singular that emerged\nin all 20 NLMs explored in this study. Such ‘default reasoning’ in number agreement\nwas previously identiﬁed in the Gulordava’s English network, using contextual\ndecomposition methods (Jumelet et al., 2019). Interestingly, a ‘default’ bias to one\nfeature value, known as the markedness eﬀect, was extensively studied also in humans\n(Bock et al., 2012; Bock & Miller, 1991; Eberhard, 1997; Franck et al., 2002; Lago et al.,\n2015; Lorimor et al., 2008; Vigliocco et al., 1995; Wagers et al., 2009). The relation\nbetween the emergence of default biases in NLMs and humans is an interesting topic for\nfuture work. However, we note that, unlike for humans, in our experiments, we did not\nobserve a similar default bias in the case of gender.\nThe sparsity and speciﬁcity of the agreement mechanism suggests that NLMs develop a\nseparate ‘module’ for at least one speciﬁc type of grammatical information. This is not\nquite a Fodorian module (Fodor, 1983), since the agreement mechanism is not\nhard-wired and it is not informationally encapsulated. The function of this mechanism\ncan however be characterized independently of the functions of other components in the\nnetwork, and it can be selectively impaired by neural damage, as was shown in our\nablation experiments. This sparse, dedicated representation of syntactic information\nstands in sharp contrast with the distributed encoding of semantic information, which\nNLMs typically pack into dense embedding vectors supporting the computation of\ngraded similarity relations (Jurafsky & Martin, 2020; Mikolov, Yih, & Zweig, 2013).\nIt is an open question whether semantic and syntactic information is encoded and\nprocessed jointly or separately in the human brain. At one end of the scale, it was\nused in applied NLP due to its high performance. The hypotheses emerging from its analysis are\ntherefore compelling for the study of human language processing.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 39\nclassically claimed that syntactic information is represented and processed in an innate\nand genetically determined system (e.g., Chomsky, 1984; Fodor, 1983; Pinker, 1994).\nBoth lesion and brain-imaging research have initially supported such a modular view,\nsuggesting that syntactic processing takes place in localized and specialized brain\nregions such as Broca’s area. Early neuropsychological studies showed double\ndissociations between syntactic and semantic processing. In one direction, aphasic\npatients were identiﬁed with impaired syntactic processing but largely preserved\nsemantic processing (Caramazza & Zurif, 1976). In the other direction, patients were\nidentiﬁed with severe semantic impairments but relatively preserved syntactic\nprocessing (Breedin & Saﬀran, 1999; Breedin, Saﬀran, & Coslett, 1994; Hodges &\nPatterson, 1996). Further support to this view came from brain-imaging studies, for\nexample, in an inﬂuential study, Dapretto and Bookheimer (1999) conducted an fMRI\nexperiment in which subjects had to decide whether two sentences diﬀered in their\nmeaning. In the ‘semantic’ condition, all pairs of sentences were identical except for one\nword that was replaced with either a synonym or a diﬀerent word. In the syntactic\ncondition, sentence pairs were either presented in a diﬀerent form or a diﬀerent word\norder. Brain activations related to the ‘syntactic’ task were localized to BA 44 in\nBroca’s area, while those for the semantic task were found more anteriorly along the left\ninferior frontal gyrus, in BA 47. This view became the dominant one in theﬁeld, with\nfurther support provided from later studies (e.g., Embick, Marantz, Miyashita, O’Neil,\n& Sakai, 2000; Friederici, Fiebach, Schlesewsky, Bornkessel, & Von Cramon, 2006;\nGarrard, Carroll, Vinson, & Vigliocco, 2004; Hagoort, 2014; Hashimoto & Sakai, 2002;\nPallier, Devauchelle, & Dehaene, 2011; Vigliocco, 2000). However, the original Dapretto\net al (1999) study later failed to be replicated (Siegelman, Blank, Mineroﬀ, &\nFedorenko, 2019), and in contrast to the modular view, other studies suggested that\nsemantics and syntax are processed in a common distributed system for language\nprocessing (e.g., E. Bates & Dick, 2002; E. Bates, MacWhinney, et al., 1989; Dick et al.,\n2001). This view has recently gained support from brain-imaging studies, providing\nevidence that semantic and syntactic processing in the language network may not be so\nNESTED DEPENDENCIES IN NLMS AND HUMANS 40\neasily dissociated from one another (Fedorenko, Blank, Siegelman, & Mineroﬀ, 2020;\nMollica et al., 2018). Clearly, there are substantial diﬀerences between the human brain\nand NLMs. However, ourﬁndings bring a computational point of view to this debate,\nsuggesting that separating syntactic from semantic processing is computationally\nadvantageous for addressing the language-modeling task, and is spontaneously\n‘discovered’ during the learning process as a way to solve the diﬃcult problem of\npredicting the next word (see also O’Reilly, 2006; Russin, Jo, & Randall, 2019; Ullman,\n2004, for related studies.)\nIn early debates on the linguistic abilities of neural networks of the 80s and 90s,\nconnectionist theories stressed the parallel nature of neural processing, and the\ndistributed nature of neural representations (e.g., Elman, 1991; Rumelhart et al.,\n1986a). Addressing recursive processing, Smolensky (1990) formally showed how\nsymbolic, rule-based, algebraic systems (e.g., Fodor & Lepore, 1999; Fodor & Pylyshyn,\n1988) can be represented by high-dimensional vectors, and how the generation of\nsyntactic structures can be computed with tensor products between such vectors coding\nfor words, position and role. While these early connectionist theories stressed the\nimportance of the distributed nature of neural representations, our work shows that\nmodern neural networks can develop in certain cases local representations of certain\naspects of the input, such as grammatical number or gender. One possible reason for\nthis diﬀerence is that modern recurrent neural networks, unlike their early ancestors\n(Elman, 1990), are equipped with more complex ’innate’ mechanisms and structural\nbiases. Speciﬁcally, we speculate that gating mechanisms might drive the network\ntowards more local representations of simple features such as grammatical number.\nIndeed, gating in standard LSTM recurrent networks directly operates on information\nstored in asingleunit (see, e.g., Figure 1 in Lakretz et al. (2019)), and thus only\nindirectly aﬀects information stored in other units of the network. Simple features such\nas grammatical number would be thus preferably manipulated locally by the gating\nmechanism. Intriguingly, there are claims about gating mechanisms being present in the\nbrain, both at the micro (Costa, Assael, Shillingford, de Freitas, & Vogels, 2017; Vogels\nNESTED DEPENDENCIES IN NLMS AND HUMANS 41\n& Abbott, 2009) and macro (O’Reilly, 2006; O’Reilly & Frank, 2006) levels. An\ninteresting question for future work is thus to directly test the eﬀect of gating on the\ntype of emerging representations (on the local-distributed spectrum) in the network.\nFinally, we note that other works that studied the English NLM made available by\nGulordava et al. (2018), or similar gated RNNs, found that, as with long-distance\nagreement, the models partially match human behavior, and partially depart from it,\nalso when handling other linguistic phenomena, such as negative polarity item,\nanaphoric pronoun licensing andﬁller–gap dependencies (e.g., Futrell, Wilcox, Morita,\n& Levy, 2018; Marvin & Linzen, 2018; Wilcox et al., 2018). Future research should thus\nalso attempt to explain behavioral diﬀerences in terms of the mechanisms underlying\nthese various agreement phenomena.\"\n4.2 Processing of Nested Dependencies in NLMs and Humans\nWe next explored agreement processing in recursive structures that comprise nested\nsubject-verb dependencies. Weﬁrst conﬁrmed the prediction stemming from the\nsparsity of the NLM agreement mechanism. The network exhibits exceptional diﬃculty\nin processing an embedded long-range dependency within a nested construction. Since\nNLMs lack a recursive procedure to handle multiple dependencies, once the number\nunits are taken up for the encoding of the outermost dependency, the network fails to\nprocess an embedded long-range dependency. In contrast, we found that NLMs achieve\nrelatively good performance on processingshort-rangeembedded dependencies, as they\ncan rely on short-range number units outside the core sparse mechanism. The\ncooperation between the long- and short-range mechanisms in NLMs therefore allows\nthe network to support the processing of a large proportion of agreement constructions\nin natural language, failing substantially only on relatively uncommon constructions,\nhaving two or more nested dependencies that are all long-range. *\n* In an analysis of the incidence of embedded clauses, Karlsson (2007) showed that center-embedding\nconstructions are relatively uncommon and multiple nested dependencies are practically absent from\nspoken language, and rare in written language.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 42\nHuman results were found to have similarities with the agreement-error patterns of\nNLMs, but also several important points of discrepancy:\n4.2.1 Main Similarities\n•Low error-rates on successive dependencies: humans and the NLM made a relatively\nsmall number of agreement errors on the embedded verb of successive dependencies. For\nNLMs, this is in accordance with the sequential processing observed in its dynamics\n(Figure 5). The agreement mechanism resets after theﬁrst dependency and is thus\navailable to process the second one. For humans, theseﬁndings are in accordance with\ntheir relatively good performance on right-branching constructions (e.g., Blaubergs &\nBraine, 1974; Miller & Isard, 1964)\n•Subject-congruence eﬀect in nested constructions: in the case of a plural subject\nattractor, for all verbs, both humans and NLMs made signiﬁcantly more errors in\nincongruent cases, in which the main and embedded subjects had opposite grammatical\nnumbers.\n•Higher error-rate on embedded compared to main verbs of nested dependencies: a\npositive interaction between verb position and subject congruence was found for both\nshort- and long-range embedded dependencies, suggesting that embedded verbs are\nmore error prone, conﬁrmingPrediction 1.\n4.2.2 Main Diﬀerences\n•NLM performance is worse than chance level on the embedded verb of\nLong-Nested: the major diﬀerence between NLM and human performance (Figures 6 &\nD1) lies in the behaviour of the NLM with respect to the embedded verb in\nLong-Nested. The NLM was worse than chance level, meaning that in most trials the\nnetwork predicts the grammatical number of the embedded verb based on the number\nof the main subject, which is encoded and carried through by the agreement\nmechanism. In contrast, human performance is better than chance level (although only\nmarginally so,p= 0.028).\n•Prediction 2 was not conﬁrmed in humans: a strictly related observation is that the\nNESTED DEPENDENCIES IN NLMS AND HUMANS 43\nNLM made signiﬁcantly more errors on the embedded dependency when the\ndependency was long-range. This was not conﬁrmed in humans, where the interaction\nbetween subject-congruence and length of embedded dependency was not signiﬁcant.\nHumans as well, however, made more errors in the long-range case.\nBearing in mind that the NLM is trained on raw text data, without being provided with\nany explicit grammatical knowledge, the points of similarity between the error patterns\nof humans and the NLM are intriguing. In successive constructions, the sequential\nprocessing by the agreement mechanism explains the low error rate of the NLM,\nsimilarly to that of humans. In nested constructions, the cooperation between short-\nand (sparse) long-range mechanisms produces error patterns that are comparable to\nthose observed in humans, with the exception of performance on the embedded verb in\nthe Long-Nested condition. Note in particular that NLMs and humans agree inﬁnding\nembedded agreement harder than the one in the main clause, despite the fact that the\nlatter is always longer-range.\nHowever, the points of discrepancy raise doubts about whether the agreement\nmechanism in NLMs could be similar to the one employed by humans. The NLM must\nhave developed this mechanism as a sophisticated solution to the language-modeling\ntask, allowing it to achieve high performance on structures commonly encountered in\nthe data. On such interpretation, the relatively uncommon Long-Nested construction\nunveils the limitation of the network, pointing to a major diﬀerence between it and\nhuman subjects. By dissecting the agreement mechanism of the NLM, we could see that\nit does not support genuine recursive processing. In Short-Nested, the network processes\nnested dependencies through the collaboration of twodistinctmechanisms (i.e., short-\nand long-range). In contrast, a fully recursive mechanism for handling possibly inﬁnite\nnested constructions, limited only byﬁnite resources, would presumably exhibit\nself-similarity when processing a subsequent level of the recursive structure.\nThe issue is whether human performance is, in fact, similarly constrained by nested\nconstructions. One level of nesting, as in object-extracted relative clauses, is known to\nbe relatively diﬃcult to parse by human subjects (e.g., Traxler et al., 2002), and\nNESTED DEPENDENCIES IN NLMS AND HUMANS 44\nalthough humans can process two long-range dependencies that are active\nsimultaneously (for example, “The fact that the employee who the manager hired stole\noﬃce supplies worried the executive”; Gibson, 1998), these constructions are quite\ndemanding, as we also observed in our experiments, and are therefore less common in\nnatural language. Three levels of nesting, such as doubly center-embedded sentences,\nare known to be nearly impossible to process and to be virtually non-existent in natural\nlanguage (Karlsson, 2007). Consequently, agreement mechanisms that handle only\nrelatively shallow grammatical dependencies might nonetheless provide a computational\nsolution relevant to human cortical dynamics in some brain regions. If so, the main\ndiscrepancy with respect to Long-Nested might turn out to be of a quantitative nature.\nWhile NLMs can handle only a single long-range dependency and fail on two, humans\ncan handle two simultaneously active long-range dependencies but would fail on three.\nFurther experiments are required to evaluate such interpretation of the results.\n4.3 Comparison with Psycholinguistic Theories of Agreement Processing\nSeveral theories have been suggested in the psycholinguistic literature to account for\nprocessing diﬃculties and agreement errors in nested structures. We now discuss our\nresults in light of some of these theories, which may provide complementary high-level\nexplanations compared to that suggested by the neural-network model. It might be\nworth noting that NLMs have a key advantage compared to existing psycholinguistic\ntheories, as they do not require to assume a grammar or a parsing algorithm. NLMs\nlearn to represent and process underlying structures in natural language by mere\ntraining on the language-modeling task, thus minimizing the number of prior\nassumptions (Lakretz et al., 2020).\n4.3.1 Feature Percolation Theories\nEarly psycholinguistic theories suggested that the proximity between an intervening\nnoun and a verb determines the probability of making an agreement error (Quirk,\n1972). This ‘linear-distance hypothesis’ was later rejected by empiricalﬁndings showing\nthat error rates across a prepositional phrase (PP) are higher compared to those across\nNESTED DEPENDENCIES IN NLMS AND HUMANS 45\na relative clause, although in the former case the subject is closer to the verb and the\nsyntactic complexity of the preamble is smaller (Bock & Cutting, 1992). Following\ntheseﬁndings, Bock and Cutting suggested the ‘clause-packaging hypothesis’, stating\nthat an attractor within the same clause would generate more interference than one in\nanother structural unit.\nMore recent studies supported an alternative ‘syntactic-distance hypothesis’ (Franck et\nal., 2002; Vigliocco et al., 1995; Vigliocco & Franck, 1999), according to which\nagreement errors depend on the distance between the head noun and attractor along\nthe syntactic tree, rather than in the linear order of words. According to this view, the\ngrammatical feature of the attractor is assumed to ‘percolate’ up the syntactic-tree\nduring incremental processing. Such feature percolation can inﬂuence the grammatical\nagreement between the head noun and verb through interference. Feature percolation is\nassumed to take place incrementally during sentence processing. Therefore, the longer\nthe distance from the attractor to the subject-verb path, the lower the likelihood of\ninterference. The syntactic-distance hypothesis accounts for reduced error rates across\nrelative-clauses compared to PPs, and for additional evidence for which the\nclause-packaging hypothesis makes inadequate predictions (Franck et al., 2002).\nHowever, percolation theories have diﬃculties to account for agreement errors on\nembedded dependencies, such as in Short- and Long-Nested. In these constructions, the\nattractor with respect to the embedded dependency is the main subject, and thus\nresides higher on the syntactic tree. As Wagers et al. (2009) note, percolation in such\nconstructions is thus required to happen downwards, whereas percolation theories\ntraditionally assume upward movement through the tree, which could not explain the\nobserved subject-congruence eﬀects. Moreover, syntactic distance between the main and\nembedded subjects is much greater than that between the subject and the attractor in\nsimple constructions with a prepositional phrase. This predicts lower error rates than\nthose reported for PP constructions. However, our results show higher error rates on\nthe embedded verb compared to previously reported errors on PP constructions in\nItalian (Vigliocco et al., 1995).\nNESTED DEPENDENCIES IN NLMS AND HUMANS 46\n4.3.2 Memory-based theories\nIn sentence comprehension, previousﬁndings reported processing facilitation in\nungrammatical sentences due to attraction eﬀects (e.g., Lago et al., 2015; Pearlmutter,\nGarnsey, & Bock, 1999; Wagers et al., 2009). Self-paced reading paradigms showed that\nhumans process the words that follow the verb faster in the presence of a plural\nattractor. Importantly, this eﬀect was reported only for ungrammatical sentences. To\naccount for this grammatical asymmetry, previous studies suggested that a cue-based\nmemory retrieval process (Lewis & Vasishth, 2005) is triggered as a repair mechanism\nfollowing a violation, which, in contrast, would not be triggered in grammatical\nsentences having no violation. This cue-based memory retrieval process is error prone,\nand can thus license a wrong verb form in an ungrammatical sentence, explaining the\nfacilitation observed after the verb in ungrammatical sentences only.\nLewis and Vasishth (2005) applied the Adaptive Control of Thought-Rational\narchitecture (ACT-R; Anderson (2013)) to sentence processing, and suggested that,\nduring incremental processing, the transient syntactic structure of the sentence is\nrepresented across memory ‘chunks’ in declarative memory. During sentence processing,\neach new word triggers a memory retrieval, at the end of which the word is integrated\ninto one of the memory chunks. In the case of verbs, at the end of the retrieval process,\nthe verb will be associated with the appropriate subject stored in memory, ideally,\nhaving the same grammatical number. During retrieval, a ‘competition’ among memory\nchunks takes place, and the chunk with the greatest number of features matching the\nverb is most likely to be retrieved. However, erroneous retrievals can occur, due to noise\nand similarity between memory chunks, in which case a verb carrying the wrong\nnumber might be accidentally licensed.\nCue-based retrieval processes were proposed as a repair mechanism, triggered in the\ncase of a violation (Lago et al., 2015; Wagers et al., 2009). For example, for the nested\nconstructions Short- and Long-nested, during the processing of the relative clause, a\nprediction about the number of the embedded verb is generated. If the embedded verb\nviolates this prediction, as in the case of ungrammatical sentences, a cue-based retrieval\nNESTED DEPENDENCIES IN NLMS AND HUMANS 47\nis triggered in order to check whether the correct feature was missed. An erroneous\nretrieval can then license a verb with the wrong number, leading to facilitated reading\nafterwards. In grammatical sentences, no prediction violation occurs and therefore the\nrepair mechanism will not be triggered, explaining the grammatical asymmetry\ndescribed above.\nIn our study, a violation-detection paradigm was used, and therefore a direct\ncomparison with the results from the described self-paced reading experiments and the\nACT-R model is not possible. However, we note that processing times on the embedded\nand main verbs as predicted by the ACT-R model are consistent with ourﬁndings.\nSimulations of sentence processing in the ACT-R model predict greater processing times\non embedded compared to main verbs. This increase in processing time is due in part\nto an extra retrieval cycle associated with retrieving the relative pronoun and attaching\na trace toﬁll the gap in the relative clause structure (Lewis & Vasishth, 2005). An\naccount in terms of cue-based retrieval as a repair mechanism would thus predict more\nerrors on embedded compared to main verbs in nested constructions. However, since\nprocessing times cannot be directly mapped onto agreement errors, novel simulation\nwork would be necessary to generate quantitative agreement-error predictions from the\nACT-R model, which is beyond the scope of the current study.\nA key diﬀerence in the error generation process between the two models is that while in\nthe ACT-R based model errors arise during the retrieval process, which occurs after the\npresentation of the verb, in the NLM agreement errors are estimated one time step\nbefore the verb, and are due to a wrong prediction of the next verb. Agreement errors\non ungrammatical sentences in the two models are therefore due to diﬀerent dynamics -\nerroneous retrievals vs. erroneous predictions. A possible integration of these diﬀerent\ndynamics is an interesting topic for future work.\n5 Conclusion\nOur study illustrates how investigating emergent mechanisms in neural-network-based\nlanguage models can lead to novel explicit hypotheses about linguistic processing in\nNESTED DEPENDENCIES IN NLMS AND HUMANS 48\nhumans, and even to testable predictions about cortical dynamics. The possibility of\nachieving a mechanistic understanding of natural language processing in modern NLMs\ncan thus inform research in psycho- and neurolinguistics.\nConcerning the speciﬁc object of our study, we found that the NLM fails to perform\ngenuinely recursive processing of nested constructions. The network develops\ngrammar-sensitive agreement mechanisms for handling constructions up to one degree\nof nesting only. However, the NLM behaviour matches in part various patterns of\nhuman agreement error data, showing remarkable similarity across various sentence\nconstructions. Future research should further probe the nature of the similarities and\ndiﬀerences between NLMs and humans, establishing to what extent they are only\nquantitative in nature, and to what extent they point to a speciﬁc adaptation of human\nneural networks for genuine recursion.\nThis work was supported by the Bettencourt-Schueller Foundation and an ERC grant,\n“NeuroSyntax” project, to S.D.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 49\n6 References\nAnderson, J. R. (2013).The architecture of cognition. Psychology Press.\nBaayen, H., Davidson, D., & Bates, D. (2008). Mixed-eﬀects modeling with crossed\nrandom eﬀects for subjects and items.Journal of Memory and Language,59,\n390–412.\nBates, D., Maechler, M., Bolker, B., & Walker, S. (2015).lme4: Linear mixed-eﬀects\nmodels using eigen and s4. r package version 1.1–7. 2014.\nBates, E., & Dick, F. (2002). Language, gesture, and the developing brain.\nDevelopmental Psychobiology: The Journal of the International Society for\nDevelopmental Psychobiology,40(3), 293–310.\nBates, E., MacWhinney, B., et al. (1989). Functionalism and the competition model.\nThe crosslinguistic study of sentence processing,3, 73–112.\nBernardy, J., & Lappin, S. (2017). Using deep neural networks to learn syntactic\nagreement.Linguistic Issues in Language Technology,15(2), 1–15.\nBlaubergs, M. S., & Braine, M. D. (1974). Short-term memory limitations on decoding\nself-embedded sentences.Journal of Experimental Psychology,102(4), 745.\nBock, K., Carreiras, M., & Meseguer, E. (2012). Number meaning and number\ngrammar in english and spanish.Journal of Memory and Language,66(1), 17–37.\nBock, K., & Cutting, J. C. (1992). Regulating mental energy: Performance units in\nlanguage production.Journal of memory and language,31(1), 99–127.\nBock, K., & Miller, C. (1991). Broken agreement.Cognitive Psychology,23(1), 45–93.\nBreedin, S. D., & Saﬀran, E. M. (1999). Sentence processing in the face of semantic\nloss: A case study.Journal of Experimental Psychology: General,128(4), 547.\nBreedin, S. D., Saﬀran, E. M., & Coslett, H. B. (1994). Reversal of the concreteness\neﬀect in a patient with semantic dementia.Cognitive neuropsychology,11(6),\n617–660.\nBrysbaert, M., Stevens, M., Mandera, P., & Keuleers, E. (2016). How many words do\nwe know? practical estimates of vocabulary size dependent on word deﬁnition, the\ndegree of language input and the participant’s age.Frontiers in psychology,7,\nNESTED DEPENDENCIES IN NLMS AND HUMANS 50\n1116.\nCaramazza, A., & Zurif, E. B. (1976). Dissociation of algorithmic and heuristic\nprocesses in language comprehension: Evidence from aphasia.Brain and\nlanguage,3(4), 572–582.\nChomsky, N. (1957).Syntactic structures. Berlin, Germany: Mouton.\nChomsky, N. (1984).Modular approaches to the study of the mind(Vol. 1). San Diego\nState University Press San Diego.\nCichy, R. M., & Kaiser, D. (2019). Deep neural networks as scientiﬁc models.Trends in\nCognitive Sciences,23(4), 305–317.\nCosta, R., Assael, I. A., Shillingford, B., de Freitas, N., & Vogels, T. (2017). Cortical\nmicrocircuits as gated-recurrent neural networks. InAdvances in neural\ninformation processing systems(pp. 272–283).\nDapretto, M., & Bookheimer, S. Y. (1999). Form and content: dissociating syntax and\nsemantics in sentence comprehension.Neuron,24(2), 427–432.\nDehaene, S., Meyniel, F., Wacongne, C., Wang, L., & Pallier, C. (2015). The neural\nrepresentation of sequences: From transition probabilities to algebraic patterns\nand linguistic trees.Neuron,88(1), 2–19.\nDick, F., Bates, E., Wulfeck, B., Utman, J. A., Dronkers, N., & Gernsbacher, M. A.\n(2001). Language deﬁcits, localization, and grammar: evidence for a distributive\nmodel of language breakdown in aphasic patients and neurologically intact\nindividuals.Psychological review,108(4), 759.\nEberhard, K. M. (1997). The marked eﬀect of number on subject–verb agreement.\nJournal of Memory and language,36(2), 147–164.\nElman, J. (1990). Finding structure in time.Cognitive Science,14, 179–211.\nElman, J. (1991). Distributed representations, simple recurrent networks, and\ngrammatical structure.Machine Learning,7, 195–225.\nEmbick, D., Marantz, A., Miyashita, Y., O’Neil, W., & Sakai, K. L. (2000). A syntactic\nspecialization for broca’s area.Proceedings of the National Academy of Sciences,\n97(11), 6150–6154.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 51\nFedorenko, E., Blank, I., Siegelman, M., & Mineroﬀ, Z. (2020). Lack of selectivity for\nsyntax relative to word meanings throughout the language network.bioRxiv,\n477851.\nFodor, J. (1983).The modularity of mind. MIT press.\nFodor, J., & Lepore, E. (1999). All at sea in semantic space: Churchland on meaning\nsimilarity.Journal of Philosophy,96(8), 381–403.\nFodor, J., & Pylyshyn, Z. (1988). Connectionism and cognitive architecture: A critical\nanalysis.Cognition,28, 3–71.\nFranck, J., Frauenfelder, U. H., & Rizzi, L. (2007). A syntactic analysis of interference\nin subject–verb agreement.MIT working papers in linguistics(53), 173–190.\nFranck, J., Lassi, G., Frauenfelder, U. H., & Rizzi, L. (2006). Agreement and\nmovement: A syntactic analysis of attraction.Cognition,101(1), 173–216.\nFranck, J., Vigliocco, G., & Nicol, J. (2002). Subject-verb agreement errors in french\nand english: The role of syntactic hierarchy.Language and cognitive processes,\n17(4), 371–404.\nFriederici, A. D., Fiebach, C. J., Schlesewsky, M., Bornkessel, I. D., & Von Cramon,\nD. Y. (2006). Processing linguistic complexity and grammaticality in the left\nfrontal cortex.Cerebral Cortex,16(12), 1709–1717.\nFutrell, R., Wilcox, E., Morita, T., & Levy, R. (2018). Rnns as psycholinguistic\nsubjects: Syntactic state and grammatical dependency.arXiv preprint\narXiv:1809.01329.\nFutrell, R., Wilcox, E., Morita, T., Qian, P., Ballesteros, M., & Levy, R. (2019). Neural\nlanguage models as psycholinguistic subjects: Representations of syntactic state.\nInProceedings of naacl(pp. 32–42). Minneapolis, MN.\nGarrard, P., Carroll, E., Vinson, D., & Vigliocco, G. (2004). Dissociation of lexical\nsyntax and semantics: Evidence from focal cortical degeneration.Neurocase,\n10(5), 353–362.\nGibson, E. (1998). Linguistic complexity: Locality of syntactic dependencies.\nCognition,68(1), 1–76.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 52\nGiulianelli, M., Harding, J., Mohnert, F., Hupkes, D., & Zuidema, W. (2018). Under\nthe hood: Using diagnostic classiﬁers to investigate and improve how language\nmodels track agreement information. InProceedings of the emnlp blackboxnlp\nworkshop(pp. 240–248). Brussels, Belgium.\nGoldberg, Y. (2017).Neural network methods for natural language processing. San\nFrancisco, CA: Morgan & Claypool.\nGraves, A. (2012).Supervised sequence labelling with recurrent neural networks. Berlin:\nSpringer.\nGulordava, K., Bojanowski, P., Grave, E., Linzen, T., & Baroni, M. (2018). Colorless\ngreen recurrent networks dream hierarchically. InProceedings of naacl(pp.\n1195–1205). New Orleans, LA.\nHagoort, P. (2014). Nodes and networks in the neural architecture for language:\nBroca’s region and beyond.Current opinion in Neurobiology,28, 136–141.\nHart, B., & Risley, T. R. (1995).Meaningful diﬀerences in the everyday experience of\nyoung american children.Paul H Brookes Publishing.\nHashimoto, R., & Sakai, K. L. (2002). Specialization in the left prefrontal cortex for\nsentence comprehension.Neuron,35(3), 589–597.\nHauser, M., Chomsky, N., & Fitch, T. (2002, 11). The faculty of language: What is it,\nwho has it, and how did it evolve?Science,298(5598), 1569–1579.\nHochreiter, S., & Schmidhuber, J. (1997). Long short-term memory.Neural\nComputation,9(8), 1735–1780.\nHodges, J. R., & Patterson, K. (1996). Nonﬂuent progressive aphasia and semantic\ndementia: a comparative neuropsychological study.Journal of the International\nNeuropsychological Society,2(6), 511–524.\nJaeger, T. F. (2008). Categorical data analysis: Away from anovas (transformation or\nnot) and towards logit mixed models.Journal of memory and language,59(4),\n434–446.\nJumelet, J., Zuidema, W., & Hupkes, D. (2019). Analysing neural language models:\nContextual decomposition reveals default reasoning in number and gender\nNESTED DEPENDENCIES IN NLMS AND HUMANS 53\nassignment.arXiv preprint arXiv:1909.08975.\nJurafsky, D., & Martin, J. (2020).Speech and language processing, 3d ed.Upper Saddle\nRiver: Prentice Hall.\nKarlsson, F. (2007). Constraints on multiple center-embedding of clauses.Journal of\nLinguistics,43(2), 365–392.\nKuncoro, A., Dyer, C., Hale, J., Yogatama, D., Clark, S., & Blunsom, P. (2018).\nLSTMs can learn syntax-sensitive dependencies well, but modeling structure\nmakes them better. InProceedings of acl(pp. 1426–1436). Melbourne, Australia.\nLago, S., Shalom, D. E., Sigman, M., Lau, E. F., & Phillips, C. (2015). Agreement\nattraction in spanish comprehension.Journal of Memory and Language,82,\n133–149.\nLakretz, Y., Dehaene, S., & King, J.-R. (2020). What limits our capacity to process\nnested long-range dependencies in sentence comprehension?Entropy,22(4), 446.\nLakretz, Y., Desbordes, T., King, J.-R., Crabbé, B., Oquab, M., & Dehaene, S. (2021).\nCan rnns learn recursive nested subject-verb agreements?arXiv preprint\narXiv:2101.02258.\nLakretz, Y., Kruszewski, G., Desbordes, T., Hupkes, D., Dehaene, S., & Baroni, M.\n(2019). The emergence of number and syntax units in LSTM language models. In\nProceedings of naacl(pp. 11–20). Minneapolis, MN.\nLeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning.Nature,521, 436–444.\nLewis, R. L., & Vasishth, S. (2005). An activation-based model of sentence processing\nas skilled memory retrieval.Cognitive science,29(3), 375–419.\nLinzen, T., Dupoux, E., & Goldberg, Y. (2016). Assessing the ability of LSTMs to\nlearn syntax-sensitive dependencies.Transactions of the Association for\nComputational Linguistics,4, 521–535.\nLinzen, T., & Leonard, B. (2018). Distinct patterns of syntactic agreement errors in\nrecurrent networks and humans. InProceedings of cogsci(pp. 692–697). Austin,\nTX.\nLorimor, H., Bock, K., Zalkind, E., Sheyman, A., & Beard, R. (2008). Agreement and\nNESTED DEPENDENCIES IN NLMS AND HUMANS 54\nattraction in russian.Language and cognitive processes,23(6), 769–799.\nMarvin, R., & Linzen, T. (2018). Targeted syntactic evaluation of language models.\narXiv preprint arXiv:1808.09031.\nMcCloskey, M. (1991). Networks and theories: The place of connectionism in cognitive\nscience.Psychological Science,2(6), 387–395.\nMikolov, T. (2012).Statistical language models based on neural networks(Dissertation).\nBrno University of Technology.\nMikolov, T., Yih, W.-t., & Zweig, G. (2013). Linguistic regularities in continuous space\nword representations. InProceedings of naacl(pp. 746–751). Atlanta, Georgia.\nMiller, G. A., & Isard, S. (1964). Free recall of self-embedded english sentences.\nInformation and Control,7(3), 292–303.\nMollica, F., Siegelman, M., Diachek, E., Piantadosi, S. T., Mineroﬀ, Z., Futrell, R., &\nFedorenko, E. (2018). High local mutual information drives the response in the\nhuman language network.bioRxiv, 436204.\nO’Reilly, R. C. (2006). Biologically based computational models of high-level cognition.\nscience,314(5796), 91–94.\nO’Reilly, R. C., & Frank, M. J. (2006). Making working memory work: a computational\nmodel of learning in the prefrontal cortex and basal ganglia.Neural computation,\n18(2), 283–328.\nPallier, C., Devauchelle, A.-D., & Dehaene, S. (2011). Cortical representation of the\nconstituent structure of sentences.Proceedings of the National Academy of\nSciences,108(6), 2522–2527.\nPearlmutter, N. J., Garnsey, S. M., & Bock, K. (1999). Agreement processes in sentence\ncomprehension.Journal of Memory and language,41(3), 427–456.\nPinker, S. (1994).The language instinct. New York, NY: William Morrow.\nPress, O., & Wolf, L. (2016). Using the output embedding to improve language models.\narXiv preprint arXiv:1608.05859.\nQuirk, R. (1972).A grammar of contemporary english. Longman Group.\nRadford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019).Language\nNESTED DEPENDENCIES IN NLMS AND HUMANS 55\nmodels are unsupervised multitask learners.\nhttps://d4mucfpksywv.cloudfront.net/better-language-models/\nlanguage-models.pdf.\nRumelhart, D., McClelland, J., & PDP Research Group (Eds.). (1986a).Parallel\ndistributed processing: Explorations in the microstructure of cognition, vol. 1:\nFoundations. Cambridge, MA: MIT Press.\nRumelhart, D., McClelland, J., & PDP Research Group (Eds.). (1986b).Parallel\ndistributed processing: Explorations in the microstructure of cognition, vol. 2:\nPsychological and biological models. Cambridge, MA: MIT Press.\nRussin, J., Jo, J., & Randall, C. (2019). ’reilly, and yoshua bengio.Compositional\ngeneralization in a deep seq2seq model by separating syntax and semantics.\nSiegelman, M., Blank, I. A., Mineroﬀ, Z., & Fedorenko, E. (2019). An attempt to\nconceptually replicate the dissociation between syntax and semantics during\nsentence comprehension.Neuroscience,413, 219–229.\nSmolensky, P. (1990). Tensor product variable binding and the representation of\nsymbolic structures in connectionist networks.Artiﬁcial Intelligence,46, 159–216.\nTeam, R. C., et al. (2013). R: A language and environment for statistical computing.\nTraxler, M. J., Morris, R. K., & Seely, R. E. (2002). Processing subject and object\nrelative clauses: Evidence from eye movements.Journal of Memory and\nLanguage,47(1), 69–90.\nUllman, M. T. (2004). Contributions of memory circuits to language: The\ndeclarative/procedural model.Cognition,92(1-2), 231–270.\nVigliocco, G. (2000). Language processing: The anatomy of meaning and syntax.\nCurrent Biology,10(2), R78–R80.\nVigliocco, G., Butterworth, B., & Semenza, C. (1995). Constructing subject-verb\nagreement in speech: The role of semantic and morphological factors.Journal of\nMemory and Language,34(2), 186–215.\nVigliocco, G., & Franck, J. (1999). When sex and syntax go hand in hand: Gender\nagreement in language production.Journal of Memory and Language,40(4),\nNESTED DEPENDENCIES IN NLMS AND HUMANS 56\n455–478.\nVogels, T. P., & Abbott, L. (2009). Gating multiple signals through detailed balance of\nexcitation and inhibition in spiking networks.Nature neuroscience,12(4), 483.\nWagers, M. W., Lau, E. F., & Phillips, C. (2009). Agreement attraction in\ncomprehension: Representations and processes.Journal of Memory and\nLanguage,61(2), 206–237.\nWilcox, E., Levy, R., Morita, T., & Futrell, R. (2018). What do RNN language models\nlearn aboutﬁller-gap dependencies? InProceedings of the emnlp blackboxnlp\nworkshop(pp. 211–221). Brussels, Belgium.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 57\nAppendix A\nFigure A1\nEﬀect of single-unit ablation on number-agreement performance in the Gulordava\nItalian network: to identify number units, we ablated each time a diﬀerent unit in the\nmodel and tested the ablated model on the number-agreement task. A blue (orange) dot\nrepresents accuracy of an ablated model on the SP (PS) condition of the\nNounPP-number task (Table 1). The ablation of a relatively small number of units led\nto a signiﬁcant reduction in model performance (z−score <−3; computed based on the\ndistribution of all 1300 single-unit ablation eﬀects). In particular, the ablation of unit\n815 from the second layer of the network led to a signiﬁcant reduction in performance in\nboth incongruent conditions of the NounPP NA-task: for SP, accuracy=0.95\n(z−score=−30.1; full-model accuracy=0.98); for PS, accuracy=0.75\n(z−score=−27.1; full-model accuracy=0.94). For the SP condition, unit 815 was\nfollowed by one more unit with a signiﬁcant eﬀect, unit 1119 (z−score=−6.8), and\nfor PS, it was followed by three more units - 860, 1119 and 782\n(z−scores=−18.0,−7.9and−7.4, respectively).\nNESTED DEPENDENCIES IN NLMS AND HUMANS 58\nFigure A2\nSuccess probability after single-unit ablations of the model from Gulordava et\nal. (2018): Same procedure and color scheme as described in the caption of Figure A1.\nSuccess probability was deﬁned as pcorrect\n(pcorrect+pwrong ) (section 2.1.5), where0.5corresponds\nto chance-level performance. Similarly to the results from the single-unit ablation study\nusing accuracy as a measure (Figure A1), two units in the SP condition and four units\nin the PS condition resulted in signiﬁcant reduction in performance (z−score <−3).\nNESTED DEPENDENCIES IN NLMS AND HUMANS59\nFigure A3\nThe single-unit ablation study with all 20 models: to test the robustness of the sparsity of the long-range mechanism, we trained 19\nadditional neural language models (NLMs), using the same hyperparameters as those used for training the NLM in Gulordava et al.,\n(2018), Model-G in short. For each NLM, we repeated the single-unit ablation study. Blue and orange dots correspond to accuracy of the\nablated models on the SP and PS conditions of the NounPP-number task, respectively (see caption of Figure A1). For all models, for\nboth SP and PS conditions, the ablation of at least one of the units led to a signiﬁcant reduction in model performance (z-score<-17.3 in\nall cases). However, unlike for the English Gulordava network, none of the single-unit ablations led to chance-level performance. To\nfurther quantify the sparsity of the long-range mechanism, we therefore conducted the top-k ablation study (Figure 2).\nNESTED DEPENDENCIES IN NLMS AND HUMANS 60\nFigure A4\nEvidence from ablation about the sparsity of the long-range mechanism for gender:\nTo determine the number of recurrent units that participate in the long-range\nmechanism of gender agreement, we repeated the top-k ablation study for the\ngender-agreement task (GA-task; Methods). For all 20 Italian NLMs, model\nperformance on the GA-task was re-evaluated after the ablation of the topkunits from\nthe single-unit ablation study (k= 1, ..10;k= 0corresponds to the full, non-ablated,\nmodel). Model performance is shown separately for the MF (continuous) and FM\n(dashed lines) conditions. Black lines indicate the average performance across all\nmodels, and the shaded grey area represents the corresponding SEM. For both\nincongruent conditions, mean model performance sharply drops after the ablation of a\nsingle unit, reaching near chance-level performance (MF:0.56±0.04; FM:0.52±0.02)\nafter the ablation of only 3 units (out of 1300 units in the network). This shows that\ngender information for long-range agreement is sparsely encoded in the models.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 61\nAppendix B\nFigure B1\nThe long-range number-encoding mechanism consistently emerges across models,\nwith only two variants:Mean input- (i t), forget-gate (f t) and cell-state (C t) dynamics\nare shown for the top (k= 1) units from the single-unit ablation study, from four\nmodels, during the processing of the NounPP NA-task. Error bars represent the standard\ndeviation across trials. The emerging mechanism show similar patterns to those\nidentiﬁed in the English model (Lakretz et al., 2019). Speciﬁcally, at the main subject,\ninput-gate activity rises towards its maximal value. For ‘bi-polar’ units, input-gate\nactivity is responsive to both singular and plural subjects (top panels), whereas for\n‘uni-polar’ plural units (bottom), it is selective to plural subjects only. After the subject,\nforget-gate activity rises towards the maximal value and remains so up until the verb.\nThis is required for continuous memorization of its grammatical number. Finally, input-\nand forget-gate dynamics lead to sustained cell-state activity from the subject to verb,\ncarrying the grammatical number of the subject across the attractor and up to the verb.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 62\nFigure B2\nGate and state dynamics for theﬁrst top three units from Gulordava’s network:\nMean input-gate (i t), forget-gate (f t), cell-state (C t) and hidden-state (h t) activity\ndynamics are shown for the top three units from the single-unit ablation study\n(k= 1,2,3), during the processing of the Long-Nested number-agreement task. Error\nbars correspond to the standard deviation across trials. The top unit (k=1) shows robust\npropagation of the grammatical number of the main subject across the main dependency.\nThe second unit (k=2) shows similar patterns but number propagation is less robust\nbefore inner attractor (h t activity at the 7 th time point). The third top unit (k= 3) does\nnot show clear long-range number-encoding patterns.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 63\nAppendix C\nFigure C1\nEﬀerent weights of number and gender units: number and gender units were found in\nthe second layer of the network. Units in this layer project onto the output layer, in\nwhich each unit corresponds to a word in the lexicon (50,000 in total). We tested\nwhether the eﬀerent weights of the number (gender) units are clustered with respect to\ngrammatical number (gender). A: eﬀerent weights of long-range (815; blue), short-range\nnumber units (green) andﬁve arbitrary units (black). Short-range units were identiﬁed\nby detecting units in the network that (1) consistently encode grammatical number in\nseparate values, (2) their activity is sensitive to the last encountered noun, and (3) their\noutput weights are clustered with respect to number, as shown here. All weights project\nto units in the output layer that correspond to singular and plural forms of verbs. Only\nweights of number units are clustered with respect to grammatical number. B: eﬀerent\nweights of the gender unit (1100; magenta) andﬁve arbitrary units. All weights project\nonto units in the output layer that correspond to masculine and feminine forms of\nadjectives. Only the weights of the gender unit are clustered with respect to gender value.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 64\nFigure C2\nEﬀective eﬀerent weights of the top 10 units from the single-unit ablation study:A:\nEﬀective eﬀerent weights for the 10 top units in the Gulordava Italian network for the\nPS condition. The eﬀective eﬀerent weight was computed as the product of the eﬀerent\nweight and the mean unit activity (h t) one time step before verb prediction. The\nseparation between the eﬀective weights to units that correspond to singular and plural\nforms of the verb decreases as a function ofk, with largest separation for the top four\nunits. B: Mean eﬀective eﬀerent weights to the output layer, averaged across models.\nGrey shaded area represents the corresponding SEM. Consistently with the above results\nfrom Gulordava’s network, a monotonic decrease is observed as a function ofk.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 65\nFigure C3\nInput and output word embeddings of the Italian Gulordava network:Top - output\nembeddings: a two-dimensional visualization of the adjectives (panel A) and verbs (panel\nB) from the number- and gender-agreement tasks are shown. The two leading principal\ncomponents (PCs) for the 650-dimensional word embeddings are presented. Singular\nand plural forms of the words are marked with red and blue, respectively. Masculine and\nfeminine adjectives are marked with italic and bold, respectively. For both adjectives and\nverbs, theﬁrst PC separates singular and plural forms of the words. For adjectives, the\nsecond PC also separates masculine and feminine, with PC values consistently greater\nfor feminine compared to the corresponding masculine form. Bottom - input\nembeddings: same color scheme and font styles. For nouns (panel C), the6 th and8 th\nPCs are presented; for articles (panel D; including articles in contracted form with a\npreceding preposition), the2 nd and3 rd PCs are presented. For nouns, values of the6 th\nPC are consistently greater for the singular compared to the corresponding plural form of\nthe word; and the values of the8 th PC are consistently greater for the feminine\ncompared to the corresponding masculine form. For articles, the two PCs separate\nsingular and plural forms of the words.\nNESTED DEPENDENCIES IN NLMS AND HUMANS66\nAppendix D\nFigure D1\nError rates for all conditions:collected from the NLM (panels A & B) and human subjects (C & D). Blue & Cyan (red & magenta)\ncolors correspond to whether the main and embedded subjects agree (don’t agree) on number. Secondary colors (cyan or magenta)\nrepresent the presence of a nested attractor carrying an opposite grammatical number to that of the embedded subject. Bars with stripes\ncorrespond to conditions in which the main subject is plural. Error bars represent the 95% conﬁdence level.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 67\nFigure D2\nError rates on grammatical sentences in the behavioral experiment with humans:for\nthe four constructions - Short-Successive (panel A), Long-Successive (B), Short-Nested\n(C) and Long-Nested (D). Color coding is the same as in Figure D1. Error bars\nrepresent the 95% conﬁdence level.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 68\nFigure D3\nMean error rates for the 20 models:Blue and red colors correspond to whether the\nmain and embedded subjects agree on number (congruent subjects) or not (incongruent),\nrespectively. Error bars represent the 95% conﬁdence level. Error rates were computed\nbased on the output probabilities predicted by the network for the two possible values of\ngrammatical number. Each trial in which the predicted probability of the wrong\ngrammatical number was higher than that of the correct one was counted as an error.\nNESTED DEPENDENCIES IN NLMS AND HUMANS 69\nAppendix E\nMaterials for the Behavioral Experiment with Humans\nSyntactic violations were generated by either,\ni) replacing a verb with a wrong person without changing number, for example:\n“ilfratelloche lostudente *accolgoamai contadini” (“thebrotherthat thestudent\n*welcome-1st-pers-singlovesthe farmers”); or\nii) replacing a verb with a noun, for example, “ilfratelloche lostudente *amica\namai contadini” (“thebrotherthat thestudent *friendlovesthe farmers”; note that\nthe chosen replacement nouns were not ambiguous with verb forms in Italian); or\niii) replacing a verb with its inﬁnitive form, for example, “ilfratelloche lo\nstudente *accogliereamai contadini” (“thebrotherthat thestudent *to-welcomeloves\nthe farmers”).\nSemantic violations were generated by replacing one of the nouns with either\ni) an inappropriate abstract one, for example, “la*ﬁlosoﬁa diceche laﬁglia ama\nla madre” (“*philosophy saysthat thedaughter lovesthe mother”); or\nii) an inanimate noun, for example, “la*matita diceche laﬁglia amala madre”\n(“the*pencil saysthat thedaughter lovesthe mother”).\nTo avoid correlation between abstract or inanimate nouns and semantic\nviolations, half of theseﬁller trials were felicitous, for example, “ilpadre diceche la\nﬁglia amala *ﬁlosoﬁa” (“thefather saysthat thedaughter loves*philosophy”), or “il\npadre diceche la*matita appartieneallaﬁglia” (“thefather saysthat the*pencil\nbelongsto the daughter”).\nNESTED DEPENDENCIES IN NLMS AND HUMANS 70\nNouns masculine\nfratello, studente, padre,ﬁglio, ragazzo, bambino,\namico, uomo, attore, contadino\nfeminine\nsorella, studentessa, madre,ﬁglia, ragazza, bambina,\namica, donna, attrice, contadina\nVerbs\naccogliere, amare, attrarre, bloccare, conoscere,\ncriticare, difendere, evitare, fermare, guardare, ignorare,\nincontrare, indicare, interrompere, osservare, salutare\nMatrix verbs ricordare, dire, dichiarare, sognare\nCopula essere\nPrepositions vicino a, dietro a, davanti a, accanto a\nAdjectives\nbello, famoso, brutto, ricco, povero, basso, alto, grasso,\ncattivo, buono, lento, nuovo\nTable E1\nLexicon used for the agreement tasks. For the nouns, we reported thesingularforms, in\nour experiments we use both singular and plural forms. The verb forms reported in the\ntable are the inﬁnitive form, in our experiments, we use the third person singular and\nplural inﬂections.",
  "topic": "Artificial neural network",
  "concepts": [
    {
      "name": "Artificial neural network",
      "score": 0.5830123424530029
    },
    {
      "name": "Plural",
      "score": 0.5729393362998962
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5726959109306335
    },
    {
      "name": "Sentence",
      "score": 0.5717157125473022
    },
    {
      "name": "Natural language processing",
      "score": 0.5407621264457703
    },
    {
      "name": "Computer science",
      "score": 0.49752238392829895
    },
    {
      "name": "Agreement",
      "score": 0.4911184012889862
    },
    {
      "name": "Verb",
      "score": 0.4711560010910034
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.4668154716491699
    },
    {
      "name": "Recursion (computer science)",
      "score": 0.45391231775283813
    },
    {
      "name": "Noun",
      "score": 0.432685524225235
    },
    {
      "name": "Range (aeronautics)",
      "score": 0.4125722348690033
    },
    {
      "name": "Comprehension",
      "score": 0.4112755060195923
    },
    {
      "name": "Linguistics",
      "score": 0.2631072700023651
    },
    {
      "name": "Algorithm",
      "score": 0.10972169041633606
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Composite material",
      "score": 0.0
    },
    {
      "name": "Materials science",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210128565",
      "name": "CEA Paris-Saclay",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I4210143253",
      "name": "Cognitive Neuroimaging Lab",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I2738703131",
      "name": "Commissariat à l'Énergie Atomique et aux Énergies Alternatives",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I154526488",
      "name": "Inserm",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I277688954",
      "name": "Université Paris-Saclay",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I66752286",
      "name": "University of Milano-Bicocca",
      "country": "IT"
    },
    {
      "id": "https://openalex.org/I11932220",
      "name": "Institució Catalana de Recerca i Estudis Avançats",
      "country": "ES"
    },
    {
      "id": "https://openalex.org/I187986737",
      "name": "Collège de France",
      "country": "FR"
    }
  ]
}