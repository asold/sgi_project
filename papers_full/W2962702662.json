{
  "title": "Model Transfer for Tagging Low-resource Languages using a Bilingual Dictionary",
  "url": "https://openalex.org/W2962702662",
  "year": 2017,
  "authors": [
    {
      "id": "https://openalex.org/A2152013896",
      "name": "Meng Fang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2188741563",
      "name": "Trevor Cohn",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2270364989",
    "https://openalex.org/W2494423583",
    "https://openalex.org/W2142523187",
    "https://openalex.org/W2143995218",
    "https://openalex.org/W2251699420",
    "https://openalex.org/W2168199177",
    "https://openalex.org/W179875071",
    "https://openalex.org/W2252046065",
    "https://openalex.org/W2027979924",
    "https://openalex.org/W2250741688",
    "https://openalex.org/W2963907318",
    "https://openalex.org/W2471692228",
    "https://openalex.org/W2577255746",
    "https://openalex.org/W2426917359",
    "https://openalex.org/W2147880316",
    "https://openalex.org/W1940872118",
    "https://openalex.org/W2161044106"
  ],
  "abstract": "Cross-lingual model transfer is a compelling and popular method for predicting annotations in a low-resource language, whereby parallel corpora provide a bridge to a high-resource language, and its associated annotated corpora. However, parallel data is not readily available for many languages, limiting the applicability of these approaches. We address these drawbacks in our framework which takes advantage of cross-lingual word embeddings trained solely on a high coverage dictionary. We propose a novel neural network model for joint training from both sources of data based on cross-lingual word embeddings, and show substantial empirical improvements over baseline techniques. We also propose several active learning heuristics, which result in improvements over competitive benchmark methods.",
  "full_text": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 587–593\nVancouver, Canada, July 30 - August 4, 2017.c⃝2017 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17-2093\nProceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 587–593\nVancouver, Canada, July 30 - August 4, 2017.c⃝2017 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17-2093\nModel Transfer for Tagging Low-resource Languages using a Bilingual\nDictionary\nMeng Fang and Trevor Cohn\nSchool of Computing and Information Systems\nThe University of Melbourne\nmeng.fang@unimelb.edu.au, t.cohn@unimelb.edu.au\nAbstract\nCross-lingual model transfer is a com-\npelling and popular method for predicting\nannotations in a low-resource language,\nwhereby parallel corpora provide a bridge\nto a high-resource language and its associ-\nated annotated corpora. However, parallel\ndata is not readily available for many lan-\nguages, limiting the applicability of these\napproaches. We address these drawbacks\nin our framework which takes advantage\nof cross-lingual word embeddings trained\nsolely on a high coverage bilingual dictio-\nnary. We propose a novel neural network\nmodel for joint training from both sources\nof data based on cross-lingual word em-\nbeddings, and show substantial empirical\nimprovements over baseline techniques.\nWe also propose several active learning\nheuristics, which result in improvements\nover competitive benchmark methods.\n1 Introduction\nPart-of-speech (POS) tagging is an important ﬁrst\nstep in most natural language processing (NLP)\napplications. Typically this is modelled using\nsequence labelling methods to predict the con-\nditional probability of taggings given word se-\nquences, using linear graphical models (Lafferty\net al., 2001), or neural network models, such as\nrecurrent neural networks (RNN) (Mikolov et al.,\n2010; Huang et al., 2015). These supervised learn-\ning algorithms rely on large labelled corpora; this\nis particularly true for state-of-the-art neural net-\nwork models. Due to the expense of annotating\nsufﬁcient data, such techniques are not well suited\nto applications in low-resource languages.\nPrior work on low-resource NLP has primarily\nfocused on exploiting parallel corpora to project\ninformation between a high- and low-resource\nlanguage (Yarowsky and Ngai, 2001; T ¨ackstr¨om\net al., 2013; Guo et al., 2015; Agi ´c et al., 2016;\nBuys and Botha, 2016). For example, POS tags\ncan be projected via word alignments, and the pro-\njected POS is then used to train a model in the low-\nresource language (Das and Petrov, 2011; Zhang\net al., 2016; Fang and Cohn, 2016). These meth-\nods overall have limited effectiveness due to errors\nin the alignment and fundamental differences be-\ntween the languages. They also assume a large\nparallel corpus, which may not be available for\nmany low-resource languages.\nTo address these limitations, we propose a new\ntechnique for low resource tagging, with more\nmodest resource requirements: 1) a bilingual dic-\ntionary; 2) monolingual corpora in the high and\nlow resource languages; and 3) a small annotated\ncorpus of around 1,000 tokens in the low-resource\nlanguage. The ﬁrst two resources are used as a\nform of distant supervision through learning cross-\nlingual word embeddings over the monolingual\ncorpora and bilingual dictionary (Ammar et al.,\n2016). Additionally, our model jointly incor-\nporates the language-dependent information from\nthe small set of gold annotations. Our approach\ncombines these two sources of supervision us-\ning multi-task learning, such that the kinds of er-\nrors that occur in cross-lingual transfer can be ac-\ncounted for, and corrected automatically.\nWe empirically demonstrate the validity of our\nobservation by using distant supervision to im-\nprove POS tagging performance with little super-\nvision. Experimental results show the effective-\nness of our approach across several low-resource\nlanguages, including both simulated and true low-\nresource settings. Furthermore, given the clear su-\nperiority of training with manual annotations, we\ncompare several active learning heuristics. Active\nlearning using uncertainty sampling with a word-\n587\ncross-lingual\nword \nembedding, e\ntext, x\nshared\nlayers\ndistant label, y Noun Verb Noun\n...\nh\u0003\nh\u0002\nDet NounConj\nAugmented layer\u0001\nlabel, y\nDistantly)supervised)data) Manually)Labeled)data\nraha ny marina tsara fa misaotra \nFigure 1: Illustration of the architecture of the joint model, which performs joint inference over both\ndistant supervision (left) and manually labelled data (right).\ntype bias leads to substantial gains over bench-\nmark methods such as token or sentence level un-\ncertainty sampling.\n2 Related work\nPOS tagging has been studied for many years.\nTraditionally, probabilistic models are a popular\nchoice, such as Hidden Markov Models (HMM)\nand Conditional Random Fields (CRF) (Lafferty\net al., 2001). Recently, neural network mod-\nels have been developed for POS tagging and\nachieved good performance, such as RNN and\nbidirectional long short-term memory (BiLSTM)\nand CRF-BiLSTM models (Mikolov et al., 2010;\nHuang et al., 2015). For example, the CRF-\nBiLSTM POS tagger obtained the state-of-the-\nart performance on Penn Treebank WSJ cor-\npus (Huang et al., 2015).\nHowever, in low-resource languages, these\nmodels are seldom used because of limited la-\nbelled data. Parallel data therefore appears to be\nthe most realistic additional source of informa-\ntion for developing NLP systems in low-resource\nlanguages (Yarowsky and Ngai, 2001; Das and\nPetrov, 2011; T ¨ackstr¨om et al., 2013; Fang and\nCohn, 2016; Zhang et al., 2016). Yarowsky and\nNgai (2001) pioneered the use of parallel data for\nprojecting POS tag information from one language\nto another language. Das and Petrov (2011) used\nparallel data and exploited graph-based label prop-\nagation to expand the coverage of labelled tokens.\nT¨ackstr¨om et al. (2013) constructed tag dictionar-\nies by projecting tag information from a high-\nresource language to a low-resource language via\nalignments in the parallel text. Fang and Cohn\n(2016) used parallel data to obtain projected tags\nas distant labels and proposed a joint BiLSTM\nmodel trained on both the distant data and 1,000\ntagged tokens. Zhang et al. (2016) used a few\nword translations pairs to ﬁnd a linear transfor-\nmation between two language embeddings. Then\nthey used unsupervised learning to reﬁne embed-\nding transformations and model parameters. In-\nstead we use minimal supervision to reﬁne ‘dis-\ntant’ labels through modelling the tag transforma-\ntion, based on a small set of annotations.\n3 Model\nWe now describe the modelling framework for\nPOS tagging in a low-resource language, based on\nvery limited linguistic resources. Our approach\nextends the work of Fang and Cohn (2016), who\npresent a model based on distant supervision in\nthe form of cross-lingual projection and use pro-\njected tags generated from parallel corpora as dis-\ntant annotations. There are three main differences\nbetween their work and ours: 1) We do not use par-\nallel corpora, but instead use a bilingual dictionary\nfor knowledge transfer. 2) Our model uses a more\nexpressive multi-layer perceptron when generat-\ning the gold standard tags. The multi-layer per-\nceptron can capture both language-speciﬁc infor-\n588\nCross-lingual word \nembeddings\nBidirectional LSTM\nOutput y\nInput x\nSoftmax\nFigure 2: Architecture of the universal POS tag-\nger. Cross-lingual word embeddings are pre-\ntrained using monolingual corpora and bilingual\ndictionaries.\nmation and consistent tagging errors arising from\nthis method of supervision. 3) We propose a num-\nber of active learning methods to further reduces\nthe annotation requirements. Our method is illus-\ntrated in Figure 1, and we now elaborate on the\nmodel components.\nDistant cross-lingual supervision In order to\ntransfer tag information between the high- and\nlow-resource languages, we start by learning\ncross-lingual word embeddings, which operate\nby learning vector valued embeddings such that\nwords and their translations tend to be close to-\ngether in the vector space. We use the embeddings\nfrom Ammar et al. (2016) which trains mono-\nlingual word2vec distributional representations,\nwhich are then projected into a common space,\nlearned from bilingual dictionaries.\nWe then train a POS tagger on the high-resource\nlanguage, using the cross-lingual word embed-\ndings as the ﬁrst, ﬁxed, layer of a bidirectional\nLSTM tagger. The tagger is a language-universal\nmodel based on cross-lingual word embeddings,\nfor processing an arbitrary language, given a\nmonolingual corpus and a bilingual dictionary,\nas shown in Figure 2. Next we apply this tag-\nger to unannotated text in the low-resource lan-\nguage; this application is made possible through\nthe use of cross-lingual word embeddings. We\nrefer to text tagged this way as distantly super-\nvised data, and emphasize that although much bet-\nter than chance, the outputs are often incorrect and\nare of limited utility on their own.\nAs illustrated in Figure 1, the distant compo-\nnents are generated directly as softmax outputs,\nyt ∼ Categorial(ot), with parameters ot =\nSoftmax(Wht + b) as a linear classiﬁer over a\nsentence encoding, ht, which is the output of a\nbidirectional LSTM encoder over the words.\nGround truth supervision The second compo-\nnent of the model is manually labelled text in the\nlow-resource language. To model this data we em-\nploy the same model structure as above but aug-\nmented with a second perceptron output layer, as\nillustrated in Figure 1 (right). Formally, ˜yt ∼\nCategorial(˜ot) where ˜ot = MLP(ot) is a single\nhidden layer perceptron with tanh activation and\nsoftmax output transformation. This component\nallows for a more expressive label mapping than\nFang and Cohn (2016)’s linear matrix translation.\nJoint multi-task learning To combine the two\nsources of information, we use a joint objective,\nJ= −γ\n∑\nt∈N\n⟨˜yt,log ˜ot⟩−\n∑\nt∈M\n⟨yt,log ot⟩, (1)\nwhere N and Mindex the token positions in\nthe distant and ground truth corpora, respectively,\nand γis a constant balancing the two components\nwhich we set for uniform weighting, γ = |M|\n|N| .\nConsider the training effect of the true POS\ntags: when performing error backpropagation, the\ncross-entropy error signal must pass through the\ntransformation linking ˜owith o, which can be seen\nas a language-speciﬁc step, after which the gener-\nalised error signal can be further backpropagated\nto the rest of the model.\nActive learning Given the scarcity of ground\ntruth labels and the high cost of annotation, a natu-\nral question is whether we can optimise which text\nto be annotated in order achieve the high accuracy\nfor the lowest cost. We now outline a range of\nactive learning approaches based on the following\nheuristics, which are used to select the instances\nfor annotation from a pool of candidates:\nTOKEN Select the token xt\nwith the highest uncertainty,\nH(x,t) =−∑\ny P(y|x,t) logP(y|x,t);\nSENT Select the sentence x with the highest ag-\ngregate uncertainty, H(x) =∑\nt H(x,t);\nFREQ TYPE Select the most frequent unanno-\ntated word type (Garrette and Baldridge,\n2013), in which case all token instances are\n589\nannotated with the most frequent label for the\ntype in the training corpus;1\nSUMTYPE Select a word type, z, for an-\nnotation with the highest aggregate\nuncertainty over token occurrences,\nH(z) =∑\ni∈D\n∑\nxi,t=z H(xi,t), which\neffectively combines uncertainty sampling\nwith a bias towards high frequency types;\nand\nRANDOM Select word types randomly.\n4 Experiments\nWe evaluate the effectiveness of the proposed\nmodel for several different languages, including\nboth simulated low-resource and true low-resource\nsettings. The ﬁrst evaluation set uses the CoNLL-\nX datasets of European languages (Buchholz and\nMarsi, 2006), comprising Danish (da), Dutch (nl),\nGerman (de), Greek (el), Italian (it), Portuguese\n(pt), Spanish (es) and Swedish (sv). We use the\nstandard corpus splits. The ﬁrst 20 sentences of\ntraining set are used for training as the tiny la-\nbelled (gold) data and the last 20 sentences are\nused for development (early stopping). We report\naccuracy on the held-out test set.\nThe second evaluation set includes two highly\nchallenging languages, Turkish (tk) and Malagasy\n(mg), both having high morphological complexity\nand the latter has truly scant resources. Turkish\ndata was drawn from CoNLL 20032 and Malagasy\ndata was collected from Das and Petrov (2011), in\nboth cases using the same training conﬁguration\nas above.\nIn all cases English is used as the source ‘high\nresource’ language, on which we train a tagger\nusing the Penn Treebank, and we evaluate on\neach of the remaining languages as an indepen-\ndent target. For cross-lingual word embeddings,\nwe evaluate two techniques from Ammar et al.\n(2016): CCA-based word embeddings and cluster-\nbased word embeddings. Both types of word em-\nbedding techniques are based on bilingual dictio-\nnaries. The dictionaries were formed by trans-\nlating the 20k most common words in the En-\n1We could support more than one class label, by marginal-\nising over the set of valid labels for all tokens in the training\nobjective.\n2http://www.cnts.ua.ac.be/conll2003/ner/\nglish monolingual corpus with Google Translate.3\nThe monolingual corpora were constructed from\na combination of text from the Leipzig Corpora\nCollection and Europarl. We trained the language-\nuniversal POS tagger based on the cross-lingual\nword embeddings with the universal POS tagset\n(Petrov et al., 2011), and then applied to the tar-\nget language using the embedding lookup table\nfor the corresponding language embeddings. We\nimplement our learning procedure with the DyNet\ntoolkit (Neubig et al., 2017).4 The BiLSTM layer\nuses 128 hidden units, and 32 hidden units for the\ntransformation step. We used SGD with momen-\ntum to train models, with early stopping based on\ndevelopment performance.\nFor benchmarks, we compare the proposed\nmodel against various state-of-the-art supervised\nlearning methods, namely: a B ILSTM tagger,\nBILSTM-C RF tagger (Huang et al., 2015), and\na state-of-the-art semi-supervised POS tagging\nalgorithm, M INI TAGGER (Stratos and Collins,\n2015), which is also focusing on minimising\nthe amount of labelled data. Note these meth-\nods do not use cross-lingual supervision. For a\nmore direct comparison, we include B ILSTM-\nDEBIAS (Fang and Cohn, 2016), applied using our\nproposed cross-lingual supervision based on dic-\ntionaries, instead of parallel corpora; accordingly\nthe key difference is their linear transformation for\nthe distant data, versus our non-linear transforma-\ntion to the gold data.\nResults Table 1 reports the tagging accuracy,\nshowing that our models consistently outperform\nthe baseline techniques. The poor performance of\nthe supervised methods suggests they are overﬁt-\nting the small training set, however this is much\nless of a problem for our approach (labelled Joint).\nNote that distant supervision alone gives reason-\nable performance (labelled DISTANT ) however the\njoint modelling of the ground truth and distant\ndata yields signiﬁcant improvements in almost all\ncases. B ILSTM-D EBIAS (Fang and Cohn, 2016)\nperforms worse than our proposed method, indi-\ncating that a linear transformation is insufﬁcient\nfor modelling distant supervision. The accuracies\nare higher overall for the European cf. Turkic lan-\nguages, presumably because these languages are\n3Although the use of a translation system conveys a de-\npendence on parallel text, high quality word embeddings can\nbe learned directly from bilingual dictionaries such as Panlex\n(Kamholz et al., 2014).\n4Code available at https://github.com/mengf1/trpos\n590\nda nl de el it pt es sv tk mg\nRandom 23.2 30.5 27.1 23.2 25.9 24.3 26.9 21.6 36.9 34.5\nBILSTM 61.8 62.1 60.5 70.1 73.6 67.6 63.6 57.2 44.0 63.4\nBILSTM-C RF 46.3 47.7 53.2 35.1 41.2 44.1 25.5 54.9 43.1 41.4\nMINI TAGGER 77.0 72.5 75.9 75.7 67.3 75.1 73.5 77.7 49.8 67.2\nDISTANT +CCA 73.5 64.5 57.7 53.1 59.5 67.8 63.5 66.0 57.2 49.7\nDISTANT +Cluster 70.4 61.7 65.9 65.5 64.8 66.9 68.4 64.1 51.7 50.2\nBILSTM-D EBIAS +CCA 73.2 72.8 72.5 71.2 70.7 72.1 71.1 73.1 49.2 65.9\nBILSTM-D EBIAS +Cluster 72.5 70.1 71.2 68.7 69.1 72.5 70.6 73.3 48.7 64.5\nJOINT +CCA 81.1 82.3 76.1 77.5 75.9 82.1 79.7 78.1 72.6 75.3\nJOINT +Cluster 81.9 81.5 78.9 80.1 81.9 76.7 81.2 78.0 70.4 75.7\nTable 1: POS tagging accuracy on over the ten target languages, showing ﬁrst approaches using only the\ngold data; next methods using only distant cross-lingual supervision, and lastly joint multi-task learning.\nEnglish is used as the source language and columns correspond to a speciﬁc target language.\n●\n●\n●\n●\n●\n● ● ● ● ● ● ●\n●\n●\n● ●\n● ●\n● ● ● ● ● ●\nde el\n10 100 200 400 1000 10 100 200 400 1000\n0.25\n0.50\n0.75\nnum. words (tokens or types)\naccuracy\n● FreqType\nRandom\nSent(Joint)\nSent(Trad)\nSumType(Joint)\nSumType(Trad)\nToken(Joint)\nToken(Trad)\nFigure 3: Active learning evaluation on German and Greek, using CCA trained cross-lingual word em-\nbeddings. Trad means traditional active learning; Joint means joint multi-task learning.\ncloser to English, have higher quality dictionaries\nand in most cases are morphologically simpler. Fi-\nnally, note the difference between CCA and Clus-\nter methods for learning word embeddings which\narise from the differing quality of distant supervi-\nsion between the languages.\nFigure 3 compares various active learning\nheuristics (see §3) based on different taggers, ei-\nther a supervised B ILSTM (labelled Trad) or\nour multi-task model which also includes cross-\nlingual supervision (JOINT ).\nTraditional uncertainty-based sampling strate-\ngies (TOKEN (Trad) and SENT (Trad)) do not work\nwell because models based on limited supervision\ndo not provide accurate uncertainty information, 5\nand moreover, annotating at the type rather than\ntoken level provides a signiﬁcantly stronger su-\npervision signal. The difference is apparent from\nthe decent performance of Random sampling over\nword types. Overall, S UMTYPE (Joint) outper-\nforms the other heuristics consistently, underlin-\ning the importance of cross-lingual distant super-\n5Sentence level annotation is likely to be much faster than\ntoken or type level annotation, however even if it were an\norder of magnitude faster it is still not a competitive active\nlearning strategy.\nvision, as well as combining the beneﬁts of un-\ncertainty sampling, type selection and a frequency\nbias. Comparing the amount of annotation re-\nquired between the best traditional active learn-\ning method SUMTYPE (Trad) and our best method\nSUMTYPE (Joint), we achieve the same perfor-\nmance with an order of magnitude less annotated\ndata (100 vs. 1,000 labelled words).\n5 Conclusion\nIn this paper, we proposed a means of tagging\na low-resource language without the need for\nbilingual parallel corpora. We introduced a new\ncross-lingual distant supervision method based on\na bilingual dictionary. Furthermore, deep neu-\nral network models can be effective with limited\nsupervision by incorporating distant supervision,\nin the form of model transfer with cross-lingual\nword embeddings. We show that traditional un-\ncertainty sampling strategies do not work well on\nlow-resource settings, and introduce new methods\nbased around labelling word types. Overall our\napproach leads to consistent and substantial im-\nprovements over benchmark methods.\n591\nAcknowledgments\nThis work was sponsored by the Defense Ad-\nvanced Research Projects Agency Information In-\nnovation Ofﬁce (I2O) under the Low Resource\nLanguages for Emergent Incidents (LORELEI)\nprogram issued by DARPA/I2O under Contract\nNo. HR0011-15-C-0114. The views expressed are\nthose of the author and do not reﬂect the ofﬁcial\npolicy or position of the Department of Defense\nor the U.S. Government. Trevor Cohn was sup-\nported by the Australian Research Council Future\nFellowship (project number FT130101105).\nReferences\nˇZeljko Agi ´c, Anders Johannsen, Barbara Plank,\nH´ector Alonso Mart´ınez, Natalie Schluter, and An-\nders Søgaard. 2016. Multilingual projection for\nparsing truly low-resource languages. Transactions\nof the Association for Computational Linguistics\n4:301–312.\nWaleed Ammar, George Mulcaire, Yulia Tsvetkov,\nGuillaume Lample, Chris Dyer, and Noah A Smith.\n2016. Massively multilingual word embeddings.\nTransactions of the Association for Computational\nLinguistics 4:431–444.\nSabine Buchholz and Erwin Marsi. 2006. Conll-x\nshared task on multilingual dependency parsing. In\nProceedings of the Tenth Conference on Computa-\ntional Natural Language Learning. Association for\nComputational Linguistics, pages 149–164.\nJan Buys and Jan A. Botha. 2016. Cross-lingual mor-\nphological tagging for low-resource languages. In\nProceedings of the 54th Annual Meeting of the Asso-\nciation for Computational Linguistics (ACL). Asso-\nciation for Computational Linguistics, Berlin, Ger-\nmany, pages 1954–1964.\nDipanjan Das and Slav Petrov. 2011. Unsupervised\npart-of-speech tagging with bilingual graph-based\nprojections. In Proceedings of the 49th Annual\nMeeting of the Association for Computational Lin-\nguistics: Human Language Technologies (ACL-\nHLT). pages 600–609.\nMeng Fang and Trevor Cohn. 2016. Learning when\nto trust distant supervision: An application to low-\nresource pos tagging using cross-lingual projec-\ntion. In Proceedings of the 20th SIGNLL Confer-\nence on Computational Natural Language Learning\n(CoNLL). Berlin, Germany.\nDan Garrette and Jason Baldridge. 2013. Learning a\npart-of-speech tagger from two hours of annotation.\nIn Proceedings of the 2013 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies\n(NAACL-HLT). Citeseer, pages 138–147.\nJiang Guo, Wanxiang Che, David Yarowsky, Haifeng\nWang, and Ting Liu. 2015. Cross-lingual depen-\ndency parsing based on distributed representations.\nIn Proceedings of the 53rd Annual Meeting of the\nAssociation for Computational Linguistics (ACL).\nAssociation for Computational Linguistics, pages\n1234–1244.\nZhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirec-\ntional lstm-crf models for sequence tagging. arXiv\npreprint arXiv:1508.01991.\nDavid Kamholz, Jonathan Pool, and Susan M Colow-\nick. 2014. Panlex: Building a resource for panlin-\ngual lexical translation. In Proceedings of the Ninth\nInternational Conference on Language Resources\nand Evaluation (LREC). pages 3145–3150.\nJohn Lafferty, Andrew McCallum, and Fernando\nPereira. 2001. Conditional random ﬁelds: Prob-\nabilistic models for segmenting and labeling se-\nquence data. In Proceedings of the 8th Interna-\ntional Conference on Machine Learning (ICML).\nvolume 1, pages 282–289.\nTomas Mikolov, Martin Karaﬁ ´at, Lukas Burget, Jan\nCernock`y, and Sanjeev Khudanpur. 2010. Recur-\nrent neural network based language model. In Inter-\nspeech. volume 2, page 3.\nGraham Neubig, Chris Dyer, Yoav Goldberg, Austin\nMatthews, Waleed Ammar, Antonios Anastasopou-\nlos, Miguel Ballesteros, David Chiang, Daniel\nClothiaux, Trevor Cohn, Kevin Duh, Manaal\nFaruqui, Cynthia Gan, Dan Garrette, Yangfeng Ji,\nLingpeng Kong, Adhiguna Kuncoro, Gaurav Ku-\nmar, Chaitanya Malaviya, Paul Michel, Yusuke\nOda, Matthew Richardson, Naomi Saphra, Swabha\nSwayamdipta, and Pengcheng Yin. 2017. Dynet:\nThe dynamic neural network toolkit. arXiv preprint\narXiv:1701.03980 .\nSlav Petrov, Dipanjan Das, and Ryan McDonald. 2011.\nA universal part-of-speech tagset. arXiv preprint\narXiv:1104.2086 .\nKarl Stratos and Michael Collins. 2015. Simple semi-\nsupervised pos tagging. In Proceedings of the 2015\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies (NAACL-HLT). pages 79–\n87.\nOscar T ¨ackstr¨om, Dipanjan Das, Slav Petrov, Ryan\nMcDonald, and Joakim Nivre. 2013. Token and type\nconstraints for cross-lingual part-of-speech tagging.\nTransactions of the Association for Computational\nLinguistics 1:1–12.\nDavid Yarowsky and Grace Ngai. 2001. Inducing mul-\ntilingual POS taggers and NP brackets via robust\nprojection across aligned corpora. In Proceedings of\nthe 2001 Conference of the North American Chap-\nter of the Association for Computational Linguistics\n(NAACL).\n592\nYuan Zhang, David Gaddy, Regina Barzilay, and\nTommi Jaakkola. 2016. Ten pairs to tag–\nmultilingual pos tagging via coarse mapping be-\ntween embeddings. In Proceedings of the 2016 Con-\nference of the North American Chapter of the Asso-\nciation for Computational Linguistics: Human Lan-\nguage Technologies (NAACL-HLT). pages 1307–\n1317.\n593",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8833364844322205
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6453117728233337
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.6361767649650574
    },
    {
      "name": "Heuristics",
      "score": 0.6235637664794922
    },
    {
      "name": "Natural language processing",
      "score": 0.6089749336242676
    },
    {
      "name": "Transfer of learning",
      "score": 0.5685737133026123
    },
    {
      "name": "Word (group theory)",
      "score": 0.5403345823287964
    },
    {
      "name": "Bilingual dictionary",
      "score": 0.5193127989768982
    },
    {
      "name": "Limiting",
      "score": 0.5086918473243713
    },
    {
      "name": "Bridge (graph theory)",
      "score": 0.5074440836906433
    },
    {
      "name": "Baseline (sea)",
      "score": 0.4923747777938843
    },
    {
      "name": "Resource (disambiguation)",
      "score": 0.4669208526611328
    },
    {
      "name": "Artificial neural network",
      "score": 0.41305166482925415
    },
    {
      "name": "Linguistics",
      "score": 0.0
    },
    {
      "name": "Mechanical engineering",
      "score": 0.0
    },
    {
      "name": "Internal medicine",
      "score": 0.0
    },
    {
      "name": "Engineering",
      "score": 0.0
    },
    {
      "name": "Medicine",
      "score": 0.0
    },
    {
      "name": "Geography",
      "score": 0.0
    },
    {
      "name": "Geology",
      "score": 0.0
    },
    {
      "name": "Oceanography",
      "score": 0.0
    },
    {
      "name": "Computer network",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Geodesy",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [],
  "cited_by": 86
}