{
  "title": "Controlling Pre-trained Language Models for Grade-Specific Text Simplification",
  "url": "https://openalex.org/W4389524027",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2105928631",
      "name": "Sweta Agrawal",
      "affiliations": [
        "University of Maryland, College Park"
      ]
    },
    {
      "id": "https://openalex.org/A2056869143",
      "name": "Marine Carpuat",
      "affiliations": [
        "University of Maryland, College Park"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2936695845",
    "https://openalex.org/W1647671624",
    "https://openalex.org/W3117704329",
    "https://openalex.org/W2970328625",
    "https://openalex.org/W2980278874",
    "https://openalex.org/W4386339184",
    "https://openalex.org/W2401830275",
    "https://openalex.org/W1965949675",
    "https://openalex.org/W3153637831",
    "https://openalex.org/W2964029788",
    "https://openalex.org/W3170773997",
    "https://openalex.org/W4386339106",
    "https://openalex.org/W2042262613",
    "https://openalex.org/W4285180072",
    "https://openalex.org/W2550821151",
    "https://openalex.org/W3176122622",
    "https://openalex.org/W2997195635",
    "https://openalex.org/W2605243085",
    "https://openalex.org/W4281690218",
    "https://openalex.org/W3177494585",
    "https://openalex.org/W4404783646",
    "https://openalex.org/W2467834614",
    "https://openalex.org/W3194727116",
    "https://openalex.org/W4386339173",
    "https://openalex.org/W133394232",
    "https://openalex.org/W2741986794",
    "https://openalex.org/W2011544221",
    "https://openalex.org/W4289753256",
    "https://openalex.org/W4287779338",
    "https://openalex.org/W2807895655",
    "https://openalex.org/W2963513671",
    "https://openalex.org/W2534253848",
    "https://openalex.org/W1964157370",
    "https://openalex.org/W2899168892",
    "https://openalex.org/W2949305705",
    "https://openalex.org/W4287028715",
    "https://openalex.org/W2138238299",
    "https://openalex.org/W2963283805",
    "https://openalex.org/W3173957073",
    "https://openalex.org/W4386339135",
    "https://openalex.org/W2973049837"
  ],
  "abstract": "Text simplification systems rewrite text to make it more readable while preserving its content. However, what makes a text easy to read depends on the intended readers. Recent work has shown that pre-trained language models can simplify text using a wealth of techniques to control output simplicity, ranging from specifying only the desired reading grade level, to directly specifying low-level edit operations. Yet it remains unclear how to set these control parameters in practice. Existing approaches set them at the corpus level, disregarding the complexity of individual inputs and considering only one level of output complexity. In this work, we conduct an empirical study to understand how different control mechanisms impact the adequacy and simplicity of text simplification systems. Based on these insights, we introduce a simple method that predicts the edit operations required for simplifying a text for a specific grade level on an instance-per-instance basis. This approach improves the quality of the simplified outputs over corpus-level search-based heuristics.",
  "full_text": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 12807–12819\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nControlling Pre-trained Language Models\nfor Grade-Specific Text Simplification\nSweta Agrawal\nDepartment of Computer Science\nUniversity of Maryland\nsweagraw@umd.edu\nMarine Carpuat\nDepartment of Computer Science\nUniversity of Maryland\nmarine@umd.edu\nAbstract\nText simplification (TS) systems rewrite text to\nmake it more readable while preserving its con-\ntent. However, what makes a text easy to read\ndepends on the intended readers. Recent work\nhas shown that pre-trained language models\ncan simplify text using a wealth of techniques\nto control output simplicity, ranging from spec-\nifying only the desired reading grade level, to\ndirectly specifying low-level edit operations.\nYet it remains unclear how to set these control\nparameters in practice. Existing approaches\nset them at the corpus level, disregarding the\ncomplexity of individual inputs and consider-\ning only one level of output complexity. In\nthis work, we conduct an empirical study to\nunderstand how different control mechanisms\nimpact the adequacy and simplicity of text sim-\nplification systems. Based on these insights, we\nintroduce a simple method that predicts the edit\noperations required for simplifying a text for a\nspecific grade level on an instance-per-instance\nbasis. This approach improves the quality of\nthe simplified outputs over corpus-level search-\nbased heuristics.\n1 Introduction\nIn the NLP task of text simplification, systems are\nasked to rewrite, restructure or modify an original\ntext such that it improves the readability of the\noriginal text for a target audience while preserving\nits meaning. However, text can be simplified in\nmany different ways and what makes a text simple\nto read depends on the reader. Replacing complex\nor specialized terms with simpler synonyms might\nhelp non-native speakers (Petersen and Ostendorf,\n2007; Allen, 2009), restructuring text into short\nsentences with simple words might better match the\nliteracy skills of children (Watanabe et al., 2009).\nAcknowledging that text simplification is highly\naudience-centric (Stajner, 2021), recent work has\nfocused on developing techniques to control the\nOriginal: Paracho, the “guitar capital of Mex-\nico,” makes nearly 1 million classical guitars a\nyear, many exported to the United States.\nGrade 5: Paracho is known as the “guitar cap-\nital of Mexico.” The town makes nearly 1 mil-\nlion classical guitars a year, with many exported\nto the United States.\nWord Length Ratio (W): 1.19\nDependency Tree Depth Ratio (DTD): 1.50\nGrade 3: Paracho is known as the “guitar capi-\ntal of Mexico.” The town makes many guitars\nand sells some in the United States.\nWord Length Ratio (W): 0.96\nDependency Tree Depth Ratio (DTD): 1.00\nFigure 1: Simplified texts can be obtained by either\nspecifying the target audience (via grade level) or by\nusing low-level control tokens to define theTS operation\nto be performed relative to the complex text (W, DTD).\ndegree of simplicity of the output at different lev-\nels. At a high level, one can simply specify the\ndesired reading grade level of the output (Scarton\nand Specia, 2018; Kew and Ebling, 2022). At a\nlow level, one can control complexity by describ-\ning the nature of simplification operations to be\nperformed (Mallinson and Lapata, 2019; Martin\net al., 2020). For example (Figure 1), one could ob-\ntain two distinct simplifications of the same inputs\nby indicating that they are intended for a grade 6\nvs. grade 3 audience, or by specifying values for\nlow-level control tokens such as the word length\nratio (W) between the source and the target and\nthe maximum dependency tree depth (DTD) ratio\nbetween the source and the target. For an original\ncomplex text at grade 8, when simplifying to grade\n5, the low-level control values indicate a conserva-\ntive rewrite, whereas, for grade 3, the properties\nencoded by the control tokens reflect a relatively\nmore lexical and structural change.\n12807\nWhile specifying a reading grade level might\nbe more intuitive for lay users, it provides weaker\ncontrol over the nature of simplification to be per-\nformed. On the other hand, controlling the outputs’\nsimplicity by setting several low-level properties,\nsuch as the number of words or dependency tree\ndepth, provides finer-grained control but can be\ncumbersome to set by readers, teachers, or other\nusers. As a result, it remains unclear how to op-\nerationalize the control of text simplification in\npractice. Prior work sets low-level control values\n(length, degree of paraphrasing, lexical complex-\nity, and syntactic complexity) at the corpus level\nby searching for control token values on a devel-\nopment set. This is done via maximizing a utility\ncomputed using an automatic evaluation metric,\nSARI , a metric designed to measure lexical sim-\nplicity (Xu et al., 2016). While this approach is ap-\npealing in its simplicity, it remains unclear whether\nthis approach actually helps control complexity for\nindividual inputs, as the control token values are\nalways set at the corpus level.\nThis work presents a systematic empirical study\nof the impact of control tokens on the degree and\nquality of simplifications achieved at the instance\nlevel as measured by automatic text simplifica-\ntion metrics. Our empirical study shows that most\ncorpus-level control tokens have an opposite im-\npact on adequacy and simplicity when measured\nby BLEU and SARI respectively. As a result, se-\nlecting their values based on SARI alone yields\nsimpler text at the cost of misrepresenting the orig-\ninal source content. To address this problem, we\nintroduce simple models to predict what control\ntokens are needed for a given input text and a de-\nsired grade level, based on surface-form features\nextracted from the source text and the desired com-\nplexity level. We show that the predicted low-level\ncontrol tokens improve text simplification on a con-\ntrollable TS task compared to corpus-level search-\nbased optimization.\n2 Background on Controllable Text\nSimplification\nWhile text simplification has been primarily framed\nas a task that rewrites complex text in simpler lan-\nguage in the NLP literature (Chandrasekar et al.,\n1996; Coster and Kauchak, 2011; Shardlow, 2014;\nSaggion, 2017; Zhang and Lapata, 2017), in practi-\ncal applications, it is not sufficient to know that the\noutput is simpler. Instead, it is necessary to target\nthe complexity of the output language to a specific\naudience (Stajner, 2021). Controllable Text Sim-\nplification can be framed as a conditional language\nmodeling task, where the source textXis rewritten\nas an output Y that presents attributes V as scored\nby a model P(Y|X,V ) (Prabhumoye et al., 2020).\nIn sequence-to-sequence models, techniques to con-\ntrol the properties V during generation fall under\ntwo categories depending on whether they modify\nthe training process (Sennrich et al., 2016; Holtz-\nman et al., 2018; Dathathri et al., 2019; Li et al.,\n2022) as described below, or are supplied as con-\nstraints during inference (Hokamp and Liu, 2017;\nGhazvininejad et al., 2017; Kumar et al., 2021). 1\nControl Token Mechanisms A straightforward\nmethod to capture a target attribute, V, in text gen-\neration models is to represent it as a special token\nappended to the input sequence, [V; X], which acts\nas a side constraint Sennrich et al. (2016). These\nconstraints can be appended to the source or the\ntarget sequence.2 The encoder learns a hidden rep-\nresentation for this token as for any other vocabu-\nlary token, and the decoder can attend to this rep-\nresentation to guide the generation of the output\nsequence. This simple strategy has been used to\ncontrol second-person pronoun forms when trans-\nlating into German (Sennrich et al., 2016), formal-\nity when translating to French (Niu et al., 2018), the\ntarget language in multilingual scenarios (Johnson\net al., 2016) and to control style, content, and task-\nspecific behavior for conditional language models\n(Keskar et al., 2019).\nWe provide an overview of the control tokens\nintroduced in prior work for text simplification in\nTables 1 and 2. Coarse-grained control over the\ndegree and the nature of the simplification, e.g. via\nsource and target grade levels is easier to inter-\npret by end users (Table 1, [1-6, 12]), whereas\ncontrolling multiple low-level attributes (Table 1,\n[7-11]) that map text simplification operations\nto specific properties of the input and the output\ntext can provide better control over the generated\ntext. However, it is unclear how those low-level\ncontrol values should be set during inference as\nthese could vary significantly based on the source\n1Please refer to Prabhumoye et al. (2020) for a full review\non controllable text generation techniques.\n2It is important to note that the term “control” used in\nthis paper does not imply strict constraint enforcement on the\nmodel’s output. Rather, the control tokens or side constraints\nmerely serve as inputs that influence the model’s behavior and\nencourage the generation of outputs with desired properties.\n12808\nPAPER-ID PAPER CONTROLTOKENS HOW TOSET?\n[1] Scarton and Specia (2018) Target Grade and/or Operations User-defined or Predicted\n[2] Nishihara et al. (2019)\nTarget Grade (TG) User-defined\n[3] Agrawal et al. (2021)\n[4] Yanamoto et al. (2022)\n[5] Zetsu et al. (2022)\n[6] Agrawal and Carpuat (2022)+Source Grade\n[7] Martin et al. (2020) ACCESS {C, L, WR, DTD}\nCorpus-level Optimization with SARI[8] Sheang and Saggion (2021)+W\n[9] Martin et al. (2022) −L+RL\n[10] Maddela et al. (2021) CC Average over the training dataset\n[11] Qiao et al. (2022) 10 Psycho-linguistic Features Corpus-level Optimization with SARI\n[12] Kew and Ebling (2022) λper grade-level Hyperparameter Tuning with SARI\nTable 1: Control tokens define the nature and degree of simplifications either at a coarse-grained level such as\nspecifying a target grade or via multiple low-level attributes like ACCESS. The control values are typically provided\nby the users or are set apriori during inference.\nID NAME DESCRIPTION\nC NbChars character length ratio between source and target.\nL LevSim character-level Levenshtein similarity (Levenshtein, 1966) be-\ntween source and target.\nWR WordRank ratio of log-ranks (inverse frequency order) between source and\ntarget.\nDTD DepTreeDepth maximum depth of the dependency tree of the source divided by\nthat of the target.\nW NbWords word length ratio between source and target.\nRL Replace-only LevSim character-level Levenshtein similarity only considering replace\noperations between source and target.\nCC Copy Control percentage of copying between source and the target\nTable 2: Control Tokens introduced in prior work cover a wide range of TS edit operations.\ntext and the degree of simplification required. In\nall prior work (Martin et al., 2020, 2022; Sheang\net al., 2022; Qiao et al., 2022), these values are set\nand evaluated at the corpus level. This is achieved\nby doing a hyperparameter search, optimizing for\na single metric SARI on the entire validation set.\nSARI measures the lexical simplicity based on\nthe n-grams kept, added, and deleted by the sys-\ntem relative to the source and the target sequence.\nWe identify two key issues with this corpus-level\nsearch-based strategy for setting control values as\ndescribed below:\nInput Agnostic Control Setting these control\nvalues at the corpus level disregards the nature and\ncomplexity of the original source text. It does not\naccount for what can and should be simplified in\na given input (Garbacea et al., 2021) and to what\nextent. We show that the control values are indeed\ndependent on all these factors as exhibited by a\nlarge variation observed in the values of the con-\ntrol tokens both at the corpus level (Figure 7) and\nindividual target grade levels (Figure 9).\nCostly Hyperparameter Search Searching for\ncontrol tokens value at the corpus-level is an ex-\npensive process. Martin et al. (2022) use the One-\nPlusOne optimizer with a budget of 64 evaluations\nusing the NEVERGRAD library to set the 4 AC-\nCESS hyperparameters (up to 2 hours on a single\nGPU). Sheang et al. (2022) select the values that\nachieve the best SARI on the validation set with\n500 runs. This takes >= 3 days when training the\nmodel takes only 10-15 hours. As these values are\ndomain and corpus-specific, optimizing these val-\nues even at the corpus level for multiple datasets is\ncomputationally expensive.\n12809\nWe provide an analysis of the impact of these\ncontrol values defined at the corpus level on the\ndegree and nature of TS performed at the instance\nlevel in the next section.\n3 How do Control Tokens Impact TS?\nStudy Settings We study the impact of setting\nthe low-level control values at the corpus level on\nthe instance-level simplification observed using au-\ntomatic text simplification metrics. We conduct our\nanalysis on the Newsela-grade dataset (Agrawal\nand Carpuat, 2019), which consists of news arti-\ncles associated with multiple reference simplifi-\ncations for diverse reading grade levels, and thus\nlets us analyze the degree and nature of simplifica-\ntion observed across inputs and target readability\nlevels. This data is collected from Newsela, 3 an\ninstructional content platform meant to help teach-\ners prepare a curriculum that matches the language\nskills required at each grade level and has been\nused in prior work to benchmark controllable TS\nmodels (Scarton and Specia, 2018; Nishihara et al.,\n2019). It includes up to 4 text rewrites at various\ncomplexity levels (defined by U.S. reading grade\nlevels 2-12) for an originally complex text. We use\nthe control tokens defined in Sheang et al. (2022)\n(see Table 2 [1-5]) added to the source text as a\nside constraint in the format, W_{} C_{} L_{}\nWR_{} DTD_{} {Source_text}.\nInstance-Level Findings Following prior work\n(Martin et al., 2020), we select the control tokens\nthat maximize SARI on the Newsela-grade devel-\nopment set. We measure the complexity of the\noutputs generated and compare them with the com-\nplexity of the Newsela references by computing the\nAutomatic Readability Index (Senter and Smith,\n1967, ARI, Refer Equation 1).\nAs can be seen in Figure 2, control tokens set at\nthe corpus level using SARI tend to over or under-\nsimplify individual input instances. When the refer-\nence distribution exhibits diversity in the degree of\nthe simplification performed, setting corpus-level\nvalues is sub-optimal: outputs are frequently over-\nor under-simplified as illustrated by the difference\nin the reference and predicted grade levels.\nCorpus-Level Findings Figure 3 shows the cor-\nrelation between 100 sets of control values set at the\ncorpus level and automatic TS metrics computed\nusing the outputs generated: SARI , BLEU , and FR\n3newsela.com\nFigure 2: ARI accuracy on the Newsela-grade Devel-\nopment Set: 12%. Setting corpus-level control values\nresults in over or under-simplification.\n(Flesch Reading Ease): Most control tokens have\nan opposite impact onSARI and BLEU , except the\ncharacter length ratio, (C). This suggests that set-\nting their values by optimizing for SARI alone at\nthe corpus level can be misleading, as a highSARI\nscore can be achieved at the expense of a lower\nadequacy score. These findings are consistent with\nthe observation of Schwarzer and Kauchak (2018)\nwho note a similar negative correlation between\nhuman judgments of simplicity and adequacy and\ncaution that: “improvement in one metric and not\nthe other may be due to this inverse relationship\nrather than actual system performance”. These re-\nsults lead us to concur with the recommendation of\nAlva-Manchego et al. (2021), which advocates for\nalways augmenting SARI with an adequacy metric\nfor text simplification evaluation.\nOverall, this analysis highlights important lim-\nitations of the simplification abilities provided by\nsetting control tokens based on optimizing SARI\nat the corpus level. We propose instead a simple\nmethod to predict these values based on each input\ninstance and the desired output complexity.\n4 Grade-Specific Text Simplification with\nInstance-Level Control\nSince the simplification for a given instance should\ndepend on the original source text, its complexity,\nand the desired target complexity, we introduce\na Control Predictor module (CP) that predicts a\nvector of control token values V for each input\nX at inference time. Figure 4 shows the overall\ninference pipeline for generating the simplified text\nusing the control token values predicted using CP.\n12810\nFigure 3: Adequacy-Simplicity Tradeoff on the Newsela-Grade development set when using 100 different control\ntokens set at the corpus level: Most control tokens have an opposite impact on BLEU and SARI, suggesting that\nsetting their values on SARI alone can be misleading.\nFigure 4: At inference time, low-level control tokens are first estimated via the control predictor using the source\ntext and a user-defined target grade level. The low-level tokens are then fed as input to the TS generation model to\nproduce a simplified output.\nPredicting Control Tokens We thus directly\ntrain a Control Predictor (CP( θ): X →V) to pre-\ndict the control vector given features extracted from\nan input text and the input and output grade levels.\nLet {xi,yi}∈ Drepresent a complex-simple pair,\nand the ACCESS controls associated with this pair\nbe Vi = {Wi,Ci,Li,WRi,DTD i}. We propose\nboth single and multi-output regression solutions\nfor predicting V as described below:\n1. CP-Single: The model is trained to predict\nthe individual control tokens, resulting in one\nmodel per control value.\n2. CP-Multi: The model is trained to optimize\nthe mean RMSE error over all the control\ndimensions.\nWe train a simple feature-based Gradient Boost-\ning Decision Trees classifier4 to predict the control\nvalues, V using the CatBoost library using several\nsurface-form features extracted from the source\ntext as described below:\n1. Number of Words\n4https://catboost.ai/en/docs/\n2. Number of Characters\n3. Maximum Dependency Tree Depth\n4. Word Rank\n5. Mean Age of Acquisition (Schumacher et al.,\n2016)\nWe incorporate the source and target grade levels\nas attributes to accommodate the differences in\ncontrol token values resulting from the level of\nsimplification needed.\nTS Model Training Given a source text ( x)\nand a control vector v, the controllable TS model\nP(y|x,v), is trained to generate a simplified out-\nput (y) that conforms to vin a supervised fashion,\nby setting vto oracle values derived from the refer-\nence and optimizing the cross-entropy loss on the\ntraining data.\n5 Experimental Settings\nData We use the Newsela-grade dataset (Agrawal\nand Carpuat, 2019) with 470k/2k/19k samples for\ntraining, development and test sets respectively.\nMetrics We automatically evaluate the truecased\ndetokenized system outputs using:\n12811\n1. SARI (Xu et al., 2016), which measures the\nlexical simplicity based on the n-grams kept,\nadded, and deleted by the system relative to\nthe source and the target. 5\n2. BERTS CORE (Zhang et al.) for assessing\nthe output quality and meaning preservation\n3. ARI-Accuracy (Heilman et al., 2008) that\nrepresents the percentage of sentences where\nthe system outputs’ ARI grade level is within\n1 grade of the reference text, where ARI is\ncomputed as:\nARI = 4.71( chars\nwords)+0.5(words\nsents)−21.43.\n(1)\n4. %Unchanged Outputs (U) The percentage\nof outputs that are unchanged from the source\n(i.e., exact copies).\nWe evaluate the fit of the control predictor in pre-\ndicting V using RMSE and Pearson Correlation\nwith the gold ACCESS values.\nModel Configuration We finetune the T5-base\nmodel following Sheang et al. (2022) with default\nparameters from the Transformers library except\nfor a batch size of 6, maximum length of 256, learn-\ning rate of 3e-4, weight decay of 0.1, Adam epsilon\nof 1e-8, 5 warm-up steps, and 5 epochs. For gen-\neration, we use a beam size of 8. We train all our\nmodels on one GeForce RTX 2080Ti GPUs. Train-\ning takes 7-8 hours to converge.\nWe use a learning rate of 0.1 and a tree depth\nof 6 for training all the control predictor models\nwhich takes approximately 5-10 minutes.\nControllable TS Variants We compare the\nprediction-based TS models above with two vari-\nants:\n• GRADE TOKENS : a model that uses high-\nlevel control token values, i.e. the source\ngrade (SG) and the target grade (TG) levels\nwhen finetuning the generation model (Scar-\nton and Specia, 2018).\n• AVG-GRADE : a simple approach that sets con-\ntrol values with the average of the values ob-\nserved for the source-target grade pair.\n5https://github.com/feralvam/easse\nControllable TS Baselines We compare our\napproach with the corpus-level hyperparameter\nsearch strategy ( CORPUS -LEVEL ) used in prior\nwork that selects the best low-level control values\nbased on SARI only (Martin et al., 2020).\nSource Grade at Inference While the desired\ntarget grade level is known during inference, we\nautomatically predict the grade level of each source\nsentence using the ARI score in all the settings.\n6 Results\nWe first discuss the accuracy of the Control pre-\ndictor in estimating the ACCESS control values\non the Newsela-Grade dataset and then show the\nimpact of using the predicted control tokens as\nconstraints towards controlling the degree of sim-\nplification in the generated outputs.\n6.1 Intrinsic Evaluation of Control Predictor\nCONTROL CORRELATION(↑) RMSE (↓)\nW C LevSim WR DTD\nCP-SINGLE 0.405 0.407 0.5670.3980.567 0.197\nCP-MULTI 0.420 0.422 0.5680.3930.570 0.196\nTable 3: CP-Multi improves correlation (averaged\nover 10 runs) with ground truth low-level control token\nvalues (W, C) on Newsela-grade development set over\nCP-Single.\nTable 3 shows the correlation and RMSE of pre-\ndicted values with gold low-level control tokens.\nTraining the model to jointly predict all values,\nV improves correlation (+0.015) for W, C over\ntraining independent models ( CP-Single) for\nindividual control tokens. We show that this can\nbe attributed to the correlation amongst the target\ncontrol values in Figure 5. Both (W, C) exhibit\nmoderate correlation with DTD. There is a drop\nin correlation for WR when training a joint model\nwhich is expected as WR is a proxy for lexical com-\nplexity and is the most independent control token.\nThe correlation scores for the control tokens (W,\nC, DTD, LevSim, WR) range from −0.33\n(S_W, W) to 0.49 (TG, LevSim). The mod-\nerate correlation between the source features\n(prepended with S) and the low-level tokens sug-\ngests that the source text influences the nature of\nsimplification that can be performed. Additionally,\nLevSim controls the degree of simplification as\nsuggested by its moderate-high correlation with\n12812\nFigure 5: Correlation between source features and con-\ntrol token values on the Newsela-Grade training set.\nthe target grade level and can be considered the\nmost prominent token for balancing the adequacy-\nsimplicity tradeoff.\n6.2 Overall Grade-Specific TS Results\nWe show how the different control tokens as side\nconstraints influence the degree and the nature of\nsimplification in the generated outputs in Table 4.\nCONTROL BERTSCORESARI %ACC %U\nLow-level\nCORPUS-LEVEL 0.922 42.19 3.1 0\nAVG-GRADE 0.945 44.09 32.7 0\nCP-SINGLE 0.946 45.54 36.3 2\nCP-MULTI 0.946 45.65 36.3 3\nHigh-level\nGRADETOKENS 0.955 43.02 39.8 34\nORACLE 0.955 53.53 56.7 12\nTable 4: Results on the Newsela-grade dataset: using\nsource-informed tokens (CP-∗) significantly improves\nSARI over alternative control mechanisms. All dif-\nferences are significant except the difference between\nCP-Single and CP-Multi with p-value of 0.00.\nSetting corpus-level control for grade-specific\nTS is suboptimal. Optimizing SARI alone for\nselecting the low-level control tokens and setting\ncorpus-level control values is suboptimal for match-\ning the desired complexity level. This is indicated\nby the low ARI accuracy of only 3.1%.\nPredictor-based instance-level control outper-\nforms grade or corpus-level control. Predictor-\nbased models ( CP-Single, CP-Multi) that\nset control tokens for each instance based on\nsource features improve simplicity scores com-\npared to using Avg-Grade, which only uses\ngrade information to set control values. These\nmodels show improvements in SARI (+1.4-1.5)\nand ARI (+3.6%) scores, highlighting the impor-\ntance of setting control tokens at the instance level\nrather than relying solely on just the grade in-\nformation. Furthermore, setting control tokens\nbased on the average values observed for a given\nsource-target grade pair, i.e., Avg-Grade sig-\nnificantly improves both BERTS CORE and ARI -\nbased metrics across the board compared to the\nCorpus-level approach.\nGrade-level (high) and operation-specific (low)\ncontrol tokens exhibit different adequacy and\nsimplicity tradeoffs. Low-level control tokens\noffer more precise control over the simplicity of\noutputs, resulting in improved SARI scores by\nat least 2 points compared to Grade Tokens.\nHowever, this advantage comes at the cost of lower\nadequacy (BERTScore) and control over desired\ncomplexity (ARI Accuracy). The models trained\nwith low-level control values exhibit lower grade\naccuracy scores partly due to the limited repre-\nsentation of the need for text simplification (Gar-\nbacea et al., 2021) during the generation process\nas suggested by a lower percentage of exact copies\nin the output compared to Grade Tokens (Ex-\nact copies in references: 12%). On the subset of\nthe test set with no exact matches between the\nsource and the reference text, Grade Tokens\nand CP-Multi receive ARI accuracy of 34.2 and\n34.0 respectively. Furthermore, we hypothesize\nthat the models trained with low-level control ex-\nhibit low meaning preservation because none of the\ncontrol tokens directly encourage content addition\nduring text simplification. And, while the model\nlearns to perform an appropriate content deletion, it\ndoes not generate a fitting substitution or addition\nas required to preserve the meaning of the original\nsource text. We show a detailed operation-specific\nanalysis in the following section.\n6.3 Impact of Control Tokens on TS Edit\nOperations\nPredicting control tokens for individual in-\nstances improves coverage over the range of con-\ntrol values exhibited by the oracle. We show\nthe distribution of control values observed by differ-\n12813\nFigure 6: Edit Operations by Target Grade Levels: CP-Single performs correct and diverse edits as suggested by the\nhigh Add-F1 and Del-P scores for all target grade levels >4.\nent ways of setting the low-level control values in\nFigure 7. The high variance in the range of oracle\nvalues confirms that the control tokens vary based\non the source texts’ complexity and desired output\ncomplexity. Where Corpus-level fails to even\nmatch the mean distribution, CP-Multi is able to\ncover a wider range of control values. We show\nthat this trend holds across all target grade levels in\nthe Appendix Figure 9.\nFigure 7: Distribution of control values for different\ncontrol mechanisms: CP-multi provides a broader\ncoverage of control values as observed in the oracle\ndistribution over Corpus-level and Avg-Grade.\nSimplified outputs generated using predicted\ncontrol tokens exhibit diverse edit operations.\nFigure 6 shows the distribution of the KEEP -F1,\nDEL -P, and ADD -F1 scores by target grade level\nfor the models trained with different control types,\nwhere ADD -F1 computes the F1 score for the n-\ngrams that are added to the system output relative\nto the source and the reference text. The model’s\ndeletion capability is measured by the F1 score for\nn-grams that are kept (KEEP -F1) and the precision\nof deletion operation (DEL -P) with respect to the\nsource and the reference.\nCP-Multi consistently achieves better or com-\npetitive DEL -P across all target grade levels over\nalternative control mechanisms, suggesting that set-\nting control values informed by both the source\nand desired complexity level improves the model’s\nability to appropriately delete redundant informa-\ntion. The former also generally improves ADD -F1\nscores, highlighting that the model also appropri-\nately performs lexical substitution or content addi-\ntion as required across different grade levels (ex-\ncept grades 2 and 10). Moreover, low-level control\ntokens (CP-Multi, Avg-Grade) exhibit more\ndiverse and correct modifications compared to high-\nlevel control (Grade Tokens), as evident from\ntheir better ADD -F1 and DEL -P scores for grade lev-\nels > 3, where the latter prioritizes meaning preser-\nvation (high KEEP -F1).\n7 Conclusion\nWe present a systematic analysis of the impact of\ncontrol tokens set at the corpus level on the degree\nand quality of simplification achieved by control-\nlable text simplification models at the instance level.\nOur findings show that control tokens exhibit an\nopposite correlation with adequacy and simplic-\nity. Hence, selecting their values at the corpus\nlevel based on SARI alone leads to over or under-\nsimplifying individual instances. This motivates a\nnew approach to set low-level control tokens during\ninference by predicting them given a source text\nand desired target grade level. We show that this\napproach is effective at improving the quality and\ncontrolling the degree of simplification in gener-\nated outputs based on automatic evaluation. Fur-\nthermore, predicted low-level control tokens yield\nmore diverse edit operations than alternative ways\nof setting control on the Newsela-grade dataset.\nOur proposed simple solutions improve the in-\nference capability of the controllable TS model\n12814\nfor grade-specific TS and reduce the gap with the\noracle over a corpus-level baseline approach. How-\never, more sophisticated techniques can benefit the\ndesign and prediction of low-level control values\nand their usage during inference which we leave to\nfuture work.\nLimitations\nWe note a few limitations of our work. While\nour proposed strategies are simple and improve\nthe controllability over the generated simplified\ntexts during inference, the models trained with low-\nlevel control tokens struggle to identify when a text\nneeds to be simplified compared to the model that\nuses high-level weak supervision. These results\nopen space for further research in designing end-\nto-end controllable TS models that are able to take\nadvantage of both high and low-level control to-\nkens for controlling both the degree and the nature\nof simplification.\nOur work is also limited to one dataset and one\nlanguage (English) and hence studies the mapping\nbetween U.S grade level to low-level edit opera-\ntions. It remains an open question to study how the\ncontrol predictor would generalize in other settings,\ndatasets, and language pairs.\nEthics Statement\nThis work is conducted in full awareness of and in\nline with the ACL Ethics Policy. Models, datasets,\nand evaluation methodologies used are detailed in\nSection 5. The Newsela dataset was used with\npermission and appropriate access rights and li-\ncenses. And, we ground our claims by conducting\na thorough evaluation and analysis of the outputs\ngenerated by the proposed systems (Section 6).\nWe note that while text simplification systems\nare designed with the intention of assisting users in\nbetter comprehending complex texts, the potential\nerrors introduced by these systems and ambiguous\ninterpretations of simplified text can cause harm\nto the reader and other stakeholders. The very\nnature of simplification involves content removal\nand rephrasing complex concepts, which can some-\ntimes result in oversimplification or loss of critical\nnuances. As a consequence, users relying solely on\nsimplified texts may develop an incomplete or inac-\ncurate understanding of the subject matter, leading\nto potential misconceptions or misinterpretations.\nAcknowledgments\nWe thank Eleftheria Briakou, Neha Srikanth, the\nmembers of the CLIP lab at UMD, and the anony-\nmous EMNLP reviewers for their helpful and con-\nstructive comments. This research is supported in\npart by the Office of the Director of National Intel-\nligence (ODNI), Intelligence Advanced Research\nProjects Activity (IARPA), via the HIATUS Pro-\ngram contract 2022-22072200006, by NSF grant\n2147292, and by funding from Adobe Research.\nThe views and conclusions contained herein are\nthose of the authors and should not be interpreted\nas necessarily representing the official policies, ei-\nther expressed or implied, of ODNI, IARPA, or\nthe U.S. Government. The U.S. Government is\nauthorized to reproduce and distribute reprints for\ngovernmental purposes notwithstanding any copy-\nright annotation therein.\nReferences\nSweta Agrawal and Marine Carpuat. 2019. Controlling\ntext complexity in neural machine translation. In\nProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP), pages 1549–\n1564, Hong Kong, China. Association for Computa-\ntional Linguistics.\nSweta Agrawal and Marine Carpuat. 2022. An imita-\ntion learning curriculum for text editing with non-\nautoregressive models. In Proceedings of the 60th\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 7550–\n7563, Dublin, Ireland. Association for Computational\nLinguistics.\nSweta Agrawal, Weijia Xu, and Marine Carpuat. 2021.\nA non-autoregressive edit-based approach to control-\nlable text simplification. In Findings of the Associa-\ntion for Computational Linguistics: ACL-IJCNLP\n2021, pages 3757–3769, Online. Association for\nComputational Linguistics.\nDavid Allen. 2009. A study of the role of relative\nclauses in the simplification of news texts for learners\nof english. System, 37(4):585–599.\nFernando Alva-Manchego, Carolina Scarton, and Lucia\nSpecia. 2021. The (un)suitability of automatic evalu-\nation metrics for text simplification. Computational\nLinguistics, 47(4):861–889.\nR. Chandrasekar, Christine Doran, and B. Srinivas. 1996.\nMotivations and methods for text simplification. In\nCOLING 1996 Volume 2: The 16th International\nConference on Computational Linguistics.\n12815\nWilliam Coster and David Kauchak. 2011. Simple En-\nglish Wikipedia: A new text simplification task. In\nProceedings of the 49th Annual Meeting of the Asso-\nciation for Computational Linguistics: Human Lan-\nguage Technologies, pages 665–669, Portland, Ore-\ngon, USA. Association for Computational Linguis-\ntics.\nSumanth Dathathri, Andrea Madotto, Janice Lan, Jane\nHung, Eric Frank, Piero Molino, Jason Yosinski, and\nRosanne Liu. 2019. Plug and play language models:\nA simple approach to controlled text generation. In\nInternational Conference on Learning Representa-\ntions.\nCristina Garbacea, Mengtian Guo, Samuel Carton, and\nQiaozhu Mei. 2021. Explainable prediction of text\ncomplexity: The missing preliminaries for text sim-\nplification. In Proceedings of the 59th Annual Meet-\ning of the Association for Computational Linguistics\nand the 11th International Joint Conference on Natu-\nral Language Processing (Volume 1: Long Papers),\npages 1086–1097, Online. Association for Computa-\ntional Linguistics.\nMarjan Ghazvininejad, Xing Shi, Jay Priyadarshi, and\nKevin Knight. 2017. Hafez: an interactive poetry\ngeneration system. In Proceedings of ACL 2017,\nSystem Demonstrations , pages 43–48, Vancouver,\nCanada. Association for Computational Linguistics.\nMichael Heilman, Kevyn Collins-Thompson, and Max-\nine Eskenazi. 2008. An analysis of statistical models\nand features for reading difficulty prediction. In Pro-\nceedings of the third workshop on innovative use\nof NLP for building educational applications, pages\n71–79. Association for Computational Linguistics.\nChris Hokamp and Qun Liu. 2017. Lexically con-\nstrained decoding for sequence generation using grid\nbeam search. In Proceedings of the 55th Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers), pages 1535–1546,\nVancouver, Canada. Association for Computational\nLinguistics.\nAri Holtzman, Jan Buys, Maxwell Forbes, Antoine\nBosselut, David Golub, and Yejin Choi. 2018. Learn-\ning to write with cooperative discriminators. In Pro-\nceedings of the 56th Annual Meeting of the Associa-\ntion for Computational Linguistics (Volume 1: Long\nPapers), pages 1638–1649, Melbourne, Australia. As-\nsociation for Computational Linguistics.\nMelvin Johnson, Mike Schuster, Quoc V . Le, Maxim\nKrikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat,\nFernanda Viégas, Martin Wattenberg, Greg Corrado,\nMacduff Hughes, and Jeffrey Dean. 2016. Google’s\nMultilingual Neural Machine Translation System:\nEnabling Zero-Shot Translation. arXiv:1611.04558\n[cs].\nNitish Shirish Keskar, Bryan McCann, Lav R Varshney,\nCaiming Xiong, and Richard Socher. 2019. Ctrl: A\nconditional transformer language model for control-\nlable generation. arXiv preprint arXiv:1909.05858.\nTannon Kew and Sarah Ebling. 2022. Target-level sen-\ntence simplification as controlled paraphrasing. In\nProceedings of the Workshop on Text Simplification,\nAccessibility, and Readability (TSAR-2022) , pages\n28–42, Abu Dhabi, United Arab Emirates (Virtual).\nAssociation for Computational Linguistics.\nSachin Kumar, Eric Malmi, Aliaksei Severyn, and Yu-\nlia Tsvetkov. 2021. Controlled text generation as\ncontinuous optimization with multiple constraints.\nAdvances in Neural Information Processing Systems,\n34:14542–14554.\nVladimir Iosifovich Levenshtein. 1966. Binary codes\ncapable of correcting deletions, insertions and re-\nversals. Soviet Physics Doklady , 10(8):707–710.\nDoklady Akademii Nauk SSSR, V163 No4 845-848\n1965.\nXiang Lisa Li, John Thickstun, Ishaan Gulrajani, Percy\nLiang, and Tatsunori Hashimoto. 2022. Diffusion-\nLM improves controllable text generation. In Ad-\nvances in Neural Information Processing Systems.\nMounica Maddela, Fernando Alva-Manchego, and Wei\nXu. 2021. Controllable text simplification with ex-\nplicit paraphrasing. In Proceedings of the 2021 Con-\nference of the North American Chapter of the Asso-\nciation for Computational Linguistics: Human Lan-\nguage Technologies, pages 3536–3553, Online. As-\nsociation for Computational Linguistics.\nJonathan Mallinson and Mirella Lapata. 2019. Con-\ntrollable sentence simplification: Employing syn-\ntactic and lexical constraints. arXiv preprint\narXiv:1910.04387.\nLouis Martin, Éric Villemonte De La Clergerie, Benoît\nSagot, and Antoine Bordes. 2020. Controllable sen-\ntence simplification. In Proceedings of the 12th Lan-\nguage Resources and Evaluation Conference, pages\n4689–4698.\nLouis Martin, Angela Fan, Éric de la Clergerie, Antoine\nBordes, and Benoît Sagot. 2022. MUSS: Multilin-\ngual unsupervised sentence simplification by mining\nparaphrases. In Proceedings of the Thirteenth Lan-\nguage Resources and Evaluation Conference, pages\n1651–1664, Marseille, France. European Language\nResources Association.\nDaiki Nishihara, Tomoyuki Kajiwara, and Yuki Arase.\n2019. Controllable text simplification with lexical\nconstraint loss. In Proceedings of the 57th Annual\nMeeting of the Association for Computational Lin-\nguistics: Student Research Workshop , pages 260–\n266.\nXing Niu, Sudha Rao, and Marine Carpuat. 2018. Multi-\ntask neural models for translating between styles\nwithin and across languages. In Proceedings of the\n27th International Conference on Computational Lin-\nguistics, pages 1008–1021, Santa Fe, New Mexico,\nUSA. Association for Computational Linguistics.\n12816\nSarah E Petersen and Mari Ostendorf. 2007. Text sim-\nplification for language learners: a corpus analysis.\nIn Workshop on Speech and Language Technology in\nEducation.\nShrimai Prabhumoye, Alan W Black, and Ruslan\nSalakhutdinov. 2020. Exploring controllable text\ngeneration techniques. In Proceedings of the 28th\nInternational Conference on Computational Linguis-\ntics, pages 1–14, Barcelona, Spain (Online). Interna-\ntional Committee on Computational Linguistics.\nYu Qiao, Xiaofei Li, Daniel Wiechmann, and Elma Kerz.\n2022. (psycho-)linguistic features meet transformer\nmodels for improved explainable and controllable\ntext simplification. In Proceedings of the Workshop\non Text Simplification, Accessibility, and Readability\n(TSAR-2022), pages 125–146, Abu Dhabi, United\nArab Emirates (Virtual). Association for Computa-\ntional Linguistics.\nHoracio Saggion. 2017. Automatic text simplification.\nIn Synthesis Lectures on Human Language Technolo-\ngies.\nCarolina Scarton and Lucia Specia. 2018. Learning\nSimplifications for Specific Target Audiences. In\nProceedings of the 56th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 2:\nShort Papers), volume 2, pages 712–718.\nElliot Schumacher, Maxine Eskenazi, Gwen Frishkoff,\nand Kevyn Collins-Thompson. 2016. Predicting the\nrelative difficulty of single sentences with and with-\nout surrounding context. In Proceedings of the 2016\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 1871–1881, Austin, Texas.\nAssociation for Computational Linguistics.\nMax Schwarzer and David Kauchak. 2018. Human\nevaluation for text simplification: The simplicity-\nadequacy tradeoff. In SoCal NLP Symposium.\nRico Sennrich, Barry Haddow, and Alexandra Birch.\n2016. Controlling Politeness in Neural Machine\nTranslation via Side Constraints. pages 35–40. Asso-\nciation for Computational Linguistics.\nRJ Senter and Edgar A Smith. 1967. Automated read-\nability index. Technical report, CINCINNATI UNIV\nOH.\nMatthew Shardlow. 2014. A survey of automated text\nsimplification. International Journal of Advanced\nComputer Science and Applications, 4(1):58–70.\nKim Cheng Sheang, Daniel Ferrés, and Horacio Sag-\ngion. 2022. Controllable lexical simplification for En-\nglish. In Proceedings of the Workshop on Text Simpli-\nfication, Accessibility, and Readability (TSAR-2022),\npages 199–206, Abu Dhabi, United Arab Emirates\n(Virtual). Association for Computational Linguistics.\nKim Cheng Sheang and Horacio Saggion. 2021. Con-\ntrollable sentence simplification with a unified text-\nto-text transfer transformer. In Proceedings of the\n14th International Conference on Natural Language\nGeneration, pages 341–352, Aberdeen, Scotland, UK.\nAssociation for Computational Linguistics.\nSanja Stajner. 2021. Automatic text simplification for\nsocial good: Progress and challenges. In Findings of\nthe Association for Computational Linguistics: ACL-\nIJCNLP 2021, pages 2637–2652, Online. Association\nfor Computational Linguistics.\nWillian Massami Watanabe, Arnaldo Candido Junior,\nVinícius Rodriguez Uzêda, Renata Pontin de Mat-\ntos Fortes, Thiago Alexandre Salgueiro Pardo, and\nSandra Maria Aluísio. 2009. Facilita: reading as-\nsistance for low-literacy readers. In Proceedings of\nthe 27th ACM international conference on Design of\ncommunication, pages 29–36.\nWei Xu, Courtney Napoles, Ellie Pavlick, Quanze Chen,\nand Chris Callison-Burch. 2016. Optimizing sta-\ntistical machine translation for text simplification.\nTransactions of the Association for Computational\nLinguistics, 4:401–415.\nDaiki Yanamoto, Tomoki Ikawa, Tomoyuki Kajiwara,\nTakashi Ninomiya, Satoru Uchida, and Yuki Arase.\n2022. Controllable text simplification with deep re-\ninforcement learning. In Proceedings of the 2nd\nConference of the Asia-Pacific Chapter of the Asso-\nciation for Computational Linguistics and the 12th\nInternational Joint Conference on Natural Language\nProcessing (Volume 2: Short Papers), pages 398–404,\nOnline only. Association for Computational Linguis-\ntics.\nTatsuya Zetsu, Tomoyuki Kajiwara, and Yuki Arase.\n2022. Lexically constrained decoding with edit oper-\nation prediction for controllable text simplification.\nIn Proceedings of the Workshop on Text Simplifi-\ncation, Accessibility, and Readability (TSAR-2022),\npages 147–153, Abu Dhabi, United Arab Emirates\n(Virtual). Association for Computational Linguistics.\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Wein-\nberger, and Yoav Artzi. Bertscore: Evaluating text\ngeneration with bert. In International Conference on\nLearning Representations.\nXingxing Zhang and Mirella Lapata. 2017. Sentence\nsimplification with deep reinforcement learning. In\nProceedings of the 2017 Conference on Empirical\nMethods in Natural Language Processing, pages 584–\n594, Copenhagen, Denmark. Association for Compu-\ntational Linguistics.\n12817\nA Impact of Training Data Size on Control Predictor\nFigure 8: Correlation scores for all low-level control tokens with varying training dataset sizes.\nWe vary the size of the dataset used to train the single and multi-regressor control predictors and show\nthe correlation for all the control values, V, in Figure 8. While correlation for CP-S INGLE saturates with\n100 −150K instances, CP-M ULTI is able to take advantage of correlation amongst tokens and additional\ntraining dataset to further improve the prediction of ACCESS control tokens.\n12818\nFigure 9: Distribution of control token values for different model variants by Target Grade level.\n12819",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8736096620559692
    },
    {
      "name": "Heuristics",
      "score": 0.8206180334091187
    },
    {
      "name": "Simplicity",
      "score": 0.8081104159355164
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.651552140712738
    },
    {
      "name": "Reading (process)",
      "score": 0.5738162398338318
    },
    {
      "name": "Control (management)",
      "score": 0.5548478364944458
    },
    {
      "name": "Simple (philosophy)",
      "score": 0.5387090444564819
    },
    {
      "name": "Quality (philosophy)",
      "score": 0.4828351140022278
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4619477391242981
    },
    {
      "name": "Language model",
      "score": 0.4325745701789856
    },
    {
      "name": "Text simplification",
      "score": 0.4261646270751953
    },
    {
      "name": "Natural language processing",
      "score": 0.39806681871414185
    },
    {
      "name": "Programming language",
      "score": 0.20662814378738403
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Sentence",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Epistemology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I66946132",
      "name": "University of Maryland, College Park",
      "country": "US"
    }
  ]
}