{
  "title": "Lower Energy Large Language Models (LLMs)",
  "url": "https://openalex.org/W4386872438",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A4209172497",
      "name": "Hsiao-Ying Lin",
      "affiliations": [
        "Huawei Technologies (France)"
      ]
    },
    {
      "id": "https://openalex.org/A568848126",
      "name": "Jeffrey Voas",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W6850625674",
    "https://openalex.org/W4283704460",
    "https://openalex.org/W6850496243",
    "https://openalex.org/W4292121737",
    "https://openalex.org/W4287889735",
    "https://openalex.org/W4323112125",
    "https://openalex.org/W4322718191"
  ],
  "abstract": "This message offers ideas about how to reduce the energy consumption associated with large language models.",
  "full_text": "SECTION TITLE\n14 COMPUTER   PUBLISHED BY THE IEEE COMPUTER SOCIETY  0018-9162/23©2023IEEE\nEIC’S MESSAGE\nDISCLAIMER\nThe authors are completely responsible for the content in \nthis message. The opinions expressed here are their own.\nW\ne continually hear about the high energy \ncosts required for artificial intelligence \n(AI) and machine learning (ML). So, we de -\ncided to see what has already been written \nabout the energy costs specific to large language models \n(LLMs). Here is a little bit of what we found and a better \nexplanation of our curiosity.\nSince the introduction of ChatGPT, the business influ -\nence of LLMs has increased greatly. Various LLM-based \napplications are emerging and bring a huge potential for \nincreasing work productivity, such as customized online \nchatting services 1 and topic-focused document analysis. 2 \nMeanwhile, a variety of new LLMs, such as HuggingChat, 3 \nLLaMA,4 and stableLM, 5 are contin -\nually being introduced. While these \nLLMs unlock a fruitful set of auto -\nmatically generative capabilities, \nthey also raise public concerns about \nthe energy consumption of the LLM \ntraining and inference processes. For \nexample, training the largest GPT-3 \nmodel, which has 175 billion pa -\nrameters, consumes approximately \n1,287 MWh, 6 while the average an -\nnual electricity consumption for a \nU.S. residential utility customer was only approximately \n10 MWh in 2021.7 As new LLM models are emerging, such \nas GPT-4 (170 trillion parameters), the energy consumption \nmomentum will continue.\nAs global heads of state have announced ambitious \ntargets to manage the climate crisis, green and sustain -\nable technologies are developing in all sectors, including \nAI. As current LLMs consume considerable energy, inno -\nvative concepts and technologies for lower energy con -\nsumption LLMs are a new research topic. \nLower Energy Large \nLanguage Models \n(LLMs)\nHsiao-Ying Lin , Huawei France \nJeffrey Voas , IEEE Fellow\nThis message offers ideas about how to reduce \nthe energy consumption associated with large \nlanguage models.\nDigital Object Identifier 10.1109/MC.2023.3278160\nDate of current version: 20 September 2023\nEDITOR  DIMITRIOS SERPANOS \nISI/ATHENA and University of Patras; serpanos@computer.org\n OCTOBER 2023  15\nEDITOR IN CHIEF JEFFREY VOAS \nIEEE Fellow; j.voas@ieee.org\nSo, which lower energy technol -\nogies for LLMs are accessible now? \nAvailable approaches can be classified \ninto two categories. \nFirst, energy efficiency can be im -\nproved by increasing the reuse rate, \nthat is, partly amortizing the training \nenergy cost. After LLMs are trained \nat a considerable energy expense, a \npromising approach is to reuse the re -\nsulting LLMs as much as possible with \nreasonable overhead. Hence, various \n customized LLMs are generated by \nslightly fine-tuning existing available \nLLMs. For example, one open source \ntool called  xTuring8 enables developers \nto fine-tune available typical LLMs for \ncustomized purposes with indicated \ndatasets. So, in a little experiment \nthat we ran, it took approximately 100 \ncomputing units and 7 h on Google \nColab to fine-tune a language model \nrunning on a GPU-Nvidia A100. The \nbase model (based on LLaMA) has  \n6.7 billion parameters, of which  \n4.2 million are trainable during \nfine-tuning. Thus, higher energy effi -\nciency can be achieved by employing \nexisting models by amortizing the \ntraining cost.\nThe second category focuses on \nhow to develop from-scratch LLMs \nwith better energy efficiency. Three \nexamples are introduced here. \n1. MIT researchers presented a \nstrategy called Learned Linear \nGrowth Operator (LiGO), which \nconverts a smaller model to a \nlarger model.9 This strategy can \nFirst, energy efficiency can be improved by \nincreasing the reuse rate, that is, partly amortizing \nthe training energy cost. \nIN THIS ISSUE \nI\nn the second part of this special issue on “Telemedicine,” I’m \nadding two additional articles. I thank these authors for their \npatience in waiting for their accepted articles to be published. \nComputer has seen an uptick in the number of submissions, \nand we have a backlog of accepted articles.\nIn the article “VD-HEN: Capturing Semantic Dependencies \nfor Source Code Vulnerability Detection With a Hierarchical \nEmbedding Network,” A1 the authors propose a semantic \ndependency capture method for source code vulnerabil -\nity detection. Their method extracts syntactic information \nand structural information through a statement embedding \nnetwork and program embedding network. A recursive neural \nnetwork is used to learn the statement representation from an \nAST subtree that corresponds to each statement, and the tree-\nbased convolutional neural network is used to extract program \nstructure information.\nIn the article “Enabling Cost-Benefit Analysis of \nData Sync Protocols,” A2 the authors discuss data \nsynchronization in networked applications. The article \nstates that data synchronization improves performance \nand describes a new middleware called GenSync  that \nabstracts the subtleties of data synchronization protocols \nthat allow users to choose protocols that are based on \ncomparative evaluations under operational conditions. The \narticle includes a case study where GenSync is integrated \ninto a large wireless emulator.\n—Jeffrey Voas, Editor in Chief\nAPPENDIX: RELATED ARTICLES\n A1. J. Hao, S. Luo, L. Pan, and C. Chen, “VD-HEN: Capturing \nsemantic dependencies for source code vulnerability \ndetection with a hierarchical embedding network,”  \nComputer, vol. 56, no. 10, pp. 49–61, Oct. 2023,  \ndoi: 10.1109/MC.2022.3228924.\n A2. N. Boškov, A. Trachtenberg, and D. Starobinski, “Enabling \ncost-benefit analysis of data sync protocols,” Computer, \nvol. 56, no. 10, pp. 62–71, Oct. 2023, doi: 10.1109/\nMC.2023.3251195.\nDigital Object Identifier 10.1109/MC.2023.3295521\nDate of current version: 20 September 2023\n16 COMPUTER    WWW.COMPUTER.ORG/COMPUTER\nEIC’S MESSAGE\nreduce the computational cost \nof training vision and language \nmodels by approximately 50%. \n2. A smaller model size is con -\nsidered in the beginning while \nmaintaining comparable per -\nformance, such as LLaMA (65 \nbillion parameters) and Claude \n(52 billion parameters). \n3. Energy efficiency can be ob -\ntained via leveraging sustain -\nable high-performance com -\nputing technology, including \ncustomized hardware inno -\nvations10 and green-oriented \nsoftware orchestrators. 11\nS\no, as LLMs open new chapters for \nhuman–machine interactions, \nhow to develop and maintain \ngreener LLMs becomes an essential \ntask for sustainability. This is some -\nthing that we all need to keep an eye on \nas tools such as ChatGPT become the \nnew norm.\nACKNOWLEDGMENT\nThe corresponding author is Hsiao-\nYing Lin. \nREFERENCES\n1. “Character.ai.” Accessed: May 7, \n2023. [Online]. Available: https:/ /\nbeta.character.ai/\n2. “ChatPDF.” Accessed: May 7, 2023. \n[Online]. Available: https:/ /www.\nchatpdf.com/\n3. “HuggingChat.” Accessed: May 7, \n2023. [Online]. Available: https:/ /\nhuggingface.co/chat/\n4. H. Touvron et al., “LLaMA: Open \nand efficient foundation language \nmodels,” 2023, arXiv:2302.13971 .\n5. “StableLM: Stability AI language \nmodels.” GitHub. Accessed: May 7, \n2023. [Online]. Available: https:/ /\ngithub.com/Stability-AI/StableLM\n6. D. Patterson et al., “The carbon foot -\nprint of machine learning training \nwill plateau, then shrink,” Computer, \nvol. 55, no. 7, pp. 18–28, Jul. 2022, doi: \n10.1109/MC.2022.3148714.\n7. “How much electricity does an \nAmerican home use?” U.S. Energy \nInf. Admin., Washington, DC, USA, \nOct. 2022. Accessed: May 7, 2023. \n[Online]. Available: https:/ /www.eia.\ngov/tools/faqs/faq.php?id=97&t=3\n8. “xTuring.” Accessed: May 7, 2023. \n[Online]. Available: https:/ /xturing.\nstochastic.ai/\n9. P. Wang et al., “Learning to grow \npretrained models for efficient \ntransformer training,” 2023, \narXiv:2303.00980 .\n10. W. Wan et al., “A compute-in-memory \nchip based on resistive random-access \nmemor y,” Nature, vol. 608, no. 7923, \npp. 504–512, Aug. 2022, doi: 10.1038/\ns41586-022-04992-8.\n11. J. McDonald, B. Li, N. Frey, D. Tiwari, \nV. Gadepally, and S. Samsi, “Great \npower, great responsibility: Recom -\nmendations for reducing energy for \ntraining language models,” 2022, \narXiv:2205.09646 .\nHSIAO-YING LIN is a principal \nresearcher at Huawei France, 92100 \nBoulogne-Billancourt, France. Contact \nher at hsiaoying.lin@gmail.com.\nJEFFREY VOAS, Gaithersburg, MD \n20899 USA, is the editor in chief of \nComputer. He is a Fellow of IEEE. \nContact him at j.voas@ieee.org\nIEEE SOFTWARE  January/February 2015 INTERNETWARE AND BEYOND        Volume 32  Number 1  \nIEEE SOFTWARE  March/April 2015 RELEASE ENGINEERING        Volume 32  Number 2  \nIEEE Software oﬀ ers pioneering ideas, expert \nanalyses, and thoughtful insights for software \nprofessionals who need to keep up with \nrapid technology change. It’s the authority on \ntranslating software theory into practice.\nwww.computer.org/software\nDigital Object Identifier 10.1109/MC.2023.3308281\nNote: Computer’s “Artificial Intelligence/\nMachine Learning” column opens fresh \nperspectives, novel concepts, and sus-\ntainable solutions related to AI and ML, \nso please consider submitting column \narticles to it at hsiaoying.lin@gmail.com.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7565281391143799
    },
    {
      "name": "Energy (signal processing)",
      "score": 0.417235791683197
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Statistics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210123571",
      "name": "Huawei Technologies (France)",
      "country": "FR"
    }
  ],
  "cited_by": 2
}