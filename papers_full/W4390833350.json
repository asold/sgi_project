{
    "title": "Designing Heterogeneous LLM Agents for Financial Sentiment Analysis",
    "url": "https://openalex.org/W4390833350",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A5024877482",
            "name": "Frank Xing",
            "affiliations": [
                "National University of Singapore"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2910656009",
        "https://openalex.org/W4389156617",
        "https://openalex.org/W3083410900",
        "https://openalex.org/W4388444659",
        "https://openalex.org/W4385572697",
        "https://openalex.org/W2889265674",
        "https://openalex.org/W1546425147",
        "https://openalex.org/W4381996999",
        "https://openalex.org/W4387819987",
        "https://openalex.org/W4361866125",
        "https://openalex.org/W4318477615",
        "https://openalex.org/W4378509427",
        "https://openalex.org/W4385571452",
        "https://openalex.org/W4377130677",
        "https://openalex.org/W4285129823",
        "https://openalex.org/W3035101152",
        "https://openalex.org/W2927690792",
        "https://openalex.org/W2897494692",
        "https://openalex.org/W3115467802",
        "https://openalex.org/W3199400376",
        "https://openalex.org/W4385570658",
        "https://openalex.org/W4371779578",
        "https://openalex.org/W3151685851",
        "https://openalex.org/W4385571124",
        "https://openalex.org/W2888501547",
        "https://openalex.org/W4378465262",
        "https://openalex.org/W3124308803",
        "https://openalex.org/W1276866904",
        "https://openalex.org/W4388994251",
        "https://openalex.org/W4221125416",
        "https://openalex.org/W2798300760",
        "https://openalex.org/W2171468534",
        "https://openalex.org/W4307225507",
        "https://openalex.org/W4367318783",
        "https://openalex.org/W2804045672",
        "https://openalex.org/W4365205411",
        "https://openalex.org/W3125952890",
        "https://openalex.org/W2798658104",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W4287645038",
        "https://openalex.org/W3153557772",
        "https://openalex.org/W3185341429",
        "https://openalex.org/W4237619930",
        "https://openalex.org/W2753259282"
    ],
    "abstract": "Large language models (LLMs) have drastically changed the possible ways to design intelligent systems, shifting the focuses from massive data acquisition and new modeling training to human alignment and strategical elicitation of the full potential of existing pre-trained models. This paradigm shift, however, is not fully realized in financial sentiment analysis (FSA), due to the discriminative nature of this task and a lack of prescriptive knowledge of how to leverage generative models in such a context. This study investigates the effectiveness of the new paradigm, i.e., using LLMs without fine-tuning for FSA. Rooted in Minsky's theory of mind and emotions, a design framework with heterogeneous LLM agents is proposed. The framework instantiates specialized agents using prior domain knowledge of the types of FSA errors and reasons on the aggregated agent discussions. Comprehensive evaluation on FSA datasets show that the framework yields better accuracies, especially when the discussions are substantial. This study contributes to the design foundations and paves new avenues for LLMs-based FSA. Implications on business and management are also discussed.",
    "full_text": "Designing Heterogeneous LLM Agents for\nFinancial Sentiment Analysis\nFrank Xing\nSchool of Computing\nNational University of Singapore\nxing@nus.edu.sg\nAbstract\nLarge language models (LLMs) have drastically changed the possible ways to\ndesign intelligent systems, shifting the focuses from massive data acquisition and\nnew modeling training to human alignment and strategical elicitation of the full\npotential of existing pre-trained models. This paradigm shift, however, is not fully\nrealized in financial sentiment analysis (FSA), due to the discriminative nature of\nthis task and a lack of prescriptive knowledge of how to leverage generative models\nin such a context. This study investigates the effectiveness of the new paradigm,\ni.e., using LLMs without fine-tuning for FSA. Rooted in Minsky’s theory of mind\nand emotions, a design framework with heterogeneous LLM agents is proposed.\nThe framework instantiates specialized agents using prior domain knowledge of the\ntypes of FSA errors and reasons on the aggregated agent discussions. Comprehen-\nsive evaluation on FSA datasets show that the framework yields better accuracies,\nespecially when the discussions are substantial. This study contributes to the design\nfoundations and paves new avenues for LLMs-based FSA. Implications on business\nand management are also discussed.\n1 Introduction\nSince OpenAI’s ChatGPT went viral one year ago, large language models (LLMs) have gone through\nfast improvements, showing a variety of capabilities. The AI adaptation for many financial services is\naccelerating, and big data-supported financial decision-making is no exception. Financial sentiment\nanalysis (FSA) is a prototypical task in that category and is becoming increasingly important as\nfinancial service processes and our social behavior digitalize: companies disclose electronic versions\nof their annual reports, earning calls, and announcements, and investors join online communities,\ndiscussion forums, and social media to interact with others. The recent GameStop Saga [ 8] and\nthe popularity of a spectrum of market sentiment indexes (e.g., MarketPsych [ 30]) have shown\nclear evidence that sentiment is a useful analytics tool for financial decision-making, forecasting\nshort-term returns and volatilities [38], detecting fake news and fraud [11], and predicting risk [41].\nThe usefulness and the importance of accurate FSA are also underpinned by a long thread of\nresearch [1, 37, 9, 5]. Hendershott et al. [ 16] summarized that research on the application of AI\non news, social media, and word-of-mouth data is a major category of leveraging AI in finance.\nConsidering these factors, accurate FSA is desired for multiple stakeholders.\nThe majority of FSA systems were developed in the past decade and their architecture and design\nideas have gone through several iterations along with the advances in natural language processing.\nEarly systems rely on sentiment word dictionaries and simple rules or statistics to derive sentence-\nlevel or message-level polarities. Efforts were made to discover words/phrases specific to the finance\ndomain [24, 40]. A great amount of learning-based systems were later developed. Specifically, two\nbenchmark tasks (SemEval 2017 Task 5 [6] and FiQA 2018 Task 1 [7]) were conducted, and the\nPreprint. Under review.\narXiv:2401.05799v1  [cs.CL]  11 Jan 2024\nbest results were achieved by regression ensemble (RE), convolutional neural network (CNN), and\nsupport vector regression (SVR) models based on combined features of sentiment lexica and dense\nword representations. The following wave of designs were based on fine-tuning general-purpose pre-\ntrained language models, e.g., BERT1 (Bidirectional Encoder Representations from Transformers).\nFor example, FinBERT [23] achieved good FSA results and the state-of-the-art is from integrating\nmultiple auxiliary knowledge sources to a BERT variant [12]. In terms of leveraging LLMs for FSA,\nthe current progress mainly employed the encoder type of transformer, e.g., BERT. However, the\nmost powerful LLMs now are based on the decoder part of a transformer. The decoder architecture is\nnatural for generative tasks such as discourse/chat completion and question answering, but can also\nbe fitted for discriminative tasks and classification. This study is aware of the early stage and scant\nin-depth studies in this direction and thus explores ways of leveraging generative LLMs for FSA.\nDifferent from many ad hoc designs developed from chain of thought (CoT) [10], tree of thoughts\n(ToT) [42], verification, self-consistency constraints, intermediate scratchpads, and multi-agent multi-\nrole settings, the design framework presented here follows the design science guidelines by Hevner et\nal. [18] and contributes to the prescriptive knowledge as a “design theory\" [15]. Based on Minsky’s\ntheory of mind and emotions, “emotional states\" are our Ways to Think with a specific collection\nof resources turned on and others turned off given certain environment conditions [27]. Therefore,\none FSA approach is to simulate the mental processes underlying the texts, requiring specialized\nLLM agents to play the roles of “resources\", i.e., functional parts of our brain that make us react\nto the environment. In the context of financial analysis, many resources are learned as professional\nknowledge and not innate parts of our brains. The design framework (Heterogeneous multi-Agent\nDiscussion) chooses to develop specialized LLM agents by prompting, and the main function is to\npay attention to a type of error that LLMs are prone to make for the given FSA task. The design\nartifact thus has five different agents and the FSA result is based on a shared discussion considering\noutput from all the agents. I evaluate the artifact using multiple methods, and the results generally\nconclude the framework to be effective.\n1 2 3\n... ... ...\n1 2 3\n... ... ...\n1 2 3\n... ... ...\nConsensus\nText\n1 2\nText\n... ...\n2\n...\n1\n...\n3\n...\n... ...\n3 3\n... ...\nConsensus 2\nText\n1 2 3\n...\n1 2 3\n...... ...\nConsensus\n(a) (b) (c)\nConsensus 1\nFigure 1: Different multi-agent LLM frameworks for reaching a consensus: (a) homogenous multi-\nagent debate [13], (b) multi-role multi-agent negotiation [35], (c) heterogeneous multi-agent discus-\nsion (HAD: the proposed framework). Colors denote different roles and shapes denote heterogeneous\nagents.\nThe major challenge in instantiating this design is the lack of design theory on what each agent’s\nfunction should be. For this reason, many LLM multi-agent settings employ homogeneous agents.\nFor example in the multi-agent debate framework, Du et al. [13] simply disseminate the same input\nto multiple LLM agents. Because of some randomness and perturbation, each agent’s response will\nnot be identical. Later each agent will take outputs from other agents (excluding its own output)\nas additional information to update its original response (Fig. 1 (a)). It may go through multiple\nrounds though empirical results show that consensus will be achieved fast. Another framework is\nto assign different roles to LLM agents. Sun et al. [ 35] described a negotiation procedure where\n1There is no strict definition of “how large\" a language model has to be to qualify for the name of LLM. It\nseems that LLMs are usually far larger than the word2vec models (around 1 million parameters). This definition\nincludes BERT (110-340 M parameters), GPT-3 (around 175 B parameters), and more.\n2\na “discriminator LLM\" is asked to judge whether it agrees with the output of a “generator LLM\".\nThe judgment statement is sent back to the generator if consensus is not made. The framework\nrequires a third LLM to negotiate and vote for the final result if discrepancies persist (Fig. 1 (b)).\nAlthough the LLM agents in this framework play different roles, their capability assumptions remain\nthe same. In such a sense, these agents are still non-specialized and homogeneous. In the proposed\nframework (Fig. 1 (c)), each agent has the same role, goes through a symmetric discussion workflow\n(unlike [35]), but is purposely designed to simulate the mental functions of different resources. Their\nresponses are aggregated for FSA just like resources are activated to generate different emotional\nstates.\nTherefore, one objective of this study is to test whether error types [46, 39] can be a useful guideline\nfor developing heterogeneous agents. Specifically, I am interested in the following research questions:\n• RQ1: How effective is HAD compared to naive prompting and to the fine-tuning paradigm?\n• RQ2: How to prompt LLM agents to behave heterogeneously for sentiment analysis in\nfinance?\n• RQ3: What are the quantitative contributions of each LLM agent and their relative impor-\ntance?\nTo address these questions, HAD is evaluated using multiple methods including empirical analysis of\nperformance metrics on five FSA datasets, ablation analysis with different sets of agents, and case\nstudies of outputs and intermediary representations. The experimental results show that HAD can\nin general improve the FSA performance and the improvements are constant for GPT-based LLM\nagents. It has been observed that a simple template “please pay special attention to [error type]\" can\nchange LLM agents’ attention and prompt them to behave differently. Mood, rhetoric, and reference\nagents seem to be the main performance drivers and are more critical than other LLM agents, though\nthe contributions are non-linear and have complicated interactions.\nThis study contributes to the design science literature by presenting a kernel theory-informed design\nartifact. A number of kernel theories from the natural or social sciences were introduced to information\nsystem design, whereas kernel theories from AI are comparatively rare. This study has implications\nfor the emotion theory, LLM collaboration research, and financial decision-making practices. Firstly,\nit supports the society of mind and emotion machines [27] to be actionable theories that explain how\nemotions emerge as an important type of human intelligence; Secondly, this study applies multi-agent\nLLMs in FSA. This framework has been used for factuality checking, arithmetic/mathematical\nreasoning, optimization, general-purpose sentiment analysis, but not yet on FSA to the best of my\nknowledge. This study thus provides new materials for LLM collaboration, and also reinforces the\ndesign science-based approach to framework development; Lastly, the findings contribute to the\nprescriptive knowledge of FSA system design. Investors and traders may iterate and improve their\nown FSA systems based on the HAD framework or be more informed when they decide to select or\npurchase technical solutions of a similar kind.\n2 Related Work and Design Process\nIn this section, related literature is organized into two lines: (any type of) use of LLMs for FSA,\nand ways of prompt design (not limited to FSA). I also elaborate on the theoretical foundations of\nemploying heterogeneous agents for FSA.\n2.1 Using LLMs for Financial Sentiment Analysis\nFinancial sentiment analysis (FSA) is a domain-specific business-oriented application closely related\nto the general natural language processing task of sentiment analysis. Because of its heavy use of\nterminologies and other linguistic features [ 39, 32], general sentiment analysis performances are\nusually not representative and will drop in the finance domain. FSA has been included to comprehen-\nsively evaluate LLMs for finance, together with other tasks such as Name Entity Recognition (NER),\nknowledge recall, question answering, and reading comprehension among others [32, 36].\nIn terms of using a singular LLM, the FSA task is sometimes formulated together with target or\naspect detection, and the additional information may be used to improve FSA performances. For\nexample, Lengkeek et al. [ 20] used the hierarchical structure of aspect systems to constrain FSA\n3\nresults, though this information is rarely available in real-world production environments. Zhang\net al. [44] observed that financial news is often overly succinct. A model that retrieves additional\ncontext from reliable external sources to form a more detailed instruction is consequently developed.\nDeng et al. [10] found that forcing the LLM through several reasoning paths with CoT helps generate\nmore stable and accurate labels. The LLM generated labels are also useful and meet the quality for\ncomplementing human annotations for conventional supervised learning methods. Similarly, Fei et\nal. [14] developed a three-hop reasoning framework inspired by CoT that infers firstly the implicit\naspect, secondly the implicit opinion, and finally the sentiment polarity. However, it has been pointed\nout [35] that a singular LLM has difficulties in fully exploiting the potential of LLM knowledge. This\nis especially true for FSA as it involves multiple LLM capabilities, such as reasoning, fact-checking,\nsyntactic/semantic parsing, and more. I observe a similar phenomenon as reported in [45] that LLM\nperformances on more complicated tasks are not as satisfactory as on the binary classification task.\nMoreover, the aforementioned designs (storage retrieval and CoT) and more designs that are not yet\napplied to FSA, such as verification, self-consistency constraints, or intermediate scratchpads, are\nalso largely heuristic, at most based on experiences, and lack solid theoretical foundation.\nThe proposed framework adopts in-context learning (ICL) and leverages multiple LLM instantiations\n(agents), which is also referred to as LLM collaboration. Strategies of collaboration include auxiliary\ntasks (e.g., verification) [ 4], debate [ 13], and various role-assignment [ 35] including generator,\ndiscriminator, programmer, manager, meta-controller, etc. Again, the design of auxiliary tasks and\nroles appears arbitrary and lacks solid theoretical foundations. LLM collaboration is also more\ninvestigated on many general natural language processing tasks including sentiment analysis, but\ntheir applicability on FSA lacks direct evidence. Perhaps most related to the proposed HAD design\nframework is MedPrompt [29]. It uses an ensemble of randomly shuffled CoT from homogeneous\nagents. The design is also more computationally heavy and difficult to transfer to the finance domain\nas existing financial question-answering datasets are more sparse.\n2.2 Prompt Engineering\nBefore the emergence of generative LLMs, a well-accepted way of applying a language model to\ndownstream tasks is through fine-tuning: remove the last neural network layer (referred to as the\n“head\" layer) and let the training errors back-propagate with the bottom layers parameters fixed. Two\nmajor problems with it are: (1) a not-too-small training set and labels are still needed, and (2) the\ntraining process can be computationally intensive. With the observation that generative LLMs are very\npowerful, in-context learning contends it possible to get the desired output without fine-tuning and\nelicit the model capability with an appropriate “prompt\". Typically, prompt engineering involves the\ndevelopment of task-specific prompt templates, which describe how a prompt should be formulated\nto enable the pre-trained model to perform the downstream task at hand. Liu et al. [21] provided a\nsurvey on recent advances in prompt engineering and systematically compared cloze prompts and\nprefix prompts.\nIn terms of automatically searching for the prompt template, stochastic optimization-based methods\nare discussed. Sorensen et al. [ 34], for example, discovered that a good template is the one that\nmaximizes the mutual information between input and the generated output.\nIn terms of designing prompts, Liu and Chilton [ 22] studied text-to-image generative models and\nthe prompt template “SUBJECT in the style of STYLE\". They found the clarity and salience of\nkeywords are important to the generation quality. Yu et al. [43] presented the idea of using domain\nknowledge to guide prompt design. It was reported that for the legal information entailment task,\nthe best results are obtained when prompts are derived from specific legal reasoning techniques,\nsuch as Issue-Rule-Application-Conclusion (IRAC) as taught at law schools. For FSA, however, the\ndesign guidelines are unclear and most studies used naive prompts. For example, Chen and Xing [3]\nused “You are a helpful sentiment analysis assistant - [example message]:[sentiment]. User: [test\nmessage].\" and BloombergGPT’s FSA template [36] is simply “[test message] Question: what is the\nsentiment? Answer with negative/neutral/positive\".\n2.3 Kernel Theory: Emotions and the Society of Mind\nKernel theory is a key component of the information system design process according to Walls’\ninformation system design theory (ISDT). It explains how/why the anticipated system would work\n4\nFigure 2: Illustration of the generation of emotional states from activating a collection of resources,\ncf. pg. 4 in [27].\nand sheds light on the meta-requirements. In the context of FSA, the theory has to be one that explains\nthe formative mechanism of emotion. For this reason, Minsky’s theory of mind and emotions is\npreferred over other descriptive/contrastive theories of emotions, such as Plutchik’s wheel of emotions\nor Russell’s circumplex model.\nSociety of mind is a reductionistic perspective of human intelligence that influenced AI greatly and\nargues no function directly produces intelligence. Instead, intelligence comes from the managed\ninteraction of a variety of resourceful but simpler and non-intelligent agents. For example, when\ndrinking a cup of tea, there activates a motor agent that grasps the cup, a balancer that keeps the\ntea from spreading, and a temperature sensor that confirms our throat will not be hurt. This theory\nsees emotional states as patterns of activation. For example, the state we call “angry\" could be what\nhappens when a cloud of resources that help you react with unusual speed and strength are activated\n— while some other resources that make you act prudently are suppressed (Fig. 2).\nMinsky’s theory of emotion posits that you feel “angry\" when your cake is stolen by other kids,\nbecause the IF-THEN-DO rules activate resources to help you take it back. The activation is adaptive\nas we learn and grow. For FSA, a crucial procedure is to decide what candidate resources need to be\ndesigned: it will not require the full set of resources in our brain which will be more challenging to\nbuild. In the remainder of this section, I describe the design rationales using a kernel theory-based\ndesign science framework (Table 1).\n2.4 Meta-requirements, Meta-designs, and Hypotheses\nAlthough the society of mind relies heavily on the conceptual construct of “resource\", it is purposefully\nkept in a hazy way (pg. 25 in [27]), referring to all sorts of functional parts that range from perception\nand action to reflective thinking. Therefore, it seems appropriate to simulate the resources using\nLLM agents with polymathic capabilities, and specialize their functions via prompts. This choice\nalso makes resource activation plausible, because specialized agents will not generate meaningful\nresponses to the out-of-scope context. It is thus designed such that all the LLM agents will receive\nthe original user message. To aggregate information, a widely used technique is to concatenate\nthem into a longer prompt [35, 13, 17, 21]. By translating the meta-requirements into more detailed\nmeta-designs, the HAD framework can be formally represented as:\nTable 1: Kernel Theory-Based Design: A Meta-Framework\nKernel theory Society of mind and emotion machines.\nThe theories posit that emotions come from activation of different resources.\nMeta-requirements\n1. To simulate the resources, we should define agents and their functions.\n2. To activate the agents, we should provide information about the subjectivity.\n3. To achieve a well-informed decision, we should aggregate information from different agents.\nMeta-designs\n1. Types of error are used as domain knowledge to guide building heterogeneous agent capabilities.\n2. The user message is distributed to each LLM agent.\n3. Specialized agent outputs are concatenated to form the summative prompt.\nTestable hypotheses\nEvaluate the effectiveness of the metadesigns. Specific testable hypotheses are as follows:\nHypothesis 1: The HAD framework can improve the accuracy of existing naive prompts for FSA.\nHypothesis 2: The agents have different importance but all contribute positively to the analysis.\n5\n1. Define heterogeneous agents and their prompt templates A1, A2, ..., Ak.\n2. Obtain intermediary analysis Oi = Ai(User_Message)\n3. Obtain summative analysis Result = A(User_Message, O1, ..., Ok)\nThe second step can be carried out for multi-rounds before sending for a summary depending on the\nconsensus situation. An illustration of the workflow is presented in Fig. 3.\nTo assess whether the proposed framework is effective, two testable hypotheses are developed. If types\nof error are useful for guiding agent design, we would expect the performance metrics to improve\n(H1). Because of the noted data imbalance issue in FSA, F-1 score should also be investigated on top\nof accuracy. Another observation is that the occurrences of each type of error are not equal and vary\nacross different language domains [46, 39]. It is thus hypothesized that the agents will have different\nimportance but all contribute positively to the FSA task (H2).\n3 Design Artifact: Heterogeneous Agent Discussion (HAD)\nTo instantiate a design artifact based on the HAD framework, the number of agents ( k) has to be\ndecided.\nZimbra et al. [46] had investigated a comprehensive list of Twitter sentiment analysis methods and\nconcluded three major challenges: (1) language brevity, (2) imbalanced classes, and (3) temporal\ndependency. Because of these challenges, 13 categories of commonly occurring classification errors\nwere identified. The main categories that ground to linguistic features can be summarized as: (1)\nhumor, (2) subtlety or a mixture of sentiment, (3) irrelevance (e.g., aspect mismatch), (4) marketing\ninformation mistaken as positive, and (5) atypical contextual usage. Xing et al. [39] investigated the\ncommon errors in a slightly different scope: specifically for FSA and including text sources other\nthan Twitter2. The 6 categories of errors identified, i.e., (1) irrealis mood, (2) rhetoric, (3) dependent\nopinion, (4) unspecified aspects, (5) unrecognized words, and (6) external reference, have significant\noverlap with those reported from [46].\nWith this background, five agents are designed based on [39] because (1) these categories are more\ndirectly FSA relevant and (2) these categories are less in number (6 compared to 13) and more\noperational. Since LLMs are observed to be robust to unrecognized words and spellings from the\nweb, no special agent is designed according to this error. The five agents and their characteristic\nprompts are:\n• A1 (the mood agent): Please pay special attention to any irrealis mood used.\n• A2 (the rhetoric agent): Please pay special attention to any rhetorics (sarcasm, negative\nassertion, etc.) used.\n• A3 (the dependency agent): Please focus on the speaker sentiment, not a third party.\n• A4 (the aspect agent): Please focus on the stock ticker/tag/topic, not other entities.\n• A5 (the reference agent): Please pay special attention to the time expressions, prices, and\nother unsaid facts.\nThe summative prompt takes the form of “Considering this message: [test message] and additional\nopinions from experts [opinions], what is the sentiment, positive/negative/neutral?\". Some nuances\nare adjusted according to whether the testbed classification is binary or ternary.\n4 Evaluation\nHevner et al. [ 18] described five kinds of design evaluation methods. This study leverages three\nout of them: (1) empirical testing on existing datasets and the produced performance metrics, (2)\nablation analysis with manipulated module components, and (3) observational evaluation based on\ncase studies.\n2Now has been re-branded as “X\".\n6\n \n  \nConsider this message:\n'$SBUX  this stock has been consolidating and \ncoiling  for years.  I think many underestimate it. \nspring how’\nWhat is the sentiment, positive or negative?\nAgent response\nUser prompt \nThe sentiment of the message is unclear, as it could be \ninterpreted as either positive or negative. The stock has been \nconsolidating and coiling for years, which could be seen as \neither a positive sign of stability and potential growth, or a \nnegative sign of stagnation and lack of movement. Further \ncontext or clarification would be needed to determine the \noverall sentiment of the message.\nAgent 1 response\nUser prompt \nThe sentiment of the message is negative. The use of the phrase \n\"consolidating and coiling for years\" suggests a long period of \nstagnation or underperformance, and the statement \"I think many \nunderestimate it\" further implies a lack of confidence in the stock. \nThe use of the word \"spring\" could suggest a potential turnaround in \nthe future, but the overall tone of the message is negative.\nConsider this message:\n'$SBUX  this stock has been consolidating and coiling  for \nyears.  I think many underestimate it. spring how’\nWhat is the sentiment, positive or negative?\nPlease pay special attention to the time expressions used.\nAgent 2 response\nUser prompt \nThe sentiment of the message is positive. The speaker is expressing \nthe belief that the stock has been consolidating and coiling for \nyears, and that many people underestimate it. The use of the word \n\"spring\" suggests that the speaker believes the stock has potential \nto make a significant upward movement. The irrealis mood is evident \nin the use of \"I think\" and \"many underestimate it,\" indicating the \nspeaker\\'s subjective interpretation and speculation.\nConsider this message:\n'$SBUX  this stock has been consolidating and coiling  \nfor years.  I think many underestimate it. spring how’\nWhat is the sentiment, positive or negative?\nPlease pay special attention to any irrealis mood used.\nAgent 3 response\nUser prompt \nThe sentiment of the speaker appears to be positive. They \nbelieve that the stock has potential and may be underestimated \nby others. They also use the phrase \"spring how,\" which could \nindicate that they are expecting the stock to make a \nsignificant upward move. Overall, the sentiment of the speaker \nseems to be optimistic about the potential of the stock.\nConsider this message:\n'$SBUX  this stock has been consolidating and coiling  \nfor years.  I think many underestimate it. spring how’\nWhat is the sentiment, positive or negative?\nPlease focus on the speaker sentiment, not a third party.\nUser prompt \nThe sentiment of the message appears to be positive, with \none expert interpreting it as negative and the other two \ninterpreting it as positive. The use of language such as \n\"consolidating and coiling for years\" and \"many \nunderestimate it\" can be negative, but the mention of \n\"spring\" and the overall tone of optimism expressed by \nthe other experts suggests a more positive sentiment.\nConsider this message:\n'$SBUX  this stock has been consolidating and coiling  \nfor years.  I think many underestimate it. spring how’\nAnd additional opinions from experts:\nThe sentiment of the message is negative. The use of \nthe phrase suggests…\nThe sentiment of the message is positive. The speaker \nis expressing the belief that…\nThe sentiment of the speaker appears to be positive. \nThey believe that the stock has potential…\nWhat is the sentiment, positive or negative?\nAgent response\nFigure 3: An illustrative comparison between naive prompting (the upper example) and the proposed\nHAD framework (the lower example) with 3 heterogeneous agents inspired by FSA error types.\n7\n4.1 Performance Improvement\nThe proposed design framework is evaluated on five existing datasets, i.e., the Financial Phrase-\nBank [26], StockSen [39], CMC [3], FiQA Task 1 [ 25], and SEntFiN 1.0 [ 33]. The last two are\nfiner-grained financial sentiment analysis datasets with sentiment intensity scores or multiple target-\ns/entities labels, though I applied quantization and filtering to fit the evaluations into a consistent\nclassification problem. For example, the original FiQA dataset [25] has 1173 messages with sentiment\nscores ranging from -1 to +1. By filtering those scores with an absolute value larger than 0.3, only\n771 messages are left and mapped to the positive/negative classes. The detailed statistics are reported\nin Table 2. In terms of text genre, Financial PhraseBank (FPB) is from news and SEntFiN is from\nnews headlines. StockSen and CMC are from social media (StockTwits and CoinMarketCap.com\nrespectively), and the whole FiQA is consolidated from crawling a mix of StackExchange, Reddit,\nand StockTwits.\nThe HAD framework is tested on two instruction-finetuned language models: GPT-3.53 as a restrict-\naccess representative, and BLOOMZ4 (the 560m version [28]) as an open-access representative. The\nperformance metrics on GPT-3.5 are obtained through OpenAI API, and metrics on BLOOMZ are\ncomputed using a laptop with an 8-core Apple M1 chip and 16 GB memory. For both LLMs, one\nexperiment takes minutes to hours to execute. The performance metrics are reported in Table 3.\nFor ternary classifications (FPB and SEntFiN), macro F-1 scores are used. Some metrics (in grey\ncolor) of BloombergGPT [36] and (Fin-)BERT [39, 32, 12, 3, 33] are included to help roughly assess\nthe gaps to fine-tuning based results. Noteworthy, these metrics are cited from other studies and\nBloombergGPT is a proprietary model, so the metrics may be obtained from different evaluation\nsettings (e.g., 3/5-classes or different data splits).\nThe first observation is the different behaviors of GPT-3.5 and BLOOMZ as base models. GPT-3.5\nwas trained mainly on the Common Crawl corpus [ 2], which archives the web. BLOOMZ was\ntrained on an even larger Open-science Open-collaboration Text Sources corpus [19], which is mainly\ncrowd-sourced scientific datasets. The five testing datasets are all from the web: this may be closer\nto GPT-3.5’s trained language domain. It is observed that GPT-3.5 is better instruction-tuned with\nits proprietary human feedback. In contrast, BLOOMZ inclines to the language completion task.\nAn example is that the prompt “Translate to English: Je t’aime\" without a full stop (.) at the end\nmay result in the model trying to continue the French sentence instead of translating it. BLOOMZ\ninclines to complete/answer with concise language. For the sentiment-related open-ended questions\nto heterogeneous agents, BLOOMZ often answers a final judgment of positive/negative without much\njustification, and is not good at predicting “neutral\" messages. For the afore-discussed factors,\nTable 2: Summary statistics of the five FSA datasets (post-processing).\nDataset FPB StockSen CMC FiQA SEntFiN\nPositive 570 4542 12022 507 2832\nNegative 303 1676 1523 264 2373\nNeutral 1391 – – – 2701\nTotal Size 2264 6218 13545 771 7906\nTable 3: Effects of instantiating the HAD design framework on different LLMs.\nModel\\Dataset FPB StockSen CMC FiQA SEntFiN\nAcc. F-1 Acc. F-1 Acc. F-1 Acc. F-1 Acc. F-1\n(Fin-)BERT 91.69 89.70 76.90 84.50 93.50 – – – 94.29 93.27\nBloombergGPT – 51.07 – – – – – 75.07 – –\nGPT-3.5 78.58 81.06 67.64 73.93 85.31 91.05 90.53 92.41 67.99 63.21\nGPT-3.5 (HAD) 80.48 81.41 70.44 76.55 87.55 92.50 93.91 95.22 77.45 76.93\nBLOOMZ 34.63 32.90 63.65 72.47 87.16 92.62 78.33 83.64 51.32 41.87\nBLOOMZ (HAD) 34.19 32.93 72.80 83.97 87.67 92.95 76.78 83.03 50.16 40.69\n3https://platform.openai.com/docs/models/gpt-3-5\n4https://huggingface.co/bigscience/bloomz\n8\nBLOOMZ performance metrics are generally inferior except for the CMC dataset, and the differences\nare more pronounced for FPB and SEntFiN, which contain neutral classes.\nThe second observation is that HAD generally improves the accuracies and F-1 scores on the base\nmodels (Table 3). The improvements (from +2.24% to +9.46% for accuracy and from +0.35% to\n+13.72% for F1-score) are very consistent on GPT-3.5, probably due to the richer intermediary\nanalysis generated. HAD’s effect on BLOOMZ is minimal except for on the StockSen dataset, where\nthe ca. +10% improvements are significant. Noteworthy, StockSen is the dataset on which the error\ntypes for agent design are derived.\nThe last observation is on assessing the significance of the improvements. Theoretically, fine-tuning\nthe LLMs to a downstream task will perform better than the ICL/instruction-based/zero-shot setting\njust as in the differences of supervised/unsupervised learning. The cost of fine-tuning is bi-fold\nin the context of FSA: you have to ask experts to accumulate and label thousands of examples;\nand the performance will be fragile to data distribution shifts and dependent on the optimization\ntechniques applied. By comparing the improvements to the overall differences between GPT-3.5 and\n(Fin)-BERT on FPB, StockSen, CMC, and SEntFiN, a fair estimation is that the HAD framework can\nfix 25%–35% of the gap between ICL and fine-tuning.\n4.2 Ablation Analysis\nTo test the importance of each LLM agent, their intermediary responses are removed singly and the\nperformance decreases benchmarked on GPT-3.5 (HAD) are reported in Table 4. Because of time\nconstraints, only three datasets and the average results are used: FPB and FiQA have the two smallest\nsizes, and the effect of HAD is the most pronounced on SEntFiN.\nIt is observed that the mood agent (A1), the rhetoric agent (A2), and the aspect agent (A4) are the\nmost important: removing any of them will generally have a negative impact on the performance. The\nreference agent (A5) is less important: the effect of removing it is uncertain across different datasets.\nThe dependency agent (A3) seems ineffective: removing A3 will further improve the performance.\nThe ineffectiveness of A3 may suggest considering this error type is unnecessary, or be attributed\nto an ineffective prompt design. Either way, the observed performances suggest that heterogeneous\nagents have complicated non-linear interactions, and the presented design can be further optimized\nwith more empirical evidence.\n4.3 Case Study\nFive cases are presented to illustrate the quality of HAD outputs and how those outputs predict a\npolarity different from naive prompting.\nTable 4: Effects of removing one agents (using gpt-3.5-turbo-1106 as the base model)\nModel\\Dataset FPB FiQA SEntFiN Average\nAcc. F-1 Acc. F-1 Acc. F-1 Acc. F-1\nGPT-3.5 (HAD) 80.48 81.41 93.91 95.22 77.45 76.93 – –\nGPT-3.5 -1.90 -0.35 -3.38 -2.81 -9.46 -13.72 – –\nw/o A1 -0.71 +0.64 -0.01 +0.02 -0.58 -0.61 -0.43 +0.02\nw/o A2 -2.12 -0.39 +0.64 +0.52 -0.80 -0.99 -0.76 -0.29\nw/o A3 +3.00 +3.56 +0.51 +0.42 +0.01 +0.03 +1.17 +1.34\nw/o A4 +0.04 +0.97 +0.25 +0.22 -0.66 -0.69 -0.12 +0.16\nw/o A5 +4.32 +4.29 -0.01 -0.00 -0.52 -0.43 +1.26 +1.28\n9\nIn Case 1, multiple companies are mentioned and naive prompting produces a negative prediction\nwithout much explanation. With HAD, A1 and A2 believe this message is neutral according to their\nperspectives. A1’s argument is reasonable as the positivity is more directly associated to Wells Fargo\nthan to Berkshire. With A3, A4, A5 considering the message as positive, the framework finally\nsummarizes a correct polarity as positive.\nCase 2 is challenging and can easily be mistaken as positive by naive prompting with key-phrase such\nas “drive ... higher\" spotted. To correctly understand the context, one has to know that Taylor Wimpey\nand Ashtead are home construction and construction equipment rental companies. So “driving the\nmarkets higher\" may refer to the index or property markets and is setting an economic scenario. It has\ncomplicated implications for the two companies and is not as direct as “Barclays falls\". A1, A4, A5\nare correct about the mixed sentiment. With A3’s judgment being neutral and A2 predicting negative,\nthe framework finally summarizes a correct polarity as negative.\nCase 3 is predicted as positive by naive prompting. Although as A1 explained, less smuggling is\ngood for society, the message is apparently commenting on gold itself as a commodity. Despite the\nfact that no irrealis mood or any rhetorics are present, A1, A2, A5 correctly predict the message as\nnegative. With A3 and A4 seeing it as neutral, the final decision is negative as per the majority.\nCase 1: Berkshire applies to boost Wells Fargo stake above 10 pct (positive)\n(A1) Neutral. No indication of positive or negative sentiment. The use of \"applies to\" suggests\nan irrealis mood, means Berkshire is seeking to increase its stake but the action has not yet\nbeen completed. (A2) Neutral. No indications of sarcasm or negative assertion in the message.\n(A3) The sentiment of the speaker in this message is likely positive, as they are expressing\ntheir intention to increase their stake, which suggests confidence. ( A4) The sentiment is\npositive for \"Wells Fargo\" as Berkshire Hathaway’s application suggests confidence and\noptimism in the company’s potential. (A5) The sentiment of the message is generally positive.\nBerkshire Hathaway’s decision potentially have a positive impact on Wells Fargo’s stock\nprice and overall reputation. The increase timing suggests potential for long-term success\ndespite any current challenges facing Wells Fargo.\nCase 2: London open: Taylor Wimpey and Ashtead drive markets higher, Barclays falls\n(negative)\n(A1) Mixed sentiment. Drive markets higher suggests a positive sentiment, while Barclays\nfalls indicates a negative sentiment. No use of irrealis mood. ( A2) Negative. It highlights\nthe fact that Barclays falls, while giving less emphasis to the positive performance of Taylor\nWimpey and Ashtead. No specific rhetorics used. (A3) Neutral. They are simply reporting on\nthe market movements and the performance of certain companies. (A4) Positive for Taylor\nWimpey and Ashtead as they are driving the markets higher, while the sentiment is negative\nfor Barclays as it is falling. (A5) Overall a mixed sentiment. Some companies are performing\nwell and driving the market higher, others, such as Barclays, are not faring as well.\nCase 3: Smuggling of gold sees a decline as its demand softens (negative)\n(A1) The sentiment is negative. Word “decline\" indicates a decrease in smuggling activity,\nwhich could be seen as positive, but the softening demand for gold implies a negative impact\non the overall market for gold. There is no irrealis mood used in this message. ( A2) The\nsentiment is negative. Decline and soften indicate a decrease in the demand for gold, which\ncould have negative implications for those involved in the smuggling of gold. No specific\nrhetorical devices present. ( A3) Speaker is neutral. ( A4) Neutral. ( A5) The sentiment is\nnegative. The decrease in the demand indicates a downturn in the market, leading to a decline\nin smuggling activities. This suggests a weakening gold market, which could impact prices\nand trade within the industry.\n10\nCase 4: Puravankara’s real estate scheme not a CIS: Sebi (negative)\n(A1) The sentiment is negative. The use of the word “not\" indicates the negation of a positive\noutcome, and the mention of Sebi suggests that there may be regulatory or legal issues\nassociated with Puravankara’s real estate scheme. There does not appear to be any irrealis\nmood used in this message. (A2) The sentiment is negative. “not a CIS\" may imply suspicion\nthat Puravankara’s real estate scheme was a CIS (Collective Investment Scheme), which is\nregulated by SEBI (Securities and Exchange Board of India). The use of the term \"scheme\"\nalso carries a negative connotation, as it can imply a dubious or deceptive plan. Overall,\nthe message communicates a negative view of Puravankara’s real estate activities in relation\nto SEBI regulations. ( A3) Neutral. The statement just delivers factual information. ( A4)\nNeutral. ( A5) The sentiment appears to be negative, indicated by the mention of Sebi not\nconsidering Puravankara’s real estate scheme as a Collective Investment Scheme (CIS). There\nmay be some regulatory or compliance issues with the scheme, which could have negative\nimplications for the company and its investors. Additionally, the fact that the scheme is being\nscrutinized by a regulatory authority implies a potential risk or concern. However, without\nfurther details about the specific nature of the scheme or the reasons for Sebi’s decision, it is\ndifficult to fully assess the sentiment.\nCase 5: Whirlpool may head to around 450-475: Devang Visaria (neutral)\n(A1) The sentiment is neutral. The use of \"may\" indicates an irrealis mood, suggesting that\nthe statement is hypothetical or uncertain. (A2) The sentiment appears to be neutral. There\nare no apparent rhetorics or emotional language. The statement simply presents a speculated\nrange for the potential movement of Whirlpool. (A3) Sentiment of the speaker seems to be\nsomewhat positive as they are mentioning a potential increase in the stock price of Whirlpool,\nindicating a sense of optimism or anticipation. (A4) Neutral. (A5) The sentiment is neutral.\nIt simply provides a prediction regarding the potential price movement without expressing\npositive or negative. It is based on analysis and does not convey any emotion or bias.\nCase 4 is difficult to understand and predicted as positive by naive prompting. Jargon and external\nreference are the main challenges. From the responses of A1, A2, and A5, it can be observed\nthat “Puravankara is a real estate company\", “CIS means Collective Investment Scheme\" and “Sebi\nis a security regulatory authority\" are shared knowledge. Surprisingly, A2 exhibits temporal and\ncounterfactual reasoning, which is helpful in understanding this message.\nThe last Case 5 was wrongly predicted as positive by naive prompting, probably due to the slight\npositive color of phrasing “head to\". A1 and A2 correctly identified the uncertainty associated with\nirrealis mood. A3 detected the same positivity as naive prompting, while the other four agents all\npredict the message as neutral. With the dominant number of neutral predictions (4:1), the framework\ncorrectly summarized the polarity as neutral. This shows HAD’s capability to correct slight and\nuncertain sentiments with a discussion mechanism.\n5 Discussion, Conclusion, and Future Work\nA novel theory-informed LLM collaboration design for FSA, named HAD, is studied. The design\ninvolves heterogeneous LLM agents and specializes them with FSA error types discovered in the\npast literature. This design is more computationally intensive than naive prompting, but has far\nless complexity compared to many other LLM collaboration frameworks and fine-tuning-based\napproaches. In view of the research questions and hypotheses, it has been found that HAD effectively\nimproves FSA accuracies across a number of existing datasets, especially when the LLM agents can\nproduce substantial discussions. The design framework fixes around 25% – 35% of the performance\ngap between prompting and fine-tuning. With error type-based prompts, the LLM agents behave\nheterogeneously with different focuses. The mood, rhetoric, and aspect agents are more important\nthan the reference agent. The evaluation results support Hypothesis 1 (H1), but reject Hypothesis 2\n(H2) with the observation that the performance can be further optimized if the dependency agent is\nremoved.\n11\nTechnically, this study contributes across two areas in the Knowledge Contribution Framework (KCF)\nof deep learning in information systems research [31]. The HAD framework is formulated and instan-\ntiated in a high-impact application domain of FSA, where fine-tuning is still a dominant paradigm\nand LLM collaboration is rarely applied. The framework is zero-shot and training-free, therefore, the\nperformance improvement should be able to generalize to other FSA datasets. Practically, financial\nadvisors, traders, fund managers, and other types of investors could use this framework to build their\nin-house sentiment analysis tools, or extend their knowledge of possible system designs for FSA.\nThis preliminary study has a few limitations, which may inspire future research. The first limitation\nis scalability. Predicting or Discussion with LLM agents is slower compared to statistical analysis\nand incurs costs. For this reason, a large system, i.e., with more agents, is possible, but not preferred\nduring design and evaluation. The second limitation is the confidentiality of evaluation datasets.\nStockSen, CMC, and SEntFiN are relatively new, but FPB and FiQA have been there for quite a\nfew years. Because the training material for LLMs is usually not fully transparent and some LLMs\nkeep updating using reinforcement learning and human feedback, the possibility that the evaluation\ndatasets have been exposed to the LLMs before, causing some information leaks can not be excluded.\nFinally, the case studies show that the identified error types can almost be solved. It is therefore\ninteresting to explore what are the reasons for the new/remaining errors made by LLMs and assess\nwhat are the human/expert-level performances on these FSA datasets.\nSome of the unique challenges in FSA, e.g., external references to facts and world knowledge, were\nthought to be impossible to solve in the short-term future before the transformer architecture models\ncame into existence. With the hope of artificial general intelligence (AGI) around the corner, this\nstudy exhibits the versatile capabilities of LLM that are useful for FSA, and calls for more research\non this important task.\nReferences\n[1] J. Bollen, H. Mao, and X. Zeng. Twitter mood predicts the stock market. Journal of Computa-\ntional Science, 2(1):1–8, 2011. doi:10.1016/j.jocs.2010.12.007.\n[2] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan,\nP. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-V oss, G. Krueger, T. Henighan, R. Child,\nA. Ramesh, D. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray,\nB. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei. Lan-\nguage models are few-shot learners. In Proceedings of NeuIPS’20, pages 1877–1901, 2020.\ndoi:10.48550/arXiv.2005.14165.\n[3] S. Chen and F. Xing. Understanding emojis for financial sentiment analysis. In Proceedings\nof ICIS’23, pages 1–16, 2023. URL https://aisel.aisnet.org/icis2023/socmedia_\ndigcollab/socmedia_digcollab/3/.\n[4] X. Chen, M. Lin, N. Schärli, and D. Zhou. Teaching large language models to self-debug, 2023.\ndoi:10.48550/ARXIV .2304.05128.\n[5] L. Chu, X.-Z. He, K. Li, and J. Tu. Investor sentiment and paradigm shifts in equity return\nforecasting. Management Science, 68(6):4301–4325, 2022. doi:10.1287/mnsc.2020.3834.\n[6] K. Cortis, A. Freitas, T. Daudert, M. Huerlimann, M. Zarrouk, S. Handschuh, and B. Davis.\nSemeval-2017 task 5: Fine-grained sentiment analysis on financial microblogs and news. In\nSemEval Workshop, 2017. doi:10.18653/v1/S17-2089.\n[7] D. de França Costa and N. F. F. da Silva. Inf-ufg at fiqa 2018 task 1: predicting sentiments and\naspects on financial tweets and news headlines. In Companion Proceedings of the The Web\nConference 2018, pages 1967–1971, 2018. doi:10.1145/3184558.3191828.\n[8] J. Deng, M. Yang, M. Pelster, and Y . Tan. Social trading, communication, and networks.\nInformation Systems Research, 2023. doi:10.1287/isre.2021.0143.\n[9] S. Deng, Z. J. Huang, A. P. Sinha, and H. Zhao. The interaction between microblog sen-\ntiment and stock returns: An empirical examination. MIS Quarterly, 42(3):895–918, 2018.\ndoi:10.25300/misq/2018/14268.\n12\n[10] X. Deng, V . Bashlovkina, F. Han, S. Baumgartner, and M. Bendersky. What do llms know about\nfinancial markets? a case study on reddit market sentiment analysis. In Companion Proceedings\nof the ACM Web Conference 2023, 2023. doi:10.1145/3543873.3587324.\n[11] W. Dong, S. Liao, and Z. Zhang. Leveraging financial social media data for corpo-\nrate fraud detection. Journal of Management Information Systems , 35(2):461–487, 2018.\ndoi:10.1080/07421222.2018.1451954.\n[12] K. Du, F. Xing, and E. Cambria. Incorporating multiple knowledge sources for targeted aspect-\nbased financial sentiment analysis. ACM Transactions on Management Information Systems,\n14(3):1–24, 2023. doi:10.1145/3580480.\n[13] Y . Du, S. Li, A. Torralba, J. B. Tenenbaum, and I. Mordatch. Improving factuality and reasoning\nin language models through multiagent debate, 2023. doi:10.48550/ARXIV .2305.14325.\n[14] H. Fei, B. Li, Q. Liu, L. Bing, F. Li, and T.-S. Chua. Reasoning implicit sentiment\nwith chain-of-thought prompting. In Proceedings of ACL’23 , pages 1171–1182, 2023.\ndoi:10.18653/v1/2023.acl-short.101.\n[15] S. Gregor and A. R. Hevner. Positioning and presenting design science research for maximum\nimpact. MIS Quarterly, 37(2):337–355, 2013. doi:10.25300/misq/2013/37.2.01.\n[16] T. Hendershott, X. M. Zhang, J. L. Zhao, and Z. E. Zheng. Fintech as a game\nchanger: Overview of research frontiers. Information Systems Research, 32(1):1–17, 2021.\ndoi:10.1287/isre.2021.0997.\n[17] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt.\nMeasuring massive multitask language understanding. In Proceedings of ICLR’21 , 2021.\ndoi:10.48550/arXiv.2009.03300.\n[18] A. R. Hevner, S. T. March, J. Park, and S. Ram. Design science in information systems research.\nMIS Quarterly, 28(1):75–105, 2004. doi:10.2307/25148625.\n[19] H. Laurençon, L. Saulnier, T. Wang, C. Akiki, A. V . del Moral, T. L. Scao, L. von Werra, C. Mou,\nE. G. Ponferrada, H. Nguyen, J. Frohberg, M. Sasko, Q. Lhoest, A. McMillan-Major, G. Dupont,\nS. Biderman, A. Rogers, L. B. Allal, F. D. Toni, G. Pistilli, O. Nguyen, S. Nikpoor, M. Masoud,\nP. Colombo, J. de la Rosa, P. Villegas, T. Thrush, S. Longpre, S. Nagel, L. Weber, M. Muñoz,\nJ. Zhu, D. van Strien, Z. Alyafeai, K. Almubarak, M. C. Vu, I. Gonzalez-Dios, A. Soroa,\nK. Lo, M. Dey, P. O. Suarez, A. Gokaslan, S. Bose, D. I. Adelani, L. Phan, H. Tran, I. Yu,\nS. Pai, J. Chim, V . Lepercq, S. Ilic, M. Mitchell, A. S. Luccioni, and Y . Jernite. The bigscience\nROOTS corpus: A 1.6tb composite multilingual dataset. In Proceedings of NeurIPS’22, 2022.\ndoi:10.48550/arXiv.2303.03915.\n[20] M. Lengkeek, F. van der Knaap, and F. Frasincar. Leveraging hierarchical language models\nfor aspect-based sentiment analysis on financial data. Information Processing & Management,\n60(5):103435, 2023. doi:https://doi.org/10.1016/j.ipm.2023.103435.\n[21] P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, and G. Neubig. Pre-train, prompt, and predict:\nA systematic survey of prompting methods in natural language processing. ACM Computing\nSurveys, 55(9):1–35, 2023. doi:10.1145/3560815.\n[22] V . Liu and L. B. Chilton. Design guidelines for prompt engineering text-to-image generative\nmodels. In Proceedings of CHI ’22, 2022. doi:10.1145/3491102.3501825.\n[23] Z. Liu, D. Huang, K. Huang, Z. Li, and J. Zhao. Finbert: A pre-trained financial language\nrepresentation model for financial text mining. In Proceedings of IJCAI’20, pages 4513–4519,\n2020. doi:10.24963/ijcai.2020/622.\n[24] T. Loughran and B. McDonald. When is a liability not a liability? textual analysis, dictionaries,\nand 10-ks. Journal of Finance, 66(1):35–65, 2011. doi:10.1111/j.1540-6261.2010.01625.x.\n[25] M. Maia, S. Handschuh, A. Freitas, B. Davis, R. McDermott, M. Zarrouk, and A. Balahur.\nWWW’18 open challenge: financial opinion mining and question answering. In Proceedings of\nWWW’18, pages 1941–1942, 2018. doi:10.1145/3184558.3192301.\n13\n[26] P. Malo, A. Sinha, P. Korhonen, J. Wallenius, and P. Takala. Good debt or bad debt: Detecting\nsemantic orientations in economic texts. Journal of the Association for Information Science\nand Technology, 65(4):782–796, 2014. doi:10.1002/asi.23062.\n[27] M. Minsky. The Emotion Machine: Commonsense Thinking, Artificial Intelligence, and the\nFuture of the Human Mind. Simon & Schuster, 2006.\n[28] N. Muennighoff, T. Wang, L. Sutawika, A. Roberts, S. Biderman, T. Le Scao, M. S. Bari, S. Shen,\nZ. X. Yong, H. Schoelkopf, X. Tang, D. Radev, A. F. Aji, K. Almubarak, S. Albanie, Z. Alyafeai,\nA. Webson, E. Raff, and C. Raffel. Crosslingual generalization through multitask finetuning. In\nProceedings of ACL’23, pages 15991–16111, 2023. doi:10.18653/v1/2023.acl-long.891.\n[29] H. Nori, Y . T. Lee, S. Zhang, D. Carignan, R. Edgar, N. Fusi, N. King, J. Larson, Y . Li, W. Liu,\nR. Luo, S. M. McKinney, R. O. Ness, H. Poon, T. Qin, N. Usuyama, C. White, and E. Horvitz.\nCan generalist foundation models outcompete special-purpose tuning? case study in medicine,\n2023. doi:10.48550/ARXIV .2311.16452.\n[30] R. L. Peterson. Trading on Sentiment: The Power of Minds Over Markets . Wiley, 2016.\ndoi:10.1002/9781119219149.\n[31] S. Samtani, H. Zhu, B. Padmanabhan, Y . Chai, H. Chen, and J. F. Nunamaker. Deep learning\nfor information systems research. Journal of Management Information Systems, 40(1):271–301,\n2023. doi:10.1080/07421222.2023.2172772.\n[32] R. Shah, K. Chawla, D. Eidnani, A. Shah, W. Du, S. Chava, N. Raman, C. Smiley, J. Chen, and\nD. Yang. When FLUE meets FLANG: Benchmarks and large pretrained language model for\nfinancial domain. In Proceedings of EMNLP’22, 2022. doi:10.18653/v1/2022.emnlp-main.148.\n[33] A. Sinha, S. Kedas, R. Kumar, and P. Malo. SEntFiN 1.0: Entity-aware sentiment analy-\nsis for financial news. Journal of the Association for Information Science and Technology ,\n73(9):1314–1335, 2022. doi:10.1002/asi.24634.\n[34] T. Sorensen, J. Robinson, C. Rytting, A. Shaw, K. Rogers, A. Delorey, M. Khalil, N. Fulda, and\nD. Wingate. An information-theoretic approach to prompt engineering without ground truth\nlabels. In Proceedings of ACL’22, 2022. doi:10.18653/v1/2022.acl-long.60.\n[35] X. Sun, X. Li, S. Zhang, S. Wang, F. Wu, J. Li, T. Zhang, and G. Wang. Sentiment analysis\nthrough llm negotiations, 2023. doi:10.48550/ARXIV .2311.01876.\n[36] S. Wu, O. Irsoy, S. Lu, V . Dabravolski, M. Dredze, S. Gehrmann, P. Kambadur,\nD. Rosenberg, and G. Mann. Bloomberggpt: A large language model for finance, 2023.\ndoi:10.48550/ARXIV .2303.17564.\n[37] F. Xing, E. Cambria, and R. Welsch. Intelligent asset allocation via market\nsentiment views. IEEE Computational Intelligence Magazine , 13(4):25–34, 2018.\ndoi:10.1109/mci.2018.2866727.\n[38] F. Xing, E. Cambria, and Y . Zhang. Sentiment-aware volatility forecasting.Knowledge Based\nSystems, 176:68–76, 2019. doi:10.1016/j.knosys.2019.03.029.\n[39] F. Xing, L. Malandri, Y . Zhang, and E. Cambria. Financial sentiment analysis: An investigation\ninto common mistakes and silver bullets. In Proceedings of COLING’20, pages 978–987, 2020.\ndoi:10.18653/v1/2020.coling-main.85.\n[40] F. Xing, F. Pallucchini, and E. Cambria. Cognitive-inspired domain adaptation of\nsentiment lexicons. Information Processing & Management , 56(3):554–564, 2019.\ndoi:10.1016/j.ipm.2018.11.002.\n[41] Y . Yang, Y . Qin, Y . Fan, and Z. Zhang. Unlocking the power of voice for financial risk\nprediction: A theory-driven deep learning design approach. MIS Quarterly, 47(1):63–96, 2023.\ndoi:10.25300/misq/2022/17062.\n[42] S. Yao, D. Yu, J. Zhao, I. Shafran, T. Griffiths, Y . Cao, and K. Narasimhan. Tree of thoughts:\nDeliberate problem solving with large language models. In Proceedings of NeuIPS’23, pages\n1–14, 2023.\n14\n[43] F. Yu, L. Quartey, and F. Schilder. Exploring the effectiveness of prompt engineering for\nlegal reasoning tasks. In Findings of the Association for Computational Linguistics , 2023.\ndoi:10.18653/v1/2023.findings-acl.858.\n[44] B. Zhang, H. Yang, T. Zhou, M. Ali Babar, and X.-Y . Liu. Enhancing financial sentiment\nanalysis via retrieval augmented large language models. In Proceedings of ICAIF’23, 2023.\ndoi:10.1145/3604237.3626866.\n[45] W. Zhang, Y . Deng, B. Liu, S. J. Pan, and L. Bing. Sentiment analysis in the era of large\nlanguage models: A reality check, 2023. doi:10.48550/ARXIV .2305.15005.\n[46] D. Zimbra, A. Abbasi, D. Zeng, and H. Chen. The state-of-the-art in twitter sentiment analysis:\nA review and benchmark evaluation. ACM Transactions on Management Information Systems,\n9(2):5:1–5:29, 2018. doi:10.1145/3185045.\n15"
}