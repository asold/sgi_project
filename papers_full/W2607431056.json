{
  "title": "A comparison of stimulus types in online classification of the P300 speller using language models",
  "url": "https://openalex.org/W2607431056",
  "year": 2017,
  "authors": [
    {
      "id": "https://openalex.org/A1972219705",
      "name": "William Speier",
      "affiliations": [
        "University of California, Los Angeles"
      ]
    },
    {
      "id": "https://openalex.org/A2490417413",
      "name": "Aniket Deshpande",
      "affiliations": [
        "University of California, Los Angeles"
      ]
    },
    {
      "id": "https://openalex.org/A2606861999",
      "name": "Lucy Cui",
      "affiliations": [
        "University of California, Los Angeles"
      ]
    },
    {
      "id": "https://openalex.org/A2550677807",
      "name": "Nand Chandravadia",
      "affiliations": [
        "University of California, Los Angeles"
      ]
    },
    {
      "id": "https://openalex.org/A2555501955",
      "name": "Dustin Roberts",
      "affiliations": [
        "University of California, Los Angeles"
      ]
    },
    {
      "id": "https://openalex.org/A108748537",
      "name": "Nader Pouratian",
      "affiliations": [
        "University of California, Los Angeles"
      ]
    },
    {
      "id": "https://openalex.org/A1972219705",
      "name": "William Speier",
      "affiliations": [
        "University of California, Los Angeles"
      ]
    },
    {
      "id": "https://openalex.org/A2490417413",
      "name": "Aniket Deshpande",
      "affiliations": [
        "University of California, Los Angeles"
      ]
    },
    {
      "id": "https://openalex.org/A2606861999",
      "name": "Lucy Cui",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2550677807",
      "name": "Nand Chandravadia",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2555501955",
      "name": "Dustin Roberts",
      "affiliations": [
        "University of California, Los Angeles"
      ]
    },
    {
      "id": "https://openalex.org/A108748537",
      "name": "Nader Pouratian",
      "affiliations": [
        "University of California, Los Angeles"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2098100592",
    "https://openalex.org/W2129203136",
    "https://openalex.org/W1969136701",
    "https://openalex.org/W2064083411",
    "https://openalex.org/W2039893951",
    "https://openalex.org/W1983194679",
    "https://openalex.org/W2100470503",
    "https://openalex.org/W2160634130",
    "https://openalex.org/W2120535393",
    "https://openalex.org/W2170821486",
    "https://openalex.org/W2032406297",
    "https://openalex.org/W2099784260",
    "https://openalex.org/W2056945694",
    "https://openalex.org/W2080367291",
    "https://openalex.org/W2074711172",
    "https://openalex.org/W2132428916",
    "https://openalex.org/W1968103670",
    "https://openalex.org/W2345353767",
    "https://openalex.org/W7071444332",
    "https://openalex.org/W2073065272",
    "https://openalex.org/W1971102820",
    "https://openalex.org/W1999933362",
    "https://openalex.org/W1963715548",
    "https://openalex.org/W2091605847",
    "https://openalex.org/W2098613108",
    "https://openalex.org/W2253966850",
    "https://openalex.org/W2151669316",
    "https://openalex.org/W2168634541",
    "https://openalex.org/W2093615108",
    "https://openalex.org/W2158655338",
    "https://openalex.org/W2501129673",
    "https://openalex.org/W2159977619",
    "https://openalex.org/W1508165687"
  ],
  "abstract": "The P300 Speller is a common brain-computer interface communication system. There are many parallel lines of research underway to overcome the system's low signal to noise ratio and thereby improve performance, including using famous face stimuli and integrating language information into the classifier. While both have been shown separately to provide significant improvements, the two methods have not yet been implemented together to demonstrate that the improvements are complimentary. The goal of this study is therefore twofold. First, we aim to compare the famous faces stimulus paradigm with an existing alternative stimulus paradigm currently used in commercial systems (i.e., character inversion). Second, we test these methods with language model integration to assess whether different optimization approaches can be combined to further improve BCI communication. In offline analysis using a previously published particle filter method, famous faces stimuli yielded superior results to both standard and inverting stimuli. In online trials using the particle filter method, all 10 subjects achieved a higher selection rate when using the famous faces flashing paradigm than when using inverting flashes. The improvements achieved by these methods are therefore complementary and a combination yields superior results to either method implemented individually when tested in healthy subjects.",
  "full_text": "RESEA RCH ARTICL E\nA comparison of stimulus types in online\nclassification of the P300 speller using\nlanguage models\nWilliam Speier\n1\n, Aniket Deshpande\n2\n, Lucy Cui\n3\n, Nand Chandravadia\n3\n, Dustin Roberts\n1\n,\nNader Pouratian\n1,2,3,4\n*\n1 Department of Neurosurg ery, University of California, Los Angeles, Los Angeles, CA, United States of\nAmerica, 2 Department of Bioengine ering, University of Californi a, Los Angeles , Los Angeles , CA, United\nStates of America, 3 Neuroscience Interde partmental Program , University of Californi a, Los Angele s, Los\nAngeles , CA, United States of America, 4 Brain Researc h Institute, University of California, Los Angeles, Los\nAngeles , CA, United States of America\n* npouratian@ mednet.ucla .edu\nAbstract\nThe P300 Speller is a common brain-computer interface communication system. There are\nmany parallel lines of research underway to overcome the system’s low signal to noise ratio\nand thereby improve performance, including using famous face stimuli and integrating lan-\nguage information into the classifier. While both have been shown separately to provide signifi-\ncant improvements, the two methods have not yet been implemented together to demonstrate\nthat the improvements are complimentary. The goal of this study is therefore twofold. First, we\naim to compare the famous faces stimulus paradigm with an existing alternative stimulus para-\ndigm currently used in commercial systems (i.e., character inversion). Second, we test these\nmethods with language model integration to assess whether different optimization approaches\ncan be combined to further improve BCI communica tion. In offline analysis using a previously\npublished particle filter method, famous faces stimuli yielded superior results to both standard\nand inverting stimuli. In online trials using the particle filter method, all 10 subjects achieved a\nhigher selection rate when using the famous faces flashing paradigm than when using invert-\ning flashes. The improvements achieved by these methods are therefore complementary and\na combinatio n yields superior results to either method implemented individually when tested in\nhealthy subjects.\n1 Introduction\nThe P300 Speller is a common brain-computer interface (BCI) system that provides a means\nof communication for patients with high brain stem injuries or motor neuron diseases such as\namyotrophic lateral sclerosis (ALS) [1]. The system relies on electroencephalogram (EEG)\ndetection of evoked responses to rare target stimuli to identified intended letters for communi-\ncation. Because the signal to noise ratio (SNR) is low, several trials must be combined in order\nto correctly classify responses. The resulting typing speed can therefore be slow, prompting\nmany studies focused on system optimization. Approaches include varying the grid size [2–4],\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.01753 82 April 13, 2017 1 / 11\na1111111111\na1111111111\na1111111111\na1111111111\na1111111111\nOPEN ACCESS\nCitation: Speier W, Deshpan de A, Cui L,\nChandravadi a N, Roberts D, Pouratian N (2017) A\ncomparison of stimulu s types in online\nclassification of the P300 speller using language\nmodels. PLoS ONE 12(4): e0175382. https://do i.\norg/10.1371 /journal.pone. 0175382\nEditor: Mikhail A. Lebede v, Duke University,\nUNITED STATES\nReceived: August 6, 2016\nAccepted: March 6, 2017\nPublished: April 13, 2017\nCopyright: © 2017 Speier et al. This is an open\naccess article distributed under the terms of the\nCreative Commons Attribution License, which\npermits unrestricte d use, distribu tion, and\nreproduction in any medium, provided the original\nauthor and source are credited.\nData Availabilit y Statement: Data are available\nfrom the Dataverse database: https://d ataverse.\nharvard.edu /dataset.xhtml?p ersistentId= doi:10.\n7910/DVN /PHHHB6.\nFunding: This work was supported by the Nationa l\nInstitute of Biomedic al Imaging and Bioenginee ring\nAward Number K23EB014326 (NP) and the UCLA\nScholars in Translation al Medicine Program (NP).\nCompeting interests : The authors have declared\nthat no competing interests exist.\noptimizing interstimulus interval (ISI) [5,6], and adopting different signal processing methods\n[7–10].\nOne active area of research has been to modify the type of visual stimulus used. In the origi-\nnal system, the character grid is gray and the intensified characters are changed to white. How-\never, other types of visual stimuli could potentially elicit stronger P300 or other stimulus evoked\nresponses and several studies have aimed to show superior flashing methods by using character\nmotion [11], modifying character size and sharpness [11], changing stimulus colors [12], vary-\ning the grid layout [13], or increasing stimulus contrast [14]. The most successful stimulus to\ndate has been the presentation of “famous faces” [15]. In this system, stimuli consist of overlay-\ning characters with images of a famous face. This method is based on previous findings that face\nrecognition has been found to elicit two evoked responses in addition to the P300: the N170\nand N400f [16]. By incorporating face images, the response signals elicited are more salient,\nleading to a reduction in the number of stimuli required for perfect accuracy by over 45%,\ngreatly improving typing speed [15]. While the improvement using “famous faces” was signifi-\ncant over the traditional system, to our knowledge it has not been compared to other alternative\nstimuli. Moreover, while it has been validated online [17], it was only using a traditional classi-\nfier and does not reflect the true performance of an online BCI system using state of the art clas-\nsification methods.\nSeparately, recent work has involved the incorporation of language information into the sig-\nnal classifier [18]. This movement in BCI research integrates knowledge about the domain of\nnatural language to improve classification, similar to methods used in other domains such as\nspeech recognition [19]. Several BCI studies have shown incremental improvements in system\nspeed and accuracy using n-gram language models, first using naïve Bayes [20,21] and later\nusing a partially observable Markov decision process [22] and a hidden Markov model [23,24].\nRecently, a particle filter (PF) algorithm was introduced which allowed for the use of more com-\nplicated language models to further improve results [25]. This method approximates distribu-\ntions by projecting samples through a state-space language model based on the observed EEG\nsignals [26]. The system then determines the most likely output by finding the state that attracts\nthe highest number of samples. In offline trials, this method yielded an increase in typing speed\nfrom 5.87 characters/minute to 8.70 characters/minute over a system without language model\nintegration.\nWhile both famous faces stimuli and language model integration have been shown separately\nto provide significant improvements, the two methods have not yet been implemented together\nto demonstrate that the improvements are complimentary. It is conceivable, for instance, that\nSNR could be improved to the point where perfect classification would be possible from the sig-\nnal alone and adding a bias based on prior knowledge would not provide any benefit. It is neces-\nsary to test these methods together in order to verify that the combination is indeed better than\nthe individual components.\nThe goal of this study is therefore twofold. First, we aim to compare the famous faces stimu-\nlus paradigm with an existing alternative stimulus paradigm currently used in commercial sys-\ntems such as the Intendix speller (Guger Technologies, Graz, Austria). This comparison is\nnecessary because, while the superiority of the famous faces paradigm over traditional stimuli\nhas been previously established, it has not been compared to other paradigms that are in cur-\nrent use. Second, we will test these methods with language model integration to see if the\nadvances reported in these two research areas can be combined to further improve BCI com-\nmunication. We hypothesized that using famous face stimuli will increase the speed and accu-\nracy of the P300 speller system over other stimulus paradigms and that incorporating both\nfamous face stimuli and a language model classifier will combine to yield superior perfor-\nmance than either method individually.\nStimulus comparison in the P300 speller using language models\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.01753 82 April 13, 2017 2 / 11\n2 Materials and methods\n2.1 Data collection\nAll data was acquired using g.tec amplifiers, active EEG electrodes, and electrode cap (Guger\nTechnologies, Graz, Austria); sampled at 256 Hz, referenced to the left ear; grounded to AF\nZ\n;\nand filtered using a band-pass of 0.1–60 Hz. The electrode set consisted of 32 channels placed\naccording to a previously published configuration (Fpz, Fz, FC1, FCz, FC2, FC4, FC6, C4, C6,\nCP4, CP6, FC3, FC5, C3, C5, CP3, CP5, CP1, P1, Cz, CPz, Pz, POz, CP2, P2, PO7, PO3, O1,\nOz, O2, PO4, PO8) [5]. The system used a 6 × 6 character grid, row and column flashes, and a\nstimulus onset asynchrony of 125 ms (consisting of a 100 ms flash duration and a 25 ms inter-\nstimulus interval). After each stimulus, the next 600 ms of data from each of the 32 channels\nwere used as features for classification.\nThis research was approved by the University of California, Los Angeles institutional\nreview board (IRB), IRB#11–002062. Written consent was obtained from all subjects using\na consent form approved by the IRB. The subjects in this study consisted of 25 healthy vol-\nunteers with normal or corrected to normal vision between the ages of 20 and 35. Fifteen of\nthe subjects participated in a preliminary study comparing the inverting and non-inverting\nparadigms and the remaining 10 used the inverting and famous faces paradigms. For each\nof the stimulus paradigms, the training sessions consisted of three sessions of copy spelling\n10 character phrases each for the inverting and famous faces paradigms. The approaches\nwere counterbalanced across subjects to account for possible order or fatigue effects. In the\nmain experiment, each subject then chose a target phrase to spell in online sessions, during\nwhich the subject had five minutes to spell as much of the phrase as they could using both\nstimulus paradigms. Subjects were instructed not to correct errors and to repeat the phrase\nif they completed it in under five minutes. The training data was then analyzed retrospec-\ntively using three-fold cross-validation to provide an additional offline comparison of\nresults using the two stimulus paradigms when using classifiers with and without a lan-\nguage model.\nBCI2000 was used for data acquisition and online analysis [27]. Offline analysis was per-\nformed using MATLAB (version 8.6.0, MathWorks, Inc, Natick, MA).\n2.2 Interface\nThree stimulus types are compared in this study. The first method is the standard method,\nconsisting of highlighting flashed characters by “intensifying” the font color to white (Fig 1A)\n[1]. The second method is letter inversion, or changing the background to white and the char-\nacter to black (Fig 1B). The third method overlays the character with an image of a face as pro-\nposed by Kaufmann and colleagues (Fig 1C) [15]. As in the Kaufmann study, the image of\nEinstein was used in this method.\n2.3 Classifier\nFeature selection for classification uses stepwise linear discriminant analysis (SWLDA), a clas-\nsification algorithm that selects a set of signal features using ordinary least-squares regression\n[23]. It iteratively adds significant features and removes the least significant features until\neither the target number of features is met or a state is reached where no features are added or\nremoved [10]. A score, y\nt\n, for a stimulus response is then determined by taking the dot product\nof the feature vector with the associated EEG signal. Using the score means and variances for\ntarget (μ\na\nand s\n2\na\n) and non-target (μ\nn\nand s\n2\nn\n) signals, the likelihood of a signal given a target\nStimulus comparison in the P300 speller using language models\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.01753 82 April 13, 2017 3 / 11\ncharacter, x\nt\n, can be determined [21]:\npðy\nt\njx\nt\nÞ /\nY\ni\nf ðy\ni\nt\njx\nt\nðLÞ\nÞ\nwhere\nf y\ni\nt\njx\nt\n\u0000 \u0001\n¼\n1\nﬃﬃﬃﬃﬃﬃﬃﬃﬃ ﬃ\n2ps\n2\na\np e\n\u0000\n1\n2s\n2\na\nðy\ni\nt\n\u0000 m\na\nÞ\n2\nif x\nt\ncontains target\n1\nﬃﬃﬃﬃﬃﬃﬃﬃﬃ ﬃ\n2ps\n2\nn\np e\n\u0000\n1\n2s\n2\nn\nðy\ni\nt\n\u0000 m\nn\nÞ\n2\nif x\nt\ndoes not contain target\n8\n>\n>\n>\n>\n>\n>\n>\n<\n>\n>\n>\n>\n>\n>\n>\n:\nThe PF method combines these likelihood probabilities with prior knowledge about lan-\nguage structure to decide the optimal character given the observed signal by estimating the\nprobability distribution over possible outputs [26]. This distribution is created by sampling a\nbatch of possible realizations of the model called particles, which move through states in the\nlanguage model independently, based on transition probabilities. After each character selec-\ntion, particles are resampled based on weights derived from observed EEG responses, effec-\ntively removing low probability realizations and replacing them with more likely realizations.\nThe algorithm then estimates a probability distribution over the possible output strings by\ncomputing a histogram of the particles after they have moved through the model.\nFig 1. Screensho ts of a stimulus presentat ion using Non-Invertin g (a), Inverting (b), and Famous Faces (c). In the experime nt, an image of\nEinstein was used for the famous faces paradigm , which is replaced here with an image of one of the authors due to print license. The individual pictured\nhas given written informed consent (as outlined in the PLOS consent form) to publish their image.\nhttps://d oi.org/10.1371/j ournal.pon e.0175382.g0 01\nStimulus comparison in the P300 speller using language models\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.01753 82 April 13, 2017 4 / 11\nWhen a user begins using the system, a set of P particles is generated with an empty history\nand a weight equal to 1/P. At the start of a new character t, a sample x\n0:t−1\nis drawn for each\nparticle, j, from the proposal distribution defined by the language model’s transition probabili-\nties from the particle’s history, x\n0:t−1\n(j)\n.\nx\n0:t\nðjÞ\n\u0018 pðx\n0:t\njx\n0:t \u0000 1\nðjÞ\nÞ\nWhere p(x\n0:t\n|x\n0:t−1\n) is defined from the language model by finding the frequency of occurrence\nof substrings in an underlying corpus:\np x\n0:t\njx\n0:t \u0000 1\nð Þ ¼\ncðx\n0\n; . . . ; x\nt \u0000 1\n; x\nt\nÞ\ncðx\n0\n; . . . ; x\nt \u0000 1\nÞ\nwhere c(x\n0\n,. . .,x\nt−1\n,x\nt\n) refers to the number of times a word occurs in the corpus that begins\nwith the string\n0\nx\n0\n,. . .,x\nt−1\n,x\nt\n0\n. When a particle transitions between states, its history, x\n0:t\n(j)\n, is\nstored to represent the output character sequence associated with that particle. After each stim-\nulus response, the probability weight is computed for each of the particles\nw\nt\nðjÞ\n/ pðy\nt\njx\nt\nðjÞ\nÞ /\nY\ni\nf ðy\ni\nt\njx\nt\nðjÞ\nÞ\nThe weights are then normalized and the probability of the current character is found by\nsumming the weights of all particles that end in that character.\npðx\n0:t\njy\n1:t\nÞ ¼\nX\nk\nw\nt\nðkÞ\nd\nx\nt\nðkÞ\nx\nt\nwhere δ is the Kronecker delta. A new batch of particles, x\nt\n\u0003\n, are then sampled from the current\nparticles, x\nt\n, based on the weight distribution, w\nt\n. Each of the new particles are then assigned\nan equal weight w\nt\n\u0003\n(j)\n= 1/P. The subject then moves on to the next character and the process\nthen repeats with the new batch of particles.\nDynamic classification was implemented by setting a threshold probability to determine\nwhen a decision should be made. The program flashed characters until either the probability\nof at least one character reaches the threshold or the number of flashes reached the maximum\n(120). The classifier then selected the character that satisfied has the highest probability. In off-\nline analysis, the speeds, accuracies, and CCPMs were found for threshold probability values\nbetween 0 and 1 in increments of 0.01 and the threshold that maximized CCPM was chosen\nfor each subject. This optimization was impractical for online experiments, so a previously\nreported value of 0.95 was used for all trials [24].\n2.4 Evaluation\nEvaluation of a BCI system must take into account two factors: the ability of the system to\nachieve the desired result and the amount of time required to reach that result. The efficacy of\nthe system can be measured as the selection accuracy, which we defined as the percentage of\ncharacters in the final output that matched the target string. The speed of the system was mea-\nsured using the selection rate (SR), the inverse of the average time required to make a selection.\nAs there is a tradeoff between speed and accuracy, a metric is needed which takes both into\naccount. Traditionally, BCI systems use information transfer rate (ITR), which calculates the\namount of information conveyed in a system’s output, taking into account the accuracy and\nthe number of possible selections [28]. However, this metric makes several assumptions that\nare not valid in a natural language communication system, including lack of memory between\nselections, uniform probability of selection across all characters, and a uniform distribution of\nStimulus comparison in the P300 speller using language models\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.01753 82 April 13, 2017 5 / 11\nerrors [29,30]. We include ITR here for context across existing P300 speller results, but focus\ninstead on a simpler metric consisting of the number of correctly selected characters per min-\nute (CCPM), discarding incorrect selections. Significance for all values was tested using Wil-\ncoxon signed-rank tests.\n3 Results\n3.1 Offline performance\nIn the preliminary experiment comparing traditional and inverted stimuli, subjects achieved\nsignificantly higher typing speeds (10.68 characters/minute versus 9.48 characters/minute)\nwith comparable accuracy (93.39% versus 92.13%) when using inverted stimuli. The main\nexperiment therefore compared performance using inverted and famous faces stimuli. In off-\nline analysis without feedback, two classifiers were used: the standard SWLDA method and the\nPF method, both with dynamic stopping (Table 1, Fig 2). Using the combination of famous\nfaces and particle filtering classification, there was an average selection rate of 11.97 characters\nper minute across all subjects, which was significantly higher than those achieved by famous\nfaces with SWLDA (9.78 characters/minute, p = 0.0004) or letter inversion with particle filter-\ning (10.34 characters/minute, p = 0.01). Although the average accuracy achieved by the combi-\nnation was slightly higher (96.00%) than either of the individual methods (95.00% and 91.67%\nfor famous faces and particle filtering, respectively), accuracy was not significantly different\nbetween the three analyses. Overall, the combination of particle filtering yielded an average\nCCPM of 11.49 characters/min across subjects with all subjects having a value over nine cor-\nrect characters per minute. This performance was significantly better than that achieved using\neither famous faces with SWLDA (9.31 chracters/min, p = 0.001) or inverted flashing with par-\nticle filtering (9.46 characters/min, p = 0.0003) with nine of the ten subjects having the highest\nperformance using the combined method.\n3.2 Online performance\nIn online experiments, only the PF classifier was used. All 10 subjects were able to type charac-\nters with at least 60% accuracy using each of the flashing paradigms (Table 2, Fig 3). Using the\ninverting method, nine of the 10 subjects achieved at least 75% accuracy and 6 characters per\nminute. Using the FF method, all subjects selected characters with at least 75% accuracy, with\nTable 1. Optimal selectio n rates, accuraci es, and correct characte rs per minute (CCPM ) for the 10 subjects in offline trials using the inverted (Inv)\nand famous faces (FF) flashing paradig ms with either the SWLD A or particle filtering (PF) classifiers with dynamic stopping.\nSR (selections /min) ACC (%) CCPM (characte rs/min)\nSubject Inv-PF FF-SWL DA FF-PF Inv-PF FF-SWLDA FF-PF Inv-PF FF-SWL DA FF-PF\nP 13.36 11.07 12.95 90.00 100.00 100.00 12.02 11.07 12.95\nQ 10.64 10.29 11.70 96.67 90.00 100.00 10.29 9.26 11.70\nR 12.58 10.88 13.35 86.67 96.67 96.67 10.90 10.51 12.90\nS 8.21 9.39 11.57 96.67 96.67 100.00 7.93 9.07 11.57\nT 8.30 9.21 11.61 70.00 80.00 90.00 5.81 7.37 10.45\nU 12.09 9.57 12.94 96.67 96.67 96.67 11.69 9.26 12.51\nV 9.96 11.61 11.75 100.00 100.00 100.00 9.96 11.61 11.75\nW 8.91 7.81 10.79 96.67 93.33 93.33 8.61 7.29 10.07\nX 11.53 9.81 10.06 83.33 100.00 93.33 9.61 9.81 9.39\nY 7.83 8.13 12.95 100.00 96.67 90.00 7.83 7.86 11.65\nAverage 10.34 9.78 11.97 91.67 95.00 96.00 9.46 9.31 11.49\nhttps://do i.org/10.1371/j ournal.pone .0175382.t001\nStimulus comparison in the P300 speller using language models\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.01753 82 April 13, 2017 6 / 11\nseven of 10 subjects having accuracies over 98%. All but one of the subjects had typing speeds\nover 10 characters per minute using the famous faces flashing paradigm.\nAll 10 subjects achieved a higher bit rate when using the famous faces flashing paradigm\nthan when using inverting flashes. On average, subjects selected 8.45 characters per minute\nwith 85.49% accuracy, resulting in an average bit rate of 33.86 bits/minute using inverting\nflashes. When using the famous faces paradigm, subjects achieved significant improvements\nwith an average selection rate of 11.16 characters/minute (32.0% improvement, p = 0.0005), an\naverage accuracy of 94.21% (p = 0.02), CCPM of 10.56 (44.1% improvement, p<0.0001), and\nan average bit rate of 52.27 bits/minute (54.4% improvement, p = 0.0001).\n4 Discussion\nWhile there are many active areas of research in improving the P300 speller, relatively little\nwork has been done to combine these improvements. Some of these methods could be mutu-\nally exclusive, such as the stimulus presentation pattern presented by Jin et al. [4] and the\ncheckerboard paradigm developed by Townsend et al. [31]. Others, however, can be imple-\nmented together, which can potentially produce superior results to either method used\nFig 2. Box plots of the optimal selecti on rates, accuracies , and correct characters per minute (CCPM ) for offline trials using the inverted\n(Inv) and famous faces (FF) flashing paradig ms with either the SWLDA or particle filtering (PF) classifiers with dynamic stopping.\nhttps://do i.org/10.1371/j ournal.pon e.0175382.g0 02\nTable 2. Online select ion rates, accuracies , and correct characters per minute (CCPM ) for each subject using the inverted and famous faces flash-\ning paradigms with the particle filtering classif ier.\nSR (selecti ons/min) ACC (%) CCPM (character s/min)\nSubjec t Inv-PF FF-PF Inv-PF FF-PF Inv-PF FF-PF\nP 11.02 10.96 98.18 100.00 10.82 10.96\nQ 7.36 12.20 75.00 100.00 5.52 12.20\nR 9.96 11.90 85.71 100.00 8.54 11.90\nS 6.44 11.66 100.00 89.58 6.44 10.44\nT 5.70 9.03 61.90 80.77 3.53 7.30\nU 10.00 10.45 79.59 100.00 7.96 10.45\nV 11.14 12.78 90.38 100.00 10.07 12.78\nW 6.27 10.62 77.42 75.47 4.86 8.01\nX 9.27 11.63 97.83 98.25 9.07 11.42\nY 7.38 10.34 88.89 98.04 6.56 10.14\nAverage 8.45 11.16 85.49 94.21 7.33 10.56\nhttps://do i.org/10.1371/j ournal.pone .0175382.t002\nStimulus comparison in the P300 speller using language models\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.01753 82 April 13, 2017 7 / 11\nindividually. Developing a viable system for ALS patient communication will require utilizing\nmany of the improvements that have been developed and it is important that we explore how\nthese components will work together in a final product.\nHere, we have demonstrated the performance of the P300 speller when implementing\nfamous faces flashing with a language model-based signal classifier. All subjects achieved their\nbest online performance using the combination of famous faces with the PF classifier. In off-\nline experiments, the improvements were largely a result of a reduction of the number of sti-\nmuli required to achieve a similar accuracy. When using the particle filter, the addition of\nfamous faces stimuli increased the selection rate from 10.34 characters/minute to 11.97 charac-\nters/minute, an equivalent of reducing the number of flashes by 52%, which is in line with pre-\nviously published reduction of 45% for famous faces without language modeling [15].Using\nfamous face stimuli with a traditional classifier and using standard flashing with the PF classi-\nfier achieved similar results, both of which were substantially higher in terms of selection rate\nthan previously published results using standard methods, which were on the order of 6.5\ncharacters/minute [21]. Combining the methods resulted in the best offline performance for\nall but one subject. The majority of subjects had worse offline performance using standard\nflashing compared to inverted stimuli, although famous faces stimuli yield superior results to\neither alternative method.\nThere was a decrease in online performance compared to offline analysis, with lower aver-\nage typing speeds and accuracies for each flashing paradigm. In both cases, the difference was\nmainly a result of increased selection rate as the accuracy did not significantly differ (p = 0.07\nand p = 0.25 for inverted and famous faces flashing, respectively). A similar decrease was seen\npreviously when using language model-based classifiers in an online setting [26]. This decrease\ncould have been caused by the optimization of the probability threshold for each subject in the\noffline trials. Differences could also have been affected by the target sentence chosen by the\nusers in online trials. Because offline analysis was performed on the training data, all subjects\nhad the same target sentence and therefore benefitted from the language model equally. In\nonline trials, subjects were allowed to choose their own text for free spelling. Sentences that\ncontain words that are common in the language model would have higher prior probabilities,\nresulting in faster speeds as fewer stimulus responses would be needed for the classifier to\nreach a decision. Conversely, sentences that are not likely in the language model will have a\nbias against them and will therefore take longer and are more likely to contain errors. In a\nFig 3. Box plots of the online selection rates, accuracies , and correct characte rs per minute (CCPM) for each subject using the inverted and\nfamous faces flashing paradigm s with the particle filtering classifier.\nhttps://doi.org/10 .1371/journal.p one.0175382. g003\nStimulus comparison in the P300 speller using language models\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.01753 82 April 13, 2017 8 / 11\nrealistic system, language models can be individually tailored to reflect text that patients are\nmore likely to type, resulting in further improved results.\n4.1 Limitations and future directions\nThe current study was conducted only using healthy volunteers and their performance might\nnot accurately reflect the performance of “locked-in” patients due to additional restrictions\nsuch as a lack of gaze control. The PF algorithm will likely have a similar effect in classifying\nsignals from the target population as it is simply a means for improving speed and accuracy\nand does not affect the appearance of the system for the user. Famous faces stimuli have inde-\npendently been validated in the target population [17], so it is reasonable to expect the combi-\nnation of the methods to show an improvement for the target population. Nevertheless, this\nexpectation needs to be tested in a study in the patient population to verify that these improve-\nments will translate into a better system for end users.\n5 Conclusion\nFamous faces stimuli and language model based classification have both been previously\nshown to greatly improve performance of BCI communication systems. Here, we have shown\nthat the improvements achieved by these methods are complementary and that combining\nthem yields superior results to either method implemented individually in terms of typing\nspeed and information transfer rate. This result has been validated in both online and offline\nexperimental settings. We have also demonstrated that famous faces stimuli are superior to\ninverted stimuli in addition to standard character intensifications.\nAcknowledgmen ts\nThis work was supported by the National Institute of Biomedical Imaging and Bioengineering\nAward Number K23EB014326 (NP) and the UCLA Scholars in Translational Medicine Pro-\ngram (NP).\nAuthor Contributions\nConceptualization: NP WS AD.\nData curation: WS AD LC NC DR.\nFormal analysis: WS.\nFunding acquisition: NP.\nInvestigation: WS AD LC NC DR.\nMethodology: NP WS AD LC.\nProject administration: WS.\nResources: NP.\nSoftware: WS.\nSupervision: NP WS.\nValidation: WS NC DR.\nWriting – original draft: WS AD.\nWriting – review & editing: WS AD LC NC DR NP.\nStimulus comparison in the P300 speller using language models\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.01753 82 April 13, 2017 9 / 11\nReferences\n1. Farwell LA, Donchin E. Talking off the top of your head: toward a mental prosthesis utilizing event-\nrelated brain potentials . Electroence phalogr Clin Neuroph ysiol. 1988; 70: 510–523. PMID: 246128 5\n2. Sellers EWE, Krusien ski DJDJ, McFarland DJ, Vaughan TM, Wolpaw JR. A P300 event-r elated poten-\ntial brain-com puter interface (BCI): The effects of matrix size and inter stimulus interval on performance .\nBiol Psychol. 2006; 73: 242–25 2. https://doi.or g/10.101 6/j.biopsycho .2006.04 .007 PMID: 168609 20\n3. Townsend G, Shanaha n J, Ryan DB, Sellers EW. A general P300 brain–com puter interface presenta -\ntion paradigm based on performa nce guided constraints. Neurosci Lett. Elsevier ; 2012; 531: 63–68.\nhttps://doi.or g/10.101 6/j.neulet.20 12.08.041 PMID: 229602 61\n4. Jin J, Horki P, Brunner C, Wang X, Neuper C, Pfurtschel ler G. A new P300 stimulus presenta tion pat-\ntern for EEG-ba sed spelling systems. Biomed Tech. 2010; 55: 203–21 0.\n5. Lu J, Speier W, Hu X, Pouratian N. The effects of stimulus timing features on P300 speller perform ance.\nClin Neuroph ysiol. Elsevier; 2013; 124: 306–314. https:// doi.org/10.10 16/j.clinp h.2012.08.0 02 PMID:\n22939456\n6. McFarland DJ, Sarnacki WA, Townsend G, Vaughan T, Wolpaw JR. The P300-bas ed brain-computer\ninterface (BCI): Effects of stimulus rate. Clin Neuroph ysiol. International Federation of Clinical Neuro-\nphysiolog y; 2011; 122: 731–737. https://do i.org/10.1016 /j.clinph.2 010.10.029 PMID: 21067970\n7. Kaper M, Meinick e P, Grosseka thoefer U, Lingne r T, Ritter H. BCI Competition 2003—Da ta Set IIb:\nSupport Vector Machines for the P300 Speller Paradigm. IEEE Trans Biomed Eng. 2004; 50: 1073–\n1076.\n8. Xu N, Gao X, Hong B, Miao X, Gao S, Yang F. BCI Competition 2003—Da ta Set IIb: Enhancing P300\nWave Detection Using ICA-Base d Subspace Projections for BCI Application s. IEEE Trans Biomed Eng.\n2004; 51: 1067–1 072. https://doi.or g/10.110 9/TBME.2 004.826699 PMID: 15188880\n9. Serby H, Yom-Tov E, Inbar GF. An improved P300-based brain-com puter interface. IEEE Trans Neural\nSyst Rehabil Eng. 2005; 13: 89–98. https://d oi.org/10.110 9/TNSR E.2004.84187 8 PMID: 15813410\n10. Krusiens ki DJ, Sellers EW, Cabest aing F, Bayoudh S, McFarland DJ, Vaughan TM, et al. A comparison\nof classific ation technique s for the P300 Speller. J Neural Eng. 2006; 3: 299–305 . https://doi.or g/10.\n1088/1741-2 560/3/4/0 07 PMID: 171243 34\n11. Liu Y, Zhou Z, Hu D. Comparison of stimulus types in visual P300 speller of brain-comput er interfa ces.\nCognitive Informatics (ICCI), 2010 9th IEEE Internat ional Conferen ce on. IEEE; 2010. pp. 273–27 9.\n12. Takano K, Komatsu T, Hata N, Nakajima Y, Kansaku K. Visual stimuli for the P300 brain–co mputer\ninterface : a comparison of white/gray and green/blue flicker matrices. Clin Neurophysio l. Elsevier ;\n2009; 120: 1562–1566. https://doi.or g/10.101 6/j.clinph. 2009.06.002 PMID: 19560965\n13. Salvaris M, Sepulveda F. Visual modification s on the P300 speller BCI paradigm. J Neural Eng. IOP\nPublishing; 2009; 6: 46011.\n14. Li Y, Bahn S, Nam CS, Lee J. Effects of luminosity contrast and stimulus duration on user performance\nand preference in a P300-base d brain–com puter interface . Int J Hum Comp ut Interact. Taylor & Francis;\n2014; 30: 151–16 3.\n15. Kaufman n T, Schulz SM, Gru ¨ nzinger C, Ku ¨ bler A. Flashing character s with famous faces improves\nERP-bas ed brain–com puter interface perform ance. J Neural Eng. IOP Publishing; 2011; 8: 56016.\n16. Eimer M. Event-relate d brain potentials distinguish processing stages involved in face perception and\nrecognition. Clin Neuroph ysiol. Elsevier ; 2000; 111: 694–705. PMID: 1072792 1\n17. Kaufman n T, Schulz SM, Ko ¨ blitz A, Renner G, Wessig C, Ku ¨ bler A. Face stimuli effectively prevent\nbrain–com puter interface inefficien cy in patients with neurodegen erative disease. Clin Neuroph ysiol.\n2013; 124: 893–900. https://doi.or g/10.101 6/j.clinph.2 012.11.006 PMID: 232464 15\n18. Speier W, Arnold C, Pouratian N. Integra ting language models into classifiers for BCI communic ation: a\nreview. J Neural Eng. IOP Publishing; 2016; 13: 31002.\n19. Jelinek F. Statistical methods for speech recognition. MIT Press; 1998.\n20. Kindermans P-J, Verschore H, Schrauwe n B. A Unified Probabilistic Approach to Improve Spelling in\nan Event-Rel ated Potentia l-Based Brain–Com puter Interface. Biomed Eng IEEE Trans. IEEE; 2013;\n60: 2696–270 5.\n21. Speier W, Arnold C, Lu J, Taira RK, Pouratian N. Natural language process ing with dynamic classif ica-\ntion improves P300 speller accuracy and bit rate. J Neural Eng. 2011; 9: 16004.\n22. Park J, Kim K-E. A POMDP approac h to optimizing P300 speller BCI paradigm. Neural Syst Rehabil\nEng IEEE Trans. IEEE; 2012; 20: 584–594.\n23. Speier W, Knall J, Pouratian N. Unsupervis ed training of brain-comput er interface systems using expec-\ntation maximi zation. Neural Engineeri ng (NER), 2013 6th International IEEE/EM BS Conferen ce on.\nIEEE; 2013. pp. 707–710.\nStimulus comparison in the P300 speller using language models\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.01753 82 April 13, 2017 10 / 11\n24. Speier W, Arnold C, Lu J, Deshpande A, Pouratian N. Integra ting language information with a hidden\nmarkov model to improve commu nication rate in the P300 speller. IEEE Trans Neural Syst Rehabil\nEng. 2014; 22: 678–684. https://doi.or g/10.110 9/TNSRE.20 14.2300091 PMID: 247609 27\n25. Gordon NJ, Salmond DJ, Smith AFM. Novel approach to nonlinear/n on-Gaus sian Bayesian state esti-\nmation. IEE Proceedings F (Radar and Signal Processin g). IET; 1993. pp. 107–113.\n26. Speier W, Arnold CW, Deshpande A, Knall J, Pouratian N. Incorpor ating advanced language models\ninto the P300 speller using particle filtering. J Neural Eng. 2015; 12: 46018.\n27. Schalk G, McFarland DJ, Hinterberger T, Birbaum er N, Wolpaw JR. BCI2000: a general-p urpose brain-\ncomputer interface (BCI) system. IEEE Trans Biomed Eng. 2004; 51: 1034–1043. https://doi.or g/10.\n1109/TBM E.2004.827 072 PMID: 15188875\n28. Pierce JR. An Introducti on to Informatio n Theory. Dover; 1980.\n29. Fatourech i M, Mason SG, Birch GE, Ward RK. Is informati on transfer rate a suitable performanc e mea-\nsure for self-paced brain interface systems ? Signal Processin g and Informatio n Technolo gy, 2006 IEEE\nInternational Sympos ium on. IEEE; 2006. pp. 212–216.\n30. Speier W, Arnold C, Pouratian N. Evaluati ng True BCI Communic ation Rate through Mutual Informatio n\nand Language Models. PLoS One. 2013; 8: e78432. https://doi. org/10.1371/j ournal.pone .007843 2\nPMID: 241676 23\n31. Townsend G, LaPallo BK, Boulay CB, Krusiens ki DJ, Frye GE, Hauser CK, et al. A novel P300-bas ed\nbrain-com puter interface stimulus presenta tion paradigm : Moving beyond rows and columns. Clin Neu-\nrophysiol . International Federation of Clinical Neuroph ysiology; 2010; 121: 1109–1120. https://d oi.org/\n10.1016/ j.clinph.2010.0 1.030 PMID: 20347387\nStimulus comparison in the P300 speller using language models\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.01753 82 April 13, 2017 11 / 11",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7183895111083984
    },
    {
      "name": "Brain–computer interface",
      "score": 0.6745047569274902
    },
    {
      "name": "Stimulus (psychology)",
      "score": 0.5965304374694824
    },
    {
      "name": "Speech recognition",
      "score": 0.5383836030960083
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4714459180831909
    },
    {
      "name": "Classifier (UML)",
      "score": 0.43667250871658325
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.3721655607223511
    },
    {
      "name": "Electroencephalography",
      "score": 0.17412948608398438
    },
    {
      "name": "Psychology",
      "score": 0.13948622345924377
    },
    {
      "name": "Neuroscience",
      "score": 0.12887215614318848
    },
    {
      "name": "Cognitive psychology",
      "score": 0.12215805053710938
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I161318765",
      "name": "University of California, Los Angeles",
      "country": "US"
    }
  ],
  "cited_by": 29
}