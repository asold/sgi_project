{
  "title": "Evaluating large language models for drafting emergency department encounter summaries",
  "url": "https://openalex.org/W4411359311",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2995843509",
      "name": "Christopher Y. K. Williams",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2786617309",
      "name": "Jaskaran Bains",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2109605985",
      "name": "Tianyu Tang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2114913489",
      "name": "Kishan Patel",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2945272814",
      "name": "Alexa N. Lucas",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2671097329",
      "name": "Fiona Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4316189112",
      "name": "Brenda Y. Miao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A284454978",
      "name": "Atul J. Butte",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2696559489",
      "name": "Aaron E. Kornblith",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2467236557",
    "https://openalex.org/W4281989098",
    "https://openalex.org/W2984982467",
    "https://openalex.org/W2890157215",
    "https://openalex.org/W2515682654",
    "https://openalex.org/W3005890082",
    "https://openalex.org/W4387393114",
    "https://openalex.org/W3023680935",
    "https://openalex.org/W3127725882",
    "https://openalex.org/W2132643104",
    "https://openalex.org/W2751958615",
    "https://openalex.org/W2770750122",
    "https://openalex.org/W1514648103",
    "https://openalex.org/W4389178822",
    "https://openalex.org/W4386120650",
    "https://openalex.org/W4392193048",
    "https://openalex.org/W4386272371",
    "https://openalex.org/W4391995913",
    "https://openalex.org/W4383223222",
    "https://openalex.org/W2086519542",
    "https://openalex.org/W4410090070",
    "https://openalex.org/W4396691546",
    "https://openalex.org/W4386865118",
    "https://openalex.org/W4389046946",
    "https://openalex.org/W2139056371",
    "https://openalex.org/W4392800721",
    "https://openalex.org/W4389917881"
  ],
  "abstract": "Large language models (LLMs) possess a range of capabilities which may be applied to the clinical domain, including text summarization. As ambient artificial intelligence scribes and other LLM-based tools begin to be deployed within healthcare settings, rigorous evaluations of the accuracy of these technologies are urgently needed. In this cross-sectional study of 100 randomly sampled adult Emergency Department (ED) visits from 2012 to 2023 at the University of California, San Francisco ED, we sought to investigate the performance of GPT-4 and GPT-3.5-turbo in generating ED encounter summaries and evaluate the prevalence and type of errors for each section of the encounter summary across three evaluation criteria: 1) Inaccuracy of LLM-summarized information; 2) Hallucination of information; 3) Omission of relevant clinical information. In total, 33% of summaries generated by GPT-4 and 10% of those generated by GPT-3.5-turbo were entirely error-free across all evaluated domains. Summaries generated by GPT-4 were mostly accurate, with inaccuracies found in only 10% of cases, however, 42% of the summaries exhibited hallucinations and 47% omitted clinically relevant information. Inaccuracies and hallucinations were most commonly found in the Plan sections of LLM-generated summaries, while clinical omissions were concentrated in text describing patients’ Physical Examination findings or History of Presenting Complaint. The potential harmfulness score across errors was low, with a mean score of 0.57 (SD 1.11) out of 7 and only three errors scoring 4 (‘Potential for permanent harm’) or greater. In summary, we found that LLMs could generate accurate encounter summaries but were liable to hallucination and omission of clinically relevant information. Individual errors on average had a low potential for harm. A comprehensive understanding of the location and type of errors found in LLM-generated clinical text is important to facilitate clinician review of such content and prevent patient harm.",
  "full_text": null,
  "topic": "Emergency department",
  "concepts": [
    {
      "name": "Emergency department",
      "score": 0.7183823585510254
    },
    {
      "name": "Automatic summarization",
      "score": 0.5497400164604187
    },
    {
      "name": "Computer science",
      "score": 0.465561181306839
    },
    {
      "name": "Veterans Affairs",
      "score": 0.4606592059135437
    },
    {
      "name": "Psychology",
      "score": 0.383553147315979
    },
    {
      "name": "Artificial intelligence",
      "score": 0.37995070219039917
    },
    {
      "name": "Medicine",
      "score": 0.37943339347839355
    },
    {
      "name": "Natural language processing",
      "score": 0.3335195481777191
    },
    {
      "name": "Applied psychology",
      "score": 0.32352182269096375
    },
    {
      "name": "Psychiatry",
      "score": 0.1833769977092743
    },
    {
      "name": "Internal medicine",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I180670191",
      "name": "University of California, San Francisco",
      "country": "US"
    }
  ],
  "cited_by": 7
}