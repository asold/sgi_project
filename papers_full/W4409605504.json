{
  "title": "Using a Large Language Model for Breast Imaging Reporting and Data System Classification and Malignancy Prediction to Enhance Breast Ultrasound Diagnosis: Retrospective Study",
  "url": "https://openalex.org/W4409605504",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5117217798",
      "name": "Su Miaojiao",
      "affiliations": [
        "Fujian Provincial Hospital",
        "Fuzhou University"
      ]
    },
    {
      "id": "https://openalex.org/A5101082603",
      "name": "Xia Liang",
      "affiliations": [
        "Fujian Provincial Hospital",
        "Fuzhou University"
      ]
    },
    {
      "id": "https://openalex.org/A5063783653",
      "name": "Zong-Yuan Tao",
      "affiliations": [
        "Fujian Provincial Hospital",
        "Fuzhou University"
      ]
    },
    {
      "id": "https://openalex.org/A5100522220",
      "name": "Zhiliang Hong",
      "affiliations": [
        "Fujian Provincial Hospital",
        "Fuzhou University"
      ]
    },
    {
      "id": "https://openalex.org/A5013426840",
      "name": "Sheng Cheng",
      "affiliations": [
        "Fujian Provincial Hospital",
        "Fuzhou University"
      ]
    },
    {
      "id": "https://openalex.org/A5101682845",
      "name": "Songsong Wu",
      "affiliations": [
        "Fujian Provincial Hospital",
        "Fuzhou University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4319301505",
    "https://openalex.org/W4387472906",
    "https://openalex.org/W4385230595",
    "https://openalex.org/W4387472386",
    "https://openalex.org/W4324308091",
    "https://openalex.org/W4380422747",
    "https://openalex.org/W3164654615",
    "https://openalex.org/W4376640725",
    "https://openalex.org/W4367310920",
    "https://openalex.org/W4367175039",
    "https://openalex.org/W4380423243",
    "https://openalex.org/W4383301639",
    "https://openalex.org/W4386865118",
    "https://openalex.org/W3119005666",
    "https://openalex.org/W4386030617",
    "https://openalex.org/W4390116811",
    "https://openalex.org/W4297994753",
    "https://openalex.org/W4385484108",
    "https://openalex.org/W3020186439",
    "https://openalex.org/W3158690277",
    "https://openalex.org/W2900898778",
    "https://openalex.org/W2801665024",
    "https://openalex.org/W3129818373",
    "https://openalex.org/W4380291855",
    "https://openalex.org/W4250945690",
    "https://openalex.org/W4392703844",
    "https://openalex.org/W4367332317",
    "https://openalex.org/W3010519118",
    "https://openalex.org/W4386158494",
    "https://openalex.org/W4386110374"
  ],
  "abstract": "Abstract Background Breast ultrasound is essential for evaluating breast nodules, with Breast Imaging Reporting and Data System (BI-RADS) providing standardized classification. However, interobserver variability among radiologists can affect diagnostic accuracy. Large language models (LLMs) like ChatGPT-4 have shown potential in medical imaging interpretation. This study explores its feasibility in improving BI-RADS classification consistency and malignancy prediction compared to radiologists. Objective This study aims to evaluate the feasibility of using LLMs, particularly ChatGPT-4, to assess the consistency and diagnostic accuracy of standardized breast ultrasound imaging reports, using pathology as the reference standard. Methods This retrospective study analyzed breast nodule ultrasound data from 671 female patients (mean 45.82, SD 9.20 years; range 26‐75 years) who underwent biopsy or surgical excision at our hospital between June 2019 and June 2024. ChatGPT-4 was used to interpret BI-RADS classifications and predict benign versus malignant nodules. The study compared the model’s performance to that of two senior radiologists (≥15 years of experience) and two junior radiologists (&lt;5 years of experience) using key diagnostic metrics, including accuracy, sensitivity, specificity, area under the receiver operating characteristic curve, P values, and odds ratios with 95% CIs. Two diagnostic models were evaluated: (1) image interpretation model, where ChatGPT-4 classified nodules based on BI-RADS features, and (2) image-to-text–LLM model, where radiologists provided textual descriptions, and ChatGPT-4 determined malignancy probability based on keywords. Radiologists were blinded to pathological outcomes, and BI-RADS classifications were finalized through consensus. Results ChatGPT-4 achieved an overall BI-RADS classification accuracy of 96.87%, outperforming junior radiologists (617/671, 91.95% and 604/671, 90.01%, P &lt;.01). For malignancy prediction, ChatGPT-4 achieved an area under the receiver operating characteristic curve of 0.82 (95% CI 0.79‐0.85), an accuracy of 80.63% (541/671 cases), a sensitivity of 90.56% (259/286 cases), and a specificity of 73.51% (283/385 cases). The image interpretation model demonstrated performance comparable to senior radiologists, while the image-to-text–LLM model further improved diagnostic accuracy for all radiologists, increasing their sensitivity and specificity significantly ( P &lt;.001). Statistical analyses, including the McNemar test and DeLong test, confirmed that ChatGPT-4 outperformed junior radiologists ( P &lt;.01) and showed noninferiority compared to senior radiologists ( P &gt;.05). Pathological diagnoses served as the reference standard, ensuring robust evaluation reliability. Conclusions Integrating ChatGPT-4 into an image-to-text–LLM workflow improves BI-RADS classification accuracy and supports radiologists in breast ultrasound diagnostics. These results demonstrate its potential as a decision-support tool to enhance diagnostic consistency and reduce variability.",
  "full_text": null,
  "topic": "BI-RADS",
  "concepts": [
    {
      "name": "BI-RADS",
      "score": 0.8887423276901245
    },
    {
      "name": "Preprint",
      "score": 0.7253099679946899
    },
    {
      "name": "Malignancy",
      "score": 0.6301683187484741
    },
    {
      "name": "Breast imaging",
      "score": 0.5460245609283447
    },
    {
      "name": "Ultrasound",
      "score": 0.4956437349319458
    },
    {
      "name": "Medicine",
      "score": 0.46169671416282654
    },
    {
      "name": "Computer science",
      "score": 0.406052827835083
    },
    {
      "name": "Radiology",
      "score": 0.3728238344192505
    },
    {
      "name": "Mammography",
      "score": 0.3071751296520233
    },
    {
      "name": "Breast cancer",
      "score": 0.25674593448638916
    },
    {
      "name": "Pathology",
      "score": 0.15964606404304504
    },
    {
      "name": "Cancer",
      "score": 0.13077235221862793
    },
    {
      "name": "World Wide Web",
      "score": 0.08294504880905151
    },
    {
      "name": "Internal medicine",
      "score": 0.07051941752433777
    }
  ]
}