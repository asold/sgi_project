{
  "title": "Early or Late Fusion Matters: Efficient RGB-D Fusion in Vision Transformers for 3D Object Recognition",
  "url": "https://openalex.org/W4389667009",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A3171627910",
      "name": "Georgios Tziafas",
      "affiliations": [
        "University of Groningen"
      ]
    },
    {
      "id": "https://openalex.org/A1978199749",
      "name": "Hamidreza Kasaei",
      "affiliations": [
        "University of Groningen"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2752585553",
    "https://openalex.org/W6796761347",
    "https://openalex.org/W2074142320",
    "https://openalex.org/W2911788474",
    "https://openalex.org/W3019632826",
    "https://openalex.org/W1505952289",
    "https://openalex.org/W2963032410",
    "https://openalex.org/W6757384668",
    "https://openalex.org/W2176371886",
    "https://openalex.org/W2108598243",
    "https://openalex.org/W2963956866",
    "https://openalex.org/W4292794834",
    "https://openalex.org/W4386071576",
    "https://openalex.org/W4312372834",
    "https://openalex.org/W6684489972",
    "https://openalex.org/W2789835518",
    "https://openalex.org/W2920456178",
    "https://openalex.org/W6730320844",
    "https://openalex.org/W2788515346",
    "https://openalex.org/W3011972190",
    "https://openalex.org/W4206706211",
    "https://openalex.org/W2156222070",
    "https://openalex.org/W2551737796",
    "https://openalex.org/W6810856158",
    "https://openalex.org/W3138516171",
    "https://openalex.org/W2963011558",
    "https://openalex.org/W2963901718",
    "https://openalex.org/W3040130969",
    "https://openalex.org/W6757817989",
    "https://openalex.org/W3125116114",
    "https://openalex.org/W1884730573",
    "https://openalex.org/W3094488141",
    "https://openalex.org/W6730146409",
    "https://openalex.org/W6794559225",
    "https://openalex.org/W2967153639",
    "https://openalex.org/W2962843773",
    "https://openalex.org/W1591677984",
    "https://openalex.org/W6788135285",
    "https://openalex.org/W1922904362",
    "https://openalex.org/W2207044458",
    "https://openalex.org/W4312633518",
    "https://openalex.org/W2860627718",
    "https://openalex.org/W3157898411",
    "https://openalex.org/W2774550181",
    "https://openalex.org/W2165599843",
    "https://openalex.org/W3170863103",
    "https://openalex.org/W2964189064",
    "https://openalex.org/W2902625698",
    "https://openalex.org/W4281383322",
    "https://openalex.org/W4287203292",
    "https://openalex.org/W3170874841",
    "https://openalex.org/W4386179772"
  ],
  "abstract": "The Vision Transformer (ViT) architecture has established its place in computer vision literature, however, training ViTs for RGB-D object recognition remains an understudied topic, viewed in recent literature only through the lens of multi-task pretraining in multiple vision modalities. Such approaches are often computationally intensive, relying on the scale of multiple pretraining datasets to align RGB with 3D information. In this work, we propose a simple yet strong recipe for transferring pretrained ViTs in RGB-D domains for 3D object recognition, focusing on fusing RGB and depth representations encoded jointly by the ViT. Compared to previous works in multimodal Transformers, the key challenge here is to use the attested flexibility of ViTs to capture cross-modal interactions at the downstream and not the pretraining stage. We explore which depth representation is better in terms of resulting accuracy and compare early and late fusion techniques for aligning the RGB and depth modalities within the ViT architecture. Experimental results in the Washington RGB-D Objects dataset (ROD) demonstrate that in such RGB â†’ RGB-D scenarios, late fusion techniques work better than most popularly employed early fusion. With our transfer baseline, fusion ViTs score up to 95.4% top-1 accuracy in ROD, achieving new state-of-the-art results in this benchmark. We further show the benefits of using our multimodal fusion baseline over unimodal feature extractors in a synthetic-to-real visual adaptation as well as in an open-ended lifelong learning scenario in the ROD benchmark, where our model outperforms previous works by a margin of &gt;8%. Finally, we integrate our method with a robot framework and demonstrate how it can serve as a perception utility in an interactive robot learning scenario, both in simulation and with a real robot.",
  "full_text": null,
  "topic": "RGB color model",
  "concepts": [
    {
      "name": "RGB color model",
      "score": 0.7793095111846924
    },
    {
      "name": "Artificial intelligence",
      "score": 0.7714791893959045
    },
    {
      "name": "Computer science",
      "score": 0.7388757467269897
    },
    {
      "name": "Computer vision",
      "score": 0.6082580089569092
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.5338270664215088
    },
    {
      "name": "Fusion mechanism",
      "score": 0.5136327147483826
    },
    {
      "name": "Transformer",
      "score": 0.4414350390434265
    },
    {
      "name": "Fusion",
      "score": 0.35148561000823975
    },
    {
      "name": "Engineering",
      "score": 0.11932951211929321
    },
    {
      "name": "Lipid bilayer fusion",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Geography",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Linguistics",
      "score": 0.0
    },
    {
      "name": "Geodesy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I169381384",
      "name": "University of Groningen",
      "country": "NL"
    }
  ],
  "cited_by": 16
}