{
  "title": "NMRExtractor: leveraging large language models to construct an experimental NMR database from open-source scientific publications",
  "url": "https://openalex.org/W4410823115",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2653399829",
      "name": "Qinggong Wang",
      "affiliations": [
        "Shanghai Institute of Materia Medica",
        "Nanjing University of Chinese Medicine",
        "Chinese Academy of Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A1506313323",
      "name": "Wei Zhang",
      "affiliations": [
        "Chinese Academy of Sciences",
        "University of Chinese Academy of Sciences",
        "Shanghai Institute of Materia Medica"
      ]
    },
    {
      "id": "https://openalex.org/A2123504080",
      "name": "Mingan Chen",
      "affiliations": [
        "ShanghaiTech University",
        "Chinese Academy of Sciences",
        "Shanghai Institute of Materia Medica"
      ]
    },
    {
      "id": "https://openalex.org/A2153580400",
      "name": "Xutong Li",
      "affiliations": [
        "Shanghai Institute of Materia Medica",
        "University of Chinese Academy of Sciences",
        "Chinese Academy of Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2529916829",
      "name": "Zhaoping Xiong",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2785111141",
      "name": "Jiacheng Xiong",
      "affiliations": [
        "Chinese Academy of Sciences",
        "Shanghai Institute of Materia Medica"
      ]
    },
    {
      "id": "https://openalex.org/A2783203101",
      "name": "Zunyun Fu",
      "affiliations": [
        "ShanghaiTech University"
      ]
    },
    {
      "id": "https://openalex.org/A2120510683",
      "name": "Mingyue Zheng",
      "affiliations": [
        "Shanghai Institute of Materia Medica",
        "Chinese Academy of Sciences",
        "University of Chinese Academy of Sciences",
        "Nanjing University of Chinese Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A2653399829",
      "name": "Qinggong Wang",
      "affiliations": [
        "Chinese Academy of Sciences",
        "Shanghai Institute of Materia Medica",
        "Nanjing University of Chinese Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A1506313323",
      "name": "Wei Zhang",
      "affiliations": [
        "Shanghai Institute of Materia Medica",
        "Chinese Academy of Sciences",
        "University of Chinese Academy of Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2123504080",
      "name": "Mingan Chen",
      "affiliations": [
        "Chinese Academy of Sciences",
        "ShanghaiTech University",
        "Shanghai Institute of Materia Medica"
      ]
    },
    {
      "id": "https://openalex.org/A2153580400",
      "name": "Xutong Li",
      "affiliations": [
        "Chinese Academy of Sciences",
        "University of Chinese Academy of Sciences",
        "Shanghai Institute of Materia Medica"
      ]
    },
    {
      "id": "https://openalex.org/A2529916829",
      "name": "Zhaoping Xiong",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2785111141",
      "name": "Jiacheng Xiong",
      "affiliations": [
        "Chinese Academy of Sciences",
        "Shanghai Institute of Materia Medica"
      ]
    },
    {
      "id": "https://openalex.org/A2783203101",
      "name": "Zunyun Fu",
      "affiliations": [
        "ShanghaiTech University"
      ]
    },
    {
      "id": "https://openalex.org/A2120510683",
      "name": "Mingyue Zheng",
      "affiliations": [
        "Nanjing University of Chinese Medicine",
        "University of Chinese Academy of Sciences",
        "Chinese Academy of Sciences",
        "Shanghai Institute of Materia Medica"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4406085118",
    "https://openalex.org/W4289598671",
    "https://openalex.org/W2177317049",
    "https://openalex.org/W2096541451",
    "https://openalex.org/W2950128007",
    "https://openalex.org/W3206840963",
    "https://openalex.org/W2478815458",
    "https://openalex.org/W2052130353",
    "https://openalex.org/W4386568646",
    "https://openalex.org/W4327568700",
    "https://openalex.org/W3212396168",
    "https://openalex.org/W3215187068",
    "https://openalex.org/W4385808309",
    "https://openalex.org/W2963864542",
    "https://openalex.org/W4387801166",
    "https://openalex.org/W4390880657",
    "https://openalex.org/W4206447491",
    "https://openalex.org/W4310945739",
    "https://openalex.org/W4389976884",
    "https://openalex.org/W1999145583",
    "https://openalex.org/W2312860281",
    "https://openalex.org/W3211728852",
    "https://openalex.org/W2161671078",
    "https://openalex.org/W2297681726",
    "https://openalex.org/W2059529709",
    "https://openalex.org/W2762711363",
    "https://openalex.org/W3104401854",
    "https://openalex.org/W4385027818",
    "https://openalex.org/W4386530347",
    "https://openalex.org/W4391836235",
    "https://openalex.org/W4401173005",
    "https://openalex.org/W4399442007",
    "https://openalex.org/W4391709329",
    "https://openalex.org/W4392921865",
    "https://openalex.org/W4405616956",
    "https://openalex.org/W4392002118",
    "https://openalex.org/W4387635881",
    "https://openalex.org/W4405355411",
    "https://openalex.org/W4406634509",
    "https://openalex.org/W4402953068",
    "https://openalex.org/W4389761608",
    "https://openalex.org/W3094217983",
    "https://openalex.org/W2964864162",
    "https://openalex.org/W3212619479",
    "https://openalex.org/W3135847490",
    "https://openalex.org/W2034354062",
    "https://openalex.org/W1972650279",
    "https://openalex.org/W4389883248",
    "https://openalex.org/W1584530142"
  ],
  "abstract": "NMRExtractor is a large language model-powered pipeline that automatically extracts experimental NMR data from massive open-access publications, resulting in the construction of NMRBank—the largest open-access NMR dataset available to date.",
  "full_text": "NMRExtractor: leveraging large language models to\nconstruct an experimental NMR database from\nopen-source scientiﬁc publications†\nQinggong Wang,‡ab Wei Zhang,‡bc Mingan Chen,bde Xutong Li,bc Zhaoping Xiong,f\nJiacheng Xiong,*b Zunyun Fu*d and Mingyue Zheng *abc\nNuclear magnetic resonance (NMR) spectroscopy is crucial for elucidating molecular structures, but NMR\ndata extraction remains largely manual and time-consuming. We developed NMRExtractor, a locally\ndeployable tool using aﬁne-tuned large language model, to address this challenge. By processing 5 734\n869 open-source scientiﬁc publications, we created NMRBank, a dataset containing 225 809 entries with\ncompound IUPAC names, NMR conditions,\n1H and 13C NMR chemical shifts, data conﬁdence levels, and\nreference information. Our analysis reveals that NMRBank's chemical space signi ﬁcantly surpasses\nexisting public NMR datasets. The extraction process is highly scalable, allowing automatic processing of\nnew research papers and continuous updates to NMRBank. This approach not only expands the available\nopen NMR data space but also provides a foundation for AI-based NMR predictions and related chemical\nresearch. By automating data extraction and creating a comprehensive, regularly updated NMR database,\nNMRExtractor and NMRBank address the scarcity of publicly available experimental NMR data, potentially\naccelerating progress in variousﬁelds of chemical research.\nIntroduction\nIn the era of articial intelligence (AI)-driven scientic research,\nhigh-quality, large-scale datasets are crucial for the success of\nmachine learning models. 1,2 In chemistry, comprehensive\ndatabases like PubChem 3 and ChEMBL 4 provide extensive\ninformation on compound structures, properties, and biolog-\nical activities. The USPTO dataset o ﬀers valuable data on\nchemical reactions. These resources have enabled researchers\nto apply machine learning techniques to discover new chemical\ninsights, optimize reaction conditions, and accelerate drug\ndiscovery.\n5,6 However, despite the abundance of data on\nmolecular structures and reactions, there remains a signicant\ndeciency in publicly available spectral data,7 which is essential\nfor understanding the properties of substances.8\nNuclear magnetic resonance (NMR) spectroscopy is one of\nthe most powerful and widely used techniques in chemical\nresearch for investigating molecular structures and dynamics.\n9\nBy measuring the magnetic properties of atomic nuclei, NMR\nprovides detailed information about the molecular environ-\nment, which is sensitive to structure and atomic interactions.\n10\nThe most direct application of NMR spectral data is in the\nstructural identi cation of unknown compounds.\n11 Recent\nadvancements, such as the BART-based Conditional Molecular\nGeneration Network (CMGNet) proposed by Yaoet al., demon-\nstrate the potential for automatic structural elucidation using\n13C NMR data and prior knowledge. 12 Beyond compound\nidentication,12–15 NMR chemical shis also reect the elec-\ntronic environment of atoms, revealing their electrophilic\ncharacteristics.\n16 This information has been applied to chemical\nreaction prediction studies, such as enhancing the performance\nof graph neural networks in predicting aldehyde oxidase (AOX)\nmetabolic sites17 and predicting the functionalization likeli-\nhood of atoms.18\nOver the past two decades, several databases have been\ndeveloped to store1H and 13C NMR spectra of molecules.19–28\nNotable examples include the Human Metabolome Database\n(HMDB),19 NMRShiDB2,21,22 and the Natural Products\nMagnetic Resonance Database (NP-MRD).24 However, the scale\nof these databases remains limited. NMRShiDB2, the largest\nopen NMR database, contains only 53 954 experimentally\nmeasured spectra for about 44 909 molecules. To address the\nissue of data scarcity, Jia et al. developed SRCV, a machine\naNanjing University of Chinese Medicine, 138 Xianlin Road, Nanjing 210023, China.\nE-mail: myzheng@simm.ac.cn\nbDrug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai\nInstitute of Materia Medica, Chinese Academy of Sciences, 555 Zuchongzhi Road,\nShanghai 201203, China. E-mail: fuzunyun@simm.ac.cn; s19-xiongjiacheng@simm.ac.cn\ncUniversity of Chinese Academy of Sciences, No. 19A Yuquan Road, Beijing 100049,\nChina\ndShanghaiTech University, Shanghai 201210, China\neLingang Laboratory, Shanghai 200031, China\nfProtonUnfold Technology Co., Ltd, Suzhou, China\n† Electronic supplementary information (ESI) available. See DOI:\nhttps://doi.org/10.1039/d4sc08802f\n‡ These authors contributed equally to this work.\nCite this:Chem. Sci.,2 0 2 5 ,16,1 1 5 4 8\nAll publication charges for this article\nhave been paid for by the Royal Society\nof Chemistry\nReceived 30th December 2024\nAccepted 20th May 2025\nDOI: 10.1039/d4sc08802f\nrsc.li/chemical-science\n11548 | Chem. Sci.,2 0 2 5 ,16, 11548–11558 © 2025 The Author(s). Published by the Royal Society of Chemistry\nChemical\nScience\nEDGE ARTICLE\nOpen Access Article. Published on 28 May 2025. Downloaded on 11/5/2025 3:45:43 PM. \n This article is licensed under a \nCreative Commons Attribution-NonCommercial 3.0 Unported Licence.\nView Article Online\nView Journal\n | View Issue\nlearning-based NMR spectrum recognition system.29 However,\nthis system is limited by its reliance on standardized NMR\nimages and inability to extract associated information such as\ncompound structures and measurement conditions.\nRecently, large language models (LLMs) like ChatGPT have\ndemonstrated powerful text understanding and processing\ncapabilities, making them promising tools for text mining in\nscientic literature.\n30–34 For instance, Zhenget al.used prompt\nengineering to guide ChatGPT in extracting information about\nmetal–organic framework synthesis from scienti c\nliterature.30 W. Coley et al. ne-tuned LLMs to extract reaction\ninformation from organic synthesis texts into structured data\nconforming to the Open Reaction Database (ORD) model.\n33 Our\nprevious work showed thatne-tuned large language models\nachieved excellent performance onve chemical text extraction\ntasks.34 Additionally, we found that ne-tuning open-source\nLLMs like Mistral-7b-instruct-v-0.2 provides a viable alterna-\ntive for text mining, oﬀering comparable performance with\nreduced computational costs and increased exibility for\nprivate deployment.\nThe application of LLMs is actively being explored for data\nextraction in the eld of materials science.35–46 Polak et al.\ndeveloped ChatExtract by leveraging conversational LLMs and\nprompt engineering to extract structured material property\ndata.\n38 MatSci-NLP demonstrated how instruction tuning\nenhances LLM performance, 39 while LLaMat showed that\ncontinued pretraining on materials science literature, followed\nby instruction tuning, enables superior performance in\nspecialized tasks compared to general-purpose LLMs.\n40 LLMs\nare also used for large-scale data extraction, Kimet al.developed\nL2M3, a system that uses ane-tuned LLM to extract MOF data\nfrom over 40 000 scientic articles and organize it into a struc-\ntured format. 41 Meanwhile, retrieval-augmented generation\n(RAG) and agent-based systems have gained attention, with\nHoneyComb integrating a high-quality materials science\nknowledge base (MatSciKB) and a specialized toolset (ToolHub)\nto signicantly enhance LLM reasoning and computational\ncapabilities.\n43 PaperQA, leveraging RAG techniques, has out-\nperformed other LLMs and commercial products in answering\nscientic literature-related queries, even surpassing human\nexperts in comparative evaluations.\n44 MaterialsBERT success-\nfully identied and processed approximately 681 000 polymer-\nrelated articles. The data of 24 properties of over 106 000\nunique polymers extracted has been made publicly available to\nthe scientic communityvia the Polymer Scholar website.\n46\nIn this study, we present NMRExtractor, a high-precision and\neasily extensible NMR data extraction tool utilizing LLMs. As\nillustrated in Fig. 1, NMRExtractor extracts comprehensive\nFig. 1 Schematic diagram of the NMR data extraction process and NMRBank construction using NMRExtractor. The process involves two main\nsteps: (1) using regular expressions to identify NMR paragraphs, and (2) employing aﬁne-tuned large language model for batch extraction of NMR\ndata. After eliminating entries with empty IUPAC names, we established the NMRBank dataset, comprising 225 809 entries. Of these, 156 621\nentries successfully converted IUPAC names to SMILES notation.\n© 2025 The Author(s). Published by the Royal Society of Chemistry Chem. Sci.,2 0 2 5 ,16, 11548–11558 | 11549\nEdge Article Chemical Science\nOpen Access Article. Published on 28 May 2025. Downloaded on 11/5/2025 3:45:43 PM. \n This article is licensed under a \nCreative Commons Attribution-NonCommercial 3.0 Unported Licence.\nView Article Online\ninformation including the IUPAC name of compounds, NMR\nconditions, and 1H and 13C NMR chemical shis. Using this\ntool, we have created NMRBank, a dataset containing 225 809\nexperimental NMR data entries. This dataset encompasses\na wide range of NMR chemical information and covers\na chemical space signicantly larger than existing open-source\nNMR libraries. Crucially, NMRExtractor's ability to automati-\ncally process new research papers ensures that NMRBank can\nbe continuously updated and expanded, addressing the\nongoing need for comprehensive and up-to-date NMR data in\nchemical research.\nMethods\nWorkow of NMR data extraction with NMRExtractor\nThe process of extracting NMR data using NMRExtractor and\nbuilding NMRBank is shown in Fig. 2. In therst and second\nsteps, we rst access all open-access TXT documents in\nPubMed. To prevent potential parsing errors caused by encod-\ning format mismatch, werst convert them to a unied UTF-8\nencoding format and then use regular expressions to obtain\nall text paragraphs that mention NMR data. In the third step,\naer extracting NMR data from the NMR paragraphs using\na large language model, we only retain data whose IUPAC names\nare not empty, and then furtherlter out data whose\n1H and13C\nNMR chemical shis are not empty. In the fourth andh\nsteps, we convert the IUPAC names of the compounds into\nSMILES and normalize the successfully converted SMILES. It is\nimportant to note that the term“IUPAC name” here is used\nbroadly to include not only formal IUPAC names, but also\ncommonly used names that can be recognized and interpreted\nby cheminformatics tools. A comprehensive example of NMR\ndata extraction using NMRExtractor is provided in ESI and\nFig. S1 †, demonstrating the practical application of this\nstreamlined process.\nExtraction of NMR paragraphs\nWe downloaded open-access full-text articles in txt format from\nthe PubMed database,\n47 using the latest version updated in June\n2024, which contains 5 734 869 articles. All articles wererst\nconverted to UTF-8 encoding. In the literature containing NMR\ndata, the IUPAC name is usually located in therst sentence of\nthe paragraph or as an independent paragraph.1H NMR and\n13C NMR data are usually presented together, and1H NMR data\nare usually located between the IUPAC name and13C NMR data.\nTherefore, in order to obtain paragraphs containing NMR data\nand eliminate common writing diﬀerences such as\n13C-NMR,\n13CNMR, and 13C NMR, we use the regular expression\n13C.{0,3}NMR for paragraph matching, means matching 13C\nfollowed by 0 to 3 arbitrary characters and then NMR. Aer the\nmatch is successful, we further splice the previous and next\nparagraphs to ensure that the obtained NMR paragraph\ncontains the complete IUPAC name,\n1H and 13C NMR data\n(Fig. S1†).\nFine-tuning and inference of LLMs\nBased on our previous research,34 we found thatne-tuning the\nopen-source Mistral-7b-instruct-v-0.2 model for NMR data\nextraction works almost as well as ChatGPT and can be\ndeployed locally. We ne-tuned all parameters of Mistral-7b-\ninstruct-v-0.2 and Llama3-8b-instruct on a 4 × 40GB A100,\nand Q-LoRA ne-tuned Llama2-13b-instruct on a 1 × 40GB\nA100.\n48 For inference phase, we used vLLM to boost speed,49\nachieving an average inference speed of 2 records per second on\na single 40GB A100. Examples of prompts used forne-tuning\nFig. 2 The process of extracting NMR data from original research papers using NMRExtractor. Grey boxes represent starting and end points,\npurple parallelograms represent inputs and outputs, blue rectangles represent processingﬂows, and orange diamonds represent decision points\nin the pipeline.\n11550 | Chem. Sci.,2 0 2 5 ,16, 11548–11558 © 2025 The Author(s). Published by the Royal Society of Chemistry\nChemical Science Edge Article\nOpen Access Article. Published on 28 May 2025. Downloaded on 11/5/2025 3:45:43 PM. \n This article is licensed under a \nCreative Commons Attribution-NonCommercial 3.0 Unported Licence.\nView Article Online\nand inference can be found in Fig. S2†. The hyperparameters\nused in this study are consistent with our previous work and\nprovided in Table S1†. Details on hardware resources, memory\ncost, and runtime for both modelne-tuning and inference are\nprovided in Table S2†.\nEvaluation of the performance of the LLMs\nTo enhance the performance of the model in extracting NMR\ndata from millions of papers, we expanded our training set from\n300 to 1000 samples. We added 700 NMR paragraphs from\narticles published before 2023 to the original Paragraph2NMR\ntask dataset.\n34 For a more comprehensive evaluation, we created\na new test set of 1022 unique texts, by randomly selecting 1–2\nparagraphs from NMR articles published in 2023. All data are\nmanually annotated by chemistry experts, the annotations\ninclude the compound IUPAC name,1H/13C NMR measurement\nconditions and chemical shi. The1H NMR chemical shi also\nretains information such as coupling constants, and N/A is used\nto ll in the non-existent content (Fig. S3†). We report results on\ntwo test sets: (1) test set 1, derived from our previous publica-\ntion, serves as a benchmark for comparison with existing\nmethods; (2) test set 2, newly constructed for this study,\ncontains more diverse chemical structures and NMR data\nformats, including challenging cases not present in test set 1.\nThe two test sets are completely non-overlapping, enabling\na robust assessment across diﬀerent data distributions and\nannotation styles. This dual evaluation provides both a direct\ncomparison to prior work and an assessment of the model's\ngeneralization to real-world NMR data.\nWe used exact match accuracy as our evaluation metric, and\nwe also recognized that this is a particularly strict standard.\nSome failures under this metric were merely slight rephrasings\nby the model that would be considered correct by human\nevaluators (Fig. S4 and S5†).\nPost-processing\nPost-processing is essential for information extraction, partic-\nularly when dealing with inconsistent and diverse scientic\ndata. In the research on standardized datasets in theeld of\nmaterials science, aer successfully extracting named entities\nrelated to materials science, Leigh Weston et al. used\na normalization method combining rules and look-up tables to\nconvert synonymous entities into a standardized name.\n50 Pra-\nnav Shetty et al. focused on the normalization of polymer\nnamed entities and trained a supervised clustering model with\nWord2Vec and fastText word vectors to classify named entities\nreferring to the same polymer.\n51 Similarly, as an optimized\nmulti-algorithm mapping method, ChemProps can unify poly-\nmer name expressions through API calls.\n52\nIn our work, aer extracting the NMR data using NMREx-\ntractor, we standardized the output by: (1) to enhance the\nsuccess rate of IUPAC-to-SMILES conversion, all non-standard\ncharacters in the IUPAC names were standardized. (2) Con-\nverting IUPAC names to SMILES using ChemDraw; (3) Using the\nOpen Parser for Systematic IUPAC nomenclature (OPSIN) online\nservice\n53 for IUPAC names ChemDraw couldn't convert; (4)\nstandardizing SMILES with RDKit to ensure data consistency\nand usability (Fig. S6†).54\nResults\nData preparation\nWe analyzed 5 734 869 open access articles from the PubMed\ndatabase and identied 380 220 paragraphs mentioning NMR\npassages from 58 795 articles using rule-based method. The\nproportion of articles with NMR messages in the PubMed\ndatabase is relatively small (Fig. 3a). Of these 380 220 para-\ngraphs, approximately 260 000 paragraphs contain NMR data,\noriginating from 35 270 articles (Fig. 3b).\nTo enhance our evaluation, we expanded upon our previous\nwork's 300 training and 300 test data items (test set 1) by\ncreating a diverse test set of 1022 NMR data paragraphs (test set\n2). This new set ensures comprehensive coverage across various\njournal types and allows for a thorough assessment of model\nperformance. We identied a total of 10 958 NMR paragraphs in\nNMR articles published in 2023.\nFrom these, we randomly sampled 1022 paragraphs from\n115 diﬀerent journal types, which were then manually anno-\ntated by chemistry experts (Fig. S7†). We classied the 1022\nNMR paragraphs into standardized and non-standardized\ndescriptions based on the presentation format of the NMR\ndata in the research paper (Fig. 3c). This classication resulted\nin 788 standardized NMR data descriptions (test set 2_stan-\ndard) and 244 non-standardized descriptions (test set 2_non-\nstandard). To further augment our dataset, we randomly\nselected and manually annotated 700 NMR paragraphs pub-\nlished before 2023, increasing our training set to 1000 samples.\nModel performance\nAs shown in Fig. 4a, the performance of thene-tuned Mistral-\n7b-instruct-v-0.2 model improves and gradually converges as\nthe training set size increases. Optimal results across diﬀerent\ntest sets were achieved with a training set of 800 samples, out-\nperforming both Llama3-8b-instruct and Llama2-13b-chat\n(Tables S3 and S4 †). The model attained an accuracy\nexceeding 0.96 for various element extractions in test set 1 (300)\nand over 0.85 in test set 2 (1022). Further analysis of test set 2\n(1022), categorized by text description methods, revealed an\naccuracy surpassing 0.9 for element extraction in test set\n2_standard (778). However, test set 2_non-standard (244) posed\nchallenges due to non-standardized NMR data descriptions.\nThese natural language descriptions, characterized by diverse\nexpressions and complex grammatical structures, oen con-\ntained incomplete or missing information, hindering NMR data\nextraction and slightly reducing model performance. To further\ndemonstrate the model's accuracy and data usability, we\nexamined instances where both the IUPAC name and NMR\nchemical shi terms were correctly extracted. A prediction is\ndeemed correct only when both components were accurate;\notherwise, it was classied as incorrect. As the training set\nexpanded to 800, the accuracy of correctly extracting both the\nIUPAC name and\n1H NMR chemical shi could reach 0.78 in\n© 2025 The Author(s). Published by the Royal Society of Chemistry Chem. Sci.,2 0 2 5 ,16, 11548–11558 | 11551\nEdge Article Chemical Science\nOpen Access Article. Published on 28 May 2025. Downloaded on 11/5/2025 3:45:43 PM. \n This article is licensed under a \nCreative Commons Attribution-NonCommercial 3.0 Unported Licence.\nView Article Online\nFig. 3 Article counts and NMR data description formats. (a) Total open-access papers in PubMed (grey)versus papers mentioning NMR (blue) by\nyear. (b) Papers mentioning NMR (blue) and those including NMR data (red) in PubMed. (c) Examples of standardized (test set 2_standard) and\nnon-standardized NMR (test set 2_non-standard) data descriptions in papers. Note: while this data reﬂects PubMed's June 2024 update, papers\nfrom 2023 and 2024 are underrepresented due to incomplete updating.\nFig. 4 (a) The performance of theﬁne-tuned Mistral-7b-instruct-v-0.2 on diﬀerent test sets varies with the number of training sets changes. (b)\nThe exact match accuracy of both the IUPAC name and1H/13C NMR chemical shifts on diﬀerent test sets with the number of training sets\nchanges. Error bars represent the standard deviation across three runs with independently sampled training data.\n11552 | Chem. Sci.,2 0 2 5 ,16, 11548–11558 © 2025 The Author(s). Published by the Royal Society of Chemistry\nChemical Science Edge Article\nOpen Access Article. Published on 28 May 2025. Downloaded on 11/5/2025 3:45:43 PM. \n This article is licensed under a \nCreative Commons Attribution-NonCommercial 3.0 Unported Licence.\nView Article Online\ntest set 2 (1022). And the accuracy of correctly extracting both\nthe IUPAC name and13C NMR chemical shi could reach 0.804\nin test set 2 (1022) (Fig. 4b).\nData condence and accuracy\nTo objectively evaluate NMRExtractor's performance, we\nassessed both the overall accuracy of extracted data and the\nmodel's condence score for each data point. The condence\nscore ranges from 0 to 1. The condence of the model predic-\ntions is computed based on the cumulative log probability of\nthe predicted tokens. For detailed on how condence levels are\ncalculated, please refer to the ESI.† In test set 1 (300) and test set\n2 (1022), when condence exceeds 0.6, the accuracy of extract-\ning all elements reaches over 86%. When condence exceeds\n0.8, the complete accuracy surpasses 97% (Fig. 5a and b).\nResults from three-fold cross-validation on the training set\nfurther con rm that model performance improves with\nincreasing con dence (Table S5 †). According to earlier\nstudies,\n55 the error rate in manually curated bioactivity data-\nbases (such as ChEMBL and WOMBAT) is around 5%. This\nsuggests that high-condence predictions (condence >0.8) of\nour model may achieve human-level accuracy, supporting its\nreliable large-scale deployment.\nFor test set 1 (300), 261 entities have a condence score\nabove 0.6, with 209 entities scoring above 0.8 (Fig. 5a). In the\ntest set 2 (1022), 594 entities score above 0.6, and 386 entities\nabove 0.8 (Fig. 5b). Test set 1 (300) and test set 2_standard (778)\nshow a high number of high condence values and good model\nperformance (Fig. 5a and c). While test set 2_non-standard (244)\nshows poorer model performance overall, when the condence\nscore exceeds 0.8, the accuracy of element extraction still\nexceeds 88% (Fig. 5d). The consistently high accuracy of high-\ncondence data across di ﬀerent data description formats\nallow us tolter data based on model condence aer batch\ndata extraction, thereby improving overall data quality.\nData extraction methods comparison\nBefore using ane-tuned large language model for NMR data\nextraction, we explored a variety of methods to extract NMR data\nfrom text. Initially, we attempted to extract NMR data from\nresearch papers using a traditional rule-based approach. Based\non the standardized description of NMR data in research\npapers, we developed regular expressions to locate NMR para-\ngraphs, isolated the sections containing NMR data, and then\napplied additional rules to obtain the required NMR data\n(Fig. S8†). For IUPAC names, we compiled a list of 618 common\ncompound group words (Fig. S9†) and scanned the text for these\nwords to extract relevant information. However, the rule-based\nextraction of NMR data from research papers presented chal-\nlenges. To accommodate the diversity of text, the rules required\nconstant modication and renement. We discovered that even\nwith continuous addition of new rules, it was impossible to\ncover all scenarios. Moreover, the presence of reactants and\nsolvents in the text interfered with the extraction of IUPAC\nFig. 5 NMRExtractor's performance across diﬀerent test sets and conﬁdence intervals. The number of data points in each conﬁdence interval is\nshown below it. (a) The performance of test set 1 (300) with diﬀerent conﬁdence intervals. (b) The performance of test set 2 (1022) with diﬀerent\nconﬁdence intervals. (c) The performance of test set 2_standard (778) with diﬀerent conﬁdence intervals. (d) The performance of test set 2_non-\nstandard (244) with diﬀerent conﬁdence intervals. Error bars represent the standard deviation across three runs with independently sampled\ntraining data.\n© 2025 The Author(s). Published by the Royal Society of Chemistry Chem. Sci.,2 0 2 5 ,16, 11548–11558 | 11553\nEdge Article Chemical Science\nOpen Access Article. Published on 28 May 2025. Downloaded on 11/5/2025 3:45:43 PM. \n This article is licensed under a \nCreative Commons Attribution-NonCommercial 3.0 Unported Licence.\nView Article Online\nnames, resulting in both missed NMR data and errors in the\nextracted information. In comparison to NMRExtractor, which\nis based on large language models, the traditional rule-based\nmethod performed poorly on both test set 1 (300) and test set\n2 (1022) (Fig. 6a and b). Furthermore, in batch data extraction,\nthe large language model-based method can lter data\naccording to the condence level of each entry, whereas the\nrule-based method lacks the ability to assess the accuracy of the\nextracted NMR data.\nNMR data extraction and analysis\nWe employed NMRExtractor to process 380 220 NMR para-\ngraphs in batch. Aer removing entries with empty\n13C NMR\nchemical shis, we obtained approximately 260 000 entries.\nFurther ltering out entries with both empty IUPAC names and\nNMR chemical shis yielded 225 809 entries. To standardize\nthese data, we converted IUPAC names to SMILES using\nChemDraw and OPSIN, successfully converting 156 621 entries.\nWe then standardized the SMILES using RDKit (Fig. S6†), ulti-\nmately constructing the NMRBank dataset. During standardi-\nzation, stereoisomer details are preserved in the SMILES string.\nOf these entries, the total number of unique SMILES strings is\n149 135, representing approximately 66% of our total records.\nThis normalization process ensures that structural duplicates\nare properly accounted for, providing a more accurate\ncomparison with existing databases.\nOur detailed analysis of the 156 621 records containing\nSMILES revealed 2906 compounds with multiple entries. The\nfrequency distribution follows a power-law pattern, which is\ncharacteristic of chemical databases and reects the prevalence\nof commonly studied compounds in the literature. We have\nvisualized this distribution in Fig. S10 † and provided\na comprehensive list of the most frequently occurring\ncompounds in Table S6†. For applications requiring the highest\ndata quality, we identied 91 707 unique SMILES records within\nour highest condence interval (0.8–1.0). This subset represents\nour most reliable data points and is particularly valuable for\nexperimental validation and machine learning applications.\nWe also analyzed the data distribution of the public\nNMRshiDB2 dataset to compare it with NMRBank. As shown\nin Fig. 7, the distribution of physicochemical properties in\nNMRBank, including molecular weight, log P, and TPSA,\nsignicantly diﬀers from that of NMRShiDB2. Moreover, the\nproperty ranges observed in NMRShiDB2 are fully contained\nwithin those of NMRBank, while NMRBank demonstrates\na broader spread across all examined properties. These results\nindicate that NMRBank covers a more diverse and expansive\nchemical space. Based on the con dence level, we further\nassessed the accuracy of the data in NMRBank data. A rule-\nbased approach was used to check whether the chemical shi\nvalues appeared sequentially in the paragraphs from which they\nwere extracted and whether any modications had occurred.\nWithin the high-condence interval, the\n1H and 13C NMR\nchemical shi values and their order in NMRBank exhibited\na high degree of consistency with the paragraphs in the original\npaper (Fig. S11†).\nTo illustrate typical extraction errors, we conducted case\nstudies on missed NMR paragraphs caused by regex limitations.\nWe employed the regular expression “13C.{0,3}NMR” as our\nprimary method to identify NMR-relevant paragraphs. While\nthis approach proved highly eﬀective for standard NMR nota-\ntion formats, we acknowledge its inherent limitations. Through\ncomprehensive analysis, we identied several variant notations\nsuch as “C13 NMR”, “13 C-NMR”,o r “C13-NMR” that could\nFig. 6 Performance comparison of rule-based method (blue) and\nNMRExtractor (red) on (a) test set 1 (300 samples) and (b) test set 2\n(1022 samples).\nFig. 7 (a) Distribution of conﬁdence values for data in the NMRBank.\n(b) Molecular weight distribution of molecules from NMRBank and\nNMRShiftDB2. (c) TPSA distribution of molecules from NMRBank and\nNMRShiftDB2. (d) Distribution of calculated logP of molecules from\nNMRBank and NMRShiftDB2.\n11554 | Chem. Sci.,2 0 2 5 ,16, 11548–11558 © 2025 The Author(s). Published by the Royal Society of Chemistry\nChemical Science Edge Article\nOpen Access Article. Published on 28 May 2025. Downloaded on 11/5/2025 3:45:43 PM. \n This article is licensed under a \nCreative Commons Attribution-NonCommercial 3.0 Unported Licence.\nView Article Online\npotentially be missed (Fig. S12†). Our thorough investigation of\n5.7 million articles revealed that these variant notations\nappeared 1962 times, representing approximately 0.5% of the\ntotal 380 220 identied NMR paragraphs. This small percentage\ndemonstrates the robustness of our chosen regular expression\npattern while acknowledging room for future optimization.\nWe conducted a systematic analysis of the conversion gap\nbetween IUPAC names and SMILES strings. We implemented\na multi-tool approach,rst using ChemDraw and then OPSIN\nfor failed cases, to maximize conversion success. However,\nsome structures remained challenging for both tools. Among\nthe approximately 226 000 records, around 70 000 (∼31%) could\nnot be successfully converted to SMILES strings. This gap can be\nattributed to several factors: (1) complex molecular structures:\nsome compounds, particularly natural products and complex\nsynthetic molecules, contain challenging structural features\nthat exceed the current capabilities of conversion tools. As\nshown in Fig. S13,† even accurately extracted IUPAC names like\n2-[2-(2,6-dichlorophenyl)amino]benzyl-3-(2-\nhydroxyphenylacrylamido)-6,8-dibromoquinazolin-4(3H)ones\ncould not be converted due to their structural complexity; (2)\ncommon names: some compounds are referred to by common\nor trade names rather than systematic IUPAC names, such as\nTelisatin A. These names o en lack the structural detail\nrequired by conversion tools like ChemDraw and OPSIN\n(Fig. S13†); we are actively working on improving our conversion\npipeline and exploring additional chemical structure parsing\ntools to reduce this gap in future updates.\nExisting NMR database\nIn addition to analyzing statistical properties, we compared\nNMRBank to the most common NMR databases (Table 1). Our\nndings revealed that NMRBank contains signicantly more\nentries than any existing open-source NMR database. Moreover,\nour NMR extraction process o ﬀers excellent scalability. By\nutilizing our NMRExtractor, we can quickly and automatically\nprocess new literature, greatly facilitating the continuous\nupdating of the NMRBank database.\nTable 1 Summary of major NMR databases\nDataset name\nNumber of\nNMR spectra\nNumber of\ncompounds\nCompound\ntypes\nNMR\ntechnique URL Available\nHMDB5.0 (ref. 19) 4149 — Metabolites 1H/13C https://hmdb.ca Open-source\nBMRB20 1200+ — Small molecule\nmetabolites\n1H/13C https://bmrb.io Open-source\nNMRShiDB2\n(ref. 21 and 22)\n53 954 — Not specied 1H/13C https://nmrshidb.nmr.uni-koeln.de Open-source\nSDBS23 15 218 (1H)\n13 457 (13C)\n900+ Natural products 1H/13C https://sdbs.db.aist.go.jp/\nDisclaimer.aspx\nOpen-source\nNP-MRD24 1290 — Natural products 1H/13C https://np-mrd.org Open-source\nNAPROC-13 (ref. 25) 6000+ — Natural products 13C https://c13.materia-medica.net Open-source\nCH-NMR-NP26 30 500 926 Natural products 1H/13C https://ch-nmr-np.jeol.co.jp/en/nmrdb Open-source\nSpektraris-NMR27 466 250 Taxanes 1H/13C http://langelabtools.wsu.edu/nmr/ Open-source\nC6H6 (ref. 28) — 506 Not speci ed 1H/13C https://www.c6h6.org Open-source\nIlm-NMR-P31\n(ref. 56)\n14 250 13 730 Not speci ed 31P https://github.com/clacor/Ilm-NMR-P31 Open-source\nKnowItAll NMR57 1 280 000+ — Not specied 1H/13C https://sciencesolutions.wiley.com Commercial\nMicronmr58 1 000 000+ — Not specied 13C https://www.nmrdata.com Commercial\nNMRBank 225 809 149 135 Not speci ed 1H/13C https://github.com/eat-sugar/\nNMRExtractor\nOpen-source\nTable 2 NMRBank dataset overview\nData description Data value\nDataset name NMRBank\nData introduction Contains NMR data from 5.7 million PubMed articles\nTypes of NMR technique covered 1H/13C NMR\nTotal number of NMR data 225 809\nThe number of NMR data with SMILES 156 621\nThe number of NMR data with SMILES and condence greater than 0.8 94 675\nThe number of NMR data with SMILES and condence greater than 0.6 127 402\nThe number of NMR data with unique SMILES 149 135\nThe number of NMR data with unique SMILES and condence greater than 0.8 91 707\nThe number of NMR data with unique SMILES and condence greater than 0.6 123 174\nURL https://github.com/eat-sugar/NMRExtractor\nAvailable Open-source\n© 2025 The Author(s). Published by the Royal Society of Chemistry Chem. Sci.,2 0 2 5 ,16, 11548–11558 | 11555\nEdge Article Chemical Science\nOpen Access Article. Published on 28 May 2025. Downloaded on 11/5/2025 3:45:43 PM. \n This article is licensed under a \nCreative Commons Attribution-NonCommercial 3.0 Unported Licence.\nView Article Online\nData records\nThe NMRBank dataset constructed in this work is available at\nhttps://github.com/eat-sugar/NMRExtractor, a public data\nrepository providing open code and data for researchers,\nresearch projects/teams, journals, institutions, universities,\netc. Each data entry in the NMRBank dataset includes: article\nPMID, NMR paragraph, compound IUPAC name, SMILES,1H\nNMR conditions,1H NMR chemical shis, 13C NMR conditions,\n13C NMR chemical shi, condence, and other metadata such\nas article information. Table 2 provides an overview of the\ninformation items in the NMRBank dataset, while Table 3\npresents examples from the NMRBank dataset.\nConclusions\nNMR data contains crucial chemical properties, yet it is scat-\ntered across complex scienti c literature in various forms.\nExtracting experimental NMR data from these documents is\na challenging but vital task. In this study, we leveraged large\nlanguage model technology to mine and construct an NMR\ndatabase. We developed NMRExtractor and used it to batch-\nextract NMR data from over 5.7 million public documents in\nthe PubMed database. This eﬀort resulted in the NMRBank\ndataset, containing 225 809 NMR entries, with 156 621 entries\nincluding SMILES descriptors. Each entry comprises the\ncompound's IUPAC name, SMILES descriptor,\n1H NMR, 13C\nNMR, model-assigned condence score, and source metadata\nsuch as article number and journal name.\nComparative analysis reveals that NMRBank is currently the\nlargest open-source experimental NMR dataset available, which\ncovers a wide range of chemical space. This comprehensive\nresource is poised to signicantly advance NMR data-driven\ndeep learning and its applications in chemistry. NMREx-\ntractor's ability to automatically process new research papers for\nNMR data extraction ensures eﬃcient updates to the NMRBank\ndataset. Moving forward, we plan to continually re ne\nNMRExtractor and expand the NMRBank dataset. This research\nnot only broadens the scope and accessibility of experimental\nNMR data but also introduces a versatile data extraction\nmethod applicable to chemical research and drug design. Ulti-\nmately, these advancements will accelerate the discovery and\ndevelopment of new drugs.\nData availability\nAll data and code of this work are available at GitHub:https://\ngithub.com/eat-sugar/NMRExtractor. The model weights of\nNMRExtractor can be downloaded from https://\nhuggingface.co/sweetssweets/NMRExtractor. We also provide\nan online demo of NMRExtractor on https://huggingface.co/\nspaces/sweetssweets/NMRExtractor.\nAuthor contributions\nM. Y. Z., Z. Y. F., and J. C. X. conceived the idea. Q. G. W., W. Z.\nand M. Y. Z. designed the research. Q. G. W., W. Z. implemented\nthe codes. Q. G. W., W. Z., M. A. C. collected, annotated, and\nprocessed training data. Q. G. W., W. Z., Z. Y. F. checked the\ndata. Q. G. W., W. Z., Z. P. X. benchmarked the models. Q. G. W.\nwrote the initial dra. M. Y. Z., Z. Y. F., J. C. X., and X. T. L.\nreviewed and rened the article. All authors contributed to the\nanalysis of the results. All authors read and approved thenal\nmanuscript.\nConﬂicts of interest\nThere are no conicts to declare.\nAcknowledgements\nWe extend our gratitude to PubMed for oﬀering a wealth of\nopen literature, as well as to the open-source communities and\ntools like LLM and OPSIN for their invaluable contributions.\nThis work was supported by the National Natural Science\nFoundation of China (T2225002 and 82273855 to M. Y. Z. and\n82204278 to X. T. L.), the National Key Research and\nTable 3 Example entry from the NMRBank dataset\nData description Data value\nPubMed ID (PMID) 35 601 446\nPubChem CID 35 960\nNMR paragraph 4.2.1.4. 2,6-Dimethoxy-4-vinylphenol 2d yellow oil, yield 94%. IR (KBr plate): n\nmax 3144, 2938, 2844, 1605,\n1462, 1213, 1115, 837.1H NMR (600 MHz, CDCl3)d 6.65 (s, 2H), 6.61 (dd,J = 17.5, 10.9 Hz, 1H), 5.60 (d,J =\n17.5 Hz, 1H), 5.56 (s, 1H), 5.15 (d,J = 10.8 Hz, 1H), 3.90 (s, 6H).13C NMR (151 MHz, CDCl3)d 147.06, 136.83,\n134.76, 129.18, 111.87, 102.9, 56.26\nIUPAC name of compound 2,6-Dimethoxy-4-vinylphenol\nSMILES C ]Cc1cc(OC)c(O)c(OC)c1\n1H NMR conditions 600 MHz, CDCl3\n1H NMR chemical shi 6.65 (s, 2H), 6.61 (dd,J = 17.5, 10.9 Hz, 1H), 5.60 (d,J = 17.5 Hz, 1H), 5.56 (s, 1H), 5.15 (d,J = 10.8 Hz, 1H),\n3.90 (s, 6H)\n13C NMR conditions 151 MHz, CDCl3\n13C NMR chemical shi 147.06, 136.83, 134.76, 129.18, 111.87, 102.9, 56.26\nCondence in data given by large\nlanguage models\n0.927\nArticle citation R. Soc. Open Sci.; 9(4): 220014\n11556 | Chem. Sci.,2 0 2 5 ,16,1 1 5 4 8–11558 © 2025 The Author(s). Published by the Royal Society of Chemistry\nChemical Science Edge Article\nOpen Access Article. Published on 28 May 2025. Downloaded on 11/5/2025 3:45:43 PM. \n This article is licensed under a \nCreative Commons Attribution-NonCommercial 3.0 Unported Licence.\nView Article Online\nDevelopment Program of China (2022YFC3400504 to M. Y. Z.),\nthe SIMM-SHUTCM Traditional Chinese Medicine Innovation\nJoint Research Program (E2G805H to M. Y. Z.), the Shanghai\nPost-doctoral Excellence Program (2023693 to Z. Y. F. and\n2024707 to J. C. X.) and the Shanghai Municipal Science and\nTechnology Major Project.\nReferences\n1 D. Zha, Z. P. Bhat, K.-H. Lai, F. Yang, Z. Jiang, S. Zhong and\nX. Hu, Data-centric Articial Intelligence: A Survey, ACM\nComput. Surv., 2025,57,1 –42.\n2 L. Budach, M. Feuerpfeil, N. Ihde, A. Nathansen, N. Noack,\nH. Patzlaﬀ, F. Naumann and H. Harmouch, arXiv, 2022,\npreprint, arXiv:2207.14529, DOI:10.48550/arXiv.2207.14529.\n3 S. Kim, P. A. Thiessen, E. E. Bolton, J. Chen, G. Fu,\nA. Gindulyte, L. Han, J. He, S. He, B. A. Shoemaker,\nJ. Wang, B. Yu, J. Zhang and S. H. Bryant, PubChem\nSubstance and Compound databases, Nucleic Acids Res. ,\n2015, 44, D1202–D1213.\n4 A. Gaulton, L. J. Bellis, A. P. Bento, J. Chambers, M. Davies,\nA. Hersey, Y. Light, S. McGlinchey, D. Michalovich, B. Al-\nLazikani and J. P. Overington, ChEMBL: a large-scale\nbioactivity database for drug discovery, Nucleic Acids Res.,\n2011, 40, D1100–D1107.\n5 M. Staszak, K. Staszak, K. Wieszczycka, A. Bajek,\nK. Roszkowski and B. Tylkowski, Machine learning in drug\ndesign: Use of articial intelligence to explore the chemical\nstructure–biological activity relationship, Wiley Interdiscip.\nRev.: Comput. Mol. Sci., 2022,12, e1568.\n6 A. C. Mater and M. L. Coote, Deep Learning in Chemistry,J.\nChem. Inf. Model., 2019,59, 2545–2559.\n7 N. Norori, Q. Hu, F. M. Aellen, F. D. Faraci and A. Tzovara,\nAddressing bias in big data and AI for health care: A call\nfor open science,Patterns, 2021,2, 100347.\n8 I. V. Tetko, O. Engkvist, U. Koch, J.-L. Reymond and H. Chen,\nBIGCHEM: Challenges and Opportunities for Big Data\nAnalysis in Chemistry,Mol. Inform., 2016,35, 615–621.\n9 P. R. L. Markwick, T. Malliavin and M. Nilges, Structural\nBiology by NMR: Structure, Dynamics, and Interactions,\nPLoS Comput. Biol., 2008,4, e1000168.\n10 H. Günther,NMR spectroscopy: basic principles, concepts and\napplications in chemistry, John Wiley & Sons, 2013.\n11 X. Xue, H. Sun, M. Yang, X. Liu, H.-Y. Hu, Y. Deng and\nX. Wang, Advances in the Application of Arti cial\nIntelligence-Based Spectral Data Interpretation: A\nPerspective, Anal. Chem., 2023,95, 13733–13745.\n12 L. Yao, M. Yang, J. Song, Z. Yang, H. Sun, H. Shi, X. Liu, X. Ji,\nY. Deng and X. Wang, Conditional Molecular Generation Net\nEnables Automated Structure Elucidation Based on 13C\nNMR Spectra and Prior Knowledge,Anal. Chem., 2023, 95,\n5393–\n5401.\n13 Z. Huang, M. S. Chen, C. P. Woroch, T. E. Markland and\nM. W. Kanan, A framework for automated structure\nelucidation from routine NMR spectra, Chem. Sci., 2021,\n12, 15329–15338.\n14 Z. Yang, J. Song, M. Yang, L. Yao, J. Zhang, H. Shi, X. Ji,\nY. Deng and X. Wang, Cross-Modal Retrieval between 13C\nNMR Spectra and Structures for Compound Identication\nUsing Deep Contrastive Learning, Anal. Chem., 2021, 93,\n16947–16955.\n15 M. Alberts, F. Zipoli and A. C. Vaucher,ChemRxiv, 2023,\npreprint, DOI:10.26434/chemrxiv-2023-8wxcz.\n1 6C .P .G o r d o n ,C .R a y n a u d ,R .A .A n d e r s e n ,C .C o p´eret and\nO. Eisenstein, Carbon-13 NMR Chemical Shi: A Descriptor\nfor Electronic Structure and Reactivity of Organometallic\nCompounds, Acc. Chem. Res., 2019,52, 2278–2289.\n17 J. Xiong, R. Cui, Z. Li, W. Zhang, R. Zhang, Z. Fu, X. Liu, Z. Li,\nK. Chen and M. Zheng, Transfer learning enhanced graph\nneural network for aldehyde oxidase metabolism\nprediction and its experimental application, Acta Pharm.\nSin. B, 2024,14, 623–634.\n18 E. King-Smith, F. A. Faber, U. Reilly, A. V. Sinitskiy, Q. Yang,\nB. Liu, D. Hyek and A. A. Lee, Predictive Minisci late stage\nfunctionalization with transfer learning, Nat. Commun. ,\n2024, 15, 426.\n19 D. S. Wishart, A. Guo, E. Oler, F. Wang, A. Anjum, H. Peters,\nR. Dizon, Z. Sayeeda, S. Tian, B. L. Lee, M. Berjanskii,\nR. Mah, M. Yamamoto, J. Jovel, C. Torres-Calzada,\nM. Hiebert-Giesbrecht, V. W. Lui, D. Varshavi, D. Varshavi,\nD. Allen, D. Arndt, N. Khetarpal, A. Sivakumaran,\nK. Harford, S. Sanford, K. Yee, X. Cao, Z. Budinski,\nJ. Liigand, L. Zhang, J. Zheng, R. Mandal, N. Karu,\nM. Dambrova, H. B. Schiöth, R. Greiner and V. Gautam,\nHMDB 5.0: the Human Metabolome Database for 2022,\nNucleic Acids Res., 2021,50, D622–D631.\n20 J. C. Hoch, K. Baskaran, H. Burr, J. Chin, H. R. Eghbalnia,\nT. Fujiwara, M. R. Gryk, T. Iwata, C. Kojima, G. Kurisu,\nD. Maziuk, Y. Miyanoiri, J. R. Wedell, C. Wilburn, H. Yao\nand M. Yokochi, Biological Magnetic Resonance Data\nBank, Nucleic Acids Res., 2022,51, D368–D376.\n21 S. Kuhn, H. Kolshorn, C. Steinbeck and N. Schlörer, Twenty\nyears of nmrshidb2: A case study of an open database for\nanalytical chemistry,Magn. Reson. Chem., 2024,62,7 4–83.\n22 C. Steinbeck, S. Krause and S. Kuhn,\nNMRShiDBConstructing a Free Chemical Information\nSystem with Open-Source Components, J. Chem. Inf.\nComput. Sci., 2003,43, 1733–1739.\n23 T. Saito and S. Kinugasa, Development and release of\na spectral database for organic compounds-key to the\ncontinual services and success of a large-scale database,\nSynthesiology, 2011,4,3 5–44.\n24 D. S. Wishart, Z. Sayeeda, Z. Budinski, A. Guo, B. L. Lee,\nM. Berjanskii, M. Rout, H. Peters, R. Dizon, R. Mah,\nC. Torres-Calzada, M. Hiebert-Giesbrecht, D. Varshavi,\nD. Varshavi, E. Oler, D. Allen, X. Cao, V. Gautam, A. Maras,\nE. F. Poynton, P. Tavangar, V. Yang, J. A. van Santen,\nR. Ghosh, S. Sarma, E. Knutson, V. Sullivan, A. M. Jystad,\nR. Renslow, L. W. Sumner, R. G. Linington and J. R. Cort,\nNP-MRD: the Natural Products Magnetic Resonance\nDatabase, Nucleic Acids Res., 2021,50, D665–D677.\n25 J. L. L´opez-P´erez, R. Ther´on, E. del Olmo and D. D´ıaz,\nNAPROC-13: a database for the dereplication of natural\n© 2025 The Author(s). Published by the Royal Society of Chemistry Chem. Sci.,2 0 2 5 ,16, 11548–11558 | 11557\nEdge Article Chemical Science\nOpen Access Article. Published on 28 May 2025. Downloaded on 11/5/2025 3:45:43 PM. \n This article is licensed under a \nCreative Commons Attribution-NonCommercial 3.0 Unported Licence.\nView Article Online\nproduct mixtures in bioassay-guided protocols,\nBioinformatics, 2007,23, 3256–3257.\n26 K. Asakura, A NMR spectral database of natural products\n\"CH-NMR-NP\", J. Synth. Org. Chem., 2015,73, 1247–1252.\n27 J. T. Fischedick, S. R. Johnson, R. E. B. Ketchum,\nR. B. Croteau and B. M. Lange, NMR spectroscopic search\nmodule for Spektraris, an online resource for plant natural\nproduct identi cation – Taxane diterpenoids from\nTaxus×media cell suspension cultures as a case study,\nPhytochemistry, 2015,113,8 7–95.\n28 L. Patiny, M. Zasso, D. Kostro, A. Bernal, A. M. Castillo,\nA. Bolaños, M. A. Asencio, N. Pellet, M. Todd, N. Schloerer,\nS. Kuhn, E. Holmes, S. Javor and J. Wist, The C6H6 NMR\nrepository: An integral solution to control theow of your\ndata from the magnet to the public,Magn. Reson. Chem.,\n2018, 56, 520–528.\n29 W. Jia, Z. Yang, M. Yang, L. Cheng, Z. Lei and X. Wang,\nMachine Learning Enhanced Spectrum Recognition Based\non Computer Vision (SRCV) for Intelligent NMR Data\nExtraction, J. Chem. Inf. Model., 2021,61,2 1–25.\n30 Z. Zheng, O. Zhang, C. Borgs, J. T. Chayes and O. M. Yaghi,\nChatGPT Chemistry Assistant for Text Mining and the\nPrediction of MOF Synthesis,J. Am. Chem. Soc., 2023, 145,\n18048–18062.\n31 Q. Chen, H. Sun, H. Liu, Y. Jiang, T. Ran, X. Jin, X. Xiao,\nZ. Lin, H. Chen and Z. Niu, An extensive benchmark study\non biomedical text generation and mining with ChatGPT,\nBioinformatics, 2023,39, btad557.\n32 J. Dagdelen, A. Dunn, S. Lee, N. Walker, A. S. Rosen,\nG. Ceder, K. A. Persson and A. Jain, Structured information\nextraction from scientic text with large language models,\nNat. Commun., 2024,15, 1418.\n33 Q. Ai, F. Meng, J. Shi, B. Pelkie and C. W. Coley, Extracting\nstructured data from organic synthesis procedures using\na ne-tuned large language model, Digit. Discov., 2024, 3,\n1822–1831.\n34 W. Zhang, Q. Wang, X. Kong, J. Xiong, S. Ni, D. Cao, B. Niu,\nM. Chen, Y. Li, R. Zhang, Y. Wang, L. Zhang, X. Li, Z. Xiong,\nQ. Shi, Z. Huang, Z. Fu and M. Zheng, Fine-tuning large\nlanguage models for chemical text mining, Chem. Sci.,\n2024, 15, 10600–10611.\n35 S. Miret and N. M. Krishnan, arXiv, 2024, preprint,\narXiv:2402.05200, DOI:10.48550/arXiv.2402.05200.\n36 K. Hira, M. Zaki, D. Sheth, Mausam and N. M. A. Krishnan,\nReconstructing the materials tetrahedron: challenges in\nmaterials information extraction, Digit. Discov., 2024, 3,\n1021–1037.\n37 M. Schilling-Wilhelmi, M. R´ıos-Garc´ıa, S. Shabih, M. V. Gil,\nS. Miret, C. T. Koch, J. A. M´arquez and K. M. Jablonka,\nFrom text to insight: large language models for chemical\ndata extraction,Chem. Soc. Rev., 2025,54, 1125–1150.\n38 M. P. Polak and D. Morgan, Extracting accurate materials\ndata from research papers with conversational language\nmodels and prompt engineering,Nat. Commun., 2024, 15,\n1569.\n39 Y. Song, S. Miret and B. Liu, arXiv, 2023, preprint,\narXiv:2310.08511, DOI:10.48550/arXiv.2310.08511.\n40 V. Mishra, S. Singh, D. Ahlawat, M. Zaki, V. Bihani,\nH. S. Grover, B. Mishra, S. Miret and N. M. Krishnan,\narXiv, 2024, preprint, arXiv:2412.09560, DOI: 10.48550/\narXiv.2412.09560.\n41 Y. Kang, W. Lee, T. Bae, S. Han, H. Jang and J. Kim,\nHarnessing Large Language Models to Collect and Analyze\nMetal–Organic Framework Property Data Set,J. Am. Chem.\nSoc., 2025,147, 3943–3958.\n42 Y. Song, S. Miret, H. Zhang and B. Liu,arXiv, 2023, preprint,\narXiv:2310.08511, DOI:10.48550/arXiv.2310.08511.\n43 H. Zhang, Y. Song, Z. Hou, S. Miret and B. Liu,arXiv, 2024,\npreprint, arXiv:2409.00135, DOI:10.48550/arXiv.2409.00135.\n44 J. L ´ala, O. O'Donoghue, A. Shtedritski, S. Cox,\nS. G. Rodriques and A. D. White, arXiv, 2023, preprint,\narXiv:2312.07559, DOI:10.48550/arXiv.2312.07559.\n45 J. Choi and B. Lee, Accelerating materials language\nprocessing with large language models, Comput. Mater.,\n2024, 5, 13.\n46 S. Gupta, A. Mahmood, P. Shetty, A. Adeboye and\nR. Ramprasad, Data extraction from polymer literature\nusing large language models,Comput. Mater., 2024,5, 269.\n47 J. White, PubMed 2.0,Med. Ref. Serv. Q., 2020,39, 382–387.\n48 T. Dettmers, A. Pagnoni, A. Holtzman and L. Zettlemoyer,\nAdv. Neural Inf. Process. Syst.\n, 2023,36, 10088–10115.\n49 W. Kwon, Z. Li, S. Zhuang, Y. Sheng, L. Zheng, C. H. Yu,\nJ. Gonzalez, H. Zhang and I. Stoica,presented in part at the\nProceedings of the 29th Symposium on Operating Systems\nPrinciples, Koblenz, Germany, 2023.\n50 L. Weston, V. Tshitoyan, J. Dagdelen, O. Kononova,\nA. Trewartha, K. A. Persson, G. Ceder and A. Jain, Named\nEntity Recognition and Normalization Applied to Large-\nScale Information Extraction from the Materials Science\nLiterature, J. Chem. Inf. Model., 2019,59, 3692–3702.\n51 P. Shetty and R. Ramprasad, Machine-Guided Polymer\nKnowledge Extraction Using Natural Language Processing:\nThe Example of Named Entity Normalization,J. Chem. Inf.\nModel., 2021,61, 5377–5385.\n52 B. Hu, A. Lin and L. C. Brinson, ChemProps: A RESTful API\nenabled database for composite polymer name\nstandardization, J. Cheminf., 2021,13, 22.\n53 D. M. Lowe, P. T. Corbett, P. Murray-Rust and R. C. Glen,\nChemical Name to Structure: OPSIN, an Open Source\nSolution, J. Chem. Inf. Model., 2011,51, 739–753.\n54 RDKit: Open-source cheminformatics So ware, https://\nwww.rdkit.org.\n55 P. Tiikkainen, L. Bellis, Y. Light and L. Franke, Estimating\nError Rates in Bioactivity Databases, J. Chem. Inf. Model.,\n2013, 53, 2499–2505.\n56 J. Hack, M. Jordan, A. Schmitt, M. Raru, H. S. Zorn,\nA. Seyfarth, I. Eulenberger and R. Geitner, Ilm-NMR-P31:\nan open-access 31P nuclear magnetic resonance database\nand data-driven prediction of 31P NMR shis, J. Cheminf.,\n2023, 15, 122.\n57 KnowItAll,https://www.knowitall.com, accessed Dec 8, 2024.\n58 Micronmr Database, https://www.nmrdata.com, accessed\nDec 8, 2024.\n11558 | Chem. Sci.,2 0 2 5 ,16, 11548–11558 © 2025 The Author(s). Published by the Royal Society of Chemistry\nChemical Science Edge Article\nOpen Access Article. Published on 28 May 2025. Downloaded on 11/5/2025 3:45:43 PM. \n This article is licensed under a \nCreative Commons Attribution-NonCommercial 3.0 Unported Licence.\nView Article Online",
  "topic": "Construct (python library)",
  "concepts": [
    {
      "name": "Construct (python library)",
      "score": 0.7162546515464783
    },
    {
      "name": "Pipeline (software)",
      "score": 0.6893193125724792
    },
    {
      "name": "Computer science",
      "score": 0.6728546619415283
    },
    {
      "name": "Open source",
      "score": 0.6323872208595276
    },
    {
      "name": "Open data",
      "score": 0.4840640127658844
    },
    {
      "name": "Information retrieval",
      "score": 0.3680635690689087
    },
    {
      "name": "Database",
      "score": 0.3635895252227783
    },
    {
      "name": "World Wide Web",
      "score": 0.31946009397506714
    },
    {
      "name": "Programming language",
      "score": 0.3112602233886719
    },
    {
      "name": "Software",
      "score": 0.08585456013679504
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I19820366",
      "name": "Chinese Academy of Sciences",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I131434179",
      "name": "Nanjing University of Chinese Medicine",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210112820",
      "name": "Shanghai Institute of Materia Medica",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210165038",
      "name": "University of Chinese Academy of Sciences",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I30809798",
      "name": "ShanghaiTech University",
      "country": "CN"
    }
  ],
  "cited_by": 4
}