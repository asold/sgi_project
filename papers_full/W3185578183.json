{
  "title": "Exploiting Auxiliary Data for Offensive Language Detection with Bidirectional Transformers",
  "url": "https://openalex.org/W3185578183",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A5102339100",
      "name": "Sumer Singh",
      "affiliations": [
        "University of Georgia"
      ]
    },
    {
      "id": "https://openalex.org/A5100359839",
      "name": "Sheng Li",
      "affiliations": [
        "University of Georgia"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2954221744",
    "https://openalex.org/W2786808285",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W1976780496",
    "https://openalex.org/W2552987523",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W2953553271",
    "https://openalex.org/W3171723960",
    "https://openalex.org/W2962977603",
    "https://openalex.org/W2563833337",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2910071410",
    "https://openalex.org/W2473555522",
    "https://openalex.org/W3014309243",
    "https://openalex.org/W3127214617",
    "https://openalex.org/W2963297649",
    "https://openalex.org/W2996428491",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W2595653137",
    "https://openalex.org/W2165698076",
    "https://openalex.org/W2975059944"
  ],
  "abstract": "Offensive language detection (OLD) has received increasing attention due to its societal impact. Recent work shows that bidirectional transformer based methods obtain impressive performance on OLD. However, such methods usually rely on large-scale well-labeled OLD datasets for model training. To address the issue of data/label scarcity in OLD, in this paper, we propose a simple yet effective domain adaptation approach to train bidirectional transformers. Our approach introduces domain adaptation (DA) training procedures to ALBERT, such that it can effectively exploit auxiliary data from source domains to improve the OLD performance in a target domain. Experimental results on benchmark datasets show that our approach, ALBERT (DA), obtains the state-of-the-art performance in most cases. Particularly, our approach significantly benefits underrepresented and under-performing classes, with a significant improvement over ALBERT.",
  "full_text": "Proceedings of the Fifth Workshop on Online Abuse and Harms, pages 1–5\nAugust 6, 2021. ©2021 Association for Computational Linguistics\n1\nExploiting Auxiliary Data for Offensive Language Detection with\nBidirectional Transformers\nSumer Singh\nUniversity of Georgia\nAthens, GA, USA\nsumer.singh@uga.edu\nSheng Li\nUniversity of Georgia\nAthens, GA, USA\nsheng.li@uga.edu\nAbstract\nOffensive language detection (OLD) has re-\nceived increasing attention due to its societal\nimpact. Recent work shows that bidirectional\ntransformer based methods obtain impressive\nperformance on OLD. However, such meth-\nods usually rely on large-scale well-labeled\nOLD datasets for model training. To address\nthe issue of data/label scarcity in OLD, in\nthis paper, we propose a simple yet effec-\ntive domain adaptation approach to train bidi-\nrectional transformers. Our approach intro-\nduces domain adaptation (DA) training pro-\ncedures to ALBERT, such that it can effec-\ntively exploit auxiliary data from source do-\nmains to improve the OLD performance in a\ntarget domain. Experimental results on bench-\nmark datasets show that our approach, AL-\nBERT (DA), obtains the state-of-the-art per-\nformance in most cases. Particularly, our ap-\nproach signiﬁcantly beneﬁts underrepresented\nand under-performing classes, with a signiﬁ-\ncant improvement over ALBERT.\n1 Introduction\nIn today’s digital age, the amount of offensive and\nabusive content found online has reached unprece-\ndented levels. Offensive content online has sev-\neral detrimental effects on its victims, e.g., vic-\ntims of cyberbullying are more likely to have lower\nself-esteem and suicidal thoughts (Vazsonyi et al.,\n2012). To reduce the impact of offensive online\ncontents, the ﬁrst step is to detect them in an accu-\nrate and timely fashion. Next, it is imperative to\nidentify the type and target of offensive contents.\nSegregating by type is important, because some\ntypes of offensive content are more serious and\nharmful than other types, e.g., hate speech is ille-\ngal in many countries and can attract large ﬁnes\nand even prison sentences, while profanity is not\nthat serious. To this end, offensive language detec-\ntion (OLD) has been extensively studied in recent\nyears, which is an active topic in natural language\nunderstanding.\nExisting methods on OLD, such as (Davidson\net al., 2017), mainly focus on detecting whether\nthe content is offensive or not, but they can not\nidentify the speciﬁc type and target of such con-\ntent. Waseem and Hovy (2016) analyze a corpus\nof around 16k tweets for hate speech detection,\nmake use of meta features (such as gender and lo-\ncation of the user), and employ a simple n-gram\nbased model. Liu et al. (2019) evaluate the per-\nformance of some deep learning models, includ-\ning BERT (Devlin et al., 2018), and achieve the\nstate of the art results on a newly collected OLD\ndataset, OLID (Zampieri et al., 2019). Although\npromising progress on OLD has been observed\nin recent years, existing methods, especially the\ndeep learning based ones, often rely on large-scale\nwell-labeled data for model training. In practice,\nlabeling offensive language data requires tremen-\ndous efforts, due to linguistic variety and human\nbias.\nIn this paper, we propose to tackle the challeng-\ning issue of data/label scarcity in offensive lan-\nguage detection, by designing a simple yet effec-\ntive domain adaptation approach based on bidi-\nrectional transformers. Domain adaptation aims\nto enhance the model capacity for a target do-\nmain by exploiting auxiliary information from ex-\nternal data sources (i.e., source domains), espe-\ncially when the data and labels in the target do-\nmain are insufﬁcient (Pan and Yang, 2009; Wang\nand Deng, 2018; Lai et al., 2018; Li et al., 2017;\nLi and Fu, 2016; Zhu et al., 2021). In particu-\nlar, we aim to identify not only if the content is\noffensive, but also the corresponding type and tar-\nget. In our work, the offensive language identiﬁ-\ncation dataset (OLID) (Zampieri et al., 2019) is\nconsidered as target domain, which contains a hier-\narchical multi-level structure of offensive contents.\n2\nAn external large-scale dataset on toxic comment\n(ToxCom) classiﬁcation is used as source domain.\nALBERT (Lan et al., 2019) is used in our approach\nowing to its impressive performance on OLD. A\nset of training procedures are designed to achieve\ndomain adaptation for the OLD task. In particular,\nas the external dataset is not labelled in the same\nformat as the OLID dataset, we design a separate\npredictive layer that helps align two domains. Ex-\ntensive empirical evaluations of our approach and\nbaselines are conducted. The main contributions of\nour work are summarized as follows:\n• We propose a simple domain adaptation ap-\nproach based on bidirectional transformers for\noffensive language detection, which could ef-\nfectively exploit useful information from aux-\niliary data sources.\n• We conduct extensive evaluations on bench-\nmark datasets, which demonstrate the remark-\nable performance of our approach on offensive\nlanguage detection.\n2 Related Work\nIn this section, we brieﬂy review related work on\noffensive language detection and transformers.\nOffensive Language Detection. Offensive lan-\nguage detection (OLD) has become an active re-\nsearch topic in recent years (Araujo De Souza and\nDa Costa Abreu, 2020). Nikolov and Radivchev\n(2019) experimented with a variety of models and\nobserve promising results with BERT and SVC\nbased models. Han et al. (2019) employed a GRU\nbased RNN with 100 dimensional glove word em-\nbeddings (Pennington et al., 2014). Additionally,\nthey develop a Modiﬁed Sentence Offensiveness\nCalculation (MSOC) model which makes use of\na dictionary of offensive words. Liu et al. (2019)\nevaluated three models on the OLID dataset, in-\ncluding logistic regression, LSTM and BERT, and\nresults show that BERT achieves the best perfor-\nmance. The concept of transfer learning mentioned\nin (Liu et al., 2019) is closely related to our work,\nsince the BERT model is also pretrained on exter-\nnal text corpus. However, different from (Liu et al.,\n2019), our approach exploits external data that are\nclosely related to the OLD task, and we propose a\nnew training strategy for domain adaptation.\nTransformers. Transformers (Vaswani et al.,\n2017) are developed to solve the issue of lack of\nparallelization faced by RNNs. In particular, Trans-\nTable 1: Details of OLID dataset.\nA B C Training Test Total\nOFF TIN IND 2,407 100 2,507\nOFF TIN OTH 395 35 430\nOFF TIN GRP 1,074 78 1,152\nOFF UNT — 524 27 551\nNOT — — 8,840 620 9,460\nALL — — 13,240 860 14,100\nformers calculate a score for each word with re-\nspect to every other word, in a parallel fashion.\nThe score between two words signiﬁes how related\nthey are. Due to the parallelization, transformers\ntrain rapidly on modern day GPUs. Some repre-\nsentative Transformer-based architectures for lan-\nguage modeling include BERT (Devlin et al., 2018),\nXL-NET (Yang et al., 2019) and ALBERT (Lan\net al., 2019). BERT employs the deep bidirectional\ntransformers architecture for model pretraining and\nlanguage understanding (Devlin et al., 2018). How-\never, BERT usually ignores the dependency be-\ntween the masked positions and thus there might\nbe discrepancy between model pretraining and ﬁne-\ntuning. XL-NET is proposed to address this issue,\nwhich is a generalized autoregressive pretraining\nmethod (Yang et al., 2019). Another issue of BERT\nis the intensive memory consumption during model\ntraining. Recently, some improved techniques such\nas ALBERT (Lan et al., 2019) are proposed to re-\nduce the memory requirement of BERT and there-\nfore increases the training speed. In this paper, we\nleverage the recent advances on Transformers and\ndesign a domain adaptation approach for the task\nof offensive language detection.\n3 Methodology\n3.1 Preliminary\nTarget Domain. In this work, we focus on the\noffensive language detection task on the OLID\ndataset, which is considered as target domain. The\nOLID dataset consists of real-world tweets and has\nthree interrelated subtasks/levels: (A) Detecting\nif a tweet is offensive ( OFF) or not ( NOT); (B)\nDetecting if OFF tweets are targeted (TIN) or un-\ntargeted (UNT) and; (C) Detecting if TIN tweets\nare targeted at an individual (IND), group (GRP) or\nmiscellaneous entity (OTH). The details of OLID\ndataset are summarized in Table 1. The following\nstrategies are used to preprocess the data. (1) Hash-\n3\nTable 2: Details of Toxcom Dataset.\nClassiﬁcation # of instances\nclean 143,346\ntoxic 15,294\nobscene 8,449\ninsult 7,877\nidentity hate 1,405\nsevere toxic 1,595\nthreat 478\ntag Segmentation. Hashtags are split up and the\npreceding hash symbol is removed. This is done\nusing wordsegment1. (2) Censored Word Conver-\nsion. A mapping is created of offensive words\nand their commonly used censored forms. All the\ncensored forms are converted to their uncensored\nforms. (3) Emoji Substitution.All emojis are con-\nverted to text using their corresponding language\nmeaning. This is done using Emoji 2. (4) Class\nWeights. The dataset is highly skewed at each level,\nthus a weighting scheme is used, as follows: Let\nthe classes be {c1, c2, ··· , ck}and number of sam-\nples in each class be {N1, N2, ··· , Nk}, then class\nci is assigned a weight of 1\nNi\n.\nSource Domain. To assist the OLD task in tar-\nget domain, we employ an external large-scale\ndataset on toxic comment (ToxCom) classiﬁcation3\nas source domain. ToxCom consists of 6 different\noffensive classes. Samples that belong to none of\nthe 6 classes are labelled as clean. The details of\nToxCom dataset are shown in Table 2. The num-\nber of clean comments is disproportionately high\nand will lead to considerable training time. Thus,\nonly 16,225 randomly sampled clean comments\nare employed.\n3.2 Domain Adaptation Approach\nWe propose a simple yet effective domain adapta-\ntion approach to train an ALBERT model for offen-\nsive language detection, which fully exploits auxil-\niary information from source domain to assist the\nlearning task in target domain. The effectiveness of\nusing auxiliary text for language understanding has\nbeen discussed in literature (Rezayi et al., 2021).\nBoth the source and target domains contain rich\ninformation about offensive contents, which makes\n1https://github.com/grantjenks/python-\nwordsegment\n2https://github.com/carpedm20/emoji\n3https://www.kaggle.com/c/jigsaw-\ntoxic-comment-classification-challenge/\ndata\nit possible to seek a shared feature space to facili-\ntate the classiﬁcation tasks. A naive solution is to\ncombine source and target datasets and simply train\na model on the merged dataset. This strategy, how-\never, may lead to degraded model performance for\ntwo reasons. First, two datasets are labelled in dif-\nferent ways, so that they don’t share the same label\nspace. Second, the divergence of data distributions\ndue to various data sources. In particular, the target\ndomain contains tweets, while the source domain is\ncollected from Wikipedia comments. The diverse\ndata sources lead to a signiﬁcant gap between two\ndomains, and therefore simply merging data from\ntwo domains is not an effective solution.\nTo address these issues, we propose the follow-\ning training procedures with three major steps. Let\nDS denote the source data and DT denote the tar-\nget dataset. First, we pretrain the ALBERT model\non the source domain (i.e., ToxCom dataset). The\nloss function of model training with source data is\ndeﬁned as:\nLS = argmin\nΘ\nALBERT(DS; Θ) (1)\nwhere Ls denotes the loss function, ALBERT(·)\nis the Transformer based ALBERT network, and\nΘ represents the model parameters. Second, we\nfreeze all the layers and discard the ﬁnal predictive\nlayer. Since two datasets have different labels, the\nﬁnal predictive layer could not contribute to the\ntask in target domain. Third, we reuse the frozen\nlayers with a newly added predictive layer, and\ntrain the network on the target dataset. The loss\nfunction of model ﬁnetuning with target data is\ndeﬁned as:\nLT = argmin\nˆΘ\nALBERT(DT ; Θ, ˆΘ), (2)\nwhere ˆΘ denotes the ﬁnetuned model parame-\nters. There are several ways to treat the previously\nfrozen layers in this step: (1) A feature extraction\ntype approach in which all layers remain frozen;\n(2) A ﬁnetuning type approach in which all layers\nare ﬁnetuned; and (3) A combination of both in\nwhich some layers are ﬁnetuned while some are\nfrozen. Finally, the updated model will be used to\nperform OLD task in the target domain.\nLet L denote the number of layers (including the\npredictive layer), NS denote the number of training\nsamples in the source domain, and NT denote the\nnumber of training samples in the target domain.\nK is the set of layers that remain frozen during\ntraining in the target domain.\n4\nFigure 1: Classwise F1 Scores across three levels.\nTable 3: Results. First three rows are previous state of\nthe art results at each level.\nModel A B C\nLiu et al. (2019) 0.8286 0.7159 0.5598\nHan et al. (2019) 0.6899 0.7545 0.5149\nNikolov and Radivchev (2019) 0.8153 0.6674 0.6597\nSVM 0.6896 0.6288 0.4831\nCNN (UP) 0.7552 0.6732 0.4984\nCNN 0.7875 0.7038 0.5185\nCNN (CW) 0.8057 0.7348 0.5460\nBERT 0.8023 0.7433 0.5936\nALBERT 0.8109 0.7560 0.6140\nALBERT (DA) 0.8241 0.8108 0.6790\n4 Experiments\n4.1 Baselines and Experimental Settings\nIn the experiments, four representative models are\nused as baselines, including the support vector\nmachines (SVM), convolutional neural networks\n(CNN), BERT and ALBERT. We use the base ver-\nsion of BERT and the large version of ALBERT.\nThe max sequence length is set to 32 and 64 for\nBERT and ALBERT, respectively. Training sam-\nples with length longer than max sequence length\nare discarded. Moreover, we compare our approach\nwith three state-of-the-art methods (Liu et al., 2019;\nHan et al., 2019; Nikolov and Radivchev, 2019) on\noffensive language detection.\nFor domain adaptation, the ﬁnetuning and fea-\nture extraction approaches, discussed in Section\n3.2, are tested. The feature extraction approach\ngives poor results on all three levels, with scores\nlower than ALBERT without domain adaptation.\nThe third method is not used as it introduces a\nnew hyperparameter, i.e., the number of trainable\nlayers, which would have to be optimized with\nconsiderable computational costs. The ﬁnetuning\ntype strategy gives good initial results and is used\nhenceforth. The learning rate is set to 1.5 ×10−5\nand 2 ×10−5 on the source data and target data,\nrespectively. Following the standard evaluation pro-\ntocol on the OLID dataset, the 9:1 training versus\nvalidation split is used. In each experiment (other\nthan SVM), the models are trained for 3 epochs.\nThe metric used here is macro F1 score, which is\ncalculated by taking the unweighted average for\nall classes. Best performing models according to\nvalidation loss are saved and used for testing.\n4.2 Results and Analysis\nTable 3 shows the results of baselines and our do-\nmain adaptation approach, ALBERT (DA). For\nTask A, deep learning methods, including CNN,\nBERT and ALBERT, always outperform the classi-\ncal classiﬁcation method SVM. ALBERT achieves\na macro F1 score of 0.8109, which is the highest\nscore without domain adaptation. Task C is unique\nas it consists of three labels. All models suffer on\nthe OTH class. This could be because the OTH\nclass consists of very few training samples. Our\napproach, ALBERT (DA), achieves the state-of-\nthe-art performance on Task C.\nFigure 1 further breaks down the classwise\nscores for analysis. The most notable improve-\nments are on OTH and UNT samples. ALBERT\n(DA) has an F1 score of 0.46, which is an im-\nprovement 43.75% over ALBERT on OTH sam-\nples. On UNT samples, ALBERT (DA) improves\nALBERT’s score of 0.55 to 0.65, which is an im-\nprovement of 18%. Conversely, performance on\nclasses on which the ALBERT already has high\nF1-scores, such as NOT and TIN, do not see ma-\njor improvements through domain adaptation. On\nNOT and TIN samples, ALBERT (DA) improves\nonly 1.11% and 1.06% over ALBERT, respectively.\n5 Conclusion\nIn this paper, we propose a simple yet effective\ndomain adaptation approach to train bidirectional\ntransformers for offensive language detection. Our\napproach effectively exploits external datasets that\nare relevant to offensive content classiﬁcation to\nenhance the detection performance on a target\ndataset. Experimental results show that our ap-\nproach, ALBERT (DA) obtains the state-of-the-\nart performance in most tasks, and it signiﬁcantly\nbeneﬁts underrepresented and under-performing\nclasses.\n5\nACKNOWLEDGMENTS\nWe would like to thank the anonymous reviewers\nfor their insightful comments. This research is\nsupported in part by the U.S. Army Research Ofﬁce\nAward under Grant Number W911NF-21-1-0109.\nReferences\nGabriel Araujo De Souza and Marjory Da Costa Abreu.\n2020. Automatic offensive language detection from\ntwitter data using machine learning and feature se-\nlection of metadata.\nThomas Davidson, Dana Warmsley, Michael W. Macy,\nand Ingmar Weber. 2017. Automated hate speech\ndetection and the problem of offensive language.\nCoRR, abs/1703.04009.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning.\nJiahui Han, Shengtan Wu, and Xinyu Liu. 2019.\njhan014 at SemEval-2019 task 6: Identifying and\ncategorizing offensive language in social media. In\nProceedings of the 13th International Workshop on\nSemantic Evaluation, pages 652–656, Minneapo-\nlis, Minnesota, USA. Association for Computational\nLinguistics.\nTuan Manh Lai, Trung Bui, Nedim Lipka, and Sheng\nLi. 2018. Supervised transfer learning for product\ninformation question answering. In IEEE Interna-\ntional Conference on Machine Learning and Appli-\ncations, pages 1109–1114.\nZhenzhong Lan, Mingda Chen, Sebastian Goodman,\nKevin Gimpel, Piyush Sharma, and Radu Soricut.\n2019. Albert: A lite bert for self-supervised learn-\ning of language representations.\nSheng Li and Yun Fu. 2016. Unsupervised transfer\nlearning via low-rank coding for image clustering.\nIn International Joint Conference on Neural Net-\nworks, pages 1795–1802.\nSheng Li, Kang Li, and Yun Fu. 2017. Self-taught\nlow-rank coding for visual learning. IEEE Trans-\nactions on Neural Networks and Learning Systems,\n29(3):645–656.\nPing Liu, Wen Li, and Liang Zou. 2019. NULI at\nSemEval-2019 task 6: Transfer learning for offen-\nsive language detection using bidirectional trans-\nformers. In Proceedings of the 13th Interna-\ntional Workshop on Semantic Evaluation, pages 87–\n91, Minneapolis, Minnesota, USA. Association for\nComputational Linguistics.\nAlex Nikolov and Victor Radivchev. 2019. Nikolov-\nradivchev at SemEval-2019 task 6: Offensive tweet\nclassiﬁcation with BERT and ensembles. In Pro-\nceedings of the 13th International Workshop on\nSemantic Evaluation, pages 691–695, Minneapo-\nlis, Minnesota, USA. Association for Computational\nLinguistics.\nSinno Jialin Pan and Qiang Yang. 2009. A survey on\ntransfer learning. IEEE Transactions on knowledge\nand data engineering, 22(10):1345–1359.\nJeffrey Pennington, Richard Socher, and Christopher\nManning. 2014. GloVe: Global vectors for word\nrepresentation. In Proceedings of the 2014 Confer-\nence on Empirical Methods in Natural Language\nProcessing (EMNLP) , pages 1532–1543, Doha,\nQatar. Association for Computational Linguistics.\nSaed Rezayi, Handong Zhao, Sungchul Kim, Ryan\nRossi, Nedim Lipka, and Sheng Li. 2021. Edge: En-\nriching knowledge graph embeddings with external\ntext. In Proceedings of the 2021 Conference of the\nNorth American Chapter of the Association for Com-\nputational Linguistics: Human Language Technolo-\ngies, pages 2767–2776.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. CoRR, abs/1706.03762.\nAlexander T. Vazsonyi, Hana Machackova, Anna Sev-\ncikova, David Smahel, and Alena Cerna. 2012. Cy-\nberbullying in context: Direct and indirect effects\nby low self-control across 25 european countries.\nEuropean Journal of Developmental Psychology ,\n9(2):210–227.\nMei Wang and Weihong Deng. 2018. Deep visual\ndomain adaptation: A survey. Neurocomputing,\n312:135–153.\nZeerak Waseem and Dirk Hovy. 2016. Hateful sym-\nbols or hateful people? predictive features for hate\nspeech detection on twitter. In Proceedings of the\nNAACL student research workshop, pages 88–93.\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime G. Car-\nbonell, Ruslan Salakhutdinov, and Quoc V . Le. 2019.\nXlnet: Generalized autoregressive pretraining for\nlanguage understanding. CoRR, abs/1906.08237.\nMarcos Zampieri, Shervin Malmasi, Preslav Nakov,\nSara Rosenthal, Noura Farra, and Ritesh Kumar.\n2019. Predicting the Type and Target of Offensive\nPosts in Social Media. In Proceedings of NAACL.\nRonghang Zhu, Xiaodong Jiang, Jiasen Lu, and Sheng\nLi. 2021. Transferable feature learning on graphs\nacross visual domains. In IEEE International Con-\nference on Multimedia and Expo.",
  "topic": "Exploit",
  "concepts": [
    {
      "name": "Exploit",
      "score": 0.8501580953598022
    },
    {
      "name": "Computer science",
      "score": 0.7876839637756348
    },
    {
      "name": "Offensive",
      "score": 0.7590610980987549
    },
    {
      "name": "Transformer",
      "score": 0.6817834377288818
    },
    {
      "name": "Domain adaptation",
      "score": 0.582396388053894
    },
    {
      "name": "Machine learning",
      "score": 0.5296751260757446
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.5227318406105042
    },
    {
      "name": "Artificial intelligence",
      "score": 0.507968008518219
    },
    {
      "name": "Training set",
      "score": 0.5078859925270081
    },
    {
      "name": "Labeled data",
      "score": 0.4675765335559845
    },
    {
      "name": "Language model",
      "score": 0.46535664796829224
    },
    {
      "name": "Scarcity",
      "score": 0.4412410259246826
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.4154224097728729
    },
    {
      "name": "Computer security",
      "score": 0.17626076936721802
    },
    {
      "name": "Engineering",
      "score": 0.13929018378257751
    },
    {
      "name": "Operations research",
      "score": 0.12173876166343689
    },
    {
      "name": "Voltage",
      "score": 0.07113879919052124
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Geodesy",
      "score": 0.0
    },
    {
      "name": "Classifier (UML)",
      "score": 0.0
    },
    {
      "name": "Geography",
      "score": 0.0
    },
    {
      "name": "Microeconomics",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    }
  ]
}