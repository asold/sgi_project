{
    "title": "StyleDGPT: Stylized Response Generation with Pre-trained Language Models",
    "url": "https://openalex.org/W3101893044",
    "year": 2020,
    "authors": [
        {
            "id": "https://openalex.org/A2147343871",
            "name": "Ze Yang",
            "affiliations": [
                "Beihang University"
            ]
        },
        {
            "id": "https://openalex.org/A1993208100",
            "name": "Wei Wu",
            "affiliations": [
                "Meizu (China)"
            ]
        },
        {
            "id": "https://openalex.org/A2098334175",
            "name": "Can Xu",
            "affiliations": [
                "Microsoft Research Asia (China)"
            ]
        },
        {
            "id": "https://openalex.org/A2944182475",
            "name": "Xinnian Liang",
            "affiliations": [
                "Beihang University"
            ]
        },
        {
            "id": "https://openalex.org/A2152955096",
            "name": "Jiaqi Bai",
            "affiliations": [
                "Beihang University"
            ]
        },
        {
            "id": "https://openalex.org/A2154420221",
            "name": "Liran Wang",
            "affiliations": [
                "Beihang University"
            ]
        },
        {
            "id": "https://openalex.org/A2009336559",
            "name": "Wei Wang",
            "affiliations": [
                "China Resources (China)"
            ]
        },
        {
            "id": "https://openalex.org/A2133880114",
            "name": "Zhoujun Li",
            "affiliations": [
                "Beihang University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4385245566",
        "https://openalex.org/W1591706642",
        "https://openalex.org/W2798888952",
        "https://openalex.org/W2970785611",
        "https://openalex.org/W2952335829",
        "https://openalex.org/W4287900772",
        "https://openalex.org/W2765617518",
        "https://openalex.org/W2951216772",
        "https://openalex.org/W4287824654",
        "https://openalex.org/W2962717182",
        "https://openalex.org/W2963667126",
        "https://openalex.org/W2613904329",
        "https://openalex.org/W2783549597",
        "https://openalex.org/W2952420867",
        "https://openalex.org/W2914120296",
        "https://openalex.org/W2997195635",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W4320013936",
        "https://openalex.org/W2914204778",
        "https://openalex.org/W3104078590",
        "https://openalex.org/W3000779003",
        "https://openalex.org/W2964121744",
        "https://openalex.org/W2996227762",
        "https://openalex.org/W2988937804",
        "https://openalex.org/W4288624561",
        "https://openalex.org/W2963206148",
        "https://openalex.org/W2130942839",
        "https://openalex.org/W2962896208",
        "https://openalex.org/W2963035145",
        "https://openalex.org/W2963825865",
        "https://openalex.org/W2916772188",
        "https://openalex.org/W2773330445",
        "https://openalex.org/W2547875792",
        "https://openalex.org/W2997892440",
        "https://openalex.org/W2964352131",
        "https://openalex.org/W2964309167",
        "https://openalex.org/W2133012565",
        "https://openalex.org/W2962917899",
        "https://openalex.org/W2962753250",
        "https://openalex.org/W2973330127",
        "https://openalex.org/W3022187094",
        "https://openalex.org/W2140679639",
        "https://openalex.org/W3013571468",
        "https://openalex.org/W2964008635",
        "https://openalex.org/W2521114121",
        "https://openalex.org/W1879024793",
        "https://openalex.org/W2964265128",
        "https://openalex.org/W2970597249",
        "https://openalex.org/W2963360026",
        "https://openalex.org/W2962796276",
        "https://openalex.org/W2963790827",
        "https://openalex.org/W2965373594",
        "https://openalex.org/W2155027007",
        "https://openalex.org/W2963995063",
        "https://openalex.org/W1597533204",
        "https://openalex.org/W2963963856",
        "https://openalex.org/W2963395792",
        "https://openalex.org/W2584185835",
        "https://openalex.org/W2963403868",
        "https://openalex.org/W2101105183",
        "https://openalex.org/W2962883855",
        "https://openalex.org/W4285719527",
        "https://openalex.org/W2914442349",
        "https://openalex.org/W2105767494",
        "https://openalex.org/W2154652894",
        "https://openalex.org/W1522301498",
        "https://openalex.org/W10957333",
        "https://openalex.org/W2099471712"
    ],
    "abstract": "Generating responses following a desired style has great potentials to extend applications of open-domain dialogue systems, yet is refrained by lacking of parallel data for training. In this work, we explore the challenging task with pre-trained language models that have brought breakthrough to various natural language tasks. To this end, we introduce a KL loss and a style classifier to the fine-tuning step in order to steer response generation towards the target style in both a word-level and a sentence-level. Comprehensive empirical studies with two public datasets indicate that our model can significantly outperform state-of-the-art methods in terms of both style consistency and contextual coherence.",
    "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1548–1559\nNovember 16 - 20, 2020.c⃝2020 Association for Computational Linguistics\n1548\nSTYLE DGPT: Stylized Response Generation with Pre-trained Language\nModels\nZe Yang1, Wei Wu2, Can Xu3, Xinnian Liang1, Jiaqi Bai1,\nLiran Wang1, Wei Wang4, and Zhoujun Li1∗\n1State Key Lab of Software Development Environment, Beihang University, Beijing, China\n2Meituan, Beijing, China 3Microsoft, Beijing, China 4China Resources Group\n{tobey,xnliang,bjq,wanglr,lizj}@buaa.edu.cn\n{wuwei19850318,ww.cs.tj}@gmail.com caxu@microsoft.com\nAbstract\nGenerating responses following a desired style\nhas great potentials to extend applications\nof open-domain dialogue systems, yet is re-\nfrained by lacking of parallel data for train-\ning. In this work, we explore the challeng-\ning task with pre-trained language models that\nhave brought breakthrough to various natural\nlanguage tasks. To this end, we introduce a\nKL loss and a style classiﬁer to the ﬁne-tuning\nstep in order to steer response generation to-\nwards the target style in both a word-level and\na sentence-level. Comprehensive empirical\nstudies with two public datasets indicate that\nour model can signiﬁcantly outperform state-\nof-the-art methods in terms of both style con-\nsistency and contextual coherence.\n1 Introduction\nWith advances in neural machine learning\n(Sutskever et al., 2014; Gehring et al., 2017;\nVaswani et al., 2017) and availability of huge\namount of human conversations on social media,\nthere has been signiﬁcant progress on building\nopen-domain dialogue systems with natural lan-\nguage generation techniques. Though neural gen-\nerative models are notorious for replying with\nbland responses (Li et al., 2015), some very recent\nwork demonstrates that response generation models\nlearned with pre-training techniques (Radford et al.,\n2019) can effectively overcome the deﬁciency suf-\nfered by previous models and are capable of having\nsmooth conversations with humans through reason-\nable and speciﬁc replies (Wolf et al., 2019; Zhang\net al., 2019b).\nThe compelling performance exhibited by the\npre-trained dialogue models encourages us to ex-\nplore more difﬁcult yet important problems in con-\nversational AI. In this work, we study stylized re-\nsponse generation, that is responses provided by a\n∗ Corresponding Author\nmodel should not only be coherent with the con-\nversation contexts, but also be consistent with a\ndesignated style. Such research could facilitate\ndevelopers to customize their dialogue systems in\nterms of response styles, and thus broaden appli-\ncations of the systems, from a social companion\n(Shum et al., 2018) or a virtual assistant (Ram et al.,\n2018) to a variety of vertical scenarios such as\ncustomer service (requiring a polite style), virtual\ncharacters in games (requiring speciﬁc personas),\nassistants in speciﬁc domains (requiring domain\nknowledge), etc. Normally, a target style is speci-\nﬁed by a non-conversational corpus (e.g., novels,\nnews, blogs, etc.) apart from the paired dialogue\ncorpus (Luan et al., 2017; Niu and Bansal, 2018;\nGao et al., 2019). Thus, the major challenge of the\ntask lies in the scarcity of paired data for learning\nthe correspondence between conversation contexts\nand proper responses in the desired style, which is\na key factor in success of the neural dialogue mod-\nels developed so far. As a result, it is very likely\nthat a response either digresses from the context of\nthe current dialogue (Luan et al., 2017; Gao et al.,\n2019), or loses ﬁdelity to the target style (Niu and\nBansal, 2018).\nWe consider addressing the challenge by taking\nadvantage of the large scale pre-trained language\nmodels. The basic idea is that deep neural language\nmodels learned from huge amount of text, such as\nGPT-2 (Radford et al., 2019) and DialoGPT (Zhang\net al., 2019b), have packed enough style knowledge\ninto their parameters (Dathathri et al., 2020), and\nthus by simply steering the distribution in decoding\ntowards the desired style, we can obtain both con-\ntextual coherence and style consistency. Following\nthe idea, we build a response generation model\non top of a pre-trained language model and devise\nboth a word-level loss and a sentence-level loss to\nﬁne-tune the pre-trained model towards the target\nstyle. The word-level loss regularizes the likeli-\n1549\nhood of response generation with a KL divergence\nterm between the probability of dialogues and the\nprobability of stylized language estimated by ﬁne-\ntuning a pre-trained language model on the style\ncorpus, while the sentence-level loss maximizes the\nlikelihood of a response given by the pre-trained\nresponse generation model being classiﬁed as a\nsentence matching the target style. We employ a\nGumbel trick to overcome the obstacle in back-\npropagation due to the discrete nature of natural\nlanguage when optimizing the sentence-level loss.\nThe ﬁnal response is selected by a sample-and-rank\nstrategy to further enhance relevance regarding to\nthe dialogue context and ﬁdelity regarding to the\ntarget style.\nWe name our model STYLE DGPT standing for\n“Stylized DialoGPT”. Empirical studies are con-\nducted on two tasks: arXiv-style response gener-\nation and Holmes-style response generation with\nthe data shared in (Gao et al., 2019), where re-\nsponses in the style of scientiﬁc papers and the\nstyle of Sherlock Holmes novels are pursued re-\nspectively for a given context. Besides the style\nintensity used in (Gao et al., 2019), we further\nexamine style consistency from both a lexical per-\nspective and a syntactic perspective with two new\nmetrics. Evaluation results on both automatic met-\nrics and human judgment indicate that our model\ncan signiﬁcantly outperform state-of-the-art meth-\nods. The code is available at https://github.\ncom/TobeyYang/StyleDGPT.\nOur contributions are three-fold: (1) proposal\nof tackling the problem of stylized response gen-\neration with pre-trained language models; (2) pro-\nposal of a word-level objective and a sentence-level\nobjective in ﬁne-tuning of a pre-trained language\nmodel for the task; and (3) empirical veriﬁcation of\nthe effectiveness of the proposed method on public\ndatasets.\n2 Related Work\nOpen-domain Dialogue Generation has re-\nceived more and more attention in NLP community.\nInspired by neural machine translation, early works\napply the sequence-to-sequence model to this task\nand achieve promising results (Ritter et al., 2011;\nShang et al., 2015; Vinyals and Le, 2015). Since\nthen, various architectures have been proposed to\naddress the key challenges in open-domain dia-\nlogue systems, including suppressing the generic\nresponses (Li et al., 2015; Zhao et al., 2017; Xing\net al., 2017a), context modeling (Serban et al.,\n2016, 2017; Xing et al., 2017b; Zhang et al., 2019a),\ncontrolling the attributes of responses (Xu et al.,\n2019; Zhou et al., 2017; Zhang et al., 2018a; Wang\net al., 2018; See et al., 2019) and incorporating dif-\nferent types knowledge into generation (Li et al.,\n2016; Zhang et al., 2018b; Zhou et al., 2017; Zhao\net al., 2020). In this work, we study the problem of\nstylized response generation, which aims to incor-\nporate the style information from non-parallel data\ninto the generation process.\nStylized Text Generation has attracted broad in-\nterest in recent years, especially the style transfer,\nwhich aims to alter one or more attributes of text\nwhile preserving the content. A prevalent idea of\nunsupervised style transfer is learning to separate\n“content” and “style” of text and manipulate the\nstyle to induce transfer at inference time (Li et al.,\n2018; Fu et al., 2018; John et al., 2019). How-\never, some works show that the disentanglement\ncannot be met and is not necessary, and leverage\ntechniques like reconstruction and back-translation\nintroduced in unsupervised machine translation\n(Lample et al., 2018), transformer (Dai et al., 2019)\nto achieve unsupervised style transfer. Different\nfrom style transfer, stylized response generation re-\nquires that the response is coherent with its context\nand the content can be varied. Akama et al. (2017)\nﬁrst train a basic model on a large-scale dialogue\ncorpus and then ﬁne-tune the model with a small\nstylized corpus. Niu and Bansal (2018) propose\nthree weakly-supervised methods to generate polite\nresponses using non-parallel data. Gao et al. (2019)\nbuild a structured latent space sharing between con-\nversation modeling and style transfer. However,\nlimited by the sparsity of the latent space, it is difﬁ-\ncult to balance the style and contextual coherence\nwhile sampling in the neighborhood of the latent\ncode of context at inference time.\nPretraining Methods have led remarkable suc-\ncess in various NLP tasks which demonstrates its\ngreat capabilities in language understanding and\ntext generation (Radford et al., 2018, 2019; De-\nvlin et al., 2019; Yang et al., 2019; Liu et al.,\n2019; Conneau and Lample, 2019; Clark et al.,\n2020). Recently, the pretraining methods have\nalso been used to tackle the key challenges in\ndialogue systems such as context representation\n(Mehri et al., 2019), response selection (Hender-\nson and Su, 2019), knowledge-grounded response\n1550\ngeneration (Zhao et al., 2020) and personalized\nresponse generation (Zheng et al., 2019). In partic-\nular, the large-scale pre-trained open-domain dia-\nlogue systems (Zhang et al., 2019b; Adiwardana\net al., 2020) make a large step towards human-like\nchatbot against previous works which rely on com-\nplex frameworks developed over many years. On\nthis basis, we propose to study the open-domain\nstylized response generation with pre-trained mod-\nels in this work.\n3 Problem Formalization\nSuppose that we have a dialogue corpus Dconv =\n{(Xi,Yi)}n\ni=1 and a style corpusDstyle = {Si}m\ni=1,\nwhere ∀(Xi,Yi) ∈Dconv, Xi is a conversation con-\ntext and Yi a response to Xi, and ∀Si ∈Dstyle, Si\nis a piece of text in the target style S. We do not\nassume that there exists pairs {(X,Y ′)}with Y′\nexpressed in the style S1, and Dstyle could be col-\nlected from text in an arbitrary style (e.g. scientiﬁc\npapers, novels, etc.). Our goal is to learn a genera-\ntion model P(Y|X,S) with both Dconv and Dstyle,\nand thus given a new context X, one can generate\na response Y that properly replies to the context X\nfollowing the style S.\n4 Approach\nWe employ DialoGPT (Zhang et al., 2019b) as the\ngeneral response generation model P(Y|X), and\ntry to bias P(Y|X) towards the language distri-\nbution P(S) estimated from Dstyle in ﬁne-tuning.\nBelow, we ﬁrst brieﬂy review the OpenAI GPT-2\n(Radford et al., 2019) and DialoGPT, which serve\nas the backbone of our model. Then, we introduce\ntwo learning objectives from both a word perspec-\ntive and a sentence perspective to interpolate style\nSinto response generation.\n4.1 Backbone Networks\nGPT-2 is a large transformer based generative\nmodel pre-trained with language modeling (Rad-\nford et al., 2019). Given a sequence X =\n(x0,··· ,xn), the generative probability p(X) can\nbe factorized as the product of conditional probabil-\nities over the tokens (Jelinek, 1980; Bengio et al.,\n2003):\np(X) =p(x0)\nn∏\ni=1\np(xi|x0,··· ,xi−1) (1)\n1Some pairs in Dconv may meet the condition, but there is\nnot an oracle that can tell us the information.\nGPT-2 uses a multi-layer transformer to model the\ndistributions in a recurrent way. At step t, let us\ndeﬁne Ht = [(K(1)\nt ,V(1)\nt ),··· ,(K(l)\nt ,V(l)\nt )] as\nthe past key-value matrices where (K(i)\nt ,V(i)\nt ) rep-\nresents the key-value pairs computed by the i-th\nlayer from step 0 to step t, then given the input\ntoken xt, the distribution of the next token xt+1\ncan be efﬁciently calculated using the cached Ht\nwhich is formulated as:\next = Ex∗\nt ,\noxt+1 ,Ht+1 = Transformer(ext,Ht),\np(xt+1|x0,··· ,xt) = softmax(Wo oxt+1 ),\n(2)\nwhere E ∈Rde×|V | is the word embedding ma-\ntrix with de the dimension and |V|the vocabu-\nlary size, x∗\nt ∈ R|V | is a one-hot vector corre-\nsponding to token xt, oxt+1 ∈ Rdc is the hid-\nden state at step t with dc the hidden size, and\nWo ∈R|V |×dc is a parameter matrix that maps\nthe hidden state oxt+1 to a logit vector in the size\nof |V|. At inference time, xt+1 is predicted fol-\nlowing p(xt+1|x0,··· ,xt). Moreover, GPT-2 can\nalso be used for language understanding. In this\nscenario, oX = (ox1 ,··· ,oxn+1 ) are treated as the\nrepresentations of sequence X.\nDialoGPT is a large conversational response gen-\neration model trained on 147M conversation-like\nexchanges from Reddit community (Zhang et al.,\n2019b). It inherits from GPT-2 and frames the re-\nsponse generation task as language modeling. For\na context-response pair (X,Y ), a special token\n⟨|endoftext|⟩is appended at the end of each dia-\nlogue turn and then all turns are concatenated into a\nlong sequence. Let M denote the length of the con-\ntext sub-sequence and (x0,··· ,xM−1,··· ,xN )\ndenote the dialogue sequence after concatenation,\nthe conditional generation probability of response\nY is deﬁned as:\np(Y|X) =\nN∏\ni=M\np(xi|x0,··· ,xi−1). (3)\n4.2 Response Style Controlling\nWord-Level Objective encourages the pre-\ntrained response generation model P(Y|X) (i.e.\nDialoGPT) to pick words expressing the desired\nstyle Sin decoding. Speciﬁcally, we train a lan-\nguage model P(S) with Dstyle on the basis of GPT-\n2 and use it as regularization to drive P(Y|X) to-\nwards P(S). It is inspired that if a response Y\nis not consistent with the style S, it will get high\n1551\nperplexity (i.e. Y is far from the language space\nof S). Furthermore, P(S) could not only provide\nan overall evaluation on the ﬁdelity of a response\nY, but also assign a direct probability distribution\nover the vocabulary at each step and thus provide\nword-level information about which words need to\nbe promoted in generation.\nFor each (X,Y ) ∈ Dconv, we denote pY =\n(py1 ,··· ,pym) (mis the length of Y) as the next-\nword distributions of Y given by P(Y|X). Mean-\nwhile, we feed Y into P(S) and obtain the next-\nword distributions ˆpY = (ˆpy1 ,··· ,ˆpym). Then the\nword-level objective is formulated as:\nLw = E(X,Y )∼Dconv d(pY ∥ˆpY ), (4)\nwhere d(pY ∥ˆpY ) could be any metrics measuring\nthe distance between pY and ˆpY . Here, we specify\nd(·∥·) as the Kullback-Leibler (KL) divergence.\nThen, d(pY ∥ˆpY ) =∑m\ni=1 DKL(pyi∥ˆpyi). At each\nstep, Lw modiﬁes the next-word distribution in\nthe direction of P(S) where the probabilities of\nwords with the desired style Swill be increased,\nwhich can encourage the selection of these words\nat inference time.\nSentence-level Objective modiﬁes P(Y|X) to-\nwards the target style Sfrom a syntactic and se-\nmantic perspective. In training, we hope that a\nresponse matching style Scould have more impact\nin guiding the optimization ofP(Y|X) towards the\ndesired direction. To this end, we ﬁrst train a dis-\ncriminative model P(S|X) to predict whether the\ninput sequence X matches the style S. Formally,\ngiven an input sequence X = (x0,··· ,xn), the\nprobability is deﬁned as:\np(S|X) = sigmoid(Wd ˆoX),\nˆoX = averagepooling(oX), (5)\nwhere oX = (ox1 ,··· ,oxn+1 ) are the representa-\ntions of X encoded by GPT-2, average pooling(·)\ndenotes the average pooling layer where the i-th\nelement ˆo(i)\nX is given by 1\nn+1\n∑n+1\nj=1 o(i)\nxj ,i ∈[1,dc],\nand Wd ∈R1×dc is a parameter. In the training\nphase, positive examples are sampled from Dstyle\nwhile negative examples are utterances sampled\nfrom Dconv 2. Then the sentence-level objective is\nformulated as:\nLs = E(X,Y )∼Dconv, ˜Y ∼P( ˜Y |X)[−log p(S|˜Y)].\n(6)\n2The ratio of the positive and the negative is 1 : 5in our\nexperiments.\nLs aims to regularize the output of the genera-\ntion model by ascending the probability given by\nthe discriminative model P(S|X), which is simi-\nlar to the optimization process of the generator in\nGANs (Goodfellow et al., 2014). The challenge\nis that since ˜Y is discrete, it is impossible to back-\npropagate through sampling from P(˜Y|X). Al-\nthough it can be circumvented by using the rein-\nforcement learning (RL) algorithm (Sutton et al.,\n2000), the performance is not satisfactory in our\nexperiments. In this work, we propose using the\nGumbel trick (Jang et al., 2016) to tackle the chal-\nlenge. At step t, instead of sampling a token from\np(xt+1|x0,··· ,xt), the input vector of step t+ 1\nis obtained by:\nx∗\nt+1 = gumbelsoftmax(Wo ot,τ), (7)\nwhere τ is the temperature and when τ → 0,\nx∗\nt+1 ∈R|V |becomes a one-hot vector.\nTraining Objective. The two objectives pre-\nsented above are able to drive P(Y|X) to generate\nresponses with desirable style S, but it will quickly\nresult in irrelevant responses as both of them only\nfocus on responses. To overcome this, we preserve\nthe negative log-likelihood (NLL) loss in DialoGPT\nto maintain the relevance between the context and\nresponse:\nLNLL = E(X,Y )∼Dconv [−log p(Y|X)] (8)\nThe ﬁnal training loss is the weighted sum of the\nword-level loss, sentence-level loss, and relevance\nloss:\nL= λw ·Lw + λs ·Ls + λNLL ·LNLL , (9)\nwhere λw, λs, λNLL are three weight scalars.\nSampling and Ranking. Because it is possible\nto generate non-stylized responses at inference\ntime, we employ the sample-and-rank decoding\nstrategy following Gao et al. (2019). First, we sam-\nple N independent candidate responses for each\ncontext by using top-ksampling method with tem-\nperature T. Then, we re-rank them in terms of both\nrelevance and style intensity and select the candi-\ndate with the highest score as the ﬁnal response.\nThe score of a candidateYi for context Xis deﬁned\nas\nscore(Yi) =β·p(Yi|X)+(1 −β)·p(S|Yi), (10)\nwhere p(Yi|X) measures relevance of Yi regarding\nto X, p(S|Yi) returns style intensity of Yi deﬁned\n1552\nby the discriminative model P(S|X), and β is a\nhyper-parameter.\n5 Experiments\n5.1 Datasets\nIn order to verify the effectiveness of our model,\nwe experiment on two tasks: generating arXiv-\nstyle and Holmes-style responses. The statistics of\ndatasets are summarized in Table 1. The datasets\nare constructed following the pipeline in Gao et al.\n(2019). The style corpus Dstyle for arXiv-style re-\nsponse generation task consists of ∼1M sentences\nthat are extracted from the LaTex source code of\npapers on website arXiv.org from 1998 to 2002 3.\nFor Holmes-style response generation task, Dstyle\ncontains ∼38k sentences built from ebooks of Sher-\nlock Holmes novel series downloaded from the\nsite Gutenberg.org 4. Both tasks share the same\nconversation dataset Dconv which consists of 10M\ncontext-response pairs extracted from user posts\nand comments on site Reddit.com during the year\n2011 5. The validation set Dval and the test set\nDtest are constructed by ﬁltering the Reddit data\nin 2013 with the classiﬁer in (Gao et al., 2019) (in-\ntensity score >0.4) 6. As Gao et al. (2019) do not\nrelease their test data, nor specify the size of the\ntest set, we randomly select 2k/2k samples as the\nvalidation/test sets, and each context has at least 4\nresponses.\nTask Training Validation Test\nDconv Dstyle Dval Dtest\narXiv-style Reddit arXiv arXiv-style Reddit\n10,000,000 1,347,538 2,000 2,000\nHolmes-style Reddit Holmes Holmes-style Reddit\n10,000,000 38,309 2,000 2,000\nTable 1: Tasks and datasets\n5.2 Evaluation Methodology\nWe compare different models with both automatic\nmetrics and human judgment.\nAutomatic Metrics. For automatic evaluation,\nwe measure the quality of generated responses from\nthree aspects: Style Consistency, Relevance, and\nDiversity. The relevance is measured with BLEU\n3downloaded from http://www.cs.cornell.edu/\nprojects/kddcup/datasets.html\n4http://www.gutenberg.org\n5We use the raw data collected by a third party http:\n//files.pushshift.io/reddit.\n6available at https://github.com/golsun/\nStyleFusion/tree/master/classifier\n(Papineni et al., 2002) and Rouge (Lin, 2004) 7. To\nevaluate diversity, we follow Li et al. (2015) and\nuse Distinct-1 (Dist-1) and Distinct-2 (Dist-2) as\nmetrics which are calculated as ratios of distinct\nunigrams and bigrams in responses, respectively.\nIn terms of style consistency, existing work only\nmeasures the style intensity using classiﬁers (Gao\net al., 2019). However, the style of text is an amal-\ngam, and differences between two styles are re-\nﬂected in multiple linguistic dimensions (Verma\nand Srinivasan, 2019). Thus, we propose to eval-\nuate the style of response from three perspectives:\n(1) Intensity: we report the scores from the discrim-\ninative model p(S|X)8. (2) Lexical: it is a word-\nlevel metric that measures the distance between\ntwo lexical distributions. We ﬁrst build a lexicon\nwith all the ngrams ( N = 1,2,3,4) from Dconv\nand Dstyle (i.e., Reddit, arXiv, and Holmes cor-\npora). To reduce noise, ngrams that occur less than\n10 times are ﬁltered out and there are 1,346,175\ndistinct ngrams left. Then the lexical distributions\nof a model and the target style can be represented as\nnormalized 1,346,175-dimensional vectors with\neach element the frequency of the corresponding\nngram in the generated responses (over the test set)\nand Dstyle respectively. Finally, we calculate the\nJensen-Shannon divergence (Fuglede and Topsoe,\n2004) to measure the distance of the two vectors.\n(3) Syntactic: it is a sentence-level metric. Moti-\nvated by Feng et al. (2012), the style of text can be\nrecognized by the ratio of the following 5 syntactic\ntypes: (a) simple; (b) compound; (c) complex; (d)\ncomplex-compound; (e) others. The type of a sen-\ntence is determined by the algorithm proposed by\nFeng et al. (2012) which relies on the PCFG tree\nparsed by the Stanford CoreNLP9. We compute the\ndistributions of the style corpus and responses gen-\nerated by models and report the Jensen-Shannon\ndivergence.\nHuman Evaluation. We recruit 3 well-educated\nnative speakers as annotators to compare our model\nwith each of the baselines. Each annotator checks\none context with two responses at a time with one\nresponse from our model and the other from a base-\n7Both metrics are computed by scripts of a public NLG\nevaluation project available at https://github.com/\nMaluuba/nlg-eval.\n8The evaluation is more accurate than that from the\nclassiﬁers available at https://github.com/golsun/\nStyleFusion/tree/master/classifier because\nof the capability of GPT-2.\n9https://stanfordnlp.github.io/CoreNLP\n1553\nModels\nStyle Consistency Relevance (↑) Diversity (↑)\nIntensity (↑) Lexical ( ↓) Syntactic ( ↓) BLEU1 BLEU2 RougeL Dist-1 Dist-2\narXiv-style Response Generation\nMTask (Luan et al., 2017) 0.284 0.7565 0.2653 13.42 3.56 11.53 0.040 0.091\nS2S+LM (Niu and Bansal, 2018) 0.399 0.7484 0.2549 15.25 4.62 10.41 0.052 0.273\nStyleFusion (Gao et al., 2019) 0.412 0.7582 0.2282 16.81 5.69 10.82 0.055 0.107\nDialoGPT (Zhang et al., 2019b) 0.208 0.6518 0.2561 17.84 5.20 10.68 0.296 0.711\nSTYLEDGPT 0.503 0.6237 0.1912 19.04 5.74 12.49 0.228 0.614\nHolmes-style Response Generation\nMTask (Luan et al., 2017) 0.276 0.7106 0.2356 24.47 8.87 16.03 0.027 0.063\nS2S+LM (Niu and Bansal, 2018) 0.450 0.5982 0.1959 25.32 9.15 14.82 0.051 0.304\nStyleFusion (Gao et al., 2019) 0.479 0.7023 0.1946 25.91 9.68 15.87 0.045 0.098\nDialoGPT (Zhang et al., 2019b) 0.282 0.5814 0.1598 27.19 8.31 14.78 0.172 0.589\nSTYLEDGPT 0.602 0.4807 0.0861 29.58 10.15 17.10 0.101 0.452\nTable 2: Evaluation results on automatic metrics. Numbers in bold indicate the best performing models under the\ncorresponding metrics. ↑/↓means higher/lower values are better, respectively. The unit for relevance is percentage.\nline model, and the two responses are shown in\nrandom order. The annotators then are asked to\ncompare them on four aspects: (1) Style Consis-\ntency: if the response exhibits the desired style S;\n(2) Fluency: if the response is ﬂuent without any\ngrammatical errors; (3) Relevance: if the response\nis coherent with the given context; and (4) Infor-\nmativeness: if the response is rich in content and\nthus could keep the conversation going. For each\naspect, if the annotator cannot tell which response\nis better, he/she is asked to label a “Tie”. For each\ntask, 200 test examples are sampled for annotation.\nEach pair of responses receive 3 labels on each of\nthe three aspects, and the agreement among the\nannotators are measured by Fleiss’ kappa (Fleiss\nand Cohen, 1973).\n5.3 Baselines\nWe compare our model with the following base-\nlines: (1) MTask: a vanilla multi-task learning\nmodel proposed by Luan et al. (2017) trained with\nboth Dconv and Dstyle. We use the code imple-\nmented by Gao et al. (2019) included in the project\nhttps://github.com/golsun/StyleFusion. (2)\nS2S+LM: the fusion model proposed by Niu\nand Bansal (2018) that merges the decoder of a\nseq2seq model trained on Dconv and a language\nmodel trained on Dstyle by weighted averaging\nthe word distributions at inference time. We\nuse the code published at https://github.com/\nWolfNiu/polite-dialogue-generation. (3)\nStyleFusion: the regularized multi-task learning\nmodel proposed by Gao et al. (2019) which builds\na structured latent space to bridge the conversa-\ntion modeling and style transfer. The model is\njointly learned with Dconv and Dstyle. We run the\ncode released at https://github.com/golsun/\nStyleFusion with default settings. (4) DialoGPT:\nan open-domain pre-trained response generation\nmodel built upon GPT-2 that attains a performance\nclose to human (Zhang et al., 2019b). We use\nthe 345M ﬁne-tuned model which can be down-\nloaded from https://github.com/microsoft/\nDialoGPT.\n5.4 Implementation Details\nOur models are implemented with the Hugging-\nface transformers repository 10. To balance cost\nand effect, the language model P(S) and the dis-\ncriminative model P(S|X) are built upon GPT-2\n(117M) with 12 layers and 768 hidden units. The\nembedding layer and the transformer module are\nshared between two models, and we only opti-\nmize the parameters of the projection layer and\nthe classiﬁcation layer, respectively. We choose\nDialoGPT (345M) as the basis of STYLE DGPT\nwhich has 24 layers and 1024 hidden units. In\nboth tasks, we use the vocabulary published along\nwith GPT-2 by OpenAI that contains 50,257 to-\nkens. The temperature τ of gumabel softmax\nis set as 0.1. Hyper-parameters are selected\nvia grid search, and λw/λs/λr are ﬁnally set as\n0.0005/0.05/1 for the arXiv-style response gener-\nation task and 0.005/0.05/1 for the Holmes-style\nresponse generation task, respectively. All models\nare trained with the Adam optimizer (Kingma and\nBa, 2015) (β1 = 0.9, β2 = 0.999) with a learning\nrate of 5 ×10−7. We choose k= 40and T = 1.0\nin top-kdecoding following (Radford et al., 2019;\nAdiwardana et al., 2020). At inference time, all\napproaches including our model and baselines gen-\nerate 50 candidates for each context (i.e. N = 50),\nand the top one candidate is selected for evaluation\n10https://github.com/huggingface/\ntransformers\n1554\nModels Style Consistency Fluency Relevance Informativeness KappaW(%) L( %) T( %) W(%) L( %) T( %) W(%) L( %) T( %) W(%) L( %) T( %)\narXiv-style Response Generation\nSTYLEDGPT vs. MTask 43.6 25.2 31.2 25.5 20.0 54.5 31.3 20.5 48.2 37.4 20.0 43.6 0.62\nSTYLEDGPT vs. S2S+LM 41.7 21.6 36.7 39.0 7.8 53.2 53.3 10.3 36.4 38.2 17.3 44.5 0.67\nSTYLEDGPT vs. StyleFusion38.2 18.4 43.4 23.6 18.3 58.1 38.0 16.2 45.8 31.8 15.2 53.0 0.65\nSTYLEDGPT vs. DialoGPT 51.3 10.2 38.5 16.2 21.8 62.0 21.2 26.5 52.3 23.2 23.8 53.0 0.61\nHolmes-style Response Generation\nSTYLEDGPT vs. MTask 46.3 13.8 39.1 28.0 14.8 57.2 43.8 15.4 40.8 36.8 12.0 51.2 0.65\nSTYLEDGPT vs. S2S+LM 45.0 19.5 35.5 36.3 4.8 58.9 52.2 9.0 38.8 38.6 16.3 45.1 0.61\nSTYLEDGPT vs. StyleFusion36.2 18.0 45.8 31.4 11.5 57.1 36.0 17.5 46.5 41.3 12.2 46.5 0.70\nSTYLEDGPT vs. DialoGPT 52.0 13.3 34.7 14.4 12.6 73.0 19.3 20.5 60.2 22.6 15.8 61.6 0.63\nTable 3: Human annotation results. W, L, and T refer to Win, Lose, and Tie, respectively. The ratios are calculated\nby combining labels from the three annotators.\nModels\nStyle Consistency Relevance (↑) Diversity (↑)\nIntensity (↑) Lexical ( ↓) Syntactic ( ↓) BLEU1 BLEU2 RougeL Dist-1 Dist-2\narXiv-style Response Generation\nSTYLEDGPT 0.503 0.6237 0.1912 19.04 5.74 12.49 0.228 0.614\nSTYLEDGPT (w/o Lw) 0.378 0.6357 0.2165 18.66 5.69 11.84 0.260 0.651\nSTYLEDGPT (w/o Ls) 0.670 0.6213 0.2177 17.28 4.85 11.39 0.182 0.564\nSTYLEDGPT (w/o LNLL) 0.880 0.5712 0.1594 13.16 4.08 11.86 0.046 0.273\nHolmes-style Response Generation\nSTYLEDGPT 0.602 0.4807 0.0861 29.58 10.15 17.10 0.101 0.452\nSTYLEDGPT (w/o Lw) 0.497 0.5007 0.1194 29.21 9.34 16.14 0.130 0.514\nSTYLEDGPT (w/o Ls) 0.680 0.4716 0.1551 27.89 9.22 16.54 0.097 0.459\nSTYLEDGPT (w/o LNLL) 0.891 0.4709 0.1521 26.54 8.56 15.53 0.049 0.298\nTable 4: Ablation results on automatic metrics.\naccording to Equation (10).\n5.5 Evaluation Results\nAutomatic Evaluation. Table 2 reports the eval-\nuation results on automatic metrics. Without\nany complicated manipulation on latent spaces,\nSTYLE DGPT outperforms the non-pre-trained\nbaselines with large margins on all metrics in\nboth tasks, demonstrating the advantage of pre-\ntraining over the state-of-the-art method in stylized\nresponse generation. The signiﬁcant improvement\nover the vanilla DialoGPT on style consistency in-\ndicates that STYLE DGPT can effectively leverage\nthe extra objectives and bias response decoding to-\nwards the desired style. Moreover, it seems that\nforcing responses to a particular style (i.e., arXiv\nstyle and Holmes style) is also helpful in relevance,\nthough there is a sacriﬁce on diversity. This is be-\ncause the search space in decoding now becomes\nmore concentrated on words that can express the\ntarget styles11.\nHuman Evaluation. Table 3 reports the results\nof human evaluation. The values of kappa are all\nabove 0.6, indicating substantial agreement among\nthe three annotators. We can see STYLE DGPT\n11Note that human responses for calculating the relevance\nmetrics are biased to the target styles according to a style\nclassiﬁer.\noutperforms all non-pre-trained baselines on the\nthree aspects, which echoes the results of auto-\nmatic evaluation. Speciﬁcally, S2S+LM achieves\npoor performance on ﬂuency because the weighted\naverage of the token distributions predicted by the\nlanguage model and the seq2seq decoder harms\ntheir attributes of language modeling, which also\nleads to low relevance. Compared to DialoGPT, we\nnotice that STYLE DGPT signiﬁcantly improves\nupon style consistency while achieves compara-\nble performance on relevance and informativeness,\nwhich demonstrates the effectiveness of the pro-\nposed objectives in ﬁne-tuning.\n5.6 Discussions\nAblation Study. To understand the roles of Lw,\nLs, and LNLL in learning to generate stylized re-\nsponses, we remove them one at a time from the\nfull objective in Equation (9), and then check the\nperformance of the variants ofSTYLE DGPT on the\ntest sets. Table 4 reports the evaluation results. We\ncan see that (1) all the three objectives are useful,\nas removing any of them will cause a performance\ndrop on some metrics; (2) Lw is more important\nto lexical consistency while Ls is more important\nto syntactic consistency, which echoes our motiva-\ntion in design of the two objectives; and (3) without\nLNLL , the model will be misled by the style corpus\n1555\n5k 15k 25k 35k 45k 55k\nTraining Steps\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0Intensity\n5k 15k 25k 35k 45k 55k\nTraining Steps\n0.50\n0.55\n0.60\n0.65\n0.70Dist-2\n5k 15k 25k 35k 45k 55k\nTraining Steps\n0.14\n0.16\n0.18\n0.20BLEU1\n5k 15k 25k 35k 45k 55k\nTraining Steps\n0.04\n0.06\n0.08\n0.10\n0.12\n0.14RougeL\nStyleDGPT (w/o w)\n (w/o s)\n (w/o NLL)\n (w/o w & s)\nFigure 1: Trajectories of ablated S TYLE DGPT on the\nvalidation set of arXiv-style response generation.\nand lose the connection with conversation contexts.\nSince Lw, Ls, and LNLL are coordinated in\nlearning of STYLE DGPT , more insights about the\neffect of the objectives can be obtained by checking\nthe trajectories of the variants on validation, as illus-\ntrated by Figure 112. Without Ls, there is a steady\nand signiﬁcant improvement on style intensity but\ndramatic drops on BLEU1, RougeL, and Dist-2\n(compared with the model without both Ls and\nLw), which indicates that Lw can provide stronger\nguidance regarding style expression than Ls. On\nthe other hand, comparing STYLE DGPT w/o Lw\nand STYLE DGPT w/o Lw & Ls, we ﬁnd that Ls\ncan gradually and moderately improve upon style\nintensity and relevance with only a little hurt on di-\nversity. Finally, when LNLL is removed, the model\nwill quickly forget conversation contexts and con-\nverge to the style language model. The full model\nbalances the effect of the three losses and attains\nboth style consistency and contextual coherence,\nthough it has to suffer from diversity drop due to\nthe existence of Lw.\nImpact of the Sampling NumberN. To under-\nstand how the sample-and-rank strategy affects\nmodel performance, we evaluateSTYLE DGPT and\nStyleFusion by varying the sampling number N\nin {1,10,30,50}on both tasks. Figure 2 shows\nthe results. We observe that (1) style intensity is\nmore sensitive to the value of N than other met-\nrics; (2) though the two models are comparable in\n12Similar trends are observed on Holmes-style response\ngeneration.\n1 10 30 50\nNum Samples\n0.0\n0.2\n0.4\n0.6\n0.8Intensity\n1 10 30 50\nNum Samples\n0.0\n0.2\n0.4\n0.6\n0.8Dist-2\n1 10 30 50\nNum Samples\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35BLEU1\n1 10 30 50\nNum Samples\n0.05\n0.10\n0.15\n0.20RougeL\nStyleDGPT-arXiv\nStyleDGPT-Holmes\nStyleFusion-arXiv\nStyleFusion-Holmes\nFigure 2: Comparisons over the number of sampled\ncandidates on both tasks.\nterms of style intensity whenN = 1, STYLE DGPT\ncan exhibit the desired styles with fewer samples;\n(3) STYLE DGPT is always better than StyleFu-\nsion on Dist-2, thanks to DialoGPT; and (4) while\nSTYLE DGPT is able to attain both style consis-\ntency and contextual coherence with enough sam-\nples, it is difﬁcult for StyleFusion to balance the\ntwo aspects, as whenNincreases, both BLEU1 and\nRougeL drop. This is because when sampling in\nthe neighborhood of the representation of a context\nin the structured latent space, reaching a stylized\nbut less relevant point becomes easier when the\nnumber of samples increases.\nCase Study. Finally, we conduct qualitative anal-\nysis with some examples given in Table 5 and Ta-\nble 6. First, we ﬁnd that the non-pre-trained mod-\nels can generate interesting responses occasionally\n(e.g., “the ring of ﬁre” and “the ﬁrst harry pot-\nter movie.” in Table 6), but they are not always\ncoherent with the contexts nor speciﬁc. In con-\ntrast, responses from the pre-trained models (i.e.,\nDialoGPT and STYLE DGPT) are highly coherent\nwith the contexts and rich in content. In terms of\nstyle consistency, responses given bySTYLE DGPT\nare more stylized that contain more words speciﬁc\nto a certain style. For example, “constant state” and\n“quantum ﬂuctuations” are concepts in physical sci-\nence, “the behavior” of “species” is the research\nobject of ethology, and “accident”, “investigate”,\n“discover” and “trap” are topical words in the Sher-\nlock Holmes novel series.\n1556\nContext We’ve reached the peak of human intelli-\ngence.\nMTask i think you’re missing the point.\nS2S+LM i think that’s a pretty good idea.\nStyleFusion i don’t know what’s going on.\nDialoGPT It is going to get a little higher and higher\nevery couple of months.\nSTYLE -\nDGPT\nso what happens once we reach a constant\nstate of quantum ﬂuctuations?\nHuman This is like pure consciousness thinking of\nconsciousness, the rational endpoint of the\nenlightenment dialectic.\nContext My rabbit does this every day.. not sure\nwhat he’s thinking about.\nMTask i’m not sure what is going on here.\nS2S+LM i think that’s a cute cat.\nStyleFusion i’m guessing he’s a male or female.\nDialoGPT He was thinking of lubing his ears.\nSTYLE -\nDGPT\nThis is a very good point and i also would\nlike to discuss some other differences in the\nbehavior of this species.\nHuman some sort of inner monologue.\nTable 5: The example outputs on the arXiv-style re-\nsponse generation task.\nContext What is your favorite short story ?\nMTask the ﬁrst time i saw this i thought it was a\ngood idea to put a ring on it.\nS2S+LM the ending is a good thing and the most\nawesome thing i ’ve done\nStyleFusion the ring of ﬁre\nDialoGPT The Last Question by David Foster Wallace\nSTYLE -\nDGPT\nThe one about the day before the accident,\nabout an old lady who used to live in a\nshack.\nHuman The multitude of short stories that my wife\nwrites\nContext If your username was a movie, what would\nbe the plot?\nMTask the ﬁrst harry potter movie.\nS2S+LM there’s a lot of things about the movie.\nStyleFusion it’s a trap!\nDialoGPT Probably The Prestige\nSTYLE -\nDGPT\na story of a mad scientist who goes in to\ninvestigate something and discovers he’s\ntrapped in a cave\nHuman two lovers escape to the great northwest\nTable 6: The example outputs on the Holmes-style re-\nsponse generation task.\n6 Conclusions\nWe exploit the pre-trained language models on the\nstylized response generation task. To incorporate\nthe style information from the non-parallel data into\nthe generation model, we propose two learning ob-\njectives from word level and sentence level to steer\nthe output distribution towards the desired style.\nEvaluation results on arXiv-style and Holmes-style\nresponse generation tasks indicate the effectiveness\nof the proposed approach.\nAcknowledgment\nThis work was supported in part by the Na-\ntional Natural Science Foundation of China (Grant\nNos.U1636211, 61672081, 61370126), the Beijing\nAdvanced Innovation Center for Imaging Technol-\nogy (Grant No.BAICIT2016001), and the Fund of\nthe State Key Laboratory of Software Development\nEnvironment (Grant No.SKLSDE2019ZX-17).\nReferences\nDaniel Adiwardana, Minh-Thang Luong, David R So,\nJamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang,\nApoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu,\net al. 2020. Towards a human-like open-domain\nchatbot. arXiv preprint arXiv:2001.09977.\nReina Akama, Kazuaki Inada, Naoya Inoue, Sosuke\nKobayashi, and Kentaro Inui. 2017. Generating\nstylistically consistent dialog responses with transfer\nlearning. In Proceedings of the Eighth International\nJoint Conference on Natural Language Processing\n(Volume 2: Short Papers), pages 408–412, Taipei,\nTaiwan. Asian Federation of Natural Language Pro-\ncessing.\nYoshua Bengio, R´ejean Ducharme, Pascal Vincent, and\nChristian Jauvin. 2003. A neural probabilistic lan-\nguage model. Journal of machine learning research,\n3(Feb):1137–1155.\nKevin Clark, Minh-Thang Luong, Quoc V Le, and\nChristopher D Manning. 2020. Electra: Pre-training\ntext encoders as discriminators rather than genera-\ntors. arXiv preprint arXiv:2003.10555.\nAlexis Conneau and Guillaume Lample. 2019. Cross-\nlingual language model pretraining. In Advances\nin Neural Information Processing Systems, pages\n7057–7067.\nNing Dai, Jianze Liang, Xipeng Qiu, and Xuanjing\nHuang. 2019. Style transformer: Unpaired text\nstyle transfer without disentangled latent represen-\ntation. In Proceedings of the 57th Annual Meet-\ning of the Association for Computational Linguis-\ntics, pages 5997–6007, Florence, Italy. Association\nfor Computational Linguistics.\nSumanth Dathathri, Andrea Madotto, Janice Lan, Jane\nHung, Eric Frank, Piero Molino, Jason Yosinski, and\nRosanne Liu. 2020. Plug and play language mod-\nels: A simple approach to controlled text generation.\nIn International Conference on Learning Represen-\ntations.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\n1557\nTechnologies, Volume 1 (Long and Short Papers),\npages 4171–4186, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\nSong Feng, Ritwik Banerjee, and Yejin Choi. 2012.\nCharacterizing stylistic elements in syntactic struc-\nture. In Proceedings of the 2012 Joint Conference\non Empirical Methods in Natural Language Process-\ning and Computational Natural Language Learning,\npages 1522–1533, Jeju Island, Korea. Association\nfor Computational Linguistics.\nJoseph L Fleiss and Jacob Cohen. 1973. The equiv-\nalence of weighted kappa and the intraclass corre-\nlation coefﬁcient as measures of reliability. Educa-\ntional and psychological measurement, 33(3):613–\n619.\nZhenxin Fu, Xiaoye Tan, Nanyun Peng, Dongyan Zhao,\nand Rui Yan. 2018. Style transfer in text: Explo-\nration and evaluation.\nB. Fuglede and F. Topsoe. 2004. Jensen-shannon diver-\ngence and hilbert space embedding. In International\nSymposium onInformation Theory, 2004. ISIT 2004.\nProceedings., pages 31–.\nXiang Gao, Yizhe Zhang, Sungjin Lee, Michel Galley,\nChris Brockett, Jianfeng Gao, and Bill Dolan. 2019.\nStructuring latent spaces for stylized response gen-\neration. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP), pages\n1814–1823, Hong Kong, China. Association for\nComputational Linguistics.\nJonas Gehring, Michael Auli, David Grangier, Denis\nYarats, and Yann N Dauphin. 2017. Convolutional\nsequence to sequence learning. In Proceedings\nof the 34th International Conference on Machine\nLearning-Volume 70, pages 1243–1252. JMLR. org.\nIan Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,\nBing Xu, David Warde-Farley, Sherjil Ozair, Aaron\nCourville, and Yoshua Bengio. 2014. Generative ad-\nversarial nets. In Advances in neural information\nprocessing systems, pages 2672–2680.\nMatthew Henderson and Pei-Hao Su. 2019. Con-\nvert: Efﬁcient and accurate conversational rep-\nresentations from transformers. arXiv preprint\narXiv:1911.03688.\nEric Jang, Shixiang Gu, and Ben Poole. 2016. Categor-\nical reparameterization with gumbel-softmax. arXiv\npreprint arXiv:1611.01144.\nFrederick Jelinek. 1980. Interpolated estimation of\nmarkov source parameters from sparse data. InProc.\nWorkshop on Pattern Recognition in Practice, 1980.\nVineet John, Lili Mou, Hareesh Bahuleyan, and Olga\nVechtomova. 2019. Disentangled representation\nlearning for non-parallel text style transfer. In Pro-\nceedings of the 57th Annual Meeting of the Associa-\ntion for Computational Linguistics, pages 424–434,\nFlorence, Italy. Association for Computational Lin-\nguistics.\nDiederik P Kingma and Jimmy Ba. 2015. Adam: A\nmethod for stochastic optimization. In ICLR.\nGuillaume Lample, Sandeep Subramanian, Eric Smith,\nLudovic Denoyer, Marc’Aurelio Ranzato, and Y-\nLan Boureau. 2018. Multiple-attribute text rewrit-\ning.\nJiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao,\nand Bill Dolan. 2015. A diversity-promoting objec-\ntive function for neural conversation models. InPro-\nceedings of the 2016 Conference of the North Amer-\nican Chapter of the Association for Computational\nLinguistics: Human Language Technologies, pages\n110–119.\nJiwei Li, Michel Galley, Chris Brockett, Georgios Sp-\nithourakis, Jianfeng Gao, and Bill Dolan. 2016. A\npersona-based neural conversation model. In ACL,\npages 994–1003.\nJuncen Li, Robin Jia, He He, and Percy Liang. 2018.\nDelete, retrieve, generate: a simple approach to sen-\ntiment and style transfer. In Proceedings of the 2018\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, Volume 1 (Long Papers),\npages 1865–1874, New Orleans, Louisiana. Associ-\nation for Computational Linguistics.\nChin-Yew Lin. 2004. Rouge: A package for auto-\nmatic evaluation of summaries. Text Summarization\nBranches Out.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach.\nYi Luan, Chris Brockett, Bill Dolan, Jianfeng Gao,\nand Michel Galley. 2017. Multi-task learning for\nspeaker-role adaptation in neural conversation mod-\nels. In Proceedings of the Eighth International Joint\nConference on Natural Language Processing (Vol-\nume 1: Long Papers), pages 605–614, Taipei, Tai-\nwan. Asian Federation of Natural Language Process-\ning.\nShikib Mehri, Evgeniia Razumovskaia, Tiancheng\nZhao, and Maxine Eskenazi. 2019. Pretraining\nmethods for dialog context representation learning.\nIn Proceedings of the 57th Annual Meeting of the\nAssociation for Computational Linguistics, pages\n3836–3845, Florence, Italy. Association for Compu-\ntational Linguistics.\nTong Niu and Mohit Bansal. 2018. Polite dialogue gen-\neration without parallel data. Transactions of the As-\nsociation for Computational Linguistics, 6:373–389.\n1558\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic eval-\nuation of machine translation. In Proceedings of the\n40th Annual Meeting of the Association for Compu-\ntational Linguistics, pages 311–318.\nAlec Radford, Karthik Narasimhan, Tim Salimans,\nand Ilya Sutskever. 2018. Improving language\nunderstanding by generative pre-training. URL\nhttps://s3-us-west-2. amazonaws. com/openai-\nassets/researchcovers/languageunsupervised/language\nunderstanding paper. pdf.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nBlog, 1(8):9.\nAshwin Ram, Rohit Prasad, Chandra Khatri, Anu\nVenkatesh, Raefer Gabriel, Qing Liu, Jeff Nunn,\nBehnam Hedayatnia, Ming Cheng, Ashish Nagar,\net al. 2018. Conversational ai: The science behind\nthe alexa prize. arXiv preprint arXiv:1801.03604.\nAlan Ritter, Colin Cherry, and William B Dolan. 2011.\nData-driven response generation in social media. In\nProceedings of the 2011 Conference on Empirical\nMethods in Natural Language Processing, pages\n583–593.\nAbigail See, Stephen Roller, Douwe Kiela, and Jason\nWeston. 2019. What makes a good conversation?\nhow controllable attributes affect human judgments.\narXiv preprint arXiv:1902.08654.\nIulian Vlad Serban, Alessandro Sordoni, Yoshua Ben-\ngio, Aaron C Courville, and Joelle Pineau. 2016.\nBuilding end-to-end dialogue systems using gener-\native hierarchical neural network models. In AAAI,\nvolume 16, pages 3776–3784.\nIulian Vlad Serban, Alessandro Sordoni, Ryan Lowe,\nLaurent Charlin, Joelle Pineau, Aaron C Courville,\nand Yoshua Bengio. 2017. A hierarchical latent\nvariable encoder-decoder model for generating dia-\nlogues. In AAAI, pages 3295–3301.\nLifeng Shang, Zhengdong Lu, and Hang Li. 2015. Neu-\nral responding machine for short-text conversation.\nIn ACL, pages 1577–1586.\nHeung-Yeung Shum, Xiaodong He, and Di Li. 2018.\nFrom eliza to xiaoice: Challenges and opportunities\nwith social chatbots. Frontiers of IT & EE, 19(1):10–\n26.\nIlya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.\nSequence to sequence learning with neural networks.\nIn Advances in neural information processing sys-\ntems, pages 3104–3112.\nRichard S Sutton, David A McAllester, Satinder P\nSingh, and Yishay Mansour. 2000. Policy gradient\nmethods for reinforcement learning with function ap-\nproximation. In Advances in neural information pro-\ncessing systems, pages 1057–1063.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in neural information pro-\ncessing systems, pages 5998–6008.\nGaurav Verma and Balaji Vasan Srinivasan. 2019.\nA lexical, syntactic, and semantic perspective\nfor understanding style in text. arXiv preprint\narXiv:1909.08349.\nOriol Vinyals and Quoc Le. 2015. A neural conversa-\ntional model. arXiv preprint arXiv:1506.05869.\nYansen Wang, Chenyi Liu, Minlie Huang, and Liqiang\nNie. 2018. Learning to ask questions in open-\ndomain conversational systems with typed decoders.\nIn Proceedings of the 56th Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n1: Long Papers), pages 2193–2203.\nThomas Wolf, Victor Sanh, Julien Chaumond, and\nClement Delangue. 2019. Transfertransfo: A\ntransfer learning approach for neural network\nbased conversational agents. arXiv preprint\narXiv:1901.08149.\nChen Xing, Wei Wu, Jie Liu, Yalou Huang, Ming Zhou,\nand Wei-Ying Ma. 2017a. Topic aware neural re-\nsponse generation. In AAAI, pages 3351–3357.\nChen Xing, Wei Wu, Yu Wu, Ming Zhou, Yalou Huang,\nand Wei-Ying Ma. 2017b. Hierarchical recurrent\nattention network for response generation. arXiv\npreprint arXiv:1701.07149.\nCan Xu, Wei Wu, Chongyang Tao, Huang Hu, Matt\nSchuerman, and Ying Wang. 2019. Neural re-\nsponse generation with meta-words. arXiv preprint\narXiv:1906.06050.\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-\nbonell, Russ R Salakhutdinov, and Quoc V Le. 2019.\nXlnet: Generalized autoregressive pretraining for\nlanguage understanding. In Advances in neural in-\nformation processing systems, pages 5754–5764.\nHainan Zhang, Yanyan Lan, Liang Pang, Jiafeng Guo,\nand Xueqi Cheng. 2019a. Recosa: Detecting the rel-\nevant contexts with self-attention for multi-turn di-\nalogue generation. In Proceedings of the 57th An-\nnual Meeting of the Association for Computational\nLinguistics, pages 3721–3730.\nRuqing Zhang, Jiafeng Guo, Yixing Fan, Yanyan Lan,\nJun Xu, and Xueqi Cheng. 2018a. Learning to con-\ntrol the speciﬁcity in neural response generation. In\nProceedings of the 56th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers), pages 1108–1117.\nSaizheng Zhang, Emily Dinan, Jack Urbanek, Arthur\nSzlam, Douwe Kiela, and Jason Weston. 2018b. Per-\nsonalizing dialogue agents: I have a dog, do you\nhave pets too? arXiv preprint arXiv:1801.07243.\n1559\nYizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen,\nChris Brockett, Xiang Gao, Jianfeng Gao, Jingjing\nLiu, and Bill Dolan. 2019b. Dialogpt: Large-scale\ngenerative pre-training for conversational response\ngeneration. arXiv preprint arXiv:1911.00536.\nTiancheng Zhao, Ran Zhao, and Maxine Eskenazi.\n2017. Learning discourse-level diversity for neural\ndialog models using conditional variational autoen-\ncoders. In ACL, pages 654–664.\nXueliang Zhao, Wei Wu, Chongyang Tao, Can Xu,\nDongyan Zhao, and Rui Yan. 2020. Low-resource\nknowledge-grounded dialogue generation. arXiv\npreprint arXiv:2002.10348.\nYinhe Zheng, Rongsheng Zhang, Xiaoxi Mao, and\nMinlie Huang. 2019. A pre-training based personal-\nized dialogue generation model with persona-sparse\ndata. arXiv preprint arXiv:1911.04700.\nHao Zhou, Minlie Huang, Tianyang Zhang, Xiaoyan\nZhu, and Bing Liu. 2017. Emotional chatting\nmachine: Emotional conversation generation with\ninternal and external memory. arXiv preprint\narXiv:1704.01074."
}