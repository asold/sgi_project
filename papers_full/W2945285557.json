{
  "title": "Intelligent Localization of Transformer Internal Degradations Combining Deep Convolutional Neural Networks and Image Segmentation",
  "url": "https://openalex.org/W2945285557",
  "year": 2019,
  "authors": [
    {
      "id": "https://openalex.org/A5038380017",
      "name": "Jiajun Duan",
      "affiliations": [
        "Wuhan University"
      ]
    },
    {
      "id": "https://openalex.org/A5020019416",
      "name": "Yigang He",
      "affiliations": [
        "Wuhan University"
      ]
    },
    {
      "id": "https://openalex.org/A5069621697",
      "name": "Bolun Du",
      "affiliations": [
        "Wuhan University"
      ]
    },
    {
      "id": "https://openalex.org/A5045858841",
      "name": "Ruaa M. Rashad Ghandour",
      "affiliations": [
        "Wuhan University"
      ]
    },
    {
      "id": "https://openalex.org/A5074840856",
      "name": "W. Wu",
      "affiliations": [
        "Wuhan University"
      ]
    },
    {
      "id": "https://openalex.org/A5100323491",
      "name": "Hui Zhang",
      "affiliations": [
        "Wuhan University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2194775991",
    "https://openalex.org/W2097117768",
    "https://openalex.org/W6602612410",
    "https://openalex.org/W2797405679",
    "https://openalex.org/W2798854001",
    "https://openalex.org/W2767234670",
    "https://openalex.org/W6684191040",
    "https://openalex.org/W2062900651",
    "https://openalex.org/W2117242079",
    "https://openalex.org/W2724730420",
    "https://openalex.org/W6725739302",
    "https://openalex.org/W2608946692",
    "https://openalex.org/W1931803241",
    "https://openalex.org/W2792745021",
    "https://openalex.org/W2732458570",
    "https://openalex.org/W2755753252",
    "https://openalex.org/W2760536864",
    "https://openalex.org/W2593968453",
    "https://openalex.org/W2766824859",
    "https://openalex.org/W2919115771",
    "https://openalex.org/W4255510199",
    "https://openalex.org/W2805772477",
    "https://openalex.org/W2747054162",
    "https://openalex.org/W2785630209",
    "https://openalex.org/W2737897717",
    "https://openalex.org/W2624034082",
    "https://openalex.org/W1964961836",
    "https://openalex.org/W2744297321",
    "https://openalex.org/W2265336114",
    "https://openalex.org/W2605738098",
    "https://openalex.org/W2791149978",
    "https://openalex.org/W2769980131",
    "https://openalex.org/W2805613037",
    "https://openalex.org/W2724573302",
    "https://openalex.org/W2790977031",
    "https://openalex.org/W2963150697",
    "https://openalex.org/W2043181992",
    "https://openalex.org/W2428325231",
    "https://openalex.org/W2035531407",
    "https://openalex.org/W2893813411",
    "https://openalex.org/W2767016721",
    "https://openalex.org/W2163605009",
    "https://openalex.org/W1686810756",
    "https://openalex.org/W2963446712"
  ],
  "abstract": "Industrial 4.0 placed higher demands on the field of intelligent equipment monitoring. The transformer is one of the critical power devices, its intelligent monitoring and fault positioning require in-depth studies. In this study, an efficient fault localization method for transformer internal thermal faults was proposed by introducing different deep convolutional neural networks (CNNs) and image segmentation. First, the transformer monitoring images of temperature and velocity fields in fault conditions were simulated using the lattice Boltzmann method (LBM), and the images were also used to highlight features information. In practice, transformer degradation does not frequently occur, so that the fault samples for deep learning are insufficient. To solve this problem, a transfer learning method was employed. Subsequently, fault locations were defined as classification labels, and different CNN's were used to classify the labels to achieve the fault localization results. Next, image segmentation was performed to extract the features of fault areas and simplify the data volumes. Likewise, the CNN's were employed to perform the fault localization again. Afterward, since the monitoring sensors were not located everywhere in a transformer in practical applications, information of partial monitoring areas where the monitoring sensors located was trained following a similar procedure. After image segmentation, the average fault localization accuracy using the information obtained by sensors decreased from 97.95% to 94.42%, while the data volume was reduced to nearly 1% of the original one. Besides, the average calculation time per iteration decreased by 8.816%, while the loss value was reduced by 37.68%. Finally, the Friedman hypothesis test and Nemenyi post hoc test were performed to compare the evaluation indicators of different networks, and the performance of GoogLeNet in this case was considered the best.",
  "full_text": "SPECIAL SECTION ON ADVANCES IN PROGNOSTICS AND SYSTEM HEALTH MANAGEMENT\nReceived April 17, 2019, accepted May 8, 2019, date of publication May 13, 2019, date of current version May 24, 2019.\nDigital Object Identifier 10.1 109/ACCESS.2019.2916461\nIntelligent Localization of Transformer Internal\nDegradations Combining Deep Convolutional\nNeural Networks and Image Segmentation\nJIAJUN DUAN\n, YIGANG HE\n , (Member IEEE), BOLUN DU,\nRUAA M. RASHAD GHANDOUR, WENJIE WU, AND HUI ZHANG\nSchool of Electrical Engineering and Automation, Wuhan University, Wuhan 430072, China\nCorresponding author: Yigang He (yghe1221@whu.edu.cn)\nThis work was supported in part by the National Natural Science Foundation of China under Grant 51577046, in part by the State Key\nProgram of National Natural Science Foundation of China under Grant 51637004, in part by the National Key Research and Development\nPlan ‘‘Important Scientiﬁc Instruments and Equipment Development’’ under Grant 2016YFF0102200, and in part by the Equipment\nResearch Project in Advance under Grant 41402040301.\nABSTRACT Industrial 4.0 placed higher demands on the ﬁeld of intelligent equipment monitoring. The\ntransformer is one of the critical power devices, its intelligent monitoring and fault positioning require in-\ndepth studies. In this study, an efﬁcient fault localization method for transformer internal thermal faults\nwas proposed by introducing different deep convolutional neural networks (CNNs) and image segmentation.\nFirst, the transformer monitoring images of temperature and velocity ﬁelds in fault conditions were simulated\nusing the lattice Boltzmann method (LBM), and the images were also used to highlight features information.\nIn practice, transformer degradation does not frequently occur, so that the fault samples for deep learning are\ninsufﬁcient. To solve this problem, a transfer learning method was employed. Subsequently, fault locations\nwere deﬁned as classiﬁcation labels, and different CNN’s were used to classify the labels to achieve the\nfault localization results. Next, image segmentation was performed to extract the features of fault areas\nand simplify the data volumes. Likewise, the CNN’s were employed to perform the fault localization\nagain. Afterward, since the monitoring sensors were not located everywhere in a transformer in practical\napplications, information of partial monitoring areas where the monitoring sensors located was trained\nfollowing a similar procedure. After image segmentation, the average fault localization accuracy using the\ninformation obtained by sensors decreased from 97.95% to 94.42%, while the data volume was reduced to\nnearly 1% of the original one. Besides, the average calculation time per iteration decreased by 8.816%, while\nthe loss value was reduced by 37.68%. Finally, the Friedman hypothesis test and Nemenyi post hoc test were\nperformed to compare the evaluation indicators of different networks, and the performance of GoogLeNet\nin this case was considered the best.\nINDEX TERMS Condition monitoring, fault diagnostics, convolutional neural networks (CNNs), image\nsegmentation, lattice Boltzmann method (LBM), level set, transformers, Friedman test.\nI. INTRODUCTION\nIn the era of Industrial 4.0, more intelligent fault identiﬁ-\ncation and localization methods need in-depth exploration.\nTransformer are critical for power systems [1]. According\nto surveys by IEEE and CIGRE, the annual failure rate of\noil-immersed transformers reaches 0.625%, and it increases\nby 1-2% for large power transformers (above 300kv) [2].\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was José Valente De Oliveira.\nDiscussing how to monitor and diagnose transformer faults\ncan help ensure the safety and reliability of the energy system.\nThe analysis of transformer temperature during monitoring\nprocess has long been a hot topic [3]. Several computa-\ntion and analysis methods have been commonly used, e.g.\nequivalent thermal circuit model [4], Computational Fluid\nDynamics (CFD) [5], and Finite Element Method (FEM) [6],\nto simulate transformer conditions. Wang et al.[7] employed\nLattice Boltzmann Method (LBM) to solve the transformer’s\nheat transfer problem. Recently, a promising LBM-based\nVOLUME 7, 2019\n2169-3536 \n 2019 IEEE. Translations and content mining are permitted for academic research only.\nPersonal use is also permitted, but republication/redistribution requires IEEE permission.\nSee http://www.ieee.org/publications_standards/publications/rights/index.html for more information.\n62705\nJ. Duanet al.: Intelligent Localization of Transformer Internal Degradations\nnumerical simulating method has been developed for LBM’s\nsimplicity, computational efﬁciency, and high scalability in\nparallel processing [8]. Using LBM, simulation images of\noil temperature and velocity distribution of the transformer\ncan be taken. Because LBM is fast, it can better satisfy the\nrequirements of real-time intelligent monitoring systems.\nIn the ﬁeld of monitoring internal faults of transformers,\nthere are a vast variety of methods [9], [10], e.g. Dissolved\nGas Analysis (DGA) [11], Partial Discharge (PD) [12],\nFrequency Response Analysis (FRA) [13], Infrared Ther-\nmography (IRT) [14]. Fault monitoring through temperature\ninformation is not affected by electromagnetic interference.\nBesides, the sensors can record the changes of information\nin the monitoring areas. However, existing studies rarely\nconsidered the situations when faults occur, and few studies\nhave been conducted on fault identiﬁcation or localization.\nThe conventional temperature monitoring methods are based\non mathematical model and focus on hotspot [15], [16].\nBy reasonable deductions, it is likely to detect internal faults\nof the devices based on external monitored information [17].\nThis method is effective, whereas it requires speciﬁc simu-\nlation and monitoring systems for different power devices.\nWhen impurities (e.g. moisture, machinery components, and\nmetals) appear in transformer oil, the method’s insulation\nperformance will be reduced, and the previously derived\nmonitoring standards will be no longer applicable. With the\ncontinuous development of artiﬁcial intelligence, the deep\nfeatures of temperature ﬁeld image data can be extracted.\nThe continuous advancement of equipment manufactur-\ning technologies and fault monitoring methods may lead\nto insufﬁcient fault samples. Fault diagnosis accuracies are\nlimited by the lack of fault samples, which is obvious when\nusing deep Convolutional Neural Networks (CNNs). Transfer\nlearning can transfer the knowledge in the B ﬁeld to the A ﬁeld\nso that it can be adopted to compensate the insufﬁcient fault\nsamples with the simulation data. In addition, less training\ndata, using pre-trained CNNs, can still achieve a relatively\nhigh accuracy [18]. Through transfer learning, appropriate\ntransition between different samples can be achieved [19].\nWang et al.[20] made improvements in a CNN by learning\nfrom the corresponding images published online to detect\nvehicle monitoring data. Kolar et al.[21] used a distributed\ntraining method and transfer learning in the ﬁeld of archi-\ntecture. They, by training synthetic images, achieved higher\naccuracies of the validation process using real construction\nphotos. Reference [22] applied deep learning approach to\nIRT monitoring videos and then determined the condition of\nthe machine automatically. The required data set for training\ndifferent CNNs can be supplemented with LBM simulation\nresults.\nThe monitoring images used for deep neural network train-\ning process should be processed following feature extraction\nprocedures using image processing methods. Because these\nimages may cover redundant information, and the excessive\nvariation details of temperature may occupy too much data\ncapacity, [23] and [24] studied feature extraction methods of\ntemperature images for rotating machinery. Lee et al. [25],\nby modifying the neural network architecture, enhanced the\ntemperature image quality. Existing fault feature extraction\nalgorithm can correspond to a certain device. They require\nmanual participations during analysis process, which is difﬁ-\ncult to perform during intelligent detection. Reference [26]\nstudied a Level Set Method (LSM) for image segmenta-\ntion to achieve automatic segmentations, which is faster and\nno longer limited by initial contour settings. The processed\nmonitoring images highlight fault features. Moreover, since\nCNNs’ are capable of distinguishing latent features automati-\ncally [27], it can be used to achieve intelligent fault diagnosis\nand localization [28]. Moreover, different CNNs have been\nused in a range of monitoring ﬁelds [29]–[32], most of which\nare focused on how to extract degradation features of equip-\nment. Intelligent fault localization methods are more reliable\ncompared with conventional ones since they are not required\nto calculate the speciﬁc features, e.g. hotspot and the relevant\nthreshold for each transformer.\nThe major contributions of this study are summarized as\nfollows:\n1) This study proposed a transformer fault localization\nmethod based on deep learning (different CNNs) and image\nprocessing algorithms (LBM-LSM). There is hardly any ref-\nerence about the fault localization problems of transformer\ninternal faults at present.\n2) Transfer learning method was used to solve the prob-\nlems of insufﬁcient monitoring data. LBM simulation images\nwith different fault labels were obtained and then used as\nthe primary source of data to train different CNNs. Besides,\nthe structures of pre-trained networks were modiﬁed to ﬁt the\ndiagnosing situations in this study. This method could reduce\nthe amount of data set.\n3) The practical monitoring environment limits the size\nof data, and the monitoring areas usually cannot cover the\nwhole transformer. Given these problems, this paper used\nLBM-LSM image segmentation method to reduce the data\nvolumes and extract information of partial areas.\n4) This study compared fault localization results of dif-\nferent CNNs and conventional classiﬁcation method. The\noverall evaluation indices were proposed to measure the\neffectiveness of each CNNs.\nThe rest of this paper is organized as follows:\nIn Section II the whole framework of the proposed\nmethod is presented, and procedures of LBM simulation,\nthe image processing algorithm and the fault localization\nmethod through CNNs are introduced. In Section III, experi-\nment processes are illustrated. In Section IV, further exper-\niments considering the constrained monitoring areas are\npresented. In Section V, calculation results are analyzed.\nIn Section VI, a conclusion of this study is drawn.\nII. METHODS AND PRE-PROCESSING MATERIALS\nThe proposed transformer fault localization method com-\nbined LBM computation and feature extraction techniques,\nusing image segmentation and deep CNNs. Fig. 1 shows\n62706 VOLUME 7, 2019\nJ. Duanet al.: Intelligent Localization of Transformer Internal Degradations\nFIGURE 1. Structure of intelligent monitoring method for transformer\nfaults using different CNNs.\nFIGURE 2. Framework of the proposed fault localization method and the\nstructure of this paper.\nthe overall structure of the proposed transformer monitoring\nmethod. Given the shortage of fault data samples in practical\napplications, transfer learning was adopted. During the mon-\nitoring process, almost all data were in normal condition and\ncould be easily identiﬁed through iterations in the time series.\nOnce degradation occurred, the monitored information would\nchange. Using the network trained beforehand, preliminary\nfault localization results could be obtained. Flow chart of the\nproposed fault localization method and the structure of this\npaper are shown in Fig. 2, which is split into 3 parts. The four\narrows pointing at the third part in Fig. 2 represent one section\nfrom III-A to IV-B respectively.\nA. LBM SIMULATION METHOD FOR\nTRANSFORMER MONITORING\nWhen running oil-immersed transformers, the core as a\nheat source caused natural convection or natural circulation.\nThe temperature of the transformer near the heat source rose,\nwhereas the density decreased. Besides, when the heated oil\nwas close to the heat sink, its heat could be dissipated nat-\nurally. Accordingly, the oil temperature had a close relation\nto the distribution of the velocity ﬁeld. Besides, the failures\n(e.g. moisture, mechanical or metallic impurities generated\nin the oil) had certain effects on the conditions of the oil.\nBy modifying the heat dissipation boundary conditions,\nthe faults could be simulated.\nFIGURE 3. D2Q9 structure for LBM.\nUsing LBM simulation method, temperature distribution\nﬁeld of transformers could be instantly obtained, thereby\npromoting the acquisition of massive data for deep CNNs\ntraining. Temperature and velocity distribution were closely\ncorrelated, and their combination can improve the accuracy\nof fault localization. In this study, temperature and velocity\nﬁelds were based on standard D2Q9 LBM model, as shown\nin Fig. 3. This model has been commonly used in solving ﬂuid\nﬂow problems for its more vectors than D2Q4 and D2Q5\nmodels [33]. Equilibrium distribution function for velocity\nﬁeld is expressed as [34]:\nf eq\ni =ωiρ\n[\n1 +3(ci ·u)\nc2 +9(ci ·u)2\n2c4 −3u2\n2c2\n]\n(1)\nwhere fi denotes the particle distribution functions; ci is\ndiscrete particle velocity vector; c =1x/1t, 1x is lattice\nspace; 1t is the lattice time step size;u and ρare the velocity\nand density used to calculate the equilibrium distribution\nfunction f eq\ni respectively. Moreover, ωiis the weights of the\nequilibrium distribution functions in the Boltzmann model.\nHe and Luo [35] considered the moments of equilibrium dis-\ntribution functions as Guass-type integrals, and they derived\nthe weights ωi:\nωi =\n\n\n\n4/9, i =0\n1/9, i =1,2,3,4\n1/36, i =5,6,7,8\n(2)\nThe discrete particle velocity ci is expressed as:\nci =\n\n\n\n\n\n\n\n\n\n\n(0,0) i =0\n(cos θi,sin θi)c,\nθi =(i −1)\n2 π i =1,2,3,4\n√\n2(cos θi,sin θi)c,\nθi =(i −5)\n2 π+π\n4 i =5,6,7,8\n(3)\nVOLUME 7, 2019 62707\nJ. Duanet al.: Intelligent Localization of Transformer Internal Degradations\nThe macroscopic viscosity νis calculated by:\nν=\n(\nτ−1\n2\n)\nc2\ns 1t (4)\nwhere cs denotes the lattice velocity of sound in correspond-\ning medias, which is equal to c/\n√\n3\n√\n3\n.\nGiven that the ﬂuid was driven by buoyancy, an exter-\nnal force should be considered. According to Boussinesq\nApproximation, the external force is expressed as:\nF =ρgβ1T (5)\nwhere ρdenotes the density of transformer oil; g is the gravi-\ntational vector; 1T is the temperature difference between hot\nand cold boundaries; β is the thermal expansion coefﬁcient.\nSubsequently, discrete Lattice Boltzmann Equation (LBE) is\nwritten as:\nfi (x +ci1t,t +1t)−fi (x,t)=−fi (x,t)−f eq\ni (x,t)\nτf\n+1tFi\n(6)\nwhere: Fi =ωi\nc2s\nF ·ci.\nSimilar to the velocity ﬁeld, LBE of temperature ﬁeld can\nbe expressed as\ngi (x +ci1t,t +1t)−gi (x,t)=−gi (x,t)−geq\ni (x,t)\nτg\n(7)\nEquilibrium distribution functions for temperature ﬁeld are\nwritten as\ngeq\ni =ωiρT\n[\n1 +3(ciu)\nc2 +9(ciu)2\n2c4 −3u2\n2c2\n]\n(8)\nAfter mesoscopic computation, the mesoscopic variables\nshould be reverted to macroscopic variables. According to the\nmodel, the macroscopic density ρ, macroscopic speed ρu and\nthe internal energy ρT can be respectively calculated by:\nρ =\n8∑\ni=0\nfi =\n8∑\ni=0\nf eq\ni (9)\nρu =\n8∑\ni=0\ncifi =\n8∑\ni=0\ncif eq\ni (10)\nρT =\n8∑\ni=0\ngi =\n8∑\ni=0\ngeq\ni (11)\nMoreover, the winding loss PT was affected by\ntemperature, which is expressed as:\nPT =P0[1 +kt (T −T0)] (12)\nwhere P0 denotes the winding loss at the temperature T0; kt is\nthe temperature coefﬁcient of the conductor; T is the real-\ntime temperature. The heat ﬂux density qi of the heat source\nis determined by the loss of windings and iron core, which is\nexpressed as:\nqi =P\nAi\n(13)\nwhere qi denotes the heat ﬂux density in a meter square of\nheating surface; P is the total loss; Ai is the heat transfer area.\nThe heat transfer coefﬁcient h of the transformer tank is\ncalculated by:\nh =Nu ·λ\nH (14)\nwhere Nu denotes the Nusselt number; λis the thermal con-\nductivity of the medium; H is the characteristic length.\nTABLE 1. Simulation algorithm of transformer monitoring images.\nLBM simulation was performed to obtain different images\nof speciﬁc fault locations. The calculation procedure is pre-\nsented in Table 1. Input variables for transformer LBM sim-\nulation cover physical parameters of transformer oil, e.g.\ndynamic viscosity (µ), heat capacity at constant pressure\n(Cp), density (ρ ) and thermal conductivity (k t ); parameters\nof heat sources include thermal conductivities and relevant\nlosses in iron core, primary windings and secondary wind-\nings. Furthermore, it also includes geometric parameters of\ntransformer.\nB. LBM-LSM IMAGE SEGMENTATION METHOD\n1) ENERGY EQUATION\nFuzzy c-means (FCM) clustering algorithm can split an\nimage into c different classes. Assuming that the image con-\ntains N pixels, and the value of each pixel is X ={xi}, where\ni = 1,2,..., N. The aim of the calculation process is to\noptimize the following clustering criteria [26]:\nJ (U,V ,X)=\nc∑\nk=1\nN∑\ni=1\nup\nki ∥xi −vk ∥2\ns.t.\nc∑\nk=1\nuki =1, 0 ≤uki ≤1, ∀k,i (15)\n62708 VOLUME 7, 2019\nJ. Duanet al.: Intelligent Localization of Transformer Internal Degradations\nwhere U denotes a partition matrix, where uki represents the\nmembership that the i-th element belongs to the k-th class.\nLikewise, V is a centroid vector, where vk means the centroid\nof the k-th class. The parameter pis a fuzzy index, represent-\ning the weighting exponent of each fuzzy membership. The\nnorm operator ∥·∥indicates the standard Euclidean distance.\nThe minimum of objective function J was obtained when\nhigh degree memberships were assigned to the pixels with\nintensities close to the centroid of its particular class, while\nlow membership values were assigned to the pixels with\nintensities far from the centroid.\nIf the monitoring images were recorded as Y ={yi}N\ni=1,\nthe initial image domain selected at the beginning of the\nimage processing was considered bias ﬁeld image B =\n{βi}N\ni=1, and equation (15) can be written as a continuous\nform:\nJ (U,V ,B,Y )\n=\nc∑\nk=1\n∫\nk\nUp\nki (x,y)∥Y (x,y)−B (x,y)−vk ∥2dxdy (16)\nMonitoring images should be classiﬁed into several types.\nConsidering the convenience when the monitored informa-\ntion was being transmitted, the normal part of monitoring\nimages was marked as black, and the abnormal part was\nwhite, i.e. c = 2. Thus, the optimization function in (16)\nshould be divided into two parts: 1 and 2, and the level\nset function is expressed as follows:\nJ (U,V ,B,Y )\n=\n∫\n\nUp\n1 (x,y)∥Y (x,y)−B (x,y)−v1∥2H (φ)dxdy\n+\n∫\n\nUp\n2 (x,y)∥Y (x,y)−B (x,y)−v2∥2 (1−H (φ))dxdy\ns.t.U1 (x,y)+U2 (x,y)=1, 0 ≤Uk (x,y)≤1, ∀x,y\n(17)\nwhere φ denotes the signed distance function; H( ) is the\nHeaviside function. Level set function J was used as a data\nlink in energy function, shown in (18):\nE (U,V ,B,Y ,φ)=J (U,V ,B,Y ,φ)+ν\n∫\n\n|∇H (φ)|dxdy\n(18)\nwhere ν is a constant and ν > 0. The latter integral term\ndenotes the length of a given curve which is represented\nimplicitly as the zero level of φ.\n2) LEVEL SET EQUATION\nLBM can be used to solve the parabolic diffusion equation\nrecovered by Chapman–Enskog expansion with the external\nforce, including [26]:\n∂ρ\n∂t =γ∇·∇ ρ+F (19)\nThe classical energy function optimization method aims to\nﬁnd a stable solution of gradient descent for ﬁxed U, V and\nB: ∂φ\n∂t =−∂E\n∂φ. Substituting it to equation (19), the following\nlevel set equation (LSE) could be obtained:\n∂φ\n∂t =δ(φ)(Up\n1 (x,y)∥Y (x,y)−B (x,y)−v1∥2\n−Up\n2 (x,y)∥Y (x,y)−B (x,y)−v2∥2)\n+νδ(φ)div\n( ∇φ\n|∇φ|\n)\ns.t.U1 (x,y)+U2 (x,y)=1, ∀x,y\n0 ≤Uk (x,y)≤1, ∀k,x,y (20)\nTo solve the optimization equation, the ﬁrst derivative\nof corresponding variables (e.g. uki, vk and βi) should be\ncalculated and set to zero. Accordingly, the following sup-\nplementary conditions are available:\nU∗\nk (x,y)= 1\nc∑\nl=1\n(\n∥Y (x,y)−B(x,y)−vk ∥\n∥Y (x,y)−B(x,y)−vl ∥\n) 2\n(p−1)\n(21)\nv∗\nk =\n∫\n\nUp\nk (x,y)(Y (x,y)−B (x,y))dxdy\n∫\n\nUp\nk (x,y)dxdy (22)\nB∗(x,y)=Y (x,y)−\nc∑\nk=1\nUp\nk (x,y)vk\nc∑\nk=1\nUp\nk (x,y)\n(23)\nFinally, LSE was added to LBM (19). The ρ in equation\n(19) was replaced by the signed distance function 8. After\nthe replacement, it was suggested that (20) is only a varia-\ntion formula of (19). Thus, the external force term could be\nobtained by comparison:\nF =λ\n(\nUp\n1 (x,y)∥Y (x,y)−B (x,y)−v1∥2\n−Up\n2 (x,y)∥Y (x,y)−B (x,y)−v2∥2\n)\n(24)\nwhere λ denotes a positive parameter and the parameter\nρ=2.\nThis section presents an image processing method. First,\nmonitoring images should be fused with the relevant infor-\nmation of normal conditions, so that the fault features were\nextracted. Second, the image segmentation algorithm based\non LBM-LSM was used to obtain the contours of fault loca-\ntions. In the meantime, fault areas were visually displayed\non monitoring images. The algorithmic description of image\nprocessing is given in Table 2.\nCorresponding processing results are shown in Fig. 4. The\nrows represent segmentation results, and the columns repre-\nsent different fault locations. When an initial contour was\ndrawn outside the monitoring area, e.g. on the transformer\ncore shown in Fig. 4 (a1), (b1) and (e1), it might always exist.\nHowever, this part of the segmentation results did not affect\nthe monitored areas. The last line was the boundaries of the\nfault areas obtained by LBM-LSM calculation. Fig. 4 shows\nVOLUME 7, 2019 62709\nJ. Duanet al.: Intelligent Localization of Transformer Internal Degradations\nTABLE 2. Image fusion and LBM-LSM image segmentation.\nFIGURE 4. Samples of image segmentation results for transformer fault\nareas.\nthat, segmentation results were absolutely identical wherever\ninitial contour was.\nC. DEEP LEARNING FAULT LOCALIZATION METHOD\nBecause CNNs have abilities for deep feature extraction,\nadaptive fault diagnosis can be achieved.\nTABLE 3. Dataset of transformer degradation images for training.\n1) DATA SET\nFault diagnosis process required a corresponding data set for\ntraining and evaluation. As shown in Fig. 5, fault locations\nwere simulated randomly and classiﬁed into different labels.\nThe image was easy to classify after feature extraction pro-\ncess. Intelligent localization algorithms based on deep CNNs\nwere employed to classify fault locations, thereby achieving\nthe adaptive positioning. In total, 240 images were used as\noriginal images to be classiﬁed into different tags, including\ndifferent locations of transformer oil degradations. 7 types\nof fault locations and a normal condition were studied here.\nFig. 5 shows the relevant positions of the seven fault location\ntags: top left, top right, left, center, right, bottom left, and\nbottom right so that the fault locations of the transformer can\nbe separated into different labels. The rules for the division\nof transformer areas can be adjusted according to speciﬁc\napplications. The image data set is shown in Fig. 5, including\ncolorful or gray-scale processed ones. Furthermore, more\nimage augmentation methods are to be present in the next\nsection.\n2) AUGMENTATION\nTraining process of CNNs require a considerable amount of\nmonitoring samples. Though the simulation data set and the\ntransfer learning method can make up the shortage of moni-\ntoring images that should be obtained under fault conditions,\nit is necessary to further expand the dataset and to avoid\noverﬁtting during training process. After obtaining the pro-\ncessed images by image feature fusion, the data set should be\naugmented. Using augmentation methods: randomly rotating\n90◦, 180◦or 270◦, mirroring, adding noise, etc., other moni-\ntoring image versions were obtained. In total, the transformer\nmonitoring image dataset contained 2035 images, 1628 of\nwhich (80%) were for training and 407 (20%) for testing.\nThe monitoring image data set of the transformer applied\nfor training different CNNs are listed in Table 3. Besides,\nto standardize the image size, it is necessary to maintain the\nconsistency of image feature extraction process and meet the\ndeep CNNs requirements.\nD. BRIEF INTRODUCTION TO CONVOLUTIONAL\nNEURAL NETWORKS\nAlexNet [36] achieved a top-5 error rate of 15.3% in the\n2012 ILSVR (ImageNet Large Scale Visual Recognition\n62710 VOLUME 7, 2019\nJ. Duanet al.: Intelligent Localization of Transformer Internal Degradations\nFIGURE 5. Structure and fault locations of the transformer. The pictures on the right side are examples of fault data corresponding to different labels.\nTheir fault locations are: (a) the right, (b) the upper right, (c) the bottom right, (d) the middle, (e) the left, (f) the upper left, and (g) the bottom left areas\nof the transformer.\nCompetition), much higher than that of the second one\n(26.2%). Since then, growing number of complex and better\nperformance convolutional neural networks emerged.\nVGGNet [37] emphasizes the depth of the network.\nIt rigorously used a 3×3 ﬁlter (stride=1, pad=1) and a\n2×2 maximum pooling layer (stride=2). Thus, a large effec-\ntive receptive ﬁeld was achieved by the combination of\n2 small ﬁlters.\nGoogLeNet [38] proposed the concept of ‘‘Inception\nModule’’, breaking the tradition of connecting CNNs layer\nby layer. Each module includes multiple parallel convolu-\ntional layers with a size of 1×1, 3×3, 5×5 and a max\npooling layer for the extraction of different features simul-\ntaneously. Besides, the 1×1 convolutional layer was used to\nreduce the dimensions before the 3×3 and 5×5 convolutional\nlayers, increasing the depth of the network and reducing the\nnetwork parameters.\nResNet [39] proposed a residual network which uses the\ndifference between output and input (H (x)-x) for optimiza-\ntion training. By introducing ‘‘shortcut’’ module and identity\nconnections, ResNet reduced the problem of gradient disap-\npearance in deep neural networks.\nInspired by the ‘‘identity connections’’, DenseNet [40] has\na dense connection structure, which means each layer obtains\nthe outputs of all the layers before it. This structure further\nimproved the problem of gradient disappearance. DenseNet\nreduced the amount of computation by promoting feature\npropagation process and facilitating feature reuse.\nLight networks (e.g. SqueezeNet [41]) signiﬁcantly\nreduced the amounts of parameters (1/50 of AlexNet) while\nmaintaining a relatively high accuracy. It proposed a new\nnetwork architecture ‘‘Fire Module’’. 1×1 convolution was\nTABLE 4. Basic parameters of the diagnosing networks used in this study.\nused to compress the dimension of feature maps and reduce\nthe weight parameters.\nMoreover, R-CNN (Rigion-CNN) models (e.g. R-CNN,\nfast R-CNN, Faster R-CNN, and Mask R-CNN [42]) grad-\nually appeared to achieve both image detection and target\nclassiﬁcation. The deep CNNs used for fault localization\nin this study and their fundamental parameters are listed\nin Table 4. Paper [43] gives a detailed comparison analysis\nof these networks.\nIII. SIMULATION PROCESS\nThis section falls into two parts. First, fault simulation image\nand image fusion algorithm were demonstrated, and fault\nlocalization was performed using different pre-trained deep\nCNNs. Second, fault areas of transformer monitoring images\nwere outlined by LBM-LSM image segmentation method.\nA further classiﬁcation and localization process using deep\nCNNs were demonstrated. The data set used for fault localiza-\ntion are listed in Table 3. After image augmentation process,\nthe number of pictures used for training the CNNs was 1628,\nand another 407 pictures were for validation process.\nVOLUME 7, 2019 62711\nJ. Duanet al.: Intelligent Localization of Transformer Internal Degradations\nFIGURE 6. This is the simulation results of transformer while degradation\nappears at the upper left area.\nA. FAULT LOCALIZATION BASED ON TRANSFORMER\nTEMPERATURE AND VELOCITY FIELD\n1) IMAGE FUSION AND FEATURE EXTRACTION PROCESS\nImplementing the program in Table 1 until meeting the con-\nvergence condition in (25), one group of fault simulation\nresults are shown in Fig. 6. The left image above shows\nthe temperature ﬁeld of transformer and the right demon-\nstrates the velocity ﬁeld. The convergence criteria during fault\nsimulation could be deﬁned by computing the temperature\nincrement during each simulation step, and the computation\nwould continue until it became smaller than a pre-deﬁned\nﬁxed value ε, as shown in the following Equation (25):\n∑\nx\n|T (x,t) −T (x,t −1)|\n|T (x,t)| <ε =10−7 (25)\nwhere x denotes any coordinate within the transformer.\nTo facilitate the computation process and fault diagno-\nsis abilities, the monitoring information and normal state\ndatasets were merged, so that the overall monitoring deviation\nimages could be obtained. The image fusion process for one\nresult sample is illustrated in Fig. 7.\nFIGURE 7. An example of Image fusion method.\nDenoting the monitoring image of transformer temperature\nﬁeld by FigTM , and the transformer temperature ﬁeld image\nduring normal operating condition by FigTN , respectively.\nTheir deviation value is expressed as FigTD =FigTM -FigTN ;\nLikewise, the monitoring image of transformer velocity ﬁeld\nis symbolized by FigVM , and the transformer velocity ﬁeld\nimage during normal operating condition is FigVN , therefore,\ntheir deviation value is expressed as FigVD =FigVM -FigVN .\nThe overall deviation image FigD can be deﬁned via\nEquation (26), which is essentially a matrix of the corre-\nsponding pixel values:\nFigD =1\n2\n( FigTD\nmax (FigTD)+ FigVD\nmax (FigVD)\n)\n(26)\nwhere the temperature and velocity deviation values are\ndivided by their maximum values: max (Fig TD), and (Fig VD)\nrespectively, which presents the normalization procedure.\nIn such a way, different monitoring data were proportionally\nmerged.\n2) FAULT LOCALIZATION BY DEEP LEARNING\nIn this section, we applied different pre-trained deep CNNs to\ntrain the overall deviation images and to achieve fault identi-\nﬁcation and localization automatically. These networks have\nbeen trained on more than 1 million images via ImageNet\ndatabase. Therefore, a small number of training images can\nbe used to quickly transfer the learned functions to new tasks.\nBesides, the ﬁrst 10 layers of the networks were frozen during\nthe training process so as to further reduce the parameters\nneed to be ﬁne-tuned.\nReplace the last layers with learnable weights for AlexNet,\nVGGNet, GoogLeNet, ResNet, DenseNet, and SqueezeNet\nand use them as the training networks respectively for intel-\nligent fault localization diagnosis. In most networks, this\nlayer is a fully connected layer. Replace this fully connected\nlayer with a new fully connected layer with the number of\noutputs equal to the number of categories in diagnosing data\nset (8, in this study); For some networks (e.g. SqueezeNet),\nthe last learnable layer is a 1-by-1 convolutional layer. In this\ncase, replace the convolutional layer with a new convolutional\nlayer with the number of ﬁlters equal to the number of diag-\nnosing categories.\nFIGURE 8. Validation results of transformer fault locations based on\nvarious CNNs.\n20% of the deviation images were randomly select as the\ntesting data set. The validation process of fault diagnos-\ning methods based on different CNNs are shown in Fig. 8.\n62712 VOLUME 7, 2019\nJ. Duanet al.: Intelligent Localization of Transformer Internal Degradations\nFIGURE 9. 10 Randomly selected samples of Fault localization results. The title of each picture displays the localization category with the highest\nprobability.\nTABLE 5. Parameter settings of the networks and computer configuration\ninformation.\nAnd in Table 5, hyper parameters were summarized in the\nleft side, and the hardware or software parameters are listed\nin the right side.\nTo visually display the fault types and the corresponding\nprobabilities, original dataset (without image augmentation)\nwas used to verify the localization results. The localization\nresults using GoogLeNet are shown in Fig. 9. And the fault\ndiagnosing results of other networks were similar to this\nnetwork. 10 monitoring images were randomly selected from\nthe veriﬁcation data set. For each overall deviation image,\nthe label with the highest probability among its fault loca-\ntions and the corresponding probability value are displayed,\nas shown in Fig. 9. This Figure suggests that the randomly\nselected samples could be correctly classiﬁed as the accurate\nlocations.\nDifferent neural networks were trained on the fault sample\ndata set and veriﬁed using the veriﬁcation data set. Besides,\nthe veriﬁcation results: the accuracies, the loss value, the\ncalculation time required for each iteration, and the number of\niterations when veriﬁcation accuracy reaches the maximum\nvalue for the ﬁrst time, are listed in Table 6.\nB. FAULT LOCALIZATION AFTER IMAGE SEGMENTATIONS\nThe internal structure of a transformer is very complex.\nThere are redundant changes of temperature and velocity\nTABLE 6. Validation results based on different CNNs.\nﬁeld distributions, which is inconvenient for data storage and\ntransmitting process. Data reduction and compression pro-\ncessing are necessary. In this section, image edge information\nis extracted using LSM-LBM method before different CNNs\ntraining processes.\nThe image segmentation method based on LBM-LSM was\nemployed to process the overall deviation images obtained by\n(26), so that the contours of fault areas were outlined. Several\nexamples of this method are shown in Fig. 4. Deteriorate areas\noutlined by edge segmentation method were set to 1, which\nwere illustrated by white lines, and the rest areas were set\nto 0. Assuming that the size of monitoring area comprises\nm ×n pixels, whose value varies from 0 to 255, and a color\nimage consists of three-dimensional data. After segmenta-\ntion process, each pixel was 0 or 1, and the dimension of\ndata was reduced from three dimensions to two. Besides,\nthe outline of abnormal areas only took up a small fraction\nof the whole image. For example, the outline in Fig. 4 (d1)\ncontained 779 pixels, and the size of this image was 224×224.\nThus, the number of pixels for original image reduced from\nm ×n ×3 =224 ×224 ×3 =150528 to 779. During the\ndata storage or transmitting process, each pixel of the original\nVOLUME 7, 2019 62713\nJ. Duanet al.: Intelligent Localization of Transformer Internal Degradations\nTABLE 7. Validation results after the image segmentation.\nimage required 8-bit (1B) binary data. After outlining fault\nareas, only the data whose value is 1 should occupy a data\nspace. Also, according to the image size, 8-bit (1B) coordi-\nnates were necessary for xand y axis, respectively. Therefore,\nthe total amount of binary data required for original image\nwas 150528 ×1B = 147kB, and 779×2B=1.52kB after\noutlining respectively, which was approximately only 1% of\nthe original amount.\nFIGURE 10. Validation results after image segmentations based on\nvarious CNNs.\nThe overall deviation images after segmentation were\nserved as input for different deep CNNs, and the validation\nprocess of fault localizations are shown in Fig. 10. After\nextracting the outlines of fault areas by image segmenta-\ntion algorithm, data volume can be signiﬁcantly reduced.\nLikewise, the veriﬁcation results are shown in Table 7.\nIV. FAULT LOCALIZATION BY\nMONITORING INFORMATION\nA. BEFORE IMAGE SEGMENTATIONS\nConsiderable monitoring devices and plenty of data are\nneeded if it is necessary to monitor images of the entire\ntransformer. However, in practical applications, monitoring\nimages are usually obtained through only a few sensors,\nFIGURE 11. Sensors placed on several parts near the transformer\nwindings obtain the monitoring information. And the right side shows\nsegmentation results.\nFIGURE 12. Validation results of the 9 sensors’ information based on\nvarious CNNs.\nwhich are located in partial areas of the whole transformer.\nIn this section, 9 small blocks near the windings were con-\nsidered information of different detecting sensors. Positions\nof the monitoring areas are shown in the left picture of Fig. 11.\nSubsequently, these areas were put together as shown in the\nright side of the ﬁgure. To facilitate calculation and compara-\ntive analysis, data set in this section were obtained through the\ndata set listed in Table 3. They were trained under different\nconvolutional neural networks in Table 8 to locate fault areas\nsimilar to section III. There were 1628 images for training,\nand 407 for validation.\nDifferent CNNs were employed to classify fault locations\nwith the information obtained by monitoring sensors. The\nvalidation process are shown in Fig. 12. Besides the validation\nresults: the accuracies, the loss value, the calculation time\nper iteration, and the number of iterations when veriﬁcation\naccuracy reaches the maximum value for the ﬁrst time, are\nlisted in Table 8.\nFurthermore, 10 monitoring images were randomly\nselected from veriﬁcation data set when using GoogLeNet\nas the localization network, as shown in Fig. 13. Their most\n62714 VOLUME 7, 2019\nJ. Duanet al.: Intelligent Localization of Transformer Internal Degradations\nFIGURE 13. 10 Randomly selected samples of fault localization results based on several monitoring sensors (9 sensors). The title of each picture displays\nthe localization category with the highest probability.\nTABLE 8. Validation results based on monitoring sensor information\nbefore the image segmentation.\nlikely positions are illustrated respectively. Because the real\nlabels of monitoring images could not be observed directly in\nthis situation, they are represented in parentheses.\nB. AFTER IMAGE SEGMENTATIONS\nSimilar to section III-B, edges of monitoring areas acquired\nby several sensors were extracted by LBM-LSM image seg-\nmentation method. And the same training procedures were\napplied for fault localization. Validation process through dif-\nferent CNNs in this situation is shown in Fig. 14. And the fault\nlocalization results are listed in Table 9. To visually display\nthe fault localization results, 10 randomly selected validation\nsamples are shown in Fig. 15 likewise.\nComparing the results of Table 6 and Table 7, or Table 8 and\nTable 9, fault localization accuracies in the latter situation\nwere almost lower than those of the former. However, the iter-\nation time of the latter was shorter than that of the former, and\nthe amount of data was signiﬁcantly reduced, which would\npromote data storage and transmitting process.\nIn addition, the conventional Support Vector Machine\n(SVM) method was employed here to conduct the fault\nFIGURE 14. Various CNNs’ validation results of the 9 sensors’ information\nafter image segmentations.\nTABLE 9. Validation results based on monitoring sensor information after\nthe image segmentation.\ndiagnosing situations. Its average fault localization accuracy\nwas 81.86%, much lower than that of the CNNs. It can be\nseen that the fault localization results through SVM model is\nVOLUME 7, 2019 62715\nJ. Duanet al.: Intelligent Localization of Transformer Internal Degradations\nFIGURE 15. 10 Randomly selected samples of fault localization results based on several monitoring sensors (9 sensors). And the fault areas were\noutlined by LBM-LSM image segmentation method. The title of each picture displays the localization category with the highest probability.\nrelatively poor in these situations, because it is difﬁcult for\nshallow networks to extract deep features.\nV. ANALYSIS\nA. COMPREHENSIVE EVALUATION INDICATORS/INDICES\nTo analyze which convolutional neural network is the most\nsuitable one for the fault diagnosis situations in this study,\nvalidation results in Table 6 to Table 9 were divided by the\nvalues of the ﬁrst line respectively, which is the normaliza-\ntion process. Subsequently, the loss value, the iteration time,\nand the iterations of the same network were summed, and\nthe results are listed in Table 10. These indicators were all\nexpected to be as small as possible. Therefore, the evaluation\nindicators of each network were added together to obtain their\ncomprehensive evaluation indicators respectively, shown in\nthe last column of Table 10. This Table suggests that the\nevaluation indicator of GoogLeNet proved it the best net-\nwork (the smallest). Besides, the indicators of AlexNet and\nDenseNet also showed good performance.\nTABLE 10. Evaluation indicators of the fault localization results based on\ndifferent CNNs.\nIn addition, indicators of fault localization results (includ-\ning the loss value, the iteration time and the number of\niterations) only reﬂect part of the diagnosing effects. The\noverall accuracies and the stabilities of the diagnosis process\nshould also be considered. The average veriﬁcation accuracy\nof the last 50% iterations (the last 160 iterations) is denoted\nas Piter , and the standard deviation of the last 50% iterations\nis denoted as S2\nN . Furthermore, the number of iterations used\nto calculate was iter, while the iter in this study was 160. the\nevaluation index was deﬁned as the average value minus the\nstandard deviation, as shown in Equation (27).\nPiter −S2\nN =Piter −\n\n√\n1\niter\niter∑\ni=1\n(\nPiteri −Piter\n)2 (27)\nThis index is expected to be as large as possible. The average\nveriﬁcation accuracies and standard deviations for different\ndeep CNNs in Fig. 8, Fig. 10, Fig. 12 and Fig. 14 are listed\nin table 11. According to the last column in table 11, the\ncomprehensive veriﬁcation effect of DenseNet is the best and\nthe most stable one, then followed by GoogLeNet.\nAccording to normalized evaluation indicators presented\nin Table 10, the top three networks (and their indices) were\nGoogLeNet (12), AlexNet (41.306) and DenseNet (46.411).\nAnd likewise, according to evaluation indices in Table 10,\nthe top three networks (and their indices) were DenseNet\n(394.1), GoogLeNet (393.4), ResNet50 (387.9). In addition,\nconsidering the basic network parameters in Table 4, param-\neters of GoogLeNet are less than the others’ and its size of\nnetwork is smaller. Therefore, GoogLeNet is more suitable\nfor the fault localization situations in this study. To judge the\npros and cons of the model more rigorously, we conducted\nthe Friedman test and then the Nemenyi post hoc test. The\nexperimental results are to be given in the next section.\nB. MODEL SELECTION\nWe evaluated nine networks using the results of the 5 -fold\ncross-validation, Friedman test, and Nemenyi post hoc test.\nA ﬂow chart of the evaluation process is shown in Fig. 16.\nThe Friedman test is one of the statistical hypothe-\nsis tests used to compare multiple systems and solve\nmulti-classiﬁcation problems [45]. Thus, it is applicable to\nthe case of this study.\n62716 VOLUME 7, 2019\nJ. Duanet al.: Intelligent Localization of Transformer Internal Degradations\nTABLE 11. Overall evaluation indices of the fault localization processes based on various CNNs.\nTABLE 12. The five-fold cross-validation results.\n1) FIVE-FOLD CROSS-VALIDATION\nBecause neural networks are highly sensitive to the ini-\ntial weight parameters, diagnosis results might be incon-\nsistent. Validation accuracies would ﬂuctuate around the\nnormal states. The veriﬁcation accuracies of the nine algo-\nrithms selected in this study all achieved above 90%, and\nthe ﬂuctuation intervals were partially coincident. Therefore,\nthe error of one test set is not sufﬁcient to approximate the\nVOLUME 7, 2019 62717\nJ. Duanet al.: Intelligent Localization of Transformer Internal Degradations\nFIGURE 16. A flow chart of the evaluation process.\ngeneralization error. This study divided the data set D into ﬁve\ndisjoint subsets, namely: D =D1 ∪D2 ∪... ∪D5, Di ∩Dj =\n∅(i ̸=j). During each validation process, four subsets were\nused as training data and the other were used as validation\ndata. The application scenario in Section IV-B was taken as\nan example to evaluate the networks. The testing results are\nlisted in Table 7, where D1 denotes the testing results of\nSection IV-B. The testing results were sorted according to\nthe effects from good to bad, and the corresponding ranks are\nlisted in parentheses.\n2) FRIEDMAN STATISTICAL HYPOTHESIS TEST AND\nNEMENYI SUBSEQUENT TESTING\nFirst of all, the assumption was listed as follows:\nH0: In this study, the 9 algorithms are not signiﬁcant\ndifferent;\nH1: In this study, the 9 algorithms are signiﬁcantly\ndifferent;\nThe Friedman test result obtained using SPSS reached a\nconclusion that the 9 diagnosis methods in this study have\nsigniﬁcant differences, because the signiﬁcance level was\nlower than 0.05, and the test result was judged to accept\nhypothesis H1.\nNext, The Nemenyi test is applied to quantify the signiﬁ-\ncant differences between each two models. First, we calculate\nthe average rank(AR) of each network: GoogLeNet 2.92,\nVGG16 5.48, VGG19 5.64, SqueezeNet 5.96, AlexNet 3.12,\nDenseNet 4.64, ResNet18 6.28, ResNet50 5.08, ResNet101\n5.88. Then Nemenyi post hoc test was applied and Criti-\ncal Difference (CD) value was calculated via Equation (28)\n(for α = 0.05, the Critical Value q0.05 for 9 classiﬁers\nis 3.102) [44].\nCD =qα\n√\nK (K +1)\n12N (28)\nwhere K denotes the total number of networks, and N is the\ntotal number of datasets used in the study.\nFIGURE 17. Average Rank for the results of various CNNs.\nThere were 9 models to be compared and 5 data sets for\nStatistical hypothesis test. The evaluation indicators of the\ndiagnosing effect include not only the accuracy rate, but\nalso ﬁve evaluation attributes for each data set. The critical\nrange domain CD=1.70 was calculated by equation (28).\nFig. 17 shows the performance ranks of the networks, along\nwith Nemenyi’s critical difference (CD) tail. The length of\neach tail was equal to the critical range. The x-axis shows the\naverage order value of all data sets and their attributes, and\nthe y-axis represents the name of the networks to be detected.\nTwo vertical dashed lines were inserted to clearly identify the\nend of the best performing classiﬁer’s tail and the start of the\nnext signiﬁcantly different classiﬁer.\nAs shown in Fig. 17, the performance of the GoogLeNet\nis the best as its AR value is 2.92. Also, AlexNet has good\nperformance, which didn’t show signiﬁcant differences with\nGoogLeNet. DenseNet has a slow training speed, but its accu-\nracy and stability during the diagnosing process are excellent.\nThe evaluation indicators focused in this study was not bene-\nﬁcial to this network. In addition, according to Fig. 17, other\nclassiﬁcation techniques were worse (VGGnet, SqueezeNet,\nand ResNet) in the case of this study.\nVI. CONCLUSION\nThis study proposed a fault localization method for\ntransformer thermal faults by deep CNNs and image process-\ning. Considering the shortage of fault data samples, trans-\nfer learning was adopted, and transformer LBM simulation\nresults were served as a low-layer dataset. Image segmenta-\ntion method was applied to extract fault features and reduced\nthe data volume signiﬁcantly.\nFirst, distributions of the transformer temperature and\nvelocity ﬁeld were obtained through LBM simulation, and\nthe corresponding image fusions were performed. Second,\nthe fault areas of these images were outlined using level set\nmethod, which highlighted fault features and reduced the size\nof data. Fault locations were equivalent to different labels,\nand different CNNs were trained to classify fault locations.\nFinally, monitoring information of several sensors placed\naround the transformer windings were trained using different\nCNNs. Furthermore, the fault localization results before and\nafter the image segmentation were analyzed.\n62718 VOLUME 7, 2019\nJ. Duanet al.: Intelligent Localization of Transformer Internal Degradations\nThe proposed intelligent fault localization method could\nlocate internal faults of transformers effectively. The aver-\nage localization accuracies of different CNNs (the last\n50% iterations) before and after the image segmentation\nslightly decreased from 98.9769% to 98.6531%, as shown\nin the last row of Table XI. In the meantime, according to\nTable VI and VII, the average calculation time per iteration\nof all the CNNs dropped by 7.3615%, from 13.177 sec to\n12.207 sec. The loss value reduced by 72.549%, from 0.051 to\n0.014. Besides, the data capacities reduced to approximately\n1% of the counterparts in original data set. Likewise, the aver-\nage fault localization accuracies of all the CNNs (the last\n50% iterations) before and after image segmentation process\nreached 97.9502% and 94.4209%, respectively, when using\nthe data set of partial areas. The fault diagnosing accuracies\nof in all cases was much higher than the SVM’s (81.86%).\nFurthermore, the average calculation time per iteration based\non different CNNs was presented in Table 8 and Table 9, and\nit dropped by 8.816%, from 10.526 to 9.598 sec per itera-\ntion. In addition, the loss value reduced by 37.6812%, from\n0.069 to 0.043. Finally, the evaluation method was proposed,\nand Friedman statistical hypothesis test was performed to\nverify the applicabilities of different network models in this\ncase.\nREFERENCES\n[1] M. Bagheri, A. Zollanvari, and S. Nezhivenko, ‘‘Transformer fault con-\ndition prognosis using vibration signals over cloud environment,’’ IEEE\nAccess., vol. 6, pp. 9862–9874, 2018.\n[2] G. Rigatos and P. Siano, ‘‘Power transformers’ condition monitoring using\nneural modeling and the local statistical approach to fault diagnosis,’’ Int.\nJ. Elect. Power Energy Syst., vol. 80, pp. 150–159, Sep. 2016.\n[3] J. R. da Silva and J. P. A. Bastos, ‘‘Online evaluation of power transformer\ntemperatures using magnetic and thermodynamics numerical modeling,’’\nIEEE Trans. Magn., vol. 53, no. 6, Jun. 2017, Art. no. 8106104.\n[4] D. Susa and M. Lehtonen, ‘‘Dynamic thermal modeling of power trans-\nformers: Further development—Part II,’’ IEEE Trans. Power Del., vol. 21,\nno. 4, pp. 1961–1970, Oct. 2016.\n[5] S. Tenbohlen, N. Schmidt, C. Breuer, S. Khandan, and R. Lebreton, ‘‘Inves-\ntigation of thermal behavior of an oil-directed cooled transformer wind-\ning,’’IEEE Trans. Power Del., vol. 33, no. 3, pp. 1091–1098, Jun. 2018.\n[6] L. Deng et al., ‘‘Modeling and analysis of parasitic capacitance of sec-\nondary winding in high-frequency high-voltage transformer using ﬁnite-\nelement method,’’IEEE Trans. Appl. Supercond., vol. 28, no. 3, Apr. 2018,\nArt. no. 5500105.\n[7] P.-Y. Wang, J.-M. Liu, Z.-H. Liu, and Y.-J. Chen, ‘‘Experiment and simu-\nlation of natural convection heat transfer of transformer oil under electric\nﬁeld,’’Int. J. Heat Mass Transf., vol. 115, pp. 441–452, Dec. 2017.\n[8] M. Lahonian and A. A. Golneshan, ‘‘Numerical study of temperature dis-\ntribution in a spherical tissue in magnetic ﬂuid hyperthermia using lattice\nBoltzmann method,’’IEEE Trans. Nanobiosci., vol. 10, no. 4, pp. 262–268,\nDec. 2011.\n[9] M. M. Islam, G. Lee, and S. N. Hettiwatte, ‘‘A review of condition\nmonitoring techniques and diagnostic tests for lifetime estimation of power\ntransformers,’’Elect. Eng., vol. 100, no. 2, pp. 581–605, Jun. 2018.\n[10] A. J. Christina, M. A. Salam, Q. M. Rahman, F. Wen, S. P. Ang, and\nW. Voon, ‘‘Causes of transformer failures and diagnostic methods—\nA review,’’ Renew. Sustain. Energy Rev., vol. 82, no. 1, pp. 1442–1456,\nFeb. 2018.\n[11] J. Faiz and M. Soleimani, ‘‘Dissolved gas analysis evaluation in electric\npower transformers using conventional methods a review,’’ IEEE Trans.\nDielectr. Electr. Insul., vol. 24, no. 2, pp. 1239–1248, Apr. 2017.\n[12] W. Min, H. Cao, J. Cao, H.-L. Nguyen, J. B. Gomes, and\nS. P. Krishnaswamy, ‘‘An overview of state-of-the-art partial discharge\nanalysis techniques for condition monitoring,’’ IEEE Elect. Insul. Mag.,\nvol. 31, no. 6, pp. 22–35, Dec. 2015.\n[13] S. Hashemnia, ‘‘Charactrisation of power transformer frequency response\nsignature using ﬁnite element analysis,’’ Ph.D dissertation, Dept. Elect.\nEng., Univ. Curtin, Perth, WA, Australia, 2014.\n[14] T. Mariprasath and V. Kirubakaran, ‘‘A real time study on condition\nmonitoring of distribution transformer using thermal imager,’’ Infr. Phys.\nTechnol., vol. 90, pp. 78–86, May 2018.\n[15] X. Zhang, Z. Wang, and Q. Liu, ‘‘Interpretation of hot spot factor for\ntransformers in OD cooling modes,’’ IEEE Trans. Power Del., vol. 33,\nno. 3, pp. 1071–1080, Jun. 2017.\n[16] A. Y. Arabul and I. Senol, ‘‘Development of a hot-spot temperature cal-\nculation method for the loss of life estimation of an ONAN distribution\ntransformer,’’Elect. Eng., vol. 100, no. 3, pp. 1651–1659, Sep. 2017.\n[17] T. Touret, C. Changenet, F. Ville, M. Lalmi, and S. Becquerelle, ‘‘On the\nuse of temperature for online condition monitoring of geared systems—\nA review,’’Mech. Syst. Signal Process., vol. 101, pp. 197–210, Feb. 2018.\n[18] J. Wang, C. Luo, H. Huang, H. Zhao, and S. Wang, ‘‘Transferring pre-\ntrained deep CNNs for remote scene classiﬁcation with general features\nlearned from linear PCA network,’’ Remote Sens., vol. 9, pp. 1–255,\nMar. 2017.\n[19] Y. Xue and P. Beauseroy, ‘‘Transfer learning for one class SVM adaptation\nto limited data distribution change,’’ Pattern Recognit. Lett., vol. 100,\npp. 117–123, Dec. 2017.\n[20] J. Wang, H. Zheng, Y. Huang, and X. Ding, ‘‘Vehicle type recognition\nin surveillance images from labeled Web-nature data using deep transfer\nlearning,’’IEEE Trans. Intell. Transp. Syst., vol. 19, no. 9, pp. 2913–2922,\nSep. 2018.\n[21] Z. Kolar, H. Chen, and X. Luo, ‘‘Transfer learning and deep convolutional\nneural networks for safety guardrail detection in 2D images,’’ Automat.\nConstruct., vol. 89, pp. 58–70, May 2018.\n[22] O. Janssens, R. Van de Walle, M. Loccuﬁer, and S. Van Hoecke, ‘‘Deep\nlearning for infrared thermal image based machine health monitoring,’’\nIEEE/ASME Trans. Mechatronics, vol. 23, no. 1, pp. 151–159, Jul. 2017.\n[23] L. Duan, M. Yao, J. Wang, T. Bai, and L. Zhang, ‘‘Segmented infrared\nimage analysis for rotating machinery fault diagnosis,’’ Infr. Phys. Technol.,\nvol. 77, pp. 267–276, Jul. 2016.\n[24] V. T. Tran, B.-S. Yang, F. Gu, and A. Ball, ‘‘Thermal image enhancement\nusing bi-dimensional empirical mode decomposition in combination with\nrelevance vector machine for rotating machinery fault diagnosis,’’ Mech.\nSyst. Signal Process., vol. 38, no. 2, pp. 601–614, Jul. 2013.\n[25] K. Lee, J. Lee, J. Lee, S. Hwang, and S. Lee, ‘‘Brightness-based convo-\nlutional neural network for thermal image enhancement,’’ IEEE Access,\nvol. 5, pp. 26867–26879, Nov. 2017.\n[26] S. Balla-Arabé, X. Gao, and B. Wang, ‘‘A fast and robust level set method\nfor image segmentation using fuzzy clustering and lattice Boltzmann\nmethod,’’IEEE Trans. Cybern., vol. 43, no. 3, pp. 910–920, Jun. 2013.\n[27] X. Zhang, Y. Qiao, F. Meng, C. Fan, and M. Zhang, ‘‘Identiﬁcation of\nmaize leaf diseases using improved deep convolutional neural networks,’’\nIEEE Access, vol. 6, pp. 30370–30377, 2018.\n[28] Y. LeCun, Y. Bengio, and G. Hinton, ‘‘Deep learning,’’ Nature, vol. 521,\npp. 436–444, May 2015.\n[29] Y. Qi, C. Shen, D. Wang, J. Shi, X. Jiang, and Z. Zhu, ‘‘Stacked sparse\nautoencoder-based deep network for fault diagnosis of rotating machin-\nery,’’IEEE Access, vol. 5, pp. 15066–15079, Jul. 2017.\n[30] J. Sun, C. Yan, and J. Wen, ‘‘Intelligent bearing fault diagnosis method\ncombining compressed data acquisition and deep learning,’’ IEEE Trans.\nInstrum. Meas., vol. 67, no. 1, pp. 185–195, Jan. 2017.\n[31] L. Zhao and X. Wang, ‘‘A deep feature optimization fusion method\nfor extracting bearing degradation features,’’ IEEE Access, vol. 6,\npp. 19640–19653, 2018.\n[32] W. Zhang et al., ‘‘LSTM-based analysis of industrial IoT equipment,’’\nIEEE Access, vol. 6, pp. 23551–23560, Apr. 2018.\n[33] A. A. Mohamad, ‘‘The Boltzmann equation,’’ in Lattice Boltzmann\nMethod: Fundamentals and Engineering Applications With Computer\nCodes. London, U.K.: Springer, 2011, ch. 2, sec. 3, pp. 19–22.\n[34] S. Chen and G. D. Doolen, ‘‘Lattice Boltzmann method for ﬂuid ﬂows,’’\nAnnu. Rev. Fluid Mech., vol. 30, pp. 329–364, Jan. 1998.\n[35] X. He and L. S. Luo, ‘‘Theory of the lattice Boltzmann method: From\nthe Boltzmann equation to the lattice Boltzmann equation,’’ Phys. Rev. E,\nStat. Phys. Plasmas Fluids Relat. Interdiscip. Top., vol. 56, pp. 6811–6817,\nDec. 1997.\n[36] A. Krizhevsky, I. Sutskever, and G. E. Hinton, ‘‘ImageNet classiﬁcation\nwith deep convolutional neural networks,’’ in Proc. Adv. Neural Inf. Pro-\ncess. Syst., 2012, pp. 1097–1105.\nVOLUME 7, 2019 62719\nJ. Duanet al.: Intelligent Localization of Transformer Internal Degradations\n[37] K. Simonyan and A. Zisserman. (2014). ‘‘Very deep convolutional net-\nworks for large-scale image recognition.’’ [Online]. Available: https://\narxiv.org/abs/1409.1556\n[38] C. Szegedy. (Sep. 2015). ‘‘Going deeper with convolutions.’’ [Online].\nAvailable: https://arxiv.org/abs/1409.4842\n[39] K. He, X. Zhang, S. Ren, and J. Sun, ‘‘Deep residual learning for\nimage recognition,’’ in Proc. IEEE Conf. Comput. Vis. Pattern Recognit.,\nJun. 2016, pp. 770–778.\n[40] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, ‘‘Densely\nconnected convolutional networks,’’ in Proc. IEEE Conf. Comput. Vis.\nPattern Recognit., Jan. 2018, pp. 4700–4708.\n[41] L. N. Forrest et al., ‘‘SqueezeNet: AlexNet-level accuracy with 50x fewer\nparameters and <0.5 MB model size,’’ in Proc. IEEE Conf. Comput. Vis.\nPattern Recognit., Nov. 2016, pp. 1–13.\n[42] K. He, G. Gkioxari, P. Dollár, and R. Girshick. (2017). ‘‘Mask R-CNN.’’\n[Online]. Available: https://arxiv.org/abs/1703.06870\n[43] S. Bianco, R. Cadene, L. Celona, and P. Napoletano, ‘‘Benchmark analysis\nof representative deep neural network architectures,’’ IEEE Access, vol. 6,\npp. 64270–64277, Oct. 2018.\n[44] P. Nemenyi, ‘‘Distribution-free multiple comparisons,’’ Ph.D. dissertation,\nMath Statist., Princeton Univ., Princeton, NJ, USA, 1963.\n[45] M. Mohammadi, W. Hofman, and Y.-H. Tan, ‘‘A comparative study of\nontology matching systems via inferential statistics,’’ IEEE Trans. Knowl.\nData Eng., vol. 31, no. 4, pp. 615–628, Apr. 2019.\nJIAJUN DUAN received the B.S. degree\nfrom Chongqing University, Chongqing, China,\nin 2016. He is currently pursuing the Ph.D. degree\nin electrical engineering with Wuhan Univer-\nsity, Wuhan, China. His current research interests\ninclude intelligent monitoring systems for trans-\nformers and deep learning.\nYIGANG HEreceived the M.Sc. degree in electri-\ncal engineering from Hunan University, Changsha,\nChina, in 1992, and the Ph.D. degree in electri-\ncal engineering from Xi’an Jiaotong University,\nXi’an, China, in 1996. In 1990, he joined the\nCollege of Electrical and Information Engineering,\nHunan University, and was promoted to Associate\nProfessor and Professor, in 1996 and 1999, respec-\ntively. From 2006 to 2011, he was the Director\nof the Institute of Testing Technology for Circuits\nand Systems, Hunan University. He was a Senior Visiting Scholar with the\nUniversity of Hertfordshire, Hatﬁeld, U.K., in 2002. In 2011, he joined the\nHefei University of Technology, Hefei, China. In 2017, he joined Wuhan\nUniversity, Wuhan, China, where he is currently the Vice Dean of the\nSchool of Electrical Engineering. He has authored over 200 journal and\nconference papers in the aforementioned areas and several chapters in edited\nbooks. His current research interests include the areas of circuit theory\nand its applications, testing and fault diagnosis of analog and mixed-signal\ncircuits, electrical signal detection, smart grid, radio frequency identiﬁcation\ntechnology, and intelligent signal processing.\nDr. He has been serving on the Technical Program Committee of a number\nof international conferences. He was a recipient of a number of national and\ninternational awards, prizes, and honors.\nBOLUN DU received the B.S. degree from the\nCollege of Electrical and Information Engineering,\nHunan University, Changsha, China, in 2016. He is\ncurrently pursuing the Ph.D. degree with Wuhan\nUniversity, Wuhan, China. His research interest\nincludes power electronic circuit fault diagnosis.\nRUAA M. RASHAD GHANDOURreceived the\nB.S. degree in electrical engineering from the\nSudan University of Science and Technology,\nKhartoum, Sudan. She is currently pursuing the\nPh.D. degree with Wuhan University, Wuhan,\nChina. She served as an Electrical Engineer with\nSudanese Electricity and Distribution Company.\nHer main research interests include power trans-\nformer fault diagnosis and prediction.\nWENJIE WU received the B.S. degree from\nWuhan University, Wuhan, China, in 2017, where\nshe is currently pursuing the master’s degree\nin electrical engineering. Her research interest\nincludes transformer fault diagnosis and progno-\nsis.\nHUI ZHANG received the M.Sc. degree in elec-\ntrical engineering from the Wuhan University of\nHydropower and Electrical Engineering, Wuhan,\nin 1997, and the Dr.-Ing. degree in electrical\nengineering from the Technical University of\nKarlsruhe, Germany (now Karlsruhe Institute of\nTechnology, KIT), in 2004.\nShe is currently a Professor with the School\nof Electrical Engineering, Wuhan University. Her\nresearch interests include many ﬁelds, such as\nhigh-performance optimal pulse width modulation techniques for high power\nconverters and power active ﬁltering, power quality, smart grid, and so on.\n62720 VOLUME 7, 2019",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7167834639549255
    },
    {
      "name": "Convolutional neural network",
      "score": 0.6958541870117188
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6630059480667114
    },
    {
      "name": "Segmentation",
      "score": 0.6231146454811096
    },
    {
      "name": "Deep learning",
      "score": 0.5424711108207703
    },
    {
      "name": "Artificial neural network",
      "score": 0.5136668086051941
    },
    {
      "name": "Image segmentation",
      "score": 0.5094874501228333
    },
    {
      "name": "Transformer",
      "score": 0.4589563012123108
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.4499564468860626
    },
    {
      "name": "Feature extraction",
      "score": 0.44855907559394836
    },
    {
      "name": "Computer vision",
      "score": 0.4110494554042816
    },
    {
      "name": "Engineering",
      "score": 0.14714285731315613
    },
    {
      "name": "Electrical engineering",
      "score": 0.07093286514282227
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ]
}