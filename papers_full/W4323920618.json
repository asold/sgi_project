{
  "title": "Transformer-based structuring of free-text radiology report databases",
  "url": "https://openalex.org/W4323920618",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A4225750530",
      "name": "Nowak, S.",
      "affiliations": [
        "University Hospital Bonn"
      ]
    },
    {
      "id": null,
      "name": "Biesner, D.",
      "affiliations": [
        "Fraunhofer Institute for Intelligent Analysis and Information Systems"
      ]
    },
    {
      "id": null,
      "name": "Layer, Y. C.",
      "affiliations": [
        "University Hospital Bonn"
      ]
    },
    {
      "id": null,
      "name": "Theis, M.",
      "affiliations": [
        "University Hospital Bonn"
      ]
    },
    {
      "id": "https://openalex.org/A4271828729",
      "name": "Schneider, H.",
      "affiliations": [
        "Fraunhofer Institute for Intelligent Analysis and Information Systems"
      ]
    },
    {
      "id": null,
      "name": "Block, W.",
      "affiliations": [
        "University Hospital Bonn"
      ]
    },
    {
      "id": null,
      "name": "Wulff, B.",
      "affiliations": [
        "Fraunhofer Institute for Intelligent Analysis and Information Systems"
      ]
    },
    {
      "id": null,
      "name": "Attenberger, U. I.",
      "affiliations": [
        "University Hospital Bonn"
      ]
    },
    {
      "id": null,
      "name": "Sifa, R.",
      "affiliations": [
        "Fraunhofer Institute for Intelligent Analysis and Information Systems"
      ]
    },
    {
      "id": null,
      "name": "Sprinkart, A. M.",
      "affiliations": [
        "University Hospital Bonn"
      ]
    },
    {
      "id": "https://openalex.org/A4225750530",
      "name": "Nowak, S.",
      "affiliations": [
        "University Hospital Bonn"
      ]
    },
    {
      "id": null,
      "name": "Biesner, D.",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Layer, Y. C.",
      "affiliations": [
        "University Hospital Bonn"
      ]
    },
    {
      "id": null,
      "name": "Theis, M.",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4271828729",
      "name": "Schneider, H.",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Block, W.",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Wulff, B.",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Attenberger, U. I.",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Sifa, R.",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Sprinkart, A. M.",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3010618557",
    "https://openalex.org/W4241300132",
    "https://openalex.org/W2963466845",
    "https://openalex.org/W1981276685",
    "https://openalex.org/W6702248584",
    "https://openalex.org/W4226086148",
    "https://openalex.org/W3103694015",
    "https://openalex.org/W3045332379",
    "https://openalex.org/W3204613796",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W2980708516",
    "https://openalex.org/W3162790191",
    "https://openalex.org/W4280514943",
    "https://openalex.org/W2986573554",
    "https://openalex.org/W2989759966",
    "https://openalex.org/W1660390307"
  ],
  "abstract": null,
  "full_text": "https://doi.org/10.1007/s00330-023-09526-y\nIMAGING INFORMATICS AND ARTIFICIAL INTELLIGENCE \nTransformer‑based structuring of free‑text radiology report databases\nS. Nowak1 · D. Biesner2 · Y . C. Layer1 · M. Theis1 · H. Schneider2 · W. Block1 · B. Wulff2 · U. I. Attenberger1 · R. Sifa2 · \nA. M. Sprinkart1\nReceived: 16 September 2022 / Revised: 5 January 2023 / Accepted: 3 February 2023 \n© The Author(s) 2023\nAbstract\nObjectives To provide insights for on-site development of transformer-based structuring of free-text report databases by \ninvestigating different labeling and pre-training strategies.\nMethods A total of 93,368 German chest X-ray reports from 20,912 intensive care unit (ICU) patients were included. Two labeling \nstrategies were investigated to tag six findings of the attending radiologist. First, a system based on human-defined rules was applied \nfor annotation of all reports (termed “silver labels”). Second, 18,000 reports were manually annotated in 197 h (termed “gold labels”) \nof which 10% were used for testing. An on-site pre-trained model  (Tmlm) using masked-language modeling (MLM) was compared \nto a public, medically pre-trained model  (Tmed). Both models were fine-tuned on silver labels only, gold labels only, and first with \nsilver and then gold labels (hybrid training) for text classification, using varying numbers (N: 500, 1000, 2000, 3500, 7000, 14,580) \nof gold labels. Macro-averaged F1-scores (MAF1) in percent were calculated with 95% confidence intervals (CI).\nResults Tmlm,gold (95.5 [94.5–96.3]) showed significantly higher MAF1 than  Tmed,silver (75.0 [73.4–76.5]) and  Tmlm,silver (75.2 \n[73.6–76.7]), but not significantly higher MAF1 than  Tmed,gold (94.7 [93.6–95.6]),  Tmed,hybrid (94.9 [93.9–95.8]), and  Tmlm,hybrid \n(95.2 [94.3–96.0]). When using 7000 or less gold-labeled reports,  Tmlm,gold (N: 7000, 94.7 [93.5–95.7]) showed significantly \nhigher MAF1 than  Tmed,gold (N: 7000, 91.5 [90.0–92.8]). With at least 2000 gold-labeled reports, utilizing silver labels did \nnot lead to significant improvement of  Tmlm,hybrid (N: 2000, 91.8 [90.4–93.2]) over  Tmlm,gold (N: 2000, 91.4 [89.9–92.8]).\nConclusions Custom pre-training of transformers and fine-tuning on manual annotations promises to be an efficient strategy \nto unlock report databases for data-driven medicine.\nKey Points \n• On-site development of natural language processing methods that retrospectively unlock free-text databases of radiology  \n   clinics for data-driven medicine is of great interest.\n• For clinics seeking to develop methods on-site for retrospective structuring of a report database of a certain department, it  \n   remains unclear which of previously proposed strategies for labeling reports and pre-training models is the most appropriate  \n   in context of, e.g., available annotator time.\n• Using a custom pre-trained transformer model, along with a little annotation effort, promises to be an efficient way to  \n   retrospectively structure radiological databases, even if not millions of reports are available for pre-training.\nKeywords Radiology · Deep learning · Natural language processing · Intensive care units · Thorax\nAbbreviations\nCI  Confidence interval\nCVC   Central venous catheter\nICU   Intensive care unit\nMAAUC   Macro-averaged area under the receiver oper-\nating characteristic curve\nMAF1  Macro-averaged F1-score\nML   Machine learning\nMLM   Masked-language modeling\nNLP   Natural language processing\nTFIDF   Term frequency–inverse document frequency\nS. Nowak and D. Biesner contributed equally as joint first authors.\nU.I. Attenberger, R. Sifa, and A.M. Sprinkart contributed equally \nas joint last authors.\n * S Nowak \n sebastian.nowak@ukbonn.de\n1 Department of Diagnostic and Interventional Radiology, \nUniversity Hospital Bonn, Venusberg-Campus 1, \n53127 Bonn, Germany\n2 Fraunhofer Institute for Intelligent Analysis and Information \nSystems IAIS, Sankt Augustin, Germany\n/ Published online: 11 March 2023\nEuropean Radiology (2023) 33:4228–4236\nIntroduction\nStructured reporting, i.e., the use of IT-based systems for \nimporting and arranging medical content in radiological \nreports, not only has the potential to have a positive impact \non patient care by enhancing the quality of radiologists’ \npractices, it is also beneficial for the development of image-\nbased artificial intelligence systems by helping to compile \nlarge retrospective patient collectives with diseases of inter-\nest [1, 2]. To this day, most radiological reports are in free-\ntext and not in structured format. Even if a clinic would \nintroduce structured reporting, retrospective assembling of \nlarge image collectives is labor-intensive, as the correspond-\ning reports of recent years remain unstructured. Therefore, \nthere is a need for automatic natural language processing \n(NLP) systems that categorize free-text reports in a set of \npredefined labels, thereby unlocking the corresponding \nimage database for the development of an artificial intel -\nligence–based diagnostic decision system.\nTo achieve automated analysis of medical text data, vari-\nous methods with different levels of complexity have been \nproposed. For example, simple systems based on human-\ndefined rules have been applied to automatically annotate \nthe occurrence of findings in English chest X-ray reports \n[3]. These rule-based systems have the advantage that the \nmethod itself does not require any manually annotated \nreports. However, the creator of such a system must have \nconsiderable expert knowledge about general information, \ncontent, and wording of the reports. Moreover, there may \nstill be findings whose appearance and description are sub -\nject to great variability, making the establishment of com -\nprehensive rules a difficult task.\nOn the other hand, there are machine learning \n(ML)–based methods that have the disadvantage of requiring \na large amount of time-consuming manual annotated reports \nfor training. In recent years, transformer models based on the \nself-attention mechanism have emerged as the state-of-the-\nart ML–based NLP method, also for medical text data [4–9]. \nThe required amount of annotated data to train a transformer \ncan be reduced by transfer learning, i.e., utilizing the funda-\nmental text comprehension skills of a model that has already \nbeen pre-trained on different large public datasets and/or for \nanother task.\nIn contrast to radiological image datasets, where the appear-\nance of a finding, e.g., a pneumothorax, is independent of the \ncountry, the description of the finding in a radiological report \ncan differ substantially, which is most obvious if the coun -\ntries do not share a common language. For NLP, this lim -\nits the development and application of pre-trained models \ncompared to computer vision applications, as, e.g., a model \npre-trained on English reports cannot be directly applied to \nGerman texts. Moreover, unlike cross-sectional radiological \nimages, text-based medical data contain sensitive information \ndirectly linked to personal data. This makes the public shar-\ning of medical text data in compliance with data protection \nlaws highly problematic in many countries [10]. Even when \nsharing pre-trained parameters of a transformer model trained \non sensible data, it also cannot be ensured that data protection \nlaws are met, as it has been shown that information from the \ntraining data can be extracted from large pre-trained transform-\ners [11]. There are efforts to automate the de-identification of \nGerman text data using ML methods, from medical and other \ndomains. However, currently, these methods cannot guarantee \n100% accuracy [10, 12]. Consequently, efficient development \nof NLP models for structuring radiological reports on-site is \nof great interest.\nSeveral approaches have already been presented for the on-\nsite development of transformer models based on radiologi-\ncal text data. Two studies that are based on several hundred \nthousand English-language reports propose to employ a pub-\nlicly available transformer pre-trained on medical text and to \nfine-tune that model in a two-step hybrid label approach. With \nthe hybrid approach, the pre-trained model is first adapted to \na high number of rule-based annotated text (termed “silver \nlabels”) and then to only a very limited number of manual \nannotations (termed “gold labels”) [7, 8]. In contrast, another \nstudy proposes a custom pre-training of the transformer by \nMLM and next-sentence prediction using millions of radiology \nreports and subsequent fine-tuning to only a few gold-labeled \nreports [9].\nHowever, for clinics seeking to develop NLP models on-\nsite, it remains unclear which of those pre-training and labeling \nstrategies are most appropriate for structuring their free-text \nradiological report database. First, it is not clear if a custom \npre-training of transformer models is also beneficial with a \nsignificantly lower number of reports than in above-mentioned \nstudies. Second, it is not clear whether the effort required to \ncreate a rule-based system for silver label generation in hybrid \ntraining is worthwhile compared to utilizing more gold labels \nby investing more annotator time. Therefore, the goal of this \nwork is to provide insight and guidance for efficient retrospec-\ntive structuring of radiological databases by systematically \nevaluating the performance of publicly available and custom \npre-trained text-based transformers with respect to different \nlabeling strategies and human annotation effort.\nMaterials and methods\nDataset and annotation\nWith institutional review board approval (AZ 411/21), \nwritten informed consent was waived, and approved data \nprocessing took place on the basis of the Health Data Pro -\ntection Act North Rhine-Westphalia (GDSG NW) §6 (2) \nstate law NRW. The retrospective dataset includes 93,368 \n4229European Radiology  (2023) 33:4228–4236\nfree-text chest X-ray reports of 20,912 ICU patients (age: \n62.7 ± 21.4, 8081 f emale) from University Hospital Bonn \nthat were extracted consecutively from the radiological \ninformation system dating between December 2015 and \nJuly 2021.\nFirst, 35 labels including not only findings but also \nfurther information, e.g., on indication, were defined for \nsystematic annotation of the reports (see Supplement \nS1). Information on the interpretation of findings was \nnot assessed from the reports. Under the supervision of \na radiology resident (Y.C.L.), two medical research assis -\ntants labeled this information using the open-source soft -\nware doccano [ 13]. The medical research assistants were \ntrained to assign the correct labels based on the context \nof the free-text reports and not just on individual words. \nIn case of ambiguity, they were instructed to consult the \nsupervisor. Manually annotated gold labels were curated \nfor 18,000 reports including only reports with unique \nadmission numbers. A subset of six findings that are fre -\nquently raised during a patient’s ICU stay were selected \nfrom the entire label set. This selection was based on \nfrequency of the finding and their clinical relevance and \nwas made prior to NLP development. The NLP models \nwere developed to predict the occurrence of these labels \nbased on the report text via multi-label classification. \nThese labels and their relative appearances within the \ngold-labeled reports are pulmonary infiltrates (20.0%), \npleural effusion (45.6%), pulmonary congestion (34.0%), \npneumothorax (3.8%), regular position of the central \nvenous catheter (CVC) (45.8%), and misplaced position \nof the CVC (8.4%).\nThe 18,000 gold-labeled reports were randomly split into \ntraining set A (14,580), validation set B (1620), and test set \nC (1800). Additional 500 reports (test set D) were labeled by \nthe radiology resident and both research assistants indepen-\ndently to determine the agreement between the annotators. \nThis dataset was also used for the final test of the best NLP \nmodel with annotations of the radiology resident. Moreover, \nsilver labels were created for a total of 91,068 reports apply-\ning a rule-based model which is described below. These are \nall available reports except the 1800 and 500 texts of the \ngold-labeled hold-out test sets C and D. Silver-labeled data \nwere split into training set E (81,961) and validation set F \n(9107). Figure 1 shows an overview of the entire study.\nRule‑based model\nA set of rules was defined to automatically annotate the free-\ntext radiological reports. In short, the algorithm searches for \nspecific terms, negations, and descriptions of uncertainty or \napplies further text-based rules in the “findings” section of \nthe report. Detailed descriptions of the rule-based system \ncan be found in Supplement S2.\nBaseline NLP model\nAs a baseline NLP approach, we trained a term fre -\nquency–inverse document frequency (TFIDF) model on the \ntraining text and fitted a one-layer fully connected neural \nnetwork to the labeled training data [ 14]. Training details \ncan be found in Supplement S3.\nTransformer‑based model\nWe applied BERT as an established transformer model that \nhas also been used in other work on medical text analy -\nsis [5, 7–9]. See Supplement S4 for details on the model \narchitecture.\nTo investigate the impact of different pre-training strate-\ngies, we employed (i) a publicly available BERT language \nmodel that was pre-trained on (not annotated) German legal \ndocuments, Wikipedia, and news articles and then further \nadapted to medical articles and texts scraped from the web \n (Tmed) [15–17] and (ii) created a custom pre-trained BERT \nlanguage model  (Tmlm) by applying MLM on the texts of \ntrain set E. To demonstrate the general effect of pre-training, \nwe also trained a model from scratch for classification on \ngold-labeled text data without any pre-training  (Trand,gold).\nTo examine the difference between different label strate-\ngies, three experiments were performed with the two pre-\ntrained models. First, the pre-trained models were fine-tuned \non the 14,580 gold labels of training set A only  (Tmed,gold, \n Tmlm,gold ). Second, both pre-trained models were fine-\ntuned on silver-labeled training set E  (Tmed,silver,  Tmlm,silver). \nThird, the models fine-tuned on silver-labeled training set \nE  (Tmed,silver ,  Tmlm,silver ) were subsequently fine-tuned on \ntraining set A in a hybrid training  (Tmed,hybrid,  Tmlm,hybrid). To \ninvestigate the effect of the number of available gold labels \nfor fine-tuning, the models were also trained with limited \nnumbers of gold-labeled reports of train set A (500, 1000, \n2000, 3500, 7000 reports). All models were tested on test set \nC, and the best model was additionally tested on test set D.\nWhen fine-tuning the models for text classification, \nwe applied the following concepts. As proposed in pre -\nvious studies, we fine-tuned all pre-trained models for \ntext classification in two steps: First, frozen pre-trained \nlanguage model parameters were used to adapt the new \nclassification head and then all parameters were trained, \nbut with layer-specific learning rates with maximum val -\nues increasing linearly from  10−9 to  10−6 from the first \nto the last layer [ 18–20]. Since the threshold for binari -\nzation of the predictions after sigmoid activation is not \nintrinsically set in multi-label classification, class-specific \nthresholds were determined by identifying the thresholds \nwith the highest F1-scores on the training data [ 21]. Also, \noversampling and loss weighting according to the occur -\nrence of the classes within the training data were used to \n4230 European Radiology  (2023) 33:4228–4236\nFig. 1  Ov erview of the presented study. The dataset of the pre -\nsented study includes a total of 93,368 free-text chest X-ray \nreports of intensive care unit patients. For a subset of the dataset, \nhuman annotations were generated for the occurrence of six find -\nings within the reports to create gold-labeled training, validation, \nand test datasets. Furthermore, a rule-based system was applied \nfor silver label generation. The use of an on-site pre-trained model \nusing masked-language modeling  (Tmlm) was compared to a public, \nmedically pre-trained model  (Tmed) when adapting to silver labels \nonly, gold labels only, and to first with silver and then gold labels \n(hybrid). To also give insights into which pre-training and labeling \nstrategy is most appropriate in context of available human anno -\ntation time, the models were developed using varying numbers of \ngold-labeled reports\nTable 1  Model performances \nfor different pre-training and \nlabeling strategies using all \ntraining data\nF1-scores (%) observed for the hold-out test set of 1800 gold-labeled reports for the rule-based (RB) sys -\ntem, the TFIDF approach and the transformer models trained with all 14,580 gold-labeled training data\nThe support (SP), i.e., the number of positive samples, is given for each class\nFor each class, the highest F1-scores are indicated in bold\nSilver Gold Hybrid\nClass SP RB T med Tmlm TFIDF T rand Tmed Tmlm Tmed Tmlm\nInfiltrates 352 69.7 69.3 69.2 79.8 80.3 92.9 92.9 93.6 92.0\nCongestion 611 94.3 94.1 94.2 88.7 88.2 98.1 98.1 98.1 97.9\nEffusion 818 95.0 94.6 94.7 88.7 91.0 98.8 98.8 98.8 98.8\nPneumothorax   65 87.8 87.1 87.0 75.2 79.7 96.1 96.0 98.5 98.4\nRegular CVC 825 67.0 67.8 67.9 89.8 90.7 93.4 95.4 94.9 95.0\nMisplaced CVC 151 36.9 37.3 38.1 77.2 75.7 88.8 91.7 85.6 89.3\nMacro average 2822 75.1 75.0 75.2 83.2 84.3 94.7 95.5 94.9 95.2\nMicro average 2822 77.3 77.3 77.5 87.1 87.7 95.7 96.5 96.1 96.1\n4231European Radiology  (2023) 33:4228–4236\ncompensate for class imbalance. Classes that occurred in \nless than 25% of the training reports were duplicated until \nthey accounted for at least 25%.\nThe pre-trained models fine-tuned for text classification \non 14,580 and 7000 gold-labeled reports were trained for \n75 epochs. Models that were fine-tuned on less than 7000 \nreports were trained with the same amount of optimiza -\ntion steps as the models trained on 7000 reports to ensure \nconvergence. The pre-trained models that were fine-tuned \non 81,961 silver-labeled reports were trained for 25 epochs.\nFor the custom pre-training via MLM, first, the BERT model \nwas trained on 81,961 reports with a maximum learning rate \nof  10−4 and 15% of tokens masked for 150 epochs. After that, \nthe model was further trained for 150 epochs with a maximum \nlearning rate of  10−5 and 15% of whole words masked within \nthe text. For custom pre-training, no weight decay was used.\nFor all models, the “bert-base-german-cased” tokenizer \nof the Huggingface’s transformer library was used and all \nmodels were trained using the Adam optimizer with decou-\npled weight decay regularization of 0.01, a learning rate \nTable 2  Model performances \nfor different pre-training \nand labeling strategies using \ndifferent numbers of gold-\nlabeled training data\nF1-scores (%) observed on all classes for the hold-out test set of 1800 gold-labeled reports for the experi -\nments on training with the different numbers ( N) of the 14,580 gold-labeled training reports. The highest \nF1-scores of a class at a given N are highlighted by bold font. Approximately 5.5 h of work was performed \nto annotate 500 reports\n* Significantl y higher F1-scores comparing to all models trained with the same label strategy (gold or \nhybrid), independent of the model  (Tmed,  Tmlm, TFIDF)\n† Significantl y higher F1-scores of a hybrid or gold-trained model respectively compared to all models \ntrained with the other label strategy\nN Gold Hybrid Gold Hybrid\nTFIDF T med Tmlm Tmed Tmlm TFIDF T med Tmlm Tmed Tmlm\nMacro averaged Micro averaged\n500 (3.4%) 34.9 59.8 70.9* 86.9 † 90.4*† 57.9 81.6 85.0* 92.7 † 93.9†\n1000 (6.9%) 44.7 64.5 85.6* 91.5† 87.6 66.3 82.3 91.4* 94.4† 92.6\n2000 (13.7%) 58.2 84.1 91.4* 89.1 91.8 74.3 91.6 94.0* 93.0 94.3*\n3500 (24.0%) 68.6 88.5 93.5* 91.6 93.0 79.6 93.3 95.6* 94.1 95.1\n7000 (48.0%) 77.4 91.5 94.7* 92.1 94.1 84.3 94.4 96.2* 94.4 95.6*\n14,580 (100%) 83.2 94.7 95.5 94.9 95.2 87.1 95.7 96.5 96.1 96.1 \nMisplaced CVC Congestion\n500 (3.4%)   2.6 33.2 33.3 53.4 † 73.6*† 37.4 87.5 94.2* 97.6† 97.5†\n1000 (6.9%) 16.8 44.0 65.4* 77.1 77.4† 55.0 90.2 97.5* 97.9 95.9\n2000 (13.7%) 45.0 66.7 81.8* 72.2 82.9* 68.6 97.1 98.1 97.2 97.1\n3500 (24.0%) 54.3 74.7 87.0* 78.0 85.7 76.9 97.8 98.3 97.1 97.0\n7000 (48.0%) 68.2 80.4 88.9* 80.9 88.1 83.2 98.4 98.6 97.9 97.9\n14,580 (100%) 77.2 88.8 91.7 85.6 89.3 88.7 98.1 98.1 98.1 97.9 \nRegular CVC Effusion\n500 (3.4%) 77.2 85.6 81.7 90.9 † 92.2† 68.2 88.8 92.1* 98.3† 97.9†\n1000 (6.9%) 80.2 83.9 89.2* 92.7† 91.9 76.4 89.4 96.5* 98.5† 95.8\n2000 (13.7%) 85.2 89.9 92.5 92.4 92.8 80.4 97.5 97.1 97.9 98.0\n3500 (24.0%) 87.2 90.9 94.6* 92.3 94.2 83.7 98.5 98.3 98.4 98.1\n7000 (48.0%) 88.7 91.7 95.0* 93.1 94.5 87.7 98.8 98.7 98.2 98.6\n14,580 (100%) 89.8 93.4 95.4 94.9 95.0 88.7 98.8 98.8 98.8 98.8  \nInfiltrates Pneumothorax\n500 (3.4%) 24.2 63.6 79.4* 88.0 † 90.3†   0.0   0.0 44.9* 93.0† 91.2†\n1000 (6.9%) 36.6 62.3 85.4* 90.6† 89.9   3.0 16.9 79.3* 92.2† 74.8\n2000 (13.7%) 53.0 84.7 89.1 86.5 90.2 16.7 68.7 89.8* 88.7 90.0\n3500 (24.0%) 67.9 88.0 91.2 90.5 91.9 41.5 81.0 91.7 93.7 90.9\n7000 (48.0%) 77.2 90.7 92.6 89.4 91.3 59.6 89.1 94.4 93.1 94.4\n14,580 (100%) 79.8 92.9 92.9 93.6 92.0 75.2 96.1 96.0 98.5 98.4\n4232 European Radiology  (2023) 33:4228–4236\nscheme with warmup until 10% of all training steps and \nsubsequent cosine decay, drop-out of 0.1, mixed precision, \nrandom seed 42, and a batch size of 24 on an NVIDIA RTX \n3090 or NVIDIA TITAN RTX using PyTorch v1.8.1 and the \ntransformers library v4.13.0 [15, 22]. The performance met-\nrics were calculated using scikit-learn v0.24.2, and 95% CIs \nwere calculated by bootstrapping with 1000 resamples for \nthe text-classification models [23]. Performance differences \nwere considered significant based on non-overlapping CIs.\nResults\nTime for manual annotation of 18,000 radiological reports \nwas 197 h (39.4 s per report). The two medical research \nassistants’ annotations showed high agreement with the \nradiology resident’s annotations, with mean accuracy of \n97.4% and 97.3% and MAF1 in percent of 92.9 and 93.5, \nrespectively.\nIn the custom pre-training of BERT  (Tmlm), an accuracy \nof 88.6% was achieved after 3.3 days of training to predict \nFig. 2  Model performances for \ndifferent numbers of gold-\nlabeled reports. F1-scores in \n% (y-axis) are displayed for \nthe rule-based (RB) system in \nblack, as well as for  Tmed,gold \n(blue),  Tmlm,gold (orange), \n TFIDFgold (green), and \n Tmlm,hybrid (red) using various \nnumbers of gold-labeled reports \nfor training (x-axis)\n4233European Radiology  (2023) 33:4228–4236\n15% masked tokens and subsequently an accuracy of 78.4% \nwas achieved after again 3.3 days of training to predict 15% \nmasked whole words on test data set C.\nTable 1 shows the performance of all examined models \ntrained with all available silver- and/or gold-labeled text \nclassification data. The highest performance was observed \nfor  Tmlm,gold with a MAF1 in percent of 95.5 (CI: 94.5–96.3), \nwhich was significantly higher than that of the rule-based sys-\ntem (75.1 [73.6–76.5]),  Tmed,silver (75.0 [73.4–76.5]),  Tmlm,silver \n(75.2 [73.6–76.7]),  TFIDFgold (83.2 [81.3–85.1]), and  Trand,gold \n(84.3 [82.5–86.0]). However, the performance was not signifi-\ncantly higher than that of  Tmed,gold (94.7 [93.6–95.6]),  Tmed,hybrid \n(94.9 [93.9–95.8]), and  Tmlm,hybrid (95.2 [94.3–96.0]).\nTable 2 and Fig.  2 show the performance of the exam -\nined models for all classes when using lower numbers of \ngold-labeled data. The classification of the description of \na misplaced CVC was found to be the most challenging \nclass with the lowest F1-scores for each method. Consider -\ning models trained exclusively with gold-labeled reports, \n Tmlm,gold showed significantly higher MAF1 as well as mis-\nplaced CVC F1-scores than  TFIDFgold and  Tmed,gold when \nonly 1000 to 7000 gold-labeled reports were provided for \ntraining. The hybrid models adapted on only 500 gold labels \n (Tmlm,hybrid  90.4 [89.0–91.9],  Tmed,hybrid  86.9 [85.1–88.5]) \nachieved already significantly higher MAF1 than the rule-\nbased system (75.1 [73.6–76.5]). Considering both models \ntrained with a hybrid label scheme, no significant differences \nin MAF1 and F1-scores for misplaced CVC were observed \nfor  Tmed,hybrid and  Tmlm,hybrid trained with 1000 or more gold \nlabels. When using 2000 or more gold-labeled reports (22 h of \nannotation), the previous use of silver labels in hybrid training \nof the BERT models  (Tmlm,hybrid 91.8 [90.4–93.2],  Tmed,hybrid \n89.1 [87.6–90.6]) did not provide a significant improvement \nof MAF1 over the BERT models  (Tmlm,gold 91.4 [89.9–92.8], \n Tmed,gold 84.1 [81.7, 86.0]) trained directly on the gold-labeled \nreports. Due to less than 4% positive pneumothorax cases \nleading to wide CIs, F1-scores for pneumothorax of the rule-\nbased system (87.8 [81.1–93.0]) are only significantly lower \ncompared with  Tmlm,hybrid (98.4 [95.9–100.0]) and  Tmed,hybrid \n(98.5 [96.0–100.0]) trained with all gold labels.\nTable 3 shows further performance metrics for the best \nmodel,  Tmlm,gold, which was pre-trained using MLM and fine-\ntuned to 14,580 gold labels that showed the highest MAF1 \n(95.5, CI: 94.5–96.3) and macro-averaged area under the \nreceiver operating characteristic curve (MAAUC: 97.1, CI: \n96.3–97.8) for test set C with 1800 cases, as well as for test \nset D with 500 cases (MAF1: 93.5, CI: 91.0–95.3; MAAUC: \n95.7, CI: 93.8–97.1). Due to space limitations, CIs for each \nsingle value in Tables 1–3 can be found in Supplement S5.\nDiscussion\nThe current study investigates efficient on-site development \nof NLP methods in the context of different pre-training and \nlabeling strategies for structuring and thus unlocking radio-\nlogical databases for data-driven medicine using German \nICU chest X-ray reports. The work provides clinics seeking \nto develop NLP models on-site with insights and guidance \non which strategy is preferable for their specific project in \nthe context of available annotator and developer time and \nthe complexity of the information to be extracted. Methods \nfor training transform-based NLP models will be provided \nupon reasonable request (https:// qilab. de).\nThe results show that when training with a large set of \nsilver labels without the use of gold labels, the pre-trained \nBERT models achieved comparable performance to the rule-\nbased system and are limited by the quality of the silver \nlabels. By using a publicly available, medically pre-trained \nBERT with a hybrid label approach that was first adapted \non all silver labels and then fine-tuned on a small set of \ngold-labeled reports, significantly higher performance can \nTable 3  De tailed model \nperformance of  Tmlm,gold for \nboth test sets\nF1-scores and AUC in % for each class on both test sets for  Tmlm,gold trained with all available data\nThe support (SP), i.e., the number of positive samples is given for each class and both test sets\nAC accuracy, RC recall, PR precision \nClass 1800 test set 500 test set\nSP AC PR RC F1 AUC  SP AC PR RC F1 A UC \nInfiltrates 352 97.2 91.2 94.6 92.9 96.2 105 94.6 86.1 88.6 87.3 92.4\nCongestion 611 98.7 97.6 98.7 98.1 98.7 176 97.8 97.1 96.6 96.9 97.5\nEffusion 818 98.9 98.5 99.0 98.8 98.9 241 99.4 100 98.8 99.4 99.4\nPneumothorax   65 99.7 100 92.3 96.0 96.2   20 99.4 100 85.0 91.9 92.5\nRegular CVC 825 95.8 95.8 95.0 95.4 95.8 211 95.8 93.6 96.7 95.1 95.9\nMisplaced CVC 151 98.6 88.8 94.7 91.7 96.8 50 98.0 87.0 94.0 90.4 96.2\nMacro average 2822 98.1 95.3 95.7 95.5 97.1 803 97.5 94.0 93.3 93.5 95.7\nMicro average 2822 97.7 96.1 96.8 96.5 97.4 803 97.4 95.1 95.8 95.4 96.8\n4234 European Radiology  (2023) 33:4228–4236\nbe achieved compared to the rule-based system. Both find -\nings are in line with previous studies that used silver-labeled \nchest X-ray reports in the English language by CheXpert \nand further trained on 1000 manually curated reports or sen-\ntences [3, 7, 8]. However, when utilizing 2000 or more gold-\nlabeled reports that were generated in only 22 h of annota -\ntion, the hybrid label approach did not provide a significant \nimprovement over training the publicly available BERT \nmodel directly with the gold labels. The results of this work \nalso show that the custom pre-training of BERT with only \n81,961 reports can not only achieve high MLM accuracy \ncompared to previous studies with millions of reports [ 9], \nbut also demonstrate that this model achieves significantly \nhigher performance than the publicly available pre-trained \nBERT model when further trained for report classification \nwith 7000 or less gold labels.\nThe performance of the rule-based system that gener -\nates the silver labels varies strongly between the extracted \nclasses. This can be explained by the fact that some infor -\nmation from the radiological reports have more variable \nattributes and are more difficult to identify by rules and \nstandard formulations. In contrast to previous studies, we \nextracted information about a regular or misplaced position \nof the CVC from the findings. Especially, the formulations \nfor a misplaced CVC appeared to be difficult to recognize \nwith simple rules, in contrast to, e.g., pleural effusion and \npulmonary congestion. Through further effort by clini -\ncians and technicians, certainly more special cases could \nbe covered by advanced rules, in order to further develop \nthe simple rule-based labeler. However, this would require \nextensive reading and studying of the reports, during which \ngold labels could already be generated. With regard to the \nresults of this study, it is therefore questionable whether for \ninformation with variable attributes and descriptions, the \neffort of developing advanced rules for a rule-based labeler \nis worthwhile compared to generating more gold labels with \nsubsequent training of custom pre-trained transformers.\nA limitation of the study is that annotation of the contents \nof the radiology reports was performed by medical research \nassistants under the supervision of a radiology resident. \nBecause the annotators did not have to interpret imaging, \nbut were simply required to identify and mark the statements \nof the attending radiologist within the report, we judged that \nannotation was not required to be conducted by board-certi-\nfied radiologists. The high agreement of the different annota-\ntors confirmed this judgement, which minimized the cost of \nannotation and allowed for capturing a larger set of reports.\nConclusion\nIn conclusion, we find that an on-site custom pre-training of \ntext-based transformers with subsequent adaptation to manu-\nally curated gold labels promises to be an efficient strategy to \nunlock radiological report databases for data-driven medicine.\nSupplementary Information  The online version contains supplemen -\ntary material available at https:// doi. org/ 10. 1007/ s00330- 023- 09526-y.\nFunding  Open Access funding enabled and organized by Projekt \nDEAL. S.R., B.W., D.B, and H.S. are affiliated with the Competence \nCenter for Machine Learning Rhine-Ruhr, which is funded by the \nFederal Ministry of Education and Research of Germany (grant no. \n01|S18038B). The authors gratefully acknowledge this support. The \nfunders had no influence on the conceptualization and design of the \nstudy, data analysis and data collection, preparation of the manuscript, \nand the decision to publish.\nDeclarations \nGuarantor The scientific guarantor of this publication is PD Dr.-Ing. \nAlois Martin Sprinkart.\nConflict of interest The authors of this manuscript declare no relation-\nships with any companies whose products or services may be related \nto the subject matter of the article.\nStatistics and biometry  No complex statistical methods were neces -\nsary for this paper.\nInformed consent Written informed consent was waived by the Insti-\ntutional Review Board (University of Bonn).\nEthical approval Institutional Review Board approval was obtained by \nthe local ethics committees at the Medical Faculty of the Rheinische \nFriedrich-Wilhelms-Universität Bonn (AZ 411/21).\nMethodology  \n• retrospective\n• experimental study\n• performed at one institution\nOpen Access This article is licensed under a Creative Commons Attri-\nbution 4.0 International License, which permits use, sharing, adapta -\ntion, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, \nprovide a link to the Creative Commons licence, and indicate if changes \nwere made. The images or other third party material in this article are \nincluded in the article's Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in \nthe article's Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a \ncopy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\nReferences\n 1. N obel JM, Kok EM, Robben SG (2020) Redefining the structure \nof structured reporting in radiology. Insights Imaging 11(1):1–5\n4235European Radiology  (2023) 33:4228–4236\n 2 .  Eur opean Society of Radiology (ESR) (2018) ESR paper on struc -\ntured reporting in radiology. Insights Imaging 9:1–7\n 3. Irvin J, Rajpurkar P, Ko M et al (2019) Chexpert: a large chest \nradiograph dataset with uncertainty labels and expert comparison. \nIn Proceedings of the AAAI conference on artificial intelligence \n33(1):590–597\n 4. Vaswani A, Shazeer N, Parmar N et al (2017) Attention is all you \nneed. In Advances in neural information processing systems 30\n 5. Devlin J, Chang MW, Lee K, Toutanova K (2018) Bert: pre-train-\ning of deep bidirectional transformers for language understanding. \narXiv preprint arXiv: 1810. 04805\n 6. Wahab A, Sifa R (2021) Dibert: Dependency injected bidirectional \nencoder representations from transformers. In 2021 IEEE Sympo-\nsium Series on Computational Intelligence 1–8\n 7. Smit A , Jain S, Rajpurkar P, Pareek A, Ng AY, Lungren MP \n(2020) CheXbert: combining automatic labelers and expert anno-\ntations for accurate radiology report labeling using BERT. arXiv \npreprint arXiv: 2004. 09167\n 8. McDermott MB, Hsu TMH, Wenig WH, Ghassemi M, Szolovits P \n(2020) Chexpert++: approximating the chexpert labeler for speed, \ndifferentiability, and probabilistic output. In Proceedings of the \n5th Machine Learning for Healthcare Conference 913–927\n 9. Bressem KK, Adams LC, Gaudin RA et al (2020) Highly accurate \nclassification of chest radiographic reports using a deep learning \nnatural language model pre-trained on 3.8 million text reports. \nBioinformatics 36(21):5255–5261\n 10. Richter-Pechanski P, Amr A, Katus HA, Dieterich C (2019) Deep \nlearning approaches outperform conventional strategies in de-\nidentification of German medical reports. In GMDS 101–109\n 11. Carlini N, Tramer F, Wallace E et al (2021) Extracting training \ndata from large language models. In 30th USENIX Security Sym-\nposium 2633–2650\n 12. Biesner D, R amamurthy R, Stenzel R et al (2022) Anonymiza -\ntion of German financial documents using neural network-based \nlanguage models with contextual word representations. Int J Data \nSci Anal 13(2):151–161\n 13. Nakayama H, Kubo T, Kamura J, Taniguchi Y, Liang X (2018) \ndoccano: Text annotation tool for human. Available via https:// \ngithub. com/ docca no/ docca no. Accessed 28 Jul 2022\n 14. Baeza-Yates R, Ribeiro-Neto B (1999) Modern information \nretrieval, 2nd edn. ACM Press, New York\n 15. Wolf T, Debut L, Sanh V et al (2019) Huggingface’s transformers: \nstate-of-the-art natural language processing. arXiv preprint arXiv: \n1910. 03771\n 16. Deepset (2021) German BERT. Available via https:// huggi ngface. \nco/ bert- base- german- cased. Accessed 28 Jul 2022\n 17. Shrestha M (2021) German Medical BERT. Available via https:// \nhuggi ngface. co/ smanj il/ German- MedBE RT. Accessed 28 Jul 2022\n 18. Sun C, Qiu X, X u Y, Huang X (2019) How to fine-tune bert for \ntext classification? In 2019 China national conference on Chinese \ncomputational linguistics 194–206\n 19. Nowak S, Mesropyan N, Faron A et al (2021) Detection of liver \ncirrhosis in standard T2-weighted MRI using deep transfer learn-\ning. Eur Radiol 31(11):8807–8815\n 20. Luetkens JA, Nowak S, Mesropyan N et al (2022) Deep learning \nsupports the differentiation of alcoholic and other-than-alcoholic \ncirrhosis based on MRI. Sci Rep 12(1):1–8\n 21. Gan L, Yuen B, Lu T (2019) Multi-label classification with opti -\nmal thresholding for multi-composition spectroscopic analysis. \nMach Learn Knowl Extr 1(4):1084–1099\n 22. Loshchilov I, Hutter F (2017) Decoupled weight decay regulariza-\ntion. arXiv preprint arXiv: 1711. 05101\n 23. Pedregosa F, Varoquaux G, Gramfort A et al (2011) Scikit-learn: \nmachine learning in Python. J Mach Learn Res 12:2825–2830\nPublisher's Note  Springer Nature remains neutral with regard to \njurisdictional claims in published maps and institutional affiliations.\n4236 European Radiology  (2023) 33:4228–4236",
  "topic": "Gold standard (test)",
  "concepts": [
    {
      "name": "Gold standard (test)",
      "score": 0.5803443789482117
    },
    {
      "name": "Medicine",
      "score": 0.3567464351654053
    },
    {
      "name": "Natural language processing",
      "score": 0.34802600741386414
    },
    {
      "name": "Database",
      "score": 0.3362061083316803
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3325779438018799
    },
    {
      "name": "Computer science",
      "score": 0.25572556257247925
    },
    {
      "name": "Radiology",
      "score": 0.2255237102508545
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I2799391451",
      "name": "University Hospital Bonn",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I4210144576",
      "name": "Fraunhofer Institute for Intelligent Analysis and Information Systems",
      "country": "DE"
    }
  ],
  "cited_by": 16
}