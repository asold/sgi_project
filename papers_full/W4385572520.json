{
  "title": "Recursion of Thought: A Divide-and-Conquer Approach to Multi-Context Reasoning with Language Models",
  "url": "https://openalex.org/W4385572520",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2098145308",
      "name": "Soo-Chan Lee",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2100966015",
      "name": "Gunhee Kim",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2607964821"
  ],
  "abstract": "Generating intermediate steps, or Chain of Thought (CoT), is an effective way to significantly improve language models‚Äô (LM) multi-step reasoning capability. However, the CoT lengths can grow rapidly with the problem complexity, easily exceeding the maximum context size. Instead of increasing the context limit, which has already been heavily investigated, we explore an orthogonal direction: making LMs divide a problem into multiple contexts. We propose a new inference framework, called Recursion of Thought (RoT), which introduces several special tokens that the models can output to trigger context-related operations. Extensive experiments with multiple architectures including GPT-3 show that RoT dramatically improves LMs‚Äô inference capability to solve problems, whose solution consists of hundreds of thousands of tokens.",
  "full_text": "Findings of the Association for Computational Linguistics: ACL 2023, pages 623‚Äì658\nJuly 9-14, 2023 ¬©2023 Association for Computational Linguistics\nRecursion of Thought: A Divide-and-Conquer Approach\nto Multi-Context Reasoning with Language Models\nSoochan Lee\nSeoul National University\nsoochan.lee@vision.snu.ac.kr\nGunhee Kim\nSeoul National University\nSNU-LG AI Research Center\ngunhee@snu.ac.kr\nAbstract\nGenerating intermediate steps, or Chain of\nThought (CoT), is an effective way to signiÔ¨Å-\ncantly improve language models‚Äô (LM) multi-\nstep reasoning capability. However, the CoT\nlengths can grow rapidly with the problem\ncomplexity, easily exceeding the maximum\ncontext size. Instead of increasing the con-\ntext limit, which has already been heavily in-\nvestigated, we explore an orthogonal direc-\ntion: making LMs divide a problem into\nmultiple contexts. We propose a new infer-\nence framework, called Recursion of Thought\n(RoT), which introduces several special to-\nkens that the models can output to trigger\ncontext-related operations. Extensive exper-\niments with multiple architectures including\nGPT-3 show that RoT dramatically improves\nLMs‚Äô inference capability to solve problems,\nwhose solution consists of hundreds of thou-\nsands of tokens.\n1 Introduction\nRecently, LMs have become a prominent direction\nto solve reasoning. Given a question sequence, the\nmodels are tasked to predict the following answer\nsequence. One recent line of research for reason-\ning with LMs is chain of thought(CoT) generation\n(Nye et al., 2021; Wei et al., 2022; Kojima et al.,\n2022). In CoT generation, complex reasoning prob-\nlems are solved by generating intermediate reason-\ning steps, or chain of thought, before producing the\nÔ¨Ånal answer. This allows the problem‚Äôs complex-\nity to be spread across multiple token generations,\nmaking each generation more straightforward given\nthe previous tokens.\nAlthough CoT dramatically increases reasoning\naccuracy, there is a critical issue that limits its util-\nity: the effective context size of sequence models\ncannot grow unbounded. Context refers to the set\nof input tokens that a model is conditioned on when\ngenerating output. Practically, all sequence mod-\nels have a limit on the maximum context length\ndue to various reasons. For instance, Transformers\n(Vaswani et al., 2017) suffer from a quadratic com-\nputational cost on the context length, and RNNs\n(Hochreiter and Schmidhuber, 1997) struggle with\nlong-term dependency modeling. Therefore, even\nthe state-of-the-art LMs limit the maximum context\nlength to a few thousand tokens. However, com-\nplex real-world problems may take even millions\nof tokens of reasoning steps to reach the answer.\nWhile there has been extensive research on\nTransformers with longer contexts (Tay et al.,\n2020b), we explore an orthogonal direction: divide\nand conquer. Our new model-agnostic inference\nframework Recursion of Thought(RoT) lets an LM\nrecursively create multiple contexts by producing\nspecial tokens. Therefore, even if a problem‚Äôs solu-\ntion exceeds the maximum context size, the model\ncan divide it into multiple short contexts. We show\nthe potential of RoT with our new synthetic bench-\nmark consisting of eight arithmetic and algorith-\nmic tasks. One can easily adjust the difÔ¨Åculty of\nthe tasks to produce problems with extremely long\n(100K+ tokens) reasoning steps. Without any task-\nspeciÔ¨Åc component, such as a calculator, the mod-\nels with RoT can easily learn to solve extremely\ncomplex problems whose solutions consist of hun-\ndreds of thousands of tokens. To the best of our\nknowledge, no previous work comes close to han-\ndling this scale of reasoning procedures. Since RoT\nis an early exploration in this direction, it needs sev-\neral improvements to be applied to more practical\nscenarios. Nonetheless, the impressive experimen-\ntal results suggest that the multi-context paradigm\nof RoT might play an important role in future LMs.\nIn the supplementary Ô¨Åle, we provide our PyTorch\n(Paszke et al., 2019) implementation that can fully\nreproduce the experiments.\n2 Related Work\nScratchpad (Nye et al., 2021) is one of the earli-\nest approaches demonstrating that Ô¨Åne-tuning lan-\n623\nguage models to produce CoT can largely improve\nreasoning accuracy. In the paper, the authors also\nmention the conÔ¨Åned context size as a major hurdle\nto scaling their method. More recently, it has been\nfound that sufÔ¨Åciently large pre-trained language\nmodels can be induced to produce CoT, by sim-\nply tuning the prompt (Wei et al., 2022; Kojima\net al., 2022). Several concurrent works extend CoT\nprompting to decompose complex problems into\nsmaller problems (Dua et al., 2022; Zhou et al.,\n2022; Khot et al., 2022). Although these works\nalso share the principle of divide and conquer like\nRoT, they mostly focus on improving the reason-\ning accuracy of relatively small problems whose\nsolutions usually can Ô¨Åt in a single context. On the\nother hand, we focus on solving problems that the\nsolutions are orders of magnitude longer than the\ncontext size. More detailed description of related\nwork can be found in Appendix A.\n3 Recursion of Thought (RoT)\n3.1 Inference\nWe start with how an RoT-trained LM performs\nat test time. RoT is a model-agnostic framework,\nwhose only requirement is that the model can in-\nfer p(xi+1‚à£X1‚à∂i), the probability of the next token\nxi+1 given a sequence X1‚à∂i = [x1; ...; xi]. For\nrecursive context control, we introduce the follow-\ning special tokens: GO , STOP , and THINK . GO\nand STOP respectively mark the start and end of\na problem sequence. They can be nested inside\nanother GO -STOP pair to indicate a subproblem.\nTHINK initiates a recursion procedure. RoT teaches\na model how to use these tokens so that it can per-\nform divide-and-conquer problem-solving. We for-\nmulate each inference context of a QA problem,\ndenoted X, as the following concatenation:\nX =[Q; Qsub,1; Asub,1; ... ; Qsub,N ; Asub,N ; A]\n(1)\nwhere Qand Aare the main question and answer\nsequence, and Qsub,‚àó and Asub,‚àó are those of the\ntop-level subproblems. Although a subproblem can\nhave smaller, lower-level subproblems recursively,\nonly the top-level subproblems remain in an RoT\ncontext. During inference, a model is given Q\nand tasked to generate the rest. Questions (Qand\nQsub,‚àó) start with a GO token, and answers (Aand\nAsub,‚àó) end with a STOP token. In the base cases,\ncontexts do not have (Qsub,‚àó,Asub,‚àó) pairs.\nFigure 1 presents an example of solving 408 +\n351 for better understanding. The pseudocode and\nmore detailed illustrations can be found in Ap-\npendix B and E. RoT starts by initializing the con-\ntext X with the original question Q(i.e., GO 4 0\n8 + 3 5 1 = in Figure 1). Then, similar to CoT,\nthe model solves multiple subproblems (generating\nQsub,‚àó and Asub,‚àó) before producing the Ô¨Ånal an-\nswer. However, there is a key difference: instead of\nproducing a sub-answer directly, the model outputs\nthe THINK token. This special token triggers a re-\ncursive process that separates the sub-question in a\nnew context. If the new context is a base case (i.e.,\nX2, X4, and X5), the answer is produced directly.\nOtherwise, the model recursively solves more sub-\nproblems. If enough subproblems are solved, the\nmodel generates the Ô¨Ånal answer ending with a\nSTOP . Once an answer is returned to the previ-\nous context, it replaces the THINK token, and the\ngeneration continues.\nFor tail recursion, where the last subquestion‚Äôs\nanswer becomes the Ô¨Ånal answer, we additionally\nintroduce the TAIL token. If TAIL is used in the\nplace of a GO token in the last subquestion Qsub,N ,\nits answer Asub,N is treated as the Ô¨Ånal answer A.\n3.2 Training\nCurrently, we train RoT in a supervised manner,\nusing ground truth (GT) intermediate steps that in-\nclude when to output the special tokens. The GTs\nare constructed following the standard procedures\ndeveloped for humans. For example, the proce-\ndures for arithmetic problems are borrowed from\nelementary school math. More details can be found\nin Appendix H. We leave training RoT with less\nsupervision as a future work.\nEach training example is constructed as a pair\nof a ground truth context sequence X and the cor-\nresponding target sequence Y. An example and\nthe pseudocode for creating a target sequence are\npresented in Figure 3 and Algorithm 2 in Appendix\nD. Overall, Y is a copy of X except for the parts\ncorresponding to Qand Asub,‚àó. Since the question\nQis always given in a context, Qis replaced by\nspecial PAD tokens, which are excluded from the\nloss function. Each subproblem‚Äôs answer Asub,n\nis replaced by a THINK token followed by several\nPAD s that Ô¨Åll in the rest to make sure ‚à£X‚à£ =‚à£Y‚à£.\nThis way, the model is trained to output THINK in-\nstead of the Ô¨Årst token of Asub,n. Since the whole\nAsub,n will be returned from the recursive process\n624\nùëÑ\n4 0 8 + 3 5GO 1 =\nùëÑsub,1\nGO 8 + 1 =\nùê¥sub,1\nTHINK THINK\nùê¥sub,2\nGO 4 0 + 3 5 =\nùëÑsub,2\n7 5 STOP9\nùê¥\n9 STOP 7 5 STOP\nùëã1\nGO 8 + 1 =\nùëÑ ùê¥\nùëã2 GO 4 0 + 3 5 = THINKGO 0 + 5 =\nùê¥sub,1ùëÑsub,1ùëÑ\n5 STOP\nTHINKGO 4 + 3 =\nùê¥sub,2ùëÑsub,2 ùê¥\n7 5 STOPùëã3\nGO 0 + 5 =\nùëÑ ùê¥\n5 STOPùëã4 GO 4 + 3 =\nùëÑ ùê¥\nùëã5 7 STOP\n7 STOP\n9 STOP\nFigure 1: An example of the Recursion of Thought inference solving 408+351. Each table represents an inference\ncontext Xk in order of creation. For each context, the model is givenQand tasked to generate the rest. The model\noutputs the THINK token when it needs to generateAsub,‚àó, the answer of a subproblem. The THINK token triggers\na recursive process and is later replaced by the answer returned from the process.\nand replace the THINK during inference, we do not\nneed a training signal for the rest of Asub,n.\nGiven a pair (X,Y ), the training objective is\ndeÔ¨Åned as follows:\nL =‚àí/summation.disp\ni\nI[yi+1 ‚â† PAD ]log p(yi+1‚à£X1‚à∂i) (2)\nwhere I is the indicator function that excludes\nPAD s from training. Its form is almost iden-\ntical to the standard LM objective: LLM =\n‚àí‚àëi log p(xi+1‚à£X1‚à∂i), which is to predict the next\ntoken given previous tokens. Therefore, any se-\nquence model is trained in the standard way, i.e.,\nend-to-end via stochastic gradient descent.\n4 Experiments\n4.1 Baselines\nWe compare RoT with two baselines. The Ô¨Årst one\nis to output an answer directly from a question,\nwhich we call Without Thought(WT). The other\none is to generate all the intermediate steps before\nthe answer without recursion (Nye et al., 2021),\nwhich we refer to as Chain of Thought(CoT; not\nto be confused with the CoT prompting (Wei et al.,\n2022)). We construct the ground truths for CoTs\nby unraveling the same recursive process which we\ndesign for RoT, into a single context sequence (see\nAppendix F for examples). Therefore, the number\nof tokens to generate while solving a problem is\nthe same for both CoT and RoT (if we do not count\nthe THINK tokens). However, the sizes of the in-\ndividual contexts of CoT are far longer than those\nof RoT due to the recursively nested subproblems,\nlimiting the range of solvable problems. Refer to\nAppendix M for a more detailed analysis of the\ncontext sizes. For a fair comparison, we train these\nbaselines and do not use any prompting technique.\nWhen evaluating, we consider a problem to be cor-\nrectly solved only if all the intermediate steps and\nthe answer are correct.\n4.2 The Reasoning Problems\nTo evaluate the reasoning capabilities, we test\nfour basic arithmetic tasks and four algorithmic\ntasks: addition, subtraction, multiplication, divi-\nsion, longest common subsequence, longest palin-\ndromic subsequence, 0-1 knapsack, and matrix\nchain multiplication. The details can be found in\nAppendix G. We choose these tasks because we\ncan easily increase the problem difÔ¨Åculty while\nbeing able to get ground truth solutions. There-\nfore, we can test problems whose solution contains\nhundreds of thousands of tokens. All problems are\nformulated in pure sequence modeling, without any\nexternal programs (e.g., calculator) involved.\n4.3 Experiments with GPT-3\nUsing the OpenAI API, we Ô¨Åne-tune GPT-3 for\neach reasoning task in ¬ß4.2 for 10K steps with a\nbatch size of 256. The results are presented in Fig-\nure 2a, and the technical details are described in\nAppendix I. Each point in the graphs represents\none experiment at a certain problem difÔ¨Åculty. We\nreport the accuracy on a test set of 1K unique prob-\nlems randomly sampled as explained in Appendix\nG. To the best of our knowledge, the problems at\nthis scale (e.g., 48-digit addition/subtraction and\n16-digit multiplication/division) have never been\nsolved by any LM without the help of external pro-\ngrams. For reference, Minerva (Lewkowycz et al.,\n2022) achieves around 80% accuracy on 10-digit\naddition and 20% on 18-digit addition.\n625\n/uni00000015/uni00000017/uni00000016/uni00000015/uni00000017/uni0000001b\n/uni00000030/uni00000044/uni0000005b/uni00000003/uni00000027/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000056\n/uni00000013/uni00000011/uni00000018/uni00000013\n/uni00000013/uni00000011/uni0000001a/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000024/uni00000047/uni00000047/uni0000004c/uni00000057/uni0000004c/uni00000052/uni00000051\n/uni0000003a/uni0000004c/uni00000057/uni0000004b/uni00000052/uni00000058/uni00000057/uni00000003/uni00000037/uni0000004b/uni00000052/uni00000058/uni0000004a/uni0000004b/uni00000057/uni00000026/uni0000004b/uni00000044/uni0000004c/uni00000051/uni00000003/uni00000052/uni00000049/uni00000003/uni00000037/uni0000004b/uni00000052/uni00000058/uni0000004a/uni0000004b/uni00000057/uni00000035/uni00000048/uni00000046/uni00000058/uni00000055/uni00000056/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000052/uni00000049/uni00000003/uni00000037/uni0000004b/uni00000052/uni00000058/uni0000004a/uni0000004b/uni00000057\n/uni00000015/uni00000017/uni00000016/uni00000015/uni00000017/uni0000001b\n/uni00000030/uni00000044/uni0000005b/uni00000003/uni00000027/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000056\n/uni00000013/uni00000011/uni00000018/uni00000013\n/uni00000013/uni00000011/uni0000001a/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000036/uni00000058/uni00000045/uni00000057/uni00000055/uni00000044/uni00000046/uni00000057/uni0000004c/uni00000052/uni00000051\n/uni00000017/uni0000001b /uni00000014/uni00000019\n/uni00000030/uni00000044/uni0000005b/uni00000003/uni00000027/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000056\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000030/uni00000058/uni0000004f/uni00000057/uni0000004c/uni00000053/uni0000004f/uni0000004c/uni00000046/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051\n/uni00000017/uni0000001b /uni00000014/uni00000019\n/uni00000030/uni00000044/uni0000005b/uni00000003/uni00000027/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000056\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000027/uni0000004c/uni00000059/uni0000004c/uni00000056/uni0000004c/uni00000052/uni00000051\n/uni00000016 /uni00000014/uni00000019/uni00000015/uni00000017\n/uni00000036/uni00000048/uni00000054/uni00000058/uni00000048/uni00000051/uni00000046/uni00000048/uni00000003/uni0000002f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b\n/uni00000013/uni00000011/uni00000018/uni00000013\n/uni00000013/uni00000011/uni0000001a/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni0000002f/uni00000026/uni00000036\n/uni0000001a /uni00000015/uni00000017/uni00000017/uni00000013\n/uni00000036/uni00000048/uni00000054/uni00000058/uni00000048/uni00000051/uni00000046/uni00000048/uni00000003/uni0000002f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b\n/uni00000013/uni00000011/uni00000018/uni00000013\n/uni00000013/uni00000011/uni0000001a/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni0000002f/uni00000033/uni00000036\n/uni00000017 /uni00000019\n/uni00000006/uni00000003/uni00000052/uni00000049/uni00000003/uni0000002c/uni00000057/uni00000048/uni00000050/uni00000056\n/uni00000013/uni00000011/uni00000018/uni00000013\n/uni00000013/uni00000011/uni0000001a/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000013/uni00000010/uni00000014/uni00000003/uni0000002e/uni00000051/uni00000044/uni00000053/uni00000056/uni00000044/uni00000046/uni0000004e\n/uni00000015 /uni00000016 /uni00000017\n/uni00000006/uni00000003/uni00000052/uni00000049/uni00000003/uni00000030/uni00000044/uni00000057/uni00000055/uni0000004c/uni00000046/uni00000048/uni00000056\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000030/uni00000026/uni00000030\n/uni00000015/uni00000017/uni00000016/uni00000015/uni00000017/uni0000001b\n/uni00000030/uni00000044/uni0000005b/uni00000003/uni00000027/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000056\n/uni00000013/uni00000011/uni00000018/uni00000013\n/uni00000013/uni00000011/uni0000001a/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000024/uni00000047/uni00000047/uni0000004c/uni00000057/uni0000004c/uni00000052/uni00000051\n/uni00000016/uni00000014/uni00000019/uni00000015/uni00000017\n/uni00000036/uni00000048/uni00000054/uni00000058/uni00000048/uni00000051/uni00000046/uni00000048/uni00000003/uni0000002f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b\n/uni00000013/uni00000011/uni00000018/uni00000013\n/uni00000013/uni00000011/uni0000001a/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni0000002f/uni00000026/uni00000036\n/uni00000015/uni00000017/uni00000016/uni00000015/uni00000017/uni0000001b\n/uni00000030/uni00000044/uni0000005b/uni00000003/uni00000027/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000056\n/uni00000013/uni00000011/uni00000018/uni00000013\n/uni00000013/uni00000011/uni0000001a/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000036/uni00000058/uni00000045/uni00000057/uni00000055/uni00000044/uni00000046/uni00000057/uni0000004c/uni00000052/uni00000051\n/uni0000001a/uni00000015/uni00000017/uni00000017/uni00000013\n/uni00000036/uni00000048/uni00000054/uni00000058/uni00000048/uni00000051/uni00000046/uni00000048/uni00000003/uni0000002f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b\n/uni00000013/uni00000011/uni00000018/uni00000013\n/uni00000013/uni00000011/uni0000001a/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni0000002f/uni00000033/uni00000036\n/uni00000017/uni0000001b/uni00000014/uni00000019\n/uni00000030/uni00000044/uni0000005b/uni00000003/uni00000027/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000056\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000030/uni00000058/uni0000004f/uni00000057/uni0000004c/uni00000053/uni0000004f/uni0000004c/uni00000046/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051\n/uni00000017 /uni00000019\n/uni00000006/uni00000003/uni00000052/uni00000049/uni00000003/uni0000002c/uni00000057/uni00000048/uni00000050/uni00000056\n/uni00000013/uni00000011/uni00000018/uni00000013\n/uni00000013/uni00000011/uni0000001a/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000013/uni00000010/uni00000014/uni00000003/uni0000002e/uni00000051/uni00000044/uni00000053/uni00000056/uni00000044/uni00000046/uni0000004e\n/uni00000017/uni0000001b/uni00000014/uni00000019\n/uni00000030/uni00000044/uni0000005b/uni00000003/uni00000027/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000056\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000027/uni0000004c/uni00000059/uni0000004c/uni00000056/uni0000004c/uni00000052/uni00000051\n/uni00000015/uni00000016/uni00000017\n/uni00000006/uni00000003/uni00000052/uni00000049/uni00000003/uni00000030/uni00000044/uni00000057/uni00000055/uni0000004c/uni00000046/uni00000048/uni00000056\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000030/uni00000026/uni00000030\n(a) GPT-3\n/uni0000001b/uni00000014/uni00000019/uni00000015/uni00000017/uni00000016/uni00000015/uni00000017/uni00000013/uni00000017/uni0000001b/uni00000018/uni00000019/uni00000019/uni00000017\n/uni00000030/uni00000044/uni0000005b/uni00000003/uni00000027/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000056\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000024/uni00000047/uni00000047/uni0000004c/uni00000057/uni0000004c/uni00000052/uni00000051\n/uni00000017/uni0000001b/uni00000014/uni00000015/uni00000014/uni00000019/uni00000015/uni00000013/uni00000015/uni00000017/uni00000015/uni0000001b/uni00000016/uni00000015\n/uni00000036/uni00000048/uni00000054/uni00000058/uni00000048/uni00000051/uni00000046/uni00000048/uni00000003/uni0000002f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni0000002f/uni00000026/uni00000036\n/uni0000001b/uni00000014/uni00000019/uni00000015/uni00000017/uni00000016/uni00000015/uni00000017/uni00000013/uni00000017/uni0000001b/uni00000018/uni00000019/uni00000019/uni00000017\n/uni00000030/uni00000044/uni0000005b/uni00000003/uni00000027/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000056\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000036/uni00000058/uni00000045/uni00000057/uni00000055/uni00000044/uni00000046/uni00000057/uni0000004c/uni00000052/uni00000051\n/uni0000001b/uni00000014/uni00000019/uni00000015/uni00000017/uni00000016/uni00000015/uni00000017/uni00000013/uni00000017/uni0000001b/uni00000018/uni00000019\n/uni00000036/uni00000048/uni00000054/uni00000058/uni00000048/uni00000051/uni00000046/uni00000048/uni00000003/uni0000002f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni0000002f/uni00000033/uni00000036\n/uni00000015/uni00000017/uni0000001b/uni00000014/uni00000015/uni00000014/uni00000019/uni00000015/uni00000013/uni00000015/uni00000017/uni00000015/uni0000001b/uni00000016/uni00000015\n/uni00000030/uni00000044/uni0000005b/uni00000003/uni00000027/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000056\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000030/uni00000058/uni0000004f/uni00000057/uni0000004c/uni00000053/uni0000004f/uni0000004c/uni00000046/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051\n/uni00000015/uni00000017/uni00000019/uni0000001b/uni00000014/uni00000013/uni00000014/uni00000015\n/uni00000006/uni00000003/uni00000052/uni00000049/uni00000003/uni0000002c/uni00000057/uni00000048/uni00000050/uni00000056\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000013/uni00000010/uni00000014/uni00000003/uni0000002e/uni00000051/uni00000044/uni00000053/uni00000056/uni00000044/uni00000046/uni0000004e\n/uni00000015/uni00000017/uni0000001b/uni00000014/uni00000015/uni00000014/uni00000019/uni00000015/uni00000013/uni00000015/uni00000017/uni00000015/uni0000001b/uni00000016/uni00000015\n/uni00000030/uni00000044/uni0000005b/uni00000003/uni00000027/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000056\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000027/uni0000004c/uni00000059/uni0000004c/uni00000056/uni0000004c/uni00000052/uni00000051\n/uni00000015/uni00000017/uni00000019/uni0000001b/uni00000014/uni00000013/uni00000014/uni00000015\n/uni00000006/uni00000003/uni00000052/uni00000049/uni00000003/uni00000030/uni00000044/uni00000057/uni00000055/uni0000004c/uni00000046/uni00000048/uni00000056\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000030/uni00000026/uni00000030 (b) Tiny Transformer\n/uni00000015/uni00000017/uni00000019/uni0000001b/uni00000014/uni00000013/uni00000014/uni00000015/uni00000014/uni00000017/uni00000014/uni00000019\n/uni00000030/uni00000044/uni0000005b/uni00000003/uni00000027/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000056\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000024/uni00000047/uni00000047/uni0000004c/uni00000057/uni0000004c/uni00000052/uni00000051\n/uni00000015/uni00000017/uni00000019/uni0000001b/uni00000014/uni00000013/uni00000014/uni00000015/uni00000014/uni00000017/uni00000014/uni00000019\n/uni00000030/uni00000044/uni0000005b/uni00000003/uni00000027/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000056\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000036/uni00000058/uni00000045/uni00000057/uni00000055/uni00000044/uni00000046/uni00000057/uni0000004c/uni00000052/uni00000051\n/uni00000015/uni00000016/uni00000017/uni00000018/uni00000019/uni0000001a/uni0000001b\n/uni00000030/uni00000044/uni0000005b/uni00000003/uni00000027/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000056\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000030/uni00000058/uni0000004f/uni00000057/uni0000004c/uni00000053/uni0000004f/uni0000004c/uni00000046/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051\n/uni00000014/uni00000015/uni00000016/uni00000017/uni00000018/uni00000019/uni0000001a/uni0000001b\n/uni00000030/uni00000044/uni0000005b/uni00000003/uni00000027/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000056\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000027/uni0000004c/uni00000059/uni0000004c/uni00000056/uni0000004c/uni00000052/uni00000051 (c) Tiny LSTM\nFigure 2: Comparison of the thought types. In each graph, the x-axis is the problem difÔ¨Åculty, while the y-axis\nis the reasoning accuracy. Each point represents an independent experiment. The green vertical lines indicate the\nmaximum problem difÔ¨Åculty that CoT can handle without exceeding the maximum context size.\nResults. Even WT Ô¨Åne-tuning cannot make GPT-\n3 deal with such a level of complexity, while CoT\nis not applicable due to the context limit of 2048.\nThe green dotted lines mark the maximum difÔ¨Å-\nculty that can be handled by CoT under the context\nlimit. On the other hand, RoT enables the GPT-3\nto achieve near-perfect scores in every experiment.\nAs presented in Appendix M, solving each problem\nrequires up to tens of thousands of tokens. Without\nany architectural change, RoT makes GPT-3 handle\nthese extremely complex problems.\n4.4 Experiments with Tiny Language Models\nRecent research on reasoning has been mostly fo-\ncused on extremely large pre-trained LMs. In this\nsection, we show an interesting result that RoT can\nmake even tiny models, without any pre-training,\nperform convoluted reasoning procedures. We\ntest the two basic sequence model architectures:\na Transformer (Vaswani et al., 2017) with 536K\nparameters and an LSTM (Hochreiter and Schmid-\nhuber, 1997) with 272K parameters. These mod-\nels are more than a million times smaller than the\nrecent 540B-parameter PaLM (Chowdhery et al.,\n2022). The context limit is set to 2048 for the\nTransformer and 512 for the LSTM.\nBy virtue of their small sizes, we conduct far\nmore extensive experiments than GPT-3, which are\npresented in Figure 2b and Figure 2c. For each\nexperiment, we train a randomly initialized model\nand evaluate it on a test set of 30K unique problems.\nWe repeat each experiment eight times and report\nthe average and standard deviation of the accura-\ncies. With the tiny Transformer, we experiment to\nthe extent that even humans would Ô¨Ånd daunting.\nFor example, we test addition/subtraction up to 64\ndigits and multiplication/division up to 32 digits.\nNote that a 32-digit number cannot even Ô¨Åt into the\n64-bit integer datatype.\nThroughout the experiments, we observe con-\nsistent patterns: (i) WT‚Äôs accuracy drops most\nquickly as the problem difÔ¨Åculty increases, (ii) CoT\nachieves near-perfect accuracy, but it can only be\napplied to simple problems due to the context limit,\n(iii) RoT achieves near-perfect accuracy and can be\nscaled up to extremely complex problems. Despite\nthe small sizes, RoT makes the Transformers mas-\nter all types of extremely complex problems. We\ndo not test more difÔ¨Åcult problems mainly because\nthe evaluation becomes too costly, not because RoT\nis incapable of learning them.\n5 Conclusion\nWe explored the novel idea of making LMs produce\nspecial tokens to create multiple contexts. Follow-\ning the principle of divide and conquer, LMs with\nRoT can solve extremely complex problems that\nhave never been handled by any LM. We believe\nthe core idea of utilizing multiple contexts has a\ngreat potential and can play an essential role in\nfuture language models.\n626\nLimitations\nAlthough RoT remarkably improves LMs‚Äô reason-\ning capability, we currently rely on supervised train-\ning to teach RoT. To apply RoT to a wider range\nof tasks, it would be crucial to reduce the expen-\nsive supervision. Parallel to our work, Khot et al.\n(2022) use prompting techniques to induce LMs\nto decompose problems. However, prompting has\nother drawbacks. First, lengthy prompts should\nbe added for each inference, causing additional\ncomputational overhead. And more critically, it is\nhard to guarantee high accuracy. To achieve rea-\nsonable accuracy in the tasks in our experiments,\neach subproblem should be solved at extremely\nhigh accuracy (e.g., > 99.9%) since each problem\nmay contain hundreds or thousands of subprob-\nlems. We have tested several prompting techniques\nwith GPT-3, but could not get satisfactory accu-\nracy. Therefore, we conclude that solely relying on\nprompting cannot be a solution to this problem. As\none possible approach, we may combine RoT with\nthe RL-based methodologies that are developed\nfor reducing supervision of Neural Programmer-\nInterpreters (Li et al., 2017; Fox et al., 2018; Pierrot\net al., 2019).\nAnother limitation of this work is that the exper-\niments are performed on somewhat synthetic tasks.\nSince our goal is to enable LMs to solve reasoning\nproblems whose intermediate steps are orders of\nmagnitude longer than the context limit, we need\na dataset with such complex problems. However,\nno currently available dataset meets this require-\nment. For example, the Long-Range Arena bench-\nmark (Tay et al., 2020a) has at most 16K-token se-\nquences and focuses on problems with long inputs\nand short outputs. On the other hand, we tackle\nproblems that require generating 100K+ tokens to\nsolve. Gathering natural language data at this scale\nis extremely challenging and costly. Therefore, we\ncurrently resort to arithmetic and algorithmic prob-\nlems since it is easy to scale them up and generate\nground-truth solutions. In the future, we hope to\nsee new datasets and benchmarks that cover natural\nlanguage reasoning at this scale.\nInterestingly, RoT cannot facilitate length gen-\neralization, e.g., training on 8-digit multiplication\nwith RoT cannot make a model generalize to 16-\ndigit multiplication. We believe this problem is\nrooted in a more fundamental limitation of the\nTransformer architecture (Hahn, 2020), orthogonal\nto RoT. Fortunately, since RoT is a model-agnostic\nframework, we would be able to apply RoT to more\nadvanced architectures to come in the future, which\nmight be capable of length generalization.\nEthics Statement\nSince the problem types in our experiments are\npure arithmetic or algorithmic tasks, we do not\nÔ¨Ånd any ethical concerns directly related to our\nwork. If RoT is applied to more general problems,\nthe training data should meet ethical standards to\nensure the non-toxic behavior of the model.\nAcknowledgements\nWe thank Jaekyeom Kim, Hyunwoo Kim, and\nDongjoo Kim for their thoughtful discussions. This\nwork is partly supported by LG AI Research, the In-\nstitute of Information & Communications Technol-\nogy Planning & Evaluation (IITP) grant funded by\nthe Korea government (MSIT) (No.2019-0-01082,\nSW StarLab; No.2022-0-00156, Fundamental re-\nsearch on continual meta-learning for quality en-\nhancement of casual videos and their 3D metaverse\ntransformation), and the National Research Foun-\ndation of Korea (NRF) grant funded by the Korea\ngovernment (MSIT) (No.2023R1A2C2005573).\nReferences\nJonathon Cai, Richard Shin, and Dawn Song. 2017.\nMaking neural programming architectures general-\nize via recursion. In 5th International Conference\non Learning Representations, ICLR 2017, Toulon,\nFrance, April 24-26, 2017, Conference Track Pro-\nceedings. OpenReview.net.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, Parker Schuh, Kensen Shi,\nSasha Tsvyashchenko, Joshua Maynez, Abhishek B\nRao, Parker Barnes, Yi Tay, Noam M. Shazeer, Vin-\nodkumar Prabhakaran, Emily Reif, Nan Du, Ben-\nton C. Hutchinson, Reiner Pope, James Bradbury, Ja-\ncob Austin, Michael Isard, Guy Gur-Ari, Pengcheng\nYin, Toju Duke, Anselm Levskaya, Sanjay Ghe-\nmawat, Sunipa Dev, Henryk Michalewski, Xavier\nGarc√≠a, Vedant Misra, Kevin Robinson, Liam Fe-\ndus, Denny Zhou, Daphne Ippolito, David Luan,\nHyeontaek Lim, Barret Zoph, Alexander Spiridonov,\nRyan Sepassi, David Dohan, Shivani Agrawal, Mark\nOmernick, Andrew M. Dai, Thanumalayan Sankara-\nnarayana Pillai, Marie Pellat, Aitor Lewkowycz, Er-\nica Oliveira Moreira, Rewon Child, Oleksandr Polo-\nzov, Katherine Lee, Zongwei Zhou, Xuezhi Wang,\nBrennan Saeta, Mark Diaz, Orhan Firat, Michele\nCatasta, Jason Wei, Kathleen S. Meier-Hellstern,\n627\nDouglas Eck, Jeff Dean, Slav Petrov, and Noah\nFiedel. 2022. PaLM: Scaling language modeling\nwith pathways. ArXiv, abs/2204.02311.\nDheeru Dua, Shivanshu Gupta, Sameer Singh, and\nMatt Gardner. 2022. Successive prompting\nfor decomposing complex questions. ArXiv,\nabs/2212.04092.\nRoy Fox, Richard Shin, Sanjay Krishnan, Ken\nGoldberg, Dawn Song, and Ion Stoica. 2018.\nParametrized hierarchical procedures for neural pro-\ngramming. In 6th International Conference on\nLearning Representations, ICLR 2018, Vancouver,\nBC, Canada, April 30 - May 3, 2018, Conference\nTrack Proceedings. OpenReview.net.\nMichael Hahn. 2020. Theoretical limitations of self-\nattention in neural sequence models. Transactions\nof the Association for Computational Linguistics,\n8:156‚Äì171.\nSepp Hochreiter and J√ºrgen Schmidhuber. 1997. Long\nshort-term memory. Neural Computation, 9:1735‚Äì\n1780.\nTushar Khot, H. Trivedi, Matthew Finlayson, Yao\nFu, Kyle Richardson, Peter Clark, and Ashish Sab-\nharwal. 2022. Decomposed prompting: A mod-\nular approach for solving complex tasks. ArXiv,\nabs/2210.02406.\nDiederik P. Kingma and Jimmy Ba. 2015. Adam: A\nmethod for stochastic optimization. In 3rd Inter-\nnational Conference on Learning Representations,\nICLR 2015, San Diego, CA, USA, May 7-9, 2015,\nConference Track Proceedings.\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\ntaka Matsuo, and Yusuke Iwasawa. 2022. Large\nlanguage models are zero-shot reasoners. ArXiv,\nabs/2205.11916.\nAitor Lewkowycz, Anders Johan Andreassen, David\nDohan, Ethan Dyer, Henryk Michalewski,\nVinay Venkatesh Ramasesh, Ambrose Slone,\nCem Anil, Imanol Schlag, Theo Gutman-Solo,\nYuhuai Wu, Behnam Neyshabur, Guy Gur-Ari,\nand Vedant Misra. 2022. Solving quantitative\nreasoning problems with language models. ArXiv,\nabs/2206.14858.\nChengtao Li, Daniel Tarlow, Alexander L. Gaunt, Marc\nBrockschmidt, and Nate Kushman. 2017. Neural\nprogram lattices. In 5th International Conference\non Learning Representations, ICLR 2017, Toulon,\nFrance, April 24-26, 2017, Conference Track Pro-\nceedings. OpenReview.net.\nMaxwell Nye, Anders Johan Andreassen, Guy Gur-Ari,\nHenryk Michalewski, Jacob Austin, David Bieber,\nDavid Dohan, Aitor Lewkowycz, Maarten Bosma,\nDavid Luan, Charles Sutton, and Augustus Odena.\n2021. Show your work: Scratchpads for interme-\ndiate computation with language models. ArXiv,\nabs/2112.00114.\nAdam Paszke, Sam Gross, Francisco Massa, Adam\nLerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca\nAntiga, Alban Desmaison, Andreas Kopf, Edward\nYang, Zachary DeVito, Martin Raison, Alykhan Te-\njani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang,\nJunjie Bai, and Soumith Chintala. 2019. PyTorch:\nAn Imperative Style, High-Performance Deep Learn-\ning Library. In Advances in Neural Information Pro-\ncessing Systems 32, pages 8024‚Äì8035. Curran Asso-\nciates, Inc.\nThomas Pierrot, Guillaume Ligner, Scott E. Reed,\nOlivier Sigaud, Nicolas Perrin, Alexandre Laterre,\nDavid Kas, Karim Beguir, and Nando de Freitas.\n2019. Learning compositional neural programs with\nrecursive tree search and planning. In Advances in\nNeural Information Processing Systems 32: Annual\nConference on Neural Information Processing Sys-\ntems 2019, NeurIPS 2019, December 8-14, 2019,\nVancouver, BC, Canada, pages 14646‚Äì14656.\nScott E. Reed and Nando de Freitas. 2016. Neural\nprogrammer-interpreters. In 4th International Con-\nference on Learning Representations, ICLR 2016,\nSan Juan, Puerto Rico, May 2-4, 2016, Conference\nTrack Proceedings.\nYi Tay, Mostafa Dehghani, Samira Abnar, Yikang\nShen, Dara Bahri, Philip Pham, Jinfeng Rao, Liu\nYang, Sebastian Ruder, and Donald Metzler. 2020a.\nLong range arena: A benchmark for efÔ¨Åcient trans-\nformers. ArXiv, abs/2011.04006.\nYi Tay, Mostafa Dehghani, Dara Bahri, and Donald\nMetzler. 2020b. EfÔ¨Åcient transformers: A survey.\nACM Computing Surveys, 55:1 ‚Äì 28.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems 30: Annual Conference on Neural\nInformation Processing Systems 2017, December 4-\n9, 2017, Long Beach, CA, USA, pages 5998‚Äì6008.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Ed Chi, Quoc Le, and Denny Zhou. 2022.\nChain of thought prompting elicits reasoning in large\nlanguage models. ArXiv, abs/2201.11903.\nDenny Zhou, Nathanael Scharli, Le Hou, Jason Wei,\nNathan Scales, Xuezhi Wang, Dale Schuurmans,\nOlivier Bousquet, Quoc Le, and Ed Huai hsin\nChi. 2022. Least-to-most prompting enables com-\nplex reasoning in large language models. ArXiv,\nabs/2205.10625.\n628\nA Extended Related Work\nChain of Thought. Scratchpad (Nye et al., 2021) Ô¨Åne-tunes LMs to generate CoT before the Ô¨Ånal\nanswer. It demonstrates its effectiveness in 8-digit addition, polynomial evaluation, and Python program\nexecution. Instead of Ô¨Åne-tuning, it is found that we can elicit large pre-trained LMs to produce CoT\nwith appropriate prompting. For example, CoT prompting (Wei et al., 2022) adds several QA exemplars\nwith CoT before the main question, encouraging the model to generate Ô¨Ånal answers in a similar manner.\nCompared to the few-shot CoT prompting of Wei et al. (2022), Kojima et al. (2022)‚Äôs zero-shot CoT\nprompting is even simpler; after a question, they start the answer with ‚ÄúLet‚Äôs think step by step,‚Äù and\nthen let the model Ô¨Ånish the rest. Minerva (Lewkowycz et al., 2022) utilizes these prompting techniques\nwith a specially curated scientiÔ¨Åc pre-training dataset to achieve remarkable results on various reasoning\nbenchmarks.\nPrompting Language Models to Divide and Conquer Reasoning Problems. Based on CoT prompt-\ning (Wei et al., 2022), several concurrent works demonstrate that decomposing problems into smaller\nsubproblems can effectively improve reasoning accuracy. Successive prompting (Dua et al., 2022) induces\na model to alternate between generating a question and answering the question until the Ô¨Ånal answer is\nproduced. Similarly, least-to-most prompting (Zhou et al., 2022) makes a model start from the easiest\nsubproblem and progressively solve more complex ones on top of the previous results. Decomposed\nprompting (Khot et al., 2022) is a modular approach that the subproblems are solved by different modules\ndepending on the problem type. It also supports recursive decomposition. These works are all closely\nrelated to our work. Our work is unique in that we deal with far more complex problems that consist of\nthousands of subproblems. In this case, the individual subproblems should be solved with almost perfect\naccuracy, or the overall accuracy drops signiÔ¨Åcantly. We empirically Ô¨Ånd that such a level of accuracy is\nhard to achieve by simply prompting a pre-trained LM.\nNeural Programmer-Interpreter (NPI). Unlike language models, NPI (Reed and de Freitas, 2016)\ninteracts with its environment through a series of program execution. It consists of an LSTM core, an\nencoder for each domain, and a memory of program embeddings. At every time step, the LSTM core takes\na program embedding, arguments, and an observation of its environment to produce the next program\nembedding and corresponding arguments. Cai et al. (2017) combine NPI with recursion and show that\nrecursion plays a critical role in generalization. Since NPI requires full execution traces for training, there\nare multiple works to relax this requirement using reinforcement learning (Li et al., 2017; Fox et al., 2018;\nPierrot et al., 2019).\n629\nB RoT Inference Algorithm\nAlgorithm 1 Recursion of Thought Inference\nRequire: A sequence model M trained for Recursion of Thought, a question sequence Q\n1: function ROT(M, Q)\n2: X ‚Üê Q ‚ñ∑Initialize context with Q\n3: ians ‚Üê ‚à£X‚à£+1 ‚ñ∑Start of answer\n4: t‚Üê false ‚ñ∑Tail recursion\n5: while True do\n6: x‚Üê M(X) ‚ñ∑Generate next token\n7: X ‚Üê [X; x]\n8: if x= STOP then\n9: return Xians‚à∂‚à£X‚à£\n10: else if x= GO then\n11: igo ‚Üê ‚à£X‚à£ ‚ñ∑Mark last GO\n12: else if x= TAIL then\n13: igo ‚Üê ‚à£X‚à£\n14: t‚Üê true ‚ñ∑Mark tail recursion\n15: else if x= THINK then\n16: Qsub ‚Üê Xigo‚à∂‚à£X‚à£‚àí1\n17: Asub ‚Üê ROT(M,Qsub)\n18: if tthen\n19: return Asub\n20: end if\n21: X ‚Üê [X1‚à∂‚à£X‚à£‚àí1; Asub]\n22: ‚ñ∑Replace THINK with Asub\n23: ians ‚Üê ‚à£X‚à£+1\n24: end if\n25: end while\n26: end function\nC Training Batch Distribution\nWe use the same problem distribution for both training and evaluation since out-of-distribution generaliza-\ntion is not within the scope of this paper. That is, when teaching 6-digit multiplication to the model, both\ntraining and test sets are all examples of 6-digit multiplication. The problem distributions are elaborated\nin Appendix G. Another important detail regarding the training of RoT is that each training example in a\nbatch is a context, not a whole problem. Since RoT generates multiple contexts per problem, often a large\nportion of contexts can be a duplicate (mostly the base cases). Therefore, to build a training batch for RoT,\nwe Ô¨Årst sample a top-level problem and Ô¨Ånd the set of unique RoT contexts from the problem. Out of the\nunique contexts, we randomly sample one context as a training example. We Ô¨Ånd this simple technique\nworks well, and we do not need a more sophisticated method, such as the adaptive curriculum learning in\nReed and de Freitas (2016).\n630\nD Target Sequence\nAlgorithm 2 Creating the target sequence\nRequire: Context X =[Q; Qsub,1; Asub,1; ... ; Qsub,N ; Asub,N ; A]\n1: Y ‚Üê PAD ...PAD\n/sym0AF/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B3/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B0\n‚à£Q‚à£\n2: for nin 1...N do\n3: Y ‚Üê [Y; Qsub,n]\n4: Y ‚Üê [Y; THINK PAD ...PAD\n/sym0AF/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B3/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B1/sym0B0\n‚à£Asub,n‚à£‚àí1\n]\n5: end for\n6: Y ‚Üê [Y; A]\n7: return Y\nùëÑ\n4 0 8 + 3 5GO 1 =\nùëÑsub,1\nGO 8 + 1 =\nùê¥sub,1\n9 STOPùëã1\nGO 8 + 1 = THINKùëå1 PAD\n7 5 STOP\nùê¥sub,2\nGO 4 0 + 3 5 =\nùëÑsub,2\nTHINKGO 4 0 + 3 5 =\n7 5 STOP9\nùê¥\n7 5 STOP9PAD PADPAD PAD¬∑¬∑¬∑\nFigure 3: The target sequence Y1 for X1 in Figure 1.\nE A Step-by-Step Illustration of RoT Inference\nIn this section, we provide a step-by-step illustration of the example in Figure 1. Here we assume an ideal\nmodel fully trained for RoT.\nStep 1\nThe context is initialized with the question Q.\nQ\nX1 GO 4 0 8 + 3 5 1 =\nStep 2\nThe model generates the Ô¨Årst subquestion 8 +1.\nQ Q sub,1\nX1 GO 4 0 8 + 3 5 1 = GO 8 + 1 =\nStep 3\nInstead of immediately producing the answer, the model outputs the THINK token.\nQ Q sub,1 Asub,1\nX1 GO 4 0 8 + 3 5 1 = GO 8 + 1 = THINK\n631\nStep 4\nThe THINK token triggers the creation of a new context. The new context is initialized with the\nsubproblem starting from the last GO of X1, i.e., 8 +1.\nQ Q sub,1 Asub,1\nX1 GO 4 0 8 + 3 5 1 = GO 8 + 1 = THINK\nQ\nX2 GO 8 + 1 =\nStep 5\nSince the subproblem is a base case, the model outputs the answer 9 immediately.\nQ Q sub,1 Asub,1\nX1 GO 4 0 8 + 3 5 1 = GO 8 + 1 = THINK\nQ A\nX2 GO 8 + 1 = 9 STOP\nStep 6\nThe answer is returned and replaces the THINK token.\nQ Q sub,1 Asub,1\nX1 GO 4 0 8 + 3 5 1 = GO 8 + 1 = 9 STOP\nStep 7\nThe model generates the next subproblem, which is to add the remaining digits. Then, it produces\nTHINK to Ô¨Ånd its answer.\nQ Q sub,1 Asub,1 Qsub,2 Asub,2\nX1 GO 4 0 8 + 3 5 1 = GO 8 + 1 = 9 STOP GO 4 0 + 3 5 = THINK\n632\nStep 8\nThe THINK token creates a new context X3 for solving 40 +35.\nQ Q sub,1 Asub,1 Qsub,2 Asub,2\nX1 GO 4 0 8 + 3 5 1 = GO 8 + 1 = 9 STOP GO 4 0 + 3 5 = THINK\nQ\nX3 GO 4 0 + 3 5 =\nStep 9\nSince 40 +35 is not a base case, the model recursively produces more subproblems. In this case,\nthe Ô¨Årst subproblem is to add the last digits, i.e., 0 and 5. Then it outputs the THINK token to solve\nthe subproblem.\nQ Q sub,1 Asub,1 Qsub,2 Asub,2\nX1 GO 4 0 8 + 3 5 1 = GO 8 + 1 = 9 STOP GO 4 0 + 3 5 = THINK\nQ Q sub,1 Asub,1\nX3 GO 4 0 + 3 5 = GO 0 + 5 = THINK\nStep 10\nThe new context X4 is created to solve 0 +5.\nQ Q sub,1 Asub,1 Qsub,2 Asub,2\nX1 GO 4 0 8 + 3 5 1 = GO 8 + 1 = 9 STOP GO 4 0 + 3 5 = THINK\nQ Q sub,1 Asub,1\nX3 GO 4 0 + 3 5 = GO 0 + 5 = THINK\nQ A\nX4 GO 0 + 5 = 5 STOP\n633\nStep 11\nThe answer is returned to X3 and replaces the THINK token.\nQ Q sub,1 Asub,1 Qsub,2 Asub,2\nX1 GO 4 0 8 + 3 5 1 = GO 8 + 1 = 9 STOP GO 4 0 + 3 5 = THINK\nQ Q sub,1 Asub,1\nX3 GO 4 0 + 3 5 = GO 0 + 5 = 5 STOP\nStep 12\nThe model generates the next subproblem.\nQ Q sub,1 Asub,1 Qsub,2 Asub,2\nX1 GO 4 0 8 + 3 5 1 = GO 8 + 1 = 9 STOP GO 4 0 + 3 5 = THINK\nQ Q sub,1 Asub,1 Qsub,2 Asub,2\nX3 GO 4 0 + 3 5 = GO 0 + 5 = 5 STOP GO 4 + 3 = THINK\nStep 13\nX5 is created to solve the subproblem 4 +3. Since this is a base case, the model produces the\nanswer directly.\nQ Q sub,1 Asub,1 Qsub,2 Asub,2\nX1 GO 4 0 8 + 3 5 1 = GO 8 + 1 = 9 STOP GO 4 0 + 3 5 = THINK\nQ Q sub,1 Asub,1 Qsub,2 Asub,2\nX3 GO 4 0 + 3 5 = GO 0 + 5 = 5 STOP GO 4 + 3 = THINK\nQ A\nX5 GO 4 + 3 = 7 STOP\n634\nStep 14\nThe answer from X5 replaces the THINK token in X3.\nQ Q sub,1 Asub,1 Qsub,2 Asub,2\nX1 GO 4 0 8 + 3 5 1 = GO 8 + 1 = 9 STOP GO 4 0 + 3 5 = THINK\nQ Q sub,1 Asub,1 Qsub,2 Asub,2\nX3 GO 4 0 + 3 5 = GO 0 + 5 = 5 STOP GO 4 + 3 = 7 STOP\nStep 15\nSince all subproblems are solved in X3, the answer 75 is generated and returned to X1.\nQ Q sub,1 Asub,1 Qsub,2 Asub,2\nX1 GO 4 0 8 + 3 5 1 = GO 8 + 1 = 9 STOP GO 4 0 + 3 5 = THINK\nQ Q sub,1 Asub,1 Qsub,2 Asub,2 A\nX3 GO 4 0 + 3 5 = GO 0 + 5 = 5 STOP GO 4 + 3 = 7 STOP 7 5 STOP\nStep 16\nThe answer of X3 replaces the THINK token in X1.\nQ Q sub,1 Asub,1 Qsub,2 Asub,2\nX1 GO 4 0 8 + 3 5 1 = GO 8 + 1 = 9 STOP GO 4 0 + 3 5 = 7 5 STOP\nStep 17\nSince the subproblems in X1 are all solved, the model produces the Ô¨Ånal answer.\nQ Q sub,1 Asub,1 Qsub,2 Asub,2\nX1 GO 4 0 8 + 3 5 1 = GO 8 + 1 = 9 STOP GO 4 0 + 3 5 = 7 5 STOP\nA\n7 5 9 STOP\nF Examples of CoT Training Data\nIf we solve the example of 408+351 in Figure 1 with RoT, the following Ô¨Åve contexts are produced.\n‚Ä¢ X1: GO 4 0 8 + 3 5 1 = GO 8 + 1 = 9 STOP GO 4 0 + 3 5 = 7 5 STOP 7 5 9 STOP\n‚Ä¢ X2: GO 8 + 1 = 9 STOP\n‚Ä¢ X3: GO 4 0 + 3 5 = GO 0 + 5 = 5 STOP GO 4 + 3 = 7 STOP 7 5 STOP\n635\n‚Ä¢ X4: GO 0 + 5 = 5 STOP\n‚Ä¢ X5: GO 4 + 3 = 7 STOP\nThe CoT context of the same problem is:\n‚Ä¢ XCoT: GO 4 0 8 + 3 5 1 = GO 8 + 1 = 9 STOP GO 4 0 + 3 5 = GO 0 + 5 STOP GO 4 +\n3 STOP 7 5 STOP 7 5 9 STOP\nIn a slightly more complicated example of 34 √ó5, the RoT contexts are as follows:\n‚Ä¢ X1: GO 3 4 * 5 = GO 4 * 5 = 2 0 STOP GO 3 * 5 = 1 5 STOP TAIL 1 5 0 + 2 0 = THINK\n‚Ä¢ X2: GO 4 * 5 = 2 0 STOP\n‚Ä¢ X3: GO 3 * 5 = 1 5 STOP\n‚Ä¢ X4: GO 1 5 0 + 2 0 = GO 0 + 0 = 0 STOP GO 1 5 + 2 = 1 7 STOP 1 7 0 STOP\n‚Ä¢ X5: GO 0 + 0 = 0 STOP\n‚Ä¢ X6: GO 1 5 + 2 = GO 5 + 2 = 7 STOP 1 7 STOP\n‚Ä¢ X7: GO 5 + 2 = 7 STOP\nThe corresponding CoT context is:\n‚Ä¢ XCoT: GO 3 4 * 5 = GO 4 * 5 = 2 0 STOP GO 3 * 5 = 1 5 STOP TAIL 1 5 0 + 2 0 = GO\n0 + 0 = 0 STOP GO 1 5 + 2 = GO 5 + 2 = 7 STOP 1 7 STOP 1 7 0 STOP\nNotice that the CoT context consists of all the corresponding RoT contexts as its subsequences. The\nnumber of tokens to generate is identical to that of RoT if we do not count the THINK tokens. Even in\nthese simple examples, however, the context size of CoT is far longer than that of RoT. For much more\ncomplex problems, such as 8-digit multiplication or 0-1 Knapsack, the CoT context size can be orders of\nmagnitude larger than RoT. See Appendix M for more details on the distribution of context sizes.\nG Problem SpeciÔ¨Åcations\nG.1 The Arithmetic Problems\nFor arithmetic tasks, we test addition, subtraction, multiplication, and division on non-negative integers.\nFor subtraction, we add a constraint that the Ô¨Årst operand is not less than the second one, to enforce\nnon-negative answers. For division, we let the output include both a quotient and a remainder, separated\nby a special token R , e.g., GO 7 √∑ 3 = 2 R 1 STOP .\nAs brieÔ¨Çy mentioned in ¬ß4.2, naively sampling the operands from a uniform distribution makes the\noperands extremely biased towards large numbers. For example, the probability of sampling a 2-digit\nnumber from the 6-digit space is less than 0.01%. Thus, we deÔ¨Åne a variation of the log-uniform\ndistribution (often called the reciprocal distribution) to sample the operands. As a result, we obtain\nroughly the same proportion of operands for each number of digits.\nThe probability density of a log-uniform distribution is proportional to the reciprocal of the value. By\ndeÔ¨Ånition, zero is not in the support of a log-uniform distribution, and samples are overly concentrated to\nthe Ô¨Årst few values in the sampling range. Therefore, we slightly extend the log-uniform distribution by\nintroducing an offset parameter Œ¥. To sample an integer in range [Œ±,Œ≤) with offset Œ¥, we Ô¨Årst uniformly\nsample a real number r in range [log(Œ±+Œ¥),log(Œ≤ +Œ¥)]. Then, r is transformed to ‚åäexp(r) ‚àíŒ¥‚åã.\nWe denote the extended log-uniform distribution Ulog(Œ±,Œ≤,Œ¥ ). As Œ¥gets larger, the samples are more\ndispersed to larger numbers. In the experiments, we set Œ¥=3.\nAdditionally, we introduce several other sampling details for division problems. Assume that we\nindependently sample two numbers aand bfor the dividend and the divisor. In about half of the cases, the\n636\nAddition Subtraction Multiplication Division\n1330 +121163 376776 ‚àí35241 9466 √ó176175 620261 √∑155034\n114780 +4356 10638 ‚àí100 179 √ó516 111730 √∑1176\n638 +2 109033 ‚àí52649 5509 √ó133 28268 √∑1\n35 +77 85137 ‚àí3098 6783 √ó2 588137 √∑25571\n114261 +354 22355 ‚àí2824 6 √ó80285 180330 √∑739\n3 +13792 7 ‚àí1 37275 √ó19258 879975 √∑97772\n10151 +7 652781 ‚àí78853 168484 √ó154 111461 √∑905026\n22 +1399 64914 ‚àí3114 3331 √ó40 42338 √∑14003\n363356 +450475 13041 ‚àí1422 349 √ó158 108 √∑384103\n73 +11 28293 ‚àí4540 17988 √ó262130 60002 √∑7479\n179895 +4128 11553 ‚àí3576 8140 √ó1670 131467 √∑131290\n3 +10 656291 ‚àí2795 51 √ó5 890679 √∑62\n1 +141972 93 ‚àí42 16497 √ó158 228 √∑131108\n57612 +18403 55972 ‚àí1782 74 √ó10 892 √∑124\n9 +1621 84587 ‚àí51 216 √ó13414 15 √∑964156\n3370 +381 273269 ‚àí5867 621 √ó2 369044 √∑28364\n678 +8854 274405 ‚àí14 2 √ó5951 457 √∑46\n422 +10348 51926 ‚àí9 189486 √ó13080 14687 √∑730\n118 +582 4272 ‚àí229 552792 √ó763 200361 √∑1049\n1343 +408534 223267 ‚àí377 77 √ó3 19715 √∑965179\n24 +9251 14857 ‚àí1994 179090 √ó469029 98 √∑7\n315 +652424 914771 ‚àí836 1037 √ó258 406 √∑9\n355 +4434 3035 ‚àí2963 8 √ó769974 47345 √∑122\n22 +834928 30 ‚àí12 47765 √ó7254 391613 √∑1631\n3028 +357 149 ‚àí4 5608 √ó18164 892642 √∑3898\n777 +1355 89057 ‚àí6 21437 √ó12 241554 √∑1901\n154874 +81059 296410 ‚àí9 15007 √ó15 116475 √∑12908\n64936 +216852 45 ‚àí3 539860 √ó427 488317 √∑197443\n3 +340939 78906 ‚àí3 3583 √ó9754 7519 √∑325\n3 +984775 56560 ‚àí29960 13 √ó66 3560 √∑847611\n50581 +1183 98 ‚àí6 266394 √ó185 9711 √∑1385\n415 +943 16551 ‚àí920 3988 √ó12 44540 √∑103\n110 +49 25606 ‚àí194 5514 √ó57 19721 √∑58\n15 +17058 45 ‚àí37 5 √ó1712 59544 √∑24\n36278 +100 129443 ‚àí70196 17 √ó430178 333057 √∑333057\n6 +23516 221 ‚àí54 227 √ó127 25719 √∑5142\n1462 +848 11010 ‚àí818 20888 √ó54 7544 √∑46\n1002 +2773 47759 ‚àí67 96 √ó232801 45 √∑410\n135 +178346 10 ‚àí8 175 √ó1050 195659 √∑2047\n22672 +162038 1439 ‚àí153 146 √ó166 412572 √∑16\nTable 1: 40 randomly selected samples of each type of 6-digit arithmetic problems.\ndividend awould be less than the divisorb, so the quotients will be zero for those cases. To ensure a diverse\nrange of quotients, we sample the divisor bfrom Ulog(1,10N ,3), the quotient cfrom Ulog(0,10N /b,3),\nand the remainder rfrom Ulog(0,b, 3). The dividend is calculated from these values: a=b√óc+r. This\nway, we can sample division problems with a diverse range of quotients and remainders.\nTable 1 presents 40 problem samples for each 6-digit problem type. Several properties of our sampling\nscheme can be observed in the table. First, each number ranges over diverse numbers of digits. Second,\nthe division problems are mostly non-trivial, i.e., the quotients are not concentrated at zero.\nG.2 The Algorithmic Problems\nG.2.1 Longest Common Subsequence (LCS)\nThe question of an LCS problem is two number sequences joined by the LCS token, and the answer is the\ncorresponding LCS and its length separated by ; . Here is an example of a length-4 LCS problem:\n‚Ä¢ Q: GO 1 2 3 4 LCS 2 4 6 8 =\n‚Ä¢ A: 2 4 ; 2 STOP\nFor a length-N LCS problem, we sample two sequences of length N. Each character of the sequences is\nrandomly sampled from 0-9 with equal probability.\n637\nG.2.2 Longest Palindromic Subsequence (LPS)\nThe question of a length-N LPS problem starts with the LPS , followed by a sequence of lengthN. Similar\nto LCS, the answer contains the corresponding LPS and its length separated by ; . The following is an\nexample of a length-8 LPS problem:\n‚Ä¢ Q: GO LPS 4 1 2 5 3 2 6 1 =\n‚Ä¢ A: 1 2 3 2 1 ; 5 STOP\nThe sequence of an LPS problem is sampled in the same way as done for the LCS problem.\nG.2.3 0-1 Knapsack\nEach item in a 0-1 Knapsack problem is represented by its value and weight. For instance, 1 2 & 3 4\nrepresents an item with a value of 12 and a weight of 34. The question part of a 0-1 Knapsack problem is\na sequence consisting of the KNAPSACK token, a list of items separated by , , the token @ , and the capacity\nof the knapsack. The answer part starts with a list of items to include, then $ , and Ô¨Ånally the total value.\nThe following is an example of a 3-item knapsack problem.\n‚Ä¢ Q: GO KNAPSACK 5 & 1 2 , 2 5 & 1 5 , 1 9 & 1 8 @ 4 0 =\n‚Ä¢ A: 2 5 & 1 5 , 1 9 & 1 8 $ 4 4 STOP\nIn this example, given a knapsack of capacity 40, the last two are selected with a total value of 44.\nFor a Ô¨Åxed number of items, we uniformly sample each item‚Äôs value and weight from the integers of\nrange [1, 99].\nG.2.4 Matrix Chain Multiplication (MCM)\nThe cost of multiplying many matrices is very sensitive to the order of multiplication. Matrix chain\nmultiplication is the task of Ô¨Ånding the best order with the minimum cost. Here, the cost is deÔ¨Åned to be\nthe total number of element multiplications. In the example of three matrices A, B, and C, whose shapes\nare 4 √ó2, 2 √ó8, and 8 √ó3 respectively, the cost of computing (AB)Cis 4 √ó2 √ó8 +4 √ó8 √ó3 =160,\nwhile another order A(BC) costs only 2 √ó8 √ó3 +4 √ó2 √ó3 =72. In the question of an MCM problem,\nthe sizes of the matrices are enumerated, and the answer contains the order and the total cost separated by\n; . The example above is represented as the following sequences.\n‚Ä¢ Q: GO MCM 4 √ó 2 , 2 √ó 8 , 8 √ó 3 =\n‚Ä¢ A: 4 √ó 2 , ( 2 √ó 8 , 8 √ó 3 ) ; 7 2 STOP\nGiven a Ô¨Åxed number of matrices, we sample the sizes of matrices from the range [1, 99].\nG.2.5 Sorting\nAlthough not included in the main text, we test the problem of sorting multi-digit numbers. The results\nare presented in Appendix N. The problem difÔ¨Åculty is deÔ¨Åned by the maximum number of terms. For a\nsorting problem of at most N terms, we Ô¨Årst uniformly sample the number of terms from [2,N]. Then\nwe sample each term from Ulog(0,1000,5). The following is an example of the sorting problem.\n‚Ä¢ Q: GO SORT 1 3 9 , 1 6 0 , 4 3 4 , 7 9 6 , 4 1 =\n‚Ä¢ A: 4 1 , 1 3 9 , 1 6 0 , 4 3 4 , 7 9 6 STOP\n638\nH Details of the Recursive Reasoning Procedures\nIn this section, we elaborate on the procedures to recursively solve the arithmetic problems. SpeciÔ¨Åcally,\nwe present the algorithms to produce the subproblems of a problem. Therefore, for a set of randomly\nsampled questions, we can generate ground truth contexts using these algorithms. For better understanding,\nwe present the key parts of our Python code, the thought methods. For each problem, we create a child\nclass the Problem class and implement thought static method. The method takes a set of arguments for a\nproblem and returns the list of direct subproblems. Each subproblem is represented by a problem class,\nproblem arguments, and recursion type (whether it is a tail recursion or not). We use named tuple T to\ngroup this information:\n1 from collections import namedtuple\n2 T = namedtuple('Thought', ['prob_cls', 'args', 'type'], defaults=[''])\nFor instance, T(Mul, (3, 4)) represents a regular subproblem of 3 √ó4, and T(Add, (12, 340),\n‚Äôtail‚Äô) represents a subproblem of 12 +340 which should be performed as a tail recursion. Once\nthe thought method returns a list of Ts, we can recursively Ô¨Ånd more subproblems for each subproblem.\nH.1 Addition\nThe core idea of our recursive procedure for addition is to Ô¨Årst add the last digits and then add the rest. If\nthe sum of the last digits is greater than or equal to 10, we insert another subproblem for adding the carry\nright after adding the last digits.\n1 class Add(Problem):\n2 @staticmethod\n3 def thought(args) -> list[T]:\n4 left, right = args\n5\n6 # Base cases\n7 if left < 10 and right < 10:\n8 return []\n9\n10 l_last, r_last = left % 10, right % 10\n11 thoughts = [T(Add, (l_last, r_last))]\n12\n13 l_rest, r_rest = left // 10, right // 10\n14 if l_last + r_last >= 10:\n15 thoughts.append(T(Add, (l_rest, 1)))\n16 l_rest += 1\n17\n18 if l_rest > 0 and r_rest > 0:\n19 thoughts.append(T(Add, (l_rest, r_rest)))\n20\n21 return thoughts\nFigure 1 in the main draft is an example with no carry, and the following is another example of 27+65\nwith a carry.\n‚Ä¢ X1: GO 3 1 7 + 6 5 = GO 7 + 5 = 1 2 STOP GO 3 1 + 1 = 3 2 STOP GO 3 2 + 6 = 3 8\nSTOP 3 8 2 STOP\n‚Ä¢ X2: GO 7 + 5 = 1 2 STOP\n‚Ä¢ X3: GO 3 1 + 1 = GO 1 + 1 = 2 STOP 3 2 STOP\n‚Ä¢ X4: GO 1 + 1 = 2 STOP\n‚Ä¢ X5: GO 3 2 + 6 = GO 2 + 6 = 8 STOP 3 8 STOP\n‚Ä¢ X6: GO 2 + 6 = 8 STOP\n639\nH.2 Subtraction\nSimilar to addition, we Ô¨Årst subtract the last digits and solve the rest recursively. When subtracting the\nlast digits xand y, we always borrow 10 for xto prevent a negative result. The borrowing of 10 is easy\nfor a sequence model: just put 1 before x. Therefore, the base cases of subtraction are when a‚â§19 and\nb‚â§9. If the subtraction result of the last digits is smaller than 10, i.e., the borrow is actually needed, we\nsubtract 1 from the rest of the Ô¨Årst operand m.\n1 class Sub(Problem):\n2 @staticmethod\n3 def thought(args) -> list[T]:\n4 left, right = args\n5\n6 # Base cases\n7 if left <= 19 and right <= 9:\n8 return []\n9\n10 l_last = left % 10 + 10\n11 r_last = right % 10\n12 thoughts = [T(Sub, (l_last, r_last))]\n13 l_rest, r_rest = left // 10, right // 10\n14 if l_last - r_last < 10:\n15 thoughts.append(T(Sub, (l_rest, 1)))\n16 l_rest -= 1\n17 if r_rest > 0:\n18 thoughts.append(T(Sub, (l_rest, r_rest)))\n19\n20 return thoughts\nHere is an example of 432-216:\n‚Ä¢ X1: GO 4 3 2 - 2 1 6 = GO 1 2 - 6 = 6 STOP GO 4 3 - 1 = 4 2 STOP GO 4 2 - 2 1 =\n2 1 STOP 2 1 6 STOP\n‚Ä¢ X2: GO 1 2 - 6 = 6 STOP\n‚Ä¢ X3: GO 4 3 - 1 = GO 1 3 - 1 = 1 2 STOP 4 2 STOP\n‚Ä¢ X4: GO 1 3 - 1 = 1 2 STOP\n‚Ä¢ X5: GO 4 2 - 2 1 = GO 1 2 - 1 = 1 1 STOP GO 4 - 2 = 2 STOP 2 1 STOP\n‚Ä¢ X6: GO 1 2 - 1 = 1 1 STOP\n‚Ä¢ X7: GO 4 - 2 = 2 STOP\nNotice that the Ô¨Ånal answer and the questions of each subproblem can be easily constructed from the\nprevious sequence.\nH.3 Multiplication\nThe base cases of multiplication are (i) when either operand is 0 or 1, or (ii) when both operands are less\nthan 10. If one of the operands is 0, then the answer is zero; when one of them is 1, then the answer is just\na copy of the other operand. For the cases where both operands are less than 10, we just let the model\nmemorize them, which is similar to an elementary school math curriculum.\nThere are two types of non-base cases. For the simpler case, where the second operand is less than\n10, we Ô¨Årst split the Ô¨Årst operand into the last digit and the rest. We then multiply each of them with the\nsecond operand and combine the results. Otherwise, we split the second operand into the last digit and the\nrest. The Ô¨Årst operand is multiplied to each of them, and the results are summed.\n1 class Mul(Problem):\n2 @staticmethod\n3 def thought(args) -> list[T]:\n4 left, right = args\n640\n5\n6 # Base cases\n7 if left <= 1 or right <= 1:\n8 return []\n9 if left <= 9 and right <= 9:\n10 return []\n11\n12 thoughts = []\n13 if right < 10:\n14 thoughts.append(T(Mul, (left % 10, right)))\n15 thoughts.append(T(Mul, (left // 10, right)))\n16\n17 a1 = (left % 10) * right\n18 a2 = (left // 10) * right\n19 thoughts.append(T(Add, (a2 * 10, a1), 'tail'))\n20 else:\n21 a1 = left * (right % 10)\n22 thoughts.append(T(Mul, (left, right % 10)))\n23\n24 a2 = left * (right // 10)\n25 thoughts.append(T(Mul, (left, right // 10)))\n26\n27 thoughts.append(T(Add, (a2 * 10, a1), 'tail'))\n28 return thoughts\nHere are some example contexts of multiplication:\n‚Ä¢ X1: GO 4 3 * 2 1 = GO 4 3 * 1 = 4 3 STOP GO 4 3 * 2 = 8 6 STOP TAIL 8 6 0 + 4 3\n= THINK\n‚Ä¢ X2: GO 4 3 * 1 = 4 3 STOP\n‚Ä¢ X3: GO 4 3 * 2 = GO 3 * 2 = 6 STOP GO 4 * 2 = 8 STOP TAIL 8 0 + 6 = THINK\n‚Ä¢ X4: GO 3 * 2 = 6 STOP\n‚Ä¢ X5: GO 4 * 2 = 8 STOP\n‚Ä¢ X6: GO 8 0 + 6 = GO 0 + 6 = 6 STOP 8 6 STOP\n‚Ä¢ X7: GO 0 + 6 = 6 STOP\n‚Ä¢ X8: GO 8 6 0 + 4 3 = GO 0 + 3 = 3 STOP GO 8 6 + 4 = 9 0 STOP 9 0 3 STOP\n‚Ä¢ X9: GO 0 + 3 = 3 STOP\n‚Ä¢ X10: GO 8 6 + 4 = GO 6 + 4 = 1 0 STOP GO 8 + 1 = 9 STOP 9 0 STOP\n‚Ä¢ X11: GO 6 + 4 = 1 0 STOP\n‚Ä¢ X12: GO 8 + 1 = 9 STOP\nNotice that we use tail recursion in X1 and X3.\nH.4 Comparison\nComparison is used as a subroutine during division. The procedure for comparison consists of three steps:\n1. Compare the numbers of digits.\n2. If the numbers of digits are the same, compare the most signiÔ¨Åcant digits.\n3. If the most signiÔ¨Åcant digits are identical, compare the remaining digits recursively.\nWe Ô¨Ånd that the sequence models can perform the Ô¨Årst step without an explicit subproblem. Therefore, we\nonly add intermediate steps for the second and third steps.\n641\n1 class Compare(Problem):\n2 @staticmethod\n3 def thought(args) -> list[T]:\n4 left, right = args\n5\n6 # Base cases\n7 if left < 10 and right < 10:\n8 return []\n9\n10 thoughts = []\n11 digit_l, digit_r = len(str(left)), len(str(right))\n12 if digit_l == digit_r:\n13 # Compare the first digits\n14 l_first, r_first = int(str(left)[0]), int(str(right)[0])\n15 thoughts.append(T(Compare, (l_first, r_first)))\n16 if l_first == r_first:\n17 # Compare the rest\n18 l_rest = int(str(left)[1:])\n19 r_rest = int(str(right)[1:])\n20 thoughts.append(T(Compare, (l_rest, r_rest)))\n21\n22 return thoughts\nThe following is an example of comparing 153 and 159.\n‚Ä¢ X1: GO 1 5 3 VS 1 5 9 = GO 1 VS 1 = EQ STOP GO 5 3 VS 5 9 = LT STOP LT STOP\n‚Ä¢ X2: GO 1 VS 1 = EQ STOP\n‚Ä¢ X3: GO 5 3 VS 5 9 = GO 5 VS 5 = EQ STOP GO 3 VS 9 = LT STOP LT STOP\n‚Ä¢ X4: GO 5 VS 5 = EQ STOP\n‚Ä¢ X5: GO 3 VS 9 = LT STOP\nH.5 Division\nSolving division is the most challenging among the four basic arithmetic operations since the procedure\nis basically trial and error, searching for the correct quotient. Nonetheless, the following process is a\nrecursive version of the elementary school division.\nThe base case is when the dividend is less than or equal to the divisor. If the dividend is smaller than\nthe divisor, the quotient is 0, and the remainder is the dividend. If the dividend is equal to the divisor, then\nthe quotient is 1, and the remainder is 0. Both cases can be handled relatively easily by neural sequence\nmodels. To determine whether it is one of these cases, we always perform the comparison as the Ô¨Årst\nsubproblem.\nIf it is not a base case, we check whether the dividend is smaller than 10 times the divisor. If the\ndividend is smaller, we subtract the divisor from the dividend and recursively divide the result with the\ndivisor. The Ô¨Ånal answer is attained by simply adding 1 to the quotient of the smaller division.\nTo explain the other case, where the dividend is greater than 10 times the divisor, let us call the dividend\naand the divisor b. First, we split the ainto the last digit xand the remaining digits m. Then, we divide m\nwith the divisor b, i.e., we are solving the one-digit-smaller subproblem Ô¨Årst. Since we deÔ¨Åne the division\noperation to return both a quotient and a remainder, the quotient q1 =m/band the remainder r1 =m\nmod bfrom the subproblem are added to the context. Next, we concatenate the remainder and x, which\nis numerically computing r√ó10 +x, and divide it again with b. Let the quotient and the remainder of\nthis operation q2 and r2. Then, the quotient of the Ô¨Ånal answer is q1 √ó10 +q2, while the remainder is\nsimply r2.\n1 class Div(Problem):\n2 @staticmethod\n3 def thought(args) -> list[T]:\n4 left, right = args\n642\n5 thoughts = [T(Compare, (left, right))]\n6\n7 # Base cases\n8 if left <= right:\n9 return thoughts\n10\n11 thoughts.append(T(Compare, (left, right * 10)))\n12 if left <= right * 10:\n13 diff = left - right\n14 thoughts.append(T(Sub, (left, right)))\n15 thoughts.append(T(Div, (diff, right)))\n16 else:\n17 thoughts.append(T(Div, (left // 10, right)))\n18 left_remainder = (left // 10) % right * 10 + left % 10\n19 thoughts.append(T(Div, (left_remainder, right)))\n20 return thoughts\nThe following is an example of 76 √∑29.\n‚Ä¢ X1: GO 7 6 √∑ 2 9 = GO 7 6 VS 2 9 = GT STOP GO 7 6 VS 2 9 0 = LT STOP GO 7 6 - 2\n9 = 4 7 STOP GO 4 7 √∑ 2 9 = 1 R 1 8 STOP 2 R 1 8 STOP\n‚Ä¢ X2: GO 7 6 VS 2 9 = GO 7 VS 2 = GT STOP GT STOP\n‚Ä¢ X3: GO 7 VS 2 = GT STOP\n‚Ä¢ X4: GO 7 6 VS 2 9 0 = LT STOP\n‚Ä¢ X5: GO 7 6 - 2 9 = GO 1 6 - 9 = 7 STOP GO 7 - 1 = 6 STOP GO 6 - 2 = 4 STOP 4 7\nSTOP\n‚Ä¢ ...\n‚Ä¢ X9: GO 4 7 √∑ 2 9 = GO 4 7 VS 2 9 = GT STOP GO 4 7 VS 2 9 0 = LT STOP GO 4 7 - 2\n9 = 1 8 STOP GO 1 8 √∑ 2 9 = 0 R 1 8 STOP 1 R 1 8 STOP\n‚Ä¢ X10: GO 4 7 VS 2 9 = GO 4 VS 2 = GT STOP GT STOP\n‚Ä¢ X11: GO 4 VS 2 = GT STOP\n‚Ä¢ X12: GO 4 7 VS 2 9 0 = LT STOP\n‚Ä¢ X13: GO 4 7 - 2 9 = GO 1 7 - 9 = 8 STOP GO 4 - 1 = 3 STOP GO 3 - 2 = 1 STOP 1 8\nSTOP\n‚Ä¢ ...\n‚Ä¢ X17: GO 1 8 √∑ 2 9 = GO 1 8 VS 2 9 = LT STOP 0 R 1 8 STOP\n‚Ä¢ X18: GO 1 8 VS 2 9 = GO 1 VS 2 = LT STOP LT STOP\n‚Ä¢ ...\nH.6 Longest Common Subsequence (LCS)\nGiven sequences Aand B, the algorithm starts by comparing the last characters of the two sequences. If\nthe last two characters are the same, we Ô¨Ånd LCS of the subsequences without the last characters, i.e.,\nLCS of A‚à∂‚àí1 and B‚à∂‚àí1. Otherwise, we compute the LCSs of the cases where the last character of either\nside is removed and return the better one. In the following code, LCS._answer is the subroutine that Ô¨Ånds\nthe LCS of two sequences. Equal returns TRUE if the two arguments are the same, or FALSE otherwise.\n643\n1 class LCS(Problem):\n2 @staticmethod\n3 def thought(args) -> list[T]:\n4 l, r = args\n5 if len(l) == 0 or len(r) == 0:\n6 return []\n7\n8 thoughts = [T(Equal, (l[-1], r[-1]))]\n9 if l[-1] == r[-1]:\n10 thoughts.append(T(LCS, (l[:-1], r[:-1])))\n11 return thoughts\n12\n13 lcs1_args = (l[:-1], r)\n14 lcs2_args = (l, r[:-1])\n15 lcs1 = LCS._answer(lcs1_args)\n16 lcs2 = LCS._answer(lcs2_args)\n17 thoughts.extend([\n18 T(LCS, lcs1_args),\n19 T(LCS, lcs2_args),\n20 T(Compare, (len(lcs1), len(lcs2)))\n21 ])\n22 return thoughts\nThe following is an example of Ô¨Ånding the LCS of 123 and 234.\n‚Ä¢ X1: GO 1 2 3 LCS 2 3 4 = GO EQUAL 3 , 4 = FALSE STOP GO 1 2 LCS 2 3 4 = 2 ; 1\nSTOP GO 1 2 3 LCS 2 3 = 2 3 ; 2 STOP GO 1 VS 2 = LT STOP 2 3 ; 2 STOP\n‚Ä¢ X2: GO EQUAL 3 , 4 = FALSE STOP\n‚Ä¢ X3: GO 1 2 LCS 2 3 4 = GO EQUAL 2 , 4 = FALSE STOP GO 1 LCS 2 3 4 = ; 0 STOP GO\n1 2 LCS 2 3 = 2 ; 1 STOP GO 0 VS 1 = LT STOP 2 ; 1 STOP\n‚Ä¢ ...\n‚Ä¢ X21: GO 1 2 3 LCS 2 3 = GO EQUAL 3 , 3 = TRUE STOP GO 1 2 LCS 2 = 2 ; 1 STOP 2 3\n; 2 STOP\n‚Ä¢ ...\n‚Ä¢ X23: GO 1 VS 2 = LT STOP\nH.7 Longest Palindromic Subsequence (LPS)\nThe overall algorithm for LPS is similar to LCS. The base cases are when the sequence length is less than\n3. If it is not a base case, we Ô¨Årst check if the characters at both ends of the sequence are the same. If\nthey are the same, we Ô¨Ånd the LPS of the subsequence excluding them. Otherwise, we compare the cases\nwhere one of the end characters is excluded.\n1 class LPS(Problem):\n2 @staticmethod\n3 def thought(args) -> list[T]:\n4 # Base cases\n5 if len(args) == 1:\n6 return []\n7 elif len(args) == 2:\n8 return [T(Equal, args)]\n9\n10 thoughts = [T(Equal, (args[0], args[1]))]\n11 if args[0] == args[-1]:\n12 sub_lps = LPS._answer(args[1:-1])\n13 thoughts.extend([\n14 T(LPS, args[1:-1]),\n15 T(Add, (len(sub_lps), 2))\n16 ])\n644\n17 else:\n18 lps1_args = args[:-1]\n19 lps2_args = args[1:]\n20 lps1 = LPS._answer(lps1_args)\n21 lps2 = LPS._answer(lps2_args)\n22 thoughts.extend([\n23 T(LPS, lps1_args),\n24 T(LPS, lps2_args),\n25 T(Compare, (len(lps1), len(lps2)))\n26 ])\n27 return thoughts\nThe following is an example of LPS.\n‚Ä¢ X1: GO LPS 1 2 3 2 = GO EQUAL 1 , 2 = FALSE STOP GO LPS 1 2 3 = 1 ; 1 STOP GO\nLPS 2 3 2 = 2 3 2 ; 3 STOP GO 1 VS 3 = LT STOP 2 3 2 ; 3 STOP\n‚Ä¢ X2: GO EQUAL 1 , 2 = FALSE STOP\n‚Ä¢ X3: GO LPS 1 2 3 = GO EQUAL 1 , 3 = FALSE STOP GO LPS 1 2 = 1 ; 1 STOP GO LPS 2\n3 = 2 ; 1 STOP GO 1 VS 1 = EQ STOP 1 ; 1 STOP\n‚Ä¢ ...\n‚Ä¢ X10: GO LPS 2 3 2 = GO EQUAL 2 , 2 = TRUE STOP GO LPS 3 = 3 ; 1 STOP GO 1 + 2 =\n3 STOP 2 3 2 ; 3 STOP\n‚Ä¢ ...\n‚Ä¢ X14: GO 1 VS 3 = LT STOP\nH.8 0-1 Knapsack\nThe base cases are when there is only one item. In this case, we simply compare the item‚Äôs weight and\nthe knapsack‚Äôs capacity, to determine whether the item should be included. If it is a non-base case, we\ncompare two possibilities: (i) include the Ô¨Årst item, or (ii) exclude the Ô¨Årst item. We recursively compute\nthe subproblems and Ô¨Ånd the case with the best value.\n1 class LPS(Problem):\n2 @staticmethod\n3 def thought(args) -> list[T]:\n4 items, capacity = args\n5 value, weight = items[0]\n6\n7 # Base case\n8 if len(items) == 1:\n9 return [T(Compare, (weight, capacity))]\n10\n11 # When excluding the current item\n12 items_max, value_max = Knapsack._answer((items[1:], capacity))\n13 thoughts = [\n14 T(Knapsack, (items[1:], capacity)),\n15 T(Compare, (weight, capacity)),\n16 ]\n17\n18 # When including the current item\n19 if weight <= capacity:\n20 items_sub, value_sub = Knapsack._answer(\n21 (items[1:], capacity - weight))\n22 value_incl = value_sub + value\n23 thoughts.extend([\n24 T(Sub, (capacity, weight)),\n25 T(Knapsack, (items[1:], capacity - weight)),\n26 T(Add, (value_sub, value)),\n27 T(Compare, (value_incl, value_max)),\n28 ])\n29\n645\n30 return thoughts\nThe following is an example of a 0-1 knapsack problem with three items and a knapsack capacity of 10.\n‚Ä¢ X1: GO KNAPSACK 3 & 9 , 4 & 2 , 9 & 5 @ 1 0 = GO KNAPSACK 4 & 2 , 9 & 5 @ 1 0 =\n4 & 2 , 9 & 5 $ 1 3 STOP GO 9 VS 1 0 = LT STOP GO 1 0 - 9 = 1 STOP GO KNAPSACK 4\n& 2 , 9 & 5 @ 1 = $ 0 STOP GO 0 + 3 = 3 STOP GO 3 VS 1 3 = LT STOP 4 & 2 , 9 & 5\n$ 1 3 STOP\n‚Ä¢ X2: GO KNAPSACK 4 & 2 , 9 & 5 @ 1 0 = GO KNAPSACK 9 & 5 @ 1 0 = 9 & 5 $ 9 STOP\nGO 2 VS 1 0 = LT STOP GO 1 0 - 2 = 8 STOP GO KNAPSACK 9 & 5 @ 8 = 9 & 5 $ 9 STOP\nGO 9 + 4 = 1 3 STOP GO 1 3 VS 9 = GT STOP 4 & 2 , 9 & 5 $ 1 3 STOP\n‚Ä¢ ...\n‚Ä¢ X11: GO 9 VS 1 0 = LT STOP\n‚Ä¢ X12: GO 1 0 - 9 = 1 STOP\n‚Ä¢ X13: GO KNAPSACK 4 & 2 , 9 & 5 @ 1 = GO KNAPSACK 9 & 5 @ 1 = $ 0 STOP GO 2 VS 1\n= GT STOP $ 0 STOP\n‚Ä¢ ...\n‚Ä¢ X17: GO 0 + 3 = 3 STOP\n‚Ä¢ X18: GO 3 VS 1 3 = LT STOP\nH.9 Ternary Addition and Multiplication\nTernary addition and multiplication arise as subproblems while solving MCM, which will be explained in\nthe next section. They are simple extensions of addition and multiplication to three integers.\n1 class TernaryAdd(Problem):\n2 @staticmethod\n3 def thought(args) -> list[T]:\n4 a1, a2, a3 = args\n5 return [\n6 T(Add, (a1, a2)),\n7 T(Add, (a1 + a2, a3), 'tail')\n8 ]\n9\n10\n11 class TernaryMul(Problem):\n12 @staticmethod\n13 def thought(args) -> list[T]:\n14 a1, a2, a3 = args\n15 return [\n16 T(Mul, (a1, a2)),\n17 T(Mul, (a1 * a2, a3), 'tail')\n18 ]\nH.10 Matrix Chain Multiplication (MCM)\nGiven N matrices, the N‚àí1 subproblems are deÔ¨Åned for each possible binary split. For the multiplication\nof four matrices ABCD, there are three possible binary splits: A(BCD), (AB)(CD), and (ABC)D.\nFor each binary split, the total cost is the sum of (i) the minimum cost of computing the Ô¨Årst group, (ii)\nthe minimum cost of computing the second group, and (iii) the cost of multiplying the two matrices\nresulting from each group. Once we get the total costs of each binary split, we return the best split with\nthe minimum cost. The following code implements this procedure.\n646\n1 class MCM(Problem):\n2 @staticmethod\n3 def thought(args) -> list[T]:\n4 mats, min_order, min_cost = args\n5\n6 # Base cases\n7 if len(mats) == 1:\n8 return []\n9\n10 if min_order is None:\n11 # Top-level problem\n12 l_mats, r_mats = mats[:1], mats[1:]\n13 else:\n14 # Middle of recursion\n15 l_mats, r_mats = mats\n16\n17 l_args = (l_mats, None, None)\n18 r_args = (r_mats, None, None)\n19 l_order, l_cost = MCM._answer(l_args)\n20 r_order, r_cost = MCM._answer(r_args)\n21 agg_cost = l_mats[0][0] * r_mats[0][0] * r_mats[-1][1]\n22 thoughts = [\n23 T(MCM, l_args),\n24 T(MCM, r_args),\n25 T(TernaryMul, (l_mats[0][0], r_mats[0][0], r_mats[-1][1])),\n26 T(TernaryAdd, (l_cost, r_cost, agg_cost)),\n27 ]\n28\n29 cost = l_cost + r_cost + agg_cost\n30 if min_cost is not None:\n31 thoughts.append(T(Compare, (cost, min_cost)))\n32 if min_cost is None or cost < min_cost:\n33 min_cost = cost\n34 min_order = l_order, r_order\n35\n36 if len(r_mats) > 1:\n37 new_l_mats = l_mats + (r_mats[0],)\n38 new_r_mats = r_mats[1:]\n39 thoughts.append(\n40 T(MCM, ((new_l_mats, new_r_mats), min_order, min_cost), 'tail'))\n41\n42 return thoughts\nThe following is an example of a three-matrix MCM.\n‚Ä¢ X1: GO MCM 3 √ó 9 , 9 √ó 4 , 4 √ó 5 = GO MCM 3 √ó 9 = 3 √ó 9 ; 0 STOP GO MCM 9 √ó 4 ,\n4 √ó 5 = 9 √ó 4 , 4 √ó 5 ; 1 8 0 STOP GO 3 * 9 * 5 = 1 3 5 STOP GO 0 + 1 8 0 + 1 3\n5 = 3 1 5 STOP TAIL MCM 3 √ó 9 , 9 √ó 4 | 4 √ó 5 ACC 3 √ó 9 , ( 9 √ó 4 , 4 √ó 5 ) ; 3\n1 5 = THINK\n‚Ä¢ ...\n‚Ä¢ X32: GO MCM 3 √ó 9 , 9 √ó 4 | 4 √ó 5 ACC 3 √ó 9 , ( 9 √ó 4 , 4 √ó 5 ) ; 3 1 5 = GO MCM\n3 √ó 9 , 9 √ó 4 = 3 √ó 9 , 9 √ó 4 ; 1 0 8 STOP GO MCM 4 √ó 5 = 4 √ó 5 ; 0 STOP GO 3 *\n4 * 5 = 6 0 STOP GO 1 0 8 + 0 + 6 0 = 1 6 8 STOP GO 1 6 8 VS 3 1 5 = LT STOP ( 3\n√ó 9 , 9 √ó 4 ) , 4 √ó 5 ; 1 6 8 STOP\n‚Ä¢ ...\nH.11 Sorting\nAmong several sorting algorithms, we choose merge sort for our experiments with CoT and RoT. Note that\nWT is not relevant to the sorting algorithm since it produces the answer directly. The merge sort algorithm\nis simple: (i) split the given sequence into two equally sized subsequences, (ii) sort each subsequence, and\n(iii) merge the two sorted sequences. Since the Ô¨Ånal merge operation is quite complicated, we deÔ¨Åne the\nmerge as a problem type.\n647\n1 class Merge(Problem):\n2 @staticmethod\n3 def thought(args) -> list[T]:\n4 l, r = args\n5 if len(l) == 0 or len(r) == 0:\n6 return []\n7\n8 thoughts = [T(Compare, (l[0], r[0]))]\n9 if l[0] < r[0] and len(l) > 1:\n10 thoughts.append(T(Merge, (l[1:], r)))\n11 elif l[0] >= r[0] and len(r) > 1:\n12 thoughts.append(T(Merge, (l, r[1:])))\n13 return thoughts\n14\n15\n16 class MergeSort(Problem):\n17 @staticmethod\n18 def thought(args) -> list[T]:\n19 if len(args) < 2:\n20 return []\n21\n22 l_len = (len(args) + 1) // 2\n23 l = args[:l_len]\n24 r = args[l_len:]\n25 return [\n26 T(MergeSort, l),\n27 T(MergeSort, r),\n28 T(Merge, (tuple(sorted(l)), tuple(sorted(r))), 'tail')\n29 ]\nI Fine-Tuning GPT-3 for Recursion of Thought\nUsing the OpenAI API, we Ô¨Åne-tune GPT-3 for Recursion of Thought. The goal is to learn 16-digit\naddition, 16-digit subtraction, 8-digit multiplication, and 8-digit division simultaneously. GPT-3‚Äôs Ô¨Åne-\ntuning API takes a dataset where each example is a prompt-completion pair in plain text. It is converted to\ntokens by a special tokenizer for GPT, which we cannot control. This API is not directly compatible with\nRoT due to several reasons.\n‚Ä¢ There is no special tokens such as GO , THINK , and STOP .\n‚Ä¢ The input and target sequences have to be the same. However, they are different in RoT due to the\nTHINK token. Once THINK is produced, the RoT framework triggers the recursion process to Ô¨Ånd\nthe subproblem‚Äôs answer and replace the THINK token with it. Therefore, the THINK token appears\nin the target sequences, but never in the input sequences.\nMoreover, the way that GPT-3 tokenizes numbers hinders the learning of arithmetic reasoning rules.\nGPT-3 tokenizes a multi-digit number into a set of two-digit or three-digit numbers. For example, the\ntext 1234567 is converted to the sequence of tokens 123 45 67 . Under this tokenization scheme, the\nrelationship between the numbers becomes obscured. As an example, the tokens 7 , 17 , 27 , ..., 997 all\nhave 7 as their last digit. Since there is no direct way for a model to know that they share the same digit, it\nis crucial to use each digit as a token. We believe that OpenAI needs to correct this tokenization of GPT-3\nfor numbers.\nLuckily, we can mimic the RoT procedures with the API by using several tricks. First, we replace the\nspecial tokens with plain lower-case words, e.g., GO ‚Üí go and STOP ‚Üí stop, which are included in the\nvocabulary of GPT-3. Second, we add a space before each token to make sure that the GPT tokenizer\nseparates each token. We also add space before each digit to prevent the tokenizer from grouping a\nnumber into 2-to-3-digit tokens. Finally, to simulate the behavior of the THINK and STOP tokens, we\nderive multiple examples from each context, one for each THINK or STOP output.\nAs an example, context X3 in Figure 1 is converted to the following JSON lines for GPT-3 as follows:\n648\nX3 GO 4 0 + 3 5 = GO 0 + 5 = 5 STOP GO 4 + 3 = 7 STOP 7 5 STOP\nY3 PAD √ó7 GO 0 + 5 = THINK PAD GO 4 + 3 = THINK PAD 7 5 STOP\n‚áì\n1 {\"prompt\": \" go 4 0 + 3 5 =\", \"completion\": \" go 0 + 5 = think\"}\n2 {\"prompt\": \" go 4 0 + 3 5 = go 0 + 5 = 5 stop\", \"completion\": \" go 4 + 3 = think\"}\n3 {\"prompt\": \" go 4 0 + 3 5 = go 0 + 5 = 5 stop go 4 + 3 = 7 stop\", \"completion\": \" 7 5 stop\"}\nIn the case of Without Thought (WT), each problem is simply converted into a single example:\nX GO 4 0 + 3 5 = 7 5 STOP\nY PAD √ó7 7 5 STOP\n‚áì\n1 {\"prompt\": \" go 4 0 + 3 5 =\", \"completion\": \" 7 5 stop\"}\nIn both cases of RoT and WT, we Ô¨Åne-tune GPT-3 for 10K steps with a batch size of 256. Among\nthe several variants of GPT-3, we use Ada which is offered at the lowest cost. Note that RoT produces\nmultiple contexts for each problem, and each RoT context is converted to multiple training examples. For\nthis reason, the GPT-3 Ô¨Åne-tuned for RoT encounters much fewer problems during training, although the\nnumbers of training steps are the same.\nJ Training Details of the Tiny Models\nIn all experiments, we use a batch size of 256 and Adam optimizer (Kingma and Ba, 2015) with a learning\nrate of 0.001, i.e., the default learning rate in PyTorch. We train the Transformers for 500K steps and\ndecay the learning rate by half every 50K steps. Since the LSTMs converge slower than the Transformers,\nwe train them for 800K steps and decay the learning rate by half every 100K steps. At every 20K steps,\nwe evaluate the model on a test set of 30K problems, and if a model reaches a perfect accuracy of 1.0, we\ndo not train the model further. The models can be trained on a single GPU with 12GB memory.\nK EfÔ¨Åcient Evaluation of RoT\nAt the problem scales that RoT is tested, solving a single problem can require hundreds of thousands of\ntokens. Therefore, we have to develop an efÔ¨Åcient evaluation algorithm. Since the models are deterministic,\nwe do not need to evaluate the same context multiple times. Therefore, given a test set, we Ô¨Årst Ô¨Ånd all\nunique contexts that should appear while solving the test set. Note that there would be a lot of duplicate\ncontexts, especially for the base cases. These unique contexts can be evaluated in parallel. We evaluate\neach context in a similar manner to the training. For each context, we construct the target sequence, as\nwe described in ¬ß3.2, and check if the model outputs the target sequence correctly, given the GT context.\nIn the case of GPT-3, we convert the contexts and target sequences as described in Appendix I to feed\ninto the API. Once every context is individually evaluated, the next step is to aggregate the results. In this\naggregation stage, a (sub)problem is marked correct only if its subproblems are all marked correct. This\nway, we efÔ¨Åciently evaluate RoT with minimal cost.\nL Failure Case Analysis of GPT-3 with RoT\nIn this section, we provide some failure cases of RoT in the GPT-3 experiments for further insights.\nAlthough the model achieves an accuracy of over 99% in almost every case, there are several problems\nwhere it makes mistakes. Nonetheless, only a few characters are wrong in each context.\nThe most common type of error is repeating the same character a wrong number of times. The following\nis the examples of this error type.\n649\nPrompt go 1 6 4 3 4 vs 1 0 1 1 6 = go 1 vs 1 = eq stop\nCompletion go 6 4 3 4 vs 1 1 6 = think\nModel Output go 6 4 3 4 vs 1 1 1 6 = think\nPrompt go 4 8 0 9 4 4 9 5 1 8 2 5 5 9 1 * 4 4 3 0 2 5 3 6 0 1 7\n= go 4 8 0 9 4 4 9 5 1 8 2 5 5 9 1 * 7 = 3 3 6 6 6 1 4 6\n6 2 7 7 9 1 3 7 stop go 4 8 0 9 4 4 9 5 1 8 2 5 5 9 1 * 4\n4 3 0 2 5 3 6 0 1 = 2 1 3 0 7 0 8 1 0 4 7 0 8 0 9 6 0 5 1\n7 0 3 1 9 1 stop\nCompletion tail 2 1 3 0 7 0 8 1 0 4 7 0 8 0 9 6 0 5 1 7 0 3 1 9 1 0\n+ 3 3 6 6 6 1 4 6 6 2 7 7 9 1 3 7 = think\nModel Output tail 2 1 3 0 7 0 8 1 0 4 7 0 8 0 9 6 0 5 1 7 0 3 1 9 1 0\n+ 3 3 6 6 6 6 1 4 6 6 2 7 7 9 1 3 7 = think\nPrompt go 1 0 5 4 6 2 0 * 1 5 = go 1 0 5 4 6 2 0 * 5 = 5 2 7 3 1\n0 0 stop go 1 0 5 4 6 2 0 * 1 = 1 0 5 4 6 2 0 stop\nCompletion tail 1 0 5 4 6 2 0 0 + 5 2 7 3 1 0 0 = think\nModel Output tail 1 0 5 4 6 2 0 0 0 + 5 2 7 3 1 0 0 = think\nAnother common case is incorrectly counting the number of digits while comparing two numbers.\nWhen comparing numbers following our recursive procedure, the model has to immediately return the\nanswer if the numbers of digits are different. In the following example, the Ô¨Årst number has seven digits,\nand the second one has six digits.\nPrompt go 1 0 6 9 0 3 4 vs 8 9 1 5 0 6 =\nCompletion gt stop\nModel Output go 1 vs 8\nAlthough the model should directly output the answer, i.e., gt stop, it decides that the numbers of digits\nare the same and moves on to the next step, which is to compare the most signiÔ¨Åcant digits. This error is\ncaused by the speciÔ¨Åc recursive procedure of our choice. Since we assume that the model would easily\nÔ¨Ågure out the difference in the number of digits, we did not add explicit steps to count the digits. Although\nthe model detects the difference in most cases, it turns out to be a relatively challenging operation. A\npossible solution is to teach the model to explicitly count the number of digits and compare them.\nM Context Length Distribution\nIn Figure 4, we present the distributions of context lengths for each problem type. We compare the context\nlengths of RoT and CoT. For each conÔ¨Åguration, we randomly sample 10K contexts from the training\ndistribution and plot the histogram of their lengths. The graphs show that the context sizes of CoT are\nmany orders of magnitude larger than RoT. In theory, the total number of tokens to generate for each\nproblem is identical in both RoT and CoT (if we do not count the THINK tokens). However, RoT‚Äôs context\nsizes are much smaller since it utilizes multiple contexts.\nAnother advantage of RoT is the utilization of dynamic programming. Since we can easily cache the\nduplicate computations of RoT as explained in Appendix K, we can drastically reduce the amount of\ntoken generation if there is a redundant structure in the problem. The amount of tokens to generate for\neach problem is plotted in Figure 5. The beneÔ¨Åt is especially prominent in algorithmic problems. For\nexample, Ô¨Ånding the LCS of two 32-digit sequences results in more than 1018 tokens if we naively use\nCoT or RoT. If we use dynamic programming with RoT, we can efÔ¨Åciently solve the same problem with\nmuch less cost.\n650\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013\n/uni00000024/uni00000047/uni00000047/uni00000003/uni00000012/uni00000003/uni00000016/uni00000015/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000015/uni00000013/uni00000013/uni00000013/uni00000015/uni00000018/uni00000013/uni00000013/uni00000016/uni00000013/uni00000013/uni00000013\n/uni00000024/uni00000047/uni00000047/uni00000003/uni00000012/uni00000003/uni00000016/uni00000015/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000013/uni00000015/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013\n/uni00000024/uni00000047/uni00000047/uni00000003/uni00000012/uni00000003/uni00000019/uni00000017/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni0000001b/uni00000013/uni00000013/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000024/uni00000047/uni00000047/uni00000003/uni00000012/uni00000003/uni00000019/uni00000017/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013\n/uni00000036/uni00000058/uni00000045/uni00000003/uni00000012/uni00000003/uni00000016/uni00000015/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000015/uni00000018/uni00000013/uni00000013/uni00000016/uni00000013/uni00000013/uni00000013\n/uni00000036/uni00000058/uni00000045/uni00000003/uni00000012/uni00000003/uni00000016/uni00000015/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000013/uni00000015/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013\n/uni00000036/uni00000058/uni00000045/uni00000003/uni00000012/uni00000003/uni00000019/uni00000017/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni0000001c/uni00000013/uni00000013/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000036/uni00000058/uni00000045/uni00000003/uni00000012/uni00000003/uni00000019/uni00000017/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013\n/uni00000030/uni00000058/uni0000004f/uni00000003/uni00000012/uni00000003/uni00000014/uni00000019/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000013/uni00000015/uni00000013/uni00000013/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000030/uni00000058/uni0000004f/uni00000003/uni00000012/uni00000003/uni00000014/uni00000019/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000013/uni00000015/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013\n/uni00000030/uni00000058/uni0000004f/uni00000003/uni00000012/uni00000003/uni00000016/uni00000015/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000030/uni00000058/uni0000004f/uni00000003/uni00000012/uni00000003/uni00000016/uni00000015/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013\n/uni00000027/uni0000004c/uni00000059/uni00000003/uni00000012/uni00000003/uni00000014/uni00000019/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000027/uni0000004c/uni00000059/uni00000003/uni00000012/uni00000003/uni00000014/uni00000019/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000013/uni00000015/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013\n/uni00000027/uni0000004c/uni00000059/uni00000003/uni00000012/uni00000003/uni00000016/uni00000015/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000013/uni00000018/uni00000013/uni00000013/uni00000013/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000027/uni0000004c/uni00000059/uni00000003/uni00000012/uni00000003/uni00000016/uni00000015/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000013 /uni00000014/uni00000013/uni00000013\n/uni0000002f/uni00000026/uni00000036/uni00000003/uni00000012/uni00000003/uni0000004f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b/uni00000003/uni00000014/uni00000019/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000013 /uni00000014\n/uni00000014/uni00000048/uni00000014/uni00000013\n/uni0000002f/uni00000026/uni00000036/uni00000003/uni00000012/uni00000003/uni0000004f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b/uni00000003/uni00000014/uni00000019/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013\n/uni0000002f/uni00000026/uni00000036/uni00000003/uni00000012/uni00000003/uni0000004f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b/uni00000003/uni00000016/uni00000015/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000013 /uni00000018\n/uni00000014/uni00000048/uni00000014/uni0000001b\n/uni0000002f/uni00000026/uni00000036/uni00000003/uni00000012/uni00000003/uni0000004f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b/uni00000003/uni00000016/uni00000015/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000018/uni00000013/uni00000014/uni00000013/uni00000013\n/uni0000002f/uni00000033/uni00000036/uni00000003/uni00000012/uni00000003/uni0000004f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b/uni00000003/uni00000014/uni00000019/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000013/uni00000018/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013\n/uni0000002f/uni00000033/uni00000036/uni00000003/uni00000012/uni00000003/uni0000004f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b/uni00000003/uni00000014/uni00000019/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000013/uni00000014/uni00000013/uni00000013\n/uni0000002f/uni00000033/uni00000036/uni00000003/uni00000012/uni00000003/uni0000004f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b/uni00000003/uni00000016/uni00000015/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000013 /uni00000015\n/uni00000014/uni00000048/uni00000014/uni00000013\n/uni0000002f/uni00000033/uni00000036/uni00000003/uni00000012/uni00000003/uni0000004f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b/uni00000003/uni00000016/uni00000015/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013\n/uni0000002e/uni00000051/uni00000044/uni00000053/uni00000056/uni00000044/uni00000046/uni0000004e/uni00000003/uni00000012/uni00000003/uni00000019/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000050/uni00000056/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000013/uni00000015/uni00000018/uni00000013/uni00000013/uni00000018/uni00000013/uni00000013/uni00000013\n/uni0000002e/uni00000051/uni00000044/uni00000053/uni00000056/uni00000044/uni00000046/uni0000004e/uni00000003/uni00000012/uni00000003/uni00000019/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000050/uni00000056/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000013/uni00000015/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013\n/uni0000002e/uni00000051/uni00000044/uni00000053/uni00000056/uni00000044/uni00000046/uni0000004e/uni00000003/uni00000012/uni00000003/uni00000014/uni00000015/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000050/uni00000056/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000013/uni00000015/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013\n/uni0000002e/uni00000051/uni00000044/uni00000053/uni00000056/uni00000044/uni00000046/uni0000004e/uni00000003/uni00000012/uni00000003/uni00000014/uni00000015/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000050/uni00000056/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000013/uni00000015/uni00000013/uni00000013\n/uni00000030/uni00000026/uni00000030/uni00000003/uni00000012/uni00000003/uni00000019/uni00000003/uni00000050/uni00000044/uni00000057/uni00000055/uni0000004c/uni00000046/uni00000048/uni00000056/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000018/uni00000013/uni00000013/uni00000013/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000030/uni00000026/uni00000030/uni00000003/uni00000012/uni00000003/uni00000019/uni00000003/uni00000050/uni00000044/uni00000057/uni00000055/uni0000004c/uni00000046/uni00000048/uni00000056/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000013/uni00000015/uni00000018/uni00000013/uni00000018/uni00000013/uni00000013\n/uni00000030/uni00000026/uni00000030/uni00000003/uni00000012/uni00000003/uni00000014/uni00000015/uni00000003/uni00000050/uni00000044/uni00000057/uni00000055/uni0000004c/uni00000046/uni00000048/uni00000056/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000015/uni00000011/uni00000018/uni00000018/uni00000011/uni00000013/uni0000001a/uni00000011/uni00000018\n/uni00000014/uni00000048/uni0000001a\n/uni00000030/uni00000026/uni00000030/uni00000003/uni00000012/uni00000003/uni00000014/uni00000015/uni00000003/uni00000050/uni00000044/uni00000057/uni00000055/uni0000004c/uni00000046/uni00000048/uni00000056/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\nFigure 4: The distributions of context lengths.\n651\n/uni00000015/uni00000013/uni00000013/uni00000013/uni00000015/uni00000018/uni00000013/uni00000013/uni00000016/uni00000013/uni00000013/uni00000013\n/uni00000024/uni00000047/uni00000047/uni00000003/uni00000012/uni00000003/uni00000016/uni00000015/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000015/uni00000013/uni00000013/uni00000013/uni00000015/uni00000018/uni00000013/uni00000013/uni00000016/uni00000013/uni00000013/uni00000013\n/uni00000024/uni00000047/uni00000047/uni00000003/uni00000012/uni00000003/uni00000016/uni00000015/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni0000001b/uni00000013/uni00000013/uni00000013/uni0000001c/uni00000013/uni00000013/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000024/uni00000047/uni00000047/uni00000003/uni00000012/uni00000003/uni00000019/uni00000017/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni0000001b/uni00000013/uni00000013/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000024/uni00000047/uni00000047/uni00000003/uni00000012/uni00000003/uni00000019/uni00000017/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000015/uni00000018/uni00000013/uni00000013/uni00000016/uni00000013/uni00000013/uni00000013\n/uni00000036/uni00000058/uni00000045/uni00000003/uni00000012/uni00000003/uni00000016/uni00000015/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000015/uni00000013/uni00000013/uni00000013/uni00000015/uni00000018/uni00000013/uni00000013/uni00000016/uni00000013/uni00000013/uni00000013\n/uni00000036/uni00000058/uni00000045/uni00000003/uni00000012/uni00000003/uni00000016/uni00000015/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni0000001b/uni00000013/uni00000013/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000036/uni00000058/uni00000045/uni00000003/uni00000012/uni00000003/uni00000019/uni00000017/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni0000001b/uni00000013/uni00000013/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000036/uni00000058/uni00000045/uni00000003/uni00000012/uni00000003/uni00000019/uni00000017/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000013/uni00000015/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000030/uni00000058/uni0000004f/uni00000003/uni00000012/uni00000003/uni00000014/uni00000019/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000013/uni00000015/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000030/uni00000058/uni0000004f/uni00000003/uni00000012/uni00000003/uni00000014/uni00000019/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000030/uni00000058/uni0000004f/uni00000003/uni00000012/uni00000003/uni00000016/uni00000015/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000030/uni00000058/uni0000004f/uni00000003/uni00000012/uni00000003/uni00000016/uni00000015/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000027/uni0000004c/uni00000059/uni00000003/uni00000012/uni00000003/uni00000014/uni00000019/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000027/uni0000004c/uni00000059/uni00000003/uni00000012/uni00000003/uni00000014/uni00000019/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000013/uni00000018/uni00000013/uni00000013/uni00000013/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000027/uni0000004c/uni00000059/uni00000003/uni00000012/uni00000003/uni00000016/uni00000015/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000013/uni00000018/uni00000013/uni00000013/uni00000013/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000027/uni0000004c/uni00000059/uni00000003/uni00000012/uni00000003/uni00000016/uni00000015/uni00000010/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013/uni00000014/uni00000018/uni00000013/uni00000013/uni00000013\n/uni0000002f/uni00000026/uni00000036/uni00000003/uni00000012/uni00000003/uni0000004f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b/uni00000003/uni00000014/uni00000019/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000013 /uni00000014\n/uni00000014/uni00000048/uni00000014/uni00000013\n/uni0000002f/uni00000026/uni00000036/uni00000003/uni00000012/uni00000003/uni0000004f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b/uni00000003/uni00000014/uni00000019/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000019/uni00000013/uni00000013/uni00000013/uni00000013/uni0000001b/uni00000013/uni00000013/uni00000013/uni00000013\n/uni0000002f/uni00000026/uni00000036/uni00000003/uni00000012/uni00000003/uni0000004f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b/uni00000003/uni00000016/uni00000015/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000013/uni00000018\n/uni00000014/uni00000048/uni00000014/uni0000001b\n/uni0000002f/uni00000026/uni00000036/uni00000003/uni00000012/uni00000003/uni0000004f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b/uni00000003/uni00000016/uni00000015/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000015/uni00000013/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013/uni00000013\n/uni0000002f/uni00000033/uni00000036/uni00000003/uni00000012/uni00000003/uni0000004f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b/uni00000003/uni00000014/uni00000019/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000013/uni00000018/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013\n/uni0000002f/uni00000033/uni00000036/uni00000003/uni00000012/uni00000003/uni0000004f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b/uni00000003/uni00000014/uni00000019/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000013/uni00000013\n/uni0000002f/uni00000033/uni00000036/uni00000003/uni00000012/uni00000003/uni0000004f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b/uni00000003/uni00000016/uni00000015/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000013 /uni00000015\n/uni00000014/uni00000048/uni00000014/uni00000013\n/uni0000002f/uni00000033/uni00000036/uni00000003/uni00000012/uni00000003/uni0000004f/uni00000048/uni00000051/uni0000004a/uni00000057/uni0000004b/uni00000003/uni00000016/uni00000015/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000013/uni00000015/uni00000013/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013/uni00000013\n/uni0000002e/uni00000051/uni00000044/uni00000053/uni00000056/uni00000044/uni00000046/uni0000004e/uni00000003/uni00000012/uni00000003/uni00000019/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000050/uni00000056/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000013/uni00000015/uni00000018/uni00000013/uni00000013/uni00000018/uni00000013/uni00000013/uni00000013\n/uni0000002e/uni00000051/uni00000044/uni00000053/uni00000056/uni00000044/uni00000046/uni0000004e/uni00000003/uni00000012/uni00000003/uni00000019/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000050/uni00000056/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013\n/uni0000002e/uni00000051/uni00000044/uni00000053/uni00000056/uni00000044/uni00000046/uni0000004e/uni00000003/uni00000012/uni00000003/uni00000014/uni00000015/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000050/uni00000056/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000013/uni00000015/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013\n/uni0000002e/uni00000051/uni00000044/uni00000053/uni00000056/uni00000044/uni00000046/uni0000004e/uni00000003/uni00000012/uni00000003/uni00000014/uni00000015/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000050/uni00000056/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000030/uni00000026/uni00000030/uni00000003/uni00000012/uni00000003/uni00000019/uni00000003/uni00000050/uni00000044/uni00000057/uni00000055/uni0000004c/uni00000046/uni00000048/uni00000056/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000018/uni00000013/uni00000013/uni00000013/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000030/uni00000026/uni00000030/uni00000003/uni00000012/uni00000003/uni00000019/uni00000003/uni00000050/uni00000044/uni00000057/uni00000055/uni0000004c/uni00000046/uni00000048/uni00000056/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\n/uni00000014/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013\n/uni00000030/uni00000026/uni00000030/uni00000003/uni00000012/uni00000003/uni00000014/uni00000015/uni00000003/uni00000050/uni00000044/uni00000057/uni00000055/uni0000004c/uni00000046/uni00000048/uni00000056/uni00000003/uni00000012/uni00000003/uni00000035/uni00000052/uni00000037\n/uni00000015/uni00000011/uni00000018/uni00000018/uni00000011/uni00000013/uni0000001a/uni00000011/uni00000018\n/uni00000014/uni00000048/uni0000001a\n/uni00000030/uni00000026/uni00000030/uni00000003/uni00000012/uni00000003/uni00000014/uni00000015/uni00000003/uni00000050/uni00000044/uni00000057/uni00000055/uni0000004c/uni00000046/uni00000048/uni00000056/uni00000003/uni00000012/uni00000003/uni00000026/uni00000052/uni00000037\nFigure 5: The distribution of the total number of tokens to produce in order to solve each problem. RoT can utilize\ndynamic programming to reduce redundant computations.\n652\n/uni0000001b/uni00000014/uni00000019/uni00000015/uni00000017/uni00000016/uni00000015/uni00000017/uni00000013/uni00000017/uni0000001b/uni00000018/uni00000019/uni00000019/uni00000017\n/uni00000006/uni00000003/uni00000052/uni00000049/uni00000003/uni0000002c/uni00000057/uni00000048/uni00000050/uni00000056\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c\n/uni00000036/uni00000052/uni00000055/uni00000057/uni0000004c/uni00000051/uni0000004a\n/uni0000003a/uni0000004c/uni00000057/uni0000004b/uni00000052/uni00000058/uni00000057/uni00000003/uni00000037/uni0000004b/uni00000052/uni00000058/uni0000004a/uni0000004b/uni00000057\n/uni00000026/uni0000004b/uni00000044/uni0000004c/uni00000051/uni00000003/uni00000052/uni00000049/uni00000003/uni00000037/uni0000004b/uni00000052/uni00000058/uni0000004a/uni0000004b/uni00000057\n/uni00000035/uni00000048/uni00000046/uni00000058/uni00000055/uni00000056/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000052/uni00000049/uni00000003/uni00000037/uni0000004b/uni00000052/uni00000058/uni0000004a/uni0000004b/uni00000057\nFigure 6: Sorting experiment with the tiny Transformer.\nProblem DifÔ¨Åculty WT CoT RoT\nAddition 32-digit 0.991 ‚àí 0.998\n48-digit 0.853 ‚àí 0.995\nSubtraction 32-digit 0.991 ‚àí 0.998\n48-digit 0.886 ‚àí 0.998\nMultiplication 8-digit 0.337 ‚àí 0.999\n16-digit 0.098 ‚àí 0.994\nDivision 8-digit 0.363 ‚àí 1.000\n16-digit 0.123 ‚àí 0.989\nLCS length 16 0.980 ‚àí 0.995\nlength 24 0.832 ‚àí 0.998\nLPS length 24 0.995 ‚àí 1.000\nlength 40 0.800 ‚àí 0.974\n0-1 Knapsack 4 items 0.945 ‚àí 0.999\n6 items 0.634 ‚àí 1.000\nMCM 3 matrices 0.481 ‚àí 0.997\n4 matrices 0.110 ‚àí 0.992\nTable 2: The exact values of the GPT-3 experiments in Figure 2a.\nN Transformers Are Powerful Sorting Machines\nIn fact, the Ô¨Årst algorithmic task that we tested is sorting since it has been widely used as a benchmark for\nalgorithmic reasoning (Reed and de Freitas, 2016; Cai et al., 2017; Pierrot et al., 2019). However, we\nÔ¨Ånd that Transformers are incredibly good at sorting, even in the WT setting. Figure 6 shows the sorting\nexperiment. For CoT and RoT, we train the merge sort algorithm. Interestingly, WT easily achieves a\nperfect score in sorting 64 three-digit numbers. Also, the training converges much faster than RoT. The\nTransformer architecture, more speciÔ¨Åcally the attention mechanism, seems to be perfectly suited for the\nsorting operation.\nO The Exact Values of Figure 2\nTable 2-5 show the exact values of the graphs in Figure 2. Except for the GPT-3 experiments in Table 2,\nwe report the average and the standard deviation of eight runs. Each GPT-3 experiment is done only once.\n653\nProblem DifÔ¨Åculty WT CoT RoT\nAddition\n8-digit 0.863 ¬±0.265 1 .000 ¬±0.000 1 .000 ¬±0.000\n16-digit 0.370 ¬±0.475 1 .000 ¬±0.000 1 .000 ¬±0.000\n24-digit 0.336 ¬±0.430 1 .000 ¬±0.000 1 .000 ¬±0.000\n32-digit 0.455 ¬±0.458 ‚àí 1.000 ¬±0.000\n40-digit 0.119 ¬±0.316 ‚àí 1.000 ¬±0.000\n48-digit 0.082 ¬±0.216 ‚àí 1.000 ¬±0.000\n56-digit 0.105 ¬±0.277 ‚àí 1.000 ¬±0.000\n64-digit 0.000 ¬±0.000 ‚àí 1.000 ¬±0.001\nSubtraction\n8-digit 0.982 ¬±0.006 1 .000 ¬±0.000 1 .000 ¬±0.000\n16-digit 0.705 ¬±0.411 1 .000 ¬±0.000 1 .000 ¬±0.000\n24-digit 0.238 ¬±0.412 1 .000 ¬±0.000 1 .000 ¬±0.000\n32-digit 0.221 ¬±0.385 ‚àí 1.000 ¬±0.000\n40-digit 0.426 ¬±0.433 ‚àí 1.000 ¬±0.000\n48-digit 0.114 ¬±0.303 ‚àí 1.000 ¬±0.000\n56-digit 0.116 ¬±0.307 ‚àí 1.000 ¬±0.000\n64-digit 0.161 ¬±0.282 ‚àí 1.000 ¬±0.000\nMultiplication\n2-digit 1.000 ¬±0.000 1 .000 ¬±0.000 1 .000 ¬±0.000\n4-digit 0.817 ¬±0.023 1 .000 ¬±0.000 1 .000 ¬±0.000\n8-digit 0.340 ¬±0.032 ‚àí 1.000 ¬±0.000\n12-digit 0.169 ¬±0.015 ‚àí 1.000 ¬±0.000\n16-digit 0.104 ¬±0.016 ‚àí 1.000 ¬±0.000\n20-digit 0.048 ¬±0.020 ‚àí 1.000 ¬±0.000\n24-digit 0.033 ¬±0.017 ‚àí 0.999 ¬±0.001\n28-digit 0.014 ¬±0.006 ‚àí 0.999 ¬±0.001\n32-digit 0.012 ¬±0.001 ‚àí 0.999 ¬±0.000\nDivision\n2-digit 1.000 ¬±0.000 1 .000 ¬±0.000 1 .000 ¬±0.000\n4-digit 0.978 ¬±0.008 1 .000 ¬±0.000 1 .000 ¬±0.000\n8-digit 0.354 ¬±0.029 ‚àí 1.000 ¬±0.000\n12-digit 0.186 ¬±0.009 ‚àí 1.000 ¬±0.000\n16-digit 0.128 ¬±0.011 ‚àí 1.000 ¬±0.000\n20-digit 0.087 ¬±0.012 ‚àí 1.000 ¬±0.000\n24-digit 0.075 ¬±0.005 ‚àí 1.000 ¬±0.000\n28-digit 0.059 ¬±0.007 ‚àí 0.999 ¬±0.000\n32-digit 0.048 ¬±0.008 ‚àí 0.999 ¬±0.000\nTable 3: The exact values of the Transformer experiments in Figure 2b (arithmetic problems).\n654\nProblem DifÔ¨Åculty WT CoT RoT\nLCS\nlength 3 1.000 ¬±0.000 1 .000 ¬±0.000 ‚àí\nlength 4 0.997 ¬±0.008 ‚àí 1.000 ¬±0.000\nlength 8 0.999 ¬±0.002 ‚àí 1.000 ¬±0.000\nlength 12 0.965 ¬±0.025 ‚àí 1.000 ¬±0.000\nlength 16 0.880 ¬±0.035 ‚àí 1.000 ¬±0.000\nlength 20 0.759 ¬±0.043 ‚àí 1.000 ¬±0.000\nlength 24 0.622 ¬±0.038 ‚àí 1.000 ¬±0.000\nlength 28 0.484 ¬±0.043 ‚àí 0.999 ¬±0.000\nlength 32 0.375 ¬±0.030 ‚àí 0.999 ¬±0.000\nLPS\nlength 4 1.000 ¬±0.000 1 .000 ¬±0.000 ‚àí\nlength 7 1.000 ¬±0.000 1 .000 ¬±0.000 ‚àí\nlength 8 1.000 ¬±0.000 ‚àí 1.000 ¬±0.000\nlength 16 0.999 ¬±0.001 ‚àí 1.000 ¬±0.000\nlength 24 0.950 ¬±0.019 ‚àí 1.000 ¬±0.000\nlength 32 0.788 ¬±0.019 ‚àí 1.000 ¬±0.000\nlength 40 0.608 ¬±0.023 ‚àí 1.000 ¬±0.000\nlength 48 0.477 ¬±0.030 ‚àí 0.999 ¬±0.001\nlength 56 0.365 ¬±0.029 ‚àí 0.998 ¬±0.000\n0-1 Knapsack\n2 items 1.000 ¬±0.000 1 .000 ¬±0.000 1 .000 ¬±0.000\n4 items 0.966 ¬±0.006 1 .000 ¬±0.000 1 .000 ¬±0.000\n6 items 0.849 ¬±0.007 ‚àí 1.000 ¬±0.000\n8 items 0.640 ¬±0.242 ‚àí 1.000 ¬±0.000\n10 items 0.481 ¬±0.279 ‚àí 1.000 ¬±0.000\n12 items 0.435 ¬±0.252 ‚àí 0.988 ¬±0.029\nMCM\n2 matrices 0.973 ¬±0.009 1 .000 ¬±0.000 1 .000 ¬±0.000\n4 matrices 0.177 ¬±0.069 ‚àí 1.000 ¬±0.000\n6 matrices 0.088 ¬±0.029 ‚àí 1.000 ¬±0.000\n8 matrices 0.033 ¬±0.025 ‚àí 1.000 ¬±0.000\n10 matrices 0.051 ¬±0.032 ‚àí 0.998 ¬±0.001\n12 matrices 0.026 ¬±0.011 ‚àí 0.996 ¬±0.002\nTable 4: The exact values of the Transformer experiments in Figure 2b (algorithmic problems).\n655\nProblem DifÔ¨Åculty WT CoT RoT\nAddition\n2-digit 1.000 ¬±0.000 1 .000 ¬±0.000 1 .000 ¬±0.000\n4-digit 0.642 ¬±0.305 1 .000 ¬±0.001 1 .000 ¬±0.000\n6-digit 0.005 ¬±0.008 0 .997 ¬±0.005 0 .999 ¬±0.000\n8-digit 0.000 ¬±0.000 0 .905 ¬±0.155 0 .999 ¬±0.001\n10-digit 0.000 ¬±0.000 0 .795 ¬±0.341 0 .986 ¬±0.024\n12-digit 0.000 ¬±0.000 ‚àí 0.871 ¬±0.275\n14-digit 0.000 ¬±0.000 ‚àí 0.358 ¬±0.430\n16-digit 0.000 ¬±0.000 ‚àí 0.120 ¬±0.202\nSubtraction\n2-digit 1.000 ¬±0.000 1 .000 ¬±0.000 1 .000 ¬±0.000\n4-digit 0.776 ¬±0.179 1 .000 ¬±0.000 1 .000 ¬±0.000\n6-digit 0.006 ¬±0.001 1 .000 ¬±0.000 1 .000 ¬±0.000\n8-digit 0.000 ¬±0.000 0 .896 ¬±0.252 0 .994 ¬±0.016\n10-digit 0.000 ¬±0.000 0 .443 ¬±0.377 0 .908 ¬±0.236\n12-digit 0.000 ¬±0.000 ‚àí 0.507 ¬±0.398\n14-digit 0.000 ¬±0.000 ‚àí 0.295 ¬±0.406\n16-digit 0.000 ¬±0.000 ‚àí 0.101 ¬±0.137\nMultiplication\n2-digit 1.000 ¬±0.000 1 .000 ¬±0.000 1 .000 ¬±0.000\n3-digit 0.855 ¬±0.044 ‚àí 1.000 ¬±0.000\n4-digit 0.636 ¬±0.061 ‚àí 1.000 ¬±0.000\n5-digit 0.338 ¬±0.063 ‚àí 1.000 ¬±0.000\n6-digit 0.270 ¬±0.030 ‚àí 0.987 ¬±0.008\n7-digit 0.162 ¬±0.025 ‚àí 0.896 ¬±0.105\n8-digit 0.138 ¬±0.025 ‚àí 0.670 ¬±0.208\nDivision\n1-digit 1.000 ¬±0.000 1 .000 ¬±0.000 1 .000 ¬±0.000\n2-digit 1.000 ¬±0.000 ‚àí 1.000 ¬±0.000\n3-digit 1.000 ¬±0.001 ‚àí 1.000 ¬±0.000\n4-digit 0.891 ¬±0.072 ‚àí 1.000 ¬±0.000\n5-digit 0.516 ¬±0.077 ‚àí 0.998 ¬±0.004\n6-digit 0.308 ¬±0.069 ‚àí 0.996 ¬±0.007\n7-digit 0.192 ¬±0.028 ‚àí 0.958 ¬±0.036\n8-digit 0.115 ¬±0.015 ‚àí 0.914 ¬±0.090\nTable 5: The exact values of the LSTM experiments in Figure 2c.\n656\nACL 2023 Responsible NLP Checklist\nA For every submission:\n‚ñ°\u0013 A1. Did you describe the limitations of your work?\nLimitations\n‚ñ° A2. Did you discuss any potential risks of your work?\nNot applicable. Left blank.\n‚ñ°\u0013 A3. Do the abstract and introduction summarize the paper‚Äôs main claims?\nAbstract & Section 1\n‚ñ°\u0017 A4. Have you used AI writing assistants when working on this paper?\nLeft blank.\nB ‚ñ°\u0013 Did you use or create scientiÔ¨Åc artifacts?\nWe include the source code used in our experiments.\n‚ñ°\u0017 B1. Did you cite the creators of artifacts you used?\nWe did not use any external artifcats.\n‚ñ°\u0017 B2. Did you discuss the license or terms for use and / or distribution of any artifacts?\nWe did not use any external artifcats.\n‚ñ° B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided\nthat it was speciÔ¨Åed? For the artifacts you create, do you specify intended use and whether that is\ncompatible with the original access conditions (in particular, derivatives of data accessed for research\npurposes should not be used outside of research contexts)?\nNot applicable. Left blank.\n‚ñ° B4. Did you discuss the steps taken to check whether the data that was collected / used contains any\ninformation that names or uniquely identiÔ¨Åes individual people or offensive content, and the steps\ntaken to protect / anonymize it?\nNot applicable. Left blank.\n‚ñ°\u0013 B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and\nlinguistic phenomena, demographic groups represented, etc.?\nWe provide documentation in README.md inside the source code.\n‚ñ°\u0013 B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,\netc. for the data that you used / created? Even for commonly-used benchmark datasets, include the\nnumber of examples in train / validation / test splits, as these provide necessary context for a reader\nto understand experimental results. For example, small differences in accuracy on large test sets may\nbe signiÔ¨Åcant, while on small test sets they may not be.\nAppendix C, G, H\nC ‚ñ°\u0013 Did you run computational experiments?\nSection 4\n‚ñ°\u0013 C1. Did you report the number of parameters in the models used, the total computational budget\n(e.g., GPU hours), and computing infrastructure used?\nSection 4, Appendix I, J\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing\nassistance.\n657\n‚ñ°\u0013 C2. Did you discuss the experimental setup, including hyperparameter search and best-found\nhyperparameter values?\nAppendix J\n‚ñ°\u0013 C3. Did you report descriptive statistics about your results (e.g., error bars around results, summary\nstatistics from sets of experiments), and is it transparent whether you are reporting the max, mean,\netc. or just a single run?\nSection 4, Appendix O\n‚ñ° C4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did\nyou report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,\netc.)?\nNot applicable. Left blank.\nD ‚ñ°\u0017 Did you use human annotators (e.g., crowdworkers) or research with human participants?\nLeft blank.\n‚ñ° D1. Did you report the full text of instructions given to participants, including e.g., screenshots,\ndisclaimers of any risks to participants or annotators, etc.?\nNo response.\n‚ñ° D2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)\nand paid participants, and discuss if such payment is adequate given the participants‚Äô demographic\n(e.g., country of residence)?\nNo response.\n‚ñ° D3. Did you discuss whether and how consent was obtained from people whose data you‚Äôre\nusing/curating? For example, if you collected data via crowdsourcing, did your instructions to\ncrowdworkers explain how the data would be used?\nNo response.\n‚ñ° D4. Was the data collection protocol approved (or determined exempt) by an ethics review board?\nNo response.\n‚ñ° D5. Did you report the basic demographic and geographic characteristics of the annotator population\nthat is the source of the data?\nNo response.\n658",
  "topic": "Recursion (computer science)",
  "concepts": [
    {
      "name": "Recursion (computer science)",
      "score": 0.8102304935455322
    },
    {
      "name": "Computer science",
      "score": 0.8055068254470825
    },
    {
      "name": "Divide and conquer algorithms",
      "score": 0.7930668592453003
    },
    {
      "name": "Context (archaeology)",
      "score": 0.7258340716362
    },
    {
      "name": "Inference",
      "score": 0.6379026770591736
    },
    {
      "name": "Limit (mathematics)",
      "score": 0.6121099591255188
    },
    {
      "name": "Theoretical computer science",
      "score": 0.5647936463356018
    },
    {
      "name": "Programming language",
      "score": 0.4389195442199707
    },
    {
      "name": "Artificial intelligence",
      "score": 0.34271740913391113
    },
    {
      "name": "Mathematics",
      "score": 0.17793875932693481
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    }
  ],
  "cited_by": 5
}