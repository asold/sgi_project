{
    "title": "Cross-Forgery Analysis of Vision Transformers and CNNs for Deepfake Image Detection",
    "url": "https://openalex.org/W4283452332",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A4283542186",
            "name": "Davide Alessandro Coccomini",
            "affiliations": [
                "National Research Council",
                "Istituto di Scienza e Tecnologie dell'Informazione \"Alessandro Faedo\""
            ]
        },
        {
            "id": "https://openalex.org/A253185264",
            "name": "Roberto Caldelli",
            "affiliations": [
                "Consorzio Nazionale Interuniversitario per le Telecomunicazioni"
            ]
        },
        {
            "id": "https://openalex.org/A2032466494",
            "name": "Fabrizio Falchi",
            "affiliations": [
                "Istituto di Scienza e Tecnologie dell'Informazione \"Alessandro Faedo\"",
                "National Research Council"
            ]
        },
        {
            "id": "https://openalex.org/A2161798937",
            "name": "Claudio Gennaro",
            "affiliations": [
                "National Research Council",
                "Istituto di Scienza e Tecnologie dell'Informazione \"Alessandro Faedo\""
            ]
        },
        {
            "id": "https://openalex.org/A2102836602",
            "name": "Giuseppe Amato",
            "affiliations": [
                "National Research Council",
                "Istituto di Scienza e Tecnologie dell'Informazione \"Alessandro Faedo\""
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3138202081",
        "https://openalex.org/W2944294033",
        "https://openalex.org/W3179508259",
        "https://openalex.org/W2108598243",
        "https://openalex.org/W3034371424",
        "https://openalex.org/W3046357466",
        "https://openalex.org/W2960274051",
        "https://openalex.org/W4285531802",
        "https://openalex.org/W3034900344",
        "https://openalex.org/W2989505547",
        "https://openalex.org/W3035574324",
        "https://openalex.org/W3034521057",
        "https://openalex.org/W3034301684",
        "https://openalex.org/W3034713808",
        "https://openalex.org/W2984700035",
        "https://openalex.org/W2982058372",
        "https://openalex.org/W3145444543",
        "https://openalex.org/W2963684180",
        "https://openalex.org/W2341528187",
        "https://openalex.org/W3151130473",
        "https://openalex.org/W3128609017",
        "https://openalex.org/W2904573504",
        "https://openalex.org/W3101998545",
        "https://openalex.org/W3141468933",
        "https://openalex.org/W1959608418",
        "https://openalex.org/W2951939904",
        "https://openalex.org/W2963767194",
        "https://openalex.org/W4287758545",
        "https://openalex.org/W3025670292",
        "https://openalex.org/W3178572954",
        "https://openalex.org/W3094502228",
        "https://openalex.org/W3099319035",
        "https://openalex.org/W3008823916",
        "https://openalex.org/W4298289240"
    ],
    "abstract": "Deepfake Generation Techniques are evolving at a rapid pace, making it\\npossible to create realistic manipulated images and videos and endangering the\\nserenity of modern society. The continual emergence of new and varied\\ntechniques brings with it a further problem to be faced, namely the ability of\\ndeepfake detection models to update themselves promptly in order to be able to\\nidentify manipulations carried out using even the most recent methods. This is\\nan extremely complex problem to solve, as training a model requires large\\namounts of data, which are difficult to obtain if the deepfake generation\\nmethod is too recent. Moreover, continuously retraining a network would be\\nunfeasible. In this paper, we ask ourselves if, among the various deep learning\\ntechniques, there is one that is able to generalise the concept of deepfake to\\nsuch an extent that it does not remain tied to one or more specific deepfake\\ngeneration methods used in the training set. We compared a Vision Transformer\\nwith an EfficientNetV2 on a cross-forgery context based on the ForgeryNet\\ndataset. From our experiments, It emerges that EfficientNetV2 has a greater\\ntendency to specialize often obtaining better results on training methods while\\nVision Transformers exhibit a superior generalization ability that makes them\\nmore competent even on images generated with new methodologies.\\n",
    "full_text": null
}