{
    "title": "Transformer-Based High-Frequency Oscillation Signal Detection on Magnetoencephalography From Epileptic Patients",
    "url": "https://openalex.org/W4214879898",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2531374610",
            "name": "Jiayang Guo",
            "affiliations": [
                "First Affiliated Hospital of Xiamen University"
            ]
        },
        {
            "id": "https://openalex.org/A2494508957",
            "name": "Naian Xiao",
            "affiliations": [
                "First Affiliated Hospital of Xiamen University"
            ]
        },
        {
            "id": "https://openalex.org/A2102420315",
            "name": "Hailong Li",
            "affiliations": [
                "Cincinnati Children's Hospital Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2097111700",
            "name": "Lili He",
            "affiliations": [
                "Cincinnati Children's Hospital Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2143171724",
            "name": "Qiyuan Li",
            "affiliations": [
                "First Affiliated Hospital of Xiamen University"
            ]
        },
        {
            "id": "https://openalex.org/A2102680316",
            "name": "Ting Wu",
            "affiliations": [
                "Jiangsu Province Hospital",
                "Nanjing University of Chinese Medicine"
            ]
        },
        {
            "id": "https://openalex.org/A2146830989",
            "name": "Xiaonan He",
            "affiliations": [
                "Capital Medical University",
                "Beijing Anzhen Hospital"
            ]
        },
        {
            "id": "https://openalex.org/A2128604055",
            "name": "Peizhi Chen",
            "affiliations": [
                "Xiamen University of Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2121456605",
            "name": "Duo CHEN",
            "affiliations": [
                "Nanjing University of Chinese Medicine"
            ]
        },
        {
            "id": "https://openalex.org/A2104627736",
            "name": "Jing Xiang",
            "affiliations": [
                "Cincinnati Children's Hospital Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2628264683",
            "name": "Xueping Peng",
            "affiliations": [
                "University of Technology Sydney"
            ]
        },
        {
            "id": "https://openalex.org/A2531374610",
            "name": "Jiayang Guo",
            "affiliations": [
                "Xiamen University",
                "First Affiliated Hospital of Xiamen University"
            ]
        },
        {
            "id": "https://openalex.org/A2494508957",
            "name": "Naian Xiao",
            "affiliations": [
                "First Affiliated Hospital of Xiamen University"
            ]
        },
        {
            "id": "https://openalex.org/A2102420315",
            "name": "Hailong Li",
            "affiliations": [
                "Cincinnati Children's Hospital Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2097111700",
            "name": "Lili He",
            "affiliations": [
                "Cincinnati Children's Hospital Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2143171724",
            "name": "Qiyuan Li",
            "affiliations": [
                "First Affiliated Hospital of Xiamen University",
                "Xiamen University"
            ]
        },
        {
            "id": "https://openalex.org/A2102680316",
            "name": "Ting Wu",
            "affiliations": [
                "Nanjing University of Chinese Medicine"
            ]
        },
        {
            "id": "https://openalex.org/A2146830989",
            "name": "Xiaonan He",
            "affiliations": [
                "Beijing Anzhen Hospital"
            ]
        },
        {
            "id": "https://openalex.org/A2128604055",
            "name": "Peizhi Chen",
            "affiliations": [
                "Xiamen University",
                "Xiamen University of Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2121456605",
            "name": "Duo CHEN",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2104627736",
            "name": "Jing Xiang",
            "affiliations": [
                "Cincinnati Children's Hospital Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2628264683",
            "name": "Xueping Peng",
            "affiliations": [
                "University of Technology Sydney",
                "Australian Institute of Physics",
                "Australian Institute of Business"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2736471100",
        "https://openalex.org/W3033146745",
        "https://openalex.org/W3132259035",
        "https://openalex.org/W3126944956",
        "https://openalex.org/W2804738787",
        "https://openalex.org/W6675634716",
        "https://openalex.org/W6687483927",
        "https://openalex.org/W2047297625",
        "https://openalex.org/W2526511911",
        "https://openalex.org/W4300629043",
        "https://openalex.org/W6769412140",
        "https://openalex.org/W2979747269",
        "https://openalex.org/W6783401557",
        "https://openalex.org/W6764679822",
        "https://openalex.org/W3045676091",
        "https://openalex.org/W3163537075",
        "https://openalex.org/W3035471470",
        "https://openalex.org/W3089168780",
        "https://openalex.org/W2071390615",
        "https://openalex.org/W2559799576",
        "https://openalex.org/W6767963107",
        "https://openalex.org/W6780064559",
        "https://openalex.org/W6782220583",
        "https://openalex.org/W2111242620",
        "https://openalex.org/W2107974789",
        "https://openalex.org/W2964189376",
        "https://openalex.org/W1493773489",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W2265970145",
        "https://openalex.org/W2942821150",
        "https://openalex.org/W1988111220",
        "https://openalex.org/W1844293057",
        "https://openalex.org/W3120755852",
        "https://openalex.org/W2055726526",
        "https://openalex.org/W2965277555",
        "https://openalex.org/W3133650345",
        "https://openalex.org/W2973281329",
        "https://openalex.org/W3091206105",
        "https://openalex.org/W2954731415",
        "https://openalex.org/W2104933073",
        "https://openalex.org/W3128252541",
        "https://openalex.org/W2194775991",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W3094502228",
        "https://openalex.org/W3172942063",
        "https://openalex.org/W3134761328",
        "https://openalex.org/W3016129867"
    ],
    "abstract": "High-frequency oscillations (HFOs), observed within 80–500 Hz of magnetoencephalography (MEG) data, are putative biomarkers to localize epileptogenic zones that are critical for the success of surgical epilepsy treatment. It is crucial to accurately detect HFOs for improving the surgical outcome of patients with epilepsy. However, in clinical practices, detecting HFOs in MEG signals mainly depends on visual inspection by clinicians, which is very time-consuming, labor-intensive, subjective, and error-prone. To accurately and automatically detect HFOs, machine learning approaches have been developed and have demonstrated the promising results of automated HFO detection. More recently, the transformer-based model has attracted wide attention and achieved state-of-the-art performance on many machine learning tasks. In this paper, we are investigating the suitability of transformer-based models on the detection of HFOs. Specifically, we propose a transformer-based HFO detection framework for biomedical MEG one-dimensional signal data. For signal classification, we develop a transformer-based HFO (TransHFO) classification model. Then, we investigate the relationship between depth of deep learning models and classification performance. The experimental results show that the proposed framework outperforms the state-of-the-art HFO classifiers, increasing classification accuracy by 7%. Furthermore, we find that shallow TransHFO ( <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" id=\"m1\"><mml:mo>&lt;</mml:mo></mml:math> 10 layers) outperforms deep TransHFO models (≥10 layers) on most data augmented factors.",
    "full_text": "Transformer-Based High-Frequency\nOscillation Signal Detection on\nMagnetoencephalography From\nEpileptic Patients\nJiayang Guo1, Naian Xiao2*, Hailong Li3, Lili He3, Qiyuan Li1, Ting Wu4, Xiaonan He5,\nPeizhi Chen6, Duo Chen7, Jing Xiang8 and Xueping Peng9*\n1Department of Hematology, The First Afﬁliated Hospital of Xiamen University and Institute of Hematology, School of Medicine,\nXiamen University, Xiamen, China,2Department of Neurology, The First Afﬁliated Hospital of Xiamen University, Xiamen, China,\n3Department of Radiology, Imaging Research Center, Cincinnati Children’s Hospital Medical Center, Cincinnati, OH,\nUnited States,4Department of Radiology, Jiangsu Province Hospital of Chinese Medicine, Afﬁliated Hospital of Nanjing University\nof Chinese Medicine, Nanjing, China,5Emergency Critical Care Center, Beijing Anzhen Hospital, Capital Medical University,\nBeijing, China,6College of Computer and Information Engineering, Xiamen University of Technology, Xiamen, China,7School of\nArtiﬁcial Intelligence and Information Technology, Nanjing University of Chinese Medicine, Nanjing, China,8Department of\nNeurology, The MEG Center, Cincinnati Children’s Hospital Medical Center, Cincinnati, OH, United States,9Australian AI Institute,\nFEIT, University of Technology Sydney, Sydney, NSW, Australia\nHigh-frequency oscillations (HFOs), observed within 80 –500 Hz of\nmagnetoencephalography (MEG) data, are putative biomarkers to localize\nepileptogenic zones that are critical for the success of surgical epilepsy treatment. It is\ncrucial to accurately detect HFOs for improving the surgical outcome of patients with\nepilepsy. However, in clinical practices, detecting HFOs in MEG signals mainly depends on\nvisual inspection by clinicians, which is very time-consuming, labor-intensive, subjective,\nand error-prone. To accurately and automatically detect HFOs, machine learning\napproaches have been developed and have demonstrated the promising results of\nautomated HFO detection. More recently, the transformer-based model has attracted\nwide attention and achieved state-of-the-art performance on many machine learning\ntasks. In this paper, we are investigating the suitability of transformer-based models on the\ndetection of HFOs. Speci ﬁcally, we propose a transformer-based HFO detection\nframework for biomedical MEG one-dimensional signal data. For signal classiﬁcation,\nwe develop a transformer-based HFO (TransHFO) classi ﬁcation model. Then, we\ninvestigate the relationship between depth of deep learning models and classiﬁcation\nperformance. The experimental results show that the proposed framework outperforms\nthe state-of-the-art HFO classiﬁers, increasing classiﬁcation accuracy by 7%. Furthermore,\nwe ﬁnd that shallow TransHFO (< 10 layers) outperforms deep TransHFO models (≥10\nlayers) on most data augmented factors.\nKeywords: magnetoencephalography, high-frequency oscillation, transformer, deep learning, epilepsy\nEdited by:\nXin Gao,\nKing Abdullah University of Science\nand Technology, Saudi Arabia\nReviewed by:\nDelong Yang,\nShenzhen Institutes of Advanced\nTechnology (CAS), China\nRj Wang,\nPCL, China\n*Correspondence:\nNaian Xiao\nwsxna@163.com\nXueping Peng\nxueping.peng@uts.edu.au\nSpecialty section:\nThis article was submitted to\nMolecular Diagnostics and\nTherapeutics,\na section of the journal\nFrontiers in Molecular Biosciences\nReceived: 26 November 2021\nAccepted: 19 January 2022\nPublished: 04 March 2022\nCitation:\nGuo J, Xiao N, Li H, He L, Li Q, Wu T,\nHe X, Chen P, Chen D, Xiang J and\nPeng X (2022) Transformer-Based\nHigh-Frequency Oscillation Signal\nDetection on\nMagnetoencephalography From\nEpileptic Patients.\nFront. Mol. Biosci. 9:822810.\ndoi: 10.3389/fmolb.2022.822810\nFrontiers in Molecular Biosciences | www.frontiersin.org March 2022 | Volume 9 | Article 8228101\nORIGINAL RESEARCH\npublished: 04 March 2022\ndoi: 10.3389/fmolb.2022.822810\n1 INTRODUCTION\nIt is estimated that about 1% of the population around the world\nis affected by epilepsy (Health Quality Ontario, 2012). Long-term\nfollow-up studies in epilepsy indicate that approximately 30% of\nepilepsy cases are intractable to medical therapy (Yang et al.,\n2021), but may beneﬁt from surgery (Ibrahim et al., 2012; Zhang\net al., 2019; Guo et al., 2021). A favorable surgical outcome\ndepends on many factors, one of which is the accurate\nidentiﬁcation of epileptogenic zones ( Rosenow and Lüders,\n2001). Magnetoencephalography (MEG) is a non-invasive\ntechnology for pre-operative workup prior to epilepsy surgery\n(Xiang et al., 2009), which help clinicians localize epileptogenic\nzones (Rampp et al., 2010; Niranjan et al., 2013). Recently, several\nstudies showed that high-frequency oscillations (HFOs), which\ncan be observed within 80– 500 Hz of MEG data, are putative\nbiomarkers to locate the epileptogenic tissue. It has the potential\nto improve the presurgical diagnosis and surgical outcome of\npatients with epilepsy (von Ellenrieder et al., 2016; Van Klink\net al., 2016; Papadelis et al., 2016).\nIn current clinical practices, machine learning methods are\nwidely used for clinical classi ﬁcation problems using one-\ndimensional biomedical signal data (e.g., MEG, EEG)\n(Fernandez-Blanco et al., 2020 ; Li et al., 2020 ; Maiorana,\n2020; Lombardi et al., 2021 ). Detecting HFOs in MEG\nsignals mainly depends on visual inspection by surgeons.\nSuch visual identi ﬁcation of HFOs is very time-consuming,\nlabor-intensive, subjective, an d error-prone due to the short\nduration and low amplitude of HFOs and the large volume of\nMEG signal data ( Zelmann et al., 2012 ). Thus, helping\nclinicians with HFO detection can be treated as a clinical\nclassiﬁcation problem. To detect HFOs accurately and\nautomatically, machine learni ng approaches have been used\n(Elahian et al., 2017; Guo et al., 2018; Weiss et al., 2019). Most\nexisting HFO detection models theﬁrst segment aﬁxed length\nof MEG signals from the whole MEG data, then treat these\nMEG signal segments as feature vectors. For example, one of\nthe earlier works on HFO detection models employed the fully\nconnected feed-forward network to automatically learn the\ndistribution of segmented MEG signals ( Guo et al., 2018 ).\nThese studies have demonstrated that machine learning\nmodels were able to achieve promising results on automatic\nidentiﬁcation of HFO signals.\nMore recently, a novel model architecture, called Transformer,\nhas attracted wide attention in natural language processing and\ncomputer vision (Vaswani et al., 2017; Zhai et al., 2021). The\nTransformer utilized a self-attention mechanism to learn an input\nfeature sequence and decide which parts of the sequence are\nimportant. It has outperformed peer models and achieved state-\nof-the-art performance on many machine learning tasks, such as\nlanguage translation (Vaswani et al., 2017\n), image classiﬁcation\n(Dosovitskiy et al., 2020), speech recognition (Kim et al., 2020),\ntime-series data processing ( Li et al., 2019 ), and healthcare\nanalytics (Peng et al., 2019 ; Peng et al., 2020 ; Peng et al.,\n2021). Due to the fact that MEG signals are inherently time-\nseries signal data, we are wondering whether the Transformer\nmodel is able to understand the time dependency embedded in\nthe MEG signals better than existing fully connected feed-forward\nnetwork-based models.\nIn this paper, we are investigating the suitability of the\nTransformer model on the detection of HFOs from MEG data.\nFurthermore, we are questioning what the preferred architecture\nof the Transformer-based deep learning model is for MEG signal\nclassiﬁcation tasks. We propose a Transformer-based HFO\ndetection framework designed for one-dimensional biomedical\nMEG signal data. Brie ﬂy, the framework includes signal\nsegmentation, virtual sample generation, signal classi ﬁcation,\nand signal labeling. Within this framework, we developed and\nvalidated a Transformer-based HFO (TransHFO) classiﬁcation\nmodel to distinguish HFO signals from normal signals. We\ndesigned experiments to investigate whether the TransHFO\nmodel is able to achieve robust and reliable performance on\nHFO classi ﬁcation. Furthermore, with the TransHFO\nclassiﬁcation framework, we set to conduct exploratory\nexperiments to test if the relationship between the depth of\nTransHFO models and classiﬁcation performance is positively\nmonotonic. Namely, we would investigate whether HFO\nclassiﬁcation performance would increase as the depth of\nTransHFO model increases. This would guide the transformer-\nbased model design on HFO classiﬁcation problems, as well as\nother similar tasks using one-dimensional biomedical signal data\n(e.g., MEG, EEG).\nTo summarize, our main contributions are as follows:\n We proposed a novel and effective transformer-based HFO\ndetection framework designed speci ﬁcally for the\npresurgical diagnosis of biomedical one-dimensional\nMEG signal data.\n We investigated through quantitative experiments\nwhether transformer-based deep learning models are\nable to achieve robust and reliable performance on\nHFO classiﬁcation task.\n We conducted exploratory experiments to examine the\nrelationship between the depth of transformer-based deep\nlearning models and the classiﬁcation performance, which\nwould result in principles and insights for future model\ndesign.\nThe remainder of this paper is organized as follows:Section 2\nbrieﬂy reviews the related work on MEG data.Section 3describes\nthe proposed detection framework. Section 4 presents the\nexperiments and results on the real-world MEG dataset, and\nSection 5concludes the paper by summarizing the research and\npresenting future directions.\n2 RELATED WORK\nIn this section, we brieﬂy reviewed existing works of machine\nlearning-based approaches for automated identiﬁcation of the\nepileptic HFOs and Transformer-based detector on clinical\napplications.\nMachine learning provides clinicians and surgeons with a\npossible opportunity for improving the performance of\nFrontiers in Molecular Biosciences | www.frontiersin.org March 2022 | Volume 9 | Article 8228102\nGuo et al. Transformer-Based HFO Signal Detection\ndetecting HFOs and reducing human interference.\nTraditional machine learning algorithms, such as logistic\nregression ( Elahian et al., 2017 ), have been used for the\nidenti ﬁcation of epileptogenic zones. Deep neural network-\nbased models also have been exploited to detect HFOs in MEG\ns i g n a ld a t a .T h i si n c l u d e so u rp r i o rw o r ku s i n ga na u t o -\nencoder-based SMO detector ( Guo et al., 2018). In another\nstudy, Weiss et al. (2019) discuss possible machine learning\nstrategies that can be applied to HFOs to better identify\nepileptogenic regions. It set to apply a virtual sample\ngeneration approach to increase the size of training\nsamples for the deep learning model. Here, we utilize an\nadaptive synthetic (ADASYN)-based virtual sample\ngeneration approach for our MEG dataset (He et al., 2008).\nMore recently, Transformer-based approaches are the current\nstate of the art in many clinical tasks, such as clinical text\nclassiﬁcation ( Gao et al., 2021 ) and predicting depression\n(Meng et al., 2021). The key component of the Transformer is\nthe multi-head attention mechanism, which can avoid\ninformation loss over time steps compared to recurrent\nstructures. Research has proposed the integration of attention\nmechanism and convolutional neural networks (CNN) to classify\ncategorized images from visual evoked MEG brain signals (Kim\net al., 2019). So far, these approaches have shown promising\nprediction accuracy, but some argue that the power of attention\nmechanism in a CNN is limited by the weaknesses of the CNN.\nVaswani et al. (2017) used a sole attention mechanism to\nconstruct a sequence-to-sequence model for a neural machine\ntranslation task that achieved a state-of-the-art quality score.\nAccording toShen et al. (2018), attention mechanism allows for\nmore ﬂexibility, and is more task/data-driven when modeling\ndependencies. Unlike sequential models, attention mechanism is\neasy to compute. Computation can also be signi ﬁcantly\naccelerated with distributed/parallel computing schemes.\nHowever, to the best of our knowledge, a model based entirely\non Transformer structure has not yet been designed for analysis\nof MEG data.\n3 TRANSFORMER-BASED HFO\nDETECTION FRAMEWORK\nThis section begins with introducing the overview of HFO\ndetection framework. Then, we described virtual sample\ngeneration. Next, the TransHFO classiﬁcation model with the\ndense layer and transformer model for biomedical MEG one-\ndimensional signal data is elaborated.\n3.1 Overview of HFO Detection Framework\nThe overview of transformer-based HFO detection framework is\ndescribed inFigure 1. Speciﬁcally, the framework includes signal\nsegmentation, virtual sample generation, signal classiﬁcation, and\nsignal labeling. We developed a TransHFO model for HFO signal\nclassiﬁcation. The framework contains a training phase and a\ntesting phase. During the training phase, given the gold standard\nof MEG signal segments with a certain duration (i.e., 1,000 ms),\nthe virtual sample generation method is used to augment the size\nof the HFOs and normal control (NC) signals. A TransHFO\nmodel is trained to distinguish HFOs from NC signals. During the\ntesting process, given a set of MEG data, the framework split the\ndata into a series of signal segments with a moving window into\nthe same length of training data. Then, the trained TransHFO\nmodel is used to classify the segments. The assigned labels can be\nvisualized by software such as the MEG processor (Xiang et al.,\n2015).\n3.2 Virtual Sample Generation\nTo increase the size of training samples for the deep learning\nmodel, a virtual sample generation approach has been applied.\nHere, an adaptive synthetic (ADASYN)-based virtual sample\ngeneration approach is utilized for our MEG dataset (He et al.,\n2008). ADASYN was originally proposed to perform over-\nsampling for imbalanced datasets. However, it has also been\napplied to increase sample size when the training samples of\nmachine learning models are insufﬁcient (Kawahara et al., 2017).\nThe ADASYN approachﬁrst calculates the degree of imbalance\nFIGURE 1 |The proposed Transformer-based HFO detection framework is designed speciﬁcally for the presurgical diagnosis of biomedical one-dimensional MEG\nsignal data. Brieﬂy, the HFO classiﬁcation framework includes signal segmentation, signal augmentation, TransHFO signal classiﬁcation, and signal labeling. This\nframework achieves more robust and reliable performance on HFO classiﬁcation than baseline models. Furthermore, weﬁnd that shallow TransHFO (< 10 layers)\noutperforms deep TransHFO (≥10 layers) on most data augmented factors, revealing the importance of human labeled data and the potential of deep-learning\nmethods for automatic diagnosis of medical signal.\nFrontiers in Molecular Biosciences | www.frontiersin.org March 2022 | Volume 9 | Article 8228103\nGuo et al. Transformer-Based HFO Signal Detection\nbetween minority and majority class samples. If the degree of\nimbalance is smaller than a preset threshold for maximum\ntolerated imbalance, it estimates the number of virtual samples\nto be generated from the minority class. For each sample in the\nminority class, this approach ﬁnds the k-nearest neighbors\n(KNN) based on Euclidean distance and calculates the density\ndistribution of the minority class for the given minor sample.\nEventually, it generates virtual samples for each minority sample\nbased on estimated sample size and density distribution.\nTo utilize the ADASYN as the virtual sample generation\nmethod for our balanced MEG dataset, we manually create an\nimbalanced dataset from our ground truth data. Speciﬁcally, both\nHFOs and normal control (NC) samples are separated into three\nbins, respectively. One bin of HFO samples and three bins of NC\nsamples are combined as an imbalanced dataset. The ADASYN is\nthen applied to generate virtual ripple samples for this temporary\nimbalanced dataset. Similarly, the ADASYN is utilized to\nsynthesize NC samples. This procedure is repeated until the\npre-deﬁned number of virtual samples is generated. By varying\ndifferent data augmented factors, we conducted exploratory\nexperiments to examine the relationship between the depth of\ndeep learning models and the classi ﬁcation performance,\nresulting in several principles and insights for future model\ndesign [t].\n3.3 TransHFO Classiﬁcation Model\nWe propose an HFO classi ﬁcation framework called the\n“Transformer-based HFO (TransHFO) ” classiﬁcation. The\narchitecture of TransHFO is shown in Figure 2 . The\nframework consists of a dropout layer, a stack ofN identical\nlayers, and two dense layers.\nEach layer in N stacked transformer has two sub-layers\n(Vaswani et al., 2017 ). The ﬁrst is a multi-head self-\nattention mechanism, and the second sub-layer is a feed-\nforward network. Residual connection ( He et al., 2016 )i s\nemployed around each of the two sub-layers, followed by\nlayer normalization (Ba et al., 2016). That is, the outputo of\neach layer is\no\ni /equals Norm(ReLU(sublayer(oi−1)+ oi−1)), (1)\nwhere i is theith layer in transformer blocks and sublayer (oi−1)i s\nthe function implemented by the layer itself.\nThe two dense layers are fully connected to change the number\nof units in the framework. The dense layer (lower) and layer\n(upper) are set with activation“ReLU”, and 128 and 10 units of\nthe output space, respectively. The third dense layer is“Sigmoid”\nin the framework with 1 unit of the output space and sigmoid\nactivation function.\nA standard cross-entropy loss is used as the training objective\nof TransHFO, deﬁned as\nL /equals− ∑\nk\ni/equals 1\nyi log(^yi), (2)\nwhere y is the one-hot target for medical outcome and^yi is the\nprobability of theith class given patient journey.\n3.3.1 Dense Layer\nDense layer can be thought of exploring the importance of each\nsignal within a sequence and compresses the sequence of\nsignals into a low-dimension vector representation. For\nsimplicity, we take the dropout output s as an example.\nFormally, it is written as:\no /equals wTσ(w(1)s + b(1))+ b, (3)\nwhere σ is ReLU function and w, w(1), b(1), o are learnable\nparameters.\n3.3.2 Transformer\nTo learn relationships between patients’MEG, theTransformer\nmodule is proposed to capture the inherent dependencies, which\nis calculated as follows:\nv /equals Transformer(o) (4)\nThe Transformer is identical to that of BERT (Vaswani et al.,\n2017) and (Devlin et al., 2018), which has two sub-layers. Theﬁrst\nis a multi-head attention mechanism (explained below), and the\nsecond is a position-wise addition and normalization layer. A\nresidual connection (He et al., 2016) is employed around each of\nthe two sub-layers, followed by layer normalization (Ba et al.,\n2016).\nThe multi-head attention mechanism relies on self-attention,\nwhere all of the keys, values, and queries come from the same\nplace. The self-attention operates on a queryQ, a keyK, and a\nvalue V:\nFIGURE 2 |Transformer-based HFO (TransHFO) classiﬁcation model.\nFrontiers in Molecular Biosciences | www.frontiersin.org March 2022 | Volume 9 | Article 8228104\nGuo et al. Transformer-Based HFO Signal Detection\nAttention(Q, K, V)/equals softmax QKT\n/radicaltpext/radicaltpext\nd\n√() V (5)\nwhere Q, K, andV are n × d matrices, n denotes the number of\ndiagnoses in a visit in a patient record, and d denotes the\nembedding dimension.\nThe multi-head attention mechanism obtainsh (i.e., one per\nhead) different representations of (Q, K, V), computes self-\nattention for each representation, and concatenates the results.\nThis can be expressed as follows:\nheadi /equals Attention(QWQ\ni , KW K\ni , VWV\ni ) (6)\nMultiHead(Q, K, V)/equals Concat(head1, ... , headh)WO (7)\nwhere the projections are parameter matrices WQ\ni ∈ Rd×dk ,\nWK\ni ∈ Rd×dk , WV\ni ∈ Rd×dv and WO ∈ Rhdv×d, dk = dv = d/h.\n4 EXPERIMENTS\nWe conducted experiments based on a real-world MEG dataset to\ncompare the performance of our proposed method TransHFO\nwith several state-of-the-art methods in terms of the classiﬁcation\nperformance. We also evaluated the impact of the data\naugmentation on the baseline methods and our TransHFO\nmodel. Furthermore, we explored the inﬂuence of the network\ndepth on TransHFO model.\n4.1 Dataset Description\nMEG data were obtained from 20 clinical patients (age: 6– 60 years,\nmean age 32; 10 female patients and 10 male patients) affected by\nlocalization-related epilepsy, which is characterized by partial\nseizures arising from one part of the brain, and were\nretrospectively studied. The data were acquired under approval\nfrom an Institutional Review Board. MEG recordings were\nperformed in a magnetically shielded room (MSR) using a 306-\nchannel, whole-head MEG system (VectorView, Elekta Neuromag,\nHelsinki, Finland). The sampling rate of MEG data was set to\n2,400 Hz, and approximately 60 min of MEG data were recorded\nfor each patient. MEG data were preliminarily analyzed at a sensor\nlevel with MEG Processor (Xiang et al., 2015; Li and Yin, 2020).\nThe spike was visually identiﬁed in waveform with a band-pass\nﬁlter of 1– 70 Hz, while HFOs were analyzed with a band-passﬁlter\nof 80– 500 Hz. For the model evaluation purpose, the clinical\nepileptologists selected HFOs and NC signal segments based on\nintracranial recordings (iEEG) for these patients. By comparing the\nMEG sources and the brain areas generating HFOs, the clinical\nepileptologists marked HFOs. The duration of each signal segment\nwhich contains a series of 2000 signal time points is 1 s. A total of\n202 signal segments (101 HFO samples and 101 NC samples) were\ncomposed as a gold standard dataset for model evaluation.\n4.2 Experiment Setup\n4.2.1 Model Evaluation\nWe conducted a comprehensive evaluation in this study by\nemploying the proposed TransHFO to classify the HFO\nsignals from normal controls. A k-fold cross-validation was\ndesigned in our experiments. The whole gold standard dataset\nwould be divided intok portions. In each repeated iteration, we\nrandomly used one portion of the data as testing data, and applied\nthe rest (k-1) portions of the data as training data. This process\nwould be repeatedk times until all data have been tested once.\nThe classiﬁcation performance was evaluated by aggregating all\niterations.\n4.2.2 Baseline Methods\nWe choose three baseline methods: Logistic regression, which is\ntraditional machine learning model; SMO (Guo et al., 2018),\nwhich is the latest deep learning model used in MEG data; and the\nResDen model, which is the simpliﬁed version of our proposed\nTransHFO model.\n Logistic regression (LR): The maximum-likelihood\nestimation algorithm was used to optimize the coefﬁcient\nof the logistic regression model.\n SMO: We implemented 4-layer SSAE-based neural\nnetworks with an input layer, three hidden layers, and an\noutput layer. The number of nodes in three hidden layers\nwas set to 30. A loss function with L2 regularization and\nsparsity regularization terms were utilized. Hyper parameter\nsparsity proportion was selected from [0.1, 0.2, 0.3, 0.4, 0.5]\nand L2 regularization weight was decided from [0.1, 0.2, 0.3,\n0.4, 0.5]. The learning rate was set to 0.01. The training is\nstopped if the model returns the same loss on validation data\nin three consecutive epochs.\n ResDen: ResDen follows the same framework as TransHFO,\nbut Multi-Head Attention is replaced with a simple dense\nlayer with“ReLU” activation and having the same number\nof units as that of Dense-1 in the TransHFO model.\n4.2.3 Evaluation Metrics\nWe calculated true positive (TP), false positive (FP), true negative\n(TN), and false negative (FN) for the classiﬁcation by comparing\nthe classiﬁed labels and gold-standard labels. Then, we calculated\naccuracy, sensitivity, precision, and F-score by:\nAccuracy /equals\nTP + TN\nTP + TN + FP + FN\nPrecision /equals TP\nTP + FP\nSensitivity /equals TP\nTP + FN\nSpecificity /equals TN\nTN + FP\nF − score /equals 2× precision × sensitivity\nprecision + sensitivity\n(8)\n4.2.4 Implementation Details\nWe implement all the approaches with Tensorﬂow 2.0, except LR.\nFor training models, we use RMSprop with a mini-batch of 32\npatients and 10 epochs. The drop-out rate is 0.1 for all the\napproaches. Virtual samples are generated by ADASYN, and\nthe size of samples is the scalars (1, 5, 10, 20, and 40) times the size\nFrontiers in Molecular Biosciences | www.frontiersin.org March 2022 | Volume 9 | Article 8228105\nGuo et al. Transformer-Based HFO Signal Detection\nof the original data. The number of the stackedN identical layers\nvaries from 1 to 40 in the TransHFO framework.\n4.3 Results\n4.3.1 HFO Performance Comparison Using Different\nModels\nIn this section, weﬁrst compared HFO classiﬁcation performance\nof the proposed framework with the-state-of-art models. As\nshown in Table 1 , we set up two scenarios: with data\naugmentation and without data augmentation. The upper part\nof Table 1illustrated HFO performance using only gold standard\ndata without any data augmentation scheme. In our experiments,\ntraditional machine learning model LR had the lowest\nperformance compared to other three neural network-based\nmodels. The proposed model achieved the best performance\nwith an accuracy of 0.9580, a precision of 0.9929, a sensitivity\nof 0.9289, a speciﬁcity of 0.9917, and an F-score of 0.9593. It\nachieved better performance than our previously developed SMO\ndetector. Compared to ResDen, our model had higher accuracy,\nprecision, speciﬁcity, and F-score, while both our model and\nResDen reached 0.9289 on sensitivity.\nFor the data augmentation scenario, the proposed model\nhad an accuracy of 0.9615, a precision of 1.0, a sensitivity of\n0.9286, a speciﬁcity of 1.0, and an F-score of 0.9630. This is\nagain the best among four compared models. Also, the\nproposed model and ResDen also had better performance\nthan the LR model and SMO detector, demonstrating the\nsuperior strength of deep learning models. Compared to\nResDen, our model achieved better performance on\naccuracy, precision, speci ﬁcity, and F-score. We believe\nthat this is due to the multi-head attention mechanism\nadded into the model. Furthermore, by comparing the\nupper part and lower part of the table, we noted that,\nexcept LR, these three neural network-based models all had\nimproved performance with data augmentation, illustrating\nthe effectiveness of data augmentation on neural networks.\nFor SMO and ResDen, the accuracy increased 4% and 2%,\nrespectively. However, the proposed TransHFO model only\nhad a slight increase on accuracy (0.5%). The effect of data\naugmentation is very limited.\n4.3.2 Impact of Data Augmentation\nFigure 3 listed the HFO classi ﬁcation performance of the\nproposed TransHFO model as well as the other three models,\ntested on dataset augmented by 0- to 40-fold. The LR model has\nno performance change using different augmented data. For\nTransHFO, the best accuracy and F-score were 0.9615 and\n0.963, respectively, at an augmentation factor of 10. For both\nResDen and SMO, the best performance was obtained by using an\naugmentation factor of 5. A clear trend showed that all neural\nnetwork-based models achieved improved performance with an\naugmentation factor of 5 or 10. However, the incremental\nchanges of performance on accuracy and F-score were limited.\nCombined with previous experiment, we believe that data\naugmentation is a technique for increasing sample data so as\nto avoid model overﬁtting. This will prevent the model achieved\noverﬁtted low performance. On the other hand, data\naugmentation may not be effective to increase the\nperformance of HFO classiﬁcation. Considering the training\ntime cost, an augmentation factor that is able to increase the\nsample size to 1,000– 2,000 may be sufﬁcient for training a model\nwith residual links and attention mechanism.\n4.3.3 Impact of Network Depth of TransHFO\nFor the proposed TransHFO, we tested the HFO classiﬁcation\nperformance using different a rchitecture and augmentation\nfactors. As displayed in Figure 4 , we listed the accuracy,\nF-score, precision, sensitivity, and speci ﬁcity, respectively.\nFirst, a general trend of these ﬁgures showed that the HFO\nclassiﬁcation performance decreased dramatically when the\nmodel had more than 10 layers. If we use 10 layers as a\ncutoff between shallow TransHFO ( < 10 layers) and deep\nTransHFO ( ≥10 layers), the results demonstrated that the\nshallow TransHFO achieved better HFO classi ﬁcation\nperformance than deep TransHFO. For the one-dimensional\nbiomedical MEG signals, the more layers of the model may not\nincrease the performance. This observation needs further\nconﬁrmation by using additional experiments with more bio-\nsignals.\nSecond, we noted that when the training data were augmented\nby a factor of 10, the proposed TransHFO achieved the best\nTABLE 1 |Performance comparison of different models. The TransHFO achieved better performance than LR, SMO, and ResDen models in both no data augmentation and\ndata augmentation scenarios.\nModel Accuracy Precision Sensitivity Speci ﬁcity F-score\nLR 0.807 7 0.909 1 0.714 3 0.916 7 0.800 0\nSMO 0.846 2 0.916 7 0.785 7 0.916 7 0.846 2\nResDen 0.923 1 0.928 6 0.928 6 0.916 7 0.928 6\nTransHFO 0.958 0 0.992 9 0.928 9 0.991 7 0.959 3\nLR (Aug) 0.807 7 0.909 1 0.714 3 0.916 7 0.800 0\nSMO(Aug) 0.884 6 0.923 1 0.857 1 0.916 7 0.888 9\nResDen (Aug) 0.948 7 0.952 4 0.952 4 0.944 4 0.952 4\nTransHFO(Aug) 0.961 5 1.000 0 0.928 6 1.000 0 0.963 0\nBold values represents the best performance of different models in the corresponding Evaluation Metrics\nFrontiers in Molecular Biosciences | www.frontiersin.org March 2022 | Volume 9 | Article 8228106\nGuo et al. Transformer-Based HFO Signal Detection\nperformance. However, as mentioned in the previous section, the\nperformance of HFO classiﬁcation was quite similar for shallow\nTransHFO using very different augmentation factors from 0 to\n40. On the other side, the performance of HFO classiﬁcation had\nvery large variations for deep TransHFO using different\naugmented training data. The results suggest that for bio-\nsignal MEG signals, a small augmentation factor and a shallow\nTransHFO model would be ef ﬁcient to achieve a desirable\nperformance. Additional data augmentation or deeper\narchitecture may not improve the performance of HFO\nclassiﬁcation.\n4.4 Discussion\nHFO classiﬁcation task is a crucial step towards surgical treatment on\nepilepsy patients. With the ground truth training dataset, the\nTransHFO detector achieves an accuracy of 96.15% on the HFO\nclassiﬁcation task. This sheds light on the feasibility of using\ntransformer-based networks techniques. Meanwhile, weﬁnd that\nshallow TransHFO (< 10 layers) outperforms deep TransHFO\nmodels (≥10 layers) on most HFO classi ﬁcation tasks with\ndifferent data augmented factors. This ﬁn d i n go f f e r su st h e\npossibility to use interpretable and shallow models based on\nappropriately expressing the structure of MEG data for precise\nHFO detection.\nThis study mainly focuses on the shallow transformer-\nbased model that can achieve better performance than the\ndeep learning model in HFO detection tasks. Supported by the\nresults, the TransHFO detector beneﬁts from both the virtual\nsample generation technique and the multi-head attention\nmechanism. However, according to Figure 4 ,t h es h a l l o w\nTransHFO achieved better performance than deep\nTransHFO in HFO classi ﬁcation tasks with different data\naugmented factors. For the HFO detection task, more layers\nof the model may decrease the performance. The strengths of\nshallow TransHFO over deep TransHFO in the HFO\nclassi ﬁcation tasks may partially be attributed to the nature\nof the dataset. The dataset is asmall dataset that consists of\none-dimensional biomedical MEG signals from one\ninstitution. For such a dataset, the virtual sample generation\ntechnique may not augment enough higher-level features of\nMEG signals that can be lea rned by deep TransHFO.\nAdditionally, our observation needs further con ﬁrmation by\nusing additional experiments with more bio-signals from\nexternal data sites.\nFIGURE 3 |Performance of different models with varying augmentation factors from 0 to 40. The models had better performance with augmentation factors 5, 10,\nand 20. (A) Accuracy. (B) F-score. (C) Precision. (D) Sensitivity. (E) Speciﬁcity.\nFrontiers in Molecular Biosciences | www.frontiersin.org March 2022 | Volume 9 | Article 8228107\nGuo et al. Transformer-Based HFO Signal Detection\nThere are several limitations in this study. First, we have a\nsmall cohort of epilepsy patients. We only collect 202 samples\nfrom 20 patients. Although the virtual sample generation\napproach mitigates the insuf ﬁcient issue in a way, a larger\ncohort possibly provides better biological varieties. Second,\naccording to clinical routine, we pre-deﬁned the duration of\nMEG signal segments as 1 s. Additional information for HFO\nclassiﬁcation may be revealed by other signal duration (e.g.,\n0.5– 2 s). Third, this paper treats the MEG segments from\ndifferent channels equally and independently. However, there\nare complex timing and co-occurrence relationships among\nsegments. Mining and utilizing these relationships may\nimprove the effectiveness of H FO detection. Finally, only\ninternal validation was conducted on a set of data from one\ninstitution. Additional datasets from external data sites are\nrequired to test the generalizability of our detector.\n5 CONCLUSION\nIn this paper, we presented a novel Transformer-based HFO\ndetection framework designed speciﬁcally for biomedical MEG\none-dimensional signal data. The proposed HFO detection\nframework employs Transformer models with a self-attention\nmechanism and virtual sample generation technique. Compared\nwith the previously developed HFO classiﬁers, the proposed\nframework increased classiﬁcation accuracy by 7%. With this\nnew framework, we designed experiments to investigate whether\ndeep TransHFO models are able to achieve robust and reliable\nperformance on HFO classi ﬁcation. Furthermore, with the\nproposed classi ﬁcation framework, we set to conduct\nexploratory experiments to discover whether the relationship\nbetween the depth of TransHFO models and classi ﬁcation\nperformance is positively monotonic. Based on exploratory\nFIGURE 4 |Performance of different augmentation factors (0, 1, 5, 10, 20, and 40) with varyingN, the number of identical layers in TransHFO framework, from 1 to\n40. (A) Accuracy. (B) F-score. (C) Precision. (D) Sensitivity. (E) Speciﬁcity.\nFrontiers in Molecular Biosciences | www.frontiersin.org March 2022 | Volume 9 | Article 8228108\nGuo et al. Transformer-Based HFO Signal Detection\nexperiments, we ﬁnd that shallow TransHFO ( < 10 layers)\noutperforms deep TransHFO ( ≥10 layers) on most data\naugmented factors. The experimental results demonstrate that\nour proposed framework is a promising computer-aided\ndiagnosis tool for clinical usage. Several future directions are\nclariﬁed as follows. Theﬁrst is to extend our framework into a\nmulti-label classiﬁer with a function to recognize additional\npatterns or sub-patterns (e.g., spike, ripple and fast ripple) in\nMEG. The second direction includes external validation and\nclinical applications of the proposed framework on other\nneuromagnetic data such as iEEG. The ﬁnal direction is to\ndesign an interpretable and shallow network based on\nappropriately expressing the structure of MEG data for precise\nHFO detection.\nDATA AVAILABILITY STATEMENT\nThe data analyzed in this study is subject to the following licenses/\nrestrictions: The raw data supporting the conclusions of this\narticle will be made available by the authors, without undue\nreservation. Requests to access these datasets should be directed\nto corresponding author. Requests to access these datasets should\nbe directed to wsxna@163.com.\nETHICS STATEMENT\nThe studies involving human participants were reviewed and\napproved by Cincinnati Children ’s Hospital Medical Center,\nCincinnati, United States. The patients/participants provided\ntheir written informed consent to participate in this study.\nAUTHOR CONTRIBUTIONS\nJ G ,N X ,H L ,L H ,J X ,X H ,a n dX Pc o n c e i v e da n dd e s i g n e dt h e\ne x p e r i m e n t s .J G ,N X ,P C ,D C ,T W ,a n dX Pp e r f o r m e dt h e\nexperiments. JG, HL, NX, QL, and XP wrote the manuscript. All\nauthors contributed to the article and approved the submitted\nversion.\nFUNDING\nThis work is supported by the Natural Science Foundation of\nFujian Province of China (No. 2019J01573), US National\nInstitutes of Health (R01-EB029944 and R01-EB030582), and\nthe National Natural Science Foundation of China (Nos.\n82172022, 61801413, and 62006100).\nREFERENCES\nBa, J. L., Kiros, J. R., and Hinton, G. E. (2016).Layer Normalization. arXiv preprint\narXiv:1607.06450.\nDevlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2018).Bert: Pre-training of\nDeep Bidirectional Transformers for Language Understanding. arXiv preprint\narXiv:1810.04805.\nDosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner,\nT., et al. (2020). An Image Is worth 16x16 Words: Transformers for Image\nRecognition at Scale. arXiv preprint arXiv:2010.11929.\nElahian, B., Yeasin, M., Mudigoudar, B., Wheless, J. W., and Babajani-Feremi, A.\n(2017). Identifying Seizure Onset Zone from Electrocorticographic Recordings:\na Machine Learning Approach Based on Phase Locking Value.Seizure 51,\n35– 42. doi:10.1016/j.seizure.2017.07.010\nFernandez-Blanco, E., Rivero, D., and Pazos, A. (2020). Eeg Signal Processing with\nSeparable Convolutional Neural Network for Automatic Scoring of Sleeping\nStage. Neurocomputing 410, 220– 228. doi:10.1016/j.neucom.2020.05.085\nGao, S., Alawad, M., Young, M. T., Gounley, J., Schaefferkoetter, N., Yoon, H.-J.,\net al. (2021). Limitations of Transformers on Clinical Text Classiﬁcation. IEEE\nJ. Biomed. Health Inform.25, 3596– 3607. doi:10.1109/jbhi.2021.3062322\nGuo, J., Li, H., Sun, X., Qi, L., Qiao, H., Pan, Y., et al. (2021). Detecting High\nFrequency Oscillations for Stereoelectroencephalography in Epilepsy via\nHypergraph Learning. IEEE Trans. Neural Syst. Rehabil. Eng. 29, 587– 596.\ndoi:10.1109/tnsre.2021.3056685\nGuo, J., Yang, K., Liu, H., Yin, C., Xiang, J., Li, H., et al. (2018). A Stacked Sparse\nAutoencoder-Based Detector for Automatic Identiﬁcation of Neuromagnetic\nHigh Frequency Oscillations in Epilepsy. IEEE Trans. Med. Imaging 37,\n2474– 2482. doi:10.1109/tmi.2018.2836965\nHe, H., Bai, Y., Garcia, E. A., and Li, S. (2008).“Adasyn: Adaptive Synthetic\nSampling Approach for Imbalanced Learning,” in 2008 IEEE International\nJoint Conference on Neural Networks (IEEE World Congress on\nComputational Intelligence), Hong Kong, China, June 1 – 8, 2008,\n1322– 1328. doi:10.1109/ijcnn.2008.4633969\nHe, K., Zhang, X., Ren, S., and Sun, J. (2016).“Deep Residual Learning for Image\nRecognition,” in 2016 IEEE Conference on Computer Vision and Pattern\nRecognition (CVPR), Los Vegas, NV, June 27– 30, 2016, 770– 778. doi:10.1109/\ncvpr.2016.90\nHealth Quality Ontario (2012). Epilepsy Surgery: an Evidence Summary. Ont\nHealth Technol. Assess. Ser.12, 1– 28.\nIbrahim, G. M., Barry, B. W., Fallah, A., Snead, O. C., Drake, J. M., Rutka, J. T., et al.\n(2012). Inequities in Access to Pediatric Epilepsy Surgery: a Bioethical\nFramework. Foc 32, E2. doi:10.3171/2011.12.focus11315\nKawahara, J., Brown, C. J., Miller, S. P., Booth, B. G., Chau, V., Grunau, R. E., et al.\n(2017). Brainnetcnn: Convolutional Neural Networks for Brain Networks;\ntowards Predicting Neurodevelopment. NeuroImage 146, 1038– 1049. doi:10.\n1016/j.neuroimage.2016.09.046\nKim, J., El-Khamy, M., and Lee, J. (2020). “T-Gsa: Transformer with\nGaussian-Weighted Self-Attention for Speech Enhancement, ” in\nICASSP 2020-2020 IEEE International Conference on Acoustics,\nSpeech and Signal Processing (ICASSP), Barcelona, Spain, May 4 – 8,\n2020. (IEEE), 6649 – 6653. doi:10.1109/icassp40776.2020.9053591\nKim, Y., Jang, S., Won, K., and Jun, S. C. (2019). Canet: A Channel Attention\nNetwork to Determine Informative Multi-Channel for Image Classiﬁcation\nfrom Brain Signals.Annu. Int. Conf. IEEE Eng. Med. Biol. Soc.2019, 680– 683.\ndoi:10.1109/EMBC.2019.8857517\nLi, H., and Yin, Z. (2020).“Attention, Suggestion and Annotation: A Deep Active\nLearning Framework for Biomedical Image Segmentation,” in International\nConference on Medical Image Computing and Computer-Assisted\nIntervention, Lima, Peru, October 4 – 8, 2020. (Berlin: Springer), 3 – 13.\ndoi:10.1007/978-3-030-59710-8_1\nLi, S., Jin, X., Xuan, Y., Zhou, X., Chen, W., Wang, Y.-X., et al. (2019). Enhancing\nthe Locality and Breaking the Memory Bottleneck of Transformer on Time\nSeries Forecasting. Adv. Neural Inf. Process. Syst.32, 5243– 5253.\nLi, Y., Yang, H., Li, J., Chen, D., and Du, M. (2020). Eeg-based Intention\nRecognition with Deep Recurrent-Convolution Neural Network:\nPerformance and Channel Selection by Grad-Cam. Neurocomputing 415,\n225– 233. doi:10.1016/j.neucom.2020.07.072\nLombardi, F., Shriki, O., Herrmann, H. J., and de Arcangelis, L. (2021). Long-range\nTemporal Correlations in the Broadband Resting State Activity of the Human\nBrain Revealed by Neuronal Avalanches.Neurocomputing 461, 657– 666. doi:10.\n1016/j.neucom.2020.05.126\nFrontiers in Molecular Biosciences | www.frontiersin.org March 2022 | Volume 9 | Article 8228109\nGuo et al. Transformer-Based HFO Signal Detection\nMaiorana, E. (2020). Deep Learning for Eeg-Based Biometric Recognition.\nNeurocomputing 410, 374– 386. doi:10.1016/j.neucom.2020.06.009\nMeng, Y., Speier, W. F., Ong, M. K., and Arnold, C. (2021). Bidirectional\nRepresentation Learning from Transformers Using Multimodal Electronic\nHealth Record Data to Predict Depression.IEEE J. Biomed. Health Inform.\n25, 3121– 3129. doi:10.1109/jbhi.2021.3063721\nN i r a n j a n ,A . ,L a i n g ,E .J .C . ,L a g h a r i ,F .J . ,R i c h a r d s o n ,R .M . ,a n dL u n s f o r d ,L .\nD. (2013). Preoperative Magnetoencephalographic Sensory Cortex\nMapping. Stereotact Funct. Neurosurg. 91, 314 – 322. doi:10.1159/\n000350019\nPapadelis, C., Tamilia, E., Stufﬂebeam, S., Grant, P. E., Madsen, J. R., Pearl, P. L.,\net al. (2016). Interictal High Frequency Oscillations Detected with\nSimultaneous Magnetoencephalogr aphy and Electroencephalography as\nBiomarker of Pediatric Epilepsy. JoVE 118 , e54883. doi:10.3791/54883\nPeng, X., Long, G., Pan, S., Jiang, J., and Niu, Z. (2019).“Attentive Dual Embedding\nfor Understanding Medical Concepts in Electronic Health Records,” in 2019\nInternational Joint Conference on Neural Networks (IJCNN), Budapest,\nHungary, July 14– 19, 2019, 1– 8. doi:10.1109/ijcnn.2019.8852429\nPeng, X., Long, G., Shen, T., Wang, S., and Jiang, J. (2021). “Self-attention\nEnhanced Patient Journey Understanding in Healthcare System, ” in\nECML-PKDD 2020 Workshop, Ghent, Belgium, September 14 – 18, 2020\n(Berlin: Springer), 719 – 735. doi:10.1007/978-3-030-67664-3_43\nPeng, X., Long, G., Shen, T., Wang, S., Jiang, J., and Zhang, C. (2020).“Bitenet:\nBidirectional Temporal Encoder Network to Predict Medical Outcomes,” in\nIEEE International Conference on Data Mining (ICDM), Sorrento, Italy,\nNovember 17– 20, 2020, (IEEE), 412– 421. doi:10.1109/icdm50108.2020.00050\nRampp, S., Kaltenhäuser, M., Weigel, D., Buchfelder, M., Blümcke, I., Dörﬂer, A.,\net al. (2010). Meg Correlates of Epileptic High Gamma Oscillations in Invasive\nEeg. Epilepsia 51, 1638– 1642. doi:10.1111/j.1528-1167.2010.02579.x\nRosenow, F., and Lüders, H. (2001). Presurgical Evaluation of Epilepsy.Brain 124,\n1683– 1700. doi:10.1093/brain/124.9.1683\nShen, T., Zhou, T., Long, G., Jiang, J., Pan, S., and Zhang, C. (2018).“Disan:\nDirectional Self-Attention Network for Rnn/cnn-free Language\nUnderstanding,” in AAAI conference, Long Beach, CA, February 2– 7, 2018, 32.\nVan Klink, N., Hillebrand, A., and Zijlmans, M. (2016). Identiﬁcation of Epileptic\nHigh Frequency Oscillations in the Time Domain by Using Meg Beamformer-\nBased Virtual Sensors.Clin. Neurophysiol. 127, 197– 208. doi:10.1016/j.clinph.\n2015.06.008\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., et al.\n(2017). “Attention Is All You Need,” in NeurIPS proceeding, Las Vegas, NV,\nDecember 4– 9, 2017, 5998\n– 6008.\nvon Ellenrieder, N., Pellegrino, G., Hedrich, T., Gotman, J., Lina, J.-M., Grova, C.,\net al. (2016). Detection and Magnetic Source Imaging of Fast Oscillations (40-\n160 Hz) Recorded with Magnetoencephalography in Focal Epilepsy Patients.\nBrain Topogr 29, 218– 231. doi:10.1007/s10548-016-0471-9\nWeiss, S. A., Waldman, Z., Raimondo, F., Slezak, D., Donmez, M., Worrell, G., et al.\n(2019). Localizing Epileptogenic Regions Using High-Frequency Oscillations\nand Machine Learning.Biomar. Med. 13 (5), 409– 418.\nXiang, J., Korman, A., Samarasinghe, K. M., Wang, X., Zhang, F., Qiao, H., et al.\n(2015). Volumetric Imaging of Brain Activity with Spatial-Frequency Decoding\nof Neuromagnetic Signals. J. Neurosci. Methods 239, 114– 128. doi:10.1016/j.\njneumeth.2014.10.007\nXiang, J., Liu, Y., Wang, Y., Kirtman, E. G., Kotecha, R., Chen, Y., et al. (2009).\nFrequency and Spatial Characteristics of High-Frequency Neuromagnetic\nSignals in Childhood Epilepsy. Epileptic Disord. 11, 113– 125. doi:10.1684/\nepd.2009.0253\nYang, Y., Sarkis, R., El Atrache, R., Loddenkemper, T., and Meisel, C. (2021).\nVideo-based Detection of Generalized Tonic-Clonic Seizures Using Deep\nLearning. IEEE J. Biomed. Health Inform 25, 2997– 3008. doi:10.1109/jbhi.\n2021.3049649\nZelmann, R., Mari, F., Jacobs, J., Zijlmans, M., Dubeau, F., and Gotman, J. (2012). A\nComparison between Detectors of High Frequency Oscillations. Clin.\nNeurophysiol. 123, 106– 116. doi:10.1016/j.clinph.2011.06.006\nZhai, X., Kolesnikov, A., Houlsby, N., and Beyer, L. (2021). Scaling Vision\nTransformers. arXiv preprint arXiv:2106.04560.\nZhang, Y., Guo, Y., Yang, P., Chen, W., and Lo, B. (2019). Epilepsy Seizure Prediction on\nEeg Using Common Spatial Pattern andC o n v o l u t i o n a lN e u r a lN e t w o r k .IEEE\nJ. Biomed. Health Inform.24, 465– 474. doi:10.1109/JBHI.2019.2933046\nConﬂict of Interest:The authors declare that the research was conducted in the\nabsence of any commercial orﬁnancial relationships that could be construed as a\npotential conﬂict of interest.\nPublisher’s Note:All claims expressed in this article are solely those of the authors\nand do not necessarily represent those of their afﬁliated organizations, or those of\nthe publisher, the editors, and the reviewers. Any product that may be evaluated in\nthis article, or claim that may be made by its manufacturer, is not guaranteed or\nendorsed by the publisher.\nCopyright © 2022 Guo, Xiao, Li, He, Li, Wu, He, Chen, Chen, Xiang and Peng. This\nis an open-access article distributed under the terms of the Creative Commons\nAttribution License (CC BY). The use, distribution or reproduction in other forums is\npermitted, provided the original author(s) and the copyright owner(s) are credited\nand that the original publication in this journal is cited, in accordance with accepted\nacademic practice. No use, distribution or reproduction is permitted which does not\ncomply with these terms.\nFrontiers in Molecular Biosciences | www.frontiersin.org March 2022 | Volume 9 | Article 82281010\nGuo et al. Transformer-Based HFO Signal Detection"
}