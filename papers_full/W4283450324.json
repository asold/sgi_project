{
  "title": "Theory-Grounded Measurement of U.S. Social Stereotypes in English Language Models",
  "url": "https://openalex.org/W4283450324",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A1991904507",
      "name": "Yang Cao",
      "affiliations": [
        "University of Maryland, College Park"
      ]
    },
    {
      "id": "https://openalex.org/A2225222309",
      "name": "Anna Sotnikova",
      "affiliations": [
        "University of Maryland, College Park"
      ]
    },
    {
      "id": "https://openalex.org/A3151569556",
      "name": "Hal Daumé Iii",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2010729824",
      "name": "Rachel Rudinger",
      "affiliations": [
        "University of Maryland, College Park"
      ]
    },
    {
      "id": "https://openalex.org/A2116783507",
      "name": "Linda Zou",
      "affiliations": [
        "University of Maryland, College Park"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2102085635",
    "https://openalex.org/W3174356895",
    "https://openalex.org/W3185212449",
    "https://openalex.org/W2132585345",
    "https://openalex.org/W2123814310",
    "https://openalex.org/W3117534689",
    "https://openalex.org/W3022118589",
    "https://openalex.org/W2613175112",
    "https://openalex.org/W4401837159",
    "https://openalex.org/W2053070609",
    "https://openalex.org/W2167595980",
    "https://openalex.org/W2899689163",
    "https://openalex.org/W4210984115",
    "https://openalex.org/W4242386715",
    "https://openalex.org/W3168584517",
    "https://openalex.org/W3041804225",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W4308264370",
    "https://openalex.org/W2387324665",
    "https://openalex.org/W3087250496",
    "https://openalex.org/W2950018712",
    "https://openalex.org/W2949590328",
    "https://openalex.org/W2117986441",
    "https://openalex.org/W4221157363",
    "https://openalex.org/W1494175060",
    "https://openalex.org/W4252665401",
    "https://openalex.org/W2972413484",
    "https://openalex.org/W3105882417",
    "https://openalex.org/W2005061283",
    "https://openalex.org/W2963078909",
    "https://openalex.org/W4249292692",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2567992152",
    "https://openalex.org/W4301906562",
    "https://openalex.org/W2031615586",
    "https://openalex.org/W3172415559",
    "https://openalex.org/W3172917028",
    "https://openalex.org/W2893425640",
    "https://openalex.org/W4255416805",
    "https://openalex.org/W3034937117",
    "https://openalex.org/W2009551222",
    "https://openalex.org/W3176477796"
  ],
  "abstract": "Yang Cao, Anna Sotnikova, Hal Daumé III, Rachel Rudinger, Linda Zou. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2022.",
  "full_text": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics:\nHuman Language Technologies, pages 1276 - 1295\nJuly 10-15, 2022 ©2022 Association for Computational Linguistics\nTheory-Grounded Measurement of U.S. Social Stereotypes\nin English Language Models\nYang Trista Cao∗1, Anna Sotnikova ∗1 Hal Daumé III1,2 Rachel Rudinger1 Linda Zou1\n1University of Maryland, College Park 2Microsoft Research\n{ycao95, asotniko, hal3, rudinger, lxzou}@umd.edu\nAbstract\nNLP models trained on text have been shown\nto reproduce human stereotypes, which can\nmagnify harms to marginalized groups when\nsystems are deployed at scale. We adapt the\nAgency-Belief-Communion (ABC) stereotype\nmodel of Koch et al. (2016) from social psy-\nchology as a framework for the systematic\nstudy and discovery of stereotypic group-trait\nassociations in language models (LMs). We\nintroduce the sensitivity test (SeT) for measur-\ning stereotypical associations from language\nmodels. To evaluate SeT and other measures\nusing the ABC model, we collect group-trait\njudgments from U.S.-based subjects to com-\npare with English LM stereotypes. Finally, we\nextend this framework to measure LM stereo-\ntyping of intersectional identities.\n1 Introduction\nStereotypes are abstract and over-generalized pic-\ntures in people’s minds that capture attributes\nabout groups of people in the complex social\nworld (Lippmann, 1965). They influence peo-\nple’s thoughts and behaviors, and allow people\nto make predictions beyond their personal expe-\nrience or information given (Bruner et al., 1957;\nWheeler and Petty, 2001). Stereotypes are also\nentwined with the production of prejudice, discrim-\nination, and in-group favoritism (Stangor, 2014;\nJackson, 2011). A long line of research in social\npsychology has established models of generic di-\nmensions that estimate people’s stereotypes of so-\ncial groups (Koch et al., 2016; Fiske et al., 2002,\ni.a.). We build on the Agency Beliefs Commu-\nnion (ABC) model, which measures stereotypes\ntoward a social group with respect to 16 traits\nin three dimensions: Agency/Socioeconomic Suc-\ncess, Conservative–Progressive Beliefs, and Com-\n∗Equal contribution.\nFigure 1: Crowdsourced analysis of the social group\n“man” under the ABC model (Koch et al., 2016). Colors:\npurple=agency, red=belief, green=communion.\nmunion (§2); an analysis of the group“man” across\n32 traits (16 opposing dyads) is shown in Figure 1.\nPre-trained language models (LMs) encode cor-\nrelations between social groups and traits, like\nassociating the group “Muslim” with the trait\nthreatening, or “man” with confident (e.g., Ben-\nder et al., 2021; Nozza et al., 2021; Hovy and Yang,\n2021). We conduct a systematic study of social\nstereotypes in contextualized English masked LMs,\ngrounded in group-trait associations from the ABC\nmodel. To capture the group-trait associations in\nthe LM, we first assess two previously proposed\nword association tests and also propose a new mea-\nsurement: the sensitivity test (SeT) (§3).\nTo evaluate the degree to which two LMs—\nBERT (Devlin et al., 2019) and RoBERTa (Liu\net al., 2019)—align with human stereotype judg-\nments, we design a human study for collecting\ngroup-trait judgments (§4). We show that our mea-\nsure, SeT, best aligns with human judgements on\ngroup-trait associations and find that, in general,\nthe association from language models have moder-\nate alignment with human judgements.\nFinally, with the best-aligned association mea-\nsurement, we extend the ABC approach to study\n1276\nAgency\npowerless ↔ powerful\nBeliefs\nCommunion\nuntrustworthy ↔ trustworthy\nlow status ↔ high status religious ↔ science-oriented dishonest ↔ sincere\ndominated ↔ dominating conventional ↔ alternative cold ↔ warm\npoor ↔ wealthy conservative ↔ liberal benevolent ↔ threatening\nunconfident ↔ confident traditional ↔ modern repellent ↔ likable\nunassertive ↔ competitive egotistic ↔ altruistic\nTable 1: List of stereotype dimensions and corresponding traits in the ABC model (Koch et al., 2016).\nLM stereotypes on intersectional groups (§ 5.2).\nDue largely to the difficulty of extending current ap-\nproaches for measuring stereotypes in LMs to large\nnumbers of groups, most current approaches only\nstudy isolated groups, despite the fact that people’s\nsocial identities are multifaceted (Ghavami and Pe-\nplau, 2013). Because our approach is generalizable\nto unstudied groups, we take a step towards explor-\ning stereotypes of intersectional identities, finding\nsome correspondence between model behavior and\nthe literature on intersectional stereotypes.\n2 Background and Related Work\nPeople’s impressions of the world and the actions\nthey take are guided by their stereotypes. To\nsystematize this observation, the field of social\npsychology has proposed models of stereotypes,\nincluding traits that can coordinate social behaviors\nto serve as fundamental dimensions of stereotyping.\nSome models are designed to focus on social\nevaluation towards individual persons (Abele\nand Wojciszke, 2014), ingroup members (Elle-\nmers, 2017; Yzerbyt, 2018), or a small set of\noutgroups (Fiske et al., 2002); the Agency Beliefs\nCommunion (ABC) model—whose traits are de-\nsigned to distinguish groups—is suited for a larger\nset of U.S. social groups (Abele et al., 2020). The\nABC model takes a data-driven strategy to select\na set of traits by eliminating those that are less\neffective in capturing stereotypes. The list contains\n16 pairs, where each pair represents two polarities\n(see Table 1), categorized into three dimensions:\nagency/socioeconomic success, conservative-\nprogressive beliefs, and communion/warmth.\nOurs is far from the first work to assess stereo-\ntypes in language models, and has both advan-\ntages and disadvantages compared to previous ap-\nproaches (see Table 2). Past work has generally\ntaken one of two approaches. The first approach\ntests systems with hand-constructed templates like\n“The [group] is □”, where [group] ranges over\nsocial groups (e.g., “woman” or “Hispanic”), and\n□represents a “masked word” and ranges over oc-\ncupations (“a professor” or “a nurse”) (e.g., Boluk-\nMeasurement\nGeneralizes\nGrounded\nExhaustive\nNatural\nSpecificity\nDebiasing (Bolukbasi et al.) ✓ ✓\nCrowS-Pairs (Nangia et al.) ✓ ✓ ✓\nStereoset (Nadeem et al.) ✓ ✓ ✓\nS. Bias Frames (Sap et al.) ✓ ✓✓✓\nCEAT (Guo and Caliskan) ✓ ✓ ✓✓\nThis Work ✓ ✓ ✓✓\nTable 2: Comparison with previous work: Generalizes\ndenotes approaches that naturally extend to previously\nunconsidered groups; Grounded approaches are those\nthat are grounded in social science theory; Exhaustive-\nness refers to how well the traits cover the space of\npossible stereotypes; Naturalness is the degree to which\nthe text input to the LM is natural (we consider naturally\noccurring web scraped data as “very natural” and crowd-\nsourced sentences as “somewhat natural.”). Specificity\nindicates whether the stereotype is specific or abstract.\nbasi et al., 2016; May et al., 2019) or associa-\ntions drawn from implicit association tests (IAT)\n(e.g., pleasant/unpleasant words or career/family-\nrelated words) (e.g., Caliskan et al., 2017; Guo\nand Caliskan, 2021). In Table 2 we refer to these\nas “unnatural” prompts. The second approach col-\nlects more natural sentences containing stereotypes,\neither by web crawling with crowdworkers anno-\ntations for social bias (Sap et al., 2019) or by hav-\ning crowdworkers directly write stereotyping sen-\ntences (Nangia et al., 2020; Nadeem et al., 2020).\nIn our work, we take the first approach with traits\nfrom the ABC model, using prompts. The advan-\ntage of this approach is that the templates and the\ntraits are completely controlled and are easy to ex-\ntend to other social groups. The second approach\nis harder to control, which also leads to significant\nannotation challenges (Blodgett et al., 2021). Us-\ning natural sentences limits generalizability, as it\nrequires a unique collection of prompts (and em-\nbedded traits) for each social group; in contrast, the\nprompt-based approach easily generalizes to any\nplausible group, especially when based on a theo-\nretically grounded framework like ABC or IAT.\nAn advantage of our work is that the ABC traits\n1277\nDomain Groups\nGender/\nsexuality\nman, woman, non-binary, trans, cis, gay,\nlesbian\nRace/\nethnicity\nBlack, White, Hispanic, Asian,\nNative American\nReligion\nJewish, Muslim, Christian, Buddhist,\nMormon, Catholic, Amish, Protestant,\nAtheist, Hindu\nSocio-\neconomic\nwealthy, working class, immigrant, veteran,\nunemployed, refugee, doctor, mechanic\nAge teenager, elderly\nDisability\nstatus\nblind, autistic, neurodivergent, Deaf,\nperson with a disability\nPolitics Democrat, Republican\nNationality\nMexican, Chinese, Russian, Indian, Irish,\nCuban, Italian, Japanese, German, French,\nBritish, Jamaican, American, Filipino\nTable 3: Social groups domains and corresponding so-\ncial groups used for the model experiments and human\nexperiments. Single groups for human experiments are\nhighlighted with italic font style.\nare more exhaustive in stereotype coverage with\nverification from social psychological experiments.\nThe ABC model covers three dimensions with 16\ntraits, which are consensual, spontaneous, and have\nbeen tested using expansive range of social groups\n(Koch et al., 2021). They used a carefully designed\ndata-driven approach to gather people’s fundamen-\ntal dimensions of social perceptions with as little\nsampling bias as possible. Thus the resulted 16\ntraits cover most stereotypes.\nNevertheless, the main trade-off of our approach\nis that the testing data are not as natural and specific\nas other approaches. Although we carefully pick\nand adjust the templates and the form of the social\ngroup terms so that the testing sentences are gram-\nmatically correct, they are likely not representative\nof sentences seen in the real world or in the training\ndata of the language models. Further, while our ap-\nproach has the benefit of near-exhaustive coverage\nof potential stereotypes, this comes at a cost: the\ntraits we consider are much more high level (e.g.,\n“repellent”) than more fine-grained stereotypes col-\nlected by other means (e.g., the angry Black woman\nstereotype (Collins, 2002))—this approach there-\nfore trades coverage for specificity.\n3 Measuring Stereotypes in LMs\nOur goal is to measure stereotypes in (masked)\nLMs, and compare them to stereotypes elicited\nfrom people. 2 In §4 we describe our approach for\neliciting human judgments of group-trait affinities;\n2Both the code and the dataset, along with a datasheet (Ge-\nbru et al., 2018), are available under a MIT licence at:\nhttps://github.com/TristaCao/U.S_Stereotypes.\nhere we describe how we measure these in LMs.\nPrevious work has proposed various ways to mea-\nsure word associations in LMs, including increased\nlog probability score (ILPS) and contextualized em-\nbedding association test (CEAT), both of which we\nsummarize below. Finally, we present a new mea-\nsurement which we call the Sensitivity Test (SeT),\nwhich adapts concepts from active learning to the\ntask of measuring a LM’s associations.\n3.1 Measurements of Word Associations\nIncreased Log Probability Score (ILPS) quanti-\nfies word associations in language models through\nmasked word probabilities. It calculates the associ-\nation score with a pre-defined template, “[Group]\nare □.” (Kurita et al., 2019), where □is a masked\ntoken. For example, given a group “Asian” and a\ntrait smart, P(“Asian”,smart) measures the prob-\nability of smart given “Asians” by filling in the\ntemplate. Since this probability is affected by the\nprior probability of smart, ILPS normalizes this\nprobability by the “prior” probability of the trait\ngiven a masked group, as below:\nILPS(g,t) = log P(□= t | g are □.)\nP(□2 = t | □1 are □2.)\nIntuitively, ILPS measures how much each group\nraises the likelihood of a trait filling in the tem-\nplate. One can easily show that this equivalent to\nthe weight of evidence of the trait in favor of the\nhypothesis that the group is the target: s(g,t) =\nwoe(g : t |template) (Wod, 1985).\nContextualized Embedding Association Test\n(CEAT) estimates word associations with word\nembedding distances (Guo and Caliskan, 2021) .\nIntuitively, CEAT measures whether some groups\nare closer to certain traits in a latent vector space.\nGiven two sets of target words defining groups\nX,Y (e.g. Xmale = {“man”, “father”, ... },\nYfemale = {“woman”, “mother”, ...}) and two sets\nof polar traits A,B (e.g. Apleasant = {love, peace,\n...}, Bpleasant = {evil, nasty, ... }), CEAT com-\nputes the effect sizes of the difference between X\nand Y being closer to Athan Band corresponding\np-values. Since contextualized word representa-\ntions are affected by the contexts around the word,\nfor each word in the four word sets, CEAT ran-\ndomly samples 1000 sentences from Reddit, in\nwhich the word appears, and uses these to approxi-\n1278\nSingular Plural\nThe/That/A [group] is □. Most/Many/All [group] are □. / [Group] are □.\nDeclarative Interrogative\n[Group] are □. Why are [group] □?\nNon-adverbial Adverbial\n[Group] are □. [Group] are very/so/mostly □.\nFact Belief\n[Group] are □. I/We/Everyone/People believe/expect/think/know(s) that[group] are □.\nFact Social Expectation\n[Group] are □. [Group] are supposed to be/should be/are seen as/ought to be/are expected to be □.\nGroup-first Trait-first\n[Group] are □. The □people are [group].\nNon-comparative Comparative\n[Group] are □. [Group] are more likely to be □than others.\nTable 4: Template Variations.\nmate the true effect size as below:\nCEAT(A,B,X,Y ) =\nˆE\ng∼X\ns(g,A,B)− ˆE\ng∼Y\ns(g,A,B)\nˆS\ng∼X∪Y\ns(g,A,B)\ns(g,A,B ) = ˆE\nt∼A\ncos(⃗g,⃗t) − ˆE\nt∼B\ncos(⃗g,⃗t)\nˆE (resp. ˆS) is the empirical expectation (resp. stan-\ndard deviation), and ⃗x denotes the embedding of x.\nIn our setting, since we care about social bias\namong multiple groups rather than the difference\nbetween two groups, we modify the CEAT to cal-\nculate the effect size of the distance difference be-\ntween g with Aand Bfor each group as below:\nCEAT(g,A,B ) =\nˆE\nt∼A\ncos(⃗g,⃗t) − ˆE\nt∼B\ncos(⃗g,⃗t)\nˆS\nt∼A∪B\ncos(⃗g,⃗t)\nSensitivity Test (SeT) is a new approach we pro-\npose to measure word association for social bias\nin language models, inspired by ideas from active\nlearning (Beygelzimer et al., 2008). The intuition\nof SeT is that even though a model assigns the same\nprobability to two different words, the robustness\nof those two probabilities may be different. For ex-\nample, both p(competent|“Blind people are □. ”)\nand p(kind|“Men are □”) might be low. However,\nthe language model may well not have seen many\nexamples with blind people, as opposed to the pre-\nsumably very large number of examples of men. In\nthis case, a small number of examples may be suf-\nficient to alter the model’s predictions about blind\npeople, while a larger number would be required\nfor men. SeT captures the model’s confidence in\na prediction by measuring how much the model\nweights would have to change in order to change\nthat prediction. Specifically, SeT computes the min-\nimal change to the last-layer of the language model\nso that a given trait becomes the highest probability\ntrait (over the full vocabulary).\nFor example, consider the template “The\n[group] is □.” with the group “woman” and\nthe trait incompetent. Let ℓℓℓ be the logits at □\nwhen the input is “The woman is □.”, and let t\nbe the index of incompetent in ℓℓℓ (so that ℓt =\np(incompetent |context)). Let h be the last hid-\nden layer before the logits, and let A be the matrix\nof the last linear layer so that ℓℓℓ = Ah. SeT com-\nputes the minimal distance between A and some\nother matrix A′so that t is the top word among the\nnew logits ℓℓℓ′= A′h. Formally:\nSeT(g,t) = log ∆(A,hg,t)\n∆(A,h□,t)\nwhere hg is the penultimate layer on input g\nA is the matrix before the logits\n∆(A,h,t) = min\nA′\n∥A′−A∥2\n2\ns.t. (A′h)t ≥(A′h)t′+ γ, ∀t′̸= t\nfor a fixed margin γ >0, which we set to 1. SeT\nreturns the negative distanceas measure of the asso-\nciation between the corresponding group and trait,\nnormalized by a prior akin to ILPS. This optimiza-\ntion problem does not (to our knowledge) admit\na closed form solution; we solve it iteratively us-\ning the column squishing algorithm (Bittorf et al.,\n2012; Daumé and Kumar, 2017).\n3.2 Implementation details\nWe test the above measurements on both BERT and\nRoBERTa pretrained large models from an open-\nsource HuggingFace3 library.\n3https://huggingface.co/models\n1279\nSocial groups. Table 3 lists all the individual so-\ncial groups we cover in this work. We manually\nconstruct the list by combining and picking groups\nfrom the list of social groups from Sotnikova et al.\n(2021) and Koch et al. (2016) and also adding so-\ncial groups we think are stereotyped in U.S. culture.\nTraits. We use the 32 adjectives of the 16 traits\nfrom the ABC model (Table 1). For each traits, we\ncalculate the score of its left-side adjective from\nits right-side adjective: Spowerless-powerful(g) =\nS(g,powerful)−S(g,powerless), where Sis one\nof the scores from §3.1.4\nTemplates. ILPS and SeT both require templates\nin calculating scores. We thus carefully construct\na list of templates (Table 4) that covers multiple\ngrammatical and semantic variations, inspired by\nwork investigating harmful search automatic sug-\ngestions (Hazen et al., 2020). We find that differ-\nent model structure requires different templates in\norder to bring up stereotypes that correlate with\nhuman data. See §5 for evidence.\nSubwords. Due to the nature of BERT and\nRoBERTa’s tokenizers, some of the adjectives are\ndivided into multiple subwords. This is problem-\natic because all the measurements compute their\nscores at token level. Neither ILPS nor CEAT deals\nwith subwords directly: in their released imple-\nmentations, they either take the first or the last\nsub-token of the word. To remedy this, we adjust\nthe ILPS measurement (denoted as ILPS⋆) to prop-\nerly compute the probability of traits in context\nusing the chain rule across subwords. For SeT, we\ncalculate the sensitivity score for each subword\nindividually and take the maximum SeT score as\nthe SeT score for the word, which effectively com-\nputes a lower-bound on how much the model pa-\nrameters would need to change. We did not modify\nCEAT’s measurement as it is not clear what is the\nbest way to compute comparable word embeddings\nfor words that consist of multiple subwords.\n4 Human Study\nIn the previous section, we describe how we com-\npute associations between groups and traits in lan-\n4In preliminary experiments, when calculating the score\nfor each adjective, we considered including 1-3 additional\nadjectives by averaging their scores to improve robustness and\nmitigate ambiguity. The full list is in Appendix Table A7.\nHowever, we found that this did not improve correlations, so\nwe reverted to using the 32 adjectives from the ABC model.\nguage models.5 In this section, we assess stereo-\ntypes of social groups through groups-trait asso-\nciation, like in Figure 1. We adopt this approach\nbecause it is widely used to evaluate group stereo-\ntypes in social psychology field (Fiske et al., 2002;\nKoch et al., 2016). It also aligns with Lippmann\n(1965)’s theory of stereotypes that they are abstract\npictures in people’s head. We broadly follow pro-\ncedures from previous social psychology papers to\ncollect human evaluation on social groups.\nSurvey Design. We recruit participants from Pro-\nlific6. Each participant is paid $2.00 to rate 5 so-\ncial groups on 16 pairs of traits and on average\nparticipants spend about 10 minutes on the sur-\nvey. This results in a pay of $12.00 per hour.\nMaryland’s current minimum wage is $12.20 7.\nFirst, participants read the consent form, and\nif they agree to participate in the study, they\nsee the survey’s instructions. For each social\ngroup, participants read \"As viewed by Ameri-\ncan society, (while my own opinions may dif-\nfer), how [e.g., powerless, dominant, poor]\nversus [e.g., powerful, dominated, wealthy]\nare <group>?\" They then rate each trait with a 0-\n100 slider scale where two sides are the two dimen-\nsions of the trait (e.g. powerless and powerful).\nEach annotated group is shown on a separate page,\nand participants cannot go back to previous pages.\nTo avoid social-desirability bias, we explicitly write\nin the instruction that“we are not interested in your\npersonal beliefs, but rather how you think people\nin America view these groups. ”\nParticipant Demographics. At the end of the\nsurvey we collect participants’ demographic in-\nformation, including gender, race, age, education\nlevel, type of living area, etc. Our participants rep-\nresent 26 states, with 63.3% from California, New\nYork, Texas, or Florida; the gender breakdown is\n48.2% male, 49.6% female, and 2.2% genderqueer,\nagender, or questioning; and skew young, with over\n96% at most 40 years old; and with racial demo-\ngraphics that approximately match the U.S. census.\nFor more details on demographics, see Appendix E.\nQuality Assurance. Ensuring annotation qual-\nity in a highly subjective task is a challenge, and\ncommon approaches in NLP like having questions\nwhere we “know” the answer as tests, measuring\n5Approved by our institutional IRB, #1724519-1.\n6https://www.prolific.co/\n7https://www.minimum-wage.org/maryland\n1280\ninterannotator agreement, and calibrating reviewers\nagainst each other (Paun et al., 2018) do not make\nsense here. Yet, it is still important to ensure the an-\nnotation quality. After much iteration, we include\nthree test questions, and warn the participants at\nthe beginning that there are test questions.\n1. After the first group, participants must name the\ngroup they just scored.\n2. After the second, participants must list one trait\nthey just marked high and one marked low.\n3. The fifth (final) group is a repetition of one of\nthe four groups they previously scored.\nWe discard annotations with incorrect answers to ei-\nther of the first two questions. For the third test, we\ncompute intra-annotator (self) agreement and dis-\ncard annotations with accuracy-to-self lower than\n80%. For each group we collect20 annotations that\npass our quality threshold. In total, we collected\nannotations from 247 participants, with 133 pass-\ning the quality tests (suggesting that having such\ntests is important). The 114 annotations that did\nnot pass tests were excluded from our dataset, but\nall 247 participants were paid.\nSocial groups and traits. The social groups we\nused for the human study are highlighted in Table 3.\nThis table contains only single groups used for the\nmodel § 3 and human experiments. We collect\nannotations for 25 social groups within 5 domains,\nacross all 16 pairs of traits.\n5 Results\nIn this section we present results on correlations be-\ntween human and model stereotypes for individual\ngroups, comparing across different measurements,\nincluding our proposed measurement, SeT (§5.1).\nNext, we analyze how model scores change for in-\ntersectional social groups. We consider several pos-\nsible factors that may influence the score changes\nsuch as identity order, some domain domination,\nand consider emergent traits (§5.2).\n5.1 Correlation on Individual Groups\nBefore we answer the question of how language\nmodel stereotype scores align with human stereo-\ntypes across the measurements introduced in §3,\nwe first run a pilot experiment to select the best\ntemplate(s) for each measurement-model pair from\nthe set of templates in Table 4 (except for CEAT,\nwhich does not require templates). We randomly\npicked four social groups (Asian, Black, Hispanic,\nimmigrant) and five annotations from each group\nfor the pilot. Since our goal is to inspect the\nalignment between human and model stereotypes,\nwe take the averaged score of the five annotations\nas “ground truth” and select templates that give the\ncorrelation score according to Kendall τ. We limit\nthe selection to at most two templates to avoid\noverfitting on the pilot data, selected to maximize\ncorrelation for each measurement-model pair.\nThe selected templates and corresponding cor-\nrelation scores are shown in appendix (Table 5);\nthe score range for weak correlation is 0.10 - 0.19,\nmoderate 0.20 - 0.29, and strong 0.30 and above\n(Botsch, 2011). For a fixed LM, the best templates\ntend to be similar across all measures: RoBERTa\ntends to achieve highest correlation with templates\nlike “That [group] is [trait].” while for BERT\nthe preferred templates tend to be “All [group] are\n[trait].” or “[Group] should be [trait].”\nGiven the best templates for each measurement-\nmodel pair, we measure to what degree language\nmodel stereotypes are aligned with human stereo-\ntypes with all annotations on 25 social groups. To\nquantify alignment, we both calculate the Kendall\nrank correlation coefficient (Kendall’s τ) and the\nPrecision at 3 (P@3). The former indicates the\ncorrelation between model and human scores on\ngroup-trait associations in terms of the number of\nswaps required to get the same order. The latter\nindicates the percentage of the model’s top stereo-\ntypes which accord with human’s judgements. For\nP@3, we also calculate at both the group level and\noverall with all groups. For each group, we com-\npute its P@3 score by taking the average of the\nP@3 scores with the top 3 traits (top at one polar-\nity) and the score with the bottom 3 (top at the other\npolarity) because each trait has two polar adjectives\nand the group-trait score is calculated with the dif-\nference of the two polarities. To calculate the P@3\nscores, we binarize the human group-trait scores\nat a threshold of 50. The overall P@3 score is the\naverage of the groups’ individual P@3 scores.\nThe overall scores are in Table 6. We see that\nin general that RoBERTa contains group-trait as-\nsociations that are more similar to human judge-\nments than does BERT. Additionally, we see that\nboth ILPS ⋆ and SeT have higher P@3 scores\nthan CEAT and ILPS. The RoBERTa model with\nthe SeT measurement approach yields outputs are\nthe most aligned with human’s judgements, with\nRoBERTa/ILPS⋆ a close second. From its scores,\nwe see that model’s group-trait associations have\n1281\nRoBERTa BERT\nMeasure τ Template(s) τ Template(s)\nILPS 0.280 That [group] is [trait]. 0.215 All [group] are [trait].\n[Group] should be [trait].\nILPS⋆ 0.258 All [group] are [trait].\nThat [group] is [trait]. 0.123 We expect that[group] are [trait].\n[Group] should be [trait].\nSeT 0.253 That [group] is [trait]. 0.214 All [group] are [trait].\n[Group] should be [trait].\nTable 5: Best two templates for each measurement-model pair and corresponding correlations. Some have only one\ntemplate because there is no combination of two templates that give higher correlation score than this one template.\nCEAT ILPS ILPS ⋆ SeT\nRoBERTa BERT RoBERTa BERT RoBERTa BERT RoBERTa BERT\nKendall’s τ 0.019 0.111 † 0.169† 0.094† 0.175† 0.015 0.199† 0.116\nPrecision at 3 0.500 0.587 0.620 0.533 0.653 0.560 0.653 0.613\nTable 6: Overall alignment scores with human annotations. The highest scores are bold for each row. For correlation\nscores, we mark scores where the p-value is <0.05 with †.\nmoderate correlation with human’s judgements.\nMoreover, in general, two out of the three top\nranked group-trait associations from the model\nagree with human data. See Table A19 for the over-\nall scores of test groups only, where the four pilot\ngroups are excluded, and Appendix B for group\nlevel alignment scores.\n5.2 Intersectional Groups in LMs\nBackground. Intersectionality is a core concept\nin Black feminism, introduced in the Combahee\nRiver Collective Statement in 1977 (1977; 1983),\nconsidering the ways in which feminist theory and\nantiracism need to combine: “Because the intersec-\ntional experience is greater than the sum of racism\nand sexism, any analysis that does not take intersec-\ntionality into account cannot sufficiently address\nthe particular manner in which Black women are\nsubordinated.” The concept was applied in law by\nCrenshaw (1989) to analyze the ways in which U.S.\nantidiscrimination law fails Black women.\nThe concept of intersectionality has broadened\nand, while its boundaries remain contested (e.g.,\nBrowne and Misra, 2003), there are a number of\ncore principles that are central (Steinbugler et al.,\n2006; Zinn and Dill, 1996): (1) social categories\nand hierarchies are historically contingent, (2) the\nexperience at an intersection is more than the sum\nof its parts (Collins, 2002; King, 1988), (3) in-\ntersections create both oppression and opportu-\nnity (Bonilla-Silva, 1997), (4) individuals may ex-\nperience both advantage and disadvantage as a re-\nsult of intersectionality, and (5) these hierarchies\nimpact social structure and social interaction.\nGoals and Research Questions. We aim to un-\nderstand whether we can measure evidence of inter-\nsectional behavior in language models with respect\nto stereotyping. In particular, we are interested in\nquestions surrounding how language models stereo-\ntype people who simultaneously belong to multiple\nsocial groups. We will only use the term “inter-\nsectionality” when specifically considering cases\nwhere (per (3) above) the resulting experience (in\nthis case, stereotyping) is more than the sum of\nits parts. For example, common U.S. stereotypes\nfor Black women are as “welfare queens” (which\nmay show up as low agency in our traits), while\ncommon stereotypes for Black men is as “criminal”\n(which may show up as low communion) (hooks,\n1992; Collins, 2002). To limit our scope, we will\nonly consider pairs of social groups (e.g., cis men),\nand will refer to the the groups that make up a pair\nas the component identities (e.g., cis, or men). We\naim to answer the following research questions:\n1. When presented with a paired identity, is the\nlanguage model sensitive to the order in which\nthe component identities appear?\n2. When paired, do certain social categories domi-\nnate others in a language model’s predictions?\n3. Can the language model detect stereotypes that\nbelong to an intersectional group (but not to\neither of the components that make up the pair)?\nTo answer these questions, we use the SeT measure-\nment with the RoBERTa model (the best perform-\ning pair on the single-group experiments) to com-\npute group-trait associations on our paired groups,\nwhich are combinations of all the single groups\nin Table 3. We manually omit the groups that do\n1282\nnot logically exist (e.g. “cis non-binary person”,\n“teenage elderly person”) or are grammatically awk-\nward (e.g. “doctor elderly person”, “immigrant\nblind person”). Note we include both orders of the\nsingle groups in the paired groups when possible\n(e.g. “Catholic teenager” and “teenage Catholic\nperson”). We then conduct the analysis by com-\nputing the correlation between groups’ list of trait\nscores with Kendall’s τ.\nQ1: Identity Order. Given an paired group with\ntwo identities, the language model may not be able\nto capture both of the identities and may predict\nstereotypes based only on one of the components.\nIn fact, the average correlation score between a\npaired group and the most correlated of its compo-\nnents is 0.56, which is moderately high. We thus\ncalculate the correlation of trait scores between the\npaired group and both its first and second com-\nponent identities (when both orders are possible).\nIn addition, we calculate the correlation of paired\ngroups with reversed identity order (e.g. “Asian\nteenager” and “teenage Asian person”). The aver-\nage correlation score between a paired group and\nits first component is 0.43; the correlation score\nto its second component is 0.46, which are quite\nclose. Further, the average correlation score of in-\ntersectional groups with reversed identity is 0.69,\nwhich is moderately high. Taken together, these\nresults indicate that (a) many paired groups have\nsimilar group-trait association scores with one of\ntheir component identities alone; (b) the order does\nnot matter significantly, but the language model\ntends to focus slightly more on the second compo-\nnent. The implication of this is that we can expect\nthat the language model may be able to capture\nintersectional stereotypes.\nQ2: Dominant Domains. Stryker (1980) sug-\ngests that people tend to identify themselves with\ntheir race/ethnicity identity before other identities,\nthough this is contested and, in some cases, thought\nto be antithetical to the idea of intersectionality\n(e.g., Collins, 2002). Prompted by this debate, we\nask if there is a hierarchy of the domains that lan-\nguage model picks up on for paired groups. To\nanswer this question, for each identity domain pair,\nwe compute the average correlation score between\nthe paired groups with each of its two component\nidentities, and take the difference of the averaged\ncorrelation scores of the two domains. For each\ndomain, we count the domains it dominates (i.e.\nhas score difference ≥0.1) and is dominated by.\nThese results show that age and political stance\nare dominant domains, which is expected as iden-\ntities within these two domains have strong char-\nacteristics that may overwhelm domains they are\npaired with. On the other end, race and nationality\nare, generally, dominated domains. It is surprising\nthat the race domain is majorly dominated, con-\ntrasting documented literature in human behavior.\nThe full results are shown in Appendix Table A8\nas well as detailed scores Table A9.\nQ3: Emergent Intersectional Stereotypes. Fi-\nnally, we look into emergent stereotypes of paired\ngroups, with the goal of finding intersectional be-\nhavior in the language model. To detect intersec-\ntional stereotypes, we need to operationalize the\nnotion of the whole being greater than its parts.\nFor a fixed paired group g = (g1,g2) (e.g., “trans\nDemocrats”), and a given trait t (e.g., warm), we\ncompute S(g,t)−max{S(g1,t),S(g2,t)}, where\nSis the score from the language model, capturing\nwhether this trait is more associated with the paired\ngroup than the maximum of its association with\nthe component identities. (We consider also the\nreverse, where we look for scores much less than\nthe min.) We might hope to find some well attested\nintersectional identities from the literature, such\nas “Black women” have an attitude (low com-\nmunion) and “White men” are privileged (high\nagency) (Ghavami and Peplau, 2013).\nThe top 50 emergent group-trait associations ac-\ncording to our measure are listed in Table A10.\nWe also see some good examples are: the lan-\nguage model scores “Hispanic unemployed peo-\nple” as more egotistic than people of the com-\nponent identities, “Democrat teenagers” as more\naltruistic, “male doctors” as more benevolent,\netc. However, there are also some unexpected pat-\nterns; for instance, almost all nationality identities\ncombined with “mechanic” are trustworthy and\nlikeable, and almost all nationality identities com-\nbined with “autistic” are egotistic. Looking into\nthe scores themselves, we find that both “mechanic”\nand “autistic” have low scores on the correspond-\ning traits, and combining them with nationalities\nraises to about average levels.\nAside from analyzing face validity—which is\nmixed—we compare the results of our model to the\ntraits that Ghavami and Peplau (2013) found when\nconducting human studies of race/gender pairs. To\ndo this, we categorize the traits from Ghavami and\n1283\nPeplau (2013) to the ABC dimensions8 and com-\npare with our full list of emergent group-trait associ-\nations. Taking their group-trait matches as ground\ntruth, our detection of traits for these race/gender\nintersectional groups achieves a precision 0.83 and\nrecall 0.65—better than random guessing (preci-\nsion 0.72, recall 0.50) but far from perfect.\n6 Limitations and Ethical Considerations\nThere are several limitations to our work, which\nshould be taken into account in the interpretation\nof our results.\nFirst, our results are likely affected by reporting\nbias and by a defaulting effect where, when people\nannotate traits for “men”, they may actually have\nin their head “cis straight white men”, because the\ndefaults go unremarked. This goes both for the\nhuman scores (how does a participant conceptu-\nalize “men”?) and language model scores (what\ndo sentences containing the word “man” assume\ngiven that most language a langauge model has\nbeen trained on likely exhibits defaulting?).\nSecond, our work only focus on assessing stereo-\ntypes within language models and not in any de-\nployed system. Though stereotypes from language\nmodels may impact the outputs of downstream sys-\ntems which are built upon these language models,\nit is not clear how exactly the stereotypes trans-\nfer (Cao et al., 2022). Additionally, our work is\nlimited to English and U.S. social stereotypes.\nThird, although we followed and built on best\npractices from social psychology in developing the\nhuman study, it nevertheless has some shortcom-\nings. In particular, even after many iterations on\nwording, it was difficult to phrase the survey ques-\ntions to encourage people to reporting their true\nimpressions. There is tension between asking a par-\nticipant what they think—which risks a counfound-\ning potential social desirability bias (Latkin et al.,\n2017) (people’s tendency to respond in socially ac-\nceptable ways)—and asking what they think others\nthink—which led to comments from a few partici-\npants that they felt unqualified to speak for others.\nAsking these questions of participants and collect-\ning the data also raises the possibility of this work\ninadvertantly reinforcing stereotypes.\nFinally, aggregating human judgements into a\nsingle number by averaging (or any other statistic)\n8Ghavami and Peplau (2013) covers paired groups com-\nbined with race domain and binary genders. The traits they\nraised span the agency and communion dimensions.\nto compare to model predictions risks collapsing a\nsignificant amount of information down to a single\nnumber. This number cannot distinguish between a\nweakly held but common stereotype and a strongly\nheld but rare one. Nor can it distinguish between\ntraits where half of annotators say 0 and the other\nhalf say 100, from traits where all annotators say\n50. These average judgments should be interpreted\nas not what any single person would say, but an\naverage over people. This limitation is exacerbated\nby the defaulting effect, where some people may\nimagine a different prototype for a given group,\nand other people may imagine another.\n7 Conclusion\nIn this paper, we measured language model (LM)\nstereotypes by adopting the ABC stereotype model\nfrom social psychology. Comparing to previous\nwork on detecting LM stereotypes, our approach is\neasy to extend to previously unconsidered groups,\ngrounded in traits proven effective by social psy-\nchology, and exhaustively covering the space of\npossible stereotypes, at the cost of being more ab-\nstract than in other NLP work. This yields a dif-\nferent set of trade-offs than previous approaches to\nmeasuring stereotypes in LMs.\nWith the ABC model and data regarding human\nstereotypes from our human study, we assessed LM\nstereotypes using three different association mea-\nsurements, including SeT, a metric we proposed.\nWe showed that LM group-trait stereotypes in gen-\neral have moderate correlation with human judge-\nments, and that SeT provides correlations that bet-\nter align with human’s. Based on these results, we\nextended our analysis to intersectional groups. We\nfound that the LM may be able to capture inter-\nsectional stereotypes but is not particularly good\non identifying emergent intersectional stereotypes.\nOur results also show that that, in general, age and\npolitical stance are dominant domains in language\nmodels, whereas race and nationality are domi-\nnated domains. We hope that our work provides\ninsights for future works on measuring and miti-\ngating stereotypes in natural language processing\nsystems, and that the grounding in theories from so-\ncial psychology has benefits beyond just studying\nstereotypes.\nAcknowledgments\nThis material is based upon work partially sup-\nported by the National Science Foundation under\n1284\nGrant No. 2131508. The authors are also grateful\nto all the reviewers who have provided helpful sug-\ngestions to improve this work, and thank members\nof the CLIP lab at the University of Maryland for\nthe support on this project. We are grateful to all\nthose who participated in our human study, without\nwhom this research would not have been possible.\nReferences\nAndrea Abele, Naomi Ellemers, Susan Fiske, Alex\nKoch, and Vincent Yzerbyt. 2020. Navigating the\nsocial world: Toward an integrated framework for\nevaluating self, individuals, and groups. Psychologi-\ncal review, 128.\nAndrea Abele and Bogdan Wojciszke. 2014. Communal\nand agentic content a dual perspective model. Adv.\nExp. Soc. Psychol., 50:198–255.\nEmily M Bender, Timnit Gebru, Angelina McMillan-\nMajor, and Shmargaret Shmitchell. 2021. On the\ndangers of stochastic parrots: Can language models\nbe too big?. In Proceedings of the 2021 ACM Confer-\nence on Fairness, Accountability, and Transparency,\npages 610–623.\nAlina Beygelzimer, Sanjoy Dasgupta, and John Lang-\nford. 2008. Importance weighted active learning.\nCoRR, abs/0812.4952.\nVictor Bittorf, Benjamin Recht, Christopher Ré, and\nJoel Tropp. 2012. Factoring nonnegative matrices\nwith linear programs. Advances in Neural Informa-\ntion Processing Systems, 2.\nSu Lin Blodgett, Gilsinia Lopez, Alexandra Olteanu,\nRobert Sim, and Hanna Wallach. 2021. Stereotyping\nNorwegian salmon: An inventory of pitfalls in fair-\nness benchmark datasets. In Proceedings of the 59th\nAnnual Meeting of the Association for Computational\nLinguistics and the 11th International Joint Confer-\nence on Natural Language Processing (Volume 1:\nLong Papers), pages 1004–1015, Online. Association\nfor Computational Linguistics.\nTolga Bolukbasi, Kai-Wei Chang, James Zou,\nVenkatesh Saligrama, and Adam Kalai. 2016. Man\nis to computer programmer as woman is to home-\nmaker? debiasing word embeddings. NeurIPS, pages\n4349–4357.\nEduardo Bonilla-Silva. 1997. Rethinking racism: To-\nward a structural interpretation. American sociologi-\ncal review, pages 465–480.\nRobert E. Botsch. 2011. Significance and Measures of\nAssociation.\nIrene Browne and Joya Misra. 2003. The intersection of\ngender and race in the labor market. Annual review\nof sociology, 29(1):487–513.\nJ.S. Bruner, Brunswik E, L. Festinger, F. Heider, K.F.\nMuenzinger, C.E. Osgood, and D. Rapaport. 1957.\nGoing beyond the information given. Contemporary\napproaches to cognition, pages 41–67.\nAylin Caliskan, Joanna J Bryson, and Arvind Narayanan.\n2017. Semantics derived automatically from lan-\nguage corpora contain human-like biases. Science,\n356(6334):183–186.\nYang Trista Cao, Yada Pruksachatkun, Kai-Wei Chang,\nRahul Gupta, Varun Kumar, Jwala Dhamala, and\nAram Galstyan. 2022. On the intrinsic and extrinsic\nfairness evaluation metrics for contextualized lan-\nguage representations.\nPatricia Hill Collins. 2002. Black feminist thought:\nKnowledge, consciousness, and the politics of em-\npowerment. routledge.\nCombahee River Collective. 1977. A Black Feminist\nStatement. na.\nCombahee River Collective. 1983. The combahee river\ncollective statement. Home girls: A Black feminist\nanthology, 1:264–274.\nKimberlé Crenshaw. 1989. Demarginalizing the inter-\nsection of race and sex: A black feminist critique\nof antidiscrimination doctrine, feminist theory and\nantiracist politics. u. Chi. Legal f., page 139.\nHal Daumé, III and Abhishek Kumar. 2017. Column\nsquishing for multiclass updates (blog post).\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. In NAACL-HLT (1).\nNaomi Ellemers. 2017. Morality and the Regulation of\nSocial Behavior: Groups as Moral Anchors.\nSusan T. Fiske, Amy J. C. Cuddy, Peter Glick, and\nJun Xu. 2002. A model of (often mixed) stereotype\ncontent: competence and warmth respectively follow\nfrom perceived status and competition. Journal of\npersonality and social psychology, 82 6:878–902.\nTimnit Gebru, Jamie Morgenstern, Briana Vecchione,\nJennifer Wortman Vaughan, Hanna Wallach, Hal\nDaumé, and Kate Crawford. 2018. Datasheets for\ndatasets.\nNegin Ghavami and Letitia Anne Peplau. 2013. An in-\ntersectional analysis of gender and ethnic stereotypes:\nTesting three hypotheses. Psychology of Women\nQuarterly, 37(1):113–127.\nWei Guo and Aylin Caliskan. 2021. Detecting emergent\nintersectional biases: Contextualized word embed-\ndings contain a distribution of human-like biases. In\nProceedings of the 2021 AAAI/ACM Conference on\nAI, Ethics, and Society , AIES ’21, page 122–133,\nNew York, NY , USA. Association for Computing\nMachinery.\n1285\nTimothy J. Hazen, Alexandra Olteanu, Gabriella Kazai,\nFernando Diaz, and Michael Golebiewski. 2020. On\nthe social and technical challenges of web search\nautosuggestion moderation. arXiv:2007.05039 [cs].\nArXiv: 2007.05039.\nbell hooks. 1992. Yearning: Race, gender, and cultural\npolitics. Hypatia, 7(2).\nDirk Hovy and Diyi Yang. 2021. The importance of\nmodeling social factors of language: Theory and\npractice. In Proceedings of the 2021 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, pages 588–602, Online. Association\nfor Computational Linguistics.\nLynne M. Jackson. 2011. The psychology of prejudice:\nFrom attitudes to social action. American Psycholog-\nical Association.\nDeborah K King. 1988. Multiple jeopardy, multiple\nconsciousness: The context of a black feminist ideol-\nogy. Signs: Journal of women in culture and society,\n14(1):42–72.\nAlex Koch, Roland Imhoff, Ron Dotsch, Christian\nUnkelbach, and Hans Alves. 2016. The abc of\nstereotypes about groups: Agency/socioeconomic\nsuccess, conservative-progressive beliefs, and com-\nmunion. Journal of personality and social psychol-\nogy, 110:675–709.\nAlex Koch, Vincent Yzerbyt, Andrea Abele, Naomi\nEllemers, and Susan T. Fiske. 2021. Social evalua-\ntion: Comparing models across interpersonal, intra-\ngroup, intergroup, several-group, and many-group\ncontexts, volume 63, page 1–68. Elsevier.\nKeita Kurita, Nidhi Vyas, Ayush Pareek, Alan W.\nBlack, and Yulia Tsvetkov. 2019. Measuring bias\nin contextualized word representations. CoRR,\nabs/1906.07337.\nCarl A. Latkin, Catie Edwards, Melissa A. Davey-\nRothwell, and Karin E. Tobin. 2017. The relation-\nship between social desirability bias and self-reports\nof health, substance use, and social network factors\namong urban substance users in baltimore, maryland.\nAddictive Behaviors, 73:133–136.\nWalter Lippmann. 1965. Public Opinion. New York\n:Free Press.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoBERTa: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nChandler May, Alex Wang, Shikha Bordia, Samuel R.\nBowman, and Rachel Rudinger. 2019. On measuring\nsocial biases in sentence encoders. In Proceedings\nof the 2019 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, Volume 1 (Long and\nShort Papers), pages 622–628, Minneapolis, Min-\nnesota. Association for Computational Linguistics.\nMoin Nadeem, Anna Bethke, and Siva Reddy. 2020.\nStereoset: Measuring stereotypical bias in pretrained\nlanguage models. CoRR, abs/2004.09456.\nNikita Nangia, Clara Vania, Rasika Bhalerao, and\nSamuel R. Bowman. 2020. CrowS-pairs: A chal-\nlenge dataset for measuring social biases in masked\nlanguage models. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language\nProcessing (EMNLP), pages 1953–1967, Online. As-\nsociation for Computational Linguistics.\nDebora Nozza, Federico Bianchi, and Dirk Hovy. 2021.\nHONEST: Measuring hurtful sentence completion\nin language models. In Proceedings of the 2021\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, pages 2398–2406, Online.\nAssociation for Computational Linguistics.\nSilviu Paun, Bob Carpenter, Jon Chamberlain, Dirk\nHovy, Udo Kruschwitz, and Massimo Poesio. 2018.\nComparing Bayesian Models of Annotation. Trans-\nactions of the Association for Computational Linguis-\ntics, 6:571–585.\nMaarten Sap, Saadia Gabriel, Lianhui Qin, Dan Juraf-\nsky, Noah A. Smith, and Yejin Choi. 2019. Social\nbias frames: Reasoning about social and power im-\nplications of language. CoRR, abs/1911.03891.\nAnna Sotnikova, Yang Trista Cao, Hal Daumé III, and\nRachel Rudinger. 2021. Analyzing stereotypes in\ngenerative text inference tasks. In Findings of the\nAssociation for Computational Linguistics: ACL-\nIJCNLP 2021, pages 4052–4065, Online. Association\nfor Computational Linguistics.\nDr. Charles Stangor. 2014. Principles of social psychol-\nogy – 1st international edition. BCcampus.\nAmy C Steinbugler, Julie E Press, and Janice Johnson\nDias. 2006. Gender, race, and affirmative action:\nOperationalizing intersectionality in survey research.\nGender & Society, 20(6):805–825.\nSheldon Stryker. 1980. Symbolic interactionism: a\nsocial structural version. Benjamin/Cummings Pub.\nCo.\nS. Wheeler and Richard Petty. 2001. The effects of\nstereotype activation on behavior: A review of pos-\nsible mechanisms. Psychological bulletin, 127:797–\n826.\nI.J. Wod. 1985. Weight of evidence: A brief survey.\nBayesian statistics, 2:249–270.\nVincent Y . Yzerbyt. 2018. The dimensional compen-\nsation model. Agency and Communion in Social\nPsychology.\nMaxine Baca Zinn and Bonnie Thornton Dill. 1996.\nTheorizing difference from multiracial feminism.\nFeminist studies, 22(2):321–331.\n1286\nA Traits\nThe full list of traits and respective adjectives is in the Table A7\nTrait Adjectives\nAgency scale\nPowerful forceful, formidable, capable\nPowerless weak, helpless, incapable\nHigh status privileged, elite, advantaged\nLow status unskilled, lowly, inferior\nDominant commanding, authoritative\nDominated subservient, submissive, deferential\nWealthy affluent, rich, prosperous\nPoor impoverished, destitute, needy\nConfident self-assured, assured, self-possessed\nUnconfident bashful, meek, timid\nCompetitive ambitious, driven, zealous\nUnassertive submissive, diffident, passive\nBeliefs scale\nModern radical, forward-looking\nTraditional old-fashioned\nScience-oriented analytical, logical, atheistic\nReligious devout, pious, reverent\nAlternative unorthodox, avant-garde, eccentric\nConventional mainstream\nLiberal left-wing, Democrat, progressive\nConservative right-wing, Republican\nCommunion scale\nTrustworthy reliable, dependable, truthful\nUntrustworthy unreliable, undependable\nSincere genuine, forthright, honest\nDishonest insincere, deceitful\nWarm friendly, kind, loving\nCold unfriendly, unkind, aloof\nBenevolent considerate, generous\nThreatening intimidating, menacing, frightening\nLikable pleasant, amiable, lovable\nRepellent vile, loathsome, nasty\nAltruistic helpful, charitable, selfless\nEgotistic selfish, self-centered, insensitive\nTable A7: Full list of traits and corresponding adjectives.\n1287\nDominates Dominated by\nage gender/sexuality, race/ethnicity, nationality, poli-\ntics, religion, socio-economic -\npolitics nationality, socio-economic, disability age, religion\ngender/ sexuality race/ethnicity, nationality age\ndisability race/ethnicity, nationality politics\nsocial-economic race/ethnicity, nationality age, politics\nreligion politics -\nrace/ ethnicity - age, gender/sexuality, socio-economic, disability\nnationality - age, gender/sexuality, politics, socio-economic,\ndisability\nTable A8: Domination relations between social domains.\nB Experiment Results with Single Groups\nTable A11 presents the Kendall’sτ correlation scores between model and human at group level, while\nTable A12 and Table A13 shows the alignment with the precision at 3 scores (former computed with the\ntop 3 traits and latter with the bottom 3 traits).\nC Experiment Results of Intersectional Groups\nTable A8 presents the dominating relationship between domains, while Table A9 lists the average\ncorrelation scores of the paired group with each of its identities’ domain for each domain pairs.\nTable A10 shows the top 50 emergent group-trait associations.\nDomain A Domain B Correlation A Correlation B\nage disability 0.532 0.475\ngender disability 0.418 0.356\nage gender 0.552 0.320\nage nationality 0.583 0.337\ndisability nationality 0.543 0.309\ngender nationality 0.481 0.225\npolitical stance nationality 0.287 0.179\nrace nationality 0.594 0.525\nreligion nationality 0.490 0.525\nsocio nationality 0.540 0.338\nage political stance 0.319 0.177\ndisability political stance 0.019 0.397\ngender political stance 0.315 0.375\nrace political stance 0.376 0.348\nreligion political stance 0.380 0.271\nage race 0.520 0.395\ndisability race 0.538 0.392\ngender race 0.478 0.371\nage religion 0.502 0.449\ndisability religion 0.465 0.463\ngender religion 0.439 0.360\nrace religion 0.522 0.460\nage socio 0.562 0.406\ndisability socio 0.420 0.419\ngender socio 0.374 0.397\npolitical stance socio 0.433 0.290\nrace socio 0.387 0.488\nreligion socio 0.404 0.439\nTable A9: Full list of correlations for paired social groups. The table shows two domains, which comprise group\nAB, correlations between group AB and group A, group AB and group B.\nD Human study setup\nThe survey for the collection of associated traits is presented in Figure A2.\n1288\nFigure A2: Example of the survey for one group.\n1289\nE Annotators demographics\n55.4% are white, with 50.6% male annotators, 40.4 female annotators and no annotators who provided\nanother gender. 15.1% of annotators are Black, and 25.6% are Hispanic with slightly more female\nannotators 56.4%. We provide four tables A14, A15, A16, A17 showing how perceptions of White people,\nBlack people, White men, and White women are different from each other across annotator demographics.\nWe see variations between in-group and out-group annotations. For instance, women see themselves as\nmore powerful than men see women. While overall scores for men and women groups are similar across\nwhite and Black annotators. In Table A18, we show correlation scores for all social groups and overall\nscore between the model and Black, white, white female, and white male annotators.\n1290\nGroup AB Emerged Trait Increased Score Max Score\nJamaican mechanic trustworthy 0.1055 -0.0449\ngay with a disability conventional 0.0931 0.0017\ngay with a disability threatening 0.0922 -0.0316\nHispanic unemployed person egotistic 0.0919 -0.1546\ngay with a disability liberal 0.0882 0.0401\nfemale Native American dominant 0.0860 0.0682\nDemocrat teenager altruistic 0.0858 -0.0986\nDeaf mechanic likable 0.0854 0.0046\nBlack mechanic likable 0.0821 -0.0118\nDemocrat mechanic trustworthy 0.0819 -0.0449\nmale doctor benevolent 0.0819 -0.0230\nfemale Indian person dominant 0.0808 0.0471\nLatina dominant 0.0808 0.0720\nFilipino mechanic trustworthy 0.0802 -0.0137\nNative American mechanic trustworthy 0.0796 -0.0449\nteenage Democrat altruistic 0.0794 -0.0986\ntrans mechanic likable 0.0792 -0.0118\nDemocrat mechanic sincere 0.0792 -0.0205\nDemocrat teenager sincere 0.0790 -0.0205\nfemale Black person dominant 0.0785 0.0471\nunemployed Italian person poor 0.0784 0.0384\nfemale doctor alternative 0.0779 0.0052\nIrish autistic person egotistic 0.0775 -0.0708\nRussian mechanic likable 0.0773 -0.0118\nunemployed Hispanic person egotistic 0.0772 -0.1546\nRussian unemployed person egotistic 0.0762 -0.1788\nfemale doctor traditional 0.0750 0.0107\nAmish mechanic trustworthy 0.0748 -0.0170\nRepublican mechanic sincere 0.0745 -0.0164\nmale teenager conventional 0.0738 -0.0589\nHispanic French person egotistic 0.0733 -0.1210\nCuban person with a disability poor 0.0731 0.0486\natheist mechanic trustworthy 0.0727 -0.0381\nHispanic Irish person egotistic 0.0725 -0.1322\nfemale Indian person dominated 0.0721 0.0421\ngay with a disability traditional 0.0717 0.0229\nunemployed German person poor 0.0715 0.0384\nfemale American person dominated 0.0709 0.0328\nIrish mechanic trustworthy 0.0709 -0.0300\nMuslim autistic person egotistic 0.0708 -0.0708\nmale teenager traditional 0.0705 -0.0490\nRussian autistic person egotistic 0.0704 -0.0708\nJapanese autistic person egotistic 0.0700 -0.0708\ntrans Republican sincere 0.0698 -0.0164\nGerman White person egotistic 0.0696 -0.0833\nmale Buddhist benevolent 0.0696 -0.0148\nIrish Deaf person egotistic 0.0693 -0.0589\nNative American mechanic sincere 0.0690 -0.0249\nGerman Republican egotistic 0.0688 -0.0517\nTable A10: Top 50 emergent group-trait associations.\n1291\nCEAT ILPS ILPS ⋆ SeT\nRoBERTa BERT RoBERTa BERT RoBERTa BERT RoBERTa BERT\nWhite people 0.150 -0.033 -0.117 -0.383 0.117 -0.350 -0.033 -0.217\nHispanic people 0.533 0.200 0.133 0.300 0.483 0.283\nAsian people 0.092 0.126 0.159 0.126 0.243 0.326\nBlack people -0.209 -0.075 0.209 0.142 0.176 0.042 0.393 0.209\nImmigrants -0.117 -0.267 0.233 0.350 0.217 0.383 0.283 0.400\nMen 0.183 -0.033 0.083 0.433 0.233 0.183 0.200 0.383\nWomen -0.433 0.083 0.217 0.017 -0.100 0.050 0.083 0.067\nWealthy people 0.100 -0.133 0.067 0.017 0.150 0.167 0.067 0.083\nJewish people 0.250 0.083 0.017 -0.067 0.150 -0.217 0.033 -0.100\nMuslim people 0.233 -0.050 0.000 -0.167 0.183 -0.017 0.250 -0.233\nChristians 0.343 0.393 0.209 0.075 0.410 -0.176 0.243 0.142\nCis people 0.167 -0.067 -0.167 -0.033 0.217 -0.400 0.050 0.033\nTrans people -0.283 -0.050 0.067 -0.067 0.033 0.083 0.133 0.050\nWorking class people 0.050 0.300 0.183 -0.117 -0.300 0.017 0.250 -0.033\nNon -binary people 0.050 -0.183 0.117 -0.050 0.067 -0.250\nNative Americans -0.217 -0.017 0.117 0.350 0.000 -0.183 0.200 0.283\nBuddhists 0.000 0.300 0.417 0.517 0.483 0.217 0.383 0.533\nMormons 0.167 0.367 -0.033 0.100 0.283 -0.333 -0.083 0.283\nVeterans 0.100 0.417 0.250 -0.083 0.267 -0.083 0.217 -0.033\nUnemployed people -0.233 0.083 0.067 0.500 0.067 0.400 0.050 0.500\nTeenagers -0.150 -0.133 0.200 -0.267 0.367 -0.033 0.217 -0.250\nElderly people 0.017 0.417 0.650 0.333 0.533 0.117 0.700 0.400\nBlind people 0.017 0.367 0.217 0.267 0.100 0.150 0.200 0.267\nAutistic people 0.350 -0.117 0.317 0.250 0.267 -0.050\nNeurodivergent people -0.167 0.000 0.083 -0.017 -0.100 0.050 0.017 -0.117\nTable A11: Overall alignment scores with human annotations for Kendall’sτ. There are some missing scores for\nCEAT because there are no occurrences of these groups in the Reddit 2014 dataset.\nCEAT ILPS ILPS ⋆ SeT\nRoBERTa BERT RoBERTa BERT RoBERTa BERT RoBERTa BERT\nWhite people 1.00 1.00 0.33 0.33 0.67 0.67 0.67 0.67\nHispanic people 1.00 0.67 0.67 0.67 0.67 0.67\nAsian people 1.00 1.00 1.00 1.00 1.00 1.00\nBlack people 0.00 0.33 0.33 0.33 0.33 0.00 0.67 0.33\nImmigrants 0.33 0.00 0.67 0.00 0.33 0.00 0.33 0.33\nMen 0.67 0.00 0.67 1.00 0.67 0.33 0.67 1.00\nWomen 0.33 1.00 1.00 1.00 1.00 1.00 1.00 1.00\nWealthy people 1.00 0.67 0.33 0.33 0.67 0.67 0.67 0.67\nJewish people 0.67 0.67 0.00 0.33 0.33 0.33 0.33 0.33\nMuslim people 0.00 0.00 0.00 0.00 0.33 0.33 0.33 0.00\nChristians 1.00 1.00 1.00 1.00 1.00 0.67 1.00 1.00\nCis people 1.00 1.00 1.00 0.67 1.00 0.67 1.00 1.00\nTrans people 0.33 0.33 1.00 0.00 0.67 0.67 1.00 0.33\nWorking class people 0.67 0.67 0.67 0.33 0.33 1.00 0.67 0.67\nNon-binary people 1.00 0.67 1.00 0.67 1.00 0.67\nNative Americans 0.33 0.67 0.67 1.00 0.33 0.67 0.67 0.67\nBuddhists 0.33 0.67 1.00 1.00 1.00 1.00 0.677 1.00\nMormons 0.67 1.00 1.00 1.00 1.00 0.67 1.00 1.00\nVeterans 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00\nUnemployed people 0.33 0.00 0.00 0.67 0.00 0.00 0.00 0.67\nTeenagers 0.00 0.33 0.67 0.33 0.67 0.33 0.67 0.67\nElderly people 0.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00\nBlind people 0.67 0.67 1.00 1.00 0.67 1.00 1.00 1.00\nAutistic people 1.00 0.67 1.00 1.00 1.00 0.67\nNeurodivergent people 0.33 0.00 0.00 0.33 0.00 0.33 0.00 0.33\nTable A12: Overall alignment scores with human annotations for Precision at the top 3 traits.\n1292\nCEAT ILPS ILPS ⋆ SeT\nRoBERTa BERT RoBERTa BERT RoBERTa BERT RoBERTa BERT\nWhite people 0.67 0.33 0.00 0.00 0.33 0.67 0.67 0.67\nHispanic people 1.00 0.33 1.00 0.67 0.67 0.67\nAsian people 0.33 0.00 0.67 1.00 1.00 1.00\nBlack people 0.33 0.33 1.00 0.67 1.00 0.00 0.67 0.33\nImmigrants 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00\nMen 0.33 0.67 0.33 1.00 0.67 1.00 0.67 1.00\nWomen 0.00 0.33 0.00 0.00 0.00 0.33 0.00 0.00\nWealthy people 0.33 0.00 0.33 0.00 0.33 0.67 0.33 0.00\nJewish people 0.67 0.33 1.00 0.67 1.00 0.00 1.00 0.67\nMuslim people 0.67 0.67 0.67 0.33 1.00 1.00 1.00 0.67\nChristians 0.67 1.00 0.33 0.33 0.33 0.00 0.33 0.67\nCis people 0.33 0.33 0.00 0.33 0.33 0.00 0.33 0.33\nTrans people 0.00 0.67 0.33 0.33 0.33 0.33 0.33 0.33\nWorking class people 0.67 0.67 0.33 0.33 0.67 0.33 0.33 0.67\nNon-binary people 0.00 0.00 0.33 0.67 0.00 0.00\nNative Americans 0.33 0.33 0.33 0.67 0.67 0.33 0.67 0.67\nBuddhists 0.33 0.67 1.00 1.00 0.33 0.67 1.00 0.67\nMormons 0.67 1.00 0.33 0.33 0.33 0.00 0.33 0.67\nVeterans 0.33 0.67 0.67 0.00 0.33 0.33 0.67 0.00\nUnemployed people 0.67 1.00 1.00 1.00 1.00 1.00 1.00 1.00\nTeenagers 0.33 0.33 1.00 0.33 1.00 1.00 0.67 0.00\nElderly people 0.33 1.00 1.00 0.67 1.00 0.33 1.00 1.00\nBlind people 1.00 0.67 0.33 0.33 0.67 0.33 0.33 0.33\nAutistic people 0.67 0.33 1.00 0.67 0.33 0.33\nNeurodivergent people 0.67 0.67 0.67 1.00 0.67 0.67 0.67 0.67\nTable A13: Overall alignment scores with human annotations for Precision at the bottom 3 traits.\nSocial Group\nTrait pair Women Men White Black\npowerless-powerful 46.8 81.4 80.7 37.1\nlow status-high status 44.9 76.3 78.6 25.5\ndominated-dominant 34.3 84.8 72.6 26.3\npoor-wealthy 55.2 67.7 76.6 28.8\nunconfident-confident 57.3 78.3 77.4 54.7\nunassertive-competitive 53.8 75.5 79.3 49.9\ntraditional-modern 61.8 53.3 60.8 31.7\nreligious-science oriented 59.9 56.1 52.8 27.0\nconventional-alternative 55.3 46.7 47.1 44.2\nconservative-liberal 61.7 40.8 43.0 56.8\nuntrustworthy-trustworthy 52.2 50.9 58.2 29.9\ndishonest-sincere 52.4 45.3 56.6 37.4\ncold-warm 53.8 42.3 56.8 53.0\nthreatening-benevolent 64.3 39.7 54.2 31.4\nrepellent-likable 65.5 59.7 59.1 40.3\negoistic-altruistic 50.1 42.8 50.6 47.5\nTable A14: Group-trait associations from white annotators for a subset of social groups. Scores which are closer to\n0 indicate closer to the trait on the left (powerless, low status, etc.) and scores closer to 100 indicate closer to the\ntrait on the right (powerful, high status, etc.).\n1293\nSocial Group\nTrait pair Women Men White Black\npowerless-powerful 61.0 93.0 73.8 56.6\nlow status-high status 67.8 86.0 74.3 49.3\ndominated-dominant 56.0 94.0 72.5 55.3\npoor-wealthy 59.0 91.0 76.8 40.6\nunconfident-confident 82.3 85.0 69.7 75.9\nunassertive-competitive 54.0 57.0 80.5 76.3\ntraditional-modern 64.8 67.0 80.3 53.7\nreligious-science oriented 35.5 65.0 81.8 21.7\nconventional-alternative 66.0 62.0 52.5 57.9\nconservative-liberal 71.3 82.0 71.5 67.7\nuntrustworthy-trustworthy 78.5 57.0 62.8 46.9\ndishonest-sincere 78.5 61.0 62.3 42.7\ncold-warm 87.5 66.0 50.7 58.3\nthreatening-benevolent 78.3 38.0 35.5 49.7\nrepellent-likable 85.0 59.0 49.3 62.1\negoistic-altruistic 80.8 77.0 59.8 39.6\nTable A15: Group-trait associations from Black annotators for a subset of social groups. Scores which are closer to\n0 indicate closer to the trait on the left (powerless, low status, etc.) and scores closer to 100 indicate closer to the\ntrait on the right (powerful, high status, etc.).\nSocial Group\nTrait pair Women Men White Black\npowerless-powerful 37.5 80.0 81.9 29.8\nlow status-high status 44.0 77.0 83.4 18.3\ndominated-dominant 42.0 83.3 69.8 18.0\npoor-wealthy 47.0 70.5 83.0 12.5\nunconfident-confident 55.5 75.5 81.6 51.0\nunassertive-competitive 61.0 83.3 82.3 39.0\ntraditional-modern 59.5 59.3 76.8 26.3\nreligious-science oriented 46.0 62.5 61.3 21.5\nconventional-alternative 51.0 55.0 64.6 42.3\nconservative-liberal 54.0 36.7 55.1 53.0\nuntrustworthy-trustworthy 49.5 45.7 47.5 32.5\ndishonest-sincere 48.0 42.5 52.5 34.0\ncold-warm 50.0 43.0 55.6 48.0\nthreatening-benevolent 56.5 34.0 48.3 24.0\nrepellent-likable 50.5 57.3 57.0 40.5\negoistic-altruistic 51.5 44.8 47.6 53.8\nTable A16: Group-trait associations from white male annotators for a subset of social groups. Scores which are\ncloser to 0 indicate closer to the trait on the left (powerless, low status, etc.) and scores closer to 100 indicate closer\nto the trait on the right (powerful, high status, etc.).\n1294\nSocial Group\nTrait pair Women Men White Black\npowerless-powerful 48.1 82.8 81.8 41.3\nlow status-high status 45.1 75.5 76.8 29.6\ndominated-dominant 33.2 86.2 78.1 31.0\npoor-wealthy 56.4 64.8 73.5 38.1\nunconfident-confident 57.5 81.7 76.2 56.9\nunassertive-competitive 52.8 67.7 78.9 56.9\ntraditional-modern 62.1 47.2 51.0 34.9\nreligious-science oriented 58.5 49.7 50.6 30.2\nconventional-alternative 55.9 38.3 37.4 45.3\nconservative-liberal 62.8 45.0 38.6 59.0\nuntrustworthy-trustworthy 52.6 56.2 61.0 28.4\ndishonest-sincere 53.1 48.2 53.9 39.1\ncold-warm 54.3 41.7 51.4 55.9\nthreatening-benevolent 65.4 45.3 53.4 35.6\nrepellent-likable 67.7 62.0 53.3 40.1\negoistic-altruistic 49.9 40.7 47.7 44.0\nTable A17: Group-trait associations from white female annotators for a subset of social groups. Scores which are\ncloser to 0 indicate closer to the trait on the left (powerless, low status, etc.) and scores closer to 100 indicate closer\nto the trait on the right (powerful, high status, etc.).\nSocial Group\nTrait pair Black White White Men White Women\nWhite person -0.130 0.080 -0.180 0.220\nHispanic person 0.360 0.470 0.200 0.570\nAsian person 0.560 0.100 0.190 0.050\nBlack person 0.470 0.370 0.250 0.370\nimmigrant 0.010 0.420 0.300 0.420\nman -0.130 0.220 0.180 0.320\nwoman -0.060 -0.030 0.080 -0.080\nwealthy person -0.600 0.050 0.050 0.080\nJewish person 0.020 -0.020 -0.120 0.070\nMuslim person —— 0.230 0.140 0.280\nChristian 0.270 0.390 0.280 0.010\ncis person -0.840 0.090 -0.020 0.170\ntrans person 0.190 0.150 0.180 0.120\nworking class person 0.010 0.290 0.290 0.220\nnon-binary -0.040 0.050 -0.030 0.120\nNative American 0.140 0.070 0.080 0.130\nBuddhist 0.230 0.320 0.250 0.320\nMormon -0.030 0.030 0.100 -0.180\nveteran 0.220 0.200 0.180 0.190\nunemployed person 0.030 0.020 -0.040 0.000\nteenager 0.200 0.200 0.220 0.130\nelderly person 0.540 0.650 0.710 0.620\nblind person 0.226 0.217 0.217 0.217\nautistic person 0.267 0.217 0.267 0.167\nneurodivergent person 0.092 0.050 0.092 0.033\noverall 0.151 0.187 0.177 0.164\nTable A18: Correlation scores between the model and white, Black, white male, and white female annotators.\nScores with p-values less than 0.05 are marked bold.\nCEAT ILPS ILPS ⋆ SeT\nRoBERTa BERT RoBERTa BERT RoBERTa BERT RoBERTa BERT\nKendall’s τ 0.028 0.123 † 0.142† 0.071 0.173 † -0.007 0.174† 0.093\nTable A19: Overall alignment scores with human annotations with only test groups. The highest scores are bold for\neach row. For correlation scores, we mark scores where the p-value is <0.05 with †.\n1295",
  "topic": "Association (psychology)",
  "concepts": [
    {
      "name": "Association (psychology)",
      "score": 0.5877289175987244
    },
    {
      "name": "Computer science",
      "score": 0.5735794901847839
    },
    {
      "name": "Computational linguistics",
      "score": 0.5693715214729309
    },
    {
      "name": "Linguistics",
      "score": 0.5224756002426147
    },
    {
      "name": "Grounded theory",
      "score": 0.45106321573257446
    },
    {
      "name": "Natural language processing",
      "score": 0.3908322751522064
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3720744252204895
    },
    {
      "name": "Cognitive science",
      "score": 0.34727680683135986
    },
    {
      "name": "Sociology",
      "score": 0.3392021059989929
    },
    {
      "name": "Psychology",
      "score": 0.29497087001800537
    },
    {
      "name": "Epistemology",
      "score": 0.19003021717071533
    },
    {
      "name": "Anthropology",
      "score": 0.15022167563438416
    },
    {
      "name": "Philosophy",
      "score": 0.14132803678512573
    },
    {
      "name": "Qualitative research",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I66946132",
      "name": "University of Maryland, College Park",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210164937",
      "name": "Microsoft Research (United Kingdom)",
      "country": "GB"
    }
  ],
  "cited_by": 20
}