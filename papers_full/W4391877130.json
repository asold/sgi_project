{
  "title": "CANAL - Cyber Activity News Alerting Language Model : Empirical Approach vs. Expensive LLMs",
  "url": "https://openalex.org/W4391877130",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A3204852956",
      "name": "Urjitkumar Patel",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5114127655",
      "name": "Fang-Chun Yeh",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5093940847",
      "name": "Chinmay Gondhalekar",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4254635861",
    "https://openalex.org/W4390678101",
    "https://openalex.org/W3007007518",
    "https://openalex.org/W3095319910",
    "https://openalex.org/W4360764185",
    "https://openalex.org/W6850828640",
    "https://openalex.org/W4309623083",
    "https://openalex.org/W6803439242",
    "https://openalex.org/W3185498326",
    "https://openalex.org/W4319079731",
    "https://openalex.org/W2293948899",
    "https://openalex.org/W6806962599",
    "https://openalex.org/W3200739701",
    "https://openalex.org/W4294170691",
    "https://openalex.org/W2295598076",
    "https://openalex.org/W6773820404",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4301581299",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4300485781",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W3168867926",
    "https://openalex.org/W4387994989",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4286987939",
    "https://openalex.org/W4223518423",
    "https://openalex.org/W4280534475",
    "https://openalex.org/W4225591000",
    "https://openalex.org/W4361866125"
  ],
  "abstract": "In today's digital landscape, where cyber attacks have become the norm, the detection of cyber attacks and threats is critically imperative across diverse domains. Our research presents a new empirical framework for cyber threat modeling, adept at parsing and categorizing cyber-related information from news articles, enhancing real-time vigilance for market stakeholders. At the core of this framework is a fine-tuned BERT model, which we call CANAL - Cyber Activity News Alerting Language Model, tailored for cyber categorization using a novel silver labeling approach powered by Random Forest. We benchmark CANAL against larger, costlier LLMs, including GPT-4, LLaMA, and Zephyr, highlighting their zero to few-shot learning in cyber news classification. CANAL demonstrates superior performance by outperforming all other LLM counterparts in both accuracy and cost-effectiveness. Furthermore, we introduce the Cyber Signal Discovery module, a strategic component designed to efficiently detect emerging cyber signals from news articles. Collectively, CANAL and Cyber Signal Discovery module equip our framework to provide a robust and cost-effective solution for businesses that require agile responses to cyber intelligence.",
  "full_text": "3rd IEEE International Conference on AI in Cybersecurity (ICAIC), DOI: 10.1109/ICAIC60265.2024.10433839, PREPRINT COPY\nCANAL - Cyber Activity News Alerting Language\nModel : Empirical Approach vs. Expensive LLMs\nUrjitkumar Patel\nRatings Data Science\nS&P Global\nNew York, USA\nurjitkumar.patel@spglobal.com\nFang-Chun Yeh\nRatings Data Science\nS&P Global\nNew York, USA\njessie.yeh@spglobal.com\nChinmay Gondhalekar\nRatings Data Science\nS&P Global\nNew York, USA\nchinmay.gondhalekar@spglobal.com\nAbstract—In today’s digital landscape, where cyber attacks\nhave become the norm, the detection of cyber attacks and threats\nis critically imperative across diverse domains. Our research\npresents a new empirical framework for cyber threat modeling,\nadept at parsing and categorizing cyber-related information from\nnews articles, enhancing real-time vigilance for market stakehold-\ners. At the core of this framework is a fine-tuned BERT model,\nwhich we call CANAL - Cyber Activity News Alerting Language\nModel, tailored for cyber categorization using a novel silver\nlabeling approach powered by Random Forest. We benchmark\nCANAL against larger, costlier LLMs, including GPT-4, LLaMA,\nand Zephyr, highlighting their zero to few-shot learning in cyber\nnews classification. CANAL demonstrates superior performance\nby outperforming all other LLM counterparts in both accuracy\nand cost-effectiveness. Furthermore, we introduce the Cyber\nSignal Discovery module, a strategic component designed to\nefficiently detect emerging cyber signals from news articles.\nCollectively, CANAL and Cyber Signal Discovery module equip\nour framework to provide a robust and cost-effective solution for\nbusinesses that require agile responses to cyber intelligence.\nIndex Terms—Large Language Models (LLM), BERT, Natural\nLanguage Processing (NLP), Machine Learning, Generative AI\n(GenAI), Cyber Risk Modeling, Cyber Signal Discovery, Cyber\nNews Alerts, Empirical Cost Analysis\nI. I NTRODUCTION\nThe recent escalation in cyber attacks is a significant\nconcern that spans across multiple sectors. As reported by\nISACA’s 2023 State of Cybersecurity [1], there’s an evident\nincrease in cyberattacks across organizations. This trend is\nnot limited to one domain; it affects diverse areas such as\ntechnology, oil and gas, healthcare, education, and finance.\nThe technology sector frequently confronts data breaches and\nintellectual property theft, while the oil and gas industry\nfaces threats to its critical infrastructure. In finance, cyber\nattacks can lead to significant financial losses and under-\nmine consumer confidence. Each of these sectors, including\nhealthcare, where data encryption in ransomware attacks is\nalarmingly high [2], and education, with its highest rate of\nransomware incidents [3], demonstrates the broad spectrum\nof cyber vulnerability.\nIn this context, the timely detection and dissemination of\ninformation about cyber attacks and threats become crucial.\nNews articles, in particular, play an essential role in pro-\nviding real-time information and early warnings. We define\na framework which combines entity relevance with a novel\ncategorization scheme that segments cyber-related news into\nfive distinct groups, each providing unique insights. This\nsystem not only aids in constructing comprehensive cyber\nprofiles for entities but also facilitates informed decision-\nmaking by providing nuanced insights into their cyber risk\nexposure.\nRecent advancements in Natural Language Processing\n(NLP), especially transformer-based models like BERT [4],\nT5 [5], Flan [6], GPT [7], Llama [8], Mistral [9], Claude [10],\nPaLM [11] have revolutionized various NLP tasks, including\napplications in the cyber domain. In past year, we have\nseen capable applications such as OpenAI’s ChatGPT [12],\nGoogle’s Bard [13] which are powered by multi billion param-\neter models, GPT4 and Palm respectively, have become inte-\ngral part of indiviuals and organizations for their daily tasks.\nThese powerful models have shown remarkable capabilities\nin processing and understanding complex language structures.\nHowever, the widespread adoption of these advanced models\nis often hampered by their need for substantial computational\nresources and the associated high costs of infrastructure or\nAPI usage. We demonstrate that for tasks such as Cyber\nCategorization, simpler and smaller BERT [4] model when\nfinetuned with good data, outperforms these huge expensive\nmodels.\nAddressing the prevalent challenges, our research introduces\na cost-efficient empirical framework, leveraging a finetuned\nBERT architecture with minimal training data requirements.\nThis framework excels in accurately categorizing cyber-related\ncontent from news articles, ensuring timely awareness for\nstakeholders. A key feature is the Cyber Signal Discovery\nmodule, adept at spotting emerging threats and enhancing\nour cyber terminology database with human-verified updates.\nBelow, we outline the pivotal contributions of our research to\nthe field:\n• Introduction of CANAL (Cyber Activity News Alert-\ning Language Model): A cutting-edge model specifically\ndeveloped for the efficient categorization of cyber-related\ninformation within news articles.\n• Unique 5 Class Cyber Categorization: We introduce a\nnovel classification scheme, grouping cyber-related news\narXiv:2405.06772v1  [cs.CR]  10 May 2024\ninto five distinct categories, each serving a different\nfunction across business domains.\n• Efficient Fine-Tuning of CANAL: Empirical fine-tuning\nframework using a minimal dataset, achieving state-of-\nthe-art results.\n• Benchmarking Against Larger Models: Comparative\nanalysis with major LLMs, focusing on zero to few-shot\nlearning in cyber classification.\n• Cyber Signal Discovery Module: Advanced module for\ndetecting emerging cyber threats, integrated with human\nexpertise.\n• Cost-Effective and Resource-Efficient Solution:\nDemonstrating a more economical and efficient\nalternative in cyber categorization.\n• Cyber Alerting Solution that Utilizes News Data:\nUtilizing raw news data for comprehensive and up-to-\ndate cyber threat alerting.\nII. L ITERATURE REVIEW\nThe realm of cybersecurity is undergoing a significant\ntransformation, driven by the increasing frequency and com-\nplexity of cyber threats in various sectors. The ISACA 2023\nState of Cybersecurity report indicates a rise in cyberattacks\nimpacting sectors such as technology, healthcare, education,\nand finance [1]. In response to these challenges, Artificial\nIntelligence (AI) is playing a crucial role in evolving the\ncybersecurity landscape. AI-driven approaches are enhancing\nthreat detection capabilities and enabling automated responses.\nThe advent of transformer-based models, such as those\nintroduced by Vaswani et al. [14], has ushered in a new era in\nNLP. Jacob Devlin et al.’s BERT [4] stands out in this evolu-\ntion, leveraging deep bidirectional representations to transform\ntasks like question answering and language inference. Its\napplication in domain-specific tasks, as exemplified by Dogu\nAraci’s FinBERT [15], showcases the adaptability of encoder-\nonly transformer models, which are particularly effective for\ncyber-specific classification tasks where generative capabilities\nare less critical.\nWhile generative models like llama [8], BloombergGPT\n[16], GPT [7] [17] have expanded the scope of transformers,\ntheir scalability, seen in models like PaLM [11], introduces\nsignificant resource demands. The resource-intensive nature\nof these models [18] and the associated costs [19] make them\nless practical for smaller, specific applications. Hoffman et al.’s\nChinchilla study [20] offers a balanced perspective on model\nsize and training data, yet the deployment of such large models\nin constrained environments remains debatable. This context\nunderscores the relevance of models like BERT, which provide\na more feasible and efficient approach for specialized tasks in\nthe realm of cybersecurity.\nThe integration of NLP into cybersecurity, particularly using\ntransformer-based models like BERT, has opened new avenues\nin threat detection and classification. Notable applications\nof BERT in cybersecurity extend beyond traditional models.\nEbelechukwu et al.’s CAN-BERT for anomaly detection in\nautomotive systems [21], Rahali et al.’s MalBERT for Malware\nidentification using Android application source code [22], and\nChen et al.’s BERT-Log for system log interpretation [23] are\na few examples. Adding to this, Kimia Aneri et al. introduced\nCyBERT, which fine-tunes BERT for cybersecurity claim\nclassification, focusing on optimal hyperparameters for en-\nhanced accuracy [24]. Furthermore, Salih Yasir et al. explored\nmalware detection using fastText and BERT, emphasizing\nthe purification and optimization of API call sequences for\nclassification tasks [25]. Moreover, Aghaei et al. introduced\nSecureBERT, a cybersecurity language model capable of cap-\nturing text connotations in cybersecurity text tailored for Cyber\nThreat Intelligence (CTI) tasks, exemplifying the model’s\nadaptability to specialized cybersecurity needs [26]. These\ndiverse applications underscore BERT’s adaptability and ef-\nfectiveness in addressing specialized cybersecurity challenges.\nThe evolution of cybersecurity alert systems has been\nmarked by significant advancements through the analysis of\nonline data. In 2015, Yigit Erkal et al. utilized Twitter data\nfor cyber security content identification, using a Naive Bayes\nClassifier and TF-IDF vectorization [27]. By 2018, Mohamad\nSyahir Abdullah et al. furthered this field by focusing on\ndetecting cyber-attack news, employing a Conditional Random\nField classifier and Latent Semantic Analysis [28]. In 2021,\nThea Riebe et al. introduced CySecAlert, a Twitter-based\nsystem for alerting on cyber security topics [29]. On a cyber\nspecific NER, Md TanvirAlum et al. proposed CyNER, a\nPython library for cybersecurity named entity recognition\n(NER), leveraging transformer-based models and heuristics to\nextract cybersecurity-related entities [30]\nHowever, despite these advancements, there appears to be\na gap in the literature concerning the application of BERT-\nbased models for generating cyber alerts from more real time\nnews sources like Google News. To the best of our knowledge,\nno studies have yet explored the finetuning of BERT models\nspecifically for the generation of cyber alerts based on Google\nNews alert data. This gap signifies a potential area for future\nresearch, particularly given BERT’s proven efficacy in text\nclassification and its potential applicability in the nuanced field\nof cyber risk modeling.\nOur study addresses a significant gap in cyber threat de-\ntection by introducing a framework that generates entity-\nfocused cyber alerts from online news, utilizing cost-effective\nand efficient Large Language Models (LLMs). This approach\novercomes key challenges such as limited training data and the\ndynamic nature of cyber threats. By processing vast amounts\nof online news to identify relevant cyber risks, our framework\nenhances the accuracy and timeliness of alerts, making it a\nvaluable addition to existing cyber threat intelligence systems.\nOverall, our research contributes to advancing cyber threat\ndetection strategies in today’s digital landscape.\nIII. B ACKGROUND AND THEORY\nA. Problem Statement\nIn the rapidly evolving domain of cybersecurity, the daily\ninflux of thousands of news articles presents a significant chal-\nlenge in information management and analysis. Our study’s\ngoal is two-fold: firstly, to effectively categorize these articles\ninto five distinct categories — Recent Cyber Attack, Litigation,\nFuture Threats, Preventive Action, and “Other”; and secondly,\nto discover and highlight emerging cyber threats and signals.\nThis dual approach is essential for systematically organizing\nand analyzing the vast array of incoming cyber-related news,\nenabling a more focused and efficient method for cyber threat\nintelligence. Our system aims to achieve these objectives\nusing a practical, efficient, and cost-effective approach, distin-\nguishing it from the more expensive Large Language Models\n(LLMs). The categorization is as follows:\n• Recent Cyber Attack : This category encompasses\narticles that report on recent real cyber attacks targeting\nentities. These articles provide critical insights into actual\ncyber threats that have resulted in tangible damage to\ncompanies. These Articles constitute a significant portion\nof our dataset, as they offer invaluable information for\nunderstanding the evolving cyber threat landscape.\n• Cyber Litigation : Litigation Articles pertain to news ar-\nticles that discuss legal actions, investigations, or charges\nrelated to cyber incidents. These articles are crucial for\nprofessionals tracking legal developments and conse-\nquences in the cybersecurity domain.\n• Future Cyber Threats: Future Threats category includes\narticles that address potential cyber risks and threats\nthat organizations may face in the future. These articles\nare forward-looking and target an audience interested in\nproactive risk assessment.\n• Cyber Risk Preventive: Preventive Action articles high-\nlight positive actions, remedies, vulnerability fixes, and\npatches aimed at reducing the likelihood of future cyber\nrisks. This category is particularly important as it con-\ntributes to building a positive cyber profile for an entity.\n• Other: The “Other” category encompasses a diverse\nrange of articles, including reports, studies, educational\ncontent, guidance materials, and miscellaneous topics\nrelated to cybersecurity. This category serves as a catch-\nall for articles that do not neatly fit into the first four\nclassifications, providing additional context and insights\ninto various aspects of cybersecurity.\nBy efficiently sorting these articles into relevant categories,\nour system seeks to enhance the utility and accessibility\nof cyber news, making it more actionable for cybersecurity\nprofessionals and organizations.\nB. Data\nWe utilize Google News data via news alerts RSS feeds\nfor our entire experiment. Initially, leveraging SME (Subject\nMatter Expertise), we configured the Google News Alerts with\nspecific cyber terms such as ’data breach,’ ’ransomware,’ and\nTABLE I: Data structure - Example of a single article entry\nfrom data theft feed\nid link publisheddatetime updateddatetime headline content feedname\nUQPuJTWfJ98oipewHLcFEf\nhttps://www.bnnbloomberg.ca/tesla-data-breach-blamed-on-insider-wrongdoing-impcted-75-000-1.1961383\n2023-08-2017:40:21.000\n2023-08-2017:40:21.000\nTesla DataBreach Blamedon ’InsiderWrongdoing’Impacted75,000 - BNNBloomberg\n(Bloomberg)– Tesla Inc.’sMay data breachimpacted morethan 75,000people, includedemployee-relatedrecords and was aresult of “insider...\ndatatheft\nTABLE II: Five Cyber attack categories.\nCategory News Headlines\nRecent Royal Mail hit by cyber attack causing ’severe disruption’ to services\nCyber HHS compromised in massive MOVEit hack\nattack FTX says $415 million of crypto was hacked\n...\nFuture Metro Bank Warns Against Rising Malware Attacks\nCyber Apple issues 30-day warning to iPhone users\nthreat Alarm raised over Mozilla VPN security flaw\n...\nCisco Releases A Fix For The Major ClamA V Antivirus Software Flaw\nCyber Microsoft issues 75 patches, including three for zero-day\nPrevention Android 14 Will Block Malware With Enhanced Security Updates\n...\nCommonSpirit Health sued over ransomware attack\nCyber Meta hit with 390 mn euro fine over EU data breaches\nLitigation JPMorgan Must Face Lawsuit by Ray-Ban Maker over $272 M\n...\nThis New McDonald’s Hack Turns Sprite Into Cotton Candy Soda\nOther Samsung Galaxy Z Fold 5 can fix design flaw present in the brand’s folding\nOur View: Google should have to answer for reckless site-blocking issues\n...\n’cyberattack.’ This setup generates a substantial number of\nnews alerts daily, which we scrape and save to our database.\nWe continually refine these feeds, adding new terms as they\nemerge in the cyber domain.\nOver a period of one year and ten months, starting from\nearly 2022 through to the end of October 2023, we have\namassed a collection of approximately 265,000 cyber ralated\narticles. Each article is accompanied by metadata such as ID,\nlink, publication date, and a headline, as detailed in Table I.\nFor our experiments, we focus exclusively on the headlines,\nwhich we have found to be sufficiently informative for our\ncategorization challenge. Table II showcases various examples\nof news titles within each category.\nC. Theoretical Framework\nGiven a news title comprising a sequence of N tokens\nw1, w2, . . . , wN , we aim to determine a probability distribution\nP over five cyber categories. This distribution is a function of\nthe input tokens, represented as:\nP = f(w1, w2, . . . , wN ) (1)\nWhere f denotes the model that estimates the probability\ndistribution that satisfy the following condition:\n5X\ni=1\nPi = 1,\nwhere Pi ∈ {Pcyber attack, Pfuture threat, Pprevention, Plitigation, Pother}\nFig. 1: An illustration of Emerging Cyber Signal Discovery\nModule\nThe predicted final category is obtained through a decision\nfunction g, which could be a simple maximization of the\nprobabilities or a threshold-based approach:\nPredicted Category = g(P), where g : P → Category\nThis function evaluates the highest probability or applies a\npre-defined threshold to determine the most likely category.\nIV. M ETHODOLOGY\nA. Emerging Cyber Signal Discovery Module\nIn response to increasing cyber attack frequencies, we’ve\ndeveloped an Emerging Cyber Signal Discovery Module to\nidentify and catalog new cyber attack terms for related\nnews article retrieval. The module comprises three integral\ncomponents: predefined cyber base terminologies, a tailored\nword vector model, and human feedback. Initially, a curated\nset of 30 cyber base terminologies is selected with the aid\nof subject matter expertise. Subsequently, each terminology\nis fed into the model, which, in turn, outputs related new\nterms meeting predefined criteria. Lastly, through a process of\nhuman feedback, the returned terms are meticulously reviewed\nand incorporated into the existing repository of cyber base\nterminologies. This systematic approach ensures the continual\naugmentation and refinement of the terminology lexicon to\neffectively adapt to the evolving landscape of cyber threats.\nAn illustration of the module can see in Fig. 1.\nThe word vector model that we use in this module is\ntrained by all news articles that we collect at the moment\nusing the skip-gram method [31]. The training objective of\nthe Skip-gram model is to find word representations that are\nuseful for predicting the surrounding words in a sentence or a\ndocument. More formally, given a sequence of training words\nw1, w2, . . . , wT , the objective of the Skip-gram model is to\nmaximize the average log probability\n1\nT\nTX\nt=1\nX\n−c≤j≤c,j̸=0\nlog p(wt+j|wt) (2)\nFig. 2: An illustration with Ransomware Feed Term\nwhere c is the size of the training context (which can be\na function of the center word wt). Larger c results in more\ntraining examples and thus can lead to a higher accuracy, at\nthe expense of the training time.\nThe basic Skip-gram formulation defines p(wt+j|wt) using\nthe softmax function:\np(wO|wI) = exp(v′\nwO\nT vwI )\nPW\nw=1 exp(v′w\nT vwI )\n(3)\nwhere vw and v′\nw are the ”input” and ”output” vector\nrepresentations of w, and W is the number of words in the\nvocabulary.\nUtilizing the word vector model, we map words from the\ncorpus into vectors within a hundred-dimensional vector space,\nformalizing the transformation as a function f : word 7→ R100.\nWe then use cosine similarity to compute the similarity score\nbetween input cyber terms and other terms. The similarity\nscore can be represented as:\nSimilarity(wp, wq) = vwp · vwq\n∥vwp∥∥vwq ∥ (4)\nHere, wp and wq represent two different words, and vwp and\nvwq are their respective word vectors obtained from the skip-\ngram model. The dot product in the numerator measures the\nsimilarity in the orientation of the vectors, and the denominator\nnormalizes the similarity by the magnitudes of the vectors.\nThis cosine similarity metric provides a measure of the direc-\ntional similarity between words in the vector space, ranging\nfrom 0 (completely dissimilar) to 1 (completely similar). This\napproach allows us to quantify the semantic relationships\nbetween cyber terms and other terms in our corpus, aiding\nin the analysis of the contextual associations between words.\nIn our Cyber Signal Discovery module, we adhere to two\nprincipal criteria for term selection: (1) Candidate terms must\nexhibit at least a 60% similarity score to the given cyber\nterm. (2) Candidate terms must not duplicate or merely extend\nthe existing entries in our cyber terminology database. Fig. 2\nillustrates this procedure using ’ransomware’ as an input term.\nIn the first iteration, terms such as ’LockBit’ and ’SickKids’\nthat score above the similarity threshold and are not already\ncataloged are identified. These are then subjected to human\nvalidation. For instance, ’LockBit’ is approved and subse-\nquently becomes a seed term for the next iteration, leading\nto the discovery of ’BlackCat’ and ’BianLian’ in subsequent\nrounds. This iterative process effectively enriches our database\nwith relevant and emerging cyber terms.\nB. Random Forest Silver Labeling\nSilver labeling is an innovative technique situated between\ngold standard annotations and unsupervised predictions. It is\nparticularly valuable in scenarios where acquiring labeled data\nis cost-prohibitive or logistically challenging. In our study,\nsilver labels were generated to extend our training dataset,\nenabling us to train supervised models with a more substantial\nand diverse set of examples than would be feasible with\nmanually annotated data alone.\nWe use the Random Forest algorithm for its ensemble ap-\nproach that averages predictions from multiple decision trees,\nreducing overfitting risks. It is particularly suited for our small\ndataset size, outperforming gradient boosting methods like\nXGBoost [32] and LightGBM [33] that typically require larger\ndatasets to avoid learning noise as patterns. We implemented\na Random Forest with 100 decision trees, optimized through\ncross-validation to ensure a balance between computational\nefficiency and predictive accuracy. The decision trees utilize\nEntropy as a measure to maximize split quality, defined as\nE(S) =\ncX\ni=1\n−pi log2 pi (5)\nwhere pi represents the probability of an element belonging\nto class i, and c is the number of classes.\nInformation Gain (IG), crucial for determining the most\ninformative feature at each split, is used in our model to guide\nthe decision-making process of the trees:\nIG(D, A) = E(D) −\nmX\nj=1\n|Dj|\n|D| E(Dj) (6)\nHere, IG(D, A) is the information gain from partitioning\ndataset D with feature A, E(D) is the dataset’s entropy, m is\nthe number of distinct values feature A can take, and E(Dj)\nis the entropy of the subset where A equals j. The term |Dj|\n|D|\nweights the entropy of each subset, indicating the proportion of\ninstances in subset Dj post-split. Information gain quantifies\nthe expected reduction in entropy upon learning the value of\nattribute A.\nC. CANAL\nCentral to our framework is CANAL (Cyber Activity News\nAlerting Language Model), a fine-tuned BERT [4] model\nmeticulously crafted for cyber news categorization. BERT’s\narchitecture includes multi-layer bidirectional transformer en-\ncoders, self-attention mechanisms, and feed-forward neural\nnetworks, which are adept at processing complex text.\nThe classifier layer is added atop the BERT model for\nclassification tasks. The final hidden state from BERT, denoted\nby h, with weights W and bias b, produces the output y via:\ny = f(W · h + b) (7)\nFig. 3: Illustration of CANAL with BERT Fine Tuning on\ncyber classification task.\nwhere f is the softmax activation function. Fine-tuning with\na lower learning rate using AdamW optimizer and a custom\nlearning rate scheduler is crucial to retain the pre-trained\nknowledge.\nThe softmax function for the classifier output is:\nsoftmax(yi) = eyi\nP\nj eyj\n(8)\nwhere yi is the output logit for class i.\nThe Fig. 3 presents a schematic of CANAL. The left section\noutlines the BERT Base Model structure, showcasing its dual\ntraining objectives: Next Sentence Prediction and Masked\nLanguage Model (LM) Prediction. These components process\nsequences of tokenized inputs, each sequence initiated with\na [CLS] token and interspersed with [SEP] tokens. In the\nright section, the BERT Classifier is depicted, which has been\nfine-tuned using a curated dataset specific to cyber-related\nnews for enhanced classification accuracy. The classifier also\nprocesses tokenized inputs through dense layers, ultimately\nyielding categorized outputs. This schematic encapsulates the\nmodel’s initial pre-training on diverse language data followed\nby its subsequent specialization through fine-tuning for cyber\nthreat detection and classification.\nWe explore several other fine-tuning techniques to opti-\nmize CANAL’s performance including Partial Finetuning with\nPEFT (Parameter-Efficient Fine-Tuning), and the integration of\nPEFT with LoRA (Low-Rank Adaptation).\n1) Parameter-Efficient Fine-Tuning (PEFT): We explore\nParameter-Efficient Fine-Tuning (PEFT) [34] for its efficiency\nin fine-tuning large LLMs. While full fine-tuning updates all\nparameters, partial fine-tuning in PEFT selectively freezes a\nportion of the model’s weights while fine-tuning the rest.\nThe fine-tuning process for both full and partial parameter\nupdates explores the performance impact on our multiclass\nclassification task, providing insights into the trade-offs be-\ntween computational efficiency and classification effective-\nness.\nFig. 4: An illustration of LoRA from an original paper [35]\n2) PEFT with LoRA: We also experiment with PEFT com-\nbined with Low-Rank Adaptation (LoRA) [35]. LoRA updates\na pre-trained weight matrix W0 with a low-rank decomposition\nW0 +∆W = W0 +BA, where B ∈ Rd×r and A ∈ Rr×k, and\nthe rank r ≪ min(d, k). As shown in figure 4, during training,\nW0 is frozen, while A and B contain trainable parameters. The\nmodified forward pass with LoRA is:\nh = W0x + ∆Wx = W0x + BAx (9)\nOur approach integrates BERT’s architecture with PEFT\nand LoRA fine-tuning for effective cyber multiclassification,\nas demonstrated in our methodology.\nD. Generative Models\nIn our investigation of cyber-related text classification, we\nbenchmark our model against three state-of-the-art language\nmodels that are at the forefront of NLP advancements. At\nthe time of writing, GPT-4 by OpenAI has emerged as a\nfrontrunner, leading the field with its remarkable capabilities\nin generating human-like text and is accessible through the\nOpenAI API. Alongside GPT-4, Llama 13B and Zephyr 7B\nBeta have made significant strides in the open-source space,\nexcelling across various NLP benchmarks. Below, we provide\nbrief introductions to the technical details of each model.\n1) GPT-4: GPT-4 [7], an advanced multimodal model,\nstands out in the realm of natural language processing, par-\nticularly in processing image and text inputs to generate text\noutputs. Its proficiency is highlighted in complex scenarios,\nsuch as human-designed exams, where it notably scored in the\ntop 10% in a simulated bar exam. Surpassing earlier versions\nlike GPT-3 and GPT-3.5, as well as other significant large\nlanguage models (LLMs) including Cloude, Llama, and PaLM,\nGPT-4 demonstrates exceptional capabilities across multiple\nlanguages in standard NLP benchmarks. This versatility and\nrobustness mark a new milestone in the evolution of language\nmodels.\n2) Llama 2 Chat (Unquantized): The Llama 2 Chat [8]\nmodel, a fine-tuned version of Llama 2 , is optimized for\ndialogue use cases and ranges from 7 × 109 to 7 × 1010\nparameters. Its training incorporates the pretraining of Llama\n2 with public online sources, followed by supervised fine-\ntuning, and further refinement through Reinforcement Learn-\ning with Human Feedback (RLHF), using rejection sam-\npling and Proximal Policy Optimization (PPO). The model\nadopts most architectural settings from Llama 1 , including\nthe standard transformer architecture with modifications like\npre-normalization using RMSNorm, the SwiGLU activation\nfunction [36], and rotary positional embeddings (RoPE). Ad-\nditionally, it features grouped-query attention and an increased\ncontext length, trained using the AdamW optimizer.\n3) Zephyr 7B Beta (Unquantized): The Zephyr language\nmodel [37], as detailed in the paper, represents a significant\nshift from the Llama 2 Chat model in its approach to train-\ning and alignment with user intent. Zephyr, specifically the\n7-billion parameter model Zephyr-7B, is designed to be a\nsmaller, more aligned model focusing on distilled supervised\nfine-tuning (dSFT) and distilled direct preference optimization\n(dDPO). Unlike Llama 2 Chat, Zephyr uses AI Feedback (AIF)\nfrom a set of teacher models for preference data, bypassing\nthe need for human annotation and additional sampling. This\napproach enables rapid training in just a few hours, setting a\nnew benchmark for 7B parameter chat models and surpassing\nthe performance of Llama 2 Chat on certain benchmarks.\nThese three language models, GPT-4, Llama 13B (unquan-\ntized), and Zephyr 7B Beta (unquantized), serve as bench-\nmarks in our evaluation, allowing us to assess the performance\nof our cyber-related text classification model in comparison to\nthe industry-leading and open-source state-of-the-art models\nin the field.\nE. Entity Relevance Module\nWe introduce the Entity Relevance Module as part of our\nsystem to enhance the processing of news articles by deter-\nmining the contextual relevance of identified entities within\nthe text. Unlike standard NER models that simply tag entities,\nthis module assesses their contextual significance within the\nnews titles.\nFor instance, in the statement ”Cyber attacks rise, says Y\nBank,” a traditional NER model would identify ”Y Bank” as an\nentity, but our module also evaluates its contextual relevance,\nrecognizing that ”Y Bank” is offering an opinion rather than\nbeing the central focus.\nThe model applies a sigmoid function to determine the\nprobability of relevance:\nP(Class 1 - Relevant ) = σ(W · Φ(input) + b) (10)\nwhere σ denotes the sigmoid activation function, W and b\nare the model weights and bias, and Φ(input) is the feature\nrepresentation of the input.\nWhile details of the training process are beyond this paper’s\nscope, in summary, the Entity Relevance Module is trained on\nlabeled data, producing probabilities that contribute to nuanced\nentity-centric analysis.\nV. T RAINING AND EVALUATION SCHEME\nA. Train-Test Data\n• Train Set Composition: The dataset utilized for training\nin this study was collated over a period extending from\nJanuary 2022 to September 2023. This comprehensive\ndataset comprises a diverse array of samples a total\nvolume of about 250000 samples.\n• Test Set Composition: In assessing the performance of\nCANAL, exclusive data from October 2023 was em-\nployed for the evaluation. Specifically, a subset compris-\ning 2000 articles from the articles of that month was\nsampled for testing.\nB. Data Labeling and Categorization\n• Gold Standard Dataset: A subset of 600 samples from\ntrain set was meticulously labeled by domain experts\nto establish a ’Gold Standard’ dataset. Special attention\nwas paid to addressing class imbalance through stratified\nsampling and weighting classes inversely proportional to\ntheir frequencies in the input data. This dataset served as a\nbenchmark for the initial Random Forest model training.\n• Silver Label Dataset using RF:\nThe Random Forest model, initially trained on the 600-\nsample ’Gold Standard’ dataset, was then applied to the\nremaining data spanning from 2022 to September 2023.\nThis step involved using the trained model to automate\nthe labeling process, thereby generating ’Silver Labels’\nfor a large volume of data. This approach enabled us with\nadditional 8,000 records, which exhibited a high degree\nof certainty in their labeling.\n• BERT Model Fine-Tuning Data: The selected sample\nset, enriched with both gold and silver labeled data,\nwas employed for the fine-tuning of a BERT based\nmodel. This subset was specifically chosen to represent\nthe population distribution accurately, ensuring that the\nmodel’s training would be reflective of the diverse char-\nacteristics present within the larger dataset. This step was\ncrucial for adapting the model to the specific nuances and\ncharacteristics of our dataset.\nC. Cyber Signal Discovery Module Training Scheme\nThe Emerging Cyber Signal Discovery Module is executed\non a monthly basis to identify novel cyber terms. Prior to each\nrun, the word vector model undergoes updates through the\nlatest news data. We conclude the process either after 10 runs\nor when our stopping criteria are met. These criteria include:\n(1) words exhibiting a similarity score greater than 60% to\nthe specified cyber term, and (2) words that neither duplicate\nnor merely extend the entries present in our cyber terminology\ndatabase. We halt the process at the occurrence of the first of\nthese conditions. This periodic assessment ensures the con-\ntinuous detection and incorporation of emerging cybersecurity\nterminology, contributing to the adaptability and efficacy of\nthe system in capturing evolving cyber threats.\nTABLE III: Random Forest Hyperparameters\nHyperparameter Value\nbootstrap True\ncriterion entropy\nmax depth 10\nmax features auto\nn estimators 100\nrandom state 42\nverbose 0\nwarm start False\nD. Random Forest Training Scheme\nOur Random Forest (RF) model was trained on a Gold Stan-\ndard dataset comprising 600 samples with expertly annotated\nlabels to establish a robust initial model. The hyperparameters\nof the model are listed in Table III. To counter potential bias in\nsilver label generation, we filtered our data retrieval with pre-\ncise SQL queries, ensuring a representative dataset for training.\nThis phase was critical for establishing a strong foundational\nmodel capable of further refinement and application on a larger\ndataset.\nE. Training Scheme for BERT fine-tuning\n1) Fine-Tuning Runs: We conducted a series of four distinct\nBERT fine-tuning runs, each with a specific configuration\naimed at exploring the effects of different levels of layer-\nwise training on model performance. The configurations for\nthe fine-tuning runs were as follows:\n• PeFT LoRA r=8: This run involved a Parameter efficient\nfine tuning (PeFT) approach with a Low-Rank Adaptation\n(LoRA) with a rank of 8, which creates adapter weight\nmatrices which are used in conjunction with complete\nmodel weights to work on classification task.\n• Last Layer + Classification Layer : The second run was\nconfined to training only the last layer of the BERT model\nin conjunction with the classification layer.\n• Last 2 Layers + Classification Layer : The third run\nextended the training to include the last two layers of the\nBERT model alongside the classification layer.\n• Full BERT Fine-Tuning : The final run encompassed a\ncomprehensive fine-tuning of the entire BERT model.\n2) Gradient Freezing: In our fine-tuning methodology, we\nemployed gradient freezing for all layers except the ones\nundergoing fine-tuning. This technique not only requires less\ncomputational power but also reduces the time needed for\nmodel training compared to full model fine-tuning. Gradient\nfreezing is a commonly adopted practice within the machine\nlearning community for its efficiency in fine-tuning deep\nlearning models.\n3) BERT Hyper parameters: The table IV provides final\nhyper-parameters used for BERT model fine tuning. A com-\nprehensive analysis of the training, validation cross entropy\nloss and recall trends across multiple epochs during the fine-\ntuning process of the BERT-based model is plotted in Fig. 5.\nThe x-axis represents the number of training epochs, ranging\nfrom 1 to 10. The y-axis denotes the cross entropy loss values\nTABLE IV: BERT Training Hyperparameters\nParameter Value\nlearning rate 2e-5\nper device train batch size 8\nper device eval batch size 8\ndata seed 727\nseed 767\nsave strategy epoch\nevaluation strategy epoch\nload best model at end True\nnum train epochs 10.0\nand recall values, which are computed for both the training\nand validation datasets.\nF . Prompt Engineering for LLMs\nIn our approach to classifying cyber news into five cate-\ngories, we iteratively refined prompt templates to enhance the\nunderstanding and performance of Language Large Models.\n• Template 1, Zero Shot: Basic Instruction Set\nOur initial template provided only the basic instruction\nand the five categories, relying on the LLMs’ inherent\ncapabilities to interpret and classify the content correctly.\nTemplate 1 Zero Shot:\nYou are a cyber analyst. You will be provided with\na sentence of news regarding different entities. The\nentity could be an organization, location, place,\nperson, or group. The sentence will be delimited\nwith #### characters. Classify the sentence into one\nof five categories and output the category name only.\nFive categories are:\n1) Recent Cyber Attack\n2) Cyber Litigation\n3) Cyber Attack Prevention\n4) Future Cyber Threat\n5) Other\nFig. 5: Illustration of training and validation Cross-Entropy\nloss over 10 epochs\n• Template 2, Zero Shot: Defined Criteria for Each\nCategory\nTo improve clarity, the second template incorporated\nspecific criteria for each category, particularly empha-\nsizing that the news should pertain to an identifiable\nentity in categories like Recent Cyber Attack, Litigation,\nPrevention, and Future Threat.\nTemplate 2 Zero Shot:\nYou are a cyber analyst. You will ... Classify the\nsentence into one of the following five categories,\nnow defined with specific criteria:\n1) Recent Cyber Attack: Sentences reporting on\nrecent cyber attacks targeting entities.\n2) Cyber Litigation: Sentences discussing legal\nactions, investigations, or charges related to\ncyber incidents.\n3) Cyber Attack Prevention: Sentences highlight-\ning positive actions, remedies, vulnerability\nfixes, and patches aimed at reducing the like-\nlihood of future cyber risks.\n4) Future Cyber Threat: Sentences addressing\npotential cyber risks and threats that organi-\nzations may face in the future.\n5) Other: Sentences encompassing a diverse\nrange of articles, including reports, studies,\neducational content, guidance materials, and\nmiscellaneous topics related to cybersecurity.\n• Template 2, Few Shots: Inclusion of Examples\nTo further assist the LLMs, we introduced examples in\nboth one-shot and few-shot formats for each category.\nThis approach was designed to further aid LLMs in\ngrasping our categorization criteria, providing concrete\ninstances as references.\nTemplate 2 with Few Shots:\nYou are a cyber analyst. You will ... Classify the\nsentence into one of the five categories and output\nthe category name only ...\nFive categories are:\n1) Recent Cyber Attack: Sentences reporting on\nrecent cyber attacks ...\n2) ...\n3) Other: Sentences encompassing a diverse\nrange of articles ...\nExamples for each category are:\n{\"sentence\": \"Royal Mail hit by cyber\nattack causing ’severe disruption’\nto services.\", \"category\": \"Recent\nCyber Attack\"},\n...\n{\"sentence\": \"Meta hit with 390 mn euro\nfine over EU data breaches\", \"\ncategory\": \"Cyber Litigation\"}\nVI. E VALUATION RESULTS\nA. Evaluation Metrics\nIn this section, we outline the performance metrics utilized\nto assess the models in our multi-class classification task.\nCANAL, finetuned BERT model, is designed to optimize\ncross-entropy loss across five cyber categories in a multi-\nclass categorization context. For a comparative analysis with\nother LLMs, where probability distributions are inaccessible,\nwe adopt standard metrics such as Precision, Recall, F1-\nScore, and Accuracy. These metrics are chosen for their clarity\nin conveying performance insights. Here below is a quick\nintroduction to all these metrics,\nCross-Entropy Loss (Log Loss): Quantifies the difference\nbetween predicted and actual class probabilities.\nLog Loss = − 1\nN\nNX\ni=1\nMX\nj=1\nyij log(pij) (11)\nHere, N is the number of instances, M is the number of\nclasses, yij is 1 if instance i is in class j, and pij is the\npredicted probability.\nPrecision: Evaluates the proportion of accurate positive\npredictions.\nPrecision = True Positives\nTrue Positives + False Positives (12)\nRecall: Measures the model’s ability to identify all positive\ninstances.\nRecall = True Positives\nTrue Positives + False Negatives (13)\nF1-Score: Balances precision and recall, providing a com-\nprehensive performance measure.\nF1-Score = 2 · Precision · Recall\nPrecision + Recall (14)\nAccuracy: Quantifies the overall correctness of the model’s\npredictions.\nAccuracy = Number of Correct Predictions\nTotal Number of Predictions (15)\nB. Evaluation Results\n1) Evaluation of Cyber Signal Discovery Module: The\nEmerging Cyber Signal Discovery Module operates with a\nhuman-in-the-loop moderation approach. During each itera-\ntion, the algorithm generates a set of signals on average,\nproportional to the quantity of novel cyber-related content\nin the news. Typically, 15-20% of these signals are accepted\nthrough human validation. Compared to the exhaustive manual\nselection of cyber terminology, our module demonstrates re-\nmarkable efficiency in terms of time savings and in discerning\nemerging cyber attack-related terms.\nFig. 6: Confusion matrix for a Random Forest classifier, with\ninstances exceeding a 0.98 probability threshold. Categories\nare represented with 0: ’Other’, 1: ’Prevention’, 2: ’Recent\nCyber Attack’, 3: ’Future Threat’, 4: ’Litigation’\n2) Evaluation of Random Forest Silver Labeling: We ap-\nplied various probability thresholds to the Random Forest\nclassifier, ultimately settling on a 0.98 cutoff for sample\ninclusion. This threshold, rigorously chosen, ensures that\nonly predictions with a confidence level of 0.98 or higher\nare considered. We ensured that this approach mirrors the\ndistribution observed in the full dataset, allowing us to cul-\ntivate a sample that closely aligns with gold standard data\nquality. The resulting subset, approximately 8,000 records\nstrong, showcases a high level of labeling confidence. Figure 6\npresents a confusion matrix for the Random Forest classifier,\ndemonstrating its accuracy when operating above this stringent\nconfidence threshold.\n3) Evaluation of BERT Fine-Tuning schemes: After ex-\namining the loss in Fig. 5 and the recall in Fig. 7 at\ncheckpoint 4 (epoch 4), the full fine-tuning of the BERT\nmodel demonstrated the best performance compared to other\nmethods. While the focus was on absolute performance in\nFig. 7: Recall scores for BERT Fine-Tuning Schemes\nFig. 8: Accuracy Improvements with Prompt Engineering\nwhich full fine-tuning excelled, it is worth noting that other\nconfigurations, such as fine-tuning only the last layer plus\nthe classifier and the last two layers plus the classifier , also\nshowed promising results. These strategies may be preferred in\nscenarios where computational resources are limited or when\nworking with very large models, where full fine-tuning would\nbe too resource-intensive.\n4) Evaluation of Expensive LLMs: Fig. 8 to Fig. 11 il-\nlustrate the performance of sophisticated language models\n(LLMs) in predicting various categories using different matri-\nces. The abbreviations in these figures are as follows: ZS for\nZero Shot, OS for One Shot, FS for Few Shot, T1 for Template\n1, and T2 for Template 2. Upon examination, both GPT-4\nand GPT-3.5 demonstrate a robust ability to identify cyber\nattacks, supported by high precision and recall. However, they\nencounter challenges in litigation, prevention, and future threat\nscenarios, where recall is exceptionally high but precision\nis relatively low. This suggests a tendency to over-identify\ninstances in litigation, prevention, and future threat, potentially\nleading to more false positives.\nIn Fig. 9 and Fig. 11, Llama 2 exhibits strong recall but\nlower precision in litigation and prevention scenarios under\nthe template 1 Zero Shot, mirroring the behavior observed in\nGPT-4 and GPT-3.5. Notably, when presented with additional\nexamples, there is a noticeable improvement in precision,\nsignifying the model’s ability to learn from these examples\nand reduce false positive predictions in both litigation and\nprevention categories.\nIn the context of Zephyr 7B, it is noteworthy that the\nFig. 9: Precision Improvements with Prompt Engineering\nFig. 10: F1 scores Improvements with Prompt Engineering\napplication of prompt engineering yields more benefits com-\npared to other LLMs. This insight is illustrated in Fig. 10,\nwhere when prompt engineering is applied, its F1 scores\nfor litigation, prevention, future threat, and other categories\nshow more significant improvement than those of other LLMs.\nAdditionally, it is noticed that the results produced by Zephyr\ndeviate from the desired structure, requiring extra time and\neffort for the extraction of predictions.\nIn our comparative analysis, GPT-4 emerged as a front-\nrunner among the LLMs, yet the overall performance of\nthese models did not meet our expectations. As Table V\nshows, none achieved an F1 score above 82% in any category.\nThis suggests that despite the use of prompt engineering to\nenhance task understanding, these models still face challenges\nin fully grasping the tasks. Notably, a closer examination of\nfalse positives revealed a tendency for incorrect predictions\nin samples with ambiguous content or lacking specific entity\nreferences, even with explicit instructions. This finding points\nto a critical area for improvement in terms of the LLMs ability\nto discern and interpret nuanced or incomplete information.\n5) CANAL vs Other Expensive LLMs: In the comparative\nevaluation between our framework, CANAL, and other ex-\npensive LLMs, CANAL emerges as the superior performer\nacross all five assessed categories. For categories with very few\nsamples, such as prevention and the future threat category, we\nexpected these highly capable LLMs to perform well due to\ntheir training on large datasets. However, CANAL outperforms\nthe expensive LLMs in these categories. In Table V, the accu-\nracy of CANAL for the prevention category is approximately\nFig. 11: Recall Improvements with Prompt Engineering\nTABLE V: Model Performance Comparison\nModel Category Accuracy Precision Recall F1-Score\nGPT-3.5 Cyber Attack 58.67 90.26 62.63 73.95\nFS Litigation 27.35 27.35 100.00 42.95\nPrevention 35.00 39.87 74.12 51.85\nFuture Threat 25.00 37.70 42.59 40.00\nOther 65.25 87.93 71.66 78.97\nGPT-4 Cyber Attack 66.67 81.78 78.29 80.00\nFS Litigation 42.86 44.12 93.76 60.00\nPrevention 46.67 55.75 74.13 63.64\nFuture Threat 31.40 36.19 70.37 47.80\nOther 68.39 94.14 71.43 81.23\nLlama 13B Cyber Attack 62.43 87.93 71.66 78.97\nFS Litigation 52.08 60.98 78.13 68.49\nPrevention 38.14 57.69 52.94 55.21\nFuture Threat 18.64 25.58 40.74 31.43\nOther 63.75 87.68 70.02 77.86\nZephyr 7B Cyber Attack 58.81 71.15 77.22 74.06\nFS Litigation 38.89 77.78 43.75 56.00\nPrevention 45.74 57.28 69.41 62.77\nFuture Threat 19.54 34.00 31.48 32.69\nOther 70.42 86.45 79.16 82.64\nCANAL Cyber Attack 81.44 83.69 96.80 89.77\nLitigation 88.24 93.75 93.75 93.75\nPrevention 60.82 83.10 69.41 75.64\nFuture Threat 47.37 90.00 50.00 64.29\nOther 86.37 93.35 92.04 92.69\nNote. The best results in each category are highlighted in bold,\nwhile the second-best results are underlined. FS stands for Few\nShots.\n13% higher than that of GPT-4 Few Shots, and the accuracy of\nCANAL for the future threat category is around 16% higher\nthan that of GPT-4 FS.\nConversely, in categories with a more substantial number\nof training samples, such as recent cyber attack and other\ncategory, CANAL exhibits even more exceptional perfor-\nmance than other LLMs. In the recent cyber attack category,\nwhere GPT-4 attains the highest accuracy among all high\nparameter LLMs with approximately 67%, CANAL surpasses\nthis performance with an impressive accuracy of about 81%.\nSimilarly, in the Other category, where Zephyr 7B leads with\naround 70% accuracy among LLMs, CANAL outshines with\na superior accuracy of about 86%. These findings underscore\nCANAL’s robust and consistently superior performance across\ndiverse categories, reinforcing its efficacy in handling nuanced\nlanguage tasks.\nIn Table VI, we provide an empirical comparison of in-\nference time and cost for processing 10,000 articles between\nCANAL and other LLMs. Our results show that CANAL\nis highly efficient and cost-effective. Cost estimations are\nbased on the current OpenAI API pricing [38] and the lowest\navailable A100 & T4 usage rates, approximately $1/hour &\n$0.071/hour respectively [39] [40] at the time of writing.\nCANAL not only processes data faster but also maintains\nminimal operational costs, emphasizing its viability for large-\nscale applications.\nTABLE VI: Comparison of Models for Processing 10,000\nArticles\nModel Inference Time (hr) Infrastructure Inference Cost ($)\nGPT-3.5 1.33 OpenAI API 4.4\nGPT-4 2.50 OpenAI API 84.5\nLlama 13B 7.83 A100 (48 GB) 10.2\nZyphyr 7B 2.83 A100 (48 GB) 3.0\nCANAL 0.067 T4 (16 GB) 0.0047\nTABLE VII: Example classification snippets.\nCyber News CANAL + Cyber Signal Detec-\ntion + Entity Relevance\nMcLaren Health Care Facing 3\nLawsuits in Ransomware...\nMcLaren Health Care Facing 3\nLawsuits in Ransomware Hack -\nClass - Litigation\nSeiko confirms thousands of user\naccounts were ...\nSeiko confirms thousands of user\naccounts were breached in cyber-\nattack - Class - Cyber Attack\nMicrosoft fixes over 100 vulnera-\nbilities, 2 act...\nMicrosoft fixes over 100 vulnera-\nbilities, 2 actively exploited bugs -\nClass - Prevention\nBuffer overflow bug gives root on\npotentially millions...\nBuffer overflow bug gives root on\npotentially millions of Linux boxes\n- The Stack - Class - Future Threat\nMastercard introduces new grocery\ndelivery and ...\nMastercard introduces new gro-\ncery delivery and streaming perks\n- CNBC - Class - Other\n6) CANAL in action: In Table VII, we exhibit the cul-\nmination of our multifaceted analysis pipeline. Our dual ap-\nproach begins with key element extraction: identifying relevant\nentities (marked in red) via an entity relevance model and\npinpointing cyber signals (highlighted in blue) through our\ncontinually updated cyber taxonomy. Subsequently, CANAL is\ndeployed for cyber news classification. This integrated process\nenables us to construct in-depth cyber risk profiles, leveraging\nnews data tailored to specific entities.\nVII. C ONCLUSION\nWe have successfully demonstrated that our framework,\nuniquely trained using a silver labeling approach with just\n600 manually labeled data points, excels in 5-class cyber\nnews categorization. CANAL not only outperforms current top\nLarge Language Models in this specific task but also provides\na more cost-efficient and empirical approach. Additionally,\nour detailed comparison reveals how existing industry LLMs\nperform in cyber categorization tasks and suggests that their\nefficacy can be further enhanced through prompt engineering\ntechniques. Furthermore, we showcased the effectiveness of\nour Cyber Signal Discovery module in identifying emerg-\ning cyber signals. Future research may focus on leveraging\nadvancements in cost-effective and smaller-sized empirical\nLLMs, specifically tailored to the dynamic requirements of\ncyber categorization.\nREFERENCES\n[1] ISACA, “State of cybersecurity 2023,” https://www.isaca.org/resources/\nreports/state-of-cybersecurity-2023, 2023, accessed: 2023-11-01.\n[2] “Ransomware attacks on healthcare organizations,” https://www.sophos\n.com/en-us/press/press-releases/2023/11/cybercriminals-successfully-e\nncrypted-data-ransomware-attacks-nearly, 2023, accessed: 2023-11-01.\n[3] “The education sector reports the highest rate of ransomware attacks,\nsophos survey finds,” https://www.sophos.com/en-us/press/press-rel\neases/2023/07/the-state-of-ransomware-in-education, 2023, accessed:\n2023-11-01.\n[4] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training\nof deep bidirectional transformers for language understanding,” 2019.\n[5] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena,\nY . Zhou, W. Li, and P. J. Liu, “Exploring the limits of transfer learning\nwith a unified text-to-text transformer,” 2023.\n[6] J. Wei, M. Bosma, V . Y . Zhao, K. Guu, A. W. Yu, B. Lester, N. Du,\nA. M. Dai, and Q. V . Le, “Finetuned language models are zero-shot\nlearners,” 2022.\n[7] OpenAI, “Gpt-4 technical report,” 2023.\n[8] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y . Babaei,\nN. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, D. Bikel, L. Blecher,\nC. C. Ferrer, M. Chen, G. Cucurull, D. Esiobu, J. Fernandes, J. Fu,\nW. Fu, B. Fuller, C. Gao, V . Goswami, N. Goyal, A. Hartshorn,\nS. Hosseini, R. Hou, H. Inan, M. Kardas, V . Kerkez, M. Khabsa,\nI. Kloumann, A. Korenev, P. S. Koura, M.-A. Lachaux, T. Lavril, J. Lee,\nD. Liskovich, Y . Lu, Y . Mao, X. Martinet, T. Mihaylov, P. Mishra,\nI. Molybog, Y . Nie, A. Poulton, J. Reizenstein, R. Rungta, K. Saladi,\nA. Schelten, R. Silva, E. M. Smith, R. Subramanian, X. E. Tan, B. Tang,\nR. Taylor, A. Williams, J. X. Kuan, P. Xu, Z. Yan, I. Zarov, Y . Zhang,\nA. Fan, M. Kambadur, S. Narang, A. Rodriguez, R. Stojnic, S. Edunov,\nand T. Scialom, “Llama 2: Open foundation and fine-tuned chat models,”\n2023.\n[9] A. Q. Jiang, A. Sablayrolles, A. Mensch, C. Bamford, D. S. Chaplot,\nD. de las Casas, F. Bressand, G. Lengyel, G. Lample, L. Saulnier,\nL. R. Lavaud, M.-A. Lachaux, P. Stock, T. L. Scao, T. Lavril, T. Wang,\nT. Lacroix, and W. E. Sayed, “Mistral 7b,” 2023.\n[10] Anthropic, “Model Card: Claude,” https://www-files.anthropic.com/pro\nduction/images/Model-Card-Claude-2.pdf, 2023.\n[11] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts,\nP. Barham, H. W. Chung, C. Sutton, S. Gehrmann, P. Schuh, K. Shi,\nS. Tsvyashchenko, J. Maynez, A. Rao, P. Barnes, Y . Tay, N. Shazeer,\nV . Prabhakaran, E. Reif, N. Du, B. Hutchinson, R. Pope, J. Bradbury,\nJ. Austin, M. Isard, G. Gur-Ari, P. Yin, T. Duke, A. Levskaya, S. Ghe-\nmawat, S. Dev, H. Michalewski, X. Garcia, V . Misra, K. Robinson, L. Fe-\ndus, D. Zhou, D. Ippolito, D. Luan, H. Lim, B. Zoph, A. Spiridonov,\nR. Sepassi, D. Dohan, S. Agrawal, M. Omernick, A. M. Dai, T. S. Pillai,\nM. Pellat, A. Lewkowycz, E. Moreira, R. Child, O. Polozov, K. Lee,\nZ. Zhou, X. Wang, B. Saeta, M. Diaz, O. Firat, M. Catasta, J. Wei,\nK. Meier-Hellstern, D. Eck, J. Dean, S. Petrov, and N. Fiedel, “Palm:\nScaling language modeling with pathways,” 2022.\n[12] OpenAI, “ChatGPT: A large-scale generative model for language\nunderstanding,” 2022. [Online]. Available: https://chat.openai.com/\n[13] Google, “Bard: conversational generative artificial intelligence chatbot\ndeveloped by google,” 2023. [Online]. Available: https://bard.google.co\nm/\n[14] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nL. Kaiser, and I. Polosukhin, “Attention is all you need,” 2023.\n[15] D. Araci, “Finbert: Financial sentiment analysis with pre-trained lan-\nguage models,” 2019.\n[16] S. Wu, O. Irsoy, S. Lu, V . Dabravolski, M. Dredze, S. Gehrmann,\nP. Kambadur, D. Rosenberg, and G. Mann, “Bloomberggpt: A large\nlanguage model for finance,” 2023.\n[17] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal,\nA. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-\nV oss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. M. Ziegler,\nJ. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray,\nB. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever,\nand D. Amodei, “Language models are few-shot learners,” 2020.\n[18] P. Ganesh, Y . Chen, X. Lou, M. A. Khan, Y . Yang, H. Sajjad, P. Nakov,\nD. Chen, and M. Winslett, “Compressing large-scale transformer-based\nmodels: A case study on bert,” Transactions of the Association for\nComputational Linguistics , vol. 9, p. 1061–1080, 2021. [Online].\nAvailable: http://dx.doi.org/10.1162/tacl a 00413\n[19] L. Floridi and M. C. Chiriatti, “Gpt-3: Its nature, scope, limits, and\nconsequences,” Minds & Machines , vol. 30, pp. 681–694, 12 2020.\n[Online]. Available: https://doi.org/10.1007/s11023-020-09548-1\n[20] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai,\nE. Rutherford, D. de Las Casas, L. A. Hendricks, J. Welbl, A. Clark,\nT. Hennigan, E. Noland, K. Millican, G. van den Driessche, B. Damoc,\nA. Guy, S. Osindero, K. Simonyan, E. Elsen, J. W. Rae, O. Vinyals, and\nL. Sifre, “Training compute-optimal large language models,” 2022.\n[21] E. Nwafor and H. Olufowobi, “Canbert: A language-based intrusion de-\ntection model for in-vehicle networks,” in 2022 21st IEEE International\nConference on Machine Learning and Applications (ICMLA) , 2022, pp.\n294–299.\n[22] A. Rahali and M. A. Akhloufi, “Malbertv2: Code aware bert-based\nmodel for malware identification,” Big Data and Cognitive Computing ,\nvol. 7, no. 2, 2023. [Online]. Available: https://www.mdpi.com/2504-2\n289/7/2/60\n[23] S. Chen and H. Liao, “Bert-log: Anomaly detection for system\nlogs based on pre-trained language model,” Applied Artificial\nIntelligence, vol. 36, no. 1, p. 2145642, 2022. [Online]. Available:\nhttps://doi.org/10.1080/08839514.2022.2145642\n[24] K. Ameri, M. Hempel, H. Sharif, J. Lopez Jr., and K. Perumalla,\n“Cybert: Cybersecurity claim classification by fine-tuning the bert\nlanguage model,” Journal of Cybersecurity and Privacy , vol. 1, no. 4,\npp. 615–637, 2021. [Online]. Available: https://www.mdpi.com/2624-8\n00X/1/4/31\n[25] S. Yesir and I. Sogukpinar, “Malware detection and classification using\nfasttext and bert,” in 2021 9th International Symposium on Digital\nForensics and Security (ISDFS) , 2021, pp. 1–6.\n[26] E. Aghaei, X. Niu, W. Shadid, and E. Al-Shaer, “Securebert: A domain-\nspecific language model for cybersecurity,” 2022.\n[27] Y . Erkal, M. Sezgin, and S. Gunduz, “A new cyber security alert system\nfor twitter,” in 2015 IEEE 14th International Conference on Machine\nLearning and Applications (ICMLA) , 2015, pp. 766–770.\n[28] M. Abdullahi, Y . Baashar, H. Alhussian, A. Alwadain, N. Aziz, L. F.\nCapretz, and S. J. Abdulkadir, “Detecting cybersecurity attacks in\ninternet of things using artificial intelligence methods: A systematic\nliterature review,” Electronics, vol. 11, no. 2, 2022. [Online]. Available:\nhttps://www.mdpi.com/2079-9292/11/2/198\n[29] T. Riebe, T. Wirth, M. Bayer, P. K ¨uhn, M.-A. Kaufhold, V . Knauthe,\nS. Guthe, and C. Reuter, “Cysecalert: An alert generation system for\ncyber security events using open source intelligence data,” inInformation\nand Communications Security , D. Gao, Q. Li, X. Guan, and X. Liao,\nEds. Cham: Springer International Publishing, 2021, pp. 429–446.\n[30] M. T. Alam, D. Bhusal, Y . Park, and N. Rastogi, “Cyner: A python\nlibrary for cybersecurity named entity recognition,” 2022.\n[31] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean,\n“Distributed representations of words and phrases and their composi-\ntionality,” Advances in neural information processing systems , vol. 26,\n2013.\n[32] T. Chen and C. Guestrin, “Xgboost,” Proceedings of the 22nd\nACM SIGKDD International Conference on Knowledge Discovery\nand Data Mining - KDD ’16 , 2016. [Online]. Available: http:\n//dx.doi.org/10.1145/2939672.2939785\n[33] G. Ke, Q. Meng, T. Finley, T. Wang, W. Chen, W. Ma, Q. Ye, and T.-\nY . Liu, “Lightgbm: A highly efficient gradient boosting decision tree,”\nAdvances in neural information processing systems , vol. 30, 2017.\n[34] H. Liu, D. Tam, M. Muqeeth, J. Mohta, T. Huang, M. Bansal, and\nC. Raffel, “Few-shot parameter-efficient fine-tuning is better and cheaper\nthan in-context learning,” 2022.\n[35] E. J. Hu, Y . Shen, P. Wallis, Z. Allen-Zhu, Y . Li, S. Wang, L. Wang,\nand W. Chen, “Lora: Low-rank adaptation of large language models,”\n2021.\n[36] N. Shazeer, “Glu variants improve transformer,” arXiv preprint\narXiv:2002.05202, 2020.\n[37] L. Tunstall, E. Beeching, N. Lambert, N. Rajani, K. Rasul, Y . Belkada,\nS. Huang, L. von Werra, C. Fourrier, N. Habib, N. Sarrazin, O. San-\nseviero, A. M. Rush, and T. Wolf, “Zephyr: Direct distillation of lm\nalignment,” 2023.\n[38] “OpenAI Pricing,” https://openai.com/pricing, accessed: 2023-11-21.\n[39] “GPU Pricing,” https://www.databricks.com/blog/2021/12/15/are-gpus-r\neally-expensive-benchmarking-gpus-for-inference-on-the-databricks-c\nlusters.html, accessed: 2023-11-21.\n[40] “GPU Pricing,” https://lambdalabs.com/service/gpu-cloud#pricing,\naccessed: 2023-11-21.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.5105072259902954
    },
    {
      "name": "Computer security",
      "score": 0.40439650416374207
    },
    {
      "name": "Business",
      "score": 0.3543948829174042
    }
  ],
  "institutions": [],
  "cited_by": 5
}