{
  "title": "DistilBERT: A Novel Approach to Detect Text Generated by Large Language Models (LLM)",
  "url": "https://openalex.org/W4391450222",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A4378562786",
      "name": "BV Pranay Kumar",
      "affiliations": [
        "Kakatiya University"
      ]
    },
    {
      "id": "https://openalex.org/A5065620244",
      "name": "MD Shaheer Ahmed",
      "affiliations": [
        "Christ University"
      ]
    },
    {
      "id": "https://openalex.org/A3161029205",
      "name": "Manchala Sadanandam",
      "affiliations": [
        "Kakatiya University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4379140845",
    "https://openalex.org/W4360939370",
    "https://openalex.org/W4327640446",
    "https://openalex.org/W4318263917",
    "https://openalex.org/W4389437456",
    "https://openalex.org/W4386874840",
    "https://openalex.org/W4389519574",
    "https://openalex.org/W4378765257",
    "https://openalex.org/W4387339568",
    "https://openalex.org/W4385812794",
    "https://openalex.org/W3021395787",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2060209952",
    "https://openalex.org/W2996428491",
    "https://openalex.org/W4385605307",
    "https://openalex.org/W4391158414",
    "https://openalex.org/W2980708516"
  ],
  "abstract": "Abstract Large language models (LLMs) have emerged as powerful tools for generating human-quality text, raising concerns about their potential for misuse in academic settings. This paper investigates the use of DistilBERT, a distilled version of BERT, for detecting LLM-generated text. We evaluate its performance on two publicly available datasets, LLM-Detect AI Generated Text and DAIGT-V3 Train Dataset, achieving an average accuracy of around 94%. Our findings suggest that DistilBERT is a promising tool for safeguarding academic integrity in the era of LLMs.",
  "full_text": "DistilBERT: A Novel Approach to Detect Text\nGenerated by Large Language Models (LLM)\nBV Pranay Kumar  (  pranaybv4u@gmail.com )\nKakatiya University\nMD Shaheer Ahmed \nChristu Jyothi Institute of Technology and Science\nManchala Sadanandam \nKakatiya University\nResearch Article\nKeywords: DistilBert, BERT, LLM, Transformer, LLM-generated text, ChatGPT\nPosted Date: February 1st, 2024\nDOI: https://doi.org/10.21203/rs.3.rs-3909387/v1\nLicense:   This work is licensed under a Creative Commons Attribution 4.0 International License.  \nRead Full License\nAdditional Declarations: No competing interests reported.\nDistilBERT: A Novel Approach to Detect Text Generated by\nLarge Language Models (LLM)\nBV Pranay Kumar1,2*, MD Shaheer Ahmed2,3† and Manchala Sadanandam1,2†\n1*Department of Computer Science and Engineering, Kakatiya University , Warangal,\n506009, Telangana, India.\n1*Department of Computer Science and Engineering, Christu Jyothi Ins titute of\nTechnology and Science, Jangaon, 506167, Telangana, India.\n2Department of Computer Science and Engineering, Christu Jyothi Ins titute of\nTechnology and Science, Jangaon, 506167, Telangana, India.\n3Department of Computer Science and Engineering, Kakatiya University , Warangal,\n506009, Telangana, India.\n*Corresponding author(s). E-mail(s): pranaybv4u@gmail.com;\nContributing authors: shaheerhasidea@gmail.com; sadanb4u@gmail.com;\n†These authors contributed equally to this work.\nAbstract\nLarge language models (LLMs) have emerged as powerful tools for ge nerating human-quality text,\nraising concerns about their potential for misuse in academic s ettings. This paper investigates the\nuse of DistilBERT, a distilled version of BERT, for detecting LL M-generated text. We evaluate its\nperformance on two publicly available datasets, LLM-Detect AI Generated Text and DAIGT-V3 Train\nDataset, achieving an average accuracy of around 94%. Our ﬁnding s suggest that DistilBERT is a\npromising tool for safeguarding academic integrity in the era of LL Ms.\nKeywords: DistilBert, BERT, LLM, Transformer, LLM-generated text, C hatGPT\n1 Introduction\nThe rapid evolution of Large Language Models\n(LLMs)[\n1] presents both remarkable opportuni-\nties and signiﬁcant challenges for academic set-\ntings, including higher education and research.\nWith their ﬂuency and factuality, LLMs hold\npromise for tasks like generating content, sum-\nmarizing research, and automating administra-\ntive processes[\n2]. However, their ability to mimic\nhuman writing raises concerns about potential\nmisuse in ﬁelds like scientiﬁc authorship, where\nauthenticity and integrity are paramount. For edu-\ncators, distinguishing student-generated text from\nLLM outputs becomes crucial in ensuring the\nvalidity of assignments and assessments.\nAddressing these concerns lies in develop-\ning reliable methods for detecting LLM-generated\ntext. Among the popular LLMs, the Bidirec-\ntional Encoder Representations from Transform-\ners (BERT) [\n3] model stands out for its high per-\nformance in various natural language processing\ntasks. However, its immense size and computa-\ntional complexity limit its widespread adoption\n1\nin real-time applications. This is where Distil-\nBERT [\n4] emerges as a compelling alternative. A\nsmaller, faster, and more resource-eﬃcient version\nof BERT, DistilBERT inherits its predecessor’s\ncapabilities while oﬀering broader accessibility\nand lower deployment costs [\n5].\nThis research investigates the potential of Dis-\ntilBERT in tackling the crucial task of LLM\ngenerated text detection. We delve into evaluating\nits performance against human-written and LLM-\ngenerated text, focusing on its ability to accu-\nrately discern the origin of a given text sample.\nThe ﬁndings aim to shed light on DistilBERT’s\nsuitability as a practical solution for safeguarding\nacademic integrity and empowering educators in\na landscape increasingly inﬂuenced by advanced\nlanguage models.\n1.1 Concerns with LLM generated\ntext\nWhile LLMs like ChatGPT [\n6], Bard [ 7], and\nClaude [ 8] oﬀer mesmerizing capabilities, their\nvery strengths pose inherent dangers, particu-\nlarly in academic settings. These models excel at\ngenerating text that is not only grammatically\ncorrect and stylistically cohesive but also often\ninfused with factual details gleaned from vast\ndatasets. This ability to ”hallucinate [\n9]” knowl-\nedge, weave intricate narratives, and even engage\nin self-referential loops, aptly dubbed the ”Curse\nof Recursion[\n10],” presents a two-fold threat:\n1. Deception and Plagiarism [ 11]: The\nease with which LLMs can mimic human writing\nopens the door to a wave of academic dishonesty.\nImagine an essay composed entirely by an LLM,\nseamlessly integrated with citations and seemingly\nbacked by factual evidence. Unwary educators and\nplagiarism detection systems might struggle to\nidentify such fabrications, potentially undermin-\ning the entire foundation of academic trust and\nintellectual merit.\n2. Erosion of Critical Thinking [\n12]: The\nabundance of readily available, machine-generated\n”knowledge” risks fostering a culture of intellec-\ntual dependence. Students accustomed to relying\non LLMs for summaries, research assistance, and\neven essay writing might lose the crucial skills\nof critical evaluation, independent thought, and\noriginal argumentation. This could lead to a gen-\neration ill-equipped to navigate the complexities\nof information overload and discern truth from\nﬁction.\nTherefore, developing robust methods for\ndetecting LLM-generated text is not just a tech-\nnological challenge but an ethical imperative. It is\nabout safeguarding the very essence of academic\nendeavor - the pursuit of genuine understanding,\nhonest inquiry, and the independent construction\nof knowledge. DistilBERT, with its potential for\neﬃcient and accurate LLM detection, emerges as\na promising tool in this crucial ﬁght. By empow-\nering educators and upholding academic integrity,\nwe can ensure that the transformative power of\nlanguage models is harnessed for good, fostering a\nfuture where technology augments human intellect\nrather than supplants it.\n2 Experimental Setup\n2.1 Datasets\nTwo datasets were utilized in this research: the\n“LLM - Detect AI Generated Text” dataset and\nthe “DAIGT-V3 Train Dataset”.\nThe “LLM - Detect AI Generated Text”\ndataset, available on\nKaggle, comprises a collec-\ntion of essays, some authored by students and\nothers generated by various large language models\n(LLMs). The objective of the dataset is to iden-\ntify whether a particular essay was produced by an\nLLM. It includes around 10,000 essays, all penned\nin response to one of seven essay prompts. The\nessays from two prompts form the training set,\nwhile the rest make up the hidden test set. Almost\nall training set essays were written by students,\nwith only a few LLM-generated essays provided as\nexamples.\nThe “LLM - Detect AI Generated Text”\ndataset includes three CSV ﬁles:\n• train\nprompts.csv: Contains prompts used to\ngenerate the essays in the training set.\n• train essays.csv: Contains 1378 unique val-\nues and four columns (‘id‘, ‘prompt id‘, ‘text‘,\n‘generated‘). The ‘generated‘ column indicates\nwhether the text was generated by an LLM.\n• test\nessays.csv: Contains three columns (‘id‘,\n‘prompt id‘, ‘text‘).\nOn the other hand, the “DAIGT-V3 Train\nDataset”, accessible on Kaggle, is designed to\n2\ntrain and evaluate models for detecting LLM-\ngenerated text. This dataset includes 20,000\nhuman-written essays and 20,000 LLM-generated\nessays. Like the “LLM - Detect AI Generated\nText” dataset, the essays in this dataset are writ-\nten in response to a variety of prompts, which are\nalso provided in the dataset. The dataset includes\ntwo CSV ﬁles:\n• test\nv3 drcat 01.csv: Contains ﬁve columns\n(‘text‘, ‘label‘, ‘prompt name‘, ‘source‘,\n‘RDizzl3 seven‘).\n• train v3 drcat 02.csv: Contains six columns\n(‘text‘, ‘label‘, ‘prompt name‘, ‘source‘,\n‘RDizzl3 seven‘, ‘model‘).\nBoth datasets provide valuable data for train-\ning and evaluating models capable of distinguish-\ning between human-written and AI-generated\ntext.\n2.2 Software Setup\nThe proposed methods of this study were imple-\nmented using Python programming language. The\nproposed method was implemented using Hug-\nging face transformers class embedded in Python.\nThe libraries used and their respective versions\nare TensorFlow version 2.12.0, Keras version 0.1.7,\nKerasNLP version 0.6.1, NumPy version 1.23.5,\nPandas version 2.0.3, scikit-learn version 1.1.3,\nmatplotlib version 3.7.3, and seaborn version\n0.14.1.\n2.3 Data Preprocessing\nData preprocessing is a vital stage in any machine\nlearning endeavor, particularly when dealing with\ntext data. It involves cleaning the data and prepar-\ning it for the model. In the realm of Natural\nLanguage Processing (NLP)[\n13], text data can\ncontain noise in various forms such as emotions,\npunctuation, and text in diﬀerent cases.\nFor the ”LLM - Detect AI Generated Text”\nand ”DAIGT-V3 Train Dataset”, several prepro-\ncessing steps were undertaken. Initially, all the\ntext was converted to lowercase to ensure uni-\nformity and prevent duplication due to case dif-\nferences. Subsequently, punctuation marks and\nnumbers were removed from the text as they often\ndo not contribute meaningful information for the\ntask at hand.\nNext, common words, known as stopwords,\nthat do not carry much meaning were eliminated.\nThese often include words like ’is’, ’the’, ’and’,\netc. Following this, techniques known as stemming\nand lemmatization were used to reduce words to\ntheir root form. For instance, ’running’ might be\nreduced to ’run’. This step aids in grouping sim-\nilar words together. Lastly, extra white spaces in\nthe text were removed to clean up the text.\nBy applying these preprocessing steps, the text\ndata was made more suitable for the subsequent\nmachine learning model, thereby enhancing the\nmodel’s ability to extract useful features from the\ntext and improve its predictive performance\n3 Methodology\n3.1 Models\nThe primary model used in this research\nis DistilBERT, speciﬁcally the dis-\ntil\nbert base uncased variant. DistilBERT\nis a distilled version of BERT (Bidirectional\nEncoder Representations from Transformers), a\ntransformer-based machine learning technique for\nnatural language processing tasks.\nBERT is a powerful language model that\nhas signiﬁcantly improved the state-of-the-art on\nmany Natural Language Processing tasks. How-\never, it is also quite large, with models containing\nbillions of parameters [\n14] and being trained on\nmassive datasets. As a result, using BERT for pro-\nduction applications can be challenging due to the\nhigh computational requirements for training and\ninference.\nFig. 1 Architecture of DistilBERT\n3\nThe architecture of DistilBERT is shown in\nFigure 1. DistilBERT addresses these issues by\ncreating a smaller, faster, and cheaper version of\nBERT. It achieves this by using a process known\nas distillation, where a larger model (the teacher)\ntransfers its knowledge to a smaller model (the\nstudent). The student model is trained to mimic\nthe output of the teacher model, thus retaining\nmost of its performance while reducing its size and\ncomputational requirements.\nThe distil\nbert base uncased [] variant of\nDistilBERT is pre-trained on the same corpus as\nthe BERT base model in a self-supervised manner.\nThis means it was trained on raw texts without\nany human labeling, using an automatic process\nto generate inputs and labels from those texts\nusing the BERT base model. It was trained with\nthree objectives: distillation loss, masked language\nmodeling (MLM) [\n15], and cosine embedding loss.\nFig. 2 Flow diagram of DistilBERT\nCompared to BERT, DistilBERT retains more\nthan 95% of the performance of BERT while\nhaving 40% fewer parameters. In terms of infer-\nence time, DistilBERT is more than 60% faster\nand requires 40% less memory than BERT. These\nadvantages make DistilBERT a highly eﬀective\nchoice for many NLP tasks, especially in scenarios\nwhere computational resources are limited.\nThe Figure\n2 depicts the DistilBERT classi-\nﬁcation process for identifying whether a given\ntext was written by a human or generated by\na machine. First, the input text is divided into\nindividual tokens (words or sub-words) and then\nconverted into numerical representations called\nembeddings. These embeddings are then fed into\nmultiple attention layers that analyze the relation-\nships between the tokens. Finally, a classiﬁcation\nlayer determines the ﬁnal outcome, classifying\nthe text as either human-written or machine-\ngenerated.\n3.2 Metrics of Evaluation\nThe performance of the models was evaluated\nusing four key metrics: accuracy, precision, recall,\nand the F1 score. These metrics were calculated\nbased on the True Positive (TP), True Negative\n(TN), False Positive (FP), and False Negative\n(FN) values derived from the model’s predictions.\nAccuracy was computed as the ratio of cor-\nrect predictions (both true positives and true\nnegatives) to the total number of instances. This\ngives us an overall measure of how often the model\nis correct in its predictions.\nAccuracy = T P+ T N\nT P+ T N+ F P+ F N (1)\nPrecision was deﬁned as the proportion of\ntrue positive predictions out of all positive predic-\ntions. It provides a measure of the model’s ability\nto correctly identify positive instances.\nPrecision = T P\nT P+ F P (2)\nRecall, also known as sensitivity, measures\nthe proportion of actual positive instances that\nwere correctly identiﬁed. It provides a measure of\nthe model’s ability to correctly identify positive\ninstances.\nRecall = T P\nT P+ F N (3)\n4\nThe F1 score is the harmonic mean of pre-\ncision and recall, giving equal weight to both\nmetrics. It ranges from 0 to 1, with 1 indicat-\ning perfect precision and recall, and 0 indicating\npoor performance. The F1 score is especially use-\nful when dealing with imbalanced datasets, as it\ntakes both false positives and false negatives into\naccount.\nF1 Score = 2 ∗ (Precision ∗ Recall)\n(Precision + Recall) (4)\nThese metrics provide a comprehensive evalu-\nation of the model’s performance. By considering\nboth precision and recall, the F1 score oﬀers a\nbalance between these two metrics, making it a\nbetter choice than accuracy when dealing with\nimbalanced datasets.\n4 Results and Discussion\nIn this section, we present the results of the Distil-\nBERT in Detecting Large Language Model(LLM)\nGenerated Text.\n4.1 Confusion Matrix\nThe performance of a classiﬁcation model for a\nDistilBERT is expressed in the form a confusion\nmatrix.\n4.1.1 Test Set Confusion Matrix\nFig. 3 Test Set Confusion Matrix\nFigure 3 displays the confusion matrix for the\ntest set, evaluating the model’s performance on\npreviously unseen data . This matrix provides\ndetailed insights into true positives, true neg-\natives, false positives, and false negatives ,\noﬀering deeper understanding of the model’s accu-\nracy and potential biases.\n4.1.2 Validation Set Confusion Matrix\nFigure\n4 presents the Validation Set Confusion\nMatrix, oﬀering insights into the model’s perfor-\nmance on unseen data during training. It analyzes\nhow accurately the model predicted each class,\nrevealing strengths and weaknesses for further\nevaluation.\nFig. 4 Validation Set Confusion Matrix\n4.2 Classiﬁcation Report\n4.2.1 Test Set Classiﬁcation Report\nTable\n1 presents the Classiﬁcation Report for\nthe Test Set , oﬀering a detailed breakdown of\nthe model’s performance on unseen data.\n4.2.2 Validation Set Classiﬁcation\nReport\nTable 3 delves into the model’s Validation\nSet Classiﬁcation Report , providing a detailed\nanalysis of its performance on held-out data.\n5\nTable 1 Test Set Classiﬁcation Report\nprecision recall f1-score support\n0 1.00 0.84 0.91 16763\n1 0.89 1.00 0.94 22839\naccuracy 0.93\nmacro avg 0.95 0.92 0.93 39602\nweighted avg 0.94 0.93 0.93 39602\nTable 2 Validation Set Classiﬁcation Report\nprecision recall f1-score support\n0 1.00 0.84 0.91 7768\n1 0.90 1.00 0.95 10713\naccuracy 0.93\nmacro avg 0.95 0.92 0.93 18481\nweighted avg 0.94 0.93 0.93 18481\n4.3 Model Performance Analysis\n4.3.1 Confusion Matrix Analysis\nOn the test set, the model achieved an overall\naccuracy of 93%. The model was more accurate\nat distinguishing between human-written text and\nAI-generated text, with a precision of 91% for\nhuman-written text and a recall of 84%. For AI-\ngenerated text, the precision was 89% and the\nrecall was 100%. This suggests that the model\ntends to misclassify human-written text as AI-\ngenerated more frequently than the other way\naround.\nThe F1-score, which is the harmonic mean of\nprecision and recall, was 0.91 for human-written\ntext and 0.94 for AI-generated text. This indi-\ncates that the model performs slightly better at\nclassifying AI-generated text than human-written\ntext.\nOn the validation set, the model achieved an\nF1 score of 0.95, indicating excellent performance.\nThe confusion matrix for this set showed 6561 true\npositives, 24 false positives, 1207 false negatives,\nand 10689 true negatives. These ﬁgures suggest\nthat the model correctly identiﬁed a majority\nof instances, with only a small number of false\npositives and false negatives.\nIn conclusion, the confusion matrix analysis\nreveals that the model performs well in both the\ntest and validation sets. However, it is particularly\neﬀective at classifying AI-generated text. Further\nwork could be done to improve the model’s perfor-\nmance on human-written text, especially in terms\nof reducing the number of false negatives\n4.3.2 Classiﬁcation Report Analysis\nThe model had an overall accuracy of 93% on the\ntest set. For class 0, the model correctly identiﬁed\nall instances (precision = 1.00), but it missed some\ninstances where it should have predicted class 0\n(recall = 0.84). For class 1, the model was slightly\nless accurate at predicting class 1 than class 0, but\nit did not miss any instances where it should have\npredicted class 1.\nOn the validation set, the model also had an\noverall accuracy of 93%. The precision, recall, and\nF1-score for class 0 were similar to the test set.\nFor class 1, the model was slightly less accurate at\npredicting class 1 than class 0, but it did not miss\nany instances where it should have predicted class\n1.\nIn summary, the classiﬁcation reports con-\nﬁrm the ﬁndings of the confusion matrices. The\nmodel performs well overall, but there is room\nfor improvement in its performance on class 1,\nparticularly in terms of recall\n4.4 Implications\nThe results of this study provide valuable insights\ninto the performance of DistilBert in detecting\nLarge Language Model (LLM) generated text. The\nmodel demonstrated high accuracy rates on both\nthe test and validation sets, indicating its eﬀec-\ntiveness in distinguishing between human-written\ntext and AI-generated text.\nHowever, the model’s performance was not\nuniform across all classes. While it was highly\naccurate at classifying human-written text, it\nstruggled slightly more with classifying AI-\ngenerated text. This could imply that the model\nmay beneﬁt from further training or tuning to\nimprove its performance on class 1, particularly in\nterms of recall.\nGiven the slight underperformance on AI-\ngenerated text, future work could focus on improv-\ning the model’s ability to accurately classify this\ntype of text. This could involve augmenting the\ntraining data with more examples of AI-generated\ntext or adjusting the model’s hyperparameters.\n6\nAs the model becomes more accurate in\ndistinguishing between human-written and AI-\ngenerated text, users can gain greater trust in\nthe information they receive. This could be par-\nticularly useful in ﬁelds like journalism, where\nit’s crucial to distinguish between credible news\nsources and fake news generated by bots.\nThe ability of DistilBert to detect LLM-\ngenerated text can be used to ensure the quality\nof datasets used for various applications. For\ninstance, in social media monitoring, this capa-\nbility can help ﬁlter out bot-generated posts,\nthereby enhancing the reliability of data used for\nsentiment analysis or trend identiﬁcation.\n4.5 Limitations\nAI models like DistilBERT, when used to classify\nwhether a text is AI-generated or human-written,\nface several limitations:\n1. Short Texts: These models are very unreli-\nable on short texts (below 1,000 characters).\nEven longer texts can sometimes be incorrectly\nlabeled by the classiﬁer.\n2. Mislabeling: Sometimes human-written text\nwill be incorrectly but conﬁdently labeled as\nAI-written by these classiﬁers.\n3. Language Limitations: These models per-\nform signiﬁcantly worse in languages other\nthan English and are unreliable on code.\n4. Predictable Text: Text that is very pre-\ndictable cannot be reliably identiﬁed. For\nexample, it is impossible to predict whether a\nlist of the ﬁrst 1,000 prime numbers was written\nby AI or humans, because the correct answer\nis always the same.\n5. Evasion: AI-written text can be edited to\nevade the classiﬁer. Classiﬁers like these can\nbe updated and retrained based on successful\nattacks, but it is unclear whether detection has\nan advantage in the long-term.\n6. Calibration Issues: Classiﬁers based on neu-\nral networks [\n16] are known to be poorly cali-\nbrated outside of their training data. For inputs\nthat are very diﬀerent from text in their train-\ning set, the classiﬁer is sometimes extremely\nconﬁdent in a wrong prediction.\n7. Manipulation: AI-generated text can be\nmanipulated to escape detection. The tool may\nnot perform as well with text written by chil-\ndren or in languages other than English, as its\nprimary training was based on adult-written\nEnglish content.\n8. Machine Translation: Inﬂuence of machine\ntranslation can lead to reduced accuracy.\nMachine translation leaves some traces of AI\nin the output, even if the original was purely\nhuman-written.\n9. Human Manual Editing: Cases where\nhuman-generated text is edited by a human for\nthe purpose of avoiding detection are almost\nundetectable by current tools.\n10. Machine Paraphrase: Use of AI to trans-\nform AI-generated text results in text that\nthe classiﬁers consider human-written. Most\nAI-generated texts remain undetected when\nmachine-paraphrased.\n5 Conclusion\nThis research investigated the performance of Dis-\ntilBERT in detecting LLM-generated text. We\nconducted experiments on two publicly available\ndatasets, the LLM-Detect AI Generated Text\ndataset and the DAIGT-V3 Train Dataset, and\nevaluated the model’s performance using four key\nmetrics: accuracy, precision, recall, and the F1\nscore.\nThe results of the experiments showed that\nDistilBERT achieved high performance in detect-\ning LLM-generated text. The model achieved\nan average accuracy of around 94% on the\nLLM-Detect AI Generated Text dataset and\nthe DAIGT-V3 Train Dataset. Additionally, the\nmodel achieved high precision, recall, and F1\nscores on both datasets.\nThese results suggest that DistilBERT is a\npromising tool for detecting LLM-generated text.\nThe model’s high performance and eﬃciency make\nit a viable option for a variety of applications,\nsuch as academic integrity assessment and con-\ntent moderation. We also explored the impact of\ndiﬀerent hyperparameter settings on the model’s\nperformance. It is found that the model was most\nsensitive to the number of layers and the dropout\nrate. However, even with a small number of lay-\ners and a moderate dropout rate, the model still\nachieved high performance.\nOverall, the research demonstrates that Distil-\nBERT is a powerful and eﬀective tool for detecting\n7\nLLM-generated text. The model’s high perfor-\nmance and eﬃciency make it a promising option\nfor a variety of applications.\n5.1 Future Work\nFuture research directions for evaluating Distil-\nBert’s performance in detecting Large Language\nModel (LLM) generated text could include the\nfollowing:\nExploring Alternative Models: While Dis-\ntilBert has proven eﬀective, comparing its per-\nformance against other prominent models like\nRoBERTa [\n17], ALBERT [ 18], or T5 [ 19] would\noﬀer a wider perspective on architectural suit-\nability for this task. This broader understand-\ning would guide us towards the most eﬀective\nmodels for distinguishing human-written and AI-\ngenerated text.\nExpanding Linguistic Reach: The current\nfocus on English language evaluation presents an\nopportunity for expansion. Future research can\nassess DistilBert’s performance across diverse lan-\nguages, gauging its ability to identify AI-generated\ntext in multilingual settings. This would signiﬁ-\ncantly enhance its real-world applicability.\nTackling Longer Sequences: As the length\nof analyzed text sequences increases, DistilBert’s\nperformance might decline. Investigating its han-\ndling of longer sequences and devising methods\nto improve its performance in such scenarios is\ncrucial for ensuring its eﬀectiveness in diverse use\ncases.\nBridging the Gap to Real-World Appli-\ncations: Existing research often leans towards\ntheoretical exploration. Future studies can delve\ndeeper into real-world applications such as plagia-\nrism detection or fake news identiﬁcation, demon-\nstrating the practical impact of these models\nand guiding their development towards tangible\nsolutions.\nEnhancing Model Interpretability :\nUnderstanding the rationale behind a model’s\nclassiﬁcation decisions can be invaluable. Future\nresearch on model interpretability can not only\nprovide insights into the decision-making pro-\ncess but also potentially lead to performance\nimprovements.\nCombining Techniques: Exploring the com-\nbination of DistilBert with other techniques like\nrule-based systems or other machine learning\nmodels holds promise for further performance\ngains. This synergistic approach could leverage the\nstrengths of diﬀerent methods to create a more\nrobust and accurate system for LLM detection.\nBy pursuing these diverse research directions,\nwe can reﬁne and expand the capabilities of Distil-\nBert and other models, ultimately unlocking their\nfull potential for distinguishing human-written\nand AI-generated text across various languages\nand real-world applications.\nData Availability Statement\nThe datasets analyzed during the current study\nare available in the following repositories:\n• LLM - Detect AI Generated Text:\nhttps://www.kaggle.com/competitions/\nllm-detect-ai-generated-text/data\n• DAIGT-V3 Train Dataset: https://www.kaggle.\ncom/datasets/thedrcat/daigt-v3-train-dataset\nAccess to these datasets may be subject to\nspeciﬁc terms and conditions. Please refer to the\nrespective repository pages for more details and\ninstructions on how to obtain access.\nReferences\n[1] Kim, J. K., Chua, M., Rickard, M. & Lorenzo,\nA. J. Chatgpt and large language model (llm)\nchatbots: The current state of acceptability\nand a proposal for guidelines on utilization\nin academic medicine. Journal of Pediatric\nUrology 19, 598–604 (2023).\n[2] Jungherr, A. Using chatgpt and other large\nlanguage model (llm) applications for aca-\ndemic paper assignments (2023). URL\nhttps:\n//doi.org/10.31235/osf.io/d84q6.\n[3] Devlin, J., Chang, M., Lee, K. & Toutanova,\nK. Bert: Pre-training of deep bidirec-\ntional transformers for language understand-\ning (2018). URL\nhttps://arxiv.org/pdf/1810.\n04805v2.\n[4] Sanh, V., Debut, L., Chaumond, J. & Wolf,\nT. Distilbert, a distilled version of bert:\nsmaller, faster, cheaper and lighter (2019).\nURL\nhttps://arxiv.org/pdf/1910.01108.pdf.\n8\n[5] Joshy, A. & Sundar, S. Analyzing the per-\nformance of sentiment analysis using bert,\ndistilbert, and roberta (2022).\n[6] Thorp, H. H. Chatgpt is fun, but not an\nauthor. Science 379, 313 (2023).\n[7] Aydin, O. Google bard generated literature\nreview: Metaverse. Journal of AI 7, 1–14\n(2023).\n[8] Lozic, E. & Stular, B. Chatgpt v bard v bing\nv claude 2 v aria v human-expert. how good\nare ai chatbots at scientiﬁc writing? (2023).\n[9] Bouyamourn, A. Why llms hallucinate,\nand how to get (evidential) closure: Percep-\ntual, intensional, and extensional learning for\nfaithful natural language generation 3181–\n3193 (2023). URL\nhttps://doi.org/10.18653/\nv1/2023.emnlp-main.192.\n[10] Shumailov, I. et al. The curse of recursion:\ntraining on generated data makes models for-\nget (2023). URL\nhttps://doi.org/10.48550/\narxiv.2305.17493.\n[11] Leaver, T. & Srdarov, S. Chatgpt isn’t magic.\nM/C Journal 26 (2023).\n[12] Vaccino-Salvadore, S. Exploring the ethi-\ncal dimensions of using chatgpt in language\nlearning and beyond. Languages 8, 191\n(2023).\n[13] Kang, Y., Cai, Z., Tan, C., Huang, Q. &\nLiu, H. Natural language processing (nlp)\nin management research: A literature review.\nManagement Research Review 7, 139–172\n(2020).\n[14] Sun, C., Qiu, X., Xu, Y. & Huang, X. How to\nﬁne-tune bert for text classiﬁcation 11856,\n194–206 (2019). URL\nhttps://doi.org/10.\n1007/978-3-030-32381-3 16.\n[15] Liu, Y. Robust evaluation measures for evalu-\nating social biases in masked language models\n(2024). URL\nhttps://doi.org/10.48550/arxiv.\n2401.11601.\n[16] Visa, A. A texture classiﬁer based on neural\nnetwork principles (1990).\n[17] Liu, Y. et al. Roberta: A robustly optimized\nbert pretraining approach (2019). URL https:\n//doi.org/10.48550/arxiv.1907.11692.\n[18] Lan, Z. et al. Albert: A lite bert for self-\nsupervised learning of language representa-\ntions (2019). URL\nhttps://doi.org/10.48550/\narxiv.1909.11942.\n[19] Bahani, M., Ouaazizi, A. E. & Maalmi, K.\nThe eﬀectiveness of t5, gpt-2, and bert on\ntext-to-image generation task. Pattern Recog-\nnition Letters 173, 57–63 (2023).\n9",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.5340228080749512
    },
    {
      "name": "Language model",
      "score": 0.48177263140678406
    },
    {
      "name": "Natural language processing",
      "score": 0.47480952739715576
    },
    {
      "name": "Artificial intelligence",
      "score": 0.38590383529663086
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I48018076",
      "name": "Christ University",
      "country": "IN"
    },
    {
      "id": "https://openalex.org/I28210344",
      "name": "Kakatiya University",
      "country": "IN"
    }
  ],
  "cited_by": 6
}