{
  "title": "Transformers for autonomous recognition of psychiatric dysfunction via raw and imbalanced EEG signals",
  "url": "https://openalex.org/W4386580123",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2797205079",
      "name": "Neha Gour",
      "affiliations": [
        "Khalifa University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2162667643",
      "name": "Taimur Hassan",
      "affiliations": [
        "Khalifa University of Science and Technology",
        "Abu Dhabi University"
      ]
    },
    {
      "id": "https://openalex.org/A2187252682",
      "name": "Muhammad Owais",
      "affiliations": [
        "Khalifa University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2794410948",
      "name": "Iyyakutti Iyappan Ganapathi",
      "affiliations": [
        "Khalifa University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2422160478",
      "name": "Pritee Khanna",
      "affiliations": [
        "Indian Institute of Information Technology Design and Manufacturing Jabalpur"
      ]
    },
    {
      "id": "https://openalex.org/A1088487163",
      "name": "Mohamed L. Seghier",
      "affiliations": [
        "Khalifa University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A433153394",
      "name": "Naoufel Werghi",
      "affiliations": [
        "Khalifa University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2797205079",
      "name": "Neha Gour",
      "affiliations": [
        "Khalifa University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2162667643",
      "name": "Taimur Hassan",
      "affiliations": [
        "Khalifa University of Science and Technology",
        "Abu Dhabi University"
      ]
    },
    {
      "id": "https://openalex.org/A2187252682",
      "name": "Muhammad Owais",
      "affiliations": [
        "Khalifa University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2794410948",
      "name": "Iyyakutti Iyappan Ganapathi",
      "affiliations": [
        "Khalifa University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2422160478",
      "name": "Pritee Khanna",
      "affiliations": [
        "Indian Institute of Information Technology Design and Manufacturing Jabalpur"
      ]
    },
    {
      "id": "https://openalex.org/A1088487163",
      "name": "Mohamed L. Seghier",
      "affiliations": [
        "Khalifa University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A433153394",
      "name": "Naoufel Werghi",
      "affiliations": [
        "Khalifa University of Science and Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2075647286",
    "https://openalex.org/W3121810080",
    "https://openalex.org/W2924079966",
    "https://openalex.org/W3034845153",
    "https://openalex.org/W3193449393",
    "https://openalex.org/W2139564752",
    "https://openalex.org/W3191630664",
    "https://openalex.org/W2887501928",
    "https://openalex.org/W3164114146",
    "https://openalex.org/W2808108733",
    "https://openalex.org/W4285011618",
    "https://openalex.org/W2915893085",
    "https://openalex.org/W1968263075",
    "https://openalex.org/W2915196348",
    "https://openalex.org/W2806000515",
    "https://openalex.org/W3020932535",
    "https://openalex.org/W1981276685",
    "https://openalex.org/W4226206033",
    "https://openalex.org/W4282928097",
    "https://openalex.org/W3004161400",
    "https://openalex.org/W3160046514",
    "https://openalex.org/W2126719297",
    "https://openalex.org/W3092278230",
    "https://openalex.org/W2575115745",
    "https://openalex.org/W4308793399",
    "https://openalex.org/W3140301847",
    "https://openalex.org/W3083067908",
    "https://openalex.org/W3029036868",
    "https://openalex.org/W4306756967",
    "https://openalex.org/W1991750181",
    "https://openalex.org/W2559463885",
    "https://openalex.org/W2741907166",
    "https://openalex.org/W4289538860",
    "https://openalex.org/W4312597583",
    "https://openalex.org/W2003922371",
    "https://openalex.org/W3188872815",
    "https://openalex.org/W3125937743",
    "https://openalex.org/W2963351448",
    "https://openalex.org/W3102455230"
  ],
  "abstract": null,
  "full_text": "Gour et al. Brain Informatics           (2023) 10:25  \nhttps://doi.org/10.1186/s40708-023-00201-y\nRESEARCH Open Access\n© The Author(s) 2023. Open Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which \npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the \noriginal author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or \nother third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line \nto the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory \nregulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this \nlicence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\nBrain Informatics\nTransformers for autonomous recognition \nof psychiatric dysfunction via raw \nand imbalanced EEG signals\nNeha Gour1*, Taimur Hassan1,2, Muhammad Owais1, Iyyakutti Iyappan Ganapathi1, Pritee Khanna3, \nMohamed L. Seghier4 and Naoufel Werghi1 \nAbstract \nEarly identification of mental disorders, based on subjective interviews, is extremely challenging in the clinical setting. \nThere is a growing interest in developing automated screening tools for potential mental health problems based \non biological markers. Here, we demonstrate the feasibility of an AI-powered diagnosis of different mental disorders \nusing EEG data. Specifically, this work aims to classify different mental disorders in the following ecological context \naccurately: (1) using raw EEG data, (2) collected during rest, (3) during both eye open, and eye closed conditions, (4) \nat short 2-min duration, (5) on participants with different psychiatric conditions, (6) with some overlapping symptoms, \nand (7) with strongly imbalanced classes. To tackle this challenge, we designed and optimized a transformer-based \narchitecture, where class imbalance is addressed through focal loss and class weight balancing. Using the recently \nreleased TDBRAIN dataset (n= 1274 participants), our method classifies each participant as either a neurotypi-\ncal or suffering from major depressive disorder (MDD), attention deficit hyperactivity disorder (ADHD), subjective \nmemory complaints (SMC), or obsessive–compulsive disorder (OCD). We evaluate the performance of the proposed \narchitecture on both the window-level and the patient-level. The classification of the 2-min raw EEG data into five \nclasses achieved a window-level accuracy of 63.2% and 65.8% for open and closed eye conditions, respectively. \nWhen the classification is limited to three main classes (MDD, ADHD, SMC), window level accuracy improved to 75.1% \nand 69.9% for eye open and eye closed conditions, respectively. Our work paves the way for developing novel AI-\nbased methods for accurately diagnosing mental disorders using raw resting-state EEG data.\nKeywords EEG Classification, Transformer Networks, Multivariate Time-series Classification, Class Imbalance, \nPsychiatric Dysfunction\n1 Introduction\nElectroencephalography (EEG) signals are widely \nused in many applications related to brain–computer \ninterfacing [1 , 2], motor imagery classification [3 –5], \nemotion recognition [6 , 7], neuroscience [8 , 9], and \nbiomedical engineering [10, 11]. In the field of neu -\nroscience, EEG signals can serve as useful biomarkers \nand clinically relevant features for the identification of \nneurological and mental dysfunctions. These features \nare further used to monitor and improve the treat -\nment plan for patients. Automated classification of EEG \n*Correspondence:\nNeha Gour\nneha.gour@ku.ac.ae\n1 Khalifa University Center for Autonomous Robotic System \nand Cyber-Physical Security System Center, Department of Electrical \nEngineering and Computer Science, Khalifa University, Abu Dhabi, United \nArab Emirates\n2 Departement of Electrical and Computer Engineering, Abu Dhabi \nUniversity, Abu Dhabi, United Arab Emirates\n3 Department of Computer Science and Engineering, Indian Institute \nof Information Technology, Design and Manufacturing, Jabalpur, India\n4 Healthcare Engineering Innovation Center, Department of Biomedical \nEngineering, Khalifa University, Abu Dhabi, United Arab Emirates\nPage 2 of 13Gour et al. Brain Informatics           (2023) 10:25 \nsignals has numerous applications in the area of neuro -\nlogical and mental disease diagnosis and management.\nEEG has various advantages, making it one of the \nmost widely used tool in the clinical setting, like non-\ninvasive acquisition, portability, cost-effective, and \noffering high temporal resolution. However, multiple \nchallenges are associated with EEG signal processing \nand automated neurological dysfunction classification \ntasks. The EEG signals have a low signal-to-noise ratio, \nlow spatial resolution, and high inter-subject variability \n[12]. Although the high temporal resolution is benefi -\ncial as rapid changes in brain activity can be observed \n[13], handling such data with limited computation \ncapabilities can be challenging. Raw EEG signals are \nalso associated with various artifacts introduced by \ndifferent sources that interfere with feature extraction \nand classification. Typically, raw EEG signals are pre-\nprocessed to remove these artifacts [14, 15], including \npulse and respiratory artifacts, eye movements, muscle \nactivity, and other movement artifacts. In some cases, \nthe EEG pre-processing techniques might result in the \nloss of important information. An automated model for \nmental dysfunction classification using raw EEG sig -\nnals is highly desirable as it might open the possibility \nfor more ecological applications of EEG for large-scale \nscreening procedures. In addition to the challenging \nnature of raw EEG data, the classification of different \nmental disorders is notoriously difficult because many \nof these disorders share similar symptoms, and many \nof them can be defined as spectrum disorders or syn -\ndromes with no clear cutoffs [16]\nWith the recent advances in deep learning, methods are \nproposed for diverse applications like computer vision, \nnatural language processing (NLP), time series, and bio -\nmedical applications. The deep learning methods have \nproduced state-of-the-art performance exceeding human \nexperts in some cases. Deep learning methods need copi -\nous amounts of data and a balanced sample distribution. \nImplementing deep learning methods for biomedical \napplications is still a challenging task due to data scar -\ncity and prevalent class imbalance. Recently, Transformer \nmodels have shown tremendous success in NLP and mul-\ntivariate analysis. They are praised for their capacity to \nmodel self and mutual attention between serial data [17, \n18]. EEG signal is multivariate time series data having \ninformation on multiple electrodes for a fixed amount of \ntime. It reflects the activation of multiple brain networks \nthat interact at different spatio-temporal scales. We \nhypothesize that such multivariate EEG signals can be \nbest captured and interpreted using a transformer model.\nThe proposed work aims to implement a transformer \nmodel for classifying mental dysfunctions using raw \nEEG data. To effectively evaluate the performance of the \ntransformer model, we have used the publicly available \nTDBRAIN dataset [19].\nThe contributions of this work are summarized as \nfollows:\n• Transformer model is implemented for challenging \nraw EEG data of psychiatric patients without pre-\nprocessing and feature extraction.\n• Comparative analysis of multi-class neurological dys-\nfunction classification model on eye-open and eye-\nclosed resting state raw EEG data.\n• Analysis of various methods to curb the class imbal -\nance issue in the publicly available TDBRAIN data -\nset.\n• The performance is analysed on patient-level in addi-\ntion to window-level decisions, which are generally \nused in EEG classification frameworks.\nThe work is organized as follows. Section  2 discusses \nstate-of-the-art techniques for classifying EEG signals. \nSection  3 describes the proposed transformer architec -\nture methodology for classifying mental dysfunction. \nThe dataset used for experimental evaluation of the per -\nformance of the proposed algorithm is also discussed \nhere. The evaluation criteria and results are discussed \nin Sect.  4. Finally, we conclude with a summary of main \nfindings and some important questions that warrant \nfuture research in Sect. 5.\n2  Related work\nThe EEG signal processing majorly comprises tradi -\ntional machine learning approaches [20] and deep \nlearning methods [12]. The conventional machine \nlearning methods include pre-processing, relevant fea -\nture extraction, and classification using machine learn -\ning classifiers. The machine learning methods differ in \nhow EEG data is treated before the feature extraction \nstep in the time and frequency domain. Initial tech -\nniques in the literature include handcrafted feature \nextraction from five major frequency bands: alpha, \nbeta, theta, delta, and gamma. Alhudhaif [21] imple -\nmented an approach to extract 25-time domain features \nfrom raw, alpha ( 8 − 13 Hz), beta ( 13 − 30 Hz), theta \n( 4 − 8 Hz), and delta ( 0.5 − 4 Hz) frequency bands. The \nfinal 125 features are classified using One-Against-All \n(OVA) approach. The adaptive synthetic (ADASYN) \nsampling method is combined with OVA for multi-\nclass imbalanced EEG signals classification. Hosseini -\nfard et al. [22] proposed a similar approach for binary \nclassification of EEG signals into depressive disorders \nand healthy categories. The bandpass Butterworth \nfilter is applied to raw EEG signals to extract delta, \ntheta, alpha, and beta bands. Correlation dimension, \nPage 3 of 13\nGour et al. Brain Informatics           (2023) 10:25 \n \nHiguchi, DFA, and Lyapunov exponent methods were \nfurther applied on frequency bands to extract features \nfor all 19 EEG channels. Linear discriminate analysis \n(LDA), Logistic regression (LR), and k -nearest neigh -\nbor (KNN) classifiers are used for the binary classifi -\ncation. Das et  al. [23] proposed machine learning and \ndeep learning approaches on the EEG signal’s discrete \nwavelet transform (DWT) scalograms using SVM, RF, \nAdaBoost, and CNN classifiers. Bajaj et  al. [24] uti -\nlized time–frequency representation (TFR) of EEG \nsignal using smoothed pseudo-Wigner–Ville distribu -\ntion (SPWVD) for seizure classification. Handcrafted \nfeatures like angular second moment (ASM), contrast \n(CON), mean-to-standard deviation ratio (MSR), and \narea are extracted and applied to the least square SVM \nfor classification.\nEmre et al. [25] implemented a machine learning-based \napproach for multi-class classification of EEG signals. \nPre-processing and artifact correction is done on the \nEEG dataset, and features are extracted from four fre -\nquency bands. An unbalanced dataset for nine classes of \npsychiatric disorders is used for the experiments using \nclassifiers, namely, C5.0, random forest (RF), support \nvector machines (SVM), and artificial neural networks \n(ANN). Under-sampling and oversampling methods are \nimplemented on the dataset for comparison. The hand -\ncrafted feature extraction methods rely on expert knowl -\nedge related to EEG data which may not be as robust for \nclassification.\nDeep learning-based methods have recently exhib -\nited superior performance compared to traditional \nmachine learning approaches. Deep learning methods \neliminate the need for feature engineering and rely on \ndeep learning networks for automatic feature learning. \nConvolutional neural networks (CNN), deep belief net -\nworks (DBN), recurrent neural networks (RNN), stacked \nauto-encoders (SAE), and transformers are some of the \ncommonly used architectures in literature for the classi -\nfication of EEG signals. Although neurological dysfunc -\ntion classification is a well-established area of research, \nmost machine learning and deep learning-based meth -\nods focus mainly on binary classification of diseases like \nADHD, SMC, OCD, MDD, post-traumatic stress disor -\nder (PTSD), schizophrenia, etc. [26]. In addition, most of \nthe works used pre-processed EEG data instead of focus -\ning on raw EEG data. Some of the recently published \ndeep learning methods for EEG classification are dis -\ncussed further. Moghaddari et  al. [27] proposed a CNN \narchitecture for diagnosing ADHD in children using \ncontinuous mental task EEG. The data is pre-processed, \nand frequency bands are separated to construct the CNN \nnetwork’s input images. Another frequency bands-based \napproach is proposed by Uyulan et al. [28] for classifying \nEEG signals into healthy and MDD classes. ResNet-50, \nMobileNet, and Inception-v3 CNN models are applied to \ntopographic maps of frequency bands EEG signals.\nFor the raw EEG sinal classification few methods are \nalso proposed in the literature. Supakar et  al. [29] pro -\nposed an RNN–LSTM based approach for Schizophre -\nnia classification from EEG data. The dimension of the \nEEG data is reduced using principal component analysis \n(PCA) and treated as a multi-variate time series signal \nfor the LSTM architecture. Erguzel et  al. [30] proposed \na traditional machine learning approach using SVM, \nKNN, ANN, and Naive Bayes methods for trichotillo -\nmania and OCD classification. Based on the literature \nreview, it can be concluded that the multi-class classi -\nfication for mental dysfunctions is less explored. Lawh -\nern et al. [31] proposed a compact convolutional neural \nnetwork for EEG-based BCIs. The raw EEG signals from \nfour publicly available datasets were epoched, and the \nresulting EEG segments were used as inputs for the \nCNN-based architecture. Another similar approach was \nproposed by Schirrmeister et  al. [32], named DeepCon -\nvNet, for raw EEG data. The architecture comprised four \nblocks of convolutional and max-pooling operations fol -\nlowed by a dense softmax classification layer. Moreover, \ntransformer-based architectures have also been proposed \nin the literature to classify EEG signals. For instance, Xie \net al. [33] proposed a transformer-based approach com -\nbining deep learning with spatial–temporal information \nfrom raw EEG data for motor imagery classification, in \naddition to five different architectures integrating trans -\nformer and CNN architectures. Song et al. [34] recently \nproposed a compact convolutional transformer for \nEEG-based motor image classification and emotion \nTable 1 TDBRAIN dataset for resting state raw EEG data with eye \nopen and eye close\nS.No. Indication No. of EEG \nsessions\nFormal Dx\n1. MDD 426 198\n2. ADHD 271 141\n3. SMC 119 -\n4. OCD 75 58\n5. Tinnitus 33 -\n6. Insomnia 32 32\n7. Parkinson 27 17\n8. Burnout 10 10\n9. Dyslexia 26 20\n10. Chronic pain 14 14\n11. Others 80 -\n12. Unknown 255 -\n13. Healthy 47 -\nPage 4 of 13Gour et al. Brain Informatics           (2023) 10:25 \nrecognition tasks, tested on for three publicly available \ndatasets. To handle raw EEG data, the suggested archi -\ntecture comprised a convolutional module, a self-atten -\ntion module, and a fully connected classifier.\nFrom the literature review, it can be concluded that \nEEG signals classification is widely used for motor \nimagery identification and epilepsy detection. Various \nmethods were also proposed for classifying different neu-\nrological disorders. However, multi-class EEG-based clas-\nsification of psychiatric dysfunction is scarce. Perhaps, \nmost importantly, it can be noted that most deep learn -\ning methods use EEG signals as input in the frequency \ndomain rather than raw EEG signals in the time domain. \nThe motivation of this work is to fill the gap in current \nliterature by proposing a deep learning based method \nusing raw EEG signals in the time domain for multi-class \npsychiatric dysfunction classification. The strength of \nour proposed approach lies in using raw EEG signals in \nthe time domain without any subsequent transformation \nto frequency bands or image-based features. Although \ntransformer models were previously implemented for \nEEG-based classification, our approach is among the few \navailable studies that addressed the challenging question \nof classification of mental dysfunction. As far as we know, \nour work is the first to propose a transformer model \nfor raw EEG signals using the TDBRAIN dataset, while \naddressing the problem of class imbalance.\nFig. 1 Proposed framework for neurological dysfunction classification using transformer-based model on raw EEG data\nFig. 2 Transformer Modules (Left to Right): Scaled dot-product attention, Multi-head attention, and Transformer module\nPage 5 of 13\nGour et al. Brain Informatics           (2023) 10:25 \n \n3  Materials and methods\nTDBRAIN dataset for psychiatric dysfunction classifica -\ntion is used for experimentation. A transformer-based \nmethod is used for the classification of raw EEG signals \ninto five categories of neurological dysfunction is dis -\ncussed here.\n3.1  Data set used for proposed work\nThe proposed method is employed on the EEG sig -\nnals from the recently released ”two decades brain clin -\nics research archive for insights in neurophysiology \n(TDBRAIN) dataset” [19]. The dataset comprises 1274 \nraw EEG data of patients with a clinical lifespan of 5 − 89 \nyears. The EEG signals are captured while giving specific \ninstructions to patients and following standard protocols. \nThe psychophysiological recordings are captured using a \n10–10 electrode international system at a sampling rate \nof 500 Hz.\nThe final raw EEG signals include 26-channel record -\nings. The EEG recordings were taken while the patient \nwas resting with eyes open (EO) and eyes closed (EC) for \n2 min each. During the EO task, the patients were asked \nto focus on a red dot at the center of a computer screen \nwhile in resting state. The EC samples were recorded in \nthe patient with closed eyes and retaining the same posi -\ntion as the EO task. Differences between EO and EC have \nbeen previously reported in terms of topography as well \nas power levels [35]. Among 1274 patients, EEG data was \ncaptured for mental dysfunctions, namely, major depres -\nsive disorder (MDD), attention deficit hyperactivity dis -\norder (ADHD), subjective memory complaints (SMC), \nobsessive–compulsive disorder (OCD), tinnitus, Insom -\nnia, Parkinson, Burnout, Dyslexia, Chronic pain, and \nHealthy. Individual distribution of each class is shown in \nTable 1.\n3.2  Pre‑processing and data preparation\nThe proposed work focuses on classifying five main \nclasses highlighted by Dijk et  al. [19]: ADHD, MDD, \nOCD, SMC, and healthy. As shown in Table  1, ADHD, \nMDD, and SMC classes have a relatively higher num -\nber of samples than OCD and healthy classes. Based on \nthis observation, experiments were performed on differ -\nent cost functions to address the class imbalance issue. \nIn addition to five class classifications, experiments \nwith three majority classes were also performed. The \nTDBRAIN dataset comprises EO and EC EEG signals \nfor each patient. The proposed model is implemented \nfor both types of signals separately. Bandpass filtering is \napplied to the raw EEG signal with 50 Hz frequency [35]. \nEach EEG signal is then down-sampled using a sampling \nfrequency of 100 Hz to reduce the temporal resolution of \nthe EEG time series data. The EEG data is finally cropped \nby 3s from both ends to remove any potential artifacts \nintroduced due to the filtering and down-sampling pro -\ncess. Z-score normalization is applied to the EEG signal \nas follows:\nwhere S is the original EEG signal and S∗ is the normal -\nized EEG signal. µ is the mean value of the signal along \nthe electrodes, and σ is the standard deviation. The pre-\nprocessed EEG signals are divided into epochs of window \nsize 10 seconds with 2 seconds overlapping. Each win -\ndow comprises all 26 electrodes of an EEG signal.\n3.3  Model architecture\nTransformer network architecture originally proposed by \nVaswani et  al. [17] is adopted for classifying EEG signals \nfrom the TDBRAIN dataset as shown in Fig.  1. The raw \nEEG signal is pre-processed as described in Sect.  3.2 and \napplied to the transformer network for three and five-\nclass classification. The transformer network follows an \nencoder–decoder structure. In this work, the encoder part \nof the transformer is used for feature extraction, followed \nby the softmax layer for multi-class classification. The \ntransformer encoder comprises two sub-layers: a multi-\nhead attention layer and a fully connected feed-forward \nlayer. A residual connection is around these sub-layers, fol-\nlowed by layer normalization operations. The multi-head \nattention layer comprises of scalar dot-product attention \nblock as shown in Fig. 2. The input vector is multiplied with \nthree different weight matrices to construct three vectors. \nThe query vector (Q), key vector (K), and values vector (V) \nare applied in the scaled dot-product attention for weighted \nvalue calculation, as shown in the following equation:\nThe combination of several such scaled dot-product \nattention layers in parallel is applied to create a multi-\nhead attention layer. The multiple attention layers allow \nthe model to focus on features from different subspaces \nat different locations. The output of the multi-head atten-\ntion layer is calculated as follows:\nwhere\nThe multi-head attention layer is combined with a fully \nconnected feed-forward layer to create a transformer \n(1)S∗ = S − µ\nσ\n(2)Attention(Q, K , V ) = softmax\n(\nQK T\n√\ndk\n)\nV\n(3)\nMultiHead(Q ,K ,V ) = Concat(Att1 , ....,Atth)W O\n(4)Atti = Attentioni(Q , K , V )\nPage 6 of 13Gour et al. Brain Informatics           (2023) 10:25 \nblock. A typical transformer architecture for classifica -\ntion comprises multiple transformer blocks. We have \nused four encoder transformer blocks, each having eight \nattention heads for the multi-attention layer.\nRecently, the transformer network originally pro -\nposed for natural language processing is adapted for \nmulti-variate time series data [36]. The EEG signal as \ninput to the transformer network is formulated as multi-\nvariate time series data with electrodes as variables. \nIn this work, each training sample is represented as \nX ∈ Rm ×e =[ x1 ,x2 , ...,xm ] . The training sample consti -\ntutes m feature vectors as input of length as number of \nelectrodes (e).\n3.4  Class imbalance\nThe proposed method is implemented on the TDBRAIN \ndataset for neurological dysfunction classification. In the \noriginal study published by Dijk et al. [19], more empha -\nsis was given to the five main classes of mental dys -\nfunction: MDD, ADHD, OCD, SMC, and Healthy. We \nselected these classes to evaluate the transformer model \nin our work for the first section of the experimental setup. \nThe distribution of these classes (as shown in Table  1) \nshows the prevalence of class imbalance in the TDBRAIN \ndataset. The number of samples of MDD, ADHD, and \nSMC classes is relatively higher than in OCD and healthy \nclasses. The second experimental section involves imple -\nmenting transformer models for three majority classes, \nMDD, ADHD, and SMC. An ablation study is also per -\nformed using three different loss functions to address \nthe class imbalance issue in the TDBRAIN dataset. The \ntransformer model is trained with categorical cross-\nentropy (CCE), weighted sparse categorical cross-entropy \n(WCCE), and focal loss functions. The CCE loss adjusts \nmodel weights during training [37]. The CCE loss func -\ntion is calculated between the ground truth label and the \npredicted probability score of each class and defined as \nfollows:\nwhere n is the number of classes, ti is ground truth label, \np i is probability by softmax function for ith class. The \nWCCE loss function is implemented by applying the \nclass weights of each class from the training dataset. The \nclass weights for each class are calculated by the method \ngiven by King et al. [38]:\nwhere W i is the weight of class i, N is the total number \nof EEG signals, k is the total number of classes, and N i \nis the number of EEG signal samples in class i. The class \nweights are applied during transformer weight learn -\ning and penalize the classification of minority class into \nmajority class. The WCCE loss function is defined as \nfollows:\nTraining the deep learning models using focal loss [39] is \nanother method for the dataset with class imbalance. The \nfocal loss function down weights the influence of major -\nity classes, resulting in efficient learning for minority \nclasses. The focal loss is calculated similarly to the vanilla \nCCE loss function with an added modulating factor for \nclass imbalance. The focal loss is defined as follows:\n(5)LCCEq =−\nn∑\ni=1\ntilog(pi)\n(6)W i= N\nk × Ni\n(7)LWCCE =−\nn∑\ni=1\nW itilog(pi)\n(8)LFL =−\nn∑\ni=1\n(i− pi)γ log(pi)\nTable 2 Performance of transformer model for EEG signals with eyes open on different methods for five class (ADHD, MDD, OCD, SMC, \nand Healthy) classification\nThe best performance is in bold\nDecision Method Accuracy F1‑score Precision Recall\nWindow-level Trans + CCE 63.21 41.99 42.51 41.49\nTrans + Focal Loss ( γ = 2) 61.25 40.91 41.65 40.20\nTrans + Focal Loss ( γ = 0.5) 60.27 37.59 36.38 41.27\nTrans + WCCE 53.30 43.67 44.64 42.73\nPatient-level Trans + CCE 64.38 42.90 42.81 43.96\nTrans + Focal Loss ( γ = 2) 68.49 43.29 45.00 41.72\nTrans + Focal Loss ( γ = 0.5) 61.64 38.78 39.66 40.90\nTrans + WCCE 57.53 45.03 45.33 44.75\nPage 7 of 13\nGour et al. Brain Informatics           (2023) 10:25 \n \nwhere γ is a modulating factor that can be tuned accord -\ning to the dataset. In our work, the values of γ are \nselected based on the through empirical study performed \nfor object detection in class imbalance conditions. The \nwork by Lin et al. [39] suggest the best value for γ as 2. \nIn addition a grid analysis is done on the proposed model \nto get the best value for γ as 0.5 for TDBRAIN dataset in \nsome cases (as shown in subsequent Sect. 4).\n3.5  Training setup\nThe EEG classification in literature is divided into \nwithin-individual and cross-individual training setups. \nThese setups differ in how training and testing sets are \nextracted from the dataset. In a within-individual setup, \nmultiple sessions of the same individual are divided into \ntraining and testing sets. Within-individual setup leads to \nhigher accuracy during testing. However, in the real-life \nscenario, the cross-individual setup is more relevant. The \nmodel trained on training individuals is tested on new \nindividuals. The cross-individual setup provides more \nrobust and generalized models due to information trans -\nfer among individuals. This work uses a cross-individual \nsetup to create training, validation, and testing sets from \nthe TDBRAIN dataset. The five and three class samples \nare divided into 80% , 10% , and 10% for training, valida -\ntion, and testing sets, respectively.\nThe transformer model is trained and tested with \nwindow-level signals as described in Sect.  3.2. Dur -\ning the testing stage, the window-level predictions are \naggregated using a majority voting technique to obtain a \npatient-level prediction. The classification scores for each \nwindow for a particular patient are aggregated together. \nMajority voting is applied to the windows to get the final \ndecision for each patient.\nThe architecture hyper-parameters were chosen \naccording to the original transformer encoder mod -\nule [17]. Based on empirical experimentation, the \nhyper-parameters of the transformer model were subse -\nquently tuned during model validation on the raw EEG \nsignals of the TDBRAIN dataset. Different values of \nattention heads, head size, number of transformer blocks, \nand dense layer size were explored during the experimen-\ntation. Based on the performance, the values for atten -\ntion heads, head size, number of transformer blocks, and \ndense layer were fixed at 4, 32, 4, and 512, respectively. \nThe multi-head attention layer was implemented with \na ReLU activation function with a dropout rate of 0.25. \nThe training hyper-parameter tuning was done for learn -\ning rate, batch size, and number of epochs. The trans -\nformer model was trained using the Adam optimizer \nwith a 0.001, 0.0001, and 0.0005 learning rate. The best \nresult was obtained with a learning rate of 0.0005. The \nmodels were trained on NVIDIA Tesla P100 GPU with a \nmemory size of 15GB, for which the batch size was set to \n4 to accommodate the computational capabilities. Dur -\ning initial tests, we explored training for 100, 200, and \n300 epochs for hyper-parameter tuning of the number of \nepochs. The number of epochs was set to 100 based on \nthe achieved performance during these initial tests. The \nmodel was trained for 100 epochs with the early-stopping \nand checkpoint method to choose the best model among \nthe trained models. The best models were selected based \non the highest validation accuracy, and the training was \nstopped using a patience parameter of 20. The code is \nimplemented on Python 3.8 on the TensorFlow backend \nwith CUDA: 9.1.85 and cuDNN: 7.1.1 versions.\n4  Results and discussion\nThe proposed method is applied to raw EEG signals of \nthe TDBRAIN dataset. The models are tested on hold -\nout 10% of the TDBRAIN dataset. The performance is \nevaluated and compared on the confusion matrix-based \nparameters. Accuracy, F1-score, Precision, and Recall \nTable 3 Performance of transformer model for EEG signals with eyes close on different methods for five class (ADHD, MDD, OCD, SMC, \nand Healthy) classification\nThe best performance is in bold\nDecision Method Accuracy F1‑score Precision Recall\n Window-level Trans + CCE 61.74 46.57 51.24 47.83\nTrans + Focal Loss ( γ = 2) 55.28 31.34 35.77 32.70\nTrans + Focal Loss ( γ = 0.5) 65.85 45.60 51.99 45.03\nTrans + WCCE 49.61 36.94 37.06 37.72\nPatient-level Trans + CCE 67.12 49.84 63.55 49.54\nTrans + Focal Loss ( γ = 2) 57.53 32.00 40.79 32.84\nTrans + Focal Loss ( γ = 0.5) 68.49 44.59 49.51 45.11\nTrans + WCCE 52.05 36.89 35.79 38.25\nPage 8 of 13Gour et al. Brain Informatics           (2023) 10:25 \nparameters are calculated and compared with different \nexperiments. The F1-score (12) is defined as the har -\nmonic mean of precision and recall parameters. Accuracy \n(9), Precision (10), and recall (11) are defined in terms of \ntrue positive (TP ), true negative (FP ), false positive (FP ), \nand false negative (FN) as follows:\n(9)Accuracy= TP + TN\nTP + TN + FP + FN\n(10)Precision= TP\nFP + TP\n(a)E O-Tr ans+ CCE (b)E O-T rans+FL (γ = 2.0)\n(c)E O-Tr ans+ FL (γ = 0.5) (d)E O-T rans+W CCE\n(e)E C-T rans+ CCE (f)E C-Tr ans+FL (γ = 2.0)\n(g) EC-T rans +F L( γ = 0.5) (h)E C-Tr ans+W CCE\nFig. 3 Confusion matrices for the five-class classification eye open and eye closed samples\nPage 9 of 13\nGour et al. Brain Informatics           (2023) 10:25 \n \nWe have compared the results of the proposed method \nfor the EO and EC EEG signals based on accuracy, \nF1-score, precision, and recall parameters. The final \ndecision is made window level and patient level for the \nthree- and five-class classification. It is observed that \nthe performance with patient-level decisions is relatively \nbetter than window-level decisions. Tables  2 and 3 sum -\nmarize the performance of the transformer model for \nfive-class classification on EO and EC samples. The pro -\nposed method shows superior performance using EO \nsamples in terms of accuracy for all loss functions. How -\never, better performance is observed in terms of F1-score, \nprecision, and recall five-class classification performance \nwith EC samples. The transformer model with WCCE \nloss function shows improved performance with respect \nto CCE loss function in the case of EO five-class classi -\nfication for window level decision. The best accuracy of \n(11)Recall= TP\nTP + FN\n(12)F 1 − Score = 2 ×\n[Precision× Recall\nPrecision+ Recall\n]\n68.49% is achieved with focal loss ( γ = 2) in patient-level \ndecision for EO experiment and 68.49% for EC experi -\nment with focal loss ( γ = 0.5) in patient-level decision.\nThe confusion matrix of window level decision for each \nexperiment shows the advantage of using WCCE and \nfocal loss function for classification (as shown in Fig.  3). \nThe model trained on EO samples is biased toward the \nADHD class, and the minority classes, i.e., OCD and \nhealthy, are not recognized (Fig.  3(a)). However, it can \nbe seen in Fig.  3(b) and (c) that the models recognize \nsome of the samples of minority classes. This can also \nbe observed in the improvement of F1-score parameters \nin the WCCE case. In the case of the EC experiment for \nfive classes, the healthy class is recognized more effi -\nciently than other cases (Fig.  3(d–f)). The recognition \nof minority class led to better F1-score, precision, and \nrecall parameter values among other experiments for five \nclasses.\nThe results of the three-class classification on EO and \nEC samples are shown in Tables  4 and 5, respectively, \nfor window-level and patient-level decisions. The three \nmajority classes’ experiments perform better than the \nfive-class classification. Due to the prevalence of class \nTable 4 Performance of transformer model for EEG signals with eyes open on different methods for three class (ADHD, MDD, and \nSMC) classification\nThe best performance is in bold\nDecision Method Accuracy F1‑score Precision Recall\nWindow-level Trans + CCE 71.87 66.57 65.57 71.56\nTrans + Focal Loss ( γ = 2) 71.43 62.10 68.09 59.67\nTrans + Focal Loss ( γ = 0.5) 75.11 63.87 82.62 60.25\nTrans + WCCE 67.86 64.01 61.73 72.42\nPatient-level Trans + CCE 68.75 60.01 60.37 61.87\nTrans + Focal Loss ( γ = 2) 73.44 63.96 74.84 60.36\nTrans + Focal Loss ( γ = 0.5) 76.56 65.75 91.07 60.71\nTrans + WCCE 70.31 67.04 64.78 74.39\nTable 5 Performance of transformer model for EEG signals with eyes close on different methods for three class (ADHD, MDD, and \nSMC) classification\n The best performance is in bold\nDecision Method Accuracy F1‑score Precision Recall\nWindow-level Trans + CCE 67.97 64.86 66.25 63.92\nTrans + Focal Loss ( γ = 2) 69.87 60.55 66.21 57.48\nTrans + Focal Loss ( γ = 0.5) 68.64 59.13 63.61 63.54\nTrans + WCCE 66.18 62.63 67.15 61.15\nPatient-level Trans + CCE 67.19 64.83 72.75 60.92\nTrans + Focal Loss ( γ = 2) 70.31 61.19 75.52 56.05\nTrans + Focal Loss ( γ = 0.5) 70.31 61.87 66.53 65.36\nTrans + WCCE 65.62 60.91 72.62 57.43\nPage 10 of 13Gour et al. Brain Informatics           (2023) 10:25 \nimbalance, the performance parameters get affected in \nfive-class classification. The transformer model trained \nwith EO samples shows better performance than EC \nsamples. The EO experiment with the CCE loss function \nachieved 76.56% accuracy compared to 70.31% accuracy \nachieved by the EC experiment with focal loss ( γ = 0.5) \nin patient-level. The advantage of using focal loss can \nbe seen in the case of precision of EO case with value as \n91.07%.\nFigure  4 shows the confusion matrices for the three-\nclass classification for window-level decisions. As shown \nin Fig.  4(a)   and (d), for the EO experiment using CCE \nand WCCE loss functions, ADHD and SMC classes are \nclassified better in comparison to MDD class. A similar \npattern is observed in the case of EC experiments using \nCCE and WCCE loss functions (Fig.  4(e) and (h)). In case \nof MDD class, the EO and EC experiments using focal \nloss function shows higher number of true positives as \nshown in Fig. 4(c) and (f).\nThe transformer model was trained for 100 epochs, \nand the best model was selected using the early stopping \nand checkpoint method. During training, a checkpoint is \ncreated when the validation error is less than the previ -\nous epochs, and the current model is saved as the best \n(a)E O-T rans+ CCE (b) EO -T rans+FL (γ = 2.0) (c)E O- Trans +F L( γ = 0.5)\n(d) EO -T rans+WCCE (e)E C- Trans + CCE (f)E C-Tr ans+FL (γ = 2.0)\n(g) EC -T rans+FL (γ = 0.5) (h)E C-Tr ans+WCCE\nFig. 4 Confusion matrices for the three-class classification eye open and eye closed samples\nPage 11 of 13\nGour et al. Brain Informatics           (2023) 10:25 \n \nmodel. The training and validation accuracy plots for 100 \nepochs for the five-class classification are shown in Fig. 5. \nIt can be seen from the plot that the best validation accu -\nracy for the eye-open EEG data was identified at epoch \nnumber 45 (Fig.  5(a)). Likewise, the best validation accu -\nracy for the eye-closed EEG data was identified at epoch \n50 (Fig. 5(b)). Beyond these identified epochs, the model \nstarted overfitting the data with no further improvement \nto validation accuracy.\n4.1  Comparision with methods from literature\nThe proposed transformer model is also compared with \nother state-of-the-art deep learning-based models that \nwere previously developed for raw EEG-based classi -\nfication. Two CNN-based methods (i.e. EEGNet [31] \nand DeepConvNet [32]), originally proposed for clas -\nsifying raw EEG data for brain–computer interfaces, \nwere selected. The two methods were tested on the \nTDBRAIN dataset while keeping the same parameters \nsettings according to the original implementations [31, \n32]. To ensure an unbiased comparison, our model was \ncompared against the two methods under their opti -\nmal original parametrizations for the five-class clas -\nsification problem. More specifically, the two methods \nused the CCE loss function for raw EEG classification, \ntherefore, our proposed method with the CCE loss \nfunction was used here for comparison purposes (see \nTable  6). Our proposed method outperformed both \nmethods in terms of Accuracy, F1-score, Precision, and \nRecall. Interestingly, our proposed transformer-based \narchitecture is relatively close in terms of the number \nof training parameters (#TP) to the compact EEGNet \narchitecture [31], but have much less parameters than \nthe DeepConvNet method [32], which suggests that our \nFig. 5  Accuracy plots for five-class classification of eye-open and eye-closed samples (Blue plot: training curve and orange plot: validation curve)\nTable 6 Performance comparision of transformer model with state-of-the-art for Raw EEG classification for five classes (ADHD, MDD, \nOCD, SMC, and Healthy)\nThe best performance is in bold\nAuthor Method Accuracy F1‑score Precision Recall # TP\n Eye Open EEG\n Lawhern et al. [31] EEGNet 54.89 36.53 42.04 41.13 53.86k\n Schirrmeister et al. [32] DeepConvNet 59.49 35.77 37.26 37.99 207.53k\n Proposed Method Transformer 63.21 41.99 42.51 41.49 72.64k\n Eye Close EEG\n Lawhern et al. [31] EEGNet 55.28 40.84 44.64 42.92 53.86k\n Schirrmeister et al. [32] DeepConvNet 59.78 38.04 55.52 42.15 207.53k\n Proposed Method Transformer 61.74 46.57 51.24 47.83 72.64k\nPage 12 of 13Gour et al. Brain Informatics           (2023) 10:25 \nmodel achieved higher performance with a reasonable \nnumber of training parameters.\n4.2  Limitations and future work\nWe observed that the models trained on complex raw \nEEG data did not provide high performance that could \nbe clinically useful. An attempt has been made to analyze \npossible limitations and future solutions for classifying \nthe TDBRAIN dataset. TDBRAIN dataset suffers from \nclass imbalance, a classical problem in medical datasets. \nTo address this issue, we have implemented the trans -\nformer model with class weights and focal loss function. \nThe results obtained by these methods are not yet suitable \nfor real-life deployment. The transformer model imple -\nments a window-level approach based on the assumption \nthat EEG signals of 10 s are robust stationary representa -\ntions of brain dynamics that are patient-specific.\nAs future work, we plan to investigate whole EEG sig -\nnal analysis for mental dysfunction analysis. Various \ntechniques like large margin nearest neighbor, sampling \nmethods for imbalanced classification, and EEG signal \naugmentation can be implemented to further address the \nissue of class imbalance. The raw EEG signals are used \nin this work to train the classification model. Classifying \nraw EEG signals is challenging, and artifacts present in \nthe signal may hinder the learning process. However, raw \nEEG signal analysis can open the possibility for near real-\ntime applications for diagnostic purposes, including fast \nanalysis of raw signals from portable EEG devices. Our \nrationale was also motivated by the fact that different \nclinical populations might not show similar artifacts (e.g. \nneurotypicals might display fewer artefacts than people \nwith mental deficits), which could in turn help the classi -\nfication. Nonetheless, the value of pre-processing should \nnot be overlooked, as it is expected that better perfor -\nmance can be obtained after artefacts removal. Likewise, \nit is also most likely that spectral features might yield bet-\nter classification of the different mental conditions than \nfeatures extracted in the time domain.\n5  Conclusion\nAn automated psychiatric dysfunction classification \nmethod using raw EEG signals is proposed in this work. \nThe proposed method implements a transformer model \nwith three different loss functions for classification. \nTwo sets of experiments are performed using samples \ncollected during rest from patients with eyes open and \nclosed. The novelty of the work lies in the implementa -\ntion of transformer models for multi-class classification \nand the addition of specialized loss functions to address \nthe class imbalance issue in the publicly available \nTDBRAIN dataset. The approaches are employed for \nclassification into five and three categories of mental \ndysfunction. The raw EEG signal is taken as input for \nthe transformer block with eight attention heads. The \nextracted features from the transformer blocks are \napplied to a fully connected layer and classified using \nthe softmax function. The parametric evaluation of the \ntraining and testing phase shows that the transformer \nwith categorical cross entropy shows better accuracy \nfor five-category classification. The transformer with \nweighted categorical cross entropy performed better \nin the open-eye case in terms of F1-score, precision, \nand recall. For the three-category classification case, \nthe transformer with categorical cross-entropy yielded \nbetter accuracy for eye-open samples than that with \nthe focal loss for eye-closed samples. Classwise perfor -\nmance of all the models is also analyzed using confu -\nsion matrices. The proposed work can be incorporated \nwith real-life clinical systems to analyze and classify \nneurological and mental dysfunctions. Future work \nneeds to implement robust methods to address the \nclass imbalance in the TDBRAIN dataset.\nAuthor contributions\nNG and NW—conceptualization, NG—methodology implementation, and \nwriting original draft; TH, PK, MS, and NW—supervision and manuscript review \nand editing; MO and IIG—result interpretations and validations; all authors \nreviewed the manuscript.\nFunding\nThis work is supported by research grants from Khalifa University Ref: CIRA-\n2021-052, the Advanced Technology Research Center Program (ASPIRE) Ref: \nAARE20-279, and Terry Fox Foundation Ref: EX2019-014.\n Availability of data and materials\nThe TDBRAIN dataset used for the experimentation of this work is publicly \navailable on Brain Clinics website (https:// brain clini cs. com/ resou rces/). No \nnew data were created or analyzed in this study. Data sharing is not applicable \nto this article.\nDeclarations\nEthics approval and consent to participate\nNot applicable.\nCompeting interests\nNot applicable.\nReceived: 22 March 2023   Accepted: 17 July 2023\nReferences\n 1. Lotte F, Congedo M, Lécuyer A, Lamarche F, Arnaldi B (2007) A review \nof classification algorithms for eeg-based brain-computer interfaces. J \nNeural Eng 4(2):1\n 2. Gu X, Cao Z, Jolfaei A, Xu P , Wu D, Jung T-P , Lin C-T (2021) Eeg-based \nbrain-computer interfaces (bcis): a survey of recent studies on signal \nsensing technologies and computational intelligence approaches \nand their applications. IEEE/ACM Trans Comput Biol Bioinform \n18(5):1645–1666\nPage 13 of 13\nGour et al. Brain Informatics           (2023) 10:25 \n \n 3. Padfield N, Zabalza J, Zhao H, Masero V, Ren J (2019) Eeg-based brain-\ncomputer interfaces using motor-imagery: techniques and challenges. \nSensors 19(6):1423\n 4. Rahman M, Khanam F, Ahmad M, Uddin MS et al (2020) Multiclass eeg \nsignal classification utilizing rényi min-entropy-based feature selection \nfrom wavelet packet transformation. Brain Inform 7(1):1–11\n 5. Sadiq MT, Yu X, Yuan Z, Aziz MZ, Siuly S, Ding W (2021) Toward the \ndevelopment of versatile brain-computer interfaces. IEEE Trans Artif \nIntell 2(4):314–328\n 6. Wang X-W, Nie D, Lu B-L (2014) Emotional state classification from eeg \ndata using machine learning approach. Neurocomputing 129:94–106\n 7. Rahman MM, Sarkar AK, Hossain MA, Hossain MS, Islam MR, Hossain \nMB, Quinn JM, Moni MA (2021) Recognition of human emotions using \neeg signals: a review. Comput Biol Med 136:104696\n 8. Mahato S, Paul S Electroencephalogram (eeg) signal analysis for diag-\nnosis of major depressive disorder (mdd): a review. Nanoelectronics, \nCircuits and Communication Systems, 323–335 (2019)\n 9. Sánchez-Reyes L-M, Rodríguez-Reséndiz J, Avecilla-Ramírez GN, García-\nGomar M-L, Robles-Ocampo J-B (2021) Impact of eeg parameters detect-\ning dementia diseases: a systematic review. IEEE Access 9:78060–78074\n 10. Perera H, Shiratuddin MF, Wong KW (2018) Review of eeg-based pattern \nclassification frameworks for dyslexia. Brain Inform 5(2):1–14\n 11. Maitin AM, Romero Muñoz JP , García-Tejedor ÁJ (2022) Survey of machine \nlearning techniques in the analysis of eeg signals for parkinson’s disease: \nA systematic review. Appl Sci 12(14):6967\n 12. Craik A, He Y, Contreras-Vidal JL (2019) Deep learning for electroencepha-\nlogram (eeg) classification tasks: a review. J Neural Eng 16(3):031001\n 13. Gevins A, Smith ME, McEvoy LK, Leong H, Le J (1999) Electroencephalo-\ngraphic imaging of higher brain function philosophical transactions of \nthe royal society of London. Series B Biol Sci 354(1387):1125–1134\n 14. Jiang X, Bian G-B, Tian Z (2019) Removal of artifacts from eeg signals: a \nreview. Sensors 19(5):987\n 15. Mannan MMN, Kamran MA, Jeong MY (2018) Identification and removal \nof physiological artifacts from electroencephalogram signals: a review. \nIeee Access 6:30630–30652\n 16. Marshall M (2020) The hidden links between mental disorders. Nature \n581(7806):19–22\n 17. Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser, Ł, \n(2017) Polosukhin I Attention is all you need. Advances in neural informa-\ntion processing systems 30\n 18. Wen Q, Zhou T, Zhang C, Chen W, Ma Z, Yan J, Sun L (2022) Transformers \nin time series: a survey. arXiv. https:// doi. org/ 10. 48550/ arXiv. 2202. 07125\n 19. van Dijk H, van Wingen G, Denys D, Olbrich S, van Ruth R, Arns M (2022) \nThe two decades brainclinics research archive for insights in neurophysi-\nology (tdbrain) database. Scientif Data 9(1):1–10\n 20. Hosseini M-P , Hosseini A, Ahi K (2020) A review on machine learning \nfor eeg signal processing in bioengineering. IEEE Rev Biomed Eng \n14:204–218\n 21. Alhudhaif A (2021) A novel multi-class imbalanced eeg signals classifica-\ntion based on the adaptive synthetic sampling (adasyn) approach. PeerJ \nComp Sci 7:523\n 22. Hosseinifard B, Moradi MH, Rostami R (2013) Classifying depression \npatients and normal subjects using machine learning techniques \nand nonlinear features from eeg signal. Comp Meth prog Biomed \n109(3):339–345\n 23. Das D, Chowdhury T, Pal U (2020) Analysis of multi-class classification of \neeg signals using deep learning. In: International Conference on Pattern \nRecognition and Artificial Intelligence, pp. 203–217 . Springer\n 24. Bajaj V, Rai K, Kumar A, Sharma D (2017) Time-frequency image based \nfeatures for classification of epileptic seizures from eeg signals. Biomed \nPhys Eng Exp 3(1):015012\n 25. Tarhan N (2022) Multi-class classification model for psychiatric disorder \ndiscrimination. Int J Med Inform. https:// doi. org/ 10. 1016/j. ijmed inf. 2022. \n104926\n 26. Rivera MJ, Teruel MA, Mate A, Trujillo J (2022) Diagnosis and prognosis of \nmental disorders by means of eeg and deep learning: a systematic map-\nping study. Artifi Intell Rev 55(2):1209–1251\n 27. Moghaddari M, Lighvan MZ, Danishvar S (2020) Diagnose adhd disorder \nin children using convolutional neural network based on continuous \nmental task eeg. Comp Meth Prog Biomed 197:105738\n 28. Uyulan C, Ergüzel TT, Unubol H, Cebi M, Sayar GH, Nezhad Asad M, Tarhan \nN (2021) Major depressive disorder classification based on different \nconvolutional neural network models: deep learning approach. Clin EEG \nNeurosci 52(1):38–51\n 29. Supakar R, Satvaya P , Chakrabarti P (2022) A deep learning based model \nusing rnn-lstm for the detection of schizophrenia from eeg data. Comput \nBiol Med 151:106225\n 30. Erguzel TT, Ozekes S, Sayar GH, Tan O, Tarhan N (2015) A hybrid artificial \nintelligence method to classify trichotillomania and obsessive compul-\nsive disorder. Neurocomputing 161:220–228\n 31. Lawhern VJ, Solon AJ, Waytowich NR, Gordon SM, Hung CP , Lance BJ \n(2018) Eegnet: a compact convolutional neural network for eeg-based \nbrain-computer interfaces. J Neural Eng 15(5):056013\n 32. Schirrmeister RT, Springenberg JT, Fiederer LDJ, Glasstetter M, Eggensper-\nger K, Tangermann M, Hutter F, Burgard W, Ball T (2017) Deep learning \nwith convolutional neural networks for eeg decoding and visualization. \nHuman Brain Map 38(11):5391–5420\n 33. Xie J, Zhang J, Sun J, Ma Z, Qin L, Li G, Zhou H, Zhan Y (2022) A \ntransformer-based approach combining deep learning network and \nspatial-temporal information for raw eeg classification. IEEE Trans Neural \nSyst Rehab Eng 30:2126–2136\n 34. Song Y, Zheng Q, Liu B, Gao X (2022) Eeg conformer: convolutional trans-\nformer for eeg decoding and visualization. IEEE Trans Neural Syst Rehabil \nEng. https:// doi. org/ 10. 1109/ TNSRE. 2022. 32302 50\n 35. Barry RJ, Clarke AR, Johnstone SJ, Magee CA, Rushby JA (2007) Eeg dif-\nferences between eyes-closed and eyes-open resting conditions. Clin \nNeurophysiol 118(12):2765–2773\n 36. Zerveas G, Jayaraman S, Patel D, Bhamidipaty A, Eickhoff C. (2021). A \ntransformer-based framework for multivariate time series representa-\ntion learning. In: Proceedings of the 27th ACM SIGKDD Conference on \nKnowledge Discovery & Data Mining, pp. 2114–2124\n 37. Zhang Z, Sabuncu M (2018) Generalized cross entropy loss for training \ndeep neural networks with noisy labels. Advances in neural information \nprocessing systems 31\n 38. King G, Zeng L (2001) Logistic regression in rare events data. Polit Anal \n9(2):137–163\n 39. Lin T-Y, Goyal P , Girshick R, He K, Dollár P (2017) Focal loss for dense object \ndetection. In: Proceedings of the IEEE International Conference on Com-\nputer Vision, pp. 2980–2988\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in pub-\nlished maps and institutional affiliations.",
  "topic": "Neurotypical",
  "concepts": [
    {
      "name": "Neurotypical",
      "score": 0.6750658750534058
    },
    {
      "name": "Electroencephalography",
      "score": 0.6582285165786743
    },
    {
      "name": "Major depressive disorder",
      "score": 0.43879270553588867
    },
    {
      "name": "Context (archaeology)",
      "score": 0.4342942535877228
    },
    {
      "name": "Computer science",
      "score": 0.42298591136932373
    },
    {
      "name": "Audiology",
      "score": 0.4110547602176666
    },
    {
      "name": "Artificial intelligence",
      "score": 0.39655280113220215
    },
    {
      "name": "Psychology",
      "score": 0.377435564994812
    },
    {
      "name": "Psychiatry",
      "score": 0.36321139335632324
    },
    {
      "name": "Medicine",
      "score": 0.30628710985183716
    },
    {
      "name": "Cognition",
      "score": 0.17633643746376038
    },
    {
      "name": "Autism spectrum disorder",
      "score": 0.094270259141922
    },
    {
      "name": "Autism",
      "score": 0.08747240900993347
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I176601375",
      "name": "Khalifa University of Science and Technology",
      "country": "AE"
    },
    {
      "id": "https://openalex.org/I207223250",
      "name": "Indian Institute of Information Technology Design and Manufacturing Jabalpur",
      "country": "IN"
    }
  ],
  "cited_by": 20
}