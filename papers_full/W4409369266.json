{
  "title": "Political Actor Agent: Simulating Legislative System for Roll Call Votes Prediction with Large Language Models",
  "url": "https://openalex.org/W4409369266",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5088223732",
      "name": "Hao Li",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5101791902",
      "name": "Rong Gong",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5101763478",
      "name": "Hao Jiang",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6761315499",
    "https://openalex.org/W4296154596",
    "https://openalex.org/W6677777871",
    "https://openalex.org/W3034936923",
    "https://openalex.org/W4285275339",
    "https://openalex.org/W6681701252",
    "https://openalex.org/W2039158004",
    "https://openalex.org/W6730449110",
    "https://openalex.org/W2949911880",
    "https://openalex.org/W4362508448",
    "https://openalex.org/W4396723160",
    "https://openalex.org/W3174253982",
    "https://openalex.org/W4385570856",
    "https://openalex.org/W6646835132",
    "https://openalex.org/W6776486982",
    "https://openalex.org/W3034473085"
  ],
  "abstract": "Predicting roll call votes through modeling political actors has emerged as a focus in quantitative political science and computer science. Widely used embedding-based methods generate vectors for legislators from diverse data sets to predict legislative behaviors. However, these methods often contend with challenges such as the need for manually predefined features, reliance on extensive training data, and a lack of interpretability. Achieving more interpretable predictions under flexible conditions remains an unresolved issue. This paper introduces the Political Actor Agent (PAA), a novel agent-based framework that utilizes Large Language Models to overcome these limitations. By employing role-playing architectures and simulating legislative system, PAA provides a scalable and interpretable paradigm for predicting roll-call votes. Our approach not only enhances the accuracy of predictions but also offers multi-view, human-understandable decision reasoning, providing new insights into political actor behaviors. We conducted comprehensive experiments using voting records from the 117-118th U.S. House of Representatives, validating the superior performance and interpretability of PAA. This study not only demonstrates PAA's effectiveness but also its potential in political science research.",
  "full_text": "Political Actor Agent: Simulating Legislative System for Roll Call Votes Prediction\nwith Large Language Models\nHao Li, Ruoyuan Gong, Hao Jiang*\nWuhan University, Wuhan, 430072 China\nwhulh@whu.edu.cn, GongRuoyuan@whu.edu.cn, jh@whu.edu.cn\nAbstract\nPredicting roll call votes through modeling political actors\nhas emerged as a focus in quantitative political science and\ncomputer science. Widely used embedding-based methods\ngenerate vectors for legislators from diverse data sets to pre-\ndict legislative behaviors. However, these methods often con-\ntend with challenges such as the need for manually prede-\nfined features, reliance on extensive training data, and a lack\nof interpretability. Achieving more interpretable predictions\nunder flexible conditions remains an unresolved issue. This\npaper introduces the Political Actor Agent (PAA), a novel\nagent-based framework that utilizes Large Language Models\nto overcome these limitations. By employing role-playing ar-\nchitectures and simulating legislative system, PAA provides\na scalable and interpretable paradigm for predicting roll call\nvotes. Our approach not only enhances the accuracy of pre-\ndictions but also offers multi-view, human-understandable\ndecision reasoning, providing new insights into political actor\nbehaviors. We conducted comprehensive experiments using\nvoting records from the 117-118th U.S. House of Representa-\ntives, validating the superior performance and interpretability\nof PAA. This study not only demonstrates PAA’s effective-\nness but also its potential in political science research.\nIntroduction\nLegislative actions, such as proposing, reviewing, and voting\non bills, enable political actors to influence national and so-\ncietal development. Modeling these actors has emerged as an\ninterdisciplinary focus within quantitative political science\nand computer science. The representations obtained from\nmodeling political actors are applied to downstream tasks\nsuch as roll-call vote prediction (Feng et al. 2022; Mou et al.\n2021), and political stance prediction (Feng et al. 2021; Li\nand Goldwasser 2019).\nIn this paper, we primarily focus on the problem of\npredicting legislators’ roll call votes.With voting records,\nbill texts, and background knowledge, there are two main\napproaches to modeling political actors. The ideal point\nmodel, one of the most widely used methods for roll call\nvote prediction, represents legislators and bills as points in\none or multiple dimensions (Clinton, Jackman, and Rivers\n*Corresponding author\nCopyright © 2025, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\n2004; Kraft, Jain, and Rush 2016). Recently, some studies\nhave employed heterogeneous information graphs to repre-\nsent legislators, bills, and contextual knowledge, including\ncomplex relationships between party affiliations, lobbying\n(Davoodi, Waltenburg, and Goldwasser 2020), and assets\n(Feng et al. 2022, 2021; Mou et al. 2024). These studies\nthen use heterogeneous graph neural networks to generate\nembeddings for nodes within the graph and predict voting\noutcomes. Both approaches embed legislators and bills into\na vector space and use neural networks or similarity mea-\nsures to predict results.\nHowever, the aforementioned embedding-based methods\nexhibit several limitations: 1. Limitations of predefined\nfeatures: The model’s training relies solely on predefined\nfeatures, preventing natural extension to new, untrained rela-\ntionships. 2. Volume of training data:Most models depend\non large datasets to achieve optimal performance, which is\nnot feasible in real-world scenarios, such as predicting votes\nof newly elected legislators. 3. Interpretability of predic-\ntions: Predictions based on embeddings lack interpretability,\nparticularly in providing insights in a manner understand-\nable to humans.\nTo address these challenges, we have turned our attention\nto the accomplishments of agent research based on Large\nLanguage Models (LLMs) (Wang et al. 2024). With de-\nsigned profile, planning, and action modules, LLM agents\ncan exhibit intelligent decision-making behaviors. Some\nstudies have applied LLM Agents in fields such as eco-\nnomics (Kim et al. 2024; Zhou et al. 2024a), social simu-\nlation (Mou, Wei, and Huang 2024; Chuang et al. 2024; Dai\net al. 2024), and voting decision-making (Yang et al. 2024;\nMajumdar, Elkind, and Pournaras 2024a). As shown in fig-\nure 1, by reframing the problem of modeling political actors\nas constructing political agents, we introduce deeper insights\ninto this field.\nSpecifically, we designed the Political Actor Agent (PAA)\nbased on a role-playing architecture (Li et al. 2023), which\noffers several advantages: 1. Scalable Politician Profile:\nEach agent is equipped with a scalable profile. This profile\nis more flexible and easier to manage compared to man-\nually designed relational rules. 2. Multi-view Planning:\nFrom various views, such as the delegate and trustee views\n(Alexander 2019), the PAA can formulate different vot-\ning plans. Decision-making reasons understandable to hu-\nThe Thirty-Ninth AAAI Conference on Artificial Intelligence (AAAI-25)\n388\nIdeal Point Model\nLegislatorBill 1 Bill 2\n1 2\nYea Nay\nGraph-based Model\n1\n2\ncommittee\nparty\ncaucus\nNay\nNay\nNay\nYea\nYea\nAgent-based Model\nProfile Agent\nLLM\n1\n2\nVoting Prediction\nYea\nNay\nFigure 1: Examples of different political actor modeling\nmethods include: The ideal point model represents legisla-\ntors and bill entities as vectors. The graph-based model em-\nbeds nodes from heterogeneous information graphs into vec-\ntors using a graph embedding model. Our agent-based model\ndoes not rely on distances between embeddings; instead, it\ndirectly generates voting outcomes using LLM agents.\nmans can better provide new insights for political science\nresearch. 3. Simulated Legislative Action: Based on legis-\nlators’ voting strategies, we developed an Influence Mecha-\nnism that simulates parliamentary dynamics. Legislators are\ncategorized as leader agents and follower agents, with fol-\nlower agents being influenced by the voting outcomes of\nleader agents. This mechanism allows for accurate vote pre-\ndictions even with limited known data. Our contributions are\nas follows:\n1. We propose a new agent-based paradigm for political\nactor research. Compared to embedding-based methods,\nour role-playing framework for legislator simulation of-\nfers more accurate and interpretable results for corre-\nsponding downstream tasks.\n2. We introduce the Political Actor Agent (PAA) for roll-\ncall vote prediction. Our approach, through the design\nof scalable profiles, multi-view planning, and simulated\nlegislator actions, significantly enhances prediction accu-\nracy and offers interpretable decision-making insights for\npolitical science research.\n3. We conduct comprehensive experiments using voting\nrecords from the 117-118th House of Representatives.\nOur experiments demonstrate that our method not only\nachieves high prediction accuracy but also provides in-\nterpretable political insights.\nRelated Works\nThis section introduces roll call voting prediction based on\npolitical actor modeling and the use of LLM agents for de-\ncision simulation.\nModeling Political Actors for Voting Prediction\nLegislators’ voting behavior in parliament has been a pri-\nmary research focus due to its characteristic transparency\nand significance. One of the most popular techniques in po-\nlitical science is the ideal point model, constructed based\non voting records and typically used to represent unidimen-\nsional or multidimensional ideological positions (Poole and\nRosenthal 1985; Clinton, Jackman, and Rivers 2004). The\nideal point model has been expanded in several studies. For\ninstance, (Gerrish and Blei 2011) employ a topic model to\nperform a detailed analysis of legislative texts, enhancing the\ncontextual understanding of votes. Further extending this ap-\nproach, researchers have developed a topic factorized ideal\npoint model that assigns ideal points for each topic rather\nthan globally, allowing for more nuanced interpretations of\nlegislative behavior (Gu et al. 2014). Additionally, efforts\nhave been made to learn multidimensional embeddings of\nlegislators and bills to improve prediction accuracy (Kraft,\nJain, and Rush 2016), and to integrate broader political texts,\nsuch as speeches and tweets, into the ideal point model to\nenrich the dataset (Vafa, Naidu, and Blei 2020).\nIn terms of incorporating richer contextual information,\ngraph-based methods, driven by advancements in knowl-\nedge graphs and graph neural networks, have gained pop-\nularity. External knowledge is introduced into voting pre-\ndiction in the form of heterogeneous information graphs.\nCompared to ideal point models, graph-based models can\nmore flexibly capture complex political relationships, such\nas cosponsorship (Yang et al. 2021), donors (Davoodi, Wal-\ntenburg, and Goldwasser 2020), and stakeholders (Davoodi,\nWaltenburg, and Goldwasser 2022). Additionally, more ex-\npert knowledge has been incorporated, such as news data\n(Feng et al. 2021), Twitter statements (Mou et al. 2021), wiki\npages, and political think tanks (Feng et al. 2022).\nPolitical decision-making often involves highly complex\nmechanisms and background knowledge. Recent studies\nhave focused on leveraging large language models (LLMs).\nFor instance, (Mou et al. 2024) constructed a multi-view po-\nlitical knowledge graph to enhance the domain knowledge\nof LLMs. Similarly, (Mou et al. 2023) developed a pretrain-\ning architecture that maps language to actor representations.\n389\nThese attempts demonstrate the capability of LLMs in re-\nlated tasks but remain complementary to embedding-based\nmethods. This paper proposes a novel approach to modeling\nlegislators as actors from an agent view, aiming to advance\nthe prediction and understanding of voting behavior.\nLLM Agent in Decision Simulation\nRoll call voting can be viewed as a decision-making behav-\nior. As LLM agents demonstrate the potential for human-\nlevel intelligence (Wang et al. 2024), many studies have\napplied them in fields such as natural sciences (Boiko,\nMacKnight, and Gomes 2023), software engineering (Qian\net al. 2023), and embodied intelligence (Wu et al. 2023).\nSome researchers are exploring the integration of large lan-\nguage models with social sciences, particularly in simulat-\ning decision-making behaviors. In economics, for instance,\n(Horton 2023) treat LLM agents as economic agents, ob-\nserving their economic decisions under different conditions\nand scenarios. (Zhou et al. 2024b) propose a financial bias\nindicator framework, analyzing irrational biases in LLM\nagents through behavioral finance theories.\nIn the realm of voting decision simulation, studies like\n(Argyle et al. 2023) investigate the feasibility of using large\nlanguage models to simulate human samples, designing\nagents based on demographic data to model the reactions\nof different populations. The article (Yang et al. 2024) finds\nthat the input method and presentation of choices can af-\nfect the voting behavior of LLMs. (Majumdar, Elkind, and\nPournaras 2024b) delve deeper into the issue of bias in the\nvoting process, discovering that equal-share methods can\nlead to fairer voting outcomes.\nThe above research on decision simulation indicates that\nLLM agents can offer new insights into social sciences. Un-\nlike agents based on demographic data, this paper explores a\nmore sophisticated decision simulation. By setting detailed\npolitical profiles and voting mechanisms, we aim to predict\nthe roll-call voting results of political actors. Our goal is to\ninvestigate the ability of LLM agents to simulate complex,\ndiverse outcomes and to summarize their behavior based on\nspecific political perspectives.\nMethod\nIn this section, we detail the framework of the Political Ac-\ntor Agent (PAA) for roll call vote prediction. As illustrated\nin figure 2, we begin by collecting data from Wikipedia and\nlegislative bills from the Congress. We then construct scal-\nable agent profiles for each legislator, incorporating personal\ninformation, constituency details, and data on bills they have\nsponsored and voted on. Subsequently, we design a multi-\nview planning module for each agent to perform reason-\ning based on various political science views. Finally, in the\nsimulated legislative action module, we implement an influ-\nence mechanism that allows leader agents associated with\nthe bill to act first, with the remaining agents making their\nchoices after learning the leaders’ decisions. This approach\nleverages political science perspectives and LLM agents to\nachieve more accurate and interpretable voting predictions.\nProfile Construction Module\nUsing a role-playing architecture, we simulate characters\nwhere agents assume specific roles to make voting deci-\nsions. The profile construction module is integrated into the\nprompt to influence the design and behavior of the LLMs.\nThe design of the profile is highly scalable and can synthe-\nsize information from different data sources under various\nconditions, such as personal basic information, career his-\ntory, voting records, etc. Specifically, the profiles we use in-\nclude the following personal details:\nPersonal information This refers to the basic information\nof legislators such as party affiliation, committee member-\nships, core group affiliations, educational background, num-\nber of children, place of birth, and other relevant details.\nConstituency details This section details the legislator’s\nconstituency, including information such as the median fam-\nily income of the district, urban-rural population distribu-\ntion, and total population. This information helps model the\nsocial and economic context in which the legislator operates.\nSponsorship activity Each bill is initiated by a sponsor\nand possibly several cosponsors. Historical records of bill\nsponsorship are extremely useful for modeling a legislator’s\nspecific preferences. Past studies have also demonstrated\nthe significance of sponsorship information in political ac-\ntor modeling (Yang et al. 2021).\nVoting records: Historical voting records provide the\nmost direct data on a legislator’s political stance. Unlike pre-\nvious political actor models, the PAA integrates past voting\nrecords directly into the profile without explicit model train-\ning. Leveraging the capabilities of large language models,\nwe can predict voting outcomes based on a limited amount\nof known information, which is particularly useful when\nmodeling newly elected legislators with less data available.\nMulti-view Planning Module\nInspired by political science, the planning module decom-\nposes the task of voting decision-making into three main\nviews, aiding the agent in decision-making. In the ap-\npendix, we present the prompts used for these different\nviews (Alexander 2019).\nTrustee view The Trustee view implies that the legislator\nrelies on their expertise, making decisions based on what\nthey believe to be the best policies for their constituents and\nthe country.\nDelegate view The Delegate view indicates that the legis-\nlator sees their role as expressing the will of the majority of\ntheir constituents, acting in accordance with the wishes of\ntheir voters.\nFollower view Legislators in this category follow the\nopinions of their party leaders. They are not keen on reflect-\ning public opinion directly and often lack substantial per-\nsonal insights.\nPractical evidence shows that legislators’ decisions are in-\nfluenced by multiple views. After planning through these\n390\nData Simulated Legislative ActionProfile Construction\nMulti-view Planning\nWiki Page\nBill Information\n……\nConstituency\nPersonal information\nTrustee View Prompt\nDelegate View Prompt\nFollower View Prompt\nLeader Agents\nOther Agents\ncorresponding\nVoting Action\nYea Nay\ninfluence\nSpeaker of \nthe House\nMajority \nLeader\nDemocratic \nLeader\nCaucus \nMembers\nCommittee \nChair\n……\nConstituency details\nSponsorship activity\nVoting records\nFigure 2: Framework of PAA\nvarious views, the agent synthesizes these results to arrive\nat the final decision.\nSimulated Legislative Action Module\nPrevious political actor models, while recognizing differ-\nences among legislators, typically generated predictions in\na single step. Embedding-based methods fail to intricately\nsimulate the decision-making processes of real legislators\nand do not effectively model the influence of leader figures.\nIn the PAA, we have designed an ”influence mechanism” to\nmodel how leading agents influence other agents.\nLeader agents Leader agents, denoted as L , comprise the\nfollowing agents:\nL = {S, R, D, CC, CM}, (1)\nwhere S represents the Speaker of the House, R and D rep-\nresent the Republican and Democratic Leader, respectively,\nwith information sourced from the official website1. CC de-\nnotes the Chairperson of the committee introducing the bill,\nand CM represents caucus members related to the bill. A\ncongressional caucus is a group of members of the United\nStates Congress who meet to pursue common legislative ob-\njectives, often actively pushing legislation through their ac-\ntions.\nInfluence mechanism In the influence mechanism, leader\nagents first vote based on the multi-view planning module.\nVl = p(L), (2)\nwhere Vl represents the voting prediction of leader agents,\nand p represents the multi-view planning module. The vot-\ning prediction for the remaining agents O is as follows:\nVo = p(O|Vl), (3)\n1https://www.house.gov/leadership\nwhere Vo represents the voting predictions of other agents,\nmade under the condition of knowing Vl, p(O|Vl) indicates\nthat we include Vl in the prompt to predict the vote of agent\nO. This method effectively approximates the real-world leg-\nislative process. It is worth noting that this influence mecha-\nnism is highly flexible and can be adapted to different condi-\ntions for selecting leadership agents. The configuration pre-\nsented here is just one of the possible scenarios.\nExperiments\nIn this section, we conduct a detailed evaluation of the Polit-\nical Actor Agent (PAA) in predicting roll call votes. Section\n4.1 introduces the datasets selected for the experiment and\nthe baselines used. Section 4.2 details the experimental re-\nsults across different dataset splits. Sections 4.3 and 4.4 fea-\nture extensive ablation studies, analyzing the impact of vari-\nous PAA modules on the outcomes, with a deep dive into the\nprofile module. Section 4.5 demonstrates the consistency of\nthe PAA’s results. Section 4.6 provides an interpretable ex-\nample to illustrate how the PAA generates its predictions.\nDatasets and Baselines\nWe selected voting data from the 117th to 118th House\nof Representatives, covering 432 legislators. In addition to\nthe voting data for bills, we collected additional data for\nconstructing profiles and heterogeneous information graphs.\nThis includes the most recent Wikipedia pages of the leg-\nislators (as of March 2024), Wikipedia pages for all con-\nstituencies, data on the sponsors and cosponsors of bills, and\nTwitter posts by the legislators. We selected five methods as\nbaselines, including a variant of the ideal point model, three\ngraph-based models, and one that incorporates a pre-trained\nmodel.\n391\n1. ideal-vector (Kraft, Jain, and Rush 2016): A multi-\ndimensional ideal point model based on word embed-\ndings, learning politician representations from bill texts.\n2. LSTM+GCN (Yang et al. 2021): A graph-based model\nusing a Graph Convolutional Network (GCN) to generate\nrepresentations of legislators and an LSTM to generate\nrepresentations of bill texts.\n3. Vote+MTL(Mou et al. 2021): A graph-based model that\nincorporates Twitter data, using a Relational Graph Con-\nvolutional Network (RGCN) to generate representations\nof politicians.\n4. PAR (Feng et al. 2022): A graph-based model that com-\nbines various socio-contextual information, integrating\nrepresentational models with expert knowledge to gen-\nerate politician representations.\n5. UPPAM(Mou et al. 2023): A contrastive learning frame-\nwork based on the social network of legislators and bill\ntexts, using pre-trained models to generate politician rep-\nresentations.\nRoll Call Vote Prediction\nImplementation We divided the dataset in chronological\norder and selected three different ratios for dataset splits.\n1. split 244: 20% training, 40% validation, 40% testing.\n2. split 433: 40% training, 30% validation, 30% testing.\n3. split 622: 60% training, 20% validation, 20% testing.\nAs an agent-based approach, the PAA does not train mod-\nels. Instead, we sample 20 voting records from the training\nset to construct the profile for each agent and directly evalu-\nate the results on the test set.\nOur methods were tested using Llama-3-70B (PAAL) and\nGPT-4o-mini (PAAG) as the base models. We chose accu-\nracy and macro-averaged F1-score as metrics to evaluate the\nmodel’s performance on a three-class task: in favor, against,\nand abstaining. We conducted experiments for PAA L on a\nfour NVIDIA RTX A6000 GPUs, while the PAA G experi-\nments were carried out using the OpenAI API2.\nResults The results are presented in table 1. The primary\nfindings of the experiment indicate that PAA G consistently\noutperformed across all dataset splits, achieving superior re-\nsults compared to state-of-the-art methods. PAAL performed\nparticularly well in terms of the macro-averaged F1 score.\nThis is largely due to the label imbalance in the three-class\nvoting problem. As the proportion of the training set de-\ncreases within the dataset, the performance of embedding-\nbased methods declines more rapidly, whereas PAA remains\nmore stable. This suggests that PAA is better adapted to sce-\nnarios with limited data, such as predicting the voting be-\nhavior of new legislators.\nPAR and UPPAM performed next best to PAA G in the\nsplit622. PAR learns representations of legislators through\nexternal knowledge and social media corpora, while UP-\nPAM utilizes extensive social media data to train a pre-\ntrained model. Their performance in the voting prediction\n2https://platform.openai.com/docs/api-reference/introduction\ntask also validates the capabilities of large-scale external\nknowledge and pre-trained models. Unlike these methods,\nour approach does not utilize any social media data. With\nthe aid of LLMs, PAA achieves comparable or even supe-\nrior results under less time and data constraints.\nAblation Studies\nImplementation We designed ablation experiments to\nfurther verify the impact of various modules on the perfor-\nmance of the PAA. On the split244, while keeping other con-\nditions constant, we individually removed the profile mod-\nule, the planning module, and the acting module to assess\ntheir individual contributions to the PAA’s effectiveness.\n1. PAA w/o Pro: Remove profile module.\n2. PAA w/o Pla: Remove planning module.\n3. PAA w/o Act: Remove acting module.\nResult The experimental results are shown in table 2. The\nresults indicate that different modules impact the perfor-\nmance of the PAA to varying degrees. Notably, the profile\nmodule has the greatest effect, as it contains a wealth of cru-\ncial information, including personal details, voting records,\nand more. Next, we will further explore the influence of the\nprofile on the performance of the PAA.\nAnalysis of Profile Module\nImplementation The profile module comprises four key\ncomponents: legislator personal information, constituency\ndetails, legislative sponsorship activity, and voting records.\nWe have designed experiments to address specific concerns\nrelated to the performance of the PAA. RQ1: The outstand-\ning performance of PAA might be attributed to the fact that\nthe agent, based on a large language model, had already been\nexposed to legislative information and legislator-related cor-\npora during the pre-training phase. RQ2: Which part of the\nagent profile plays a more significant role in predicting out-\ncomes? RQ3: Does an excessive length of voting records\ndilute the importance of other components and adversely af-\nfect the performance of the experiments?\nBased on the considerations above, for RQ1 and RQ2, we\nconducted detailed experiments on the split 244 dataset with\nPAAG. For RQ3, we devised an experiment to analyze the ef-\nfect of the length of voting records on the performance of the\nPAA. One approach involves sampling 20 data points from\nthe training set to add to the profile, while another uses the\nentire training set. The PAA variants used in the experiment\nare as follows:\n1. PAA ano: Anonymize the names of legislators and bill\nnumbers. Names and bill numbers are replaced with ran-\ndom numbers.\n2. PAA dec: Introduce incorrect information to deceive the\nlarge language model; we swapped names of legislators\nwith differing stances to observe whether PAA predicts\nbased on pre-trained data.\n3. PAA w/o Per: Remove basic information about legisla-\ntors from the profile.\n4. PAA w/o Con: Remove constituency information from\nthe profile.\n392\nMethod split244 split433 split622\nacc f1 acc f1 acc f1\nideal-vector 80.9 ± 0.12 79.2 ± 0.13 82.2 ± 0.23 80.6 ± 0.36 86.1 ± 0.32 84.4 ± 0.25\nLSTM+GCN 83.5 ± 0.13 82.5 ± 0.12 85.3 ± 0.12 83.2 ± 0.35 87.8 ± 0.08 85.2 ± 0.12\nV ote+MTL 83.2 ± 0.04 83.5 ± 0.12 84.2 ± 0.20 84.3 ± 0.03 89.5 ± 0.14 86.2 ± 0.06\nPAR 85.3 ± 0.11 80.2 ± 0.12 85.8 ± 0.12 85.2 ± 0.12 90.2 ± 0.23 87.5 ± 0.03\nUPPAM 86.5 ± 0.10 80.5 ± 0.07 88.5 ± 0.03 85.9 ± 0.03 91.7 ± 0.08 86.3 ± 0.09\nPAAL 85.9 ± 0.10 87.2 ± 0.08 85.7 ± 0.10 88.1 ± 0.07 87.7 ± 0.05 89.6 ± 0.05\nPAAG 91.8 ± 0.15 92.2 ± 0.10 91.3 ± 0.20 91.7 ± 0.12 92.1 ± 0.10 93.0 ± 0.12\nTable 1: Results of various methods on different splits. The best results are highlighted in bold, and the second-best results are\nunderlined. Each experimental group was run five times, and we show the mean and standard deviation in the table.\nMethod split244\nacc f1\nPAA w/o Pro 78.6 ± 0.10 73.4 ± 0.07\nPAA w/o Pla 80.1 ± 0.12 74.1 ± 0.13\nPAA w/o Act 80.7 ± 0.19 74.2 ± 0.16\nPAAG 91.8 ± 0.15 92.2 ± 0.10\nTable 2: The results of ablation experiments conducted on\nthe profile, planning, and action modules.\n5. PAA w/o Spo: Remove information about Sponsored and\nCosponsored Bills from the profile.\n6. PAA w/o Rec: Remove voting records from the profile.\n7. PAA F\nG, PAAF\nL: Use the entire training set data for voting\nin the profile.\nResults The results are presented in table 3. From the find-\nings, we can see that both PAAano and PAAdec exhibit a de-\ncrease in predictive performance when names and bill iden-\ntifiers are modified. The fact that PAA dec performs slightly\nworse than PAAano suggests that legislator information has\na certain impact on the experimental results. Yet, both vari-\nants still significantly outperform the current baselines. Our\nfindings indicate that model performance is only slightly af-\nfected by the names, suggesting that PAA likely relies on the\ninformation in our profile module for predictions.\nAdditionally, the study of the profile reveals that all four\ntypes of information we selected are effective for prediction.\nBasic information, sponsorship, and voting records have the\nmost significant impact, while constituency information has\nthe least. This might be because the relationship between\nconstituency and voting behavior is less apparent compared\nto other information, suggesting the need for more explicit\nmechanisms to better utilize this data.\nThe experimental results, as shown in figure 3, indicate\nthat as the size of the training set increases, the performance\nof PAAL and PAAG improves, achieving the best results on\nthe split622 dataset. However, the performance of PAAF\nL and\nPAAF\nG gradually declines, with the worst results observed\non the split622 dataset. This suggests that an excessive num-\nber of voting records can confuse the large language model,\npreventing it from capturing other important information.\nTherefore the PAA opts for a sampling method to construct\nMethod split244\nacc f1\nPAA-ano 90.8 ± 0.10 91.3 ± 0.08\nPAA-Dec 90.1 ± 0.08 90.7 ± 0.11\nPAA w/o Per 82.9 ± 0.17 76.3 ± 0.23\nPAA w/o Con 90.9 ± 0.06 91.3 ± 0.09\nPAA w/o Spo 83.6 ± 0.09 78.9 ± 0.05\nPAA w/o Rec 83.4 ± 0.13 77.8 ± 0.19\nPAAG 91.8 ± 0.15 92.2 ± 0.10\nTable 3: The results of the ablation experiments that modi-\nfied the profile module.\nprofiles, achieving better performance with fewer resources.\n78\n80\n82\n84\n86\n88\n90\n92\n94\n82\n84\n86\n88\n90\n92\n94\nAccuracyF1\nPAAG PAAL PAAG\nF PAAL\nF\nsplit244 split433 split622\nsplit244 split433 split622\nFigure 3: The results on the impact of profile length on the\nperformance of the PAA.\n393\nConsistency Analysis\nImplementation Unlike other embedding-based models\nthat generate representations of legislators, large language\nmodels are prone to underlying hallucinations, potentially\ngenerating different results across multiple runs. Therefore,\nwe analyzed the consistency of results produced by the PAA.\nWe randomly selected 50 legislator agent and bill pairs and\nrepeated the experiment 20 times.\nResults The experimental results using PAA G and PAAL\nare shown in figure 4 respectively. In the heatmaps, red\nindicates correct predictions, while blue denotes incorrect\npredictions. The horizontal axis represents different experi-\nmental runs, and the vertical axis represents different agent-\nbill pairs. Overall, we observed that the hallucination phe-\nnomenon commonly associated with large language mod-\nels was not significant. Specifically, PAAL showed stronger\nconsistency, with only a few instances where the same\nagent-bill pair produced different results across experiments.\nMeanwhile, PAAG achieved a higher number of correct pre-\ndictions, though its consistency was not as strong as that\nof Llama-3-70B. Thus, conducting multiple experiments to\nmitigate the effects of hallucinations is highly beneficial.\nNumber of experiments\n0 2010\n50\n25\nLegislator-Bill Pairs\nLlama-3-70B\nLegislator-Bill Pairs\n0 2010\n50\n25\nNumber of experiments\nGPT-4o-mini\nFigure 4: The consistency experiment results.\nInterpretability\nAs shown in figure 5, we present an example to illustrate\nthe interpretability of the PAA’s voting prediction results. In\nthis example, the Agent explains its choice from three differ-\nent views, each backed by factual evidence. It is noteworthy\nthat he mentioned his conservative inclinations and the cor-\nresponding choice of leadership agent, which highlights the\neffectiveness of our multi-view planning module and influ-\nence mechanism.\nConclusion\nIn this study, we introduced the Political Actor Agent (PAA),\nan innovative approach leveraging Large Language Mod-\nels (LLMs) for the predictive modeling of legislative be-\nLegislator 026- \"250th Anniversary of the United States \nMarine Corps Commemorative Coin Act (H.R. 1096)\":\nReal result：Yea  \nPrediction result: Yea\nReason：\nTrustee: As a proud Republican with deep respect for \nour military, supporting this bill aligns with my career \nfocus on honoring those who serve. I believe it's \nessential to recognize and celebrate the sacrifices made \nby our armed forces, which reflects my commitment to \nupholding our nation's values.\nDelegate: My district has a strong military presence, and \nmany of my constituents have served or have family \nmembers in the military. By supporting this bill, I am \nnot only honoring their service but also ensuring that \ntheir legacy is remembered, which is something my \nvoters deeply care about.\nFollower: The Republican leadership has shown strong \nsupport for this bill, emphasizing its importance in \ncelebrating our military's heritage. Their endorsement \nreinforced my decision, as it reflects our party's shared \ncommitment to the armed forces.\nFigure 5: An example demonstrating how an agent cast a\nvote and subsequently summarize the reasons for its deci-\nsion.\nhavior. By incorporating agents in a role-playing architec-\nture, PAA uniquely simulates the dynamics of legislative\ndecision-making, providing a robust framework for under-\nstanding and predicting roll call votes. The utilization of\nextensive pre-existing knowledge and reasoning capabilities\nfrom LLMs ensures high accuracy and interpretability with-\nout relying on massive bespoke training datasets. Addition-\nally, although our experiments focused on U.S. legislators,\nPAA can be easily extended to other countries.\nHowever, the PAA also has several limitations: 1. Data\nDiversity: Despite achieving superior performance com-\npared to baselines with fewer data types, the current archi-\ntecture lacks support for integrating diverse data sources\nlike social media commentary and news. 2. Task Diver-\nsity: Compared to existing political actor modeling meth-\nods, PAA primarily supports the task of roll call vote predic-\ntion. Developing mechanisms to support more downstream\ntasks remains an unresolved issue. 3. Hallucination: Sta-\nble and consistent prediction results are essential, although\nwe have analyzed PAA’s results from a consistency perspec-\ntive, The hallucination issue in LLMs is complex, and con-\nsistency is only one measure of it.\nIn the future, we plan to further explore the integration\nof more diverse data types, such as real-time social media\nanalytics and global news events, to enhance the predictive\npower of PAA. Additionally, we aim to design more versatile\nmechanisms to accommodate different downstream tasks,\nbroadening the applicability and utility of the PAA in com-\nputational political science.\n394\nAcknowledgments\nThis work was supported by the Key R&D Program of China\nunder Grant 2022YFB2901202.\nReferences\nAlexander, R. M. 2019. Representation and the Electoral\nCollege. Oxford University Press.\nArgyle, L. P.; Busby, E. C.; Fulda, N.; Gubler, J. R.; Rytting,\nC.; and Wingate, D. 2023. Out of one, many: Using lan-\nguage models to simulate human samples. Political Analy-\nsis, 31(3): 337–351.\nBoiko, D. A.; MacKnight, R.; and Gomes, G. 2023. Emer-\ngent autonomous scientific research capabilities of large lan-\nguage models. arXiv preprint arXiv:2304.05332.\nChuang, Y .-S.; Studdiford, Z.; Nirunwiroj, K.; Goyal, A.;\nFrigo, V . V .; Yang, S.; Shah, D.; Hu, J.; and Rogers, T. T.\n2024. Beyond Demographics: Aligning Role-playing LLM-\nbased Agents Using Human Belief Networks.arXiv preprint\narXiv:2406.17232.\nClinton, J.; Jackman, S.; and Rivers, D. 2004. The statistical\nanalysis of roll call data.American Political Science Review,\n98(2): 355–370.\nDai, G.; Zhang, W.; Li, J.; Yang, S.; Rao, S.; Caetano, A.;\nSra, M.; et al. 2024. Artificial Leviathan: Exploring Social\nEvolution of LLM Agents Through the Lens of Hobbesian\nSocial Contract Theory. arXiv preprint arXiv:2406.14373.\nDavoodi, M.; Waltenburg, E.; and Goldwasser, D. 2020. Un-\nderstanding the language of political agreement and dis-\nagreement in legislative texts. In Proceedings of the 58th\nAnnual Meeting of the Association for Computational Lin-\nguistics, 5358–5368.\nDavoodi, M.; Waltenburg, E.; and Goldwasser, D. 2022.\nModeling US state-level policies by extracting winners and\nlosers from legislative texts. In Proceedings of the 60th An-\nnual Meeting of the Association for Computational Linguis-\ntics (Volume 1: Long Papers), 270–284.\nFeng, S.; Chen, Z.; Zhang, W.; Li, Q.; Zheng, Q.; Chang,\nX.; and Luo, M. 2021. Kgap: Knowledge graph augmented\npolitical perspective detection in news media.arXiv preprint\narXiv:2108.03861.\nFeng, S.; Tan, Z.; Chen, Z.; Wang, N.; Yu, P.; Zheng, Q.;\nChang, X.; and Luo, M. 2022. PAR: Political actor repre-\nsentation learning with social context and expert knowledge.\narXiv preprint arXiv:2210.08362.\nGerrish, S. M.; and Blei, D. M. 2011. Predicting legislative\nroll calls from text. In Proceedings of the 28th International\nConference on Machine Learning, ICML 2011.\nGu, Y .; Sun, Y .; Jiang, N.; Wang, B.; and Chen, T. 2014.\nTopic-factorized ideal point estimation model for legislative\nvoting network. In Proceedings of the 20th ACM SIGKDD\ninternational conference on Knowledge discovery and data\nmining, 183–192.\nHorton, J. J. 2023. Large language models as simulated eco-\nnomic agents: What can we learn from homo silicus? Tech-\nnical report, National Bureau of Economic Research.\nKim, J.; Kovach, M.; Lee, K.-M.; Shin, E.; and Tzavel-\nlas, H. 2024. Learning to be Homo Economicus: Can\nan LLM Learn Preferences from Choice. arXiv preprint\narXiv:2401.07345.\nKraft, P.; Jain, H.; and Rush, A. M. 2016. An embedding\nmodel for predicting roll-call votes. In Proceedings of the\n2016 conference on empirical methods in natural language\nprocessing, 2066–2070.\nLi, C.; and Goldwasser, D. 2019. Encoding social informa-\ntion with graph convolutional networks forpolitical perspec-\ntive detection in news media. In Proceedings of the 57th\nannual meeting of the association for computational linguis-\ntics, 2594–2604.\nLi, G.; Hammoud, H.; Itani, H.; Khizbullin, D.; and\nGhanem, B. 2023. Camel: Communicative agents for”\nmind” exploration of large language model society. Ad-\nvances in Neural Information Processing Systems, 36:\n51991–52008.\nMajumdar, S.; Elkind, E.; and Pournaras, E. 2024a. Gen-\nerative AI V oting: Fair Collective Choice is Resilient\nto LLM Biases and Inconsistencies. arXiv preprint\narXiv:2406.11871.\nMajumdar, S.; Elkind, E.; and Pournaras, E. 2024b. Gen-\nerative AI V oting: Fair Collective Choice is Resilient\nto LLM Biases and Inconsistencies. arXiv preprint\narXiv:2406.11871.\nMou, X.; Li, Z.; Lyu, H.; Luo, J.; and Wei, Z. 2024. Unify-\ning Local and Global Knowledge: Empowering Large Lan-\nguage Models as Political Experts with Knowledge Graphs.\nIn Proceedings of the ACM on Web Conference 2024, 2603–\n2614.\nMou, X.; Wei, Z.; Chen, L.; Ning, S.; He, Y .; Jiang, C.; and\nHuang, X.-J. 2021. Align voting behavior with public state-\nments for legislator representation learning. In Proceedings\nof the 59th Annual Meeting of the Association for Compu-\ntational Linguistics and the 11th International Joint Con-\nference on Natural Language Processing (Volume 1: Long\nPapers), 1236–1246.\nMou, X.; Wei, Z.; and Huang, X. 2024. Unveiling\nthe truth and facilitating change: Towards agent-based\nlarge-scale social movement simulation. arXiv preprint\narXiv:2402.16333.\nMou, X.; Wei, Z.; Zhang, Q.; and Huang, X.-J. 2023. Up-\npam: A unified pre-training architecture for political actor\nmodeling based on language. In Proceedings of the 61st\nAnnual Meeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers), 11996–12012.\nPoole, K. T.; and Rosenthal, H. 1985. A spatial model for\nlegislative roll call analysis. American journal of political\nscience, 357–384.\nQian, C.; Cong, X.; Yang, C.; Chen, W.; Su, Y .; Xu, J.; Liu,\nZ.; and Sun, M. 2023. Communicative agents for software\ndevelopment. arXiv preprint arXiv:2307.07924.\nVafa, K.; Naidu, S.; and Blei, D. 2020. Text-Based Ideal\nPoints. In Proceedings of the 58th Annual Meeting of the\nAssociation for Computational Linguistics, 5345–5357.\n395\nWang, L.; Ma, C.; Feng, X.; Zhang, Z.; Yang, H.; Zhang, J.;\nChen, Z.; Tang, J.; Chen, X.; Lin, Y .; et al. 2024. A survey on\nlarge language model based autonomous agents. Frontiers\nof Computer Science, 18(6): 186345.\nWu, Z.; Wang, Z.; Xu, X.; Lu, J.; and Yan, H. 2023. Embod-\nied task planning with large language models.arXiv preprint\narXiv:2307.01848.\nYang, J. C.; Korecki, M.; Dailisan, D.; Hausladen, C. I.; and\nHelbing, D. 2024. Llm voting: Human choices and ai col-\nlective decision making. arXiv preprint arXiv:2402.01766.\nYang, Y .; Lin, X.; Lin, G.; Huang, Z.; Jiang, C.; and Wei, Z.\n2021. Joint representation learning of legislator and legisla-\ntion for roll call prediction. In Proceedings of the Twenty-\nNinth International Conference on International Joint Con-\nferences on Artificial Intelligence, 1424–1430.\nZhou, Y .; Ni, Y .; Liu, X.; Zhang, J.; Liu, S.; Ye, G.; and Chai,\nH. 2024a. Are Large Language Models Rational Investors?\narXiv preprint arXiv:2402.12713.\nZhou, Y .; Ni, Y .; Liu, X.; Zhang, J.; Liu, S.; Ye, G.; and Chai,\nH. 2024b. Are Large Language Models Rational Investors?\narXiv preprint arXiv:2402.12713.\n396",
  "topic": "Legislature",
  "concepts": [
    {
      "name": "Legislature",
      "score": 0.7607808113098145
    },
    {
      "name": "Politics",
      "score": 0.6380777955055237
    },
    {
      "name": "Roll call",
      "score": 0.4791692793369293
    },
    {
      "name": "Computer science",
      "score": 0.4708912968635559
    },
    {
      "name": "Political science",
      "score": 0.39280053973197937
    },
    {
      "name": "Voting",
      "score": 0.14637944102287292
    },
    {
      "name": "Law",
      "score": 0.13997134566307068
    }
  ],
  "institutions": [],
  "cited_by": 1
}