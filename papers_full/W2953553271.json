{
  "title": "NULI at SemEval-2019 Task 6: Transfer Learning for Offensive Language Detection using Bidirectional Transformers",
  "url": "https://openalex.org/W2953553271",
  "year": 2019,
  "authors": [
    {
      "id": "https://openalex.org/A2028289032",
      "name": "Ping Liu",
      "affiliations": [
        "Illinois Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A1966168618",
      "name": "Wen Li",
      "affiliations": [
        "Indiana University"
      ]
    },
    {
      "id": "https://openalex.org/A2113383548",
      "name": "Liang Zou",
      "affiliations": [
        "New York University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2962740662",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W80056832",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2963943967",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2595653137",
    "https://openalex.org/W2588334501",
    "https://openalex.org/W2922580172",
    "https://openalex.org/W2739978796",
    "https://openalex.org/W3100063718",
    "https://openalex.org/W205930466",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2740168486",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2962977603"
  ],
  "abstract": "Transfer learning and domain adaptive learning have been applied to various fields including computer vision (e.g., image recognition) and natural language processing (e.g., text classification). One of the benefits of transfer learning is to learn effectively and efficiently from limited labeled data with a pre-trained model. In the shared task of identifying and categorizing offensive language in social media, we preprocess the dataset according to the language behaviors on social media, and then adapt and fine-tune the Bidirectional Encoder Representation from Transformer (BERT) pre-trained by Google AI Language team. Our team NULI wins the first place (1st) in Sub-task A - Offensive Language Identification and is ranked 4th and 18th in Sub-task B - Automatic Categorization of Offense Types and Sub-task C - Offense Target Identification respectively.",
  "full_text": "Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019), pages 87–91\nMinneapolis, Minnesota, USA, June 6–7, 2019. ©2019 Association for Computational Linguistics\n87\nNULI at SemEval-2019 Task 6: Transfer Learning for Offensive\nLanguage Detection using Bidirectional Transformers\nPing Liu\nDepartment of Computer Science\nIllinois Institute of Technology\npliu19@hawk.iit.edu\nWen Li\nDepartment of Linguistics\nIndiana University\nwl9@indiana.edu\nLiang Zou\nDepartment of Mathematics\nNew York University\nlz1904@nyu.edu\nAbstract\nTransfer learning and domain adaptive learn-\ning have been applied to various ﬁelds in-\ncluding computer vision (e.g., image recog-\nnition) and natural language processing (e.g.,\ntext classiﬁcation). One of the beneﬁts of\ntransfer learning is to learn effectively and ef-\nﬁciently from limited labeled data with a pre-\ntrained model. In the shared task of identi-\nfying and categorizing offensive language in\nsocial media, we preprocess the dataset ac-\ncording to the language behaviors on social\nmedia, and then adapt and ﬁne-tune the Bidi-\nrectional Encoder Representation from Trans-\nformer (BERT) pre-trained by Google AI Lan-\nguage team1. Our team NULI wins the ﬁrst\nplace (1st) in Sub-task A - Offensive Lan-\nguage Identiﬁcation and is ranked 4th and 18th\nin Sub-task B - Automatic Categorization of\nOffense Types and Sub-task C - Offense Tar-\nget Identiﬁcation respectively.\n1 Introduction\nAnti-social online behaviors, including cyberbul-\nlying, trolling and offensive language (Xu et al.,\n2012; Kwok and Wang, 2013; Cheng et al., 2017),\nare attracting more attention on different social\nnetworks. The intervention of such behaviors\nshould be taken at the earliest opportunity. Auto-\nmatic offensive language detection using machine\nlearning algorithms becomes one solution to iden-\ntifying such hostility and has shown promising\nperformance.\nIn SemEval-2019 Task 6: Identifying and Cat-\negorizing Offensive Language in Social Media\n(Zampieri et al., 2019b), the organizers collected\ntweets through Twitter API and annotated them hi-\nerarchically regarding offensive language, offense\ntype, and offense target. The task is divided into\nthree sub-tasks: a) detecting if a post is offensive\n1https://github.com/google-research/bert\n(OFF) or not (NOT); b) identifying the offense\ntype of an offensive post as targeted insult (TIN),\ntargeted threat (TTH), or untargeted (UNT); c) for\na post labeled as TIN/TTH in sub-task B, identify-\ning the target of offense as individual (IND), group\nof people (GRP), organization or entity (ORG),\nor other (OTH). The three sub-tasks are indepen-\ndently evaluated by macro-F1 metric.\nThe challenges of this shared task include: a)\ncomparatively small dataset makes it hard to train\ncomplex models; b) the characteristics of language\non social media pose difﬁculties such as out-of-\nvocabulary words and ungrammatical sentences;\nc) the distribution of target classes is imbalanced\nand inconsistent between training and test data. To\naddress the problem of out-of-vocabulary words\nespecially emoji and hashtags, we preprocess each\ntweet by interpreting emoji as meaningful En-\nglish phrases and segmenting hashtags into space\nseparated words. The classiﬁers we experiment\nwith include: linear model with features of word\nunigrams, word2vec, and Hatebase; word-based\nLong Short-Term Memory (LSTM); ﬁne-tuned\nBidirectional Encoder Representation from Trans-\nformer (BERT) (Devlin et al., 2018). We choose\nBERT for our ofﬁcial submission, since it per-\nforms the best in our experiments.\nIn the rest of this paper, we organize the con-\ntent as follows: related work of hostility on social\nmedia is stated in section 2; section 3 introduces\ndata description, details of preprocessing, and the\nmethodology of our models; experimental results\nare discussed in section 4. We also present the\nconclusion of our work at the end of paper.\n2 Related Work\nSchmidt and Wiegand (2017) surveyed features\nwidely used for hate speech detection, includ-\ning simple surface feature, word generalization,\n88\nknowledge-based features, etc. Davidson et al.\n(2017) reported hate speech detection results us-\ning word n-grams and sentiment lexicon and pro-\nvided insights on misclassiﬁed examples. A pro-\nposal of typology of abusive language sub-tasks\nis presented in (Waseem et al., 2017). (Liu et al.,\n2018) also discuss that the forecasting of the fu-\nture hostility on Instagram can be divided into\ntwo levels: presence and intensity. In addition\nto English, researchers also investigated offen-\nsive language detection for Chinese (Su et al.,\n2017) and Slovene (Fi ˇser et al., 2017). In the\nshared task on aggression identiﬁcation organ-\nised as part of the ﬁrst workshop on trolling, ag-\ngression and cyberbullying (TRAC - 1) at COL-\nING 2018, word/character n-grams and word em-\nbeddings were the most commonly used features\namong the participants, and the most popular clas-\nsiﬁers were SVM, LSTM, and RNN. The best per-\nforming system employed bidirectional LSTM on\nGlove embeddings.\n3 Data and Methodology\n3.1 Data Description\nOffensive Language Identiﬁcation Dataset (OLID)\n(Zampieri et al., 2019a) is collected from Twit-\nter API by searching certain keywords set. The\nkeywords include some unbiased targeted phrase\nsuch as ‘she is’, ‘he is’ and ‘you are’ which have\nhigh proportional offensive tweets. The distribu-\ntion of offensive tweets is controlled around 30%\nby using different sampling methods. Another ob-\nservation reported in the paper is political tweets\ntend to be more likely offensive using keywords\nas ‘MEGA’, ‘liberal’ and ‘conservative’.\nThe main task of this competition is decom-\nposed into three different levels according to the\nhierarchical annotation: a) Offensive Language\nDetection b) Categorization of Offensive Lan-\nguage c) Offensive Language Target Identiﬁca-\ntion. All the three different tasks share the same\ndataset, and the latter one is the subset of the pre-\nvious one.\nThe tasks release the dataset into three different\nparts, which are the startingKit, training dataset\nand testing dataset. The summary of dataset distri-\nbution is concluded in the Table1. From the table,\nit is easy to observe that the distribution of three\nsplittings is a little twisted which should be ex-\npected in real life, and also make the tasks much\nharder.\nClass StartKit Training Testing\nNOT 243 8840 620\nOFF 77 4400 280\nTIN 38 3876 213\nUNT 39 524 27\nIND 30 2407 100\nGRP 7 1074 78\nOTH 2 395 35\nTable 1: Data Distribution: The ﬁrst two rows are the\nclass distribution of sub-task A. The mid part two rows\nare the class distribution of sub-task B. The last three\nrows are the class distribution of sub-task C.\n3.2 Preprocessing\nEmoji substitution We use one online emoji\nproject on github2 which could map the emoji uni-\ncode to substituted phrase. We treat such phrases\ninto regular English phrase thus it could main-\ntain their semantic meanings, especially when the\ndataset size is limited.\nHashTag segmentation The HashTag becomes\na popular culture cross multi social networks, in-\ncluding Twitter, Instagram, Facebook etc. In order\nto detect whether the HashTag contains profan-\nity words, we apply word segmentation using one\nopen source on the github 3. One typical example\nwould be ‘#LunaticLeft’ is segmented as ‘Lunatic\nLeft’ which is obviously offensive in this case.\nMisc. We also convert all the text into lower\ncase. ‘URL’ is substituted by ‘http’, since ‘URL’\ndoes not have embedding representation in some\npre-trained embedding and models. Consecutive\n‘@USER’s are limited to three times to reduce the\nredundancy.\n3.3 Methodology\nLinear model We ﬁrstly select Logistic Re-\ngression as our baseline model to determine the\nlower bound performance that we should com-\npare. First we cross-validate hyper-parameters of\ndifferent vectorizers to build bag of words rep-\nresentation. Secondly, we adopt the pre-trained\nword2vec model from google4, then aggregate the\nmaximum and average value in each dimension.\n2https://github.com/carpedm20/emoji\n3https://github.com/grantjenks/python-wordsegment\n4https://code.google.com/archive/p/word2vec/\n89\n(a) Sub-task A (b) Sub-task B (c) Sub-task C\nSystem MacroF Acc\nAll NOT 0.4004 0.6677\nAll OFF 0.2494 0.3323\nLinear 0.7102 0.7273\nLSTM 0.7166 0.7659\nBERT 0.7826 0.8485\nSystem MacroF Acc\nAll TIN 0.4686 0.8818\nAll UNT 0.1057 0.1182\nLinear 0.6028 0.8000\nLSTM 0.5029 0.8795\nBERT 0.3830 0.8682\nSystem MacroF Acc\nAll GRP 0.1441 0.2758\nAll IND 0.2554 0.6211\nAll OTH 0.0623 0.1031\nLinear 0.5607 0.7062\nLSTM 0.5056 0.7036\nBERT 0.8435 0.7294\nTable 2: Results on Dev Data.\nThirdly, we use the dictionary Hatebase API 5 to\naggregate the hate words in each category. We val-\nidate all the features combinations, then report the\naccuracy and F1 with the highest to determine the\nmodel parameters.\nLSTM Long Short-Term Memory is introduced\nin 1991 (Hochreiter and Schmidhuber, 1997)\nwhich is an more powerful extension of recurrent\nneural network. The gates inside of LSTM could\nprevent gradient vanishing problem, to memorize\nthe long time dependency. LSTM has been used\nin tons of natural language processing task, such\nas sentiment classiﬁcation, neural translation, lan-\nguage generation etc. We would also like to use\nLSTM as our second powerful baseline model to\ncompare and report the result. The speciﬁc setting\nis the following: the input is mapped from one-\nhot encoder into a shared embedding layers with\ndimension 140; the hidden units of LSTM is 64\nand follower by a dropout layer with rate 0.5. The\nmaximum sequence length is 140, thus the sen-\ntences would be either cut off or padded.\nBERT Google research team releases Bidirec-\ntional Encoder Representation from Transformer\n(BERT) (Devlin et al., 2018) and achieve state of\nthe art results on many NLP tasks. BERT uses\nidentical multi-head transformer structure that is\nintroduced in (Vaswani et al., 2017). The model is\npre-trained on huge corpus from different sources.\nSince the dataset size in this SemEval-2019 Task\n6 is not that big, we pass the dataset into the pre-\ntrained BERT model, and report the loss and ac-\ncuracy at each epoch. The observation from ex-\nperiments shows that after 1st or 2nd epochs, the\nmodel converges fast and always get very lower\nloss on the validation set. In such case, in the\nsub-task B and sub-task C, we report the macro-\nF1 score after the model trains after 1st, 2nd and\n5http://www.hatebase.org\n3rd epoch.\n4 Experiment Results\nThe evaluation metric of this task is Macro-F1,\nwhich is the unweighted-average F1 of all the\nclasses. The imbalance distribution makes the\nmacro-F1 hard to achieve, and usually the score\nis penalized by the minority class. Weighted-loss\nis one solution during the training time to balance\nthe model not to lead to the majority class predic-\ntion.\nIn the table 2 and 3, we report the results of our\ndev-dataset and ﬁnal test dataset. From the table 2,\nwe list the performance of our three selected mod-\nels for each sub-task. The data is stratiﬁed split\ninto 9:1 as train and test. There is also one inde-\npendent validation set to determine the model se-\nlection that is split from train set. One observation\nfrom the table shows the problem of imbalanced\ndata, so that higher accuracy does not guarantee\nhigher macro-F1 score. Thus the stop criterion is\nbased on average loss of validation set we men-\ntioned before. Based on the results of validation,\nwe choose to use BERT as our selected model for\nthe ﬁnal submission.\nIn the table 3, it shows the results on ofﬁcial\ntest dataset. It should be noticed that in the sub-\ntask A, we also submit one result of a Bagging\nclassiﬁer with number 50, and Logistic Regression\nis the weak classiﬁer. The features are the same\nwith linear model we mentioned before. The re-\nsult from BERT model sub-task A achieves the 1st\nplace among all the participants. BERT-3 denotes\nwe train BERT with only 3 epochs. Same notation\nwith the latter two sub-tables. In the sub-task B\nand sub-task C, the results are not as good as sub-\ntask A due to two reasons: 1) the class distribu-\ntion is more skewed than that of sub-task A. 2) the\nnumber of training instance is much smaller than\nsub-task A. The worst performance is sub-task C,\n90\n(a) Sub-task A (b) Sub-task B (c) Sub-task C\nSystem MacroF Acc\nAll NOT 0.4189 0.7209\nAll OFF 0.2182 0.2790\nBagg 0.7558 0.8105\nLinear 0.7501 0.7953\nBERT-3 0.8286 0.8628\nSystem MacroF Acc\nAll TIN 0.4702 0.8875\nAll UNT 0.1011 0.1125\nBERT-1 0.6932 0.8875\nBERT-2 0.4702 0.8875\nBERT-3 0.7159 0.8958\nSystem MacroF Acc\nAll GRP 0.1787 0.3662\nAll IND 0.2130 0.4695\nAll OTH 0.0941 0.1643\nBERT-1 0.5267 0.7277\nBERT-2 0.5598 0.6948\nTable 3: Results on Test Data.\nNOT OFF\nPredicted label\nNOT\nOFF\nTrue label\n563 57\n61 179\nConfusion Matrix\n0.0\n0.2\n0.4\n0.6\n0.8\nFigure 1: Sub-task A, BERT model after ﬁne-tuning\nTIN UNT\nPredicted label\nTIN\nUNT True label\n203 10\n15 12\nConfusion Matrix\n0.0\n0.2\n0.4\n0.6\n0.8\nFigure 2: Sub-task B, BERT model after ﬁne-tuning\nsince it is three-class classiﬁcation, and the ‘OTH’\nclass has very few examples.\nThe confusion matrix of three sub-tasks are\nshown in ﬁg 1, 2, and 3. This is another way to\nexplain the results as we discussed before. The ﬁg-\nures are provided by the organizers, and we use the\nﬁgures to summarize test distribution in the table\n1. In the previous section, we mentioned the dis-\ncrepancy of class distribution between training and\ntest datasets. For example, in sub-task C, the class\n‘OTH’ constitutes 0.101 of the training data, while\nit makes up 0.164 of the test data. This adds difﬁ-\nculty to the task, however, we are often confronted\nwith the same situation in real-world problems.\nGRP IND OTH\nPredicted label\nGRP\nIND\nOTH True label\n60 17 1\n12 84 4\n22 9 4\nConfusion Matrix\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nFigure 3: Sub-task C, BERT model after ﬁne-tuning\n5 Conclusion\nOffensive language and online hostility is crucial\non the social network. The minority proportion\nof the nature and morphological language are the\ndifﬁculties to achieve high performance. The Di-\nversity and evolution of the language at different\nages is another challenge for social media detec-\ntion task. As a conclusion, our work shows the\ncompetitive results in this shared task using cus-\ntomized processing to dataset, as well as the power\nof pre-trained model. In real life, labeled data\nis always limited and requires expensive human\nlabors. In such case, transfer learning is always a\ngood option to get started. Domain adaption also\nhas prior knowledge of speciﬁc domain before do-\ning any modeling work on hand. How to tune the\nparameters is nontrivial, and there are a lot of more\nefﬁcient ways to be explored, which could yield\nbetter performance.\n91\nReferences\nJustin Cheng, Michael Bernstein, Cristian Danescu-\nNiculescu-Mizil, and Jure Leskovec. 2017. Anyone\ncan become a troll: Causes of trolling behavior in\nonline discussions. In Proceedings of the 2017 ACM\nconference on computer supported cooperative work\nand social computing, pages 1217–1230. ACM.\nThomas Davidson, Dana Warmsley, Michael Macy,\nand Ingmar Weber. 2017. Automated Hate Speech\nDetection and the Problem of Offensive Language.\nIn Proceedings of ICWSM.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. arXiv preprint arXiv:1810.04805.\nDarja Fiˇser, Tomaˇz Erjavec, and Nikola Ljubeˇsi´c. 2017.\nLegal Framework, Dataset and Annotation Schema\nfor Socially Unacceptable On-line Discourse Prac-\ntices in Slovene. In Proceedings of the Workshop\nWorkshop on Abusive Language Online (ALW), Van-\ncouver, Canada.\nSepp Hochreiter and J ¨urgen Schmidhuber. 1997.\nLong short-term memory. Neural computation ,\n9(8):1735–1780.\nIrene Kwok and Yuzhou Wang. 2013. Locate the\nhate: Detecting Tweets Against Blacks. In Twenty-\nSeventh AAAI Conference on Artiﬁcial Intelligence.\nPing Liu, Joshua Guberman, Libby Hemphill, and\nAron Culotta. 2018. Forecasting the presence and\nintensity of hostility on instagram using linguistic\nand social features. In Twelfth International AAAI\nConference on Web and Social Media.\nAnna Schmidt and Michael Wiegand. 2017. A Sur-\nvey on Hate Speech Detection Using Natural Lan-\nguage Processing. In Proceedings of the Fifth Inter-\nnational Workshop on Natural Language Process-\ning for Social Media. Association for Computational\nLinguistics, pages 1–10, Valencia, Spain.\nHuei-Po Su, Chen-Jie Huang, Hao-Tsung Chang, and\nChuan-Jie Lin. 2017. Rephrasing Profanity in Chi-\nnese Text. In Proceedings of the Workshop Work-\nshop on Abusive Language Online (ALW) , Vancou-\nver, Canada.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems, pages 5998–6008.\nZeerak Waseem, Thomas Davidson, Dana Warmsley,\nand Ingmar Weber. 2017. Understanding Abuse: A\nTypology of Abusive Language Detection Subtasks.\nIn Proceedings of the First Workshop on Abusive\nLangauge Online.\nJun-Ming Xu, Kwang-Sung Jun, Xiaojin Zhu, and\nAmy Bellmore. 2012. Learning from bullying traces\nin social media. In Proceedings of the 2012 confer-\nence of the North American chapter of the associa-\ntion for computational linguistics: Human language\ntechnologies, pages 656–666. Association for Com-\nputational Linguistics.\nMarcos Zampieri, Shervin Malmasi, Preslav Nakov,\nSara Rosenthal, Noura Farra, and Ritesh Kumar.\n2019a. Predicting the Type and Target of Offensive\nPosts in Social Media. In Proceedings of NAACL.\nMarcos Zampieri, Shervin Malmasi, Preslav Nakov,\nSara Rosenthal, Noura Farra, and Ritesh Kumar.\n2019b. SemEval-2019 Task 6: Identifying and Cat-\negorizing Offensive Language in Social Media (Of-\nfensEval). In Proceedings of The 13th International\nWorkshop on Semantic Evaluation (SemEval).",
  "topic": "Offensive",
  "concepts": [
    {
      "name": "Offensive",
      "score": 0.8786742687225342
    },
    {
      "name": "Computer science",
      "score": 0.7994186878204346
    },
    {
      "name": "Language identification",
      "score": 0.7124053239822388
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6418131589889526
    },
    {
      "name": "Categorization",
      "score": 0.6412861347198486
    },
    {
      "name": "Transformer",
      "score": 0.628287136554718
    },
    {
      "name": "SemEval",
      "score": 0.6204830408096313
    },
    {
      "name": "Transfer of learning",
      "score": 0.6101368069648743
    },
    {
      "name": "Natural language processing",
      "score": 0.5951104760169983
    },
    {
      "name": "Encoder",
      "score": 0.5648517608642578
    },
    {
      "name": "Task (project management)",
      "score": 0.5298457145690918
    },
    {
      "name": "Multi-task learning",
      "score": 0.47306621074676514
    },
    {
      "name": "Natural language",
      "score": 0.46802693605422974
    },
    {
      "name": "Machine learning",
      "score": 0.355207234621048
    },
    {
      "name": "Speech recognition",
      "score": 0.34831127524375916
    },
    {
      "name": "Engineering",
      "score": 0.08835199475288391
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    },
    {
      "name": "Operations research",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I180949307",
      "name": "Illinois Institute of Technology",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I592451",
      "name": "Indiana University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I57206974",
      "name": "New York University",
      "country": "US"
    }
  ],
  "cited_by": 171
}