{
  "title": "Method of Underwater Acoustic Signal Denoising Based on Dual-Path Transformer Network",
  "url": "https://openalex.org/W4312966247",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2112124272",
      "name": "Yongqiang Song",
      "affiliations": [
        "National University of Defense Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2006442482",
      "name": "Feng Liu",
      "affiliations": [
        "Chinese People's Liberation Army"
      ]
    },
    {
      "id": "https://openalex.org/A2153524251",
      "name": "Tongsheng Shen",
      "affiliations": [
        "Chinese People's Liberation Army"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3116360501",
    "https://openalex.org/W3129171852",
    "https://openalex.org/W3083806292",
    "https://openalex.org/W2902033916",
    "https://openalex.org/W2566039893",
    "https://openalex.org/W2169026211",
    "https://openalex.org/W1559883067",
    "https://openalex.org/W2347087257",
    "https://openalex.org/W2757713609",
    "https://openalex.org/W2580793313",
    "https://openalex.org/W2965120462",
    "https://openalex.org/W2887002979",
    "https://openalex.org/W2982088483",
    "https://openalex.org/W2980314190",
    "https://openalex.org/W2964856508",
    "https://openalex.org/W3022420203",
    "https://openalex.org/W3023121504",
    "https://openalex.org/W3128444015",
    "https://openalex.org/W3012178694",
    "https://openalex.org/W3094466931",
    "https://openalex.org/W3162168790",
    "https://openalex.org/W3217641970",
    "https://openalex.org/W3185546912",
    "https://openalex.org/W4229452064",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2466903746",
    "https://openalex.org/W3172124183",
    "https://openalex.org/W2284986873",
    "https://openalex.org/W6631190155",
    "https://openalex.org/W3185109982",
    "https://openalex.org/W2157394606",
    "https://openalex.org/W2964058413",
    "https://openalex.org/W2221409856",
    "https://openalex.org/W1522301498"
  ],
  "abstract": "The presence of natural ambient noise interferes with the system for locating and identifying underwater targets. This paper suggests that a Dual-Path Transformation Network (DPTN) reduces ambient noise in underwater acoustic signals. First, the input acoustic signals&#x2019; higher-order non-linear features are extracted using a multi-scale convolutional encoder neural network. Second, sub-vectors with the same length are created according to the time dimension from the higher-order non-linear features. The sub-vectors are stitched together to form a three-dimensional tensor. Third, a neural network transformer based on the feed-forward network is constructed. Further, to capture long-term series features and separate the target signal from the noisy signals, the three-dimensional tensor is used as the input of the transformer-based masking network. Finally, overlap-add and transpose are used to obtain discernible target signals. The experimental results verify the effectiveness of the proposed underwater acoustic signal denoising algorithm and demonstrate that the proposed DPRN method can obtain higher output signal-to-noise ratio (SNR) and the scale-invariant signal-to-noise ratio (SI-SNR) compared with the other classical algorithms.",
  "full_text": "Author et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\n.\nVOLUME 4, 2016 1\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2022.3224752\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nDate of publication xxxx 00, 0000, date of current version xxxx 00, 0000.\nDigital Object Identifier 10.1109/ACCESS.2017.DOI\nMethod of Underwater Acoustic Signal\nDenoising Based on Dual-Path\nTransformer Network\nYONGQIANG SONG1 FENG LIUR2, AND TONGSHENG SHEN.2, (Member, IEEE)\n1National Innovation Institute of Defense Technology, Beijing, 100071, China\n2Chinese Academy of Military Science, Beijing, 100071, China\nCorresponding author: First A. Author (e-mail: author@ boulder.nist.gov).\nThis research was funded by the National Natural Science Foundation of China, grant number 41906169.\nABSTRACT The presence of natural ambient noise interferes with the system for locating and identifying\nunderwater targets. This paper suggests that a Dual-Path Transformation Network(DPTN) reduces ambient\nnoise in underwater acoustic signals. First, the input acoustic signals’ higher-order non-linear features are\nextracted using a multi-scale convolutional encoder neural network. Second, sub-vectors with the same\nlength are created according to the time dimension from the higher-order non-linear features. The sub-\nvectors are stitched together to form a three-dimensional tensor. Third, a neural network transformer based\non the feed-forward network is constructed. Further, to capture long-term series features and separate the\ntarget signal from the noisy signals, the three-dimensional tensor is used as the input of the transformer-\nbased masking network. Finally, overlap-add and transpose are used to obtain discernible target signals. The\nexperimental results verify the effectiveness of the proposed underwater acoustic signal denoising algorithm\nand demonstrate that the proposed DPRN method can obtain higher output signal-to-noise ratio (SNR) and\nthe scale-invariant signal-to-noise ratio (SI-SNR) compared with the other classical algorithms.\nINDEX TERMS Deep learning; Underwater acoustics; Dual-Path transformer network\nI. INTRODUCTION\nThe study of underwater acoustics is a crucial foundation\nfor the passive sonar systems used by underwater vehicles\nto detect, track, localize, and identify targets in the marine\nenvironment [1]. However, the feature extraction of underwa-\nter acoustic signals by modern sonar systems is fraught with\nchallenges due to the complex natural environment, variable\nacoustic sources, and high noise intensity. Multi-target sig-\nnal mixing, complex spectral components, and interspersed\nnoise signals are the leading causes of these issues because\nthey lower the signal-to-noise ratio of the sonar acceptance\nsignal. Therefore, it is necessary to implement noise reduc-\ntion processing for the signals. At this stage, conventional\ndenoising methods usually use transformation analysis meth-\nods and time-to-frequency conversion methods to achieve\nsignal enhancement [2] [3]. For example, Amplitude-Aware\nPermutation Entropy [4] Wavelet and Block Thresholding\n[5] [6], multi-directional filters [7], Minimum Variance Dis-\ntortionless Response [8], Variational Approach [9], Wavelet\nTransform [10], Empirical Mode Decomposition [11] [12]\n[13], Linear Spectrum [14], Singular Value Decomposition\n[15].\nConventional methods for improving underwater acoustic\nsignals have apparent drawbacks in terms of signal-to-noise\nratio. Large-scale data and ocean environment parameters\ncannot be modeled using the constrained conditions of con-\nventional methods. It is not easy to iteratively update the data\nafter system deployment, making the underwater acoustic\nsignals detection for a long time dependent on manual in-\nterpretation. The background noise characteristics vary with\nthe ocean scene and can produce considerable dynamic de-\nviations at different times. Underwater acoustic signals are\nsubject to ambient and machine interference, which can cause\npropagation attenuation and distortion, resulting in a rela-\ntively low signal-to-noise ratio of the signal received by the\ndetection system. conventional methods in fitting the model\nneed to know the frequency range of the signal affected\nby propagation characteristics, target interference, transient\nsignals, and many other factors. There is a significant gap\nbetween the frequency range of different noises, which often\n2 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2022.3224752\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nleads to the model and noise type being unsuitable. The\nemergence of these problems makes conventional algorithms\nface many challenges.\nDeep learning-based models have great potential for de-\nnoising applications compared with conventional methods.\nDeep learning can learn correlations before and after time\nseries through neural networks. In addition, the introduction\nof filters allows the network to automatically capture the\nunderlying features of the signal. This process eliminates\nmanual extraction and automatically compiles the sequence\nin a coded fashion. This process eliminates manual extraction\nand automatically compiles the sequence in a coded fashion.\nThe model’s noise reduction effect can be improved by\nadjusting the parameters and modifying the network archi-\ntecture. For example, Zhou [16] proposes the Denoising Rep-\nresentation Recognition (DRR) model that converts the spec-\ntrum to a correlation coefficient to generate data for parallel\ntraining in the convolutional denoising autoencoder(CDAE)\nmodel. Wang [17] proposes a novel stacked convolutional\nsparse denoising autoencoder (SCSDA) model to complete\nthe blind denoising task of underwater heterogeneous in-\nformation data. The stacked sparse denoising autoencoder\n(SSDA) was constructed by three sparse denoising autoen-\ncoders (SDA) to extract overcomplete sparse features. The\noutput of the last encoding layer of the SSDA was used\nas the input of the convolutional neural network (CNN) to\nextract the features.Othman [18] proposes a residual deep\nneural network(Resnet), which works onIIR Wiener filter\nintegration to reduce noise. Alberto [19] proposes a novel\napproach based on a computationally and energy-efficient\ndeep convolutional denoising autoencoder to reduce the noise\ninterference. Qiu [20] proposes a reinforcement learning\nsystem that requires sophisticated design and critical pa-\nrameter choice to meet its oscillatory condition to keep the\nbalance among signals, noise, and the nonlinear system. Li\n[21] proposes an approach based on relativistic conditional\ngenerative adversarial networks (RCGAN) to resolve the\nconditions of complex marine ambient noise and scarce data.\nXing [22] trains and updates the noisy signal via orthogonal\nmatching pursuit (OMP) and method of optimal directions\n(MOD). The signal reconstruction is completed according to\nthe updated dictionary and sparse coefficients. To summarise,\nthe underwater acoustic signal denoising methods can be\nbroadly classified into three processing modes, time-domain\nprocessing, spectrogram mapping, and mask separation, as\nshown in Figure 1.\nThe mask separation method is now the dominant ap-\nproach compared to the first two methods, as shown in Figure\n2. Firstly, a set of features (e.g., Mel Frequency Cepstrum\nCoefficient, MFCC) is learned from the underwater acoustic\nsignal using the auditory properties of the human ear. A\nfilter is used to encode the features into a masking network\nto estimate the mask parameters for each source. Finally,\na decoder is used to recover the masked higher-order fea-\ntures into the underwater acoustic signal. Recurrent neural\nnetworks (e.g., Long Short-Term Memory and Gated Recur-\nrent Unit) can be used in many areas of signal processing.\nDeep learning methods built on recurrent neural networks\nare essential to modern signal processing. They are often\nused as a vital module for mask separation in the field of\nunderwater acoustic signal noise reduction [23] [24] [25].\nHowever, the inherent sequential processing sequence mode\nof the Recurrent Neural Network (RNN) prevents the model\nfrom parallelizing the computation during training. After the\nmodel feeds the audio file to the encoder via the index log,\nthe RNN-based masking process takes up most of the CUDA\nmemory space. When the natural ambient noise loudness\nmasks the target signal, gradient disappearance and explosion\nare often encountered during training using RNN models. It\nis challenging to calculate the multiplicative gradients, which\ncan vary exponentially with the number of layers due to the\ndifficulty in capturing long-term dependencies with RNN.\nIn order to obtain the denoised acoustic signal, we con-\nstruct a Dual-Path Transformer Network (DPTN) based on\nthe abovementioned analysis. This network combines the\ntechniques of multi-head attention transformer [26] and\nDual-path framework processing. This paper has three con-\ntributions:\n1. The one-dimensional convolutional neural network is\nbuilt to construct the encoder module, and a chunking op-\neration is used to convert the feature vector into a three-\ndimensional tensor. We cascade the encoder and chunk oper-\nation as a feature extraction module for underwater acoustic\nsignals.\n2. The multi-head attention converter and Dual-path\nframework construct the separation network to extract the\nfeature mask of the target signal. Further, the denoised signal\ntensor is restored to the original signal format using overlap-\nadd and transposition network.\n3. The Dual-Path transformer network (DPTN) can si-\nmultaneously focus on the complete underwater acoustic\nsequence information and process all time step points in par-\nallel. Relevance between far-off sampling points is achieved\nby adding a feedforward network and residual connections to\nthe masking network, making it more straightforward for the\nmodel to learn the long-term dependencies of the signal.\nThe specific content is arranged as follows: the Section.2\ndetails the flow of the method, namely Dual-Path Trans-\nformer Network (DPTN). The Section.3 uses the ablation\nexperiment and comparison test to analyse the influence of\neach step of the method in this paper, and the conclusion is\nin Section.4.\nII. MATERIALS AND METHODS\nThe proposed model is based on the learned-domain masking\napproach and employs a feature extraction module, masking\nseparation module, and signal reconfiguration module, as\nshown in Figure 3.\nThe feature extraction encode module is a one-dimensional\nconvolutional neural network that estimates a learned repre-\nsentation for the input signal. It learns a complete set of state\nchanges and the dynamic parameters of the filter from the\nVOLUME 4, 2016 3\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2022.3224752\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nFIGURE 1. A brief description of the acoustic signal denoising methods\nFIGURE 2. A brief description of the mask separation method\nexisting knowledge. Afterward, the feature vector is sliced\ninto sub-sequences of the same size without changing the\ndimensionality of the features. Finally, the subsequence is\nbuilt into a 3D tensor using chunking as the input to the\nmasking network. The masking network employs two trans-\nformers embedded inside the Dual-path processing block.\nThe masking network can be divided into two main parts:\nintra-transformer and inter-transformer, which rely on short-\nterm dependencies and long-term dependencies to learn the\ntarget signal and ambient noise, respectively. Moreover, the\ndifferent characteristics of the signal are learned by short-\nterm and long-term dependencies, respectively. The mask\nof the target signal is extracted by matrix amplification\nand compression operations. The mask and the higher-order\nfeatures of the signal are point multiply calculations by\nHadamard functions.Finally, the signal reconfiguration de-\ncode module reconstructs the underwater acoustic signals in\nthe time domain.\nA. FEATURE EXTRACTION ENCODE MODULE\nThe encoder takes in time-domain mixture underwater acous-\ntic signal x ∈ RT (where T is the time duration of the input\nsignal) as input, which contains target signal and ambient\nnoise signal. It learns an high-dimensional representation\nh ∈ RF×T (where F is the feature dimension of the\ninput signal) using the one-dimensional convolutional neural\nnetwork (Conv1D) and Relu activation function :\nh = Relu(Conv1D(x)) (1)\nB. SIGNAL RECONFIGURATION DECODE MODULE\nThe decoder uses a transposed convolution network, with\nthe same stride and kernel size of the encoder. The input to\nthe decoder is the element-wise multiplication between the\nmask mtarget and the output of the encoder h. Therefore, the\ntransformation of the decoder can be expressed as follows:\nStarget = T ransposeConv1D(mtarget ∗ h) (2)\nWhere Starget denotes the clearly target underwater acous-\ntic signal.\nC. TRANSFORMER BLOCK\nThe Dual-path approach is used in the transformer block to\nmodel both short-term and long-term dependencies. Figure 4\n4 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2022.3224752\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nFIGURE 3. A brief description of Dual-Path Transformer Network (DPTN)\nillustrates our model’s transformer block, intra-Transformer\nfor modeling short-term dependencies and inter-Transformer\nfor modeling longer-term dependencies.\nIntra-Transformer processes the second dimension of h′ ∈\nRF×C×Nc , and thus acts on each chunk independently,\nmodeling the short-term dependencies within each chunk.\nNext, we permute the last two dimensions (which we de-\nnote with P) and the inter-Transformer is applied to model\nthe transitions across chunks. This scheme enables effective\nmodelling of long-term dependencies across the chunks. The\noverall transformation of the transformer is therefore defined\nas follows:\nh′′ = finter (P (fintra (h′))) (3)\nwhere finter is the inter-Transformer operation and fintra\nis the intra-Transformer operation. Figure 5 shows the archi-\ntecture of the multi-head attention used to build for both the\nintra-Transformer and inter-Transformer blocks.\nAssume that the feature tensor g is the input to intra-\nTransformer. First of all, sinusoidal positional encoding (PE)\nfunction is added to the input g:\ng′ = g + P Epos (4)\nP E(pos,2i) = sin\n\u0010 pos\n1000(2i)/dmodel\n\u0011\n(5)\nP E(pos,2i+1) = cos\n\u0010 pos\n1000(2i+1)/dmodel\n\u0011\n(6)\nWe must introduce some information about the relative\nor absolute position of the tokens in the sequence since our\nmodel lacks recursive operations and convolution kernels that\nact on the sequence order. Then, several layers of deformers\nare applied, and inside each transformer layer L(.), we first\napply layer normalization, followed by the multi-head self-\nattention (MSA):\ng′′ = MSA (LayerNormalazation (g′)) (7)\nThe attention allows the model to jointly attend to infor-\nmation from different representation subspaces at different\npositions. Each attention head computes the scaled dot-\nproduct attention between all the sequence elements. The\ninput consists of queries ( Q), keys ( K), and values ( V ) of\nthe dimension. We compute the dot products of the query\nwith all keys, divide each by and apply a softmax function\nto obtain weights on the values. We simultaneously compute\nthe attention function on a set of queries packed into a matrix\nQ. The keys and values are also packed into matrices K and\nV . We compute the parameters matrix of outputs as:\nAttention (Q, K, V) =softmax\n\u0012QKT\n√dk\n\u0013\n(8)\nThe multi-head self-attention (MSA) (9) allows the model\nto jointly attend to information from different representation\nsubspaces at different positions. With a single attention head,\naveraging inhibits this, which enhances the expressiveness\nof each attention layer without changing the number of\nparameters.\nMSA (Q, K, V) =Concat(head1, ..., headi)Wo (9)\nheadi = attention\n\u0010\nQWQ\ni , KWK\ni , V WV\ni\n\u0011\n(10)\nWhere the projections are parameter matrices WQ\ni ⊂\nRdmodel×dk , WK\ni ⊂ Rdmodel×dk , and WV\ni ⊂ Rdmodel×dk .\nTo enhance gradient backpropagation, we add residual con-\nnections between transformer layers and across the trans-\nformer architecture. Last but not least, the transformer uses\na feed-forward network (FFW), which is applied to each\nposition separately:\nVOLUME 4, 2016 5\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2022.3224752\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nFIGURE 4. Transformer block\ng′′′ = F eedF orward(Norm(g′′ + g′)) +g′′ + g′ (11)\nA fully connected feed-forward network is present in each\nlayer of the encoder and decoder, and it is applied to each\ntransformer network layer identically and separately. This is\ncomposed of two linear transformations with an activation\nfunction called ReLU in the middle.\nF eedF orward(α) =max(0, W1x + b1)W2 + b2 (12)\nThe network structure of the linear transformation is the\nsame on different modules when faced with different under-\nwater ambient noise, but the model can be designed with\ndifferent parameters at different layers.\nIII. EVALUATION\nThe experimental results will be presented and discussed in\nthis section on the ShipsEar dataset [27] and the Deepship\ndataset [28]. Some ablation experiments and comparison\ntests show some of our explorations for underwater acoustic\nnoise reduction.\nA. DATASET\nThe ShipsEar dataset was collected with recordings made by\nhydrophones deployed from docks to capture different vessel\nspeed noises and cavitation noises corresponding to dock-\ning or undocking maneuvers. The recordings are of actual\nvessel sounds captured in a natural environment. Therefore,\nanthropogenic and natural background noise and vocalization\nare present in marine mammals. The ShipsEar comprises 90\nrecordings in wav format with five significant classes. Where\neach primary class contains one or more subclasses (e.g.,\nClass A is composed of fishing, trawlers, mussel, tugboats,\nand dredgers), the duration of each audio segment varies from\n15 seconds to 10 minutes. Each class is divided, as shown in\nTable 1.\nThe Deepship dataset consists of 47 h and 4 min of real-\nworld underwater recordings of 265 different ships belonging\nto four classes, as shown in Table 2. The dataset includes\nrecordings from different sea states and yearly noise levels.\nThe dataset is beneficial for evaluating the performance of\nexisting algorithms and researching deep learning methods.\nTo better verify the performance of the model. All signals\nwere segmented according to a fixed time of 5 seconds. We\n6 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2022.3224752\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nFIGURE 5. The architecture of the multi-head attention\nTABLE 1. ShipsEar Dataset\nShip Type Targets(Seconds)\nClass A Dredger (262s), Fishboat(514s), Musselboat(730s), Trawler(163s), Tugboat(206s)\nClass B Motorboat (1014s), Pilotship(138s), Sailboat(408s)\nClass C Passengers (4270s)\nClass D Oceanliner (942s), Roro(1483)\nClass E Natural Noise (1160s)\nTABLE 2. DeepShip Dataset\nShip Type Targets(No.of Ships) Total Time) Total Recordings\nCargo Ship 69 10 h 40 min 110\nTug 17 11 h17 min 70\nPassenger ship 46 12 h22 min 193\nTanker 133 12 h45 min 240\nset up three tasks to verify the denoising effect of the model:\nTask 1: Samples without noise classes are randomly se-\nlected from the ShipsEar, and the noise classes in ShipsEar\nare superimposed with these extracted samples. The signal-\nto-noise ratio of the mixed signals is adjusted by the signal\nfusion method to 0 dB. The dataset is then divided into a test\nset, validation set, and training set according to the ratio of\n6:2:2.\nTask 2: The first 20% of each audio file in ShipsEar and\nDeepShip is extracted and used as the training set, and the\nremaining 80% of the segments of the audio files are divided\ninto two parts: the validation set and the test set. In Task 2,\nnoise is added the same way as in Task 1.\nTask 3: Debug the denoising model individually by train-\ning all the data in the ShipsEar. The dataset in DeepShip is\nused as a test set and input to the trained denoising model\naccording to the predefined classes to achieve signal noise\nreduction. Use the evaluation metrics to compare the change\nin the signal-to-noise ratio of the signal after noise reduction.\nIn Task 3, noise is added the same way as in Task 1.\nThe difficulty from Task 1 to Task 3 gradually increases\nand at the same time it also becomes more suitable for\npractical applications.\nVOLUME 4, 2016 7\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2022.3224752\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nB. OPTIMISATION\nTable 3 shows the Dual-Path Transformer Network (DPTN)\nmodel used in this article compiled by CUDA11.3 [29]. The\nencoder is based on 256 convolutional filters with a kernel\nsize of 4 and a stride factor of 2. The decoder uses the same\nnumber of permutation convolution filters. The encoder was\nchosen to have the same kernel size and move a step to\nmaintain consistency before and after the audio duration. In\nablation experiments, where the input and output channels\nof the network are kept the exact size before and after the\nfeature tensor transfer, we test the number of repetitions\nnecessary for the transformer process in the masking network\nto fit the denoising network better. We applied 8 parallel at-\ntention heads and 1024-dimensional positional feed-forward\nnetworks within each transformer layer. The learning rate is\ninitialized to 1e-5 and decays for every 10 epochs by 0.98\nEarly stop training is introduced when there has been no\nimprovement for 5 epochs. The weight decay has defaulted\nto an L2 penalty. Adam [30] is used as the optimizer, and\nthe dynamic mixing (DM) [31] is introduced as the data\naugmentation. The gradual increase in the difficulty of the\ntwo tasks exercises the generalization ability and robustness\nwhile making the model conditions more realistic. The mask-\ning network processes chunks of size C = 250 with a 50%\noverlap. We employ N1 and N2 layers of transformers in\nboth intra-Transformer and inter-Transformer.\nC. TRAINING OBJECTIVE\nThe objective of training the end-to-end learning framework\nis to maximize the signal-to-noise ratio (SNR) [32]and the\nscale-invariant signal-to-noise ratio (SI-SNR) [33]. They are\ncommonly used as the evaluation metric for signal noise re-\nduction. SNR requires both the target signal and the enhanced\nsignal to know. It is an energy ratio expressed in dB between\nthe energy of the target signal contained in the enhanced\nsignal and the energy of the error. SI-SNR uses a single\ncoefficient to account for scaling discrepancies compared to\nSNR. The scale invariance is ensured by normalizing the\nsignal to zero-mean before the calculation. So the higher it\nis, the better. SNR and SI-SNR are defined as:\nSNR = 10log10\n∥Starget∥2\n\r\r\rbStarget − Starget\n\r\r\r\n2 (13)\nSI − SNR = 10log10\n∥θstarget∥2\n∥bstarget − θstarget∥2 (14)\nθ = ⟨bstarget, starget⟩\n∥starget∥2 (15)\nWhere bstarget ∈ R1×T and starget ∈ R1×T are the\nestimated and original clearly sources and ∥S∥2 = ⟨S, S⟩\ndenotes the signal power.\nD. RESULTS\n1) Waveform and spectrum display before and after noise\nreduction inTask 1\nThe waveform and spectrum display before and after noise\nreduction in Task 1 are shown in Figures 6 through 10. The\noriginal signals of various classes(Class A to D) are allowed\nto become distorted by ambient noise(Class E) using the Luo\nmethod [34]. It is clear that when the various underwater\nacoustic signals are interfered with by ambient noise, the\ncharacteristics of the underwater acoustic signals themselves\nare significantly altered. After using the proposed DPTN\nalgorithm, most of the noise is eliminated, and the underwater\nacoustic signal retains the detailed information of the original\nunderwater acoustic signal.\n2) Comparison of ablation experiments inTask 1\nIn Task 1, we investigate the effects of various hyperparam-\neters and network structures on the Dual-Path Transformer\nNetwork (DPTN) performance. Table 4 provides a summary\nof the findings, and the experiment is used for the test set\nnoise reduction.\nWe note that the number of intra- and inter-transformers\nsignificantly impacts the performance. When both transform-\ners are iterated 8 times, the best result is obtained. Instead,\nwe find a slight reduction in the model’s effectiveness after\n16 iterations on each transformer. When we examine the\ncause, we can see that when the model design is too complex,\nthe Dual-Path Transformer Network (DPTN) may overfit.\nAfter training, the model loses some generalization ability\nbut retains a robust fitting ability. In addition, we let the\ninter-transformer use a single-time transformer, which has\na performance of 15.59dB. We can observe a significant\nweakening of the model effect when using a single-layer\ntransformer for the intra-transformer, indicating that local\nprocessing, or the intra-transformer, has a more significant\nimpact on the denoising performance. The intra-Transformer\nis the initial transformer of the masking network. It has the\nability to modify the model’s hyperparameters to alter the\nperformance of the subsequent network structure in addition\nto learning the mask. Therefore, the effectiveness of the\nDPTN depends on selecting the proper network structure\nfor each layer. Finally, it is clear that this paper’s positional\ncoding was beneficial. We notice a slight performance differ-\nence between 8 and 16 heads when considering the number\nof heads. In order to make the model more lightweight, the\nproposed DPTN selects an attention technique with 8 heads.\nWe test the Dual-Path Transformer Network’s (DPTN)\nsignal enhancement speed with various network structures\nduring training. The training curve for the model in Task 1 is\ndepicted in Figures 11 and 12. We plot the performance ver-\nsus time for the first 150 training iterations on the validation\nset. We utilized the same computer and GPU for every model\nto ensure an accurate comparison. Additionally, a batch size\nof 1 was used for training all systems. When the hyperparam-\neters are selected to make the model more lightweight, the\nmodel converges faster during training. However, the model\n8 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2022.3224752\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nTABLE 3. Dual-Path Transformer Network Structure\nIntra-Transformer Inter-Transformer Masking network DPTN\nPositional Encoding Positional Encoding Intra-Transformer Encoder\nNormalization Normalization Inter-Transformer Chunking\nMulti-head attention Multi-head attention Masking network\nNormalization Normalization Overlap-add\nFeedforward Feedforward Decoder\nPReLu PReLu\nLinear Linear\nFIGURE 6. The waveform and spectrum of cargoship\nFIGURE 7. The waveform and spectrum of fishship\nTABLE 4. Ablation experiment of the DPTN(Nintra is the number of the intra-transformer,Ninter is the number of the inter-transformer, Heads is the number of\nthe multi-head,D is the dimension of feedforward, PE is the positional encoding.)\nModel SNR/SI-SNR Nintra Ninter Heads D PE\nDPTN 16.68/15.82 8 8 8 1024 Yes\nDPTN(No PE ) 14.61/13.28 8 8 8 1024 No\nDPTN(D=2048) 14.69/13.25 8 8 8 2048 Yes\nDPTN(Heads=4) 14.37/13.05 8 8 4 1024 Yes\nDPTN(Heads=16) 15.61/13.09 8 16 4 1024 Yes\nDPTN(Ninter=1) 15.59/13.89 8 1 8 1024 Yes\nDPTN(Nintra=1) 13.73/10.2 1 8 8 1024 Yes\nDPTN(N=4) 15.07/12.26 4 4 8 1024 Yes\nDPTN(N=16) 14.81/12.89 16 16 8 1024 Yes\nVOLUME 4, 2016 9\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2022.3224752\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nFIGURE 8. The Waveform and spectrum of motorboat\nFIGURE 9. The Waveform and spectrum of oceanliner\nFIGURE 10. The Waveform and spectrum of passenger\n10 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2022.3224752\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nTABLE 5. Results of different noise reduction methods.\nMethod Task 1(SNR/SI-SNR) Task 2 Task 3\nRNN 10.21/9.9 8.37/8.6 7.89/6.67\nFCN 9.68/10.93 8.25/8.8 7.30/7.62\nDPTN 16.68/15.82 13.71/12.53 10.37/11.69\nWavelet denoising 9.64/8.98\nInterval-dependent denoising 8.67/7.33\nFIGURE 11. The SNR variation cure of ablation experiment\nFIGURE 12. The SI-SNR variation cure of ablation experiment\ntesting results are not as good as DPTN. For example, the\ndenoising effect of DPTN is improved by 1.09 over DPTN\n(Ninter=1), but the model convergence time is prolonged by\nabout 3 hours. Therefore, different collocation methods can\nbe invoked according to different experimental needs.\n3) Comparison of the denoising performance of different\nmodels inTask 1, 2 and 3\nTable 5 compares the performance of the Dual-Path Trans-\nformer Network (DPTN) with other deep learning-based\napproaches to three tasks in noise reduction. The denoising\nmethods include Recurrent Neural Network (RNN) [25],\nFully Connected Neural Network-based model (FCN) [16],\nwavelet denoising method [12] and interval correlation de-\nnoising method [13]. Since the wavelet denoising and interval\ndenoising methods feed the noisy signal directly into the\nmodel and reduce the noise by transform decomposition\nmethods, so the whole process can be implemented without\ntraining the model. By evaluating three tasks on the test\ndataset, the signal-to-noise ratio improvement of our pro-\nposed DPTN model is 16.68db, 13.71db, and 10.37db in task\n1, task 2, and task 3, respectively.\n4) RMSE, Spectral entropy, and Phase diagram display\nbefore and after noise reduction by DPTN\nTo more thoroughly assess the results of the denoising under-\nwater acoustic signal using DPTN and the change in features\nbefore and after denoising. We calculated the change in the\nshort root mean square error (RMSE) before and after signal\ndenoising, which is a way of responding to the change in\nsignal energy. By comparing the changes of RMSE before\nand after noise reduction, we know that the clear underwater\nacoustic signal will not change drastically in a short period.\nHowever, when ambient noise is added, it will cause the\nRMSE of the signal to change. As shown in Figure 13 and\nFigure 14, we can find that the value of RMSE of the noisy\nsignal is around 0.1 in the first 2 seconds. The value of RMSE\ncan increase to about 0.15 when the change in RMSE from\n4S to 5S is significant. On the other hand, the RMSE of\nthe denoised signal is approximately 0.075 in the first two\nseconds and can continue to be approximately 0.075 when\nthe change in RMSE is minimal in the period between 4 and 5\nseconds. The results show that the RMSE of the target signal\ncan be maintained in a relatively stable state after using the\nDPTN method for noise reduction.\nFurther, we use spectral entropy to investigate the changes\nin underwater acoustic signals before and after denoising.\nSpectral entropy reflects the relationship between the power\nVOLUME 4, 2016 11\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2022.3224752\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nFIGURE 13. The Noisy signal Short RMSE\nFIGURE 14. The Denoised Signal Short RMSE\nspectrum and entropy rate. Entropy is a measure of the degree\nof uncertainty of various random tests. The natural ambient\nnoise in the underwater acoustic signal experiments has a\nhigh degree of randomness and confusion, which causes the\nspectral entropy to fluctuate widely. As shown in Figure 15,\nthe noisy signal’s spectral entropy fluctuates between 0.3 and\n0.9, and when the DPTN denoising method is applied, it\nfluctuates between 0.6 and 0.8.\nFinally, we compared the phase diagram’s transformation\nbefore and after denoising. The phase diagram is an essential\nfeature in identifying the signal of the underwater acoustic\nsignal. In the identification task, the signal’s phase change\ncan be used to determine the type of underwater acoustic\nsignal. As shown in Figure 16 and Figure 17, the two\noriginal signals fall under the same class (Class A) in the\nShipsEar data. However, different phase change is produced\nwhen natural ambient noise is added. Phase change makes\nit difficult for the signal classification system to differentiate\nbetween the classes of two signals. The phase change of the\ntwo denoised signals is similar after using the DPTN model\nFIGURE 15. Spectral Entropy\nFIGURE 16. Phase diagram\nto eliminate background noise, allowing us to distinguish\nbetween the two denoised signals that belonged to the same\nclass.\nIV. CONCLUSIONS\nThis paper proposes an end-to-end method of masking pat-\ntern denoising. First, the method reconstructs the noisy signal\nby coding and learns the feature mapping by deep learning.\nThen, in the high-dimensional feature space of deep neural\nnetworks, the transformer between features allows the model\nto acquire more knowledge. Finally, the denoised signal is\nrecovered by decoding. To validate the effectiveness of our\nmethod, we verify the model’s performance on the ShipsEar\nand DeepShip datasets. The experimental results show that\nour proposed model is more competitive than other deep\nlearning techniques. The signal-to-noise ratio improvement\n12 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2022.3224752\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nFIGURE 17. Phase diagram\nof our suggested DPTN model is 16.68 dB, 13.71 dB, and\n10.37 dB in Task 1, Task 2, and Task 3, respectively. In\nfuture work, we apply migration learning methods and GAN\nto underwater acoustic signal denoising.\nREFERENCES\n[1] Railey K , Dibiaso D , Schmidt H . An acoustic remote sensing method\nfor high-precision propeller rotation and speed estimation of unmanned\nunderwater vehicles[J]. The Journal of the Acoustical Society of Amer-\nica, 2020, 148(6):3942-3950.\n[2] Jiang F, Zhang Z. An improved underwater TDOA/AOA joint localisation\nalgorithm[J]. IET Communications, 2021, 15(6): 802-814.\n[3] Vieira V , Coelho R , FMD Assis. Hilbert–Huang–Hurst-based non-linear\nacoustic feature vector for emotion classification with stochastic models\nand learning systems[J]. IET Signal Processing, 2020, 14(8):522-532.\n[4] Li G, Yang Z, Yang H. Noise reduction method of underwater acous-\ntic signals based on uniform phase empirical mode decomposition,\namplitude-aware permutation entropy, and Pearson correlation coeffi-\ncient[J]. Entropy, 2018, 20(12): 918.\n[5] Moreaud U, Courmontagne P, Chaillan F, et al. Performance assess-\nment of noise reduction methods applied to underwater acoustic sig-\nnals[C]//OCEANS 2016 MTS/IEEE Monterey. IEEE, 2016: 1-15.\n[6] Ou H, Allen J S, Syrmos V L. Frame-based time-scale filters for under-\nwater acoustic noise reduction[J]. IEEE Journal of oceanic engineering,\n2011, 36(2): 285-297.\n[7] Moreaud U, Courmontagne P, Chaillan F, et al. A new way for under-\nwater acoustic signal analysis: The morphological filtering[C]//OCEANS\n2015-Genova. IEEE, 2015: 1-9.\n[8] Tzeng Y , Too G . On the alternative objective functions for mini-\nmum variance distortionless response technique in order to restore the\noriginal source[J]. Journal of the Acoustical Society of America, 2016,\n139(4):2084-2084.\n[9] Chen D, Chu X, Ma F, et al. A variational approach for adaptive\nunderwater sonar image denoising[C]//2017 4th International Conference\non Transportation Information and Safety (ICTIS). IEEE, 2017: 1177-\n1181.\n[10] Taroudakis M, Smaragdakis C, Ross Chapman N. Denoising underwater\nacoustic signals for applications in acoustical oceanography[J]. Journal\nof Computational Acoustics, 2017, 25(02): 1750015.\n[11] Li Y X . A novel noise reduction technique for underwater acoustic\nsignals based on complete ensemble empirical mode decomposition with\nadaptive noise, minimum mean square variance criterion and least mean\nsquare adaptive filter[J]. Defence Technology, 2020, 16(3):12.\n[12] Li Y , Li Y , Chen X , et al. A New Underwater Acoustic Signal Denois-\ning Technique Based on CEEMDAN, Mutual Information, Permutation\nEntropy, and Wavelet Threshold Denoising[J]. Entropy, 2018, 20(8):563\n[13] Yan H, Xu T, Wang P, et al. MEMS hydrophone signal denoising and\nbaseline drift removal algorithm based on parameter-optimized varia-\ntional mode decomposition and correlation coefficient[J]. Sensors, 2019,\n19(21): 4622.\n[14] Qi Q, Chen H, Yan Z, et al. Holographic reconstruction research on\nthe radiated acoustic field of the underwater vehicle[C]//OCEANS 2019-\nMarseille. IEEE, 2019: 1-5.\n[15] Lee K C. Underwater acoustic localisation by GMM fingerprinting\nwith noise reduction[J]. International Journal of Sensor Networks, 2019,\n31(1): 1-9.\n[16] Zhou X , Yang K . A denoising representation framework for underwater\nacoustic signal recognition[J]. The Journal of the Acoustical Society of\nAmerica, 2020, 147(4):EL377-EL383.\n[17] Wang X, Zhao Y , Teng X, et al. A stacked convolutional sparse denoising\nautoencoder model for underwater heterogeneous information data[J].\nApplied Acoustics, 2020, 167: 107391.\n[18] Othman A , Iqbal N , Hanafy S M , et al. Automated Event Detection\nand Denoising Method for Passive Seismic Data Using Residual Deep\nConvolutional Neural Networks[J]. IEEE Transactions on Geoscience\nand Remote Sensing, 2021, PP(99):1-11.\n[19] Testolin A, Diamant R. Underwater acoustic detection and localization\nwith a convolutional denoising autoencoder[C]//2019 IEEE 8th Interna-\ntional Workshop on Computational Advances in Multi-Sensor Adaptive\nProcessing (CAMSAP). IEEE, 2019: 281-285.\n[20] Qiu Y , Yuan F, Ji S, et al. Stochastic resonance with reinforcement learn-\ning for underwater acoustic communication signal[J]. Applied Acoustics,\n2021, 173: 107688.173:107688.\n[21] LI Y , W ANG B, SHAO G, et al. A Method of Noise Reduction for Un-\nderwater Acoustic Communication Signal Based on RCGAN[J]. ACTA\nELECTONICA SINICA, 2022, 50(1): 54.\n[22] Xing C, Wu Y , Xie L, et al. A sparse dictionary learning-based denoising\nmethod for underwater acoustic sensors[J]. Applied Acoustics, 2021,\n180: 108140.\n[23] Zhang W, Li X, Zhou A, et al. Underwater acoustic source separation\nwith deep Bi-LSTM networks[C]//2021 4th International Conference\non Information Communication and Signal Processing (ICICSP). IEEE,\n2021: 254-258.\n[24] Liu L, Cai L, Ma L, et al. Channel state information prediction for\nadaptive underwater acoustic downlink OFDMA system: deep neural net-\nworks based approach[J]. IEEE Transactions on Vehicular Technology,\n2021, 70(9): 9063-9076.\n[25] Zhang,Fumin and Zhang,Ziqiao and Tong,Feng et al. Modeling and\nlearning underwater acoustic channel parameters through deep recursive\nneural networks[J]. The Journal of the Acoustical Society of America,\n2022, 151(4):A233-A234.\n[26] Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need[J].\nAdvances in neural information processing systems, 2017, 30.\n[27] D Santos-Domínguez, Torres-Guijarro S , A Cardenal-López, et al.\nShipsEar: An underwater vessel noise database[J]. Applied Acoustics,\n2016, 113:64-69.\n[28] Irfan,Muhammad and Jiangbin,Zheng and Ali,Shahid and\nIqbal,Muhammad and Masood,Zafar and Hamid,Umar, et al. DeepShip:\nAn underwater acoustic benchmark dataset and a separable convolution\nbased autoencoder for classification[J]. Expert systems with applications,\n2021, 183:115270.\n[29] Qi J , Li K C , Jiang H , et al. GPU-accelerated DEM implementation\nwith CUDA[J]. International Journal of Computational Science and En-\ngineering, 2015, 11(3):330-337.\n[30] Kingma D P, Ba J. Adam: A method for stochastic optimization[J]. arXiv\npreprint arXiv:1412.6980, 2014.\n[31] Zeghidour N, Grangier D. Wavesplit: End-to-end speech separation by\nspeaker clustering[J]. IEEE/ACM Transactions on Audio, Speech, and\nLanguage Processing, 2021, 29: 2840-2849.\n[32] Bogale T E , Vandendorpe L . Max-Min SNR Signal Energy Based\nSpectrum Sensing Algorithms for Cognitive Radio Networks with Noise\nVariance Uncertainty[J]. IEEE Transactions on Wireless Communica-\ntions, 2014, 13(1):280-290.\n[33] Le Roux J, Wisdom S, Erdogan H, et al. SDR–half-baked or well\ndone?[C]//ICASSP 2019-2019 IEEE International Conference on Acous-\ntics, Speech and Signal Processing (ICASSP). IEEE, 2019: 626-630.\n[34] Hershey J R, Chen Z, Le Roux J, et al. Deep clustering: Discriminative\nembeddings for segmentation and separation[C]//2016 IEEE interna-\nVOLUME 4, 2016 13\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2022.3224752\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\ntional conference on acoustics, speech and signal processing (ICASSP).\nIEEE, 2016: 31-35.\nY ONG QIANG SONG\nHe received the bachelor’s and master’s degrees\nin Shandong Normal University,JINAN, China, in\n2017 and 2020, respectively, and he is currently\npursuing the doctor’s degree in National Inno-\nvation Institute of Defense Technology, Beijing,\nChina. He research interests include underwater\nacoustic signal noise reduction and chaotic signal\nprocessing.\nPLACE\nPHOTO\nHERE\nFENG LIU Assistant Researcher\nNational Innovation Institute of Defense Tech-\nnology, Chinese Academy of Military Science,\nChina. He received the bachelor’s degrees in\nHuazhong University of Science and Technology\nHe received the master’s degrees in Naval Aviation\nEngineering University. He received the doctor’s\ndegrees in NavalAviation Engineering University.\nHe research interests include underwater acoustic\nsignal noise reduction and chaotic signal processing.\nPLACE\nPHOTO\nHERE\nTONGSHENG SHEN Researcher\nNational Innovation Institute of Defense Tech-\nnology, Chinese Academy of Military Science,\nChina He research interests include underwater\nacoustic signal noise reduction and chaotic signal\nprocessing.\n14 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2022.3224752\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.60429447889328
    },
    {
      "name": "Underwater",
      "score": 0.5724391937255859
    },
    {
      "name": "Noise reduction",
      "score": 0.46423378586769104
    },
    {
      "name": "Noise measurement",
      "score": 0.42116862535476685
    },
    {
      "name": "Algorithm",
      "score": 0.41758063435554504
    },
    {
      "name": "Acoustics",
      "score": 0.36380869150161743
    },
    {
      "name": "Speech recognition",
      "score": 0.3433346450328827
    },
    {
      "name": "Artificial intelligence",
      "score": 0.29609382152557373
    },
    {
      "name": "Physics",
      "score": 0.12640133500099182
    },
    {
      "name": "Geology",
      "score": 0.0
    },
    {
      "name": "Oceanography",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I170215575",
      "name": "National University of Defense Technology",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210160531",
      "name": "Chinese People's Liberation Army",
      "country": "CN"
    }
  ],
  "cited_by": 11
}