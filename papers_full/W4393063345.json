{
    "title": "AE-GPT: Using Large Language Models to extract adverse events from surveillance reports-A use case with influenza vaccine adverse events",
    "url": "https://openalex.org/W4393063345",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2077188490",
            "name": "Yiming Li",
            "affiliations": [
                "The University of Texas Health Science Center at Houston"
            ]
        },
        {
            "id": "https://openalex.org/A2103418678",
            "name": "Jianfu Li",
            "affiliations": [
                "Mayo Clinic in Florida"
            ]
        },
        {
            "id": "https://openalex.org/A2111286734",
            "name": "Jianping He",
            "affiliations": [
                "The University of Texas Health Science Center at Houston"
            ]
        },
        {
            "id": "https://openalex.org/A2137772693",
            "name": "Cui Tao",
            "affiliations": [
                "Mayo Clinic in Florida"
            ]
        },
        {
            "id": "https://openalex.org/A2077188490",
            "name": "Yiming Li",
            "affiliations": [
                "The University of Texas Health Science Center at Houston",
                "The University of Texas Health Science Center"
            ]
        },
        {
            "id": "https://openalex.org/A2103418678",
            "name": "Jianfu Li",
            "affiliations": [
                "Mayo Clinic in Florida"
            ]
        },
        {
            "id": "https://openalex.org/A2111286734",
            "name": "Jianping He",
            "affiliations": [
                "The University of Texas Health Science Center at Houston",
                "The University of Texas Health Science Center"
            ]
        },
        {
            "id": "https://openalex.org/A2137772693",
            "name": "Cui Tao",
            "affiliations": [
                "Mayo Clinic in Florida"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4212974972",
        "https://openalex.org/W4389481977",
        "https://openalex.org/W4293740214",
        "https://openalex.org/W1918065319",
        "https://openalex.org/W1976988340",
        "https://openalex.org/W3002783676",
        "https://openalex.org/W2546821105",
        "https://openalex.org/W3178079110",
        "https://openalex.org/W1983077458",
        "https://openalex.org/W4318685230",
        "https://openalex.org/W979396035",
        "https://openalex.org/W3135084718",
        "https://openalex.org/W4225479391",
        "https://openalex.org/W6856529530",
        "https://openalex.org/W4366241052",
        "https://openalex.org/W3058517477",
        "https://openalex.org/W4322492760",
        "https://openalex.org/W4362553921",
        "https://openalex.org/W4372348374",
        "https://openalex.org/W4385460459",
        "https://openalex.org/W4212893806",
        "https://openalex.org/W3169536731",
        "https://openalex.org/W2320856077",
        "https://openalex.org/W1845364899",
        "https://openalex.org/W1998268789",
        "https://openalex.org/W2008361529",
        "https://openalex.org/W2781571133",
        "https://openalex.org/W1975597036",
        "https://openalex.org/W2136970311",
        "https://openalex.org/W6855514161",
        "https://openalex.org/W6851355582",
        "https://openalex.org/W3130890978",
        "https://openalex.org/W4327946446",
        "https://openalex.org/W3177920269",
        "https://openalex.org/W6778883912",
        "https://openalex.org/W6851013863",
        "https://openalex.org/W4243640523",
        "https://openalex.org/W2986530058",
        "https://openalex.org/W4389543814",
        "https://openalex.org/W4392468106",
        "https://openalex.org/W3128981050",
        "https://openalex.org/W2605987436",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W4360979863",
        "https://openalex.org/W4385951095",
        "https://openalex.org/W4386655575",
        "https://openalex.org/W4287327402",
        "https://openalex.org/W4385495736",
        "https://openalex.org/W4385292160",
        "https://openalex.org/W3172480024",
        "https://openalex.org/W4324027515",
        "https://openalex.org/W4385474113",
        "https://openalex.org/W4382132333",
        "https://openalex.org/W4384921136",
        "https://openalex.org/W4361020574",
        "https://openalex.org/W2116310281",
        "https://openalex.org/W4384918448"
    ],
    "abstract": "Though Vaccines are instrumental in global health, mitigating infectious diseases and pandemic outbreaks, they can occasionally lead to adverse events (AEs). Recently, Large Language Models (LLMs) have shown promise in effectively identifying and cataloging AEs within clinical reports. Utilizing data from the Vaccine Adverse Event Reporting System (VAERS) from 1990 to 2016, this study particularly focuses on AEs to evaluate LLMs’ capability for AE extraction. A variety of prevalent LLMs, including GPT-2, GPT-3 variants, GPT-4, and Llama2, were evaluated using Influenza vaccine as a use case. The fine-tuned GPT 3.5 model (AE-GPT) stood out with a 0.704 averaged micro F1 score for strict match and 0.816 for relaxed match. The encouraging performance of the AE-GPT underscores LLMs’ potential in processing medical data, indicating a significant stride towards advanced AE detection, thus presumably generalizable to other AE extraction tasks.",
    "full_text": "RESEA RCH ARTICL E\nAE-GPT: Using Large Language Models to\nextract adverse events from surveillance\nreports-A use case with influenza vaccine\nadverse events\nYiming Li\nID\n1\n, Jianfu Li\n2\n, Jianping He\n1\n, Cui Tao\nID\n2\n*\n1 McWilliam s School of Biomed ical Informatics , The University of Texas Health Science Center at Houston ,\nHouston , TX, United States of America, 2 Department of Artificial Intelligenc e and Informatics, Mayo Clinic,\nJacksonvi lle, FL, United States of America\n* Tao.C ui@mayo.edu\nAbstract\nThough Vaccines are instrumental in global health, mitigating infectious diseases and pan-\ndemic outbreaks, they can occasionally lead to adverse events (AEs). Recently, Large Lan-\nguage Models (LLMs) have shown promise in effectively identifying and cataloging AEs\nwithin clinical reports. Utilizing data from the Vaccine Adverse Event Reporting System\n(VAERS) from 1990 to 2016, this study particularly focuses on AEs to evaluate LLMs’ capa-\nbility for AE extraction. A variety of prevalent LLMs, including GPT-2, GPT-3 variants, GPT-\n4, and Llama2, were evaluated using Influenza vaccine as a use case. The fine-tuned GPT\n3.5 model (AE-GPT) stood out with a 0.704 averaged micro F1 score for strict match and\n0.816 for relaxed match. The encouraging performance of the AE-GPT underscores LLMs’\npotential in processing medical data, indicating a significant stride towards advanced AE\ndetection, thus presumably generalizable to other AE extraction tasks.\nIntroduction\nVaccines are a vital component of public health and have been instrumental in preventing\ninfectious illnesses [1, 2]. Nowadays, we possess vaccines that cope with over 20 life-threaten-\ning diseases, contributing to enhanced health and longevity for people across all age groups\n[3]. Each year, vaccinations save between 3.5 to 5 million individuals from fatal diseases such\nas diphtheria, tetanus, pertussis, influenza, and measles [3]. However, vaccine-related adverse\nevents (AEs), although rare, can occur after immunization. By September 2023, Vaccine\nAdverse Event Reporting System (VAERS) had received more than 1,791,000 vaccine AE\nreports, of which 9.5% were classified as serious, which include events that result in death, hos-\npitalization, or significant disability [4–6]. Consequently, vaccine AEs can cause a range of side\neffects in individuals, from mild, temporary symptoms to severe complications [7–10]. They\nmay also give rise to vaccine hesitancy among healthcare providers and recipients [11].\nUnderstanding AEs following vaccinations is vital in surveilling the effective implementa-\ntion of immunization programs [12]. Such vigilance ensures the continuous safety of\nPLOS ONE\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03009 19 March 21, 2024 1 / 16\na1111111111\na1111111111\na1111111111\na1111111111\na1111111111\nOPEN ACCESS\nCitation: Li Y, Li J, He J, Tao C (2024) AE-GPT:\nUsing Large Language Models to extract adverse\nevents from surveillance reports-A use case with\ninfluenza vaccine adverse events. PLoS ONE 19(3):\ne0300919. https://d oi.org/10.1371/j ournal.\npone.030091 9\nEditor: Vincenzo Bonnici, Univers ity of Parma,\nITALY\nReceived: October 12, 2023\nAccepted: March 6, 2024\nPublished: March 21, 2024\nPeer Review History: PLOS recognize s the\nbenefits of transpar ency in the peer review\nprocess; therefore, we enable the publication of\nall of the content of peer review and author\nresponse s alongside final, published articles. The\neditorial history of this article is available here:\nhttps://doi.o rg/10.1371/jo urnal.pone.0 300919\nCopyright: © 2024 Li et al. This is an open access\narticle distributed under the terms of the Creative\nCommons Attributi on License, which permits\nunrestricted use, distribution , and reproduction in\nany medium, provide d the original author and\nsource are credited .\nData Availabilit y Statement: All data underlying\nthe findings described in this manuscript to be\nfreely available at https:// www.kaggle.c om/\ndatasets/yim ingli99/ae-g pt-data.\nvaccination campaigns, allowing for prompt responses when AE occurs. This not only con-\nduces to recognizing early warning signs but also fosters hypotheses regarding potential new\nvaccine AEs or shifts in the frequency of known ones, ultimately contributing to the refine-\nment and development of vaccines [13].\nTherefore, the extraction of AEs and AE-related information would play a pivotal role in\nadvancing our understanding of conditions such as syndromes and other system disorders\nthat can emerge after vaccination. VAERS functions as a spontaneous reporting system for\nadverse events post-vaccination, serving as the national early warning mechanism to flag\npotential safety issues with U.S. licensed vaccines [14–16]. VAERS collects structured informa-\ntion such as age, medical background, and vaccine type. It also includes a short narrative from\nthe reporters to describe symptoms, medical history, diagnoses, treatments, and their temporal\ninformation [14]. Although it does not establish causal relationships between AEs and vac-\ncines, VAERS detects possible safety concerns warranting deeper investigation through robust\nsystems and study designs [14]. Du et al. employed advanced deep learning algorithms to\ndetect nervous system disorder-related events in the cases of Guillain-Barre syndrome (GBS)\nlinked to influenza vaccines from the VAERS reports [17]. Through the evaluation of different\nmachine learning and deep learning methods, including domain-specific BERT models such\nas BioBERT and VAERS BERT, their research demonstrated the superior performance of deep\nlearning techniques over traditional machine learning methods (ie, conditional random fields\nwith extensive features) [17].\nNowadays, with the popularity of artificial intelligence (AI) surging, a remarkable break-\nthrough has emerged: the development of large language models (LLMs) [18–20]. These cut-\nting-edge AI constructs have redefined the way computers understand and generate human\nlanguage, leading to unprecedented advancements in various aspects [21]. These models, pow-\nered by advanced machine learning techniques, have the capacity to comprehend context,\nsemantics, and nuances, allowing them to generate coherent and contextually relevant text\n[19]. For example, Generative Pre-trained Transformer (GPT), developed by OpenAI, repre-\nsents a pioneering milestone in the realm of AI [22]. Built on a massive dataset, GPT is a state-\nof-the-art language model that excels in generating coherent and contextually relevant text\n[23]. Since its inception, GPT has exhibited exceptional capabilities, ranging from crafting\nimaginative narratives and aiding content creation to facilitating language translation and\nengaging in natural conversations with virtual assistants [24, 25]. Its impact across various\ndomains has highlighted its potential to revolutionize human-computer interaction, making\nsignificant strides towards machines truly understanding and interacting with human lan-\nguage [26]. Another model Llama 2, available free of charge, however, takes a novel approach\nby incorporating multimodal learning, seamlessly fusing text and image data [27]. This unique\nfeature enables Llama 2 to not only comprehend and generate text with finesse but also to\nunderstand and contextualize visual information, setting it apart from traditional language\nmodels like GPT [27].\nLLMs represent a significant leap forward in natural language processing (NLP), enabling\napplications ranging from text generation and translation to sentiment analysis and Chatbot\nvirtual assistants [28]. By learning patterns from vast amounts of text data, these LLMs have\nthe potential to bridge the gap between human communication and machine understanding,\nopening up new avenues for communication, information extraction, and problem-solving\n[29]. Hu et al. examined ChatGPT’s potential for clinical named entity recognition (NER) in a\nzero-shot context, comparing its performance with GPT-3 and BioClinicalBERT on synthetic\nclinical notes [30]. ChatGPT outperformed GPT-3, although BioClinicalBERT still performed\nbetter. The study demonstrates ChatGPT’s promising utility for zero-shot clinical NER tasks\nwithout requiring annotation [30].\nPLOS ONE\nAE-GPT: Using large language models to extract adverse events from surveillance reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03009 19 March 21, 2024 2 / 16\nFunding: This article was partially supported by the\nNational Institute of Allergy And Infectious\nDiseases of the National Institutes of Health under\nAward Numbers R01AI130460 and U24AI171008.\nThe funders had no role in study design, data\ncollection and analysis , decision to publish, or\npreparation of the manuscript.\nCompeting interests : The authors have declared\nthat no competing interests exist.\nAbbreviati ons: AE, adverse event; AI, artificial\nintelligence ; CDC, Centers for Disease Control and\nPrevention; FDA, Food and Drug Administratio n;\nGBS, Guillain-B arre syndrome; GPT, Generative\nPre-trained Transfo rmer; ICU, intensive care unit;\nLLM, Large Language Model; NER, named entity\nrecognition; NLP, natural language processing;\nVAERS, Vaccine Adverse Event Reporting System.\nIn this study, we aim to develop AE-GPT, an automatic adverse event extraction tool based\non LLMs, with a specific focus on adverse events following the Influenza vaccine. The influ-\nenza vaccine, being one of the most frequently reported vaccines in the VAERS, serves as a\nprominent use case for our investigation. Our choice is not only motivated by the vaccine’s\nsubstantial reporting frequency but also by its significance in public health. As we delve into\nextracting AE-related entities, the influenza vaccine provides a robust and relevant context for\nevaluating the performance of our proposed AE-GPT framework. While our study centers on\nthe influenza vaccine as a use case, the framework’s applicability extends to other vaccine\ntypes, enriching the generalizability of our findings across the broader domain of vaccine\nsafety surveillance. Unlike several studies that have explored the application of LLMs in execut-\ning NER tasks, our focus extends beyond zero-shot learning (inference from the pre-trained\nmodel), providing comprehensive performance comparisons between pretrained LLMs, fine-\ntuned LLMs, and traditional language models. This research aims to address this gap by pro-\nviding a thorough examination of the LLM’s capabilities, specifically focusing on its perfor-\nmance within the NER task and also proposing the advanced fine-tuned models AE-GPT,\nwhich specializes in AE related entity extraction. Our investigation not only involves utilizing\nthe pretrained model for inference but also enhancing the LLM’s NER performance through\nfine-tuning with the customized dataset, thus providing a deeper understanding of its potential\nand effectiveness.\nMaterials and methods\nFig 1 presents an overview of the study framework. Our investigation commenced with zero-\nshot entity recognition, involving the direct input of user prompts into pretrained LLMs (GPT\n& Llama 2). To achieve a comprehensive assessment of LLMs’ effectiveness in clinical entity\nrecognition, our analysis covered a range of LLMs, namely GPT-2, GPT-3, GPT-3.5, GPT-4,\nand Llama 2. Furthermore, to enhance their performance, we performed fine-tuning on these\nLLMs using annotated data, followed by utilizing user prompts to facilitate result inference.\nFig 1. Overview of the study framework.\nhttps://d oi.org/10.1371/j ournal.pon e.0300919.g0 01\nPLOS ONE\nAE-GPT: Using large language models to extract adverse events from surveillance reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03009 19 March 21, 2024 3 / 16\nData source and use case\nVAERS functions as an advanced alert mechanism jointly overseen by the Centers for Disease\nControl and Prevention (CDC) and the U.S. Food and Drug Administration (FDA), playing a\npivotal role in identifying potential safety concerns associated with FDA-approved vaccines\n[31, 32]. As of Aug 2013, VAERS has documented more than 1,781,000 vaccine-related AEs\n[32].\nThe influenza vaccine plays a significant role in preventing millions of illnesses and visits to\ndoctors due to flu-related symptoms each year [33]. For example, in the 2021–2022 flu season,\nprior to the emergence of the COVID-19 pandemic, flu vaccination was estimated to have pre-\nvented around 1.8 million flu-related illnesses, resulting in approximately 1,000,000 fewer\nmedical visits, 22,000 fewer hospitalizations, and nearly 1,000 fewer deaths attributed to influ-\nenza [34]. A study conducted in 2021 highlighted that among adults hospitalized with flu,\nthose who had received the flu vaccine had a 26% reduced risk of needing intensive care unit\n(ICU) admission and a 31% lower risk of flu-related mortality compared to individuals who\nhad not been vaccinated [35].\nHowever, influenza vaccines also have been associated with a range of potential adverse\neffects, such as pyrexia, hypoesthesia, and even rare conditions like GBS [36]. Among them,\nGBS ranks as the primary contributor to acute paralysis in developed nations, and continues\nto be the most frequently documented serious adverse event following trivalent influenza vac-\ncination in the VAERS database, with a report rate of 0.70 cases per 1 million vaccinations\n[37–39]. This rare autoimmune disorder, GBS, affects the peripheral nervous system, charac-\nterized by rapidly advancing, bilateral motor neuron paralysis that typically arises subsequent\nto an acute respiratory or gastrointestinal infection [37, 40–42].\nAs a use case, this study focuses on symptom descriptions (referred to as narrative safety\nreports) that include GBS and symptoms frequently linked with GBS. Particularly, our interest\nlies in these reports following the administration of diverse influenza virus vaccines, including\nFLU3, FLU4, H5N1, and H1N1. In order to enable a direct performance comparison with tra-\nditional language models, we employed the identical dataset that was utilized by Du et al. in\ntheir previous study [17]. This dataset comprises a total of 91 annotated reports. In the context\nof understanding the development of GBS and other nervous system disorders, we explored\nsix entity types that collectively capture significant clinical insights within VAERS reports:\ninvestigation, nervous_AE, other_AE, procedure, social_circumstance, and temporal_expression.\nInvestigation, which refers to lab tests and examinations, including entities like “neurological\nexam” and “lumbar puncture” [17]. nervous_AE (e.g., “tremors” “Guillain-Barre ´ syndrome”)\ninvolves symptoms and diseases related to nervous system disorders, whereas other_AE (e.g.,\n“complete bowel incontinence” “diarrhea”) is associated with other symptoms and diseases\n[17]. procedure addresses clinical interventions to the patient, including vaccination, treatment\nand therapy, intensive care, featuring instances such as “flu shot” and “hospitalized” [17].\nsocial_circumstance records events associated with the social environment of a patient, for\nexample, “smoking” and “alcohol abuse” [17]. temporal_expression is concerned with temporal\nexpressions with prepositions like “for 3 days” and “on Friday morning” [17].\nModels\nTo fully investigate the performance of LLMs on the NER task, GPT models and Llama 2 will\nbe leveraged.\nGPT. GPT represents a groundbreaking advancement in the realm of NLP and artificial\nintelligence [43]. Developed by OpenAI, GPT stands as a remarkable example of the transfor-\nmative capabilities of large-scale neural language models [44]. At its core, GPT is founded\nPLOS ONE\nAE-GPT: Using large language models to extract adverse events from surveillance reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03009 19 March 21, 2024 4 / 16\nupon the innovative Transformer architecture, a model that has revolutionized the field by\neffectively capturing long-term dependencies within sequences, making it exceptionally well-\nsuited for tasks involving language understanding and generation [45, 46]. The GPT family\nhas multiple versions: The GPT-2 model, with 1.5 billion parameters, is capable of generating\nextensive sequences of text while adapting to the style and content of arbitrary inputs [47].\nMoreover, GPT-2 can also perform various NLP tasks, such as classification [47]. On the other\nhand, GPT-3 with 175 billion parameters, takes the capabilities even further [35]. It’s an auto-\nregressive language model trained with 96 layers on a combination of 560GB+ web corpora,\ninternet-based book corpora, and Wikipedia datasets, each weighted differently in the training\nmix [48, 49]. GPT-3 model is available in four versions: Davinci, Curie, Babbage and Ada\nwhich differ in the amount of trainable parameters– 175, 13, 6.7 and 2.7 billion respectively\n[48, 50]. GPT-4 has grown in size by a factor of 1000, now reaching a magnitude of 170 trillion\nparameters, a substantial increase when compared to GPT-3.5’s 175 billion parameters [51].\nOne of the most notable improvements in GPT-4 is the expanded context length. In GPT-3.5,\nthe context length is 2048 [51]. However, in GPT-4, it has been elevated to 8192 or 32768,\ndepending on the specific version, representing an augmentation of 4 to 16 times compared to\nGPT-3.5 [51]. In terms of its generated output, GPT-4 possesses the capacity to not just accom-\nmodate multimodal input, but also produce a maximum of 24000 words (equivalent to 48\npages) [51]. This represents an increase of 8 times compared to GPT-3.5, constrained by 3000\nwords (equivalent to 6 pages) [51].\nThe rationale behind GPT’s design stems from the understanding that pre-training, involv-\ning the unsupervised learning of language patterns from vast textual corpora, can provide a\nstrong foundation for subsequent fine-tuning on specific tasks [44]. This enables GPT to\nacquire a sophisticated understanding of grammar, syntax, semantics, and even world knowl-\nedge, essentially learning to generate coherent and contextually relevant text [52].\nGPT’s architecture comprises multiple layers of self-attention mechanisms, which allow the\nmodel to weigh the importance of different words in a sentence based on their contextual rela-\ntionships [53, 54]. This intricate layering, coupled with the model’s considerable parameters,\nempowers GPT to process and generate complex linguistic structures, making it a versatile\ntool for a wide range of NLP tasks, including text completion, translation, summarization, and\neven creative writing [55].\nLLama 2. Llama 2 emerges as a cutting-edge advancement in the domain of natural lan-\nguage processing, marking a significant evolution in the landscape of language models [27].\nDeveloped as an extension of its predecessor, Llama, this model represents an innovative step\nforward in harnessing the power of transformers for language understanding and generation\n[56]. The architecture of Llama 2 is firmly rooted in the Transformer framework, which has\nrevolutionized the field by enabling the modeling of complex dependencies in sequences.\nThe rationale behind Llama 2’s conception rests upon the recognition that while pre-train-\ning large language models on diverse text corpora is beneficial, customizing their multi-layer\nself-attention architecture for linguistic structures can further optimize their performance\n[56].\nExperiment setup\nDataset split. In this study, we partitioned the dataset into a training set and a test set\nusing an 8:2 ratio, where 72 VAERS reports were designated for the training set and the\nremaining 19 reports for the test set.\nPretrained model inference. We firstly inferred the results by using the available pre-\ntrained LLMs. GPT-2 model source has been made publicly available, we used\nPLOS ONE\nAE-GPT: Using large language models to extract adverse events from surveillance reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03009 19 March 21, 2024 5 / 16\nTFGPT2LMHeadModel as the pretrained GPT-2 model to test its ability in this NER task [57].\nLlama 2 is also an open-source LLM, which can be accessed through MetaAI [56].\nTo evaluate the performance of the pre-trained models, we conducted several experiments,\nselecting the temperature and max tokens settings (shown in Table 1) that yielded the best\nresults. Temperature, a hyperparameter, influences the randomness of the generated text.\nHigher values, such as 1.0 or above, increase diversity, while lower values, like 0.5 or below,\nproduce more focused outputs. Meanwhile, max tokens determine the maximum length of the\ngenerated text, serving to control and limit the length of the output. We employed the prompts\n(as depicted in Table 1) that adeptly articulate our objective, are comprehensible to the LLMs,\nand additionally aid in the efficient extraction of results.\nInference for the pretrained GPT models was executed on a server equipped with 8 Nvidia\nA100 GPUs, where each GPU provided a memory capacity of 80GB. Meanwhile, the pre-\ntrained Llama models were inferred on a server, which included 5 Nvidia V100 GPUs, each\noffering a memory capacity of 32GB.\nModel fine-tuning. Fine-tuning the GPT models is facilitated through OpenAI\nChatGPT’s API calls, with the exception that the GPT-2 model’s fine-tuning stems from\nGPT2sQA and the fine-tuning for GPT-4 has not been made accessible yet [58]. For Llama 2\nmodels, the fine-tuning process begins with HuggingFace. Subsequently, the model’s embed-\ndings are automatically fine-tuned and updated. Throughout the process, the temperature\nremains consistent. The format requirements for training set templates differ among models,\ndepending on whether they are instruction-based or not. Fig 2 presents an example of the\nquestion answering-based training set used by GPT-2, which initializes with the question\n“Please extract all the names of nervous_AE from the following note”. The question is followed\nby the answer with annotations where the entities (i.e., Guillain Barre Syndrome, quadriplegic,\nGBS) and the starting character offset (i.e., 0, 141, 212) should be indicated. The training set\nends with the context (Guillain Barre Syndrome. Onset on. . .). Fig 3 shows an example to illus-\ntrate the structured format of the training set tailored for GPT-3, where the prompt and anno-\ntations are necessitated. In the prompts, only the original report is required because of the\npredetermined NER template embedded in GPT-3, while the annotations include the entity\ntypes and the entities. For instance, as shown in Fig 3, “Guillain Barre Syndrome. Onset. . .” is\nthe original description from the VAERS reports. Within the annotations section, all the\nTable 1. Prompts and hyperparame ters of pretrained models.\nModel Prompt Temperature Max\ntokens\nGPT-2 Please extract all names of investigation, nervous AE, other AE, procedure, social circumstance, and timestamp from\nthis note, and put them in a list\n1.0 1,000\nGPT-\n3\nada Answer the question based on the context below, and if the question can’t be answered based on the context, say \"I\ndon’t know\"\n0 150\nbabbage Context: [note]\ncurie —\ndavinci Question : Please extract all names of [timestamp/nervous_AE/other_AE/procedure/investigation/social circumstance]\nfrom this note\nAnswer:\nGPT-3.5 Please extract all names of investigation, nervous AE, other AE, procedure, social circumstance, and timestamp from\nthis note, and put them in a list\n0.8 1,000\nGPT-4\nLlama 2-7b-chat \"Please extract all names of [timestamp/nervous AE/other AE/procedure/investigation/social circumstance] from this\nnote: [note]\n0.6 512\n2-13b-\nchat\nhttps://do i.org/10.1371/j ournal.pone .0300919.t001\nPLOS ONE\nAE-GPT: Using large language models to extract adverse events from surveillance reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03009 19 March 21, 2024 6 / 16\ninvolved entity types (nervous_AE, timestamp, investigation, other_AE, and procedure) are\nlisted, with ’Guillain Barre Syndrome’, ’quadriplegic’, and ’GBS’ being the entities classified\nunder nervous_AE. Fig 4 shows an instruction-based training example utilized for GPT-3.5,\nand Llama 2-chat, which utilizes prompt instructions to guide and refine the model’s\nresponses, ensuring more accurate and contextually relevant outputs. The process of human-\nmachine interaction is imitated. In this scenario, three roles are identified: the system, user,\nand assistant. The system outlines the task to be accomplished by GPT, stipulating—\"You are\nan assistant adept at named entity recognition.\" Unlike the structured format training set, in\naddition to the original VAERS reports, users are also required to clarify the task with a specific\nquestion—e.g., \"Please extract all the nervous_AE entities in the following note.\" The annota-\ntions section only include the anticipated responses that users expect GPT to provide.\nFor model fine-tuning, we selected the initial hyperparameters as outlined in Table 2. Typi-\ncally, these settings are based on defaults, except for GPT-3, where non-default values outper-\nformed the defaults. As for prompts, they differ slightly due to model-specific training set\nneeds.\nFine-tuning for the pretrained GPT models was executed on a server equipped with 8 Nvi-\ndia A100 GPUs, where each GPU provided a memory capacity of 80GB. Meanwhile, the\nFig 2. One example of a question answering -based trainin g set.\nhttps://d oi.org/10.1371/j ournal.pon e.0300919.g0 02\nFig 3. One example of the structured format training set.\nhttps://d oi.org/10.1371/j ournal.pon e.0300919.g0 03\nPLOS ONE\nAE-GPT: Using large language models to extract adverse events from surveillance reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03009 19 March 21, 2024 7 / 16\npretrained Llama models were fine-tuned on a server, which included 5 Nvidia V100 GPUs,\neach offering a memory capacity of 32GB.\nPost-processing. In the post-processing stage, we addressed instances of nested entities,\nas depicted in Fig 5 (“Muscle strength” vs “Muscle strength decreased”). To effectively handle\nthis, we adopted a strategy wherein entities possessing the longest spans were retained, while\nthe nested entities were excluded from consideration. In the examples illustrated in Fig 5, the\ninvestigation term \"Muscle strength\" was eliminated, resulting in nervous_AE \"Muscle strength\ndecreased\" for the final output. This procedure ensured a streamlined and accurate representa-\ntion of the entities within the given context.\nEvaluation. The performance of the LLMs was evaluated by metrics, including precision,\nrecall, and F1. These evaluations were conducted under two distinct matching criteria: exact\nmatching, which required identical entity boundaries, and relaxed matching, which took into\nconsideration overlapping entity boundaries.\nPrec isio n ¼\nTrue pos iti ve\nTrue pos iti ve þ Fal se pos iti ve\nReca ll ¼\nTru e pos iti ve\nTrue pos iti ve þ Fal se neg ativ e\nFig 4. One example of the instructio n-based training set.\nhttps://d oi.org/10.1371/j ournal.pon e.0300919.g0 04\nTable 2. Prompts and hyperparame ters of model fine-tunin g.\nModel Prompt Training set forma t Temperature Max\ntokens\nGPT-2 Please extract all the names of [timestamp/nervous_AE/other_AE/procedure/investigation/\nsocial circumstance] from the following note\nQuestion answering-\nbased\n1.0 1,000\nGPT-\n3\nada JSON format specified by OpenAI Structured 0.8 1,000\nbabbage\ncurie\ndavinci\nGPT-3.5 Please extract all the [timestamp/nervous_AE/other_AE/procedure/investigation/social\ncircumstance] in the following note: [note]\nInstruction -based 1.0 4,096\nLlama 2-7b-chat JSON format specified by Llama Instruction -based 1.0 4,096\n2-13b-\nchat\nhttps://do i.org/10.1371/j ournal.pone .0300919.t002\nPLOS ONE\nAE-GPT: Using large language models to extract adverse events from surveillance reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03009 19 March 21, 2024 8 / 16\nF \u0000 1 ¼\n2 � Prec isi on � Rec all\nPrec isio n þ Reca ll\nResults\nTables 3 and 4 presents the NER performance across various LLMs using strict F1 and relaxed\nF1 metrics respectively. In terms of evaluation metrics, strict F1 requires an exact match in\nboth content and position between the predicted and true segments, while relaxed F1 allows\nfor partial matches, providing a more lenient evaluation of model performance. Notably, the\nGPT-3.5 model emerges as the frontrunner in this NER task. Remarkably, GPT-3, 3.5, and 4\nmodels surpass LLama models significantly. Within the GPT model family, performance sig-\nnificantly improves with each successive version upgrade. GPT-3-davinci, in particular,\nachieved the highest performance among all GPT-3 models.\nInterestingly, the performance of the fine-tuned GPT-3 model closely rivals that of GPT-4\nthough the fine-tuned GPT-3 model outperforms both the pretrained GPT-3.5 and GPT-4\nmodels.\nTables 3 and 4 show the NER performance for various entity types, encompassing investiga-\ntion, nervous_AE, other_AE, procedure, social_circumstance, and temporal_expression respec-\ntively. Among these categories, temporal_expression exhibits the highest performance,\nfollowed by nervous_AE and procedure.\nHowever, it’s worth noting that LLMs encounter significant challenges in extracting\nsocial circumstance entities, with the fine-tuned GPT-3.5 model achieving the highest F1\nscore of 0.5 only in this category. Across all models evaluated, GPT-3.5 generally delivers\nthe best performance, except for the pretrained GPT-3.5, which excels in precision scores\nfor investigation extraction. Therefore, we proposed the fine-tuned GPT-3.5, and named it\nas “AE-GPT”.\nDiscussion\nOur research has yielded remarkable insights into the capabilities of LLMs in the context of\nNER. With a specific focus on the performance of these models, we have achieved substantial\nachievements throughout this study. Additionally, we are pleased to introduce the advanced\nfine-tuned models collectively known as AE-GPT, which have demonstrated exceptional\nprowess in the extraction of AE related entities. Our work showcases the success of leveraging\npretrained LLMs for inference and fine-tuning them with a customized dataset, underscoring\nthe effectiveness and potential of this approach.\nIn the realm of LLMs for AE NER tasks, the fine-tuned GPT-3.5-turbo model (AE-GPT)\nnotably stood out, demonstrating superior performance compared to its competing models.\nInterestingly, the process of fine-tuning seemed to have a significant effect on the capabilities\nof certain models. For instance, both the fine-tuned GPT-3 and GPT-3.5 showed enhanced\nperformance, even outstripping the more advanced but unfine-tuned GPT-4. This suggests\nFig 5. One example of nested entities.\nhttps://d oi.org/10.1371/j ournal.pon e.0300919.g0 05\nPLOS ONE\nAE-GPT: Using large language models to extract adverse events from surveillance reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03009 19 March 21, 2024 9 / 16\nTable 3. NER performan ce comparison on VAERS reports by strict F1.\nGPT-2 GPT-3 GPT-3.5 GPT-4 Llama\nada babbage curie davinci 2-7b-chat 2-13b-chat\nPretrained Fine-\ntuned\nPretrained Fine-\ntuned\nPretrained Fine-\ntuned\nPretrained Fine-\ntuned\nPretrained Fine-\ntuned\nPretrained Fine-\ntuned\nPretrained Pretrained Fine-\ntuned\nPretrained Fine-\ntuned\ninvestigation 0 0 0 0.389 0 0.304 0 0.214 0 0.344 0.241 0.667 0.304 0.097 0.024 0.099 0.114\nnervous_AE 0 0 0 0.319 0 0.277 0 0.356 0 0.459 0.208 0.727 0.458 0.102 0.024 0.173 0.096\nother_AE 0 0 0 0.17 0 0.17 0 0.183 0 0.351 0.165 0.638 0.412 0.234 0.041 0.213 0.042\nprocedure 0 0 0 0.39 0 0.388 0 0.511 0 0.464 0.059 0.716 0.02 0.283 0.066 0.189 0.077\nsocial_circumstance 0 0 0 0 0 0 0 0 0 0 0.133 0.5 0 0 0 0 0\ntemporal_expression 0 0 0 0.457 0 0.545 0 0.504 0 0.583 0.252 0.76 0.323 0.202 0.062 0.013 0.053\nMicroaverage 0 0 0 0.335 0 0.356 0 0.359 0 0.436 0.183 0.704 0.308 0.16 0.046 0.134 0.07\nNote: The scores were averaged scores after 10 runs\nhttps:// doi.org/10.1371 /journal.pone. 0300919.t0 03\nTable 4. NER performan ce comparison on VAER S reports by relaxed F1.\nGPT-2 GPT-3 GPT-3.5 GPT-4 Llama\nada babbage curie davinci 2-7b-chat 2-13b-chat\nPretrained Fine-\ntuned\nPretrained Fine-\ntuned\nPretrained Fine-\ntuned\nPretrained Fine-\ntuned\nPretrained Fine-\ntuned\nPretrained Fine-\ntuned\nPretrained Pretrained Fine-\ntuned\nPretrained Fine-\ntuned\ninvestigation 0 0 0 0.463 0 0.448 0 0.321 0 0.53 0.289 0.795 0.464 0.13 0.047 0.128 0.21\nnervous_AE 0 0.047 0 0.478 0 0.408 0 0.483 0 0.584 0.308 0.872 0.658 0.277 0.047 0.378 0.192\nother_AE 0 0.021 0 0.243 0 0.243 0 0.286 0 0.412 0.278 0.704 0.486 0.309 0.062 0.295 0.042\nprocedure 0 0.08 0 0.419 0 0.464 0 0.534 0 0.522 0.094 0.743 0.305 0.318 0.077 0.245 0.088\nsocial_circumstan ce 0 0 0 0 0 0 0 0.286 0 0 0.133 0.5 0 0 0 0 0\ntemporal_expres sion 0 0.075 0 0.705 0 0.743 0 0.628 0 0.729 0.613 0.886 0.673 0.519 0.198 0.093 0.093\nMicroaverage 0 0.049 0 0.457 0 0.484 0 0.456 0 0.54 0.329 0.816 0.515 0.269 0.101 0.221 0.118\nNote: The scores were averaged scores after 10 runs.\nhttps://doi.o rg/10.1371/j ournal.pone .0300919.t004\nPLOS ONE\nAE-GPT: Using large language models to extract adverse events from surveillance reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03009 19 March 21, 2024 10 / 16\nthat the specific fine-tuning with AE datasets could have equipped GPT models with a more\nprofound insight of the domain, whereas the generic, broad knowledge base of the pretrained\nGPT-4 may not have been as optimized for this particular task. However, this fine-tuning\neffect was not universally observed. Despite similar attempts at enhancement, GPT-2 did not\nexhibit substantial improvements when fine-tuned. One plausible explanation is that GPT-2’s\nunderlying architecture and training might have specialized in tasks like text completion rather\nthan NER tasks [59]. Its core strengths may not align as seamlessly with the demands of AE\nNER, resulting in fine-tuning less effective for this model. On the other hand, the performance\nof Llama remained stagnant across both its iterations and fine-tuning attempts. This could be\nindicative of a plateau in the model’s learning capacity for the AE NER task, or perhaps the\nfine-tuning process or data did not sufficiently align with the model’s strengths. Another possi-\nbility is that Llama’s architecture inherently lacks certain features or capacities which make the\nGPT series more adaptable to the AE NER task. The limited size of the dataset may also con-\ntribute to the overfitting, which degrades the performance. Further investigation might be\nneeded to discern the specific factors influencing Llama’s performance.\nCompared to the work carried out by Du et al., which focused on using the conventional\nmachine learning-based methods and deep learning-based methods [17]. AE-GPT outper-\nforms the proposed model in Du’s work (the highest exact match micro averaged F-1 score at\n0.6802 by ensembles of BioBERT and VAERS BERT; highest lenient match micro averaged F-\n1 score at 0.8078 by Large VAERS BERT) [17]. AE-GPT’s (the fine-tuned GPT-3.5 model’s)\nenhanced performance in extracting specific entities like investigations, various adverse events,\nsocial circumstances, and timestamps can be attributed to its vast pretraining on diverse data-\nsets and its inherent architectural advantages, allowing it to capture broader contextual\nnuances. Meanwhile, the ensembles of BioBERT and VAERS BERT, despite their biomedical\nspecialization, might have limitations in adaptability across diverse data representations, lead-\ning to their comparative underperformance. However, when focusing on procedure extraction,\nthe domain-specific nature of the BioBERT and VAERS BERT ensemble might provide a\nmore attuned understanding of the intricate and context-dependent nature of medical proce-\ndures. This specificity could overshadow GPT-3.5’s broad adaptability, explaining the latter’s\nlesser effectiveness in that particular extraction task.\nOur study embarked on a comprehensive comparison of prevalent large language models,\nencompassing GPT-2, various versions of GPT-3, GPT-3.5, GPT-4, and Llama 2, specifically\nfocusing on their aptitude to extract AE-related entities. Crucially, both pretrained and fine-\ntuned iterations of these models were scrutinized. Based on its exhaustive nature, this research\nstands as one of the most holistic inquiries to date into the performance of LLMs in the NER\ndomain. Furthermore, it carves a niche by exploring the impact of fine-tuning on LLMs for\nNER tasks, distinguishing our efforts from other existing research and reinforcing the study’s\nunique contribution to the field.\nWhile our study offers valuable insights, it is not without its limitations. The dataset utilized\nin this research is relatively constrained, comprising only 91 VAERS reports. This limited\nscope might impede the generalizability of our findings to broader contexts. Moreover, it’s\nnoteworthy that we primarily focused on VAERS reports, which differ in structure and content\nfrom traditional clinical reports, potentially limiting the direct applicability of our findings to\nother medical documentation.\nIn our forthcoming endeavors, we aim to incorporate fine-tuning experiments with GPT-4,\nespecially as it becomes accessible for such tasks in the fall of 2023. This will not only add\nanother dimension to our current findings but also ensure that our research remains at the\ncutting edge, reflecting the latest advancements in the world of LLMs.\nPLOS ONE\nAE-GPT: Using large language models to extract adverse events from surveillance reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03009 19 March 21, 2024 11 / 16\nError analysis\nWhile AE-GPT (the fine-tuned GPT-3.5 model) has demonstrated commendable performance\nin recognizing a majority of entity types, it exhibits inherent limitations. Table 5 shows the\nerror statistics of AE-GPT across various entity types. Our classification of error types remains\nconsistent with that of Du et al., ensuring easier comparison [17]. ’Boundary mismatch’\ndenotes discrepancies in the span range of entities between machine-annotated and human-\nannotated results. ’False positive’ refers to entities identified by the proposed model that aren’t\npresent in the gold standard, while ’false negative’ indicates entities the model failed to extract.\n’Incorrect entity type’ pertains to instances where, though the entity’s span range is accurate,\nthe entity itself has been misclassified. It is evident that the model exhibits a predominant chal-\nlenge in dealing with boundary mismatch, false positives and false negatives, which can be\nattributed to several factors. The quality and representativeness of the training data play a sig-\nnificant role; inconsistent or limited annotations can lead to mismatches and incorrect identi-\nfications [60, 61]. The inherent complexity of distinguishing similar and potentially\noverlapping entities adds to the challenge. Additionally, textual ambiguity and the trade-off\nbetween specialization during fine-tuning and the generalization from the model’s original\nvast pretraining can impact accuracy. While GPT-3 is powerful, capturing all the nuances of a\nspecialized NER task can still pose challenges.\nIn particular, AE-GPT tends to miss specific procedure names, such as \"IV immunoglobu-\nlin\" and \"flu vax.\" Likewise, it exhibits a heightened likelihood of failing to recognize entities\nrelated to social circumstances. This underscores the necessity for an improved and broader\ndomain-specific vocabulary within GPT-3.5.\nMoreover, AE-GPT frequently confuses general terms such as \"injection\" and \"vaccinated\"\nas exact procedure names, and fails to extract the real vaccine names following it in the text.\nThis misinterpretation results in concurrent false positive and false negative errors.\nAnother noteworthy limitation of AE-GPT is its proneness to splitting errors. For instance,\nthe named phrase \"unable to move his hands, arms or legs.\", the model often erroneously seg-\nments this into \"unable to move his hands’’ and \"arms or legs,\" revealing a shortcoming in its\ngrasp of language understanding.\nIn our next steps, we intend to improve rare entity extraction, such as social circumstances,\nby leveraging ontologies and terminologies in these specific domains. We also plan to enhance\nthe embeddings within LLMs to broaden their coverage of these rare entities. Furthermore,\nexpanding our dataset to include drug AEs is on our agenda. We will also introduce clinical\nnotes and biomedical literature to further enrich the dataset. This increased data volume will\nenable LLMs to better distinguish nuances between entity classes, such as procedure vs. investi-\ngation and nervous_AE vs. other_AE.\nTable 5. Statistics of AE-GPT predictio n errors on different entity types.\nBoundary Mismatch\n(out of human\nannotated entities)\nFalse Positive (out\nof machine\nannotated entities)\nFalse Negativ e (out\nof human\nannotated entities)\nIncorrect Entity Type\n(out of machine\nannotated entities)\ninvestigat ion 13/66, 19.7% 20/90, 22.22% 6/66, 9.1% 5/90, 5.56%\nnervous_AE 28/175, 16% 15/169, 8.88% 30/175, 17.14% 1/169, 0.59%\nother_AE 12/169, 7.1% 21/132, 15.91% 63/169, 37.28% 3/132, 2.27%\nprocedure 4/156, 2.56% 28/140, 20% 46/156, 29.49% 2/140, 1.43%\nsocial_ci rcumstance 0/2, 0% ½, 50% ½, 50% 0/2, 0%\ntempor al_expressio n 21/141,14. 89% 6/130, 4.62% 22/141,1 5.6% 0/130,0%\nhttps://d oi.org/10.1371/j ournal.pon e.0300919.t00 5\nPLOS ONE\nAE-GPT: Using large language models to extract adverse events from surveillance reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03009 19 March 21, 2024 12 / 16\nIn future investigations, we will also acknowledge the importance of delving into the statis-\ntical significance of identified AEs. While the current study primarily focuses on evaluating the\nperformance of different pretrained and fine-tuned LLMs in the NER task, we have previously\nconducted statistical analyses using structured data [62, 63]. The subsequent phase of assessing\nthe statistical significance of AEs represents a crucial avenue for further exploration. Our plan\nis to integrate the extracted data from unstructured text with the previously collected struc-\ntured data, incorporating rigorous statistical methods, such as hypothesis testing and signifi-\ncance thresholds. This approach aims to systematically evaluate the significance of AEs within\nthe context of the Influenza vaccine use case, providing a more comprehensive understanding\nand enhancing the robustness and reliability of our findings.\nConclusion\nIn conclusion, our comprehensive exploration of LLMs within the context of NER, including\nthe development of our specialized AE extraction model AE-GPT, has not only highlighted the\nprofound implications of our findings but also marks a significant achievement as the first\npaper to evaluate the realm of pretrained and fine-tuned LLMs in NER. The introduction of\nour specialized fine-tuned model, AE-GPT, exhibits the ability to tailor LLMs to domain-spe-\ncific tasks, offering promising avenues for addressing real-world challenges, particularly in the\nextraction of AE related entities. Our research underlines the broader significance of LLMs in\nadvancing natural language understanding and processing, with implications spanning various\nfields, from healthcare and biomedicine to information retrieval and beyond. As we continue\nto harness the potential of LLMs and refine their performance, we anticipate further break-\nthroughs that will drive innovation and enhance the utility of these models across diverse\napplications.\nAuthor Contributions\nData curation: Yiming Li.\nFormal analysis: Yiming Li.\nFunding acquisition: Cui Tao.\nMethodology: Yiming Li, Jianfu Li, Jianping He, Cui Tao.\nProject administration: Cui Tao.\nSoftware: Yiming Li.\nSupervision: Cui Tao.\nValidation: Jianfu Li.\nVisualization: Yiming Li.\nWriting – original draft: Yiming Li.\nWriting – review & editing: Jianfu Li, Cui Tao.\nReferences\n1. Di Renzo L, Franza L, Monsignor e D, Esposito E, Rio P, Gasbar rini A, et al. Vaccines , Microbiota and\nImmunonutr ition: Food for Thought. Vaccines (Basel). 2022 Feb 15; 10(2):294. https:/ /doi.org/10.33 90/\nvaccines 10020294 PMID: 35214752\n2. Li Y, Lundin SK, Li J, Tao W, Dang Y, Chen Y, et al. Unpacking adverse events and association s post\nCOVID-19 vaccination: a deep dive into vaccine adverse event reporting system data. Expert Review of\nVaccines. 2024 Dec 31; 23(1):53–9 . https://doi.or g/10.1080 /14760584.202 3.22922 03 PMID: 38063069\nPLOS ONE\nAE-GPT: Using large language models to extract adverse events from surveillance reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03009 19 March 21, 2024 13 / 16\n3. Vaccines and immunizat ion [Internet]. [cited 2023 Sep 14]. Available from: https:// www.who.int/ health-\ntopics/vac cines-and -immunizati on\n4. Vaccine Adverse Event Reporting System [Internet]. U.S. Departm ent of Health and Human Services;\nAbout VAERS. Available from: https:// vaers.hhs.go v/about.htm l\n5. Wide-rangi ng Online Data for Epidemiologi c Resea rch (CDC WOND ER) [Internet ]. Centers for Disease\nControl and Prevention (CDC); CDC WOND ER. Availab le from: https://wo nder.cdc.go v/\n6. Fraiman J, Erviti J, Jones M, Greenlan d S, Whelan P, Kaplan RM, et al. Serious adverse events of spe-\ncial interest following mRNA COVID-19 vaccination in random ized trials in adults. Vaccine. 2022 Sep\n22; 40(40):579 8–805. https://doi.or g/10.1016/ j.vaccine.202 2.08.036 PMID: 36055877\n7. Possible Side effects from Vaccines | CDC [Interne t]. 2023 [cited 2023 Sep 14]. Available from: https://\nwww.cdc .gov/vacci nes/vac-gen /side-effe cts.htm\n8. McNeil MM, Weintra ub ES, Duffy J, Sukumaran L, Jacobs en SJ, Klein NP, et al. Risk of anaphyl axis\nafter vaccination in childre n and adults. J Allergy Clin Immunol. 2016 Mar; 137(3):868 –78. https:// doi.\norg/10.1016/ j.jaci.2015.07 .048 PMID: 26452420\n9. Strebel PM, Sutter RW, Cochi SL, Biellik RJ, Brink EW, Kew OM, et al. Epidem iology of Poliomye litis in\nthe United States One Decad e after the Last Reported Case of Indigen ous Wild Virus-As sociated Dis-\nease. Clinical Infectious Diseases. 1992; 14(2):568– 79. https://doi.or g/10.109 3/clinids/14 .2.568 PMID:\n1554844\n10. Babazad eh A, Mohseni Afshar Z, Javanian M, Mohammadni a-Afrouz i M, Karkhah A, Masrour- Roudsari\nJ, et al. Influenza Vaccinatio n and Guillain–B arre ´ Syndrom e: Reality or Fear. J Transl Int Med. 2019\nDec 31; 7(4):137–4 2.\n11. Paterson P, Meurice F, Stanbe rry LR, Glismann S, Rosenthal SL, Larson HJ. Vaccine hesitancy and\nhealthcare provide rs. Vaccine. 2016 Dec 20; 34(52):670 0–6. https://doi.or g/10.1016/ j.vaccine.201 6.10.\n042 PMID: 278103 14\n12. Machingai dze S, Wiyson ge CS. Understand ing COVID-19 vaccine hesitancy . Nat Med. 2021 Aug; 27\n(8):1338–9 . https://doi. org/10.1038/s 41591-021- 01459-7 PMID: 34272500\n13. Varricchio F, Iskander J, Destefano F, Ball R, Pless R, Braun MM, et al. Understand ing vaccine safety\ninformati on from the Vaccine Adverse Event Reporting System. Pediatr Infect Dis J. 2004 Apr; 23\n(4):287–94 . https://doi. org/10.1097/0 0006454 -200404000 -00002 PMID: 15071280\n14. Patricia Wodi A, Marquez P, Mba-Jona s A, Barash F, Nguon K, Moro PL. Sponta neous reports of pri-\nmary ovarian insufficiency after vaccination: A review of the vaccine adverse event reporting system\n(VAERS). Vaccine. 2023 Feb 24; 41(9):1616 –22. https://doi.or g/10.101 6/j.vaccine.20 22.12.03 8 PMID:\n36732165\n15. Shimabu kuro TT, Nguyen M, Martin D, DeStefano F. Safety monitori ng in the Vaccine Adverse Event\nReporting System (VAERS). Vaccine. 2015 Aug; 33(36):439 8–405. https://doi.or g/10.1016/ j.vaccine.\n2015.07. 035 PMID: 26209838\n16. Li Y, Li J, Dang Y, Chen Y, Tao C. Tempora l and Spatial Analysis of COVID-19 Vaccines Using Reports\nfrom Vaccine Adverse Event Reporting System. JMIR Preprints [Internet ]. [cited 2023 Sep 11]; Avail-\nable from: https://prep rints.jmir. org/preprint/ 51007 https://doi.or g/10.219 6/preprints.51 007\n17. Du J, Xiang Y, Sankaranar ayanapi llai M, Zhang M, Wang J, Si Y, et al. Extracting postmarket ing\nadverse events from safety reports in the vaccine adverse event reporting system (VAERS) using deep\nlearning. Journal of the American Medical Informatics Association . 2021 Jul 1; 28(7):1393 –400. https://\ndoi.org/10.10 93/jamia/oc ab014 PMID: 3364793 8\n18. y Arcas BA. Do Large Langua ge Models Understand Us? Daedalus. 2022 May 1; 151(2):183 –97.\n19. Chen J, Liu Z, Huang X, Wu C, Liu Q, Jiang G, et al. When Large Languag e Models Meet Personaliz a-\ntion: Perspe ctives of Challeng es and Opportuni ties. 2023.\n20. Li Y, Bubeck S, Eldan R, Giorno AD, Gunasek ar S, Lee YT. Textbooks Are All You Need II: phi-1.5 tech-\nnical report. 2023.\n21. Monteith B, Sung M. TechRxiv. Preprint. 2023. Unleashing the Economic Potentia l of Large Language\nModels: The Case of Chines e Language Efficiency. Availab le from: https://doi.or g/10.362 27/techrxiv.\n23291831.v 1\n22. Cheng K, Li Z, Li C, Xie R, Guo Q, He Y, et al. The Potenti al of GPT-4 as an AI-Powered Virtual Assis-\ntant for Surgeons Specialized in Joint Arthroplasty. Ann Biomed Eng. 2023 Jul 1; 51(7):1366 –70.\nhttps://doi.or g/10.100 7/s10439 -023-03207 -z PMID: 37071279\n23. Lee JS, Hsiang J. Patent claim generation by fine-tuning OpenAI GPT-2. World Patent Informatio n.\n2020 Sep 1; 62:1019 83.\n24. Biswas S. Prospecti ve Role of Chat GPT in the Military: According to ChatGP T. Qeios [Internet]. 2023\nFeb 27 [cited 2023 Aug 15]; Availab le from: https://ww w.qeios.com /read/8W YYOD\nPLOS ONE\nAE-GPT: Using large language models to extract adverse events from surveillance reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03009 19 March 21, 2024 14 / 16\n25. Imamguluy ev R. The Rise of GPT-3: Implications for Natural Language Processin g and Beyond . Inter-\nnational Journal of Research Publication and Reviews. 2023 Mar 3; 4:4893– 903.\n26. Ueda Daiju, Shanno n L Walston Toshim asa Matsum oto, Deguchi Ryo, Tatekaw a Hiroyuki, Miki Yukio.\nEvaluating GPT-4-ba sed ChatGPT’s Clinical Potential on the NEJM Quiz. medRxiv. 2023 Jan\n1;2023.0 5.04.23289493 .\n27. Roumeliotis KI, Tselikas ND, Nasiopoulo s DK. Llama 2: Early Adopters ’ Utilizat ion of Meta’s New\nOpen-So urce Pretrained Model. Preprints . 2023;2023.\n28. Gong Y. Multilevel Large Language Models for Everyone . 2023.\n29. Hagendor ff T. Machine Psychology : Investigating Emergen t Capabilities and Behavior in Large Lan-\nguage Models Using Psychologi cal Methods . 2023.\n30. Hu Y, Ameer I, Zuo X, Peng X, Zhou Y, Li Z, et al. Zero-sh ot Clinical Entity Recognit ion using ChatGPT\n[Internet ]. arXiv.org. 2023. Availab le from: https://doi. org/10.48550 /arXiv.23 03.16416\n31. Gringeri M, Battini V, Cammar ata G, Mosini G, Guarnier i G, Leoni C, et al. Herpes zoster and simplex\nreactivatio n following COVID-19 vaccination: new insights from a vaccine adverse event reporting sys-\ntem (VAERS) database analysis. Expert Rev Vaccines. 2022 May; 21(5):675– 84. https:// doi.org/10.\n1080/14760 584.2022.2044 799 PMID: 35191364\n32. VAERS—D ata [Interne t]. [cited 2023 Aug 17]. Available from: https://va ers.hhs.gov/d ata.html\n33. Vega-Bri ceño LE, Abarca V K, Sa ´ nchez D I. [Flu vaccin e in childre n: state of the art]. Rev Chilena Infec-\ntol. 2006 Jun; 23(2):164– 9.\n34. Centers for Disease Control and Prevention [Interne t]. 2023 [cited 2023 Aug 11]. Benefi ts of Flu Vacci-\nnation During 2021–2022 Flu Season . Available from: https://www .cdc.gov/flu/ about/burden -averted/\n2021-2022.h tm\n35. Ferdinands JM, Thompson MG, Blanton L, Spencer S, Grant L, Fry AM. Does influenza vaccinat ion\nattenuate the severity of breakthroug h infections? A narrativ e review and recommenda tions for further\nresearch . Vaccine. 2021 Jun 23; 39(28):367 8–95. https://doi.or g/10.1016/ j.vaccine.202 1.05.011 PMID:\n34090700\n36. Du J, Cai Y, Chen Y, Tao C. Trivalen t influenza vaccine adverse symptoms analysis based on MedDRA\nterminolog y using VAERS data in 2011. Journal of Biomed ical Semantics . 2016 May 13; 7(1):13.\n37. Wang DJ, Boltz DA, McElhaney J, McCulle rs JA, Webby RJ, Webster RG. No evidence of a link\nbetween influenza vaccin es and Guillain–B arre syndrom e–associated antiganglios ide antibodies. Influ-\nenza Other Respir Viruses. 2012 May; 6(3):159–6 6. https://doi.or g/10.111 1/j.1750-265 9.2011.0 0294.x\nPMID: 219553 90\n38. Cw A, Bc J, Jd L. The Guillain-Bar re ´ syndrom e: a true case of molecular mimicry . Trends in immunolog y\n[Internet ]. 2004 Feb [cited 2023 Aug 12]; 25(2). Availab le from: https://pubm ed.ncbi.nl m.nih.gov/\n15102364/\n39. Vellozzi C, Burwen DR, Dobardzic A, Ball R, Walton K, Haber P. Safety of trivalent inactivated influenza\nvaccines in adults: Backgrou nd for pandemic influenza vaccine safety monitoring. Vaccine. 2009 Mar\n26; 27(15):211 4–20. https://doi.or g/10.1016/ j.vaccine.200 9.01.125 PMID: 19356614\n40. Grabenstein JD. Guillain- Barre ´ Syndro me and Vaccinatio n: Usually Unrelated. Hosp Pharm. 2000 Feb\n1; 35(2):199– 207.\n41. Vucic S, Kiernan MC, Cornblath DR. Guillain-Bar re ´ syndrome: an update. J Clin Neurosc i. 2009 Jun; 16\n(6):733–41 .\n42. Yu RK, Usuki S, Ariga T. Ganglioside Molecular Mimicry and Its Pathologica l Roles in Guillain- Barre ´\nSyndrom e and Related Diseases. Infect Immun . 2006 Dec; 74(12):651 7–27.\n43. Natuva R, Puppala SSS. Chat GPT—a Boon or Bane to Academic Cardiology ? Indian Journal of Clini-\ncal Cardiolo gy. 2023 Aug 17;2632 46362311856 44.\n44. Hou W, Ji Z. GeneTurin g tests GPT models in genomics. bioRxiv. 2023 Mar 13;2023.03 .11.532238.\nhttps://doi.or g/10.110 1/2023.03. 11.532238 PMID: 369936 70\n45. Topal MO, Bas A, van Heerden I. Exploring Transfor mers in Natural Language Generatio n: GPT,\nBERT, and XLNet.\n46. Sallam M. ChatGPT Utility in Healthcare Education, Resea rch, and Practice: Systematic Review on the\nPromisin g Perspective s and Valid Concerns. Healthc are. 2023 Mar 19; 11(6):887. https:// doi.org/10.\n3390/healt hcare1106088 7 PMID: 369815 44\n47. Schneider ETR, de Souza JVA, Gumiel YB, Moro C, Paraiso EC. A GPT-2 Language Model for Bio-\nmedical Texts in Portuguese. In: 2021 IEEE 34th Interna tional Symposium on Comp uter-Based Medical\nSystems (CBMS). 2021. p. 474–9.\n48. Olmo A, Sreedhar an S, Kambha mpati S. GPT3-to-p lan: Extracting plans from text using GPT-3. 2021.\n49. Gokaslan A, Cohen V. OpenW ebText Corpus.\nPLOS ONE\nAE-GPT: Using large language models to extract adverse events from surveillance reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03009 19 March 21, 2024 15 / 16\n50. Brown T, Mann B, Ryder N, Subbiah M, Kaplan JD, Dhariwal P, et al. Language Models are Few-Sho t\nLearners. In: Advances in Neural Informatio n Processin g Systems [Internet]. Curran Associates, Inc.;\n2020 [cited 2023 Aug 24]. p. 1877–9 01. Available from: https://procee dings.neu rips.cc/pape r/2020/\nhash/145 7c0d6bfcb4 967418bfb8 ac142f64a-Ab stract.htm l\n51. Koubaa A. GPT-4 vs. GPT-3.5: A Concise Showdow n. Preprints [Internet]. 2023 Mar 24; Availab le\nfrom: https://doi.or g/10.20944/ preprints202 303.0422. v1\n52. Budzianow ski P, Vulić I. Hello, It’s GPT-2 –How Can I Help You? Towards the Use of Pretrained Lan-\nguage Models for Task-Or iented Dialogue System s. 2019.\n53. Ghojogh B, Ghodsi A. Attentio n mechanism, transforme rs, BERT, and GPT: tutorial and survey. 2020;\n54. Vijayasara thi M S. A, Tanuj G. Applica tion of ChatGPT in medical scienc e and Research. 2023 Jul 1;\n3:1480–3.\n55. Roy K, Zi Y, Narayanan V, Gaur M, Sheth A. Knowledge-Inf used Self Attentio n Transforme rs. 2023.\n56. Touvron H, Martin L, Stone K, Albert P, Almahairi A, Babaei Y, et al. Llama 2: Open Foundati on and\nFine-Tuned Chat Models. 2023.\n57. OpenAI GPT2 [Internet ]. [cited 2023 Sep 8]. Available from: https://huggi ngface.co/do cs/trans formers/\nmodel_d oc/gpt2\n58. Tarlaci F. GPT2sQA [Internet] . 2023 [cited 2023 Sep 6]. Available from: https://github .com/fta rlaci/\nGPT2sQA\n59. Austin J. The Book of Endless History : Authorial Use of GPT2 for Interactive Storytelling. In: Cardona-\nRivera RE, Sulliva n A, Young RM, editors. Interactive Storytel ling. Cham: Springer International Pub-\nlishing; 2019. p. 429–32. (Lecture Notes in Computer Science).\n60. Li Y., Peng X., Li J., Peng S., Pei D., Tao C., et al. Developm ent of a Natural Language Processin g Tool\nto Extract Acupunctu re Point Location Terms. In: 2023 IEEE 11th Internat ional Conference on Health-\ncare Informatics (ICHI) [Internet] . 2023. p. 344–51. Availab le from: https://d oi.org/10.110 9/ICHI578 59.\n2023.00053\n61. Li Y, Tao W, Li Z, Sun Z, Li F, Fenton S, et al. Artifici al intelligence- powered pharmacovi gilance: A\nreview of machine and deep learning in clinical text-based adverse drug event detection for benchmar k\ndatasets. J Biomed Inform. 2024 Mar 4;10462 1. https://doi.or g/10.101 6/j.jbi.2024.10 4621 PMID:\n38447600\n62. Luo C, Jiang Y, Du J, Tong J, Huang J, Lo Re V, et al. Predict ion of post-vaccinati on Guillain- Barre ´ syn-\ndrome using data from a passiv e surveillanc e system. Pharma coepidemi ol Drug Saf. 2021 May; 30\n(5):602–9.\n63. Du J, Cai Y, Chen Y, He Y, Tao C. Analysis of Individua l Differences in Vaccine Pharmac ovigilance\nUsing VAERS Data and MedDRA System Organ Classes: A Use Case Study With Trivalen t Influenza\nVaccine. Biomed Inform Insights. 2017 Apr 11; 9:11782 22617700627 . https://doi. org/10.1177/\n11782226177 00627 PMID: 28469434\nPLOS ONE\nAE-GPT: Using large language models to extract adverse events from surveillance reports\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03009 19 March 21, 2024 16 / 16"
}