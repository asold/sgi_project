{
  "title": "S‐PLM: Structure‐Aware Protein Language Model via Contrastive Learning Between Sequence and Structure",
  "url": "https://openalex.org/W4405330335",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5003943520",
      "name": "Duolin Wang",
      "affiliations": [
        "University of Missouri"
      ]
    },
    {
      "id": "https://openalex.org/A5021973112",
      "name": "Mahdi Pourmirzaei",
      "affiliations": [
        "University of Missouri"
      ]
    },
    {
      "id": "https://openalex.org/A5039988690",
      "name": "Usman L. Abbas",
      "affiliations": [
        "University of Kentucky"
      ]
    },
    {
      "id": "https://openalex.org/A5103082007",
      "name": "Shuai Zeng",
      "affiliations": [
        "University of Missouri"
      ]
    },
    {
      "id": "https://openalex.org/A5047946195",
      "name": "Negin Manshour",
      "affiliations": [
        "University of Missouri"
      ]
    },
    {
      "id": "https://openalex.org/A5076603704",
      "name": "Farzaneh Esmaili",
      "affiliations": [
        "University of Missouri"
      ]
    },
    {
      "id": "https://openalex.org/A5093382204",
      "name": "Biplab Poudel",
      "affiliations": [
        "University of Missouri"
      ]
    },
    {
      "id": "https://openalex.org/A5112452050",
      "name": "Yuexu Jiang",
      "affiliations": [
        "University of Missouri"
      ]
    },
    {
      "id": "https://openalex.org/A5069728983",
      "name": "Qing Shao",
      "affiliations": [
        "University of Kentucky"
      ]
    },
    {
      "id": "https://openalex.org/A5100457144",
      "name": "Jin Chen",
      "affiliations": [
        "University of Alabama at Birmingham"
      ]
    },
    {
      "id": "https://openalex.org/A5082428303",
      "name": "Dong Xu",
      "affiliations": [
        "University of Missouri"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3144701084",
    "https://openalex.org/W3177500196",
    "https://openalex.org/W4327550249",
    "https://openalex.org/W3146944767",
    "https://openalex.org/W4288066876",
    "https://openalex.org/W4362664122",
    "https://openalex.org/W3166142427",
    "https://openalex.org/W3177828909",
    "https://openalex.org/W4205773061",
    "https://openalex.org/W4365444089",
    "https://openalex.org/W3108655343",
    "https://openalex.org/W4362471278",
    "https://openalex.org/W2788388592",
    "https://openalex.org/W2604823638",
    "https://openalex.org/W2120755421",
    "https://openalex.org/W3106745904",
    "https://openalex.org/W2085487226",
    "https://openalex.org/W4382247824",
    "https://openalex.org/W2054800842",
    "https://openalex.org/W3011725683",
    "https://openalex.org/W4210830887",
    "https://openalex.org/W4220991280",
    "https://openalex.org/W2194775991",
    "https://openalex.org/W2889498145",
    "https://openalex.org/W2041837226",
    "https://openalex.org/W3164046276",
    "https://openalex.org/W2950374603",
    "https://openalex.org/W2104972430"
  ],
  "abstract": "Abstract Proteins play an essential role in various biological and engineering processes. Large protein language models (PLMs) present excellent potential to reshape protein research by accelerating the determination of protein functions and the design of proteins with the desired functions. The prediction and design capacity of PLMs relies on the representation gained from the protein sequences. However, the lack of crucial 3D structure information in most PLMs restricts the prediction capacity of PLMs in various applications, especially those heavily dependent on 3D structures. To address this issue, S‐PLM is introduced as a 3D structure‐aware PLM that utilizes multi‐view contrastive learning to align the sequence and 3D structure of a protein in a coordinated latent space. S‐PLM applies Swin‐Transformer on AlphaFold‐predicted protein structures to embed the structural information and fuses it into sequence‐based embedding from ESM2. Additionally, a library of lightweight tuning tools is provided to adapt S‐PLM for diverse downstream protein prediction tasks. The results demonstrate S‐PLM's superior performance over sequence‐only PLMs on all protein clustering and classification tasks, achieving competitiveness comparable to state‐of‐the‐art methods requiring both sequence and structure inputs. S‐PLM and its lightweight tuning tools are available at https://github.com/duolinwang/S-PLM/ .",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6640994548797607
    },
    {
      "name": "Sequence (biology)",
      "score": 0.5896978974342346
    },
    {
      "name": "Embedding",
      "score": 0.4684612452983856
    },
    {
      "name": "Protein sequencing",
      "score": 0.4444971978664398
    },
    {
      "name": "Protein structure prediction",
      "score": 0.4231763482093811
    },
    {
      "name": "Artificial intelligence",
      "score": 0.418828547000885
    },
    {
      "name": "Protein structure",
      "score": 0.3727740943431854
    },
    {
      "name": "Peptide sequence",
      "score": 0.20532655715942383
    },
    {
      "name": "Biology",
      "score": 0.1587936282157898
    },
    {
      "name": "Genetics",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    }
  ]
}