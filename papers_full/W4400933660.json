{
    "title": "A question-answering framework for automated abstract screening using large language models",
    "url": "https://openalex.org/W4400933660",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A5093532593",
            "name": "Opeoluwa Akinseloyin",
            "affiliations": [
                "Coventry University"
            ]
        },
        {
            "id": "https://openalex.org/A2116695089",
            "name": "Xiaorui Jiang",
            "affiliations": [
                "University of Sheffield"
            ]
        },
        {
            "id": "https://openalex.org/A206588628",
            "name": "Vasile Palade",
            "affiliations": [
                "Coventry University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2095601341",
        "https://openalex.org/W1997684599",
        "https://openalex.org/W3156775206",
        "https://openalex.org/W2512040454",
        "https://openalex.org/W2973152762",
        "https://openalex.org/W6848766623",
        "https://openalex.org/W3149778443",
        "https://openalex.org/W6731613980",
        "https://openalex.org/W6778883912",
        "https://openalex.org/W2045384400",
        "https://openalex.org/W2124493593",
        "https://openalex.org/W168362576",
        "https://openalex.org/W2961191798",
        "https://openalex.org/W2184378182",
        "https://openalex.org/W3087185831",
        "https://openalex.org/W4315641584",
        "https://openalex.org/W2560438049",
        "https://openalex.org/W2063198586",
        "https://openalex.org/W1576855214",
        "https://openalex.org/W2043566294",
        "https://openalex.org/W2154352790",
        "https://openalex.org/W6777418044",
        "https://openalex.org/W3165198619",
        "https://openalex.org/W2596568673",
        "https://openalex.org/W2183168769",
        "https://openalex.org/W2066908458",
        "https://openalex.org/W2035792132",
        "https://openalex.org/W3111278950",
        "https://openalex.org/W4391215636",
        "https://openalex.org/W3185341429",
        "https://openalex.org/W4383722515",
        "https://openalex.org/W4387144848",
        "https://openalex.org/W4384071683",
        "https://openalex.org/W4319460874",
        "https://openalex.org/W6800366643",
        "https://openalex.org/W4308628131",
        "https://openalex.org/W4252076394",
        "https://openalex.org/W2911489562",
        "https://openalex.org/W2971258845",
        "https://openalex.org/W6781031682",
        "https://openalex.org/W2953029151",
        "https://openalex.org/W6859964065",
        "https://openalex.org/W2565695915",
        "https://openalex.org/W2147469877",
        "https://openalex.org/W2969341057",
        "https://openalex.org/W2600107025",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W3196385594",
        "https://openalex.org/W3046375318",
        "https://openalex.org/W4389805278",
        "https://openalex.org/W4313371821",
        "https://openalex.org/W3023715695"
    ],
    "abstract": "Abstract Objective This paper aims to address the challenges in abstract screening within systematic reviews (SR) by leveraging the zero-shot capabilities of large language models (LLMs). Methods We employ LLM to prioritize candidate studies by aligning abstracts with the selection criteria outlined in an SR protocol. Abstract screening was transformed into a novel question-answering (QA) framework, treating each selection criterion as a question addressed by LLM. The framework involves breaking down the selection criteria into multiple questions, properly prompting LLM to answer each question, scoring and re-ranking each answer, and combining the responses to make nuanced inclusion or exclusion decisions. Results and Discussion Large-scale validation was performed on the benchmark of CLEF eHealth 2019 Task 2: Technology-Assisted Reviews in Empirical Medicine. Focusing on GPT-3.5 as a case study, the proposed QA framework consistently exhibited a clear advantage over traditional information retrieval approaches and bespoke BERT-family models that were fine-tuned for prioritizing candidate studies (ie, from the BERT to PubMedBERT) across 31 datasets of 4 categories of SRs, underscoring their high potential in facilitating abstract screening. The experiments also showcased the viability of using selection criteria as a query for reference prioritization. The experiments also showcased the viability of the framework using different LLMs. Conclusion Investigation justified the indispensable value of leveraging selection criteria to improve the performance of automated abstract screening. LLMs demonstrated proficiency in prioritizing candidate studies for abstract screening using the proposed QA framework. Significant performance improvements were obtained by re-ranking answers using the semantic alignment between abstracts and selection criteria. This further highlighted the pertinence of utilizing selection criteria to enhance abstract screening.",
    "full_text": null
}