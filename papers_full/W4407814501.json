{
  "title": "EAGER-LLM: Enhancing Large Language Models as Recommenders through Exogenous Behavior-Semantic Integration",
  "url": "https://openalex.org/W4407814501",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2782760702",
      "name": "Minjie Hong",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2100287684",
      "name": "Yan Xia",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2152099389",
      "name": "Zehan Wang",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2116445876",
      "name": "Jieming Zhu",
      "affiliations": [
        "Huawei Technologies (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2100304378",
      "name": "Ye Wang",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A3126936045",
      "name": "Sihang Cai",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2112425659",
      "name": "Xiao-Da Yang",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2652520829",
      "name": "Quanyu Dai",
      "affiliations": [
        "Huawei Technologies (China)"
      ]
    },
    {
      "id": "https://openalex.org/A1995934682",
      "name": "Zhenhua Dong",
      "affiliations": [
        "Huawei Technologies (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2138990207",
      "name": "Zhimeng Zhang",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2011399166",
      "name": "Zhou Zhao",
      "affiliations": [
        "Zhejiang University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4386728933",
    "https://openalex.org/W4296591867",
    "https://openalex.org/W4297971002",
    "https://openalex.org/W3045200674",
    "https://openalex.org/W4290944002",
    "https://openalex.org/W4392846385",
    "https://openalex.org/W4376312036",
    "https://openalex.org/W2998702515",
    "https://openalex.org/W2963367478",
    "https://openalex.org/W2054141820",
    "https://openalex.org/W6600234944",
    "https://openalex.org/W2964044287",
    "https://openalex.org/W4360612299",
    "https://openalex.org/W6600669965",
    "https://openalex.org/W2951645301",
    "https://openalex.org/W2027731328",
    "https://openalex.org/W2981852735",
    "https://openalex.org/W2171279286",
    "https://openalex.org/W2984100107",
    "https://openalex.org/W2783272285",
    "https://openalex.org/W3153940464",
    "https://openalex.org/W6600339457",
    "https://openalex.org/W4401863330",
    "https://openalex.org/W2966483207",
    "https://openalex.org/W4400909953",
    "https://openalex.org/W2723293840",
    "https://openalex.org/W3065542300",
    "https://openalex.org/W4396734745",
    "https://openalex.org/W3100260481",
    "https://openalex.org/W4401856724",
    "https://openalex.org/W4288089799"
  ],
  "abstract": "Large language models (LLMs) are increasingly leveraged as foundational backbones in the development of advanced recommender systems, offering enhanced capabilities through their extensive knowledge and reasoning. Existing llm-based recommender systems (RSs) often face challenges due to the significant differences between the linguistic semantics of pre-trained LLMs and the collaborative semantics essential for RSs. These systems use pre-trained linguistic semantics but learn collaborative semantics from scratch via the llm-Backbone. However, LLMs are not designed for recommendations, leading to inefficient collaborative learning, weak result correlations, and poor integration of traditional RS features. To address these challenges, we propose EAGER-LLM, a decoder-only llm-based generative recommendation framework that integrates endogenous and exogenous behavioral and semantic information in a non-intrusive manner. Specifically, we propose 1)dual-source knowledge-rich item indices that integrates indexing sequences for exogenous signals, enabling efficient link-wide processing; 2)non-invasive multiscale alignment reconstruction tasks guide the model toward a deeper understanding of both collaborative and semantic signals; 3)an annealing adapter designed to finely balance the model's recommendation performance with its comprehension capabilities. We demonstrate EAGER-LLM's effectiveness through rigorous testing on three public benchmarks.",
  "full_text": "EAGER-LLM: Enhancing Large Language Models as\nRecommenders through Exogenous Behavior-Semantic\nIntegration\nMinjie Hongâˆ—\nhongminjie@zju.edu.cn\nZhejiang University\nHangzhou, Zhejiang, China\nYan Xiaâˆ—\nxiayan.zju@gmail.com\nZhejiang University\nHangzhou, Zhejiang, China\nZehan Wang\nwangzehan01@zju.edu.cn\nZhejiang University\nHangzhou, Zhejiang, China\nJieming Zhuâ€ \njiemingzhu@ieee.org\nHuawei Noahâ€™s Ark Lab\nShenzhen, Guangdong, China\nYe Wang\n22151150@zju.edu.cn\nZhejiang University\nHangzhou, Zhejiang, China\nSihang Cai\ncaisihang@zju.edu.cn\nZhejiang University\nHangzhou, Zhejiang, China\nXiaoda Yang\nxiaodayang@zju.edu.cn\nZhejiang University\nHangzhou, Zhejiang, China\nQuanyu Dai\ndaiquanyu@huawei.com\nHuawei Noahâ€™s Ark Lab\nShenzhen, Guangdong, China\nZhenhua Dong\ndongzhenhua@huawei.com\nHuawei Noahâ€™s Ark Lab\nShenzhen, Guangdong, China\nZhimeng Zhang\nzhimeng@zju.edu.cn\nZhejiang University\nHangzhou, Zhejiang, China\nZhou Zhaoâ€¡\nzhaozhou@zju.edu.cn\nZhejiang University\nHangzhou, Zhejiang, China\nAbstract\nLarge language models (LLMs) are increasingly leveraged as foun-\ndational backbones in the development of advanced recommender\nsystems, offering enhanced capabilities through their extensive\nknowledge and reasoning. Existing llm-based recommender sys-\ntems (RSs) often face challenges due to the significant differences\nbetween the linguistic semantics of pre-trained LLMs and the collab-\norative semantics essential for RSs. These systems use pre-trained\nlinguistic semantics but learn collaborative semantics from scratch\nvia the llm-Backbone. However, LLMs are not designed for recom-\nmendations, leading to inefficient collaborative learning, weak re-\nsult correlations, and poor integration of traditional RS features. To\naddress these challenges, we proposeEAGER-LLM, a decoder-only\nllm-based generative recommendation framework that integrates\nendogenous and exogenous behavioral and semantic information\nin a non-intrusive manner. Specifically, we propose 1) dual-source\nknowledge-rich item indices that integrates indexing sequences\nâˆ—Both authors contributed equally to this research.\nâ€ Project Lead.\nâ€¡Corresponding Author.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nWWW â€™25, Sydney, NSW, Australia\nÂ© 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 979-8-4007-1274-6/25/04\nhttps://doi.org/10.1145/3696410.3714933\nfor exogenous signals, enabling efficient link-wide processing; 2)\nnon-invasive multiscale alignment reconstruction tasks guide the\nmodel toward a deeper understanding of both collaborative and\nsemantic signals; 3) an annealing adapter designed to finely balance\nthe modelâ€™s recommendation performance with its comprehension\ncapabilities. We demonstrate EAGER-LLMâ€™s effectiveness through\nrigorous testing on three public benchmarks.\nCCS Concepts\nâ€¢ Information systems â†’Recommender systems.\nKeywords\nGenerative Recommendation; Large Language Models; LLM-as-\nRecommender; Behavior-Semantic Collaboration\nACM Reference Format:\nMinjie Hong, Yan Xia, Zehan Wang, Jieming Zhu, Ye Wang, Sihang Cai,\nXiaoda Yang, Quanyu Dai, Zhenhua Dong, Zhimeng Zhang, and Zhou\nZhao. 2025. EAGER-LLM: Enhancing Large Language Models as Recom-\nmenders through Exogenous Behavior-Semantic Integration. In Proceedings\nof the ACM Web Conference 2025 (WWW â€™25), April 28-May 2, 2025, Sydney,\nNSW, Australia. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/\n3696410.3714933\n1 Introduction\nRecommender systems are tools designed to alleviate the phenom-\nenon of information overload in Web environments by algorithmi-\ncally analyzing user behavior to predict and push content that may\nbe of interest to users. Typical recommender systems [11, 17, 20, 34]\nencode users and items as latent representations within a shared\narXiv:2502.14735v1  [cs.IR]  20 Feb 2025\nWWW â€™25, April 28-May 2, 2025, Sydney, NSW, Australia Minjie Hong et al.\n!!\n !\"\n !#\"â€¦â€¦â€¦â€¦\n\"!\n \"\"\nâ€¦\n\"!\n \"\"\nDecoder-Only LLM Backbone\n\"$%&\nText InstructionsUser History of t ItemsTokens of t+1 Item\nPredictedTokens\n Item 50Item 51Item 52Item 53\nItem 47Item 48Item 49\nItem 54Item 55Item 56\nFigure 1: A framework of LLM-as-Recommender. It frames\nrecommendation as next token generation tasks, which di-\nrectly generate target items.\nspace to capture semantic similarities, followed by efficient retrieval\nusing Approximate Nearest Neighbors (ANNs) algorithms [8, 16].\nThe distinct separation of these two phases often introduces perfor-\nmance limitations due to the absence of end-to-end optimization.\nResearch across domains like vision [1, 23], speech [4, 15], and\nmultimodality [42] demonstrates the broader applicability of LLMs.\nSeveral recent studies investigate the potential roles of LLMs in\nrecommender systems (RSs). Unlike traditional models that en-\ncode users and items as embedding vectors, some LLM-based RSs\n[2, 5, 13, 21] converts user behaviors and preferences, alongside the\ncandidate item set, into discrete natural language text sequences\nor prompts. These prompts are then used to extract item-related\ninformation from the LLMâ€™s textual outputs. [7, 14, 24, 43] enhance\ncollaboration by incorporating additional or existing tokens into\nthe LLM to represent user and item IDs, which are then fine-tuned\nduring specialized training to fit interaction data. [35, 38] employs\nexogenous collaboration models to obtain collaboration embed-\ndings, which are integrated into the inputs of the LLM, thereby\nenriching the recommendation process.\nBut these paradigms suffer from several flaws:(1) While the plain\ntext approach can yield favorable outcomes in zero-shot recommen-\ndation [5, 13] , it primarily analyzes only the surface-level textual\nsemantics of behavioral sequences. This method heavily relies on\ncandidate sets and incurs significant computational overhead when\nmodeling extensive historical sequences. (2) In real-world appli-\ncations, where the number of candidate recommendation items\nvastly exceeds the vocabulary size of LLMs, the tokenization re-\ndundancy introduced by Vanilla IDs complicates LLMsâ€™ ability to\naccurately interpret commands. This redundancy results in low\nlearning efficiency and a failure to effectively leverage semantic\nfeatures. (3) The substantial disparity between the domains of ex-\nternal collaborative signals and the semantic signals of pre-trained\nLLMs means that directly integrating these signals can significantly\ndisrupt the original functionalities of the LLMs. Consequently, the\nmodel struggles to effectively process and interpret the information\ncontained in these external signals [35, 38].\nTo overcome the challenges outlined, we introduce EAGER-\nLLM, a novel decoder-only LLM-based generative recommenda-\ntion framework. In this framework, we compress massive exoge-\nnous signals into a few newly added tokens with extremely high\ncompression ratios. Additionally, we incorporate a non-invasive\nmulti-scale alignment reconstruction tasks and Multi-Stage Train-\ning that facilitates an efficient understanding and integration of\nexogenous behaviors, semantic signals, and recommendation data\nknowledge with the LLMâ€™s original parameters. Our approach is\ndetailed through three aspects:\nPrimarily, we introduceDual-source Knowledge-rich Item In-\ndices to address the inefficiencies of previous approaches that used\natomic tokens to represent item IDs, which resulted in tokenization\nredundancy and overly discrete and independent semantics that\ndid not effectively support the recommendation task. Our method\nefficiently characterizes large candidate sets with a small number\nof identifiers, incorporating a useful priori knowledge with a high\ncompression ratio to integrate exogenous semantic and behavioral\ninformation into the decoding inference process. We implement an\nindexing structure where semantically similar items share identifier\nprefixes. Given the distinct domain differences between behavioral\nand semantic feature spaces, prior research in multimodal and\nbimodal models [3] has shown that even advanced encoder-side\nfeature fusion approaches like Q-former [ 19] are insufficient for\neffective integration of dual-source features. Consequently, we dis-\ncretize and separately splice the exogenous behavioral and semantic\nsignals. This decoupled indexing scheme minimizes information\nloss from encoder-side feature fusion and enables the model to\nmore effectively represent the complex interplay between behavior\nand semantics during subsequent training.\nFurthermore, we have introduced Non-Invasive Multiscale\nAlignment Reconstruction Tasks . Given the vast amount of ex-\nogenous semantic and behavioral signals compressed into a small\nnumber of tokens at a very high compression ratio, it is challenging\nfor the model to directly assimilate adequate exogenous knowledge.\nTo address this, we have devised the Global Contrast Decompres-\nsion Task and Comprehensive Interaction Modeling Tasks. These\ninitiatives aid the model in decompressing extensive exogenous\nknowledge from a limited number of highly compressed tokens. By\nincorporating additional summarization tokens and leveraging the\nrestricted context of recommendation data, these tasks effectively\nminimize the domain gap between natural language and collabo-\nrative semantics, enhancing the efficiency of the recommendation\nprocess. In addition, we introduced a multi-stage training scheme\ncentered on the Annealing Adapter, which flexibly balances rec-\nommendation accuracy and model text inference capability. The\ncontributions of this paper can be summarized as follows:\nâ€¢We present EAGER-LLM, an innovative decoder-only LLM-based\ngenerative recommendation framework that synergistically in-\ntegrates endogenous and exogenous behavioral and semantic\ninformation\nâ€¢We propose Dual-source Knowledge-rich Item Indices, Multiscale\nAlignment Reconstruction Tasks and the Annealing Adapter that\nnon-intrusively guide the model towards a deep understanding\nof collaborative and semantic signals.\nâ€¢Extensive experiments across three public recommendation bench-\nmarks demonstrate the superiority of EAGER-LLM over existing\nmethods, emphasizing its effectiveness and robustness.\nEAGER-LLM: Enhancing LLMs as Recommenders through Exogenous Behavior-Semantic Integration WWW â€™25, April 28-May 2, 2025, Sydney, NSW, Australia\n744 7\n43 30\n5652\n9565\nCanditate Items\nDescription\nInteraction\nLLM asSemantic Encoder\nPretrainedBehavior Encoder\nEmbeddings\nHierarchicalK-Means\n 4\n6\n3\n5\n9\n6\n3\n7\n9\n5\n6\n2\n5\n3\n6\n2\n5\n4\n5\n7\n7\n4\n3\n0\nSemantic-Behavior Tokens\nHierarchicalK-Means\nFigure 2: The illustration of Dual-source Knowledge-rich Item Indice. Incorporate massive exogenous behavioral semantic\nsignals into project indices with extremely high compression ratios.\n2 Related work\n2.1 Sequential Recommendation\nThe use of deep sequential models for understanding user-item\ninteractions in recommender systems has significantly evolved,\nwith various approaches making notable contributions. GRU4REC\n[11] introduced the use of GRU-based RNNs to model sequential\nuser behaviors effectively. SASRec [17] implemented self-attention\nmechanisms akin to those found in decoder-only transformer mod-\nels to enhance recommendation accuracy. Drawing inspiration from\nthe success of masked language modeling in NLP, BERT4Rec [30]\napplied transformers with masking techniques specifically tailored\nfor sequential recommendation tasks. Additionally, TIGER [28] has\nstarted emphasizing the use of semantic IDs. In this approach, each\nitem is represented by a series of tokens that reflect its related de-\ntails, and the system predicts the sequence of upcoming item tokens\nusing a seq2seq method. Additionally EAGER [36] advances the in-\nvestigation by implementing a dual-stream generation architecture\nthat incorporates both semantic and behavioral information. In this\nwork, we extend EAGER [36] to EAGER-LLM by bridging LLMs\nand recommenders with dual-source knowledge-rich item indices\nand non-invasive multiscale alignment reconstruction, which not\nonly enhances recommendation accuracy but also retains conver-\nsation and explanation generation abilities of LLMs. Recently, P5\n[7, 14] fine-tunes a pre-trained LLMs for multi-task recommender\nsystems. In this study, we endeavor to further investigate a para-\ndigm designed to mitigate the substantial discrepancies between\nLLMs in recommendation tasks and their original training tasks by\nintegrating exogenous semantic and behavioral information.\n2.2 LLMs as Recommenders\nRecently, LLMs have been utilized in recommendation tasks due\nto their ability to understand, generate, and infer natural language\nproperties. LLM-based RSs [24] constructs user/item correlations\nthrough its powerful high-quality textual representations and exten-\nsive external knowledge, and is expected to solve the problems of\npoor generalization [22] and poor performance of traditional RSs on\nsparse historical interaction data, etc. Chat-Rec [6] aims to enhance\nconversational recommendation systems by integrating ChatGPTâ€™s\ninteractive capabilities with established recommendation models,\nsuch as MF [18] and LightGCN [10]. P5 [7] fine-tunes a pre-trained\nlarge language model for multi-task recommender systems, utiliz-\ning the LLM tokenizer (SentencePiece tokenizer) to generate tokens\nfrom randomly assigned item pseudo-IDs. M6 [5]explores the use\nof item text information (such as names) as identifiers for items.\nLC-Rec [39] designs a learning-based vector quantization method\nto generate ID from Itemâ€™s semantic representation and proposes\nalignment tuning tasks to enhance the intergration of collabora-\ntive semantics in LLMs. Recently, new research has emerged to\nbridge the significant gap between pre-trained language models\nand recommendation tasks. CoLLM [38] infuses behavior informa-\ntion into LLMs by incorporating representations from an external\ncollaborative model into the input. In this work, we aim to further\nexplore recommender frameworks that can integrate endogenous\nand exogenous behavioral and semantic signals based on LLM.\n3 METHODOLOGY\n3.1 Problem Formulation\nSequential recommendation is a crucial metric in LLM-based rec-\nommender systems (RSs). We transform the traditional two-tower\nmodel, which computes similarity followed by reordering, into a\ngenerative recommendation paradigm. In this framework, each item\nx is represented by a set of tokens Y = [y1,y2,Â·Â·Â· ,yğ‘˜]âˆˆY . As\nillustrated in 3, given an input sequence X, which includes instruc-\ntions and the interaction history, the sequence of the target item Y\nis generated directly in an autoregressive manner. The probability\ncan be calculated by:\nğ‘(Y|X)=\nÃ–ğ‘˜\nğ‘–=1ğ‘(yğ‘–|X,y1,y2,..., yiâˆ’1) (1)\n3.2 Dual-source Knowledge-rich Item Indices\nSome existing LLM-based methods utilize bracket notations as\nnewly-introduced atomic tokens to represent items. However, this\nmethod can be problematic in data-rich real-world scenarios, where\nthe number of potential recommended items greatly exceeds the\nvocabulary of LLMs. This leads to tokenization redundancy, making\nit challenging for LLMs to process commands accurately. Moreover,\nthe description-based approach [2], which assigns tokens to index\nitems based on the semantics of item titles or descriptions, intro-\nduces a strong inductive bias. This can obscure the true intent of\nuser behaviors, as it does not model behavioral sequences clearly\nand unbiasedly, compromising the modelâ€™s ability to understand\nand predict user preferences effectively.\nAdditionally, existing methods often overlook the value of ex-\nogenous prior knowledge. Furthermore, our experiments show that\nWWW â€™25, April 28-May 2, 2025, Sydney, NSW, Australia Minjie Hong et al.\nCould you provide the (title/id) based on the (id/title/description) ?\nWhat's the next recommendation based on this user's history of interactions?\nPreferenceUnderstandingSequence RecommendationSemanticReconstruction\nInstructionInputsOutputs\nInferring user preferences based on the history of the given userâ€˜s behavioral sequences.\nThis user likes to travel and prefers natural landscapes such as lakes and riversâ€¦..\nDecoder-only LLM-Backbone\nâ€¦\nPromptsâ€¦,\n y'()\nSemanticProjector\nBehaviorProjectorhidden state\nContrastive loss\n Contrastive loss\nTitle: a lake\nInteraction\nSemanticEncoder\nBehaviorEncoder\nâ€¦\n,\nS1_10\nS2_91\nB1_53\nB2_23Predicted Item Tokens\nSayram Lake\nS1_10\nS2_91\nB1_53\nB2_23\nSayram Lake\nS1_10\nS2_91\nB1_53\nB2_23\nInteraction historyItem 53Item 28Item 16Item 02\nOutputs\nDescriptive information\nInteraction historyItem 53Item 28Item 16Item 02\nâ€¦\n!!*\n !)*â€¦\n !!+\n !)+â€¦\nitem sequence â€¦\nFigure 3: Overview of Non-Invasive Multiscale Alignment Reconstruction Tasks. Includes Global Contrast Decompression Task\n(GCT), Comprehensive Interaction Modeling Task (CIT). These tasks facilitate the LLM-Backboneâ€™s comprehension of complex\nexogenous signals from these densely packed, knowledge-rich tokens in a non-invasive manner, and to integrate the llmâ€™s\nreasoning capabilities for deep understanding of recommendations.\nsignificant results are achieved when effectively integrating exoge-\nnous behavioral and semantic signals, showing subtle interaction,\nunderstanding, and cooperation.\nTo address our objectives, we aim to: 1) introduce a small number\nof tokens to efficiently represent a vast set of candidates; 2) infuse\nuseful a priori knowledge into identifiers to incorporate exogenous\nsemantic and behavioral information about items into the reasoning\nprocess; and 3) design an indexing structure where semantically\nsimilar items share identifier prefixes. To achieve these goals, we\nutilize a discretized indexing algorithm that encodes dual-source\ninformation for item representation. As illustrated in 2, for any\ngiven item along with its descriptive text (title, synopsis, etc.), se-\nmantic embeddings are derived using pre-trained language models\n(e.g., T5 [27], Llama [32]). In this study, we specifically employ the\nLLM-Backbone itself for semantic extraction:\nhiddenstateğ‘¡ = ğ‘™ğ‘™ğ‘š(ğ‘¥ğ‘¡,hiddenstateğ‘¡âˆ’1), ğ‘¡ = 1,2,3,...,ğ‘›\nğ‘§ğ‘ \nğ‘– = 1\nğ‘›\nğ‘›âˆ‘ï¸\nğ‘–=1\nhiddenstateğ‘–\n(2)\nThe descriptive textğ‘¥1:ğ‘›of itemğ‘–is entered sequentially into the last\nhidden state transformed by the LLM and averaged as the semantic\nrepresentation ğ‘§ğ‘  of the item. Behavioral features ğ‘§ğ‘ are extracted\nby the encoder of a two-tower model (e.g., DIN [40]) that uses only\nID sequences as recommendations:\nğ‘§ğ‘\nğ‘– = ğµğ‘’â„ğ‘ğ‘£ğ‘–ğ‘œğ‘Ÿğ¸ğ‘›ğ‘ğ‘œğ‘‘ğ‘’ğ‘Ÿ (ğ‘–) (3)\nGiven the domain disparities between behavioral and seman-\ntic feature spaces, prior research has shown that even advanced\nencoder-side feature fusion techniques (e.g., Q-former [19]) often\nresult in significant compression losses and fail to effectively inte-\ngrate dual-source features. This places supernumerary strain on\nthe decoding process. Consequently, we opt to separately and dis-\ncretely process the exogenous semantic and behavioral signals.\nWhile vector quantization is commonly used for discretization, it\nproves unstable for training, leading to issues like item ID conflicts.\nTo facilitate reproducibility in our study, we employ hierarchical\nK-Means to discretize the semantic embedding ğ‘ğ‘  and behavioral\nembedding ğ‘ğ‘ , where each cluster is progressively subdivided into\nEAGER-LLM: Enhancing LLMs as Recommenders through Exogenous Behavior-Semantic Integration WWW â€™25, April 28-May 2, 2025, Sydney, NSW, Australia\nğ‘˜ child clusters until each cluster contains only a single item. The\nembeddings for each item are discretized into ğ¶ğ‘  and ğ¶ğ‘. Specifi-\ncally, the j-th ID of the i-th item is denoted as ğ‘ğ‘¡\nğ‘–ğ‘— , where t includes\ns for semantic, b for behavioral, and u for the unitive. Theoretically,\nwith each item represented by four tokens and each token capa-\nble of 256 distinct values, this method can uniquely characterize\nup to 2564 = 4294967296 items. This capacity is more than ade-\nquate for real-world applications, ensuring efficiency in vocabulary\nexpansion and the subsequent encoding and decoding processes.\n3.3 Non-Invasive Multiscale Alignment\nReconstruction Tasks\nAfter incorporating additional tokens to represent items, we achieve\na high compression ratio (â‰ˆ2,000,000:1), which significantly con-\ndenses massive exogenous signals into a very small number of\ntokens. This extreme compression ratio presents a challenge for the\nmodel to independently learn substantial, useful knowledge. Draw-\ning inspiration from [36, 39], we have devised a series of multi-scale\nalignment reconstruction tasks.\n3.3.1 Global Contrast Decompression Task. A method that\nnon-intrusively enhances the modelâ€™s ability to quickly and easily\ninterpret knowledge-rich indices at extreme compression rates. This\nis achieved by incorporating additional summarization token and\ntrainable Decompression Guidance Projectors.\nseq = {ğ‘‹Prompts,ğ‘‹ğ‘¢\n1 ,......,ğ‘‹ ğ‘¢\nğ‘›,ğ‘¦ğ‘ \n1,......,ğ‘¦ ğ‘\nğ‘˜,ğ‘¦[ğ¶ğ‘‚ğ‘]} (4)\nWhere ğ‘‹Prompts denotes the sequence of text prompts{ğ‘¥P\n1 ,...,ğ‘¥ Pğ‘š}\nand ğ‘‹ğ‘¢\nğ‘– represents the indexed tokens for the i-th item, reflecting\nthe userâ€™s chronological behavior sequence. As outlined in 3.2, ğ‘¦ğ‘¡\nğ‘—\ndenotes the j-th level of the predicted item tokens, where ğ‘¡ = ğ‘cor-\nresponds to the itemâ€™s behavioral token, and ğ‘¡ = ğ‘  to the semantic\ntoken. The summary token ğ‘¦[ğ¶ğ‘‚ğ‘]is strategically placed at the\nend to encapsulate the global knowledge of the preceding sequence.\nTo efficiently transmit exogenous dual-source signals into the\npreordered tokens through gradient updating, we introduce non-\nintrusive Decompression Guidance Projectors ğ‘“ğ‘¡ . This projector\ntransforms the global hidden state distilled byğ‘¦[ğ¶ğ‘‚ğ‘]into semanti-\ncally and behaviorally-guided latent states. Additionally, we employ\na contrastive learning paradigm that utilizes original exogenous\nsemantic embbeddings ğ‘ğ‘  and behavioral embbeddings ğ‘ğ‘ to ac-\ncelerate and assist the decompression process of hyper-compressed\nTokens.\nhiddenstateğ‘¡ = Ë†ğ‘™ğ‘™ğ‘š(ğ‘¥ğ‘¡,hiddenstateğ‘¡âˆ’1), ğ‘¡ = 1,2,3,...,ğ‘›\nLğ‘¡\ncon = F(ğ‘“ğ‘¡(hiddenstate[CON]),Zğ‘¡), ğ‘¡ âˆˆ{ğ‘,ğ‘ }\n(5)\nThe total contrastive loss Lcon , is calculated by proportionally\nsumming Lğ‘¡con and Lğ‘con . The function F(Â·,Â·)serves as the metric\nfor contrastive learning. Importantly, the Decompression Guidance\nProjectors ğ‘“ğ‘¡ are utilized only during training, not in inference.\n3.3.2 Comprehensive Interaction Modeling Task. To effec-\ntively harness the inference capabilities, pre-training knowledge,\nand trainable parameters of the LLM-Backbone for fitting recom-\nmendation data, we have restructured the traditional sequence\nrecommendation task and its auxiliary tasks into a Next Token\nDecoder-only LLM-Backbone\nSequence RecommendationSemanticReconstruction\nPreferenceReconfiguration\nDecoder-only LLM-Backbone\n+\n UpXAdapter\nTrainingInference\nDownSequence RecommendationSemanticReconstruction\nPreferenceReconfiguration\nFigure 4: The illustration of multi-stage training & inference\nprocess.\nPrediction task, which LLMs are good at. Unlike using additional\nselectors as suggested by [ 43], we contend that this could alter\nthe modelâ€™s output form and output domain distribution, poten-\ntially compromising the original capabilities of the LLM-Backbone\nand diminishing the frameworkâ€™s generalizability across different\nbackbones.\nAs illustrated in 3, Comprehensive Interaction Modeling is seg-\nmented into three subtasks: Sequence Recommendation Task, Se-\nmantic Reconstruction Task and Preference Understanding Task.\nThese tasks effectively leverage the modelâ€™s own parameters to\nintegrate exogenous signals, recommendation data knowledge, and\nthe modelâ€™s intrinsic reasoning capabilities organically.\n3.4 Initial training, Annealing Adapter Tuning\nand Inference\n3.4.1 Initial training. In the initialization phase of enhancing\nthe modelâ€™s recommendation capabilities, we devised various con-\nditional language modeling objectives. This strategy encourages\nhighly divergent models, compared to pre-recommendation pre-\ntrain tasks, to cultivate in-depth generalization, understanding, and\nreasoning abilities pertinent for recommendation tasks.\nThe initial training can be formulated as follows:\nmax\nÎ¦\nâˆ‘ï¸\n(ğ‘¥,ğ‘¦)âˆˆZ\n|ğ‘¦|âˆ‘ï¸\nğ‘¡=1\nlog \u0000ğ‘ƒÎ¦+ğœ‘ğ‘Ÿ (ğ‘¦ğ‘¡ |ğ‘¥,ğ‘¦<ğ‘¡)\u0001 (6)\nğ‘¥ represents the \"Instruction Input\".ğ‘¦denotes the \"Instruction\nOutput\" within the initial training data.ğ‘¦ğ‘¡ stands for the ğ‘¡-th token\nof ğ‘¦. Î¦ corresponds to the original parameters of the LLM-Backbone.\nğœ‘ğ‘Ÿ represents the additional parameters in Sequence Recommenda-\ntion Task (SRT), and Zrefers to the training set. We combine the\ngeneration and exogenous Semantic, Behavioral Reconstruction\nLoss to train our model, given by:\nL= Lğ‘”ğ‘’ğ‘› +ğ¼SRT (ğœ†1Lğ‘ \nğ‘ğ‘œğ‘› +ğœ†2Lğ‘\nğ‘ğ‘œğ‘›) (7)\nWhere ğ¼SRT is an indicator function that is 1 if the task is SRT\nand 0 otherwise. ğœ†1 and ğœ†2 are loss coefficients.\n3.4.2 Annealing Adapter Tuning. we observed that annealing\nwith restricted quantities of high-grade sequence recommendation\ndata considerable improves the performance of the LLM-Backbone\non pivotal benchmarks subsequent to the initial training of recom-\nmendation capabilities.\nAchieving the optimal solution for enhancing sequence recom-\nmendation performance remains a formidable challenge without\nWWW â€™25, April 28-May 2, 2025, Sydney, NSW, Australia Minjie Hong et al.\nTable 1: Statistics of the Datasets.\nDataset #Users #Items #Interactions #Sparsity\nBeauty 22,363 12,101 198,360 0.00073\nSports and Outdoors 35,598 18,357 296,175 0.00045\nInstruments 24,733 9,923 206,153 0.00083\nadjusting the data volume ratio across various tasks. Integrating\ntasks such as sequence recommendation, preference understand-\ning, and semantic reconstruction, while neglecting to bridge the\ngap between natural language processing and sequential behavior,\ncomplicates the optimization of sequence recommendation perfor-\nmance without modifying the proportion of data volume allocated\nto different tasks.\nConversely, training on a limited set of high-grade sequence rec-\nommendation tasks during the Annealing Training phase can also\nimpair the modelâ€™s original capabilities due to the significant dis-\nparity between the language semantics modeled by LLMs and the\ncollaborative semantics implicit in recommender systems. There-\nfore, the use of an Adapter to introduce additional parameters in\nthis phase, as shown in 4, constitutes an efficient and pragmatic\napproach to mitigate the adverse effects associated with Annealing\nTraining.\nFormally,\nmaxğœ‘ğ‘\nâˆ‘ï¸\n(ğ‘¥,ğ‘¦)âˆˆZ\n|ğ‘¦|âˆ‘ï¸\nğ‘¡=1\nlog \u0000ğ‘ƒÎ¦+ğœ‘ğ‘Ÿ +ğœ‘ğ‘ (ğ‘¦ğ‘¡ |ğ‘¥,ğ‘¦<ğ‘¡)\u0001 (8)\nwhere ğœ‘ğ‘ denotes the parameters of Annealing Adapter.\n3.4.3 Inference. It is noteworthy that the additional parameter\nğœ™ , brought forth by the SRT, is disregarded during the inference\nstage. Moreover, employing the Annealing Adapter dynamically to\nmeet varying task demands acts as a potent strategy for achieving\na flexible balance between the modelâ€™s textual reasoning abilities\nand recommendation accuracy.\n4 EMPIRICAL STUDY\nWe analyze the proposed EAGER-LLM method on three datasets and\ndemonstrate its effectiveness by answering the following research\nquestions:\nâ€¢RQ1: How does EAGER-LLM compare to state-of-the-art sequen-\ntial recommendation methods in different datasets?\nâ€¢RQ2: How do the components of EAGER-LLM (e.g., DKI, GCT,\nAAT) and hyper-parameter adjustments affect its performance?\n4.1 Experimental Setting\n4.1.1 Dataset. We conducted experiments using three real-world\npublic datasets of Amazon product reviews [9, 26], which are among\nthe most widely utilized benchmarks for sequence recommenda-\ntion. Specifically, the experiments focused on three subcategories:\nâ€œBeautyâ€, â€œSports and Outdoorsâ€ and â€œMusical Instrumentsâ€. In line\nwith previous studies [ 12, 29, 37], we utilized the 5-core dataset\napproach, which excludes unpopular items and inactive users with\nfewer than five interaction records. The statistics for these datasets\nare presented in 1.\n4.1.2 Evaluation Metrics. We utilize two widely recognized cri-\nteria for the matching phase: Recall and Normalized Discounted\nCumulative Gain (NDCG). We present metrics calculated for the top\n5/10 recommended candidates. In line with the standard evaluation\nprotocol [17], we adopt the leave-one-out method for assessments.\nDuring training phases, we restrict the userâ€™s historical item count\nto 20. Additionally, for generative methods employing beam search,\nwe consistently set the beam size to 20.\n4.1.3 Implementation Details. We utilize Llama-7b [32] as LLM-\nBackbone. In constructing the item indexes, LLM-Backbone itself\nand DIN [40] as encoders. For training, our approach mirrors that\nof LC-Rec for ease of comparison, employing the AdamW optimizer\nwith a learning rate set to 5e-5 and weight decay at 0.01. We im-\nplement data parallelism and gradient accumulation to achieve an\noverall batch size of 128. For GCT, we adopt InfoNCE to serve as\nthe loss metric.\n4.2 Performance Comparison (RQ1)\n4.2.1 Baselines. We compare the following four categories of\nmethods:\n(1) Traditional seqiential methods\nâ€¢GRU4REC [11]: An RNN-based sequential recommendation\nmodel that utilizes GRU model to encode the item sequence.\nâ€¢Caser [31]: a CNN-based approach that utilizes horizontal and\nvertical CNN layers to model the patterns in user behavior.\nâ€¢HGN [25]: employs hierarchical gating networks to effectively\ndiscern long-term and short-term user preferences.\n(2) For transformer-based methods , we have:\nâ€¢S^3-Rec [41]: enhances recommendation by pre-training bidi-\nrectional Transformer to maximize mutual information.\nâ€¢BERT4Rec [30]: Utilizes a bidirectional Transformer to over-\ncome the constraints of unidirectional models.\nâ€¢FDSA [37]: models feature sequence transition patterns using a\nself-attention module.\n(3) For generative methods , we have:\nâ€¢TIGER [28]: employs T5 to generate IDs for items and uses an\nautoregressive decoding process to identify target candidates.\nâ€¢P5-CID [14]: leverages collaborative signals to construct ID iden-\ntifiers for T5-based generative recommender model.\n(4) For LLM-Based methods , we have:\nâ€¢LC-Rec [39]: LC-Rec designs a vector quantization method to\ngenerate semantic IDs and use Llama as backbone to autoregres-\nsively decodes the identifiers of the target candidates items.\nâ€¢LETTER [35]: Integrates collaborative signals into LLM-Backbone\nthrough a series of regularizations.\n4.2.2 Overall Performance. We provide a detailed report in 2 on\nthe sequence recommendation performance of our method across\nthree datasets, comparing it against various baseline models. The\nresults lead to several key observations :\nTraditional baselines employ a simple inner-product match-\ning approach, which segments the process and limits its ability to\neffectively model complex user interaction histories and intentions.\nMoreover, this approachâ€™s computational complexity grows expo-\nnentially with the candidate set, also restricting the representational\nEAGER-LLM: Enhancing LLMs as Recommenders through Exogenous Behavior-Semantic Integration WWW â€™25, April 28-May 2, 2025, Sydney, NSW, Australia\nTable 2: Performance comparison of different methods. The best performance is highlighted in bold while the second best\nperformance is underlined. The last column indicates the improvements over the best baseline models and all the results\nof EAGER-LLM are statistically significant with p < 0.05 compared to the best baseline models. We used the official LC-Rec\ncheckpoints to rerun the inference with the conflicts removed in Instruments.\nDataset Metric Traditional Transformer-based Generative LLM-based Improv.\nGRU4REC Caser HGN Bert4Rec S^3-Rec FDSA P5-CID TIGER LC-Rec Ours\nBeauty\nRecall@5 0.0164 0.0205 0.0325 0.0203 0.0387 0.0267 0.0400 0.0454 0.0482 0.0548 13.69%\nRecall@10 0.0283 0.0347 0.0512 0.0347 0.0647 0.0407 0.0590 0.0648 0.0681 0.0830 21.88%\nNDCG@5 0.0099 0.0131 0.0206 0.0124 0.0244 0.0163 0.0274 0.0321 0.0327 0.0369 12.84%\nNDCG@10 0.0137 0.0176 0.0266 0.0170 0.0327 0.0208 0.0335 0.0384 0.0409 0.0459 12.22%\nSports\nRecall@5 0.0129 0.0116 0.0189 0.0115 0.0251 0.0182 0.0313 0.0264 0.0304 0.0373 19.17%\nRecall@10 0.0204 0.0194 0.0313 0.0191 0.0385 0.0288 0.0431 0.0400 0.0451 0.0569 26.16%\nNDCG@5 0.0086 0.0072 0.0120 0.0075 0.0161 0.0122 0.0224 0.0181 0.0196 0.0251 12.05%\nNDCG@10 0.0110 0.0097 0.0159 0.0099 0.0204 0.0156 0.0262 0.0225 0.0246 0.0315 20.23%\nInstruments\nRecall@5 0.0821 0.0543 0.0813 0.0671 0.0863 0.0834 0.0827 0.0863 0.0964 0.0991 2.80%\nRecall@10 0.1031 0.0710 0.1048 0.0822 0.1136 0.1046 0.1016 0.1064 0.1177 0.1224 3.99%\nNDCG@5 0.0698 0.0355 0.0668 0.0560 0.0626 0.0681 0.0708 0.0738 0.0819 0.0851 3.91%\nNDCG@10 0.0765 0.0409 0.0744 0.0608 0.0714 0.0750 0.0768 0.0803 0.0890 0.0926 4.04%\nTable 3: Performance comparison of LETTER and our\nmethod. For fair comparison, llm-bacbone is uniformly\nLlama2-7b. All the results of EAGER-LLM are statistically\nsignificant with p < 0.05.\nModel Instruments\nR@5 R@10 N@5 N@10\nTIGER 0.0870 0.1058 0.0737 0.0797\nLETTER-TIGER 0.0909 0.1122 0.0763 0.0831\nLC-Rec 0.0824 0.1006 0.0712 0.0712\nLETTER-LC-Rec 0.0913 0.1115 0.0789 0.0854\nEAGER-LLM (Llama2-7B) 0.0994 0.1206 0.0854 0.0922\nImprov. 8.95% 7.48% 8.26% 8.02%\nspace size. In contrast, EAGER-LLM aligns with the generative rec-\nommendation paradigm. It not only leverages pre-training knowl-\nedge to enhance recommendation-relevant capabilities, but it also\nreduces computational costs by directly generating the target item\nID through beam search. This approach expands the limitations of\nlatent space size in item representation, allowing it to incorporate\nsignificantly more exogenous information.\nGenerative recommendation, llm-based approaches (TIGER,\nLC-REC etc.) neglected the importance of exogenous behavioral\nsignals for sequence recommendation. While the transformer ar-\nchitecture with generation loss works well in various domains, it\nis not designed for the task of sequence recommendation. These\nnon-native approaches ignore the rank-order relationship of the\ncandidates in the recommendation task, which leads to poor model\nperformance on ranking-related metrics such as ndcg. Therefore,\nwe believe that introducing additional behavioral signals is the key\nto improving the overall performance of model recommendation\nwithout changing the model architecture and training process.\nThere are also some approaches that attempt to incorporate\nexogenous behavioral signals into the recommendations (P5-\nCID, LETTER). LETTER, for instance, integrates collaborative sig-\nnals into discrete coding through a series of regularizations. How-\never LETTER does not have open source code and is only imple-\nmented as Llama2-7b [33], we evaluated our EAGER-LLM using the\nLlama2-7b on the Instruments dataset, as detailed in 3. Our method\noutperforms LETTER by over 8% across all metrics. We contend that\neven sophisticated encoder-side feature fusion methods can intro-\nduce additional compression loss, hindering the efficient integration\nof multi-source features. Therefore, allowing the LLM-Backbone\nitself to handle the fusion of information without introducing extra\ngeneralization bias at the input emerges as a simpler and more\neffective strategy.\n4.3 Ablation Study (RQ2)\nIn the ablation experiments, the Sequence Recommendation Predic-\ntion Task was used as the core metric to evaluate the performance\nimpact of each component. The main components of EAGER-LLM\ninclude Dual-source Knowledge-rich Item Indices (DKI), Global\nContrast Decompression Task (GCT), and Annealing Adapter Tun-\ning (AAT). The results are reported in 4, we can observe that:\nâ€¢Removing EAGER-LLM of the DKI, GCT, ATT (random index)\nachieves the worst results in different datasets, but still outper-\nforms the vast majority of traditional baselines. This underscores\nthe inherent superiority and robustness of our foundational\nframework in addressing the sequence recommendation task,\nand highlights significant potential for further development and\nenhancement in future work.\nWWW â€™25, April 28-May 2, 2025, Sydney, NSW, Australia Minjie Hong et al.\nTable 4: Ablation studies by selectively discarding the Dual-source Knowledge-rich Item Indices (DKI), Global Contrastive Task\n(GCT), and Annealing Adapter Tuning (AAT).\nVariants Beauty Musical Instruments\nDKI GCT AAT R@1 R@5 R@10 NDCG@5 NDCG@10 R@1 R@5 R@10 NDCG@5 NDCG@10\n0.0135 0.0453 0.0650 0.0295 0.0358 0.0631 0.0883 0.1071 0.0757 0.0817\nâœ“ 0.0152 0.0499 0.0760 0.0329 0.0413 0.0696 0.0978 0.1199 0.0802 0.0886\nâœ“ âœ“ 0.0175 0.0513 0.0781 0.0346 0.0432 0.0694 0.0981 0.1215 0.0839 0.0914\nâœ“ âœ“ âœ“ 0.0176 0.0544 0.0817 0.0363 0.0451 0.0707 0.0991 0.1225 0.0852 0.0927\n0.020.0250.030.0350.040.0450.050.055 Beauty\n0.070.0750.080.0850.090.0950.1\nNDCG@5Recall@5\nInstruments\nRandomSemanticBehaviorUnitLLM-BS\nFigure 5: The performance of our architecture (w/o GCT,\nAAT), under indexing with different exogenous signal com-\npositions.\nâ€¢Removing DKI significantly impacts sequence recommendation\nperformance, illustrating the base modelâ€™s effectiveness in en-\nhancing recommendations by integrating exogenous behavioral\nand semantic information. This also showcases DKIâ€™s capability\nto encapsulate vast information within a few tokens at a high\ncompression ratio.\nâ€¢GCT significantly enhances the NDCG metrics compared to Re-\ncall, indicating its efficacy in decoding exogenous behavioral\nsignals compressed by DKI. GCT effectively incorporates exter-\nnal knowledge that optimizes the modelâ€™s ability to sequence\nrecommendations. This underscores our architectureâ€™s adapt-\nability in harnessing distinct properties from various exogenous\ninformation sources.\n4.4 Further Analysis (RQ2)\nAs depicted in 5, we conducted performance experiments on the\nBeauty and Instruments datasets using various exogenous signal\nindexing methods: (1) Random, where each level of indices is ran-\ndomly selected from candidates; (2) Semantic, utilizing indices\nderived solely from textual semantic signals; (3) Behavior, using\nindices generated solely from behavioral signals; and (4) Unit, com-\nbining indices from both Semantic and Behavior. The Unit index\n0.0350.0370.0390.0410.0430.0450.0470.0490.0510.053\n0 2 4 6 8 10 12 14 16 18\nBeauty\nRecall@5NDCG@5\nFigure 6: Analysis of the performance impact of Items Indices\nschemes of different lengths.\nsignificantly exceeds the sum of the individual contributions from\nthe two sources, yielding much higher results.\nTo our shock , in the Beauty dataset, the Semantic index per-\nforms worse than the Random index, likely due to a high compres-\nsion ratio that complicates the modelâ€™s ability to decode separate\nexogenous signals, especially after removing GCT and AAT. This\noften results in a diminished or even negative impact on recommen-\ndation performance. More intriguingly, the integration of exoge-\nnous Behavioral signals enables effective interaction between the\ndual information streams, enhancing their mutual comprehension\nand decoding. This synergy not only mitigates the negative impacts\nbut also transforms them into substantial positive outcomes.\nIn 6, we demonstrate the impact of varying lengths of the Item\nIndices scheme on performance within the Beauty dataset. Four\nlayers provide sufficient information for learning, while additional\nlayers do not hinder ID generation but increase inference time.\n5 CONCLUSION\nIn this paper, we introduce EAGER-LLM, a novel decoder-only,\nLLM-based generative recommendation framework that seamlessly\nintegrates both endogenous and exogenous behavioral and semantic\ninformation non-intrusively. Extensive experiments validate the\neffectiveness and robustness of EAGER-LLM, showcasing superior\nperformance compared to existing state-of-the-art methods.\nAcknowledgments\nThis work was partially supported by the National Natural Science\nFoundation of China under Grant No. U24A20326. We also thank\nMindSpore1 for the partial support of this work, which is a new\ndeep learning computing framework.\n1https://www.mindspore.cn\nEAGER-LLM: Enhancing LLMs as Recommenders through Exogenous Behavior-Semantic Integration WWW â€™25, April 28-May 2, 2025, Sydney, NSW, Australia\nReferences\n[1] Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana\nHasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, et al.\n2022. Flamingo: a visual language model for few-shot learning. Advances in\nneural information processing systems 35 (2022), 23716â€“23736.\n[2] Keqin Bao, Jizhi Zhang, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan\nHe. 2023. Tallrec: An effective and efficient tuning framework to align large\nlanguage model with recommendation. InProceedings of the 17th ACM Conference\non Recommender Systems . 1007â€“1014.\n[3] Zhe Chen, Jiannan Wu, Wenhai Wang, Weijie Su, Guo Chen, Sen Xing, Muyan\nZhong, Qinglong Zhang, Xizhou Zhu, Lewei Lu, et al . 2024. Internvl: Scaling\nup vision foundation models and aligning for generic visual-linguistic tasks. In\nProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition .\n24185â€“24198.\n[4] Yunfei Chu, Jin Xu, Xiaohuan Zhou, Qian Yang, Shiliang Zhang, Zhijie Yan,\nChang Zhou, and Jingren Zhou. 2023. Qwen-audio: Advancing universal audio\nunderstanding via unified large-scale audio-language models. arXiv preprint\narXiv:2311.07919 (2023).\n[5] Zeyu Cui, Jianxin Ma, Chang Zhou, Jingren Zhou, and Hongxia Yang. 2022.\nM6-rec: Generative pretrained language models are open-ended recommender\nsystems. arXiv preprint arXiv:2205.08084 (2022).\n[6] Yunfan Gao, Tao Sheng, Youlin Xiang, Yun Xiong, Haofen Wang, and Jiawei\nZhang. 2023. Chat-rec: Towards interactive and explainable llms-augmented\nrecommender system. arXiv preprint arXiv:2303.14524 (2023).\n[7] Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. 2022.\nRecommendation as language processing (rlp): A unified pretrain, personalized\nprompt & predict paradigm (p5). In Proceedings of the 16th ACM Conference on\nRecommender Systems . 299â€“315.\n[8] Ruiqi Guo, Philip Sun, Erik Lindgren, Quan Geng, David Simcha, Felix Chern, and\nSanjiv Kumar. 2020. Accelerating large-scale inference with anisotropic vector\nquantization. In International Conference on Machine Learning . PMLR, 3887â€“3896.\n[9] Ruining He and Julian McAuley. 2016. Ups and downs: Modeling the visual\nevolution of fashion trends with one-class collaborative filtering. In proceedings\nof the 25th international conference on world wide web . 507â€“517.\n[10] Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng\nWang. 2020. Lightgcn: Simplifying and powering graph convolution network for\nrecommendation. In Proceedings of the 43rd International ACM SIGIR conference\non research and development in Information Retrieval . 639â€“648.\n[11] B Hidasi. 2015. Session-based Recommendations with Recurrent Neural Networks.\narXiv preprint arXiv:1511.06939 (2015).\n[12] Yupeng Hou, Shanlei Mu, Wayne Xin Zhao, Yaliang Li, Bolin Ding, and Ji-Rong\nWen. 2022. Towards universal sequence representation learning for recommender\nsystems. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Dis-\ncovery and Data Mining . 585â€“593.\n[13] Yupeng Hou, Junjie Zhang, Zihan Lin, Hongyu Lu, Ruobing Xie, Julian McAuley,\nand Wayne Xin Zhao. 2024. Large language models are zero-shot rankers for\nrecommender systems. In European Conference on Information Retrieval . Springer,\n364â€“381.\n[14] Wenyue Hua, Shuyuan Xu, Yingqiang Ge, and Yongfeng Zhang. 2023. How to\nindex item ids for recommendation foundation models. In Proceedings of the\nAnnual International ACM SIGIR Conference on Research and Development in\nInformation Retrieval in the Asia Pacific Region . 195â€“204.\n[15] Shengpeng Ji, Ziyue Jiang, Xize Cheng, Yifu Chen, Minghui Fang, Jialong Zuo,\nQian Yang, Ruiqi Li, Ziang Zhang, Xiaoda Yang, et al. 2024. WavTokenizer: an\nEfficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling.arXiv\npreprint arXiv:2408.16532 (2024).\n[16] Jeff Johnson, Matthijs Douze, and HervÃ© JÃ©gou. 2019. Billion-scale similarity\nsearch with GPUs. IEEE Transactions on Big Data 7, 3 (2019), 535â€“547.\n[17] Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recom-\nmendation. In 2018 IEEE international conference on data mining (ICDM) . IEEE,\n197â€“206.\n[18] Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix factorization tech-\nniques for recommender systems. Computer 42, 8 (2009), 30â€“37.\n[19] Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. 2023. Blip-2: Bootstrapping\nlanguage-image pre-training with frozen image encoders and large language\nmodels. In International conference on machine learning . PMLR, 19730â€“19742.\n[20] Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, and Jun Ma. 2017.\nNeural attentive session-based recommendation. In Proceedings of the 2017 ACM\non Conference on Information and Knowledge Management . 1419â€“1428.\n[21] Lei Li, Yongfeng Zhang, and Li Chen. 2023. Personalized prompt learning for\nexplainable recommendation. ACM Transactions on Information Systems 41, 4\n(2023), 1â€“26.\n[22] Jianghao Lin, Xinyi Dai, Yunjia Xi, Weiwen Liu, Bo Chen, Hao Zhang, Yong\nLiu, Chuhan Wu, Xiangyang Li, Chenxu Zhu, et al . 2023. How can recom-\nmender systems benefit from large language models: A survey. arXiv preprint\narXiv:2306.05817 (2023).\n[23] Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. 2024. Visual instruc-\ntion tuning. Advances in neural information processing systems 36 (2024).\n[24] Qijiong Liu, Jieming Zhu, Lu Fan, Zhou Zhao, and Xiao-Ming Wu. 2024. STORE:\nStreamlining Semantic Tokenization and Generative Recommendation with A\nSingle LLM. arXiv preprint arXiv:2409.07276 (2024).\n[25] Chen Ma, Peng Kang, and Xue Liu. 2019. Hierarchical gating networks for\nsequential recommendation. InProceedings of the 25th ACM SIGKDD international\nconference on knowledge discovery & data mining . 825â€“833.\n[26] Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel.\n2015. Image-based recommendations on styles and substitutes. In Proceedings\nof the 38th international ACM SIGIR conference on research and development in\ninformation retrieval. 43â€“52.\n[27] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang,\nMichael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits\nof transfer learning with a unified text-to-text transformer. Journal of machine\nlearning research 21, 140 (2020), 1â€“67.\n[28] Shashank Rajput, Nikhil Mehta, Anima Singh, Raghunandan Hulikal Keshavan,\nTrung Vu, Lukasz Heldt, Lichan Hong, Yi Tay, Vinh Tran, Jonah Samost, et al.\n2024. Recommender systems with generative retrieval. Advances in Neural\nInformation Processing Systems 36 (2024).\n[29] Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factor-\nizing personalized markov chains for next-basket recommendation. InProceedings\nof the 19th international conference on World wide web . 811â€“820.\n[30] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang.\n2019. BERT4Rec: Sequential recommendation with bidirectional encoder rep-\nresentations from transformer. In Proceedings of the 28th ACM international\nconference on information and knowledge management . 1441â€“1450.\n[31] Jiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommenda-\ntion via convolutional sequence embedding. In Proceedings of the eleventh ACM\ninternational conference on web search and data mining . 565â€“573.\n[32] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne\nLachaux, TimothÃ©e Lacroix, Baptiste RoziÃ¨re, Naman Goyal, Eric Hambro, Faisal\nAzhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv\npreprint arXiv:2302.13971 (2023).\n[33] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yas-\nmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhos-\nale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv\npreprint arXiv:2307.09288 (2023).\n[34] Jinpeng Wang, Jieming Zhu, and Xiuqiang He. 2021. Cross-batch negative sam-\npling for training two-tower recommenders. In Proceedings of the 44th interna-\ntional ACM SIGIR conference on research and development in information retrieval .\n1632â€“1636.\n[35] Wenjie Wang, Honghui Bao, Xinyu Lin, Jizhi Zhang, Yongqi Li, Fuli Feng, See-\nKiong Ng, and Tat-Seng Chua. 2024. Learnable Tokenizer for LLM-based Genera-\ntive Recommendation. arXiv preprint arXiv:2405.07314 (2024).\n[36] Ye Wang, Jiahao Xun, Minjie Hong, Jieming Zhu, Tao Jin, Wang Lin, Haoyuan\nLi, Linjun Li, Yan Xia, Zhou Zhao, et al. 2024. EAGER: Two-Stream Generative\nRecommender with Behavior-Semantic Collaboration. In Proceedings of the 30th\nACM SIGKDD Conference on Knowledge Discovery and Data Mining . 3245â€“3254.\n[37] Tingting Zhang, Pengpeng Zhao, Yanchi Liu, Victor S Sheng, Jiajie Xu, Deqing\nWang, Guanfeng Liu, Xiaofang Zhou, et al . 2019. Feature-level deeper self-\nattention network for sequential recommendation.. In IJCAI. 4320â€“4326.\n[38] Yang Zhang, Fuli Feng, Jizhi Zhang, Keqin Bao, Qifan Wang, and Xiangnan He.\n2023. Collm: Integrating collaborative embeddings into large language models\nfor recommendation. arXiv preprint arXiv:2310.19488 (2023).\n[39] Bowen Zheng, Yupeng Hou, Hongyu Lu, Yu Chen, Wayne Xin Zhao, Ming\nChen, and Ji-Rong Wen. 2024. Adapting large language models by integrating\ncollaborative semantics for recommendation. In 2024 IEEE 40th International\nConference on Data Engineering (ICDE) . IEEE, 1435â€“1448.\n[40] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui\nYan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through\nrate prediction. In Proceedings of the 24th ACM SIGKDD international conference\non knowledge discovery & data mining . 1059â€“1068.\n[41] Kun Zhou, Hui Wang, Wayne Xin Zhao, Yutao Zhu, Sirui Wang, Fuzheng Zhang,\nZhongyuan Wang, and Ji-Rong Wen. 2020. S3-rec: Self-supervised learning for se-\nquential recommendation with mutual information maximization. In Proceedings\nof the 29th ACM international conference on information & knowledge management .\n1893â€“1902.\n[42] Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. 2023.\nMinigpt-4: Enhancing vision-language understanding with advanced large lan-\nguage models. arXiv preprint arXiv:2304.10592 (2023).\n[43] Yaochen Zhu, Liang Wu, Qi Guo, Liangjie Hong, and Jundong Li. 2024. Collab-\norative large language model for recommender systems. In Proceedings of the\nACM on Web Conference 2024 . 3162â€“3172.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7907909154891968
    },
    {
      "name": "Recommender system",
      "score": 0.5529482960700989
    },
    {
      "name": "Semantics (computer science)",
      "score": 0.5346471667289734
    },
    {
      "name": "Search engine indexing",
      "score": 0.506102979183197
    },
    {
      "name": "RSS",
      "score": 0.49661093950271606
    },
    {
      "name": "Comprehension",
      "score": 0.4600737690925598
    },
    {
      "name": "Semantic integration",
      "score": 0.42789506912231445
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4085369110107422
    },
    {
      "name": "Natural language processing",
      "score": 0.40080776810646057
    },
    {
      "name": "Information retrieval",
      "score": 0.3606418967247009
    },
    {
      "name": "World Wide Web",
      "score": 0.35851800441741943
    },
    {
      "name": "Semantic Web Stack",
      "score": 0.31297361850738525
    },
    {
      "name": "Semantic Web",
      "score": 0.2863999605178833
    },
    {
      "name": "Programming language",
      "score": 0.2199370563030243
    }
  ]
}