{
  "title": "Leveraging large language models for data analysis automation",
  "url": "https://openalex.org/W4407832526",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A4294606857",
      "name": "Jacqueline A. Jansen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2246232546",
      "name": "Artur Manukyan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5093472178",
      "name": "Nour Al Khoury",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2305467968",
      "name": "Altuna Akalin",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2804158849",
    "https://openalex.org/W2891675942",
    "https://openalex.org/W4283775237",
    "https://openalex.org/W4387129749",
    "https://openalex.org/W4324325724",
    "https://openalex.org/W4387844929",
    "https://openalex.org/W4388155974",
    "https://openalex.org/W3088520040",
    "https://openalex.org/W6855942653",
    "https://openalex.org/W4403791334",
    "https://openalex.org/W6600424091",
    "https://openalex.org/W4321649710",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W4400680519",
    "https://openalex.org/W4389520295",
    "https://openalex.org/W6850575969",
    "https://openalex.org/W4399584509",
    "https://openalex.org/W2923014074",
    "https://openalex.org/W4367672983",
    "https://openalex.org/W4398203645",
    "https://openalex.org/W4360591931",
    "https://openalex.org/W4386554740"
  ],
  "abstract": "Data analysis is constrained by a shortage of skilled experts, particularly in biology, where detailed data analysis and subsequent interpretation is vital for understanding complex biological processes and developing new treatments and diagnostics. One possible solution to this shortage in experts would be making use of Large Language Models (LLMs) for generating data analysis pipelines. However, although LLMs have shown great potential when used for code generation tasks, questions regarding the accuracy of LLMs when prompted with domain expert questions such as omics related data analysis questions, remain unanswered. To address this, we developed mergen , an R package that leverages LLMs for data analysis code generation and execution. We evaluated the performance of this data analysis system using various data analysis tasks for genomics. Our primary goal is to enable researchers to conduct data analysis by simply describing their objectives and the desired analyses for specific datasets through clear text. Our approach improves code generation via specialized prompt engineering and error feedback mechanisms. In addition, our system can execute the data analysis workflows prescribed by the LLM providing the results of the data analysis workflow for human review. Our evaluation of this system reveals that while LLMs effectively generate code for some data analysis tasks, challenges remain in executable code generation, especially for complex data analysis tasks. The best performance was seen with the self-correction mechanism, in which self-correct was able to increase the percentage of executable code when compared to the simple strategy by 22.5% for tasks of complexity 2. For tasks for complexity 3, 4 and 5, this increase was 52.5%, 27.5% and 15% respectively. Using a chi-squared test, it was shown that significant differences could be found using the different prompting strategies. Our study contributes to a better understanding of LLM capabilities and limitations, providing software infrastructure and practical insights for their effective integration into data analysis workflows.",
  "full_text": null,
  "topic": "Executable",
  "concepts": [
    {
      "name": "Executable",
      "score": 0.8732298612594604
    },
    {
      "name": "Computer science",
      "score": 0.7239493727684021
    },
    {
      "name": "Workflow",
      "score": 0.6666669845581055
    },
    {
      "name": "Data science",
      "score": 0.5594221353530884
    },
    {
      "name": "Code (set theory)",
      "score": 0.4237947463989258
    },
    {
      "name": "Programming language",
      "score": 0.2424868643283844
    },
    {
      "name": "Database",
      "score": 0.14212757349014282
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.0
    }
  ]
}