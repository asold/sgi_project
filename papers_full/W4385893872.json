{
    "title": "ScoNe: Benchmarking Negation Reasoning in Language Models With Fine-Tuning and In-Context Learning",
    "url": "https://openalex.org/W4385893872",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A5087123740",
            "name": "Jingyuan Selena She",
            "affiliations": [
                "Haverford College"
            ]
        },
        {
            "id": "https://openalex.org/A5042601761",
            "name": "Christopher Potts",
            "affiliations": [
                "Stanford University"
            ]
        },
        {
            "id": "https://openalex.org/A5112713734",
            "name": "Samuel R. Bowman",
            "affiliations": [
                "New York University"
            ]
        },
        {
            "id": "https://openalex.org/A5002577142",
            "name": "Atticus Geiger",
            "affiliations": [
                "Stanford University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4289237923",
        "https://openalex.org/W4308021463",
        "https://openalex.org/W2962736243",
        "https://openalex.org/W2954194820",
        "https://openalex.org/W4320442509",
        "https://openalex.org/W4379986648",
        "https://openalex.org/W1840435438",
        "https://openalex.org/W2101234009",
        "https://openalex.org/W2951286828",
        "https://openalex.org/W2962843521",
        "https://openalex.org/W4287854875",
        "https://openalex.org/W3105928338",
        "https://openalex.org/W2964044490",
        "https://openalex.org/W3099843385",
        "https://openalex.org/W2963120843",
        "https://openalex.org/W3097977265",
        "https://openalex.org/W4287124808",
        "https://openalex.org/W4226236946",
        "https://openalex.org/W3122890974",
        "https://openalex.org/W3177474387",
        "https://openalex.org/W3034995113",
        "https://openalex.org/W4281557260",
        "https://openalex.org/W2130158090",
        "https://openalex.org/W4297801719",
        "https://openalex.org/W4295312788",
        "https://openalex.org/W3175508917",
        "https://openalex.org/W4323557327",
        "https://openalex.org/W3088209710",
        "https://openalex.org/W3213468647",
        "https://openalex.org/W2965373594",
        "https://openalex.org/W2963846996",
        "https://openalex.org/W3035097102",
        "https://openalex.org/W2923014074",
        "https://openalex.org/W4385570323",
        "https://openalex.org/W2971089712",
        "https://openalex.org/W4285309087",
        "https://openalex.org/W4221143046",
        "https://openalex.org/W3004346089",
        "https://openalex.org/W2997789497",
        "https://openalex.org/W4292779060"
    ],
    "abstract": "A number of recent benchmarks seek to assess how well models handle natural language negation. However, these benchmarks lack the controlled example paradigms that would allow us to infer whether a model had truly learned how negation morphemes semantically scope. To fill these analytical gaps, we present the Scoped Negation NLI (ScoNe-NLI) benchmark, which contains contrast sets of six examples with up to two negations where either zero, one, or both negative morphemes affect the NLI label. We use ScoNe-NLI to assess fine-tuning and in-context learning strategies. We find that RoBERTa and DeBERTa models solve ScoNe-NLI after many shot fine-tuning. For in-context learning, we test the latest InstructGPT models and find that most prompt strategies are not successful, including those using step-by-step reasoning. To better understand this result, we extend ScoNe with ScoNe-NLG, a sentence completion test set that embeds negation reasoning in short narratives. Here, InstructGPT is successful, which reveals the model can correctly reason about negation, but struggles to do so on NLI examples outside of its core pretraining regime.",
    "full_text": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics\nVolume 2: Short Papers, pages 1803–1821\nJuly 9-14, 2023 ©2023 Association for Computational Linguistics\nScoNe: Benchmarking Negation Reasoning in Language Models\nWith Fine-Tuning and In-Context Learning∗\nJingyuan Selena She\nHaverford College\njshe@haverford.edu\nChristopher Potts\nStanford University\ncgpotts@stanford.edu\nSamuel R. Bowman\nNew York University & Anthropic, PBC\nbowman@nyu.edu\nAtticus Geiger\nStanford University\natticusg@stanford.edu\nAbstract\nA number of recent benchmarks seek to as-\nsess how well models handle natural language\nnegation. However, these benchmarks lack the\ncontrolled example paradigms that would allow\nus to infer whether a model had learned how\nnegation morphemes semantically scope. To\nfill these analytical gaps, we present theScoped\nNegation NLI (ScoNe-NLI) benchmark, which\ncontains contrast sets of six examples with up\nto two negations where either zero, one, or\nboth negative morphemes affect the NLI la-\nbel. We use ScoNe-NLI to assess fine-tuning\nand in-context learning strategies. We find that\nRoBERTa and DeBERTa models solve ScoNe-\nNLI after many shot fine-tuning. For in-context\nlearning, we test InstructGPT models and find\nthat most prompt strategies are not success-\nful, including those using step-by-step reason-\ning. To better understand this result, we extend\nScoNe with ScoNe-NLG, a sentence comple-\ntion test set that embeds negation reasoning\nin short narratives. Here, InstructGPT is suc-\ncessful, which reveals the model can correctly\nreason about negation, but struggles to do so\non prompt-adapted NLI examples outside of its\ncore pretraining regime.\n1 Introduction\nNegation is a ubiquitous but complex linguistic\nphenomenon that poses a significant challenge for\nNLP systems. A diverse array of benchmarks fo-\ncused on negation have appeared in recent years,\nmany of which contain families of contrasting ex-\namples that provide a local view of the model deci-\nsion boundary (Gardner et al., 2020). For instance,\nCooper et al. (1996), McCoy and Linzen (2018),\nWang et al. (2019), Ettinger (2020), Hartmann et al.\n(2021), and Kassner and Schütze (2020) all conduct\nevaluations with minimal pairs of examples that are\nidentical except for a negative morpheme. These\nexamples reveal whether the presence of negation\nhas a causal impact on model predictions.\n∗ https://github.com/selenashe/ScoNe\nHowever, negation is not simply present or ab-\nsent in a sentence. Rather, negation morphemes\nare semantic operators that take scope in complex\nways, as we see in clear contrasts like the person\nwho was at the talk wasn’t happy and the person\nwho wasn’t at the talk was happy. The recent Con-\ndaQA benchmark of Ravichander et al. (2022) in-\ncludes minimal pairs aimed at determining whether\nmodels are sensitive to these differences in scope.\nWith the current paper, we seek to provide an\neven fuller picture of the complexities of negation\nand semantic scope. We introduce the English-\nlanguage Scoped Negation Natural Language In-\nference Benchmark (ScoNe-NLI). ScoNe-NLI ex-\ntends the negated portion of the Monotonicity NLI\ndataset (Geiger et al., 2020) such that each of the\n1,202 examples is now a contrast set with six ex-\namples in which zero, one, or two negations are\npresent and each negation may or may not have\na semantic scope such that the NLI label is im-\npacted by its presence. These six conditions offer a\nrich picture of how negation affects NLI reasoning,\nand they allow us to determine whether models are\ntruly able to handle nested negation and scope or\nwhether they have found simplistic solutions.\nWe evaluate models on ScoNe-NLI using many-\nshot fine-tuning as well as a wide range of in-\ncontext learning strategies. For fine-tuning ap-\nproaches, we find that RoBERTa and DeBERTa\nmodels both solve ScoNe-NLI. For in-context\nlearning, we evaluate the latest InstructGPT model\nwith a variety of prompt strategies. We find that\nthese models perform well on sections of ScoNe-\nNLI where the negation morphemes can simply be\nignored, but they systematically fail in conditions\nwhere exactly one negative morpheme has seman-\ntic scope such that its presence changes the NLI\nlabel. In other words, these models fail to learn in\ncontext how negation actually takes scope.\nTo better understand this result, we introduce a\nsentence completion test set (ScoNe-NLG) contain-\n1803\nSplit Premise Rel. Hypothesis Examples\nNo negation The cowboy fell off a horse at\nthe competition\n⊐ The cowboy fell off a\nracehorse at the competition\n1,202\nOne Not\nScoped\nThe cowboy did not fear\nanything, until he fell off a\nhorse at the competition\n⊐ The cowboy did not fear\nanything, until he fell off a\nracehorse at the competition\n1,202\nTwo Not\nScoped\nThe cowboy, who was not very\nold, was not proud that he fell\noff a horse at the competition\n⊐ The cowboy, who was not\nvery old, was not proud that\nhe fell off a racehorse at the\ncompetition\n1,202\nTwo Scoped There is no way that the\ncowboy did not fall off a horse\nat the competition\n⊐ There is no way that the\ncowboy did not fall off a\nracehorse at the competition\n1,202\nOne Scoped The cowboy did not fall off a\nhorse at the competition\n⊏ The cowboy did not fall off a\nracehorse at the competition\n1,202\nOne Scoped,\nOne not\nScoped\nThe cowboy did not fall off a\nhorse, but the competition was\nnot too important\n⊏ The cowboy did not fall off a\nracehorse, but the\ncompetition was not too\nimportant\n1,202\n(a) A six-example contrast set from ScoNe-NLI.\nNo Negation\nGlen is a fan of learning\nmath. When he sees that\nhis new high school\nrequires that he take a\ncalculus course, he\nNegation\nGlen is not a fan of\nlearning math. When he\nsees that his new high\nschool requires that he take\na calculus course, he\nNon-Scoping Negation\nGlen isn’t just a fan of\nlearning math, he’s\nobsessive. When he sees\nthat his new high school\nrequires that he take a\ncalculus course, he\n(b) A three-example contrast\nset from ScoNe-NLG.\nTable 1: Two contrast sets from the ScoNe Benchmark\ning examples that seem better aligned with what\nwe can infer about the training data used for In-\nstructGPT models. In each ScoNe-NLG example,\nnegation reasoning is needed to provide a coherent\nending to an incomplete narrative (see Figure 1b).\nScoNe-NLG contains minimal triplets of exam-\nples where negation is absent, present with relevant\nscope, or present without relevant scope. Instruct-\nGPT is successful on ScoNe-NLG. When consid-\nered alongside our negative result for ScoNe-NLI,\nthis finding seems to show that these models can\nlearn in-context about how negation takes scope,\nbut only when the examples are hand-tailored to\nbe aligned with the training data and aligned with\nknown strengths of these models. Thus, when used\ntogether, ScoNe-NLI and ScoNe-NLG serve as a\nclear diagnostic for exploring useful prompting\nstrategies and assessing the capacity of language\nmodels to reason about negation and scope.\n2 A Brief Review of Negation in NLI\nBenchmarks\nA diverse array of benchmarks and diagnostic ex-\nperiments have included negation reasoning in re-\ncent years (Nairn et al., 2006; McCoy and Linzen,\n2018; Wang et al., 2019; Ettinger, 2020; Hartmann\net al., 2021; Kassner and Schütze, 2020; Ravichan-\nder et al., 2022).\nHossain et al. (2022) analyze a variety of natu-\nral language understanding benchmarks and find\nthat negation is underrepresented, and that when\nnegation is present it often has no impact on the\nexample label. Hossain et al. (2020) address this\nissue by manually adding negation to the premise-\nhypothesis pairs in MNLI (Williams et al., 2018),\nSNLI (Bowman et al., 2015), and RTE (Dagan\net al., 2007; Cooper et al., 1996).\nYanaka et al. (2019a) introduce the crowd-\nsourced MED dataset, which has many NLI exam-\nples where negation generates inferences. Mono-\ntonicity NLI (MoNLI; Geiger et al. 2020) consists\nof modified SNLI sentences that have gold labels\nimpacted by lexical entailments in affirmative con-\ntexts (PMoNLI) and lexical entailments reversed\nby a negation (NMoNLI). BERT fine-tuned on\nSNLI and MNLI fails to generalize to both of these\ndatasets, but succeeds with further fine-tuning on\nMED/MoNLI. Some automatically generated NLI\ndatasets also include negation reasoning (Geiger\net al., 2019; Richardson et al., 2020; Yanaka et al.,\n2019b, 2021).\n3 ScoNe-NLI\nScoNe-NLI is an extension of MoNLI (Geiger\net al., 2020). MoNLI was generated by randomly\nselecting a sentence from SNLI and replacing a\nnoun with a hypernym (more general term) or\n1804\nNo One Two Two One One Scoped,\nFine-tuning Datasets Negation Not Scoped Not Scoped Scoped Scoped One not Scoped\nMAF-NLI 82.0 86.0 81.5 91.0 5.0 5.0\nMAF-NLI+ MoNLI (Geiger et al., 2020) 96.2 87.5 99.5 8.9 100.0 100.0\nMAF-NLI+ MED (Yanaka et al., 2020) 84.8 83.5 82.0 58.9 99.5 97.0\nMAF-NLI+ Neg-NLI (Hossain et al., 2020) 91.3 88.5 83.0 70.4 37.0 29.0\nMAF-NLI+ MoNLI + ScoNe-NLI 100.0 100.0 100.0 100.0 100.0 100.0\nTable 2: DeBERTa fine-tuning results on ScoNe-NLI.MAF-NLI stands for on MNLI, ANLI, and Fever-NLI.\nConditional Q Is it true that if Premise, then\nHypothesis?\nHypothesis Q Assume that Premise. Is it then definitely\ntrue that Hypothesis? Answer yes or no.\nConditional\nTruth\nIf Premise, then Hypothesis. Is this true?\nBrown et al. P: Premise\\n Q: Hypothesis\\n Yes, No, or\nMaybe?\nStructured P: Premise\\n H: Hypothesis\\nL:\nReasoning\nLogical and commonsense reasoning exam.\\n\\n\nExplain your reasoning in detail, then answer with Yes or\nNo. Your answers should follow this 4-line format:\\n\\n\nPremise: <a tricky logical statement about the world>.\\n\nQuestion: <question requiring logical deduction>.\\n\nReasoning: <an explanation of what you understand about\nthe possible scenarios>\\n\nAnswer: <Yes or No>.\\n\\n\nPremise: Premise\\n\nQuestion: Hypothesis\\n\nReasoning: Let’s think logically step by step. The premise\nbasically tells us that\nTable 3: Prompts used to adapt a 2-way NLI example\n(Premise, Hypothesis). Newlines are indicated with \\n.\nFull prompts with few-shot variants are in Appendix E.\nhyponym (less general term). The original and\nedited sentences are then used to form two premise–\nhypothesis pairs, one with the label entailment and\nthe other with the label neutral. In about half of\nthe examples, this replacement is in an affirma-\ntive context with no negation (PMoNLI). In the\nother half, it is under the scope of a single negation\n(NMoNLI).\nThe authors generated ScoNe-NLI by using each\nexample of NMoNLI to create a contrast set of six\nexamples where gold labels are impacted by the\nscope of zero, one, or two negations, as in Table 1.\nTo succeed across all sections of ScoNe, models\nneed to attend to the presence of negation as well as\nthe way it scopes semantically. Table 1a shows an\nactual example of how ScoNe extends MoNLI. We\nuse the train–test split of MoNLI where substituted\nlexical items are disjoint across training and testing\ndata. Appendix C provides further details.\nFine-Tuning on ScoNe-NLI We used pub-\nlicly available weights on HuggingFace for the\nDeBERTa-v3-base models already fine-tuned on\nMNLI, Fever-NLI, and Adversarial-NLI (Laurer\net al., 2022; He et al., 2021). Appendix B contains\ncomparable results for the RoBERTa model (Liu\net al., 2019). Fine-tuning results are in Table 2.\nFine-tuning on existing NLI datasets is in-\nsufficient for good performance on ScoNe-NLI:\nDeBERTa-v3-base fine-tuned on existing NLI\ndatasets, even those that focus on negation, sys-\ntematically fails. Thus, it seems that ScoNe-NLI\ncaptures novel aspects of negation reasoning.\nIn contrast, fine-tuning on MoNLI and ScoNe-\nNLI training data results in near perfect perfor-\nmance on ScoNe-NLI test data. This shows that\nDeBERTa can learn negation reasoning and gener-\nalize to new lexical items.\nIn-context Learning on ScoNe-NLIWe evalu-\nated InstructGPT using OpenAI’s API with text-\ndavinci-002 and text-davinci-003 engines and a\ntemperature of 0.0 (Brown et al., 2020). We ask\nInstructGPT to infer NLI labels given the premise\nand hypothesis using prompts. All prompts are\nconstructed such that if the response contain “yes”\n(case-insensitive), then the label entailment is pre-\ndicted, else the label neutral is predicted. We use\nsix prompts (Table 3). For each prompt, we imple-\nmented both zero-shot and few-shot inference ex-\nperiments. Appendix E provides the full prompts.\nInstructGPT makes systematic errors similar\nto a baseline that ignores negation entirely.The\nbest results are for the few-shot reasoning prompt\nwith davinci-003. While its overall accuracy of\n82% may initially appear to be a success, further\nanalysis reveals otherwise. InstructGPT succeeds\nonly on the sections of ScoNe-NLI where zero\nor two negations take scope, namely, no nega-\ntion (99%), one not scoped (97%), two not scoped\n1805\nNo One Two Two One One Scoped,\nNegation Not Scoped Not scoped Scoped Scoped One not Scoped Overall\nZero-shot\nStructured 0.50 0.50 0.50 0.50 0.50 0.50 0.50\nBrown et al. 0.74 0.70 0.74 0.55 0.44 0.45 0.60\nConditional Q 0.79 0.84 0.80 0.50 0.52 0.44 0.65\nConditional Truth 0.98 0.86 0.80 0.43 0.66 0.47 0.70\nHypothesis Q 0.69 0.90 0.70 0.51 0.62 0.42 0.64\nReasoning 0.90 0.88 0.94 0.72 0.52 0.46 0.73\nFew-shot\nStructured 0.50 0.50 0.50 0.50 0.50 0.50 0.50\nBrown et al. 0.86 0.66 0.80 0.83 0.36 0.28 0.63\nConditional Q 0.92 0.85 0.90 0.62 0.34 0.34 0.66\nConditional Truth 0.94 0.90 0.94 0.64 0.36 0.37 0.69\nHypothesis Q 0.98 0.96 0.94 0.83 0.51 0.40 0.77\nReasoning 0.99 0.97 0.98 0.89 0.69 0.43 0.82\nIgnore-Negation 1.00 1.00 1.00 1.00 0.00 0.00 0.66\nTable 4: In-context learning results on ScoNe-NLI for InstructGPT ( davinci-003 engine; see Appendix F for\ncorresponding results for davinci-002, which are uniformly lower). Zero-shot results are given in the first group of\nrows, with the best results in that condition underlined. Few-shot results are given in the second group, with the\nbest results for this condition (and overall) in bold. The bottom row specifies a simple, idealized Ignore-Negation\nbaseline that makes predictions as if negations were absent. The baseline shows that the seemingly solid Overall\nresults of these models are driven largely by conditions for which negation can be ignored. Conversely, models are\noften at or below chance where negation is critical in some way.\nNo One One Not\nNegation Scoped Scoped Overall\nZero-shot 0.99 0.90 0.88 0.92\nFew-shot 0.93 1.00 0.93 0.95\nTable 5: Results for ScoNe-NLG using davinci-003.\nThe three conditions correspond to those of ScoNe and\ntest the essential scope-taking properties of negation.\n(98%), and two scoped (89%). InstructGPT per-\nforms much worse on sections where exactly one\nnegation takes scope, namely one scoped (69%),\none scoped/one not (48%). An idealized baseline\nentirely ignoring the presence of negation (last row\nof Table 4) succeeds and fails on the same sections,\nindicating a systematic flaw in InstructGPT.\n4 ScoNe-NLG\nInstructGPT fails to reason about negation when\ngiven NLI examples that must be adapted to natural\nlanguage generation (NLG) with prompts. We hy-\npothesized that InstructGPT may correctly reason\nabout negation when evaluated on examples hand\ntailored to its pretraining objective, because there\nis no need for prompt engineering (Liu et al., 2021;\nWei et al., 2022; Kojima et al., 2022).\nDataset ScoNe-NLG is a natural language gener-\nation dataset that contains 74 contrasting triplets\nof examples of half-completed naturalistic narra-\ntives that have different coherent completions de-\npending on the presence and scope of a negation.\nInstructGPT fails on the sections of ScoNe-NLI\nexamples containing only one negation, so we opt\nfor contrast sets with three examples that require\nknowledge of a lexical entailment in an affirmative\ncontext without negation, an affirmative context\nwith non-scoping negation, and an negative context\nwith scoping negation, respectively. See Table 1b.\nIn-context Learning on ScoNe-NLGWe used In-\nstructGPT to complete the partial sentence inputs\nwith the text-davinci-003 engine (temperature of\n0.0). In the zero-shot setting, the prompt consists\nof the ScoNe-NLG example. In the few-shot set-\nting, four demonstrations from ScoNe-NLG are\ngiven one with no negation, two with scoping nega-\ntion, and one with non-scoping negation. See Ap-\npendix E.13 for the complete prompts.\nTo evaluate, the authors went through the re-\nsponses by hand and determined whether the gen-\nerated text is coherent and compatible with the\ninitial narrative. The authors agreed on these anno-\ntations for 216/222 of the zero-shot responses with\na Fleiss kappa of 0.84 and 220/222 of the few-shot\nresponses with a Fleiss kappa of 0.91. These agree-\nment rates are so high that we evaluate InstructGPT\nonly for the cases where the annotators agree. Here,\nInstructGPT is successful but not perfect, achieving\n95% and 92% accuracy in the few and zero-shot\nsettings, respectively. We do not observe the sys-\ntematic failures seen on ScoNe-NLI.\n1806\nSCONE-BOOL (p, h)\n1 lexrel ←GET-LEXREL (p, h)\n2 neg1 ←FIRST -SCOPE (p, h)\n3 neg2 ←SECOND -SCOPE (p, h)\n4 if (neg1 ⊕ neg2)):\n5 return REVERSE (lexrel)\n6 return lexrel\n(a) An interpretable program\nthat solves ScoNe-NLI by\ncomputing two Boolean vari-\nables that encode whether\nthe first and second negation\nscope and reversing entail-\nment if exactly one is true.\nSCONE-COUNT (p, h)\n1 lexrel ←GET-LEXREL (p, h)\n2 count ←COUNT -SCOPED (p, h)\n3 if count == 1:\n4 return REVERSE (lexrel)\n5 return lexrel\n(b) An interpretable program\nthat solves ScoNe-NLI by\ncounting the scoped nega-\ntions and reversing entail-\nment if there is exactly one.\nIGNORE -SCOPE (p, h)\n1 lexrel ←GET-LEXREL (p, h)\n2 count ←COUNT -NEG (p, h)\n3 if count == 1:\n4 return REVERSE (lexrel)\n5 return lexrel\n(c) A flawed heuristic pro-\ngram: we count the nega-\ntions and reverse entailment\nif there is a single negation,\nwhich is equivalent to ignor-\ning the scope of negation.\nIGNORE -NEGATION (p, h)\n1 lexrel ←GET-LEXREL (p, h)\n2 return lexrel\n(d) A flawed heuristic pro-\ngram for ScoNe-NLI that out-\nputs the lexical relation and\nignores negation entirely.\nFigure 1: Four human-interpretable algorithms for ScoNe-NLI. The first two solve the task perfectly, and the other\ntwo implement flawed heuristics that a model might learn to implement. The function GET-LEXREL retrieves\nthe relation between the aligned words in the premise and hypothesis, COUNT -SCOPED counts scoped negations,\nCOUNT -NEG counts negations regardless of scope, and GET-FIRST returns true if the first negation scopes, while\nGET-SECOND returns true if there is a second negation and it scopes.\n5 Future Work on Interpretability\nScoNe is based in naturalistic examples, but it also\nhas a controlled structure that offers valuable op-\nportunities to move beyond simple behavioral test-\ning and more deeply understand how models solve\ntasks related to lexical entailment and negation.\nThe theory of causal abstraction provides a\nframework for interpretability (Geiger et al.,\n2023a), where a neural model can be understood\nto implement the intermediate variables and inter-\nnal structure of a program or algorithm (Geiger\net al., 2021, 2022; Wu et al., 2022b,a; Huang et al.,\n2022; Geiger et al., 2023b). In fact, the MoNLI\ndataset and the technique of interchange interven-\ntions (which is the primary technique in causal\nabstraction analysis) were jointly introduced in\nGeiger et al. 2020, where interchange interventions\nwere used to investigate whether a BERT model im-\nplements a simple, human-interpretable algorithm\nthat can perfectly label MoNLI using a variable\nrepresenting lexical entailment and a variable rep-\nresenting the presence of negation.\nWith ScoNe, we can ask even deeper inter-\npretability questions of this form. To encourage\nfuture work in this direction, we present a range\nof algorithmic solutions in Figure 1. Two of these\nsolutions solve ScoNe and could perhaps explain\nneural models that learn the task perfectly, and two\nothers implement flawed heuristics that could ex-\nplain neural models with poor task performance.\nFigure 1a and Figure 1b present two intuitive\nand correct algorithms that solve ScoNe, but have\ndistinct intermediate variables and internal struc-\nture. The first computes two Booleans representing\nwhether each negation scopes, and the second com-\nputes a count of how many negations scope.\nFigure 1d is the flawed heuristic that ignores\nnegation that we discussed in Section 3 as a hypoth-\nesis about how models fail at our task. Figure 1d\nis a second flawed heuristic that counts the number\nof negations present but ignores scope.\nUsing the toolkit of causal abstraction, we can as-\nsess models not only behaviorally, but also evaluate\nwhether they implement an interpretable algorithm.\nThe results of Geiger et al. (2023b) begin to show\nhow such analyses could be extended to in-context\nlearning with LLMs, as in Section 4.\n6 Conclusion\nWe introduced ScoNe, a benchmark for fine-tuning\nand in-context learning experiments on negation.\nScoNe is challenging for NLI models fine-tuned\non other datasets, even those designed for nega-\ntion reasoning, but modest amount of fine-tuning\non ScoNe leads to success. For in-context learn-\ning, we find that that InstructGPT models fail dra-\nmatically on ScoNe. However, we also introduce\nScoNe-NLG, which uses more narrative-like exam-\nples to probe models’ capacity to handle negation,\nand show that InstructGPT is successful with zero-\nshot and few-shot prompts for this task. These\nresults show that ScoNe supports fine-grained as-\nsessments of whether models can reason accurately\nabout natural language negation, and our discus-\nsion in Section 5 suggests that ScoNe can be a\npowerful tool for discovering how models reason\nsemantically.\n1807\nLimitations\nWe are releasing ScoNe as a diagnostic tool for con-\nducting controlled scientific experiments. This is\nour primary intended use, and we advise against un-\ncritical use of ScoNe for real-world applications, as\nwe have not audited the dataset for such purposes.\nAs a diagnostic tool, ScoNe’s primary limitation\nis its focus on English. Cross-linguistically, we\nfind many strategies for expressing negation. The\nEnglish-language strategy of using mostly adver-\nbial modifiers for sentential negation is not the only\none by any means, and we would expect to see\nquite different results for languages in which nega-\ntion is expressed, for example, with verbal suffixes.\nThis highlights the value of potential future efforts\nextending ScoNe to other languages.\nBy the same token, we acknowledge that many\nlinguistic phenomena interact with negation even\ninternal to English. ScoNe restricts to negation in\nthe context of lexical entailment, and mostly uses\n“not” as the negative morpheme. This excludes a\nwide range of negation morphemes and negation\nstrategies that ultimately need to be brought into\nthe picture.\nFinally, we note that there may be undesirable\nbiases in ScoNe that could interact with biases in\nthe models. ScoNe is in part derived from SNLI,\nwhich is known to contain gaps, social biases, and\nartifacts (Poliak et al., 2018; McCoy et al., 2019;\nBelinkov et al., 2019; Gururangan et al., 2018;\nTsuchiya, 2018), and ScoNe may inherit some of\nthese.\nReferences\nYonatan Belinkov, Adam Poliak, Stuart Shieber, Ben-\njamin Van Durme, and Alexander Rush. 2019. Don’t\ntake the premise for granted: Mitigating artifacts in\nnatural language inference. In Proceedings of the\n57th Annual Meeting of the Association for Compu-\ntational Linguistics, pages 877–891, Florence, Italy.\nAssociation for Computational Linguistics.\nSamuel R. Bowman, Gabor Angeli, Christopher Potts,\nand Christopher D. Manning. 2015. A large anno-\ntated corpus for learning natural language inference.\nIn Proceedings of the 2015 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n632–642, Lisbon, Portugal. Association for Compu-\ntational Linguistics.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens\nWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-\nteusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\nLanguage models are few-shot learners. In Ad-\nvances in Neural Information Processing Systems ,\nvolume 33, pages 1877–1901. Curran Associates,\nInc.\nRobin Cooper, Dick Crouch, Jan Van Eijck, Chris Fox,\nJohan Van Genabith, Jan Jaspars, Hans Kamp, David\nMilward, Manfred Pinkal, Massimo Poesio, et al.\n1996. Using the framework. Technical report, LRE\n62-051 D-16, The FraCaS Consortium.\nIdo Dagan, Oren Glickman, and Bernardo Magnini.\n2007. The pascal recognising textual entailment chal-\nlenge. In Machine Learning Challenges Workshop.\nAllyson Ettinger. 2020. What BERT Is Not: Lessons\nfrom a New Suite of Psycholinguistic Diagnostics for\nLanguage Models. Transactions of the Association\nfor Computational Linguistics, 8:34–48.\nMatt Gardner, Yoav Artzi, Victoria Basmova, Jonathan\nBerant, Ben Bogin, Sihao Chen, Pradeep Dasigi,\nDheeru Dua, Yanai Elazar, Ananth Gottumukkala,\nNitish Gupta, Hannaneh Hajishirzi, Gabriel Ilharco,\nDaniel Khashabi, Kevin Lin, Jiangming Liu, Nel-\nson F. Liu, Phoebe Mulcaire, Qiang Ning, Sameer\nSingh, Noah A. Smith, Sanjay Subramanian, Reut\nTsarfaty, Eric Wallace, Ally Zhang, and Ben Zhou.\n2020. Evaluating models’ local decision boundaries\nvia contrast sets. In Findings of the Association for\nComputational Linguistics: EMNLP 2020, Online\nEvent, 16-20 November 2020, volume EMNLP 2020\nof Findings of ACL, pages 1307–1323. Association\nfor Computational Linguistics.\nAtticus Geiger, Ignacio Cases, Lauri Karttunen, and\nChristopher Potts. 2019. Posing fair generalization\ntasks for natural language inference. In Proceedings\nof the 2019 Conference on Empirical Methods in Nat-\nural Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 4475–4485, Stroudsburg,\nPA. Association for Computational Linguistics.\nAtticus Geiger, Hanson Lu, Thomas Icard, and Christo-\npher Potts. 2021. Causal abstractions of neural net-\nworks. In Advances in Neural Information Process-\ning Systems, volume 34, pages 9574–9586.\nAtticus Geiger, Chris Potts, and Thomas Icard. 2023a.\nCausal abstraction for faithful interpretation of AI\nmodels. ArXiv:2106.02997.\nAtticus Geiger, Kyle Richardson, and Christopher Potts.\n2020. Neural natural language inference models\npartially embed theories of lexical entailment and\nnegation. In Proceedings of the Third BlackboxNLP\nWorkshop on Analyzing and Interpreting Neural Net-\nworks for NLP, pages 163–173, Online. Association\nfor Computational Linguistics.\n1808\nAtticus Geiger, Zhengxuan Wu, Hanson Lu, Josh\nRozner, Elisa Kreiss, Thomas Icard, Noah Goodman,\nand Christopher Potts. 2022. Inducing causal struc-\nture for interpretable neural networks. In Proceed-\nings of the 39th International Conference on Machine\nLearning, volume 162 of Proceedings of Machine\nLearning Research, pages 7324–7338. PMLR.\nAtticus Geiger, Zhengxuan Wu, Christopher Potts,\nThomas Icard, and Noah D. Goodman. 2023b. Find-\ning alignments between interpretable causal variables\nand distributed neural representations. Ms., Stanford\nUniversity.\nSuchin Gururangan, Swabha Swayamdipta, Omer Levy,\nRoy Schwartz, Samuel Bowman, and Noah A. Smith.\n2018. Annotation artifacts in natural language infer-\nence data. In Proceedings of the 2018 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 2 (Short Papers), pages 107–112,\nNew Orleans, Louisiana. Association for Computa-\ntional Linguistics.\nMareike Hartmann, Miryam de Lhoneux, Daniel Her-\nshcovich, Yova Kementchedjhieva, Lukas Nielsen,\nChen Qiu, and Anders Søgaard. 2021. A multilingual\nbenchmark for probing negation-awareness with min-\nimal pairs. In Proceedings of the 25th Conference on\nComputational Natural Language Learning, pages\n244–257, Online. Association for Computational Lin-\nguistics.\nPengcheng He, Xiaodong Liu, Jianfeng Gao, and\nWeizhu Chen. 2021. Deberta: Decoding-enhanced\nbert with disentangled attention. In International\nConference on Learning Representations.\nMd Mosharaf Hossain, Dhivya Chinnappa, and Eduardo\nBlanco. 2022. An analysis of negation in natural lan-\nguage understanding corpora. In Proceedings of the\n60th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 2: Short Papers), pages\n716–723, Dublin, Ireland. Association for Computa-\ntional Linguistics.\nMd Mosharaf Hossain, Venelin Kovatchev, Pranoy\nDutta, Tiffany Kao, Elizabeth Wei, and Eduardo\nBlanco. 2020. An analysis of natural language infer-\nence benchmarks through the lens of negation. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 9106–9118, Online. Association for Computa-\ntional Linguistics.\nJing Huang, Zhengxuan Wu, Kyle Mahowald, and\nChristopher Potts. 2022. Inducing character-level\nstructure in subword-based language models with\nType-level Interchange Intervention Training. Ms.,\nStanford University and UT Austin.\nNora Kassner and Hinrich Schütze. 2020. Negated and\nmisprimed probes for pretrained language models:\nBirds can talk, but cannot fly. In Proceedings of the\n58th Annual Meeting of the Association for Compu-\ntational Linguistics, pages 7811–7818, Online. Asso-\nciation for Computational Linguistics.\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\ntaka Matsuo, and Yusuke Iwasawa. 2022. Large\nlanguage models are zero-shot reasoners. ArXiv,\nabs/2205.11916.\nMoritz Laurer, Wouter van Atteveldt, Andreu Casas,\nand Kasper Welbers. 2022. Less annotating, more\nclassifying – addressing the data scarcity issue of\nsupervised machine learning with deep transfer learn-\ning and bert-nli.\nPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang,\nHiroaki Hayashi, and Graham Neubig. 2021. Pre-\ntrain, prompt, and predict: A systematic survey of\nprompting methods in natural language processing.\nACM Computing Surveys (CSUR).\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nR. Thomas McCoy and Tal Linzen. 2018. Non-entailed\nsubsequences as a challenge for natural language\ninference. CoRR, abs/1811.12112.\nTom McCoy, Ellie Pavlick, and Tal Linzen. 2019. Right\nfor the wrong reasons: Diagnosing syntactic heuris-\ntics in natural language inference. In Proceedings of\nthe 57th Annual Meeting of the Association for Com-\nputational Linguistics, pages 3428–3448, Florence,\nItaly. Association for Computational Linguistics.\nRowan Nairn, Cleo Condoravdi, and Lauri Karttunen.\n2006. Computing relative polarity for textual in-\nference. In Proceedings of the Fifth International\nWorkshop on Inference in Computational Semantics\n(ICoS-5).\nAdam Paszke, Sam Gross, Francisco Massa, Adam\nLerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca\nAntiga, Alban Desmaison, Andreas Kopf, Edward\nYang, Zachary DeVito, Martin Raison, Alykhan Te-\njani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang,\nJunjie Bai, and Soumith Chintala. 2019. Pytorch:\nAn imperative style, high-performance deep learning\nlibrary. In Advances in Neural Information Process-\ning Systems 32, pages 8024–8035. Curran Associates,\nInc.\nF. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel,\nB. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,\nR. Weiss, V . Dubourg, J. Vanderplas, A. Passos,\nD. Cournapeau, M. Brucher, M. Perrot, and E. Duch-\nesnay. 2011. Scikit-learn: Machine learning in\nPython. Journal of Machine Learning Research ,\n12:2825–2830.\n1809\nAdam Poliak, Jason Naradowsky, Aparajita Haldar,\nRachel Rudinger, and Benjamin Van Durme. 2018.\nHypothesis only baselines in natural language infer-\nence. In Proceedings of the Seventh Joint Confer-\nence on Lexical and Computational Semantics, pages\n180–191, New Orleans, Louisiana. Association for\nComputational Linguistics.\nAbhilasha Ravichander, Matt Gardner, and Ana Maraso-\nvi´c. 2022. Condaqa: A contrastive reading compre-\nhension dataset for reasoning about negation.\nKyle Richardson, Hai Hu, Lawrence S. Moss, and\nAshish Sabharwal. 2020. Probing natural language\ninference models through semantic fragments. In The\nThirty-Fourth AAAI Conference on Artificial Intelli-\ngence, AAAI 2020, The Thirty-Second Innovative Ap-\nplications of Artificial Intelligence Conference, IAAI\n2020, The Tenth AAAI Symposium on Educational\nAdvances in Artificial Intelligence, EAAI 2020, New\nYork, NY, USA, February 7-12, 2020, pages 8713–\n8721. AAAI Press.\nMasatoshi Tsuchiya. 2018. Performance impact caused\nby hidden bias of training data for recognizing tex-\ntual entailment. In Proceedings of the Eleventh In-\nternational Conference on Language Resources and\nEvaluation (LREC 2018), Miyazaki, Japan. European\nLanguage Resources Association (ELRA).\nAlex Wang, Amanpreet Singh, Julian Michael, Felix\nHill, Omer Levy, and Samuel R. Bowman. 2019.\nGlue: A multi-task benchmark and analysis platform\nfor natural language understanding. In 7th Inter-\nnational Conference on Learning Representations,\nICLR 2019, New Orleans, LA, USA, May 6-9, 2019.\nOpenReview.net.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V Le,\nand Denny Zhou. 2022. Chain of thought prompt-\ning elicits reasoning in large language models. In\nAdvances in Neural Information Processing Systems.\nAdina Williams, Nikita Nangia, and Samuel Bowman.\n2018. A broad-coverage challenge corpus for sen-\ntence understanding through inference. In Proceed-\nings of the 2018 Conference of the North American\nChapter of the Association for Computational Lin-\nguistics: Human Language Technologies, Volume\n1 (Long Papers), pages 1112–1122, New Orleans,\nLouisiana. Association for Computational Linguis-\ntics.\nZhengxuan Wu, Karel D’Oosterlinck, Atticus Geiger,\nAmir Zur, and Christopher Potts. 2022a. Causal\nProxy Models for concept-based model explanations.\nArXiv:2209.14279.\nZhengxuan Wu, Atticus Geiger, Joshua Rozner, Elisa\nKreiss, Hanson Lu, Thomas Icard, Christopher Potts,\nand Noah Goodman. 2022b. Causal distillation for\nlanguage models. In Proceedings of the 2022 Con-\nference of the North American Chapter of the As-\nsociation for Computational Linguistics: Human\nLanguage Technologies, pages 4288–4295, Seattle,\nUnited States. Association for Computational Lin-\nguistics.\nHitomi Yanaka, Koji Mineshima, Daisuke Bekki, and\nKentaro Inui. 2020. Do neural models learn system-\naticity of monotonicity inference in natural language?\nIn Annual Meeting of the Association for Computa-\ntional Linguistics.\nHitomi Yanaka, Koji Mineshima, Daisuke Bekki, Ken-\ntaro Inui, Satoshi Sekine, Lasha Abzianidze, and\nJohan Bos. 2019a. Can neural networks understand\nmonotonicity reasoning? In Proceedings of the 2019\nACL Workshop BlackboxNLP: Analyzing and Inter-\npreting Neural Networks for NLP, pages 31–40, Flo-\nrence, Italy. Association for Computational Linguis-\ntics.\nHitomi Yanaka, Koji Mineshima, Daisuke Bekki, Ken-\ntaro Inui, Satoshi Sekine, Lasha Abzianidze, and\nJohan Bos. 2019b. HELP: A dataset for identify-\ning shortcomings of neural models in monotonic-\nity reasoning. In Proceedings of the Eighth Joint\nConference on Lexical and Computational Semantics\n(*SEM 2019) , pages 250–255, Minneapolis, Min-\nnesota. Association for Computational Linguistics.\nHitomi Yanaka, Koji Mineshima, and Kentaro Inui.\n2021. SyGNS: A systematic generalization testbed\nbased on natural language semantics. In Findings of\nthe Association for Computational Linguistics: ACL-\nIJCNLP 2021, pages 103–119, Online. Association\nfor Computational Linguistics.\n1810\nAppendices\nA Experimental Details\nA.1 Fine-tuning Protocol\nFor our fine-tuning experiments, we used a learning rate of 1e-5, batch size of 4, gradient accumulation\nsteps of 6 for a total of 10 epochs. We used these default hyperparameters as they were successful in\nfine-tuning on ScoNe. We implemented these experiments with Pytorch (Paszke et al., 2019) and used the\nscikit learn package (Pedregosa et al., 2011).\nA.2 Hugging Face Models\nWe test RoBERTa 1 and DeBERTa2 in these experiments. We used the roberta-large model fine-\ntuned on MNLI 3 with 354 million parameters, 500K steps, and trained on 1,024 V100 GPUs (Liu\net al., 2019). DeBERTa-v3-base-mnli-fever-anli model4 was fine-tuned on MNLI, Fever-NLI,5 and ANLI.6\nRoBERTa weights link:\nhttps://huggingface.co/roberta-large-mnli\nDeberta weights link:\nhttps://huggingface.co/MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\nA.3 Fine-Tuning Datasets\nWe further fine-tuned our model on the datasets MoNLI,7 Negation-NLI, 8 MED. 9\nB RoBERTa Results\nNo One Two Two One One Scoped,\nFine-tuning Datasets Negation Not Scoped Not Scoped Scoped Scoped One not Scoped\nMAF-NLI 96.5 97.0 97.0 96.5 3.0 5.0\nMAF-NLI+ MoNLI (Geiger et al., 2020) 85.4 100.0 100.0 4.5 100.0 100.0\nMAF-NLI+ MED (Yanaka et al., 2020) 85.1 92.0 89.5 44.6 85.5 81.5\nMAF-NLI+ Neg-NLI (Hossain et al., 2020) 93.1 97.5 93.0 73.2 20.5 17.5\nMAF-NLI+ MoNLI + ScoNe-NLI 100.0 100.0 100.0 100.0 100.0 100.0\nTable 6: RoBERTa fine-tuning results on ScoNe-NLI.MAF-NLI stands for on MNLI, ANLI, and Fever-NLI.\nC ScoNe Dataset Details\nFor some examples, we modified the lexical items replaced. Consider the NMoNLI sentence pair ‘a man\nis not tossing anything’-‘a man is not tossing socks’ (entailment), and non-scoping counterpart ‘a man not\nhere is tossing something’-‘a man not here is tossing socks’ (neutral). Here, ’anything’ must be replaced\nby ’something’. The positive and negative examples in MoNLI do not come in minimal pairs, so the\nexamples in ScoNe-NLI with no negation are not from PMoNLI.\n1released under the MIT license\n2released under the MIT license\n3released under the MIT license\n4released under the MIT license\n5released under the Creative Commons Attribution-ShareAlike License (version 3.0)\n6released under the Attribution-NonCommercial 4.0 International license\n7released under the Creative Commons Attribution Share Alike 4.0 International license\n8released under the MIT license\n9released under the Creative Commons Attribution Share Alike 4.0 International license\n1811\nD Prompting Methods\nThe experimental runs reported in the paper were conducted on January 11, 2023. We used InstructGPT10\nmodels with 1.3 billion parameters and 6 billion parameter. The exact cost of constructing the InstructGPT\nmodels is not public, but the pre-training protocol involves (1) fine-tuning a GPT3 model on an instruction\nfollowing dataset, (2) fine-tuning a GPT3 model to rank different answers to the instruction following\ndataset, and (3) using reenforcement learning to combine these two models. We use a temperature\nparameter of 0.0 for all experiments. If the response contains “yes” (case-insensitive), then we infer the\nlabel entailment, else we infer neutral. Across experiments, the only thing that varies is the nature of\nthe prompt function.\nE In-Context Learning Prompts\nWe have indicated all actual newlines with \\n. The newlines in the formatting are just to make them\nintuitive to read.\nE.1 Conditional Question Prompt\nPrompt example\nIs it true that if we didn’t eat pizza, then we didn’t eat food?\nE.2 Few-Shot Conditional Question Prompt\nPrompt example\nQ1: Is it true that if a not so tall person reading a paper is not currently sitting inside a building, then\na not so tall person reading a paper is not currently sitting inside a club?\\n\nA1: Yes\\n\n\\n\nQ2: Is it true that if the man does not own a dog and does not own a cat, then the man does not own\na retriever and does not own a cat?\\n\nA2: Yes\\n\n\\n\nQ3: Is it true that if a not so tall person reading a paper is not currently sitting inside a cabin, then a\nnot so tall person reading a paper is not currently sitting inside a building?\\n\nA3: Maybe\\n\n\\n\nQ4: Is it true that if a not so tall person reading a paper is not currently sitting inside a casino, then a\nnot so tall person reading a paper is not currently sitting inside a building? A4: Maybe\\n\n\\n\nQ: Is it true that if we didn’t eat pizza, then we didn’t eat food?\\n\nA:\nE.3 Hypothesis Question Prompt\nPrompt example\nAssume that we didn’t eat pizza. Is it then definitely true that we didn’t eat food? Answer Yes or No.\n10information on terms of use is available at: https://openai.com/terms/\n1812\nE.4 Few-Shot Hypothesis Question Prompt\nPrompt example\nQ1: Assume that a not so tall person reading a paper is not currently sitting inside a building. Is it\nthen definitely true that a not so tall person reading a paper is not currently sitting inside a casino?\nAnswer Yes or No.\\n\nA1: Yes\\n\n\\n\nQ2: Assume that the girl will not get a stuffed dog as a gift, but not because she failed the exam. Is it\nthen definitely true that the girl will not get a stuffed pinscher as a gift, but not because she failed the\nexam? Answer Yes or No.\\n\nA2: Yes\\n\n\\n\nQ3: Assume that the girl will not get a stuffed shetland as a gift, but not because she failed the exam.\nIs it then definitely true that the girl will not get a stuffed dog as a gift, but not because she failed the\nexam? Answer Yes or No.\\n\nA3: No\\n\n\\n\nQ4: Assume that a not so tall person reading a paper is not currently sitting inside a monastery. Is it\nthen definitely true that a not so tall person reading a paper is not currently sitting inside a building?\nAnswer Yes or No.\\n\nA4: No\\n\n\\n\nQ: Assume that we didn’t eat pizza. Is it then definitely true that we didn’t eat food? Answer Yes or\nNo.\\n\nA:\nE.5 Conditional Truth Evaluation Prompt\nPrompt example\nIf we didn’t eat pizza, then we didn’t eat food. Is this true?\n1813\nE.6 Few-Shot Conditional Truth Evaluation Prompt\nPrompt example\nC1: If the man does not own a dog and does not own a cat, then the man does not own a shetland\nand does not own a cat. Is this true?\\n\nA1: Yes\\n\n\\n\nC2: If a not so tall person reading a paper is not currently sitting inside a building, then a not so tall\nperson reading a paper is not currently sitting inside a house. Is this true?\\n\nA2: Yes\\n\n\\n\nC3: If the man does not own a collie and does not own a cat, then the man does not own a dog and\ndoes not own a cat. Is this true?\\n\nA3: Maybe\\n\n\\n\nC4: If the man does not own a corgi and does not own a cat, then the man does not own a dog and\ndoes not own a cat. Is this true?\\n\nA4: Maybe\\n\n\\n\nC:If we didn’t eat pizza, then we didn’t eat food. Is this true?\\n\nA:\nE.7 Brown Et Al Style Prompt\nPrompt example\nC: We didn’t eat pizza\\n\nQ: We didn’t eat food. Yes, No, or Maybe?\nE.8 Few-Shot Brown Et Al Style Prompt\nPrompt example\nC1: The man, who’s eyes are not open, is not steering a car.\\n\nQ1: The man, who’s eyes are not open, is not steering a sedan. Yes, No, or Maybe?\\n\nA2: Yes\\n\n\\n\nC2: A dog not on the playground did not catch any ball.\\n\nQ2: A dog not on the playground did not catch any volleyball. Yes, No, or Maybe?\\n\nA3: Yes\\n\n\\n\nC3: the man does not own a collie and does not own a cat.\\n\nQ3: the man does not own a dog and does not own a cat. Yes, No, or Maybe?\\n\nA4: Maybe\\n\n\\n\nC4: A not so tall person reading a paper is not currently sitting inside a inn.\\n\nQ4: A not so tall person reading a paper is not currently sitting inside a building. Yes, No, or\nMaybe?\\n\nA5: Maybe\\n\n\\n\nC: We didn’t eat pizza\\n\nQ: We didn’t eat food. Yes, No, or Maybe?\\n\nA:\n1814\nE.9 Structured Prompt\nPrompt example\nP: We didn’t eat pizza\\n\nH: We didn’t eat food\\n\nL:\nE.10 Few-Shot Structured Prompt\nPrompt example\nP1: The players who did not score did not have a ball.\\n\nH1: The players who did not score did not have a baseball.\\n\nL1: entailment\\n\n\\n\nP2: the man does not own a dog and does not own a cat.\\n\nH2: the man does not own a poodle and does not own a cat.\\n\nL2: entailment\\n\n\\n\nP3: the man does not own a terrier and does not own a cat.\\n\nH3: the man does not own a dog and does not own a cat.\\n\nL3: neutral\\n\n\\n\nP4: the man does not own a husky and does not own a cat.\\n\nH4: the man does not own a dog and does not own a cat.\\n\nL4: neutral\\n\n\\n\nP: We didn’t eat pizza\\n\nH: We didn’t eat food\\n\nL:\nE.11 Reasoning Prompt\nPrompt example\nLogical and commonsense reasoning exam.\\n\n\\n\nExplain your reasoning in detail, then answer with Yes or No. Your answers should follow this 4-line\nformat:\\n\n\\n\nPremise: <a tricky logical statement about the world>.\\n\nQuestion: <question requiring logical deduction>.\\n\nReasoning: <an explanation of what you understand about the possible scenarios>.\\n\nAnswer: <Yes or No>.\\n\n\\n\nPremise: we didn’t eat pizza\\n\nQuestion: Can we logically conclude for sure that we didn’t eat food?\\n\nReasoning: Let’s think logically step by step. The premise basically tells us that\n1815\nE.12 Few-shot Reasoning Prompt\nFor this prompt, we insert two demonstrations right before the test example. These are of the correct type\nfor the test example, and they exemplify each of the two labels. The demonstrations are from a fixed set\nof examples, which we include here:\nE.12.1 No Negation\nPrompt example\nHere are some examples of the kind of reasoning you should do:\\n\n\\n\nPremise: The students ate pizza\\n\nQuestion: Can we logically conclude for sure that the students ate food?\\n\nReasoning: Let’s think logically step by step. The premise basically tells us that pizza is a type of\nfood. Therefore, the premise that the students ate pizza entails that the students ate food.\\n\nAnswer: Yes\\n\n\\n\nPremise: The students ate food\\n\nQuestion: Can we logically conclude for sure that the students ate pizza?\\n\nReasoning: Let’s think logically step by step. The premise basically tells us that pizza is a type\nof food. Therefore, the premise that the students ate food does not allow us to conclude that the\nstudents ate pizza. They might have eaten something else.\\n\nAnswer: No\\n\n\\n\nE.12.2 One Scoped\nPrompt example\nHere are some examples of the kind of reasoning you should do:\\n\n\\n\nPremise: The students didn’t eat any pizza\\n\nQuestion: Can we logically conclude for sure that the students didn’t eat any food?\\n\nReasoning: Let’s think logically step by step. The premise basically tells us that pizza is a type of\nfood. Therefore, the premise that the students didn’t eat any pizza does not allow us to conclude that\nthe students didn’t eat any food. They might have eaten something else.\\n\nAnswer: No\\n\n\\n\nPremise: The students didn’t eat any food\\n\nQuestion: Can we logically conclude for sure that the students didn’t eat any pizza?\\n\nReasoning: Let’s think logically step by step. The premise basically tells us that pizza is a type of\nfood. Therefore, the premise that the students didn’t eat any food entails that the students didn’t eat\nany pizza.\\n\nAnswer: Yes\\n\n\\n\n1816\nE.12.3 One Not Scoped\nPrompt example\nHere are some examples of the kind of reasoning you should do:\\n\n\\n\nPremise: The students who weren’t in class ate pizza\\n\nQuestion: Can we logically conclude for sure that the students who weren’t in class ate food?\\n\nReasoning: Let’s think logically step by step. The premise basically tells us that pizza is a type of\nfood. Therefore, the premise that the students who weren’t in class ate pizza entails that the students\nwho weren’t in class ate food.\\n\nAnswer: Yes\\n\n\\n\nPremise: The students who weren’t in class ate food\\n\nQuestion: Can we logically conclude for sure that the students who weren’t in class ate pizza?\\n\nReasoning: Let’s think logically step by step. The premise basically tells us that pizza is a type of\nfood. Therefore, the premise that the students who weren’t in class ate food does not allow us to\nconclude that the students who weren’t in class ate pizza. They might have eaten something else.\\n\nAnswer: No\\n\n\\n\nE.12.4 One Scoped, One Not Scoped\nPrompt example\nHere are some examples of the kind of reasoning you should do:\\n\n\\n\nPremise: The students who weren’t in class didn’t eat any pizza\\n\nQuestion: Can we logically conclude for sure that the students who weren’t in class didn’t eat any\nfood?\\n\nReasoning: Let’s think logically step by step. The premise basically tells us that pizza is a type of\nfood. Therefore, the premise that the students who weren’t in class didn’t eat any pizza does not\nallow us to conclude that the students who weren’t in class didn’t eat any food. They might have\neaten something else.\\n\nAnswer: No\\n\n\\n\nPremise: The students who weren’t in class didn’t eat any food\\n\nQuestion: Can we logically conclude for sure that the students who weren’t in class didn’t eat any\npizza?\\n\nReasoning: Let’s think logically step by step. The premise basically tells us that pizza is a type of\nfood. Therefore, the premise that the students who weren’t in class didn’t eat any food entails that\nthe students who weren’t in class didn’t eat any pizza.\\n\nAnswer: Yes\\n\n\\n\n1817\nE.12.5 Two Not Scoped\nPrompt example\nHere are some examples of the kind of reasoning you should do:\\n\n\\n\nPremise: The students who weren’t in class ate pizza that wasn’t hot\\n\nQuestion: Can we logically conclude for sure that the students who weren’t in class ate food that\nwasn’t hot?\\n\nReasoning: Let’s think logically step by step. The premise basically tells us that pizza is a type of\nfood. Therefore, the premise that the students who weren’t in class ate pizza that wasn’t hot entails\nthat the students who weren’t in class ate food that wasn’t hot.\\n\nAnswer: Yes\\n\n\\n\nPremise: The students who weren’t in class ate food that wasn’t hot\\n\nQuestion: Can we logically conclude for sure that the students who weren’t in class ate pizza that\nwasn’t hot?\\n\nReasoning: Let’s think logically step by step. The premise basically tells us that pizza is a type of\nfood. Therefore, the premise that the students who weren’t in class ate food that wasn’t hot does not\nallow us to conclude that the students who weren’t in class ate pizza that wasn’t hot. They might\nhave eaten something else.\\n\nAnswer: No\\n\n\\n\nE.12.6 Two Scoped\nPrompt example\nHere are some examples of the kind of reasoning you should do:\\n\n\\n\nPremise: It is not the case that the students didn’t eat any pizza\\n\nQuestion: Can we logically conclude for sure that it is not the case that the students didn’t eat any\nfood?\\n\nReasoning: Let’s think logically step by step. The premise basically tells us that pizza is a type of\nfood. Therefore, the premise that it is not the case that the students didn’t eat any pizza entails that it\nis not the case that the students didn’t eat any food.\\n\nAnswer: Yes\\n\n\\n\nPremise: It is not the case that the students didn’t eat any food\\n\nQuestion: Can we logically conclude for sure that it is not the case that the students didn’t eat any\npizza? Reasoning: Let’s think logically step by step. The premise basically tells us that pizza is a\ntype of food. Therefore, the premise that it is not the case that the students didn’t eat any food does\nnot allow us to conclude that it is not the case that the students didn’t eat any pizza. They might have\neaten something else.\\n\nAnswer: No\\n\n\\n\n1818\nE.13 ScoNe-NLG Prompts\nIn the zero-shot condition, models are simply prompted with the ScoNe-NLG examples. In the few-shot\ncondition, the test is example is proceeded with a fixed set of four demonstrations, separated by double\nnewlines. The examples are as follows:\nPrompt example\nGlen is not a fan of learning math. When he sees that his new high school requires that he take a\ngeometry course, he is not pleased.\\n\n\\n\nI saw John take his BMW to the store the other day, so when Suzy asked me if John owns a car, I\nsaid yes.\\n\n\\n\nI’ve seen John with a dog that isn’t very cute, so when Suzy asked me if John owns a pet, I said\nyes.\\n\n\\n\nI recently confirmed that John is not allergic to any shellfish. So it makes sense that when we served\nshrimp\nF In-Context Learning Results for davinci-002\nNo One Two Two One One Scoped,\nNegation Not Scoped Not scoped Scoped Scoped One not Scoped Overall\nZero-shot\nStructured 0.50 0.50 0.50 0.50 0.50 0.50 0.50\nBrown et al. 0.69 0.60 0.59 0.55 0.50 0.48 0.57\nConditional Q 0.76 0.55 0.65 0.50 0.50 0.50 0.58\nConditional Truth 0.76 0.64 0.66 0.60 0.50 0.57 0.62\nHypothesis Q 0.80 0.83 0.86 0.62 0.45 0.40 0.66\nReasoning 0.85 0.70 0.68 0.62 0.57 0.56 0.66\nFew-shot\nStructured 0.50 0.50 0.50 0.50 0.50 0.50 0.50\nBrown et al. 0.82 0.75 0.78 0.72 0.35 0.29 0.62\nConditional Q 0.92 0.82 0.78 0.52 0.36 0.32 0.62\nConditional Truth 0.92 0.89 0.88 0.59 0.36 0.37 0.67\nHypothesis Q 0.99 0.91 0.92 0.68 0.38 0.40 0.72\nReasoning 0.73 0.85 0.78 0.62 0.74 0.54 0.71\nTable 7: In-context learning results for GPT-3 (davinci-002 engine).\n1819\nACL 2023 Responsible NLP Checklist\nA For every submission:\n□\u0013 A1. Did you describe the limitations of your work?\nYes, primarily in the Limitations section.\n□\u0013 A2. Did you discuss any potential risks of your work?\nYes, in the Limitations section.\n□\u0013 A3. Do the abstract and introduction summarize the paper’s main claims?\nYes, in the abstract and the introduction.\n□\u0017 A4. Have you used AI writing assistants when working on this paper?\nLeft blank.\nB □\u0013 Did you use or create scientiﬁc artifacts?\nSections 3 and 4.\n□\u0013 B1. Did you cite the creators of artifacts you used?\nSection 3.\n□\u0013 B2. Did you discuss the license or terms for use and / or distribution of any artifacts?\nAppendix A and D.\n□\u0013 B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided\nthat it was speciﬁed? For the artifacts you create, do you specify intended use and whether that is\ncompatible with the original access conditions (in particular, derivatives of data accessed for research\npurposes should not be used outside of research contexts)?\nIn Limitations, and in Appendix A and D, and in supplementary materials.\n□ B4. Did you discuss the steps taken to check whether the data that was collected / used contains any\ninformation that names or uniquely identiﬁes individual people or offensive content, and the steps\ntaken to protect / anonymize it?\nNot applicable. Left blank.\n□\u0013 B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and\nlinguistic phenomena, demographic groups represented, etc.?\nIn the Introduction and in Limitations section.\n□\u0013 B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,\netc. for the data that you used / created? Even for commonly-used benchmark datasets, include the\nnumber of examples in train / validation / test splits, as these provide necessary context for a reader\nto understand experimental results. For example, small differences in accuracy on large test sets may\nbe signiﬁcant, while on small test sets they may not be.\nSections 3 and 4.\nC □\u0013 Did you run computational experiments?\nSections 3 and 4.\n□ C1. Did you report the number of parameters in the models used, the total computational budget\n(e.g., GPU hours), and computing infrastructure used?\nNo response.\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing\nassistance.\n1820\n□\u0013 C2. Did you discuss the experimental setup, including hyperparameter search and best-found\nhyperparameter values?\nAppendix A.\n□\u0013 C3. Did you report descriptive statistics about your results (e.g., error bars around results, summary\nstatistics from sets of experiments), and is it transparent whether you are reporting the max, mean,\netc. or just a single run?\nSections 3 and 4.\n□ C4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did\nyou report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,\netc.)?\nNo response.\nD □\u0017 Did you use human annotators (e.g., crowdworkers) or research with human participants?\nLeft blank.\n□ D1. Did you report the full text of instructions given to participants, including e.g., screenshots,\ndisclaimers of any risks to participants or annotators, etc.?\nNot applicable. Left blank.\n□ D2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)\nand paid participants, and discuss if such payment is adequate given the participants’ demographic\n(e.g., country of residence)?\nNot applicable. Left blank.\n□ D3. Did you discuss whether and how consent was obtained from people whose data you’re\nusing/curating? For example, if you collected data via crowdsourcing, did your instructions to\ncrowdworkers explain how the data would be used?\nNot applicable. Left blank.\n□ D4. Was the data collection protocol approved (or determined exempt) by an ethics review board?\nNot applicable. Left blank.\n□ D5. Did you report the basic demographic and geographic characteristics of the annotator population\nthat is the source of the data?\nNot applicable. Left blank.\n1821"
}