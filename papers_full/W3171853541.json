{
  "title": "Improved Transformer Net for Hyperspectral Image Classification",
  "url": "https://openalex.org/W3171853541",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2889156133",
      "name": "Yuhao Qing",
      "affiliations": [
        "North University of China"
      ]
    },
    {
      "id": "https://openalex.org/A2116245357",
      "name": "Wenyi Liu",
      "affiliations": [
        "North University of China"
      ]
    },
    {
      "id": "https://openalex.org/A2854927377",
      "name": "Liuyan Feng",
      "affiliations": [
        "North University of China"
      ]
    },
    {
      "id": "https://openalex.org/A2810657518",
      "name": "Wanjia Gao",
      "affiliations": [
        "North University of China"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2068067793",
    "https://openalex.org/W2001298023",
    "https://openalex.org/W2077028485",
    "https://openalex.org/W2499938349",
    "https://openalex.org/W2465503420",
    "https://openalex.org/W2719511702",
    "https://openalex.org/W2767805377",
    "https://openalex.org/W2793272303",
    "https://openalex.org/W2801324747",
    "https://openalex.org/W2898381489",
    "https://openalex.org/W2166923144",
    "https://openalex.org/W1971891445",
    "https://openalex.org/W2102049927",
    "https://openalex.org/W2532852010",
    "https://openalex.org/W2131864940",
    "https://openalex.org/W3009883650",
    "https://openalex.org/W2919115771",
    "https://openalex.org/W2779054585",
    "https://openalex.org/W2899747753",
    "https://openalex.org/W2588023376",
    "https://openalex.org/W2909158354",
    "https://openalex.org/W2090424610",
    "https://openalex.org/W2888715336",
    "https://openalex.org/W2609880332",
    "https://openalex.org/W2764276316",
    "https://openalex.org/W2792332881",
    "https://openalex.org/W2548340849",
    "https://openalex.org/W2194775991",
    "https://openalex.org/W2937675449",
    "https://openalex.org/W2888119354",
    "https://openalex.org/W2614256707",
    "https://openalex.org/W2500751094",
    "https://openalex.org/W2937615289",
    "https://openalex.org/W3036990306",
    "https://openalex.org/W2809742058",
    "https://openalex.org/W3031696400",
    "https://openalex.org/W2950266692",
    "https://openalex.org/W3037409780",
    "https://openalex.org/W3043082011",
    "https://openalex.org/W2977002487",
    "https://openalex.org/W3124739931",
    "https://openalex.org/W2804902458",
    "https://openalex.org/W3112739920",
    "https://openalex.org/W3096609285",
    "https://openalex.org/W3035022492",
    "https://openalex.org/W2963563276",
    "https://openalex.org/W2884585870",
    "https://openalex.org/W2943166903",
    "https://openalex.org/W1521436688",
    "https://openalex.org/W3100245404",
    "https://openalex.org/W3103753223",
    "https://openalex.org/W3101640299",
    "https://openalex.org/W3106294914"
  ],
  "abstract": "In recent years, deep learning has been successfully applied to hyperspectral image classification (HSI) problems, with several convolutional neural network (CNN) based models achieving an appealing classification performance. However, due to the multi-band nature and the data redundancy of the hyperspectral data, the CNN model underperforms in such a continuous data domain. Thus, in this article, we propose an end-to-end transformer model entitled SAT Net that is appropriate for HSI classification and relies on the self-attention mechanism. The proposed model uses the spectral attention mechanism and the self-attention mechanism to extract the spectral–spatial features of the HSI image, respectively. Initially, the original HSI data are remapped into multiple vectors containing a series of planar 2D patches after passing through the spectral attention module. On each vector, we perform linear transformation compression to obtain the sequence vector length. During this process, we add the position–coding vector and the learnable–embedding vector to manage capturing the continuous spectrum relationship in the HSI at a long distance. Then, we employ several multiple multi-head self-attention modules to extract the image features and complete the proposed network with a residual network structure to solve the gradient dispersion and over-fitting problems. Finally, we employ a multilayer perceptron for the HSI classification. We evaluate SAT Net on three publicly available hyperspectral datasets and challenge our classification performance against five current classification methods employing several metrics, i.e., overall and average classification accuracy and Kappa coefficient. Our trials demonstrate that SAT Net attains a competitive classification highlighting that a Self-Attention Transformer network and is appealing for HSI classification.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7503100037574768
    },
    {
      "name": "Hyperspectral imaging",
      "score": 0.7144111394882202
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6780107617378235
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.6558037400245667
    },
    {
      "name": "Support vector machine",
      "score": 0.46903714537620544
    },
    {
      "name": "Convolutional neural network",
      "score": 0.43748199939727783
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I135714990",
      "name": "North University of China",
      "country": "CN"
    }
  ]
}