{
  "title": "THE-X: Privacy-Preserving Transformer Inference with Homomorphic Encryption",
  "url": "https://openalex.org/W4281806276",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2109824826",
      "name": "Tianyu Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2605948870",
      "name": "Hangbo Bao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2612910427",
      "name": "Shaohan Huang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1974723233",
      "name": "Li Dong",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2144995628",
      "name": "Binxing Jiao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2123654898",
      "name": "Daxin Jiang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2462479932",
      "name": "HaoYi Zhou",
      "affiliations": [
        "Beihang University",
        "Microsoft Research (India)"
      ]
    },
    {
      "id": "https://openalex.org/A2116050490",
      "name": "Jian-Xin Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2171151462",
      "name": "Furu Wei",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2968989294",
    "https://openalex.org/W3000479830",
    "https://openalex.org/W4210968720",
    "https://openalex.org/W2897925395",
    "https://openalex.org/W2925618549",
    "https://openalex.org/W3153137927",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2130158090",
    "https://openalex.org/W2923014074",
    "https://openalex.org/W2081769211",
    "https://openalex.org/W3121694563",
    "https://openalex.org/W2031533839",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W2963846996",
    "https://openalex.org/W4253067820",
    "https://openalex.org/W2901147448",
    "https://openalex.org/W2952087486",
    "https://openalex.org/W3217629331",
    "https://openalex.org/W1692991189",
    "https://openalex.org/W2970408908",
    "https://openalex.org/W3104033643",
    "https://openalex.org/W2768174108",
    "https://openalex.org/W131533222",
    "https://openalex.org/W3098049952",
    "https://openalex.org/W3193647133",
    "https://openalex.org/W1847843939",
    "https://openalex.org/W2987932087",
    "https://openalex.org/W2473418344",
    "https://openalex.org/W2462831000",
    "https://openalex.org/W3102378604",
    "https://openalex.org/W2970157301",
    "https://openalex.org/W3203265613",
    "https://openalex.org/W1873763122",
    "https://openalex.org/W2251939518",
    "https://openalex.org/W2096421956",
    "https://openalex.org/W3102554603",
    "https://openalex.org/W3210646981",
    "https://openalex.org/W4287112812",
    "https://openalex.org/W2923890923",
    "https://openalex.org/W2975429091",
    "https://openalex.org/W2963748441"
  ],
  "abstract": "As more and more pre-trained language models adopt on-cloud deployment, the privacy issues grow quickly, mainly for the exposure of plain-text user data (e.g., search history, medical record, bank account). Privacy-preserving inference of transformer models is on the demand of cloud service users. To protect privacy, it is an attractive choice to compute only with ciphertext in homomorphic encryption (HE). However, enabling pre-trained models inference on ciphertext data is difficult due to the complex computations in transformer blocks, which are not supported by current HE tools yet. In this work, we introduce THE-X, an approximation approach for transformers, which enables privacy-preserving inference of pre-trained models developed by popular frameworks. THE-X proposes a workflow to deal with complex computation in transformer networks, including all the non-polynomial functions like GELU, softmax, and LayerNorm. Experiments reveal our proposed THE-X can enable transformer inference on encrypted data for different downstream tasks, all with negligible performance drop but enjoying the theory-guaranteed privacy-preserving advantage.",
  "full_text": "Findings of the Association for Computational Linguistics: ACL 2022, pages 3510 - 3520\nMay 22-27, 2022c⃝2022 Association for Computational Linguistics\nTHE-X: Privacy-Preserving Transformer Inference with\nHomomorphic Encryption\nTianyu Chenp o⋆, Hangbo Baon, Shaohan Huangn, Li Dongn, Binxing Jiaom,\nDaxin Jiangm, Haoyi Zhoup o, Jianxin Lip o u, Furu Wein\nBDBC, Beihang University, Chinap\nSKLSDE, Beihang University, Chinao\nMicrosoft Researchn NLP Group, Microsoft STCAm\n{tianyuc, zhouhy,lijx}@buaa.edu.cn\n{t-habao,shaohanh, lidong1, binxjia, djiang, fuwei}@microsoft.com\nAbstract\nAs more and more pre-trained language mod-\nels adopt on-cloud deployment, the privacy is-\nsues grow quickly, mainly for the exposure of\nplain-text user data (e.g., search history, medi-\ncal record, bank account). Privacy-preserving\ninference of transformer models is on the de-\nmand of cloud service users. To protect pri-\nvacy, it is an attractive choice to compute\nonly with ciphertext in homomorphic encryp-\ntion (HE). However, enabling pre-trained mod-\nels inference on ciphertext data is difﬁcult due\nto the complex computations in transformer\nblocks, which are not supported by current HE\ntools yet. In this work, we introduce THE-X,\nan approximation approach for transformers,\nwhich enables privacy-preserving inference\nof pre-trained models developed by popular\nframeworks. THE-X proposes a workﬂow to\ndeal with complex computation in transformer\nnetworks, including all the non-polynomial\nfunctions like GELU, softmax, and Layer-\nNorm. Experiments reveal our proposed THE-\nX can enable transformer inference on en-\ncrypted data for different downstream tasks,\nall with negligible performance drop but enjoy-\ning the theory-guaranteed privacy-preserving\nadvantage.\n1 Introduction\nAccompanying the revolution of pre-trained mod-\nels in many NLP applications, such as senti-\nment analysis (Xu et al., 2019a), question an-\nswering (Yang et al., 2019b), information re-\ntrieval (Yang et al., 2019c), and text genera-\ntion (Raffel et al., 2020), many related technologies\nhave been deployed on the cloud to process user\ndata from personal customers, small businesses,\nand large enterprises by industrial service providers.\nHowever, the convenience of the on-cloud pre-\ntraining technology also comes with a series of\n⋆ Contribution during internship at MSRA. uThe corre-\nsponding author is Jianxin Li <lijx@buaa.edu.cn>.\nFinetuned Model Cloud Service\n（encrypted text)\nEncrypt (data, key)\nDecrypt (res, key)\nUser\n(plain text)\nFigure 1: An overview of our THE-X. The transformer-\nbased model could inference on encrypted data with\nour THE-X, enabling theory-guaranteed privacy protec-\ntion for users.\nprivacy challenges due to the sensitive nature of\nuser data. For example, the input text or even text\nvector representations in user requests can leak pri-\nvate information, which may cause the speciﬁc user\nto be identiﬁed (Schwartz and Solove, 2011; Zhu\nand Han, 2020). This lack of privacy guarantees\nmay impede privacy-conscious users from releas-\ning their data to service providers. Thus, service\nproviders may suffer from the deﬁciency of evolv-\ning models with user data. Besides, unintended\ndata disclosure and other privacy breaches may\nresult in litigation, ﬁnes, and reputation damages\nfor service providers. These concerns spark our\nproposal of THE-X, to enable privacy-preserving\ninference of transformer.\nSpeciﬁcally, we identify two challenges for the\nprivacy-preserving inference of pre-trained mod-\nels. The ﬁrst challenge is how to protect users’\nplain text data from access by third-party service\nproviders. (e.g., the clinic record or shopping his-\ntory). Prior work has applied Differential Privacy\n(DP) (Dwork et al., 2006) and its variants to address\nsimilar privatization issues - originally for statis-\ntical databases and more recently for DL (Abadi\net al., 2016) and NLP (Qu et al., 2021; Basu et al.,\n2021b; Fernandes et al., 2019; Lyu et al., 2020;\nBasu et al., 2021a). However, this solution may\nsuffer from eavesdropping attackers. A handful of\nresearch (Zhu and Han, 2020; Zhao et al., 2020)\n3510\ndemonstrated it possible to recover raw data from\ngradient leakage. Also, privacy protection could\nnever be theory-guaranteed. The second challenge\nis the performance concern, recent works like Tex-\ntHide (Huang et al., 2020) and FedNLP (Lin et al.,\n2021) leverages the federated learning (Yang et al.,\n2019a) to train model on encrypted data, at cost\nof considerable performance dropping. Focusing\non the privacy of training data, they have not fully\nexplored privacy-preserving inference.\nTo solve the concerns above, we depict one prac-\ntice of privacy-preserving inference in Figure 1,\nwhere a ﬁne-tuned language model could be con-\nverted into the cloud service mode with THE-X,\nand process users’ data with its eyes blind. During\ninference, the content of the user query is anony-\nmous to the transformer model. The results of\ncomputation are also ciphertext, which only can be\ndecrypted by the user’s private key.\nIn addition, we need a theory-guaranteed en-\ncryption solution like the homomorphic encryp-\ntion (HE) (Gentry, 2009) to convince both service\nproviders and users of the privacy security in pro-\nduction scenarios. The semantic security of HE\nis guaranteed by lattice-based cryptography, and\nthe HE computation results on ciphertext could be\ndecrypted to the same results in plaintext, prevent-\ning performance reduction cost. The basic idea of\nhomomorphic encryption is to perform computa-\ntions on encrypted data without ﬁrst decrypting it,\nwhich could fully ensure privacy in cloud-serving\nscenarios. It allows user data to be encrypted and\nout-sourced to commercial cloud environments for\nprocessing.\nHowever, due to the complex operations (e.g.,\nGELU activation) in transformer-based models, the\npopular partially homomorphic encryption solu-\ntion, which only supports addition or multiplica-\ntion, can not easily be adapted into scenarios of\npre-trained models. Based on HE transformer back-\nend (Boemer et al., 2019b,a, 2020), we designed a\nseries of approximation components to fulﬁll the\nwhole inference pipeline of the mainstream trans-\nformer backbone. We evaluate THE-X for BERT-\ntiny on the GLUE benchmark (Wang et al., 2019)\nand the CONLL2003 task (Tjong Kim Sang and\nDe Meulder, 2003). Our results show that THE-X\ncan achieve the privacy-preserving inference with\nthe averaged performance reduction of only 1.49%.\nOur contributions include:\n• We are the ﬁrst work to explore the privacy-\npreserving transformer inference with HE.\n• We design a practical and effective approxi-\nmation workﬂow for converting transformer-\nbased models into a function that consists of\nfully HE operations.\n• A thorough set of experiments conﬁrms the\nnegligible performance reduction with our\nproposed THE-X approximation.\n2 Background\n2.1 Security and Privacy Concern of\nPre-trained Models\nPre-trained models like BERT (Devlin et al., 2019)\nand GPT-3 (Brown et al., 2020) rely heavily on\nthe use of plain text data to get human-like perfor-\nmance. Despite the remarkable achievements of\npre-trained models, these state-of-the-art models\ncan not directly answer some sensitive use cases, in-\ncluding the medical record (Christoph et al., 2015),\nsearch history (Shen et al., 2007) and other person-\nally identiﬁable information (PII).\nTo avoid the direct computation on plain-text\ndata, recent works like TextHide (Huang et al.,\n2020) and DP-ﬁnetuning (Kerrigan et al., 2020)\nintroduce the classical federated learning and dif-\nferential privacy (DP) to protect the sensitive data.\nHowever, TextHide (Huang et al., 2020) can only\nbe applied to sentence-level tasks. Due to the mix-\nup operation, TextHide fails to model token-level\ntasks like named entity recognition or semantic\nrole labelling. DP-ﬁnetuning would greatly sacri-\nﬁce the performance of ﬁne-tuned model by 20%\nperplexity for a generation model like GPT-2.\n2.2 Practical Homomorphic Encryption\nThe classic deﬁnition of homomorphic encryption\nis a form of encryption that permits users to per-\nform computations on its encrypted data without\nﬁrst decrypting it. These computations results are\nretained in an encrypted form, which could be de-\ncrypted into identical output produced by the same\ncomputations on the unencrypted data. Let F be a\nfunction or the entire pre-trained model, E as an\nencryption function, D as a decryption function.\nThen for any allowed plain text input x, we have:\nF(x) = D(g(E(x)), (1)\nwhere gis a constructed function to play the same\nrole of function F, except on encrypted data. Fig-\nure 1 shows how a user performs inference using\n3511\na cloud-deployed pre-trained model which is not\ntrusted. First, the pre-trained model receives a ci-\nphertext encrypted by the user private key and per-\nforms inference function gon the ciphertext. Then,\nthe server will send an encrypted result to the user,\nwhich can only be decrypted by the user key. At no\npoint does the cloud service provider gain access\nto the plain text.\nThe Intel HE transformer for nGraph (Boemer\net al., 2019b,a) is a Homomorphic Encryption\nbackend to the deep learning models. Currently,\nit supports the CKKS (Cheon et al., 2017) en-\ncryption scheme, implemented by the Simple En-\ncrypted Arithmetic Library (SEAL) (SEAL) from\nMicrosoft Research. It is a research tool to demon-\nstrate the feasibility of HE on deep learning.\n2.3 Challenges of Transformer Inference\nwith HE\nSome HE schemes only support a single alge-\nbraic operation, such as addition or multiplica-\ntion. These are known as \"partially homomor-\nphic\" schemes (PHE). Other schemes, called \"fully\nhomomorphic\"(FHE), support two such as addi-\ntion and multiplication. Note that composing\naddition and multiplication sufﬁces to construct\npolynomial functions, and hence polynomial ap-\nproximations to non-polynomial functions such as\nGELU (Hendrycks and Gimpel, 2016) or Layer-\nNorm (Xu et al., 2019b). Notably, this limitation\nprevents the exact computation of any comparison-\nbased operations such as Max, Min, as well as\ncommon functions such as exponential or sigmoid.\nFinally, \"leveled homomorphic\" schemes (LHE)\nsupport addition and multiplication, only up to a\nﬁxed computational depth.\n3 THE-X: Formal Description\nThere are two core ideas in THE-X. The ﬁrst one is\nto incorporate the user device into the HE inference,\nand the second is using \"simpliﬁed computation\"\nto approximate the non-polynomial functions.\nIn the following, we will describe how to enable\nhomomorphic encryption of transformer-based\nmodels with THE-X.\n3.1 Approximation Workﬂow\nFirst, we present the approximation workﬂow of\nTHE-X, which consists of two stages: Standard\nFinetuning and LN Distill as depicted in Figure 2.\nGiven a pre-trained model Mand corresponding\nAlgorithm 1: Approximation Workﬂow\nData: labeled task data D.\nInput: pre-trained Transformer model M,\nsoftmax estimation model S.\n1 ˆM←M⊙ (S,ReLU).\n// replace GELU and Softmax\n2 while not done do\n3 sample batches (xi,yi) from D,\n4 let (xi,yi) optimize ˆMwith Sfrozen.\nend\n5 ˜M← ˆM⊕ ˜N.\n// add the layernorm approximation\n6 while not done do\n7 sample batches (xi,yi) from D,\n8 freeze the parameters of ˜Mexcept ˜N.\n9 compute k-th layernorm output Ok, ˜Ok.\n10 compute loss ℓk = MSELoss(Ok, ˜Ok).\n11 update ˜Nwith loss L= ∑\nk ℓk.\nend\n12 ¯M← ˜M⊖N .\n// discard the origin layernorm\nreturn ¯M.\ndownstream data, we aim to produce a fully HE\nsupported ¯Mwhich is ﬁne-tuned and ready for\ndeployment.\nThe two-stage optimization of algorithm 1 aims\nto ﬁnd the best approximation checkpoint. For com-\nputation efﬁciency, pre-trained models can also be\nﬁne-tuned together with the layernorm approxima-\ntion, and it needs only a single optimization loop.\nWe will discuss the schedule of the different ap-\nproximation workﬂow in Sec 4.6. There are three\nmajor non-polynomial functions in the transformer\nblock, where we will study in detail.\n3.1.1 Gaussion Error Linear Units (GLEU)\nWith a computation of Gaussian error, Gaussian Er-\nror Linear Units (GLEUs) (Hendrycks and Gimpel,\n2016) is not suitable to serve as an active func-\ntion in HE state. The Gaussian kernel includes\nunsupported functions like exponential. While in\nthe implementation of the transformer, GELU is\ndeﬁned as a fast approximated version, where the\ntanhfunction is still non-polynomial, unsupported\nby HE.\nG(x) = 0.5x(1+tanh[\n√\n2/π(x+0.044715x3)]).\n(2)\n3512\nStandard \nFine-tuning \nDrop Pooler\nReplace Softmax\nReplace GeLU\nAdd LN Approximation\nLN Distill\nDrop Origin LN\nHE-transformer\nPre-trained \nTransformer Model\n(Input with plain text)\nFine-tuned\nTransformer Model\n(Input with cypher text)\nKeep Original LN\nFigure 2: The Approximation Workﬂow of THE-X. To replace the non-polynomial operations, we split the ﬁne-\ntuning stage into several subphases. Given a pre-trained checkpoint, we drop the pooler of the pre-trained model\nand replace softmax and GeLU. Afterward, we follow the standard ﬁne-tuning for classiﬁcation or regression tasks.\nWe add LayerNorm approximation into the ﬁne-tuned model and distill knowledge from original LN layers. After\ndropping the original LN, we convert the model into fully HE-supported ops with the HE transformer.\nGELU vs ReLU 3\n2\n1\n。 — ReLU \n— GELU \n-3 -2 -1 。 1 2 3\nFigure 3: The activation results of GELU compared\nwith ReLU. With an input around zero, the activation\nresults are very close. With a larger or smaller input\nvalue, the activation results tend to converge.\nWe illustrate the numerical comparison between\nGELU and RELU in Figure 3 , where the outputs\nof GELU are very close to RELU. Hence, we pro-\npose to replace the GELU layer in the model with a\nReLU activation function. Despite the Max func-\ntion in ReLU, other computations are well sup-\nported by HE. To enable the computation of Max,\nwe implement the ﬁrst key idea, incorporating the\nuser device into the inference. The server will\nconvey ciphertext input to the user for local Max\ncomputation. Once received the connection, a user\ndevice decrypts the ciphertext input and calls the\nlocal Max function to get the results and return\nre-encrypted results to the server. Despite the com-\nmunication cost, no plaintext is leaked during the\nTLS connection and semantic security is guaran-\nteed.\n3.1.2 Softmax\nThe second non-polynomial function is softmax,\nwhich includes the exponential and division com-\nputation.\nSoftmax(xi) = exp(xi)∑\nj exp(xj). (3)\nThe ﬁrst thought to approximate softmax is to\nﬁnd alternatives of softmax operation in trans-\nformer, which include Taylor series approxima-\ntion (Vincent et al., 2015), softmax-free linear at-\ntention (Lu et al., 2021). However, both of them\nhave some limitations. The Taylor series approxi-\nmation can only approximate the exponential oper-\nation. Softmax-free linear attention utilizes newton-\ninverse to approximate division, but the approxi-\nmation error is unbounded in full-scale attention\nsettings.\nFor these considerations, we have no choice but\nto design an estimation network with addition and\nmultiplication.\nS(xi) = xi ∗T(\n∑\nj\nReLU(((xj)/2 + 1)3)). (4)\nEquation 4 is the formal description of our soft-\nmax estimation network. Same as the approxima-\ntion of GELU, ReLU operation here is realized\nby communication with the client. Instead of a\ndivision operation, we approximate reciprocal op-\neration with a three-layer linear neural network\ndenoted as T.\nTo get a better estimation of softmax, we ran-\ndomly generate input tensors whose values are be-\ntween [−3,3] and use their softmax scores as MSE\ntargets. Then we optimize the T for 100k steps\nwith a learning rate of 1e-3 until the MSE loss drop\ndown to 1e-6.\nAn under-explored problem here is the Inﬁnite\nvalue of Masked Attention, where the input of soft-\nmax is always the masked attention scores. To\nprevent the attention of masked tokens, the origin\ntransformer model ﬁlls the masked attention scores\nwith negative inﬁnity before softmax. When fed\nwith an inﬁnite value, the softmax estimation model\n3513\nmay face numerical disaster. We will discuss this\nphenomenon and the corresponding solution in Sec\n4.5.\n3.1.3 LayerNorm\nRecall that the layer normalization (Ba et al., 2016)\nin transformer is implemented over a mini-batch of\ninputs, which could be formulated as:\ny= x−E[x]√\nVar[x] + ϵ\n∗γ+ β. (5)\nThe mean and standard deviation are calculated\nover division operations where the approximation\nis needed. γ and βare learnable afﬁne transform\nparameters. To avoid the introduction of new pa-\nrameters, we keep the learnable parameters while\nleaving the mean and standard deviation achieved\nby regression.\nˆy= x◦γ + β. (6)\nThe new parameter γ predicts the value of stan-\ndard deviation by regression from originˆγ. We ﬁnd\nthe simple linear replacement is enough for values\nwith a small scale of bias. Here γ,β ∈R and ◦\ndenotes the Hadamard product.\nThe layer normalization will be applied in each\nmulti-head attention block and after the output\ndense layer. So the approximation error tends to\naccumulate when the transformer stacks with too\nmany layers.\nWe treat the layernorm approximation as an indi-\nvidual stage in Figure 1 as LN-Distill to learn from\norigin LN layers. A challenge here is the Attention\nOverﬂow, where the input attention score before\nnormalization may have an unbounded scale, lead-\ning to numerical problems. We will discuss the\ndetail of Attention Overﬂow in Sec 4.5.\n3.1.4 Other Practical Replacement\nAfter the approximation workﬂow, a ﬁne-tuned\nmodel consists of only addition and multiplication\noperations, which is fully compatible with homo-\nmorphic encryption. We power the model by HE\ntransformer backend. Since the HE transformer\nbackend could only work for TensorFlow check-\npoint, any pre-trained transformers inherited from\nPyTorch building version need to be converted into\nTensorFlow format ﬁrst. There are some other de-\ntails worth mentioning here.\n• For the softmax(QKT\n√dk\n)V operation in atten-\ntion score computation, we absorb the value\nof 1√dk\ninto the weights of query projection\nlayer.\n• We use a fully kernel convolution layer in-\nstead of linear projection due to the lack of\nsupported dense operation.\n• All matrix multiplication will be converted\ninto the element-wise style.\n• We drop the pooler layer for the unsupported\noperation of tanh.\n3.2 Privacy-preserving Inference\nIn this section, we describe the behavior of HE\nmodels during privacy-preserving inference. Note\nthat inference is completed by the joint effort of the\nserver and the user device.\nAlgorithm 2: Inference with HE\nInput: user plain text query Pq, private key\nKgenerated under server protocol,\nencrypted server model M.\n1 client computes embeddings: Eq ←Pq.\n2 client encrypts query embeddings:\nCq ←Encrypt(Eq,K).\n3 server forwards the model: Ci = M(Cq).\n4 client handles activation: Ca = ReLU(Ci).\n5 server continues forwarding: Co = M(Ca).\n6 client decrypts results:\nPo = Decrypt(Co,K).\nIn Algorithm 2, notably absent is the support\nof ReLU operations, where the server exchanges\nthe activation results with the client. However, all\nthe communication between client and server is in\nciphertext, ensuring the privacy of user queries and\nmay prevent eavesdropping attackers from recover-\ning private text data.\n4 Experiments\nIn this section, we design both sequence-level and\ntoken-level tasks to evaluate the approximation per-\nformance of our THE-X solution. We also discuss\nseveral identiﬁed factors which greatly affect ap-\nproximation workﬂow.\n4.1 Evaluation Tasks\nGLUE (Wang et al., 2019), the General Language\nUnderstanding Evaluation benchmark, is a collec-\ntion of tools for evaluating the performance of\nmodels across a diverse set of existing NLU tasks.\n3514\nTable 1: Performance on the GLUE 1 tasks for both baseline (standard ﬁnetuning) and THE-X with BERT-tiny,\nmeasured on the development sets. We report the best results by hyper-parameter search. |D|denotes the number\nof training examples. THE-X only suffers average utility performance loss: < 1.5% in most tasks. ‘P/S corr.’ is\nPearson/Spearman correlation and ‘m/mm’ denotes the accuracy scores on matched/mismatched set.\nTasks |D| Type Metrics Baseline ReLU ReLU-S ReLU-S-L HE Perf ↓\nSST-2 67k Sentiment Acc. 82.45 82.40 82.34 82.11 82.11 0.34\nMRPC 3.7k Paraphrase F1/Acc. 81.57/70.10 81.69/70.34 80.81/69.85 79.93/68.87 79.94/68.87 1.63/1.23\nSTS-B 7k Similarity P/S corr. 72.83/73.66 72.89/73.03 74.19/74.27 68.38/70.96 68.39/70.97 4.44/2.69\nQQP 364k Paraphrase F1 80.28/84.03 79.55/82.89 79.38/83.36 78.28/83.75 78.33/83.63 1.95/0.40\nMNLI 393k NLI m/mm 69.75/70.75 69.51/70.60 68.61/69.13 68.59/69.41 68.47/69.08 1.28/1.67\nQNLI 108k NLI ACC. 78.38 78.35 78.33 78.33 78.20 0.18\nRTE 2.5k NLI ACC. 58.56 58.32 58.27 58.12 58.12 0.44\nAverage Perf↓ 0.00 0.25 0.34 1.42 1.48 1.48\nTable 2: Performance on the CONLL2003 task for both\nbaseline and THE-X with BERT-tiny, measured on the\ndevelopment sets. We ﬁnd that the replacement with\nReLU has a slight effect on performance and even gets\na better F1 score by 0.12 than original GELU activa-\ntion.\nMetrics Precision Recall F1 Perf ↓\nRaw 82.34 84.85 83.57 0\nReLU 82.29 85.13 83.69 -0.12\nReLU-S 82.08 84.73 83.38 0.19\nReLU-S-L 79.65 83.79 81.67 1.90\nHE 79.65 83.79 81.67 1.90\nWe choose a subset of GLUE 1 tasks, which in-\nclude: MRPC (Dolan and Brockett, 2005), SST-\n2 (Socher et al., 2013), QQP 2, STS-B (Cer et al.,\n2017), MNLI (Williams et al., 2018), QNLI (Ra-\njpurkar et al., 2016), and RTE (Dagan et al., 2005;\nHaim et al., 2006; Giampiccolo et al., 2007; Ben-\ntivogli et al., 2009).\nFollowing previous work (Devlin et al., 2019;\nTurc et al., 2019), we exclude the WNLI task from\nthe GLUE benchmark. We also use the famous\nCoNLL-2003 (Tjong Kim Sang and De Meulder,\n2003) named entity recognition task as our addi-\ntional token-level evaluation. In conclusion, we\ninclude the most varieties of NLU tasks, covering\nboth sequence-level and sentence-level tasks, in\nboth regression and classiﬁcation format.\n4.2 Experiment Settings\nFor computation efﬁciency and energy-saving con-\nsideration, we use the released BERT-tiny (Turc\n1CoLA task is not reported because of the limited capacity\nof BERT-tiny.\n2https://www.quora.com/proﬁle/Ricky-Riche-2/First-\nQuora-Dataset-Release-Question-Pairs\net al., 2019) as our demo model, which is a stan-\ndard transformer-based language model with only\n2 layers and a hidden size of 128. We provide four\nsettings to evaluate different parts of our approxi-\nmation components.\n• Baseline. In this setting, we make no replace-\nment or approximation. We use the raw pre-\ntrained checkpoint to ﬁne-tune on downstream\ntasks.\n• ReLU. We ﬁne-tune the pre-trained model\nwith all GELU activation replaced with ReLU.\n• ReLU-S. In addition to ReLU, we ﬁne-tune\nthe model with the softmax operation replaced\nby the softmax estimation model.\n• ReLU-S-L. We implement full approximation\nincluding a layer normalization replacement.\n• HE. We convert the ﬁne-tuned checkpoint\nwith HE-transformer and power the inference\nwith SEAL backend.\nImplementation. To reduce the variance of re-\nsults under different settings, we choose hyper-\nparameters from a ﬁxed set during approximation\nﬁne-tuning and HE inference runtime.\n• For ﬁne-tuning the approximation compo-\nnents, we choose a batch size from {4, 8, 16,\n32, 128} and a learning rate from 1e-4, 3e-\n4, 3e-5, 5e-5 as mentioned in the initial bert\ncode (Turc et al., 2019). We use an Adam op-\ntimizer with weight decay chosen from {0.05,\n0.1, 0.2, 0.4, 0.5}\n• For HE evaluation, we use the HE-transformer\nbackend, where two parameters are recom-\nmended searching by Intel, the poly modules\n3515\nand coeff-modules. We choose the poly mod-\nules degree from {1024, 2048, 4096, 8192,\n16384} and choose the coeff-modules from\n{20, 30, 60}.\n4.3 Approximation Results\nTable 1 shows the results of the baseline and THE-\nX on the GLUE benchmark. The averaged perfor-\nmance reduction of THE-X is 1.48% when com-\npared to the baseline model. We observe the most\nperformance reduction comes from the approxi-\nmation of layernorm, which incurs a reduction of\n1.08%. The softmax estimation model contributes\nthe least performance drop among the approxima-\ntion components, for only 0.09% on average, in-\ndicating the softmax function could be well imi-\ntated by neural networks. We also ﬁnd the average\nperformance reduction of HE is quite negligible,\nwhere the slight drop may be due to the sequence\ntruncation.\nThe results of THE-X on token-level NER task\nare reported in Table 2. The replacement of GELU\nwith ReLU even improves the performance of the\nF1 score. We assume the slight improvement may\ncome from unexpected bias. However, the layer-\nnorm approximation incurs the most performance\nreduction. We assume token-level tasks need a\nmore detailed pattern in attention score. After all,\nTHE-X still works well in the token-level task with\na merely F1 reduction of 1.9%.\nAcross different types of tasks, we ﬁnd our THE-\nX yields the best performance on the classiﬁcation\ntasks, including paraphrase, sentiment and NLI.\nAmong the classiﬁcation tasks, the performance\nof QNLI drops the least, for only 0.18%. We also\nﬁnd the performance drops most on the regression\ntasks, such as the similarity task STS-B, for 4.44%\npearson correlation and 2.69% spearman correla-\ntion. We assume the regression task needs a higher\nnumerical precision than the classiﬁcation task.\n4.4 Negative Inﬁnity\nRecall in Equation 4, we replace softmax with a\nneural estimation model. To prevent the attention\nof masked tokens, the origin transformer model\nﬁlls the masked attention scores with negative in-\nﬁnity before softmax, where the numerical disas-\nter occurs in our approximation method. In Fig-\nure 4, to solve this problem, we give an empiri-\ncal study of how \"negative\" the masked attention\nscores should be. Despite the indistinguishable F1\nscore change of raw model ﬁne-tune with different\nFigure 4: Performance on CONLL2003 task with dif-\nferent mask values. We ﬁnd the “Negative Inﬁnity”\nvalue of the 0 mask greatly reduces approximation per-\nformance. In THE-X using a mask value in [-3, -5]\nmight be a default choice.\nattention mask values, the approximation method\nis extremely sensitive to the numerical changes.\nWe assume the softmax estimation model fails to\ndeal with large input values and leads to a credi-\nble performance drop. However, when the value\nof the attention mask becomes too small, it serves\nas a bias to attention scores, which also leads to a\ncertain performance drop. We recommend using a\nmoderate mask value between -2 and -5.\n4.5 Attention Overﬂow\nAnother challenge of THE-X is the attention score\ninput of layer normalization. In most cases, the\nscale of multi-head attention output is very dense\naround [−1,1]. However, before normalization, we\nalso observe the attention scores are scarily sparse,\nwith some extreme values reaching 1e4, which is\ndifﬁcult for our LN-distill stage. To prevent the\noverﬂow attention scores, we use theweight decay\nof Adam optimizer as regularization.\nIn Figure 5, we present the attention overﬂow\nphenomenon across different tasks. Without any\nregularization, our approximation method yields\nuncontrolled attention scores, leading to poor per-\nformance. As the weight decay increases, the at-\ntention scores tend to converge and beneﬁt better\napproximation results. We also observe that the\nlarger weight decay may harm the performance\non NLI tasks, where the regularization could be\nseen as trade-off between better approximation re-\nsults and higher performance upper bound. For the\nNER task, larger weight decay may even beneﬁt\nthe performance and also boost our approximation\nmethod.\n3516\nFigure 5: Performance on all tasks with different weight decay values, measured on the development sets. Metrics\nare marked on the y-axis and weight decay values are marked on the x-axis.\n4.6 Schedule of Approximation workﬂow\nThere are still doubts about how to organize the sev-\neral optimization steps for the best approximation\nperformance. We investigate four schedule plans:\n• Two Stages. Where we freeze the softmax\nestimation model during standard ﬁne-tuning.\nWe select the best checkpoint to implement\nthe second stage - distill the layer normaliza-\ntion network.\n• Joint FT S. We optimize the softmax estima-\ntion model during standard ﬁne-tuning and\napply the LN-distillation after.\n• Joint FT LN. We apply one-pass optimiza-\ntion with the softmax estimation model frozen\nbut update the other parameters including\nlayer normalization network. No further LN-\ndistill will be implemented.\n• Joint FT S + LN. A total one-pass optimiza-\ntion with all approximation parameters up-\ndated with the model together.\nAs illustrated in Figure 6, we observe that ﬁne-\ntuning the different approximation components in-\ndividually (aka. \"Two stages\") may be a good de-\nfault to keep the best performance of approxima-\ntion. For the regression task STS-B, jointly ﬁne-\ntuning the softmax estimation model and approx-\nimated layernorm even fails to fulﬁll the approxi-\nmation pipeline, pulling the performance down to\n0.4%. We assume ﬁne-tuning different components\nmay fall into a bi-level optimization problem and\n100 \n- Two Stages - Joint FT S 一 Joint FT LN - Joint FT S+LN \n80 \n60 \n40 \n20 \n。\n多飞一？ 沁邸； 多－8 Q咄 愤\\_\\ Q~\\..\\ «t ｀饺\nFigure 6: Performance on all tasks with different or-\nganizations of approximation workﬂow. Jointly ﬁne-\ntuning the softmax estimation model or approximated\nlayernorm leads to a performance drop across all tasks.\nit is hard to achieve satisfying results. In conclu-\nsion, the softmax estimation model and the approx-\nimated layernorm are both critical components to\nthe performance of THE-X, deserving individual\noptimization.\n5 Conclusions\nWe present THE-X, a practical approach to enable\npre-trained transformer models to infer under ho-\nmomorphic encryption. It requires several approxi-\nmation components to replace the original opera-\ntions in the transformer model. It imposes a slight\nburden in terms of performance cost but enjoys the\nfull advantage of homomorphic encryption - the\ntheory-guaranteed user privacy.\nWe see this as a ﬁrst step in combing homomor-\nphic encryption to address emerging privacy issues\nin pre-trained models. We hope our work motivates\nfurther research, including better approximation so-\nlutions on different NLP applications.\n3517\n6 Acknowledgments\nThis paper is supported in part by the NSFC\nthrough grant No.U20B2053. We also thanks the\nsupport from Beijing Advanced Innovation Center\nfor Future Blockchain and Privacy Computing.\nReferences\nMartín Abadi, Andy Chu, Ian J. Goodfellow, H. Bren-\ndan McMahan, Ilya Mironov, Kunal Talwar, and\nLi Zhang. 2016. Deep learning with differential pri-\nvacy. In Proceedings of the 2016 ACM SIGSAC Con-\nference on Computer and Communications Security,\nVienna, Austria, October 24-28, 2016 , pages 308–\n318. ACM.\nLei Jimmy Ba, Jamie Ryan Kiros, and Geoffrey E.\nHinton. 2016. Layer normalization. CoRR,\nabs/1607.06450.\nPriyam Basu, Tiasa Singha Roy, Rakshit Naidu, and\nZumrut Muftuoglu. 2021a. Privacy enabled ﬁnan-\ncial text classiﬁcation using differential privacy and\nfederated learning. In Proceedings of the Third\nWorkshop on Economics and Natural Language Pro-\ncessing, pages 50–55, Punta Cana, Dominican Re-\npublic. Association for Computational Linguistics.\nPriyam Basu, Tiasa Singha Roy, Rakshit Naidu, Züm-\nrüt Müftüoglu, Sahib Singh, and Fatemehsadat\nMireshghallah. 2021b. Benchmarking differential\nprivacy and federated learning for BERT models.\nCoRR, abs/2106.13973.\nLuisa Bentivogli, Bernardo Magnini, Ido Dagan,\nHoa Trang Dang, and Danilo Giampiccolo. 2009.\nThe ﬁfth PASCAL recognizing textual entailment\nchallenge. In Proceedings of the Second Text Analy-\nsis Conference, TAC 2009, Gaithersburg, Maryland,\nUSA, November 16-17, 2009. NIST.\nFabian Boemer, Rosario Cammarota, Daniel Demm-\nler, Thomas Schneider, and Hossein Yalame. 2020.\nMP2ML: A mixed-protocol machine learning frame-\nwork for private inference. In PPMLP’20: Proceed-\nings of the 2020 Workshop on Privacy-Preserving\nMachine Learning in Practice, Virtual Event, USA,\nNovember, 2020, pages 43–45. ACM.\nFabian Boemer, Anamaria Costache, Rosario Cam-\nmarota, and Casimir Wierzynski. 2019a. ngraph-\nhe2: A high-throughput framework for neural net-\nwork inference on encrypted data. In Proceedings of\nthe 7th ACM Workshop on Encrypted Computing &\nApplied Homomorphic Cryptography, WAHC@CCS\n2019, London, UK, November 11-15, 2019 , pages\n45–56. ACM.\nFabian Boemer, Yixing Lao, Rosario Cammarota, and\nCasimir Wierzynski. 2019b. ngraph-he: a graph\ncompiler for deep learning on homomorphically en-\ncrypted data. In Proceedings of the 16th ACM In-\nternational Conference on Computing Frontiers, CF\n2019, Alghero, Italy, April 30 - May 2, 2019 , pages\n3–13. ACM.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen,\nEric Sigler, Mateusz Litwin, Scott Gray, Benjamin\nChess, Jack Clark, Christopher Berner, Sam Mc-\nCandlish, Alec Radford, Ilya Sutskever, and Dario\nAmodei. 2020. Language models are few-shot learn-\ners. In Advances in Neural Information Processing\nSystems 33: Annual Conference on Neural Informa-\ntion Processing Systems 2020, NeurIPS 2020, De-\ncember 6-12, 2020, virtual.\nDaniel Cer, Mona Diab, Eneko Agirre, Iñigo Lopez-\nGazpio, and Lucia Specia. 2017. SemEval-2017\ntask 1: Semantic textual similarity multilingual and\ncrosslingual focused evaluation. In Proceedings\nof the 11th International Workshop on Semantic\nEvaluation (SemEval-2017), pages 1–14, Vancouver,\nCanada. Association for Computational Linguistics.\nJung Hee Cheon, Andrey Kim, Miran Kim, and\nYong Soo Song. 2017. Homomorphic encryption for\narithmetic of approximate numbers. In Advances in\nCryptology - ASIACRYPT 2017 - 23rd International\nConference on the Theory and Applications of Cryp-\ntology and Information Security, Hong Kong, China,\nDecember 3-7, 2017, Proceedings, Part I , volume\n10624 of Lecture Notes in Computer Science, pages\n409–437. Springer.\nJ Christoph, L Griebel, I Leb, I Engel, F Köpcke,\nD Toddenroth, H-U Prokosch, J Laufer, K Mar-\nquardt, and M Sedlmayr. 2015. Secure secondary\nuse of clinical data with cloud-based nlp services.\nMethods of information in medicine , 54(03):276–\n282.\nIdo Dagan, Oren Glickman, and Bernardo Magnini.\n2005. The PASCAL recognising textual entail-\nment challenge. In Machine Learning Challenges,\nEvaluating Predictive Uncertainty, Visual Object\nClassiﬁcation and Recognizing Textual Entailment,\nFirst PASCAL Machine Learning Challenges Work-\nshop, MLCW 2005, Southampton, UK, April 11-\n13, 2005, Revised Selected Papers , volume 3944 of\nLecture Notes in Computer Science, pages 177–190.\nSpringer.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 4171–4186, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\n3518\nWilliam B. Dolan and Chris Brockett. 2005. Automati-\ncally constructing a corpus of sentential paraphrases.\nIn Proceedings of the Third International Workshop\non Paraphrasing, IWP@IJCNLP 2005, Jeju Island,\nKorea, October 2005, 2005 . Asian Federation of\nNatural Language Processing.\nCynthia Dwork, Frank McSherry, Kobbi Nissim, and\nAdam D. Smith. 2006. Calibrating noise to sensi-\ntivity in private data analysis. In Theory of Cryp-\ntography, Third Theory of Cryptography Conference,\nTCC 2006, New York, NY, USA, March 4-7, 2006,\nProceedings, volume 3876 of Lecture Notes in Com-\nputer Science, pages 265–284. Springer.\nNatasha Fernandes, Mark Dras, and Annabelle McIver.\n2019. Generalised differential privacy for text docu-\nment processing. In Principles of Security and Trust\n- 8th International Conference, POST 2019, Held\nas Part of the European Joint Conferences on The-\nory and Practice of Software, ETAPS 2019, Prague,\nCzech Republic, April 6-11, 2019, Proceedings, vol-\nume 11426 of Lecture Notes in Computer Science ,\npages 123–148. Springer.\nCraig Gentry. 2009. Fully homomorphic encryption us-\ning ideal lattices. In Proceedings of the 41st Annual\nACM Symposium on Theory of Computing, STOC\n2009, Bethesda, MD, USA, May 31 - June 2, 2009 ,\npages 169–178. ACM.\nDanilo Giampiccolo, Bernardo Magnini, Ido Dagan,\nand Bill Dolan. 2007. The third PASCAL recog-\nnizing textual entailment challenge. In Proceedings\nof the ACL-PASCAL@ACL 2007 Workshop on Tex-\ntual Entailment and Paraphrasing, Prague, Czech\nRepublic, June 28-29, 2007, pages 1–9. Association\nfor Computational Linguistics.\nR Bar Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo\nGiampiccolo, Bernardo Magnini, and Idan Szpektor.\n2006. The second pascal recognising textual entail-\nment challenge. In Proceedings of the Second PAS-\nCAL Challenges Workshop on Recognising Textual\nEntailment.\nDan Hendrycks and Kevin Gimpel. 2016. Bridging\nnonlinearities and stochastic regularizers with gaus-\nsian error linear units. CoRR, abs/1606.08415.\nYangsibo Huang, Zhao Song, Danqi Chen, Kai Li, and\nSanjeev Arora. 2020. TextHide: Tackling data pri-\nvacy in language understanding tasks. In Findings\nof the Association for Computational Linguistics:\nEMNLP 2020 , pages 1368–1382, Online. Associa-\ntion for Computational Linguistics.\nGavin Kerrigan, Dylan Slack, and Jens Tuyls. 2020.\nDifferentially private language models beneﬁt from\npublic pre-training. In Proceedings of the Second\nWorkshop on Privacy in NLP, pages 39–45, Online.\nAssociation for Computational Linguistics.\nBill Yuchen Lin, Chaoyang He, Zihang Zeng, Hulin\nWang, Yufen Huang, Mahdi Soltanolkotabi, Xiang\nRen, and Salman Avestimehr. 2021. Fednlp: A re-\nsearch platform for federated learning in natural lan-\nguage processing. CoRR, abs/2104.08815.\nJiachen Lu, Jinghan Yao, Junge Zhang, Xiatian\nZhu, Hang Xu, Weiguo Gao, Chunjing Xu, Tao\nXiang, and Li Zhang. 2021. SOFT: softmax-\nfree transformer with linear complexity. CoRR,\nabs/2110.11945.\nLingjuan Lyu, Xuanli He, and Yitong Li. 2020. Differ-\nentially private representation for NLP: formal guar-\nantee and an empirical study on privacy and fair-\nness. In Findings of the Association for Compu-\ntational Linguistics: EMNLP 2020, Online Event,\n16-20 November 2020 , volume EMNLP 2020 of\nFindings of ACL, pages 2355–2365. Association for\nComputational Linguistics.\nChen Qu, Weize Kong, Liu Yang, Mingyang Zhang,\nMichael Bendersky, and Marc Najork. 2021. Natu-\nral language understanding with privacy-preserving\nbert. Proceedings of the 30th ACM International\nConference on Information & Knowledge Manage-\nment.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. 2020. Exploring the limits\nof transfer learning with a uniﬁed text-to-text trans-\nformer. J. Mach. Learn. Res., 21:140:1–140:67.\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and\nPercy Liang. 2016. Squad: 100, 000+ questions for\nmachine comprehension of text. In Proceedings of\nthe 2016 Conference on Empirical Methods in Nat-\nural Language Processing, EMNLP 2016, Austin,\nTexas, USA, November 1-4, 2016, pages 2383–2392.\nThe Association for Computational Linguistics.\nPaul M Schwartz and Daniel J Solove. 2011. The pii\nproblem: Privacy and a new concept of personally\nidentiﬁable information. NYUL rev., 86:1814.\nSEAL. 2020. Microsoft SEAL (release 3.6). https:\n//github.com/Microsoft/SEAL. Microsoft\nResearch, Redmond, W A.\nXuehua Shen, Bin Tan, and ChengXiang Zhai. 2007.\nPrivacy protection in personalized search. SIGIR Fo-\nrum, 41(1):4–17.\nRichard Socher, Alex Perelygin, Jean Wu, Jason\nChuang, Christopher D. Manning, Andrew Y . Ng,\nand Christopher Potts. 2013. Recursive deep mod-\nels for semantic compositionality over a sentiment\ntreebank. In Proceedings of the 2013 Conference\non Empirical Methods in Natural Language Process-\ning, EMNLP 2013, 18-21 October 2013, Grand Hy-\natt Seattle, Seattle, Washington, USA, A meeting of\nSIGDAT, a Special Interest Group of the ACL, pages\n1631–1642. ACL.\nErik F. Tjong Kim Sang and Fien De Meulder.\n2003. Introduction to the CoNLL-2003 shared task:\nLanguage-independent named entity recognition. In\n3519\nProceedings of the Seventh Conference on Natu-\nral Language Learning at HLT-NAACL 2003, pages\n142–147.\nIulia Turc, Ming-Wei Chang, Kenton Lee, and Kristina\nToutanova. 2019. Well-read students learn better:\nOn the importance of pre-training compact models.\narXiv preprint arXiv:1908.08962.\nPascal Vincent, Alexandre de Brébisson, and Xavier\nBouthillier. 2015. Efﬁcient exact gradient update\nfor training deep networks with very large sparse tar-\ngets. In Advances in Neural Information Processing\nSystems 28: Annual Conference on Neural Informa-\ntion Processing Systems 2015, December 7-12, 2015,\nMontreal, Quebec, Canada, pages 1108–1116.\nAlex Wang, Amanpreet Singh, Julian Michael, Felix\nHill, Omer Levy, and Samuel R. Bowman. 2019.\nGLUE: A multi-task benchmark and analysis plat-\nform for natural language understanding. In 7th\nInternational Conference on Learning Representa-\ntions, ICLR 2019, New Orleans, LA, USA, May 6-9,\n2019. OpenReview.net.\nAdina Williams, Nikita Nangia, and Samuel R. Bow-\nman. 2018. A broad-coverage challenge corpus\nfor sentence understanding through inference. In\nProceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\nNAACL-HLT 2018, New Orleans, Louisiana, USA,\nJune 1-6, 2018, Volume 1 (Long Papers) , pages\n1112–1122. Association for Computational Linguis-\ntics.\nHu Xu, Bing Liu, Lei Shu, and Philip S. Yu. 2019a.\nBERT post-training for review reading comprehen-\nsion and aspect-based sentiment analysis. In Pro-\nceedings of the 2019 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\nNAACL-HLT 2019, Minneapolis, MN, USA, June 2-\n7, 2019, Volume 1 (Long and Short Papers) , pages\n2324–2335. Association for Computational Linguis-\ntics.\nJingjing Xu, Xu Sun, Zhiyuan Zhang, Guangxiang\nZhao, and Junyang Lin. 2019b. Understanding and\nimproving layer normalization. In Advances in Neu-\nral Information Processing Systems 32: Annual Con-\nference on Neural Information Processing Systems\n2019, NeurIPS 2019, December 8-14, 2019, Vancou-\nver, BC, Canada, pages 4383–4393.\nQiang Yang, Yang Liu, Yong Cheng, Yan Kang, Tian-\njian Chen, and Han Yu. 2019a. Federated Learning.\nSynthesis Lectures on Artiﬁcial Intelligence and Ma-\nchine Learning. Morgan & Claypool Publishers.\nWei Yang, Yuqing Xie, Aileen Lin, Xingyu Li, Luchen\nTan, Kun Xiong, Ming Li, and Jimmy Lin. 2019b.\nEnd-to-end open-domain question answering with\nbertserini. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, NAACL-HLT 2019, Minneapolis, MN,\nUSA, June 2-7, 2019, Demonstrations, pages 72–77.\nAssociation for Computational Linguistics.\nWei Yang, Haotian Zhang, and Jimmy Lin. 2019c. Sim-\nple applications of BERT for ad hoc document re-\ntrieval. CoRR, abs/1903.10972.\nBo Zhao, Konda Reddy Mopuri, and Hakan Bilen.\n2020. idlg: Improved deep leakage from gradients.\nCoRR, abs/2001.02610.\nLigeng Zhu and Song Han. 2020. Deep leakage from\ngradients. In Qiang Yang, Lixin Fan, and Han Yu,\neditors, Federated Learning - Privacy and Incentive,\nvolume 12500 of Lecture Notes in Computer Sci-\nence, pages 17–31. Springer.\n3520",
  "topic": "Homomorphic encryption",
  "concepts": [
    {
      "name": "Homomorphic encryption",
      "score": 0.7603193521499634
    },
    {
      "name": "Ciphertext",
      "score": 0.7544057369232178
    },
    {
      "name": "Computer science",
      "score": 0.7527121305465698
    },
    {
      "name": "Inference",
      "score": 0.6596841812133789
    },
    {
      "name": "Encryption",
      "score": 0.5802328586578369
    },
    {
      "name": "Cloud computing",
      "score": 0.5455453395843506
    },
    {
      "name": "Information privacy",
      "score": 0.5167588591575623
    },
    {
      "name": "Computation",
      "score": 0.4757761061191559
    },
    {
      "name": "Transformer",
      "score": 0.46729782223701477
    },
    {
      "name": "Cryptography",
      "score": 0.4116450250148773
    },
    {
      "name": "Computer security",
      "score": 0.3985525369644165
    },
    {
      "name": "Theoretical computer science",
      "score": 0.37296611070632935
    },
    {
      "name": "Data mining",
      "score": 0.3427565097808838
    },
    {
      "name": "Algorithm",
      "score": 0.2612972855567932
    },
    {
      "name": "Artificial intelligence",
      "score": 0.25176429748535156
    },
    {
      "name": "Engineering",
      "score": 0.09968283772468567
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ]
}