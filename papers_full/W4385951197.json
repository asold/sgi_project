{
  "title": "TKG: Telecom Knowledge Governance Framework for LLM Application",
  "url": "https://openalex.org/W4385951197",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5077294086",
      "name": "Haoran Cai",
      "affiliations": [
        "Huawei Technologies (China)"
      ]
    },
    {
      "id": "https://openalex.org/A5100582810",
      "name": "Sijie Wu",
      "affiliations": [
        "Huawei Technologies (China)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6778883912",
    "https://openalex.org/W6849137788",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4309088836",
    "https://openalex.org/W4377865902",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4308949298",
    "https://openalex.org/W4200634402",
    "https://openalex.org/W4285294723",
    "https://openalex.org/W4362515116",
    "https://openalex.org/W4313433600",
    "https://openalex.org/W4285247752",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4327993492",
    "https://openalex.org/W4312122703",
    "https://openalex.org/W4283026156",
    "https://openalex.org/W4361866125"
  ],
  "abstract": "<title>Abstract</title> The emergence of ChatGPT and the competition among various Large Language Models have drawn significant attention from society. The success of Natural Language Processing (NLP) in the general field has captured the interest of researchers and engineers from academia and industry. In the telecom industry, Large Language Models (LLMs) have found extensive use in intelligent customer service and data search, contributing to the improvement of work efficiency in product delivery and operation. Nevertheless, it is important to note that while generic large models are versatile, their application to specific domains is hindered by the lack of high-quality domain-specific data. This often results in LLMs being unable to provide high-quality answers to specific problems. In this paper, we aim to investigate knowledge data governance in the telecom field, build high-quality domain-specific corpus, and utilize the dataset to fine-tune the large language model, which can enhance its ability to solve downstream practical problems such as Q\\&amp;A, search, and text generation. To address the challenge of model hallucination, we propose a data solution, namely Telecom Knowledge Governance (TKG), for intelligent application scenarios. TKG constructs a large-scale telecom domain corpus that ensures the accessed data is up-to-date, comprehensive, and of the highest quality. Moreover, we recruit five technical experts in the telecom field and develop automated generation tools to create a high-quality telecom Q\\&amp;A dataset that includes over 100,000 domain-specific questions and answers. Finally, we use this dataset to fine-tune the model, allowing it to learn how to apply telecom knowledge to specific scenarios more effectively. The results show that our knowledge data can greatly improve the model performance.",
  "full_text": "TKG: Telecom Knowledge Governance Framework\nfor LLM Application\nHaoran Cai \nHuawei Technologies (China)\nSijie Wu \nHuawei Technologies (China)\nResearch Article\nKeywords: Knowledge Data Governance, Large Language Model, Data-Centric AI.\nPosted Date: August 17th, 2023\nDOI: https://doi.org/10.21203/rs.3.rs-3252192/v1\nLicense:   This work is licensed under a Creative Commons Attribution 4.0 International License.  \nRead Full License\nAdditional Declarations: No competing interests reported.\nTKG: Telecom Knowledge Governance Framework for LLM\nApplication\nHaoran Cai and Sijie Wu\nHuawei Technologies Co., Ltd, Nanjing, 210012, China.\n*Corresponding author(s). E-mail(s): caihaoran1@huawei.com;\nContributing authors: wusijie6@huawei.com;\nAbstract\nThe emergence of ChatGPT and the competition among various Larg e Language Models have drawn\nsigniﬁcant attention from society. The success of Natural Lang uage Processing (NLP) in the general\nﬁeld has captured the interest of researchers and engineers from acad emia and industry. In the telecom\nindustry, Large Language Models (LLMs) have found extensive us e in intelligent customer service and\ndata search, contributing to the improvement of work eﬃciency in product delivery and operation.\nNevertheless, it is important to note that while generic large mo dels are versatile, their application\nto speciﬁc domains is hindered by the lack of high-quality dom ain-speciﬁc data. This often results in\nLLMs being unable to provide high-quality answers to speciﬁc p roblems.\nIn this paper, we aim to investigate knowledge data governance in the telecom ﬁeld, build high-\nquality domain-speciﬁc corpus, and utilize the dataset to ﬁn e-tune the large language model, which\ncan enhance its ability to solve downstream practical problems such as Q&A, search, and text gener-\nation. To address the challenge of model hallucination, we pro pose a data solution, namely Telecom\nKnowledge Governance (TKG), for intelligent application sce narios. TKG constructs a large-scale tele-\ncom domain corpus that ensures the accessed data is up-to-date , comprehensive, and of the highest\nquality. Moreover, we recruit ﬁve technical experts in the teleco m ﬁeld and develop automated gener-\nation tools to create a high-quality telecom Q&A dataset that includes over 100,000 domain-speciﬁc\nquestions and answers. Finally, we use this dataset to ﬁne-tu ne the model, allowing it to learn how to\napply telecom knowledge to speciﬁc scenarios more eﬀectively . The results show that our knowledge\ndata can greatly improve the model performance.\nKeywords: Knowledge Data Governance, Large Language Model, Data-Centric AI.\n1 Introduction\nIn recent years, due to the rapid growth of large\ncorpus and hardware capacities, researchers have\ndiscovered that scaling up models and training\ndata can continuously enhance model capacity,\nleading to the emergence of Large Language Mod-\nels (LLMs) [\n9, 17], such as GPT-3 [ 7] (175B\nparameters), PaLM [ 8] (540B parameters), and\nLLaMA [ 16] (65B parameters). LLMs have made\nsigniﬁcant contributions to the ﬁeld of natural lan-\nguage processing (NLP), providing a task-agnostic\nfoundation for a wide range of applications. The\nversatility of LLMs as general problem solvers has\nsparked the interest of researchers to investigate\ntheir capabilities beyond their traditional use as\nchatbots. Speciﬁcally, there has been a growing\ntrend in employing LLMs as assistants or even\n1\nreplacements for domain experts and tools in var-\nious specialized domains, including healthcare [\n4],\nﬁnance [ 19], and education [ 6].\nDespite their impressive performance in var-\nious natural language processing tasks, exist-\ning general LLMs often exhibit poor accuracy\nwhen applied directly to domain-speciﬁc problem-\nsolving, such as those in the telecommunications\nﬁeld. In particular, LLMs struggle to provide\nsound advice on equipment fault diagnosis and\nmarketing strategy due to their lack of knowl-\nedge in the telecom ﬁeld. This limitation is mainly\nattributed to two factors. Firstly, LLMs are pri-\nmarily pre-trained on general corpora [\n7, 15], such\nas Common Crawl and Wikipedia, which oﬀer\nlimited exposure to domain-speciﬁc resources. In\ntelecommunications, there exist numerous man-\nuals, delivery documents, and fault diagnosis\ncases related to communication equipment, which\nLLMs are not trained to handle. Secondly, the\nstrategies to analyze and solve domain-speciﬁc\ntasks can diverge signiﬁcantly from what the\nmodel has encountered within general domains.\nFor instance, our scenario focuses on device con-\nﬁguration search, fault diagnosis guidance, and\nmarketing strategy decision-making, all of which\nrequire domain-speciﬁc knowledge that LLMs may\nnot possess.\nHowever, it is challenging to prepare data for\nLLMs in the telecommunications ﬁeld for the fol-\nlowing three reasons. (1) Data in the telecommu-\nnications ﬁeld is rapidly evolving. In the telecom-\nmunications ﬁeld, new technologies, services, and\nstandards are introduced regularly. For a telecom-\nmunications company, its products are updated\nfrequently. Frequent model retraining results in\nsigniﬁcant costs. One approach is to search the\nknowledge base and send the results to LLMs for\nsummarizing [\n13], but this method requires con-\ntinuous updating of the knowledge database to\nensure that it remains current and relevant. (2)\nData quality in the telecommunications ﬁeld is\nlow. First, the raw data contains a lot of redun-\ndant content, which can make the training pro-\ncess unstable [\n20, 23]. Second, domain knowledge\nincludes a large number of tables, and the format\nof the tables is complex. Finally, data within the\ncompany may contain a lot of private information\nof employees. (3) Data annotation in the telecom-\nmunications ﬁeld heavily relies on the expertise of\ndomain experts [\n7]. The telecommunications ﬁeld\nis characterized by a vast array of technical terms\nand jargon that can be diﬃcult to understand\nfor individuals outside the ﬁeld. Constructing a\nlarge amount of high-quality annotating data by\ndomain experts is very time-consuming while it is\nhard to annotate data automatically. Addressing\nthese challenges requires extensive domain knowl-\nedge and a continuous update of the knowledge\ndatabase.\nTo address these challenges, in this paper,\nwe present the TKG (Telecom Knowledge Gov-\nernance) framework, which oﬀers a solution\nfor knowledge data governance in the telecom\ndomain. The objective of this framework is to pro-\nvide LLMs (large language models) with the lat-\nest, most comprehensive, and high-quality knowl-\nedge data to enhance their performance. To\nachieve this, we ﬁrst construct a structured knowl-\nedge database that can access and parse hundreds\nof thousands of source documents and case data,\nensuring that the data is current and reliable.\nThe database can support knowledge search and\nincrease the credibility of the search result by pro-\nviding engineers with up-to-date information that\ncan prevent mistakes in device deployment and\noperation scenarios. Then, we leverage the knowl-\nedge database to create a domain-speciﬁc model\npre-training corpus that incorporates the rele-\nvant terminology, concepts, and domain knowl-\nedge of the telecommunications industry. This\nprocess involves data cleaning and data dedu-\nplication. Additionally, we design an automated\nmethod to construct a ﬁne-tuning dataset, which\ncontains more than 100,000 question and answer\npairs. This dataset is used to ﬁne-tune the base\nmodel. Results show that our high-quality data\ncan greatly improve the model performance.\nSpeciﬁcally, this paper makes the following\ncontributions:\n• We propose and implement the TKG frame-\nwork, which serves as a solution for knowledge\ndata governance in the telecom domain. Our\nframework supports LLM applications in tele-\ncom domain scenarios, such as search, Q&A,\nand content creation.\n• We collect a substantial amount of structured\nknowledge data, totaling 130 million records.\nWe also construct over 100,000 Q&A pairs,\n2\nincluding rich product information in the tele-\ncom domain and the experience of delivery and\noperation experts.\n• We conduct experiments to assess the impact\nof data quality on the performance of existing\nLLMs. We show that ﬁne-tuned models with\nour data can provide high-quality services that\nare comparable to those provided by domain\nexperts.\nThe rest of the paper is organized as fol-\nlows. Section 2 reviews the related work. Section\n3 presents our motivation. Section 4 presents the\ndesign of TKG framework. Section 5 evaluates our\ndesign. Section 6 concludes the paper.\n2 Related Work\nCurrently, the industry has introduced multiple\nlarge models in diﬀerent domains, such as Fin-\nBert [\n3] in ﬁnance, Huatuo [ 4] in healthcare, TAL-\nEduBERT [ 6] in education, and LaWGPT [ 5] in\nlegal industry. These models are mostly retrained\nbased on the basic models through collecting cor-\npora from various domains and ﬁne-tuned with\nhigh-quality tuning datasets to adapt to down-\nstream tasks. However, we focus more on the\ndimension of data, emphasizing data quality, real-\ntime availability, and data governance to address\nthe challenges posed by complex and diverse data\ntypes and sources, and to build the ﬁrst knowledge\ndatabase in the telecommunications domain.\nRecently, the role of data in AI has been signif-\nicantly magniﬁed, giving rise to the emerging con-\ncept of data-centric AI [\n11, 14, 18, 22]. In the con-\nventional model-centric AI lifecycle, researchers\nand developers primarily focus on identifying more\neﬀective models to improve AI performance while\nkeeping the data largely unchanged. However, this\nmodel-centric paradigm overlooks the potential\nquality issues and undesirable ﬂaws of data, such\nas missing values, incorrect labels, and anoma-\nlies. Complementing the existing eﬀorts in model\nadvancement, data-centric AI emphasizes the sys-\ntematic engineering of data to build AI systems,\nshifting our focus from model to data. In this\nwork, we also refer to the DCAI framework and\nfocus on several aspects including data collection,\ndata cleaning, data quality assurance, etc. At the\nsame time, we also incorporate traditional data\nFig. 1 Issues of the telecom data\ngovernance methodology to ensure that our tele-\ncom domain data management is carried out in\nan orderly manner and provide a guideline for\nknowledge data governance in the industry.\n3 Motivation\nThe application of LLMs to the telecommunica-\ntions domain is a complex process that is highly\ndependent on the quantity and quality of knowl-\nedge data available for training. However, after we\ncarefully review the telecommunication data, we\nﬁnd that the data preparation stage presents sev-\neral challenges that must be addressed to ensure\nthe performance of the model.\nFirstly, our telecommunications service\ndomain includes 8 major commercial product\nsolutions and over 280 systems, each of which\ngenerates countless document data. However,\nalthough some structured data has entered the\ncompany’s data lake, the vast majority of unstruc-\ntured data assets are scattered across diﬀerent\ndepartments. Currently, we lack a uniﬁed knowl-\nedge database to collect, parse, and store this\ndata, resulting in an inability to fully leverage the\nvalue of the data.\nWe have collected a large amount of unstruc-\ntured knowledge data from diﬀerent departments,\nincluding the company’s product documents and\ncase experience from front-line engineers. There\nare many types of unstructured data, such as\nhdx ﬁles, word ﬁles, excel spreadsheets, pdf docu-\nments, and so on. Table\n1 shows the type distribu-\ntion of the collected data. An urgent need exists\nfor a tool to parse these data into structured data\nand keep the data up to date.\nSecondly, although the amount of data is large,\nthe quality of data is usually low. After parsing the\ndata into structured format, we cannot directly\n3\nTable 1 Data type distribution\nType hdx word ppt pdf excel video html\nNumber 94.46% 5.08% 0.19% 0.16% 0.06% 0.01% 0.01%\ntrain the model with these data. We review the\ndata and present the data quality problem in\nFig.\n1. We ﬁnd that the repetitive rate of data\nin the telecommunications ﬁeld is very high. The\nproportion of duplicate content in the 1.3 billion\nparsed data is about 89%. That is because we split\nthe product document into atomic knowledge by\nthe minimum section, and there can be a lot of\nsimilar content in diﬀerent documents. The dupli-\ncate data will greatly aﬀects the stability of the\nmodel [\n20]. In addition, there are also many other\nserious problems, such as incomplete and insecure\ncontents. Please note that one data record can\nhave more than one issues, so the sum of the values\nis large than 1. It is not hard to see that designing\na data governance framework for improving data\nquality is essential for enhancing the performance\nof large models.\nFinally, the generation of domain ﬁne-tuning\ndataset relies heavily on expert experience. Ope-\nnAI has invested a lot of research personnel and\nexperts in data annotation [\n7]. However, it should\nbe noted that telecommunication data diﬀers sig-\nniﬁcantly from general information, posing unique\nchallenges for data analysis and modeling. A vast\narray of technical terms and jargon make it diﬃ-\ncult, if not impossible, for people outside the ﬁeld\nto annotate the data. While at the same time, if we\nask domain experts to carefully select and revise\neach data to ensure the answer is as expected, the\ncost of time and money is unacceptable. Design-\ning a method for automatic annotation of domain\ndata is crucial.\nHence, our objective is to design a telecommu-\nnication knowledge data governance framework,\nwhich enables continuous ingestion and parsing of\ndomain data, improves data quality, and achieves\nautomatic domain data annotation.\n4 TKG Framework\n4.1 Overview\nTo address the aforementioned challenges, we pro-\npose the TKG framework, a solution for knowl-\nedge data governance in the telecom domain,\nensuring high-quality data for LLM applications\nin speciﬁc scenarios such as document search,\nQ&A, and content generation. The detail of this\nframework is shown in Figure\n2.\nStandard Guideline is a guidance methodol-\nogy that we have developed based on traditional\ndata governance practices. This module provides\nclear requirements for data standards and speciﬁc\nattributes, and is synchronized with knowledge\nproducers and accessors. The Integrator is used\nto access knowledge from multiple data sources.\nFor each data source, we can customize the con-\nﬁguration of the data update cycle and access\nmethod (such as oﬄine or online) by adjusting the\nparameters.\nBased on the Guideline’s contents, the Parser\nmodule is developed, consisting of several data\nparsing plugins for various types of documents.\nThese plugins can automatically convert ﬁles such\nas pdf, doc, ppt, and hdx into structured ﬁles in a\nuniﬁed json format. Through adaptive matching of\ndocument types, the Parser selects the appropriate\nparsing plugins.\nTo improves the data quality, we propose the\nFilter and Deduplicator modules to ﬁlter and\nremove duplicate content in the structured docu-\nment database. These pre-processed high-quality\ndata will be used to build a domain pre-training\ndataset for LLM, known as the Pre-training\nDatabase. In addition to the quality of the data\nitself, the diversity of the data also has a signif-\nicant impact on the quality of the training set.\nTherefore, we have designed a rule-based classiﬁ-\ncation method to classify data according to data\napplication scenarios and sources.\nThe Extractor can automatically generate\nquestion-answer(Q&A) pairs from the high-\nquality database as a ﬁne-tuning dataset for the\ndomain-speciﬁc large model, which forms the\nFine-tuned Database. This module requires the\ninvolvement of experts in the telecom ﬁeld to check\nthe quality of the generated data.\nThe Scheduler is responsible for executing and\nmanaging resources for the above-mentioned mod-\nules, ensuring stable and eﬃcient system opera-\ntion.\n4\nFig. 2 TKG framework\nAdditionally, to more intuitively display the\ndata distribution and quality information, we\nselect multiple indicator metrics related to data\nquality, and present them in the visualization sys-\ntem. Next, we will present some key aspects of the\nframework in detail.\n4.2 Data Parsing\nIn order to fully explore the value of data,\nour data governance framework ﬁrst parses non-\nstructured documents into textual data. In the\nparsing phase, we use several open-source libraries\nsuch as Apache Tika [\n1]. First, the non-structured\ndocuments are converted to text. Then, we use\nregular expressions and natural language process-\ning techniques to extract relevant information\nfrom the text.\nSpeciﬁcally, for documents such as pdf, doc,\nand hdx, we split the article into multiple small\nstructured ﬁles, which we call atomic ﬁles. The\ngranularity of splitting is the smallest chapter of\nthe document, which includes attributes such as\ntitle and content.\nUnlike the general domain, the telecom domain\nknowledge includes a large amount of tabular\ndata. If this part of data is directly dropped dur-\ning data processing, domain knowledge will be\nlost. However, only extract the text data in the\ntable is unable to restore semantics. In order to\nmake full use of the data in the tables, we have\ndesigned a table parsing method. By extracting\nand concatenating the table title, table header,\nand speciﬁc table content, we can form the data\ninto semantically clear sentences or phrases.\nFinally, we store the parsed structured ﬁles in\nMongoDB, called the Structured Database. The\nstructured data is stored in MongoDB. Each data\nrecords contains many ﬁelds, such as\nid, content,\nﬁle name, ﬁle type, product line, and language,\nwhere the content ﬁeld stores the valuable knowl-\nedge. This allows us to easily query and retrieve\nthe data for further analysis. We also build multi-\nple indexing strategies based on Elasticsearch (ES)\nto accelerate database retrieval. Based on this, we\nidentify many quality issues in the original parsed\ndata as show in Fig.\n1.\n4.3 Data Cleaning\nThe process of data cleaning involves two key\naspects of processing. The ﬁrst aspect pertains\nto heuristic text ﬁltering. In light of the issues\nthat are identiﬁed during the early stages of the\nknowledge data analysis, we develop eﬀective rules\nto identify and ﬁlter out low-quality data. These\nrules include ﬁltering out data with empty con-\ntent ﬁelds, content containing garbled characters,\nor content that is too short. Additionally, we\nimplement measures to prevent the leakage of\nknowledge assets by ﬁltering out data with high\nsecurity classiﬁcation.\nThe second aspect of data cleaning entails\nprivacy data processing. The domain knowledge\ndata may contain sensitive information such as\nemployee id numbers, names, and phone num-\nbers. To address this, we employ regular expres-\nsion matching methods to detect and locate such\nsensitive data. We then proceed to remove any\nsentences that contain such data to protect the\nprivacy of individuals involved.\n4.4 Data Deduplication\nDuplicate data poses a signiﬁcant challenge to\ndeveloping accurate and diverse language models.\nThe presence of such data can reduce the vari-\nety of the corpus, leading to instability during\nmodel training, ultimately impacting the overall\n5\nperformance of the model. To address this issue,\nwe employ the MinHashLSH algorithm in the dis-\ntributed big data processing system Spark [\n21] to\ndeduplicate data. MinHashLSH is a powerful text\ndeduplication algorithm that utilizes minimum\nhashing and locality-sensitive hashing techniques\nto compare similarity between texts through their\nnumerical representations.\nWe ﬁrst preprocess the text data using the\nJieba segmentation tool, which involves segment-\ning the text and eliminating punctuation and stop\nwords. Next, we transform the segmented text\ninto vector representations and calculate the hash\nvalues of feature vectors using multiple hash func-\ntions. We then employ the LSH model to compare\nthe similarity of text data based on Jaccard sim-\nilarity. We determine that text with a similarity\nscore above a predetermined threshold is con-\nsidered as similar data and, thus, retained only\none copy of it. Algorithm\n1 describes the Min-\nHashLSH in detail. However, computing the simi-\nlarity between all data can be time-consuming. To\novercome this challenge, we conduct the dedupli-\ncation process in batches, thereby improving the\nspeed of the process.\nAlgorithm 1 MinHashLSH Algorithm for Data\nDeduplication in Spark\nRequire: MongoDB data, content ﬁeld\nEnsure: Deduplicated data based on content\nﬁeld\n1: Initialize Spark session\n2: Read data from MongoDB\n3: Tokenize content ﬁeld into shingles\n4: for each shingle do\n5: Compute minhash signature\n6: end for\n7: Initialize MinHashLSH model with input\nparameters\n8: Fit the MinHashLSH model on the dataset\nwith computed minhash signatures\n9: Perform approximate similarity join using the\nﬁtted MinHashLSH model\n10: Set a similarity threshold to remove duplicates\n11: Filter out the results with similarity greater\nthan the threshold\n12: Return the deduplicated data\n4.5 Dataset Extraction\nThe case library data in the company contains a\ncollection of problems encountered by front-line\nengineers in their work, along with their corre-\nsponding solutions. The case data provides key\nﬁeld information such as the problem descrip-\ntion and solution process which naturally possess\nQ&A attributes. To extract Q&A pairs from this\ndata, we developed a Python script that auto-\nmatically extracts the ’problem description’ ﬁeld\nas the question and the ’solution process’ ﬁeld as\nthe answer. However, due to the length limit dur-\ning large model ﬁne-tuning, we ﬁltered out Q&A\npairs with an answer length exceeding 1024. The\ngenerated data was stored in JSON format, which\nresulted in a total of 90,000 Q&A pairs.\nAlternatively, existing open-source large mod-\nels possess strong text understanding and gener-\nation capabilities, and can automatically extract\nand generate Q&A pairs from text data. To utilize\nthis approach, we constructed a prompt template\nto elicit Q&A pairs using ChatGLM, a popu-\nlar large language model. We then integrated\nthe knowledge data into the prompt template\nas the ﬁnal prompt input to ChatGLM, which\nallowed the model to generate 1-2 Q&A pairs\nfrom each piece of knowledge data. Accordingly,\nwe construct 10,000 Q&A pairs with the help of\nChatGLM model. The generated Q&A pairs were\ncollected and stored in a JSON ﬁle for later use.\nAccordingly, we build a dataset with 100,000 Q&A\npairs in total.\n5 Evaluation\nIn this section, we ﬁrst describe the experimen-\ntal setup used to evaluate the performance of\nour proposed data governance framework, then we\npresent the evaluation results.\n5.1 Experiment Setup\nWe conducted our experiments on a cluster of\nmachines with high-end hardware. We deploy our\nTKG framework on a cluster with 8 nodes. Mon-\ngoDB cluster has 3 nodes and Spark cluster has 5\nworker nodes. Each node is equipped with two 16-\ncore Intel 2.60 GHz Xeon(R) E5-2697A processors,\n128 GB memory, a 10 Gbps NIC.\nWe use the ChatGLM-6B model [\n2] for our\nexperiments, which is a large-scale language model\n6\nTable 2 Data comparition\nsize records repetitive incomplete invalid insecure\nOriginal 735GB 135,756,975 121,746,855 19,874,821 746,663 8,335,478\nTKG 83GB 9,763,410 0 0 0 0\nthat has been pre-trained on a massive Chinese\ncorpus of text data. We ﬁne-tune the ChatGLM-\n6B model on 8 NVIDIA V100 GPUs with our\ndataset using the PyTorch framework. To acceler-\nate the ﬁne-tuning process, we use the P-tuning-v2\nmethod [\n12] proposed by the authors of GLM\nmodel [ 10].\nWe use several common metrics to evaluate\nthe quality of the data produced by our proposed\nTKG framework. First, we review the size and\nthe quality problem, e.g., the number of repeti-\ntive records, of the dataset after pre-processing by\nthe framework. Second, we measured the training\nloss of the model during the ﬁne-tuning process,\nwhich is an important indicator of the model’s\nconvergence and generalization ability. Addition-\nally, we used the Bleu and Rouge metrics to\nevaluate the quality of the generated text. These\nmetrics are commonly used in natural language\nprocessing tasks to measure the overlap between\nthe generated text and the reference text.\nFor the ﬁne-tuning process, we use a large and\na small datasets, which contains 100,000 and 2,000\nof question and answer pairs, respectively. The\nformer dataset is constructed by our automated\nmethod, while the latter dataset is a high-quality\nsubset of the former one, carefully selected by our\ndomain experts. We randomly split each dataset\ninto training, validation, and testing sets, with\n80%, 10%, and 10% of the data, respectively. We\nused the training set to ﬁne-tune the model, and\nthe validation set to monitor the training progress\nand select the best model based on the validation\nloss. Finally, we evaluated the performance of the\nbest model on the test set.\nTo ensure the reproducibility of our experi-\nments, we use the same random seed for all exper-\niments and reported the average performance over\n5 runs. We use the Adam optimization algorithm,\na batch size of 32, a learning rate of 2e-5, and a\nmaximum sequence length of 1024 tokens for all\nexperiments.\n5.2 Results\nAfter the parsing of source unstructured data,\nwe improve the data quality by data cleaning\nand deduplication to form pre-training database.\nThen, we construct a ﬁne-tuning database for\nthe telecom domain. Accordingly, we presents the\nevaluation results on the two kinds of datasets,\nwhich reﬂects the performance of our data gover-\nnance framework.\n5.2.1 Data cleaning and deduplication\nThe data parsed from original unstructured data\ncontains 135,756,975 records. However, some seri-\nous problems exist in the dataset as shown in\nFig.\n1. We use a combination of rule-based and\nmachine learning-based methods for data cleaning\nand deduplication. The dataset is ﬁrst dedupli-\ncated with the MinHashLSH algorithm based on\nthe content ﬁeld, after which we are left with\n14,007,843 records. We then applied a set of\nrules to remove records that contained incomplete,\ninvalid, and insecure content. Further data clean-\ning resulted in 9,763,410 high-quality records that\ncan be used for pre-training telecom domain large\nlanguage model.\nTable\n2 compares the data before and after the\nprocessing of TKG framework. After the process-\ning of TKG framework, the data size is greatly\nreduced by 88.7%, but the quality issuses are\nall solved. The result shows that our proposed\ndata governance framework for large-scale models\nachieved promising results in both data cleaning\nand deduplication. The framework is able to eﬀec-\ntively handle a large-scale dataset and produce\nhigh-quality results.\n5.2.2 Model ﬁne-tuning\nWe ﬁne-tune the ChatGLM-6B model on the two\nﬁne-tuning datasets. Figure\n3 and 4 show the loss\ncurve during the ﬁne-tuning process. The training\nloss decrease steadily for both datasets, indicating\nthat the model is learning from the data. However,\nwe observe that the training loss decreases slower\n7\nFig. 3 Train loss using the large dataset Fig. 4 Train loss using the small dataset\nTable 3 Results of Model Fine-tuning\nmodel Bleu-4 Rouge-1 Rouge-2 Rouge-L\nChatGLM 2.35 17.69 2.01 8.16\nTKG-2k 12.55 33.48 14.29 24.82\nTKG-100k 2.36 18.37 3.09 8.09\nwhen using the larger dataset of 100,000 records\ncompared to the smaller dataset of 2,000 records.\nThere are two reasons for the results. First, the\nsame number of iterations on the smaller dataset\nof 2,000 records lead to a longer training time in\nterms of epochs. This is because each epoch covers\nfewer iterations on the smaller dataset. As a result,\nthe model is able to learn more from each record\nin the smaller dataset, leading to faster conver-\ngence and better performance. Second, the smaller\ndataset of 2,000 records is carefully selected from\nthe larger dataset of 100,000 records to contain\nonly high-quality records. In contrast, the larger\ndataset is produced by the automated method\nand contains many low-quality records, which may\nhave slowed down the ﬁne-tuning process.\nWe use the Bleu-4, Rouge-1, Rouge-2, and\nRouge-L scores to evaluate the the performance of\nthe two ﬁne-tuned model. The results are reported\nin Table\n3. ChatGLM indicates the original Chat-\nGLM model. TKG-2k and TKG-100k represents\nﬁne-tuned model with 2,000 and 100,000 reocords,\nrespectively. The Bleu-4 score is a measure of the\nn-gram overlap between the generated text and\nthe reference text, while the Rouge scores measure\nthe overlap of the longest common subsequence\nbetween the generated text and the reference text.\nThe result shows that our high-quality data can\nimprove the model performance by up to 7 × .\nWe found that using a smaller but higher-quality\ndataset can lead to better results compared to\nusing a larger dataset with more noise. These\nresults highlight the importance of data quality\nin the ﬁne-tuning process and the potential bene-\nﬁts of using data governance frameworks to ensure\nhigh-quality training data.\n6 Conclusion\nIn this paper, we carefully review the telecom\nknowledge data and design the TKG framework\nto assess and improve the knowledge data qual-\nity. The framework enables LLMs to access the\nlatest and most reliable knowledge data, enhanc-\ning their credibility and performance. Meanwhile,\nthe TKG framework can automatically construct\nﬁne-tuning corpus for LLMs. Experiment results\nshow that the TKG framework greatly improves\nthe data quality. The framework can be beneﬁcial\nfor engineers in the telecommunications industry.\nFurthermore, the methodology used in this frame-\nwork can be applied to other domains to enhance\nthe performance of large language models.\n8\nReferences\n[1] Apache tika. https://tika.apache.org/, 2023\n[2] Chatglm-6b. https://github.com/THUDM/\nChatGLM-6B, 2023\n[3] Finbert. https://github.com/ProsusAI/\nﬁnBERT, 2023\n[4] Huatuo. https://github.com/SCIR-HI/\nHuatuo-Llama-Med-Chinese , 2023\n[5] Lawgpt. https://github.com/pengxiao-song/\nLaWGPT, 2023\n[6] Tal-edubert. https://github.com/tal-tech/\nedu-bert, 2023\n[7] Brown, T., Mann, B., Ryder, N., Subbiah,\nM., Kaplan, J.D., Dhariwal, P., Neelakan-\ntan, A., Shyam, P., Sastry, G., Askell, A.,\net al.: Language models are few-shot learners.\nAdvances in neural information processing\nsystems 33, 1877–1901 (2020)\n[8] Chowdhery, A., Narang, S., Devlin, J.,\nBosma, M., Mishra, G., Roberts, A., Barham,\nP., Chung, H.W., Sutton, C., Gehrmann, S.,\net al.: Palm: Scaling language modeling with\npathways. arXiv preprint arXiv:2204.02311\n(2022)\n[9] Du, N., Huang, Y., Dai, A.M., Tong, S., Lep-\nikhin, D., Xu, Y., Krikun, M., Zhou, Y.,\nYu, A.W., Firat, O., Zoph, B., Fedus, L.,\nBosma, M.P., Zhou, Z., Wang, T., Wang,\nY.E., Webster, K., Pellat, M., Robinson,\nK., Meier-Hellstern, K.S., Duke, T., Dixon,\nL., Zhang, K., Le, Q.V., Wu, Y., Chen,\nZ., Cui, C.: Glam: Eﬃcient scaling of lan-\nguage models with mixture-of-experts. In:\nInternational Conference on Machine Learn-\ning, ICML 2022, 17-23 July 2022, Baltimore,\nMaryland, USA. vol. 162, pp. 5547–5569\n(2022)\n[10] Du, Z., Qian, Y., Liu, X., Ding, M., Qiu, J.,\nYang, Z., Tang, J.: GLM: general language\nmodel pretraining with autoregressive blank\ninﬁlling. In: Proceedings of the 60th Annual\nMeeting of the Association for Computa-\ntional Linguistics (Volume 1: Long Papers),\nACL 2022, Dublin, Ireland, May 22-27, 2022.\npp. 320–335 (2022)\n[11] Jakubik, J., V¨ ossing, M., K¨ uhl, N., Walk,\nJ., Satzger, G.: Data-centric artiﬁcial intel-\nligence. arXiv preprint arXiv:2212.11854\n(2022)\n[12] Liu, X., Ji, K., Fu, Y., Tam, W., Du, Z.,\nYang, Z., Tang, J.: P-tuning: Prompt tuning\ncan be comparable to ﬁne-tuning across scales\nand tasks. In: Proceedings of the 60th Annual\nMeeting of the Association for Computa-\ntional Linguistics (Volume 2: Short Papers),\nACL 2022, Dublin, Ireland, May 22-27, 2022.\npp. 61–68 (2022)\n[13] Nakano, R., Hilton, J., Balaji, S., Wu,\nJ., Ouyang, L., Kim, C., Hesse, C., Jain,\nS., Kosaraju, V., Saunders, W., Jiang, X.,\nCobbe, K., Eloundou, T., Krueger, G., But-\nton, K., Knight, M., Chess, B., Schul-\nman, J.: Webgpt: Browser-assisted question-\nanswering with human feedback. CoRR\nabs/2112.09332 (2021)\n[14] Polyzotis, N., Zaharia, M.: What can data-\ncentric ai learn from data and ml engineering?\narXiv preprint arXiv:2112.06439 (2021)\n[15] Raﬀel, C., Shazeer, N., Roberts, A., Lee, K.,\nNarang, S., Matena, M., Zhou, Y., Li, W.,\nLiu, P.J.: Exploring the limits of transfer\nlearning with a uniﬁed text-to-text trans-\nformer. J. Mach. Learn. Res. 21, 140:1–140:67\n(2020)\n[16] Touvron, H., Lavril, T., Izacard, G., Mar-\ntinet, X., Lachaux, M.A., Lacroix, T.,\nRozi` ere, B., Goyal, N., Hambro, E., Azhar,\nF., et al.: Llama: Open and eﬃcient foun-\ndation language models. arXiv preprint\narXiv:2302.13971 (2023)\n[17] Wei, J., Tay, Y., Bommasani, R., Raﬀel,\nC., Zoph, B., Borgeaud, S., Yogatama, D.,\nBosma, M., Zhou, D., Metzler, D., et al.:\nEmergent abilities of large language models.\narXiv preprint arXiv:2206.07682 (2022)\n9\n[18] Whang, S.E., Roh, Y., Song, H., Lee, J.G.:\nData collection and quality challenges in deep\nlearning: A data-centric ai perspective. The\nVLDB Journal pp. 1–23 (2023)\n[19] Wu, S., Irsoy, O., Lu, S., Dabravolski, V.,\nDredze, M., Gehrmann, S., Kambadur, P.,\nRosenberg, D.S., Mann, G.: Bloomberggpt:\nA large language model for ﬁnance. CoRR\nabs/2303.17564 (2023)\n[20] Xue, F., Fu, Y., Zhou, W., Zheng, Z., You,\nY.: To repeat or not to repeat: Insights\nfrom scaling LLM under token-crisis. CoRR\nabs/2305.13230 (2023)\n[21] Zaharia, M., Chowdhury, M., Das, T., Dave,\nA., Ma, J., McCauly, M., Franklin, M.J.,\nShenker, S., Stoica, I.: Resilient distributed\ndatasets: A fault-tolerant abstraction for in-\nmemory cluster computing. In: Proceedings\nof the 9th USENIX Symposium on Net-\nworked Systems Design and Implementation,\nNSDI 2012, San Jose, CA, USA, April 25-27,\n2012. pp. 15–28 (2012)\n[22] Zha, D., Bhat, Z.P., Lai, K.H., Yang,\nF., Jiang, Z., Zhong, S., Hu, X.: Data-\ncentric artiﬁcial intelligence: A survey. arXiv\npreprint arXiv:2303.10158 (2023)\n[23] Zhao, W.X., Zhou, K., Li, J., Tang, T., Wang,\nX., Hou, Y., Min, Y., Zhang, B., Zhang, J.,\nDong, Z., Du, Y., Yang, C., Chen, Y., Chen,\nZ., Jiang, J., Ren, R., Li, Y., Tang, X., Liu,\nZ., Liu, P., Nie, J., Wen, J.: A survey of large\nlanguage models. CoRR abs/2303.18223\n(2023)\n10",
  "topic": "Corporate governance",
  "concepts": [
    {
      "name": "Corporate governance",
      "score": 0.687603771686554
    },
    {
      "name": "Telecommunications",
      "score": 0.6186621189117432
    },
    {
      "name": "Business",
      "score": 0.5353766679763794
    },
    {
      "name": "Computer science",
      "score": 0.22638991475105286
    },
    {
      "name": "Finance",
      "score": 0.08564704656600952
    }
  ]
}