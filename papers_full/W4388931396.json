{
  "title": "Exploring large language model for next generation of artificial intelligence in ophthalmology",
  "url": "https://openalex.org/W4388931396",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2117327603",
      "name": "Kai Jin",
      "affiliations": [
        "Second Affiliated Hospital of Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2098733522",
      "name": "Lu Yuan",
      "affiliations": [
        "National Research Center for Maternal and Child Health",
        "Children's Hospital of Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A3211779617",
      "name": "Hongkang Wu",
      "affiliations": [
        "Second Affiliated Hospital of Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A1854755823",
      "name": "Andrzej Grzybowski",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2131681556",
      "name": "Juan Ye",
      "affiliations": [
        "Second Affiliated Hospital of Zhejiang University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4292858576",
    "https://openalex.org/W4324308091",
    "https://openalex.org/W4378783137",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4321606060",
    "https://openalex.org/W4375850424",
    "https://openalex.org/W4368340908",
    "https://openalex.org/W4381092249",
    "https://openalex.org/W4367175039",
    "https://openalex.org/W4386046428",
    "https://openalex.org/W4376133327",
    "https://openalex.org/W4367394076",
    "https://openalex.org/W4324020464",
    "https://openalex.org/W4379209901",
    "https://openalex.org/W4366368023",
    "https://openalex.org/W4221114274",
    "https://openalex.org/W4378348076",
    "https://openalex.org/W4382517681",
    "https://openalex.org/W4297377503",
    "https://openalex.org/W4366753179",
    "https://openalex.org/W4367834585",
    "https://openalex.org/W4367669592",
    "https://openalex.org/W4386110374",
    "https://openalex.org/W4379094566",
    "https://openalex.org/W4366209204",
    "https://openalex.org/W4200594589",
    "https://openalex.org/W4367059909",
    "https://openalex.org/W4226140336",
    "https://openalex.org/W4323030608",
    "https://openalex.org/W2107455939",
    "https://openalex.org/W3203201400",
    "https://openalex.org/W3119161812",
    "https://openalex.org/W4365514412",
    "https://openalex.org/W4210951263",
    "https://openalex.org/W4304758302",
    "https://openalex.org/W4353015365",
    "https://openalex.org/W4381309537",
    "https://openalex.org/W4381384296",
    "https://openalex.org/W4378172691",
    "https://openalex.org/W3192447662",
    "https://openalex.org/W4318069287",
    "https://openalex.org/W3038901217",
    "https://openalex.org/W2888109941",
    "https://openalex.org/W4200299622",
    "https://openalex.org/W4205723032",
    "https://openalex.org/W4200295368",
    "https://openalex.org/W4317853296",
    "https://openalex.org/W4380872237",
    "https://openalex.org/W3083027974",
    "https://openalex.org/W4381487488",
    "https://openalex.org/W4290613782"
  ],
  "abstract": "In recent years, ophthalmology has advanced significantly, thanks to rapid progress in artificial intelligence (AI) technologies. Large language models (LLMs) like ChatGPT have emerged as powerful tools for natural language processing. This paper finally includes 108 studies, and explores LLMs’ potential in the next generation of AI in ophthalmology. The results encompass a diverse range of studies in the field of ophthalmology, highlighting the versatile applications of LLMs. Subfields encompass general ophthalmology, retinal diseases, anterior segment diseases, glaucoma, and ophthalmic plastics. Results show LLMs’ competence in generating informative and contextually relevant responses, potentially reducing diagnostic errors and improving patient outcomes. Overall, this study highlights LLMs’ promising role in shaping AI’s future in ophthalmology. By leveraging AI, ophthalmologists can access a wealth of information, enhance diagnostic accuracy, and provide better patient care. Despite challenges, continued AI advancements and ongoing research will pave the way for the next generation of AI-assisted ophthalmic practices.",
  "full_text": "Frontiers in Medicine 01 frontiersin.org\nExploring large language model \nfor next generation of artificial \nintelligence in ophthalmology\nKai Jin 1†, Lu Yuan 2†, Hongkang Wu 1, Andrzej Grzybowski 3 and \nJuan Ye 1*\n1 Eye Center, The Second Affiliated Hospital, School of Medicine, Zhejiang University, Hangzhou, China, \n2 Department of Ophthalmology, The Children's Hospital, Zhejiang University School of Medicine, \nNational Clinical Research Center for Child Health, Hangzhou, China, 3 Institute for Research in \nOphthalmology, Foundation for Ophthalmology Development, Poznan, Poland\nIn recent years, ophthalmology has advanced significantly, thanks to rapid \nprogress in artificial intelligence (AI) technologies. Large language models (LLMs) \nlike ChatGPT have emerged as powerful tools for natural language processing. \nThis paper finally includes 108 studies, and explores LLMs’ potential in the next \ngeneration of AI in ophthalmology. The results encompass a diverse range of \nstudies in the field of ophthalmology, highlighting the versatile applications of \nLLMs. Subfields encompass general ophthalmology, retinal diseases, anterior \nsegment diseases, glaucoma, and ophthalmic plastics. Results show LLMs’ \ncompetence in generating informative and contextually relevant responses, \npotentially reducing diagnostic errors and improving patient outcomes. Overall, \nthis study highlights LLMs’ promising role in shaping AI’s future in ophthalmology. \nBy leveraging AI, ophthalmologists can access a wealth of information, enhance \ndiagnostic accuracy, and provide better patient care. Despite challenges, \ncontinued AI advancements and ongoing research will pave the way for the next \ngeneration of AI-assisted ophthalmic practices.\nKEYWORDS\nartificial intelligence, large language model, ChatGPT, ophthalmology, diagnostic \naccuracy and efficacy\nIntroduction\nThe history of artificial intelligence (AI) in medicine dates back to the 1950s when \nresearchers began to explore the use of computers to analyze medical data and make \ndiagnostic decisions. However, past methods had limitations in accuracy and speed and \nstill could not analyze unstructured medical data ( 1). Natural Language Processing (NLP) \nis a subfield of AI that focuses on enabling computers to understand, interpret, and \ngenerate human language. It involves the development of algorithms and models that can \nprocess and analyze unstructured text data. Large Language Models (LLM) refer to \nadvanced artificial intelligence models, such as GPT-3 (Generative Pre-trained \nTransformer 3), that are built on transformer architecture. The transformer architecture \nis a deep learning model that efficiently captures context and dependencies in sequential \ndata, making it a fundamental choice for natural language processing tasks and beyond. \nThese models are trained on massive amounts of text data from the internet, enabling \nthem to generate human-like text and perform a wide range of NLP tasks with remarkable \naccuracy and versatility. ChatGPT builds on the capabilities of large language models to \nOPEN ACCESS\nEDITED BY\nHaoyu Chen,  \nThe Chinese University of Hong Kong, China\nREVIEWED BY\nJo-Hsuan \"Sandy\" Wu,  \nUniversity of California, San Diego,  \nUnited States  \nJana Lipkova,  \nUniversity of California, Irvine, United States\n*CORRESPONDENCE\nJuan Ye  \n yejuan@zju.edu.cn\n†These authors have contributed equally to this \nwork\nRECEIVED 09 September 2023\nACCEPTED 20 October 2023\nPUBLISHED 23 November 2023\nCITATION\nJin K, Yuan L, Wu H, Grzybowski A and \nYe J (2023) Exploring large language model for \nnext generation of artificial intelligence in \nophthalmology.\nFront. Med. 10:1291404.\ndoi: 10.3389/fmed.2023.1291404\nCOPYRIGHT\n© 2023 Jin, Yuan, Wu, Grzybowski and Ye. This \nis an open-access article distributed under the \nterms of the Creative Commons Attribution \nLicense (CC BY). The use, distribution or \nreproduction in other forums is permitted, \nprovided the original author(s) and the \ncopyright owner(s) are credited and that the \noriginal publication in this journal is cited, in \naccordance with accepted academic practice. \nNo use, distribution or reproduction is \npermitted which does not comply with these \nterms.\nTYPE Review\nPUBLISHED 23 November 2023\nDOI 10.3389/fmed.2023.1291404\nJin et al. 10.3389/fmed.2023.1291404\nFrontiers in Medicine 02 frontiersin.org\ngenerate coherent and contextually relevant responses, making it \nwell-suited for chatbot applications. It is designed to generate \nhuman-like responses to a wide range of prompts and questions \nand may enhance healthcare delivery and patients’ quality of life \n(Figure  1 ) ( 2). The use of LLMs in healthcare offers several \npotential benefits.\nChatGPT and LLMs can be applied in various ways. They can \nserve as clinical documentation aids, helping with administrative tasks \nsuch as clinic scheduling, medical coding for billing, and generating \npreauthorization letters (3). LLMs can also be used as summarization \ntools, improving communication with patients and assisting in clinical \ntrials. They can make processes such as curriculum design, testing of \nknowledge base, and continuing medical education more dynamic (4). \nLLMs can reduce the burden of administrative tasks for healthcare \nprofessionals, save time, and improve efficiency. They also have the \npotential to provide valuable clinical insights and support decision-\nmaking ( 5). This capability may help ophthalmologists enabling \nevidence-based decision-making and revolutionizing various aspects \nof eye care and research.\nMethod of literature search\nFor this review, we followed the Preferred Reporting Items for \nSystematic Reviews and Meta-Analyzes (PRISMA) guidelines.\nStudy selection and search strategy\nWe conducted a comprehensive literature search following the \nPRISMA guidelines. Searches were performed on PubMed and \nGoogle Scholar databases, spanning from January 2016 to June 2023. \nKeywords were selected from two distinct categories: ophthalmology-\nrelated terms (ophthalmology, eye diseases, eye disorders) and large \nlanguage model-related terms (large language models, ChatGPT, \nnatural language processing, chatbots). The search strategy involved \nthe use of the following keywords: (“Ophthalmology” OR “Eye \nDiseases” OR “Eye Disorders”) AND (“Large Language Models” OR \n“ChatGPT” OR “Natural Language Processing” OR “Chatbots”). The \nterms from each category were cross-referenced independently with \nterms from the other category.\nInclusion and exclusion criteria\nWe established specific inclusion criteria for article selection. The \npublication period considered research from January 2016 to June \n2023 to ensure the inclusion of up-to-date findings. Initially, 6,130 \narticles were identified through titles and abstracts. We prioritized \nresearch quality and the application of Large Language Models \n(LLMs) in our selection process. Additionally, articles published prior \nto 2016 were included for historical context and those pertinent to \nclosely related topics.\nIn the meantime, studies meeting the following criteria will \nbe excluded: (1) duplicate literature previously included in the review, \n(2) irrelevant topics, where the article is unrelated to ophthalmology \nor the application of the large language model, (3) conference \nabstracts, and (4) non-original research, such as editorials, case \nreports or commentaries.\nFIGURE 1\nWorkflow of large language model (LLM) for artificial intelligence (AI) in ophthalmology. Text (symptoms, medical history, etc.) and images (Optical \ncoherence tomography, Fundus fluorescein angiography, etc.) are encoded and fed into a model that has been trained on a large amount of data, \nwhich can decode the relevant information required. LLM applications include automated question-answering, diagnose, information screening, \nsummarization, image analysis, predictive modeling.\nAbbreviations: AI, Artificial Intelligence; NLP, Natural Language Processing; LLM, \nLarge Language Model; GPT, Generative Pre-trained Transformer; HER, Electronic \nHealth Records; eAMD, exudative Age-related Macular Degeneration; DR, Diabetic \nRetinopathy; OCT, Optical Coherence Tomography; BERT, Bidirectional Encoder \nRepresentations from Transformers.\nJin et al. 10.3389/fmed.2023.1291404\nFrontiers in Medicine 03 frontiersin.org\nLanguage considerations\nA comprehensive review was conducted primarily on English-\nlanguage articles, totaling 6,130 papers. Furthermore, we evaluated 14 \npapers predominantly published in Chinese. For articles in languages \nsuch as French, Spanish, and German, we assessed their abstracts. This \nmultilingual approach allowed us to comprehensively evaluate the \nliterature. The primary inclusion criterion required research to \nspecifically address the application of AI in ophthalmology and \ndemonstrate a certain level of perceived quality.\nData extraction and analysis\nFollowing a rigorous selection process, relevant data were \nextracted and analyzed from the selected articles. Key themes, trends, \nadvancements, and challenges related to the utilization of LLMs in \nophthalmology were systematically synthesized.\nIn accordance with the PRISMA guidelines, this review adhered \nto a structured and rigorous approach, encompassing a \ncomprehensive literature search, meticulous inclusion criteria, \nlanguage considerations, and thorough data extraction ( Figure 2). \nA total of 108 articles were independently screened for eligibility by \ntwo reviewers (Kai Jin and Lu Yuan), including assessments of titles \nand abstracts, followed by full-text review. Any disagreements were \nresolved through discussion with a third author (Juan Y e). \nUltimately, 108 studies were included in the review.\nResults\nWe finally included 108 studies. The results (Table 1) encompass \na diverse range of studies in the field of ophthalmology, highlighting \nthe versatile applications of LLMs. The results reflect a wide spectrum \nof LLM applications, and subfields of interest in ophthalmology. They \nshowcase the versatility of LLMs in addressing various aspects of \nautomated question-answering (55 studies), diagnose (5 studies), \ninformation screening (27 studies), summarization (5 studies), image \nanalysis (5 studies), predictive modeling (11 studies). Subfields \nencompass general ophthalmology (38 studies), retinal diseases (32 \nstudies), anterior segment diseases (27 studies), glaucoma (6 studies), \nand ophthalmic plastics (5 studies) (Figure 3).\nFIGURE 2\nPRISMA 2020 flow diagram for this systematic review.\nJin et al. 10.3389/fmed.2023.1291404\nFrontiers in Medicine 04 frontiersin.org\nTABLE 1 Summary of representative current studies using LLM in ophthalmology.\nReference Year Publication Subspeciality Aim Application Approaches\nLin et al. (6) 2023 Eye General ophthalmology To compare the performance \non a practice ophthalmology \nwritten examination\nAutomated question-\nanswering\nGPT-3.5, GPT-4\nAntaki et al. (7) 2023 Ophthalmology Science General ophthalmology To evaluate the performance \non ophthalmology questions\nAutomated question-\nanswering\nChatGPT\nCai et al. (8) 2023 American Journal of \nOphthalmology\nGeneral ophthalmology To compare the performance \non ophthalmology board-style \nquestions.\nAutomated question-\nanswering\nBing Chat, ChatGPT 3.5, \nand ChatGPT 4.0,\nMihalache et al. (9) 2023 JAMA Ophthalmology General ophthalmology To assess the performance on \nboard certification exam in \nophthalmology\nAutomated question-\nanswering\nChatGPT\nBernstein et al. (10) 2023 JAMA Network Open General ophthalmology To generate ophthalmology \nadvice\nAutomated question-\nanswering\nChatGPT version 3.5\nAli et al. (11) 2023 Ophthalmic Plast \nReconstr Surg\nLacrimal drainage disorders To response to lacrimal \ndrainage disorders\nAutomated question-\nanswering\nChatGPT\nTsui et al. (12) 2023 Eye Posterior vitreous detachment, \nretinal tear and detachment, \nocular surface disease, \nexudative age-related macular \ndegeneration (eAMD), and \npost-intravitreal injection pain \nand redness\nTo response to common \nocular symptoms\nAutomated question-\nanswering\nChatGPT\nPotapenko et al. (13) 2023 Acta Ophthalmologica Retinal diseases To evaluate accuracy on \npatient information\nAutomated question-\nanswering\nChatGPT\nMomenaei et al. (14) 2023 Ophthalmology Retina Retinal diseases To evaluate the \nappropriateness and \nreadability of the medical \nknowledge\nAutomated question-\nanswering\nChatGPT-4\nWaisberg et al. (15) 2023 Irish Journal of Medical \nScience\nAnterior ischemic optic \nneuropathy\nFundus image analysis Image analysis GPT-4\nHu et al. (16) 2022 Transl Vis Sci Technol. Glaucoma To Predict Glaucoma \nProgression Requiring Surgery\nPredictive Modeling Pre-trained Transformers\nLee et al. (17) 2023 Ophthalmic Res General ophthalmology To assign procedural codes \nbased on the surgical report\nPredictive Modeling Bidirectional Encoder \nRepresentations from \nTransformers (BERT)\nLiu et al. (18) 2023 AMIA Retinal vascular disease To provide a diagnosis based \non FFA reports\nSummarization GPT3.5-Turbo\nYu et al. (19) 2022 BMC Medical \nInformatics and \nDecision Making\nDiabetic retinopathy To Identify diabetic \nretinopathy-related clinical \nconcepts and their attributes\nInformation \nscreening\nNLP(Extraction, Named \nentity recognition), DL, \nPre-trained Transfomers\nValentín-Bravo et al. \n(20)\n2023 Arch Soc Esp Oftalmol. Vitreoretinal disease To write a scientific article Information \nscreening\nChatGPT, DALL-E 2\nSingh et al. (4) 2023 Clin Exp Ophthamol. Dry eye disease To conduct a literature review Information \nscreening\nChatGPT\nSingh et al. (21) 2023 Seminars in \nOphthalmology\nCornea, retina, glaucoma, \npediatric ophthalmology, \nneuroophthalmology, and \nophthalmic plastics surgery\nTo construct ophthalmic \ndischarge summaries and \noperative notes\nInformation \nscreening\nChatGPT\nRasmussen et al. \n(22)\n2023 Graefe’s archive for \nclinical and \nexperimental \nophthalmology\nVernal keratoconjunctivitis To provided responses to \npatient and parent questions\nAutomated question-\nanswering\nChatGPT\nlim et al. (23) 2023 Ebiomedicine Myopia To deliver accurate responses \nto common myopia-related \nquery\nAutomated question-\nanswering\nChatGPT-3.5, \nChatGPT-4.0, and Google \nBard\nWaisberg et al. (24) 2023 Annals of Biomedical \nEngineering\nGeneral ophthalmology To write ophthalmic operative \nnotes\nInformation \nscreening\nGPT-4\nJin et al. 10.3389/fmed.2023.1291404\nFrontiers in Medicine 05 frontiersin.org\nGeneral ophthalmology\nThe application of LLMs in ophthalmology is a rapidly growing \nfield with promising potential, encompassing various aspects of \npatient care and clinical workflows. LLMs can analyze general \nophthalmology patient data and medical records to recommend \npersonalized diagnosis and treatment plans for individuals with \nspecific eye conditions. Chatbots integrated with electronic health \nrecord (EHR) systems can access patient information to provide \ncontext-aware responses and support clinical decision-making.\nThe majority of current NLP applications in ophthalmology focus \non extracting specific text, such as visual acuity, from free-text notes \nfor the purposes of quantitative analysis ( 25). NLP also offers \nopportunities to develop search engines for data within free-text \nnotes, clean notes, automated question-answering, and translating \nophthalmology notes for other specialties or for patients. Low vision \nrehabilitation improves quality of life for visually impaired patients, \nfree-text progress notes within the EHR using NLP provide valuable \ninformation relevant to predicting patients’ visual prognosis (26). NLP \nwith unstructured clinician notes supports low vision and blind \nrehabilitation for war veterans with traumatic brain injury based on \nveterans’ needs rather than system-level factors (27, 28). This suggests \nthat AI with NLP may be particularly important for the performance \nof predictive models in ophthalmology. Given the potential of LLMs \nin healthcare and the increasing reliance of patients on online \ninformation, it is important to evaluate the quality of chatbot-\ngenerated advice and compare it with human-written advice from \nophthalmologists. The panel of ophthalmologists had a 61.3% \naccuracy in distinguishing between chatbot and human responses (10).\nAs chatbot technology is continually evolving, there are additional \napplications in general ophthalmology. The researchers evaluated the \nability of the ChatGPT to respond to ocular symptoms by scripting 10 \nprompts reflective of common patient messages relating to various \nocular conditions (12). These conditions included posterior vitreous \ndetachment, retinal tear and detachment, ocular surface disease, \nexudative age-related macular degeneration (eAMD), and post-\nintravitreal injection pain and redness. The abilities of ChatGPT in \nconstructing discharge summaries and operative notes were evaluated \nthrough a study conducted by Swati et al. (21). The study found that \nChatGPT was able to construct ophthalmic discharge summaries and \noperative notes in a matter of seconds, with tailored responses based \non the quality of inputs given. However, there were some limitations \nsuch as the presence of generic text and factual inaccuracies in some \nresponses. The authors suggest that ChatGPT can be  utilized to \nminimize the time spent on discharge summaries and improve patient \ncare, but it should be  used with caution and human verification. \nAnother study aimed to assess the performance of an AI chatbot, \nChatGPT, in answering practice questions for ophthalmology board \ncertification examinations (9). ChatGPT correctly answered 46.4% of \nthe questions, with the best performance in the category of general \nmedicine (79%) and the poorest in retina and vitreous (0%). ChatGPT \nprovided explanations and additional insight for 63% of questions but \nselected the same multiple-choice response as the most common \nanswer provided by ophthalmology trainees only 44% of the time. The \nresearchers compared the performance of several generative AI \nmodels on the ophthalmology board-style questions (6–8), including \nBing Chat (Microsoft), ChatGPT 3.5 and 4.0 (OpenAI). Performance \nwas compared with that of human respondents. Results showed that \nChatGPT-4.0 and Bing Chat performed comparably to \nhuman respondents.\nExisting electronic differential diagnosis support tools, like the \nIsabel Pro Differential Diagnosis Generator, have limitations in terms \nof structured input and context-specific language processing. In one \nstudy, ChatGPT identified the correct diagnosis in 9 out of 10 cases \nand had the correct diagnosis listed in all 10 of its lists of differentials \n(29). Isabel, on the other hand, identified only 1 out of 10 provisional \ndiagnoses correctly, but included the correct diagnosis in 7 out of 10 \nof its differential diagnosis lists. The median position of the correct \ndiagnosis in the ranked differential lists was 1.0 for ChatGPT versus \n5.5 for Isabel.\nFIGURE 3\nMajor applications of LLM in Ophthalmology. The patient’s information like symptoms, medical history and other health-related details are inputted \ninto the LLM, which outputs valuable clinical insights to the physician and helps him or her make decisions.\nJin et al. 10.3389/fmed.2023.1291404\nFrontiers in Medicine 06 frontiersin.org\nRetinal diseases\nSome studies evaluate the accuracy of an AI-based chatbot in \nproviding patient information on common retinal diseases, including \nAMD, diabetic retinopathy (DR), retinal vein occlusion, retinal artery \nocclusion, and central serous chorioretinopathy.\nIn healthcare settings, when patients provide information about \ntheir medical history, symptoms, or other health-related details, there \nis the potential for miscommunication or misalignment between the \npatient’s perspective and the physician’s understanding of the situation. \nTraditional methods of obtaining patient information may lead to \ndissatisfaction if the information obtained misaligns with the \nphysician’s information (30). ChatGPT can improve patient satisfaction \nin terms of information provision by providing accurate and well-\nformulated responses to various topics, including common retinal \ndiseases (13). This accessibility can be particularly beneficial when \nophthalmologists are not readily available. Among retinal diseases, DR \nis a leading cause of blindness in adults, and there is increasing interest \nin developing AI technologies to detect DR using EHRs. Most AI-based \nDR diagnoses are focused on medical images, but there is limited \nresearch exploring the lesion-related information captured in the free \ntext image reports. In Yu et  al. ( 19) study, two state-of-the-art \ntransformer-based NLP models, including BERT and RoBERTa, were \nexamined and compared with a recurrent neural network implemented \nusing Long short-term memory (LSTM) to extract DR-related concepts \nfrom clinical narratives. The results show that for concept extraction, \nthe BERT model pretrained with the MIMIC III dataset outperformed \nother models, achieving the highest performance with F1-scores of \n0.9503 and 0.9645 for strict and lenient evaluations, respectively. The \nfindings of this study could have a significant impact on the \ndevelopment of clinical decision support systems for DR diagnoses.\nAnterior segment disease\nAnterior segment vision-threatening disease included the \ndiagnosis of corneal ulcer, iridocyclitis, hyphema, anterior scleritis, \nor scleritis with corneal involvement. Patients with anterior \nsegment diseases present a diagnostic challenge for many primary \ncare physicians. The researchers developed a decision support tool \nto predict vision-threatening anterior segment disease using \nprimary clinical notes based on NLP ( 31). The ultimate prediction \nmodel exhibited an area under the curve (AUC) of 0.72, with a 95% \nconfidence interval ranging from 0.67 to 0.77. Using a threshold \nthat achieved a sensitivity of 90%, the model demonstrated a \nspecificity of 30%, a positive predictive value of 5.8%, and a high \nnegative predictive value of 99%. One study evaluates the accuracy \nof responses provided by the ChatGPT to patient and parent \nquestions on vernal keratoconjunctivitis (VKC), a complex and \nrecurring disease primarily affecting children ( 22). The researchers \nformulated questions in four categories and assessed the chatbot’s \nresponses for information accuracy. The chatbot was found to \nprovide both relevant and inaccurate statements. Inaccurate \nstatements were particularly observed regarding treatment and \npotential side effects of medications. A comparative analysis of the \nperformance of three LLMs, namely ChatGPT-3.5, ChatGPT-4.0, \nand Google Bard, was conducted in delivering accurate and \ncomprehensive responses to common myopia-related queries. \nChatGPT-4.0 demonstrated the highest accuracy, with 80.6% of \nresponses rated as ‘good’ , compared to 61.3% in ChatGPT-3.5 and \n54.8% in Google Bard ( 23).\nGlaucoma\nPrevious studies have developed predictive models for glaucoma \nprogression, but uncertainty remains on how to integrate the \ninformation in free-text clinical notes, which contain valuable clinical \ninformation (32). Some studies aim to predict glaucoma progression \nrequiring surgery using deep learning approaches on EHRs and natural \nlanguage processing of clinical free-text notes. Sunil et al. presents an \nartificial intelligence approach to predict near-term glaucoma \nprogression using clinical free-text notes and data from electronic \nhealth records (33). The authors developed models that combined \nstructured data and text inputs to predict whether a glaucoma patient \nwould require surgery within the following year. The model \nincorporating both structured clinical features and free-text features \nachieved the highest performance with an AUC of 0.899 and an F1 \nscore of 0.745. Another study aims to fill the gap by developing a deep \nlearning predictive model for glaucoma progression using both \nstructured clinical data and natural language processing of clinical free-\ntext notes from EHRs. The combination model showed the best AUC \n(0.731), followed by the text model (0.697) and the structured model \n(0.658) (34). Hu et  al. ( 16) explored the use of transformer-based \nlanguage models, specifically Bidirectional Encoder Representations \nfrom Transformers (BERT), to predict glaucoma progression requiring \nsurgery using clinical free-text notes from EHRs. The results showed \nthat the BERT models outperformed an ophthalmologist’s review of \nclinical notes in predicting glaucoma progression. Michelle et al. (35) \nutilized an automated pipeline for data extraction from EHRs to \nevaluate the real-world outcomes of glaucoma surgeries, tube shunt \nsurgery had a higher risk of failure (Baerveldt: Hazard Ratio (HR) 1.44, \n95% CI 1.02 to 2.02; Ahmed: HR 2.01, 95% CI 1.28 to 3.17).\nOphthalmic plastics\nIn the study conducted by Mohammad et al. ( 11), ChatGPT’s \nperformance in providing information about primary acquired \nnasolacrimal duct obstruction and congenital nasolacrimal duct \nobstruction was evaluated. Regarding insights into the history and \neffectiveness of dacryocystorhinostomy surgery, ChatGPT was tested \non this specific topic. Agreement among the three observers was high \n(95%) in grading the responses. The responses of ChatGPT were \ngraded as correct for only 40% of the prompts, partially correct in \n35%, and outright factually incorrect in 25%. Hence, some degree of \nfactual inaccuracy was present in 60% of the responses, if we consider \nthe partially correct responses.\nDiscussion\nThe newer generation of GPT models, exemplified by GPT-3 and \nbeyond, differs from their predecessors through significantly larger \nmodel sizes, improved performance on various language tasks, \nenhanced few-shot learning abilities, and increased versatility, while \nalso necessitating more substantial computational resources and \nraising ethical considerations.\nJin et al. 10.3389/fmed.2023.1291404\nFrontiers in Medicine 07 frontiersin.org\nStrengths\nAI technology, such as online chat-based AI language models, \nhas the potential to assist clinical workflows and augment patient \neducation and communication about common ophthalmology \ndiseases prevention queries ( Table 1). GPT’s medical subspecialty \ncapabilities have improved significantly from GPT-3 to GPT-4. \nBoth LLMs struggled with image-based and higher-order \nophthalmology questions, perhaps reflecting the importance of \nvisual analysis in ophthalmology. Given the ongoing advances in \ncomputer vision, it may be possible to address this limitation in \nfuture LLMs. There is room for improvement in medical \nconversational agents, as all models exhibited instances of \nhallucination, incorrect justification, or non-logical reasoning ( 36). \nAlthough ChatGPT 4.0 has demonstrated remarkable capabilities \nin a variety of domains, the presence of these errors raises concerns \nabout the reliability of the system, especially in critical clinical \ndecision making.\nOphthalmologists are starting to use ChatGPT to help with \npaperwork such as scientific articles, discharge summaries and \noperative notes (15, 24, 37). The scientific accuracy and reliability on \ncertain topics were not sufficient to automatically generate \nscientifically rigorous articles. This was also objected to by some \nophthalmologists ( 38). Firstly, operative notes are not general \ndescriptions of surgical procedures and a specific patient has its own \nunique characteristics. Secondly, operative notes are legal documents \nand the surgeon is responsible for the accuracy and completeness of \nthe notes. Thirdly, there is no evidence that GPT-4 can accurately \ncapture the unique aspects of individual cases in the real world, such \nas intraoperative complications. Finally, the writing of operative notes \nrequires a degree of clinical decision-making and clinical judgment \nthat cannot be automated.\nIn a recent development, ChatGPT has emerged as an author or \nco-author of scientific papers in the field of ophthalmology (39, 40). \nThis innovative inclusion has sparked discussions and garnered \nattention from the scientific community. The presence of ChatGPT as \nan author in scientific research reflects the evolving landscape of \nartificial intelligence’s involvement in various domains, including \nophthalmology, opening avenues for new perspectives and \ncollaborative contributions.\nChallenges\nDespite the promising future, integrating LLMs into \nophthalmology also poses several challenges that need to be addressed. \nFirstly, ensuring patient data privacy and maintaining the security of \nsensitive medical information will be  critical ( 41). These models \nrequire vast amounts of data to achieve their potential, but data-\nsharing must be conducted responsibly and in compliance with strict \nethical and legal guidelines (42, 43).\nAnother significant challenge is the potential for bias in the data \nused to train these language models (44). If the data used for training \nis not diverse enough, the models may exhibit biases that can lead to \ninaccurate or unfair recommendations, particularly when dealing with \nunderrepresented populations. Efforts must be made to identify and \nmitigate these biases to ensure equitable and reliable outcomes for \nall patients.\nFurthermore, there may be resistance or skepticism among some \nhealthcare professionals towards adopting AI-driven technologies like \nLLMs. It will be crucial to address these concerns, provide proper \ntraining, and foster a collaborative environment where human experts \nand AI work together synergistically (45).\nThe interpretability and explainability of the decisions made by \nthese models are another challenge. As they are often considered \n“black boxes, ” “understanding the reasoning behind their \nrecommendations can be difficult, ” leading to potential mistrust from \nclinicians and patients (46). Developing methods to make the models \nmore transparent and explainable will be essential for their widespread \nacceptance and adoption (47).\nLastly, the rapidly evolving nature of AI and language model \ntechnologies demands continuous updates and improvements. Staying \nup-to-date with the latest advancements and incorporating new \nknowledge into the models is essential to maintain their accuracy and \nrelevance in the ever-changing field of ophthalmology.\nWhile LLMs like ChatGPT offer tremendous potential in \nophthalmology, addressing the challenges of AI hallucination and \nmisinformation is paramount. It is essential to consider the broader \nsocietal implications, including patient trust, medical liability, ethical \nconcerns, scientific integrity, health disparities, and regulatory \noversight when integrating AI into ophthalmic practices. Responsible \nAI implementation and continuous monitoring are essential to \nharness the benefits of AI while minimizing potential risks. One \nconcern in the use of LLMs for medical applications is the lack of \nreproducibility, as these generative models may not consistently \nprovide the same answers, potentially impacting the reliability of their \noutputs in clinical settings. Addressing these challenges will \nbe essential to fully realize the potential benefits of large language \nmodels in ophthalmology and to ensure their responsible and ethical \nimplementation in patient care (48).\nFuture perspectives\nThe future perspectives of LLMs in ophthalmology hold \ntremendous promise for transforming the landscape of eye care and \nresearch (49). These advanced language models, powered by AI and \nNLP , are poised to revolutionize how ophthalmologists diagnose, treat, \nand manage various eye conditions. LLMs can be integrated with \nimage analysis techniques to create multimodal AI systems. These \nsystems can process both textual and visual information, enhancing \ntheir capabilities in ophthalmology. For instance, LLMs can analyze \ntextual patient records and medical literature, while image analysis \nalgorithms can interpret medical images such as fundus photographs. \nThrough their ability to analyze vast amounts of medical literature, \npatient data, and diagnostic images, these models can provide more \naccurate and timely diagnoses, personalized treatment plans, and even \npredict disease progression. The combination of LLMs and image \nanalysis can lead to more efficient and accurate decision-making in \nophthalmic practice. Additionally, LLMs can be  used as tools to \nsupport communication and knowledge exchange in the following \nways. While LLMs themselves do not directly facilitate communication \nlike human interaction, their capabilities can enhance and streamline \ninformation exchange and knowledge sharing among eye care \nprofessionals worldwide. As research and development in this field \ncontinue to progress, we can expect these language models to become \nJin et al. 10.3389/fmed.2023.1291404\nFrontiers in Medicine 08 frontiersin.org\nindispensable tools that enhance efficiency, accessibility, and \nultimately improve patient outcomes in ophthalmology.\nLimitations\nThis review acknowledges several potential limitations that may \nhave affected the comprehensiveness and potential bias of the \nliterature search and selection process. These limitations include \npublication bias, language bias due to the focus on English-language \nstudies, potential database selection bias, the possibility of excluding \nrelevant studies due to search term restrictions, the limited date \nrange, and the predefined exclusion criteria that may have omitted \nrelevant research. The review also recognizes the potential for missed \nreferences and acknowledges the subjectivity in reviewer bias, which \ncould impact study inclusion. Moreover, the review underscores the \nimportance of addressing these limitations to ensure a more \ncomprehensive and balanced assessment of the field of AI in \nophthalmology. Despite these potential constraints, the review \nprovides valuable insights into the applications and challenges of AI \nin ophthalmology, but readers should consider these limitations \nwhen interpreting the findings and drawing conclusions from \nthe review.\nAuthor contributions\nKJ: Conceptualization, Data curation, Funding acquisition, \nInvestigation, Methodology, Writing – original draft, Writing – review \n& editing. LY: Data curation, Formal analysis, Investigation, \nMethodology, Writing – original draft. HW: Formal analysis, Software, \nValidation, Writing – review & editing. AG: Supervision, Validation, \nVisualization, Writing – review & editing. JY: Conceptualization, \nFunding acquisition, Project administration, Resources, Supervision, \nValidation, Visualization, Writing – review & editing.\nFunding\nThe author(s) declare financial support was received for the \nresearch, authorship, and/or publication of this article. This work has \nbeen financially supported by Natural Science Foundation of China \n(grant number 82201195), and Clinical Medical Research Center for \nEye Diseases of Zhejiang Province (grant number 2021E50007).\nAcknowledgments\nThanks to all the peer reviewers and editors for their opinions \nand suggestions.\nConflict of interest\nThe authors declare that the research was conducted in the \nabsence of any commercial or financial relationships that could \nbe construed as a potential conflict of interest.\nPublisher’s note\nAll claims expressed in this article are solely those of the authors \nand do not necessarily represent those of their affiliated organizations, \nor those of the publisher, the editors and the reviewers. Any product \nthat may be evaluated in this article, or claim that may be made by its \nmanufacturer, is not guaranteed or endorsed by the publisher.\nReferences\n 1. Jin K, Y e J. Artificial intelligence and deep learning in ophthalmology: current status \nand future perspectives. Adv Ophthalmol Pract Res. (2022) 2:100078. doi: 10.1016/j.\naopr.2022.100078\n 2. Will ChatGPT transform healthcare? Nat Med. (2023) 29:505–6. doi: 10.1038/\ns41591-023-02289-5\n 3. Sharma P , Parasa S. ChatGPT and large language models in gastroenterology. Nat \nRev Gastroenterol Hepatol. (2023) 20:481–2. doi: 10.1038/s41575-023-00799-8\n 4. Singhal K, Azizi S. Large language models encode clinical knowledge. Nature. \n(2023) 620:172–80. doi: 10.1038/s41586-023-06291-2\n 5. Arora A, Arora A. The promise of large language models in health care. Lancet \n(London, England). (2023) 401:641. doi: 10.1016/S0140-6736(23)00216-7\n 6. Lin JC, Y ounessi DN, Kurapati SS, Tang OY , Scott IU. Comparison of GPT-3.5, \nGPT-4, and human user performance on a practice ophthalmology written examination. \nEye (London, England). (2023). doi: 10.1038/s41433-023-02564-2\n 7. Antaki F , Touma S, Milad D, El-Khoury J, Duval R. Evaluating the performance of \nChatGPT in ophthalmology: an analysis of its successes and shortcomings. Ophthalmol \nSci. (2023) 3:100324. doi: 10.1016/j.xops.2023.100324\n 8. Cai LZ, Shaheen A, Jin A, Fukui R, Yi JS, Y annuzzi N, et al. Performance of \ngenerative large language models on ophthalmology board style questions. Am J \nOphthalmol. (2023) 254:141–9. doi: 10.1016/j.ajo.2023.05.024\n 9. Mihalache A, Popovic MM, Muni RH. Performance of an artificial intelligence \nChatbot in ophthalmic knowledge assessment. JAMA Ophthal. (2023) 141:589–97. doi: \n10.1001/jamaophthalmol.2023.1144\n 10. Bernstein IA, Zhang YV , Govil D, Majid I, Chang RT, Sun Y , et al. Comparison of \nophthalmologist and large language model Chatbot responses to online patient eye care \nquestions. JAMA Netw Open. (2023) 6:e2330320. doi: 10.1001/jamanetworkopen.2023.30320\n 11. Ali MJ. ChatGPT and lacrimal drainage disorders: performance and scope of \nimprovement. Ophthal Plast Reconstr Surg . (2023) 39:221–5. doi: 10.1097/\nIOP .0000000000002418\n 12. Tsui JC, Wong MB, Kim BJ, Maguire AM, Scoles D. Appropriateness of ophthalmic \nsymptoms triage by a popular online artificial intelligence chatbot. Eye (Lond). (2023). \ndoi: 10.1038/s41433-023-02556-2\n 13. Potapenko I, Boberg-Ans LC, Stormly HM. Artificial intelligence-based chatbot \npatient information on common retinal diseases using ChatGPT. Acta Ophthalmol. \n(2023). doi: 10.1111/aos.15661\n 14. Momenaei B, Wakabayashi T, Shahlaee A, Durrani AF , Pandit SA, Wang K, et al. \nAppropriateness and readability of chatgpt-4-generated responses for surgical treatment \nof retinal diseases. Ophthalmol Retina. (2023). 7:862–8.\n 15. Waisberg E, Ong J, Masalkhi M, Kamran SA, Zaman N, Sarker P , et al. GPT-4: a \nnew era of artificial intelligence in medicine. Ir J Med Sci . (2023). doi: 10.1007/\ns11845-023-03377-8\n 16. Hu W , Wang SY . Predicting Glaucoma progression requiring surgery using clinical \nfree-text notes and transfer learning with transformers. Transl Vis Sci Technol. (2022) \n11:37. doi: 10.1167/tvst.11.3.37\n 17. Lee YM, Bacchi S, Macri C, Tan Y , Casson R, Chan WO. Ophthalmology operation \nnote encoding with open-source machine learning and natural language processing. \nOphthalmic Res. (2023) 66:928–39.\n 18. Liu X, Wu J, Shao A, Shen W , Y e P , Wang Y , et al. Transforming retinal vascular \ndisease classification: a comprehensive analysis of chatgpt’s performance and inference \nabilities on non-english clinical environment. medRxiv (2023). doi: \n10.1101/2023.06.28.23291931\n 19. Yu Z, Y ang X, Sweeting GL, Ma Y , Stolte SE, Fang R, et al. Identify diabetic \nretinopathy-related clinical concepts and their attributes using transformer-based \nJin et al. 10.3389/fmed.2023.1291404\nFrontiers in Medicine 09 frontiersin.org\nnatural language processing methods. BMC Med Inform Decis Mak. (2022) 22:255. doi: \n10.1186/s12911-022-01996-2\n 20. Valentín-Bravo FJ, Mateos-Álvarez E, Usategui-Martín R, Andrés-Iglesias C, \nPastor-Jimeno JC, Pastor-Idoate S. Artificial intelligence and new language models in \nophthalmology: complications of the use of silicone oil in vitreoretinal surgery. Arch Soc \nEsp Oftalmol (Engl Ed). (2023) 98:298:303.\n 21. Singh S, Djalilian A, Ali MJ. ChatGPT and ophthalmology: exploring its potential \nwith discharge summaries and operative notes. Semin Ophthalmol. (2023) 38:503–7. doi: \n10.1080/08820538.2023.2209166\n 22. Rasmussen MLR, Larsen AC, Subhi Y , Potapenko I. Artificial intelligence-based \nChatGPT chatbot responses for patient and parent questions on vernal keratoconjunctivitis. \nGraefes Arch Clin Exp Ophthalmol. (2023) 261:3041–3. doi: 10.1007/s00417-023-06078-1\n 23. Lim ZW , Pushpanathan K, Y ew SME, Lai Y , Sun CH, Lam JSH, et al. Benchmarking \nlarge language models’ performances for myopia care: a comparative analysis of \nChatGPT-3.5, ChatGPT-4.0, and Google bard. EBioMedicine. (2023) 95:104770. doi: \n10.1016/j.ebiom.2023.104770\n 24. Waisberg E, Ong J, Masalkhi M, Kamran SA, Zaman N, Sarker P , et al. GPT-4 and \nophthalmology operative notes. Ann Biomed Eng . (2023). doi: 10.1007/\ns10439-023-03263-5\n 25. Chen JS, Baxter SL. Applications of natural language processing in ophthalmology: \npresent and future. Front Med. (2022) 9:906554. doi: 10.3389/fmed.2022.1078403\n 26. Gui H, Tseng B, Hu W , Wang SY . Looking for low vision: predicting visual \nprognosis by fusing structured and free-text data from electronic health records. Int J \nMed Inform. (2022) 159:104678. doi: 10.1016/j.ijmedinf.2021.104678\n 27. Winkler SL, Finch D, Llanos I, Delikat J, Marszalek J, Rice C, et al. Retrospective \nanalysis of vision rehabilitation for veterans with traumatic brain injury-related vision \ndysfunction. Mil Med. (2023) 188:e2982–6. doi: 10.1093/milmed/usad120\n 28. Winkler SL, Finch D, Wang X, Toyinbo P , Marszalek J, Rakoczy CM, et al. Veterans \nwith traumatic brain injury-related ocular injury and vision dysfunction: \nrecommendations for rehabilitation. Optom Vis Sci . (2022) 99:9–17. doi: 10.1097/\nOPX.0000000000001828\n 29. Balas M, Ing EB. Conversational ai models for ophthalmic diagnosis: comparison \nof chatgpt and the isabel pro differential diagnosis generator. JFO Open Ophthalmol. \n(2023) 1:100005. doi: 10.1016/j.jfop.2023.100005\n 30. Visser M, Deliens L, Houttekier D. Physician-related barriers to communication \nand patient- and family-centred decision-making towards the end of life in intensive \ncare: a systematic review. Crit Care. (2014) 18:604. doi: 10.1186/s13054-014-0604-z\n 31. Singh K, Thibodeau A, Niziol LM, Nakai TK, Bixler JE, Khan M, et al. Development \nand validation of a model to predict anterior segment vision-threatening eye disease \nusing primary care clinical notes. Cornea. (2022) 41:974–80. doi: 10.1097/\nICO.0000000000002877\n 32. Salazar H, Misra V , Swaminathan SS. Artificial intelligence and complex statistical \nmodeling in glaucoma diagnosis and management. Curr Opin Ophthalmol . (2021) \n32:105–17. doi: 10.1097/ICU.0000000000000741\n 33. Jalamangala Shivananjaiah SK, Kumari S, Majid I, Wang SY . Predicting near-term \nglaucoma progression: an artificial intelligence approach using clinical free-text notes \nand data from electronic health records. Front Med. (2023) 10:1157016. doi: 10.3389/\nfmed.2023.1157016\n 34. Wang SY , Tseng B, Hernandez-Boussard T. Deep learning approaches for \npredicting Glaucoma progression using electronic health records and natural language \nprocessing. Ophthalmol Sci. (2022) 2:100127. doi: 10.1016/j.xops.2022.100127\n 35. Sun MT, Singh K, Wang SY . Real-world outcomes of Glaucoma filtration surgery \nusing electronic health records: an informatics study. J Glaucoma. (2022) 31:847–53. doi: \n10.1097/IJG.0000000000002122\n 36. Azamfirei R, Kudchadkar SR, Fackler J. Large language models and the perils of \ntheir hallucinations. Crit Care. (2023) 27:120. doi: 10.1186/s13054-023-04393-x\n 37. Asensio-Sánchez VM. Artificial intelligence and new language models in \nophthalmology: complications of the use of silicone oil in vitreoretinal surgery. Arch Soc \nEsp Oftalmol (Engl Ed). (2023) 98:298–303.\n 38. Lawson MLA. Artificial intelligence in surgical documentation: a critical review \nof the role of large language models. Ann Biomed Eng . (2023). doi: 10.1007/\ns10439-023-03282-2\n 39. Salimi A, Saheb H. Large language models in ophthalmology scientific writing: \nethical considerations blurred lines or not at all? Am J Ophthalmol. (2023) 254:177–81. \ndoi: 10.1016/j.ajo.2023.06.004\n 40. Ali MJ, Singh S. ChatGPT and scientific abstract writing: pitfalls and caution. \nGraefes Arch Clin Exp Ophthalmol. (2023) 261:3205–6. doi: 10.1007/s00417-023-06123-z\n 41. Abdullah YI, Schuman JS, Shabsigh R, Caplan A, Al-Aswad LA. Ethics of artificial \nintelligence in medicine and ophthalmology. Asia-Pacific J. Ophthalmol. (Phila Pa) . \n(2021) 10:289–98. doi: 10.1097/APO.0000000000000397\n 42. Shen Y , Heacock L, Elias J. ChatGPT and other large language models are double-\nedged swords. Radiology. (2023) 307:e230163. doi: 10.1148/radiol.230163\n 43. Tom E, Keane PA, Blazes M, Pasquale LR, Chiang MF , Lee AY , et al. Protecting \ndata privacy in the age of AI-enabled ophthalmology. Transl Vis Sci Technol. (2020) 9:36. \ndoi: 10.1167/tvst.9.2.36\n 44. Gianfrancesco MA, Tamang S, Y azdany J, Schmajuk G. Potential biases in machine \nlearning algorithms using electronic health record data. JAMA Intern Med . (2018) \n178:1544–7. doi: 10.1001/jamainternmed.2018.3763\n 45. Dow ER, Keenan TDL, Lad EM, Lee AY , Lee CS, Loewenstein A, et al. From data \nto deployment: the collaborative community on ophthalmic imaging roadmap for \nartificial intelligence in age-related macular degeneration. Ophthalmology. (2022) \n129:e43–59. doi: 10.1016/j.ophtha.2022.01.002\n 46. González-Gonzalo C, Thee EF , Klaver CCW , Lee AY , Schlingemann RO, Tufail A, \net al. Trustworthy AI: closing the gap between development and integration of AI \nsystems in ophthalmic practice. Prog Retin Eye Res. (2022) 90:101034. doi: 10.1016/j.\npreteyeres.2021.101034\n 47. Tools such as ChatGPT threaten transparent science; here are our ground rules for \ntheir use. Nature. (2023) 613:612. doi: 10.1038/d41586-023-00191-1\n 48. Chou YB, Kale AU, Lanzetta P , Aslam T, Barratt J, Danese C, et al. Current status \nand practical considerations of artificial intelligence use in screening and diagnosing \nretinal diseases: vision academy retinal expert consensus. Curr Opin Ophthalmol. (2023) \n34:403–13. doi: 10.1097/ICU.0000000000000979\n 49. Li JO, Liu H, Ting DSJ, Jeon S, Chan RVP , Kim JE, et al. Digital technology, tele-\nmedicine and artificial intelligence in ophthalmology: a global perspective. Prog Retin \nEye Res. (2021) 82:100900. doi: 10.1016/j.preteyeres.2020.100900",
  "topic": "Medicine",
  "concepts": [
    {
      "name": "Medicine",
      "score": 0.3786621391773224
    },
    {
      "name": "Optometry",
      "score": 0.3327077031135559
    }
  ]
}