{
    "title": "MAST: An Earthquake-Triggered Landslides Extraction Method Combining Morphological Analysis Edge Recognition With Swin-Transformer Deep Learning Model",
    "url": "https://openalex.org/W4389722667",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2106566374",
            "name": "Yu Huang",
            "affiliations": [
                "Institute of Mountain Hazards and Environment",
                "Chinese Academy of Sciences"
            ]
        },
        {
            "id": "https://openalex.org/A2096361407",
            "name": "Jianqiang Zhang",
            "affiliations": [
                "Chinese Academy of Sciences",
                "Institute of Mountain Hazards and Environment"
            ]
        },
        {
            "id": "https://openalex.org/A2264285690",
            "name": "Haiqing He",
            "affiliations": [
                "East China University of Technology",
                "Ministry of Natural Resources"
            ]
        },
        {
            "id": "https://openalex.org/A2112671405",
            "name": "Yang Jia",
            "affiliations": [
                "Sichuan Highway Design and Research Institute"
            ]
        },
        {
            "id": "https://openalex.org/A2106791084",
            "name": "Rong Chen",
            "affiliations": [
                "Institute of Mountain Hazards and Environment",
                "Chinese Academy of Sciences"
            ]
        },
        {
            "id": "https://openalex.org/A2153617986",
            "name": "Yonggang Ge",
            "affiliations": [
                "Chinese Academy of Sciences",
                "Institute of Mountain Hazards and Environment"
            ]
        },
        {
            "id": "https://openalex.org/A4324360886",
            "name": "Zaiyang Ming",
            "affiliations": [
                "Chinese Academy of Sciences",
                "Institute of Mountain Hazards and Environment"
            ]
        },
        {
            "id": "https://openalex.org/A2106887204",
            "name": "Lili Zhang",
            "affiliations": [
                "Chinese Academy of Sciences",
                "Institute of Mountain Hazards and Environment"
            ]
        },
        {
            "id": "https://openalex.org/A2107442531",
            "name": "Haoyu Li",
            "affiliations": [
                "Institute of Mountain Hazards and Environment",
                "Chinese Academy of Sciences"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4361225625",
        "https://openalex.org/W4319227723",
        "https://openalex.org/W2115820600",
        "https://openalex.org/W3014944364",
        "https://openalex.org/W6752633530",
        "https://openalex.org/W6824508966",
        "https://openalex.org/W6762559549",
        "https://openalex.org/W2304932561",
        "https://openalex.org/W6692391016",
        "https://openalex.org/W2885734264",
        "https://openalex.org/W2907675382",
        "https://openalex.org/W2963131120",
        "https://openalex.org/W3014774833",
        "https://openalex.org/W2997890878",
        "https://openalex.org/W3045270068",
        "https://openalex.org/W3008537971",
        "https://openalex.org/W2792442025",
        "https://openalex.org/W4200535305",
        "https://openalex.org/W2967019526",
        "https://openalex.org/W2990986966",
        "https://openalex.org/W2931695950",
        "https://openalex.org/W2945998314",
        "https://openalex.org/W2417596819",
        "https://openalex.org/W2953654709",
        "https://openalex.org/W3036453075",
        "https://openalex.org/W4292566160",
        "https://openalex.org/W4308512233",
        "https://openalex.org/W4382371057",
        "https://openalex.org/W6848016077",
        "https://openalex.org/W6805641521",
        "https://openalex.org/W6851017844",
        "https://openalex.org/W3156159991",
        "https://openalex.org/W3203480968",
        "https://openalex.org/W4214755140",
        "https://openalex.org/W4324359161",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W6792155083",
        "https://openalex.org/W6839481214",
        "https://openalex.org/W3080137196",
        "https://openalex.org/W6793982374",
        "https://openalex.org/W4327810809",
        "https://openalex.org/W4313524854",
        "https://openalex.org/W4249307133",
        "https://openalex.org/W4284897182",
        "https://openalex.org/W4205365435"
    ],
    "abstract": "Earthquake-triggered landslides (ETLs) are characterized by their extensive occurrences, having wide distributions. The conventional human&#x2013;computer interaction extraction method is often time-consuming and labor-intensive, failing to meet the demands of disaster emergency response. There is a pressing need for a swift detection of ETLs. In this study, we introduce an ETLs extraction method (MAST) combining morphological analysis edge recognition with a Swin-Transformer (SWT) deep learning model, which is specifically designed for landslide extraction. The MAST model adopts a hierarchical construction approach akin to convolution neural networks, aiding in tasks such as target detection and semantic segmentation. To enhance the accuracy of landslide edge extraction, we incorporate an edge recognition algorithm based on the morphological analysis into the MAST model. This algorithm leverages morphological operations to extract the features of landslide boundaries. It effectively addresses issues such as discretization and irregularization of the extracted landslide boundaries, leading to more precise delineation of landslide boundaries. Drawing on UAV data collected from Wan Dong Village, De Tou Town, Sichuan Luding, China, during the 2022 Ms 6.8 Luding Earthquake, we conducted automated extraction of ETLs utilizing the MAST model. Experimental results demonstrate the superior performance of the MAST model compared to the traditional full convolution neural network (FCN) model and normal SWT model. The MAST model exhibits enhanced value in landslide extraction. Notably, it demonstrates a significant advantage in boundary extraction. Employing the Boundary IoU metric to evaluate the accuracy of ETLs extraction, the MAST model outperforms the SWT and FCN models at various distances.",
    "full_text": "2586 IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING, VOL. 17, 2024\nMAST: An Earthquake-Triggered Landslides\nExtraction Method Combining Morphological\nAnalysis Edge Recognition With Swin-Transformer\nDeep Learning Model\nYu Huang , Jianqiang Zhang , Haiqing He ,Y a n gJ i a, Rong Chen , Yonggang Ge , Zaiyang Ming ,\nLili Zhang ,a n dH a o y uL i\nAbstract—Earthquake-triggered landslides (ETLs) are charac-\nterized by their extensive occurrences, having wide distributions.\nThe conventional human–computer interaction extraction method\nis often time-consuming and labor-intensive, failing to meet the\ndemands of disaster emergency response. There is a pressing need\nfor a swift detection of ETLs. In this study, we introduce an ETLs\nextraction method (MAST) combining morphological analysis edge\nrecognition with a Swin-Transformer (SWT) deep learning model,\nwhich is speciﬁcally designed for landslide extraction. The MAST\nmodel adopts a hierarchical construction approach akin to con-\nvolution neural networks, aiding in tasks such as target detection\nand semantic segmentation. To enhance the accuracy of landslide\nManuscript received 11 October 2023; revised 25 November 2023; accepted\n12 December 2023. Date of publication 14 December 2023; date of current\nversion 10 January 2024. This work was supported in part by the Second\nTibetan Plateau Scientiﬁc Expedition and Research Program (STEP) under Grant\n2019QZKK0902, in part by the West Light Foundation of the Chinese Academy\nof Sciences under Grant E3R2120, and in part by the Chinese Committee on\nICIMOD Program under Grant E2R5040.(Corresponding author: Jianqiang\nZhang.)\nYu Huang and Zaiyang Ming are with the Key Laboratory of Mountain Haz-\nards and Earth Surface Process, Institute of Mountain Hazards and Environment,\nChinese Academy of Sciences, Chengdu 610041, China, also with the Institute\nof Mountain Hazards and Environment, Chinese Academy of Sciences, Chengdu\n610041, China, also with the Key Laboratory of Mine Environmental Monitoring\nand Improving Around Poyang Lake of Ministry of Natural Resources, East\nChina University of Technology, Nanchang 330013, China, and also with the\nSchool of Surveying and Geoinformation Engineering, East China Univer-\nsity of Technology, Nanchang 330013, China (e-mail: huangyu@ecut.edu.cn;\nMingzy@ecut.edu.cn).\nJianqiang Zhang, Rong Chen, and Yonggang Ge are with the Key Laboratory\nof Mountain Hazards and Earth Surface Process, Institute of Mountain Hazards\nand Environment, Chinese Academy of Sciences, Chengdu 610041, China,\nand also with the Institute of Mountain Hazards and Environment, Chinese\nAcademy of Sciences, Chengdu 610041, China (e-mail: zhangjq@imde.ac.cn;\nrongchen@imde.ac.cn; gyg@imde.ac.cn).\nHaiqing He is with the Key Laboratory of Mine Environmental Monitoring\nand Improving Around Poyang Lake of Ministry of Natural Resources, East\nChina University of Technology, Nanchang 330013, China, and also with the\nSchool of Surveying and Geoinformation Engineering, East China University\nof Technology, Nanchang 330013, China (e-mail: hehaiqing@ecut.edu.cn).\nYang Jia is with the Sichuan Highway Planning, Survey, Design and Research\nInstitute, Ltd., Chengdu 610041, China (e-mail: jiayang@schdri.com).\nLili Zhang and Haoyu Li are with the Key Laboratory of Mountain Haz-\nards and Earth Surface Process, Institute of Mountain Hazards and Envi-\nronment, Chinese Academy of Sciences, Chengdu 610041, China, also with\nthe Institute of Mountain Hazards and Environment, Chinese Academy of\nSciences, Chengdu 610041, China, and also with the University of Chinese\nAcademy of Sciences, Beijing 100049, China (e-mail: zhanglili@imde.ac.cn;\nlihaoyu231@mails.ucas.ac.cn).\nDigital Object Identiﬁer 10.1109/JSTARS.2023.3342989\nedge extraction, we incorporate an edge recognition algorithm\nbased on the morphological analysis into the MAST model. This\nalgorithm leverages morphological operations to extract the fea-\ntures of landslide boundaries. It effectively addresses issues such\nas discretization and irregularization of the extracted landslide\nboundaries, leading to more precise delineation of landslide bound-\naries. Drawing on UA V data collected from Wan Dong Village, De\nTou Town, Sichuan Luding, China, during the 2022 Ms 6.8 Luding\nEarthquake, we conducted automated extraction of ETLs utilizing\nthe MAST model. Experimental results demonstrate the superior\nperformance of the MAST model compared to the traditional full\nconvolution neural network (FCN) model and normal SWT model.\nThe MAST model exhibits enhanced value in landslide extrac-\ntion. Notably, it demonstrates a signiﬁcant advantage in boundary\nextraction. Employing the Boundary IoU metric to evaluate the\naccuracy of ETLs extraction, the MAST model outperforms the\nSWT and FCN models at various distances.\nIndex Terms—Deep learning, earthquake-triggered landslides\n(ETLs), edge recognition, morphological analysis, transformer.\nI. INTRODUCTION\nO\nN SEPTEMBER 5, 2022, a seismic event of magnitude\n6.8 shook Luding County, situated in the Ganzi Tibetan\nAutonomous Prefecture within Sichuan Province. This seismic\nactivity resulted in a considerable number of landslides, trig-\ngered by the ground shaking and surface rupture stemming from\nthe earthquake. These earthquake-triggered landslides (ETLs)\nhave effectively obstructed roads and rivers, engulfed towns,\nand villages, severely impeding postdisaster rescue operations.\nConsequently, they have exacerbated the direct damage caused\nby the earthquake and stand as one of the natural disasters\nresponsible for severe human casualties and extensive property\ndamage. Given these implications, the precise identiﬁcation of\nETLs emerges as an urgent and indispensable task in earthquake\nrescue and relief efforts[1], [2].\nETLs are typically analyzed through visual or automated\nmethods. Visual extraction primarily relies on the expertise\nand experience of specialists in landslides, involving manual\nanalysis of remote-sensing images to determine the location\nor boundaries of the landslides. Visual extraction takes into\naccount the color tone, texture, development location, geometric\nshape, and other features of the landslide on the remote-sensing\nimage, and the extraction results have high accuracy, but it is\n© 2023 The Authors. This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see\nhttps://creativecommons.org/licenses/by-nc-nd/4.0/\nHUANG et al.: MAST: ETLS EXTRACTION METHOD COMBINING MORPHOLOGICAL ANALYSIS EDGE RECOGNITION 2587\ntime-consuming and laborious, and in addition, this method is\naffected by individual experts, which leads to differences in\nthe results of the judgment. The automatic extraction method\nis to transform the experience of visual extraction into the meth-\nods and rules of remote-sensing software and utilize comput-\ners to automatically identify landslides. Compared with visual\ninterpretation, automatic extraction is greatly affected by the\nquality of remote-sensing images, and the recognition accuracy\nis relatively low. In recent years, the development of machine\nlearning methods has brought new opportunities in the automatic\nextraction of ETLs, such as support vector machine (SVM) and\nrandom forest. SVM is a supervised learning algorithm, and in\nautomatic ETLs extraction, SVM can be trained with labeled\nlandslide and nonlandslide samples to learn the boundary fea-\ntures and classiﬁcation rules of landslides[3], [4], [5], [6].S V M\nexhibits superior classiﬁcation performance and generalization\nability in the context of landslide boundary extraction. It excels\nat accurately delineating boundaries from new ETLs data. On\nthe other hand, random forest employs an integrated learning\napproach by constructing multiple decision trees and amalga-\nmating them for classiﬁcation or regression tasks[7], [8].I nt h e\nautomated extraction of ETLs, RF leverages the aggregated deci-\nsions from multiple decision trees to ascertain landslide bound-\naries. RF demonstrates robustness and resistance to overﬁtting,\nproﬁciently managing noise and uncertainty present in ETLs\ndata [9], [10], [11], [12]. In addition to SVM and RF, various\nenhanced machine learning approaches have found application\nin automated ETLs extraction. For instance, neural-network-\nbased methodologies, such as convolutional neural networks\n(CNNs) and recurrent neural networks (RNNs), can adeptly\ndiscern spatial and temporal features of landslides from seismic\ndata, signiﬁcantly enhancing the precision of landslide extrac-\ntion [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23],\n[24], [25], [26], [27], [28]. For instance, Ramdhoni et al.[14] em-\nployed the Smorph method to perform landslide extraction. This\nmethod involves utilizing slope and slope shape to construct a\ntransformation matrix, achieving a landslide extraction accuracy\nof 79.54%[14]. Sameen and Pradhan[20] introduced a landslide\ndetection method utilizing residual networks. This approach\nenhances network performance by fusing feature information\nwithin the same design, with the F1 score of 77% and mIoU\nof 77.20% [20]. Meanwhile, some cutting-edge research has\ncombined multisource remote-sensing data for land cover clas-\nsiﬁcation. Li et al.[29], [30] proposed a spatial logic aggregation\nnetwork with morphological transformation for tree species\nclassiﬁcation. Additionally, they introduced a Representation-\nenhanced Status Replay Network (RSRNet), which includes\nmodal and semantic augmentation enhancement to enhance\nthe transferability and discreteness of feature representation,\nreduces the impact of representation bias in the feature extractor,\nand alleviates the bias of the classiﬁer while maintaining the\nstability of the decision boundary. The SRS was built to regulate\nthe learning and optimization of the classiﬁer. The RSRNet has\ndemonstrated superiority in multisource remote-sensing image\nclassiﬁcation [29], [30].\nIn recent years, self-attention networks, such as the trans-\nformer, have emerged as a groundbreaking approach in nat-\nural language processing and image segmentation[31], [32].\nFor instance, Van Nguyen et al.[33] developed a lightweight\ntransformer-based toolkit for multilingual natural language\nprocessing. This toolkit surpasses previous multilingual NLP\npipelines in tasks, such as sentence segmentation and part-of-\nspeech tagging[33]. Maria et al.[34] conducted an investigation\ninto the viability of transformer-based solutions for medical\nimage segmentation tasks. The study introduces the medical\ntransformer, which undergoes evaluation using three distinct\nmedical image segmentation datasets. The results demonstrate\nits superior performance[34]. The transformer architecture has\nshown remarkable advancements in image analysis tasks, such\nas image categorization and object detection. For instance, Zhao\net al. [35] explored its potential in 3-D point cloud process-\ning. They developed self-attentive networks for semantic scene\nsegmentation, part-of-speech segmentation, and object catego-\nrization. The achieved mean Intersection over Union (mIoU) on\nregion 5 of the S3DIS dataset, commonly utilized for large-scale\nsemantic scene segmentation, reached 70.4%[35].\nVarious enhanced machine learning methods have demon-\nstrated promising performance in the automated extraction of\nETLs. However, several challenges persist. First, labeling ETLs\ndata demands substantial time and expertise. Additionally, the\nmorphology and features of landslides are inﬂuenced by multiple\nfactors, including geological conditions, surface morphology,\nand seismic intensity, necessitating robust boundary extraction\nalgorithms. Accurate identiﬁcation of ETL edges enables early\nimplementation of appropriate measures to mitigate potential\nrisks. Nevertheless, traditional semantic segmentation detection\nmethods such as average intersection and merger ratio, and\nF1 score often struggle to yield satisfactory results due to the\ncomplexity and noise interference in ETL images[36].\nTherefore, in this study, we introduce an ETLs extrac-\ntion method (MAST), which combines morphological analysis\nedge recognition with Swin-Transformer (SWT) deep learning\nmodel. It integrates a morphological edge detection algorithm\nfor precise landslide extraction. The research focused on seismic\nlandslides in the Wan Dong Village of Detuo Town, Luding\nCounty. The introduction of the Boundary IoU value as a novel\nevaluation metric for landslide boundary extraction precision\nallowed for a targeted, detailed, and quantitative comparison\nof the results obtained by the MAST, normal SWT, and tradi-\ntional full convolution neural network (FCN) model. The study\ndemonstrates the applicability of MAST in the ﬁeld of ETLs\nextraction and its superiority in landslide boundary extraction.\nMoreover, it provides support for the enhanced applicability and\neffectiveness of deep learning methods in the domain of seismic\nlandslide extraction.\nII. STUDY AREA AND DA TASETS\nOn September 5, 2022, a magnitude 6.8 earthquake struck\nLuding County, Sichuan Province, China, at a depth of 16 km.\nThe epicenter was pinpointed at 29.59◦N latitude and 102.08◦E\nlongitude, triggering over 8000 earthquake-induced avalanches\nand landslides. For this research, the study area was designated\nas Wandong Village in Detou Town, Luding County, spanning\nfrom 102.05◦ to 102.26◦ east longitude and 29.33◦ to 29.70◦\nnorth latitude, covering approximately 9.26 km2. The area is lo-\ncated 9.43 km from the earthquake center, experiencing a seismic\n2588 IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING, VOL. 17, 2024\nFig. 1. (a) Location map of the study area. (b) Terrain schematic of the study\narea.\nintensity of magnitude 8. In the aftermath of the Luding earth-\nquake, the Sichuan Geographic Information Bureau employed a\nUA V to capture aerial photographs of the earthquake-affected re-\ngion on September 6, 2022. The UA V imagery was obtained at a\nspatial resolution of 0.2 m and underwent geometric corrections\nusing ground control points. The Institute of Mountain Hazards\nand Environment, Chinese Academy of Sciences (CAS), utilized\nthese images for ETL investigation using the visual extraction\nmethod. Concurrent ﬁeld inspections were carried out to validate\nthe ﬁndings. Ultimately, a total of 434 ETLs were identiﬁed in\nthe study area, covering an area of 1.49 km2 (Fig. 1). This catalog\nof ETLs serves as the reference data for automated identiﬁcation\nin this study.\nThis study establishes a high-quality dataset of landslide\nsamples to serve as the foundation for training the landslide\nrecognition model. The UA V image is segmented into 512×\n512 pixel unit images, from which the landslide inventory map is\ngenerated. Data augmentation techniques are applied to enhance\ndataset diversity, mitigate overﬁtting, and bolster the model’s\ngeneralization capability. The original landslide sample data\nare expanded by rotating, ﬂipping, and mirroring the images,\nresulting in the acquisition of approximately 3000 images, con-\nstituting a set of highly precise landslide sample data. In the\ncase of the landslide sample data, 70% is randomly chosen as\nthe training set for model development while the remaining 30%\nis designated as the test set. All the experiments in this study are\nconducted with Python.\nIII. METHODS\nIn this research, we introduce the MAST approach, which\nintegrates the SWT deep learning method with the morpho-\nlogical edge detection method. SWT, equipped with a hybrid\nloss function, serves as a feature extractor to capture crucial\nfeatures in ETLs images. This extracted information is then\ncombined with the morphological edge detection to improve the\nidentiﬁcation of ETL boundaries (see Fig.2). MAST harnesses\nthe outstanding performance of SWT in computer image recog-\nnition. Additionally, it addresses issues such as the discretiza-\ntion and irregularity of extracted landslide boundaries through\nFig. 2. Schematic diagram of MAST structure (SWT: This section illustrates\nthe structure employed by Swin Transformer, whereDn represents the image\nbeing divided into blocks, andMn represents the calculation of RGB channels.\nMA: This part pertains to the morphological analysis algorithm section, and\ndifferent treatment methods are adopted for different ETLs).\nthe morphological edge detection method, thereby enhancing\naccuracy in the automated extraction of ETLs.\nA. Improved SWT With Hybrid Loss Function\nSWT stands out as an advanced deep learning model for\nexceptional performance in computer vision. Its architecture\nresembles the hierarchical structure of convolutional networks,\nprogressively halving the resolution and doubling the number\nof channels through successive layers. The model adopts a\nhierarchical design comprising four stages, each of which in-\ncorporates two components: 1) patch merging and 2) SWT[37],\n[38]. The patch merging process initiates at the beginning of\neach stage, involving downsampling. Its purpose is to lower\nresolution and ﬁne-tune channel numbers, creating a hierarchi-\ncal design. Notably, this approach, unlike traditional pooling,\navoids information loss. The structure of the SWT block closely\nresembles that of the standard transformer block. However,\na key distinction lies in its innovative hierarchical attention\nmechanism. This mechanism conﬁnes attention computation\n(multihead self-attention) to speciﬁc windows. By substituting\nthe conventional multihead self-attention (MSA) with the mov-\ning window multihead self-attention (SW-MSA), the image gets\nbroken down into mask blocks of varied scales. Subsequently,\na moving window is employed to establish connections among\nthese mask blocks. This alteration signiﬁcantly enhances target\ndetection and image classiﬁcation performance. Consequently,\nthe SWT showcases notable attributes including high scalability,\nadeptness in handling diverse image sizes, and outstanding para-\nmetric and computational efﬁciency. In this article, the number\nof transformer layers is set to 10, attention head count 8, the\nSW-MSA window size is set to 15× 15, and the optimizer is\nselected as the Adam optimizer.\nThe calculation of the loss functionlfor the transformer model\nis\nι = λclsιcls. (1)\nThe variableλcls represents the cross-entropy loss function,\noften utilized to gauge the disparity between two probability\ndistributions, particularly in classiﬁcation scenarios. It quantiﬁes\nHUANG et al.: MAST: ETLS EXTRACTION METHOD COMBINING MORPHOLOGICAL ANALYSIS EDGE RECOGNITION 2589\nthe dissimilarity between the predicted probability distribution\ngenerated by the model and the actual label distribution. In the\ncontext of binary classiﬁcation, the formulation of the cross-\nentropy loss function is as follows:\nιcls = − 1\nn\nK∑\nk\n[\nyklog\n( 1\n1+ e−Zk\n)\n+( 1−yk)log\n( e−Zk\n1+ e−Zk\n)]\n. (2)\nGiven the challenges associated with vanishing gradients and\nthe insufﬁcient uncertainty captured by the cross-entropy loss\nfunction λcls, this study adopts a hybrid loss function, encom-\npassing the cross-entropy loss functionλcls and region contrast\nloss functionsλac, the combined loss function is computed as a\nweighted sum of these components using the following equation:\nι = λclsιcls + λacιac (3)\nIn the formula,λcls =0 .7,λac = 0.3; ιac represents a region\ncontrast loss function utilized to guide the original class activa-\ntion mapping to emphasize absent objects in the image, offering\nsupplementary constraints on the feature representation. This\nfunction is predominantly invoked in this article to address the\nissue of vanishing gradients associated with the cross-entropy\nloss function, which is calculated as\nιac = 1\nn\nK∑\nk\nSL1\n(\nMk, ˆMk\n)\n(4)\nSL1(y, ˆy)=\n{\n0.5(ˆy −y)2,|ˆy −y| < 1\n|ˆy −y|− 0.5,|ˆy −y|≥ 1 . (5)\nSL1 stands for smooth L1 loss function.\nThe enhancement of the loss function in this article enables\nthe model to optimize its performance in the landslide extraction\ntask. It effectively addresses the issue of gradient vanishing,\nconsequently reducing overﬁtting to local details in the training\ndata. This reﬁnement facilitates a more accurate capture of the\ndata’s overall structure and key features.\nB. Landslide Edge Detection Using Morphological Analysis\nConventional machine extraction methods operate at the pixel\nlevel and interpret slope edges as jagged boundaries in many\ncases, which do not align with reality; the results often contain\nnumerous fragmented polygons, requiring time and effort to\nmanually integrate and rectify. In this study, we utilize mor-\nphological analysis and SWT-result-based edge detection to\nrectify the fragmented, jagged, and irregularly deﬁned landslide\nboundaries [39], [40], [41].\nThe steps for landslide edge detection based on the morpho-\nlogical analysis are as follows.\n1) In image preprocessing, we utilize sample quantization or\ncoding to transform the initial continuous space and lumi-\nnance into discrete representations. To enhance computa-\ntional and output efﬁciency, the raw image is partitioned\ninto anM×N a r r a yw i t haﬁ x e du n i ts i z e\nFM (x,y)=\n⎧\n⎪⎨\n⎪⎩\nF(0,0) ... F (0,N −1)\n... ... ...\nF(M −1,0) ... F (M −1,N −1)\n⎫\n⎪⎬\n⎪⎭\n.\n(6)\nPreprocessing of landslide images involves noise reduc-\ntion and enhancement of edge information. During this\nstep, voids within the landslide are ﬁlled, and any debris\nor deformations resulting from the interpretation are re-\nmoved. The UA V image resolution in this study is 0.2 m.\nTo reduce noise and facilitate the subsequent extraction\nof landslide edge structures, we uniformly remove debris\npolygons at the pixel level in a 5× 5 pattern.\n2) Deﬁning Structural Elements: Given that the landslide\ncomprises irregular polygons of various sizes, this study\naddresses the attribution of deciphering result fragments\nin small areas. This study employs the nearest neighbor al-\ngorithm, attributing deciphering result fragments of small\nareas to the landslide body with the nearest Euclidean\ndistance. Concurrently, the connecting area between them\nis replenished\nFL = KNN (Fl,FL) (7)\nwhere Fl represent deciphering result fragments in small\nareas; FL represent the landslide structural elements;\nKNN represent the nearest neighbor algorithm.\n3) Expansion Operation:Conducts an image expansion op-\neration using the updated deﬁned structural elements. This\noperation expands the brightly lit regions, enhancing the\nedge features of the landslide. This process widens the\nregion at the landslide’s boundary, ﬁlling cavities, and\nnarrow gaps in the foreground, enhancing edge continuity\nFL ⊕D = FL|(D)F\n⋂\nFL ̸= ⊘ (8)\nwhere FL represent the landslide structural elements;D\nrepresent the area which to extend.\n4) Corrosive Operation: Applying an erosion operation to\nthe image using structural elements. This operation de-\ncreases high-brightness areas, resulting in more compact\nboundary features for the landslide\nFL ⊖ D = FL|(D)F ∈ FL (9)\nwhere FL represent the landslide structural elements;D\nrepresent the area which to corrode.\n5) Fitting Extraction:The morphology of landslide edges is\ncomplex and inﬂuenced by various factors, and different\ntypes of landslides may show different morphologies.\nHowever, it is difﬁcult for the edges of landslides to show\nmultiple consecutive turns or high curvature changes. In\nthis article, by calculating the difference between the\nexpansion operation and the erosion operation, we can\napproximate the location of the landslide boundary and\nextract its structural elements.\n2590 IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING, VOL. 17, 2024\nFig. 3. (a) Visually interpreted landslide area. (b) FCN extracted landslide\narea. (c) SWT extracted landslide area. (d) MAST extracted landslide area.\n6) Boundary Optimization: Employ smoothing algorithms\nand other edge optimization methods to eliminate un-\nnecessary noise and details, enhancing the clarity and\ncontinuity of the landslide boundary. This process aims\nto optimize the boundary and improve accuracy.\nIV . RESULTS\nA. Remote-Sensing Extraction Results for ETLs\nLandslides were extracted from UA V images using the MAST\nmodel [see Fig. 3(b)]. These extractions were then compared\nand analyzed in comparison to those obtained through the SWT\nmodel [see Fig. 3(c)] and the deep fully CNN model [see\nFig. 3(d)] [38]. Speciﬁcally, FCN extracted landslides covering\nan area of 1.43 km2, SWT extracted landslides covering 1.46\nkm2, and MAST extracted landslides covering 1.46 km2.T h i s\nanalysis indicates that landslides extracted using the SWT and\nMAST models more closely align with the reference ETLs cat-\nalog. The comparison of landslide area and distribution reveals\nnotable differences. The FCN model tends to fragment large\nlandslides (e.g., landslide A), forming multiple smaller ones,\nwhereas the SWT and MAST models better capture the entire\nlandslide. Similarly, for extensive landslides (e.g., landslide B),\nthe FCN model often misconstrues them as several smaller\nlandslides while the SWT and MAST models accurately identify\nthe complete landslide. However, in cases where landslides are\ninterconnected, distinguishing and decomposing them proves\nchallenging for all three methods. For instance, landslide C,\nsituated on the right bank of a river, is identiﬁed by all three\nmodels as a single landslide, conﬂating it with a landslide on the\nleft bank of the river. The MAST model displays an advantage\nin certain cases, such as landslide D, where the FCN and SWT\nmodels misidentify it while the MAST model closely aligns with\nthe parameter data for the identiﬁed landslides.\nB. Semantic Segmentation Accuracy\nAccording to the results obtained from different models for\nETL extraction, we constructed a confusion matrix for ETLs and\nTABLE I\nCONFUSION MATR IX FO RLANDSLIDE EXTRACTION RESULTS\nTABLE II\nLANDSLIDE EXTRACTION AREA RESULTS FROM REMOTE-SENSING IMAGE\nno ETLs (refer to TableI). In the matrix, “P” denotes the positive\nregion, signifying the area where ETLs are present, and “N” in-\ndicates the negative region, representing the area without ETLs.\n“TP” refers to the true-positive region, where ETLs are accu-\nrately identiﬁed, aligning with both actual and predicted positive\nconditions. On the other hand, “TN” signiﬁes the true-negative\nregion, correctly capturing the absence of landslides in both\nactual and predicted negative conditions. “FN” stands for the\nfalse-negative region, denoting areas misclassiﬁed as nonland-\nslides despite being actual landslides. Finally, “FP” refers to the\nfalse-positive region, representing areas incorrectly identiﬁed as\nlandslides when they are not. Analyzing the confusion matrix\nresults in Table I, we observe that FCN accurately extracted\nlandslides covering an area of 1.23 km2. In comparison, SWT\nand MAST demonstrated improved performance by identifying\nlandslides covering 1.27 km2 and 1.28 km2, respectively. These\nvalues were 0.03 km2 and 0.04 km2 higher than FCNs extrac-\ntion results. Notably, FCN failed to extract landslides covering\n0.26 km2, the highest among the three methods. In contrast,\nMAST achieved the best results with only 0.21 km2 of extracted\nlandslides.\nBased on the confusion matrix, ﬁve metrics (see TableII)\nwere calculated to obtain the overall accuracy, positive precision,\nrecall, F1 score, and mean intersection and merger ratio (mIoU)\nto quantitatively compare the accuracy of different models for\nETLs extraction.\nAccuracy is the proportion of correct predictions to the total\nnumber of results and is given as\nAccuracy =( TP + TN)/(TP + TN + FP + FN). (10)\nHUANG et al.: MAST: ETLS EXTRACTION METHOD COMBINING MORPHOLOGICAL ANALYSIS EDGE RECOGNITION 2591\nPositive precision (precision) is the proportion of positive\ncorrect areas to the total positive data and is given by the formula\nPrecision = TP/(TP + FP). (11)\nThe recall rate (recall) reﬂects the ratio of ETLs samples\npredicted as correct to all actual ETLs samples and is given\nby the formula\nRecall = TP/(TP + FN). (12)\nThe F1 index (F1-score) is the harmonic mean of precision\nand recall and is given by the formula\nF1=2 (precision ×recall)/(precision + recall). (13)\nThe mean intersection and merger ratio (mIoU) is the average\nof the ratio of the intersection and merger sets of the 2 sets of\ntrue and predicted values and is given as\nmIoU =( TP/(TP + FP + FN)+ TN/(TN + FP + FN))/2.\n(14)\nThe eight metrics presented in TableII are highly representa-\ntive within the chosen domain of image semantic segmentation.\nIt is evident that both the MAST and SWT algorithms consis-\ntently outperform the FCN algorithm across most metrics. In\nterms of overall accuracy, both SWT and MAST surpass FCN\nby over 1%, with MAST exhibiting a slight advantage over SWT\nby 0.17%. Positive accuracy is notably higher with SWT at 1.3%\nover FCN; however, MAST further improves by 1.6% compared\nto SWT, showcasing its superior accuracy in ETLs extraction.\nThis trend is similarly reﬂected in the mIoU values, where\nMAST exceeds FCN by 2.85% and surpasses SWT by 1.11%. In\nsummary, the MAST algorithm consistently achieves superior\naccuracy in the task of landslide extraction. Nevertheless, it is\nessential to acknowledge that due to the relatively small landslide\narea in comparison to the nonlandslide area, traditional accuracy\nevaluation metrics may not effectively represent the disparities\nin ETLs extraction accuracy across various machine learning\nmodels.\nV. DISCUSSION\nA. Impact of Morphological Analysis on Landslide Boundary\nExtraction\nIn this study, we present a detailed comparison of land-\nslide extraction boundaries using FCN, SWT, and MAST on\nUA V imagery (see Fig.4). The MAST model, incorporating\na morphological analysis step, demonstrates signiﬁcant advan-\ntages in identifying landslide areas on an individual landslide\nlevel. Its extraction results align more closely with the objec-\ntive characteristics of ETLs boundaries. By synthesizing deep\nlearning models and morphological analysis, MAST effectively\naddresses morphological features inherent to landslides. It com-\npensates for the limitations of deep learning models in handling\ncomplex features’ boundaries, overcoming issues, such as debris\npolygons, incomplete landslide interpretation, hollow areas, and\nrugged landslide boundaries. Consequently, the boundary of the\nlandslide is smoothed, eliminating the jagged state. This under-\nscores MASTs performance in landslide extraction and analysis,\nFig. 4. Schematic diagram illustrating the extraction results of each method\nfor a single landslide. (a) SWT landslide extraction result: contains numerous\ndebris polygons. (b) SWT landslide extraction result: interprets a single landslide\nsection as two separate landslide regions. (c) SWT extraction result: shows\nhollow areas within the landslide.\nshowcasing its prowess in integrating diverse technological tools\nto enhance model performance.\nFirst, the MAST method effectively eliminates debris poly-\ngons. Both the SWT and FCN models tend to generate numerous\ndebris polygons within landslide areas due to surface complexity\nand image coverage. This issue is nearly unavoidable following\na landslide event. However, the introduction of morphological\nanalysis in the MAST model allows for the removal of these\ndebris polygons, thus rectifying the oversegmentation of indi-\nvidual landslides [see Fig.4(a)]. In our study, FCN resulted in\n37 609 debris polygons and SWT in 4978 debris polygons while\nthe MAST model yielded none. Automated removal of debris\npolygons signiﬁcantly reduces the time and labor required for\nmanual clean-up.\nSecond, the MAST method addresses the challenge of a single\nlandslide being extracted as multiple smaller landslides. This\noften arises due to the decomposition of ETLs into various\nstacking zones, with vegetation cover further complicating the\nsituation. The SWT model, in particular, tends to classify these\nzones as distinct small landslides, a limitation not fully resolved\nby deep learning algorithms alone. The MAST model effectively\nseparates these smaller landslides, reaggregates them into their\nprimary landslide form [see Fig.4(b)], and ﬁlls in the interven-\ning connectivity, rectifying the problem of mistaking a single\nlandslide for multiple smaller ones.\nThe third crucial improvement involves resolving hollow\nareas within landslide bodies. In some larger ETLs, fragmen-\ntation leaves parts of the vegetation intact within the land-\nslide body, often unconnected to surrounding vegetation. Both\nthe SWT and FCN models tend to misinterpret these vege-\ntated areas within the landslide body as nonlandslide areas,\nresulting in hollow boundaries [see Fig. 4(c)]. To enhance\nextraction accuracy, the MAST model employs morphological\nanalysis to ﬁll these hollow regions. Utilizing area operations,\nit identiﬁes independent areas within the polylines, examines\ntheir topology, and identiﬁes overlapping regions. Since the\nETLs considered occurred within a relatively recent timeframe,\nwithout overlapping old and new landslides, these identiﬁed\noverlapping regions are reassigned as parts of the landslides,\neffectively addressing the issue of hollow areas within the\nlandslides.\n2592 IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING, VOL. 17, 2024\nFig. 5. Schematic diagram of Boundary IoU and mIoU calculation methods.\nB. Boundary Segmentation Calculation Metrics—Boundary\nIoU\nThe traditional parameters for evaluating the accuracy of\nautomatic landslide extraction are predominantly inﬂuenced by\nthe landslide area in relation to the nonlandslide area. Given that\nthe landslide area is typically much smaller compared to the\nnonlandslide area, even a correct extraction of landslide areas\nwith a low accuracy would result in a large correctly extracted\nnonlandslide area, inﬂating the overall accuracy. Furthermore,\nthese evaluation metrics emphasize overall variability and may\nnot effectively account for boundary consistency. In the domain\nof computer vision, deep learning has attained a high level of\nproﬁciency in landslide extraction applications. However, the\ndifferences in ETLs extraction among various deep learning\nmodels are marginal, rendering traditional accuracy evalua-\ntion parameters inadequate for characterizing extraction accu-\nracy differences. To better elucidate these disparities in ETLs\nextraction achieved by distinct deep learning methodologies,\nthis study employs Boundary IoU (see Fig.5), a computational\nmetric for boundary segmentation, to evaluate landslide extrac-\ntion accuracy[42].\nBoundary IoU represents an extension of IoU-based met-\nrics, speciﬁcally designed for pixel-level boundary segmentation\ntasks aimed at accurately delineating object boundaries. Conse-\nquently, this parameter stands as a highly effective measure of\nthe consistency between automatically extracted boundaries of\nETLs and their true boundaries. Within the domain of image\nsegmentation, the quality of boundary segmentation serves as\na crucial reference index for determining the effectiveness of\nan algorithm. Currently prevalent mIoU-based AP metrics often\nlack sensitivity toward the segmentation quality of mask bound-\naries, contributing to the limited enhancement of mask boundary\nsegmentation quality despite ongoing algorithmic optimizations\nin recent years. In contrast, Boundary IoU demonstrates sensi-\ntivity to the segmentation quality of object boundaries, providing\na robust assessment of different segmentation algorithms con-\ncerning object boundaries.\nBoundary IoU is calculated as\nBoundary IoU= |(Gd) ∩G) ∩(Pd) ∩P)|\n|(Gd) ∩G) ∪(Pd) ∩P)| (15)\nTABLE III\nBOUNDARY IOUC ALCULA TIONINDICA TORS\nFig. 6. Variances in values calculated by FCN, SWT, and MAST across various\nmetrics are examined.\nwhere Gd denotes the set of pixels whose distance from the\ncontour of the ground truth mask is not greater thand, andPd\ndenotes the set of pixels whose distance from the contour of the\npredicted mask is not greater thand (see TableIII).\nThe distancedcontrols the sensitivity of Boundary IoU. When\ndis sufﬁciently large, Boundary IoU is equivalent to Mask IoU.\nOn the other hand, whend is relatively small, Boundary IoU\ndisregards pixels in the mask that are distant from the boundary,\nplacing more emphasis on segmentation quality near the object’s\nboundary, even for larger-sized objects. The range of Boundary\nIoU values is from 0 to 1. A value closer to 1 indicates a higher\noverlap between the predicted boundary and the real boundary,\nsignifying a more accurate prediction. The goal of the boundary\nsegmentation algorithm is to strive for a Boundary IoU as close\nto 1 as possible to achieve precise boundary segmentation.\nThe calculation of Boundary IoU values for ETLs extracted by\nFCN, SWT, and MAST methods (see Fig.6) demonstrates that\nMAST exhibits superior performance for d values of 2 m, 5 m,\nand 10 m, followed by SWT. The Boundary IoU values vary with\ndifferent d values and display a discernible pattern. As thed value\nincreases, the differences in Boundary IoU values of landslides\nextracted by different methods become more prominent, offering\na clearer demonstration of the extraction boundary differences.\nFor instance, at ad value of 2 m, the Boundary IoU values for\nthe three methods are 23.7%, 25.12%, and 26.56%, respectively.\nThe differences among the three methods are relatively small,\nwith SWTs Boundary IoU being 1.42% higher than that of FCN,\nHUANG et al.: MAST: ETLS EXTRACTION METHOD COMBINING MORPHOLOGICAL ANALYSIS EDGE RECOGNITION 2593\nand MASTs being 1.44% higher than SWTs. At ad value of 5 m,\nthe Boundary IoU values for the three methods rise to 44.37%,\n49.29%, and 51.46%, respectively. The differences between the\nthree methods also escalate, with SWTs Boundary IoU being\n4.92% higher than FCNs, and MASTs being 2.17% higher than\nS W T s .A tad value of 10 m, the Boundary IoU values for\nthe three methods increase to 59.23%, 68.11%, and 70.26%,\nrespectively. The differences between the three also intensify,\nwith SWTs Boundary IoU being 8.88% higher than FCNs, and\nMASTs being 2.15% higher than SWTs. These ﬂuctuations\nin Boundary IoU values for different methods illustrate that\ncompared to the FCN model, the SWT model signiﬁcantly\nimproves accuracy in ETLs extraction. Moreover, MAST also\nenhances the accuracy of ETLs extraction, although the degree\nof improvement is relatively moderate. Simultaneously, this\nstudy aims to demonstrate the stability of the MAST model\nby calculating the variance of the boundary IoU results. At\nd values of 2 m, 5 m, and 10 m, the variances are 0.68,\n0.39, and 0.34, respectively. These results indicate that MAST\ncan maintain a relatively stable performance across different\nETL scenarios.\nIn comparison to the traditional semantic segmentation index\nmIoU, FCN, SWT, and MAST all achieved scores higher than\n83% (see Fig.6). However, because the mIoU algorithm places\ngreater emphasis on overall region identiﬁcation, the differences\nin mIoU scores between different algorithms are relatively mi-\nnor, making it less effective in reﬂecting MASTs enhancement\nin the landslide boundary extraction segment.\nThe disparity between MAST and SWT becomes more notice-\nable at mIoU and BIoU fordvalues of 2 m and 5 m. Speciﬁcally,\nat a d value of 5 m, SWT exhibits a 4.92% higher BIoU than\nFCN, and MAST surpasses SWT by 2.17% in BIoU. The BIoU\ndifference is nearly twice that of mIoU. At ad value of 10 m,\nSWT achieves an 8.88% higher BIoU than FCN, with MAST\nexceeding SWT by 2.15% in BIoU. Here again, the difference in\nBIoU is considerably more pronounced than in mIoU. Notably,\nthe BIoU difference between MAST and SWT stabilizes at\napproximately 2.17% for a d value of 5 m and 2.15% for a\nd value of 10 m, indicating a leveling off. Consequently, this\nstudy posits that the inﬂuence of morphological analysis on\nthe speciﬁc boundary range between MAST and SWT remains\nwithin 10 m. This conclusion is substantiated by the fact that a\nrange exceeding 10 m is sufﬁciently broad for seismic landslides,\nadequately covering the landslide range. The results of numeri-\ncal BIoU calculations no longer yield signiﬁcant differences. For\nd values of 5 m and 10 m, MAST outperforms SWT by 2.17%\nand 2.15%, respectively. Hence, beyond a distance value of 5 m,\nthe integration of morphological analysis yields approximately\na 2% improvement for MAST. However, due to the constraint\nimposed by the area of earthquake-induced landslides, thed\nvalue cannot be boundlessly increased.\nVI. CONCLUSION\nIn this study, we enhance the SWT model by modifying\nits hybrid loss function and integrating a morphological edge\ndetection method with morphological analysis, resulting in the\nMAST ETLs extraction model. We also introduce the Boundary\nIoU method to evaluate ETLs extraction accuracy and draw the\nfollowing conclusions from the comparison experiments.\n1) The MAST model excels in landslide extraction. Com-\npared to the traditional FCN model, MAST exhibits supe-\nrior feature extraction and context understanding capabil-\nities when processing landslide images. Its self-attention\nmechanism and hierarchical structure enable the capture of\nboth detailed and global landslide information, thereby en-\nhancing edge extraction accuracy at the semantic segmen-\ntation level. Overall, MAST achieves a 1.23% higher ac-\ncuracy than FCN and a 0.17% higher accuracy than SWT.\nPositive accuracy is 2.92% higher than FCN and 1.62%\nhigher than SWT. The mIoU is 2.85% higher than FCN\nand 1.11% higher than SWT. The morphological edge\ndetection integrated into MAST signiﬁcantly contributes\nto landslide boundary extraction. Through morphological\noperations such as swelling and erosion, it enhances the\ncontinuity and accuracy of landslide boundaries. This\nmethod effectively reduces noise and unnecessary de-\ntails, especially in the treatment of debris polygons and\nsegmented small broken landslides, thus improving edge\ndetection accuracy and stability while preserving the shape\nand structural characteristics of the landslide boundary.\n2) The introduced Boundary IoU in the experimental results\nshowcases that more accurate landslide extraction results\nare achievable using the MAST method. According to the\nB IoU results, MAST performs better atd values of 2 m,\n5 m, and 10 m. At ad value of 2 m, MASTs B IoU is 1.42%\nhigher than FCN and 1.44% higher than SWT. At ad value\nof 5 m, MASTs B IoU surpasses FCN by 4.92%, and SWT\nby 2.17%. At ad value of 10 m, MASTs B IoU exceeds\nFCNs by 8.88%, and SWTs by 2.15%. This substantiates\nthat MAST and SWT outperform the FCN model not only\nin traditional semantic segmentation but also in critical\nedge recognition. It highlights MASTs superior ability to\nrecognize boundaries accurately and segment object edges\nprecisely. Additionally, the introduction of morphological\nanalysis has a limited effect on the speciﬁc boundary range\nof both MAST and SWT, staying within 10 m.\nThis study veriﬁes the outstanding performance of the SWT\nmodel in the realm of ETLs machine learning. Moreover, the\nMAST model, an extension of the SWT model, enhances ETLs\nextraction accuracy further. Future efforts should concentrate\non strengthening multisource data fusion, integrating various\nremote sensing, geographic information, and seismic monitoring\ndata to enhance comprehensiveness and accuracy of extraction.\nAlso, since the model used in this article is a UA V image,\nthe data source is single and is affected by the nature of the\nUA V itself, which is subject to weather conditions. In addition,\nthe ETLs extraction model needs to be enhanced with its gen-\neralization capability to incorporate multisource data in order\nto have wider applicability in landslide extraction in different\nregions, under different incentive conditions and with different\ngeological scenarios. Integrating the results of the study with\ndisaster emergency response and decision support systems is\nessential to provide timely and accurate information for disaster\nmanagement and to minimize disaster losses.\n2594 IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING, VOL. 17, 2024\nREFERENCES\n[1] J. Zhang et al., “Distribution patterns of landslides triggered by the 2022 Ms\n6.8 Luding earthquake, Sichuan, China,”J. Mountain Sci., vol. 20, no. 3,\npp. 607–623, Mar. 2023. [Online]. Available: https://link.springer.com/10.\n1007/s11629-022-7772-0\n[2] Z. Xiao et al., “Analysis of spatial distribution of landslides triggered\nby the Ms 6.8 Luding earthquake in China on Sep. 5, 2022,”Geoen-\nvironmental Disasters, vol. 10, no. 1, pp. 1–15, Feb. 2023. [Online].\nAvailable: https://geoenvironmental-disasters.springeropen.com/articles/\n10.1186/s40677-023-00233-w\n[3] D. Costanzo, E. Rotigliano, C. Irigaray, J. D. Jiménez-Perálvarez, and\nJ. Chacón, “Factors selection in landslide susceptibility modelling on\nlarge scale following the GIS matrix method: Application to the River\nBeiro Basin (Spain),”Natural Hazards Earth Syst. Sci., vol. 12, no. 2,\npp. 327–340, Feb. 2012. [Online]. Available: https://nhess.copernicus.org/\narticles/12/327/2012/\n[4] G. Rajmohan, C. V . Chinnappan, A. D. J. William, S. C. Balakrishnan,\nB. A. Muthu, and G. Manogaran, “Revamping land coverage analy-\nsis using aerial satellite image mapping,”Trans. Emerg. Telecommun.\nTechnol., vol. 32, no. 7, Jul. 2021, Art. no. e3927. [Online]. Available:\nhttps://onlinelibrary.wiley.com/doi/10.1002/ett.3927\n[5] T. Kavzoglu, I. Colkesen, and E. ¸ Sahin, “Machine learning tech-\nniques in landslide susceptibility mapping: A survey and a case study,”\nin Landslides: Theory, Practice and Modelling . Cham, Switzerland:\nSpringer, 2018. [Online]. Available: https://www.semanticscholar.org/\npaper/f2f4a4cc8c7179f7a91d5b0c25a6ab8d5a79bc57\n[6] M. Marjanovi´c, M. Kovaˇcevi´c, B. Bajat, S. Mihali´c, and B. Abolmasov,\n“Landslide assessment of the Starˇca Basin (Croatia) using machine\nlearning algorithms,” Acta Geotechnica Slovenica, vol. 8, pp. 45–55,\n2011.\n[7] S. J. Rigatti, “Random forest,” J. Insurance Med. , vol. 47, no. 1,\npp. 31–39, Jan. 2017. [Online]. Available: https://meridian.allenpress.\ncom/jim/article/47/1/31/131479/Random-Forest\n[8] J. L. Speiser, M. E. Miller, J. Tooze, and E. Ip, “A comparison of random\nforest variable selection methods for classiﬁcation prediction modeling,”\nExpert Syst. Appl., vol. 134, pp. 93–101, Nov. 2019. [Online]. Available:\nhttps://linkinghub.elsevier.com/retrieve/pii/S0957417419303574\n[9] B. T. Pham, D. T. Bui, I. Prakash, and M. B. Dholakia, “Rotation forest\nfuzzy rule-based classiﬁer ensemble for spatial prediction of landslides\nusing GIS,”Natural Hazards, vol. 83, no. 1, pp. 97–127, Aug. 2016. [On-\nline]. Available: http://link.springer.com/10.1007/s11069-016-2304-2\n[10] M. Belgiu and L. Dr˘agu¸t, “Random forest in remote sensing: A review\nof applications and future directions,” ISPRS J. Photogrammetry Re-\nmote Sens., vol. 114, pp. 24–31, Apr. 2016. [Online]. Available: https:\n//linkinghub.elsevier.com/retrieve/pii/S0924271616000265\n[11] D. Seo, Y . Kim, Y . Eo, and W. Park, “Learning-based colorization of\ngrayscale aerial images using random forest regression,”Appl. Sci.,v o l .8 ,\nno. 8, Jul. 2018, Art. no. 1269. [Online]. Available: http://www.mdpi.com/\n2076-3417/8/8/1269\n[12] W. Chen, Z. Sun, and J. Han, “Landslide susceptibility modeling using\nintegrated ensemble weights of evidence with logistic regression and\nrandom forest models,”Appl. Sci., vol. 9, no. 1, Jan. 2019, Art. no. 171.\n[Online]. Available: https://www.mdpi.com/2076-3417/9/1/171\n[13] C. Pelletier, G. Webb, and F. Petitjean, “Temporal convolutional neural\nnetwork for the classiﬁcation of satellite image time series,”Remote Sens.,\nvol. 11, no. 5, Mar. 2019, Art. no. 523. [Online]. Available: https://www.\nmdpi.com/2072-4292/11/5/523\n[14] F. Ramdhoni, A. Damayanti, and T. L. Indra, “Smorph application for\nlandslide identiﬁcation in Kebumen Regency,”IOP Conf. Ser .: Earth Env-\niron. Sci., vol. 451, no. 1, Mar. 2020, Art. no. 012013. [Online]. Available:\nhttps://iopscience.iop.org/article/10.1088/1755-1315/451/1/012013\n[15] Y . Wang, X. Wang, and J. Jian, “Remote sensing landslide recogni-\ntion based on convolutional neural network,” Math. Problems Eng.,\nvol. 2019, pp. 1–12, Sep. 2019. [Online]. Available: https://www.hindawi.\ncom/journals/mpe/2019/8389368/\n[16] C. Tang, J. Tang, C. J. van Westen, J. Han, O. Mavrouli, and C. Tang,\n“Modeling landslide failure surfaces by polynomial surface ﬁtting,”Ge-\nomorphology, vol. 368, Nov. 2020, Art. no. 107358. [Online]. Available:\nhttps://linkinghub.elsevier.com/retrieve/pii/S0169555X20303317\n[17] H. Lu et al., “Landslides information extraction using object-oriented\nimage analysis paradigm based on deep learning and transfer learning,”\nRemote Sens., vol. 12, no. 5, Feb. 2020, Art. no. 752. [Online]. Available:\nhttps://www.mdpi.com/2072-4292/12/5/752\n[18] D. Cha, “Landslides detection and volume estimation in Jinbu area of\nKorea,”Forest Sci. Technol., vol. 14, pp. 61–65, 2018.\n[19] W. Xia, J. Chen, J. Liu, C. Ma, and W. Liu, “Landslide extraction\nfrom high-resolution remote sensing imagery using fully convolutional\nspectral–topographic fusion network,” Remote Sens., vol. 13, no. 24,\nDec. 2021, Art. no. 5116. [Online]. Available: https://www.mdpi.com/\n2072-4292/13/24/5116\n[20] M. I. Sameen and B. Pradhan, “Landslide detection using resid-\nual networks and the fusion of spectral and topographic infor-\nmation,” IEEE Access , vol. 7, pp. 114363–114373, 2019. [On-\nline]. Available: https://www.semanticscholar.org/paper/7d0c946386b99\ne9782d1e3e966ebcaaf5574b4cc\n[21] C. Ye et al., “Landslide detection of hyperspectral remote sensing data\nbased on deep learning with constrains,”IEEE J. Sel. Topics Appl. Earth\nObserv. Remote Sens., vol. 12, no. 12, pp. 5047–5060, Dec. 2019. [Online].\nAvailable: https://ieeexplore.ieee.org/document/8911205/\n[22] W. Wiratama and D. Sim, “Fusion network for change detection of high-\nresolution panchromatic imagery,”Appl. Sci., vol. 9, no. 7, Apr. 2019,\nArt. no. 1441. [Online]. Available: https://www.mdpi.com/2076-3417/9/\n7/1441\n[23] H. Zhao, F. Liu, H. Zhang, and Z. Liang, “Convolutional neural net-\nwork based heterogeneous transfer learning for remote-sensing scene\nclassiﬁcation,” Int. J. Remote Sens., vol. 40, no. 22, pp. 8506–8527,\nNov. 2019. [Online]. Available: https://www.tandfonline.com/doi/full/10.\n1080/01431161.2019.1615652\n[24] C. Tang, C. J. Van Westen, H. Tanyas, and V . G. Jetten, “Analysing post-\nearthquake landslide activity using multi-temporal landslide inventories\nnear the epicentral area of the 2008 Wenchuan earthquake,”Natural Haz-\nard Earth Syst. Sci., vol. 16, no. 12, pp. 2641–2655, Dec. 2016. [Online].\nAvailable: https://nhess.copernicus.org/articles/16/2641/2016/\n[25] M. Tang et al., “Activity law and hydraulics mechanism of land-\nslides with different sliding surface and permeability in the three\nGorges Reservoir Area, China,” Eng. Geol. , vol. 260, Oct. 2019,\nArt. no. 105212. [Online]. Available: https://linkinghub.elsevier.com/\nretrieve/pii/S0013795218304538\n[26] C. Zhang et al., “A deeply supervised image fusion network for\nchange detection in high resolution bi-temporal remote sensing im-\nages,” ISPRS J. Photogrammetry Remote Sens., vol. 166, pp. 183–200,\nAug. 2020. [Online]. Available: https://linkinghub.elsevier.com/retrieve/\npii/S0924271620301532\n[27] H. Wang, Q. Guo, X. Ge, and L. Tong, “A spatio-temporal monitoring\nmethod based on multi-source remote sensing data applied to the case\nof the Temi landslide,”Land, vol. 11, no. 8, Aug. 2022, Art. no. 1367.\n[Online]. Available: https://www.mdpi.com/2073-445X/11/8/1367\n[28] Q. Guo, L. Tong, and H. Wang, “A monitoring method based on vegetation\nabnormal information applied to the case of Jizong shed-tunnel landslide,”\nRemote Sens., vol. 14, no. 22, Nov. 2022, Art. no. 5640. [Online]. Available:\nhttps://www.mdpi.com/2072-4292/14/22/5640\n[29] J. Wang, W. Li, Y . Wang, R. Tao, and Q. Du, “Representation-enhanced sta-\ntus replay network for multisource remote-sensing image classiﬁcation,”\nIEEE Trans. Neural Netw. Learn. Syst., pp. 1–13, 2023.\n[30] M. Zhang, W. Li, X. Zhao, H. Liu, R. Tao, and Q. Du, “Morphological\ntransformation and spatial-logical aggregation for tree species classiﬁca-\ntion using hyperspectral imagery,”IEEE Trans. Geosci. Remote Sens.,\nvol. 61, pp. 1–12, Jan. 2023, Art. no. 5501212. [Online]. Available:\nhttps://ieeexplore.ieee.org/document/10005092/\n[31] C. Zhang, W. Jiang, Y . Zhang, W. Wang, Q. Zhao, and C. Wang, “Trans-\nformer and CNN hybrid deep neural network for semantic segmentation\nof very-high-resolution remote sensing imagery,”IEEE Trans. Geosci.\nRemote Sens., vol. 60, pp. 1–20, Jan. 2022, Art. no. 4408820. [Online].\nAvailable: https://ieeexplore.ieee.org/document/9686732/\n[32] S. A. Kamran, K. F. Hossain, A. Tavakkoli, S. A. Baker, and S. L. Zucker-\nbrod, “SwinVFTR: A novel volumetric feature-learning transformer for\n3D OCT ﬂuid segmentation,” 2023,arXiv:2303.09233.\n[33] M. Van Nguyen, V . D. Lai, A. P. B. Veyseh, and T. H. Nguyen, “Trankit: A\nlight-weight transformer-based toolkit for multilingual natural language\nprocessing,” inProc. 16th Conf. Eur . Chapter Assoc. Comput. Linguistics:\nSyst. Demonstrations, 2021, pp. 80–90.\n[34] J. M. J. Valanarasu, P. Oza, I. Hacihaliloglu, and V . M. Patel, “Medical\ntransformer: Gated axial-attention for medical image segmentation,” in\nProc. Int. Conf. Medical Image Comput. Comput.-Assisted Intervention,\n2021, pp. 36–46.\n[35] H. Zhao, L. Jiang, J. Jia, P. H. S. Torr, and V . Koltun, “Point transformer,”\nin Proc. IEEE/CVF Int. Conf. Comput. Vis., 2021, pp. 16239–16248.\n[36] Y . Huang et al., “How spatial resolution of remote sensing image affects\nearthquake triggered landslide detection: An example from 2022 Luding\nearthquake, Sichuan, China,”Land, vol. 12, no. 3, Mar. 2023, Art. no. 681.\n[Online]. Available: https://www.mdpi.com/2073-445X/12/3/681\nHUANG et al.: MAST: ETLS EXTRACTION METHOD COMBINING MORPHOLOGICAL ANALYSIS EDGE RECOGNITION 2595\n[37] A. Vaswani et al., “Attention is all you need,” inProc. 31st Int. Conf.\nNeural Inf. Process. Syst., 2017, pp. 6000–6010.\n[38] Z. Liu et al., “Swin transformer: Hierarchical vision transformer us-\ning shifted windows,” in Proc. IEEE/CVF Int. Conf. Comput. Vis.\n2021, pp. 9992–10002. [Online]. Available: https://ieeexplore.ieee.org/\ndocument/9710580/\n[39] A. álvarez and T. Ritchey, “Applications of general morphological analy-\nsis,” Acta Morphologica Generalis, vol. 4, no. 1, pp. 1–40, 2015.\n[40] F. Wang, E. Wu, S. Chen, and H. Wu, “Texture feature extraction and\nmorphological analysis of landslide based on image edge detection,”Math.\nProblems Eng., vol. 2022, pp. 1–12, Jul. 2022. [Online]. Available: https:\n//www.hindawi.com/journals/mpe/2022/2302271/\n[41] T. W. Yeh and R. Y . Chuang, “Morphological analysis of landslides\nin extreme topography by UAS-SfM: Data acquisition, 3D models and\nchange detection,”Int. Arch. Photogrammetry, Remote Sens., Spatial Inf.\nSci., vol. 43, pp. 173–178, Aug. 2020. [Online]. Available: https://isprs-\narchives.copernicus.org/articles/XLIII-B5-2020/173/2020/\n[42] B. Cheng, R. Girshick, P. Dollar, A. C. Berg, and A. Kirillov, “Boundary\nIoU: Improving object-centric image segmentation evaluation,” inProc.\nIEEE/CVF Conf. Comput. Vis. Pattern Recognit., 2021, pp. 15329–15337.\n[Online]. Available: https://ieeexplore.ieee.org/document/9578118/\nYu Huang is currently working toward the M.Sc. de-\ngree in remote sensing and mountain hazard detection\nwith the School of Surveying and Geoinformation\nEngineering, East China University of Technology,\nNanchang, China, and the Institute of Mountain Haz-\nards and Environment, Chinese Academy of Sci-\nences, Chengdu, China.\nHis research interests include drone and satellite\nimage processing and machine learning for natural\ndisaster management.\nJianqiang Zhang received the Ph.D. degree in the\ndistribution and risk assessment of landslides trig-\ngered by the Wenchuan earthquake from the Insti-\ntute of Mountain Hazards and Environment, Chinese\nAcademy of Sciences, Chengdu, China, in 2011.\nHe is currently an Associate Professor with the\nInstitute of Mountain Hazards and Environment, Chi-\nnese Academy of Sciences, and also with the Key\nLaboratory of Mountain Hazards and Earth Surface\nProcess, Institute of Mountain Hazards and Environ-\nment, Chinese Academy of Sciences. He has long\nbeen committed to the research of remote sensing identiﬁcation and suscepti-\nbility assessment and risk assessment of mountain disasters, such as landslides\nand debris ﬂows. His research interests include comprehensive risk assessment\nand risk change of mountain disasters.\nHaiqing He received the Ph.D. degree in geodesy and\nsurvey engineering from Wuhan University, Wuhan,\nChina, in 2013.\nHe is currently a Full Professor with the School\nof Surveying and Geoinformation Engineering, East\nChina University of Technology, Nanchang, China,\nand also with the Key Laboratory of Mine Environ-\nmental Monitoring and Improving around Poyang\nLake of Ministry of Natural Resources, East China\nUniversity of Technology. His research interests in-\nclude photogrammetry and remote sensing, image\nprocessing, and machine learning.\nYang Jia, photograph and biography not available at the time of publication.\nRong Chen, photograph and biography not available at the time of publication.\nYonggang Ge,photograph and biography not available at the time of publication.\nZaiyang Ming, photograph and biography not available at the time of publica-\ntion.\nLili Zhang, photograph and biography not available at the time of publication.\nHaoyu Li, photograph and biography not available at the time of publication."
}