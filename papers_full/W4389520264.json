{
  "title": "Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!",
  "url": "https://openalex.org/W4389520264",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2140097851",
      "name": "Yubo Ma",
      "affiliations": [
        "Nanyang Technological University"
      ]
    },
    {
      "id": "https://openalex.org/A2110093419",
      "name": "Yixin Cao",
      "affiliations": [
        "Singapore Management University"
      ]
    },
    {
      "id": "https://openalex.org/A2095929489",
      "name": "Hong Yong",
      "affiliations": [
        "Nanyang Technological University"
      ]
    },
    {
      "id": "https://openalex.org/A2124989948",
      "name": "Aixin Sun",
      "affiliations": [
        "Nanyang Technological University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4389520009",
    "https://openalex.org/W4366400290",
    "https://openalex.org/W4385572845",
    "https://openalex.org/W4285114721",
    "https://openalex.org/W3177312484",
    "https://openalex.org/W4297633153",
    "https://openalex.org/W4385571184",
    "https://openalex.org/W2952087486",
    "https://openalex.org/W4385569985",
    "https://openalex.org/W3106098584",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W2908510526",
    "https://openalex.org/W4385571676",
    "https://openalex.org/W3156636935",
    "https://openalex.org/W4221159406",
    "https://openalex.org/W4385571411",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W4378465119",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W3105470358",
    "https://openalex.org/W4297899309",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4389523957",
    "https://openalex.org/W3122241445",
    "https://openalex.org/W3034900014",
    "https://openalex.org/W3156470785",
    "https://openalex.org/W4321524373",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W4385572217",
    "https://openalex.org/W4286987939",
    "https://openalex.org/W2407338347",
    "https://openalex.org/W4385572965",
    "https://openalex.org/W4221166835",
    "https://openalex.org/W4385573087",
    "https://openalex.org/W3034891697",
    "https://openalex.org/W2626967530",
    "https://openalex.org/W4389524085",
    "https://openalex.org/W4302305884",
    "https://openalex.org/W4385573954",
    "https://openalex.org/W4221161695",
    "https://openalex.org/W4385571451",
    "https://openalex.org/W4389519818",
    "https://openalex.org/W4287891464",
    "https://openalex.org/W4385573991",
    "https://openalex.org/W2251628379",
    "https://openalex.org/W4323650985"
  ],
  "abstract": "Large Language Models (LLMs) have made remarkable strides in various tasks. Whether LLMs are competitive few-shot solvers for information extraction (IE) tasks, however, remains an open problem. In this work, we aim to provide a thorough answer to this question. Through extensive experiments on nine datasets across four IE tasks, we demonstrate that current advanced LLMs consistently exhibit inferior performance, higher latency, and increased budget requirements compared to fine-tuned SLMs under most settings. Therefore, we conclude that LLMs are not effective few-shot information extractors in general. Nonetheless, we illustrate that with appropriate prompting strategies, LLMs can effectively complement SLMs and tackle challenging samples that SLMs struggle with. And moreover, we propose an adaptive filter-then-rerank paradigm to combine the strengths of LLMs and SLMs. In this paradigm, SLMs serve as filters and LLMs serve as rerankers. By prompting LLMs to rerank a small portion of difficult samples identified by SLMs, our preliminary system consistently achieves promising improvements (2.4% F1-gain on average) on various IE tasks, with an acceptable time and cost investment.",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 10572–10601\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nLarge Language Model Is Not a Good Few-shot InformationExtractor,\nbut a GoodReranker for Hard Samples!\nYubo Ma1, Yixin Cao2, YongChing Hong1, Aixin Sun1\n1 S-Lab, Nanyang Technological University\n2 Singapore Management University\nyubo001@e.ntu.edu.sg\nAbstract\nLarge Language Models (LLMs) have made\nremarkable strides in various tasks. Whether\nLLMs are competitive few-shot solvers for in-\nformation extraction (IE) tasks, however, re-\nmains an open problem. In this work, we\naim to provide a thorough answer to this ques-\ntion. Through extensive experiments on nine\ndatasets across four IE tasks, we demonstrate\nthat current advanced LLMs consistently ex-\nhibit inferior performance, higher latency, and\nincreased budget requirements compared to\nfine-tuned SLMs under most settings. There-\nfore, we conclude that LLMs are not effec-\ntive few-shot information extractors in gen-\neral 1. Nonetheless, we illustrate that with\nappropriate prompting strategies, LLMs can\neffectively complement SLMs and tackle chal-\nlenging samples that SLMs struggle with. And\nmoreover, we propose an adaptive filter-then-\nrerank paradigm to combine the strengths of\nLLMs and SLMs. In this paradigm, SLMs\nserve as filters and LLMs serve as rerankers.\nBy prompting LLMs to rerank a small portion\nof difficult samples identified by SLMs, our pre-\nliminary system consistently achieves promis-\ning improvements (2.4% F1-gain on average)\non various IE tasks, with an acceptable time\nand cost investment. Our code is available at\nhttps://github.com/mayubo2333/LLM-IE.\n1 Introduction\nLarge Language Models (LLMs, Brown et al. 2020;\nChowdhery et al. 2022; Touvron et al. 2023) have\nshown remarkable abilities on various NLP applica-\ntions such as factual question answering (Yu et al.,\n2023; Sun et al., 2023), arithmetic reasoning (Chen\net al., 2022a; Qian et al., 2023) and logical rea-\nsoning (Jung et al., 2022; Pan et al., 2023). Given\nthe reasoning, memorization, instruction-following\nand few-shot adaption capabilities emerging from\n1A more precise assertion is that current LLMs, with\nvanilla prompting setting and without IE-specific fine-tuning,\nare not good few-shot information extractors in general.\nLLMs, it prompts a compelling question: Can\nLLMs be used to boost performance in few-shot\ninformation extraction (IE) tasks?\nTo answer this question, we conduct an exten-\nsive empirical study to compare the performance\nbetween LLMs using in-context learning 2 (ICL)\nand fine-tuned Small Language Models (SLMs).\nWe fairly evaluate SLMs-based and LLMs-based\nmethods across nine datasets spanning four com-\nmon IE tasks: (1) Named Entity Recognition, (2)\nRelation Extraction, (3) Event Detection and (4)\nEvent Argument Extraction. For each dataset, we\nexplored four to six settings to encompass typi-\ncal low-resource extents, from 1-shot to 20-shot or\neven more. Given the potential sensitivity of LLMs’\nperformance to the prompt context, we meticu-\nlously considered variations in instruction, demon-\nstration number and selection strategy, prompt for-\nmat, etc. Our study reveals that LLMs excel over\nSLMs only when annotations are extremely lim-\nited, i.e., both label types 3 and the samples 4 per\nlabel are extremely scarce. With more ( e.g., hun-\ndreds of) samples, SLMs significantly outperform\nLLMs. Furthermore, LLMs incur greater inference\nlatency and costs than fine-tuned SLMs. Hence, we\nclaim that current LLMs are not good few-shot\ninformation extractors in general.\nWe further investigate whether LLMs and SLMs\nexhibit different abilities to handle various types of\nsamples. We categorize samples according to their\ndifficulty measured by SLMs’ confidence scores,\nand compare LLMs’ and SLMs’ results within each\ngroup. We find that LLMs are good at hard sam-\nples, though bad at easy samples. We posit that\nthe knowledge and reasoning abilities in LLMs en-\nable them to handle hard samples (which are sim-\n2All LLMs discussed in this paper are not fine-tuned, and\nresults for LLMs are based on in-context learning.\n3Label types denote entity/relation/event/role types in dif-\nferent tasks. We use them interchangeably there-in-after.\n4Samples refer to (i) demonstrations in ICL of LLMs, or\n(ii) training samples for SLMs’ fine-tuning.\n10572\nply beyond SLMs’ capabilities) well. Nevertheless,\nLLMs demonstrate strong predisposition to false-\npositive predictions on negative samples. Since\nmost negative samples are easy samples (which\ncould be solved readily by SLMs), the performance\nof LLMs on easy samples sometimes collapses and\nare usually much worse than fine-tuned SLMs.\nLeveraging these findings, we pursue an ap-\nproach to incorporate LLMs and SLMs within a\nsingle system and combine their merits. To this end,\nwe propose a novel filter-then-rerank framework.\nThe basic idea is that SLMs serve as a filter and\nLLMs as a reranker. Specifically, SLMs initially\npredict and determine the difficulty of each sample.\nIf the sample is a hard one, we further pass the\ntop-N most-likely candidate labels from SLMs to\nLLMs for reranking. Otherwise we view the predic-\ntion from SLMs as the final decision. By providing\neasy/hard samples with different solution strategies,\nour system utilizes each model’s strengths to com-\nplement each other. Also, it reranks only a small\nsubset of samples and minimizes the extra latency\nand budgets for calling LLMs. With a modest cost\nincrease, our framework yields a consistent F1 im-\nprovement, averaging 2.4% higher than previous\nmethods on various few-shot IE tasks. To the best\nof our knowledge, this is the first successful attempt\nto use LLMs to enhance few-shot IE tasks.\n2 Related Work\n2.1 LLMs for Information Extraction\nRecent studies have increasingly explored Informa-\ntion Extraction (IE) tasks using LLMs. Drawing in-\nspiration from instruction tuning (Wei et al., 2022a),\nseveral methods (Wadhwa et al., 2023; Wang et al.,\n2023a; Lu et al., 2023) transform annotated sam-\nples into instruction-answer pairs and then fine-\ntune LLMs, such as FlanT5 (Chung et al., 2022),\non them. Nonetheless, this method necessitates a\nvast range of samples with diverse schemas and\noften yields suboptimal results in low-resource sce-\nnarios. In the context of few-shot IE tasks, preva-\nlent strategies bifurcate into two main streams. The\nfirst approach perceives LLMs as efficient annota-\ntors (Ding et al., 2023; Josifoski et al., 2023). In\nthese methods, they produce a plethora of pseudo-\nlabeled samples through LLMs and leverage the\nenhanced annotations to train SLMs. Conversely,\nthe latter approach employs LLMs in inference us-\ning the ICL paradigm, which is the focus of our\nsubsequent discussion.\n2.2 Few-shot IE with ICL\nRegarding few-shot IE tasks, recent studies inten-\nsively compare the performance between SLMs\nand LLMs but yield inconsistent conclusions.\nSome studies favor LLMs as competent few-shot\nextractors (Agrawal et al., 2022; Wang et al.,\n2023b; Li et al., 2023; Zhang et al., 2023a;\nWadhwa et al., 2023), while others dispute this\nclaim (Jimenez Gutierrez et al., 2022; Qin et al.,\n2023; Wei et al., 2023; Gao et al., 2023). This\ndiscrepancy leaves the question of whether LLMs\nperform competitively on few-shot IE tasks unre-\nsolved, thus hindering the advances of this domain.\nWe attribute such disagreement to the absence\nof an comprehensive and unified benchmark. Ex-\nisting studies usually vary in tasks, datasets, and\nfew-shot settings. Furthermore, some studies rely\non overly simplistic datasets (Jimenez Gutierrez\net al., 2022; Li et al., 2023) and may exaggerate\nthe effectiveness of LLMs. Driven by these find-\nings, our research undertakes comprehensive ex-\nperiments across four IE tasks, nine datasets with\nvarious schema complexities (from coarse-grained\nto fine-grained) and low-resource settings.\nIn addition to the empirical study, we develop an\ninnovative filter-then-rerank paradigm to combine\nthe strengths of both LLMs and SLMs. It utilizes\nprompting strategies akin to QA4RE (Zhang et al.,\n2023a), transforming IE tasks into multi-choice\nquestions. However, our method stands apart by\nintegrating SLMs and LLMs within a single frame-\nwork. This incorporation (1) enables our paradigm\napplicable to various IE tasks by providing candi-\ndate spans in the text and (2) achieves promising\nperformance under low-resource IE scenarios.\n3 Large LMs v.s. Small LMs\nIn this section, we compare the performance be-\ntween LLMs and SLMs to evaluate whether LLMs\nperform competitively.\n3.1 Task, Dataset and Evaluation\nWe run experiments on nine widely-used datasets\nacross four IE tasks. (1) Named Entity Recognition\n(NER): CONLL03 (Tjong Kim Sang and De Meul-\nder, 2003), OntoNotes (Weischedel et al., 2013)\nand FewNERD (Ding et al., 2021). (2) Relation\nExtraction (RE): TACRED (Zhang et al., 2017)\nand TACREV (Alt et al., 2020). (3) Event De-\ntection (ED): ACE05 (Doddington et al., 2004),\nMA VEN (Wang et al., 2020) and ERE (Song et al.,\n10573\nT ext \nT ext \nT ext \nRelation ExtractionNamed Entity Recognition \nEvent Detection Event Argument Extraction\nFigure 1: Examples of prompts used. The green, blue and black parts in the top boxes represent the instruction,\ndemonstration (demo) and test sentence in the prompt respectively. The red parts represent the outputs from LLMs.\nWe plot only 1 example for convenience of visualization. The actual demo number is usually much larger than 1.\n2015). (4) Event Argument Extraction (EAE):\nACE05, ERE and RAMS (Ebner et al., 2020). With\nlabel numbers ranging from 4 to 168, we assess\nLLMs’ performance under different schema com-\nplexities. See their details in Appendix A.1.\nFew-shot SetWe construct few-shot datasets from\nthe original datasets above. For training and vali-\ndation set, we adopt K-shot sampling strategy, i.e.,\nsampling Ksamples for each label type. See more\ndetails in Appendix A.2. For test set, we down-\nsample their original test sets to reduce the cost\nof LLMs. We randomly sample 500 sentences for\nRE tasks, and 250 sentences for other task. We en-\nsure that each label has at least one corresponding\nsample to avoid the absence of rare labels.\nEvaluation We adopt micro-F1 score in NER, RE\nand ED tasks. For EAE task, we follow previous\nwork (Wang et al., 2023b) and adopt head-F1 score,\nwhich merely considers matching of the head word\nrather than the whole content of a text span. We re-\nport averaged score w.r.t 5 sampled train/validation\nsets unless otherwise stated.\n3.2 Small Language Models\nWe adopt five supervised methods to evaluate the\nabilities of SLMs. (1) Vanilla fine-tuning for all\ntasks, (2) FSLS (Ma et al., 2022a) for NER and ED\ntasks, (3) KnowPrompt (Chen et al., 2022b) for RE\ntask, (4) PAIE (Ma et al., 2022b) for EAE task, and\n(5) UIE (Lu et al., 2022c) for all tasks. See their\ndetails in Appendix B.\n3.3 Large Language Models\nDetailed in Appendix C, we evaluate the ICL abil-\nities of LLMs. Given labeled sentences D =\n{(si,yi)}and a test sentence s, our goal is to pre-\ndict structured information yfrom susing a frozen\nLLM L. We feed LLM with prompt PE,I,f (D,s):\nPE,I,f (D,s) = [I; f(E(D,s)); f(s)] (1)\nWe give examples of prompts on four IE tasks\nin Figure 1. The prompts consist of three parts: in-\nstruction I (color in green in Figure 1), demonstra-\ntion f(E(D,s)) (demo; color in blue) and the ques-\ntion f(x) (color in black). Here Edenotes demo\nselector and E(D,s) ⊂D denotes selected sen-\ntences as the demo to predict s. Prompt format f 5\nrefers to the template which converts demoE(D,s)\nand sample s to input context for LLMs. Then\nLLM generates f(y) (color in red) from which we\ncould readily parse the extraction results y.\nModels L: We explore six LLMs from two\nsources. (1) OpenAI models 6: we employ Chat-\n5We slightly abuse the notationfto allow s, yand {(s,y)}\nas the input for simplicity.\n6The versions of model we use are:gpt-3.5-turbo-0301,\n10574\nFine−tuning FSLS UIE ChatGPT CODEX InstructGPT LLaMA (13B) Vicuna (13B)\n0\n20\n40\n60\n80\n100\n1−shot 5−shot 10−shot 20−shot\nCONLL03\nF1 score\n0\n20\n40\n60\n80\n100\n1−shot 5−shot 10−shot 20−shot\nOntoNotes\nF1 score\n0\n20\n40\n60\n80\n100\n1−shot 5−shot 10−shot 20−shot\nFewNERD\nF1 score\n(a) Named Entity Recognition (NER)\nFine−tuning KnowPrompt UIE ChatGPT CODEX InstructGPT LLaMA (13B) Vicuna (13B)\n0\n20\n40\n60\n80\n1−shot 5−shot 10−shot 20−shot 50−shot 100−shot\nTACREV\nF1 score\n0\n20\n40\n60\n80\n1−shot 5−shot 10−shot 20−shot 50−shot 100−shot\nTACRED\nF1 score\n(b) Relation Extraction (RE)\nFine−tuning FSLS UIE ChatGPT CODEX InstructGPT LLaMA (13B) Vicuna (13B)\n0\n20\n40\n60\n80\n1−shot 5−shot 10−shot 20−shot\nACE05\nF1 score\n0\n20\n40\n60\n80\n1−shot 5−shot 10−shot 20−shot\nERE\nF1 score\n0\n20\n40\n60\n80\n1−shot 5−shot 10−shot 20−shot\nMAVEN\nF1 score\n(c) Event Detection (ED)\nFine−tuning PAIE UIE ChatGPT InstructGPT LLaMA (13B) Vicuna (13B)\n0\n20\n40\n60\n80\n1−shot 5−shot 10−shot 20−shot\nACE05\nF1 score\n0\n20\n40\n60\n80\n1−shot 5−shot 10−shot 20−shot\nERE\nF1 score\n0\n20\n40\n60\n80\n1−shot 5−shot 10−shot 20−shot\nRAMS\nF1 score\n(d) Event Argument Extraction (EAE)\nFigure 2: Overall results of SLM-based methods (dashed lines) and LLM-based methods (solid lines) on nine\ndatasets across four IE tasks. The black, horizontal dashed lines represent the SoTA performance on full dataset.\nGPT, CODEX (Chen et al., 2022a) and Instruct-\nGPT (Ouyang et al., 2022) for main experiments.\nWe also evaluate GPT-4 in Appendix D.3. (2)\nOpen-source models: we use LLaMA-13B (Tou-\nvron et al., 2023) and its instruction-tuned counter-\npart, Vicuna-13B (Chiang et al., 2023).\nInstruction I: The instruction (1) describes the\ntask and (2) enumerates all possible labels for ref-\nerence. we adopt instructions shown in Figure 1.\nDemo selectorE: The maximum input length of\ncode-davinci-002, text-davinci-003 and gpt-4-0314.\nDue to budget constraints, we execute InstructGPT and GPT-\n4 only once per setting. We do not conduct EAE task on\nCODEX since it had been unavailable at that time.\nLLMs usually limits the sentence number in de-\nmos even under few-shot settings. Therefore for\neach test sentence s, we demand a demo retriever\nE(D,s) which selects a small subset from D as\nthe sentences in demo. Following previous meth-\nods (Liu et al., 2022; Su et al., 2022), we retrieve\ndemos according to their sentence embedding simi-\nlarity to the test samples.\nPrompt format f: We use simple textual tem-\nplates to format the demos and the test sample in\nmain experiments. For example, the template for\nNER is “Sentence: [S], Entities: ([type1],\n[entity1]), ([type2], [entity2])...\".\n10575\n56.0\n57.0\n58.0\n59.0\n60.0\nI0 I1 I2 I3 I4 I5\nInstruction format\nF1 score\n36\n40\n44\n48\n52\n56\n60\n4 8 16 32 64 96\nDemonstration number\nF1 score ChatGPT\nCODEX 52.5\n55.0\n57.5\n60.0\nrandom embed epr\nDemonstration selection\nF1 score\nFigure 3: LLMs’ performance w.r.t prompt variants on 20-shot FewNERD dataset. See full results on other datasets\nin Appendix E.2- E.5. Left: ChatGPT’s performance (F1 Score) across six instruction variants. Middle: F1 Score\nchanges over varying numbers of demo. Right: ChatGPT’s performance across three demo selection strategies.\nRandom: Random sampling. Embed: Sentence embedding. EPR: Efficient Prompt Retriever (Rubin et al., 2022).\n3.4 Main Results\nWe summarize the main experimental outcomes in\nFigure 2, indicating that LLMs only outperform\nSLMs in environments with restricted labels and\nsamples. Conversely, SLMs are generally more\neffective. Given (1) the practicality of fine-grained\nIE tasks and the manageable effort of obtaining 10-\n20 annotations per label and (2) the excessive time\nand budget demands of LLM inference, we con-\nclude that LLMs are not as effective as supervised\nSLMs for few-shot IE tasks under real scenarios.\nWe detail our findings as below.\nPerformance w.r.t sample number.The perfor-\nmance dynamics of SLMs and LLMs are influenced\nby variations in sample size. Under extremely low-\nresource (1-shot or 5-shot) settings, LLMs some-\ntimes present superior performance than SLMs.\nYet, LLMs tend to reach a performance plateau\nwith only modest increases in sample size. Con-\nversely, SLMs demonstrate marked performance\nenhancement as sample sizes grow. This trend is\nevident in Figure 2, where the SLM trajectories\n(represented by dashed lines) ascend more steeply\ncompared to the LLM ones (solid lines).\nPerformance w.r.t label number.Compared with\nSLMs, LLMs tend to struggle on fine-grained\ndatasets. For instance, LLMs perform relatively\nworse on MA VEN and RAMS datasets (with\n168/139 labels) than on CONLL (4 labels only).\nDetailed quantitative results are shown in Ap-\npendix E.1, illustrating a clear negative correlation\nbetween the label number and the result disparity\nbetween LLMs and SLMs across various IE tasks.\nComparisons among LLMs.We observe perfor-\nmance variability among LLMs. (1) Open-source\nmodels, LLaMA and Vicuna, significantly lag be-\nhind proprietary LLMs across all few-shot IE tasks.\n(2) Among proprietary LLMs, ChatGPT performs\nbetter on NER and EAE tasks, but poorer so on RE\nand ED tasks. InstructGPT and CODEX demon-\nstrate comparable performance across these tasks.\nLLMs show limited inference speed.We compare\nthe inference speed of different methods and show\ntheir results in Table 1. We observe that LLMs\nis much slower than SLMs since they have much\nmore parameters, longer input contexts and extra\nresponse decay (if external APIs applied).\n3.5 Analysis on Prompt Sensitivity\nPrevious work (Lu et al., 2022b) indicates that the\nefficacy of LLMs on specific tasks can be signifi-\ncantly influenced by the construction of the prompt.\nTo ensure that LLMs’ suboptimal outcomes are\nnot erroneously ascribed to inappropriate prompt\ndesigns, we meticulously examine the impact of\ndiverse prompt variations from four aspects,i.e., in-\nstruction format, demo number, demo selector and\nprompt format. We leave comprehensive details\nof the variants and their results to Appendix E.2-\nE.5, and illustrate salient findings in Figure 3. Our\nfindings include that (1) diverse instruction strate-\ngies yield comparable results in IE task; (2) in-\ncreasing the number of samples in demonstrations\ndoes not unequivocally enhance performance; and\n(3) The selection strategy of demonstration mat-\nters, and retrieval based on sentence embedding\nTable 1: The inference seconds over 500 sentences (run\non single V100 GPU). Here LLaMA is extremely slow\nsince we set batch size as 1 due to memory limit.\nDataset (Task) Roberta T5 LLaMA CODEX\nFewNERD (NER) 2.8 39.4 1135.4 179.4\nTACREV (RE) 1.4 45.6 1144.9 151.6\nACE05 (ED) 6.6 62.5 733.4 171.7\n10576\n(what we used) proves sufficiently effective. Con-\nsequently, we believe that there unlikely exists a\nlottery prompt that substantially alters our conclu-\nsions that LLMs are not good few-shot IE solver.\n3.6 Discussion: Why LLMs Fail to Obtain\nSatisfactory Performance on IE Tasks?\nUnderutilized Annotations.We notice that LLMs\nappear to benefit less from additional annotations,\ni.e., more training samples and label types, than\nSLMs. We speculate that LLMs are constrained\nby ICL in two ways. (1) More samples: The num-\nber of effective samples for LLMs, those in de-\nmos, is limited by maximum input length. More-\nover, we also observe LLMs’ performance plateaus\nin some tasks before reaching this limit (see Ap-\npendix E.3). Meanwhile, SLMs can continually\nlearn from more samples through supervised learn-\ning, widening the performance gap as annotated\nsamples increase. (2) More labels: LLMs struggle\nwith fine-grained datasets. It suggests a difficulty\nin understanding numerous labels and their subtle\ninteractions merely from the given instruction and\nexemplars for LLMs. Also, the examples per label\nin demos decrease as label types increase.\nUnexplored Task format. As stated in Zhang\net al. (2023a), IE-related tasks are scarce in the\nwidely-used instruction tuning datasets like Wei\net al. (2022a) and Wang et al. (2022). Furthermore,\nthe highly-flexible format of NER and ED tasks\nimpair the ICL abilities 7. Therefore it is likely that\ninstruction-tuned LLMs are not well-acquainted\nwith such IE-related task formats.\n4 LLMs are Good Few-shot Reranker\n4.1 Filter-then-rerank Paradigm\nRead following sentences and identify what is the entity type\nof “The New Yorker” quoted by <t>.\nSentence:\nIn 2004 Gourevitch was assigned to cover the 2004 U.S.\npresidential election for “<t> The New Yorker <t>”.\nCandidate Choices:\n(a)The New Yorker does not belong to any known entities.\n(b)The New Yorker is a broadcast program.\n(c)The New Yorker is a kind of written art.\n(d)The New Yorker is a media/newspaper organization.\nAnalysis:\nThe New Yorker is a well-known American magazine that has\nbeen published since 1925, and is primarily known for its\nlong-form journalism, commentary, and satire. It has a\nreputation for publishing high-quality writing on a wide\nvariety of topics, including politics, culture, and the arts.\nSo The New Yorker is a media/newspaper organization.\nCorrect Answer: (d)\nFigure 4: Multi-choice question (MCQ) prompt.\n7These two tasks require unfixed numbers of (label, span)\ntuple. Furthermore, the length of each span is also unfixed.\nTo mitigate LLMs’ drawbacks mentioned above,\nwe propose a filter-then-rerank paradigm to inte-\ngrate both SLMs and LLMs within the same system.\nThis paradigm uses SLMs as filters to select the\ntop-N candidate labels, then LLMs rerank them\nto make final decisions. By using SLM-generated\ncandidate answers, the focus of LLMs shifts from\nsentence-level (i.e., identifying all entities/events\nin the sentence) to sample-level (i.e., determin-\ning single entity/event candidate provided). Each\nquestion now corresponds to a single sample, al-\nlowing us to reframe prompts as multi-choice ques-\ntions (MCQ; shown in Figure 4) problem. Un-\nder such format, each candidate label is converted\nto a choice by pre-defined templates. We claim\nfilter-then-rerank paradigm is more likely to elicit\nthe powers of LLMs and smoothly solve few-shot\nIE tasks because: (1) LLMs are more familiar\nwith MCQ prompts than IE-format prompts (Zhang\net al., 2023a). (2) This paradigm reduces the la-\nbel scopes significantly, since N is usually much\nsmaller than fine-grained label numbers.\n4.2 LLMs are Hard Sample Solver\nOur filter-then-rerank paradigm, unfortunately,\npresents unsatisfactory performance (and even suf-\nfers longer latency since LLMs rerank candidates\nper sample). Given LLMs’ abilities in memoriza-\ntion and reasoning, however, we still believe that\nLLMs are potential to solve some, if not most, IE\nsamples effectively. We hypothesize that LLMs\nare more proficient than SLMs on hard samples.\nThese samples are characterized by their requisite\nfor external knowledge acquisition or sophisticated\nreasoning strategies, areas where LLMs can lever-\nage their extensive parametric knowledge bases and\ninherent reasoning mechanisms. In contrast, SLMs\noften falter with such samples, constrained by their\nrestricted modeling capacities.\nWe leverage an unsupervised metric from SLMs\nto evaluate thedifficulty of samples. Given a sample\nxin the sentence s, we define the highest probabil-\nity across all labels as the confidence score:\nconf(x) = max\nl∈L\nPSLM (l|x; s) (2)\nwhere Ldenotes the label set andPSLM (l|x; s) the\nprobability of a span x(in the sentence s) referring\nto label l computed by SLMs. We classify sam-\nples with low confidence scores as hard samples.\nOtherwise we view them as easy samples.\n10577\nwo. LLM reranking          w. LLM reranking\n0\n25\n50\n75\n100\n0.15 0.25 0.35 0.45 0.55 0.65 0.75 0.85 0.95\nConfidence Score\nMicro−F1\nFewNERD (NER)\n0\n25\n50\n75\n100\n0.15 0.25 0.35 0.45 0.55 0.65 0.75 0.85 0.95\nConfidence Score\nMicro−F1\nTACREV (RE)\n0\n25\n50\n75\n100\n0.15 0.25 0.35 0.45 0.55 0.65 0.75 0.85 0.95\nConfidence Score\nMicro−F1\nACE05 (ED)\nFigure 5: Relationship between confidence scores and\nperformance with/without LLM reranking. We adopt\nRoBERTa-large as filter and InstructGPT as reranker.\nWe conduct experiments to confirm our hypoth-\nesis that LLMs excel on hard samples. We group\nsamples by confidence scores and compare two\nmethods within each group: (a) SLM-based meth-\nods without LLM reranking, and (b) SLMs as the\nfilter and LLMs as the reranker. Method (b) dif-\nfers from (a) by adding a single LLM to rerank the\ntop-N SLM predictions, using MCQ prompts.\nThe results in Figure 5 substantiate our assump-\ntion. (1) LLM-based reranking (blue lines) en-\nhances performance on hard samples (left areas in\nthe figure). We provide a detailed analysis of spe-\ncific challenging instances where LLM rerankers\nprove advantageous in Appendix F.1. These in-\nstances demonstrate the efficacy of LLMs in har-\nnessing external knowledge and complex reason-\ning to rectify erroneous predictions initially made\nby SLMs (red lines). (2) Conversely, LLM-based\nreranking impedes performance on easy samples\n(right areas), resulting in a significant degradation,\nparticularly for very easy samples (rightmost areas).\nIn conclusion, LLMs exhibit greater proficiency in\nhandling hard samples compared to SLMs, yet they\nunderperform relative to SLMs on easy samples.\n4.3 Why LLMs Fail on Easy Samples\nWe investigate why LLMs (relatively) fail on easy\nsamples in this section. As shown in Table 2, we\nobserve significant higher negative sample ratios\nfor easy samples across diverse IE tasks. In other\nTable 2: Comparative ratios of negative to positive sam-\nples across various datasets and subsets. We set fixed\nthreshold τ here for simplicity.\nFewNERD TACREV ACE05\nOverall 5.88 3.03 38.2\nEasy samples (τ >0.9) 9.44 3.21 44.0\nHard samples (τ <0.6) 1.28 2.68 1.36\nwords, most negative samples are easy samples for\nSLMs. Here we refer negative samples to those\nlabeled as None. We speculate that the proficiency\nof SLMs with negative samples stems from their\nability to adeptly discern apparent patterns during\nthe fine-tuning stages. Therefore, SLMs could pre-\ndict negative samples with (relatively) high confi-\ndence and accuracy. Due to LLMs’ predisposition\nto false-positive predictions on negative samples,\nhowever, the performance of LLMs on easy sam-\nples collapses. We attribute such false-positive pre-\ndictions to (1) hallucination and (2) span boundary\nmismatch. We detail such two kinds of mistakes\nwith cases in Appendix F.2.\n5 Adaptive Filter-then-rerank Paradigm\nAbove findings can be summarized as: (1) SLMs\ngenerally outperform LLMs, especially with more\ntraining samples and fine-grained labels. (2) SLMs\nare much more time- and cost-efficient. (3) LLMs\nserve as powerful rerankers on hard samples that\nchallenge SLMs. Based on them, we propose a\nsimple, efficient, and effective adaptive reranker\nthat combines the strengths of SLMs and LLMs.\n5.1 Method\nOur adaptive filter-then-rerank approach, shown\nin Figure 6, uses supervised SLMs as a filter to\nmake preliminary decisions. Samples with confi-\ndence scores exceeding threshold are viewed as\neasy samples otherwise hard ones. For easy sam-\nples, we retain SLM predictions as final results. For\nhard samples, top-N predictions from SLMs are\nreranked via LLMs using ICL. Here LLMs employ\nMCQ prompts (Figure 4), containing demos and a\nsample to be reranked. The LLMs then generate the\nfinal answer and optionally provide an explanation.\n5.2 Experimental Setup\nWe conduct experiments on FewNERD for NER\ntask, TACREV for RE task and ACE05 for ED\ntask. We employ top-performing SLM-based meth-\nods from Section 3 (FSLS or KnowPrompt) as the\n10578\nFilter\nThe sentence implies that Laura Silsby is associated with the city of Meridian in the state of Idaho, and\ndoes not provide information about her birthplace. So Laura Silsby lives in the city Meridian.\nAnswer: (b)\nDemonstration\nThe lawyer denied Italian news reports that she\nwept while addressing the court, but said Knox was\nupset as she recounted the pressure, the\naggressiveness of the police who called her a liar.\n(a)she is the other family member of lawyer\n(b)she is a lawyer\n(c)she has no known relations to lawyer\nAnalysis: The word 'she' refers to someone who was\nupset while recounting certain events in court. The\nword 'lawyer' refers to someone who denied a news\nreport about that same person weeping in court.\nThere is no information in the sentence to indicate\nthat the two individuals are related in any way.\nAnswer: (c)\nAdrien said he met the Baptists’ leader, Laura Silsby of\nMeridian, Idaho, in Port-au-Prince on Jan 26.\n(a)Laura Silsby lives in the state or province Meridian\n(b)Laura Silsby lives in the city Meridian\n(c)Laura Silsby was born in the city Meridian\n(d)Laura Silsby has no known relations to Meridian\nAnalysis:\nQuestionAdrien said he met the\nBaptists’ leader, Laura Silsby \nof Meridian, Idaho, in Port-au-\nPrince on Jan 26.\nThe last hostage, Italian\nengineer Eugenio Vagni,\nwas released early Sunday.\nper:origin per: cities_of_residence\nSmall LM\nLarge LM\nReranker\nEasy Sample Hard Sample\nFigure 6: The overall architecture of our adaptive filter-then-rerank paradigm. We color easy samples in orange and\nhard samples in pink. For easy samples, the final predictions are exactly from the SLM-based methods. For hard\nsamples, the top-N predictions from SLMs are fed into LLMs as the format of multiple-choice questions (pink box).\nThe question is paired with demos (green box). LLMs rerank these N candidates and generate the final prediction.\nfilter, and Vicuna-13B, InstructGPT or GPT-4 as\nthe reranker. The threshold τ to determine sam-\nple difficulty is optimized on the valid set. For\nhard sample, the top-3 SLM predictions and None\n(if not included) are feed to LLMs for reranking.\nEach LLM prompt has 4-shot demos. See demo\nexamples in Appendix G.1. We follow templates\nin Lu et al. (2022a) for TACREV and carefully de-\nsign others. See these templates in Appendix G.2.\nWe adopt chain-of-thought reasoning (Wei et al.,\n2022b), i.e., prefacing the answer with an explana-\ntion, to facilitate LLMs’ reranking procedure.\nBaseline We compare our method with two kinds\nof baselines to validate its effectiveness.\n(1) LLMs with ICL: We follow the prompts in Sec-\ntion 3.3 and conduct experiments on three LLMs.\n(2) Supervised SLMs: We follow previous SoTA\nmethods shown in Section 3.4 (FSLS or Know-\nPrompt). We additionally combine two SLMs with\nensemble or reranking approach (i.e., replace the\nLLM with another SLM as the reranker) to verify\nthat improvements from our SLM-LLM integrated\nsystem are not solely due to the ensemble effects.\n5.3 Main Results\nTable 3 shows that our filter-then-rerank method\nconsistently improves performance across three\ndatasets and nine settings. For instance, with In-\nstructGPT, reranking provides an average F1 gain\nof 2.4% without SLM ensemble (Lines 4 vs. 7).\nBased on ensemble SLMs as the filter, our method\nstill achieves 2.1% (Lines 5 vs. 8) gains on av-\nerage. This confirms (1) the effectiveness of the\nLLM reranking and (2) its gains are different and\n(almost) orthogonal to the SLM ensemble.\n5.4 Analysis\nFew makes big differenceOur method selectively\nreranks hard samples. Table 4 shows that (1) only a\nminor fraction (0.5%~10%) of samples are deemed\nhard and are reranked by LLMs. (2) Despite their\nlimited quantity, reranking results in a substantial\nperformance boost on these samples (10%~25%\nabsolute F1 gains). This uplift on a small subset\nsignificantly enhances the overall performance.\nGPT-4 is more aggressiveFrom Tables 3 and 4,\nGPT-4 generally improves more on hard samples,\nyet InstructGPT surpasses GPT-4 in NER and RE\ntasks when evaluated overall. This discrepancy\narises from GPT-4’s aggressive reranking which\nintroduces more true positives. InstructGPT, how-\never, focuses more on reducing false positives.\nFew makes small costFigure 7 demonstrates that\nour method impressively reduces budget and la-\ntency by approximately 80%~90% compared to\ndirect ICL. This reduction is due to (1) fewer LLM\ncallings (only for hard samples) and (2) shorter\nprompts (fewer candidate labels and demos).\n5.5 Ablation Study\nWe investigate the effectiveness of the modules\nin adaptive filter-then-rerank system by removing\neach of them in turn: (1) CoT: We exclude the\nexplantion for each examples in demo. (2) Demo:\n10579\nTable 3: Overall results of LLM-based ICL methods, SLM-based supervised methods, and our proposed filter-then-\nrerank (SLM+LLM) methods. The best results are in bold face and the second best are underlined. All results\nexcept InstructGPT and GPT-4 are averaged over 5 runs, and sample standard deviations are in the round bracket.\nFewNERD (NER) TACREV (RE) ACE (ED)\n5-shot 10-shot 20-shot 20-shot 50-shot 100-shot 5-shot 10-shot 20-shot\nLLM\nCODEX 53.8(0.5) 54.0(1.4) 55.9(0.5) 59.1(1.4) 60.3(2.4) 62.4(2.6) 47.1(1.2) 47.7(2.8) 47.9(0.5)\nInstructGPT 53.6(−) 54.6(−) 57.2(−) 60.1(−) 58.3(−) 62.7(−) 52.9(−) 52.1(−) 49.3(−)\nGPT-4 - - 57.8(−) - - 59.3(−) - - 52.1(−)\nSLM\nPrevious SoTA 59.4(1.5) 61.4(0.8) 61.9(1.2) 62.4(3.8) 68.5(1.6) 72.6(1.5) 55.1(4.6) 63.9(0.8) 65.8(2.0)\n+ Ensemble (S) 59.6(1.7) 61.8(1.2) 62.6(1.0) 64.9(1.5) 71.9(2.2) 74.1(1.7) 56.9(4.7) 64.2(2.1) 66.5(1.7)\n+ Rerank (S) 59.4(1.5) 61.0(1.7) 61.5(1.7) 64.2(2.3) 70.8(2.3) 74.3(2.2) 56.1(0.3) 64.0(1.0) 66.7(1.7)\nSLM + LLM\nVicuna-13B\n+ Rerank (L) 60.0(1.8) 61.9(2.1) 62.2(1.4) 65.2(1.4) 70.8(1.6) 73.8(1.7) 56.9(4.0) 63.5(2.7) 66.0(2.6)\n+ Ensemble (S) + Rerank (L) 59.9(0.7) 62.1(0.7) 62.8(1.1) 66.5(0.5) 73.6(1.4) 75.0(1.5) 57.9(5.2) 64.4(1.2) 66.2(2.4)\nInstructGPT\n+ Rerank (L) 60.6(2.1) 62.7(0.8) 63.3(0.6) 66.8(2.6) 72.3(1.4) 75.4(1.5) 57.8(4.6) 65.3(1.7) 67.3(2.2)\n+ Ensemble (S) + Rerank (L) 61.3(1.9) 63.2(0.9) 63.7(1.8) 68.9(1.3) 74.8(1.3) 76.8(1.2) 59.5(3.7) 65.3(1.9) 67.8(2.1)\nGPT-4\n+ Rerank (L) 60.8(2.3) 62.6 (2.7) 63.0(1.3) 65.9(2.7) 72.3(0.3) 74.5(1.5) 59.6(2.9) 64.9(2.5) 67.1(2.5)\n+ Ensemble (S) + Rerank (L) 61.1(2.2) 62.8(0.9) 63.6(1.2) 68.6(1.3) 73.9(1.4) 75.9(2.4) 60.9(3.9) 65.6(1.5) 67.8(1.7)\nTable 4: The F1-score differences before and after\nreranking on the reranked samples, as well as their pro-\nportion of the total samples.\nGPT-4 InstructGPT\nbefore after △ ratio before after △ ratio\nFewNER 31.9 40 .7 8 .8 3 .2% 31.4 28 .3 −3.1 3.3%\nTACREV 25.3 43 .0 17.7 9.1% 33.8 43 .4 9 .6 7 .1%\nACE05 31.1 57 .9 26.8 1.6% 35.6 55 .7 20 .1 0 .5%\nWe remove all examples, rendering the reranking\na zero-shot problem. (3) LF (label filtering): We\nretain all labels as candidate choices for reranking,\ninstead of only the top- N labels from the SLMs.\n(4) AD (adaptive): We feed all samples, not just\nhard ones, to the LLMs.\nWe show their results in Table 5 and see that\n(1) Demos with explanations consistently enhance\nthe reranking ability of LLMs across all datasets.\n(2) Demos without explanations also contribute to\nperformance improvement. (3) Label filtering re-\nsults in gains and notably reduces the demo length,\nDirect ICL (InstructGPT) Filter−then−rerank Fine−tuning (RoBERTa−large)\n0\n10\n20\n30\n40\nFewNERD TACREV ACE05\nFinancial cost\ndollar($)\n0\n50\n100\n150\nFewNERD TACREV ACE05\nTime cost\nsecond(s)\nFigure 7: The financial and time cost over 500 sentences.\nInstructGPT as the reranker.\nTable 5: Ablation study on three datasets. The filter is\nensembled SLMs and the reranker is GPT-4.\nCoT Demo LF AD\nFewNERD\n(20-shot)\nTACREV\n(100-shot)\nACE05\n(20-shot)\n✓ ✓ ✓ ✓ 63.6(1.2) 75.9(2.4) 67.8(1.7)\n✗ ✓ ✓ ✓ 63.2(1.2) 75.4(2.4) 67.2(1.7)\n✗ ✗ ✓ ✓ 63.0(1.4) 74.9(2.2) 66.6(1.5)\n✗ ✗ ✗ ✓ 62.4(2.1) 73.8(2.5) 66.5(1.3)\n✗ ✗ ✗ ✗ 12.5(2.7) 59.9(6.0) 5.4(1.1)\nPrevious SoTA methods 62.6(1.0) 74.1(1.7) 66.5(1.7)\nhence cutting inference costs. (4) The performance\ncollapses without a filter to identify sample diffi-\nculty, reiterating the need for an integrated SLM-\nLLM system to complement each other.\n6 Conclusion\nThrough an extensive empirical study on nine\ndatasets spanning four IE tasks, we find that LLMs,\ndespite their superiority in extreme low-resource\nscenarios, are not effective few-shot information\nextractors in general. They struggle with IE-related\nprompts, have limited demonstration capacity, and\nincur high inference costs. However, LLMs signifi-\ncantly improve the performance on hard samples\nwhen combined with SLM. Building on these in-\nsights, we propose an adaptive filter-then-rerank\nparadigm to leverage the strengths of SLMs and\nLLMs and mitigate their limitations. This approach\nconsistently achieves promising results, with an av-\nerage 2.4% F1 gain across multiple few-shot IE\ntasks, while minimizing latency and budget costs.\n10580\nLimitations\nWe do work hard to find better prompts to elicit the\npower of LLMs on few-shot IE tasks in Section 3.5,\nby exploring various kinds of LLMs, demonstra-\ntion strategies and prompt formats. We find that dif-\nferent prompt variants do not significantly impact\nin-context learning abilities. As an empirical study,\nwe acknowledge the potential existence of a lottery\nprompt superior to our explored prompts. However,\nit seems unlikely that an improved prompt would\nsubstantially alter our conclusions.\nAnother common risk when evaluating LLMs\non public benchmark is their potential memoriza-\ntion of samples tested. To mitigate such poten-\ntial contamination, we use earlier and stable ver-\nsions of these models rather than the newer and\nupdated ones (for example, gpt-4-0314instead of\ngpt-4). Even if such contamination makes abilities\nof LLMs overestimated, our primary conclusions\nremain unchanged because we find that LLMs are\nNOT good few-shot information extractors.\nRegarding our adaptive filter-then-rerank\nparadigm, a key limitation lies in how to assess\nsample difficulty. In this work, we employ a\nsimple unsupervised metric, i.e., the maximum\nprobabilities from SLMs. This is predicated on the\nassumption that SLMs are well-calibrated (Guo\net al., 2017). However, it is an obviously imperfect\nassumption. We envision that calibrating SLMs-\nbased filters or developing an advanced difficulty\nmetric could substantially enhance LLM rerankers’\nperformance. We leave them for future work.\nAcknowlegement\nThis study is supported under the RIE2020 In-\ndustry Alignment Fund – Industry Collaboration\nProjects (IAF-ICP) Funding Initiative, the Singa-\npore Ministry of Education (MOE) Academic Re-\nsearch Fund (AcRF) Tier 1 grant, as well as cash\nand in-kind contribution from the industry part-\nner(s).\nReferences\nMonica Agrawal, Stefan Hegselmann, Hunter Lang,\nYoon Kim, and David Sontag. 2022. Large language\nmodels are few-shot clinical information extractors.\nIn Proceedings of the 2022 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n1998–2022, Abu Dhabi, United Arab Emirates. Asso-\nciation for Computational Linguistics.\nChristoph Alt, Aleksandra Gabryszak, and Leonhard\nHennig. 2020. TACRED revisited: A thorough eval-\nuation of the TACRED relation extraction task. In\nProceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 1558–\n1569, Online. Association for Computational Linguis-\ntics.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language models are few-shot learners. In Ad-\nvances in Neural Information Processing Systems 33:\nAnnual Conference on Neural Information Process-\ning Systems 2020, NeurIPS 2020, December 6-12,\n2020, virtual.\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan,\nHenrique Pondé de Oliveira Pinto, Jared Kaplan,\nHarrison Edwards, Yuri Burda, Nicholas Joseph,\nGreg Brockman, Alex Ray, Raul Puri, Gretchen\nKrueger, Michael Petrov, Heidy Khlaaf, Girish Sas-\ntry, Pamela Mishkin, Brooke Chan, Scott Gray,\nNick Ryder, Mikhail Pavlov, Alethea Power, Lukasz\nKaiser, Mohammad Bavarian, Clemens Winter,\nPhilippe Tillet, Felipe Petroski Such, Dave Cum-\nmings, Matthias Plappert, Fotios Chantzis, Eliza-\nbeth Barnes, Ariel Herbert-V oss, William Hebgen\nGuss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie\nTang, Igor Babuschkin, Suchir Balaji, Shantanu Jain,\nWilliam Saunders, Christopher Hesse, Andrew N.\nCarr, Jan Leike, Joshua Achiam, Vedant Misra, Evan\nMorikawa, Alec Radford, Matthew Knight, Miles\nBrundage, Mira Murati, Katie Mayer, Peter Welinder,\nBob McGrew, Dario Amodei, Sam McCandlish, Ilya\nSutskever, and Wojciech Zaremba. 2021. Evaluat-\ning large language models trained on code. ArXiv\npreprint, abs/2107.03374.\nTing Chen, Simon Kornblith, Mohammad Norouzi, and\nGeoffrey E. Hinton. 2020. A simple framework for\ncontrastive learning of visual representations. In Pro-\nceedings of the 37th International Conference on\nMachine Learning, ICML 2020, 13-18 July 2020, Vir-\ntual Event, volume 119 of Proceedings of Machine\nLearning Research, pages 1597–1607. PMLR.\nWenhu Chen, Xueguang Ma, Xinyi Wang, and\nWilliam W. Cohen. 2022a. Program of thoughts\nprompting: Disentangling computation from reason-\ning for numerical reasoning tasks.\nXiang Chen, Ningyu Zhang, Xin Xie, Shumin Deng,\nYunzhi Yao, Chuanqi Tan, Fei Huang, Luo Si, and\nHuajun Chen. 2022b. Knowprompt: Knowledge-\naware prompt-tuning with synergistic optimization\nfor relation extraction. In WWW ’22: The ACM Web\n10581\nConference 2022, Virtual Event, Lyon, France, April\n25 - 29, 2022, pages 2778–2788. ACM.\nWei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng,\nZhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan\nZhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion\nStoica, and Eric P. Xing. 2023. Vicuna: An open-\nsource chatbot impressing gpt-4 with 90%* chatgpt\nquality.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, Parker Schuh, Kensen Shi,\nSasha Tsvyashchenko, Joshua Maynez, Abhishek\nRao, Parker Barnes, Yi Tay, Noam Shazeer, Vin-\nodkumar Prabhakaran, Emily Reif, Nan Du, Ben\nHutchinson, Reiner Pope, James Bradbury, Jacob\nAustin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,\nToju Duke, Anselm Levskaya, Sanjay Ghemawat,\nSunipa Dev, Henryk Michalewski, Xavier Garcia,\nVedant Misra, Kevin Robinson, Liam Fedus, Denny\nZhou, Daphne Ippolito, David Luan, Hyeontaek Lim,\nBarret Zoph, Alexander Spiridonov, Ryan Sepassi,\nDavid Dohan, Shivani Agrawal, Mark Omernick, An-\ndrew M. Dai, Thanumalayan Sankaranarayana Pil-\nlai, Marie Pellat, Aitor Lewkowycz, Erica Moreira,\nRewon Child, Oleksandr Polozov, Katherine Lee,\nZongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark\nDiaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy\nMeier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov,\nand Noah Fiedel. 2022. Palm: Scaling language mod-\neling with pathways.\nHyung Won Chung, Le Hou, Shayne Longpre, Barret\nZoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi\nWang, Mostafa Dehghani, Siddhartha Brahma, Al-\nbert Webson, Shixiang Shane Gu, Zhuyun Dai,\nMirac Suzgun, Xinyun Chen, Aakanksha Chowdh-\nery, Alex Castro-Ros, Marie Pellat, Kevin Robinson,\nDasha Valter, Sharan Narang, Gaurav Mishra, Adams\nYu, Vincent Zhao, Yanping Huang, Andrew Dai,\nHongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Ja-\ncob Devlin, Adam Roberts, Denny Zhou, Quoc V . Le,\nand Jason Wei. 2022. Scaling instruction-finetuned\nlanguage models.\nBosheng Ding, Chengwei Qin, Linlin Liu, Yew Ken\nChia, Boyang Li, Shafiq Joty, and Lidong Bing. 2023.\nIs GPT-3 a good data annotator? In Proceedings\nof the 61st Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 11173–11195, Toronto, Canada. Association\nfor Computational Linguistics.\nNing Ding, Guangwei Xu, Yulin Chen, Xiaobin Wang,\nXu Han, Pengjun Xie, Haitao Zheng, and Zhiyuan\nLiu. 2021. Few-NERD: A few-shot named entity\nrecognition dataset. In Proceedings of the 59th An-\nnual Meeting of the Association for Computational\nLinguistics and the 11th International Joint Confer-\nence on Natural Language Processing (Volume 1:\nLong Papers), pages 3198–3213, Online. Association\nfor Computational Linguistics.\nGeorge Doddington, Alexis Mitchell, Mark Przybocki,\nLance Ramshaw, Stephanie Strassel, and Ralph\nWeischedel. 2004. The automatic content extrac-\ntion (ACE) program – tasks, data, and evaluation. In\nProceedings of the Fourth International Conference\non Language Resources and Evaluation (LREC’04),\nLisbon, Portugal. European Language Resources As-\nsociation (ELRA).\nSeth Ebner, Patrick Xia, Ryan Culkin, Kyle Rawlins,\nand Benjamin Van Durme. 2020. Multi-sentence ar-\ngument linking. In Proceedings of the 58th Annual\nMeeting of the Association for Computational Lin-\nguistics, pages 8057–8077, Online. Association for\nComputational Linguistics.\nJun Gao, Huan Zhao, Changlong Yu, and Ruifeng Xu.\n2023. Exploring the feasibility of chatgpt for event\nextraction.\nTianyu Gao, Xingcheng Yao, and Danqi Chen. 2021.\nSimCSE: Simple contrastive learning of sentence em-\nbeddings. In Proceedings of the 2021 Conference\non Empirical Methods in Natural Language Process-\ning, pages 6894–6910, Online and Punta Cana, Do-\nminican Republic. Association for Computational\nLinguistics.\nChuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Wein-\nberger. 2017. On calibration of modern neural net-\nworks. In Proceedings of the 34th International Con-\nference on Machine Learning, ICML 2017, Sydney,\nNSW, Australia, 6-11 August 2017 , volume 70 of\nProceedings of Machine Learning Research, pages\n1321–1330. PMLR.\nBernal Jimenez Gutierrez, Nikolas McNeal, Clayton\nWashington, You Chen, Lang Li, Huan Sun, and\nYu Su. 2022. Thinking about GPT-3 in-context learn-\ning for biomedical IE? think again. In Findings of the\nAssociation for Computational Linguistics: EMNLP\n2022, pages 4497–4512, Abu Dhabi, United Arab\nEmirates. Association for Computational Linguistics.\nMartin Josifoski, Marija Sakota, Maxime Peyrard, and\nRobert West. 2023. Exploiting asymmetry for syn-\nthetic training data generation: Synthie and the case\nof information extraction.\nJaehun Jung, Lianhui Qin, Sean Welleck, Faeze Brah-\nman, Chandra Bhagavatula, Ronan Le Bras, and\nYejin Choi. 2022. Maieutic prompting: Logically\nconsistent reasoning with recursive explanations. In\nProceedings of the 2022 Conference on Empirical\nMethods in Natural Language Processing , pages\n1266–1279, Abu Dhabi, United Arab Emirates. Asso-\nciation for Computational Linguistics.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVeselin Stoyanov, and Luke Zettlemoyer. 2020.\nBART: Denoising sequence-to-sequence pre-training\nfor natural language generation, translation, and com-\nprehension. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\n10582\npages 7871–7880, Online. Association for Computa-\ntional Linguistics.\nPeng Li, Tianxiang Sun, Qiong Tang, Hang Yan, Yuan-\nbin Wu, Xuanjing Huang, and Xipeng Qiu. 2023.\nCodeIE: Large code generation models are better\nfew-shot information extractors. In Proceedings\nof the 61st Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 15339–15353, Toronto, Canada. Association\nfor Computational Linguistics.\nJiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan,\nLawrence Carin, and Weizhu Chen. 2022. What\nmakes good in-context examples for GPT-3? In\nProceedings of Deep Learning Inside Out (DeeLIO\n2022): The 3rd Workshop on Knowledge Extrac-\ntion and Integration for Deep Learning Architectures,\npages 100–114, Dublin, Ireland and Online. Associa-\ntion for Computational Linguistics.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach.\nIlya Loshchilov and Frank Hutter. 2019. Decoupled\nweight decay regularization. In 7th International\nConference on Learning Representations, ICLR 2019,\nNew Orleans, LA, USA, May 6-9, 2019 . OpenRe-\nview.net.\nKeming Lu, I-Hung Hsu, Wenxuan Zhou,\nMingyu Derek Ma, and Muhao Chen. 2022a.\nSummarization as indirect supervision for relation\nextraction. In Findings of the Association for\nComputational Linguistics: EMNLP 2022 , pages\n6575–6594, Abu Dhabi, United Arab Emirates.\nAssociation for Computational Linguistics.\nKeming Lu, Xiaoman Pan, Kaiqiang Song, Hongming\nZhang, Dong Yu, and Jianshu Chen. 2023. Pivoine:\nInstruction tuning for open-world information extrac-\ntion. ArXiv preprint, abs/2305.14898.\nYao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel,\nand Pontus Stenetorp. 2022b. Fantastically ordered\nprompts and where to find them: Overcoming few-\nshot prompt order sensitivity. In Proceedings of the\n60th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), pages\n8086–8098, Dublin, Ireland. Association for Compu-\ntational Linguistics.\nYaojie Lu, Qing Liu, Dai Dai, Xinyan Xiao, Hongyu\nLin, Xianpei Han, Le Sun, and Hua Wu. 2022c. Uni-\nfied structure generation for universal information\nextraction. In Proceedings of the 60th Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 1: Long Papers), pages 5755–5772, Dublin,\nIreland. Association for Computational Linguistics.\nJie Ma, Miguel Ballesteros, Srikanth Doss, Rishita\nAnubhai, Sunil Mallya, Yaser Al-Onaizan, and Dan\nRoth. 2022a. Label semantics for few shot named\nentity recognition. In Findings of the Association for\nComputational Linguistics: ACL 2022, pages 1956–\n1971, Dublin, Ireland. Association for Computational\nLinguistics.\nYubo Ma, Zehao Wang, Yixin Cao, Mukai Li, Meiqi\nChen, Kun Wang, and Jing Shao. 2022b. Prompt\nfor extraction? PAIE: Prompting argument interac-\ntion for event argument extraction. In Proceedings\nof the 60th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 6759–6774, Dublin, Ireland. Association for\nComputational Linguistics.\nYubo Ma, Zehao Wang, Yixin Cao, and Aixin Sun. 2023.\nFew-shot event detection: An empirical study and a\nunified view. In Proceedings of the 61st Annual Meet-\ning of the Association for Computational Linguis-\ntics (Volume 1: Long Papers), pages 11211–11236,\nToronto, Canada. Association for Computational Lin-\nguistics.\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-\nroll L. Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, John\nSchulman, Jacob Hilton, Fraser Kelton, Luke Miller,\nMaddie Simens, Amanda Askell, Peter Welinder,\nPaul Christiano, Jan Leike, and Ryan Lowe. 2022.\nTraining language models to follow instructions with\nhuman feedback.\nLiangming Pan, Alon Albalak, Xinyi Wang, and\nWilliam Yang Wang. 2023. Logic-lm: Empower-\ning large language models with symbolic solvers for\nfaithful logical reasoning.\nCheng Qian, Chi Han, Yi R. Fung, Yujia Qin, Zhiyuan\nLiu, and Heng Ji. 2023. Creator: Tool creation for\ndisentangling abstract and concrete reasoning of large\nlanguage models.\nChengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao\nChen, Michihiro Yasunaga, and Diyi Yang. 2023. Is\nchatgpt a general-purpose natural language process-\ning task solver?\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. 2020. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer. J. Mach. Learn. Res., 21:140:1–140:67.\nOhad Rubin, Jonathan Herzig, and Jonathan Berant.\n2022. Learning to retrieve prompts for in-context\nlearning. In Proceedings of the 2022 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, pages 2655–2671, Seattle, United States.\nAssociation for Computational Linguistics.\nZhiyi Song, Ann Bies, Stephanie Strassel, Tom Riese,\nJustin Mott, Joe Ellis, Jonathan Wright, Seth Kulick,\nNeville Ryant, and Xiaoyi Ma. 2015. From light\nto rich ERE: Annotation of entities, relations, and\n10583\nevents. In Proceedings of the The 3rd Workshop on\nEVENTS: Definition, Detection, Coreference, and\nRepresentation, pages 89–98, Denver, Colorado. As-\nsociation for Computational Linguistics.\nHongjin Su, Jungo Kasai, Chen Henry Wu, Weijia Shi,\nTianlu Wang, Jiayi Xin, Rui Zhang, Mari Ostendorf,\nLuke Zettlemoyer, Noah A. Smith, and Tao Yu. 2022.\nSelective annotation makes language models better\nfew-shot learners.\nZhiqing Sun, Xuezhi Wang, Yi Tay, Yiming Yang, and\nDenny Zhou. 2023. Recitation-augmented language\nmodels. In International Conference on Learning\nRepresentations.\nErik F. Tjong Kim Sang and Fien De Meulder.\n2003. Introduction to the CoNLL-2003 shared task:\nLanguage-independent named entity recognition. In\nProceedings of the Seventh Conference on Natural\nLanguage Learning at HLT-NAACL 2003, pages 142–\n147.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal\nAzhar, Aurelien Rodriguez, Armand Joulin, Edouard\nGrave, and Guillaume Lample. 2023. Llama: Open\nand efficient foundation language models.\nSomin Wadhwa, Silvio Amir, and Byron Wallace. 2023.\nRevisiting relation extraction in the era of large lan-\nguage models. In Proceedings of the 61st Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers) , pages 15566–\n15589, Toronto, Canada. Association for Computa-\ntional Linguistics.\nXiao Wang, Wei Zhou, Can Zu, Han Xia, Tianze Chen,\nYuan Zhang, Rui Zheng, Junjie Ye, Qi Zhang, Tao\nGui, Jihua Kang, J. Yang, Siyuan Li, and Chunsai\nDu. 2023a. Instructuie: Multi-task instruction tuning\nfor unified information extraction. ArXiv preprint,\nabs/2304.08085.\nXiaozhi Wang, Ziqi Wang, Xu Han, Wangyi Jiang, Rong\nHan, Zhiyuan Liu, Juanzi Li, Peng Li, Yankai Lin,\nand Jie Zhou. 2020. MA VEN: A Massive General\nDomain Event Detection Dataset. In Proceedings\nof the 2020 Conference on Empirical Methods in\nNatural Language Processing (EMNLP), pages 1652–\n1671, Online. Association for Computational Linguis-\ntics.\nXingyao Wang, Sha Li, and Heng Ji. 2023b.\nCode4Struct: Code generation for few-shot event\nstructure prediction. In Proceedings of the 61st An-\nnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 3640–\n3663, Toronto, Canada. Association for Computa-\ntional Linguistics.\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc\nLe, Ed Chi, Sharan Narang, Aakanksha Chowdhery,\nand Denny Zhou. 2023c. Self-consistency improves\nchain of thought reasoning in language models. In\nThe Eleventh International Conference on Learning\nRepresentations (ICLR 2023).\nYizhong Wang, Swaroop Mishra, Pegah Alipoormo-\nlabashi, Yeganeh Kordi, Amirreza Mirzaei, Atharva\nNaik, Arjun Ashok, Arut Selvan Dhanasekaran,\nAnjana Arunkumar, David Stap, Eshaan Pathak,\nGiannis Karamanolakis, Haizhi Lai, Ishan Puro-\nhit, Ishani Mondal, Jacob Anderson, Kirby Kuznia,\nKrima Doshi, Kuntal Kumar Pal, Maitreya Patel,\nMehrad Moradshahi, Mihir Parmar, Mirali Purohit,\nNeeraj Varshney, Phani Rohitha Kaza, Pulkit Verma,\nRavsehaj Singh Puri, Rushang Karia, Savan Doshi,\nShailaja Keyur Sampat, Siddhartha Mishra, Sujan\nReddy A, Sumanta Patro, Tanay Dixit, and Xudong\nShen. 2022. Super-NaturalInstructions: Generaliza-\ntion via declarative instructions on 1600+ NLP tasks.\nIn Proceedings of the 2022 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n5085–5109, Abu Dhabi, United Arab Emirates. As-\nsociation for Computational Linguistics.\nJason Wei, Maarten Bosma, Vincent Y . Zhao, Kelvin\nGuu, Adams Wei Yu, Brian Lester, Nan Du, An-\ndrew M. Dai, and Quoc V . Le. 2022a. Finetuned\nlanguage models are zero-shot learners. In The Tenth\nInternational Conference on Learning Representa-\ntions, ICLR 2022, Virtual Event, April 25-29, 2022.\nOpenReview.net.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Ed Huai hsin Chi, Quoc Le, and Denny Zhou.\n2022b. Chain of thought prompting elicits reasoning\nin large language models. Proceedings of the 36th\nInternational Conference on Neural Information Pro-\ncessing Systems.\nXiang Wei, Xingyu Cui, Ning Cheng, Xiaobin Wang,\nXin Zhang, Shen Huang, Pengjun Xie, Jinan Xu,\nYufeng Chen, Meishan Zhang, Yong Jiang, and Wen-\njuan Han. 2023. Zero-shot information extraction via\nchatting with chatgpt.\nRalph Weischedel, Martha Palmer, Mitchell Marcus, Ed-\nuard Hovy, Sameer Pradhan, Lance Ramshaw, Nian-\nwen Xue, Ann Taylor, Jeff Kaufman, Michelle Fran-\nchini, et al. 2013. Ontonotes release 5.0 ldc2013t19.\nLinguistic Data Consortium, Philadelphia, PA.\nYi Yang and Arzoo Katiyar. 2020. Simple and effective\nfew-shot named entity recognition with structured\nnearest neighbor learning. In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP), pages 6365–6375,\nOnline. Association for Computational Linguistics.\nWenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu,\nMingxuan Ju, Soumya Sanyal, Chenguang Zhu,\nMichael Zeng, and Meng Jiang. 2023. Generate\nrather than retrieve: Large language models are\nstrong context generators. In International Confer-\nence for Learning Representation (ICLR 2023).\nKai Zhang, Bernal Jimenez Gutierrez, and Yu Su. 2023a.\nAligning instruction tasks unlocks large language\n10584\nmodels as zero-shot relation extractors. In Find-\nings of the Association for Computational Linguis-\ntics: ACL 2023 , pages 794–812, Toronto, Canada.\nAssociation for Computational Linguistics.\nYuhao Zhang, Victor Zhong, Danqi Chen, Gabor Angeli,\nand Christopher D. Manning. 2017. Position-aware\nattention and supervised data improve slot filling.\nIn Proceedings of the 2017 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n35–45, Copenhagen, Denmark. Association for Com-\nputational Linguistics.\nZhuosheng Zhang, Aston Zhang, Mu Li, and Alex\nSmola. 2023b. Automatic chain of thought prompt-\ning in large language models. In The Eleventh In-\nternational Conference on Learning Representations\n(ICLR 2023).\nA Datasets\nA.1 Full Datasets\nWe construct few-shot IE datasets and conduct\nthe empirical study on nine datasets spanning four\ntasks, with varying schema complexities ranging\nfrom 4 to 168. We show their statistics in Table 6.\nA.2 Details of Few-shot IE Datasets\nSampling Algorithm for Train/Valid Datasets.\nWe downsample sentences from original training\ndataset to construct few-shot training and valid\ndatasets. We adopt K-shot sampling strategy that\neach label has (at least) K samples. We set 6 K-\nvalues (1, 5, 10, 20, 50, 100) for RE tasks and 4\nK-values (1, 5, 10, 20) for other tasks. For RE\ntask, each sentence has exactly one relation and we\nsimply select Ksentences for each label. For NER,\nED and EAE tasks, each sentences is possible to\ncontain more than one entities/events/arguments.\nSince our sampling is at sentence-level, the algo-\nrithm of accurate sampling , i.e., finding exactly\nK samples for each label, is NP-complete 8 and\nunlikely to find a practical solution. Therefore we\nfollow Yang and Katiyar (2020) adopting a greedy\nsampling algorithm to select sentences for NER and\nED tasks, as shown in Algorithm 1. Note that the\nactual sample number of each label can be larger\nthan Kunder this sampling strategy. For all three\ntasks, we additionally sample negative sentences\n(without any defined labels) and make the ratio of\npositive sentences (with at least one label) and neg-\native sentences as 1:1. The statistics of the curated\ndatasets are listed in Table 7.\n8The Subset Sum Problem, a classical NP-complete prob-\nlem, can be reduced to this sampling problem.\nAlgorithm 1Greedy Sampling\nRequire: shot number K, original full dataset\nD= {(X,Y)}tagged with label set E\n1: Sort E based on their frequencies in {Y}as\nan ascending order\n2: S ←ϕ, Counter ←dict()\n3: for y∈Edo\n4: Counter(y) ←0\n5: end for\n6: for y∈Edo\n7: while Counter(y) <K do\n8: Sample (X,Y) ∈D s.t.∃j,yj = y\n9: D←D\\ (X,Y)\n10: Update Counter (not only y but all\nevent types in Y)\n11: end while\n12: end for\n13: for s∈S do\n14: S←S\\ sand update Counter\n15: if ∃y∈E, s.t. Counter(y) <K then\n16: S←S ⋃s\n17: end if\n18: end for\n19: return S\nBased on the subsets constructed above, we op-\ntionally further split them into training and valid\nsets. For few-shot datasets with more than 300 sen-\ntences, we additionally split 10% sentences as the\nvalid set and the remaining sentences as training set.\nOtherwise, we do not construct valid set and con-\nduct 5-fold cross validation to avoid overfitting.\nB Details on SLMs\nWe adopt five representative supervised methods to\nevaluate the ability of SLMs on few-shot IE tasks.\n(1). Fine-tuning (FT): Add a classifier head on\nSLMs to predict the labels of each sentence/word.\n(2). FSLS(Ma et al., 2022a): The state-of-the-art\nextractive-based method for few-shot NER task.\nMa et al. (2023) also validate its competitive per-\nformance on few-shot ED tasks.\n(3). KnowPrompt(Chen et al., 2022b): The best\nextractive-based method for few-shot RE task.\n(4). PAIE(Ma et al., 2022b): The best extractive-\nbased method for few-shot EAE task.\n(5). UIE(Lu et al., 2022c): A competitive unified\ngeneration-based method for few-shot IE tasks. We\nintroduce their implementation details below:\nFine-tuning/FSLS. We implement these two meth-\n10585\nTable 6: Statistics of nine datasets used. Note that the #mentions for event detection tasks refers to the number of\ntrigger words, while the #mentions for event argument extraction tasks refers to the number of arguments.\nNamed Entity Recognition Relation Extraction Event Detection Event Arg Extraction\nDataset CONLL OntoNotes FewNERDTACREV TACREDACE05 MA VEN EREACE05 RAMS ERE\n#Label Type 4 18 66 41 41 33 168 38 33 139 38\n#Sents Train 14,041 49,706 131,965 68,124 68,124 14,024 32,360 14,736 14,024 7329 14,736\nTest 3,453 10,348 37,648 15,509 15,509 728 8,035 1,163 728 871 1,163\n#Mentions Train 23,499 128,738 340,247 13,012 13,012 5,349 77,993 6,208 4859 17026 8924\nTest 5,648 12,586 96,902 3,123 3,123 424 18,904 551 576 2023 822\nTable 7: The statistics of few-shot training sets. We set\ndifferent random seeds and generate 5 training sets for\neach setting. We report their average statistics.\nDataset Settings # Labels # Sent # Sample # Avg shot\nCONLL’03\n1-shot\n4\n4.8 5.8 1.4\n5-shot 16.2 21.8 5.5\n10-shot 29.2 42.6 10.7\n20-shot 65.6 82.0 20.5\nOntoNotes\n1-shot\n18\n20.0 33.4 1.9\n5-shot 84.8 148.0 8.2\n10-shot 158.6 281.0 15.6\n20-shot 332.8 547.2 30.4\nFewNERD\n1-shot\n66\n89.8 147.0 2.2\n5-shot 286.2 494.8 7.5\n10-shot 538.0 962.0 14.6\n20-shot 1027.2 1851.4 28.1\nTACREV\n1-shot\n41\n81.6 41.0 1.0\n5-shot 387.6 205.0 5.0\n10-shot 741.2 406.0 9.9\n20-shot 1367.2 806.0 19.7\n50-shot 2872.0 1944.0 47.4\n100-shot 4561.0 3520.0 85.9\nTACRED\n1-shot\n41\n81.6 41.0 1.0\n5-shot 387.6 205.0 5.0\n10-shot 741.2 406.0 9.9\n20-shot 1367.2 806.0 19.7\n50-shot 2871.2 1944.0 47.4\n100-shot 4575.2 3520.0 85.9\nACE05\n1-shot\n33\n47.4 41.0 1.2\n5-shot 192.8 165.0 5.0\n10-shot 334.6 319.4 9.7\n20-shot 579.4 598.2 18.1\nMA VEN\n1-shot\n168\n157.6 298.0 1.8\n5-shot 540.4 1262.2 7.5\n10-shot 891.2 2413.8 14.4\n20-shot 1286.4 4611.4 27.4\nERE\n1-shot\n38\n48.4 54.6 1.4\n5-shot 175.0 219.2 5.8\n10-shot 304.8 432.4 11.4\n20-shot 521.6 806.6 21.2\nACE05\n1-shot\n33\n23.4 40.2 1.2\n5-shot 79.8 178.2 5.4\n10-shot 130.8 337.4 10.2\n20-shot 213.4 630.2 19.1\nRAMS\n1-shot\n139\n130.2 332.6 2.4\n5-shot 514.0 1599.6 11.5\n10-shot 795.2 3193.2 23.0\n20-shot 1070.4 6095.4 43.9\nERE\n1-shot\n38\n21.6 102.8 2.7\n5-shot 74.2 403.4 10.6\n10-shot 127.2 775.6 20.4\n20-shot 190.2 1397.2 36.8\nods by ourselves. We use RoBERTa-large (Liu\net al., 2019) as the backbones. We adopt Auto-\nmatic Mixed Precision (AMP) training strategy9 to\nsave memory. We run each experiment on a single\nNVIDIA V100 GPU. We train each model with\nthe AdamW (Loshchilov and Hutter, 2019) opti-\nmizer with linear scheduler and 0.1 warm-up steps.\nWe set the weight-decay coefficient as 1e-5 and\nmaximum gradient norms as 1.0. We set the batch\nsize as 64, the maximum input length as 192, the\ntraining step as 500 and the learning rate as 5e-5.\nKnowPrompt We implement this method based\non original source code10, and use RoBERTa-large\nas our backbones. We set 10 maximum epochs for\n50- and 100-shot datasets, and as 50 epochs for\nother datasets. We keep all other hyperparameters\nas default, and run each experiment on a single\nNVIDIA V100 GPU.\nPAIE We implement this method on original\nsource code11, and use BART-large (Lewis et al.,\n2020) as backbones. We keep all hyperparameters\nas default for ACE and RAMS dataset. For ERE\ndataset, we set the training step as 1000, the batch\nsize as 16 and the learning rate as 2e-5. We run\neach experiment on a single NVIDIA V100 GPU.\nUIE We implement this method based on original\nsource code 12, and use T5-large (Raffel et al.,\n2020) as the backbones. We run each experiment\non a single NVIDIA Quadro RTX8000 GPU. We\nset the batch size as 4 with 4000 training steps.\nWe set the maximum input length as 800 and the\nlearning rate as 1e-4.\nC LLMs Implementations\nRegarding our empirical study, we explore the ICL\nabilities of LLMs on few-shot IE tasks. We mainly\nuse five LLMs from two sources. (1) OpenAI\n9https://pytorch.org/docs/stable/amp.html\n10https://github.com/zjunlp/KnowPrompt\n11https://github.com/mayubo2333/PAIE\n12https://github.com/universal-ie/UIE\n10586\nmodels: CODEX (code-davinci-002; Chen et al.\n2021), InstructGPT (text-davinci-003; Ouyang\net al. 2022), and ChatGPT (gpt-3.5-turbo-0301).\n(2) Open-source models: LLaMA-13B (Touvron\net al., 2023) and its instruction-tuned counterpart,\nVicuna-13B (Chiang et al., 2023). We detail their\nimplementation details in the next sections below.\nC.1 Open-source Models\nWe implement multiple ICL approaches on\nLLaMA-13B and Vicuna-13B without fine-tuning.\nWe set the maximum input length as 2048 and the\nbatch size as 1. We run each experiment on a single\nNVIDIA V100 GPU. To achieve this, we leverage\nthe Accelerate13 framework and fp16 inference\nto save memory. We set maximum output length\nas 96 and sampling temperature as 0 (i.e., greedy\ndecoding). We set both frequency_penalty and\npresence_penaltyas 0.\nC.2 OpenAI Models\nWe implement multiple ICL approaches on Ope-\nnAI models by calling their official APIs14. We set\nthe maximum input length as 3600 for all tasks and\nmodels. The only exception occurs when we use\nCODEX on RE tasks, where we set the maximum\ninput length as 7000. We unify the maximum out-\nput length as 32 for RE task, and 96 for other three\ntasks. We set the sampling temperature coefficient\nas 0, i.e., greedy decoding.\nD Pivot Experiments on LLMs\nD.1 Sampling Temperature\nExisting prompt-engineering discussion15 suggests\nsetting the sampling temperature t = 0 for tasks\nwith structured outputs, including IE tasks. We\nvalidate this conclusion in Table 8, from which we\ncould see the generated quality whent= 0 is much\nhigher than the quality when t̸= 0. Therefore we\nset t= 0 in all main experiments, and do not take\nself-consistency (Wang et al., 2023c) into account.\nD.2 Automatic Chain-of-thought\nWe additionally investigate whether rationales\ncould facilitate LLMs’ performance on few-shot\nIE tasks. Since there exists no golden rationales in\n13https://huggingface.co/docs/accelerate\n14https://openai.com/blog/openai-api\n15https://help.openai.com/en/articles/6654000-best-\npractices-for-prompt-engineering-with-openai-api\nTable 8: F1-scores across different t values. Experi-\nments run on 10-shot settings with CODEX.\nFewNERD TACREV ACE05\nt= 0 48.5(1.9) 53.7(2.3) 42.9(2.2)\n+ 5-ensemble 53.5(1.3) 58.6(1.5) 46.3(0.8)\nt= 0.7 40.9(2.3) 39.9(1.2) 35.6(1.0)\n+ self-consistency 52.1(0.9) 53.4(1.3) 45.6(3.0)\noriginal datasets, we follow Automatic Chain-of-\nthought (Auto-CoT; Zhang et al. 2023b) method as\nbelow. Regarding each sample, we query LLMs\nAccording to [sentence], Why [span] is a [label].\nFor example, given the sentence “DSC and Trac-\ntion Control on all Speed3 models is also stan-\ndard. ”, we would feed LLM the query that “Could\nyou explain why Speed3 is a kind of car”. Then we\ninsert the bootstrapped rationales between the sen-\ntences and ground-truth answers. If a sentence has\nno positive labels, however, we do not ask LLMs\nand keep the original format as the vanilla ICL ap-\nproach. Here we prompt InstructGPT to generate\nthe rationales with temperature t= 0.7. We com-\npare the performance with and without Auto-CoT\nas shown in Table 9.\nTable 9: The F1-score difference between with and\nwithout Auto-CoT. We generate rationales by Instruct-\nGPT, then adopt ICL w. Auto-CoTapproach and use\nCODEX as our backbone for inference.\n10-shot train setFewNERD\n(NER)\nTACREV\n(RE)\nACE05\n(ED)\nwo. Auto-CoT 54.0(1.4) 57.3(1.8) 47.7(2.8)\nw. Auto-CoT 36.6(1.7) 22.0(1.2) 43.1(3.4)\nWe are frustrated to find Auto-CoT degrades the\nperformance with a large margin. We speculate\nthis degration could be attributed to three main\nreasons. (1) The rationale increase the length of\neach sample and thus decrease the overall example\nnumber in demos. (2) There exists an obvious\ndiscrepancy between sentences with and without\npositive labels. The rationales are only provided for\nsentences with positive labels because it is hard to\nexplain why a sentence dose not contain any label.\n(3) Some auto-generated rationales are low-quality,\nespecially for RE tasks. We would explore better\nstrategy to exploit auto-genertaed rationales in the\nfuture work.\n10587\nTable 10: F1-scores difference among GPT-4, CODEX and InstructGPT.\nNER (20-shot) RE (100-shot) ED (20-shot) EAE (20-shot)\nCONLL OntoNotes FewNERDTACREV TACREDACE05 MA VEN EREACE05 RAMS ERE\nInstructGPT 77.2 47.7 57.2 62.7 53.8 49.3 25.4 40.8 45.8 42.2 41.9\nCODEX 81.1 55.6 55.9 62.4 53.6 47.9 22.8 39.0 - - -\nGPT-4 84.7 65.6 57.8 59.3 50.4 52.1 30.2 40.5 42.9 38.6 38.2\nSupervised SoTA 72.3 74.9 61.4 72.6 63.1 65.8 54.7 56.2 55.2 57.7 55.6\nD.3 GPT-4 v.s. Others\nWe tend to minimize the GPT-4 calls due to its high\nprice. Thus we utilize 20-/100-shot settings across\neach dataset to compare GPT-4’s performance with\nother LLMs. Table 10 reveals that GPT-4 does not\noutperform other LLMs significantly, except on\nOntoNotes and MA VEN. However, even on these\ndatasets, GPT-4 still falls behind supervised SLMs\nby a significant margin. Consequently, the exclu-\nsion of GPT-4 does not undermine the conclusions\ndrawn from our main experiments, and we omit it\nfrom our empirical study.\nE Auxiliary Experiments\nE.1 LLMs struggle on Fine-grained Datasets\nBased on the results shown in Figure 2, we addi-\ntionally provide a quantitative analysis to show that\nLLMs struggle with fine-grained datasets. Under\nthe 5-shot setting, we compare the performance\ndifference of LLMs (ChatGPT) and SLMs (SoTA\nfew-shot models) among different datasets. For\neach IE task, we observe a clear negative corre-\nTable 11: Performance comparison between LLMs\n(ChatGPT) and SLM-based methods among datasets\nwith various schema complexities.\nNamed Entity Recognition\nCoNLL OntoNotes FewNERD\n# Entity 4 18 66\nMicro-F1 (SLM) 52.5 59.7 59.4\nMicro-F1 (LLM) 77.8 59.4 55.5\n∆F1 (LLM, SLM) 25.3 -0.3 -3.9\nEvent Detection\nACE05 ERE MA VEN\n# Event 33 38 168\nMicro-F1 (SLM) 55.1 48.0 49.4\nMicro-F1 (LLM) 39.6 33.8 25.3\n∆F1 (LLM, SLM) -15.5 -14.2 -24.1\nEvent Argument Extraction\nACE05 ERE RAMS\n# Event / #Role 33 / 22 38 / 26 139 / 65\nHead-F1 (SLM) 45.9 40.4 54.1\nHead-F1 (LLM) 52.8 40.7 44.2\n∆F1 (LLM, SLM) 6.9 0.3 -9.9\nlation between the label number (row 2) and the\nperformance difference (row 5). In other words,\nwith more label types, LLMs tend to perform rel-\natively worse than SLMs. Therefore we conclude\nthat LLMs struggle on fine-grained datasets.\nE.2 Finding Better Instruction\nTo investigate whether LLMs would benefit from\ncomplex instructions, we explored six instruction\nvariants from simple to complex. Take NER task\nas an example, we illustrate them as below.\nInstruction0: [empty]\nInstruction1: Identify the entities\nexpressed by each sentence, and locate\neach entity to words in the sentence.\nThe possible entity types are: [Type_1],\n[Type_2], ..., [Type_N]. If you do not\nfind any entity in this sentence, just\noutput ‘Answer: No entities found.’\nInstruction2: Identify the entities\nexpressed by each sentence, and locate\neach entity to words in the sentence.\nThe possible entity types are:\n• [Type_1]: [Definition_1]\n• [Type_2]: [Definition_2]\n• ...\n• [Type_N]: [Definition_N]\nIf you do not find any entity in\nthis sentence, just output ‘Answer: No\nentities found.’\nInstruction3: Assume you are an\nentity-instance annotator. Given a\nsentence, you need to (1) identify the\nword or phrase about the entity in the\nsentence, and (2) classify its entity\ntype. The possible entity types are\nlisted as below: [Type_1], [Type_2],\n. . . , [Type_N]. Please note that your\nannotation results must follow such\nformat: ”’Answer: ([Type_1] <SEP>\n10588\nidentified_entity:[Entity_1]), ([Type_2]\n<SEP> identified_entity:[Entity_2]),\n......”’. If you do not find any entity\nin this sentence, just output ‘Answer:\nNo entities found.’\nInstruction4: Assume you are an\nentity-instance annotator. Your\nobjective is to perform a series\nof intricate steps for Named Entity\nRecognition. Firstly, you have to\nidentify a particular word or phrase\nin the sentence that corresponds to\nan entity. Following this, classify\nthe entity into one of the potential\nentity types. The potential entity\ntypes are provided as below: [Type_1],\n[Type_2], . . . , [Type_N]. Please note\nthat your annotation results must follow\nsuch format: ‘Answer: ([Type_1] <SEP>\nidentified_entity:[Entity_1]), ([Type_2]\n<SEP> identified_entity:[Entity_2]),\n......’. If you do not find any entity\nin this sentence, just output ‘Answer:\nNo entities found.’\nInstruction5: Assume you are an\nentity-instance annotator. Given a\nsentence, you need to (1) identify the\nword or phrase about the entity in the\nsentence, and (2) classify its entity\ntype. The possible entity types are\nlisted as below:\n• [Type_1]: [Definition_1]\n• [Type_2]: [Definition_2]\n• ...\n• [Type_N]: [Definition_N]\nPlease note that your annotation\nresults must follow such\nformat: ‘Answer: ([Type_1] <SEP>\nidentified_entity:[Entity_1]), ([Type_2]\n<SEP> identified_entity:[Entity_2]),\n......’. If you do not find any entity\nin this sentence, just output ‘Answer:\nNo entities found.’\nRegarding these six instructions, we evaluate\ntheir performance of ChatGPT on four 20-shot IE\ntasks. As shown in Table 12, there is no signifi-\ncant correlation between the instruction complexity\nTable 12: F1-scores across six instruction formats. Ex-\nperiments run on 20-shot settings with ChatGPT.\nFewNERD\n(NER)\nTACREV\n(RE)\nACE\n(ED)\nACE\n(EAE)\nI0 57.6(2.1) 49.1(2.4) 44.0(1.4) 50.9(0.1)\nI1 58.3(0.5) 49.6(1.2) 42.6(1.0) 51.5(1.1)\nI2 57.7(1.0) 50.0(1.5) 41.8(0.9) 50.3(1.5)\nI3 57.6(2.3) 52.3(1.8) 42.9(1.3) 49.2(2.3)\nI4 56.8(0.9) 49.6(2.9) 41.6(1.9) 49.9(1.2)\nI5 57.8(0.5) 47.2(1.8) 43.1(1.8) 50.6(1.8)\nand LLMs’ performance. Even the prompt with-\nout instruction (I0) leads to comparable, if not bet-\nter, results than prompt with complex instructions.\nTherefore, we use simple instruction (I1) in our\nmain experiment.\nE.3 Do More Samples in Demos Help?\nWe wonder whether longer demos bring more pow-\nerful ICL abilities for LLMs. Thus we investigate\nthe impact of increasing the number of demon-\nstrations on LLMs’ performance in Figure 8. We\nobserve that: (1) The performance of the RE task\nconsistently improves with more demos, indicating\nits potential benefiting from additional annotations.\n(2) The NER and ED tasks reach a stable or de-\ngraded performance with increased demo numbers,\nsuggesting that they are limited even before reach-\ning the maximum input length. (3) Open-source\nLLMs, i.e., LLaMA and Vicuna, have more limited\ncapacities in leveraging demos compared to Ope-\nnAI models, with their performance stagnating or\neven collapsing with only a few (2-4) demos.\nE.4 Finding Better Demo Selection Strategy\nThe maximum input length of LLMs usually limits\nthe sentence number in demos even under few-\nshot settings. For each test sentence s, we de-\nmand a demo retriever E(D,s) which selects a\nsubset from Das the sentences in demo. Following\nprevious work, we consider three commonly-used\nstrategies. (1) Random sampling. (2) Sentence-\nembedding (Liu et al., 2022; Su et al., 2022): re-\ntrieving the top-K nearest sentences measured by\nsentence embedding. We compute the embeddings\nby SimCSE-RoBERTa-large(Gao et al., 2021).\nE(D,s) = arg-topKs′∈D[Sent-embed(s′,s)] (3)\n(3) Efficient Prompt Retriever (Rubin et al., 2022):\nretrieving by a neural retriever Rtrained on D.\nE(D,s) = arg-topKs′∈D[RD(s′,s)] (4)\n10589\nChatGPT CODEX\n36\n40\n44\n48\n52\n56\n60\n4 8 16 32 64 96\nFewNERD (NER)\nF1 score\n36\n40\n44\n48\n52\n56\n60\n4 8 16 32 64 96\nTACREV (RE)\nF1 score\n32\n36\n40\n44\n48\n4 8 16 32 64 96\nACE05 (ED)\nF1 score\n(a) OpenAI LLMs\nLLaMA (13B) Vicuna (13B)\n4\n8\n12\n16\n20\n24\n28\n2 4 8 16\nFewNERD (NER)\nF1 score\n4\n8\n12\n16\n20\n24\n28\n2 4 8 16\nTACREV (RE)\nF1 score\n4\n8\n12\n16\n20\n24\n28\n2 4 8 16\nACE05 (ED)\nF1 score\n(b) Open-source LLMs\nFigure 8: Relationship between demo number and F1-score among three datasets. Note that the x-axis in each\nsubfigure represents the number of demos (not the shot value K) during ICL. We adopt sentence embedding as the\ndemo selection strategy and text prompt in this experiment.\nFor each test sentence s, we pre-retrieve M sim-\nilar sentences ¯D = {(s′\ni,y′\ni)}M\ni=1 ⊂ D. Then\nwe score each sentence in ¯Dby their likelihoods\nPL(f(y′\ni)|f(s′\ni)) where f denotes the prompt for-\nmat adopted and Lthe scoring LM. We randomly\nselect positive sampless′\ni\n(pos) from the top-KD sen-\ntences and hard negative samples s′\ni\n(hard-neg) from\nthe bottom-KD ones. Then we train RD by in-\nbatch contrastive learning (Chen et al., 2020). For\neach sentence s′\ni within the batch, there are 1 posi-\ntive sentences s′\ni\n(pos) and 2B−1 negative sentences\n{s′\nj\n(hard-neg)}B\nj=1 ∪{s′\nj}B\nj̸=i. Here we adopt M as\n40, KD as 5, f as text prompt, the batch size Bas\n128, and the scoring LM Las FLAN-T5-xl.\nTable 13: F1-scores on three demo-selection strategies.\nExperiments run on 20-shot settings with ChatGPT.\nFewNERD\n(NER)\nTACREV\n(RE)\nACE\n(ED)\nRandom Sampling 53.2(0.4) 43.0(3.3) 38.0(1.5)\nSentence Embedding 57.6(2.3) 49.6(1.2) 42.9(1.3)\nEfficient Prompt Retriever 57.2(0.6) 48.0(0.8) 43.5(1.4)\nTable 13 demonstrates the F1-score performance\non different selection strategies. We find that both\nthe sentence embedding and EPR surpass random\nsampling by a large margin. Given the simplicity\nof the sentence embedding, we adopt it, rather than\nEPR, as our selection strategy in main experiment.\nTable 14: F1-scores across three prompt formats. Ex-\nperiments run on 20-shot settings with ChatGPT.\nFewNERD\n(NER)\nTACREV\n(RE)\nACE\n(ED)\nACE\n(EAE)\nText 57.6(2.3) 49.6(1.2) 42.9(1.3) 51.5(1.1)\nCode 53.2(0.9) 50.2(1.8) 44.3(2.0) 47.3(1.5)\nE.5 Finding Better Prompt Format\nPrevious studies on LLMs for few-shot IE tasks\nhave explored different prompt formats and high-\nlighted the importance of selecting an appropri-\nate format for achieving competitive performance.\nTherefore, we investigate two commonly-used vari-\nants in previous work: (1) Text prompt as shown in\nFigure 1. (2) Code prompt: We follow Wang et al.\n(2023b); Li et al. (2023) and recast the output of IE\ntasks in the form of code. See more details about\nthis format in their original papers.\nTable 14 shows comparable performance across\nall formats. Based on simplicity, we choose the\ntext prompt for our main experiment.\nF Case Study\nF.1 Hard Samples\nTable 15 showcases some hard examples which\nbenefits from our LLM reranking. In accordance\nwith our intuition, we observe that the LLM\n10590\nrerankers correct two kinds of erroneous predic-\ntions made by LLMs. (1) The lack of external\nknowledge, such as the first (Triptolemus is a fig-\nure in Greek mythology) and third examples (Mi-\nnas Gerais is a state instead of city). (2) Limited\nreasoning abilities, such as the second (His wife’s\nchildren are his children) and the fourth (The word\n\"fought\" in this sentence does not involve any phys-\nical violence) examples.\nF.2 Easy Samples\nAs discussed in Section 4.3, we attribute the in-\nferior performance of LLMs on easy samples to\ntheir false-positive predictions for negative samples.\nUpon examining the incorrect cases, we speculate\nthat two main reasons are responsible: (1) LLM\nhallucination and (2) span boundary mismatch. We\nprovide details on them with specific cases below.\nLLM Hallucination. The most distinctive mis-\ntakes made by LLMs. Without specific fine-tuning\non IE tasks, LLMs (with in-context learning ap-\nproaches) sometimes hallucinate and provide mean-\ningless, even confusing explanations or answers.\nFor instance, LLMs might predict a verb, preposi-\ntion or even special symbols as an entity.\nCase 1 : LLMs predict the word die as entity\nperson-other (Ground truth: None)\nSentence: Flavius Rumoridus (died 5th cen-\ntury AD) was a Roman soldier who was ap-\npointed consul in AD 403 in the Western Ro-\nman Empire at the same time as the eastern\nemperor Theodosius II served in the same\ncapacity in the East.\nCandidate Choices:\n(a) died do/does not belong to any known\nentities.\n(b) died is a kind of geopolitical entity.\n(c) died is a person, but not affiliated with\nfollowing professions: actor, artist, ath-\nlete, author, director, politician, scholar,\nsoldier.\nAnalysis: The sentence provides information\nabout Flavius Rumoridus, who was a Roman\nsoldier and appointed consul in AD 403. The\nsentence also mentions that he died in the 5th\ncentury AD, which is a statement about his\ndeath. Therefore, the correct answer is (c)\nbecause the sentence does not provide any\ninformation about Flavius Rumoridus being\naffiliated with any of the professions listed in\noption (c).\nCorrect Answer:(c)\nCase 2 : LLMs predict the word of as entity\norganization-other(Ground truth: None)\nSentence: During these years he studied at\nthe South Kensington Schools of the Royal\nCollege of Art.\nCandidate Choices:\n(a) of do/does not belong to any known en-\ntities.\n(b) of is an educational institute.\n(c) of pertains to an organization that does\nnot fall under the categories of com-\npany, educational institution, govern-\nment, media, political party, religion,\nsports league, sports team, band or mu-\nsical group.\nAnalysis: In the given sentence,of is a prepo-\nsition that indicates the relationship between\nSouth Kensington Schools and Royal College\nof Art. None of the candidate choices directly\naddress the correct relationship between these\nentities or state that they are not applicable.\nTherefore, the correct answer is (c): of does\nnot pertain to any known entities mentioned\nin the choices provided.\nCorrect Answer:(c)\nSpan boundary mismatch . Different from\nsentence-level approaches which take one or mul-\ntiple sentences as an unit and assign each word’s\nlabel globally, LLMs under our filter-then-rerank\n10591\nparadigm adopt sample-level approaches. In other\nwords, LLMs only consider each word/span candi-\ndate independently. The sample-level approaches\nenable LLMs to rerank candidates with the help of\nmulti-choice question prompt. However, they also\naggravate the span boundary mismatching prob-\nlem in NER and ED tasks. We empirically find\neasy samples suffering much more from boundary\nmismatching problem than hard samples.\nCase 3: LLMs predict Baron, a subspan of Baron\nCarl Hurleman, as the entity person-other(The\nground-truth entity type of Baron is None. And the\nground-truth entity type of Baron Carl Hurleman\nis person-artist/author).\nSentence: Additions in the 1740s were by\nBaron Carl Hurleman (1700 - 1753).\nCandidate Choices:\n(a) Baron do/does not belong to any known\nentities.\n(b) Baron is a person, but not affiliated with\nfollowing professions: actor, artist, ath-\nlete, author, director, politician, scholar,\nsoldier.\n(c) Baron is a kind of geopolitical entity\nAnalysis: In the given sentence, Baron is a\ntitle given to a person named Carl Hurleman,\nwho is mentioned as the one who made ad-\nditions in the 1740s. The sentence does not\nprovide any information about connections\nto geopolitical entities or any other known\nentities mentioned in the choices provided.\nTherefore, the correct answer is (b): Baron is\na person, but not affiliated with following pro-\nfessions: actor, artist, athlete, author, director,\npolitician, scholar, soldier.\nCorrect Answer:(b)\nCase 4 : LLMs predict 65th, a subspan of\n65th British Academy Film Awards , as the en-\ntity other-awards (The ground-truth entity type\nof 65th is None. And the ground-truth entity\ntype of 65th British Academy Film Awards is\nother-awards).\nSentence: Ralph Fiennes was nominated for\nthe BAFTA Award for Outstanding Debut by\na British Writer, Director or Producer at the\n65th British Academy Film Awards.\nCandidate Choices:\n(a) 65th do/does not belong to any known\nentities.\n(b) 65th is a kind of award.\n(c) 65th refers to some event except attack,\nelection, natural disaster, protest, revolu-\ntion and sports.\nAnalysis: The sentence mentions the 65th\nBritish Academy Film Awards, which is an\nevent that recognizes outstanding achieve-\nments in the film industry. Therefore, option\n(c) is incorrect as it excludes events like award\nceremonies. Option (a) is also incorrect as\nthe number 65th is associated with the event.\nHence, the correct answer is (b) as65th refers\nto the specific edition of the BAFTA Awards.\nCorrect Answer:(b)\nG Details on AdaptiveFilter-then-rerank\nParadigm\nG.1 Demonstration Examples\nWe convert few-shot IE tasks to multiple-choice\nquestions in our filter-then-rerank paradigm. We\nshow 4 examples used in demonstrations for FewN-\nERD dataset in Table 16, for TACREV dataset in\nTable 17, and for ACE05 datasets in Table 18.\nG.2 Template\nIn our filter-then-rerank paradigm, we utilize tem-\nplates converting candidate labels to question op-\ntions. We list the template for FewNERD dataset\nin Table 19, for TACREV dataset in Table 20, and\nfor ACE05 datasets in Table 21.\n10592\nTable 15: Examples of the samples corrected by LLM reranking. We sample four examples from NER, RE and ED\ntasks, respectively. Sentences: The sentences in which samples locate. We color the samples (entities or trigger\nwords) to be identified. Before: The prediction before LLM reranking. Based on SLM-based methods. After: The\nreranked prediction using LLMs. Rationales: LLM-generated Explanations.\nSentences (entity/event) Before After Rationales\nNamed Entity Recognition\nAccording to it, King Eleusis and\nCothonea (Cyntinia), parents of Trip-\ntolemus, are visited by Demeter, who\nrears their son, feeding him divine milk\nby day and placing him into the fire at\nnight, which makes Triptolemus grow\nfaster than mortal children normally do.\nperson-other\n✗\nother-god\n✓\nAccording to the context, Triptolemus is a\nfigure in Greek mythology, the son of King\nEleusis and Cothonea (Cyntinia). He was a\ndemigod who was sent by Demeter to teach\nmankind the art of agriculture. So Triptole-\nmus is a god in some legend/religious story.\nRelation Extraction\nSurvivors include his wife, Sandra; four\nsons, Jeff, James, Douglas and Harris; a\ndaughter, Leslie; his mother, Sally; and\ntwo brothers, Guy and Paul.\nNone\n✗\nper:children\n✓\nThe sentence states ’Survivors include his\nwife, Sandra; four sons, Jeff, James, Douglas\nand Harris; a daughter, Leslie; his mother,\nSally; and two brothers, Guy and Paul.’ This\nindicates ’his’ is the father of Jeff, James,\nDouglas and Harris, and the husband of San-\ndra. So his is the parent of Jeff.\nEliza Samudio, Bruno ’s ex-girlfriend\nand his 4-month-old baby boy’s mother,\ndisappeared from her hometown of Belo\nHorizonte, Minas Gerais.\nper:cities_of\n_residence ✗\nper:states_of\n_residence ✓\nThe sentence states that ’Eliza Samudio,\nBruno’s ex-girlfriend and his 4-month-old\nbaby boy’s mother, disappeared from her\nhometown of Belo Horizonte, Minas Gerais.’\nThis indicates that Eliza Samudio is from the\ncity of Belo Horizonte, which is located in\nthe state of Minas Gerais. So Eliza Samudio\nlives in the state or province Minas Gerais.\nEvent Detection\nWe have fought every institution, every\nlaw firm ... it ’s cost us a fortune but now\nwe ’re going on a massive expansion.\nConflict.Attack\n✗\nNone\n✓\nIn the given sentence, the word fought is\nused to describe the action of the speaker\nfighting against various institutions and law\nfirms. This does not involve any physical\nviolence or court proceedings, so the word\nfought does not trigger any known event.\n10593\nTable 16: Demo examples used in FewNERD dataset. We color the entity in blue.\nInstruct: Read following sentences and identify what is the entity type of 392 quoted by <t>.\nSentence: Powell v. Texas , <t> 392 <t> U.S. 514 ( 1968 ) , was a United States Supreme Court case that ruled that a\nTexas statute criminalizing public intoxication did not violate the Eighth Amendment protection against cruel and unusual\npunishment.\n(a) 392 is a legal document, a term or a convention in legal sense.\n(b) 392 does not belong to any known entities.\n(c) 392 refers to a protest, uprising or revolution event\n(d) 392 refers to a government or governmental agency\nAnalysis: In the context you provided, 392 refers to the volume number in the United States Reports where the Supreme\nCourt’s decision in Powell v. Texas can be found. However, 392 itself does not refer to a legal document. So 392 do/does\nnot belong to any known entities.\nAnswer: (b)\nInstruct: Read following sentences and identify what is the entity type of The New Yorker quoted by <t>.\nSentence: In 2004 Gourevitch was assigned to cover the 2004 U.S. presidential election for \" <t> The New Yorker <t> \".\n(a) The New Yorker does not belong to any known entities.\n(b) The New Yorker is a broadcast program.\n(c) The New Yorker is a kind of written art.\n(d) The New Yorker is a media/newspaper organization.\nAnalysis: The New Yorker is a well-known American magazine that has been published since 1925, and is primarily\nknown for its long-form journalism, commentary, and satire. It has a reputation for publishing high-quality writing on a\nwide variety of topics, including politics, culture, and the arts. So The New Yorker is a media/newspaper organization.\nAnswer: (d)\nInstruct: Read following sentence and identify what is the entity type of St. quoted by <t>.\nSentence: The May 1980 eruption of Mount <t> St. <t> Helens in the state of Washington seriously affected both 47th Air\nDivision and 92d Bombardment Wing operations at Fairchild AFB , resulting in dispersal of Fairchild ’s B-52 and KC-135\naircraft to various bases while around-the-clock shifts removed the volcanic ash from facilities within the base perimeter. ”\n(a) St. does not belong to any known entities.\n(b) St. is a natural disaster event.\n(c) St. is a geographic position about mountain.\nAnalysis: According to the context, St. is an abbreviation of Saint, used in the name of Mount St. Helens, which is an\nactive volcano in the state of Washington. However, St. itself does not refer to anything. So St. do/does not belong to any\nknown entities.\nAnswer: (a)\nInstruct: Read following sentence and identify what is the entity type of Ridzuan quoted by <t>.\nSentence: <t> Ridzuan <t> was promoted to Harimau Muda A for 2014 season .\n(a) Ridzuan does not belong to any known entities.\n(b) Ridzuan is a person, but not affiliated with following professions: actor, artist, author, director, politician, scholar,\nsoldier.\n(c) Ridzuan is an athlete.\nAnalysis: The mention of ’Harimau Muda A’ indicates that it is a sports-related context, and ’promoted’ implies a\nprogression or advancement within the sports team. So Ridzuan is an athlete.\nAnswer: (c)\n10594\nTable 17: Demo examples used in TACREV dataset. We color the subject and object entities in blue.\nInstruct: Read the sentence and determine the relation between she and lawyer quoted by <t>.\nSentence: The <t> lawyer <t> denied Italian news reports that she wept while addressing the court, but said Knox was\nupset as <t> she <t> recounted “ the pressure, the aggressiveness of the police who called her a liar . ”\n(a) she is the other family member of lawyer\n(b) she is a lawyer\n(c) she has no known relations to lawyer\nAnalysis: In the sentence, the word ’she’ refers to someone who was upset while recounting certain events in court.\nThe word ’lawyer’ refers to someone who denied a news report about that same person weeping in court. There is no\ninformation in the sentence to indicate that the two individuals are related in any way. So she has no known relations to\nlawyer.\nAnswer: (c)\nInstruct: Read the sentence and determine the relation between MEF and Myanmar Equestrian Federation quoted by <t>.\nSentence: Y ANGON , Dec. 27 -LRB- Xinhua -RRB- – Myanmar will hold a horse race in Yangon to commemorate the\ncountry ’s 63rd Anniversary Independence Day , the <t> Myanmar Equestrian Federation <t> -LRB- <t> MEF <t> -RRB-\nconfirmed to Xinhua on Monday.\n(a) MEF is also known as Myanmar Equestrian Federation\n(b) MEF has political affiliation with Myanmar Equestrian Federation\n(c) MEF has no known relations to Myanmar Equestrian Federation\nAnalysis: The symbols -LRB- and -RRB- in the sentence stand for left and right round brackets and are used to enclose\nthe abbreviation ’MEF’ to indicate that it is a replacement for the longer name ’Myanmar Equestrian Federation. So MEF\nis also known as Myanmar Equestrian Federation.\nAnswer: (a)\nInstruct: Read the sentence and determine the relation between Douglas Flint and chairman quoted by <t>.\nSentence: At the same time , Chief Financial Officer <t> Douglas Flint <t> will become <t> chairman <t> , succeeding\nStephen Green who is leaving to take a government job.\n(a) Douglas Flint has no known relations to chairman\n(b) Douglas Flint is a chairman\n(c) Douglas Flint is the employee of chairman\nAnalysis: The sentence states that Chief Financial Officer Douglas Flint Douglas Flint will succeed Stephen Green as a\nchairman. So Douglas Flint is a chairman.\nAnswer: (b)\nInstruct: Read the sentence and determine the relation between FAA and U.S. quoted by <t>.\nSentence: On its Web site , the <t> U.S. <t> <t> FAA <t> says the Category 2 rating means the country lacks the laws or\nregulations that are needed for the certification and oversight of air carriers , according to minimum international standards.\n(a) FAA is also known as U.S.\n(b) FAA has no known relations to U.S.\n(c) FAA has a headquarter in the country U.S.\nAnalysis: The sentence states that the FAA says the Category 2 rating means the country lacks the laws or regulations\nneeded for the certification and oversight of air carriers, indicating that the FAA is responsible for overseeing aviation\nregulations in the country. Actually the FAA (Federal Aviation Administration) is a U.S. government agency responsible\nfor regulating and overseeing civil aviation in the United States, and it has its headquarters in Washington, D.C.. So FAA\nhas a headquarter in the country U.S..\nAnswer: (c)\n10595\nTable 18: Demo examples used in ACE05 dataset. We color the trigger word in blue.\nInstruct: Read following sentences and identify what event is triggered by the word loan quoted by <t>.\nSentence: Separately , former WorldCom CEO Bernard Ebbers failed on April 29 to make a first repayment of 25 million\ndollars, plus interest, on a 400-million - dollar <t> loan <t> from MCI, the Journal said, citing SEC documents.\n(a) The word loan does not trigger any known event.\n(b) The word loan triggers a TRANSFER-MONEY event: giving, receiving, borrowing, or lending money when it is NOT\nin the context of purchasing something.\n(c) The word loan triggers a DECLARE-BANKRUPTCY event: an Entity officially requests legal protection from debt\ncollection due to an extremely negative balance sheet.\nAnalysis: In the given sentence, the word loan is used to describe the 400-million-dollar loan from MCI to former\nWorldCom CEO Bernard Ebbers, which he failed to repay on time. This situation clearly involves a transfer of money\nwithout the context of purchasing something, which falls under the TRANSFER-MONEY event. So the word loan\ntriggers a TRANSFER-MONEY event: giving, receiving, borrowing, or lending money when it is NOT in the context of\npurchasing something.\nAnswer: (b)\nInstruct: Read following sentences and identify what event is triggered by the words treated quoted by <t>.\nSentence: When she ’s in Germany , Lynch will be <t> treated <t> for bullet wounds and broken bones .\n(a) The word treated triggers an INJURE event: a PERSON gets/got injured whether it occurs accidentally, intentionally\nor even self-inflicted.\n(b) The word treated does not trigger any known event.\n(c) The word treated triggers a TRANSPORT event: an ARTIFACT (WEAPON or VEHICLE) or a PERSON is moved\nfrom one PLACE (GEOPOLITICAL ENTITY , FACILITY , LOCATION) to another.\nAnalysis: The sentence suggests that Lynch has already been injured and will receive medical treatment in Germany for\nher injuries. The word ’treated’ simply describes the medical care she will receive and does not indicate a new event or\naction taking place. So the word treated does not trigger any known event.\nAnswer: (b)\nInstruct: Read following sentences and identify what event is triggered by the words buy quoted by <t>.\nSentence: And I won’t dwell on the irony of an Oracle employee being driven out of Oracle , starting his own company ,\nand forcing Ellison to spend $ 10.3 billion to get his company – but not him – back ( though it does rather delightfully\nremind me of Coca - Cola basically giving away the bottling franchise and then spending billions to <t> buy <t> it back ) .\n(a) The word buy triggers a DECLARE-BANKRUPTCY event: an Entity officially requests legal protection from debt\ncollection due to an extremely negative balance sheet.\n(b) The word buy triggers a TRANSFER-OWNERSHIP event: The buying, selling, loaning, borrowing, giving, or\nreceiving of artifacts or organizations by an individual or organization.\n(c) The word buy does not trigger any known event.\nAnalysis: In the given sentence, the word buy is used to describe the action of Oracle spending $10.3 billion to get a\ncompany back. This clearly involves the transfer of ownership of the company from one entity to another. So the word buy\ntriggers a TRANSFER-OWNERSHIP event: The buying, selling, loaning, borrowing, giving, or receiving of artifacts or\norganizations by an individual or organization.\nAnswer: (b)\nInstruct: Read following sentences and identify what event is triggered by the words set quoted by <t>.\nSentence: British forces also began establishing the country’s first postwar administration Tuesday, granting a local sheik\npower to <t> set <t> up an administrative committee representing the groups in the region.\n(a) The word set triggers a START-POSITION event: a PERSON elected or appointed begins working for (or changes\noffices within) an ORGANIZATION or GOVERNMENT.\n(b) The word set triggers a START-ORG event: a new ORGANIZATION is created.\n(c) The word set does not trigger any known event.\nAnalysis: The phrase ’set up’ specifically implies the creation or establishment of a new organization or entity, rather than\nsimply the word ’set’. So the word set does not trigger any known event.\nAnswer: (c)\n10596\nTable 19: Templates for FewNERD dataset, where {ent} is the placeholder for entity type.\nEntity Template\nno-entity {ent} do/does not belong to any known entities.\nperson-artist/author {ent} is an artist or author.\nperson-actor {ent} is an actor.\nart-writtenart {ent} is a kind of writtenart.\nperson-director {ent} is a director.\nperson-other {ent} is a person, but not affiliated with following professions: actor, artist, athlete,\nauthor, director, politician, scholar, soldier.\norganization-other {ent} pertains to an organization that does not fall under the categories of company,\neducational institution, government, media, political party, religion, sports league,\nsports team, band or musical group.\norganization-company {ent} is a company\norganization-sportsteam {ent} is a sports team\norganization-sportsleague {ent} is a sports league\nproduct-car {ent} is a kind of car\nevent-protest {ent} refers to a protest, uprising or revolution event\norganization-\ngovernment/governmentagency\n{ent} refers to a government or governmental agency\nother-biologything {ent} is a special term about biology / life science.\nlocation-GPE {ent} is a kind of geopolitical entity\nlocation-other {ent} is a geographic locaton that does not fall under the categories of geopolitical\nentity, body of water, island, mountain, park, road, railway and transit.\nperson-athlete {ent} is an athlete or coach.\nart-broadcastprogram {ent} is a broadcast program.\nproduct-other {ent} is a kind of product that does not fall under the categories of airplane, train,\nship, car, weapon, food, electronic game and software.\nbuilding-other {ent} is a kind of building that does not fall under the categories of airport, hospital,\nhotel, library, restaurant, sports facility and theater\nproduct-weapon {ent} is a kind of weapon.\nbuilding-airport {ent} is an airport.\nbuilding-sportsfacility {ent} is a sports facility building.\nperson-scholar {ent} is a scholar.\nart-music {ent} is a music.\nevent-other {ent} refers to some event except attack, election, natural disaster, protest, revolution\nand sports\nother-language {ent} is a kind of human language.\nother-chemicalthing {ent} is some special term about chemical science.\nart-film {ent} is a film.\nbuilding-hospital {ent} is a hospital.\nother-law {ent} is a legal document, a term or a convention in legal sense.\nproduct-airplane {ent} is kind of airplane product.\nlocation-\nroad/railway/highway/transit\n{ent} is a geographic position about roadways, railways, highways or public transit\nsystems.\nperson-soldier {ent} is a soldier\nlocation-mountain {ent} is geographic position about mountain.\norganization-education {ent} is an educational institute/organization.\norganization-media/newspaper {ent} is a media/newspaper organization.\n10597\nproduct-software {ent} is a software product.\nlocation-island {ent} is geographic position about island.\nlocation-bodiesofwater {ent} is geographic position situated near a body of water.\nbuilding-library {ent} is a library.\nother-astronomything {ent} is a special term about astronomy.\nperson-politician {ent} is a politician or lawyer or judge.\nbuilding-hotel {ent} is a hotel building.\nproduct-game {ent} is a electronic game product.\nother-award {ent} is a kind of award.\nevent-sportsevent {ent} refers to some event related to sports.\norganization-showorganization {ent} is a band or musical organization.\nother-educationaldegree {ent} is a kind of educational degree.\nbuilding-theater {ent} is a theater.\nother-disease {ent} is a kind of disease.\nevent-election {ent} is an event about election.\norganization-politicalparty {ent} is a political party/organization.\nother-currency {ent} is a kind of currency.\nevent-\nattack/battle/war/militaryconflict\n{ent} is an event about attack, battle, war or military conflict.\nproduct-ship {ent} is a ship.\nbuilding-restaurant {ent} is a restaurant.\nother-livingthing {ent} is a living animal/creature/organism.\nart-other {ent} is a work of art, but not belong to the categories of music, film, written art,\nbroadcast or painting.\nevent-disaster {ent} is a natural disaster event.\norganization-religion {ent} is a religious organization.\nother-medical {ent} refers to some kind of medicine.entity\nlocation-park {ent} is a park.\nother-god {ent} is a god in some legend/religious story.\nproduct-food {ent} is a kind of food.\nproduct-train {ent} is a kind of train(vehicle).\nart-painting {ent} is an art painting.\n10598\nTable 20: Templates for TACREV dataset, where {subj} and {obj} are the placeholders for subject and object\nentities. Copied from (Lu et al., 2022a)\nRelation Template\nno_relation {subj} has no known relations to {obj}\nper:stateorprovince_of_death {subj} died in the state or province {obj}\nper:title {subj} is a {obj}\norg:member_of {subj} is the member of {obj}\nper:other_family {subj} is the other family member of {obj}\norg:country_of_headquarters {subj} has a headquarter in the country {obj}\norg:parents {subj} has the parent company {obj}\nper:stateorprovince_of_birth {subj} was born in the state or province {obj}\nper:spouse {subj} is the spouse of {obj}\nper:origin {subj} has the nationality {obj}\nper:date_of_birth {subj} has birthday on {obj}\nper:schools_attended {subj} studied in {obj}\norg:members {subj} has the member {obj}\norg:founded {subj} was founded in {obj}\nper:stateorprovinces_of_residence {subj} lives in the state or province {obj}\nper:date_of_death {subj} died in the date {obj}\norg:shareholders {subj} has shares hold in {obj}\norg:website {subj} has the website {obj}\norg:subsidiaries {subj} owns {obj}\nper:charges {subj} is convicted of {obj}\norg:dissolved {subj} dissolved in {obj}\norg:stateorprovince_of_headquarters {subj} has a headquarter in the state or province {obj}\nper:country_of_birth {subj} was born in the country {obj}\nper:siblings {subj} is the siblings of {obj}\norg:top_members/employees {subj} has the high level member {obj}\nper:cause_of_death {subj} died because of {obj}\nper:alternate_names {subj} has the alternate name {obj}\norg:number_of_employees/members {subj} has the number of employees {obj}\nper:cities_of_residence {subj} lives in the city {obj}\norg:city_of_headquarters {subj} has a headquarter in the city {obj}\nper:children {subj} is the parent of {obj}\nper:employee_of {subj} is the employee of {obj}\norg:political/religious_affiliation {subj} has political affiliation with {obj}\nper:parents {subj} has the parent {obj}\nper:city_of_birth {subj} was born in the city {obj}\nper:age {subj} has the age {obj}\nper:countries_of_residence {subj} lives in the country {obj}\norg:alternate_names {subj} is also known as {obj}\nper:religion {subj} has the religion {obj}\nper:city_of_death {subj} died in the city {obj}\nper:country_of_death {subj} died in the country {obj}\norg:founded_by {subj} was founded by {obj}\n10599\nTable 21: Templates for ACE05 dataset, where {evt} is the placeholder for event type.\nEvent Template\nno-event The word {evt} does not trigger any known event.\nMovement.Transport The word {evt} triggers a TRANSPORT event: an ARTIFACT (WEAPON or\nVEHICLE) or a PERSON is moved from one PLACE (GEOPOLITICAL ENTITY ,\nFACILITY , LOCATION) to another.\nPersonnel.Elect The word {evt} triggers an ELECT event which implies an election.\nPersonnel.Start-Position The word {evt} triggers a START-POSITION event: a PERSON elected or appointed\nbegins working for (or changes offices within) an ORGANIZATION or GOVERN-\nMENT.\nPersonnel.Nominate The word {evt} triggers a NOMINATE event: a PERSON is proposed for a position\nthrough official channels.\nConflict.Attack The word {evt} triggers an ATTACK event: a violent physical act causing harm or\ndamage.\nPersonnel.End-Position The word {evt} triggers an END-POSITION event: a PERSON stops working for\n(or changes offices within) an ORGANIZATION or GOVERNMENT.\nContact.Meet The word {evt} triggers a MEET event: two or more entities come together at a\nsingle location and interact with one another face-to-face.\nLife.Marry The word {evt} triggers a MARRY event: two people are married under the legal\ndefinition.\nContact.Phone-Write The word {evt} triggers a PHONE-WRITE event: two or more people directly\nengage in discussion which does not take place ’face-to-face’.\nTransaction.Transfer-Money The word {evt} triggers a TRANSFER-MONEY event: giving, receiving, borrowing,\nor lending money when it is NOT in the context of purchasing something.\nJustice.Sue The word {evt} triggers a SUE event: a court proceeding has been initiated for the\npurposes of determining the liability of a PERSON, ORGANIZATION or GEOPO-\nLITICAL ENTITY accused of committing a crime or neglecting a commitment\nConflict.Demonstrate The word {evt} triggers a DEMONSTRATE event: a large number of people come\ntogether in a public area to protest or demand some sort of official action. For eample:\nprotests, sit-ins, strikes and riots.\nBusiness.End-Org The word {evt} triggers an END-ORG event: an ORGANIZATION ceases to exist\n(in other words, goes out of business).\nLife.Injure The word {evt} triggers an INJURE event: a PERSON gets/got injured whether it\noccurs accidentally, intentionally or even self-inflicted.\nLife.Die The word {evt} triggers a DIE event: a PERSON dies/died whether it occurs acci-\ndentally, intentionally or even self-inflicted.\nJustice.Arrest-Jail The word {evt} triggers a ARREST-JAIL event: a PERSON is sent to prison.\nTransaction.Transfer-\nOwnership\nThe word {evt} triggers a TRANSFER-OWNERSHIP event: The buying, selling,\nloaning, borrowing, giving, or receiving of artifacts or organizations by an individual\nor organization.\nJustice.Execute The word {evt} triggers an EXECUTE event: a PERSON is/was executed\nJustice.Trial-Hearing The word {evt} triggers a TRIAL-HEARING event: a court proceeding has been\ninitiated for the purposes of determining the guilt or innocence of a PERSON,\nORGANIZATION or GEOPOLITICAL ENTITY accused of committing a crime.\nJustice.Sentence The word {evt} triggers a SENTENCE event: the punishment for the DEFENDANT\nis issued\nLife.Be-Born The word {evt} triggers a BE-BORN event: a PERSON is given birth to.\nJustice.Charge-Indict The word {evt} triggers a CHARGE-INDICT event: a PERSON, ORGANIZATION\nor GEOPOLITICAL ENTITY is accused of a crime\nBusiness.Start-Org The word {evt} triggers a START-ORG event: a new ORGANIZATION is created.\nJustice.Convict The word {evt} trigges a CONVICT event: a PERSON, ORGANIZATION or\nGEOPOLITICAL ENTITY is convicted whenever it has been found guilty of a\nCRIME.\nBusiness.Declare-Bankruptcy The word {evt} triggers a DECLARE-BANKRUPTCY event: an Entity officially\nrequests legal protection from debt collection due to an extremely negative balance\nsheet.\nJustice.Release-Parole The word {evt} triggers a RELEASE-PAROLE event.\n10600\nJustice.Fine The word {evt} triggers a FINE event: a GEOPOLITICAL ENTITY , PERSON or\nORGANIZATION get financial punishment typically as a result of court proceedings.\nJustice.Pardon The word {evt} triggers a PARDON event: a head-of-state or their appointed repre-\nsentative lifts a sentence imposed by the judiciary.\nJustice.Appeal The word {evt} triggers a APPEAL event: the decision of a court is taken to a higher\ncourt for review\nBusiness.Merge-Org The word {evt} triggers a MERGE-ORG event: two or more ORGANIZATION\nEntities come together to form a new ORGANIZATION Entity.\nJustice.Extradite The word {evt} triggers a EXTRADITE event.\nLife.Divorce The word {evt} triggers a DIVORCE event: two people are officially divorced under\nthe legal definition of divorce.\nJustice.Acquit The word {evt} triggers a ACQUIT event: a trial ends but fails to produce a convic-\ntion.\n10601",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.5830424427986145
    },
    {
      "name": "Shot (pellet)",
      "score": 0.4453321099281311
    },
    {
      "name": "Complement (music)",
      "score": 0.43856939673423767
    },
    {
      "name": "Investment (military)",
      "score": 0.4162677526473999
    },
    {
      "name": "Cognitive psychology",
      "score": 0.3220398426055908
    },
    {
      "name": "Psychology",
      "score": 0.27235764265060425
    },
    {
      "name": "Political science",
      "score": 0.17005905508995056
    },
    {
      "name": "Biology",
      "score": 0.08829039335250854
    },
    {
      "name": "Law",
      "score": 0.07778313755989075
    },
    {
      "name": "Chemistry",
      "score": 0.0708405077457428
    },
    {
      "name": "Politics",
      "score": 0.0
    },
    {
      "name": "Phenotype",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Organic chemistry",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Complementation",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I172675005",
      "name": "Nanyang Technological University",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I79891267",
      "name": "Singapore Management University",
      "country": "SG"
    }
  ],
  "cited_by": 80
}