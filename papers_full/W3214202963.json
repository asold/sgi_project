{
  "title": "Integrating Transformers and Knowledge Graphs for Twitter Stance Detection",
  "url": "https://openalex.org/W3214202963",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2027098760",
      "name": "Thomas Clark",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2937749668",
      "name": "Costanza Conforti",
      "affiliations": [
        "Monash University"
      ]
    },
    {
      "id": "https://openalex.org/A2031764755",
      "name": "Fangyu. Liu",
      "affiliations": [
        "Monash University"
      ]
    },
    {
      "id": "https://openalex.org/A2512114965",
      "name": "Zaiqiao Meng",
      "affiliations": [
        "Monash University"
      ]
    },
    {
      "id": "https://openalex.org/A108414181",
      "name": "Ehsan Shareghi",
      "affiliations": [
        "Monash University"
      ]
    },
    {
      "id": "https://openalex.org/A2098750953",
      "name": "Nigel Collier",
      "affiliations": [
        "Monash University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3168747821",
    "https://openalex.org/W2792410075",
    "https://openalex.org/W2898695519",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3033176962",
    "https://openalex.org/W13682356",
    "https://openalex.org/W3175604467",
    "https://openalex.org/W3005441132",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2970986510",
    "https://openalex.org/W2080133951",
    "https://openalex.org/W3118741274",
    "https://openalex.org/W3133499716",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2982295985",
    "https://openalex.org/W2998385486",
    "https://openalex.org/W3034850762",
    "https://openalex.org/W2973840669",
    "https://openalex.org/W3148568192",
    "https://openalex.org/W3098267758",
    "https://openalex.org/W3102551064",
    "https://openalex.org/W2347127863",
    "https://openalex.org/W3099215402",
    "https://openalex.org/W2970476646",
    "https://openalex.org/W3168028266",
    "https://openalex.org/W3034524234",
    "https://openalex.org/W2963995027"
  ],
  "abstract": "Stance detection (SD) entails classifying the sentiment of a text towards a given target, and is a relevant sub-task for opinion mining and social media analysis. Recent works have explored knowledge infusion supplementing the linguistic competence and latent knowledge of large pre-trained language models with structured knowledge graphs (KGs), yet few works have applied such methods to the SD task. In this work, we first perform stance-relevant knowledge probing on Transformers-based pre-trained models in a zero-shot setting, showing these models' latent real-world knowledge about SD targets and their sensitivity to context. We then train and evaluate new knowledge-enriched stance detection models on two Twitter stance datasets, achieving state-of-the-art performance on both.",
  "full_text": "Proceedings of the 2021 EMNLP Workshop W-NUT: The Seventh Workshop on Noisy User-generated Text, pages 304–312\nNovember 11, 2021. ©2021 Association for Computational Linguistics\n304\nIntegrating Transformers and Knowledge Graphs\nfor Twitter Stance Detection\nThomas Hikaru Clark♠, Costanza Conforti♠, Fangyu Liu♠,\nZaiqiao Meng♠, Ehsan Shareghi♣♠, Nigel Collier♠\n♠Language Technology Lab, University of Cambridge\n♣Department of Data Science and AI, Monash University\n♠{thc44, cc918, fl399, zm324, nhc30}@cam.ac.uk\n♣ehsan.shareghi@monash.edu\nAbstract\nStance detection (SD) entails classifying the\nsentiment of a text towards a given target,\nand is a relevant sub-task for opinion min-\ning and social media analysis. Recent works\nhave explored knowledge infusion — supple-\nmenting the linguistic competence and latent\nknowledge of large pre-trained language mod-\nels with structured knowledge graphs (KGs),\nyet few works have applied such methods\nto the SD task. In this work, we ﬁrst per-\nform stance-relevant knowledge probing on\nTransformers-based pre-trained models in a\nzero-shot setting, showing these models’ la-\ntent real-world knowledge about SD targets\nand their sensitivity to context. We then pro-\npose novel knowledge-enriched stance detec-\ntion models. We evaluate them on two Twitter\nstance datasets, achieving state-of-the-art per-\nformance on both.\n1 Introduction\nStance detection (SD) involves identifying a text’s\nstance towards a given target (for example, whether\na tweet is supportive, against, or neutral towards\nJoe Biden). This is a challenging task with down-\nstream use cases in opinion mining, fake news de-\ntection, and rumor veriﬁcation (Küçük and Can,\n2018; Fake News Challenge, 2017; Conforti et al.,\n2020). A major challenge for SD is the need\nfor knowledge of current events and other fast-\nchanging facts about the world.\nLarge pre-trained Transformer models trained\non vast corpora (Vaswani et al., 2017; Devlin et al.,\n2019) have blurred the line between language mod-\nels and knowledge bases, as shown by their perfor-\nmance on benchmarks like LAMA, which measure\nstatic factual knowledge (Petroni et al., 2020a; Rad-\nford et al., 2019). Recent works in SD have capital-\nized on the Transformer architecture; however, it\nremains uncertain how to adapt these models to the\nconstantly shifting factual landscape found in SD\ntasks, for example in political tweets. At the same\ntime, knowledge infusion (KI) approaches have\nhad success in integrating KGs with Transformers\nfor question-answering (QA) tasks, but there is a\nshortage of work on KI for SD.\nOur contributions are as follows: 1) We\nperform stance-relevant knowledge probing on\nTransformers-based pre-trained models, showing\nthese models’ partial real-world knowledge and\nsensitivity to context, and 2) We train and evaluate\nknowledge-enriched stance detection models on\ntwo Twitter stance datasets, achieving state-of-the-\nart performance on both.\n2 Previous Work\nThe original author baseline for the SemEval-16\nSD task used an SVM classiﬁer on hand-crafted\nfeatures (Mohammad et al., 2017). More recent\napproaches for SD have achieved better perfor-\nmance using transfer learning with Transformer\nmodels, but without adding knowledge infusion\n(Ghosh et al., 2019; Schiller et al., 2021; Kaushal\net al., 2021). This typically involves concatenating\na tweet and target and feeding it into a Transformer\nmodel with a classiﬁcation layer attached. To our\nknowledge, Kawintiranon and Singh (2021) is the\nonly SD work using “knowledge enhancement”,\nbut this approach was based on identifying stance-\nsignaling words rather than using KGs.\nMost attempts to augment Transformer models\nwith structured knowledge from KGs have focused\non QA tasks, such as CommonsenseQA (Talmor\net al., 2019), not SD. Bian et al. (2021) used Con-\nceptNet (Speer and Havasi, 2013) to extract knowl-\nedge descriptions relating entities in each question\nto entities in each answer choice via multi-hop rea-\nsoning on a KG, with a BERT-based classiﬁer to\nchoose the best answer. Similarly, K-BERT (Liu\net al., 2019) enriches entities in an input sentence\nbased on lookup in a KG. The success of these\nmethods suggests that downstream tasks can bene-\nﬁt from contextual priming, where the same input\n305\nsupplemented with additional factual context leads\nto better predictions. This can be contrasted with\napproaches like K-Adapter and KnowBERT, which\ninfuse knowledge by modifying the model archi-\ntecture, rather than by adding context to the input\n(Wang et al., 2020; Peters et al., 2020). One advan-\ntage of contextual priming is the ability to leave a\nmodel’s architecture largely unchanged, requiring\nonly a method of collecting and generating useful\nfactual context.\n3 Probing Transformers for\nStance-Relevant Knowledge\nIn this section, we seek to establish a lower bound\nfor the stance-relevant knowledge already present\nin Transformer models before doing any knowl-\nedge infusion. Rather than testing recall of en-\ncyclopedic facts, we probe whether models make\nstance-related inferences regarding real-world enti-\nties in a human-like way. The three models we test\nare RoBERTa-Base (Liu et al., 2020), RoBERTa-\nLarge, and Twitter-RoBERTa (Barbieri et al., 2020).\nRoBERTa is pre-trained on a large internet corpus,\nincluding news articles, while Twitter-RoBERTa\nis trained on ∼ 58M tweets, making these models\ngood candidates for political SD on Twitter. Using\neach model in a masked language modeling setting,\nwe feed it a sentence with a single word replaced\nby the special [MASK] token, returning a probabil-\nity distribution over all vocabulary tokens. Rather\nthan using an automatically-generated knowledge\nbenchmark like LAMA (Petroni et al., 2020b), we\ndraw on a human-in-the-loop paradigm (Nie et al.,\n2019) and manually design probes relevant to the\nSD task. Examples involve public ﬁgures and po-\nlitical issues that appear as targets in major SD\ndatasets (Mohammad et al., 2017; Grimminger and\nKlinger, 2021), such as Donald Trump, Hillary\nClinton, and climate change. We evaluate the mod-\nels using Accuracy@1, which is the percentage of\nprompts for which the highest-probability token\ngenerated by a model is appropriate in context, e.g.\nfactually correct or aligned with reasonable infer-\nences. Some key example pairs are shown below:\n(1) The Proud [MASK], a far-right group, held a\nrally.\n(2) The protests were sparked by the killing of\nGeorge [MASK], an unarmed black man in\nMinneapolis, Minnesota.\nIn example (1) above, all models were able to\npredict “Boys\" for the masked token. In example\n(2), all models predicted “Zimmerman\" rather than\nthe desired “Floyd\"; this illustrates how models\ncan quickly become outdated when new words and\nnames enter common usage after a model is pre-\ntrained.\n(3) I think that climate change is such a [MASK].\nSave the earth!\n(4) I think that climate change is such a [MASK].\nDrill, baby, drill!\nFor the above pair of probes, we test how the\npresence of pro- and anti-environmentalist slogans\nimpact stance-relevant predictions. Both RoBERTa\nmodels have reasonable predictions, outputting\n“threat” and “problem” for (3) and “hoax” for (4).\nThis shows how the models can sometimes leverage\nstance-relevant knowledge to make better predic-\ntions. This is not always the case, however:\n(5) Joe has a bumper sticker that reads ‘Drill Baby\nDrill’. He thinks climate change is a[MASK].\n(6) Joe has a bumper sticker that reads ‘Drill Baby\nDrill’. He thinks climate change is [MASK].\nFor (5), all models predict “hoax”, which ini-\ntially looks like a good stance-aware inference. For\n(6), however, all models predict “real”. The dele-\ntion of a single article, “a”, caused all models to\nmake a stance-incongruent prediction.\nFigure 1: Accuracy@1 on a test set of 105 handpicked\nstance-relevant knowledge probes, showing the supe-\nrior performance of RoBERTa-Large compared to the\nother models. The correctness of the answers was man-\nually labeled by the ﬁrst author.\nWe include additional examples of prompts in\nthe Appendix, as well as a breakdown of probing\nperformance by model in Figure 1. The key points\nof our probing analysis are that a) Transformer\n306\nmodels contain latent stance-relevant knowledge\nthat can inform SD tasks, b) RoBERTa-Large beats\nsmaller models, and c) stance-aware predictions\ncan often be overruled by context. The results\nestablish a promising lower bound on the stance-\nrelevant knowledge of LMs, yet a signiﬁcant gap\nremains. We therefore propose a way of using KGs\nto infuse knowledge speciﬁcally for SD tasks.\n4 Knowledge Infusion for SD\n4.1 Basic Knowledge Infusion\nA KG is described by a list of triples of the form\n(e1, r, e2), where e1 and e2 are entities (nodes)\nlinked by the relation (edge) r. To leverage such\nknowledge, we follow the intuition that short de-\nscriptions of unfamiliar entities may operate as a\nform of contextual priming. This is supported by\nthe knowledge probing literature, as well as works\nlike AUTO PROMPT (Shin et al., 2020) which learn\nto construct optimal contextual triggers for eliciting\nknowledge from a LM.\nGiven a tweet, we use the spaCy entity linker\n(Honnibal and Montani, 2020), which identiﬁes\nspans in a text that refer to entities from the Wiki-\ndata KG (Vrandeˇci´c and Krötzsch, 2014). spaCy\ncan identify different forms of an entity, and out-\nputs short descriptions of any found entities. We\nthen generate short knowledge descriptions of the\nform “[Entity], [Description]” for all entities found\nin a tweet. For example, a tweet containing the\nstring ‘Putin’ would be paired with the following\ndescription: “Vladimir Putin, 2nd and 4th Presi-\ndent of Russia”. These descriptions are prepended\nto the tweet along with the stance detection target,\nseparated from the tweet string by a special separa-\ntor token. This enrichment process is done for both\nthe training data and the testing data. We report\nresults for this approach in Section 5.\n4.2 Custom Knowledge Graph Construction\nand Pathﬁnding\nThe previous approach operates as a form of knowl-\nedge lookup, but does not exploit the informative\nrelations between entities that may be contained in\na KG. Prior works have exploited multi-hop knowl-\nedge paths within a KG to improve NLU perfor-\nmance (Bian et al., 2021), an approach we now\napply to SD. To reduce the computational cost of\nﬁnding knowledge pathways, we propose a cus-\ntomized collection approach of ﬁltering for Wiki-\ndata triples within a small number of hops from the\nFigure 2: Illustration of our proposed path-based\nknowledge infusion method.\ntarget entities of the SD datasets. Additionally, we\ninclude Wikidata triples relating to trending tropes,\nwhich we identify by ﬁnding words and colloca-\ntions with a high temporal concentration in a large\nTwitter dataset spanning the timeframe of the SD\ntask. Collocations are identiﬁed using Pointwise\nMutual Information (PMI). Examples of trending\ntropes are provided in the Appendix. In short, we\nuse several strategies to limit the size of the KG\nwhile keeping the entities and relations most likely\nto help with SD.\nTo infuse knowledge, we use our custom KG\nto ﬁnd knowledge pathways connecting entities in\na tweet to the SD targets. Since there are many\npossible pathways between two nodes in a KG, we\nlimit paths to length 3 and choose the minimum\ncost path. We initially assign edge costs using a\nrandom walk strategy, which penalizes knowledge\npaths through less informative hub nodes. An ex-\nample of low and high informativeness pathways\nfound by the random walk strategy is shown below,\nreﬂecting the intuition that two people both hold-\ning the occupation President of the United States is\na more informative relation than two people both\nworking in Washington, D.C.\n(7) High Informativeness: Donald Trump held\nthe position of President of the United States.\nPresident of the United States has ofﬁceholder\nJoe Biden.\n(8) Low Informativeness : Donald Trump has\nwork location Washington, D.C. Presidential\ntransition of Joe Biden has headquarters loca-\ntion Washington, D.C.\nWe turn any found knowledge pathways into\nnatural language knowledge descriptions that are\nprepended to the tweet. The example shown in\nFigure 2 shows how this approach could plausibly\n307\nimprove SD performance. Suppose a tweet men-\ntions the entity “Kamala”, but the model has not\nbeen exposed to many instances of this entity in\nits training data. The SD task is to determine the\ntweet’s stance towards Donald Trump. Using a\nKG, the model establishes a knowledge pathway\nfrom Kamala Harris to Donald Trump, reﬂecting\nthe knowledge that both are politicians.\n4.3 Edge Cost Tuning\nA major problem for our knowledge infusion ap-\nproach is ﬁnding informative multi-hop knowledge\npaths. While the random-walk edge weighting\nmethod is a ﬁrst step, it is highly dependent on\nthe properties of the KG being traversed. Secondly,\nthis method does not take advantage of the avail-\nable training data to improve the estimates of edge\ncost. As a result, we propose a method called Edge\nCost Tuning (ECT) for using the available training\ndata to test KG edges for informativeness.\nECT builds on the previous path-based knowl-\nedge infusion model, using it to evaluate the help-\nfulness of various knowledge paths. For each tweet\nin the training set, our model ﬁnds the lowest-cost\nknowledge path from the target to an entity in that\ntweet. Both an enriched and unenriched version of\nthe tweet are fed to the model. If the enriched ver-\nsion causes the model to assign a higher probability\nto the correct label than the unenriched version, the\ncosts for all links along that knowledge path are\nreduced. Otherwise, the costs for all links along\nthat knowledge path are increased. This causes un-\nhelpful edges in the KG to accumulate high costs,\nwhile helpful edges are promoted. Importantly, this\nprocedure has an interpretable result, as edges in\nthe KG can be sorted by their change in cost to un-\nderstand which pieces of context were most helpful\nor unhelpful in making stance predictions. The Ap-\npendix contains before-and-after examples of the\nECT method.\n5 Experiments\nWe consider two Twitter datasets for SD: SemEval-\n16 (Mohammad et al., 2017) and Grimminger &\nKlinger (G&K) (Grimminger and Klinger, 2021).\nThe ﬁrst involves a range of controversial political\ntargets, such as abortion, atheism, and the 2016\nU.S. presidential election. The task is to predict a\nclass label from among { favor, against, neither}.\nThe dataset contains 2914 training examples and\n1249 test examples. The second centers exclusively\nFigure 3: In this synthetic example, the tweet mentions\nKamala Harris, who is connected to Donald Trump\nthrough a two-hop knowledge path. This knowledge\npath is tested against a no-enrichment baseline. Since\nthe knowledge enrichment leads to a higher probability\nfor the correct label, the corresponding edges in the KG\nare strengthened.\non the 2020 U.S. presidential election, and the pre-\ndiction classes are against, favor, neither, neutral,\nand mixed. The dataset contains 2400 training ex-\namples and 600 test examples. Most SD models\nin the literature use SemEval-16 as a benchmark,\nand recent works have used BERT to achieve new\nstate-of-the-art performance (Ghosh et al., 2019;\nKaushal et al., 2021; Schiller et al., 2021; Kawinti-\nranon and Singh, 2021).\nOur general architecture for SD with Transform-\ners involves the target (plus optional knowledge en-\nrichments) and the tweet being concatenated with\nan intervening separator token before being fed\ninto a RoBERTa model with a classiﬁcation head.\nThe weights of the entire network are updated dur-\ning training. The architecture is very similar to\nthat used in other Transformer-based SD models\n(Ghosh et al., 2019; Schiller et al., 2021; Kaushal\net al., 2021). We compare our knowledge infusion\nmodels with base models ﬁne-tuned on the same\ntask data, as well as with K-Adapter, described in\nSection 2 (Wang et al., 2020).\nAs reported in Table 1, the best model for the\nSemEval-16 task was RoBERTa-Large with entity\nenrichment, while the best model for the G&K task\nwas RoBERTa-Large with path enrichment and\nedge cost adjustment. One possible explanation\nfor this is that ECT may work best when all exam-\nples for a task share a common topic (e.g. the 2020\nelection), as opposed to SemEval-16, which had\n5 heterogeneous targets. Using a single KG with\na single set of edge costs for such a task seems to\nunderperform enrichment via direct entity lookup.\n308\nSemEval-16 Grimminger & Klinger\nModel Acc. F1 Ag. Fav. Nei. Neu.\nBaseline* - 69.1 79.0 89.0 95.0 53.0\nRoBERTa-Base 71.8 71.4 81.8 91.4 93.9 60.0\nTwitter-RoBERTa 71.4 71.7 82.7 90.0 94.5 56.4\nK-Adapter 74.5 74.8 86.1 93.2 94.1 63.8\nRoBERTa-Large 76.9 77.3 86.9 92.2 93.6 62.7\n+ Entities 77.2 78.5 86.9 92.9 94.6 65.1\n+ Paths 75.7 76.1 86.8 92.5 95.2 68.3\n+ ECT 75.1 76.2 87.0 93.7 96.0 67.2\nTable 1: Results for SemEval-16 Task: Mean Accuracy\nand F1 Scores (mean of Favor and Against labels). Re-\nsults for Grimminger & Klinger Task: Mean F1 Scores\nby label: Against, Favor, Neither, and Neutral. The\nMixed label was exceedingly rare in the dataset and no\nmodel ever predicted it, so all F1 scores for the Mixed\nlabel were 0. ECT = Edge Cost Tuning. *Baselines re-\nfer to author baselines from original SemEval and G&K\npapers.\nThe following are some examples from the\nG&K task that the knowledge-infused SD model\nwith ECT correctly predicted while the unenriched\nmodel failed (knowledge descriptions are in ital-\nics):\n(9) @realDonaldTrump It’s today! The day I go\nto the polls and vote for Joe Biden and Ka-\nmala Harris. donald trump held the position\nof president of the united states. president of\nthe united states has ofﬁceholder joe biden.\n(Correct Label: against Donald Trump)\n(10) Trump must have stock in Regeneron. stock,\nﬁnancial instrument. Donald Trump, 45th and\ncurrent president of the United States. Regen-\neron Pharmaceuticals, pharmaceutical com-\npany. (Correct Label: against Donald Trump)\n(11) Biden or Kamala won’t commit to their policy\non packing the court, Joe’s comment, “vote for\nme I’ll let you know?\" On fracking Joes ﬂip\nﬂopping, Kamala is against fracking! VOTE\nRED! donald trump has member of politi-\ncal party republican party. republican party\nhas color red (Correct Label: favor Donald\nTrump)\nWhile there were also examples where the gen-\nerated knowledge descriptions were irrelevant or\nnoisy, these examples demonstrate how an appro-\npriate knowledge description can improve down-\nstream model performance. Examples (9) and (11)\nillustrate the utility of multi-hop reasoning, adding\ncontext relating Donald Trump to Joe Biden and\nthe color red, respectively. Example (10) illus-\ntrates the usefulness of backing off to simple entity-\nenrichment in cases where no knowledge paths\nexist, providing useful additional context about the\ncompany Regeneron.\n6 Conclusion\nIn this work, we highlighted three key points based\non knowledge probing: Transformer models con-\ntain latent stance-relevant knowledge, RoBERTa-\nLarge is better at this than the other models, and\nmodels can be misled by sentence context. We\nalso established new state-of-the-art performance\non two SD datasets using knowledge infusion. We\nintroduce a novel method, Edge Cost Tuning, that\nuses training data to re-weight the connections in a\nknowledge graph, which produced best results on\none of the two SD tasks. Our approach depends\ngreatly on choice of KG and edge cost weighting\nmethod, so future work can explore additional ways\nof ﬁltering for informative edges in a KG.\nReferences\nFrancesco Barbieri, Jose Camacho-Collados, Luis Es-\npinosa Anke, and Leonardo Neves. 2020. Tweet-\nEval: Uniﬁed Benchmark and Comparative Evalu-\nation for Tweet Classiﬁcation.\nNing Bian, Xianpei Han, Bo Chen, and Le Sun. 2021.\nBenchmarking knowledge-enhanced commonsense\nquestion answering via knowledge-to-text transfor-\nmation.\nCostanza Conforti, Jakob Berndt, Mohammad Taher\nPilehvar, Chryssi Giannitsarou, Flavio Toxvaerd,\nand Nigel Collier. 2020. Will-They-Won’t-They: A\nVery Large Dataset for Stance Detection on Twitter.\nIn Proceedings of the 58th Annual Meeting of the\nAssociation for Computational Linguistics, Strouds-\nburg, PA, USA. Association for Computational Lin-\nguistics.\nJacob Devlin, Ming Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In NAACL HLT 2019 - 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies - Proceedings of the Conference, volume 1.\nFake News Challenge. 2017. Fake News Challenge:\nExploring how artiﬁcial intelligence technologies\ncould be leveraged to combat fake news.\nShalmoli Ghosh, Prajwal Singhania, Siddharth Singh,\nKoustav Rudra, and Saptarshi Ghosh. 2019. Stance\nDetection in Web and Social Media: A Comparative\n309\nStudy. In Lecture Notes in Computer Science (in-\ncluding subseries Lecture Notes in Artiﬁcial Intelli-\ngence and Lecture Notes in Bioinformatics), volume\n11696 LNCS.\nLara Grimminger and Roman Klinger. 2021. Hate to-\nwards the political opponent: A twitter corpus study\nof the 2020 us elections on the basis of offensive\nspeech and stance detection.\nMatthew Honnibal and Ines Montani. 2020. spacy.\nhttps://github.com/explosion/spaCy.\nAyush Kaushal, Avirup Saha, and Niloy Ganguly. 2021.\ntWT–WT: A dataset to assert the role of target enti-\nties for detecting stance of tweets. In Proceedings\nof the 2021 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies , pages 3879–3889,\nOnline. Association for Computational Linguistics.\nKornraphop Kawintiranon and Lisa Singh. 2021.\nKnowledge enhanced masked language model for\nstance detection. In Proceedings of the 2021 Con-\nference of the North American Chapter of the Asso-\nciation for Computational Linguistics: Human Lan-\nguage Technologies, pages 4725–4735, Online. As-\nsociation for Computational Linguistics.\nDilek Küçük and Fazli Can. 2018. Stance detection on\ntweets: An SVM-based approach.\nWeijie Liu, Peng Zhou, Zhe Zhao, Zhiruo Wang, Qi Ju,\nHaotang Deng, and Ping Wang. 2019. K-BERT:\nEnabling language representation with knowledge\ngraph.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2020.\nRoBERTa: A Robustly Optimized BERT Pretrain-\ning Approach.\nSaif M. Mohammad, Parinaz Sobhani, and Svetlana\nKiritchenko. 2017. Stance and sentiment in Tweets.\nACM Transactions on Internet Technology, 17(3).\nYixin Nie, Adina Williams, Emily Dinan, Mohit\nBansal, Jason Weston, and Douwe Kiela. 2019. Ad-\nversarial NLI: A new benchmark for natural lan-\nguage understanding.\nMatthew E. Peters, Mark Neumann, Robert L. Lo-\ngan, Roy Schwartz, Vidur Joshi, Sameer Singh, and\nNoah A. Smith. 2020. Knowledge enhanced con-\ntextual word representations. In EMNLP-IJCNLP\n2019 - 2019 Conference on Empirical Methods in\nNatural Language Processing and 9th International\nJoint Conference on Natural Language Processing,\nProceedings of the Conference.\nFabio Petroni, Patrick Lewis, Aleksandra Piktus, Tim\nRocktäschel, Yuxiang Wu, Alexander H. Miller, and\nSebastian Riedel. 2020a. How context affects lan-\nguage models’ factual predictions.\nFabio Petroni, Tim Rocktäschel, Patrick Lewis, Anton\nBakhtin, Yuxiang Wu, Alexander H. Miller, and Se-\nbastian Riedel. 2020b. Language models as knowl-\nedge bases? In EMNLP-IJCNLP 2019 - 2019 Con-\nference on Empirical Methods in Natural Language\nProcessing and 9th International Joint Conference\non Natural Language Processing, Proceedings of\nthe Conference.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nModels are Unsupervised Multitask Learners | En-\nhanced Reader. OpenAI Blog, 1(8).\nBenjamin Schiller, Johannes Daxenberger, and Iryna\nGurevych. 2021. Stance Detection Benchmark:\nHow Robust is Your Stance Detection? KI - Kun-\nstliche Intelligenz.\nTaylor Shin, Yasaman Razeghi, Robert L. Logan IV,\nEric Wallace, and Sameer Singh. 2020. AutoPrompt:\nEliciting Knowledge from Language Models with\nAutomatically Generated Prompts.\nRobert Speer and Catherine Havasi. 2013. ConceptNet\n5: A Large Semantic Network for Relational Knowl-\nedge.\nAlon Talmor, Jonathan Herzig, Nicholas Lourie, and\nJonathan Berant. 2019. Commonsenseqa: A ques-\ntion answering challenge targeting commonsense\nknowledge.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems, volume 2017-Decem.\nDenny Vrande ˇci´c and Markus Krötzsch. 2014. Wiki-\ndata: A free collaborative knowledgebase. Commun.\nACM, 57(10):78–85.\nRuize Wang, Duyu Tang, Nan Duan, Zhongyu Wei, Xu-\nanjing Huang, Jianshu Ji, Guihong Cao, Daxin Jiang,\nand Ming Zhou. 2020. K-ADAPTER: Infusing\nknowledge into pre-trained models with adapters.\n310\nA Trending Topics Identiﬁcation\nWe hypothesize that knowledge of trending topics\nis important for political SD on Twitter for two\nmain reasons: a) especially in the social media do-\nmain, trending topics can be very stance-signaling\nand b) pre-trained models will typically not have\nlatent knowledge of these tropes because they are\ntoo temporally concentrated to be well-represented\nin the pre-training data. We implement a simple\nstrategy for detecting tropes, based on three as-\nsumptions:\n(1) Trending tropes will be relatively frequent n-\ngrams.\n(2) Trending tropes will be highly non-uniform in\ntheir distribution over time.\n(3) Multi-word tropes will behave like colloca-\ntions, with high pointwise mutual information\nbetween words.\nFor a given SD task, we sample a large selection\nof tweets from the same timeframe as the SD data\n(summer 2015 for SemEval-16, autumn 2020 for\nG&K). Within this sample, we choose uni-, bi-, and\ntri-grams that ﬁt the above criteria. Figure 4 shows\na sampling of discovered trending topics for the\nG&K SD task, each accompanied by a histogram\nof its occurrence over time.\nB Results of Edge Cost Tuning\nAt the end of edge cost tuning, edges in\nthe graph will have either lower, higher, or\nthe same costs as before. Looking at the\nresults, we see that the adjustments gener-\nally align with intuition. For example, in\nthe G&K dataset, the triple (politician,\noccupation_, Kamala Harris) had one\nof the biggest decreases in cost after adjustment.\nThis makes sense, because she may not have been\na very prominent entity in the RoBERTa training\ndata, but rose to much higher prominence in 2020\nas Joe Biden’s running mate. The decreased cost\nfor that triple indicates that injecting this piece of\nknowledge generally helped predictions, while the\nlowered cost ensures that this piece of knowledge\nwill be highly accessible to the model when evalu-\nated on test data.\nC Stance-Relevant Knowledge Probes\n311\nFigure 4: Examples of top bigram tropes for the G&K time frame on Twitter, restricted to tweets that mention\nDonald Trump.\nSubject Relation Object\ndonald trump occupation politician\ndonald trump position held president of the ...\npresident of the ... ofﬁceholder joe biden\npolitician occupation_ kamala harris\ndonald trump member of political... republican party\ndonald trump award received time person of the year\nrepublican party opposite of democratic party\n... ... ...\ndonald trump award received wwe hall of fame\ntrump tower occupant trump family\ngolf country of origin scotland\ngovernment manifestation of power\ndonald trump signiﬁcant person_ 2021 storming of the...\n2021 storming of the ... instance of demonstration\nTable 2: Results of Edge Cost Tuning on G&K training data, arranged from biggest decrease in cost (top) to biggest\nincrease in cost (bottom).\n312\nPrompt RoBERTa-\nLarge\nRoBERTa-\nBase\nTwitter-\nRoBERTa\nDonald Trump spoke at a pro [MASK] rally on the\nanniversary of Roe v. Wade.\nlife life life\nHillary Clinton spoke at a pro [MASK] rally on the\nanniversary of Roe v. Wade.\nabortion life abortion\nDonald Trump is a member of the [MASK] Party. Republican Republican Republican\nHillary Clinton is a member of the [MASK] Party. Democratic Democratic Democratic\nIreland passed a referendum which repealed the con-\nstitutional ban on [MASK].\nabortion abortion abortion\nThe Proud [MASK], a far-right group, held a rally. Boys Boys Boys\nAmy Coney [MASK] was nominated to the Supreme\nCourt by President Trump.\nBarrett Barrett worth\nI believe in God, guns, and the Bible. Feminism is\n[MASK].\nbullshit bullshit bullshit\nI believe in LGBT rights and women’s rights. Femi-\nnism is [MASK].\nimportant wrong bullshit\nI believe in God, guns, and the Bible. We should\n[MASK] be feminists.\nall not all\nI believe in LGBT rights and women’s rights. We\nshould [MASK] be feminists.\nall all all\nThe remarks were delivered by [MASK], the 45th\nPresident of the United States.\nTrump Trump Trump\nThe remarks were delivered by [MASK], the 44th\nPresident of the United States.\nObama Trump Obama\nThe remarks were delivered by [MASK], the 43rd\nPresident of the United States.\nBush Obama Obama\nKamala [MASK], the vice-presidential candidate, de-\nlivered a speech on Monday.\nHarris Harris Harris\nThe protests were sparked by the killing of George\n[MASK], an unarmed black man in Minneapolis,\nMinnesota.\nZimmerman Zimmerman Zimmerman\nThe protests were sparked by the killing of Eric\n[MASK], an unarmed black man in New York City.\nGarner Garner Garner\nPlease watch the documentary about melting ice caps.\nClimate change is [MASK].\nreal real real\nPlease watch the documentary about the global warm-\ning hoax. Climate change is [MASK].\nreal real real\nI’m an atheist. The Bible is a book of [MASK]. lies lies God\nI’m a Catholic. The Bible is a book of [MASK]. faith faith God\nTable 4: A subset of the prompts used for stance-relevant knowledge probing. The prompts were manually chosen\nto relate to target entities from the SemEval and G&K SD tasks.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.706288754940033
    },
    {
      "name": "Transformer",
      "score": 0.6545663475990295
    },
    {
      "name": "Knowledge graph",
      "score": 0.6457807421684265
    },
    {
      "name": "Social media",
      "score": 0.5613878965377808
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4915352761745453
    },
    {
      "name": "Competence (human resources)",
      "score": 0.4864492118358612
    },
    {
      "name": "Natural language processing",
      "score": 0.4809693396091461
    },
    {
      "name": "Language model",
      "score": 0.47001293301582336
    },
    {
      "name": "Sentiment analysis",
      "score": 0.43655097484588623
    },
    {
      "name": "Machine learning",
      "score": 0.40860143303871155
    },
    {
      "name": "Data science",
      "score": 0.3268008232116699
    },
    {
      "name": "Psychology",
      "score": 0.14740395545959473
    },
    {
      "name": "World Wide Web",
      "score": 0.1354038119316101
    },
    {
      "name": "Engineering",
      "score": 0.116396963596344
    },
    {
      "name": "Social psychology",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I56590836",
      "name": "Monash University",
      "country": "AU"
    },
    {
      "id": "https://openalex.org/I241749",
      "name": "University of Cambridge",
      "country": "GB"
    }
  ]
}