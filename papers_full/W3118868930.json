{
  "title": "Transformer based Automatic COVID-19 Fake News Detection System",
  "url": "https://openalex.org/W3118868930",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4281377855",
      "name": "Gundapu, Sunil",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3161063230",
      "name": "Mamidi, Radhika",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2911109671",
    "https://openalex.org/W2124594303",
    "https://openalex.org/W2626778328",
    "https://openalex.org/W2980458196",
    "https://openalex.org/W3120176075",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3036607812",
    "https://openalex.org/W2925285378",
    "https://openalex.org/W3080590497",
    "https://openalex.org/W2996428491",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W3032089915",
    "https://openalex.org/W2944480943",
    "https://openalex.org/W2977526300",
    "https://openalex.org/W3107091374",
    "https://openalex.org/W1956559956",
    "https://openalex.org/W4205767499",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W2998619990",
    "https://openalex.org/W2909299092",
    "https://openalex.org/W3097827700",
    "https://openalex.org/W2493916176",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W3097301690",
    "https://openalex.org/W2963567867",
    "https://openalex.org/W3098835531"
  ],
  "abstract": "Recent rapid technological advancements in online social networks such as Twitter have led to a great incline in spreading false information and fake news. Misinformation is especially prevalent in the ongoing coronavirus disease (COVID-19) pandemic, leading to individuals accepting bogus and potentially deleterious claims and articles. Quick detection of fake news can reduce the spread of panic and confusion among the public. For our analysis in this paper, we report a methodology to analyze the reliability of information shared on social media pertaining to the COVID-19 pandemic. Our best approach is based on an ensemble of three transformer models (BERT, ALBERT, and XLNET) to detecting fake news. This model was trained and evaluated in the context of the ConstraintAI 2021 shared task COVID19 Fake News Detection in English. Our system obtained 0.9855 f1-score on testset and ranked 5th among 160 teams.",
  "full_text": "Transformer based Automatic COVID-19 Fake\nNews Detection System\nSunil Gundapu and Radhika Mamidi\nInternational Institute of Information Technology, Hyderabad\nsunil.g@research.iiit.ac.in, radhika.mamidi@iiit.ac.in\nAbstract. Recent rapid technological advancements in online social net-\nworks such as Twitter have led to a great incline in spreading false infor-\nmation and fake news. Misinformation is especially prevalent in the on-\ngoing coronavirus disease (COVID-19) pandemic, leading to individuals\naccepting bogus and potentially deleterious claims and articles. Quick de-\ntection of fake news can reduce the spread of panic and confusion among\nthe public. For our analysis in this paper, we report a methodology to\nanalyze the reliability of information shared on social media pertaining\nto the COVID-19 pandemic. Our best approach is based on an ensemble\nof three transformer models (BERT, ALBERT, and XLNET) to detect-\ning fake news. This model was trained and evaluated in the context of\nthe ConstraintAI 2021 shared task “COVID19 Fake News Detection in\nEnglish” [1]. Our system obtained 0.9855 f1-score on testset and ranked\n5th among 160 teams.\nKeywords: covid-19, fake news, deep learning, transformer models\n1 Introduction\nThe COVID-19 pandemic is considered the global public health crisis of the\nwhole world and the biggest problem people faced after World War II. COVID-\n19, a contagious disease caused by a coronavirus, has caused more than 75 million\nconﬁrmed cases and 1.7 million deaths across the world till 2020 December 1.\nUnfortunately, the misinformation about COVID-19 has encouraged the growing\nof the disease and chaos among people. During the Munich Security Council held\non February 15, 2020, World Health Organization (WHO) Director-General,\nTedros Adhanom Ghebreyesus [2] stated that the world was in a war to ﬁght\nnot only a pandemic, but also an infodemic. So we should address the challenge\nof fake news detection to stop the spreading of COVID-19 misinformation.\nSince the global pandemic impacts the people, there is a broader public ﬁnd-\ning information about the COVID-19, whose safety is intimidated by adversarial\nagents invested in spreading fake news for economic and political reasons. Be-\nsides, due to medical and public health issues, it is also hard to be totally valid\nand factual, leading to diﬀerences that worsen with fake news. This diﬃculty\n1 https://www.worldometers.info/coronavirus/\narXiv:2101.00180v3  [cs.CL]  21 Jan 2021\n2 Gundapu and Mamidi\nis compounded by the quick advancement of knowledge about the disease. As\nresearchers gain more knowledge about the virus, claims that looked right may\nturn out to be false, and vice versa. Detecting this spread of COVID-19 associ-\nated fake news, thus, has become a pivotal problem, gaining notable attention\nfrom government and global health organizations (WHO, 2020), online social\nnetworks (TechCrunch, 2020), and news organizations (BBC, 2020; CNN, 2020;\nNew York Times, 2020).\nIn response to the present disinformation, this paper looks at developing an\neﬃcient fake news detection architecture with respect to COVID-19. Initially,\nwe started with developing machine learning (ML) algorithms with Term Fre-\nquency and Inverse Document Frequency (TF-IDF) feature vectors to detect\nmisinformation on the provided dataset. These supervised TF-IDF methods are\nstill relevant for many classiﬁcation tasks and performed pretty well for fake\nnews detection. We developed an eﬀective ensemble model integrated with three\ntransformer models for detecting fake news on the social media platforms. This\nresulted in higher accuracy and a more generalized model.\nThe rest of this paper is organized as follows, Section II presents some prior\nworks related to fake news, and its spread, on social media platforms. In Section\nIII, we describe the dataset provided in the Constraint AI- 2021 shared task.\nSection IV presents implemented models and framework for misinformation de-\ntection. Section V provides the discussions on the results. Finally we conclude\nthis paper in Section VI.\n2 Related Work\nFake News Detection: Fake news can be deﬁned as inaccurate and mis-\nleading information that is growing knowingly or unknowingly [3]. Recognizing\nthe spread of false information such as rumors, fake news, propaganda, hoaxes,\nspear phishing, and conspiracy theories is an essential task for natural language\nprocessing [4]. Gartner’s [5] research studies explained that most people in ad-\nvanced economies would believe more fake information than truthful information\nby 2022.\nTo date, so many automated misinformation detection architectures have\nbeen developed. Rohit et al. [6] provided an extensive survey to detect fake\nnews on various online social networks. Ghorbani et al. [7] presented an inclu-\nsive overview of the recent studies related to misinformation. Furthermore, they\ndescribed the impact of misleading information, shown state-of-the-art fake news\ndetection systems, and explored the disinformation detection datasets. The ma-\njority of the fake news detection models developed using supervised machine\nlearning algorithms to classify the data as misleading or not [8]. This supervised\nclassiﬁcation is concluded by comparing the user input text with some already\ncreated corpora containing genuine and misleading information [9].\nAswini et al. [10] proposed a deep learning architecture with various word\nembeddings for Fake News Challenge (FCN-1) dataset 2. They developed the\n2 http://www.fakenewschallenge.org/\nFake News Detection 3\narchitecture to accurately predict the stance between a given pair of news head-\nlines and the corresponding article/body. On the same FCN-1 dataset, Sean\net al. [11] developed an average weighted model of TalosCNN and TalosTree\ncalled TalosComb. TalosCNN is a convolutional neural network with pre-trained\nword2vec embeddings, and TalosTree is a gradient-boosted decision tree model\nwith SVD, word count, TF-IDF. By analyzing the relationship between the news\nheadline and the corresponding article, Heejung et al. [12] designed the Bidi-\nrectional Encoder Representations from Transformers model (BERT) to detect\nmisleading news articles.\nCOVID-19: In the case of COVID-19 fake news, a large number of misleading\ncontents remain online on social media platforms. NLP researchers have been\nworking on developing algorithms for the detection of online COVID-19 related\ndisinformation. To develop any algorithm, we require a corpus. So members of\nthe NLP community created the various fake news datasets: FakeCovid [13],\nReCOVery [14], CoAID [15], and CMU-MisCOV19 [16]. Yichuan Li et al. [17]\ndeveloped multi-dimensional and multilingual MM-COVID corpora, which cov-\ners six languages. Mabrook et al. [18] created a large Twitter dataset related to\nCOVID-19 misinformation. And authors developed an ensemble-stacking model\nwith six machine learning algorithms on the created dataset for detecting mis-\ninformation.\nElhadad et al. [22] constructed a voting ensemble machine learning classiﬁer\nfor fake news detection that uses seven feature extraction techniques and ten\nmachine learning models. Tamanna et al. [20] used the COVIDLIES dataset\nto detect the misinformation by retrieving the misconceptions relevant to the\nTwitter posts. For COVID-19 fake news detection and fact-checking, Rutvik et\nal. [19] proposed a two-stage transformer model. The ﬁrst model retrieves the\nmost relevant facts about COVID-19 by using a novel fact-checking algorithm,\nand the second model, by computing the textual entailment, veriﬁes the level\nof truth. Adapting all these classical and hybrid related work techniques, we\ndeveloped a COVID-19 fake news detection system in this paper.\n3 Dataset Description\nThe ConstraintAI’213 shared task organizers developed a COVID-19 fake news\ndetection in English dataset [21] containing 10,700 data points collected from\nvarious online social networks such as Twitter, Facebook, and Instagram, etc.\nFrom the total dataset, 6,420 data points are reserved for training, 2,140 data\npoints are used for hyperparameter tuning as a part of the validation phase, and\nthe remaining 2,140 social media posts are kept aside for testing. Each dataset\nexcept the test set contains social media data points and their corresponding\nlabels, either real or fake.\n3 https://constraint-shared-task-2021.github.io/\n4 Gundapu and Mamidi\nCorpus Real Fake\nTrain 3360 3060\nValid 1120 1020\nTest 1120 1020\n(a) Dataset Statistics\nTweet Label\nCDC Recommends Mothers Stop fake\nBreastfeeding To Boost Vaccine Eﬃcacy\n1000 COVID-19 testing labs in India: ICMR real\n(b) Label-wise example\nTable 1: Fake news dataset information\nTable 1 shows the corpus size and label distribution, and if we observe, the\nlabels in each dataset are all roughly balanced. Table 2 shows some examples\nfrom the COVID-19 fake news detection in the English dataset. We illustrate the\nmost occurring word cloud of the real and fake data points after removing the\nstop words in Figures 1(a) and 1(b). In Figure 1(a), we can see unique words in\nreal-labeled data points which don’t often occur in Figure 1(b), like “covid19”,\n“discharged”, “conﬁrmed”, “testing”, “indiaﬁghtscorona”, and “indiawin”, etc.;\nmeanwhile, from Figure 1(b), we can ﬁnd unique words frequently appearing in\nthe fake articles, which include “coronavirus”, “kill”, “muslim”, “hydroxychloro-\nquine”, “china”, and “facebook post”, but don’t frequently appear in the true\nlabeled data points. These frequent textual words can give important informa-\ntion to diﬀerentiate the true data points from fake ones.\n(a) Positive word cloud\n (b) Negative word cloud\nFig. 1: Illustration of frequent word cloud\n4 Methodology\nIn this part, we present our transformer based ensemble model that is trained and\ntuned on the datasets which reported in the previous section. We compare our\nFake News Detection 5\napproach with various machine learning (ML) and deep learning (DL) models\nwith diﬀerent word embeddings. The full code of system architecture can be\nfound at GitHub4.\n4.1 Data Preprocessing\nThe main aim of this part is to use the NLP techniques to preprocess the input\ntweet data and prepare for the next step to extract the proper features. In Figure\n2, we shown the detailed data preprocessing pipeline with examples.\nFig. 2: Data preprocessing pipeline\nIn the preprocessing step, we will forward the tokenized tweet through the\npipeline to eliminate the noise in the fake news dataset by remove or normilize\nthe unnecessary tokens. The preprocessing pipeline includes the following sub-\nparts:\n1. Emoticon Conversion: In this step, we converted the each emoticon in\nthe tweet to text. Example:\n →Face with medical mask emoji\n2. Handling of Hashtags:We identiﬁed the hashtag tokens by seeing pound\n(#) sign and splitted these based on digits or capital letters. Example:\n#IndiaFightsCorona →IndiaFightsCorona\n3. Stemming: We removed the inﬂectional morphemes like “ed”, “est”, “s”,\nand “ing” from their token stem. Ex: confirmed →“confirm” + “−ed”\n4. Text cleaning:To remove the irrelevent data we used this step. Removed\npunctuation marks, digits and, non-ASCII glyphs from the tweet.\n4.2 Supervised Machine Learning Models\nTo build the ﬁnest system for fake news detection, we started our investiga-\ntions with traditional NLP approaches like Linear Regression (LR), Support\nVector MAchines (SVM), Passive Agressive Classiﬁer (PAC), XGBoost, and\nMulti-Layer Perceptron (MLP). We study the results of above mentioned su-\npervised models with the combination of three types of word vectors:\n4 https://github.com/SunilGundapu/Covid-19-fake-news-detection\n6 Gundapu and Mamidi\n1. Word-level, n-gram level, and character level TF-IDF vectors with the feature\nmatrix size of 100000.\n2. English Glove [23] word embeddings with the dimension of 300.\n3. TF-IDF weighted averaging with Glove embeddings. We described below the\nfake news vector construction.\nTweet vector =\nN∑\ni=1\ntf-idf(tokeni) ×Glove(tokeni)\nN (1)\nIn the above formula, N is the total number of words in the input fake news\ntweet, and tokeni is the ith token in the input text. After analyzing the results,\nTF-IDF weighted averaging gave better results than the standard TF-IDF.\n4.3 Deep Learning Models\nSupervised machine learning algorithms performed very well on the provided\ndataset. In this section, we experiment with deep learning models that give\nbetter results than traditional classiﬁcation algorithms.\nLSTM: We used Long Short-Term Memory (LSTM) [24] architecture with two\ndiﬀerent pre-trained word embeddings Glove and Fasttext [25]. LSTM is a type of\nRecurrent Neural Network (RNN) that can solve long term dependency problem,\nand it is a well-suited model for sequence classiﬁcation.\nWe converted the input data points into word vectors by using pre-trained\nword embeddings. These word vectors are passed as input to the LSTM layer.\nWe stacked up two LSTM layers one after another with the dropout of 0.25. The\nsize of LSTM is 128, and the last time step output is treated as input data point\nrepresentation. The ﬁnal time step’s outcome is passed as an input to a dense\nlayer for fake news detection.\nBiLSTM with Attention: Sometimes not all the tokens in the input text\ncontribute equally to the representation of input text. So we advantage word\nattention [26] mechanism to catch the tokens’ prominent inﬂuence on the input\ndata point. We built this attention mechanism on top of BiLSTM layers.\nThe sequence of word vector is passed through a BiLSTM layer, which con-\ntains one forward and backward LSTM layer. Attention mechanism applied to\nthe output of BiLSTM layer, which produces a dense vector. This dense vector\nis forwarded to a fully connected network.\nCNN: We explored a Convolution Neural Network (CNN) [27] model for mis-\ninformation detection. The model consists of an embedding layer, a convolution\nlayer with 3 convolutions, a max-pooling layer, and a fully connected network.\nIn the embedding layer, the input texts are converted inton×d sequence matrix,\nFake News Detection 7\nwhere n is the length of the input data point and d is the length of the word\nembedding dimension. In the convolution layer, fed the sequence matrix through\nthree 1D convolutions of kernel sizes 3, 4, and 5. And each convolutions ﬁlter size\nis 128. The convolution layer’s output is max pooled over time and concatenated\nto get the input datapoint representations in the max-pooling layer. The output\nof the max-pooling layer is passed to a fully connected network with a softmax\noutput layer.\nCNN + BiLSTM:A CNN and BiLSTM architecture is an ensemble of CNN\nand bidirectional LSTM models with Fasttext/Glove word embeddings. In this\narchitecture, the CNN extracts the maximum amount of features/information\nfrom the input text using convolution layers. The output of CNN becomes the\ninput to BiLSTM, which keeps the data in chronological order in both directions.\nThe sequence of word vectors are forwarded through a convolution of kernel\nsize 3 with ﬁlter size 128. The output of convolution is passed through a BiLSTM.\nThe outcome of BiLSTM is max-pooled over time and followed by one dense layer\nand a softmax layer.\n4.4 Transformer Models\nThis section explored individual and ensembling of the three transformer mod-\nels BERT, ALBERT, and XLNet. These models have outperformed the other\nML and DL algorithms. We implemented these models using HuggingFace 5 is a\nPyTorch transformer library. And the hyperparameters of the three models are\ndescribed in Table 1.\nModel Learning RateBatch SizeOptimizer Max Length Type\nBERT 2e-5 16 Adam 128 BERT-Base\nXLNet 2e-5 16 Adam 128 XLNetLarge\nALBERT 2e-5 32 Adam 128 ALBERT-Xlarge\nTable 2: Hyperparameters of transformer models\nBERT: Bidirectional Encoder Representations from Transformers (henceforth,\nBERT) [28] is a transformer model developed to pre-train deep bidirectional\nrepresentations from unseen data. This model developed by combining two ro-\nbust concepts: (i) It’s a deep transformer model so that it can process lengthy\nsentences eﬀectively by using attention mechanism, and (ii) It’s a bidirectional\n5 https://huggingface.co/transformers/\n8 Gundapu and Mamidi\nnetwork, so it takes into account the entire text passage to comprehend the\nmeaning of each token.\nBERT implementation has two steps; one is pre-training and another ﬁne-\ntuning. In the ﬁrst step, the model is trained on unseen data over various pre-\ntraining problems using a dataset in a particular language or in increases data\nwith multiple languages. In the second step, all the initialized parameters are\nﬁne-tuned using the labeled data from certain tasks.\nWe ﬁne-tuned the pre-trained BERT (Base) model for our COVID-19 fake\nnews detection task. BERT base model contains the 12 layers of encoder blocks\nand 12 bidirectional self-attention heads by considering the sequence of 512 to-\nkens and emitting the representations of a sequence of hidden vectors. We added\none additional output layer on top of the BERT model to calculate the condi-\ntional probability over the output classes, either fake or real. See FIGURE 1 for\nthe ﬁne-tuned model of BERT.\nFig. 3: BERT model architecture\nXLNet: XLNet is an enhanced version of BERT. To understand the language\ncontext deeper, XLNet [29] uses Transformer-XL [30] as a feature engineering\nmodel, which alone is an adoption upon the native Transformer. This Trans-\nformer XL model integrates the two components Recurrence Mechanism and\nRelative Positional Encoding(RPE) to the Transformer used in BERT to handle\nthe long-term dependencies for texts that are longer than the maximum allowed\ninput length. Recurrence Mechanism will give context between two sequences\nat speciﬁc segments and RPE, which carries similarity information between two\ntokens.\nFake News Detection 9\nThe XLNet model has been trained on a huge dataset using the permutation\nlanguage modeling. This technique is one of the main diﬀerences between BERT\nand XLNet, and it uses permutations to generate data from the forward and\nbackward directions at the same time. We used the pre-trained XLNet model\nfrom Hugging Face, then ﬁne-tuned the model with a maximum length of 128\nto update the pre-trained model to ﬁt our fake news detection dataset.\nALBERT: Modern language models increasing the model size and quantity of\nparameters when pre-training natural language representations. They often give\nbetter improvements in many downstream tasks, but in some cases, they become\nharder due to memory limitation and longer hours of training. To address these\nproblems, a self-supervised learning model ALBERT (A Lite BERT) [31] often\nuses parameter reduction techniques to increase model speed and lower memory\nconsumption. We used the A Lite BERT model for our misinformation detection\nproblem, which achieves better performance than DL models.\nEnsemble Model: We ensembeled the three transformer models BERT, AL-\nBERT, and XLNet for better prediction. See Figure 4 for the ensemble model.\nOur ensemble model computes an average of all softmax values from these three\ntransformer models after extracting the softmax probabilities from each model.\nThis model relatively better than other models.\nFig. 4: Transformer based ensemble model architecture\n5 Results and Discussion\nIn this section, we compared the performance of various machine learning, deep\nlearning, and transformer-based models using several evaluation metrics like pre-\ncision, recall, weighted f1-score and accuracy. The results of the various experi-\nments on the test set are reported in Table 3. The results clearly showing that\nTransformer based models are considerably better than other machine and deep\nlearning models for our COVID-19 misinformation detection task. And while\n10 Gundapu and Mamidi\nModel Type Model Precision Recall Accuracy F1-Score\nSVM 0.9640 0.9640 0.964013 0.964037\nML PAC 0.9673 0.9673 0.967285 0.967289\nModels MLP 0.9645 0.9645 0.964494 0.964485\nLSTM with FastText 0.9682 0.9682 0.9682203 0.968224\nDeep Learning CNN with FastText 0.9698 0.9698 0.969802 0.969819\nModels LSTM + CNN 0.9762 0.9762 0.976163 0.976168\nBiLSTM + Attention 0.9790 0.9785 0.978524 0.978504\nBERT 0.9813 0.9813 0.981306 0.981308\nTransformer ALBERT 0.9781 0.9781 0.978031 0.978037\nModels XLNet 0.9787 0.9789 0.978596 0.978592\nEnsemble Model 0.9855 0.9855 0.985512 0.985514\nTable 3: Comparision of various fake news detection models on testset\ndoing experiments, we observed that few models good at retrieving prominent\nfeatures while other models have the best classiﬁcation performance.\nClassical machine learning models with various TF-IDF feature vectors gave\nthe approximate baseline model results. We observe that the TF-IDF weighted\naverage performed better than the normal TF-IDF vectors. Bi-directional LSTM\nwith attention mechanism f1-score approximate very close to transformer models.\nThe BERT, XLNet, and ALBERT demonstrate better performance than deep\nlearning models. An ensemble of the transformer-based model produces the best\nF1 score of 0.9855 on the test set. Our transformer based model ranked 5th\namong 160 teams.\nTest Sample BERT ALBERT XLNet Ensemble\n#BillGates is shocked that America’s pandemic \u0013 \u0017 \u0017 \u0013\nresponse is among the worst in the world.\nWe will all come out stronger from this \u0017 \u0017 \u0013 \u0013\n#COVID #pandemic. Just #StaySafeStayHealthy\nTable 4: Misclassiﬁed samples from testset\nIn some problems, enesembling of four transformer models is very diﬃcult,\nand sometimes this approach will not perform well. But if we observe the results\nof individual transformer models on our dataset are very close, meaning that\nany transformer model can be used for our fake news detection task. This is the\nmajor reason behind the ensembling of transformer models.\nIn Table 4, we showed the two misclassiﬁed test samples. The ﬁrst test sam-\nple actual label is “real”, but only BERT and ensemble models are predicted\ncorrectly remaining two models wrongly predicted. And the second sample true\nlabel is “fake”, but XLNet and ensemble predicted correctly remaining two mod-\nFake News Detection 11\nels wrongly predicted. However, the ensemble model is correctly predicted in\nboth cases because we are averaging the BERT, ALBERT, and XLNet softmax\nprobabilities. This is a principal observation to ensemble the transformer models.\n6 Conclusion\nIn this paper, we presented various algorithms to combat the global infodemic,\nbut transformer-based algorithms performed better than others. And we sub-\nmitted these models to the Shared Task of COVID-19 fake news detection for\nEnglish, ConstraintAI-2021 workshop.\nFake news is a progressively signiﬁcant and tricky problem to solve, partic-\nularly in an unanticipated situation like the COVID-19 epidemic. Leveraging\nstate-of-the-art classical and advanced NLP models can help address the prob-\nlem of COVID-19 fake news detection and other global health emergencies. We\nintend to explore other contextualized embeddings like FLAIR, ELMo, etc., for\na better fake news detecting system in future works.\nReferences\n1. Patwa, P., Bhardwaj, M., Guptha, V., Kumari, G., Sharma, S., PYKL, S., Das,\nA., Ekbal A., Akhtar, S., Chakraborty.: Overview of CONSTRAINT 2021 Shared\nTasks: Detecting English COVID-19 Fake News and Hindi Hostile Posts. (2021). In:\nProceedings of the First Workshop on Combating Online Hostile Posts in Regional\nLanguages during Emergency Situation (CONSTRAINT). Springer.\n2. Datta, R., Yadav, K., Singh, A., Datta, K., Bansal, A.: The infodemics of COVID-\n19 amongst healthcare professionals in india. Med. J. Armed Forces India, vol. 76,\nno. 3, pp. 276–283, Jul. 2020.\n3. Chen, X., Sin, S.J.: ’Misinformation? What of it?’ Motivations and individual dif-\nferences in misinformation sharing on social media. In: ASIST (2013)\n4. Thorne, J., Vlachos, A.: Automated Fact Checking: Task formulations, methods\nand future directions. In: COLING (2018)\n5. Titcomb, J., Carson, J.: www.telegraph.co.uk. Fake news: What exactly is it – and\nhow can you spot it?\n6. Kaliyar, R., Singh, N.: Misinformation Detection on Online Social Media-A Survey.\n(2019). 1-6. 10.1109/ICCCNT45670.2019.8944587.\n7. Zhang, X., Ghorbani, A.: An overview of online fake news: Characterization, de-\ntection, and discussion. (2020). Inf. Process. Manag., 57, 102025.\n8. Khan, J.Y., Khondaker, M.T., Iqbal, A., Afroz, S.: A Benchmark Study on Machine\nLearning Methods for Fake News Detection. (2019). ArXiv, abs/1905.04749.\n9. Elhadad, M., Li, K.F., Gebali, F.: A Novel Approach for Selecting Hybrid Features\nfrom Online News Textual Metadata for Fake News Detection. In: Proc. 3PGCIC,\nAntwerp, Belgium, 2019, pp. 914–925.\n10. Thota, A., Tilak, P., Ahluwalia, S., Lohia, N.: Fake News Detection: A Deep Learn-\ning Approach. (2018). SMU Data Science Review: Vol. 1 : No. 3 , Article 10.\n11. Sean, B., Doug, S., Yuxi, P: Talos Targets Disinformation\nwith Fake News Challenge Victory. (2017). Available online:\nhttps://blog.talosintelligence.com/2017/06/talos-fake-news-challenge.html\n12 Gundapu and Mamidi\n12. Jwa, H., Oh, D., Park, K., Kang, J., Lim, H.: exBAKE: Automatic Fake News De-\ntection Model Based on Bidirectional Encoder Representations from Transformers\n(BERT). (2019). Applied Sciences, 9, 4062.\n13. Shahi, G.K., Nandini, D.: FakeCovid - A Multilingual Cross-domain Fact Check\nNews Dataset for COVID-19. (2020). ArXiv, abs/2006.11343.\n14. Zhou, X., Mulay, A., Ferrara, E., Zafarani, R.: ReCOVery: A Multimodal Reposi-\ntory for COVID-19 News Credibility Research. (2020). In: Proceedings of the 29th\nACM International Conference on Information & Knowledge Management.\n15. Cui, L., Lee, D.: CoAID: COVID-19 Healthcare Misinformation Dataset. (2020).\nArXiv, abs/2006.00885.\n16. Memon, S.A., Carley, K.M.: Characterizing COVID-19 Misinformation Communi-\nties Using a Novel Twitter Dataset. (2020). ArXiv, abs/2008.00791.\n17. Li, Y., Jiang, B., Shu, K., Liu, H.: MM-COVID: A Multilingual and Multi-\nmodal Data Repository for Combating COVID-19 Disinformation. (2020). ArXiv,\nabs/2011.04088.\n18. Al-Rakhami, M.S., Al-Amri, A.M.: Lies Kill, Facts Save: Detecting COVID-19\nMisinformation in Twitter. (2020). IEEE Access, 8, 155961-155970.\n19. Vijjali, R., Potluri, P., Kumar, S., Teki, S.: Two Stage Transformer Model for\nCOVID-19 Fake News Detection and Fact Checking. (2020).\n20. Hossain, T., RobertL.Logan, I., Ugarte, A., Matsubara, Y., Young, S.,Singh,\nS.: COVIDLies: Detecting COVID-19 Misinformation on Social Media. (2020).\nNLP4COVID@EMNLP.\n21. Patwa, P., Sharma, S., Pykl, S., Guptha, V., Kumari, G., Akhtar, M.S., Ekbal, A.,\nDas, A., Chakraborty, T. (2020). Fighting an Infodemic: COVID-19 Fake News\nDataset. ArXiv, abs/2011.03327.\n22. Elhadad, M.K., Li, K., Gebali, F.: Detecting Misleading Information on COVID-19.\n(2020). IEEE Access, 8, 165201-165215.\n23. Pennington, J., Socher, R., Manning, C.D.: Glove: Global Vectors for Word Rep-\nresentation. (2014). In: EMNLP.\n24. Hochreiter, S., Schmidhuber, J.: Long Short-Term Memory. (1997). Neural Com-\nputation, 9, 1735-1780.\n25. Bojanowski, P., Grave, E., Joulin, A., Mikolov, T.: Enriching Word Vectors with\nSubword Information. (2017). Transactions of the Association for Computational\nLinguistics, 5, 135-146.\n26. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser,\nL., Polosukhin, I.: Attention is All you Need. (2017). NIPS.\n27. LeCun, Y., Bengio, Y., Hinton, G.: Deep learning. (2015). Nature, 521(7553),\npp.436-444.\n28. Devlin, J., Chang, M., Lee, K., Toutanova, K.: BERT: Pre-training of Deep Bidi-\nrectional Transformers for Language Understanding. (2019). NAACL-HLT.\n29. Yang, Z., Dai, Z., Yang, Y., Carbonell, J., Salakhutdinov, R., Le, Q.V.: XL-\nNet: Generalized Autoregressive Pretraining for Language Understanding. (2019).\nNeurIPS.\n30. Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q.V., Salakhutdinov, R.:\nTransformer-XL: Attentive Language Models Beyond a Fixed-Length Context.\n(2019). ACL.\n31. Lan, Z., Chen, M., Goodman, S., Gimpel, K., Sharma, P., Soricut, R.: ALBERT:\nA Lite BERT for Self-supervised Learning of Language Representations. (2020).\nArXiv, abs/1909.11942.",
  "topic": "Misinformation",
  "concepts": [
    {
      "name": "Misinformation",
      "score": 0.9013357162475586
    },
    {
      "name": "Social media",
      "score": 0.6689925789833069
    },
    {
      "name": "Coronavirus disease 2019 (COVID-19)",
      "score": 0.6222356557846069
    },
    {
      "name": "Internet privacy",
      "score": 0.561604380607605
    },
    {
      "name": "Computer science",
      "score": 0.5585407614707947
    },
    {
      "name": "Pandemic",
      "score": 0.5256444215774536
    },
    {
      "name": "Fake news",
      "score": 0.49348676204681396
    },
    {
      "name": "Context (archaeology)",
      "score": 0.44934120774269104
    },
    {
      "name": "Confusion",
      "score": 0.4250931143760681
    },
    {
      "name": "Transformer",
      "score": 0.4188280701637268
    },
    {
      "name": "Computer security",
      "score": 0.3282244801521301
    },
    {
      "name": "Psychology",
      "score": 0.1952137053012848
    },
    {
      "name": "World Wide Web",
      "score": 0.1939188539981842
    },
    {
      "name": "Infectious disease (medical specialty)",
      "score": 0.1836492121219635
    },
    {
      "name": "Engineering",
      "score": 0.12213125824928284
    },
    {
      "name": "History",
      "score": 0.11694890260696411
    },
    {
      "name": "Medicine",
      "score": 0.09701469540596008
    },
    {
      "name": "Disease",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Psychoanalysis",
      "score": 0.0
    },
    {
      "name": "Pathology",
      "score": 0.0
    }
  ]
}