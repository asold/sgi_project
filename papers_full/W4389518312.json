{
  "title": "AlGhafa Evaluation Benchmark for Arabic Language Models",
  "url": "https://openalex.org/W4389518312",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2226134900",
      "name": "Ebtesam Almazrouei",
      "affiliations": [
        "Technology Innovation Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2225593095",
      "name": "Ruxandra Cojocaru",
      "affiliations": [
        "Technology Innovation Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2214869861",
      "name": "Michele Baldo",
      "affiliations": [
        "Technology Innovation Institute"
      ]
    },
    {
      "id": "https://openalex.org/A3033313434",
      "name": "Quentin Malartic",
      "affiliations": [
        "Technology Innovation Institute"
      ]
    },
    {
      "id": "https://openalex.org/A5092093417",
      "name": "Hamza Alobeidli",
      "affiliations": [
        "Technology Innovation Institute"
      ]
    },
    {
      "id": "https://openalex.org/A5093382151",
      "name": "Daniele Mazzotta",
      "affiliations": [
        "Technology Innovation Institute"
      ]
    },
    {
      "id": "https://openalex.org/A4287929330",
      "name": "Guilherme Penedo",
      "affiliations": [
        "Technology Innovation Institute"
      ]
    },
    {
      "id": "https://openalex.org/A5093457029",
      "name": "Giulia Campesan",
      "affiliations": [
        "Technology Innovation Institute"
      ]
    },
    {
      "id": "https://openalex.org/A5102513296",
      "name": "Mugariya Farooq",
      "affiliations": [
        "Technology Innovation Institute"
      ]
    },
    {
      "id": "https://openalex.org/A4313776441",
      "name": "Maitha Alhammadi",
      "affiliations": [
        "Technology Innovation Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2403313545",
      "name": "Julien Launay",
      "affiliations": [
        "Technology Innovation Institute"
      ]
    },
    {
      "id": "https://openalex.org/A3113154218",
      "name": "Badreddine Noune",
      "affiliations": [
        "Technology Innovation Institute"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4281758439",
    "https://openalex.org/W3210486066",
    "https://openalex.org/W2158874082",
    "https://openalex.org/W4385571124",
    "https://openalex.org/W4223891676",
    "https://openalex.org/W4297663785",
    "https://openalex.org/W4389519614",
    "https://openalex.org/W3034469191",
    "https://openalex.org/W1614298861",
    "https://openalex.org/W2901236145",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4283026156",
    "https://openalex.org/W2972463128",
    "https://openalex.org/W3014635508",
    "https://openalex.org/W3173465197",
    "https://openalex.org/W4297672137",
    "https://openalex.org/W4297801177",
    "https://openalex.org/W3177765786",
    "https://openalex.org/W2971150411",
    "https://openalex.org/W4380874786",
    "https://openalex.org/W2770803436",
    "https://openalex.org/W4285240123",
    "https://openalex.org/W3155561744",
    "https://openalex.org/W3153642904",
    "https://openalex.org/W4393722339",
    "https://openalex.org/W3105771185",
    "https://openalex.org/W4385570293",
    "https://openalex.org/W3035296331",
    "https://openalex.org/W3001279689",
    "https://openalex.org/W2898401058",
    "https://openalex.org/W4378505278",
    "https://openalex.org/W2970960342",
    "https://openalex.org/W3118781290",
    "https://openalex.org/W4385572802",
    "https://openalex.org/W3154956759",
    "https://openalex.org/W4281481109",
    "https://openalex.org/W3115903740",
    "https://openalex.org/W4379468930",
    "https://openalex.org/W2962990575"
  ],
  "abstract": "Ebtesam Almazrouei, Ruxandra Cojocaru, Michele Baldo, Quentin Malartic, Hamza Alobeidli, Daniele Mazzotta, Guilherme Penedo, Giulia Campesan, Mugariya Farooq, Maitha Alhammadi, Julien Launay, Badreddine Noune. Proceedings of ArabicNLP 2023. 2023.",
  "full_text": "Proceedings of the The First Arabic Natural Language Processing Conference (ArabicNLP 2023), pages 244–275\nDecember 7, 2023 ©2023 Association for Computational Linguistics\nAlGhafa Evaluation Benchmark for Arabic Language Models\nEbtesam Almazrouei and Ruxandra Cojocaru† and Michele Baldo\nQuentin Malartic and Hamza Alobeidli and Daniele Mazzotta\nGuilherme Penedo and Giulia Campesan and Mugariya Farooq\nMaitha Alhammadi and Julien Launay and Badreddine Noune\nTechnology Innovation Institute, Abu Dhabi, UAE\n† ruxandra.cojocaru@tii.ae\nAbstract\nRecent advances in the space of Arabic large\nlanguage models have opened up a wealth of\npotential practical applications. From optimal\ntraining strategies, large scale data acquisition\nand continuously increasing NLP resources, the\nArabic LLM landscape has improved in a very\nshort span of time, despite being plagued by\ntraining data scarcity and limited evaluation\nresources compared to English. In line with\ncontributing towards this ever-growing field,\nwe introduce AlGhafa, a new multiple-choice\nevaluation benchmark for Arabic LLMs. For\nshowcasing purposes, we train a new suite of\nmodels, including a 14 billion parameter model,\nthe largest monolingual Arabic decoder-only\nmodel to date. We use a collection of pub-\nlicly available datasets, as well as a newly intro-\nduced HandMade dataset consisting of 8 billion\ntokens. Finally, we explore the quantitative and\nqualitative toxicity of several Arabic models,\ncomparing our models to existing public Arabic\nLLMs.\n1 Introduction\nRecent advances in the field of AI, and particu-\nlarly the development of large language models\n(LLMs), have been driven by a convergence of fac-\ntors including the availability of large amounts of\nunlabelled textual data (Suá rez et al., 2020; Raffel\net al., 2020), advancements in hardware (Hooker,\n2020), software (Narayanan et al., 2021), compute\ninfrastructure (Jouppi et al., 2023), as well as algo-\nrithmic innovations (Vaswani et al., 2023). Without\ndoubt, all these factors combined have accelerated\nthe progress and capabilities of AI, leading to the\nemergence of large language models (Brown et al.,\n2020). At its root, one can find efforts to teach\ncomputers to understand and generate impressively\nhuman-like text. These efforts began with relatively\nsimple statistical models (Mikolov et al., 2013) and\nrule-based systems, but in recent years, the field has\nbeen revolutionized by the advent of deep learning\nand the availability of large-scale computational\nresources and data (Sevilla et al., 2022).\nThe inaugural iteration of Generative Pretrained\nTransformer (GPT) (Radford et al., 2018) demon-\nstrated the efficacy of causal language modelling\nas a pre-training objective, where the model is\ntrained, auto-regressively, to learn the probability\nof a word given previous context, substantively\nenhancing the model’s ability for generalization.\nSubsequently, GPT-2 (Radford et al., 2019) pro-\nvided empirical evidence that augmenting both the\nsize of the model and the volume of the training\ndataset enables surpassing previously established\nbenchmarks in numerous tasks within a zero-shot\nframework. This framework enables the model\nto successfully solve tasks without explicit train-\ning, simply from in-context instructions and ex-\namples. The strategy of scaling GPT models was\ntaken to its zenith with the introduction of GPT-3\n(Brown et al., 2020), a model comprising an unpar-\nalleled 175-billion parameters. Training on textual\ndata consisting of hundreds of billions of words\nsourced from the internet enabled larger model\nsizes, which in turn showed increased abilities for\nfew-shot learning. This unlocked novel capabilities\nduring model evaluation and demonstrated their\npotential for practical applications. In recent years,\na series of Large Language Models (LLMs) have\nbeen introduced: Gopher (Rae et al., 2021), PaLM\n(Chowdhery et al., 2022), Llama2 (Touvron et al.,\n2023), with the largest dense language models now\nhaving over 500 billion parameters. These large\nauto-regressive transformers have demonstrated im-\npressive performance on many tasks using a variety\nof evaluation protocols such as zero-shot, few-shot,\nand to some extent fine-tuning.\nFurther research revealed that larger models sys-\ntematically deliver better language modelling per-\nformance (Kaplan et al., 2020), retaining more com-\nplex relationships and more subtleties of the lan-\nguage. Larger models were shown to also capture\n244\nmore contextual information than smaller models,\ndemonstrating improved emergent downstream ca-\npabilities (Wei et al., 2022). However, given the\nsubstantial increase in compute needs and the po-\ntential energy cost considerations associated with\nthe training of such large language models (Lakim\net al., 2022), several works have gone into discov-\nering the optimal allocation between the number\nof model parameters and data samples used. This\nhas led to the formalism of power law scaling rela-\ntionships between the number of model parameters\nand training tokens, given a computational budget\n(Kaplan et al., 2020). Recent results regarding the\nscaling of these model (Hoffmann et al., 2022) have\nconfirmed that model performance is linked with\nthe availability of large, high-quality (Gao et al.,\n2020; Penedo et al., 2023), and diverse datasets.\nNevertheless, in the global linguistic landscape,\nmuch of the advancements in large language mod-\nels over the recent years predominantly cater to\nhigh-resource languages, denoting those languages\nthat enjoy substantial amounts of digitally avail-\nable training data. Here English stands at a priv-\nilege, still covering ∼ 46% of recent Common-\nCrawl dumps, followed at 4 −6% each by German,\nRussian, French, Japanese, Spanish, and Chinese\n1. These languages stand to profit massively from\nthe progression of language models in contrast to a\nsignificant proportion of languages, often charac-\nterized by their lower resources, and which attract\nless attention, despite their cumulative prevalence2.\nHere, Arabic represents a case of particular note, as\nit is the native tongue of 360 million people (includ-\ning dialects) and the official language of 27 states\nand territories, but its overall presence on Common-\nCrawl for example is ∼ 0.5% (∼ 0.66% in recent\ndumps ). This in part may be due to a possible bias\nin the crawling algorithms, but it also stems from\nthe fact that not all societies interact with the inter-\nnet in the same way, thus different public content\nthat can then be harvested as datasets.\nThe main contributions of the present work are:\n• we present AlGhafa3, a multiple-choice zero-\nand few-shot evaluation benchmark based on\n1https://commoncrawl.github.io/\ncc-crawl-statistics/plots/languages\n2English, the preferred language of 25.9 per-\ncent of internet users https://www.verbolabs.com/\ninternet-users-by-languages-worldwide/ , is dispro-\nportionately represented, accounting for 63.7 percent of all\ntext content.\n3https://gitlab.com/tiiuae/alghafa\neleven existing datasets, that we curate and\nmodify; we evaluate our own models against\nthis benchmark and also other publicly avail-\nable Arabic LLMs; we plan to publicly release\nthe benchmark to aid the community in build-\ning more tools for evaluating Arabic LLMs.\n• for the purpose of this academic study, we\ntrain a new family of decoder-only Arabic\nmonolingual LLMs, with model sizes of 1B,\n3B, 7B and 14B parameters; our 14B model\nis to our knowledge the largest monolingual\ndecoder-only Arabic model, trained on 248\nGT (billion tokens) in total, using 4 epochs\nof 64.5 GT to match the optimality threshold\nprediction according to the Hoffmann et al.\n(2022) scaling law.\n• we perform a qualitative and quantitative tox-\nicity evaluation of our Arabic models, con-\ntrasted with other existing models following a\nconsistent methodology.\n• finally, we present our HandMade dataset,\ncontaining 8 GT (after extraction, cleaning\nand deduplication) of high-quality new Ara-\nbic content crawled from the internet.\n2 Related work\nIn the past three years, several Arabic generative\nlanguage models have been published (with a few\nbeing publicly available), exploring different archi-\ntectures (BERT, GPT and T5-based) and increasing\nmodel sizes, while facing limitations in training\ndata and evaluation resources.\nAraGPT2 (Antoun et al., 2021) was the first ded-\nicated Arabic generative language model to be de-\nveloped where the training corpus included Arabic\ndata from internet and news articles. The largest\nmodel in this family, AraGPT2-MEGA, with 1.46B\nparameters on a GROVER architecture (modified\nlayer normalization order in the transformer with\nrespect to GPT2), was shown to be able to produce\nhigh quality Arabic output in both generation and\nquestion-answering tasks.\nA larger GPT-based Arabic model, was intro-\nduced by (Lakim et al., 2022). The Noor project\ncomprises of a family of Arabic multi-billion pa-\nrameter models, with the Noor-10B being made\navailable via API. However, their work mostly fo-\ncused on the evaluation of the carbon footprint of\nbuilding and training the model.\nNagoudi et al. (2022) introduced a range of GPT\nmodels (300M to 13B parameters), trained on 400\n245\nGB of text, with the largest model (Jasmine-13B)\nstill in training at the time of publication. The\nauthors focused on the few-shot learning of these\nmodels and presented an extensive model evalu-\nation on a range of tasks including NLU tasks,\nlanguage modeling, word manipulation, common-\nsense inference and autocompletion. Furthermore,\nthey evaluated their models on various societal bi-\nases including gender, stereotypical, religion and\ncolor bias.\nIn line with evaluating the capabilities of Arabic\nLLM, Sengupta et al. (2023) recently released Jais\nand Jais-chat. Jais is a 13B parameter pretrained\nmodel while Jais-chat represents the instruction-\ntuned version of their foundation model. To train\nthe model, the authors did not utilize only Arabic\ndata but instead used a mixture of Arabic, English\nand Code in the ratio 1:2:0.4. Specifically, the\nmodel was trained on 395 billion tokens which\nincluded: 72 GT of Arabic data (of which 18 GT\nwere machine translated from English) that were\nrepeated 1.6 times to obtain 116 GT of Arabic data\nat the end, plus 232 GT of English tokens and a\nremaining 47 GT of code. The results from the\npaper suggest that bilingual data mixture can result\nin better overall performance metrics. For Jais-chat,\nthe authors used a mixture of prompt-response pairs\n(4 million in Arabic and 6 million in English).\nIn the space of BERT-based models, Ghaddar\net al. (2021) posit that existing Arabic models\nare largely under-trained which affects their per-\nformance significantly. They propose the JABER\n(135M) and SABER (369M) BERT-style models,\nshowing increased performance over a variety of\nNatural Language Understanding (NLU) tasks. In\naddition to this, the authors highlight the usage\nof improved filtering process for the training data\nwhich reduces the size of training corpus but pro-\nduces better results.\nFollowing this strategy, Alghamdi et al. (2023)\npropose a T5 model (AraMUS) with 11B parame-\nters while maintaining the high-quality standard of\nthe Arabic training data used. The authors claim\nthat AraMUS is the first multi-billion parameter\nT5 Arabic model which has been thoroughly evalu-\nated on a diverse set of NLU tasks and compared\nagainst the existing SOTA models. Its performance,\nevaluated on the ALUE benchmark (Seelawi et al.,\n2021) present state-of-the-art results among BERT\nand T5 models.\nParallely, Nagoudi et al. (2021) introduced\nAraT5 for transfer learning in Arabic and pre-\ntrained three models, one trained on Modern Stan-\ndard Arabic (MSA), another one on Twitter data\nand last on both MSA and Twitter. They also intro-\nduced a new benchmark called ARGEN to evaluate\nArabic language generation. AraT5 models per-\nformed well on the benchmark and outperformed\nmT5 in terms of Text Summarization, Question An-\nswering, Machine Translation, Paraphrasing and\nother Arabic NLU tasks.\n3 Data\n3.1 Data sources\nOur pretraining data sources can be divided in\nweb data and curated data sources. In terms\nof web data, we first leverage CommonCrawl\n(commoncrawl.org), which is a freely and pub-\nlicly available internet scraping archive that has\nbeen collecting data since 2008. We process 94\nCommonCrawl dumps, up to March/April 2023,\nextracting Arabic content (see Section 3.2). We\nalso include data from ArabicWeb16 (Suwaileh\net al., 2016), a dedicated public web crawl based\non 150 million URLs with high Arabic coverage.\nFinally, we present our own HandMade crawled\ndataset (see Appendix A), obtained by scraping 36\nmillion unique URLs. We note here the importance\nof new large scale Arabic datasets, both due to the\ngeneral data scarcity in Arabic and the possibil-\nity that CommonCrawl’s targeting algorithm may\nnot be optimum for leveraging Arabic language\nwebsites.\nIn terms of curated data, we focused on four\nmain categories: wikipedia, news, books and con-\nversations. Our wikipedia dataset covers the MSA\nversion (main articles, wikisource and wiktionary)\nbut also the Egyptian and Moroccan versions (main\narticles). For news, we collate 4 existing datasets:\nAbu El Khair (El-khair, 2016), Arabic-News (Saad,\n2019), SaudiNewsNet (Alhagri, 2015), and Ulti-\nmateArabicNews (Al-Dulaimi, 2022). Finally, for\nbooks, we leverage the Open Islamicate Texts Ini-\ntiative (OpenITI) (Nigst et al., 2023) corpus con-\nsisting of pre-modern Islamicate texts.\n3.2 Data processing\nFor large-scale data processing, we use the data pro-\ncessing pipeline inspired by Penedo et al. (2023),\nwith some modifications in the processing order\nand adapting filtering to Arabic content.\nOne relevant choice in our data processing\n246\npipeline for CommonCrawl samples is that we fol-\nlow the strategy of Gao et al. (2020), applying py-\ncld2 instead of fasttext for language identification\nas it is designed to work at HTML level, which\nallows for a significant saving in downstream text\nprocessing. We then continue with text extraction\nfrom samples identified as Arabic using the trafi-\nlatura library. To validate our decision, we test\nboth strategies (trafilatura followed by fasttext ver-\nsus pycld2 followed by trafilatura) by processing\none random CommonCrawl segment from 2022\nand find that our chosen approach recovers 99% of\nthe Arabic samples. Considering that Penedo et al.\n(2023), after processing roughly half of existing\nCommonCrawl data, estimated the Arabic content\nto be at ∼ 0.5%, and that text extraction is a highly\ncomputationally expensive step, this approach re-\nduces data processing costs considerably with very\nlittle data loss and is particularly recommendable\nwhen only targeting specific languages.\nOnce the Arabic text samples have been ex-\ntracted, we apply a URL filter comparing to a cu-\nrated list of 46 million domains (across different\nlanguages) (url) with known pornographic, violent\nor gambling-related content. We then run fasttext\nto confirm Arabic language identification at text\nlevel and, finally, we apply the Gopher repetition\nfilter from (Rae et al., 2021) using their default\nvalues.\nWe apply a stringent deduplication strategy, us-\ning fuzzy deduplication based on MinHash (Broder,\n1997) and exact deduplication based on suffix array\n(Manber and Myers, 1993) using the implementa-\ntion of Lee et al. (2022). This is performed in a\nthree-step scheme: first, MinHash is applied indi-\nvidually to each separate dataset; then the dedupli-\ncated results are merged, and MinHash is applied\nglobally; lastly, after separating books and con-\nversations, exact deduplication is applied to the\nmerged dataset as a final step, removing all ex-\nact matches above 50 consecutive tokens. After\nthe global MinHash step, exact deduplication was\napplied separately to the books dataset due to its\nlarge individual sample size requiring a different\ndistribution of the computational workload and to\nthe conversations dataset, where we lowered the\nthreshold and removed exact duplicates above 25\nconsecutive tokens. Finally, we apply the sample-\nlevel and line-level quality filters used in Penedo\net al. (2023) adapted to Arabic, implementing the\nchanges detailed in Appendix B.1. This finally\nSplit Percentage (%) Tokens (GT)\nwebdata 94.77 61.07\nbooks 2.45 1.58\nnews 2.17 1.40\nconversations 0.34 0.22\nwikipedia 0.20 0.13\nTable 1: Final pre-training dataset mixture\nleaves us with ∼ 64.5 GT of clean and dedupli-\ncated Arabic tokens. Our data processing pipeline\nin summarized in Figure 1. Note that the stages\nfeatured here occur after the initial language iden-\ntification followed by HTML extraction, and still\nfrom stage 1 (language re-identification and basic\nfiltering) to 5 (final Arabic quality filtering), 86%\nof the disk size content in Arabic is lost, mainly\ndue to the deduplication steps.\nOur final data mixture is described in Table 1,\nshowing that most of our data (∼ 95%) comes from\ninternet sources and not curated datasets. However,\nafter identifying and analyzing our top 150 inter-\nnet domains across the entire training dataset (see\nFigure 2 and Appendix B.2 for details), we find\nnews to be the dominant category, accounting for a\nweighted 65% of the top 150 domains.\nStage 1\n100%\nStage 2\n37%\nStage 3\n26%\nS t a g e  4\n1 5 %\nS t a g e  5\n1 4 %\nAfter Arabic quality ﬁltering\nAfter string-level dedup\nAfter global sample-level dedup\nAfter individual sample-level dedup\nAfter Arabic ID & basic ﬁltering\nFigure 1: Data processing steps, showing the percentage\nof data measured in disk size left after every step. All\npercentages are computed with respect to the total data\nleft after finalizing stage1: applying language identifica-\ntion, HTML extraction and basic filtering (consisting in\nrepetition filter and minimum words per sample).\n3.3 Tokenization\nAfter exploring different approaches for tokeniza-\ntion, we found that byte-level BPE and Sentence-\nPiece offered the best coverage and fertility ratios.\nWe then compared two specific tokenizers that had\n247\nModel Layers Heads dmodel Total\nparam.\nSeq.len. Gtokens Epochs\nAraGPT2–1.5B (Antoun et al., 2021) 24 48 1536 1.5B 1024 NA NA\nJasmine–13B (Nagoudi et al., 2022) 40 40 5120 13B 2048 NA NA\nJais–13B (Sengupta et al., 2023) 40 40 5120 13B 2048 395\nar/en/code\n1\nOur–1B 24 32 2048 1.3B 2048 20 1\nOur–3B 32 40 2560 2.7B 2048 60 1\nOur–7B 32 71 4544 7B 2048 140 2\nOur–14B 36 96 6144 14B 2048 258 4\nTable 2: Model architecture compared to other autoregressive Arabic language models\nAdult\nSports\nPets\nAnimals\nFinance\nBeauty\nFashion\nFitness\nSociety\nReligion\nFamily\nOnline\nCommunity\nForums\nShopping\nMarketplace\nArts\nEntertain.\nReference\nEncyclopedias\nTravel\nT ourism\nHotels\nNews\nFigure 2: Topic distribution in the top 150 URL domains\ncovering ∼ 20% of the total number of samples in the final\nArabic pre-training dataset\na vocabulary size of 65k and used BPE as a model\nand sentence-piece as a pre-tokenizer (to which we\nrefer to as tok1 and tok2), where the main differ-\nence is that tok1 imposes a much stricter normal-\nization, where 56 Arabic unicode characters are\neither removed or replaced. We tested these two\ntokenizers by training 1B and 3B parameter models\ntrained to optimality (same number of tokens for\nsame sized models) and running them against our\nzero-shot evaluation pipeline (see Appendix C), the\ntwo tokenizers perform similarly but we continue\nwith tok1 due to its higher compression rate.\n4 Model\nA de facto architecture for large language models,\nthe canonical transformer architecture (Vaswani\net al., 2023), has seen several improvements to\nenhance the overall model qualitative performance\nand speed up both training and inference workloads.\nOur family of Arabic models are a suite of decoder\nbased generative models (Radford et al., 2018),\nclosely following the architecture of the Falcon\nmodels4 which in turn was modified from the GPT-\n3 architecture (Brown et al., 2020). We highlight\nthe following attributes:\n• Multi-query attention (Shazeer, 2019) is\nused to improve the scalability of inference.\n• Flash attention (Dao et al., 2022).\n• Parallel attention, where the attention mod-\nule and MLP blocks are executed in parallel.\n• Rotary embeddings proposed in Su et al.\n(2022).\nMore details on model architecture are given in\nTable 2, comparing with other previously released\ndecoder-only Arabic LLMs.\n4.1 Training\nWe pretrained our models on NVIDIA A100 GPUs.\nFor our 7B model we used 96 GPUs during approx-\nimately 1 week, and for our 14B model we used up\nto 384 GPUs for approximately 2 weeks, including\nlearning rate sweeps.\nOur models were trained to optimality, following\nthe scaling laws of Hoffmann et al. (2022). Due\nto the scarcity of Arabic data, we used 2 epochs\nfor our 7B model and 4 epochs for our 14B model.\nThis decision was reinforced by the recent work of\nMuennighoff et al. (2023), which shows that when\ntraining on constrained data for a fixed compute\nbudget, training up to 4 epochs of repeated data\nproduces negligible changes to the loss when com-\npared to using unique data. The work of Hernandez\net al. (2022) cautions against data repetition as it\n4https://huggingface.co/tiiuae/falcon-40b\n248\n0.0 0.1 0.2 0.3 0.4 0.5\navg\n1B\n3B\n7B\n14B\nJais-13B\nNoor 10B\nAraGPT2-Mega\nrandom\nmodel\n0.00 0.05 0.10 0.15 0.20 0.25\nscore*\n1B\n3B\n7B\n14B\nJais-13B\nNoor 10B\nAraGPT2-Mega\nrandom\nmodel\nFigure 3: Agreggate zero-shot evaluation results on our benchmark for our series of 1B, 3B, 7B and 14B models trained to\noptimality, compared to AraGPT2-Mega, Noor-10B (evaluated via API) and Jais-13B models. Average is the mean accuracy\nacross tasks. Score* is the average of (at − bt)/(1 − bt) across tasks, where: at is task accuracy and bt is task baseline.\ncan significantly degrade model performance, es-\npecially for larger models. However, their finding\nrefers to upsampling specific datasets (a practice\nused in the past to increase the amount of high qual-\nity data in the training dataset) rather than repeating\nthe entire training dataset for a limited number of\ntimes. For our largest model, with 14B parameters,\nusing 4 epochs is not expected to lead to perfor-\nmance degradation.\n5 Evaluation and results\n5.1 Throughput\nFor performing throughput experiments, we de-\nployed our 14B model using BF16, and the Jais-\n13B model using FP32, each on a single p4d in-\nstance (8 × A100 GPUs, with 40Gb of memory\neach). Both models were deployed using the Hug-\ngingFace transformers library. We observed a\nspeedup of our 14B model by +15%, +75%, and\n+158%, respectively for a batch size of 8, 16, and\n32, making it significantly faster than Jais-13B for\nlarge scale inference applications on commonly\nused A100 GPUs.\n5.2 Arabic multiple-choice tasks evaluation\nbenchmark\nWe construct AlGhafa 5, a multiple-choice zero-\nand few-shot evaluation benchmark based on 11\nexisting datasets (see Appendix C), that we curate\n5https://gitlab.com/tiiuae/alghafa\nby translating and/or modifying partially or fully\nwith human verification from native Arabic speak-\ners. All tasks used for evaluation are transformed\ninto multiple-choice tasks following the setup from\n(Brown et al., 2020). The model under evaluation is\nprompted with the text of the task and the context,\nif available. Then the log-probs of each choice are\ncalculated and normalized by number of characters.\nThe highest log-prob choice is then selected and\ncompared with the correct one to score the model.\nThe metric used is accuracy: the number of correct\nchoices the model guesses divided by the total num-\nber of samples. The results are then compared to a\nrandom baseline (since the datasets are balanced, it\nis one divided by the number of choices). All the\nclassification tasks (Facts balanced, Sentiment, Rat-\ning sentiment, Rating sentiment no neutral), were\nbalanced by removing extra samples from classes\nwith more samples. To use the generative LLM as\na classifier, the prompt for the model was designed\nas a multiple-choice task, with the possible choices\nrepresenting the possible classes.\nThe Rating tasks are created from HARD-Arabic-\nDataset, a collection of reviews with scores from\n1 (bad) to 5 (good). We remove samples that are\ntoo long since the context length of the model is\n2000 tokens. Moreover, we do not need too many\nsamples for evaluation, so the tasks were built with\na random subset of the original dataset. The ag-\ngregate results displayed in Figure 3 show that our\nmonolingual 14B model trained on 258 GT and\n249\nTest\nModel EM F1 ArchitectureFine-tuned on task?\nRandom Guess3.45 3.93 - -\nAraT5-base31.2 65.7 T5 Yes\nAT5B 31.6 67.2 T5 Yes\nAraMUS 35.3 72.3 T5 Yes\nOur-14B 21.1 13.8 Decoder No\nTable 3: Performance on QA tasks with Exact Match\n(EM) and F1 as performance metrics.\ndeployed in BF16 ranks second after the bilingual\nJais-13B model trained on 395 GT and deployed\nin FP32. Detailed figures from Appendix C show\nthat our 14B model performs better on the reading\ncomprehension tasks Belebele Ar-MSA and Bele-\nbele Ar-dialects, and also on MCQ Exams, whereas\nJais-13B particularly excels on the SOQAL Ar and\nXGLUE Ar tasks, although with a significantly in-\ncreased inference cost for large scale applications\n(see Section 5.1).\n5.3 Generative Tasks\nFollowing Alghamdi et al. (2023) and Ghaddar\net al. (2022), we evaluate our model on two types\nof generative tasks: Question Answering (QA) and\nQuestion Generation (QG). For QA evaluation task,\nwe aggregated four datasets: three from the human\ntranslated section of XTREME benchmark (Hu\net al., 2020): MLQA (Lewis et al., 2019), XQUAD\n(Artetxe et al., 2019) and Ty Di QA (Artetxe et al.,\n2019), and a fourth dataset ARCD (Mozannar et al.,\n2019). More details about the size and description\nof the datasets are listed in Appendix C.\nWe evaluate QA on two metrics, exact match\n(EM) and F1, to compare with existing results by\n(Ghaddar et al., 2022; Alghamdi et al., 2023) (see\nTable 3). For QA task, we prompted our model\nwith the context and question from the dataset and\nevaluated the completion from the model against\nthe actual or \"gold\" answer to the questions. It is to\nbe noted that some of the questions in the datasets\nhad multiple answers, in that case, we evaluated the\ncompletion from the model against the reference\nanswers. The choice of using EM and F1 as perfor-\nmance metrics was to evaluate our model against\nthe state-of-the-art models (Alghamdi et al., 2023;\nNagoudi et al., 2021; Ghaddar et al., 2022).\nFor QG tasks, we used the same datasets as QA\nfollowing (Alghamdi et al., 2023) where the model\nwas prompted with the context and answer and the\ncompletion is expected to produce a question. We\ntested our model on BLEU metrics as used by the\nbaselines. The results on the test set are shown in\nModel Test Architecture Fine-tuned on task?\nAraT5-base 13.5 T5 Yes\nAT5B 17.0 T5 Yes\nAraMUS 17.4 T5 Yes\nOur-14B 10.6 Decoder No\nTable 4: Performance on QG tasks with BLEU score as\nperformance metric.\nTable 4.\nBoth QA and QG tasks were evaluated on the\npre-trained version of our 14B parameter model,\nwith no task-specific fine-tuning as used in the case\nof AraT5-base, AT5B and AraMUS. We note here\nthat encode-decoder models are known to perform\nbest after adding a multitask fine-tuning step Wang\net al. (2022).\n6 Toxicity and bias analysis\nWe address the study of stereotypical bias related\nto gender, religion and ethnicity following two dis-\ntinct approaches, respectively a descriptive and a\nquantitative one.\n6.1 Descriptive analysis\nWe follow an approach similar to Brown et al.\n(2020) and Chowdhery et al. (2022) in perform-\ning a qualitative inspection of eventual bias related\nto gender, nationality, and religion. We analyze co-\noccurrence statistics between groups and descrip-\ntive words in predictions generated from prompts\nfollowing the pattern \"The group member is al-\nways\" (\"/char2e/char2e/char2e /char41/chard6/char0d/chardf/char40/char58 /char2a/char10/chare9/charab/charf1/chard2/char6a/char2e/chard6/charcf/char40 /charf1/char09/char92/charab/char2a\"), where group\nmember is substituted by a gender, national or re-\nligious identity. We adapted the prompt pattern\nproposed by (Chowdhery et al., 2022), using the\nterm always instead of very to adapt to the Arabic\nlanguage syntax. We note that a similar pattern is\nused in bias analysis in (Nagoudi et al., 2022). For\neach prompt we generate 800 completions using nu-\ncleus sampling, with top-p=0.9 and a temperature\nof 1. In order to reduce inappropriate toxic content\nwe perform a two-step analysis: at first we apply a\nsimple \"bad word\" filter (see Appendix E.1) on the\nproduced content, then we employ a part-of-speech\ntagger (Obeid et al., 2020) to retain only adjectives\nfrom the first sentence of the completion. Finally,\nwe remove adjectives that are considered not de-\nscriptive in terms of bias and, for each group, we\nreport the top-10 most frequent descriptive words\nobtained (see Appendix E.2 for full details).\n250\n6.2 Quantitative analysis\nWe propose a quantitative approach to bias and\ntoxicity analysis following the method described\nin (Ousidhoum et al., 2021). At first, we generate\n113176 open sentences including an explicit social\ngroup member as subject followed by an ordinary\naction from the ATOMIC series of patterns (Sap\net al., 2019). In order to highlight any eventual\nbias related to gender, we use gendered pronouns\nand generate a total of 4000 patterns from the 1000\nATOMIC heads addingbecause she/of her and be-\ncause he/of his in case, respectively, of a female or\nmale subject. Our evaluation focuses on the study\nof bias in groups related to ethnicity and religion.\nFrom these patterns, we obtain masked close\nprompts for whose the assessed LLMs need to gen-\nerate the last token giving a reason for the action\ntaken. For each prompt, we generate 10 comple-\ntions using nucleus sampling with top-p=0.9 and a\ntemperature of 1, with the exception of the Jais-chat\nmodel, for which, in order to meet the submission\ndeadline, a single completion for each prompt is\ngenerated. For both the considered fine-tuned mod-\nels we include their pre-prompts. For Jais-chat, we\nused the recommended Arabic pre-prompt 6, con-\nsisting of 307 words. For our chat fine-tuned 14B\nmodel, we use a custom pre-prompt with a total of\n466 words.\nA simple logistic regression (LR) classifier (see\nAppendix E.3) is then used to probe for toxicity.\nSince toxic language classifiers can exhibit a built-\nin bias toward specific terms including the names\nof certain social groups (Sap et al., 2019), (Park\net al., 2018), (Hutchinson et al., 2020), the toxicity\nprobing is performed in two steps.\nIn the preliminary stage, the classifier is run on\nthe raw prompts including only the subject and the\naction. We then filter out 40.0% of the patterns\nas they have been classified as toxic. In the main\nstage, the classifier is applied to the full sentences\nstarting with a non-toxic prompt. Our \"bad word\"\nfilter is also applied to avoid inappropriate content.\nThe proportion of sentences marked as toxic for\neach of the assessed models is reported in Table 5.\nWe gain further insights for these results with the\nlabels provided by the human annotators in 6.2.1.\nFurther statistics regarding toxicity in social groups\nare displayed in Appendix E.4. From an overall\ntoxicity comparison between our 14B model and\n6https://huggingface.co/inception-mbzuai/\njais-13b-chat\nModel %\nOur-14B 7.02\nOur-14B-chat 1.93\nJais-13B 4.57\nJais-chat-13B∗ 3.56\nNoor-10B 7.31\nAraGPT2-1.5B 3.66\nAraBERT-136M 9.34\nTable 5: Proportion of generated sentences that are\nmarked as toxic by the LR classifier\nPTLM normal % toxic % confusing %\nOur-14B 40.0 5.0 55.0\nAraBERT-136M 50.0 15.0 35.0\nAraGPT2-1.5B 10.0 0.0 90.0\nJais-13B 25.0 10.0 65.0\nNoor-10B 30.0 10.0 60.0\nTable 6: Human evaluation of 20 samples for each of the\n5 Arabic PTLMs of interest. We report the percentage\nscores for labelled sentences in each category.\nour chat fine-tuned 14B model (details given in\nAppendix D), we notice a definite reduction in the\nproduced toxic content due to the proposed fine-\ntuning and the use of pre-prompts.\n6.2.1 Human Evaluation\nTo have further insights on the assessed Pretrained\nLanguage Models (PTLMs), we sample 20 gener-\nated statements from each one, for a total of 100\nsentences, and asked 3 Arabic speakers to annotate\nthem as normal, toxic or confusing without know-\ning from which model they have been produced. A\nsentence can be marked as confusing whether it is\nnot clear if it is toxic or not or if it seems to lack\ncommonsense. We report in Table 6 the majority\nvoting results for the annotator labels. When com-\nparing Tables 5 and 6 we can notice, at first, that the\nproportion of sentences masked as confusing is sig-\nnificant, in particular for AraGPT2-1.5B. This can\nprobably contribute to the low level of toxicity dis-\nplayed by this model. In fact, when looking at the\ncompletions it generates we can notice a tendency\nto produce punctuation and stop words. When look-\ning at the proportion of toxic labeled content, we\ncan notice an overall agreement in scale between\nthe classifier and the human annotators.\n7 Limitations\nAs our models are trained chiefly on publicly avail-\nable Arabic data crawled from the internet (∼ 95%)\nand cleaned using a large-scale automated pipeline,\nthey can present to some degree several of the is-\nsues commonly found in large language models:\n251\noutputting incorrect/private/sensitive information,\ntoxicity and/or bias, the potential for misuse. We\ncaution the reader that these models were trained\nfor academic research and should not be used in\nhandling sensitive information and taking high-risk\ndecisions without taking additional steps.\nOur quantitative toxicity analysis for Arabic\ncompletions shows that our models can display\nslightly increased toxicity when compared to some\nother pre-existing Arabic models, especially with\nrespect to certain categories. We show this can\nbe significantly alleviated through fine-tuning. We\nplan to train another suite of models with the objec-\ntive of intrinsically reducing model toxicity either\nby including improved Arabic toxicity filters in our\ndata processing pipeline or by improving the toxic\nURL list for the Arabic language, while analyzing\nthe overall effect on model performance.\nFinally, as most of our training data comes from\nthe internet, we plan to pursue a detailed analysis\nof dialectal coverage and model performance over\ndifferent Arabic dialects.\nAcknowledgements\nAuthors thank Nilabhra Roy Chowdhury, Kebin\nWu, Alessandro Cappelli, Baptiste Pannier, Daniel\nHesslow and Maxim Panov for useful discus-\nsions. We also thank Olivier Cruchant and Amine\nLoughzali from aws for technical support. Fi-\nnally we thank our Arabic speaking volunteers,\nBasma Boussaha, Ameera Bawazir, Lina Bariah\nand Haithem Boussaid, for manually validating\ntranslations and/or toxicity labels.\nReferences\nBlacklist ut1. https://dsi.ut-capitole.fr/\nblacklists/. Accessed: 2023-09-12.\nIbrahim Abu Farha, Wajdi Zaghouani, and Walid Magdy.\n2021. Overview of the WANLP 2021 shared task\non sarcasm and sentiment detection in Arabic. In\nProceedings of the Sixth Arabic Natural Language\nProcessing Workshop, pages 296–305, Kyiv, Ukraine\n(Virtual). Association for Computational Linguistics.\nAhmed Hashim Al-Dulaimi. 2022. Ultimate arabic\nnews dataset.\nAzalden Alakrot, Liam Murray, and Nikola S. Nikolov.\n2018. Dataset construction for the detection of anti-\nsocial behaviour in online communication in arabic.\nProcedia Computer Science, 142:174–181. Arabic\nComputational Linguistics.\nNuha Albadi, Maram Kurdi, and Shivakant Mishra.\n2018. Are they our brothers? analysis and detec-\ntion of religious hate speech in the arabic twitter-\nsphere. In 2018 IEEE/ACM International Confer-\nence on Advances in Social Networks Analysis and\nMining (ASONAM), pages 69–76.\nAsaad Alghamdi, Xinyu Duan, Wei Jiang, Zhenhai\nWang, Yimeng Wu, Qingrong Xia, Zhefeng Wang,\nYi Zheng, Mehdi Rezagholizadeh, Baoxing Huai,\nPeilun Cheng, and Abbas Ghaddar. 2023. Aramus:\nPushing the limits of data and model scale for arabic\nnatural language processing.\nM. Alhagri. 2015. Saudi newspapers arabic corpus\n(saudinewsnet).\nWissam Antoun, Fady Baly, and Hazem Hajj. 2021.\nAragpt2: Pre-trained transformer for arabic language\ngeneration.\nMikel Artetxe, Sebastian Ruder, and Dani Yogatama.\n2019. On the cross-lingual transferability of mono-\nlingual representations. CoRR, abs/1910.11856.\nLucas Bandarkar, Davis Liang, Benjamin Muller, Mikel\nArtetxe, Satya Narayan Shukla, Donald Husa, Naman\nGoyal, Abhinandan Krishnan, Luke Zettlemoyer, and\nMadian Khabsa. 2023. The belebele benchmark: a\nparallel reading comprehension dataset in 122 lan-\nguage variants.\nAndrei Z Broder. 1997. On the resemblance and con-\ntainment of documents. In Proceedings. Compres-\nsion and Complexity of Sequences 1997, pages 21–29.\nIEEE.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language models are few-shot learners.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, Parker Schuh, Kensen Shi,\nSasha Tsvyashchenko, Joshua Maynez, Abhishek\nRao, Parker Barnes, Yi Tay, Noam Shazeer, Vin-\nodkumar Prabhakaran, Emily Reif, Nan Du, Ben\nHutchinson, Reiner Pope, James Bradbury, Jacob\nAustin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,\nToju Duke, Anselm Levskaya, Sanjay Ghemawat,\nSunipa Dev, Henryk Michalewski, Xavier Garcia,\nVedant Misra, Kevin Robinson, Liam Fedus, Denny\nZhou, Daphne Ippolito, David Luan, Hyeontaek Lim,\nBarret Zoph, Alexander Spiridonov, Ryan Sepassi,\nDavid Dohan, Shivani Agrawal, Mark Omernick, An-\ndrew M. Dai, Thanumalayan Sankaranarayana Pil-\nlai, Marie Pellat, Aitor Lewkowycz, Erica Moreira,\n252\nRewon Child, Oleksandr Polozov, Katherine Lee,\nZongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark\nDiaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy\nMeier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov,\nand Noah Fiedel. 2022. Palm: Scaling language mod-\neling with pathways.\nTri Dao, Daniel Y . Fu, Stefano Ermon, Atri Rudra,\nand Christopher Ré. 2022. Flashattention: Fast and\nmemory-efficient exact attention with io-awareness.\nNing Ding, Yulin Chen, Bokai Xu, Shengding Hu, Yu-\njia Qin, Zhiyuan Liu, Maosong Sun, and Bowen\nZhou. 2023. Ultrachat: A large-scale auto-generated\nmulti-round dialogue data. https://github.com/\nthunlp/ultrachat.\nIbrahim Abu El-khair. 2016. 1.5 billion words arabic\ncorpus.\nIbrahim Abu El-Khair. 2017. Effects of stop words\nelimination for arabic information retrieval: A com-\nparative study.\nAshraf Elnagar, Yasmin Khalifa, and Anas Einea. 2018.\nHotel Arabic-Reviews Dataset Construction for Sen-\ntiment Analysis Applications, pages 35–52.\nLeo Gao, Stella Biderman, Sid Black, Laurence Gold-\ning, Travis Hoppe, Charles Foster, Jason Phang, Ho-\nrace He, Anish Thite, Noa Nabeshima, et al. 2020.\nThe pile: An 800gb dataset of diverse text for lan-\nguage modeling. arXiv preprint arXiv:2101.00027.\nAbbas Ghaddar, Yimeng Wu, Sunyam Bagga, Ahmad\nRashid, Khalil Bibi, Mehdi Rezagholizadeh, Chao\nXing, Yasheng Wang, Xinyu Duan, Zhefeng Wang,\nBaoxing Huai, Xin Jiang, Qun Liu, and Phillippe\nLanglais. 2022. Revisiting pre-trained language mod-\nels and their evaluation for Arabic natural language\nprocessing. In Proceedings of the 2022 Conference\non Empirical Methods in Natural Language Process-\ning, pages 3135–3151, Abu Dhabi, United Arab Emi-\nrates. Association for Computational Linguistics.\nAbbas Ghaddar, Yimeng Wu, Ahmad Rashid, Khalil\nBibi, Mehdi Rezagholizadeh, Chao Xing, Yasheng\nWang, Duan Xinyu, Zhefeng Wang, Baoxing Huai,\nXin Jiang, Qun Liu, and Philippe Langlais. 2021.\nJABER: junior arabic bert. CoRR, abs/2112.04329.\nEdouard Grave, Piotr Bojanowski, Prakhar Gupta, Ar-\nmand Joulin, and Tomas Mikolov. 2018. Learning\nword vectors for 157 languages. In Proceedings of\nthe International Conference on Language Resources\nand Evaluation (LREC 2018).\nMomchil Hardalov, Todor Mihaylov, Dimitrina\nZlatkova, Yoan Dinkov, Ivan Koychev, and Preslav\nNakov. 2020. EXAMS: A multi-subject high school\nexaminations dataset for cross-lingual and multilin-\ngual question answering. In Proceedings of the 2020\nConference on Empirical Methods in Natural Lan-\nguage Processing (EMNLP), pages 5427–5444, On-\nline. Association for Computational Linguistics.\nDanny Hernandez, Tom Brown, Tom Conerly, Nova\nDasSarma, Dawn Drain, Sheer El-Showk, Nelson\nElhage, Zac Hatfield-Dodds, Tom Henighan, Tris-\ntan Hume, Scott Johnston, Ben Mann, Chris Olah,\nCatherine Olsson, Dario Amodei, Nicholas Joseph,\nJared Kaplan, and Sam McCandlish. 2022. Scaling\nlaws and interpretability of learning from repeated\ndata.\nJordan Hoffmann, Sebastian Borgeaud, Arthur Mensch,\nElena Buchatskaya, Trevor Cai, Eliza Rutherford,\nDiego de Las Casas, Lisa Anne Hendricks, Johannes\nWelbl, Aidan Clark, Tom Hennigan, Eric Noland,\nKatie Millican, George van den Driessche, Bogdan\nDamoc, Aurelia Guy, Simon Osindero, Karen Si-\nmonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals,\nand Laurent Sifre. 2022. Training compute-optimal\nlarge language models.\nSara Hooker. 2020. The hardware lottery.\nJunjie Hu, Sebastian Ruder, Aditya Siddhant, Gra-\nham Neubig, Orhan Firat, and Melvin Johnson.\n2020. XTREME: A massively multilingual multi-\ntask benchmark for scalinguating cross-lingual gen-\neralisation. In Proceedings of the 37th International\nConference on Machine Learning , volume 119 of\nProceedings of Machine Learning Research, pages\n4411–4421. PMLR.\nBen Hutchinson, Vinodkumar Prabhakaran, Emily Den-\nton, Kellie Webster, Yu Zhong, and Stephen Denuyl.\n2020. Social biases in NLP models as barriers for\npersons with disabilities. In Proceedings of the 58th\nAnnual Meeting of the Association for Computational\nLinguistics, pages 5491–5501, Online. Association\nfor Computational Linguistics.\nNorman P. Jouppi, George Kurian, Sheng Li, Peter\nMa, Rahul Nagarajan, Lifeng Nai, Nishant Patil,\nSuvinay Subramanian, Andy Swing, Brian Towles,\nCliff Young, Xiang Zhou, Zongwei Zhou, and David\nPatterson. 2023. Tpu v4: An optically reconfigurable\nsupercomputer for machine learning with hardware\nsupport for embeddings.\nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B.\nBrown, Benjamin Chess, Rewon Child, Scott Gray,\nAlec Radford, Jeffrey Wu, and Dario Amodei. 2020.\nScaling laws for neural language models.\nImad Lakim, Ebtesam Almazrouei, Ibrahim Abualhaol,\nMerouane Debbah, and Julien Launay. 2022. A holis-\ntic assessment of the carbon footprint of noor, a very\nlarge Arabic language model. In Proceedings of Big-\nScience Episode #5 – Workshop on Challenges &\nPerspectives in Creating Large Language Models ,\npages 84–94, virtual+Dublin. Association for Com-\nputational Linguistics.\nKatherine Lee, Daphne Ippolito, Andrew Nystrom,\nChiyuan Zhang, Douglas Eck, Chris Callison-Burch,\nand Nicholas Carlini. 2022. Deduplicating training\ndata makes language models better. In Proceedings\nof the 60th Annual Meeting of the Association for\n253\nComputational Linguistics (Volume 1: Long Papers),\npages 8424–8445.\nPatrick Lewis, Barlas O ˘guz, Ruty Rinott, Sebastian\nRiedel, and Holger Schwenk. 2019. Mlqa: Eval-\nuating cross-lingual extractive question answering.\narXiv preprint arXiv:1910.07475.\nHaonan Li, Fajri Koto, Minghao Wu, Alham Fikri Aji,\nand Timothy Baldwin. 2023. Bactrian-x : A multi-\nlingual replicable instruction-following model with\nlow-rank adaptation.\nYaobo Liang, Nan Duan, Yeyun Gong, Ning Wu, Fen-\nfei Guo, Weizhen Qi, Ming Gong, Linjun Shou,\nDaxin Jiang, Guihong Cao, et al. 2020. Xglue:\nA new benchmark dataset for cross-lingual pre-\ntraining, understanding and generation. arXiv\npreprint arXiv:2004.01401.\nUdi Manber and Gene Myers. 1993. Suffix arrays: a\nnew method for on-line string searches. Journal on\nComputing, 22(5):935–948.\nTomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey\nDean. 2013. Efficient estimation of word representa-\ntions in vector space.\nHussein Mozannar, Elie Maamary, Karl El Hajal, and\nHazem Hajj. 2019. Neural Arabic question answer-\ning. In Proceedings of the Fourth Arabic Natural\nLanguage Processing Workshop, pages 108–118, Flo-\nrence, Italy. Association for Computational Linguis-\ntics.\nHamdy Mubarak, Ammar Rashed, Kareem Darwish,\nYounes Samih, and Ahmed Abdelali. 2021. Arabic\noffensive language on Twitter: Analysis and exper-\niments. In Proceedings of the Sixth Arabic Natu-\nral Language Processing Workshop, pages 126–135,\nKyiv, Ukraine (Virtual). Association for Computa-\ntional Linguistics.\nNiklas Muennighoff, Alexander M. Rush, Boaz Barak,\nTeven Le Scao, Aleksandra Piktus, Nouamane Tazi,\nSampo Pyysalo, Thomas Wolf, and Colin Raffel.\n2023. Scaling data-constrained language models.\nNiklas Muennighoff, Thomas Wang, Lintang Sutawika,\nAdam Roberts, Stella Biderman, Teven Le Scao,\nM Saiful Bari, Sheng Shen, Zheng-Xin Yong, Hailey\nSchoelkopf, et al. 2022. Crosslingual generaliza-\ntion through multitask finetuning. arXiv preprint\narXiv:2211.01786.\nHala Mulki, Hatem Haddad, Chedi Bechikh Ali, and\nHalima Alshabani. 2019. L-HSAB: A Levantine\nTwitter dataset for hate speech and abusive language.\nIn Proceedings of the Third Workshop on Abusive\nLanguage Online, pages 111–118, Florence, Italy.\nAssociation for Computational Linguistics.\nEl Moatez Billah Nagoudi, Muhammad Abdul-Mageed,\nAbdelRahim Elmadany, Alcides Alcoba Inciarte, and\nMd Tawkat Islam Khondaker. 2022. Jasmine: Arabic\ngpt models for few-shot learning.\nEl Moatez Billah Nagoudi, AbdelRahim A. Elmadany,\nand Muhammad Abdul-Mageed. 2021. Arat5: Text-\nto-text transformers for arabic language understand-\ning and generation. CoRR, abs/2109.12068.\nDeepak Narayanan, Mohammad Shoeybi, Jared Casper,\nPatrick LeGresley, Mostofa Patwary, Vijay Anand\nKorthikanti, Dmitri Vainbrand, Prethvi Kashinkunti,\nJulie Bernauer, Bryan Catanzaro, Amar Phanishayee,\nand Matei Zaharia. 2021. Efficient large-scale lan-\nguage model training on gpu clusters using megatron-\nlm.\nLorenz Nigst, Maxim Romanov, Sarah Bowen Sa-\nvant, Masoumeh Seydi, and Peter Verkinderen. 2023.\n\"openiti: a machine-readable corpus of islamicate\ntexts\".\nOssama Obeid, Nasser Zalmout, Salam Khalifa, Dima\nTaji, Mai Oudah, Bashar Alhafni, Go Inoue, Fadhl\nEryani, Alexander Erdmann, and Nizar Habash. 2020.\nCAMeL tools: An open source python toolkit for Ara-\nbic natural language processing. In Proceedings of\nthe 12th Language Resources and Evaluation Confer-\nence, pages 7022–7032, Marseille, France. European\nLanguage Resources Association.\nNedjma Ousidhoum, Zizheng Lin, Hongming Zhang,\nYangqiu Song, and Dit-Yan Yeung. 2019. Multi-\nlingual and multi-aspect hate speech analysis. In\nProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP), pages 4675–\n4684, Hong Kong, China. Association for Computa-\ntional Linguistics.\nNedjma Ousidhoum, Xinran Zhao, Tianqing Fang,\nYangqiu Song, and Dit-Yan Yeung. 2021. Probing\ntoxic content in large pre-trained language models.\nIn Proceedings of the 59th Annual Meeting of the\nAssociation for Computational Linguistics and the\n11th International Joint Conference on Natural Lan-\nguage Processing (Volume 1: Long Papers), pages\n4262–4274, Online. Association for Computational\nLinguistics.\nJi Ho Park, Jamin Shin, and Pascale Fung. 2018. Re-\nducing gender bias in abusive language detection.\nIn Proceedings of the 2018 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n2799–2804, Brussels, Belgium. Association for Com-\nputational Linguistics.\nGuilherme Penedo, Quentin Malartic, Daniel Hesslow,\nRuxandra Cojocaru, Alessandro Cappelli, Hamza\nAlobeidli, Baptiste Pannier, Ebtesam Almazrouei,\nand Julien Launay. 2023. The refinedweb dataset for\nfalcon llm: Outperforming curated corpora with web\ndata, and web data only.\nAlec Radford, Karthik Narasimhan, Tim Salimans, and\nIlya Sutskever. 2018. Improving language under-\nstanding by generative pre-training.\n254\nAlec Radford, Jeff Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners.\nJack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie\nMillican, Jordan Hoffmann, Francis Song, John\nAslanides, Sarah Henderson, Roman Ring, Susan-\nnah Young, Eliza Rutherford, Tom Hennigan, Ja-\ncob Menick, Albin Cassirer, Richard Powell, George\nvan den Driessche, Lisa Anne Hendricks, Mari-\nbeth Rauh, Po-Sen Huang, Amelia Glaese, Jo-\nhannes Welbl, Sumanth Dathathri, Saffron Huang,\nJonathan Uesato, John Mellor, Irina Higgins, Anto-\nnia Creswell, Nat McAleese, Amy Wu, Erich Elsen,\nSiddhant Jayakumar, Elena Buchatskaya, David Bud-\nden, Esme Sutherland, Karen Simonyan, Michela Pa-\nganini, Laurent Sifre, Lena Martens, Xiang Lorraine\nLi, Adhiguna Kuncoro, Aida Nematzadeh, Elena\nGribovskaya, Domenic Donato, Angeliki Lazaridou,\nArthur Mensch, Jean-Baptiste Lespiau, Maria Tsim-\npoukelli, Nikolai Grigorev, Doug Fritz, Thibault Sot-\ntiaux, Mantas Pajarskas, Toby Pohlen, Zhitao Gong,\nDaniel Toyama, Cyprien de Masson d’Autume, Yujia\nLi, Tayfun Terzi, Vladimir Mikulik, Igor Babuschkin,\nAidan Clark, Diego de Las Casas, Aurelia Guy,\nChris Jones, James Bradbury, Matthew Johnson,\nBlake Hechtman, Laura Weidinger, Iason Gabriel,\nWilliam Isaac, Ed Lockhart, Simon Osindero, Laura\nRimell, Chris Dyer, Oriol Vinyals, Kareem Ayoub,\nJeff Stanway, Lorrayne Bennett, Demis Hassabis, Ko-\nray Kavukcuoglu, and Geoffrey Irving. 2021. Scaling\nlanguage models: Methods, analysis & insights from\ntraining gopher.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. 2020. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer.\nMotaz Saad. 2019. Arabic-news.\nMaarten Sap, Ronan LeBras, Emily Allaway, Chan-\ndra Bhagavatula, Nicholas Lourie, Hannah Rashkin,\nBrendan Roof, Noah A. Smith, and Yejin Choi. 2019.\nAtomic: An atlas of machine commonsense for if-\nthen reasoning.\nHaitham Seelawi, Ibraheem Tuffaha, Mahmoud Gzawi,\nWael Farhan, Bashar Talafha, Riham Badawi, Zyad\nSober, Oday Al-Dweik, Abed Alhakim Freihat, and\nHussein Al-Natsheh. 2021. ALUE: Arabic language\nunderstanding evaluation. In Proceedings of the\nSixth Arabic Natural Language Processing Workshop,\npages 173–184, Kyiv, Ukraine (Virtual). Association\nfor Computational Linguistics.\nNeha Sengupta, Sunil Kumar Sahu, Bokang Jia,\nSatheesh Katipomu, Haonan Li, Fajri Koto,\nOsama Mohammed Afzal, Samta Kamboj, Onkar\nPandit, Rahul Pal, Lalit Pradhan, Zain Muhammad\nMujahid, Massa Baali, Alham Fikri Aji, Zhengzhong\nLiu, Andy Hock, Andrew Feldman, Jonathan Lee,\nAndrew Jackson, Preslav Nakov, Timothy Baldwin,\nand Eric Xing. 2023. Jais and jais-chat: Arabic-\ncentric foundation and instruction-tuned open gener-\native large language models.\nJaime Sevilla, Lennart Heim, Anson Ho, Tamay Be-\nsiroglu, Marius Hobbhahn, and Pablo Villalobos.\n2022. Compute trends across three eras of machine\nlearning.\nNoam Shazeer. 2019. Fast transformer decoding: One\nwrite-head is all you need.\nZien Sheikh Ali, Watheq Mansour, Tamer Elsayed, and\nAbdulaziz Al-Ali. 2021. AraFacts: The first large\nArabic dataset of naturally occurring claims. In Pro-\nceedings of the Sixth Arabic Natural Language Pro-\ncessing Workshop, pages 231–236, Kyiv, Ukraine\n(Virtual). Association for Computational Linguistics.\nJianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha,\nBo Wen, and Yunfeng Liu. 2022. Roformer: En-\nhanced transformer with rotary position embedding.\nPedro Javier Ortiz Suá rez, Laurent Romary, and Benoît\nSagot. 2020. A monolingual approach to contextual-\nized word embeddings for mid-resource languages.\nIn Proceedings of the 58th Annual Meeting of the As-\nsociation for Computational Linguistics. Association\nfor Computational Linguistics.\nReem Suwaileh, Mucahid Kultlu, Nihal Fathima, Tamer\nElsayed, and Matthew Lease. 2016. \"arabicweb16:\nA new crawl for today’s arabic web\". In Proceedings\nof the 39th annual international ACM SIGIR confer-\nence on Research and development in information\nretrieval: SIGIR ’16\", pages 673–676. Pisa, Italy.\nRohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann\nDubois, Xuechen Li, Carlos Guestrin, Percy Liang,\nand Tatsunori B. Hashimoto. 2023. Stanford alpaca:\nAn instruction-following llama model. https://\ngithub.com/tatsu-lab/stanford_alpaca.\nNLLB Team, Marta R. Costa-jussà, James Cross, Onur\nÇelebi, Maha Elbayad, Kenneth Heafield, Kevin Hef-\nfernan, Elahe Kalbassi, Janice Lam, Daniel Licht,\nJean Maillard, Anna Sun, Skyler Wang, Guillaume\nWenzek, Al Youngblood, Bapi Akula, Loic Bar-\nrault, Gabriel Mejia Gonzalez, Prangthip Hansanti,\nJohn Hoffman, Semarley Jarrett, Kaushik Ram\nSadagopan, Dirk Rowe, Shannon Spruit, Chau\nTran, Pierre Andrews, Necip Fazil Ayan, Shruti\nBhosale, Sergey Edunov, Angela Fan, Cynthia\nGao, Vedanuj Goswami, Francisco Guzmán, Philipp\nKoehn, Alexandre Mourachko, Christophe Ropers,\nSafiyyah Saleem, Holger Schwenk, and Jeff Wang.\n2022. No language left behind: Scaling human-\ncentered machine translation.\nHugo Touvron, Louis Martin, Kevin Stone, Peter Al-\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay\nBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti\nBhosale, Dan Bikel, Lukas Blecher, Cristian Canton\nFerrer, Moya Chen, Guillem Cucurull, David Esiobu,\nJude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,\n255\nCynthia Gao, Vedanuj Goswami, Naman Goyal, An-\nthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan\nInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,\nIsabel Kloumann, Artem Korenev, Punit Singh Koura,\nMarie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-\nana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-\ntinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-\nbog, Yixin Nie, Andrew Poulton, Jeremy Reizen-\nstein, Rashi Rungta, Kalyan Saladi, Alan Schelten,\nRuan Silva, Eric Michael Smith, Ranjan Subrama-\nnian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-\nlor, Adina Williams, Jian Xiang Kuan, Puxin Xu,\nZheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,\nMelanie Kambadur, Sharan Narang, Aurelien Ro-\ndriguez, Robert Stojnic, Sergey Edunov, and Thomas\nScialom. 2023. Llama 2: Open foundation and fine-\ntuned chat models.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2023. Attention is all\nyou need.\nThomas Wang, Adam Roberts, Daniel Hesslow,\nTeven Le Scao, Hyung Won Chung, Iz Beltagy, Julien\nLaunay, and Colin Raffel. 2022. What language\nmodel architecture and pretraining objective work\nbest for zero-shot generalization?\nJason Wei, Yi Tay, Rishi Bommasani, Colin Raffel,\nBarret Zoph, Sebastian Borgeaud, Dani Yogatama,\nMaarten Bosma, Denny Zhou, Donald Metzler, Ed H.\nChi, Tatsunori Hashimoto, Oriol Vinyals, Percy\nLiang, Jeff Dean, and William Fedus. 2022. Emer-\ngent abilities of large language models.\nMarcos Zampieri, Preslav Nakov, Sara Rosenthal, Pepa\nAtanasova, Georgi Karadzhov, Hamdy Mubarak,\nLeon Derczynski, Zeses Pitenis, and Ça˘grı Çöltekin.\n2020. SemEval-2020 task 12: Multilingual offensive\nlanguage identification in social media (OffensEval\n2020). In Proceedings of the Fourteenth Workshop on\nSemantic Evaluation, pages 1425–1447, Barcelona\n(online). International Committee for Computational\nLinguistics.\nA HandMade Dataset\nA.1 Collecting links with custom spiders\nWe realized data availability would be an issue, so\nwe decided to build a collection of web links taken\nfrom handmade selected websites with custom spi-\nders. This was done by a team of four Arabic\nspeakers with knowledge of common news, gov-\nernment, books, and blog websites. The pipeline\nlooked like this:\n1. Arabic speakers select websites’ homepages.\n2. The websites are sorted on the potential\namount of content.\n3. An engineer evaluates the complexity of the\nscrape. Mostly checking for a sitemap or\na straightforward API that would return the\nlinks.\n4. The engineer writes a spider using Scrapy and\nlaunches it on an EC2 instance.\n5. The spider batches links in 10k CSV files.\nOut of 255 domains selected, we wrote spiders\nfor 54 of them. We followed the same logic as\nCommonCrawl and respected the Disallow on the\nCCBot User Agent. Other websites were discarded\nfor either low resources, blocked URLs, or rate-\nlimiting issues.\nThis approach had several downfalls:\n1. Very time-consuming: this is by far the most\nproblematic. We tried to be as efficient as\npossible in the custom scraping logic, creat-\ning base spider classes. But still, it had sev-\neral manual steps, from filtering homepages\nto launching and monitoring.\n2. While Scrapy offers a rate-limiting logic to\navoid being IP banned from the server, we still\nencountered several homepages that would\nblock the requests or, worse, return a link to\nan empty page.\n3. We weren’t checking for duplicate links.\nScrapy provides a state manager to avoid vis-\niting previous links. Still, when scraping\nsitemaps or using a sequential API (requests\nthat required a \"previous request token\"), this\nfeature had to be disabled.\nWe also experimented with a link-hopper strat-\negy: given a starting seed, visit all links in that\ndomain. On every link, repeat the search and col-\nlect. The starting seeds were collected by using\nthe site operator on Google and looking for top-\nlevel domains (e.g., .gov.ae) of any of the coun-\ntries whose official language is Arabic. The issue\nwith this strategy is that it requires downloading\nthe whole page to fetch the next set of links. It\nalso inevitably visits many bad-quality pages, like\n\"Contact Us\" or Navigation menus.\nAfter executing both strategies, we collected\naround 60 million links, though as will be checked\nlater, around 25 million were duplicates or invalid.\n256\nA.2 Scraping with Kafka and EFS\nOur first approach: to collect the data from the\nlinks, we set up a pipeline using Kafka and writing\nthem to AWS EFS (Elastic File System).\n1. Every time the spiders write a new CSV file,\na Kafka message is sent to the \"Download\"\nqueue containing the file path.\n2. An observer receives the message, opens the\nfile and parses the links and metadata.\n3. The link is downloaded and written to file:\none file per each link. A message with the file\npath and metadata is sent to a \"Parse\" Kafka\nqueue on success.\n4. A different observer receives the message and,\nbased on the metadata, decides which parser\nto use.\nWe wrote parsers for the different file types:\nHTML, using Trafilatura; PDFs, using itextpdf\nin Java; Epub, using ebooklib W ARC files, by un-\nzipping and using Trafilatura again; Doc and Docx,\nusing python-docx.\nEach parser would take a file path as input, open\nand parse it, and then write the contents to disk.\nWe tried extracting content with OCR for PDFs\nbut ultimately discarded them as we felt OCR tech-\nnology in Arabic was not accurate enough. Low\naccuracy risks introducing systematic artifacts in\nthe training data, like wrong bytes, spacing arti-\nfacts, and flipped texts. This limited our ability to\nrely on PDF files for data, as we identified that only\n5% of all of the ones we had collected were parsed\ncorrectly.\nAnother issue with this approach was the lack of\ndeduplication, which caused a waste of resources\nreprocessing the same content.\nA.3 Scraping using MongoDB and Dagster\nDue to technical issues and low visibility in the data\nextraction, we estimated we had lost more than half\nof the potential data we could have collected from\nthe links. The idea was that, with proper tooling,\nwe could go from the CSV files to the data faster,\ncheaper, and more reliably.\nTo solve the issues of scalability and dedupli-\ncation, we decided to set up a sharded MongoDB\ncluster. We collected all the CSV files and inserted\nthe single links as documents in a MongoDB col-\nlection. We used the hash of the cleaned URL as a\nshard key and unique index:\n• The unique index allowed us to deduplicate\nthe links automatically.\n• Using a hash as a shard key means you can\npartition the ranges on each shard beforehand.\nThis way, you don’t trigger re-balancing the\ncluster, which actually caused it to crash.\nA cleaned URL is obtained by removing the proto-\ncol and trailing \"/\", then decoding from Base64.\nTo properly deduplicate all the links, we decided\nto include also the list of links from our other\ndatasets: Common Crawl and ArabicWeb16. In\ntotal, we obtained 330 Million documents. The\ncollisions between our HandMade dataset and\nArabicWeb16 + Common Crawl ended up being\naround 2 million.\nWe kept in each document:\n• The source URL.\n• A flag to signal whether it had been down-\nloaded. This became an index key once we\nstarted scraping the links.\n• A counter to check the number of duplicates.\nThis field also kept track of which dataset it\nwas found in (HandMade, Common Crawl,\nArabicWeb16).\nUsing MongoDB also provided a quick way to\ncheck the quality and sources of the data manually.\nTo simplify deployment and parallelization, we\nused Dagster and converted our parsers, and Kafka\nqueues into DAGs. We attempted using Airflow\nbefore Dagster, but we decided to switch since\ntesting the DAGs was quite cumbersome.\nThe DAGs for downloading were pretty straight-\nforward: a generator would fetch 10k random links\nfrom the database, then yield using a Dynamic out.\nThis would spawn an operator for each yielded\nbatch of documents. Each operator would loop\nthrough them by downloading one at a time. Once\nall are downloaded or failed, do a batch update by\nchanging the \"downloaded\" flag to true and adding\nmetadata about the status of the download, like the\nstatus code and text, the time of download, and the\ncontent length.\nEach operator also generated metrics using\nStatsD that we collected on a Prometheus Push\nGateway and visualized in Grafana. We monitored\nstatus codes, length of files, download times, and\ndatabase operation times. This way, we could de-\ntect hitting a rate limiter or database performance\nissues.\n257\nEverything was deployed using Helm charts on\na Kubernetes cluster on AWS EKS. Using Helm\ncharts is strongly recommended as it reduces the\ncomplexity of using Kubernetes, and most of the\ntools already have an open-source chart you can\nuse on artifacthub.io.\nA.4 Lesson learned and possible\nimprovements\nExtracting text from PDFs is the most valuable\nimprovement we could achieve since it would add\na large amount of high-quality, long correlation\ntext. This would allow for better coherency over\nlong generations and unlock studies in increasing\nthe context length.\nB Dataset processing and analysis\nB.1 Arabic filters\nWe check the default values from (Rae et al., 2021)\nfor the quality and repetition filters and find that\nmost are suitable for Arabic text. We make the\nfollowing modifications:\n• we slightly increase the maximum ellipsis per\nline ratio, to avoid penalyzing shorter samples.\n• we add a minimum average of words per line\nfilter, to eliminate ”list” style samples (e.g.,\nwebsite content menus), as they typically lack\ncoherence.\n• we run several experiments concerning the\nuse or Arabic ”stop words”, in the sense that\na sample must contain a minimum of such\nwords to pass the filter; we find that compared\nto English, due to the nature of the Arabic\nlanguage, for the same minimum stop word\n(e.g., 3) value much larger lists are needed (El-\nKhair, 2017), and we compare three existing\nlists of Arabic stop words 7 8 9 with lengths\n234, 801 and 2276 words, finally using the\nshortest list.\nWe also implement line-wise corrections that\neliminate undesirable lines (e.g., containing social\nmedia counters, likes, navigation buttons), using\ncustom lists both in English and Arabic.\nB.2 Topic distribution\nThe top 150 source URL domains cover approx-\nimately 20% of the samples in our final Arabic\n7https://talkinarabic.com/arabic-words/\n8https://countwordsfree.com/stopwords/arabic\n9https://github.com/mohataher/\narabic-stop-words\npre-training dataset. We manually annotate the\nmain topic corresponding to each domain, follow-\ning a list of 25 topics similar to the main cat-\negories in version 1 of https://cloud.google.\ncom/natural-language/docs/categories. We\nfind news to be the dominant category, accounting\nfor a weighted 65% of the top 150 domains.\nAn interesting claim of Nagoudi et al. (2022)\nwas that, according to human evaluation, their\nmodel seemed to produce human-like output for the\nnews domain. One possible reason for this is that\nthis category seems to be over-represented in the\navailable Arabic data, particularly compared to En-\nglish data (see for comparison the topic distribution\nin Chowdhery et al. (2022)).\nC Evaluation datasets\nFor creating AlGhafa10, our multiple-choice evalu-\nation benchmark for zero- and few-shot evaluation\nof Arabic LLMs, we adapt the following tasks:\n• Belebele Ar MSA : Bandarkar et al. (2023)\n900 entries\n• Belebele Ar Dialects: Bandarkar et al. (2023)\n5400 entries\n• COPA Ar : 89 entries machine-translated\nfrom English and verified by native Arabic\nspeakers. Machine-translated from English\nand Verified by Humans.\n• Facts balanced (based on AraFacts)\nSheikh Ali et al. (2021): 80 entries (after\nbalancing dataset), consisting in a short article\nand a corresponding claim, to be deemed true\nor false.\n• MCQ Exams Ar: Hardalov et al. (2020) 2248\nentries\n• OpenbookQA Ar : 336 entries. Machine-\ntranslated from English and Verified by Hu-\nmans.\n• Rating sentiment (HARD-Arabic-Dataset)\nElnagar et al. (2018): determine the sentiment\nof reviews, with 3 possible categories (pos-\nitive, neutral, negative) transformed to a re-\nview score (1-5) as follows: 1-2 negative, 3\nneutral, 4-5 positive. 6000 entries (2000 for\neach class).\n• Rating sentiment no neutral (HARD-\nArabic-Dataset) (Elnagar et al., 2018): 8000\nentries in which we remove the neutral class\nby extending the positive class (score 1-3).\n8000 entries (4000 for each class).\n10https://gitlab.com/tiiuae/alghafa\n258\n• Sentiment (Abu Farha et al., 2021): 1725\nentries based on Twitter posts, that can be\nclassified as positive, negative, or neutral.\n• SOQAL (Mozannar et al., 2019): grounded\nstatement task to assess in-context reading\ncomprehension, consisting of a context and a\nrelated question; consists of 155 entries with\none original correct answer, transformed to\nmultiple choice task by adding four possible\nhuman-curated incorrect choices per sample.\n• XGLUE (based on XGLUE-MLQA) (Liang\net al., 2020; Lewis et al., 2019): consists of\n155 entries transformed to a multiple choice\ntask by adding 4 human-curated incorrect\nchoices per sample.\n• XQuAD (Artetxe et al., 2019) (Cross-lingual\nQuestion Answering Dataset) used to evaluate\nquestion answering performance among vari-\nous languages. The test set we used contained\n1.19k question-answer pairs in Arabic.\n• MLQA (Lewis et al., 2019) Publicly avail-\nable dataset used to evaluate the Question An-\nswering ability of a model over various lan-\nguages. The test dataset we used contains\n5335 question-answer pairs in Arabic.\n• Ty Di QA (Artetxe et al., 2019) Question An-\nswering dataset with 11 languages containg\n204k pairs of question-answwers. THe test set\nwe used contained 921 question-answer pairs.\n• ARCD (Mozannar et al., 2019) Arabic\nReading Comprehension Dataset (ARCD)\nwhich contains 1,395 questions obtained from\nWikipedia articles. We utilize 702 samples\nwith context, a question related to the contet\nand possible answers to the question.\nWe also evaluated other Arabic datasets, consid-\nering the current size of Arabic models and without\nfine-tuning on the task, zero-shot tests were pro-\nducing near-random results, hence we discarded\nthem from our analysis. The discarted datasets\nwere: hatespeech detection (Seelawi et al., 2021),\noffensive speech detection (Seelawi et al., 2021),\nentailment and contradiction analysis (Liang et al.,\n2020), sarcasm detection (Abu Farha et al., 2021),\nprocessing & question-to-question semantic simi-\nlarity analysis (Seelawi et al., 2021).\nMultiple-choice tasks were built by Arabic\nspeakers by adding the wrong answers. Here an ex-\nample of a modified XGLUE dataset entry, query:\n/charfa/char0a\n/char09/charaf/char10/chare8/char40/char50/charf1/char10/char4a/charbb/char59/charcb/char40/char10/chare8/char58/char41/charee/char44/char11/char85/charfa/charce/charab/char10/char49/charca/char92/char6b /char3a /charfa/char0a/charcd/char41/char10/char4a/charcb/char40 /charc8/char40/char0d/charf1/char82/charcb/char40/char09/chare1/charab /char49/char2e/char6b/char2e/char15/char40\n/charc8/charf0/char0d/char40 /char69/char4a/char2e/char92/char10/char4a/charcb /charf1/char4a/char0a/charbb /charf1/chara3/char10/chare9/charaa/chard3/char41/char67/char2e/char09/chare1/chard3 /char31/char39/char35/char37 /chard0/char41/charab /char5a/char41/char4a/char0a/chard2/char4a/char0a/charba/charcb/char40\n/char41/charee/char44/char0a/charca/charab /charc9/char92/char6d/char1a/char10/char27/char10/chare8/char0d/char40/char51/chard3/char40\n/char40/char50/charf1/char10/char4a/charbb/char59/charcb/char40/charfa/charce/charab/char10/char49/charca/char92/char6b/char10/chare9/char83/char40/char50/char59/charcb/char40/char10/char48/char42/char41/char6d/char2e/chard7/char09/chare1/chard3 /charc8/char41/char6d/char2e/chard7/charf8/char0a\n/char0d/char40 /charfa/char0a\n/char09/charaf\n/char3a /charf1/chareb /char48/char2e/char40/charf1/char6d/char2e/charcc\nChoices:\n/char2c/char10/chare9/char83/char59/char09/char4a/charea/charcb/char40 /char2c /char5a/char41/char4a/char0a/chard2/char4a/char0a/charba/charcb/char40 /char2c/charf1/char4a/char0a/charbb /charf1/chara3 /char2c /chard0/charf1/charca/charaa/charcb/char40 /charc8/char41/char6d/char2e/chard7/char2c/char10/chare9/char4a/char0a/charcb/charf0/char59/charcb/char40/char10/char48/char41/char10/charaf/char43/charaa/charcb/char40\nCorrect Answer:\n/char5a/char41/char4a/char0a/chard2/char4a/char0a/charba/charcb/char40\nC.1 Machine translation and cultural\nrelevancy\nSome of our multi-choice evaluation datasets\n(COPA and OpenBookQA) were translated from\nEnglish to Arabic. This was done by randomly se-\nlecting a subset of the original dataset, performing\nmachine translation using the 3B model from Team\net al. (2022), then having native Arabic speaking\nvolunteers check and correct the translation where\nneeded. We asked our volunteers to also grade an\nautomated translation as directly acceptable or not\n(case in which it was either corrected or rejected).\nOn over 500 questions, we find that only 58% were\nconsidered directly acceptable, and of over 1800\npossible answers (that could consist of one or more\nwords), 75% were marked as directly acceptable.\nAnother concern when choosing to translate\ndatasets from English to Arabic is the cultural rel-\nevancy of the information, which is particularly\nimportant for evaluation datasets. We randomly\nselected 500 items from each of the BoolQ train\nand validation splits and had a human native Ara-\nbic speaker manually rate as cultural relevant or\nnot, obtaining a rate of 82.7% that where deemed\nrelevant for Arabic speakers.\nWe consider that the limited accuracy of auto-\nmated translation models and the intrinsic cultural\ndifferences between English speaking countries\nand other populations represent a major roadblock\nin scaling up LLMs for lower resource languages\nby relying on existing resources for the English\nlanguage.\n259\nfine-tuning dataset none (pretrained) xP3-Ar Bactrian-Ar Alpaca-Ar 10% Ultrachat-Ar\nquestions 42% 15% 83% 86% 83%\nleading sentences 82% 60% 89% 92% 95%\naverage 62% 37.5% 86% 89% 89%\nTable 7: Table showing percentage of accepted answers by a native Arabic speaker for our pre-trained and chat\nfine-tuned 14B models, for prompts formulated as questions and \"leading sentences\", and also the average for the\ntwo categories\nD Fine-tuning\nD.1 Setup\nIn order to improve the chat capability of our model,\nwe fine-tuned the model on various datasets. The\nbest fine tuned model was selected based on hu-\nman feedback. Different fine-tuned versions of\nthe model tested on one or a mixture of datasets\nwere prompted with an array of questions and the\nresponse ranked from 1 to 5 (1 being the lowest/ in-\ncoherent and 5 being the highest/meaningful). The\nspecifics of the datasets used for fine-tuning are\nlisted below:\n• xP3-Ar (Crosslingual Public Pool of Prompts)\n(Muennighoff et al., 2022): includes a collec-\ntion of prompts from 46 languages. We used\nthe already existing Arabic text and machine\ntranslated the English prompts to Arabic. A\ntotal of 1.19M samples were included.\n• Bactrian-Ar (Li et al., 2023): The Arabic ver-\nsion of Bactrian11 with 67k samples.\n• Alpaca-Ar (Taori et al., 2023): The Arabic\nversion of the Alpaca dataset12 with 52k sam-\nples. The whole dataset was used to fine-tune\nour model for downstream conversation tasks.\n• 10% UltraChat-Ar (Ding et al., 2023): we\nused 10% of the Ultrachat dataset (150k sam-\nples) for fine-tuning a chat version of our 14B\nmodel, after machine translating it from En-\nglish to Arabic.\nWe perform human evaluation of the pre-trained\nand fine-tuned models. We select six categories\n(education, health, technology, history, creativity,\noil and gas) and for each we create ten questions\nand ten equivalent \"leading sentences\", having 120\nprompts in total. A leading sentence is a way to\nreformulate a question as the beginning of an an-\nswer, which tends to provide better results for pre-\ntrained models. For each prompt, we randomly\n11https://huggingface.co/datasets/MBZUAI/\nBactrian-X\n12https://github.com/PhoebusSi/alpaca-CoT\ngenerate 5 completions from the each model, with\nmaximum length 100 tokens and temperature 0.7.\nWe ask one native Arabic speaker to evaluate the\nfive completions for each prompt and select how\nmany (from 0 to 5) are acceptable answer, where an\nacceptable answer is defined as relevant, grammat-\nically correct and factually accurate. The results,\npresented in Table 7, show that the fine-tuned mod-\nels using either Alpaca-Ar or 10% of UltraChat\nmachine translated to Arabic obtain the highest per-\ncentage of accepted answers. We present examples\nof prompt-pair answers using the pre-trained model\n(see Tables 10 and 8) and the model fine-tuned with\n10% of UltraChat-Ar (see Tables 11 and 9).\n260\nPrompt (Leading Sentences) Best Answer [Pre-trained version]\n/charf9/char0a/chareb/char10/char48/char40/char50/char41/chard3/char42/char40 /charfa/char0a\n/char09/charaf /char50/char41/charbe/char10/char4a/char4b/char2e/char42/char40/char10/char48/char42/char41/char6d/char2e/chard7 /char2c /char5a/char41/char09/char92/char09/charae/charcb/char40 /char3a /char51/chare5/char94/char6d/charcc/char27/char40 /char42 /charc8/char41/char11/char4a/chard6/charcf/char40 /charc9/char4a/char0a/char1c/char2e/char83/charfa/charce/charab /char41/charee/char09/char44/chard3/charf0 /char2c /char40/char59/char67/char2e/char10/chare9/charab/charf1/char09/char4a/char10/char4a/chard3/char10/char48/char42/char41/char6d/char2e/chard7\n/char2c/char10/chare9/char4a/char0a/charbb/char09/char59/charcb/char40/char09/chare0/char59/chard6/charcf/char40/charf0 /char2c /charc9/char10/charae/char09/char4a/charcb/char40/charf0 /char2c/char10/chare9/char4a/char0a/char09/char4a/char10/charae/char10/char4a/charcb/char40/charf0 /char2c/char10/chare9/char6a/char92/charcb/char40/charf0 /char2c /chard5/chare6/char0a/charca/charaa/char10/char4a/charcb/char40/charf0 /char2c/char10/chare8/char58/char59/char6a/char2e/char10/char4a/chard6/charcf/char40/char10/chare9/char10/charaf/char41/chara2/charcb/char40/charf0\n/char2c/char10/chare9/charcb/charf0/char59/charcb/char40 /char41/charee/char44/char0a/charca/charab /charc9/chard2/charaa/char10/char4b /charfa/char0a/char10/chare6/charcb/char40/char10/char48/char42/char41/char6a/char2e/chard6/charcf/char40 /charfa/char0a\n/char09/charaf /chara8/charf1/char09/char4a/char10/char4a/charcb/char40 /char40/char09/char59/chareb /char2e /char41/chareb/char51/char1e/char0a/char09/charab/charf0\n/char50/char41/charbe/char09/charaf/char42/char40/char10/chare9/char4b/char0a/char41/charab/char50/charfa/charce/charab /charc9/chard2/charaa/char10/char4b /char2c /char50/char41/charbe/char10/char4a/char4b/char2e/char42/char41/char4b/char2e/char10/chare9/char93/char41/char09/char67/char10/char48/char41/char09/char4a/char09/char93/char41/char67 /char58/charf1/char6b/char2e/charf0 /char49/char2e/char6b/char2e/charf1/char10/char4a/char82/char1d/char0a\n/char2c/char10/chare9/char09/char4a/chard3/char42/char40/charf0/char10/chare9/char09/char4a/char09/char93/char41/char6d/charcc/char27/char40/char10/chare9/char0d/char4a/char1c/char0a/char4a/char2e/charcb/char40 /chard1/charea/charcb /char51/char09/charaf/charf1/char10/char4b/charf0 /char2c /char41/charee/char45/char2e/char41/char6d/char19/char95/char40 /char59/char4a/char0a/char4b/char2e/char09/char59/char09/char67/char41/char10/char4b/charf0 /char2c/char10/chare9/char4a/char0a/charab/char40/char59/char4b/char2e/char42/char40\n/char80/charf1/chard2/charca/chard3 /chara9/char10/charaf/char40/charf0 /charfa/charcd/char40 /char41/charea/charca/char4b/char0a/charf1/char6d/char1a/char10/char27/charf0 /chard1/charee/char10/char45/char40/char50/char41/charbe/char10/char4a/char4b/char2e/char40/char10/char87/char4a/char0a/char10/charae/char6d/char1a/char10/char27/char09/chare1/chard3 /char40/charf1/char09/char4a/charba/chard2/char10/char4a/char4b/char0a/charfa/char0a/charbb\n/charf1/chareb /char51/chareb/char41/char4b/char2e/charc9/char4a/char2e/char10/charae/char10/char4a/char82/chard3/char09/chare0/char41/chard2/char09/char92/charcb/char10/chare9/charaa/chard3/char41/char6d/char2e/charcc/char27/char40 /charfa/char0a\n/char09/charaf /chare9/char10/char4a/char83/char40/char50/char59/charcb /char91/char92/char09/char6d/char1a/char10/char27/charc9/char09/char92/char09/charaf/char0d/char40 /char50/char41/char4a/char0a/char10/char4a/char09/char6b/char40/char09/chare0/char40/char11/char49/char4a/char0a/char6b /char2c /charc8/char41/char10/charae/chard6/charcf/char40 /char40/char09/char59/chareb /charfa/char0a\n/char09/charaf /chard5/charba/charcb /chare9/chard3/char59/char10/charae/char09/char4a/char83 /char41/chard3\n/char09/chare0/char40 /char49/char2e/charcb/char41/chara2/charcb/char40/charfa/charce/charab /char49/char2e/char6d/char2e/char1a/char27/char0a/charfa/char0a/char10/chare6/charcb/char40 /char50/charf1/chard3/char42/char40/char09/chare1/chard3/char10/chare9/charaa/chard3/char41/char6d/char2e/charcc/char27/char40 /charfa/char0a\n/char09/charaf /char49/char2e/char83/char41/char09/char4a/chard6/charcf/char40 /char91/char92/char09/char6a/char10/char4a/charcb/char40\n/char10/chare8/char51/charba/char09/charaf /chara9/char10/charaf/charf1/chard3 /charc8/char43/char09/char67/char09/chare1/chard3/charf0 /char2c/char10/chare9/charaa/chard3/char41/char6d/char2e/charcc/char27/char40 /charfa/char0a\n/char09/charaf /chard5/chare7/char27/char0a/char59/char10/charae/char10/char4a/charcb/char40 /charc9/char4a/char2e/char10/charaf /char41/charee/char45/char2e/char10/chare9/char4b/char0a/char40/char50/char58/charfa/charce/charab/char09/chare0/charf1/charba/char4b/char0a\n/charc8/char41/char10/charae/chard6/charcf/char40 /char51/chare5/char95/char41/char09/char4a/charab /char2e/char10/chare9/char4a/char0a/charaa/chard3/char41/char6d/char2e/charcc/char27/char40/char10/char48/char41/char92/char92/char09/char6a/char10/char4a/charcb/char40 /charc9/char09/char92/char09/charaf/char40/charfa/charce/charab /chard5/charba/char09/charaf/char51/charaa/char09/char4a/char83\n/char49/char2e/char09/charab/char51/char4b/char0a/charf8/char0a/char09/char59/charcb/char40 /charf9/char0a/charaa/chard3/char41/char6d/char2e/charcc/char27/char40 /char91/char92/char09/char6a/char10/char4a/charcb/char40 /charfa/char0a\n/char09/charaf /char51/char09/charaf/charf1/char10/char4a/char10/char4b/char09/chare0/char40 /char49/char2e/char6d/char2e/char1a/char27/char0a/charfa/char0a/char10/chare6/charcb/char40/char51/char1e/char0a/char4b/char0a/char41/charaa/chard6/charcf/char40/char09/char91/charaa/char4b/char2e/charbc/char41/char09/char4a/chareb\n/char41/charea/chard2/chareb/char40/char09/chare1/chard3/charf0 /char2c /chare9/char10/char4a/char83/char40/char50/char58 /charfa/char0a\n/char09/charaf /char49/char2e/charcb/char41/chara2/charcb/char40\n/char49/char2e/char09/charab/char51/char4b/char0a/charf8/char0a/char09/char59/charcb/char40 /charf9/char0a/charaa/chard3/char41/char6d/char2e/charcc/char27/char40 /char91/char92/char09/char6a/char10/char4a/charcb/char40 /charfa/char0a\n/char09/charaf /char51/char09/charaf/charf1/char10/char4a/char10/char4b/char09/chare0/char40 /char49/char2e/char6d/char2e/char1a/char27/char0a/charfa/char0a/char10/chare6/charcb/char40/char51/char1e/char0a/char4b/char0a/char41/charaa/chard6/charcf/char40/char09/char91/charaa/char4b/char2e/charbc/char41/char09/char4a/chareb\n/char41/charea/chard2/chareb/char40/char09/chare1/chard3/charf0 /char2c /chare9/char10/char4a/char83/char40/char50/char58 /charfa/char0a\n/char09/charaf /char49/char2e/charcb/char41/chara2/charcb/char40\n/char49/char2e/char09/charab/char51/char4b/char0a/charf8/char0a/char09/char59/charcb/char40 /charf9/char0a/charaa/chard3/char41/char6d/char2e/charcc/char27/char40 /char91/char92/char09/char6a/char10/char4a/charcb/char40 /charfa/char0a\n/char09/charaf /char51/char09/charaf/charf1/char10/char4a/char10/char4b/char09/chare0/char40 /char49/char2e/char6d/char2e/char1a/char27/char0a/charfa/char0a/char10/chare6/charcb/char40 /char50/charf1/chard3/char42/char40/char09/char91/charaa/char4b/char2e/charbc/char41/char09/char4a/chareb\n/char41/charea/chard2/chareb/char40/char09/chare1/chard3/charf0 /char2c /chare9/char10/char4a/char83/char40/char50/char58 /charfa/char0a\n/char09/charaf /char49/char2e/charcb/char41/chara2/charcb/char40\n/charc8/char43/char09/char6d/char1a/char09/char27/char09/chare1/chard3/char09/chare1/char1e/char0a/char09/charae/char09/chara3/charf1/chard6/charcf/char40 /charf8/char59/charcb /char50/char41/charbe/char10/char4a/char4b/char2e/char42/char40/charf0 /chara8/char40/char59/char4b/char2e/char42/char0d/char40/char10/chare9/char09/charaf/char41/char10/charae/char11/char4b/char09/char50/char09/char51/charab/char0d/char40 /chard1/charea/charcb /char69/char4a/char0a/char10/char1c/char10/char4b /charfa/char0a/char10/chare6/charcb/char40/char10/chare9/char4a/char2e/char83/char41/char09/char4a/chard6/charcf/char40/char10/chare9/char0d/char4a/char1c/char0a/char4a/char2e/charcb/char40/charf0 /char58/char50/char40/charf1/chard6/charcf/char40/charf0 /char49/char2e/char4b/char0a/char50/char59/char10/char4a/charcb/char40/char51/char1e/char0a/char09/charaf/charf1/char10/char4b\n/char2c/char10/chare9/charcb/char41/charaa/char09/charaf/char10/char86/char51/char09/charaf /charfa/char0a\n/char09/charaf /charc9/chard2/charaa/charcb/char40/charfa/charce/charab/char09/chare1/char1e/char0a/char09/charae/char09/chara3/charf1/chard6/charcf/char40/char10/char48/char40/char50/char59/char10/charaf/char09/char51/char4b/char0a/char09/char51/charaa/char10/char4b /charfa/charcd/char40 /charf9/charaa/char83/char40 /char41/chard2/charbb /char2e/char09/charac/char51/chare5/char94/char10/char4a/charcb/char40/charf0/char51/char1e/char0a/charba/char09/charae/char10/char4a/charcb/char40/char10/chare9/char4b/char0a/char51/char6b\n/char2c /charc9/chard2/charaa/charcb/char40 /char5a/char40/char58/char40 /charfa/char0a\n/char09/charaf/char10/chare9/char4a/char0a/charcb/char41/charab/char10/chare8/char58/charf1/char6b/char2e/char09/chare0/char41/chard6/charde/char09/char95/charf0 /char2c/char10/chare9/chard3/charf1/char83/char51/chard6/charcf/char40/char09/charac/char40/char59/chareb/char42/char40/char10/char87/char4a/char0a/char10/charae/char6d/char1a/char10/char27/char09/charac/char59/charee/char45/char2e\n/char2e /chare9/char6b/char2e/charf0 /charc9/chard2/charbb /char40/charfa/charce/charab /char41/char09/char4a/char4a/char0a/charcb/char40/char10/chare9/charca/charbf /charf1/chard6/charcf/char40 /chard0/char41/charea/chard6/charcf/char40/char10/chare9/char4b/char0a/char58/char41/char10/char4b/charf0\n/char10/chare9/char4a/char2e/chareb /charf1/chareb /chard0/char0d/char40 /chara8/char40/char59/char4b/char2e/char42/char0d/char40/char09/chare1/char10/charae/charca/char4b/char0a /chare9/char3c/charcb/char40/charf0 /char29 /char3a /charfa/charcd/char41/charaa/char10/char4b /charc8/char41/char10/charaf /char3f /chare8/char58/char41/char4a/char2e/charab/char09/chare1/chard3 /char5a/char41/char11/char82/char1d/char0a/char09/chare1/chard6/charcf/char41/charee/char44/char2e/charee/char45/char0a/chare9/char3c/charcb/char40/char09/chare1/chard3\n/chara9/chard2/char82/charcb/char40 /chard5/charba/charcb /charc9/charaa/char6b/char2e/charf0 /char41/char0d/char4a/char1c/char0a/char11/char83/char09/chare0/charf1/chard2/charca/charaa/char10/char4b /char42 /chard5/charba/char10/char4b/char41/charea/chard3/char40/char09/chare0/charf1/chara2/char1d/char2e/char09/chare1/chard3 /chard5/charba/char6b/char2e/char51/char09/char6b/char40\n/char2e /char28/char09/chare0/charf0/char51/charba/char11/char82/char10/char1d /chard5/charba/charca/charaa/charcb/char10/chare8/char59/char0d/char4a/char09/charaf/char42/char40/charf0 /char50/char41/char92/char1d/char2e/char42/char40/charf0\n/charfa/char0a/chare6/char2e/charca/char83 /chard0/char0d/char40 /charfa/char0a/char47/char2e/char41/char6d/char2e/char1a/char27/char0a/char40/char0d/chard5/chare6/char0a/charca/charaa/char10/char4a/charcb/char40/charfa/charce/charab /charfa/char0a/charab/char41/char09/char4a/chara2/char93/char42/char40 /char5a/char41/charbf/char09/char59/charcb/char40/char51/char1e/char0a/char11/char4b/char0d/char41/char10/char4b /char40/char09/char51/char6a/char2e/char10/char4a/char4b/char0a/char42 /char5a/char09/char51/char6b/char2e/char69/char4a/char2e/char93/char40 /charfa/char0a/charab/char41/char09/char4a/chara2/char93/char42/char40 /char5a/char41/charbf/char09/char59/charcb/char40 /char3f\n/charfa/char0a/charab/char41/char09/char4a/chara2/char93/char42/char40 /char5a/char41/charbf/char09/char59/charcb/char40/char09/chare0/char40/char10/char48/char41/char83/char40/char50/char59/charcb/char40/char10/char49/char10/char4a/char1c/char2e/char11/char4b/char40 /char59/char10/charae/char09/charaf /char2c/char10/chare9/char4a/char0a/chard3/charf1/char4a/char0a/charcb/char40 /char41/char09/char4a/char10/char4b/char41/char4a/char0a/char6b/char09/chare1/chard3\n/char51/char1e/char0a/char11/char4b/char41/char10/char4a/charcb/char40 /char40/char09/char59/chareb/char09/chare0/charf1/charba/char4a/char0a/char83 /charc9/chareb/char09/chare1/charba/charcb/charf0 /char2c /chard5/chare6/char0a/charca/charaa/char10/char4a/charcb/char40/charfa/charce/charab /charfa/char0a/char47/char2e/char41/char6d/char2e/char1a/char27/char0a/char40/char51/char1e/char0a/char11/char4b/char41/char10/char4b /chare9/charcb/char09/chare0/charf1/charba/char4a/char0a/char83\n/char2c /charc8/char41/char10/charae/chard6/charcf/char40 /char40/char09/char59/chareb /charfa/char0a\n/char09/charaf /chare9/char4a/char0a/charca/charab/char09/charac/char51/charaa/char10/char4a/char09/char1c/char83 /char41/chard3 /char40/char09/char59/chareb /char3f /charfa/char0a/chare6/char2e/charca/char83 /chard0/char40 /charfa/char0a/char47/char2e/char41/char6d/char2e/char1a/char27/char0a/char40\n/char2e /chard5/chare6/char0a/charca/charaa/char10/char4a/charcb/char40/charfa/charce/charab /charfa/char0a/charab/char41/char09/char4a/chara2/char93/char42/char40 /char5a/char41/charbf/char09/char59/charcb/char40/char51/char1e/char0a/char11/char4b/char41/char10/char4b/char10/chare9/char4a/char0a/char09/charae/char4a/char0a/charbb/charfa/charce/charab/char09/charac/char51/charaa/char10/char4a/char09/char1c/char83 /char41/chard2/charbb\nTable 8: Best Answers from the \"Leading Sentence\" style prompts from the pre-trained model.\n261\nPrompt (Leading Sentences) Best Answer [Fine-tuned version]\n/char3a/char50/charf1/char09/char4b /charf9/char0a/chareb/char10/char48/char40/char50/char41/chard3/char42/char40 /charfa/char0a\n/char09/charaf /char50/char41/charbe/char10/char4a/char4b/char2e/char42/char40/char10/char48/char42/char41/char6d/char2e/chard7/char3a /chard0/char59/char09/char6a/char10/char4a/char82/chard6/charcf/char40 /chara9/char4b/char0a/charf1/char09/char4a/char10/char4b/charfa/charce/charab/char10/chare8/char59/char6a/char10/char4a/chard6/charcf/char40/char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40/char10/char48/char40/char50/char41/chard3/char42/char40/char10/chare9/charcb/charf0/char58 /charc9/chard2/charaa/char10/char4b /char3a/char10/chare8/char58/char59/char6a/char2e/char10/char4a/chard6/charcf/char40/char10/chare9/char10/charaf/char41/chara2/charcb/char40 /char2e/char31\n/charc9/char11/char4a/chard3/char10/chare8/char58/char59/char6a/char2e/char10/char4a/chard6/charcf/char40/char10/chare9/char10/charaf/char41/chara2/charcb/char40 /char50/char58/char41/char92/chard3 /charfa/char0a\n/char09/charaf /char50/char41/chard2/char11/char4a/char10/char1c/char83/char42/char40 /charc8/char43/char09/char67/char09/chare1/chard3 /char41/charee/char45/char0a/char59/charcb/char10/chare9/char10/charaf/char41/chara2/charcb/char40 /char6c/char2e/char1a/char27/char0a/char09/char51/chard3\n/charc9/char10/charae/char09/char4a/charcb/char40 /char2e/char32 /char2e/char10/chare9/char4a/char0a/char09/char93/char50/char42/char40/char10/chare9/char4b/char0a/char50/char40/char51/char6d/charcc/char27/char40/char10/chare9/char10/charaf/char41/chara2/charcb/char40/charf0/char10/chare9/char4a/char0a/char0d/char4b/char41/chard6/charcf/char40/char10/chare9/char10/charaf/char41/chara2/charcb/char40/charf0 /char68/char41/char4b/char0a/char51/charcb/char40/char10/chare9/char10/charaf/char41/chara3/charf0/char10/chare9/char4a/char0a/char82/chard2/char11/char82/charcb/char40/char10/chare9/char10/charaf/char41/chara2/charcb/char40\n/chard0/char40/char59/char10/char4a/char82/chard6/charcf/char40 /charc9/char10/charae/char09/char4a/charca/charcb/char10/chare9/char4a/char0a/char10/char4a/char6a/char10/char4a/charcb/char40/char10/chare9/char4a/char0a/char09/char1c/char4a/char2e/charcb/char40 /charfa/char0a\n/char09/charaf/char10/chare8/char59/char6a/char10/char4a/chard6/charcf/char40/char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40/char10/char48/char40/char50/char41/chard3/char42/char40/char10/chare9/charcb/charf0/char58/char10/char48/char51/chard2/char11/char4a/char10/char1c/char83/char40 /char3a /chard0/char40/char59/char10/char4a/char82/chard6/charcf/char40\n/char10/chare9/charcb/charf0/char58 /char51/chard2/char11/char4a/char10/char1c/char82/char10/char1d /char3a /char41/char4a/char0a/char6b/char2e/charf1/charcb/charf1/char09/char4a/charba/char10/char4a/charcb/char40 /char2e/char33 /char2e/char10/chare9/char4a/char0a/char0d/char4b/char41/char4b/char2e/char51/charea/charba/charcb/char40/char10/char48/char41/char4a/char2e/charbb /char51/chard6/charcf/char40/charf0/char10/chare9/char4a/char0a/charbb/char09/char59/charcb/char40 /charc9/char10/charae/char09/char4a/charcb/char40/char10/chare9/chard2/char09/chara2/char09/char1d/char40/charf0 /char2c /charfa/char0a/char47/char2e/char58 /charf0/char51/char10/char1e/chard3 /charc9/char11/char4a/chard3\n/charfa/char0a/charab/char41/char09/char4a/chara2/char93/char42/char40 /char5a/char41/charbf/char09/char59/charcb/char40 /charc9/char11/char4a/chard3/char10/chare9/chard3/char59/char10/charae/char10/char4a/chard6/charcf/char40/char10/char48/char41/char4a/char0a/char09/char4a/char10/charae/char10/char4a/charcb/char40 /charfa/char0a\n/char09/charaf/char10/chare8/char59/char6a/char10/char4a/chard6/charcf/char40/char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40/char10/char48/char40/char50/char41/chard3/char42/char40\n/char3a/char10/chare9/char4a/char0a/char6a/char92/charcb/char40/char10/chare9/char4b/char0a/char41/charab/char51/charcb/char40 /char2e/char34 /char2e /char41/charee/char10/char45/char41/charab/char41/char09/char4a/char93/char10/chare9/char4a/char0a/char6b/char2e/char41/char10/char4a/char09/char4b/char40/charf0/char10/chare8/char5a/char41/char09/charae/charbb/char09/chare1/char1e/char0a/char82/char6a/char10/char4a/charcb /char5a/char41/char4a/char0a/char11/char83/char42/char40/char10/char49/char09/char4b/char51/char10/char1e/char09/char4b/char40/charf0/char10/char48/char41/char10/char4b/charf1/char4b/char2e/charf0/char51/charcb/char40/charf0\n/char09/chare1/charab /char49/char2e/char1c/char0a/char4a/char2e/chara2/char10/char4a/charcb/char40 /charc9/char11/char4a/chard3/char10/chare8/char51/charba/char10/char4a/char4a/char2e/chard6/charcf/char40/char10/chare9/char4a/char0a/char6a/char92/charcb/char40/char10/chare9/char4b/char0a/char41/charab/char51/charcb/char40/char10/char48/char40/char50/char58/char41/char4a/char2e/chard3 /charfa/char0a\n/char09/charaf/char10/chare8/char59/char6a/char10/char4a/chard6/charcf/char40/char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40/char10/char48/char40/char50/char41/chard3/char42/char40/char10/chare9/charcb/charf0/char58 /char51/chard2/char11/char4a/char10/char1c/char82/char10/char1d\n/char09/chare0/char41/chard2/char09/char92/charcb/char10/chare9/charaa/chard3/char41/char6d/char2e/charcc/char27/char40 /charfa/char0a\n/char09/charaf /chare9/char10/char4a/char83/char40/char50/char59/charcb /char91/char92/char09/char6d/char1a/char10/char27/charc9/char09/char92/char09/charaf/char0d/char40 /char3a /chard0/char59/char09/char6a/char10/char4a/char82/chard6/charcf/char40\n/char3a/char50/charf1/char09/char4b /charf1/chareb /char51/chareb/char41/char4b/char2e/charc9/char4a/char2e/char10/charae/char10/char4a/char82/chard3\n/charfa/charce/charab /char40/char58/char41/chard2/char10/char4a/charab/char40/char10/chare9/charaa/chard3/char41/char6d/char2e/charcc/char27/char40 /charfa/char0a\n/char09/charaf /char41/charee/char10/char44/char83/char40/char50/char58 /charbd/char4a/char0a/charca/charab /char49/char2e/char6d/char2e/char1a/char27/char0a/charfa/char0a/char10/chare6/charcb/char40/char10/char48/char41/char92/char92/char09/char6a/char10/char4a/charcb/char40 /charc9/char09/char92/char09/charaf/char40/char09/charad/charca/char10/char4a/char09/char6d/char1a/char10/char27/char59/char10/charaf\n/char3a /char41/charee/char10/char45/char41/charab/char40/char51/chard3 /char49/char2e/char6d/char2e/char1a/char27/char0a/charfa/char0a/char10/chare6/charcb/char40/char10/chare9/charaa/char0d/char4b/char41/char11/char82/charcb/char40/char10/char48/char41/char92/char92/char09/char6a/char10/char4a/charcb/char40/char09/char91/charaa/char4b/char2e/charbd/char4a/char0a/charcb/char40 /char2c /charbd/charcb/char09/char58 /chara9/chard3/charf0 /char2e/char10/chare9/char4a/char0a/char09/char4a/charea/chard6/charcf/char40 /charbd/char09/charaf/char40/char59/chareb/char40/charf0 /charbd/char10/char4b/char41/chard3/char41/chard2/char10/char4a/chareb/char40\n/char59/char4b/char0a/char59/charaa/charcb/char40 /charc9/chard2/char11/char82/char1d/char0a/chara9/char83/char40/charf0 /charc8/char41/char6d/char2e/chard7/char10/chare9/char83/char59/char09/char4a/charea/charcb/char40 /char3a/char10/chare9/char83/char59/char09/char4a/charea/charcb/char40 /char2e/char31\n/char10/chare9/char4a/char0a/char0d/char4b/char41/char4a/char0a/chard2/char4a/char0a/charba/charcb/char40/charf0/char10/chare9/char4a/char0a/char09/char4b/char59/chard6/charcf/char40/charf0/char10/chare9/char4a/char0a/charba/char4a/char0a/char09/char4b/char41/charbe/char4a/char0a/chard6/charcf/char40/charf0/char10/chare9/char4a/char0a/char0d/char4b/char41/char4b/char2e/char51/charea/charba/charcb/char40/char10/chare9/char83/char59/char09/char4a/charea/charcb/char40 /charbd/charcb/char09/char58 /charfa/char0a\n/char09/charaf /char41/chard6/chardf/char2e/char2c/char10/char48/char41/char92/char92/char09/char6a/char10/char4a/charcb/char40/char09/chare1/chard3\n/char10/chare8/char51/char1e/char0a/char4a/char2e/charbb /char41/char93/char51/char09/charaf /char51/char09/charaf/charf1/char10/char4b/charf0 /charc9/chard2/charaa/charcb/char40/char10/char86/charf1/char83 /charfa/char0a\n/char09/charaf/char51/char1e/char0a/char4a/char2e/charbb /char51/char4b/char0a/char59/char10/charae/char10/char4a/char4b/char2e/char10/char48/char41/char92/char92/char09/char6a/char10/char4a/charcb/char40 /chare8/char09/char59/chareb /charf9/char09/chara2/char6d/char1a/char10/char27/char2e/char09/chare0/char40/char51/char1e/char0a/chara2/charcb/char40/char10/chare9/char83/char59/char09/char4a/chareb/charf0\n/charf9/char0a/chard4/char10/charaf/char51/charcb/char40 /chard0/charf1/char4a/char0a/charcb/char40 /chard5/charcb/char41/charab /charfa/char0a\n/char09/charaf/char10/chare9/char4a/char0a/chard2/chareb/char42/char40/char09/chara9/charcb/char41/char4b/char2e/char40/char51/chard3/char40 /char91/char92/char09/char6a/char10/char4a/charcb/char40 /char40/char09/char59/chareb /char59/charaa/char4b/char0a/char3a/char51/char10/char4b/charf1/char4a/char0a/char4a/char2e/chard2/charba/charcb/char40 /chard0/charf1/charca/charab /char2e/char32 /char2e /charf9/char0a\n/char09/charae/char4a/char0a/char09/chara3/charf1/charcb/char40 /charf1/chard2/char09/char4a/charca/charcb\n/char2c/char10/chare9/char6d/char2e/chard7/char51/char1e/char2e/charcb/char40/char10/char48/char41/char09/charaa/charcb /charc9/chard2/char11/char82/char1d/char0a/charf0 /char2e /char41/char4a/char0a/char6b/char2e/charf1/charcb/charf1/char09/char4a/charba/char10/char4a/charcb/char40/charfa/charce/charab/char10/char48/char41/charab/char41/char09/char4a/char92/charcb/char40/char09/chare1/chard3 /char59/char4b/char0a/char59/charaa/charcb/char40 /char59/chard2/char10/char4a/charaa/char10/char4b/char11/char49/char4a/char0a/char6b\n/char09/chare1/chard3/char42/char40/charf0 /char2c /charfa/char0a/charab/char41/char09/char4a/chara2/char93/char42/char40 /char5a/char41/charbf/char09/char59/charcb/char40/charf0 /char2c/char10/char48/char41/char09/char4b/char41/char4a/char0a/char4a/char2e/charcb/char40 /chard0/charf1/charca/charab/charf0\n/char50/char41/charbe/char10/char4a/char4b/char2e/char42/char40/charf0 /chara8/char40/char59/char4b/char2e/char42/char0d/char40/char10/chare9/char09/charaf/char41/char10/charae/char11/char4b/char09/char50/char09/char51/charab/char0d/char40 /char3a /chard0/char59/char09/char6a/char10/char4a/char82/chard6/charcf/char40\n/char3a/char50/charf1/char09/char4b /charc8/char43/char09/char67/char09/chare1/chard3/char09/chare1/char1e/char0a/char09/charae/char09/chara3/charf1/chard6/charcf/char40 /charf8/char59/charcb\n/char10/chare9/charbb /char50/char41/char11/char82/chard3 /charfa/char0a\n/char09/charaf/char10/chare9/char6b/char40/char51/charcb/char41/char4b/char2e/char09/chare0/charf1/char09/charae/char09/chara3/charf1/chard6/charcf/char40 /char41/charee/char44/char0a/char09/charaf /char51/charaa/char11/char82/char1d/char0a/char10/chare9/char0d/char4a/char1c/char0a/char4b/char2e/char10/char87/charca/char09/char67 /char3a /char68/charf1/char10/char4a/char09/charae/chard6/charcf/char40 /charc9/char93/char40/charf1/char10/char4a/charcb/char40 /chara9/char4a/char0a/char6a/char2e/char11/char82/char10/char1d /char2e/char31\n/charfa/char0a/charab/char41/chard2/char6d/char2e/charcc/char27/char40 /charc9/chard2/charaa/charcb/char40/charf0/char09/chare0/charf0/char41/charaa/char10/char4a/charcb/char40/char10/chare9/char09/charaf/char41/char10/charae/char11/char4b/char09/char51/char4b/char0a/char09/char51/charaa/char10/char4b /char2e /chard5/charba/char6d/charcc/char27/char40/char09/chare1/chard3/char09/charac/charf1/char09/char6b/char09/chare0/charf0/char58 /chard1/chareb/char50/char41/charbe/char09/charaf/char40/charf0 /chard1/chareb/char50/char41/charbe/char09/charaf/char40\n/char2e/char32 /char2e /chara9/char4b/char0a/char50/char41/char11/char82/chard6/charcf/char40 /charfa/char0a\n/char09/charaf /char41/charaa/chard3 /charc9/chard2/charaa/charcb/char40/charfa/charce/charab/char09/chare1/char1e/char0a/char09/charae/char09/chara3/charf1/chard6/charcf/char40 /chara9/char4a/char0a/char6a/char2e/char11/char82/char10/char1d /charc8/char43/char09/char67/char09/chare1/chard3\n/char09/chare0/charf1/chard3/char59/char10/charae/char4b/char0a/char09/chare1/char4b/char0a/char09/char59/charcb/char40/char09/chare1/char1e/char0a/char09/charae/char09/chara3/charf1/chard2/charca/charcb /char51/char4b/char0a/char59/char10/charae/char10/char4a/charcb/char40/charf0/char10/char48/char41/char4a/char0a/char10/charaf/char51/char10/char1e/charcb/char40/charf0/char10/char48/char41/char09/charaf/char41/charbe/chard6/charcf/char40 /charc9/char11/char4a/chard3/char09/char51/char09/charaf/char40/charf1/char6b /chard5/chare7/char27/char0a/char59/char10/charae/char10/char4b /char3a/char09/char51/char09/charaf/char40/charf1/char6d/charcc/char27/char40 /chard5/chare7/char27/char0a/char59/char10/charae/char10/char4b\n/char68/char2e/char50/char41/char09/char67/char51/char1e/char0a/charba/char09/charae/char10/char4a/charcb/char40/char10/chare9/charca/char93/char40/charf1/chard3/charfa/charce/charab/char09/chare1/char1e/char0a/char09/charae/char09/chara3/charf1/chard6/charcf/char40/char09/char51/char09/charae/char6d/char1a/char27/char0a/char40/char09/char59/chareb/charf0 /char2e/char10/chare8/char51/charba/char10/char4a/char4a/char2e/chard3 /char40/char50/char41/charbe/char09/charaf/char40\n/char58/char50/char40/charf1/chard6/charcf/char41/char4b/char2e/char09/chare1/char1e/char0a/char09/charae/char09/chara3/charf1/chard6/charcf/char40 /char59/char4b/char0a/charf0/char09/char51/char10/char4b /char3a /char58/char50/char40/charf1/chard6/charcf/char40/char51/char1e/char0a/char09/charaf/charf1/char10/char4b /char2e/char33 /char2e/char10/chare8/char59/char4b/char0a/char59/char67/char2e/char50/char41/charbe/char09/charaf/char40 /char51/char4b/char0a/charf1/chara2/char10/char1d/charf0/char10/char86/charf0/char59/char09/char4a/char92/charcb/char40\n/char49/char2e/char4b/char0a/char50/char59/char10/char4a/charcb/char40/charf0 /char41/char4a/char0a/char6b/char2e/charf1/charcb/charf1/char09/char4a/charba/char10/char4a/charcb/char40 /charfa/charcd/char40 /charc8/charf1/char93/charf1/charcb/char40 /charbd/charcb/char09/char58 /charc9/chard2/char11/char82/char1d/char0a/charf0 /char2e /chard1/chareb/char50/char41/charbe/char09/charaf/char40/char09/char59/char4a/char0a/char09/charae/char09/char4a/char10/char4a/charcb /char41/charee/char09/char45/charf1/char6b/char2e/char41/char10/char4a/char6d/char1a/char27/char0a/charfa/char0a/char10/chare6/charcb/char40\n/char09/chare1/char4b/char0a/char09/char59/charcb/char40/char09/chare1/char1e/char0a/char09/charae/char09/chara3/charf1/chard6/charcf/char40/char10/char48/char41/char67/char41/char6a/char2e/char09/char4a/char4b/char2e/charc8/char41/char09/charae/char10/char4a/char6b/char42/char40 /char3a/char10/char48/char41/char67/char41/char6a/char2e/char09/char4a/charcb/char41/char4b/char2e/charc8/char41/char09/charae/char10/char4a/char6b/char42/char40 /char2e/char34 /char2e/char10/char48/char40/char59/charaa/chard6/charcf/char40/charf0\n/char3a/char50/charf1/char09/char4b/char10/chare9/char4a/char2e/chareb /charf1/chareb /chard0/char0d/char40 /chara8/char40/char59/char4b/char2e/char42/char0d/char40/char09/chare1/char10/charae/charca/char4b/char0a/char3a /chard0/char59/char09/char6a/char10/char4a/char82/chard6/charcf/char40 /char09/chare0/charf1/charba/char10/char4b/char09/chare0/char40/char09/chare1/charba/chard6/chardf /char0a/char2e /char41/charaa/chard3/char09/chare1/char1e/char0a/char09/char4a/char11/char4b/char42/char40/char09/chare1/chard3 /char6c/char2e/char1a/char27/char0a/char09/char51/chard3 /chara9/char10/charaf/char40/charf1/charcb/char40 /charfa/char0a\n/char09/charaf /charf1/chareb /chara8/char40/char59/char4b/char2e/char42/char40\n/char10/char48/char43/charbe/char11/char82/chard6/charcf/char40 /charc9/char67/charfa/charce/charab/char10/chare8/char50/char59/char10/charae/charcb/char40 /charc9/char11/char4a/chard3 /char2c /char41/chareb/char51/char1e/char0a/char09/charab/char09/chare1/chard3/char51/char11/char1e/charbb /char40/char10/chare9/char4b/char0a/char51/chara2/char09/charaf/char10/char48/char41/chard2/char82/charcb/char40/char09/char91/charaa/char4b/char2e\n/char2c /charbd/charcb/char09/char58 /chara9/chard3/charf0 /char2e /char41/char09/char4a/charcb/charf1/char6b/char09/chare1/chard3 /chard5/charcb/char41/charaa/charcb/char40 /charfa/char0a\n/char09/charaf /chara0/char41/chard6/char09/chardf/char42/char40/char10/chare9/char4b/char0a/char0d/charf0/char50 /charf0/char40\n/char2e /charf8/char51/char09/char6b/char40/char10/chare8/char50/char41/charea/chard3 /charf8/char0a/char40 /charc9/char11/char4a/chard3 /char41/chard3/char41/chard6/char10/chardf/char2c/char10/chare9/char83/char50/char41/chard2/chard6/charcf/char41/char4b/char2e/char41/charea/charca/char10/charae/char93/charf0 /char41/chareb/char51/char4b/char0a/charf1/chara2/char10/char1d/char09/chare1/charba/chard6/chardf /char0a/char10/chare8/char50/char41/charea/chard3 /chara8/char40/char59/char4b/char2e/char42/char40/char09/chare0/char41/char09/charaf\n/chard5/chare6/char85/char50 /charf0/char40 /charfa/char0a/char09/chare6/chareb/char09/char59/charcb/char40/char09/charad/char92/charaa/charcb/char40 /charc9/char11/char4a/chard3/char10/chare9/char09/charae/charca/char10/char4a/char09/char6d/chard7/char09/chare1/char4b/char0a/char50/char41/chard6/char10/chardf/charc8/char43/char09/char67/char09/chare1/chard3 /chare9/char09/char4a/char1c/char0a/char82/char6d/char1a/char10/char27/char09/chare1/charba/chard6/chardf /char0a/charf0\n/char10/chare8/char59/char4b/char0a/char59/char67/char2e/char48/char2e/char50/char41/char6d/char2e/char1a/char10/char27/char09/chare1/charab/char11/char49/char6a/char4a/char2e/charcb/char40 /charc8/char43/char09/char67/char09/chare1/chard3 /charfa/char10/chare6/char6b /charf0/char40/char10/chare9/char4a/char0a/char09/char4a/chareb/char09/char59/charcb/char40 /chara1/char0d/char1d/char40/char51/char09/char6d/charcc/char27/char40\n/char2c/char09/charac/char41/chara2/chard6/charcf/char40/char10/chare9/char4b/char0a/char41/charee/char09/char45 /charfa/char0a\n/char09/charaf /char2e/char10/chare8/char59/char4b/char0a/char59/char67/char2e/char50/char41/charbe/char09/charaf/char40/char09/char51/char1e/char0a/char09/charae/char6a/char10/char4a/charcb\n/chara8/char40/char59/char4b/char2e/char42/char40 /chard5/charce/charaa/char10/char4a/char4b/char0a/char09/chare0/char40 /char91/char09/char6d/char19/char11/char85/charf8/char0a/char42/char09/chare1/charba/chard6/chardf /char0a/charf0 /char2c/char10/chare9/char4a/char2e/char82/char10/char1c/charba/chard6/charcf/char40/char10/char48/char40/char50/char41/charea/chard6/charcf/char40/charf0/char10/chare9/char4b/char0a/char51/chara2/char09/charae/charcb/char40/char10/chare9/char4a/char2e/chareb/charf1/chard6/charcf/char40/char09/chare1/chard3 /char6c/char2e/char1a/char27/char0a/char09/char51/chard3 /charf1/chareb /chara8/char40/char59/char4b/char2e/char42/char40\n/char3a/char50/charf1/char09/char4b /charfa/char0a/chare6/char2e/charca/char83 /chard0/char0d/char40 /charfa/char0a/char47/char2e/char41/char6d/char2e/char1a/char27/char0a/char40/char0d/chard5/chare6/char0a/charca/charaa/char10/char4a/charcb/char40/charfa/charce/charab /charfa/char0a/charab/char41/char09/char4a/chara2/char93/char42/char40 /char5a/char41/charbf/char09/char59/charcb/char40/char51/char1e/char0a/char11/char4b/char0d/char41/char10/char4b /char3a /chard0/char59/char09/char6a/char10/char4a/char82/chard6/charcf/char40/char2e /charfa/char0a/chare6/char2e/charca/char83/charf0 /charfa/char0a/char47/char2e/char41/char6d/char2e/char1a/char27/char0a/char40 /chard5/chare6/char0a/charca/charaa/char10/char4a/charcb/char40/charfa/charce/charab /charfa/char0a/charab/char41/char09/char4a/chara2/char93/char42/char40 /char5a/char41/charbf/char09/char59/charcb/char40/char51/char1e/char0a/char11/char4b/char41/char10/char4b/char09/chare0/char40\n/charfa/char0a\n/char09/charaf/char10/chare8/char50/charf1/char11/char4b/char11/char48/char40/char59/char67/char40/charfa/charce/charab/char10/chare8/char50/char59/char10/charae/charcb/char40 /chare9/char4b/char0a/char59/charcb /charfa/char0a/charab/char41/char09/char4a/chara2/char93/char42/char40 /char5a/char41/charbf/char09/char59/charcb/char40/char09/chare0/char40/char09/chare1/char1e/char0a/char67 /charfa/char0a\n/char09/charaf\n/char10/chare9/char4a/char0a/chard2/char4a/char0a/charca/charaa/char10/char4b /char48/char2e/char50/char41/char6d/char2e/char1a/char10/char27 /char51/char1e/char0a/char09/charaf/charf1/char10/char4b /charc8/char43/char09/char67/char09/chare1/chard3 /chard5/chare6/char0a/charca/charaa/char10/char4a/charcb/char40\n/char09/chare1/char4b/char0a/char09/char59/charcb/char40 /charbd/char0d/char4a/charcb/charf0/char40/char09/chare1/char1e/char0a/char4b/char2e/char10/chare8/charf1/char6d/char2e/char09/charaf/char10/char87/charca/char09/char67/charfa/charce/charab/char10/chare8/char50/char59/char10/charae/charcb/char40 /char41/char09/char92/char1d/char0a/char40 /chare9/char4b/char0a/char59/charcb /chare9/char09/char4b/char41/char09/charaf /char2c/char10/chare9/char92/char92/char09/char6d/chard7\n/char42/char09/chare1/char4b/char0a/char09/char59/charcb/char40 /charbd/char0d/char4a/charcb/charf0/char40/charf0 /char41/char4a/char0a/char6b/char2e/charf1/charcb/charf1/char09/char4a/charba/char10/char4a/charcb/char40 /charfa/charcd/char40 /charc8/charf1/char93/charf1/charcb/char40/char10/chare9/char4a/char0a/char09/char4b/char41/charbe/chard3/char40 /chard1/charee/char45/char0a/char59/charcb\n/char09/chare1/charba/chard2/char10/char4a/char4b/char0a/char42 /char59/char10/charaf /char2c /charc8/char41/char11/char4a/chard6/charcf/char40 /charc9/char4a/char0a/char1c/char2e/char83/charfa/charce/charab /char2e /charbd/charcb/char09/char58/char09/chare0/charf1/charaa/char4a/char0a/chara2/char10/char1c/char82/char1d/char0a/char10/chare9/chard3/char09/char50/char43/charcb/char40 /char41/char4a/char0a/char6b/char2e/charf1/charcb/charf1/char09/char4a/charba/char10/char4a/charcb/char40 /charfa/charcd/char40 /charc8/charf1/char93/charf1/charcb/char40/char09/chare1/chard3/char09/char91/char09/charae/char09/char6a/char09/char4a/chard6/charcf/char40 /charc9/char09/char67/char59/charcb/char40/char10/char48/char40/char09/char58/char10/char87/chara3/char41/char09/char4a/chard6/charcf/char40 /charfa/char0a\n/char09/charaf /char48/char2e/char43/chara2/charcb/char40\n/char2c /charbd/charcb/char09/char58/charfa/charce/charab/char10/chare8/charf0/char43/charab /char2e /charfa/char0a/charab/char41/char09/char4a/chara2/char93/char42/char40 /char5a/char41/charbf/char09/char59/charcb/char40/charfa/charce/charab/char10/chare9/chard6/char0d/chardf/char41/char10/charae/charcb/char40/char10/chare9/chara2/char11/char82/char09/char1d/char42/char40 /charfa/char0a\n/char09/charaf/char10/chare9/charbb /char50/char41/char11/char82/chard2/charca/charcb\n/char10/char48/char40/char50/char41/charea/chard6/charcf/char40/char09/chare0/char40/char59/char10/charae/char09/charaf /charfa/charcd/char40 /charf8/char0a/char58/char0d/charf1/char4b/char0a/char59/char10/charaf /charfa/char0a/charab/char41/char09/char4a/chara2/char93/char42/char40 /char5a/char41/charbf/char09/char59/charcb/char40/charfa/charce/charab /chara0/char51/char09/charae/chard6/charcf/char40 /char58/char41/chard2/char10/char4a/charab/char42/char40/char09/chare0/char41/char09/charaf\n/charfa/charcd/char40/char10/chare9/char09/charaf/char41/char09/char93/char42/char41/char4b/char2e/char2e /chara8/char40/char59/char4b/char2e/char42/char40/charf0/char10/char48/char43/charbe/char11/char82/chard6/charcf/char40 /charc9/char67/charf0 /charf8/char0a/char59/char10/charae/char09/char4a/charcb/char40/char51/char1e/char0a/charba/char09/charae/char10/char4a/charcb/char40 /charc9/char11/char4a/chard3/char10/chare9/char4a/char0a/char83/char41/char83/char42/char40\nTable 9: Best Answers from the \"Leading Sentence\" style prompts from the model fine-tuned on UltraChat-Ar\n(10%).\n262\nPrompt (Questions) Best Answer [Pre-trained version]\n/char3f /charf9/char09/charaa/charca/char10/char4a/char83 /chard0/char0d/char40 /charc9/char4a/char2e/char10/charae/char10/char4a/char82/chard6/charcf/char40 /charfa/char0a\n/char09/charaf/char10/chare9/char4a/char0a/chard3/char43/char83/char42/char0d/char40/char10/char48/char41/char83/char40/char50/char59/charcb/char40 /char80/char50/char59/char10/char4a/char83 /charc9/chareb/charfa/char0a\n/char09/charaf /charfa/char0a/char47/char2e/char51/charaa/charcb/char40 /charfa/char0a\n/char09/charaf/char41/char10/charae/char11/char4a/charcb/char40/char09/char51/charbb /char51/chard6/charcf/char40 /charfa/char0a\n/char09/charaf /char41/chareb/char41/char10/charae/charcb/char40 /charfa/char0a/char10/chare6/charcb/char40 /chare9/char10/char4b/char51/chare5/char09/char95/char41/char6d/chard7/charfa/char0a\n/char09/charaf /charf8/char0a/charf0/char41/char10/charaf/char51/char4b/char2e/char59/chard4/char67/char40 /char50/charf1/char10/char4a/charbb/char59/charcb/char40 /chare9/char6b/char51/chara3 /charc8/char40/char0d/charf1/char83\n/charfa/char0a/charab/charf1/charca/charcb /char68/char43/char93/char40 /charf1/chareb /charfa/char0a/char09/chare6/char4b/char0a/char59/charcb/char40 /char68/char43/char93/char42/char40/char09/chare0/char40 /char3a /chare9/charcb/charf1/char10/charae/char4b/char2e/char41/chareb/char40/char59/char4b/char2e/char59/char10/charaf/charf0 /charfa/char0a/char09/chare6/char4b/char0a/char59/charcb/char40 /char68/char43/char93/char42/char40/char09/chare0/char40/charf1/char09/char4a/charaa/char4b/char2e/char09/chare0/char40/char59/char4a/char0a/chard6/charcf/char40\n/charfa/char0a/charab/charf1/charcb/char40 /charfa/char0a\n/char09/charaf /chare9/charcb/char42/char40/charf0 /chare9/char3c/charcb/char40 /chard0/charf1/charea/char09/charae/chard3/charf0 /chare9/char3c/charcb/char40/char09/chare1/charab /charc9/char4b/char0a/char59/char4b/char2e/charf1/chareb /charf8/char0a/char59/char4a/char0a/charca/char10/charae/char10/char4a/charcb/char40 /charfa/char0a/char09/chare6/char4b/char0a/char59/charcb/char40 /charfa/char0a/charab/charf1/charcb/char40 /charfa/char0a\n/char09/charaf/char09/chare1/char4b/char0a/char59/charcb/char41/char09/charaf /char2c /charfa/char0a/char09/chare6/char4b/char0a/char59/charcb/char40\n/char10/chare8/char58/char41/charab/char42 /chara8/charf0/char51/chare5/char11/char84/chard3 /charf1/chareb /charfa/char0a/char09/chare6/char4b/char0a/char59/charcb/char40 /char68/char43/char93/char42/char40/char09/chare0/char40 /char3a/char09/charac/char41/char09/char93/char40/charf0 /char2e/char09/chare1/char4b/char0a/char59/charcb/char40/char09/chare1/charab /charc9/char4b/char0a/char59/char4b/char2e/charf1/chareb /charf8/char0a/char59/char4a/char0a/charca/char10/charae/char10/char4a/charcb/char40 /charfa/char0a/char09/chare6/char4b/char0a/char59/charcb/char40\n/char09/chare1/charab/char11/char49/char4b/char0a/char59/char6a/charca/charcb /charc9/char10/charae/char10/char4a/char09/char4b/char40 /chard5/chare7/char11/char27 /char2e /charfa/char0a/char09/chare6/char4b/char0a/char59/charcb/char40 /char91/char09/char4a/charcb/char40 /charc8/char43/char09/char67/char09/chare1/chard3/char09/chare1/char4b/char0a/char59/charcb/char40 /chard1/charea/char09/charaf\n/char3f /charc8/char41/char09/charae/chara3/char0d/char43/charcb /charf8/char0a/char59/char4a/char0a/charca/char10/charae/char10/char4a/charcb/char40 /chard5/chare6/char0a/charca/charaa/char10/char4a/charcb/char40/char09/chare1/chard3 /charc9/char09/char92/char09/charaf/char0d/char40 /charfa/char0a/charcd/char09/char51/char09/char1e/chard6/charcf/char40 /chard5/chare6/char0a/charca/charaa/char10/char4a/charcb/char40 /charc9/chareb/char2c /char40/char59/char09/char4a/charbb /charfa/char0a\n/char09/charaf/char10/chare9/char4a/char0a/char09/char4b/char41/chara2/char1d/char0a/char51/char1e/char2e/charcb/char40 /char41/char4a/char0a/char4a/char2e/chard3/charf1/charcb/charf1/charbb/char10/chare9/charaa/chard3/char41/char67/char2e/char09/chare1/chard3/char10/chare8/char59/char4b/char0a/char59/char67/char2e/char10/chare9/char83/char40/char50/char58 /charfa/char0a\n/char09/charaf\n/chard1/chareb/char0d/charf0/char40/char58/char40/char09/chare0/char41/charbf /charc8/char09/char51/char09/char1e/chard6/charcf/char40 /charfa/char0a\n/char09/charaf /chard1/charea/chard2/char4a/char0a/charca/charaa/char10/char4b /char40/charf1/char10/charae/charca/char10/char4b/char09/chare1/char4b/char0a/char09/char59/charcb/char40 /charc8/char41/char09/charae/chara3/char42/char40/char09/chare0/char40/char09/chare0/charf1/char11/char4a/char6b/char41/char4a/char2e/charcb/char40 /char59/char67/char2e/charf0\n/char40/charf1/char10/charae/charca/char10/char4b/char09/chare1/char4b/char0a/char09/char59/charcb/char40 /charc8/char41/char09/charae/chara3/char42/char40/char09/chare1/chard3/char10/chare8/char59/char67/charf1/chard6/charcf/char40/char10/char48/char40/char50/char41/char4a/char2e/char10/char4a/char09/char6b/char42/char40 /charfa/char0a\n/char09/charaf /charc9/char09/char92/char09/charaf/char40\n/charc9/char09/charae/chara3 /char39/char30/char30/char09/chare1/chard3 /char48/char2e/char51/char10/charae/char4b/char0a/char41/chard3/charfa/charce/charab/char10/chare9/char83/char40/char50/char58/char09/chare0/charf1/char11/char4a/char6b/char41/char4a/char2e/charcb/char40 /charf8/char51/char6b/char2e/char40 /char2e/char10/chare9/char83/char50/char59/chard6/charcf/char40 /charfa/char0a\n/char09/charaf /chard1/charea/chard2/char4a/char0a/charca/charaa/char10/char4b\n/char40/charf0/char59/char67/char2e/charf0/charf0 /char2c /char80/char58/char41/char82/charcb/char40/char09/charad/char92/charcb/char40 /charfa/charcd/char40 /charc8/charf0/char42/char40/char09/charad/char92/charcb/char40/char09/chare1/chard3\n/char10/char48/char40/char50/char41/char4a/char2e/char10/char4a/char09/char6b/char40 /charfa/char0a\n/char09/charaf/charfa/charce/charab/char40/char10/char48/char41/char67/char2e/char50/char58/charfa/charce/charab /char40/charf1/charca/char92/char6b /charc8/char09/char51/char09/char1e/chard6/charcf/char40 /charfa/char0a\n/char09/charaf /chard1/charea/chard2/char4a/char0a/charca/charaa/char10/char4b /char40/charf1/char10/charae/charca/char10/char4b/char09/chare1/char4b/char0a/char09/char59/charcb/char40 /charc8/char41/char09/charae/chara3/char42/char40/char09/chare0/char40\n/char10/chare9/char09/char4b/char50/char41/char10/charae/chard3 /chard0/charf1/charca/charaa/charcb/char40/charf0/char10/chare9/char4b/char0a/char09/char51/char1e/char0a/charca/char6d/char2e/char1a/char09/char27/char42/char40/char10/chare9/char09/charaa/charca/charcb/char40/charf0/char10/char48/char41/char4a/char0a/char09/char93/char41/char4b/char0a/char51/charcb/char40 /charfa/char0a\n/char09/charaf/char10/chare9/char4a/char0a/char83/char41/char4a/char0a/char10/charae/charcb/char40 /charc9/char4a/char0a/char92/char6a/char10/char4a/charcb/char40\n/char09/chare1/char4b/char0a/char09/char59/charcb/char40 /charc8/char41/char09/charae/chara3/char42/char40 /char5a/char40/char58/char40/char09/chare0/char41/charbf /char2c /charbd/charcb/char09/char58 /charfa/charcd/char40/char10/chare9/char09/charaf/char41/char09/char93/char42/char41/char4b/char2e/char2e/char10/chare9/char83/char50/char59/chard6/charcf/char40 /charfa/char0a\n/char09/charaf /chard1/charea/chard2/char4a/char0a/charca/charaa/char10/char4b /chard5/chare7/char10/char27/char09/chare1/char4b/char0a/char09/char59/charcb/char40 /charc8/char41/char09/charae/chara3/char42/char41/char4b/char2e\n/charfa/char0a\n/char09/charaf /chard1/charea/chard2/char4a/char0a/charca/charaa/char10/char4b /char40/charf1/char10/charae/charca/char10/char4b\n/char3f/char10/chare9/char93/char41/char09/char6d/charcc/char27/char40/char10/char48/char41/char67/char2e/char41/char4a/char0a/char10/char4a/char6b/char42/char40 /charf8/char0a/charf0/char09/char59/charcb /chard5/chare6/char0a/charca/charaa/char10/char4a/charcb/char40 /char51/char4b/char0a/charf1/chara2/char10/char1d /chara9/char4a/char0a/chara2/char10/char1c/char82/char09/char1d/char09/charad/char4a/char0a/charbb /char3f/char10/chare9/char93/char41/char09/char6d/charcc/char27/char40/char10/char48/char41/char67/char2e/char41/char4a/char0a/char10/char4a/char6b/char42/char40 /charf8/char0a/charf0/char09/char59/charcb /chard5/chare6/char0a/charca/charaa/char10/char4a/charcb/char40 /char51/char4b/char0a/charf1/chara2/char10/char1d /chara9/char4a/char0a/chara2/char10/char1c/char82/char09/char1d/char09/charad/char4a/char0a/charbb\n/char3f/char10/chare9/char93/char41/char09/char6d/charcc/char27/char40/char10/chare9/char4a/char0a/char4b/char2e/char51/char10/char1e/charcb/char40/char09/char51/charbb /char40/char51/chard3/char10/char87/char4b/char0a/char51/chara3/char09/chare1/charab /chard0/char40 /char3f /charfa/char0a/char09/chare6/charea/chard6/charcf/char40 /charc9/char4a/char0a/chareb/char41/char10/char4a/charcb/char40/char10/char87/char4b/char0a/char51/chara3/char09/chare1/charab /charbd/charcb/char09/char58/char09/chare0/charf1/charba/char4b/char0a/charc9/chareb\n/char41/charea/chard3/char0f/char59/char10/charae/char09/char4b/char09/chare0/char0d/char40/char09/char90/char51/char10/char1e/char09/charae/char4b/char0a/charfa/char0a/char10/chare6/charcb/char40 /chard5/chare6/char0a/char10/charae/charcb/char40/charf0/char10/char48/char40/char50/char41/charea/chard6/charcf/char40/charf0/char09/charac/char50/char41/charaa/chard6/charcf/char40 /char50/char41/char10/char4a/char09/char6d/char1a/char09/char27/char09/chare0/char0d/char40 /char41/char09/char4a/charcb/char09/charad/char4a/char0a/charbb\n/char3f /charc9/char0d/char4b/char41/charea/charcb/char40 /charfa/char0a/char09/chare6/char10/charae/char10/char4a/charcb/char40 /charfa/char0a\n/char09/charaf/char51/charaa/chard6/charcf/char40 /chard1/char09/char6a/char09/char92/char10/char4a/charcb/char40 /char40/char09/char59/chareb /charc9/char09/chara3 /charfa/char0a\n/char09/charaf/char13/char41/char93/charf1/char92/char09/char6b /char2c /char41/char09/char4a/char4b/char2e/char43/chara2/charcb\n/char41/charee/char44/char2e/char82/char10/char1c/charba/char4b/char0a/char09/chare0/char40/char09/char90/char51/char10/char1e/char09/charae/char4b/char0a/charfa/char0a/char10/chare6/charcb/char40/char10/chare9/char4a/char0a/char83/char41/char83/char42/char40/char10/char48/char40/char50/char41/charea/chard6/charcf/char40/char09/charad/char4b/char0a/char51/charaa/char10/char4b /char59/char4a/char0a/charaa/char09/char4b/char09/chare0/char40 /char41/char09/char4a/charcb/char09/charad/char4a/char0a/charbb /charf0\n/char09/chare1/chard3 /char43/char4a/char0a/char6b/char2e/chara9/char09/char4a/char92/char09/char1d/char09/chare0/char40 /char41/char09/char4a/charcb/char09/charad/char4a/char0a/charbb /charf0 /char3f /charfa/charcd/charf0/char42/char40/char10/chare9/char4a/char0a/char83/char40/char50/char59/charcb/char40 /charc9/char67/char40/char51/chard6/charcf/char40 /charfa/char0a\n/char09/charaf /char49/char2e/charcb/char41/chara2/charcb/char40\n/char3f /charc9/char4a/char2e/char10/charae/char10/char4a/char82/chard6/charcf/char40/char10/chare8/char58/char41/char4a/char0a/char10/charaf /charfa/charcd/char40 /chard1/charea/charca/chareb/char0d/charf1/char10/char4b /charfa/char0a/char10/chare6/charcb/char40/char10/char48/char40/char50/char41/charea/chard6/charcf/char40/char09/chare0/charf1/charba/charca/char10/char4a/chard6/chardf /char0a/char09/chare1/char4b/char0a/char09/char59/charcb/char40/char09/chare1/char1e/char0a/charab/char59/char4a/char2e/chard6/charcf/char40\n/charfa/char0a/char10/chare6/charcb/char40/char10/char48/char40/char50/char41/charea/chard6/charcf/char40/char09/chare0/charf1/charba/charca/char10/char4a/chard6/chardf /char0a/char09/chare1/char4b/char0a/char09/char59/charcb/char40/char09/chare1/char1e/char0a/charab/char59/char4a/char2e/chard6/charcf/char40/char09/chare1/chard3 /char43/char4a/char0a/char6b/char2e/chara9/char09/char4a/char92/char09/char1d/char09/chare0/char40 /char41/char09/char4a/charcb/char09/charad/char4a/char0a/charbb /charf0\n/char10/chare9/char4a/char0a/char83/char41/char83/char40/char10/char48/char40/char50/char41/charea/chard3 /charbc/char41/char09/char4a/chareb/char09/chare0/char40 /charbd/char11/char83 /char42 /char3f /charc9/char4a/char2e/char10/charae/char10/char4a/char82/chard6/charcf/char40/char10/chare8/char58/char41/char4a/char0a/char10/charaf /charfa/charcd/char40 /chard1/charea/charca/chareb/char0d/charf1/char10/char4b\n/chare8/char09/char59/chareb /char40/charf1/chard2/charca/charaa/char10/char4a/char4b/char0a/char09/chare0/char40 /char49/char2e/char6d/char2e/char1a/char27/char0a/char48/char2e/char43/chara2/charcb/char40 /charc9/charbf/char09/chare0/char40 /charfa/char0a/char09/chare6/charaa/char4b/char0a/char42 /char40/char09/char59/chareb/char09/chare1/charba/charcb /char2c /char49/char2e/charcb/char41/chara2/charcb/char40 /char41/charea/chard2/charca/charaa/char10/char4a/char4b/char0a/char09/chare0/char40 /char49/char2e/char6d/char2e/char1a/char27/char0a\n/charfa/char0a/char09/chare6/charaa/char4b/char0a/char42 /char40/char09/char59/chareb/char09/chare1/charba/charcb /char2c /char49/char2e/charcb/char41/chara2/charcb/char40 /char41/charea/chard2/charca/charaa/char10/char4a/char4b/char0a/char09/chare0/char40 /char49/char2e/char6d/char2e/char1a/char27/char0a/char10/chare9/char4a/char0a/char83/char41/char83/char40/char10/char48/char40/char50/char41/charea/chard3 /charbc/char41/char09/char4a/chareb/char09/chare0/char40 /charc9/char4b/char2e/char2c/char10/char48/char40/char50/char41/charea/chard6/charcf/char40\n/char3f /charfa/char0a/charab/char41/char09/char4a/chara2/char93/char42/char40 /char5a/char41/charbf/char09/char59/charcb/char40 /chard0/char40/char59/char09/char6a/char10/char4a/char83/char41/char4b/char2e/char09/chare0/char41/chara3/char51/chare5/char84/charca/charcb /char68/char2e/char43/charab /char51/char4b/char0a/charf1/chara2/char10/char1d/char09/chare1/charba/chard6/chardf /char0a/char09/charad/char4a/char0a/charbb /char09/chare1/chard3 /charfa/char0a/charab/char41/char09/char4a/chara2/char93/char42/char40 /char5a/char41/charbf/char09/char59/charcb/char40/char09/chare1/charba/chard2/char10/char4a/char4b/char0a/char59/char10/charaf /char2c /char49/char2e/char4b/char0a/char51/char10/charae/charcb/char40 /charc9/char4a/char2e/char10/charae/char10/char4a/char82/chard6/charcf/char40 /charfa/char0a\n/char09/charaf\n/charc8/char43/char09/char67/char09/chare1/chard3 /charf8/char51/char09/char6b/char42/char40/char09/char90/char40/char51/chard3/char42/char40/charf0/char09/chare0/char41/chara3/char51/chare5/char84/charca/charcb/char10/chare8/char59/char4b/char0a/char59/char67/char2e/char10/char48/char41/char67/char2e/char43/charab/charfa/charce/charab /char50/charf1/char11/char4a/charaa/charcb/char40\n/charfa/char0a/chare6/char84/char4a/char0a/chara3/char41/char09/char4a/char09/charaa/chard6/charcf/char40/char09/chare1/char1e/char0a/char09/char4b/char51/charcb/char40/charf0/char10/chare9/char4a/char0a/charaa/chara2/char10/charae/chard6/charcf/char40/char10/chare9/charaa/char11/char83/char42/char40 /char50/charf1/char93 /charc9/char4a/char0a/charca/char6d/char1a/char10/char27\n/charc9/char4a/char0a/charca/char6a/char10/char4a/charcb /char51/char10/char4b/charf1/char4a/char0a/char4a/char2e/chard2/charba/charcb/char40/char10/chare8/char09/char51/charea/char6b/char2e/char40 /char5a/char41/char4a/char2e/chara3/char42/char40 /chard0/char59/char09/char6a/char10/char4a/char82/char1d/char0a/char2c /charfa/char0a/charcd/char41/char6d/charcc/char27/char40/char10/char49/char10/charaf/charf1/charcb/char40 /charfa/char0a\n/char09/charaf /char2e /charfa/chare6/char09/char95/char51/chard2/charca/charcb\n/char2e /charfa/char0a/chare6/char84/char4a/char0a/chara3/char41/char09/char4a/char09/charaa/chard6/charcf/char40/char09/chare1/char1e/char0a/char09/char4b/char51/charcb/char41/char4b/char2e/char51/char4b/char0a/charf1/char92/char10/char4a/charcb/char40/charf0/char10/chare9/char4a/char0a/char09/char4a/char1c/char0a/char82/charcb/char40/char10/chare9/charaa/char11/char83/char42/char40/char09/chare1/chard3/char10/chare9/char4a/char0a/char0d/char4b/char51/chard6/charcf/char40/char10/char48/char41/char09/char4b/char41/char4a/char0a/char4a/char2e/charcb/char40\n/charfa/charcd/char40/char10/chare9/char6b/char2e/char41/char67 /charbc/char41/char09/char4a/chareb/char09/chare0/charf1/charba/char10/char4b /char59/char10/charaf /charfa/char0a/char10/chare6/charcb/char40/char10/char87/chara3/char41/char09/char4a/chard6/charcf/char40 /char59/char4b/char0a/char59/char6d/char1a/char10/char27/charfa/char0a\n/char09/charaf /charfa/char0a/charab/char41/char09/char4a/chara2/char93/char42/char40 /char5a/char41/charbf/char09/char59/charcb/char40 /char59/charab/char41/char82/char1d/char0a/char09/chare0/char40/char09/chare1/charba/chard6/chardf /char0a\n/chare9/charca/char67/char40/char51/chard3 /charfa/char0a\n/char09/charaf /charc8/char40/char09/char51/char4b/char0a/char42 /charfa/char0a/charab/char41/char09/char4a/chara2/char93/char42/char40 /char5a/char41/charbf/char09/char59/charcb/char40/char09/chare0/char40/char09/chare1/chard3 /chard1/char09/charab/char51/charcb/char40/charfa/charce/charab /char2e /char40/char09/char51/char1e/char0a/charbb /char51/char10/char4b/char51/char11/char1e/charbb /char40 /char68/char2e/char43/charab\n/charc9/char4a/char0a/char1c/char2e/char83/charfa/charce/charab /char2e /char49/char2e/chara2/charcb/char40 /charfa/char0a\n/char09/charaf /char40/char59/char4a/char0a/char09/charae/chard3/char09/chare0/charf1/charba/char4b/char0a/char09/chare0/char40/char09/chare1/charba/chard6/chardf /char0a/chare9/char09/char4b/char40/charfa/charce/charab/char10/chare9/charcb/char58/char42/char40/char09/char91/charaa/char4b/char2e/charbc/char41/char09/char4a/chareb/char09/chare0/char40 /char42/char40 /char2c /charfa/charcd/charf0/char42/char40\n/charc9/char4a/char0a/charca/char6a/char10/char4a/charcb /charfa/char0a/charab/char41/char09/char4a/chara2/char93/char42/char40 /char5a/char41/charbf/char09/char59/charcb/char40 /chard0/char40/char59/char09/char6a/char10/char4a/char83/char40/char09/chare1/charba/chard6/chardf /char0a/char2c /charc8/char41/char11/char4a/chard6/charcf/char40\nTable 10: Best Answers from the \"Question\" style prompts from the pre-trained model.\n263\nPrompt (Questions) Best Answer [Fine-tuned version]\n/charfa/char0a\n/char09/charaf/char10/chare9/char4a/char0a/chard3/char43/char83/char42/char0d/char40/char10/char48/char41/char83/char40/char50/char59/charcb/char40 /char80/char50/char59/char10/char4a/char83 /charc9/chareb /char3a /chard0/char59/char09/char6a/char10/char4a/char82/chard6/charcf/char40\n/char3a/char50/charf1/char09/char4b /char3f /charf9/char09/charaa/charca/char10/char4a/char83 /chard0/char0d/char40 /charc9/char4a/char2e/char10/charae/char10/char4a/char82/chard6/charcf/char40\n/char2c /charbd/charcb/char09/char58 /chara9/chard3/charf0 /char2e/char10/char48/char41/charaa/chard3/char41/char6d/char2e/charcc/char27/char40 /charfa/char0a\n/char09/charaf/char10/chare9/char4a/char0a/chard3/char43/char83/char42/char40/char10/char48/char41/char83/char40/char50/char59/charcb/char40 /charc9/char4a/char2e/char10/charae/char10/char4a/char82/chard6/chardf/char2e/char0d/charf1/char4a/char2e/char09/char1c/char10/char4a/charcb/char40 /char49/char2e/charaa/char92/charcb/char40/char09/chare1/chard3\n/charfa/char0a\n/char09/charaf /char40/char59/char4b/char0a/char40/char09/char51/char10/char1e/chard3 /char41/char09/charaf/char40/char51/char10/char1e/charab/char40/char10/char49/char1c/char2e/char82/char10/char1c/charbb /char40/char10/chare9/char4a/char0a/chard3/char43/char83/char42/char40/char10/char48/char41/char83/char40/char50/char59/charcb/char40/char09/chare0/char40 /charfa/charcd/char40/char10/chare8/char50/char41/char11/char83/char42/char40 /char50/char59/char6d/char2e/char1a/char10/char27\n/char10/char48/char41/char83/char40/char50/char59/charcb/char40/char10/char48/char40/char50/charf0/char58 /char6c/char2e/chard7/char59/char4b/char2e/char10/char48/char41/charaa/chard3/char41/char6d/char2e/charcc/char27/char40/char09/chare1/chard3 /char59/char4b/char0a/char59/charaa/charcb/char40/char10/char49/chard3/char41/char10/charaf/char11/char49/char4a/char0a/char6b /char2c/char10/chare8/char51/char1e/char0a/char09/char67/char42/char40/char10/char48/char40/charf1/char09/char4a/char82/charcb/char40\n/char58/char59/charab /char59/char4b/char0a/char40/char09/char51/char10/char4b /chara9/chard3 /char2c /charbd/charcb/char09/char58 /charfa/charcd/char40/char10/chare9/char09/charaf/char41/char09/char93/char42/char41/char4b/char2e/char2e/char10/chare9/char4a/char0a/char83/char40/char50/char59/charcb/char40 /char41/charea/char6a/char2e/chareb/char41/char09/char4a/chard3 /charfa/char0a\n/char09/charaf/char10/chare9/char4a/char0a/chard3/char43/char83/char42/char40\n/char10/char48/char41/charaa/chard3/char41/char6d/char2e/charcc/char27/char40 /char68/char2e/char41/char10/char4a/char6d/char1a/char10/char27/char59/char10/charaf /char2c /chard5/charcb/char41/charaa/charcb/char40 /char5a/char41/char6d/char1a/char09/char27/char40 /chara9/char4a/char0a/chard4/char67/char2e/charfa/char0a\n/char09/charaf/char09/chare1/char1e/char0a/chard2/charca/char82/chard6/charcf/char40 /char48/char2e/char43/chara2/charcb/char40\n/char2e/char09/chare1/char1e/char0a/chard2/charca/char82/chard6/charcf/char40 /char48/char2e/char43/chara2/charcb/char40/char10/char48/char41/char67/char2e/char41/char4a/char0a/char10/char4a/char6b/char40 /charfa/char0a/chare6/char2e/charca/char10/char4b /charfa/char0a/char10/chare6/charcb/char40/char10/char48/char40/char50/charf0/char59/charcb/char40/char09/chare1/chard3 /char59/char4b/char0a/char09/char51/chard6/charcf/char40 /chard5/chare7/char27/char0a/char59/char10/charae/char10/char4b /charfa/charcd/char40\n/charfa/charce/charab/char10/char48/char41/charaa/chard3/char41/char6d/char2e/charcc/char27/char40 /charfa/char0a\n/char09/charaf/char10/chare9/char4a/char0a/chard3/char43/char83/char42/char40/char10/char48/char41/char83/char40/char50/char59/charcb/char40 /charc9/char4a/char2e/char10/charae/char10/char4a/char82/chard3 /char59/chard2/char10/char4a/charaa/char4a/char0a/char83/char09/charac/char41/chara2/chard6/charcf/char40/char10/chare9/char4b/char0a/char41/charee/char09/char45 /charfa/char0a\n/char09/charaf/charf0\n/charf9/char0a/chard6/chardf /char0a/char58/char41/charbf /char42/char40 /chara9/chard2/char10/char4a/char6a/char2e/chard6/charcf/char40/char10/char48/char41/char67/char2e/char41/char4a/char0a/char10/char4a/char6b/char40 /charbd/charcb/char09/char58 /charfa/char0a\n/char09/charaf /char41/chard6/chardf/char2e/char2c /charc9/chard3/char40/charf1/charaa/charcb/char40/char09/chare1/chard3/char10/chare9/charab/charf1/char09/char4a/char10/char4a/chard3/char10/chare9/charab/charf1/chard2/char6d/char2e/chard7\n/charbd/char09/char4a/charba/chard6/chardf /char0a/charc9/chareb /char3a /chard0/char59/char09/char6a/char10/char4a/char82/chard6/charcf/char40 /char2e /char48/char2e/char43/chara2/charcb/char40 /char49/char2e/charca/chara3/charf0\n/chard5/chare6/char0a/charca/charaa/char10/char4a/charcb/char40/char09/chare1/chard3 /charc9/char09/char92/char09/charaf/char0d/char40 /charfa/char0a/charcd/char09/char51/char09/char1e/chard6/charcf/char40 /chard5/chare6/char0a/charca/charaa/char10/char4a/charcb/char40 /charc9/chareb /char3a /chard0/char59/char09/char6a/char10/char4a/char82/chard6/charcf/char40\n/char3a/char50/charf1/char09/char4b /char3f /charc8/char41/char09/charae/chara3/char0d/char43/charcb /charf8/char0a/char59/char4a/char0a/charca/char10/charae/char10/char4a/charcb/char40\n/char09/chare0/char42 /charc8/char40/char0d/charf1/char82/charcb/char40 /char40/char09/char59/chareb/charfa/charce/charab /chara9/char4a/char0a/chard2/char6d/char2e/charcc/char27/char40 /char49/char2e/char83/char41/char09/char4a/char10/char4b/char10/chare8/char59/char67/char40/charf0/char10/chare9/char4b/char2e/char41/char67/char2e/char40 /char59/char67/char2e/charf1/char10/char4b /char42\n/charbd/charcb/char09/char58 /charfa/char0a\n/char09/charaf /char41/chard6/chardf/char2e/char2c/char10/chare9/char09/charae/charca/char10/char4a/char09/char6d/chard7/charc9/chard3/char40/charf1/charab/charfa/charce/charab /char59/chard2/char10/char4a/charaa/char4b/char0a/charc9/char09/charae/chara2/charca/charcb /char69/char2e/charee/char09/char45 /charc9/char09/char92/char09/charaf/char40\n/char48/char2e/charf1/char4a/char0a/charaa/charcb/char40/charf0 /char41/char4b/char0a/char40/char09/char51/chard6/charcf/char40/char09/char91/charaa/char4b/char2e/charbc/char41/char09/char4a/chareb /char2c /charbd/charcb/char09/char58 /chara9/chard3/charf0 /char2e /chard5/charce/charaa/char10/char4a/charcb/char40 /char48/char2e/charf1/charca/char83/char40/charf0 /chare9/char10/char4b/char40/char50/char59/char10/charaf/charf0 /charc9/char09/charae/chara2/charcb/char40/char10/char48/char41/chard3/char41/chard2/char10/char4a/chareb/char40\n/char51/char1e/char2e/charbb /char40 /char40/char50/char59/char10/charaf /charfa/char0a/charcd/char09/char51/char09/char1e/chard6/charcf/char40 /chard5/chare6/char0a/charca/charaa/char10/char4a/charcb/char40 /char51/char09/charaf/charf1/char4b/char0a/char3a/char10/chare9/char09/char4b/charf0/char51/chard6/charcf/char40 /char2e/char31 /char3a /charc9/char11/char4a/chard3 /char2c /charfa/char0a/charcd/char09/char51/char09/char1e/chard6/charcf/char40 /chard5/chare6/char0a/charca/charaa/char10/char4a/charca/charcb/char10/chare9/charca/chard2/char10/char4a/char6a/chard6/charcf/char40\n/char50/char41/char4a/char0a/char10/char4a/char09/char6b/char40/char09/chare1/char4b/char0a/char59/charcb/char40/charf1/charca/charcb/char09/chare1/charba/chard6/chardf /char0a/char2e/char09/chare1/char1e/char0a/char10/char4b/charf0/char51/charcb/char40/charf0 /charfa/char0a/char09/chare6/chard3/char09/char51/charcb/char40 /charc8/charf0/char59/char6d/char2e/charcc/char27/char41/char4b/char2e/char10/char87/charca/charaa/char10/char4a/char4b/char0a/char41/chard2/char4a/char0a/char09/charaf/char10/chare9/char09/char4b/charf0/char51/chard6/charcf/char40/char09/chare1/chard3\n/char09/chare0/charf0/char59/char4b/char0a/char51/char4b/char0a/char41/chard3 /char50/char41/char4a/char0a/char10/char4a/char09/char6b/char40 /charc8/char41/char09/charae/chara3/char43/charcb/char09/chare1/charba/chard6/chardf /char0a/charf0 /char2c /chare9/char82/char1d/char0a/char50/char59/char10/char4b/char10/chare9/char4a/char0a/char09/charae/char4a/char0a/charbb /charf0 /chare9/char82/char1d/char0a/char50/char59/char10/char4b/char09/chare0/charf0/char59/char4b/char0a/char51/char4b/char0a/char41/chard3\n/chard1/charee/char09/char45/char40/char51/char10/charaf/char40 /chara9/chard3 /charc9/charab/char41/char09/charae/char10/char4a/charcb/char40 /charc8/char41/char09/charae/chara3/char43/charcb /charfa/char0a/charcd/char09/char51/char09/char1e/chard6/charcf/char40 /chard5/chare6/char0a/charca/charaa/char10/char4a/charcb/char40 /char69/char4a/char0a/char10/char1c/char4b/char0a/char3a/char10/chare9/char4a/char0a/charab/char41/chard2/char10/char4a/char6b/char2e/char42/char40/char10/chare9/char0d/char4a/char11/char82/char09/char1c/char10/char4a/charcb/char40 /char2e/char32 /char2e /chare9/chard2/charca/charaa/char10/char4b\n/char5a/char41/char09/char4a/char4b/char2e/charfa/char0a\n/char09/charaf /char59/charab/char41/char82/char1d/char0a/char09/chare0/char40/char09/chare1/charba/chard6/chardf /char0a/char41/chardc/chard8/char2c/char10/char48/char41/char4a/char0a/char09/charae/charca/char09/char6d/charcc/char27/char40/charf0 /char50/char41/chard4/charab/char42/char40/char09/charad/charca/char10/char4a/char09/char6d/chard7/char09/chare1/chard3\n/charf8/char0a/charf0/char09/char59/charcb /chard5/chare6/char0a/charca/charaa/char10/char4a/charcb/char40 /char51/char4b/char0a/charf1/chara2/char10/char1d /chara9/char4a/char0a/chara2/char10/char1c/char82/char09/char1d/char09/charad/char4a/char0a/charbb /char3a /chard0/char59/char09/char6a/char10/char4a/char82/chard6/charcf/char40\n/char3a/char50/charf1/char09/char4b /char3f/char10/chare9/char93/char41/char09/char6d/charcc/char27/char40/char10/char48/char41/char67/char2e/char41/char4a/char0a/char10/char4a/char6b/char42/char40\n/char10/char48/char41/char67/char2e/char41/char4a/char0a/char10/char4a/char6b/char42/char40 /charf8/char0a/charf0/char09/char59/charcb /chard5/chare6/char0a/charca/charaa/char10/char4a/charcb/char40 /char51/char4b/char0a/charf1/chara2/char10/char1d /char41/charea/charcb/char43/char09/char67/char09/chare1/chard3/char09/chare1/charba/chard6/chardf /char0a/char10/char86/char51/chara3/char10/chare8/char59/charab /charbc/char41/char09/char4a/chareb\n/char10/chare8/char58/char59/char6a/chard6/charcf/char40/char10/char48/char41/char67/char2e/char41/char4a/char0a/char10/char4a/char6b/char42/char40 /char59/char4b/char0a/char59/char6d/char1a/char10/char27/char09/chare1/char1e/char0a/chard2/charca/charaa/chard6/charcf/char40/charfa/charce/charab /char49/char2e/char6d/char2e/char1a/char27/char0a/char3a/char10/chare8/char58/char59/char6a/chard6/charcf/char40/char10/char48/char41/char67/char2e/char41/char4a/char0a/char10/char4a/char6b/char42/char40 /char59/char4b/char0a/char59/char6d/char1a/char10/char27/char2e/char31/char10/chare9/char93/char41/char09/char6d/charcc/char27/char40\n/char09/chare0/char40/char09/chare1/charba/chard6/chardf /char0a/char2e /charfa/char0a/chare6/char85/char40/char50/char59/charcb/char40 /charc9/char92/char09/charae/charcb/char40 /charfa/char0a\n/char09/charaf/char10/chare9/char93/char41/char09/char6d/charcc/char27/char40/char10/char48/char41/char67/char2e/char41/char4a/char0a/char10/char4a/char6b/char42/char40 /charf8/char0a/charf0/char09/char58/char09/chare1/chard3 /char49/char2e/charcb/char41/chara3 /charc9/charbe/charcb\n/charf0/char40/char10/chare9/char4a/char0a/char82/char6d/charcc/char27/char40 /charf0/char40/char10/chare9/char4b/char0a/char59/char82/char6d/char2e/charcc/char27/char40 /charf0/char40/char10/chare9/char4a/char0a/char09/charaf/char51/charaa/chard6/charcf/char40/char10/char48/char41/char10/charaf/char41/charab/char42/char40 /charc9/char11/char4a/chard3/char10/char48/char42/char41/char6d/char2e/chard7/charbd/charcb/char09/char58 /charc9/chard2/char11/char82/char1d/char0a\n/char49/char2e/char4a/char0a/charcb/char41/char83/char40/char09/charad/char4a/char0a/char4a/char0a/charba/char10/char4b/char09/chare1/char1e/char0a/chard2/charca/charaa/chard6/charcf/char40/charfa/charce/charab /char49/char2e/char6d/char2e/char1a/char27/char0a/char3a /char81/char1d/char0a/char50/char59/char10/char4a/charcb/char40 /char49/char2e/char4a/char0a/charcb/char41/char83/char40/char09/charad/char4a/char0a/char4a/char0a/charba/char10/char4b /char2e/char32 /char2e/char10/chare9/char4b/char0a/charf1/chard2/char09/char4a/char10/char4a/charcb/char40 /charf0/char40/char10/chare9/char4a/char0a/charca/char93/char40/charf1/char10/char4a/charcb/char40\n/charbd/charcb/char09/char58/char09/chare1/chard2/char09/char92/char10/char4a/char4b/char0a/char2e /char49/char2e/charcb/char41/chara3 /charc9/charbe/charcb/char10/chare8/char58/char59/char6a/chard6/charcf/char40/char10/char48/char41/char67/char2e/char41/char4a/char0a/char10/char4a/char6b/char42/char40/char10/chare9/char4a/char0a/char4a/char2e/charca/char10/char4a/charcb /chard1/charee/char45/char2e/char10/chare9/char93/char41/char09/char6d/charcc/char27/char40 /char81/char1d/char0a/char50/char59/char10/char4a/charcb/char40\n/char10/chare9/char4a/char0a/chard2/char4a/char0a/charca/charaa/char10/char4a/charcb/char40 /char58/char40/charf1/chard6/charcf/char40 /charf0/char40 /char2c/char10/chare9/char4b/char0a/char51/chare5/char94/char4a/char2e/charcb/char40 /charc9/char0d/char4b/char41/char83/charf1/charcb/char40 /charf0/char40 /char2c/char10/chare8/char59/charab/char41/char82/chard6/charcf/char40 /char41/char4a/char0a/char6b/char2e/charf1/charcb/charf1/char09/char4a/charba/char10/char4a/charcb/char40 /chard0/char40/char59/char09/char6a/char10/char4a/char83/char40\n/charc9/charbe/char11/char82/char1d/char2e/charc9/chard2/charaa/charcb/char40/char09/chare1/char1e/char0a/chard2/charca/charaa/chard6/charcf/char40/charfa/charce/charab /char49/char2e/char6d/char2e/char1a/char27/char0a/char3a/char10/chare9/char4b/char0a/char41/charab/char51/charcb/char40 /charfa/char0a/chard7/char59/char10/charae/chard3/charf0 /char50/charf1/chard3/char42/char40 /char5a/char41/char4a/char0a/charcb/charf0/char40 /chara9/chard3/char09/chare0/charf0/char41/charaa/char10/char4a/charcb/char40 /char2e/char33 /char2e/char10/chare9/char92/char92/char09/char6a/char10/char4a/chard6/charcf/char40\n/chard5/chare6/char0a/char10/charae/charcb/char40/charf0/char10/char48/char40/char50/char41/charea/chard6/charcf/char40/charf0/char09/charac/char50/char41/charaa/chard6/charcf/char40 /char50/char41/char10/char4a/char09/char6d/char1a/char09/char27/char09/chare0/char0d/char40 /char41/char09/char4a/charcb/char09/charad/char4a/char0a/charbb /char3a /chard0/char59/char09/char6a/char10/char4a/char82/chard6/charcf/char40\n/char40/char09/char59/chareb /charc9/char09/chara3 /charfa/char0a\n/char09/charaf/char13/char41/char93/charf1/char92/char09/char6b /char2c /char41/char09/char4a/char4b/char2e/char43/chara2/charcb /char41/charea/chard3/char0f/char59/char10/charae/char09/char4b/char09/chare0/char0d/char40/char09/char90/char51/char10/char1e/char09/charae/char4b/char0a/charfa/char0a/char10/chare6/charcb/char40\n/char3a/char50/charf1/char09/char4b /char3f /charc9/char0d/char4b/char41/charea/charcb/char40 /charfa/char0a/char09/chare6/char10/charae/char10/char4a/charcb/char40 /charfa/char0a\n/char09/charaf/char51/charaa/chard6/charcf/char40 /chard1/char09/char6a/char09/char92/char10/char4a/charcb/char40\n/chard5/chare6/char0a/char10/charae/charcb/char40/charf0/char10/char48/char40/char50/char41/charea/chard6/charcf/char40/charf0/char09/charac/char50/char41/charaa/chard6/charcf/char40 /char50/char41/char4a/char0a/char10/char4a/char09/char6b/char40 /char41/charea/charcb/char43/char09/char67/char09/chare1/chard3 /char41/char09/char4a/char09/char4a/charba/chard6/chardf /char0a/char10/char86/char51/chara3/char10/chare8/char59/charab /charbc/char41/char09/char4a/chareb\n/char3a /charc9/char0d/char4b/char41/charea/charcb/char40 /charfa/char0a/char09/chare6/char10/charae/char10/char4a/charcb/char40 /charfa/char0a\n/char09/charaf/char51/charaa/chard6/charcf/char40 /chard1/char09/char6a/char09/char92/char10/char4a/charcb/char40 /char40/char09/char59/chareb /charc9/char09/chara3 /charfa/char0a\n/char09/charaf/char10/chare9/char93/char41/char09/char67 /char2c /char41/char09/char4a/char4b/char2e/char43/chara2/charcb /char41/charea/chard3/char59/char10/charae/char09/char4b /charfa/char0a/char10/chare6/charcb/char40\n/charfa/char0a/charab/char41/chard2/char6d/char2e/charcc/char27/char40 /charc9/chard2/charaa/charcb/char40/charf0 /charc9/char93/char40/charf1/char10/char4a/charcb/char40 /charc9/char11/char4a/chard3/char10/chare9/chard4/charab/char41/char09/char4a/charcb/char40/char10/char48/char40/char50/char41/charea/chard6/charcf/char40 /char3a/char10/chare9/chard4/charab/char41/char09/char4a/charcb/char40/char10/char48/char40/char50/char41/charea/chard6/charcf/char40/charfa/charce/charab/char09/char51/char1e/char0a/charbb/char51/char10/char1e/charcb/char40 /char2e/char31\n/charf8/char0a/char09/char59/charcb/char40 /chard0/charf1/char4a/char0a/charcb/char40 /chard5/charcb/char41/charab /charfa/char0a\n/char09/charaf/char10/chare9/char4a/char0a/char83/char41/char83/char40/char10/char48/char40/char50/char41/charea/chard3 /charf9/char0a/chareb /charf8/char0a/char59/char10/charae/char09/char4a/charcb/char40/char51/char1e/char0a/charba/char09/charae/char10/char4a/charcb/char40/charf0/char10/char48/char43/charbe/char11/char82/chard6/charcf/char40 /charc9/char67/charf0\n/char41/char09/char4a/char4b/char2e/char43/chara2/charcb/char10/char48/char40/char50/char41/charea/chard6/charcf/char40 /chare8/char09/char59/chareb /chard5/chare6/char0a/charca/charaa/char10/char4a/charcb/char09/chare1/char4b/char0a/char59/chareb/char41/char67/char2e/charf9/charaa/char82/char09/char1d/char09/chare0/char40 /char49/char2e/char6d/char2e/char1a/char27/char0a/char2e /char41/char4a/char0a/char6b/char2e/charf1/charcb/charf1/char09/char4a/charba/char10/char4a/charcb/char40/charfa/charce/charab /char59/chard2/char10/char4a/charaa/char4b/char0a\n/char2e/char51/char1e/char0a/char09/charaa/char10/char4a/charcb/char40 /chara9/char4b/char0a/char51/chare5/char85 /chard5/charcb/char41/charab /charfa/char0a\n/char09/charaf /char68/char41/char6a/char2e/char09/char4a/charcb/char40/charfa/charce/charab /chard1/charee/char10/char45/char59/charab/char41/char82/chard6/charcf/char10/chare8/char51/charba/char4a/char2e/chard3/char09/chare1/char83/char09/char59/char09/char4a/chard3\n/char2c /chard5/chare6/char0a/charca/charaa/char10/char4a/charcb/char40 /charfa/char0a\n/char09/charaf /char41/char4a/char0a/char6b/char2e/charf1/charcb/charf1/char09/char4a/charba/char10/char4a/charca/charcb /char59/char4b/char0a/char40/char09/char51/char10/char1e/chard6/charcf/char40 /chard0/char40/char59/char09/char6a/char10/char4a/char83/char42/char40 /chara9/chard3 /char3a /char81/char1d/char0a/char50/char59/char10/char4a/charcb/char40 /charfa/char0a\n/char09/charaf /char41/char4a/char0a/char6b/char2e/charf1/charcb/charf1/char09/char4a/charba/char10/char4a/charcb/char40 /char6c/char2e/chard7/char58 /char2e/char32\n/chard0/char40/char59/char09/char6a/char10/char4a/char83/char40 /char41/char09/char4a/char09/char4a/charba/chard6/chardf /char0a/char2e /charf8/char0a/char59/char10/charae/char09/char4a/charcb/char40/char51/char1e/char0a/charba/char09/charae/char10/char4a/charcb/char40/charf0 /chara1/char11/char82/char09/char1c/charcb/char40 /chard5/charce/charaa/char10/char4a/charcb/char40/char09/char50/char09/char51/charaa/char10/char4b/char10/chare9/char10/charae/char4b/char0a/char51/chara2/char1d/char2e/char81/char1d/char0a/char50/char59/char10/char4a/charcb/char40 /charfa/char0a\n/char09/charaf /char41/charea/char6d/char2e/chard7/char58 /chard1/charea/chard6/charcf/char40/char09/chare1/chard3\n/chard5/chare7/char27/char0a/char59/char10/charae/char10/char4a/charcb /char41/char4a/char0a/char6b/char2e/charf1/charcb/charf1/char09/char4a/charba/char10/char4a/charcb/char40\n/charc8/char40/char59/char4a/char2e/char10/char1c/char83/char40 /chara9/char4a/char0a/chara2/char10/char1c/char82/char09/char1c/char83 /charc9/chareb /char3a /chard0/char59/char09/char6a/char10/char4a/char82/chard6/charcf/char40\n/char3a /char50/charf1/char09/char4b /char3f /charfa/char0a/charab/char41/char09/char4a/chara2/char93/char42/char41/char4b/char2e/charf8/char0a/char51/chare5/char11/char84/char4a/char2e/charcb/char40 /char49/char2e/charca/char10/charae/charcb/char40\n/charc8/char40/char59/char4a/char2e/char10/char1c/char83/char42/char10/chare9/char4b/char0a/charf1/char4a/char0a/char6d/charcc/char27/char40/char10/chare9/char4a/char0a/char4a/char2e/chara2/charcb/char40/char10/chare9/char83/char59/char09/char4a/charea/charcb/char40 /charc8/char41/char6d/char2e/chard7/charfa/char0a\n/char09/charaf/char10/chare8/char51/chard2/char10/char4a/char82/chard3/char11/char48/char41/char6d/char1a/char27/char2e/char40 /charbc/char41/char09/char4a/chareb/char09/chare0/char40/char09/chare1/char1e/char0a/char67 /charfa/char0a\n/char09/charaf\n/charf8/char0a/char51/chare5/char11/char84/char4a/char2e/charcb/char40 /char49/char2e/charca/char10/charae/charcb/char40 /charc8/char40/char59/char4a/char2e/char10/char1c/char83/char40 /chard5/char10/chare6/char4b/char0a/char09/chare0/char40 /char6c/char6b/char2e/char51/chard6/charcf/char40/char51/char1e/char0a/char09/charab/char09/chare1/chard4/char09/charaf/char2c /charfa/char0a/charab/char41/char09/char4a/chara2/char93/char42/char40 /charf8/char0a/char51/chare5/char11/char84/char4a/char2e/charcb/char40 /char49/char2e/charca/char10/charae/charcb/char40\n/char2c /char50/char41/char4a/char2e/char10/char4a/charab/char42/char40 /charfa/char0a\n/char09/charaf /char41/chareb/char09/char59/char09/char67/char40 /char49/char2e/char6d/char2e/char1a/char27/char0a/charfa/char0a/char10/chare6/charcb/char40 /charc9/chard3/char40/charf1/charaa/charcb/char40/char09/chare1/chard3 /char59/char4b/char0a/char59/charaa/charcb/char40 /charbc/char41/char09/char4a/chareb /char2e /char49/char2e/char4b/char0a/char51/char10/charae/charcb/char40 /charc9/char4a/char2e/char10/charae/char10/char4a/char82/chard6/charcf/char40 /charfa/char0a\n/char09/charaf /charc9/chard3/char41/charbe/charcb/char41/char4b/char2e\n/char10/chare9/char4a/char0a/char10/charaf/char43/char09/char67/char42/char40 /char50/char41/char11/char4b/char42/char40/charf0 /char2c /char5a/char41/char09/char92/charab/char43/charcb/char10/chare9/char10/charaf/charf1/char11/char4b/charf1/chard3 /char50/char58/char41/char92/chard3 /charfa/charcd/char40/char10/chare9/char6b/char2e/char41/char6d/charcc/char27/char40/charf0 /char2c /chara8/char50/char09/char51/charcb/char40/char10/chare9/char4a/char0a/charca/chard4/charab/char10/chare9/char09/charae/charca/charbe/char10/char4b /charc9/char11/char4a/chard3\n/char2c /charbd/charcb/char09/char58 /charfa/charcd/char40/char10/chare9/char09/charaf/char41/char09/char93/char42/char41/char4b/char2e/char2e /charfa/char0a/charab/char41/char09/char4a/chara2/char93/char40 /char51/char09/char6b/char41/char4b/char2e/charf8/char0a/charf1/char4a/char0a/char6b /charf1/char09/char92/charab /charc8/char40/char59/char4a/char2e/char10/char1c/char83/char42\n/charc8/char40/char59/char4a/char2e/char10/char1c/char83/char40 /char59/char09/char4a/charab /char41/charee/char10/char45/char41/charab/char40/char51/chard3 /char49/char2e/char6d/char2e/char1a/char27/char0a/charfa/char0a/char10/chare6/charcb/char40 /charc9/chard3/char40/charf1/charaa/charcb/char40/char09/chare1/chard3 /char59/char4b/char0a/char59/charaa/charcb/char40 /charbc/char41/char09/char4a/chareb\n/char10/chare9/char4b/char0a/char41/charee/char09/char45 /charfa/char0a\n/char09/charaf /char2e/char09/char91/char1d/char0a/char51/chard2/charca/charcb/char10/chare9/char4a/char0a/char6a/char92/charcb/char40/char10/chare9/charcb/char41/char6d/charcc/char27/char40/charf0 /char2c /chare9/charcb/char40/char59/char4a/char2e/char10/char1c/char83/char40 /char58/char40/char51/chard6/charcf/char40 /charf1/char09/char92/charaa/charcb/char40 /chara8/charf1/char09/char4b/charf0 /char2c/char09/char91/char1d/char0a/char51/chard6/charcf/char40 /char51/chard4/charab/charc9/char11/char4a/chard3 /char2c /char5a/char41/char09/char92/charab/char42/char40\n/char10/chare9/char6b/char2e/char41/char67 /charbc/char41/char09/char4a/chareb/char09/chare0/charf1/charba/char10/char4b/char09/chare0/char40 /char6c/char6b/char2e/char51/chard6/charcf/char40/char09/chare1/chard3 /char2c/char09/charac/char41/chara2/chard6/charcf/char40\nTable 11: Best Answers from the \"Question\" style prompts from the model fine-tuned on UltraChat-Ar (10%).\n264\nTraining set A Training set B\nTest set A 76.0 75.7\nTest set B 73.3 75.7\nTest set A 81.8 82.0\nTest set B 78.3 81.8\nTable 12: F1 (top) and accuracy (bottom) percentage\nscores for the classifier trained on, respectively, training\nset A (left) and B (right).\nIdentity Percentage Identity Percentage\nBlack 11.4 Jewish 9.8\nAtheist 9.6 Spanish 9.0\nLatino 8.5 Chinese 8.4\nWhite 8.3 Hindu 7.8\nIndian 7.7 African 7.6\nArabic 7.5 Asian 7.0\nRussian 7.0 European 6.7\nMuslim 6.1 Brown 5.9\nChristian 5.8 Pakistani 5.5\nBuddhist 5.4 Japanese 5.4\nKorean 4.3\nFemale 9.9 Male 7.9\nTable 13: Percentage of produced potentially toxic state-\nments with respect to each studied identity, ordered from\nhighest to lowest scores\nE Toxicity and bias analysis\nE.1 Bad word filter\nIn order to filter out potentially inappropriate state-\nments, we apply a \"bad-word\" filter on the pro-\nduced completions. To achieve this, we collected\nand merged 3 sources of Arabic bad words 13 14 15 .\nThe obtained list has been split into two subsets,\none containing obscene words and one with poten-\ntially toxic ones. For each generated sentence, we\ncompute its toxicity score, adding 1 to the total for\neach obscene word and 0.34 for mid bad words.\nThe produced content is then filtered out, removing\nall completions with a toxicity score over 1.\n13https://github.com/ASammour/bad-words-AR/\nblob/master/words.js\n14https://github.com/LDNOOBW/\nList-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-/\nblob/master/ar\n15https://github.com/uxbert/arabic_\nbad_dirty_word_filter_list/blob/master/\narabic-profanity-bad-words-dictionary.txt\nE.2 Top-10 descriptive words for social groups\nAt first, we report the list of the adjectives that are\nnot reported among the top-10 descriptive words\nas they are too general and not particularly de-\nscriptive: always (/char41/chard6/char0d/chardf/char40/char58), more (/char51/char11/char1e/charbb /char40), many (/char59/char4b/char0a/char59/charaa/charcb/char40),\nespecially ( /char10/chare9/char93/char41/char09/char67), other (/charf8/char51/char09/char6b/char40), own (/charbd/charca/chard3), gen-\neral ( /chard0/char41/charaa/charcb/char40), some ( /char09/char91/charaa/char4b/char2e), different ( /char10/chare9/char09/charae/charca/char10/char4a/char09/char6a/chard6/charcf/char40), last\n( /char10/chare8/char51/char1e/char0a/char09/char67/char42/char40). In Tables 14, 15, 16, 17 we display the\ntop-10 most common adjectives generated by our\n14B model for, respectively, gender, religion, na-\ntionality and Arabic ethnicity identities in the com-\npletions. We can notice at first that the generated\nadjectives generally belong to the semantic field of\ntheir prompted social group. For example, when in-\nspecting religious identities we encounter a variety\nof terms relates to spirituality, with a stronger pres-\nence of science and materialism for Atheists. For\nnational identities, we can notice terms related to\nnational populations and geopolitics, with a focus\non the geographical area of interest. Overall, no\nparticular biases is displayed for the studied social\ngroups.\nE.3 Toxic language classifier\nAs proposed in (Ousidhoum et al., 2021), we probe\nthe eventual bias in the assessed LLMs using a\nsimple logistic regression model as toxic language\nclassifier. The embedding of sentences is obtained\nusing (Grave et al., 2018) Arabic word vectors. We\ninclude in the training set 3 out of the 4 datasets\nused in (Ousidhoum et al., 2021), in particular\n(Ousidhoum et al., 2019), (Zampieri et al., 2020)\nand (Mulki et al., 2019), since (Albadi et al., 2018)\nis not publicly available as of the writing of this\npaper. Moreover, we integrate in our training set\ntwo more hate speech datasets: (Mubarak et al.,\n2021) and (Alakrot et al., 2018). The selection of\nthe training datasets as been performed as follows:\nall of the 5 candidates datasets have been sliced in\ntraining and test subsets. Then, we refer as Dataset\nA as the one obtained from the merging of the sub-\nsets of the 3 originally included only. On the other\nhand, we name as Dataset B the one that includes\nall of the 5 considered datasets. The subsets slicing\nhas been performed as first step in order to prevent\nthe occurrence of a data leakage between any of\nthe training and test segments. We trained the same\narchitecture on, respectively, the balanced training\nslice of Dataset A and B and evaluated on both test\nsubsets A and B. The F1 and accuracy scores for\n265\nTerm Top-10 descriptive words\nMan /charc9/char09/char92/char09/charaf/char40better, /char51/char1e/char0a/char4a/char2e/charbbbig, /char10/chare9/char4a/char0a/char6b/char2e/charf0/char09/char51/charcb/char40marital, /char10/chare9/char4b/char0a/charf1/char10/charafstrong, /chare9/char10/char4a/char4a/char2e/char1c/char0a/char4a/char2e/char6bsweetheart, /charfa/char0a/char6b/char2e/char50/char41/char09/char6d/charcc/char27/char40external,\n/char10/chare9/char4a/char0a/char92/char09/char6a/char11/char82/charcb/char40personal, /charc9/char4b/char0a/charf1/chara2/charcb/char40long, /char51/char1e/char2e/charbb /char40greater, /char49/char2e/char83/char41/char09/char4a/chard6/charcf/char40appropriate\nMen /charc9/char09/char92/char09/charaf/char40better,/char51/char1e/char0a/char4a/char2e/charbbbig, /char10/chare9/char4a/char0a/charcb/char41/char67/char2e/char51/charcb/char40menswear, /char59/char4b/char0a/char59/char67/char2enew,/charfa/char0a/charcd/char41/char67/char2e/char51/charcb/char40men, /char10/chare9/char4a/char0a/char09/char93/char41/char4b/char0a/char51/charcb/char40sport, /char10/chare8/char09/char51/char1e/char0a/chard2/chard6/charcf/char40\nfeatured, /char10/chare9/char4a/char0a/chard6/charcf/char41/charaa/charcb/char40globalism,/charfa/char0a/char6b/char2e/char50/char41/char09/char6d/charcc/char27/char40external, /char09/char51/char1e/char0a/chardc/chard8distinct\nWoman /charc9/char09/char92/char09/charaf/char40better, /char59/char4b/char0a/char59/char67/char2enew, /char10/chare9/charaa/char0d/char4b/char40/char50amazing, /char10/chare9/char4a/char0a/charaa/char4a/char0a/char4a/char2e/chara2/charcb/char40natural, /char51/char1e/char0a/char4a/char2e/charbbbig, /char10/chare9/charaa/char0d/char4b/char40/char51/charcb/char40brilliant, /char10/chare9/char4a/char0a/charaa/char4a/char0a/char4a/char2e/chara3\nnormal, /char51/char1e/char0a/char92/char10/charafshort, /char10/char48/char41/char4a/char2e/char6a/char2e/char6a/chard2/charca/charcbfor veiled women, /char10/char48/char41/char4a/char2e/char6a/char2e/char6d/chard7veiled\nWomen /char59/char4b/char0a/char59/char67/char2enew, /charc9/char09/char92/char09/charaf/char40better, /char10/chare9/char4a/char0a/charaa/char4a/char0a/char4a/char2e/chara2/charcbnatural, /char10/chare9/charaa/char0d/char4b/char40/char50amazing, /char10/chare9/char4a/char0a/charaa/char4a/char0a/char4a/char2e/chara3normal, /char51/char1e/char0a/char92/char10/charae/charcb/char40short, /char10/chare9/charaa/char0d/char4b/char40/char51/charcb/char40\nlong, /char10/chare9/charaa/char0d/char4b/char40/char51/charcb/char40brilliant, /chard1/charab/char41/char09/char4bsmooth, /char51/char1e/char0a/char4a/char2e/charbbbig\nShe /charc9/char09/char92/char09/charaf/char40better, /char10/chare8/char59/char4b/char0a/char59/char67/char2enew, /char51/char1e/char0a/char4a/char2e/charbbbig, /charfa/char0a/charab/char41/chard2/char10/char4a/char6b/char2e/char42/char40social, /char10/chare9/char4a/char0a/char09/char4a/char09/charae/charcb/char40artistic, /char10/chare8/char09/char51/char1e/char0a/chard2/chard6/charcf/char40featured, /char90/char41/char09/char6d/charcc/char27/char40\nprivate, /char10/char48/char41/char4a/char2e/char6a/char2e/char6d/chard7veiled, /char10/chare9/charaa/char0d/char4b/char40/char51/charcb/char40brilliant, /char10/chare9/charaa/char0d/char4b/char40/char50amazing\nTable 14: Top-10 most common descriptive words found in the first sentence, gender-related identities\nTerm Top-10 descriptive words\nMuslim /chard5/charce/char82/chard6/charcf/char40Muslim, /charc9/char09/char92/char09/charaf/char40better, /char10/chare9/char4a/char0a/char09/char1c/char4b/char0a/char59/charcb/char40religious, /char10/chare9/char4a/char0a/chard3/char43/char83/char40Islamic, /char10/chare9/char4b/char0a/charf1/char4a/char2e/char09/char4a/charcb/char40prophetic, /chard5/chare7/char0d/char27/char40/char58perma-\nnent, /char59/char4b/char0a/char59/char67/char2enew, /char69/char4a/char0a/char6d/char19/char95correct, /char09/chare1/charba/chard2/chard6/charcf/char40possible, /char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40Arabic\nChristian /charfa/char0a/char6a/char4a/char0a/char82/chard6/charcf/char40Christian, /char80/char59/char10/charae/chard6/charcf/char40holy, /char59/char4b/char0a/char59/char67/char2enew, /chard5/charce/char82/chard6/charcf/char40Muslims, /char10/chare9/char4a/char0a/char09/char1c/char4b/char0a/char59/charcb/char40religious, /charf9/char0a\n/char10/charae/char4a/char0a/char10/charae/char6d/charcc/char27/char40real,\n/char10/chare9/char4b/char0a/char59/char4b/char2e/char42/char40eternal, /charc9/char09/char92/char09/charaf/char40better, /char10/chare9/char4a/char0a/char09/char4b/char41/char82/char09/char1d/char42/char40humanity, /char59/char4a/char0a/char6b/charf1/charcb/char40the only\nBuddhist /charf8/char0a/char09/char58/charf1/char4a/char2e/charcb/char40Buddhism, /char10/chare9/char4a/char0a/char09/char1c/char4b/char0a/char59/charcb/char40religious,/charfa/charce/charab/char40higher, /char10/chare9/char4b/char0a/char09/char58/charf1/char4a/char2e/charca/charcbfor Buddhism, /charc8/charf0/char42/char40the first, /char51/char1e/char2e/charbb /char40\ngreater, /char10/chare9/charca/chard3/char41/charbe/charcb/char40full, /charc9/char09/char92/char09/charaf/char40better, /charfa/char0a/chare6/char84/char09/charae/char09/char4a/charcb/char40psycho , /char10/chare9/char4a/char0a/char09/char4b/char41/char82/char09/char1d/char42/char40humanity\nAtheist /char10/chare9/char4a/char0a/char10/charae/chara2/char09/char4a/chard3boolean,/chard5/charce/char82/chard6/charcf/char40Muslim, /char10/chare9/char4a/char0a/char09/char1c/char4b/char0a/char59/charcb/char40religious,/charfa/char0a/chard7/char43/char83/char42/char40Islamic, /char69/char4a/char0a/char6d/char19/char95correct, /char10/chare9/char4a/char0a/chard2/charca/charab\nscientific,/charc8/charf0/char42/char40first, /charf8/char0a/char58/char41/chard3material, /char6c/char19/char09/char95/char40/charf0clear,/charfa/char0a\n/char10/charaf/char43/char09/char67/char40moral\nTable 15: Top-10 most common descriptive words found in the first sentence, religious identities\n266\nTerm Top-10 descriptive words\nAmerican /char10/chare9/char4a/char0a/charba/char4b/char0a/char51/chard3/char42/char40American, /char10/chare8/char59/char6a/char10/char4a/chard6/charcf/char40United, /char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40Arabic,/chara1/char83/charf0/char42/char40middle, /char10/chare9/char4a/char0a/char09/char1c/char4a/char0a/chara2/char82/charca/char09/charae/charcb/char40\nPalestian, /char10/chare9/char4a/char0a/chard6/charcf/char41/charaa/charcb/char40globalism, /char51/char1e/char0a/char4a/char2e/charbbbig, /char10/chare9/char4b/char0a/char58/char41/char92/char10/char4a/char10/charaf/char42/char40economic, /char10/chare9/char4a/char0a/char6b/char2e/char50/char41/char09/char6d/charcc/char27/char40external,\n/char10/chare9/char4b/char0a/char51/charba/char82/charaa/charcb/char40military\nChinese /char10/chare9/char4a/char0a/char09/char4a/char1c/char0a/char92/charcb/char40Chinese, /char10/chare8/char59/char6a/char10/char4a/chard6/charcf/char40United, /char10/chare9/char4a/char0a/charba/char4b/char0a/char51/chard3/char42/char40American, /char51/char1e/char0a/char4a/char2e/charbbbig , /char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40Arabic,\n/charc9/char09/char92/char09/charaf/char40better, /char51/char1e/char2e/charbb /char40greater, /char10/chare9/char4a/char0a/charcb/charf0/char59/charcb/char40international, /char10/chare8/char59/charabseveral, /char10/chare9/char4a/char0a/chard6/charcf/char41/charaa/charcb/char40globalism\nIndian /charf8/char0a/char59/char09/char4a/charea/charcb/char40Indian, /char10/chare9/char4b/char0a/char59/char09/char4a/charea/charcb/char40Hindi, /char51/char1e/char0a/char4a/char2e/charbbbig, /charc9/char09/char92/char09/charaf/char40better , /char10/chare9/charaa/char0d/char4b/char40/char51/charcb/char40brilliant, /char10/chare9/char4a/char0a/char92/char09/char6a/char11/char82/charcb/char40\npersonal, /char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40Arabic, /char10/chare8/char09/char51/char1e/char0a/chard2/chard6/charcf/char40featured, /char59/char4b/char0a/char59/char67/char2enew, /char10/chare9/char4a/char0a/charaa/char4a/char0a/char4a/char2e/chara2/charcb/char40natural\nBrazilian /charfa/char0a/charce/char4b/char0a/char09/char50/char40/char51/char1e/char2e/charcb/char40Brazilian, /charc9/char09/char92/char09/charaf/char40better, /charc9/char09/char92/char09/charaf/char42/char40the best, /charc8/charf0/char42/char40first, /char51/char1e/char0a/char4a/char2e/charbbbig, /charfa/char0a/charcd/char41/chara2/char1d/char0a/char42/char40\nItalian, /charfa/char0a\n/char09/char47/char41/char4a/char2e/char83/char42/char40Spaniard, /char51/char1e/char0a/char4a/char2e/charba/charcb/char40great, /char10/chare9/char4a/char0a/char4b/char2e/charf0/char50/charf0/char42/char40European, /charf9/char0a/char0d/char4b/char41/charee/char09/char44/charcb/char40final\nIndonesian /charfa/char0a/chare6/char84/char4a/char0a/char09/char4b/charf0/char59/char09/char4b/char42/char40Indonesian, /charc9/char09/char92/char09/charaf/char40better, /char10/chare8/char51/char1e/char0a/char4a/char2e/charbbbig , /char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40Arabic, /charc8/charf0/char42/char40first,\n/char10/chare9/char4a/char0a/char6b/char41/char4a/char0a/char82/charcb/char40tourist, /char10/chare9/char4a/char0a/chard3/char43/char83/char42/char40Islamic, /char10/chare8/char59/char4b/char0a/char59/char67/char2enew, /char10/chare9/char4b/char0a/char58/char41/char92/char10/char4a/char10/charaf/char42/char40economic, /char10/chare9/char4b/char0a/charf1/char4a/char0a/char83/char42/char40\nAsian\nBangladeshi /charfa/char0a/chare6/char11/char84/char1d/char0a/char58/char43/char09/charaa/char09/char4a/char4a/char2e/charcb/char40Bangladeshi, /charc9/char09/char92/char09/charaf/char40better , /char10/chare9/char4b/char0a/char59/char09/char4a/charea/charcb/char40Hindi, /char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40Arabic, /char10/chare8/char59/char4b/char0a/char59/char67/char2enew,\n/charfa/char0a/chare6/char09/char95/char41/chard6/charcf/char40past, /char10/chare8/char51/char1e/char0a/char4a/char2e/charbbbig, /char51/char1e/char2e/charbb /char40greater, /char10/chare9/char4a/char0a/chard3/char43/char83/char42/char40Islamic, /charc9/char09/char92/char09/charaf/char42/char40the best\nPakistani /charc9/char09/char92/char09/charaf/char42/char40the best, /char10/chare9/chard6/chardf /char0a/char59/char10/charae/charcb/char40old, /char10/chare9/char4b/char0a/char59/char09/char4a/charea/charcb/char40Hindi, /chard5/charce/char82/chard6/charcf/char40Muslim, /char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40Arabic, /char10/chare8/char51/char1e/char0a/char4a/char2e/charbb\nbig, /char10/chare9/char4a/char0a/charcb/char41/char6d/charcc/char27/char40current, /charfa/charcd/charf0/char42/char40first, /char10/chare9/char4a/char0a/chard3/char43/char83/char42/char40Islamic, /charf8/char0a/charf1/char4b/char2e/char51/char10/char1e/charcb/char40educational\nCanadian /charf8/char0a/char59/char09/char4a/charba/charcb/char40Canadian, /char10/chare9/char4a/char0a/charba/char4b/char0a/char51/chard3/char42/char40American, /charc9/char09/char92/char09/charaf/char40better,/char51/char1e/char0a/char4a/char2e/charbbbig, /char10/chare8/char59/char6a/char10/char4a/chard6/charcf/char40United,\n/chard0/char41/char09/char6d/charcc/char27/char40raw, /char10/chare9/char4a/char0a/chard6/charcf/char41/charaa/charcb/char40globalism, /char10/chare9/char4b/char0a/char58/char41/char92/char10/char4a/char10/charaf/char42/char40economic, /char10/char48/char41/char4a/char0a/char82/char09/char1d/char41/chard3/charf0/char50romances, /char51/char1e/char2e/charbb /char40\ngreater\nJapanese /char10/chare9/char4a/char0a/char09/char4b/char41/char4b/char2e/char41/char4a/char0a/charcb/char40Japanese, /char10/chare8/char51/char1e/char0a/char4a/char2e/charbbbig, /char10/chare9/char4a/char0a/chard6/charcf/char41/charaa/charcb/char40globalism, /char10/chare9/char4a/char0a/char09/char4b/char41/char11/char4a/charcb/char40the second, /charf8/char0a/char58/charf1/charaa/char82/charcb/char40Saudi,\n/char59/char4b/char0a/char59/char67/char2enew, /char10/chare9/char11/char4a/char4b/char0a/char59/char6d/charcc/char27/char40modern, /charc8/charf0/char42/char40the first, /char51/char1e/char2e/charbb /char40greater, /char10/chare9/char4b/char0a/charf1/char4a/char0a/char83/char42/char40Asian\nNigerian /charf8/char0a/char51/char1e/char0a/char6a/char2e/char4a/char0a/char09/char4a/charcb/char40Nigerian, /char10/chare8/char51/char1e/char0a/char4a/char2e/charbbbig, /char10/chare9/char4a/char0a/char10/charae/char4b/char0a/char51/char09/charaf/char42/char40African, /charc8/charf0/char42/char40the first, /charfa/char0a/char09/chare6/char09/charae/charcb/char40artistic,\n/charc9/char09/char92/char09/charaf/char40better, /char10/chare9/char4b/char0a/charf1/char10/charafstrong, /charfa/charcd/charf0/char42/char40the first, /charf9/char0a/char0d/char4b/char41/charee/char09/char44/charcb/char40final, /char10/chare9/charca/char4b/char0a/charf1/chara3long\nRussian /charfa/char0a/chare6/char85/charf0/char51/charcb/char40Russian, /char10/chare8/char59/char6a/char10/char4a/chard6/charcf/char40United, /char10/chare9/char4a/char0a/charba/char4b/char0a/char51/chard3/char42/char40American, /char10/chare9/char4a/char0a/charcb/charf0/char59/charcb/char40international,\n/char10/chare9/char4b/char0a/char51/charba/char82/charaa/charcb/char40military, /char10/chare9/char4b/char0a/char50/charf1/char82/charcb/char40Syrian, /charc9/char09/char92/char09/charaf/char40better, /char10/chare9/char4a/char0a/char83/char41/char4a/char0a/char82/charcb/char40political, /charfa/char0a/char47/char2e/charf0/char50/charf0/char42/char40\nEuropean, /char10/chare9/char4a/char0a/chard6/charcf/char41/charaa/charcb/char40globalism\nGerman /charfa/char0a\n/char09/char47/char41/chard6/charcf/char42/char40German, /charc8/charf0/char42/char40first, /charc9/char09/char92/char09/charaf/char40better, /char51/char1e/char0a/char4a/char2e/charbbbig, /char10/chare9/char4a/char0a/chard6/charcf/char41/charaa/charcb/char40globalism, /char10/chare9/char4a/char0a/char4b/char2e/charf0/char50/charf0/char42/char40\nEuropean, /charfa/char0a\n/char09/char47/char41/char11/char4a/charcb/char40second, /char10/chare8/char51/char1e/char0a/char4a/char2e/charbbbig, /char10/chare8/char59/char4b/char0a/char59/char67/char2enew, /char10/chare9/char4a/char0a/char09/char4b/char59/char4a/char2e/charcb/char40physical\nTable 16: Top-10 most common descriptive words found in the first sentence, national identities\n267\nTerm Top-10 descriptive words\nArabic /char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40Arabic, /char51/char1e/char0a/char4a/char2e/charbbbig, /char59/char4b/char0a/char59/char67/char2enew, /charc8/charf0/char42/char40first, /char10/chare9/char4a/char0a/char92/char09/char6a/char11/char82/charcb/char40personal, /charfa/char0a/charab/char41/chard2/char10/char4a/char6b/char2e/char42/char40social, /char10/chare9/char4a/char0a/char09/char93/char41/chard6/charcf/char40\npast, /char10/chare9/char4a/char0a/char4b/char2e/char51/char09/charaa/charcb/char40western, /char40/char51/char1e/char0a/char4a/char2e/charbbgreat, /char90/char41/char09/char6d/charcc/char27/char40private\nMoroccan /charfa/char0a/char47/char2e/char51/char09/charaa/chard6/charcf/char40Moroccan, /char10/chare9/char4a/char0a/char10/charae/char4b/char0a/char51/char09/charaf/char42/char40African, /charfa/char0a/char09/chare6/chara3/charf1/charcb/char40national, /charfa/charcd/charf0/char42/char40first, /char10/chare8/char51/char1e/char0a/char4a/char2e/charbbbig, /charf9/char0a/char0d/char4b/char41/charee/char09/char44/charcb/char40final,\n/charfa/char0a/char47/char2e/char51/charaa/charcb/char40Arabi, /charc9/char09/char92/char09/charaf/char40better, /char10/chare9/char4a/char0a/char4b/char2e/charf0/char50/charf0/char42/char40European, /char10/chare9/char4b/char0a/char51/char0d/char4b/char40/char09/char51/char6b/char2eAlgerian\nAlgerian /charf8/char0a/char51/char0d/char4b/char40/char09/char51/char6d/char2e/charcc/char27/char40Algerian, /char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40Arabic, /charfa/char0a/char09/chare6/chara3/charf1/charcb/char40national, /charc9/char09/char92/char09/charaf/char40better, /charfa/char0a/chare6/char84/char09/char1d/char51/char09/charae/charcb/char40French, /charc8/charf0/char42/char40first,\n/char10/chare9/char4a/char0a/char10/charae/char4b/char0a/char51/char09/charaf/char42/char40African, /char51/char1e/char0a/char4a/char2e/charbbbig, /char10/chare9/char4a/char0a/charcb/charf0/char59/charcb/char40international, /charf9/char0a/char0d/char4b/char41/charee/char09/char44/charcb/char40final\nSaudi /charf8/char0a/char58/charf1/charaa/char82/charcb/char40Saudi, /char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40Arabic, /charc9/char09/char92/char09/charaf/char40better,/char10/chare8/char51/char1e/char0a/char4a/char2e/charbbbig, /char10/chare9/char4a/char0a/chard6/charcf/char41/charaa/charcb/char40globalism, /char10/chare9/char4a/char0a/char09/char93/char41/char4b/char0a/char51/charcb/char40\nsports,/charfa/char0a\n/char09/char47/char41/char11/char4a/charcb/char40second, /charfa/char0a/chare6/char09/char95/char41/char4b/char0a/char51/charcb/char40athlete, /charc9/char09/char92/char09/charaf/char42/char40best, /charfa/char0a/char09/chare6/chara3/charf1/charcb/char40national\nEmirati /char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40Arabic, /charfa/char0a\n/char10/char47/char40/char50/char41/chard3/char42/char40Emirati, /charfa/char0a/char47/char2e/char51/charaa/charcb/char40Arabi, /charc8/charf0/char42/char40first, /char10/chare9/char4a/char0a/char09/char93/char41/char4b/char0a/char51/charcb/char40sports, /char10/chare9/char4a/char0a/chard6/charcf/char41/charaa/charcb/char40globalism,\n/char10/chare9/char4a/char0a/charcb/charf0/char59/charcb/char40international, /char10/chare8/char59/char4a/char0a/char11/char83/char51/charcb/char40rational, /char10/chare8/char59/char6a/char10/char4a/chard6/charcf/char40United, /char10/chare9/char4a/char0a/char09/char4b/char41/char82/char09/char1d/char42/char40humanity\nLebanese /char81/char09/char1c/char4a/char2e/char4bLebanese, /char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40Arabic, /charc9/char09/char92/char09/charaf/char40better,/char51/char1e/char0a/char4a/char2e/charbbbig, /char10/chare9/char4b/char0a/char58/char41/char92/char10/char4a/char10/charaf/char42/char40economic, /charfa/charcd/charf0/char42/char40first,\n/char10/chare9/char4a/char0a/char83/char41/char4a/char0a/char82/charcb/char40political, /char10/chare8/char59/char4b/char0a/char59/char67/char2enew,/chare9/charba/char6a/char09/char92/chard3funny, /char10/chare9/char4a/char0a/charab/char41/chard2/char10/char4a/char6b/char2e/char42/char40social\nKuwaiti /charfa/char0a/char10/chare6/char4b/char0a/charf1/charba/charcb/char40Kuwaiti, /char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40Arabic, /char51/char1e/char0a/char4a/char2e/charbbbig, /charc9/char09/char92/char09/charaf/char40better, /char10/chare9/char4a/char0a/char09/char4a/chara3/charf1/charcb/char40national, /char10/chare9/char4a/char0a/char09/char4a/char09/charae/charcb/char40artistic,\n/char10/chare9/char4a/char0a/char09/char93/char41/char4b/char0a/char51/charcb/char40sports,/charfa/char0a/charab/char41/chard2/char10/char4a/char6b/char2e/char42/char40social, /char59/char4b/char0a/char59/char67/char2enew, /char10/chare9/char4a/char0a/chard6/charcf/char41/charaa/charcb/char40globalism\nQatari /char10/chare9/char4b/char0a/char51/chara2/char10/charae/charcb/char40Qatari, /char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40Arabic, /charc9/char09/char92/char09/charaf/char40better, /char10/chare9/char4a/char0a/chard6/charcf/char41/charaa/charcb/char40globalism, /char10/chare9/char4a/char0a/char09/char93/char41/chard6/charcf/char40past, /charc8/charf0/char42/char40first,\n/charc9/char09/char92/char09/charaf/char42/char40best, /char51/char1e/char0a/char4a/char2e/charbbbig, /char10/chare9/char4b/char0a/charf1/char4a/char0a/char83/char42/char40Asian, /char10/chare9/char4b/char0a/charf1/char10/charafstrong\nTunisian /charfa/char0a/chare6/char84/char09/char1d/charf1/char10/char4a/charcb/char40Tunisian, /char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40Arabic, /char51/char1e/char0a/char4a/char2e/charbbbig, /char10/chare9/char4a/char0a/char10/charae/char4b/char0a/char51/char09/charaf/char42/char40African, /charf9/char0a/char0d/char4b/char41/charee/char09/char44/charcb/char40final, /charfa/char0a/char09/chare6/char09/charae/charcb/char40artistic,\n/charfa/char0a/chare6/char09/char95/char41/chard6/charcf/char40past, /charc9/char09/char92/char09/charaf/char40better, /char10/chare8/char59/char4b/char0a/char59/char67/char2enew, /char10/chare9/char4a/char0a/char09/char93/char41/char4b/char0a/char51/charcb/char40sports\nJordanian /charfa/char0a\n/char09/char47/char58/char50/char42/char40Jordanian, /char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40Arabic, /charfa/char0a/char09/chare6/chara3/charf1/charcb/char40national, /char10/chare9/char4a/char0a/char09/char1c/char4a/char0a/chara2/char82/charca/char09/charae/charcb/char40Palestinian, /charc9/char09/char92/char09/charaf/char40better,\n/char10/chare9/char4a/char0a/chard6/charde/char11/char85/char41/charea/charcb/char40Hashemite, /char10/chare9/char4b/char0a/char58/char41/char92/char10/char4a/char10/charaf/char42/char40economic, /char10/chare9/char4a/char0a/char83/char41/char4a/char0a/char82/charcb/char40political,/charfa/charcd/charf0/char42/char40first, /char51/char1e/char0a/char4a/char2e/charbbbig\nSyrian /charf8/char0a/char50/charf1/char82/charcb/char40Syrian, /char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40Arabic, /char51/char1e/char0a/char4a/char2e/charbbbig, /charc8/charf0/char42/char40first, /char10/chare9/char4a/char0a/char09/char1c/char4a/char0a/chara2/char82/charca/char09/charae/charcb/char40Palestinian, /charfa/char0a/charce/char4a/char0a/char0d/char4b/char40/char51/chare5/char85/char42/char40Israeli,\n/charfa/char0a/charbb/char51/char10/char1e/charcb/char40Turkish, /char10/chare9/char4a/char2e/charaa/char93difficult, /char10/chare9/char4a/char0a/chard6/charcf/char41/charaa/charcb/char40globalism, /charfa/char0a/chare6/char85/char41/char4a/char0a/char82/charcb/char40politician\nOmani /charfa/char0a\n/char09/char47/char41/chard2/charaa/charcb/char40Omani, /charc8/charf0/char42/char40first, /charc9/char09/char92/char09/charaf/char40better, /charfa/char0a/char09/chare6/chara3/charf1/charcb/char40national, /char10/chare9/char4a/char0a/char6a/char2e/char4a/char0a/charca/char09/char6d/charcc/char27/char40Gulf, /char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40Arabic,\n/char10/chare9/char4b/char0a/charf1/char4a/char0a/char83/char42/char40Asian, /char51/char1e/char0a/char4a/char2e/charba/charcb/char40great, /char10/chare9/char4a/char0a/char09/char93/char41/char4b/char0a/char51/charcb/char40sports, /char51/char1e/char0a/char4a/char2e/charbbbig\nBahrain /charfa/char0a/char09/chare6/char4b/char0a/char51/char6a/char4a/char2e/charcb/char40Bahraini, /char10/chare9/char4a/char0a/char6a/char2e/char4a/char0a/charca/char09/char6d/charcc/char27/char40Gulf, /char10/chare9/char4a/char0a/char4b/char2e/char51/charaa/charcb/char40Arabic, /charfa/charcd/charf0/char42/char40first, /charc9/char09/char92/char09/charaf/char40better, /char10/chare9/char4a/char0a/char09/char93/char41/char4b/char0a/char51/charcb/char40\nsports,/char51/char1e/char0a/char4a/char2e/charbbbig, /charfa/char0a/char09/chare6/chara3/charf1/charcb/char40national, /char10/chare8/char51/char1e/char0a/char4a/char2e/charbbbig, /char10/chare9/char4b/char0a/charf1/char4a/char0a/char83/char42/char40Asian\nTable 17: Top-10 most common descriptive words found in the first sentence, Arabic national identities\n268\nboth classifiers are reported in Table 12.\nE.4 Statistics on social groups\nWhen inspecting sentences that have been\nmarked as toxic by the classifier, we can\nencounter samples as \"A brown person hang-\ning out with friends because she is black\"\n(\"/char5a/char40/char58/charf1/char83 /char41/charee/char09/char45/char0d/char42 /char5a/char41/char10/charaf/char59/char93/char0d/char42/char40 /chara9/chard3 /chare8/char09/char51/char09/char1e/char10/char4a/char10/char4b /char51/chard6/charde/char85/char0d/char40 /char91/char09/char6d/char19/char11/char85\")\nor \"An Indian woman gets di-\nvorced because she gave birth\"\n(\" /char10/char49/char4a/char2e/char6d/char2e/char1a/char09/char27/char40 /char41/charee/char09/char45/char0d/char42/char10/char86/char43/chara2/charcb/char40/charfa/charce/charab /charc9/char92/char6d/char1a/char10/char27/char10/chare9/char4b/char0a/char59/char09/char4a/chareb/char10/chare8/char0d/char40/char51/chard3/char40\").\nIn both these examples we can notice how\nordinary actions are justified by ethnicity or by\ngender-related reasons. We report in Table 13\nthe proportion of sentences, with respect to every\nsocial groups, that have been reported as toxic by\nthe LR classifier. We observe that when focusing\non religious identity the model displays to be more\nprone to produce toxic content when the subject is\nelse Jewish or an Atheist. For ethnic groups, Black\npeople tend to be more likely associated to toxic\nstatements. When focusing on gender, women\nappear the be associated more often with potential\ntoxicity.\n269\nF Supplementary evaluation results\nBelebele Ar dialects (norm)\nBelebele Ar MSA (norm)\nCOPA Ar (norm)\nFacts balanced (norm)\nMCQ Exams Ar (norm)\nOpenbookQA Ar (norm)\nRating sentiment (norm)\nRating sentiment no neutral (norm)\nSentiment (norm)\nSOQAL Ar (norm)\nXGLUE Ar (norm)\naverage\nscore*\ntasks\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0accuracy\nModel\nAraGPT2-Mega\nNoor 10B\nJais-13B\n14B 257.6GT\nrandom\nFigure 4: Zero-shot evaluation results on the AlGhafa benchmark for our largest model, with 14B parameters,\ncompared with: Noor (Lakim et al., 2022), Jais (Sengupta et al., 2023) and AraGPT2 (Antoun et al., 2021). Average\nis the mean accuracy across tasks. Score* is the average of (at − bt)/(1 − bt) across tasks, where: at is task\naccuracy and bt is task baseline.\n270\nBelebele Ar dialects (norm)\nBelebele Ar MSA (norm)\nCOPA Ar (norm)\nFacts balanced (norm)\nMCQ Exams Ar (norm)\nOpenbookQA Ar (norm)\nRating sentiment (norm)\nRating sentiment no neutral (norm)\nSentiment (norm)\nSOQAL Ar (norm)\nXGLUE Ar (norm)\naverage\nscore*\ntasks\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0accuracy\nModel\n1B\n3B\n7B\n14B\nrandom\nFigure 5: Zero-shot evaluation results of our models trained to optimality on the AlGhafa benchmark. Average is\nthe mean accuracy across tasks. Score* is the average of (at − bt)/(1 − bt) across tasks, where: at is task accuracy\nand bt is task baseline\n271\nCOPA Ar (norm)\nFacts balanced (norm)\nMCQ Exams Ar (norm)\nOpenbookQA Ar (norm)\nRating sentiment (norm)\nRating sentiment no neutral (norm)\nSentiment (norm)\nSOQAL Ar (norm)\nXGLUE Ar (norm)\naverage\nscore*\ntasks\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0accuracy\nModel\n1B tok1\n1B tok2\n3B tok1\n3B tok2\nrandom\nFigure 6: Zero-shot evaluation results on the AlGhafa benchmark of our 1B and 3B models trained to optimality\nusing v1 and llm tokenizers, respectively. Average is the mean accuracy across tasks. Score* is the average of\n(at − bt)/(1 − bt) across tasks, where: at is task accuracy and bt is task baseline.\n272\nCOPA Ar (norm)\nFacts balanced (norm)\nMCQ Exams Ar (norm)\nOpenbookQA Ar (norm)\nRating sentiment (norm)\nRating sentiment no neutral (norm)\nSentiment (norm)\nSOQAL Ar (norm)\nXGLUE Ar (norm)\naverage\nscore*\ntasks\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0accuracy\nModel\n3B minhash\n3B exactsubstr\nrandom\nFigure 7: Zero-shot evaluation results on the AlGhafa benchmark of our 1B and 3B models trained to optimality\nusing a dataset deduplicated with only minhash, and another deduplicated using both minhash and exactsubtring\n(ess). Average is the mean accuracy across tasks. Score* is the average of (at − bt)/(1 − bt) across tasks, where:\nat is task accuracy and bt is task baseline.\n273\nBelebele Ar dialects (norm)\nBelebele Ar MSA (norm)\nCOPA Ar (norm)\nFacts balanced (norm)\nMCQ Exams Ar (norm)\nOpenbookQA Ar (norm)\nRating sentiment (norm)\nRating sentiment no neutral (norm)\nSentiment (norm)\nSOQAL Ar (norm)\nXGLUE Ar (norm)\naverage\nscore*\ntasks\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0accuracy\nModel\n1B 45GT\n1B 90GT\n1B 135GT\nrandom\nFigure 8: Zero-shot evaluation results of 1B models trained over 1, 2 and 3 epochs over a 45 GT dataset. Average is\nthe mean accuracy across tasks. Score* is the average of (at − bt)/(1 − bt) across tasks, where: at is task accuracy\nand bt is task baseline.\n274\n0 1 2 3 4 5 6 7 8\nshots\n0.25\n0.26\n0.27\n0.28\n0.29\n0.30\n0.31Belebele Ar MSA (norm) [accuracy %]\nModel\n1B\n3B\n7B\n14B\nrandom\n0 1 2 3 4 5 6 7 8\nshots\n0.250\n0.275\n0.300\n0.325\n0.350\n0.375\n0.400\n0.425MCQ Exams Ar (norm) [accuracy %]\nModel\n1B\n3B\n7B\n14B\nrandom\n0 1 2 3 4 5 6 7 8\nshots\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8SOQAL Ar (norm) [accuracy %]\nModel\n1B\n3B\n7B\n14B\nrandom\n0 1 2 3 4 5 6 7 8\nshots\n0.25\n0.26\n0.27\n0.28\n0.29\n0.30Belebele Ar dialects (norm) [accuracy %]\nModel\n1B\n3B\n7B\n14B\nrandom\n0 1 2 3 4 5 6 7 8\nshots\n0.26\n0.28\n0.30\n0.32\n0.34\n0.36OpenbookQA Ar (norm) [accuracy %]\nModel\n1B\n3B\n7B\n14B\nrandom\n0 1 2 3 4 5 6 7 8\nshots\n0.34\n0.36\n0.38\n0.40\n0.42\n0.44Sentiment (norm) [accuracy %]\nModel\n1B\n3B\n7B\n14B\nrandom\n0 1 2 3 4 5 6 7 8\nshots\n0.50\n0.55\n0.60\n0.65\n0.70COPA Ar (norm) [accuracy %]\nModel\n1B\n3B\n7B\n14B\nrandom\n0 1 2 3 4 5 6 7 8\nshots\n0.325\n0.350\n0.375\n0.400\n0.425\n0.450\n0.475\n0.500Rating sentiment (norm) [accuracy %]\nModel\n1B\n3B\n7B\n14B\nrandom\n0 1 2 3 4 5 6 7 8\nshots\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7XGLUE Ar (norm) [accuracy %]\nModel\n1B\n3B\n7B\n14B\nrandom\n0 1 2 3 4 5 6 7 8\nshots\n0.45\n0.50\n0.55\n0.60\n0.65\n0.70\n0.75Facts balanced (norm) [accuracy %]\nModel\n1B\n3B\n7B\n14B\nrandom\n0 1 2 3 4 5 6 7 8\nshots\n0.50\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85Rating sentiment no neutral (norm) [accuracy %]\nModel\n1B\n3B\n7B\n14B\nrandom\n0 1 2 3 4 5 6 7 8\nshots\n0.35\n0.40\n0.45\n0.50\n0.55Average [accuracy %]\n Model\n1B\n3B\n7B\n14B\nrandom\nFigure 9: Few-shot evaluation results of our models trained to optimality on our benchmark. Average is the mean\naccuracy across tasks. Score* is the average of (at − bt)/(1 − bt) across tasks, where: at is task accuracy and bt is\ntask baseline.\n275",
  "topic": "Arabic",
  "concepts": [
    {
      "name": "Arabic",
      "score": 0.748879611492157
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.5351613163948059
    },
    {
      "name": "Computer science",
      "score": 0.5207952857017517
    },
    {
      "name": "Linguistics",
      "score": 0.47230103611946106
    },
    {
      "name": "Natural language processing",
      "score": 0.4650261402130127
    },
    {
      "name": "Programming language",
      "score": 0.41600683331489563
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3271787762641907
    },
    {
      "name": "Philosophy",
      "score": 0.2824978530406952
    },
    {
      "name": "Geography",
      "score": 0.1266741156578064
    },
    {
      "name": "Cartography",
      "score": 0.09197261929512024
    }
  ]
}