{
  "title": "Explaining pretrained language models' understanding of linguistic structures using construction grammar",
  "url": "https://openalex.org/W4387576792",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2782282100",
      "name": "Leonie Weissweiler",
      "affiliations": [
        "Munich Center for Machine Learning",
        "Ludwig-Maximilians-Universität München"
      ]
    },
    {
      "id": "https://openalex.org/A3021366198",
      "name": "Valentin Hofmann",
      "affiliations": [
        "University of Oxford",
        "Ludwig-Maximilians-Universität München"
      ]
    },
    {
      "id": "https://openalex.org/A2965293488",
      "name": "Abdullatif Köksal",
      "affiliations": [
        "Munich Center for Machine Learning",
        "Ludwig-Maximilians-Universität München"
      ]
    },
    {
      "id": "https://openalex.org/A2035156685",
      "name": "Hinrich Schütze",
      "affiliations": [
        "Ludwig-Maximilians-Universität München",
        "Munich Center for Machine Learning"
      ]
    },
    {
      "id": "https://openalex.org/A2782282100",
      "name": "Leonie Weissweiler",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3021366198",
      "name": "Valentin Hofmann",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2965293488",
      "name": "Abdullatif Köksal",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2035156685",
      "name": "Hinrich Schütze",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2094200269",
    "https://openalex.org/W2605717780",
    "https://openalex.org/W1964268059",
    "https://openalex.org/W2964204621",
    "https://openalex.org/W2162175054",
    "https://openalex.org/W3170666909",
    "https://openalex.org/W2171397533",
    "https://openalex.org/W6755207826",
    "https://openalex.org/W2623494909",
    "https://openalex.org/W2313797551",
    "https://openalex.org/W2963044847",
    "https://openalex.org/W125414735",
    "https://openalex.org/W2122566486",
    "https://openalex.org/W2130454225",
    "https://openalex.org/W4235777569",
    "https://openalex.org/W6757883768",
    "https://openalex.org/W6779068807",
    "https://openalex.org/W2104776191",
    "https://openalex.org/W2902402179",
    "https://openalex.org/W1541437793",
    "https://openalex.org/W4205857304",
    "https://openalex.org/W6678712861",
    "https://openalex.org/W3034995113",
    "https://openalex.org/W4230557881",
    "https://openalex.org/W266716723",
    "https://openalex.org/W4225707828",
    "https://openalex.org/W6766673545",
    "https://openalex.org/W4386566833",
    "https://openalex.org/W6731833932",
    "https://openalex.org/W2888922637",
    "https://openalex.org/W6695028801",
    "https://openalex.org/W2963015836",
    "https://openalex.org/W6675354045",
    "https://openalex.org/W2962739339",
    "https://openalex.org/W6769627184",
    "https://openalex.org/W6767594909",
    "https://openalex.org/W3035507081",
    "https://openalex.org/W6839193947",
    "https://openalex.org/W3115633976",
    "https://openalex.org/W6757635932",
    "https://openalex.org/W3099178230",
    "https://openalex.org/W2996728628",
    "https://openalex.org/W2978670439",
    "https://openalex.org/W6784614367",
    "https://openalex.org/W3200809495",
    "https://openalex.org/W6849478444",
    "https://openalex.org/W4385574039",
    "https://openalex.org/W6767913650",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W6811340617",
    "https://openalex.org/W6791446462",
    "https://openalex.org/W2974273066",
    "https://openalex.org/W1550933260",
    "https://openalex.org/W1558866924",
    "https://openalex.org/W2150945838",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W3122890974",
    "https://openalex.org/W2942096694",
    "https://openalex.org/W2101234009",
    "https://openalex.org/W4281690148",
    "https://openalex.org/W4365799834",
    "https://openalex.org/W4288631803",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2887428522",
    "https://openalex.org/W4229005866",
    "https://openalex.org/W3099668342"
  ],
  "abstract": "Construction Grammar (CxG) is a paradigm from cognitive linguistics emphasizing the connection between syntax and semantics. Rather than rules that operate on lexical items, it posits constructions as the central building blocks of language, i.e., linguistic units of different granularity that combine syntax and semantics. As a first step toward assessing the compatibility of CxG with the syntactic and semantic knowledge demonstrated by state-of-the-art pretrained language models (PLMs), we present an investigation of their capability to classify and understand one of the most commonly studied constructions, the English comparative correlative (CC). We conduct experiments examining the classification accuracy of a syntactic probe on the one hand and the models' behavior in a semantic application task on the other, with BERT, RoBERTa, and DeBERTa as the example PLMs. Our results show that all three investigated PLMs, as well as OPT, are able to recognize the structure of the CC but fail to use its meaning. While human-like performance of PLMs on many NLP tasks has been alleged, this indicates that PLMs still suffer from substantial shortcomings in central domains of linguistic knowledge.",
  "full_text": "TYPE Original Research\nPUBLISHED /one.tnum/two.tnum October /two.tnum/zero.tnum/two.tnum/three.tnum\nDOI /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/three.tnum./one.tnum/two.tnum/two.tnum/five.tnum/seven.tnum/nine.tnum/one.tnum\nOPEN ACCESS\nEDITED BY\nSomnath Banerjee,\nUniversity of Tartu, Estonia\nREVIEWED BY\nYunfei Long,\nUniversity of Essex, United Kingdom\nAnitha S. Pillai,\nHindustan Institute of Technology and Science,\nIndia\n*CORRESPONDENCE\nLeonie Weissweiler\nweissweiler@cis.lmu.de\nRECEIVED /one.tnum/nine.tnum May /two.tnum/zero.tnum/two.tnum/three.tnum\nACCEPTED /zero.tnum/six.tnum September /two.tnum/zero.tnum/two.tnum/three.tnum\nPUBLISHED /one.tnum/two.tnum October /two.tnum/zero.tnum/two.tnum/three.tnum\nCITATION\nWeissweiler L, Hofmann V, Köksal A and\nSchütze H (/two.tnum/zero.tnum/two.tnum/three.tnum) Explaining pretrained\nlanguage models’ understanding of linguistic\nstructures using construction grammar.\nFront. Artif. Intell./six.tnum:/one.tnum/two.tnum/two.tnum/five.tnum/seven.tnum/nine.tnum/one.tnum.\ndoi: /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/three.tnum./one.tnum/two.tnum/two.tnum/five.tnum/seven.tnum/nine.tnum/one.tnum\nCOPYRIGHT\n© /two.tnum/zero.tnum/two.tnum/three.tnum Weissweiler, Hofmann, Köksal and\nSchütze. This is an open-access article\ndistributed under the terms of the\nCreative\nCommons Attribution License (CC BY) . The use,\ndistribution or reproduction in other forums is\npermitted, provided the original author(s) and\nthe copyright owner(s) are credited and that\nthe original publication in this journal is cited, in\naccordance with accepted academic practice.\nNo use, distribution or reproduction is\npermitted which does not comply with these\nterms.\nExplaining pretrained language\nmodels’ understanding of\nlinguistic structures using\nconstruction grammar\nLeonie Weissweiler/one.tnum,/two.tnum*, Valentin Hofmann /one.tnum,/three.tnum, Abdullatif Köksal /one.tnum,/two.tnum\nand Hinrich Schütze /one.tnum,/two.tnum\n/one.tnumCenter for Information and Language Processing, LMU Munich, Munich , Germany, /two.tnumMunich Center for\nMachine Learning, Munich, Germany, /three.tnumFaculty of Linguistics, University of Oxford, Oxford,\nUnited Kingdom\nConstruction Grammar (CxG) is a paradigm from cognitive lingu istics emphasizing\nthe connection between syntax and semantics. Rather than rules th at operate on\nlexical items, it posits constructions as the central building blocks of language, i.e.,\nlinguistic units of diﬀerent granularity that combine syntax and semantics. As a ﬁrst\nstep toward assessing the compatibility of CxG with the syntactic and semantic\nknowledge demonstrated by state-of-the-art pretrained lang uage models (PLMs),\nwe present an investigation of their capability to classify and un derstand one of\nthe most commonly studied constructions, the English comparativ e correlative\n(CC). We conduct experiments examining the classiﬁcation accuracy of a syntactic\nprobe on the one hand and the models’ behavior in a semantic app lication task on\nthe other, with BERT, RoBERTa, and DeBERTa as the example PLMs. O ur results\nshow that all three investigated PLMs, as well as OPT, are able to r ecognize the\nstructure of the CC but fail to use its meaning. While human-lik e performance of\nPLMs on many NLP tasks has been alleged, this indicates that PL Ms still suﬀer from\nsubstantial shortcomings in central domains of linguistic kn owledge.\nKEYWORDS\nNLP, probing, construction grammar, computational linguistic s, large language models\n/one.tnum. Introduction\nThe sentence “The better your syntax, the better your semantics.” contains a construction\ncalled the English comparative correlative (CC; Fillmore, 1986). Paraphrased, it could be read\nas “If your syntax is better, your semantics will also be better.” Humans reading this sentence\nare capable of doing two things: (i) recognizing that two instances of “the” followed by an\nadjective/adverb in the comparative as well as a phrase of the given structure (i.e., the syntax\nof the CC) express a speciﬁc meaning (i.e., the semantics of the CC); (ii) understanding the\nsemantic meaning conveyed by the CC, i.e., understanding that in a sentence of the given\nstructure, the second half is somehow correlated with the ﬁrst.\nIn this paper, we ask the following question: are pretrained language models (PLMs)\nable to achieve these two steps? This question is important for two reasons. Firstly, we\nhope that recognizing the CC and understanding its meaning is challenging for PLMs,\nhelping to set the research agenda for further improvements. Secondly, the CC is one of\nthe most commonly studied constructions in construction grammar (CxG), a usage-based\nsyntax paradigm from cognitive linguistics, thus providing an interesting alternative to the\ncurrently prevailing practice of analysing the syntactic capabilities of PLMs with theories\nfrom generative grammar (e.g.,\nMarvin and Linzen, 2018 ).\nFrontiers in Artiﬁcial Intelligence /zero.tnum/one.tnum frontiersin.org\nWeissweiler et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/three.tnum./one.tnum/two.tnum/two.tnum/five.tnum/seven.tnum/nine.tnum/one.tnum\nWe divide our investigation into two parts. In the ﬁrst part, we\nexamine the CC’s syntactic properties and how they are represented\nby PLMs, with the objective to determine whether PLMs can\nrecognize an instance of the CC. More speciﬁcally, we construct\ntwo syntactic probes with diﬀerent properties: one is inspired by\nrecent probing methodology (e.g.,\nBelinkov et al., 2017 ; Conneau\net al., 2018 ) and draws upon minimal pairs to quantify the amount\nof information contained in each PLM layer; for the other one,\nwe write a context-free grammar (CFG) to construct approximate\nminimal pairs in which only the word order determines if the\nsentences are an instance of the CC or not. We ﬁnd that starting\nfrom the third layer, all investigated PLMs are able to distinguish\npositive from negative instances of the CC. However, this method\nonly covers one speciﬁc subtype of comparative sentences. To cover\nthe full diversity of instances, we conduct an additional experiment\nfor which we collect and manually label sentences from C4 (\nRaﬀel\net al., 2020 ) that resemble instances of the CC, resulting in a diverse\nset of sentences that either are instances of the CC or resemble\nthem closely without being instances of the CC. Applying the same\nmethodology to this set of sentences, we observe that all examined\nPLMs are still able to separate the examples very well.\nIn the second part of the paper, we aim to determine if the PLMs\nare able to understand the meaning of the CC. We generate test\nscenarios in which a statement containing the CC is given to the\nPLMs, which they then have to apply in a zero-shot manner. As this\nway of testing PLMs is prone to a variety of biases, we introduce\nseveral mitigating methods in order to determine the full capability\nof the PLMs. We ﬁnd that neither the masked language models nor\nthe autoregressive models that we investigated performed above\nchance level on this task.\nWe make three main contributions:\n– We present the ﬁrst comprehensive study examining how\nwell PLMs can recognize and understand a CxG construction,\nspeciﬁcally the English comparative correlative.\n– We develop a way of testing the PLMs’ recognition of the\nCC that overcomes the challenge of probing for linguistic\nphenomena not lending themselves to minimal pairs.\n– We adapt methods from zero-shot prompting and calibration\nto develop a way of testing PLMs for their understanding of\nthe CC.\n/two.tnum. Construction grammar and natural\nlanguage processing\n/two.tnum./one.tnum. Construction grammar\nA core assumption of generative grammar ( Chomsky, 1988 ),\nwhich can be already found in Bloomﬁeldian structural linguistics\n(\nBloomﬁeld, 1933 ), is a strict separation of lexicon and grammar:\ngrammar is conceptualized as a set of compositional and general\nrules that operate on a list of arbitrary and speciﬁc lexical items in\ngenerating syntactically well-formed sentences. This dichotomous\nview was increasingly questioned in the 1980s when several studies\ndrew attention to the fact that linguistic units larger than lexical\nitems (e.g., idioms) can also possess non-compositional meanings\n(\nLakoﬀ, 1987 ; Langacker, 1987 ; Fillmore et al., 1988 ; Fillmore,\nTABLE /one.tnumStandard examples of constructions at various levels, adapted\nfrom Goldberg (/two.tnum/zero.tnum/one.tnum/three.tnum).\nConstruction\nname\nConstruction\ntemplate\nExamples\nWord Banana\nWord (partially ﬁlled) pre-N, V-ing Pretransition, Working\nIdiom (ﬁlled) Give the devil his due\nIdiom (partially ﬁlled) Jog <someone’s>\nmemory\nShe jogged his memory\nIdiom (minimally ﬁlled) The X-er the Y-er The more I think about\nit, the less I know\nDitransitive construction\n(unﬁlled)\nSubj V Obj1 Obj2 He baked her a muﬃn\nPassive (unﬁlled) Subj aux VPpp (PP by) The armadillo was hit by\na car\n1989). For instance, it is not clear how the eﬀect of the words\n“let alone” (as in “she doesn’t eat ﬁsh, let alone meat”) on both\nthe syntax and the semantics of the rest of the sentence could\nbe inferred from general syntactic rules (\nFillmore et al., 1988 ).\nThis insight about the ubiquity of stored form-meaning pairings\nin language is adopted as the central tenet of grammatical theory\nby Construction Grammar (CxG; see\nHoﬀmann and Trousdale,\n2013 for a comprehensive overview). Rather than a system divided\ninto non-overlapping syntactic rules and lexical items, CxG views\nlanguage as a structured system of constructions with varying\ngranularities that encapsulate syntactic and semantic components\nas single linguistic signs—ranging from individual morphemes up\nto phrasal elements and ﬁxed expressions (\nGoldberg A., 1995 ; Kay\nand Fillmore, 1999 ). In this framework, syntactic rules can be\nseen as emergent abstractions over similar stored constructions\n(\nGoldberg, 2003 , 2006). A diﬀerent set of stored constructions can\nresult in diﬀerent abstractions and thus diﬀerent syntactic rules,\nwhich allows CxG to naturally accommodate for the dynamic\nnature of grammar as evidenced, for instance, by inter-speaker\nvariability and linguistic change (\nHilpert, 2006).\n/two.tnum./two.tnum. Why construction grammar for NLP?\nThere has recently been growing interest in developing probing\napproaches for PLMs based on CxG. We see these approaches as\ncoming from two diﬀerent motivational standpoints, summarized\nbelow.\n/two.tnum./two.tnum./one.tnum. Constructions are essential for language\nmodeling\nAccording to CxG, meaning is encoded in abstract\nconstellations of linguistic units of diﬀerent sizes. Examples\nof these can be found in\nTable 1. This means that LMs, which\nthe ﬁeld of NLP is trying to develop to achieve human language\ncompetency, must also be able to assign meaning to these units\nto be full LMs. Their ability to assign meaning to words, or\nmore speciﬁcally to subword units which are sometimes closer to\nFrontiers in Artiﬁcial Intelligence /zero.tnum/two.tnum frontiersin.org\nWeissweiler et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/three.tnum./one.tnum/two.tnum/two.tnum/five.tnum/seven.tnum/nine.tnum/one.tnum\nTABLE /two.tnumTranslated back to English by humans, they all mean “She\nsneezed her cappuccino’s foam,” which does not correctly convey the\nresultative meaning component, i.e., that the foam is removed from the\ncappuccino by the sneeze (as opposed to put there).\nLang Reference translation DeepL translation\nGerman Sie nieste den Schaum von\nihrem Cappuccino runter.\nSie nieste den Schaum von\nihrem Cappuccino.\nItalian Lei ha starnutito via la schiuma\ndal suo cappuccino.\nStarnutì la schiuma del suo\ncappuccino.\nTurkish Cappuccino’sunun köpü˘günü\nhap¸ sırdı.\nHap¸ sırarak cappuccino’sunun\nköpü˘günü uçurdu.\nmorphemes than to words, has been shown at length ( Reif et al.,\n2019; Wiedemann et al., 2019 ; Schwartz et al., 2022 ). The question\ntherefore remains: are PLMs able to retrieve and use meanings\nassociated with patterns involving multiple tokens? We do not\ntake this to only mean contiguous, ﬁxed expressions, but much\nmore importantly, non-contiguous patterns with slots that have\nvarying constraints placed on them. To imitate and match human\nlanguage behavior, models of human language need to learn how\nto recognize these patterns, retrieve their meaning, apply this\nmeaning to the context, and use them when producing language.\nSimply put, there is no way around learning constructions if LMs\nare to advance. In addition, we believe that it is an independently\ninteresting question whether existing PLMs pick up on these\nabstract patterns using the current architectures and training\nsetups, and if not, which change in architecture would be necessary\nto facilitate this.\n/two.tnum./two.tnum./two.tnum. Importance in downstream tasks\nRegardless of more fundamental questions about the long-term\ngoals of LMs, we also ﬁrmly believe that probing for CxG is relevant\nfor analysing the challenges that face applied NLP , as evaluated on\ndownstream tasks, at this point in time. Discussion is increasingly\nfocusing on diagnosing the speciﬁc scenarios that are challenging\nfor current models.\nSrivastava et al. (2023) propose test suites that\nare designed to challenge LMs, and many of them are designed\nby looking for “patterns” with a non-obvious, non-literal meaning\nthat is more than the sum of the involved words. One example\nof such a failure can be found in\nTable 2, where we provide the\nDeepL/one.tnumtranslations for the famous instance of the caused-motion\nconstruction ( Goldberg A. E., 1995 , CMC): “She sneezed the foam\noﬀ her cappuccino, ” where the unusual factor is that sneeze does not\nusually take a patient argument or cause a motion. For translation,\nthis means that it either has to use the corresponding CMC in the\ntarget language, which might be quite diﬀerent in form from the\nEnglish CMC, or paraphrase in a way that conveys all meaning\nfacets. For the languages we tested, DeepL did not achieve this:\nthe resulting sentence sounds more like the foam was sneezed\nonto the cappuccino, or is ambiguous between this and the correct\ntranslation. Interestingly, for Russian, the motion is conveyed in the\ntranslation, but not the fact that it is caused by a sneeze.\nTargeted adversarial test suites like this translation example\ncan be a useful resource to evaluate how well LMs perform\non constructions, but more crucially, CxG theory and probing\n/one.tnumhttps://www.deepl.com/translator\nmethods will inform the design of better and more systematic test\nsuites, which in turn will be used to improve LMs.\n/two.tnum./two.tnum./three.tnum. Diversity in linguistics for NLP\nDiscussions about PLMs as models of human language\nprocessing have recently gained popularity. One forum for such\ndiscussions is the Neural Nets for Cognition Discussion Group at\nCogSci2022\n/two.tnum. The work is still very tentative, and most people agree\nthat LMs are not ready to be used as models of human language\nprocessing. However, the discussion about whether LMs are ready\nto be used as cognitive models is dominated by results of probing\nstudies based on Generative Grammar (GG), or more speciﬁcally\nTransformational Grammar. This means that GG is being used as\nthe gold standard against which the cognitive plausibility of LMs is\nevaluated. Studies using GG assume a direct relationship between\nthe models’ performance on probing tasks and their linguistic\ncompetency. Increased performance on GG probing tasks is seen\nas a sign it is becoming more reasonable to use LMs as cognitive\nmodels. Another linguistic reason for theoretical diversity is that if\nwe could show that LMs conform better to CxG rather than GG,\nthis might open up interesting discussions if they ever start being\nused as cognitive models.\n/three.tnum. The English comparative correlative\nThe English comparative correlative (CC) is one of the most\ncommonly studied constructions in linguistics, for several reasons.\nFirstly, it constitutes a clear example of a linguistic phenomenon\nthat is challenging to explain in the framework of generative\ngrammar (\nCulicover and Jackendoﬀ, 1999 ; Abeillé and Borsley,\n2008), even though there have been approaches following that\nschool of thought ( Den Dikken, 2005 ; Iwasaki and Radford, 2009 ).\nSecondly, it exhibits a range of interesting syntactic and semantic\nfeatures, as detailed below. These reasons, we believe, also make\nthe CC an ideal testbed for a ﬁrst study attempting to extend the\ncurrent trend of syntax probing for rules by developing methods\nfor probing according to CxG.\nThe CC can take many diﬀerent forms, some of which are\nexempliﬁed here:\n(1) The more, the merrier.\n(2) The longer the bake, the browner the color.\n(3) The more she practiced, the better she became.\nSemantically, the CC consists of two clauses, where the second\nclause can be seen as the dependent variable for the independent\nvariable speciﬁed in the ﬁrst one (\nGoldberg, 2003 ). It can be\nseen on the one hand as a statement of a general cause-and-\neﬀect relationship, as in a general conditional statement [e.g., (2)\ncould be paraphrased as “If the bake is longer, the color will be\nmore brown”], and on the other as a temporal development in a\ncomparative sentence [paraphrasing (3) as “She became better over\ntime, and she practiced more over time”]. Usage of the CC typically\nimplies both readings at the same time. Syntactically, the CC is\ncharacterized in both clauses by an instance of “the” followed by\nan adverb or an adjective in the comparative, either with “-er” for\n/two.tnumhttp://neural-nets-for-cognition.net\nFrontiers in Artiﬁcial Intelligence /zero.tnum/three.tnum frontiersin.org\nWeissweiler et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/three.tnum./one.tnum/two.tnum/two.tnum/five.tnum/seven.tnum/nine.tnum/one.tnum\nsome adjectives and adverbs, or with “more” for others, or special\nforms like “better.” Special features of the comparative sentences\nfollowing this are the optional omission of the future “will” and of\n“be, ” as in (1). Crucially, “the” in this construction does not function\nas a determiner of noun phrases (\nGoldberg, 2003 ); rather, it has a\nfunction speciﬁc to the CC and has variously been called a “degree\nword” (\nDen Dikken, 2005 ) or “ﬁxed material” ( Hoﬀmann et al.,\n2019).\n/four.tnum. Related work\n/four.tnum./one.tnum. Construction grammar probing\n/four.tnum./one.tnum./one.tnum. CxGBERT\nTayyar Madabushi et al. (2020) investigate how well BERT\n(Devlin et al., 2019 ) can classify whether two sentences contain\ninstances of the same construction. Their list of constructions is\nextracted with a modiﬁed version of\nDunn (2017)’s algorithm:\nthey induce a CxG in an unsupervised fashion over a corpus,\nusing statistical association measures. Their list of constructions\nis taken directly from\nDunn (2017), and they ﬁnd their instances\nby searching for those constructions’ occurrences in WikiText\ndata. This makes the constructions possibly problematic, since\nthey have not been veriﬁed by a linguist, which could make the\nconclusions drawn later from the results about BERT’s handling of\nconstructions hard to generalize from.\nThe key probing question of this paper is: Do two sentences\ncontain the same construction? This does not necessarily need to\nbe the most salient or overarching construction of the sentence,\nso many sentences will contain more than one instance of a\nconstruction. Crucially, the paper does not follow a direct probing\napproach, but rather ﬁnetunes or even trains BERT on targeted\nconstruction data, to then measure the impact on CoLA. They ﬁnd\nthat on average, models trained on sentences that were sorted into\ndocuments based on their constructions do not reliably perform\nbetter than those trained on original, unsorted data. However, they\nadditionally test BERT Base with no additional pre-training on\nthe task of predicting whether two sentences contain instances of\nthe same construction, measuring accuracies of about 85% after\n500 training examples for the probe. These results vary wildly\ndepending on the frequency of the construction, which might relate\nback to the questionable quality of the automatically identiﬁed list\nof constructions.\n/four.tnum./one.tnum./two.tnum. Neural reality of argument structure\nconstructions\nLi et al. (2022) probe for LMs’ handling of four argument\nstructure constructions: ditransitive, resultative, caused-motion,\nand removal. Speciﬁcally, they attempt to adapt the ﬁndings\nof\nBencini and Goldberg (2000), who used a sentence sorting\ntask to determine whether human participants perceive the\nargument structure or the verb as the main factor in the overall\nsentence meaning. The paper aims to recreate this experiment\nfor MiniBERTa (\nWarstadt et al., 2020b ) and RoBERTa ( Liu et al.,\n2019), by generating sentences artiﬁcially and using agglomerative\nclustering on the sentence embeddings. They ﬁnd that, similarly\nto the human data, which is sorted by the English proﬁciency of\nthe participants, PLMs increasingly prefer sorting by construction\nas their training data size increases. Crucially, the sentences\nconstructed for testing had no lexical overlap, such that this sorting\npreference must be due to an underlying recognition of a shared\npattern between sentences with the same argument structure. They\nthen conduct a second experiment, in which they insert random\nverbs, which are incompatible with one of the constructions,\nand then measure the Euclidean distance between this verb’s\ncontextual embedding and that of a verb that is prototypical for\nthe corresponding construction. The probing idea here is that if\nconstruction information is picked up by the model, the contextual\nembedding of the verb should acquire some constructional\nmeaning, which would bring it closer to the corresponding\nprototypical verb meaning than to the others. They indeed ﬁnd that\nthis eﬀect is signiﬁcant, for both high and low frequency verbs.\n/four.tnum./one.tnum./three.tnum. CxLM\nTseng et al. (2022) study LM predictions for the slots of various\ndegrees of openness for a corpus of Chinese constructions. Their\noriginal data comes from a knowledge database of Mandarin\nChinese constructions (\nZhan, 2017 ), which they ﬁlter so that only\nconstructions with a ﬁxed repetitive element remain, which are\neasier to ﬁnd automatically in a corpus. They ﬁlter this list down\nfurther to constructions which are rated as commonly occurring\nby annotators, and retrieve instances from a POS-tagged Taiwanese\nbulletin board corpus. They binarize the openness of a given slot\nin a construction and mark each word in a construction as either\nconstant or variable. The key probing idea is then to examine\nthe conditional probabilities that a model outputs for each type\nof slot, with the expectation that the prediction of variable slot\nwords will be more diﬃcult than that of constant ones, providing\nthat the model has acquired some constructional knowledge. They\nﬁnd that this eﬀect is signiﬁcant for two diﬀerent Chinese BERT-\nbased models, as negative log-likelihoods are indeed signiﬁcantly\nhigher when predicting variable slots compared to constant ones.\nInterestingly, the negative log-likelihood resulting from masking\nthe entire construction lies in the middle of the two extremes. They\nfurther evaluate a BERT-based model which is ﬁnetuned on just\npredicting the variable slots of the dataset they compiled and ﬁnd,\nunsurprisingly, that this improves accuracy greatly.\n/four.tnum./one.tnum./four.tnum. A discerning several thousand judgments\nMahowald (2023) focuses on the English Article + Adjective +\nNumeral + Noun (AANN) construction, e.g. “The president has\nhad a terrible 5 weeks” and GPT-3’s recognition of its particular\nsemantic and syntactic constraints. He designs a few-shot prompt\nfor grammatical acceptability using the CoLA corpus of linguistic\nacceptability (\nWarstadt et al., 2019 ). As probing data, he artiﬁcially\nconstructs several variants of the AANN construction to test for\nGPT-3’s understanding of its properties. Its output on the linguistic\nacceptability task is also contrasted with human ratings sourced\nfrom Mechanical Turk. The probing concept exploits that the\nAANN construction has several properties that seem to violate a\nnumber of rules: “a” is not marking a singular here, as the noun is\nplural. Also, the order of the number and the adjective is reversed,\nand in some cases, verb agreement rules must be suspended.\nThere are also interesting constraints on the construction itself: for\nFrontiers in Artiﬁcial Intelligence /zero.tnum/four.tnum frontiersin.org\nWeissweiler et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/three.tnum./one.tnum/two.tnum/two.tnum/five.tnum/seven.tnum/nine.tnum/one.tnum\nexample, some adjectives, such as color words, are not acceptable.\nFurthermore, qualitative adjectives must appear before quantitative\nones. Overall, GPT-3 judgments match the direction of the human\nones across a variety of conditions, except on the question of\nquantitative vs qualitative adjectives, where humans showed no\npreference, and GPT-3 had a slightly preference against the one\ndescribed in the literature. This shows that the model understood\nthe syntactic structure of the AANN construction to the point\nwhere it can override more global “rules” about word order, but\nmakes no statement about its understanding of the meaning.\n/four.tnum./two.tnum. NLP and construction grammar\nOther computational studies about CxG have either focused\non automatically annotating constructions (\nDunietz et al., 2017 )\nS→ SPOS| SNEG\nSPOS→ POS1 PUNCT POS2 ‘.’| POS1 INSERT PUNCT POS2 ‘.’\nSNEG→ NEG1 PUNCT NEG2 ‘.’| NEG1 INSERT PUNCT NEG2 ‘.’\nPUNCT→ ‘,’| ‘;’| ǫ\nCORE_POS→ ADV_I ‘the’ NUM NOUN VERB\nCORE_NEG→ ADV_I NUM VERB ‘the’ NOUN\nPOS_UPPER→ ‘0 The’ CORE_POS\nPOS_LOWER→ ‘0 the’ CORE_POS\nNEG_UPPER→ ‘0 The’ CORE_NEG\nNEG_LOWER→ ‘0 the’ CORE_NEG\nPOS1→ POS_UPPER| POS_UPPER ADD| START POS_LOWER| START POS_LOWER ADD\nPOS2→ POS_LOWER| POS_LOWER ADD\nNEG1→ NEG_UPPER| NEG_UPPER ADD| START NEG_LOWER| START NEG_LOWER ADD\nNEG2→ NEG_LOWER| NEG_LOWER ADD\nINSERT→ INSERT1| INSERT2\nINSERT2→ ADDITION BETWEEN_ADD_AND_SENT SENT\nPRON→ ‘we’| ‘they’\nADDITION→ ‘, and by the way,’| ‘, and I want to add that’| ‘, and’ PRON ‘just want to say that’| ‘, and\nthen’ PRON ‘said that’| ‘, and then’ PRON ‘said that’\nSAY→ ‘say’| ‘think’| ‘mean’| ‘believe’\nBETWEEN_ADD_AND_SENT→ PRON SAY ‘that’| PRON SAY ‘that’| PRON SAY ‘that’| PRON SAY ‘that’\nLOC_SENT→ PRON ‘said this in’ LOC ‘too’\nLOC→ CITY ‘and’ LOC| CITY\nCITY→ ‘Munich’| ‘Washington’| ‘Cologne’| ‘Prague’| ‘Istanbul’\nSENT→ ‘this also holds in other cases’| ‘this is not always true’| ‘this is always true’| ‘this has only\nrecently been the case’| ‘this has not always been the case’| ‘this has always been the case’\nINSERT1→ ‘without stopping’| ‘without a break’| ‘without a pause’| ‘uninterrupted’\nSTART→ ‘Nowadays, ’| ‘Nowadays’| ‘Therefore, ’| ‘Therefore’| ‘We can’ CANWORD ‘that’| ‘It is’ KNOWNWORD\n‘that’| ‘It follows that’| ‘Sometimes’\nSTART→ Sometimes,’| It was recently announced that’| People have told me that’| I recently read in a\nreally interesting book that’| I have recently read in an established, well-known newspaper that’| It was\nreported in a special segment on TV today that’\nCANWORD→ say’| surmise’| accept’| state’\nKNOWNWORD→ clear’| known’| accepted’| obvious’\nADD→ TEMP| UNDER1| TEMP UNDER1| UNDER1 TEMP\nADV_I→ ADV| ADV and’ ADV\nTEMP→ TEMP1 TEMP2\nTEMP1→ before’| after’| during’\nTEMP2→ the morning’| the afternoon’| the night’\nUNDER1→ under the’ UNDER2\nUNDER2→ bed’| roof’| sun’\nVERB→ push’| attack’| chase’| beat’| believe’| boil’| box’| burn’| call’| date’\nNOUN→ lions’| pandas’| camels’| pigs’| horses’| sheep’| chickens’| foxes’| cows’| deer’\nADV→ worse’| earlier’| slower’| deeper’| bigger’| smaller’| flatter’| weaker’| stronger’| louder’\nNUM→ twelve’| thirteen’| fourteen’| fifteen’| sixteen’| seventeen’| eighteen’| nineteen’| twenty’|\n‘twenty-one’\nAlgorithm /one.tnum. Context-free grammar for artiﬁcial data creation training set.\nFrontiers in Artiﬁcial Intelligence /zero.tnum/five.tnum frontiersin.org\nWeissweiler et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/three.tnum./one.tnum/two.tnum/two.tnum/five.tnum/seven.tnum/nine.tnum/one.tnum\nor on the creation and evaluation of automatically built lists of\nconstructions (\nMarques and Beuls, 2016 ; Dunn, 2019).\n/four.tnum./three.tnum. General probing\nOur work also bears some similarity to recent work in\ngenerative grammar-based syntax probing of large PLMs in that we\napproximate the minimal pairs-based probing framework similar\nto\nWei et al. (2021), Marvin and Linzen (2018), or Goldberg\n(2019). However, as we are concerned with diﬀerent phenomena\nand investigating them from a diﬀerent theoretical standpoint, the\nsyntactic half of our work clearly diﬀers.\nThe semantic half of our study is closest to recent work on\ndesigning challenging test cases for models such as\nRibeiro et al.\n(2020), who design some edge cases for which most PLMs fail.\nDespite the diﬀerent motivation, the outcome is very similar to a\nlist of some particularly challenging constructions.\nS→ SPOS | SNEG\nSPOS→ POS1 PUNCT POS2 ’.’ | POS1 INSERT PUNCT POS2 ’.’\nSNEG→ NEG1 PUNCT NEG2 ’.’ | NEG1 INSERT PUNCT NEG2 ’.’\nPUNCT→ ’,’ | ’;’ | ”\nCORE_POS→ ADV_I ’the’ NUM NOUN VERB\nCORE_NEG→ ADV_I NUM VERB ’the’ NOUN\nPOS_UPPER→ ’0 The’ CORE_POS\nPOS_LOWER→ ’0 the’ CORE_POS\nNEG_UPPER→ ’0 The’ CORE_NEG\nNEG_LOWER→ ’0 the’ CORE_NEG\nPOS1→ POS_UPPER | POS_UPPER ADD | START POS_LOWER | START POS_LOWER ADD\nPOS2→ POS_LOWER | POS_LOWER ADD\nNEG1→ NEG_UPPER | NEG_UPPER ADD | START NEG_LOWER | START NEG_LOWER ADD\nNEG2→ NEG_LOWER | NEG_LOWER ADD\nINSERT→ INSERT1 | INSERT2\nINSERT2→ ADDITION BETWEEN_ADD_AND_SENT SENT\nPRON→ ’I’ | ’you’\nADDITION→ ’, and by the way ,’ | ’, and I want to add that’ | ’, and’ PRON ’just want to say that’ | ’,\nand then’ PRON ’said that’ | ’, and then’ PRON ’said that’\nSAY→ ’say’ | ’think’ | ’mean’ | ’believe’\nBETWEEN_ADD_AND_SENT→ PRON SAY ’that’ | PRON SAY ’that’ | PRON SAY ’that’ | PRON SAY ’that’\nLOC_SENT→ PRON ’said this in’ LOC ’too’\nLOC→ CITY ’and’ LOC | CITY\nCITY→ ’London’ | ’New York’ | ’Berlin’ | ’Madrid’ | ’Paris’\nSENT→ ’this also holds in other cases’ | ’this is not always true’ | ’this is always true’ | ’this has\nonly recently been the case’ | ’this has not always been the case’ | ’this has always been the case’\nINSERT1→ ’without stopping’ | ’without a break’ | ’without a pause’ | ’uninterrupted’ |\nSTART→ ’Nowadays ,’ | ’Nowadays’ | ’Therefore ,’ | ’Therefore’ | ’We can’ CANWORD ’that’ | ’It is’\nKNOWNWORD ’that’ | ’It follows that’ | ’Sometimes’ | ’Sometimes ,’ | ’It was recently announced that’ |\n’People have told me that’ | ’I recently read in a really interesting book that’ | ’I have recently read in\nan established , well-known newspaper that’ | ’It was reported in a special segment on TV today that’\nCANWORD→ ’say’ | ’surmise’\nKNOWNWORD→ ’clear’ | ’known’\nADD→ TEMP | UNDER1 | TEMP UNDER1 | UNDER1 TEMP\nADV_I→ ADV | ADV ’and’ ADV\nTEMP→ TEMP1 TEMP2\nTEMP1→ ’before’ | ’after’ | ’during’\nTEMP2→ ’the day’ | ’the night’ | ’the evening’\nUNDER1→ ’under the’ UNDER2\nUNDER2→ ’bridge’ | ’stairs’ | ’tree’\nVERB→ ’slam’ | ’break’ | ’bleed’ | ’shake’ | ’smash’ | ’throw’ | ’strike’ | ’shoot’ | ’swallow’ | ’choke’\nNOUN→ ’cats’ | ’dogs’ | ’girls’ | ’boys’ | ’men’ | ’women’ | ’people’ | ’humans’ | ’mice’ | ’alligators’\nADV→ ’faster’ | ’quicker’ | ’harder’ | ’higher’ | ’later’ | ’longer’ | ’shorter’ | ’lower’ | ’wider’ |\n’better’\nNUM→ ’two’ | ’three’ | ’four’ | ’five’ | ’six’ | ’seven’ | ’eight’ | ’nine’ | ’ten’ | ’eleven’\nAlgorithm /two.tnum. Context-free grammar for artiﬁcial data creation test set.\nFrontiers in Artiﬁcial Intelligence /zero.tnum/six.tnum frontiersin.org\nWeissweiler et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/three.tnum./one.tnum/two.tnum/two.tnum/five.tnum/seven.tnum/nine.tnum/one.tnum\n/five.tnum. Syntax\nOur investigation of PLMs’ knowledge of the CC is split into\ntwo parts. First, we probe for the PLMs’ knowledge of the syntactic\naspects of the CC, to determine if they recognize its structure. Then\nwe devise a test of their understanding of its semantic aspects by\ninvestigating their ability to apply, in a given context, information\nconveyed by a CC.\n/five.tnum./one.tnum. Probing methods\nAs the ﬁrst half of our analysis of PLMs’ knowledge of the\nCC, we investigate its syntactic aspects. Translated into probing\nquestions, this means that we ask: can a PLM recognize an\ninstance of the CC? Can it distinguish instances of the CC from\nsimilar-looking non-instances? Is it able to go beyond the simple\nrecognition of its ﬁxed parts (“The COMP-ADJ/ADV, the ...”) and\ngroup all ways of completing the sentences that are instances of\nthe CC separately from all those that are not? And to frame all of\nthese questions in a syntactic probing framework: will we be able to\nrecover, using a logistic regression as the probe, this distinguishing\ninformation from a PLM’s embeddings?\nThe established way of testing a PLM for its syntactic knowledge\nhas in recent years become minimal pairs (e.g.,\nWarstadt et al.,\n2020a; Demszky et al., 2021 ). This would mean pairs of sentences\nwhich are indistinguishable except for the fact that one of them\nis an instance of the CC and the other is not, allowing us to\nperfectly separate a model’s knowledge of the CC from other\nconfounding factors. While this is indeed possible for simpler\nsyntactic phenomena such as verb-noun number agreement, there\nis no obvious way to construct minimal pairs for the CC. We\ntherefore construct minimal pairs in two ways: one with artiﬁcial\ndata based on a context-free grammar (CFG), and one with\nsentences extracted from C4.\n/five.tnum./one.tnum./one.tnum. Synthetic data\nIn order to ﬁnd a pair of sentences that is as close as possible\nto a minimal pair, we devise a way to modify the words following\n“The X-er” such that the sentence is no longer an instance of the\nconstruction. The pattern for a positive instance is “The ADV-er the\nNUM NOUN VERB, ” e.g., “The harder the two cats ﬁght.” To create\na negative instance, we reorder the pattern to “The ADJ-er NUM\nVERBthe NOUN, ” e.g., “The harder two ﬁght the cats.” The change\nin role of the numeral from the dependent of a head to a head itself,\nmade possible by choosing a verb that can be either transitive or\nintransitive, as well as the change from an adverb to an adjective,\nallows us to construct a negative instance that uses the same words\nas the positive one, but in a diﬀerent order.\n/three.tnumIn order to generate\na large number of instances, we collect two sets each of adverbs,\nnumerals, nouns, and verbs that are mutually exclusive between\ntraining and test sets. To investigate if the model is confused by\nadditional content in the sentences, we write an CFG to insert\nphrases before the start of the ﬁrst half, in between the two halves,\nand after the second half of the CC. We show the rules making up\nthe CFG in\nAlgorithms 1, 2.\nWhile this setup is rigorous in the sense that positive and\nnegative sentences are exactly matched, it comes with the drawback\nof only considering one type of CC. To be able to conduct a more\ncomprehensive investigation, we adopt a complementary approach\nand turn to pairs extracted from C4. We show examples of training\n/three.tnum Note that an alternative reading of this sentence exists: the numeral “two”\nforms the noun phrase by itself and “The harder” is still interp reted as part of\nthe CC. The sentence is actually a positive instance on this int erpretation. We\nregard this reading as very improbable.\nTABLE /three.tnumExamples of data for the syntactic probe.\nSentence Label Source\n“The higher up the nicer!” Positive Corpus\nShe thinks the more water she drinks the better her skin looks. Positive Corpus\nSubtract the smaller from the larger. Negative Corpus\nThe way the older guys help out the younger guys is fantastic. Negative Corpus\nNowadays, the bigger the 18 sheep date, the louder and bigger t he 12 horses beat under the sun. Positive Artiﬁcial train\nThe ﬂatter the 14 lions push, the deeper and smaller the 16 deer burn u nder the roof. Positive Artiﬁcial train\nSometimes, the worse and earlier 17 believe the deer, and we jus t want to say that they mean that this has\nalways been the case, the ﬂatter 21 attack the foxes before the a fternoon under the roof.\nNegative Artiﬁcial train\nNowadays, the smaller 16 box the camels, and by the way, they mean that this is always true; the weaker 13\ndate the cows.\nNegative Artiﬁcial train\nThe harder and longer the three cats throw, the harder and shor ter the 10 dogs shake. Positive Artiﬁcial test\nI have recently read in an established, well-known newspaper that t he later the ten mice strike; the later\nand better the seven men smash under the tree during the night .\nPositive Artiﬁcial test\nThe higher nine strike the women without a pause the shorter 10 choke the girls. Negative Artiﬁcial test\nWe can say that the longer and faster four strike the men under t he stairs before the evening, the harder\nfour throw the dogs after the day under the bridge.\nNegative Artiﬁcial test\nFrontiers in Artiﬁcial Intelligence /zero.tnum/seven.tnum frontiersin.org\nWeissweiler et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/three.tnum./one.tnum/two.tnum/two.tnum/five.tnum/seven.tnum/nine.tnum/one.tnum\nand test data in Table 3. These cover a broad range of CC patterns,\nalbeit without meeting the criterion that positive and negative\nsamples are exactly matched.\n/five.tnum./one.tnum./two.tnum. Corpus-based minimal pairs\nWhile accepting that positive and negative instances extracted\nfrom a corpus will automatically not be minimal and therefore\ncontain some lexical overlap and context cues, we attempt to\nregularize our retrieved instances as far as possible. To form a\nﬁrst candidate set, we POS tag C4 using spaCy (\nHonnibal and\nMontani, 2018 ) and extract all sentences that follow the pattern\n“The” (DET) followed by either “more” and an adjective or adverb,\nor an adjective or adverb ending in “-er, ” and at any point later\nin the sentence again the same pattern. We discard examples with\nadverbs or adjectives that were falsely labeled as comparative, such\nas “other.” We then group these sentences by their sequence of\nPOS tags, and manually classify the sequences as either positive\nor negative instances. We observe that sentences sharing a POS\ntag pattern tend to be either all negative or all positive instances,\nallowing us to save annotation time by working at the POS tag\npattern level instead of the sentence level. To make the ﬁnal set\nas diverse as possible, we sort the patterns randomly and label as\nmany as possible. In order to further reduce interfering factors in\nour probe, we separate the POS tag patterns between training and\ntest sets. We give examples in\nTable 3.\nPlease note that due to the inherent diﬃculty of creating\nminimal pairs for this construction, while the two approaches\nare complementary, neither of them is perfect. While we think\nthat our experimental setup (e.g., no surface patterns indicating\npositive/negative classes, clear distinction between training/test\ndata) is designed well-enough, we would like to note that probing\nclassiﬁers with logistic regression are not robust to such confound\nvariables.\n/five.tnum./one.tnum./three.tnum. The probe\nFor both datasets, we investigate the overall accuracy of our\nprobe as well as the impact of several factors. The probe consists\nof training a simple logistic regression model on top of the mean-\npooled sentence embeddings (\nVuli´c et al., 2020 ). To quantify the\nimpact of the length of the sentence, the start position of the\nconstruction, the position of its second half, and the distance\nbetween them, we construct four diﬀerent subsets Dtrain\nf and Dtest\nf\nfrom both the artiﬁcially constructed and the corpus-based dataset.\nFor each subset, we sample sentences such that both the positive\nand the negative class is balanced across every value of the feature\nwithin a certain range of values. This ensures that the probes are\nunable to exploit correlations between a class and any of the above\nfeatures. We create the dataset as follows\nDf =\n⋃\nv∈ fv\n⋃\nl∗∈ L\nS(D, v, l∗, n∗),\nwhere f is the feature, fv is the set of values for f , L =\n{positive, negative} are the labels, and S is a function that returns\nn∗ elements from D that have value v and label l∗.\nTo make this task more cognitively realistic, we aim to test if a\nmodel is able to generalize from shorter sentences, which contain\nrelatively little additional information besides the parts relevant to\nthe classiﬁcation task, to those with greater potential interference\ndue to more additional content that is not useful for classiﬁcation.\nThus, we restrict the training set to samples from the lowest quartile\nof each feature so that fv becomes [ vmin\nf , vmin\nf + 1\n4 (vmax\nf − vmin\nf )]\nfor Dtrain\nf and [vmin\nf , vmax\nf ] for Dtest\nf . We report the test performance\nfor every value of a given feature separately to recognize patterns.\nFor the artiﬁcial syntax probing, we generate 1,000 data points\nfor each value of each feature for each training and test for each\nsubset associated with a feature. For the corpus syntax probing,\nwe collect 9,710 positive and 533 negative sentences in total, from\nwhich we choose 10 training and ﬁve test sentences for each value\nof each feature in a similar manner. To improve comparability\nFIGURE /one.tnum\nOverall accuracy per layer for Dlength. All shown models are the large model variants. The models can easi ly distinguish between positive and negative\nexamples in at least some of their layers.\nFrontiers in Artiﬁcial Intelligence /zero.tnum/eight.tnum frontiersin.org\nWeissweiler et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/three.tnum./one.tnum/two.tnum/two.tnum/five.tnum/seven.tnum/nine.tnum/one.tnum\nand make the experiment computationally feasible, we test the\n“large” size of each of our three models, using the Huggingface\nTransformers library (\nWolf et al., 2019 ). Our logistic regression\nprobes are implemented using Scikitlearn ( Pedregosa et al., 2011 ).\n/five.tnum./two.tnum. Probing results\n/five.tnum./two.tnum./one.tnum. Artiﬁcial data\nAs shown in\nFigure 1, the results of our syntactic probe indicate\nthat all models can easily distinguish between positive and negative\nexamples in at least some of their layers, independently of any of the\nsentence properties that we have investigated. We report full results\nin Figures A1–A3 in the Appendix (\nSupplementary material). We\nﬁnd a clear trend that DeBERTa performs better than RoBERTa,\nwhich in turn performs better than BERT across the board. As\nDeBERTa’s performance in all layers is nearly perfect, we are unable\nto observe patterns related to the length of the sentence, the\nstart position of the CC, the start position of the second half of\nthe CC, and the distance between them. By contrast, we observe\ninteresting patterns for BERT and RoBERTa. For Dlength, and to a\nlesser degree Ddistance (which correlates with it), we observe that at\nﬁrst, performance goes down with increased length as we would\nexpect—the model struggles to generalize to longer sentences with\nmore interference since it was only trained on short ones. However,\nthis trend is reversed in the last few layers. We hypothesize this may\nbe due to an increased focus on semantics in the last layers (\nPeters\net al., 2018 ; Tenney et al., 2019 ), which could lead to interfering\nfeatures particularly in shorter sentences.\n/five.tnum./two.tnum./two.tnum. Corpus data\nIn contrast, the results of our probe on more natural data from\nC4 indicate two diﬀerent trends: ﬁrst, as the positive and negative\ninstances are not identical on a bag-of-word level, performance is\nnot uniformly at 50% (i.e., chance) level in the ﬁrst layers, indicating\nthat the model can exploit lexical cues to some degree. We observe\na similar trend as with the artiﬁcial experiment, which showed\nthat DeBERTa performs best and BERT worst. The corresponding\ngraphs can be found in Figures A4–A6 in\nSupplementary material.\nGenerally, this additional corpus-based experiment validates\nour ﬁndings from the experiment with artiﬁcially generated data,\nas all models perform at 80% or better from the middle layers\non, indicating that the models are able to classify instances of the\nconstruction even when they are very diverse and use unseen POS\ntag patterns.\nComparing the average accuracies on Dlength for both data\nsources in\nFigure 1, we observe that all models perform better on\nartiﬁcial than on corpus data from the ﬁfth layer on, with the\nnotable exception of a dip in performance for BERT large around\nlayer 10.\n/six.tnum. Semantics\n/six.tnum./one.tnum. Probing approach\nFor the second half of our investigation, we turn to semantics.\nIn order to determine if a model has understood the meaning of\nthe CC, i.e., if it has understood that in any sentence, “the COMP\n.... the COMP” implies a correlation between the two halves, we\nadopt a usage-based approach and ask: can the model, based on\nthe meaning conveyed by the CC, draw a correct inference in a\nspeciﬁc scenario? For this, we construct general test instances of\nthe CC that consist of a desired update of the belief state of the\nmodel about the world, which we then expect it to be able to apply.\nMore concretely, we generate sentences of the form “The ADJ1-er\nyou are, the ADJ2-er you are., ” while picking adjectives at random.\nTo this general statement, we then add a speciﬁc scenario with\ntwo random names: “ NAME1is ADJ1-er than NAME2.” and ask\nthe model to draw an inference from it. We ﬁrst construct a test\nscenario for this that works with masked language models and test\nBERT, RoBERTa and DeBERTa on it, and then modify the setup and\nmove on to autoregressive models, speciﬁcally OPT (\nZhang et al.,\n2022).\n/six.tnum./two.tnum. Experiments on masked language\nmodels\n/six.tnum./two.tnum./one.tnum. Probing methods\nIn our experiments with masked language models, we now ask\nthe models to draw an inference from the context by predicting a\ntoken at the masked position in the following sentence: “Therefore,\nNAME1is [MASK]than NAME2.” If the model has understood the\nTABLE /four.tnumOverview of constructions investigated in CxG-speciﬁc probing li terature, with examples.\nReferences Language Source Construction Example\nTayyar Madabushi et al.\n(2020)\nEnglish From automatically constructed\nlist by\nDunn (2017)\nPersonal Pronoun + didn’t + V +\nhow\nWe didn’t know how or why.\nLi et al. (2022) English Argument structure constructions\naccording to Bencini and Goldberg\n(2000)\ncaused-motion Bob cut the bread into the pan.\nTseng et al. (2022) Chinese From constructions list by Zhan\n(2017)\na + 到+ 爆, etc. 好吃到爆了!\nIt’s so delicious!\nWeissweiler et al. (2022) English McCawley (1988) Comparative correlative The bigger, the better.\nMahowald (2023) English Jackendoﬀ (1977) Article + Adjective + Numeral +\nNoun\nA lovely 5 days\nFrontiers in Artiﬁcial Intelligence /zero.tnum/nine.tnum frontiersin.org\nWeissweiler et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/three.tnum./one.tnum/two.tnum/two.tnum/five.tnum/seven.tnum/nine.tnum/one.tnum\nTABLE /five.tnumOverview of the schemata of all test scenarios used for semantic p robing for masked language models.\nNo. Purpose Approach Sentence schema\nS1 Base The ADJ1-er you are, the ADJ2-er you are. The ANT1-er you are, the ANT2-er you are.\nNAME1is ADJ1-er than NAME2. Therefore, NAME1is [MASK]than NAME2.\nS2 Bias test Recency The ANT1-er you are, the ANT2-er you are. The ADJ1-er you are, the ADJ2-er you are.\nNAME1is ADJ1-er than NAME2. Therefore, NAME1is [MASK]than NAME2.\nS3 Vocabulary The ADJ1-er you are, the ANT2-er you are. The ANT1-er you are, the ADJ2-er you are.\nNAME2is ADJ1-er than NAME2. Therefore, NAME1is [MASK]than NAME2.\nS4 Name The ADJ1-er you are, the ADJ2-er you are. The ANT1-er you are, the ANT2-er you are.\nNAME2is ADJ1-er than NAME1. Therefore, NAME2is [MASK]than NAME1.\nS5 Calibration Short NAME1is ADJ1-er than NAME2. Therefore, NAME1is [MASK]than NAME2.\nS6 Name The ADJ1-er you are, the ADJ2-er you are. The ANT1-er you are, the ANT2-er you are.\nNAME1is ADJ1-er than NAME2. Therefore, NAME3is [MASK]than NAME4.\nS7 Adjective The ADJ1-er you are, the ADJ2-er you are. The ANT1-er you are, the ANT2-er you are.\nNAME1is ADJ3-er than NAME2. Therefore, NAME1is [MASK]than NAME2.\nmeaning conveyed by the CC and is able to use it in predicting the\nmask, we expect the probability of ADJ2to be high.\nTo provide the model with an alternative, we add a second\nsentence, another instance of the CC, using the antonyms of the\ntwo adjectives. This sentence is carefully chosen to have no impact\non the best ﬁller for [MASK], but also for other reasons explained\nin Section 6.2.1.1. The full test context is shown in\nTable 5, S1.\nThis enables us to compare the probability of ADJ2for the mask\ntoken directly with a plausible alternative, ANT2. One of our test\nsentences might be “The stronger you are, the faster you are. The\nweaker you are, the slower you are. Terry is stronger than John.\nTherefore, Terry will be [MASK]than John, ” where we compare\nthe probabilities of “faster” and “slower.”\nNote that success in our experiment does not necessarily\nindicate that the model has fully understood the meaning of the CC.\nThe experiment can only provide a lower bound for the underlying\nunderstanding of any model. However, we believe that our task\nis not unreasonable for a masked language model in a zero-shot\nsetting. It is comparable in diﬃculty and non-reliance on world\nknowledge to the NLU tasks presented in LAMBADA (\nPaperno\net al., 2016 ), on which GPT-2 (117 M to 1.5 B parameters) has\nachieved high zero-shot accuracy ( Radford et al., 2019 , Table 4).\nWhile we investigate masked language models and not GPT-2, our\nlargest models are comparable in size to the sizes of GPT-2 that were\nused (340 M for BERT L, 355 M for RoBERTaL, and 1.5 B parameters\nfor DeBERTa-XXL L), and we believe that this part of our task is\nachievable to some degree.\n/six.tnum./two.tnum./one.tnum./one.tnum. Biases\nIn this setup, we hypothesize several biases that models could\nexhibit and might cloud our assessment of its understanding of the\nCC, and devise a way to test their impact.\nFirstly, we expect that models might prefer to repeat the\nadjective that is closest to the mask token. This has recently been\ndocumented for prompt-based experiments (\nZhao et al., 2021 ).\nHere, this adjective is ANT2, the wrong answer. To test the\ninﬂuence this has on the prediction probabilities, we construct an\nalternative version of our test context in which we ﬂip the ﬁrst two\nsentences so that the correct answer is now more recent. The result\ncan be found in\nTable 5, S2.\nSecondly, we expect that models might assign higher\nprobabilities to some adjectives, purely based on their frequency\nin the pretraining corpus, as for example observed by\nHoltzman\net al. (2021). To test this, we construct a version of the test context\nin which ADJ2/ANT2are swapped, which means that we can\nkeep both the overall words the same as well as the position of the\ncorrect answer, while changing which adjective it is. The sentence\nis now S3 in\nTable 5. If there is a large diﬀerence between the\nprediction probabilities for the two diﬀerent versions, that this\nmeans that a model’s prediction is inﬂuenced by the lexical identity\nof the adjective in question.\nLastly, a model might have learned to associate adjectives with\nnames in pretraining, so we construct a third version, in which\nwe swap the names. This is S4 in\nTable 5. If any prior association\nbetween names and adjectives inﬂuences the prediction, we expect\nthe scores between S4 and S1 to diﬀer.\n/six.tnum./two.tnum./one.tnum./two.tnum. Calibration\nAfter quantifying the biases that may prevent us from seeing\na model’s true capability in understanding the CC, we aim to\ndevelop methods to mitigate it. We turn to calibration, which has\nrecently been used in probing with few-shot examples by\nZhao\net al. (2021). The aim of calibration is to improve the performance\nof a model on a classiﬁcation task, by ﬁrst assessing the prior\nprobability of a label (i.e., its probability if no context is given),\nand then dividing the probability predicted in the task context by\nthis prior; this gives us the conditional probability of a label given\nthe context, representing the true knowledge of the model about\nthis task. In adapting calibration, we want to give a model every\npossible opportunity to do well so that we do not underestimate its\nunderlying comprehension.\nWe therefore develop three diﬀerent methods of removing the\nimportant information from the context in such a way that we\ncan use the prediction probabilities of the two adjectives in these\nFrontiers in Artiﬁcial Intelligence /one.tnum/zero.tnum frontiersin.org\nWeissweiler et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/three.tnum./one.tnum/two.tnum/two.tnum/five.tnum/seven.tnum/nine.tnum/one.tnum\nTABLE /six.tnumSelected accuracies and results for the semantic probe.\nAccuracy Decision ﬂip\nS/one.tnumS/two.tnumS/two.tnumS/three.tnumS/four.tnum\nBERTB 37.65 64.64 26.98 75.69 02.70\nBERTL 36.85 67.21 30.44 73.31 02.32\nRoBERTaB 61.60 52.84 09.91 76.18 02.76\nRoBERTaL 55.71 68.00 14.33 79.47 04.33\nDeBERTaB 49.72 49.80 00.91 99.66 01.07\nDeBERTaL 50.88 51.40 07.04 94.83 02.23\nDeBERTaXL 47.73 49.33 05.46 89.28 02.51\nDeBERTaXXL 47.34 48.72 03.59 82.09 01.13\nWe report the average accuracy on the more diﬃcult sentences in ter ms of recency bias (S1)\nand the easier ones (S2), as well as the percentage of decisions ﬂipped b y changing from the\nbase S1 to the sentences testing for recency bias (S2), vocabulary bi as (S3), and name bias (S4).\nRoBERTa and DeBERTa perform close to chance on S1 and S2 accuracy, indi cating that they\ndo not understand the meaning of CC. BERT’s performance is strongly i nﬂuenced by biases\n(recency, lexical identity), also indicating that it has very lim ited if any understanding of CC.\ncontexts for calibration. The simplest way of doing this is to remove\nboth instances of the CC, resulting in S5 in\nTable 5. If we want\nto keep the CC in the context, the two options to remove any\ninformation are to replace either the names or the adjectives with\nnew names/adjectives. We therefore construct two more instances\nfor calibration: S6 and S7 in\nTable 5.\nFor each calibration method, we collect ﬁve examples with\ndiﬀerent adjectives or names. For a given base sample Sb, we\ncalculate Pc, the calibrated predictions, as follows:\nPc(a|Sb) = P(a|Sb)/[\ni= 5∑\ni= 1\n(P(a|Ci)/5)]\nwhere Ci is the i-th example of a given calibration technique,\na is the list of adjectives tested for the masked position, and the\ndivision is applied elementwise. We collect a list of 20 adjectives\nand their antonyms manually from the vocabulary of the RoBERTa\ntokenizer and 33 common names and generate 144,800 sentences\nfrom them. We test BERT (\nDevlin et al., 2019 ) in the sizes base\nand large, RoBERTa ( Liu et al., 2019 ) in the sizes base and large,\nand DeBERTa ( He et al., 2020 ) in the sizes base, large, xlarge, and\nxxlarge.\n/six.tnum./two.tnum./two.tnum. Results\nIn\nTable 6, we report the accuracy for all examined models. Out\nof the three variations to test biases, we report accuracy only for\nthe sentence testing the recency bias as we expect this bias to occur\nsystematically across all sentences: if it is a large eﬀect, it will always\nlead to the sentence where the correct answer is the more recent one\nbeing favored. To assess the inﬂuence of each bias beyond accuracy,\nwe report as decision ﬂip the percentage of sentences for which the\ndecision (i.e., if the correct adjective had a higher probability than\nthe incorrect one) was changed when considering the alternative\nsentence that was constructed to test for bias. We report full results\nin\nTable 7.\nLooking at the accuracies, we see that RoBERTa’s and DeBERTa’s\nscores are close to 50 (i.e., chance) accuracy for both S1 and S2.\nBERT models diﬀer considerably as they seem to suﬀer from bias\nrelated to the order of the two CCs, but we can see that the average\nbetween them is also very close to chance. When we further look at\nthe decision ﬂips for each of the biases, we ﬁnd that there is next\nto no bias related to the choice of names (S4). However, we can\nsee a large bias related to both the recency of the correct answer\n(S2) and the choice of adjectives (S3). The recency bias is strongest\nin the BERT models, which also accounts for the diﬀerence in\naccuracies. For RoBERTa and DeBERTa models, the recency bias\nis small, but clearly present. In contrast, they exhibit far greater\nbias toward the choice of adjective, even going as far as 99.66%\nof decisions ﬂipped by changing the adjective for DeBERTa base.\nThis suggests that these models’ decisions about which adjective to\nassign a higher probability is almost completely inﬂuenced by the\nchoice of adjective, not the presence of the CC. Overall, we conclude\nthat without calibration, all models seem to be highly susceptible\nto diﬀerent combinations of bias, which completely obfuscate any\nunderlying knowledge of the CC, leading to an accuracy at chance\nlevel across the board.\nWe therefore turn to our calibration methods, evaluating them\nﬁrst on their inﬂuence on the decision ﬂip scores, which directly\nshow if we were able to reduce the impact of the diﬀerent types\nof bias. We report these only for order and vocabulary bias as we\nfound name bias to be inconsequential. We report the complete\nresults in\nTable 7. We see that across all models, while all three\ncalibration methods work to reduce some bias, none does so\nconsistently across all models or types of bias. Even in cases where\ncalibration has clearly reduced the decision ﬂip score, we ﬁnd that\nthe ﬁnal calibrated accuracy is still close to 50%. This indicates that\ndespite the eﬀort to retrieve any knowledge that the models have\nabout the CC, they are unable to perform clearly above chance, and\nwe have therefore found no evidence that the investigated models\nunderstand and can use the semantics of the CC.\nTo investigate if this was result was exclusive to smaller, masked\nlanguage models, we repeat our experiment and turn to larger,\nautoregressive models, more speciﬁcally, diﬀerent sizes of OPT\n(\nZhang et al., 2022 ).\n/six.tnum./three.tnum. Experiments on autoregressive\nlanguage models\n/six.tnum./three.tnum./one.tnum. Methods\n/six.tnum./three.tnum./one.tnum./one.tnum. Probing setup\nSince we concluded from our experiments with masked\nlanguage models that none of them have reached signiﬁcant\nperformance on our task, we move on to investigating newer\nautoregressive models. We hope that as these models have\nbeen shown to perform signiﬁcantly better on natural language\nunderstanding (NLU;\nZhang et al., 2022 ), which is a prerequisite\nfor our probing setup, their performance will be more directly\nindicative of their understanding of the CC in context.\nAs we can no longer perform our experiments on the basis of\ncomparing the predictions for a given MASK token, we modify\nthe setup such that our metric is based on the comparison of\nthe perplexity of two competing whole sentences. Our main idea\nis to no longer work with antonyms but instead create contrast\nFrontiers in Artiﬁcial Intelligence /one.tnum/one.tnum frontiersin.org\nWeissweiler et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/three.tnum./one.tnum/two.tnum/two.tnum/five.tnum/seven.tnum/nine.tnum/one.tnum\nTABLE /seven.tnumAccuracies for the semantic probe with our three calibration me thods compared to no calibration.\nAccuracies Decision ﬂips\nModel Test sentence − S/five.tnumS/six.tnumS/seven.tnum− S/five.tnumS/six.tnumS/seven.tnum\nBERTB\nS1 37.65 37.62 44.39 47.9 – – – –\nS2 64.64 62.79 56.66 55.41 26.99 25.22 14.75 10.77\nS3 38.04 44.78 44.09 48.29 75.69 23.51 86.33 91.05\nS4 – – – – 2.71 – – –\nBERTL\nS1 36.85 31.91 47.21 44.03 – – – –\nS2 67.13 73.48 54.39 64.45 30.44 41.8 13.37 22.24\nS3 36.46 43.43 47.79 44.36 73.31 25.94 88.65 85.97\nS4 – – – – 2.32 – – –\nRoBERTaB\nS1 61.6 58.76 42.13 62.32 – – – –\nS2 52.85 51.35 71.33 60.25 9.92 8.67 31.13 10.86\nS3 62.21 55.17 43.04 62.76 76.19 22.04 79.03 74.75\nS4 – – – – 2.76 – – –\nRoBERTaL\nS1 55.72 58.37 65.08 69.53 – – – –\nS2 68.01 74.53 62.73 77.76 14.34 17.82 15.94 15.86\nS3 55.36 52.02 65.28 69.23 79.48 43.64 79.75 78.32\nS4 – – – – 3.25 – – –\nDeBERTaB\nS1 41.61 36.41 32.79 43.27 – – – –\nS2 42.95 43.04 33.77 42.36 24.21 24.4 8.79 7.49\nS3 41.92 38.64 32.39 43.31 74.58 17.83 72.29 64.42\nS4 – – – – 1.67 – – –\nDeBERTaL\nS1 58.5 60.34 45.17 65.42 – – – –\nS2 64.56 66.43 49.99 62.77 13.47 14.27 14.43 13.15\nS3 58.8 59.84 45.41 65.45 78.25 30.36 75.61 70.21\nS4 – – – – 2.65 – – –\nDeBERTaXL\nS1 67.24 74.59 57.33 76.64 – – – –\nS2 76.31 78.92 63.75 78.41 18.02 18.79 17.37 16.48\nS3 67.28 74.35 57.51 76.69 82.35 43.29 78.43 72.99\nS4 – – – – 3.34 – – –\nWe report the average accuracy on the more diﬃcult sentences in ter ms of recency bias (S1), the easier ones (S2), and vocabulary bias (S3), as we ll as the percentage of decisions ﬂipped by\nchanging from the base S1 to each sentence. Our calibration techn iques are short (S5), name (S6), and adjective (S7).\nFIGURE /two.tnum\nAccuracy and name bias scores for test sentences S/eight.tnum–S/one.tnum/one.tnum on the left and S/one.tnum/two.tnum–S/one.tnum/five.tnum on the right, on diﬀerent sizes of OPT.\nFrontiers in Artiﬁcial Intelligence /one.tnum/two.tnum frontiersin.org\nWeissweiler et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/three.tnum./one.tnum/two.tnum/two.tnum/five.tnum/seven.tnum/nine.tnum/one.tnum\nTABLE /eight.tnumOverview of the schemata of test scenarios S/eight.tnum–S/one.tnum/five.tnum, used for semantic probing for autoregressive language models.\nNo. Name order Validity Sentence schema\nS8 Same True The ADJ1-er you are, the ADJ2-er you are. NAME1is ADJ1-er than NAME2.\nTherefore, NAME1will be ADJ2-er than NAME2.\nS9 False The ADJ1-er you are, the ADJ2-er you are. NAME1is ADJ1-er than NAME2.\nTherefore, NAME2will be ADJ2-er than NAME1.\nS10 True The ADJ1-er you are, the ADJ2-er you are. NAME2is ADJ1-er than NAME1.\nTherefore, NAME2will be ADJ2-er than NAME1.\nS11 False The ADJ1-er you are, the ADJ2-er you are. NAME2is ADJ1-er than NAME1.\nTherefore, NAME1will be ADJ2-er than NAME2.\nS12 Flipped True The ADJ1-er you are, the ADJ2-er you are. NAME1is less ADJ1than NAME2.\nTherefore, NAME2will be ADJ2-er than NAME1.\nS13 False The ADJ1-er you are, the ADJ2-er you are. NAME1is less ADJ1than NAME2.\nTherefore, NAME1will be ADJ2-er than NAME2.\nS14 True The ADJ1-er you are, the ADJ2-er you are. NAME2is less ADJ1than NAME1.\nTherefore, NAME1will be ADJ2-er than NAME2.\nS15 False The ADJ1-er you are, the ADJ2-er you are. NAME2is less ADJ1than NAME1.\nTherefore, NAME2will be ADJ2-er than NAME1.\nby swapping the two names in the last sentence. Given the\ncontext “The ADJ1-er you are, the ADJ2-er you are. NAME1is\nADJ1-er than NAME2., ” we contrast the perplexities of “Therefore,\nNAME1will be ADJ2-er than NAME2” and “Therefore, NAME2\nwill be ADJ2-er than NAME1.” While the sentences are bag-of-\nwords equivalent, only the ﬁrst one follows from the context.\nThis has the additional eﬀect of removing the confounding\nfactor of the second sentence with antonyms from the factors\nthat inﬂuence the model’s performance. For example, we would\nnow contrast “The stronger you are, the faster you are. Terry\nis stronger than John. Therefore, Terry will be faster than\nJohn” with “The stronger you are, the faster you are. Terry is\nstronger than John. Therefore, John will be faster than Terry.”\n/six.tnum./three.tnum./one.tnum./two.tnum. Name bias\nSimilarly to our previous experiment in Section 6.2.1, we\nhypothesize biases to this setup and test them. Our “adjective bias”\nand “recency bias” are not immediately applicable here, as we no\nlonger have a masked token.\nHowever, we expect that models might consistently prefer one\nﬁnal sentence, which is the one that changes the acceptability of\nthe entire test phrase, over another, regardless of context. To test\nthis, we construct a second pair of sentences, where the names are\nswapped both times. This means that when iterating through all 4-\ntuples of sentences that belong together, we can now compare all\nfour and count only those as valid results where either both pairs\nwere correctly classiﬁed or both were incorrectly classiﬁed. For the\nothers, where one was correct and the other incorrect, this indicates\nthat the model preferred one ﬁnal sentence over the other in all\ncontexts. We count how many times this occurs to quantify the\nstrength of this name bias in a model.\n/six.tnum./three.tnum./two.tnum. Initial results\nFor our results, we consider each four-tuple of sentences S8-\nS11. We perform perplexity comparisons twice: ﬁrstly, we expect the\nperplexity of S8 to be lower than that of S9; secondly, we anticipate\nthe perplexity of S10 to be lower than that of S11. We denote C\nto represent the count of correct results where both conditions\nare met, I to represent the count of incorrect results where both\nconditions fail, and In to represent the count of inconclusive results\nwhere one condition is met and the other is not.\nThe general trend for these three counts can be seen in the right\nhalf of\nFigure 2. As the models increase in size, C rises and In drops,\nwith I remaining generally low. The only exception to this is the\nOPT-1.3b model, for unknown reasons.\nWe then develop two more abstract metrics based on these\ncounts:\n1. We deﬁne the accuracy, A, as the number of correct responses\ndivided by the number of valid responses (correct and incorrect\nones). In mathematical terms: A = C\nC+ I .\n2. As a complementary metric, we deﬁne the “name bias, ” B, as\nthe percentage of inconclusive responses over total responses.\nMathematically, B = In\nC+ I+ In .\nWe use “name bias” to denote situations where the model\nconsistently favored one of the two possibilities for the last sentence,\nindicating a possible bias for this sentence, perhaps due to the order\nof names and the combination with the particular adjective.\nOur observations show that A remains consistently high (with\nthe exception of 1.3 b) and B decreases as the model size increases.\nThese results were initially encouraging for the hypothesis that\nlarger, autoregressive models are able to capture the semantics\nof the CC. However, there is one important possibility for bias\nin all four sentences: the correct answer is consistently that in\nFrontiers in Artiﬁcial Intelligence /one.tnum/three.tnum frontiersin.org\nWeissweiler et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/three.tnum./one.tnum/two.tnum/two.tnum/five.tnum/seven.tnum/nine.tnum/one.tnum\nwhich the two names are in the same order in both sentences.\nWe therefore have to examine the possibility that the near-perfect\naccuracy displayed in our task is merely due to the name order\nbeing parallel and not to any deeper understanding of the sentences.\n/six.tnum./three.tnum./three.tnum. Additional experiment\nWe therefore construct four additional sentences, named S12–\nS15 in\nTable 8. They are constructed with “less, ” to ensure that the\ncorrect answer is now the one where the order of names is swapped.\nWe rerun the same experiment as before with these sentences.\nWe expect that if the model was merely preferring the parallel\norder of names, the accuracy would be close to zero, whereas a\ncontinued good accuracy would indicate that it formed a deeper\nunderstanding of the task.\nThe results in\nFigure 2 show that unfortunately the former was\nthe case: all values are approximately inverted compared to the ﬁrst\nexperiment. If the model had formed an understanding of the CC\nin this task, our reformulation of the task could not have completely\ndestroyed the performance. We therefore conclude that none of the\nmodels, at least in this setup, have demonstrated an understanding\nof the CC.\n/six.tnum./four.tnum. Problem analysis\nDiﬀerent conclusions might be drawn as to why none of\nthese models have learned the semantics of the CC. Firstly, they\nmight not have seen enough examples of it to have formed a\ngeneral understanding. Given the amount of examples that we\nwere able to ﬁnd in C4, and the overall positive results from\nthe syntax section, we ﬁnd this to be unlikely. Secondly, it could\nbe argued that models have never had a chance to learn what\nthe CC means because they have never seen it together with a\ncontext in which it was immediately applied, and do not have\nthe same opportunities as humans available, which would be to\neither interact with the speaker to clarify the meaning, or to make\ndeductions using observations in the real world. This is in line\nwith other considerations about large PLMs acquiring advanced\nsemantics, even though it has for many phenomena been shown\nthat pre-training is enough (\nRadford et al., 2019 ). Lastly, it might\nbe possible that the type of meaning representation required to\nsolve this task is beyond the current transformer-style architectures.\nOverall, our ﬁnding that PLMs do not learn the semantics of the CC\nadds to the growing body of evidence that complex semantics like\nnegation (\nKassner and Schütze, 2020 ) is still beyond state-of-the-art\nPLMs.\n/seven.tnum. Conclusion\nWe have made a ﬁrst step toward a thorough investigation of\nthe compatibility of the paradigm of CxG and the syntactic and\nsemantic capabilities exhibited by state-of-the-art large PLMs. For\nthis, we chose the English comparative correlative, one of the most\nwell-studied constructions, and investigated if large PLMs based\non masked language modeling have learned it, both syntactically\nand semantically. We found that even though they are able to\nclassify sentences as instances of the construction even in diﬃcult\ncircumstances, they do not seem to be able to extract the meaning it\nconveys and use it in context, indicating that while the syntactic\naspect of the CC is captured in pretraining of these models, the\nsemantic aspect is not. We then repeated a modiﬁed version of our\nsemantic experiments with larger, autoregressive language models,\nand found that they were similarly unable to capture the semantics\nof the construction.\n/eight.tnum. Limitations\nAs our experimental setup requires signiﬁcant customization\nwith regards to the properties of the speciﬁc construction we\ninvestigate, we are unable to consider other constructions or\nother languages in this work. We hope to be able to extend our\nexperiments in this direction in the future. Our analysis is also\nlimited—as all probing papers are—by the necessary indirectness\nof the probing tasks: we cannot directly assess the model’s internal\nrepresentation of the CC, but only construct tasks that might show\nit but are imperfect and potentially aﬀected by external factors.\nData availability statement\nThe datasets presented in this study can be found in\nonline repositories. The names of the repository/repositories\nand accession number(s) can be found at:\nhttps://github.com/\nLeonieWeissweiler/ComparativeCorrelative.\nAuthor contributions\nLW designed the original research question together with VH.\nThey wrote and discussed the linguistics background as well as\nthe motivation for the experiments and the speciﬁcs of the syntax\nexperiments. The speciﬁcs of the semantics experiments were\ndesigned by LW and AK. HS acted as main advisor to LW, VH,\nand AK and gave guidance on the process throughout. All authors\ncontributed to the article and approved the submitted version.\nFunding\nThis work was funded by the European Research Council\n(#740516). VH was also supported by the German Academic\nScholarship Foundation. AK was also supported by the German\nFederal Ministry of Education and Research (BMBF, Grant No.\n01IS18036A).\nAcknowledgments\nThe content of this manuscript has been presented in part at\nthe 2022 Conference on Empirical Methods in Natural Language\nProcessing (\nWeissweiler et al., 2022 ), and the Construction\nGrammars and NLP (CxGs+NLP) Workshop at the Georgetown\nUniversity Round Table on Linguistics (GURT;\nWeissweiler et al.,\n2023). We are very grateful to David Mortensen and Lori Levin for\nhelpful discussions and comments.\nFrontiers in Artiﬁcial Intelligence /one.tnum/four.tnum frontiersin.org\nWeissweiler et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/three.tnum./one.tnum/two.tnum/two.tnum/five.tnum/seven.tnum/nine.tnum/one.tnum\nConﬂict of interest\nThe authors declare that the research was conducted in the\nabsence of any commercial or ﬁnancial relationships that could be\nconstrued as a potential conﬂict of interest.\nPublisher’s note\nAll claims expressed in this article are solely those of the\nauthors and do not necessarily represent those of their aﬃliated\norganizations, or those of the publisher, the editors and the\nreviewers. Any product that may be evaluated in this article, or\nclaim that may be made by its manufacturer, is not guaranteed or\nendorsed by the publisher.\nSupplementary material\nThe Supplementary Material for this article can be found\nonline at: https://www.frontiersin.org/articles/10.3389/frai.2023.\n1225791/full#supplementary-material\nReferences\nAbeillé, A., and Borsley, R. D. (2008). Comparative correlatives and parameters.\nLingua 118, 1139–1157. doi: 10.1016/j.lingua.2008.02.001\nBelinkov, Y., Durrani, N., Dalvi, F., Sajjad, H., and Glass, J. (2 017). “What do\nneural machine translation models learn about morphology?, ” in Proceedings of the\n55th Annual Meeting of the Association for Computational Linguistics (Volume 1:\nLong Papers) (Vancouver, BC: Association for Computational Linguistics ), 861–872.\ndoi: 10.18653/v1/P17-1080\nBencini, G. M., and Goldberg, A. E. (2000). The contribution of a rgument\nstructure constructions to sentence meaning. J. Mem. Lang . 43, 640–651.\ndoi: 10.1006/jmla.2000.2757\nBloomﬁeld, L. (1933). Language. New York, NY: Holt, Rinehart & Winston.\nChomsky, N. (1988). Generative grammar. Studies in English lin guistics and\nliterature.\nConneau, A., Kruszewski, G., Lample, G., Barrault, L., and Baroni , M. (2018).\n“What you can cram into a single $&!#* vector: probing sentence embeddings for\nlinguistic properties, ” in Proceedings of the 56th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers)(Melbourne, VIC: Association for\nComputational Linguistics), 2126–2136. doi: 10.18653/v1/ P18-1198\nCulicover, P. W., and Jackendoﬀ, R. (1999). The view from the\nperiphery: the English comparative correlative. Linguist. Inq . 30, 543–571.\ndoi: 10.1162/002438999554200\nDemszky, D., Sharma, D., Clark, J. H., Prabhakaran, V., and Ei senstein, J.\n(2021). “Learning to recognize dialect features, ” in Annual Conference of the North\nAmerican Chapter of the Association for Computational Linguistics: Human Language\nTechnologies (NAACL HTL) 2021. doi: 10.18653/v1/2021.naacl-main.184\nDen Dikken, M. (2005). Comparative correlatives comparatively . Linguist. Inq. 36,\n497–532. doi: 10.1162/002438905774464377\nDevlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2019). “ BERT: pre-training\nof deep bidirectional transformers for language understand ing, ” inProceedings of the\n2019 Conference of the North American Chapter of the Association for Computational\nLinguistics: Human Language Technologies, Volume 1 (Long and Short Pa pers)\n(Minneapolis, MI: Association for Computational Linguistics ), 4171–4186.\nDunietz, J., Levin, L., and Carbonell, J. (2017). Automatically tagging constructions\nof causation and their slot-ﬁllers. Trans. Assoc. Comput. Linguist . 5, 117–133.\ndoi: 10.1162/tacl_a_00050\nDunn, J. (2017). Computational learning of construction gram mars. Lang. Cogn. 9,\n254–292. doi: 10.1017/langcog.2016.7\nDunn, J. (2019). “Frequency vs. association for constraint s election in usage-\nbased construction grammar, ” in Proceedings of the Workshop on Cognitive Modeling\nand Computational Linguistics (Minneapolis, MI: Association for Computational\nLinguistics), 117–128. doi: 10.18653/v1/W19-2913\nFillmore, C. J. (1986). “Varieties of conditional sentences, ” in Eastern States\nConference on Linguistics, Vol. 3, 163–182. Available online at: https://books.google.de/\nbooks/about/Proceedings_of_the_Eastern_States_Confer.html?id=QQiNZntjqRYC&\nredir_esc=y\nFillmore, C. J. (1989). “Grammatical construction: theory and the\nfamiliar dichotomies, ” in Language Processing in Social Context , eds R.\nDietrich and C. F. Graumann (Amsterdam: North-Holland), 17–38 .\ndoi: 10.1016/B978-0-444-87144-2.50004-5\nFillmore, C. J., Kay, P., and O’Connor, M. C. (1988). Regularity and idiomaticity\nin grammatical constructions: the case of let alone. Language 64, 501–538.\ndoi: 10.2307/414531\nGoldberg, A. (2006). Constructions at Work: The Nature of\nGeneralization in Language . Oxford, UK: Oxford University Press.\ndoi: 10.1093/acprof:oso/9780199268511.001.0001\nGoldberg, A. (1995). Constructions: A Construction Grammar Approach to\nArgument Structure. Chicago, IL; London: University of Chicago Press.\nGoldberg, A. E. (2003). Constructions: a new theoretical approa ch to language.\nTrends Cogn. Sci. 7, 219–224. doi: 10.1016/S1364-6613(03)00080-9\nGoldberg, A. E. (2013). “Chapter: 1415 Constructionist approach es, ” in The\nOxford Handbook of Construction Grammar, eds T. Hoﬀmann, and G. Trousdale\n(Oxford: Oxford University Press), 1531. doi: 10.1093/oxf ordhb/9780195396683.013.\n0002\nGoldberg, Y. (2019). Assessing Bert’s syntactic abilities. arXiv preprint\narXiv:1901.05287.\nGoldberg, A. E. (1995). Constructions: A Construction Grammar Approach to\nArgument Structure. University of Chicago Press.\nHe, P., Liu, X., Gao, J., and Chen, W. (2020). “Deberta: decod ing-enhanced Bert\nwith disentangled attention, ” in International Conference on Learning Representations.\nHilpert, M. (2006). A synchronic perspective on the grammaticali zation of Swedish\nfuture constructions. Nordic J. Linguist. 29, 151–173. doi: 10.1017/S03325865060\n01569\nHoﬀmann, T., Horsch, J., and Brunner, T. (2019). The more dat a, the better: a usage-\nbased account of the english comparative correlative construc tion. Cogn. Linguist. 30,\n1–36. doi: 10.1515/cog-2018-0036\nHoﬀmann, T., and Trousdale, G. (2013). The Oxford Handbook\nof Construction Grammar . Oxford: Oxford University Press.\ndoi: 10.1093/oxfordhb/9780195396683.001.0001\nHoltzman, A., West, P., Shwartz, V., Choi, Y., and Zettlemoyer , L. (2021).\n“Surface form competition: why the highest probability answer isn’t always right, ”\nin Proceedings of the 2021 Conference on Empirical Methods in Natural Language\nProcessing (Punta Cana: Association for Computational Linguistics), 7 038–7051.\ndoi: 10.18653/v1/2021.emnlp-main.564\nHonnibal, M., and Montani, I. (2018). spaCy 2: natural language understanding\nwith Bloom embeddings, convolutional neural networks and inc remental parsing.\nIwasaki, E., and Radford, A. (2009). “Comparative correlativ es in English: a\nminimalist-cartographic analysis, ” in Essex Research Reports in Linguistics, Vol. 57\n(Essex).\nJackendoﬀ, R. (1977). X Syntax: A Study of Phrase Structure. Cambridge, MA:\nMIT Press.\nKassner, N., and Schütze, H. (2020). “Negated and misprimed pr obes for\npretrained language models: Birds can talk, but cannot ﬂy, ” in Proceedings of the\n58th Annual Meeting of the Association for Computational Linguistics (Association for\nComputational Linguistics), 7811–7818. doi: 10.18653/v1/ 2020.acl-main.698\nKay, P., and Fillmore, C. J. (1999). Grammatical constructions and linguistic\ngeneralizations: the What’s X doing Y? Construction. Language 75, 1–33.\ndoi: 10.2307/417472\nLakoﬀ, G. (1987). Women, Fire, and Dangerous Things: What Categories\nReveal About the Mind . Chicago, IL: University of Chicago Press.\ndoi: 10.7208/chicago/9780226471013.001.0001\nLangacker, R. W. (1987). Foundations of Cognitive Grammar: Theoretical\nPrerequisites. Stanford, CA: Stanford University Press.\nLi, B., Zhu, Z., Thomas, G., Rudzicz, F., and Xu, Y. (2022). “Ne ural reality of\nargument structure constructions, ” in Proceedings of the 60th Annual Meeting of the\nAssociation for Computational Linguistics (Volume 1: Long Papers)(Dublin: Association\nfor Computational Linguistics), 7410–7423. doi: 10.18653/ v1/2022.acl-long.512\nLiu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., et al. (20 19). Roberta: a\nrobustly optimized Bert pretraining approach. arXiv preprint arXiv:1907.11692.\nFrontiers in Artiﬁcial Intelligence /one.tnum/five.tnum frontiersin.org\nWeissweiler et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/three.tnum./one.tnum/two.tnum/two.tnum/five.tnum/seven.tnum/nine.tnum/one.tnum\nMahowald, K. (2023). A discerning several thousand judgment s: GPT-3 rates the\narticle+ adjective+ numeral+ noun construction. arXiv preprint: arXiv:2301.12564.\ndoi: 10.18653/v1/2023.eacl-main.20\nMarques, T., and Beuls, K. (2016). “Evaluation strategies for c omputational\nconstruction grammars, ” in Proceedings of COLING 2016, the 26th International\nConference on Computational Linguistics: Technical Papers(Osaka: The COLING 2016\nOrganizing Committee), 1137–1146.\nMarvin, R., and Linzen, T. (2018). “Targeted syntactic evalu ation of language\nmodels, ” in Proceedings of the 2018 Conference on Empirical Methods in Natural\nLanguage Processing(Brussels: Association for Computational Linguistics), 119 2–1202.\ndoi: 10.18653/v1/D18-1151\nMcCawley, J. D. (1988). “The comparative conditional constru ction in English,\nGerman, and Chinese, ” in Annual Meeting of the Berkeley Linguistics Society, Vol. 14\n(Berkeley, CA), 176–187. doi: 10.3765/bls.v14i0.1791\nPaperno, D., Kruszewski, G., Lazaridou, A., Pham, N. Q., Berna rdi, R., Pezzelle,\nS., et al. (2016). “The LAMBADA dataset: Word prediction requir ing a broad\ndiscourse context, ” in Proceedings of the 54th Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Papers) (Berlin: Association for\nComputational Linguistics), 1525–1534. doi: 10.18653/v1/ P16-1144\nPedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion , B., Grisel, O., et al.\n(2011). Scikit-learn: machine learning in Python. J. Mach. Learn. Res. 12, 2825–2830.\nPeters, M., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Le e, K., et al. (2018).\n“Deep contextualized word representations, ” in Annual Conference of the North\nAmerican Chapter of the Association for Computational Linguistics: Human Language\nTechnologies (NAACL HLT) 2018(New Orleans, LO). doi: 10.18653/v1/N18-1202\nRadford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutsk ever, I. (2019).\nLanguage models are unsupervised multitask learners. OpenAI blog1, 9.\nRaﬀel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Mate na, M., et al. (2020).\nExploring the limits of transfer learning with a uniﬁed text-to- text transformer. J. Mach.\nLearn. Res. 21, 1–67.\nReif, E., Yuan, A., Wattenberg, M., Viegas, F. B., Coenen, A. , Pearce, A., et al. (2019).\n“Visualizing and measuring the geometry of Bert, ” in Advances in Neural Information\nProcessing Systems, Vol. 32(Vancouver, BC: Curran Associates, Inc.).\nRibeiro, M. T., Wu, T., Guestrin, C., and Singh, S. (2020). “Be yond accuracy:\nbehavioral testing of NLP models with CheckList, ” in Proceedings of the 58th\nAnnual Meeting of the Association for Computational Linguistics (Association for\nComputational Linguistics), 4902–4912. doi: 10.18653/v1/ 2020.acl-main.442\nSchwartz, L., Haley, C., and Tyers, F. (2022). “How to encode a rbitrarily\ncomplex morphology in word embeddings, no corpus needed, ” in Proceedings of\nthe First Workshop on NLP Applications to Field Linguistics(Gyeongju: International\nConference on Computational Linguistics), 64–76.\nSrivastava, A., Rastogi, A., Rao, A., Md Shoeb, AA, Abid, A., and Fisch, A. (2023).\nBeyond the imitation game: quantifying and extrapolating the c apabilities of language\nmodels. Trans. Mach. Learn. Res.2835–2856.\nTayyar Madabushi, H., Romain, L., Divjak, D., and Milin, P. (2 020). “CxGBERT:\nBERT meets construction grammar, ” in Proceedings of the 28th International\nConference on Computational Linguistics (Barcelona: International Committee\non Computational Linguistics), 4020–4032. doi: 10.18653/v 1/2020.coling-\nmain.355\nTenney, I., Xia, P., Chen, B., Wang, A., Poliak, A., McCoy, R. T ., et al. (2019).\n“What do you learn from context? Probing for sentence structu re in contextualized\nword representations, ” inInternational Conference on Learning Representations (ICLR),\nVol. 7. (New Orleans, LO).\nTseng, Y.-H., Shih, C.-F., Chen, P.-E., Chou, H.-Y., Ku, M.- C., and Hsieh, S.-K.\n(2022). “CxLM: a construction and context-aware language mo del, ” inProceedings of\nthe Thirteenth Language Resources and Evaluation Conference(Marseille: European\nLanguage Resources Association), 6361–6369.\nVuli´c, I., Ponti, E. M., Litschko, R., Glavaš, G., and Korhonen, A. (2 020). “Probing\npretrained language models for lexical semantics, ” in Conference on Empirical Methods\nin Natural Language Processing (EMNLP) 2020. doi: 10.18653/v1/2020.emnlp-main.586\nWarstadt, A., Parrish, A., Liu, H., Mohananey, A., Peng, W., Wang, S.-F., et al.\n(2020a). BLiMP: the benchmark of linguistic minimal pairs for English. Trans. Assoc.\nComput. Linguist. 8, 377–392. doi: 10.1162/tacl_a_00321\nWarstadt, A., Singh, A., and Bowman, S. R. (2019). Neural net work acceptability\njudgments. Trans. Assoc. Comput. Linguist. 7, 625–641. doi: 10.1162/tacl_a_00290\nWarstadt, A., Zhang, Y., Li, X., Liu, H., and Bowman, S. R. (20 20b). “Learning\nwhich features matter: RoBERTa acquires a preference for lingu istic generalizations\n(eventually), ” in Proceedings of the 2020 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP)(Association for Computational Linguistics), 217–235.\ndoi: 10.18653/v1/2020.emnlp-main.16\nWei, J., Garrette, D., Linzen, T., and Pavlick, E. (2021). “Fr equency eﬀects on\nsyntactic rule learning in transformers, ” in Proceedings of the 2021 Conference on\nEmpirical Methods in Natural Language Processing (Punta Cana: Association for\nComputational Linguistics), 932–948. doi: 10.18653/v1/20 21.emnlp-main.72\nWeissweiler, L., He, T., Otani, N., R. Mortensen, D., Levin, L ., and Schütze,\nH. (2023). “Construction grammar provides unique insight int o neural language\nmodels, ” inProceedings of the First International Workshop on Construction Grammars\nand NLP (CxGs+NLP , GURT/SyntaxFest 2023)(Washington, DC: Association for\nComputational Linguistics), 85–95.\nWeissweiler, L., Hofmann, V., Köksal, A., and Schütze, H. (202 2). “The better your\nsyntax, the better your semantics? Probing pretrained langua ge models for the English\ncomparative correlative, ” inProceedings of the 2022 Conference on Empirical Methods in\nNatural Language Processing(Abu Dhabi: Association for Computational Linguistics),\n10859–10882. doi: 10.18653/v1/2022.emnlp-main.746\nWiedemann, G., Remus, S., Chawla, A., and Biemann, C. (2019). D oes Bert make\nany sense? Interpretable word sense disambiguation with cont extualized embeddings.\narXiv preprint: arXiv:1909.10430.\nWolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., et al.\n(2019). Huggingface’s transformers: State-of-the-art natural language processing. arXiv\npreprint: arXiv:1910.03771. doi: 10.18653/v1/2020.emnlp-demos.6\nZhan, W. (2017). On theoretical issues in building a knowledge database of Chinese\nconstructions. J. Chinese Inform. Process. 31, 230–238.\nZhang, S., Roller, S., Goyal, N., Artetxe, M., Chen, M., Chen, S., et al. (2022). Opt:\nOpen pre-trained transformer language models. arXiv preprint arXiv:2205.01068.\nZhao, Z., Wallace, E., Feng, S., Klein, D., and Singh, S. (2021). “Calibrate before\nuse: improving few-shot performance of language models, ” in Proceedings of the 38th\nInternational Conference on Machine Learning, Vol. 139 of Proceedingsof Machine\nLearning Research, eds M. Meila and T. Zhang, 12697–12706.\nFrontiers in Artiﬁcial Intelligence /one.tnum/six.tnum frontiersin.org",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7595681548118591
    },
    {
      "name": "Natural language processing",
      "score": 0.6783133745193481
    },
    {
      "name": "Syntax",
      "score": 0.6396129131317139
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5985878705978394
    },
    {
      "name": "Linguistics",
      "score": 0.5421844124794006
    },
    {
      "name": "Grammar",
      "score": 0.5383393168449402
    },
    {
      "name": "Principle of compositionality",
      "score": 0.46914926171302795
    },
    {
      "name": "Semantics (computer science)",
      "score": 0.46023061871528625
    },
    {
      "name": "Programming language",
      "score": 0.10805556178092957
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4403386549",
      "name": "Munich Center for Machine Learning",
      "country": null
    },
    {
      "id": "https://openalex.org/I8204097",
      "name": "Ludwig-Maximilians-Universität München",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I40120149",
      "name": "University of Oxford",
      "country": "GB"
    }
  ]
}