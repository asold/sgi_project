{
  "title": "GPT-4 enhanced multimodal grounding for autonomous driving: Leveraging cross-modal attention with large language models",
  "url": "https://openalex.org/W4392001696",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2789536672",
      "name": "Haicheng Liao",
      "affiliations": [
        "University of Macau",
        "City University of Macau"
      ]
    },
    {
      "id": "https://openalex.org/A4310594201",
      "name": "Huanming Shen",
      "affiliations": [
        "University of Electronic Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A2128758369",
      "name": "Zhenning Li",
      "affiliations": [
        "City University of Macau",
        "University of Macau"
      ]
    },
    {
      "id": "https://openalex.org/A2126434332",
      "name": "Chengyue Wang",
      "affiliations": [
        "University of Macau",
        "City University of Macau"
      ]
    },
    {
      "id": "https://openalex.org/A2124567311",
      "name": "Guofa Li",
      "affiliations": [
        "Chongqing University"
      ]
    },
    {
      "id": "https://openalex.org/A2030470278",
      "name": "Yiming Bie",
      "affiliations": [
        "Jilin University"
      ]
    },
    {
      "id": "https://openalex.org/A2269845662",
      "name": "Chengzhong Xu",
      "affiliations": [
        "University of Macau",
        "City University of Macau"
      ]
    },
    {
      "id": "https://openalex.org/A2789536672",
      "name": "Haicheng Liao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4310594201",
      "name": "Huanming Shen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2128758369",
      "name": "Zhenning Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2126434332",
      "name": "Chengyue Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2124567311",
      "name": "Guofa Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2030470278",
      "name": "Yiming Bie",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2269845662",
      "name": "Chengzhong Xu",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2466381818",
    "https://openalex.org/W3201264086",
    "https://openalex.org/W6760782946",
    "https://openalex.org/W6778485988",
    "https://openalex.org/W6810517632",
    "https://openalex.org/W6776721752",
    "https://openalex.org/W6788486808",
    "https://openalex.org/W6750703656",
    "https://openalex.org/W3170182874",
    "https://openalex.org/W6782659297",
    "https://openalex.org/W6799328305",
    "https://openalex.org/W4307504011",
    "https://openalex.org/W3207010184",
    "https://openalex.org/W4387204747",
    "https://openalex.org/W3131890248",
    "https://openalex.org/W2031489346",
    "https://openalex.org/W6675026286",
    "https://openalex.org/W6805649452",
    "https://openalex.org/W2969825018",
    "https://openalex.org/W6687483927",
    "https://openalex.org/W6690386867",
    "https://openalex.org/W6843589712",
    "https://openalex.org/W6794797104",
    "https://openalex.org/W4312705088",
    "https://openalex.org/W6850239468",
    "https://openalex.org/W4323922813",
    "https://openalex.org/W3214982047",
    "https://openalex.org/W6768156624",
    "https://openalex.org/W6639102338",
    "https://openalex.org/W6788931046",
    "https://openalex.org/W6783235222",
    "https://openalex.org/W3134026309",
    "https://openalex.org/W6787853842",
    "https://openalex.org/W6620707391",
    "https://openalex.org/W6805508905",
    "https://openalex.org/W6783307742",
    "https://openalex.org/W6691468707",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W6757068625",
    "https://openalex.org/W6801390177",
    "https://openalex.org/W6811107092",
    "https://openalex.org/W6781547866",
    "https://openalex.org/W6766406184",
    "https://openalex.org/W6747769535",
    "https://openalex.org/W6746706695",
    "https://openalex.org/W2612146718",
    "https://openalex.org/W3001555892",
    "https://openalex.org/W4378499195",
    "https://openalex.org/W4297749157",
    "https://openalex.org/W2593581739",
    "https://openalex.org/W4283798518",
    "https://openalex.org/W2970231061",
    "https://openalex.org/W4393153766",
    "https://openalex.org/W4255556797",
    "https://openalex.org/W4236965008",
    "https://openalex.org/W4289126595",
    "https://openalex.org/W4386185158",
    "https://openalex.org/W4362597616",
    "https://openalex.org/W3131970643",
    "https://openalex.org/W3104529101",
    "https://openalex.org/W2963263347",
    "https://openalex.org/W3094502228",
    "https://openalex.org/W3142041998",
    "https://openalex.org/W4312747027",
    "https://openalex.org/W4385015470",
    "https://openalex.org/W2518103058",
    "https://openalex.org/W3023458288",
    "https://openalex.org/W2896457183"
  ],
  "abstract": "In the field of autonomous vehicles (AVs), accurately discerning commander intent and executing linguistic commands within a visual context presents a significant challenge. This paper introduces a sophisticated encoder-decoder framework, developed to address visual grounding in AVs. Our Context-Aware Visual Grounding (CAVG) model is an advanced system that integrates five core encoders—Text, Emotion, Image, Context, and Cross-Modal—with a multimodal decoder. This integration enables the CAVG model to adeptly capture contextual semantics and to learn human emotional features, augmented by state-of-the-art Large Language Models (LLMs) including GPT-4. The architecture of CAVG is reinforced by the implementation of multi-head cross-modal attention mechanisms and a Region-Specific Dynamic (RSD) layer for attention modulation. This architectural design enables the model to efficiently process and interpret a range of cross-modal inputs, yielding a comprehensive understanding of the correlation between verbal commands and corresponding visual scenes. Empirical evaluations on the Talk2Car dataset, a real-world benchmark, demonstrate that CAVG establishes new standards in prediction accuracy and operational efficiency. Notably, the model exhibits exceptional performance even with limited training data, ranging from 50% to 75% of the full dataset. This feature highlights its effectiveness and potential for deployment in practical AV applications. Moreover, CAVG has shown remarkable robustness and adaptability in challenging scenarios, including long-text command interpretation, low-light conditions, ambiguous command contexts, inclement weather conditions, and densely populated urban environments.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7967910766601562
    },
    {
      "name": "Robustness (evolution)",
      "score": 0.5431460738182068
    },
    {
      "name": "Context (archaeology)",
      "score": 0.49129122495651245
    },
    {
      "name": "Adaptability",
      "score": 0.463113933801651
    },
    {
      "name": "Modal",
      "score": 0.4502134919166565
    },
    {
      "name": "Process (computing)",
      "score": 0.431879460811615
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4118184745311737
    },
    {
      "name": "Human–computer interaction",
      "score": 0.34886348247528076
    },
    {
      "name": "Programming language",
      "score": 0.09963089227676392
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Ecology",
      "score": 0.0
    },
    {
      "name": "Polymer chemistry",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    }
  ]
}