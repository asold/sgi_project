{
  "title": "A Language Modeling Approach to Sentiment Analysis",
  "url": "https://openalex.org/W1591450302",
  "year": 2007,
  "authors": [
    {
      "id": "https://openalex.org/A275320758",
      "name": "Yi Hu",
      "affiliations": [
        "Shanghai Jiao Tong University"
      ]
    },
    {
      "id": "https://openalex.org/A2155422635",
      "name": "Ruzhan Lu",
      "affiliations": [
        "Shanghai Jiao Tong University"
      ]
    },
    {
      "id": "https://openalex.org/A2099351229",
      "name": "Xuening Li",
      "affiliations": [
        "Shanghai Jiao Tong University",
        "Jiangnan University"
      ]
    },
    {
      "id": "https://openalex.org/A2097224230",
      "name": "Yuquan Chen",
      "affiliations": [
        "Shanghai Jiao Tong University"
      ]
    },
    {
      "id": "https://openalex.org/A2110538932",
      "name": "Jianyong Duan",
      "affiliations": [
        "Shanghai Jiao Tong University"
      ]
    },
    {
      "id": "https://openalex.org/A275320758",
      "name": "Yi Hu",
      "affiliations": [
        "Shanghai Jiao Tong University"
      ]
    },
    {
      "id": "https://openalex.org/A2155422635",
      "name": "Ruzhan Lu",
      "affiliations": [
        "Shanghai Jiao Tong University"
      ]
    },
    {
      "id": "https://openalex.org/A2099351229",
      "name": "Xuening Li",
      "affiliations": [
        "Shanghai Jiao Tong University"
      ]
    },
    {
      "id": "https://openalex.org/A2097224230",
      "name": "Yuquan Chen",
      "affiliations": [
        "Shanghai Jiao Tong University"
      ]
    },
    {
      "id": "https://openalex.org/A2110538932",
      "name": "Jianyong Duan",
      "affiliations": [
        "Shanghai Jiao Tong University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2114524997",
    "https://openalex.org/W2166706824",
    "https://openalex.org/W2099111195",
    "https://openalex.org/W1934041838",
    "https://openalex.org/W2089065004",
    "https://openalex.org/W2155328222",
    "https://openalex.org/W2168625136",
    "https://openalex.org/W4240913316",
    "https://openalex.org/W2143969069",
    "https://openalex.org/W2162095731",
    "https://openalex.org/W1604938182",
    "https://openalex.org/W2136542423",
    "https://openalex.org/W1576520375",
    "https://openalex.org/W1848260039",
    "https://openalex.org/W2937343401",
    "https://openalex.org/W2158195707",
    "https://openalex.org/W3146306708"
  ],
  "abstract": null,
  "full_text": "Y. Shi et al. (Eds.): ICCS 2007, Part II, LNCS 4488, pp. 1186–1193, 2007. \n© Springer-Verlag Berlin Heidelberg 2007 \nA Language Modeling Approach to Sentiment Analysis \nYi Hu1, Ruzhan Lu1, Xuening Li1,2, Yuquan Chen1, and Jianyong Duan1 \n1 Department of Computer Science and Engineering  \nShanghai Jiao Tong University, Shanghai, China \n2 School of Foreign Studies \nSouthern Yangtze University, Wuxi, China \n{huyi, lu-rz, xuening_li, yqchen, duan_jy}@cs.sjtu.edu.cn \nAbstract. This paper presents a language modeling approach to the sentiment \ndetection problem. It captures the subtle information in text processing to char-\nacter the semantic orientation of documents as “thumb up” (positive) or “thumb \ndown” (negative). To handle this problem, we propose an idea to estimate both \nthe positive and negative language models from training collections. Tests are \ndone through computing the Kullback-Leibler divergence between the language \nmodel estimated from test document and these two trained sentiment models. \nWe assert the polarity of a test document by observing whether its language \nmodel is close to the trained “thumb up” model or the “thumb down” model. \nWhen compared with an outstanding classifier, i.e., SVMs on movie review \ncorpus, language modeling approach showed its better performance.  \nKeywords: Sentiment Analysis; Language Modeling; KL-divergence. \n1   Introduction \nTraditional attention to document categorization lies in mapping a document to given \ntopics such as sport, finance and politics [4]. Whereas, recent years have seen a grow-\ning interest in non-topical analysis, in wh ich characterizations are sought of the opin-\nions and feelings depicted in documents, rather than just their themes. The problem \nclassifying a document as “thumb up” (positive) or “thumb down” (negative) is called \nsentiment classification.  Labeling documents by such semantic orientations would \nprovide succinct summaries and would be great useful in many intelligent information \nsystems. Its immediate applications include mining webs and blocking junk mails.  \nSentiment classification has become a hot direction for its broad applications, \nwhich has been attempted in different domains such as movie reviews, product re-\nviews, and customer feedback reviews [1][2][6][8]. Some researchers have taken \npositive or negative word/phrase counting methods into account and determining if a \nword/phrase is positive or negative [9]. Other methods classify whole documents into \npositive and negative by employing machine-learning algorithms. Several learning \nalgorithms are compared in [2] where it found that Support Vector Machines (SVMs) \ngenerally give better results. Their work shows that, generally, these algorithms are \nnot able to achieve accuracies on sentimen t classification comparable to those re-\nported for standard topic-based categorization. The reason exists in many challenging \n A Language Modeling Approach to Sentiment Analysis 1187 \naspects in this task. Intuitively, feelings in natural language are very often expressed \nin subtle and complex ways, which usually needs knowledge to deal with.  \nThis paper presents a language modeling approach to analyze documents as posi-\ntive or negative, which emphasizes on suitably estimating the “thumb up” and “thumb \ndown” language models from training sets, and evaluating a test document repre-\nsented with a language model via its distance from the two sentiment models. We also \ntry SVMs, a powerful discriminative model, for this sentiment analysis. \nThe rest of the paper is organized as follows. Our method is formalized in Section 2. \nSection 3 follows with a description of preliminary experiments, and section 4 gives \nthe conclusion. Note that this paper discusses an ongoing work and provides the \nframework of our idea and initial results, rather than a complete solution. \n2   Language Modeling Approach to Sentiment Classification \nIn this section, we propose a language modeling approach to detecting semantic orien-\ntation in document. The motivation is very simple: the “thumb up” and “thumb down” \nlanguages are likely to be substantially different, i.e. they prefer to different language \nhabits. We exploit this divergence in the language models to classify test document.  \nThe “thumb up” orientation is represented with a positive language model Pθ  that \nis a probability distribution over n-grams in positive collection. Accordingly, a nega-\ntive language model Nθ  represents the language model for “thumb down” orientation. \nA test document generates a language model dθ . Note that a language model is a \nstatistical model: probability distribution over language units, indicating the likeli-\nhood of observing these units in a language. Therefore a document can then compare \nits model with “thumb up” or “thumb down” model using distance mechanism: \n                    0\" \"(; , ) ( , ) ( , ) : 0\" \"\nPN dP dN\nthumb updD i s D i s thumb downϕθ θ θ θ θ θ <⎧=− ⎨>⎩\n.             (1) \nWhere Dis(p,q) is the distance between two distributions p and q. This formula ex-\npresses the classifying idea that if (, )dPDis θθ is smaller than (, )dNDis θθ , it means the \ntest document d is closer to “thumb up”. Otherwise, if (, )dPDis θθ is greater than \n(, )dNDis θθ , “thumb down”. Note that if (; , ) PNdϕ θθ equals to zero, the test document \nis regarded as “neutral”, but this case has not been discussed in our work. Next sub-\nsection, we exploit the Kullback-Leibler Divergence as the distance measure.  \n2.1   Using Kullback-Leibler Divergence for Sentiment Classification \nGiven two probability mass functions ()px  and ()qx , (| |)Dp q , the Kullback-Leibler \ndivergence (or relative entropy) between p and q is defined as \n                                            ()(| |) ( ) l o g ()x\npxDp q px qx\n⎛⎞= ⎜⎟⎝⎠∑ .                                           (2) \n1188 Y. Hu et al. \nIt is easy to show that (| |)Dp q  is always non-negative and is zero if and only if \npq= . Even though it is not a true distance between distributions because it is not \nsymmetric and does not satisfy the triangle inequality, it is still often useful to think of \nthe KL-divergence as a “distance” between distributions [3]. Formally, the KL-\ndivergence between probability distributions dθ  and Pθ / Nθ  is calculated by: \n                       \nˆPr( | )ˆˆ ˆ(| |) P r ( |) l o g ˆPr( | )\nˆPr( | )ˆˆ ˆ(| | ) P r ( |) l o g ˆPr( | )\nd\ndP d\nng r a m P\nd\ndN d\nng r a m N\nng r a mD n gram\nng r a m\nng r a mD n gram\nng r a m\nθθθ θ\nθ\nθθθ θ\nθ\n−\n−\n⎧ ⎛⎞ −=−⎪ ⎜⎟⎜⎟ −⎪ ⎝⎠⎨ ⎛⎞ −⎪ =− ⎜⎟⎪ ⎜⎟ −⎝⎠⎩\n∑\n∑\n.                  (3) \nWhere ˆθ  is the estimated model for the real θ  and ˆPr( | )ng r a m θ−  is the probability of \nn-gram given the estimated model ˆθ . \nOnce we have a language models to represent test document and a score based on \nits distance to the two sentiment language models, we classify the test document as \n“thumb up” or “thumb down”. Finally, substituting equation (3) into equation (1) we \nhave a new sentiment classifying function: \n                            \nˆ ˆ ˆˆ ˆˆ( ;,) (| |) (| | )\nˆPr( | )ˆPr( | )log ˆPr( | )\nP N dP dN\nN\nd\nng r a m P\ndDD\nng r a mng r a m\nng r a m\nϕθ θ θ θ θ θ\nθθ\nθ−\n=−\n⎛⎞ −=− ⎜⎟⎜⎟ −⎝⎠\n∑\n.                     (4) \nIn this study, we only employ word-based unigrams and bigrams as model parame-\nters. Because of the data sparseness problem, higher order n-grams (n >= 3) have not \nbeen discussed, even if the higher order n-grams might approximate the true language \nmodel in theory. But it is possible to use n-grams of higher orders in the same frame-\nwork. In general, the computation of the above formula involves a sum over all the n-\ngrams that have a non-zero probability according to ˆPr( | )ng r a m θ− . However, when ˆθ  \nis based on certain general smoothing technique, the computation would assign a non-\nzero probability to unseen n-gram according to ˆPr( | ) smoothng r a m θ− . We also observe \nthe smoothing effect in language modeling of sentiment. \n2.2   Estimation for Model Parameters \nUsually, the real language models ( Pθ  and Nθ ) are unknown. They are estimated by \ntraining from two available collections labeled with “positive” and “negative” to ob-\ntain ˆ\nPθ  and ˆ\nNθ , respectively. ˆ\ndθ  has the similar meaning.  \nFor investigating the ability of language modeling approach, we use two methods \nto estimate the unigrams and bigrams distribution: <1> the Maximum Likelihood \nEstimate (MLE); <2> the smoothing estimation for these three language models.  \n \nMLE for Unigrams and Bigrams \nMLE is used widely for model estimate, so we directly give the formula (5) and  \nsimply analyze it as follows. \n A Language Modeling Approach to Sentiment Analysis 1189 \n                  \n1\n1\n1\n#( \" \")Pr ( | \" \") #( \" \")\n#( \" \")Pr ( | , \" \") #( \" \")\ni\nML i\nii\nML i i\ni\nwi n sw s s {d,P,N} for unigramin s\nww i nsw w s s {d,P,N} for bigramwi n s\n−\n−\n−\n⎧ =∈⎪ ∗⎪⎨\n⎪ =∈⎪ ∗⎩\n.           (5) \n \nWhat we have to explain in (5) is the “s”, which can represent a test document (d), the \n“thumb up” collection ( P) or the “thumb down” collection ( N). The #( )ng r a m−  de-\nnotes the n-gram  occurring times in corresponding collection ( d, P or N), and “*” \ndenotes any word. The meanings of these characters are fixed in the rest of this paper. \nThe maximum likelihood estimate is an unreasonable one when the amount of \ntraining data is small compared to the mode l size. It is clearly inaccurate to assign \nzero probability to unseen n-grams. The smoothing describes techniques for adjusting \nthe maximum likelihood estimate to hopefully produce more accurate models. \n \nDirichlet Prior Smoothing for Unigram \nDirichlet Prior smoothing [10][12] is a linearly interpolated method to the problem of \nzero probabilities and suitable for unigrams  smoothing. Its purpose is to address the \nestimation bias due to the fact that a document collection is a relatively small amount \nof data with which to estimate a unigram model. More specifically, it is to discount \nthe MLE appropriately and assign non-zero probabilities to n-grams not observed in \ncollection. In terms of unigram model, the smoothing estimation is \n                       Pr ( |\" \")P r(| \" \" ) Pr ( | )\nDP\nsM L\nws i f w o r d w i s s e e nws wC o t h e r w i s e\nγ\nα\n⎧= ⎨\n⎩\n.                               (6) \n \nWhere Pr ( | \" \")wsγ  is the smoothed probability of w seen in the  collection represented \nwith “s”. Pr ( | )ML wC  is the whole corpus ( C ) language model based on MLE, and sα  \nis a coefficient controlling the probability mass assigned to unseen words, so that all \nprobabilities sum to one. In general, sα  may depend on “ s”. In this study, we exploit \nthe following smoothing formalization,  \n                                 #( \" \") Pr ( | )Pr ( |\" \") #( \" \")\nMLwi n s w Cws in s\nγ\nμ\nμ\n+= ∗+\n,                              (7) \nand  \n                                                     .||\ns\nC\nμα μ= +\n                                                     (8) \nAlthough Dirichlet Prior smoothing is valid in many NLP tasks, in the sentiment \nclassification of movie review corpus, it only give slight improvement to simple MLE \n(see the experiment section). \n \nKenser-Ney Smoothing for Bigram \nKneser and Ney [5] have introduced an exte nsion of absolute discounting where the \nlower-order distribution that one combines with a higher-order distribution built in a \nnovel manner. To their consideration, a lower-order distribution is a significant factor \n1190 Y. Hu et al. \nin the combined model only when few or no counts are present in the higher-order \ndistribution. Following Kneser-Ney smoothing, Stanley F. Chen and Joshua Goodman \n[10] mathematically motivate Kneser and Ney’s algorithm by selecting the lower-\norder distribution such that the marginal of the higher-order smoothed distribution \nmatch the marginal of the training data. Then the Kneser-Ney smoothing performs \nbest compared with other smoothing techniques when given different conditions [10].  \nTo a bigram model, Chen et al select a smoothed distribution PrKN that satisfies the \nfollowing constraint on unigram marginals for all wi: \n                                       \n1\n1\n#( )Pr ( ) #( )i i\ni\nKN i i\nw iw\nwww w−\n− =∑ ∑\n.                                                 (9) \nThe left-hand side of this equation is the unigram marginal for wi of the smoothed \nbigram distribution PrKN , and the right-hand side is the MLE of wi found in the train-\ning data. Therefore, to our smoothing, we assume that the bigram model has the form \ngiven in Equation (10), \n1\n1 11\n11\nmax{#( ) , 0}Pr ( | , \" \") ( ) Pr ( ), \" \" #( ) #( )\nii\nii\nKN i i iK N i\nii iiww\nww D Dww s N w w t os ww ww\n−\n− +−\n−−\n−=+\n∑∑\ni . (10) \nIn equation (10), D is the fixed discount from observed  bigrams and 1\n12 2\nnD nn= +\n by \nNey’s suggestion. Moreover,  \n                                               1\n11\n()Pr ( ) ()\ni\nKN i\ni\nNww Nw\n+\n+−\n= i\nii\n.                                               (11) \nFor all the meanings of character such as D, N1+, n 1 and n 2, readers can refer to \nKneser and Chen’s papers[5][10]. \n3   Document Set and Experiments \nTurney [7][8] found movie reviews to be the most difficult of several domains for \nsentiment classification task, reporting an accuracy of 65.83% on a 120-document set \n(random-choice baseline: 50%). Herein lies the reason we chose movie reviews for \nstudy, and our data source was the Internet Movie Database (IMDB) archive of the \nrec.arts.movies.reviews newsgroup that is adopted in Pang’s work [2]. The datasets \nselected only reviews where the author rating was expressed either with stars or some \nnumerical value. Ratings were extracted and converted into one of two categories: \npositive (thumb up) and negative (thumb down). \nTo avoid domination of the corpus by a small number of prolific reviewers, the \ncorpus imposed a limit of fewer than 20 reviews per author per sentiment category, \nyielding a corpus of 1000 negative and 1000 positive reviews, with a total of more \nthan a hundred reviewers represented. Note that all these original documents were \npreprocessed by stemming and stop-word removal in our work.  \nWe designed two experiments to investigate SVM and our method. The first was to \nselect the most suitable kernel from linear, polynomial, RBF and sigmoid kernels for \n A Language Modeling Approach to Sentiment Analysis 1191 \nsentiment classification. The second was to compare the performance between our \nmethod and SVMs. In order to see fair play, all the following experiments selected the \nfeatures based on word unigrams and bigrams occurring more than 2 times in the \n2,000 reviews. The value of a feature is its appearing number.  \nWith respect to the two experiments, we split the 2000 movie reviews into 1200 \ntraining samples (600 positive and 600 negative) and 800 test samples (400 positive \nand 400 negative), and they were both evaluated in average accuracy based on 3-fold \ncross validation.  \n \nSVMs Experiment \nWe extracted two kinds of input feature sets for SVMs, i.e., unigrams and bigrams. \nThe following experiments compared the performance of SVMs using linear, poly-\nnomial, RBF and sigmoid kernels, four conventional learning methods commonly \nused for text categorization. We used Joachim’s SVMlight package [11] for training and \ntesting, and other parameters to different kernel functions set to their default values in \nthis package. This experiment aimed at seeing which one is more suitable for the \nsentiment detection problem. Table 1 outlines the different results of SVMs on the \nIDMB corpus when different kernel functions are used.  \nTable 1. Comparison of four kernel functions on the IDMB training and test sets. Linear kernel \nachieved highest performance on both unigram and bigram features for categorization. \nFeatures # of features Linear Polynomial Radial Basis Function Sigmoid \nunigrams 13693 78.21 59.59 50.09 49.25 \nbigrams 18602 73.42 51.46 51.19 62.00 \nThe best results on the two feature sets come from the SVM using linear kernel. \nOur language model based method is compared with the SVM using linear kernel. \n \nLanguage Modeling Approach Experiment \nWe evaluated the language modeling approach described in section 2 on IMDB col-\nlections. As mentioned above, we used unigrams and bigrams models for evaluation. \nTable 2 is the experiment result. \nTable 2. Comparison between language modelling approach and SVMs \nFeatures # of fea-\ntures \nLM-MLE LM-Smoothing SVMlight \n (linear kernel) \nunigrams 13693 Uni-MLE 82.02 Uni-DP 84.13 78.21 \nbigrams 18602 Bi-MLE 61.62  Bi-KN 73.80 73.42 \nUni-DP (the smoothed unigram model) performed the best globally on unigrams fea-\ntures set in Table 2, which achieved an average significant improvement of +7.57% \ncompared to the best SVM result. What surprised us is that the simple Uni-MLE \ncould also perform better than SVM-Uni did. On the other hand, the experiment on \n1192 Y. Hu et al. \nbigram features showed that the best result of language modeling approach (Bi-KN) \nwas close to the result of SVM and the performance of Bi-MLE was poor.  \nWith respect to the effect of smoothing  technique: <1> Dirichlet Prior smoothed \nunigram model with parameter u set to 450 (In our experiment, the best result ap-\npeared when we set u = 450). Uni-DP performed well for the sentiment classification \ntask but it only slightly improved the performance of Uni-MLE (+2.57%).  Although \nthe model based on MLE was inherently poorly estimated, it was not clear that the \nsimple model must be smoothed since the improvement was limited. This phenome-\nnon let us consider that it might be better to find a way of paying more attention to \nsome sensitive concepts to achieve better performance for sentiment classification. \n<2> Kneser-Ney method smoothed bigram model based on an absolute discount idea, \nand it did great contribution to estimate a better bigram model leading to a signifi-\ncantly better result than MLE (+19.77%). It obtained the comparable performance to \nSVM. The reason might be depicted as: in theory, the higher order n-gram model \nreadily approximates the true language model, but for data sparseness, a powerful \nsmoothing mechanism could provide apparent contribution. \n4   Conclusion \nIn this paper, we have presented a new method based on language model for senti-\nment classification. With respect to this generative sentiment classifier, we represent \nthe “thumb up” and “thumb down” semantic orientation with their corresponding \nlanguage models estimated from positive and negative collections. When classifying a \ntest document, the distances of its language model from these two sentiment models \nare compared to determine its sentiment class. \nCompared with SVMs, we might conclude as follows in terms of our experimental \nresults: to sentiment classification, when training data is limited, the smoothed low \norder model, i.e., the unigram model can globally do the best. On the other hand, \nsmoothing technique does great contribution to higher order model that can also \nachieve comparable performance to SVMs. \nThe experiments showed the potential power of language modeling approach in \nthis task. We demonstrate that our generative sentiment classifier is applicable by \nlearning the positive and negative semantic orientation efficiently in the supervised \nmanner. This seems to indicate the promising future of language modeling approach \nfor the sentiment detection problem. On the other hand, we stress that the approaches \nwe use are not specific to movie reviews, an d it should be easily applicable to other \ndomains when given training data. \nThe difficulty of sentiment classification is apparent: negative reviews may contain \nmany apparently positive n-grams even while maintaining a strongly negative tone, \nand the opposite is also common. All classifiers will face this difficulty. To the lan-\nguage modeling approach, our future work will focus on finding a good way to esti-\nmate better language models, especially the higher order n-gram  models by introduc-\ning semantic link between n-grams. \n \nAcknowledgement. This work is supported by NSFC Major Research Program \n60496326: Basic Theory and Core Techniques of Non Canonical Knowledge. \n A Language Modeling Approach to Sentiment Analysis 1193 \nReferences \n1. Bo Pang and Lillian Lee: A Sentimental Education: Sentiment Analysis Using Subjectivity \nSummarization Based on Minimum Cuts. In: Proc. of the 42nd ACL. (2004) 271-278 \n2. Bo Pang, Lillian Lee and Shivakumar Vaithyanathan: Thumbs up? Sentiment Classifica-\ntion using Machine Learning Techniques. In: Proc. Conf. on EMNLP. (2002) \n3. Cover, T. M. and Thomas, J. A.: Elements of Information Theory. Wiley. (1991) \n4. Hearst, M.A.: Direction-based text interpretation as an information access refinement. In \nP. Jacobs (Ed.), Text-Based Intelligent Systems: Current Research and Practice in Infor-\nmation Extraction and Retrieval. Mahwah, NJ: Lawrence Erlbaum Associates. (1992) \n5. Kneser,R. & Ney,H: Improved backing-off for m-gram language modeling. In: Proc. of the \nIEEE Internaltional Conference on Acoustics, Speech and Signal Processing, Detroit, \nMI,volume 1. May, (1995) 181-184 \n6. Michael Gamon: Sentiment classification on customer feedback data: noisy data, large fea-\nture vectors, and the role of linguistic analysis. In: Proc. the 20th International Conference \non Computational Linguistics. (2004) \n7. Peter D. Turney: Thumbs up or thumbs down? Semantic orientation applied to unsuper-\nvised classification of reviews. In: Proc. of the ACL. (2002) \n8. Peter D. Turney and Michael L. Littman: Measuring praise and criticism: Inference of se-\nmantic orientation from association. ACM Transactions on Information Systems (TOIS). \n21(4), (2003), 315-346 \n9. Peter D. Turney and Michael L. Littman: Unsupervised learning of semantic orientation \nfrom a hundred-billion-word corpus. Technical Report EGB-1094, National Research \nCouncil Canada. (2002) \n10. S. F. Chen and J. T. Goodman: An Empirical Study of Smoothing Techniques for Lan-\nguage Modeling. Technical Report: TR-10-98, Harvard University. (1998) \n11. Thorsten Joachims: Making large-scale SVM learning practical. In Bernhard Scholkopf \nand Alexander Smola, editors, Advances in Kernel Methods - Support Vector Learning, \nMIT Press. (1999) 44–56 \n12. Zhai, C. and Lafferty, J.: A study of smoothing methods for language models applied to ad \nhoc information retrieval. In Proc. of SIGIR’2001. (2001) ",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8743171691894531
    },
    {
      "name": "Language model",
      "score": 0.7068500518798828
    },
    {
      "name": "Artificial intelligence",
      "score": 0.653915524482727
    },
    {
      "name": "Natural language processing",
      "score": 0.6399259567260742
    },
    {
      "name": "Sentiment analysis",
      "score": 0.6079328060150146
    },
    {
      "name": "Rule of thumb",
      "score": 0.6054744720458984
    },
    {
      "name": "Classifier (UML)",
      "score": 0.5216115713119507
    },
    {
      "name": "Thumb",
      "score": 0.4426955580711365
    },
    {
      "name": "Machine learning",
      "score": 0.3625481426715851
    },
    {
      "name": "Algorithm",
      "score": 0.12510985136032104
    },
    {
      "name": "Anatomy",
      "score": 0.0
    },
    {
      "name": "Medicine",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I183067930",
      "name": "Shanghai Jiao Tong University",
      "country": "CN"
    }
  ]
}