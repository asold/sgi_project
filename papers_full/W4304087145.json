{
    "title": "TFF-Former: Temporal-Frequency Fusion Transformer for Zero-training Decoding of Two BCI Tasks",
    "url": "https://openalex.org/W4304087145",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2909411850",
            "name": "Xujin Li",
            "affiliations": [
                "Institute of Automation",
                "University of Chinese Academy of Sciences"
            ]
        },
        {
            "id": "https://openalex.org/A1947499342",
            "name": "Wei Wei",
            "affiliations": [
                "Institute of Automation"
            ]
        },
        {
            "id": "https://openalex.org/A2097688741",
            "name": "Shuang Qiu",
            "affiliations": [
                "University of Chinese Academy of Sciences",
                "Institute of Automation"
            ]
        },
        {
            "id": "https://openalex.org/A2124591032",
            "name": "Huiguang He",
            "affiliations": [
                "Institute of Automation",
                "University of Chinese Academy of Sciences"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2106006415",
        "https://openalex.org/W2137049752",
        "https://openalex.org/W1975194708",
        "https://openalex.org/W2068562173",
        "https://openalex.org/W2163027455",
        "https://openalex.org/W2177405552",
        "https://openalex.org/W2168572392",
        "https://openalex.org/W2132876794",
        "https://openalex.org/W2903567258",
        "https://openalex.org/W6697529478",
        "https://openalex.org/W2568518072",
        "https://openalex.org/W6636442617",
        "https://openalex.org/W2163605009",
        "https://openalex.org/W2150590430",
        "https://openalex.org/W2238628508",
        "https://openalex.org/W3102455230",
        "https://openalex.org/W2808255765",
        "https://openalex.org/W3086896457",
        "https://openalex.org/W3017080928",
        "https://openalex.org/W3149679044",
        "https://openalex.org/W2143183535",
        "https://openalex.org/W1844272693",
        "https://openalex.org/W2151297119",
        "https://openalex.org/W2605492512",
        "https://openalex.org/W2792885690",
        "https://openalex.org/W3098199041",
        "https://openalex.org/W6763367864",
        "https://openalex.org/W3164024107",
        "https://openalex.org/W2947476638",
        "https://openalex.org/W4220891365",
        "https://openalex.org/W2553904372",
        "https://openalex.org/W2531409750",
        "https://openalex.org/W3186148480",
        "https://openalex.org/W4226175289",
        "https://openalex.org/W4206694574",
        "https://openalex.org/W4205558134",
        "https://openalex.org/W4226187087",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W4298395628",
        "https://openalex.org/W4403736933"
    ],
    "abstract": "Brain-computer interface (BCI) systems provide a direct connection between the human brain and external devices. Visual evoked BCI systems including Event-related Potential (ERP) and Steady-state Visual Evoked Potential (SSVEP) have attracted extensive attention because of their strong brain responses and wide applications. Previous studies have made some breakthroughs in within-subject decoding algorithms for specific tasks. However, there are two challenges in current decoding algorithms in BCI systems. Firstly, current decoding algorithms cannot accurately classify EEG signals without the data of the new subject, but the calibration procedure is time-consuming. Secondly, algorithms are tailored to extract features for one specific task, which limits their applications across tasks. In this study, we proposed a Temporal-Frequency Fusion Transformer (TFF-Former) for zero-training decoding across two BCI tasks. EEG data were organized into temporal-spatial and frequency-spatial forms, which can be considered as two views. In the TFF-Former framework, two symmetrical Transformer streams were designed to extract view-specific features. The cross-view module based on the cross-attention mechanism was proposed to guide each stream to strengthen common representations of features across EEG views. Additionally, an attention-based fusion module was built to fuse the representations from the two views effectively. The mean mask mechanism was applied to adaptively decrease redundant EEG tokens aggregation for the integration of common representations. We validated our method on the self-collected RSVP dataset and benchmark SSVEP dataset. Experimental results demonstrated that our TFF-Former model achieved competitive performance compared with models in each of the above paradigms. It can further promote the application of visual evoked EEG-based BCI system.",
    "full_text": null
}