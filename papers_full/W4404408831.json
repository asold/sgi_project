{
  "title": "Agentic AI for Streamlining Title and Abstract Screening: Addressing Precision and evaluating calibration of AI guardrails",
  "url": "https://openalex.org/W4404408831",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2765477022",
      "name": "T Disher",
      "affiliations": []
    },
    {
      "id": null,
      "name": "G Janoudi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2140682150",
      "name": "M. Rada",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2765477022",
      "name": "T Disher",
      "affiliations": []
    },
    {
      "id": null,
      "name": "G Janoudi",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4213127247",
    "https://openalex.org/W4402335544",
    "https://openalex.org/W4392791588",
    "https://openalex.org/W2942625760",
    "https://openalex.org/W4404396608"
  ],
  "abstract": "1. Abstract Background Title and abstract (TiAb) screening in systematic literature reviews (SLRs) is labor-intensive. While agentic artificial intelligence (AI) platforms like Loon Lens 1.0 offer automation, lower precision can necessitate increased full-text review. This study evaluated the calibration of Loon Lens 1.0’s confidence ratings to prioritize citations for human review. Methods We conducted a post-hoc analysis of citations included in a previous validation of Loon Lens 1.0. The data set consists of records screened by both Loon Lens 1.0 and human reviewers (gold standard). A logistic regression model predicted the probability of discrepancy between Loon Lens and human decisions, using Loon Lens confidence ratings (Low, Medium, High, Very High) as predictors. Model performance was assessed using bootstrapping with 1000 resamples, calculating optimism-corrected calibration, discrimination (C-index), and diagnostic metrics. Results Low and Medium confidence citations comprised 5.1% of the sample but accounted for 60.6% of errors. The logistic regression model demonstrated excellent discrimination (C-index = 0.86) and calibration, accurately reflecting observed error rates. “Low” confidence citations had a predicted probability of error of 0.65 (95% CI: 0.56-0.74), decreasing substantially with higher confidence: 0.38 (95% CI 0.28-0.49) for “Medium”, 0.05 (95% CI 0.04-0.07) for “High”, and 0.01 (95% CI 0.007-0.01) for “Very High”. Human review of “Low” and “Medium” confidence abstracts would lead to improved overall precision from 62.97% to 81.4% while maintaining high sensitivity (99.3%) and specificity (98.1%). Conclusions Loon Lens 1.0’s confidence ratings show good calibration used as the basis for a model predicting the probability of making an error. Targeted human review significantly improves precision while preserving recall and specificity. This calibrated model offers a practical strategy for optimizing human-AI collaboration in TiAb screening, addressing the challenge of lower precision in automated approaches. Further research is needed to assess generalizability across diverse review contexts.",
  "full_text": null,
  "topic": "Calibration",
  "concepts": [
    {
      "name": "Calibration",
      "score": 0.7157965898513794
    },
    {
      "name": "Computer science",
      "score": 0.42831724882125854
    },
    {
      "name": "Psychology",
      "score": 0.4114413261413574
    },
    {
      "name": "Statistics",
      "score": 0.1086696982383728
    },
    {
      "name": "Mathematics",
      "score": 0.09812465310096741
    }
  ],
  "institutions": []
}