{
    "title": "New Reading Scenes : On Large Language Model and Machine Reading",
    "url": "https://openalex.org/W4410730477",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A2620087150",
            "name": "Katia Schwerzmann",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4234281577",
        "https://openalex.org/W4200312414",
        "https://openalex.org/W3144899131",
        "https://openalex.org/W4408706105",
        "https://openalex.org/W4405254412",
        "https://openalex.org/W4410730477"
    ],
    "abstract": null,
    "full_text": "26.05.2025\nblog.kulturwissenschaften.de/new-reading-scenes/\nNew Reading Scenes\nOn Large Language Model and Machine\nReading\nVon: Katia Schwerzmann\nReading – the foundational skill of the humanities – has been profoundly\ntransformed by the rise of digital media and the widespread digitization of texts.\nAlready in 2012, N. Katherine Hayles analyzed this transformation in depth in her\nbook How We Think: Digital Media and Contemporary Technogenesis.  Ever a\ngroundbreaking theorist of media, literature, and critical posthumanism, Hayles has\nsince continued to explore how humans and machines form what she calls a\n“cognitive assemblage” that challenges the idea of autonomous, self-possessed\nsubjectivity in processes of meaning-making.  Literary st udies scholar Julika Griem\nhas proposed to analyze these transformations by paying close attention to the\n“reading scene” or scenes where practices of reading are explicitly thematized in\nliterary texts and visual media. She proposes that this media reflexivity enables us\nto analyze the changing forms, valuations, and norms assigned to reading as a\ncultural practice.\nWhat new reading scenes emerge with the spread of large language models (LLMs)\nand the research practices that surround them? How is reading transformed in\nterms of modes, methods, but also valuations, when machines read for us, that is,\n“interpret” content, summarize texts, produce outlines, propose essay questions?\nWhat does the formatting of an LLM’s output – the breakdown of content in bullet\npoints, the use of bold typography to focus the reader’s attention on “what counts”\n(but counts following what norms?), the chat with a bot – do to our understanding\nand valuation of reading? What do we read of a text, a philosophical position, or a\nsource in a foreign language when we read it through machine reading? Is this\nreading through the machine a reading with the machine? In other words, do we\nform an assemblage of shared cognition, and are we co-constituting meaning when\nwe think and read through an LLM?\nOne is reminded of Friedrich Nietzsche, who, in 1882, chiselled away on his\nHansen Writing Ball the following words: “Unser Schreibzeug arbeitet mit an\nunseren Gedanken”  (“Our writing tool works with us at shaping our thoughts”).\nMartin Stingelin has pointed to this passage as one of the foundational “writing\nscenes” where the writer acknowledges how the machine contributes in a very\nembodied, material way, to co-shaping what they think and what they write.\n1\n2\n3\n4\n5\n1 von 5\nTransposing this to our current reading scene, are we still reading with the machine\nor have we started to read from it, such that we are nudged to align with the\ninterpretations that a model generates and the valuations attached to these\ninterpretations? And could we arrive at a point where we consider machine reading\n– reading from the machine – the default mode of what it means to read? Perhaps\nthis will not be the case for people who grew up learning to read independently of\nmodels. But what about the next generation?\nMany German Länder are currently introducing the use of LLMs in school for\nteaching and learning purposes.  I am convinced that LLMs will have a massive\nimpact on the ability to read and interpret texts and also to make sense of oral\ndiscourse. That is why I am sceptical about the introduction of these models in\neducational settings at a stage when children and adolescents are still learning how\nto read – grappling with how to parse information, how to interpret complex texts,\nand how to develop an awareness for the rhetorical dimension of language. The\nrationale behind this introduction, apart from clear economic interests, is that LLMs\nconstitute a chance as long as students learn how to use them “critically.”\nCritical thinking is the operative yet under-defined concept that does a lot of work in\nthe institutional positioning of schools and universities toward LLMs. Critical thinking\nfunctions as the safe-guard of students‘ autonomy, a value still considered essential\nin pedagogical settings. At the same time, it is expected that critical thinking toward\nAI does not hinder readiness to use the tools in order to optimally prepare students\nfor the job market. What does the reading scene look like in which students are\ntaught “critical thinking” towards LLMs’ outputs? What I have found so far is that\nactivities addressed to high-school students often consist in discovering the\ninaccuracies and errors that the model generated in response to a prompt. Students\nmay be for instance asked to compare AI output with information existing elsewhere\non the web or in books. In this reading scene, students are trained to become not\nthe active producer of meaning, of analysis, of arguments, but the evaluators,\nmodulators, improvers of AI models. These evaluations, modulations, and\nimprovements expected from the students are made on the basis of and thus\nremain determined by the kind of normative ration\nality that characterizes current AI.\nTwo clarifications: the first regards the question of the necessary expertise to\nproduce such an evaluation, while the second addresses the idea of LLMs as\nnormativizing machines.\nExpertise\nSerious output evaluation presupposes a degree of expertise that must be at least\nequal or superior to the “expertise” of the model. Without expertise, the reader of\nmodels’ output has to either systematically fact-check the entirety of the output or\ntake the model’s word for it. Additionally, the acquisition of the necessary expertise\nrests on the existence of an exteriority to the model. However, this exteriority, when\n6\n7\n2 von 5\nwe are thinking of the internet, is itself increasingly populated by synthetic content,\nthat is, content generated by AI models.\nSpeaking from my own experience, I have yet to get an output that does not contain\nhallucinations, errors, or inaccuracies. To mention but one example, I recently asked\nGPT to explain inflation from a Marxist perspective. The model first generated\nsomewhat unsurprisingly a supply-and-demand-based explanation. But even after\nthe third prompting/demand for correction, the model still couldn’t shift its “attention\nhead” to the location in its vector space containing what is apparently a very\nminoritized position: the Marxist theory of economy. This position couldn’t be\ngenerated either because it is highly minoritized in the dataset or because the\nmodel is fine-tuned to favor other explanations. This is not a kind of conspiracy\ntheory but the reality of model training. For instance, the Chinese model DeepSeek\nrefuses to address any question regarding the Cultural Revolution. One can expect\nthat the alignment of big tech companies with the Trump administration could have\nsimilar effects. The Trump administration has already proceeded to purge content\nrelated to diversity and climate change from many government websites.\nSimultaneously, LLMs are fine-tuned through reinforcement learning to repeat in an\napologetic and subservient tone that they always aim to generate content that is\n“neutral and balanced,” which is a misleading claim to say the least.\nLLMs as Normativizing Machines\nThis claim to neutrality must be challenged but not so much, as one might expect,\nby pointing to the existence of biases in AI models. Biases are, in fact, readily\nacknowledged by companies, which frame them both as a temporary issue and an\nopportunity to perform their version of liberalism, wherein every subject is said to\ndeserve equal representation, not so much in the eyes of society as in those of AI\nmodels. This framing conveniently offers companies a compelling justification to\ncollect even more data to fulfil their promise of neutrality.\nInstead, the claim to neutrality must be challenged by showing how it invisibilizes\nthe fact that LLMs and other generative AIs are essentially normativizing machines.\nThe inherent normativity of current AI marks a departure from earlier forms of rule-\nbased artificial intelligence that pertained to what historian Erickson and colleagues\nhave called in their book How Reason Almost Lost Its Mind “Cold War Rationality,” a\nrationality devoid of human judgement and interpretation – and thus considered\nparticularly apt to minimize uncertainty.  In contrast , current machine-learning-\nbased AI explicitly relies on the inte gration and automation of moral judgment,\nvaluation, and interpretation.  So w hen an LLM asserts that it aims to be neutral\nand balanced, it conceals not only the normative work going into the systematic\nproduction of this claim, which consists in reinforcement learning based on human\nevaluations; it also works at neutralizing the question of positionality, which has\nbeen a major epistemological contribution of feminist and postcolonial studies. The\nclaim to neutrality reveals current AI’s aspiration to produce a gaze from everywhere\n8\n9\n10\n3 von 5\nthat purports to emerge from reality itself, to map it in its totality, and in doing so, to\nneutralize positionality.\nIn the meantime, LLM-based machine reading is being used to fulfill evaluative\ntasks such as the automated assessment of resumes, job applications,  and more\nrecently college applications in the U.S., as well as the automated grading of\nstudents’ homework in German schools. If you want to successfully pass these\ntests, you had better make sure that your application materials reflect the statistical\nnorms and ethico-technical valuations of the LLM that will evaluate them.\nIn conclusion, I am convinced that reading scenes shaped around the praxis and\nvaluation of close reading will not disappear. On the contrary, close reading will\ncontinue to play an essential role in the critique of technology. However, the scene\nshould now include model outputs, the model’s chain-of-thought mechanism,\nresearch papers written by the machine learning community, and the logics of\ntechnology itself. Additionally, we need genealogies or histories that reveal the\ncontingency of technology’s current trajectory and its non-naturalness, and analyze\nthe specific valuations – in every sense of the word – that contribute to shaping its\ncourse.\n11\n12\n13\n14\nReferences\n1. Hayles, Katherine N. (2021): How W e Think: Digital Media and\nContemporary Technogenesis, Chicago: The University of Chicago Press.\n2. Hayles, Katherine N. (2017): Unthought: The Power of the Cognitive\nNonconscious, Chicago: The University of Chicago Press, https://\ndoi.org/10.7208/chicago/9780226447919.001.0001.\n3. Griem, Julika (2021): Szenen des Lesens: Schauplätze einer\ngesellschaftlichen Selbstverständigung, Bielefeld: transcript, https://\ndoi.org/10.1515/9783839458792.\n4. Cited in: Stingelin, Martin, Davide Giuriato and Sandro Zanetti (eds.) (2004):\n‚Mir ekelt vor diesem tintenklecksenden Säkulum‘: Schreibszenen im Zeitalter\nder Manuskripte, München: Fink, p. 8.\n5. Stingelin/Giuriato/Zanetti 2004.\n6. One of these tools is licensed by German startup Fobizz: https://fobizz.com/\nde/klassenraeume_ki/.\n7. A website provided by the Canton of Vaud in Switzerland (the canton in\nwhich I went to school and studied), offering pedagogical resources and\nguidelines on the use of generative AI https://www.eduvaud.ch/ressources/\nne-vous-fiez-pas-aux-reponses-dune-ia/ (Last Access: 24.04.2025).\n8. https://www.npr.org/sections/shots-health-news/2025/01/31/nx-s1-5282274/\ntrump-administration-purges-health-websites (Last Access: 24.04.2025).\n4 von 5\n9. Erickson, Paul et al. (20 13): How Reason Almost Lost Its Mind: The Strange\nCareer of Cold War Rationality, Chicago/London: The University of Chicago\nPress, https://doi.org/10.7208/chicago/9780226046778.001.0001.\n10. Schwerzmann, Katia and Alexander Campolo (2025): ‘Desired Behaviors’:\nAlignment and the Emergence of a Machine Learning Ethics”, in: AI &\nSociety, pp. 1–14, https://doi.org/10.1007/s00146-025-02272-3.\n11. Schwerzmann, Katia (2024): From Enclosure to Foreclosure and Beyond:\nOpening AI’s Totalizing Logic, Philpapers (Preprint), https://philpapers.org/\nrec/SCHFET-6 (Last Access: 24.04.2025).\n12. Gan, Chengguang, Qinghao Zhang and Tatsunori Mori (2024): Application of\nLLM Agents in Recruitment: A Novel Framework for Resume Screening, on:\narXiv, 13/08/2024, http://arxiv.org/abs/2401.08315 (Last Access: 24.04.2025).\n13. Mühlhoff, Rainer and Marte Henningsen (2025): Chatbots im Schulunterricht:\nWir testen das Fobizz-Tool zur automatischen Bewertung von\nHausaufgaben, on: arXiv, 21/01/2025, https://doi.org/10.48550/\nARXIV.2412.06651.\n14. The mechanism of “chain-of-thought” simulates “close reading” by dissecting\n(that is, literally analyzing) the user’s prompt in its simplest elements,\nenabling the model to tackle each of these successively. Wei, Jason et al.\n(2023): Chain-of-Thought Prompting Elicits Reasoning in Large Language\nModels, on: arXiv, 10/01/2023, http://arxiv.org/abs/2201.11903 (Last Access:\n07.05.2025).\nSUGGESTED CITATION: Schwerzmann, Katia: New Reading Scenes. On Large\nLanguage Model and Machine Reading, in: KWI-BLOG, [https://\nblog.kulturwissenschaften.de/new-reading-scenes/], 26.05.2025\nDOI: https://doi.org/10.37189/kwi-blog/20250526-0830\n5 von 5\nThis text is made available via DuEPublico, the institutional repository of the University of\nDuisburg-Essen. This version may eventually differ from another version distributed by a\ncommercial publisher.\nDOI:\nURN:\n10.37189/kwi-blog/20250526-0830\nurn:nbn:de:hbz:465-20250526-110002-5\nAll rights reserved."
}