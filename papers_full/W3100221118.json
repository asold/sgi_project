{
  "title": "Use of BERT (Bidirectional Encoder Representations from Transformers)-Based Deep Learning Method for Extracting Evidences in Chinese Radiology Reports: Development of a Computer-Aided Liver Cancer Diagnosis Framework",
  "url": "https://openalex.org/W3100221118",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A2109188315",
      "name": "Honglei Liu",
      "affiliations": [
        "Capital Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2113395567",
      "name": "Zhiqiang Zhang",
      "affiliations": [
        "Capital Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2098995436",
      "name": "Yan Xu",
      "affiliations": [
        "Beijing Friendship Hospital",
        "Capital Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2081369280",
      "name": "Ni Wang",
      "affiliations": [
        "Capital Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2111324523",
      "name": "Yanqun Huang",
      "affiliations": [
        "Capital Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2101615167",
      "name": "Zhenghan Yang",
      "affiliations": [
        "Capital Medical University",
        "Beijing Friendship Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2094922298",
      "name": "Rui Jiang",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2098099518",
      "name": "Hui Chen",
      "affiliations": [
        "Capital Medical University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2768488789",
    "https://openalex.org/W2993873509",
    "https://openalex.org/W2897360548",
    "https://openalex.org/W2750288184",
    "https://openalex.org/W2966351171",
    "https://openalex.org/W2917157846",
    "https://openalex.org/W2909707119",
    "https://openalex.org/W2946766957",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2978511610",
    "https://openalex.org/W2911462778",
    "https://openalex.org/W2963571188",
    "https://openalex.org/W3007060302",
    "https://openalex.org/W45588658",
    "https://openalex.org/W2953196299",
    "https://openalex.org/W2952100895",
    "https://openalex.org/W2056902052",
    "https://openalex.org/W2139054399",
    "https://openalex.org/W2563364981",
    "https://openalex.org/W2329011065",
    "https://openalex.org/W3023321484",
    "https://openalex.org/W3009459039",
    "https://openalex.org/W2943444949",
    "https://openalex.org/W2558253459",
    "https://openalex.org/W2969542839",
    "https://openalex.org/W2607074821",
    "https://openalex.org/W2797206252",
    "https://openalex.org/W3102251128"
  ],
  "abstract": "Background Liver cancer is a substantial disease burden in China. As one of the primary diagnostic tools for detecting liver cancer, dynamic contrast-enhanced computed tomography provides detailed evidences for diagnosis that are recorded in free-text radiology reports. Objective The aim of our study was to apply a deep learning model and rule-based natural language processing (NLP) method to identify evidences for liver cancer diagnosis automatically. Methods We proposed a pretrained, fine-tuned BERT (Bidirectional Encoder Representations from Transformers)-based BiLSTM-CRF (Bidirectional Long Short-Term Memory-Conditional Random Field) model to recognize the phrases of APHE (hyperintense enhancement in the arterial phase) and PDPH (hypointense in the portal and delayed phases). To identify more essential diagnostic evidences, we used the traditional rule-based NLP methods for the extraction of radiological features. APHE, PDPH, and other extracted radiological features were used to design a computer-aided liver cancer diagnosis framework by random forest. Results The BERT-BiLSTM-CRF predicted the phrases of APHE and PDPH with an F1 score of 98.40% and 90.67%, respectively. The prediction model using combined features had a higher performance (F1 score, 88.55%) than those using APHE and PDPH (84.88%) or other extracted radiological features (83.52%). APHE and PDPH were the top 2 essential features for liver cancer diagnosis. Conclusions This work was a comprehensive NLP study, wherein we identified evidences for the diagnosis of liver cancer from Chinese radiology reports, considering both clinical knowledge and radiology findings. The BERT-based deep learning method for the extraction of diagnostic evidence achieved state-of-the-art performance. The high performance proves the feasibility of the BERT-BiLSTM-CRF model in information extraction from Chinese radiology reports. The findings of our study suggest that the deep learning–based method for automatically identifying evidences for diagnosis can be extended to other types of Chinese clinical texts.",
  "full_text": "Original Paper\nUse of BERT (Bidirectional Encoder Representations from\nTransformers)-Based Deep Learning Method for Extracting\nEvidences in Chinese Radiology Reports: Development of a\nComputer-Aided Liver Cancer Diagnosis Framework\nHonglei Liu1,2, PhD; Zhiqiang Zhang1,2, BS; Yan Xu3, MD; Ni Wang1,2, BS; Yanqun Huang1,2, BS; Zhenghan Yang3,\nMD; Rui Jiang4, PhD; Hui Chen1,2, PhD\n1School of Biomedical Engineering, Capital Medical University, Beijing, China\n2Beijing Key Laboratory of Fundamental Research on Biomechanics in Clinical Application, Capital Medical University, Beijing, China\n3Department of Radiology, Beijing Friendship Hospital, Capital Medical University, Beijing, China\n4Ministry of Education Key Laboratory of Bioinformatics, Research Department of Bioinformatics at the Beijing National Research Center for Information\nScience and Technology, Center for Synthetic and Systems Biology, Department of Automation, Tsinghua University, Beijing, China\nCorresponding Author:\nHui Chen, PhD\nSchool of Biomedical Engineering, Capital Medical University\nNo 10, Xitoutiao, Youanmen, Fengtai District\nBeijing\nChina\nPhone: 86 010 83911545\nEmail: chenhui@ccmu.edu.cn\nAbstract\nBackground: Liver cancer is a substantial disease burden in China. As one of the primary diagnostic tools for detecting liver\ncancer, dynamic contrast-enhanced computed tomography provides detailed evidences for diagnosis that are recorded in free-text\nradiology reports.\nObjective: The aim of our study was to apply a deep learning model and rule-based natural language processing (NLP) method\nto identify evidences for liver cancer diagnosis automatically.\nMethods: We proposed a pretrained, fine-tuned BERT (Bidirectional Encoder Representations from Transformers)-based\nBiLSTM-CRF (Bidirectional Long Short-Term Memory-Conditional Random Field) model to recognize the phrases of APHE\n(hyperintense enhancement in the arterial phase) and PDPH (hypointense in the portal and delayed phases). To identify more\nessential diagnostic evidences, we used the traditional rule-based NLP methods for the extraction of radiological features. APHE,\nPDPH, and other extracted radiological features were used to design a computer-aided liver cancer diagnosis framework by\nrandom forest.\nResults: The BERT-BiLSTM-CRF predicted the phrases of APHE and PDPH with an F1 score of 98.40% and 90.67%,\nrespectively. The prediction model using combined features had a higher performance (F1 score, 88.55%) than those using APHE\nand PDPH (84.88%) or other extracted radiological features (83.52%). APHE and PDPH were the top 2 essential features for\nliver cancer diagnosis.\nConclusions: This work was a comprehensive NLP study, wherein we identified evidences for the diagnosis of liver cancer\nfrom Chinese radiology reports, considering both clinical knowledge and radiology findings. The BERT-based deep learning\nmethod for the extraction of diagnostic evidence achieved state-of-the-art performance. The high performance proves the feasibility\nof the BERT-BiLSTM-CRF model in information extraction from Chinese radiology reports. The findings of our study suggest\nthat the deep learning–based method for automatically identifying evidences for diagnosis can be extended to other types of\nChinese clinical texts.\n(J Med Internet Res 2021;23(1):e19689) doi: 10.2196/19689\nJ Med Internet Res 2021 | vol. 23 | iss. 1 | e19689 | p. 1http://www.jmir.org/2021/1/e19689/\n(page number not for citation purposes)\nLiu et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nKEYWORDS\nBiLSTM-CRF; natural language processing; radiology reports; information extraction; computer-aided diagnosis; BERT\nIntroduction\nIn the past decades, electronic health records (EHRs) from\nmillions of patients have become massive sources of valuable\nclinical data. Machine learning–based algorithms, especially\ndeep learning algorithms, have been applied effectively to\nanalyze patient data and they have shown promising results,\nthereby advancing medical research and better informing clinical\ndecision making for the secondary use of EHRs [1,2]. Owing\nto the high dimensionality, noise, heterogeneity, random errors,\nand systematic biases, the data mining of EHRs remains\nchallenging. Natural language processing (NLP) technologies\ncould extract meaningful information, thus facilitating the\napplication of clinical texts. There are 2 types of methods for\ninformation extraction, namely, rule-based methods and machine\nlearning methods [1]. The use of machine learning methods for\ndata mining of EHRs can derive previously unknown clinical\ninsights and be applied powerfully in clinical decision-making\nand computer-aided diagnosis of diseases [3,4]. Recently, deep\nlearning methods have had a profound impact in various areas\nof research because of their simplicity, efficient processing, and\nstate-of-the-art results [5,6]. In particular, recurrent neural\nnetworks and Word2Vec embedding are the most popular\nmethods that are utilized in clinical NLP tasks [2]. Deep learning\nmethods have made improvements in various clinical\napplications, especially for text classification, named-entity\nrecognition (NER), relation extraction, and question answering\n[7,8]. With growing acceptance and increasing number of\napplications, deep learning methods have become a baseline in\nmany clinical NLP tasks.\nWord embedding is an essential step for sequencing labelling\ntasks. Learning word representations from massive unannotated\ndocuments is a long-established method. The Word2Vec method\n[9] is the first word embedding approach based on deep learning\nmethods. The model derives the semantic and synthetic meaning\nof a word on account of its adjacent words by using\nunsupervised learning. Global Vector word representation [10]\nis another effective word embedding method, which constructs\na global word-word co-occurrence matrix and utilizes matrix\nfactorization to learn embeddings in a lower dimensional space.\nHowever, the word-level representations have a limitation that\nonly a single embedding is provided for a word with no thought\nfor polysemy under different contexts. Unlike the traditional\nembedding methods, ELMo (Embeddings from Language\nModels) [11] uses a bidirectional language model to embed the\ncontext information into word representations. BERT\n(Bidirectional Encoder Representations from Transformers)\n[12] is another prominent contextualized word representation\nmodel, which uses a masked language model that predicts\nrandomly masked words in a context sequence. Different from\nELMo, BERT targets different training objectives and uses a\nmasked language model to learn bidirectional representations.\nFor clinical sequence labelling tasks such as NER, rule-based\napproach and conditional random fields (CRFs) have been used\nwidely. Deep learning technologies substantially improve the\nNER performance through multi-layer data representations. Of\nthe popular deep learning methods, BiLSTM (bidirectional long\nshort-term memory) can capture long-range related information\neffectively. Furthermore, BiLSTM with CRF, known as\nBiLSTM-CRF, outperforms the traditional models with feature\nextraction and reduces the workload of feature selection [13].\nDue to the difference in the grammatical features from English\nand the limitation of the EHR corpus, information extraction\nof Chinese EHRs using NLP remains challenging. In the medical\nfield, researchers have developed information extraction\nalgorithms for varied implementations, including diagnostic\nmodels for different diseases such as cancers [14] and childhood\ndiseases [15]. For Chinese NER tasks, BiLSTM-CRF is the\nmost common and practical approach [16,17]. BERT has also\nreceived extensive attention in Chinese EHRs. Zhang et al used\nfine-tuning BERT for NER and relation extraction in several\ntypes of Chinese clinical documents. The comprehensive clinical\ninformation related to breast cancer was extracted [14]. Wu et\nal developed an aided clinical diagnosis service on EHRs by\nusing a deep learning model [3]. Liang et al applied an automatic\nNLP system and achieved a high diagnostic accuracy in\nchildhood diseases [15].\nThe radiology report is a crucial component of EHRs, as it is\nthe communication bridge between radiologists and physicians.\nThe accuracy and efficiency of diagnosis are limited since it is\nformulated based on subjective judgment, especially for\ninexperienced physicians. Hence, extracting useful radiological\ninformation from radiology reports has considerable significance\nin advancing radiological research and clinical practice [18,19].\nNLP technologies have received great attention in the processing\nof radiology reports and have been successfully applied in\nidentifying biomedical concepts [20], extracting\nrecommendations [21], determining the change level of clinical\nfindings [22], and so on.\nWith the development of machine learning methods in recent\neras, computer-aided early diagnosis for cancer based on\nmassive clinical data becomes feasible. Many diseases have\nbeen investigated to date, such as hepatocellular cancer [23]\nand colorectal cancer [24]. In this study, we focused on the\ncomputer-aided diagnosis of liver cancer, which remains to be\na substantial disease burden in China. For liver cancer diagnosis,\ndynamic contrast-enhanced computed tomography (CT) is one\nof the primary diagnostic tests. Imaging findings of the key\nenhanced scan phases such as the arterial phase, portal phase,\nand delayed phase are recorded in the radiology reports.\nAccording to the guidelines of the Chinese Society of Clinical\nOncology (CSCO), hyperintense enhancement in the arterial\nphase (APHE) and hypointense enhancement in the portal and\ndelayed phases (PDPH) are significant diagnostic evidences for\nliver cancer [25].\nIn this study, we designed deep learning–based methods to\nidentify evidences for liver cancer diagnosis automatically. We\nrecognized the phrases of APHE and PDPH by using a\nBERT-BiLSTM-CRF model by combining a pretrained,\nJ Med Internet Res 2021 | vol. 23 | iss. 1 | e19689 | p. 2http://www.jmir.org/2021/1/e19689/\n(page number not for citation purposes)\nLiu et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nfine-tuned BERT language model with BiLSTM-CRF. We also\napplied the FENLP (feature extraction using the rule-based\nNLP) method based on the content of radiology reports to extract\nthe radiological features. Therefore, the evidences for diagnosis,\nconsidering both clinical knowledge and radiology findings,\ncontained APHE, PDPH, and radiological features extracted by\nFENLP [26]. With these evidences, we designed a\ncomputer-aided liver cancer diagnosis framework by using\nrandom forest.\nMethods\nEvidence Extraction for Diagnosis of Liver Cancer\nFigure 1 shows the workflow of the evidence extraction for the\ndiagnosis of liver cancer. We implemented 2 feature extraction\nmethods based on clinical knowledge and the content of\nradiology reports to generate a radiological feature set. Then,\nwe built a random forest model to predict liver cancer by using\nthese features as inputs.\nFigure 1. The workflow of this research. Labels 0/1 represent the absence/presence of a certain feature. BERT: Bidirectional Encoder Representations\nfrom Transformers; BiLSTM: bidirectional long short-term memory; CRF: conditional random field; APHE: hyperintense enhancement in the arterial\nphase; PDPH: hypointense in the portal and delayed phases.\nData Sets\nWe collected abdomen and pelvic CT radiology reports from a\ntertiary hospital in Beijing, China, between 2012 and 2019. To\nprotect patient privacy, we removed all the identifying\ninformation. An unstructured radiology report has different\nsections, including Type of Examination, Clinical History,\nComparison, Technique, Imaging Findings, and Impressions.\nThe Impressions section summarizes crucial radiology findings\nfrom the Findings section and contains a diagnosis indicated\nby a radiologist. In this study, the diagnosis of liver cancer was\ndetermined according to the Impression section and the\nannotation of experienced radiologists, resulting in 480 patients\nwith liver cancer. We randomly selected 609 patients without\nliver cancer from our data set. Therefore, 480 and 609 radiology\nreports for patients with and without liver cancer, respectively,\nwere used in this study. We then trained and evaluated an NER\nmodel on the Imaging Findings section. The reports were\nrandomly divided into the training set and the test set in a ratio\nof 8:2.\nBERT-BiLSTM-CRF for Recognition of APHE and\nPDPH\nWe considered the recognition of APHE and PDPH as a\nsequence labelling task at the character level, where the goal\nwas to assign the BIO (Begin, Inside, Outside) tags to each\nChinese character. In this study, BIO tags contained B-APHE,\nI-APHE, B-PDPH, I-PDPH, and O-Outside. We invited 2\nradiologists with more than 5 years of medical experience to\nannotate all the data. If there was any inconsistency, another\nexperienced radiological expert was then asked to make the\nfinal annotation, to obtain the gold standard annotated data. To\nensure the consistency of the annotation, radiologists were\ntrained in advance. At the report level, APHE and PDPH were\nnot mutually exclusive, that is, 1 report could contain both\nAPHE and PDPH. Of all the reports, 602 had the phrase of\nAPHE and 330 had the phrase of PDPH. For the 480 reports\ndiagnosed with liver cancer, the numbers of APHE and PDPH\nwere 442 and 330, respectively.\nBiLSTM-CRF is commonly used in the sequence labeling task.\nTo further improve the recognition performance for the features\nof APHE and PDPH, we performed the BERT-BiLSTM-CRF\nmodel comprising a fine-tuned BERT language model for word\nembedding and BiLSTM-CRF method for feature recognition.\nCRF and BiLSTM-CRF model were applied as the baseline.\nAPHE and PDPH in Chinese radiology reports had a variety of\npresentations such as detailed presentation, CT values of\ndifferent phases, and abbreviations (Table 1). The deep learning\nmodel for the recognition of APHE and PDPH consisted of 3\nlayers, namely, the word embedding layer, BiLSTM layer, and\nCRF layer (Figure 2).\nJ Med Internet Res 2021 | vol. 23 | iss. 1 | e19689 | p. 3http://www.jmir.org/2021/1/e19689/\n(page number not for citation purposes)\nLiu et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nTable 1. Some expressions of APHEa and PDPHb in Chinese.\nDetailed descriptionsExpressions of APHE and PDPH in Chinese\nThe arterial phase shows the heterogeneous density in the enhanced scan.增强后动脉期明显不均匀强化\nMarked enhancement is shown in the arterial phase.动脉期强化明显\nMultiple enhancement areas are seen in the arterial phase.动脉期可见多发强化灶\nThe portal phase has relatively low density.门脉期相对低密度\nPDPH occurs in the portal phase.门脉期可见消退\naAPHE: hyperintense enhancement in the arterial phase.\nbPDPH: hypointense in the portal and delayed phases.\nFigure 2. The architecture of the BERT-BiLSTM-CRF model for the recognition of APHE and PDPH. BERT: Bidirectional Encoder Representations\nfrom Transformers; BiLSTM: bidirectional long short-term memory; CRF: conditional random field; APHE: hyperintense enhancement in the arterial\nphase; PDPH: hypointense in the portal and delayed phases.\nWord Embedding Layer\nThe word embedding layer could map and transform the discrete\ncharacters into distributed representations. A word-level vector\nrepresentation learned a real valued vector to represent a word\nfrom a large amount of unannotated text. On most NLP tasks,\nBERT could achieve state-of-the-art performance while\nrequiring minimal architectural modification [27]. In this study,\nwe applied Word2Vec and BERT to train the character vectors,\nfollowed by a comparison of the results. The Word2Vec was\nused with a dimension size of 100 and a batch size of 120. The\nWord2Vec was pretrained on the Chinese Wikipedia data. The\nsentence embedding had been pretrained and fine-tuned by\nBERT on the original Google BERT GitHub repository [28].\nThe maximum sequence length was set to 256 with a batch size\nof 64.\nBiLSTM Layer\nRecurrent neural networks is a family of neural networks, which\nis usually used for modelling sequential data. The LSTM (Long\nShort-Term Memory Networks) is a variant of the recurrent\nneural networks, and it can effectively capture high\ndependencies and retrieve rich global information. LSTM solves\nthe problem by using the gating mechanism. An LSTM unit\nconsists of 3 gates (ie, Input Gate, Output Gate, and Forget\nGate), which can select semantic information in a neural\nnetwork. Compared with LSTM, BiLSTM can learn forward\nand backward information of input words by splitting the\nneurons into 2 directions of a text sequence. We set the number\nof hidden units in BiLSTM to 100 and the optimizer to Adam.\nCRF Layer\nFor the sequence labelling step in our study, adjacent tags had\ndependencies. For example, an inside tag I must follow a begin\ntag B. We applied the sequential CRF to calculate optimal\nsequence combinations on top of the BiLSTM layer that could\nconsider the dependencies of adjacent tags.\nAPHE and PDPH Labels at the Report Level\nConsidering the characteristics of Chinese language and also\navoiding the noise, we defined the following as APHE or PDPH\nfeatures at the report level: (1) 2 continuous characters that were\nthe abbreviations of APHE (ie, 快进) or PDPH (ie, 快出); (2)\nmore than 3 continuous characters that were predicted as APHE\nor PDPH. Criterion (1) was checked first and was only based\non the characters. If not met, criterion (2) was checked, which\nwas based on CRF results.\nFENLP for Radiological Feature Extraction\nWe implemented the NLP pipeline in the Findings section to\nextract useful features from the unstructured radiology reports\nto facilitate liver cancer diagnosis. As shown in Figure 1, the\nJ Med Internet Res 2021 | vol. 23 | iss. 1 | e19689 | p. 4http://www.jmir.org/2021/1/e19689/\n(page number not for citation purposes)\nLiu et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nNLP pipeline consisted of 4 successive steps, that is, word\nsegmentation, entity annotation, coreference resolution, and\nrelationship extraction, resulting in radiological features\nconsisting of 1 or more terms. The detailed description of the\npipeline is provided in our previous study [26]. The whole\npipeline was based on a lexicon that was constructed manually\naccording to Chinese grammatical characteristics. A small\nnumber of reports were sampled randomly for generating the\nlexicon by manual reading. The lexicon contained clinical terms\nand lists of synonyms. The lexicon was collected in the same\nhospital and clinical text type with this study. Five entity types\n(Location, Morphology, Density, Enhancement, and Modifier)\nwere recognized. After coreference resolution, according to the\nsynonym list in the lexicon, we then used several patterns of\nentity types as rules to obtain the final radiological features\n(Table S1 of Multimedia Appendix 1). Therefore, the\nradiological features could be seen as a combination of several\nentities such as 肝脏+低密度影 (liver + low density) and 肝脏\n+增强扫描未见强化 (liver + enhancement scan showed no\nenhancement).\nPrediction Models\nUsing the radiological features obtained by\nBERT-BILSTM-CRF and FENLP, we used a random forest\nmodel for the liver cancer diagnosis. Random forest is an\nensemble learning method constructed with a multitude of\ndecision trees, which is widely used in classification tasks. The\nperformance was measured by the recall, precision, and F1\nscore. Random forest could generate the feature importance\nscore, which was computed by Gini impurity. Gini impurity is\na measurement of the probability that a sample is classified\nincorrectly without a specific feature. In our study, the higher\nthe feature importance score of the radiological features was,\nthe more linked it was with the liver cancer diagnosis. We used\nthe feature importance score to rank all the radiological features.\nResults\nWe extracted the features of APHE and PDPH by using 3\ndifferent models, that is, CRF, BiLSTM-CRF, and\nBERT-BiLSTM-CRF. The recognition results were presented\nboth at the report level and character level (Table 2). At the\nreport level, the performance was computed depending on\nwhether the radiology reports contained a feature of APHE or\nPDPH. At the character level, the recognition results of BIO\ntags for each Chinese character were counted. For the\ncharacter-level recognition results of APHE and PDPH, the\nBERT-BiLSTM-CRF model obtained the best performance,\nwith F1 scores of 89.14% and 82.19%, respectively. At the\nreport level, the BERT-BiLSTM-CRF model also achieved the\nbest performance (F1 scores of 98.40% for APHE and 90.67%\nfor PDPH). For the other 2 baseline models, the BiLSTM-CRF\nmodel outperformed the CRF model but underperformed the\nBERT-BiLSTM-CRF model. If a single character was\nrecognized as a feature, it would be regarded as noisy\ninformation, thereby leading to its exclusion from the\nreport-level results. As a result, the recognition performances\nat the report level were higher than those at the character level\nin all the models. We chose the recognition results of APHE\nand PDPH at the report level by the BERT-BiLSTM-CRF model\nas the predictors for further liver cancer diagnosis.\nThe feature extraction method FENLP used the lexicon\ndescribed in our previous study, which included 831 words and\n5 entity types. Entity combinations conforming to specific entity\npatterns were formulated as radiological features. The patterns\nincluded Location + Density, Location + Enhancement, Location\n+ Enhancement + Modifier, Location + Density + Modifier,\nand Location + Morphology. We retained the radiological\nfeatures that occurred more than twice. We finally obtained 301\nradiological features; among them, 6 features had a frequency\nhigher than 300 (Table S2 of Multimedia Appendix 1).\nJ Med Internet Res 2021 | vol. 23 | iss. 1 | e19689 | p. 5http://www.jmir.org/2021/1/e19689/\n(page number not for citation purposes)\nLiu et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nTable 2. Recognition performance of APHEa and PDPHb by using different models at the character level and report level.\nF1 score (%)Recall (%)Precision (%)Accuracy (%)Models\nCharacter level\nConditional random field\n77.7072.1984.1396.05APHE\n68.0659.0280.3797.44PDPH\nBidirectional long short-term memory-conditional random field\n86.5182.5690.8697.54APHE\n79.8975.7284.5698.24PDPH\nBERTc+ Bidirectional long short-term memory-conditional random field\n89.1487.2291.1497.97APHE\n82.1976.6488.6098.46PDPH\nReport level\nConditional random field\n95.0091.9498.2894.52APHE\n83.2179.1787.6989.00PDPH\nBidirectional long short-term memory-conditional random field\n96.0094.7497.3095.89APHE\n89.3986.7692.1993.61PDPH\nBERT+ Bidirectional long short-term memory-conditional random field\n98.4099.1997.6298.17APHE\n90.6794.4487.1893.61PDPH\naAPHE: hyperintense enhancement in the arterial phase.\nbPDPH: hypointense in the portal and delayed phases.\ncBERT: Bidirectional Encoder Representations from Transformers.\nAccording to the presence or absence of each feature extracted\nfrom either BERT-BILSTM-CRF or FENLP, each radiology\nreport was represented by a 0-1 vector. The prediction results\nusing different patterns of features are shown in Table 3. F1\nscores of random forest using features from\nBERT-BILSTM-CRF and FENLP were 84.88% and 83.92%,\nrespectively. With a combination of both kinds of features, the\nfinal F1 score of prediction model increased to 88.55%. Among\nall the feature input patterns, the precision and accuracy also\nobtained the highest value while inputting all the features, while\nthe prediction model had the highest recall rate with only 2\nfeatures of APHE and PDPH. Among the features with a\nfrequency higher than 10 in all the reports, the top 10 features\nlinked with the liver cancer diagnosis were identified with the\nfeature importance score computed by Gini impurity (Figure\n3). The top 2 features were APHE and PDPH, which had\nsubstantially larger feature importance scores than the other\nfeatures extracted from FENLP.\nTable 3. Performance of different patterns of features for liver cancer diagnosis.\nF1 score (%)Recall (%)Precision (%)Accuracy (%)Patterns of Features\n84.8888.7081.3886.11APHEa and PDPHb\n83.9284.8083.0685.71Radiological features from FENLPc\n88.5585.7791.5290.25All features\naAPHE: hyperintense enhancement in the arterial phase.\nbPDPH: hypointense in the portal and delayed phases.\ncFENLP: feature extraction using the rule-based natural language processing.\nJ Med Internet Res 2021 | vol. 23 | iss. 1 | e19689 | p. 6http://www.jmir.org/2021/1/e19689/\n(page number not for citation purposes)\nLiu et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nFigure 3. Top 10 radiological features linked with liver cancer diagnosis ranked by feature importance score. APHE: hyperintense enhancement in the\narterial phase; PDPH: hypointense in the portal and delayed phases.\nDiscussion\nPrincipal Results\nDiagnostic prediction of cancer by using data mining methods\nis an essential and significant application of EHRs [5]. From\nprevious studies, features extracted from EHRs have proved to\nbe the valid input of the diagnostic model [14,29]. In particular,\nthe use of machine learning methods, especially deep learning\nmethods for clinical information extraction, could facilitate in\nproviding new evidences in computer-aided diagnosis. As the\nburden of liver cancer is widely accepted as one of the principal\nand universal challenges in health care and as patients with liver\ncancer are usually diagnosed at the terminal stage, the early and\naccurate diagnosis of liver cancer by radiology examination has\ngreat significance [30,31]. In contrast with previous studies of\nliver cancer diagnosis, our study focused on the identification\nof evidences for live cancer diagnosis from Chinese radiology\nreports. We selected APHE and PDPH as the known evidences\nfor diagnosis according to the guidelines of CSCO. These 2\nfeatures were essential but not sufficient enough to represent\nthe whole report and further be used to diagnose liver cancer.\nFurthermore, using FENLP, we also extracted uncertain numbers\nof radiological features from the report content, because we\naimed to obtain new evidences for essential diagnosis.\nTherefore, the evidences for diagnosis were obtained both from\nclinical knowledge and the content of reports. For the\nrecognition of APHE and PDPH, we applied BERT on word\nembedding in the deep learning method, which achieved\nstate-of-the-art performance.\nWord embedding is an essential step for sequencing labelling\ntasks. Previously popular models such as Word2Vec and Global\nVector word representation focused on learning\ncontext-independent word representations. Recent advances in\nword representations based on language models, including\nELMo, CoVe, and BERT, could dynamically improve the word\nrepresentations and discriminate among multiple meanings of\na word. In particular, based on the attention mechanism, BERT\nexhibited an upward trend and outperformed the previous\nmodels in many NLP tasks. Recognition of APHE and PDPH\nusing traditional NLP methods had difficulties, because the\nrelated descriptions covered varied Chinese sentence structures\nand entity types (Table 1). For example, for hyperintense\nenhancement, the sentence pattern and phrase could have\ndifferent styles due to the different writing habits of different\nradiologists or due to the use of Chinese abbreviations. Different\nfrom the Word2Vec model, BERT learned context-dependent\nword representations by using bidirectional transformers. The\nBiLSTM algorithms are widely used and easily implanted in\nsequence-related work such as entity extraction. We annotated\nall the characters in the Findings section manually with BIO\ntags and then applied the BERT-BiLSTM-CRF model to\nrecognize APHE and PDPH. The high performance proved the\nfeasibility of the BERT-BiLSTM-CRF model in information\nextraction from Chinese radiology reports.\nIn this study, among the recognition results of APHE and PDPH\nobtained by the 3 different models, the BERT-BILSTM-CRF\nmodel finally achieved the best performance for both APHE\n(F1 score 98.40%, precision 97.62%, and recall 99.19%) and\nPDPH (90.67%, 87.18%, and 94.44%, respectively) at the report\nlevel. For the 2 baseline models based on CRF, the model with\na BiLSTM layer received a much higher F1 score than the model\nwithout a BiLSTM layer. The results indicated that, with the\nword embedding language model BERT and the BiLSTM\nmodel, the recognition of APHE and PDPH could result in much\nhigher performance. To avoid the noise in the recognition\nresults, we used the recognition results at the report level to be\nthe input radiological features of the liver cancer diagnostic\nmodel. Report-level recognition concerned only continuous\ncharacters longer than 3 characters and specific Chinese\nabbreviations. Therefore, report-level results could represent\nwhether the report contained the features of APHE or PDPH.\nThe recognition of APHE and PDPH by BERT-BiLSTM-CRF\nwas accurate enough to be the predictors of liver cancer\ndiagnosis.\nOnly 2 fixed features of APHE and PDPH were not enough for\nliver cancer diagnosis. Therefore, we further performed the\nautomatic NLP pipeline FENLP to extend the feature set based\non Chinese grammar and radiological characteristics. Different\nfrom that of BERT-BILSTM-CRF, the number of features\ngenerated by FENLP was unknown and changed according to\nJ Med Internet Res 2021 | vol. 23 | iss. 1 | e19689 | p. 7http://www.jmir.org/2021/1/e19689/\n(page number not for citation purposes)\nLiu et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nthe training texts. In this study, we finally extracted 301 features.\nThe top features were the typical morphology of the different\nlocations, which were essential to the diagnosis of the liver\ndiseases (Table S2 of Multimedia Appendix 1).\nWe chose the random forest as the liver cancer diagnostic model.\nWith 2 kinds of features obtained by BERT-BILSTM-CRF and\nFENLP, random forest could reach an F1 score of 88.55%,\nwhich was much higher than the model using either kind of\nfeatures. The performance of the diagnostic model using APHE\nand PDPH was slightly higher than that of the model using\nfeatures extracted from FENLP. By contrast, FENLP produced\nmuch more features than BERT-BILSTM-CRF. We further\nranked the features by the feature importance score computed\nby Gini impurity, which could reflect the degree of association\nwith liver cancer. APHE and PDPH were the top 2 features with\na clearly higher feature importance score compared with other\nfeatures obtained by FENLP. The results indicated the strong\nassociation of APHE and PDPH with liver cancer, which\ncoincided with the current clinical knowledge. Of the top\nfeatures obtained by FENLP, the feature high density of liver\nhad the highest feature importance score, which was the\nimportant and basic risk factor for the diagnosis of liver diseases.\nBroadening of hepatic fissures was an essential feature that\nexisted in liver cirrhosis or in liver cancer progressed from liver\ncirrhosis [30]. Our results confirmed that the radiological\nfeatures from FENLP could also be an evidence for diagnosis,\nwhich could further improve the diagnostic performance.\nFurthermore, the top features linked with liver cancer could\nextend the diagnostic evidence and be the supplementary\nfeatures of APHE and PDPH.\nDesigning disease diagnostic models based on EHRs is a\nsignificantly important research field. Recently, NLP and deep\nlearning-based models have been widely applied in many studies\n[7]. For instance, Sada et al designed and performed\nNLP-assisted radiology document classification for liver cancer\ndetection. The model finally received an F1 score of 0.78 [23].\nCompared with previous studies on clinical information\nextraction, the evidences for diagnosis in this study were\nidentified based on the clinical knowledge from the guidelines\nof CSCO and the content of the reports. APHE and PDPH are\n2 widely accepted evidences for disease diagnosis, and they\nhave also proved to be essential features in our liver cancer\ndiagnostic model. Other radiological features from FENLP\nenlarged the potential evidences for the diagnosis of liver cancer.\nMoreover, we utilized the BERT-BiLSTM-CRF model in this\nstudy, which achieved the state-of-the-art performance.\nLimitations\nOur study had the following limitations. The number of\nradiological features from FENLP was not fixed since all\ndesirable features were retained, which might introduce some\nnoise into the extracted radiological features. Besides, from the\nclinical knowledge in the guidelines of CSCO, we only extracted\n2 characteristic features. In future, we will collect more\nevidences for diagnosis in order to further improve the\nperformance and make the model more explanatory. Through\nthe analysis of the misjudged samples in the recognition of\nAPHE and PDPH, we identified the main error that occurred\nwhen the description of APHE and PDPH only included CT\nvalues. With the comparison of CT values in different phases,\nwe could define these 2 features. However, our methods did not\nfocus on the CT value extraction, and the number of these cases\nwere small. In future studies, CT value extraction and analysis\ncan avoid this kind of error and increase the prediction\nperformance.\nConclusion\nIn this study, we developed a deep learning–based method for\nthe recognition of evidences for disease diagnosis and designed\na computer-aided liver cancer diagnosis framework. The\ndiagnostic evidences contained APHE, PDPH, and radiological\nfeatures extracted by FENLP. We proposed the BERT-based\ndeep learning model BERT-BILSTM-CRF for recognizing the\nphrases of APHE and PDPH, which are the essential features\nassociated with liver cancer diagnosis. Our work confirms that\nBERT-based deep learning model can be used and has desirable\nperformance in the radiological feature extraction of Chinese\nradiology reports. Furthermore, this study was a comprehensive\nstudy for NLP and its application, focusing on Chinese radiology\nreports. The deep learning model proposed in this study for\ninformation extraction is expected to be extended to different\ntypes of Chinese clinical texts and other kinds of applications.\nAcknowledgments\nThis work was supported by grants from the National Natural Science Foundation of China (No. 81701792 and No. 81971707)\nand the National Key Research and Development Program of China (No. 2018YFC0910404)\nAuthors' Contributions\nHL proposed and designed the whole pipeline, analyzed the results, and wrote the paper. YX and ZY collected the original data,\nannotated the radiology reports, and provided clinical knowledge guidance in lexicon construction. ZZ, NW, and YH cleaned the\ndata. RJ provided theoretical guidance and revised this paper. HC provided theoretical guidance and revised this paper.\nConflicts of Interest\nNone declared.\nMultimedia Appendix 1\nSupplementary data.\nJ Med Internet Res 2021 | vol. 23 | iss. 1 | e19689 | p. 8http://www.jmir.org/2021/1/e19689/\n(page number not for citation purposes)\nLiu et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\n[DOCX File , 20 KB-Multimedia Appendix 1]\nReferences\n1. Wang Y, Wang L, Rastegar-Mojarad M, Moon S, Shen F, Afzal N, et al. Clinical information extraction applications: A\nliterature review. J Biomed Inform 2018 Jan;77:34-49 [FREE Full text] [doi: 10.1016/j.jbi.2017.11.011] [Medline: 29162496]\n2. Wu S, Roberts K, Datta S, Du J, Ji Z, Si Y, et al. Deep learning in clinical natural language processing: a methodical review.\nJ Am Med Inform Assoc 2020 Mar 01;27(3):457-470 [FREE Full text] [doi: 10.1093/jamia/ocz200] [Medline: 31794016]\n3. Wu J, Liu X, Zhang X, He Z, Lv P. Master clinical medical knowledge at certificated-doctor-level with deep learning\nmodel. Nat Commun 2018 Oct 19;9(1):4352 [FREE Full text] [doi: 10.1038/s41467-018-06799-6] [Medline: 30341328]\n4. Gálvez JA, Pappas JM, Ahumada L, Martin JN, Simpao AF, Rehman MA, et al. The use of natural language processing\non pediatric diagnostic radiology reports in the electronic health record to identify deep venous thrombosis in children. J\nThromb Thrombolysis 2017 Oct;44(3):281-290. [doi: 10.1007/s11239-017-1532-y] [Medline: 28815363]\n5. Sheikhalishahi S, Miotto R, Dudley JT, Lavelli A, Rinaldi F, Osmani V. Natural Language Processing of Clinical Notes\non Chronic Diseases: Systematic Review. JMIR Med Inform 2019 Apr 27;7(2):e12239 [FREE Full text] [doi: 10.2196/12239]\n[Medline: 31066697]\n6. Dreisbach C, Koleck TA, Bourne PE, Bakken S. A systematic review of natural language processing and text mining of\nsymptoms from electronic patient-authored text data. Int J Med Inform 2019 May;125:37-46 [FREE Full text] [doi:\n10.1016/j.ijmedinf.2019.02.008] [Medline: 30914179]\n7. Chen L, Song L, Shao Y, Li D, Ding K. Using natural language processing to extract clinically useful information from\nChinese electronic medical records. Int J Med Inform 2019 Apr;124:6-12. [doi: 10.1016/j.ijmedinf.2019.01.004] [Medline:\n30784428]\n8. Li P, Yuan Z, Tu W, Yu K, Lu D. Medical Knowledge Extraction and Analysis from Electronic Medical Records Using\nDeep Learning. Chin Med Sci J 2019 Jun 30;34(2):133-139. [doi: 10.24920/003589] [Medline: 31315754]\n9. Mikolov T, Chen K, Corrado G, Dean J. Distributed Representations of Words and Phrases and their Compositionality. In:\nAdvances in Neural Information Processing Systems 26 (NIPS 2013). United States: NIPS Foundation; 2013:3111-3119.\n10. Pennington J, Socher R, Manning C. GloVe: Global Vectors for Word Representation. 2014 Presented at: Proceedings of\nthe Conference on Empirical Methods in Natural Language Processing (EMNLP); 2014; Doha, Qatar p. 1532-1543. [doi:\n10.3115/v1/d14-1162]\n11. Peters M, Neumann M, Iyyer M, Gardner M, Clark C, Lee K. Deep contextualized word representations. 2018 Presented\nat: Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics:\nHuman Language Technologies; 2018; New Orleans, LA,USA p. 2227-2237 URL: https://arxiv.org/abs/1802.05365\n12. Devlin J, Chang M, Kristina K, Toutanova. BERT: Pre-training of Deep Bidirectional Transformers for Language\nUnderstanding. 2019 Presented at: Proceedings of the 2019 Conference of the North American Chapter of the Association\nfor Computational Linguistics: Human Language Technologies; 2019; Minneapolis, MN, USA p. 4171-4186. [doi:\n10.18653/v1/N19-1423]\n13. Zhiheng H, Xu W, Yu K. Bidirectional LSTM-CRF models for sequence tagging. 2015. URL: https://arxiv.org/abs/1508.\n01991 [accessed 2020-01-03]\n14. Zhang X, Zhang Y, Zhang Q, Ren Y, Qiu T, Ma J, et al. Extracting comprehensive clinical information for breast cancer\nusing deep learning methods. Int J Med Inform 2019 Dec;132:103985. [doi: 10.1016/j.ijmedinf.2019.103985] [Medline:\n31627032]\n15. Liang H, Tsui BY, Ni H, Valentim CCS, Baxter SL, Liu G, et al. Evaluation and accurate diagnoses of pediatric diseases\nusing artificial intelligence. Nat Med 2019 Mar;25(3):433-438. [doi: 10.1038/s41591-018-0335-9] [Medline: 30742121]\n16. Wang Q, Zhou Y, Ruan T, Gao D, Xia Y, He P. Incorporating dictionaries into deep neural networks for the Chinese clinical\nnamed entity recognition. J Biomed Inform 2019 Apr;92:103133 [FREE Full text] [doi: 10.1016/j.jbi.2019.103133] [Medline:\n30818005]\n17. Ji B, Li S, Yu J, Ma J, Tang J, Wu Q, et al. Research on Chinese medical named entity recognition based on collaborative\ncooperation of multiple neural network models. J Biomed Inform 2020 Apr;104:103395. [doi: 10.1016/j.jbi.2020.103395]\n[Medline: 32109551]\n18. Bozkurt S, Alkim E, Banerjee I, Rubin DL. Automated Detection of Measurements and Their Descriptors in Radiology\nReports Using a Hybrid Natural Language Processing Algorithm. J Digit Imaging 2019 Aug;32(4):544-553 [FREE Full\ntext] [doi: 10.1007/s10278-019-00237-9] [Medline: 31222557]\n19. Steinkamp JM, Chambers C, Lalevic D, Zafar HM, Cook TS. Toward Complete Structured Information Extraction from\nRadiology Reports Using Machine Learning. J Digit Imaging 2019 Aug;32(4):554-564 [FREE Full text] [doi:\n10.1007/s10278-019-00234-y] [Medline: 31218554]\n20. Flynn RWV, Macdonald TM, Schembri N, Murray GD, Doney ASF. Automated data capture from free-text radiology\nreports to enhance accuracy of hospital inpatient stroke codes. Pharmacoepidemiol Drug Saf 2010 Aug;19(8):843-847.\n[doi: 10.1002/pds.1981] [Medline: 20602346]\n21. Yetisgen-Yildiz M, Gunn ML, Xia F, Payne TH. A text processing pipeline to extract recommendations from radiology\nreports. J Biomed Inform 2013 Apr;46(2):354-362 [FREE Full text] [doi: 10.1016/j.jbi.2012.12.005] [Medline: 23354284]\nJ Med Internet Res 2021 | vol. 23 | iss. 1 | e19689 | p. 9http://www.jmir.org/2021/1/e19689/\n(page number not for citation purposes)\nLiu et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\n22. Hassanpour S, Bay G, Langlotz CP. Characterization of Change and Significance for Clinical Findings in Radiology Reports\nThrough Natural Language Processing. J Digit Imaging 2017 Jun;30(3):314-322 [FREE Full text] [doi:\n10.1007/s10278-016-9931-8] [Medline: 28050714]\n23. Sada Y, Hou J, Richardson P, El-Serag H, Davila J. Validation of Case Finding Algorithms for Hepatocellular Cancer From\nAdministrative Data and Electronic Health Records Using Natural Language Processing. Med Care 2016 Feb;54(2):e9-14\n[FREE Full text] [doi: 10.1097/MLR.0b013e3182a30373] [Medline: 23929403]\n24. Xu H, Fu Z, Shah A, Chen Y, Peterson NB, Chen Q, et al. Extracting and integrating data from entire electronic health\nrecords for detecting colorectal cancer cases. AMIA Annu Symp Proc 2011;2011:1564-1572 [FREE Full text] [Medline:\n22195222]\n25. Guidelines of Chinese Society of Clinical Oncology (CSCO): Hepatocellular Carcinoma. Beijing,China: Chinese Society\nof Clinical Oncology; 2018.\n26. Liu H, Xu Y, Zhang Z, Wang N, Huang Y, Hu Y, et al. A Natural Language Processing Pipeline of Chinese Free-text\nRadiology Reports for Liver Cancer Diagnosis. IEEE Access 2020 Aug 28;8:159110-159119. [doi:\n10.1109/ACCESS.2020.3020138]\n27. Tawfik NS, Spruit MR. Evaluating sentence representations for biomedical text: Methods and experimental results. J\nBiomed Inform 2020 Apr;104:103396. [doi: 10.1016/j.jbi.2020.103396] [Medline: 32147441]\n28. GitHub. URL: https://github.com/google-research/bert [accessed 2020-03-01]\n29. Pathak S, van Rossen J, Vijlbrief O, Geerdink J, Seifert C, van Keulen M. Post-Structuring Radiology Reports of Breast\nCancer Patients for Clinical Quality Assurance. IEEE/ACM Trans Comput Biol Bioinform 2020;17(6):1883-1894. [doi:\n10.1109/TCBB.2019.2914678] [Medline: 31059453]\n30. Kudo M, Trevisani F, Abou-Alfa GK, Rimassa L. Hepatocellular Carcinoma: Therapeutic Guidelines and Medical Treatment.\nLiver Cancer 2016 Nov;6(1):16-26 [FREE Full text] [doi: 10.1159/000449343] [Medline: 27995084]\n31. Nagtegaal ID, Odze RD, Klimstra D, Paradis V, Rugge M, Schirmacher P, WHO Classification of Tumours Editorial Board.\nThe 2019 WHO classification of tumours of the digestive system. Histopathology 2020 Jan;76(2):182-188 [FREE Full\ntext] [doi: 10.1111/his.13975] [Medline: 31433515]\nAbbreviations\nAPHE: hyperintense enhancement in the arterial phase\nBERT: Bidirectional Encoder Representations from Transformers\nBiLSTM: bidirectional long short-term memory\nBIO: Begin, Inside, Outside\nCRF: conditional random field\nCSCO: Chinese Society of Clinical Oncology\nCT: computed tomography\nEHR: electronic health record\nELMo: Embeddings from Language Model\nFENLP: feature extraction using the rule-based natural language processing\nNER: named-entity recognition\nNLP: natural language processing\nPDPH: hypointense in the portal and delayed phases\nEdited by G Eysenbach; submitted 29.04.20; peer-reviewed by M Torii, J Zheng; comments to author 01.06.20; revised version\nreceived 30.06.20; accepted 11.11.20; published 12.01.21\nPlease cite as:\nLiu H, Zhang Z, Xu Y, Wang N, Huang Y, Yang Z, Jiang R, Chen H\nUse of BERT (Bidirectional Encoder Representations from Transformers)-Based Deep Learning Method for Extracting Evidences in\nChinese Radiology Reports: Development of a Computer-Aided Liver Cancer Diagnosis Framework\nJ Med Internet Res 2021;23(1):e19689\nURL: http://www.jmir.org/2021/1/e19689/\ndoi: 10.2196/19689\nPMID: 33433395\n©Honglei Liu, Zhiqiang Zhang, Yan Xu, Ni Wang, Yanqun Huang, Zhenghan Yang, Rui Jiang, Hui Chen. Originally published\nin the Journal of Medical Internet Research (http://www.jmir.org), 12.01.2021. This is an open-access article distributed under\nthe terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted\nJ Med Internet Res 2021 | vol. 23 | iss. 1 | e19689 | p. 10http://www.jmir.org/2021/1/e19689/\n(page number not for citation purposes)\nLiu et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nuse, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet\nResearch, is properly cited. The complete bibliographic information, a link to the original publication on http://www.jmir.org/,\nas well as this copyright and license information must be included.\nJ Med Internet Res 2021 | vol. 23 | iss. 1 | e19689 | p. 11http://www.jmir.org/2021/1/e19689/\n(page number not for citation purposes)\nLiu et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX",
  "topic": "Encoder",
  "concepts": [
    {
      "name": "Encoder",
      "score": 0.6673452258110046
    },
    {
      "name": "Deep learning",
      "score": 0.5591388940811157
    },
    {
      "name": "Computer science",
      "score": 0.554957389831543
    },
    {
      "name": "Liver cancer",
      "score": 0.5430038571357727
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5120373368263245
    },
    {
      "name": "Transformer",
      "score": 0.4511867165565491
    },
    {
      "name": "Radiology",
      "score": 0.36162298917770386
    },
    {
      "name": "Medical physics",
      "score": 0.3474363684654236
    },
    {
      "name": "Medicine",
      "score": 0.3410124182701111
    },
    {
      "name": "Cancer",
      "score": 0.20287930965423584
    },
    {
      "name": "Engineering",
      "score": 0.19345268607139587
    },
    {
      "name": "Internal medicine",
      "score": 0.16126680374145508
    },
    {
      "name": "Electrical engineering",
      "score": 0.11790129542350769
    },
    {
      "name": "Operating system",
      "score": 0.07787010073661804
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ]
}