{
    "title": "Frustratingly Easy Edit-based Linguistic Steganography with a Masked Language Model",
    "url": "https://openalex.org/W3154426351",
    "year": 2021,
    "authors": [
        {
            "id": "https://openalex.org/A3042137137",
            "name": "Honai Ueoka",
            "affiliations": [
                "Kyoto University"
            ]
        },
        {
            "id": "https://openalex.org/A2096275950",
            "name": "Yugo Murawaki",
            "affiliations": [
                "Kyoto University"
            ]
        },
        {
            "id": "https://openalex.org/A112209514",
            "name": "Sadao Kurohashi",
            "affiliations": [
                "Kyoto University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3015468748",
        "https://openalex.org/W1482218439",
        "https://openalex.org/W2096050104",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W2162174114",
        "https://openalex.org/W3083360291",
        "https://openalex.org/W2963929190",
        "https://openalex.org/W1832326700",
        "https://openalex.org/W2181849526",
        "https://openalex.org/W2964121744",
        "https://openalex.org/W3033529678",
        "https://openalex.org/W3034287667",
        "https://openalex.org/W2577138561",
        "https://openalex.org/W2618218947",
        "https://openalex.org/W3032816972",
        "https://openalex.org/W1544827683"
    ],
    "abstract": "With advances in neural language models, the focus of linguistic steganography has shifted from edit-based approaches to generation-based ones. While the latter's payload capacity is impressive, generating genuine-looking texts remains challenging. In this paper, we revisit edit-based linguistic steganography, with the idea that a masked language model offers an off-the-shelf solution. The proposed method eliminates painstaking rule construction and has a high payload capacity for an edit-based model. It is also shown to be more secure against automatic detection than a generation-based method while offering better control of the security/payload capacity trade-off.",
    "full_text": "Proceedings of the 2021 Conference of the North American Chapter of the\nAssociation for Computational Linguistics: Human Language Technologies, pages 5486–5492\nJune 6–11, 2021. ©2021 Association for Computational Linguistics\n5486\nFrustratingly Easy Edit-based Linguistic Steganography\nwith a Masked Language Model\nHonai Ueoka Yugo Murawaki Sadao Kurohashi\nGraduate School of Informatics, Kyoto University\nhueoka@icn.cce.i.kyoto-u.ac.jp\n{murawaki, kuro}@i.kyoto-u.ac.jp\nAbstract\nWith advances in neural language models, the\nfocus of linguistic steganography has shifted\nfrom edit-based approaches to generation-\nbased ones. While the latter’s payload capac-\nity is impressive, generating genuine-looking\ntexts remains challenging. In this paper, we re-\nvisit edit-based linguistic steganography, with\nthe idea that a masked language model of-\nfers an off-the-shelf solution. The proposed\nmethod eliminates painstaking rule construc-\ntion and has a high payload capacity for an\nedit-based model. It is also shown to be\nmore secure against automatic detection than a\ngeneration-based method while offering better\ncontrol of the security/payload capacity trade-\noff.\n1 Introduction\nSteganography is the practice of concealing a mes-\nsage in some cover data such that an eavesdropper\nis not even aware of the existence of the secret\nmessage (Simmons, 1984; Anderson and Petitco-\nlas, 1998). While images, videos, and audio have\nbeen dominant cover media (Fridrich, 2009), nat-\nural language is a promising choice, thanks to the\nomnipresence of text (Bennett, 2004).\nFormally, the goal of linguistic steganography\nis to create a steganographic system (stegosystem)\nwith which the sender Alice encodes a secret mes-\nsage, usually in the form of a bit sequence, into\na text and the receiver Bob decodes the message,\nwith the requirement that the text is so natural that\neven if transmitted in a public channel, it does not\narouse the suspicion of the eavesdropper Eve. For\na stegosystem that creates the text through transfor-\nmation, we refer to the original text as thecover text\nand the modiﬁed text as the stego text. A stegosys-\ntem has two objectives, security and payload ca-\npacity. Security is the degree of how unsuspicious\nthe stego text is while payload capacity is the size\nof the secret message relative to the size of the\nstego text. The two objectives generally exhibit a\ntrade-off relationship (Chang and Clark, 2014).\nEdit-based approaches used to dominate the re-\nsearch on linguistic steganography. Arguably, the\nmost effective approach was synonym substitu-\ntion (Chapman et al., 2001; Bolshakov, 2005; Taski-\nran et al., 2006; Chang and Clark, 2014; Wilson\nand Ker, 2016), where a bit chunk was assigned to\neach member of a synonym group, for example, ‘0’\nto marry and ‘1’ towed. The cover text She will\nmarry him was then modiﬁed to the stego text She\nwill wed him such that the latter carried the secret\nbit sequence ‘1’.\nThis conceptual simplicity was, however, over-\nshadowed by the complexity of linguistic phenom-\nena such as part-of-speech ambiguity, polysemy,\nand context sensitivity. For this reason, edit-based\napproaches were characterized by the painstaking\nconstruction of synonym substitution rules, which\nwere tightly coupled with acceptability checking\nmechanisms (see Chang and Clark (2014) for a\nreview and their own elaborate method). With\nall these efforts, edit-based stegosystems suffered\nfrom low payload capacity, for example, 2 bits per\nsentence (Chang and Clark, 2014).\nWith advances in neural language models (LMs),\nedit-based approaches have been replaced by\ngeneration-based ones (Fang et al., 2017; Yang\net al., 2019; Dai and Cai, 2019; Ziegler et al., 2019;\nShen et al., 2020). In these approaches, bit chunks\nare directly assigned to the conditional probability\ndistribution over the next word estimated by the\nLM, yielding impressive payload capacities of 1–5\nbits per word (Shen et al., 2020).\nHowever, it remains challenging for an LM to\ngenerate so genuine-looking texts that they fool\nboth humans and machines (Ippolito et al., 2020)\neven if they do not encode secret messages. It is\nalso worth noting that generation-based stegosys-\ntems do not necessarily cut out the need for cover\ntexts, as Ziegler et al. (2019) and Shen et al. (2020)\n5487\nAlice\nCover text\nMasking strategy\nSecret message\n1,0,1\nEncoding strategy\nWe completed the charitable task.\nWe [MASK] the charitable [MASK] .\nMasked LM\n Eve\n0 finished\n1 started\nMasked text\nWe started the charitable project .Stego text\nMasking strategy\nEncoding strategy\nWe [MASK] the charitable [MASK] .\nMasked LM\nWe started the charitable project.\nMasked text\nSego text\n00 task\n01 project\n10 job\n11 labor\n0 finished\n1 started\n00 task\n01 project\n10 job\n11 labor\n1,0,1 Secret message\nBob\nFigure 1: Overview of the proposed method. Alice (sender) and Bob (receiver) share the masked language model\n(masked LM) and the masking and encoding strategies in advance. Alice masks some tokens in the cover text and\nmakes the masked LM generate a vocabulary distribution for each masked token. Bit chunks are assigned to some\nhigh-probability subwords in the distribution from which one is chosen according to the secret message. The stego\ntext is then transmitted in a public channel Eve (eavesdropper) monitors. Receiving the stego text, Bob performs\nmostly the same procedure to decode the secret message.\nconditioned generation on human-written introduc-\ntory sentences to ensure the stego text quality.\nIn this paper, we revisit edit-based linguistic\nsteganography. Our key idea is that a masked lan-\nguage model (masked LM), which was ﬁrst intro-\nduced with BERT (Devlin et al., 2019), offers an\noff-the-shelf solution. Usually treated as an in-\ntermediate model with no direct application, the\nmasked LM drastically simpliﬁes an edit-based\nstegosystem. It eliminates painstaking rule con-\nstruction because it readily offers a list of words\napplicable in the context. As illustrated in Figure 1,\nall Alice and Bob have to share is the masking and\nencoding strategies in addition to the masked LM.\nIn our experiments, we showed that the proposed\nmethod had a high payload capacity for an edit-\nbased model. As expected, the amount was far\nsmaller than those of generation-based models, but\nthe proposed method offers better control of the se-\ncurity/payload capacity trade-off. We also demon-\nstrated that it was more secure against automatic\ndetection than a generation-based method although\nit was rated slightly lower by human adversaries.\nOur code is available at https://github.com/ku-\nnlp/steganography-with-masked-lm.\n2 Proposed Method\n2.1 Masked LM\nThe essential ingredient of the proposed edit-based\nstegosystem is a masked LM. It was ﬁrst intro-\nduced along with BERT (Devlin et al., 2019) as an\neffective pretraining strategy for the Transformer-\nbased (Vaswani et al., 2017) neural net. The pre-\ntrained model is usually ﬁne-tuned on downstream\ntasks, but for our purpose we keep it intact.\nGiven a text in which some tokens were replaced\nwith the special token [MASK], the masked LM is\ntrained to recover the original tokens based only on\ntheir context. As a result of the training, it provides\na probability distribution over the vocabulary for\neach masked token according to the applicability in\nthe given context. Note that high probability items\nare not necessarily synonymous with the original\ntokens but nevertheless ﬁt into the context.\nOur key insight is that we can use these probabil-\nity distributions to encode a secret message in the\nform of a bit sequence. As shown in Figure 1, Alice\nand Bob share some encoding strategywith which\nbit chunks are assigned to some high probability\nitems. Alice creates a stego text by choosing items\nthat correspond to the secret message. Bob in turn\ndecodes the secret message by selecting bit chunks\nthat correspond to each token in the stego text. The\nonly remaining requirement for Alice is to share\nsome masking strategywith Bob in advance so that\nBob can correctly identify the tokens to be masked.\n2.2 Masking Strategy\nWe have various design choices for masking and\nencoding strategies, which affect both security and\npayload capacity. For masked LM training, BERT\nrandomly masked about 15% of tokens in the input,\nbut we need to ensure that both Alice and Bob mask\n5488\nthe same tokens. In this paper, we present a simple\nstrategy. As a general rule, we mask every one in\nf tokens in the input, but we skip tokens if they\nmatch any of the following criteria:\n1. A punctuation or number.\n2. A stopword.\n3. A non-initial subword, which BERT’s stan-\ndard tokenizer marks with the initial “##”.\nEditing subwords is dangerous because there is no\n100 percent guarantee that Bob’s subword tokeniza-\ntion reproduces Alice’s original segmentation. For\nexample, if “##break” in the word “un ##break\n##able” is replaced with “#us”, the subword tok-\nenizer would segment the new word into “un ##us-\nable”, distorting the masking positions. We will\nrevisit this problem in Section 3.4.\nThe hyperparameter f is expected to control the\nsecurity/payload capacity trade-off. A large f low-\ners the payload capacity but is likely to increase the\ndifﬁculty of detection. We also anticipate that since\nthe tokens we decide to skip do not have many\ngood alternatives, not masking them is good for the\nstego text quality.\n2.3 Encoding Strategy\nWe use block encoding for simplicity. For each\nmasked token, we select and sort items whose prob-\nabilities are greater than p. To avoid distorting\nmasking positions, we drop items that are to be\nskipped in the masking phase. Let nbe the largest\ninteger that satisﬁes 2n ≤c, where cis the number\nof the remaining items. Each item is given a unique\nbit chunk of size n. Coding is an active research\ntopic (Dai and Cai, 2019; Ziegler et al., 2019; Shen\net al., 2020) and is orthogonal to our core proposal.\n3 Experiments\nWe tested the proposed method with several conﬁg-\nurations and compared it with a generation-based\nmethod. To assess security, we employed automatic\ndiscriminators and human adversaries.\n3.1 Models and Data\nBERT For the proposed edit-based method, we\nused BERT (Devlin et al., 2019) as the masked LM.\nSpeciﬁcally, we used Google’sBERTBase, Cased\nmodel and Hugging Face’stransformers pack-\nage (Wolf et al., 2020) with default settings. Given\na random bit sequence as the secret message and\na paragraph as the cover text, the model encoded\nbit chunks on a sentence-by-sentence basis. When\nthe bit chunks reached the end of the secret mes-\nsage, the process was terminated, discarding the\nremaining sentences in the given paragraph. The\nlast bit chunk usually exceeded the limit, and the\nremainder was ﬁlled with zeros.\nGPT-2 Ziegler et al. (2019) built a state-of-the-\nart generation-based model on top of the GPT-2\nneural LM (Radford et al., 2019). We used their\noriginal implementation1 to encode random bit se-\nquences. We set the option finish_sent to true\nto avoid terminating generation at the middle of\na sentence. We tested the temperature parameter\nτ = {0.4,0.7,1.0}. Since the generation was con-\nditioned on context sentences, we supplied the ﬁrst\nthree sentences of a paragraph.\nData We extracted paragraphs from the English\npart of the CC-100 dataset (Wenzek et al., 2020)\nand used them as the cover texts for BERT and as\nthe contexts for GPT-2.2 For each stegosystem, we\nalso extracted texts that were comparable to the\ncorresponding stego texts in terms of length. We\nrefer to them as real texts.\n3.2 Automatic Detection\nWe trained discriminators to distinguish stego texts\nfrom real texts. This corresponds to a situation\nunusually favorable to Eve as she has access to\nlabeled data, though not to secret messages. A\npractical reason for this is that after all, we cannot\nbuild discriminators without training data. Besides,\na stegosystem’s performance is deemed satisfactory\nif it manages to fool the discriminator even under\nsuch disadvantageous conditions.\nFor each stegosystem, we ﬁne-tuned the same\nBERTBase, Cased model on the binary classiﬁca-\ntion task. The details are explained in Appendix A.\n3.3 Human Evaluation\nWe asked Amazon Mechanical Turk3 workers to\ngive 5-point scale ratings on the stego and real\n1https://github.com/harvardnlp/NeuralSteganography\n2Ziegler et al. (2019) used the CNN/Dailymail (Hermann\net al., 2015; Nallapati et al., 2016) as the contexts. We found,\nhowever, that the resulting stego texts were excessively easy\nfor automatic discriminators to distinguish from real news\narticles, presumably due to domain mismatch with a web\ncorpus on which GPT-2 had been trained. That is why we\nchose CC-100, a web corpus, in our experiments. Note that\nthis setting may have worked slightly against the proposed\nmethod because BERT was mainly trained on Wikipedia.\n3https://www.mturk.com/\n5489\nModel Parameters Bits/word ↑ Acc ↓\nBERT f = 3\np= 0.02 0.204 0.586\nGPT-2 τ = 1.0 1.67 0.819\nTable 1: Results of automatic detection.\n0.0 0.1 0.2 0.3 0.4 0.5\nBits/word\n0.5\n0.6\n0.7\n0.8Accuracy\nf = 2\nf = 3\nf = 4\nFigure 2: The effect of the masking interval f.\ntexts according to naturality and correctness. Since\nwe found a consistent bias toward shorter texts,\nwe tuned each stegosystem’s hyperparameters to\ngenerate stego texts with comparable length. The\ndetails are explained in Appendix B.\n3.4 Results\nTable 1 shows the result of automatic detection.\nAs expected, the proposed method, BERT, had a\nmuch lower payload capacity than the generation-\nbased GPT-2 although it was high for an edit-based\nmethod. In practical situations, however, security\nis given priority over payload capacity. In this\nrespect, BERT’s performance was remarkable as\nits stego texts were nearly indistinguishable from\nreal texts. By contrast, GTP-2’s stego texts were\neasily detectable for the discriminator even though\nthey were much shorter than BERT’s.\nFigure 2 shows the effect of the masking interval\nparameter f, with p = 0.02. We can observe a\nclear trade-off between the two objectives.\nFigure 3 indicates the effectiveness of the mask\nskipping heuristics explained in Section 2.2. With\nf = 4 and p = 0.02, masking stopwords and\nsubwords not only raised detection accuracy but\nalso lowered payload capacities. Because these\ntokens did not have many good alternatives, they\nconsumed only small bit chunks and simply dam-\naged the stego text quality.\nAs we brieﬂy discussed in Section 2.2, editing\nsubwords may cause distortion in mask positions,\nleading to decoding failures. We quantiﬁed the risk,\nwith the hyperparameter settings of p= 0.02 and\nf = 3. We found that 1.41% of the masked tokens\n0.00 0.05 0.10 0.15 0.20 0.25\nBits/word\n0.50\n0.55\n0.60\n0.65\n0.70Accuracy\n Base\n+stopwords\n+stopwords,\nsubwords\nFigure 3: The effect of mask skipping heuristics. The\nplus sign indicates that the model stops skipping the\nspeciﬁed class of tokens.\n0.0 0.1 0.2 0.3 0.4 0.5\nBits/word\n0.50\n0.55\n0.60\n0.65\n0.70Accuracy\np = 0.005\np = 0.01\np = 0.02\nFigure 4: The effect of the probability threshold p.\nhad substitution candidates that did not reproduce\nthe original segmentations. Although this danger\napplies equally to generation-based steganography\nbuilt on top of subword LMs (Dai and Cai, 2019;\nZiegler et al., 2019; Shen et al., 2020), to our knowl-\nedge, we are the ﬁrst to point it out.\nFigure 4 shows the effect of the probability\nthreshold p. Lowering the threshold increases the\npayload capacity because the number of alternative\ntokens increases. It did sacriﬁce detection accuracy,\nbut not as much as we expected.\nAs for human evaluation, Table 3 summarizes\nthe results with average ratings. Overall, both meth-\nods achieved high average ratings, almost equal to\nthat of the real texts. However, BERT slightly un-\nderperformed GPT-2. We conjecture that the qual-\nity of the cover texts affected the edit-based method\nmore directly than the generation-based method.\nFollowing Ziegler et al. (2019), we initially used\nnews articles for cover/real texts but switched to\nweb texts because we noticed that the discrimina-\ntor appeared to exploit the domain mismatch with\na web corpus on which GPT-2 had been trained.\nConsidering the massive quality improvement ef-\nforts given to GPT-2’s training data, however, there\nseems to be much room to improve the quality of\nCC-100 (Wenzek et al., 2020).\nTable 2 shows good and bad stego texts produced\nby the BERT-based method. In the ﬁrst example,\nBERT successfully suggested context-aware words,\n5490\nCover text Stego text Rating\nSwitzerland also has an amazing scientiﬁc commu-\nnity that includes Geneva University and CERN,\nwhich is one of the topresearch institutes in the world\nand is home to theworld’s largest particle physicslab-\noratory.\nSwitzerland also has an international scientiﬁc com-\nmunity that includes Basel University and CERN,\nwhich is one of the top physics institutes in the world\nand is home to the world’s largest particle physics\nlaboratory.\n5.0\nAllowing local authorities to increase that charge puts\nthe negative political feedback, particularly in areas\nwhere compliance is less, like Donegal, on to the\nlocal councils and protects the central government.\nAllowing local authorities to ﬁle that charge puts\nthe negative negative feedback, particularly in areas\nwhere opposition is less, like Donegal, on to the local\ngovernment and protects the central government.\n2.8\nTable 2: Two examples of stego texts produced by the proposed edit-based method. The last column indicates\naverage ratings by crowdworkers.\nBERT GPT-2 Real texts\n4.32 ±0.97 4.43 ±0.89 4.54 ±0.78\nTable 3: The results of human evaluation. The ratings\nrange from 1 to 5, and higher is better.\ne.g. Basel for a university in Switzerland. In the\nsecond example, a single mistake, the unnatural\nrepetition of negative, had a critical impact on hu-\nman raters. Finally, we conﬁrmed that the current\nsentence-wise encoding created a risk of discrepan-\ncies between the ﬁrst and second sentences.\nEditing proper nouns like Geneva is prone to\nfactual errors. One may feel tempted to apply a\npart-of-speech tagger or a named entity tagger to\nskip proper nouns. Just like subword substitution,\nhowever, a naïve application of automatic analysis\ndoes not guarantee the sameness of the masking\npositions. A good compromise with a guarantee of\nsuccess in decoding is to skip words with capital-\nized letters. Solving this problem at its source is an\ninteresting direction for future research.\n4 Conclusions\nIn this paper, we demonstrated that the masked\nlanguage model could revolutionize edit-based lin-\nguistic steganography. The proposed method is\ndrastically simpler than existing edit-based meth-\nods, has a high payload capacity, and allows easy\ncontrol of the security/payload capacity trade-off.\nThe masked language model is a general frame-\nwork adopted by many BERT-like models, of which\nattempts to handle longer texts (Beltagy et al.,\n2020; Wang et al., 2020) are particularly relevant\nto steganography. Tailoring the training procedure\nto steganography is also an interesting research\ndirection.\nEthical Considerations\nThis paper works on steganography. Unlike cryp-\ntography, steganography conceals the fact that a\nsecret message is being transmitted as well as its\ncontents. Steganography can be just fun, but it\nusually involves a conﬂict of interest between two\nparties: those who want to censor media and those\nwho want to evade detection. Depending on value\njudgments, either one or both can be evil. Steganog-\nraphy is an effective tool to counter censorship in\ncountries where encryption is illegal and visibly\nencrypted messages may be incriminating. How-\never, it can also be used to transfer malicious data.\nAs such, steganography can be seen as a dual-use\ntechnology.\nReferences\nSahar Abdelnabi and Mario Fritz. 2020. Adversar-\nial watermarking transformer: Towards tracing text\nprovenance with data hiding. arXiv:2009.03015.\nRoss J Anderson and Fabien AP Petitcolas. 1998. On\nthe limits of steganography. IEEE Journal on Se-\nlected Areas in Communications, 16(4):474–481.\nIz Beltagy, Matthew E. Peters, and Arman Cohan.\n2020. Longformer: The long-document transformer.\narXiv:2004.05150.\nKrista Bennett. 2004. Linguistic steganography: Sur-\nvey, analysis, and robustness concerns for hiding in-\nformation in text. Technical report, Center for Ed-\nucation and Research in Information Assurance and\nSecurity, Purdue University.\nIgor A. Bolshakov. 2005. A method of linguistic\nsteganography based on collocationally-veriﬁed syn-\nonymy. In Information Hiding, pages 180–191,\nBerlin, Heidelberg. Springer Berlin Heidelberg.\nChing-Yun Chang and Stephen Clark. 2014. Practical\nlinguistic steganography using contextual synonym\nsubstitution and a novel vertex coding method.Com-\nputational Linguistics, 40(2):403–448.\n5491\nMark Chapman, George I. Davida, and Marc Rennhard.\n2001. A practical and effective approach to large-\nscale automated linguistic steganography. In Infor-\nmation Security, pages 156–165, Berlin, Heidelberg.\nSpringer Berlin Heidelberg.\nFalcon Dai and Zheng Cai. 2019. Towards near-\nimperceptible steganographic text. In Proceedings\nof the 57th Annual Meeting of the Association for\nComputational Linguistics, pages 4303–4308, Flo-\nrence, Italy. Association for Computational Linguis-\ntics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers),\npages 4171–4186, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\nTina Fang, Martin Jaggi, and Katerina Argyraki. 2017.\nGenerating steganographic text with LSTMs. In\nProceedings of ACL 2017, Student Research Work-\nshop, pages 100–106, Vancouver, Canada. Associa-\ntion for Computational Linguistics.\nJessica Fridrich. 2009. Steganography in digital me-\ndia: principles, algorithms, and applications. Cam-\nbridge University Press.\nKarl Moritz Hermann, Tomas Kocisky, Edward Grefen-\nstette, Lasse Espeholt, Will Kay, Mustafa Suleyman,\nand Phil Blunsom. 2015. Teaching machines to read\nand comprehend. In Advances in Neural Informa-\ntion Processing Systems, volume 28, pages 1693–\n1701. Curran Associates, Inc.\nDaphne Ippolito, Daniel Duckworth, Chris Callison-\nBurch, and Douglas Eck. 2020. Automatic detec-\ntion of generated text is easiest when humans are\nfooled. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 1808–1822, Online. Association for Computa-\ntional Linguistics.\nDiederik P. Kingma and Jimmy Ba. 2017.\nAdam: A method for stochastic optimization.\narXiv:1412.6980.\nRamesh Nallapati, Bowen Zhou, Cicero dos Santos,\nÇa˘glar GuÌ‡lçehre, and Bing Xiang. 2016. Abstrac-\ntive text summarization using sequence-to-sequence\nRNNs and beyond. In Proceedings of The 20th\nSIGNLL Conference on Computational Natural Lan-\nguage Learning, pages 280–290, Berlin, Germany.\nAssociation for Computational Linguistics.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners.\nJiaming Shen, Heng Ji, and Jiawei Han. 2020. Near-\nimperceptible neural linguistic steganography via\nself-adjusting arithmetic coding. In Proceedings of\nthe 2020 Conference on Empirical Methods in Natu-\nral Language Processing (EMNLP), pages 303–313,\nOnline. Association for Computational Linguistics.\nGustavus J Simmons. 1984. The prisoners’ problem\nand the subliminal channel. In Advances in Cryptol-\nogy, pages 51–67. Springer.\nCuneyt M. Taskiran, Umut Topkara, Mercan Topkara,\nand Edward J. Delp. 2006. Attacks on lexical nat-\nural language steganography systems. In Security,\nSteganography, and Watermarking of Multimedia\nContents VIII, volume 6072, pages 97–105. Interna-\ntional Society for Optics and Photonics, SPIE.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems, volume 30, pages 5998–6008. Cur-\nran Associates, Inc.\nSinong Wang, Belinda Z. Li, Madian Khabsa, Han\nFang, and Hao Ma. 2020. Linformer: Self-attention\nwith linear complexity. arXiv:2006.04768.\nGuillaume Wenzek, Marie-Anne Lachaux, Alexis Con-\nneau, Vishrav Chaudhary, Francisco Guzmán, Ar-\nmand Joulin, and Edouard Grave. 2020. CCNet:\nExtracting high quality monolingual datasets from\nweb crawl data. In Proceedings of the 12th Lan-\nguage Resources and Evaluation Conference, pages\n4003–4012, Marseille, France. European Language\nResources Association.\nAlex Wilson and Andrew D. Ker. 2016. Avoiding de-\ntection on twitter: embedding strategies for linguis-\ntic steganography. Electronic Imaging, 2016(8):1–\n9.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art natural language process-\ning. In Proceedings of the 2020 Conference on Em-\npirical Methods in Natural Language Processing:\nSystem Demonstrations, pages 38–45, Online. Asso-\nciation for Computational Linguistics.\nZhong-Liang Yang, Xiao-Qing Guo, Zi-Ming Chen,\nYong-Feng Huang, and Yu-Jin Zhang. 2019. RNN-\nStega: Linguistic steganography based on recurrent\nneural networks. IEEE Transactions on Information\nForensics and Security, 14(5):1280–1295.\nZachary Ziegler, Yuntian Deng, and Alexander Rush.\n2019. Neural linguistic steganography. In Proceed-\nings of the 2019 Conference on Empirical Methods\n5492\nin Natural Language Processing and the 9th Inter-\nnational Joint Conference on Natural Language Pro-\ncessing (EMNLP-IJCNLP), pages 1210–1215, Hong\nKong, China. Association for Computational Lin-\nguistics.\nA Details of Automatic Detection\nThe edit-based and generation-based methods dif-\nfer considerably in the amount of text needed to\nencode a secret message because the latter has a\nhigher payload capacity by design. For a fair com-\nparison, we chose to encode bit sequences of equal\nsize, meaning that the proposed method yielded\nlonger stego texts. Speciﬁcally, we used random\n32-bit sequences. The sequence of sentences was\ngiven to the discriminator at once. For GPT-2, we\ndiscarded the contexts and only fed stego texts into\nthe discriminator.\nFor the binary classiﬁcation task, we prepared\nthe training, development and test sets with 8,000,\n1,000, and 1,000 paragraphs, respectively. Each set\nhad the same amount of stego and real texts, and\nthey were comparable with respect to length. The\ndiscriminators were trained for 20 epochs, with the\nbatch size of 32. We applied early stopping if the\nvalidation loss did not drop ﬁve times in a row. The\nmodel snapshots were saved for every 250 steps,\nand the one with the lowest validation loss was\nchosen. We used Adam (Kingma and Ba (2017))\nas the optimizer with the learning late of 10−6.\nB Details of Human Evaluation\nFor the proposed edit-based method, we used the\nsame masking and encoding strategies used for\nautomatic detection. The hyperparameters were\nas follows: p = 0.02, and f = 4, stopwords and\nsubwords were skipped. We used random 6-bit\nsequences as secret messages.\nFor the generation-based method, the tempera-\nture parameter τ was set to 0.7. We used random\n45-bit sequences as secret messages.\nWe designed a MTurk HIT (human intelligence\ntask) following Abdelnabi and Fritz (2020). Work-\ners were asked to rate texts (each question had\n5 texts) with a Likert scale from 1 (lowest) to 5\n(highest). As shown in Table 4, the ratings were\ndescribed with the instructions ranging from “This\nsentence is completely understandable, natural,\nand grammatically correct”to “This sentence is\ncompletely not understandable, unnatural, and you\ncannot get its main idea”. Each HIT had 5 texts,\nwith stego texts from both methods and real texts\nRating Description\n5 The text is understandable, natural,\nand grammatically and structurally\ncorrect.\n4 The text is understandable, but it con-\ntains minor mistakes.\n3 The text is generally understandable,\nbut some parts are ambiguous.\n2 The text is mainly not understandable,\nbut you can get the main ideas.\n1 The text is completely not understand-\nable, unnatural, and you cannot get\nthe main ideas.\nTable 4: Ratings explanations given in the human eval-\nuation.\nof comparable length appearing in a random order.\nThe questions also had a simple attention check\nand if the answer to the attention check was wrong,\nthe corresponding HIT was discarded. We have set\nthe reward per assignment at $0.3.\nWe observed that human raters strongly favored\nshorter texts. To verify the observation, we per-\nformed linear regression analysis with the number\nof words as a parameter. We found that it indeed\nhad a statistically signiﬁcant negative impact on\nthe ratings with p< 10−3 for the t-statistic."
}