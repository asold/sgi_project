{
    "title": "CHATBOT USING LARGE LANGUAGE MODEL",
    "url": "https://openalex.org/W4396889529",
    "year": 2024,
    "authors": [
        {
            "id": null,
            "name": "Department of Artificial Intelligence and Machine Learning  Sri Shakthi Institute of Engineering and Technology Coimbatore,India",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A5101353311",
            "name": "Mr.DHANUSH B",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4384389802",
        "https://openalex.org/W4293193852",
        "https://openalex.org/W3084179455",
        "https://openalex.org/W2994392280",
        "https://openalex.org/W3158308652"
    ],
    "abstract": "The concept of Natural Language Processing has seen a remarkable advancement in the recent years. This remarkable advancement was particularly with the development of Large Language Models (LLM). Large Language Models are used to develop a human like conversations. This LLM is a part of Natural Language Processing which focuses on enabling computers to understand, interpret, and generate human language. The existing system of chatbots does not generate human like responses. The proposed system of chatbots uses the power of Large Language Models to generate more human like responses, providing the conversation in a natural way. By genereating human like respones, it will be in a natural way for the user. To enhance user experience, the chatbot uses a dynamic learning mechanism, by which it continuously adapt to user preferences and evolving conversational patterns. This system uses feedbacks from the users to refine its responses everytime.Moreover, the chatbot is designed with a multi-turn conversational context awareness, allowing it to maintain coherence and relevance throughout extended dialogues.The effectiveness of the proposed chatbot is evaluated through user testing, comparing its performance against traditional rule-based chatbots and existing conversational agents. This report explains about the usage of Large Language Models in the design and implementation of conversational chatbots. The outcomes of this research contribute to the advancement of intelligent chatbot systems, demonstrating the potential of large language models to significantly enhance conversational AI applications.",
    "full_text": "          International Journal of Scientific Research in Engineering and Management (IJSREM) \n                        Volume: 08 Issue: 05 | May - 2024                         SJIF Rating: 8.448                                    ISSN: 2582-3930                                                                                                                                               \n \n¬© 2024, IJSREM      | www.ijsrem.com                               DOI: 10.55041/IJSREM34001               |        Page 1 \nCHATBOT USING LARGE LANGUAGE MODEL \n \nMr.DHANUSH B \nDepartment of  \nArtificial Intelligence and \nMachine Learning \nSri Shakthi Institute of  \nEngineering and Technology \nCoimbatore,India \n \nMr.PRAGATHEESWARAPANDI \nG \nDepartment of  \nArtificial Intelligence and \nMachine Learning \nSri Shakthi Institute of  \nEngineering and Technology \nCoimbatore,India \n \nMr.GOPINATH S \nDepartment of  \nArtificial Intelligence and \nMachine Learning \nSri Shakthi Institute of  \nEngineering and Technology \nCoimbatore,India \n \nMr.VIJAYAPRADHAP P \nDepartment of  \nArtificial Intelligence and \nMachine Learning \nSri Shakthi Institute of  \nEngineering and Technology \nCoimbatore,India \n \n \nMr.V ARSHIK DANIEL L \nDepartment of  \nArtificial Intelligence and \nMachine Learning \nSri Shakthi Institute of  \nEngineering and Technology \nCoimbatore,India \n \nMs.NIVEDHA S \nAssistant Professor \nDepartment of  \nArtificial Intelligence and \nMachine Learning \nSri Shakthi Institute of  \nEngineering and Technology \nCoimbatore,India\n \n \n \n    \n    Abstract- The concept of Natural Language Processing \nhas seen a remarkable advancement in the recent years. \nThis remarkable advancement was particularly with the \ndevelopment of Large Language Models (LLM). Large \nLanguage Models are used to develop a human like \nconversations. This LLM is a part of Natural Language \nProcessing which focuses on enabling computers to \nunderstand, interpret, and generate human language. The \nexisting system of chatbots does not generate human like \nresponses. The proposed system  of chatbots uses the \npower of Large Language Models to generate more \nhuman like responses, providing the conversation in a \nnatural way. By genereating human like respones, it will \nbe in a natural way for the user. To enhance user \nexperience, the chatbot u ses a dynamic learning \nmechanism, by which it continuously adapt to user \npreferences and evolving conversational patterns. This \nsystem uses feedbacks from the users to refine its \nresponses everytime.Moreover, the chatbot is designed \nwith a multi -turn conve rsational context awareness, \nallowing it to maintain coherence and relevance \nthroughout extended dialogues.The effectiveness of the \nproposed chatbot is evaluated through user testing, \ncomparing its performance against traditional rule-based \nchatbots and ex isting conversational agents. This report \nexplains about the usage of Large Language Models in the \ndesign and implementation of conversational chatbots. \nThe outcomes of this research contribute to the \nadvancement of intelligent chatbot systems, \ndemonstrating the potential of large language models to \nsignificantly enhance conversational AI applications.  \n \nINTRODUCTION \n         The evolution of Artificial Intelligence (AI) and \nNatural Language Processing (NLP) has witnessed a \ntransformative breakthrough with the development of \nLarge Language Models (LLMs). Large Language Model \nrepresents an advanced language model that undergoes \ntraining on an extensive corpus of text data. The existing \nsystem of chatbots are like Traditional chatbots which \ngenerates responses in a more machine like way. It will be \nlike asking questions to a machine, by which the user \nwould get bored. To generate the responses in a more \nnatural way, in the proposed system we use the power of \nLLMs to generate human like responses.By using deep \nlearning techniques, Large Language Models can produce \nhuman-like text, making them highly versatile for a range \nof applications. These include text completion, language \ntranslation, sentiment analysis, and much more. Currently \nthere are some challenges and limitations in chatbots. \nInitially in the process, we have to define intents and \ncollect details.  As the number of intent s increases, \n          International Journal of Scientific Research in Engineering and Management (IJSREM) \n                        Volume: 08 Issue: 05 | May - 2024                         SJIF Rating: 8.448                                    ISSN: 2582-3930                                                                                                                                               \n \n¬© 2024, IJSREM      | www.ijsrem.com                               DOI: 10.55041/IJSREM34001               |        Page 2 \nmanaging and disambiguating them becomes difficult. To \novercome these challenges, Large Language \nModels.Large language models (LLMs) provide a new \nway to build chatbots by accepting natural language \nprompts. Yet, it is unclear how to design prompts to power \nchatbots to carry on naturalistic conversations while \npursuing a given goal such as collecting self -report data \nfrom users. We explore what design factors of prompts can \nhelp steer chatbots to talk naturally and collect.  \n \n \nLITERATURE REVIEW \nWe propose MPC (ModularPrompted Chatbot), a \nnew approach for creating high -quality conversational \nagents withoutthe need for fine -tuning. Our method \nutilizespre-trained large language models (LLMs) as \nindividual modules for long -term consistencyand \nflexibility, by using techniques such as fewshot \nprompting, chain-of-thought (CoT), andexternal memory. \nOur human evaluation results show that MPC is on par \nwith fine -tunedchatbot models in open -domain \nconversations,making it an effective solution for creating \nconsistent and engaging chatbots. Large language models \n(LLMs) provide a new way to build chatbots by accepting \nnatural language prompts.Yet, it is unclear how to design \nprompts to power chatbots to carry on naturalistic \nconversations while pursuing a given goal such as \ncollecting self-report data from users. We explore what \ndesign factors of prompts can help steer chatbots to talk \nnaturally and collect data reliably. To this aim, we \nformulated four prompt designs with different structures \nand personas. Throu gh an online study ( ùëÅ = 48) where \nparticipants conversed withchatbots driven by different \ndesigns of prompts, we assessed how prompt designs and \nconversation topics affected theconversation flows and \nusers‚Äô perceptions of chatbots. Our chatbots covered 79% \nof the desired. Large language models (LLMs) provide a \nnew way to build chatbots by accepting natural language \nprompts. Yet, it is unclear how to design prompts to power \nchatbots to carry on naturalistic conversations while \npursuing a given goal, such as collecting self -report data \nfrom users. We explore what design factors of prompts \ncan help steer chatbots to talk naturally and collect data \nreliably. To this aim, we formulated four prompt designs \nwith different structures and personas. Through an online \nstudy (N = 48) where participants conversed with chatbots \ndriven by different designs of prompts, we assessed how \nprompt designs and conversation topics affected the \nconversation flows and users' perceptions of chatbots. Our \nchatbots covered 79% of the desired information slot s \nduring conversations, and the designs of prompts and \ntopics significantly influenced the conversation flows and \nthe data collection performance.One of the major \ndrawbacks of modularized task -completion dialogue \nsystemsis that each module is trained individually, which \npresents several challenges.For example, downstream \nmodules are affected by earlier modules, and the \nperformance of the entire system is not robust to the \naccumulated errors. This paper presents a novel end -to-\nend learning framework for task -completion dialogue \nsystems to tackle such issues. Our neural dialogue system \ncan directly interact with a structured database to assist \nusers in accessing information and accomplishing certain \ntasks. The reinforcement learning based dialogue manager \noffers robust capabilities to handle noises caused by other \ncomponents of the dialogue system. Our experiments in a \nmovie-ticket booking domain show that our end -to-end \nsystem not only outperforms modularized dialogue \nsystem baselines for both objective and su bjective \nevaluation, but also is robust to noises as demonstrated by \nseveral systematic experiments with different error \ngranularity and rates specific to the language \nunderstanding module. \n \n  EXISTING SYSTEM \n             Developed by OpenAI, GPT -3 is one of the most \npowerful and widely known language models. It has been \nused to create chatbots that can engage in conversations, \nanswer questions, and generate human -like text. Based \non the GPT -3 architecture, ChatGPT is a specific \nimplementation that demonstrates the conversational \ncapabilities of large language models. It can be used for \na wide range of applications, from natural language \nunderstanding to creative writing.  Rasa, an open-source \nconversational AI platform, can be integrated with large \nlanguage models for advanced natural language \nunderstanding. This allows developers to leverage the \npower of these models within the Rasa framework for \nbuilding chatbots. Microsoft's Bot Framework can be \nenhanced with the use of large language models to \nimprove the conversational abilities of chatbots built on \nthe platform. \n \n   PROPOSED SYSTEM \n                 The proposed application involves integrating a \nlarge language model with extensive  knowledge to \ncreate a chatbot capable of providing accurate and \ncontext-aware information on organization -related \n          International Journal of Scientific Research in Engineering and Management (IJSREM) \n                        Volume: 08 Issue: 05 | May - 2024                         SJIF Rating: 8.448                                    ISSN: 2582-3930                                                                                                                                               \n \n¬© 2024, IJSREM      | www.ijsrem.com                               DOI: 10.55041/IJSREM34001               |        Page 3 \nqueries. The chatbot could assist users in understanding \nquestions. A proposed educational chatbot could \nleverage a large language model to offer personalized \ntutoring. It would adapt to individual learning styles, \nanswer questions across various subjects, and provide \nexplanations in a manner similar to human tutors. \nIntegrating a large language model with legal expertise \ncould result in a chatbot capable of analyzing legal \ndocuments, answering legal queries, and providing \ninsights into complex legal scenarios.  \n    \n    HARDWARE REQUIREMENTS \n‚Ä¢ High Performance GPU \n‚Ä¢ High Performance CPU \n‚Ä¢ Large Memory (RAM) \n‚Ä¢ Storage \n   SOFTWARE REQUIREMENTS \n‚Ä¢ Deep Learning Frameworks \n‚Ä¢ CUDA and cuDNN \n‚Ä¢ Distributed Computing Tools     \nDESIGN \nPREPARING DATASET \n                 The JSON dataset is a JSON document, \nwhich includes metadata, such as column names and \ntypes, as well as the dataset name. Since it has a \nnormalized and well-known structure, it can be used to \nreturn data in a predictable Format, for example, when \nbuilding REST APIs in Etlworks Integrator.To create a \nnew JSON Data Set Format, go to Connections, select \nFormats tab, click Add Format, type in json data set in \nthe search field, and select JSON Data Set. Note that it \nis not the same as JSON. Dat aset-JSON was adapted \nfrom the Dataset -XML Version 1.0 specification but \nuses JSON format. Like Dataset -XML, each Dataset -\nJSON file is connected to a Define -XML file that \ncontains detailed information about the \nmetadata.JavaScript Object Notation (JSON) is  a \nstandard text-based format for representing structured \ndata based on JavaScript object syntax. It is commonly \nused for transmitting data in web applications (e.g., \nsending some data from the server to the client, so it can \nbe displayed on a web page, or vice versa). \n \nTOKENIZATION \n                   Tokenization, in the realm of Natural \nLanguage Processing (NLP) and machine learning, \nrefers to the process of converting a sequence of text into \nsmaller parts, known as tokens. These tokens can be as \nsmall as characters or as long as wo rds. The primary \nreason this process matters is that it helps machines \nunderstand human language by breaking it down into \nbite-sized pieces, which are easier to analyze.The \nprimary goal of tokenization is to represent text in a \nmanner that's meaningful for  machines without losing \nits context. By converting text into tokens, algorithms \ncan more easily identify patterns. This pattern \nrecognition is crucial because it makes it possible for \nmachines to understand and respond to human input. \nFor instance, when a machine encounters the w ord \n\"running\", it doesn't see it as a singular entity but rather \nas a combination of tokens that it can analyze and derive \nmeaning from. \n \nLEMMATIZATION \n                    Lemmatization is the process of grouping \ntogether different inflected forms of the same word. It's \nused in computational linguistics, natural language \nprocessing (NLP) and chatbots. Lemmatization links \nsimilar meaning words as one word, making tools such \nas chatbots and search engine queries more effective and \naccurate.The goal of lemmatization is to reduce a word \nto its root form, also called a lemma. For example, the \nverb \"running\" would be identified as \"run.\" \nLemmatization studies the morphological, or structural, \nand contextual analysis of words.To correctly identify a \nlemma, tools analyze the context, meaning and the \nintended part of speech in a sentence, as well as the word \nwithin the larger context of the surrounding sentence, \nneighboring sentences or even the entire document. \nWith this in -depth understanding, tools that use \nlemmatization can better understand the meaning of a \nsentence. \n \nBAG OF WORDS \n                      Bag of words is a Natural Language \nProcessing technique of text modelling. In technical \nterms, we can say that it is a method of feature extraction \nwith text data. This approach is a simple and flexible \n          International Journal of Scientific Research in Engineering and Management (IJSREM) \n                        Volume: 08 Issue: 05 | May - 2024                         SJIF Rating: 8.448                                    ISSN: 2582-3930                                                                                                                                               \n \n¬© 2024, IJSREM      | www.ijsrem.com                               DOI: 10.55041/IJSREM34001               |        Page 4 \nway of extracting features from documents.A bag of \nwords is a representation of text that describes the \noccurrence of words within a document. We just keep \ntrack of word counts and disregard the grammatical \ndetails and the word order. It is called a ‚Äúbag‚Äù of words \nbecause any information about the order or structure of \nwords in the document is discarded. The model is only \nconcerned with whether known words occur in the \ndocument, not where in the document. \n \nPREDICTION \n                       There are a number of approaches to text \nprediction. In other articles I‚Äôve covered Multinomial \nNaive Bayes and Neural Networks.One of the simplest \nand most common approaches is called ‚ÄúBag of \nWords.‚ÄùThe approach is relatively simple: given a set of \ntopics and a set of terms a ssociated with each topic, \ndetermine which topic(s) exist within a document (for \nexample, a sentence).While other, more exotic \nalgorithms also organize words into ‚Äúbags,‚Äù in this \ntechnique we don‚Äôt create a model or apply mathematics \nto the way in which th is ‚Äúbag‚Äù intersects with a \nclassified document. A document‚Äôs classification will \nbe polymorphic, as it can be associated with multiple \ntopics. \n \nFLOWCHART \n \n \n \nRESULT \n \n \n \n \n \nCONCLUSION \nThe integration of Large Language \nModels (LLMs) into chatbot frameworks represents a \nsignificant advancement in the search for more natural, \ncontext-aware, and engaging conversational interfaces. \nAs we overcome certain challenges and limitations in \nthis study, some takeaways emerge.The key takeaway is \nthe usage of Large Laguage Model in this proposed \nsystem of chatbot has helped to overcome the challenge \nand limitation of increased number of intents. This Large \nLanguage Model has also made the chatbot to ge nerate \nhuman like responses.The next generation of Language \nModel Systems (LLMs) and LLM chatbots are expected \nto offer improved accuracy, expanded language support, \nenhanced computational efficiency, and seamless \nintegration with emerging technologies. Th ese \nadvancements indicate a higher level of versatility and \npracticality compared to the previous models.Recent \nstrides in LLMs have been remarkable, and their future \nappears even more promising. Although we may not be \nfully prepared, the future is already  unfolding, \ndemanding our adaptability to embrace the opportunities \nit presents. \n \nREFERENCES \n[1] Humza Naveed,Asad Ullah Khan1,Shi Qiu \"A \nComprehensive Overview of Large Language \nModels\" for researching large language models \n[2] Wanli Xing,Andrew Lan,Scott Crossley\"Special \nIssue on the Use of Large Language Models in \nEducation\" for detailed resarch on LLM's. \n[3] Chiara Valentina Misischia,Flora \nPoecze,Christine Strauss\"Chatbots in customer \nservice: Their relevance and impact on service \nquality\" for refrence for chatbot. \n[4] Andr√© S. Abade, Paulo Afonso Ferreira and \nFl√°vio de Barros Vidal ‚ÄúPlant diseases recognition on \nimages using convolutional neural networks: a \nsystematic review‚Äù. \n[5] Nuria Haristiani\"Artificial Intelligence (AI) \nChatbot as Language Learning Medium: An \ninquiry\" on how AI helps chatbot. \n \n"
}