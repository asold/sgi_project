{
    "title": "Can language models automate data wrangling?",
    "url": "https://openalex.org/W4310529830",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A4310530245",
            "name": "Gonzalo Jaimovitch-Lopez",
            "affiliations": [
                "Universitat Politècnica de València"
            ]
        },
        {
            "id": "https://openalex.org/A2170579254",
            "name": "Cèsar Ferri",
            "affiliations": [
                "Universitat Politècnica de València"
            ]
        },
        {
            "id": "https://openalex.org/A1158908784",
            "name": "José Hernández-Orallo",
            "affiliations": [
                "Universitat Politècnica de València"
            ]
        },
        {
            "id": "https://openalex.org/A52549106",
            "name": "Fernando Martínez Plumed",
            "affiliations": [
                "Universitat Politècnica de València"
            ]
        },
        {
            "id": "https://openalex.org/A2560476870",
            "name": "Maria-Jose Ramirez-Quintana",
            "affiliations": [
                "Universitat Politècnica de València"
            ]
        },
        {
            "id": "https://openalex.org/A4310530245",
            "name": "Gonzalo Jaimovitch-Lopez",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2170579254",
            "name": "Cèsar Ferri",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1158908784",
            "name": "José Hernández-Orallo",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A52549106",
            "name": "Fernando Martínez Plumed",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2560476870",
            "name": "Maria-Jose Ramirez-Quintana",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2305848008",
        "https://openalex.org/W3083607226",
        "https://openalex.org/W4206165574",
        "https://openalex.org/W3133702157",
        "https://openalex.org/W6680532216",
        "https://openalex.org/W2103086259",
        "https://openalex.org/W3013280221",
        "https://openalex.org/W3031190654",
        "https://openalex.org/W2477228960",
        "https://openalex.org/W2162774438",
        "https://openalex.org/W2087615914",
        "https://openalex.org/W4213251046",
        "https://openalex.org/W2611064819",
        "https://openalex.org/W3136824354",
        "https://openalex.org/W6755016755",
        "https://openalex.org/W3173777717",
        "https://openalex.org/W2524620548",
        "https://openalex.org/W4237412827",
        "https://openalex.org/W2160580192",
        "https://openalex.org/W4247007654",
        "https://openalex.org/W2079557269",
        "https://openalex.org/W3083410900",
        "https://openalex.org/W3134642945",
        "https://openalex.org/W2951621897",
        "https://openalex.org/W3156789018",
        "https://openalex.org/W4310529830",
        "https://openalex.org/W2064766209",
        "https://openalex.org/W2056081083",
        "https://openalex.org/W3156470785",
        "https://openalex.org/W2010921848",
        "https://openalex.org/W6675354045",
        "https://openalex.org/W3081911854",
        "https://openalex.org/W6676014748",
        "https://openalex.org/W2100358124",
        "https://openalex.org/W3153427360",
        "https://openalex.org/W2109394932",
        "https://openalex.org/W2560177618",
        "https://openalex.org/W979215280",
        "https://openalex.org/W2293101314",
        "https://openalex.org/W7034340615",
        "https://openalex.org/W1970672099",
        "https://openalex.org/W3102095584",
        "https://openalex.org/W3082424964",
        "https://openalex.org/W4289828103",
        "https://openalex.org/W2890483089"
    ],
    "abstract": null,
    "full_text": "Vol.:(0123456789)\nMachine Learning (2023) 112:2053–2082\nhttps://doi.org/10.1007/s10994-022-06259-9\n1 3\nCan language models automate data wrangling?\nGonzalo Jaimovitch‑López1 · Cèsar Ferri1 · José Hernández‑Orallo1 · \nFernando Martínez‑Plumed1  · María José Ramírez‑Quintana1\nReceived: 25 January 2022 / Revised: 16 August 2022 / Accepted: 29 September 2022 /  \nPublished online: 1 December 2022 \n© The Author(s) 2022\nAbstract\nThe automation of data science and other data manipulation processes depend on the inte-\ngration and formatting of ‘messy’ data. Data wrangling is an umbrella term for these tedi-\nous and time-consuming tasks. Tasks such as transforming dates, units or names expressed \nin different formats have been challenging for machine learning because (1) users expect \nto solve them with short cues or few examples, and (2) the problems depend heavily on \ndomain knowledge. Interestingly, large language models today (1) can infer from very few \nexamples or even a short clue in natural language, and (2) can integrate vast amounts of \ndomain knowledge. It is then an important research question to analyse whether language \nmodels are a promising approach for data wrangling, especially as their capabilities con-\ntinue growing. In this paper we apply different variants of the language model Generative \nPre-trained Transformer (GPT) to five batteries covering a wide range of data wrangling \nproblems. We compare the effect of prompts and few-shot regimes on their results and how \nthey compare with specialised data wrangling systems and other tools. Our major finding \nis that they appear as a powerful tool for a wide range of data wrangling tasks. We provide \nsome guidelines about how they can be integrated into data processing pipelines, provided \nthe users can take advantage of their flexibility and the diversity of tasks to be addressed. \nHowever, reliability is still an important issue to overcome.\nKeywords Data science automation · Data wrangling · Language models · Machine \nlearning pipelines\nEditors: Tijl De Bie, Jose Hernandez-Orallo, Joaquin Vanschoren, Gaël Varoquaux, Chris Williams.\n * Fernando Martínez-Plumed \n fmartinez@dsic.upv.es\n Gonzalo Jaimovitch-López \n gonjailo@dsic.upv.es\n Cèsar Ferri \n cferri@dsic.upv.es\n José Hernández-Orallo \n jorallo@dsic.upv.es\n María José Ramírez-Quintana \n mramirez@dsic.upv.es\n1 VRAIN, Universitat Politècnica de València, Valencia, Spain\n2054 Machine Learning (2023) 112:2053–2082\n1 3\n1 Introduction\nData wrangling refers to repetitive and time-consuming data preparation tasks, including \nthe transformation of data presented in different formats into a standardised form for easy \naccess, understanding and analysis. The (semi-)automation of these manual and non-sys-\ntematic tasks can impact the costs of data preparation significantly. If language models (on \ntheir own or integrated within other systems) are able to solve a significant proportion of \nthese problems in the next years, the transformative effect on society and the marketplace \nwould be huge, given how widespread these formatting chores happen (from spreadsheet \nmanipulation to data science projects) (Furche et al., 2016).\nOne key difficulty of some data wrangling problems such as standardising a field into \na single format stems in the context of interaction (Terrizzano et al., 2015). For automa-\ntion to be really useful, the amount of information given by the users and their degree of \ninvolvement must be low enough so that there is a net gain in the process. For instance, \nin a standardisation of dates, the tool should be able to infer the transformation pattern \nfrom very few examples (or no examples at all), and complete the rest automatically. The \nsecond challenge for data wrangling is that data manipulation operations are very differ -\nent. One project may require the integration of measurement units from different countries, \nwhile another project may involve identifying the order of a level of studies variable col-\nlected for thousands of customers. In many cases, the domain is not very specialised. For \ninstance, in a date field, the day can be the first, second or third number, and these numbers \ncan be delimited by different symbols. However, dates happens in the myriad of different \ntransformations that we can find on the Internet or any other non-specialised source. This \nknowledge is general, but critical for data wrangling. An Artificial Intelligence (AI) system \nbased only on basic string transformations may never find the right solution given just one \nexample without domain constraints or background knowledge. For instance, the transfor -\nmations needed for dates are very different from those used for addresses or emails, but \nthese are domains generally well-known by humans.\nThere seems to be a great potential in language models (Bengio et al., 2003) for data \nwrangling precisely because they compress huge amounts of human knowledge about \nmany different domains, and have recently shown reasonably good performance in con-\ntextualising this knowledge for few-shot inference (Puri & Catanzaro, 2019; Schick & \nSchütze, 2020; Brown et al., 2020; Gao et al., 2020). It is then very important to determine \nwhether language models could be used in the future for data wrangling tasks, and whether \nthey get better as the number of parameters increase, a question subject to recent debate \n(Bender et al., 2021; Tamkin et al., 2021). The applicability of language models for the \nautomation of other parts of data science (including the machine learning pipelines) may \nalso be affected by the progress in data wrangling, especially as we move towards more \ndomain-dependent and more open-ended tasks, as shown in the quadrants of Figure 1 in De \nBie et al. (2022).\nIn this paper we test experimentally whether language models can be used to solve typi-\ncal problems in data wrangling, using different kinds of prompts. Some (few-shot) prompts \nwill have input-output examples and a single input ending the prompt, for which the lan-\nguage model will have to provide the output as a continuation of the prompt (e.g., Input: \n‘marshap@gmail.com’ /uni2216.var nOutput: ‘marshap’/uni2216.var n/uni2216.var nInput: ‘alant@hot-\nmail.com’/uni2216.var nOutput:). For the transformation datasets, we compare the inference \npower of GPT-3 with other specialised tools on a benchmark of simple data wrangling \nproblems. Other (zero-shot) prompts simply describe the question or give instructions \n2055Machine Learning (2023) 112:2053–2082 \n1 3\ndirectly, without the need of extra examples (e.g., Is (’bronze’, ‘gold’, ’sil-\nver’) an ordinal? ). A combination of few-shot and instruction-based prompts is \nalso possible, and also some fixed examples in the prompt, as we will explore.\nFor this reason many data wrangling tools not using language models combine the avail-\nable information in the examples given by the user with some domain knowledge (‘any \ninformation the learner has about the unknown transformation before seeing the exam-\nples’ Singh and Gulwani 2015), in an attempt to reduce the hypothesis space. Different \napproaches have been proposed relying on the coupling of ‘few examples’ and ‘background \nknowledge’. One of them is based on Inductive Programming Gulwani et al. (2015), learn-\ning transformations from very few examples by incorporating prior knowledge about the \ndomain in a declarative way. This domain knowledge is used to reduce the hypothesis space \nmaking the generalisation process effective even from very few examples. As this approach \nsuffers from intractability when background knowledge becomes large, the use of ad-hoc \ndomain-specific languages (DSLs) (see Cropper et al., 2015; Wu et al., 2012) restricts the \nsearch space, and has led to the first commercial products such as Microsoft Excel with \nFlashFill (Gulwani, 2011). Even with domain-specific languages, many constraints on \nthe transformations are added to make things work, or very specific collections of built-in \nfacilities or functions. For instance, Amazon SageMaker Data Wrangler1 contains over 300 \nbuilt-in data transformations. Other Data Analytics tools such as Trifacta Wrangler (Kan-\ndel et  al., 2011) even allow the user to define their own transformations. Many systems \ncombine some of these ideas or apply ad-hoc optimisations (Ham, 2013; Bhupatiraju et al., \n2017; Ellis & Gulwani, 2017; Petrova-Antonova & Tancheva, 2020; Gulwani, 2011; Singh \n& Gulwani, 2016, 2015). On the other hand, in Contreras-Ochando et al. (2019a, 2019b), \ngeneral-purpose inductive programming systems can still be employed with domain-\nspecific background knowledge that is selected or ranked from contextual information or \nmeta-features about the examples to be transformed. Still, this background knowledge has \nto be added to the system.\nWhile we will make some comparisons, it is not the goal of this paper to see for each \nand every task whether current language models are better than the specialised tools above. \nThe great advantage of language models is their versatility, and the power of dealing with \na wide ranging of data wrangling problems, provided the user (e.g., a data scientist) comes \nup with the right way of prompting the language model. It is then more important to under-\nstand how the operation with language models can be inserted into the data processing and \nanalysis pipeline, rather than just comparing what tool is best at each specific task. This \nwould not even be realistic because (1) the best prompts are not always available for gen-\neral users, especially because different prompts are needed for different tasks and (2) com-\nparing a general system against dozens of specific systems may be unfair when considering \nthe learning curves and other costs associated with dealing with these tools. Of course, the \nanalysis assumes that new generations of language models will be generally accessible and \nmore sustainable in the ratio between performance and compute. The progress and initia-\ntives in the past year (Smith et al., 2022; Reed et al., 2022; Wei et al., 2022) suggest more \ngeneralised access to powerful language models may soon become commonplace.\nTo our knowledge, this is the first paper analysing the potential of language models for \ndata wrangling systematically, 2 determining the influence of the type of data wrangling \n1 https:// aws. amazon. com/ sagem aker/ data- wrang ler/.\n2 A preliminary version of this paper, only including the manipulation battery, was presented in Jaimov -\nitch-Lopez et al. (2021).\n2056 Machine Learning (2023) 112:2053–2082\n1 3\ntask, the relevance of the semantic content, the size of the model, the type of prompt and \nthe number of examples.\nThe paper is organised as follows. Section  2 presents the problem of data wrangling in \nthe context of data science and other tasks that involve data manipulation, the diversity of \nthese tasks, a taxonomy and an analysis of the role of semantic information. Section  3 sets \nthe experimental goals, the batteries and metrics we will use (and how they correspond \nwith the taxonomy), the language models, prompts and few-shot regimes we will use. Sec-\ntion 4 discusses the results for each battery, including some examples and in some cases \ncomparisons with some other systems or baselines. Finally, Sect.  5 summarises the con-\ntributions and the limitations. It also gives some guidelines for a general use of language \nmodels in data wrangling and other data processing pipelines and closes with future work.\n2  Data wrangling: taxonomy of tasks and the role of knowledge\nMany daily tasks that involve computers entail the conversion of data from one format to \nanother, so that an application can duly digest the data. In a discipline such as data science, \nwhere data takes centre stage, this is even more so. It is widely recognised that a large pro-\nportion of the data analyst’s time will be taken up with data preparation and transformation \nchallenges appearing in messy datasets, what is generally referred to as data wrangling. \nNazabal et  al. (2020) provide a comprenhensive taxonomy of such problems into three \nmain groups: those issues related to organising the data; those related to improving the \nquality of the data; and those related to feature engineering. Each of these large groups of \ntasks is subdivided into specific tasks according to the nature of the data wrangling prob-\nlem they face (see Table 1). Under data organisation we find data parsing, data dictionary, \ndata integration and data transformation tasks, all focused on obtaining the best data rep-\nresentation for the tasks to be solved. Data quality tasks include canonicalisation, missing \ndata, anomalies and non-stationarity tasks related to cleaning corrupted entries in the data. \nFinally, feature engineering is a more diverse group that includes a more diverse range of \noperation with the features, from simple combinations and non-linear mappings to more \nsophisticated operations, such as embeddings.\nHowever, what determines whether a particular data wrangling task is a candidate for \nautomation by language models? To approach this question we have to know what lan-\nguage model are and what type of interface we have with them. Language models are con-\nceptually simple systems: they estimate the probability p(y|x) of a given sequence of char -\nacters or tokens y following another sequence x, in the spirit of efficient coding (Shannon, \n1949). Today, these models are usually based on large deep learning architectures such as \ntransformers (attention-based architectures, Vaswani et  al., 2017), but they still estimate \nthis same probability. They are trained over massive natural language corpora and hence \nexploit the extrinsic patterns borrowed from humans. However, beyond making plausible \ncontinuations following the inputs (the so-called ‘prompts’), or as part of this capability, \nrecent systems such as BERT (Devlin et al., 2018), GPT-2 (Radford et al., 2019), GPT-3 \n(Brown et al., 2020), and PanGu- /u1D6FC (Zeng et al., 2021) can also be employed as ‘few-shot \nlearners’, trying to exploit intrinsic patterns in the prompt. Few-shot inference happens \nwhen the models are able to extrapolate from previous examples in the ‘prompt’, with-\nout being retrained or fine-tuned. Extensive experimental research (Hendrycks et al., 2021, \n2021; Xu et al., 2020; Izacard & Grave, 2020) is showing remarkable extrapolations from \nsmall prompts.\n2057Machine Learning (2023) 112:2053–2082 \n1 3\nTable 1  Taxonomy of data wrangling problems (adapted from Nazabal et al. 2020).\nTasks categorised by the level of aggregation of the data to which they may be applied (table, feature or value). We indicate with ∙ that most of the instances of the task may \nbe automatable with language models, while ∙ represents that only some of the instances or variations may be appropriate\nProblem Group Description Level Automatable\nTable Feature Value\nData organisation Data Parsing Identify the structure of the raw data source so that it can be read properly (e.g., csv or \nxml files, relational databases, etc.)\n∙\nData Dictionary Understand the contents of the data (e.g., profile of the data, meaning and type of each \nattribute, etc.)\n∙ ∙ ∙\nData Integration Combine related information from multiple sources (e.g., in different tables) into a single \ndata structure (e.g., a table, or time series, etc.)\n∙\nData Transformation Manipulate the shape of the data (e.g., switching the format of the table from a “wide” to \na “long” format or vice versa) and extraction of relevant pieces of information from it \n(e.g., names of people or places, relationships, etc.)\n∙ ∙ ∙ ∙\nData quality Canonicalisation Standarise features and units obtaining a common representation (e.g., (e.g. U.K., UK and \nUnited Kingdom; or specific formats for dates, addresses, etc.)\n∙ ∙ ∙\nMissing Data Detect missing entries and understand missing data patterns for repair (i.e., imputing \nthose missing entries with other values according to different rules)\n∙ ∙ ∙\nAnomalies Detect patterns that does not conform to expected normal behaviours (e.g., due to system-\natic errors in measurement devices or malicious activity or fraud)\n∙ ∙\nNon-stationarity Detect changes in behaviour of data (e.g., dataset shift, protocol changes, etc.) ∙\nFeature engineering Manipulate or create features based on existing ones (e.g., aggregating several features \ninto a unique feature, one-hot encoding representations of categorical variables, etc.)\n∙ ∙\n2058 Machine Learning (2023) 112:2053–2082\n1 3\nGoing back to Table  1, given a set of tabular data, which of these tasks can be per -\nformed at the level of columns (features) and/or instances (values)? If that is the case, \nthe limited window (number of input tokens) of a language model (of the order of hun-\ndreds of tokens) could be sufficient for these tasks, which could be excellent candidates \nfor automation by language models. Indeed, the state of the art of language models sug-\ngest they can be a promising tool for data wrangling precisely because they (1) capture a \nwide range of domain background knowledge, and contextualise it to the problem quite \neffectively, without the need of extra knowledge (e.g., we do not have to tell them that \n‘23/12/2021’ is a date), and (2) they not only infer from very few examples (e.g., pairs \nof date transformations ‘Input: 23/12/2021, Output: 12-23-2021 ’), but \nwe can also add hints to the prompt to make few-shot learning more effective, or even \nzero-shot learning possible (e.g., ‘The conversion of 23/12/2021 into US \nformat is:’).\nAll this makes prompt-commanded language models very versatile, because they can \ndo many things by just choosing an appropriate prompt. In this regime, they are able to \nperform a wide variety of ‘few-shot’ tasks when the prompt wraps several examples, which \nare ‘continued’ with textual data that can also contain transformed values or the answer to \nfactual questions about the input data. Of course, many integration tasks (e.g., merging two \ntables) or those that require some sort of temporal analysis are not suitable (today) for this \ntype of prompt-commanded AI systems, because of the size or structure of the data or the \nlack of memory of language models beyond what is expressed in the prompt.\nAccording to these considerations, Table  1 discusses good candidate tasks to be \naddressed by language models. However, we are also interested in the reasons why lan-\nguage models can make a difference in these tasks. The answer to this question is the \nhigh domain knowledge associated with them, their semantics. Knowledge is key in data \ntransformation and cleaning, as well as other data-intensive tasks such as schema match-\ning or data integration, data discovery, etc. (Zhang et al., 2019). For instance, automated \ndata cleaning processes usually employ transformation and validation rules that depend on \ndata types (Kandel et  al., 2011; Raman & Hellerstein, 2001). Most commercial systems \n(Sleeper, 2021; Trifacta, 2022; Ferrari and Russo, 2016) attempt to detect semantic types, \ntypically using a combination of rule-based approaches and dictionary lookup. However, \nthese approaches are limited to a few data types or to those where it is possible to specify \nstrict validations, and are often not robust enough to process dirty or missing data. For \ninstance, a particularly difficult data wrangling task to automate is the semantic detec-\ntion of ordinal data types, where the variables have natural, ordered categories, and thus a \ndirection (e.g., quality ∈{  bad, average, good, excellent } ) and a myriad \nof variations of these labels –including typographical errors– depending on the source and \nsituation.\nLooking at those tasks in Table  1 indicated as automatable, we recognise the use of \ndomain knowledge in all of them. Data dictionary tasks require some knowledge about \nthe data many data wrangling tools simply lack (e.g., identifying that undergraduate , \npostgraduate and PhD are values of a data type that may represent study level). Data \ntransformation also needs knowledge, to determine, for instance, that 12/18/2022  is \na date that can only refer to 18th December 2022. Canonicalisation is even more clearly \nknowledge-dependent. For instance, statistical analysis does not suffice to tell whether \nU.K., UK and United Kingdom are simply the same thing. Missing data imputation \ncan be done through models, but on many occasions it depends on knowledge as well, \nsuch as imputing that the country for the city of Venice is Italy. Similarly, we know that a \nnegative age is an anomaly that is clearly wrong, but an unusual negative temperature (in \n2059Machine Learning (2023) 112:2053–2082 \n1 3\nCelsius) might still be okay. Finally, for feature engineering, knowledge can do easily what \nlearning representations may require enormous amount of data. For instance, we can only \nsuggest that density is a more meaningful feature than area and total popula-\ntion because we know the semantics of the features. In the end, in all these examples \nthere is a striking commonality: this is general knowledge that large language models have \nbeen able to capture and can use appropriately if prompted in the right way. This is what \nwe want to explore in this paper.\nThe last column in Table  1 (column “Automatable”) actually lists the data wrangling \ntasks we will analyse in this paper. The possibilities for automation will be illustrated \nwith some experiments. Regarding the automatable tasks, those related to data cleans-\ning, data quality, as well as the construction of new features, involve different types \nof transformation, standardisation, extraction or generation of information. These are \neasy to configure in input/output prompts (as strings), as we will see in the following \nsections. According to the taxonomy shown in Table  1, we will focus our study on \nfive main tasks: First, data transformation involves the extraction of relevant pieces \nof information from multiple features, while discarding any unnecessary information. \nAlso, we will analyse the automation of canonicalisation tasks where the objective is \nto standardise representations in characteristics, metrics and units. We will work on \ntasks for the detection and imputation of missing values; and, the detection of anoma-\nlies in the data that do not fit the normal patterns. Finally, we will see examples of the \nprocess of selection, manipulation and transformation of raw data into new features \nwith different examples (feature engineering).\nOverall, in this work we completely cover the set of problems in Nazabal et  al. \n(2020) that can be candidates for automation by language models, leaving out those \ntasks that, due to their size, access requirements and temporal nature, cannot be \naddressed by language models at present.\n3  Experimental design\nData wrangling can appear in many different moments of the data processing pipeline \nand can be handled by very different users, from non-expert users to advanced data sci-\nentists. The fundamental element of data wrangling is its non-systematic occurrence, \nand so are their solutions. When data wrangling tasks are identified in isolation, e.g., \nfollowing Table  1, then some tools can use specific procedures for each of them. How -\never, as a result, many variations or non-standardised data wrangling problems are left \nout of the range of these tools. In this paper, we want to study how language models \ncan be used in a flexible way to attempt any data wrangling task, trying to emulate a \nscenario where a user has general access to an off-the-shelf language model and has \nsome practice writing prompts. This mimics the situation of a programmer that has \nto solve many different problems by writing code with the same programming lan-\nguage. Determining what programming languages and environments can lead to effec-\ntive solutions more easily is hard to evaluate, but this should not be an excuse to criti-\ncise the efforts to produce imperfect, yet still valuable assessment methodologies. This \nrationale guides our experimental setting.\nOur experimental goals are: (1) determine to which extent a state-of-the-art lan-\nguage model can obtain good results on those data wrangling problems in Table  1 \nunder the few-shot setting, (2) analyse the effect of the number of instances given in \nthe few-shot setting, (3) explore the effect of the number of parameters of the language \n2060 Machine Learning (2023) 112:2053–2082\n1 3\nmodel to better understand the future potential, (4) analyse the performance of a state-\nof-the-art language model on those data wrangling problems in Table  1 under the \nzero-shot setting using different prompts; (5) study the variation of performance for \ndifferent batteries and domains, and (6) compare the results with some other systems \nspecifically designed for data wrangling.\n3.1  Batteries and metrics\nFor the experimental setting, we employ five batteries of data wrangling problems. Some \nof them were collected in previous studies. These allow us to compare the results given by \nlanguage models with some other (data wrangling) tools. Other batteries have been col-\nlected for this paper. In this case, we have taken datasets from very different sources with \nthe main criterion of diversity for inclusion. The five batteries that we use are:\n3.1.1  Manipulation battery\nThis battery contains several common data wrangling problems (see, e.g., Ellis and Gul-\nwani, 2017) of very different domains that require to convert an input into an output that \nhas to meet a standard or canonical format, or extract part of it. This battery is built over \nthe most comprehensive benchmark for data-wrangling transformation problems to date, \nthe Data Wrangling Dataset Repository3 (Contreras-Ochando et al., 2019b), which we have \nextended considerably4 BIG-bench collaboration (2022).\nThe tasks are mostly of the Data Transformation, Canonicalisation and Feature Engi-\nneering groups in Table  1. Overall, the battery contains 117 different tasks divided into 7 \ndifferent domains (dates, emails, freetext, names, phones, times and units). For every task \nwe have 32 examples (we use 3744 instances in total) composed by an input string and an \noutput string, and performance is evaluated with average accuracy: exact matching with the \ncorrect output. We provide further details about the tasks in each domain in Table  2 and \nsome illustrative examples in Table 3.\n3.1.2  Types battery\nThe types battery deals with semantic type detection tasks, which are mostly of the Data \nDictionary group in Table  1. Therefore, this battery aims to automatically detect the \nsemantic data type of some columns in a given dataset. To build this battery, we followed \na similar procedure to Hulsebos et al. (2019). Firstly, we selected 11 semantic types from \nthe DBpedia ontology5 (an ontology that describes semantic concepts extracted from web \npages such as “Address”, “Affiliation” and “Country”). Then, we collected 5 datasets from \nwell-known machine learning repositories (Kaggle 6 and OpenML 7) and selected from \nthem those columns whose header names match the selected semantic types from DBpedia \n(such as Age or Gender) or are closely related to them (such as the header ScheduledDate \n3 http:// dmip. webs. upv. es/ dataw rangl ing/.\n4 https:// github. com/ google/ BIG- bench/ tree/ main/ bigbe nch/ bench mark_ tasks/ mult_ data_ wrang ling.\n5 https:// dbped ia. org/ ontol ogy/.\n6 https:// www. kaggle. com/.\n7 https:// www. openml. org/.\n2061Machine Learning (2023) 112:2053–2082 \n1 3\nTable 2  Manipulation Battery: Datasets included in the data wrangling repository and extended in this bat-\ntery\nTask description Expected output\nAdd punctuation The date in numeric format split by a punctuation sign\nChange format The date in one particular format\nChange punctuation The date in one particular format\nGet day The day in numeric format\nGet day ordinal The day in numeric ordinal format\nGet month name The name of the month\nGet week day The name of the weekday\nReduce month name The name of the month reduced to three letters\nSet format The date split in DMY format\nGenerate email An email account created with the name and the domain\nGet after at Everything after the at symbol\nGet domain The domain before the dot\nBefore at Everything before the at symbol\nAfter symbol Everything after a symbol\nBetween symbols Everything between a pair of symbols\nDelete punctuation Remove punctuation\nDelete spaces Remove blanks\nDigit to end Everything after the first digit if exists\nFirst character Get first character\nGet after comma Everything after a comma\nGet caps Capitalise each word in a text\nTo upper Convert text to upper case\nAdd title The name with a title\nGet title The title attached to the name, if exists\nGenerate login A login generated using the name\nReduce name The name reduced before the surname(s)\nAdd prefix by country Phone numbers with the prefix of the countries\nDelete parentheses The list of phone numbers without parentheses\nGet number A phone number presented in the string, if exists\nSet prefix The list of phone numbers with the prefix\nSet punctuation A phone number split by a punctuation sign\nAdd time The time increasing the hour by the integer\nAppend o’clock time The time appending an o’clock time\nAppend time The time appending the integer as new component\nConvert time The time formatted to 24 hours format\nConvert time The time formatted to a given format\nConvert time The time formatted to 12 hours format\nConvert time The time changed from the first time zone to the second\nDelete time The time deleting the last component\nGet hour The hour component\nGet minutes The minutes component\nGet time A time presented in the string\nConvert units The value transformed to a different magnitude\nGet system The system represented by the magnitude\n2062 Machine Learning (2023) 112:2053–2082\n1 3\nwhich is related to the semantic type “date/time”). That allows us to use the semantic types \nas the real type labels for the columns. With all of this, the type battery is conformed by 17 \ncolumns. The list of datasets, the characteristics of the selected columns, and their (real) \nsemantic types can be found in Table 4. Performance is evaluated by averaging accuracy by \nconsidering a success if the output given by GPT-3 contains the real semantic type of the \ncolumn (in singular or plural).\n3.1.3  Ordinal battery\nThis battery is concerned with detecting and sorting ordinal attributes, tasks that are mostly \nof the Data Dictionary group in Table 1. This battery includes the identification of whether \nTable 2  (continued)\nTask description Expected output\nGet units The units of the system\nGet value The numeric value without any magnitude\nTable 3  Examples of data wrangling tasks of different domains included in the Manipulation Battery\nDomain # Tasks Example (input → output)\nDates 21 74-03-31 → 31\nEmail 10 Jan.Kotas@litwareinc.com → litwareinc.com\nFreetext 25 Association of Computational Linguistics → ACL\nNames 15 Prof. Kathleen S. Fisher → Fisher, K.\nPhones 18 John DOE 3 … [TS]865-000-0000 … → 865-000-0000\nTimes 24 3:40 PM → 15:40\nUnits 10 12.20 dg → 1220.0 mg\nTable 4  Types Battery: Datasets used for detecting the semantic type, with the number of numerical and \ncategorical columns selected for the experiments and their real semantic types\nIn some datasets there are more than one column with the same semantic type. We used four datasets from \nKaggle and one dataset from OpenML\nDataset # Examples # Selected col-\numns\nSemantic types\nNumerical cat-\negorical\nMedicalNoShows 110527 1 4 Age, gender, time/date, neighbourhood\nGenderByName 148022 0 2 Name, gender\nCountriesWorld 227 0 2 Country, region\nSpeedDating 8378 1 3 Age, gender, race\nZillow 10730 0 4 City, state, metropolitan area, country\n2063Machine Learning (2023) 112:2053–2082 \n1 3\nan attribute is ordinal or non-ordinal. In the case of being ordinal, we want to determine the \norder. For instance,  bronze,  silver,  gold, and  platinum should be identified \nas ordinal and given the order  bronze < silver < gold < platinum. For compos-\ning the battery, we looked at the literature dealing with ordinal attributes, in particular (Shi \net al., 2016; Bellmann & Schwenker, 2020). These papers cover the attributes in the UCI \ndatasets Cars, Nursery, BreastCancer, Hayes-Roth, Balance and CMC. In Hayes-Roth, Bal-\nance and CMC the attributes are represented by numbers, so we excluded these for being \ntrivial. We also add some other datasets with a good number of categorical attributes with \na higher proportion of non-ordinal cases, such as SoyBean and Mushroom, to have a more \nbalanced battery of ordinal and non-ordinal attributes. All these were integrated into our \nbattery. The full list of datasets and attributes, and their characteristics can be found in \nTable 5, and we will show all the attributes in Table  9. We will evaluate whether a system \ncan distinguish between ordinal and non-ordinal attributes (just from their labels), sum-\nmarised as accuracy, and then whether it orders them correctly (we will consider all the \npairwise comparisons between attributes, aggregated into a single metric, Spearman cor -\nrelation between the inferred order and the correct order).\n3.1.4  Anomalies battery\nThis battery, which deals with semantic outlier detection tasks, clearly corresponds to the \nAnomalies group in Table 1. It aims to detect the existence of values in the data that appear \nto be inconsistent with the remainder of that set of data. This is one of the hardest problems \nin data wrangling since anomalies are not normally encoded explicitly in the data. The \nrelated concept of outlier is purely statistical, but an anomaly may not be an outlier and \nvice versa. Outliers can be univariate (e.g., a person who is 2.2 meters tall), bivariate (e.g., \nin a survey of a human population, a 5-year-old is not an outlier and a person who weighs \n90 kg is not an outlier, but a 5-year-old who weighs 90 kg is an outlier) or multivariate. \nHere we focus on univariate outliers or, more precisely, anomalies. Lots of methods exist \nto analyse numerical data that has outliers in it (see e.g., Ben-Gal, 2005 for a good review), \nand much less for categorical data, most of them based on frequencies (He et al., 2005; Das \n& Schneider, 2007) where the rare values are usually (wrongly) treated as outliers. Anoma-\nlies can simply refer to a value that does not fit, not to their statistical frequency, such as \nhaving three rows with the value ‘Umbrella’ in a column of countries.\nWe will separate our analysis based on the type of attribute. For numerical attributes, \nas ground truth we will use boxplots to detect outliers (i.e., a data point that is located out-\nside the whiskers of the box plot). For categorical attributes, given the difficulty of finding \nTable 5  Ordinal Battery: \nDatasets used for ordinal \nattribute ordering, with the \nnumber of non-numerical non-\nbinary features that are ordinal \nand non-ordinal in each of them\nDataset # Examples # Features (non-numerical)\nOrdinal Non-ordinal\nSoyBean 47 6 11\nPostOperative 90 8 0\nNursery 12960 8 0\nMushroom 8124 2 16\nCars 1728 7 0\nBreastCancer 699 4 1\n2064 Machine Learning (2023) 112:2053–2082\n1 3\nlabelled anomalies, we will create synthetic anomalies by randomly altering attribute val-\nues, as it is done in related work (see, e.g., Das et al. 2008; Lazarevic & Kumar, 2005; \nChen et  al., 2008). Anomalies will be introduced in 1% of the values of each categori-\ncal attribute and randomly picked values of each of the other attributes of the dataset will \nbe used for this purpose. For instance, if a particular dataset has 5 attributes and we are \ninserting anomalies in one of them, this process will be repeated 4 times inserting random \nvalues of the rest of the attributes, one in each turn. The idea is that the inserted anomalies \nhave a different semantic meaning than the original attributes, and using values of the other \nattributes for this purpose is a straightforward solution that allows us to experiment with \ndifferent types of values but in a similar context. Finally, for composing the battery, we \nlooked at the literature dealing with detecting outliers in tabular data, in particular (Ashok \n& Nawaz, 2016; Porwal & Mukund, 2017; Noto et al., 2012), which cover the attributes \nin the UCI datasets Wine, Ozone, Mpg, Iris, Glass, Ecoli and BreastCancer. The full list \nof datasets and attributes, and their characteristics can be found in Table  6. For evaluating \nperformance, we will calculate the outlier detection hit rate per column of each dataset \ncompared with the set of outliers proposed with those obtained using the boxplot method \nor the ground truth depending on the type of attribute.\n3.1.5  Imputation battery\nThe tasks here are mostly of the Missing Data group in Table  1, namely finding miss-\ning values in data and trying to impute these values. Traditionally, there are several ways \nof dealing with missing values (Rubin, 1976; García et al., 2016; Fernando et al., 2021). \nReplacing the missing values by a fictitious value (imputation) is usually a better practice \nthan ignoring or removing the row. The new value is computed by means of simple strate-\ngies such as employing the mean or median (for numerical values) or mode (for categorical \nvalues) of the feature. More sophisticated methods of imputation are used by estimating \nthe value from the other attributes with predictive models. In order to test the utility of \nTable 6  Anomalies Battery: \nDatasets used for semantic \noutlier detection, with the \nnumber of features with and \nwithout outliers\nAll features are numerical except for the dataset indicated by △ , with \ncategorical features\nDataset # Examples # Features\nw outliers w/o Outliers\nWine 178 7 5\nOzone 366 4 6\nMpg△ 234 2 3\nIris 150 1 3\nGlass 178 8 1\nEcoli 336 4 3\nBreastCancer 699 6 4\n2065Machine Learning (2023) 112:2053–2082 \n1 3\nlanguage models to impute missing values, we are going to employ different datasets. For \nthe experiments, we consider three well-known datasets that are frequently used by the \nmachine learning literature from the UCI repository (Dua & Graff, 2017): Adult, Iris and \nMpg. Additionally, we also employ databases with information in specific fields such as \nthe UK Postcode Address FILE, 8 tennis players from ATP, 9 and a simplified version of \nthe UCS Satellite Database. 10 These are three databases that can be seen as examples of \nspecific domains. Apart from numerical and categorical features, in these three datasets \nwe can find features that are textual. We believe these datasets are representative of real \ndatabases that could present missing data, and thus they can be especially useful to show \nthe capacity of GPT-3 to impute data with respect to other classical predictive techniques, \nsince classical imputation methods do not work correctly with textual features as an output \n(structured prediction models would be needed, or generators, which is why language mod-\nels may be a good option). The list of datasets and attributes can be found in Table 7.\nWe will use a traditional imputation method for comparison. A DecisionTreeClassifier \nfrom the scikit learn library (Pedregosa et al., 2011) with the default configuration using 99 \nrows of the table to train a model that is used to predict the missing value in another row \n(not included in the 99 rows).\nFor each example, we repeat the procedure 10 times, and we measure the performance \nof the imputation comparing the predicted value with the actual value. In the case of the \ncategorical attributes, we show the mean accuracy in imputing missing values. For the \nnumerical attributes, we divide the estimated mean absolute error (MAE) by the standard \ndeviation ( /u1D70E ) of the values of the feature. To make it more comparable with accuracy, we \ncalculate its complementary, i.e., 1 − MAE\n/u1D70E.\n3.2  Language models and prompts\nAs we discussed at the beginning of this section, despite the taxonomy in Table  1, there \nare thousands of variants of data wrangling tasks, and success or failure may depend on \nformats, domains, extra data availability, and many other factors that make each situation \nunique. For instance, standardising addresses in an international context is very different \nfrom discovering the order of a feature expressing martial arts levels. Having hundreds \nTable 7  Imputation Battery: \nDatasets used for imputing \nmissing values, with the number \nof numerical, categorical, and \ntextual features\nWe used three datasets from UCI and three databases with information \nfrom specific fields\nDataset # Examples # Features\nNumerical Categorical Textual\nAdult 48842 6 8\nMpg 234 6 0\nIris 150 4 0\nPAF-address 26 0 1 7\nATP players 550 8 2 6\nUCS-satellite 4852 8 4 4\n8 Extracted from: https:// www. power edbyp af. com/ produ ct/ paf/.\n9 Source: https:// datah ub. io/ sports- data/ atp- world- tour- tennis- data.\n10 Extracted from: https:// www. ucsusa. org/ resou rces/ satel lite- datab ase.\n2066 Machine Learning (2023) 112:2053–2082\n1 3\nof specific tools or domain-specific languages is not a scalable solution for this diversity. \nAccordingly, we want to consider data wrangling pipelines where a user has access to an \noff-the-shelf language model and plays with a few prompts to explore whether the specific \ndata wrangling at hand can be solved. It is not our goal to find the optimal prompt for each \ntask and language model, but some prompts that users (not necessarily expert data scien-\ntists) can come up for making this data wrangling process. We do not want to overfit to the \nbest prompt for each task and language models, as both tasks and language models evolve \nand change constantly. We want to have a general understanding of areas of higher poten-\ntial in terms of results versus the effort of thinking of a good prompt and the associated \nexamples.\nWe use four versions of OpenAI GPT-3 (Brown et al., 2020) of increasing capabilities: \nAda, Babbage, Curie and DaVinci which line up closely with 350M, 1.3B, 6.7B, and 175B \nparameters, respectively. We mostly focus on one architecture, GPT-3, since it is still con-\nsidered state of the art and highly representative. Although there are other large language \nmodels in the literature, the access to them has issues about open access to the source code, \nthe cost per token, the necessary infrastructure, the privacy of the APIs or public use of \nresults. Some collaborative initiatives are starting to test other large language models to \nevaluate their capabilities, making evaluation data public, but access to the language mod-\nels directly is limited. In particular, the BIG-bench collaboration (BIG-bench collabora-\ntion, 2022) has trained and evaluated Google’s latest language models (Big-G) (BIG-bench \ncollaboration, 2022), and we could include our Manipulation Battery. Although we do not \nhave access to the models, we have access to the results up to 3-shot (see Fig. 1). The com-\nparison shows that GPT-3 is representative of the state of the art in language models. In \nparticular, the most advanced GPT-3 model, Da Vinci, has very similar results to other top \nlanguage models for this battery.11\nFig. 1  Average accuracies per language model and domain on the Manipulation Battery tasks up to 3-shot. \nLanguage models sorted by average accuracy across all domains. The y-axis shows the id of the architecture \n(OpenAI GPT-3 or Google BIG-G models) and, in each case, whether the model is dense or sparse (Zoph \net al., 2022), and the number of parameters\n11 For the sake of replicability and reproducibility, all the code and results can be found in https:// github. \ncom/ gonza lojai movit ch/ lm- dw.\n2067Machine Learning (2023) 112:2053–2082 \n1 3\nFocusing, therefore, on the use of GPT-3, we first analysed several possible prompts. \nSince our aim is not to find the optimal input prompt for each task and model, but rather to \nprovide illustrative (simple) prompts, we explore a few choices that could be considered by \na user that is familiar with language models and the prompt samples that are recommended \nin the language models APIs.12 Also, in Table 10 we show the templates used and the alter-\nnatives we tried for some batteries which were discarded due to its low specificity (making \nit more difficult for GPT3 to understand the task) and, therefore, their poorer results in our \ninitial experiments. In the end, what we want to show is that, in a simple way, any practi-\ntioner can use a pretrained language model to semi-automate many data wrangling tasks \nthat appear in the data-processing pipeline, without the need to train predictive models or \nfine-tune pretrained models for each different task.\nAs a result, for each of the data wrangling tasks we will use different input prompts, try-\ning to keep them as natural and simple as possible. Depending on the task, we may use dif-\nferent few-shot or zero-shot schemas. For instance, for the manipulation battery we will use \na few-shot approach, while for the rest of tasks, we will not provide exemplars, but rather \nsimple instructions about the task that we expect the language model to perform, thus fol-\nlowing a zero-shot scenario.\n3.2.1  Manipulation battery\nAs all the examples in this battery are input-output pairs, prompts are easy to figure out \nhere. Simply, the main prompt we will use follows an input-output style, where the string \n‘Input:’ is used to indicate the start of the input, and the string ‘Output: ’ is used to \nindicate the start of the output. The line break /uni2216.var n separates the input from the output of an \nexample, as well as the examples in the prompt (when one or more examples are provided). \nThe instance will have one (one-shot) or more (few-shot) input-output pairs. They will be \nrandomly selected (without considering the possible order sensitivity of GPT-3 (Lu et al., \n2021) from the same problem and domain, and one single input will end the prompt. The \nlanguage model will have to provide the output by continuing the prompt. Our intention is \nthat GPT-3 generalises the concept only from the instances provided in new instances of \nthe same task with no other information or description of the task at hand in the prompt. \nThe prompts given below are two one-shot examples (from different domains):\nInput: ‘290386’/uni2216.var nOutput: ‘29-03-86’/uni2216.var n/uni2216.var nInput: ‘250374’/uni2216.var nOutput:\nInput: ‘08:50-09:30’ /uni2216.var nOutput: ‘09:30’ /uni2216.var n /uni2216.var nInput: ‘09:50-\n08:30’ /uni2216.var nOutput:\n3.2.2  Types battery\nIn this battery we use two prompts to determine the type of a column. We follow a zero-\nshot strategy in that the first prompt asks the system for the “domain” that best describes a \nset of values randomly chosen from the column. Since “domain” is a broad term with sev -\neral meanings, the second prompt directly asks the system for the “semantic type” of the \nselected values. Examples of each prompt are:\n12 For instance, OpenAI collects many different examples: https:// openai. com/ blog/ openai- api/.\n2068 Machine Learning (2023) 112:2053–2082\n1 3\nWhat is the best domain that describes the values in \n{2016-04-29T18: 38:08Z,2016-04-29T16:08:27Z,2016-04-\n29T16:19:04Z,2016-04-29T17:29:31Z, 2016-04-29T16:07:23Z,2016-\n04-27T08:36:51Z,2016-04-27T15:05:12Z,2016-04-\n27T15:39:58Z,2016-04-29T08:02:16Z,2016-04-27T12:48:25Z}? What \nis the best semantic type that describes the values in {male, \nfemale,female,female,male,male,male,male,female,female}?\nFor the experiments, the number of values to be included in each prompt has been set \nto 10, as shown in the above examples. To mitigate the effect that the random selection of \nthese 10 examples could have on the performance of the task, we have repeated the experi-\nments with each prompt and column 5 times, and then, the results were averaged.\n3.2.3  Ordinal battery\nHere we will try two different ways (prompts) to distinguish ordinal and non-ordinal fea-\ntures. In the first prompt we will ask the system if a given value is greater than another, \nrepeating this for all possible combinations of values in each attribute of a dataset and \ncomputing whether the final order between all the unique values is consistent. An exam-\nple of a prompt follows:\nIs “ house” higher than “ apartment”? Yes/uni2216.var n Is “ apartment” \nhigher than “ house”? No/uni2216.var n Is “ red” higher than “ blue”? No/uni2216.var n Is \n“blue” higher than “ red”? No /uni2216.var n Is “ old” higher than “ young”? Yes/uni2216.var \nn Is “ young” higher than “ old”? No/uni2216.var n Is “ totally agree” higher \nthan “ agree”? Yes/uni2216.var n Is “ agree” higher than “ totally agree”? No/uni2216.var \nn Is “ New York” higher than “ Chicago”? No/uni2216.var n Is “ Chicago” higher \nthan “New York”? No/uni2216.var n Is “Heavy rain” higher than “ Showers”? Yes/uni2216.var \nn Is “ Showers” higher than “ Heavy rain”? No/uni2216.var n Is “ gold” higher \nthan “platinum”?\nWhile this is a 12-shot, followed by the real question at the end (the 13th line), it \ndoes not really need any real example. The context is always the same for all the exam-\nples, while only the 13th line changes. This long context is added because it helps to \nframe the question and gives better results. We do compare all pairs in the attribute (and \nin both directions), and calculate the rank of each value depending on how many times \nit compared favourable against the rest. This gives us a ‘rank’ for each value. Taking \nthis rank as the derived order, we check how many times the comparisons follow this \norder, and if this is greater than 75% then we say the attribute is ordinal, otherwise it is \nnon-ordinal.\nAlternatively, we will try an even simpler version of the prompt where we will \ndirectly ask if the unique values of a given attribute of a dataset are of ordinal type:\nIs (low, medium, high) an ordinal? Yes /uni2216.var n Is (door, win-\ndow, wheel) an ordinal? No /uni2216.var n Is (‘2’, ‘4’, ‘more’) an ordinal? \nAgain, the first two lines are fixed and only the last one changes depending on the \nattribute. This prompt is much easier, but does not give us an order, just whether the \nattribute is ordinal or not.\n2069Machine Learning (2023) 112:2053–2082 \n1 3\n3.2.4  Anomalies battery\nHere we will follow a zero-shot strategy where we will provide the language model with \na prompt asking directly whether there are any outliers in a given set of data. For this \nbattery we only include one prompt. We performed many preliminary tests to get good \nresults. While we were looking for anomalies and not outliers, in the end we saw that \nthe results were similar when we modified the prompt by asking for anomalies, oddities \nor abnormal phenomena in the data instead of using the word ‘outliers’. A couple of \nexamples of the prompt follow:\nAre there any outliers in {70 ◦ F, 71◦ F, ..., 74◦ F}? \nAre there any outliers in {audi, chevrolet, dodge, ford, \n..., volkswagen}? \n3.2.5  Imputation battery\nWe use two prompts to make the language model infer the missing value from a set of \nexamples. We use instances without missing values in the prompt and we leave the last \nline for the instance with the missing value. We have explored two alternatives. In the \nFig. 2  Average results for the seven domains in the Manipulation Battery and the four versions of GPT-3. \nEach plot represents how many examples are given (from zero-shot to 10-shot). The dashed horizontal lines \nshow the average results per system. Disaggregated results for all tasks shown in Fig. 8 in the supplemen-\ntary material\n2070 Machine Learning (2023) 112:2053–2082\n1 3\nfirst one, Full prompt, we use all the available features in the data set. This is an exam-\nple of the Full prompt:\nCity: Detroit, State: Michigan, County: Wayne /uni2216.var n City: \nFargo, State: North Dakota, County: Cass /uni2216.var n ..., City: Ath-\nens, State: Georgia, County:\nThe second approach, 1-Feature prompt, is much shorter usually. We select the most \nuseful feature13 For example, for the same dataset as above, if we determine City as the \nmost relevant feature for inferring County, an example of the 1-Feature prompt would be:\n City: Detroit, County: Wayne /uni2216.var n City: Fargo, County: Cass /uni2216.var \nn ..., City: Athens, County:\nAs we can see, the Full prompt strategy will make prompts very large (requiring many \ntokens from the language model) as soon as the instances have many features. Because of \nthat we will employ a nine-shot approach, so only nine complete rows will be used. We \nwill also explore a zero-shot approach with this configuration, which is simply the full row \nwhere the missing value appears. The second strategy (1-Feature prompt) allows us to pro-\nvide more training examples without using too many tokens. Additionally, given that only \nTable 8  Examples of problems \nin the domain ‘units’ Problem Input → Output\n‘getUnits-1’ 56.77cl → cl\n‘getValue-1’ 56.77cl → 56.77\n‘getSystem-1’ 56.77cl → Volume\n‘convert-1’ 1441.8mg; g → 1.4418001\nFig. 3  Average accuracies for the tasks in the units domain for all GPT-3 systems and learning settings. \nComplete details of all domains and descriptions of all tasks are presented in Fig. 8 and Table  2, respec-\ntively, in the supplementary material\n13 We compute the most useful attribute according to the attribute importance of a random forest model \nlearned from the whole table using the attribute with the missing value as an output.\n2071Machine Learning (2023) 112:2053–2082 \n1 3\none input feature is employed we need to increase the information provided to the language \nmodel, specifically we will employ 99 examples.\n4  Results and discussion\nWe start by analysing the performance of the different GPT-3 family of models (Ada, Bab-\nbage, Curie and DaVinci). The models are employed on the various data wrangling bat-\nteries described in the previous section. The result metrics are assessed using the differ -\nent few-shot learning settings, including zero-shot regimes for some of the batteries, as \nexplained in the previous section.\nLet us start with the Manipulation Battery. In this case, the models are given several \ninput examples in the ‘input-output’ prompt and no other further information or descrip-\ntion of the task at hand. Figure  2 shows the results obtained by using the four different \nmodels (Ada, Babbage, Curie and DaVinci) and different few-shot learning settings, from \nzero-shot to ten-shot for all domains (which make a total of 11 configurations per task). \nRegarding the results, we see the sharp increase from zero-shot learning to 1-shot learning, \nand a more moderate increase that stabilises around 9-shot inference. In general, the results \nshow that GPT-3 can be employed to learn simple transformations from few examples, \nand, as expected, the accuracy improves when we provide more instances. We also see \nthat, as expected, the most powerful engine is DaVinci. Nevertheless, the performance is \nnot uniform across the analysed domains. The domain emails is the one where the GPT-3 \nmodels obtain the highest performance, whereas units is the domain with the lowest perfor-\nmance. This may be related to the need of semantic information about the domain but also \nsome reasoning or calculation capabilities (e.g., multiplication in the case of units). We \ninclude further details in the supplementary material: disaggregated results in Fig. 8 and a \nset of illustrative examples of wrong answers obtained by GPT-3 for problems with differ -\nent types of inputs (Tables 11 and 12).\nWith the intention of getting more insight into how the models fail, we perform a fine-\ngrain analysis of the ‘units’ domain in the Manipulation Battery. Table 8 includes examples \nof some of these tasks to better understand the differences in performance shown in Fig.  3. \nThe problems in tasks getUnits-i and getValue-i (see Table  2 for details) can be translated \nas ‘extracting a part of the string’, a transformation that the GPT-3 models can solve. \nFig. 4  Average accuracies \nof GPT-3 (DaVinci version), \nFlashFill Gulwani et al. (2015), \nTrifacta Wrangler and DBK \nContreras-Ochando et al. (2019b) \nfor a 1-shot learning setting. \nResults of the compared systems \nare obtained from Contreras-\nOchando et al. (2019a, 2019b). \nThe tasks addressed are a subset \nof those in Fig. 8. Coloured, \nhorizontal lines show the aver-\nage results per system across \ndomains\n2072 Machine Learning (2023) 112:2053–2082\n1 3\nHence, we see that GPT-3 presents good results in domains where tasks can be solved by \nsimple string transformations. However, getSystem-i and convert-i are much more complex \ntasks. Thus, getUnits-i requires the identification of the unit acronym (e.g., ‘cl’ for centi-\nlitres) and relating it with its dimension (e.g., volume), while convert-i needs to perform \nan arithmetic operation (e.g., a division), in addition to the identification of the conversion \ncoefficient to the target unit (e.g., a coefficient of 1000 to convert milligrams into grams).\nFinally, in order to compare the performance of GPT-3 with other data wrangling sys-\ntems, we consider the subset of 26 problems in the Manipulation battery, for which there \nare results in the literature. We make the comparison for the 1-shot setting, which is the \nsame setting used by the other systems. We compare GPT-3 DaVinci and the following \ndata wrangling tools: FlashFill (Gulwani et al., 2015), TrifactaWrangler (Petrova-Antonova \n& Tancheva, 2020) and Dynamic Background Knowledge (DBK) (Contreras-Ochando \net al., 2019b). The results (displayed in Fig. 4) show that general-purpose language models \nare competitive with first-generation data wrangling tools such as FlashFill, and are getting \ncloser in performance to more sophisticated tools such as DBK. Again, we see that the \nperformance of the compared systems is related to the types involved in the target func-\ntions. The best results are obtained in domains where the problems are solved by simple \nstring operations, while in other domains like units where some functions include arith-\nmetic operations the results are much worse. The exception is DBK, which can induce the \ndomain of the problem and then select proper base functions to address it.\nWe now move on to the rest of the experimental batteries. Figure  5 shows the results \nobtained by using the most powerful GPT-3 engine, DaVinci, for the Types and Ordinal \nBatteries. It is interesting to note that there is, in many cases, a notable difference depend-\ning on the prompt.\nFor the case of the Types Battery, GPT-3 is more accurate the more informative the \nprompt is: asking for the “domain” seems to be less specific than asking for the “semantic \ntype” of the values. In general, the results for the type detection using the second prompt \nare very satisfactory, with a mean success rate of 0.7 in front of a mean accuracy of 0.2 \nobtained with the first prompt.\nLet us analyse in more detail the answers given by GPT-3 for this battery. First of all, \nwe must be aware of the expressive power of natural language, which implies that there is \nno unique way to name a concept. In terms of solving the semantic type task, this means \nFig. 5  Average results for different datasets and the types and ordinal batteries, using different prompts\n2073Machine Learning (2023) 112:2053–2082 \n1 3\nthat some values can be assumed as belonging to different but related types. For instance, \nPalmira and Verona could be considered as values of the type City, but also of the type \nTown or even Place. Although it can be argued that a city, a place and a town are not \nexactly the same concept (there exist some differences among them), it is clear they are \nrelated (all of them are locations). That is what we observe in the experiments, with GPT-3 \ngiving all these answers for one of the columns of the Zillow dataset depending on the \nprompt, as shown in Table  13 in the Supplementary material. Given that for evaluating \nthe performance of the system we set the real semantic type of this column as “city”, the \nrest of the answers were considered as failures. This fact explains the increase in accuracy \nwe got with the second prompt since it directly asks for the “semantic type” allowing the \nsystem to focus on the least general concept (type) to which the observed values belong. \nNote that, “place” could be considered a much too general type for denoting Palmira and \nVerona, whereas “town” could perhaps be too much specific). Another way to solve the \nproblem of having a set of possible answers (e.g., all possible column names with some \na priori probabilities) would be to consider the conditional probabilities (“logprobs”) pro-\nvided by the language models (i.e., how likely some word can appear in the text given the \nother one in this text.) for each possible output and combine them with the a priori prob-\nabilities to determine the most likely column name.\nApart from these considerations related to the performance of the system on the Types \nBattery, we would like to highlight that the flexibility of GPT-3 providing several differ -\nent answers as potential types is a feature rather than being a drawback. It is evident that \nlanguage models can work as effective tools for solving this kind of Data Dictionary tasks, \nsince they do not need (predefined) type ontologies to solve them. In fact, from a general \npoint of view, a user could consider that any of the three answers given by GPT-3 for the \nabove example are acceptable (i.e., they are valid types for the column), since with any of \nthem the user is able to know that the values of such column are related to locations and \nnot with other concepts such as names and countries.\nFinally, the differences observed in the results of the Types Battery when GPT-3 deals \nwith nominal and numerical attributes should be discussed. It is relatively easier for GPT-3 \n(and also for other language models) to infer the right type for a nominal attribute than for \na numerical one. The reason is clear; the values of nominal attributes are usually different \n(and specific) depending on the real concept (i.e., names, cities, countries, … ) to which the \nvalues belong to. However, it is much more difficult to determine whether a few numerical \nvalues such as {2, 4, 15, 23} correspond, for instance, to ages or Celsius degrees without \nany additional information. In the experiments we carried out, for both prompts, GPT-3 \nfails in determining that the semantic type of the two numerical attributes in the battery is \n“age”, being “numbers” the most common type returned by the system (see Table 13 in the \nSupplementary material). It could be interesting to explore prompts that include a descrip-\ntion of the dataset domain, and observe whether with this information the language model \nis successful. For instance, if we give information that the table is about customers, then \ngiven some numbers, the language model could infer that the type might be “age”.\nIn the case of the Ordinal Battery, it also depends on the prompt and domain. In general, \nhowever, asking whether there is an ordering between the unique values of an attribute \n(prompt 2) seems to be more effective. The results for telling ordinal vs non-ordinal are \nvery satisfactory, with an average success rate of 0.83 for this prompt. However, if we look \nat how good the orderings are, the picture is a bit more elaborate. Table  9 shows all cases, \nwith the Spearman correlation of the predicted ordering and the actual ordering using \nprompt 1, whether the method predicted ORDINAL or NON-ORDINAL with prompt 1 \nand prompt 2 and the actual value of ORDINAL/NON-ORDINAL. When the Spearman \n2074 Machine Learning (2023) 112:2053–2082\n1 3\nTable 9  Quality of orderings for the Ordinal Battery: Spearman correlation of the predicted ordering using \nprompt 1, the predicted types (with prompts 1 and 2) and the actual type\nDataset Attribute Spearman Pred. w. Prompt1 Pred. w. Prompt2 Actual\nBreastcancer Age 0.95 ORDINAL ORDINAL ORDINAL\nBreast-quad – NON-ORDINAL ORDINAL NON-ORDINAL\nInv-nodes 0.80 NON-ORDINAL ORDINAL ORDINAL\nMenopause – NON-ORDINAL ORDINAL ORDINAL\nTumor-size 0.90 ORDINAL ORDINAL ORDINAL\nCars Buying 1.00 ORDINAL ORDINAL ORDINAL\nClass 1.00 ORDINAL ORDINAL ORDINAL\nDoors 0.70 NON-ORDINAL ORDINAL ORDINAL\nLug-boot 0.87 ORDINAL ORDINAL ORDINAL\nMaint 1.00 ORDINAL ORDINAL ORDINAL\nPersons 0.50 NON-ORDINAL NON-ORDINAL ORDINAL\nSafety 1.00 ORDINAL ORDINAL ORDINAL\nMushroom Cap-color – NON-ORDINAL NON-ORDINAL NON-ORDINAL\nCap-shape 0.09 NON-ORDINAL NON-ORDINAL NON-ORDINAL\nCap-surface – NON-ORDINAL NON-ORDINAL NON-ORDINAL\nGill-attachment – NON-ORDINAL ORDINAL NON-ORDINAL\nGill-color – NON-ORDINAL NON-ORDINAL NON-ORDINAL\nGill-spacing 1.00 ORDINAL ORDINAL NON-ORDINAL\nHabitat 0.93 ORDINAL NON-ORDINAL NON-ORDINAL\nOdor 0.28 NON-ORDINAL NON-ORDINAL NON-ORDINAL\nPopulation 0.14 NON-ORDINAL NON-ORDINAL ORDINAL\nRing-number 0.87 ORDINAL ORDINAL ORDINAL\nRing-type 0.38 NON-ORDINAL NON-ORDINAL NON-ORDINAL\nSpore-print-color – NON-ORDINAL NON-ORDINAL NON-ORDINAL\nStalk-color-above-\nring\n– NON-ORDINAL NON-ORDINAL NON-ORDINAL\nStalk-color-below-\nring\n– NON-ORDINAL NON-ORDINAL NON-ORDINAL\nStalk-root 0.45 NON-ORDINAL NON-ORDINAL NON-ORDINAL\nStalk-surface-above-\nring\n– NON-ORDINAL NON-ORDINAL NON-ORDINAL\nStalk-surface-below-\nring\n– NON-ORDINAL NON-ORDINAL NON-ORDINAL\nVeil-color – NON-ORDINAL NON-ORDINAL NON-ORDINAL\nNursery Children 0.74 NON-ORDINAL ORDINAL ORDINAL\nCass 0.78 ORDINAL ORDINAL ORDINAL\nForm 0.20 NON-ORDINAL NON-ORDINAL ORDINAL\nHas-nurs 0.70 NON-ORDINAL ORDINAL ORDINAL\nHealth 0.50 NON-ORDINAL ORDINAL ORDINAL\nHhousing 0.50 NON-ORDINAL ORDINAL ORDINAL\nParents 0.00 NON-ORDINAL ORDINAL ORDINAL\nSocial 0.50 NON-ORDINAL ORDINAL ORDINAL\n2075Machine Learning (2023) 112:2053–2082 \n1 3\nTable 9  (continued)\nDataset Attribute Spearman Pred. w. Prompt1 Pred. w. Prompt2 Actual\nPostoperative BP-STBL – NON-ORDINAL ORDINAL ORDINAL\nCORE-STBL – NON-ORDINAL ORDINAL ORDINAL\nL-BP 1.00 ORDINAL ORDINAL ORDINAL\nL-CORE 1.00 ORDINAL ORDINAL ORDINAL\nL-O2 0.63 NON-ORDINAL ORDINAL ORDINAL\nL-SURF 1.00 ORDINAL ORDINAL ORDINAL\nSURF-STBL – NON-ORDINAL ORDINAL ORDINAL\nSoybean Area-damaged 0.74 NON-ORDINAL ORDINAL NON-ORDINAL\nCanker-lesion 0.32 NON-ORDINAL NON-ORDINAL NON-ORDINAL\nCrop-hist 0.32 NON-ORDINAL ORDINAL ORDINAL\nDate 0.73 NON-ORDINAL ORDINAL ORDINAL\nFruit spots 0.11 NON-ORDINAL NON-ORDINAL NON-ORDINAL\nFruit-pods 0.40 NON-ORDINAL NON-ORDINAL NON-ORDINAL\nFermination 0.87 ORDINAL ORDINAL ORDINAL\nLeafspot-size – NON-ORDINAL NON-ORDINAL NON-ORDINAL\nLeafspots-halo 0.87 ORDINAL ORDINAL NON-ORDINAL\nLeafspots-marg – NON-ORDINAL NON-ORDINAL NON-ORDINAL\nMycelium 1.00 ORDINAL ORDINAL NON-ORDINAL\nPrecip – NON-ORDINAL ORDINAL ORDINAL\nRoots 1.00 ORDINAL ORDINAL NON-ORDINAL\nSeed-tmt 0.50 NON-ORDINAL NON-ORDINAL NON-ORDINAL\nSeverity 1.00 ORDINAL ORDINAL ORDINAL\nStem-cankers 0.80 NON-ORDINAL ORDINAL NON-ORDINAL\nTemp – NON-ORDINAL ORDINAL ORDINAL\nFig. 6  Average results for the Anomalies Battery for different datasets using numerical features (left), and \ncategorical ones for Mpg dataset (right)\n2076 Machine Learning (2023) 112:2053–2082\n1 3\ncorrelation is ‘-’ the first prompt gave some unresolved comparisons, and the order could \nnot be calculated. All these were assigned to NON-ORDINAL systematically.\nIn all those cases where an ordinal attribute is correctly classified as ordinal (14 out of \n63) the average Spearman correlation is very high: 0.95. These are highly reliable cases \nwhere the order of attributes is perfectly determined (8 out of 14) or reasonably good \n(worst case is 0.78 correlation). Some of these attributes have a textual representation of \nnumbers or intervals (e.g., age, tumor-size, etc.) or are very easy (‘high’, ‘mid’, ‘low’) so it \nis not surprising that language models do well. Many discrepancies not due to unresolved \ncomparisons happen in cases where the correlations are high, but not high enough (e.g., \ninv-nodes, doors, children, has-nurs, health, housing, social, L-02), all of which are well \ncategorised by the second prompt. In these cases we can say that recognising whether an \nattribute is ordinal or not is doable, but the order might not be good enough. Then there are \nsome cases where the correlation is low and both prompts fail to recognise it is an ordinal \n(persons, population, form) or just the first prompt (parents, L-O2). Finally, there are some \nnon-ordinal features that get high scores and are categorised as ordinal by one or both of \nthe prompts (gill-spacing, habitat, leafspots-halo, mycelium, roots, stem-cankers). Some of \nthese have an ‘absent’ value, which is usually recognised as having a lower order than other \nvalues, or other elements that could suggest that are partially ordinal.\nMoving to the Anomalies Battery, and starting with the analysis of numerical attributes, \nFig. 6 (left) shows the poor performance of GPT-3, with a median success rate of 0.16. \nSome examples of its operation are shown in Table 14 in the Supplementary material. Why \nthis poor performance? This may be due to the fact that in many of these cases the role \nof semantic information is limited, and most especially as we take the outlier detection \n(boxplot whiskers) as ground truth (when it may be wrong for many datasets). It is not \nonly that these methods ignore semantics, but also that different outlier detection methods \nmay return different sets of outliers depending on the approach they implement (distance \nand density of data points, statistical models to predict the probability of a dataset distribu-\ntion, etc.). On the other hand, the performance of GPT-3 is sometimes erratic, obtaining as \nFig. 7  Average results for the Imputation Battery for domain databases (left), and UCI datasets (right). \nDataset results are split by numerical features (Reg) and categorical attributes (Class) when they have fea-\ntures of both types. For the those databases representing specific domains (“domain databases”), we employ \nthe Full prompt with 9-shot and zero-shot configurations. For the UCI datasets, we show the performance \nof the imputation with the Full prompt with 9-shot and zero-shot configurations, the 1-Feature prompt with \n99-shot and finally a decision tree trained with 99 examples\n2077Machine Learning (2023) 112:2053–2082 \n1 3\nanswers the same set of values it takes as input, possibly indicating that GPT-3 has not cor-\nrectly understood the task to be performed.\nAnalysing now the categorical attributes, Fig. 6 (right) shows the average results. In this \ncase, although the average accuracy results are somewhat better than in the previous case \n(0.35), if we analyse the attributes individually, we can observe that GPT-3 is not able to \ncorrectly use their semantic information to detect the anomalies. Some examples of this are \nshown in Table 15 in the Supplementary material. It seems that when we insert anomalies \nto the attributes with a low number of unique values, anomalies, GPT-3 is able to detect \nthem (see, e.g., attributes “drv” and “fl” in Table 15). However, for more complex attrib-\nutes, such as the car “model”, which includes a many unique alphanumeric terms of differ -\nent lengths, when trying to detect the introduced anomalies, GPT-3 performs very poorly. \nIn general, from this and the previous experiments we have seen that GPT-3 works well for \nsimple examples of anomaly detection where the context is clear (e.g., {flat, house, \napartment, dinosaur } or {70◦ F, 71◦ F, 71◦ F, 110◦ F, 71◦ F}). However, for \nreal datasets, it is (still) much more difficult to obtain acceptable results.\nFinally, in Figure  7 we show the experimental results for the Imputation Battery. Fig-\nure 7 (left) shows the results for those databases representing real cases of specific domains \n(which we call “domain databases”), namely, the UCs-Satellite, PAF-Address and ATP \nPlayers datasets. ‘Reg’ stands for ‘regression’ imputation (the output is a numerical value) \nand ‘Class’ stands for ‘classification’ imputation (the output is a a nominal or a textual \nvalue). Here, we focus on two learning strategies: zero-shot and 9-shot. We employ the Full \nprompt described in Sect.  3.2. We discard the use of traditional imputation methods for \ncomparison since some of the attributes are textual and they cannot be directly processed \nby the DecisionTreeClassifer. If we analyse the performance for GPT-3, we see that, in \ngeneral, the results are positive, with 0.48 and 0.80 as average performance for, respec-\ntively, zero-shot and 9-shot strategies. Focusing on the 9-shot, the exception to the good \nresults is the dataset PAF-Address. In this case, the instances are formed by different com-\nponents of actual addresses in the UK and, for most of the features, the model was not able \nto correctly infer the individual values of one feature given the others. In some cases lan-\nguage models following a zero-shot learning strategy failed because they were not able to \nproperly identify the task to be performed.\nFigure 7 (right) shows the results for the UCI datasets (Mpg, Iris and Adult). Here, we \nanalyse four different strategies: 1-Feature prompt with 99 examples; Full prompt with \n9-shot; Full prompt with zero-shot; and a DecisionTreeClassifer trained with 99 exam-\nples and only one feature (the most relevant one with respect to the target). The results \nin Fig.  7(right) show that language models have a comparable effectiveness to imputa-\ntion methods based on simple predictive models (decision trees). This is specially the case \nwhen following the 1-Feature prompt strategy with 99-shot, which seems to be the best \noption in all datasets except for MPG.\n5  Conclusions\nLarge language models based on transformers and trained on enormous datasets have \nrecently disrupted artificial intelligence thanks to an unexpected abstraction capacity that \nhas expanded their applicability to fields and problems not originally anticipated. In this \nwork we have analysed different configurations and prompts, as well as the effect of the \n2078 Machine Learning (2023) 112:2053–2082\n1 3\nnumber of examples (from zero-shot to 99-shot, depending on the problem) to see their \nperformance for a wide range of data wrangling problems. To our knowledge, this paper is \nthe first one that explores the possibilities of language models for data wrangling problems. \nThe results show the capacity of these systems to learn transformation functions from few \nexamples, to detect data types and domains, determine when there is an order in the attrib-\nutes and in many cases give the order as well, complete missing data based on semantic \ncomponents, rather than statistical properties and, to some extent, detect anomalous data. \nThe performance of the studied language models is comparable to well-known systems \nspecialised in data wrangling for some of the batteries, and a good complement that fills \nnew niches for others. These results open a promising research direction to explore the \npossible applications of language models when used freely through their Application Pro-\ngramming Interfaces (APIs) or when integrated into specialised tools for data wrangling. \nThis is not limited to data wrangling, but could well be used for other tasks in data science, \nespecially those that can be learnt from very few examples and require extensive domain \nknowledge (De Bie et al., 2022).\nEven so, access to large language models is still limited because of cost, infrastructure, \nprivacy issues or lack of training. It is infeasible to use them locally and therefore differ -\nent subscription models are provided to users via APIs, but this access is still restricted \nor expensive. We think that this paper comes at the right time, as new open initiatives are \nemerging to universalise the use of such systems. A notable example is the BigScience 14 \nconsortium consisting of 900 researchers from 60 countries and more than 250 institutions. \nThey are jointly creating very large multilingual language models for universal and free \naccess by the scientific community and other professional users. This will make the sce-\nnario and pipelines we are describing more common.\nAll in all, throughout the paper we have tried to understand how we can include lan-\nguage models in the data processing and analysis pipeline. Note that it was not our goal to \nsee for each and every task whether current language models are better than those systems \nthat are specialised in solving data wrangling tasks. Our paper mostly focuses on a general \nassessment of the possibilities, the range of tasks and prompts data scientists should use \nfor particular cases in their data processing pipelines. The integration of each particular \nsolution into specific tools that maximise performance would end up with a large number \nof systems the user would need to know and the effort of realising which one serves each \nparticular problem.\nCoping with variability with a general and flexible approach instead comes at the cost of \nsome familiarity and maturity of the users. Part of this will come from experience, as they \nstart using language models successfully. For instance, in Table 10 we show the data-wran-\ngling tasks where GPT-3 can help automate according to our experiments, under which \nconditions the systems are most and least useful. While this only applies for the tasks and \nGPT-3, it is also possible to set some basic guidelines that can be followed for the general \nuse of language models in data wrangling and other data processing pipelines (see Table 16 \nin the Supplementary material).\nAs future work, we would like to analyse how data wrangling automation can be \nimproved by giving more information to the user about the reliability of the results given \nby the language models, using their probabilities and determining cutoffs. Some assis-\ntance for choosing examples or prompts could also be useful. It is also necessary that other \n14 https:// bigsc ience. huggi ngface. co/\n2079Machine Learning (2023) 112:2053–2082 \n1 3\nresearchers, especially those in human-computer interaction, perform studies with real data \nscientists and machine learning practitioners using language models for data wrangling. \nQuestionnaires should be conducted to evaluate how effective the automation or assistance \nis. This is necessary to determine how useful these systems are, since the way they are used \nis very different from other data wrangling systems, and a comparison solely based on per-\nformance –ignoring many other factors– will always be partial.\nSupplementary Information The online version contains supplementary material available at https:// doi. \norg/ 10. 1007/ s10994- 022- 06259-9.\nAcknowledgements We thank Lidia Contreras for her help with the Data Wrangling Dataset Repository. \nWe thank the anonymous reviewers from ECMLPKDD Workshop on Automating Data Science (ADS2021) \nand the anonymous reviewers of this special issue for their comments.\nAuthor contributions All authors contributed equally to this work.\nFunding Open Access funding provided thanks to the CRUE-CSIC agreement with Springer Nature. \nThis work was funded by the Future of Life Institute, FLI, under grant RFP2-152, the MIT-Spain - INDI-\nTEX Sustainability Seed Fund under project COST-OMIZE, the EU (FEDER) and Spanish MINECO \nunder RTI2018-094403-B-C32  and  PID2021-122830OB-C42, Generalitat Valenciana under PROME-\nTEO/2019/098 and INNEST/2021/317, EU’s Horizon 2020 research and innovation programme under grant \nagreement No. 952215 (TAILOR) and US DARPA HR00112120007 ReCOG-AI.\n Data availability The Manipulation Battery is publicly available at https:// github. com/ google/ BIG- bench/ \ntree/ main/ bigbe nch/ bench mark_ tasks/ mult_ data_ wrang ling and https:// github. com/ gonza lojai movit ch/ \nlm- dw.\n Code availability All the code and results can be found in https:// github. com/ gonza lojai movit ch/ lm- dw.\nDeclarations \nConflict of interest No conflicts of interest or competing interests.\nConsent for publication Not applicable.\nEthical approval Not applicable.\nConsent to participate Not applicable.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, \nwhich permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, provide a link to the Creative Com-\nmons licence, and indicate if changes were made. The images or other third party material in this article \nare included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the \nmaterial. If material is not included in the article’s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly \nfrom the copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\nReferences\nAshok, P., & Nawaz, G. K. (2016). Outlier detection method on uci repository dataset by entropy based \nrough k-means. Defence Science Journal, 66(2), 113–121.\nBellmann, P., & Schwenker, F. (2020). Ordinal classification: Working definition and detection of ordinal \nstructures. IEEE Access, 8, 164380–164391. https:// doi. org/ 10. 1109/ ACCESS. 2020. 30215 96\n2080 Machine Learning (2023) 112:2053–2082\n1 3\nBen-Gal, I. (2005). Outlier detection. In Data mining and knowledge discovery handbook (pp. 131–146). \nSpringer.\nBender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). On the dangers of stochastic par -\nrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness, \nAccountability, and Transparency (pp. 610–623). FAccT ’21.\nBengio, Y., Ducharme, R., Vincent, P., & Janvin, C. (2003). A neural probabilistic language model. The \nJournal of Machine Learning Research, 3, 1137–1155.\nBhupatiraju, S., Singh, R., Mohamed, A. R., & Kohli, P. (2017). Deep API programmer: Learning to pro-\ngram with APIs. arXiv preprint arXiv: 1704. 04327.\nBIG-bench collaboration. (2022). Beyond the imitation game: Measuring and extrapolating the capabilities \nof language models. arXiv preprint arXiv: 2206. 04615. https:// github. com/ google/ BIG- bench/\nBrown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., \nSastry, G., Askell, A., & Agarwal, S. (2020). Language models are few-shot learners. arXiv preprint \narXiv: 2005. 14165.\nChen, Y., Dang, X., Peng, H., & Bart, H. L. (2008). Outlier detection with the kernelized spatial depth func-\ntion. IEEE Transactions on Pattern Analysis and Machine Intelligence, 31(2), 288–305.\nContreras-Ochando, L., Ferri, C., & Hernández-Orallo, J. (2019a). Automating common data science matrix \ntransformations. In ECMLPKDD workshop on Automating Data Science. ECML-PKDD ’19.\nContreras-Ochando, L., Ferri, C., Hernández-Orallo, J., Martínez-Plumed, F., Ramírez-Quintana, M. J., & \nKatayama, S. (2019b). Automated data transformation with inductive programming and dynamic back-\nground knowledge. In Proceedings of the European Conference on Machine Learning and Knowledge \nDiscovery in Databases, ECML PKDD 2019. ECML-PKDD ’19.\nCropper, A., Tamaddoni, A., & Muggleton, S. H. (2015). Meta-interpretive learning of data transformation \nprograms. In Inductive Logic Programming (pp. 46–59).\nDas, K., & Schneider, J. (2007). Detecting anomalous records in categorical datasets. In Proceedings of \nthe 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (pp. \n220–229).\nDas, K., Schneider, J., & Neill, D. B. (2008). Anomaly pattern detection in categorical datasets. In Proceed-\nings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining \n(pp. 169–176).\nDe Bie, T., De Raedt, L., Hernández-Orallo, J., Hoos, H. H., Smyth, P., & Williams, C. K. I. (2022). Auto-\nmating data science: Prospects and challenges. Communications of the ACM, 65(3), 76–87.\nDevlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). BERT: Pre-training of deep bidirectional trans-\nformers for language understanding. arXiv preprint arXiv: 1810. 04805.\nDua, D., & Graff, C. (2017). UCI machine learning repository. http:// archi ve. ics. uci. edu/ ml.\nEllis, K., & Gulwani, S. (2017). Learning to learn programs from examples: Going beyond program struc-\nture. In IJCAI (pp. 1638–1645).\nFernando, M. P., Cèsar, F., David, N., & José, H. O. (2021). Missing the missing values: The ugly duckling \nof fairness in machine learning. International Journal of Intelligent Systems, 36(7), 3217–3258.\nFerrari, A., & Russo, M. (2016). Introducing Microsoft Power BI. Microsoft Press.\nFurche, T., Gottlob, G., Libkin, L., Orsi, G., & Paton, N. W. (2016). Data wrangling for big data. Challenges \nand opportunities. EDBT, 16, 473–478.\nGao, T., Fisch, A., & Chen, D. (2020). Making pre-trained language models better few-shot learners. arXiv \npreprint arXiv: 2012. 15723.\nGarcía, S., Ramírez-Gallego, S., Luengo, J., Benítez, J. M., & Herrera, F. (2016). Big data preprocessing: \nMethods and prospects. Big Data Analytics, 1(1), 1–22.\nGulwani, S. (2011). Automating string processing in spreadsheets using input-output examples. In Procs. \n38th Principles of Programming Languages (pp. 317–330).\nGulwani, S., Hernández-Orallo, J., Kitzelmann, E., Muggleton, S. H., Schmid, U., & Zorn, B. (2015). Induc-\ntive programming meets the real world. Communications of the ACM, 58(11), 90–99.\nHam, K. (2013). OpenRefine (version 2.5). http:// openr  efine. org. free/ Open-source tool for cleaning and \ntransforming data. Journal of the Medical Library Association: JMLA, 101 (3), 233.\nHe, Z., Xu, X., Huang, Z. J., & Deng, S. (2005). Fp-outlier: Frequent pattern based outlier detection. Com-\nputer Science and Information Systems, 2(1), 103–118.\nHendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., & Steinhardt, J. (2021). Measuring \nmassive multitask language understanding. In ICLR.\n2081Machine Learning (2023) 112:2053–2082 \n1 3\nHendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart, S., Tang, E., Song, D., & Steinhardt, J. (2021). \nMeasuring mathematical problem solving with the MATH dataset. In CoRR. arxiv: 2103. 03874.\nHulsebos, M., Hu, K., Bakker, M., Zgraggen, E., Satyanarayan, A., Kraska, T., Demiralp, Ç., & Hidalgo, C. \n(2019). Sherlock: A deep learning approach to semantic data type detection. In Proceedings of the 25th \nACM SIGKDD International Conference on Knowledge Discovery & Data Mining (pp. 1500–1508).\nIzacard, G., & Grave, E. (2020). Leveraging passage retrieval with generative models for open domain ques-\ntion answering. arXiv preprint arXiv: 2007. 01282.\nJaimovitch-Lopez, G., Ferri, C., Hernandez-Orallo, J., Martinez-Plumed, F., & Ramirez-Quintana, M. J. \n(2021). Can language models automate data wrangling?. In ECML/PKDD Workshop on Automated \nData Science (ADS2021). https:// sites. google. com/ view/ autods.\nKandel, S., Paepcke, A., Hellerstein, J., & Heer, J. (2011). Wrangler: Interactive visual specification of data \ntransformation scripts. In Proceedings of the SIGCHI Conference on Human Factors in Computing \nSystems (pp. 3363–3372). ACM.\nLazarevic, A., & Kumar, V. (2005). Feature bagging for outlier detection. In Proceedings of the Eleventh \nACM SIGKDD International Conference on Knowledge Discovery in Data Mining (pp. 157–166).\nLu, Y., Bartolo, M., Moore, A., Riedel, S., & Stenetorp, P. (2021). Fantastically ordered prompts and where \nto find them: Overcoming few-shot prompt order sensitivity. arXiv preprint arXiv: 2104. 08786.\nNazabal, A., Williams, C. K., Colavizza, G., Smith, C. R., & Williams, A. (2020). Data engineering for data \nanalytics: A classification of the issues, and case studies. arXiv preprint arXiv: 2004. 12929.\nNoto, K., Brodley, C., & Slonim, D. (2012). Frac: A feature-modeling approach for semi-supervised and \nunsupervised anomaly detection. Data Mining and Knowledge Discovery, 25(1), 109–133.\nPedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Pretten-\nhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, \nM., & Duchesnay, E. (2011). Scikit-learn: Machine learning in Python. Journal of Machine Learning \nResearch, 12, 2825–2830.\nPetrova-Antonova, D., & Tancheva, R. (2020). Data cleaning: A case study with OpenRefine and Trifacta \nWrangler. In International Conference on the Quality of Information and Communications Technology \n(pp. 32–40). Springer.\nPorwal, U., & Mukund, S. (2017). Outlier detection by consistent data selection method. arXiv preprint \narXiv: 1712. 04129.\nPuri, R., & Catanzaro, B. (2019). Zero-shot text classification with generative language models. arXiv pre-\nprint arXiv: 1912. 10165.\nRadford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019). Language models are unsuper-\nvised multitask learners. OpenAI Blog, 1(8), 9.\nRaman, V., & Hellerstein, J. M. (2001). Potter’s wheel: An interactive data cleaning system. In VLDB \n(Vol. 1, pp. 381–390).\nReed, S., Zolna, K., Parisotto, E., Colmenarejo, S. G., Novikov, A., Barth-Maron, G., Gimenez, M., Sulsky, \nY., Kay, J., Springenberg, J. T., & Eccles, T. (2022). A generalist agent. arXiv preprint arXiv: 2205. \n06175.\nRubin, D. B. (1976). Inference and missing data. Biometrika, 63(3), 581–592.\nSchick, T., & Schütze, H. (2020). Exploiting cloze questions for few-shot text classification and natural lan-\nguage inference. arXiv preprint arXiv: 2001. 07676.\nShannon, C. E. (1949). Communication theory of secrecy systems. The Bell System Technical Journal, \n28(4), 656–715.\nShi, Y., Li, W., & Sha, F. (2016). Metric learning for ordinal data. In Proceedings of the AAAI Conference \non Artificial Intelligence (Vol. 30).\nSingh, R., & Gulwani, S. (2015). Predicting a correct program in programming by example. In International \nConference on Computer Aided Verification (pp. 398–414). Springer.\nSingh, R., & Gulwani, S. (2016). Transforming spreadsheet data types using examples. In Proceedings of \nthe 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (pp. \n343–356).\nSleeper, R. (2021). Tableau Desktop Pocket Reference. O’Reilly Media Inc.\nSmith, S., Patwary, M., Norick, B., LeGresley, P., Rajbhandari, S., Casper, J., Liu, Z., Prabhumoye, S., \nZerveas, G., Korthikanti, V., & Zhang, E. (2022). Using deepspeed and megatron to train megatron-\nturing nlg 530b, a large-scale generative language model. arXiv preprint arXiv: 2201. 11990.\nTamkin, A., Brundage, M., Clark, J., & Ganguli, D. (2021). Understanding the capabilities, limitations, and \nsocietal impact of large language models. arXiv preprint arXiv: 2102. 02503.\nTerrizzano, I. G., Schwarz, P. M., Roth, M., & Colino, J. E. (2015). Data wrangling: The challenging jour -\nney from the wild to the lake. In CIDR.\nTrifacta (2022): Trifacta Wrangler. https:// www. trifa cta. com\n2082 Machine Learning (2023) 112:2053–2082\n1 3\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., & Polosukhin, I. \n(2017). Attention is all you need. arXiv preprint arXiv: 1706. 03762.\nWei, J., Bosma, M. P., Zhao, V., Guu, K., Yu, A. W., Lester, B., Du, N., Dai, A. M., & Le, Q. V. (2022). \nFinetuned language models are zero-shot learners. https:// openr eview. net/ forum? id= gEZrG CozdqR\nWu, B., Szekely, P., & Knoblock, C. A. (2012). Learning data transformation rules through examples: Pre-\nliminary results. In Information Integration on the Web (p. 8).\nXu, S., Semnani, S. J., Campagna, G., & Lam, M. S. (2020). AutoQA: From databases to QA semantic pars-\ners with only synthetic training data. In EMNLP.\nZeng, W., Ren, X., Su, T., Wang, H., Liao, Y., Wang, Z., Jiang, X., Yang, Z., Wang, K., Zhang, X., & Li, \nC. (2021). Pangu-/u1D6FC : Large-scale autoregressive pretrained chinese language models with auto-parallel \ncomputation. arXiv preprint arXiv: 2104. 12369.\nZhang, D., Suhara, Y., Li, J., Hulsebos, M., Demiralp, Ç., & Tan, W. C. (2019). Sato: Contextual semantic \ntype detection in tables. arXiv preprint arXiv: 1911. 06311.\nZoph, B., Bello, I., Kumar, S., Du, N., Huang, Y., Dean, J., Shazeer, N., & Fedus, W. (2022). Designing \neffective sparse expert models. arXiv preprint arXiv: 2202. 08906.\nPublisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations."
}