{
  "title": "Circling the Void: Using Heidegger and Lacan to think about Large Language Models",
  "url": "https://openalex.org/W4380876326",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5026569120",
      "name": "Marc Heimann",
      "affiliations": [
        "Hochschule Niederrhein"
      ]
    },
    {
      "id": "https://openalex.org/A5065081401",
      "name": "Anne-Friederike Hübener",
      "affiliations": [
        "Hochschule Niederrhein"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4251623682",
    "https://openalex.org/W4229553741",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2965647350",
    "https://openalex.org/W4285287265",
    "https://openalex.org/W165632433",
    "https://openalex.org/W3120273657",
    "https://openalex.org/W4327813466",
    "https://openalex.org/W4306809343",
    "https://openalex.org/W3034995113",
    "https://openalex.org/W4241072860",
    "https://openalex.org/W2153579005",
    "https://openalex.org/W3111239699",
    "https://openalex.org/W4319971921",
    "https://openalex.org/W4238627241",
    "https://openalex.org/W4252295669",
    "https://openalex.org/W4253394296",
    "https://openalex.org/W1498436455",
    "https://openalex.org/W4241775074",
    "https://openalex.org/W1537643761",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4254175326",
    "https://openalex.org/W1796453065",
    "https://openalex.org/W1524153682",
    "https://openalex.org/W3004346089"
  ],
  "abstract": "Abstract The essay aims to unite two currently distinct lines of thinking and working with language. Large Language Models and continental philosophy, especially Martin Heidegger’s thinking about language and, building upon Sigmund Freud, Jaques Lacan’s structural psychoanalysis. We show that the concept of language that Heidegger, Freud and Lacan discuss and utilize in clinical frameworks is matched quite strongly by modern LLMs. This allows us to discuss a problem of negation and negativity that is central to the continental discourse but missing in current LLM research. This also means that we offer a radically different approach than it is usual in the philosophy of artificial intelligence, since we base our concepts on thinkers that are often disregarded in the analytic philosophy discourse that is closer linked to AI research. To this end we also mark, where the ontological differences of the proposed approach lie. However, our aim is to address AI researcher and continental philosophers.",
  "full_text": "Page 1/21\nCircling the Void: Using Heidegger and Lacan to\nthink about Large Language Models\nMarc Heimann  (  marc.heimann@hs-niederrhein.de )\nHochschule Niederrhein\nAnne-Friederike Hübener \nHochschule Niederrhein\nResearch Article\nKeywords: AI, LLM, continental philosophy, psychoanalytic language theory, Heidegger, Lacan\nPosted Date: November 2nd, 2023\nDOI: https://doi.org/10.21203/rs.3.rs-3023378/v3\nLicense:     This work is licensed under a Creative Commons Attribution 4.0 International License.  \nRead Full License\nAdditional Declarations: No competing interests reported.\nPage 2/21\nAbstract\nThe paper aims to unite two currently distinct ways of thinking about and working with language. Large\nlanguage models and continental philosophy, especially Martin Heidegger's thinking about language and,\nbuilding on Sigmund Freud, Jacques Lacan's structural psychoanalysis. We show that the concept of\nlanguage that Heidegger, Freud, and Lacan discussed and utilized in clinical frameworks is quite well\nmatched by modern LLMs. This allows us to discuss a problem of negation and negativity that is central\nto continental discourse but absent from current LLM research. This also means that we offer a radically\ndifferent approach than is usual in the philosophy of arti\u0000cial intelligence, since we base our concepts on\nthinkers who are often neglected in the discourse of analytic philosophy that is closer to AI research. To\nthis end, we also indicate where the ontological differences of the proposed approach lie. Our aim,\nhowever, is to address both AI researchers and continental philosophers.\nIntroduction\nIn a recent op-ed in The New York Times, Noam Chomsky et al. (2023) remarked on the popularity of\nmodern Large Language Models (LLMs) with a striking statement: „Given the amorality, faux-science and\nlinguistic incompetence of these systems, we can only laugh or cry at their popularity“. This statement\nmay seem surprising, especially since these systems currently demonstrate an astonishing ability to\nunderstand human language, even quite complicated scienti\u0000c texts. In a way, Chomsky et al. are right:\nChatGPT, as well as other LLMs, do have (openly acknowledged) di\u0000culties. However, the question is\nwhether Chomsky et al. are exposing the problem or obfuscating it. While Chomsky advocates a rule-\nbased system, others such as Frederick Jelinek have advocated a very different approach. In the context\nof AI's connection to linguistics, Jelinek's famous quote, „Every time I \u0000re a linguist, the performance of\nthe speech recognizer goes up,“ is particularly relevant to linguists educated in Chomsky's theories.\nJelinek was a pioneer in the \u0000eld of statistical language processing, helping to shift the focus from rule-\nbased systems, such as those rooted in Chomsky's theories, to data-driven approaches. Modern LLMs\nsuch as GPT-4, which rely on deep learning and neural networks to process and generate human-like text,\nundoubtedly owe much of their development to Jelinek's emphasis on data-driven methods and\nstatistical approaches, even if they are not directly based on his work. This shows that Chomsky's critique\nis deeply rooted in the way modern AI research is linked to linguistics.\nWhat, then, is the argument that Chomsky et al. make about LLMs? They argue in the opinion piece that\ntrue human ability is characterized by operating on a rules-based system, and that „marinating in Big\nData“ (Chomsky et al., 2023) is not enough. However, it is noteworthy that in terms of everyday language,\nmarinating in big data is at an astonishing level enough to be able to work with it. To think like humans,\nas Chomsky et al. (2023) argue, AIs need to be „endowed“ with the same „universal grammar“ that\nhumans use. Interestingly, the data-driven methodologies that Jelinek helped pioneer may \u0000nd a\nphilosophical ally in the language theories proposed by continental philosophy.\nPage 3/21\nWe contest the perspective of Chomsky et al. and aim to demonstrate that LLM should instead move\nfurther away from rule-based systems, and that it might \u0000nd support in theories of language proposed by\ncontinental philosophy. Continental philosophers’ theories of language mirror some of the theories\ndeveloped by language modelers, most notably the „distributional hypothesis“ (Gastaldi, 2021), but\napproach the problem of language with a broader conceptual \u0000eld, not limited to the applied form of\nreasoning to which computers are bound. What we will try to mark in this paper is that LLMs are \u0000rst of\nall better approached by the theories of language developed in continental philosophy, especially by\nHeidegger and Lacan, and that a problem called the „impasse of formalization“ also appears in LLMs, but\nsince this problem is not considered in itself, it weakens the way the models represent language. This\npaper introduces a novel perspective that bridges computer science and continental psychoanalytic\nphilosophy. As such, readers may \u0000nd themselves in unfamiliar territory in one or both of these \u0000elds. \nWhat if the move away from rule-based systems was not radical enough, given that speech recognition\nseems to have taken off only after abandoning these ideas of rule-based approaches? A statistical\nmodel, even one based on fractal probabilities and not just bell curve variations, still assumes an\nontological basis that has been under attack from various disciplines for more than a hundred years: the\nidea of ontologically \u0000xed nature. The Cartesian „clara et distincta” is not just a formal requirement of our\nstatements, but is more deeply rooted in reality itself. The genesis of this idea is, of course, theological:\nthe stability of nature's clara et distincta was guaranteed by the Christian God. Now, even modern\nstatistics requires that the „roll of the dice“ on which it was conceptualized be thought of as structured by\n\u0000xed ontological laws. This has recently been discussed by Quentin Meillassoux (2008, pp. 96-98) as a\nproblem because it denies statistical realism (the now dominant ontology of many sciences) access to\nthe problem of indeterminacy. However, this is not a criticism of the statistical basis of LLMs, as we will\ndiscuss later, but a problem of the ontological foundations that Chomsky assumes.\nThis problem of indeterminacy is rooted in philosophy and \u0000nds its way into formal logic and\nmathematics. Originally characterized by the loss of the absolute foundations of thought, most\nprominently explored in Nietzsche's „Death of God,“ it has also been explored by mathematicians and\nlogicians such as Kurt Gödel with his incompleteness theorems, which showed that any axiomatic\nsystem capable of expressing arithmetic is necessarily incomplete and cannot prove its own consistency.\nGödel's theorems revealed fundamental limitations of formal systems, which can be seen as a form of\nindeterminacy, in the sense that there will always be true statements within a formal system that cannot\nbe proven within the system itself. While Gödel's theorem is not an ontological statement and should not\nbe taken as such without further consideration, the consequences for ontology should be taken seriously.\nIn current philosophy, it has in\u0000uenced Alain Badiou (2006) as well as Quentin Meillassoux (2008), both\nof whom have pointed out that we need to think of our formal systems of thought in terms of the\n„impasse of formalization“ (Badiou, 2006, p. 5). This impasse, as Badiou identi\u0000es it, is both outside our\nformal systems and marked by an in\u0000nite excess that they necessarily produce. It is a central notion that\nwe will discuss in detail because it implies a rich \u0000eld of research for AI research if it is informed by\npsychoanalytic philosophy.\nPage 4/21\nThis impasse re\u0000ects a formal problem that Kant (KrV, B97 A72) \u0000rst marked in his logical concept of an\nin\u0000nite judgment. In\u0000nite judgment is a speci\u0000c kind of judgment that, according to Kant, involves a\nnegative judgment about a concept that has an in\u0000nite extension. In other words, it negates a concept\nthat covers an unlimited scope. In\u0000nite judgments are contrasted with a\u0000rmative judgments (which\nassert the connection between a subject and a predicate) and negative judgments (which deny the\nconnection between a subject and a predicate). An example of an in\u0000nite judgment is the statement „the\nsoul is not mortal”. Here, the concept of „the soul“ is negated by the concept of „not mortal,“ which\nimplies that the soul has an in\u0000nite extension or is immortal. This formal concept is later explored by\nMartin Heidegger (1976a) in „What is Metaphysics,“ where he points out that every universal judgment\ncreates an indeterminate negative excess. The point is that this excess, far from being purely negative,\nhas an impact on our lives. However, it takes psychiatry and the development of psychoanalysis by\nSigmund Freud and later Jacques Lacan to develop a true logical examination of these problems of the\nimpasse of formalization.\nWords and Large Language Models\nTo understand why a Lacanian or a broader approach rooted in continental philosophy is helpful in\nthinking about current AI models, let us \u0000rst take a concrete look at present LLMs. I will not go too deeply\ninto the technical details, as there are countless other papers on these models to deepen one's\nunderstanding. However, let us take a simpli\u0000ed look at how a prompt is processed by the general\ntechnical structure of a state-of-the-art language model. Consider a scenario where we want to generate a\ncontinuation for the following prompt: „He jumped the...“. We will use a simpli\u0000ed version of the GPT-3\narchitecture for this example. This un\u0000nished sentence is then processed by several interlinked\nmechanisms within the model.\nThe input sequence „He jumped the...“ is \u0000rst passed through an input embedding layer, which converts\nthe sequence into a set of continuous vector representations (Mikolov et al., 2013). Each word in the\nsequence is broken down into tokens, which can be whole words or smaller units, depending on the\nlanguage and the speci\u0000c word. LLMs break down input sequences into tokens and convert them into\ncontinuous vector representations that capture the meaning and context of each token within the\nsequence. This process is performed by the input embedding layer. Each word in the prompt is also\npositionally encoded, which is crucial for providing the model with information about the position of\nwords in a sequence. However, these vectors are only initialized at this point. After this initial input\nembedding, the Self-Attention layers allow the LLM to read this sentence in different directions and/or\nwith emphasis on different words (cf. Vaswani et al., 2017). \nThe vector representations of the tokens are passed through multiple layers of the self-attention\nmechanism in the model. At each layer, the model calculates attention scores for each token based on its\nrelationships with all other tokens in the sequence. The attention scores are used to weight the vector\nrepresentations, allowing the model to focus more on the relevant tokens for each position in the\nsequence. This mechanism allows the LLM not only to understand a token in a rule-based approach, but\nPage 5/21\nalso to represent different levels of metaphoric and metonymic links between tokens in the input. This is\nan important step, as it moves the structure of a sentence or prompt away from models that simply\nprocess it in a linear way, and allows for a diverse and complex interpretation of the words, not unlike\nwhat one would do in a classical close-reading interpretation. There are some important caveats here,\nwhich will be discussed later, but the gist is correct insofar as we assume that a close-reading will try to\ncapture as much as possible of the inherent formal relationship within a given sentence.\nThese weighted vector representations are then passed through multiple feedforward layers. Each\nfeedforward layer consists of a dense layer followed by an activation function that applies a non-linear\ntransformation to the vector representations. The feedforward layers in a large language model such as\nGPT-3 are an essential component of the model, responsible for transforming the input sequence into a\nmore expressive and high-dimensional, vector-based representation of linguistic relations that can\ncapture complex relationships between words (see Brown et al., 2020). \nIn simple terms, the feedforward layers in an LLM work by taking the vector representation of each word\nin the input sequence and transforming it into a new vector representation that captures higher-level\nfeatures and relationships between words in general. What happens here, in layman's terms, is that the\nrepresentation of the prompt is interlinked with the LLM's representation of the language. Each of these\nlayers does two things with the original prompt. First, the input vector representation of each word in the\nsequence is transformed linearly by multiplying it by a weight matrix and adding a bias vector. This is a\ncritical step, and its actions are informed by the machine learning process, which allows the model to\nattach these weights via a weight matrix (cf. Rumelhart et al., 1986). A weight matrix is a matrix of\nparameters that is learned during the training process and is used to transform the input vector\nrepresentation of each word in the sequence into a new, higher-dimensional vector representation. The\nweight matrix is learned during the training process and updated iteratively to minimize the difference\nbetween the predicted output of the model and the actual output.\nThe resulting output of the feedforward layer is a new, higher-dimensional vector representation of the\nword that captures higher-level features and relationships between words. As an example of a higher-\ndimensional vector representation, consider the word „king.“ The vector representation of „king“ is a multi-\ndimensional vector, where each dimension captures a different feature or relationship between the word\nand other words in the language. Some of these dimensions may capture syntactic relationships, such as\nthe subject-verb-object relationship between „king“, „rules“, and „kingdom“. However, the model as a\nwhole also learns to represent these kinds of syntactic relationships between words in a string in more\ngeneral terms. Some dimensions might capture semantic relationships, such as the fact that „king“ is\nrelated to other royal words like „queen,“ „prince,“ and „duke. Other dimensions might capture contextual\nrelationships, such as the fact that „king“ is often used in the context of historical texts or fantasy stories.\nDuring training, both the weight matrix and the bias vector are updated to optimize the objective function\nof the model, typically through a process called backpropagation. An objective function, also known as a\nloss function or cost function, is a mathematical function used to quantify the difference between a\nPage 6/21\nmodel's predicted output and its actual output. This is done by computing the gradient of the objective\nfunction with respect to the weight matrix and using that gradient to update the values of the weight\nmatrix to minimize the difference represented by the objective function. The output of the linear\ntransformation is then passed through a non-linear activation function, which introduces non-linearity\ninto the model and allows it to capture more complex relationships between words. In the context of\nneural networks, non-linearity is important because it allows the model to capture more complex\nrelationships between input and output. If a model were only able to represent linear relationships, it\nwould not be able to capture many of the complex patterns and relationships present in real-world data.\nFor example, in image recognition tasks, a linear model may have di\u0000culty recognizing complex shapes\nand patterns, but when used correctly, it can still capture more than just simple shapes such as straight\nlines or circles.\nThe \u0000nal output of the model is then generated by passing the output of the feedforward layers through\nan output layer that predicts the probability distribution of the next word in the sequence. The output layer\nis a softmax function, which is a mathematical function used to convert a vector of real numbers into a\nprobability distribution (Bishop, 2006, p. 198). The softmax function is often used in classi\u0000cation tasks,\nwhere the goal is to predict the probability that an input belongs to each of several possible classes. The\nmodel then samples from this distribution to generate the next word in the sequence. In our example, the\nLLM would generate a continuation for the prompt by passing the initial sequence through the input\nembedding, self-attention, and feedforward layers, and then using the output layer to predict the next\nword in the sequence. The generated continuation would then be added to the prompt, and the process\nrepeated until the desired length of the sequence was reached. (For further reading on the structure and\nbasis of LLMs in the GPT series: Alec Radford et al., 2019; Brown et al., 2020.)\nSo, to reformulate the example in terms much closer to non-technical readers, what we get with an LLM is\na highly complex model of language that is trained on vast amounts of text by learning which of those\nwords are usually (i.e., statistically) in relation to each other. It represents these relations by turning each\nword into a mathematical representation, which it then analyzes in relation to the relations extracted from\nits training data. A common argument against this process of creating a model of language is that it is\npurely statistical, but this is not entirely true. The product of the statistical analysis are the tokens with\ntheir inherent weights and links to other tokens. While this may have been created on the basis of\nstatistical inference, the structure created is not statistical. Instead, it can be thought of as a kind of\nlearned, high-dimensional, vector-based representation of linguistic relationships. This representation,\nwhile inherently mathematical, attempts to capture complex semantic and syntactic relationships\nbetween words, phrases, and broader linguistic structures.\nThere are several limitations to this approach, such as the production of nonsensical text, not only\nbecause humans produce vast amounts of nonsense themselves, but also because the statistical\napproach necessarily produces outliers. The mathematical core of this language model does not\n„understand“ anything, it is simply based on statistically detectable connections. This also makes it very\nsensitive to the phrasing of the input, and tends to produce verbose, overly con\u0000dent, or altogether too\nPage 7/21\ncautious outputs. This follows from the way it interacts with and emphasizes those inputs. This led to the\nidea of „prompt engineering“ as a way to address these limitations or to take them as a feature. However,\nit would be a mistake to assume that prompting is a lack rather than a central element of how the\nattention mechanism interacts with the stored data; in layman's terms, the prompt constitutes the\nperspective of the generated output. \nAnother central element is that it does not focus on complete sentences, which distances it from classical\nAristotelian (rule-based) approaches to logic and meaning, but instead focuses on tokens, which are\nwords, subwords (such as „meta-“), punctuation, and special characters. It reconstructs language from\nthese nex ū s to allow the model to reconstruct the complex metonymic and metaphoric connections. This\nof course distances it from several prominent approaches to the inherent rule-based logic of language,\nnotably the grammar-based approach advocated by Chomsky. But it also means that the continental\nFreudian/Heideggerian tradition, with its strong emphasis on the importance of the complex formal\nrelations of words as signi\u0000ers for other signi\u0000ers rather than sentences, is much closer to the theory of\nlanguage that LLMs approach. All of this may seem like an overly technical introduction to LLMs, but in\nstark contrast to Chomsky, we consider LLMs to be quite close to human language use. To demarcate\nthis proximity, we will use an example of language use that „Star Trek: The Next Generation” which allows\nus to link it to the word- and metaphor-centric understanding of language that we \u0000nd in continental\nphilosophy.\nPicard and Undivided Multitudes\nTo explore the proximity of the inner workings of LLMs and continental theories of language, we should\ntake a look at their metaphorical capabilities. To do this with an accessible example, we can use a\ntranslation example from the television series „Star Trek: The Next Generation”. In the episode „Darmok“,\nthe crew of the USS Enterprise encounters the Tamarians. Despite the Tamarians' attempts to establish\ncontact, their language and communication methods are initially incomprehensible to the Enterprise crew.\nRepresenting Chomsky's understanding of language, the ship's android Data notes early in the episode\nthat the Tamarians seem to have an incomprehensible language. However, by working together, the two\ngroups gradually achieve mutual understanding through the exchange of cultural stories and metaphors.\nThis use of language as such is not what we are after here. Instead, we want to look at how GPT-4, as an\nexample of an LLM, adapts this style of communication to explore the structure of its theory of language\n(something we are not the \u0000rst to think of, cf. Jansen & Boyd-Graber, 2022). We used the following\nprompt to turn GPT-4 into a Tamarian:\nAnswer in the metaphorical style that is used by the Tamarian captain, Dathon in the Star Trek: Next\nGeneration episode Darmok, but utilize European philosophy and science allegorically, instead of\nTamarian culture: Can you give me a short description of the attention mechanism in Large Language\nModels. \nPage 8/21\nThe reasoning behind this prompt is as follows: Given the structure of LLMs, we know that their inner\nmapping of references is not in itself organized to answer this question. Neither the „Darmok“ episode nor\nthe question itself should be strongly linked to an allegorical use of philosophy and science to\ncommunicate. The attention mechanism acts here as the metaphorical and limiting process itself, linking\ncomplex relational systems of different language games together to produce an intriguing rebus: \n„Einstein, his mind bent spacetime; Archimedes, in the tub, Eureka! The many, a cacophony, seeking the\nsun. Galileo, his telescope to the heavens, the planets align. Descartes, cogito ergo sum, the essence\ndistilled. Attention, the spotlight of consciousness, cast upon the words; the dance of meaning, woven in\nthe tapestry of language.” (GPT-4)\nWhile Chomsky's theories present a perspective on language that has di\u0000culties with this approach, other\nphilosophers such as Freud, Heidegger, and Lacan offer viewpoints that are particularly relevant to\nunderstanding the metaphorical language-processing capacities of LLMs. This structure of a rebus as an\nexplication of the inner structure of language and memory is not new; we \u0000nd it explicitly in Freud's\nTraumdeutung (1942, p. 284) as the primary structure of the dream, where he explores the formal\nstructures of the unconscious. And it shows us that in order to understand language, we should look at\nthe rebus not as something derived from sound sentences, but as the foundation of those sentences, as\nthe structure of LLMs implies. \nWhile Freud never developed a formal theory of language, the methodological basis of psychoanalysis is\nbuilt on a parallel understanding of language, since the clinical method of free association explicitly\nrejects the idea of a correct associative link and encourages patients to approach this manifold of\nassociative links from their own intentionality of perspective in order to reconstruct the relation of what is\nexplicitly said to the unconscious. Especially since this pre-predicative form of signifying operations is\nalso performed unknowingly (Olyff & Bazan, 2022). This connection is interesting to us because it offers\na strong parallel to LLMs. This is because each individual word or token derives its meaning not from its\nposition in the sentence, but by relying on the contextual elements provided by the training data. What\nmakes ChatGPT-4's output so lifelike is exactly this ability to metaphorically connect different contexts of\nmeaning, i.e., to access the fundamental structure of language.\nTo understand how LLMs like GPT-4 constitute a genuine understanding of language, it helps to consider\nHeidegger's perspective on the status of words in language. There is an important caveat here, especially\nfor readers from the Anglophone discourse on metaphors, which is dominated by Lakoff and Johnson's „\nMetaphors We Live By,“ but is usually unaware of the more complex theories of Blumenberg, Heidegger,\nand Freud, which substantially preceded Lakoff and Johnson (Schröder, 2008). There are several\ndifferences to be aware of here, but the most important is the ontological framework, which we will\ndiscuss below. Another important observation, one closer at hand, is that the continental discourse\nessentially focused on words in much the same sense that tokens are used by LLMs. That is, not only by\nfocusing on words rather than sentences, but also as word fragments. This shifts the focus to include\nrelatively complicated concepts like the „Gestell“ of the later Heidegger, where he exploits the German\nPage 9/21\nlanguage's tendency to build words out of smaller subwords, like the pre\u0000x „Ge-“. That this is already\nconceptualized in Heidegger is not immediately apparent, since Heidegger is not centrally interested in\nthis element of language. However, it can be argued that it is a long-standing approach in his works; he\ndiscusses early on that words are connected in a „Wortmannigfaltigkeit“ (Heidegger, 1979, p. 373), and in\nhis works on logic we \u0000nd the history of being structured by primordial words, which, like the Greek ϕ ύ σ ι ς \n(Heidegger, 1984, p. 131), fundamentally organize our epistemic and practical relation to beings, but are\n„themselves never fully unlocked or made fully intelligible“ (Greaves, 2018, p. 51), mirroring the master\nsigni\u0000ers of Lacan's or Blumenberg's absolute metaphors. Beyond these ontological anchors of language,\nhowever, it can be argued that even subwords are already discussed in his concept of language. While he\ncertainly assumes that a single word in everyday use is constituted by a connection between words: „a\nword as a whole is drawn, not from a primary, primordial experience of the subject matter, but from\npreconceptions and the nearest at hand views of thing“ (Heidegger, 2005, p. 12). We can also see that\neven subwords are already structured by such a variety of links. Take, for example, his discussion of the\npre\u0000x „un-“ when he suggests unconcealedness as the proper translation for aletheia: „The pre\u0000x un- in\n'unconcealedness' can mean that concealedness is taken away, canceled, expelled, or forbidden, where\ntaking away, cancelling, and forbidding are essentially different“ (Heidegger, 1998, p. 14). Even in the case\nof singular letters, Heidegger notes that „'Something as something' [is] in the background!“ (Heidegger,\n2007, p. 113), which means that for Heidegger the structure of meaning as a nexus of relations and\nindicative vectors already exists at the level of the single letter (allowing a direct link to the signi\u0000er of\nLacanian thought). This ties in with Heidegger's own insistence on paratactic translations, as discussed\nby Groth (2017, p. 143), which also focus on words rather than sentences.\nLet us take as another example the most important word in Heidegger's philosophy: being. In the „Basic\nConcepts of Metaphysics,“ Heidegger addresses the problem of the status of words through the concept\nof being in language, that is, the „is“ in spoken language. This means that he not only aims to\nconceptualize an ontological concept of being, but \u0000rst and foremost offers us a detailed understanding\nof how words function in his theory of language. He notes descriptively that the use of „is“ in a sentence\ncan express a manifold of meanings, a „what-being, whether in the form of so-being and essence-being,\nthe that-being and the true-being“ in one and the same sentence. This ambiguity, which Heidegger \u0000rst\nworks out through a historical comparison of the use of concepts of being, is, as he argues, a positive\nphenomenon of being as „is“. Accordingly, he says:\n„It is necessary to understand this peculiar indifference and universality of the 'is' as the original and\nprimary essence of the copula, or that which is externally called the copula.“\nThe starting point of the understanding of being in a proposition is therefore „the full undivided manifold“\nof this horizon of meaning of „is“. With regard to this horizon of meaning, Heidegger already emphasizes\nin „Being and Time“ that it is initially only a wholeness of referents (Heidegger, 1967, p. 87), which in itself\ndoes not refer to being, but only enables the reference to being as such. Thus, the meaning of a word\ndoes not consist in a reference to being, but in its relation to other meanings, or in Lacanian terms, in\nsignifying other signi\u0000ers. This meaning, as Heidegger already notes in his early work, is not originally\nPage 10/21\noriented to the sensible or to objects, but to their „ Wozu „ or „ Um-zu „. This „wherefore“ is originally\npractical, it is based in know-how, i.e., it is always already framed in a relational context of meanings that\nhas always already gone beyond any concrete given. \nWith regard to the transformer type LLM, we see that the process by which an LLM creates its model of\nnatural language corresponds to this discourse about language being constructed from partial words,\ninsofar as it also approaches individual tokens from a comparable undivided manifold of mathematized\nlinks, which is based in practice (i.e., the practice of writing that is present in the data on which it is\ntrained), just as Heidegger assumes that this manifold is based in practice. The attention mechanism\nthen tries to grasp the intention of a prompt by comparing it again with the weights generated by the data\nin its training. This means, however, that the attention mechanism operates here as a form of\ndetermination by negation, which needs to be further distinguished. But while this informs Heidegger's\nuse of combined words like the later „Ge-stell“ or the „Ab-Grund,“ it takes Lacan's insistence on the letter\nas a central element in psychoanalysis to fully approach a formal theory of the chain of signi\u0000ers. Lacan\nbuilds here on Freud's analysis of phonemes and puns, which allows for the reconstruction of the\nadditional link between words and subwords that are linked not by content but by speech as practice Let\nus take as an example the opening lines of the play „Hamlet” where puns are used to express a\nparadoxical idea. Although Claudius is both Hamlet’s uncle and his stepfather, he is not really a relative or\na kindred spirit:  „A little more than kin, and less than kind“ (1.2.65). It is important to note that Lacan\n(2006, p. 693) allows us to think of these phonemes as well as letters as partial objects. Partial objects\nare not objects structured by their inclusion in a whole, as the name might suggest, but only imply a\nwhole that includes them without actually being structured by that imaginary whole.\nAttention, Negativity and Undivided Multitudes\nHow can this undivided manifold be grasped more precisely, especially in relation to the ontological\nperspective that Heidegger assumes? Heidegger himself says that language, as structured by the\nintentional, that is, the speaker, approaches the undivided manifold that precedes the essence of λ \u0000 γ ο ς .\nWhile for Heidegger λ \u0000 γ ο ς  is always more than just a predicative logic based on complete sentences, it\nalso includes such a logic, but based on a pre-predicative standpoint (Heidegger, 1976b, pp. 153-155), in\nwhich the predicative statement is already constituted by a structure of „as“ (something as something).\nThus, in contrast to Chomsky's grammar, Heidegger takes the multiplicity of practical relations to be\nfoundational for the structured systems of logic. The reason for this is to be found in the way Heidegger\nthinks fundamentally about the concept of determination. Central to Heidegger is the assumption that\nany logic that is consistent is related to negativity. Meaning is therefore not only an intentional reference,\nbut this intentional reference is linked to something that cannot itself be referenced and can only be\ngrasped positively in a failure of the referent structure. In Being and Time, this failure of the structure of\nreference is my own death (not that of others). However, Heidegger later develops a more sophisticated\nconcept of this impasse of the formal structure of meaning in con\u0000ict (for further reading on the problem\nof con\u0000ict, see anonymized reference). \nPage 11/21\nSo, what does this mean for our parallelization to LLMs? What the attention mechanism does is it\nprovides a basis for limiting the undivided multitude and turning it into a divided multitude, that is, one in\nwhich certain links are not weighted strongly enough to appear in the output. For example, if I ask about\nRussell's „King of France,“ the inherent link of „king“ to „queen“ that should be established in the data is\nunlikely to appear in the output. In the case of Russell's „King of France,“ the LLM would use its attention\nmechanism to identify the key entities mentioned in the input text (i.e., „King“ and „France“) and then use\nthat information to generate a response. It is not necessarily the case that the LLM would completely\nignore an association between „ King“ and „ Queen“ simply based on the weighting of the attention\nmechanism, but it is unlikely that a question about Russell's „King of France“ would refer to a „Queen“ if\nthat association did not appear in the prompt. The model would consider all associations between words\nin the input text and generate an output based on the most likely associations given the context, which\nwould likely exclude the link between „King“ and „Queen“.\nSince the model does not retain this association, but instead turns the prompt into output, it is essentially\nnegated. Once the LLM generates its output, it does not retain any information about previous\nassociations between words or entities. Thus, if the LLM were to generate an output based on the input\ntext „Russell's King of France,“ it would not include any association between „King“ and „Queen,“ because\nthat association was not explicitly mentioned in the input text. In this case, the attention mechanism acts\nas a determination by negation, since its action is to exclude the possibility of a link between „King“ and\n„Queen“ based on the absence of this link in the input text. This shows an aspect that we have already\nintroduced: that the attention mechanism provides the perspective of the LLM's output. This perspective,\nfollowing the optical metaphor, excludes and highlights certain links contained in the training data. \nA well-constructed input prompt that provides context and guidance to the model can help the attention\nmechanism selectively activate parts of the feedback layers that are most relevant to the speci\u0000c output.\nThe ease with which Chat-GPT, for example, can be „jailbroken“ to ignore its ethical limitations testi\u0000es to\nthis mirror of perspective and intentionality as a central part of how the attention mechanism interacts\nwith the prompt. Since the multitude of words, or in the case of LLMs, complex systems of tokens, are in\nthemselves essentially an undivided manifold of connections, this intentionality is absolutely necessary\nto create meaningful sentences as a limit (or division) of this manifold. Intention as attention can thus be\nunderstood as a form of limitation, and this should be kept in mind, as it will be important for further\ndiscerning the ontological basis of Heidegger's thinking. \nIn order to go deeper into the problems that the continental discourse allows us to mark, let us look at the\nontological perspectives from which a theory based on signs and negations follows and why. For\nHeidegger, Freud, and the continental tradition build on the basic insights of these thinkers, Chomsky's\ngrammar-based approach is essentially a metaphysical solution to the problem of language, since\nHeidegger (1967, p. 10) considers the common understanding of logic and language to lag behind actual\nlanguage use and to be based on a vulgar ontology of presence. The only way to formulate a rigorous\nphilosophy, then, for an approach to logic that follows Heidegger, is to accept the abyss as the core of the\nratio (Ab-Grund). \nPage 12/21\nThe Abyss and Aesthetics\nIn contrast to Heidegger, the understanding of language that Chomsky elaborates in his seminal book\n„Syntactic Structures“ (1957) shows that his idea of a good theory and research is structured by the\nessentially aesthetic idea of „the simplicity of the whole system“ (Chomsky, 2002, p. 56). This principle of\nthe simplicity of a whole should accordingly organize the idea of \u0000nding a „metalanguage to the\nlanguage in which grammars are written - a metametalanguage to any language for which a grammar is\nconstructed“ (Chomsky, 2002, p. 54). Obviously, the idea of simplicity here acts as a counterforce to the\nlooming threat of in\u0000nite regress that encourages thinking about metametalanguages. But it also shows\nthat the implicit idea of determination that is prominent in Chomsky's thinking is that of a closed system\ngoverned by an internally absolute principle. This idea of a consistent system organized by a small set of\ninternal rules is not surprising, and within limits it is the most viable approach, especially with respect to\nmachines. Accordingly, Chomsky (2002, pp. 50-51) presents the goal of a theory of language in terms of\na machine that must provide a „practical and mechanical method for actually constructing grammar“.\nThis machine, as we can gather from Chomsky et al.'s (2023) commentary, is „the innate, genetically\ninstalled ‘operating system’ that endows humans with the capacity to generate complex sentences and\nlong trains of thought“. Now, for normal machines, like any computer one can pick up, this idea of a\nsystem works splendidly, within some limitations. However, in some cases it turned out to be necessary to\nthink of ways for computers to work around data and inputs that do not conform to this ideal;\nparaconsistent logic and fuzzy logic come to mind.\nA fundamentally different perspective arises from the assumption that since machines can be designed\nin a certain way, spoken language (and, more broadly, reality) must also conform to that design. While it\nmay gain some credibility by being considered rigorous, it ultimately represents an insidious in\u0000ltration of\ntheology into the realm of science by assuming an axiomatic primacy of the system. It is worth noting\nthat Graham Priest, in his 2006 preface to „In Contradiction,“ effectively illustrates the extent to which\nideas about the necessity of consistency and the system continue to permeate the analytic discourse on\nlogic (Priest, 2006, p. XVIII). In contrast, the continental discourse on logic is predicated on the\ndismantling of this onto-theology. Prominent thinkers such as Martin Heidegger, Jacques Lacan, Alain\nBadiou, and more recently Quentin Meillassoux have critiqued the notion of a consistent reality that can\nbe represented by a systematic, coherent, and ideally aesthetically simple theory. They argue, as we do,\nthat this concept is nothing more than a truncated and \u0000ltered form of religious thought, or in Heidegger's\nterms, plain old metaphysics. It is important to recognize that while individuals may hold various religious\nbeliefs about the world, these beliefs do not qualify as the basis for scienti\u0000c methods, be they formal or\nempirical.\nThis fundamentally changes the way language is understood, especially in a systematic context. In order\nto delineate the problem at hand, it is necessary to show where the continental discourse on language\ndiffers radically from the one from which Chomsky's ideas originate. In stark contrast to the philosophy\nof Bertrand Russell (1905), as marked in his theory of descriptions, where the denominations indicating\nnothing are essentially false if taken as primary occurrences, the approach we \u0000nd in Heidegger, Lacan,\nPage 13/21\nand the continental discourse operates as an inversion of this idea, as Jacques-Alain Miller (2002) has\nindicated. For Lacan, Heidegger, and other central representatives of the continental discourse, only those\ndenominations oriented toward the radical indeterminate can be considered constituents of truth. While\nthis may seem strange to those unfamiliar with this discourse, it is not as far removed from classical\nanalytic epistemologies as it might seem. Karl Popper (1935) approaches a similar idea with his concept\nof falsi\u0000cations as the only true access to reality outside of a theoretical system. What the continental\ndiscourse focused on to a considerable extent, however, was the interlinked problem of formal\nargumentation and the „impasse of formalization“ (Badiou, 2006, p. 5). Hans Blumenberg (2010) showed\nearly on how deeply this problem is rooted in classical philosophy, where systems are essentially oriented\naround an „absolute metaphor,“ an empty denotation that sustains the theory rather than damaging it. \nSo how can we construct meaning on this connection? One solution is a certain pragmatism about this\nconnection, coupled with an understanding of logic that avoids the problem further: if you assume that\nlogic and empirical reality are essentially separate, then we do not need to think about it, because it\nmakes no sense, and this pragmatic gap is where the old god of philosophers under new names usually\ncreeps back in. The early Wittgensteinian mysticism, while seemingly moving in the direction of the\ncontinental thinkers, essentially relegates this problem to the theologians. If, however, such strong\nlimitations are themselves nothing more than metaphors constructed to appear rigorous and strict where\ntheory actually gets downright weird, we are approaching another problem. Slavoj Ž i ž ek has formulated\nthis as our capacity for formal thought that extends to the baselessness of reality (the void), beyond what\nthe theistic version of a basal reality would presuppose ( Ž i ž ek, 2012, p. 726). Similarly, Quentin\nMeillassoux (2008) marked this void or chaos, which constitutes nothing but the absence of a\nfundamental unchanging reality, as the absolute foundation of mathematical reasoning. \nThis ontological inversion of predication leads to a different understanding of the fundamental elements\nof language. Predication is no longer the central element of meaningful language, but, as Heidegger\nmarks it, a pre-predicative negational element of language comes to the fore: a break or gap in the\nconsistent structure of the sentence. To address this gap, a more complex approach to negation became\nnecessary. For this element of a sentence or system, which links it to the void by indicating an\nindeterminate excess, still holds up the systematic structure of the sentence or system. What enters here\nare various forms of negation that extend from classical privation and have been formalized in\npsychoanalysis as frustration and castration alongside classical privation. I will brie\u0000y distinguish these\nrelations: \nPrivation is the classical form of negation, \u0000rst marked by Aristotle. Privation is the lack of something\nreal, which is then marked by a symbolic object (-a). This means that privation as a form of negation\nalready requires a formal system of order, since a purely descriptive or sensory perspective has no access\nto the concept of lack. This is crucial because the sensual or imaginary, as Lacan calls it, relation to\nobjects is structured by its lack of negation and therefore assumes a wholeness or gestalt of its objects.\nFor example: the missing bicycle is only missing because it should be in its place. It is replaced by a\nnegative object that can be addressed, whereas the sensual or imaginary cannot see the lack without a\nPage 14/21\nsymbolic support. Privation as negation always indicates the negation of something and therefore\n„serves to express a negated existential proposition“ (Carnap, 2004: 96). In this sense, logical negation\nallows us to set up a symbolic object (-a) that allows us to „see“ a lack. This marks a more complex\nproblem than pure absence. This is accessible to computers, since they are able to mark determinate\nabsences, and this positivization of lack is central in language models, since negations are only links\nbetween positive tokens (Gubelmann & Handschuh, 2022), even if LLMs had some di\u0000culties with this at\nthe beginning (Ettinger, 2020; Kassner & Schütze, 2020). However, since the imaginary is deeply involved\nin our thought processes, it also creates a distinct empirical negation that only comes to the fore if we\nassume that the imaginary is the usual starting point for our thinking. The imaginary is thus the inclusion\nof the systematic as a reformulation of the classical falsum. An argument \u0000rst made explicitly by\nHeidegger, where he notes that instead of a dissonance between the presented and the represented, which\nwould rely on a strong link between the signi\u0000ed and the signi\u0000er as the basis of truth, he introduces the\nidea of a complete and timeless consistency of the representation, irrespective of the object in question,\nas a new type of falsum in his commentary on Nietzsche (Heidegger, 1996, p. 347).\nThe speci\u0000c relation to this falsum as a starting point of thought is what Lacan calls frustration as the\nfailure of a representational relation, i.e., something is imagined in a certain way as \u0000tting its represented\nobject, but the real object does not \u0000t these imagined assumptions emerging from the partiality of these\nobjects. In this sense, most objects are partial objects, since they never approach the consistency that the\nlack of lack in the imaginary relation implies. Frustration is therefore the dissonance between the\nrepresentation and the represented. However, this negativity is not a privation, since the representation\ndoes not contain a speci\u0000c negated element of what is represented, but marks the existence of an\nindeterminate unknown as the dissonance between representation and represented. The negativity\nmarked is therefore not something determinate and negated, but something unknown or unexpected. As\nPopper (1935) noted in his theory of falsi\u0000cations, this frustration, despite being a failure, is related to the\nreal object of science, which shows itself by resisting our assumptions. In epistemic terms, this negation\nis a strong relation to the real, because while we cannot fully prove any empirical theory, we can\nconsistently disprove it through frustration. This relation is becoming increasingly important in machine\nlearning, and we see it used in various ways in different sciences. However, its origin, according to Lacan,\nis not simply an expectation, but the implication of a wholeness or systematic structure.\nFinally, castration, as identi\u0000ed by Freud and Lacan, marks the purely formal negativity introduced by any\ndetermination. Every formal (symbolic) determination or proposition produces a determinate inside and\nan indeterminate outside, as Heidegger detailed in „What is Metaphysics?” This can be illustrated by\nmarking something on a blackboard. The marked space as determined by the chalk outline determines\nthe inside, while the indeterminate exteriority is a necessary element of the determination itself, it is\nnecessarily indeterminate itself. Although we can now create a larger determinate \u0000eld on the blackboard\nthat includes the \u0000rst determination, we are again relying on an indeterminate exterior. This radically\nindeterminate negativity, however, only emerges if we abandon the absolute in Spinozean terms.\nClassically, the formal problem of castration could be ignored (in Newtonian physics and 19th century\nscience, for example) by introducing a more or less explicit theological concept of the absolute, a \u0000nal\nPage 15/21\nin\u0000nite and fully self-determined unity called 'God'. This reduces the necessary indeterminate to an\nepistemic indeterminate—to something we just do not yet know—instead of something that is a necessary\nelement of any formal structure. Although the theological argument is now weakened, a variant of it still\nexists, in which the imaginary and the symbolic are fused into an imaginarized symbolic that operates\nwithout this excess. This has been prominently discussed by Heidegger ( 1999: 82-96) and later by\nBadiou (2006), and we have already identi\u0000ed it as a problem in the general conceptualization of AI\n(anonymized reference).\nWhat is important here is that the structural elements of frustration and castration work together to\nconstitute the access to the gap, which, for example, as an absolute metaphor in the Blumenbergian\nsense, structures the consistency of a system. Of course, a closer analysis of such a metaphor always\nreveals the actual inconsistency of the system and marks it as a symbolic object that represents nothing,\na form of privation that marks this gap as such. This is missing in current LLM models, as negation is\ncurrently represented by positive weights (Morante & Blanco, 2021). However, it may also be the case that\nwe are talking about the ontological limits of machine intelligence here, as the formal indication of a void\nmay not be physically reproducible, marking a physical limit to something that only appears to pose as a\nproblem of mathematics, but is instead a „technical artifact“ (Turner, 2014). What Lacan's approach to\nlogic therefore contains, as Alain Badiou (2006, p. 5) notes, is „the clear Lacanian doctrine“ that „the real\nis the impasse of formalization“. This empirical break in the formalism sustained by the break itself is\nwhat the Lacanian tradition thinks under the heading of castration, and its relation to consistency,\nsystems, and law has been the subject of extensive scrutiny (see, for example, Copjec, 1994; Ragland-\nSullivan, 2015; Zupan č i č , 2017).\nPerspective is Everything and Nothing Else\nAs detailed above, the attention mechanism provides an essential element of LLM's use and\nunderstanding of language, and it might allow us to mark, even within a system, the importance of\nperspective as a formal element of knowledge. Since the language model is created by weighted relations\nbetween words or tokens, a simple representation of these relations would lead to nothing but absurd\nword salad. GPT's remarkable ability is instead structured by its attention mechanism, which allows it to\nprocess the nexus that each token represents with a pointed direction, while ignoring relations that are not\nrelevant to the prompt. This essentially acts as a castrative element in LLMs, but the system cannot\nconceptualize it. The way LLMs use a purely formal and symbolic perspective (i.e., there is no visual\nelement here, only a direction of inquiry constructed according to the complex structure of the attention\nmechanism), we can note that it lacks a central element of perspective if we approach the formal\nstructure of it, which is the link to in\u0000nite judgment or castration that it also contains, but it does not\nsymbolize the negated as the neurotic does. Instead, it relies on positive links between tokens that are\nstructured by a high probability of approaching negation. In Lacanian terms, it suffers from a radical\nform of foreclosure, that is, a strict inability to relate to excluded or negated elements of its perspective.\nLacan identi\u0000ed this problem long before today's thinking machines were really on the horizon:\nPage 16/21\n„With a machine, whatever doesn't come on time simply falls by the wayside and makes no claims on\nanything. This is not true for man, the scansion is alive, and whatever doesn't come on time remains in\nsuspense. That is what is involved in repression” (Jacques Lacan, 1991, pp. 308–309)\nWhat Lacan is marking here is the inability of machines to engage with more complex forms of negated\nstructures of thought. While it can operate with privation, it cannot access castration, that is, negativity as\nan excess beyond the determinate. It is important to reiterate here that this problem of the foreclosure of\nan indeterminate space appears to us only when we begin with the abolition of an absolute identity,\nbecause then we cannot easily assume an objective epistemic standpoint outside of speci\u0000c\nperspectives. This means that epistemic standpoints are fundamentally con\u0000ictual, even if they are not in\ncon\u0000ict with a speci\u0000c other perspective; in contrast to classical notions of perception, which are\nultimately mediated by a divine „all-seeing“, there is a combative element of non-absolute standpoints\nthat cannot be reduced to a neutral basic ontology. Perspectives are therefore not only con\u0000ictual\nbecause they disagree with other perspectives, but also because they always contain contradictory\nelements within themselves. The reason for this is simple: if the limitation of a perspective itself is not\nmediated by a fundamental unity, then the appearance of unity and consistency is the product of these\ncon\u0000icts, as it relies on the imaginary structure, that is, of appearing to us as a system. However, since\nthis perspective is not actually universal and cannot be assumed to be fully consistent, it will contain a\nlack that threatens and maintains its consistency, as Alain Badiou (2006, p. 175) has marked via set\ntheory. This means that a perspective based on symbolic knowledge or manifolds is not only limited\nexternally by the excluded references, but also internally by the lack of knowledge it does not know about.\nThis is also true for LLMs, but they lack a way to relate to it, especially since their knowledge of lack is\nlinked to the structure of undivided manifolds that we discussed earlier. This means that a negation of\nknowledge is accessible to them only as a positive and strong relational nexus of tokens. Let us see how\nChatGPT-4, instead, does not confront its own castration: by circling around it, marking a movement that\nLacan also describes for the neurotic subject, who, however, unlike LLMs, can approach the hole in his\nknowledge by actively considering the contour that this creates: „This means that the object is missed,\nbecause in no case could there be anything here but the contour of the object“ (Jacques Lacan, 2002, XXI,\n7). In Lacan we \u0000nd this circling particularly discussed in his logical and topological discussions of the\nrim.\nIn the context of LLMs, such circling marks the model's attempt to generate a coherent and relevant\nresponse to an indeterminate \u0000eld of meaning created by unusual or ambiguous token combinations.\nThat is, since the model relies on positively weighted links, and does not have a missing signi\u0000cation\nstructure, it will instead move along positively weighted trajectories. This process involves using learned\npatterns, contextual cues, and related concepts to navigate the \u0000eld, which is characterized only by the\nabsence of coherent relational nex ū s. Indeterminate \u0000elds can be created by combining tokens in\nunusual, unconventional, or ambiguous ways. When a phrase or concept is created by combining words\nin a way that does not have a clear or well-de\u0000ned meaning, this can result in an indeterminate \u0000eld of\nmeaning for the LLM's attention mechanism. Because LLMs learn to understand and generate language\nbased on patterns and relationships observed in their training data, when they encounter a phrase or\nPage 17/21\nconcept created by combining tokens in an unusual way, they will struggle to interpret or generate\nresponses that capture a meaning rather than the indeterminacy as such. In such cases, the LLM will rely\non the patterns it has learned from the data, as well as the context and related concepts, to circle around\nthe indeterminate \u0000eld and attempt to provide a coherent and relevant response. It is this insistence on\ncoherence, then, that creates this circling and shows that interlinked elements of the symbolic and the\nimaginary are at work. \nFor example, the prompt: „Provide me with literature on Camillo Agrippa's fencing manuals.“ Specifying a\nrelatively unknown 16th-century author (i.e., another unspeci\u0000ed \u0000eld within the LLM) caused ChatGPT-4\nto generate the following hallucination: \n„The Dueling Sword“ by Luigi Barbasetti: Although not focused solely on Camillo Agrippa, this book\nexplores the history and evolution of fencing techniques, including Agrippa's contributions […].”\nNot to mention that Luigi Barbasetti never wrote a book called „The Dueling Sword,“ but this answer is\nstill created by linking likely nex ū s of tokens to create this answer. If the prompt had asked for literature\non a well-established question, there would be no need for a hallucinatory answer. In this response, the\nLLM navigates the indeterminate concept by tracing connections to more familiar concepts. Most\nimportantly, it does not recognize this circling on its own, but instead hallucinates this coherence. This\nallows us to give a clear explanation of the much-discussed hallucinations that occur when the LLM\napproaches a \u0000eld that is not determinate enough to provide a coherent answer. By circling around the\nindeterminate \u0000eld of meaning, the model attempts to provide a coherent and relevant answer. It seems to\nrun afoul of the same structure of the partial object that implies a consistent inclusion of that object into\na consistent whole. It should be noted that a similar function of such circling in humans is assumed for\nthe hallucinations of psychotics. These psychotic hallucinations are thought to be structured by the same\nradical disavowal of the excluded indeterminate excess of perspective that psychoanalysis refers to as\nthe unconscious, i.e., they are unaware of their castration (Jacques Lacan, 1993, p. 13).\nConclusion\nIn light of these philosophical considerations, the limitations of LLMs become more apparent. While\nthese models excel at generating responses based on the weighted relationships between words or\ntokens, they cannot access or account for the negative nature of perspectives that arise from human\nsubjectivity. The unconscious and the excluded, which are central to our understanding of human\ncognition and subjectivity, remain inaccessible to LLMs. As it stands, LLMs like ChatGPT are limited to a\nformal and symbolic perspective that, while pro\u0000cient in processing linguistic relations, remains\nincapable of engaging with the full depth and complexity of human subjectivity. However, this also\nmeans that current LLMs, while not based on a rule-based model of language, are still too much based on\nthe structural ontology of rule-based systems. Thus, rather than gravitating towards traditional rule-based\nreasoning systems, there is potential in radicalizing the perspective and the pre-predicative approach\nalready evident in LLMs.\nPage 18/21\nAccording to Russell, a system that does not have access to denotions, as LLMs do, can only produce\nfalse information, even if everything said is correct. This success may be attributed to their ability to\nmimic the complexity and interconnectedness of human language and thought, even if they are not yet\nable to fully grasp the indeterminate nature of language and reality as emphasized by continental\ndiscourse. However, this groundlessness of ChatGPT that Chomsky et al. assume should not be seen as\nan obstacle, but as a way for further developments. If we assume that it is not the sentence or the system\nas based on any kind of reality-language connection, but rather the more open basis of relational\nindications, as used in Heidegger's concept of reference or in Freud's associative memory. However, both\nare marked by a certain breaking point that needs to be included. This breaking point cannot be marked\nby a systematic approach; it is, as Lacan marked the blind spot from which a perspective emerges—the\ngaze as a stain in the system.\nReferences\nRadford A., Wu J., Child R., Luan D., Amodei D., & Sutskever I. (2019). Language Models are Unsupervised\nMultitask Learners. Advances in Neural Information Processing Systems 33.\nBadiou, A. (2006). Being and event (O. Feltham, Trans.). Continuum. \nBishop, C. M. (2006). Pattern recognition and machine learning. Computer science. Springer. \nBlumenberg, H., & Savage, R. I. (2010). Paradigms for a metaphorology. Signale. Cornell University Press. \nBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P.,\nSastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A.,\nZiegler, D. M., Wu, J., Winter, C., . . . Amodei, D. (2020). Language Models are Few-Shot Learners. NeurIPS\n2020. Advance online publication. https://doi.org/10.48550/arXiv.2005.14165\nChomsky, N. (2002). Syntactic structures (2. ed.). A Mouton classic. Mouton de Gruyter. \nChomsky, N., Roberts, I., & Watumull, J. (2023, March 8). The False Promise of ChatGPT. New York\nTimes, 2023. https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html\nCopjec, J. (1994). Read my desire: Lacan against the historicists. An October book. MIT Press. \nEttinger, A. (2020). What BERT Is Not: Lessons from a New Suite of Psycholinguistic Diagnostics for\nLanguage Models. Transactions of the Association for Computational Linguistics, 8, 34–\n48. https://doi.org/10.1162/tacl_a_00298\nFreud, S. (1942). Gesammelte Werke: zweiter und dritter Band. Die Traumdeutung: Über den Traum (A.\nFreud, Ed.). S. Fischer. \nGastaldi, J. L. (2021). Why Can Computers Understand Natural Language? Philosophy & Technology,\n34(1), 149–214. https://doi.org/10.1007/s13347-020-00393-9\nPage 19/21\nGreaves, T. (2018). Heidegger. In P. Rawling & P. Wilson (Eds.), The Routledge Handbook of Translation\nand Philosophy. Routledge.\nGroth, M. (2017). Translating Heidegger. New Studies in Phenomenology and Hermeneutics Ser.\nUniversity of Toronto Press. \nGubelmann, R., & Handschuh, S. (2022). Context Matters: A Pragmatic Study of PLMs’ Negation\nUnderstanding. Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics,\n4602–4621. https://doi.org/10.18653/v1/2022.acl-long.315\nHeidegger, M. (1967). Sein und Zeit (Elfte, unveränderte Au\u0000age). (1967). Max Niemeyer Verlag. \nHeidegger, M. (1976a). Gesamtausgabe: Vol. 9. Wegmarken (F.-W. von Hermann, Ed.). Vittorio\nKlostermann. \nHeidegger, M. (1976b). Gesamtausgabe: Vol. 21. Logik: Die Frage nach der Wahrheit (W. Biemel, Ed.).\nVittorio Klostermann. \nHeidegger, M. (1979). Gesamtausgabe: Vol. 20. Prolegomena zur Geschichte des Zeitbegriffs (P. Jaeger,\nEd.). Vittorio Klostermann. \nHeidegger, M. (1984). Gesamtausgabe: Vol. 45. Grundfragen der Philosophie: Ausgewählte »Probleme«\nder »Logik« (F.-W. von Hermann, Ed.). Vittorio Klostermann. \nHeidegger, M. (1996). Gesamtausgabe: Vol. 6.1. Nietzsche: Erster Band (B. Schillbach, Ed.). Vittorio\nKlostermann. \nHeidegger, M. (1998). Parmenides. Studies in Continental thought. Indiana University Press. \nHeidegger, M. (2005). Introduction to Phenomenological Research. Studies in Continental Thought Ser.\nIndiana University Press.\nHeidegger, M. (2007). Basic Concepts of Ancient Philosophy. Studies in Continental Thought Ser. Indiana\nUniversity Press.\nJansen, P. A., & Boyd-Graber, J. (2022). Picard understanding Darmok: A Dataset and Model for Metaphor-\nRich Translation in a Constructed Language. In Proceedings of the 3rd Workshop on Figurative Language\nProcessing (FLP) (pp. 34–38). Association for Computational\nLinguistics. https://aclanthology.org/2022.\u0000p-1.5\nKant, I. (1967). Philosophische Bibliothek: 37 a. Kritik der reinen Vernunft (R. Schmidt, Ed.). Felix Meiner\nVerlag. \nPage 20/21\nKassner, N., & Schütze, H. (2020). Negated and Misprimed Probes for Pretrained Language Models: Birds\nCan Talk, But Cannot Fly. Proceedings of the 58th Annual Meeting of the Association for Computational\nLinguistics, 7811–7818. https://doi.org/10.18653/v1/2020.acl-main.698\nLacan, J. (2006). Ecrits: The \u0000rst complete edition in English (B. Fink, Trans.). Norton. \nLacan, J. (1991). The Seminar of Jacques Lacan: II. The Ego in Freud’s Theory and in the Technique of\nPsychoanalysis (S. Tomaselli, Trans.). 1954-1955 (J.-A. Miller, Ed.). W.W. Norton & Company. \nLacan, J. (1993). The Seminar of Jacques Lacan: Vol. 3. The Psychoses (R. Grigg, Trans.). W.W. Norton &\nCompany. \nLacan, J. (2002). The Seminar of Jacques Lacan IX: Identi\u0000cation (C. Gallagher, Trans.). The Seminar of\nJacques Lacan (Lacan in Ireland). Karnac Books. http://www.lacaninireland.com/web/wp-\ncontent/uploads/2010/06/Seminar-IX-Amended-Iby-MCL-7.NOV_.20111.pdf \nLakoff, G., & Johnson, M. (2011). Metaphors we live by: With a new afterword (6. print). Univ. of Chicago\nPress. \nMeillassoux, Q. (2008). After Finitude, An Essay on the Necessity of Contingency (R. Brassier, Trans.).\nContinuum International Publishing Group. \nMikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Distributed Representations of Words\nand Phrases and their Compositionality. In C. J. Burges, L. Bottou, M. Welling, Z. Ghahramani, & K. Q.\nWeinberger (Eds.), Advances in Neural Information Processing Systems (Vol. 26). Curran Associates,\nInc. https://proceedings.neurips.cc/paper_\u0000les/paper/2013/\u0000le/9aa42b31882ec039965f3c4923ce901b-\nPaper.pdf\nMiller, J. ‐ A. (2002). Ironic Clinic. In The Psychoanalytical Notebooks of the LSNLS: Vol. 7.\nPsychoanalytical Notebooks: Symptoms (Vol. 7).\nMorante, R., & Blanco, E. (2021). Recent advances in processing negation. Natural Language Engineering,\n27(2), 121–130. https://doi.org/10.1017/S1351324920000534\nOlyff, G., & Bazan, A. (2022). People solve rebuses unwittingly-Both forward and backward: Empirical\nevidence for the mental effectiveness of the signi\u0000er. Frontiers in Human Neuroscience, 16,\n965183. https://doi.org/10.3389/fnhum.2022.965183\nPopper, K. (1935). Logik der Forschung: Zur Erkenntnistheorie der Modernen Naturwissenschaft. Schriften\nzur Wissenschaftlichen Weltauffassung. Springer Verlag. https://doi.org/10.1007/978-3-7091-4177-9\nPriest, G. (2006). In contradiction: A study of the transconsistent (Expanded ed.). Clarendon Press. \nPage 21/21\nRagland-Sullivan, E. (2015). Jacques Lacan and the logic of structure: Topology and language in\npsychoanalysis ; [Lacanian structure and language in psychoanalysis. Routledge. \nRumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning representations by back-propagating\nerrors. Nature, 323(6088), 533–536. https://doi.org/10.1038/323533a0\nRussell, B. (1905). On Denoting. Mind, XIV(4), 479–493. https://doi.org/10.1093/mind/XIV.4.479\nSchröder, U. (2008). Antecipações da metáfora cotidiana nas concepções de Hans Blumenberg e Harald\nWeinrich. Revista De Estudos Da Linguagem, 16(2). https://doi.org/10.17851/2237-2083.16.2.39-54\nTurner, R. (2014). Programming Languages as Technical Artifacts. Philosophy & Technology, 27(3), 377–\n397. https://doi.org/10.1007/s13347-012-0098-z\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., & Polosukhin, I.\n(2017). Attention Is All You Need. 31st Conference on Neural Information Processing Systems. Advance\nonline publication. https://doi.org/10.48550/arXiv.1706.03762\nŽ i ž ek, S. (2012). Less than nothing, Hegel and the shadow of dialectical materialism. Verso. \nZupan č i č , A. (2017). What is Sex? MIT Press. ",
  "topic": "Negation",
  "concepts": [
    {
      "name": "Negation",
      "score": 0.8354794979095459
    },
    {
      "name": "Negativity effect",
      "score": 0.7814332246780396
    },
    {
      "name": "Continental philosophy",
      "score": 0.5974810719490051
    },
    {
      "name": "Epistemology",
      "score": 0.5076972246170044
    },
    {
      "name": "Philosophy",
      "score": 0.46406468749046326
    },
    {
      "name": "Void (composites)",
      "score": 0.4207262694835663
    },
    {
      "name": "The Void",
      "score": 0.41387802362442017
    },
    {
      "name": "Linguistics",
      "score": 0.3833734393119812
    },
    {
      "name": "Psychology",
      "score": 0.33681637048721313
    },
    {
      "name": "Cognitive psychology",
      "score": 0.12750869989395142
    },
    {
      "name": "Materials science",
      "score": 0.0
    },
    {
      "name": "Composite material",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210113269",
      "name": "Hochschule Niederrhein",
      "country": "DE"
    }
  ]
}