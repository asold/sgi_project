{
  "title": "Evaluating True BCI Communication Rate through Mutual Information and Language Models",
  "url": "https://openalex.org/W2093615108",
  "year": 2013,
  "authors": [
    {
      "id": "https://openalex.org/A2743467098",
      "name": "Speier William",
      "affiliations": [
        "University of California, Los Angeles",
        "Los Angeles Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A4304740646",
      "name": "Arnold Corey",
      "affiliations": [
        "University of California, Los Angeles",
        "Los Angeles Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A2246755098",
      "name": "Pouratian Nader",
      "affiliations": [
        "University of California, Los Angeles"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2106006415",
    "https://openalex.org/W2098100592",
    "https://openalex.org/W2158655338",
    "https://openalex.org/W2148270649",
    "https://openalex.org/W2129203136",
    "https://openalex.org/W1983194679",
    "https://openalex.org/W2039893951",
    "https://openalex.org/W2100470503",
    "https://openalex.org/W2160634130",
    "https://openalex.org/W2120535393",
    "https://openalex.org/W2095223585",
    "https://openalex.org/W1971102820",
    "https://openalex.org/W2119985414",
    "https://openalex.org/W2126617441",
    "https://openalex.org/W1985638190",
    "https://openalex.org/W2083742331",
    "https://openalex.org/W2167068610",
    "https://openalex.org/W1980381399",
    "https://openalex.org/W1656685195",
    "https://openalex.org/W1548938556",
    "https://openalex.org/W2159977619"
  ],
  "abstract": "Brain-computer interface (BCI) systems are a promising means for restoring communication to patients suffering from \"locked-in\" syndrome. Research to improve system performance primarily focuses on means to overcome the low signal to noise ratio of electroencephalogric (EEG) recordings. However, the literature and methods are difficult to compare due to the array of evaluation metrics and assumptions underlying them, including that: 1) all characters are equally probable, 2) character selection is memoryless, and 3) errors occur completely at random. The standardization of evaluation metrics that more accurately reflect the amount of information contained in BCI language output is critical to make progress. We present a mutual information-based metric that incorporates prior information and a model of systematic errors. The parameters of a system used in one study were re-optimized, showing that the metric used in optimization significantly affects the parameter values chosen and the resulting system performance. The results of 11 BCI communication studies were then evaluated using different metrics, including those previously used in BCI literature and the newly advocated metric. Six studies' results varied based on the metric used for evaluation and the proposed metric produced results that differed from those originally published in two of the studies. Standardizing metrics to accurately reflect the rate of information transmission is critical to properly evaluate and compare BCI communication systems and advance the field in an unbiased manner.",
  "full_text": "Evaluating True BCI Communication Rate through\nMutual Information and Language Models\nWilliam Speier1,5, Corey Arnold5, Nader Pouratian1,2,3,4*\n1 Department of Bioengineering, University of California Los Angeles, Los Angeles, California, United States of America,2 Department of Neurosurgery, University of\nCalifornia Los Angeles, Los Angeles, California, United States of America,3 Interdepartmental Program in Neuroscience, University of California Los Angeles, Los Angeles,\nCalifornia, United States of America,4 Brain Research Institute, University of California Los Angeles, Los Angeles, California, United States of America,5 Medical Imaging\nInformatics Group, University of California Los Angeles, Los Angeles, California, United States of America\nAbstract\nBrain-computer interface (BCI) systems are a promising means for restoring communication to patients suffering from\n‘‘locked-in’’ syndrome. Research to improve system performance primarily focuses on means to overcome the low signal to\nnoise ratio of electroencephalogric (EEG) recordings. However, the literature and methods are difficult to compare due to\nthe array of evaluation metrics and assumptions underlying them, including that: 1) all characters are equally probable, 2)\ncharacter selection is memoryless, and 3) errors occur completely at random. The standardization of evaluation metrics that\nmore accurately reflect the amount of information contained in BCI language output is critical to make progress. We present\na mutual information-based metric that incorporates prior information and a model of systematic errors. The parameters of\na system used in one study were re-optimized, showing that the metric used in optimization significantly affects the\nparameter values chosen and the resulting system performance. The results of 11 BCI communication studies were then\nevaluated using different metrics, including those previously used in BCI literature and the newly advocated metric. Six\nstudies’ results varied based on the metric used for evaluation and the proposed metric produced results that differed from\nthose originally published in two of the studies. Standardizing metrics to accurately reflect the rate of information\ntransmission is critical to properly evaluate and compare BCI communication systems and advance the field in an unbiased\nmanner.\nCitation: Speier W, Arnold C, Pouratian N (2013) Evaluating True BCI Communication Rate through Mutual Information and Language Models. PLoS ONE 8(10):\ne78432. doi:10.1371/journal.pone.0078432\nEditor: Thomas Wennekers, The University of Plymouth, United Kingdom\nReceived June 13, 2013;Accepted September 10, 2013;Published October 22, 2013\nCopyright: /C2232013 Speier et al. This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits\nunrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\nFunding: This work was supported by the NLM Training Grand T15-LM007356 (WS), the National Institute Of Biomedical Imaging and Bioengineering Award\nNumber K23EB014326 (NP), the UCLA Scholars in Translational Medicine Program (NP), and the UCLA Department of Neurosurgery Visionary Ball Fund. The\nfunders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\nCompeting Interests:The authors have declared that no competing interests exist.\n* E-mail: npouratian@mednet.ucla.edu\nIntroduction\nBrain computer interface (BCI) systems convert neurological\nsignals into computer commands in order to restore function to\npatients who have lost control of effector muscles. Several BCI\nsystems are currently under development, with applications that\ninclude moving a cursor on a screen, controlling a robotic\nprosthesis, and typing letters and words to restore communication\n[1]. With several groups working diligently to advance these\ntechnologies, regardless of application, it is paramount to have\nvalidated metrics with appropriate assumptions to compare\nbetween system designs and move the field forward in an unbiased\nmanner. In this work, we focus on BCI for restoring language\ncommunication and the associated metrics for evaluation.\nThe P300 speller is the most commonly used BCI approach for\nrestoring linguistic communication [2]. Briefly, a user observes a\ngrid of characters on a computer screen (analogous to a visual\nkeyboard) while subsets of characters are flashed in pseudo-\nrandom patterns. These flashes result in visual stimuli that elicit\nevoked electroencephalographic (EEG) responses which are then\nused to decipher the target letter or symbol of interest. System\nnoise requires that multiple stimulus presentations be averaged in\norder to achieve sufficient signal-to-noise to make accurate\nselections, resulting in slow typing rates. Several approaches have\nbeen developed to improve performance, including using different\nstimulus paradigms [3–5], optimizing system parameters [6–8],\nimplementing different classifiers [9–11], and integrating language\ndomain knowledge [5,12,13]. Alternative methodologies to the\nP300 speller have also been explored, including auditory stimuli\n[14,15], and different neurological phenomena such as motor\nimagery [16] and steady state visually evoked potentials (SSVEP)\n[17,18].\nGiven the number and variety of approaches, a reliable metric is\nimportant for evaluation and comparison across experimental\nparadigms and ultimately across studies, which to date is lacking.\nA useful metric must consider the amount of time taken, the\naccuracy of selections, and the tradeoff between the two.\nIncreasing the amount of data and therefore time needed to\nmake a decision can increase the accuracy of the selection at the\nexpense of system speed. Perfect accuracy however is not always\nnecessary as a BCI can integrate prior knowledge about the\ndomain and common user behavior to understand output despite\nerrors. In the case of typing natural language, for instance, text is\noften readable despite the presence of typos. In a non-typing\ncontext, errors may not be permissible, so errors must be corrected\nPLOS ONE | www.plosone.org 1 October 2013 | Volume 8 | Issue 10 | e78432\nby subsequent ‘‘undo’’ selections, which would result in a perfect\naccuracy, but slower typing speed.\nInformation Transfer Rate (ITR) is a general evaluation metric\ndevised for BCI systems that determines the amount of informa-\ntion that is conveyed by a system’s output [19]. The metric is\nappealing for several reasons: it is derived from information theory\nprinciples, it combines the competing statistics of speed and\naccuracy, and it reduces to an information transfer problem that\ncan be compared across applications [20]. However, ITR is not\nappropriate for evaluating language systems because it makes two\nassumptions that are incorrect in general, particularly in the\nlanguage domain: 1) that all possible selections are equally\nprobable and 2) that systems are memoryless. Several methods\nhave since been introduced in attempt to reduce the adverse\nattributes of ITR. Word Symbol Rate (WSR) normalizes ITR by\nits maximum value and then scales down based on error rate [14].\nPractical Bit Rate (PBR) finds the theoretical bit rate if the user\nhad corrected every selection error [3]. Characters per Minute\n(CPM) calculates the theoretical number of characters correctly\ntyped after error correction [7]. Output Characters per Minute\n(OCM) is an online metric similar to CPM that requires all errors\nto be corrected [12]. In general, these metrics all depend on\naspects that are system specific and therefore not generalizable (see\nmethods).\nA standard method for evaluating results does not exist, making\nit difficult to compare the relative value or the superiority of\ndifferent experimental paradigms or approaches. We present an\ninformation rate metric (MI\nn) based on mutual information\ndesigned to incorporate language domain knowledge to more\naccurately measure the utility of language-based BCI systems.\nThree versions of this metric are compared to five existing\nmethods that are currently used for evaluation in P300 literature.\nWe use each metric to optimize the dataset used by Speier et al.\n[13] to show the difference in performance achieved. We then\nreevaluate the results of 11 published studies using the existing\nmetrics used in the literature and compare the results to those\ndetermined using the proposed metrics. We cannot retroactively\naccount for differences in system parameters and experimental\nparadigms, so it is impossible to make fair comparisons between\nstudies. However, we show the effects of choosing various\nevaluation metrics on comparisons made within studies and the\nconclusions that result. Our analysis shows that the selection of a\nmetric significantly affects system optimization as well as the\nevaluation of different approaches for BCI communication,\nleading to the necessity for adopting a consistent and reliable\nperformance metric.\nMethods\nData from published BCI communication studies are used to\nshow the effects of evaluation (Table 1). Studies were included if\nthey provided the accuracy and selection speed that were achieved\nby each study subject, which are the only two values necessary for\ncalculating each evaluation metric, allowing us to evaluate each\nsubject’s performance separately using each metric. The average\nvalues were then taken for each study arm and the results were\nreanalyzed. The results of each of these studies were evaluated\nusing both previously published as well as the proposed metrics.\nEvaluation with Previously Published Metrics\nMeans for evaluating published studies using previously\ndescribed metrics are briefly described here. Please see SI1-SI5\nfor derivations.\nInformation Transfer Rate. ITR finds the average bits of\ninformation contained in each selection, B, as the mutual\ninformation between the selection, y, and the target character,\nx, divided by the time required. The method assumes that each\nselection is independent, marginal probabilities are uniform over\nthe character in the grid (i.e.,p(x)~ 1\nN where Nis the number of\npossible selections), and errors are uniform over the non-target\ncharacters (i.e., p(yjx)~P if x~y andp(yjx)~ 1{P\nN{1 otherwise\nwhere P is the selection accuracy).\nB~log NzP log Pz(1{P) log1{P\nN{1\nITR is then the bits per symbol divided by the average time\nrequired to select a single symbol,T.\nITR~B=T\nThe theory behind ITR was derived from the concept of a noisy\nchannel with1{P representing the error frequency in the output\nstring. Instead, BCI literature generally uses P as the selection\naccuracy. In some systems, this is equivalent, but it is not in cases\nwhere multiple steps are used for one selection or where\nbackspaces can be used to correct errors. In these cases,\ncounterintuitive results can occur where two users can type the\nsame string without errors and one can have a slower speed, but a\nhigher ITR (Figure 1).\nWord Symbol Rate. To calculate WSR, the bits per symbol\nare scaled by their maximum possible value,log N. The result is\ncalled symbol rate (SR), which is treated as the probability of a\ncorrect selection, which is not appropriate when multiple decisions\nare required for a selection. The average number of selections\nnecessary to choose one character is then found by determining\nthe number of additional selections required for correcting errors.\nIf an average selection provides less than half the maximal amount\nof information, then there will be more errors than correct\nselections, so WSR becomes,\nWSR~\n2SR{1\nT SRw0:5\n0 SRƒ0:5\n8\n<\n:\nPractical Bit Rate. PBR also simulates the correction of all\ntyping errors. However, instead of using SR, actual typing\naccuracy is used. This metric then divides the bits of information\ncontained in a single correct selection (still assuming all characters\nhave equal probability) by the average number of selections\nrequired to choose that character. Subjects with selection accuracy\nbelow 50% would make errors at a faster rate than they would be\nable to correct them, so the bit rate becomes,\nPBR~\n(2P{1) logN\nT Pw0:5\n0 Pƒ0:5\n8\n<\n:\nPractical bit rate has also been computed substituting ITR for\nlog N [4]. Because both PBR and ITR include penalties for\nEvaluating BCI Communication Performance\nPLOS ONE | www.plosone.org 2 October 2013 | Volume 8 | Issue 10 | e78432\nincorrect selections, this metric will double count errors, resulting\nin an overly conservative estimate of bit rate.\nCharacters per Minute. CPM extends PBR as it uses the\nsame correction factor to account for additional selections required\nto correct errors. It differs in that it does not take matrix size into\naccount and instead calculates the number of characters selected\nper minute.\nCPM~\n2P{1\nT Pw0:5\n0 Pƒ0:5\n8\n<\n:\nOutput Characters per Minute. OCM is only possible in\nonline implementations, requiring all errors to be corrected. OCM\nis computed by dividing the total number of typed characters by\nthe time required to type them.\nProposed Method\nWe propose an alternate mutual information-based metric that\nhas similar benefits to ITR, but does not rely on the same\nassumptions. Three versions are included that progressively\nremove assumptions, resulting in increasingly accurate represen-\ntations of the true bit rate. The first version, MI\n0, removes the\nuniform probability assumption and instead uses relative symbol\nfrequency as a prior probability. The second version, MI\nn,\nremoves the assumption of independent selections by incorporat-\ning knowledge about then previous characters using an n-gram\nmodel. The third version, MI\nne, uses an error model to\nincorporate additional information contained in incorrect selec-\ntions (see SI6-SI8 for derivations).\nThis metric is applicable in any case where the selection\nprobabilities can be modeled. In general, this can be done by\nmeasuring relative frequencies of different selections. In many\ncontexts, this data is not widely available, but it can be learned by\nmeasuring the selection frequencies as a user interacts with the\nsystem. In the context of natural language, these probabilities can\neasily be estimated by measuring relative character frequencies in\na corpus of natural language. For this reason, and because these\nsystems are traditionally evaluated in pure spelling mode,\nevaluating is performed here in a language context. This method\ncould easily be extended to any system with an available data set of\npast output.\nMI0. With this method, the system remains memoryless (i.e.,\nall selections are assumed independent) and all errors are still\nassumed to be uniform over all incorrect characters. Similar to\nITR, MI\n0 is the mutual information between the target symbol\nand the selected symbol. However, we remove the assumption that\nall characters are equally probable and instead determine their\nprobabilities by their relative frequencies in the general purpose\nBrown corpus [21] (Figure 2) as\nTable 1.Parameter values, optimization metric, and evaluation metric used in each of the included datasets.\nStudy Method Subjects N Steps ISI (ms) Gap (s) Opt Eval\nKaper (22) all 8 36 1 140 2 ITR ITR\nSerby (11) all 6 36 1 150 2 ITR SR, ACC, ITR\nBlankertz (16) 2 6 2 NA NA none OCM\nSellers (6) 3 63,175 5 9 1 175 5 none ITR\n363,350 5 9 1 350 5 none ITR\n666,175 5 36 1 175 5 none ITR\n666,350 5 36 1 350 5 none ITR\nFurdea (14) auditory 13 25 1 625 3.75 WSR ITR, WSR\nvisual 13 25 1 287.5 8.75 WSR ITR, WSR\nCeocetti (17) 8 5 $3 NA NA none ACC, ITR, OCM\nTownsend (3) all 18 72 1 125 3.5 WSR ITR, PBR\nJin (4) all 10 84 1 175 2 none ACC, PBR\nRyan (12) all 24 72 1 125 6 WSR ITR, OCM\nSchreuder (15) S1 14 6 2 175 18.25 none ACC, ITR, OCM\nS2a, S2b 14 6 2 175 12 none ACC, ITR, OCM\nSpeier (13) all 6 36 1 125 3.5 ITR ITR\ndoi:10.1371/journal.pone.0078432.t001\nFigure 1. ITR calculation for hypothetical cases of typing a 10\ncharacter sequence with error correction in 10 minutes.For\neach error, two additional selections are required. As a result, the ITR\nincreases because the increase in number of selections more than\noffsets the decrease in selection accuracy.\ndoi:10.1371/journal.pone.0078432.g001\nEvaluating BCI Communication Performance\nPLOS ONE | www.plosone.org 3 October 2013 | Volume 8 | Issue 10 | e78432\np(x)~ c(x)\nc( /C3 )\nwhere c(x) is the number of occurrences of characterx in the\ncorpus and c( /C3 ) is the total number of characters in the corpus.\nThe bits per symbol may then be computed:\nB0~{\nX\ny\np(y) logp(y)zP log Pz(1{P) log1{P\nN{1\nwhere p(y)~ 1{P\nN{1 zNP{1\nN{1 p(X~y). Note that hereP repre-\nsents the accuracy in the final output, not the individual selection\naccuracy. Multiplying by the size of the output string and dividing\nby the total time yields MI\n0:\nMI0~B0\nYjj\nT\nMIn. MIn builds on MI0 by removing the assumption that all\ncharacter selections are independent. We assume that selected\ncharacters are directly dependent on the respective target\ncharacters and that target characters are dependent on the\nprevious n characters. The conditional probabilities\np(xjx\n{1,:::,x{n) can be found by determining the fraction of\noccurrences of the stringx{n,:::,x{1 that are followed byx in the\ncorpus:\np(xjx{1,:::,x{n)~c(x{n,:::,x{1,x)\nc(x{n,:::,x{1)\nKnowledge from additional steps can be factored into this\nequation by conditioning over previous targets and summing over\ntheir possible values as follows:\nBn~\n{\nX\nx{1,:::,x{n\np(x{1,:::,x{n)\nX\ny\np(yjx{1,:::,x{n) logp(yjx{1,:::,x{n)zP log P\nz(1{P) log1{P\nN{1\nwhere p(yjx{1,:::,x{n)~ 1{P\nN{1 zNP{1\nN{1 p(X~yjx{1,:::,x{n).\nMultiplying by the size of the output string and dividing by time\nyields the value for MIn.\nMIn~Bn\nYjj\nT\nMIne. Townsend et al. showed that errors in P300 systems are\nsystematic, and therefore incorrect selections contain information\nabout the target character [3]. Below, we propose error models\nbased on values determined in their analysis. First, errors in the\ncheckerboard paradigm have been shown to occur more often\nwithin the same virtual matrix as the target character.\nFigure 2. Marginal probability of characters in the English language (a) and conditional probabilities of characters given previous\ncharacters of space (b), ‘t’ (c), and ‘q’ (d).\ndoi:10.1371/journal.pone.0078432.g002\nEvaluating BCI Communication Performance\nPLOS ONE | www.plosone.org 4 October 2013 | Volume 8 | Issue 10 | e78432\np(yjx)~\nPx ~y\n(1{P)P1\nN\n2 {1 x=y,cb(x)~cb(y)\n(1{P)P2\nN\n2\ncb(x)=cb(y)\n8\n>>\n>\n>\n>\n<\n>>\n>\n>\n>\n:\nWhere cb(x) refers to the virtual matrix that character x is\nassigned to,P\n1 refers to the probability of an error occurring in the\nsame virtual matrix as the target, andP2~1{P1 refers to the\nprobability of an error occurring in a different virtual matrix.\nThese values were found to be .7414 and .2586 respectively by\nTownsend et al. [3].\nNext, there were three distinct types of errors found in the row/\ncolumn paradigm. Adjacent characters were observed to be\nselected the most often, followed by characters that shared a row\nor column with the target character, both of which were more\nlikely than erroneously selecting a distant character.\np(yjx)~\nPx ~y\n(1{P)P1\nN1\nr(x){r(y)jj z c(x){c(y)jj ~1\n(1{P)P2\nN2\nx=y, r(x){r(y)ðÞ c(x){c(y)ðÞ ~0\n(1{P)P3\nN3\notherwise\n8\n>>\n>\n>\n>\n>\n>\n>\n>\n<\n>>>>\n>\n>\n>\n>\n>\n:\nHere, r(x) and c(x) are the row and column of characterx in\nthe matrix. P\n1, P2, and P3 are the probabilities of incorrectly\npicking characters that are adjacent, in the same row or column,\nor anywhere else relative to the target character.N1, N2, and N3\nare the numbers of characters that are adjacent, in the same row\nor column, or anywhere else relative to the target character. The\nerror probabilities were found to be .4065, .4452, and .1483\nrespectively by Townsend et al. [3].\nOther flashing paradigms such as those presented by Jin et al.\n[4] are more random so error patterns are less likely to occur. No\nother papers included error analysis, so a uniform model was used\nfor P300 systems with alternative flashing paradigms. The bits per\nsymbol is then\nBne~\nX\nx,x{1,:::,x{n\np(x,x{1,:::,x{n)\nX\ny\np(yjx) log p(yjx)P\nx0 p(yjx0)p(x0jx{1,:::,x{n)\nThe information rate is then found by Multiplying by the size of\nthe output string and dividing the bits per symbol by the total time.\nMIne~Bne\nYjj\nT\nAnalysis\nData. Eleven studies were chosen as a representative sample\nof existing BCI communication literature. Seven visual P300\nstudies were included: one study focused on optimizing system\nparameters [6], two proposed new flashing paradigms [3,4], two\nused novel classification techniques [22,11], and two integrated\nlanguage information [12,13]. The remaining four studies\nproposed systems based on alternative neurological signal para-\ndigms including audio P300 [14,15], motor imagery [16], and\nSSVEP [17]. Nine of the studies [3–4,11–15,22] included\ncomparisons between study arms to validate the proposed method.\nThe remaining two [16,17] each demonstrated their system alone\nas a proof of concept.\nThe studies reviewed used a variety of system parameters\n(Table 1), all of which significantly influence system performance.\nBecause these values vary widely, performance differences\nobserved in a comparison across studies could be a result of the\ndifferent parameter combinations, rather than a validation of the\ntechniques used. Additionally, each study used a different subject\npopulation and sample sizes were small (between two and 24),\nmaking it difficult to find significant differences in results.\nIndividual studies are usually self-controlled and use standardized\nsystems, which alleviates these concerns. We therefore focus on\nreanalyzing the comparisons within studies instead of comparing\nresults between studies. Comparison across studies becomes more\nappropriate in situations where a study builds directly upon a\nprevious one, which allowing limiting the parameter and protocol\nvariation.\nEach aforementioned study was evaluated using the each of the\nexisting and proposed evaluation metrics. Within each study, the\nresults of the different groups were compared using paired t-tests.\nThese results were then compared to the findings in the original\npaper.\nOptimization. The first analysis performed considered a\npreviously published dataset [13]. In this study, the probability of\neach of the possible characters was computed after each stimulus\nand the most probable character was selected once a confidence\nthreshold was reached. In the published results, the value for the\nthreshold was determined by choosing the value that optimized\nthe results using the ITR metric.\nAnalysis consisted of re-optimizing the results using each of the\nmetrics detailed above. The new optimal threshold probability is\nreported for each optimization as well as the corresponding\nperformance using the MI\n2e metric. These values are then\ncompared to the results from optimizing on the MI2e metric and\nevaluated for significance using paired t-tests.\nResults\nOptimization\nThe original optimization reported in Speier et al. used ITR\nand chose an optimal value of 0.86 for the threshold probability\n[13]. Many of the existing metrics chose similar optimal values,\nwith only studies optimizing based on sample rate and accuracy\nchoosing significantly different values. Using MI\n0 resulted in the\nsame optimal values, and MI2 resulted in values that were lower,\nbut not significant (p = 0.087) (Table 2). The threshold values\nchosen using MI2e were significantly lower than those using all\nother metrics, with lower values for five of the six subjects\n(Figure 3).\nWhen optimizing on the existing metrics, the average\nconfidence threshold values varied between 0.12 and 0.98, and\nthe corresponding information rates varied between 13.14 and\n16.05 bits per minute. The optimized values achieved using MI\n0\nwere identical to those using ITR, and MI 2 achieved an\ninsignificant increase in results (p = 0.087). When optimizing on\nMI2e, the average confidence threshold was significantly lower\n(0.49) and the derived bit rate (17.05) was significantly higher than\nthose using any other metric (Table 2).\nEvaluating BCI Communication Performance\nPLOS ONE | www.plosone.org 5 October 2013 | Volume 8 | Issue 10 | e78432\nEvaluation\nIn the Kaper et al. [22] study, all metrics other than WSR\nreflect better results using inner cross validation with significant\ndifferences between ‘‘inner’’ and ‘‘outer’’ noted using ITR, MI\n0,\nMI2, and MI 2e (p = 0.00044, p = 0.00033, p = 0.00027, and\np = 0.00014, respectively), which is consistent with the published\nconclusions (Table 3).\nIn the Serby et al. [11] report, all metrics agreed with the\noriginal conclusion that independent component analysis achieved\na higher bit rate than the maximum likelihood method. Each\nmetric showed significant results other than accuracy (p = 0.34)\nand WSR (p = 0.09) with p values ranging from 0.023 (PBR) to\n0.008 (MI\n2e).\nThe Sellers et al. [6] paper showed varying results depending on\nthe metric used. All existing metrics other than accuracy\ndetermined the 363 grid with an ISI of 175 ms to have the best\nperformance, although none were significant. The three proposed\nmetrics however identified the 666 grid with an ISI of 175 ms as\nthe superior configuration with significant results (p = 0.015,\np = 0.044, and p = 0.002, respectively).\nAll metrics in the Furdea et al. [14] study determined that the\nvisual P300 speller was superior to their audio version. All metrics\nother than accuracy (p = 0.078) revealed significant differences\nbetween the two approaches with p values less than 1026.\nIn the Townsend et al. [3] study, the results from the\ncheckerboard paradigm proved better than the row/column\nparadigm on a 968 grid by all metrics other than selection rate.\nThe results were significant using ITR (p = 0.035), MI0 (p = 0.044),\nand MI2 (p = 0.047), but not MI2e (p = 0.12).\nThere was variability in the results of the system presented in Jin\net al. [4]. The original paper concluded that 19-P method was\nsuperior using PBR, which is consistent with the WSR and CPM\nmetrics. However, selection rate, ITR, MI0,M I2, and MI2e all\nindicated the 9-P method was superior. In all cases, the results\nwere close and none were statistically significant.\nIn the Ryan et al. [12] paper, evaluation using accuracy, ITR,\nSWR, PBR, or CPM revealed significantly higher values using the\nnonpredictive speller with p values between 0.02 and 0.04. OCM\n(the metric used in the original paper), MI0,M I2, and MI2e all\nshowed significantly higher rates for the predictive speller\n(p,1028).\nIn the Schreuder et al. [15] paper, all metrics other than\naccuracy showed significantly higher results for the S2a and S2b\ntrials, including ITR (the metric used in the original paper) and the\nFigure 3. Values of ITR (broken curve), and MI2e (full curve) versus the number of stimulus sequences used in classification for each\nsubject in the Speier et al. (13) dataset (a–f).Optimal values are marked by diamonds.\ndoi:10.1371/journal.pone.0078432.g003\nTable 2.Threshold values and average MI2e value of the\ndataset from Speier et al. when optimizing on different\nevaluation metrics.\nMetric Threshold p-value Bit rate p-value\nMI2e 0.49 17.05\nMI2 0.82 0.005 16.24 0.021\nMI0 0.86 0.006 16.05 0.020\nACC 0.98 0.001 13.14 0.007\nSR 0.12 0.003 15.25 0.008\nITR 0.86 0.006 16.05 0.020\nWSR 0.93 0.001 15.31 0.005\nPBR 0.87 0.005 15.97 0.015\nCPM 0.87 0.005 15.97 0.015\nOCM * * * *\nOCM was not computable because the system did not require all errors to be\ncorrected. p-values are determined using paired t-tests between the given\nvalue and the results when optimizing on MI\n2e. Asterisks denote methods that\ncannot be computed for the target system.\n*method cannot be computed for the target system\ndoi:10.1371/journal.pone.0078432.t002\nEvaluating BCI Communication Performance\nPLOS ONE | www.plosone.org 6 October 2013 | Volume 8 | Issue 10 | e78432\nproposed metric (p,0.0001). There were no significant differences\nbetween the S2a and S2b trials using any metric.\nThe Speier et al. [13] paper showed superior results for the NLP\nmethod regardless of the evaluation metric used. All metrics\nshowed significant results other than selection rate (p = 0.064).\nDiscussion\nEvaluation\nIn six of the 11 studies analyzed, changing the evaluation metric\ncould have resulted in different conclusions from that originally\npublished. Only two of the existing metrics, PBR and CPM,\nalways agreed. This highlights the critical importance of identi-\nfying an appropriate metric for evaluation of P300 speller studies,\nand more generally all BCI studies.\nThe proposed metrics agreed with the published conclusion in\nnine of the 11 studies. In the Sellers et al. study, all existing metrics\nchose the 363 grid because they did not consider actual typing\nability. Because they only have nine characters to choose from,\ntheir system would not be able to type most English words and is\ntherefore less effective at communicating language. This short-\ncoming could be addressed by making selections in two steps, but\nthe effectiveness would need to be reevaluated [6]. The proposed\nmetrics also would have provided different conclusions in the study\nby Jin et al., although the results were close and the difference was\nnot statistically significant [4].\nMost existing metrics could not account for the predictive model\nused in the Ryan et al. [12] study. The nonpredictive speller\nachieved a higher accuracy and similar selection speed, so it was\nfound to be significantly better in most cases. The only existing\nmetric that was able to account for the improvements in their\nsystem was the metric introduced in the same paper. The metrics\nproposed here are able to account for the predictive model and\nthus agree with the highly significant results found in the study.\nAnother critical advantage of the proposed metrics is their\nuniversal utility. Only the proposed metrics were consistently\ncomputable and intuitive across all studies. Some of the existing\nmetrics could not be computed for all of the studies either because\nall errors were not corrected (OCM), the system involved multi-\nstep decisions (WSR, PBR, and CPM), or rates and accuracies\nwere not recorded for intermediate steps (ITR). While ITR could\nbe computed if all intermediate results were recorded, it did not\nTable 3.Results from published P300 papers reevaluated using different metrics.\nStudy Method ACC SR ITR WSR PBR CPM OCM MI 0 MI2 MI2e\nKaper (22) inner 54.38 13.85 25.21 0.13 9.41 1.82 * 21.13 12.94 18.06\nouter 47.88 9.70 14.47 0.23 3.10 0.60 * 12.21 7.51 11.59\nSerby (11) ML 90.02 3.66 15.79 2.45 15.54 3.01 * 12.63 7.49 7.77\nICA 92.12 4.56 19.88 3.13 19.66 3.80 * 15.90 9.43 9.74\nonline 79.53 3.89 13.77 1.72 12.35 2.39 * 11.11 6.64 7.27\nBlankertz (16) * *****4 . 8 8 19.95 11.73 11.73\nSellers (6) 363,175 61.25 3.87 4.53 0.32 3.99 1.26 * 2.43 1.58 1.82\n363,350 69.38 2.31 3.19 0.10 2.83 0.89 * 1.70 1.11 1.21\n666,175 53.75 2.31 4.50 0.26 2.68 0.52 * 3.72 2.26 3.10\n666,350 48.13 1.28 1.93 0.00 0.08 0.02 * 1.64 1.01 1.54\nFurdea (14) auditory 88.08 1.15 4.66 0.91 4.65 1.00 * 3.59 2.22 2.26\nvisual 98.08 3.54 15.75 3.24 15.79 3.40 * 12.15 7.46 7.49\nCeocetti (17) 92.25 19.64 35.34 * * * 5.51 22.54 13.25 13.25\nTownsend (3) cb72 91.52 4.33 23.01 3.12 22.45 3.64 * 15.67 9.25 9.28\nrc72 77.34 4.64 19.70 2.07 16.51 2.68 * 13.68 8.12 8.59\nJin (4) 9-P 87.33 5.82 29.32 3.35 27.14 4.25 * 18.65 11.09 11.09\n12-P 88.00 5.40 27.49 3.20 25.97 4.06 * 17.48 10.39 10.39\n14-P 93.26 3.77 20.93 2.78 20.55 3.21 * 13.34 7.90 7.90\n16-P 93.23 5.26 29.14 3.85 28.36 4.44 * 18.58 11.00 11.00\n19-P 93.99 4.70 26.39 3.56 25.86 4.05 * 16.83 9.96 9.96\nRyan (12) PS 84.92 3.78 17.85 2.03 16.46 2.67 5.28 21.64 12.71 12.71\nNS 89.80 3.74 19.28 2.51 18.52 3.00 3.12 12.79 7.51 7.51\nSchreuder (15) S1 87.99 2.08 3.75 * * * 0.62 2.54 1.49 1.49\nS2a 86.16 3.05 5.27 * * * 0.91 3.71 2.18 2.18\nS2b 86.07 2.96 5.26 * ** 0.94 3.83 2.25 2.25\nSpeier (13) Static 82.97 5.91 22.06 2.65 20.24 3.91 * 17.78 10.60 11.42\nDynamic 89.63 6.45 27.38 4.14 26.61 5.15 * 21.92 13.00 13.55\nNLP 92.59 7.31 33.15 5.51 32.91 6.37 * 26.44 15.65 16.05\nBold numbers refer to the leading method using that metric and bold method names refer to the results found in the original publication. Asterisks denote methods\nthat cannot be computed for the target system.\n*method cannot be computed for the target system\ndoi:10.1371/journal.pone.0078432.t003\nEvaluating BCI Communication Performance\nPLOS ONE | www.plosone.org 7 October 2013 | Volume 8 | Issue 10 | e78432\nalways reflect actual performance. In the Schreuder et al. [15]\nstudy, subjects were able to type the target sentences faster in the\nS2b trial, but the S2a trial had a higher ITR value due to the\nmulti-step nature of the system.\nOptimization\nThe performance of BCI systems is influenced highly by system\nparameter values. These parameters are typically set by optimizing\nusing some metric. Our analyses illustrate the impact of the\noptimization method on system performance. Optimization is\ndesigned to make a value achieve its optimal value, so it is trivial\nthat optimizing on MI\n2e achieves the highest information rate.\nThe interesting aspect of this analysis is the disparity between the\nthreshold value determined by MI\n2e and the thresholds chosen\nusing other metrics. The threshold is significantly lower than the\nvalues determined by other metrics. A lower threshold results in\nfaster decisions, resulting in significantly higher bit rates when\nerror information is taken into account.\nOptimizing on MI\n2e results in the adoption of lower threshold\nvalues in part because it takes the information contained in errors\ninto account. This information may not be useful in all cases. If the\nreader is not aware of the error model, then this information\nwould be ignored and the functional information transfer would be\nthat described by MI\n2. In this case, the optimization on MI2e\nwould be too aggressive, resulting in an error rate that might be\ntoo high for practical use. The end application should be\nconsidered when choosing the evaluation metric so that the\nsystem can be appropriately optimized.\nIn many BCI communication studies, optimization and\nevaluation are performed using different metrics. The papers\nreferenced in this study used several different optimization\nprocedures, resulting in incompatible results even after converting\nthem to consistent metrics. Even within papers, various metrics are\nused for evaluation in order to compare with various different\nstudies. Going forward, we suggest a standard metric should be\nchosen to standardize BCI results and allow for more consistent\ncomparisons across studies, such as the one presented here.\nError Model\nThe improvements in results from including the error model\nvaried from negligible amounts [14] to over 50% improvement\n[6], and were based mainly on the average accuracy achieved.\nDepending on the application, information considered by this\nerror model might not actually be useful. If the output string is sent\nto a post-processing algorithm designed to correct errors using this\nerror model, it could be translated into a real increase in overall\naccuracy. When a human is reading the user input, knowledge of\nthe trends of errors could be useful in trying to determine the\nattempted output, but this could be a difficult task. Further studies\ncould show a reader’s ability to correct different types of errors (see\nfuture directions). It is the system designer’s role to consider the\nend application when determining the correct metric to use, and it\nmight be appropriate to omit an error model in some instances.\nLimitations\nThe ideal error model used in MIne would include the actual\nprobabilities p(yjx) for allSx,yT pairs for each subject. However,\nit would be impractical to actually find all of these in a training\nstep, so some simplifying assumptions need to be made. The\nprobabilities of adjacent, same row or column, and same virtual\nmatrix probabilities used in thep(yjx) values used in section 2.2.3\nwould vary between subject and system, and therefore should be\ncalculated during training rather than blindly using the values\nprovided by Townsend et al. [3]. Unfortunately, studies rarely\npublish these numbers, so this was not possible in this study.\nWhile adopting a standard evaluation metric makes information\nrates of BCI systems comparable, comparisons between studies\ncan still be misleading. BCI systems are high-dimensional systems\nthat can have many different parameters, electrode configurations,\nand hardware constraints. It is therefore difficult to determine\nwhether an improved performance corresponds to a superior\nmethod or a better tuning of the system parameters. For this\nreason, researchers should be cautious when comparing between\nstudies and limit these comparisons to situations where studies\nshare similar configurations such as when a new study directly\nbuilds upon a previous one. Some work has been performed in\nparameter optimization [6–8], but several aspects such as the\nlength of the pause between selections have not been addressed.\nFurthermore, most of these studies involved healthy subjects, so\nthe translation of these results into the target patient population\ncould vary between systems, irrespective of the evaluation metric\nused.\nFuture Directions\nIn this study, we focused on using BCI systems for communi-\ncating language information. In general, these systems are often\nextended to include various types of menu-based commands [3].\nProbabilities for selections can still be computed similar to the n-\ngram language model, assuming a data set of sequences of\nselections is provided. In this case, the conditional probability of a\nselection sequence would be the relative frequency of that\nsequence in the selection history. To our knowledge, no such\ndata set has been published. Furthermore, all studies that we know\nof were performed using a pure spelling task. Studies of alternate\nuses of these systems would allow us to create more general models\nof selection probabilities in order to further generalize this metric.\nTo date, no BCI communication systems use information about\nthe types of errors to improve their selections. Current systems\ntreat all errors as a wrong answer that is either ignored or deleted,\nrather than combining it with knowledge about common types of\nerrors to acquire information about the target symbol. Applica-\ntions can improve their output if they incorporate this information\nthrough either a post-processing program or integrate it into the\nclassifier itself. When designing a BCI system, constraints of the\ntarget domain should be considered because they provide\ninformation that can improve overall performance when incorpo-\nrated into the classifier. To this end, we have recently reported the\nbenefits of integrating knowledge of language into P300 speller\nclassification [13].\nUltimately, the goal of a communication system is to convey the\nintent of the user. It is clear that a lower error rate is preferable,\nbut it is uncertain how low it needs to be in order for the output to\nbe understood. In addition to the number of errors, the types of\nerrors that occur can be important to reader comprehension. In\nEnglish, for instance, replacing a vowel with another vowel will\noften result in another word, while replacing a vowel with a\nconsonant will usually result in a string that is not a word, making\nthe error more apparent and easier to correct. The relationship\nbetween language-based BCI output accuracy and reader\nunderstanding has not yet been studied.\nConclusion\nThe performance metric used is integral to the evaluation of\nBCI systems as it can influence optimization and comparison of\ndifferent methods. Current methods for evaluating language-based\nBCI systems are largely misapplied and based on incorrect\nEvaluating BCI Communication Performance\nPLOS ONE | www.plosone.org 8 October 2013 | Volume 8 | Issue 10 | e78432\nassumptions, leading to suboptimal implementations and mislead-\ning results. System designers should consider the inherent structure\nof the language domain and the ultimate goal of communication\nwhen developing and evaluating these systems. The mutual\ninformation metric presented here compensates for many of these\nshortcomings and provides a better way to compare and evaluate\nlanguage-based BCI results.\nAuthor Contributions\nConceived and designed the experiments: WS CA NP. Performed the\nexperiments: WS. Analyzed the data: WS CA NP. Contributed reagents/\nmaterials/analysis tools: WS CA NP. Wrote the paper: WS.\nReferences\n1. Wolpaw J, Birbaumer N, McFarland D, Pfurtscheller G, Vaughan T (2002)\nBrain-computer interfaces for communication and control. Clin Neurophysiol\n133:767–791.\n2. Farwell L, Donchin E (1988) Talking off the top of your head: toward a mental\nprosthesis utilizing event-related brain potentials. Electroencephalogr Clin\nNeurophysiol 70(6):510–523.\n3. Townsend G, LaPallo B, Boulay C, Krusienski D, Frye G, et al. (2010) A novel\nP300-based brain-computer interface stimulus presentation paradigm: moving\nbeyond rows and columns. Clin Neurophysiol 121:1109–1120.\n4. Jin J, Allison B, Sellers E, Brunner C, Horki P, et al. (2011) Optimized stimulus\npresentation patterns for an event-related potential EEG-based brain-computer\ninterface. Med Biol Eng Comput 49:181–191.\n5. Wang P, King C, Do A, Nenadic Z (2012) Pushing the Communication Speed\nLimit of a Noninvasive BCI Speller. Cornell University Library arXiv:1212.0469\n[cs.HC].\n6. Sellers E, Krusienski D, McFarland D, Vaughan T, Wolpaw J (2006) A P300\nevent-related potential brain-computer interface (BCI): The effects of matrix size\nand inter stimulus interval on performance. Biological Psychology 73:242–252.\n7. McFarland D, Sarnacki W, Townsend G, Vaughan T, Wolpaw J (2011) The\nP300-based brain-computer interface (BCI): effects of stimulus rate. Clin\nNeurophysiol 122:731–737.\n8. Lu J, Speier W, Hu X, Pouratian N (2012) The effects of stimulus timing features\non P300 speller performance. Clin Neurophysiol 124(2):306–314.\n9. Kaper M, Meinicke P, Grossekathoefer U, Lingner T, Ritter H (2004) BCI\ncompetition 2003 – data set IIb: support vector machines for the P300 speller\nparadigm. IEEE Trans Biomed Eng 50:1073–1076.\n10. Xu N, Gao X, Hong B, Miao X, Gao S (2004) BCI competition 2003 – data set\nIIb: enhancing P300 wave detection using ICA-based subspace projections for\nBCI applications. IEEE Trans Biomed Eng 51:1067–1072.\n11. Serby H, Yom-Tov E (2005) An improved P300-based brain-computer\ninterface. IEEE TransNeural Systems and Rehab Eng 13(1):89–98.\n12. Ryan DB, Frye GE, Townsend G, Berry DR, Mesa-G S, et al. (2011) Predictive\nspelling with a P300-based brain-computer interface: increasing the rate of\ncommunication. Int J Hum-Comput Interact 27:69–84.\n13. Speier W, Arnold C, Lu J, Taira RK, Pouratian N (2012) Natural language\nprocessing with dynamic classification improves P300 speller accuracy and bit\nrate. J Neural Eng 9(1):016004.\n14. Furdea A, Halder S, Drusienski DJ, Bross D, Nijboer F, et al. (2009) An auditory\noddball (P300) spelling system for brain-computer interfaces. Psychophysiology\n46:617–625.\n15. Schreuder M, Rost T, Tangermann M (2011) Listen, you are writing! Speeding\nup online spelling with a dynamic auditory BCI. Front Neurosci 5(112).\n16. Blankertz B, Dornhege G, Krauledat M, Schro¨der M, Williamson J, et al. (2006)\nThe Berlin brain-computer interface presents the novel mental typewriter hex-o-\nspell. Proceedings of the 3rd International Brain-Computer Interface Workshop\nand Training Course, Graz, Austria.\n17. Cecotti H (2010) A self-paced and calibration-less SSVEP-based brain-computer\ninterface speller. IEEE Trans on Neural Systems and Rehab Eng 18:127–133.\n18. Yin E, Zhou Z, Jiang J, Chen F, Liu Y, et al. (2013) A novel hybrid BCI speller\nbased on incorporation of SSVEP into the P300 paradigm. J Neural Eng\n10:026012.\n19. McFarland D, Sarnacki W, Wolpaw J (2003) Brain-computer interface (BCI)\noperation: optimizing information transfer rates. Biol Psychol 63:237–251.\n20. Pierce J (1980) An Introduction to Information Theory. New York: Dover.\n21. Francis W, Kucera H (1979) Brown Corpus Manual.\n22. Kaper M, Ritter H (2004) Generalizing to new subjects in brain-computer\ninterfacing. Conf Proc IEEE Eng Med Biol Soc 6:1073–1076.\nEvaluating BCI Communication Performance\nPLOS ONE | www.plosone.org 9 October 2013 | Volume 8 | Issue 10 | e78432",
  "topic": "Brain–computer interface",
  "concepts": [
    {
      "name": "Brain–computer interface",
      "score": 0.8590617179870605
    },
    {
      "name": "Metric (unit)",
      "score": 0.8109792470932007
    },
    {
      "name": "Computer science",
      "score": 0.7256863713264465
    },
    {
      "name": "Mutual information",
      "score": 0.6734576225280762
    },
    {
      "name": "Standardization",
      "score": 0.4634670317173004
    },
    {
      "name": "Interface (matter)",
      "score": 0.46291640400886536
    },
    {
      "name": "Performance metric",
      "score": 0.462504118680954
    },
    {
      "name": "Field (mathematics)",
      "score": 0.4595645070075989
    },
    {
      "name": "Data mining",
      "score": 0.42573463916778564
    },
    {
      "name": "Noise (video)",
      "score": 0.4143921732902527
    },
    {
      "name": "Communications system",
      "score": 0.4113413095474243
    },
    {
      "name": "Artificial intelligence",
      "score": 0.37774956226348877
    },
    {
      "name": "Machine learning",
      "score": 0.3700413107872009
    },
    {
      "name": "Speech recognition",
      "score": 0.3333205282688141
    },
    {
      "name": "Electroencephalography",
      "score": 0.3182620406150818
    },
    {
      "name": "Mathematics",
      "score": 0.15106496214866638
    },
    {
      "name": "Telecommunications",
      "score": 0.09466442465782166
    },
    {
      "name": "Psychology",
      "score": 0.0
    },
    {
      "name": "Maximum bubble pressure method",
      "score": 0.0
    },
    {
      "name": "Image (mathematics)",
      "score": 0.0
    },
    {
      "name": "Operations management",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Parallel computing",
      "score": 0.0
    },
    {
      "name": "Bubble",
      "score": 0.0
    },
    {
      "name": "Pure mathematics",
      "score": 0.0
    },
    {
      "name": "Psychiatry",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ]
}