{
  "title": "Exploring Prompt Engineering with GPT Language Models for Document-Level Machine Translation: Insights and Findings",
  "url": "https://openalex.org/W4389524035",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2890528055",
      "name": "YANGJian-wu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1998986688",
      "name": "Gang Hu",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3103883205",
    "https://openalex.org/W3005724337",
    "https://openalex.org/W2963532001",
    "https://openalex.org/W4385245566"
  ],
  "abstract": "This paper describes Lan-Bridge Translation systems for the WMT 2023 General Translation shared task. We participate in 2 directions: English to and from Chinese. With the emergence of large-scale models, various industries have undergone significant transformations, particularly in the realm of document-level machine translation. This has introduced a novel research paradigm that we have embraced in our participation in the WMT23 competition. Focusing on advancements in models such as GPT-3.5 and GPT-4, we have undertaken numerous prompt-based experiments. Our objective is to achieve optimal human evaluation results for document-level machine translation, resulting in our submission of the final outcomes in the general track.",
  "full_text": "Proceedings of the Eighth Conference on Machine Translation (WMT), pages 166–169\nDecember 6–7, 2023. ©2023 Association for Computational Linguistics\n166\nExploring Prompt Engineering with GPT Language Models for\nDocument-Level Machine Translation: Insights and Findings\nYangjian Wu\nLan-Bridge / Sichuan (China)\nwuyangjian@lan-bridge.com\nGang Hu\nLan-Bridge / Sichuan (China)\nhugang@lan-bridge.com\nAbstract\nThis paper describes Lan-Bridge Translation\nsystems for the WMT 2023 General Transla-\ntion shared task. We participate in 2 direc-\ntions: English to and from Chinese. With the\nemergence of large-scale models, various in-\ndustries have undergone significant transforma-\ntions, particularly in the realm of document-\nlevel machine translation. This has introduced\na novel research paradigm that we have em-\nbraced in our participation in the WMT23 com-\npetition. Focusing on advancements in models\nsuch as GPT-3.5, we have undertaken numer-\nous prompt-based experiments. Our objective\nis to achieve optimal human evaluation results\nfor document-level machine translation, result-\ning in our submission of the final outcomes in\nthe general track.\n1 Introduction\nRecently, large-scale language models, such as\nGPT-3.5 and GPT-4 (gpt), have emerged as power-\nful tools in the field of natural language processing.\nThese models have showcased their impressive ca-\npabilities in a wide range of tasks, including text\ngeneration, question answering, language transla-\ntion, and more. Language models like GPT-3.5 pos-\nsess the ability to understand and generate coherent,\ncontextually relevant text, capturing the nuances\nof language usage and producing high-quality out-\nputs.\nIn particular, machine translation is an area\nwhere these language models have shown tremen-\ndous promise. Traditional machine translation mod-\nels (Yang et al., 2020) used the conventional Trans-\nformer architecture (Vaswani et al., 2017) since\nGPT-3.5 has the potential to revolutionize the trans-\nlation process by leveraging its massive size and\nlanguage understanding capabilities. With the ad-\nvent of large models, the machine translation field\nhas faced new challenges, and utilizing large mod-\nels for machine translation is a novel attempt.By ef-\nfectively incorporating prompts and context, GPT-\n3.5 can produce translations that exhibit fluency,\naccuracy, and adherence to the source text.\nThis study focuses on experimenting and evaluat-\ning different prompt engineering techniques to fur-\nther enhance the translation performance of GPT-\n3.5. By providing more refined and contextually\nspecific prompts, we aim to observe the model’s\nability to adjust and refine its translations, resulting\nin improved translation quality. Additionally, we\nexplore the impact of temperature adjustments on\nthe generated translations, allowing us to fine-tune\nthe level of randomness in the output and achieve\nmore deterministic and accurate translations.\nFurthermore, we investigate both sentence-level\nand document-level approaches, examining the ef-\nfectiveness of GPT-3.5 in handling translations at\ndifferent granularity levels. These approaches aim\nto leverage the model’s language understanding\ncapabilities to not only produce accurate sentence-\nlevel translations but also ensure coherence and\nconsistency at the overall document level.\nBy delving into these aspects and evaluating the\nperformance of GPT-3.5 in the context of the WMT\ncompetition, we aim to contribute to the broader\nunderstanding of the capabilities, strengths, and\nlimitations of state-of-the-art language models in\nthe field of machine translation.\nThe inspiration for this study stems from the\noutstanding performance exhibited by these large-\nscale language models, especially in addressing\nreal-world challenges such as major wildfires.\nGPT-3.5-4k and GPT-3.5-16k, with their increased\nmodel capacities, have demonstrated remarkable\ncapabilities in generating high-quality text across\nvarious domains. Motivated by these advance-\nments, our study aims to harness the power of these\nmodels and explore their potential in the specific\ndomain of machine translation.\nBy leveraging the robustness and adaptability of\nGPT-3.5-4k and GPT-3.5-16k, we conduct rigorous\n167\nexperimentation to thoroughly evaluate their trans-\nlation capabilities. We delve into the nuances of\ndifferent parameter adjustments, including prompts\nand temperature, to optimize and enhance the mod-\nels’ performance specifically for translation tasks.\nBy strategically fine-tuning these parameters, we\naim to unlock hidden potential and push the bound-\naries of their translation capabilities.\nReal-world challenges, such as major wildfires,\nrequire timely and accurate translation of critical\ninformation across languages. The effectiveness of\nmachine translation plays a pivotal role in commu-\nnicating vital updates and ensuring efficient infor-\nmation dissemination during such situations. By\ninvestigating the translation capabilities of GPT-\n3.5-4k and GPT-3.5-16k, we strive to contribute\ninsights that can improve translation efficiency and\naid in overcoming language barriers in emergency\nsituations.\nWith this study, we aim to shed light on the im-\nmense potential of large-scale language models,\nsuch as GPT-3.5, in addressing real-world chal-\nlenges through machine translation. By harnessing\ntheir capabilities and understanding their perfor-\nmance in various scenarios, we hope to pave the\nway for more effective and accurate translation sys-\ntems that can assist in critical situations.\n2 Methods\nWe have designed three prompt schemes:\nP1: Translate this sentence from SRC to TGT,\ndo not write any explanations\nP2: Translation Request - Sentence-by-Sentence\nTranslation. Language Pair: SRC to TGT. Instruc-\ntions: 1. Each sentence of the document will be\nprovided individually in the \"Original Sentence\"\nsection. 2. In the \"Translation\" section, please\nprovide the corresponding translation for each sen-\ntence, considering the context and aiming for faith-\nful translation while minimizing unaligned transla-\ntions. 3. Avoid including any explanations in the\ntranslation. Original Sentence:\nP3: Translation Request - Sentence-by-Sentence\nTranslation. Language Pair: SRC to TGT. Instruc-\ntions: 1. Each sentence of the document will be\nprovided individually in the \"Original Sentence\"\nsection. 2. In the \"Translation\" section, please\nprovide the corresponding translation for each sen-\ntence, considering the context and aiming for faith-\nful translation while minimizing unaligned trans-\nlations. 3. Avoid including any explanations in\nthe translation. 4.Please review the translations for\nverifying that they remain faithful to the original\ntext and provide revised versions accordingly if\nnecessary. If no revisions are needed, provide the\ntranslations as they are.\nIn our study, we conducted several experiments\nto evaluate the performance of GPT-3.5. The fol-\nlowing were the approaches we employed:\n• Sentence-to-sentence translation: We used the\nprompt \"Translate this sentence from SRC to\nTGT, do not write any explanations\" to evalu-\nate the model’s ability to translate individual\nsentences accurately.\n• Multi-turn dialogue translation: We explored\nthe impact of multi-turn conversations on the\nperformance of GPT-3.5. Using the prompt\nP1.\n• Multi-turn dialogue translation with detailed\nprompt P3. This experiment aims to test\nwhether GPT-3.5 has the ability to get faith-\nful translations while minimizing unaligned\ntranslations.\n• Comparison between GPT-3.5-4k and GPT-\n3.5-16k: We performed separate experiments\nusing both GPT-3.5-4k and GPT-3.5-16k mod-\nels to observe any differences in translation\nabilities between the two.\n• Adjusting temperature parameter: We varied\nthe temperature parameter (0, 0.3, 0.7) to ex-\namine its impact on the translation quality.\nChanging the temperature can control the ran-\ndomness of the generated translations.\n• Incorporating fake CoT prompt P3. This ex-\nperiment aims to test whether GPT-3.5 has the\nability to automatically reflect and optimize\nits translations.\n3 Result\nWe conduct experiments to quantify the impact of\neach component in our system. The evaluation\nconduct on test set on wmt22 using SacreBLEU\n(Post, 2018) and COMET (Stewart et al., 2020).\nAs shown in Table 1, here are the conclusions\nbased on your experimental results:\n• From the first and second experiment results,\nit can be concluded that the performance of\nGPT-3.5 in multi-turn dialogue is better than\n168\nlanguage pair Prompt Multi-turn T Model Bleu-A Bleu-B Chrf-A Chrf-B Comet-A Comet-B\nzh-en P1 false 0 GPT-3.5-4k 26.6 20.0 57.4 52.5 52.7 43.5\nzh-en P1 true 0 GPT-3.5-4k 27.7 20.7 58.4 53.2 55.8 46.7\nzh-en P3 true 0 GPT-3.5-16k 23.4 18.0 54.4 50.2 54.9 46.1\nen-zh P1 true 0 GPT-3.5-4k 45.7 53.9 41.1 48.5 63.4 71.2\nen-zh P2 true 0 GPT-3.5-4k 44.2 51.4 39.9 46.0 62.1 70.6\nen-zh P2 true 0.7 GPT-3.5-4k 42.8 49.3 38.4 44.1 61.7 68.7\nen-zh P2 true 0.7 GPT-3.5-16k 42.7 49.3 38.3 44.8 63.2 71.1\nen-zh P2 true 0.3 GPT-3.5-16k 44.4 51.5 39.9 46.3 63.8 71.2\nTable 1: Bleu/Chrf/Comet score on wmt22 test set. The COMET scores are calculated with the model wmt20-\ncomet-da, the ChrF scores are calculated using all available references and SacreBLEU signature is the default\nsettings. Scores are multiplied by 100. T represents Temperature\nsingle-turn translation. This indicates that con-\ntext can help improve the translation quality\nof GPT-3.5 by providing additional prompts.\n• Comparing the results of the third experiment\nwith the fourth experiment, it is concluded that\nthe performance of P2 is worse. This suggests\nthat GPT-3.5 does not fully understand the\ngiven prompt, which results in difficulty in\ngenerating accurate translations.\n• Comparing the results of the fourth, fifth,\nand seventh experiments, it is concluded that\nlower temperature values yield better trans-\nlation results. This indicates that reducing\ntemperature parameter leads to more deter-\nministic and high-quality translations.\n• Comparing the results of the fifth and sixth\nexperiments, it is concluded that GPT-3.5-16k\nperforms better in translation than GPT-3.5-\n4k.\n• Comparing the results of the seventh exper-\niment with previous results, it is concluded\nthat P3 performs the worst. Additionally, ob-\nserving the actual revised results, it can be\nnoted that GPT-3.5-16k rarely modifies its\ntranslations, indicating that without specific\nand clear instructions, it is unable to make\neffective modifications to its own translations.\nBased on our previous results, we have chosen\nGPT-3.5-16k as the final model for our submis-\nsion. For the WMT23 en-zh/zh-en track, we set\nthe temperature to 0 and utilized P1 as the prompt.\nAdopting a multi-turn dialogue approach, we sub-\nmitted our final results with the systerm name \"Lan-\nBridgeMT\". Figure 1 and Figure 2 show the results\nof our systerm. 1 Additionally, for other language\npairs in the general WMT competition, we opted to\nsubmit the results generated by our LanMT (Han\net al., 2022) engine. This decision was made to\nassess the engine’s performance and determine its\nscoring capabilities directly in the online evaluation\nenvironment.\nBy taking these approaches, we aim to showcase\nthe effectiveness of GPT-3.5 and demonstrate the\nperformance of our LanMT engine in the respective\nWMT tracks. These submissions reflect our over-\narching goal of participating in and contributing to\nthe advancement of machine translation research\nand development.\n4 Conclusion\nIn this study, we evaluated the translation perfor-\nmance of GPT-3.5 using various experimental ap-\nproaches. Our findings indicate that incorporating\nmulti-turn dialogue prompts improves the transla-\ntion quality of GPT-3.5, highlighting the impor-\ntance of context in guiding the model’s translations.\nFurthermore, we observed that GPT-3.5-16k, com-\npared to GPT-3.5-4k, demonstrates superior trans-\nlation capabilities in commit scores, indicating its\nenhanced ability to understand and fulfill user in-\nstructions. However, there are marginal differences\nin the other two metrics, BLEU and ChrF. Addition-\nally, we found that lower temperature values result\nin improved translation quality, indicating the use-\nfulness of controlling randomness in the generated\ntranslations. However, it is important to note that\nGPT-3.5 may struggle with understanding ambigu-\nous prompts and lacks the ability to autonomously\nadjust and optimize its translations without explicit\ninstructions. These findings contribute to our under-\n1https://github.com/wmt-conference/wmt23-news-\nsystems\n169\nFigure 1: Score for zh-en translation task\nFigure 2: Score for en-zh translation task\nstanding of the strengths and limitations of GPT-3.5\nin translation tasks, emphasizing the need for pre-\ncise prompts to achieve optimal translation results.\nReferences\nGpt-4 technical report.\nBing Han, Yangjian Wu, Gang Hu, and Qiulin Chen.\n2022. Lan-bridge MT’s participation in the WMT\n2022 general translation shared task. In Proceedings\nof the Seventh Conference on Machine Translation\n(WMT), pages 268–274, Abu Dhabi, United Arab\nEmirates (Hybrid). Association for Computational\nLinguistics.\nMatt Post. 2018. A call for clarity in reporting BLEU\nscores. In Proceedings of the Third Conference on\nMachine Translation: Research Papers, pages 186–\n191, Brussels, Belgium. Association for Computa-\ntional Linguistics.\nCraig Stewart, Ricardo Rei, Catarina Farinha, and\nAlon Lavie. 2020. COMET - deploying a new\nstate-of-the-art MT evaluation metric in produc-\ntion. In Proceedings of the 14th Conference of\nthe Association for Machine Translation in the\nAmericas (V olume2: User Track), pages 78–109,\nVirtual. Association for Machine Translation in the\nAmericas.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is\nall you need. Advances in neural information\nprocessing systems, 30.\nShuoheng Yang, Yuxin Wang, and Xiaowen Chu. 2020.\nA survey of deep learning techniques for neural ma-\nchine translation. arXiv preprint arXiv:2002.07526.",
  "topic": "Realm",
  "concepts": [
    {
      "name": "Realm",
      "score": 0.7558445930480957
    },
    {
      "name": "Machine translation",
      "score": 0.7541285753250122
    },
    {
      "name": "Computer science",
      "score": 0.7484873533248901
    },
    {
      "name": "Translation (biology)",
      "score": 0.5862107872962952
    },
    {
      "name": "Task (project management)",
      "score": 0.571617841720581
    },
    {
      "name": "Natural language processing",
      "score": 0.5263743996620178
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4568915367126465
    },
    {
      "name": "Bridge (graph theory)",
      "score": 0.42834874987602234
    },
    {
      "name": "Software engineering",
      "score": 0.3236180543899536
    },
    {
      "name": "Engineering",
      "score": 0.14184561371803284
    },
    {
      "name": "Systems engineering",
      "score": 0.10806503891944885
    },
    {
      "name": "Medicine",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Messenger RNA",
      "score": 0.0
    },
    {
      "name": "Internal medicine",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    }
  ]
}