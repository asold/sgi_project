{
  "title": "Comparative Analysis of Large Language Models for Answering Cancer-Related Questions in Korean",
  "url": "https://openalex.org/W4410450768",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5066445933",
      "name": "Hyun Chang",
      "affiliations": [
        "Catholic Kwandong University",
        "International St. Mary's Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A5103415397",
      "name": "Jin-Woo Jung",
      "affiliations": [
        "Catholic Kwandong University",
        "International St. Mary's Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A5100728951",
      "name": "Yong-Ho Kim",
      "affiliations": [
        "Catholic Kwandong University",
        "International St. Mary's Hospital"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4381587418",
    "https://openalex.org/W4387500346",
    "https://openalex.org/W4389232726",
    "https://openalex.org/W4387242094",
    "https://openalex.org/W4327681325",
    "https://openalex.org/W4386781106",
    "https://openalex.org/W4386117070",
    "https://openalex.org/W4386110374",
    "https://openalex.org/W4386414742",
    "https://openalex.org/W4396833233",
    "https://openalex.org/W4388014118",
    "https://openalex.org/W3093325279",
    "https://openalex.org/W3120350743",
    "https://openalex.org/W1857789879",
    "https://openalex.org/W4220744328",
    "https://openalex.org/W2130071626"
  ],
  "abstract": "Both ChatGPT and CLOVA X answered Korean-language cancer-related questions with no significant difference in overall quality.",
  "full_text": "1\nwww.eymj.org\nINTRODUCTION\nLarge language models (LLMs) have emerged as powerful tools \ncapable of generating human-like text responses across various \ndomains, including medicine.1 The integration of LLMs, such \nas ChatGPT , into healthcare has opened new avenues for pa-\ntient education, clinical decision support, and medical re -\nsearch.2 These models, trained on extensive datasets, have the \npotential to revolutionize how medical information is accessed \nand utilized by both healthcare professionals and the general \npublic.\nThe effectiveness and reliability of LLMs in providing accu-\nrate medical information are still under investigation.3-6 Previ-\nous studies have revealed variations in model performance \nacross different medical topics.7,8 For example, Chen, et al. 7 \nreported that 12.5% of the ChatGPT’s responses were halluci-\nnated (that is, contained inaccuracies), primarily in recommen-\ndations for localized treatment of advanced diseases, targeted \ntherapy, and immunotherapy. Similarly, Lim, et al.8 found that \n15% of the ChatGPT-4.0-generated answers related to myopia \ntreatment and prevention were less optimal than other myo-\npia care domains.\nRecent advances in LLMs have been driven primarily by ob-\nComparative Analysis of Large Language Models \nfor Answering Cancer-Related Questions in Korean\nHyun Chang1, Jin-Woo Jung2, and Yongho Kim3\nDepartments of 1Medical Oncology and Hematology, 2Urology, 3Radiation Oncology, International St. Mary’s Hospital, \nCatholic Kwandong University, Incheon, Korea.\nPurpose: Large language models (LLMs) have shown potential in medicine, transforming patient education, clinical decision \nsupport, and medical research. However, the effectiveness of LLMs in providing accurate medical information, particularly in \nnon-English languages, remains underexplored. This study aimed to compare the quality of responses generated by ChatGPT \nand Naver’s CLOVA X to cancer-related questions posed in Korean.\nMaterials and Methods: The study involved selecting cancer-related questions from the National Cancer Institute and Korean Na-\ntional Cancer Information Center websites. Responses were generated using ChatGPT and CLOVA X, and three oncologists assessed \ntheir quality using the Global Quality Score (GQS). The readability of the responses generated by ChatGPT and CLOVA X was calcu-\nlated using KReaD, an artificial intelligence-based tool designed to objectively assess the complexity of Korean texts and reader com-\nprehension.\nResults: The Wilcoxon test for the GQS score of answers using ChatGPT and CLOVA X showed that there is no statistically signifi-\ncant difference in quality between the two LLMs (p>0.05). The chi-square statistic for the variables “Good rating” and “Poor rat-\ning” showed no significant difference in the quality of responses between the two LLMs (p>0.05). KReaD scores were higher for \nCLOVA X than for ChatGPT (p=0.036). The categorical data analysis for the variables “Easy to read” and “Hard to read” revealed no \nsignificant difference (p>0.05).\nConclusion: Both ChatGPT and CLOVA X answered Korean-language cancer-related questions with no significant difference in \noverall quality.\nKey Words:   Large language model, patients, cancer, Korean language \nOriginal Article \npISSN: 0513-5796 · eISSN: 1976-2437\nReceived: July 16, 2024   Revised: December 27, 2024\nAccepted: January 20, 2025   Published online: May 15, 2025\nCorresponding author: Hyun Chang, MD, PhD, Department of Medical Oncology \nand Hematology, International St. Mary’s Hospital, Catholic Kwandong University, \n25 Simgok-ro 100beon-gil, Seo-gu, Incheon 22711, Korea.\nE-mail: hchang@ish.ac.kr\n•The authors have no potential conflicts of interest to disclose.\n© Copyright: Yonsei University College of Medicine 2025\nThis is an Open Access article distributed under the terms of the Creative Com -\nmons Attribution Non-Commercial License (https://creativecommons.org/licenses/\nby-nc/4.0) which permits unrestricted non-commercial use, distribution, and repro-\nduction in any medium, provided the original work is properly cited.\nYonsei Med J\nhttps://doi.org/10.3349/ymj.2024.0200\n\n2\nLarge Language Models for Korean Questions of Cancer\nhttps://doi.org/10.3349/ymj.2024.0200\njectives to improve comprehension and production of English \ntexts.9,10 These advances have led to various powerful LLMs that \nare proficient in English, reflecting the norms and values of \nmostly English-speaking societies, which are over-represented \nin the pre-training corpora.11,12 In other words, most LLMs in-\ncluding ChatGPT are predominantly trained on English-lan-\nguage data, resulting in limited training for other languages, and \nconsequently, less reliable outputs for non-English queries, \nwhich often include distinctive cultural nuances, geopolitical \nsituations, and other regional specificities, as well as unique \nlinguistic attributes.11,13 \nIt is of paramount importance to evaluate how LLM systems \nperform across different languages, given the linguistic and cul-\ntural nuances influencing medical communication. Despite \nthese insights, a notable gap exists in research in the medical \nfield regarding the performance of LLMs in non-English lan-\nguages.14,15 ChatGPT’s answers to cirrhosis-related questions \nare less accurate in Arabic than in English.14 An evaluation of \nLLMs in answering neurophysiology-related questions in Eng-\nlish and Persian revealed some incorrect answers unique to \nPersian.15 This underscores the necessity for the development \nof effective tools that can address medical questions in a vari-\nety of languages, particularly in a manner that is culturally ap-\npropriate and readily comprehensible. For Korean-speaking \ncancer patients, access to tools that can answer medical ques-\ntions in their native language at any time and in any location \nwould greatly enhance accessibility and convenience. It is there-\nfore essential to evaluate publicly available LLMs, such as Chat-\nGPT and CLOVA X, in this context in order to gain insight into \ntheir effectiveness and identify areas for improvement.\nThis study compared the quality of the responses of two \nLLMs: ChatGPT (GPT-4) and Naver’s CLOVA X, to cancer-re-\nlated questions posed in Korean. CLOVA X is a chat service \nbased on HyperCLOVA X, which is pretrained using an evenly \ndistributed mixture of Korean, English, and programming \nsource code data. CLOVA X is tailored to the Korean linguistic \nand cultural framework and can understand and generate \nEnglish, among several other languages.11 \nBy systematically evaluating the quality and readability of the \nresponses generated using ChatGPT and CLOVA X, this study \nprovides a comprehensive understanding of their strengths and \nlimitations in the context of Korean-language medical-related \ninquiries. This study contributes to the growing body of knowl-\nedge on artificial intelligence (AI) in healthcare and highlights \nthe need for continuous improvement and adaptation of LLMs \nto meet the diverse needs of global users.\nMATERIALS AND METHODS\nQuestion curation\nThe study was conducted between March 1, 2024, and April \n30, 2024. Questions frequently asked by the public regarding \ncancer were collected from the National Cancer Institute’s \n(NCI) webpage ( https://www.cancer.gov/about-cancer/\ncauses-prevention/risk/myths) and the Korean National Can-\ncer Information Center’s webpage (https://cancer.go.kr). The \nprimary objective of this study was to ascertain whether there is \na significant difference in the quality of responses to cancer-re-\nlated questions posed in Korean between ChatGPT and CLOVA \nX. Sample size calculations were performed using the pwr \npackage (pwr_1.3-0) in R. Based on a paired t-test with an effect \nsize (Cohen’s d) of 0.6, a significance level (α) of 0.05, and power \nof 0.8, the analysis determined that 24 pairs of responses were \nrequired.16 We ultimately selected the most recent 26 questions \n(Supplementary Tables 1 and 2, only online). To better charac-\nterize LLM performance across various topics within cancer, \nquestions were categorized into four subgroups for statistical \nanalysis: 1) general knowledge of cancer, 2) carcinogenesis, \n3) cancer screening, and 4) cancer prevention.\nInquiries and response generation\nIn April 2024, the 26 questions were entered into Microsoft (Mi-\ncrosoft Corporation, Redmond, WA, USA) Copilot and Naver \n(Naver Corporation, Seongnam, South Korea) CLOVA X. Copi-\nlot runs on the latest generation of ChatGPT-4 but includes a \n“More Precise” response mode to better match the length of \nhuman responses compared with the typically lengthier re-\nsponses of ChatGPT-4 (https://copilot.microsoft.com/).9 CLO-\nVA X, a conversational AI developed by Naver, is built on the \nfoundations of HyperCLOVA X technology and is trained on a \ndiverse range of Korean texts, including news articles, books, and \nweb content, to enhance its understanding of Korean culture, \nhistory, and society (https://clova-x.naver.com/).11 Each question \nwas entered independently using the “New Chat” function into \nboth Copilot and CLOVA X. All questions to Copilot and CLOVA \nX were in Korean.\nGrading system for accuracy\nThree experienced oncologists, including a medical oncolo-\ngist, a radiation oncologist, and a urologic oncologist, all active \nin academic practice at the time of this study, independently \nreviewed and graded the quality of the responses to questions \naccording to the Global Quality Score (GQS).17\nThe quality and usefulness of content were scored from 1 to \n5, where a score of 1 denotes poor quality and proficiency, and \na score of 5 denotes maximum quality and reliability of con-\ntent. The GQS scoring is defined as follows:\nGQS 1: Poor quality, poor flow of the site; most information \nmissing; not at all useful for patients.\nGQS 2: Generally poor quality and poor flow; some useful \ninformation listed, but many important topics missing; of ex-\ntremely limited use to patients.\nGQS 3: Moderate quality; suboptimal flow; some important \ninformation adequately discussed, but other information \npoorly discussed; somewhat useful for patients.\n3\nHyun Chang, et al.\nhttps://doi.org/10.3349/ymj.2024.0200\nGQS 4: Good quality; generally good flow; most of the rele-\nvant information present, but some topics not covered; useful \nfor patients.\nGQS 5: Excellent quality and flow; very useful for patients.\nIf the scores for a given inquiry differed among the three ex-\nperts, they re-evaluated the LLM answers and jointly reached \na final decision. The proportions of each grade among the re-\nsponses were calculated and reported as percentages.\nReadability\nThe readability of the answers generated using ChatGPT and \nCLOVA X was assessed using KReaD, an AI-based index that \nevaluates the complexity of Korean text and the comprehen-\nsion ability of a reader. The KReaD score was calculated using \nthe online tool available at [KReaD] (https://www.kread.ai/).18\nStatistical analysis\nThe Wilcoxon signed-rank test was used to compare the GQS \nbetween ChatGPT and CLOVA X, as the Shapiro–Wilk test in-\ndicated that the GQS scores were not normally distributed. \nThis test allows for the comparison of the central tendency of \nthe two groups without assuming normality.19 The paired t-test \nwas used to compare the mean KReaD score between ChatG-\nPT and CLOVA X, as the Shapiro–Wilk test indicated that these \nscores were normally distributed.\nThe ratings were reclassified into two categories: “Poor rat-\ning” and “Good rating. ” “Poor rating” included GQS 1, GQS 2, \nand GQS 3, indicating incorrectly or inadequately answered \nqueries, whereas “Good rating” included GQS 4 and GQS 5, \nindicating correctly and adequately answered queries.20 In or-\nder to analyze the readability of the texts, the KReaD scores \nwere converted to the appropriate grade level. The grade level \nrepresented the difficulty of the text, which was an estimate of \nthe appropriate grade level for reading the text. The answers \ngenerated using ChatGPT and CLOVA X were then reclassi-\nfied into two categories: “Easy to read” and “Hard to read. ” \nAnswers in the “Easy to read” category exhibited grade levels \nindicating a reading level appropriate for students below the \n1st–2nd grade of middle school. Conversely, texts classified as \n“Hard to read” exhibited grade levels corresponding to the read-\ning levels of upper middle school 3rd grade through 1st grade of \nhigh school (Supplementary Table 3, only online).21 The chi-\nsquare test was applied to the reclassified data to evaluate po-\ntential differences in the distributions of ratings and readability \nscores. Statistical analysis was performed using R 4.4.1 version. \nThis study did not involve human subjects. No ethical ap-\nproval or consent was required.\nRESULTS\nQuality analysis of ChatGPT and CLOVA X\nA total of 26 cancer-related questions in Korean were inputted \ninto ChatGPT and CLOVA X (Supplementary Tables 1 and 2, \nonly online). ChatGPT responded with the following GQS: 5 \nGQS 5 (19.2%), 16 GQS 4 (61.5%), 4 GQS 3 (15.4%), and 1 GQS \n1 (13.2%). CLOVA X responded with the following GQS: 3 GQS \n5 (11.5%), 14 GQS 4 (53.8%), 5 GQS 3 (19.2%), and 4 GQS 2 \n(15.4%) (Table 1).\nThe Wilcoxon signed-rank test comparing the GQS values of \nanswers from ChatGPT and CLOVA X showed no statistically \nsignificant difference in the central tendency of quality scores \nbetween the two LLMs (p=0.078) (Fig. 1 and Supplementary \nFig. 1, only online). The chi-square test for “Good rating” ver-\nsus “Poor rating” showed no significant difference in the qual-\nity of responses between ChatGPT and CLOVA X ( p=0.348) \n(Table 2).\nWhen examining the subgroups of questions, the ratings for \nChatGPT in the “General knowledge of cancer” category \nshowed 28.6% rated as GQS 4 and 14.3% as GQS 5 (Table 1 and \nFig. 1B). By contrast, CLOVA X had 14.3% of responses rated as \nGQS 5 and 14.3% as GQS 4. Notably, the “General knowledge \nof cancer” category contained the highest proportion of poor \nratings for both models: ChatGPT had one GQS 1 and three \nGQS 3 ratings, while CLOVA X had three GQS 2 and two GQS 3 \nTable 1. GQS Scores of ChatGPT and CLOVA X for Questions Catego-\nrized by Subgroup\nChatGPT \n(n)\nCLOVA X \n(n)\nGeneral knowledge of cancer (n=7)\n1. Poor quality, not at all useful 1 0\n2. Generally poor quality, very limitedly useful 0 3\n3. Moderate quality, somewhat useful 3 2\n4. Good quality, useful 2 1\n5. Excellent quality, very useful 1 1\nCarcinogenesis (n=7)\n1. Poor quality, not at all useful 0 0\n2. Generally poor quality, very limitedly useful 0 1\n3. Moderate quality, somewhat useful 0 1\n4. Good quality, useful 5 4\n5. Excellent quality, very useful 2 1\nCancer prevention (n=6)\n1. Poor quality, not at all useful 0 0\n2. Generally poor quality, very limitedly useful 0 0\n3. Moderate quality, somewhat useful 0 0\n4. Good quality, useful 5 5\n5. Excellent quality, very useful 1 1\nCancer screening (n=6)\n1. Poor quality, not at all useful 0 0\n2. Generally poor quality, very limitedly useful 0 0\n3. Moderate quality, somewhat useful 1 2\n4. Good quality, useful 4 4\n5. Excellent quality, very useful 1 0\nGQS, Global Quality Score.\n4\nLarge Language Models for Korean Questions of Cancer\nhttps://doi.org/10.3349/ymj.2024.0200\nratings. In the “Carcinogenesis” category, ChatGPT demon-\nstrated strong performance, with 71.4% of the responses rated \nas GQS 4 and 28.6% as GQS 5 (Table 1 and Fig. 1B). CLOVA X \nalso performed better, with 71.4% of the responses rated as \nGQS 4 or GQS 5. However, two responses (28.6%) were rated \nGQS 3 and GQS 2. In the “Cancer screening” category, Chat-\nGPT had one response (16.7%) rated as GQS 3, and CLOVA X \nhad two responses (33.3%) rated as GQS 3 (Table 1 and Fig. \n1B). In the “Cancer prevention” category, all ChatGPT and \nCLOVA X responses were rated as GQS 4 or 5, indicating strong \nperformance in providing useful health information (Table 1 \nand Fig. 1B).\nReadability analysis of ChatGPT and CLOVA X\nIn the readability assessment, KReaD scores were higher (i.e., \nmore difficult to read) for CLOVA X than for ChatGPT [1503± \n154 (Korean middle school 1st–2nd grade) vs. 1,575±159 (Ko-\nrean middle school 1st–2nd grade), respectively] (paired t-\ntest, p=0.036) (Fig. 2A and Supplementary Fig. 2, only online). \nUpon analysis of readability by subgroup, no significant dif-\nferences were observed between the two LLMs across all sub-\ngroups. However, a marginal difference was noted in the “Can-\ncer screening” subgroup (p=0.081) (Fig. 2B). \nAmong ChatGPT responses, 69.2% were classified as “Easy to \nread, ” appropriate for students below the middle school 1st \n–2nd grade level, while the remaining 30.8% were classified as \n“Hard to read” (Tables 2 and 3). In contrast, 50% of the respons-\nes produced by CLOVA X were classified as “Easy to read, ” while \nthe remaining 50% were classified as “Hard to read. ” The analy-\nsis of categorical data for the variables “Easy to read” and “Hard \nto read” showed no significant difference in readability between \nthe responses from ChatGPT and CLOVA X (chi-square test, \np=0.157) (Table 2).\nDISCUSSION\nSeveral studies have been conducted to evaluate the respons-\nes provided by LLMs to cancer-related questions in English.3-8 \nHowever, to the best of the authors’ knowledge, no research has \nbeen conducted on LLMs trained on Korean language data, \nnor has any comparative study been conducted involving widely \nused models such as ChatGPT . This study is the first of its kind.\nOne notable finding in this study is the significant proportion \nof responses in Korean generated using ChatGPT and CLOVA X \nthat received poor ratings. Specifically, 19.2% of ChatGPT’s an-\nswers and 34.6% of CLOVA X’s answers were rated as poor. This \nhighlights a limitation in the accuracy and reliability of AI-gen-\nerated responses to cancer-related questions in Korean, em-\nphasizing the need for continuous improvements and updates \nto these models to ensure the delivery of high-quality informa-\ntion in Korean. Although comparing results across studies can \nbe challenging due to different research methods, previous \nstudies suggest that the accuracy of ChatGPT’s responses is \ngenerally lower for Korean questions than for English ones. For \nexample, Johnson, et al.5 reported that two of the 13 answers \n(15.3%) using ChatGPT to English questions on the NCI web-\npage were rated as inaccurate by one reviewer and as accurate \nby four reviewers. In another study assessing ChatGPT’s re-\nsponses to head and neck cancer inquiries, 86.4% of the an-\nswers were comprehensive and correct, 11% were incomplete \n5\n4\n3\n2\n1\n5\n4\n3\n2\n1 General knowledgeChatGPT\np=0.572 p=0.203p=0.078 p>0.999 p=0.346\nCategory\nCarcinogenesis PreventionCLOVA X Screening\nGQS\nGQS\nBA\n  ChatGPT\n  CLOVA X\nFig. 1. Accuracy comparison between ChatGPT and CLOVA X. (A) Comparison of GQS in generated responses from ChatGPT and CLOVA X, with two-\ntailed p-values estimated using a Wilcoxon signed-rank test. (B) GQS for the two LLMs in each of the four categories. Two-tailed p-values were estimated \nusing a Wilcoxon signed-rank test. GQS, Global Quality Score; LLM, large language model.\nTable 2. Categorization of Ratings for ChatGPT and CLOVA X\nRating category ChatGPT CLOVA X p value*\nGQS 0.348\nGood rating 21 (80.8) 17 (65.4)\nPoor rating   5 (19.2)   9 (34.6)\nKReaD 0.157\nEasy to read 18 (69.2) 13 (50.0)\nHard to read   8 (30.8) 13 (50.0)\nData are presented as n (%).\n*Compared with Pearson’s chi-square test.\n5\nHyun Chang, et al.\nhttps://doi.org/10.3349/ymj.2024.0200\nFig. 2. KReaD scores for the two LLMs. (A) Comparison of readability in generated responses from ChatGPT and CLOVA X, with two-tailed p-values esti-\nmated using a paired t-test. (B) Readability scores for the two LLMs in each of the four categories. Bar plots show the mean values ±standard deviation. \nTwo-tailed p-values were estimated using a paired t-test. LLM, large language model.\nor partially correct, and 2.6% contained a mix of accurate and \ninaccurate information.3 Notably, no completely irrelevant re-\nsponses were present.3\nHallucinations in LLMs refer to the phenomenon where the \ngenerated output contains inaccurate or nonfactual informa-\ntion. When integrating LLMs into the medical domain, these \nfluent hallucinations can disseminate incorrect medical infor-\nmation, leading to misdiagnoses, inappropriate treatments, \nand harmful patient education.22 We observed some hallucina-\ntions in the answers generated by both ChatGPT and CLOVA X. \nFor example, responses to the question “ Are there herbal prod-\nucts that can cure cancer?” demonstrated hallucinations by \nproviding misleading information. ChatGPT’s answer claims \nspecific herbs such as mulberry and ginger have strong anti-\ncancer properties without substantial evidence, stating that \nginger is “10000 times more effective than Taxol, ” which is inac-\ncurate. CLOVA X’s answer, although more cautious, still lacks \ndetailed guidance, merely advising consultation with a profes-\nsional. These examples highlight a key weakness of LLMs and \nthe importance of ensuring the accuracy of LLM outputs in the \nmedical domain.22\nWhen comparing the accuracy of ChatGPT and CLOVA X in \nresponse to Korean-language questions regarding cancer, both \nperformed competently, with no significant differences in the \noverall quality ratings. However, specific differences emerged \nin category-based analyses. ChatGPT demonstrated slightly \nbetter performance in the “Carcinogenesis” category. Both \nLLMs showed similar strengths in the “Cancer prevention” \ncategory, suggesting that the depth of training data relevant to \nspecific topics might influence performance.\nSimilar patterns have been observed in other studies evalu-\nating the performance of language models in medical contexts. \nSamaan et al. studied ChatGPT’s ability to answer cirrhosis-re-\nlated questions in Arabic and found variations in the accuracy \nof responses across different medical topics.14 The study showed \nthat although ChatGPT responded correctly to 72.5% of the \nquestions, its accuracy varied significantly, particularly when \ncomparing responses in Arabic to those in English.14    \nDomain-adapted, fine-tuned medical LLMs have recently \ndemonstrated high-level medical reasoning and improved do-\nmain-specific benchmark performance.23 Considering that the \namount of medical or health information data in Korean is not \nas substantial as in English, parameter-efficient fine-tuning \nmethods could be a practical choice to improve the accuracy of \nLLM responses in the medical field.\nThe findings of this study underscore the potential of LLMs \nas a supportive tool in health communication, capable of pro-\nviding reliable, understandable information to the public. How-\never, ongoing monitoring and evaluation are crucial to ensure \nthat the information provided by LLMs remains accurate and \nup-to-date, fostering trust among users. This is particularly im-\nportant in the medical field, where the accuracy of information \ncan significantly affect health outcomes.\nHealth-related information must be easy to read and under-\nstand, highlighting the importance of readability in LLM-gen-\nerated health content. Although a statistical difference existed \nin the KReaD readability scores for the two LLMs, both systems \nfell within the readability level of Korean middle school grades \nTable 3. Grade Levels for ChatGPT and CLOVA X\nGrade \nlevel*\nChatGPT CLOVA X \nFrequency Proportion Frequency Proportion\nE3-4 - -   1 0.038\nE5-6   7 0.269   3 0.115\nM1-2 11 0.423   9 0.346\nM3-H1   8 0.308 12 0.462\nH2-H3 - -   1 0.038\nE, elementary school; M, middle school; H, high school.\n*Grade level was assessed based on the KReaD score.\n1800\n1600\n1400\n1200\n1500\n1000\n500\n0\nChatGPT General \nknowledge\np=0.036 p=0.745 p=0.444 p=0.319 p=0.081\nCarcinogenesis PreventionCLOVA X Screening\nKReaD\nKReaD\nB\n  ChatGPT   \n   CLOVA X\nA\n6\nLarge Language Models for Korean Questions of Cancer\nhttps://doi.org/10.3349/ymj.2024.0200\n1–2. Additionally, categorical data analysis revealed no signifi-\ncant difference in readability between the two systems. This \nsuggests that both systems are currently at a comparable level \nin presenting information accessible to the intended audience.\nThis study had several limitations. First, the number of ques-\ntions considered in this study was relatively small (26 ques-\ntions), which might limit the generalizability of the findings. \nFurthermore, questions were selected from only two sources, \nwhich may not comprehensively cover the diversity of public \ninquiries regarding cancer. Future research should focus on ex-\npanding the range of questions and include a broader array of \nsources and medical subfields to better understand AI perfor-\nmance across a more diverse set of inquiries.\nLongitudinal studies could explore how AI systems evolve \nwith new data inputs and training iterations. Investigating \nother LLMs and their capabilities in different languages would \nalso contribute valuable insights into the global applicability \nof AI in medical communication.\nIn conclusion, this study suggests that LLMs such as ChatG-\nPT and CLOVA X have the potential to serve as supportive tools \nfor answering cancer-related questions in Korean. However, \ncontinuous improvement and adaptation of these models is \nneeded to better meet the diverse needs of users and to main-\ntain high standards of information quality and reliability.\nDATA AVAILABILITY\nThe datasets generated during the current study are available \nfrom the corresponding author upon reasonable request.\nAUTHOR CONTRIBUTIONS\nConceptualization: Hyun Chang. Data curation: all authors. Formal \nanalysis: all authors. Funding acquisition: Hyun Chang. Investigation: \nall authors. Methodology: all authors. Project administration: Hyun \nChang. Resources: Hyun Chang. Software: Hyun Chang. Supervision: \nHyun Chang. Validation: Hyun Chang. Visualization: Hyun Chang. \nWriting—original draft: Hyun Chang. Writing—review & editing: all \nauthors. Approval of final manuscript: all authors.\nORCID iDs\nHyun Chang https://orcid.org/0000-0002-5203-7513\nJin-Woo Jung https://orcid.org/0009-0009-4765-8436\nYongho Kim https://orcid.org/0000-0003-1722-1937\nREFERENCES\n1. Tian S, Jin Q, Yeganova L, Lai PT , Zhu Q, Chen X, et al. Opportuni-\nties and challenges for ChatGPT and large language models in \nbiomedicine and health. Brief Bioinform 2023;25:bbad493. \n2. Clusmann J, Kolbinger FR, Muti HS, Carrero ZI, Eckardt JN, Laleh \nNG, et al. The future landscape of large language models in medi-\ncine. Commun Med (Lond) 2023;3:141.\n3. Kus¸cu O, Pamuk AE, Sütay Süslü N, Hosal S. Is ChatGPT accurate \nand reliable in answering questions regarding head and neck can-\ncer? Front Oncol 2023;13:1256459. \n4. Goodman RS, Patrinely JR, Stone CA Jr, Zimmerman E, Donald \nRR, Chang SS, et al. Accuracy and reliability of chatbot responses \nto physician questions. JAMA Netw Open 2023;6:e2336483. \n5. Johnson SB, King AJ, Warner EL, Aneja S, Kann BH, Bylund CL. \nUsing ChatGPT to evaluate cancer myths and misconceptions: \nartificial intelligence and cancer information. JNCI Cancer Spectr \n2023;7:pkad015. \n6. Pugliese N, Wai-Sun Wong V , Schattenberg JM, Romero-Gomez M, \nSebastiani G, Castera L, et al. Accuracy, reliability, and compre-\nhensibility of ChatGPT-generated medical responses for patients \nwith nonalcoholic fatty liver disease. Clin Gastroenterol Hepatol \n2024;22:886-9.e5.\n7. Chen S, Kann BH, Foote MB, Aerts HJWL, Savova GK, Mak RH, et \nal. Use of artificial intelligence chatbots for cancer treatment in-\nformation. JAMA Oncol 2023;9:1459-62.\n8. Lim ZW, Pushpanathan K, Yew SME, Lai Y, Sun CH, Lam JSH, et \nal. Benchmarking large language models’ performances for myo-\npia care: a comparative analysis of ChatGPT-3.5, ChatGPT-4.0, and \nGoogle Bard. EBioMedicine 2023;95:104770. \n9. Achiam J, Adler S, Agarwal S, Ahmad L, Akkaya I, Aleman FL, et al. \nGPT-4 technical report. arXiv [Preprint]. 2023 [accessed on 2024 \nJuly 6]. Available at: https://doi.org/10.48550/arXiv.2303.08774.\n10. Brown TB, Mann B, Ryder N, Subbiah M, Kaplan J, Dhariwal P , et \nal. Language models are few-shot learners. arXiv [Preprint]. 2020 \n[accessed on 2024 July 12]. Available at: https://doi.org/10.48550/\narXiv.2005.14165.\n11. Yoo KM, Han J, In S, Jeon H, Jeong J, Kang J, et al. HyperCLOVA X \ntechnical report. arXiv [Preprint]. 2024 [accessed on 2024 July 10]. \nAvailable at: https://doi.org/10.48550/arXiv.2404.01954. \n12. Zhang X, Li S, Hauer B, Shi N, Kondrak G. Don’t trust ChatGPT \nwhen your question is not in English: a study of multilingual abili-\nties and types of LLMs. arXiv [Preprint]. 2023 [accessed on 2024 \nJuly 2]. Available at: https://doi.org/10.48550/arXiv.2305.16339. \n13. Holmström O, Kunz J, Kuhlmann M. Bridging the resource gap: ex-\nploring the efficacy of English and multilingual LLMs for Swedish. \nIn: Ilinykh N, Morger F , Dannélls D, Dobnik S, Megyesi B, Nivre J, \neditors. Proceedings of the second workshop on resources and rep-\nresentations for under-resourced languages and domains (RE-\nSOURCEFUL-2023). Tórshavn: Association for Computational Lin-\nguistics; 2023. p.92-110.\n14. Samaan JS, Yeo YH, Ng WH, Ting PS, Trivedi H, Vipani A, et al. \nChatGPT's ability to comprehend and answer cirrhosis related \nquestions in Arabic. Arab J Gastroenterol 2023;24:145-8.\n15. Shojaee-Mend H, Mohebbati R, Amiri M, Atarodi A. Evaluating \nthe strengths and weaknesses of large language models in an -\nswering neurophysiology questions. Sci Rep 2024;14:10785. \n16. Ye C, Zweck E, Ma Z, Smith J, Katz S. Doctor versus artificial intel-\nligence: patient and physician evaluation of large language model \nresponses to rheumatology patient questions in a cross-sectional \nstudy. Arthritis Rheumatol 2024;76:479-84. \n17. Mangan MS, Cakir A, Yurttaser Ocak S, Tekcan H, Balci S, Ozcelik \nKose A. Analysis of the quality, reliability, and popularity of infor-\nmation on strabismus on YouTube. Strabismus 2020;28:175-80.\n18. Jo Y, Lee C, Choi G, Cheon G. [The reliability of Korean text difficul-\nty analysis program(KReaD)]. Korean J Literacy Res 2020;11:467-\n85. Korean\n19. Wilcoxon F . Individual comparisons by ranking methods. In: Kotz S, \nJohnson NL, editors. Breakthroughs in statistics. New York: Spring-\ner; 1992. p.196-202.\n20. Steeb T , Reinhardt L, Harlaß M, Heppt MV , Meier F , Berking C. \nAssessment of the quality, understandability, and reliability of \nYouTube videos as a source of information on basal cell carcino-\n7\nHyun Chang, et al.\nhttps://doi.org/10.3349/ymj.2024.0200\nma: web-based analysis. JMIR Cancer 2022;8:e29581. \n21. Paasche-Orlow MK, Taylor HA, Brancati FL. Readability stan -\ndards for informed-consent forms as compared with actual read-\nability. N Engl J Med 2003;348:721-6.\n22. Zhou H, Liu F , Gu B, Zou X, Huang J, Wu J, et al. A survey of large \nlanguage models in medicine: progress, application, and chal-\nlenge. arXiv [Preprint]. 2023 [accessed on 2024 July 9]. Available at: \nhttps://doi.org/10.48550/arXiv.2311.05112.\n23. Christophe C, Kanithi PK, Munjal P , Raha T , Hayat N, Rajan R, et al. \nMed42--evaluating fine-tuning strategies for medical LLMs: full-pa-\nrameter vs. parameter-efficient approaches. arXiv [Preprint]. 2024 \n[accessed on 2024 July 10]. Available at: https://doi.org/10.48550/\narXiv.2404.14779.",
  "topic": "Question answering",
  "concepts": [
    {
      "name": "Question answering",
      "score": 0.4923752546310425
    },
    {
      "name": "Natural language processing",
      "score": 0.48905739188194275
    },
    {
      "name": "Computer science",
      "score": 0.48722711205482483
    },
    {
      "name": "Cancer",
      "score": 0.4847411811351776
    },
    {
      "name": "Information retrieval",
      "score": 0.46167680621147156
    },
    {
      "name": "Linguistics",
      "score": 0.3901669979095459
    },
    {
      "name": "Medicine",
      "score": 0.3384302258491516
    },
    {
      "name": "Internal medicine",
      "score": 0.13270550966262817
    },
    {
      "name": "Philosophy",
      "score": 0.0774243175983429
    }
  ]
}