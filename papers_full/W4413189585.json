{
  "title": "How Accurate Is AI? A Critical Evaluation of Commonly Used Large Language Models in Responding to Patient Concerns About Incidental Kidney Tumors",
  "url": "https://openalex.org/W4413189585",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5065039360",
      "name": "Bernhard Ralla",
      "affiliations": [
        "Charité - Universitätsmedizin Berlin",
        "Freie Universität Berlin",
        "Humboldt-Universität zu Berlin"
      ]
    },
    {
      "id": "https://openalex.org/A5075808524",
      "name": "Nadine Biernath",
      "affiliations": [
        "Charité - Universitätsmedizin Berlin",
        "Freie Universität Berlin",
        "Humboldt-Universität zu Berlin"
      ]
    },
    {
      "id": "https://openalex.org/A5058465853",
      "name": "Isabel Lichy",
      "affiliations": [
        "Charité - Universitätsmedizin Berlin",
        "Freie Universität Berlin",
        "Humboldt-Universität zu Berlin"
      ]
    },
    {
      "id": "https://openalex.org/A5044592434",
      "name": "Lukas Kurz",
      "affiliations": [
        "Charité - Universitätsmedizin Berlin",
        "Freie Universität Berlin",
        "Humboldt-Universität zu Berlin"
      ]
    },
    {
      "id": "https://openalex.org/A5068778197",
      "name": "Frank Friedersdorff",
      "affiliations": [
        "Charité - Universitätsmedizin Berlin",
        "Freie Universität Berlin",
        "Humboldt-Universität zu Berlin"
      ]
    },
    {
      "id": "https://openalex.org/A5006752837",
      "name": "Thorsten Schlomm",
      "affiliations": [
        "Charité - Universitätsmedizin Berlin",
        "Freie Universität Berlin",
        "Humboldt-Universität zu Berlin"
      ]
    },
    {
      "id": "https://openalex.org/A5064421681",
      "name": "Jacob Schmidt",
      "affiliations": [
        "Charité - Universitätsmedizin Berlin",
        "Freie Universität Berlin",
        "Humboldt-Universität zu Berlin"
      ]
    },
    {
      "id": "https://openalex.org/A5075445828",
      "name": "Henning Plage",
      "affiliations": [
        "Charité - Universitätsmedizin Berlin",
        "Freie Universität Berlin",
        "Humboldt-Universität zu Berlin"
      ]
    },
    {
      "id": "https://openalex.org/A5109816374",
      "name": "Jonathan Jeutner",
      "affiliations": [
        "Charité - Universitätsmedizin Berlin",
        "Freie Universität Berlin",
        "Humboldt-Universität zu Berlin"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4405765969",
    "https://openalex.org/W4409994853",
    "https://openalex.org/W4412098903",
    "https://openalex.org/W4411019980",
    "https://openalex.org/W4407135263",
    "https://openalex.org/W4403880728",
    "https://openalex.org/W4403158403",
    "https://openalex.org/W4401943355",
    "https://openalex.org/W4409347038",
    "https://openalex.org/W4405332152",
    "https://openalex.org/W4406658975",
    "https://openalex.org/W4392193191",
    "https://openalex.org/W4403420208",
    "https://openalex.org/W4401001163",
    "https://openalex.org/W4408674287",
    "https://openalex.org/W2070405603",
    "https://openalex.org/W2105074581",
    "https://openalex.org/W6777530833",
    "https://openalex.org/W2589738578",
    "https://openalex.org/W2845456171",
    "https://openalex.org/W2104329375",
    "https://openalex.org/W4398142441",
    "https://openalex.org/W4401328392",
    "https://openalex.org/W4323542843",
    "https://openalex.org/W4406247478",
    "https://openalex.org/W4409618482",
    "https://openalex.org/W4405256839",
    "https://openalex.org/W4407757667",
    "https://openalex.org/W4393863981",
    "https://openalex.org/W4405001813",
    "https://openalex.org/W4411900414",
    "https://openalex.org/W4366447635",
    "https://openalex.org/W3024863504"
  ],
  "abstract": "Background: Large language models (LLMs) such as ChatGPT, Google Gemini, and Microsoft Copilot are increasingly used by patients seeking medical information online. While these tools provide accessible and conversational explanations, their accuracy and safety in emotionally sensitive scenarios—such as an incidental cancer diagnosis—remain uncertain. Objective: To evaluate the quality, completeness, readability, and safety of responses generated by three state-of-the-art LLMs to common patient questions following the incidental discovery of a kidney tumor. Methods: A standardized use-case scenario was developed: a patient learns of a suspicious renal mass following a computed tomography (CT) scan for back pain. Ten plain-language prompts reflecting typical patient concerns were submitted to ChatGPT-4o, Microsoft Copilot, and Google Gemini 2.5 Pro without additional context. Responses were independently assessed by five board-certified urologists using a validated six-domain rubric (accuracy, completeness, clarity, currency, risk of harm, hallucinations), scored on a 1–5 Likert scale. Two statistical approaches were applied to calculate descriptive scores and inter-rater reliability (Fleiss’ Kappa). Readability was analyzed using the Flesch Reading Ease (FRE) and Flesch–Kincaid Grade Level (FKGL) metrics. Results: Google Gemini 2.5 Pro achieved the highest mean ratings across most domains, notably in accuracy (4.3), completeness (4.3), and low hallucination rate (4.6). Microsoft Copilot was noted for empathetic language and consistent disclaimers but showed slightly lower clarity and currency scores. ChatGPT-4o demonstrated strengths in conversational flow but displayed more variability in clinical precision. Overall, 14% of responses were flagged as potentially misleading or incomplete. Inter-rater agreement was substantial across all domains (κ = 0.68). Readability varied between models: ChatGPT responses were easiest to understand (FRE = 48.5; FKGL = 11.94), while Gemini’s were the most complex (FRE = 29.9; FKGL = 13.3). Conclusions: LLMs show promise in patient-facing communication but currently fall short of providing consistently accurate, complete, and guideline-conform information in high-stakes contexts such as incidental cancer diagnoses. While their tone and structure may support patient engagement, they should not be used autonomously for counseling. Further fine-tuning, clinical validation, and supervision are essential for safe integration into patient care.",
  "full_text": null,
  "topic": "Readability",
  "concepts": [
    {
      "name": "Readability",
      "score": 0.8399127721786499
    },
    {
      "name": "Medicine",
      "score": 0.6996122598648071
    },
    {
      "name": "CLARITY",
      "score": 0.5222288370132446
    },
    {
      "name": "Plain language",
      "score": 0.51547771692276
    },
    {
      "name": "Inter-rater reliability",
      "score": 0.4698449969291687
    },
    {
      "name": "Context (archaeology)",
      "score": 0.4696604013442993
    },
    {
      "name": "Medical physics",
      "score": 0.399615079164505
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3662470281124115
    },
    {
      "name": "Medical education",
      "score": 0.33316946029663086
    },
    {
      "name": "Natural language processing",
      "score": 0.33203941583633423
    },
    {
      "name": "Computer science",
      "score": 0.22624444961547852
    },
    {
      "name": "Psychology",
      "score": 0.19951915740966797
    },
    {
      "name": "Rating scale",
      "score": 0.18837079405784607
    },
    {
      "name": "Developmental psychology",
      "score": 0.10366559028625488
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Art",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Literature",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    }
  ]
}