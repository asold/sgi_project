{
  "title": "Retrieval augmented generation for 10 large language models and its generalizability in assessing medical fitness",
  "url": "https://openalex.org/W4409157497",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2633798901",
      "name": "Yu He Ke",
      "affiliations": [
        "Singapore General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2326964429",
      "name": "Jin Liyuan",
      "affiliations": [
        "Singapore National Eye Center",
        "Duke-NUS Medical School",
        "SingHealth",
        "Singapore Eye Research Institute"
      ]
    },
    {
      "id": "https://openalex.org/A4384585140",
      "name": "Kabilan Elangovan",
      "affiliations": [
        "SingHealth"
      ]
    },
    {
      "id": "https://openalex.org/A2508072520",
      "name": "Hairil Rizal Abdullah",
      "affiliations": [
        "Singapore General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2065359256",
      "name": "Nan Liu",
      "affiliations": [
        "Duke-NUS Medical School"
      ]
    },
    {
      "id": "https://openalex.org/A2138017839",
      "name": "Alex Tiong Heng Sia",
      "affiliations": [
        "Duke-NUS Medical School",
        "KK Women's and Children's Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2438065910",
      "name": "Chai Rick Soh",
      "affiliations": [
        "Duke-NUS Medical School",
        "Singapore General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2794043957",
      "name": "Joshua Yi Min Tung",
      "affiliations": [
        "Singapore General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A3100970948",
      "name": "Jasmine Chiat Ling Ong",
      "affiliations": [
        "Singapore General Hospital",
        "Duke-NUS Medical School"
      ]
    },
    {
      "id": "https://openalex.org/A4211402138",
      "name": "Chang Fu-Kuo",
      "affiliations": [
        "Chang Gung University",
        "Chang Gung Memorial Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2712125072",
      "name": "Shao-Chun Wu",
      "affiliations": [
        "National Sun Yat-sen University",
        "Kaohsiung Chang Gung Memorial Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A1354848730",
      "name": "Vesela P. Kovacheva",
      "affiliations": [
        "Harvard University",
        "Brigham and Women's Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2619557440",
      "name": "Daniel Shu Wei Ting",
      "affiliations": [
        "Singapore Eye Research Institute",
        "Duke-NUS Medical School",
        "Singapore National Eye Center",
        "SingHealth"
      ]
    },
    {
      "id": "https://openalex.org/A2633798901",
      "name": "Yu He Ke",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2326964429",
      "name": "Jin Liyuan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4384585140",
      "name": "Kabilan Elangovan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2508072520",
      "name": "Hairil Rizal Abdullah",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2065359256",
      "name": "Nan Liu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2138017839",
      "name": "Alex Tiong Heng Sia",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2438065910",
      "name": "Chai Rick Soh",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2794043957",
      "name": "Joshua Yi Min Tung",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3100970948",
      "name": "Jasmine Chiat Ling Ong",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4211402138",
      "name": "Chang Fu-Kuo",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2712125072",
      "name": "Shao-Chun Wu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1354848730",
      "name": "Vesela P. Kovacheva",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2619557440",
      "name": "Daniel Shu Wei Ting",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4384561707",
    "https://openalex.org/W4384700226",
    "https://openalex.org/W4385278400",
    "https://openalex.org/W2400747978",
    "https://openalex.org/W4386482202",
    "https://openalex.org/W3167242683",
    "https://openalex.org/W2058432557",
    "https://openalex.org/W3206834005",
    "https://openalex.org/W3020807179",
    "https://openalex.org/W4367672504",
    "https://openalex.org/W1626788079",
    "https://openalex.org/W4383711355",
    "https://openalex.org/W2140731588",
    "https://openalex.org/W3000603264",
    "https://openalex.org/W4386867830",
    "https://openalex.org/W4404624225",
    "https://openalex.org/W2896334191",
    "https://openalex.org/W1493896010",
    "https://openalex.org/W2979370615",
    "https://openalex.org/W4210551020"
  ],
  "abstract": null,
  "full_text": "npj |digital medicine Article\nPublished in partnership with Seoul National University Bundang Hospital\nhttps://doi.org/10.1038/s41746-025-01519-z\nRetrieval augmented generation for 10\nlarge language models and its\ngeneralizability in assessing medical\nﬁtness\nCheck for updates\nYu He Ke1,2,15,L i y u a nJ i n3,4,5,15, Kabilan Elangovan5, Hairil Rizal Abdullah1,2, Nan Liu3, Alex Tiong Heng Sia3,6,\nChai Rick Soh1,3, Joshua Yi Min Tung2,7, Jasmine Chiat Ling Ong3,8,C h a n g - F uK u o9,10,11, Shao-Chun Wu12,13,\nVesela P. Kovacheva14 &D a n i e lS h uW e iT i n g3,4,5\nLarge Language Models (LLMs) hold promise for medical applications but often lack domain-speciﬁc\nexpertise. Retrieval Augmented Generation (RAG) enables customization by integrating specialized\nknowledge. This study assessed the accuracy, consistency, and safety of LLM-RAG models in\ndetermining surgicalﬁtness and delivering preoperative instructions using 35 local and 23\ninternational guidelines. Ten LLMs (e.g., GPT3.5, GPT4, GPT4o, Gemini, Llama2, and Llama3, Claude)\nwere tested across 14 clinical scenarios. A total of 3234 responses were generated and compared to\n448 human-generated answers. The GPT4 LLM-RAG model with international guidelines generated\nanswers within 20 s and achieved the highest accuracy, which was signiﬁcantly better than human-\ngenerated responses (96.4% vs. 86.6%,p = 0.016). Additionally, the model exhibited an absence of\nhallucinations and produced more consistent output than humans. This study underscores the\npotential of GPT-4-based LLM-RAG models to deliver highly accurate, efﬁcient, and consistent\npreoperative assessments.\nLarge Language Models (LLMs) have gained signiﬁcant attention for their\nclinical applications potential1, and have been demonstrated to match\nhuman performance in basic clinical tasks such as rating a patient’s\nAmerican Society of Anesthesiologists (ASA) physical status2. However,\nwhere complex tasks, such as clinical assessment and management are\ngiven, the response only relies on pre-train knowledge and is not grounded\non institutional practicing guidelines. Most importantly, hallucinations\nfrom LLMs pose signiﬁcant safety and ethical concerns3.\nSurgery cancellations on the day of surgery due to medical unﬁtness4,\nincorrect physician instructions5, and non-compliance to preoperative\ninstructions6 pose a signiﬁcant economic impact7, with operating room\nexpenses estimated between USD 1400 to 1700 per hour8. Thorough\npreoperative evaluations can minimize these cancellations9, but tradi-\ntional preoperative evaluations are inherently labor-intensive and costly.\nThe utilization of domain-speciﬁc LLM for delivering preoperative\ninstructions presents substantial potential for personalized preoperative\nmedicine.\nIn the rapidly evolvingﬁeld of LLMs, the challenge of optimizing\nperformance to meet speciﬁc needs is a key focus. While out-of-the-box\nLLMs offer impressive capabilities, techniques likeﬁne-tuning and RAG\n1Department of Anesthesiology, Singapore General Hospital, Singapore, Singapore.2Data Science and Artiﬁcial Intelligence Lab, Singapore General\nHospital, Singapore, Singapore.3Duke-NUS Medical School, Singapore, Singapore.4Singapore National Eye Centre, Singapore Eye Research Institute,\nSingapore, Singapore.5Singapore Health Services, Artiﬁcial Intelligence Ofﬁce, Singapore, Singapore.6Department of Women’s Anaesthesia, KK Women’s and\nChildren’s Hospital, Singapore, Singapore.7Department of Urology, Singapore General Hospital, Singapore, Singapore.8Division of Pharmacy, Singapore General\nHospital, Singapore, Singapore.9Department of Rheumatology, Allergy, and Immunology, Chang Gung Memorial Hospital, Taipei, Taiwan, ROC.10Center for\nArtiﬁcial Intelligence in Medicine, Chang Gung Memorial Hospital, Taipei, Taiwan, ROC.11School of Medicine, Chang Gung University, Taoyuan, Taipei, Taiwan\nROC. 12Department of Anesthesiology, Kaohsiung Chang Gung Memorial Hospital, College of Medicine, Chang Gung University, Kaohsiung, Taiwan, ROC.\n13School of Medicine, College of Medicine, National Sun Yat-sen University, Kaohsiung, Taiwan, ROC.14Department of Anesthesiology, Perioperative and Pain\nMedicine, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, USA.15These authors contributed equally: Yu He Ke, Liyuan Jin.\ne-mail: daniel.ting45@gmail.com\nnpj Digital Medicine|           (2025) 8:187 1\n1234567890():,;\n1234567890():,;\npresent promising avenues for further enhancing their accuracy and\nrelevance.\nThe primary challenges inﬁne-tuning LLMs stem from various factors\nincluding the need for extensive retraining datasets, particularly for complex\nﬁelds like healthcare; and technical hurdles such as limitations in context\ntokens and the computational demands typically quantiﬁed in petaﬂops for\nGraphics Processing Unit (GPU) memory10.\nRetrieval Augmented Generation (RAG) is an innovative approach for\ntailoring LLMs to speciﬁc tasks, and a scalable solution agnostic to various\nLLM-based healthcare applications. Itoffers an easier solution without the\nneed for extensive training examples or time as required byﬁne-tuning, and\naccessibility to updated customized knowledge without signiﬁcant time in\ncreating up-to-date ground truth and retraining required byﬁne-tuning.\nUnlike traditional LLMs, RAG functions similarly to a search engine,\nretrieving relevant, customized textdata in response to queries. This cap-\nability effectively turns RAG into a tool that integrates specialized knowl-\nedge into LLMs, enhancing their baseline capabilities. In healthcare, for\ninstance, LLMs equipped with RAG and embedded with extensive clinical\nguidelines (LLM-RAG) can yield more accurate outputs\n11. Currently, two\nprimary open-source frameworks for RAG exist - LangChain12 and\nLlamaindex13. Although the retrieval process of RAG can be technically\nchallenging, RAG’s utility in contexts with smaller, more focused knowledge\ncorpora remains signiﬁcant.\nThis study aims to develop and evaluate an LLM-RAG pipeline for\npreoperative medicine using various LLMs and perioperative guidelines.\nThe primary objective is to assess the pipeline’s accuracy in determining\npatients’ﬁtness for surgery. The secondary objective is to evaluate the LLM-\nRAG’s ability to provide accurate, consistent, and safe preoperative\ninstructions, including fasting guidelines, pre-operative medication man-\nagement, and whether the patient should be seen by a nurse or a doctor in\nthe pre-operative clinic.\nResults\nA total of 3682 components were evaluated (448 human-generated and\n3234 LLM-generated). The LLM-RAGmodels took on average 1 s for\nretrieval and 15–20 s for results generation, while the human evaluators took\nan average of 10 min to generate the full preoperative instructions. The\nGenerative Pre-training Transfor mer (GPT)4_international model\nemerged as the most accurate model with the highest accuracy in predicting\nmedical ﬁtness for surgery (96.4%) compared to answers given by human\nevaluators (86.6%), as well as its non-RAG counterpart (92.9%) and\nRAG counterpart with local guidelines (92.9%) (Fig.1 and Supplementary\nTable 2). A detailed example of the prompt, clinical scenario and the GPT4-\ninternational response (response 1) can be found in Table 1.T h e\nGPT4_international model performedb e t t e rt h a nh u m a n si ne v a l u a t i o n so f\npatient’s ﬁtness for surgery (Odds Ratio (OR) = 4.84,p = 0.016).\nThe GPT-4 RAG model, when using local guidelines, accurately pre-\ndicted whether a patient should be seen by a nurse or a doctor 93.0% of the\ntime (Supplementary Table 3). Thisperformance is notably higher com-\npared to its non-RAG counterpart, which achieved an accuracy of 86.0%.\nFurthermore, the GPT4 models also had the highest accuracy when asses-\nsing forﬁtness for operation in sicker, ASA 3 patients. The comparison, the\nGemini and Large Language Model Meta AI (LLAMA)2-13b models had\nless than 50% accuracy when assessing ASA 3 patients (Supplementary\nFig 1).\nThe secondary outcomes show thatthe GPT4_international model\nwas better than humans at generating what medical optimization was\nrequired by the scenario (71.0% vs 55.0%,p = 0.026), but the human-\ngenerated answers were better than the GPT4_international model at\ngeneration of medication instructions order (91.0% vs 98.0%,p = 0.035)\n(Supplementary Table 4 and 5). Overall, there were no signiﬁcant differ-\nences between GPT4_international and human responses in terms of\naccuracy across all secondary outcomes combined (83.0% vs. 81.0%,\np = 0.710), and this was not changed at 65% sensitivity analysis (p = 0.688)\nand 85% sensitivity analysis (p = 0.710) (Supplementary Table 6).\nThe S.C.O.R.E (Safety, Consensus, Objectivity, Reproducibility,\nExplainability) evaluation showed that the GPT4 RAG model was able to\nhave high reproducibility of results (4.86 out of 5) and provided safe\ninstructions (4.93 out of 5) (Supplementary Table 7). The false negative rate,\nwhich reﬂects instances where medically unﬁt patients were incorrectly\nidentiﬁed asﬁt for surgery, was 62.5% among human evaluators compared\nto 25% in the GPT4_international model (Supplementary Table 8).\nFig. 1 | Percentage of Accurately Predicting\nMedical Fitness for Surgery Across Different\nAgents. The ﬁgure illustrates the percentage of\naccurate assessments for medicalﬁtness for surgery\nmade by various LLMs and human evaluators. Each\nbar represents the accuracy of a speciﬁc model or\nhuman-generated response. The overall accuracy of\nGPT4_international models was 93.0%, which was\nsigniﬁcantly higher than human evaluators (86.0%).\nhttps://doi.org/10.1038/s41746-025-01519-z Article\nnpj Digital Medicine|           (2025) 8:187 2\nTable 1 | The LLM-RAG model prompt, an example clinical scenario (scenario 1), the expert panel’s proposed correct answer,\nand various LLM-RAG responses\nPrompt for LLM-RAG model:\nYou are the anesthesiologist seeing this patient in the preoperative clinic 2 weeks before the date of operation. The patients have already taken their routine preoperative\ninvestigations and theﬁndings are listed within the clinical summary.\nYour role is to evaluate the clinical summary and give the preoperative anesthesia instructions for the following patient targeted to your fellow medical colleagues. You are to\nfollow strictly the department’s guidelines.\nYour instructions should consist of the following components:\n1. Should the patient be seen by a Doctor or a Nurse— Doctor/Nurse\n2. Fasting instructions - list instructions based on the number of hours before the time of the listed surgery\n3. Suitability for preoperative carbohydrate loading— yes/no.\n4. Medication instructions— name each medication and give the instructions for the day of the operation and days leading up to the operation as required.\n5. Any instructions for the healthcare team— for example, preoperative blood group matching, arranging for preoperative dialysis, or standby post-operative high\ndependency/ICU beds.\n6. Any preoperative optimization required for the patient— list what needs to be optimized.\n7. Any need to delay the operation for further medical workup and preoperative optimization?\n8. Any speciﬁc department protocols to follow for this patient - name as many as necessary, and give short reasoning for using these protocols.\nYour instructions are theﬁnal instructions, do not give uncertain answers. If the medical condition is already optimized, there is no need to offer further optimization. If there\nare no relevant instructions in any of the above categories, leave it blank and write NA.\nClinical scenario 1\n38/Chinese/Female\nAllergy to aspirin, paracetamol, penicillin - rashes and itchiness\nExSmoker— smoked 10 years ago/Occasional Drinker\nLMP: last month\nWt 94.7 Ht 166.3 BMI 34.2 BP 127/81 HR 88 SpO2 100% on RA\nComing in for BILATERAL REVISION FESS, REVISION SEPTOPLASTY, ADENOIDECTOMY, AND BILATERAL INFERIOR TURBINOPLASTIES/SEVERE OSA ON CPAP\n=== PAST MEDICAL HISTORY===\n1. Severe OSA on CPAP— AHI 58— CPAP settings: AutoCPAP (4–15) cmH2O, without humidiﬁer/Chinstrap\n2. Right persistent Sinusitis\n3. Allergic rhinitis\n4. Adenoid hypertrophy\n5. High BMI\n6. Asthma— f/u GP, last seen 3 months ago for attack— on PRN ventolin— Does not use ventolin at all— No previous admissions/ intubations for asthma\n7. Diabetes— HbA1C 9.4%, Last seen outpatient doctor >1 year ago.\nNo history of HTN/ HLD/ IHD/ CVA\n=== SURGICAL HISTORY===\nTonsillectomy > 10 years ago mild PONV\n===Investigations===\nHb 13.0 TW 4 Plt 392\nINR PT APTT normal\nNa 134 K3.4 Cr 77 Glu 13\nECG NSR\nCXR NAD\n=== MEDICATIONS===\nVentolin PRN\nLMP; Last menstrual period, Wt; Weight\nCorrect Answers:\nFasting instructions: No food by mouth at least 6 h before the operation, and clear water up to 2 h before the operation.\nPreoperative carbohydrate loading: No\nMedication instructions Bring ventolin on the morning of the operation\nInstructions to the healthcare team (Perioperative instructions) 1. List as morning case.\n2. Do a hypocount on the morning of the operation.\n3. Bring CPAP\n4. Book Post operative HD\nPreoperative optimization required 1. Refer to the internal medicine perioperative team (IMPT) for diabetes optimization\nNeed to delay operation Yes — Due to the need to improve diabetes control.\nExample: GPT4_international response\n1. The patient should be seen by a Doctor due to her complex medical history including severe obstructive sleep apnea (OSA) on CPAP, high BMI, asthma, and diabetes.\n2. Fasting instructions: The patient should fast for at least 6 h for solids and 2 h for clearﬂuids before the time of surgery.\n3. The patient is not suitable for preoperative carbohydrate loading due to her diabetes.\n4. Medication instructions:\n- Ventolin: Continue as needed.\n- Diabetes medications: The patient should consult with her endocrinologist for speciﬁc instructions regarding her diabetes medications in the days leading up to the\noperation. On the day of the operation, these medications are typically held.\n- CPAP: The patient should continue using her CPAP machine as prescribed up until the time of surgery.\n5. Instructions for the healthcare team:\n- Arrange for post-operative high dependency/ICU beds due to the patient’s severe OSA.\n- Ensure the availability of the patient’s CPAP machine in the recovery area.\n- Monitor blood glucose levels closely in the perioperative period.\n6. Preoperative optimization:\n- Optimize the patient’s blood glucose levels. Consultation with an endocrinologist may be necessary.\n- Ensure the patient’s asthma is well-controlled.\n7. There is a need to delay the operation for further medical workup and preoperative optimization, particularly for her poorly controlled diabetes.\nhttps://doi.org/10.1038/s41746-025-01519-z Article\nnpj Digital Medicine|           (2025) 8:187 3\nThe Inter-rater reliability (IRR) for human-generated answers was\nconsistently lower than that for GPT-4 International across all categories\n(Supplementary Table 9). The IRR for GPT-4_International in pre-\ndicting medical ﬁtness was 0.93. Additionally, GPT-4_International\ndemonstrated high consistency in providing instructions for healthcare\nworkers (IRR = 0.96) and identifying types of optimization require-\nments (IRR = 0.92).\nThe evaluation revealed low hallucination rates across several LLM\nsystems, including GPT3.5, GPT4, GPT4o, LLAMA3, Gemini, and\nClaude, with hallucination rates ranging from 0% to 2.9%. In contrast,\nLLAMA2 exhibited signiﬁcantly higher hallucination rates (Supple-\nmentary Fig 2). Notably, the RAG-enhanced versions of the LLAMA2-\n7b model demonstrated substantially higher hallucination rates com-\npared to their native counterparts, with rates of 48.6% and 32.9%\nversus 12.8%, respectively (Suppl e m e n t a r yT a b l e4 ) .T h ed i s t i n c t\nn-gram analysis revealed that GPT-3.5, GPT-4, GPT-4-turbo,\nLLAMA3-80b, Gemini, and Claude models achieved high average\ndistinct scores for both 2-gram and 3-gram metrics (Fig. 2), indi-\ncating strong language diversity across these models.\nDiscussion\nThis study highlights the potential of integrating LLM-RAG models into\nhealthcare workﬂows, such as preoperative medicine. Ourﬁndings indicate\nthat the LLM-RAG system can outperform doctors in assessing a patient’s\nﬁtness for surgery and deliver comparably accurate, yet more consistent\nevaluations for other preoperative assessments. These results suggest that\nLLM-RAG models could complement and assist clinicians, improving\nefﬁciency and reducing workload in speciﬁc preoperative tasks.\nTable 1 (continued) | The LLM-RAG model prompt, an example clinical scenario (scenario 1), the expert panel’s proposed\ncorrect answer, and various LLM-RAG responses\nPrompt for LLM-RAG model:\nExample: Llama2-70b_local response (With hallucinations)\n“Doctor/Nurse— Doctor\nFasting instructions— 6 h for solids, 2 h for clearﬂuids\nSuitability for preoperative carbohydrate loading— yes (wrong answer)\nMedication instructions— Ventolin PRN, continue as prescribed\nAny instructions for the healthcare team— None (wrong answer)\nAny preoperative optimization required for the patient— optimization of medical comorbidities, including iron-deﬁciency anemia(The patient does not have iron-deﬁciency\nanemia)\nAny need to delay the operation for further medical workup and preoperative optimization— No (wrong answer)\nThe scenario is retained in its original format to reﬂect the typical style in which medical notes are written\nLMP last menstrual period,Wt weight, Ht height, BMI body mass index,BP blood pressure,HR heart rate,SpO2 peripheral oxygen saturation,RA room air,FESS functional endoscopic sinus surgery,OSA\nObstructive sleep apnea,CPAP continuous positive airway pressure,AHI Apnea–hypopnea index,cmH2O centimeters of water,f/u follow-up, PRN pro re nata (as needed),Ventolin brand name for\nalbuterol, HbA1C Glycated hemoglobin,HTN hypertension, HLD hyperlipidemia, IHD Ischemic heart disease,CVA Cerebrovascular accident,TW Total white blood cell count,Plt platelet count,PT\nProthrombin time,INR International normalized ratio,APTT activated partial thromboplastin time,Na Sodium, K Potassium, Cr Creatinine, Glu Glucose, ECG Electrocardiogram, NSR normal sinus rhythm,\nCXR chest X-ray,NAD no abnormality detected,HD high-dependency.\nFig. 2 | Average Distinct n-gram scores by the different LLM-RAG Models.The\nﬁgure shows the average distinct 1-gram (Yellow line), 2-gram (Orange line), and\n3-gram (Red line) scores for each LLM-RAG model. N-gram scores are a measure of\nlinguistic diversity, with higher scores indicating greater originality and creativity in\nthe generated text. 1-grams represents individual words, 2-grams represents pairs of\nconsecutive words, and 3-grams represents triplets of successive words. The bot\nshows that the Llama3 models have little variations in their linguistic variability.\nhttps://doi.org/10.1038/s41746-025-01519-z Article\nnpj Digital Medicine|           (2025) 8:187 4\nThe emergence ofﬁne-tuned models with Uniﬁed Language Model for\nBiomedical Sciences14 and Biomedical Language Model (BioMedLM)\ndeveloped by the Stanford Center for Research on Foundation Models\n(Stanford-CRFM)15 exempliﬁes the trend toward specialization in LLM\napplications. These domain-speciﬁc models are tailored to understand and\nprocess medical information, offering enhanced accuracy and relevance in\nclinical settings16. The capability of LLM-RAG models to process vast\namounts of data and generate responses based on comprehensive, updated\nguidelines positions them as potentially valuable tools in standardizing\npreoperative assessments.\nThis study also highlights a key advantage of the LLM-RAG— its ability\nto incorporate local healthcare practices and adapt international recom-\nmendations to the speciﬁc context. This is evident in the GPT responses,\nwhere generic referrals to“medicine colleagues” were transformed into the\nspeciﬁc “Optimize diabetes control with the Internal Medicine Perioperative\nTeam (IMPT)” within the local context (Scenario 1, GPT4 response). This\nability to reproduce guidelines tailored to local requirements not only\ndemonstrates the system’s adaptability but also provides speciﬁc, actionable\ninformation that supports potential automation.\nThe results of our study are particularly relevant in the context of the\nevolving landscape of elective surgical services, which have increasingly\nshifted towards day surgery models, reduced hospital stays, and pre-\noperative assessments conducted in outpatient clinics\n17.B ye m p l o y i n ga\nsimple vanilla RAG framework, Langchain, and Pinecone retrieval agent, we\nobserved signiﬁcant improvements and improved clinical alignment for\npre-operation assessment in LLM healthcare applications. For complex\nclinical use cases, such as clinical decision tools for medication-related\nqueries, advanced RAG frameworks such as Llamaindex and improved\nchunking, embedding, and retrieval are expected. The potential role of\nLLM-RAG in this setting as a clinical adjunct is, therefore, of considerable\ninterest because manpower constraints are common within healthcare.\nFurthermore, the inherent subjectivity in clinical decisions, driven by\nvariations in individual judgment and risk tolerance, underscores the value\nof LLM-RAG systems in promoting consistency. For example, GPT models\nhave demonstrated more uniform responses than anesthesiologists in tasks\nsuch as ASA scoring\n2. This consistency offers a critical advantage in peri-\noperative medicine, where standardized evaluations can prevent mis-\ncommunication and reduce conﬂicts among the care team. In our study, the\nlower agreement between human responses and“ground truth” reﬂects\nvariability among eight clinicians, whereas the ground truth was established\nby an expert panel. Differences in guideline familiarity highlight how LLM-\nRAG can offer consistent, guideline-based support and reduce subjective\nvariation. By providing standardized recommendations, LLM-RAG sys-\ntems foster a more cohesive approach to patient care.\nA qualitative analysis of LLM-RAG model responses compared to\nhuman-generated answers revealed potential discrepancies in information\ncompleteness. In Scenario 4, for example, the GPT4 models included spe-\nciﬁc instructions for all the medications (Keppra, Paracetamol, and Tra-\nmadol) on the surgical day. Conversely, the majority of the human\nevaluators did not give instructions for the analgesics. This observed dif-\nference could be attributed to a lack of universally accepted guidelines for\ncontinuing certain medications (e.g., analgesics) on the surgical day. These\nﬁndings suggest that LLM-RAG models,by comprehensively incorporating\navailable information, may be less susceptible to such variability (with\nhigher IRR), potentially leading to more consistent and improved pre-\noperative instructions for current clinical workﬂows.\nA valuable application of this LLM-RAG pipeline is to augment the\npreoperative workﬂow while ensuring safety through a“human-in-the-\nloop” framework. In many pre-op clinics, including ours, patients are\ninitially screened to determine whether they require evaluation by a nurse or\na doctor, or if they should be seen in advance versus on the day of surgery,\nparticularly for low-risk, healthy patients. By safely triaging these decisions,\nthe pipeline has the potential to save signiﬁcant time and reduce costs.\nAdditionally, this approach could support clinicians by drafting patient\ninstructions, which may help alleviate some of the administrative burden\nand reduce clinician burnout. Importantly, the LLM-RAG model would be\ndeployed as a support tool rather than an autonomous decision-maker,\nensuring that a qualiﬁed clinician reviews all recommendations.\nWhile the RAG system demonstrated versatility, we observed that the\ninternational guidelines often led to more accurate outputs compared to\nlocal guidelines. This difference may stem from the fact that international\nguidelines tend to be more comprehensive, with text-based explanations\naccompanying diagrams and tables, facilitating easier extraction and\ninterpretation by the RAG system. In contrast, local guidelines may be less\ndetailed, limiting the model’s ability to fully leverage the information. To\nfurther optimize this application, future improvements could focus on\nenhancing the completeness of local guid e l i n et e x t so rm a n u a l l yc o n v e r t i n g\ndiagrams into text, supporting the seamless integration of LLM-RAG sys-\ntems in diverse clinical environments.\nA key consideration for LLM-RAGmodels is their computational\noverhead, particularly the added latency and resource demands of com-\nbining retrieval with generation. RAG models require embedding, indexing,\nand retrieval steps, which can increase processing time, especially in real-\ntime applications. Scalability is also a challenge, as larger retrieval pools can\nenhance accuracy but require more memory and computational power.\nFuture adaptations, such as dynamic retrieval mechanisms, could help\noptimize retrieval depth based on system load and query complexity,\nimproving efﬁciency across different settings.\nWhile RAG models still require signiﬁcant resources, they offer a more\nsustainable alternative to traditionalﬁne-tuning, reducing the need for\nextensive retraining cycles\n10,18. Solutions like GPT-4 Turbo, with a 128k-\ntoken context, could further decrease resource use by allowing access to\nlarger document sets in a single pass, enhancing overall efﬁciency for real-\nworld applications.\nThe study’s ﬁndings are based on simulated clinical scenarios, which\nmay limit their generalizability to real-world settings. Additionally, varia-\ntions in individual hospital protocolscan lead to different thresholds for\nassessing surgicalﬁtness. Although efforts were made to standardize the\nclinical scenarios following both local and international guidelines to\nminimize ambiguities regardingﬁtness for surgery, these standardizations\nmay not account for all possible variables in actual clinical practice.\nFine-tuning, as another attractive LLM technique, was not explored for\nassessing its performance in patients’ pre-operation assessment in the\ncurrent study. This is mainly attributed to the limitation of training dataset\nnumbers less than traditionally recommended amounts (at least 50 exam-\nples are suggested by OpenAI documentation). Further experimentation on\nﬁnetuning LLMs would be necessary tocompare their performance with the\ncurrent LLM-RAG framework.\nOne of RAG’s notable advantages is its adaptability, allowing it to\nincorporate the latest medical guidelines and best practices— an especially\ncritical feature in the rapidly evolvingﬁeld of perioperative medicine.\nHowever, the model’s performance remains contingent on both the quality\nof retrieved information and ongoing expert oversight. Physicians play a\ncrucial role in monitoring the model’s input and output to identify and\ncorrect any inaccurate or outdated information. It is vital to develop\nadaptive retrieval mechanisms that prioritize up-to-date, high-quality\nsources, and maintain vigilant human supervision to ensure patient safety\nand optimal care.\nThe use of LLM-RAG models also raisesseveral ethical considerations,\nparticularly around the potential for biases to inﬂuence model outputs. Since\nthese models are trained on large datasets and guided by institutional\nprotocols, any inherent biases within the source material can inadvertently\naffect clinical recommendations. For instance, biases related to race, gender,\nsocioeconomic status, or regional healthcare practices could impact the\nmodel’s decision-making process, potentially reinforcing existing healthcare\ndisparities. This is particularly concerning in high-stakes environments\nwhere equitable patient access to care is essential.\nIn this study, the chosen clinical scenarios were structured to yield clear\ndecisions about delaying surgeries for medical optimization. However, real-\nworld clinical situations often involve nuanced decisions, particularly in\nhttps://doi.org/10.1038/s41746-025-01519-z Article\nnpj Digital Medicine|           (2025) 8:187 5\ncritical areas like cancer treatment, where the choice to postpone surgery\nexists in a realm of ethical ambiguity. Users of LLM-RAG models must\nrecognize that in complex ethical landscapes where nuanced recommen-\ndations are needed, the model might lean towards certain decisions inﬂu-\nenced by its training data. These models are best utilized as supportive tools\nthat complement but do not replace, the expert judgment of medical\nprofessionals.\nFuture research on LLM-RAG could address several key areas to\nenhance model performance and adaptability. One promising direction\nis the development of adaptive retrieval mechanisms that dynamically\nprioritize relevant documents based on query speciﬁcity and real-time\nﬁltering, potentially improving r esponse relevance while reducing\ncomputational demands. Additionally, domain-speciﬁc retrieval aug-\nmentation could be explored toﬁne-tune RAG for specialized ﬁelds\nsuch as cardiology or oncology. Future studies could also investigate\noptimal inference parameters to determine the most effective settings\nfor balancing response diversity, accuracy, and relevance across dif-\nferent clinical applications. Moreover, establishing standardized eva-\nluation metrics speciﬁc to healthcare, particularly for assessing factual\naccuracy and contextual relevance, would support rigorous testing and\nmodel comparison, laying the groundwork for broader clinical\ndeployment.\nLLM-RAG models hold signiﬁcant promise for real-world applica-\ntions that demand precise, context-rich information retrieval and\nresponse generation. In healthcare, RAG can streamline workﬂows by\nretrieving up-to-date guidelines for decision support and assisting in\ncomprehensive medical documentation, all while signiﬁcantly reducing\nthe time required to process patient information. For example, at our local\ninstitution, we have implemented a SecureGPT-enabled RAG system in\nour anesthesia clinical practice that supports real-time and secure infor-\nmation retrieval. Notably, this system can process a patient chart in\naround 10 s, thereby enabling faster decision-making, potential cost\nsavings, and increased productivity.\nIn conclusion, this study shows that the LLM-RAG model with GPT-4\ncan achieve high accuracy, consistency, and safety in assessing patientﬁtness\nfor surgery. The model performed as well as, and in some cases better than,\nclinicians in generating detailed instructions for a variety of clinical sce-\nnarios, while keeping hallucination rates low. These results suggest that the\nmodel could be a valuable support tool in healthcare, helping to improve\nconsistency and reduce clinician workload. Its adaptability and scalability\nmake it promising for use in preoperative care and other healthcare\napplications.\nMethods\nThe LLM-RAG pipeline framework is composed of multiple distinct\ncomponents:\nRetrieval augmented generation pipeline\nTo utilize clinical documents effectively within RAG frameworks, they must\nﬁrst be converted into a structured text format. Conventional RAG models,\nsuch as vanilla RAG, often rely on tools like Langchain, which provide\nloaders to extract text while preserving essential metadata for retrieval.\nHowever, this automated process may retrieve extraneous content\n19 and can\nhave difﬁculty interpreting visual elements (like diagrams) or structured\ndata (such as tables). In our study, the clinical documents— particularly the\ninternational perioperative guidelines— already included textual explana-\ntions for key diagrams and tables within the main document. After text\nconversion, the content is segmented into chunks for embedding and\nretrieval. The optimal chunk size for capturing semantic information in\nhealthcare contexts remains a focus of ongoing research.\nIn our study, we utilized an advanced LLM-RAG framework developed\nwith Python 3.11, employing Llamaindex for its streamlined pipeline and\nenhanced retrieval capabilities (see Fig.3). Speciﬁcally, we implemented the\nAuto-Merging Retrieval feature in Llamaindex, which is designed to\nimprove retrieval quality by organizing chunks in a hierarchical, tree-like\nstructure. During retrieval, parent chunks accumulate relevant sub-chunks\nbased on a predeﬁned threshold, creating a merged representation that\nenhances contextualﬂow and continuity.\nTo address computational efﬁciency in our RAG framework, we set the\n“similarity_top_k” parameter (the maximum number of retrievable infor-\nmation pieces) to 30. This threshold was chosen to balance two primary\nobjectives: maximizing the retrieval of essential clinical information while\nminimizing the inclusion of irrelevantcontent that could introduce noise.\nBy limiting the number of retrieved documents, we reduce unnecessary\ncomputational load, which helps tocontrol resource consumption and\nlatency. Additionally, this conﬁguration aligns with the requirements of\nlong-context LLMs, allowing them to access an optimal amount of infor-\nmation without compromising the logicalﬂow in complex clinical scenar-\nios. This approach effectively reduces computational overhead, supporting\ncost-effectiveness and efﬁciency, especially for real-time healthcare appli-\ncations where quick response times are critical.\nPrompt engineering\nPrompt engineering followed the guidance by Bertalan et al.20. Key princi-\nples we emphasized included speciﬁcity, contextualization, and open-\nFig. 3 | Architecture for the RAG model and how it\ndiffers from a simple LLM-based search model.\nThis ﬁgure illustrates the architecture of a RAG\nmodel. Unlike traditional LLM-based search mod-\nels, RAG models incorporate a retrieval module that\nsearches a pre-indexed database of domain-speciﬁc\nknowledge. This enables the model to access and\nutilize external information, such as medical\nguidelines or research papers, to generate more\naccurate and informative responses. The retrieved\ninformation is then fed into a language model to\nproduce aﬁnal response that is grounded in factual\nknowledge. This approach signiﬁcantly reduces the\nrisk of generating hallucinations or misleading\ninformation, making RAG models particularly well-\nsuited for tasks that require accurate and reliable\ninformation.\nhttps://doi.org/10.1038/s41746-025-01519-z Article\nnpj Digital Medicine|           (2025) 8:187 6\nendedness to elicit comprehensive responses from the LLM. In this context,\n“role-playing” refers to structuring prompts so that the LLM assumes the\nperspective of a speciﬁc clinical role, such as a preoperative clinician, to\ngenerate responses that align with that professional viewpoint. Our\napproach involved an iterative process of prompt reﬁnement and sample\nresponse generation, continuing untilwe achieved satisfactory output from\nthe LLM.\nL a r g el a n g u a g em o d e la n dr e s p o n s eg e n e r a t i o n\nA list of pre-trained foundational LLMs is selected for this case study,\nincluding Generative Pre-trained Transformer (GPT) 3.5\n21, GPT 422,\nGPT4o23, Large Language Model Meta AI (LLaMA) 2-7B24, LLAMA2-\n13B24, LLAMA2-70B25, LLAMA3-8B26, LLAMA3-70B27, Gemini-1.5-Pro28,\nand Claude-3-Opus29. Current LLM selections were based on evaluating the\nbest-performing cloud-based models, including the GPT family and\nGemini, as well as the top-performing local models, such as the LLaMA\nfamily and Claude. Cloud-based LLMs offer the advantages ofﬂexible\nscaling and continuous updates but also depend on the ongoing viability of\nthe external provider. By contrast, local LLMs necessitate substantial insti-\ntutional investments in hardware andenergy consumption, while granting\nenhanced data privacy and more direct control over system performance.\nBoth approaches are important considerations for future LLM integration\ninto clinical workﬂows. Detailed characteristics of these LLMs are provided\nin Table2. In each scenario, the same knowledge corpus extracted from\nclinical guidelines was used as user prompts, and clinical questions were\ninput as system prompts for consistency across all models. The complete\ncodebase used in this study is publicly available on GitHub:https://github.\ncom/Liyuan1Y/RAG-LLM-Demo.\nTo ensure consistency in responses generated by the various LLMs, we\nstandardized key inference parameters. The“temperature” was set to 0.1 to\nreduce randomness and make outputs more deterministic, enhancing\nconsistency. The“maximum output token length” was ﬁxed at 2048 to limit\nresponse length and prevent overly lengthy outputs. The“Top-P value” was\nset at 0.90, enabling the model to sample from the smallest group of words\nwhose cumulative probability exceeds this threshold, balancing response\ncreativity and relevance. This conﬁguration aimed to minimize hallucina-\ntions and produce responses that wereboth meaningful and reproducible.\nWe utilized the cloud-based OpenAIplayground platform to conduct our\nexperiments.\nInference for LLaMA models was performed on the Google Cloud\nPlatform (GCP™) using two NVIDIA® A100 (80GB) GPUs through Vertex\nAI™. We obtained the models from Meta’so fﬁcial Hugging Face® repository\nfor LLM-RAG inferences. However, for LLaMA2 models, we reﬁned the\nprocess by selecting the top 10 relevant information pieces to feed into the\nLLM for inference. Additionally, the maximum tokens generated were\nr e d u c e dt o1 , 0 2 4d u et oL L a M A 2’s 4k context length limitation.\nFor the Gemini-1.5-Pro responses, we employed GCP Vertex AI’s\nlanguage generation playground. On the other hand, the Claude-3 Opus\nmodel was implemented via GCP’s notebooks and through API calls.\nDetailed in Fig.4 is the operational framework of the LLM-RAG model,\nproviding a schematic representation of the interplay of the algorithmic\nworkﬂow integral to the system’sf u n c t i o n a l i t y .\nNomenclature of LLM systems\nThree distinct answer sets were generated for this study using the GPT-4\nmodel. Theﬁrst, denoted as“GPT-4,” utilized the base language model\nwithout additional context. The second,“GPT-4-local,” was the LLM-RAG\nsystem using the GPT-4 base model with a knowledge base derived from 35\nlocal preoperative guidelines. The third,“GPT-4_international,” utilized a\nk n o w l e d g eb a s ed e r i v e df r o m2 3i n t e r n ational preoperative guidelines.\nSimilar conﬁgurations were also generated using other LLMs in this study.\nEvaluation of LLM with the S.C.O.R.E. evaluation framework\nIn this study, we are employing a novel qualitative evaluation framework\nS.C.O.R.E30. It provides a nuanced analysis of medical context based LLM\nTable 2 | Comparison of the different large language models used in the study\nModel Training Corpus Model Size Data Size Other Key Features\nGPT3.5 Internet text (up to 2021) 175 billion parameters 45 terabyte (TB) of text Advanced text generation and understanding\nGPT4 Diverse internet sources (up to 2022) Larger than 175 billion\nparameters\nEstimated to be larger\nthan 45 TB\nEnhanced text generation, understanding, and multimodal capabilities\nGPT4-o Varied (details not publicly disclosed) Not publicly disclosed Not publicly disclosed Reason across audio, vision, and text in real-time as a single model\nLLAMA2-7B Varied (details not publicly disclosed) 7 billion parameters Not publicly disclosed Focused on speci ﬁc tasks and domains\nLLAMA2-13B Varied (details not publicly disclosed) 13 billion parameters Not publicly disclosed Focused on speci ﬁc tasks and domains with a larger capacity\nLLAMA2-70B Varied (details not publicly disclosed) 70 billion parameters Not publicly disclosed Focused on speci ﬁc tasks and domains with a larger capacity\nLLAMA3-8B All tokens are collected from publicly available sources. Training dataset\nincludes four times more code than what was used in Llama 2.\n8 billion parameters 15 Trillion Tokens of pre-\ntraining data\nMultilingual Capability (training data includes over 5% non-English\ncontent, covering more than 30 languages)\nLLAMA3-70B All tokens are collected from publicly available sources. Training dataset\nincludes four times more code than what was used in Llama 2.\n70 billion parameters 15 Trillion Tokens of pre-\ntraining data\nMultilingual Capability (training data includes over 5% non-English\ncontent, covering more than 30 languages)\nGemini-\n1.5-ProK1\nData is sourced from multiple domains, including web documents and code\nrepositories, ensuring a broad coverage of knowledge and language\nuse cases.\nNot publicly disclosed Not publicly disclosed Multimodal Capabilities, Extended Context Length: Capable of recalling\nand reasoning over up to 10 million tokens across multiple modalities.\nClaude-3-Opus Web-Documents, Books, Scienti ﬁc Papers, Code Repositories. Not publicly disclosed Not publicly disclosed Advanced Language Understanding, Extensive Multimodal Capabilities,\nLong-Context Handling\nhttps://doi.org/10.1038/s41746-025-01519-z Article\nnpj Digital Medicine|           (2025) 8:187 7\nresponses, addressing several limitations in existing quantitative and qua-\nlitative methodologies. This framework offers unique assessments that align\nwith our research objectives in qualitatively assessing LLM responses based\non its safety, clinical consensus, objectivity, reproducibility, explainability\nwhich are essential for our study toclinically validate our LLM-RAG\npipeline. Initial assessments indicaterobust performance, promising sig-\nniﬁcant contributions upon release. Additionally, a distinct n-gram analysis\nwas conducted to assess language diversity.\nTo assess the reproducibility and reliability of the LLM framework, we\nconducted a primary analysis to identify the best-performing system for the\nprimary outcome. The GPT-4 international model emerged as the top\nperformer (accuracy rate of 93%). Subsequently, the GPT-4 international\nLLM-RAG system underwent four additional iterative evaluations to further\ntest its robustness.\nThe performance of the GPT4-international LLM-RAG system in\ngenerating preoperative instructionswas evaluated by two attending anes-\nthesiologists (more than 5 years and 15 years of anesthesiology\nexperiences, respectively) using the S.C.O.R.E. Evaluation Framework fra-\nmework (Table2). Each scenario was scored based on the 4x repeats gen-\nerated. The average score was taken and represented. This assessment\nencompassed (1) safety, ensuring non-hallucinated responses with no\nmisleading information; (2) consensus, gauging agreement with existing\nmedical literature; (3) objectivity, verifying the absence of bias or personal\nopinions; (4) reproducibility, conﬁrming consistent performance across\nmultiple iterations; and (5) explainability, evaluating the clarity and ratio-\nnale behind generated instructions. In addition, a Distinct n-gram analysis\nwas conducted to evaluate the linguisticdiversity of the generated responses.\nEvaluation framework\nThis study utilized two distinct sets of preoperative guidelines, reﬂecting\nboth local and international perspectives. Theﬁrst comprised 35 local\nprotocols from a major tertiary hospital in Singapore, adapted from\nestablished international perioperative standards; these protocols represent\nthe full set of anesthesia guidelines currently in use at our institution. The\nsecond set consisted of 23 internationally recognized guidelines from var-\nious anesthesia societies (e.g., the American Society of Anesthesiologists,\nEuropean Society of Anaesthesiology, and relevant specialty organizations)\nand UpToDate articles (Supplementary Table 1). UpToDate was included\nfor its high-quality, consensus-based recommendations grounded in cur-\nrent evidence and its ability to synthesize information when guidelines differ\namong societies. All guidelines— complete with diagrams andﬁgures— were\nextracted in their native PDF format and loaded into separate LLM-RAG\nsystems. This selection process provides a comprehensive framework cov-\nering patient assessment, medication management, and speciﬁcs u r g i c a l\nprocedures, ensuring relevance across both local and global contexts.\nClinical scenarios\nThis study assessed the performance of the LLM-RAG system on 14 de-\nidentiﬁed clinical scenarios, carefully selected to represent a range of ASA\nclassiﬁcations (ASA 1–3), medical conditions, and surgical complexities\n(Table 3). The scenarios were formatted to reﬂect real preoperative clinic\nnotes, retaining clinical acronyms commonly used in practice, such as DM\nfor diabetes mellitus and HTN for hypertension. Each scenario was fully de-\nidentiﬁed, with modiﬁcations to age, sex, and past medical history, as well as\nadjustments to surgical dates and types of procedures. Due to the anon-\nymized nature of the data and the minimal risk associated with this study,\nethics approval was not required (Reviewed by Singapore General Hospital\nResearch and Innovation Ofﬁce).\nSix key aspects of preoperative instructions were assessed, with the\nprimary outcome being the assessment of the patient’s ﬁtness for surgery.\nThis was complemented byﬁve additional parameters: (1) fasting guide-\nlines, (2) suitability for preoperative carbohydrate loading, (3) medication\ninstructions, (4) instructions to healthcare workers (perioperative instruc-\ntions), and (5) types of preoperative optimizations required. These aspects\nwere selected due to their established signiﬁcance in the current medical\nliterature and their potential impact on surgical outcomes\n31.\nOutput\nFour junior doctors (1–7 years of anesthesia experience) and four attending\nanesthesiologists (1 from SingaporeGeneral Hospital, Singapore, 1 from\nHarvard Medical School, United states, 2 from Chang Gung Memorial\nHospital, Taiwan) independently responded to the primary outcome\nFig. 4 | Operational framework of the LLM-RAG model incorporating local and\ninternational preoperative guidelines.This ﬁgure illustrates the operational fra-\nmework of the LLM-RAG model, which leverages both local and international\npreoperative guidelines to provide accurate and reliable medical advice. The model\nﬁrst processes a user query to extract relevant keywords and semantic information. It\nthen searches a pre-indexed database containing local and international guidelines\nto identify relevant information. The retrieved information is analyzed to under-\nstand the context of the query, and a language model is used to generate a com-\nprehensive response.\nhttps://doi.org/10.1038/s41746-025-01519-z Article\nnpj Digital Medicine|           (2025) 8:187 8\nassessment as human evaluators. This selection reﬂects the typical global\npractice in which preoperative assessments are often conducted by junior\ndoctors or anesthetic nurses\n32, while senior consultants provide theﬁnal,\nindividualized clinical decisions. Additionally, the junior doctors provided\nresponses for parameters related to secondary outcomes. To maintain the\nintegrity of the study and ensure unbiased responses, the participants were\nblinded to the study’s objectives. The human-generated answers were then\ncollated and aggregated for comparison with the LLM-generated answers.\nThe ‘correct’ answers in the study were based on established pre-\noperative guidelines and reviewed by an expert panel made up of two board-\ncertiﬁed perioperative anesthesiologists. Where there were disagreements,\ndiscussions were made between the two panelists to come to aﬁnal decision.\nIn ambiguous cases, like the suspension of ACE inhibitors before surgery,\nboth potential answers were considered correct\n33.T h i sw a st or eﬂect the real-\nworld complexities of preoperative decision-making, especially where evi-\ndence for one choice over another was scarce. The study focused on sce-\nnarios with clear directives regarding the postponement of operations for\nadditional optimizations.\nFor the secondary objectives, which involved preoperative\ninstructions with multiple components, a response was deemed“cor-\nrect” if it aligned with at least 75% of the guidelines. This threshold\nacknowledges the inherent subjectivity in preoperative instructions,\nwhere the clinical signiﬁcance of omissions can vary. For example,\nomitting a recommendation for continuous positive airway pressure\n(CPAP) use in a high-risk sleep apnea patient could be critical, whereas\nomitting a preference for morning surgery in a non-critical case might be\nless consequential (Supplementary, Scenario 1). Given the absence of\nestablished accuracy thresholds in this context, we conducted a sensi-\ntivity analysis by evaluating performance at both 65% and 85% accuracy\ncutoffs.\nOnly the LLMs were evaluated to determine whether a patient should\nbe seen by a nurse anesthetist or a doctor. The assessment criteria were based\non Singapore’sl o c a lg u i d e l i n e s ,w h i c hs t a t et h a tA S AIo rI Ip a t i e n t so v e r2 1\nyears old, not undergoing high-risk surgery or facing a high risk of com-\nplications, and without any abnormal investigation results, can be evaluated\nby a nurse anesthetist. These guidelines are more conservative than those in\nother countries due to the heavily doctor-led nature of Singapore’sh e a l t h -\ncare system, and they account for variations in thresholds across different\ninstitutions.\nWe assessed the LLM-RAG systems’ responses for accuracy, con-\nsistency, and safety. The comparison between the LLM-RAG responses and\nthe correct answers was conducted manually, allowing minor differences in\nwording as long as the clinical meaning remained consistent. We prioritized\nthe intent and medical implications of each recommendation over exact\nphrasing, ensuring a fair and meaningful assessment. To further safeguard\npatient welfare, any response containing a critical medical error (e.g.,\nincorrect fasting instructions ormedication dosages) was classiﬁed as a\n“Hallucination” and automatically deemed incorrect, regardless of whether\nother aspects of the response were accurate.\nA comparative analysis is pe rformed against the human-\ngenerated responses and the best-performing LLM-RAG model\nusing Fisher’s exact test. Consistency within the human and LLM\nanswers were analyzed using percentage agreement for interrater\nreliability (IRR). All statistical evaluations are performed in the\nPython 3.6 environment.\nThe study is not funded. All the authors had full access to the study\ndata. The full raw data is available within the appendix and upon request.\nThe manuscript was reviewed by all the other authors. YHK and DSWT\nwere responsible for the decision to submit the manuscript for publication.\nResearch in context\nEvidence before this study: Prior research suggests the potential of LLM-\nRAG models for generating context-speciﬁc information. However, their\napplication, adaptability to both regional and international guidelines, and\nevaluation within realistic, simulated clinical scenarios in healthcare still\nneed to be improved.\nAdded value of this study\nWe developed and evaluated 10 LLM-RAG models speciﬁcally tailored to\nthe preoperative setting using 35 local perioperative guidelines and 23\ninternational guidelines. The GPT4 LLM-RAG model with international\nguidelines demonstrated the best accuracy and consistency, and outper-\nforms anesthesiologists in assessing surgicalﬁtness, providing safe responses\nwith a low hallucination rate.\nImplications of all the available evidence\nOur ﬁndings, combined with existing research, underscore the advantages\nof grounded knowledge, agnostic to various healthcare domains,\nTable 3 | Summary of the 14 de-identiﬁed clinical scenarios\nNo. Age Gender ASA BMI Notable Medical History Planned Procedure\n1 38 Female 2 34.2 Severe Obstructive Sleep Apnea on CPAP, Obese, Asthma, Diabetes Bilateral Revision FESS, Septoplasty,\nAdenoidectomy, Turbinoplasties\n2 24 Male 2 26.9 Previously referred for abnormal electrocardiography, otherwise healthy ACL Reconstruction\n3 70 Male 1 30.0 Osteoarthritis of knees Right Total Knee Replacement\n4 78 Female 2 18.0 Epilepsy (well-controlled), Renal Calculus, Cervical Spondylosis Hysterectomy\n5 16 Female 1 19.6 Social smoker, previously repaired ring ﬁnger tendon injury Left Ring Finger Exploration, Possible Tendon Rod\nInsertion\n6 53 Male 2 21.0 Stage 3C Hepatic Flexure Adenocarcinoma, Ischemic Heart Disease,\nHyperlipidemia\nRight Hemicolectomy\n7 73 Male 3 24.7 Severe Pulmonary Hypertension, End Stage Kidney Failure on Dialysis,\nStroke\nLeft Lower Limb Angioplasty\n8 80 Male 3 19.9 Hypertension, Chronic Kidney Disease, Colonic Adenocarcinoma Resection of Colonic Adenocarcinoma\n9 50 Female 2 22.9 Hypertension, Childhood Asthma, Thyroidectomy Laparoscopic Cholecystectomy\n10 71 Male 2 27.0 Benign Prostate Hyperplasia, Hypertension, Hyperlipidemia MRI Targeted Prostate Biopsy\n11 63 Male 2 33.7 Obstructive Sleep Apnea, Chronic Kidney Disease, Obesity Right Carpal and Cubital Tunnel Surgery\n12 77 Male 3 19.2 Chronic obstructive pulmonary disease (GOLD E), Benign Prostate\nHyperplasia, Chronic Smoker\nTotal Knee Replacement\n13 71 Male 3 26.0 Ischemic Heart Disease, Hypertension, Diabetes Mellitus MRI-guided Prostate Biopsy\n14 44 Male 2 24.2 Asthma, History of Chest Wall Dermato ﬁbrosarcoma Functional Endoscopic Sinus Surgery\nhttps://doi.org/10.1038/s41746-025-01519-z Article\nnpj Digital Medicine|           (2025) 8:187 9\nupgradability, and scalability as essential factors for successfully deploying\nefﬁcient RAG-enhanced LLMs in healthcare settings. This study provides\nstrong support for considering these models as potential assistive compa-\nnions inﬁelds like perioperative medicine.\nData availability\nData is provided within the manuscript or supplementary informationﬁles.\nCode availability\nThe complete codebase used in this study is publicly available on GitHub:\nhttps://github.com/Liyuan1Y/RAG-LLM-Demo.\nReceived: 10 September 2024; Accepted: 16 February 2025;\nReferences\n1. Thirunavukarasu, A. J. et al. Large language models in medicine.Nat.\nMed. 29, 1930–1940 (2023).\n2. Lim, D. Y. Z. et al. Large language models in anaesthesiology: use of\nChatGPT for American Society of Anesthesiologists physical status\nclassiﬁcation. Br. J. Anaesth. https://doi.org/10.1016/j.bja.2023.06.\n052 (2023).\n3. Lee, S.-W. & Choi, W.-J. Utilizing ChatGPT in clinical research related\nto anesthesiology: a comprehensive review of opportunities and\nlimitations. Anesth. Pain. Med.18, 244–251 (2023).\n4. Garg, R., Bhalotra, A. R., Bhadoria, P., Gupta, N. & Anand, R. Reasons\nfor cancellation of cases on the day of surgery-a prospective study.\nIndian J. Anaesth.53,3 5–39 (2009).\n5. Pfeifer, K., Slawski, B., Manley, A. -M., Nelson, V. & Haines, M.\nImproving preoperative medication compliance with standardized\ninstructions. Minerva Anestesiol.82,4 4–49 (2016).\n6. Naderi-Boldaji, V. et al. Incidence and root causes of surgery\ncancellations at an academic medical center in Iran: a retrospective\ncohort study on 29,978 elective surgical cases.Patient Saf. Surg.17,\n24 (2023).\n7. Koushan, M., Wood, L. C. & Greatbanks, R. Evaluating factors\nassociated with the cancellation and delay of elective surgical\nprocedures: a systematic review.Int. J. Qual. Health Care33,\nmzab092 (2021).\n8. Haana, V., Sethuraman, K., Stephens, L., Rosen, H. & Meara, J. G.\nCase cancellations on the day of surgery: an investigation in an\nAustralian paediatric hospital.ANZ J. Surg.79, 636–640 (2009).\n9. Liu, S. et al. Preoperative assessment clinics and case cancellations: a\nprospective study from a large medical center in China.Ann. Transl.\nMed. 9, 1501 (2021).\n10. Nishant, R., Kennedy, M. & Corbett, J. Artiﬁcial intelligence for\nsustainability: challenges, opportunities, and a research agenda.Int.\nJ. Inf. Manag.53, 102104 (2020).\n11. Zakka, C. et al. Almanac: retrieval-augmented language models for\nclinical medicine.Res. Sq.https://doi.org/10.21203/rs.3.rs-2883198/v1\n(2023).\n12. LangChain. https://www.langchain.com/.\n13. LlamaIndex — data framework for LLM applications.https://www.\nllamaindex.ai/.\n14. Yang, R. et al. Integrating UMLS Knowledge into Large Language\nModels for Medical Question Answering.arXiv [cs.CL](2023).\n15. stanford-crfm/BioMedLM · Hugging Face.https://huggingface.co/\nstanford-crfm/BioMedLM.\n16. Pal, S., Bhattacharya, M., Lee, S. -S. & Chakraborty, C. A domain-\nspeciﬁc next-generation large language model (LLM) or ChatGPT is\nrequired for biomedical engineering and research.Ann. Biomed. Eng.\nhttps://doi.org/10.1007/s10439-023-03306-x (2023).\n17. Nicholson, A., Coldwell, C. H., Lewis, S.R. & Smith, A. F. Nurse-led\nversus doctor-led preoperative assessment for elective surgical\npatients requiring regional or general anaesthesia.Cochrane\nDatabase Syst. Rev.https://doi.org/10.1002/14651858.CD010160.\npub2 (2013).\n18. Vinuesa, R. et al. The role of artiﬁcial intelligence in achieving the\nSustainable Development Goals.Nat. Commun.11, 233 (2020).\n19. Hinton, G., Vinyals, O. & Dean, J. Distilling the knowledge in a neural\nnetwork. arXiv [stat.ML](2015).\n20. Meskó, B. Prompt engineering as an important emerging skill for\nmedical professionals: tutorial.J. Med. Internet Res.25, e50638\n(2023).\n21. GPT-3.5 Turbo ﬁne-tuning and API updates.https://openai.com/\nblog/gpt-3-5-turbo-ﬁne-tuning-and-api-updates.\n22. GPT-4. https://openai.com/research/gpt-4.\n23. Hello GPT-4o. https://openai.com/index/hello-gpt-4o/.\n24. Introducing LLaMA: a foundational, 65-billion-parameter language\nmodel.https://ai.meta.com/blog/large-language-model-llama-meta-ai/.\n25. Meta-llama/llama-2-70b-chat-hf · hugging face.https://huggingface.\nco/meta-llama/Llama-2-70b-chat-hf.\n26. meta-llama/Meta-Llama-3-8B · Hugging Face.https://huggingface.\nco/meta-llama/Meta-Llama-3-8B.\n27. meta-llama/Meta-Llama-3-70B · Hugging Face.https://huggingface.\nco/meta-llama/Meta-Llama-3-70B.\n28. Gemini Team et al. Gemini 1.5: Unlocking multimodal understanding\nacross millions of tokens of context.arXiv [cs.CL](2024).\n29. Claude. https://claude.ai/.\n30. Tan, T. F. et al. A proposed S.c.o.r.e. evaluation framework for large\nlanguage models : Safety, Consensus, Objectivity, Reproducibility\nand Explainability.arXiv [cs.CL](2024).\n31. Gagné, S. & McIsaac, D. I. Modiﬁable risk factors for patients\nundergoing lung cancer surgery and their optimization: a review.J.\nThorac. Dis.10, S3761–S3772 (2018).\n32. Malley, A., Kenner, C., Kim, T. & Blakeney, B. The role of the nurse and\nthe preoperative assessment in patient transitions.AORN J.102,\n181.e1–9 (2015).\n33. Cohn, S. L., Grant, P. J. & Slawski, B. 2019 Update in perioperative\ncardiovascular medicine.Cleve. Clin. J. Med.86, 677–683 (2019).\nAcknowledgements\nThe authors sincerely thank Dr. Leong Yun Hao, Dr. Victoria Tay, Dr. Jasper\nGoh, and Dr. Taylor Lim from Singapore General Hospital for their invaluable\ncontributions as human evaluators in this study. Their dedication and\ninsightful input enriched the research. We also acknowledge the\npreoperative clinical guidelines provided by the hospital, which were pivotal\nin the successful execution of this project. The project is not funding by any\nfunding agency in the public, commercial, or not-for-proﬁts e c t o r s .\nAuthor contributions\nConceptualization and guidance: Y.H. Ke, H.R. Abdullah, D.S.W. Ting.\nGrading models: H.R. Abdullah, Y.H. Ke, V.P. Kovacheva, C.F. Kuo, S.C. Wu.\nCoding and technical development: L. Jin, K. Elangovan. Data analysis: Y.H.\nKe, L. Jin, J.Y.M. Tung, J.C.L. Ong, A.T.H. Sia, C.R. Soh, N. Liu. Manuscript\npreparation and proof-reading: All authors.\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nSupplementary informationThe online version contains\nsupplementary material available at\nhttps://doi.org/10.1038/s41746-025-01519-z\n.\nCorrespondenceand requests for materials should be addressed to\nDaniel Shu Wei Ting.\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nhttps://doi.org/10.1038/s41746-025-01519-z Article\nnpj Digital Medicine|           (2025) 8:187 10\nPublisher’s noteSpringer Nature remains neutral with regard to\njurisdictional claims in published maps and institutional afﬁliations.\nOpen AccessThis article is licensed under a Creative Commons\nAttribution-NonCommercial-NoDerivatives 4.0 International License,\nwhich permits any non-commercial use, sharing, distribution and\nreproduction in any medium or format, as long as you give appropriate\ncredit to the original author(s) and the source, provide a link to the Creative\nCommons licence, and indicate if you modiﬁed the licensed material. You\ndo not have permission under this licence to share adapted material\nderived from this article or parts of it. The images or other third party\nmaterial in this article are included in the article’s Creative Commons\nlicence, unless indicated otherwise in a credit line to the material. If material\nis not included in the article’s Creative Commons licence and your intended\nuse is not permitted by statutory regulation or exceeds the permitted use,\nyou will need to obtain permission directly from the copyright holder. To\nview a copy of this licence, visithttp://creativecommons.org/licenses/by-\nnc-nd/4.0/\n.\n© The Author(s) 2025\nhttps://doi.org/10.1038/s41746-025-01519-z Article\nnpj Digital Medicine|           (2025) 8:187 11",
  "topic": "Generalizability theory",
  "concepts": [
    {
      "name": "Generalizability theory",
      "score": 0.9237943887710571
    },
    {
      "name": "Computer science",
      "score": 0.5058898329734802
    },
    {
      "name": "Natural language processing",
      "score": 0.4055471420288086
    },
    {
      "name": "Psychology",
      "score": 0.3905639052391052
    },
    {
      "name": "Artificial intelligence",
      "score": 0.35352563858032227
    },
    {
      "name": "Information retrieval",
      "score": 0.32846906781196594
    },
    {
      "name": "Developmental psychology",
      "score": 0.07453396916389465
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I2251586001",
      "name": "Singapore General Hospital",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I4210126319",
      "name": "Duke-NUS Medical School",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I157582758",
      "name": "SingHealth",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I4210116917",
      "name": "Singapore Eye Research Institute",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I2799299286",
      "name": "Singapore National Eye Center",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I4210112252",
      "name": "KK Women's and Children's Hospital",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I3020100970",
      "name": "Chang Gung Memorial Hospital",
      "country": "TW"
    },
    {
      "id": "https://openalex.org/I173093425",
      "name": "Chang Gung University",
      "country": "TW"
    },
    {
      "id": "https://openalex.org/I4210093821",
      "name": "Kaohsiung Chang Gung Memorial Hospital",
      "country": "TW"
    },
    {
      "id": "https://openalex.org/I142974352",
      "name": "National Sun Yat-sen University",
      "country": "TW"
    },
    {
      "id": "https://openalex.org/I1283280774",
      "name": "Brigham and Women's Hospital",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I136199984",
      "name": "Harvard University",
      "country": "US"
    }
  ],
  "cited_by": 38
}