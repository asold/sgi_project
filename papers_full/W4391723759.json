{
  "title": "Artificial Intelligence to Automate Network Meta-Analyses: Four Case Studies to Evaluate the Potential Application of Large Language Models",
  "url": "https://openalex.org/W4391723759",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2486523368",
      "name": "Tim Reason",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2118564877",
      "name": "Emma Benbow",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2046090370",
      "name": "Julia Langham",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1986744770",
      "name": "Andy Gimblett",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4291130909",
      "name": "Sven L Klijn",
      "affiliations": [
        "Bristol-Myers Squibb (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2138684868",
      "name": "Bill Malcolm",
      "affiliations": [
        "Bristol-Myers Squibb (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A2486523368",
      "name": "Tim Reason",
      "affiliations": [
        "European Framework Program Consulting (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A2118564877",
      "name": "Emma Benbow",
      "affiliations": [
        "European Framework Program Consulting (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A2046090370",
      "name": "Julia Langham",
      "affiliations": [
        "European Framework Program Consulting (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A1986744770",
      "name": "Andy Gimblett",
      "affiliations": [
        "European Framework Program Consulting (United Kingdom)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2596664472",
    "https://openalex.org/W4378803794",
    "https://openalex.org/W2061598819",
    "https://openalex.org/W2783040364",
    "https://openalex.org/W2558697804",
    "https://openalex.org/W2593758073",
    "https://openalex.org/W2770117783",
    "https://openalex.org/W2156100542",
    "https://openalex.org/W3149778443",
    "https://openalex.org/W4365512576",
    "https://openalex.org/W1966561347",
    "https://openalex.org/W2577537660",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W4319067669",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W2891147113",
    "https://openalex.org/W2198093519",
    "https://openalex.org/W2035121233",
    "https://openalex.org/W2560367415",
    "https://openalex.org/W2572174216"
  ],
  "abstract": null,
  "full_text": "Vol.:(0123456789)\nPharmacoEconomics - Open (2024) 8:205–220 \nhttps://doi.org/10.1007/s41669-024-00476-9\nORIGINAL RESEARCH ARTICLE\nArtificial Intelligence to Automate Network Meta‑Analyses: Four \nCase Studies to Evaluate the Potential Application of Large Language \nModels\nTim Reason1 · Emma Benbow1 · Julia Langham1  · Andy Gimblett1 · Sven L. Klijn2  · Bill Malcolm3\nAccepted: 1 February 2024 / Published online: 10 February 2024 \n© The Author(s) 2024\nAbstract\nBackground The emergence of artificial intelligence, capable of human-level performance on some tasks, presents an \nopportunity to revolutionise development of systematic reviews and network meta-analyses (NMAs). In this pilot study, we \naim to assess use of a large-language model (LLM, Generative Pre-trained Transformer 4 [GPT-4]) to automatically extract \ndata from publications, write an R script to conduct an NMA and interpret the results.\nMethods We considered four case studies involving binary and time-to-event outcomes in two disease areas, for which an \nNMA had previously been conducted manually. For each case study, a Python script was developed that communicated with \nthe LLM via application programming interface (API) calls. The LLM was prompted to extract relevant data from publica-\ntions, to create an R script to be used to run the NMA and then to produce a small report describing the analysis.\nResults The LLM had a > 99% success rate of accurately extracting data across 20 runs for each case study and could gener-\nate R scripts that could be run end-to-end without human input. It also produced good quality reports describing the disease \narea, analysis conducted, results obtained and a correct interpretation of the results.\nConclusions This study provides a promising indication of the feasibility of using current generation LLMs to automate data \nextraction, code generation and NMA result interpretation, which could result in significant time savings and reduce human \nerror. This is provided that routine technical checks are performed, as recommend for human-conducted analyses. Whilst \nnot currently 100% consistent, LLMs are likely to improve with time.\n1 Introduction\nMany countries have health technology assessment (HTA) \nagencies to systematically evaluate the efficacy, safety and \nvalue of new interventions to inform price negotiations and \nreimbursement decisions [1, 2]. Pharmaceutical companies \nare very often required to submit robust evidence of the \ncost-effectiveness of the new intervention compared with \nthe currently available treatments (comparators) using data \nthat have been acquired in a systematic, non-biased and \ntransparent way. Systematic literature reviews (SLRs) and \nmeta-analyses are considered the most rigorous methods \nfor gathering and synthesising such evidence [3 ]. In addi-\ntion to HTAs, SLRs and meta-analysis are also integral for \nother evidence-based practices including informing clinical \ndecision making, clinical guidelines, medical education and \npolicy [4].\nExtended author information available on the last page of the article\nKey Points for Decision Makers \nThis is a promising first assessment of the feasibility \nof using LLMs to automate data extraction, analysis \nand result interpretation, which could result in signifi-\ncant time savings and reduce human error in the NMA \nprocess.\nThis study has shown that GPT-4 can successfully rep-\nlicate the results of four NMAs in two disease areas for \ntwo outcome types (binary and time-to-event).\nThere is a need for further research to develop and test \nLLM-based processes.\n206 T. Reason et al.\nThe HTA process generally involves several key steps \n[5], and an overview is shown in Fig.  1. Firstly, SLRs are \nconducted to identify relevant clinical studies of the inter -\nvention and comparators, preferably head-to-head evidence \nfrom randomized controlled trials (RCTs). Secondly, data \nfrom the studies identified in the SLR are extracted and \nthen synthesized using statistical techniques to determine \nthe relative effectiveness. Typically, due to an absence of \ndirect head-to-head evidence for all the different compara-\ntors, indirect or mixed treatment comparisons using methods \nsuch as network meta-analyses (NMA) are employed at this \nstage, which compare multiple treatments simultaneously \nusing direct and indirect evidence across a “network” of \nRCTs [6]. These methods require the assessment of clinical \nand methodological heterogeneity and transitivity of the tri-\nals included [7]. Finally, economic models are developed to \ndetermine the cost-effectiveness of the intervention versus \nthe comparators, populated using the clinical data obtained, \nand statistical data generated in the above steps.\nThe HTA process is very labour and resource intensive, \nrequiring a large team of experts in the field of health eco-\nnomic outcomes research (HEOR), including SLR analysts, \nstatisticians and economic modellers [5 , 8]. For example, \nto reduce errors, there is a requirement for at least three \nanalysts to be involved in the SLR and data extraction: two \nanalysts to perform dual independent screening and dupli-\ncated data extraction or data checking and a third analyst to \nresolve any issues [9 ]. Despite these quality-control meas-\nures, the processes can still be prone to error [10]. In addi-\ntion, the HTA process is time-consuming, generally taking \nover a year to complete, with the SLR and NMA part of this \nprocess taking several months each [8 , 11]. A faster HTA \nprocess would ultimately mean faster access to new treat-\nments and, therefore, better outcomes for patients.\nArtificial intelligence (AI) tools, especially generative AI \nwith large language models (LLMs), have the potential to \noptimise many steps of the HTA workflow, making the pro-\ncess quicker, less costly, more efficient and less error-prone \n[12, 13]. The latest LLMs, including GPT-4 [14], have been \ntrained using vast quantities of publicly available text data \nto understand, generate and manipulate human language \nby recognising patterns and relationships in language [15]. \nThey are capable of human-level performance on some pro-\ngramming and analytics tasks [16]; however, the practical \nuse of these AI models remains untested in HEOR.\nThe aim of this study is to perform a feasibility assess-\nment of LLM-based automated NMA, using previous manu-\nally conducted NMAs as case studies. The scope of the work \nwas to develop LLM-based processes for automated data \nextraction, software programming to perform the NMA and \ninterpretation of the results from the NMA (highlighted with \nred in Fig.  1). Manual assessments of study heterogeneity \nand suitability of studies for inclusion in an NMA were con-\nducted prior to automation.\n2  Methods\n2.1  Case Studies\nThe ability of the LLM to replicate the results of manu-\nally conducted NMAs was tested using four case studies. \nFor each of these case studies, a literature review had been \nconducted to identify relevant trials, followed by a feasibil-\nity analysis to determine which trials were appropriate to \ninclude in the NMA, i.e. involving a review of the study \ndesign, patient characteristics and outcomes to determine \nwhether the trials were sufficiently similar to include in \nthe NMA [17]. The four case studies spanned two disease \nareas (hidradenitis suppurativa [HS], which is a chronic, \ninflammatory skin disorder, and non-small cell lung can-\ncer [NSCLC]) and two types of outcome (binary and time-\nto-event [survival]). These outcomes were chosen because \nif a prototype could be shown to work for binary or time-\nto-event outcomes, then it should be generalisable to other \noutcome types.\nWe have implicitly assumed that all studies included in \nthe analyses were sufficiently homogeneous to be combined \nbased on a previous publication [18] (NSCLC) and from \na topline manual check of study design and characteristics \n(HS).\nCase study 1 involved an indirect comparison of the \nefficacy of treatments for patients with moderate-to-severe \nhidradenitis suppurativa (unpublished literature review and \nanalysis). The literature review had identified six relevant \ntrials evaluating the clinical response to different treat-\nments (adalimumab, secukinumab and bimekizumab) in this \npatient population, and the feasibility analysis determined \nthat all six trials were suitable to include in the NMA. The \nnetwork diagram for the analysis is shown in Fig. S1 and the \ntrials and clinical response data are summarised in Table S1 \n(Online Resource).\nCase studies 2, 3 and 4 concerned the efficacy of second-\nline treatments for patients with NSCLC. The SLR was \nFig. 1  Overview of HTA process including NMA. Use of LLMs to \nautomate the process have been applied within this study to those \nsteps in the process highlighted with a red box. HTA  health technol-\nogy assessment, LLM large language model, NMA network meta-\nanalysis\n207\nAI to Automate NMAs: Potential of LLMs\noriginally conducted in 2018 and updated in 2021 [18]. \nCase study 2 involved treatments and outcome data (over -\nall survival [OS]), which were used in the primary analysis \n(base case) of an economic model. The feasibility analysis \nidentified five trials reporting on OS across relevant treat-\nments (nivolumab, pembrolizumab and atezolizumab, with \ndocetaxel as the common comparator treatment) that were \nappropriate for inclusion in the NMA (Fig. S2 and Table S2 \n[Online Resource]). Case study 3 involved an extra seven tri-\nals reporting OS for three additional treatments (nintedanib \n+ docetaxel, pemetrexed and ramucirumab + docetaxel) \nthat had been used in a sensitivity analysis of an economic \nmodel (Fig. S3 and Table S3 [Online Resource]). Case study \n4 concerned the efficacy outcome of progression-free sur -\nvival (PFS), and the feasibility analysis determined that the \nsame five trials used in Case study 2 were appropriate for \nthe NMA for this outcome (Fig. S4 and Table S4 [Online \nResource]).\n2.2  Overview of the LLM‑Based Process \nfor Automating the NMA\nGPT-4 (Generative Pre-trained Transformer 4, developed \nby OpenAI [14]) was selected as the LLM engine for this \nstudy, as it was considered superior to other publicly avail-\nable LLMs at the time of study. However, the method devel-\noped for interacting with GPT-4 in this study can, in theory, \nuse different LLMs.\nTo allow the LLM to generate text to specify an NMA, it \nwas decided to choose a programming language whereby the \nanalysis and the data could be contained within one script. \nR was chosen as the software in which the AI-generated \nanalysis would be built, as it is freeware and platform (oper-\nating system) independent. To implement an NMA in R, the \n‘multinma’ package was used, which implements network \nmeta-analysis, network meta-regression and multilevel net-\nwork meta-regression models [19]. Models were estimated \nin a Bayesian framework using Stan [20].\nLLMs require the user to provide ‘prompts’, i.e. instruc-\ntions stating what the user wants the LLM to do and the out-\nput required. Interaction with the LLM was achieved through \napplication programming interface (API) calls (a way for \ntwo or more computer programs to communicate with each \nother) written in a Python script. The outline of the process, \nas shown in Fig. 2a, is as follows:\n• For data extraction from the publications, a prompt \nincluding text from the publication and requesting extrac-\ntion of all relevant data from the supplied publication text \nwas sent via an API call to the LLM for each publication \nneeded for the NMA.\n• To produce an R script with code to run the NMA, a \nprompt requesting generation of an R script was passed \nto the LLM via an API call, along with the data from all \npublications and an example R script (sourced from the \nVignettes for the ‘multinma’ package) [19].\n• To produce a small report containing a description of \nthe disease, a description of the analysis conducted, the \nresults of the analysis and an interpretation of the results, \nthe LLM-generated R script was called from the Python \nscript and the results of the NMA, along with a prompt \nrequesting generation of a small report, were sent via an \nAPI call to the LLM.\nExample prompts are provided in the Online Resource.\nFig. 2  a LLM-based process for automating the NMA. b Chunking \napproach to data extraction. API application programming interface, \nLLM large language model, NMA network meta-analysis\n208 T. Reason et al.\n2.3  Prompts Used to Instruct the LLM \nand Hyperparameters\nPrompts were developed that were used to instruct the LLM \nto:\n• Extract the required data for the analysis from the \nabstracts of the publications.\n• Determine if all data required was contained in the \nabstract and, if not, extract any missing data from the \nfull publication.\n• Infer missing data from other information, e.g. the num-\nber of patients affected from the proportion of patients \naffected and the number at risk as well as the number of \npatients at risk from total trial size and randomisation \nratio.\n• Transform extracted data to the correct format for inclu-\nsion into the model for analysis (number affected for \nbinary outcomes and log scale for time-to-event out-\ncomes).\n• Generate an R script for NMA using generic script from \nthe R ‘multinma’ package.\n• Interpret the results of the analysis and write a small \nNMA report.\nThe Python script was used to pass the output of each \nprompt to the next, with the prompts loaded into Python \nas strings. Almost identical prompts were used for the four \nanalyses conducted, with the following differences: use of \nrelevant disease name (HS and NSCLC) and relevant out-\ncome name (clinical response, OS and PFS); different R \nscript examples were provided for binary and time-to-event \noutcomes [19], and additional contextual information was \nrequired for R script production for time-to-event outcomes \n(see Methods Sect. 2.4.3 below).\nIn addition to developing prompts, there was also a \nrequirement to adjust some of the LLM’s hyperparameters, \nincluding role and temperature.\n2.4  Prompt Development and Key Learnings\nThe prompts used have a significant impact on the output \nquality of the LLM. To evaluate the LLM’s capability to per-\nform the required tasks, it was essential to create prompts of \nsufficient quality to obtain the required responses. Therefore, \nthe following prompt creation process was followed: for each \noutcome type, initial prompts were generated and given to \nthe LLM. The returned output was evaluated and, based on \nthe contents, adjustments were made to the prompts. The \nadjusted prompts were then sent back to the LLM for further \ntesting and evaluation. This process of output evaluation and \nprompt adjustment continued until no further improvements \ncould be made and final prompts were reached. An example \nof the development of the OS data extraction prompt is given \nin Fig. S5 (Online Resource).\nSeveral key learnings were uncovered through the prompt \ndevelopment process, which shaped the form of the final \nprompts. These were: using an iterative approach to data \nextraction, using multiple prompts and providing contextual \ninformation, as discussed in more detail below.\n2.4.1  Chunking Approach to Data Extraction\nA token is a chunk of text that an LLM reads or generates. \nAt the time of the study, GPT-4 had a token limit of 8192 \n(approximately 6000 words), which restricted the amount \nof text that could be passed to, and be generated from, a \nsingle prompt. Since all the publications used for this study \nexceeded this limit, there was a need to cut publications into \nchunks before passing them to the LLM for data extraction. \nAs shown in Fig. 2b, we asked the LLM to screen overlap-\nping chunks of text from the main publication (e.g. pages \n1–3, 3–5, 5–7, 7–9, etc.) to ensure that all text reviewed was \nin context and then asked the LLM to assess whether it had \nobtained all data required, before providing additional text \nfor screening. It was possible for the LLM to get to the end \nof the publication without extracting all required data if it \nfailed to identify that data.\n2.4.2  Multiple Prompts\nThe first approach for creating an R script was to ask the \nLLM to write an initial R script using data from the first \nstudy, and then to ask it to add data from more trials. This \napproach worked well for the binary outcome, where the \ndata required for the analysis in R is number at risk and \nnumber of patients affected in each arm. However, for the \ntime-to-event outcomes (OS and PFS), the input is a hazard \nratio and standard error for each treatment comparison, and \nthe initial approach used did not produce the right format for \nthis input, leading to incorrect results. Thus, for the time-to-\nevent outcomes, we asked the LLM to gather the required \ndata (hazard ratios, error measures, etc.) from all trials \nbefore writing the R script. For consistency, this approach \nwas also used for the binary outcome. For the analysis input, \ndifferent treatments were given numbers in the R script (Fig. \nS7 [Online Resource]) but the LLM did not always use the \nsame numbering for the same treatment. Therefore, it was \nnecessary to prompt the LLM to fix this in the initial script, \nto match the numbers with the names and doses of the treat-\nments. Thus, multiple prompts were used to generate the \nrequired R script:\n• Collate all data.\n• Use this and the example R script to write an initial \nscript.\n209\nAI to Automate NMAs: Potential of LLMs\n• Tidy the initial script to ensure correct treatment number-\ning is used.\n2.4.3  Contextual Information\nFor some tasks, the LLM was frequently observed to make \ngeneral errors, such as not understanding statistical signifi-\ncance. These were not related to the content (disease and \ntreatment) or language used in the included studies. Address-\ning these errors required the provision of contextual infor -\nmation in addition to the instructions. The contextual infor-\nmation was developed iteratively in the same manner as the \nprompts.\nThe LLM was initially not very successful at writing an \nexecutable R script or choosing the correct model to use \nfor the analysis, for either outcome type. For example, the \nLLM sometimes invented R packages and functions that it \nincluded in the script. Including worked examples has previ-\nously been shown to improve the performance of LLMs in \nmulti-step reasoning tasks [21]. Therefore, we provided an \nexample script appropriate for the type of analysis needed, \nas contextual information for the LLM. The example scripts \nused were sourced from the online vignette of the ‘multi-\nnma’ package [19] (Fig. S6 [Online Resource]).\nSimilarly, when asked to write the R script for the time-\nto-event outcomes, the LLM did not always construct the \ninput for the analysis in the correct way nor maintain the \norder of the treatment comparison. For instance, the LLM \nwould try to construct a dataframe for the input data that had \na row per treatment arm in the treatment names and number-\nat-risk columns but then would only include one row per \nstudy for the hazard ratios. It was therefore necessary to \nprovide context to the LLM, which was achieved by includ-\ning contextual statements within the code-writing prompt. \nFor example, including the text “The order of the treatment \ncomparison is important” ensured that the LLM maintained \nthe treatment comparison order for each hazard ratio. Some \nof the trials included in the analyses treated patients with a \ncombination of treatment plus placebo, e.g. treatment X plus \nplacebo. Usually, when conducting an NMA, we would con-\nsider the treatment effects for these patients to be equivalent \nto patients treated only with treatment X. For the LLM to \nconsistently make this assumption, and to therefore number \nthe treatments correctly, we needed to provide contextual \ninformation, such as adding the statement, “We consider \npatients treated with ‘treatment X plus placebo’ to be treated \nwith ‘treatment X’”, to the prompt asking the LLM to tidy \nthe R script.\nThe LLM also required context for interpretation of the \nNMA results. The LLM reliably identified when a treatment \noutperformed the comparator, for both the binary and the \ntime-to-event outcomes. However, we noticed that the LLM \nsometimes claimed that either all or none of the comparisons \nreached statistical significance, when in fact some did and \nsome did not. Therefore, contextual statements, such as “A \nresult is statistically significant if the lower and upper bound \nfor the credible interval are either both greater than 1 or both \nless than 1”, were included.\nTo summarise, the following contextual information was \nprovided to the LLM: example R scripts for the analysis, the \nimportance of the order of the treatment comparison when \nconsidering a hazard ratio, the assumptions generally made \nwhen considering equivalence of treatments and the defini-\ntion of statistical significance.\n2.5  Non‑text‑Based Publications\nFor all case studies considered, some of the publications \nneeded for the case study were text-based, whilst some were \nphotographs of presentations, or posters, or contained data \nwithin figures. Whilst it is now possible to ask an LLM to \nreceive images as input (e.g. with GPT-4 Vision, Gemini), at \nthe time of the study, GPT-4 was not able to receive images \nas input and thus was not able to extract any data for these \npublications. The trials that had image-based publications \nand the approach taken to obtain data are listed in Table 1.\n2.6  LLM Hyperparameters\n‘Role’ and ‘temperature’ are some of the hyperparameters \nthat can be used to control the behaviour of GPT-4. Assign-\ning a role to the LLM is a simple way to add context to \na prompt, for example if you assign it a role of ‘a poet’, \nthe style, and possibly the content, of the response will be \ndifferent from that obtained if the role assigned is ‘a surly \nteenager’ [22]. Thus, there was a need to assign an appropri-\nate role to GPT-4. We found that by telling GPT that it is a \nstatistician and a medical researcher, we obtained the type \nand quality of responses that we needed.\nThe temperature parameter of GPT-4 is a number \nbetween 0 and 2 that determines the randomness of the \ngenerated output. A lower value for the temperature \nparameter will lead to a less random response, whilst a \nhigher value will produce a more creative and/or surpris-\ning output. We wanted the responses to be as deterministic \nas possible, so we set the temperature to be 0.\nDefault values were used for all other hyperparameters.\n2.7  Output Generation and Assessment\nFor each case study, a single Python script included the \nfinal set of prompts for interaction with the LLM and com-\nmands for the generated R script to run and to obtain the \nresults of the analysis (Fig.  2a). Each Python script was \nrun end to end, without human intervention, and produced \n210 T. Reason et al.\nan R script and a short report describing the disease area \nand method of analysis, presenting the NMA results and \nproviding an interpretation of the results.\nReproducing results with LLMs can be difficult because \nof random elements at play that vary outputs over time \n[23], i.e. LLMs do not produce deterministic results. As \npreviously mentioned (Sect.  2.6), temperature is one of \nseveral hyperparameters that control the behaviour of \nGPT-4. Despite setting the temperature of GPT-4 to 0 \n(least random), outputs were observed to vary when the \nsame prompt set was used on multiple occasions. There-\nfore, we ran the Python script end to end 20 times for \neach analysis (80 runs in total) to capture variation in \nperformance.\nThe performance of the LLM was assessed in three \nstages:\n• Assessment of data extraction: for each run, did the \nLLM correctly extract all required data from each \ntrial? This was evaluated by comparing outputs from \nthe LLM with data extracted/checked by two of the \ninvestigators (SLR and NMA experts).\n• Assessment of R script (evaluated by one of the inves-\ntigators, an NMA expert familiar with R and who wrote \nthe R script for the manually conducted NMAs):\no Did the LLM produce an R script that contained all \nrelevant extracted data and the correct functions to \nconduct an NMA?\no Could the script be run without human interven-\ntion? If not, was minor (less than 2 minutes of work) \nor major (more than 2 minutes of work) editing \nrequired to enable this?\no Did the script produce results that matched the same \nNMA conducted by a human?\n• Assessment of the NMA report (qualitatively assessed by \none of the investigators, familiar with the disease area):\no Was a reasonable description of the disease area pro-\nvided?\no Was the methodological description of the analysis \ncorrect?\no Were correct results presented?\no Was the interpretation of the results correct and \ninformative?\n3  Results\nA summary of the LLM’s success in data extraction across \neach case study is shown in Fig.  3a, and the quality of the \ngenerated R script produced is shown in Fig. 3b.\nFour case studies were considered, and Fig.  S1–S4 \n(Online Resource) display the network for each case study.\n1. Case study 1 (indirect comparison of the efficacy of \ntreatments for patients with moderate-to-severe HS): \nthree publications reporting clinical response data for \nsix trials (two trials per publication).\n2. Case study 2 (indirect comparison of the efficacy of sec-\nond-line treatment for patients with NSCLC: base case \nanalysis of OS): four publications reported OS across \nfive trials.\n3. Case study 3 (indirect comparison of the efficacy of sec-\nond-line treatment for patients with NSCLC: sensitivity \nanalysis of OS): 11 publications reported OS data from \n12 trials.\n4. Case study 4 (indirect comparison of the efficacy of \nsecond-line treatment in patients with NSCLC: PFS): \nfour publications reporting PFS across five trials.\n3.1  Data Extraction\nA summary of the LLM’s overall performance for data \nextraction is presented in Fig. 3a.\nTable 1  Non-text-based publications and approach to data extraction\nHS hidradenitis suppurativa, NSCLC non-small cell lung cancer, OS overall survival, PFS progression-free survival\nCase study Trials Approach taken\nCase study 1 (HS) BE HEARD I and II [31]\nPhotographs of a presentation\nData provided to GPT-4 within Python script (hard-coded into script), \nbefore R script generation\nCase studies 2, 3 and 4 (NSCLC OS, \nOS sensitivity, PFS)\nKEYNOTE-010 [32]\nPhotograph of poster\nGPT-4 was asked to extract all data from an older publication [33]     \nand then was provided with the updated hazard ratio (hard-coded \ninto the Python script), before R script generation\nCase study 3 (NSCLC OS sensitivity) GFPC 05-06 [34]\nHazard ratio provided in a figure\nGPT-4 was asked to extract all data from the text in the publication \nand then was provided with the hazard ratio (hard-coded into the \nPython script), before R script generation\n211\nAI to Automate NMAs: Potential of LLMs\nFig. 3  a Summary of the data \nextraction performance. b \nSummary of R script quality. \nHS hidradenitis suppurativa, \nNSCLC non-small cell lung \ncancer, OS overall survival, PFS \nprogression-free survival\n\n212 T. Reason et al.\nFor case study 1, the LLM accurately and consistently \nextracted the correct data from the text-based publications \nfor each of the 20 runs. For the text-based publications avail-\nable for case study 2 (Sect.  2.5), the LLM accurately and \nconsistently extracted the correct data most times but failed \nto extract number at risk data for the KEYNOTE-010 trial \n(three items of data) in two of the 20 runs. Since the LLM \nneeded to extract 35 separate pieces of data for each run, \nthis equates to a very high overall extraction success rate \nof 99.1%. Similarly, for the text-based documents avail-\nable for case study 3, the LLM accurately and consistently \nextracted the correct data for all but one run, where it did \nnot manage to extract the number of patients at risk (three \nitems of data) for the KEYNOTE-010 trial. Since the LLM \nneeded to extract 77 separate pieces of data for each run, \nthis equates to a very high overall extraction success rate \nof 99.8%. For the text-based publications available for case \nstudy 4, the LLM accurately and consistently extracted the \ncorrect data, except for one run, where it failed to extract the \nnumber at risk data for the CheckMate017 trial (two data \nitems; Fig. 3a). Since the LLM needed to extract 35 separate \npieces of data for each run, this equates to an overall extrac-\ntion success rate of 99.7%.\nIt is not clear why the LLM failed to extract number of \npatients at risk from the KEYNOTE-010 publication in two \nruns for case study 2 and one run for case study 3 and why \nit failed to extract the number of patients at risk from the \nCheckMate017 trial for one run of case study 4, and there \ndid not appear to be a systematic pattern for this failure. \nHowever, it may be due to the language used to describe \npatient assignment in these publications, and it may be \npossible to enhance performance further using improved \nprompting, or by running the data extraction multiple times, \nand using the responses where the LLM has found the data \nrequired.\nThus, the LLM achieved a data extraction success rate \nof over 99% for each case study. The LLM did not report \nincorrect data on any occasion, it only intermittently failed \nto extract data from two trials. This level of performance \nexceeds the performance seen for human data extraction, \nwhere between 8 and 42% of data extraction errors have \nbeen observed [10].\n3.2  R Script Generation\nAll R scripts generated with the LLM were well commented \nand the script was easy to read and interpret (Fig. S7 and \nFig. S8 [Online Resource]). The LLM-generated R scripts \nran with no or very minor amendments (Tables  2, 3, 4, 5) \nin each of the 20 runs of case study 1 and case study 2, 15 \nruns of case study 3 and 19 runs of case study 4 (Fig.  3b). \nIn these cases, once any required amendments had been \nimplemented, the scripts ran and produced correct results \n(Sect. 3.3).\nFor case study 1, the R script failed to run (producing \nan error message) on five occasions. Four scripts contained \nvery minor errors that took less than 2 min to fix (Table  2). \nFor the fifth script, the LLM had included data directly from \na publication that reported non-integer values for number of \nevents [24]. On all other occasions, it followed instructions \nin the prompt to only use integer values and thus calculated \nthe number of events from the percentage given. Again, this \nwas a minor error, requiring a quick and very simple fix \n(Table 2).\nFor case study 2, the R script failed to run on eight occa-\nsions and required human input. For each of these occasions, \nthe script contained very minor errors that took less than 2 \nmin to fix (Table 3).\nCase study 3 was the most complicated of all analyses \nconducted: the number of trials and treatments included in \nthe network for the sensitivity analysis of OS were greater \nthan for the base case analysis of OS (12 trials and eight \ntreatments versus 5 trials and five treatments [Fig. S3, \nOnline Resource]), and, whilst all trials included an arm \nwhere patients were treated with docetaxel, not all hazard \nratios were reported with docetaxel as the reference treat-\nment. Four of the generated R scripts ran without requiring \nhuman input, whilst 16 failed to run (producing an error \nmessage). Of these, 11 scripts contained very minor errors \nthat took less than 2 min to fix (Table  4). For the remain-\ning five scripts, the LLM had incorrectly constructed the \ndataframe, used as input to the R set_agd_contrast func-\ntion: the column containing (log) hazard ratios should have \none entry per treatment in each trial, with ‘NA’ provided \nfor the reference treatment, but the LLM only included one \n‘NA’ in the whole column, so, without prior knowledge of \nthe network and the data, it was not possible to update the \nTable 2  Summary of intervention required for HS analysis R script\nHS hidradenitis suppurativa\nNumber of runs Description of intervention required\n4 (20%) Conversion of output of R nma function to a \ndataframe produced a dataframe with slightly \ndifferent column headings than were expected. \nSo, the formula to convert mean log odds ratio \nand lower and upper credible limits to natural \nscale failed. This was easily fixed by either \nchanging the way that the dataframe was \nproduced or by changing the column headings \nwithin the conversion formula\n1 (5%) The SUNSHINE and SUNRISE publication \nreported non-whole numbers for the patients \nachieving clinical response. GPT-4 had tried \nto include these non-integers in the analysis. \nThis error was easily fixed by converting these \nvalues to whole numbers\n213\nAI to Automate NMAs: Potential of LLMs\nscript to enable it to run and produce correct results. It may \nbe possible to avoid this error by feeding the LLM with more \ndomain knowledge, along with the prompt.\nFor case study 4, two of the generated R scripts failed to \nrun, with one requiring only a minor correction to the format \nof treatment numbers for one trial. For the remaining run, \nthe dataframe used within R’s set_agd_contrast function did \nnot have the correct format for an analysis of trial-level data \n(e.g. hazard ratios; Table 5).\nThus, in many cases, the LLM generated an R script that \nran without human input, and in the majority of cases, a \nscript was generated that ran following minor human input \n(< 2 min of effort). All errors caused the R script to fail \nand produce an error message, no script ran and generated \nerroneous results.\n3.3  NMA Results\nWhere the R scripts ran, the NMA results calculated very \nclosely matched those of the human-conducted NMA.\nThe mean odds ratios for treatments versus placebo, cal-\nculated using the LLM-generated R scripts for case study 1, \nwere very close to those calculated by the manual (human) \nNMA for all 20 runs (Table  6). All differences observed \nwere within the range of expected variability (< 1%), since \nresults can vary slightly when running an NMA multiple \ntimes using the same R code, due to Monte Carlo error \noccurring when the random seed is not set within the anal-\nysis (these differences are also observed when running a \nhuman-written script several times) [25].\nFor case studies 2, 3 and 4, the mean hazard ratios for \ntreatments versus docetaxel, produced by the LLM-gen-\nerated R scripts, were identical to those calculated by the \nmanual NMA, whilst the limits of the credible interval \nvaried slightly but only within the realms of the variability \nobtained if a human ran the NMA, using the same R code \nmultiple times (due to Monte Carlo error; Tables  7, 8 and \n9, respectively).\n3.4  Report Writing and Interpretation of Results\nUsing the results from the R scripts, the NMA reports gener-\nated with the LLM were clearly written and included a good \nsummary of the disease area (hidradenitis suppurativa for \ncase study 1 [Fig. S9 (Online Resource)] and NSCLC for case \nstudies 2–4 [Fig. S10 (Online Resource)]). The methods of \nanalysis were summarized clearly and at an appropriate level \nof detail, as we asked the LLM to create a concise report (i.e. \nwe did not request the methods to be as elaborate as they might \nTable 3  Summary of intervention required for base case OS analysis R script\nOS overall survival\nNumber of runs Description of intervention required\n8 (40%) Some of the publications reported confidence intervals for the hazard ratio that were not 95%. GPT-4 had constructed a \ndataframe that included all treatments, hazard ratios and confidence interval limits and had included a column in this to \nrecord the confidence levels. Whilst the hazard ratio and confidence interval limit columns included a row per treatment in \neach trial, the confidence level column only contained one value per hazard ratio:\nThis was easily fixed by editing the values in this column to include the correct number of rows\nTable 4  Summary of intervention required for sensitivity analysis of \nOS R script\nOS overall survival\nNumber of runs Description of minor intervention required\n4 (20%) GPT-4 had constructed a dataframe that \nincluded all treatments, hazard ratios and \nconfidence interval limits and a column for \nthe trials. Whilst the other columns included \na row per treatment in each trial, GPT-4 had \nonly included one row per trial in the studies \ncolumn. This was easily fixed by editing the \nvalues in this column to include the correct \nnumber of rows\n7 (35%) When tidying the script, GPT-4 did not update \nthe treatment numbering correctly, leading to \na disconnected network in some cases. This \nwas easily fixed by editing the treatment num-\nbers in the script\n214 T. Reason et al.\nneed to be for an HTA submission). The interpretation of the \nresults was correct in all 20 runs for each case study, with the \ncorrect treatment identified as the best treatment in the net-\nwork. Whether treatment effects were statistically significant \nwas also correctly stated. Variation was seen in the amount of \ndetail generated by the LLM in different runs. Examples of the \ninterpretation summary are shown in Fig. 4.\n4  Discussion\nWe present a novel LLM-based process for automating the \ndata extraction, software script construction and results \ninterpretation for an NMA, which required only trial publi-\ncations as the input. Using four previously conducted NMAs \nas case studies, we demonstrated that an LLM (GPT-4) was \ncapable of extracting data to a high standard and could pro-\nduce quality R script, which included all required data, and \ncould be run end to end with little or no human interven -\ntion. We also demonstrated that the LLM could successfully \nTable 5  Summary of intervention required for PFS R script\nPFS progression-free survival\nNumber of runs Description of minor intervention required\n1 (5%) When tidying the script, GPT-4 did not update the treatment numbering correctly. This was easily fixed by editing the \ntreatment numbers in the script\n1 (5%) GPT-4 did not construct the dataframe used within R’s set_agd_contrast function to have the correct format for an analy-\nsis of trial-level data:\nHow the dataframe should have looked:\nTable 6  Results of the manual \nNMA and example results \nof LLM generated NMA for \nclinical response in patients \nwith moderate-to-severe \nhidradenitis suppurativa\nFor each case study, the set of results produced by the first R script generated by GPT-4 were used for the \nexamples given here. These results were then compared to the remaining 19 sets of results and assessed by \none of the investigators (NMA expert)\nCrI credible interval, LLM large language model, NMA network meta-analysis\nTreatment versus placebo Odds ratio [95% CrI] obtained from \nmanual NMA\nOdds ratio [95% CrI] \nobtained from GPT-4 \nNMA\nAdalimumab 2.84 [2.06, 3.97] 2.84 [2.06, 3.90]\nBimekizumab every 2 weeks 2.26 [1.52, 3.36] 2.24 [1.52, 3.30]\nBimekizumab every 4 weeks 2.21 [1.44, 3.37] 2.20 [1.44, 3.38]\nSecukinumab every 2 weeks 1.61 [1.18, 2.20] 1.61 [1.20, 2.16]\nSecukinumab every 4 weeks 1.65 [1.22, 2.27] 1.65 [1.22, 2.19]\n215\nAI to Automate NMAs: Potential of LLMs\nproduce good quality text that summarised the disease \narea, summarised the analysis method used, presented the \nresults in an informative manner and interpreted the results \ncorrectly.\nWhilst some studies have considered use of automation \nor AI within HEOR [12, 13, 16], we believe that this is the \nfirst study to consider the use of an LLM to automate data \nextraction and NMA end to end. As an early feasibility \nTable 7  Results of the manual \nNMA and example results of \nLLM-generated NMA for base \ncase analysis of overall survival \nin patients receiving second-line \ntreatment for NSCLC\nFor each case study, the set of results produced by the first R script generated by GPT-4 were used for the \nexamples given here. These results were then compared to the remaining 19 sets of results and assessed by \none of the investigators (NMA expert)\nCrI credible interval, LLM large language model, NMA network meta-analysis, NSCLC non-small cell lung \ncancer\nTreatment versus docetaxel Hazard ratio [95% CrI] obtained from \nmanual NMA\nHazard ratio [95% CrI] \nobtained from GPT-4 \nNMA\nAtezolizumab 0.78 [0.69, 0.88] 0.78 [0.69, 0.88]\nNivolumab 0.68 [0.58, 0.80] 0.68 [0.58, 0.80]\nPembrolizumab 10 mg/kg 0.59 [0.49, 0.70] 0.59 [0.49, 0.71]\nPembrolizumab 2 mg/kg 0.73 [0.62, 0.86] 0.73 [0.62, 0.86]\nTable 8  Results of the manual \nNMA and example results \nof LLM-generated NMA for \nsensitivity analysis of overall \nsurvival in patients receiving \nsecond-line treatment for \nNSCLC\nFor each case study, the set of results produced by the first R script generated by GPT-4 were used for the \nexamples given here. These results were then compared to the remaining 19 sets of results and assessed by \none of the investigators (NMA expert)\nCrI credible interval, LLM large language model, NMA network meta-analysis, NSCLC non-small cell lung \ncancer\nTreatment versus docetaxel Hazard ratio [95% CrI] obtained from \nmanual NMA\nHazard ratio [95% CrI] \nobtained from GPT-4 \nNMA\nAtezolizumab 0.78 [0.68, 0.87] 0.78 [0.69, 0.88]\nNintedanib + docetaxel 0.94 [0.83, 1.06] 0.94 [0.83, 1.06]\nNivolumab 0.68 [0.59, 0.79] 0.68 [0.59, 0.78]\nPembrolizumab 10 mg/kg 0.59 [0.49, 0.71] 0.59 [0.49, 0.71]\nPembrolizumab 2 mg/kg 0.73 [0.62, 0.86] 0.73 [0.62, 0.86]\nPemetrexed 0.97 [0.87, 1.10] 0.97 [0.86, 1.09]\nRamucirumab + docetaxel 0.86 [0.76, 0.97] 0.86 [0.75, 0.98]\nTable 9  Results of the manual \nNMA and example results \nof LLM-generated NMA for \nprogression-free survival in \npatients receiving second-line \ntreatment for NSCLC\nFor each case study, the set of results produced by the first R script generated by GPT-4 were used for the \nexamples given here. These results were then compared to the remaining 19 sets of results and assessed by \none of the investigators (NMA expert)\nCrI credible interval, LLM large language model, NMA network meta-analysis, NSCLC non-small cell lung \ncancer\nTreatment versus docetaxel Hazard ratio [95% CrI] obtained from \nmanual NMA\nHazard ratio [95% CrI] \nobtained from GPT-4 \nNMA\nAtezolizumab 0.93 [0.82, 1.05] 0.93 [0.81, 1.06]\nNivolumab 0.81 [0.70, 0.95] 0.81 [0.69, 0.95]\nPembrolizumab 10 mg/kg 0.79 [0.67, 0.94] 0.79 [0.66, 0.95]\nPembrolizumab 2 mg/kg 0.88 [0.74, 1.04] 0.88 [0.74, 1.05]\n216 T. Reason et al.\nassessment, this study points to several potential benefits of \nautomated data extraction and NMA. The primary poten -\ntial benefit is in time savings in the data extraction process, \nwhich could enable quicker and less costly decision making \nin healthcare, which may ultimately speed up patient access \nto medicines. Specifying the user prompts and data required \nfor the process should take no longer than 1–2 h. This time \nincludes the time required to update the prompts and run \nthe Python script but does not include checking of data \nextraction, assessment of study or population heterogeneity \nFig. 4  Report writing: examples \nof the LLM’s (GPT-4) interpre-\ntations of the results. CrI cred-\nible interval, HR hazard ratio, \nHS hidradenitis suppurativa, \nNSCLC non-small cell cancer\n\n217\nAI to Automate NMAs: Potential of LLMs\nand feasibility analysis. The time taken will depend on the \ncomplexity of the treatment network and the run time of \nthe process (which runs without human attention); the run \ntime for the four case studies considered was approximately \n10 min for the three smaller NMAs (including 5 or 6 treat-\nments and trials) and approximately 15 min for the larger \nNMA (8 treatments, 12 trials). The time taken by the LLM is \nsubstantially lower than the time it took to manually extract \ndata, write the R script and run it (approximately half a day \nper outcome).\n4.1  Limitations\nThe novel approach developed has been tested on a single \nLLM (GPT-4) and on a limited number of case studies. The \ntreatment networks were relatively simple; all trials included \na common treatment and the LLM was not asked to check \nwhether the proportional hazards assumption held for the \nthree analyses of time-to-event (survival) data.\nFurther research is needed to determine the level of addi-\ntional work required to use our approach with LLMs other \nthan GPT-4 and whether improved accuracy and/or process-\ning speed can be achieved with other LLMs or alternative \nprompting strategies and context.\nThe responses given by LLMs are not always consist-\nent when asking the same question multiple times, and the \nresponses may change over time, as the LLM learns from the \nquestions it is being asked. This means that it could be dif-\nficult to reproduce results. However, if using general access \nLLMs, this uncertainty could be reduced by ensuring that \nLLM parameters are set to reduce the level of randomness \nin responses by asking the LLM to repeat all tasks and then \nidentifying (and discarding) outliers in the responses and by \nusing a specific version of an LLM, e.g. GPT-4 at 1 January \n2024. Alternatively, using open-source LLMs, for example \nthrough the ‘Ollama’ package [26, 27], would allow tighter \nLLM version control and allow better reproducibility of \nresponses. Many open-source LLMs can be downloaded and \nused locally [26], which would enable the same LLM model \nversion to be used.\nWe believe that the prompts developed within this study \nare generalisable to NMAs in different disease areas, and \nsimilar prompts can be used for continuous outcomes; how-\never, there is a need to demonstrate that this is the case. \nWe would also want to demonstrate the methodology and \ndeveloped prompts with NMAs with larger and more com-\nplicated networks. Additionally, there is a need to investigate \nusing LLMs to support further NMA tasks, such as choosing \nstatistical models; choosing fixed effects or random effects \nmodels; determining whether the models have converged \n(Gelman–Rubin diagnostic); testing the proportional hazards \nassumption (very important when considering time-to-event \noutcomes); and deciding the approach to analysis, use of \nfractional polynomials, conducting feasibility analyses, etc.\nWhilst the LLM used in this study (GPT-4) showed great \npromise for extracting data, it was not 100% perfect on every \nsingle run. Future studies should investigate the practical-\nity of and effect on performance when collating data from \nrepeated extractions on each publication and taking the \nmode of results. Due to the token limit of GPT-4, it was \nnecessary to pass the publication text in chunks to the LLM, \nwhich may have affected data extraction performance. Thus, \nconsideration should also be given to improvements in per-\nformance and effect on speed when using LLMs capable \nof processing whole documents at a time (e.g. GPT-4 32k \ncontext model [32,768 tokens] or GPT-4 Turbo [128,000 \ntokens]).\nSince the study was conducted, image capabilities have \nbeen rolled out for GPT-4 [28], and multi-modal functional-\nity has been developed for other LLMs (e.g. Google’s Gem-\nini) [29]. Thus, there is now a need to determine whether this \nallows for data extraction from the image-based publications \nthat we encountered.\nIn the materials used for this study, the extracted data \nwere reported within the main text of the documents, not \nwithin tables. This meant that we could use a Python pack -\nage (PyPDF2) to convert the PDF documents to text and then \npass this text to the LLM for data extraction. Investigating \ndata extraction from tables was out of scope for the current \nstudy, but it may be possible to use the same Python package \nto parse table text from the PDF and for this to be provided \nin the correct order, to use other Python packages, such as \nOpenCV, or to pass the table as an image to a multi-modal \nLLM, which may then be able to extract the relevant data.\nOverall, the LLM produced R scripts of high quality; \nhowever, there were a few occasions when a useable script \nwas not produced. Whilst the errors in these scripts were \nvery easy to spot and fix and would be identified when \nconducting quality assurance checks of all input data and \nsoftware (as is currently applied to human-generated soft-\nware), there is a need to investigate the effect of enhanced \nprompt engineering and/or fine tuning on the quality of the R \nscript generated. Fine tuning allows users to train the model, \nmaking it follow instructions better, and consistently for -\nmat responses, a crucial aspect for applications demanding \na specific response format, such as code completion [30], a \npreview version of which was made available at the end of \n2023 for GPT-4 [30].\nThe summary report generated with the LLM was always \ninformative and accurate, but, whilst the overall sentiment of \nthe writing was preserved, the level of detail provided and \nthe exact text used varied each time this was requested. The \nreport produced was not sufficiently detailed to be used for \nan HTA appraisal but did provide an easy-to-read high-level \nreview of the analysis and could be useful in settings such \n218 T. Reason et al.\nas early HTA planning and scientific advice. Whether fine \ntuning can be used to improve the consistency of the report \nshould be investigated, along with the LLM’s ability to gen-\nerate sections of text for a full technical report.\nThe approach developed herein is not yet of sufficient \nrobustness to meet the methodological rigour required by \nHTA bodies, and it does not include some important steps \nof NMA, e.g. heterogeneity assessment. However, there \nis likely to be rapid advancement in the use of LLMs to \na point where they could be used for the majority of the \nprocess. Heterogeneity assessment and more detailed report-\ning would need to be further explored to implement fully \nautomated NMAs for HTA purposes. Furthermore, once \ncomplete automation is achieved, there will still be a need \nfor human involvement due to the requirement for human \naccountability in the process.\n4.2  Recommendations and Future Research\nWhilst we found that the LLM is currently not 100% consist-\nent, it is one of the first types of general purpose LLMs, and \nthus, there is scope for LLMs to improve with time and addi-\ntional training. The ability to use fine tuning and the intro-\nduction of better models and larger word limits are likely \nto improve the success rate seen in this study. The novel \napproach developed in this study has potential to be devel-\noped further but could already be applied to data extraction, \nsoftware script generation and to aid result interpretation \nwithin the NMA process. This would reduce the time taken \nto conduct an NMA and reduce the level of human error.\nWe would recommend that the same level of (human) \nchecking be applied to LLM extracted data and LLM gener-\nated software, as would be applied during a manual NMA \nprocess, i.e. that data extraction is checked, input data and \nsoftware used are subjected to quality assurance and any text \nand outputs produced by the LLM is sense-checked and, if \nnecessary, corrected and improved by a human.\nGiven the level of accuracy that we have observed, we \nbelieve that elements of AI should start to be incorporated \ninto the SLR and NMA workflow now. We firmly believe \nthat the accuracy issues we have encountered in this study \nare very likely to improve, and even disappear completely, \nwith time.\nFurther research could also investigate the use of LLMs \nto extract data from published tables, to add generation of \ngraphical outputs normally used to interpret NMA to the R \nscript (e.g. forest plots and network diagrams) and to provide \nadditional standard outputs (e.g. surface under the cumula-\ntive ranking curve SUCRA). Additionally, further research \ncould investigate the use of LLMs to support further \nupstream tasks, such as choosing an appropriate statistical \nmodel, using deviance information criteria (DIC) to deter -\nmine fixed or random effects, node splitting to determine \nheterogeneity, determining effect modification due to covari-\nates, deciding the approach to analysis and conducting feasi-\nbility assessments, as well as scaling the methods developed \nin this study to conduct larger NMAs. Whether an LLM \nis capable of producing a more detailed report or generat-\ning sections of text for a full technical report could also be \ninvestigated.\n5  Conclusions\nThis study offers evidence for the use of LLMs like GPT-4 \nin automating data extraction and NMA. The use of genera-\ntive AI to automate NMAs offers great potential to enable \nquicker and less costly decision making in healthcare, and \nthis potential should be further developed, so that it might \nbe harnessed and used to deliver faster patient access to \nmedicines.\nSupplementary Information The online version contains supplemen-\ntary material available at https:// doi. org/ 10. 1007/ s41669- 024- 00476-9.\nAcknowledgements The SLRs and feasibility analyses used to identify \npublications and data for the non-small cell lung cancer analyses (case \nstudies 2–4) were conducted by Precision-HEOR.\nDeclarations \nFunding This study was supported by Bristol Myers Squibb.\nConflict of interest Tim Reason, Emma Benbow, Julia Langham, and \nAndy Gimblett are consultants at Estima Scientific and have worked \non behalf of Bill Malcolm and Sven L. Klijn, who are employees and \nshareholders of Bristol Myers Squibb.\nAvailability of data and material All data generated or analysed during \nthis study are included in this published article (and its supplementary \ninformation files).\nEthics approval Not applicable.\nConsent to participate Not applicable.\nConsent for publication Not applicable.\nCode availability Examples for using R’s ‘multinma’ package were \nprovided to GPT-4 for context for the binary outcome (Beta-blockers \nexample) and time-to-event outcomes (Parkinson’s disease example). \nVignettes, including these examples, are provided here: https:// cran.r- \nproje ct. org/ web/ packa ges/ multi nma/ index. html.\nAuthor contributions T.R.: idea conceptualisation, development of \napproach and editorial input. E.B.: development of approach, critical \nappraisal of SLR and NMA and drafting versions of the paper. J.L.: \ncritical appraisal of SLR and NMA and editorial input. A.G.: Python \nand API technical input. S.L.K.: technical input and editorial input. \nW.M.: technical input and editorial input.\nOpen Access  This article is licensed under a Creative Commons Attri-\nbution-NonCommercial 4.0 International License, which permits any \n219\nAI to Automate NMAs: Potential of LLMs\nnon-commercial use, sharing, adaptation, distribution and reproduction \nin any medium or format, as long as you give appropriate credit to the \noriginal author(s) and the source, provide a link to the Creative Com-\nmons licence, and indicate if changes were made. The images or other \nthird party material in this article are included in the article's Creative \nCommons licence, unless indicated otherwise in a credit line to the \nmaterial. If material is not included in the article's Creative Commons \nlicence and your intended use is not permitted by statutory regula-\ntion or exceeds the permitted use, you will need to obtain permission \ndirectly from the copyright holder. To view a copy of this licence, visit \nhttp:// creat iveco mmons. org/ licen ses/ by- nc/4. 0/.\nReferences\n 1. Angelis A, Lange A, Kanavos P. Using health technology assess-\nment to assess the value of new medicines: results of a systematic \nreview and expert consultation across eight European countries. \nEur J Health Econ. 2018;19(1):123–52. https:// doi. org/ 10. 1007/ \ns10198- 017- 0871-0.\n 2. Jenei K, Raymakers AJN, Bayle A, Berger-Thürmel K, Cherla A, \nHonda K, et al. Health technology assessment for cancer medi-\ncines across the G7 countries and Oceania: an international, cross-\nsectional study. Lancet Oncol. 2023;24(6):624–35. https:// doi. org/ \n10. 1016/ S1470- 2045(23) 00175-4.\n 3. Barratt A, Irwig L, Glasziou P, Cumming RG, Raffle A, Hicks \nN, et al. Users’ guides to the medical literature: XVII. How to \nuse guidelines and recommendations about screening. JAMA. \n1999;281(21):2029. https:// doi. org/ 10. 1001/ jama. 281. 21. 2029.\n 4. Munn Z, Stern C, Aromataris E, Lockwood C, Jordan Z. What \nkind of systematic review should I conduct? A proposed typology \nand guidance for systematic reviewers in the medical and health \nsciences. BMC Med Res Methodol. 2018;18(1):5. https:// doi. org/ \n10. 1186/ s12874- 017- 0468-4.\n 5. Goodman C. HTA 101: essential information for newcomers. \nHealth Technology Assessment International. https:// htai. org/ wp- \nconte nt/ uploa ds/ 2023/ 06/ The- Newco mers- Guide- to- HTA-A- colle \nction- of- resou rces- for- early- career- profe ssion als-2. pdf. Accessed \n05 Jan 2024.\n 6. Rouse B, Chaimani A, Li T. Network meta-analysis: an introduc-\ntion for clinicians. Intern Emerg Med. 2017;12(1):103–11. https:// \ndoi. org/ 10. 1007/ s11739- 016- 1583-7.\n 7. McKenzie J, Brennan S, Ryan R, Thomson H, Johnston R. Chap-\nter 9: summarizing study characteristics and preparing for synthe-\nsis in Cochrane handbook for systematic reviews of interventions \nversion 64. www. train ing. cochr ane. org/ handb ook. Accessed 05 \nJan 2024.\n 8. Borah R, Brown AW, Capers PL, Kaiser KA. Analysis of the \ntime and workers needed to conduct systematic reviews of \nmedical interventions using data from the PROSPERO registry. \nBMJ Open. 2017;7(2): e012545. https:// doi. org/ 10. 1136/ bmjop \nen- 2016- 012545.\n 9. Higgins J, Thomas J, Chandler J, Cumpston M, Li T, Page M, \net al. Cochrane handbook for systematic reviews of interventions \nversion 6.4. Cochrane; 2023. http:// www. train ing. cochr ane. org/ \nhandb ook. Accessed 05 Jan 2024.\n 10. Mathes T, Klaßen P, Pieper D. Frequency of data extraction errors \nand methods to increase data extraction quality: a methodological \nreview. BMC Med Res Methodol. 2017;17(1):152. https:// doi. org/ \n10. 1186/ s12874- 017- 0431-4.\n 11. Khangura S, Konnyu K, Cushman R, Grimshaw J, Moher D. Evi-\ndence summaries: the evolution of a rapid review approach. Syst \nRev. 2012;1(1):10. https:// doi. org/ 10. 1186/ 2046- 4053-1- 10.\n 12. Rueda JD, Cristancho RA, Slejko JF. Is artificial intelligence the \nnext big thing in health economics and outcomes research? Value \nOutcomes Spotlight Magazine. 2019:22–4. https:// www. ispor.  \norg/ docs/ defau lt- source/ publi catio ns/ value- outco mes- spotl ight/ \nmarch- april-  2019/ vos- heor- artic les--- rueda.  pdf? sfvrsn=  18cb1 \n6f5_0. Accessed 05 Jan 2024.\n 13. van Dinter R, Tekinerdogan B, Catal C. Automation of system -\natic literature reviews: a systematic literature review. Inf Softw \nTechnol. 2021;136: 106589. https:// doi. org/ 10. 1016/j. infsof. 2021. \n106589.\n 14. OpenAI. GPT-4. https:// openai. com/ chatg pt. Accessed 05 Jan \n2024.\n 15. Ray PP. ChatGPT: a comprehensive review on background, appli-\ncations, key challenges, bias, ethics, limitations and future scope. \nInternet Things Cyber-Phys Syst. 2023;3:121–54. https:// doi. org/ \n10. 1016/j. iotcps. 2023. 04. 003.\n 16. Poldrack RA, Lu T, Beguš G. AI-assisted coding: experiments \nwith GPT-4. 2023. https:// arxiv. org/ abs/ 2304. 13187. Accessed 05 \nJan 2024.\n 17. Cope S, Zhang J, Saletan S, Smiechowski B, Jansen JP, Schmid P. \nA process for assessing the feasibility of a network meta-analysis: \na case study of everolimus in combination with hormonal ther -\napy versus chemotherapy for advanced breast cancer. BMC Med. \n2014;12(1):93. https:// doi. org/ 10. 1186/ 1741- 7015- 12- 93.\n 18. Cope S, Mojebi A, Popoff E, Hertel N, Korytowsky B, McKenna \nM, et al. Comparative efficacy and safety of nivolumab versus rel-\nevant treatments in pretreated advanced non-small cell lung can-\ncer: a systematic literature review and indirect treatment compari-\nson of randomized controlled trials. Copenhagen: ISPOR; 2019. \nhttps:// www. ispor. org/ docs/ defau lt- source/ euro2 019/ cope- et- al--- \ncompa rative- effic acy- and- safety- of- nivol umab- pdf. pdf? sfvrsn= \n56345 56b_0. Accessed 05 Jan 2024.\n 19. Phillippo DM. multinma: Bayesian network meta-analysis of indi-\nvidual and aggregate data https:// cran.r- proje ct. org/ web/ packa ges/ \nmulti nma/ index. html. Accessed 05 Jan 2024.\n 20. Carpenter B, Gelman A, Hoffman MD, Lee D, Goodrich B, Betan-\ncourt M, et al. Stan: a probabilistic programming language. J Stat \nSoftw. 2017;76(1). http:// www. jstat soft. org/ v76/ i01/. Accessed 05 \nJan 2024.\n 21. Wei J, Wang X, Schuurmans D, Bosma M, Ichter B, Xia F, et al. \nChain-of-thought prompting elicits reasoning in large language \nmodels. 2022. https:// arxiv. org/ abs/ 2201. 11903. Accessed 05 Jan \n2024.\n 22. OpenAI. API reference. https:// platf  orm. openai. com/ docs/ api- \nrefer ence/ chat/ create. Accessed 25 Jan 2024.\n 23. Edwards B. As ChatGPT gets “lazy,” people test “winter break \nhypothesis” as the cause. ARS Technica. 2023. https:// arste chnica. \ncom/ infor mation- techn ology/ 2023/ 12/ is- chatg pt- becom ing- lazier- \nbecau se- its- decem ber- people- run- tests- to- find- out/. Accessed 05 \nJan 2024.\n 24. Kimball AB, Jemec GBE, Alavi A, Reguiai Z, Gottlieb AB, \nBechara FG, et al. Secukinumab in moderate-to-severe hidradeni-\ntis suppurativa (SUNSHINE and SUNRISE): week 16 and week \n52 results of two identical, multicentre, randomised, placebo-con-\ntrolled, double-blind phase 3 trials. Lancet. 2023;401(10378):747–\n61. https:// doi. org/ 10. 1016/ S0140- 6736(23) 00022-3.\n 25. Cohen D. Applied Bayesian statistics using Stan and R: reproduc-\nibility. Methods Bites Tutorial. https:// www. mzes. uni- mannh eim. \nde/ socia lscie nceda talab/ artic le/ appli ed- bayes ian- stati stics/# repro \nducib ility. Accessed 30 Jan 2024.\n 26. Ollama. https:// ollama. ai. Accessed 30 Jan 2024.\n 27. Touvron H, Martin L, Stone K, Albert P, Almahairi A, Babaei Y, \net al. Llama 2: open foundation and fine-tuned chat models. ArXiv \nComput Sci. 2023. https:// doi. org/ 10. 48550/ arXiv. 2307. 09288.\n 28. OpenAI. ChatGPT can now see, hear, and speak. https:// openai.  \ncom/ blog/ chatg pt- can- now- see- hear- and- speak. Accessed 05 Jan \n2024.\n220 T. Reason et al.\n 29. Google. Gemini AI. https:// deepm ind. google/ techn ologi es/ gemin \ni/# intro ducti on. Accessed 05 Jan 2024.\n 30. OpenAI. GPT-3.5 Turbo fine-tuning and API updates. https://  \nopenai. com/ blog/ gpt-3- 5- turbo- fine- tuning- and- api- updat es. \nAccessed 05 Jan 2024.\n 31. Kimball A, Zouboulis C, Sayed C. Bimekizumab in patients with \nmoderate-to-severe HS: 48-week efficacy and safety from BE \nHEARD I & II, two phase 3, randomized, double-blind, placebo \ncontrolled, multicenter studies. In: American Academy of Der -\nmatology Annual Meeting, 2023, New Orleans, LA.\n 32. Herbst RS, Baas P, Kim DW, Felip E, Perez-Gracia JL, Han \nJY, et al. Factors associated with better overall survival (OS) in \npatients with previously treated, PD-L1-expressing, advanced \nNSCLC: Multivariate analysis of KEYNOTE-010. J Clin Oncol. \n2017;35(15_suppl):9090–9090. https:// doi. org/ 10. 1200/ JCO. \n2017. 35. 15_ suppl. 9090.\n 33. Herbst RS, Baas P, Kim DW, Felip E, Pérez-Gracia JL, Han \nJY, et  al. Pembrolizumab versus docetaxel for previously \ntreated, PD-L1-positive, advanced non-small-cell lung can -\ncer (KEYNOTE-010): a randomised controlled trial. Lancet. \n2016;387(10027):1540–50. https:// doi. org/ 10. 1016/ S0140- \n6736(15) 01281-7.\n 34. Vergnenegre A, Corre R, Berard H, Paillotin D, Dujon C, Robinet \nG, et al. Cost-effectiveness of second-line chemotherapy for non-\nsmall cell lung cancer: an economic, randomized, prospective, \nmulticenter phase iii trial comparing docetaxel and pemetrexed: \nthe GFPC 05–06 study. J Thorac Oncol. 2011;6(1):161–8. https:// \ndoi. org/ 10. 1097/ JTO. 0b013 e3182 00f4c1.\nAuthors and Affiliations\nTim Reason1 · Emma Benbow1 · Julia Langham1  · Andy Gimblett1 · Sven L. Klijn2  · Bill Malcolm3\n * Tim Reason \n tim.reason@estima-sci.com\n1 Estima Scientific, Mediaworks, 191 Wood Lane, \nLondon W12 7FP, UK\n2 Bristol Myers Squibb, Princeton, NJ, USA\n3 Bristol Myers Squibb, Uxbridge, UK",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7535626292228699
    },
    {
      "name": "Scripting language",
      "score": 0.7407037019729614
    },
    {
      "name": "Python (programming language)",
      "score": 0.6182568073272705
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4756823778152466
    },
    {
      "name": "Machine learning",
      "score": 0.46956610679626465
    },
    {
      "name": "Natural language processing",
      "score": 0.45700135827064514
    },
    {
      "name": "Data extraction",
      "score": 0.4460236132144928
    },
    {
      "name": "Data science",
      "score": 0.39593997597694397
    },
    {
      "name": "Data mining",
      "score": 0.38572192192077637
    },
    {
      "name": "Programming language",
      "score": 0.2393156886100769
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "MEDLINE",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210091812",
      "name": "Bristol-Myers Squibb (United States)",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210125795",
      "name": "Bristol-Myers Squibb (United Kingdom)",
      "country": "GB"
    }
  ]
}