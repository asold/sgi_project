{
  "title": "Automating Evaluation of AI Text Generation in Healthcare with a Large Language Model (LLM)-as-a-Judge",
  "url": "https://openalex.org/W4409709519",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5093345669",
      "name": "Emma Croxford",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2144316405",
      "name": "Yanjun Gao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5097536029",
      "name": "Elliot First",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1927182445",
      "name": "Nicholas Pellegrino",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5115911902",
      "name": "Miranda Schnier",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2132341066",
      "name": "John Caskey",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1487277841",
      "name": "Madeline Oguss",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2440412144",
      "name": "Graham Wills",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2126977617",
      "name": "Guanhua (陳冠華) Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2625526828",
      "name": "Dmitriy Dligach",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A896309055",
      "name": "Matthew M. Churpek",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1993136452",
      "name": "Anoop Mayampurath",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2138891105",
      "name": "Frank Liao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5106625715",
      "name": "Cherodeep Goswami",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2130389339",
      "name": "Karen K Wong",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2429196096",
      "name": "Brian W. Patterson",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2102230835",
      "name": "Majid Afshar",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4398225015",
    "https://openalex.org/W2152560313",
    "https://openalex.org/W3128566614",
    "https://openalex.org/W2026148049",
    "https://openalex.org/W2147733805",
    "https://openalex.org/W4401728459",
    "https://openalex.org/W4392986561",
    "https://openalex.org/W4394807113",
    "https://openalex.org/W4395703766",
    "https://openalex.org/W6979086561",
    "https://openalex.org/W4206256378",
    "https://openalex.org/W4393057994",
    "https://openalex.org/W4402909345",
    "https://openalex.org/W2139056371",
    "https://openalex.org/W4391995913",
    "https://openalex.org/W4410105807",
    "https://openalex.org/W4385572545",
    "https://openalex.org/W4404782209",
    "https://openalex.org/W2949676527",
    "https://openalex.org/W3045153201",
    "https://openalex.org/W2327037637",
    "https://openalex.org/W4234180827",
    "https://openalex.org/W1996290308"
  ],
  "abstract": "Abstract Electronic Health Records (EHRs) store vast amounts of clinical information that are difficult for healthcare providers to summarize and synthesize relevant details to their practice. To reduce cognitive load on providers, generative AI with Large Language Models have emerged to automatically summarize patient records into clear, actionable insights and offload the cognitive burden for providers. However, LLM summaries need to be precise and free from errors, making evaluations on the quality of the summaries necessary. While human experts are the gold standard for evaluations, their involvement is time-consuming and costly. Therefore, we introduce and validate an automated method for evaluating real-world EHR multi-document summaries using an LLM as the evaluator, referred to as LLM-as-a-Judge. Benchmarking against the validated Provider Documentation Summarization Quality Instrument (PDSQI)-9 for human evaluation, our LLM-as-a-Judge framework demonstrated strong inter-rater reliability with human evaluators. GPT-o3-mini achieved the highest intraclass correlation coefficient of 0.818 (95% CI 0.772, 0.854), with a median score difference of 0 from human evaluators, and completes evaluations in just 22 seconds. Overall, the reasoning models excelled in inter-rater reliability, particularly in evaluations that require advanced reasoning and domain expertise, outperforming non-reasoning models, those trained on the task, and multi-agent workflows. Cross-task validation on the Problem Summarization task similarly confirmed high reliability. By automating high-quality evaluations, medical LLM-as-a-Judge offers a scalable, efficient solution to rapidly identify accurate and safe AI-generated summaries in healthcare settings.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6214309930801392
    },
    {
      "name": "Health care",
      "score": 0.5779881477355957
    },
    {
      "name": "Language model",
      "score": 0.4984469413757324
    },
    {
      "name": "Natural language processing",
      "score": 0.471253901720047
    },
    {
      "name": "Artificial intelligence",
      "score": 0.37222838401794434
    },
    {
      "name": "Programming language",
      "score": 0.3499413728713989
    },
    {
      "name": "Political science",
      "score": 0.18243050575256348
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ],
  "institutions": []
}