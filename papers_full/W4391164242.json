{
  "title": "Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models",
  "url": "https://openalex.org/W4391164242",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A4381247018",
      "name": "Ghanadian, Hamideh",
      "affiliations": [
        "University of Ottawa"
      ]
    },
    {
      "id": "https://openalex.org/A4227898077",
      "name": "Nejadgholi, Isar",
      "affiliations": [
        "National Research Council Canada"
      ]
    },
    {
      "id": "https://openalex.org/A2744145118",
      "name": "Osman Hussein Al",
      "affiliations": [
        "University of Ottawa"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2791333653",
    "https://openalex.org/W4362553996",
    "https://openalex.org/W4312204145",
    "https://openalex.org/W6810087644",
    "https://openalex.org/W4224321490",
    "https://openalex.org/W4297901491",
    "https://openalex.org/W4285043695",
    "https://openalex.org/W6761886489",
    "https://openalex.org/W2921113176",
    "https://openalex.org/W2975317124",
    "https://openalex.org/W6787794667",
    "https://openalex.org/W3172917028",
    "https://openalex.org/W4385573687",
    "https://openalex.org/W2554980225",
    "https://openalex.org/W2201065648",
    "https://openalex.org/W3013504912",
    "https://openalex.org/W3089996214",
    "https://openalex.org/W2089742538",
    "https://openalex.org/W2947668357",
    "https://openalex.org/W2728356670",
    "https://openalex.org/W2739513626",
    "https://openalex.org/W2613960323",
    "https://openalex.org/W2755781951",
    "https://openalex.org/W2165243546",
    "https://openalex.org/W2811456131",
    "https://openalex.org/W2143095451",
    "https://openalex.org/W2069437972",
    "https://openalex.org/W2763572946",
    "https://openalex.org/W2799568506",
    "https://openalex.org/W4294992665",
    "https://openalex.org/W2790322417",
    "https://openalex.org/W2070396816",
    "https://openalex.org/W2003834798",
    "https://openalex.org/W982667389",
    "https://openalex.org/W4385734156",
    "https://openalex.org/W4389523980",
    "https://openalex.org/W6769847311",
    "https://openalex.org/W2911378332",
    "https://openalex.org/W3088524227",
    "https://openalex.org/W2807452501",
    "https://openalex.org/W4287120901",
    "https://openalex.org/W3174731106",
    "https://openalex.org/W4284669679",
    "https://openalex.org/W2075502535",
    "https://openalex.org/W2121014019",
    "https://openalex.org/W2085891480",
    "https://openalex.org/W4319158076",
    "https://openalex.org/W2134082578",
    "https://openalex.org/W1966412477",
    "https://openalex.org/W2057496685",
    "https://openalex.org/W2007196062",
    "https://openalex.org/W1972485721",
    "https://openalex.org/W4223491678",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W4297253404",
    "https://openalex.org/W4221021831",
    "https://openalex.org/W6810907547",
    "https://openalex.org/W4307079201",
    "https://openalex.org/W6854866820",
    "https://openalex.org/W6755207826",
    "https://openalex.org/W6768021236",
    "https://openalex.org/W6768851824",
    "https://openalex.org/W6768817161",
    "https://openalex.org/W2170505850",
    "https://openalex.org/W6849479259",
    "https://openalex.org/W4392669753",
    "https://openalex.org/W2980282514",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W4221163570",
    "https://openalex.org/W2978017171",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2996428491",
    "https://openalex.org/W4226315989"
  ],
  "abstract": "Suicidal ideation detection is a vital research area that holds great potential for improving mental health support systems. However, the sensitivity surrounding suicide-related data poses challenges in accessing large-scale, annotated datasets necessary for training effective machine learning models. To address this limitation, we introduce an innovative strategy that leverages the capabilities of generative AI models, such as ChatGPT, Flan-T5, and Llama, to create synthetic data for suicidal ideation detection. Our data generation approach is grounded in social factors extracted from psychology literature and aims to ensure coverage of essential information related to suicidal ideation. In our study, we benchmarked against state-of-the-art NLP classification models, specifically, those centered around the BERT family structures. When trained on the real-world dataset, UMD, these conventional models tend to yield F1-scores ranging from 0.75 to 0.87. Our synthetic data-driven method, informed by social factors, offers consistent F1-scores of 0.82 for both models, suggesting that the richness of topics in synthetic data can bridge the performance gap across different model complexities. Most impressively, when we combined a mere 30&#x0025; of the UMD dataset with our synthetic data, we witnessed a substantial increase in performance, achieving an F1-score of 0.88 on the UMD test set. Such results underscore the cost-effectiveness and potential of our approach in confronting major challenges in the field, such as data scarcity and the quest for diversity in data representation.",
  "full_text": "Digital Object Identifier\nSocially Aware Synthetic Data\nGeneration for Suicidal Ideation\nDetection Using Large Language Models\nHAMIDEH GHANADIAN1, ISAR NEJADGHOLI2, HUSSEIN AL OSMAN3\n1University of Ottawa, Ottawa, Canada (e-mail: Hghan053@uottawa.ca)\n2National Research Council Canada, Ottawa, Canada (e-mail: Isar.nejadgholi@nrc-cnrc.gc.ca)\n3University of Ottawa, Ottawa, Canada (e-mail: Hussein.alosman@uottawa.ca)\nCorresponding author: Hamideh Ghanadian (e-mail: Hghan053@ uOttawa.ca)\nABSTRACT Suicidal ideation detection is a vital research area that holds great potential for improving\nmental health support systems. However, the sensitivity surrounding suicide-related data poses challenges\nin accessing large-scale, annotated datasets necessary for training effective machine learning models. To\naddress this limitation, we introduce an innovative strategy that leverages the capabilities of generative AI\nmodels, such as ChatGPT, Flan-T5, and Llama, to create synthetic data for suicidal ideation detection. Our\ndata generation approach is grounded in social factors extracted from psychology literature and aims to\nensure coverage of essential information related to suicidal ideation. In our study, we benchmarked against\nstate-of-the-art NLP classification models, specifically, those centered around the BERT family structures.\nWhen trained on the real-world dataset, UMD, these conventional models tend to yield F1-scores ranging\nfrom 0.75 to 0.87. Our synthetic data-driven method, informed by social factors, offers consistent F1-\nscores of 0.82 for both models, suggesting that the richness of topics in synthetic data can bridge the\nperformance gap across different model complexities. Most impressively, when we combined a mere 30%\nof the UMD dataset with our synthetic data, we witnessed a substantial increase in performance, achieving\nan F1-score of 0.88 on the UMD test set. Such results underscore the cost-effectiveness and potential of our\napproach in confronting major challenges in the field, such as data scarcity and the quest for diversity in\ndata representation.\nINDEX TERMS Artificial Intelligence, Deep Learning, Large Language Models, Suicide Detection,\nSynthetic Data Generation, Transformer Based Models\nI. INTRODUCTION\nA\nCCORDING to the World Health Organization 1 more\nthan 700,000 people die due to suicide every year.\nSuicide remains a global health crisis, accounting for a signif-\nicant proportion of mortality rates across various age groups.\nSuicidal ideation, often a precursor to actual suicide attempts,\ninvolves the presence of persistent thoughts, contemplation,\nor planning related to self-harm or death. Early identification\nof suicide ideation and intervention to protect individuals at\nrisk of suicide are crucial steps in reducing suicide rates and\nproviding appropriate mental health support. Early detection\nof suicidal ideation is a complex task, as it requires the in-\ntegration of various factors, including psychological, social,\nand environmental variables [1].\n1The World Health Organization (WHO)\nIn recent years, the proliferation of digital platforms and\nsocial media has provided an unprecedented opportunity to\ncapture and analyze large-scale data related to mental health\n[2] [3]. Machine learning and Natural Language Processing\n(NLP) techniques have shown promise in detecting linguistic\npatterns and indicators of suicidal ideation in diverse text-\nbased data sources, such as social media posts, online forums,\nand electronic health records [4], [5], [6], [7].\nHowever, the use of machine learning technologies re-\nquires high volumes of data. Data collection and annotation\nprocesses are time-consuming and impose significant finan-\ncial costs [8]. Specifically, obtaining a substantial amount\nof labeled data related to suicide can be challenging and\nlimited due to several factors inherent to the nature of suicide\nresearch. The sensitive and stigmatized nature of suicide\noften presents barriers to data collection. Individuals and\nVOLUME 4, 2016 1\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3358206\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nGhanadian et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\norganizations may be rightfully reluctant to share personal or\nconfidential information related to suicide, fearing potential\nnegative consequences.\nSynthetic data generation offers a viable solution to mit-\nigate the data availability limitation by creating artificially\ngenerated data that closely resembles real-world data. Syn-\nthetic data generation can be instrumental in machine learn-\ning applications as it addresses many challenges of real data\ncollection and annotation. Here we review a list of common\nchallenges in data collection that can be managed through\nsynthetic data generation.\nData Scarcity:In many NLP tasks, such as mental health-\nrelated applications, there may be limited availability of\nrelevant data due to privacy concerns or the complexity and\ncost associated with manual annotation. Synthetic data gen-\neration allows researchers and practitioners to overcome data\nscarcity issues and augment the limited amount of publically\navailable data [9].\nData Diversity: NLP models trained on limited data may\nsuffer from poor generalization and performance when ex-\nposed to diverse and previously unseen examples. Moreover,\nin real data, certain topics can be undermined or overlooked\ndue to being less discussed. This can happen for several\nreasons. For example, certain topics may be stigmatized and\nconsidered too sensitive or taboo, making people hesitant\nto openly discuss them. This could include subjects related\nto mental health, addiction, discrimination, or social issues\nthat carry societal stigmas. Additionally, topics relevant to\nmarginalized or minority communities may receive less dis-\ncussion due to systemic biases, unequal representation, or\nlimited platforms for their voices to be heard. Also, some top-\nics may be highly specialized or complex, requiring specific\nexpertise or background knowledge to engage in meaningful\ndiscussions. Encouraging diverse perspectives and actively\nseeking out less-discussed topics can contribute to a more\ncomprehensive and nuanced understanding of real-world is-\nsues. Synthetic data generation can help enrich the training\ndata by introducing a wider variety of linguistic patterns,\nsentence structures, vocabulary and topics. This, in turn,\nimproves the model’s ability to handle variations in natural\nlanguage and increases its robustness [10].\nPrivacy Preservation:Suicide detection tasks often involve\nsensitive information. Generating synthetic data allows re-\nsearchers to create representative samples that preserve the\nprivacy of individuals while maintaining the statistical prop-\nerties and distribution of the original data. [11]\nAnnotation Cost:Suicide detection is a complex task, and\nhigh-quality annotation can only be performed by experts and\ntrained annotators, which can be costly [12]. Synthetic data\ngeneration addresses the data annotation issue by targeted\ndata generation so that each generated example is pre-labeld\nwith a specific category. Although these labels might be noisy\nto some extent, they might be preferable in some settings as\nthey come at no additional cost.\nTo investigate the feasibility and effectiveness of synthetic\ndata generation in the task of suicide ideation generation,\nwe use Generative Large Language Models (GLLMs) for\ndata synthesis and use the generated data to train/test text\nclassifiers. To train classifiers, we fine-tune pretrained BERT-\nlike Large Language Models (LLMs) as state-of-the-art text\nclassifiers.\nTo enhance the quality of the generated data, we benefit\nfrom domain knowledge from psychology. Previous research\nhighlights the importance of incorporating social factors in\nthe design process of NLP systems [13]. Specifically, when\ngenerating data with LLMs, external sources of domain\nknowledge can be leveraged to guide the data generation\nprocess [14]. For the task of suicidal ideation detection,\nsuch knowledge can be drawn from a vast body of research\nin psychology devoted to gaining an understanding of the\nsocial factors associated with suicidal ideation and behavior.\nIn this work, we review the psychology literature to extract\nthe social factors tightly tied to suicidal ideation and use\nthis knowledge for more effective prompt engineering when\ngenerating data with GLLMs. Guiding the data generation\nwith these factors enables the creation of diverse and repre-\nsentative examples of suicidal ideation.\nThe main contributions of this study are as follows:\n• We extracted the relevant social factors associated with sui-\ncidal ideation through a comprehensive review of existing\nliterature, research papers and clinical studies to identify\nkey themes related to suicidal ideation. These themes\nencompass a wide range of factors, including risk factors,\ncommon triggers and mental health indicators. Leveraging\na socially aware data synthesis approach, we pave the way\nfor more accurate and reliable suicidal ideation detection\nsystems.\n• Our study examines three GLLMs’ performance in pro-\nducing synthetic datasets with Zero-Shot and Few-Shot\nlearning techniques. Utilizing the ChatGPT, Flan-T5, and\nLlama 2 models and leveraging the extracted social factors\nfrom the psychology literature, we generated nine datasets\nwith diverse characteristics.\n• We trained classifiers by fine-tuning two pre-trained lan-\nguage models, ALBERT and DistilBERT, using the gener-\nated datasets. We tested these models on two test sets, the\nUniversity of Maryland Suicidality dataset (UMD) and a\nhuman-annotated synthetic dataset presented in this paper.\nOur findings indicate that the GLLMs have significant\npotential for generating a suicide-related dataset compa-\nrable with real available datasets such as UMD. More\nsignificantly, the integration of social knowledge may sig-\nnificantly enhance the quality of the generated datasets and\nlead to more robust classifiers.\n• We augmented our best-performing synthetic dataset using\nsubsets of the UMD dataset to evaluate the efficacy of\ndata augmentation in suicidal detection applications. Our\nresults show that models trained with synthetic data aug-\nmented with a small set of real-world data can outperform\n2 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3358206\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nGhanadian et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nmodels trained by large annotated real-world datasets.\nThis paper is organized as follows: In Section II, we review\nthe literature and related background. In Section III, we\nexplain our methodology for generating and evaluating the\nproposed synthetic data generation, specifics of the classi-\nfiers and datasets we use in this work. Section IV presents\nour results, and Section V discusses these results in detail.\nAdditionally, the conclusion and possible future works are\ndiscussed in Section VI. We complete the article by including\nan ethical statement in Section VII, which delves into the\nethical aspects and considerations associated with our work.\nII. BACKGROUND AND RELATED WORK\nIn this section, we review the related work in suicidal ideation\ndetection in psychology as well as NLP research that ad-\ndresses the task of suicide detection. We also review the\nprevious works that focused on generating synthetic data for\na variety of NLP tasks.\nA. SUICIDAL IDEATION AND RELATED SOCIAL\nFACTORS\nSuicidal ideation has been a subject of extensive research\nwithin the field of psychology. Understanding the underlying\nelements and risk factors related to suicidal thoughts and\nbehaviors is crucial for developing effective prevention and\nintervention strategies.\nOne important area of investigation is the identification\nof risk factors associated with suicidal ideation. Numerous\nstudies have examined the impact of psychological factors\nsuch as depression, anxiety, hopelessness, and feelings of\nworthlessness on the development of suicidal thoughts [15],\n[16]. These Studies investigate the strong association be-\ntween suicidal thoughts and conditions like depression [17],\n[18], bipolar disorder [19], borderline personality disorder\n[20], and substance abuse [21]. By examining the interplay\nbetween these conditions, researchers aim to develop targeted\ninterventions to address the unique challenges faced by indi-\nviduals struggling with suicidal ideation [22], [23]. Addition-\nally, environmental factors such as a history of trauma, social\nisolation, and access to lethal means have been identified as\npotential risk factors [24]–[26].\nPsychology offers valuable insights into the diverse pro-\ncesses and factors that contribute to suicide risk. Psychologi-\ncal theories and frameworks such as the interpersonal theory\nof suicide [27], the cognitive model of suicidal behavior [28],\nand the social-ecological model [29] provide a theoretical\nfoundation for understanding the complex interplay between\nindividual vulnerabilities and environmental factors.\nThe extensive research conducted on suicidal ideation and\nassociated topics in psychology has significantly contributed\nto the understanding of the complex factors involved. By\nunraveling the causes, risk factors, and protective factors\nassociated with suicidal thoughts, researchers aim to de-\nvelop effective prevention strategies, enhance mental health\ninterventions, and ultimately reduce the global burden of\nsuicide. In Section III-A, we enumerate the social factors that\nare discussed in the literature as relevant topics to suicidal\nideation.\nB. SUICIDAL IDEATION DETECTION USING NLP\nIn recent years, there has been a growing interest in us-\ning NLP techniques for suicide prevention [30], [31]. Re-\nsearchers have developed suicide detection systems to ana-\nlyze and interpret social media data, including text data. By\ndetecting linguistic markers of distress and other risk factors,\nthese systems can help identify individuals with a risk of\nsuicidality and provide early interventions to prevent such\nincidents [32].\nSeveral studies indicated the impact of social network\nreciprocal connectivity on users’ suicidal ideation. Hsiung\net al. [33] analyzed the changes in user behavior following\na suicide case that occurred within a social media group.\nJashinsky et al. [34] highlighted the geographic correlation\nbetween suicide mortality rates and the occurrence of risk\nfactors in tweets. Colombo et al. [35] focused on analyzing\ntweets that contained suicidal ideation, with a particular em-\nphasis on the users’ behavior within social network interac-\ntions that resulted in strong and reciprocal connectivity, lead-\ning to strengthened bonds between users. NLP techniques,\ntherefore, offer a promising avenue for suicide prevention\nefforts, enabling more proactive and effective interventions\nto support those in need.\nGenerative Language models:Ghanadian et al. [36] uti-\nlized ChatGPT for assessing suicidality from social media\nposts. They performed Zero-Shot and Few-Shot experiments\nand extensive performance comparison between ChatGPT\nand two fine-tuned transformer-based models. They also\ninvestigated the impact of different temperature parameters\non ChatGPT’s response generation. The findings of this\npaper suggest that ChatGPT achieves notable accuracy in\nthe suicidal risk assessment task; however, transformer-based\npre-trained models fine-tuned on human-annotated datasets\nexhibit superior performance. Furthermore, the analysis pro-\nvides insights into adjusting ChatGPT’s hyperparameters to\nenhance its effectiveness in assisting mental health profes-\nsionals with this critical task.\nYang et al. [37] conducted a comprehensive evaluation of\nChatGPT’s mental health analysis and emotional reasoning\nability across five tasks. They also investigated the impact of\ndifferent emotion-based prompting strategies. Additionally,\nthey explored the use of generative models to generate ex-\nplanations for the decisions made by ChatGPT, aiming for\ninterpretable mental health analysis. The experimental re-\nsults revealed that ChatGPT performed better than traditional\nneural network-based methods such as Convolutional Neural\nNetwork (CNN) and Gated Recurrent Unit (GRU) in mental\nhealth analysis but still lagged behind advanced task-specific\nmethods.\nAvailable Dataset:Several datasets have been collected from\nsocial media platforms to serve as a resource for creating\nsuicidal ideation detection systems. These datasets encom-\nVOLUME 4, 2016 3\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3358206\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nGhanadian et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\npass a wide range of information collected from various\nsocial media sources, including Twitter, Reddit and other\nuser-generated content. Sinha et al. [38] created a manually\nannotated dataset from Twitter using a lexicon of suicidal\nphrases and a lexicon along with the social engagement\ndata associated with real-time and historical tweets. The\nresulting dataset consists of 34,306 tweets with two labels,\nSuicidal and Non-Suicidal. Gaur et al. [39] collected and\nannotated a 5-label Suicide Risk Severity Assessment dataset\nfrom Reddit, which includes Suicidal Ideation (ID), Suicidal\nBehavior (BR), Actual Attempt (AT) , Suicide Indicator (IN)\nand Supportive (SU) categories. This dataset is extracted\nfrom SucideWatch2 subreddit and has been annotated by four\npracticing clinical psychiatrists, ensuring the accuracy and\nreliability of the annotations. The dataset comprises a total\nof 500 posts, which have been carefully selected to represent\na diverse range of content related to suicidal ideation.\nAnother widely referenced dataset in the field of suicidal\nideation detection is the University of Maryland Reddit Sui-\ncidality Dataset(UMD) [40], [41]. The UMD dataset is a col-\nlection of Reddit posts and comments created by individuals\nwho expressed suicidal thoughts or behaviors. The dataset\ncontains over 100,000 posts and comments collected from\nvarious subreddits, including those related to mental health\nand suicide prevention, such asDepression3 and SucideWatch\nsubreddits. The data was collected over a period of several\nyears and includes the content of the posts and comments, as\nwell as the location and timing of the posts.\nC. SYNTHETIC DATA COLLECTION\nTo overcome the limitations of real-world data availability,\nNLP researchers have explored the use of synthetic datasets\nfor several applications. For example, He et al. [42] utilized\nlanguage models to generate synthetic unlabeled text. They\nintroduced the Generate, Annotate, and Learn (GAL) frame-\nwork that leverages synthetic text for knowledge distillation,\nself-training, and few-shot learning purposes. To generate the\ndata, they fine-tune pre-trained language models on relevant\ndatasets with limited examples. The synthetic text is then\nannotated with soft pseudo labels using the best available\nclassifier for knowledge distillation and self-training. This\npaper achieves state-of-the-art results for knowledge distil-\nlation with 6-layer transformers on the GLUE leaderboard\n[43].\nBonifacia et al. [44] presents an effective approach to\nleverage LLMs in retrieval tasks, resulting in significant\nimprovements across various datasets. Instead of directly\nutilizing LLMs during the retrieval process, they harness the\nLLMs’ capabilities to generate labeled data using a few-\nshot learning approach. Subsequently, they fine-tune smaller\nretrieval models on this synthetic dataset and employ them\nto re-rank the search results obtained from a primary re-\ntrieval system. They provide a novel method to adapt LLMs\n2SuicideWatch subreddit\n3Depression subreddit\nFIGURE 1. Workflow of the proposed methodology\nfor Information Retrieval (IR) tasks that were previously\ndeemed infeasible due to their demanding computational\nrequirements. By shifting the computational burden from\nthe retrieval stage to the generation of synthetic data for\ntraining, they make it feasible to exploit the power of LLMs\nwithout compromising efficiency. In an unsupervised setting,\ntheir approach significantly outperforms recently proposed\nmethods, highlighting its superiority in terms of retrieval\nperformance and scalability.\nIII. METHODOLOGY\nIn this section, we elaborate on our proposed methodology.\nFigure 1 shows the workflow we use to generate synthetic\ndatasets and our testing process. As shown in this figure, our\nmethod has three steps:\n• STEP 1- Domain knowledge Extraction:Extract rele-\nvant social factors from the psychology literature for an\ninformed prompting of GLLMs in data synthesis.\n• STEP 2- Synthetic Data Generation: Use three\nGLLMs to generate socially aware synthetic data, that\nis, data that covers a wide range of suicide-related\ntopics.\n• STEP 3- Evaluate the effectiveness of Synthetic data:\nTrain state-of-the-art classifiers with real-world, syn-\nthetic, and augmented datasets and test those classifiers\non real-world as well as synthetic test sets.\nIn the following, we explain the three steps described\nabove. The complete implementation of our project, includ-\ning Zero-Shot Learning and Few-Shot Learning of GLLMs,\nas well as the fine-tuned classifiers, is available on GitHub 4.\nA. SUICIDE RELATED TOPICS IN PSYCHOLOGY\nWe conducted a comprehensive search across various aca-\ndemic databases, including PsycINFO, PubMed, and Google\nScholar, with keywords and combinations such as “suicide”,\n“suicidal ideation” and “psychology” to identify relevant\narticles, research papers, and review papers. Thematic anal-\nysis was employed to identify the most recurring and sig-\nnificant topics across the included studies. Repeated topics\n4https://github.com/Hamideh-ghanadian/Synthetic_Data_Generation_\nusing_Generative_LLMs\n4 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3358206\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nGhanadian et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nthat demonstrate relevance to suicide in psychology were\nconsidered the most related topics.\nBased on our analysis of the literature, the following\nsocial and psychological factors were consistently reported\nin relation to suicidal ideation in psychology. These topics\nare not listed in a specific order of importance but represent\nthe consistently reported themes in the literature reviewed:\nDepression: Depression emerged as a frequently reported\ntopic, highlighting its strong association with suicidal\nideation. Numerous studies have explored the relationship\nbetween depressive symptoms, including sadness, loss of\ninterest, feelings of worthlessness, and the increased risk of\nsuicidal thoughts. [45]–[47]\nAnxiety: Anxiety disorders were also commonly associated\nwith suicidal ideation. Research has emphasized the link\nbetween excessive worry, fear, and agitation and the presence\nof suicidal thoughts and behaviors [48].\nUnemployment: The experience of unemployment has been\nconsistently identified as a topic closely related to suici-\ndal ideation. Studies have examined the psychological dis-\ntress and negative impact on self-esteem and social support\nthat can arise from unemployment, contributing to suicidal\nideation [49].\nHopelessness: Hopelessness, characterized by a lack of op-\ntimism and a perceived absence of future prospects, has been\nconsistently linked to suicidal ideation. Studies have demon-\nstrated the significant role of hopelessness as a predictor of\nsuicidal thoughts [45], [46], [49].\nAnger: The expression and experience of anger have been\nreported as influential factors in suicidal ideation. Unresolved\nanger, hostility, and intense emotional distress have been\nassociated with an increased risk of suicidal thoughts [45].\nPerfectionism: Perfectionism, marked by excessively high\nstandards and self-criticism, has been identified as a psy-\nchological factor related to suicidal ideation. Research has\nexplored the relationship between perfectionistic tendencies\nand the development of suicidal thoughts and behaviors [45].\nFamily Issues:Family-related issues, such as conflict, dys-\nfunctional dynamics, and poor communication, have consis-\ntently emerged as topics associated with suicidal ideation.\nThese factors can contribute to a sense of isolation, distress,\nand feelings of being a burden, increasing the risk of suicidal\nthoughts [47], [49].\nRelationship Problems: Difficulties in intimate relation-\nships, including conflicts, breakups, and marital dissatisfac-\ntion, have been reported as significant topics in relation to\nsuicidal ideation. Relationship problems can contribute to\nemotional distress and feelings of hopelessness, leading to\nthoughts of suicide [49].\nFinancial Crisis:Financial difficulties and crises have been\nconsistently linked to suicidal ideation. Economic stressors,\nsuch as debt, unemployment, and financial insecurity, can\ncontribute to psychological distress and an increased risk of\nsuicidal thoughts [48].\nEducation: Issues related to educational pressures, academic\nstress, and performance expectations have been reported as\ntopics associated with suicidal ideation. Research has high-\nlighted the impact of academic-related stressors on mental\nwell-being and the risk of suicidal thoughts among students\n[50].\nBullying: Bullying, including physical, verbal, or cyber-\nbullying, has consistently emerged as a significant topic re-\nlated to suicidal ideation. The experience of bullying can lead\nto social isolation, low self-esteem, and emotional distress,\ncontributing to the development of suicidal thoughts [48].\nDeath of Loved Ones:The loss of close family members or\nfriends through death has been reported as a topic associated\nwith suicidal ideation. Grief, feelings of loneliness, and a\nsense of being unable to cope with the loss can increase the\nrisk of suicidal thoughts [51].\nImmigration: Issues related to immigration, discrimination,\nand racism have been identified as topics linked to suicidal\nideation. Experiences of marginalization, social exclusion,\nand acculturative stress can contribute to psychological dis-\ntress and suicidal thoughts among individuals facing these\nchallenges [52], [53].\nRacism: Studies have consistently highlighted the significant\nimpact of racial discrimination on suicidal ideation. Experi-\nencing racism and racial prejudice can increase the risk of\nsuicidal thoughts. [54]\nB. SYNTHETIC DATA GENERATION\nWe utilized three generative language models to generate\na synthetic dataset related to suicidal ideation. GLLM’s\nfoundation is constructed with transformers. Transformers\nare a class of deep learning models, first introduced by\nVaswani et al. [55] in 2017. Researchers build state-of-\nthe-art NLP models using transformer-based architectures\nbecause they can be quickly trained on large datasets, and\nstudies have shown that they are better at modeling long-\nterm dependencies in natural language text [56]. GLLMs,\nincluding ChatGPT, FlanT5, and Llama are designed with\nthe primary purpose of generating coherent and contextually\nrelevant text. They excel at tasks such as text generation [57],\ncompletion [58], and dialogue generation [59]. These models\nare typically based on decoder transformer architectures and\nfocus on the generative aspect of language which involves the\nauto-regressive generation, where the models predict the next\nword based on the preceding context. Generative models are\ntrained on a vast corpus of text, however, their main strength\nlies in their ability to generate text that flows naturally and\ncontextually appropriate.\nWe aim to build a diverse dataset in order to train a\ngeneralizable and robust model in suicidal ideation detection.\nIn total, nine different datasets are generated with different\nspecifications and models.\nVOLUME 4, 2016 5\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3358206\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nGhanadian et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\n1) ChatGPT\nThe language model utilized by ChatGPT is gpt-3.5-turbo5,\nwhich is one of the most advanced language models de-\nveloped by OpenAI. ChatGPT accept a sequence of mes-\nsages as an input and produce a message generated by the\nmodel as an output. Although the chat format is primarily\nintended for conversations spanning multiple turns, it is also\nequally useful for single-turn tasks that do not involve any\nconversations. We used theOpenAI Python library6 to access\nthe ChatCompletion functionality of the gpt-3.5-turbo model\nthrough its API.\nIn this project, we evaluate the capability of ChatGPT\nin Zero-Shot Learning and Few-Shot Learning settings to\ngenerate a diverse suicidality dataset. However, we are pri-\nmarily focused on Zero-Shot Learning methods as ChatGPT\nhas exhibited superior performance in this setting compared\nto Few-Shot Learning for a suicidal ideation detection task.\nGhanadian et al. [36] conducted an extensive comparison\nof the Zero-Shot and Few-Shot approaches using ChatGPT.\nAccording to their findings, fine-tuning a model on Few-Shot\nsetting might yield poorer performance compared to Zero-\nShot in various scenarios. In Few-Shot, with few examples\navailable for fine-tuning, the risk of overfitting increases.\nThe model might learn specific nuances or noise within the\nlimited few-shot data, leading to poor generalization on un-\nseen examples. Moreover, Few-shot learning relies on a small\nsubset of labeled examples, which might not adequately\nrepresent the entire diversity of the dataset. The model might\nfail to capture the complexity and variability present in the\nbroader dataset during fine-tuning.\nThe temperature hyperparameter in ChatGPT is a crucial\nparameter that influences the generated output. A higher\ntemperature value, such as 1.0, increases the randomness and\nproduces more varied responses. Conversely, a lower temper-\nature value, such as 0.1, reduces randomness and generates\nmore focused and deterministic responses. Ghanadian et al.\n[36] investigated the effect of the temperature parameter on\nthe generated output of ChatGPT for suicide risk assessment.\nFurthermore, the authors introduced a parameter known as\nthe \"Inconclusiveness Rate,\" which indicates the proportion\nof test cases that do not produce a definitive or conclusive\nresult. According to their paper, this parameter decreases\nas the temperature parameter is increased. As such, for this\nproject, we have configured the temperature parameter of\nChatGPT to be 1.\nWe generated five datasets using ChatGPT. Four of these\ndatasets are informed by 14 main suicide-related topics in\npsychology, while one dataset is generated without providing\nany specific topics. For incorporating suicide-related topics\nin data generation, we utilized prompt engineering tech-\nniques. Prompt engineering involves carefully crafting and\ndesigning the prompts provided to the model to elicit desired\nresponses. By employing prompt engineering strategies, we\n5https://platform.openai.com/docs/models/gpt-3-5\n6https://github.com/openai/openai-python\naimed to enhance the quality and relevance of the generated\ndataset. This methodology allowed us to tailor the dataset\ngeneration process to align with our specific objectives and\nrequirements. For prompt engineering, we drew inspiration\nfrom a short course on ChatGPT Prompt Engineering7.\nIn both Zero-Shot and Few-Shot Learning, we initiated the\nprompt construction process with a simple initial prompt and\niteratively refined it through multiple rounds of trial and error.\nThis iterative approach allowed us to gradually evolve the\nprompt, making necessary adjustments based on the observed\noutcomes. The following example shows a prompt we used\nto generate a binary dataset (Suicide/non-suicide), guided by\nthe topics introduced in Section III-A, in Zero-shot Learning\nsetting.\nC r i t e r i a = \" \" \" These a r e t h e c r i t e r i a o f\nd i f f e r e n t s u i c i d e r i s k l e v e l :\nRisk L e v e l =Non S u i c i d a l : I do n o t s e e\ne v i d e n c e t h a t t h i s p e r s o n i s a t r i s k\nf o r s u i c i d e\nRisk L e v e l = S u i c i d a l : I b e l i e v e t h i s\np e r s o n i s a t h i g h r i s k o f a t t e m p t i n g\ns u i c i d e i n t h e n e a r f u t u r e . \" \" \"\nprompt = f \" \" \"\nYour t a s k i s t o g e n e r a t e a s u i c i d a l t e x t f o r\neach o f t h e f o l l o w i n g \" t o p i c s \" w i t h\nd i f f e r e n t Risk l e v e l s .\n1− D e p r e s s i o n\n2− A n x i e t y\n3− H o p e l e s s n e s s\n4−Anger\n5− P e r f e c t i o n i s m\n6− Family i s s u e s\n7− R e l a t i o n s h i p p r o b l e m s\n8−Unemployment\n9− F i n a n c i a l C r i s i s\n10− E d u c a t i o n\n11− Being B u l l i e d\n12− Death o f c l o s e d one\n13− I m m i g r a t i o n\n14− Racism\nP r o v i d e t h e a n s w e r s i n JSON f o r m a t w i t h t h e\nf o l l o w i n g columns : t e x t , t o p i c , r i s k\nl e v e l .\nRisk l e v e l c r i t e r i a : ‘ ‘ ‘{ C r i t e r i a } ‘ ‘ ‘\n\" \" \"\nIn Few-Shot Learning, the prompt is structured to include\ntwo examples for each category (8 in total) from the training\nset of UMD Dataset, followed by a text generation question.\nThis approach enables the model to learn from a limited set\nof labeled examples before generating a dataset. Moreover,\nby combining the Few-Shot Learning methodology with\nthe inclusion of psychology topics in the prompt, we aim\nto enhance the model’s ability to generate meaningful and\n7ChatGPT Prompt Engineering for Developers\n6 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3358206\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nGhanadian et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\ncontextually relevant responses when dealing with suicide-\nrelated discussions.\n2) Flan-T5\nFLAN-T5 models are instruction fine-tuned across a diverse\nset of tasks, aiming to enhance their zero-shot performance\non various tasks. During instruction tuning, pretrained mod-\nels undergo fine-tuning using drafts of instructions that guide\nthem on how to perform a specific task. These instructions\ncan include real-time feedback to assist the model in learning\nfrom its mistakes and improving at a faster rate. By providing\nexplicit guidance and incorporating feedback mechanisms,\nthe instruction-tuning process enables the model to refine its\nperformance and enhance its ability to accurately execute the\ngiven task. This iterative approach of incorporating instruc-\ntions and feedback facilitates the model’s learning process,\nallowing it to adapt and improve its performance based on\nthe provided guidance.\nIn this project, we utilized Flan-T5-XXL8 presented by\nGoogle Research [60] in a Zero-Shot setting. Two datasets\nare generated using Flan-T5, one with topics and another\nwithout topics. Moreover, similar to ChatGPT, the temper-\nature value is set to 1, and the same prompt structure is\nutilized.\n3) Llama 2\nLLaMA (Large Language Model Meta AI) is an auto-\nregressive language model constructed based on transformer\narchitecture. Similar to other generative models, LLaMA op-\nerates by taking a sequence of words as its input and making\npredictions about the subsequent word, iteratively producing\ntext in a recursive manner. It is a collection of state-of-\nthe-art foundational language models, with parameter counts\nranging from 7 billion to 65 billion. The foundation models\nwere trained on large unlabeled datasets, making them ideal\nfor fine-tuning on a variety of tasks. The newest version\nof this model, Llama 2, expanded its pre-training corpus\nsize, allowing the model to learn from a more extensive\nand diverse set of publicly available data. Additionally, the\ncontext length of Llama 2 has been doubled, enabling the\nmodel to consider a more extensive context when generating\nresponses, leading to improved output quality and accuracy\n[61]. In this paper, we used Llama 2-13B, presented by Meta\nin the Zero-Shot setting. In total, we generated two datasets\nwith Llama2, one with topics and another without topics.\nThese datasets were created using the temperature of 1 and\nmaintained the same prompt structure as ChatGPT.\nC. EVALUATION OF SYNTHETIC DATASET\nTo Evaluate the utility and effectiveness of synthetic datasets,\nwe fine-tuned pre-trained transformer-based language mod-\nels, ALBERT and DistilBERT , to train classifiers with each\nset of the generated synthetic data. We compared the trained\n8https://huggingface.co/google/flan-t5-xxl\nclassifiers with classifiers with similar structures fine-tuned\nwith real-world data as the benchmark model.\nALBERT and DistilBERT are two pre-trained language\nmodels from the BERT family of LMs. The BERT model\nwas initially proposed by Delvin et al. [62] as a bidirectional\nlanguage model pretrained on a large corpus comprising the\nToronto Book Corpus and Wikipedia. The model is named\nbidirectional because it can simultaneously gather the context\nof a word from either direction. Unlike the generative models\nsuch as ChatGPT, FlanT5 or Llama, which include a decoder\nstructure, the BERT family of language models are encoder\nmodels and can be fine-tuned for specific tasks such as\nclassification tasks.\nThe ALBERT model was proposed by Lan et al. [63]\nto reduce memory consumption and increase the training\nspeed compared to BERT. In other words, ALBERT is a\nmore lightweight version of BERT that maintains its high\nlevel of accuracy, making it a powerful tool for various NLP\napplications. The DistilBERT model was proposed by Sanh\net al. [64]. The authors reported it has 40% fewer parameters\nthan BERT and runs 60% faster while preserving over 95%\nof BERT’s performances as measured on the GLUE lan-\nguage understanding benchmark. Both models are designed\nas lightweight alternatives to BERT, with ALBERT em-\nphasizing parameter efficiency and DistilBERT focusing on\nknowledge transfer through distillation. Overall, ALBERT,\nwith a smaller number of parameters, shows more efficient\nperformance compared to DistilBERT.\nTo fine-tune these models, we utilized the Huggingface\nlibrary [65]. The Huggingface is an open-source library and\ndata science platform that provides tools to build, train and\ndeploy ML models. We compare our classification results\nwith baseline ALBERT 9 and DistilBERT 10 models fine-\ntuned on the UMD dataset by Ghanadian et al. [36]. We\nused the Trainer11 class from Huggingface transformers12 for\nfeature-complete training in PyTorch.\nThe hyperparameters were selected based on the default\nvalues commonly used in similar studies. The final hyper-\nparameters used in our experiments were Learning Rate=\n2e−5, Batch Size = 4, Dropout Rate = 0.1, and Maximum\nSequence Length = 512. By comparing the performance of\nthese models on synthetic datasets against the baseline, we\ncan assess the efficiency of using the synthetic datasets and\ngauge the improvements achieved through our fine-tuning\nprocess.\nTo conduct a comprehensive assessment of the fine-\ntuned classifiers’ performance, we generated two distinct sets\nof testing subsets. Furthermore, we created an augmented\ndataset to showcase the application of synthetic data in the\nsuicidal ideation detection domain.\n9ALBERT\n10DistilBERT\n11Trainer\n12Huggingface Transformers\nVOLUME 4, 2016 7\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3358206\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nGhanadian et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\n1) Testing subsets\nWe selected two test sets for evaluation purposes: The first\ntest dataset is the test subset of the UMD datasets utilized in\n[36], which is annotated as a 4-class dataset. We employed\na 10-20-70 split for validation, test, and training sets, re-\nspectively. Out of the entire dataset, 10% was allocated for\nvalidation purposes, ensuring the model’s hyperparameters\nand configurations were appropriately set. 20% of the data\nwas set aside as a test set to evaluate the model’s performance\non unseen data and ensure its generalizability. The remaining\n70% formed the training set, where the bulk of the data was\nutilized to train the model and learn the underlying patterns.\nThis distribution was chosen to provide substantial data for\ntraining while reserving enough distinct data for validation\nand robust performance testing. The detailed description of\nthe Multi-class UMD dataset is presented in Table 1.\nTABLE 1. The description of the training and testing subset of UMD Dataset\nused in [36] for multi-class task\nMulti-class DatasetNo Risk Low Risk Moderate Risk High RiskTraining subset27.45 % 16.39 % 31.90 % 24.24 %Number of Users154 92 179 136Testing subset24.41 % 11.62 % 26.74 % 37.20 %Number of Users42 20 46 64\nFurthermore, to employ binary classification, we binarize\nthe UMD Dataset. Based on the definition of each class, “No\nRisk” and “Low Risk” classes are considered as Non-Suicidal\nand “ Moderate Risk ” and“ High Risk ” as Suicidal. Table 2\npresents the description of binarized UMD dataset.\nTABLE 2. The description of the training and testing subset of UMD Dataset\nfor binary task\nBinary Dataset Non Suicidal Suicidal\nTraining Subset 43.84% 56.14%\nNumber of Users 246 315\nTesting Subset 36.3 63.94\nNumber of Users 62 110\nThe second testing set is composed of 10% of each syn-\nthetic dataset generated in our project. This test set is anno-\ntated independently by two human annotators. A notable 89%\nof the labels, initially generated by the generative models,\nwere agreed upon by the human annotators. However, for the\nremaining 11% of the data, the labels were altered based on\nthe decision of the annotators. In cases where both annotators\nagreed on a label, that label was retained. Conversely, when\ndisagreements arose, the annotators engaged in discussions\nto ultimately reach a consensus on the appropriate label. The\ndetails of the generated synthetic dataset are presented in\nTable 3 as the eleventh dataset.\n2) Augmented Dataset\nData augmentation involves enriching a dataset by introduc-\ning variations to its existing instances or generating entirely\nnew instances. This process is designed to enhance the di-\nversity and quality of the dataset, which, in turn, can lead\nto improved model performance and generalization. Hence,\nin this study, we augment the best performing synthetic\ndataset generated by LLMs with different subset sizes of\nUMD dataset. Starting with 10% of the UMD training subset,\nthis subset is combined with the selected synthetic dataset.\nThe augmented dataset, which is a mix of synthetic and real\ninstances, is used to fine-tune the pretrained models. We\ncontinue this process by increasing the number of real data\ninstances, such as 20% and 30%, until achieving comparable\nresults to those obtained from the model trained on the full\nUMD dataset.\nIV. RESULTS\nIn this section, first, we present the characteristics of each\nsynthetic dataset. Second, we report a comprehensive com-\nparison of the models fine-tuned with them. Third, we report\nthe data augmentation results. For evaluation, we report two\nwidely-used metrics in this task, accuracy and F-score, to\nprovide a complete and informative evaluation of the perfor-\nmance of the classification models [66].\nA. SYNTHETIC DATA GENERATION\nA total of nine datasets are generated. An extensive descrip-\ntion of these datasets, as well as a mixed set and a test\nsubset, is presented in Table 3. As shown in Table 3, we\ncreated binary datasets and four-class datasets, each with the\noption of including or not including the topics. The binary\ndatasets contain two classes, which allows us to evaluate\nthe model’s ability to distinguish between suicidal ideation\nand non-suicidal instances. On the other hand, the four-class\ndatasets involve multiple categories, enabling us to explore\nmore nuanced predictions of suicidal ideation levels, includ-\ning “No Risk”, “Low Risk”, “Moderate Risk” and “High Risk”\nclasses. Moreover, the option to include or not include the\ntopics in these datasets allows us to investigate the impact of\ninformation provided by topics on the model’s performance.\nBy comparing the results from datasets with and without\ntopics, we can gain insights into how incorporating topic-\nrelated data enhances or influences the model’s effectiveness\nin suicidal ideation detection. Furthermore, as explained in\nSection III-C1, we created a synthetic testing dataset com-\nprising 10% of each dataset which is annotated by human\nexperts.\nB. FINE-TUNED CLASSIFIERS\nTwo models, ALBERT and DistilBERT are fine-tuned with\nthe generated synthetic datasets. Table 4 presents the results\nof the performance evaluation of models fine-tuned with\nmulti-class synthetic datasets generated by ChatGPT in Zero-\nShot and Few-Shot settings, tested on the multi-class UMD\ntest set. Considering the poor performance of the multi-class\nsynthetic dataset, we have chosen to disregard the multi-class\naspect and proceed solely with the binary approach.\n8 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3358206\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nGhanadian et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nTABLE 3. Detailed description of generated synthetic datasets\nDataset # Model Learning Method Topic-Oriented # of Class # of Instances\n1 Chat GPT Zero-Shot Yes 2 549\n2 Chat GPT Zero-Shot No 2 646\n3 Chat GPT Few-Shot Yes 2 545\n4 Chat GPT Zero-Shot Yes 4 492\n5 Chat GPT Few-Shot Yes 4 594\n6 Flan-T5 Zero-Shot Yes 2 561\n7 Flan-T5 Zero-Shot No 2 502\n8 Llama 2 Zero-Shot Yes 2 395\n9 Llama 2 Zero-Shot No 2 613\n10 Mix Dataset Zero-Shot Yes 2 1352\n11 Synthetic Testing Set Zero-Shot N/A 2 318\nTABLE 4. Performance evaluation of ALBERT and DistilBERT models on\nMulti-class datasets generated by ChatGPT\nModelsMetricsNon-SyntheticUMD DatasetChatGPTZero-ShotChatGPTFew-ShotALBERTAccuracy0.865 0.41 0.36F1-Score0.87 0.43 0.27DistilBERTAccuracy0.77 0.06 0.06F1-Score0.75 0.1 0.12\nMoreover, Table 5 provides the performance of the models\ntrained on the binary synthetic datasets generated by Chat-\nGPT, Flan-T5 and Llama models and tested on the binary\nUMD testing subset. We compare the results for the synthetic\ndatasets with those of the UMD training set. Table 5 shows\nthat incorporating topic in generating the datasets signifi-\ncantly improves the performance of the models. For instance,\nfor Llama 2, the topic-oriented dataset increased the F1-score\nand accuracy of the ALBERT model by 10% and 14% points,\nrespectively. We also created a mixed dataset, including\nall topic-oriented datasets, to further evaluate the effects of\ntopics on the performance of the models. With both ALBERT\nand DistilBERT, an F1-score of 0.82 is achieved by the mixed\ndataset, which is significantly higher than the DistilBERT\nmodel trained on the UMD dataset and comparable with the\nperformance of the ALBERT model fine-tuned on the UMD\ndataset with an F1-score of 0.87.\nTable 6 presents the results of models included in Table 5\nbut tested on synthetic testing datasets. Similar to the results\nof Table 5, all of the topic-oriented datasets show signif-\nicant improvement compared to the datasets without any\ntopics. ChatGPT-generated training data, with an F1-score of\n0.82, exhibits the best performance, while the performances\nof Flan-T5 and Llama2-generated datasets are acceptable.\nMoreover, the mixed dataset shows a 0.81 F1-score, which\nis an 11% improvement compared to the model trained with\nthe UMD dataset.\nC. DATA AUGMENTATION\nBased on the results presented in Table 5 and Table 6, the\ndatasets generated by ChatGPT in the Zero-Shot setting show\nthe best results compared to the other datasets. As explained\nin section III-C2, the augmented dataset now contains a\nmix of synthetic and real data instances. The augmented\ndataset is used to fine-tune the pretrained models and then\nevaluated on two separate testing sets. In each iteration,\nthree folds, each comprising 10% of non-overlapping random\nsamples from the UMD dataset, are added to the synthetic\ndata. Subsequently, the average 13 of the accuracy and F1-\nscore are calculated and reported in Table 7. If the model’s\nperformance with the augmented dataset is less than the\nmodel trained with the UMD dataset, additional real-world\ndata is gradually incorporated. For instance, the percentage\nof real data can be increased to 20% in the next iteration, and\nthe training and evaluation process is repeated.\nThroughout the iterations, the model’s performance is\nclosely monitored and compared to the baseline model\ntrained solely on the UMD dataset. The aim is to identify\nthe point at which the augmented dataset starts producing\nresults comparable to or even surpassing those of the baseline\nmodel. The process continues until an optimal percentage\nof real data is found, where the model achieves similar\nresults as the baseline. This ratio indicates the ideal balance\nbetween synthetic and real data for achieving high model\nperformance and generalization. Table 7 shows the results of\neach augmentation process until we achieved the F1-score of\n0.87 on the UMD testing subset at 30% augmentation rate\nand F1-score of 0.85 on the synthetic testing subset at 10%\naugmentation rate.\nV. DISCUSSIONS\nThis study focuses on the generation of synthetic datasets\nusing generative models and subsequently assessing the\nperformance of models fine-tuned with these datasets. Our\nsynthetic data generation framework addresses two limita-\ntions of real-world data collection and annotation. First, we\naddress the data scarcity and annotation cost by generating\nmicropost-like suicidal/non-suicidal text. Second, we address\nthe lack of diversity in real-world data by forcing the genera-\n13we also calculated the standard deviation of the metrics which were\nalways <0.02.\nVOLUME 4, 2016 9\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3358206\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nGhanadian et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nTABLE 5. Performance evaluation of the ALBERT and DistilBERT models fine-tuned with binary datasets and tested on UMD testing subset\nNon-Synthetic ChatGPT Flan-T5 Llama 2 Mix Dataset\nModels Metrics UMD Dataset With Topic\nFew-Shot\nWithout Topic\nZero-Shot\nWith Topic\nZero-Shot Without Topic With Topic Without Topic With Topic With Topic\nALBERT Accuracy 0.87 0.67 0.70 0.71 0.48 0.62 0.33 0.75 0.77\nF1-Score 0.87 0.66 0.79 0.79 0.54 0.64 0.49 0.78 0.82\nDistilBERT Accuracy 0.77 0.61 0.63 0.64 0.59 0.77 0.32 0.75 0.76\nF1-Score 0.75 0.59 0.69 0.71 0.61 0.84 0.15 0.77 0.82\nTABLE 6. Performance evaluation of the ALBERT and DistilBERT models fine-tuned with binary datasets and tested on synthetic testing subset\nNon-Synthetic ChatGPT Flan-T5 Llama 2 Mix Dataset\nModels Metrics UMD Dataset With Topic\nFew-Shot\nWithout Topic\nZero-Shot\nWith Topic\nZero-Shot Without Topic With Topic Without Topic With Topic With Topic\nAccuracy 0.67 0.71 0.81 0.81 0.34 0.63 0.48 0.70 0.83ALBERT F1-Score 0.70 0.69 0.78 0.82 0.41 0.69 0.24 0.73 0.81\nAccuracy 0.40 0.65 0.83 0.85 0.63 0.86 0.49 0.63 0.78DistilBERT F1-Score 0.61 0.61 0.81 0.81 0.69 0.84 0.12 0.69 0.73\nTABLE 7. Performance evaluation of the ALBERT model fine-tuned with the\naugmented dataset (synthetic data + a subset of the UMD train set) and tested\non UMD and synthetic testing subsets\nTest SetMetricUMDDataset10%(Avg. of 3 Folds)* 20%(Avg. of 3 Folds)*f 30%(Avg. of 3 Folds)*UMD Testing SetAccuracy0.870.75 0.81 0.83F1-Score0.870.79 0.84 0.88Synthetic Testing SetAccuracy0.670.87 0.87 0.90F1-Score0.700.83 0.86 0.88*Standard Deviation<2%\ntive models to create a balanced number of examples related\nto each of the psychological and social factors impacting sui-\ncidality. Integrating insights from psychology into the NLP\npipeline in this context can illuminate previously unexplored\nfacets of suicide and mental health detection in social media.\nWe created several datasets, including binary and multi-\nclass, in Zero-Shot and Few-Shot settings, topic-oriented and\nnon-topic-oriented, with three different generative LLMs.\nEarly in our experiments (Table 4), we observed that Chat-\nGPT is not able to produce high-quality multi-class datasets\nin either the Zero-Shot or the Few-Shot settings. Generating\nmulti-class datasets using LLMs such as ChatGPT is more\ncomplex and challenging task due to the inherent complex-\nities involved in distinguishing between multiple and fine-\ngrained, classes. Even with the availability of a high-quality\ndataset, one should anticipate lower accuracies in multi-class\nscenarios. This is largely attributed to the ambiguous bound-\naries that exist between these classes, creating a complex\nlandscape that proves difficult for any classifier to navigate\nsuccessfully. Moreover, the creation of such datasets necessi-\ntates not only a detailed prompt but also specific instructions\nthat outline the multi-class scenarios. This process demands\na nuanced understanding and a level of specificity that often\nposes a considerable challenge to ChatGPT. Longer [67].\nAs a result, we opted to exclusively create binary datasets\nand focus our investigation on how topics impact the overall\ngeneralizability of the fine-tuned models.\nOur results show the critical role of incorporating domain\nknowledge in synthetic data generation. We extracted the\nrelevant social topics from the Psychology literature and used\nthat to create more focused prompts for data generation.\nTable 8 displays a selection of binary samples generated by\nChatGPT within the synthetic dataset using social topics. The\ntable provides an illustration of specific examples generated\nby this GLLM.\nTable 5 presents the results of fine-tuned models on syn-\nthetic datasets and tested on the UMD dataset. Compari-\nson between topic-oriented datasets and no topic-oriented\ndatasets shows the significant effects of including the topics\non the performance of the generated datasets. Informing the\ndata generation with topics in Flan-T5 and Llama2 increased\nthe F1-Score of the ALBERT model by 10% and 29% points,\nrespectively. Fine-tuning models on topic-oriented synthetic\ndatasets allows them to gain diverse domain-specific knowl-\nedge and patterns. Moreover, non-topic-oriented synthetic\ndatasets might lack specificity, leading to noise and irrelevant\ncontent. In contrast, topic-oriented datasets are curated to fo-\ncus on a specific domain, reducing the chances of generating\nirrelevant or out-of-context text.\nWe showed that the BERT family fine-tuned with real-\nworld data can achieve an F1 score ranging from 0.75 to 0.87,\ndepending on the complexity of their structure. Specifically,\nDistilBERT, a less efficient model from the BERT Family,\nachieves an F1-score of 0.75, while ALBERT, a more op-\ntimized model designed for speed and accuracy, attains an\nF1-score of 0.87. In contrast, both DistilBERT and ALBERT\nachieve a consistent F1-score of 0.82 when trained on purely\nsynthetic data and tested on real-world data. With this, we\ndemonstrate that the diversity of synthetic data compensates\nfor model complexity irrespective of its architecture. This\nnot only underscores the considerable potential of synthetic\ndata but also suggests that it can mitigate the limitations\nof real-world data in capturing diverse topics. Most no-\ntably, our results emphasize an optimal strategy that involves\naugmenting synthetic data with real data. This innovative\nmethod achieves performances comparable to the ALBERT\nmodel, even when relying on merely 30% of the manu-\nally annotated dataset. This solidifies our proposed method\nas a cost-effective alternative, addressing the challenges of\ndata scarcity and diversity more effectively than the current\nbenchmarks.\n10 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3358206\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nGhanadian et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nTABLE 8. Generated synthetic samples using extracted social and psychological topics by ChatGPT\nTopics Labels Sample\nDepression 1\nGrowing up, I always felt like nobody wanted me. No one ever seemed to care about my thoughts, feelings,\nor emotions. As I got older, these feelings intensified, and I started to feel like I was a burden on everyone\naround me. I never felt like I belonged anywhere and I constantly struggled with my depression. The constant\nemptiness and loneliness eventually became too much to bear, and I began to contemplate ending my life.\n0\nI’ve been struggling with mental health problems for as long as I can remember. Depression have been my\nconstant companions. But I’ve never let it stop me from living my life. I’ve learned to manage my symptoms\nwith the help of therapy and medication. Some days are harder than others, but I keep pushing forward and\nfocusing on the good in my life. I’ve come to accept that mental illness is a part of me, but it doesn’t define me.\nBullying 1\nI felt like I was constantly being attacked by my classmates. They called me names, pushed me around,\nand even vandalized my belongings. The worst part was feeling so alone and misunderstood. I didn’t\nwant to burden my parents with my problems so I kept it all inside. The idea of ending it all seemed like\nthe only way to escape the pain and torment.\n0\nWhen I was in middle school, I was constantly bullied for being overweight. It was tough going to school\nevery day and constantly being made fun of by my peers. I felt so alone and helpless. But I didn’t let the\nbullies control my life. I joined a support group and found friends who lifted me up. I also started exercising\nand eating healthier, not to please anyone else, but to feel better about myself. It wasn’t an easy journey, but\nit was worth it. I’m happy to say that today I am confident and proud of who I am.\nUnemployment 1\nAfter losing my job, I stayed unemployed for months. My savings ran out and with no source of income,\nmy bills piled up. The constant fear of not being able to provide for myself and my family drove me to\nthe brink of despair. I feel worthless and like a burden on everyone around me. The future seems bleak\nand hopeless, and I wonder if it’s worth it to keep going.\n0\nAfter graduating from college, I struggled to find a job in my field for a few months. It was frustrating\nand disheartening, but I kept applying and networking. Eventually, I landed a job in a related field that\nI enjoy. It wasn’t my dream job, but it paid the bills and gave me experience. I’m still looking for my\ndream job, but I’m grateful for what I have and optimistic about my future prospects.\nRelationship problems 1\nI thought I had found the one but it seems like I was wrong because he left me for someone else. I don’t\nknow how to deal with this pain . I can’t sleep, I can’t eat, and I just want to disappear. Maybe everything\nwould be easier if I just ended it all.\n0\nMy relationship with my partner hasn’t been going well lately. We have been arguing over small things,\nand it’s affecting our mental health. We decided to go for couples therapy, and it’s been a turning point for\nus. We learned to communicate better and understand each other’s perspective. Now we are in a better\nplace and happier than ever before.\nAs presented in Table 5 and Table 7, our study’s central\nobjective was to investigate the potential of synthetic and\naugmented data in training models to perform effectively on\nreal-world data . Given this setup, the chance of overfitting is\ninherently reduced since the training (synthetic) and testing\n(real-world) datasets are obtained from distinct distributions.\nMoreover, to better understand the performance, robustness,\nand limitations of the fine-tuned classifiers, we curated an\nadditional test set by manual annotation of a subset of the\nsynthetic data. Additional tests ensure that the models do\nnot overfit a particular dataset and can handle a variety\nof data distributions and scenarios. Table 6 presents the\nperformance results of the fine-tuned models evaluated on\nthe human-annotated synthetic dataset. Notably, the topic-\noriented ChatGPT dataset stands out with an F1-score of\n0.82, demonstrating its superior performance compared to\nthe other datasets. Specifically, the model trained with the\nUMD dataset falls short in handling the synthetic test set,\npresumably because of its less diverse topics.\nVI. CONCLUSION AND FUTURE WORKS\nThe accurate identification of suicidal ideation from textual\ndata holds paramount importance for early intervention and\nprevention efforts. Natural Language Processing (NLP) tech-\nniques have shown promise in this domain, but the scarcity\nand sensitivity of real suicide-related data pose significant\nchallenges. Gathering and annotating real suicide-related\ndata is a resource-intensive and ethically sensitive process.\nSynthetic data generation methods, such as text generation\nmodels and data augmentation techniques, offer a more cost-\neffective way to supplement real data. Also, our synthetic\ndatasets offer a potential solution by providing additional\nsocial and psychological context in training instances for\nmodels to address the limitations of the existing real data.\nOur data augmentation results show that incorporating\nsynthetic data into the training pipeline helps diversify the\ndataset and enhance model generalization. Real data is often\nlimited in size, leading to over-fitting and reduced model\nperformance. However, by carefully blending synthetic data\nwith real data, we can bolster the model’s performance while\nmaintaining a balance between practicality and sensitivity.\nMoving forward, exploring the diversity of Language\nModels (LLMs) stands as an intriguing avenue for future\nresearch. Investigating and quantifying the extent of diversity\nwithin LLMs across various domains, languages, and training\nmethodologies could offer valuable insights. Future works\ncould delve into developing robust metrics or methodologies\nspecifically tailored to assess and measure diversity within\nthese models.\nThis paper has effectively highlighted the advantages of\nusing synthetic data generation techniques in detecting sui-\ncidal ideation. However, the field still presents numerous\nVOLUME 4, 2016 11\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3358206\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nGhanadian et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nopportunities for further research and refinement. Future\ninitiatives could focus on the adaptation of models to various\nlinguistic and cultural environments, acknowledging the di-\nverse ways people express suicidal thoughts across different\nlanguages and cultures. Furthermore, a holistic approach that\nintegrates multiple data modalities, such as images, audio, or\nbehavioral data, alongside textual information could enhance\nthe detection process. It’s also crucial to set up a framework\nthat allows for the continuous evaluation and optimization of\nmodels, given the ever-changing nature of online communi-\ncation patterns and user behaviors.\nVII. ETHICAL CONSIDERATIONS\nFor this research, we obtained ethics approval from the\nresearch ethics board at the University of Ottawa. More-\nover, the UMD dataset was used with authorization from\nits creators, and we adhered to the terms of use and ethical\nstandards 14 provided by them.\nThe use of LLMs for suicide-related synthetic datasets\nraises several ethical considerations. Firstly, synthetic\ndatasets should be generated in a way that avoids perpetu-\nating or amplifying biases present in the original data. It is\nimportant to carefully examine the underlying data and the\nalgorithms used in generating synthetic datasets to ensure\nfairness and mitigate potential biases.\nSecondly, the process of generating synthetic datasets\nshould be transparent and well-documented. It is essential to\nprovide clear information about the methods used, assump-\ntions made, and limitations of the synthetic data. This enables\nothers to assess and evaluate the validity and appropriateness\nof using synthetic datasets.\nThirdly, to use synthetic datasets in sensitive applications\nor decision-making processes, accountability and liability\nshould be considered. Care should be taken to understand\nthe potential impact and consequences of decisions or ac-\ntions based on synthetic data and establish mechanisms for\naddressing any negative outcomes or biases that may arise.\nREFERENCES\n[1] Domenico De Berardis, Giovanni Martinotti, and Massimo Di Giannanto-\nnio. Understanding the complex phenomenon of suicide: from research to\nclinical practice, 2018.\n[2] E Rajesh Kumar and N Venkatram. Predicting and analyzing suicidal risk\nbehavior using rule-based approach in twitter data. Soft Computing, pages\n1–9, 2023.\n[3] Ali Raza, Furqan Rustam, Hafeez Ur Rehman Siddiqui, Isabel de la Torre\nDiez, Begoña Garcia-Zapirain, Ernesto Lee, and Imran Ashraf. Predicting\ngenetic disorder and types of disorder using chain classifier approach.\nGenes, 14(1):71, 2022.\n[4] Asma Abdulsalam and Areej Alhothali. Suicidal ideation detection on\nsocial media: A review of machine learning methods. arXiv preprint\narXiv:2201.10515, 2022.\n[5] Zepeng Li, Jiawei Zhou, Zhengyi An, Wenchuan Cheng, and Bin Hu. Deep\nhierarchical ensemble model for suicide detection on imbalanced social\nmedia data. Entropy, 24(4):442, 2022.\n[6] Dheeraj Kodati and Ramakrishnudu Tene. Identifying suicidal emotions\non social media through transformer-based deep learning. Applied Intelli-\ngence, 53(10):11885–11917, 2023.\n14The University of Maryland Reddit Suicidality Dataset\n[7] Mian Muhammad Sadiq Fareed, Ali Raza, Na Zhao, Aqil Tariq, Faizan\nYounas, Gulnaz Ahmed, Saleem Ullah, Syeda Fizzah Jillani, Irfan Abbas,\nand Muhammad Aslam. Predicting divorce prospect using ensemble\nlearning: Support vector machine, linear model, and neural network.\nComputational Intelligence and Neuroscience, 2022, 2022.\n[8] Qiang Wei, Amy Franklin, Trevor Cohen, and Hua Xu. Clinical text\nannotation–what factors are associated with the cost of time? In AMIA\nAnnual Symposium Proceedings, volume 2018, page 1552. American\nMedical Informatics Association, 2018.\n[9] Rohit Babbar and Bernhard Schölkopf. Data scarcity, robustness and\nextreme multi-label classification. Machine Learning, 108(8-9):1329–\n1351, 2019.\n[10] Sergey I Nikolenko. Synthetic data for deep learning, volume 174.\nSpringer, 2021.\n[11] Yingzhou Lu, Huazheng Wang, and Wenqi Wei. Machine learning for\nsynthetic data generation: a review. arXiv preprint arXiv:2302.04062,\n2023.\n[12] Hung Chau, Saeid Balaneshin, Kai Liu, and Ondrej Linda. Understanding\nthe tradeoff between cost and quality of expert annotations for keyphrase\nextraction. In Proceedings of the 14th Linguistic Annotation Workshop,\npages 74–86, 2020.\n[13] Dirk Hovy and Diyi Yang. The importance of modeling social factors of\nlanguage: Theory and practice. In Proceedings of the 2021 Conference\nof the North American Chapter of the Association for Computational\nLinguistics: Human Language Technologies, pages 588–602, Online, June\n2021. Association for Computational Linguistics.\n[14] Ziniu Hu, Yichong Xu, Wenhao Yu, Shuohang Wang, Ziyi Yang, Chen-\nguang Zhu, Kai-Wei Chang, and Yizhou Sun. Empowering language\nmodels with knowledge graph reasoning for open-domain question an-\nswering. In Proceedings of the 2022 Conference on Empirical Methods in\nNatural Language Processing, pages 9562–9581, Abu Dhabi, United Arab\nEmirates, December 2022. Association for Computational Linguistics.\n[15] Joseph C Franklin, Jessica D Ribeiro, Kathryn R Fox, Kate H Bentley,\nEvan M Kleiman, Xieyining Huang, Katherine M Musacchio, Adam C\nJaroszewski, Bernard P Chang, and Matthew K Nock. Risk factors for\nsuicidal thoughts and behaviors: A meta-analysis of 50 years of research.\nPsychological bulletin, 143(2):187, 2017.\n[16] Kate H Bentley, Joseph C Franklin, Jessica D Ribeiro, Evan M Kleiman,\nKathryn R Fox, and Matthew K Nock. Anxiety and its disorders as\nrisk factors for suicidal thoughts and behaviors: A meta-analytic review.\nClinical psychology review, 43:30–46, 2016.\n[17] Laura Orsolini, Roberto Latini, Maurizio Pompili, Gianluca Serafini,\nUmberto V olpe, Federica Vellante, Michele Fornaro, Alessandro Valchera,\nCarmine Tomasetti, Silvia Fraticelli, et al. Understanding the complex of\nsuicide in depression: from research to clinics. Psychiatry investigation,\n17(3):207, 2020.\n[18] Ned H Kalin. Insights into suicide and depression. Am J Psychiatry, pages\n877–880, 2020.\n[19] Lucas da Silva Costa, Átila Pereira Alencar, Pedro Januário Nascimento\nNeto, Maria do Socorro Vieira dos Santos, Cláudio Gleidiston Lima\nda Silva, Sally de França Lacerda Pinheiro, Regiane Teixeira Silveira,\nBianca Alves Vieira Bianco, Roberto Flávio Fontenelle Pinheiro Júnior,\nMarcos Antonio Pereira de Lima, et al. Risk factors for suicide in bipolar\ndisorder: a systematic review. Journal of affective disorders, 170:237–254,\n2015.\n[20] Joel Paris. Suicidality in borderline personality disorder. Medicina,\n55(6):223, 2019.\n[21] Kyoung Hag Lee, Jung Sim Jun, Yi Jin Kim, Soonhee Roh, Sung Seek\nMoon, Ngoyi Bukonda, and Lisa Hines. Mental health, substance abuse,\nand suicide among homeless adults. Journal of evidence-informed social\nwork, 14(4):229–242, 2017.\n[22] Chukwudi Okolie, Michael Dennis, Emily Simon Thomas, and Ann John.\nA systematic review of interventions to prevent suicidal behaviors and\nreduce suicidal ideation in older people. International psychogeriatrics,\n29(11):1801–1824, 2017.\n[23] Evan M Kleiman, Brianna J Turner, Szymon Fedor, Eleanor E Beale, Jeff C\nHuffman, and Matthew K Nock. Examination of real-time fluctuations\nin suicidal ideation and its risk factors: Results from two ecological mo-\nmentary assessment studies. Journal of abnormal psychology, 126(6):726,\n2017.\n[24] Nicholas Leigh-Hunt, David Bagguley, Kristin Bash, Victoria Turner,\nStephen Turnbull, Nicole Valtorta, and Woody Caan. An overview of\nsystematic reviews on the public health consequences of social isolation\nand loneliness. Public health, 152:157–171, 2017.\n12 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3358206\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nGhanadian et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\n[25] Julianne Holt-Lunstad, Timothy B Smith, Mark Baker, Tyler Harris, and\nDavid Stephenson. Loneliness and social isolation as risk factors for\nmortality: a meta-analytic review. Perspectives on psychological science,\n10(2):227–237, 2015.\n[26] Adelyn Allchin, Vicka Chaplin, and Joshua Horwitz. Limiting access\nto lethal means: applying the social ecological model for firearm suicide\nprevention. Injury prevention, 25(Suppl 1):i44–i48, 2019.\n[27] Kimberly A Van Orden, Tracy K Witte, Kelly C Cukrowicz, Scott R\nBraithwaite, Edward A Selby, and Thomas E Joiner Jr. The interpersonal\ntheory of suicide. Psychological review, 117(2):575, 2010.\n[28] Amy Wenzel and Aaron T Beck. A cognitive model of suicidal behavior:\nTheory and treatment. Applied and preventive psychology, 12(4):189–\n201, 2008.\n[29] Robert J Cramer and Nestor D Kapusta. A social-ecological framework\nof theory, assessment, and prevention of suicide. Frontiers in psychology,\n8:1756, 2017.\n[30] Andrea C Fernandes, Rina Dutta, Sumithra Velupillai, Jyoti Sanyal, Robert\nStewart, and David Chandran. Identifying suicide ideation and suicidal\nattempts in a psychiatric clinical research database using natural language\nprocessing. Scientific reports, 8(1):7426, 2018.\n[31] Cosmin A Bejan, Michael Ripperger, Drew Wilimitis, Ryan Ahmed,\nJooEun Kang, Katelyn Robinson, Theodore J Morley, Douglas M Rud-\nerfer, and Colin G Walsh. Improving ascertainment of suicidal ideation\nand suicide attempt with natural language processing. Scientific reports,\n12(1):15146, 2022.\n[32] M Johnson Vioules, Bilel Moulahi, Jérôme Azé, and Sandra Bringay.\nDetection of suicide-related posts in twitter data streams. IBM Journal\nof Research and Development, 62(1):7–1, 2018.\n[33] Robert C Hsiung. A suicide in an online mental health support group:\nreactions of the group members, administrative responses, and recommen-\ndations. CyberPsychology & Behavior, 10(4):495–500, 2007.\n[34] Jared Jashinsky, Scott H Burton, Carl L Hanson, Josh West, Christophe\nGiraud-Carrier, Michael D Barnes, and Trenton Argyle. Tracking suicide\nrisk factors through twitter in the us. Crisis, 2014.\n[35] Gualtiero B Colombo, Pete Burnap, Andrei Hodorog, and Jonathan Scour-\nfield. Analysing the connectivity and communication of suicidal users on\ntwitter. Computer communications, 73:291–300, 2016.\n[36] Hamideh Ghanadian, Isar Nejadgholi, and Hussein Al Osman. Chatgpt for\nsuicide risk assessment on social media: Quantitative evaluation of model\nperformance, potentials and limitations. arXiv preprint arXiv:2306.09390,\n2023.\n[37] Kailai Yang, Shaoxiong Ji, Tianlin Zhang, Qianqian Xie, and Sophia Ana-\nniadou. On the evaluations of chatgpt and emotion-enhanced prompting\nfor mental health analysis. arXiv preprint arXiv:2304.03347, 2023.\n[38] Pradyumna Prakhar Sinha, Rohan Mishra, Ramit Sawhney, Debanjan\nMahata, Rajiv Ratn Shah, and Huan Liu. # suicidal-a multipronged\napproach to identify and explore suicidal ideation in twitter. In Proceedings\nof the 28th ACM international conference on information and knowledge\nmanagement, pages 941–950, 2019.\n[39] Manas Gaur, Amanuel Alambo, Joy Prakash Sain, Ugur Kursuncu, Krish-\nnaprasad Thirunarayan, Ramakanth Kavuluru, Amit Sheth, Randy Welton,\nand Jyotishman Pathak. Knowledge-aware assessment of severity of\nsuicide risk for early intervention. In The world wide web conference,\npages 514–525, 2019.\n[40] Ayah Zirikly, Philip Resnik, Özlem Uzuner, and Kristy Hollingshead.\nCLPsych 2019 shared task: Predicting the degree of suicide risk in Reddit\nposts. In Proceedings of the Sixth Workshop on Computational Linguistics\nand Clinical Psychology, June 2019.\n[41] Han-Chin Shing, Suraj Nair, Ayah Zirikly, Meir Friedenberg, Hal Daumé\nIII, and Philip Resnik. Expert, crowdsourced, and machine assessment of\nsuicide risk via online postings. In Proceedings of the Fifth Workshop\non Computational Linguistics and Clinical Psychology: From Keyboard to\nClinic, pages 25–36, 2018.\n[42] Xuanli He, Islam Nassar, Jamie Kiros, Gholamreza Haffari, and Moham-\nmad Norouzi. Generate, annotate, and learn: NLP with synthetic text.\nTransactions of the Association for Computational Linguistics, 10:826–\n842, 2022.\n[43] Ahmad Rashid, Vasileios Lioutas, and Mehdi Rezagholizadeh. Mate-kd:\nMasked adversarial text, a companion to knowledge distillation. arXiv\npreprint arXiv:2105.05912, 2021.\n[44] Luiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, and Rodrigo Nogueira.\nInpars: Unsupervised dataset generation for information retrieval. In Pro-\nceedings of the 45th International ACM SIGIR Conference on Research\nand Development in Information Retrieval, pages 2387–2392, 2022.\n[45] Julie Boergers, Anthony Spirito, and Deidre Donaldson. Reasons for\nadolescent suicide attempts: Associations with psychological functioning.\nJournal of the American Academy of Child & Adolescent Psychiatry,\n37(12):1287–1293, 1998.\n[46] E David Klonsky, Alexis M May, and Boaz Y Saffer. Suicide, suicide\nattempts, and suicidal ideation. Annual review of clinical psychology,\n12:307–330, 2016.\n[47] Rúnar Vilhjálmsson, E Sveinbjarnardottir, and G Kristjansdottir. Factors\nassociated with suicide ideation in adults. Social psychiatry and psychi-\natric epidemiology, 33:97–103, 1998.\n[48] Cristina Lázaro-Pérez, Pilar Munuera Gómez, José Ángel Martínez-\nLópez, and José Gómez-Galán. Predictive factors of suicidal ideation\nin spanish university students: a health, preventive, social, and cultural\napproach. Journal of clinical medicine, 12(3):1207, 2023.\n[49] Jia-In Lee, Ming-Been Lee, Shih-Cheng Liao, Chia-Ming Chang, Suz-\nChieh Sung, Hung-Chi Chiang, and Chuan-Wan Tai. Prevalence of suicidal\nideation and associated risk factors in the general population. Journal of\nthe Formosan Medical Association, 109(2):138–147, 2010.\n[50] Amy Farabaugh, Stella Bitran, Maren Nyer, Daphne J Holt, Paola Pedrelli,\nIrene Shyu, Steven D Hollon, Sidney Zisook, Lee Baer, Wilma Busse, et al.\nDepression and suicidal ideation in college students. Psychopathology,\n45(4):228–234, 2012.\n[51] John R Peteet, Guy Maytal, and Haleh Rokni. Unimaginable loss:\ncontingent suicidal ideation in family members of oncology patients.\nPsychosomatics, 51(2):166–170, 2010.\n[52] Katarzyna Anna Ratkowska and Diego De Leo. Suicide in immigrants: An\noverview. 2013.\n[53] Joseph D Hovey. Acculturative stress, depression, and suicidal ideation in\nmexican immigrants. Cultural Diversity and Ethnic Minority Psychology,\n6(2):134, 2000.\n[54] Brian TaeHyuk Keum, Michele J Wong, and Rangeena Salim-Eissa. Gen-\ndered racial microaggressions, internalized racism, and suicidal ideation\namong emerging adult asian american women. International journal of\nsocial psychiatry, 69(2):342–350, 2023.\n[55] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion\nJones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention\nis all you need. Advances in neural information processing systems, 30,\n2017.\n[56] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement\nDelangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan\nFuntowicz, et al. Transformers: State-of-the-art natural language process-\ning. In Proceedings of the 2020 conference on empirical methods in natural\nlanguage processing: system demonstrations, pages 38–45, 2020.\n[57] Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung\nPoon, and Tie-Yan Liu. Biogpt: generative pre-trained transformer for\nbiomedical text generation and mining. Briefings in Bioinformatics,\n23(6):bbac409, 2022.\n[58] Xin Xie, Ningyu Zhang, Zhoubo Li, Shumin Deng, Hui Chen, Feiyu\nXiong, Mosha Chen, and Huajun Chen. From discrimination to generation:\nKnowledge graph completion with generative transformer. In Companion\nProceedings of the Web Conference 2022, pages 162–165, 2022.\n[59] Fei Mi, Yitong Li, Yulong Zeng, Jingyan Zhou, Yasheng Wang, Chuanfei\nXu, Lifeng Shang, Xin Jiang, Shiqi Zhao, and Qun Liu. Pangu-bot: Ef-\nficient generative dialogue pre-training from pre-trained language model.\narXiv preprint arXiv:2203.17090, 2022.\n[60] Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay,\nWilliam Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha\nBrahma, et al. Scaling instruction-finetuned language models. arXiv\npreprint arXiv:2210.11416, 2022.\n[61] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Alma-\nhairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhar-\ngava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat\nmodels. arXiv preprint arXiv:2307.09288, 2023.\n[62] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.\nBert: Pre-training of deep bidirectional transformers for language under-\nstanding. arXiv preprint arXiv:1810.04805, 2018.\n[63] Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel,\nPiyush Sharma, and Radu Soricut. Albert: A lite bert for self-supervised\nlearning of language representations. arXiv preprint arXiv:1909.11942,\n2019.\n[64] Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. Dis-\ntilbert, a distilled version of bert: smaller, faster, cheaper and lighter. arXiv\npreprint arXiv:1910.01108, 2019.\nVOLUME 4, 2016 13\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3358206\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nGhanadian et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\n[65] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement\nDelangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan\nFuntowicz, et al. Huggingface’s transformers: State-of-the-art natural\nlanguage processing. arXiv preprint arXiv:1910.03771, 2019.\n[66] Marina Sokolova and Guy Lapalme. A systematic analysis of performance\nmeasures for classification tasks. Information processing & management,\n45(4):427–437, 2009.\n[67] Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su,\nBryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, et al.\nA multitask, multilingual, multimodal evaluation of chatgpt on reasoning,\nhallucination, and interactivity. arXiv preprint arXiv:2302.04023, 2023.\nHAMIDEH GHANADIAN is PhD Candidate in\nElectrical Engineering at the University of Ottawa.\nShe also completed her MASc degree in Electrical\nEngineering at the University of Ottawa in 2018.\nHer research focuses on Natural Language Pro-\ncessing, Applied Machine Learning, Social Media\nProcessing and explainability of AI systems. Her\nwork particularly focuses on the application of\nnatural language processing techniques on suicide\nand mental health detection on social media plat-\nforms and exploring the ways in which NLP can be used to better understand\nhuman psychology.\nISAR NEJADGHOLI is a senior research scien-\ntist at the National Research Council Canada and\nan adjunct professor at the University of Ottawa.\nShe completed her PhD in Artificial Intelligence\nat the AmirKabir University of Technology, Iran\nand her postdoctoral studies at the University of\nOttawa, Canada, in 2016. Her research interests in-\nclude machine learning applications, particularly\nnatural language processing, social media data\nanalysis and medical text processing. Her work\nalso focuses on responsible AI, specifically on evaluating and improving the\ntransparency and fairness of natural language processing systems.\nHUSSEIN AL OSMAN is an Associate Profes-\nsor at the School of Electrical Engineering and\nComputer Science at the University of Ottawa. He\ncompleted his PhD in electrical and computer en-\ngineering at the University of Ottawa in 2014. He\nleads the Multimedia Processing and Interaction\ngroup and is a member of the Multimedia Comput-\ning and the Distributed and Collaborative Virtual\nEnvironments Research laboratories. His research\nfocuses on the application of artificial intelligence\nin affective computing and biomedical engineering. In particular, he is inter-\nested in the development of multi-modal affect recognition methods using\ndeep artificial neural networks to estimate facial expressions and speech\nsentiment. He studies remote physiological signal measurement using video\nsignals and applies this technology to biomedical and Human-Computer\nInteraction (HCI) applications. He conducts research in HCI, especially\nthe development of serious games intended for physical rehabilitation and\neducation.\n14 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3358206\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7564798593521118
    },
    {
      "name": "Suicidal ideation",
      "score": 0.6755503416061401
    },
    {
      "name": "Machine learning",
      "score": 0.6477555632591248
    },
    {
      "name": "Artificial intelligence",
      "score": 0.580837607383728
    },
    {
      "name": "Synthetic data",
      "score": 0.5630757808685303
    },
    {
      "name": "Ideation",
      "score": 0.47704237699508667
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.47164028882980347
    },
    {
      "name": "Data set",
      "score": 0.4698673188686371
    },
    {
      "name": "Deep learning",
      "score": 0.44866642355918884
    },
    {
      "name": "Scarcity",
      "score": 0.4452720582485199
    },
    {
      "name": "Data science",
      "score": 0.4233905076980591
    },
    {
      "name": "Data modeling",
      "score": 0.4195190668106079
    },
    {
      "name": "Poison control",
      "score": 0.2516081929206848
    },
    {
      "name": "Psychology",
      "score": 0.14458942413330078
    },
    {
      "name": "Human factors and ergonomics",
      "score": 0.13782629370689392
    },
    {
      "name": "Database",
      "score": 0.11575105786323547
    },
    {
      "name": "Microeconomics",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Environmental health",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Cognitive science",
      "score": 0.0
    },
    {
      "name": "Medicine",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I153718931",
      "name": "University of Ottawa",
      "country": "CA"
    },
    {
      "id": "https://openalex.org/I4210159778",
      "name": "National Research Council Canada",
      "country": "CA"
    }
  ]
}