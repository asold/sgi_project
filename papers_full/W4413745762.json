{
  "title": "DropMicroFluidAgents (DMFAs): autonomous droplet microfluidic research framework through large language model agents",
  "url": "https://openalex.org/W4413745762",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2537068088",
      "name": "Dinh Nguyen Nguyen",
      "affiliations": [
        "Chinese University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A4201743981",
      "name": "Raymond Kai-yu Tong",
      "affiliations": [
        "Chinese University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A4318113123",
      "name": "Ngoc‐Duy Dinh",
      "affiliations": [
        "Chinese University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A2537068088",
      "name": "Dinh Nguyen Nguyen",
      "affiliations": [
        "Chinese University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A4201743981",
      "name": "Raymond Kai-yu Tong",
      "affiliations": [
        "Chinese University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A4318113123",
      "name": "Ngoc‐Duy Dinh",
      "affiliations": [
        "Chinese University of Hong Kong"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2086187432",
    "https://openalex.org/W2991097214",
    "https://openalex.org/W2148892249",
    "https://openalex.org/W4366487542",
    "https://openalex.org/W2041209212",
    "https://openalex.org/W2613101787",
    "https://openalex.org/W2586637063",
    "https://openalex.org/W3038080702",
    "https://openalex.org/W2564176045",
    "https://openalex.org/W2886125669",
    "https://openalex.org/W2952630931",
    "https://openalex.org/W2135937351",
    "https://openalex.org/W2102212449",
    "https://openalex.org/W3013072344",
    "https://openalex.org/W4401584820",
    "https://openalex.org/W2118131251",
    "https://openalex.org/W3157560583",
    "https://openalex.org/W3135338903",
    "https://openalex.org/W2345850129",
    "https://openalex.org/W2586737496",
    "https://openalex.org/W2115008041",
    "https://openalex.org/W4205506001",
    "https://openalex.org/W4288540357",
    "https://openalex.org/W3119505952",
    "https://openalex.org/W3099990658",
    "https://openalex.org/W3024867841",
    "https://openalex.org/W2977416072",
    "https://openalex.org/W4401339781",
    "https://openalex.org/W4324308135",
    "https://openalex.org/W4408765527",
    "https://openalex.org/W4387393188",
    "https://openalex.org/W4389991792",
    "https://openalex.org/W4385027818",
    "https://openalex.org/W4391561379",
    "https://openalex.org/W4396723768",
    "https://openalex.org/W4393153069",
    "https://openalex.org/W4392168151",
    "https://openalex.org/W4392913756",
    "https://openalex.org/W4327550249",
    "https://openalex.org/W4386529373",
    "https://openalex.org/W2911489562",
    "https://openalex.org/W4386530347",
    "https://openalex.org/W4380887490",
    "https://openalex.org/W4389475249",
    "https://openalex.org/W4353034336",
    "https://openalex.org/W4392002118",
    "https://openalex.org/W4390545914",
    "https://openalex.org/W4389625705",
    "https://openalex.org/W4390011017",
    "https://openalex.org/W4392193048",
    "https://openalex.org/W4384155367",
    "https://openalex.org/W4365143687",
    "https://openalex.org/W4385849028",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W4385490607",
    "https://openalex.org/W4319332853",
    "https://openalex.org/W4386593096",
    "https://openalex.org/W4327946446",
    "https://openalex.org/W4390507962",
    "https://openalex.org/W4390535718",
    "https://openalex.org/W4400931359",
    "https://openalex.org/W4404848909",
    "https://openalex.org/W3199256401",
    "https://openalex.org/W3135358749",
    "https://openalex.org/W4318486595",
    "https://openalex.org/W4409886498",
    "https://openalex.org/W4392805407",
    "https://openalex.org/W4409768533",
    "https://openalex.org/W4397004462",
    "https://openalex.org/W4406140557"
  ],
  "abstract": "DropMicroFluidAgents (DMFAs) is a novel multi-agent-based framework designed to perform diverse tasks and make decisions autonomously, guided by its programming and the data it analyses.",
  "full_text": "DropMicroFluidAgents (DMFAs): autonomous\ndroplet microﬂuidic research framework through\nlarge language model agents\nDinh-Nguyen Nguyen, Raymond Kai-Yu Tong and Ngoc-Duy Dinh*\nLarge language models (LLMs) have gained signiﬁcant attention in recent years due to their impressive\ncapabilities across various tasks, from natural language understanding to generation. Applying LLMs\nwithin speciﬁc domains requires substantial adaptation to account for the unique terminologies,\nnuances, and context-speci ﬁc challenges inherent to those areas. Here, we introduce\nDropMicroFluidAgents (DMFAs) employing LLM agents to perform two key functions: (1) delivering\nfocused guidance, answers, and suggestions speciﬁc to droplet microﬂuidics and (2) generating machine\nlearning models to optimise and automate the design of droplet microﬂuidic devices, including the\ncreation of code-based computer-aided design (CAD) scripts to enable rapid and precise design\nexecution. To assess the accuracy of DMFAs in question–answering tasks, we compiled a dataset of\nquestions with corresponding ground-truth answers and established an evaluation criterion.\nExperimental evaluations demonstrated that integrating DMFAs with the LLAMA3.1 model yielded the\nhighest accuracy of 76.15%, underscoring the signiﬁcant performance enhancement provided by agent\nintegration. This eﬀect was particularly pronounced when DMFAs were paired with the GEMMA2 model,\nresulting ina 34.47% improvement in accuracycompared to the standalone GEMMA2 conﬁguration. For\nevaluating the performance of DMFAs in design automation, we utilized an existing dataset onﬂow-\nfocusing droplet microﬂuidics. The resulting machine learning model demonstrated a coeﬃcient of\ndetermination of approximately 0.96. To enhance usability, we developed a streamlined graphical user\ninterface (GUI) that oﬀers an intuitive and eﬀective means for users to interact with the system. This\nstudy demonstrates the eﬀective use of LLM agents in droplet microﬂuidics research as powerful tools\nfor automating workﬂows, synthesising knowledge, optimising designs, and interacting with external\nsystems, bringing a signiﬁcant transformation to the ﬁeld of digital discovery. DMFAs is capable of\ntransforming them into closed-loop digital discovery platforms that encompass literature synthesis,\nhypothesis generation, autonomous design, execution in self-driving laboratories, analysis of results, and\nthe generation of new hypotheses. These capabilities enable their application across education and\nindustrial support, driving greater eﬃciency in scientiﬁc discovery and innovation.\n1. Introduction\nDroplet microuidics is a cutting-edge technology that lever-\nages microchannel networks to manipulate discrete droplets as\nindependent microreactors. This technology minimises sample\nconsumption, reduces waste, and allows for high-throughput\nprocessing, making it indispensable for applications where\nscalability and precision are critical.\n1–9 Droplet microuidics,\nleveraging its foundational strengths, has driven innovations\nacross various disciplines within the chemical and biological\nsciences, including advancements in next-generation\nsequencing,\n10–12 single-cell RNA sequencing, 13,14 single cell\nsecretion analysis,15,16 drug screening,17 droplet digital PCR,18\nand liquid biopsies diagnostics.19 However, designing droplet\nmicrouidics devices is complex and oen requires iterative\ntrial-and-error processes. 20–24 To address the complexity of\ndevice design, machine learning (ML) has emerged as a prom-\nising tool for automating the optimisation of droplet-based\nmicrouidic systems.\n25–32 However, implementing ML-based\ndesign automation requires expertise in both micro uidics\nand machine learning to optimise algorithms and interpret\noutcomes eﬀectively. Additionally, considerable time is needed\nto comprehend and utilise the extensive body of prior knowl-\nedge in droplet micro uidics and machine learning docu-\nmented in the scientic literature, which is critical during the\ninitial stages of experimentation.\nLLMs are advanced arti cial intelligence (AI) systems\ncapable of understanding and generating human-like text by\nDepartment of Biomedical Engineering, The Chinese University of Hong Kong, Room\n208, Ho Sin Hang Engineering Building (SHB), Shatin, N. T., Hong Kong, China.\nE-mail: ngocduydinh@cuhk.edu.hk\nCite this:Digital Discovery,2 0 2 5 ,4,\n2827\nReceived 11th July 2025\nAccepted 16th August 2025\nDOI: 10.1039/d5dd00306g\nrsc.li/digitaldiscovery\n© 2025 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 | 2827\nDigital\nDiscovery\nPAPER\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nView Journal\n | View Issue\nprocessing vast amounts of data.33 LLMs have demonstrated\nbroad applicability across various disciplines, with notable\ncontributions in specialised areas such as chemistry, 34–38\nbiology,39–43 biomedical research,44–47 materials science,48–54 and\nmedicine55–60 oﬀering signicant benets in automating and\nenhancing research processes. Furthermore, LLMs have played\na pivotal role in advancing scientic discovery and fostering\ntechnological innovation.\n61–64 However, the inherent limitations\nof LLMs, such as hallucination, bias, and incomplete factual\naccuracy, necessitate careful oversight and validation of their\noutputs.65,66 To overcome some of these limitations, Retrieval-\nAugmented Generation (RAG) frameworks combine LLMs with\nexternal knowledge retrieval systems, enabling more accurate\nand contextually relevant outputs.\n67 RAG models retrieve perti-\nnent information from structured databases or scienti c\nrepositories, ensuring the generated content aligns with veried\nknowledge. However, basic RAG implementations face scal-\nability challenges, limited retrieval accuracy, and dependence\non the quality of the external sources. 68 LLM agents are\nadvanced AI systems that go beyond generating text by acting as\nautonomous agents capable of planning, reasoning, and\nexecuting tasks. Unlike traditional LLMs, which passively\nrespond to inputs, agentic LLMs can interact with external\ntools, APIs, and databases to achieve speci c goals. These\nagents operate autonomously, performing complex, multi-step\ntasks such as iterative querying, hypothesis testing, and exper-\nimental design.\n69–74 These agents have found applications in\nautonomous scientic discovery75 and medical research.76–78\nHowever, their deployment in droplet microuidics remains\nunderexplored, representing a signi cant opportunity for\ninnovation.\nIn this study, we introduce DropMicroFluidAgents (DMFAs),\na novel multi-agent-based framework designed to perform\ndiverse tasks and make decisions autonomously, guided by its\nprogramming and the data it analyses. DMFAs comprises two\ncomponents, the Scienti c Mentor and the Automation\nDesigner, both constructed using cutting-edge LLMs, as shown\nin Fig. 1. The Scientic Mentor delivers customised guidance\nand recommendations aimed at enhancing theoretical under-\nstanding and reducing the trial-and-error costs associated with\nexperimental workows in droplet microuidics. Notably, the\nAutomation Designer is capable of developing a machine\nlearning model to optimise and automate the design of droplet\nmicrouidic devices, as well as providing code-based CAD\nscripts for drawing creation. This study emphasises the trans-\nformative potential of LLMs in advancing droplet microuidics\ndevelopment, setting the stage for the rapid acceleration of\nscientic discovery and technological innovation through AI.\nFig. 1 The overall framework of DMFAs. The Scientiﬁc Mentor is tasked with providing guidance to users by leveraging LLM agents and the\nspecialized knowledge database, supplemented by the web search tool when required. Meanwhile, the Automation Designer, also leveraging\nLLM agents, facilitates the automation of the design process for users.\n2828\n| Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 © 2025 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\n2. Methods\n2.1 Large language model selection\nThe selection of LLMs is a critical decision in the design and\noptimisation of intelligent agents. For this study, three models\navailable through the Ollama framework including LLAMA 3.1\n(8B parameters),\n79 MISTRAL (7B parameters),80 and GEMMA2\n(9B parameters)81 were selected for their distinct strengths, each\ntailored to address the specic requirements of the task as\nillustrated in Table 1. LLAMA 3.1 is renowned for its general-\npurpose capabilities and exibility, making it particularly\neﬀective for a wide range of query types. It provides a solid\nfoundation for handling both structured and unstructured\ninputs, adapting well to various contexts. The strength of\nLLAMA 3.1 lies in its ability to generate coherent responses\nacross diverse topics. MISTRAL, on the other hand, excels in its\nability to perform sophisticated contextual reasoning. Its\narchitecture is specically optimised to handle complex queries\nthat require deep comprehension and multi-step inference. The\nstrength of MISTRAL lies in its capacity to maintain context\nacross extended conversations or intricate problem-solving\ntasks, which makes it particularly valuable for applications\nrequiring high levels of logical consistency and nuanced\nunderstanding. The advanced attention mechanisms of this\nmodel allow it to consider multiple factors in parallel, oﬀering\na higher degree of precision when managing intricate rela-\ntionships between data points or abstract concepts. GEMMA2\nwas selected for its specialised prociency in domain-specic\napplications, particularly within technical elds such as\nmicrouidics and machine learning. Its design emphasises\nhigh eﬃciency and accuracy when dealing with structured\nknowledge bases, which makes it ideal for tasks that involve\nretrieving and synthesizing specialized information. The ability\nof GEMMA2 to process and lter relevant domain-speci c\ncontent quickly allows it to provide highly accurate, context-\nsensitive answers within narrow scopes, ensuring that the\nsystem can deliver expert-level insights in specialized areas.\nBuilding agents on these models involves not only leveraging\ntheir inherent strengths but also addressing critical factors such\nas scalability, latency, and ne-tuning for task-speci c\nrequirements. The integration of these LLMs ensures\na balanced approach to accuracy, eﬃciency, and contextual\nrelevance. Furthermore, their combined deployment allows for\nredundancy and cross-validation of outputs, enhancing the\noverall reliability and robustness of the system. This deliberate\nselection and integration underscore the importance of align-\ning model capabilities with the nuanced demands of the\napplication domain.\n2.2 Scienti c Mentor construction\n2.2.1 Flowchart illustrating the operational principle of the\nScientic Mentor. The Scientic Mentor represents a compre-\nhensive and adaptive pipeline for a robust question– answering\nsystem, integrating RAG with mechanisms for relevance\ngrading, hallucination detection, and iterative renement, as\nillustrated in Fig. 2a. The system initiates with a routing agent\nthat categorizes the question of a user as either pertaining to the\nmicrouidic knowledge base or necessitating external context.\nFor questions linked to the microuidic knowledge base, the\nretrieval process employs methods such as embedding simi-\nlarity or semantic search to identify the most relevant docu-\nments from the base. These retrieved documents are\nsubsequently reranked to select the top three. These selected\ndocuments are then evaluated by a document grading agent,\nwhich assesses their relevance based on their alignment with\nthe query. If irrelevant documents are identied, the pipeline\nredirects to the web-search tool for broader context or supple-\nmentary data, ensuring comprehensive coverage. The answer-\ngenerating agent is tasked with synthesizing responses based\non the retrieved and evaluated documents. A critical safeguard\nis the hallucination checking agent, where the generated\nanswer is scrutinized for unsupported or fabricated claims,\nleveraging fact-checking techniques. If hallucinations are\ndetected, the system iterates by re-fetching or supplementing\ndata, potentially from the answer-generating agent, ensuring\nthe renement of the response. Thenal step involves answer\nvalidation, where the answer grading agent veri es if the\ngenerated response adequately addresses the original question.\nIf the response is unsatisfactory, the process loops back to the\nweb search to gather additional information to re ne the\nanswer further. This architecture balances internal knowledge\nutilisation with external search capabilities, emphasising reli-\nability and adaptability at the cost of increased computational\noverhead and potential delays.\nThe Scientic Mentor is implemented sequentially using\nLLAMA 3.1, MISTRAL, and GEMMA2, represented as LLAMA-\nbased Scientic Mentor, MISTRAL-based Scienti c Mentor,\nand GEMMA-based Scientic Mentor, respectively. The accuracy\nTable 1 LLMs used\nModel\nParameter\ncount\nArchitecture\nhighlights\nTraining data\ncomposition\nDeployment\nprecision\nQuantization\napplied?\nOpen-\nsourced? Provider\nGemma\n2:9B\n9 billion Cross-attention tuned for\nstructured data\nScientic literature, technical\nmanuals, knowledge graphs\nFP16 Yes Yes Google\nMistral 7B 7 billion Sliding-window attention; latency-\noptimised\nFiltered datasets focusing on\nreasoning, logic, and academic\ntexts\nFP16 Yes Yes Mistral\nAI\nLlama\n3.1:8B\n8 billion Decoder-only transformer with\nrotary embeddings\nBroad, diverse corpus (web, code,\nmultilingual text)\nFP16 Yes Yes Meta\n© 2025 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 | 2829\nPaper Digital Discovery\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nof the LLMs-based Scientic Mentor is compared to the accu-\nracy of the standalone models, LLAMA 3.1, MISTRAL, and\nGEMMA2, in the question– answering (QA) task. Their perfor-\nmance is subsequently evaluated in the‘Results and discussion’\nsection.\n2.2.2 Generation of droplet micro uidics database and\nground truth question–answer set. LLMs, as large general-\npurpose models trained on extensive text corpora, can\nproduce inaccurate or nonspeci c responses to highly\nspecialised, domain-specic queries. However, incorporating\ndomain-specic knowledge bases and supplementary tools can\nenhance their accuracy and enable them to provide more rele-\nvant and precise guidance.\n67 To assess the e ﬃcacy of the\nScientic Mentor in addressing question– answering challenges\nwithin droplet microuidics, we constructed a droplet micro-\nuidics database and a ground truth question– answer dataset\nbased on 233 scientic papers sourced from a range of well-\nknown publishers, as shown in Fig. 3a (SI, S1). The database\nFig. 2 Details of DMFAs. (a) Illustrates how the Scientiﬁc Mentor delivers theﬁnal answer to the user by utilizing multiple LLM agents to minimize\nthe limitations of LLMs and improve the accuracy of the response. (b) Illustrates how the Automation Designer provides the machine learning\nmodel and CAD design to the user by utilizing three LLM agents to ensure an error-free result.\n2830 | Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 © 2025 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nhas not been extensively expanded because our primary aim is\nto illustrate the operational e ﬀectiveness of the proposed\nframework rather than to create an exhaustive repository.\nHowever, the framework is designed to be extensible, allowing\nend-users to enrich the database with tailored data sources such\nas scientic publications, textbooks, and experimental reports.\nFig. 3 (a) Percentage distribution source of documents (b)ﬂowchart of the droplet microﬂuidics database.\n© 2025 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 | 2831\nPaper Digital Discovery\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nThis exibility ensures that the framework can be adapted to\nspecic domains and user needs. The ground truth question–\nanswer dataset consists of 61 question– answer pairs encom-\npassing a broad spectrum of topics related to microuidics.\nThese include fundamental concepts of microuidics, princi-\nples of micro uidic device design, fabrication techniques,\nmaterial considerations, applications in biology and medicine,\nchemical and material science applications, and prospects for\nthe future of droplet microuidics (SI, S2).\nThe construction of the droplet micro uidics database\nadheres to the process outlined in theowchart presented in\nFig. 3. Thisowchart illustrates a pipeline for processing and\nstoring text data extracted from documents, such as PDFles,\nenabling eﬃcient semantic search and retrieval using the\ndatabase. The process begins by dividing the content of the\ndocuments into manageable chunks, ensuring the text is\nappropriately segmented to preserve context and prevent\ninformation loss. These chunks are passed to an embedding\nmodel, a neural network typically trained on large datasets to\nconvert textual data into high-dimensional embeddings,\nnumerical representations that encode semantic meaning. The\nembeddings are then stored in the database for similarity\nsearch, enabling fast and accurate retrieval based on the\nsemantic relationships between queries and stored data.\n2.2.3 Evaluation method. The owchart represents the\nworkow of a system designed to evaluate the accuracy of the\nScientic Mentor by comparing its output against a pre-\ndetermined ground truth, as shown in Fig. 4. The process\nbegins with a question, which is directed to two components:\nthe ground truth answer source and the Scientic Mentor. The\nground truth answer represents the correct or expected\nresponse to the question, while the Scientic Mentor generates\nan automated response. Both the ground truth answer and the\ngenerated answer produced by the Scientic Mentor are then\nforwarded to an accuracy evaluation agent based on LLAMA 3.1,\nwhich serves as a comparator. This component systematically\nanalyses the generated answer in relation to the ground truth\nanswer to measure the accuracy performance of the Scientic\nMentor using a 0– 100 scoring scale, as shown in Table 2. The\ncriteria emphasise factors such as relevance, clarity, coherence,\nconciseness, and depth of understanding in addressing the\ngiven question.\nLower scores (0– 25) indicate responses that are irrelevant,\nnonsensical, or poorly structured, reecting a lack of eﬀort or\nfocus on the question. Mid-range scores (26 – 55) represent\npartially correct responses with varying degrees of inaccuracies,\nverbosity, or insu ﬃcient depth, highlighting areas for\nimprovement in precision and alignment with the query.\nHigher scores (56– 85) denote responses that are largely relevant,\nclear, and accurate, albeit with minor issues such as unneces-\nsary details or slight omissions. The top score range (86– 100)\nreects excellence, with responses being comprehensive, highly\nprecise, and virtually awless, showcasing exceptional clarity\nand direct alignment with the question. This tiered rubric\nprovides a robust foundation for systematically evaluating and\nimproving the performance of the Scientic Mentor in gener-\nating high-quality, contextually appropriate answers. Addition-\nally, several supplementary metrics are used to evaluate the\nperformance of the Scienti \nc Mentor, including Bilingual\nEvaluation Understudy (BLEU), Recall-Oriented Understudy for\nFig. 4 Accuracy evaluation agent.\n2832 | Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 © 2025 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nGisting Evaluation (ROUGE), recall, F1 score, and Metric for\nEvaluation of Translation with Explicit Ordering (METEOR), all\nof which are detailed in Table 3.\n2.2.4 Investigation of how prompt design a ﬀects the\naccuracy of the Scientic Mentor. Prompt design is a funda-\nmental aspect of optimising the performance of LLMs, as it\nsignicantly impacts the quality, relevance, and precision of\ntheir generated outputs. A well-cra ed prompt not only\nprovides clear instructions but also sets the context in which the\nmodel should operate, ensuring that the response aligns with\nthe expectations of a user.\n82–84 The prompt must dene the task\nin a way that minimises ambiguity, especially for complex or\ndomain-specic queries. E ﬀective prompts o en include\nspecic cues, such as desired output formats or constraints,\nthat guide the model's reasoning and response generation. For\nexample, in technicalelds, the prompt might include termi-\nnology and context that ensure the model can draw from rele-\nvant domain-speci c knowledge rather than providing\ngeneralised or unrelated information. This level of clarity is\ncrucial for ensuring that the LLM produces accurate and\nappropriate results, particularly when the task involves intricate\nsubject matter or multi-step reasoning. In this context, the\neﬀectiveness of LLM agents in performing specic tasks is\nintrinsically tied to the precision of the prompts. A precise\nprompt enables the model to focus on the most relevant\ninformation, e ﬀectively guiding it through the process of\ngenerating the correct answer. This is especially important\nwhen the agent is tasked with complex problem-solving or when\na high degree of contextual understanding is required. Inaccu-\nrately phrased or vague prompts can lead to a range of issues,\nincluding irrelevant answers, incomplete responses, or even\nmisinterpretations of the query. For example, an ambiguous\nprompt may cause the model to generate a broad, generic\nresponse, rather than the highly specic answer necessary for\ntechnical or specialized tasks.\nWe systematically applied seven prompt engineering tech-\nniques to assess their impact on the accuracy of the LLAMA-\nbased Scientic Mentor:\nTable 2 Accuracy evaluation agent's criteria\nAccuracy evaluation agent's criteria\n# Score 0– 5: the response is irrelevant, nonsensical, or incoherent; no eﬀort to address the question\n# Score 6– 10: an attempt is made, but the response is entirely unrelated or meaningless\n# Score 11– 15: contains vague or random terms but lacks clarity, relevance, and logic\n# Score 16– 20: slight relevance, but the response is mostly incorrect, unclear, and fails to address the question\n# Score 21– 25: marginal eﬀort to address the question, but lacks clarity and coherence; mostly irrelevant\n# Score 26– 30: some fragments of relevance, but the response is poorly structured and fails to convey useful information\n# Score 31– 35: displays minimal understanding, with major inaccuracies and a lack of focus on the question\n# Score 36– 40: partially aligned with the question but overly verbose, unclear, or dominated by factual errors\n# Score 41– 45: demonstrates basic understanding but lacks conciseness, with signicant errors or irrelevant details\n# Score 46– 50: covers core aspects but is imprecise, verbose, or unclear; lacks depth or includes notable inaccuracies\n# Score 51– 55: partially correct, with omissions or minor inaccuracies; somewhat clear and relevant but not concise\n# Score 56– 60: mostly relevant and clear, but lacks focus or includes unnecessary details; broadly acceptable\n# Score 61– 65: addresses the question clearly and concisely, with minor inaccuracies or slight verbosity\n# Score 66– 70: a solid, clear, and mostly concise response that aligns with the question and ground truth\n# Score 71– 75: comprehensive, clear, and precise, with only minor omissions or redundant elements\n# Score 76– 80: nearlyawless response; highly clear, concise, and relevant, with only slight room for improvement\n# Score 81– 85: a thorough and precise response; clear, concise, and directly addresses the question with full relevance\n# Score 86– 90: excellent, highly clear, and succinct answer; covers all aspects comprehensively and precisely\n# Score 91– 95: virtuallyawless; exceptional clarity, conciseness, and relevance, with added depth where appropriate\n# Score 96– 100: perfect response; unparalleled clarity, precision, and focus on the question, with no room for improvement\nTable 3 Additional metrics for question–answering evaluation of the Scientiﬁc Mentor\nMetric Purpose\nBLEU Measures precision of n-gram overlaps between predictions and\nreferences\nROUGE-1 Measures overlap of unigrams (single words)\nROUGE-2 Measures overlap of bigrams (two-word sequences)\nROUGE-L Measures the longest common subsequence, capturing uency and\ncoherence\nRecall Quantify the proportion of relevant instances that have been successfully\nretrieved, highlighting the completeness of the retrieval process\nMETEOR Takes into account synonym matches and stemming, providing a more\nexible approach\nF\n1 score The harmonic mean of precision and recall at the token level between\nthe prediction and ground truth\n© 2025 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 | 2833\nPaper Digital Discovery\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\n/C15Baseline – refers to our initial instruction comprising\na direct task description.\n/C15Zero shot– perform a task without any examples provided\nin the prompt.82,85\n/C15Few shots – involves supplying the model with a small\nnumber of task-specic exemplars within the prompt to induce\nbetter performance.86\n/C15Domain expert– ask the model to reect the language and\nreasoning style characteristic of aeld specialist.87\n/C15Self-recitation – encourages the model to reiterate prior\nknowledge relevant to the task at hand before generating the\nnal answer.\n88\n/C15Chain of thought – guides the model to generate inter-\nmediate reasoning steps leading to anal answer.89,90\n/C15Composite – combines two or more strategies, such as\nintegrating few-shot examples with domain expert or chain of\nthought.\n91,92\nComprehensive descriptions of these prompts are available\nin the“modelle.json” located at the linked GitHub repository.\n2.2.5 Investigation of how embedding model aﬀects to the\naccuracy of the Scientic Mentor. Embedding models in RAG\nsystems transform textual content into high-dimensional vector\nrepresentations for semantic search and retrieval. The choice of\nembedding model signicantly aﬀects retrieval accuracy, as it\ngoverns how well semantic relationships between queries and\ndocument chunks are captured.\n93,94 Caspari et al.95 evaluated the\nsimilarity of various embedding models within the context of\nRAG systems, highlighting the importance of selecting appro-\npriate models to enhance retrieval performance. Their analysis\nrevealed that certain open-source models exhibit high similarity\nto proprietary models, o ﬀering viable alternatives for RAG\nimplementations.\nIn this study, we empirically examined the eﬀect of the\nembedding model on the accuracy of the LLAMA-basedScien-\ntic Mentorwhen used with the baseline prompt. The evaluation\nwas carried out across eight open-source embedding models\navailable on https://huggingface.co, including intoat/e5-large-\nv2,\n96 all-MiniLM-L6-v2, all-mpnet-base-v2, pritamdeka/BioBERT-\nmnli-snli-scinli-scitail-mednli-stsb,97 BAAI/bge-base-en-v1.5, multi-\nqa-distilbert-cos-v1, msmarco-distilbert-dot-v5, and stsb-roberta-\nbase-v2.98\n2.2.6 Investigation of how chunk size aﬀects to the accu-\nracy of the Scientic Mentor.In RAG systems, chunk size refers\nto the length of text segments into which source documents are\ndivided for embedding and retrieval. The choice of chunk size\nsignicantly aﬀects both retrieval relevance and generation\nquality.\n99–102 Smaller chunks can improve retrieval precision by\nfocusing on specic information but may fragment context and\nreduce semantic completeness. Larger chunks preserve more\ncontext but may dilute relevance and exceed token limitations.\nIn this study, we empirically assessed the eﬀect of the chunk\nsize hyperparameter on the accuracy of the LLAMA-based\nScientic Mentor when used with our baseline prompt. The\nevaluation encompassed 12 distinct chunk size settings: 100,\n200, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, and\n5000 tokens.\n2.2.7 Investigation of how chunk overlap a ﬀects to the\naccuracy of the Scientic Mentor. Chunk overlap involves the\nproportion of content shared between adjacent text segments\nduring document preprocessing in RAG pipelines. Introducing\noverlap helps maintain contextual continuity across chunks,\nwhich is crucial when relevant information spans chunk\nboundaries. A moderate degree of overlap enhances retrieval\ncoherence and reduces the risk of omitting critical details,\nthereby supporting more accurate downstream generation.\n103\nHowever, excessive overlap can lead to redundancy, increased\ncomputational overhead, and retrieval bias toward repetitive\ncontent.\n103 Therefore, determining the optimal overlap\npercentage is essential for maintaining informational integrity\nand maximizing retrieval eﬃcacy.\nIn this study, we empirically investigated the eﬀect of the\nchunk overlap hyperparameter on the accuracy of the LLAMA-\nbased Scientic Mentor under a baseline prompt setting. The\nanalysis was conducted using axed chunk size of 2000 and\nspanned 11 predened chunk overlap values: 100, 300, 400, 500,\n600, 700, 800, 900, 1000, 1200, and 1500 tokens.\n2.2.8 Investigation of how temperature hyperparameter\naﬀects to the accuracy of the Scientic Mentor.Temperature is\na pivotal hyperparameter in LLMs that modulates the\nrandomness of token selection during text generation. It scales\nthe logits before the somax function, thereby inuencing the\nprobability distribution over the vocabulary. Lower tempera-\ntures yield more deterministic outputs, favoring high-\nprobability tokens and enhancing coherence and factual\naccuracy.\n104–107 Conversely, higher temperatures introduce\ngreater variability, potentially fostering creativity but at the\nexpense of reliability and precision.104–107 However, the rela-\ntionship between temperature and output quality is nuanced. A\nstudy by Peeperkornet al.\n108 found that while higher tempera-\ntures slightly increase novelty, they also lead to a moderate\nincrease in incoherence, with no signicant impact on cohesion\nor typicality. Furthermore, in clinical applications, Patelet al.\n109\nobserved that varying the temperature had minimal eﬀect on\nthe accuracy of tasks such as mortality prediction and medical\ncoding, challenging the assumption that lower temperatures\nare always preferable for factual tasks.\nIn this study, we empirically evaluated the impact of the\ntemperature hyperparameter on the accuracy of the LLAMA-\nbased Scientic Mentor when applied with our baseline\nprompt. The evaluation was conducted across 16 temperature\nsettings, systematically varied from 0 to 1.5 in increments of 0.1.\n2.2.9 Investigation of how top-p hyperparameter aﬀects to\nthe accuracy of the Scientic Mentor. Top-p sampling, also\nknown as nucleus sampling, is a decoding strategy that selects\ntokens from the smallest possible set whose cumulative prob-\nability exceeds a thresholdp. This method adapts to the shape\nof the probability distribution, allowing for dynamic adjust-\nment of the candidate token set size. While top-p sampling can\nenhance the diversity of generated text, its impact on accuracy is\ncomplex. Holtzman et al.\n110 demonstrated that top-p sampling\nmitigates the issue of repetitive and unnatural text o en\nproduced by deterministic decoding methods. However, at\n2834 | Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 © 2025 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nhigher temperature settings, top-p sampling may struggle to\nbalance coherence and creativity, leading to less reliable\noutputs. To address this, Nguyen et al.111 proposed Min-P\nsampling, a dynamic truncation method that adjusts the\nsampling threshold based on the model's condence, thereby\nimproving coherence and quality even at high temperatures.\nIn this study, we conducted an empirical assessment of how\nthe top-p sampling hyperparameter inuences the accuracy of\nthe LLAMA-basedScientic Mentorunder our baseline prompt-\ning condition. The analysis spanned 11 systematically varied\ntop-p values ranging from 0 to 1 in increments of 0.1.\n2.2.10 Investigation of how top-k hyperparameter aﬀects to\nthe accuracy of the Scienti c Mentor. Top-k sampling is\na decoding technique where the model selects the next token\nfrom thek most probable candidates. This method introduces\nstochasticity while maintaining computational e ﬃciency.\nLower values of k tend to produce more focused and deter-\nministic outputs, which can improve accuracy for factual\ntasks.\n112 Higher values of k increase output variability, poten-\ntially enhancing creativity but also raising the risk of incoher-\nence and semantic dri.\n112\nIn this study, we empirically examined the inuence of the\ntop-k sampling hyperparameter on the accuracy of the LLAMA-\nbased Scientic Mentor under our baseline prompt congura-\ntion. The evaluation was performed across 16 top-k settings,\nsystematically varied from 0 to 150 in increments of 10.\n2.3 Autonomous Designer construction\n2.3.1 Flowchart illustrating the operational principle of the\nAutonomous Designer. The owchart depicts an agent-driven\niterative workow for the Autonomous Designer in droplet\nmicrouidics, with autonomous agents managing each stage of\nthe process, as illustrated in Fig. 2b. The workow begins with\nthe specic requirement that necessitates code creation. This\ninput is passed to the design automation agent, which produces\nan initial version of the code based on predened algorithms,\ntemplates, or learned patterns. The generated code is then\nevaluated by the code reviewing agent, which inspects the code\nfor logical correctness, adherence to coding standards, and\nfunctional compliance. The process progresses to the code-\nready stage, where it is assessed to ensure the code complies\nwith all dened quality and functional requirements. If the code\nis deemed ready, the machine learning model or CAD design is\nproduced. Otherwise, the code-improving agent intervenes to\nrene the code, addressing deciencies through debugging,\noptimisation, or reworking based on feedback from the\nTable 4 Prompt design for the Automation Designer\nAgent name Prompt's content\nDesign automation agent For ‘AutoLisp’ case: you are an expert in writing code in AutoLisp.\nGenerate the proper lines of code based on request. Only output the code\nand nothing else. Here is the request: {request}\nFor ‘Python’ case: you are an expert in writing code in Python. Generate\nthe proper lines of code based on request. Only output the code and\nnothing else. Here is the request {request}\nCode reviewing agent For ‘AutoLisp’ case: you are a code reviewer specialized in AutoLisp. You\nneed to review the given code and potential bugs and point out issues as\nbullet list. Only output the bullet list and nothing else here is the code:\n{code}\nFor ‘Python’ case: you are a code reviewer specialized in‘Python’. You\nneed to review the given code following PEP8 guidelines and potential\nbugs and point out issues as bullet list. Only output the bullet list and\nnothing else. Here is the code: {code}\nCode improving agent For ‘AutoLisp’ case: you are an expert in improving AutoLisp code.\nImprove the given code given the following guidelines. Only output the\nimproved code and nothing else. Here are the guidelines: {guidelines}.\nHere is the given code: {code}\nFor ‘Python’ case: you are an expert in improving Python code. Improve\nthe given code given the following guidelines. Only output the improved\ncode and nothing else. Here are the guidelines: {guidelines}. Here is the\ngiven code: {code}\nFig. 5 Human-centered validation of agent-generated CAD designs.\n© 2025 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 | 2835\nPaper Digital Discovery\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nTable 5 An example demonstrates how the LLAMA-based Scientiﬁc Mentor answers a question and how the accuracy score for the response is\ndetermined\nQuestion: how to generate microdroplets?\nGround-truth answer: microdroplet generation in microuidics is achieved through two main methods: active and passive. Active methods utilize\nexternal forces like piezoelectric actuators to precisely control droplet size, formation rate, and spacing. These methods enable high uniformityin\ndroplet generation, with deviations less than 0.3%. Passive methods rely onuid properties and channel geometry, such as T-junctions or cross-ow\ncongurations, to create droplets. These methods are inuenced by factors likeow rate, viscosity, and interfacial tension, allowing forne control\nover droplet size and uniformity. For example, PDMS-based microuidic devices have been used for nanoparticle synthesis, where hydrodynamic\ncoupling of nozzles generates droplet pairs for precise mixing. Both methods are valuable in applications like nanoparticle synthesis, oﬀering high\nreproducibility and control over reaction conditions in biomedical and material science research\nLLAMA-based Scientic Mentor's answer: based on the provided context, there are several ways to generate microdroplets in microuidic devices.\nAccording to document 3, which has a relevance score of 0.99394965, the most commonly used methods for microdroplet generation can be divided\ninto two main categories: active and passive\n“Active Methods:”\n* A piezoelectric actuator-based droplet generator is described in document 2, which allows for independent control over droplet size, rate of\nformation, and distance between droplets. This device is able to generate microdroplets with high uniformity, deviating from the mean value by less\nthan 0.3%\n“Passive Methods:”\n* The context mentions that PDMS-based microuidic devices are used to generate microdroplets for bulk synthesis of nanoparticles (document 1).\nSpecically, a device designed by Frenzet al.enables the production of droplet pairs based on the hydrodynamic coupling of two separated nozzles\n* Another method mentioned is the use of thermally isolated zones in a droplet microreactor for the synthesis of TiO\n2 nanoparticles\nAdditionally, document 3 mentions that other methods have been explored to generate microdroplets, including\n* Cross-ow and T-junction congurations\n* Adjusting channel geometry, two-phase viscosity,ow rate, wettability, and interfacial tension\nThese methods are used to achieve precise regulation over the size, shape, uniformity, and other factors of microdroplets\nAccuracy evaluation agent's feedback: the response provides a clear and detailed explanation of microdroplet generation methods, accurately\ncategorizing them into active and passive techniques. It correctly describes the characteristics and applications of each method, including the useo f\npiezoelectric actuators, PDMS-based devices, and thermally isolated zones. However, it does not fully address the question's request for\na comprehensive overview, as it relies heavily on specic documents andgures mentioned in the provided context. SCORE: 81\nMicrouidics expert rating: SCORE: 85\nStandalone LLAMA's answer: microdroplets can be generated using various methods, including\n(1) Flow-focusing technique: this involves forcing a liquid through a narrow channel or nozzle, creating a stream of droplets\n(2) Pneumatic atomization: using compressed air to break up a liquid into small droplets\n(3) Ultrasonic nebulization: using high-frequency sound waves to create tiny droplets from a liquid\n(4) Electrostatic atomization: applying an electric charge to a liquid, causing it to break up into small droplets\n(5) Centrifugal atomization: spinning a liquid at high speed to create droplets\n(6) Laser-induced breakdown spectroscopy (LIBS): using a laser pulse to create microdroplets from a liquid\n(7) Microuidic devices: specialized devices that use channels and valves to control theow of liquids and generate microdroplets\nThese methods can be used in various applications, such as drug delivery, chemical synthesis, and biological research\nAccuracy evaluation agent's feedback: the response provides a list of various methods to generate microdroplets but does not directly address the\nquestion's focus on the two main methods (active and passive) used in microuidics. SCORE: 16\nMicrouidics expert rating: SCORE: 10\nQuestion: what key factors inuence the design ofow-focusing droplet microuidics optimized using machine learning?\nGround-truth answer: the design ofow-focusing droplet microuidics, optimized using machine learning, depends on several critical factors.\nChannel geometry, including the shape and size, controls droplet generation by dening the break-oﬀ point where the dispersed phase meets the\ncontinuous phase. Flow rates of both phases aﬀect droplet size and frequency, with higher continuous phaseow reducing droplet size. Viscosity\ninuences ow behavior and shear forces, crucial for stable droplet formation. Shear forces between phases are controlled by adjusting channel\ngeometry orow rates, ensuring consistent droplet generation. Machine learning algorithms predict and optimize droplet diameter and generation\nrate by analyzing these design parameters,uid properties, and large datasets, automating the design process for more eﬃcient droplet production\nin life sciences applications\nLLAMA-based Scientic Mentor's answer: based on the provided context, the key factors that inuence the design ofow-focusing droplet\nmicrouidics optimized using machine learning are\n(1) “Channel geometry”: the shape and size of the channel in which theuids areowing play a critical role in controlling droplet generation\n(2) “Flow rate”\n: the rates at which the dispersed and continuous phases are forced through the channel aﬀect the droplet diameter and generation\nrate\n(3) “Viscosity”: the viscosity of theuids also inuences the droplet generation process, as it aﬀects theow behaviour and shear forces acting on\nthe dispersed phase\n(4) “Shear forces”: the shearing action between the continuous and dispersed phases is crucial inow-focusing designs and can be controlled by\nadjusting the channel geometry orow rates\nThese factors are mentioned in document 2 (page_content= ‘49’) as governing the generation of droplets inow-focusing designs. Additionally, the\nuse of machine learning algorithms to predict the performance of droplet generators based on these design parameters is discussed in document 1\n(page_content = ‘22, 23.’)\n2836 | Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 © 2025 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nreviewing agent. This cycle continues iteratively until the code\npasses the readiness evaluation. The agent-driven approach\nensures automation, consistency, and e ﬃciency across all\nworkow stages. This design highlights the potential of agent-\nbased systems to streamline iterative development while\nmaintaining a focus on continuous improvement and quality\nassurance. LLAMA 3.1 was selected for implementing the\nAutonomous Designer. A detailed explanation of the Autono-\nmous Designer's prompts is provided in Table 4.\n2.3.2 Human-centered validation of agent-generated CAD\ndesigns in AutoCAD environments.In the proposed multi-agent\nframework, CAD design generation is facilitated through the\nautomated production of AutoLISP scripts, which interface\ndirectly with the AutoCAD working environment to yield precise\ngeometric renderings of the intended structures. Crucially, these\noutputs are not blindly adopted but undergo a critical phase of\nhuman verication and visual inspection within the AutoCAD\ninterface prior to any downstream fabrication processes as shown\nin Fig. 5. This step ensures that the design not only adheres to the\nfunctional speci cations but also conforms to practical\nconstraints and user-dened criteria. Thedelity of AutoCAD's\ngeometric visualization enables users to assess structural integ-\nrity, dimensional accuracy, and design feasibility in a high-delity\nvirtual setting. Consequently, the integration of human oversight\nwithin an automated CAD workow ensures both adaptability and\nreliability, bridging algorithmic design generation with the\nnuanced judgment of experienced practitioners.\n3. Results and discussion\n3.1 Performance of the Scientic Mentor\nAn illustrative example involving the evaluation of two ques-\ntions demonstrates a systematic approach for assessing the\nquality of answers generated by the Scientic Mentor based on\nLLAMA and standalone LLAMA. This evaluation uses\na predened scoring framework, with the results detailed in\nTable 5, providing a comparative analysis of the performance of\ntwo models. The process begins with a specic question relating\nto microuidics, which serves as the input for the system to\ngenerate a corresponding answer. This generated response is\nthen compared against a ground truth answer, representing the\nexpected or ideal response to the given question. The accuracy\nevaluation agent assesses the generated answer based on its\nestablished criteria, such as relevance, accuracy, clarity, and\ncoherence, in relation to the ground truth. A numerical score is\nassigned to reect the performance of the generated response.\nFollowing this, microuidics expert provides additional ratings\nto ensure the robustness and reliability of the scoring process.\nThis combined evaluation leverages both automated and\nhuman assessments to rene the performance of the Scientic\nMentor and ensure alignment with high-quality standards.\nAccuracy evaluated by the accuracy evaluation agent across\nLLMs, LLMs-RAG and LLMs-based ScienticM e n t o ri sc o m p a r e d\nfor the QA task, as illustrated in Fig. 6a, with error bars repre-\nsenting the standard error. Among these, LLAMA-based Scientic\nMentor demonstrate the most substantial performance gain, with\naccuracy rising from 53.64% in the base model to 63.62% with\nRAG, and further to 76.15% in its agent framework, the highest\nscore among all con gurations. This suggests that LLAMA\nresponds particularly well to augmentation, especially within\nagent frameworks that allow for tool use, iterative reasoning, and\ntask decomposition. In contrast, GEMMA in its base form ach-\nieved only 36.56% accuracy, the lowest in the set, highlighting its\nweaker general capabilities. Despite this, it showed the most\ndramatic relative gains from augmentation, reaching 66.84% with\nRAG and 71.03% with agent architecture. MISTRAL-based systems\noﬀered the well-balanced results across all three modes, with\naccuracies of 58.11% (base), 67.05% (RAG), and 72.00% (agent).\nAcross all three LLMs, the introduction of RAG yields a signicant\nimprovement in accuracy. This reinforces the value of retrieval-\nTable 5 (Contd.)\nQuestion: what key factors inuence the design ofow-focusing droplet microuidics optimized using machine learning?\nAccuracy evaluation agent's feedback: the response provides a clear and concise list of factors inuencing ow-focusing droplet microuidics\noptimized using machine learning. However, it lacks depth and detail compared to the ground truth answer, particularly in explaining how these\nfactors interact with each other and with machine learning algorithms. Additionally, some information is presented as a simple statement without\nfurther explanation or context. SCORE: 51\nMicrouidics expert rating: SCORE: 55\nStandalone LLAMA's answer: the key factors that inuence the design ofow-focusing droplet microuidics optimized using machine learning\ninclude\n(1) Channel geometry and dimensions\n(2) Flow rates and ratios of the two immiscibleuids\n(3) Surface tension and interfacial properties\n(4) Viscosity and density of theuids\n(5) Droplet size and polydispersity\n(6) Shear stress and pressure drop across the microchannel\n(7) Operating temperature and pressure\nAccuracy evaluation agent's feedback: the answer provides a list of factors that inuence the design ofow-focusing droplet microuidics optimized\nusing machine learning but lacks explanation and context. It appears to be a summary of key parameters without elaboration on how they interact\nor are used in the optimization process. SCORE: 21\nMicrouidics expert rating: SCORE: 20\n© 2025 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 | 2837\nPaper Digital Discovery\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\naugmented methods in mitigating hallucinations and enhancing\nfactual grounding. A critical observation is the consistently\nsubstantial accuracy gains when transitioning from standalone\nmodels to their agent-augmentedcounterparts, emphasizing the\nimportance of agent-based enhancements for boosting perfor-\nmance. The relatively small error bars for most models suggest\nreliable and consistent outc o m e sa c r o s se v a l u a t i o n s .\nThe details for performing the question– answering task with\nthese models are provided in the SI, S3– S11.\nThe accuracy of LLAMA and LLAMA-based ScienticM e n t o ri n\nthe QA task, as rated by a microuidics expert, is compared, with\nerror bars indicating the standard error, as shown in Fig. 6b.\nLLAMA-based Scientic Mentor achieves a markedly higher\naccuracy of 76.07%, compared to 52.46% for LLAMA, highlighting\na substantial performance gap. The inclusion of error bars indi-\ncates that this diﬀerence is statistically signicant, with minimal\noverlap, underscoring the reliability of the results. The relatively\nlower accuracy of LLAMA suggests limitations in its ability to meet\nthe requirements of expert evaluation in this domain, potentially\ndue to deciencies in its model architecture or training process.\nIn contrast, the superior performance of LLAMA-based Scientic\nMentor likely stems from advanced design features and optimi-\nz a t i o n st h a ta d d r e s ss p e c ic shortcomings in LLAMA, making it\nbetter suited to microuidics research.\nA comprehensive performance analysis of LLAMA, GEMMA,\nMISTRAL, and Scientic Mentor, which is implemented using\nFig. 6 (a) Accuracy evaluated by the accuracy evaluation agent across LLMs and LLMs-based Scientiﬁc Mentor for the QA task. (b) Microﬂuidics\nexpert rating for QA of LLAMA-based Scientiﬁc Mentor and standalone LLAMA.\n2838 | Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 © 2025 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nLLAMA, GEMMA, and MISTRAL, is provided, across multiple\nperformance metrics, including F1 score, Recall, ROUGE-1,\nROUGE-2, ROUGE-L, BLEU, and METEOR, each accompanied\nby standard errors, as shown in Table 6. The results highlight\ndistinct trends across the models. LLAMA-based Scienti c\nMentor and GEMMA-based Scienti c Mentor consistently\nTable 6 Evaluation of extra metrics across models\nModel\nMetrics\nF1 score (%) Recall (%) ROUGE-1 ROUGE-2 ROUGE-L BLEU METEOR\nLLAMA 32.0827 /C61.1605 30.6282 /C61.5492 0.3268/C60.0117 0.0876/C60.0056 0.193/C60.0076 0.0376/C60.0054 0.2243/C60.0107\nLLAMA-based Scientic\nMentor\n42.4434 /C60.9869 63.2638 /C61.4387 0.4306/C60.01 0.1818 /C60.0082 0.263/C60.0087 0.0848/C60.0057 0.4328/C60.0117\nGEMMA 16.3745 /C61.0885 10.0868 /C60.8011 0.1646/C60.0107 0.0504/C60.0054 0.119/C60.0072 0.0023/C60.0013 0.0861/C60.0056\nGEMMA-based Scientic\nMentor\n43.6846 /C61.08 58.5453 /C61.2866 0.4442/C60.0109 0.1765/C60.0086 0.27 /C60.0097 0.0806/C60.0063 0.4082/C60.0099\nMISTRAL 34.0437 /C60.866 33.8424 /C61.0308 0.3468/C60.0088 0.0946/C60.0064 0.199/C60.0063 0.0445/C60.0052 0.2611/C60.0072\nMISTRAL-based Scientic\nMentor\n39.247 /C61.1005 51.8103 /C61.4567 0.4003/C60.0112 0.1328/C60.0078 0.226/C60.0074 0.0733/C60.007 0.3663 /C60.0102\nFig. 7 (a) Accuracyvs. prompt for LLAMA-based Scientiﬁc Mentor. (b) Recallvs. prompt for LLAMA-based Scientiﬁc Mentor.\n© 2025 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 | 2839\nPaper Digital Discovery\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\noutperform their respective non-agent counterparts in nearly all\nmetrics, showcasing the eﬀectiveness of agent integration in\nthese architectures. Speci cally, GEMMA-based Scienti c\nMentor achieves the highestF1 score (43.68 ± 1.08) and recall\n(58.55 ± 1.29), suggesting its strong ability to identify relevant\nelements in text and retrieve meaningful information. LLAMA-\nbased Scienti c Mentor also demonstrates robust perfor-\nmance, particularly in recall (63.26± 1.44), indicating its eﬃ-\nciency in capturing relevant data. In contrast, the signicantly\nlower scores of GEMMA (e.g., F\n1 score of 16.37 ± 1.09 and\nROUGE-2 of 0.0504± 0.0054) reect its limitations in standal-\none congurations, underscoring the necessity of its agent-\nenhanced counterpart for improved outcomes. Similarly,\nMISTRAL-based Scientic Mentor outperforms MISTRAL in\nmost metrics, with notable improvements in ROUGE-2 and\nMETEOR, though the gap is less pronounced than the GEMMA\nmodels. Interestingly, while LLAMA-based Scienti c Mentor\nand GEMMA-based Scientic Mentor lead in diﬀerent metrics,\nGEMMA-based Scienti c Mentor appears more balanced,\nmaintaining high scores across all dimensions of the evalua-\ntion. The GEMMA-based Scientic Mentor's balanced perfor-\nmance across various metrics can be attributed to its\narchitectural innovations and training strategies. Architectur-\nally, GEMMA incorporates interleaved local-global attention\nmechanisms and grouped-query attention (GQA), enhancing\nboth local and global context comprehension while maintain-\ning computational eﬃciency.\n81 These design choices enable the\nmodel to capture nuanced linguistic patterns, leading to\nimproved performance across diverse evaluation metrics.\nGEMMA employs knowledge distillation from larger teacher\nFig. 8 (a) Accuracy vs. embedding models for LLAMA-based Scientiﬁc Mentor. (b) Recallvs. embedding models for LLAMA-based Scientiﬁc\nMentor.\n2840 | Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 © 2025 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nmodels, allowing it to learn re ned representations and\ngeneralize eﬀectively without the need for extensive parameter\ncounts.113–115 This approach, combined with a diverse and high-\nquality training dataset encompassing web documents, code,\nand scientic articles, equips the model with a broad knowl-\nedge base and linguistic versatility. Furthermore, the standard\nerrors suggest that GEMMA-based Scienti c Mentor and\nLLAMA-based Scienti c Mentor yield relatively consistent\nresults, reecting their reliability. However, MISTRAL-based\nScientic Mentor, while generally superior to MISTRAL, does\nnot reach the performance levels of LLAMA-based Scientic\nMentor or GEMMA-based Scientic Mentor.\n3.2 Accuracy vs. prompt for LLAMA-based Scientic Mentor\nThe comparative performance of various prompting strategies\non the accuracy of LLAMA-based Scientic Mentor as illustrated\nin Fig. 7a. They-axis denotes classication accuracy, while thex-\naxis enumerates seven prompting paradigms: baseline, few\nshots, zero shot, self-recitation, chain of thought, domain\nexpert, and composite prompts. Among these, the baseline\nprompt achieves the highest accuracy at approximately 76%,\nsuggesting strong initial task performance even without\nsophisticated prompt engineering. Surprisingly, the few shots\napproach performs poorly at around 27%. Prompting strategies\nsuch as zero-shot, self-recitation, and chain-of-thought yield\nsimilar levels of accuracy ranging from 59% to 69%, indicating\nthat reasoning-based or structured prompting oﬀers modest\nbenets. Both domain expert and composite prompts slightly\nimprove upon few shots but remain less eﬀective than the\nbaseline. Thesendings underscore the importance of tailoring\nprompt strategies to the Scientic Mentor's performance.\nTo further substantiate ourndings, we assessed the impact\nof various prompting strategies on recall performance, as\nillustrated in Fig. 7b. Among the conditions tested, the baseline\nprompt achieved the highest recall, approximately 64%,\nsurpassing more complex approaches such as self-recitation at\naround 52%, chain of thought prompting at nearly 53%, and\nthe composite prompt at about 54%. These results suggest that\nthe default prompting condition is already highly eﬀective. In\ncontrast, the few-shot prompting strategy yielded the poorest\nperformance, with a recall of only around 16%. Intermediate\nrecall values were observed for the zero-shot and domain expert\nstrategies, at approximately 47 and 46%, respectively.\n3.3 Accuracy vs. embedding models for LLAMA-based\nScientic Mentor\nThe performance of LLAMA-based Scientic Mentor across eight\nembedding models as shown in Fig. 8a, withintoat-e5-large-v2\nFig. 9 (a) Accuracyvs. chunk size for LLAMA-based Scientiﬁc Mentor.\n(b) Recallvs. chunk size for LLAMA-based Scientiﬁc Mentor.\nFig. 10 (a) Accuracy vs. chunk overlap for LLAMA-based Scientiﬁc\nMentor. (b) Recall vs. chunk overlap for LLAMA-based Scienti ﬁc\nMentor.\n© 2025 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 | 2841\nPaper Digital Discovery\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nachieving the highest accuracy at around 76%. This result suggests\nthat embeddings trained on large-scale ranking and retrieval tasks\noﬀer enhanced compatibility with LLAMA's reasoning mecha-\nnisms. While pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-\nstsb, multi-qa-distilbert-cos-v1 and all-mpnet-base-v2 also yield\ncommendable results, other models such asmsmarco-distilbert-dot-\nv5 fall short, with accuracy below 55%. The observed variation\nacross models indicates that embedding selection has a consider-\nable impact on the performance of the ScienticM e n t o r .\nTo provide additional validation for our results, we analyzed\nhow various embedding models aﬀect recall performance, as\nshown in Fig. 8b. Notably, the intoat-e5-large-v2 model ach-\nieves the highest recall, surpassing 60%, while the remainder of\nthe models clusters around the 45– 50% range. The consistency\namong most models suggests a performance plateau for stan-\ndard embedding strategies, whereas int oat-e5-large-v2\ndemonstrates that recall can be signi cantly improved\nthrough advanced, larger-scale architectures.\n3.4 Accuracy vs. chunk size for LLAMA-based Scientic\nMentor\nThe accuracy of LLAMA-based Scientic Mentor as a function of\nchunk size is depicted in Fig. 9a. Accuracy surges from nearly\n41% at 100 tokens to a peak of around 76% at 2000 tokens,\nindicating increased contextual awareness with larger inputs.\nHowever, performance exhibits a decline and oscillates across\nlarger chunk sizes up to 5000 tokens, suggesting that beyond\nFig. 11 (a) Accuracyvs. temperature for LLAMA-based Scientiﬁc Mentor. (b) Recallvs. temperature for LLAMA-based Scientiﬁc Mentor.\n2842 | Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 © 2025 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\na certain context length, gains in information density may be\noﬀset by increased noise. These results underscore the critical\nrole of chunk-size optimization in maintaining the performance\nand computational e ﬃciency of LLAMA-based Scienti c\nMentor.\nTo further validate ourndings, we investigated the eﬀect of\nvarying chunk sizes on recall performance, as depicted in\nFig. 9b. Initially, recall rises steadily with increasing chunk\nsizes, peaking dramatically near 2000, where recall reaches its\nhighest value of approximately 64%. Beyond this threshold, the\nrecall percentage declines. Thesendings indicate that exces-\nsively large chunks may reduce the ability of LLAMA-based\nScientic Mentor to process and retain information e ﬀec-\ntively, emphasizing the importance of identifying an optimal\nchunk size for eﬃcient operation.\n3.5 Accuracy vs. chunk overlap for LLAMA-based Scientic\nMentor\nThe relationship between accuracy and chunk overlap for\nLLAMA-based agents with axed chunk size of 2000 is illus-\ntrated in Fig. 10a. The accuracy peaks sharply at around 76%\nwhen the chunk overlap is 200, followed by a steep decline to\napproximately 64% at an overlap of 400. Subsequent increases\nand decreases in accuracy are observed, peaking again around\n68% at overlaps of 600 and 800, before a signicant drop at 900.\nThe accuracy thenuctuates mildly and declines steadily with\nlarger overlaps, reaching a minimum at 1500. Thesendings\nhighlight the sensitivity of LLM performance to chunk overlap,\nemphasizing the importance of tuning overlap parameters for\noptimal results.\nTo provide additional validation for our results, we analyzed\nhow various chunk overlaps aﬀect recall performance, as shown\nin Fig. 10b. The peak recall occurs at 200-token overlap,\nreaching over 63%, whereas both lower and higher overlaps\nyield inferior performance. This trend suggests that while\na modest degree of overlap facilitates eﬀective context propa-\ngation between adjacent chunks, larger overlaps may introduce\nexcessive redundancy, inducing contextual ambiguity. The\nndings imply that optimal chunk overlap should be carefully\ncalibrated rather than maximized.\n3.6 Accuracy vs. temperature for LLAMA-based Scientic\nMentor\nThe impact of temperature on the accuracy of responses\ngenerated by LLAMA-based Scientic Mentor is illustrated in\nFig. 11a. At a temperature of 0.0, a maximum accuracy of\napproximately 76% is recorded, but a sharp drop is observed by\n0.1 and 0.4, where accuracy falls below 70%. Subsequent\nincreases in temperature do not follow a linear or predictable\npath; instead, they produce oscillatory behaviour in accuracy,\nranging from 64.1% to 73.3%. This instability suggests that\nhigher temperatures do not guarantee better performance and\nmay lead to over-randomized or incoherent outputs. Thend-\nings stress the importance of empirically identifying an optimal\ntemperature setting to maximize the performance of LLAMA-\nbased Scientic Mentor.\nTo further substantiate our results, we quanti ed recall\nperformance across a range of temperature settings, as depicted\nin Fig. 11b. At a temperature of 0.0, the system achieves the\nhighest recall, exceeding 63%, suggesting highly deterministic\nbehavior enhances retrieval accuracy. However, as the temper-\nature increases, recall sharply declines and stabilizes around\n52%, indicating that increased randomness in token sampling\ndegrades the system's ability to retrieve relevant information.\nThe data underscore the sensitivity of LLAMA-based Scientic\nMentor to sampling congurations, with elevated temperatures\nproducing more diverse but less consistently relevant outputs.\n3.7 Accuracy vs. top-k for LLAMA-based Scientic Mentor\nHow the accuracy evolves with increasing top- k values in\nLLAMA-based Scienti \nc Mentor is illustrated in Fig. 12a.\nDespite increasing the candidate set size from 0 to 150, the\naccuracy shows minimal variation, remaining near the 66– 68%\nrange throughout. From a deployment perspective, thesend-\nings suggest that the performance of LLAMA-based Scientic\nMentor remains relatively stable across a range of top-k values.\nTo further support ourndings, we examined the impact of\ndiﬀerent top-k congurations on recall performance, as illus-\ntrated in Fig. 12b. The curve remains notablyat, with recall\nvalues consistently near 51%, indicating that increasing the\nFig. 12 (a) Accuracyvs. top-k for LLAMA-based Scientiﬁc Mentor. (b)\nRecall vs. top-k for LLAMA-based Scientiﬁc Mentor.\n© 2025 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 | 2843\nPaper Digital Discovery\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nnumber of sampled candidates oﬀers minimal performance\ngains. From an application standpoint, this suggests that\nLLAMA-based Scientic Mentor maintains consistent eﬀective-\nness across diﬀerent top-k settings.\n3.8 Accuracy vs. top-p for LLAMA-based Scientic Mentor\nThe relationship between accuracy and the top-p parameter for\nLLAMA-based Scientic Mentor is illustrated in Fig. 13a. The\naccuracy remains relatively stable across the top-p range from 0.0\nto 1.0, with minoructuations around a mean value of approxi-\nmately 65%. This invariance implies that the accuracy of LLAMA-\nbased Scientic Mentor is not strongly correlated with the\ndiversity of token selection introduced by adjusting the top-p\nparameter. Suchndings highlight the potential robustness of\nLLAMA-based Scientic Mentor under diverse sampling regimes.\nTo reinforce our results, we assessed the eﬀect of diﬀerent\ntop-p congurations on recall performance, as shown in\nFig. 13b. The results demonstrate a remarkably stable recall rate\nof approximately 52% across all tested top-p values, from 0.0 to\n1.0. This trend suggests that recall is not signicantly impacted\nby the randomness introduced through nucleus sampling,\nhighlighting the robustness of the LLAMA-based Scienti c\nMentor.\nFig. 13 (a) Accuracyvs. top-p for LLAMA-based Scientiﬁc Mentor. (b) Recallvs. top-p for LLAMA-based Scientiﬁc Mentor.\n2844 | Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 © 2025 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\n3.9 Performance of the Automation Designer based on\nLLAMA 3.1 in generating machine learning model\nAn example illustrates a structured workow for generating\nhigh-quality machine learning code to predict microuidic chip\nparameters, as shown in Fig. 14a. The process initiates with\na query about creating the machine learning code, which is\naddressed by the design automation agent responsible for\ngenerating an initial version of the code. This preliminary code\nFig. 14 (a) Workﬂow for generating machine learning code. (b) Droplet generation rate prediction.\n© 2025 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 | 2845\nPaper Digital Discovery\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nis subsequently evaluated by the code reviewing agent, whose\nrole is to critically analyze and identify potential issues or areas\nfor renement in the generated script. Feedback from this\nreview is passed to the code improving agent, which applies the\nnecessary modications to enhance the functionality of the\ncode, accuracy, and eﬃciency. The nal stage of the process\ninvolves outputting the optimized and polished code, ready for\nimplementation or further use (SI, S12).\nAn example of the predictive performance of the generated\nmachine learning model for estimating droplet generation rates\nusing an available ow-focusing micro uidics dataset\n25 is\nillustrated in Fig. 14b. The scatter plot compares the predicted\nvalues with the corresponding actual values with the data points\nplotted against a diagonal line representing the ideal scenario\nwhere predicted values perfectly match actual values. The close\nclustering of most points along this diagonal suggests that the\nmodel accurately captures the underlying relationship between\nthe input features and the droplet generation rate. Quantitative\nperformance metrics further support this observation, with\na high coeﬃcient of determination (R\n2 = 0.96) demonstrating\nFig. 15 (a) Workﬂow for generating AutoLISP code in AutoCAD. (b) Implemented AutoCAD drawing.\n2846 | Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 © 2025 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nstrong agreement between predictions and actual values. The\nroot mean square error (RMSE) of 28.996, and the mean abso-\nlute error (MAE) of 18.03, which is lower than the MAE of 20\nreported in the previous study,\n25 demonstrate the eﬀectiveness\nof the model in minimising prediction errors. However, some\ndeviations are noticeable for higher actual droplet generation\nrates, where the predicted values slightly underestimate or\noverestimate the true values, suggesting potential areas for\nFig. 16 GUI of DMAFs. (a) GUI of Scientiﬁc Mentor. (b) GUI of Automation Designer.\n© 2025 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 | 2847\nPaper Digital Discovery\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nimprovement in model ne-tuning. Overall, this visualisation\neﬀectively illustrates the robustness and reliability of the model\nin predicting droplet generation rates across a wide range of\nvalues. Hence, the Automation Designer ensures a rigorous,\niterative renement process, fostering the production of robust\nand reliable machine learning solutions tailored to the domain\nof microuidics.\n3.10 Performance of the Automation Designer based on\nLLAMA 3.1 in generating CAD design\nAn example illustrates a structured, automated pipeline for\ngenerating and rening AutoLISP code in AutoCAD to design\na microuidic chip, employing the Automation Designer, as\nshown in Fig. 15a. The process begins with a user posing\na specic question or request regarding the AutoLISP code\nrequired for the chip design. This input is processed by the\ndesign automation agent, which generates an initial dra of the\ncode based on the provided specications. The generated code\nis then passed to the code reviewing agent, responsible for\nmeticulously analyzing the code for errors, inconsistencies, and\nalignment with the design objectives. This stage ensures that\nthe dra meets basic functional and structural requirements.\nAny identied issues or areas for improvement are forwarded to\nthe code-improving agent, which renes the code further by\naddressing the shortcomings highlighted during the review\nphase. This agent optimizes the code for eﬃciency, accuracy,\nand functionality. The nal, rened code is generated as the\nultimate result and is ready for implementation in the design,\nas shown in Fig. 15b, and for the fabrication of the microuidic\nchip. This automated, iterative process ensures a streamlined\nand reliable approach to code development, minimizing human\nerror while maximizing precision and eﬃciency in microuidic\nchip design (SI, S12).\n3.11 An user-friendly GUI of DMAFs\nTo facilitate straightforward and eﬀective user interaction, we\ndesigned a minimalistic yet intuitive GUI, as shown in Fig. 16.\nComprehensive installation guidelines are available in the\nREADME documentation on the linked GitHub repository.\n4. Conclusions and outlook\nIn this study, we present an intelligent multi-agent framework\nfor advancing droplet micro uidics research by integrating\nadvanced LLMs, which represents a notable milestone in the\neld. The framework includes the Scientic Mentor, which\nleverages domain-specic knowledge to provide reliable guid-\nance on droplet microuidics. Our experimental evaluation\nrevealed that coupling DMFAs with the LLAMA3.1 model\nresulted in the highest observed accuracy of 76.15%, demon-\nstrating the notable performance gains enabled by agent inte-\ngration. The enhancement was particularly marked when\nDMFAs were integrated with the GEMMA2 model, yielding\na 34.47% increase in accuracy compared to the standalone\nGEMMA2 baseline. We performed a systematic empirical\ninvestigation to assess the impact of key hyperparameters\nincluding prompting strategies, embedding models, chunk size\nand overlap, temperature, top-p, and top-k values on the accu-\nracy of question – answering tasks. The baseline prompt\nconsistently outperformed other prompting techniques. Among\nthe embedding models evaluated,intoat-e5-large-v2, noted for\nits sophisticated and large-scale architecture, delivered the\nhighest accuracy. Accuracy was further enhanced by employing\na simplexed-length chunking strategy with small window sizes\nand minimal overlap. A temperature setting of 0.0 yielded\noptimal results, while adjustments to top-p and top-k values\nshowed minimal eﬀect. Together, thesendings oﬀer practical\ninsights for optimizing DMFAs con gurations to achieve\na balance between computational eﬃciency and task accuracy.\nAdditionally, the framework incorporates the Automation\nDesigner, capable of generating machine learning code to\nfacilitate design optimisation and automation of microuidic\nchips, as well as producing code-based CAD scripts for rapid\nand precise creation of designs. LLMs are poised to revolu-\ntionise theeld of droplet microuidics by enhancing research\nmethodologies and accelerating scientic discovery. Droplet\nmicrouidics, characterised by its ability to manipulate discrete\ndroplets in micro-scale environments, has broad applications in\nbiotechnology, medicine, and materials science. LLM agents\noﬀer unprecedented opportunities to streamline the analysis of\nvast scienti c literature, enabling researchers to identify\npatterns, generate hypotheses, and design experiments more\neﬃciently. By providing context-aware insights and generating\npredictive models, these agents can aid in optimising droplet\ngeneration, stability, and functionality, signicantly reducing\nthe time and cost associated with experimental iterations.\nFurthermore, integrating LLMs into experimental workows\ncould improve reproducibility by standardising protocols,\nenabling researchers to detect anomalies in real time, and\nenhancing collaborative research by facilitating cross-\ndisciplinary data integration. In education and training, LLM\nagents have the potential to transform how droplet micro-\nuidics is taught and applied in both academic and industrial\ncontexts. Students and professionals can leverage these agents\nto access interactive tutorials, troubleshoot experimental\nsetups, and gain deeper insights into uid dynamics and\nmaterial properties. In examinations, LLMs could be utilised to\ndesign personalised assessments that evaluate conceptual\nunderstanding and problem-solving skills in droplet micro-\nuidics. Furthermore, these agents can provide real-time feed-\nback and adaptive learning pathways, ensuring learners at all\nlevels can progress eﬀectively. Additionally, these agents can\nbridge the gap between academia and industry by oﬀ\nering\ntailored solutions for process optimisation, quality control, and\nscaling up the production of microuidic devices. By demo-\ncratising access to advanced knowledge and tools, LLM agents\ncan enable small-scale laboratories and startups to compete\nwith larger institutions, fostering innovation across diverse\nsettings.\nPrevious studies have proposed frameworks for the auto-\nmation and validation of microuidic devices, typically imple-\nmented as closed, rule-based systems.\n116–118 While eﬀective\nwithin their de ned parameters, these frameworks do not\n2848 | Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 © 2025 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nincorporate LLMs or comparable LLM agents, making it chal-\nlenging to integrate digital discovery platforms at the state of\nthe art. However, our work, droplet microuidics LLM Agents, is\ncapable of transforming them into closed-loop digital discovery\nplatforms that encompass literature synthesis, hypothesis\ngeneration, autonomous design, execution in self-driving\nlaboratories,\n31,35,119–126 analysis of results, and the generation\nof new hypotheses.\nLLM agents hold promise for advancing the automation and\noptimisation of computer-aided design (CAD) for microuidic\ndevices. The design of droplet micro uidics systems oen\nrequires precise and intricate con gurations that are chal-\nlenging and time-intensive to develop. By leveraging the\ncomputational power of LLMs, researchers can automate CAD\nprocesses, enabling rapid prototyping of novel device architec-\ntures. These agents can analyse complex datasets to re ne\nchannel geometries and droplet manipulation parameters,\nresulting in highly eﬃcient designs. Moreover, LLMs can inte-\ngrate multi-objective optimisation frameworks that balance\ntrade-oﬀs between cost, performance, and manufacturability,\nfacilitating the development of robust and scalable devices.\nAdditionally, LLMs can facilitate the implementation and\noptimisation of machine learning models tailored to the unique\nchallenges of droplet microuidics, such as predicting droplet\nbehaviour under varying conditions, identifying emergent\npatterns in high-dimensional data, and optimising device\nperformance for specic applications. This synergy between\nLLMs and machine learning could lead to breakthroughs in\nmicrouidic technologies, unlocking new applications in diag-\nnostics, drug discovery, and synthetic biology. However, inte-\ngrating LLM agents into droplet microuidics research and\ndevelopment is challenging. Data quality, model interpret-\nability, and the risk of over-reliance on automated systems must\nbe addressed. For instance, the variability in experimental\nconditions and datasets could lead to biased or suboptimal\nrecommendations if not rigorously curated. Furthermore,\nensuring the security of sensitive experimental data and\nproprietary designs is crucial in preventing intellectual property\nthe or misuse. Ethical concerns also arise regarding the\ndisplacement of traditional skill sets and the potential mar-\nginalisation of researchers who may lack access to LLM-driven\ntools. Addressing these challenges requires a concerted eﬀort\nto establish best practices, including transparent validation\nmetrics, collaborative governance frameworks, and robust\ntraining programs. Despite these hurdles, the transformative\npotential of LLM agents in advancing droplet microuidics is\nundeniable. By bridging the gaps between computational\nintelligence, experimental precision, and educational accessi-\nbility, these agents promise to accelerate innovation and expand\nthe horizons of this dynamiceld.\nAuthor contributions\nConceptualization – N.-D. D.; methodology– D.-N. N., N.-D. D.;\ninvestigation – D.-N. N.; data curation – D.-N. N.; writing –\noriginal dra – D.-N. N.; writing– review & editing– D.-N. N., N.-\nD. D.; supervision– R. K.-Y. T., N.-D. D.; funding acquisition– R.\nK.-Y. T., N.-D. D.\nConﬂicts of interest\nThere are no conicts to declare.\nData availability\nThe datasets and code for the analyses andgure generations in\nthis work are publicly available on GitHub at url: https://\ngithub.com/duydinhlab/DMFAgents (DOI: https://doi.org/\n10.5281/zenodo.16875111).\nThe supplementary information includes the framework\noutputs, the ground-truth QA dataset, and the collection of PDF\ndocuments used for database construction. See DOI:https://\ndoi.org/10.1039/d5dd00306g.\nAcknowledgements\nWe gratefully acknowledge the funding provided by the\nResearch Grant Council of Hong Kong, General Research Fund\n(Ref No. 14211223).\nReferences\n1 G. M. Whitesides,Nature, 2006,442, 368– 373.\n2 Y. Ding, P. D. Howes and A. J. Demello,Anal. Chem., 2020,\n92, 132– 149.\n3 E. Y. u. Basova and F. Foret,Analyst, 2014,140,2 2– 38.\n4 T. Moragues,et al., Nat. Rev. Methods Primers, 2023,3,1 – 22.\n5 N. D. Dinh,et al., Lab Chip, 2013,13, 1402– 1412.\n6 N. D. Dinh,et al., Small, 2017,13, 1700684.\n7 H. Tan, S. Guo, N. D. Dinh, R. Luo, L. Jin and C. H. Chen,\nNat. Commun., 2017,8,1 – 10.\n8 N. D. Dinh,et al., Lab Chip, 2020,20, 2756– 2764.\n9 N.-D. Dinh,et al., arXiv, 2024, preprint, arXiv:2501.01962v1,\nDOI: 10.48550/arXiv.2501.01962v1.\n10 R. Zilionis,et al., Nat. Protoc., 2016,12,4 4– 73.\n11 M. Pellegrino,et al., Genome Res., 2018,28, 1345– 1352.\n12 X. Zhang,et al., Mol. Cell, 2019,73(1), 130– 142.e5.\n13 A. M. Klein,et al., Cell, 2015,161, 1187– 1201.\n14 E. Z. Macosko,et al., Cell, 2015,161, 1202– 1214.\n15 A. G´erard, et al., Nat. Biotechnol., 2020,38, 715– 721.\n16 K. Fischer,et al., Nat. Biotechnol., 2025,43, 960– 970.\n17 J. J. Agresti,et al., Proc. Natl. Acad. Sci. U. S. A., 2010, 107,\n4004– 4009.\n18 H. Yin,et al., Biosens. Bioelectron., 2021,188, 113282.\n19 Y. Belotti and C. T. Lim,Anal. Chem., 2021,93, 4727– 4738.\n20 T. S. Kaminski, O. Scheler and P. Garstecki,Lab Chip, 2016,\n16, 2168– 2187.\n21 D. T. Chiu,et al., Chem, 2017,2, 201– 223.\n22 F. Su, K. Chakrabarty and R. B. Fair,IEEE Trans. Comput.\nAided Des. Integrated Circ. Syst., 2006,25, 211– 223.\n23 S. Battat, D. A. Weitz and G. M. Whitesides,Lab Chip, 2022,\n22, 530– 536.\n© 2025 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 | 2849\nPaper Digital Discovery\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\n24 D. McIntyre, A. Lashkaripour, P. Fordyce and D. Densmore,\nLab Chip, 2022,22, 2925– 2937.\n25 A. Lashkaripour,et al., Nat. Commun., 2021,12,1 – 14.\n26 D. Nguyen, R. K. Tong and N. Dinh,arXiv, 2024, preprint,\narXiv:2411.06691v1, DOI:10.48550/arXiv.2411.06691v1.\n27 S. A. Damiati,et al., Sci. Rep., 2020,10,1 – 11.\n28 S. H. Hong, H. Yang and Y. Wang,Microuid. Nanouid.,\n2020, 24,1 – 20.\n29 W. Ji, T. Y. Ho, J. Wang and H. Yao,IEEE Trans. Comput.\nAided Des. Integrated Circ. Syst., 2020,39, 2544– 2557.\n30 T. Savage,et al., Nat. Chem. Eng., 2024,1, 522– 531.\n31 A. A. Volk,et al., Nat. Commun., 2023,14,1 – 16.\n32 Y. Pan,et al., Chem. Eng. Sci., 2025,311, 121567.\n33 J. Wei,et al., arXiv, 2022, preprint, arXiv:2206.07682v2, DOI:\n10.48550/arXiv.2206.07682v2.\n34 Z. Zheng,et al., Angew Chem. Int. Ed. Engl., 2023,62(46), 1– 8.\n35 D. A. Boiko, R. MacKnight, B. Kline and G. Gomes,Nature,\n2023, 624, 570– 578.\n36 Z. Zheng, O. Zhang, C. Borgs, J. T. Chayes and O. M. Yaghi,\nJ. Am. Chem. Soc., 2023,145, 18048– 18062.\n37 K. M. Jablonka, P. Schwaller, A. Ortega-Guerrero and\nB. Smit,Nat. Mach. Intell., 2024,6, 161– 169.\n38 A. M. Bran, S. Cox, O. Schilter, C. Baldassari, A. D. White\nand P. Schwaller,Nat. Mach. Intell., 2024,6, 525– 535.\n39 W. Hou and Z. Ji,Nat. Methods, 2024,21, 1462– 1465.\n40 H. Cui, C. Wang, H. Maan, K. Pang, F. Luo, N. Duan and\nB. Wang,Nat. Methods, 2024,21, 1470– 1480.\n41 R. Riveland and A. Pouget,Nat. Neurosci., 2024,27, 988– 999.\n42 Z. Lin,et al., Science, 2023,379, 1123– 1130.\n43 Z. Xiao, W. Li, H. Moon, G. W. Roell, Y. Chen and Y. J. Tang,\nACS Synth. Biol., 2023,12, 2973– 2982.\n44 J. Lee,et al., Bioinformatics, 2019,36, 1234– 1240.\n45 Q. Chen,et al., Bioinformatics, 2023,39(9), 1– 9.\n46 S. Thapa and S. Adhikari,Ann. Biomed. Eng., 2023,51, 2647–\n2651.\n47 Q. Jin, Y. Yang, Q. Chen and Z. Lu,Bioinformatics, 2023,\n40(2), 1– 8.\n48 X. Zhang, Z. Zhou, C. Ming and Y. Y. Sun,J. Phys. Chem.\nLett., 2023,14, 11342– 11349.\n49 Z. Hong,Energy Mater. Adv., 2023,4,1 – 3.\n50 M. P. Polak and D. Morgan,Nat. Commun., 2024,15,1 – 11.\n51 J. Choi and B. Lee,Commun. Mater., 2024,5,1 – 11.\n52 O. N. Oliveira, L. Christino, M. Oliveira and F. V. Paulovich,\nJ. Chem. Inf. Model., 2023,63, 7605– 7609.\n53 T. Xie,et al., arXiv, 2023, preprint, arXiv:2304.02213v5, DOI:\n10.48550/arXiv.2311.07361v2.\n54 M. Zaki,et al., Digital Discovery, 2024,3, 313– 327.\n55 D. Van Veen,et al., Nat. Med., 2024,30, 1134– 1142.\n56 F. Wong, C. de la Fuente-Nunez and J. J. Collins,Science,\n2023, 381, 164– 170.\n57 M. Moor,et al., Nature, 2023,616, 259– 265.\n58 R. Wang, H. Feng and G. W. Wei,J. Chem. Inf. Model., 2023,\n63, 7189– 7209.\n59 A. J. Thirunavukarasu, et al., Nat. Med., 2023, 29, 1930–\n1940.\n60 Y. Wang, Y. Zhao and L. Petzold,Proc. Mach. Learn. Res.,\n2023, vol. 219, pp. 804– 823.\n61 H. Wang,et al., Nature, 2023,620,4 7– 60.\n62 C. Stokel-Walker and R. Van Noorden,Nature, 2023, 614,\n214– 216.\n63 K. M. Merz, G. W. Wei and F. Zhu,J. Chem. Inf. Model., 2023,\n63, 5395.\n64 M. R. AI4Science and M. A. Quantum,arXiv, 2023, preprint,\narXiv:2311.07361v2, DOI:10.48550/arXiv.2311.07361v2.\n65 Y. Zhang,et al., arXiv, 2023, preprint, arXiv:2309.01219v2,\nDOI: 10.48550/arXiv.2309.01219v2.\n66 M. Sallam,Healthcare, 2023,11(6), 1– 20.\n67 P. Lewis,et al., Adv. Neural Inf. Process. Syst., 2020, 9459–\n9474.\n68 Y. Gao, et al., arXiv, 2023, preprint, arXiv:2312.10997v5,\nDOI: 10.48550/arXiv.2312.10997v5.\n69 J. Li,et al., arXiv, 2024, preprint, arXiv:2402.05120v2, DOI:\n10.48550/arXiv.2402.05120v2.\n70 J. S. Park,et al., UIST 2023– Proc. 36th Annu. ACM Symp. User\nInterface Sow. Technol., 2023.\n71 L. Wang,et al., Front. Comput. Sci., 2023,18(6), 1– 26.\n72 A. Zhao,et al., Proc. AAAI Conf. Artif. Intell., 2023,38, 19632–\n19642.\n73 T. Guo, et al., arXiv, 2024, preprint, arXiv:2402.01680v2,\nDOI: 10.48550/arXiv.2402.01680v2.\n74 C. Gao,et al., Humanit. Soc. Sci. Commun., 2024,11,1 – 24.\n75 M. D. Skarlinski, et al. , arXiv, 2024, preprint,\narXiv:2409.13740v2, DOI:10.48550/arXiv.2409.13740v2.\n76 J. Li,et al., arXiv, 2024, preprint, arXiv:2405.02957v1, DOI:\n10.48550/arXiv.2405.02957v1.\n77 X. Tang, et al., arXiv, 2024, preprint, arXiv:2311.10537v4,\nDOI: 10.48550/arXiv.2311.10537v4.\n78 S. Schmidgall, et al. , arXiv, 2024, preprint,\narXiv:2405.07960v4, DOI:10.48550/arXiv.2405.07960v4.\n79 A. Dubey,et al., arXiv, 2024, preprint, arXiv:2407.21783v2,\nDOI: 10.48550/arXiv.2407.21783v2.\n80 A. Q. Jiang,et al., arXiv, 2023, preprint, arXiv: 2310.06825v1,\nDOI: 10.48550/arXiv.2310.06825v1.\n81 G. Team,et al., arXiv, 2024, preprint, arXiv:2408.00118v3,\nDOI: 10.48550/arXiv.2408.00118v3.\n82 Y. Li,Int. Conf. Recent Adv. Nat. Lang. Process. RANLP, 2023,\npp. 641– 647.\n83 L. Wang,et al., npj Digit. Med., 2024,7,1 – 9.\n84 P. Liu,et al., ACM Comput. Surv., 2021,55(9), 1– 35.\n85 L. Reynolds and K. McDonell, arXiv, 2021, preprint,\narXiv:2102.07350v1, DOI:10.48550/arXiv.2102.07350v1.\n86 T. B. Brown, et al. , arXiv, 2020, preprint,\narXiv:2005.14165v4, DOI:10.48550/arXiv.2005.14165v4.\n87 J. White, et al., arXiv, 2023, preprint, arXiv:2302.11382v1,\nDOI: 10.48550/arXiv.2302.11382v1.\n88 Z. Sun, et al., arXiv, 2022, preprint, arXiv:2210.01296v2,\nDOI: 10.48550/arXiv.2210.01296v2.\n89 T. Kojima,et al., arXiv, 2022, preprint, arXiv:2205.11916v4,\nDOI: 10.48550/arXiv.2205.11916v4.\n90 J. Wei,et al., arXiv, 2022, preprint, arXiv:2201.11903v6, DOI:\n10.48550/arXiv.2201.11903v6.\n91 S. Huo, et al., arXiv, 2023, preprint, arXiv:2309.11392v1,\nDOI: 10.48550/arXiv.2309.11392v1.\n2850 | Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 © 2025 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\n92 R. Wang,et al., arXiv, 2023, preprint, arXiv:2305.13733v2,\nDOI: 10.48550/arXiv.2305.13733v2.\n93 H. Su,et al., arXiv, 2022, preprint, arXiv:2212.09741v3, DOI:\n10.48550/arXiv.2212.09741v3.\n94 L. Wang,et al., arXiv, 2024, preprint, arXiv:2402.05672v1,\nDOI: 10.48550/arXiv.2402.05672v1.\n95 L. Caspari,et al., arXiv, 2024, preprint, arXiv:2407.08275v1,\nDOI: 10.48550/arXiv.2407.08275v1.\n96 L. Wang,et al., arXiv, 2022, preprint, arXiv:2212.03533v2,\nDOI: 10.48550/arXiv.2212.03533v2.\n97 J. Lee,et al., arXiv, 2019, preprint, arXiv:1901.08746v4, DOI:\n10.48550/arXiv.1901.08746v4.\n98 Y. Liu,et al., arXiv, 2019, preprint, arXiv:1907.11692v1, DOI:\n10.48550/arXiv.1907.11692v1.\n99 S. R. Bhat,et al., arXiv, 2025, preprint, arXiv:2505.21700v2,\nDOI: 10.48550/arXiv.2505.21700v2.\n100 G. Xiong,et al., arXiv, 2024, preprint, arXiv:2402.13178v2,\nDOI: 10.48550/arXiv.2402.13178v2.\n101 K. Juvekar and A. Purwar, arXiv, 2024, preprint,\narXiv:2407.19794v2, DOI:10.48550/arXiv.2407.19794v2.\n102 A. J. Yepes,et al., arXiv, 2024, preprint, arXiv:2402.05131v3,\nDOI: 10.48550/arXiv.2402.05131v3.\n103 A. Ammar,et al., arXiv, 2025, preprint, arXiv:2505.08445v1,\nDOI: 10.48550/arXiv.2505.08445v1.\n104 M. Renze and E. Guven, arXiv, 2024, preprint,\narXiv:2402.05201v3, DOI:10.48550/arXiv.2402.05201v3.\n105 C. Wang, S. X. Liu and A. H. Awadallah, arXiv, 2023,\npreprint, arXiv:2303.04673v2, DOI: 10.48550/\narXiv.2303.04673v2.\n106 P.-H. Wang, et al. , arXiv, 2020, preprint,\narXiv:2012.13575v1, DOI:10.48550/arXiv.2012.13575v1.\n107 G. Hinton,et al., arXiv, 2015, preprint, arXiv:1503.02531v1,\nDOI: 10.48550/arXiv.1503.02531v1.\n108 M. Peeperkorn, et al. , arXiv, 2024, preprint,\narXiv:2405.00492v1, DOI:10.48550/arXiv.2405.00492v1.\n109 D. Patel, et al., medRxiv, 2024, preprint, DOI: 10.1101/\n2024.07.22.24310824.\n110 A. Holtzman, et al. , arXiv, 2019, preprint,\narXiv:1904.09751v2, DOI:10.48550/arXiv.1904.09751v2.\n111 M. N. Nguyen, et al. , arXiv, 2024, preprint,\narXiv:2407.01082v6, DOI:10.48550/arXiv.2407.01082v6.\n112 C. Shi,et al., arXiv, 2024, preprint, arXiv:2402.06925v3, DOI:\n10.48550/arXiv.2402.06925v3.\n113 H. Bansal,et al., arXiv, 2024, preprint, arXiv:2408.16737v2,\nDOI: 10.48550/arXiv.2408.16737v2.\n114 D. Nadeau,et al., arXiv, 2024, preprint, arXiv:2404.09785v1,\nDOI: 10.48550/arXiv.2404.09785v1.\n115 M. P. Priola, et al. , arXiv, 2024, preprint,\narXiv:2412.04235v2, DOI:10.48550/arXiv.2412.04235v2.\n116 P. Ebner and R. Wille,Proc. IEEE Comput. Soc. Annu. Symp.\nVLSI, ISVLSI, 2024, pp. 278– 283.\n117 M. Emmerich, P. Ebner and R. Wille,IEEE Trans. Comput.\nAided Des. Integrated Circ. Syst., 2025,44, 2287– 2299.\n118 R. Wille, B. Li, R. Drechsler and U. Schlichtmann,Forum\nSpecif. Des. Lang., Garching, Germany, 2018, pp. 5– 16.\n119 H. Tao, T. Wu, S. Kheiri, M. Aldeghi, A. Aspuru-Guzik,\nE. Kumacheva, H. Tao, T. Wu, M. Aldeghi, A. Aspuru-\nGuzik, E. Kumacheva and S. Kheiri, Adv. Funct. Mater.,\n2021, 31, 2106725.\n120 R. W. Epps, A. A. Volk, K. G. Reyes and M. Abolhasani,\nChem. Sci., 2021,12, 6025– 6036.\n121 M. Abolhasani and E. Kumacheva,Nature Synthesis, 2023,2,\n483– 492.\n122 S. Sadeghi, K. Mattsson, J. Glasheen, V. Lee, C. Stark, P. Jha,\nN. Mukhin, J. Li, A. Ghorai, N. Orouji, C. H. J. Moran,\nA. Velayati, J. A. Bennett, R. B. Canty, K. G. Reyes and\nM. Abolhasani,Digital Discovery, 2025,4, 1722– 1733.\n123 H. Hysmith, E. Foadian, S. P. Padhy, S. V. Kalinin,\nR. G. Moore, O. S. Ovchinnikova and M. Ahmadi,Digital\nDiscovery, 2024,3, 621– 636.\n124 R. B. Canty, J. A. Bennett, K. A. Brown, T. Buonassisi,\nS. V. Kalinin, J. R. Kitchin, B. Maruyama, R. G. Moore,\nJ. Schrier, M. Seifrid, S. Sun, T. Vegge and M. Abolhasani,\nNat. Commun., 2025,16,1 – 11.\n125 A. Ghafarollahi and M. J. Buehler,Digital Discovery, 2024,3,\n1389– 1409.\n126 T. K. Chan and N.-D. Dinh,medRxiv, 2025, preprint, DOI:\n10.1101/2025.01.01.25319863.\n© 2025 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 5 ,4,2 8 2 7–2851 | 2851\nPaper Digital Discovery\nOpen Access Article. Published on 27 August 2025. Downloaded on 11/5/2025 5:38:46 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online",
  "topic": "Microfluidics",
  "concepts": [
    {
      "name": "Microfluidics",
      "score": 0.6851725578308105
    },
    {
      "name": "Computer science",
      "score": 0.4598027765750885
    },
    {
      "name": "Nanotechnology",
      "score": 0.32670384645462036
    },
    {
      "name": "Materials science",
      "score": 0.22512969374656677
    }
  ]
}