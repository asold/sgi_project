{
  "title": "Migratable AI: Effect of identity and information migration on users' perception of conversational AI agents",
  "url": "https://openalex.org/W3041617862",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A5057758042",
      "name": "Ravi Tejwani",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5016577458",
      "name": "Felipe Romero Moreno",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5061973924",
      "name": "Sooyeon Jeong",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5102016303",
      "name": "Hae Won Park",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5108541589",
      "name": "Cynthia Breazeal",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2552244797",
    "https://openalex.org/W1840149308",
    "https://openalex.org/W2113245105",
    "https://openalex.org/W2279037851",
    "https://openalex.org/W2044140042",
    "https://openalex.org/W2032568497",
    "https://openalex.org/W2134743267",
    "https://openalex.org/W2118462055",
    "https://openalex.org/W2116746357",
    "https://openalex.org/W2951846435"
  ],
  "abstract": "Conversational AI agents are proliferating, embodying a range of devices such as smart speakers, smart displays, robots, cars, and more. We can envision a future where a personal conversational agent could migrate across different form factors and environments to always accompany and assist its user to support a far more continuous, personalized, and collaborative experience. This opens the question of what properties of a conversational AI agent migrates across forms, and how it would impact user perception. To explore this, we developed a Migratable AI system where a user's information and/or the agent's identity can be preserved as it migrates across form factors to help its user with a task. We designed a 2x2 between-subjects study to explore the effects of information migration and identity migration on user perceptions of trust, competence, likeability, and social presence. Our results suggest that identity migration had a positive effect on trust, competence, and social presence, while information migration had a positive effect on trust, competence, and likeability. Overall, users report the highest trust, competence, likeability, and social presence towards the conversational agent when both identity and information were migrated across embodiments.",
  "full_text": "Migratable AI: Effect of identity and information migration on\nusers’ perception of conversational AI agents\nRavi Tejwani1, Felipe Moreno 1, Sooyeon Jeong 1, Hae Won Park 1,\nCynthia Breazeal1\nAbstract— Conversational AI agents are proliferating,\nembodying a range of devices such as smart speakers,\nsmart displays, robots, cars, and more. We can envision a\nfuture where a personal conversational agent could migrate\nacross different form factors and environments to always\naccompany and assist its user to support a far more\ncontinuous, personalized and collaborative experience. This\nopens the question of what properties of a conversational\nAI agent migrates across forms, and how it would impact\nuser perception. To explore this, we developed a Migratable\nAI system where a user’s information and/or the agent’s\nidentity can be preserved as it migrates across form factors\nto help its user with a task. We designed a 2x2 between-\nsubjects study to explore the effects of information migra-\ntion and identity migration on user perceptions of trust,\ncompetence, likeability and social presence. Our results\nsuggest that identity migration had a positive effect on\ntrust, competence and social presence, while information\nmigration had a positive effect on trust, competence and\nlikeability. Overall, users report highest trust, competence,\nlikeability and social presence towards the conversational\nagent when both identity and information were migrated\nacross embodiments.\nI. INTRODUCTION\nWe live in the world of personiﬁed conversational\nAI agents. We interact with these agents in our daily\nlives such as smart speakers or personal robots at home\n(e.g., Alexa [1], Google Home [2], or Jibo [3]). One\nin four U.S. adults owns a smart speaker. The smart\nspeaker sales have risen by 135% in the past 2 years\n[4]. Some of these agents have access to our personal\ncalendars and communication channels which enable\nthem to provide us personalized services. Other robots\nor devices operate in public spaces such as Pepper [5]\nin retail stores or Care-E [6] at airports.\nCurrently, these conversational agents do not share\nthe information or context with each other. As a result,\nsuch platforms do not support continuity of interac-\ntion with their users across different agent personas\nor form factors. Thereby, users ending up to repeat\nthe contextual information to each agent. This highly\nlimits the ability of conversational agents to provide\ngreater personalization, collaboration or continuity of\ninteraction across contexts to assist users.\nThe concept of agent migration has been explored in\nthe past as identity migration architectures along with\nthe user studies. The identity migration architectures\n1Massachusetts Institute of Technology, Cambridge, USA.\nFig. 1: Left to right: Home agent, Home agent migrating\nto receptionist robot, Home agent migrating to waiting\nroom assistant.\nproposed in [7] [8] [9] explored the identity cues of the\nmigratable agent as appearance, voice, and dynamics\nof motion. However, they were limited to the agent’s\nidentity speciﬁc to an artiﬁcial character and were not\ngeneralized to conversational AI agents such as Alexa,\nJibo, Google Home, etc. User studies from [10] [11]\n[12] explored the user perceptions of agents that can\nmigrate across different forms and were limited to the\nusers’ experience on the extent to which the agent\nmigration was a natural process to the users and if the\nusers’ perceived the agent to be the same agent across\ndifferent embodiments during the migration.\nWe build on these prior works to propose a sys-\ntem for the migration of conversational AI assistants\n(agents) such as Jibo [3], Alexa [1] and Google Home\n[2]. We infer user intents from the conversation using\nnatural language processing and map them to differ-\nent physical embodiments. Furthermore, we propose\na generalized system that allows the migration of any\nconversational AI agent rather than a predeﬁned char-\nacter. Also, we speciﬁcally explore two key elements of\nthe migration, i.e., identity migration and information\nmigration, in our system. We validate the system using\nthe 2x2 study to measure the users’ perceptions such as\ntrust, competence, likeability and social presence across\nmultiple physical embodiments. The results from this\nstudy informs further development of this system.\nThis paper offers the following contributions. First,\nwe present a migratable AI system that allows a user\nProceedings of the 29th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN\n2020. Copyright 2021 by the author(s).\n1\narXiv:2007.05801v3  [cs.CY]  4 Sep 2021\nto continue their interaction/task from one embodi-\nment to the next while maintaining the same persona\nand/or information. Second, we designed and ran a\n2x2 between-subjects study on 72 users using informa-\ntion migration and identity migration as parameters.\nWe explore these properties in a task-based scenario\nwhere a person interacts with three different smart\ndevices in three different locations. Our motivation in\nthe study for using measures of trust, competence, and\nsocial presence was that the user’s perception on these\nmeasures are important components that inﬂuence user\nadoption, efﬁcacy of teamwork and engagement as\ndescribed by Bartneck et al. [13], Dawes et al. [14] and\nDestino et al. [15].\nII. RELATED WORK\nAgent migration has been explored through a variety\nof prior works as shown in Figure 2 in the form of\nIdentity migration architectures and User perception\nstudies.\nFig. 2: Evolution of the work in agent migration\nA. Identity(social presence) migration architectures\nImai et al. (1999) were the ﬁrst to explore the concept\nof agent migration. They developed the ITAKO system\n[16], demonstrated via a tour guide application where\na personal agent could migrate from mobile device to\na physical robot. Furthermore, the architectures pro-\nposed in [7] [8] [9] explored the identity cues of the\nmigratable agent as appearance, voice, and dynamics\nof motion.\nFor instance, the work by Luria et al. [17] used (1)\nconsistent eyes on a face display and (2) a consistent\nvoice and further it validated with the user enactments\nfor the migration of the agent. Also, visual cues of\nthe agent such as personality; voice; memory of past\nevents; visual appearance were suggested by the re-\nsearch by Cuba [18]. Personality was further described\nas a combination of the mood of the agent (e.g. happy,\nsad, etc.) and reaction to different events during an\ninteraction with the user (e.g. shy, arrogant, etc.) in [19].\nHowever, these architectures demonstrated the mi-\ngration of agent’s identity speciﬁc to an agent(artiﬁcial\ncharacter used in the research) and were not gen-\neralized to conversational AI agents such as Alexa,\nJibo, Google Home, etc. In our system, we provide\na platform for the migration of a conversational AI\nagent(s), capable of inferring user intents and goal,\nacross different embodiments.\nB. User Perception studies on migration\nUser studies from [10] [11] [12] explored user per-\nceptions of agents that can migrate across different\nforms. In the work by Gomes et al. [20], the migration\nof agent across the physical robotic pet (PhyPleo) and\nits virtual mobile application (ViPleo) was explored.\nThe work investigated the user experience for agent\nmigration and to what extent the agent migration was\na natural process to the users. The authors attempted\nto preserve the personality of the artiﬁcial pet across\nthe embodiments derived by interaction needs such\nas energy, water(thirst), cleanliness, petting and skill.\nIn the work by Cuba et al. [18], the migration of the\nagent was further investigated in terms of number of\nagents that the user perceived while interacting with\niCat agent in different platforms.\nThe key ﬁndings from the user studies were\n1) evaluation of the user’s perception of the agent’s\nidentity, i.e. if users perceive the agents in differ-\nent embodiments as the same identity.\n2) migratable agent having a consistent short term\ninteraction memory across multiple embodi-\nments, impacts the ability of users to perceive the\nagent as having a) one consistent identity, and b)\nhigher competence.\n3) users’ perception on the long-term interaction\nwith the migrating agent on the measure ”Reali-\nsation of Migration” - the degree to which partici-\npants felt that the migration process was success-\nfully communicated by the companion, changes\nbased on the continuity of the tasks performed\nby the agent in different bodies and the process\nof communication of the migration to the users.\n4) the embodiment to which the agent migrates\nshould maintain the interaction history and per-\nsonality as demonstrated by the group discus-\nsions in [12]\nIn this paper, we go beyond the user’s perception\nof agent’s identity in different embodiments and use\nsubjective and behavioral estimates of the migrated AI\nagent for users’ perceptions on trust, trustworthiness,\nlikability, competence and social presence by evaluating\nthe system with a 2x2 user study on 72 participants.\nIII. SYSTEM OVERVIEW\nWe developed a Migratable AI system which allows\nthe users to preserve the information context and iden-\ntity of the conversational agent, to seamlessly continue\na task with the agent across embodiments and locations\n(Figure 3).\nThe system includes the ability of the conversational\nagent to change or preserve the visual representation\n(image/GIF) as well as its voice proﬁle (Text-to-Speech\nproﬁler). Hence, to maintain the same identity across\nembodiments, the designer can migrate the visual rep-\nresentation and voice proﬁle of the agent. By changing\nFig. 3: Migratable AI System\nthe voice proﬁle (e.g., male to female) or the visual\nrepresentation (image/GIF of the agent), a different\nidentity can be expressed.\nA web camera was connected to a Raspberry Pi and\nattached to each embodiment to record the interaction.\nAdditionally, the Raspberry Pi used face detection to\nsend a wake up signal to the robot. The communication\nof information across embodiments was mediated by\na cloud instance using WebSockets - a bidirectional\ncommunication channel. The participant’s utterances,\ncaptured by the embodied agent using Speech-to-Text,\nwere sent to the cloud instance where the natural\nlanguage processing (NLP) engine resided. The NLP\nengine was implemented using Google’s Dialogﬂow\nAPI; the process involved intent classiﬁcation and en-\ntity detection to extract information parameters such\nas participant’s name, feeling, drink preference, etc.\nfrom a given sentence. The interaction with Alexa was\nimplemented as an Alexa skill, a voice driven appli-\ncation for Alexa. Furthermore, the participant’s utter-\nances were saved into a NoSQL database(MongoDB).\nThe orchestrator layer processed every request from\nan embodiment to set the relevant information and\nidentity parameters per embodied interaction.\nWe informed our design decisions from the past\nliterature on what helps users perceive an identity of an\nagent [7] [19] [18]. In our identity migration conditions,\nthe same visual characteristics (Figure 1, panda-esque\ncircular appearance) and voice (Joanna TTS) was used\nacross all embodiments to convey identity continuity\n(Figure 4).\nInformation parameters such as the person’s name,\nfeelings about the interview, drink preference and rea-\nson for visit were learned by each agent during the\nconversation. If the system was conﬁgured to migrate\ninformation across embodiments, this information was\nshared amongst the agents to maintain the continuity of\nthe interaction else the agent had to prompt the user for\nthe information. The number of conversational turns\n(four in this user study) touch basing the personal and\nnon-personal information between the agent and the\nparticipant were kept consistent across all the condi-\ntions. This might necessitate the agent to repeat certain\nquestions to the users when the information was not\nmigrated but it was to ensure that we do not create\na bias in the study and keep the conversational turns\nconsistent.\nIV . METHOD\nA. Research Questions\nTo explore what elements of the migratable behavior\nof an AI agent are a desirable enhancement for the user\nexperience, we designed and ran a study to explore\nhow information migration and identity migration of\nthe AI agent inﬂuences the users’ perceptions. We\nreport our ﬁndings on two main questions: 1) Does\nmigration of the information across embodiments affect\nthe users’ perception? 2) Does migration of the identity\nof an AI agent across embodiments affect the users’\nperception?\nB. Study Design\nWe designed a 2 × 2 between-subjects study with\nInformation migration × Identity migration. The 4\nconditions used in the study are described in Figure 5.\nWe used the aforementioned interview task scenario,\nand a combination of subjective and behavioral mea-\nsures.\nC. Hypotheses\nWe predicted that both information migration and\nidentity migration of the AI agent across embodiments\nwould have positive effects on user perceptions with\nrespect to trust, competence, likeability and social pres-\nence. Our hypotheses are as follows:\nFig. 4: Dialogue excerpt from participant’s interaction\nwith embodiments for each condition\n• H1. Participants will report higher trust, compe-\ntence, likability and social presence on agent em-\nbodiments when the information is migrated by\ntheir AI agent across embodiments than when the\ninformation is not migrated.\n• H2. Participants will report higher trust, compe-\ntence, likability and social presence on the agent\nembodiments when the identity of their AI agent\nis migrated across embodiments than when the\nidentity is not migrated.\n• H3. Participants will report their trust, competence,\nlikability and social presenceon agent embodiments\nin the order of conditions: (INF+,ID+) > (INF+,ID-\n), (INF-,ID+) > (INF-,ID-)\nD. Participants\nWe recruited 72 participants from ANONYMIZED\nFOR REVIEWusing email advertisements. Participants\nwere between 18 and 54 years old (32 female, 38 male\nand 2 other), with mean age M=24.2, SD=5.09. Partic-\nipants reported their familiarity with the personal AI\nFig. 5: Study conditions\nassistants such as Alexa or Google Home (M = 2.89, SD\n= 1.27) on a 5-point Likert scale that ranged from Never\nused before (1) to Use it daily (5). Participants were\nrandomly assigned and counterbalanced by gender\nacross the four conditions (n=18 per condition). Table I.\nThe study was approved by our Institutional Review\nBoard, and participants signed an informed consent\nform prior to the study.\nTABLE I: Participant Demographics\nCondition Female Male Other Age(Std. Dev.)\n(INF+,ID+) 8 10 0 24.4(5.06)\n(INF+,ID-) 9 9 0 24.6(6.09)\n(INF-,ID+) 7 10 1 28.2(10.2)\n(INF-,ID-) 8 9 1 22.6(3.61)\nE. Study Procedure\nIntroduction\nThe study was conducted at ANONYMIZED FOR RE-\nVIEW, and took about 45 minutes to complete. Each\nsubject began the study in our lab’s study room emu-\nlated as their ”home”. During the introduction step, the\nparticipants were not informed of all the future steps\nin the interaction.\nInteraction with the home agent\nThe interaction with Alexa remained the same across\nall conditions. During the conversation with the par-\nticipant, Alexa delivered the participant’s schedule for\nthe day which included a job interview. Throughout\nthe conversation, Alexa learned the participant’s name\nand how he/she was feeling about the interview. The\nconversation with the home agent lasted for about two\nminutes.\nInteraction with the front desk receptionist robot\nThe mobile robot was located in a hallway of the\nlab, and played the role of the front desk receptionist\nrobot at the interview location. The receptionist robot,\nchanged its appearance to look and sound like home\nagent (when identity was migrated) or continued to\nlook and sound like Kuri with a different voice proﬁle\n(when identity was not migrated). The receptionist\nrobot detected their face, recognized the participant\nby name, and acknowledged the reason for their visit\n(when information was migrated) or prompted the\n(a) Effect of information migration\n(b) Effect of identity migration\nFig. 6: Bar Plot for mean of normalized measures(bars) and the standard deviation(lines) for the inspection of\neffect of (a) information migration and (b) identity migration. * means p <.05, ** means p <.01, *** means p <.001\nparticipant for their name and reason for their visit\n(when information was not migrated). During the con-\nversation, the receptionist robot either validated the\nparticipant’s feelings (when information was migrated)\nor asked how they were feeling for their interview\n(when information was not migrated). The receptionist\nrobot also learned the participant’s drink preferences\n(coffee, water or tea) and escorted the participant to\nthe interview waiting area. The conversation with the\nreceptionist robot lasted for about two minutes exclud-\ning the walking time with the robot.\nInteraction with the waiting room assistant\nAt the interview waiting area, the participant interacted\nwith the waiting room assistant (Smart TV) which con-\nversed with the participant until the arrival of the in-\nterviewer. It changed its appearance to look and sound\nlike home agent (when the identity was migrated) or\ncontinued to look and sound like itself (when the iden-\ntity was not migrated). While the participant waited,\nit offered the participant their preferred drink (which\nit remembered in the condition when the information\nwas migrated) or offered the participant a drink while\nwaiting (when the information was not migrated). It\nalso acknowledged the participant’s feelings (when the\ninformation was migrated) and wished them good\nluck before the interviewer arrived. The conversation\nwith the waiting room assistant lasted for about two\nminutes.\nUser Survey\nUpon the completion of the task, the participants ﬁlled\nout a user perception survey questionnaire (likert scale,\ndescribed in the next section). The survey took about\n20 minutes.\nEconomic Exchange Game\nFinally, to get a behavioral measure of trust, each\nparticipant played a economic exchange game, based\non the Give-Some game (explained in the next section).\nThe game was played only once with each agent after\nﬁlling out the post questionnaire.\nV . Data Collection andMeasures\nA. Subjective Measures\n1) Questionnaires: Participants’ reported their sub-\njective responses to the questionnaires on Trust, Com-\npetence, Likeability and Social Presence for each of the\nthree embodied agents. We normalized the scores using\nhighest scale value and computed the mean for each\nembodied agent. We then averaged these values across\nthe 3 embodied agents to get a ﬁnal score per partici-\npant.\n• Trust was measured with a 7-point scale with 12\nitems adapted from Jian et al. [21] (Cronbach’s α =\n0.91).\n• Competence was measured with a 5-point scale\nwith 5 items on Perceived intelligence, adapted\nfrom the Godspeed questionnaire [13] (Cronbach’s\nα = 0.77).\n• Likeability was measured with a 5-point scale\nwith 5 items on Likeability, adapted from the God-\nspeed questionnaire [13] (Cronbach’s α = 0.88).\n• Social presencewas measured with a 7-point scale\nwith four items on Engagement, six items on Social\n(a) Trust across conditions\n (b) Competence across conditions\n(c) Likeability across conditions\n (d) Social Presence across conditions\nFig. 7: Box-plot for the normalized measures across conditions. The boundary of the box closest to zero indicates\nthe 25th percentile, the line within the box marks the mean and the boundary of the box farthest from zero\nindicates the 75th percentile. Whiskers above and below the box indicate the 10th and 90th percentiles. * means\np<.05, ** means p <.01\nRichness and three items on Perceptual Realism\nadapted from the Temple Presence Inventory (TPI)\nby Lombard and Ditton [22] (Cronbach’sα = 0.87).\n2) Sentiment Analysis of Written Responses:Sen-\ntiment analysis for understanding how the participants\nfelt about the embodiments (negative to positive) was\nperformed on their written responses on the post-\nsurvey subjective questions on trust, competence, like-\nability and socially engagment. We used Microsoft\nAzure Text Analytics API [23] for the analysis, which\nprovided the score between 0 and 1. The ﬁnal sentiment\nscore per participant was computed by averaging the\nscores for all the measures.\nB. Behavioral Data and Measures\n1) Economic exchange game for trust: The proce-\ndure for our economic game was taken from the work\nby DeSteno et al. [15] which measured trustworthiness\nof novel partners (human-human and human-robot)\nbased on the Give-Some Game [14], a variation of the\nprisoner’s dilemma which allows a wider range of\nbehaviors. In our case, the game is played between the\nparticipant and each embodied agent. Each player is\ngiven 4 tokens that the player can choose to give to the\nother player or keep. Each token worth $1 if they keep\nit, but worth $2 if given to the partner. The maximum\nsocial gain occurs when each partner gives all 4 tokens\nto the other partner (a payoff of $8 for each partner)\nresulting in a net social score of 16. The minimum social\nscore occurs when both partners choose to keep all the\ntokens (a payoff of 4 for each participant) resulting\nin a net social score of 4. The maximum individual\n(selﬁsh) payoff occurs when a partner gives no tokens\nand whose partner gives all four (a payoff of $12 for\nthe receiver and $0 for the giver). Thus the game offers\na range of social (trustworthy) behavior and also selﬁsh\n(untrustworthy) behavior.\nFrom the economic exchange game played by the\nparticipants, we calculated the social payoff, the net\nincrease in the money as a product of social behaviour,\nas the sum of tokens given by the participant ( γ) and\nthe tokens the participant predicted to receive ( ρ). We\nuse the social payoff and normalized by the maximum\nsocial payoff to calculate the trustworthiness (τ) score.\nτ = γ + ρ\nγmax + ρmax\n(1)\nThe scores were averaged across the games played by\nthe participant with each of the 3 embodied agents to\ncompute the ﬁnal trustworthiness score of the partici-\npant.\nVI. RESULTS\nA. Effect of Information migration\nAn independent t-test was run on the data with a\n95% conﬁdence interval (CI) for the mean difference.\nWe found a signiﬁcant effect of information migra-\ntion on Trust (subjective), Trustworthiness (behavioral),\nCompetence, Likeability but not on Social Presence and\nparticipants’ sentiment. (Figure 6a).\n1. Trust(subjective) and Trustworthiness (behavioral)\nscores were found to be signiﬁcantly higher when\nthe information was migrated, .668 ± .098 (Trust) and\n.497 ± .209 (Trustworthiness), than when the informa-\ntion was not migrated, .611 ± .103 (Trust) and .329 ±\n.168 (Trustworthiness), with t(70)=-2.42, p=.018 (Trust)\nand t(70)=-3.73, p=.0003 (Trustworthiness).\n2. Competence score was signiﬁcantly higher when\nthe information was migrated (.721 ± .127) than when\nthe information was not migrated (.647 ± .128) with\nt(70) = -2.46, p = .016.\n3. Likeability score was signiﬁcantly higher when\nthe information was migrated (.777 ± .116) than when\nthe information was not migrated (.710 ± .135) with\nt(70) = -2.26, p = .027.\n4. Social Presencepresence score was higher when\nthe information was migrated (.582 ± .116) than when\nthe information was not migrated (.563 ± .124) with\nt(70) = -.668, p = .506.\nThe overall sentiment score of the participants’ was\npositive when the information was migrated (.603 ±\n.191) than when the information was not migrated\n(.529 ± .195) with t(70) = -1.61, p = .112. The effect size\n(Cohen’s d) from the independent t-test on Informa-\ntion migration were Trust (.571), Trustworthiness (.879),\nCompetence (.580), Likeability (.534), Social Presence\n(.158)\nB. Effect of Identity migration\nAn independent t-test was run on the data with a\n95% conﬁdence interval (CI) for the mean difference.\nWe found a signiﬁcant effect of information migration\non Trust (subjective), Competence, Social Presence and\nparticipants’ sentiment, but not on Trustworthiness (be-\nhavioral) and Likeability. (Figure 6b).\n1. Trust (subjective) score was found signiﬁcantly\nhigher when the identity was migrated .666 ±.097 than\nwhen the identity was not migrated .613 ± .104 with\nt(70) = -2.24, p = .028; trustworthiness (behavioral)\nscore was also higher (not statistically signiﬁcant) when\nthe identity was migrated .459 ± .227 than when the\nidentity was not migrated .369 ±.176 with t(70) = -1.87,\np = .065.\n2. Competence score was signiﬁcantly higher when\nthe identity was migrated (.719 ± .109) than when the\nidentity was not migrated (.649 ± .146) with t(70) = -\n2.33, p = .023.\n3. Likeability score was higher (not statistically sig-\nniﬁcant) when the identity was migrated (.770 ± .128)\nthan when identity was not migrated (.717 ±.126) with\nt(70) = -1.77, p = .081.\n4. Social Presence score was signiﬁcantly higher\nwhen the identity was migrated (.613±.120) than when\nthe identity was not migrated (.530 ± .104) with t(70) =\n-3.14, p = .002.\nThe overall sentiment score was signiﬁcantly positive\nwhen the identity was migrated (.623±.183) than when\nthe identity was not migrated (.508 ± .193) with t(70)\n= -2.61, p = .011. The effect size (Cohen’s d) from\nthe independent t-test on Information migration were\nTrust (.528), Trustworthiness (.441), Competence (.549),\nLikeability (.418), Social Presence (.741).\nC. Effect of Information migration and Identity migration\nacross conditions\nA one-way ANOVA, Fisher’s test, across 4 conditions\non each measure, was run on the data. We chose to use\none-way ANOVA with conditions as independent vari-\nable than two-way ANOVA with information migra-\ntion and identity migration as independent variables\nbecause we were interested in comparing the measures\nacross 4 conditions.\n1. Trust Trust (subjective) and Trustworthi-\nness(behavioral) scores had a statistically signiﬁcant\neffect across conditions, F(3,68)=5.52, p=0.002 (Trust)\nand F(3,68)=10.2, p=0.00001 (Trustworthiness).\nTukey’s HSD test for pair-wise comparison across\nconditions showed that the trust and trustworthiness\nin condition (INF+,ID+) was signiﬁcantly greater\nthan (INF+,ID-) with p=.012 (Trust) and p=.002\n(Trustworthiness), (INF-,ID+) with p=.009 (Trust) and\np=.00002 (Trustworthiness) and (INF-,ID-) with p=.005\n(Trust) and p=.0003 (Trustworthiness). (Figure 7a)\n2. Competence We found statistically signiﬁcant\neffect across conditions on competence, F(3,68)=4.14,\np=0.009. Tukey’s HSD test for pair-wise comparison\nacross conditions showed that the competence in con-\ndition (INF+,ID+) was signiﬁcantly greater than (INF-\n,ID-) with p=.004. (Figure 7b).\n3. LikeabilityWe found statistically signiﬁcant effect\nacross conditions on likeability, F(3,68)=3.24, p=0.027.\nTukey’s HSD test for pair-wise comparison across\nconditions showed that the likeability in condition\n(INF+,ID+) was signiﬁcantly greater than (INF-,ID-)\nwith p=.027. (Figure 7c).\n4. Social PresenceWe found statistically signiﬁcant\neffect across conditions on social presence, F(3,68)=3.39,\np=0.023. Tukey’s HSD test for pair wise comparison\nacross conditions showed that the social presence in\ncondition (INF+,ID+) was signiﬁcantly greater than\n(INF-,ID-) with p=.043. (Figure 7d).\nThe overall sentiment score in condition\n(INF+,ID+)=(.687 ± .134) was signiﬁcantly positive\nthan (INF-,ID-) = (.501 ± .184) with p=.018.\nVII. DISCUSSION\nH1 was partially supported. We found evidence\nto support that participants reported signiﬁcantly\nhigher trust, trustworthiness, competence and likeabil-\nity across the agent embodiments when the information\nwas migrated than not migrated.\nH2 was partially supported. We found evidence to\nsupport that participants reported signiﬁcantly higher\ntrust, competence, likeability and social presence across\nthe agent embodiments when the identity of the AI\nagent was migrated than not migrated.\nWhen the information was migrated but the identity\nof the AI agent was not migrated, the participants did\nnot like the fact that the other agents knew about their\nconversation from previous agent. P51 said ”I did not\ntrust the agents well because they seemed to share all of\nthe information about me, and I did not want to disclose\nmore.”. Also, P39 said ”... especially after the receptionist\nagent knew what I told Alexa, I no longer trusted Alexa”.\nAlternatively, when the identity was migrated but the\ninformation of the AI agent was not migrated, the\nparticipants did not perceive it to be their own agent.\nP9 said ”it was not that engaging because it didn’t feel that\nmy agent was there”.\nH3 Participants perception was reported highest on\nall the measures in the condition when both informa-\ntion and identity of the AI agent were migrated. This\nﬁnding is noteworthy because it suggests that both the\nelements of migration of an AI agent are important to\nhave a signiﬁcant effect on user’s perception. This was\ncorroborated by the comments by the participants in\nthis condition. Participant P21 said “I think it remembers\nthat I am anxious about the interview. That means it cares\nabout me and makes it different from, for example, a coffee\nmachine.” Another participant, P34, said, “Being familiar\nwith Alexa, allowed me to trust Receptionist and TV agent”.\nVIII. CONCLUSION\nWe presented a system that enables an AI agent\nto migrate its persona and information to its next\nembodiment, thereby providing continuity of task col-\nlaboration and context across embodiments. In order\nto validate the efﬁcacy of the system, we conducted a\nstudy to investigate the elements of migration, infor-\nmation and identity migration, on users’ perception on\ntrust, competence, likability and social presence across\nembodiments. We found that the users’ perceptions\nwere reported the most positive across all measures\nwhen both information and identity of the AI agent\nwas migrated across devices.\nSince the scope of our research question is on the\nuser’s perception of information and identity migration\nacross embodiments, we analyzed the experience as a\nwhole using averaging. Analyzing each embodiment\neffect separately yielded similar trends as the average\nacross embodiments. We also acknowledge that the\nfamiliarity with the brand of agents (Amazon/Google)\ncould have had an effect on users’ perceptions. How-\never, we observe that even in cases of strong brand\npresence (Google logo on Smart TV), the general trend\nof user perception remained the same as in agents with\nno strong brand presence.\nReferences\n[1] A. Alexa, Alexa, 2014, https://developer.amazon.com/alexa.\n[2] Google, Google Home , 2013, https://store.google.com/gb/\nproduct/google home.\n[3] Jibo, Jibo, 2017, https://www.jibo.com.\n[4] npm, npm, 2019, https://www.nationalpublicmedia.com/\ninsights/reports/smart-audio-report/.\n[5] S. Robotics, Pepper, 2015, https://www.softbankrobotics.com/\nus/pepper.\n[6] KLM, care-e, 2018, http://klmcare-e-entry.com.\n[7] R. Aylett, M. Kriegel, P . Cuba, M. Vala, A. Paiva, K. Koay,\nK. Arent, E. M ´arquez Segura, S. Nylander, H. Cramer, et al.,\n“Body–hopping: Migrating artiﬁcial intelligent agents between\nembodiments.”\n[8] L. with Robots and I. Companions, Lirec, 2009, http://lirec.eu.\n[9] B. R. Duffy, G. M. O’Hare, A. N. Martin, J. F. Bradley, and\nB. Schon, “Agent chameleons: Agent minds and bodies,” in\nProceedings 11th IEEE International Workshop on Program Com-\nprehension. IEEE, 2003, pp. 118–125.\n[10] K. L. Koay, D. S. Syrdal, W. C. Ho, and K. Dautenhahn, “Proto-\ntyping realistic long-term human-robot interaction for the study\nof agent migration,” in 2016 25th IEEE International Symposium\non Robot and Human Interactive Communication (RO-MAN). IEEE,\n2016, pp. 809–816.\n[11] P . C. Ready, “Migration between two embodiments of an artiﬁ-\ncial pet.”\n[12] D. S. Syrdal, K. L. Koay, M. L. Walters, and K. Dautenhahn, “The\nboy-robot should bark!-children’s impressions of agent migra-\ntion into diverse embodiments,” in Proceedings: New Frontiers of\nHuman-Robot Interaction, a symposium at AISB, 2009.\n[13] C. Bartneck, D. Kuli ´c, E. Croft, and S. Zoghbi,\n“Measurement instruments for the anthropomorphism,\nanimacy, likeability, perceived intelligence, and perceived\nsafety of robots,” International Journal of Social Robotics ,\nvol. 1, no. 1, pp. 71–81, Jan 2009. [Online]. Available:\nhttps://doi.org/10.1007/s12369-008-0001-3\n[14] R. M. Dawes, “Social dilemmas,” Annual Review of Psychology,\nvol. 31, no. 1, pp. 169–193, 1980. [Online]. Available: https:\n//doi.org/10.1146/annurev.ps.31.020180.001125\n[15] D. Desteno, C. Breazeal, R. Frank, D. Pizarro, J. Wormwood,\nL. Dickens, and J. Lee, “Detecting the trustworthiness of novel\npartners in economic exchange,” Psychological science, vol. 23, 11\n2012.\n[16] M. Imai, T. Ono, and T. Etani, “Agent migration: communica-\ntions between a human and robot,” in IEEE SMC’99 Conference\nProceedings. 1999 IEEE International Conference on Systems, Man,\nand Cybernetics (Cat. No. 99CH37028), vol. 4. IEEE, 1999, pp.\n1044–1048.\n[17] M. Luria, S. Reig, X. Z. Tan, A. Steinfeld, J. Forlizzi,\nand J. Zimmerman, “Re-embodiment and co-embodiment:\nExploration of social presence for robots and conversational\nagents,” in Proceedings of the 2019 on Designing Interactive\nSystems Conference, ser. DIS ’19. New York, NY, USA: ACM,\n2019, pp. 633–644. [Online]. Available: http://doi.acm.org/\n10.1145/3322276.3322340\n[18] P . Cuba, “Agent migration between bodies and platforms,” 2010.\n[19] A. Martin, G. M. O’hare, B. R. Duffy, B. Sch ¨on, and J. F. Bradley,\n“Maintaining the identity of dynamically embodied agents,” in\nInternational Workshop on Intelligent Virtual Agents. Springer,\n2005, pp. 454–465.\n[20] P . F. Gomes, A. Sardinha, E. M ´arquez Segura, H. Cramer, and\nA. Paiva, “Migration between two embodiments of an artiﬁcial\npet,” International Journal of Humanoid Robotics, vol. 11, no. 01,\np. 1450001, 2014.\n[21] J.-Y. Jian, A. Bisantz, and C. Drury, “Foundations for an em-\npirically determined scale of trust in automated systems,” In-\nternational Journal of Cognitive Ergonomics, vol. 4, pp. 53–71, 03\n2000.\n[22] M. Lombard, T. B. Ditton, and L. Weinstein, “Measuring pres-\nence: the temple presence inventory,” in Proceedings of the 12th\nAnnual International Workshop on Presence, 2009, pp. 1–15.\n[23] Microsoft, Text Analytics, 2010, https://azure.microsoft.com/en-\nus/services/cognitive-services/text-analytics/.",
  "topic": "Competence (human resources)",
  "concepts": [
    {
      "name": "Competence (human resources)",
      "score": 0.7163019180297852
    },
    {
      "name": "Perception",
      "score": 0.7064896821975708
    },
    {
      "name": "Dialog system",
      "score": 0.5515918731689453
    },
    {
      "name": "Identity (music)",
      "score": 0.5108206272125244
    },
    {
      "name": "Psychology",
      "score": 0.4866657853126526
    },
    {
      "name": "Social identity theory",
      "score": 0.4742411971092224
    },
    {
      "name": "Human–computer interaction",
      "score": 0.46383389830589294
    },
    {
      "name": "Social competence",
      "score": 0.45695000886917114
    },
    {
      "name": "Computer science",
      "score": 0.44609007239341736
    },
    {
      "name": "Internet privacy",
      "score": 0.39927077293395996
    },
    {
      "name": "Social psychology",
      "score": 0.38299185037612915
    },
    {
      "name": "World Wide Web",
      "score": 0.3121023178100586
    },
    {
      "name": "Dialog box",
      "score": 0.2752244472503662
    },
    {
      "name": "Social group",
      "score": 0.18070057034492493
    },
    {
      "name": "Social change",
      "score": 0.10857203602790833
    },
    {
      "name": "Political science",
      "score": 0.08187982439994812
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Acoustics",
      "score": 0.0
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I63966007",
      "name": "Massachusetts Institute of Technology",
      "country": "US"
    }
  ]
}