{
    "title": "Exploring the Potentials of Large Language Models in Vascular and Interventional Radiology: Opportunities and Challenges",
    "url": "https://openalex.org/W4394978621",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A4307156778",
            "name": "Taofeeq Oluwatosin Togunwa",
            "affiliations": [
                "University College Hospital, Ibadan",
                "University of Ibadan"
            ]
        },
        {
            "id": "https://openalex.org/A5095789480",
            "name": "Abdulquddus Ajibade",
            "affiliations": [
                "University of Ibadan"
            ]
        },
        {
            "id": "https://openalex.org/A5073381551",
            "name": "Christabel Uche-Orji",
            "affiliations": [
                "University of Ibadan",
                "University College Hospital, Ibadan"
            ]
        },
        {
            "id": "https://openalex.org/A4267536921",
            "name": "Richard OLATUNJI",
            "affiliations": [
                "University of Ibadan"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4384202806",
        "https://openalex.org/W4205184366",
        "https://openalex.org/W4214731336",
        "https://openalex.org/W4385230908",
        "https://openalex.org/W2106422722",
        "https://openalex.org/W6778883912",
        "https://openalex.org/W4384561707",
        "https://openalex.org/W4378672794",
        "https://openalex.org/W4387398715",
        "https://openalex.org/W2981852735",
        "https://openalex.org/W4327946446",
        "https://openalex.org/W4362601804",
        "https://openalex.org/W4319662928",
        "https://openalex.org/W4388775426",
        "https://openalex.org/W4282983782",
        "https://openalex.org/W4385430086",
        "https://openalex.org/W4318069287",
        "https://openalex.org/W4383501206",
        "https://openalex.org/W2782947014",
        "https://openalex.org/W3156038334",
        "https://openalex.org/W4319301505",
        "https://openalex.org/W4376640725",
        "https://openalex.org/W2963353367",
        "https://openalex.org/W4387880927",
        "https://openalex.org/W4365443750",
        "https://openalex.org/W4380893785",
        "https://openalex.org/W4367609864",
        "https://openalex.org/W4309475162",
        "https://openalex.org/W4366989525",
        "https://openalex.org/W4380558495",
        "https://openalex.org/W4294837428",
        "https://openalex.org/W3135939397",
        "https://openalex.org/W4385416665",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W4383377279",
        "https://openalex.org/W4376118634",
        "https://openalex.org/W4295939140",
        "https://openalex.org/W4288089799"
    ],
    "abstract": "Abstract The increasing integration of artificial intelligence (AI) in healthcare, particularly in vascular and interventional radiology (VIR), has opened avenues for enhanced efficiency and precision. This narrative review delves into the potential applications of large language models (LLMs) in VIR, with a focus on Chat Generative Pre-Trained Transformer (ChatGPT) and similar models. LLMs, designed for natural language processing, exhibit promising capabilities in clinical decision-making, workflow optimization, education, and patient-centered care. The discussion highlights LLMs' ability to analyze extensive medical literature, aiding radiologists in making informed decisions. Moreover, their role in improving clinical workflow, automating report generation, and intelligent patient scheduling is explored. This article also examines LLMs' impact on VIR education, presenting them as valuable tools for trainees. Additionally, the integration of LLMs into patient education processes is examined, highlighting their potential to enhance patient-centered care through simplified and accurate medical information dissemination. Despite these potentials, this paper discusses challenges and ethical considerations, including AI over-reliance, potential misinformation, and biases. The scarcity of comprehensive VIR datasets and the need for ongoing monitoring and interdisciplinary collaboration are also emphasized. Advocating for a balanced approach, the combination of LLMs with computer vision AI models addresses the inherently visual nature of VIR. Overall, while the widespread implementation of LLMs in VIR may be premature, their potential to improve various aspects of the discipline is undeniable. Recognizing challenges and ethical considerations, fostering collaboration, and adhering to ethical standards are essential for unlocking the full potential of LLMs in VIR, ushering in a new era of healthcare delivery and innovation.",
    "full_text": "Exploring the Potentials of Large Language\nModels in Vascular and Interventional\nRadiology: Opportunities and Challenges\nTaofeeq Oluwatosin Togunwa1,2 Abdulquddus Ajibade1 Christabel Uche-Orji 1,2 Richard Olatunji1\n1 Department of Radiology, College of Medicine, University of Ibadan,\nOyo, Nigeria\n2 College Research and Innovation Hub, University College Hospital,\nIbadan, Oyo, Nigeria\nArab J Intervent Radiol 2024;8:63–69.\nAddress for correspondence Taofeeq Oluwatosin Togunwa, MBBS,\nDepartment of Radiology, College of Medicine, University of Ibadan,\nOyo 200212, Nigeria (e-mail: togunwataofeeq@gmail.com).\nIntroduction\nOver the past decade, the popularity and utilization of\nartiﬁcial intelligence (AI) within the healthcare industry\nhave experienced a signiﬁcant surge.1 This has led to the\npotential for substantial enhancements in healthcare efﬁ-\nciency and precision, ultimately resulting in improved pa-\ntient care, more informed decision-making, and\nKeywords\n► artificial intelligence\n► vascular and\ninterventional\nradiology\n► large language\nmodels\n► machine learning\n► radiology\n► patient-centered care\nAbstract The increasing integration of artiﬁcial intelligence (AI) in healthcare, particularly in\nvascular and interventional radiology (VIR), has opened avenues for enhanced efﬁcien-\ncy and precision. This narrative review delves into the potential applications of large\nlanguage models (LLMs) in VIR, with a focus on Chat Generative Pre-Trained Trans-\nformer (ChatGPT) and similar models. LLMs, designed for natural language processing,\nexhibit promising capabilities in clinical decision-making, work ﬂow optimization,\neducation, and patient-centered care. The discussion highlights LLMs’ability to analyze\nextensive medical literature, aiding radiologists in making informed decisions. More-\nover, their role in improving clinical workﬂow, automating report generation, and\nintelligent patient scheduling is explored. This article also examines LLMs’impact on\nVIR education, presenting them as valuable tools for trainees. Additionally, the\nintegration of LLMs into patient education processes is examined, highlighting their\npotential to enhance patient-centered care through simpliﬁed and accurate medical\ninformation dissemination. Despite these potentials, this paper discusses challenges\nand ethical considerations, including AI over-reliance, potential misinformation, and\nbiases. The scarcity of comprehensive VIR datasets and the need for ongoing\nmonitoring and interdisciplinary collaboration are also emphasized. Advocating for a\nbalanced approach, the combination of LLMs with computer vision AI models addresses\nthe inherently visual nature of VIR. Overall, while the widespread implementation of\nLLMs in VIR may be premature, their potential to improve various aspects of the\ndiscipline is undeniable. Recognizing challenges and ethical considerations, fostering\ncollaboration, and adhering to ethical standards are essential for unlocking the full\npotential of LLMs in VIR, ushering in a new era of healthcare delivery and innovation.\narticle published online\nApril 19, 2024\nDOI https://doi.org/\n10.1055/s-0044-1782663.\nISSN 2542-7075.\n© 2024. The Author(s).\nThis is an open access article published by Thieme under the terms of the\nCreative Commons Attribution License, permitting unrestricted use,\ndistribution, and reproduction so long as the original work is properly cited.\n(https://creativecommons.org/licenses/by/4.0/).\nThieme Medical and Scientiﬁc Publishers Pvt. Ltd., A-12, 2nd Floor,\nSector 2, Noida-201301 UP, India\nTHIEME\nReview Article 63\nArticle published online: 2024-04-19\nconsiderable cost savings. AI facilitates the evaluation and\nanalysis of various disease conditions, often using complex\nand rapidly expanding datasets. Many times, AI achieves\nremarkable accuracy and depth in these tasks by harnessing\ncutting-edge concepts and technologies such as machine\nlearning (ML), neural networks (NNs), and large language\nmodels (LLM).\n2\nThe discipline of vascular and interventional radiology\n(VIR) has also seen signiﬁcant advancements in recent years,\nwith an increase in the number of procedures performed,\nsubspecialization, and improved accuracy in interventions.3\nThe demonstrated AI applications in various VIR use cases\nabounds including AI-assisted endovascular clot retrieval for\nacute ischemic stroke, predicting responses to transcatheter\narterial chemoembolization in hepatocellular carcinoma, AI-\nguided ultrasound in echocardiography, and angiography-\nbased ML algorithms for real-time estimation of fractional\nﬂow reserve.\n4,5 So, as VIR techniques and procedures mature\nand achieve wider acceptance, it could prove more useful in\nmultidisciplinary care with the incorporation of AI poten-\ntially leading to improved outcomes for all stakeholders.\n6\nIn this context, VIR is the frontier of the concept of\nImaging 3.0, an initiative aimed at showcasing the expanded\ncontributions of radiologists beyond conventional image\ninterpretation.\n7 In detailing key aspects, VIR shows its pivotal\nrole in percutaneous, image-guided procedures such as\nabscess drainage and needle biopsy. This emphasizes the\nspecialty’s capacity to reduce morbidity, enhance patient\noutcomes, and offer cost-effective alternatives to other sur-\ngical interventions. Additionally, the signiﬁcance of trans-\njugular intrahepatic portosystemic shunts and the central\nrole of interventional radiologists in delivering cost-effective\ncentral venous access services are emphasized, making\nsubstantial contributions to multidisciplinary cancer\ntreatment.\nWhile many of the AI-used cases in VIR primarily fall\nwithin the domains of computer vision and image\nclassiﬁcation/segmentation in AI, the impact of AI in VIR\npotentially extends beyond these conventional boundaries.\nLLMs are a promising domain in AI with opportunities for\nsubstantial applications in VIR. LLMs are advanced AI models,\nsuch as Open AI’s Chat Generative Pre-Trained Transformer\n(ChatGPT), which are capable of understanding and generat-\ning human-like text.\n8 LLMs have emerged as a revolutionary\nbreakthrough in AI, as it pertains to natural language proc-\nessing (NLP). Their ability to process and comprehend lan-\nguage has propelled them into diverse sectors, including\nﬁnance, marketing, and healthcare.\nIn general healthcare, the LLM technology is now widely\nacclaimed for its role in medical language tasks, including\nautomated report generation and integration with health-\ncare systems.\n9 It enables the comprehensive extraction of\npatient data from electronic health records, laboratory\nresults, and prior imaging studies, signiﬁcantly enhancing\nthe diagnostic process and patient care. The literature on the\npotential application of LLMs in VIR is, however, sparse\nrelative to the broader discussions of opportunities and\nconcerns provoked by AI generally but more importantly,\nthe readily accessible LLM technologies like ChatGPT.\nHence, the aim of this article is to comprehensively\nexplore the potentials of LLMs in VIR. By reviewing the\ncurrent abilities of LLMs, the aim is to highlight the potentials\nof this technology, outlining its current and prospective\ncontributions to advancing clinical practices, patient out-\ncomes, and educational activities in VIR. The challenges,\npotential future directions, and advancements of LLMs in\nthe ﬁeld of VIR are also reviewed.\nOverview of LLMs\nLLMs are gaining signiﬁcant traction as invaluable tools in\nthe ﬁeld of radiology.10 These advanced AI models work by\ntransforming text into numerical tokens, thus capturing\ncontextual information during training. 11 Consequently,\nthey predict and select plausible next tokens based on\nlearned language patterns, creating the appearance of ency-\nclopedic knowledge and reasoning. ChatGPT is one of the\npopular LLMs, developed by OpenAI and made publicly\navailable in November 2022. It is trained on extensive text\ndatasets in various languages and can produce human-like\nresponses to text input. ChatGPT utilizes the GPT architec-\nture to process natural language and generate context-based\nresponses. Other publicly available LLMs include T5, Pythia,\nand LlaMA.\n12–14 For an overview of additional open access\nLLMs suitable for personal and research applications, the\nreader is referred to a detailed Github repository.15\nThe scientiﬁc community has shown diverse reactions\ntoward ChatGPT, reﬂecting the ongoing debate surrounding\nthe beneﬁts and risks of LLMs and generative AI technologies\nin general.16 On one hand, ChatGPT and other LLMs have\ndemonstrated usefulness in conversational and writing tasks\nin medicine, enhancing output efﬁciency and accuracy.9 On\nthe other hand, concerns have emerged regarding potential\nbias in its training datasets, leading to limitations and factual\ninaccuracies, a phenomenon referred to as“hallucination.”\nAdditionally, there are security concerns related to the\nspread of misinformation and the possibility of cyber-attacks\nutilizing LLMs.\n17\nThe Present and Promising Future of LLMs in\nVIR\nIn a notable experiment, ChatGPT 3.5 demonstrated impres-\nsive performance on 376 USMLE test questions from the\nJune 2022 sample exam, achieving a passing or near-passing\nscore threshold of 60%, while exhibiting high concordance\nand insightful responses, without specialized training.\n18 A\nmore recent study indicates that the latest version, ChatGPT\n4 performed even better and demonstrated remarkable\nmedical reasoning.\n19,20 Additionally, Yan et al21 introduced\nRadBERT, a language modelﬁne-tuned for radiology, excel-\nling in NLP tasks and promising automation in abnormal\nﬁndings identiﬁcation and report creation. These advances\ncould alleviate healthcare workload and burnout, suggesting\nThe Arab Journal of Interventional Radiology Vol. 8 No. 2/2024 © 2024. The Author(s).\nExploring the Potentials of Large Language Models in Vascular and Interventional Radiology Togunwa et al.64\n\nfuture developments in automated radiology reports and\nbroader healthcare applications. It is fascinating that this\ntechnology can achieve such outcomes in its early stages,\nand without domain-speciﬁc training, more so the LLMs can\nreason through novel problems to a remarkable degree with-\nout speciﬁc training, a phenomenon known as“zero shot.”\n22\nConsidering these factors, alongside the novel capabilities\nof LLMs, their potential applications are noteworthy. While\nthe literature on this emerging subject is still limited, key\nareas where LLMs demonstrate promising applications in\nVIR are highlighted (\n►Table 1).\nSupporting Clinical Decision-Making\nLLMs, equipped with sophisticated NLP methods, possess the\ncapability to analyze extensive volumes of medical literature,\nelectronic health records, and patient data. By processing and\nunderstanding the intricate patterns and nuances within this\ninformation, LLMs can assist the interventional radiologist in\nmaking more informed and precise decisions regarding\ndisease diagnosis, treatment planning, and prognostic\npredictions.\nShen et al\n23 have shown that ChatGPT can use large\nknowledge bases to swiftly answer questions about the\nmost suitable imaging study for speciﬁc clinical scenarios.\nA recent study assessed the performance of two LLMs,\nChatGPT and Glass AI, in predicting optimal neuroradiology\nimaging modalities compared with an experienced neurora-\ndiologist.\n24 Both LLMs scored similarly at 1.75 and 1.83,\nrespectively, out of a maximum possible 3 points, while\nthe neuroradiologist outperformed with a score of 2.20.\nChatGPT showed greater variability, suggesting room for\nimprovement with targeted medical text training, unlike\nGlass AI, which has more precise training on medical litera-\nture. Furthermore, ChatGPT showed promising prospects to\nenhance diagnostic accuracy, streamline work ﬂow, and\nimprove patient care by providing evidence-based recom-\nmendations and facilitating personalized treatment\nstrategies.\n16\nAdditionally, the ability of LLMs to continuously learn\nfrom new data ensures that their recommendations evolve\nwith the dynamic landscape of VIR. The regenerative attri-\nbute of LLMs makes it amenable to keep pace with the proliﬁc\nmedical devices industry stocking the cath laboratories.\nEvidence indicates improved performance on clinical tasks\nwhen LLMs are trained on domain-speciﬁc clinical data.\n9,18\nBased on this, there is some optimism that LLMs trained on\nTable 1 Summary of current and future uses of LLMs in VIR\nS/N Application Specifics References\n1. Supporting clinical-\ndecision-making\n Analyzing medical literature, electronic\nhealth records, and patient data\n23\n Assisting in disease diagnosis, treatment planning, and prognostic\npredictions\n24\n Providing evidence-based recommendations and facilitating personal-\nized treatment strategies\n16\n Continuous learning from new data for evolving recommendations in a\ndynamic VIR landscape\n9,18\n2. Improving clinical\nworkﬂow and\npatient scheduling\n Use in radiology report generation, reducing addendum requests and\nimproving reporting processes\n25,26\n Intelligent patient scheduling for risk identiﬁcation and preventive\nmeasures\n27\n Handling administrative duties like patient billings and extracting\nrelevant summaries from patient records\n27,28\n Alleviating healthcare provider workload and reducing risks to patients 29\n3. Enhancing VIR\neducation\n Assisting medical students and trainees in board-style examinations 30\n Synergizing with attending physicians for a comprehensive learning\nexperience\n31\n4. Patient education\nand patient-\ncentered care in VIR\n Simplifying medical reports for patient understanding\n32\n Providing patient education on VIR procedures with potential\nimprovements in accuracy\n33\n Generating patient-friendly explanations of complex medical\nconditions, treatment options, and risks\n35\nAbbreviations: LLMs, large language models; VIR, vascular and interventional radiology.\nThe Arab Journal of Interventional Radiology Vol. 8 No. 2/2024 © 2024. The Author(s).\nExploring the Potentials of Large Language Models in Vascular and Interventional Radiology Togunwa et al. 65\n\nVIR speciﬁc data will offer clinical decision support utility for\nthe interventional radiologist, particularly in suggesting\nrelevant procedures and appropriate treatment modalities\nincluding device choice and compatibility. However, it is\ncrucial to acknowledge that the expertise of a trained inter-\nventional radiologist remains indispensable for interpreting\nand verifying the outputs from LLMs.\nImproving Clinical Workﬂow and Patient Scheduling\nAI has the potential to improve the interventional radiolog-\nist’s daily practice in various ways. For instance, structured\nreporting has been shown to lead to a reduction in adden-\ndum requests for insufﬁcient documentation, indicating a\nmore comprehensive and clear reporting process.25 Recog-\nnizing this unique need, recent studies have explored the use\nof LLMs in radiology report generation (R2Gen). R2GenGPT is\nan emerging innovative framework for R2Gen, which lever-\nages LLMs for automated radiology reporting.\n26 It demon-\nstrates state-of-the-art performance and reduced\ncomputational complexity. Incorporation of LLMs similar\nto R2GenGPT as adjuncts for generating structured VIR\nreport holds promise for further improving the clinical\npractice workﬂow.\nAnother signiﬁcant aspect is intelligent patient schedul-\ning, where AI can identify patients at high risk and take\nprecautions to avoid potentially preventable morbidities or\nmortalities, while also reducing the chances of missing\nnecessary care through smart scheduling and patient selec-\ntion.\n27 Though the core of these algorithms may be based on\ncomplex supervised learning models or advanced ML tech-\nniques other than LLMs, LLMs still possess the ability to be\nthe front-end conversational interface. This interface would\nbe able to take the output of the back-end AI models and\npresent it in an intelligible and interactive manner.\nFurthermore, LLMs can handle administrative duties such\nas patient billings, and extract relevant summaries from a\npatient’s records such as problem lists, clinical notes, labo-\nratory data, pathology reports, vital signs, prior treatments,\nand prior imaging reports.\n27,28 These summaries provide the\ninterventional radiologist with crucial contextual informa-\ntion for clinical uses. Patel and Lam\n29 demonstrated the\nutility of ChatGPT in creating discharge summaries, allowing\nthe clinicians to focus on more clinical commitments.\nEmploying LLMs for laborious tasks like these also potentially\nreduces risks to the patient.\nEnhancing VIR Education\nThe potential of LLMs in VIR education for medical students\nand trainees is promising. Recently, ChatGPT demonstrated\nimpressive performance on a radiology-board style exami-\nnation, correctly answering 69% of questions.\n30 It excelled in\nlower-order thinking questions but faced challenges with\nhigher-order thinking questions, particularly those related to\ndescribing imagingﬁndings, calculations, classiﬁcations, and\napplying concepts. Another study compared ChatGPT-4 and\nBard (developed by Google) in responding to questions from\nthe American College of Radiology’s Diagnostic Radiology In-\nTraining (DXIT) examination. ChatGPT-4 exhibited a higher\noverall accuracy of 87.11% compared with Bard’s7 0 . 4 4 % .\nDespite occasional failures in addressing questions accurate-\nly, the authors expressed cautious optimism,suggesting that\nLLMs like ChatGPT-4 could serve as valuable study tools for\ntrainees in the future.\nConsequently, the VIR-speciﬁc trained LLM can assume a\ncrucial role in the learning curve of the VIR trainee within a\nlearner-centered collaborative training framework. Within\nthis framework, the LLM acts as an immediate repository,\ndelivering a trove of updated literature, procedural guide-\nlines, and case studies to enrich the learning experience.\nProﬁcient in evaluating lower-order thinking questions, it\nalso becomes an invaluable tool in gauging the trainee’s\nfoundational knowledge. As the trainee confronts higher-\norder challenges, the attending physician and LLM synergize,\naddressing complexities and ﬁlling knowledge gaps. The\nLLM’s identiﬁed limitations in imaging, procedural descrip-\ntions, and calculations are mitigated by the attending physi-\ncian’s expertise, creating a dynamic feedback loop for\ncomprehensive learning. Such a personalized adaptive learn-\ning pathway aligns with the ﬁndings of Duong et al,\n31\ndemonstrating the potential bene ﬁts of AI in achieving\n“precision education” within the ﬁeld of radiology. The\nunique strengths and weaknesses of the trainee are har-\nnessed to achieve superior learning experience facilitated by\nthe personalized integration of LLMs thus heralding a new\ndawn in enhanced VIR education.\nPatient Education and Patient-Centered Care in VIR\nThe integration of LLMs into VIR education extends beyond the\ntraining of the workforce. It holds some promise in enhancing\npatient-centered care through patient education as well. An\nexploratory case study conducted by radiologists revealed\npromising results in utilizing ChatGPT to simplify medical\nreports while maintaining factual accuracy, completeness, and\npatient safety.\n32 Scheschenja et al33 also explored the viability\nof using LLMs, speciﬁcally ChatGPT-3 and ChatGPT-4, for\npatient education in VIR. The authors designed hypothetical\nquestions about common VIR procedures, comparing the\naccuracy of responses from the two models. While both\nmodels provided accurate information on general procedure\ndetails, preparation, risks, and postinterventional aftercare,\nChatGPT-4 demonstrated better overall accuracy than\nChatGPT-3 in answering questions related to Port Implanta-\ntion, PTA, and TACE procedures. Recognizing the complexities\nassociated with ensuring language clarity and response coher-\nence, they concluded still that the LLMs exhibit feasibility for\nsafe and relatively accurate patient education in VIR, with GPT-\n4 showing incremental improvements.\nOther authors have reported similar results after investi-\ngating ChatGPT ’s performance on VIR knowledge.\n34,35\nMcCarthy et al35 evaluated the LLM’se fﬁcacy in delivering\neducational content on VIR, comparing it to standard mate-\nrial from the Society of Interventional Radiology Patient Care\nWeb site. Despite occasional inaccuracies and a tendency to\nproduce lengthy and somewhat complex responses, ChatGPT\nwas generally deemed a reliable source for most VIR\nprocedures.\nThe Arab Journal of Interventional Radiology Vol. 8 No. 2/2024 © 2024. The Author(s).\nExploring the Potentials of Large Language Models in Vascular and Interventional Radiology Togunwa et al.66\n\nBy leveraging the capabilities of LLMs in this manner,\ninterventional radiologists can generate patient-friendly\nexplanations of complex medical conditions, treatment\noptions, and potential risks associated with VIR procedures.\nThis empowers patients with accessible information, foster-\ning a better understanding of their health conditions and\ntreatment plans. Moreover, the LLM’s ability to produce\nhuman-like text can enhance communication between\nhealthcare professionals and patients, fostering a more em-\npathetic and transparent doctor–patient relationship. Hope-\nfully, further improvements will minimize instances of\nincorrect information and lead to safer patient education.\nChallenges, Ethics, and Recommendations in\nLLM Implementation for VIR\nAlthough the incorporation of LLMs into VIR holds great\npromise, it is also fraught with numerous challenges and\nethical considerations.36 These include reduced human in-\nvolvement, potential harm resulting from LLM reasoning\nweaknesses, limited availability of comprehensive datasets,\nthe risk of biases leading to healthcare disparities, and cost\nconstraints in low-resource settings. An overdependence on\nAI has the potential to diminish human involvement in\ndecision-making processes.\n37 To counteract this trend, it is\nessential for LLMs to augment human expertise rather than\nreplace it, emphasizing the continued centrality of interven-\ntional radiologists.\nThe assessment of the generative capabilities of LLMs,\nparticularly in the context of VIR, heavily relies on the\navailability of comprehensive datasets. The scarcity of medi-\ncal data from VIR operating suites poses a signiﬁcant obstacle\nto effective data collection.\n38 Also, LLMs encounter chal-\nlenges such as hallucinations and weak numerical reason-\ning.36,39 When applied in patient care without due caution,\nthese issues can lead to severe harm or even fatal conse-\nquences, underscoring the urgency of developing improved\nmitigation techniques.\nTo address these concerns, recent research has intro-\nduced effective strategies. These include the integration of\nexternal tools such as code interpreters, retrieval augmen-\ntation, knowledge graphs, and other mathematical\ntools.\n40–42 These measures aim to enhance the reliability\nand safety of LLM applications in VIR, ensuring that they\ncontribute positively to healthcare without compromising\npatient well-being.\nAlso, an issue of utmost concern revolves around bias and\nfairness, and addressing these are pivotal concerns in VIR.\nLLMs acquire knowledge from the data they are trained on. If\nthis data contains inherent imbalances and biases against\ncertain races or group of peoples, there is a risk of replicating\nthese biases in its AI predictions.\n32,43 This, in turn, could\nresult in unfair outcomes, potentially worsening existing\nhealthcare disparities. So, there must be emphasis on fair-\nness-aware ML and transparent development,44 where data\nare well balanced and representative of all groups, and any\npatient data are well protected to ensure privacy and\nsecurity.\nMoreover, the widespread adoption of LLMs faces chal-\nlenges due to cost and resource constraints, particularly in\nlow-resource settings.\n45 Addressing this, efﬁcient transfer\nmodels and leveraging cloud resources can enhance the\naccessibility of LLMs.46 Fostering public–private collabora-\ntion can also help distribute costs and resources, facilitating\nbroader adoption.\nGiven these challenges, additional research is needed to\nassess the performance of LLMs in clinical VIR. These inves-\ntigations should be organized around the various phases of\nclinical interactions: preoperative, perioperative, and post-\noperative care. Evaluation criteria should include conven-\ntional AI metrics like speciﬁcity, sensitivity, and F1-score.\nMoreover, it is crucial to also employ metrics tailored to\nLLMs, such as BLEU, ROUGE, BERT Score, and LLM-EVAL.\n47–49\nUltimately, rigorous validation, ongoing monitoring, and\ncollaboration with medical experts and VIR specialists are\ncrucial on all these bases. Creating a regulatory framework\nthat spans the multiple disciplines is crucial for the secure\nintegration of LLM into VIR practice. This ensures transpar-\nency and accountability without impeding advancements.\nAddressing these challenges and ethical concerns can maxi-\nmize LLMs’potential to improve healthcare outcomes.\nConclusion\nThe incorporation of LLMs into the domain of VIR signiﬁes a\npromising frontier poised to enhance the discipline. Al-\nthough the current landscape indicates that the widespread\nimplementation of LLMs in VIR may be premature, their\npotential holds the promise of improving various aspects of\nthe practice. These advanced AI tools have the capacity to\nimprove clinical decision-making, streamline workﬂow, en-\nhance medical education, and facilitate patient-centered\ncare.\nMoreover, full integration of these technologies into the\nclinical workﬂow of VIR necessitates further exploration of\nmulti-modal AI. This involves leveraging the text and lan-\nguage capabilities of LLMs in conjunction with computer\nvision AI models, recognizing the inherently visual nature of\nVIR. Additional research in this direction is crucial to unlock\nthe full spectrum of beneﬁts and possibilities that LLMs can\nbring to theﬁeld.\nEffective use of LLMs in VIR also requires recognizing\nchallenges and ethical considerations, such as AI over-reli-\nance, potential misinformation, and the need for rigorous\nvalidation. Collaboration among radiologists, AI researchers,\nand regulators is essential for balancing LLMs’potential with\npatient safety. Unlocking LLMs’ full potential in VIR also\nrequires training and reﬁning for domain nuances, imple-\nmenting robust frameworks, and adhering to ethical stand-\nards. This fosters a new era of medical practice, blending\nhuman expertise with advanced AI for patient-centered care\nand innovation.\nAuthors’ Contribution\nT.O.T. conceptualized the study. R.O. is the guarantor of\nthe study. T.O.T., R.O., and A.A. were involved in\nThe Arab Journal of Interventional Radiology Vol. 8 No. 2/2024 © 2024. The Author(s).\nExploring the Potentials of Large Language Models in Vascular and Interventional Radiology Togunwa et al. 67\n\nmethodology. T.O.T., R.O. A.A., and C.U-O. helped in pro-\nviding resources, writing— original draft preparation and\nediting. All authors have read and agreed to the ﬁnal\nversion of the manuscript.\nConﬂict of Interest\nNone declared.\nReferences\n1 Bohr A, Memarzadeh K. Chapter 2 - The rise of artiﬁcial intelli-\ngence in healthcare applications. In:Bohr A, Memarzadeh K, eds.\nArtiﬁcial Intelligence in Healthcare: Academic Press; 2020:\n25–60\n2 Parampreet K, Aaron Alexander M, Naitik P, et al. Unlocking the\npotential of artiﬁcial intelligence (AI) for healthcare. In: Stanislaw\nPS, ed. Arti ﬁcial Intelligence in Medicine and Surgery - An\nExploration of Current Trends, Potential Opportunities, and\nEvolving Threats. Rijeka: IntechOpen; 2023:Ch. 3\n3 Frandon J, Beregi J-P. Special issue: present and future perspec-\ntives of vascular interventional radiology. J Pers Med 2023;13\n(07):1131\n4 Seah J, Boeken T, Sapoval M, Goh GS. Prime time for artiﬁcial\nintelligence in interventional radiology. Cardiovasc Intervent\nRadiol 2022;45(03):283–289\n5 Waller J, O’Connor A, Rafaat E, et al. Applications and challenges of\nartiﬁcial intelligence in diagnostic and interventional radiology.\nPol J Radiol 2022;87(01):e113–e117\n6 Weiss CR, Hafezi-Nejad N. Interventional radiology: past, present,\nand future. Radiology 2023;308(01):e230809\n7 Charalel RA, McGinty G, Brant-Zawadzki M, et al. Interventional\nradiology delivers high-value health care and is an imaging 3.0\nvanguard. J Am Coll Radiol 2015;12(05):501–506\n8 Brown T, Mann B, Ryder N, et al. Language models are few-shot\nlearners. Adv Neural Inf Process Syst 2020;33:1877–1901\n9 Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF,\nTing DSW. Large language models in medicine. Nat Med 2023;29\n(08):1930–1940\n10 Mallio CA, Sertorio AC, Bernetti C, Beomonte Zobel B. Large\nlanguage models for structured reporting in radiology: perfor-\nmance of GPT-4, ChatGPT-3.5, Perplexity and Bing. Radiol Med\n(Torino) 2023;128(07):808–812\n11 Browning J, LeCun Y. Language, common sense, and the Winograd\nschema challenge. Artif Intell 2023;325:104031\n12 Biderman S, Schoelkopf H, Anthony QG, et al , Eds. Pythia: A suite\nfor analyzing large language models across training and scaling.\nInternational Conference on Machine Learning. 2023: PMLR.\n13 Raffel C, Shazeer N, Roberts A, et al. Exploring the limits of transfer\nlearning with a uniﬁed text-to-text transformer. J Mach Learn Res\n2020;21(01):5485–5551\n14 T o u v r o nH ,L a v r i lT ,I z a c a r dG ,e ta l .L l a m a :o p e na n de fﬁcient\nfoundation language models. arXiv preprint arXiv:230213971. 2023\n15 Open LLMs [Internet]. 2023. Accessed February 17, 2024 at:\nhttps://github.com/eugeneyan/open-llms\n16 Sallam M. ChatGPT utility in healthcare education, research, and\npractice: systematic review on the promising perspectives and\nvalid concerns. Healthcare (Basel) 2023;11(06):887\n17 Eggmann F, Weiger R, Zitzmann NU, Blatz MB. Implications of\nlarge language models such as ChatGPT for dental medicine. J\nEsthet Restor Dent 2023;35(07):1098–1102(n/a)\n18 Kung TH, Cheatham M, Medenilla A, et al. Performance of ChatGPT\non USMLE: potential for AI-assisted medical education using large\nlanguage models. PLOS Digit Health 2023;2(02):e0000198\n19 Nori H, King N, McKinney SM, Carignan D, Horvitz E. Capabilities\nof gpt-4 on medical challenge problems. arXiv preprint\narXiv:230313375. 2023\n20 Truhn D, Weber CD, Braun BJ, et al. A pilot study on the efﬁcacy of\nGPT-4 in providing orthopedic treatment recommendations from\nMRI reports. Sci Rep 2023;13(01):20159\n21 Yan A, McAuley J, Lu X, et al. RadBERT: adapting transformer-\nbased language models to radiology. Radiol Artif Intell 2022;4\n(04):e210258\n22 Webb T, Holyoak KJ, Lu H. Emergent analogical reasoning in large\nlanguage models. Nat Hum Behav 2023;7(09):1526–1541\n23 Shen Y, Heacock L, Elias J, et al. ChatGPT and other large language\nmodels are double-edged swords. Radiology 2023;307(02):\ne230163\n24 Nazario-Johnson L, Zaki HA, Tung GA. Use of large language\nmodels to predict neuroimaging. J Am Coll Radiol 2023;20(10):\n1004–1009\n25 Nguyen Q, Sarwar A, Luo M, Berkowitz S, Ahmed M, Brook OR.\nStructured reporting of IR procedures: effect on report compli-\nance, accuracy, and satisfaction. J Vasc Interv Radiol 2018;29(03):\n345–352\n26 Wang Z, Liu L, Wang L, Zhou L. R2GenGPT: Radiology Report\nGeneration with frozen LLMs. Meta-Radiology. 2023;1(3):100033\n27 Gurgitano M, Angileri SA, Rodà GM, et al. Interventional Radiolo-\ngy ex-machina: impact of artiﬁcial intelligence on practice. Radiol\nMed (Torino) 2021;126(07):998–1006\n28 Zheng Y, Wang L, Feng B, Zhao A, Wu Y. Innovating healthcare: the\nRole of ChatGPT in streamlining hospital workﬂow in the future.\nAnn Biomed Eng 2023\n29 Patel SB, Lam K. ChatGPT: the future of discharge summaries?\nLancet Digit Health 2023;5(03):e107–e108\n30 Bhayana R, Krishna S, Bleakney RR. Performance of ChatGPT on a\nradiology board-style examination: insights into current\nstrengths and limitations. Radiology 2023;307(05):e230582\n31 Duong MT, Rauschecker AM, Rudie JD, et al. Artiﬁcial intelligence\nfor precision education in radiology. Br J Radiol 2019;92(1103):\n20190389\n32 Jeblick K, Schachtner B, Dexl J, et al. ChatGPT makes medicine easy\nto swallow: an exploratory case study on simpliﬁed radiology\nreports. arXiv preprint arXiv:221214882. 2022\n33 Scheschenja M, Viniol S, Bastian MB, Wessendorf J, König AM,\nMahnken AH. Feasibility of GPT-3 and GPT-4 for in-depth patient\neducation prior to interventional radiological procedures: a\ncomparative analysis. Cardiovasc Intervent Radiol 2024;47(02):\n245–250\n34 Barat M, Soyer P, Dohan A. Appropriateness of recommendations\nprovided by ChatGPT to interventional radiologists. Can Assoc\nRadiol J 2023;74(04):758–763\n35 McCarthy CJ, Berkowitz S, Ramalingam V, Ahmed M. Evaluation of\nan artiﬁcial intelligence chatbot for delivery of IR patient educa-\ntion material: a comparison with societal website content. J Vasc\nInterv Radiol 2023;34(10):1760–1768.e32\n36 Javan R, Kim T, Mostaghni N, Sarin S. ChatGPT’s potential role in\ninterventional radiology. Cardiovasc Intervent Radiol 2023;46\n(06):821–822\n37 Huang S-C, Chaudhari AS, Langlotz CP, Shah N, Yeung S, Lungren\nMP. Developing medical imaging AI for emerging infectious\ndiseases. Nat Commun 2022;13(01):7060\n38 Demir KC, May M, Schmid A, et al , Eds. PoCaP Corpus: A\nMultimodal Dataset for Smart Operating Room Speech Assistant\nUsing Interventional Radiology Work ﬂow Analysis. Cham:\nSpringer International Publishing; 2022\n39 De Angelis L, Baglivo F, Arzilli G, et al. ChatGPT and the rise of large\nlanguage models: the new AI-driven infodemic threat in public\nhealth. Front Public Health 2023;11:1166120\n40 Gao L, Madaan A, Zhou S, et al. PAL: Program-aided language\nmodels. In:Andreas K, Emma B, Kyunghyun C, Barbara E, Sivan S,\nJonathan S, eds. Proceedings of the 40th International Conference\non Machine Learning; Proceedings of Machine Learning Research.\n: PMLR; 2023:10764–99\nThe Arab Journal of Interventional Radiology Vol. 8 No. 2/2024 © 2024. The Author(s).\nExploring the Potentials of Large Language Models in Vascular and Interventional Radiology Togunwa et al.68\n\n41 Yao S, Zhao J, Yu D, et al. React: Synergizing reasoning and acting\nin language models. arXiv preprint arXiv:221003629. 2022\n42 Agrawal G, Kumarage T, Alghami Z, Liu H. Can knowledge graphs\nreduce hallucinations in LLMs?: a survey arXiv preprint\narXiv:231107914. 2023\n43 Yang J, Li HB, Wei D. The impact of ChatGPT and LLMs on medical\nimaging stakeholders: perspectives and use cases. Meta-Radiolo-\ngy. 2023;1(01):100007\n44 Xu J, Xiao Y, Wang WH, et al. Algorithmic fairness in computa-\ntional medicine. EBioMedicine 2022;84:104250\n45 Köpf A, Kilcher Y, von Rütte D, et al. OpenAssistant Conversations–\nDemocratizing Large Language Model Alignment. arXiv preprint\narXiv:230407327. 2023\n46 Niu S, Liu Y, Wang J, Song H. A decade survey of transfer learning\n(2010–2020). IEEE Trans Artif Intell 2020;1(02):151–166\n47 Chan Y-H, Fan Y-C, Eds. A recurrent BERT-based model for\nquestion generation. Proceedings of the 2nd workshop on ma-\nchine reading for question answering. Hong Kong, China: Associ-\nation for Computational Linguistics;2019\n48 Lin Y-T, Chen Y-N. LLM-Eval: uniﬁed multi-dimensional automat-\nic evaluation for open-domain conversations with large language\nmodels. arXiv preprint arXiv:230513711. 2023\n49 Bandi A, Adapa PVSR, Kuchi YEVPK. The power of generative AI: a\nreview of requirements, models, input&ndash;output formats,\nevaluation metrics, and challenges. Future Internet 2023;15(08):\n260\nThe Arab Journal of Interventional Radiology Vol. 8 No. 2/2024 © 2024. The Author(s).\nExploring the Potentials of Large Language Models in Vascular and Interventional Radiology Togunwa et al. 69\n"
}