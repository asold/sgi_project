{
    "title": "Demystifying Neural Language Models' Insensitivity to Word-Order",
    "url": "https://openalex.org/W3185070134",
    "year": 2021,
    "authors": [
        {
            "id": "https://openalex.org/A5071576077",
            "name": "Louis Clouâtre",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5050015287",
            "name": "Prasanna Parthasarathi",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5075664559",
            "name": "Amal Zouaq",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5027720969",
            "name": "Sarath Chandar",
            "affiliations": [
                null
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2936695845",
        "https://openalex.org/W3117312003",
        "https://openalex.org/W3166416728",
        "https://openalex.org/W2964303116",
        "https://openalex.org/W2906152891",
        "https://openalex.org/W2882319491",
        "https://openalex.org/W3135427360",
        "https://openalex.org/W3004346089",
        "https://openalex.org/W2962911926",
        "https://openalex.org/W2963748441",
        "https://openalex.org/W2131774270",
        "https://openalex.org/W2396767181",
        "https://openalex.org/W2946359678",
        "https://openalex.org/W2946296745",
        "https://openalex.org/W2068018507",
        "https://openalex.org/W3175212568",
        "https://openalex.org/W2039133703",
        "https://openalex.org/W2156279557",
        "https://openalex.org/W2963751529",
        "https://openalex.org/W2493916176",
        "https://openalex.org/W2131744502",
        "https://openalex.org/W3098613713",
        "https://openalex.org/W2953369973",
        "https://openalex.org/W3030163527",
        "https://openalex.org/W2982399380",
        "https://openalex.org/W2963323070",
        "https://openalex.org/W2130158090",
        "https://openalex.org/W2962739339",
        "https://openalex.org/W3118608099",
        "https://openalex.org/W2970971581",
        "https://openalex.org/W2525127255",
        "https://openalex.org/W2962818281",
        "https://openalex.org/W2806120502",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W2101105183",
        "https://openalex.org/W2947469743",
        "https://openalex.org/W3164045210",
        "https://openalex.org/W2963310665",
        "https://openalex.org/W3035252911",
        "https://openalex.org/W2251939518",
        "https://openalex.org/W3152698349",
        "https://openalex.org/W2952592807",
        "https://openalex.org/W2914924671",
        "https://openalex.org/W2117130368",
        "https://openalex.org/W2965373594",
        "https://openalex.org/W2963846996",
        "https://openalex.org/W2154652894",
        "https://openalex.org/W3152540792",
        "https://openalex.org/W3036487253",
        "https://openalex.org/W2971152344",
        "https://openalex.org/W1599016936",
        "https://openalex.org/W806995027",
        "https://openalex.org/W2963403868",
        "https://openalex.org/W1647671624",
        "https://openalex.org/W2950734153",
        "https://openalex.org/W3049366647",
        "https://openalex.org/W2948947170",
        "https://openalex.org/W2950910987",
        "https://openalex.org/W131533222",
        "https://openalex.org/W2990704537",
        "https://openalex.org/W2910243263",
        "https://openalex.org/W2983577274",
        "https://openalex.org/W3118485687",
        "https://openalex.org/W3175606037",
        "https://openalex.org/W2767771229",
        "https://openalex.org/W3174418826",
        "https://openalex.org/W2973154008"
    ],
    "abstract": "Recent research analyzing the sensitivity of natural language understanding models to word-order perturbations have shown that the state-of-the-art models in several language tasks may have a unique way to understand the text that could seldom be explained with conventional syntax and semantics. In this paper, we investigate the insensitivity of natural language models to word-order by quantifying perturbations and analysing their effect on neural models' performance on language understanding tasks in GLUE benchmark. Towards that end, we propose two metrics - the Direct Neighbour Displacement (DND) and the Index Displacement Count (IDC) - that score the local and global ordering of tokens in the perturbed texts and observe that perturbation functions found in prior literature affect only the global ordering while the local ordering remains relatively unperturbed. We propose perturbations at the granularity of sub-words and characters to study the correlation between DND, IDC and the performance of neural language models on natural language tasks. We find that neural language models - pretrained and non-pretrained Transformers, LSTMs, and Convolutional architectures - require local ordering more so than the global ordering of tokens. The proposed metrics and the suite of perturbations allow a systematic way to study the (in)sensitivity of neural language understanding models to varying degree of perturbations.",
    "full_text": "Demystifying Neural Language Models’ Insensitivity to Word-Order\nLouis Clouˆatre1,3 Prasanna Parthasarathi2,3 Amal Zouaq1 and Sarath Chandar 1,3,4\n1 Polytechnique Montr´eal\n2 School of Computer Science, McGill University\n3 Quebec Artiﬁcial Intelligence Institute (Mila)\n4 Canada CIFAR AI Chair\nAbstract\nRecent research analyzing the sensitivity of\nnatural language understanding models to\nword-order perturbations have shown that the\nstate-of-the-art models in several language\ntasks may have a unique way to understand\nthe text that could seldom be explained with\nconventional syntax and semantics. In this pa-\nper, we investigate the insensitivity of natural\nlanguage models to word-order by quantify-\ning perturbations and analysing their effect on\nneural models’ performance on language un-\nderstanding tasks in GLUE benchmark. To-\nwards that end, we propose two metrics — the\nDirect Neighbour Displacement (DND) and\nthe Index Displacement Count (IDC) — that\nscore the local and global ordering of tokens\nin the perturbed texts and observe that pertur-\nbation functions found in prior literature af-\nfect only the global ordering while the local\nordering remains relatively unperturbed. We\npropose perturbations at the granularity of sub-\nwords and characters to study the correlation\nbetween DND, IDC and the performance of\nneural language models on natural language\ntasks. We ﬁnd that neural language models —\npretrained and non-pretrained Transformers,\nLSTMs, and Convolutional architectures — re-\nquire local ordering more so than the global\nordering of tokens. The proposed metrics and\nthe suite of perturbations allow a systematic\nway to study the (in)sensitivity of neural lan-\nguage understanding models to varying degree\nof perturbations.\n1 Introduction\nLarge pretrained (PT) models have become an in-\nevitability in modern Natural Language Processing\n(NLP) applications (Vaswani et al., 2017; Devlin\net al., 2018; Radford et al., 2019; Liu et al., 2019c;\nLewis et al., 2020; Brown et al., 2020; Peters\net al., 2018; Howard and Ruder, 2018). Pretraining\ntechniques such as Masked Language Modeling\n(MLM) and Causal Language Modeling (CLM)\nhave aided in making the best use of language statis-\ntics learned from large corpora to achieve improved\nperformance on several NLP benchmarks (Socher\net al., 2013; Bar Haim et al., 2006; Dagan et al.,\n2006; Dolan and Brockett, 2005; Agirre et al.,\n2007; Wang et al., 2019b,a; Warstadt et al., 2018;\nWilliams et al., 2018; Rajpurkar et al., 2016b; Gi-\nampiccolo et al., 2007; Bentivogli et al., 2009;\nLevesque et al., 2011; Rajpurkar et al., 2016a,\n2018). With the increase in applications of these\nlarge models also came a growing interest in evalu-\nating the way these models learn to solve natural\nlanguage tasks.\nResearch has shown that large models do have\nan understanding of well-formed English syntax\nin recurrent neural networks, convolutional neural\nnetworks, and in large PT Transformers (Gulordava\net al., 2018; Zhang and Bowman, 2018; Chrupała\nand Alishahi, 2019; Lin et al., 2019a; Belinkov and\nGlass, 2019; Liu et al., 2019a; Jawahar et al., 2019;\nRogers et al., 2020). More recent studies, however,\ntake a critical stance with experiments suggesting\nthat models may be insensitive to word-order per-\nturbations. Pham et al. (2020); Sinha et al. (2021,\n2020); Gupta et al. (2021); O’Connor and Andreas\n(2021) show that shufﬂed word-order have little to\nno impact during training or inference with neu-\nral language models. While, some research show\nthat models learn some abstract notion of syntax,\nfurther probing into their insensitivity to the pertur-\nbation of syntax is necessary. Speciﬁcally, What\nare the underlying mechanisms causing those un-\nintuitive, or unnatural (Sinha et al., 2020), results\nfrom neural models is still a largely unanswered\nquestion.\nRecent research exploring the sensitivity to syn-\ntax of pretrained models have mostly been applying\nperturbations to text through perturbing the order of\nwords. Perturbations applied and quantiﬁed at this\ngranularity of text offer only a limited understand-\ning to the learning dynamics of the large architec-\narXiv:2107.13955v1  [cs.CL]  29 Jul 2021\nThe scholar is typesetting.\nscholar typesetting is The.\nschotyp eset Thelar tingis.\nchlorse Thn ytpsitetnig es.\nFigure 1: Perturbations applied at different granulari-\nties of text are shown: (from top to bottom) original\ntext, word-level perturbed text, subword-levelperturbed\ntext, and character-level perturbed text.\ntures. Analysing perturbations at a ﬁner granularity\nsuch as subwords (Bojanowski et al., 2017) or char-\nacters (Gao et al., 2018; Ebrahimi et al., 2017),\nmay provide a deeper insight into the insensitivity\nof neural models. Consider Figure 1, which shows\nan unperturbed sentence, a word-level perturbed\nsentence, a subword-level perturbed sentence, and\na character-level perturbed sentence. An average\nreader may ﬁnd it possible to parse and infer the\nmeaning up to the word-level perturbed sentence,\nbut would have issues inferring any meaning from\nsubword and character-level perturbed text.\nIn this paper, we deﬁne two types of structure1\nin text, global which relates to the absolute posi-\ntion of characters, and local, which relates to the\nrelative position of characters to their immediate\nneighbors. We observe from experiments in the\npaper that most perturbations proposed and ana-\nlyzed in the literature often perturb the global struc-\ntures well with different reordering of words, while\nthe amount of disturbance to the local structure\nremains limited, thus preserving most of the local\nstructure. We hypothesize that the local structure\nenables understanding in natural language tasks\nand effectively perturbing this structure aids in ana-\nlyzing the sensitivity of neural models in language\ntasks. We, hence, propose two new metrics, the\nIndex Displacement Count metric (IDC) and the\nDirect Neighbour Displacement metric (DND)2, to\nmeasure the amount of perturbation to the global\nand local structures of text respectively.\nOur contributions are as follows:\n• We propose two metrics, IDC (global) and\nDND (local), to measure the perturbations on\n1Structure here relates to the organization of characters in\nthe text.\n2There is a wordplay in the naming of the metrics. IDC:\nstanding for I Don’t Care and DND: Do Not Disturb in internet\nslang is used to identify the metric the neural models cares the\nmost about in language tasks and the one it does not.\nglobal and local structures of text.\n• We show that the performance of neural mod-\nels – Transformers and others – to perturbed\ninput has a strong correlation with the pro-\nposed DND metric.\n• We observe that DND has a strong correla-\ntion with GLUE scores across different ar-\nchitectures, suggesting that neural language\nunderstanding models generally are sensitive\nto distortions in local structures moreso than\nglobal structures.\n• We show that commonly used lexical perturba-\ntions distort the global structures and seldom\naffect the local structures explaining the insen-\nsitivity of large models to such perturbations.\n• We show that DND has a weak correlation to\nother metrics – BLEU, Levenshtein – indicat-\ning that the common metrics used for evalua-\ntion do not measure the dimension captured\nby DND.\n• We ﬁnd that the lack of correlation to per-\nformance of non-pretrained Transformers to\nIDC is useful in detecting when models do not\nmake use of the positional information present\nin text, defaulting to bag-of-word models.\n2 Related Work\nImportance of syntax Discussions on seman-\ntics (Culbertson and Adger, 2014; Futrell et al.,\n2020) agree on speciﬁc orders of words to be nec-\nessary for comprehending the text. Psycholin-\nguistic research (Hale, 2017) corroborates this\nthrough evaluating sentence comprehension mech-\nanisms of humans. Hence, interpreting language\nas a bag-of-words could limit the expressions con-\nveyed through the word-orders (Harris, 1954; Le\nand Mikolov, 2014) and understanding syntax3 be-\ncomes an essential artifact.\nPrior works have explored the relationship\nbetween neural models and syntax. Goldberg\n(2019); Hewitt and Manning (2019) both show that\nBERT (Devlin et al., 2018) models have some syn-\ntactic capacity. Lin et al. (2019b) show that BERT\nrepresents information hierarchically and conclude\nthat BERT models linguistically relevant aspects in\n3Preference to a speciﬁc word-order over the other and the\npreference complying with the choices of an average human\nspeaking that language.\na hierarchical structure. Tenney et al. (2019); Liu\net al. (2019b) show that the contextual embeddings\nthat BERT outputs contain syntactic information\nthat could be used in downstream tasks.\nWhile it seems that syntax is both important, and\nto an extent, understood by the recent family of PT\nmodels, it is unclear how much use they make of it.\nGlavaˇs and Vuli´c (2020) showed that pretraining\nBERT on syntax does not seem to improve down-\nstream performance much. Warstadt et al. (2020)\nshowed that while models such as BERT do un-\nderstand syntax, they often prefer not to use that\ninformation to solve tasks. Ettinger (2020); Pham\net al. (2019); Sinha et al. (2020); Gupta et al. (2021)\nshow that large language models are insensitive to\nminor perturbations highlighting the lack of syn-\ntactic knowledge used in syntax rich NLP tasks.\nSinha et al. (2021) show that pretraining models\non perturbed inputs still obtain reasonable results\non downstream tasks, showing that models that\nhave never been trained on well-formed syntax can\nobtain results that are close to their peers.\nWhile syntactic information seems vital to lan-\nguage, and large PT models seem to be at least\naware of syntax, the lack of sensitivity of neural\nmodels to perturbation of syntax motivates further\nprobing.\nText Similarity Metrics Several popular simi-\nlarity metrics can be used to measure perturba-\ntions. Metrics like BLEU (Papineni et al., 2002)\nand ROUGE (Lin, 2004) will treat text as a se-\nquence of words, from which a measure of overlap\nis computed. The Levenshtein distance (Leven-\nshtein, 1966; Yujian and Bo, 2007), or the edit\ndistance, measures the minimum amount of sin-\ngle character edits (insertions, deletions or substi-\ntutions) necessary to match two strings together.\nParthasarathi et al. (2021) observed that learned\nmetrics like BERT-Score (Zhang et al., 2019) and\nBLEURT (Sellam et al., 2020) are often unaffected\nby minor perturbations in text which limits their\nusefulness in measuring perturbations. Sinha et al.\n(2020) propose a POS mini-tree overlap score to\ninterpret the results of the perturbation analysis.\nThe score computes the part-of-speech (PoS) tags\nneighborhood for every word and estimates an aver-\nage overlap in the neighborhood for all the tokens\nbefore and after applying the perturbation. The au-\nthors, however, ﬁnd that the working range of the\nproposed metric to be small and explain the effect\nonly for PT Transformer architectures.\nText Perturbations Several different types of\nreordering perturbation functions and schemes\nhave been explored to understand and study the\n(in)sensitivity of neural architectures to word-order.\nThe class of perturbation analysis could broadly be\nsplit into three categories that involves – deletion,\nparaphrase injection and/or reordering of tokens.\nSankar et al. (2019) explore utterance and word-\nlevel perturbations applied to generative dialogue\nmodels to highlight their insensitivity to the order\nof conversational history. On natural language clas-\nsiﬁcation tasks, Pham et al. (2020) deﬁne n-grams\nfor different values of n and shufﬂe them to high-\nlight the insensitivity of pretrained models. They\nshow that shufﬂing larger n-grams have a lesser\neffect than shufﬂing smaller n-grams, hinting that\npreserving more local structure causes less degrada-\ntion in performances. Studying textual entailment\ntasks, Sinha et al. (2020) perform perturbations on\nthe position of the words, with a criteria that no\nword remains in its initial position.\nHsieh et al. (2019) propose a suite of adversar-\nial attacks that replace one word in the input to\ncause a model to ﬂip its correct prediction. Gupta\net al. (2021) combine several types of destructive\ntransformations — such as sorting, reversing, shuf-\nﬂing words — towards removing all informative\nsignal in a text. Along similar lines, Wang et al.\n(2019c) inject noise by reordering articles or delet-\ning minimally towards injecting artiﬁcial noise\nto measure the robustness of pretrained language\nmodels. Character-level perturbations that perform\nminimal ﬂips to cause a degenerate response have\nbeen explored by Ebrahimi et al. (2017); Gao et al.\n(2018). Gao et al. (2018) quantify the perturbation\nin Levenshtein distance and draw a correlation to\nthe model’s performance. This work is closely re-\nlated to our own. We, however, demonstrate that\nour proposed metric is a much more robust expla-\nnation of the degradation in performance of models\nthan the Levenshtein distance.\nAlthough the recent literature on perturbation\nanalysis in PT language models was able to observe\nthe extremes — sensitivity and insensitivity, under-\nstanding the attributes of text to which PT models\nand others are sensitive to requires a detailed study.\nWe speculate that the perturbation analyses done\nat the granularity of sub-words and characters is\nnecessary for properly probing the neural models’\ninsensitivity to word-order phenomenon. Likewise,\na generic score quantifying the amount of perturba-\ntion is essential towards setting up a uniﬁed evalua-\ntion framework for perturbation functions.\n3 DND and IDC\nWe deﬁne two metrics — the Direct Neighbour\nDisplacement (DND) and the Index Displacement\nCount (IDC) — that score the local and global\nstructures that are perturbed with any reordering\nbased perturbation functions. The global structure\nhere relates to the absolute position of characters in\na text, and the local structure relates to the neigh-\nbouring character of any other character in a text.\nThe metrics are all measured on the perturbations\nof characters in text, allowing for a uniﬁed frame-\nwork to compare perturbation functions that are\napplied at various levels of text granularity4; words,\nsubwords, and characters.\n3.1 IDC\nLet a string, xi = (c)i\nk, be denoted by a sequence\nof characters c0, . . . ,ck, where k is the length of the\nstring in characters and pxi denote the positions of\ncharacters in xi. Let η(·) be a perturbation opera-\ntion.\nx′\ni ←η (xi), (1)\nwhere x′\ni denote the perturbed string with posi-\ntions of the characters speciﬁed by px′\ni .\nIDC ← 1\nk2\nk\n∑\nj=1\npx′\ni ( j)−pxi ( j)\n\n1\n(2)\nThe denominator k2 normalizes the average by\nthe length of the text5. Intuitively, an IDC of 0.3\nwould imply that characters in the perturbed text\nhave moved 30% of the text length on average. The\nvalues of IDC will lie in the range [0,0.5], where\n0.5 would be obtained by reversing a text at the\ncharacter level.\n3.2 DND\nFor every cj, let N xi (cj,R) indicate the relative\nposition of the right neighbor ( R) of character cj\nwith respect to the position of cj in string xi. Then,\nDND is computed as a summation over an indicator\nvariable that indicates when the neighbor to the\nright of ci has shifted to a different position in x′\ni.\n4Pseudo-code and examples of both metrics are shown in\nAppendix B and Appendix C.\n5k2 is used to normalize as we sum k times a number that\nis between 0 and k, where k is the text length.\nDND ← 1\nk −1\nk−1\n∑\nj=1\n(\n1\n[\nN xi (cj,R) ̸= N x′\ni (cj,R)\n])\n(3)\nDND measures the amount of distortions that\nhappened to the local neighborhood of every char-\nacter. Intuitively, a DND of 0.3 would imply that\n30% of characters in the perturbed text are no\nlonger followed by their immediate neighbouring\ncharacter in the unperturbed text. The values of\nDND will lie in the range [0,1], where 1 can be\nobtained by removing every single neighborhood\nrelations.\n4 Perturbation Functions\nTowards conducting a detailed analysis on the ef-\nfect of perturbations on performance of neural lan-\nguage models, we deﬁne three granularities of per-\nturbation functions — word-level, subword-level\nand character-level. The subwords are taken from\nthe RoBERTa-Base vocabulary. We deﬁne the per-\nturbation functions as generic operations that can\nbe applied across the different levels of granularity.\nPseudo-code and examples for all perturbations are\nshown in Appendix B.\nFull-shufﬂing randomly shufﬂes the position of\nevery word, sub-word, or character, according to\nthe level it is applied to. This transformation should\ncause a great amount of perturbation to the global\nand local structure for the speciﬁc granularity.\nThe scholar is typesetting.\nscholar typesetting is The.\nFigure 2: Example for word-level full shufﬂing. The\nperturbed sentence has an IDC of 0.29 and a DND of\n0.19.\nPhrase shufﬂing creates chunks of contiguous\ntokens of variable length and shufﬂes the phrases\nof word, subword, or characters. This perturba-\ntion has, on average, the same impact as the full\nshufﬂing on the global structure as the absolute\npositions of characters tend to change just as much\nas full shufﬂing while having a lesser impact on the\nlocal structure.\nUnlike the full-shufﬂing operation, phrase shuf-\nﬂing uses a parameter ρ that controls the average\nsize of the randomly deﬁned contiguous chunks\nThe scholar is typesetting.\nis typeThe schosetting lar.\nFigure 3: Subword-level phrase shufﬂing. The per-\nturbed sentence has an IDC of 0.35 and a DND of 0.19.\nThis example can be compared with Figure 2 in that\nthe two have the same DND scores but different IDC\nscores.\nof tokens. To randomly deﬁne our phrases, we\ntraverse the text sequentially on the desired granu-\nlarity. The entire text is assumed as a single large\nphrase and is truncated at a token with probability\nρ into smaller phrases.\nThe lower the value of ρ is, the longer, on aver-\nage, the phrases are, thus preserving more of the\nlocal structure while destroying roughly the same\namount of global structure. In the extreme case\nwith ρ = 1.0, phrase shufﬂing will be equivalent to\nfull shufﬂing as phrases will all be one token long.\nNeighbour ﬂip perturbations ﬂip tokens of the\nchosen granularity with the immediate right neigh-\nbor with probability, ρ. This function has, on aver-\nage, a smaller impact on the global structure, as the\nabsolute positions of tokens do not change much\nbut can have an arbitrary large effect on disturbing\nthe local structure.\nThe scholar is typesetting.\nheT cshlori sa typeesttnig.\nFigure 4: Character-level neighbour ﬂip. The perturbed\nsentence has an IDC of 0.04 and a DND of 0.71. Due\nto a greater distortion to the local order, the model has\na greater chance to be sensitive to this perturbation.\nThe perturbation is applied by traversing the\nstring from left-to-right on the desired granular-\nity and, with a probability ρ, switching the current\nattended token with the following token. The lower\nthe ρ is, the less perturbation happens, thus preserv-\ning more of thelocal structure. This transformation\nnever has a large impact on the global metric, thus\nletting us isolate the impact of perturbations to the\ndifferent structures.\n5 Experiments\nDataset We experiment with the GLUE Bench-\nmark (Wang et al., 2019b) datasets, a popular Natu-\nral Language Understanding (NLU) benchmark.\nOf the GLUE’s suite, we evaluate on 8 tasks –\nMulti-Genre NLI (MNLI), Corpus of Linguistic Ac-\nceptability (CoLA), Quora Question Pairs (QQP),\nMicrosoft Research Paraphrase Corpus (MRPC),\nQuestion NLI (QNLI), Recognizing Textual Entail-\nment (RTE), Stanford Sentiment TreeBank (SST),\nSemantic Textual Similarity Benchmark (STS-B)–\n(Warstadt et al., 2018; Socher et al., 2013; Dolan\nand Brockett, 2005; Agirre et al., 2007; Williams\net al., 2018; Rajpurkar et al., 2016b; Dagan et al.,\n2006; Bar Haim et al., 2006). The model agnostic\ntasks in GLUE that have diverse textual contexts,\ndataset sizes, and varying degree of difﬁculty are\ndesigned to evaluate language understanding com-\nponents of neural language models.\nWe create perturbed versions of datasets for all\ntasks with the different perturbation functions de-\nﬁned in § 4. In total, 20 different variation of our\nperturbation functions are applied6. We maintain\nan unperturbed version of the dataset to benchmark\nthe model’s performance.\nModels We experiment on neural architectures\nwith different inductive biases — BiLSTMs (Schus-\nter and Paliwal, 1997), ConvNets, PT Transform-\ners (RoBERTa-Base and BART-Base), and a Non-\nPretrained (NPT) Transformer( RoBERTa-Base ar-\nchitecture). We also experiment with different to-\nkenization schemes, using byte-pair encoding as\nwell as character-level tokenization. All training,\nﬁnetuning and evaluation are done on the perturbed\nversion of the dataset 7. The tokenization for PT\nTransformer models use their corresponding vo-\ncabulary, while NPT models use RoBERTa-Base\nvocabulary and the character-level models use ex-\nclusively characters as vocabulary.\nThe primary objectives of the experiments are to:\n(1) understand if different degrees of perturbations\naffect the models alike, (2) verify if correlation ex-\nists between the performance across different NLU\ntasks and the amount of perturbation measured by\nDND and IDC, (3) investigate the different pertur-\nbation operations used in the literature and their\ndistribution on our proposed metrics, and (4) un-\nderstand if the pretraining of models is important\nto the studied phenomenon.\n6The hyperparameters used for the perturbation functions\nare detailed in Appendix A.\n7The training details can be found in Appendix A. Code to\nreproduce the results is available in GitHub.\n6 Analysis\n6.1 Correlation with other metrics\nTowards estimating the relationship the proposed\nmetrics — IDC and DND — have with the existing\nmetrics — BLEU and Levenshtein —, we compute\npairwise ρ-correlation among the metrics averaged\nacross all samples in the GLUE validation set in\nFigure 58. Speciﬁcally, for every sample in the\nvalidation set of the tasks, we perturb them using\nthe different perturbation functions and compute\ntheir scores with the different metrics.\nFigure 5: Correlation matrix between the different met-\nrics on the GLUE tasks shows that the proposed two\nmetrics have no correlation between them, suggesting\nthat the two indeed measure orthogonal components of\nthe perturbed texts. Further, DND has a moderate to\nweak correlation with BLEU and Levenshtein distance\nsuggesting that DND measures a different component\nthat is not measured by the other metrics.\nWe observe that IDC and DND are uncorrelated\nsuggesting that the metrics measure different as-\npects of the perturbations. Further, we observe that\nDND only has a weak correlation with BLEU and\nLevenshtein, indicating that DND measures a pre-\nviously unmeasured dimension of the structure and\nsimilarity in texts.\n6.2 Comparison of Perturbation Functions\nWe populate an assorted list of perturbation func-\ntions analyzed by Parthasarathi et al. (2021) that\ncan be applied to examples in GLUE tasks. The\n16 different word-level perturbations are catego-\nrized as PoS-Tag perturbations, Dependency Tree\nperturbations, and Random shufﬂes that include\n8For every correlation, we inverted the value of DND, IDC,\nand the Levenshtein distance by subtracting the value from\n1 to make the comparison of the different correlations more\nstraightforward. They are a measure of perturbation and not\nsimilarity and are therefore inversely correlated to the GLUE\nscore.\nperturbing with different traversal orders of depen-\ndency tree — Pre-Order, Post-Order or In-Order —,\nswapping verbs, adverbs, nouns in a text, reversing\nsentences among other perturbations.\nWe perturb the samples across GLUE tasks for\nevery perturbation function, compute the scores\nwith the metrics and compare with the perturba-\ntions deﬁned in § 4. The distribution of scores\nmeasured by BLEU and Levenshtein covers the\nentire range of values for most of the word-level\nfunctions (shown in Figure 14). While the distribu-\ntion of scores computed by DND for the different\nperturbations functions shown in Figure 6 indicates\nthat the word-level and subword-level perturbations\nhave a limited impact on the local structure.\nNo surprise but, we found BLEU to be unin-\nterpretable when the perturbations were done at\ncharacter or subword level rendering it ineffective\nfor our study. Although Levenshtein does better\nin that regard, we observe DND metric to strongly\ncorrelate with model performance on perturbed\nsamples (in §6.3). The analysis provides a reason-\nable explanation to the insensitivity observed due\nto word-level perturbations studied in the litera-\nture (Sinha et al., 2020; Pham et al., 2020; Gupta\net al., 2021).\n6.3 IDC/DND vs GLUE tasks\nWe compute the average GLUE score of different\nmodels on validation data perturbed with different\nfunctions to cover the range of DND score as shown\nin Figure 8. We observe the general trend to be that\nthe proposed DND metric has a strong correlation\nwith neural models’ loss in performance on the\nGLUE benchmark tasks (Figure 7). By computing\na correlation between the performance of the differ-\nent models on the perturbed samples and a measure\nof perturbation as estimated by the different met-\nrics ( Figure 13), we see that the correlation with\nDND holds for every single architecture and set-\nting tested. On the other hand, IDC is only weakly\ncorrelated with performance decay. This implies\nthat local structure, moreso than global structure,\nis necessary for models to understand text. The\nLevenshtein distance and the BLEU metric both\nhold some explanatory power, but do not show\na monotonically increasing or decreasing perfor-\nmance which limits the usefulness of those mea-\nsures. For example, A model being evaluated on a\nperturbed text with a DND of 0.5 can be assumed\nto have much lower performance than on a per-\n(a)\n (b)\nFigure 6: We analyse different perturbations discussed in the literature with the proposed metrics — IDC and DND.\nThe two plots show the distribution of the scores deﬁned by the metrics over ∈[0,1]. In (a), one can observe the\ndistribution of scores for different word-level perturbations that they mostly impact IDC and the distribution of\nDND remains roughly in the range ∈[0,0.2]. In (b), the proposed perturbation operations on character granularity\nimpact the full range of possible DND values. Note: W = Word-level, S = Subword-level, C = Character-level. FS\n= Full Shufﬂe, NF = Neighbour Flip, PS = Phrase Shufﬂe.\n(a) DND\n (b) IDC\n(c) BLEU-4\n (d) Levenshtein\nFigure 7: Plotted are the relation between the different choices of metrics measuring the amount of perturbation\nand the performance of PT RoBERTa-Base model ﬁnetuned and tested on the perturbed data. The plots highlight\nthat the proposed DND metric has a stronger correlation to the GLUE score of model to perturbed sample than the\nother metrics. Similar trends can be observed in all of our tested models shown later in the paper.\nFigure 8: Comparison of different neural architectures’\nperformances with different level of perturbation as\nmeasured by DND.\nturbed text with a DND of 0.2. This is not true for\nany of the other metrics. But the same do not hold\nfor a model being tested with a perturbed sample\nmeasuring 0.1 BLEU and another with a0.0 BLEU.\nSimilarly, Levenshtein score 0.5 could represent\nperturbations that lead to a very low performance,\nor to a barely affected performance.\nWithout computing an average GLUE score to\nestimate the correlation but looking at the tasks\nmore closely, as in Figures 9 to 11, we see that\na few tasks buck the overall trend. Especially,\nthe semantic acceptability task, CoLA, correlates\nvery strongly with the BLEU-4 metric and only\nweakly with DND. It is also the only task in GLUE\nbenchmark that reaches chance-level performance\nwith word-level perturbations (Pham et al., 2020).\nHence, word-level perturbations, as measured by\nBLEU, being more important for the task than the\nlocal structure, as measured by DND, is expected.\nThe STS-B task, a semantic textual similarity\ntask, is barely correlated with IDC but strongly\ncorrelated with DND. It does not seem possible to\naffect this task performance with word or subword-\nlevel perturbations, implying that the bag-of-words\ninformation is sufﬁcient to obtain good textual sim-\nilarity estimates. DND, being able to measure dis-\ntortions to the bag-of-words information, is able\nto provide an explanation for degradation in per-\nformance on a task that does not seem to rely on\nsyntactic information. Whereas IDC does not seem\nto provide an explanation for the decay of perfor-\nmance in this task.\n6.4 Model speciﬁc analysis\nThe loss in performance of models in GLUE tasks\nshows a greater degree of correlation with the DND\nmetric than any other metric, as shown in Figure 13.\nWe found our results to be consistent across PT\nTransformers, NPT Transformers, ConvNets, and\nBiLSTMs. This indicates that our results gener-\nalize to neural language models across different\ninductive biases, pretrained or not-pretrained, and\nto the different pretraining techniques.\n6.4.1 Pretrained vs Non-Pretrained\nUnsurprisingly, PT Transformers outperform ev-\nery NPT variant across all types of perturbations,\nas shown in Figure 8. The PT RoBERTa and\nBART model have a comparable level of degra-\ndation across the different perturbations, shown in\nFigure 9, despite the different pretraining schemes\nused.\nAll NPT models also exhibit a strong correla-\ntion between the DND metric and their degradation\nin performance on the GLUE tasks, which indi-\ncates that the insensitivity to word-order is not an\nartifact of pretraining. In contrast with PT mod-\nels, NPT models have very low correlations be-\ntween all metrics and performance on the RTE task.\nThis is explained by the fact that most NPT mod-\nels do not obtain signiﬁcantly above chance-level\nperformance on the RTE task. As the performance\nquickly degrades to chance-level once any pertur-\nbation is applied, it is hard to measure correlations\nbetween the metrics and the task performance.\n6.4.2 NPT Transformer and Positional\nEmbeddings\nInterestingly, the NPT Transformer, as shown in\nFigure 10, has a close to zero correlation between\nits performance and IDC metric, which other Non-\nTransformer models do not mirror. As the IDC\nmetric measures the changes in absolute position\nof tokens, the IDC metric being completely uncor-\nrelated with performance implies that the absolute\nposition of tokens has little to no impact on the\nperformance of NPT Transformers. We hypothe-\nsize that learning the positional embeddings require\nmuch more data than is present in a single NLU\ntask, leading the NPT model to essentially act as\nbag-of-words model.\nTowards studying this, we conduct an ablation\nstudy on the impact of positional embeddings with\nNPT and PT Transformers. To do this, we freeze\nthe weights of the positional embeddings to0, mak-\ning them have no contribution on the overall output\nof the model. As we are interested in the marginal\nutility of positional embeddings with relation to\n(a) PT RoBERTa\n (b) PT BART\nFigure 9: Correlation matrices between perturbations measured by different metrics and the performance on GLUE\nTasks of PT Transformers. This highlights that across different pretraining settings, DND remains very strongly\ncorrelated with downstream performance.\n(a) ConvNet\n (b) BiLSTM\n(c) NPT Transformer\nFigure 10: Correlation matrices between perturbations measured by different metrics and the performance on\nGLUE Tasks of different NPT architectures. This highlights that across different architecture settings, the DND\ncorrelation remains very strongly correlated with downstream performance.\n(a) ConvNet Char\n (b) BiLSTM Char\nFigure 11: Correlation matrices between perturbations measured by different metrics and the performance on\nGLUE Tasks of ConvNets and BiLSTMs using only characters as tokens. The results showcase the correlation of\nthe proposed metrics on character-models, thereby removing tokenization as a confounder.\n(a) DND NPT\n (b) IDC NPT\n(c) DND PT\n (d) IDC PT\nFigure 12: Difference in GLUE scores between a Transformer and the same Transformer without positional em-\nbeddings. The presence of positional embeddings seem to add roughly between 0% and 1% in GLUE score no\nmatter the type of perturbations applied to the NPT model. The amount of local perturbations correlates very well\nwith the gain in performance that a PT model will have with positional embeddings.\nNPT Transformers, we report the difference in per-\nformance between the model that does not have\naccess to those embeddings and the model that\ndoes (∆ GLUE Score). Without positional embed-\ndings, a model has no information on the relative\nposition of inputs and is forced to use only a bag-\nof-words level of information from the input text.\nIn Figure 12, we can see a drop in performance of\nat most 1%, consistent across all levels of pertur-\nbations, for the NPT Transformer. This suggests\nthat NPT Transformers barely make any use of the\npositional embeddings on those tasks.\nThe positional embeddings of PT models, how-\never, seem strongly impacted by perturbations, sug-\ngesting that they make heavy use of the positional\nembeddings. We see that the impact of those em-\nbeddings degrades monotonically with perturbation\non the local structure and is somewhat correlated\nwith perturbation on the global structure, which is\nnot observed with the NPT Transformer.\n6.5 Character-Level Experimentation\nFigure 13: Plot shows the correlation between the mod-\nels’ performance to perturbed samples on the different\nGLUE tasks and the perturbation quantiﬁed by the dif-\nferent metrics. The higher the value the better the ex-\nplainability of the metric; suggests that DND is a better\nproxy to the performance of model to a perturbed ex-\nample.\nAs the results presented from experiments so far\nuse subword tokenization, it is possible that the\nlocal perturbations being directly correlated with\nperformance decay could be caused by the pertur-\nbation to the vocabulary. Towards removing tok-\nenization as a confounding factor for the observed\nphenomenon, we train character-level BiLSTMs\nand ConvNets9 to evaluate whether the correlations\nwith the DND metric hold without multi-character\nvocabulary. Results shown in Figure 13 demon-\nstrate that DND remains as good of an explana-\ntion of the decay in performance of models with\ncharacter-level tokenization, as with models using\na vocabulary of subwords. This result allows gen-\neralizing the correlation to neural models beyond\nthe choice of tokenization.\n7 Discussion\nTokenization Our results on the importance of\nlocal structure could bear some implications for\ntokenization. Recent research trends (Xu et al.,\n2021; Clark et al., 2021) look at alternatives and\nimprovements to BPE. The current research ap-\npears to be pushing towards smaller vocabulary at\nﬁner granularity, even exploring simple byte-level\nrepresentations (Xue et al., 2021; Tay et al., 2021).\nThrough our DND metric, we ﬁnd that local\nclumps of characters contain the most essential\nstructural information required to solve several\nNLU problems. As a large part of the complexity\nof NLU seems to be contained within the meaning\nof the speciﬁc order of clumps of characters, by\nhaving more of that local structure ﬁxed through\ntokenization, it is possible to inject additional in-\nductive biases into the model. The perturbation\nanalysis discussed in the paper could be used for\nbetter construction of vocabulary with improved\nheuristics.\nLocal, Global, and Bag-of-Words Our results\non the relative importance of local structure in rela-\ntion to global structure hint at the possibility that\nmuch of the tested NLU tasks can be solved with a\nbag-of-words formulation. Intuitively, local struc-\nture mainly relates to building meaningful words\nfrom the characters of a text whereas the global\nstructure relates to the general order and word-level\nsyntax being maintained. From our experiments,\n9As character sequences are much longer than subword\nsequences for the same text and memory usage of transformer\nmodels scale quadratically with sequence length, we were not\nable to run our study on a character-level Transformer.\nwe observe that as long as the local structure is\nroughly maintained, a majority of NLU tasks can\nbe solved without requiring the global structure.\nThis correlates with similar ﬁndings by O’Connor\nand Andreas (2021). In essence, the structure re-\nquired to build words seems to be necessary, but\nmuch of NLU can be solved with the information\nof which words(or subwords) are present in the\ntext, without regard to their relative positions. This\nadds further credibility to similar research that at-\ntempts to understand the success of Transformers\nin NLP through hypothesizing that the global at-\ntention makes the architectures particularly apt at\nreﬂecting over a set of items, like a bag-of-words.\nLearning Positional Embeddings is Data Hun-\ngry Our experiments indicate that learning use-\nful positional embeddings require huge amounts\nof data and are mostly unused by Transformers\nthat were not pretrained with an extensive corpora.\nThis suggests that for problems where the input\norder is important, and there is limited training\ndata, models with stronger inductive biases such as\nConvNets and LSTMs may be a better choice than\nTransformers that were not pretrained (Tran et al.,\n2018). We leave experimenting with models from\nspeciﬁc breakpoints to study the evolution of the\nutility of positional embeddings to be explored as\nfuture work.\n8 Conclusion\nIn this work, we propose the Direct Neighbour\nDisplacement metric and the Index Displacement\nCount metric — that score the local and global\nstructure of tokens in the perturbed texts. The re-\nsults provide a way to quantify perturbations to\nbetter understand the inner workings of neural lan-\nguage understanding models. Reﬂecting on our re-\nsults, we observe that perturbations on a local level,\nas measured by DND, explains the (in)sensitivity of\npretrained language models to perturbations at dif-\nferent granularities on a variety of natural language\nunderstanding tasks. Although the paper primarily\nfocuses on the effects of perturbations on English\ntexts, extending the study to neural models on other\nlanguages could be beneﬁcial. Especially, study-\ning whether perturbations have a similar effect on\nother languages could help in deepening our un-\nderstanding of cross-language tasks, like machine\ntranslation.\nAcknowledgements\nWe thank Saujas Vaduguru for the useful comments\nand discussions on early drafts. This research was\nsupported by Apog ´ee Canada, Canada First Re-\nsearch Excellence Fund program and ´Ecole Poly-\ntechnique Startup Fund PIED. SC is supported by a\nCanada CIFAR AI Chair and an NSERC Discovery\nGrant.\nReferences\nEneko Agirre, Llu’is M‘arquez, and Richard Wicen-\ntowski, editors. 2007. Proceedings of the Fourth\nInternational Workshop on Semantic Evaluations\n(SemEval-2007). Association for Computational\nLinguistics, Prague, Czech Republic.\nRoy Bar Haim, Ido Dagan, Bill Dolan, Lisa Ferro,\nDanilo Giampiccolo, Bernardo Magnini, and Idan\nSzpektor. 2006. The second PASCAL recognising\ntextual entailment challenge. In Proceedings of the\nSecond PASCAL Challenges Workshop on Recognis-\ning Textual Entailment.\nYonatan Belinkov and James Glass. 2019. Analysis\nmethods in neural language processing: A survey.\nTransactions of the Association for Computational\nLinguistics, 7:49–72.\nLuisa Bentivogli, Ido Dagan, Hoa Trang Dang, Danilo\nGiampiccolo, and Bernardo Magnini. 2009. The\nﬁfth PASCAL recognizing textual entailment chal-\nlenge. In TAC.\nPiotr Bojanowski, Edouard Grave, Armand Joulin, and\nTomas Mikolov. 2017. Enriching word vectors with\nsubword information. Transactions of the Associa-\ntion for Computational Linguistics, 5:135–146.\nTom B Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. arXiv preprint arXiv:2005.14165.\nGrzegorz Chrupała and Afra Alishahi. 2019. Corre-\nlating neural and symbolic representations of lan-\nguage. In Proceedings of the 57th Annual Meet-\ning of the Association for Computational Linguis-\ntics, pages 2952–2962, Florence, Italy. Association\nfor Computational Linguistics.\nJonathan H Clark, Dan Garrette, Iulia Turc, and John\nWieting. 2021. Canine: Pre-training an efﬁcient\ntokenization-free encoder for language representa-\ntion. arXiv preprint arXiv:2103.06874.\nRonan Collobert and Jason Weston. 2008. A uniﬁed\narchitecture for natural language processing: Deep\nneural networks with multitask learning. In Pro-\nceedings of the 25th International Conference on\nMachine Learning, ICML ’08, page 160–167, New\nYork, NY , USA. Association for Computing Machin-\nery.\nJennifer Culbertson and David Adger. 2014. Language\nlearners privilege structured meaning over surface\nfrequency. Proceedings of the National Academy of\nSciences, 111(16):5842–5847.\nIdo Dagan, Oren Glickman, and Bernardo Magnini.\n2006. The PASCAL recognising textual entailment\nchallenge. In Machine learning challenges. evalu-\nating predictive uncertainty, visual object classiﬁca-\ntion, and recognising tectual entailment, pages 177–\n190. Springer.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. BERT: pre-training of\ndeep bidirectional transformers for language under-\nstanding. CoRR, abs/1810.04805.\nWilliam B Dolan and Chris Brockett. 2005. Automati-\ncally constructing a corpus of sentential paraphrases.\nIn Proceedings of the International Workshop on\nParaphrasing.\nJavid Ebrahimi, Anyi Rao, Daniel Lowd, and De-\njing Dou. 2017. Hotﬂip: White-box adversarial\nexamples for text classiﬁcation. arXiv preprint\narXiv:1712.06751.\nAllyson Ettinger. 2020. What BERT is not: Lessons\nfrom a new suite of psycholinguistic diagnostics for\nlanguage models. Transactions of the Association\nfor Computational Linguistics, 8:34–48.\nRichard Futrell, Roger P Levy, and Edward Gibson.\n2020. Dependency locality as an explanatory prin-\nciple for word order. Language, 96(2):371–412.\nJi Gao, Jack Lanchantin, Mary Lou Soffa, and Yan-\njun Qi. 2018. Black-box generation of adversarial\ntext sequences to evade deep learning classiﬁers. In\n2018 IEEE Security and Privacy Workshops (SPW),\npages 50–56. IEEE.\nDanilo Giampiccolo, Bernardo Magnini, Ido Dagan,\nand Bill Dolan. 2007. The third PASCAL recog-\nnizing textual entailment challenge. In Proceedings\nof the ACL-PASCAL workshop on textual entailment\nand paraphrasing, pages 1–9. Association for Com-\nputational Linguistics.\nGoran Glavaˇs and Ivan Vuli´c. 2020. Is supervised syn-\ntactic parsing beneﬁcial for language understanding?\nan empirical investigation.\nYoav Goldberg. 2019. Assessing bert’s syntactic abili-\nties. CoRR, abs/1901.05287.\nKristina Gulordava, Piotr Bojanowski, Edouard Grave,\nTal Linzen, and Marco Baroni. 2018. Color-\nless green recurrent networks dream hierarchically.\narXiv preprint arXiv:1803.11138.\nAshim Gupta, Giorgi Kvernadze, and Vivek Sriku-\nmar. 2021. Bert & family eat word salad: Ex-\nperiments with text understanding. arXiv preprint\narXiv:2101.03453.\nJohn Hale. 2017. Models of human sentence compre-\nhension in computational psycholinguistics. Oxford\nResearch Encyclopedia of Linguistics.\nZellig S Harris. 1954. Distributional structure. Word,\n10(2-3):146–162.\nJohn Hewitt and Christopher D. Manning. 2019. A\nstructural probe for ﬁnding syntax in word repre-\nsentations. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 4129–4138, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\nJeremy Howard and Sebastian Ruder. 2018. Fine-\ntuned language models for text classiﬁcation. CoRR,\nabs/1801.06146.\nYu-Lun Hsieh, Minhao Cheng, Da-Cheng Juan, Wei\nWei, Wen-Lian Hsu, and Cho-Jui Hsieh. 2019. On\nthe robustness of self-attentive models. In Proceed-\nings of the 57th Annual Meeting of the Association\nfor Computational Linguistics , pages 1520–1529,\nFlorence, Italy. Association for Computational Lin-\nguistics.\nGanesh Jawahar, Beno ˆıt Sagot, and Djam ´e Seddah.\n2019. What does BERT learn about the structure\nof language? In Proceedings of the 57th Annual\nMeeting of the Association for Computational Lin-\nguistics, pages 3651–3657, Florence, Italy. Associa-\ntion for Computational Linguistics.\nQuoc Le and Tomas Mikolov. 2014. Distributed repre-\nsentations of sentences and documents. In Interna-\ntional conference on machine learning, pages 1188–\n1196. PMLR.\nV . I. Levenshtein. 1966. Binary Codes Capable of Cor-\nrecting Deletions, Insertions and Reversals. Soviet\nPhysics Doklady, 10:707.\nHector J Levesque, Ernest Davis, and Leora Morgen-\nstern. 2011. The Winograd schema challenge. In\nAAAI Spring Symposium: Logical Formalizations of\nCommonsense Reasoning, volume 46, page 47.\nMike Lewis, Yinhan Liu, Naman Goyal, Mar-\njan Ghazvininejad, Abdelrahman Mohamed, Omer\nLevy, Veselin Stoyanov, and Luke Zettlemoyer.\n2020. BART: Denoising sequence-to-sequence pre-\ntraining for natural language generation, translation,\nand comprehension. In Proceedings of the 58th An-\nnual Meeting of the Association for Computational\nLinguistics, pages 7871–7880, Online. Association\nfor Computational Linguistics.\nChin-Yew Lin. 2004. Rouge: A package for automatic\nevaluation of summaries. In Text summarization\nbranches out, pages 74–81.\nYongjie Lin, Yi Chern Tan, and Robert Frank. 2019a.\nOpen sesame: Getting inside BERT’s linguistic\nknowledge. In Proceedings of the 2019 ACL Work-\nshop BlackboxNLP: Analyzing and Interpreting Neu-\nral Networks for NLP , pages 241–253, Florence,\nItaly. Association for Computational Linguistics.\nYongjie Lin, Yi Chern Tan, and Robert Frank. 2019b.\nOpen sesame: Getting inside BERT’s linguistic\nknowledge. In Proceedings of the 2019 ACL Work-\nshop BlackboxNLP: Analyzing and Interpreting Neu-\nral Networks for NLP , pages 241–253, Florence,\nItaly. Association for Computational Linguistics.\nNelson F Liu, Matt Gardner, Yonatan Belinkov,\nMatthew E Peters, and Noah A Smith. 2019a. Lin-\nguistic knowledge and transferability of contextual\nrepresentations. arXiv preprint arXiv:1903.08855.\nNelson F. Liu, Matt Gardner, Yonatan Belinkov,\nMatthew E. Peters, and Noah A. Smith. 2019b. Lin-\nguistic knowledge and transferability of contextual\nrepresentations. In Proceedings of the 2019 Confer-\nence of the North American Chapter of the Associ-\nation for Computational Linguistics: Human Lan-\nguage Technologies, Volume 1 (Long and Short Pa-\npers), pages 1073–1094, Minneapolis, Minnesota.\nAssociation for Computational Linguistics.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019c.\nRoberta: A robustly optimized bert pretraining ap-\nproach. ArXiv, abs/1907.11692.\nJoe O’Connor and Jacob Andreas. 2021. What con-\ntext features can transformer language models use?\narXiv preprint arXiv:2106.08367.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic eval-\nuation of machine translation. In Proceedings of the\n40th annual meeting of the Association for Compu-\ntational Linguistics, pages 311–318.\nPrasanna Parthasarathi, Koustuv Sinha, Joelle Pineau,\nand Adina Williams. 2021. Sometimes we want\ntranslationese. arXiv preprint arXiv:2104.07623.\nAdam Paszke, Sam Gross, Francisco Massa, Adam\nLerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca\nAntiga, Alban Desmaison, Andreas Kopf, Edward\nYang, Zachary DeVito, Martin Raison, Alykhan Te-\njani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang,\nJunjie Bai, and Soumith Chintala. 2019. Py-\ntorch: An imperative style, high-performance deep\nlearning library. In H. Wallach, H. Larochelle,\nA. Beygelzimer, F. d Alch´e-Buc, E. Fox, and R. Gar-\nnett, editors, Advances in Neural Information Pro-\ncessing Systems 32, pages 8024–8035. Curran Asso-\nciates, Inc.\nMatthew E. Peters, Mark Neumann, Mohit Iyyer, Matt\nGardner, Christopher Clark, Kenton Lee, and Luke\nZettlemoyer. 2018. Deep contextualized word repre-\nsentations. CoRR, abs/1802.05365.\nNgoc-Quan Pham, Jan Niehues, Thanh-Le Ha, and\nAlexander Waibel. 2019. Improving zero-shot trans-\nlation with language-independent constraints. In\nProceedings of the Fourth Conference on Machine\nTranslation (Volume 1: Research Papers), pages 13–\n23, Florence, Italy. Association for Computational\nLinguistics.\nThang M Pham, Trung Bui, Long Mai, and Anh\nNguyen. 2020. Out of order: How important is\nthe sequential order of words in a sentence in nat-\nural language understanding tasks? arXiv preprint\narXiv:2012.15180.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog, 1(8):9.\nPranav Rajpurkar, Robin Jia, and Percy Liang. 2018.\nKnow what you don’t know: Unanswerable ques-\ntions for squad. CoRR, abs/1806.03822.\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev,\nand Percy Liang. 2016a. Squad: 100, 000+ ques-\ntions for machine comprehension of text. CoRR,\nabs/1606.05250.\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and\nPercy Liang. 2016b. SQuAD: 100,000+ questions\nfor machine comprehension of text. In Proceedings\nof EMNLP. Association for Computational Linguis-\ntics.\nAnna Rogers, Olga Kovaleva, and Anna Rumshisky.\n2020. A primer in bertology: What we know about\nhow bert works. Transactions of the Association for\nComputational Linguistics, 8:842–866.\nChinnadhurai Sankar, Sandeep Subramanian, Chris Pal,\nSarath Chandar, and Yoshua Bengio. 2019. Do neu-\nral dialog systems use the conversation history ef-\nfectively? an empirical study. In Proceedings of\nthe 57th Annual Meeting of the Association for Com-\nputational Linguistics, pages 32–37, Florence, Italy.\nAssociation for Computational Linguistics.\nMike Schuster and Kuldip K. Paliwal. 1997. Bidirec-\ntional recurrent neural networks. IEEE Trans. Sig-\nnal Process., 45(11):2673–2681.\nThibault Sellam, Dipanjan Das, and Ankur Parikh.\n2020. BLEURT: Learning robust metrics for text\ngeneration. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 7881–7892, Online. Association for Computa-\ntional Linguistics.\nKoustuv Sinha, Robin Jia, Dieuwke Hupkes, Joelle\nPineau, Adina Williams, and Douwe Kiela. 2021.\nMasked language modeling and the distributional\nhypothesis: Order word matters pre-training for lit-\ntle. arXiv preprint arXiv:2104.06644.\nKoustuv Sinha, Prasanna Parthasarathi, Joelle Pineau,\nand Adina Williams. 2020. Unnatural language in-\nference. arXiv preprint arXiv:2101.00010.\nRichard Socher, Alex Perelygin, Jean Wu, Jason\nChuang, Christopher D Manning, Andrew Ng, and\nChristopher Potts. 2013. Recursive deep models\nfor semantic compositionality over a sentiment tree-\nbank. In Proceedings of EMNLP, pages 1631–1642.\nYi Tay, Vinh Q Tran, Sebastian Ruder, Jai Gupta,\nHyung Won Chung, Dara Bahri, Zhen Qin, Si-\nmon Baumgartner, Cong Yu, and Donald Metzler.\n2021. Charformer: Fast character transformers\nvia gradient-based subword tokenization. arXiv\npreprint arXiv:2106.12672.\nIan Tenney, Patrick Xia, Berlin Chen, Alex Wang,\nAdam Poliak, R Thomas McCoy, Najoung Kim,\nBenjamin Van Durme, Samuel R. Bowman, Dipan-\njan Das, and Ellie Pavlick. 2019. What do you learn\nfrom context? probing for sentence structure in con-\ntextualized word representations.\nKe Tran, Arianna Bisazza, and Christof Monz. 2018.\nThe importance of being recurrent for modeling hi-\nerarchical structure. In Proceedings of the 2018\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 4731–4736, Brussels, Bel-\ngium. Association for Computational Linguistics.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. CoRR, abs/1706.03762.\nAlex Wang, Yada Pruksachatkun, Nikita Nangia,\nAmanpreet Singh, Julian Michael, Felix Hill, Omer\nLevy, and Samuel R. Bowman. 2019a. Superglue:\nA stickier benchmark for general-purpose language\nunderstanding systems. CoRR, abs/1905.00537.\nAlex Wang, Amanpreet Singh, Julian Michael, Felix\nHill, Omer Levy, and Samuel R. Bowman. 2019b.\nGLUE: A multi-task benchmark and analysis plat-\nform for natural language understanding. In 7th\nInternational Conference on Learning Representa-\ntions, ICLR 2019, New Orleans, LA, USA, May 6-9,\n2019.\nHai Wang, Dian Yu, Kai Sun, Jianshu Chen, and\nDong Yu. 2019c. Improving pre-trained multilin-\ngual model with vocabulary expansion. In Proceed-\nings of the 23rd Conference on Computational Nat-\nural Language Learning (CoNLL) , pages 316–327,\nHong Kong, China. Association for Computational\nLinguistics.\nAlex Warstadt, Amanpreet Singh, and Samuel R. Bow-\nman. 2018. Neural network acceptability judgments.\narXiv preprint 1805.12471.\nAlex Warstadt, Yian Zhang, Xiaocheng Li, Haokun\nLiu, and Samuel R. Bowman. 2020. Learning which\nfeatures matter: RoBERTa acquires a preference for\nlinguistic generalizations (eventually). In Proceed-\nings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP) , pages\n217–235, Online. Association for Computational\nLinguistics.\nAdina Williams, Nikita Nangia, and Samuel R. Bow-\nman. 2018. A broad-coverage challenge corpus for\nsentence understanding through inference. In Pro-\nceedings of NAACL-HLT.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, R’emi Louf, Morgan Funtow-\nicz, and Jamie Brew. 2019. Huggingface’s trans-\nformers: State-of-the-art natural language process-\ning. ArXiv, abs/1910.03771.\nJingjing Xu, Hao Zhou, Chun Gan, Zaixiang Zheng,\nand Lei Li. 2021. V ocabulary learning via optimal\ntransport for neural machine translation. In Proceed-\nings of the Association for Computational Linguis-\ntics.\nLinting Xue, Aditya Barua, Noah Constant, Rami Al-\nRfou, Sharan Narang, Mihir Kale, Adam Roberts,\nand Colin Raffel. 2021. Byt5: Towards a token-free\nfuture with pre-trained byte-to-byte models. arXiv\npreprint arXiv:2105.13626.\nLi Yujian and Liu Bo. 2007. A normalized levenshtein\ndistance metric. IEEE transactions on pattern anal-\nysis and machine intelligence, 29(6):1091–1095.\nKelly Zhang and Samuel Bowman. 2018. Language\nmodeling teaches you more than translation does:\nLessons learned through auxiliary syntactic task\nanalysis. In Proceedings of the 2018 EMNLP Work-\nshop BlackboxNLP: Analyzing and Interpreting Neu-\nral Networks for NLP, pages 359–361.\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q\nWeinberger, and Yoav Artzi. 2019. Bertscore: Eval-\nuating text generation with bert. arXiv preprint\narXiv:1904.09675.\nHan Zhao, Zhengdong Lu, and Pascal Poupart. 2015.\nSelf-adaptive hierarchical sentence model. CoRR,\nabs/1504.05070.\nA Experiment Details\nModel Hyperparameters The results in the pa-\nper are averaged over ﬁv experiments run for 5\nrandom seeds. Early stopping was performed af-\nter 2 full epochs not resulting in better results on\nthe validation set. All models had similar model\nsizes, containing between 100 million and 130 mil-\nlion parameters. The ConvNet architecture is the\none described in Collobert and Weston (2008) and\nthe BiLSTM architecture is the one described in\nZhao et al. (2015). Both use the same hidden size,\ndropout and word embedding size as the RoBERTa-\nBase model. Pretrained models used a learning rate\nof 2e-5, a batch size of 32, a maximum of 3 epochs\nand a weight decay of 0.1. Non pretrained models\nused a learning rate of 1e-4, a batch size of 128,\na maximum of 50 epochs and a weight decay of\n1e-6. All experiments used a warmup ratio of 0.06,\nas described in Liu et al. (2019c). Experiments us-\ning characters as input used a maximum sequence\nlength of 2048 inputs. All other experiments used a\nmaximum sequence length of 512. The Winograd\nSchema Challenge (WNLI) task was omitted from\nall experiments.\nPerturbations Subword-level perturbations\nwere all done with the RoBERTa-Base vocab-\nulary. On all level of granularity, we perform\nexperiments with the full shufﬂing, the n-gram\nshufﬂing with ρ = 0.66 and the neighbour ﬂip\nperturbation with ρ = 0.5. As the word-level\nand subword-level perturbations do not permit\na sufﬁcient exploration of DND, we populate\nthe continuum of our metric with several more\ncharacter-level perturbations by testing different\nvalues of ρ for both the n-gram shufﬂing and the\nneighbour ﬂip perturbation. Experiments are ran\nwith following values of ρ for n-gram shufﬂing:\n{0.5,0.4,0.3,0.2,0.15}, and for neighbour ﬂip\nperturbation: {0.4,0.3,0.2,0.15,0.1}.\nB Pseudocode for Metric and\nPerturbations\nFunction IDC(Xp):\nXlenp ←Xp.length();\nIDC list ←list()\nfor i ←0 and i ≤Xlenp do\nabs distortion ←abs(i-Xp [i]);\nIDC list.append(abs distortion);\nend\nIDC agg ←IDC list.mean();\nIDC ←IDC agg\nXlenp\n;\nreturn\nAlgorithm 1: Pseudocode to compute IDC\nmetric.\nFunction DND(Xp):\nXlenp ←Xp.length();\nDND list ←list()\nfor i ←0 and i ≤Xlenp −1 do\nif Xp[i]−Xp[i +1] ==1 then\nDND list.append(0);\nelse\nDND list.append(1);\nend\nend\nDND agg ←DND list.sum();\nDND ←DND agg\n(Xlenp −1) ;\nreturn\nAlgorithm 2: Pseudocode to compute DND\nmetric.\nFunction PhrasePerturbation(ρ ←0.5,\ntext←list ):\nall phrases ←list();\nphrase ←list(text[0])\nfor token in text[1 :] do\np ∼Uni f ([0,1]);\nif p < ρ then\nall phrases.append(phrase);\nphrase ←list(token)\nelse\nphrase ←[phrase,token];\nend\nend\nall phrases.append(phrase);\nperturbed text ←‘’.join(shufﬂe(all phrases))\nreturn perturbed text\nAlgorithm 3: Pseudocode for PhraseShufﬂe.\nFunction NeighborFlip(ρ ←0.5,text←list ):\nperturbed tokens ←list();\nheld token ←list(text[0])\nfor token in text[1 :] do\np ∼Uni f ([0,1]);\nif p < ρ then\nperturbed tokens.append(held token);\nheld token ←list(token)\nelse\nperturbed tokens\n←[perturbed tokens,token];\nend\nend\nperturbed tokens.append(held token);\nperturbed text ←‘’.join(perturbed tokens)\nreturn perturbed text\nAlgorithm 4: Pseudocode for NeighborFlip.\nC DND/IDC Computation Examples\nListing 1: A few example of perturbations as well as the calculation steps to obtain both the IDC and DND metrics.\n# Original order\nX = \"T h i s ’ ’ i s ’ ’ a ’ ’ t e s t\"\nP_X = [0 , 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 , 11 , 12 , 13]\n# Simple splitting along the middle\nX’ = \"a ’ ’ t e s t T h i s ’ ’ i s ’ ’\"\nP_X ’ = [8 , 9, 10 , 11 , 12 , 13 , 0, 1, 2, 3, 4, 5, 6, 7]\nIDC_list = [8 , 8, 8, 8, 8, 8, 6, 6, 6, 6, 6, 6, 6, 6]\nIDC_mean = 6.85\nIDC = 0.49\nDND_list = [0 , 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\nDND_sum = 1\nDND = 0.08\n# Shuffling of the words randomly\nX’ = \"t e s t i s ’ ’ a ’ ’ T h i s ’ ’\"\nP_X ’ = [10 , 11 , 12 , 13 , 5, 6, 7, 8, 9, 0, 1, 2, 3, 4]\nIDC_list = [10 , 10 , 10 , 10 , 1, 1, 1, 1, 1, 9, 9, 9, 9, 9]\nIDC_mean = 6.42\nIDC = 0.46\nDND_list = [0 , 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\nDND_sum = 2\nDND = 0.15\n# Flipping neighbouring characters randomly\nX’ = \"h T i ’ ’ i s ’ ’ s a ’ ’ t s e t\"\nP_X ’ = [1 , 0, 2, 4, 5, 3, 7, 6, 8, 9, 10 , 12 , 11 , 13]\nIDC_list = [1 , 1, 0, 1, 1, 2, 1, 1, 0, 0, 0, 1, 1, 0]\nIDC_mean = 0.71\nIDC = 0.05\nDND_list = [1 , 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1]\nDND_sum = 10\nDND = 0.76\nD Distribution of metrics scoring perturbations\nFigure 14: The distribution highlights that although the different word-level perturbations seem to cover the spec-\ntrum of possible scores, the perturbations do not seem to perturb the local ordering as effectively measured by\nDND.\nE Reproducibility Checklist\nAs per the prescribed Reproducibility Checklist,\nwe provide the information of the following:\n• A clear description of the mathematical set-\nting, algorithm and/or model : We provide\ndetails of models used in §5 and §B for detail-\ning pseudocodes for both the metrics and the\ndifferent perturbations proposed in the paper.\n• Submission of source code: Source code for\nthe perturbations, metrics and models is pro-\nvided in GitHub. The training code was\nadapted from the excellent Wolf et al. (2019)\ngithub.\n• Description of the computing infrastructure\nused: We used up to 20 NVIDIA V100 32 GB\nat a time to run all experiments. All models\nwhere trained and evaluated on 1 NVIDIA\nV100 32 GB GPUs for every seed of every\nmodel.\n• Average runtime for each approach: The ap-\nproximate training time for ﬁne-tuning varies\nbetween 4-8 hours and the inferencing on stan-\ndard validation sets was about an hour.\n• Explanation of evaluation metrics used, with\nlinks to code: We add necessary citations for\nthe metrics considered in the paper and also\nprovide codes to reproduce them.\n• Relevant statistics of the datasets used : We\nprovide the statistics of the datasets used in 5.\n• Explanation of any data that were excluded,\nand all pre-processing steps: The details for\nomitting WNLI data from GLUE benchmark\nare provided in §A.\n• Link to downloadable version of data : The\ndata sets used in the paper are from public\nrepositories. Links to the paper that proposes\nthe data sets is included in §5."
}