{
  "title": "Evaluating a customised large language model (DELSTAR) and its ability to address medication-related questions associated with delirium: a quantitative exploratory study",
  "url": "https://openalex.org/W4409320402",
  "year": 2025,
  "authors": [
    {
      "id": null,
      "name": "Spagl, Katharina Teresa",
      "affiliations": [
        "Universität Innsbruck"
      ]
    },
    {
      "id": null,
      "name": "Watson, Edward William",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2742113249",
      "name": "Jatowt, Adam",
      "affiliations": [
        "Universität Innsbruck"
      ]
    },
    {
      "id": null,
      "name": "Weidmann, Anita Elaine",
      "affiliations": [
        "Universität Innsbruck"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2766646492",
    "https://openalex.org/W2089926819",
    "https://openalex.org/W4210627411",
    "https://openalex.org/W3014327609",
    "https://openalex.org/W3042096137",
    "https://openalex.org/W2972175093",
    "https://openalex.org/W3143425064",
    "https://openalex.org/W4365813739",
    "https://openalex.org/W3093172808",
    "https://openalex.org/W4402726346",
    "https://openalex.org/W4384912864",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W4225597912",
    "https://openalex.org/W4387737833",
    "https://openalex.org/W4407754355",
    "https://openalex.org/W4394596461",
    "https://openalex.org/W4390607214",
    "https://openalex.org/W4387500346",
    "https://openalex.org/W2252211741",
    "https://openalex.org/W3105604018",
    "https://openalex.org/W4381586841",
    "https://openalex.org/W3206345746",
    "https://openalex.org/W4377130677",
    "https://openalex.org/W4386242180",
    "https://openalex.org/W1487097365",
    "https://openalex.org/W4283826580",
    "https://openalex.org/W4210494925",
    "https://openalex.org/W4388848802",
    "https://openalex.org/W4400368811",
    "https://openalex.org/W4372404592",
    "https://openalex.org/W4390587679",
    "https://openalex.org/W4392576299",
    "https://openalex.org/W4403016484",
    "https://openalex.org/W4391590636",
    "https://openalex.org/W4393160302",
    "https://openalex.org/W4206829499",
    "https://openalex.org/W3109391513",
    "https://openalex.org/W4210580280",
    "https://openalex.org/W4226307173",
    "https://openalex.org/W4404921521"
  ],
  "abstract": null,
  "full_text": "Vol.:(0123456789)\nInternational Journal of Clinical Pharmacy (2025) 47:1053–1063 \nhttps://doi.org/10.1007/s11096-025-01900-8\nRESEARCH ARTICLE\nEvaluating a customised large language model (DELSTAR) and its \nability to address medication‑related questions associated \nwith delirium: a quantitative exploratory study\nKatharina Teresa Spagl1  · Edward William Watson2 · Adam Jatowt3  · Anita Elaine Weidmann1 \nReceived: 24 December 2024 / Accepted: 6 March 2025 / Published online: 10 April 2025 \n© The Author(s) 2025\nAbstract\nBackground A customised large language model (LLM) could serve as a next-generation clinical pharmacy research assistant \nto prevent medication-associated delirium. Comprehensive evaluation strategies are still missing.\nAim This quantitative exploratory study aimed to develop an approach to comprehensively assess the domain-specific cus-\ntomised delirium LLM (DELSTAR) ability, quality and performance to accurately address complex clinical and practice \nresearch questions on delirium that typically require extensive literature searches and meta-analyses.\nMethod DELSTAR, focused on delirium-associated medications, was implemented as a ‘Custom GPT’ for quality assess-\nment and as a Python-based software pipeline for performance testing on closed and leading open models. Quality metrics \nincluded statement accuracy and data credibility; performance metrics covered F1-Score, sensitivity/specificity, precision, \nAUC, and AUC-ROC curves.\nResults DELSTAR demonstrated more accurate and comprehensive information compared to information retrieved by \ntraditional systematic literature reviews (SLRs) (p  < 0.05) and accessed Application Programmer Interfaces (API), private \ndatabases, and high-quality sources despite mainly relying on less reliable internet sources. GPT-3.5 and GPT-4o emerged as \nthe most reliable foundation models. In Dataset 2, GPT-4o (F1-Score: 0.687) and Llama3-70b (F1-Score: 0.655) performed \nbest, while in Dataset 3, GPT-3.5 (F1-Score: 0.708) and GPT-4o (F1-Score: 0.665) led. None consistently met desired \nthreshold values across all metrics.\nConclusion DELSTAR demonstrated potential as a clinical pharmacy research assistant, surpassing traditional SLRs in \nquality. Improvements are needed in high-quality data use, citation, and performance optimisation. GPT-4o, GPT-3.5, and \nLlama3-70b were the most suitable foundation models, but fine-tuning DELSTAR is essential to enhance sensitivity, espe-\ncially critical in pharmaceutical contexts.\nKeywords Clinical pharmacy information systems · Delirium · Drug prescribing · Intelligence artificial · Intelligence \nmachine · Patient safety\nImpact statements\n• A delirium-specific large language model (DELSTAR) \nthat focuses on medication-related information was \ndeveloped.\n• This customised, domain-specific chatbot using a simplified \ntree-of-thoughts version serves as a proof-of-concept to sup-\nport future literature-based clinical practice research.\n• DELSTAR’s ability to identify accurate and comprehen-\nsive information about medication-related causes and \ntreatments of delirium could be beneficial to support \nclinical prescribing practice in the future.\n * Anita Elaine Weidmann \n anita.weidmann@uibk.ac.at\n1 Department of Clinical Pharmacy, Institute of Pharmacy, \nInnsbruck University, Innrain 80, 6020 Innsbruck, Austria\n2 Department of Media and Learning Technology, Innsbruck \nUniversity, Innrain 52, 6020 Innsbruck, Austria\n3 Department of Computer Science and Digital Science Centre, \nInnsbruck University, Technikerstraße 21a, 6020 Innsbruck, \nAustria\n1054 International Journal of Clinical Pharmacy (2025) 47:1053–1063\nIntroduction\nDelirium, an acute non-specific neuropsychiatric syndrome, \nremains a major clinical challenge, increasing morbid-\nity, mortality and the risk of long-term cognitive decline \n[1–5]. Despite its significant impact on patient’s health, \nthe pathophysiology remains unclear, but it likely arises \nfrom multiple factors, including medication [4 , 6, 7]. This \nacute yet debilitating condition primarily affects vulnerable \ngroups, such as the elderly, the critically ill, and patients in \nthe peri-operative care setting [5 , 8–10]. Advancements in \nmedical technologies, particularly in deep medicine (DM), \nhave shown that AI-driven tools can enhance patient diag-\nnosis and treatment by processing and analysing clinical \ndata [ 11]. However, AI’s applications in clinical contexts \nrequire thorough validation due to patient safety risks [12]. \nWhile interest in AI tools is growing, understanding of their \nmechanisms and appropriate use remains limited [12, 13].\nDespite drug toxicity being estimated to account for \n12–39% of all delirium cases, comprehensive documenta -\ntion on medication-associated risks and related information \nremains lacking [14]. While several guidelines recommend \nthat all patients at risk of delirium should have a medication \nreview conducted by a clinical pharmacist, detailed prescrib-\ning guidance is not available [15, 16]. To address this gap, \nthe Institute of Clinical Pharmacy at the University of Inns-\nbruck aims to create comprehensive documentation on med-\nication-associated delirium in diverse patient populations \n(e.g. dementia, paediatrics, peri-operative). Complementing \nseveral high-quality systematic literature reviews (SLR) on \nmedication risks associated with delirium in these popula-\ntions [17–24], the team developed DELSTAR, a customised, \ndomain-specific large language model (LLM), as a novel \nresearch assistant [25]. DELSTAR, unlike existing delirium \nspecific predictive models that do not include medication \nas a predictive variable, focuses specifically on medication \nrelated information and causes [25]. By targeting collections \nof peer reviewed papers as a source data, using application \nprogram interfaces (APIs) where possible, the DELSTAR \nAI tool embodies a novel approach for clinical pharmacy \nresearch [25]. In natural language processing (NLP), LLMs \nlike DELSTAR are prone to “hallucinations,” where they \nmay produce incorrect but confident answers, raising con-\ncerns about transparency and accountability [26, 27]. To \nensure the safe and effective integration of LLMs in clinical \nand research settings, it is essential to establish precise eval-\nuation methods for assessing their quality and performance \n[11, 12]. While general benchmarks like GLUE, Super -\nGLUE, and BIG-Bench assess LLM capabilities, and frame-\nworks like AdvGLUE and TextFlint test performance and \nrobustness [28–30], no comprehensive evaluation methods \nexist for customised LLMs in clinical pharmacy applications \nlike DELSTAR. This study aims to address these evalua-\ntion challenges by testing statement quality, data integration, \ncredibility and performance testing.\nAim\nThis quantitative exploratory study aimed to develop an \napproach to comprehensively assess the domain-specific \ncustomised delirium LLM’s (DELSTAR) ability, quality \nand performance to accurately address complex research \nquestions on medication-associated delirium that typically \nrequire extensive literature searches and meta-analyses.\nEthics approval\nNo ethical approval was required for this machine learning \nevaluation study. The guidelines of the Austrian Agency for \nResearch Integrity on Good Scientific Practice were adhered \nto [31].\nMethod\nDELSTAR development\nDELSTAR’s core consists of its dataset and system prompt, \nwhich are compatible with various backend or foundation \nmodels. Iterative updates improved response quality. Nota-\nbly, DELSTAR was designed so that no external depend-\nencies on cloud systems arise. Two implementations were \ndeveloped: firstly, a “Custom GPT” using OpenAI’s web \ninterface for quality testing; secondly, a locally run Python \npipeline using LLamaIndex to test performance at a larger \nscale. The Python version supports OpenAI’s closed and \nopen models like Llama and Mistral, enabling large-scale \nautomated inferencing and data extraction. The LLM user \ninterface tool ‘Open Web UI’ was chosen as the external \ntool, since it offers a user-friendly frontend interface simi-\nlar to the OpenAI web interface. This choice facilitated a \nmore direct comparison between the open and closed foun-\ndation models capable of driving DELSTAR (V4 and V5). \nChallenges in restricting the pipeline outputs to “yes” or \n“no” were resolved using a “Yes–no-summary-bot,” built \non Llama3.1, to make binary judgments.\nDELSTAR training\nThe system accesses offline knowledge databases and live \nonline metadata to detect patterns between medication and \ndelirium symptoms. The implications are that the offline \n1055International Journal of Clinical Pharmacy (2025) 47:1053–1063 \nmodel is under full control and ownership of the researcher, \nand live data-sources can be hand-picked and subscribed to \naccording to need. Offline models with online source selec-\ntions imply a higher level of control. A document-based \ndataset was translated into text embeddings and stored as \nvectors in a vector database. Retrieval Augmented Gen-\neration (RAG) was used to retrieve relevant data chunks \nto inform DELSTAR’s responses (refer to Supplementary \nMaterial 1). Bias in the dataset were controlled for by the use \nof systematic review in the DELSTAR database embedding \nand expert consultation for the selection of performance-\ntesting questions. Figure 1 illustrates the evaluation process, \nwith further details in subsequent sections.\nGeneration of testsets\nIn the initial phase, three datasets—Master, full-factual, \nand half-fictional—were created, excluding any data used \nin chatbot development to ensure reliable test results. These \ndatasets are outlined in Table  1 and described below. The \nMaster Dataset (MD) includes all medications and related \ninformation linked to delirium, identified through three \nSLRs registered with PROSPERO [17, 20, 24], following \nJoanna Briggs Institute (JBI) and PRISMA guidelines. Iden-\ntified drugs were categorised by the Anatomical Therapeutic \nChemical (ATC) code classification (2023) from Bundes-\ninstitut für Arzneimittel und Medizinprodukte (BfArM), \nGermany [32]. Two balanced binary datasets, each contain-\ning 50% of a shuffled MD, were created. The half-fictional \ndataset (D2) features fictitious drug names generated by a \nMixtral 8 × 7b chatbot (temperature setting = 1). The full-\nfactual dataset (D3) incorporates non-delirium drugs, with \nmedication classes in the ATC code but absent from the MD \nclassified as non-delirium-associated for testing [32]. A few-\nshot approach was implemented for testing, resulting in 286 \ndrugs per dataset [ 33]. The data collection period spanned \nfrom 03.04.2024 to 16.07.2024.\nQuality assessment\nQuality testing was conducted using the MD (Sect. “ Web-\nsite and journal citation analysis”) with a node approach \nFig. 1  Methodology taxonomy used for quality assessment and performance testing\nTable 1  Comparison of the data sets used to test DELSTAR based on their size and composition\nName Master dataset (MD) Half-fictional dataset (D2) Full-factual dataset (D3)\nNumber of contained drugs 290 286 286\nComposition of the dataset 100% of drugs identified as delirium-asso-\nciated during three state-of-the-art SLRs\n50% of drugs in the Master data-\nset (associated with delirium);\n50% of fictional drug names (not \nassociated with delirium)\n50% of drugs in the Master \ndataset (associated with \ndelirium);\n50% of existing drugs (not \nassociated with delirium)\n1056 International Journal of Clinical Pharmacy (2025) 47:1053–1063\n(NA) based on a simplified version of the Tree-of-Thought \n(ToT) strategy [34, 35]. This approach, validated to improve \nquery success, is used when early decision-making or stra-\ntegic foresight is required. In this simplified version, human \nexperts, rather than a ToT controller AI, handled backtrack-\ning. In DELSTAR’s context, NA provided multiple response \noptions, allowing users to explore further details and request \nevidence. Testing followed a structured framework (Table 2), \nwith drug responses collated and analysed regarding their \nstatement quality and data credibility.\nStatement quality\nComparison of the results obtained for specific drugs using \nthe node-based approach (NA) with the information in the \nMaster Dataset performed by two independent expert phar-\nmacists (KTS /IT; JS) The outcome was assigned to one of \nthe categories (A) more specific, (B) less specific, (C) addi-\ntional or (D) general. Disagreements were resolved. Results \nwere interpreted and plotted using simple non-parametric \nstatistics (Kruskal–Wallis-Test (p < 0.05)).\nData integration and credibility\nAssessment of whether DELSTAR integrates the appropriate \nselection of data sources and available Application Program-\nming Interfaces (APIs). Sources cited by DELSTAR were \ndocumented and evaluated in terms of their scientific merit \nand quality.\nPerformance testing\nDELSTAR was reimplemented and exposed to external \ntools (online/offline foundation models) via an OpenAI-\ncompatible API using the DELSTAR design (Sect. \" State-\nment quality analysis\"). The selection of offline open models \nwas driven by the popularity and accessibility of models \nat the time of analysis, as determined by consultation with \nAI science community members. Lack of project funding \npermitted only a single closed model for use as a compara-\ntor. The online closed model was considered best-in-class at \nthe time of the analysis. The applied test strategy allowed a \nwell-informed assessment of chatbot performances/stabil-\nity and was a foundation for implementing enhancements \nin DELSTAR. A simple yes–no question was automatically \nposed for each drug in D2 and D3:\n“Does DRUG X cause delirium?”\nResponses were automatically recorded, categorised as \nyes or no, and classified as true positives (TP), false posi-\ntives (FP), true negatives (TN), or false negatives (FN) \n(Sect. \"Statement quality analysis\"). This process was \napplied to 6 DELSTAR-foundation model combinations \nwith varying parameters (Fig.  1). DELSTAR(V5) was uti-\nlised for all models except Llama3, which required a Llama-\nspecific prompt. Confusion matrices were generated, and \nperformance metrics (recall, precision, sensitivity, speci-\nficity, F1-Score, AUC) were calculated according to best \npractice data mining methodology [13, 36–39]. Stability \nwas compared using a simplified AUC-ROC based on the \nintersection of the calculated TPR and FPR, as no thresholds \nwere specified.\nResults\nSections “Statement quality analysis” to “Website and jour-\nnal citation analysis” serve as the foundation for the subse-\nquent data evaluation. Since no data was collected in these \nsections, the results presented start with a quality assess-\nment. As improvements were implemented in DELSTAR \nthroughout the testing phase, the outcomes are presented \nchronologically. The datasets generated and analysed during \nthis study are available from the corresponding author upon \nreasonable request.\nStatement quality analysis\nTwenty performed NA runs were compared with the infor -\nmation in the MD (derived from SLRs), resulting in the \nfinal evaluation presented in Table  3. Results indicate that \nDELSTAR generated higher quality statements than MD in \n50.0–75.0% (n = 20) cases, depending on the category. Nota-\nbly, DELSTAR provided more detailed information in 75.0% \n(n = 20) of “Overall Content” evaluations. Conversely, the \nTable 2  Framework structure encountered during chatbot search process: a search query is deemed successful only when all predefined ques-\ntions in the frame have been answered according to the specifications\nIN: If an error occurs, classify the error and start a new chat; EX 1 /2, EN: If an insufficient answer occurs, repeat instruction until successful\nInitial node instruction (IN) [NODE 0] Which medications cause delirium?\nExpansion node instruction 1 (EX1) Expand [NODE X] X and focus on specific generics. Produce new nodes for each drug\nExpansion node instruction 2 (EX2) Expand [NODE Y] Y and focus on delirium-specific information. Produce new nodes for each piece of \ninformation\nEvidence node instruction\n(EN)\nEvidence delirium-focused [NODE Y] Y and focus on the following labels: (a) Side effects, (b) Interac-\ntions, and (c) Alternatives\n1057International Journal of Clinical Pharmacy (2025) 47:1053–1063 \nMD was rated as more specific only once within this cat-\negory. While DELSTAR was categorised as less specific \nin 7 out of 80 categorisation options (8.8% (n = 80)) (most \nfrequently within “Interactions”), it offered general or addi-\ntional information in up to 20.0% (n = 80) of cases. The most \nfavourable results were observed within the “Therapeutic \nAlternatives” category. DELSTAR generally outperformed \nthe MD, demonstrating superior performance in most sub-\ncategories, particularly “Therapeutic Alternatives.” Nota-\nbly, one instance of incorrect information generation (hal -\nlucination) was observed. A performed Kruskal–Wallis test \n(α = 0.05) indicated a significant difference (p  = 0.00469) \nbetween the 5 groups suggesting varying quality level \ndistribution.\nCitation analysis in NA runs\nAnalysis of 20 NA Runs revealed 94 integrated citations, \npredominantly supporting “Side Effects” (28.7%; n = 94) \nand “Interactions” (22.3%; n = 94). Citation coverage was \nlower for “Therapeutic Alternatives” (20.2%; n = 94) and \n“Specific Question” (28.7%; n = 94. While various APIs \nwere available, only api.semanticscholar.org was explicitly \nutilised (n = 2), with 3 instances of access failure. Thirty-\nfive types of sources could be identified. Website citations \n(x = 19; n = 35) were most prevalent, followed by journals \n(x = 10; n  = 35) and DelstarDB databases (x  = 2; n  = 35). \nFour citations (n = 35) lacked traceability due to inaccura-\ncies, paywalls, or missing publication links.\nWebsite and journal citation analysis\nWebsite quality was assessed using criteria including author-\nship, review process, publication date, and update status. \nWebsite citations (n = 19) frequently lacked complete attri-\nbution, with only 79.0% (n = 19) mentioning an author or \nreview process. Publication or update dates were present in \n79.0% (n = 19) of cases, while source transparency (citations \nor links) was observed in 68.4% (n = 19), suggesting that \nDELSTAR occasionally cites websites with potentially low \nscientific rigour. Journal citations (n = 10) assessed using \nScopus CiteScore metrics revealed an average CiteScore of \n6.21, with 4 journals in Q1 (≥ 75th percentile) and 5 in Q2 \n(50–74th percentile). Source Normalized Impact per Paper \nranged from 0.46 to 1.868, indicating a mix of above-aver -\nage and below-average citation impact. While DELSTAR \ndemonstrates the capacity to cite high-quality journals, this \noccurs infrequently.\nPerformance testing\nA series of 5 performance tests for each DELSTAR-founda-\ntion model combination and dataset were performed (refer \nto Fig. 1).\nOverview performance D2 and D3\nThe results showed that notably more negative predictions \nfor all chatbot combinations were made within the binary \ndataset. Considering the averaged confusion matrix of Mix-\ntral8 × 7b D3, 247.2 out of 286 cases were answered with \n“no” (Fig.  2). Moreover, the models yielding the highest \nnumber of “yes” responses (GPT3.5 and Llama3-70b; D3) \nonly identified 30.4% (n = 286) of all data points as “yes”, \ndespite the dataset being binary. In Llama3-70b, half of the \nTable 3  Categorisation of Responses Obtained During the DEL -\nSTAR V3 Quality Test Concerning Their Statement Quality: \nTwo independent experts conducted a comparative analysis of the \nresponses in the categories of side effects, interactions, therapeu-\ntic alternatives, and overall content, using the Master Dataset as the \nbenchmark\nThe responses were classified according to their quality in A–E. The \ncriteria used by the independent experts were guided by their profes-\nsional competencies as qualified pharmacists\nData key: A = General information both in the dataset and chatbot; \nB = Additional information to the dataset; C = less specific than the \ninformation contained in the datatset; D = more specific than the \ninformation contained in the datatset; E = information received by the \nchatbot contains errors\nRunID Drug name Side effect Interac-\ntions\nTherapeuti-\ncal alterna-\ntives\nOverall \ncontent\n22 Fentanyl A B C A\n23 Risperi-\ndone\nB B D D\n24 Solifenacin D D D D\n26 Oxycodone B B D D\n27 Dexameth-\nasone\nD D A D\n30 Quetiapine C A D A\n31 Solifenacin A C B A\n32 Haloperi-\ndol\nC C D C\n33 Trospium A D D D\n34 Diazepam A A D D\n35 Benztro-\npine\nD D B D\n36 Ropinirole D D D D\n37 Hydrox-\nyzine\nB D D D\n39 Oxybutynin D D E D\n43 Quetiapine B D D D\n45 Midazolam D D D D\n46 Morphine D C B B\n48 Prednisone D A D D\n51 Tapentadol D D D D\n53 Lorazepam D D D D\n1058 International Journal of Clinical Pharmacy (2025) 47:1053–1063\npositive identified results were misclassified as FP. This indi-\ncates that the chatbots tended to categorise a more signifi-\ncant number of medications as not associated with delirium \nrather than associated with delirium.\nPerformance stability\nAll the chatbots exhibited varying degrees of performance \nmetrics deviation in the evaluation. Notably, GPT3.5 dem-\nonstrated the least fluctuations across most of the evaluated \nmetrics within both datasets (D2, D3), indicating a high level \nof consistency. Therefore, GPT-3.5 might be the most sta-\nble model for categorising medications. Mistral revealed the \nhighest deviations in AUC values, suggesting inconsistent \nidentification of relevant medications. Similarly, Llama3-8b \nexhibited substantial fluctuations, especially in D3, with a \nmaximal deviation of 8.2% (n = 5) in the F1-Score. These \nsubstantial disparities in performance metrics suggest that \nMistral and Llama3-8b may be less dependable for consist-\nent results, highlighting the superior stability of the frontier \nor closed models (GPT3.5; GPT4o) by comparison. Exam-\nining the open model reveals that Llama3-70b exhibits the \nmost stable performance for D2, while Mistral8 × 7b demon-\nstrates the most stable performance for Dataset 3.\nPerformance comparison\nUpon reviewing the test results presented in Fig.  3, it was \napparent that for D2 Llama3-70b (0.531) and GPT4o (0.524) \nand for D3 GPT4o (0.524) and GPT3.5 (0.568) exhibited \nthe highest sensitivity/recall values indicating that these \nsystems are most favourable in identifying drugs associ-\nated with delirium since the least positive instances are \nmissed. Moreover, it revealed precision values ranging \nfrom 0.997 to 0.697, with 4 out of 6 combinations exceed-\ning the desired threshold of 0.8 in both datasets (GPT4o, \nMixtral8-7b, GPT3.5, LLama3-70b). The F1-Score, indicat-\ning the equilibrium between precision and recall, identified \nGPT4o (0.687) and Llama3-70b (0.655) as the most effec-\ntive for D2 and GPT3.5 (0.708) and GPT4o (0,665) for D3, \ntherefore demonstrating the most optimal performance [40]. \nAn examination of the specificity, defined as the ability of \nthe model to identify negative instances correctly, revealed \nthat all chatbot combinations fall within the desired range \n(0.8–1.0) [41]. Consequently, the models exhibited varying \ndegrees of capability in correctly recognising non-delirium-\nassociated drugs, with probabilities ranging from 99.0% \n(n = 143) (GPT4o D2) to 82.1% (n = 143) (Llama3-8b D2). \nIn summary, the assessment of chatbot combinations for \nidentifying delirium-associated drugs identified GPT-4o and \ngpt3.5\nPredicted\nPP PN\nActual P 81.2 61.8\nN 5.2 137.8\nmistral-7b\nPredicted\nPP PN\nActual P 65.6 77.4\nN 14.4 128.6\nllama3-8b\nPredicted\nPP PN\nActual P 65.4 77.6\nN 21.6 121.4\ngpt4o\nPredicted\nPP PN\nActual P 75 68\nN 7.4 135.6\nmixtral 8x7b\nPredicted\nPP PN\nActual P 36.8 106.2\nN 2 141\nllama3-70b\nPredicted\nPP PN\nActual P 69.6 73.4 \nN 7 136\nFig. 2  Comparison of mean DELSTAR confusion matrix test results \nacross different platforms (GPT4o, GPT3.5, Mistral-7b, Mixtral \n8×7b, Llama3-7b und Llama3-70b) for Dataset 2/3: Intersection of \nPredicted (predicted positives (PP), predicted negatives (PN)) and \nActual Outcomes (positives (P), negatives (N))\n1059International Journal of Clinical Pharmacy (2025) 47:1053–1063 \nLlama3-70b as the top performers within D2 and GPT3.5 \nand GPT4o within D3. Despite achieving commendable \nprecision values, none of the models met the desired per -\nformance threshold of 0.8–1.0 across all metrics.\nDiscussion\nDELSTAR has demonstrated the ability to provide accurate \nand comprehensive information, as indicated in prior studies \n[42]. This feature could be helpful in identifying complex \ndiseases like delirium [43]. By utilising interdisciplinary \napproaches and expert evaluations, it became evident that \nDELSTAR can obtain more accurate information than tradi-\ntional systematic literature searches. Given that DELSTAR \nsemantic searching involves deeper connections between \nconcepts then simple keyword matching alone, search per -\nformance can be augmented to include additional findings \n[e.g. traditional systematic literature search: Polypharmacy \nAND (Delirium AND medication) NOT dementia vs. Aug-\nmented literature search using DELSTAR populated with \nkey papers and API connections: [1] RESEARCHER: Using \nevidence supplied, provide 5 nodes of most likely medica-\ntions suspected of causing delirium inc. evidence from API \nsearch—[DELSTAR OUTPUT] [2]; RESEARCHER: Node \nX selected. Please elaborate -[DELSTAR OUTPUT]; [3 ] \nRESEARCHER: Provide 5 nodes of possible mechanisms \nof action inc. evidence from API search -[DELSTAR OUT-\nPUT]; [4] RESEARCHER: Node Y selected. Please elabo-\nrate -[DELSTAR OUTPUT];[5 ] RESEARCHER: Provide \n5 nodes of possible mechanisms that also cause signs of \ndementia inc. evidence from API search/ etc.]\nThe results indicate that customised LLMs have the \npotential to assist clinical pharmacists in synthesising sci-\nentific data from the literature, thereby enhancing access to \nhigh-quality resources [27]. Since clinical decision support \nsystems can reduce medication errors, further refinements \nand research on DM seem promising [43, 44]. However, \nthe accuracy of the systems largely depends on the quality \nof training data, and errors like hallucinations illustrate \nthe importance of oversight by clinical pharmacists when \nusing pharmaceutical/medical AI models [27]. While \nLLMs like DELSTAR can potentially enhance healthcare, \nmisinformation poses significant risks to patient safety, \nparticularly in drug safety, where incorrect information \ncould lead to harm [45, 46]. In clinical pharmacy, rely -\ning on high-quality and credible sources is essential to \nensure the safety of the medication process [27, 47]. The \nperformed audit of the cited scientific sources regarding \ncomprehensiveness and information quality revealed cita-\ntion frequency and quality variations. Therefore, improv -\ning citation frequency and quality is necessary to demon-\nstrate these associations effectively [48]. To enhance data \nquality, we implemented private databases (Delstar_DB1 \nand DB2). However, similar to OpenAI models, the data \nwas not updated in real time [49]. We integrated APIs \nlike semanticscholar.org to assess the latest research find-\nings. Due to OpenAI’s confidentiality restrictions, this was \nonly partially successful [12]. Consequently, a constantly \nupdated offline model should be preferred for clinical phar-\nmacy applications to reduce security concerns and ensure \nFig. 3  Average performance metrics results for the DELSTAR foundation model combinations using dataset 2 (D2) and dataset 3 (D3): displays \nthe results of the calculations of the performance metrics averaged from the test runs performed\n1060 International Journal of Clinical Pharmacy (2025) 47:1053–1063\nhigh-quality data [ 27]. Llama3-70b, capable of processing \nmetadata-rich PDFs, may provide better performance in \nhandling large-quality datasets offline [50]. Additionally, \na tool like Searxng could help integrate scientific metadata \ninto queries for local database searches, making it a valu-\nable add-on for applications in clinical pharmacy [ 51]. \nThe evolution of LLM reasoning topologies continues. A \n‘Graph of thoughts’ (GoT) method has since evolved from \nToT whereby feedback loops applied to prior nodes are \nrefined into new nodes[52]. The authors note the benefits \nof this extension and plan to include this feature in further \niterations of DELSTAR.\nPerformance stability is critical in medical and pharma-\nceutical applications to ensure consistent outputs. DEL -\nSTAR’s performance tests showed that larger models, such \nas GPT3.5 and Llama3-70b, exhibited the highest strength. \nIn contrast, models with fewer parameters displayed more \nvariability, particularly when processing datasets contain-\ning fictional drug names [49, 53]. As clinical workloads \nincrease the likelihood of errors, more robust systems are \nneeded to minimise the errors resulting from system insta-\nbility [44]. The comparison of the performance parameters \nrevealed a tendency to classify more medications as non-\ndelirium-associated, which was reflected in low recall/sen-\nsitivity values. Given the health risks of missed instances, \nit is crucial to increase recall, for example, through inter -\nnal classification benchmarks [54, 55]. In performance \nstudies, other medical AI models have demonstrated sig-\nnificantly higher recall/sensitivity values, ranging from \n0.800 to 0.997 [13]. It is important to note that precision \nand recall are interdependent; adjusting the classification \nthreshold to increase recall may lead to a marked reduction \nin system precision. Therefore, ensemble methods—such \nas bagging, boosting, or stacking—could simultaneously \nenhance parameters and overall model performance [55]. \nRegarding performance metrics, GPT4o excelled in D2 \n(F1-Score: 0.687), while GPT3.5 led in D3 (F1-Score: \n0.708). However, none of the models achieved the ideal \nthreshold of 0.8, highlighting the need for fine-tuning. For \noffline use, Llama3-70b’s stability and performance make \nit the preferred model for clinical pharmacy applications in \nour test. Further development is needed prior to carrying \nout feasibility testing in the clinical setting. In addition, \nthe ethical implications of using AI models like DELSTAR \nin clinical practice must be explored. While the model’s \ntraining data is not based on individual patient information \nit’s use in supporting patient medication therapy decisions \nin clinical practice needs detailed consideration. The EU \nAI Act and the AI Liability Directive were released in \nAugust 2024 and will guide the discussion [56, 57].\nStrengths and limitations\nThis simplified ToT design allows researchers to efficiently \nexplore semantic information while controlling various \nvariables, leading to advancements in AI-assisted clini-\ncal tools. DELSTAR significantly reduces the time needed \nfor manual literature searches by providing rapid access to \nsynthesised data on medications and complex diseases like \ndelirium. While no comprehensive evaluation methods exist \nfor LLM in clinical pharmacy, DELSTAR emphasises the \nneed for such frameworks to improve evaluation practices for \ndomain-specific LLM. However, this study has several meth-\nodological limitations. It was designed to illustrate system \nstrengths and weaknesses rather than provide full validation \nthrough real-world use cases. The testing employed small, \nbalanced datasets (< 300 cases), which may not accurately \nrepresent real-world scenarios where data balance varies. \nAdditionally, sequential testing and continuous system \ndevelopment, including different OpenAI models, impacted \nthe analyses. None of the systems fully reflects the latest \nresearch developments, as private databases need regular \nupdates, and specific data cutoff dates constrain OpenAI’s \nGPT models.\nFurther research\nTo optimise DELSTAR for clinical pharmacy practice, \naddressing its identified weaknesses and incorporating \nhigh-quality, evidence-based data in a secure, offline envi-\nronment is essential. This approach will ensure the genera-\ntion of accurate and reliable information, which is critical \nfor safe medication management. Comprehensive testing in \nreal-world clinical scenarios should be performed, allowing \ntargeted refinements. Furthermore, a thorough review of the \nlegal and regulatory framework for evaluating and approving \nAI tools in clinical pharmacy is necessary to guarantee their \nsafety, reliability, and alignment with professional standards.\nConclusion\nThis interdisciplinary evaluation offers valuable insights \ninto the performance and quality of DELSTAR, a chatbot \nsystem designed to enhance medication safety in delirium. \nIt demonstrated strengths in retrieving information on \nmedication-associated delirium, showcasing its potential \nas a valuable resource for identifying and managing high-\nrisk conditions. However, the evaluation also identified \nareas for improvement, particularly in ensuring the use of \nhigh-quality sources and enhancing performance metrics. \nWith the rapid advancement of AI technologies, clini-\ncal pharmacists are encountering new opportunities and \nresponsibilities. One key responsibility involves evaluating \n1061International Journal of Clinical Pharmacy (2025) 47:1053–1063 \nand monitoring AI models to identify hallucinations, pre-\nvent errors, and ensure patient safety. By addressing these \nchallenges, tools like DELSTAR can be valuable in opti-\nmising the efficiency of clinical workflows and support \nevidence-based decision-making in clinical pharmacy \npractice. Further development and feasibility testing using \nreal-world clinical data is needed.\nSupplementary Information The online version contains supplemen-\ntary material available at https:// doi. org/ 10. 1007/ s11096- 025- 01900-8.\nAcknowledgements Special thanks to Mag. Danielle Hochhold (MSc); \nMag. Jasmin Stoll and Dr. Ivana Tadić for help with the independent \nanalysis.\nFunding Open access funding provided by University of Innsbruck \nand Medical University of Innsbruck. The study was funded by the \nUniversity of Innsbruck.\nConflicts of interest Anita E. Weidmann is an Associate Editor of the \nInternational Journal of Clinical Pharmacy. She had no role in han-\ndling the manuscript, specifically the processes of editorial review, \npeer review and decision-making. Katharina Spagl, Adam Jatowt and \nEdward W. Watson declare that they have no potential conflict of inter-\nest that might be relevant to the content of this manuscript.\nOpen Access This article is licensed under a Creative Commons Attri-\nbution 4.0 International License, which permits use, sharing, adapta-\ntion, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, \nprovide a link to the Creative Commons licence, and indicate if changes \nwere made. The images or other third party material in this article are \nincluded in the article’s Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in \nthe article’s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a \ncopy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\nReferences\n 1. Kassie GM, Kalisch Ellett LM, Nguyen TA, et al. Current practice \nand opinions of hospital pharmacists regarding their role in the \nscreening, prevention and treatment of delirium. Int J Clin Pharm. \n2017;39:1194–200. https:// doi. org/ 10. 1007/ s11096- 017- 0547-y.\n 2. Cerejeira J, Mukaetova-Ladinska EB. A clinical update on delir -\nium: from early recognition to effective management. Nurs Res \nPract. 2011;2011: 875196. https:// doi. org/ 10. 1155/ 2011/ 875196.\n 3. Raso J, Santos LMC, Reis DA, et al. Hospitalizations of older \npeople in an emergency department related to potential med-\nication-induced hyperactive delirium: a cross-sectional study. \nInt J Clin Pharm. 2022;44:548–56. https:// doi. org/ 10. 1007/  \ns11096- 022- 01378-8.\n 4. Lauretani F, Bellelli G, Pelà G, et al. Treatment of delirium in \nolder persons: what we should not do! Int J Mol Sci. 2020. https:// \ndoi. org/ 10. 3390/ ijms2 10723 97.\n 5. Goldberg TE, Chen C, Wang Y, et al. Association of delirium \nwith long-term cognitive decline: a meta-analysis. JAMA Neurol. \n2020;77:1373–81. https:// doi. org/ 10. 1001/ jaman eurol. 2020. 2273.\n 6. Burry L, Hutton B, Williamson DR, et al. Pharmacological \ninterventions for the treatment of delirium in critically ill adults. \nCochrane Database Syst Rev. 2019;9:CD011749. https:// doi. org/ \n10. 1002/ 14651 858. CD011 749. pub2.\n 7. Amgarth-Duff I, Hosie A, Caplan GA, et al. Delirium researchers’ \nperspectives of the challenges in delirium biomarker research: a \nqualitative study. PLoS ONE. 2021;16: e0243254. https:// doi. org/ \n10. 1371/ journ al. pone. 02432 54.\n 8. Schulthess-Lisibach AE, Gallucci G, Benelli V, et al. Predict-\ning delirium in older non-intensive care unit inpatients: devel-\nopment and validation of the DELIrium risK Tool (DELIKT). \nInt J Clin Pharm. 2023;45:1118–27. https:// doi. org/ 10. 1007/  \ns11096- 023- 01566-0.\n 9. Efraim NT, Zikrin E, Shacham D, et al. Delirium in internal \nmedicine departments in a tertiary hospital in israel: occurrence, \ndetection rates, risk factors, and outcomes. Front Med (Lausanne). \n2020;7: 581069. https:// doi. org/ 10. 3389/ fmed. 2020. 581069.\n 10. Liu SB, Wu HY, Duan ML, et al. Delirium in the ICU: how much \ndo we know? A narrative review Ann Med. 2024;56:2405072. \nhttps:// doi. org/ 10. 1080/ 07853 890. 2024. 24050 72.\n 11. Bitkina OV, Park J, Kim HK. Application of artificial intel-\nligence in medical technologies: a systematic review of main \ntrends. Digit Health. 2023;9:20552076231189332. https:// doi.  \norg/ 10. 1177/ 20552 07623 11893 31.\n 12. Thirunavukarasu AJ, Ting DSJ, Elangovan K, et al. Large lan-\nguage models in medicine. Nat Med. 2023;29:1930–40. https://  \ndoi. org/ 10. 1038/ s41591- 023- 02448-8.\n 13. Hicks SA, Strümke I, Thambawita V, et al. On evaluation met-\nrics for medical applications of artificial intelligence. Sci Rep. \n2022;12:5979. https:// doi. org/ 10. 1038/ s41598- 022- 09954-8.\n 14. Bonfichi A, Ceresa IF, Piccioni A, et al. A lethal combination \nof delirium and overcrowding in the emergency department. J \nClin Med. 2023. https:// doi. org/ 10. 3390/ jcm12 206587.\n 15. National Institute for Health and Clinical Excellence (NICE). \nRecommendations | Delirium: prevention, diagnosis and man-\nagement in hospital and long-term care | Guidance | NICE. \n18.01.2023. https:// www. nice. org. uk/ guida nce/ cg103/ chapt er/ \nRecom menda tions. Accessed 17 Dec 2024.\n 16. Australian Commission on Safety and Quality in Health Care. \nDelirium Clinical Care Standard (2021 Revision). Sydney: Aus-\ntralian Commission on Safety & Quality in Health Care; Dec \n2021.\n 17. Weidmann AE, Jónsdóttir F, Gunnarsson PS. Medication-\ninduced causes of delirium in patients with and without demen-\ntia: a systematic review of published neurology guidelines. Int J \nClin Pharm. 2025. https:// doi. org/ 10. 1007/ s11096- 024- 01861-4.\n 18. Weidmann AE, Jónsdóttir F, Gunnarsson PS. Medication-\ninduced Delirium in Dementia patients: A systematic review. \n2022. https:// www. crd. york. ac. uk/ prosp ero/ displ ay_ record. php? \nID= CRD42 02236 6020. Accessed 17 Dec 2024.\n 19. Weidmann AE, Tadic I. Psychiatry Guidelines on how to pre-\nvent medication induced Delirium in patients with and without \ndementia: A systematic review. 2024. https:// www. crd. york. ac. \nuk/ prosp ero/ displ ay_ record.  php? Recor dID= 422990. Accessed \n17 Dec 2024.\n 20. Weidmann AE, Jónsdóttir F, Gunnarsson PS. Guidelines on how \nto prevent and manage peri-operative medication induced Delir -\nium: A systematic review. 2023. https:// www. crd. york. ac. uk/  \nprosp ero/ displ ay_ record. php? ID= CRD42 02344 2726. Accessed \n17 Dec 2024.\n 21. Aslam A, Weidmann AE, Tadic I, et al. Medication associated \nwith delirium superimposed on dementia (DSD): a systematic \nreview. 2024. https:// www. crd. york. ac. uk/ prosp ero/ displ ay_ \nrecord. php? Recor dID= 546118. Accessed 17 Dec 2024.\n 22. Weidmann AE, Jónsdóttir F, Óskarsdóttir Þ. Medication induced \ndelirium in children: A Systematic Review. 2024. https:// www.  \ncrd. york. ac. uk/ prosp ero/ displ ay_ record. php? ID= CRD42 02459 \n8459. Accessed 17 Dec 2024.\n1062 International Journal of Clinical Pharmacy (2025) 47:1053–1063\n 23. Weidmann AE, Jónsdóttir F, Ágústsdóttir I. The gut microbiota \nin medication related delirium: A systematic review. 2024. \nhttps:// www. crd. york. ac. uk/ prosp ero/ displ ay_ record. php? ID= \nCRD42 02460 1841. Accessed 17 Dec 2024.\n 24. Weidmann AE, Jónsdóttir F, Gunnarsson PS. Peri-operative \nMedication induced Delirium: A systematic review. 2023. \nhttps:// www. crd. york. ac. uk/ prosp ero/ displ ay_ record. php? ID= \nCRD42 02344 2708. Accessed 18 Dec 2024.\n 25. Weidmann AE, Watson EW. Novel opportunities for clinical \npharmacy research: development of a machine learning model \nto identify medication related causes of delirium in different \npatient groups. Int J Clin Pharm. 2024;46:992–5. https:// doi.  \norg/ 10. 1007/ s11096- 024- 01707-z.\n 26. Grzybowski A, Pawlikowska-Łagód K, Lambert WC. A history \nof artificial intelligence. Clin Dermatol. 2024;42:221–9. https://  \ndoi. org/ 10. 1016/j. clind ermat ol. 2023. 12. 016.\n 27. Clusmann J, Kolbinger FR, Muti HS, et al. The future land-\nscape of large language models in medicine. Commun Med. \n2023;3:141. https:// doi. org/ 10. 1038/ s43856- 023- 00370-1.\n 28. Schnabel T, Labutov I, Mimno D, et al. Evaluation methods for \nunsupervised word embeddings. In: Màrquez L, Callison-Burch \nC, Su J, editors. Proceedings of the 2015 Conference on Empiri-\ncal Methods in Natural Language Processing; Lisbon, Portugal: \nAssociation for Computational Linguistics; 2015. p. 298–307. \nhttps:// doi. org/ 10. 18653/ v1/ D15- 1036.\n 29. Morris J, Lifland E, Yoo JY, et al. TextAttack: A Framework \nfor Adversarial Attacks, Data Augmentation, and Adversarial \nTraining in NLP. In: Liu Q, Schlangen D, editors. Proceedings \nof the 2020 Conference on Empirical Methods in Natural Lan-\nguage Processing: System Demonstrations; Online: Association \nfor Computational Linguistics; 2020. p. 119–126. https:// doi.  \norg/ 10. 18653/ v1/ 2020. emnlp- demos. 16.\n 30. Wang B, Chen W, Pei H, et al. DecodingTrust: A Comprehen-\nsive Assessment of Trustworthiness in GPT Models. 2023. \nhttps:// doi. org/ 10. 48550/ arXiv. 2306. 11698.\n 31. ÖAWI. Guidelines | ÖAWI. 2023. https:// oeawi. at/ en/ guide \nlines/. Accessed 23 Dec 2024.\n 32. Wissenschaftliches Institut der AOK. Anatomisch-thera -\npeutisch-chemische Klassifikation mit Tagesdosen: Amtliche \nFassung des ACT-Index mit DDD-Angaben für Deutschland \nim Jahr 2023. 2023. https:// www. bfarm. de/ DE/ Kodie rsyst eme/ \nKlass ifika tionen/ ATC/_ node. html. Accessed 23 Dec 2024.\n 33. Madotto A, Lin Z, Winata GI, et al. Few-Shot Bot: Prompt-\nBased Learning for Dialogue Systems. 2021. https:// doi. org/  \n10. 48550/ arXiv. 2110. 08118\n 34. Long J. Large Language Model Guided Tree-of-Thought. 2023. \nhttps:// arxiv. org/ abs/ 2305. 08291. Accessed 23 Dec 2024.\n 35. Yao S, Yu D, Zhao J, et al. Tree of Thoughts: Deliberate Prob-\nlem Solving with Large Language Models. 2023. http:// arxiv.  \norg/ pdf/ 2305. 10601.\n 36. Srinivasan R, Inakoshi H, Uchino K. Leveraging Cognitive Sci-\nence for Testing Large Language Models. In: 2023 IEEE Inter -\nnational Conference On Artificial Intelligence Testing (AITest); \nAthens, Greece: IEEE; 2023. p. 169–171. https://  doi. org/ 10. \n1109/ AITes t58265. 2023. 00035\n 37. Susmaga R. Confusion Matrix Visualization. Intelligent Infor -\nmation Processing and Web Mining. 2004:107–16. https:// doi.  \norg/ 10. 1007/ 978-3- 540- 39985-8_ 12.\n 38. Gilbraith WE, Celani CP, Booksh KS. Visualization of confu-\nsion matrices with network graphs. J Chemom. 2023. https://  \ndoi. org/ 10. 1002/ cem. 3435.\n 39. Carrington AM, Manuel DG, Fieguth PW, et al. Deep ROC \nanalysis and AUC as balanced average accuracy, for improved \nclassifier selection, audit and explanation. IEEE Trans Pattern \nAnal Mach Intell. 2023;45:329–41. https:// doi.  org/ 10. 1109/  \nTPAMI. 2022. 31453 92.\n 40. Anđelić N, Baressi Šegota S, Car Z. Improvement of malicious \nsoftware detection accuracy through genetic programming sym-\nbolic classifier with application of dataset oversampling tech -\nniques. Computers. 2023;12:242. https:// doi. org/ 10. 3390/ compu \nters1 21202 42.\n 41. Charizanos G, Demirhan H, İçen D. Binary classification with \nfuzzy logistic regression under class imbalance and com-\nplete separation in clinical studies. BMC Med Res Methodol. \n2024;24:145. https:// doi. org/ 10. 1186/ s12874- 024- 02270-x.\n 42. Ahmadi A. ChatGPT: exploring the threats and opportuni-\nties of artificial intelligence in the age of chatbots. AJCST. \n2023;12:25–30. https:// doi. org/ 10. 51983/ ajcst- 2023. 12.1. 3567.\n 43. Younis HA, Eisa TAE, Nasser M, et al. A systematic review \nand meta-analysis of artificial intelligence tools in medicine and \nhealthcare: applications, considerations, limitations, Motivation \nand Challenges. Diagnostics (Basel). 2024. https:// doi. org/ 10. \n3390/ diagn ostic s1401 0109.\n 44. Tariq RA, Vashisht R, Sinha A, et al. StatPearls: Medication \nDispensing Errors and Prevention. 2024. https:// www. ncbi. nlm. \nnih. gov/ books/ NBK51 9065/. Accessed 23 Dec 2024.\n 45. Han T, Kumar A, Agarwal C, et al. MedSafetyBench: Evaluating \nand Improving the Medical Safety of Large Language Models. \n2024. https:// doi. org/ 10. 48550/ arXiv. 2403. 03744.\n 46. Hakim JB, Painter JL, Ramcharran D, et al. The Need for Guard-\nrails with Large Language Models in Medical Safety-Critical \nSettings: An Artificial Intelligence Application in the Pharma-\ncovigilance Ecosystem: arXiv; 2024 [preprint]. https:// arxiv. org/ \nabs/ 2407. 18322. Accessed 23 Dec 2024.\n 47. Andrikyan W, Sametinger SM, Kosfeld F, et al. Artificial \nintelligence-powered chatbots in search engines: a cross-\nsectional study on the quality and risks of drug information \nfor patients. BMJ Qual Saf. 2024. https:// doi. org/ 10. 1136/ \nbmjqs- 2024- 017476.\n 48. Wu K, Wu E, Cassasola A et al. How well do LLMs cite relevant \nmedical references? An evaluation framework and analyses. \n2024 [preprint]. http:// arxiv. org/ pdf/ 2402. 02008. Accessed 23 \nDec 2024.\n 49. OpenAI Platform. Models. 2024. https:// platf  orm. openai. com/ \ndocs/ models. Accessed 29 Jul 2024.\n 50. The Apache Software Foundation. Apache Tika – a content \nanalysis toolkit. 2024. https:// tika. apache. org/. Accessed 25 \nAug 2024.\n 51. SearXNG team. Welcome to SearXNG — SearXNG Documen -\ntation. 2024. https:// docs. searx ng. org/. Accessed 25 Aug 2024.\n 52. Besta M, Blach N, Kubicek A, Gerstenberger R, Podstawski M, \nGianinazzi L, Gajda J, Lehmann T, Niewiadomski H, Nyczyk \nP, Hoefler T. Graph of thoughts: solving elaborate problems \nwith large language models. Proc AAAI Conf Artif Intell. \n2024;38(16):17682–90. https:// doi. org/ 10. 1609/ aaai. v38i16. \n29720.\n 53. AI at Meta. Llama 3 Model Card. 2024. https:// github. com/  \nmeta- llama/  llama3/  blob/ main/ MODEL_  CARD. md. Accessed \n29 Jul 2024.\n 54. Iglseder B, Frühwald T, Jagsch C. Delir bei geriatrischen \nPatienten. [Delirium in geriatric patients]. Wien Med Wochen-\nschrift. 1946;2022(172):114–21. https:// doi. org/ 10. 1007/  \ns10354- 021- 00904-z.\n 55. Stephen M. Walker. Precision vs Recall — Klu. 2024. https://  \nklu. ai/ gloss ary/ class ifica tion- preci sion- vs- recall. Accessed 28 \nJul 2024.\n 56. European Parliament. Legislative Observatory. European Par -\nliament legislative resolution on the proposal for a regulation \nof the European Parliament and of the Council on laying down \n1063International Journal of Clinical Pharmacy (2025) 47:1053–1063 \nharmonised rules on Artificial Intelligence (Artificial Intelli-\ngence Act) and amending certain Union Legislative Acts. 2024. \nhttps:// oeil. secure. europ arl. europa. eu/ oeil/ en/ proce dure- file? \nrefer ence= 2021/ 0106(COD). Accessed 28 Feb 2025.\n 57. European Parliament. Legislative Observatory. Directive of the \nEuropean Parliament and of the Council on adapting non-con-\ntractual civil liability rules to artificial intelligence (AI Liability \nDirective). 2024. https:// oeil. secure. europ arl. europa. eu/ oeil/ en/ \nproce dure- file? refer ence= 2022/ 0303(COD). Accessed 28 Feb \n2025\nPublisher's Note Springer Nature remains neutral with regard to \njurisdictional claims in published maps and institutional affiliations.",
  "topic": "Quality Score",
  "concepts": [
    {
      "name": "Quality Score",
      "score": 0.7025501728057861
    },
    {
      "name": "Medicine",
      "score": 0.6534876227378845
    },
    {
      "name": "Delirium",
      "score": 0.6036487221717834
    },
    {
      "name": "Credibility",
      "score": 0.5524090528488159
    },
    {
      "name": "Usability",
      "score": 0.47308140993118286
    },
    {
      "name": "Pharmacy",
      "score": 0.47161275148391724
    },
    {
      "name": "Medical physics",
      "score": 0.3809645175933838
    },
    {
      "name": "Computer science",
      "score": 0.3771127164363861
    },
    {
      "name": "Machine learning",
      "score": 0.3707636594772339
    },
    {
      "name": "Artificial intelligence",
      "score": 0.33299994468688965
    },
    {
      "name": "Intensive care medicine",
      "score": 0.1304994523525238
    },
    {
      "name": "Family medicine",
      "score": 0.10287275910377502
    },
    {
      "name": "Operations management",
      "score": 0.08783307671546936
    },
    {
      "name": "Metric (unit)",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Human–computer interaction",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I190249584",
      "name": "Universität Innsbruck",
      "country": "AT"
    }
  ]
}