{
  "title": "ParroT: Translating during Chat using Large Language Models tuned with Human Translation and Feedback",
  "url": "https://openalex.org/W4389524077",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2167599192",
      "name": "Wenxiang Jiao",
      "affiliations": [
        "Tencent (China)"
      ]
    },
    {
      "id": "https://openalex.org/A4313987131",
      "name": "Jen-tse Huang",
      "affiliations": [
        "Tencent (China)",
        "Chinese University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A2142863397",
      "name": "Wenxuan Wang",
      "affiliations": [
        "Tencent (China)",
        "Chinese University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A1996407929",
      "name": "Zhiwei He",
      "affiliations": [
        "Shanghai Jiao Tong University",
        "Tencent (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2082486965",
      "name": "Tian Liang",
      "affiliations": [
        "Tencent (China)",
        "Tsinghua–Berkeley Shenzhen Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2106523734",
      "name": "Xing Wang",
      "affiliations": [
        "Tencent (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2105557964",
      "name": "Shuming Shi",
      "affiliations": [
        "Tencent (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2126985900",
      "name": "Zhaopeng Tu",
      "affiliations": [
        "Tencent (China)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4320854854",
    "https://openalex.org/W4367000491",
    "https://openalex.org/W4361019538",
    "https://openalex.org/W4317547647",
    "https://openalex.org/W4320167623",
    "https://openalex.org/W4375957915",
    "https://openalex.org/W4385572225",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4319453300",
    "https://openalex.org/W2963532001",
    "https://openalex.org/W4378945542",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W4286987939",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4385567085",
    "https://openalex.org/W3159892921",
    "https://openalex.org/W4321177597",
    "https://openalex.org/W2514996388",
    "https://openalex.org/W4385567149",
    "https://openalex.org/W4385565879",
    "https://openalex.org/W4311642023",
    "https://openalex.org/W4321276803",
    "https://openalex.org/W4319793302",
    "https://openalex.org/W3168867926",
    "https://openalex.org/W3105214104",
    "https://openalex.org/W4318903120",
    "https://openalex.org/W3196731672",
    "https://openalex.org/W3102516861",
    "https://openalex.org/W2512924740",
    "https://openalex.org/W4385573155",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W2550821151",
    "https://openalex.org/W4320198919",
    "https://openalex.org/W2130942839"
  ],
  "abstract": "Large language models (LLMs) like ChatGPT have exhibited remarkable abilities on a wide range of natural language processing (NLP) tasks, including various machine translation abilities accomplished during chat. However, these models are only accessible through restricted APIs, which creates barriers to new research and advancements in the field. Therefore, we propose ParroT, a framework to enhance and regulate the translation abilities during chat based on open-source LLMs (e.g., LLaMA), human-written translation and feedback data. Specifically, ParroT reformulates translation data into the instruction-following style, and introduces a \"Hint\" field for incorporating extra requirements to regulate the translation process. Accordingly, we propose three instruction types for finetuning ParroT models, including translation instruction, contrastive instruction, and error-guided instruction. Experiments on Flores subsets and WMT22 test sets suggest that translation instruction improves the translation performance of vanilla LLMs significantly while error-guided instruction can lead to further improvement, which demonstrates the importance of learning from low-quality translations annotated by humans. We also demonstrate the potential of automatic evaluation tools in providing quality information of translations, when constructing error-guided instructions for directions that lack human annotation data. Please refer to our Github project for more implementation details: https://github.com/wxjiao/ParroT.",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 15009–15020\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nParroT: Translating during Chat using Large Language Models tuned with\nHuman Translation and Feedback\nWenxiang Jiao1∗ Jen-tse Huang1,2 Wenxuan Wang1,2 Zhiwei He1,3 Tian Liang1,4\nXing Wang1 Shuming Shi1 Zhaopeng Tu1\n1Tencent AI Lab 2The Chinese University of Hong Kong\n3Shanghai Jiao Tong University 4Tsinghua Shenzhen International Graduate School\n{joelwxjiao,brightxwang,shumingshi,zptu}@tencent.com\n{jthuang,wxwang}@cse.cuhk.edu.hk\nzwhe.cs@sjtu.edu.cn liangt21@mails.tsinghua.edu.cn\nAbstract\nLarge language models (LLMs) like ChatGPT\nhave exhibited remarkable abilities on a wide\nrange of natural language processing (NLP)\ntasks, including various machine translation\nabilities accomplished during chat. However,\nthese models are only accessible through re-\nstricted APIs, which creates barriers to new\nresearch and advancements in the field. There-\nfore, we propose ParroT, a framework to en-\nhance and regulate the translation abilities dur-\ning chat based on open-source LLMs (e.g.,\nLLaMA), human-written translation and feed-\nback data. Specifically, ParroT reformulates\ntranslation data into the instruction-following\nstyle, and introduces a “Hint” field for incorpo-\nrating extra requirements to regulate the trans-\nlation process. Accordingly, we propose three\ninstruction types for finetuning ParroT models,\nincluding translation instruction, contrastive in-\nstruction, and error-guided instruction. Experi-\nments on Flores subsets and WMT22 test sets\nsuggest that translation instruction improves\nthe translation performance of vanilla LLMs\nsignificantly while error-guided instruction can\nlead to further improvement, which demon-\nstrates the importance of learning from low-\nquality translations annotated by humans. We\nalso demonstrate the potential of automatic\nevaluation tools in providing quality informa-\ntion of translations, when constructing error-\nguided instructions for directions that lack\nhuman annotation data. Please refer to our\nGithub project for more implementation details:\nhttps://github.com/wxjiao/ParroT.\n1 Introduction\nLarge language models (LLMs), designed in the\ninstruction-following format, such as ChatGPT and\nGPT-4 (OpenAI, 2023), have garnered consider-\nable interest due to their remarkable abilities in\ncomprehending instructions and generating human-\nlike responses. These versatile models can effi-\nciently perform a wide range of natural language\n∗Corresponding author.\nParroT 有什么问题？\nTranslate the following sentences to English.\n有些鹦鹉可以⽤适当的词语回应简单的命令或问\n题，从⽽与⼈类建⽴⼀种基本的交流⽅式。\nHint: preferred/no errors/entity alignment/…\nSome parrots can respond to simple commands or \nquestions with the appropriate words, establishing \na basic form of communication with humans.\nFigure 1: Framework of ParroT. Hints are (optional)\nextra requirements to regulate the translation process.\nprocessing (NLP) tasks within a single architecture,\nincluding question answering (Omar et al., 2023),\ntext summarization (Yang et al., 2023), grammati-\ncal error correction (Wu et al., 2023), and machine\ntranslation (Jiao et al., 2023). Consequently, they\nrepresent a significant stride toward the realization\nof artificial general intelligence (AGI).\nMachine translation, a quintessential NLP task,\nfaces both challenges and opportunities presented\nby the emergence of LLMs. Traditional machine\ntranslation encompasses several sub-tasks (Farhad\net al., 2021), such as bilingual translation (Vaswani\net al., 2017), multilingual translation (Johnson\net al., 2017; Jiao et al., 2022), terminology transla-\ntion (Wang et al., 2022; Hou et al., 2022), quality\nestimation (Rei et al., 2020), and automatic post-\nediting (Pal et al., 2016), among others. These\ntasks are typically addressed by individual mod-\nels with limited cross-task interaction. However,\ncurrent LLMs have the potential to revolutionize\nthis inefficient approach and redefine the machine\ntranslation paradigm. On one hand, LLMs can\nleverage the benefits of various sub-tasks and seam-\nlessly transition between them using only natural\nlanguage instructions. For instance, if a user is\ndissatisfied with a translation result, they can re-\nquest the LLM to refine the translation implicitly\n(i.e., through automatic post-editing) or explicitly,\n15009\nby imposing constraints on specific entities (i.e.,\nterminology translation). On the other hand, LLMs\nare expected to enhance the explainability of ma-\nchine translation, ultimately leading to further im-\nprovements in translation quality. For example,\nusers may want LLMs to compare two transla-\ntions of a sentence (i.e., quality estimation) and\nprovide an explanation for the discrepancies (i.e.,\nerror analysis), which can then be addressed in a tar-\ngeted manner by the LLM itself. However, superior\nLLMs like ChatGPT and GPT-4 are only accessible\nthrough restricted APIs, which creates barriers to\nnew research and advancements in the field. There-\nfore, developing comprehensive machine transla-\ntion abilities upon open-source LLMs has become\na critical and challenging research problem.\nIn this paper, we propose the ParroT frame-\nwork to enhance and regulate the translation abil-\nities of LLMs during chat by leveraging existing\nhuman-written translation and feedback data. To\nbe compatible with chat, our framework reformu-\nlates translation data into the instruction-following\nstyle (Taori et al., 2023), and introduces a “Hint”\nfield for incorporating extra requirements to guide\nthe translation process. Accordingly, we propose\nthree distinct instruction types: (1) Translation\nInstruction, that asks LLMs to generate transla-\ntions based on source sentences. (2) Contrastive\nInstruction, that asks LLMs to generate the trans-\nlations of two different systems with the preferred\none at first. (3) Error-Guided Instruction, that\nasks LLMs to generate the translations with human-\nannotated errors as the hint. The first instruction\nguarantees the basic translation ability of LLMs\nwhile the latter two regulate the LLMs to align with\nhuman feedbacks (Ouyang et al., 2022; Liu et al.,\n2023). We adopt the open-source LLaMA (Tou-\nvron et al., 2023) and BLOOM (Scao et al., 2022)\nmodels, and conduct instruction tuning on previous\nWMT validation data and Multidimensional Qual-\nity Metric (MQM) human evaluation data. The\nresulting ParroT models are evaluated on Flores\nsubsets and WMT22 test sets.\nOur main findings are summarized as below:\n• Translation instruction, as expected, can im-\nprove the translation performance of LLMs\nsignificantly, especially for directions from\nEnglish to other languages.\n• Error-guided instruction can further improve\nthe performance when asking ParroT to gen-\nerate translations with no error, indicating the\nimportance of learning from low-quality trans-\nlations annotated by humans.\n• Parameter efficient finetuning with low-rank\nadaptation (LoRA, Hu et al., 2022) can pre-\nvent LLMs from overfitting, which achieves\nbetter performance on dominant languages but\nslows down the learning from other languages.\n• We demonstrate the potential of automatic\nevaluation tools (i.e., COMET) in providing\nquality information of translations, when con-\nstructing error-guided instructions for direc-\ntions that lack human annotation data.\n2 Instruction Pool\nIn this section, we introduce the three distinct in-\nstruction types: translation instruction, contrastive\ninstruction, and error-guided instruction. The first\ninstruction guarantees the basic translation ability\nof LLMs while the latter two regulate the LLMs to\nalign with human-written translation and feedback.\n2.1 Translation Instruction\nAs traditional translation systems, we rely on bilin-\ngual sentence pairs to accomplish the basic trans-\nlation ability of LLMs. We follow Stanford Al-\npaca (Taori et al., 2023) to transform bilingual sen-\ntence pairs into the instruction-following format,\nnamed translation instruction, for finetuning.\nTable 1 presents an example of the translation\ninstruction, which includes a preface fixed for all\ntasks, an “### Instruction:” to describe the transla-\ntion task (e.g., stating the language pair), an “###\nInput:” with the source sentence, and a “### Re-\nsponse:” with the target sentence to be generated.\nTo ensure the high quality of sentence pairs, we\nuse human-written translations rather than public\ntraining data that could be noisy.\n2.2 Contrastive Instruction\nBesides the basic translation ability, we also want\nLLMs to understand the relative quality difference\nbetween translations. In this way, we may improve\nthe quality of translations by asking LLMs to out-\nput the preferred ones. To realize this goal, we\nneed multiple different translations for each source\nsentence, which can be acquired by the systems\nsubmitted to WMT competitions. Meanwhile, the\nhuman evaluation results of these systems also pro-\nvide scores to reflect the quality differences.\n15010\nTable 1: Instruction types for finetuning ParroT models.\nType Instruction\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response\nthat appropriately completes the request.\\n\\n\nTranslation ### Instruction: \\nTranslate the following sentences from Chinese to English.\\n\\n\n### Input: \\n 检查情况显示，市场销售的粮油、肉类、水果、蔬菜、蛋奶等生活必需品供应充足，商\n品价格基本稳定，未发现严重违法违规行为，市场经营秩序总体平稳。\\n\\n\n### Response:The inspection results showed that there was an adequate supply of daily necessities, including\ngrain, oil, meat, fruit, vegetable, milk, and eggs in the market and commodity prices basically remain stable, the\nadministration found no serious offensive and noncompliant conducts, and the market order remains stable on\nthe whole.\nContrastive ### Instruction: \\nTranslate the following sentences from Chinese to English.\\n\\n\n### Input: \\n 检查情况显示，市场销售的粮油、肉类、水果、蔬菜、蛋奶等生活必需品供应充足，商\n品价格基本稳定，未发现严重违法违规行为，市场经营秩序总体平稳。\\n\\n\n### Hint: We prefer to translate it to\\n\\n\n### Response:<p>The inspection results showed that there was an adequate supply of daily necessities,\nincluding grain, oil, meat, fruit, vegetable, milk, and eggs in the market and commodity prices basically remain\nstable, the administration found no serious offensive and noncompliant conducts, and the market order remains\nstable on the whole.</p> rather than <p>The results of the inspection indicate the sufficient supply of living\nnecessities on marketing including cereals and oils, meat, fruits, vegetables, eggs and milk, and the basically\nstabilized commodity price. The inspection hasn’t found serious violation of laws and regulations. The market\norder is stable on an overall basis.</p>\nError-Guided ### Instruction: \\nTranslate the following sentences from Chinese to English.\\n\\n\n### Input: \\n 检查情况显示，市场销售的粮油、肉类、水果、蔬菜、蛋奶等生活必需品供应充足，商\n品价格基本稳定，未发现严重违法违规行为，市场经营秩序总体平稳。\\n\\n\n### Hint: A translation with major accuracy/mistranslation errors could be\\n\\n\n### Response:The results of the inspection indicate the sufficient supply of living necessities <v>on market-\ning</v> including cereals and oils, meat, fruits, vegetables, eggs and milk, and the basically stabilized commodity\nprice. The inspection hasn’t found serious violation of laws and regulations. The market order is stable on an\noverall basis.\n### Hint: A translation with minor fluency/grammar errors could be\\n\\n\n### Response:The results of the <v>inspection</v> indicate the sufficient supply of living necessities on\nmarketing including cereals and oils, meat, fruits, vegetables, eggs and milk, and the basically stabilized\ncommodity price. The inspection hasn’t found serious violation of laws and regulations. The market order is\nstable on an overall basis.\nAs shown in Table 1, we form the response\nby concatenating two translations (e.g., linked by\n“rather than”), in which the first translation has a\nhigher quality score. Meanwhile, we indicate that\nthe first translation is preferred in the “### Hint:”\nfield. Essentially, the second translation acts like\na negative sample to this sentence pair, which ex-\nplains the name contrastive instruction.\n2.3 Error-Guided Instruction\nThe potential problem of contrastive instruction is\nthat, it only tells the LLMs that the two translations\nhave quality differences but not clarify which kind\nof translation errors lead to such differences. How-\never, we want LLMs to learn the correspondence\nbetween the errors and the translations. With such\na deeper understanding on the translation errors,\nwe may ask LLMs to produce translations with no\nerror so as to improve the quality.\nWe propose error-guided instruction . As\nshown in Table 1, we use the translation with er-\nrors annotated by the “<v></v>” span to form the\nresponse. Similar to contrastive instruction, we\nadopt the “### Hint:” field to indicate the error\ntypes. This kind of fine-grained error annotation\nalso comes from the human evaluation data.\n3 Experimental Setups\n3.1 Training Data\nAlpaca Data. This dataset is built by Stanford Al-\npaca (Taori et al., 2023)1 project, which contains\n52.0K instruction-following data of multi-tasks for\n1https://github.com/tatsu-lab/stanford_alpaca\n15011\ntuning the LLaMA (Touvron et al., 2023) 2 mod-\nels. We call these data general instructions, which\nhelp the resulting ParroT models to maintain capa-\nbilities on general tasks.\nWMT Validation Data. We use human-written\nvalidation data from previous WMT compe-\ntitions rather than public training data to\navoid introducing noises into instruction tun-\ning. In this version, we use the newstest2017-\n2020 of Chinese ⇔English (i.e., Zh ⇔En) and\nGerman⇔English (i.e., De⇔En) tasks, which con-\nsist of 51.2K sentence pairs for all the four direc-\ntions. These sentence pairs are formed into the\ntranslation instructions.\nMQM Human Evaluation Data. Our human\nfeedback data comes from the Multidimensional\nQuality Metrics (MQM) datasets (Freitag et al.,\n2021)3, which annotate the different translation\nerrors (e.g., major accuracy/mistranslation, minor\nfluency/grammar) of top WMT systems. Due to its\nhigher reliability than Direct Assessment, MQM\nwas introduced to WMT competitions starting from\nWMT20 but only provided for a few language\npairs. In this version, we use the MQM data for the\nWMT20 En⇒De and Zh⇒En submissions. These\ndata are formed into the contrastive instructions\n(i.e., 20K) based on the quality scores and theerror-\nguided instructions (i.e., 26K) based on the error\nannotations, respectively.\nAutomatically Assessed Data. Although the Di-\nrect Assessment (DA) data of WMT systems pro-\nvide scores for language directions that lack MQM\ndata (i.e., De⇒En, En⇒Zh), we find the DA score\nto be very unreliable as they could be quite differ-\nent for two similar translations. Instead, we opt\nfor automatic evaluation metrics like COMET to\nscore the translations of WMT systems. We also\nheuristically determine a rough error level for each\ntranslation based on the COMET score, namely,\nMajor Error: [0, 85]; Minor Error: (85, 90]; No Er-\nror: (90, 100]. This decision comes in part from the\nobservation that top commercial systems achieve\nCOMET scores of nearly 90 on the Flores sub-\nsets (Table 3). Finally, we obtain 24K contrastive\ninstructions and 29K error-guided instructions.\nNote: To obtain a set of diverse instructions,\nwe use the three instructions in Jiao et al. (2023),\n2https://github.com/facebookresearch/llama\n3https://github.com/google/\nwmt-mqm-human-evaluation\nincluding the one in Table 1, as the seeds to ask\nGPT-4 (OpenAI, 2023) to paraphrase them. In total,\nwe have 33 different instructions that are randomly\ncombined with the training examples.\n3.2 Model Training\nWe conduct our experiments with HuggingFace\nTransformers4 on open-source LLMs from both\nthe LLaMA family (Touvron et al., 2023) and the\nBLOOM family (Scao et al., 2022). Specifically,\nwe choose LLaMA-7b and BLOOMZ-7b1-mt with\nmatched parameters, and also include LLaMA-13b\nand BLOOMZ-560m to study the effect of model\nsizes. We finetune them to the following variants:\n• Alpaca, as a reimplementation of the Stan-\nford Alpaca model fine-tuned only on the Al-\npaca multi-task dataset.\n• ParroT-T, finetuned on the Alpaca multi-task\ndataset and only the translation instructions\nfrom WMT validation data.\n• ParroT, finetuned on the Alpaca multi-task\ndataset, and all the three types of instructions\nintroduced above.\n• ParroT-LoRA, finetuned by low-rank adap-\ntation (LoRA) with default hyper-parameters\nfrom alpaca-lora5, which results in only\n4.2M tunable parameters based on LLaMA-7b.\nThe hyper-parameters for finetuning are basically\nconsistent with Stanford Alpaca (Taori et al., 2023).\nWe finetune the Alpaca and ParroT-T models for\n3 epochs on the corresponding data combination.\nFor ParroT and ParroT-LoRA, we finetune them\nfor 1.5 epochs to maintain similar training steps as\nParroT-T. We conduct finetuning on 8 Nvidia A100\nGPUs and utilize DeepSpeed 6 ZeRO stage 3 for\nmodel parallel.\n3.3 Evaluation\nTest Data. We evaluate the translation perfor-\nmance of LLMs on two sources of test sets:\n• Flores Subset: This dataset is a subset of Flores\nbenchmark, in which 50 sentences are sampled\nfor German, English, Romanian and Chinese,\nrespectively, for evaluating the translation per-\nformance of ChatGPT (Jiao et al., 2023)\n4https://github.com/huggingface/transformers\n5https://github.com/tloen/alpaca-lora\n6https://github.com/microsoft/DeepSpeed\n15012\nTable 2: Ablation study of key factors on Flores En⇒De\nsubset with Alpaca based on LLaMA-7b.\nPrompt Instruct. Search BLEU COMET\nno-input\nTP1 sample 20.0 80.0\nbeam 4 22.1 79.1\nTP3 sample 19.4 79.0\nbeam 4 21.5 79.0\ninput\nTP1 sample 21.0 79.5\nbeam 4 23.3 80.5\nTP3 sample 19.3 78.6\nbeam 4 20.6 80.0\n• WMT22 Test Sets: We also use the test sets\nfrom WMT22 competition (Kocmi et al., 2022),\nwhich are constructed based on more recent con-\ntent from various domains, including news, so-\ncial, e-commerce, and conversational domains.\nThe numbers of samples for De⇒En, En⇒De,\nZh⇒En and En ⇒Zh tasks are 1984, 2037,\n1875 and 2037, respectively.\nFor models based on BLOOM, we only evalu-\nate them on WMT22 test sets since the Flores\nbenchmark has been used in the development of\nBLOOMZ models.\nMetrics. For automatic evaluation, we adopt\nBLEU (Papineni et al., 2002) implementated in\nSacreBLEU (Post, 2018)7, and COMET (Rei et al.,\n2020)8 from Unbabel/wmt22-comet-da, which\nare driven by n-gram similarity and cross-lingual\npretrained models, respectively.\n4 Results\n4.1 Ablation Study\nBefore diving into more experiments, we investi-\ngate some factors that may affect the translation\nperformance of LLMs. By default, we conduct the\nablation studies on the Flores En⇒De subset with\nthe Alpaca model based on LLaMA-7b.\nPrompt Format. In the Alpaca multi-task\ndataset, about 60% examples contain empty “###\nInput:”, which results in two different prompt for-\nmats during finetuning, i.e., prompt-input and\nprompt-no-input. During inference, they use\nprompt-no-input which combines the instruction\nand input to fill the “### Instruction:” field, intro-\nducing the inconsistency between finetuning and\n7https://github.com/mjpost/sacrebleu\n8https://github.com/Unbabel/COMET\ninference. Therefore, we study if such an operation\nmakes any performance variation.\nInstruction Variation. Recent studies (Jiao et al.,\n2023; Zhang et al., 2023) suggest that LLMs are\nsensitive to task instructions, which could vary the\ntranslation performance considerably. We conduct\na brief study for this by comparing theTP1 and TP3\ninstructions in Jiao et al. (2023). TP1 is the one pre-\nsented in Table 1 while TP3 is “Please provide\nthe [TGT] translation for the following\nsentences.”, which was demonstrated a better\nchoice when tested on ChatGPT9.\nSearch Algorithm. In machine translation, the\nbeam search strategy (Sutskever et al., 2014; Fre-\nitag and Al-Onaizan, 2017; Vaswani et al., 2017)\nhas been the standard search algorithm for in-\nference. However, beam search requires high\ncomputation costs which becomes infeasible with\nthe LLMs, since they can easily induce out-of-\nmemory (OOM) issues. Therefore, more efficient\nsearch algorithms such as sampling may have to be\nthe choice. Therefore, we compare the sampling\nstrategy (Taori et al., 2023) and the beam search\nstrategy with a beam size of 4 for this factor.\nTable 2 presents the results of these ablation\nstudies. We have the following observations: (1)\nThe prompt-input performs slightly better than\nprompt-no-input though the gap is marginal. (2)\nThe TP1 instruction works better on Alpaca than\nTP3 which is different from that on ChatGPT.\n(3) Generally, beam search outperforms sampling\nsignificantly, especially in terms of BLEU score.\nTherefore, we use prompt-input + TP1 + beam\nsearch as the default setting for inference.\n4.2 Main Results\nTable 3 and Table 4 present the translation perfor-\nmance of LLaMA and BLOOM models on the test\nsets. For Flores subsets, we include the baseline\nresults reported in Jiao et al. (2023).\nInstruction tuning exploits the potential of\nvanilla LLMs for machine translation. Table 3\nshows that the vanilla LLaMA-7b without any fur-\nther training performs badly on the Flores subsets.\nBy inspecting the outputs, we find that the vanilla\nLLaMA-7b model tends to generate very long sen-\ntences (e.g., copy the instructions, continuing text\nexpansion), which makes the generated text not\n9https://chat.openai.com\n15013\nTable 3: Translation performance of LLaMA models on Flores subsets and WMT22 test sets.\nSystem De⇒En En ⇒De Zh ⇒En En ⇒Zh\nBLEU COMET BLEU COMET BLEU COMET BLEU COMET\nFlores Subsets\nGoogle 45.0 88.7 41.1 88.6 31.6 87.7 43.5 88.4\nDeepL 49.2 89.7 41.4 89.0 31.2 87.3 44.3 88.1\nChatGPT 43.7 89.1 38.8 88.1 24.7 85.8 38.2 86.9\nGPT-4 46.0 89.3 45.7 89.2 28.5 87.4 42.5 88.4\nBase Model: LLaMA-7b\nVanilla 3.4 60.1 2.4 49.0 1.8 53.7 0.1 47.6\nAlpaca 36.6 86.8 23.3 80.5 15.1 81.2 9.8 58.6\nAlpaca-LoRA 40.7 87.7 24.6 84.0 16.4 81.5 14.5 70.5\nParroT-T 41.3 87.7 28.5 83.3 19.5 83.1 24.7 79.9\nParroT 41.0 87.9 30.8 84.3 19.2 83.9 25.8 80.1\n+ Infer w/ Prefer. 38.1 87.6 23.0 83.9 18.6 83.1 22.5 80.1\n+ Infer w/ No Err. 42.2 88.7 32.1 84.9 21.5 83.7 27.4 81.8\nParroT-LoRA 43.8 88.3 29.0 84.9 16.9 80.6 14.8 71.5\n+ Infer w/ No Err. 42.0 88.0 29.8 85.4 17.4 81.3 19.8 76.7\nWMT22 Test Sets\nGoogle 33.3 84.8 38.4 87.1 28.6 80.9 49.9 87.4\nDeepL 32.8 84.7 36.2 87.9 24.2 79.3 44.5 86.4\nGPT-4 33.4 84.9 34.5 87.4 24.8 82.3 41.3 87.0\nBase Model: LLaMA-7b\nVanilla 2.9 52.8 1.6 45.3 1.2 50.3 0.3 46.3\nAlpaca 27.8 82.3 20.1 78.1 14.2 74.0 10.4 62.1\nAlpaca-LoRA 28.9 83.2 22.1 81.3 16.1 75.6 16.3 70.6\nParroT-T 26.6 82.5 24.0 80.4 18.1 75.3 27.0 78.4\nParroT 27.3 82.4 24.6 81.2 18.9 75.2 28.1 79.3\n+ Infer w/ No Err. 27.3 82.4 26.1 81.6 20.2 75.9 30.3 80.3\nParroT-LoRA 28.8 82.8 24.0 81.4 18.2 74.7 19.9 73.7\n+ Infer w/ No Err. 29.8 83.0 24.8 81.6 19.2 75.0 20.7 74.5\nBase Model: LLaMA-13b\nAlpaca 29.7 83.1 21.4 79.4 16.2 75.9 17.6 70.8\nParroT 27.6 83.2 27.0 82.8 19.9 75.8 30.9 81.1\n+ Infer w/ No Err. 31.1 83.6 28.1 82.6 21.7 76.7 31.7 81.0\nfaithful to the source sentences and also not gram-\nmatically correct. The reason could be the long\ncontext modeling during pretraining. Another rea-\nson is that we use the Alpaca inference format,\nwhich is basically a zero-shot setting that exhibits\nno guidance for translation.\nTuning LLaMA-7b on the Alpaca multi-task\ndataset (i.e., Alpaca) can ameliorate the above is-\nsue, resulting in complete generations with proper\nlengths. We find that Alpaca performs much better\non translation, which may benefit from the 0.5%\ntranslation instructions in the Alpaca multi-task\ndataset. However, the best performance is mainly\nobserved on high-resource directions like De⇒En,\ndue to the dominant language of Alpaca dataset\nin English. Further introducing a small amount of\ntranslation instructions (i.e., ParroT-T) in the four\nlanguage directions can significantly improve the\nperformance, especially for En⇒Zh, in which Chi-\nnese was unseen in the pretraining of LLaMA mod-\nels (Touvron et al., 2023). The findings of these\nLLaMA-based models are also consistent with that\non the WMT22 test sets.\nLearning from low-quality translations anno-\ntated by humans is also important. While pre-\nsenting the high-quality bilingual pairs to LLMs\nis important, as discussed above, we argue that\nlow-quality translations annotated by humans also\nbring benefits. As shown in Table 3, without hint\nin inference, ParroT outperforms ParroT-T slightly\non translation directions from English to other lan-\nguages (i.e., En ⇒De, En⇒Zh). However, when\nasking ParroT to generate translations with no er-\nror, the performance can be significantly improved\nacross translation directions and test sets. We spec-\nulate that ParroT does learn the relationship be-\ntween errors and translations by error-guided in-\n15014\nTable 4: Translation performance of BLOOM models on WMT22 test sets.\nSystem De⇒En En ⇒De Zh ⇒En En ⇒Zh\nBLEU COMET BLEU COMET BLEU COMET BLEU COMET\nBase Model: BLOOMZ-560m\nAlpaca 4.4 55.2 0.5 30.8 6.9 70.1 2.0 54.0\nParroT 16.4 68.9 13.3 57.7 16.0 74.8 25.4 79.0\n+ Infer w/ No Err. 16.9 69.3 12.8 56.8 15.7 75.0 26.3 79.5\nBase Model: BLOOMZ-7b1-mt\nAlpaca 17.6 73.0 3.1 44.5 13.0 76.4 23.9 81.8\nParroT 23.1 77.6 20.0 72.7 21.4 78.5 32.4 83.6\n+ Infer w/ No Err. 24.9 78.0 20.5 73.6 22.7 79.0 34.5 83.5\nTable 5: Effects of error levels as hints during inference.\nRed : improvement; Green : degradation.\nHint En⇒De Zh ⇒En\nBLEU COMET BLEU COMET\nNone 30.8 84.3 19.2 83.9\nNo Err. 32.1 84.9 21.5 83.7\nMinor Err. 28.8 83.6 20.6 82.1\nMajor Err. 28.5 82.9 19.3 80.5\nstruction, such that it can avoid the translation er-\nrors as much as possible when the hint of no error\nis provided.\nA bit unexpected is that when asking ParroT to\ngenerate preferred translations, the performance\ndrops considerably. As stated in Section 2.3, con-\ntrastive instruction only indicates that two trans-\nlations may have quality differences but not state\nwhy, which is difficult for LLMs to identify by\nthemselves. Previous study by Min et al. (2022)\nalso suggests that it is easier for LLMs to learn the\ninstruction formats rather than the input-response\npatterns, which may explain the phenomenon here.\nParameter efficient finetuning may prevent\nLLMs from overfitting. We also try low-rank\nadaptation (LoRA, Hu et al., 2022) to finetune par-\ntial parameters of LLMs for efficiency. Experimen-\ntal results in Table 3 show that Alpaca-LoRA out-\nperforms its full model counterpart noticeably. We\nspeculate that LoRA can prevent LLMs from over-\nfitting the small Alpaca multi-task dataset, leading\nto a stronger generalization ability. However, ap-\nplying LoRA to ParroT exhibits distinct behaviors\nfor high-resource and low-resource translation di-\nrections. Specifically, ParroT-LoRA outperforms\nthe corresponding full model ParroT on De ⇒En\nbut performs much worse on the other directions.\nIt seems that the small amount of tunable param-\neters also hinder the learning of instructions from\nother translation directions. Obviously, the hyper-\nparameters of LoRA should also be properly ad-\njusted to better learn from more instruction data.\nLLMs families and sizes also matter. For both\nLLaMA and BLOOM families, larger models can\nachieve much better translation performance after\ninstruction tuning. Our ParroT framework proves\nto be effective across all the models. Comparing\nthe two LLMs families, the ParroT model based\non BLOOMZ-7b1-mt performs much better on\nZh⇒En and En⇒Zh directions than those based on\nLLaMA-7b, which mainly results from the better\nmodeling of Chinese during the pretraining process\nof BLOOM.\nAutomatic evaluation tools can be effective in\nconstructing error-guided instructions. In Sec-\ntion 3.1, we construct the automatically assessed\ndata for De⇒En and En⇒Zh that are not provided\nwith the MQM data. As shown in Table 3 and Ta-\nble 4, we can observe considerable improvements\nof error-guided instruction on these two translation\ndirections. It demonstrates the potential of auto-\nmatic evaluation tools (i.e., COMET) in providing\nthe quality information of translations, as an aug-\nmentation to translation directions that lack human\nannotation data.\n4.3 Analysis\nWe conduct more analyses to understand the effects\nof our instruction types. By default, we use the\nmodel variants based on LLaMA-7b, and the Flores\nsubsets.\nEffectiveness of Error-Guided Instruction. To\nunderstand how error-guided instruction works, we\ninvestigate the behavior of ParroT when asking it\nto generate translations with varied error levels as\n15015\nTable 6: Examples from Flores Zh⇒En subset when translated with varied error levels. Red : translation errors.\nCOMET Example\nSRC n/a 例如，在卢瓦尔河谷和莱茵河谷参观城堡，或者乘游轮去游览多瑙河沿岸好玩的城市，或\n者沿伊利运河乘船游玩。\nREF n/a For example visiting castles in the Loire Valley, the Rhine valley or taking a cruise to interesting cites\non the Danube or boating along the Erie Canal.\nNone 81.2 For example, visiting the castles in theRhine Valleyand theLahn Valley, or taking a cruise along\nthe Rhine River to explore the citiesalong the river, or taking a boat trip along theIlli River .\nNo Err. 81.4 For example, visiting the castles in theRhine Valleyand theRuhr Valley, or taking a cruise to visit\nthe cities along theRhine River , or taking a boat ride along theIlli River .\nMinor Err. 78.1 For example, visiting the castles in theRhine Valleyand theRuhr Valley, or taking a cruise to visit\nthe cities along theRhine River , or taking a boat toplay in the citiesalong theElbe River .\nMajor Err. 65.3 For example, visiting thefortressin the valley of theRiver V olgaand theRiver Levan, or taking\na cruise to visit the cities along theRiver V olga, or taking a boat toplay in the citiesalong the\nRiver V olga .\nTable 7: Effects of preference as hints during inference.\nRed : improvement; Green : degradation.\nHint En⇒De Zh ⇒En\nBLEU COMET BLEU COMET\nNone 30.8 84.3 19.2 83.9\nPrefer. 23.0 83.9 18.6 83.1\nUnprefer. 29.1 83.7 19.6 82.3\nhints. As shown in Table 5, the translation quality\nis getting worse from no error to minor error to ma-\njor error, especially in terms of COMET score. The\ntranslations generated with no hint are usually com-\nparable with the minor error level. It demonstrates\nthat ParroT can place erroneous translations into\nother locations of the probability space with the reg-\nulation of human annotations. As a result, ParroT\nis more likely to generate high-quality translation\nwith “no error”.\nFor qualitative analysis, we show an example\nfrom Flores Zh ⇒En subset in Table 6, in which\nwe highlight all errors in each translation. Com-\npared to no error level, minor and major error levels\ntend to produce more over-translations and mis-\ntranslations. It is also important to point out that\nno error level does not guarantee that completely\ncorrect translations will be generated, especially\nfor named entities, which we attribute to the under-\nexplored translation abilities of current LLMs.\nFailure of Contrastive Instruction. We try to\nunderstand why contrastive instruction does not\nwork. By examining the responses of ParroT when\nasking it to generate preferred translations, we\nobserve significant differences in lexical choices\nbetween the “preferred” and “unpreferred” (i.e.,\nthe second translation in the response) translations.\nSurprisingly, as shown in Table 7, the “unpreferred”\ntranslations obtain a much higher BLEU score but\nthe situation is different for the COMET score. It\nindicates that ParroT attempted to identify the qual-\nity differences between the first and second transla-\ntions in the contrastive instructions through lexical\nchoices, which is a low-level pattern to reflect the\ntranslation quality. One potential reason is that the\nWMT systems are so competitive with each other\nthat the quality differences between them are too\nsubtle for the LLM to learn effectively. We will\ninvestigate more about contrastive instruction in\nfuture work.\n5 Related Work\nLLMs for MT. With the increasing capacity of\nLLMs, they have become good few-shot learn-\ners (Brown et al., 2020; Lin et al., 2022) on various\nNLP tasks, including machine translation. A num-\nber of recent studies focus on how to prompt LLMs\nfor machine translation, including prompt template\ncomparison (Zhang et al., 2023), few-shot example\nselection (Agrawal et al., 2022; Vilar et al., 2022),\ndomain adaptation (Moslem et al., 2023), and rare\nword translation (Ghazvininejad et al., 2023). How-\never, our ParroT framework aims to develop instant\ntranslation capability for chatbots without few-shot\nexamples. This is consistent with the performance\nof ChatGPT and GPT-4 (OpenAI, 2023), which ex-\nhibit excellent translation ability (Jiao et al., 2023;\nBang et al., 2023; He et al., 2023; Liang et al.,\n2023) during chat.\n15016\nInstruction Tuning. To eliminate the reliance\non few-shot examples, recent studies also try to\nfinetune LLMs on a small amount of instructions\ncovering different NLP tasks, making the LLMs\nzero-shot learners (Mishra et al., 2022; Wei et al.,\n2022). With the emergence of various power-\nful open-source LLMs such as BLOOM (Scao\net al., 2022) and LLaMA (Touvron et al., 2023),\nthere has been a boom for creating instruction data\nand tuning customized chatbots, for example, Al-\npaca (Taori et al., 2023), Vicuna, WizardLM (Xu\net al., 2023) and the like. However, most of these\nstudies focus on developing chatbots that are ca-\npable of general NLP tasks, while we pay more\nattention to machine translation. More importantly,\napart from the instructions built from parallel trans-\nlation data, we also transform human feedback data\ninto instructions and demonstrate its effectiveness\nin improving the translation performance.\n6 Conclusion\nWe propose ParroT to enhance and regulate the\ntranslation abilities during chat based on open-\nsource LLMs, human-written translation and feed-\nback data. We reformulate translation data into\nthe instruction-following style, and introduce a\n“Hint” field for incorporating extra requirements\nto regulate the translation process. Accordingly,\nwe propose three instruction types for finetuning\nParroT models, i.e., translation instruction, con-\ntrastive instruction, and error-guided instruction.\nExperiments on Flores subsets and WMT22 test\nsets suggest that translation instruction improves\nthe translation performance of vanilla LLMs sig-\nnificantly while error-guided instruction can lead\nto further improvement, demonstrating the impor-\ntance of learning from low-quality translations an-\nnotated by humans. While we only use three in-\nstruction types in this paper, it is natural to ex-\ntend ParroT to other hints (e.g., entity alignments),\nwhich we leave for future exploration.\nLimitations\nThis work performs a preliminary exploration\non the instant translation capability for chatbots,\nwhich can be further improved in the following\naspects:\n• Instruction Variants: Presently, the instruc-\ntions only support the translation of incoming\nsentences. It may be beneficial for chatbots to\nalso translate previous chat records when users\nstruggle to comprehend responses in foreign lan-\nguages.\n• Contrastive Translations: In this study, we did\nnot observe performance improvements related\nto contrastive instructions, possibly due to incor-\nrect instruction formatting. By exploring alter-\nnative formats, such as automatic post-editing\n(APE), we could potentially capitalize on the\nadvantages of contrastive translations.\n• LoRA Effectiveness: The current analysis did\nnot reveal consistent performance improvements\nwhen using LoRA as compared to full model\ntraining. It may be necessary to adjust the\nnumber of tunable parameters according to the\ndataset size for better results.\nReferences\nSweta Agrawal, Chunting Zhou, Mike Lewis, Luke\nZettlemoyer, and Marjan Ghazvininejad. 2022. In-\ncontext examples selection for machine translation.\narXiv.\nYejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wen-\nliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei\nJi, Tiezheng Yu, Willy Chung, Quyet V . Do, Yan Xu,\nand Pascale Fung. 2023. A multitask, multilingual,\nmultimodal evaluation of ChatGPT on reasoning, hal-\nlucination, and interactivity.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. NeurIPS.\nAkhbardeh Farhad, Arkhangorodsky Arkady, Biesialska\nMagdalena, Bojar Ondˇrej, Chatterjee Rajen, Chaud-\nhary Vishrav, Marta R Costa-jussa, España-Bonet\nCristina, Fan Angela, Federmann Christian, et al.\n2021. Findings of the 2021 conference on machine\ntranslation (WMT21). In WMT.\nMarkus Freitag and Yaser Al-Onaizan. 2017. Beam\nsearch strategies for neural machine translation.\nACL.\nMarkus Freitag, George Foster, David Grangier, Viresh\nRatnakar, Qijun Tan, and Wolfgang Macherey. 2021.\nExperts, errors, and context: A large-scale study of\nhuman evaluation for machine translation. TACL.\nMarjan Ghazvininejad, Hila Gonen, and Luke Zettle-\nmoyer. 2023. Dictionary-based phrase-level prompt-\ning of large language models for machine translation.\narXiv.\n15017\nZhiwei He, Tian Liang, Wenxiang Jiao, Zhuosheng\nZhang, Yujiu Yang, Rui Wang, Zhaopeng Tu, Shum-\ning Shi, and Xing Wang. 2023. Exploring human-\nlike translation strategy with large language models.\narXiv.\nYifan Hou, Wenxiang Jiao, Meizhen Liu, Carl\nAllen, Zhaopeng Tu, and Mrinmaya Sachan. 2022.\nAdapters for enhanced modeling of multilingual\nknowledge and text. In Findings of the Association\nfor Computational Linguistics: EMNLP 2022, pages\n3902–3917.\nEdward J Hu, Phillip Wallis, Zeyuan Allen-Zhu,\nYuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen,\net al. 2022. LoRA: Low-rank adaptation of large\nlanguage models. In ICLR.\nWenxiang Jiao, Zhaopeng Tu, Jiarui Li, Wenxuan Wang,\nJen-tse Huang, and Shuming Shi. 2022. Tencent’s\nmultilingual machine translation system for WMT22\nlarge-scale african languages. In WMT.\nWenxiang Jiao, Wenxuan Wang, Jen tse Huang, Xing\nWang, and Zhaopeng Tu. 2023. Is ChatGPT a good\ntranslator? Yes with GPT-4 as the engine. In ArXiv.\nMelvin Johnson, Mike Schuster, Quoc V Le, Maxim\nKrikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat,\nFernanda Viégas, Martin Wattenberg, Greg Corrado,\net al. 2017. Google’s multilingual neural machine\ntranslation system: Enabling zero-shot translation.\nTACL.\nTom Kocmi, Rachel Bawden, Ond ˇrej Bojar, Anton\nDvorkovich, Christian Federmann, Mark Fishel,\nThamme Gowda, Yvette Graham, Roman Grund-\nkiewicz, Barry Haddow, et al. 2022. Findings of the\n2022 conference on machine translation (WMT22).\nIn WMT.\nTian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang,\nYan Wang, Rui Wang, Yujiu Yang, Zhaopeng Tu, and\nShuming Shi. 2023. Encouraging divergent thinking\nin large language models through multi-agent debate.\narXiv.\nXi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu\nWang, Shuohui Chen, Daniel Simig, Myle Ott, Na-\nman Goyal, Shruti Bhosale, Jingfei Du, et al. 2022.\nFew-shot learning with multilingual generative lan-\nguage models. In EMNLP.\nHao Liu, Carmelo Sferrazza, and Pieter Abbeel. 2023.\nChain of hindsight aligns language models with feed-\nback. arXiv.\nSewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe,\nMike Lewis, Hannaneh Hajishirzi, and Luke Zettle-\nmoyer. 2022. Rethinking the role of demonstrations:\nWhat makes in-context learning work? In EMNLP.\nSwaroop Mishra, Daniel Khashabi, Chitta Baral, and\nHannaneh Hajishirzi. 2022. Cross-task generaliza-\ntion via natural language crowdsourcing instructions.\nIn ACL.\nYasmin Moslem, Rejwanul Haque, and Andy Way. 2023.\nAdaptive machine translation with large language\nmodels. arXiv.\nReham Omar, Omij Mangukiya, Panos Kalnis, and Es-\nsam Mansour. 2023. ChatGPT versus traditional\nquestion answering for knowledge graphs: Current\nstatus and future directions towards knowledge graph\nchatbots. arXiv.\nOpenAI. 2023. GPT-4 technical report. arXiv.\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-\nroll L Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, et al.\n2022. Training language models to follow instruc-\ntions with human feedback. arXiv.\nSantanu Pal, Sudip Kumar Naskar, Mihaela Vela, and\nJosef van Genabith. 2016. A neural network based\napproach to automatic post-editing. In ACL.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. BLEU: A method for automatic\nevaluation of machine translation. In ACL.\nMatt Post. 2018. A call for clarity in reporting BLEU\nscores. In WMT.\nRicardo Rei, Craig Stewart, Ana C Farinha, and Alon\nLavie. 2020. COMET: A neural framework for MT\nevaluation. In EMNLP.\nTeven Le Scao, Angela Fan, Christopher Akiki, El-\nlie Pavlick, Suzana Ili ´c, Daniel Hesslow, Roman\nCastagné, Alexandra Sasha Luccioni, François Yvon,\nMatthias Gallé, et al. 2022. BLOOM: A 176b-\nparameter open-access multilingual language model.\narXiv.\nIlya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.\nSequence to sequence learning with neural networks.\nNeurIPS.\nRohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann\nDubois, Xuechen Li, Carlos Guestrin, Percy Liang,\nand Tatsunori B. Hashimoto. 2023. Stanford alpaca:\nAn instruction-following llama model. https://\ngithub.com/tatsu-lab/stanford_alpaca.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal\nAzhar, et al. 2023. Llama: Open and efficient foun-\ndation language models. arXiv.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. NeurIPS.\nDavid Vilar, Markus Freitag, Colin Cherry, Jiaming Luo,\nViresh Ratnakar, and George Foster. 2022. Prompt-\ning PaLM for translation: Assessing strategies and\nperformance. arXiv.\n15018\nShuo Wang, Peng Li, Zhixing Tan, Zhaopeng Tu,\nMaosong Sun, and Yang Liu. 2022. A template-\nbased method for constrained neural machine transla-\ntion. In EMNLP.\nJason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu,\nAdams Wei Yu, Brian Lester, Nan Du, Andrew M\nDai, and Quoc V Le. 2022. Finetuned language\nmodels are zero-shot learners. In ICLR.\nHaoran Wu, Wenxuan Wang, Yuxuan Wan, Wenxiang\nJiao, and Michael Lyu. 2023. ChatGPT or Gram-\nmarly? Evaluating ChatGPT on grammatical error\ncorrection benchmark. arXiv.\nCan Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng,\nPu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin\nJiang. 2023. Wizardlm: Empowering large language\nmodels to follow complex instructions. arXiv.\nXianjun Yang, Yan Li, Xinlu Zhang, Haifeng Chen, and\nWei Cheng. 2023. Exploring the limits of ChatGPT\nfor query or aspect-based text summarization. arXiv.\nBiao Zhang, Barry Haddow, and Alexandra Birch. 2023.\nPrompting large language model for machine transla-\ntion: A case study. arXiv.\nA Flores Full Sets\nWe adopted the subset of Flores in order to directly\ncompare with the results of ChatGPT and com-\nmercial MT systems from the previous evaluation\nreport (Jiao et al., 2023), as stated in Section 3.3.\nHowever, for a more convincing evaluation, we\nalso test the LLMs on the full sets of Flores (i.e.,\nwith 1012 sentences), and list the results in Table 8.\nObviously, the trend of performance across sys-\ntems still holds, and our \"ParroT + Infer w/ No\nErr\" setting performs the best.\nB General Tasks\nIn our experiments, we include the Alpaca multi-\ntask dataset for finetuning ParroT to preserve its\nability on general tasks. We present two examples\nin Table 9, from question answering and code gen-\neration, respectively. The responses of both Alpaca\nand ParroT are correct, although the expressions\nmay be different. For comprehensive comparison,\nit is better to perform a quantitative evaluation and\nwe leave it for future work.\n15019\nTable 8: Translation performance of LLaMA models on Flores full sets.\nSystem De⇒En En ⇒De Zh ⇒En En ⇒Zh\nBLEU COMET BLEU COMET BLEU COMET BLEU COMET\nBase Model: LLaMA-7b\nVanilla 3.0 58.2 1.7 48.8 2.7 52.0 0.1 48.6\nAlpaca 36.3 87.6 23.0 81.1 16.4 81.3 8.3 56.5\nParroT-T 37.4 87.9 26.9 83.7 19.7 82.8 26.1 79.2\nParroT 38.1 88.0 28.9 84.5 21.1 83.0 27.0 80.3\n+ Infer w/ Prefer. 34.6 87.5 24.8 83.9 18.1 82.4 24.2 79.0\n+ Infer w/ No Err. 39.4 88.4 30.7 84.6 21.3 83.4 29.1 81.2\nTable 9: Examples of general tasks. The base model is LLaMA-7b.\nSystem Question Answering\nTell me about alpacas.\nAlpaca Alpacas are a species of camelid native to South America. They are domesticated and bred for their\nfiber, which is used in the production of knitted and woven items such as clothing, blankets, and rugs.\nAlpacas are typically kept as livestock, and can live up to 20 years in captivity. They are typically\nbrown, white, or grey in color, and can grow up to 12 inches tall at the shoulder.\nParroT Alpacas are a species of domesticated South American camelids, bred primarily for their fiber. They\nare typically kept as pets, for their fleece, or for their meat. Alpacas are very social animals and live\nin herds, with a dominant male leader and a number of females and young. They are very intelligent\nand can be trained to respond to basic commands. Alpacas require a lot of space and good quality\nfood in order to thrive.\nSystem Code Generation\nWrite a Python program that prints the first 10 Fibonacci numbers.\nAlpaca numbers = [0, 1]\nfor i in range(2, 10):\nnumbers.append(numbers[i-2] + numbers[i-1])\nprint(numbers)\nParroT def fibonacci(n):\nif n == 0:\nreturn 0\nelif n == 1:\nreturn 1\nelse:\nreturn fibonacci(n-1)+fibonacci(n-2)\nprint(fibonacci(10))\n15020",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8463220000267029
    },
    {
      "name": "Annotation",
      "score": 0.6801344156265259
    },
    {
      "name": "Machine translation",
      "score": 0.6345603466033936
    },
    {
      "name": "Natural language processing",
      "score": 0.5816347599029541
    },
    {
      "name": "Translation (biology)",
      "score": 0.5730651021003723
    },
    {
      "name": "Field (mathematics)",
      "score": 0.5524484515190125
    },
    {
      "name": "Quality (philosophy)",
      "score": 0.5213121771812439
    },
    {
      "name": "Artificial intelligence",
      "score": 0.49392443895339966
    },
    {
      "name": "Process (computing)",
      "score": 0.48908454179763794
    },
    {
      "name": "Programming language",
      "score": 0.2017804980278015
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Pure mathematics",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Epistemology",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Messenger RNA",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I2250653659",
      "name": "Tencent (China)",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I177725633",
      "name": "Chinese University of Hong Kong",
      "country": "HK"
    },
    {
      "id": "https://openalex.org/I183067930",
      "name": "Shanghai Jiao Tong University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210114105",
      "name": "Tsinghua–Berkeley Shenzhen Institute",
      "country": "CN"
    }
  ],
  "cited_by": 14
}