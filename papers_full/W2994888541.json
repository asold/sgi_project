{
  "title": "Contextual Temperature for Language Modeling",
  "url": "https://openalex.org/W2994888541",
  "year": 2022,
  "authors": [
    {
      "id": null,
      "name": "Wang, Pei-Hsin",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Hsieh, Sheng-Iou",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2751968651",
      "name": "Chang, Shih-Chieh",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2744529635",
      "name": "Chen, Yu-Ting",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4289510778",
      "name": "Pan, Jia-Yu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1947499342",
      "name": "Wei Wei",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Juan, Da-Chang",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2963962369",
    "https://openalex.org/W2133564696",
    "https://openalex.org/W2132339004",
    "https://openalex.org/W2963970792",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2963240485",
    "https://openalex.org/W2964222296",
    "https://openalex.org/W1821462560",
    "https://openalex.org/W2962832505",
    "https://openalex.org/W2757047188",
    "https://openalex.org/W2900260828",
    "https://openalex.org/W179875071",
    "https://openalex.org/W2899771611",
    "https://openalex.org/W2963494889",
    "https://openalex.org/W2163605009",
    "https://openalex.org/W2963983719",
    "https://openalex.org/W2888010645",
    "https://openalex.org/W1632114991",
    "https://openalex.org/W2963537482",
    "https://openalex.org/W2964110616",
    "https://openalex.org/W2890619523",
    "https://openalex.org/W2547875792",
    "https://openalex.org/W2185726469",
    "https://openalex.org/W2618606525"
  ],
  "abstract": "Temperature scaling has been widely used as an effective approach to control the smoothness of a distribution, which helps the model performance in various tasks. Current practices to apply temperature scaling assume either a fixed, or a manually-crafted dynamically changing schedule. However, our studies indicate that the individual optimal trajectory for each class can change with the context. To this end, we propose contextual temperature, a generalized approach that learns an optimal temperature trajectory for each vocabulary over the context. Experimental results confirm that the proposed method significantly improves state-of-the-art language models, achieving a perplexity of 55.31 and 62.89 on the test set of Penn Treebank and WikiText-2, respectively. In-depth analyses show that the behaviour of the learned temperature schedules varies dramatically by vocabulary, and that the optimal schedules help in controlling the uncertainties. These evidences further justify the need for the proposed method and its advantages over fixed temperature schedules.",
  "full_text": "Contextual Temperature for Language Modeling\nPei-Hsin Wang,1 Sheng-Iou Hsieh,1 Shih-Chieh Chang,1\nYu-Ting Chen, 2 Jia-Yu Pan, 2 Wei Wei,2 Da-Chang Juan 2\n1 National Tsing Hua University, Hsinchu, Taiwan2 Google, Mountain View, CA, USA\n{peihsin, steins1111}@gapp.nthu.edu.tw, scchang@cs.nthu.edu.tw,\n{yutingchen, jypan, wewei, dacheng}@google.com\nAbstract\nTemperature scaling has been widely used as an effective\napproach to control the smoothness of a distribution, which\nhelps the model performance in various tasks. Current prac-\ntices to apply temperature scaling assume either a ﬁxed, or\na manually-crafted dynamically changing schedule. How-\never, our studies indicate that the individual optimal trajec-\ntory for each class can change with the context. To this end,\nwe propose contextual temperature, a generalized approach\nthat learns an optimal temperature trajectory for each vocab-\nulary over the context. Experimental results conﬁrm that the\nproposed method signiﬁcantly improves state-of-the-art lan-\nguage models, achieving a perplexity of 55.31 and 62.89 on\nthe test set of Penn Treebank and WikiText-2, respectively.\nIn-depth analyses show that the behaviour of the learned tem-\nperature schedules varies dramatically by vocabulary, and\nthat the optimal schedules help in controlling the uncertain-\nties. These evidences further justify the need for the proposed\nmethod and its advantages over ﬁxed temperature schedules.\nIntroduction\nTemperature scaling is often used along with the Softmax\nlayer in various tasks, such as knowledge distillation, model\ncalibration, and natural language generation (Krizhevsky,\nSutskever, and Hinton 2012; Bahdanau, Cho, and Bengio\n2014; Hinton, Vinyals, and Dean 2014; Guo et al. 2017; Hu\net al. 2017; Caccia et al. 2018). A widely adopted technique\nis to apply a temperature as a denominator to the logits of\nthe Softmax layer. Speciﬁcally, given a temperatureτ, when\nτ → ∞, the distribution becomes more uniform, thus in-\ncreasing the uncertainty. Contrarily, when τ →0, the dis-\ntribution collapses to a point mass. Although temperature\nscaling has been justiﬁed to achieve great success, existing\nmethods use temperature scaling in extremely limited ways.\nThey either assume a constant temperature throughout the\ntraining (Norouzi et al. 2016; Ma et al. 2017; Chen et al.\n2019), or use a ﬁxed schedule to control the temperature (Hu\net al. 2017). Most importantly, none of them studies the ef-\nfects on different vocabulary tokens when the temperature\nchanges. We propose contextual temperature, a generalized\ntemperature scaling method which takes both the history of\na sequence and a particular word token into consideration.\nCopyright © 2021, Association for the Advancement of Artiﬁcial\nIntelligence (www.aaai.org). All rights reserved.\nThrough optimizing the use of temperature scaling by the\nchange of contexts, contextual temperature is able to gener-\nate an unique temperature for each token.\nFigure 1(a) shows the optimized temperature for each to-\nken during the course of training. As shown in the ﬁgure,\nsome certain words have a distinct heating-up temperature\nscaling, while the majority of words have a scaling that grad-\nually cooling down the temperature. We argue that existing\nmethods limit themselves to some ﬁxed schedules, and thus\nhave great difﬁculty to generalize. In addition, another ex-\nample can be observed in Figure 1(b), which indicates that\nthe average of the temperature drops, as the length of the\ncontext increases. This suggests that the temperature mech-\nanism helps promote stochasticity in the beginning of a sen-\ntence, then gradually suppressing the uncertainty until the\nend. All of these suggest the use of a more generalized tem-\nperature mechanism with the advantage of being able to deal\nwith these phenomena.\nExperiments on language modeling exhibit signiﬁ-\ncantly improved performances on both Penn Treebank and\nWikiText-2 datasets. Consistent improvements are shown on\nboth validation and testing splits. In addition, we conduct\ncomprehensive analyses and ablation studies to conﬁrm the\nimprovements. We observe that the proposed method is ca-\npable of controlling the uncertainties as the patterns of con-\ntexts change, allowing language models to achieve much\nbetter performances. To the best of our knowledge, this work\nis the ﬁrst systematic work that studies the role of tempera-\nture changing over context for training language models on\na per token basis. The experiment results suggest a new way\nof training sequential models with discrete outputs, that is,\nusing parameterized temperatures. We have also established\nthe link between the control of model uncertainty and the\nuse of temperatures, paying the way for extensions on tasks\nthat require such long-term control.\nRelated Work\nLanguage Modeling\nLanguage modeling aims at predicting the next word xt in a\nsentence given a sequence of history x1:t−1 = x1,...,x t−1.\nA language model factorizesP(x1:t), the joint probability of\nx1:t, as the product of a series of conditional probabilities,\narXiv:2012.13575v1  [cs.CL]  25 Dec 2020\n(a)\n (b)\nFigure 1: (a) Temperature of each word learned using the proposed method over training epochs. Each line in the ﬁgure repre-\nsents a distinct token ranked by frequency. The y-axis shows the tokens’ temperature values. Note that the actual value equals\nto the value on the y-axis plus 2; we eliminate the integer part (plus 2) for a better visualization. (b) Means and conﬁdence\nintervals of the temperature vector (y-axis) over positions in a sentence (x-axis). As in this ﬁgure, the average temperature is\nhigh at the beginning of a sentence and gradually decreases towards latter positions in a sentence.\nas speciﬁed below:\nP(x1:t) =\nt∏\ni=1\nP(xi|x1:i−1) (1)\nModern neural language models are comprised of two\nparts: a mapping function and a probability function over to-\nkens. A mapping function θemb ∈R|V|×d maps a token xt\ninto a real-value vectorxemb\nt ∈Rd, where dis the dimension\nof the vector and |V|is the size of vocabulary. A probability\nfunction converts a ddimensional vector into a |V|dimen-\nsional vector using a weight matrixθmodel ∈Rd×|V|. After-\nwards, a Softmax function σ is used to obtain a probability\ndistribution over tokens. That is, at timestep t, we have\nP(xt|x1:t−1) = σ(f(x1:t−1; θemb ∪θmodel)) (2)\nwhere f is a nonlinear mapping parameterized by θemb and\nθmodel. Current language models adopt various architectures\nas θmodel, including the earlier feed-forward networks (Ben-\ngio et al. 2003), recent recurrent-based ones (Hochreiter\nand Schmidhuber 1997; Mikolov et al. 2010; Zilly et al.\n2017), convolutional-based ones (Dauphin et al. 2017), and\nattention-based ones (Dai et al. 2019).\nSoftmax Layer\nA Softmax layer σ normalizes a |V|dimension, real-value\nvector z to make it sum to 1. Here, z = f(x1:t−1; θemb ∪\nθmodel) following Equation 2, and zi is the i-th element in\nz.\nσ(z)i = zi\n∑K\nj ezj\n(3)\nRecent progress suggests that Mixture of Softmaxes\n(MoS) (Yang et al. 2018) signiﬁcantly improves the per-\nformance by ﬁrst computing multiple Softmax distributions,\nand summing them up through a set of weights to provide the\nﬁnal probability distribution. Speciﬁcally, a set of M matri-\nces Wm is applied to z, yielding zm = zT ·Wm, where\nWm ∈Rd×|V|. On the other hand, the weights of M Soft-\nmaxes, denoted π, are parameterized by Wp ∈ Rh×M, h\nthe dimension of RNN output. The probability distribution\nunder the MoS model is thus\nPMoS (xt|x1:t−1; Θ) =\nM∑\nm\nπm ·σ(zm) (4)\nwhere Θ = ∪M\nm=1Wm ∪θemb ∪θmodel.\nTemperature Scaling\nTemperature, denoted τ, often serves as a hyper-parameter\nin the Softmax layer to control the smoothness of the distri-\nbution. Applying temperature scaling on z gives\nP(xt|x1:t−1; θemb,θmodel,τ) = σ(z/τ) (5)\nHere τ is a vector with dimension |V|same as z, and is\nnormally τ is set to 1.\nVarious usages of temperature scaling have been explored\nin recent progresses, breaking the limit of treating temper-\nature as a hyper-parameter. Below we divide related works\ninto three categories: (a) constant temperature, where each\nelement in τ has the same value, so each element zi in z is\ndivided by the same temperature, (b) dynamic temperature\nover training iterations, where τ is constant in one single it-\neration, but has different value in every iteration, and (c) dy-\nnamic temperature over word position, where τ is dynamic\nin one iteration, i.e., each elementziin z has its own temper-\nature value, and besides, τ could change in every iteration.\nConstant Temperature. Earlier works can be traced back\nto model distillation (Hinton, Vinyals, and Dean 2014),\nwhere τ is a hyper-parameter and chosen empirically. Con-\nstant temperature is also used during training (Norouzi et al.\n2016; Ma et al. 2017) to control the degree of augmenta-\ntion. Other works incorporating τ at inference time include\nmodel conﬁdence calibration (Guo et al. 2017), and control-\nling trade-off between quality and diversity in text genera-\ntion tasks (Caccia et al. 2018).\nDynamic Temperature Over Training Iterations. Most\nworks adopt dynamic temperature through a manually-\ncrafted schedule. Notably, Hu et al. (2017) use an approx-\nimation based on Softmax with a decreasing temperature to\nenable gradient propagation. Similar techniques are adopted\nin gumbel-softmax (Jang, Gu, and Poole 2017) to allow gra-\ndients to pass through discrete sampling objectives. In addi-\ntion, studies show that with a heating up temperature scaling,\nembedding vectors are more compact (Zhang et al. 2018).\nDynamic Temperature Over Word Position. Another\nwork that is closely related to our work, is the adaptive tem-\nperature over an attention model (Lin et al. 2018). At each\ntimestep, the model learns to output a dynamic temperature\nto control the softness of the attention, based on the informa-\ntion of decoding at the current step as well as the attention\nin previous steps. We note that contextual temperature fur-\nther learns the temperature for each vocabulary in the output\ndistribution.\nMethods\nContextual Temperature\nContextual temperature is a mechanism that chooses the op-\ntimal temperature by considering the “context” of a wordxt.\nA context of a word includes not only the historyx1:t−1, but\nalso the speciﬁc vocabulary k that we calculate the proba-\nbility on. Such a mechanism allows us to parameterize the\ntemperature vector τ using a deep neural network and adapt\nthe softness of the Softmax layer.\nOur temperature vector τ ∈R|V|is generated from the\nnon-linear mapping function f as described in Section . Al-\nthough f can be any sequential models, we parameterize it\nby AWD-LSTM (Merity, Keskar, and Socher 2018). We then\nmultiplying the output of f by Wτ Please note that using a\nsingle matrix may increase the number of parameters signiﬁ-\ncantly, and thus in practice one can choose to factorize it into\ntwo matrices. Finally, we scale the temperature vector using\na Softmax layer over the dimension of vocabulary, bounding\nits range in [α\nβ, 1+α\nβ ].\nτ = σ(f(x1:t−1; θemb,θmodel)T ·Wτ) + α\nβ (6)\nContextual Temperature MoS\nWe use the Contextual Temperature Mixture of Softmaxes\narchitecture (CT-MoS) for language modeling. The CT-MoS\nmodel extends Equation 4 by adding contextual temperature\nin Equation 6.\nPCT −MoS (xt = k|x1:t−1; Θ) =\nM∑\nm\nπm ·σ(zm ⊘τ)) (7)\nwhere ⊘represents element-wise division,Θ = ∪M\nm=1Wm∪\nθemb∪θmodel∪Wτ1 ∪Wτ2 denotes the total parameters of\nCT-MoS, and Wτ = Wτ1 ∪Wτ2 .\nCompared to prior works, the proposed method is not\nonly dynamic over training iterations, but also dynamic over\nword positions at current timestep. Most importantly, for the\nsame token but at different position of context, the proposed\nmethod learns a different temperature vector dependent on\nits history context. The detailed architecture is illustrated in\nFigure 2, which highlights the difference between the pro-\nposed CT-MoS model and the MoS model.\nFigure 2: The architecture of the proposed CT-MoS model.\nBlack components are those the same as the MoS model,\nwhile the blue ones are the newly added ones in the proposed\napproach.\nWe adopt the same regularization techniques in MoS and\nAWD-LSTM. Our loss function thus consists of four terms:\nCross Entropy ( H), Activation Regularization (AR), Tem-\nporal Activation Regularization (TAR), and Weight Decay\n(WD). AR penalizes high values of outputs, TAR is used\nto prevent outputs from changing drastically between time\nsteps, and WD prevents the model from overﬁtting. Hereγ1,\nγ2 and γ3 are constants to scale regularization terms, andm\nis the dropout mask.\nL(Θ) =\n∑K\ni τi\nK  \nLS\nH(ˆy,y) + γ1 L2(m⊙f(x1:t−1; θ))  \nAR\n+ γ2 L2(f(x1:t−1; θ) −f(x1:t; θ))  \nTAR\n+γ3 L2(Θ)  \nWD\n(8)\nThe uniqueness in our setting is the Loss Scaling term\n(LS). Using temperature scaling makes gradients of Hdis-\nproportional to that of the other three terms, since the three\n(a) i= 1\n (b) i= 0\nFigure 3: Gradients of loss with respect to (a) logit z0 and (b) logit z1. In each ﬁgure, the x-axis is the probability pi of class i,\ny-axis is the temperature value τi of class i, and z-axis is the gradient ∂L\n∂zi\n. The colorful mesh represents the gradients when the\ncontextual temperature is applied, while the red mesh represents the case without temperature.\n(a) z0 ∈R−, i= 0\n (b) z0 ∈R−, i= 1\n (c) z0 ∈R+, i= 0\n (d) z0 ∈R+, i= 1\nFigure 4: Gradients of loss with respect to zτi. The x-axis is the probability pi of class i, y-axis is the temperature value τi of\nclass i, and z-axis is the gradient ∂L\n∂zτi\n.\nterms do regularization on parameters before temperature\nscaling. This difference leads to the unbalance between four\nobjectives. Therefore, we scaleHin order to redress the bal-\nance. A similar phenomenon is reported by Hinton, Vinyals,\nand Dean. We empirically ﬁnd that scaling Hwith the aver-\nage of the temperature vector works well in our setting.\nEffects of Contextual Temperature\nIn this section, we discuss how the proposed method effects\nthe logits z and the temperature itself τ, through illustrating\ntheir corresponding gradients. We consider a language mod-\neling task with a small vocabulary of only two words, i.e.,\n|V|= 2. In this setting, the dimensionality of logits z is 2\nand so is that of the temperature vector τ. The range of τ is\nset to [0,1], that is, (α,β) = (0,1).\nGradient of the logit. At a given input, assume that the\nground-truth token is i = 0 , thus the cross-entropy loss is\nL = −ln p0, where p0 is the model’s output probability\nfor word token i = 0 . In this case, the gradients of logits\nz are illustrated in Figure 3 (the derivation of the gradients\nis in Appendix). In Figure 3(a), we consider the gradient of\nz1 of token i = 1. When no temperature mechanism is ap-\nplied, it can be seen that the magnitude of the gradient is\nbounded within [0, 1] (as shown by the red mesh), with the\nlargest magnitude 1 (most aggressive update) happens when\nthe probability p1 is closer to 1 (note that the ideal value for\np1 should be close to 0, as the other token i= 0 is assumed\nto be the ground truth).\nOn the other hand, when the contextual temperature is ap-\nplied, the gradient can now be set to a much more substan-\ntial magnitude by setting a smaller temperature value τ1 (as\nshown by the blue mesh). The additional ﬂexibility of mag-\nnifying the gradient by temperature enables the model to be\nmore efﬁcient (or aggressive) in adjusting the parameters to\nreduce the training loss.\nGradient of the temperature. Next, we analyze how the\nmodel with contextual temperature updates the value of the\ntemperature. We recall that Equation 6 deﬁnes the formula-\ntion of the temperature. We leave the detailed derivation of\nthe gradient of the temperature in Appendix. Figure 4 visu-\nalizes the gradients ∂L/∂zτ0 and ∂L/∂zτ1 when z0 is either\npositive or negative.\nWe will use the case in Figure 4(a) (where z0 ∈R−) as\nan example to explain the effect of the gradient on the tem-\nperature. In this case, if p0 is close to 0, then we expect that\nthe model should be more aggressive to update the param-\neters (since we assume that the ground-truth class is i = 0,\nmeaning that p0 should ideally be close to 1). This aggres-\nsive response is indeed visible in the ﬁgure, showing values\nof larger magnitude when p0 →0.\nThe amount of update on the temperature τ0 also depends\non its current value. In the same Figure 4(a), let’s consider\na ﬁxed p0, say, p0 = 0.1. In this case, as described above,\nthe model wants to increase the value ofp0 to closer to 1. To\ndo that, the model will attempt to increase the term ez0/τ0 .\nSince τ0 is a positive value in [0, 1] and z0 <0 in this case,\nto maximize z0/τ0, the optimal is to have the temperature\nvalue τ0 →1. When the model is updating the value of τ0,\nif its current value is already close to 1, then the gradient\nwill be small, since it is already close to the optimal value.\nOn the other hand, if the temperature τ0 is still far from 1,\nthen the gradient will update it’s value more aggressively.\nThis behavior is exactly visualized in the ﬁgure.\nExperiments\nExperimental Setups\nWe evaluate the proposed method on two widely-used\ndatasets for language modeling: Penn Treebank (PTB) (Mar-\ncus et al. 1993; Mikolov et al. 2011) and WikiText-2 (WT2)\n(Merity et al. 2017). The PTB dataset contains 929k train-\ning, 73k validation and 82k test tokens. The vocabulary size\nis capped at 10,000 most frequent unique tokens, while the\nrest of tokens are replaced with the <unk>token. We fol-\nlow common practices to pre-process the dataset (Mikolov\net al. 2011): (a) words are lower-cased, (b) numbers are\nreplaced with “N”, (c) newlines are replaced with <eos>\nand (d) punctuation is removed. WikiText-2 is derived from\nWikipedia articles and released as a popular option to train\nlanguage models. WT2 contains 2M training tokens and a\nvocabulary of around 33k tokens. Compared to PTB, WT2\nis roughly two times larger in sample size and three times\nlarger in vocabulary size.\nWe conduct experiments on PTB and WT2 using one and\nfour 1080 Ti GPUs, respectively. The environment we use\nis PyTorch (Paszke et al. 2017). We follow the training con-\nﬁgurations as reported in the MoS paper and their github 1.\nFor both PTB and WT2, we use the same number of param-\neters as MoS. That is, we use three layers of LSTM with\nembedding sizes of 960-960-620 on PTB; and for WT2, we\nuse three layers of LSTM with embedding sizes of 1150-\n1150-650.The regularization terms, γ1,γ2, and γ3 are 2.0,\n1.0 and 1.2 e−6, respectively. The number of Softmaxes to\nbe mixed is M = 15. Furthermore, we perform normaliza-\ntion described in Equation 6 to ensure each element in τ is\npositive. We have tried several different values for αand β,\nand ﬁnd that (α,β) = (1,0.5) work best in all experiments.\nResults\nWe ﬁrst show the results on the Penn Treebank dataset in\nTable 1. We compare the proposed method with MoS and\nAWD-LSTM, and the performance is compared both with\nand without ﬁne-tuning and dynamic evaluation (Krause\net al. 2017). Since the original MoS model has approxi-\nmately 22M parameters, to make a fair comparison, we aug-\nment its number of parameters to have 24M parameters. We\n1https://github.com/zihangdai/mos\nincrease the size of each layer proportionally, giving the\nword embedding size d = 300 , and making the sizes of\nthe three LSTM layers be 1030,1030 and 670. We denote\nthis augmented model as MoS+. We show that our CT-MoS\nmodel outperforms AWD-LSTM, MoS and MoS + models\non both validation and test sets. The conclusion holds for\nthe default setting with ﬁne-tuning, the one without ﬁne-\ntuning, and the one with dynamic evaluation. Our best model\nachieved 48.12 perplexity on the validation set and 47.42 on\nthe test set, beating the best state-of-the-art model of MoS\nwith a great margin.\nWe also present Table 2 to provide the results on the\nWikiText-2 dataset. Here we see a similar pattern with\nthe PTB dataset that CT-MoS outperforms the state-of-the-\nart models. Note that when using dynamic evaluation, our\nmodel achieves comparable improvements (32%) to MoS\n(33% improvement) and AWD-LSTM (32% improvement).\nModel #Param Validation Test\nAWD-LSTM w/o ﬁnetune 24M 60.7 58.8\nAWD-LSTM 24M 60.0 57.3\nAWD-LSTM † 24M 51.6 51.1\nMoS w/o ﬁnetune 22M 58.08 55.97\nMoS 22M 56.54 54.44\nMoS † 22M 48.33 47.69\nMoS+ w/o ﬁnetune 24M 59.72 57.43\nMoS+ 24M 58.54 56.36\nMoS+† 24M 50.49 49.81\nCT-MoS w/o ﬁnetune 24M 56.95 54.69\nCT-MoS 24M 55.31 53.2\nCT-MoS† 24M 48.12 47.42\nTable 1: Performance comparison on the Penn Treebank\n(PTB) dataset. †indicates using dynamic evaluation.\nModel #Param Validation Test\nAWD-LSTM w/o ﬁnetune 33M 69.1 66.0\nAWD-LSTM 33M 68.6 65.8\nAWD-LSTM † 33M 46.4 44.3\nMoS w/o ﬁnetune 35M 66.01 63.33\nMoS 35M 63.88 61.45\nMoS † 35M 42.41 40.68\nMoS+ w/o ﬁnetune 35M 65.33 62.66\nMoS+ 35M 63.71 61.28\nMoS+ † 35M 42.73 40.74\nCT-MoS w/o ﬁnetune 45M 65.25 62.21\nCT-MoS 45M 62.89 60.13\nCT-MoS † 45M 42.88 40.96\nTable 2: Perfomrance comparison on the WikiText-2 (WT2)\ndataset. †indicates using dynamic evaluation.\nAblation Studies\nModel size. We conduct ablation studies to control the\nnumber of parameters between models in order to elimi-\nnate the effects of the parameter size on the performance.\nAs mentioned before, we have augmented the original MoS\nmodel to have the same parameter size with our model. We\nhave tried two different ways of augmentation. One is in-\ncreasing only the size of word embedding, while the other\nis increasing the size of each layer proportionally. Since\nthe latter approach performs better, we only report its per-\nformance, and denote it as MoS +. Results are illustrated\nin Table 1 and Table 2. Here we notice that MoS+ has\na similar perplexity compared to MoS, indicating that di-\nrectly increasing model parameters cannot improve the per-\nformance. Similar observation and results are also reported\nby Yang et al.. This ablation study shows that the improve-\nments brought by CT-MoS are more than the mere growth\nof parameters.\nContext-Awareness of Temperature. To further illustrate\nthe effects of the proposed method, we compare it with con-\nventional temperature scaling methods, that is, using a con-\nstant temperature. We experiment with different constant\nvalues {0.5,1,4}on the MoS model. Results in Table 3\nshow that employing contextual temperature provides better\nperformance than the conventional method. This indicates\nthat the proposed method indeed has merits on adjusting the\nmodel parameters, by considering the context and providing\na dynamic and optimized temperature value for each token.\nModel Validation Test\nMoS (τ = 0.5) 60.73 58.38\nMoS (τ = 1.0) 58.08 55.97\nMoS (τ = 4.0) 57.39 55.21\nCT-MoS 56.95 54.69\nTable 3: Effects of context-awareness. Experiments are con-\nducted on the Penn Treebank dataset without ﬁne-tuning.\nTemperature Normalization Methods. Apart from us-\ning the Softmax layer to normalize the temperature, we\nhave considered some alternative normalization methods:\n(a) λTanh(µ), which is used in (Lin et al. 2018), and gives\nthe range of temperature( 1\nλ,λ). And (b) Tanh(µ) + λ, which\ngives the range (−1 + λ,1 + λ). (c) Softmax, which gives\nthe range (σ(µ) + α)/β, and is used in our all experi-\nments. Here, µ denotes the logits of the temperature, that\nis, µ = f(x1..t−1; θ)T ·Wτ1 ·Wτ2 . Results are illustrated\nin Table 4. All three methods are evaluated on PTB, and in\nthis ablative study the experiments are conducted without ei-\nther ﬁne-tuning or dynamic evaluation for conciseness. The\nexperimental results show that applying Softmax as normal-\nization methods outperforms other methods.\nModel hyper-parameter Validation Test\nλTanh(µ) λ= 4 65.11 62.21\nTanh(µ) + λ λ= 3 61.35 58.89\n(σ(µ) + α)/β α= 1, β= 0.5 56.95 54.69\nTable 4: Different methods for temperature normalization on\nthe Penn Treebank dataset.\nAnalysis\nChanges of Temperature During Training. Early in the\nIntroduction section, we have illustrated the change of con-\ntextual temperature during the training process, in Figure\n1(a). We see that contextual temperature is capable of learn-\ning and tuning itself on a per-token basis, as training pro-\nceeds. Hence, each token has a ﬂexible temperature schedule\nthat is optimal for the model.\nBesides, we observe that tokens with high temperature\nvalues are frequently used, such as “to”, “in”, and “the”, in-\ndicating that the model is more conﬁdent in predicting them,\nand thus give them high logit values. However, since these\ncommon words don’t convey much information in general,\nthe proposed method learns to give them high temperature\nvalues so as to rein in their inﬂuence when we apply a Soft-\nmax layer. In conclusion, our method has the advantage of\ndetermining the schedule automatically on a per-token basis,\nwhich is difﬁcult to achieve in traditional constant tempera-\nture scheduling methods.\nLanguage Uncertainties. Another interesting observation\nof the proposed contextual temperature is the correlation be-\ntween a word’s relative position in a sentence and its tem-\nperature. The formulation of contextual temperature makes\nit capable to change based on not only the property of the to-\nken itself, but also the context around that token. Therefore,\na same word might have different temperature values, since\nit may be in different positions and with different context.\nFigure 1(b) shows the statistics in terms of means and\nconﬁdence intervals of temperature vectors at different posi-\ntions in a sentence. To eliminate the effects of samples being\ntoo long or too short, we analyze sentences that are longer\nthan 15 words and shorter than 25 words. For each of these\nsentences, we divide it into three disjoint segments: the ﬁrst\n5 words, the middle 5 words and the last 5 words. Then,\nthe three segments are reconstructed to form a “normalized”\nsentence. Such a pre-processing ensures positions of a to-\nken only have relative effects to the analysis, and will not be\neffected by the sentence length.\nIn Figure 1(b), we can see that the temperature value is\nhigh at beginning positions of a sentence. As the position\ngets further away from the head of the sentence, the tem-\nperature value ﬁrst has a sharp decrease, followed by an-\nother decrease at the positions near the end of the sentence.\nOur intuition on this observation is as the following: the be-\nginning positions are the region where the model has little\nconﬁdence, since there is limited information in the history.\nThe model captures this fact, and learns to utilize high tem-\nReference the bonds are rated single-a-1 by moody ’s investors service inc. and single-a bystandard & poor ’s corp. ...\nCT-MoS the bonds are rated triple-a by moody ’s and service inc. and<unk>by standard & poor ’s corp. ...\nMoS the bonds are rated <unk>by moody ’and service inc. and<unk>by s&p & poor ’s corp. ...\nCT-MoS top-4 triple-a 0.34 single-a-2 0.2 single-a-1 0.15 single-a-3 0.11\nMoS top-4 <unk>0.28 triple-a 0.27 single-a-2 0.24 single-a-1 0.1\nTemperature triple-a τ = 2 + 8.34e−5 <unk>τ = 2 + 8.60e−5\nCT-MoS top-4 standard 0.53 s&p 0.22 moody 0.17 dow 0.02\nMoS top-4 s&p 0.4 moody 0.23 standard 0.19 <unk>0.03\nTemperature standard τ = 2 + 11.2e−5 s&p τ = 2 + 11.4e−5\nTable 5: Analysis of model performance on a sample from the PTB dataset.τ denotes the temperature of a certain token, or say\nelement, in the temperature vector.\nperature values to smooth the probabilities. As the history\nbuilds up at later positions, the model becomes more conﬁ-\ndent about the next token and outputs a probability distribu-\ntion that is more spiky on the plausible tokens. The forma-\ntion of the spiky distribution is done by having a lower, or\nsay cooler, temperature.\nA ﬁnal observation on this analysis is that the conﬁdence\nintervals of temperature vectors are wider at the beginning\nbut become narrower at the end generally.\nCase Studies: Effectiveness. We present case studies on\nthe PTB dataset to visualize the effect of contextual tem-\nperature. Table 5 shows one of the samples, illustrating the\ndifferences between the Reference, outputs by CT-MoS, and\noutputs by MoS. Other samples can be found in Appendix.\nWe highlight two differences in red and blue colors, re-\nspectively. At the location highlighted in red, we see that\nboth CT-MoS and MoS fail to predict the correct answer\n“single-a-1”, which refers to a rating for securities. Instead,\nthe CT-MoS model predicts “triple-a”, referring to the high-\nest rating for securities. Though it is not the same as the\nreference, it is much closer to the answer. MoS, on the other\nhand, predicts <unk>, which deviates too much from the\nground truth. Taking a closer look at the temperature, the\nword “triple-a” has a temperature of2 + 8.34e−5, which is a\nbit smaller than that of the word<unk>, whose temperature\nis 2 + 8.6e−5. This contributes to the result that the model\nchooses “triple-a” over<unk>.\nAnother highlight in this sample, using blue color, is the\nprediction of the word “standard”. In this case, the tempera-\nture of “standard” is smaller than that of “s&p”, making the\nCT-MoS model more likely to predict the word “standard”.\nCase Study: Temperature and Token Position. Another\naspect to examine how contextual temperature works is to\nlook at the change of the temperature from a speciﬁc token\nacross different positions in a sentence. In Table 6, we take a\nsample from the PTB dataset, and highlight the occurrences\nof the word “mortgage” in red. We examine its temperature\nvalues at each occurrence. As the position changes, the pro-\nposed method chooses a different temperature value, adjust-\ning its conﬁdence of the model’s belief. As we have ana-\nlyzed in Figure 1(b), a general trend is that words appear-\ning early in a sentence get larger temperature values, while\nthose appearing near the end get smaller temperature val-\nues. In this case, the temperature at the third occurrence of\n“mortgage” is 2 + 20.1e−5, and gradually decreases at sub-\nsequent occurrences. Such decrease indicates that the model\ngains more conﬁdence in making the prediction, most likely\ndue to richer information from the longer history context.\nCT-MoS\nloan mortgage(1) corp freddie mac\nposted posted yields on 30-year mort-\ngage(2) commitments for delivery\nwithin N days <eos> N N standard\nconventional ﬁxed-rate mortgages(3)\nN N N rate rate capped one-year\nadjustable rate mortgages(4) <eos>\nsource telerate systems inc <eos>fed-\neral national mortgage(5) association\nfannie mae posted posted yields on N\nyear mortgage(6) commitments for\ndelivery within N days priced at par N\nN N standard conventional ﬁxed-rate\nmortgages(7) N ...\nTemperature τ\n(1) 2 + 18.9e−5 (2) 2 + 19.3e−5\n(3) 2 + 20.1e−5 (4) 2 + 19.2e−5\n(5) 2 + 18.9e−5 (6) 2 + 19.2e−5\n(7) 2 + 18.2e−5\nTable 6: Analysis of the temperature value for one speciﬁc\nword but at different positions in a sentence.\nConclusion and Future Work\nIn this paper, we have proposed the contextual temperature\nfor training language models. The proposed model is param-\neterized using a deep neural network, and learns an optimal\ntemperature for each individual class, i.e., each token in vo-\ncabulary, based on the history of the context of each token.\nExperiments on language modeling datasets show that the\nproposed models achieve signiﬁcantly better performances\nthan state-of-the-art models. Additionally, our model is ca-\npable of generating text that has a higher semantic represen-\ntation. In the future, our work opens up new research direc-\ntions along the line of fully automated temperature mecha-\nnism to explore the implementation of context-aware tem-\nperature in various NLP tasks, such as summarization, ma-\nchine translation, and dialogue generation.\nAppendix\nPartial Derivatives of Loss to Logits\nTake the case of two classes as example, assume that the\nground-truth class is i= 0. In this case, the lossLis −ln p0,\nwhere p0 is the probability of class 0 output by the model.\nThe probabilities of the two classes are p = σ(z ⊘τ) =\n[p0,p1]. Let u = z ⊘τ = [u0,u1], and ui = zi/τi. Then,\nwe have\npi = eui\neu0 + eu1\n. (9)\nτ is deﬁned in Equation 6, and is essentially σ(zτ). So,\nτi = ezτi\nezτ0 + ezτ1\n. (10)\nThe gradients of the loss with respect to logits z0 and z1\nare\n∂L\n∂zi\n= ∂(−ln p0)\n∂zi\n=\n{ (pi −1) 1\nτi\ni= 0\npi 1\nτi\ni̸= 0 (11)\nThe gradient of zτ0 is calculated as below\n∂L\n∂zτ0\n= ∂L\n∂p0\n∂p0\n∂u0\n∂u0\n∂τ0\n∂τ0\n∂zτ0\n+ ∂L\n∂p0\n∂p0\n∂u1\n∂u1\n∂τ1\n∂τ1\n∂zτ0\n= −p1\n−z0\nτ2\n0\nezτ0 +zτ1\n(ezτ0 + ezτ1 )2 + p1\n−z1\nτ2\n1\n−ezτ0 +zτ1\n(ezτ0 + ezτ1 )2\n= 1\nτ0\np1z0τ1 + 1\nτ1\np1z1τ0\n(12)\nSimilarly, the gradient of zτ1 is calculated as\n∂L\n∂zτ1\n= ∂L\n∂p0\n∂p0\n∂u0\n∂u0\n∂τ0\n∂τ0\n∂zτ1\n+ ∂L\n∂p0\n∂p1\n∂u1\n∂u1\n∂τ1\n∂τ1\n∂zτ1\n= −p1\n−z0\nτ2\n0\n−ezτ0 +zτ1\n(ezτ0 + ezτ1 )2 + p1\n−z1\nτ2\n1\nezτ0 +zτ1\n(ezτ0 + ezτ1 )2\n= −1\nτ0\np1z0τ1 − 1\nτ1\np1z1τ0\n(13)\nCase Studies: Effectiveness\nIn Table 7, we provide with more examples on the PTB\ndataset. The difference between CT-MoS and MoS are high-\nlighted in red. In the ﬁrst sample, we see from the red posi-\ntions that, by appropriately learning the temperature values,\nthe proposed CT-MoS model correctly predicts the token\n“results”, while the MoS model predicts “treasury”, which\ndiffers from the ground truth.\nIn the second example, we illustrate outputs of a speciﬁc\ntoken for both the CT-MoS and MoS model. As shown in\nthe example, CT-MOS predicts the same token “loss” as the\nreference sentence. Temperature analysis shows that “loss”\nhas a slightly smaller temperature than “$”, scaling its prob-\nability to much larger.\nWe can see similar patterns in the third example. CT-MOS\npredicts the same token “nine” as the reference sentence,\nwhile MoS predicts “ﬁrst”. Temperature analysis shows that\n“nine” has a slightly smaller temperature than “ﬁrst”, scaling\nits probability to much larger. This helps CT-MoS achieve a\nbetter performance in this example.\nReference\nthese rate indications are n’t directly com-\nparable lending practices vary widely by lo-\ncation <eos>treasury bills <eos>results\nof the tuesday ...\nCT-MoS\nthese rate indications are n’t directly com-\nparable lending practices vary widely by lo-\ncation <eos>treasury bills results results\nof the monday ...\nMoS\nthese rate indications are n’t directly com-\nparable lending practices vary widely by\nlocation <eos>treasury bills results trea-\nsury of the monday ...\nCT-MoS top-2 results 0.81 treasury 0.07\nMoS top-2 treasury 0.64 results 0.09\nτ(1e−6 + 2) results 8.11 treasury 8.58\nReference\na share compared with a net loss of $ N mil-\nlion last year after a loss from discontinued\noperations ...\nCT-MoS\na share <eos>with $ loss loss of $ N mil-\nlion or year <eos> the loss of the opera-\ntions ...\nMoS a share <eos>with $ $ loss of $ N million\nor year <eos>the $ of the operations ...\nCT-MoS top-2 loss 0.24 $ 0.20\nMoS top-2 $ 0.11 loss 0.09\nτ(1e−4 + 2) loss 1.40 $ 1.62\nReference in the nine months <unk>’s net rose N N\nto $ N million ...\nCT-MoS the the nine months the said net income N\nN to $ N million ...\nMoS the the ﬁrst months the said net income N\nN to $ N million ...\nCT-MoS top-2 nine 0.17 third 0.10\nMoS top-2 ﬁrst 0.14 nine 0.12\nτ(1e−5 + 2) nine 7.37 ﬁrst 7.94\nTable 7: More samples from PTB.\nReferences\nBahdanau, D.; Cho, K.; and Bengio, Y . 2014. Neural ma-\nchine translation by jointly learning to align and translate.\narXiv preprint arXiv:1409.0473.\nBengio, Y .; Ducharme, R.; Vincent, P.; and Jauvin, C. 2003.\nA neural probabilistic language model. Journal of machine\nlearning research3(Feb): 1137–1155.\nCaccia, M.; Caccia, L.; Fedus, W.; Larochelle, H.; Pineau,\nJ.; and Charlin, L. 2018. Language GANs Falling Short. In\nNIPS Workshop.\nChen, C.; Xie, W.; Huang, W.; Rong, Y .; Ding, X.; Huang,\nY .; Xu, T.; and Huang, J. 2019. Progressive Feature Align-\nment for Unsupervised Domain Adaptation. In CVPR.\nDai, Z.; Yang, Z.; Yang, Y .; Carbonell, J.; Le, Q. V .; and\nSalakhutdinov, R. 2019. Transformer-XL: Attentive Lan-\nguage Models Beyond a Fixed-Length Context. In ACL.\nDauphin, Y . N.; Fan, A.; Auli, M.; and Grangier, D. 2017.\nLanguage Modeling with Gated Convolutional Networks. In\nProceedings of the 34th International Conference on Ma-\nchine Learning-Volume 70, 933–941. JMLR.\nGuo, C.; Pleiss, G.; Sun, Y .; and Weinberger, K. Q. 2017.\nOn Calibration of Modern Neural Netowrks. In ICML.\nHinton, G.; Vinyals, O.; and Dean, J. 2014. Distilling the\nKnowledge in a Neural Network. In NIPS.\nHochreiter, S.; and Schmidhuber, J. 1997. Long short-term\nmemory. Neural computation9(8): 1735–1780.\nHu, Z.; Yang, Z.; Liang, X.; Salakhutdinov, R.; and Xing,\nE. P. 2017. Toward controlled generation of text. In ICML.\nJang, E.; Gu, S.; and Poole, B. 2017. Categorical reparame-\nterization with gumbel-softmax. In ICLR.\nKrause, B.; Kahembwe, E.; Murray, I.; and Renals, S. 2017.\nDynamic evaluation of neural sequence models. arXiv\npreprint arXiv:1709.07432.\nKrizhevsky, A.; Sutskever, I.; and Hinton, G. E. 2012. Im-\nagenet classiﬁcation with deep convolutional neural net-\nworks. In Advances in neural information processing sys-\ntems, 1097–1105.\nLin, J.; Sun, X.; Ren, X.; Li, M.; and Su, Q. 2018. Learn-\ning When to Concentrate or Divert Attention: Self-Adaptive\nAttention Temperature for Neural Machine Translation. In\nEMNLP.\nMa, X.; Yin, P.; Liu, J.; Neubig, G.; and Hovy, E. 2017.\nSoftmax Q-Distribution Estimation for Structured Predic-\ntion: A Theoretical Interpretation for RAML. arXiv preprint\narXiv:1705.07136 .\nMarcus, M. P.; Marcinkiewicz, M. A.; ; and Santorini, B.\n1993. Building a large annotated corpus of english: The\npenn treebank. In Computational linguistics.\nMerity, S.; Keskar, N. S.; and Socher, R. 2018. Regularizing\nand Optimizing LSTM Language Models. In ICLR.\nMerity, S.; Xiong, C.; Bradbury, J.; and Socher, R. 2017.\nPointer Sentinel Mixture Models. In ICLR.\nMikolov, T.; Deoras, A.; Kombrink, S.; Burget, L.; and\nˇCernock`y, J. 2011. Empirical evaluation and combination\nof advanced language modeling techniques. In Twelfth an-\nnual conference of the international speech communication\nassociation.\nMikolov, T.; Karaﬁ´at, M.; Burget, L.; ˇCernock`y, J.; and Khu-\ndanpur, S. 2010. Recurrent neural network based language\nmodel. In Eleventh annual conference of the international\nspeech communication association.\nNorouzi, M.; Bengio, S.; Chen, Z.; Jaitly, N.; Schuster, M.;\nWu, Y .; and Schuurmans, D. 2016. Reward augmented max-\nimum likelihood for neural structured prediction. In NIPS.\nPaszke, A.; Gross, S.; Chintala, S.; Chanan, G.; Yang, E.;\nDeVito, Z.; Lin, Z.; Desmaison, A.; Antiga, L.; and Lerer,\nA. 2017. Automatic Differentiation in PyTorch. In NIPS\nAutodiff Workshop.\nYang, Z.; Dai, Z.; Salakhutdinov, R.; and Cohen, W. W.\n2018. Breaking the Softmax Bottleneck: A High-Rank RNN\nLanguage Model. In ICLR.\nZhang, X.; Yu, F. X.; Karaman, S.; Zhang, W.; and Chang,\nS.-F. 2018. Heated-up softmax embedding. arXiv preprint\narXiv:1809.04157 .\nZilly, J. G.; Srivastava, R. K.; Koutn´ık, J.; and Schmidhuber,\nJ. 2017. Recurrent Highway Networks. In ICML.",
  "topic": "Perplexity",
  "concepts": [
    {
      "name": "Perplexity",
      "score": 0.9485225677490234
    },
    {
      "name": "Treebank",
      "score": 0.7586405277252197
    },
    {
      "name": "Computer science",
      "score": 0.713462233543396
    },
    {
      "name": "Smoothness",
      "score": 0.6491586565971375
    },
    {
      "name": "Schedule",
      "score": 0.640141487121582
    },
    {
      "name": "Context (archaeology)",
      "score": 0.6369922161102295
    },
    {
      "name": "Scaling",
      "score": 0.617770254611969
    },
    {
      "name": "Trajectory",
      "score": 0.6055507659912109
    },
    {
      "name": "Vocabulary",
      "score": 0.540440022945404
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.5217429399490356
    },
    {
      "name": "Language model",
      "score": 0.4880565404891968
    },
    {
      "name": "Class (philosophy)",
      "score": 0.4820166826248169
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4237216114997864
    },
    {
      "name": "Mathematics",
      "score": 0.13139182329177856
    },
    {
      "name": "Linguistics",
      "score": 0.0860159695148468
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Dependency (UML)",
      "score": 0.0
    },
    {
      "name": "Astronomy",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Geometry",
      "score": 0.0
    }
  ],
  "institutions": [],
  "cited_by": 4
}