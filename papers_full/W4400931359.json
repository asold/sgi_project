{
  "title": "Exploring Temperature Effects on Large Language Models Across Various Clinical Tasks",
  "url": "https://openalex.org/W4400931359",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2235544936",
      "name": "Dhavalkumar Patel",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A1212158009",
      "name": "Prem Timsina",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A2009153445",
      "name": "Ganesh Raut",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A1968102139",
      "name": "Robert Freeman",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A2129914889",
      "name": "Matthew A. Levin",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A2170298636",
      "name": "GIRISH N. NADKARNI",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A1498187152",
      "name": "Benjamin S Glicksberg",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A1945837108",
      "name": "Eyal Klang",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A2235544936",
      "name": "Dhavalkumar Patel",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1212158009",
      "name": "Prem Timsina",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2009153445",
      "name": "Ganesh Raut",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1968102139",
      "name": "Robert Freeman",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2129914889",
      "name": "Matthew A. Levin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2170298636",
      "name": "GIRISH N. NADKARNI",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1498187152",
      "name": "Benjamin S Glicksberg",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1945837108",
      "name": "Eyal Klang",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4394877296",
    "https://openalex.org/W4391301614",
    "https://openalex.org/W4383501093",
    "https://openalex.org/W4378783467",
    "https://openalex.org/W4392782765",
    "https://openalex.org/W4377197101",
    "https://openalex.org/W4393867901",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4398183427",
    "https://openalex.org/W4396691546",
    "https://openalex.org/W4391953174",
    "https://openalex.org/W4386090262",
    "https://openalex.org/W4394943312",
    "https://openalex.org/W4396590979"
  ],
  "abstract": "Abstract Large Language Models (LLMs) are becoming integral to healthcare analytics. However, the influence of the temperature hyperparameter, which controls output randomness, remains poorly understood in clinical tasks. This study evaluates the effects of different temperature settings across various clinical tasks. We conducted a retrospective cohort study using electronic health records from the Mount Sinai Health System, collecting a random sample of 1283 patients from January to December 2023. Three LLMs (GPT-4, GPT-3.5, and Llama-3-70b) were tested at five temperature settings (0.2, 0.4, 0.6, 0.8, 1.0) for their ability to predict in-hospital mortality (binary classification), length of stay (regression), and the accuracy of medical coding (clinical reasoning). For mortality prediction, all modelsâ€™ accuracies were generally stable across different temperatures. Llama-3 showed the highest accuracy, around 90%, followed by GPT-4 (80-83%) and GPT-3.5 (74-76%). Regression analysis for predicting the length of stay showed that all models performed consistently across different temperatures. In the medical coding task, performance was also stable across temperatures, with GPT-4 achieving the highest accuracy at 17% for complete code accuracy. Our study demonstrates that LLMs maintain consistent accuracy across different temperature settings for varied clinical tasks, challenging the assumption that lower temperatures are necessary for clinical reasoning.",
  "full_text": null,
  "topic": "Coding (social sciences)",
  "concepts": [
    {
      "name": "Coding (social sciences)",
      "score": 0.47694721817970276
    },
    {
      "name": "Regression",
      "score": 0.42964625358581543
    },
    {
      "name": "Computer science",
      "score": 0.3938632607460022
    },
    {
      "name": "Statistics",
      "score": 0.3682750165462494
    },
    {
      "name": "Psychology",
      "score": 0.3602648377418518
    },
    {
      "name": "Medicine",
      "score": 0.3415672779083252
    },
    {
      "name": "Mathematics",
      "score": 0.188217431306839
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I98704320",
      "name": "Icahn School of Medicine at Mount Sinai",
      "country": "US"
    }
  ]
}