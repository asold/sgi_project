{
  "title": "Detect Llama - Finding Vulnerabilities in Smart Contracts Using Large Language Models",
  "url": "https://openalex.org/W4400620841",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2486886926",
      "name": "Peter Ince",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2139554617",
      "name": "Xiapu Luo",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2461895243",
      "name": "Jiangshan Yu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2108886137",
      "name": "Joseph K. Liu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2226739391",
      "name": "Xiaoning Du",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4384648639",
    "https://openalex.org/W4381826673",
    "https://openalex.org/W4378509449",
    "https://openalex.org/W2970809537",
    "https://openalex.org/W4367060825",
    "https://openalex.org/W4391877140",
    "https://openalex.org/W6846665566",
    "https://openalex.org/W4376167329",
    "https://openalex.org/W4316661173",
    "https://openalex.org/W4380993527",
    "https://openalex.org/W2539190473",
    "https://openalex.org/W1480909796",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W6675354045",
    "https://openalex.org/W4384155618",
    "https://openalex.org/W2805827286",
    "https://openalex.org/W3214421193",
    "https://openalex.org/W2908007588",
    "https://openalex.org/W4221161494",
    "https://openalex.org/W3105187050"
  ],
  "abstract": null,
  "full_text": "arXiv:2407.08969v1  [cs.CR]  12 Jul 2024\nDetect Llama - Finding Vulnerabilities in Smart\nContracts using Large Language Models\nPeter Ince 1, Xiapu Luo 2, Jiangshan Yu 3, Joseph K. Liu 1, and Xiaoning Du 1\n1 Monash University, Clayton, Australia\n{peter.ince1,jospeh.liu,xiaoning.du}@monash.edu\n2 The Hong Kong Polytechnic University, Hung Hom, Hong Kong\ncsxluo@comp.polyu.edu.hk\n3 University of Sydney, Darlington, Australia\nJiangshan.yu@sydney.edu.au\nAbstract. In this paper, we test the hypothesis that although OpenAI’s\nGPT-4 performs well generally, we can ﬁne-tune open-source models to\noutperform GPT-4 in smart contract vulnerability detectio n.\nWe ﬁne-tune two models from Meta’s Code Llama and a dataset of 17k\nprompts, Detect Llama - Foundation and Detect Llama - Instru ct, and\nwe also ﬁne-tune OpenAI’s GPT-3.5 Turbo model (GPT-3.5FT).\nWe then evaluate these models, plus a random baseline, on a te stset we\ndevelop against GPT-4, and GPT-4 Turbo’s, detection of eigh t vulnera-\nbilities from the dataset and the two top identiﬁed vulnerab ilities - and\ntheir weighted F1 scores.\nWe ﬁnd that for binary classiﬁcation (i.e., is this smart con tract vulner-\nable?), our two best-performing models, GPT-3.5FT and Dete ct Llama\n- Foundation, achieve F1 scores of 0 .776 and 0 .68, outperforming both\nGPT-4 and GPT-4 Turbo, 0 .66 and 0 .675.\nFor the evaluation against individual vulnerability ident iﬁcation, our top\ntwo models, GPT-3.5FT and Detect Llama - Foundation, both si gniﬁ-\ncantly outperformed GPT-4 and GPT-4 Turbo in both weighted F 1 for\nall vulnerabilities (0 .61 and 0 .56 respectively against GPT-4’s 0 .218 and\nGPT-4 Turbo’s 0 .243) and weighted F1 for the top two identiﬁed vul-\nnerabilities (0 .719 for GPT-3.5FT, 0 .674 for Detect Llama - Foundation\nagainst GPT-4’s 0 .363 and GPT-4 Turbo’s 0 .429).\nKeywords: Smart Contract Security · Large Language Models · Vul-\nnerability detection · Ethereum.\n1 Introduction\nOver the past few years, we have seen Decentralised Finance (DeF i) expand over\nchains and grow its usage - often measured in Total Value Locked (T vL). At its\npeak in 2022, DeFi’s TvL over all chains reached almost USD $250B, resting\nat approximately USD $54B as at November 2023[6]. With this inﬂux of money\ncomes attention to the protocols and networks of bad actors and hackers. Over\n2 Ince et al.\nthe past few years, blockchain networks have seen 148 exploits wo rth approxi-\nmately USD $4.28B[2].\nThese continued attacks highlight the need for more tools to detec t vulnera-\nbilities in smart contracts quickly with as few false positives as possible . There\nare many great tools for automated smart contract vulnerability d etection; how-\never, each category has its own challenges;\n– Static Analysis tools are fast but often produce false positives\n– Dynamic analysis tools including fuzzing and static analysis tools tend\nto be more accurate but can take a signiﬁcant amount of time to iden tify\nvulnerability\nConsequently, there is much need for a tool that encompasses th e best of\nboth static analysis and fuzzing/symbolic execution tools - that is bo th fast and\nreduces the capturing of false positives in results.\nWe have seen Large Language Models such as OpenAI’s GPT-4[27] p erform\nrelatively well for few-shot learning when it comes to detection class iﬁcation of\nthe vulnerable state of Solidity smart contracts[5].\nWe hypothesize that by training the most performant open-sourc e code-based\nLarge Language Model available with labelled Solidity smart contract v ulner-\nabilities, we can outperform GPT-4 and oﬀer a middle tool in-between static\nanalysis and fuzzing/symbolic execution.\nIn this paper, we leverage Meta’s Code Llama models[32] and ﬁne-tu ne them\non a dataset of 17,000 prompts created from a dataset of 9,252 lab elled smart\ncontracts[42] and produce two open-source models based on the Code Llama 34b\nparameter Foundation and Instruct tuned models.\nWe also ﬁne-tune OpenAI’s GPT-3.5 Turbo model[31] with a subset of 4,000\nprompts, and create a random baseline for comparison.\nWe then create a custom test set, compare the three ﬁne-tuned models with\nthe random baseline, GPT-4 and GPT-4 Turbo and analyse the result s.\nWe ﬁnd that while, in general, all the ﬁne-tuned models outperform G PT-4\nand GPT-4 Turbo - the ﬁne-tuned GPT-3.5 Turbo outperforms all o f the other\nmodels with a weighted F1 Score of 0 .61 on all eight vulnerabilities and 0 .71\non the two most accurate vulnerabilities, with the Code Llama 34b Fou ndation\nbased model performing slightly less well with a weighted F1 score of 0 .586 and\n0.674 respectively.\n1.1 Our contributions\nIn this paper, we make the following contributions to the ﬁeld of smar t contract\nsecurity;\n– We release some of the ﬁrst open-source Large Language Models f or special-\nisation as a smart contract vulnerability detection tool[16,15] (a ﬁne -tuned\nversion of Code Llama 34b models)\n– We ﬁne-tune and evaluate GPT-3.5 Turbo as a smart contract vulne rability\ndetection tool\nDetect Llama 3\n– We evaluate GPT-4 and GPT-4 Turbo as smart contract vulnerability de-\ntection tools and show that both open-source models and GPT-3.5 T urbo\ncan be ﬁne-tuned to signiﬁcantly outperform GPT-4 and GPT-4 Tur bo on\nspeciﬁc detection tasks\n– We release both our open-source models and the prompt sets used for both\ntraining[17] and evaluation[18] to allow for future research to build u pon our\nwork\n1.2 Structure\nThe remainder of this paper comprises the following sections; in sect ion 2, we\nprovide some necessary background to give context and underst anding to our\nresearch. Section 3 covers related research to our work, and se ction 4 details our\napproach for preparing our dataset and training prompts, and ﬁn e-tuning our\nmodels.\nIn section 5, we share the process and details of our model evaluat ion, and\nin section 7, we discuss some of the improvements that could be made to our\nmodels and dataset and future work.\n2 Background\nIn this section, we provide necessary background information on Detecting Vul-\nnerabilities in Smart Contracts , Detecting Vulnerabilities in Smart Contracts\nwith AI , and Generate Pre-trained Transformers (GPTs) .\n2.1 Detecting Vulnerabilities in Smart Contracts\nFor almost as long as smart contracts have existed on Ethereum, t here have been\npeople attempting to exploit vulnerabilities in the code for ﬁnancial ga ins, such\nas the DAO Attack in 2016 that caused a hard fork of both the Ethe reum chain\nand community[34].\nAs a result, we have seen both the rise of smart contract auditors (typically\nﬁrms or individuals that specialise in testing and analysing for speciﬁc v ulnera-\nbilities in smart contracts) alongside automated tools that assist wit h identifying\nvulnerabilities.\nThere are two primary categories of automated tools; these tools are often\nused with manual smart contract testing to assist in the security a ssurance of\nsmart contracts.\nStatic analysis Static analysis tools, such as Slither[10] and SmartCheck[38],\nwork via analysing the code for exploits without executing the smart contract[10].\nSome static analysis tools, such as [10] and [38], may also translate th e source\ncode into some form of intermediate representation to simplify the r epresentation\nand analysis while still maintaining overall semantics.\n4 Ince et al.\nDynamic analysis Dynamic analysis tools include both symbolic execution\ntools, such as Oyente[25], Osiris[40] and Mythril[3]; and fuzzing tools, such as\nItyFuzz[33] and ConFuzzius[39].\nDynamic analysis tools work by executing the contract in various way s; sym-\nbolic execution converts the smart contract code to representa tive symbols and\nuses a constraint solver, such as Z3[26], to determine whether or n ot there are\nany vulnerabilities. Fuzzzers, or fuzz-testing tools, use various f orms of trace\nanalysis, taint analysis, input mutation, or other techniques to gen erate input\ntransactions to the deployed smart contract.\n2.2 Detecting Vulnerabilities in Smart Contracts with AI\nThere have been several tools that have used various forms of Ar tiﬁcial Intelli-\ngence, or Machine Learning, to identify vulnerabilities in smart contr acts. Most\nAI/ML tools for detecting vulnerabilities in smart contracts start w ith a dataset\nof labelled smart contracts. These smart contracts are identiﬁed and labelled us-\ning static and dynamic analysis tools, manual identiﬁcation, or a comb ination.\nSome examples of labelled datasets are [22] and [42]. In [24], Lutz et al used\na Deep Neural Network to identify six vulnerability types with an F1 sc ore of\n96% and were able to use transfer learning to identify new vulnerabilit ies with\nan average F1 score above 90%[24].\nAlso, in [36], Tann et al use Long Short Term Memory (LSTM) and train\ntheir model on their own dataset, achieving fast, large-scale analy sis of contracts\nwith a 99% accuracy rate[36].\n2.3 Generative Pre-trained Transformers (GPTs)\nGenerative Pre-trained Transformers (GPTs) are language mode ls that are pre-\ntrained (i.e., unsupervised) on a large corpus of information, often crawled\nfrom the internet for text and general understanding or taken f rom open-source\ncode repository sites. Open-source Language Models, such as th e StarCoder\nmodels[21], also choose to open-source the repositories used in the pre-training\nphase[19].\nGPT language models can then be ”ﬁne-tuned” on speciﬁc prompt an d re-\nsponse sets. The process of ﬁne-tuning alters some of the model parameters to\nﬁt the data provided in the prompts; an example of this is OpenAI’s GP T-3.5\n(a version of which we use for our evaluation), which is a version of GP T3[1]\nthat has been ﬁne-tuned using RLHF (Reinforcement Learning fro m Human\nFeedback)[29].\nInnovations such as LORA (Low-Rank Adaption)[12] reduce the ov erhead\nof memory required for the ﬁne-tuning of large language models by s electively\nmodifying a small percentage of training parameters instead of mod ifying them\nall[12]. QLoRA (Quantized Low-Rank Adaption) builds on the world by Hu et\nal in [12] by using 4-bit quantization to further reduce the memory o verhead[7].\nThe current state-of-the-art GPT model is OpenAI’s GPT-4[27] and GPT-4\nTurbo Preview[28](sometimes referred to simply as GPT-4 Turbo in th is paper),\nDetect Llama 5\nwhich were not available for ﬁne-tuning at the time of writing this pape r and is\nclosed-source, so can only be accessed through OpenAI’s API.\n3 Related work\n3.1 LLMs for vulnerability detection\nSince the release of ChatGPT by OpenAI in late 2022, we have seen an invigo-\nration of interest in using Large Language Models for various use ca ses.\nFor smart contract vulnerability detection with LLMs, we have seen two\napproaches; the ﬁrst, by David et al, identiﬁed a set of historically v ulnerable\nsmart contracts and applied state-of-the-art (SOTA) LLMs as f ew-shot learners,\nnamely GPT-4-32k from OpenAI and Claude from Anthropic, to dete ct vulnera-\nbilities in those historical smart contracts. David et al also created some smaller\nsmart contracts for testing with speciﬁc vulnerabilities inserted[5]. In [5], David\net al found that while the best-performing model, GPT-4-32k, was able to detect\nvulnerable smart contracts with a True Positive rate of 78 .7%, however, the rate\nof correct vulnerability identiﬁcation was only 40%[5].\nThe other approach by Gai et al trained a Large Language Model o n a dataset\nof over 68 million transactions focusing on previously compromised De Fi smart\ncontracts[11]. Gai et al’s trained Language Model becomes a part o f their intru-\nsion detection system, BlockGPT[11], which seeks to identify abnormal trans-\nactions while they are in the mempool (i.e., before the application proc esses\nthem), so that the protocol can be paused before an attack can be executed on\nthe smart contract[11].\nAnother work that uses GPT for smart contract vulnerability dete ction is\n[13] by Hu et al. Hu et al propose GPTLens, a system for vulnerability detection\nusing open-ended prompting with the addition of a two-step auditor → critic\nprocess that analyses the detected vulnerabilities and ranks them based on their\ncorrectness, severity and profitability rating[13].\nTo further compare our smart contract vulnerability detection mo dels, we\nuse a modiﬁed version of GPTLens[13] and a version of their critic ana lysis\ntechnique to validate identiﬁed vulnerabilities.\n4 Approach\n4.1 Dataset selection and processing\nFor our dataset, we wanted it to meet two criteria;\n1. It should have a large number of smart contracts with vulnerabilit y labels\nfor training\n2. It should allow the process to be able to generate our test set to validate our\nmodels\n6 Ince et al.\nThe dataset that had the largest amount of Ethereum Solidity smar t con-\ntracts with vulnerability labels that we found in our investigation was ScrawlD:\nA Dataset of Real World Ethereum Smart Contracts Labelled wi th Vulnerabili-\nties[42] by Yashavant et al.\nIn [42], Yashavant et al use a suite of 5 diﬀerent tools to identify vuln erable\nsmart contracts using a majority vote approach across 8 diﬀeren t vulnerabilities[42].\nThe latest update to the dataset from [42] by Yashavant et al inclu des 9,252\nsmart contracts, 5,364 of which contain at least one vulnerability[41 ].\nProcessing The dataset from [42],[41] contains only the Ethereum addresses o f\nthe smart contracts.\nTherefore, our process to prepare the smart contracts is as fo llows;\n1. Download the smart contract code from EtherScan’s Veriﬁed Sm art Contract\nAPI[9]\n2. Remove comments and additional new lines from the smart contra cts\n3. Add vulnerability label data to each smart contract record\nFor training our models, our context window is limited (as discussed in s ec-\ntion 4.3); therefore, we measure the number of tokens using the G PT2 Tokenizer,\nsort the records and exclude the top 750 smart contracts (thos e over 7340 tokens\nin length).\nOur analysis showed that most token lengths appear to be in the ran ge\n(0,≤ 7340), with some outliers far beyond the range (with the highest ha ving\nmore than 100,000 tokens).\n4.2 Prompt strategy\nOnce we have the processed records for the smart contract, inc luding their vul-\nnerabilities, we are able to put them together with the prompts.\nWe are using the Alpaca Instruct [37] prompt style for our prompting of open\nsource models.\nWe took each of the smart contracts and their corresponding vuln erabilities\nand turned them into prompts in two styles;\n– The ﬁrst style prompt is focused on the generation of smart contr acts; both\nthose with at least 1 vulnerability (see listing 1.1) and those without an y\ndetected vulnerability (see listing 1.2).\n– The second prompt style is focused on the detection of vulnerable s mart\ncontracts; as with the previous style, with at least 1 vulnerability (s ee listing\n1.3) and no detected vulnerabilities (see listing 1.4).\nOur goal was to add an additional layer of data to the model around what\nconstitutes the particular types of vulnerability to the models by ap proaching\nthe same vulnerability from two perspectives in the training prompts .\nDetect Llama 7\nListing 1.1. Instruction-input style prompt for detection when an examp le contains 1\nor more vulnerabilities\n{\"instruction\": \"You are an expert AI system trained to assist\nwith smart contract security by analysing Solidity smart\ncontracts for vulnerabilities.\",\n\"input\": \"Please analyse the following smart contract for\nvulnerabilities: <smart contract code>\",\n\"output\": \"The provided contract has 1 or more of the following\nvulnerabilities:\n<Listed Vulnerabilities in the format SWC-ID - Vulnerability name\n>\"}\nListing 1.2. Instruction-input style prompt for detection when an examp le contains\nno vulnerabilities - only output diﬀerence shown\n{\"instruction\": \"...\",\n\"input\": \"...\",\n\"output\": \"The provided smart contract has none of the following\nvulnerabilities:\n<All Eight included vulnerabilities in the format SWC-ID -\nVulnerability name>\"}\nListing 1.3. Instruction-input style prompt for generation when a smart contract\ncontains 1 or more vulnerabilities\n{\"instruction\": \"You are an expert AI system trained to assist\nwith smart contract security by generating vulnerable and non-\nvulnerable smart contracts on the Ethereum blockchain, written\nin Solidity.\",\n\"input\": \"Generate an Ethereum smart contract written in Solidity\nthat has 1 or more of the following vulnerabilities:\n<All Eight included vulnerabilities in the format SWC-ID -\nVulnerability name>\",\n\"output\": \"<smart contract code>\"}\nListing 1.4. Instruction-input style prompt for generating a smart cont ract when\nexample contains no vulnerabilities - only input diﬀerence shown. Vulnerabilities listed\nfrom [42]\n{\"instruction\": \"...\",\n\"input\": \"Generate an Ethereum smart contract written in Solidity\nthat has none of the following vulnerabilities:\n<All Eight included vulnerabilities in the format SWC-ID -\nVulnerability name>\",\n\"output\": \"<smart contract code>\"}\n8 Ince et al.\n4.3 Model selection and training\nOne of the challenges inherent in training a Large Language Model fo r detecting\nand generating smart contract vulnerabilities is the context window (the number\nof tokens allowed in the input) and the total number of tokens (bot h input and\noutput). These challenges exist because smart contracts vary w ildly in length.\nTherefore, a language model must have a relatively large context w indow to be\nuseful for vulnerability detection.\nHowever, most state-of-the-art open-source Large Languag e Models have had\na smaller context window (usually around 2,000 tokens, as with the init ial version\nof WizardCoder[23] by Luo et al), especially those constrained by th e cost of the\nhardware (or cloud resource rental) associated with training LLMs .\nSome open-source models have a larger context window, such as th e Star-\nCoder series of models with a context window of 8,000 tokens[21]. Ho wever,\nthe model did not perform as well on evaluation metrics as other ope n-source\nmodels[21].\nOpen-source LLMs made an evolutionary leap when Meta released th eir col-\nlection of Code Llama models[32]. With [32], Rozier et al released a series of\nmodels - a foundation (aka a base), a Python-tuned, and an Instr uct-tuned\nmodel. These models were released in three sizes: 7 billion, 13 billion, and 34\nbillion parameters[32]. Not only did these models outperform many oth er LLMs\non benchmarks like HumanEval (such as Luo et al’s StarCoder models [21], but\nthey were also trained on a larger input context window of 16,000 tok ens and\nsupported up to 100,000 token context windows[32].\nThis extended content window and improved performance made Cod e Llama\nthe right base model for us.\nCode Llama For ﬁne-tuning of the Code Llama models, we used the dataset\ncreated as described in section 4.2. The ﬁnal training dataset was 1 7,000 records\nin length.\nFor training, we used a context window of 7500 tokens, three epoc hs, ten\nwarm-up steps and 20 eval steps; and to allow us to train a larger mo del on less\nGPU hardware, we used QLORA[7] and Flash Attention V2[4].\nGPT-3.5 Finetune For ﬁne-tuning of GPT-3.5 Turbo[31], we used a smaller\ndataset of 4,000 records (primarily a cost constraint). The trainin g featured only\nthe prompts for detection featured in section 4.2 and used the Cha tGPT prompt\nstyle[31] instead of the Alpaca Instruct[37] style.\nIn total, we trained a total of 16,906,389 tokens over three epoch s.\n5 Evaluation\nTo evaluate the eﬀectiveness of the models, we must create our ow n test set.\nDetect Llama 9\n5.1 Building the test data\nAs some of the tools used by Yashavant et al in [42] had not been upd ated for\nlater versions of the Solidity compiler, all of the smart contracts in t he test set\nhad to be 0 .4.x(i.e. - the version of Solidity used must be ≥ 0.4.0 and ≤ 0.4.26).\nGiven this requirement, we analysed the data on Ethereum to ﬁnd th e top\nopen-source smart contracts using version 0 .4.xand downloaded approximately\n600 smart contracts.\nWe then individually ran all of the tools used by [42] on the smart contr acts;\n1. Osiris[40]\n2. Oyente[25]\n3. Mythril[3]\n4. Slither[10]\n5. SmartCheck[38]\nSome modiﬁcations had to be made to account for diﬀerent solidity ve rsions\nin the ≥ 0.4.0 and ≤ 0.4.26 range.\nWe then processed the smart contract ﬁles using the ﬁles and proc esses by\nYashavant et al in [42] and [41].\n5.2 Setting a random baseline\nWe then created a random baseline. Each smart contract was rand omly assigned\nbetween 0 and 4 of the smart contract vulnerabilities from [42].\n5.3 Implementation\nGathering the results of the tests involved us searching for vulner abilities with\neach of the models we are testing.\nFor the Detect Llama models based on Meta’s Code Llama models[32] we use\nthe input style shown in listing 1.1 with the Alpaca Instruct[37] promp t style.\nFor our ﬁne-tuned GPT-3.5 Turbo, we use the same input style as sh own in\nlisting 1.1 with the ChatGPT prompt style[31].\nTo perform the Zero-shot GPT-4 and GPT-4 Turbo analysis, we use the\nprompt shown in listing 1.5 - the prompt uses learnings from [20] (part of the\nprompt is Think step by step [20] - in conjunction with the using the function\ncalling feature[8] to structure the analysis responses eﬃciently as JSON.\nListing 1.5. Prompt used for GPT-4 Zero-shot analysis - with prompt tunin g seen in\n[20]\nYou are a world renown smart contract auditor. You must analyze\nEthereum smart contracts to detect exploits and develop\nexample code to test the exploit to validate it. You are able\nto utilize fuzzing techniques to locate and fix weaknesses in\nthe contracts, while also understanding the concepts of\ncryptography, blockchain technology, and secure coding\npractices.\n10 Ince et al.\nThe specific exploits you MUST search for in each smart contract\nare;\n<All Eight included vulnerabilities in the format SWC-ID -\nVulnerability name>\nRules you MUST follow:\n- Be brief and to the point\n- Think step by step\n- Try your best to avoid false positives in exploit identification\n- Provide the code vulnerable code from the smart contract with\nline numbers\n- \"Status\" should be only \"No Exploit\" or \"Exploit Found\"\n5.4 Alternate technique evaluation\nGPTLens To assist in evaluating our models, we also compare them against\nresults generated using techniques from GPTLens, developed by H u et al in [13].\nHowever, as the auditing prompt in GPTLens is designed to be open-e nded\nwhile searching for vulnerabilities[13], we must add some speciﬁcations around\nthe vulnerabilities we are searching for.\nIn [13], Hu et al ﬁnd the best results with one auditor and one critic, ﬁ nding\nup to 3 vulnerabilities.\nEach smart contract is processed as follows;\n– Smart contract uses the auditor prompt from [13], modiﬁed to sear ch within\nthe 8 vulnerabilities deﬁned in the dataset[42], returning the top 3 v ulnera-\nbilities.\n– The few-shot critic prompt is run against the audit response and gr aded on\na scale of 0-10 for correctness, severity and proﬁtability[13].\n– The ranking algorithm is then run to calculate a ﬁnal score based on the\ncorrectness, severity and proﬁtability ratings returned by the critic[13].\nCritic analysis In addition to the GPTLens style analysis, we also use the\ntwo-step process of analysis → critic proposed in [13] to augment our Zero-shot\nanalysis using GPT-4 and GPT-4 Turbo.\nFor each evaluation response from our GPT-4 and GPT-4 Turbo vuln erability\ndetection, we use our critic prompt set; the system prompt is show n in listing\n1.6 with the individual prompt shown in listing 1.7. Note that our critic pr ompt\nalso uses the Think step by step from [20].\nListing 1.6. System prompt used for GPT-4/GPT-4 Turbo Critic Analysis wi th\nprompt tuning from [20]\nThe vulnerabilities and listed code combinations are likely to\ncontain mistakes. As a harsh vulnerability critic, your duty\nis to scrutinize the exploit listed and associated code and\nDetect Llama 11\nevaluate the correctness and severity of given vulnerabilities\nand associated reasoning and provide a ’confirm’ or ’reject’\nresponse with detailed feedback.\nRules you MUST follow:\n- Be brief and to the point\n- Think step by step\n- \"Status\" should only be ’No changes recommended’ when you have\nnot rejected any exploits identified and have not put any\nrejected exploits in exploits_rejected, or ’Changes\nrecommended’ if you have rejected any exploits and stored them\nin exploits_rejected\n- \"Exploits\" should contain the confirmed exploits with your\nfeedback\n- \"Exploits_rejected\" should contain the rejected exploits with\nthe reason for rejection\nListing 1.7. Example prompt for criticism of detected vulnerability ana lysis\nplease critique these exploit and code combinations for Ethereum\nsmart contracts written in Solidity:\n======== EXPLOIT 1 ========\nexploit : SWC-107 - Reentrancy\ncode : Lines 138-144:\nfunction transfer(address _to, uint _value) public whenNotPaused {\nrequire(!isBlackListed[msg.sender]);\nif (deprecated) {\nreturn UpgradedStandardToken(upgradedAddress).\ntransferByLegacy(msg.sender, _to, _value);\n} else {\nreturn super.transfer(_to, _value);\n}\n}\n<continued for each exploit>\nWe evaluated the entire test set using a modiﬁed GPTLens[13] tech nique. In\n[13], Hu et al calculate the ﬁnal score in addition to the correctness, severity\nand proﬁtability of the vulnerability.\nAs we only seek to determine whether the vulnerability analysis is corr ect\n(i.e., is the smart contract vulnerable), we focus our testing primar ily on cor-\nrectness.\n12 Ince et al.\nIn table 1, we show our evaluation of the results from GPTLens[13] with\ndiﬀerent parameters for inclusion of results. The results for DOS F 1 and Tx-\nOrigin FT have been excluded as they were all zero.\nFor the GPTLens results shown in table 1, 75 vulnerability description s were\nreturned and reclassiﬁed into the eight distinct vulnerabilities, with 2 3 unrelated\nvulnerability types excluded from reporting.\nModel Weighted\nF1\nARTHM\nF1\nLE F1 RENT\nF1\nTimeM\nF1\nTimeO\nF1\nUE F1\nGPTLens-gte1c 0.317 0.590 0.264 0.089 0.055 0.183 0.014\nGPTLens-gt1c 0.320 0.601 0.251 0.092 0.063 0.187 0.021\nGPTLens-gt2c 0.307 0.603 0.213 0.084 0.070 0.197 0.023\nGPTLens-gt3c 0.317 0.608 0.201 0.094 0.045 0.269 0.025\nGPTLens-gt4c 0.305 0.603 0.180 0.095 0.000 0.219 0.026\nGPTLens-gt5c 0.310 0.609 0.160 0.095 0.000 0.250 0.028\nGPTLens-gt5f-\ngt5c\n0.297 0.608 0.159 0.095 0.000 0.095 0.037\nGPTLens-gt6c 0.278 0.571 0.175 0.115 0.000 0.130 0.034\nGPTLens-gt7c 0.200 0.433 0.153 0.111 0.000 0.000 0.000\nTable 1. F1 Scores of GPTLens analysis using GPT-4 Turbo\nThe model abbreviations shown in table 1 are as follows;\n– GPTLens-gte1c - results including vulnerabilities\nwith correctness ≥ 1\n– GPTLens-gt1c - results including vulnerabilities\nwith correctness > 1\n– GPTLens-gt2c - results including vulnerabilities\nwith correctness > 2\n– GPTLens-gt3c - results including vulnerabilities\nwith correctness > 3\n– GPTLens-gt4c - results including vulnerabilities\nwith correctness > 4\n– GPTLens-gt5c - results including vulnerabilities\nwith correctness > 5\n– GPTLens-gt5f-gt5c - results including vulnerabilities\nwith final score >5 and correctness > 5\n– GPTLens-gt6c - results including vulnerabilities\nwith correctness > 6\n– GPTLens-gt7c - results including vulnerabilities\nwith correctness > 7\nWe can see from table 1 that the results are relatively similar (as meas ured\nby Weighted F1 ) for a correctness score [ ≥ 1,≤ 6].\nFor the rest of this paper, when we refer to GPTLens, we are referring to the\nbest-performing conﬁguration from table 1, GPTLens-gt1c.\nDetect Llama 13\n5.5 Evaluation Metrics\nAs there are eight potential vulnerabilities, we use a combination of m etrics to\nevaluate how our models performed.\nBinary Classiﬁcation The score is based on a binary result of whether it\npredicted that the smart contract had a vulnerability correctly.\nClassiﬁcation Performance Measures We use the calculated Accuracy, Pre-\ncision, Recall, and F1 Score to evaluate the models’ performance.\nWe also take a weighted F1 Score to measure the eﬀectiveness over all.\n6 Results analysis\nIn the following tables the models and vulnerabilities are largely repres ented as\nabbreviations.\n6.1 Abbreviation guide\nThe names included in the tables are listed below.\nModels\n– DL-Foundation - Detect Llama - Foundation - this model was ﬁne-tuned\non the full 17,000 record dataset and uses Meta’s 34b parameter C ode Llama\nFoundation model[32]\n– DL-Instruct - Detect Llama - Instruct - this model was also ﬁne-tuned on\nthe full dataset; however, it uses the Instruct trained variant o f Meta’s 34b\nparameter Code Llama model[32]\n– GPT-4 - GPT-4 Zero-shot Analysis - OpenAI’s GPT-4 Model[27] with a\nspeciﬁc prompt identifying what to look for (seen in listing 1.5) using th e\nfunction calling feature[8] to structure the data.\n– GPT-4 Turbo - GPT-4 Turbo Zero-shot Analysis - OpenAI’s GPT-4 Turbo\nModel[28] with a speciﬁc prompt identifying what to look for (seen in list ing\n1.5) using the function calling feature[8] to structure the data.\n– GPT-4 Critic - GPT-4 with Critic Step from [13] - results from GPT-4\nprocessed using an additional critic analysis step using listing 1.6 and 1 .7.\n– GPT-4 Turbo Critic - GPT-4 Turbo with Critic Step from [13] - results\nfrom GPT-4 Turbo processed using an additional critic analysis step using\nlisting 1.6 and 1.7.\n– GPT-3.5FT - GPT-3.5 Turbo Fine-tune - OpenAI’s GPT-3.5 Turbo[31]\nﬁne-tuned with the 4,000 record detection dataset.\n– GPTLens - Best performing GPTLens[13] ranking - the best performing\nranking from table 1.\n– Random - Random baseline - a randomly generated baseline for comparison.\n14 Ince et al.\nVulnerabilities originally from [42] by Yashavant et al.\n– LE - Locked Ether\n– ARTHM - Arithmetic (Integer Overﬂow and Underﬂow)\n– DOS - Denial of Service\n– RENT - Reentrancy\n– TimeM - Time Manipulation (Block values as a proxy for time)\n– TimeO - Timestamp Ordering (Transaction Order Dependence)\n– Tx-Origin - Authorization through tx.origin\n– UE - Unhandled Exception (Unchecked Call Return Value)\nTable 2. Binary Vulnerability Classiﬁcation results\nModel Precision Recall F1 Speciﬁcity Accuracy\nDL-\nFoundation\n0.517 0.993 0.68 0.023 0.521\nDL-Instruct 0.774 0.443 0.563 0.864 0.648\nGPT-4 0.675 0.646 0.66 0.676 0.661\nGPT-4\nCritic\n0.679 0.635 0.656 0.688 0.661\nGPT-4\nTurbo\n0.629 0.727 0.675 0.549 0.640\nGPT-4\nTurbo\nCritic\n0.623 0.646 0.634 0.588 0.617\nGPT-3.5FT 0.77 0.782 0.776 0.77 0.776\nGPTLens* 0.533 0.988 0.692 0.147 0.564\nRandom 0.508 0.79 0.618 0.195 0.5\n6.2 RQ1: How eﬀective is GPT-4 at zero-shot vulnerability\ndetection?\nWe can see from our results in table 2 that for binary classiﬁcation, G PT-4 (and\nGPT-4 Turbo) achieves an F1 score of slightly better than random, moderately\nbetter than DL-Instruct, similar to DL-Foundation and moderate ly worse than\nGPT-3.5FT.\nHowever, as random performs relatively well in table 2, it is not the be st\nmeasure for us to use.\nIf we look at table 3, we can use the weighted F1 - a score from sklear n.metrics\nthat uses the number of True Positive values for each label classiﬁc ation to weight\nthe F1 score[30] - as a general guide to the eﬀectiveness of a mode l.\nWe can see that, generally, GPT-4 and GPT-4 Turbo perform only slig htly\nbetter than random in identifying the eight vulnerabilities, slightly wor se than\nDL-Instruct overall and signiﬁcantly worse than DL-Foundation a nd GPT-3.5FT\nDetect Llama 15\nmodels. However, GPT-4 performs only slightly worse than the best performer,\nGPT-3.5FT, in identifying the Arithmetic vulnerability in smart contrac ts (as\nshown in table 3).\nTable 3. F1 Scores for all models and all vulnerabilities\nModel Weighted\nF1\nARTHM\nF1\nDOS\nF1\nLE F1 RENT\nF1\nTimeM\nF1\nTimeO\nF1\nTx-\nOrigin\nF1\nUE F1\nGPT-3.5FT 0.61 0.639 0 0.81 0.185 0 0.219 0 0\nrandom 0.184 0.268 0 0.188 0.106 0.042 0.222 0 0\nDL-Foundation 0.568 0.493 0 0.36 0.048 0 0.174 0 0\nDL-Instruct 0.297 0.517 0 0.269 0.056 0 0.175 0 0\nGPT-4 0.218 0.609 0 0 0.1 0 0.17 0 0.02\nGPT-4 Turbo 0.243 0.593 0 0.133 0.073 0.070 0.172 0 0\nGPT-4 Critic 0.226 0.586 0 0.101 0 0.137 0 0 0\nGPT-4 Turbo\nCritic\n0.255 0.591 0.075 0.086 0.123 0.193 0 0 0\nGPTLens* 0.320 0.601 0.251 0.092 0.063 0.187 0 0.021 0\n6.3 RQ2: Can we ﬁne-tune an open-source model to be more\neﬀective than GPT-4?\nAs discussed earlier in our paper, we ﬁne-tuned two variants of Met a’s Code\nLlama model, Detect Llama (DL) - Foundation and DL Instruct.\nFor binary classiﬁcation (as seen in table 2), we can see that the DL- Foundation\nmodel performs similarly to GPT-4 and GPT-4 Turbo and slightly bette r than\nrandom, whereas the DL-Instruct model scores moderately wor se than random\nand the GPT-4 models when comparing F1 scores.\nHowever, when we examine the weighted F1 scores in table 3, we can s ee that\nDL-Instruct moderately outperforms the GPT-4 models and rand om, whereas\nDL-Foundation signiﬁcantly outperforms random, the GPT-4 mode ls and DL-\nInstruct with a weighted F1 of 0 .568.\n6.4 RQ3: Can we ﬁne-tune GPT-3.5 Turbo to be more eﬀective\nthan GPT-4?\nWe can see from both table 2 and table 3 that our ﬁne-tuned GPT-3.5 Turbo is\nat least moderately better than all of the other models at binary cla ssiﬁcation,\nand for general performance (using weighted F1 as a guide) perfo rms slightly\nbetter on average than our DL-Foundation model, and signiﬁcantly better than\nour DL-Instruct model, the GPT-4 models and random.\n16 Ince et al.\n6.5 RQ4: How eﬀective is our model when compared to alternate\nvulnerability detection techniques using GPT-4?\nTo evaluate against other techniques, we focus on a modiﬁed GPTLe ns[13] using\nGPT-4 Turbo Preview for Auditor and Critic, as well as an additional c ritic step\napplied to the GPT-4 and GPT-4 Turbo results.\nWe can see from table 3 that our modiﬁed GPTLens outperforms (ba sed on\nweighted F1 score) both GPT-4 and GPT-4 Turbo and our DL-Instr uct model.\nHowever, GPTLens signiﬁcantly under-performs our DL-Foundat ion model and\nthe GPT-3.5FT model with a weighted F1 of 0 .320 for GPTLens*, 0 .568 for\nDL-Foundation and 0 .61 for GPT-3.5FT.\nGPT-4 Critic and GPT-4 Turbo Critic see only a slight increase in perfor -\nmance over the models without the critic step (weighted F1 score of 0.218 vs\n0.226 for GPT-4 and GPT-4 Critic and 0 .243 and 0 .255 for GPT-4 Turbo and\nGPT-4 Turbo Critic respectively).\n6.6 Further analysis\nIf we further examine the results in table 3, we can see that the only vulner-\nabilities where many models outperform random by a signiﬁcant amoun t are\nARTHM, or Arithmetic, and LE, or Locked Ether.\nTo further identify the accuracy of the models over those two vuln erabilities,\nwe can view the results in further detail in table 4.\nTable 4. Scores for ARTHM and LE Vulnerabilities\nModel Weighted\nF1\nARTHM\nPrec.\nARTHM\nRecall\nARTHM\nF1\nARTHM\nAcc.\nLE\nPrec.\nLE Re-\ncall\nLE F1 LE\nAcc.\nGPT-3.5FT 0.719 0.65 0.63 0.639 0.77 0.823 0.798 0.81 0.926\nrandom 0.225 0.311 0.235 0.268 0.584 0.168 0.212 0.188 0.636\nDL-Foundation 0.674 0.336 0.92 0.493 0.386 0.625 0.253 0.36 0.822\nDL-Instruct 0.350 0.586 0.463 0.517 0.72 0.8 0.162 0.269 0.826\nGPT-4 0.363 0.652 0.571 0.609 0.763 0 0 0 0.785\nGPT-4 Turbo 0.429 0.550 0.642 0.593 0.714 0.148 0.121 0.133 0.688\nGPT-4 Critic 0.338 0.659 0.528 0.586 0.759 0 0 0 0.795\nGPT-4 Turbo\nCritic\n0.393 0.584 0.599 0.591 0.732 0.143 0.051 0.075 0.752\nGPTLens* 0.441 0.645 0.562 0.601 0.758 0.261 0.242 0.251 0.714\nIn table 4, we can see that the GPT-4’s performance has increased to be\nsigniﬁcantly above random and slightly above DL-Instruct (and GPT -4 Turbo\nperforming moderately better than DL-Instruct), and DL-Foun dation and GPT-\n3.5FT have increased their weighted F1 score to 0 .674 and 0 .719 respectively.\nWe can also see in table 4 that GPTLens* performs slightly better tha n GPT-\n4 Turbo, however, the GPT-4 models with an additional critic step pe rform\nslightly worse than the GPT-4 models individually.\nThe downward performance trend of the GPT-4 models with critic in t able 4\nis likely due to the increase in performance in by GPT-4 Critic and GPT-4 Turbo\nDetect Llama 17\nCritic models at identifying TimeM vulnerability than the original models ( as\nshown by the TimeM F1 Score in table 3).\n7 Discussions\nIn this section, we discuss improvements that can be made to our mo dels and\nfuture work.\n7.1 Increasing Solidity version range\nAs we mentioned earlier in our paper, due to the age of the tools used in [42],\nall of the smart contracts in our test set had to be Solidity version 0 .4.x. The\ncurrent version of Solidity is 0 .8.22[35], so for the tool to be as accurate and\nuseful in wide, general release we could update the tools used for t he majority\nvote to support later versions of Solidity.\nThis would allow us to create a new training set with smart contracts f rom\nSolidity version 0 .8.x.\n7.2 Focusing vulnerability detection\nAs we are searching for eight diﬀerent vulnerabilities with varying leve ls of suc-\ncess and accuracy (as seen in table 3), we could improve results with less well-\ndetected vulnerabilities by identifying more smart contracts that h ad only those\nvulnerabilities and adding them to the training set.\n7.3 Reducing model size\nThe Llama Code base models from Meta that were used for ﬁne-tunin g of our\nmodels are 34 billion parameters. The 34b parameter models are the la rgest;\nMeta also released 13 billion and 7 billion parameter models of the Founda -\ntion and Instruct variants used for training[32]. To serve our 34b parameter\nDetect Llama models with the popular Text Generation Inference en gine from\nHuggingface[14] requires a single A100 80gb GPU.\nFor future research, we could train smaller models with a lower param eter\ncount to see how much accuracy is lost. If a smaller model can provid e a similar\namount of accuracy once trained, it would make it faster, cheaper and more\naccessible to run.\n8 Conclusion\nIn this work, we introduce our two trained open-source models, De tect Llama\n- Foundation and Detect Llama - Instruct; ﬁne-tuned versions of Meta’s Code\nLlama[32] 34b Foundation and Instruct models, respectively.\nWe then evaluate these models against a ﬁne-tuned version of GPT- 3.5 Turbo\nand OpenAI’s GPT-4 and GPT-4 Turbo Preview.\n18 Ince et al.\nWe ﬁnd that on a weighted F1 score of all eight vulnerabilities and two b est-\npredicted vulnerabilities (across all models), our Detect Llama - Fou ndation\nmodel signiﬁcantly outperformed GPT-4 and GPT-4 Turbo, with our model\nscoring weighted F1 of 0 .568 and 0 .674 respectively compared to GPT-4’s 0 .218\nand 0 .363, and GPT-4 Turbo’s 0 .243 and 0 .429.\nOne surprise we found from our research was that our ﬁne-tuned GPT-3.5\nTurbo model outperformed all other models. Achieving a weighted F 1 score of\n0.61 for all vulnerabilities and 0 .719 for the two best-detected vulnerabilities.\nThe performance of the ﬁne-tuned GPT-3.5 Turbo model was surp rising, as\nthe ﬁne-tuning process is not listed as adding new data or abilities but rather\nImproved steerability, reliable output formatting and cus tom tone [31].\nThis research also releases our two open-source models, Detect L lama -\nFoundation[16] and Detect Llama - Instruct[15], and the training[17 ] and evaluation[18]\ndatasets; aiding to lay the groundwork for further research into the area of Large\nLanguage Models for smart contract vulnerability detection.\nAcknowledgements. This paper is supported by Australian Research Coun-\ncil (ARC) Discover Project DP220101234, partially supported by A RC under\nproject DE210100019 and Collaborative research project (H-ZG GQ).\nReferences\n1. Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Nee-\nlakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S. , Herbert-Voss, A.,\nKrueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D .M., Wu, J., Win-\nter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S. , Chess, B., Clark, J.,\nBerner, C., McCandlish, S., Radford, A., Sutskever, I., Amo dei, D.: Language Mod-\nels are Few-Shot Learners (Jul 2020). https://doi.org/10. 48550/arXiv.2005.14165,\nhttp://arxiv.org/abs/2005.14165, arXiv:2005.14165 [cs]\n2. ChainSec: Comprehensive List of DeFi Hacks & Exploits (20 23),\nhttps://chainsec.io/defi-hacks/\n3. Consensys: Mythril: Security analysis tool for EVM bytec ode (2023),\nhttps://github.com/Consensys/mythril\n4. Dao, T.: FlashAttention-2: Faster Attention with Better Parallelism and\nWork Partitioning (Jul 2023). https://doi.org/10.48550/ arXiv.2307.08691,\nhttp://arxiv.org/abs/2307.08691, arXiv:2307.08691 [cs]\n5. David, I., Zhou, L., Qin, K., Song, D., Cavallaro, L., Gerv ais, A.:\nDo you still need a manual smart contract audit? (Jun 2023).\nhttps://doi.org/10.48550/arXiv.2306.12338, http://arxiv.org/abs/2306.12338,\narXiv:2306.12338 [cs]\n6. DeﬁLlama: DeﬁLlama - Dashboard (Nov 2023), https://defillama.com/\n7. Dettmers, T., Pagnoni, A., Holtzman, A., Zettlemoyer, L. :\nQLoRA: Eﬃcient Finetuning of Quantized LLMs (May 2023).\nhttps://doi.org/10.48550/arXiv.2305.14314, http://arxiv.org/abs/2305.14314,\narXiv:2305.14314 [cs]\n8. Eleti, A., Harris, J., Kilpatrick, L.: Function calling a nd other API updates (Jul\n2023), https://openai.com/blog/function-calling-and-other- api-updates\nDetect Llama 19\n9. EtherScan.io: EtherScan.io - API - Contracts,\nhttps://docs.etherscan.io/api-endpoints/contracts\n10. Feist, J., Grieco, G., Groce, A.: Slither: A Static Analy sis Frame-\nwork For Smart Contracts. In: 2019 IEEE/ACM 2nd Internation al Work-\nshop on Emerging Trends in Software Engineering for Blockch ain (WET-\nSEB). pp. 8–15 (May 2019). https://doi.org/10.1109/WETSE B.2019.00008,\nhttp://arxiv.org/abs/1908.09878, arXiv:1908.09878 [cs]\n11. Gai, Y., Zhou, L., Qin, K., Song, D., Gervais, A.: Blockch ain Large\nLanguage Models (Apr 2023). https://doi.org/10.48550/ar Xiv.2304.12749,\nhttp://arxiv.org/abs/2304.12749, arXiv:2304.12749 [cs]\n12. Hu, E.J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wan g, S., Wang, L.,\nChen, W.: LoRA: Low-Rank Adaptation of Large Language Model s (Jun 2021),\nhttps://arxiv.org/abs/2106.09685v2\n13. Hu, S., Huang, T., ˙Ilhan, F., Tekin, S.F., Liu, L.: Large Language Model-\nPowered Smart Contract Vulnerability Detection: New Persp ectives (Oct 2023),\nhttp://arxiv.org/abs/2310.01152, arXiv:2310.01152 [cs]\n14. Huggingface: Text Generation Inference (Sep 2023),\nhttps://github.com/huggingface/text-generation-inference, original-date:\n2022-10-08T10:26:28Z\n15. Ince, P.: Detect Llama 34b Instruct Model (Sep 2023),\nhttps://huggingface.co/peterxyz/detect-llama-34b-Instruct\n16. Ince, P.: Detect Llama 34b Model (Nov 2023),\nhttps://huggingface.co/peterxyz/detect-llama-34b\n17. Ince, P.: Smart Contract Vulnerability Dataset (Sep 202 3),\nhttps://huggingface.co/datasets/peterxyz/smart-contract-vuln-detection\n18. Ince, P.: peterdouglas/detect-llama-evaluation (Apr 2024),\nhttps://github.com/peterdouglas/detect-llama-evaluation\n19. Kocetkov, D., Li, R., Ben Allal, L., Li, J., Mou, C., Mu˜ no z Ferrandis, C., Jernite,\nY., Mitchell, M., Hughes, S., Wolf, T., Bahdanau, D., von Wer ra, L., de Vries, H.:\nThe Stack: 3 TB of permissively licensed source code. Prepri nt (2022)\n20. Kojima, T., Gu, S.S., Reid, M., Matsuo, Y., Iwasawa, Y.: L arge Language Models\nare Zero-Shot Reasoners. Advances in Neural Information Pr ocessing Systems 35,\n22199–22213 (Dec 2022)\n21. Li, R., Allal, L.B., Zi, Y., Muennighoﬀ, N., Kocetkov, D. , Mou, C., Marone, M.,\nAkiki, C., Li, J., Chim, J., Liu, Q., Zheltonozhskii, E., Zhu o, T.Y., Wang, T.,\nDehaene, O., Davaadorj, M., Lamy-Poirier, J., Monteiro, J. , Shliazhko, O., Gon-\ntier, N., Meade, N., Zebaze, A., Yee, M.H., Umapathi, L.K., Z hu, J., Lipkin, B.,\nOblokulov, M., Wang, Z., Murthy, R., Stillerman, J., Patel, S.S., Abulkhanov, D.,\nZocca, M., Dey, M., Zhang, Z., Fahmy, N., Bhattacharyya, U., Yu, W., Singh, S.,\nLuccioni, S., Villegas, P., Kunakov, M., Zhdanov, F., Romer o, M., Lee, T., Timor,\nN., Ding, J., Schlesinger, C., Schoelkopf, H., Ebert, J., Da o, T., Mishra, M., Gu, A.,\nRobinson, J., Anderson, C.J., Dolan-Gavitt, B., Contracto r, D., Reddy, S., Fried,\nD., Bahdanau, D., Jernite, Y., Ferrandis, C.M., Hughes, S., Wolf, T., Guha, A.,\nvon Werra, L., de Vries, H.: StarCoder: may the source be with you! (May 2023).\nhttps://doi.org/10.48550/arXiv.2305.06161, http://arxiv.org/abs/2305.06161,\narXiv:2305.06161 [cs]\n22. Liu, Z., Qian, P., Yang, J., Liu, L., Xu, X., He, Q., Zhang, X.: Re-\nthinking Smart Contract Fuzzing: Fuzzing With Invocation O rdering and\nImportant Branch Revisiting. IEEE Transactions on Informa tion Forensics\nand Security 18, 1237–1251 (2023). https://doi.org/10.1109/TIFS.2023. 3237370,\n20 Ince et al.\nhttps://ieeexplore.ieee.org/document/10018241, conference Name: IEEE\nTransactions on Information Forensics and Security\n23. Luo, Z., Xu, C., Zhao, P., Sun, Q., Geng, X., Hu, W., Tao, C. , Ma, J.,\nLin, Q., Jiang, D.: WizardCoder: Empowering Code Large Lang uage Mod-\nels with Evol-Instruct (Jun 2023). https://doi.org/10.48 550/arXiv.2306.08568,\nhttp://arxiv.org/abs/2306.08568, arXiv:2306.08568 [cs]\n24. Lutz, O., Chen, H., Fereidooni, H., Sendner, C., Dmitrie nko, A., Sadeghi, A.R.,\nKoushanfar, F.: ESCORT: Ethereum Smart COntRacTs Vulnerab ility Detection\nusing Deep Neural Network and Transfer Learning. arXiv:210 3.12607 [cs] (Mar\n2021), http://arxiv.org/abs/2103.12607, arXiv: 2103.12607\n25. Luu, L., Chu, D.H., Olickel, H., Saxena, P., Hobor, A.: Ma k-\ning Smart Contracts Smarter. In: Proceedings of the 2016 ACM\nSIGSAC Conference on Computer and Communications Security .\npp. 254–269. CCS ’16, Association for Computing Machinery, New\nYork, NY, USA (Oct 2016). https://doi.org/10.1145/297674 9.2978309,\nhttps://doi.org/10.1145/2976749.2978309\n26. de Moura, L., Bjørner, N.: Z3: An Eﬃcient SMT Solver. In: R amakrishnan, C.R.,\nRehof, J. (eds.) Tools and Algorithms for the Construction a nd Analysis of Sys-\ntems. pp. 337–340. Lecture Notes in Computer Science, Sprin ger, Berlin, Heidel-\nberg (2008). https://doi.org/10.1007/978-3-540-78800- 3\n24\n27. OpenAI: GPT-4 Technical Report (Mar 2023).\nhttps://doi.org/10.48550/arXiv.2303.08774, http://arxiv.org/abs/2303.08774,\narXiv:2303.08774 [cs]\n28. OpenAI: New models and developer products announced at D evDay (Jun 2023),\nhttps://openai.com/blog/new-models-and-developer-pr oducts-announced-at-devday\n29. Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C .L., Mishkin, P., Zhang,\nC., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J. , Kelton, F., Miller,\nL., Simens, M., Askell, A., Welinder, P., Christiano, P., Le ike, J., Lowe, R.: Train-\ning language models to follow instructions with human feedb ack (Mar 2022).\nhttps://doi.org/10.48550/arXiv.2203.02155, http://arxiv.org/abs/2203.02155,\narXiv:2203.02155 [cs]\n30. Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O.,\nBlondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vand erplas, J., Passos, A.,\nCournapeau, D., Brucher, M., Perrot, M., Duchesnay, E.: Sci kit-learn: Machine\nlearning in Python. Journal of Machine Learning Research 12, 2825–2830 (2011)\n31. Peng, A., Wu, M., Allard, J., Heidel, S.: GPT-\n3.5 Turbo ﬁne-tuning and API updates (Aug 2023),\nhttps://openai.com/blog/gpt-3-5-turbo-fine-tuning-a nd-api-updates\n32. Rozi` ere, B., Gehring, J., Gloeckle, F., Sootla, S., Gat , I., Tan, X.E., Adi, Y., Liu, J.,\nRemez, T., Rapin, J., Kozhevnikov, A., Evtimov, I., Bitton, J., Bhatt, M., Ferrer,\nC.C., Grattaﬁori, A., Xiong, W., D´ efossez, A., Copet, J., A zhar, F., Touvron, H.,\nMartin, L., Usunier, N., Scialom, T., Synnaeve, G.: Code Lla ma: Open Foundation\nModels for Code (Aug 2023), https://arxiv.org/abs/2308.12950v2\n33. Shou, C., Tan, S., Sen, K.: ItyFuzz: Snapshot-Based Fuzz er for\nSmart Contract. In: Proceedings of the 32nd ACM SIGSOFT In-\nternational Symposium on Software Testing and Analysis. pp . 322–\n333. ISSTA 2023, Association for Computing Machinery, New\nYork, NY, USA (Jul 2023). https://doi.org/10.1145/359792 6.3598059,\nhttps://dl.acm.org/doi/10.1145/3597926.3598059\nDetect Llama 21\n34. Siegel, D.: Understanding The DAO Attack (Jun 2016),\nhttps://www.coindesk.com/learn/understanding-the-dao-attack/ , section:\nLearn\n35. Solidity Team: Solidity 0.8.22 Release Announcement (O ct 2023),\nhttps://soliditylang.org/blog/2023/10/25/solidity-0.8.22-release-announcement\n36. Tann, W.J.W., Han, X.J., Gupta, S.S., Ong, Y.S.: Towards Safer Smart Contracts:\nA Sequence Learning Approach to Detecting Security Threats . arXiv:1811.06632\n[cs] (Jun 2019), http://arxiv.org/abs/1811.06632, arXiv: 1811.06632\n37. Taori, R., Gulrajani, I., Zhang, T., Dubois, Y., Guestri n, C., Liang, P.,\nHashimoto, T.B.: Alpaca: A Strong, Replicable Instruction -Following Model,\nhttps://crfm.stanford.edu/2023/03/13/alpaca.html\n38. Tikhomirov, S., Voskresenskaya, E., Ivanitskiy, I., Ta khaviev, R.,\nMarchenko, E., Alexandrov, Y.: SmartCheck: static analysi s of ethereum\nsmart contracts. In: Proceedings of the 1st International W ork-\nshop on Emerging Trends in Software Engineering for Blockch ain.\npp. 9–16. WETSEB ’18, Association for Computing Machinery, New\nYork, NY, USA (May 2018). https://doi.org/10.1145/319411 3.3194115,\nhttps://dl.acm.org/doi/10.1145/3194113.3194115\n39. Torres, C.F., Iannillo, A.K., Gervais, A., State, R.: Co nFuzzius: A Data\nDependency-Aware Hybrid Fuzzer for Smart Contracts (Mar 20 21),\nhttp://arxiv.org/abs/2005.12156, arXiv:2005.12156 [cs]\n40. Torres, C.F., Sch¨ utte, J., State, R.: Osiris: Hunting f or Integer Bugs in Ethereum\nSmart Contracts. In: Proceedings of the 34th Annual Compute r Security Applica-\ntions Conference. pp. 664–676. ACSAC ’18, Association for C omputing Machin-\nery, New York, NY, USA (Dec 2018). https://doi.org/10.1145 /3274694.3274737,\nhttps://dl.acm.org/doi/10.1145/3274694.3274737\n41. Yashavant, C.S.: ScrawlD: A Dataset of Real World Ethere um Smart Contracts\nLabelled with Vulnerabilities (Sep 2023), https://github.com/sujeetc/ScrawlD,\noriginal-date: 2022-03-04T16:42:58Z\n42. Yashavant, C.S., Kumar, S., Karkare, A.: ScrawlD: A Data set of Real\nWorld Ethereum Smart Contracts Labelled with Vulnerabilit ies (Feb 2022).\nhttps://doi.org/10.48550/arXiv.2202.11409, http://arxiv.org/abs/2202.11409,\narXiv:2202.11409 [cs]",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8645751476287842
    },
    {
      "name": "Programming language",
      "score": 0.4314382076263428
    },
    {
      "name": "Natural language processing",
      "score": 0.32167619466781616
    }
  ],
  "institutions": [],
  "cited_by": 7
}