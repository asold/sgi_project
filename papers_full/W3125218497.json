{
    "title": "An Explainable Transformer-Based Deep Learning Model for the Prediction of Incident Heart Failure",
    "url": "https://openalex.org/W3125218497",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2751608690",
            "name": "Shishir Rao",
            "affiliations": [
                "University of Oxford"
            ]
        },
        {
            "id": "https://openalex.org/A2898879642",
            "name": "Yikuan Li",
            "affiliations": [
                "University of Oxford"
            ]
        },
        {
            "id": "https://openalex.org/A2127490300",
            "name": "Rema Ramakrishnan",
            "affiliations": [
                "University of Oxford"
            ]
        },
        {
            "id": "https://openalex.org/A2186042737",
            "name": "Abdelaali Hassaine",
            "affiliations": [
                "University of Oxford"
            ]
        },
        {
            "id": "https://openalex.org/A2237919805",
            "name": "Dexter Canoy",
            "affiliations": [
                "University of Oxford"
            ]
        },
        {
            "id": "https://openalex.org/A1893846423",
            "name": "John Cleland",
            "affiliations": [
                "University of Glasgow"
            ]
        },
        {
            "id": "https://openalex.org/A297530023",
            "name": "Thomas Lukasiewicz",
            "affiliations": [
                "University of Oxford"
            ]
        },
        {
            "id": "https://openalex.org/A2399110041",
            "name": "Gholamreza Salimi Khorshidi",
            "affiliations": [
                "University of Oxford"
            ]
        },
        {
            "id": "https://openalex.org/A2589677415",
            "name": "Kazem Rahimi",
            "affiliations": [
                "University of Oxford"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2601031783",
        "https://openalex.org/W2972004025",
        "https://openalex.org/W2770196824",
        "https://openalex.org/W2901424910",
        "https://openalex.org/W2807593075",
        "https://openalex.org/W3000238064",
        "https://openalex.org/W2481271618",
        "https://openalex.org/W6726186668",
        "https://openalex.org/W2282821441",
        "https://openalex.org/W6739575509",
        "https://openalex.org/W6762319049",
        "https://openalex.org/W2119852447",
        "https://openalex.org/W2608320814",
        "https://openalex.org/W2944890781",
        "https://openalex.org/W3017637887",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W6766978945",
        "https://openalex.org/W4238746485",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W2804604520",
        "https://openalex.org/W2014411687",
        "https://openalex.org/W2616535083",
        "https://openalex.org/W2262148753",
        "https://openalex.org/W2946057388",
        "https://openalex.org/W3136527868",
        "https://openalex.org/W2018272155",
        "https://openalex.org/W87622087",
        "https://openalex.org/W2274923892",
        "https://openalex.org/W2071013975",
        "https://openalex.org/W2136238096",
        "https://openalex.org/W1948573329",
        "https://openalex.org/W2068310561",
        "https://openalex.org/W2510374688",
        "https://openalex.org/W2553226765",
        "https://openalex.org/W2038138438",
        "https://openalex.org/W1984011921",
        "https://openalex.org/W1592090008",
        "https://openalex.org/W2137754485",
        "https://openalex.org/W2216030004",
        "https://openalex.org/W2790571740",
        "https://openalex.org/W2944854690",
        "https://openalex.org/W4293861706",
        "https://openalex.org/W2121671360",
        "https://openalex.org/W2604294572",
        "https://openalex.org/W4385245566"
    ],
    "abstract": "Predicting the incidence of complex chronic conditions such as heart failure is challenging. Deep learning models applied to rich electronic health records may improve prediction but remain unexplainable hampering their wider use in medical practice. We aimed to develop a deep-learning framework for accurate and yet explainable prediction of 6-month incident heart failure (HF). Using 100,071 patients from longitudinal linked electronic health records across the U.K., we applied a novel Transformer-based risk model using all community and hospital diagnoses and medications contextualized within the age and calendar year for each patient's clinical encounter. Feature importance was investigated with an ablation analysis to compare model performance when alternatively removing features and by comparing the variability of temporal representations. A post-hoc perturbation technique was conducted to propagate the changes in the input to the outcome for feature contribution analyses. Our model achieved 0.93 area under the receiver operator curve and 0.69 area under the precision-recall curve on internal 5-fold cross validation and outperformed existing deep learning models. Ablation analysis indicated medication is important for predicting HF risk, calendar year is more important than chronological age, which was further reinforced by temporal variability analysis. Contribution analyses identified risk factors that are closely related to HF. Many of them were consistent with existing knowledge from clinical and epidemiological research but several new associations were revealed which had not been considered in expert-driven risk prediction models. In conclusion, the results highlight that our deep learning model, in addition high predictive performance, can inform data-driven risk factor identification.",
    "full_text": "3362 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 26, NO. 7, JUL Y 2022\nAn Explainable Transformer-Based Deep\nLearning Model for the Prediction of\nIncident Heart Failure\nShishir Rao , Yikuan Li , Rema Ramakrishnan , Abdelaali Hassaine ,D e x t e rC a n o y ,\nJohn Cleland , Thomas Lukasiewicz, Gholamreza Salimi-Khorshidi, and Kazem Rahimi\nAbstract— Predicting the incidence of complex chronic\nconditions such as heart failure is challenging. Deep learn-\ning models applied to rich electronic health records may\nimprove prediction but remain unexplainable hampering\ntheir wider use in medical practice. We aimed to develop\na deep-learning framework for accurate and yet explain-\nable prediction of 6-month incident heart failure (HF). Using\n100,071 patients from longitudinal linked electronic health\nrecords across the U.K., we applied a novel Transformer-\nbased risk model using all community and hospital di-\nagnoses and medications contextualized within the age\nand calendar year for each patient’s clinical encounter.\nFeature importance was investigated with an ablation anal-\nysis to compare model performance when alternatively re-\nmoving features and by comparing the variability of tem-\nporal representations. A post-hoc perturbation technique\nManuscript received July 21, 2021; revised December 17, 2021; ac-\ncepted January 25, 2022. Date of publication February 7, 2022; date\nof current version July 4, 2022. The work of Yikuan Li and Kazem\nRahimi was supported by British Heart Foundation (BHF) under Grant\nFS/PhD/21/29110. The work of Dexter Canoy and Kazem Rahimi was\nsupported by BHF under Grant PG/18/65/33872. The work of John\nCleland was supported in part by the National Institute of Health Re-\nsearch (NIHR) under Grant NIHRDH-NIHR130487 and in part by BHF\nunder Grant RE/18/6/34217. The work of Thomas Lukasiewicz was\nsupported in part by the Alan Turing Institute (ATI) under EPSRC Grant\nEP/N510129/1, in part by the AXA Research Fund, and in part by\nEU TAILOR Grant. The work of Kazem Rahimi was also supported in\npart by the UKRI’s Global Challenges Research Fund (GCRF) under\nGrant ES/P0110551/1, in part by the Oxford NIHR Biomedical Research\nCentre, and in part by the Oxford Martin School (OMS), University of\nOxford. (Shishir Rao and Yikuan Li contributed equally to this work.)\n(Corresponding author: Kazem Rahimi.)\nShishir Rao, Yikuan Li, Abdelaali Hassaine, and Gholamreza\nSalimi-Khorshidi are with the Nufﬁeld Department of Women’s and\nReproductive Health, University of Oxford, OX1 2JD Oxford, U.K.\n(e-mail: shishir.rao@wrh.ox.ac.uk; yikuan.li@wrh.ox.ac.uk; abdelaali.\nhassaine@wrh.ox.ac.uk; reza.khorshidi@wrh.ox.ac.uk).\nDexter Canoy and Kazem Rahimi are with the Nufﬁeld Department\nof Women’s and Reproductive Health, University of Oxford, OX1 2JD\nOxford, U.K., and also with the NIHR Oxford Biomedical Research Cen-\ntre, Oxford University Hospitals National Health Service (NHS) Founda-\ntion Trust, OX3 9DU Oxford, U.K. (e-mail: dexter.canoy@wrh.ox.ac.uk;\nkazem.rahimi@wrh.ox.ac.uk).\nRema Ramakrishnan is with the National Perinatal Epidemiology\nUnit, University of Oxford, OX1 2JD Oxford, U.K. (e-mail: rema.\nramakrishnan@npeu.ox.ac.uk).\nJohn Cleland is with the Robertson Centre for Biostatistics, Uni-\nversity of Glasgow, G12 8QQ Glasgow, U.K. (e-mail: john.cleland@\nglasgow.ac.uk).\nThomas Lukasiewicz is with the Department of Computer Sci-\nence, University of Oxford, OX1 2JD Oxford, U.K. (e-mail: thomas.\nlukasiewicz@cs.ox.ac.uk).\nDigital Object Identiﬁer 10.1109/JBHI.2022.3148820\nwas conducted to propagate the changes in the input to\nthe outcome for feature contribution analyses. Our model\nachieved 0.93 area under the receiver operator curve and\n0.69 area under the precision-recall curve on internal 5-fold\ncross validation and outperformed existing deep learning\nmodels. Ablation analysis indicated medication is impor-\ntant for predicting HF risk, calendar year is more important\nthan chronological age, which was further reinforced by\ntemporal variability analysis. Contribution analyses iden-\ntiﬁed risk factors that are closely related to HF. Many of\nthem were consistent with existing knowledge from clinical\nand epidemiological research but several new associations\nwere revealed which had not been considered in expert-\ndriven risk prediction models. In conclusion, the results\nhighlight that our deep learning model, in addition high\npredictive performance, can inform data-driven risk factor\nidentiﬁcation.\nIndex Terms— Electronic health records, heart failure,\nresearch design.\nI. I NTRODUCTION\nH\nEART failure (HF) remains a major cause of morbidity,\nmortality, and economic burden [1]. Despite recent ev-\nidence suggesting improvements in the quality of clinical care\nthat patients with HF receive, and favourable trends in prognosis\n[2], the incidence of HF has changed little [3]. Indeed, as a\nconsequence of population growth and ageing, the absolute\nburden of HF has been increasing, with incidence rates similar\nto the four most common causes of cancer combined [3]. These\nobservations reinforce the need for fuller implementation of ex-\nisting strategies for HF prevention and further investigations into\nrisk factors. Several statistical models have been developed to\npredict risk of incident HF; however, the predictive performance\nof these models has been largely unsatisfactory [1].\nThe growing availability of comprehensive clinical datasets,\nsuch as linked electronic health records (EHR) with extensive\nclinical information from a large number of individuals, to-\ngether with advances in machine learning, offer new opportu-\nnities for developing more robust risk-prediction models than\nconventional statistical approaches [4], [5]. Such data-driven\napproaches can also potentially discover new associations that\nare less dependent on expert knowledge. However, empirical\nevidence of robust prediction of complex chronic conditions,\nsuch as HF is limited. Prominent deep learning (DL) architec-\ntures have shown modest performance in large-scale, complex\nEHR datasets [6]–[8] for risk prediction of various conditions\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nRAO et al.: EXPLAINABLE TRANSFORMER-BASED DEEP LEARNING MODEL 3363\nFig. 1. Illustration of the risk prediction task. For a hypothetical patient,\nstudy entry is the start of patient medical history. And baseline marks the\nbeginning of the “follow-up” or prediction window.\nincluding HF. Due to their high level of abstraction, these DL\nmodels have typically had poor “explainability” or ability to\ndemonstrate results in a language understandable by humans.\nThis has limited their trustfulness and contribution to risk factor\ndiscoveries and wider clinical adoption [9]. Recent research has\nshown progress in explaining DL models in the ﬁelds of natural\nlanguage and computer vision and methods such as saliency map\n[10] and feature perturbation [11] have gained wide popularity.\nHowever, explainable DL with rich EHR is still in its nascency;\nhence, tailoring known methods to improve model explainability\nin the medical context is crucial.\nIn this study, we applied a state-of-the-art sequential deep\nlearning model for predicting incident HF using temporal,\nmulti-modal EHR. In addition to comparing our model to\nstate-of-the-art DL models, we investigated explainability of\nour Transformer model from three perspectives: ablation study,\ntemporal variability analysis, and post-hoc perturbation analysis\nto deliver more explainable risk prediction. The ablation study\nhighlighted the importance of modalities in EHR to HF risk\nprediction. Temporal variability analysis of the two forms of\ntemporality we encode in the model – age in months and calendar\nyear – demonstrated that the model found calendar year as an\ninformative modality. The perturbation analysis lastly provided\npost-hoc explainability to better understand risk and preventative\nfactors for incident HF.\nII. M ETHODS\nA. Dataset\nWe used U.K. Clinical Practice Research Datalink (CPRD),\none of the largest de-identiﬁed longitudinal population based-\nEHR databases nationally representative in terms of age, sex,\nand ethnicity [12]. It contains primary care data from general\npractices (GP) since 1985, and links to secondary care and\nother administrative databases [4], [12] (e.g., Hospital Episode\nStatistics [13]).\nB. Introduction to Incident HF Risk Prediction\nIn this work, we focused on predicting the risk of incident HF\nusing longitudinal EHR. As shown in Fig. 1, for each patient, we\nused all available information before the baseline for learning to\npredict the risk of incident HF within a six-month window after\nthe baseline. The incident HF was deﬁned as the ﬁrst recoded\nHF diagnosis code (adopted from Caliber code repository [14])\nfor each patient in the EHR. For patients with at least one\ndiagnosis of HF, the baseline was deﬁned as a randomly sampled\ntimestamp up to six months before the ﬁrst record of HF; our\nprocess ensured no HF diagnoses in the learning period. For\neach patient without HF, the baseline was a randomly selected\nFig. 2. Diagram of BEHRT for MLM and risk prediction. BEHRT utilizes\nencounters (diagnoses, medications), age in months, and calendar year\nannotations for EHR modelling. Predictors are represented as summed\nembeddings. “UNK”, “D#”/“M#”, and “SEP” represent unknown code,\ndiagnoses/medications, and visit separations, respectively.\ntime stamp. The study entry was the date of the earliest available\ninformation of a patient, and it was the date of GP registration\nin our case.\nC. Cohort Selection\nGP records between 1985 and 2015 that met certain quality\nstandards for research (as assessed by CPRD) with full data-\nlinkage with secondary care and from patients who are at least\n16 years old were included in our study. Afterwards, patients\nwith at least ﬁve visits were included for general representation\npre-training. This cohort included 1,609,024 patients in total and\nis referred to as dataset A. Additionally, to develop models for\npredicting incident HF, we selected a subset of dataset A with\nricher medical information. More speciﬁcally, we kept patients\nwith i) at least 10 visits to their GP or hospital, ii) at least three\nyears of records, and iii) and at least 10 unique codes recorded.\nThis led to the selection of a cohort of 100,071 patients, with\n13,050 (13%) cases of incident HF, henceforth referred to as\ndataset B.\nD. Model Architecture and Details of Model Training\nWe extended the BEHRT architecture reported by Li et al.\n[15] inspired by the Transformer [16] to model the classiﬁcation\nobjective. In brief, BEHRT captures disease/medication associ-\nations within their temporal context to bolster predictive perfor-\nmance. BEHRT works robustly with large-scale, sequential data\nand outperforms other traditional and DL models on subsequent\nvisit prediction tasks (Appendix section A “Details for BEHRT\nmodel”) [15].\nWe included encounter (disease/medication), age, and calen-\ndar year as input information. Each of the three modalities are\nrepresented by a trainable embedding matrix [15], which is a\ntwo-dimensional matrix with each instance as a vector. Each\nencounter and its respective age and calendar year layers are\nsummed to form a single predictor in the model ( Fig. 2).\nThe model was implemented using PyTorch [17]. We applied\nBayesian optimization [18] for model hyperparameter tuning on\nthe number of layers, hidden size and intermediate size. After\n3364 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 26, NO. 7, JUL Y 2022\n20 iterations of searching the parameter space, we chose the\noptimal hyperparameters for the model, with number of layers: 4,\nhidden size: 120, number of attention heads: 6, and intermediate\nsize: 108. We pre-trained BEHRT’s weights using the Masked\nLanguage Modelling [19] pre-training task using the dataset A:\nwe randomly masked some encounters in the medical history of\nthe patient and predicted the masked encounters. This task is un-\nsupervised and undertaken to let the model gain a general under-\nstanding of the predictors and their temporal relationship in the\nlongitudinal data. After pre-training the model, we implemented\nthe model for the heart failure prediction task on dataset B.\nWe also replicated two state-of-the-art DL models, Deepr [7]\nand RETAINEX [20]. Both models have been benchmarked as\nsuperior EHR prediction models and we apply them on our\ndataset and compare them directly with the BEHRT model on\nincident HF risk prediction.\nE. Ablation Study\nAblation study is a commonly used approach to provide\nexplanations for the feature importance in modelling. In this\nwork, we conducted ablation study to assess importance of\ndifferent data modalities (diagnoses (D), medications (M), age\n(A), and calendar year (Y)) by alternatively removing each of\nthem. More speciﬁcally, we devised six experiments with the\nfollowing combination of modalities as input into the models:\nD, DA, DAY , DM, DMA, and DMAY (letters corresponding to\nmodalities), and assessed how each of the additional modalities\ncan inﬂuence the model performance.\nF . Analysis of Temporal Variability Using Embedding\nSimilarity\nTemporal variability is intrinsic to EHR because the popula-\ntion, the disease pattern, and many other properties can change\nover time. Considering BEHRT modelled medical trajectory in\nthe context of time-related modalities (i.e., age and calendar\nyear), we would expect the learned representation of age and\ncalendar year can capture such information. In this work, we\napplied “cosine distance”, a commonly used distance metric, to\nmeasure the similarity between the representation of different\nages and calendar years, respectively. The larger the difference\nin the learned representations over a unit of time (age/year), the\nmore substantial the temporal variability.\nG. Model Explanation Using Post-hoc Perturbation\nWe aimed to develop ways of quantifying encounter contribu-\ntions to the prediction of incident HF, as a way of making models\nexplainable. For this, we extended a perturbation technique in-\nspired by work in language modelling [11] on summed, predictor\nembeddings to represent the disease/medication. The funda-\nmental concept is to measure change in predictive probability\nafter perturbing the input in order to indicate the contribution\nof predictors. If large perturbations of predictors minimally\nchange outcome probability, then predictors are unimportant for\nprediction. However, if minimal perturbation greatly changes\noutcome probability, the respective predictors are highly impor-\ntant. In this work, we proposed an asymmetric loss function\nto prioritize encounters that enhanced HF/non-HF predictions.\nHF and non-HF represent HF positive and negative, respectively.\nAlgorithm 1 demonstrates the general algorithm for conducting\nperturbation analyses and more details can be found in Appendix\nsection “Details of perturbation methods”.\nFig. 3. Illustration for conducting population-level encounter contribu-\ntion. We use trainable noise to understand contribution of each predictor\nto output prediction. We aggregate individual-level contribution scores\nfor a disease/medication (e.g., disease code: D1) to form population-\nlevel metrics of the same.\nThe perturbation approach is a local surrogate method that can\nonly quantify the contribution of encounters at the individual\nlevel. However, by aggregating the individual-level encounter\n(i.e., diagnosis or medication) contribution across the popula-\ntion, we can analyze an encounter’s contribution at the popula-\ntion level. In this study, we focused on the contribution of the ﬁrst\nincidence (if repetition was applicable) of a disease/medication\nin the context of age and calendar year for each patient (as shown\nin Fig. 3).\nH. Model Evaluation and Perturbation Analysis\n60%, 20%, and 20% of the patients in Dataset B were se-\nlected as training, tuning, and held-out cohorts, respectively.\nThe training and tuning cohorts were used for hyper-parameter\ntuning, and the combined tuning and held-out cohort was used\nfor conducting perturbation analysis. Furthermore, to evaluate\nthe model performance in a more robust approach, we applied\nﬁve-fold cross-validation on Dataset B and reported model\nperformance using area under the receiver operating character-\nistic (AUROC) and precision-recall curve (AUPRC) with 95%\nconﬁdence interval (CI) over ﬁve folds.\nThe perturbation analysis investigated the association be-\ntween an encounter code and HF using relative contribution\n(RC) with 95% CI [21]. It is calculated by dividing average\ncontribution ( Fig. 3 ) of the encounter code in HF patients by\nRAO et al.: EXPLAINABLE TRANSFORMER-BASED DEEP LEARNING MODEL 3365\nTABLE I\nCHARACTERISTICS OF PATIENTS IN THE TRAINING,T EST, AND\nVALIDATION SET\naverage contribution of the encounter code in non-HF patients.\nRC >1.0 and <1.0 implies the encounter code is positively\nassociated with HF and non-HF respectively.\nWe applied the perturbation analysis on patients with rela-\ntively conﬁdent predictions (predictive probability larger than\n0.8 and smaller than 0.2) and focused on encounter codes\nthat were trained sufﬁciently (with at least 5% prevalence in\nthe cohorts). Additionally, we speciﬁcally investigated some\nestablished risk factors for HF [22], [23] and then looked into\nother encounters that were positively or negatively associated\nwith HF. To understand differential contribution to HF by age\nand calendar year, we conducted contribution analyses stratiﬁed\nby age groups: (50–60], (60–65], (65–70], (70–75], (75–80] and\ncalendar year groups: [1990–1995], (1995–2000], (2000–2005],\n(2005–2010] when clinical events were ﬁrst recorded. For strat-\niﬁcation, we clarify the “(” and “]/[” represent the exclusion and\nthe inclusion, respectively.\nIII. R ESULTS\nA. Dataset Preparation\nOur dataset included diagnostic codes (299 Caliber codes\n[24]) and medications (426 codes) as well as patient age in\nmonths and calendar year. Both disease and medication codes\nwith unknown mapping were mapped to an “UNKNOWN” cate-\ngory. Of 100,071 patients for incident HF prediction (Dataset B),\nthe median age in years at baseline was 70; 1st and 3rd quartile:\n(59, 79), 52% were men, 65% had history of hypertension, 9%\na prior myocardial infarction, and 5.1% an ischemic stroke. The\nmedian follow-up duration (date of ﬁrst record to baseline) was 9\nyears. More details for training, test, and external validation set,\nas well as code and HF phenotyping processes can be found in\nTable I and Appendix section “Details of disease and medication\nphenotyping”.\nTABLE II\nMODEL PERFORMANCE\nCI: Conﬁdence Interval; bold model is best performing.\nFig. 4. Ablation study with inclusion of diagnoses (D), medications (M),\nage (A), year (Y). Model performance metrics are AUROC and AUPRC\nwith 95% conﬁdence intervals.\nB. Model Performance\nThe BEHRT model, with all four modalities (DMAY),\nshowed best performance on ﬁve-fold internal cross-validation\nwith an AUROC of 0.93 (0.926, 0.934) and AUPRC of 0.69\n(0.667, 0.713) ( Table II). BEHRT showed noticeable improve-\nment in predictive ability – approximately 2%/7% absolute\nimprovement in AUROC/AUPRC compared to RETAINEX and\nDeepr.\nC. Analysis of Ablation Study\nFig. 4 shows the results of the ablation study. It demon-\nstrates that the BEHRT model with the inclusion of medication\ndata outperforms the model with just diagnoses in both AUROC\nand AUPRC. Furthermore, utilisation of calendar year achieves\nsubstantial improvements in terms of AUROC/ AUPRC than the\nmodel with age solely, thus, indicating calendar year to be more\ninformative for contextualizing predictors than chronological\nage.\nD. Analysis of Temporal Variability\nFig. 5(a) and 5(b) show two cosine similarity [25] matrices\nfor each pair of instances in embeddings of calendar year and\nage. We chose four diseases with high occurrence in the dataset\nto ensure these embeddings were well-trained.\nCalendar year showed substantial dissimilarity across years\n(from 0 to 0.8). By contrast, the dissimilarity as a consequence of\nvariation in age in months was less pronounced (from 0 to 0.3). In\nother words, representation of diseases among individuals was\nmore sensitive to variation in year in which they were recorded\n3366 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 26, NO. 7, JUL Y 2022\nFig. 5. Age and year embedding analysis. We show cosine similarity\nmeasurement for summed embedding of diseases within different year\n(a) and age groups (b). A: depression, B: peripheral arterial disease,\nC: anxiety disorders, D: hypo or hyperthyroidism; age axis represents\nage in months from 16 to 100 years in months; year axis represents\nyear from 1988 to 2014. Lighter colours indicate higher dissimilarity and\ndarker colours, lower dissimilarity.\nFig. 6. Age-stratiﬁed RC analyses for established risk factors. X and y\naxes represent age groups and RC (mean; 95% CI). The black dotted\nline denotes 1.0 RC.\nthan to the age of the patient. This suggests that calendar year\nshows stronger temporal variability, and the latent information\nof diseases in the context of calendar year can differ across\ndifferent years, and hence, was more informative for the incident\nHF prediction than chronological age.\nE. Contribution Analysis\nWe ﬁrst investigated if BEHRT could naturally capture es-\ntablished risk factors [23] through the proposed RC metric. We\nderived RC for diseases: hypertension, atrial ﬁbrillation and ﬂut-\nter, myocardial infarction, diabetes (I,II), ischaemic stroke. For\nthese HF risk factors, the average RC was >1 both in the general\n(Table III ) as well as age-stratiﬁed analyses ( Fig. 6 /Table IV )\ndemonstrating that the BEHRT (DMAY) model associated these\ndiseases with HF. Furthermore, the RC was generally higher\nfor those aged 50–60 years and lower in older ages, implying\nlittle contribution of the risk factors individually to HF in older\nages (consistent with evidence from past epidemiological studies\n[26], [27]).\nFig. 7. Lowest age-stratiﬁed RC for medications and contextuality of\nmedications and risk factors analysis. (a), Lowest 10 RC of medications.\nx and y axis represent age groups and RC (mean; 95% CI). The black\ndotted line denotes 1.0 RC. (b), RC (mean; 95% CI) for established risk\nfactors stratiﬁed by treatment status. Black forest plot: general popula-\ntion of people with disease (column); red forest plot: those with disease\n(column) not treated with medication (row); blue forest plot: those with\ndisease (column) and treated with medication (row). Some graphs fail\nto have treated/untreated forest plot due to insufﬁcient size in subgroup\n(eg diabetes; drugs for diabetes).\nAge-stratiﬁed RC was <1 for hypertension and diabetes in\nsome age groups ( Fig. 6 ), which was unexpected given that\nthese are established risk factors for HF. We hypothesized that\ntreatments might be contextually associated with these diseases\nin older age patients and thus bias the association of these\ndiseases.\nTaking hypertension as an example: if hypertension is com-\nmonly treated with antihypertensives, and antihypertensives are\nassociated with non-HF, our perturbation analyses would yield\nthat both antihypertensives and by contextualisation, hyperten-\nsion are associated with non-HF. To test our hypothesis, we\nﬁrst investigated disease prevalence and found that 73% of pa-\ntients >65 with hypertension are treated with antihypertensives\nwhile 70% of all diabetic patients are treated with medications\nfor diabetes. Now understanding that these diseases frequently\ncontextualise with their respective treatments in older ages, we\ninvestigated if these treatments associate strongly with non-HF\n(RC <1). We found that indeed medications such as antihy-\npertensives, digoxin, and drugs for diabetes, all established\ntreatments of validated risk factors, were largely associated with\nnon-HF (Fig. 7(a)/Table VIII) [28].\nWhile Fig. 7(a) demonstrates that treatments of known risk\nfactors are associated with non-HF, to better disentangle the\nRAO et al.: EXPLAINABLE TRANSFORMER-BASED DEEP LEARNING MODEL 3367\nrelationship between risk and treated risk, we conducted strati-\nﬁed analyses on untreated and treated patients. For example, to\nunderstand the association of treated and untreated hypertension\nto HF as opposed to general hypertension, we derive RC for\ndiseases in the subgroup of patients with hypertension treated\nand untreated with antihypertensives. In Fig. 7(b), with respect to\ngeneral population (black lines), in treated patients (blue lines),\nthere is a general decrease in the RC for each disease (16 of\n19 cases) with lesser association to HF. Also, while RCs of risk\nfactors were generally attenuated in treated subgroups compared\nto untreated subgroups, RCs were most attenuated in subgroups\ntreated with antihypertensives, digoxin, and medications for\ndiabetes. In some cases, RC was not calculated for the untreated\nor treated subgroup because it failed to have enough patients for\nsubstantive calculation. Through these experiments, we show\nthat BEHRT naturally captures untreated risk factors associate\nstrongly with HF while treated risk factors are mitigated in risk\ndue to treatment and thus, appropriately associate lesser with\nHF.\nAfter validating our model’s ability to capture known risk\nfactors and the interplay between risk and treatments of risk,\nwe investigated other novel risk factors independently derived\nby the model. We found diseases like bacterial diseases, lower\nrespiratory tract infections, myocardial infarction and pleural\neffusion, and medications such as “corticosteroid /antibacterial\ndrugs”, “bronchodilators” and “acne and rosacea drugs” were all\npositively associated with HF ( Tables V and VI). Furthermore,\nthe age-stratiﬁed RC analysis for the ten (i.e., highest RC)\ndiagnoses (Fig. 8(a)) and medications ( Fig. 8(b)) most strongly\nassociated with HF showed consistent pattern as the analysis of\nthe validated risk factors implying limited discriminatory contri-\nbution of these predictors individually in older people. However,\nfor some predictors (e.g., left bundle branch block), CIs were too\nwide to allow ﬁrm conclusions about any differential RC by age\n(Tables VII and VIII).\nAdditionally, analogous to the relationship between contex-\ntualised treatments of risks and risks themselves, many of the\nmedications that showed a high RC to HF ( Fig. 8(b)) are contex-\ntualised treatments for paired diagnoses ( Fig. 8(a)). This implies\nthat the model identiﬁed diagnosis and treatment pairs that were\nat least contemporaneous and often causally associated. For\nexample, dermatitis may be treated with corticosteroids, which\nmay be linked to cardiovascular risk [29] as may be depression,\nand therefore its treatments [30]. And lower respiratory tract\ninfection, asthma and chronic obstructive lung disease are often\ntreated with “cough preparations”, ”bronchodilators” and ”an-\ntibacterial drugs” [31], [32]. This could signal delayed diagnosis\nof HF due to misattribution of HF symptoms to respiratory\ndiseases [32]. Or it might be that direct effects of drugs such\nas non-steroidal anti-inﬂammatory drugs (NSAIDs) are at least\nin part responsible for causing HF [33].\nWe saw in both ablation and temporal variability analyses\n(Results section D) that calendar year substantially effects pre-\ndiction, hence, we wish to further investigate the differential RC\nby calendar year. For presentation, we have analysed two case\nstudies of <1 RC medications depicted in Fig. 7(a): digoxin and\ntreatments for glaucoma.\nFig. 9(a) demonstrates the two medications stratiﬁed by year.\nWhile digoxin was consistently associated with non-HF across\nyear groups, the results were more heterogenous for treatment of\nglaucoma. We hypothesized that while the prescription medicine\nFig. 8. Age-stratiﬁed RC analyses for top 10 diseases (a) and medica-\ntions (b) identiﬁed by model. x and y axis represent age groups and RC\n(mean; 95% CI), respectively. RC equals to 1 (black dotted line) implies\nequal contribution to both HF and non-HF predictions.\nhad constant BNF coding across the years, the underlying drug\ncomposition might have changed around the year, 2000. So,\nwe analyse the number of times different glaucoma drugs and\ndigoxin were ﬁrst prescribed in patients from Dataset A between\nthe years 1990 and 2010 in Fig. 9(b) (not counting repeat\nprescriptions).\nWe found that throughout the 1990’s, timolol (beta blocker)\nwas a common topical treatment for glaucoma [34]. With the\nintroduction of new medications in the 2000’s, the use of oph-\nthalmic timolol started to decline [35].\nOur RC analysis in Fig. 9(a) shows that BEHRT implicitly\ndemonstrates the ability to capture this change in prescription of\nthe particular glaucoma treatment. Speciﬁcally, BEHRT identi-\nﬁes that the prevalent treatment, timolol, [36]prescribed prior to\n2000 highly associated with HF (RC >1). Timolol has known\ncardiovascular side-effects such as bradycardia with potential\nto exacerbate HF [36]. Following 2000, BEHRT identiﬁes that\nthe prevalent glaucoma treatment – namely, prostaglandin ana-\nlogues – has <1 RC. Prostaglandins and analogues such as\nprostaglandin I 2 [37], [38] and others [39] have known vasodi-\nlating properties with the potential of reducing cardiovascular\nrisk, although large-scale randomized trials to investigate pre-\nventative effects are currently lacking [37], [38].\nIn stark contrast, prescription of digoxin wanes following\n2005 ( Fig. 9(b) ). However, RC for this positive inotropic drug\nremains stable in any year strata further lending support to the\nhypothesis that digoxin could play a role in prevention of HF.\n3368 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 26, NO. 7, JUL Y 2022\nFig. 9. Y ear-stratiﬁed RC of medications. (a), RC (mean; 95% CI)\nof three medications to HF prediction stratiﬁed by year. x and y axes\nrepresent year group and RC respectively; to the black line denotes\nthe 1.0 RC. (b), frequency of drugs by components in different year\ngroups in Dataset (a). X/y represent the year group/counts of ﬁrst-time\ndrug (component) prescriptions to patients respectively. Individual drug\ncomponents are represented with bars in different colour.\nIV. D ISCUSSION\nBy incorporating large-scale routine EHR data, we developed\nand validated a model for incident HF prediction. It showed\nsuperior performance compared to state-of-the-art models, RE-\nTAINEX and Deepr. Compared to age, calendar year substan-\ntially improved predictive performance while contribution anal-\nysis demonstrated that diseases and medications were strong pre-\ndictors. Our explainable framework also conﬁrmed the relative\nimportance of established risk factors [23] and provided insights\ninto medications that might negatively/positively contribute to\nHF prediction.\nOur work has several novelties. We included many potentially\npredictive variables not previously included in epidemiological\nstudies. Although age is usually incorporated as a risk factor\nfor risk prediction [6], [20], our ablation analysis found that\nincorporating calendar year provided additional and stronger\ninformation for accurate prediction of incident HF. A potential\nexplanation was the temporal variability caused by the changes\nin medicine (e.g., the change in disease pattern, policy, or the\navailability of and the use of treatments) was substantial in the\nchanges of the calendar year. Therefore, the calendar year was an\nexpressive feature that can capture such temporal changes and\nreﬂected by the dissimilarity of year representations as shown\nin the temporal variability analysis. It is further supported by\nour perturbation analysis stratiﬁed by year. This showed that\nmedications over different years made quantitatively different\ncontributions to disease prediction, which would be missed if\ntemporal context was not included in the models. Changes in\nsuch predictors over time or more subtle changes in disease\npatterns for instance due to advances in technologies leading\nto more accurate and frequent diagnosis are well known to\nclinicians. BEHRT enables incorporation of such information\nfor better prediction.\nWith regards to encounter contribution, we discovered that\nBEHRT can independently capture the interplay between risk\nand treated risk. While BEHRT generally captured risk factors\nappropriately, in some age groups, we saw some risk factors\nassociating with non-HF. A cursory analysis might lead to\nfalse conclusions that for instance, hypertension decreases the\nrisk of HF in older age. However, this conclusion is biased\nby indication; the correct interpretation is that the medication\nserves as a proxy for hypertension, which has a strong effect\non HF incidence. Our analysis of risk and treated risk generally\ndemonstrates while risk factors associate with HF, treated risk\nattenuates that association – conclusions consistent with medical\nunderstanding of HF-risk.\nAdditionally, through both age and year stratiﬁed analysis,\nBEHRT demonstrates medications with potentially preventa-\ntive effects on HF. In the case of digoxin and prostaglandin\nanalogues, the stable RC <1 in both age and year stratiﬁcation\nsignals potentially preventative effects of these drugs. However,\nas with standard statistical models, a causal interpretation should\nbe made with great caution. Rather, our method generates hy-\npotheses, which depending on the totality of evidence from\nthis work and other sources, should provide the impetus for\nadditional conﬁrmatory studies.\nOur study has some limitations. First, the phenotyping method\nfor diagnoses maps codes to 299 disease categories[40] losing\ninformation in the original granularity of the disease encoding\nand potentially biased by an expert’s preferences. Second, during\ncohort selection, we kept patients with sufﬁcient records to make\nrobust predictions potentially compromising model generaliz-\nability for prediction in low-risk groups who have fewer clinical\nencounters. Additionally, model transferability needs further\ninvestigation since only CPRD is used in our study.\nV. C ONCLUSION\nWe developed a superior model for incident HF prediction us-\ning routine EHR providing a promising avenue for research into\nprediction of other complex conditions. Incorporating BEHRT\ninto routine EHR could alert clinicians to those at risk for more\ntargeted preventive care or recruitment into clinical trials. In\naddition, we highlight a data-driven approach for identiﬁcation\nof potential risk factors that generate new hypotheses requiring\ncausal exploration. We note there are several medications which\ncontribute negatively to HF prediction. Not only are many used\nto treat established risk factors of HF, but others have not been\ntested for such an indication and might provide a starting point\nfor drug repurposing studies. The model and analysis could be\napplied to more deeply phenotyped populations for discovery of\nnew disease mechanisms and patterns in other complex condi-\ntions.\nRAO et al.: EXPLAINABLE TRANSFORMER-BASED DEEP LEARNING MODEL 3369\nTABLE III\nRELATIVE CONTRIBUTION SCORES FOR MEDICALL YVALIDATED RISK\nFACTORS.I NT H E COLUMNS,W E HAVE HEART FAILURE (HF) PATIENT’S\nAVERAGE CONTRIBUTION SCORES,N ON-HEART FAILURE (NON-HF)\nPATIENTS AVERAGE CONTRIBUTION SCORES,R ELEVANT STANDARD\nDEVIATION MEASURES, AND RELATIVE CONTRIBUTION AND 95%\nCONFIDENCE INTERVAL FOR THESE RISK FACTORS\nTABLE IV\nAGE-STRATIFIED,R ELATIVE CONTRIBUTION AND 95% C ONFIDENCE\nINTERVALS FOR MEDICALL YVALIDATED RISK FACTORS.I NT H E COLUMNS,\nWE HAVE RC AND CI FOR FIVE AGE CATEGORIES\nAPPENDIX\nA. Details for BEHRT Model\nIn NLP literature and BERT, [19] words in sentences are con-\nsidered “tokens” and sentences are separated from one another\nwith a separation element. Similarly, we conceptualized medical\nevents such as diagnoses and medications in a doctor/hospital\nvisit as encounters (or tokens) and separate visits by a sepa-\nration element (“SEP”). Similar to the original BERT model,\nwe implemented an annotation ordering the sequential medical\nhistory data. Furthermore, we added layers of information that\ninvolve age and calendar year of each encounter. Thus, the total\ninput comprised of three layers of information for each and every\nencounter: the encounter itself (diagnoses and/or medications),\nage, and calendar year.\nB. Details of Perturbation Methods\nAdditionally to Guan et al. ’s method [11], we developed an\nasymmetric loss function to prioritize learning perturbations in\naddition to the information entropy-based loss term. Shown in\nthe equations below is the full description of the loss function\nTABLE V\nRELATIVE CONTRIBUTION SCORES FOR DISEASES THAT OCCURRED IN AT\nLEAST 5% OF THE POPULATION\nconducted over one patient’s medical history.\nalpha (y, x, s)=\n{β1,i fy =1 ,M (˜x) −s ≥ 0\nβ2,i fy =0 ,M (˜x) −s ≤ 0\nβ3, otherwise\n(1)\nL (σ)= alpha(y, x, s) ×\nE∈∥(M (x) −s)∥2λ\nn∑\ni =1\nH(˜x |s) |∈i∼N(0,σ 2\ni I)\n(2)\nwhere ˜xrepresents perturbed input encounter embeddings (orig-\ninal represented by x), n represents number of encounters in this\npatient’s medical history, s represents output state of original\ninput (without perturbation), M( ˜x) is the output state of per-\nturbed input, β1 and β2 are weight hyperparameters ( β1 <β 2);\nif β1 = β2 , then loss function is symmetric, y is heart failure la-\nbel, E∈∥M(˜x) −s∥2 represents mean squared error described in\nGuan et al. [11], alpha(y, ˜x, s) means asymmetric weight func-\ntion, λ ∑n\ni =1 H(˜x|s)|∈i∼N(0,σ2\ni I) information entropy based\nloss function described in Guan et al. [11].\nTo describe (1) and (2) in words, for heart failure patients, we\nprioritize perturbations that increases the outcome probability\nthan those that decreases it; and we prioritize the opposite for\nnon-heart failure patients. To do so, we penalize with the alpha\n( y ,x ,s )constant. Asymmetric losses are often used in scenarios\nwhere an error in one direction (perhaps positive) is more costly\nthan an error in the opposite direction[12], [24].\nThis perturbation method delivers learned ϵ = [ϵ1, ϵ2, …,\nϵn] with ϵ1 per predictor i – the trained, allowable variance\nfor the predictor, with maximum variance deﬁned by a user\ndeﬁned hyperparameter (set to 0.5 in our work). To assess\ncontribution of predictor, we transform ϵ1t o0 . 5 - ϵ1 to reﬂect\nthe inverse relationship: the lower the ϵ1, the higher contribution\nto heart failure prediction and vice-versa. This is shown as the\n3370 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 26, NO. 7, JUL Y 2022\nTABLE VI\nRELATIVE CONTRIBUTION SCORES FOR MEDICATIONS THAT OCCURRED IN\nAT LEAST 5% OF THE POPULATION\nTABLE VII\nAGE-STRATIFIED,R ELATIVE CONTRIBUTION AND 95% C ONFIDENCE\nINTERVALS FOR DISEASES THAT OCCURRED IN AT LEAST 5% OF THE TEST\nAND VALIDATION DATASET.I NT H E COLUMNS,W E HAVE RC AND CI FOR\nFIVE AGE CATEGORIES WITH LOWER BOUND AND UPPER BOUND\ntransform() function in Algorithm 1. As seen in Fig. 3 ,w eﬁ r s t\nestablish patient-level contribution, or 0.5- ϵ1 for a particular\nencounter (disease/medication) in time.\nC. Details of Disease and Medication Phenotyping\nIn our study, we used all diagnostic codes and medications\nat each encounter as well as patient age in months and calen-\ndar year. Encounters represent each individual’s time-stamped\nrecording of a diagnosis or medication. For medication specif-\nically, we included all available prescription records as new\nencounters in the dataset. Because of how CPRD records medi-\ncations in six-week increments, medications make up the largest\nnumber of encounters.\nIn the U.K., primary care and secondary care use differ-\nent coding systems for diagnosis (i.e., Read Code [41] in GP\nand 10th revision of International Statistical Classiﬁcation of\nDiseases and Related Health Problems [ICD-10] Code [42]\nin Hospital Episode Statistics). We mapped these codes us-\ning a dictionary given by CPRD. This led to 56,624 unique\ncodes, which were then mapped to 299 clinically meaningful\ndisease categories, using Caliber, a previously published and\nclinically-validated phenotyping method. [14] Medication codes\nwere classiﬁed using the British National Formulary hierar-\nchical coding format. [43] Medication data in CPRD indicate\nmedication prescription as opposed to medication retrieval or\ndispensation. We used codes at the section level prevalent in\nthe population leading to 426 unique medication group codes.\nRAO et al.: EXPLAINABLE TRANSFORMER-BASED DEEP LEARNING MODEL 3371\nTABLE VIII\nAGE-STRATIFIED,R ELATIVE CONTRIBUTION, 95% C ONFIDENCE INTERVALS\nFOR MEDICATIONS THAT OCCURRED IN AT LEAST 5% OF THE TEST,\nVALIDATION DATASET.I NT H E COLUMNS,W E HAVE RC, CI FOR FIVE AGE\nCATEGORIES WITH LOWER BOUND,U PPER BOUND\nBoth disease and medication codes with unknown mapping\nwere mapped to an “UNKNOWN” category. The “heart failure”\nphenotype is deﬁned by Caliber to be a collection of Read and\nICD-10 codes. We looked at the diagnoses codes strictly (as\nopposed to codes of historical diagnoses). The codes are found:\nhttps:// www.caliberresearch.org/ portal under the “heart fail-\nure” section using incident codes from primary (Read) and\nsecondary care (ICD-10).\nVI. D ATAAVAILABILITY\nThe data acquired for this study is available from Clinical\nPractice Research Datalink (CPRD). 1 To access the data, we re-\nfer readers to the website2 where it explains: “Access to data from\nCPRD is subject to a full licence agreement containing detailed\nterms and conditions of use. Anonymised patient datasets can\nbe extracted for researchers against speciﬁc study speciﬁcations,\nfollowing protocol approval from the Independent Scientiﬁc\nAdvisory Committee (ISAC).” Therefore, data that supports the\nﬁndings of this study was used under license, and not publicly\navailable.\nACKNOWLEDGMENT\nThe funders had no role in study design, data collection and\nanalysis, decision to publish, or preparation of the manuscript.\nThe views expressed are those of the authors and not necessarily\nthose of the OMS, the BHF, the GCRF, the NIHR, the ATI, the\nAXA Research Fund, TAILOR, or the Department of Health and\nSocial Care.\nREFERENCES\n[1] B. W. Sahle, A. J. Owen, K. L. Chin, and C. M. Reid, “Risk prediction\nmodels for incident heart failure: A systematic review of methodology\nand model performance,” J. Cardiac Failure, vol. 23, no. 9, pp. 680–687,\nSep. 2017, doi: 10.1016/j.cardfail.2017.03.005.\n[2] E. R. C. Millett and G. Salimi-Khorshidi, “Temporal trends and patterns\nin mortality after incident heart failure a longitudinal analysis of 86 000\nindividuals,”JAMA Cardiol., vol. 4, pp. 1102–1111, 2019, doi: 10.1001/ja-\nmacardio.2019.3593.\n[3] N. Conrad et al., “Temporal trends and patterns in heart failure incidence:\nA population-based study of 4 million individuals,” Lancet, vol. 391,\nno. 10120, pp. 572–580, 2018, doi: 10.1016/S0140-6736(17)32520-5.\n[4] F. Rahimian et al. , “Predicting the risk of emergency admission with\nmachine learning: Development and validation using linked electronic\nhealth records,”PLOS Med., vol. 15, no. 11, Nov. 2018, Art. no. e1002695,\ndoi: 10.1371/journal.pmed.1002695.\n[5] K. W. Johnson et al. , “Artiﬁcial intelligence in cardiology,” J.\nAmer. College Cardiol. , vol. 71, no. 23, pp. 2668–2679, 2018,\ndoi: 10.1016/j.jacc.2018.03.521.\n[6] J. R. A. Solares et al. , “Deep learning for electronic health records: A\ncomparative review of multiple deep neural architectures,” J. Biomed.\nInformat., vol. 101, 2020, Art. no. 103337. [Online]. Available: https:\n//doi.org/10.1016/j.jbi.2019.103337\n[7] P. Nguyen, T. Tran, N. Wickramasinghe, and S. Venkatesh, “Deepr: A\nconvolutional net for medical records,” IEEE J. Biomed. Health Informat. ,\nvol. 21, no. 1, pp. 22–30, Jan. 2017, doi: 10.1109/JBHI.2016.2633963.\n[8] E. Choi, M. T. Bahadori, J. A. Kulas, A. Schuetz, W. F. Stewart, and J. Sun,\n“RETAIN: An interpretable predictive model for healthcare using reverse\ntime attention mechanism,” in Proc. Int. Conf. Adv. Neural Inf. Process.\nSyst., 2016, pp. 3512–3520.\n[9] M. T. Ribeiro, S. Singh, and C. Guestrin, “‘Why should i trust you?’\nExplaining the predictions of any classiﬁer,” in Proc. ACM SIGKDD Int.\nConf. Knowl. Discov. Data Mining , 2016, vol. 13-17, pp. 1135–1144,\ndoi: 10.1145/2939672.2939778.\n1[Online]. Available: https://www.cprd.com-/Data\n2[Online]. Available: https://www.cprd.com/primary-care\n3372 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 26, NO. 7, JUL Y 2022\n[10] D. Smilkov, N. Thorat, B. Kim, F. Viégas, and M. Wattenberg, “Smooth-\nGrad: Removing noise by adding noise,” 2017. [Online]. Available: http:\n//arxiv.org/abs/1706.03825\n[11] C. Guan, X. Wang, Q. Zhang, R. Chen, D. He, and X. Xie, “Towards a\ndeep and uniﬁed understanding of deep neural models in {NLP},” in Proc.\n36th Int. Conf. Mach. Learn. , 2019, vol. 97, pp. 2454–2463. [Online].\nAvailable: http://proceedings.mlr.press/v97/guan19a.html\n[12] E. Herrett et al. , “Data resource proﬁle: Clinical practice research\ndatalink (CPRD),” Int. J. Epidemiol. , vol. 44, no. 3, pp. 827–836, 2015,\ndoi: 10.1093/ije/dyv098.\n[13] A. Herbert, L. Wijlaars, A. Zylbersztejn, D. Cromwell, and P. Hardelid,\n“Data resource proﬁle: Hospital episode statistics admitted patient care\n(HES APC),” Int. J. Epidemiol. , vol. 46, no. 4, pp. 1093–1093, 2017,\ndoi: 10.1093/ije/dyx015.\n[14] V . Kuan et al. , “A chronological map of 308 physical and mental\nhealth conditions from 4 million individuals in the English National\nHealth Service,” Lancet Digit. Health , vol. 1, no. 2, pp. e63–e77, 2019,\ndoi: 10.1016/s2589-7500(19)30012-3.\n[15] Y . Li et al., “BEHRT: Transformer for electronic health records,” Sci. Rep.,\nvol. 10, no. 1, 2020, Art. no. 7155, doi: 10.1038/s41598-020-62922-y.\n[16] A. Vaswani et al. , “Attention is all you need,” Adv. Neural Informat.\nProcess. Syst. , no. Nips, 2017. [Online]. Available: https://proceedings.\nneurips.cc/paper/2017/ﬁle/3f5ee243547dee91fbd053c1c4a845aa-\nPaper.pdf\n[17] A. Paszke et al. , “PyTorch: An imperative style, high-performance deep\nlearning library,” in Proc. Int. Conf. Neural Inf. Process. Syst. , 2019,\npp. 8026–8037.\n[18] P. I. Frazier, “Bayesian Optimization,” 2018 INFORMS Ann. Meet. , no.\nSection 5, pp. 1–22, 2018, doi: 10.1287/educ.2018.0188.\n[19] J. Devlin, M.-W. Chang, K. Lee, K. T. Google, and A. I. Lan-\nguage, “BERT: Pre-training of deep bidirectional transformers for lan-\nguage understanding,” Proc. 2019 Conf. North , pp. 4171–4186, 2019,\ndoi: 10.18653/V1/N19-1423.\n[20] B. C. Kwon et al. , “RetainVis: Visual analytics with interpretable and\ninteractive recurrent neural networks on electronic medical records,” IEEE\nTrans. Vis. Comput. Graph. , vol. 25, no. 1, pp. 299–309, Jan. 2019,\ndoi: 10.1109/TVCG.2018.2865027.\n[21] J. O. Friedrich, N. K. J. Adhikari, and J. Beyene, “The ratio of means\nmethod as an alternative to mean differences for analyzing continuous\noutcome variables in meta-analysis: A simulation study,” BMC Med. Res.\nMethodol., vol. 8, 2008, Art. no. 32, doi: 10.1186/1471-2288-8-32.\n[22] T. J. Cahill and R. K. Kharbanda, “Heart failure after myocardial infarction\nin the era of primary percutaneous coronary intervention: Mechanisms,\nincidence and identiﬁcation of patients at risk,” World J. Cardiol. ,v o l .9 ,\npp. 407–415, 2017, doi: 10.4330/wjc.v9.i5.407.\n[23] J. Hippisley-Cox and C. Coupland, “Development and validation of risk\nprediction equations to estimate future risk of heart failure in patients with\ndiabetes: A prospective cohort study,” BMJ Open, vol. 5, no. 9, Sep. 2015,\nArt. no. e008503, doi: 10.1136/bmjopen-2015-008503.\n[24] V . Kuan et al. , “A chronological map of 308 physical and mental\nhealth conditions from 4 million individuals in the English National\nHealth Service,” Lancet Digit. Health , vol. 1, no. 2, pp. e63–e77, 2019,\ndoi: 10.1016/S2589-7500(19)30012-3.\n[25] T. vor der Brück and M. Pouly, “Text similarity estimation based on word\nembeddings and matrix norms for targeted marketing,” in Proc. 2019 Conf.\nNorth Amer. Chapt. Associat. Computat. Linguist.: Human Lang. Technol.,\nVolume 1 (Long and Short Papers) , 2019, pp. 1827–1836.\n[26] J. Tromp et al. , “Age dependent associations of risk factors with heart\nfailure: Pooled population based cohort study,” BMJ, vol. 372, 2021,\nArt. no. 461, doi: 10.1136/bmj.n461.\n[27] S. J. Jacobsen, D. S. Freedman, R. G. Hoffmann, H. W. Gruchow, A. J. An-\nderson, and J. J. Barboriak, “Cholesterol and coronary artery disease: Age\nas an effect modiﬁer,” J. Clin. Epidemiol. , vol. 45, no. 10, pp. 1053–1059,\nOct. 1992, doi: 10.1016/0895-4356(92)90145-d.\n[28] T. J. Campbell and P. S. MacDonald, “Digoxin in heart failure and cardiac\narrhythmias,”Med. J. Aust. , vol. 179, no. 2, pp. 98–102, 2003.\n[29] D. E. Sholter and P. W. Armstrong, “Adverse effects of corticosteroids on\nthe cardiovascular system,” Can. J. Cardiol. , vol. 16, no. 4. pp. 505–511,\n2000.\n[30] R. D. Goodwin, K. W. Davidson, and K. Keyes, “Mental dis-\norders and cardiovascular disease among adults in the United\nStates,” J. Psychiatr. Res. , vol. 43, no. 3, pp. 239–246, Jan. 2009,\ndoi: 10.1016/j.jpsychires.2008.05.006.\n[31] C. C. Butler et al. , “Treatment of acute cough/lower respiratory tract\ninfection by antibiotic class and associated outcomes: A 13 European coun-\ntry observational study in primary care,” J. Antimicrobial Chemotherapy ,\nvol. 65, no. 11, pp. 2472–2478, Nov. 2010, doi: 10.1093/jac/dkq336.\n[32] C. Macie, K. Wooldrage, J. Manfreda, and N. Anthonisen, “Cardio-\nvascular morbidity and the use of inhaled bronchodilators,” Int. J.\nChronic Obstructive Pulmonary Dis. , vol. 3, no. 1, pp. 163–169, 2008,\ndoi: 10.2147/copd.s1516.\n[33] G. S. Bleumink, J. Feenstra, M. C. J. M. Sturkenboom,\nand B. H. C. Stricker, “Nonsteroidal anti-inﬂammatory drugs\nand heart failure,” Drugs, vol. 63, no. 6. pp. 525–534, 2003,\ndoi: 10.2165/00003495-200363060-00001.\n[34] J. Mäenpää and O. Pelkonen, “Cardiac safety of ophthalmic tim-\nolol,” Expert Opin. Drug Saf. , vol. 15, pp. 1549–1561, 2016,\ndoi: 10.1080/14740338.2016.1225718.\n[35] P. Harasymowycz et al. , “Medical management of glaucoma in the 21st\ncentury from a Canadian perspective,” J. Ophthalmol. , vol. 2016, 2016,\nArt. no. 6509809, doi: 10.1155/2016/6509809.\n[36] W. T. Abraham, “ β-blockers: The new standard of therapy for mild\nheart failure,” Arch. Intern. Med. , vol. 160, pp. 1237–1247, 2000,\ndoi: 10.1001/archinte.160.9.1237.\n[37] M. Lièvre, S. Morand, B. Besse, J. N. Fiessinger, and J. P. Boissel,\n“Oral beraprost sodium, a prostaglandin I 2 analogue, for intermittent\nclaudication: A double-blind, randomized, multicenter controlled trial,”\nCirculation, vol. 102, pp. 426–431, 2000, doi: 10.1161/01.CIR.102.4.426.\n[38] E. R. Mohler, W. R. Hiatt, J. W. Olin, M. Wade, R. Jeffs, and A. T.\nHirsch, “Treatment of intermittent claudication with beraprost sodium,\nan orally active prostaglandin I 2 analogue: Double-blinded, randomized,\ncontrolled trial,” J. Amer. Coll. Cardiol. , vol. 41, pp. 1679–1686, 2003,\ndoi: 10.1016/S0735-1097(03)00299-7.\n[39] H. I. Pass and H. W. Pogrebniak, “Potential uses of prostaglandin E1\nanalog for cardiovascular disease,”J. Thoracic Cardiovasc. Surg., vol. 108,\npp. P789–P790, 1994, doi: 10.1016/s0022-5223(94)70312-4.\n[40] V . Kuan et al. , “A chronological map of 308 physical and mental\nhealth conditions from 4 million individuals in the English National\nHealth Service,” Lancet Digit. Health , vol. 1, no. 2, pp. e63–e77, 2019,\ndoi: 10.1016/S2589-7500(19)30012-3.\n[41] T. Benson, “The history of the read codes: The inaugural James read memo-\nrial lecture 2011,” Informat. Primary Care , vol. 19, no. 3, pp. 173–182,\n2012, doi: 10.14236/jhi.v19i3.811.\n[42] W. H. Organization, ICD-10: International Statistical Classiﬁcation of\nDiseases and Related Health Problems: Tenth Revision . 1st ed., Washing-\nton, DC, USA: Pan American Health Organization, 2004, Spanish version.\n[43] H. J. Curtis and B. Goldacre, “OpenPrescribing: Normalised data and\nsoftware tool to research trends in English NHS primary care pre-\nscribing 1998–2016,” BMJ Open , vol. 8, 2018, Art. no. e019921,\ndoi: 10.1136/bmjopen-2017-019921."
}