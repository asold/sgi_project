{
  "title": "Enhancing treatment decision-making for low back pain: a novel framework integrating large language models with retrieval-augmented generation technology",
  "url": "https://openalex.org/W4410379873",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2106791084",
      "name": "Rong Chen",
      "affiliations": [
        "Sun Yat-sen University",
        "The First Affiliated Hospital, Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2365599531",
      "name": "Siyun Zhang",
      "affiliations": [
        "The First Affiliated Hospital, Sun Yat-sen University",
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2773656725",
      "name": "Yiyi Zheng",
      "affiliations": [
        "Sun Yat-sen University",
        "The First Affiliated Hospital, Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2160155186",
      "name": "Qiuhua Yu",
      "affiliations": [
        "Sun Yat-sen University",
        "The First Affiliated Hospital, Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2164315597",
      "name": "Chuhuai Wang",
      "affiliations": [
        "Sun Yat-sen University",
        "The First Affiliated Hospital, Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2106791084",
      "name": "Rong Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2365599531",
      "name": "Siyun Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2773656725",
      "name": "Yiyi Zheng",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2160155186",
      "name": "Qiuhua Yu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2164315597",
      "name": "Chuhuai Wang",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3010721913",
    "https://openalex.org/W2770316315",
    "https://openalex.org/W4388034541",
    "https://openalex.org/W4389266727",
    "https://openalex.org/W3138023331",
    "https://openalex.org/W3023278774",
    "https://openalex.org/W3107317036",
    "https://openalex.org/W1943745580",
    "https://openalex.org/W2041927436",
    "https://openalex.org/W4406316108",
    "https://openalex.org/W2949189974",
    "https://openalex.org/W2997055469",
    "https://openalex.org/W4317614181",
    "https://openalex.org/W4403382158",
    "https://openalex.org/W4407138912",
    "https://openalex.org/W4394742411",
    "https://openalex.org/W2664267452",
    "https://openalex.org/W2843010082",
    "https://openalex.org/W4362515116",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4361289889",
    "https://openalex.org/W4383301640",
    "https://openalex.org/W4405728682",
    "https://openalex.org/W4386867830",
    "https://openalex.org/W4400549596",
    "https://openalex.org/W4392597393",
    "https://openalex.org/W4407941451",
    "https://openalex.org/W4385476046",
    "https://openalex.org/W4281483047",
    "https://openalex.org/W4400083046",
    "https://openalex.org/W4322761615",
    "https://openalex.org/W4367669592",
    "https://openalex.org/W4367175507",
    "https://openalex.org/W4327681325",
    "https://openalex.org/W4312174617",
    "https://openalex.org/W2182014728",
    "https://openalex.org/W4382776994",
    "https://openalex.org/W2974628135",
    "https://openalex.org/W3214400552",
    "https://openalex.org/W3112211262",
    "https://openalex.org/W4360891289",
    "https://openalex.org/W4383187389",
    "https://openalex.org/W4380685958",
    "https://openalex.org/W4381743186"
  ],
  "abstract": "Introduction Chronic low back pain (CLBP) is a global health problem that seriously affects the quality of life among patients. The etiology of CLBP is complex, with non-specific symptoms and considerable heterogeneity, which poses a great challenge for diagnosis. In addition, the uncertain treatment responses as well as the potential influence of psychological and social factors further increase the difficulty of personalized decision-making in clinical practice. Methods This study proposed an innovative support framework on clinical decision, which combined large language models (LLMs) with retrieval-augmented generation (RAG) technology. Moreover, the least-to-most (LtM) prompting technology was introduced, aiming to simulate the decision-making process of senior experts thereby improving personalized treatment for CLBP. Additionally, a special CLBP-related dataset was generated to verify effectiveness of the framework, which compared the proposed model CLBP-GPT with GPT-4.0, ERNIE Bot, and DeepSeek in terms of five key indicators: accuracy, relevance, clarity, benefit, and completeness. Results The results showed that the CLBP-GPT model proposed in this study scored significantly better than other comparison models in all five evaluation dimensions. Specifically, the total score of CLBP-GPT was 4.40 (SD = 0.20), substantially higher than GPT-4.0 (4.03, SD = 0.48), ERNIE Bot (3.54, SD = 0.53), and DeepSeek (3.81, SD = 0.47). In terms of accuracy, the average score of CLBP-GPT was 4.38 (SD = 0.19), while the scores of other models were all below 4, indicating that CLBP-GPT could provide more accurate clinical decision-making recommendations. In addition, CLBP-GPT scored as high as 4.42 (SD = 0.19) in the completeness dimension, further demonstrating that the decision content output by the model was more comprehensive and covered more key information related to CLBP. Discussion This study not only provides new technical support for clinical decision-making in CLBP, but also introduces a powerful tool for doctors to formulate personalized and efficient treatment strategies. It is expected to improve the diagnosis and treatment of CLBP in the future.",
  "full_text": "fmed-12-1599241 May 9, 2025 Time: 17:31 # 1\nTYPE Original Research\nPUBLISHED 14 May 2025\nDOI 10.3389/fmed.2025.1599241\nOPEN ACCESS\nEDITED BY\nHao Jiang,\nNanjing University of Information Science\nand Technology, China\nREVIEWED BY\nGuilu Wu,\nHainan University, China\nShuran Sheng,\nShanghai Dianji University, China\n*CORRESPONDENCE\nChuhuai Wang\nwangchuh@mail.sysu.edu.cn\nQiuhua Yu\nyuqiuhua@mail.sysu.edu.cn\n†These authors have contributed equally to\nthis work\nRECEIVED 24 March 2025\nACCEPTED 30 April 2025\nPUBLISHED 14 May 2025\nCITATION\nChen R, Zhang S, Zheng Y, Yu Q and Wang C\n(2025) Enhancing treatment\ndecision-making for low back pain: a novel\nframework integrating large language\nmodels with retrieval-augmented\ngeneration technology.\nFront. Med.12:1599241.\ndoi: 10.3389/fmed.2025.1599241\nCOPYRIGHT\n© 2025 Chen, Zhang, Zheng, Yu and Wang.\nThis is an open-access article distributed\nunder the terms of the Creative Commons\nAttribution License (CC BY). The use,\ndistribution or reproduction in other forums\nis permitted, provided the original author(s)\nand the copyright owner(s) are credited and\nthat the original publication in this journal is\ncited, in accordance with accepted academic\npractice. No use, distribution or reproduction\nis permitted which does not comply with\nthese terms.\nEnhancing treatment\ndecision-making for low back\npain: a novel framework\nintegrating large language\nmodels with retrieval-augmented\ngeneration technology\nRong Chen†, Siyun Zhang†, Yiyi Zheng, Qiuhua Yu* and\nChuhuai Wang*\nDepartment of Rehabilitation Medicine, The First Afﬁliated Hospital, Sun Yat-sen University,\nGuangzhou, China\nIntroduction: Chronic low back pain (CLBP) is a global health problem that\nseriously affects the quality of life among patients. The etiology of CLBP is\ncomplex, with non-speciﬁc symptoms and considerable heterogeneity, which\nposes a great challenge for diagnosis. In addition, the uncertain treatment\nresponses as well as the potential inﬂuence of psychological and social\nfactors further increase the difﬁculty of personalized decision-making in clinical\npractice.\nMethods: This study proposed an innovative support framework on clinical\ndecision, which combined large language models (LLMs) with retrieval-\naugmented generation (RAG) technology. Moreover, the least-to-most (LtM)\nprompting technology was introduced, aiming to simulate the decision-making\nprocess of senior experts thereby improving personalized treatment for CLBP.\nAdditionally, a special CLBP-related dataset was generated to verify effectiveness\nof the framework, which compared the proposed model CLBP-GPT with\nGPT-4.0, ERNIE Bot, and DeepSeek in terms of ﬁve key indicators: accuracy,\nrelevance, clarity, beneﬁt, and completeness.\nResults: The results showed that the CLBP-GPT model proposed in this study\nscored signiﬁcantly better than other comparison models in all ﬁve evaluation\ndimensions. Speciﬁcally, the total score of CLBP-GPT was 4.40 (SD = 0.20),\nsubstantially higher than GPT-4.0 (4.03, SD= 0.48), ERNIE Bot (3.54, SD= 0.53),\nand DeepSeek (3.81, SD = 0.47). In terms of accuracy, the average score of\nCLBP-GPT was 4.38 (SD= 0.19), while the scores of other models were all below\n4, indicating that CLBP-GPT could provide more accurate clinical decision-\nmaking recommendations. In addition, CLBP-GPT scored as high as 4.42 (SD =\n0.19) in the completeness dimension, further demonstrating that the decision\ncontent output by the model was more comprehensive and covered more key\ninformation related to CLBP.\nDiscussion: This study not only provides new technical support for clinical\ndecision-making in CLBP, but also introduces a powerful tool for doctors to\nFrontiers in Medicine 01 frontiersin.org\nfmed-12-1599241 May 9, 2025 Time: 17:31 # 2\nChen et al. 10.3389/fmed.2025.1599241\nformulate personalized and efﬁcient treatment strategies. It is expected to\nimprove the diagnosis and treatment of CLBP in the future.\nKEYWORDS\nchronic low back pain, clinical decision-making, GPT-4.0, large language models,\ntreatment\n1 Introduction\nChronic low back pain (CLBP) is a global public health\nproblem, aﬀecting approximately 70%–85% of the adult population\n(1). CLBP not only leads to reduced lumbar mobility and\nweakened muscle strength but also causes emotional disorders\nsuch as depression and anxiety, which seriously impairs the\nquality of life (2). As the disease progresses, the patient would\nexperience increased pain sensitivity and decreased pain tolerance,\nwhich leads to further deterioration of pain symptoms and\nfunctional impairment. The etiology of CLBP is complex, involving\nbiomechanics, neurophysiology, and psychosocial factors (3). This\nmultifactorial nature, coupled with the non-speciﬁc symptoms,\nmake it extremely complicated for diagnosis. In addition, there\nare signiﬁcant diﬀerences in clinical manifestations, treatment\nresponses, and psychosocial factors among CLBP patients, further\nincreasing the diﬃculty of clinical decision-making. Personalized\nclinical decision-making can formulate more accurate and eﬀective\ntreatment plans based on the speciﬁc conditions of the patients,\nthereby improving the treatment eﬀect as well as patient satisfaction\n(4). However, given the complexity and individual diﬀerences of\nCLBP , there are still many challenges in achieving personalized\ndecision-making, including the uniﬁcation of diagnostic criteria,\nthe optimization of treatment plans, and the comprehensive\nconsideration of psychosocial factors.\nIn the ﬁeld of personalized treatment for CLBP , many studies\nhave explored a variety of treatment strategies and decision-\nsupporting systems. Covering a variety of methods such as\ndrug therapy, physical therapy and psychological intervention,\nthese studies have contribute to alleviate symptoms and improve\nthe quality of life (5–7). However, without certain evidence\nand eﬀective alternative treatment, it’s particularly important to\nconsider values and preferences of patients in the decision-\nmaking process. As an evidence-based tool, the Patient Decision\nAid (PDA) supports patients in making informed decisions by\nproviding information about diﬀerent treatment options and\nrelated outcomes (8). Studies have shown that for patients, high-\nquality PDAs can eﬀectively improve knowledge level, reduce\ndecision conﬂicts, and better match treatment options based on\nvalues and preferences. Therefore, the use of PDAs is recommended\nin more and more clinical practice guidelines (9). However, there\nis currently a lack of high-quality PDAs that meet international\nstandards for CLBP patients. Although Cho’s study provided a\ndecision-making aid for patients with CLBP who were considering\nlumbar fusion, but it was not suitable for widespread promotion\nbecause of insuﬃcient interpretability (10). In addition, existing\ndecision-supporting systems have limited eﬀect in integrating\nmulti-source data, simulating expert decision-making processes,\nand providing personalized advice. Moreover, CLBP patients\ngenerally express dissatisfaction with the contradictory and biased\ninformation provided by diﬀerent medical professionals (11, 12),\nwhich highlights the urgent need to develop high-quality, unbiased\ndecision-supporting tools.\nIn recent years, the rapid development of artiﬁcial intelligence\n(AI) technology has greatly promoted the progress in the medical\nﬁeld, with its application beneﬁting multiple process such as\ndiagnosis, treatment, and drug development (13, 14). In the ﬁeld of\nCLBP , studies have explored the application of AI in the predicting\nrecurrence of CLBP and the selection of opioid drug (15, 16).\nHowever, despite the progress made in these studies, the research\non clinical decision-supporting for CLBP is still insuﬃcient and\nurgently needs further exploration. With the development of LLMs,\nespecially the applications based on chatbot systems, LLMs are\ngradually becoming an important tool in the ﬁeld of healthcare,\nproviding new possibilities for clinical decision-making and patient\nparticipation (17, 18). LLMs are based on transformer architecture,\nwhich can simulate the understanding and generation capabilities\nof human language through training on large-scale text data (19).\nIn medical text processing tasks, LLMs perform well and can\nprovide in-depth analysis of massive unstructured medical data. As\na result, they can signiﬁcantly improve the eﬃciency of medical\ndata processing and the accuracy of clinical decision-making,\nproviding strong support for doctors in various clinical scenarios\n(20, 21). However, LLMs still face challenges in clinical practice,\nespecially the \"hallucinations\" or erroneous responses they may\nproduce, which have caused experts and patients to worry about\nthe reliability of the system (22, 23). To address this problem,\nretrieval-augmented generation (RAG) technology has emerged.\nRAG combines the advantages of information retrieval and text\ngeneration, which helps to retrieve relevant information from\nexternal knowledge bases, and generate more accurate answers\nbased on this information. This method not only eﬀectively\nimproves the performance of the model in medical decision-\nmaking by compensates for the knowledge limitations, but also\nmaintains the ﬂuency and ﬂexibility of the generated content (24).\nIn addition, prompt engineering, as an emerging technology, can\nguide LLMs to generate more accurate and relevant content by\ndesigning speciﬁc prompt words or sentences, thereby improving\nthe output quality and interpretability (25). This technology helps\nto simulate the thinking process of experts, generate more accurate\nand personalized medical advice, and provide a more reliable\nsuggestions for clinical decision-making.\nThis study aims to develop a clinical decision-supporting\nsystem called CLBP-GPT, which innovatively integrates GPT-\n4.0 and RAG technology to address the key issues of CLBP in\nclinical practice, achieving personalized diagnosis and treatment.\nBy introducing RAG technology, the system can not only integrate\nthe latest medical advancement and clinical guidelines, but\nFrontiers in Medicine 02 frontiersin.org\nfmed-12-1599241 May 9, 2025 Time: 17:31 # 3\nChen et al. 10.3389/fmed.2025.1599241\nalso signiﬁcantly improve its professionalism and interpretability\nof decisions. In addition, we speciﬁcally adopt LtM prompt\nengineering technology, which signiﬁcantly ensure LLMs to\ndeeply analyze and understand complex cases by optimizing the\nprocessing of medical history and current symptoms, thereby\nproviding clinicians with more personalized diagnosis and\ntreatment recommendations.\nOur main contributions are as follows:\n1. This study constructed a special dataset for CLBP and\ndeveloped key indicators for evaluating clinical decision,\nincluding accuracy, relevance, clarity, beneﬁt, and\ncompleteness. These indicators provided a scientiﬁc basis\nfor subsequent model optimization and the development\nof decision-supporting system, ensuring the high quality\nand clinical applicability of our results.\n2. By simulating the expert’s decision-making process and\nintroducing LtM prompt engineering technology,\nLLM could be utilized for in-depth analysis and\nunderstanding of complex cases. As a result, the model\ncould generate more accurate and more clinically realistic\npersonalized diagnosis and treatment recommendations,\nthus improving the quality and interpretability of\ndecision support.\n3. We collected the latest research papers and medical\nguidelines to build a knowledge base in the ﬁeld of\nCLBP. Through RAG technology, this knowledge base\nwas combined with LLMs, which signiﬁcantly improved\nthe professionalism and decision-making ability of the\nmodel, enabling more accurate and comprehensive clinical\nrecommendations.\nThe structure of the paper is as follows: Section 2 provides\na detailed description of the materials and methods, Section 3\noutlines the experiments, Section 4 presents the experimental\nresults, Section 5 shows a discussion of the experimental results,\nand ﬁnally, Section 6 concludes the paper.\n2 Materials and methods\n2.1 Framework\nThis study constructed a clinical decision framework for CLBP\non LLMs and RAG technology, which is shown in Figure 1.\nThe framework consists of seven core modules: First, the data\ncollection module constructs a multi-source heterogeneous patient\ndata set by integrating information both from Internet medical\nplatform and the hospital; second, the knowledge base construction\nmodule systematically integrates the latest research results and\nclinical guidelines in the ﬁeld of CLBP to ensure the timeliness and\nauthority; third, GPT-4.0 is used as the feature extraction module\nto perform semantic analysis on the patients’ complaint and\nextracts multi-dimensional key features including demographic\ncharacteristics, pain characteristics, accompanying symptoms, past\nmedical history, occupation and lifestyle, and psychosocial factors;\nfourth, the knowledge retrieval module accurately matches the\nmost relevant medical knowledge from our base indicated by the\nextracted feature keywords; ﬁfth, the prompt engineering module\nimproves the accuracy and reliability of decision-making system by\noptimizing the interaction between LLMs and retrieved knowledge;\nsixth, the result generation module uses the advanced capabilities of\nGPT-4.0 to output decision-making recommendations with clinical\nvalue; ﬁnally, the personalized decision module provides patients\nwith customized treatment plans to ensure the feasibility and\nclinical applicability of the recommendations.\n2.2 Dataset\nThis study adopted a multi-source data collection strategy\nto construct a CLBP patient complaint dataset. First, we used\ncrawler technology to obtain online patient consultation data on\nCLBP from 39 Health Network; second, we integrated the patient\ncomplaint records accumulated by the cooperative hospitals.\nThrough the above channels, 80 representative CLBP patient\ncomplaint samples were compiled, covering a variety of clinical\ntypes such as acute low back pain, chronic low back pain, and\nneuropathic low back pain. In the data preprocessing stage, we\nperformed preliminary data cleaning steps to remove missing\ninformation and comments that did not contain substantive\ncontent. Subsequently, we used the regular expression method in\ntext processing technology to eﬀectively remove special characters\nin the comments, including URL links and emoticons, to reduce\nthe noise interference and improve the data quality. It is worth\nnoting that we always adhered to the principles of respecting users\nand protecting personal privacy when processing these public data.\nWe have implemented strict manual screening and desensitization\nfor all content that may involve personal privacy. Speciﬁcally, we\ndeleted all sensitive information, including but not limited to the\npatient’s name, ID number, contact information, home address and\nother data that directly identify a certain individual; secondly, we\nranged the age information to blur the precise age characteristics;\nﬁnally, we simpliﬁed the gender information, retaining only basic\nclassiﬁcation labels such as \"male\" and \"female\" to avoid any detailed\ndescription that may leak personal privacy.\n2.3 Retrieval-augmented generation\n(RAG)\nAs an important component of generative AI, LLMs have\nthe potential to revolutionize the way medical information is\ndelivered (26). Nowadays, LLMs have demonstrated signiﬁcant\nvalue in content creation, idea generation, and human-computer\ninteraction. However, their inherent limitations, such as the need\nfor the latest information, the tendency to generate inaccurate\nfacts, and the reliance on public domain data, restrict their full\napplication in healthcare settings. To address these challenges, RAG\ntechnology has created an innovative framework by combining\nLLMs with external knowledge bases (27, 28). This framework\nenables LLMs to break through the limitations of training data and\naccess a wider range of information resources. In the healthcare\nﬁeld, RAG technology can integrate a variety of professional data\nsources, including peer-reviewed research, authoritative medical\nguidelines, and internal policy documents of medical institutions\nFrontiers in Medicine 03 frontiersin.org\nfmed-12-1599241 May 9, 2025 Time: 17:31 # 4\nChen et al. 10.3389/fmed.2025.1599241\nFIGURE 1\nThe framework of CLBP-GPT for chronic low back pain that integrates LLMs and RAG techniques: (1) collect patient questions from the Internet as\nwell as hospitals, and organize them into data sets. (2) Build a knowledge base for CLBP based on the latest literature and research papers. (3) Use\nGPT to extract key features from patient complaints. (4) Retrieve the latest knowledge in the knowledge base based on keywords. (5) Prompt\nengineering design. (6) Generate results using GPT-4.0. (7) Provide personalized decisions to patients.\nsuch as hospitals and pharmaceutical companies. By introducing\nRAG technology, existing generative AI tools can not only\nprocess public information, but also eﬀectively utilize private data,\nthereby signiﬁcantly expanding their scope of application and\nimproving accuracy in medical settings (29). In this study, we\ntook CLBP as the research topic, systematically collected 4612\nrelevant articles and the latest medical guidelines in PubMed\namong past 5 years (2021–2025) to construct a professional\nvector knowledge base. After extracting the characteristic keywords\nrelated to CLBP from main complaint content, the most relevant\nmedical knowledge was retrieved from the knowledge base by\ncalculating the cosine similarity. Moreover, the information was\ninput into the subsequent prompt engineering link. This research\ndesign can not only eﬀectively integrate the latest medical research\nresults but also ensure the professionalism and timeliness of the\ngenerated content.\n2.4 LtM prompting\nPrompt engineering is an emerging research ﬁeld that focuses\non the design, optimization, and application of LLMs instructions.\nIt aims to guide LLMs to generate speciﬁc outputs through carefully\ndesigned prompt words and instructions, thereby eﬃciently\ncompleting complex tasks (25). In this study, we used Chinese\nas the prompt language, which puts higher requirements on\nLLMs. To address the challenges of Chinese data processing,\nwe deeply combined characteristics and contextual elements of\nChinese language in the prompt design. In addition, the progressive\nprompt engineering method was implemented, which gradually\ntransitioned from minimal prompts to more extensive prompts to\nimprove the model’s ability in clinical decision-making (30). The\nspeciﬁc process includes: ﬁrst, designing basic prompts based on\nChinese language characteristics to ensure understanding of the\nbasic requirements; second, guiding the model to focus on key\nFrontiers in Medicine 04 frontiersin.org\nfmed-12-1599241 May 9, 2025 Time: 17:31 # 5\nChen et al. 10.3389/fmed.2025.1599241\nfeatures through targeted prompts to deepen the understanding\nof background information; ﬁnally, introducing knowledge base\nretrieval results to enrich contextual information, which help\nthe model better understand the complexity and details of the\ntask. Through this hierarchical prompt engineering framework, we\ngradually guided GPT-4 to conduct in-depth analysis of the text,\nsigniﬁcantly improving the accuracy and reliability of the model.\nThis approach not only integrates professional knowledge in the\nmedical ﬁeld but also utilizes the advantages of LLMs in language\nunderstanding and context analysis, providing a new research\nparadigm for the application of large models in the Chinese context.\n3 Experiment\nRecently, LLMs represented by the GPT series have\ndemonstrated unprecedented learning and generating capabilities,\ngreatly promoting the application and development of AI in\nthe medical ﬁeld (31). In order to comprehensively evaluate\nthe advantages of CLBP-GPT in supporting clinical decision,\nwe not only compared it with the base model GPT-4.0 but also\nintroduced the domestic leading ERNIE Bot and innovative AI\nmodel DeepSeek as references, ensuring the comprehensiveness\nand objectivity of the evaluation. In terms of experimental design,\nwe developed a complete automated evaluation system for the\nCLBP-GPT model. The system was based on the GPT-4.0 API\ninterface provided by OpenAI and realized the automation of the\nentire process from data input to result output. This innovative\ndesign signiﬁcantly improved the evaluation eﬃciency and\neﬀectively avoided the subjective bias that might be caused by\nmanual intervention, ensuring the reliability and consistency of\nthe experimental results. For other models, due to the interface\nlimitations of their latest versions, it was not possible to adopt\nthe same automated evaluation scheme. To ensure the fairness\nand comparability of the evaluation across diﬀerent models, we\nultimately chose to conduct the evaluation using the traditional\nmethod of manual questioning combined with manual recording.\nThis approach aimed to ensure that all models were tested under\nuniform standards, thereby more comprehensively and objectively\ndemonstrating their true performance in the ﬁeld of clinical\ndecision-supporting for low back pain. Our evaluation process\nwas carefully designed and mainly included the following four key\nsteps: ﬁrst, standardized data preparation to ensure the quality\nand consistency of input data; second, collecting the answers to\ndiﬀerent questions based on each model; then, submitting the\nquestions and answers to three experts for scoring respectively,\nand taking the average as the score of the indicator; ﬁnally,\nconducting a comprehensive analysis of the scores by diﬀerent\nmodels. This systematic evaluation method improved experimental\neﬃciency and provided a reusable technical framework for similar\nresearch in the future.\n3.1 Evaluation metrics\nTo evaluate the model performance more comprehensively and\nsystematically, we have reﬁned the evaluation indicators into ﬁve\ncore dimensions and adopted a uniﬁed standard for scoring. By\nformulating a detailed grading guide, we ensured the consistency\nand fairness of the scoring criteria. The following are the speciﬁc\nevaluation dimensions and detailed scoring criteria:\n(1) Accuracy was used to measure whether the answer\nwas consistent with medical common sense, which was\nassessed by ﬁve-point likert scale (1–5 points). The\nscoring scale was as follows: 1 (very inaccurate): The\nanswer has a fundamental misunderstanding of medical\nconcepts; 2 (partially inaccurate): The answer contains\nmore wrong information than correct information; 3\n(moderately accurate): The answer is generally correct,\nbut there are a few inaccuracies; 4 (mostly accurate): The\nanswer is basically correct, with only minor errors or\nomissions. 5 (completely accurate): The answer reﬂects a\nhigh level of medical understanding, and the information\nis accurate and correct.\n(2) Relevance (scoring scale: 1.0–5.0 points) was used to\nevaluate whether the answer was directly addressed to\nthe question content or it is oﬀ topic. The scoring scale\nwas as follows: 1 (completely irrelevant): The answer\nis completely irrelevant to the question or oﬀ-topic; 2\n(slightly relevant): The answer is related to the question\nbut contains a lot of irrelevant information; 3 (moderately\nrelevant): The answer is basically relevant but contains\nsome unnecessary content; 4 (Highly relevant): The\nanswer is directly relevant with only a few irrelevant\ndetails; 5 (Completely relevant): The answer focuses on the\nquestion accurately without any deviation.\n(3) Clarity (scoring scale: 1.0–5.0 points) was used to measure\nwhether the answer was easy to understand. Scoring scale\nwas as follows: 1 point (Very unclear): The answer is\nconfusing, unclear or diﬃcult to understand; 2 points: The\nanswer has some clarity but may need further explanation;\n3 points (Clear): The answer is easy to understand, and\nthe expression is relatively clear; 4 points (Very clear):\nThe answer has clear logic and is easy to follow; 5 points\n(Extremely clear): The answer is extremely concise and\neasy to understand.\n(4) Beneﬁt (scoring scale: 1.0–5.0 points) was used to assess\nwhether the answer was signiﬁcantly helpful in the\ndecision-making process. Scoring scale is as follows: 1\n(Not useful): The answer is not helpful in the decision-\nmaking process; 2 (Somewhat useful): The answer\nprovides limited help in the decision-making process;\n3 (Moderately Useful): The answer is somewhat helpful\nin the decision-making process; 4 (Highly Useful): The\nanswer is signiﬁcantly helpful in the decision-making\nprocess; 5 (Extremely Useful): The answer is of high value\nin the decision-making process and can help make an\ninformed decision.\n(5) Completeness (scoring scale: 1.0–5.0 points) was used\nto assess whether the answer contains all necessary\ninformation to fully answer the question. The scoring\nscale was as follows: 1 (Very Incomplete): The answer\nomits key information and cannot fully answer the\nquestion; 2 (Partially Complete): The answer contains\nsome necessary information, but important content is\nFrontiers in Medicine 05 frontiersin.org\nfmed-12-1599241 May 9, 2025 Time: 17:31 # 6\nChen et al. 10.3389/fmed.2025.1599241\nmissing; 3 (Moderately Complete): The answer covers\nmost of the necessary information; 4 (Mostly Complete):\nThe answer is almost complete with only a few omissions;\n5 (Completely Complete): The answer fully covers all\nnecessary information without any omissions.\n4 Results\nImplementing a systematic evaluation experiment, we\ncomprehensively compared the performance of CLBP-GPT with\nthree mainstream generative models in multiple key performance.\nTo ensure the rigor and professionalism of the evaluation, we\ncarefully selected 80 representative questions as test samples, with\neach question answered by each model. Subsequently, a review\npanel was formed by three experts with rich experience in the ﬁeld\nof CLBP. During the review process, the experts followed a uniﬁed\nevaluation standard. Finally, average score of the three experts\nwas calculated and analyzed, which maximized the objectivity and\nreliability of the evaluation.\nThe experimental results are shown in Table 1. In this\nexperiment, CLBP-GPT showed signiﬁcant advantages in multiple\nkey performance. First, in terms of accuracy, the average score of\nCLBP-GPT was 4.38, signiﬁcantly higher than the score of GPT-\n4.0 (3.98), ERNIE Bot (3.54), and DeepSeek (3.83). This result\nshowed that CLBP-GPT could capture the core of the problem\nmore accurately and provide more precise answers when generating\ncontent. In addition, the standard deviation (SD) for CLBP-GPT\nwas 0.19 (Figure 2), which was much lower than other models,\nindicating more stable performance. Secondly, CLBP-GPT also\nperformed well in terms of relevance and clarity. The relevance\nscore was 4.39 and the clarity score was 4.42, both signiﬁcantly\nhigher than other models. In other words, the content generated\nby CLBP-GPT was not only highly relevant to the problem, but\nalso easy to understand, which could eﬀectively meet current\nneeds. In contrast, although the performance of other models in\nthese two dimensions had its own highlights, there was still a\ncertain gap remained with CLBP-GPT. Finally, as for Beneﬁt and\nCompleteness, CLBP-GPT demonstrated its excellent performance\nas well. With Beneﬁt score of 4.38 and Completeness score of 4.42,\nCLBP-GPT ranked the ﬁrst among all models. In our opinion,\nCLBP-GPT could provide useful information, comprehensively\ncover all aspects of the problem and avoid missing key details at\nthe same time. Overall, CLBP-GPT received an excellent total score\nof 4.40, further verifying its leading position in generative models.\nIts low standard deviation (0.20) also emphasized the stability and\nreliability, making CLBP-GPT particularly outstanding in complex\ntasks.\n5 Discussion\nOur study demonstrated the feasibility and clinical value of\ncombining LLMs with RAG techniques to build a comprehensive\ndecision-supporting framework for CLBP. The CLBP-GPT\nmodel addressed two key challenges in clinical AI applications:\ndynamic integration of knowledge and personalized adaptation\nto patient-speciﬁc contexts. Compared with previous studies\nevaluating standalone LLMs (e.g., GPT-4.0), our framework\nachieved superior clinical relevance through its hybrid architecture\nthat combined structured knowledge retrieval with advanced\nlanguage understanding capabilities. The performance of our\nframework signiﬁcantly beneﬁted from three key innovations:\n1) The multidimensional feature extraction module that\nleveraged GPT-4 was utilized for semantic analysis, which\nexhibited remarkable ability to identify clinical features\nfrom unstructured responses, consistent with recent ﬁndings\non the diagnostic acuity of LLMs (32–34). 2) The dynamic\nknowledge retrieval mechanism eﬀectively mitigated the inherent\n“hallucination” risk of pure LLMs approaches by grounding\ndecisions in validated clinical guidelines. 3) The personalized\ndecision module introduced context-aware adaptation including\noccupational, psychosocial, and lifestyle factors, dimensions\nthat were often overlooked in traditional decision-supporting\nsystems (35).\nTraditional clinical decision-making tools often relied on static\ndecision trees or rule-based systems, which have limited the\nability to handle complicated CLBP cases in clinical practice.\nThese systems often focused only on biomedical factors such as\nanatomical abnormalities, while ignoring the signiﬁcant impact\nof psychosocial and lifestyle factors. Here these neglected factors\nhave been recognized to play a key role in the development and\nmanagement of CLBP (36, 37). Furthermore, the personalized\ndecision module in our framework considered occupational,\npsychosocial, and lifestyle factors, ﬁlling a major gap in current\nLBP researches. In a recent investigation into the management of\nCLBP within primary care settings (38), researchers discovered\na strong correlation between psychosocial stress levels and\nthe persistence of LBP symptoms. However, the decision-\nmaking tool employed in that study failed to incorporate these\ncritical factors. In contrast, our proposed model oﬀers a more\nholistic approach, eﬀectively capturing the multifaceted nature\nof CLBP cases. By integrating a broader range of variables, our\nmodel is able to provide more comprehensive and personalized\nrecommendations, addressing the unique needs of each patient\nmore eﬀectively.\nIn terms of knowledge integration, previous studies have\nstruggled to keep up with the latest advances in this rapidly\nevolving ﬁeld. But existing decision-making systems have\ndiﬃculty incorporating the latest evidence (39), which has\nbeen directly addressed by dynamic knowledge retrieval\nmechanism in our CLBP-GPT model. It could quickly match\nclinical scenarios with the latest evidence, ensuring that the\nrecommendations given were based on the latest understanding\nof CLBP pathophysiology, treatment options, and patient-\ncentered care principles. In addition, although simple machine\nlearning algorithms have been explored for CLBP diagnosis\nin previous researches, they lacked the ability to eﬀectively\nprocess unstructured data like CLBP-GPT. Such studies usually\nhad high requirements for input data, which must be highly\nstructured and diﬃcult to incorporate patient narratives, making\nit nearly impossible in real clinical settings (40, 41). In our model,\nsemantic analysis could be eﬀectively performed to eﬃciently\nextract valuable clinical features from unstructured descriptions,\nthereby improving the accuracy and comprehensiveness of the\nCLBP decision-making process. Notably, our system extended\nFrontiers in Medicine 06 frontiersin.org\nfmed-12-1599241 May 9, 2025 Time: 17:31 # 7\nChen et al. 10.3389/fmed.2025.1599241\nTABLE 1 Experimental results for each model.\nModels CLBP-GPT, mean\n(SD)\nGPT-4.0, mean (SD) ERNIE Bot, mean\n(SD)\nDeepSeek, mean (SD)\nAccuracy 4.38 (0.19) 3.98 (0.49) 3.54 (0.55) 3.83 (0.47)\nRelevance 4.39 (0.20) 4.04 (0.47) 3.53 (0.49) 3.74 (0.44)\nClarity 4.42 (0.20) 4.01 (0.49) 3.56 (0.50) 3.85 (0.46)\nBeneﬁt 4.38 (0.21) 4.04 (0.49) 3.53 (0.57) 3.86 (0.54)\nCompleteness 4.42 (0.19) 4.10 (0.46) 3.52 (0.54) 3.77 (0.41)\nTotal 4.40 (0.20) 4.03 (0.48) 3.54 (0.53) 3.81 (0.47)\nFIGURE 2\nBox plots of the experimental results of the ﬁve indicators in each model. From left to right, they are CLBP-GPT, GPT4.0, ERNIE Bot, and DeepSeek.\nprevious ChatGPT applications in three key ways: First, the\nintegration of real-world patient data from hospitals and online\nhealthcare platforms enabled continuous learning and population-\nspeciﬁc adaptation. Second, the knowledge retrieval module\nenables real-time retrieval of the domain-speciﬁc knowledge,\nsigniﬁcantly enhancing the model’s decision-making accuracy\nwhile addressing the temporal limitations inherent in prior\nresearch (42). Third, a dedicated prompt engineering framework\nestablished an auditable reasoning path, which enhanced clinical\ninterpretability compared to traditional black-box models\n(43). The system could synthesize complex clinical variables\nconsistently with the superior performance of GPT-4 (44, 45),\nespecially when dealing with multifactorial pain conditions that\nrequired consideration of both biomedical and psychosocial\nfactors. However, our implementation diﬀered from pure\nLLMs approaches by explicitly incorporating clinical workﬂow\nconstraints, ensuring that the generated recommendations\nremained practical for implementation in resource-limited\nsettings. As a consequence, the ﬁnal indicators of CLBP-GPT were\nahead of pure LLMs approaches, providing users with a more\ncomplete clinical decision-making system whether in hospital or\nonline consultation.\nHowever, there were still several limitations in the study\nthat needed to be further improved. First, the current validation\nmainly focused on the evaluation of accuracy, so long-term follow-\nup studies should be conducted on the improvement of clinical\noutcomes. To solve this problem, we plan to establish cooperation\nwith multiple medical institutions in subsequent research to build\na patient data tracking system, which would record the initial\nstatus of patients. When they receive treatment based on CLBP-\nGPT decision recommendations, the pain relief rate, functional\nrecovery, basic health data would be recorded to provide baseline\ndata for subsequent comparisons. At the same time, a large\nmodel relied on memory mechanism was introduced, enabling the\nmodel to retain and call the historical information of patients.\nBy combining with real-time feedback data, the decision-making\nstrategy was dynamically optimized. By continuously collecting\nlong-term clinical indicators such as pain relief rate and functional\nrecovery, we would iteratively optimize the model by gradually\nimproving the decision-making accuracy and eﬀectiveness in long-\nterm clinical scenarios. Second, the knowledge-update mechanism\nneeded to be optimized, but it was diﬃcult to fully match the\nrapid development of the CLBP treatment. Third, the cross-\ncultural adaptability of the integrated psychological and social\nfactors module required further enhancement to ensure eﬀective\ndeployment worldwide. Based on the above ﬁndings, future\nresearches should be multicenter ones with clinical validation\nto evaluate the universality and eﬀectiveness of the framework\nin diﬀerent medical environments. In addition, a real-time\nknowledge synchronization mechanism should be developed\nFrontiers in Medicine 07 frontiersin.org\nfmed-12-1599241 May 9, 2025 Time: 17:31 # 8\nChen et al. 10.3389/fmed.2025.1599241\nto ensure the integration of the latest evidence-based medicine\nin a timely manner. Moreover, scholars should optimize the\ndesign of the doctor-AI collaborative interface, improve the\neﬃciency of workﬂow integration, and ultimately achieve a deep\nintegration of AI-assisted decision-making systems in clinical\npractice. We believed that the further advancement would lay\na solid foundation for the widespread application of the hybrid\nLLM-RAG architecture in chronic pain management.\n6 Conclusion\nThis study is the ﬁrst to systematically validate the application\nvalue of the hybrid LLM-RAG framework in the ﬁeld of chronic\npain management, conﬁrming the representation of a paradigm\nshift in this ﬁeld. This framework innovatively combines the deep\nanalytical capabilities of experienced clinicians with the systematic\nrigor of evidence-based medicine, providing a new solution\nfor CLBP management. As the development of personalized\nmedicine, the framework will not only demonstrate its feasibility\nin clinical practice but also provides a scalable template for\nmanaging complex chronic diseases that require longitudinal\nmultidisciplinary collaboration.\nData availability statement\nThe original contributions presented in this study are\nincluded in this article, further inquiries can be directed to the\ncorresponding authors.\nAuthor contributions\nRC: Data curation, Project administration, Validation,\nFormal Analysis, Methodology, Writing – review & editing,\nConceptualization, Investigation, Writing – original draft,\nSoftware. SZ: Software, Writing – original draft, Data curation. YZ:\nValidation, Conceptualization, Writing – original draft. QY: Formal\nAnalysis, Validation, Supervision, Writing – review and editing.\nCW: Validation, Methodology, Supervision, Funding acquisition,\nWriting – review and editing.\nFunding\nThe author(s) declare that ﬁnancial support was received for the\nresearch and/or publication of this article. This study was supported\nby the Guangdong-Hong Kong Technology and Innovation\nCooperation Funding (2023A0505010014), National Key Research\nand Development Program of China (2022YFC2009700), and the\nNational Natural Science Foundation of China (82172532).\nAcknowledgments\nWe appreciate the public database provider and maintenance\nstaﬀ. We also acknowledge the valuable insights provided\nby all reviewers.\nConﬂict of interest\nThe authors declare that the research was conducted in the\nabsence of any commercial or ﬁnancial relationships that could be\nconstrued as a potential conﬂict of interest.\nGenerative AI statement\nThe authors declare that no Generative AI was used in the\ncreation of this manuscript.\nPublisher’s note\nAll claims expressed in this article are solely those of the\nauthors and do not necessarily represent those of their aﬃliated\norganizations, or those of the publisher, the editors and the\nreviewers. Any product that may be evaluated in this article, or\nclaim that may be made by its manufacturer, is not guaranteed or\nendorsed by the publisher.\nReferences\n1. Wu A, March L, Zheng X, Huang J, Wang X, Zhao J, et al. Global low back pain\nprevalence and years lived with disability from 1990 to 2017: Estimates from the Global\nburden of disease study 2017. Ann Transl Med.(2017) 8:299. doi: 10.21037/atm.2020.\n02.175\n2. Gerhart J, Burns J, Bruehl S, Smith D, Post K, Porter L, et al. Variability in negative\nemotions among individuals with chronic low back pain: Relationships with pain and\nfunction. Pain. (2018) 159:342–50. doi: 10.1097/j.pain.0000000000001102\n3. Kabeer A, Osmani H, Patel J, Robinson P , Ahmed N. The adult with low back pain:\nCauses, diagnosis, imaging features and management. Br J Hosp Med (Lond).(2023)\n84:1–9. doi: 10.12968/hmed.2023.0063\n4. Wilson L, Denham A, Ionova Y , O’Neill C, Greco C, Hassett A, et al. Preferences\nfor risks and beneﬁts of treatment outcomes for chronic low back pain: Choice-\nbased conjoint measure development and discrete choice experiment. PM R (2024)\n16:836–47. doi: 10.1002/pmrj.13112\n5. Rajasekaran S, Dilip Chand Raja S, Pushpa BT, Ananda KB, Ajoy Prasad\nS, Rishi MK. The catastrophization eﬀects of an MRI report on the patient\nand surgeon and the beneﬁts of ‘clinical reporting’: Results from an RCT\nand blinded trials. Eur Spine J. (2021) 30:2069–81. doi: 10.1007/s00586-021-\n06809-0\n6. Reisener M, Pumberger M, Shue J, Girardi F , Hughes A. Trends in lumbar spinal\nfusion-a literature review. J Spine Surg.(2020) 6:752–61. doi: 10.21037/jss-20-492\n7. Xu W, Ran B, Luo W, Li Z, Gu R. Is lumbar fusion necessary for chronic low back\npain associated with degenerative disk disease? A Meta-Analysis. World Neurosurg.\n(2021) 146:298–306. doi: 10.1016/j.wneu.2020.11.121\n8. Stacey D, Légaré F , Lewis E, Barry EF , Bennett KB, Eden M. Decision\naids for people facing health treatment or screening decisions. Cochrane\nDatabase Syst Rev. (2017) 4:CD001431. doi: 10.1002/14651858.CD001431.\npub5\nFrontiers in Medicine 08 frontiersin.org\nfmed-12-1599241 May 9, 2025 Time: 17:31 # 9\nChen et al. 10.3389/fmed.2025.1599241\n9. Elwyn G, Frosch D, Thomson R, Joseph-Williams N, Lloyd A, Kinnersley P ,\net al. Shared decision making: A model for clinical practice. J Gen Intern Med.(2012)\n27:1361–7. doi: 10.1007/s11606-012-2077-6\n10. Cho Y , McKay M, Zadro J, Hoﬀmann T, Maher C, Harris I, et al. Development\nof a patient decision aid for people with chronic low back pain and degenerative disc\ndisease considering lumbar fusion: A mixed-methods study. Musculoskelet Sci Pract.\n(2025) 76:103261. doi: 10.1016/j.msksp.2025.103261\n11. Lim Y , Chou L, Au R, Seneviwickrama K, Cicuttini F , Briggs A, et al. People\nwith low back pain want clear, consistent and personalised information on prognosis,\ntreatment options and self-management strategies: A systematic review. J Physiother.\n(2019) 65:124–35. doi: 10.1016/j.jphys.2019.05.010\n12. Low M, Burgess L, Wainwright T. Patient information leaﬂets for lumbar\nspine surgery: A missed opportunity. J Patient Exp.(2020) 7:1403–9. doi: 10.1177/\n2374373519897176\n13. Mao C, Zhu Q, Chen R, Su W. Automatic medical specialty classiﬁcation based\non patients’ description of their symptoms.BMC Med Inform Decis Mak.(2023) 23:15.\ndoi: 10.1186/s12911-023-02105-7\n14. Zhu Q, Cheong-Iao Pang P , Chen C, Zheng Q, Zhang C, Li J, et al. Automatic\nkidney stone identiﬁcation: An adaptive feature-weighted LSTM model based on\nurine and blood routine analysis. Urolithiasis. (2024) 52:145. doi: 10.1007/s00240-024-\n01644-6\n15. Huang Y , Li C, Chen J, Wang Z, Zhao D, Y ang L, et al. A multidimensional\nregression model for predicting recurrence in chronic low back pain.Eur J Pain. (2025)\n29:e4793. doi: 10.1002/ejp.4793\n16. Licciardone J, Van Alfen B, Digilio M, Fowers R, Ballout B, Bibi Y , et al. Impact\nof shared decision-making on opioid prescribing among patients with chronic pain: A\nretrospective cohort study. J Pain.(2024) 25:104522. doi: 10.1016/j.jpain.2024.03.018\n17. Jiang F , Jiang Y , Zhi H, Dong Y , Li H, Ma S, et al. Artiﬁcial intelligence in\nhealthcare: Past, present and future. Stroke Vasc Neurol.(2017) 2:230–43. doi: 10.1136/\nsvn-2017-000101\n18. Laranjo L, Dunn A, Tong H, Kocaballi A, Chen J, Bashir R, et al. Conversational\nagents in healthcare: A systematic review. J Am Med Inform Assoc.(2018) 25:1248–58.\ndoi: 10.1093/jamia/ocy072\n19. Zhao WX, Zhou K, Li J, Tang T, Wang X, Hou Y. A survey of large language\nmodels. arXiv [Preprint](2023):doi: 10.48550/arXiv.2303.18223\n20. Thirunavukarasu A, Ting D, Elangovan K, Gutierrez L, Tan T, Ting D. Large\nlanguage models in medicine. Nat Med.(2023) 29:1930–40. doi: 10.1038/s41591-023-\n02448-8\n21. Brown B, Mann N, Ryder M, Subbiah JD, Kaplan P , Dhariwal A, et al. Language\nmodels are few-shot learners.Adv Neural Information Process Syst.(2020) 33:1877–901.\ndoi: 10.48550/arXiv.2005.14165\n22. Lee P , Bubeck S, Petro J. Beneﬁts, limits, and risks of GPT-4 as an AI chatbot for\nmedicine. N Engl J Med.(2023) 388:1233–9. doi: 10.1056/NEJMsr2214184\n23. Duﬀourc M, Gerke S. Generative AI in health care and liability risks for\nphysicians and safety concerns for patients. JAMA. (2023) 330:313–4. doi: 10.1001/\njama.2023.9630\n24. Ng KKY , Matsuba I, Zhang PC. RAG in health care: A novel framework\nfor improving communication and decision-making by addressing LLM limitations.\nNEJM AI.(2025) 2:AIra2400380. doi: 10.1056/AIra2400380\n25. Meskó B. Prompt engineering as an important emerging skill for medical\nprofessionals: Tutorial. J Med Internet Res.(2023) 25:e50638. doi: 10.2196/50638\n26. Jo E, Song S, Kim J, Lim S, Kim J, Cha J, et al. Assessing GPT-4’s performance in\ndelivering medical advice: Comparative analysis with human experts. JMIR Med Educ.\n(2024) 10:e51282. doi: 10.2196/51282\n27. Miao J, Thongprayoon C, Suppadungsuk S, Garcia Valencia OA,\nCheungpasitporn W. Integrating retrieval-augmented generation with large language\nmodels in nephrology: Advancing practical applications. Medicina. (2024) 60:445.\ndoi: 10.3390/medicina60030445\n28. Zhou Z, Y ang T, Ren T. IHILLM-RAG: A safe and private medical large language\nmodel based on intelligent hardware interaction and retrieval-augmented generation\n(RAG). in Proceedings of the Fourth International Computational Imaging Conference\n(CITA 2024). SPIE (2025). p. 1070–9. doi: 10.1117/12.3056789\n29. Wang C, Ong J, Wang C, Ong H, Cheng R, Ong D. Potential for GPT technology\nto optimize future clinical decision-making using retrieval-augmented generation.\nAnn Biomed Eng.(2024) 52:1115–8. doi: 10.1007/s10439-023-03327-6\n30. Zhou D, Schärli N, Hou L, Wei J, Scales N, Wang D, et al. Least-to-most\nprompting enables complex reasoning in large language models. arXiv [Preprint]\n(2022):doi: 10.48550/arXiv.2205.10625\n31. Lahat A, Sharif K, Zoabi N, Shneor Patt Y , Sharif Y , Fisher L, et al. Assessing\ngenerative pretrained transformers (GPT) in Clinical decision-making: Comparative\nanalysis of GPT-3.5 and GPT-4. J Med Internet Res.(2024) 26:e54571. doi: 10.2196/\n54571\n32. Eysenbach G. The role of ChatGPT, generative language models, and artiﬁcial\nintelligence in medical education: A conversation with ChatGPT and a call for papers.\nJMIR Med Educ.(2023) 9:e46885. doi: 10.2196/46885\n33. Rasmussen M, Larsen A, Subhi Y , Potapenko I. Artiﬁcial intelligence-\nbased ChatGPT chatbot responses for patient and parent questions on vernal\nkeratoconjunctivitis. Graefes Arch Clin Exp Ophthalmol.(2023) 261:3041–3. doi: 10.\n1007/s00417-023-06078-1\n34. Samaan J, Yeo Y , Rajeev N, Hawley L, Abel S, Ng W, et al. Assessing the accuracy\nof responses by the language model ChatGPT to questions regarding bariatric surgery.\nObes Surg. (2023) 33:1790–6. doi: 10.1007/s11695-023-06603-5\n35. Johnson S, King A, Warner E, Aneja S, Kann B, Bylund C. Using ChatGPT\nto evaluate cancer myths and misconceptions: Artiﬁcial intelligence and cancer\ninformation. JNCI Cancer Spectr.(2023) 7:kad015. doi: 10.1093/jncics/pkad015\n36. Mohd Isa I, Teoh S, Mohd Nor N, Mokhtar S. Discogenic low back pain:\nAnatomy, pathophysiology and treatments of intervertebral disc degeneration. Int J\nMol Sci.(2022) 24:208. doi: 10.3390/ijms24010208\n37. Hooten W, Cohen S. Evaluation and treatment of low back pain: A clinically\nfocused review for primary care specialists. Mayo Clin Proc. (2015) 90:1699–718.\ndoi: 10.1016/j.mayocp.2015.10.009\n38. Vader K, Donnelly C, Lane T, Newman G, Tripp D, Miller J. Delivering team-\nbased primary care for the management of chronic low back pain: An interpretive\ndescription qualitative study of healthcare provider perspectives. Can J Pain.(2023)\n7:2226719. doi: 10.1080/24740527.2023.2226719\n39. Pangarkar S, Kang D, Sandbrink F , Bevevino A, Tillisch K, Konitzer L, et al.\nV A/DoD clinical practice guideline: Diagnosis and treatment of low back pain. J Gen\nIntern Med.(2019) 34:2620–9. doi: 10.1007/s11606-019-05086-4\n40. Shim J, Ryu K, Cho E, Ahn J, Kim H, Lee Y , et al. Machine learning approaches\nto predict chronic lower back pain in people aged over 50 years. Medicina (Kaunas).\n(2021) 57:1230. doi: 10.3390/medicina57111230\n41. Lamichhane B, Jayasekera D, Jakes R, Glasser M, Zhang J, Y ang C, et al. Multi-\nmodal biomarkers of low back pain: A machine learning approach. Neuroimage Clin.\n(2021) 29:102530. doi: 10.1016/j.nicl.2020.102530\n42. Nori H, King N, McKinney SM, Carignan D, Horvitz E. Capabilities of gpt-4 on\nmedical challenge problems. arXiv [Preprint](2023):doi: 10.48550/arXiv.2303.13375\n43. Chiesa-Estomba C, Lechien J, Vaira L, Brunet A, Cammaroto G, Mayo-Y anez\nM, et al. Exploring the potential of Chat-GPT as a supportive tool for sialendoscopy\nclinical decision making and patient information support. Eur Arch Otorhinolaryngol.\n(2024) 281:2081–6. doi: 10.1007/s00405-023-08104-8\n44. Takagi S, Watari T, Erabi A, Sakaguchi K. Performance of GPT-3.5 and GPT-4\non the Japanese medical licensing examination: Comparison study. JMIR Med Educ.\n(2023) 9:e48002. doi: 10.2196/48002\n45. Moshirfar M, Altaf A, Stoakes I, Tuttle J, Hoopes P. Artiﬁcial intelligence in\nophthalmology: A comparative analysis of GPT-3.5, GPT-4, and human expertise in\nanswering StatPearls questions. Cureus. (2023) 15:e40822. doi: 10.7759/cureus.40822\nFrontiers in Medicine 09 frontiersin.org",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.5716696977615356
    },
    {
      "name": "Artificial intelligence",
      "score": 0.39600270986557007
    },
    {
      "name": "Natural language processing",
      "score": 0.34993332624435425
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I157773358",
      "name": "Sun Yat-sen University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210128921",
      "name": "The First Affiliated Hospital, Sun Yat-sen University",
      "country": "CN"
    }
  ],
  "cited_by": 2
}