{
  "title": "Text Augmented Open Knowledge Graph Completion via Pre-Trained Language Models",
  "url": "https://openalex.org/W4385572441",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2232394156",
      "name": "Pengcheng Jiang",
      "affiliations": [
        "University of Illinois Urbana-Champaign"
      ]
    },
    {
      "id": "https://openalex.org/A2325138078",
      "name": "Shivam Agarwal",
      "affiliations": [
        "University of Illinois Urbana-Champaign"
      ]
    },
    {
      "id": "https://openalex.org/A2158505021",
      "name": "Bowen Jin",
      "affiliations": [
        "University of Illinois Urbana-Champaign"
      ]
    },
    {
      "id": "https://openalex.org/A2096156584",
      "name": "Xuan Wang",
      "affiliations": [
        "Virginia Tech"
      ]
    },
    {
      "id": "https://openalex.org/A2110385854",
      "name": "Jimeng Sun",
      "affiliations": [
        "University of Illinois Urbana-Champaign"
      ]
    },
    {
      "id": "https://openalex.org/A2103606203",
      "name": "Jiawei Han",
      "affiliations": [
        "University of Illinois Urbana-Champaign"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2972167903",
    "https://openalex.org/W1533230146",
    "https://openalex.org/W4288122335",
    "https://openalex.org/W3021393704",
    "https://openalex.org/W3103296573",
    "https://openalex.org/W3010336026",
    "https://openalex.org/W2184957013",
    "https://openalex.org/W4285261975",
    "https://openalex.org/W3098267758",
    "https://openalex.org/W3172335055",
    "https://openalex.org/W2949434543",
    "https://openalex.org/W2593560537",
    "https://openalex.org/W2788798739",
    "https://openalex.org/W2759136286",
    "https://openalex.org/W2953351527",
    "https://openalex.org/W4252403066",
    "https://openalex.org/W2891146220",
    "https://openalex.org/W4223974161",
    "https://openalex.org/W3100103516",
    "https://openalex.org/W2159583324",
    "https://openalex.org/W2963041663",
    "https://openalex.org/W2970485665",
    "https://openalex.org/W3044438666",
    "https://openalex.org/W3164540570",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2432356473",
    "https://openalex.org/W2786016794",
    "https://openalex.org/W2728059831",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3034833075",
    "https://openalex.org/W3035458998",
    "https://openalex.org/W3104415840",
    "https://openalex.org/W2127795553",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2769099080",
    "https://openalex.org/W3130089296",
    "https://openalex.org/W2890216969",
    "https://openalex.org/W2952068915",
    "https://openalex.org/W3117339789",
    "https://openalex.org/W4283765342",
    "https://openalex.org/W2739716023",
    "https://openalex.org/W2970476646"
  ],
  "abstract": "The mission of open knowledge graph (KG) completion is to draw new findings from known facts. Existing works that augment KG completion require either (1) factual triples to enlarge the graph reasoning space or (2) manually designed prompts to extract knowledge from a pre-trained language model (PLM), exhibiting limited performance and requiring expensive efforts from experts. To this end, we propose TagReal that automatically generates quality query prompts and retrieves support information from large text corpora to probe knowledge from PLM for KG completion. The results show that TagReal achieves state-of-the-art performance on two benchmark datasets. We find that TagReal has superb performance even with limited training data, outperforming existing embedding-based, graph-based, and PLM-based methods.",
  "full_text": "Findings of the Association for Computational Linguistics: ACL 2023, pages 11161‚Äì11180\nJuly 9-14, 2023 ¬©2023 Association for Computational Linguistics\nText-Augmented Open Knowledge Graph Completion via\nPre-Trained Language Models\nPengcheng Jiang* , Shivam Agarwal* , Bowen Jin* , Xuan Wang‚Ä†,\nJimeng Sun* and Jiawei Han*\n*Department of Computer Science, University of Illinois at Urbana-Champaign\n‚Ä†Department of Computer Science, Virginia Tech\n{pj20, shivama2, bowenj4, jimeng, hanj}@illinois.edu xuanw@vt.edu\nAbstract\nThe mission of open knowledge graph (KG)\ncompletion is to draw new findings from known\nfacts. Existing works that augment KG comple-\ntion require either (1) factual triples to enlarge\nthe graph reasoning space or (2) manually de-\nsigned prompts to extract knowledge from a\npre-trained language model (PLM), exhibiting\nlimited performance and requiring expensive\nefforts from experts. To this end, we propose\nTAGREAL that automatically generates quality\nquery prompts and retrieves support informa-\ntion from large text corpora to probe knowledge\nfrom PLM for KG completion. The results\nshow that TAGREAL achieves state-of-the-art\nperformance on two benchmark datasets. We\nfind that TAGREAL has superb performance\neven with limited training data, outperforming\nexisting embedding-based, graph-based, and\nPLM-based methods.\n1 Introduction\nA knowledge graph (KG) is a heterogeneous graph\nthat encodes factual information in the form of\nentity-relation-entity triplets, where a relation con-\nnects a head entity and a tail entity (e.g., ‚ÄúMiami-\nlocated_in-USA‚Äù) (Wang et al., 2017; Hogan et al.,\n2021). KG (Dai et al., 2020) plays a central role\nin many NLP applications, including question an-\nswering (Hao et al., 2017; Yasunaga et al., 2021),\nrecommender systems (Zhou et al., 2020), and drug\ndiscovery (Zitnik et al., 2018). However, existing\nworks (Wang et al., 2018; Hamilton et al., 2018)\nshow that most large-scale KGs are incomplete and\ncannot fully cover the massive real-world knowl-\nedge. This challenge motivates KG completion,\nwhich aims to find one or more object entities given\na subject entity and a relation (Lin et al., 2015). For\nexample, in Figure 1, our goal is to predict the ob-\nject entity with ‚ÄúDetroit‚Äù as the subject entity and\n‚Äúcontained_by‚Äù as the relation.\nHowever, existing KG completion approaches\n(Trouillon et al., 2016b; Das et al., 2018) have sev-\nTriple Query: (Detroit, contained_by, ?)\nDetroitis located in [MASK] .Canada\nPeople from Detroit,[MASK] .Michigan(phew‚Ä¶ not sure though.)\nPLM\nHuman effort\nPrompt mining\nFilled Triple: (Detroit, contained_by, Michigan) ADD\nKnowledge Graph\nSupport information retrieval\nDetroit is the largest city in the U.S state of Michigan. People from Detroit,[MASK] .Michigan(I‚Äôm pretty sure!!!)\nFigure 1: The quality of hand-crafted prompts can be\nlimited, while prompt mining is a scalable alternative.\nSupport information also helps PLM understand the pur-\npose of prompts. In this example, Canada and Michigan\nare potentially valid options but given prompt mining\nand support information retrieval, the model becomes\nconfident about Michigan as the answer here.\neral limitations (Fu et al., 2019). First, their perfor-\nmance heavily depends on the density of the graph.\nThey usually perform well on dense graphs with\nrich structural information but poorly on sparse\ngraphs which are more common in real-world ap-\nplications. Second, previous methods (e.g., Bordes\net al. (2013)) assume a closed-world KG without\nconsidering vast open knowledge in the external\nresources. In fact, in many cases, a KG is usually\nassociated with a rich text corpus (Bodenreider,\n2004), which contains a vast amount of factual data\nnot yet extracted. To overcome these challenges we\ninvestigate the task of open knowledge graph com-\npletion, where KG can be constructed using new\nfacts from outside the KG. Recent text-enriched\nsolutions (Fu et al., 2019) focus on using a pre-\ndefined set of facts to enrich the knowledge graph.\nNonetheless, the pre-defined set of facts is often\nnoisy and constricted, that is, they do not provide\nsufficient information to efficiently update the KG.\n11161\nPre-trained language models (PLMs) (Devlin\net al., 2019; Liu et al., 2019a) have shown to be\npowerful in capturing factual knowledge implicitly\nfrom learning on massive unlabeled texts (Petroni\net al., 2019b). Since PLMs are superb in text en-\ncoding, they can be utilized to facilitate knowl-\nedge graph completion with external text informa-\ntion. Recent knowledge graph completion methods\n(Shin et al., 2020; Lv et al., 2022) focus on using\nmanually crafted prompts (e.g., ‚ÄúDetroit is located\nin [MASK]‚Äù in Figure 1) to query the PLMs for\ngraph completion (e.g., ‚ÄúMichigan‚Äù). However,\nmanually creating prompts can be expensive with\nlimited quality (e.g., PLM gives a wrong answer\n‚ÄúCanada‚Äù to the query with a handcrafted prompt,\nas shown in Figure 1).\nBuilding on the above limitations of standard KG\nand the enormous power of PLMs (Devlin et al.,\n2019; Liu et al., 2019a), we aim to use PLMs for\nopen knowledge graph completion. We propose an\nend-to-end framework that jointly exploits the im-\nplicit knowledge in PLMs and textual information\nin the corpus to perform knowledge graph comple-\ntion (as shown in Figure 1). Unlike existing works\n(e.g., (Fu et al., 2019; Lv et al., 2022)), our method\ndoes not require a manually pre-defined set of facts\nand prompts, which is more general and easier to\nadapt to real-world applications.\nOur contributions can be summarized as:\n‚Ä¢ We study the open KG completion problem\nthat can be assisted by facts captured from\nPLMs. To this end, we propose a new frame-\nwork TAGREAL that denotes text augmented\nopen KG completion with real-world knowl-\nedge in PLMs.\n‚Ä¢ We develop prompt generation and infor-\nmation retrieval methods, which enable\nTAGREAL to automatically create high-\nquality prompts for PLM knowledge prob-\ning and search support information, making\nit more practical especially when PLMs lack\nsome domain knowledge.\n‚Ä¢ Through extensive quantitative and qualitative\nexperiments on real-world knowledge graphs\nsuch as Freebase1 we show the applicability\nand advantages of our framework.2\n1https://github.com/thunlp/OpenNRE\n2Our code is available at: https://github.com/\npat-jj/TagReal\n2 Related Work\n2.1 KG Completion Methods\nKG completion methods can be categorized\ninto embedding-based and PLM-based methods.\nEmbedding-based methods represent entities and\nrelations as embedding vectors and maintain their\nsemantic relations in the vector space. TransE (Bor-\ndes et al., 2013) vectorizes the head, the relation\nand the tail of triples into a Euclidean space. Dist-\nMult (Yang et al., 2014) converts all relation em-\nbeddings into diagonal matrices in bilinear models.\nRotatE (Sun et al., 2019) presents each relation em-\nbedding as a rotation in complex vector space from\nthe head entity to the tail entity.\nIn recent years, researchers have realized that\nPLMs can serve as knowledge bases (Petroni et al.,\n2019a; Zhang et al., 2020; AlKhamissi et al.,\n2022). PLM-based methods for KG comple-\ntion (Yao et al., 2019; Kim et al., 2020; Chang\net al., 2021; Lv et al., 2022) start to gain atten-\ntion. As a pioneer, KG-BERT (Yao et al., 2019)\nfine-tunes PLM with concatenated head, relation,\nand tail in each triple, outperforming the conven-\ntional embedding-based methods in link prediction\ntasks. Lv et al.(2022) present PKGC, which uses\nmanually designed triple prompts and carefully se-\nlected support prompts as inputs to the PLM. Their\nresult shows that PLMs could be used to substan-\ntially improve the KG completion performance,\nespecially in the open-world (Shi and Weninger,\n2018) setting. Compared to PKGC, our frame-\nwork TAGREAL automatically generates prompts\nof higher quality without any domain expert knowl-\nedge. Furthermore, instead of pre-supposing the\nexistence of support information, we search rele-\nvant textual information from the corpus with an\ninformation retrieval method to support the PLM\nknowledge probing.\n2.2 Knowledge Probing using Prompts\nLAMA (Petroni et al., 2019a) is the first framework\nfor knowledge probing from PLMs. The prompts\nare manually created with a subject placeholder\nand an unfilled space for the object. For exam-\nple, a triple query (Miami, location, ?) may have\na prompt ‚ÄúMiami is located in [MASK]‚Äù where\n‚Äú<subject> is located in [MASK]‚Äù is the tem-\nplate for ‚Äúlocation‚Äù relation. The training goal is to\ncorrectly fill [MASK]with PLM‚Äôs prediction. An-\nother work, BertNet (Hao et al., 2022), proposes\nan approach applying GPT-3 (Brown et al., 2020)\n11162\nKG triplesPattern Mining & Selection (with MetaPADand TruePIE)Prompt Optimization (with PLM)\nPrompt GenerationQuality Prompts\nSupport Information Retrieval (with BM25) Support Texts Query (‚Ñé,ùëü,?)Inference\nMasked Sentence\nPredicted entityùë°\nTriples (‚Ñé,ùëü,ùë°)Labels (0 / 1)Training\nLabeled SentencesPre-trained Language ModelFine-tune\nPrompt Generation & Support Information Retrieval \nFigure 2: TAGREAL Framework. The input and output\nof each phase are highlighted by red and green, respec-\ntively. The dotted arrow indicates the optional process.\nto automatically generate a weighted prompt en-\nsemble with input entity pairs and a manual seed\nprompt. It then uses PLM again to search and se-\nlect top-ranked entity pairs with the ensemble for\nKG completion.\n2.3 Prompt Mining Methods\nWhen there are several relations to interpret, man-\nual prompt design is costly due to the require-\nment of domain expert knowledge. In addition,\nthe prompt quality could not be ensured. Hence,\nquality prompt mining catches the interest of re-\nsearchers. Jiang et al. 2020 propose an approach\nMINE which searches middle words or dependency\npaths between the given inputs and outputs in a\nlarge text corpus (e.g., Wikipedia). They also pro-\npose a reasonable approach to optimize the ensem-\nble of the mined prompts by weighting prompt in-\ndividuals regarding their performance on the PLM.\nBefore the emergence and widespread use of\nPLMs, textual pattern mining performed a similar\nfunction to find reliable patterns for information ex-\ntraction. For instance, MetaPAD (Jiang et al., 2017)\ngenerates quality meta patterns by context-aware\nsegmentation with the pattern quality function, and\nTruePIE (Li et al., 2018) proposes the concept of\npattern embedding and a self-training framework,\nthat discovers positive patterns automatically.\n3 Methodology\nWe propose TAGREAL , a PLM-based framework\nto handle KG completion tasks. In contrast to the\nprevious work, our framework does not rely on\nhandcrafted prompts or pre-defined relevant facts.\nAs shown in Figure 2, we automatically create ap-\npropriate prompts and search relevant support in-\nformation, which are further utilized as templates\nto explore implicit knowledge from PLMs.\n3.1 Problem Formulation\nKnowledge graph completion is to add new\ntriples (facts) to the existing triple set of a KG.\nThere are two tasks to achieve this goal. The first\nis triple classification, which is a binary classifica-\ntion task to predict whether a triple(h,r,t) belongs\nto the KG, where h,r,t denote head entity, relation\nand tail entity respectively. The second task is link\nprediction, which targets on predicting either the\ntail entity twith a query (h,r,?) or the head entity\nhwith a query (?,r,t).\n3.2 Prompt Generation\nPrevious studies (e.g., Jiang et al. (2020)) demon-\nstrate that the accuracy of relational knowledge\nextracted from PLMs heavily relies on the qual-\nity of prompts used for querying. To this end, we\ndevelop a comprehensive approach for automatic\nquality prompt generation given triples in KG as\nthe only input, as shown in Figure 3. We use textual\npattern mining methods to mine quality patterns\nfrom large corpora as the prompts used for PLM\nknowledge probing. As far as we know, we are\npioneers in using textual pattern mining methods\nfor LM prompt mining. We believe in the appli-\ncability of this approach for the following reasons.\n‚Ä¢ Similar data sources. We apply pattern mining on\nlarge corpora (e.g., Wikipedia) which are the data\nsources where most of PLMs are pre-trained.\n‚Ä¢ Similar objectives. Textual pattern mining is to\nmine patterns to extract new information from\nlarge corpora; prompt mining is to mine prompts\nto probe implicit knowledge from PLMs.\n‚Ä¢ Similar performance criteria. The reliability of\na pattern or a prompt is indicated by how many\naccurate facts it can extract from corpora/PLMs.\nSub-corpora mining is the first step that creates\nthe data source for the pattern mining. Specifically,\ngiven a KG with a relation set R= (r1,r2,...,r k),\nwe first extract tuples Tri paired by head entities\nand tail entities for each relation ri ‚ààRfrom the\nKG. For example, for the relation r1: /busi-\nness/company/founder, we extract all tu-\nples like <microsoft, bill_gates> in this\nrelation from the KG. For each tuple tj, we then\nsearch sentences stj containing both head and tail\nfrom a large corpus (e.g., Wikipedia) and other\nreliable sources, which is added to compose the\nsub-corpus Cri . We limit the size of each set to Œ∏\n11163\n, size(      )\nFinal prompts                for relation\nFinal prompts                for relation\nInput: Relations Tuples for‚à∂<microsoft, bill_gates>‚à∂<amazon, jeff_benzos>‚ãÆ‚à∂<sony, masaru_ibuka>\tTuple ExtractionSub-corpus for‚Äú[Y] co-founded [X] corporation in 1975 withpaulallen.‚Äù‚ãÆ‚Äú[Y] is a co-founder of[X], along with his late childhood friend paulallen.‚Äù ‚ãÆ‚Äú[Y] was a co-founder of [X] , along with akiomorita.‚Äù‚ãÆ‚Äú[X] founder and wasedaalumnus [Y] ‚Äù\nSub-corpora Mining\nPhrase Segmentation(e.g., with AutoPhrase)& Frequent Pattern Mining(e.g., with FP-Growth)\nPrompt candidates               for relationùëù!\":ùëù#\":ùëù$\": ùëù%\":‚ãÆùëù&'#\":ùëù&'!\":ùëù&\":\nPrompt Selection\nPrompt Optimizationùëù!,!:         [Y],  founder of [X]ùëù!,#:         [Y], co-founder of [X]‚ãÆùëù!,$:         [Y], chairman of [X]\nFinal prompts                for relationùëù%,!:         [X], neighborhood of [Y]ùëù%,#:         [Y] 's [X] neighborhood‚ãÆùëù%,$:         [X] area of [Y]\n‚ãÆ\nOutput: Final prompts\n +Reliable Sources (optional)\nContextual (e.g., MetaPAD)Embedding (e.g., TruePIE)+\nprob. distribution of\n‚à∂\t/business/company/founder‚ãÆ‚à∂\t/location/neighbor/neighbor_of\n<latexit sha1_base64=\"XUbn61ZbL7FgDF7bVOD1f3Wb3Bs=\">AAACEnicbVBNS8NAEJ34WetX1KOXxSLqpSQq6rHoxWMF+wFNDZvttl262YTdjVBCfoMX/4oXD4p49eTNf+Om7aG2Phh4vDfDzLwg5kxpx/mxFhaXlldWC2vF9Y3NrW17Z7euokQSWiMRj2QzwIpyJmhNM81pM5YUhwGnjWBwk/uNRyoVi8S9Hsa0HeKeYF1GsDaSb594IdZ9gnlazfxU+m72kB5lyGMCTTm55tslp+yMgOaJOyElmKDq299eJyJJSIUmHCvVcp1Yt1MsNSOcZkUvUTTGZIB7tGWowCFV7XT0UoYOjdJB3UiaEhqN1OmJFIdKDcPAdOZnqlkvF//zWonuXrVTJuJEU0HGi7oJRzpCeT6owyQlmg8NwUQycysifSwx0SbFognBnX15ntRPy+5F+ezuvFS5nsRRgH04gGNw4RIqcAtVqAGBJ3iBN3i3nq1X68P6HLcuWJOZPfgD6+sXmWCeDw==</latexit>\nP0\nr1 2 P0\n<latexit sha1_base64=\"rFr2STcyMRpbgcbm1K6SgxwQWzk=\">AAACCnicbVBNS8NAEJ34WetX1KOX1SJ4KomKeix68VjBfkBTyma7aZduNmF3I5SQsxf/ihcPinj1F3jz37hpc6itDwYe780wM8+POVPacX6speWV1bX10kZ5c2t7Z9fe22+qKJGENkjEI9n2saKcCdrQTHPajiXFoc9pyx/d5n7rkUrFIvGgxzHthnggWMAI1kbq2UdeiPWQYJ7Ws14qe6MMeUygWdWuOFVnArRI3IJUoEC9Z397/YgkIRWacKxUx3Vi3U2x1IxwmpW9RNEYkxEe0I6hAodUddPJKxk6MUofBZE0JTSaqLMTKQ6VGoe+6cxPVPNeLv7ndRIdXHdTJuJEU0Gmi4KEIx2hPBfUZ5ISzceGYCKZuRWRIZaYaJNe2YTgzr+8SJpnVfeyen5/UandFHGU4BCO4RRcuIIa3EEdGkDgCV7gDd6tZ+vV+rA+p61LVjFzAH9gff0C1uKa/w==</latexit>\nPrk 2 P\n<latexit sha1_base64=\"7+mcSsxWBbxf8VzLGuupe25vQXk=\">AAACCnicbVBNS8NAEJ34WetX1KOX1SJ4KomKeix68VjBfkBTyma7aZduNmF3I5SQsxf/ihcPinj1F3jz37hpc6itDwYe780wM8+POVPacX6speWV1bX10kZ5c2t7Z9fe22+qKJGENkjEI9n2saKcCdrQTHPajiXFoc9pyx/d5n7rkUrFIvGgxzHthnggWMAI1kbq2UdeiPWQYJ7Ws14qe26GPCbQrGpXnKozAVokbkEqUKDes7+9fkSSkApNOFaq4zqx7qZYakY4zcpeomiMyQgPaMdQgUOquunklQydGKWPgkiaEhpN1NmJFIdKjUPfdOYnqnkvF//zOokOrrspE3GiqSDTRUHCkY5QngvqM0mJ5mNDMJHM3IrIEEtMtEmvbEJw519eJM2zqntZPb+/qNRuijhKcAjHcAouXEEN7qAODSDwBC/wBu/Ws/VqfVif09Ylq5g5gD+wvn4BeyCaxQ==</latexit>\nPr1 2 P\n<latexit sha1_base64=\"HJ7geknRgeX4TXp1z7+f459Aeu0=\">AAAB8nicbVBNS8NAFHypX7V+VT16CRbBU0lU1GPRi8cK1hbSUDbbbbt0sxt2X4QS+jO8eFDEq7/Gm//GTZuDtg4sDDPvsfMmSgQ36HnfTmlldW19o7xZ2dre2d2r7h88GpVqylpUCaU7ETFMcMlayFGwTqIZiSPB2tH4NvfbT0wbruQDThIWxmQo+YBTglYKujHBESUia0571ZpX92Zwl4lfkBoUaPaqX92+omnMJFJBjAl8L8EwIxo5FWxa6aaGJYSOyZAFlkoSMxNms8hT98QqfXegtH0S3Zn6eyMjsTGTOLKTeUSz6OXif16Q4uA6zLhMUmSSzj8apMJF5eb3u32uGUUxsYRQzW1Wl46IJhRtSxVbgr948jJ5PKv7l/Xz+4ta46aoowxHcAyn4MMVNOAOmtACCgqe4RXeHHRenHfnYz5acoqdQ/gD5/MHibWRbg==</latexit>\nP\n<latexit sha1_base64=\"4XI+wJjqEGR/m+ohfIGxTEIgvCk=\">AAAB9HicbVBNSwMxEJ3Ur1q/qh69BIvgqeyqqMeiF49V7Ae0S8mm2TY0m12TbKEs+zu8eFDEqz/Gm//GtN2Dtj4YeLw3w8w8PxZcG8f5RoWV1bX1jeJmaWt7Z3evvH/Q1FGiKGvQSESq7RPNBJesYbgRrB0rRkJfsJY/up36rTFTmkfy0Uxi5oVkIHnAKTFW8lLVczPc5RKnD1mvXHGqzgx4mbg5qUCOeq/81e1HNAmZNFQQrTuuExsvJcpwKlhW6iaaxYSOyIB1LJUkZNpLZ0dn+MQqfRxEypY0eKb+nkhJqPUk9G1nSMxQL3pT8T+vk5jg2ku5jBPDJJ0vChKBTYSnCeA+V4waMbGEUMXtrZgOiSLU2JxKNgR38eVl0jyrupfV8/uLSu0mj6MIR3AMp+DCFdTgDurQAApP8Ayv8IbG6AW9o495awHlM4fwB+jzBzCCkbs=</latexit>\nr1 2 R\n<latexit sha1_base64=\"Z6nOtfQdw4AzBRlRysyXkvmvsVo=\">AAAB9HicbVBNSwMxEJ3Ur1q/qh69BIvgqeyqqMeiF49V7Ae0S8mm2TY0m12TbKEs+zu8eFDEqz/Gm//GtN2Dtj4YeLw3w8w8PxZcG8f5RoWV1bX1jeJmaWt7Z3evvH/Q1FGiKGvQSESq7RPNBJesYbgRrB0rRkJfsJY/up36rTFTmkfy0Uxi5oVkIHnAKTFW8lLVG2W4yyVOH7JeueJUnRnwMnFzUoEc9V75q9uPaBIyaaggWndcJzZeSpThVLCs1E00iwkdkQHrWCpJyLSXzo7O8IlV+jiIlC1p8Ez9PZGSUOtJ6NvOkJihXvSm4n9eJzHBtZdyGSeGSTpfFCQCmwhPE8B9rhg1YmIJoYrbWzEdEkWosTmVbAju4svLpHlWdS+r5/cXldpNHkcRjuAYTsGFK6jBHdShARSe4Ble4Q2N0Qt6Rx/z1gLKZw7hD9DnD4p0kfU=</latexit>\nrk 2 R\n<latexit sha1_base64=\"4XI+wJjqEGR/m+ohfIGxTEIgvCk=\">AAAB9HicbVBNSwMxEJ3Ur1q/qh69BIvgqeyqqMeiF49V7Ae0S8mm2TY0m12TbKEs+zu8eFDEqz/Gm//GtN2Dtj4YeLw3w8w8PxZcG8f5RoWV1bX1jeJmaWt7Z3evvH/Q1FGiKGvQSESq7RPNBJesYbgRrB0rRkJfsJY/up36rTFTmkfy0Uxi5oVkIHnAKTFW8lLVczPc5RKnD1mvXHGqzgx4mbg5qUCOeq/81e1HNAmZNFQQrTuuExsvJcpwKlhW6iaaxYSOyIB1LJUkZNpLZ0dn+MQqfRxEypY0eKb+nkhJqPUk9G1nSMxQL3pT8T+vk5jg2ku5jBPDJJ0vChKBTYSnCeA+V4waMbGEUMXtrZgOiSLU2JxKNgR38eVl0jyrupfV8/uLSu0mj6MIR3AMp+DCFdTgDurQAApP8Ayv8IbG6AW9o495awHlM4fwB+jzBzCCkbs=</latexit>\nr1 2 R\n<latexit sha1_base64=\"Wno3kQyyi9iY+T7kRpEhbFMlvCM=\">AAAB+nicbVDLTsMwENzwLOWVwpGLRYXEqUoAAccKLhyL1JfURpHjOq1Vx4lsB1SFfgoXDiDElS/hxt/gtDlAy0grjWd25d0JEs6Udpxva2V1bX1js7RV3t7Z3du3KwdtFaeS0BaJeSy7AVaUM0FbmmlOu4mkOAo47QTj29zvPFCpWCyaepJQL8JDwUJGsDaSb1ey5tTPpO9OUZ8JlL/sqlNzZkDLxC1IFQo0fPurP4hJGlGhCcdK9Vwn0V6GpWaE02m5nyqaYDLGQ9ozVOCIKi+brT5FJ0YZoDCWpoRGM/X3RIYjpSZRYDojrEdq0cvF/7xeqsNrL2MiSTUVZP5RmHKkY5TngAZMUqL5xBBMJDO7IjLCEhNt0iqbENzFk5dJ+6zmXtbO7y+q9ZsijhIcwTGcggtXUIc7aEALCDzCM7zCm/VkvVjv1se8dcUqZg7hD6zPH98Zk8E=</latexit>\nTr1 2 T\n<latexit sha1_base64=\"euQrQrAZND8ZB83M6DKunNKQGjM=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKeyqqMegF4/xkQckS5idzCZDZmeXmV4hLPkELx4U8eoXefNvnCR70GhBQ1HVTXdXkEhh0HW/nMLS8srqWnG9tLG5tb1T3t1rmjjVjDdYLGPdDqjhUijeQIGStxPNaRRI3gpG11O/9ci1EbF6wHHC/YgOlAgFo2il++xu0itX3Ko7A/lLvJxUIEe9V/7s9mOWRlwhk9SYjucm6GdUo2CST0rd1PCEshEd8I6likbc+Nns1Ak5skqfhLG2pZDM1J8TGY2MGUeB7YwoDs2iNxX/8zophpd+JlSSIldsvihMJcGYTP8mfaE5Qzm2hDIt7K2EDammDG06JRuCt/jyX9I8qXrn1dPbs0rtKo+jCAdwCMfgwQXU4Abq0AAGA3iCF3h1pPPsvDnv89aCk8/swy84H99yTY3q</latexit>\nR\n<latexit sha1_base64=\"KMpJy7hEUeqeV3/pwWGEkdPflpU=\">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lU1GPRi8cKxhbaUDbbTbt0swm7E6GE/gYvHhTx6g/y5r9x2+agrQ8GHu/NMDMvTKUw6LrfTmlldW19o7xZ2dre2d2r7h88miTTjPsskYluh9RwKRT3UaDk7VRzGoeSt8LR7dRvPXFtRKIecJzyIKYDJSLBKFrJz3XPm/SqNbfuzkCWiVeQGhRo9qpf3X7CspgrZJIa0/HcFIOcahRM8kmlmxmeUjaiA96xVNGYmyCfHTshJ1bpkyjRthSSmfp7IqexMeM4tJ0xxaFZ9Kbif14nw+g6yIVKM+SKzRdFmSSYkOnnpC80ZyjHllCmhb2VsCHVlKHNp2JD8BZfXiaPZ3Xvsn5+f1Fr3BRxlOEIjuEUPLiCBtxBE3xgIOAZXuHNUc6L8+58zFtLTjFzCH/gfP4AydeOrg==</latexit>\nr1\n<latexit sha1_base64=\"NYbkFH83bXnPUsovQjxpGb4PAcg=\">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lU1GPRi8cKxhbaUDbbSbt0swm7G6GE/gYvHhTx6g/y5r9x2+agrQ8GHu/NMDMvTAXXxnW/ndLK6tr6RnmzsrW9s7tX3T941EmmGPosEYlqh1Sj4BJ9w43AdqqQxqHAVji6nfqtJ1SaJ/LBjFMMYjqQPOKMGiv5ueqNJr1qza27M5Bl4hWkBgWavepXt5+wLEZpmKBadzw3NUFOleFM4KTSzTSmlI3oADuWShqjDvLZsRNyYpU+iRJlSxoyU39P5DTWehyHtjOmZqgXvan4n9fJTHQd5FymmUHJ5ouiTBCTkOnnpM8VMiPGllCmuL2VsCFVlBmbT8WG4C2+vEwez+reZf38/qLWuCniKMMRHMMpeHAFDbiDJvjAgMMzvMKbI50X5935mLeWnGLmEP7A+fwBIgiO6A==</latexit>\nrk\n<latexit sha1_base64=\"Fq26QnbIZKQHBazXdNiFbSC6BwY=\">AAACDnicbZDLSsNAFIYn9VbrLerSzWApVJCSqKi4KrpxWcFeoA1hMp20QycXZiZiiHkCN76KGxeKuHXtzrdxkmahrT8MfPznHOac3wkZFdIwvrXSwuLS8kp5tbK2vrG5pW/vdEQQcUzaOGAB7zlIEEZ90pZUMtILOUGew0jXmVxl9e4d4YIG/q2MQ2J5aORTl2IklWXrtYGH5BgjlrRSO+G2mV5AhfUkTh+S+/Qwtw5svWo0jFxwHswCqqBQy9a/BsMARx7xJWZIiL5phNJKEJcUM5JWBpEgIcITNCJ9hT7yiLCS/JwU1pQzhG7A1fMlzN3fEwnyhIg9R3Vmy4vZWmb+V+tH0j23EuqHkSQ+nn7kRgzKAGbZwCHlBEsWK0CYU7UrxGPEEZYqwYoKwZw9eR46Rw3ztHF8c1JtXhZxlMEe2Ad1YIIz0ATXoAXaAINH8AxewZv2pL1o79rHtLWkFTO74I+0zx+WkZxy</latexit>\nPr1 : P (y|x, r1)\n<latexit sha1_base64=\"FMepRgrTdWsRu93RpwkZ0YdNeZ8=\">AAAB+nicbVDLTsMwENzwLOWVwpGLRYXEqUoAAceKXjgWiT6kNooc122tOk5kO6Aq5FO4cAAhrnwJN/4Gp80BWkZaaTyzK+9OEHOmtON8Wyura+sbm6Wt8vbO7t6+XTloqyiRhLZIxCPZDbCinAna0kxz2o0lxWHAaSeYNHK/80ClYpG419OYeiEeCTZkBGsj+XYlbWR+Kn03Q30mUP6yq07NmQEtE7cgVSjQ9O2v/iAiSUiFJhwr1XOdWHsplpoRTrNyP1E0xmSCR7RnqMAhVV46Wz1DJ0YZoGEkTQmNZurviRSHSk3DwHSGWI/VopeL/3m9RA+vvZSJONFUkPlHw4QjHaE8BzRgkhLNp4ZgIpnZFZExlphok1bZhOAunrxM2mc197J2fndRrd8UcZTgCI7hFFy4gjrcQhNaQOARnuEV3qwn68V6tz7mrStWMXMIf2B9/gCqgZOf</latexit>\nCr1 2 C\n<latexit sha1_base64=\"4XI+wJjqEGR/m+ohfIGxTEIgvCk=\">AAAB9HicbVBNSwMxEJ3Ur1q/qh69BIvgqeyqqMeiF49V7Ae0S8mm2TY0m12TbKEs+zu8eFDEqz/Gm//GtN2Dtj4YeLw3w8w8PxZcG8f5RoWV1bX1jeJmaWt7Z3evvH/Q1FGiKGvQSESq7RPNBJesYbgRrB0rRkJfsJY/up36rTFTmkfy0Uxi5oVkIHnAKTFW8lLVczPc5RKnD1mvXHGqzgx4mbg5qUCOeq/81e1HNAmZNFQQrTuuExsvJcpwKlhW6iaaxYSOyIB1LJUkZNpLZ0dn+MQqfRxEypY0eKb+nkhJqPUk9G1nSMxQL3pT8T+vk5jg2ku5jBPDJJ0vChKBTYSnCeA+V4waMbGEUMXtrZgOiSLU2JxKNgR38eVl0jyrupfV8/uLSu0mj6MIR3AMp+DCFdTgDurQAApP8Ayv8IbG6AW9o495awHlM4fwB+jzBzCCkbs=</latexit>\nr1 2 R\n<latexit sha1_base64=\"4XI+wJjqEGR/m+ohfIGxTEIgvCk=\">AAAB9HicbVBNSwMxEJ3Ur1q/qh69BIvgqeyqqMeiF49V7Ae0S8mm2TY0m12TbKEs+zu8eFDEqz/Gm//GtN2Dtj4YeLw3w8w8PxZcG8f5RoWV1bX1jeJmaWt7Z3evvH/Q1FGiKGvQSESq7RPNBJesYbgRrB0rRkJfsJY/up36rTFTmkfy0Uxi5oVkIHnAKTFW8lLVczPc5RKnD1mvXHGqzgx4mbg5qUCOeq/81e1HNAmZNFQQrTuuExsvJcpwKlhW6iaaxYSOyIB1LJUkZNpLZ0dn+MQqfRxEypY0eKb+nkhJqPUk9G1nSMxQL3pT8T+vk5jg2ku5jBPDJJ0vChKBTYSnCeA+V4waMbGEUMXtrZgOiSLU2JxKNgR38eVl0jyrupfV8/uLSu0mj6MIR3AMp+DCFdTgDurQAApP8Ayv8IbG6AW9o495awHlM4fwB+jzBzCCkbs=</latexit>\nr1 2 R\n<latexit sha1_base64=\"DRZdoqlGvkGLd3BqMIfk4DJEFq8=\">AAAB8HicbVBNS8NAEN3Ur1q/qh69LBbBU0lU1GPRi8cK9kPaEDbbTbt0dxN2J0IJ+RVePCji1Z/jzX/jts1BWx8MPN6bYWZemAhuwHW/ndLK6tr6RnmzsrW9s7tX3T9omzjVlLVoLGLdDYlhgivWAg6CdRPNiAwF64Tj26nfeWLa8Fg9wCRhviRDxSNOCVjpMTN5kEHg5UG15tbdGfAy8QpSQwWaQfWrP4hpKpkCKogxPc9NwM+IBk4Fyyv91LCE0DEZsp6likhm/Gx2cI5PrDLAUaxtKcAz9fdERqQxExnaTklgZBa9qfif10shuvYzrpIUmKLzRVEqMMR4+j0ecM0oiIklhGpub8V0RDShYDOq2BC8xZeXSfus7l3Wz+8vao2bIo4yOkLH6BR56Ao10B1qohaiSKJn9IreHO28OO/Ox7y15BQzh+gPnM8fIsuQog==</latexit>\ns t 1\n<latexit sha1_base64=\"sW+IZxEfJdgC4f3CPiN070Jj7NE=\">AAAB8HicbVBNS8NAEN3Ur1q/qh69LBbBU0lU1GPRi8cK9kPaEDbbTbt0dxN2J0IJ+RVePCji1Z/jzX/jts1BWx8MPN6bYWZemAhuwHW/ndLK6tr6RnmzsrW9s7tX3T9omzjVlLVoLGLdDYlhgivWAg6CdRPNiAwF64Tj26nfeWLa8Fg9wCRhviRDxSNOCVjpMTN5kEEwyoNqza27M+Bl4hWkhgo0g+pXfxDTVDIFVBBjep6bgJ8RDZwKllf6qWEJoWMyZD1LFZHM+Nns4ByfWGWAo1jbUoBn6u+JjEhjJjK0nZLAyCx6U/E/r5dCdO1nXCUpMEXni6JUYIjx9Hs84JpREBNLCNXc3orpiGhCwWZUsSF4iy8vk/ZZ3busn99f1Bo3RRxldISO0Sny0BVqoDvURC1EkUTP6BW9Odp5cd6dj3lrySlmDtEfOJ8/dl6Q2Q==</latexit>\ns t h\n<latexit sha1_base64=\"WznT86dl5cWIS+5RpVWvnUYTtUU=\">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lU1GPRi8cKxhbaUDbbTbt0swm7E6GE/gYvHhTx6g/y5r9x2+agrQ8GHu/NMDMvTKUw6LrfTmlldW19o7xZ2dre2d2r7h88miTTjPsskYluh9RwKRT3UaDk7VRzGoeSt8LR7dRvPXFtRKIecJzyIKYDJSLBKFrJz7HnTXrVmlt3ZyDLxCtIDQo0e9Wvbj9hWcwVMkmN6XhuikFONQom+aTSzQxPKRvRAe9YqmjMTZDPjp2QE6v0SZRoWwrJTP09kdPYmHEc2s6Y4tAselPxP6+TYXQd5EKlGXLF5ouiTBJMyPRz0heaM5RjSyjTwt5K2JBqytDmU7EheIsvL5PHs7p3WT+/v6g1boo4ynAEx3AKHlxBA+6gCT4wEPAMr/DmKOfFeXc+5q0lp5g5hD9wPn8AzOWOsA==</latexit>\nt1\n<latexit sha1_base64=\"dPWjqX6/nVhIZX4QhSrAKW92LPE=\">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0mqqMeiF48VTFtoQ9lst+3SzSbsToQS+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MJHCoOt+O4W19Y3NreJ2aWd3b/+gfHjUNHGqGfdZLGPdDqnhUijuo0DJ24nmNAolb4Xju5nfeuLaiFg94iThQUSHSgwEo2glP8NebdorV9yqOwdZJV5OKpCj0St/dfsxSyOukElqTMdzEwwyqlEwyaelbmp4QtmYDnnHUkUjboJsfuyUnFmlTwaxtqWQzNXfExmNjJlEoe2MKI7MsjcT//M6KQ5ugkyoJEWu2GLRIJUEYzL7nPSF5gzlxBLKtLC3EjaimjK0+ZRsCN7yy6ukWat6V9WLh8tK/TaPowgncArn4ME11OEeGuADAwHP8ApvjnJenHfnY9FacPKZY/gD5/MHzmqOsQ==</latexit>\nt2\n<latexit sha1_base64=\"9QpSKn880CcaiphecyA57m+6RWE=\">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lU1GPRi8cKxhbaUDbbTbt0swm7E6GE/gYvHhTx6g/y5r9x2+agrQ8GHu/NMDMvTKUw6LrfTmlldW19o7xZ2dre2d2r7h88miTTjPsskYluh9RwKRT3UaDk7VRzGoeSt8LR7dRvPXFtRKIecJzyIKYDJSLBKFrJz7E3nPSqNbfuzkCWiVeQGhRo9qpf3X7CspgrZJIa0/HcFIOcahRM8kmlmxmeUjaiA96xVNGYmyCfHTshJ1bpkyjRthSSmfp7IqexMeM4tJ0xxaFZ9Kbif14nw+g6yIVKM+SKzRdFmSSYkOnnpC80ZyjHllCmhb2VsCHVlKHNp2JD8BZfXiaPZ3Xvsn5+f1Fr3BRxlOEIjuEUPLiCBtxBE3xgIOAZXuHNUc6L8+58zFtLTjFzCH/gfP4AIIeO5w==</latexit>\nth\n0.30880.20440.1441\n0.27180.23550.0923\n<latexit sha1_base64=\"Q5sk8kaQ9uZCUHBTdDtYfVtrExk=\">AAAB8HicbVBNS8NAEN3Ur1q/qh69LBbBU0lU1GPRi8cK9kPaEDbbTbt0dxN2J0IJ+RVePCji1Z/jzX/jts1BWx8MPN6bYWZemAhuwHW/ndLK6tr6RnmzsrW9s7tX3T9omzjVlLVoLGLdDYlhgivWAg6CdRPNiAwF64Tj26nfeWLa8Fg9wCRhviRDxSNOCVjpMTN5kEHA86Bac+vuDHiZeAWpoQLNoPrVH8Q0lUwBFcSYnucm4GdEA6eC5ZV+alhC6JgMWc9SRSQzfjY7OMcnVhngKNa2FOCZ+nsiI9KYiQxtpyQwMoveVPzP66UQXfsZV0kKTNH5oigVGGI8/R4PuGYUxMQSQjW3t2I6IppQsBlVbAje4svLpH1W9y7r5/cXtcZNEUcZHaFjdIo8dIUa6A41UQtRJNEzekVvjnZenHfnY95acoqZQ/QHzucPd+OQ2g==</latexit>\ns t i\n<latexit sha1_base64=\"uxL/n+0c28V7FdkH7t5rQCptJpI=\">AAAB73icbVBNS8NAEN34WetX1aOXxSJ4KomKehGKXjxWsB/QhrLZTtqlm03cnQgl9E948aCIV/+ON/+N2zYHbX0w8Hhvhpl5QSKFQdf9dpaWV1bX1gsbxc2t7Z3d0t5+w8Sp5lDnsYx1K2AGpFBQR4ESWokGFgUSmsHwduI3n0AbEasHHCXgR6yvRCg4Qyu1rmkHB4CsWyq7FXcKuki8nJRJjlq39NXpxTyNQCGXzJi25yboZ0yj4BLGxU5qIGF8yPrQtlSxCIyfTe8d02Or9GgYa1sK6VT9PZGxyJhRFNjOiOHAzHsT8T+vnWJ45WdCJSmC4rNFYSopxnTyPO0JDRzlyBLGtbC3Uj5gmnG0ERVtCN78y4ukcVrxLipn9+fl6k0eR4EckiNyQjxySarkjtRInXAiyTN5JW/Oo/PivDsfs9YlJ585IH/gfP4Af9+PoQ==</latexit>\n= ‚úì\n<latexit sha1_base64=\"3/c1a0ICFjGijZDCYRy8U3m68zg=\">AAAB+nicbVDLSsNAFL2pr1pfqS7dDBbBVUlU1GXRjcsK9gFtCJPptB06mYSZiVJiPsWNC0Xc+iXu/BsnbRbaemDgcM693DMniDlT2nG+rdLK6tr6RnmzsrW9s7tnV/fbKkokoS0S8Uh2A6woZ4K2NNOcdmNJcRhw2gkmN7nfeaBSsUjc62lMvRCPBBsygrWRfLvaD7EeE8zTZuan0ncz3645dWcGtEzcgtSgQNO3v/qDiCQhFZpwrFTPdWLtpVhqRjjNKv1E0RiTCR7RnqECh1R56Sx6ho6NMkDDSJonNJqpvzdSHCo1DQMzmQdVi14u/uf1Ej288lIm4kRTQeaHhglHOkJ5D2jAJCWaTw3BRDKTFZExlpho01bFlOAufnmZtE/r7kX97O681rgu6ijDIRzBCbhwCQ24hSa0gMAjPMMrvFlP1ov1bn3MR0tWsXMAf2B9/gCPxZQ0</latexit>\nP r 1\n[X] and [Y] and[Y], founder of [X][Y] leaves [X] [Y] co-founded [X] with paul allen\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t‚ãÆfounder [Y][Y] says [X] that[X]‚Äôs founder [Y]\nFigure 3: Prompt generation process. The solid lines connect the intermediate processes, and the arrows point to\nthe intermediate/final results. Input and output are highlighted in red and green respectively. [X] and [Y] denote\nhead and tail entities respectively.\nfor each tuple to mine more generic patterns for\nfuture applications.\nPhrase segmentation and frequent pattern\nmining are applied to mine patterns from sub-\ncorpora as prompt candidates. We use AutoPhrase\n(Shang et al., 2018) to segment corpora to more nat-\nural and unambiguous semantic phrases, and use\nFP-Growth algorithm (Han et al., 2000) to mine\nfrequent appeared patterns to compose a candidate\nset P\n‚Ä≤\nri = (p\n‚Ä≤\n1,p\n‚Ä≤\n2,...,p\n‚Ä≤\nm). The size of the set is\nlarge, as there are plenty of messy textual patterns.\nPrompt selection. To select quality patterns\nfrom the candidate set, we apply two textual min-\ning approaches: MetaPAD (Jiang et al., 2017) and\nTruePIE (Li et al., 2018). MetaPAD applies pat-\ntern quality function introducing several criteria\nof contextual features to estimate the reliability\nof a pattern. We explain why those features can\nalso be adapted for LM prompt estimation: (1) Fre-\nquency and concordance: Since a PLM learns more\ncontextual relations between frequent patterns and\nentities during the pre-training stage, a pattern oc-\ncurs more frequently in the background corpus can\nprobe more facts from the PLM. Similarly, if a pat-\ntern composed of highly associated sub-patterns\nappears frequently, it should be considered as a\ngood one as the PLM would be familiar with the\ncontextual relations among the sub-patterns. (2)\nInformativeness: A pattern with low informative-\nness (e.g., p\n‚Ä≤\n1 in Figure 3) has the weak ability of\nPLM knowledge probing, as the relation between\nthe subject or object entities cannot be well inter-\npreted by it. (3) Completeness: The completeness\nof a pattern affects a lot to the PLM knowledge\nprobing especially when any of the placeholders is\nmissing (e.g., p\n‚Ä≤\nm‚àí2 in Figure 3) so that PLM can-\nnot even give an answer. (4) Coverage: A quality\npattern should be able to probe accurate facts from\nPLM as many as possible. Therefore, patterns like\np\n‚Ä≤\n4 which only suit a few or only one case should\nhave a low quality score. We then apply TruePIE\non the prompts (patterns) selected by MetaPAD.\nTruePIE filters the prompts that have low cosine\nsimilarity with the positive samples (e.g., p\n‚Ä≤\n3 and\np\n‚Ä≤\nm‚àí1 are filtered), which matters to the creation of\nprompt ensemble since we want the prompts in the\nensemble to be semantically close to each other so\nthat some poor-quality prompts would not signifi-\ncantly impact the prediction result by PLM. As a\nresult, we create a more reliable prompt ensemble\nPri = {pi,1,pi,2,...,p i,n}based on the averaged\nprobabilities given by the prompts:\nP(y|x,ri) = 1\nn\nn‚àë\nj=1\nPLM(y|x,pi,j), (1)\nwhere ri is the i-th relation and pi,j is the j-th\nprompt in Pri . Beyond prompt selection, a prompt\noptimization process is also employed. Pointed\nout by Jiang et al. 2020, some prompts in the en-\nsemble are more reliable and ought to be weighted\nmore. Thus, we change Equation 1 to:\nP(y|x,ri) =\nn‚àë\nj=1\nwi,jPLM(y|x,pi,j), (2)\nwhere wi,j is the weight of j-th prompt for i-th\nrelation. In our setting, all weights {w1,1,..,w k,n}\n11164\nQuery\tùëû!\":\t<ùëöicrosoft, /business/company/founder,?>BM25‚Äúhowever,microsoftisplanningasignificantmarketingpushintothefieldwithakeynotespeechbybill_gates,thecompany'sco-founderandchairman.‚Äùùëù#:    [Y],  founder of [X]ùëù$:    [Y], co-founder of [X]\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t‚ãÆùëù%:    [Y], chairman of [X]\n‚Äú[CLS]however,microsoftisplanningasignificantmarketingpushintothefieldwithakeynotespeechbybill_gates,thecompany'sco-founderandchairman.[SEP][MASK],founderofmicrosoft‚Äù‚ãÆ\nPrompt ensemble ùí´\"\nSupport Information ùëÜ&!\"\nQuery instances ùëû2!\"\t:\nFigure 4: Support information retrieval.\nare learned through PLM to optimize P(y|x,ri)\nfor ri ‚ààRahead of the training process.\n3.3 Support Information Retrieval\nIn addition to the prompt mining, we also attach\nsome query-wise and triple-wise support text infor-\nmation to the prompt to help the PLMs understand\nthe knowledge we want to probe as well as to aid\nin training triple classification ability. As seen in\nFigure 4, for the i-th query qr\ni in relation r, we use\nBM25 (Robertson et al., 1995) to retrieve highly\nranked support texts with score greater than Œ¥and\nlength shorter than œïfrom the reliable corpus and\nrandomly select one of them as the support informa-\ntion. To compose the input cloze ÀÜqr\ni to the PLM, we\nconcatenate the support text to each prompt in the\noptimized ensemble we obtained through previous\nsteps, with the subject filled and the object masked.\n[CLS] and [SEP] are the tokens for sequence\nclassification and support information-prompt sep-\naration accordingly.\nIn the training stage, we search texts using triples\nrather than queries, and the [MASK] would be\nfilled by the object entities. It is worth noting that\nsupport text is optional in TAGREAL , and we leave\nit blank if no matching data is found.\n3.4 Training\nTo train our model, we create negative triples in\naddition to the given positive triples following\nthe idea introduced by PKGC (Lv et al., 2022),\nto handle the triple classification task. We cre-\nate negative triples by replacing the head and tail\nin each positive triple with the \"incorrect\" en-\ntity that achieves high probability by the KGE\nmodel. We also create random negative sam-\nples by randomly replacing the heads and tails\nto enlarge the set of negative training/validation\ntriples. The labeled training triples are assembled\nas T = T+ ‚à™(T‚àí\nKGE ‚à™T‚àí\nRAND) where T+ is the\npositive set, T‚àí\nKGE and T‚àí\nRAND are two negative\nsets we created by embedding model-based and ran-\ndom approaches respectively. Then, we transform\nall training triples of each relation rinto sentences\nwith the prompt ensemble Pr and the triple-wise\nsupport information retrieved by BM25 (if there is\nany). At the training stage, the[MASK] is replaced\nby the object entity in each positive/negative triple.\nThe query instances ÀÜqr\ni are then used to fine-tune\nthe PLM by updating its parameters. Cross-entropy\nloss (Lv et al., 2022) is applied for optimization:\nL= ‚àí\n‚àë\nœÑ‚ààT\n(yœÑ log(c1\nœÑ) + (1‚àíyœÑ)log(c0\nœÑ)\nM ), (3)\nwhere c0\nœÑ,c1\nœÑ ‚àà [0,1] are the softmax classifica-\ntion scores of the token [CLS] for the triple œÑ,\nyœÑ is the ground truth label (1/0) of the triple, and\nM = (|T+|/|T‚àí|) is the ratio between the number\nof positive and negative triples. After the PLM is\nfine-tuned with positive/negative triples in training\nset, it should have a better performance on classi-\nfying the triples in the dataset compared to a raw\nPLM. This capability would enable it to perform\nKG completion as well.\n3.5 Inference\nGiven a query (h,r,?), we apply the query-wise\nsupport information that is relevant to the head\nentity h and relation r, as we presume that we\nare unaware of the tail entity (our prediction goal).\nThen, we make the corresponding query instances\ncontaining [MASK], with both support informa-\ntion and prompt ensemble, as shown in Figure 4.\nTo leverage the triple classification capability of\nthe PLM on link prediction, we replace [MASK]\nin a query instance with each entity in the known\nentity set and rank their classification scores in\ndescending order to create a 1-d vector as the pre-\ndiction result for each query. This indicates that\nthe lower-indexed entities in the vector are more\nlikely to compose a positive triple with the input\nquery. For prompt ensemble, we sum up the scores\nby entity index before ranking them. The detailed\nillustration is placed in Appendix E.\n11165\nModel 20% 50% 100%\nHits@5 Hits@10 MRR Hits@5 Hits@10 MRR Hits@5 Hits@10 MRR\nKGE-based\nTransE (Bordes et al., 2013) 29.13 32.67 15.80 41.54 45.74 25.82 42.53 46.77 29.86\nDisMult (Yang et al., 2014) 3.44 4.31 2.64 15.98 18.85 13.14 37.94 41.62 30.56\nComplEx (Trouillon et al., 2016a) 4.32 5.48 3.16 15.00 17.73 12.21 35.42 38.85 28.59\nConvE (Dettmers et al., 2018) 29.49 33.30 24.31 40.10 44.03 32.97 50.18 54.06 40.39\nTuckER (Bala≈æevi¬¥c et al., 2019) 29.50 32.48 24.44 41.73 45.58 33.84 51.09 54.80 40.47\nRotatE (Sun et al., 2019) 15.91 18.32 12.65 35.48 39.42 28.92 51.73 55.27 42.64\nText&KGE-based\nRC-Net (Xu et al., 2014) 13.48 15.37 13.26 14.87 16.54 14.63 14.69 16.34 14.41\nTransE+Line (Fu et al., 2019) 12.17 15.16 4.88 21.70 25.75 8.81 26.76 31.65 10.97\nJointNRE (Han et al., 2018) 16.93 20.74 11.39 26.96 31.54 21.24 42.02 47.33 32.68\nRL-based MINERV A (Das et al., 2017) 11.64 14.16 8.93 25.16 31.54 22.24 43.80 44.70 34.62\nCPL (Fu et al., 2019) 15.19 18.00 10.87 26.81 31.70 23.80 43.25 49.50 33.52\nPLM-based PKGC (Lv et al., 2022) 35.77 43.82 28.62 41.93 46.70 31.81 41.98 52.56 32.11\nTagReal (our method) 45.59 51.34 35.41 48.98 55.64 38.03 50.85 60.64 38.86\nTable 1: Performance comparison of KG completion on FB60K-NYT10 dataset. Results are averaged values of\nten independent runs of head/tail entity predictions. The highest score is highlighted in bold.\n4 Experiment\n4.1 Datasets and Compared Methods\nDatasets. We use the datasets FB60K-NYT10\nand UMLS-PubMed provided by Fu et al., where\nFB60K and UMLS are knowledge graphs and\nNYT10 and PubMed are corpora. FB60K-NYT10\ncontains more general relations (e.g., ‚Äúnational-\nity of perso‚Äù) whereas UMLS-PubMed focuses on\nbiomedical domain-specific relations (e.g., ‚Äúgene\nmapped to diseas‚Äù). We apply the pre-processed\ndataset 3 (with training/validation/testing data size\n8:1:1) to align the evaluation of our method with\nthe baselines. Due to the imbalanced distribution\nand noise present in FB60K-NYT10 and UMLS-\nPubMed, 16 and 8 relations are selected for the\nperformance evaluation, respectively. We place\nmore details of the datasets in Appendix A.\nCompared Methods. We compare our model\nTAGREAL with four categories of methods. For (1)\ntraditional KG embedding-based methods, we eval-\nuate TransE (Bordes et al., 2013), DisMult (Yang\net al., 2014), ComplEx (Trouillon et al., 2016a),\nConvE (Dettmers et al., 2018),TuckER(Bala≈æevi¬¥c\net al., 2019) and RotatE (Sun et al., 2019) where\nTuckER is a newly added model. For (2) joint text\nand graph embedding methods, we evaluate RC-\nNet (Xu et al., 2014), TransE+LINE (Fu et al.,\n2019) and JointNRE (Han et al., 2018). For (3) re-\ninforcement learning (RL) based path-finding meth-\nods, we evaluate MINERV A(Das et al., 2017) and\nCPL (Fu et al., 2019). For (4) PLM-based meth-\nods, we evaluate PKGC (Lv et al., 2022) and our\nmethod TAGREAL . We keep the reported data of\n(2) and (3) by Fu et al.2019 while re-evaluating all\n3https://github.com/INK-USC/CPL#\ndatasets\nmodels in (1) in different settings for more rigorous\ncomparison (see Appendix I for details). PKGC\nin our setting can be viewed as TAGREAL with\nmanual prompts and without support information.\n4.2 Experimental Setup\nFor FB60K-NYT10, we use LUKE (Yamada et al.,\n2020), a PLM pre-trained on more Wikipedia data\nwith RoBERTa (Liu et al., 2019b). For UMLS-\nPubMed, we use SapBert (Liu et al., 2021) that pre-\ntrained on both UMLS and PubMed with BERT\n(Devlin et al., 2019). For sub-corpora mining, we\nuse Wikipedia with 6,458,670 document examples\nas the general corpus and NYT10/PubMed as the\nreliable sources, and we mine 500 sentences at max-\nimum (Œ∏ = 500) for each tuple. For the prompt\nselection, we apply MetaPAD with its default set-\nting, and apply TruePIE with the infrequent pattern\npenalty, and thresholds for positive patterns and\nnegative patterns reset to {0.5, 0.7, 0.3} respec-\ntively. For support information retrieval, we use\nBM25 to search relevant texts with Œ¥ = 0.9 and\nœï= 100in the corpora NYT10/PubMed. We fol-\nlow the same fine-tuning process as PKGC. We\nuse TuckER as the KGE model to create negative\ntriples, and we set M = 30 as the ratio of posi-\ntive/negative triples. To compare with baselines,\nwe test our model on training sets in the ratios of\n[20%, 50%, 100%] for FB60K-NYT10 and [20%,\n40%, 70%, 100%] for UMLS-PubMed. The evalu-\nation metrics are described in Appendix F.\n5 Results\n5.1 Performance Comparison\nWe show the performance comparison with the\nstate-of-the-art methods in Tables 1 and 2. As one\ncan observe, TAGREAL outperforms the existing\n11166\nModel 20% 40% 70% 100%\nHits@5 Hits@10 Hits@5 Hits@10 Hits@5 Hits@10 Hits@5 Hits@10\nKGE-based\nTransE (Bordes et al., 2013) 19.70 30.47 27.72 41.99 34.62 49.29 40.83 53.62\nDisMult (Yang et al., 2014) 19.02 28.35 28.28 40.48 32.66 47.01 39.53 53.82\nComplEx (Trouillon et al., 2016a) 11.28 17.17 24.64 35.15 25.89 38.19 34.54 49.30\nConvE (Dettmers et al., 2018) 20.45 30.72 27.90 42.49 30.67 45.91 29.85 45.68\nTuckER (Bala≈æevi¬¥c et al., 2019) 19.94 30.82 25.79 41.00 26.48 42.48 30.22 45.33\nRotatE (Sun et al., 2019) 17.95 27.55 27.35 40.68 34.81 48.81 40.15 53.82\nText&KGE-based\nRC-Net (Xu et al., 2014) 7.94 10.77 7.56 11.43 8.31 11.81 9.26 12.00\nTransE+Line (Fu et al., 2019) 23.63 31.85 24.86 38.58 25.43 34.88 22.31 33.65\nJointNRE (Han et al., 2018) 21.05 31.37 27.96 40.10 30.87 44.47 - -\nRL-based MINERV A (Das et al., 2017) 11.55 19.87 24.65 35.71 35.80 46.26 57.63 63.83\nCPL (Fu et al., 2019) 15.32 24.22 26.96 38.03 37.23 47.60 58.10 65.16\nPLM-based PKGC (Lv et al., 2022) 31.08 43.49 41.34 52.44 47.39 55.52 55.05 59.43\nTagReal (our method) 35.83 46.45 46.26 55.99 53.46 60.40 60.68 62.88\nTable 2: Performance comparison of KG completion on UMLS-PubMed dataset. Results are averaged values\nof ten independent runs of head/tail entity predictions. The highest score is highlighted in bold.\nCondition FB60K-NYT10 UMLS-PubMed\n20% 50% 100% 20% 40% 70% 100%\nman (35.77, 43.82) (41.93, 46.70) (41.98, 52.56) (31.08, 43.49) (41.34, 52.44) (47.39, 56.52) (55.05, 59.43)\nman+supp (43.23, 47.74) (47.10, 52.02) (48.66, 57.46) (32.95, 44.42) (44.37, 54.96) (51.98, 59.09) (59.99, 61.23)\nmine+supp (44.54, 49.53) (47.43, 53.87) (49.03, 58.82) (35.56, 45.33) (45.35, 55.44) (53.12, 59.65) (60.27, 61.70)\noptim+supp (45.59, 51.34) (48.98, 55.64) (50.85, 60.64) (35.83, 46.45) (46.26, 55.99) (53.46, 60.40) (60.68, 62.88)\nTable 3: Ablation study on prompt and support information. Data in brackets denotes Hits@5 (left) and Hits@10\n(right). \"man\", \"mine\" and \"optim\" denote TAGREAL with manual prompts, mined prompt ensemble without\noptimization and optimized prompt ensemble, respectively. \"supp\" denotes application of support information.\nworks in most cases. Given dense training data,\nKGE-based methods (e.g., RotatE) and RL-based\nmethods (e.g., CPL) can still achieve relatively\nhigh performance. However, when the training\ndata is limited, these approaches suffer, whereas\nPLM-based methods (PKGC and TAGREAL ) are\nnot greatly impacted. Our approach performs no-\nticeably better in such cases than the current non-\nPLM-based ones. This is because the KGE models\ncannot be trained effectively with inadequate data,\nand the RL-based path-finding models cannot rec-\nognize the underlying patterns given insufficient\nevidential and general paths in KG. On the other\nhand, PLMs already possess implicit information\nthat can be used directly, and the negative effects\nof insufficient data in fine-tuning would be less\nharsh than in training from scratch. TAGREAL out-\nperforms PKGC due to its ability to automatically\nmine quality prompts and retrieve support infor-\nmation in contrast to manual annotations which\nare often limited. Next, we analyze the impacts of\nsupport information and prompt generation on the\nperformance of TAGREAL .\n5.2 Model Analysis\nWe conduct an ablation study to verify the effec-\ntiveness of both automatically generated prompts\nand retrieved support information. The results are\npresented in Table 3, Figure 5 and 6.\n0 2 4 6\nTraining Progress\n0.65\n0.70\n0.75\n0.80\n0.85F1-score\nFB60K-NYT10\nf1: (man, LUKE)\nf2: (optim, LUKE)\nf3: (f1) + supp\nf4: (f2) + supp\n0 2 4 6\nTraining Progress\n0.80\n0.85\n0.90\n0.95\nUMLS-PubMed\nu1: (man, SapBert)\nu2: (optim, LUKE)\nu3: (optim, SapBert)\nu4: (u2) + supp\nu5: (u3) + supp\nFigure 5: Performance (F1-Score) variation of triple\nclassification w.r.t training time. \"man\" or \"optim\"\nmeans TAGREAL with manual prompts or optimized\nprompt ensemble. \"supp\" denotes support information.\nppn\nllc\nppl\nppb\npdd\nppe\npep\nbpc\nppr\nlnn\nbcf\nppc\nlac\nlca\nbcp\nluc\nrelations\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0Hits@10\nman\nman+supp\nmine+supp\noptim+supp\nFigure 6: Relation-wise KG completion performance\n(Hits@10) comparison on FB60K-NYT10. Labels on\nthe x-axis are the abbreviations of relations.\nSupport Information. As shown in Table 3,\nfor FB60K-NYT10, support information helps im-\nprove Hits@5 and Hits@10 in ranges of [5.2%,\n11167\nManual Prompt[Y] is located in [X].\nQuery: (?, /location/location/contains, alba)\n‚Äúinalba,italy'strufflecapital,inthenorthwesternprovinceofpiedmont,demandforthefungihasspawnedacottageindustryofpackagetours,foodfestivalsandastripmalloftruffle-themedshops.‚Äù\n[Y], [X] .  0.10490836homein[Y], [X] .   0.23949857[Y] is in [X] .   0.24573646school in [Y], [X] . 0.32810964people from [Y], [X] .   0.34946583\nOptimized Prompt Ensembleweights\nSupport Information (retrieved by BM25)\nPredictions (Top10 in descending order of classification scores)Man :  Optim :  Man + Supp :  Optim+ Supp :  \nunited_states_of_america,pennsylvania,france,lombardy,abruzzo,jamaica,piedmont,ivrea,massachusetts,iraqsicily,italy,massachusetts,lazio,piedmont,united_states_of_america,abruzzo,tuscany,iraq,milancuneo,piedmont,italy,sicily,lazio,texas,campania,northern_italy,scotland,calabriapiedmont,cuneo,italy, northern_italy,canale,tuscany,campania,sicily,lazio, calabria\nFigure 7: Example of the link prediction with TAGREAL on FB60K-NYT10. Man denotes manual prompt.\nOptim denotes optimized prompt ensemble. Supp denotes support information. The ground truth tail entity ,\nhelpful information and optimized prompts (darker for higher weights) are highlighted.\n7.5%] and [3.8%, 5.3%], respectively. For UMLS-\nPubMed, it helps improve Hits@5 and Hits10 in\nranges of [1.9%, 4.94%] and [0.9%, 3.6%], respec-\ntively. Although the overlap between UMLS and\nPubMed is higher than that between FB60K and\nNYT10 (Fu et al., 2019), the textual information in\nPubMed could not help as much as NYT10 since\nthat: (1) SapBert already possesses adequate im-\nplicit knowledge on both UMLS and PubMed so\nthat a large portion of additional support texts might\nbe useless. The lines \"u2\", \"u3\", \"u4\" and \"u5\" in\nFigure 5 show that support information helps more\nwhen using LUKE as the PLM as it contains less\ndomain-specific knowledge. It also infers that the\nsupport information could be generalized to any\napplication, especially when fine-tuning a PLM is\ndifficult in low-resource scenarios (Arase and Tsu-\njii, 2019; mahabadi et al., 2021). (2) UMLS con-\ntains more queries with multiple correct answers\nthan FB60K (see Appendix A), which means some\nqueries are likely \"misled\" to another answer and\nthus not counted into the Hits@N metric.\nPrompt Generation. Almost all of the relations,\nas shown in Figure 6, could be converted into better\nprompts by our prompt mining and optimization, al-\nbeit some of them might be marginally worse than\nmanually created prompts due to the following fact.\nA few of the mined prompts, which are of lower\nquality than the manually created prompts, may\nsignificantly negatively affect the prediction score\nfor the ensemble with equal weighting. Weight-\ning based on PLM reduces such negative effects\nof the poor prompts for the optimized ensembles\nand enables them to outperform most handcrafted\nprompts. In addition, Table 3 shows the overall im-\nprovement for these three types of prompts, demon-\nstrating that for both datasets, optimized ensembles\noutperform equally weighted ensembles, which in\nturn outperform manually created prompts. More-\nover, by comparing line \"f1\" with line \"f2\", or line\n\"u1\" with line \"u3\" in Figure 5, we find a perfor-\nmance gap between PLM with manual prompts and\nwith the optimized ensemble for triple classifica-\ntion, highlighting the effectiveness of our method.\n5.3 Case Study\nFigure 7 shows an example of using TAGREAL for\nlink prediction with a query (?, /location/location/\ncontains, alba) where ‚Äú piedmont‚Äù is the ground\ntruth. By comparing the prediction results in differ-\nent pairs, we find that both prompt generation and\nsupport information could enhance the KG com-\npletion performance. With the handcrafted prompt,\nthe PLM simply lists out the terms that have some\nconnections to the subject entity ‚Äú alba‚Äù without\nbeing aware that we are trying to find the place it is\nlocated in. Differently, with the optimized prompt\nensemble, the PLM lists entities that are highly rel-\nevant to our target, where ‚Äúcuneo‚Äù, ‚Äúitaly‚Äù, ‚Äúnorth-\nern_italy‚Äù are correct real-world answers, indicat-\ning that our intention is well conveyed to the PLM.\nWith the support information, the PLM increases\nthe score of entities that are related to the keywords\n(‚Äúitaly‚Äù, ‚Äúpiedmont‚Äù) in the text. Moreover, the op-\ntimized ensemble removes ‚Äútexas‚Äù and ‚Äúscotland‚Äù\nfrom the list and leaves only Italy-related locations.\nMore examples are placed in Appendix H.\n11168\n6 Conclusion and Future Works\nIn this study, we proposed a novel framework to\nexploit the implicit knowledge in PLM for open\nKG completion. Experimental results show that\nour method outperforms existing methods espe-\ncially when the training data is limited. We showed\nthat the optimized prompts with our approach out-\nperform the handcrafted ones in PLM knowledge\nprobing. The effectiveness of the support informa-\ntion retrieval to aid the prompting is also demon-\nstrated. In the future, we may leverage QA model‚Äôs\npower to retrieve more reliable support information.\nAnother potential extension is to make our model\nmore explainable by exploring path-finding tasks.\n7 Limitations\nDue to the nature of deep learning, our method is\nless explainable than path-finding-based KG com-\npletion methods (e.g., CPL), which provide a con-\ncrete reasoning path to the target entity. Composing\nthe path with multiple queries might be an appli-\ncable strategy that is worthwhile to investigate in\norder to extend our work on the KG reasoning task.\nFor the link prediction task, we adapt the ‚Äúrecall\nand re-ranking‚Äù strategy from PKGC (Lv et al.,\n2022), which brings a trade-off between prediction\nefficiency and accuracy. We alleviate the issue by\napplying different hyper-parameters given different\nsizes of training data, which is discussed in detail\nin Appendix C.\nAs a common issue of existing KG completion\nmodels, the performance of our model also de-\ngrades when the input KG contains noisy data. The\nadvantage of our approach in addressing this issue\nis that it can use both corpus-based textual informa-\ntion and implicit PLM knowledge to reduce noise.\n8 Ethical Statements\nIn this study, we use two datasets FB60K-NYT10\nand UMLS-PubMed, which include the knowledge\ngraphs FB60K and UMLS as well as the text cor-\npora NYT10 and PubMed. The data is all publicly\navailable. Our task is knowledge graph completion,\nwhich is performed by finding missing facts given\nexisting knowledge. This work is only relevant to\nNLP research and will not be put to improper use\nby ordinary people.\n9 Acknowledgements\nResearch was supported in part by US DARPA\nKAIROS Program No. FA8750-19-2-1004 and\nINCAS Program No. HR001121C0165, National\nScience Foundation IIS-19-56151, IIS-17-41317,\nand IIS 17-04532, and the Molecule Maker Lab\nInstitute: An AI Research Institutes program sup-\nported by NSF under Award No. 2019897, and the\nInstitute for Geospatial Understanding through an\nIntegrative Discovery Environment (I-GUIDE) by\nNSF under Award No. 2118329, and NSF Award\nSCH-2205289, SCH-2014438, IIS-2034479.\nReferences\nBadr AlKhamissi, Millicent Li, Asli Celikyilmaz, Mona\nDiab, and Marjan Ghazvininejad. 2022. A review on\nlanguage models as knowledge bases. arXiv preprint\narXiv:2204.06031.\nYuki Arase and Jun‚Äôichi Tsujii. 2019. Transfer fine-\ntuning: A BERT case study. In Proceedings of\nthe 2019 Conference on Empirical Methods in Natu-\nral Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP), Hong Kong, China. Association\nfor Computational Linguistics.\nIvana Bala≈æevi ¬¥c, Carl Allen, and Timothy M\nHospedales. 2019. Tucker: Tensor factorization\nfor knowledge graph completion. arXiv preprint\narXiv:1901.09590.\nOlivier Bodenreider. 2004. The unified medical lan-\nguage system (umls): integrating biomedical termi-\nnology. Nucleic acids research, 32(suppl_1):D267‚Äì\nD270.\nAntoine Bordes, Nicolas Usunier, Alberto Garcia-\nDuran, Jason Weston, and Oksana Yakhnenko.\n2013. Translating embeddings for modeling multi-\nrelational data. Advances in neural information pro-\ncessing systems, 26.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. Advances in neural information processing\nsystems, 33:1877‚Äì1901.\nTing-Yun Chang, Yang Liu, Karthik Gopalakrishnan,\nBehnam Hedayatnia, Pei Zhou, and Dilek Hakkani-\nTur. 2021. Incorporating commonsense knowledge\ngraph in pretrained models for social commonsense\ntasks. arXiv preprint arXiv:2105.05457.\nYuanfei Dai, Shiping Wang, Neal Naixue Xiong, and\nWenzhong Guo. 2020. A survey on knowledge graph\nembedding: Approaches, applications and bench-\nmarks. Electronics, 9:750.\n11169\nRajarshi Das, Shehzaad Dhuliawala, Manzil Zaheer,\nLuke Vilnis, Ishan Durugkar, Akshay Krishnamurthy,\nAlex Smola, and Andrew McCallum. 2017. Go for\na walk and arrive at the answer: Reasoning over\npaths in knowledge bases using reinforcement learn-\ning. arXiv preprint arXiv:1711.05851.\nRajarshi Das, Shehzaad Dhuliawala, Manzil Zaheer,\nLuke Vilnis, Ishan Durugkar, Akshay Krishnamurthy,\nAlex Smola, and Andrew McCallum. 2018. Go for a\nwalk and arrive at the answer: Reasoning over paths\nin knowledge bases using reinforcement learning. In\nInternational Conference on Learning Representa-\ntions.\nTim Dettmers, Pasquale Minervini, Pontus Stenetorp,\nand Sebastian Riedel. 2018. Convolutional 2d knowl-\nedge graph embeddings. In Proceedings of the AAAI\nconference on artificial intelligence, volume 32.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171‚Äì4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nCong Fu, Tong Chen, Meng Qu, Woojeong Jin, and\nXiang Ren. 2019. Collaborative policy learning for\nopen knowledge graph reasoning. In Proceedings of\nthe 2019 Conference on Empirical Methods in Natu-\nral Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 2672‚Äì2681, Hong Kong,\nChina. Association for Computational Linguistics.\nWill Hamilton, Payal Bajaj, Marinka Zitnik, Dan Juraf-\nsky, and Jure Leskovec. 2018. Embedding logical\nqueries on knowledge graphs. Advances in neural\ninformation processing systems, 31.\nJiawei Han, Jian Pei, and Yiwen Yin. 2000. Mining\nfrequent patterns without candidate generation. ACM\nsigmod record, 29(2):1‚Äì12.\nXu Han, Zhiyuan Liu, and Maosong Sun. 2018. Neu-\nral knowledge acquisition via mutual attention be-\ntween knowledge graph and text. In Proceedings of\nthe AAAI Conference on Artificial Intelligence, vol-\nume 32.\nShibo Hao, Bowen Tan, Kaiwen Tang, Hengzhe Zhang,\nEric P Xing, and Zhiting Hu. 2022. Bertnet: Har-\nvesting knowledge graphs from pretrained language\nmodels. arXiv preprint arXiv:2206.14268.\nYanchao Hao, Yuanzhe Zhang, Kang Liu, Shizhu He,\nZhanyi Liu, Hua Wu, and Jun Zhao. 2017. An end-\nto-end model for question answering over knowledge\nbase with cross-attention combining global knowl-\nedge. In Proceedings of the 55th Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers) , pages 221‚Äì231, Vancouver,\nCanada. Association for Computational Linguistics.\nAidan Hogan, Eva Blomqvist, Michael Cochez, Clau-\ndia D‚Äôamato, Gerard De Melo, Claudio Gutierrez,\nSabrina Kirrane, Jos√© Emilio Labra Gayo, Roberto\nNavigli, Sebastian Neumaier, Axel-Cyrille Ngonga\nNgomo, Axel Polleres, Sabbir M. Rashid, Anisa Rula,\nLukas Schmelzeisen, Juan Sequeda, Steffen Staab,\nand Antoine Zimmermann. 2021. Knowledge graphs.\nACM Comput. Surv., 54(4).\nMeng Jiang, Jingbo Shang, Taylor Cassidy, Xiang Ren,\nLance M Kaplan, Timothy P Hanratty, and Jiawei\nHan. 2017. Metapad: Meta pattern discovery from\nmassive text corpora. In Proceedings of the 23rd\nACM SIGKDD International Conference on Knowl-\nedge Discovery and Data Mining, pages 877‚Äì886.\nZhengbao Jiang, Frank F Xu, Jun Araki, and Graham\nNeubig. 2020. How can we know what language\nmodels know? Transactions of the Association for\nComputational Linguistics, 8:423‚Äì438.\nBosung Kim, Taesuk Hong, Youngjoong Ko, and\nJungyun Seo. 2020. Multi-task learning for knowl-\nedge graph completion with pre-trained language\nmodels. In Proceedings of the 28th International\nConference on Computational Linguistics , pages\n1737‚Äì1743.\nQi Li, Meng Jiang, Xikun Zhang, Meng Qu, Timothy P\nHanratty, Jing Gao, and Jiawei Han. 2018. Truepie:\nDiscovering reliable patterns in pattern-based infor-\nmation extraction. In Proceedings of the 24th ACM\nSIGKDD International Conference on Knowledge\nDiscovery & Data Mining, pages 1675‚Äì1684.\nYankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and\nXuan Zhu. 2015. Learning entity and relation embed-\ndings for knowledge graph completion. In AAAI.\nFangyu Liu, Ehsan Shareghi, Zaiqiao Meng, Marco\nBasaldella, and Nigel Collier. 2021. Self-alignment\npretraining for biomedical entity representations. In\nProceedings of the 2021 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\npages 4228‚Äì4238.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019a.\nRoberta: A robustly optimized bert pretraining ap-\nproach. ArXiv, abs/1907.11692.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019b.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nXin Lv, Lei Hou, Juanzi Li, and Zhiyuan Liu. 2018.\nDifferentiating concepts and instances for knowledge\ngraph embedding. arXiv preprint arXiv:1811.04588.\n11170\nXin Lv, Yankai Lin, Yixin Cao, Lei Hou, Juanzi Li,\nZhiyuan Liu, Peng Li, and Jie Zhou. 2022. Do pre-\ntrained models benefit knowledge graph completion?\na reliable evaluation and a reasonable approach. In\nFindings of the Association for Computational Lin-\nguistics: ACL 2022, pages 3570‚Äì3581.\nRabeeh Karimi mahabadi, Yonatan Belinkov, and James\nHenderson. 2021. Variational information bottleneck\nfor effective low-resource fine-tuning. In Interna-\ntional Conference on Learning Representations.\nFabio Petroni, Tim Rockt√§schel, Patrick Lewis, An-\nton Bakhtin, Yuxiang Wu, Alexander H Miller, and\nSebastian Riedel. 2019a. Language models as knowl-\nedge bases? arXiv preprint arXiv:1909.01066.\nFabio Petroni, Tim Rockt√§schel, Sebastian Riedel,\nPatrick Lewis, Anton Bakhtin, Yuxiang Wu, and\nAlexander Miller. 2019b. Language models as knowl-\nedge bases? In Proceedings of the 2019 Conference\non Empirical Methods in Natural Language Pro-\ncessing and the 9th International Joint Conference\non Natural Language Processing (EMNLP-IJCNLP),\npages 2463‚Äì2473, Hong Kong, China. Association\nfor Computational Linguistics.\nStephen E Robertson, Steve Walker, Susan Jones,\nMicheline M Hancock-Beaulieu, Mike Gatford, et al.\n1995. Okapi at trec-3. Nist Special Publication Sp,\n109:109.\nJingbo Shang, Jialu Liu, Meng Jiang, Xiang Ren,\nClare R V oss, and Jiawei Han. 2018. Automated\nphrase mining from massive text corpora. IEEE\nTransactions on Knowledge and Data Engineering,\n30(10):1825‚Äì1837.\nBaoxu Shi and Tim Weninger. 2018. Open-world knowl-\nedge graph completion. In Proceedings of the AAAI\nconference on artificial intelligence, volume 32.\nTaylor Shin, Yasaman Razeghi, Robert L. Logan IV , Eric\nWallace, and Sameer Singh. 2020. AutoPrompt: Elic-\niting Knowledge from Language Models with Auto-\nmatically Generated Prompts. In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP), pages 4222‚Äì4235,\nOnline. Association for Computational Linguistics.\nZhiqing Sun, Zhi-Hong Deng, Jian-Yun Nie, and Jian\nTang. 2019. Rotate: Knowledge graph embedding by\nrelational rotation in complex space. In International\nConference on Learning Representations.\nTh√©o Trouillon, Johannes Welbl, Sebastian Riedel, √âric\nGaussier, and Guillaume Bouchard. 2016a. Com-\nplex embeddings for simple link prediction. In In-\nternational conference on machine learning, pages\n2071‚Äì2080. PMLR.\nTh√©o Trouillon, Johannes Welbl, Sebastian Riedel, Eric\nGaussier, and Guillaume Bouchard. 2016b. Com-\nplex embeddings for simple link prediction. In Pro-\nceedings of The 33rd International Conference on\nMachine Learning, volume 48 of Proceedings of Ma-\nchine Learning Research , pages 2071‚Äì2080, New\nYork, New York, USA. PMLR.\nMeng Wang, Ruijie Wang, Jun Liu, Yihe Chen, Lei\nZhang, and Guilin Qi. 2018. Towards empty an-\nswers in sparql: approximating querying with rdf\nembedding. In International semantic web confer-\nence, pages 513‚Äì529. Springer.\nQuan Wang, Zhendong Mao, Bin Wang, and Li Guo.\n2017. Knowledge graph embedding: A survey of\napproaches and applications. IEEE Transactions on\nKnowledge and Data Engineering, 29:2724‚Äì2743.\nChang Xu, Yalong Bai, Jiang Bian, Bin Gao, Gang\nWang, Xiaoguang Liu, and Tie-Yan Liu. 2014. Rc-\nnet: A general framework for incorporating knowl-\nedge into word representations. In Proceedings of the\n23rd ACM international conference on conference\non information and knowledge management, pages\n1219‚Äì1228.\nIkuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki\nTakeda, and Yuji Matsumoto. 2020. Luke: Deep con-\ntextualized entity representations with entity-aware\nself-attention. In EMNLP.\nBishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao,\nand Li Deng. 2014. Embedding entities and relations\nfor learning and inference in knowledge bases. arXiv\npreprint arXiv:1412.6575.\nLiang Yao, Chengsheng Mao, and Yuan Luo. 2019. Kg-\nbert: Bert for knowledge graph completion. arXiv\npreprint arXiv:1909.03193.\nMichihiro Yasunaga, Hongyu Ren, Antoine Bosselut,\nPercy Liang, and Jure Leskovec. 2021. QA-GNN:\nReasoning with language models and knowledge\ngraphs for question answering. In Proceedings of\nthe 2021 Conference of the North American Chapter\nof the Association for Computational Linguistics: Hu-\nman Language Technologies, pages 535‚Äì546, Online.\nAssociation for Computational Linguistics.\nYunyi Zhang, Jiaming Shen, Jingbo Shang, and Ji-\nawei Han. 2020. Empower entity set expan-\nsion via language model probing. arXiv preprint\narXiv:2004.13897.\nSijing Zhou, Xinyi Dai, Haokun Chen, Weinan Zhang,\nKan Ren, Ruiming Tang, Xiuqiang He, and Yong Yu.\n2020. Interactive recommender system via knowl-\nedge graph-enhanced reinforcement learning. Pro-\nceedings of the 43rd International ACM SIGIR Con-\nference on Research and Development in Information\nRetrieval.\nMarinka Zitnik, Monica Agrawal, and Jure Leskovec.\n2018. Modeling polypharmacy side effects with\ngraph convolutional networks. Bioinformatics,\n34(13):i457‚Äìi466.\n11171\nA Dataset Overview\nWe use the datasets FB60K-NYT10 and UMLS-\nPubMed provided by (Fu et al., 2019). 4 They\ntake the following steps to split the data: (1) split\nthe data of each KG (FB60K or UMLS) in the ratio\nof 8:1:1 for training/validation/testing data. (2) For\ntraining data, they keep all triples in any relations.\n(3) For validation/testing data, they only keep the\ntriples in 16/8 relations they concern (see relations\nin Table 5). The processed data has {train: 268280,\nvalid: 8765, test: 8918} for FB60K and {train:\n2030841, valid: 8756, test: 8689} for UMLS. As\nfor the corpora, there are 742536 and 5645558\ndocuments in NYT10 and PubMed respectively.\nFB60K-NYT10 UMLS-PubMed\n#query_tail 57279 12956\n#query_head 23319 12956\n#triples/#queries 2.22 6.81\nTable 4: The number of queries and the ratio of\ntriples/queries for FB60K-NYT10 and UMLS-PubMed\nSub-training-set splitting. To split the training\ndata in the ratio of 20%/50% for FB60K-NYT10\nor 20%/40%/70% for UMLS-PubMed, we use the\nsame random seeds (55, 83, 5583) as Fu et al. used,\nand report the results in average.\nQuery-triple ratio. Within the relations that we\nfocus on, we calculate the ratio of the triples by\nthe queries (including both (h,r,?) and (?,r,t))\nto indicate the number of correct answers a query\nmay have in average. The result is given in Table\n4. For UMLS-PubMed, as the relations are sym-\nmetric in pairs, the number of queries for head and\ntail predictions are the same. Table 5 presents the\ncounting in a more detailed setting. Both tables\nshow that there are more multi-answer queries in\nUMLS-PubMed than in FB60K-NYT10, which ex-\nplains why the support information may not be as\nhelpful in the former as it is in the latter, as revealed\nby Table 3 and discussed in Section 5.2.\nB Textual Pattern Mining\nThe purpose of pattern mining is to find rules that\ndescribe particular patterns in the data. Information\nextraction is a common goal for pattern mining\nand prompt mining, where the former focuses on\nextracting facts from massive text corpora and the\n4https://github.com/INK-USC/CPL#\ndatasets\nlatter on extracting facts from PLMs. In this sec-\ntion, we use another example (Figure 8) to explain\nin detail how the textual pattern mining approaches\nlike MetaPAD (Jiang et al., 2017) and TruePIE\n(Li et al., 2018) are implemented to mine quality\nprompts. In the example, given the relation loca-\ntion/neighborhood/neighborhood_of\nas the input, we first extract tuples (e.g., <east\nnew york, brooklyn>) in the relation from\nthe KG (i.e., FB60K). Then, we construct a\nsub-corpus by searching the sentences in a large\ncorpus (e.g., Wikipedia) and the KG-related corpus\n(i.e. NYT10 for FB60). After the creation of sub-\ncorpus, we apply phrase segmentation and frequent\npattern mining to mine raw prompt candidates.\nSince the candidate set is noisy as some prompts\nwith low completeness (e.g., in lower [Y]),\nlow informativeness (e.g., the [Y], [X]) and\nlow coverage (e.g., [X], manhattan, [Y])\nare present, we use MetaPAD to handle the prompt\nfiltering with its quality function introducing\nthose contextual features. After the prompts have\nbeen processed by MetaPAD, we choose one of\nthem to serve as a seed prompt (for example,\n[X] neighborhood of [Y]) so that other\nprompts can be compared to it by computing their\ncosine similarity. As the positive seed prompt is\nselected manually, we can tell that there is still\nroom for future improvement.\nC Re-ranking Recalls from KGE Model\nRe-ranking framework. According to the\ninference process we present in Figure 9, we\nfill the placeholder ( [MASK]) with each entity\n(e1,e2,...,e n) in the entity set E. However, as\nmentioned by Lv et al.2022, the inference speed\nof PLM-based models is much slower than that of\nKGE models, which is a disadvantage of using\nPLM for KG completion. To address this issue,\nthey use the recalls from KGE models, that is,\nusing KGE models to run KG completion and\nselect X top-ranked entities for each query as\nthe entity set E. Then, they shuffle the set and\nre-rank those entities using the PLM-based model.\nIn our work, we adapt this re-ranking framework\nto accelerate the inference and evaluation as our\ntime complexity is Ztimes as large as PKGC (Lv\net al., 2018) for each case where Z is the size of\nprompt ensemble. We use the recalls from TuckER\n(Bala≈æevi¬¥c et al., 2019) for both datasets.\n11172\n[X] hospital in [Y] , school in [Y], [X] , manhattan, [Y] , the [Y] , [X] , to [X] , [Y],the [X] district of [Y] , at [Y] ‚Äòs [X], [Y] ‚Äôs [X] neighborhood, [X] ballpark in [Y], of [X] , [Y] , [X] in [Y] and , district in [Y], avenue in the [X] neighborhood of [Y] ,born in [X] , [Y] , [X] is close to [Y] , located in the [X] neighborhood of [Y] , in the [X] district of [Y] , [Y] 's [X] neighborhood, the [X] area of [Y] , in lower [Y], [Y] division, [X] , born in the [X] neighborhood of [Y] , club in [X] , [Y],‚ãØ‚ãØ‚ãØ‚ãØ\nPatterns mined with FP-Growth\nPatterns selected by MetaPAD‚Äôs contexual segmentation[X] district of [Y], [X] neighbors [Y] ,[X] , in [Y] , [X] section of [Y] , home in [X] , [Y] , avenue in the [X] neighborhood of [Y] , neighborhood of [X] , [Y] , [X] is adjacent to [Y] , [X] neighborhood in [Y] ,[X], close to [Y] , [X] is in [Y] , [X] neighboring city [Y] , in the [X] neighborhood of [Y] ,people from [X] , [Y] , street in [X] , [Y] , ‚ãØ‚ãØ\nReliable patterns (for relation     ) output by TruePIE[X] neighborhood of [Y] ,[X] neighbors [Y] , neighborhood of [X] , [Y] , [X] is adjacent to [Y], [X] is a neighborhood in [Y] ,[X], close to [Y] ,[X] neighboring city [Y] , [X], near [Y] ,[X] , in [Y] ,in the [X] neighborhood of [Y] , [Y] ‚Äòs [X] neighborhood, ,‚ãØ\n<east new york, brooklyn>, <koreatown, manhattan>, <samos, tucson>, <prospect park, minneapolis>, <grand, riverside>, <love field, dallas>, <bayway, elizabeth>, <germantown, philadelphia>, <alphabet city, manhattan>, <upper west side, manhattan>, <cascade, seattle>, <fishtown, philadelphia>, <broad channel, queens>, <herald square, manhattan>, <canal street, buffalo>, <jacksonheights, edmonton>, <hegewisch, chicago>, <pearl district, portland>, <tottenville, staten>, <brooklynheights, brooklyn>, <south harrison, tucson>, <coal harbour, vancouver>, <britannia, ottawa>, <south norwalk, fairfield> ‚ãØ‚ãØ‚ãØ‚ãØ\nHead-tailtuples in relation\n‚Äúpoiret was born on 20 april 1879 to a cloth merchant in the poor neighborhood of [X], [Y].‚Äù‚Äú[X] is one of a few neighborhoods in [Y] that is completely privately owned.‚Äù‚Äúone of [Y]‚Äôs most exclusive neighborhoods, [X] is home to two of the three prestigious ‚Äòhill schools‚Äô‚Äù‚Äúthe family then moved to the [X] neighborhood of [Y].‚Äù‚Äúshe eventually settled in [X], [Y], where she lived until 1982.‚Äù‚Äúit is also represented within the city of [Y] by the [X] neighborhood council‚Äù‚ãØ‚ãØ‚ãØ‚ãØ\nSearch in large corporaSub-corpus for relation \nRelation  : location/neighborhood/neighborhood_of(in FB60K-NYT10) Extracttuples in relation of      in FB60K\n<latexit sha1_base64=\"p/ZeGgVnBBPTcLaUfSZwZ3XHcQk=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lU1GPRi8eK9gPaUDbbSbt0swm7G6GE/gQvHhTx6i/y5r9x2+agrQ8GHu/NMDMvSATXxnW/ncLK6tr6RnGztLW9s7tX3j9o6jhVDBssFrFqB1Sj4BIbhhuB7UQhjQKBrWB0O/VbT6g0j+WjGSfoR3QgecgZNVZ6yNSkV664VXcGsky8nFQgR71X/ur2Y5ZGKA0TVOuO5ybGz6gynAmclLqpxoSyER1gx1JJI9R+Njt1Qk6s0idhrGxJQ2bq74mMRlqPo8B2RtQM9aI3Ff/zOqkJr/2MyyQ1KNl8UZgKYmIy/Zv0uUJmxNgSyhS3txI2pIoyY9Mp2RC8xZeXSfOs6l1Wz+8vKrWbPI4iHMExnIIHV1CDO6hDAxgM4Ble4c0Rzovz7nzMWwtOPnMIf+B8/gCi7Y4K</latexit>\nr\n<latexit sha1_base64=\"p/ZeGgVnBBPTcLaUfSZwZ3XHcQk=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lU1GPRi8eK9gPaUDbbSbt0swm7G6GE/gQvHhTx6i/y5r9x2+agrQ8GHu/NMDMvSATXxnW/ncLK6tr6RnGztLW9s7tX3j9o6jhVDBssFrFqB1Sj4BIbhhuB7UQhjQKBrWB0O/VbT6g0j+WjGSfoR3QgecgZNVZ6yNSkV664VXcGsky8nFQgR71X/ur2Y5ZGKA0TVOuO5ybGz6gynAmclLqpxoSyER1gx1JJI9R+Njt1Qk6s0idhrGxJQ2bq74mMRlqPo8B2RtQM9aI3Ff/zOqkJr/2MyyQ1KNl8UZgKYmIy/Zv0uUJmxNgSyhS3txI2pIoyY9Mp2RC8xZeXSfOs6l1Wz+8vKrWbPI4iHMExnIIHV1CDO6hDAxgM4Ble4c0Rzovz7nzMWwtOPnMIf+B8/gCi7Y4K</latexit>\nr\n(Wikipedia)(NYT10)\n<latexit sha1_base64=\"p/ZeGgVnBBPTcLaUfSZwZ3XHcQk=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lU1GPRi8eK9gPaUDbbSbt0swm7G6GE/gQvHhTx6i/y5r9x2+agrQ8GHu/NMDMvSATXxnW/ncLK6tr6RnGztLW9s7tX3j9o6jhVDBssFrFqB1Sj4BIbhhuB7UQhjQKBrWB0O/VbT6g0j+WjGSfoR3QgecgZNVZ6yNSkV664VXcGsky8nFQgR71X/ur2Y5ZGKA0TVOuO5ybGz6gynAmclLqpxoSyER1gx1JJI9R+Njt1Qk6s0idhrGxJQ2bq74mMRlqPo8B2RtQM9aI3Ff/zOqkJr/2MyyQ1KNl8UZgKYmIy/Zv0uUJmxNgSyhS3txI2pIoyY9Mp2RC8xZeXSfOs6l1Wz+8vKrWbPI4iHMExnIIHV1CDO6hDAxgM4Ble4c0Rzovz7nzMWwtOPnMIf+B8/gCi7Y4K</latexit>\nr\n<latexit sha1_base64=\"p/ZeGgVnBBPTcLaUfSZwZ3XHcQk=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lU1GPRi8eK9gPaUDbbSbt0swm7G6GE/gQvHhTx6i/y5r9x2+agrQ8GHu/NMDMvSATXxnW/ncLK6tr6RnGztLW9s7tX3j9o6jhVDBssFrFqB1Sj4BIbhhuB7UQhjQKBrWB0O/VbT6g0j+WjGSfoR3QgecgZNVZ6yNSkV664VXcGsky8nFQgR71X/ur2Y5ZGKA0TVOuO5ybGz6gynAmclLqpxoSyER1gx1JJI9R+Njt1Qk6s0idhrGxJQ2bq74mMRlqPo8B2RtQM9aI3Ff/zOqkJr/2MyyQ1KNl8UZgKYmIy/Zv0uUJmxNgSyhS3txI2pIoyY9Mp2RC8xZeXSfOs6l1Wz+8vKrWbPI4iHMExnIIHV1CDO6hDAxgM4Ble4c0Rzovz7nzMWwtOPnMIf+B8/gCi7Y4K</latexit>\nr\nPhrase segmentation & frequent pattern mining\nMetaPAD\nTruePIE\n<latexit sha1_base64=\"p/ZeGgVnBBPTcLaUfSZwZ3XHcQk=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lU1GPRi8eK9gPaUDbbSbt0swm7G6GE/gQvHhTx6i/y5r9x2+agrQ8GHu/NMDMvSATXxnW/ncLK6tr6RnGztLW9s7tX3j9o6jhVDBssFrFqB1Sj4BIbhhuB7UQhjQKBrWB0O/VbT6g0j+WjGSfoR3QgecgZNVZ6yNSkV664VXcGsky8nFQgR71X/ur2Y5ZGKA0TVOuO5ybGz6gynAmclLqpxoSyER1gx1JJI9R+Njt1Qk6s0idhrGxJQ2bq74mMRlqPo8B2RtQM9aI3Ff/zOqkJr/2MyyQ1KNl8UZgKYmIy/Zv0uUJmxNgSyhS3txI2pIoyY9Mp2RC8xZeXSfOs6l1Wz+8vKrWbPI4iHMExnIIHV1CDO6hDAxgM4Ble4c0Rzovz7nzMWwtOPnMIf+B8/gCi7Y4K</latexit>\nr\nFigure 8: Example of textual pattern mining\n11173\nrelations #triples(all) #queries(all) ratio(all) #triples(test) #queries(test) ratio(test)\nFB60K-NYT10\n/people/person/nationality 44186 20215 2.19 4438 2282 1.94\n/location/location/contains 42306 11971 3.53 4244 2373 1.79\n/people/person/place_lived 29160 12760 2.29 3094 2066 1.50\n/people/person/place_of_birth 28108 16341 1.72 2882 2063 1.40\n/people/deceased_person/place_of_death 6882 4349 1.58 678 518 1.31\n/people/person/ethnicity 5956 2944 2.02 574 305 1.88\n/people/ethnicity/people 5956 2944 2.02 592 318 1.86\n/business/person/company 4334 2370 1.83 450 379 1.19\n/people/person/religion 3580 1688 2.12 300 175 1.71\n/location/neighborhood/neighborhood_of 1275 547 2.33 130 91 1.43\n/business/company/founders 904 709 1.28 94 87 1.08\n/people/person/children 821 711 1.15 56 56 1.00\n/location/administrative_division/country 829 498 1.66 88 72 1.22\n/location/country/administrative_divisions 829 498 1.66 102 79 1.29\n/business/company/place_founded 754 548 1.38 80 73 1.10\n/location/us_county/county_seat 264 262 1.01 32 32 1.00\nUMLS-PubMed\nmay_be_treated_by 71424 7703 9.27 7020 3118 2.25\nmay_treat 71424 7703 9.27 6956 3091 2.25\nmay_be_prevented_by 10052 3232 3.11 1014 584 1.74\nmay_prevent 10052 3232 3.11 1034 586 1.76\ngene_mapped_to_disease 6164 1732 3.56 596 331 1.80\ndisease_mapped_to_gene 6164 1732 3.56 652 357 1.82\ngene_associated_with_disease 536 289 1.85 58 49 1.18\ndisease_has_associated_gene 536 289 1.85 48 41 1.17\nTable 5: Number of triples (#triples) and queries (#queries) in relations for FB60K-NYT10 and UMLS-PubMed.\nTriples/queries for both head prediction and tail prediction are counted. \"all\" and \"test\" denote the whole dataset\nand testing data respectively.\nLimitations. Nonetheless, implementing the\nre-ranking framework has a trade-off between effi-\nciency and Hits@N performance. When the train-\ning data is large (e.g., 100%), the KGE model could\nbe well trained so that the ground truth entity egt\nis more likely to be contained in the top X ranked\nones. However, when the training data is limited\n(e.g., 20%), the trained KGE model could not per-\nform well on link prediction, as shown in Table 1\nand 2. In such a case, there is a probability that egt\nis not among the top X entities if we keep using\nthe same X regardless of the size of the training\ndata. To alleviate this side effect, we test and select\ndifferent values of the hyper-parameter X for dif-\nferent sizes of training data, as presented in Table\n6.\nDaatset 20% 40% 50% 70% 100%\nFB60K-NYT10 70 - 40 - 20\nUMLS-PubMed 50 50 - 30 30\nTable 6: Best X for different training sizes\nTo check how much space there is for improvement,\nwe manually add the ground truth entity into the\nrecalls (we should not do this for the evaluation\nof TAGREAL as we suppose the object entity is\nunknown) and test the performance of TAGREAL\non UMLS-PubMed. The result is shown in Table\n7. By comparing this data with Table 3 for UMLS-\nPubMed, we find that changing the values of X\ncould not perfectly address the issue. We leave the\nimprovement as one of our major future works.\nCondition 20% 40% 70% 100%\nman (44.83, 60.99) (50.81, 67.69) (52.98, 69.21) (60.19, 72.58)\nmine (44.98, 61.56) (52.81, 68.66) (56.30, 70.20) (61.29, 74.76)\noptim (45.71, 63.61) (54.22, 69.03) (58.18, 71.05) (63.67, 75.55)\nTable 7: Link prediction of TAGREAL on UMLS-\nPubMed with ground truth added to the KGE recalls.\nData in brackets are Hits@5 (left) and Hits@10 (right).\nD Computing Infrastructure & Budget\nWe trained and evaluated TAGREAL on 7 NVIDIA\nRTX A6000 running in parallel as we support multi-\nGPU computing. Training TAGREAL to a good\nperformance took about 22 and 14 hours on the\nentire FB60K-NYT10 dataset (with LUKE (Ya-\nmada et al., 2020)) and the entire UMLS-PubMed\ndataset (with SapBert (Liu et al., 2021)) respec-\ntively. The training time is proportional to the size\n(ratio) of the training data. The evaluation took\nabout 12 minutes for FB60K-NYT10 with LUKE\nwhen hyper-parameter X = 20, and 16 minutes\nfor UMLS-PubMed with SapBert when X = 30.\nThe evaluation time is proportional to X, which\n11174\nexplains why we applied the re-ranking framework\n(Appendix C) to improve the prediction efficiency.\nE Link Prediction with Ensemble\nùëí!ùëí\"ùëí# ùëí$‚ãØùëù!ùëù\"‚ãÆ ‚ãÆùëù%\n‚ãØ‚ãØ‚ãØ\n+\t\t\t\t\t\t+\t\t\t\t\t\t+\t\t\t\t\t+\t\t\t\t\t\t++\t\t\t\t\t\t+\t\t\t\t\t\t+\t\t\t\t\t+\t\t\t\t\t\t++\t\t\t\t\t\t+\t\t\t\t\t\t+\t\t\t\t\t+\t\t\t\t\t\t+sumargsortrank ‚ãØ‚ãØùëí!!\"ùëí##ùëí$ ùëí%&\nEqually Weighted Ensembleùëí!ùëí\"ùëí# ùëí$‚ãØ\n‚ãÆ\n‚ãØ‚ãØ‚ãØ\n+\t\t\t\t\t\t+\t\t\t\t\t\t+\t\t\t\t\t+\t\t\t\t\t\t++\t\t\t\t\t\t+\t\t\t\t\t\t+\t\t\t\t\t+\t\t\t\t\t\t++\t\t\t\t\t\t+\t\t\t\t\t\t+\t\t\t\t\t+\t\t\t\t\t\t+\nargsort‚ãØ‚ãØùëí$ùëí##ùëí&'ùëí($\nOptimized ensemble√ó0.12√ó0.39\n√ó0.27\nrank\n0.620.180.400.530.440.310.690.16\n0.150.200.770.28\n4.962.885.873.79\n0.070.020.050.060.170.120.270.06\n0.040.050.210.08\n0.760.582.660.54sumscore\nFigure 9: Prediction with ensemble. e1,e2,...,e n de-\nnote the indices of entities. p1,p2,...,p m denote the\nprompts in the ensemble.\nFor the link prediction with equally-weighted or\noptimized ensembles, we apply the method shown\nin Figure 9. Specifically, for each sentence with\n[MASK] filled with an entity ei, we calculate its\nclassification score with the fine-tuned PLM. For\neach query, we get an m√ónmatrix where mis\nthe number of prompts in the ensemble, nis the\nnumber of entities in the entity set (which is X\nif the re-ranking framework is applied). For an\nensemble that is equally weighted, we simply sum\nthe scores of each entity obtained from the different\nprompts, whereas for an optimized ensemble, we\nmultiply the weighting of the prompts by the scores\nbefore the addition. After sorting the vector in size\nof 1√ónin descending order, we can get the ranking\nof entities as the result of the link prediction.\nF Evaluation Metrics\nFollowing previous KG completion works (Fu\net al., 2019; Lv et al., 2022), we use Hits@N and\nMean Reciprocal Rank (MRR) as our evaluation\nmetrics. As mentioned in Section 3.5, the predic-\ntion of each query (h,r,?) is a 1-d vector of in-\ndices of entities in descending order regarding their\nscores. Specifically, for a query qi, We record the\nrank of the object entity tas Ri, then we have:\nHits@N =\nQ‚àë\ni=1\nRi,in\nQ and Ri,in =\n{\n0,Ri >N\n1,Ri ‚â§N,\n(4)\nMRR =\nQ‚àë\ni=1\n1\nQRi\n, (5)\nwhere Qis the number of queries in evaluation.\nG Code Interpretation\n0 1 2 3 4 5 6 7\nTraining Progress\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0F1-score\ncode (UMLS-PubMed)\nword (UMLS-PubMed)\ncode (FB60K-NYT10)\nword (FB60K-NYT10)\nFigure 10: Performance variation of triple classifica-\ntion w.r.t training time. \"code\" and \"word\" denote the\nrepresentation of KG entities.\nTo exploit the power of PLM, we need to map\nthe code (entity_id) in KG/corpus into the words\n(Figure 10 shows the performance difference of\nPLM between using word and using code). For\nFB60K-NYT10, we use the mapping provided by\nJointNRE (Han et al., 2018) 5, which covers the\ntranslation for all entities. For UMLS-PubMed,\nwe jointly use three mappings 6,7,8 which cover\n97.22% of all entities.\nH Case Study\nIn addition to Figure 7, we show more examples\napplying TAGREAL on link prediction in Figure\n11. We can see that the predictions with optimized\nprompt ensemble outperform those with manual\nprompts in all the cases, and even outperforms pre-\ndictions with manual prompts and support infor-\nmation in some cases. In all these examples, the\nsupport information aids the PLM knowledge prob-\ning in different ways. For the first example, we\nbelieve that the PLM captures the words ‚Äúbrother\njames_murray‚Äù and ‚Äúhis wife jenny‚Äù, and realize\nthat we are talking about the Scottish lexicographer\n‚Äújames_murray‚Äù but not the American comedian\nwith the same name, based on our survey. For\nthe second example, the PLM probably captures\n‚Äúglycemic control‚Äù which is highly relevant to the\ndisease ‚Äúhyperglycemia‚Äù. For the third example,\nthe term ‚Äúantiemetic‚Äù (the drug against vomiting) is\nlikely captured so that the answer ‚Äúvomiting‚Äù could\nbe correctly predicted. Hence, it is not necessary\nfor the support information to include the object\n5https://github.com/thunlp/JointNRE\n6https://evs.nci.nih.gov/ftp1/NCI_\nThesaurus/\n7https://www.ncbi.nlm.nih.gov/books/\nNBK9685/\n8https://bioportal.bioontology.org/\nontologies/VANDF\n11175\nManual PromptThe nationality of [X] is [Y] .\nExample 1: Query: (james_murray, /people/person/nationality, ?) Dataset: FB60K-NYT10\n‚Äúsurvivedbybrother james_murrayandhis wife jennyofsidney,australia,fourteenniecesandnephewsandthirteengreatniecesandnephewsinusa,scotland,englandandaustralia.‚Äù\n[X]'s nationality is [Y] .[X] was born in [Y] .  [X] is from [Y] .   [X] is from [Y] (country) . [X] born in [Y] .   \nOptimized Prompt Ensembleweights\nSupport Information (retrieved by BM25)\nPredictions (Top10 in descending order of classification scores)united_states_of_america, united_kingdom, republic_of_ireland, england, south_africa, sweden, wales, scotland, pakistan, canadaMan :  united_states_of_america, scotland, england, republic_of_ireland, united_kingdom, pakistan, wales, germany,switzerland,swedenOptim :  Man + Supp :  australia, england,scotland,germany,united_states_of_america,south_africa,canada,sweden,wales,belgiumOptim+ Supp :  scotland,australia,england,united_states_of_america, great_britain,wales,germany,belgium,republic_of_ireland,south_africa\nManual Prompt[Y] may be treated by [X].\nExample 2: Query: (insulin_degludec, may_be_treated_by, ?) Dataset: UMLS-PubMed[X] is a therapy for [Y] . a cure for [Y] is [X] . [X], treatment to [Y] . [Y] treated by [X] .  [X] treats [Y] .   \nOptimized Prompt Ensembleweights\nSupport Information (retrieved by BM25)\nPredictions (Top10 in descending order of classification scores)Man :  Optim :  \n‚Äúthis reportedly allows for less pharmacodynamic variability and within-subject variability than currently available insulin analogs ,and a duration of action that is over 24 hours . the lack of proof of carcinogenicity with insulin_degludecis yet another factor that would be taken into consideration when choosing the optimal basal insulin for a diabetic individual . a formulation of insulin insulin_degludecwith insulin aspart, insulin_degludec70% / aspart30% , may permit improved flexibly of dosing without compromising glycemic control or safety .‚Äù\ntype_2_diabetes_mellitus, diabetic_ketoacidosis,type_1_diabetes_mellitus,hyperglycemia,hyperkalemia,abnorm_drug_ind,inj_myocardial_reperfusion,obesity, defic_dis, hiv_infecttype_2_diabetes_mellitus,hyperglycemia,type_1_diabetes_mellitus,hyperkalemia,abnorm_drug_ind,defic_dis,obesity,diabetic_ketoacidosis,pain_postop,atrial_fibrillationMan + Supp :  type_2_diabetes_mellitus,type_1_diabetes_mellitus,hyperglycemia,abnorm_drug_ind,aids,diabetic_ketoacidosis,hyperkalemia,defic_dis,obesity,blood_poisOptim+ Supp :  hyperglycemia,aids,hyperkalemia,abnorm_drug_ind,type_2_diabetes_mellitus,type_1_diabetes_mellitus,blood_pois,diabetic_ketoacidosis,delirium,leg_dermatoses\nManual Prompt[Y] may be prevented by [X] .\nExample 3: Query: (aprepitant, may_prevent, ?) Dataset: UMLS-PubMed[X] that prevents [Y][X] in prevention of [Y] . [Y] prevented by [X] . [X] prevents [Y] .   \nOptimized Prompt Ensembleweights\nSupport Information (retrieved by BM25)\nPredictions (Top10 in descending order of classification scores)Man :  Optim :  Man + Supp :  Optim+ Supp :  \n‚Äúthe prophylactic and therapeutic efficacy of antiemeticused for rinvmay be enhanced by adding aprepitantbefore starting radiotherapy in high riskcases as in ours .‚Äù\nperennial_allergic_rhinitis, hiccups,motion_sickness,vomiting,nasal_polyp,nausea,lv_dysfunction,status_epilepticus,pain,postop_complnasal_polyp,vomiting,status_epilepticus,motion_sickness,perennial_allergic_rhinitis,nausea,hiccups,asthma,lv_dysfunction,painvomiting,nausea,postop_compl,motion_sickness,withdrawal_syndrome,status_epilepticus,pain,anxiety_disorder,hiccups,reye_s_syndromevomiting,motion_sickness,nausea,status_epilepticus,withdrawal_syndrome,reye_s_syndrome,pain,postop_compl,hiccups,psychotic_disorder\n0.097866900.239158590.323349730.38601556\n0.107764380.115349660.135974180.287796420.49708182\n0.172833960.288633610.316872160.337899720.35120992\nFigure 11: Examples of the link prediction with TAGREAL . Man denotes manual prompt. Optim denotes opti-\nmized prompt ensemble. Supp denotes support information. The ground truth tail entity , helpful information\nand optimized prompts (darker for higher weights) are highlighted.\n11176\nentity itself, and including only some text relevant\nto it could also be helpful.\nI Re-evaluation of Knowledge Graph\nEmbedding Models\nWe find that the performance of some KGE mod-\nels was underestimated by Fu et al.2019 due to\nthe low embedding dimension set for entity and\nrelation. According to our re-evaluation (Table 8),\nmany of these models could perform much better\nwith higher dimension, and we report their best\nperformance in Table 1 and 2 based on our exper-\niments. For the previously evaluated models, we\nuse the same code 9,10,11 as Fu et al. used to ensure\nthe fairness of the comparison. For TuckER (Bal-\na≈æevi¬¥c et al., 2019), we use the code provided by\nthe author. 12 Same as Fu et al., to make the com-\nparison more rigorous, we do not apply the filtered\nsetting (Bordes et al., 2013; Sun et al., 2019) of\nthe Hits@N evaluation to all the models including\nTAGREAL .\n9https://github.com/thunlp/OpenKE\n10https://github.com/DeepGraphLearning/\nKnowledgeGraphEmbedding\n11https://github.com/TimDettmers/ConvE\n12https://github.com/ibalazevic/TuckER\n11177\nFB60K-NYT10 Fu et al.‚Äôs setting Our setting\n(edim, rdim, filter) Ratio: (Hits@5, Hits@10, MRR) (edim, rdim, filter) Ratio: (Hits@5, Hits@10, MRR)\nTransE (Bordes et al., 2013) (100, 100, n/a) 20%: (15.12, 18.83, 12.57) (600, 600, n/a) 20%: (29.13, 32.67, 15.80)\n50%: (19.38, 23.20, 13.36) 50%: (41.54, 45.74. 25.82)\n100%: (38.53, 43.38, 29.90) 100%: (42.53, 46.77, 29.86)\nDisMult (Yang et al., 2014) (100, 100, n/a) 20%: (1.42, 2.55, 1.05) (600, 600, n/a) 20%: (3.44, 4.31, 2.64)\n50%: (15.23, 19.05, 12.36) 50%: (15.98, 18.85, 13.14)\n100%: (32.11, 35.88, 24.95) 100%: (37.94, 41.62, 30.56)\nComplEx (Trouillon et al., 2016a) (100, 100, n/a) 20%: (4.22, 5.97, 3.44) (600, 600, n/a) 20%: (4.32, 5.48, 3.16)\n50%: (19.10, 23.08, 12.99) 50%: (15.00, 17.73, 12.21)\n100%: (32.91, 34.62, 24.67) 100%: (35.42, 38.85, 28.59)\nConvE (Dettmers et al., 2018) (200, 200, n/a) 20%: (20.60, 26.90, 11.96) (100, 100, n/a) 20%: (22.91, 26.29, 19.48)\n50%: (24.39, 30.59, 18.51) 50%: (26.52, 29.84, 22.67)\n100%: (33.02, 39.78, 24.45) 100%: (31.71, 35.66, 25.58)\n(600, 600, n/a) 20%: (29.49, 33.30, 24.31)\n50%: (40.10, 44.03, 32.97)\n100%: (50.18, 54.06, 40.39)\nTuckER (Bala≈æevi¬¥c et al., 2019) - - (100, 100, n/a) 20%: (20.04, 23.02, 16.27)\n50%: (24.04, 27.88, 20.21)\n100%: (34.54, 38.77, 28.19)\n(600, 600, n/a) 20%: (29.50, 32.48, 24.44)\n50%: (41.73, 45.58, 33.84)\n100%: (51.09, 54.80, 40.47)\nRotatE (Sun et al., 2019) (200, 100, ?) 20%: (9.25, 11.83, 8.04) (100, 50, n/a) 20%: (1.34, 2.13, 1.08)\n50%: (25.96, 31.63, 23.34) 50%: (2.54, 4.03, 1.91)\n100%: (58.32, 60.66, 51.85) 100%: (5.42, 7.87, 2.09)\n(200, 100, n/a) 20%: (7.47, 9.14, 5.81)\n50%: (21.68, 25.45, 17.35)\n100%: (47.96, 52.02, 39.17)\n(600, 300, n/a) 20%: (15.91, 18.32, 12.65)\n50%: (35.48, 39.42, 28.92)\n100%: (51.73, 55.27, 42.64)\nUMLS-PubMed Fu et al.‚Äôs setting Our setting\n(edim, rdim, filter) Ratio: (Hits@5, Hits@10) (edim, rdim, filter) Ratio: (Hits@5, Hits@10)\nTransE (Bordes et al., 2013) (100, 100, n/a) 20%: (7.12, 11.17) (600, 600, n/a) 20%: (19.70, 30.47)\n40%: (26.86, 38.08) 40%: (27.72, 41.99)\n70%: (31.32, 43.58) 70%: (34.62, 49.29)\n100%: (32.28, 45.52) 100%: (40.83, 53.62)\nDisMult (Yang et al., 2014) (100, 100, n/a) 20%: (14.66, 21.16) (600, 600, n/a) 20%: (19.02, 28.35)\n40%: (26.90, 38.35) 40%: (28.28, 40.48)\n70%: (31.65, 44.98) 70%: (32.66, 47.01)\n100%: (32.80, 47.50) 100%: (39.53, 53.82)\nComplEx (Trouillon et al., 2016a) (100, 100, n/a) 20%: (18.18, 19.58) (600, 600, n/a) 20%: (11.28, 17.17)\n40%: (23.77, 34.15) 40%: (24.64, 35.15)\n70%: (30.04, 43.60) 70%: (25.89, 38.19)\n100%: (31.84, 46.57) 100%: (34.54, 49.30)\nConvE (Dettmers et al., 2018) (200, 200, n/a) 20%: (20.51, 30.11) (200, 200, n/a) 20%: (20.45, 30.72)\n40%: (28.01, 42.04) 40%: (27.90, 42.49)\n70%: (31.01, 45.81) 70%: (30.67, 45.91)\n100%: (30.35, 45.35) 100%: (29.85, 45.68)\n(600, 600, n/a) 20%: (20.26, 30.29)\n40%: (26.85, 41.57)\n70%: (26.97, 42.44)\n100%: (25.43, 41.58)\nTuckER (Bala≈æevi¬¥c et al., 2019) - - (100, 100, n/a) 20%: (5.13, 8.06)\n40%: (20.48, 31.20)\n70%: (29.66, 42.89)\n100%: (31.56, 44.72)\n(256, 256, n/a) 20%: (19.94, 30.82)\n40%: (25.79, 41.00)\n70%: (26.48, 42.48)\n100%: (30.22, 45.33)\n(600, 600, n/a) 20%: (18.84, 27.94)\n40%: (24.57, 37.79)\n70%: (25.50, 41.32)\n100%: (24.41, 40.56)\nRotatE (Sun et al., 2019) (200, 100, n/a) 20%: (4.03, 6.50) (600, 300, n/a) 20%: (17.95, 27.55)\n40%: (8.65, 13.21) 40%: (27.35, 40.68)\n70%: (14.90, 21.67) 70%: (34.81, 48.81)\n100%: (20.75, 27.82) 100%: (40.15, 53.82)\nTable 8: Performance of knowledge graph embedding models on FB60K-NYT10 and UMLS-PubMed. \"edim\"\nand \"rdim\" denotes the embedding size of entity and relation respectively. \"filter\" denotes the application of the\nfiltered setting. Best setting for each model is highlighted in bold.\n11178\nACL 2023 Responsible NLP Checklist\nA For every submission:\n‚ñ°\u0013 A1. Did you describe the limitations of your work?\nSection 7.\n‚ñ°\u0013 A2. Did you discuss any potential risks of your work?\nSection 7 and Section 8.\n‚ñ°\u0013 A3. Do the abstract and introduction summarize the paper‚Äôs main claims?\nAbstract and Section 1.\n‚ñ°\u0017 A4. Have you used AI writing assistants when working on this paper?\nLeft blank.\nB ‚ñ°\u0013 Did you use or create scientiÔ¨Åc artifacts?\nSection 4.\n‚ñ°\u0013 B1. Did you cite the creators of artifacts you used?\nSection 3, Section 4, Appendix A, Appendix G, Appendix I.\n‚ñ°\u0013 B2. Did you discuss the license or terms for use and / or distribution of any artifacts?\nSection 3, Section 4, Appendix A, Appendix G, Appendix I.\n‚ñ°\u0013 B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided\nthat it was speciÔ¨Åed? For the artifacts you create, do you specify intended use and whether that is\ncompatible with the original access conditions (in particular, derivatives of data accessed for research\npurposes should not be used outside of research contexts)?\nSection 8.\n‚ñ° B4. Did you discuss the steps taken to check whether the data that was collected / used contains any\ninformation that names or uniquely identiÔ¨Åes individual people or offensive content, and the steps\ntaken to protect / anonymize it?\nNot applicable. The used datasets FB60K, UMLS, NYT10 and PubMed are all publicly accessible.\n‚ñ°\u0013 B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and\nlinguistic phenomena, demographic groups represented, etc.?\nSection 4, Appendix A.\n‚ñ°\u0013 B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,\netc. for the data that you used / created? Even for commonly-used benchmark datasets, include the\nnumber of examples in train / validation / test splits, as these provide necessary context for a reader\nto understand experimental results. For example, small differences in accuracy on large test sets may\nbe signiÔ¨Åcant, while on small test sets they may not be.\nReported in Appendix A.\nC ‚ñ°\u0013 Did you run computational experiments?\nSection 4, Section 5.\n‚ñ°\u0013 C1. Did you report the number of parameters in the models used, the total computational budget\n(e.g., GPU hours), and computing infrastructure used?\nAppendix D.\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing\nassistance.\n11179\n‚ñ°\u0013 C2. Did you discuss the experimental setup, including hyperparameter search and best-found\nhyperparameter values?\nSection 4.2 and Appendix C.\n‚ñ°\u0013 C3. Did you report descriptive statistics about your results (e.g., error bars around results, summary\nstatistics from sets of experiments), and is it transparent whether you are reporting the max, mean,\netc. or just a single run?\nSection 5.\n‚ñ°\u0013 C4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did\nyou report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,\netc.)?\nSection 4, Appendix I.\nD ‚ñ°\u0017 Did you use human annotators (e.g., crowdworkers) or research with human participants?\nLeft blank.\n‚ñ° D1. Did you report the full text of instructions given to participants, including e.g., screenshots,\ndisclaimers of any risks to participants or annotators, etc.?\nNo response.\n‚ñ° D2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)\nand paid participants, and discuss if such payment is adequate given the participants‚Äô demographic\n(e.g., country of residence)?\nNo response.\n‚ñ° D3. Did you discuss whether and how consent was obtained from people whose data you‚Äôre\nusing/curating? For example, if you collected data via crowdsourcing, did your instructions to\ncrowdworkers explain how the data would be used?\nNo response.\n‚ñ° D4. Was the data collection protocol approved (or determined exempt) by an ethics review board?\nNo response.\n‚ñ° D5. Did you report the basic demographic and geographic characteristics of the annotator population\nthat is the source of the data?\nNo response.\n11180",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.813129723072052
    },
    {
      "name": "Knowledge graph",
      "score": 0.7118426561355591
    },
    {
      "name": "Embedding",
      "score": 0.6674747467041016
    },
    {
      "name": "Graph",
      "score": 0.6166421175003052
    },
    {
      "name": "Language model",
      "score": 0.6144375801086426
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.5826218128204346
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5026047229766846
    },
    {
      "name": "Natural language processing",
      "score": 0.4939165711402893
    },
    {
      "name": "Information retrieval",
      "score": 0.3975258469581604
    },
    {
      "name": "Machine learning",
      "score": 0.3801228106021881
    },
    {
      "name": "Theoretical computer science",
      "score": 0.17402887344360352
    },
    {
      "name": "Geodesy",
      "score": 0.0
    },
    {
      "name": "Geography",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I157725225",
      "name": "University of Illinois Urbana-Champaign",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I859038795",
      "name": "Virginia Tech",
      "country": "US"
    }
  ],
  "cited_by": 16
}