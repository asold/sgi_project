{
  "title": "MS2Mol: A transformer model for illuminating dark chemical space from mass spectra",
  "url": "https://openalex.org/W4381334298",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5076874522",
      "name": "Thomas Butler",
      "affiliations": [
        "Enveda Therapeutics (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A5025383494",
      "name": "Abraham Frandsen",
      "affiliations": [
        "Enveda Therapeutics (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A5052891524",
      "name": "Rose Lightheart",
      "affiliations": [
        "Enveda Therapeutics (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A5065833710",
      "name": "Brian Bargh",
      "affiliations": [
        "Enveda Therapeutics (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A5092213609",
      "name": "TJ Bollerman",
      "affiliations": [
        "Enveda Therapeutics (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A5114060054",
      "name": "Thomas Kerby",
      "affiliations": [
        "Enveda Therapeutics (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A5066236566",
      "name": "Kiana West",
      "affiliations": [
        "Enveda Therapeutics (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A5018318324",
      "name": "Gennady Voronov",
      "affiliations": [
        "Enveda Therapeutics (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A5010822968",
      "name": "Kevin R. Moon",
      "affiliations": [
        "Enveda Therapeutics (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A5030581253",
      "name": "Tobias Kind",
      "affiliations": [
        "Enveda Therapeutics (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A5082720301",
      "name": "Pieter C. Dorrestein",
      "affiliations": [
        "Enveda Therapeutics (United States)",
        "University of California, San Diego"
      ]
    },
    {
      "id": "https://openalex.org/A5015485079",
      "name": "August Allen",
      "affiliations": [
        "Enveda Therapeutics (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A5003250302",
      "name": "Viswa Colluru",
      "affiliations": [
        "Enveda Therapeutics (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A5089107006",
      "name": "David Healey",
      "affiliations": [
        "Enveda Therapeutics (United States)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2125069590",
    "https://openalex.org/W3119952098",
    "https://openalex.org/W2114688451",
    "https://openalex.org/W3139516621",
    "https://openalex.org/W3118695441",
    "https://openalex.org/W3094640617",
    "https://openalex.org/W2504691963",
    "https://openalex.org/W3048832160",
    "https://openalex.org/W3209680996",
    "https://openalex.org/W2177317049",
    "https://openalex.org/W3108482473",
    "https://openalex.org/W2015503332",
    "https://openalex.org/W2179948434",
    "https://openalex.org/W3206878019",
    "https://openalex.org/W4281688302",
    "https://openalex.org/W3176980311",
    "https://openalex.org/W3201481795",
    "https://openalex.org/W2551876238",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W1816313093",
    "https://openalex.org/W1997386061",
    "https://openalex.org/W2059327215",
    "https://openalex.org/W4281658583",
    "https://openalex.org/W3202344023",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W2016589492",
    "https://openalex.org/W2097998348",
    "https://openalex.org/W2069870183",
    "https://openalex.org/W2895677720",
    "https://openalex.org/W3216027541",
    "https://openalex.org/W2160592148",
    "https://openalex.org/W2066273100",
    "https://openalex.org/W4318620627",
    "https://openalex.org/W2883265831",
    "https://openalex.org/W4324315446",
    "https://openalex.org/W4391772345",
    "https://openalex.org/W2070072705",
    "https://openalex.org/W2980282514",
    "https://openalex.org/W4229971999",
    "https://openalex.org/W2769423117",
    "https://openalex.org/W2034549041",
    "https://openalex.org/W4299416872",
    "https://openalex.org/W2962784628",
    "https://openalex.org/W3047578609",
    "https://openalex.org/W3129424480",
    "https://openalex.org/W4229590462",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W1678356000",
    "https://openalex.org/W4238471389",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W4238781491",
    "https://openalex.org/W1975147762",
    "https://openalex.org/W4313422424",
    "https://openalex.org/W4284961832",
    "https://openalex.org/W4304092658",
    "https://openalex.org/W3194841450"
  ],
  "abstract": "The ability to identify small molecules in complex samples from their mass spectra is among the grand challenges of analytical chemistry. Improvements to this ability could significantly advance fields as diverse as drug discovery, diagnostics, environmental science, and synthetic biology. A primary bottleneck is that standard structure elucidation technologies are limited to identifying only those molecules that are contained in databases of known spectra or molecular structures and are therefore not well suited to identifying the vast majority of potentially billions of natural metabolites, whose structures are not yet catalogued. To improve the identification of molecular structures within this vast dark chemical space, we present MS2Mol, a \\textit{de novo} structure prediction model based on a generative sequence to sequence transformer. We also release EnvedaDark, a first-of-its-kind for benchmarking identification performance on unknown metabolites. EnvedaDark contains experimental mass spectra from 226 natural products not currently found in major databases. We demonstrate on this challenging dataset that MS2Mol is able to predict 21\\% of molecular structures to within a close-match accuracy threshold and 62\\% to within meaningful similarity, both of which are significant improvements over the closest match retrieved using standard database methods. We further present a confidence scorer that enables practical usage for novel molecule discovery and enriches the accuracy on meaningfully-similar and close-match thresholds to 98\\% and 63\\%, respectively, for the top 10\\% most confident predictions.",
  "full_text": "MS2Mol: A transformer model for illuminating dark\nchemical space from mass spectra\nThomas Butler1, Abraham Frandsen1, Rose Lightheart1, Brian Bargh1, TJ\nBollerman1, Thomas Kerby1, Kiana West1, Gennady Voronov1, Kevin Moon1,\nTobias Kind1, Pieter Dorrestein2, August Allen1, Viswa Colluru1, and David\nHealey1\n1Enveda Biosciences, Boulder, CO, USA\n2Collaborative Mass Spectrometry Innovation Center, Skaggs School of Pharmacy and\nPharmaceutical Sciences, University of California San Diego, La Jolla, CA, USA\nAbstract\nThe ability to identify small molecules in complex samples from their mass spectra\nis among the grand challenges of analytical chemistry. Improvements to this ability\ncould significantly advance fields as diverse as drug discovery, diagnostics, environmental\nscience, and synthetic biology. A primary bottleneck is that standard structure elucida-\ntion technologies are limited to identifying only those molecules that are contained in\ndatabases of known spectra or molecular structures and are therefore not well suited\nto identifying the vast majority of potentially billions of natural metabolites, whose\nstructures are not yet catalogued. To improve the identification of molecular struc-\ntures within this vast dark chemical space, we present MS2Mol, ade novo structure\nprediction model based on a generative sequence to sequence transformer. We also\nrelease EnvedaDark, a first-of-its-kind for benchmarking identification performance\non unknown metabolites. EnvedaDark contains experimental mass spectra from 226\nnatural products not currently found in major databases. We demonstrate on this\nchallenging dataset that MS2Mol is able to predict 21% of molecular structures to within\na close-match accuracy threshold and 62% to within meaningful similarity, both of which\nare significant improvements over the closest match retrieved using standard database\nmethods. We further present a confidence scorer that enables practical usage for novel\nmolecule discovery and enriches the accuracy on meaningfully-similar and close-match\nthresholds to 98% and 63%, respectively, for the top 10% most confident predictions.\n1 Introduction\nUnderstanding the small-molecule chemistry of complex samples is a central goal of many\nscientific endeavors, including natural products discovery, human metabolomics, synthetic\nbiology, food science, and studies of environmental contamination. Tandem mass spectrometry\n(MS/MS) coupled with liquid or gas chromatography is the principal tool for these studies\n1\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nbecause it can detect large numbers of small molecules in experimental samples with high\nsensitivity. The resulting MS/MS fragmentation spectra are the primary experimental\nsignature of the chemical contents of complex chemical mixtures. Yet molecular structures\ncannot be reliably identified for the majority of spectra from complex samples [1]. One reason\nfor low annotation rates is that standard annotation methods work by predicting matches\nfrom databases of reference spectra or known molecules. However, a substantial fraction of\nthe spectra in complex samples correspond to molecules not contained in existing databases.\nSuch compounds, with unknown structure and spectra, can be said to exist in a dark chemical\nspace. Further, in many discovery applications it is often precisely these \"dark\" compounds\nthat are of greatest interest. [2].\nDark chemical space poses a particular challenge for standard compound identification\nmethods since these methods are limited to predicting only molecular structures contained\nin their databases. In contrast, ourde novo structure prediction method uses generative\nmachine learning to predict chemical structures directly from spectra without relying on\ndatabases of known compounds. Because complex biological samples often contain a mixture\nof known and novel compounds, database retrieval methods andde novoprediction can be\npowerfully complementary technologies for untargeted profiling experiments.\nThe unique utility ofde novostructure prediction is reflected in the relative sizes of dark and\nknown chemical space. While there is substantial uncertainty about the number of distinct\nmetabolite structures that exist in nature, estimates range in the billions [3, 4]. In contrast,\nCOCONUT [5], a global repository of known natural products, contains around 400,000\ncompounds, suggesting that we have discovered only a tiny fraction of existing biological\nmetabolites, of which an even smaller number, in the tens of thousands, have experimentally-\ndetermined reference spectra available in repositories like NIST2020, MoNa, MassBank, and\nGNPS. Synthetic chemical space is similarly dark, with large structure databases like ZINC\ncontaining in the billions of molecules [6], still a small fraction of the potentially1060 possible\nmolecular structures that could exist. In short, all estimates point to dark chemical space\nbeing astronomically larger than known chemical space, supporting a critical role forde novo\nstructure prediction.\nCompound identification from mass spectrometry can be naturally categorized into three\ndifferent approaches: spectral reference search, compound library search, and de novo\ngeneration (see Figure 1).\nSpectral reference searchbased systems implement a similarity function for pairs of spectra,\nsim : S × S → [0, 1] where S is the space of MS/MS spectra. These systems allow users to\nmatch experimental unknowns to spectra in reference libraries. Predicted structures then\nconsist of the highest scoring matches from the database. One common similarity function\nis a modified cosine similarity function [7], but more sophisticated similarity functions use\nunsupervised learning to create dense embeddings of spectra, which have been shown to\nachieve higher accuracy than cosine similarity in some contexts. Examples of these include\nword2vec-style embeddings [8] and Siamese networks using contrastive loss [9, 10]. Spectral\nlibrary search is limited by the relatively small number of compounds found in publicly\navailable reference libraries.\n2\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nCompound library searchbased systems attempt to overcome the limited coverage of spectral\nreference libraries by creating a similarity function between mass spectra and candidate\nmolecular structures,sim : S × M → [0, 1], whereS is the space of mass spectra, andM is\nthe space of molecular structures. This allows a mass spectrum to be used as a query into\nmolecular databases such as PubChem [11] and COCONUT[5] that lack mass spectral data\nbut contain many more structures.\nThere are two main approaches to compound library search. The first uses one of manyin\nsilico fragmentation algorithms to convert molecular libraries into (synthetic) spectral libraries\nand then performs a spectral library search on the synthetic spectra [12, 13, 14, 15, 16]. The\nsecond predicts a molecular fingerprint from the mass spectra, sometimes with prior prediction\nof molecular formulas and/or fragmentation trees. The molecular fingerprint indicates which\nof a predetermined set of substructures or features are present in a structure. This method\nthen compares the fingerprint to a library of fingerprints from a structural database of known\ncompounds. Examples of these methods are CSI:FingerID [17], implemented in the SIRIUS\nsoftware suite, and the tool used in the highest-accuracy submission to the recent Critical\nAssessment of Small Molecule Identification (CASMI) contest [18]. This is also used by\nMIST[19], which predicts the same CSI:FingerID fingerprints using a neural network.\nWhile designed to identify known molecules, compound library search may be adapted for\nidentification of novel structures in cases where the candidate set of structures is limited\nenough that a library containing all possible candidate structures can be enumerated. An\nexample is the discovery of novel bile acid conjugates using CSI:FingerID and COSMIC\n[20], which used 16,000 hypothesized bile acid conjugates as the molecular library to search.\nFor complex mixtures containing heterogenous molecular structures, however, the space of\npossible structures is likely to be too large to enumerate.\nDe novo structure predictionsystems use machine learning to generate potentially novel\nmolecular structures directly from mass spectra, with three different methods published\nin recent years. MSNovelist [21] relies on CSI:FingerID [17] to predict a fingerprint for an\nunknown molecule, then uses a decoder trained on molecular fingerprints from structure\nlibraries to translate the fingerprint into a molecular structure represented by a Simplified\nmolecular-input line entry system (SMILES) string [22]. MassGenie [23] trains a model\nwith a standard transformer encoder-decoder architecture on large amounts ofin silico\nfragmentation data generated from chemical structure libraries, finetuned with experimental\nspectra. Spec2Mol [24], like MSNovelist, uses a separate pretrained decoder, but instead of\npredicting fingerprints, a convolutional neural network (CNN) spectrum encoder is trained to\npredict into the learned embedding space of a pretrained GRU SMILES autoencoder, the\ndecoder half of which is then used to generate the output SMILES.\nIn this work we present MS2Mol, a transformer-based model for thede novogeneration of\nmolecular structures from MS/MS spectra. This model uses an encoder-decoder architecture\nadapted from BART [25] and is trained end-to-end on spectrum-structure pairs. MS2Mol’s\ndesign differs from previousde novomodels in several ways. First, we introduce byte pair\nencoding for SMILES predictions, which provides us with a learnable substructure vocabulary\nfit on the training dataset, allowing the model to add common substructures and SMILES\nelements with single tokens. Secondly, we include precursor mass as an input, allowing the\n3\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nmodel to take advantage of knowing the mass of the unfragmented compound, but avoid\noverfitting to that information by randomly masking it during training. Third, we encode\nfragmentation masses using separate integer and fractional mass tokens, which, relative to\nnaive mass binning, maintains the high-resolution mass information needed to disambiguate\nchemical formulas while representing with a smaller vocabulary. Fourth, we train a small\nreranking model and use it to rank the MS2Mol predictions generated for a single input\nspectrum, which improves the accuracy of the top-ranked predictions. Finally, we use a\nconfidence model to prospectively predict the quality of the predictions, enabling users of the\nmodel to act on a subset of highly-confident predictions in applications where errors could be\ncostly.\nEvaluating the performance ofde novo structure elucidation methods against database\nmethods is challenging. Evaluation sets must have known structures, so they commonly\nconsist of holdout sets from spectral reference libraries or consist of former challenge spectra\nfrom the Critical Assessment of Small Molecule Identification (CASMI) challenges. Since\ntheir structures are typically known, database retrieval methods are advantaged on these\nsets, since these methods drastically reduce the search space to that of known structures.\nFurthermore, it is common for structure evaluation to only consider exact structure match\nas a metric of success; however, database search methods by definition cannot retrieve\nan exact match structure for an unknown compound. These methods can still be useful\nas baseline methods, though, by identifying analogs from known compounds. Previously\npublished de novomethodologies have dealt with these challenges in different ways; MassGenie\ndoes not benchmark against a molecular-search baseline. MSNovelist benchmarks against\nCSI:FingerID on molecules contained in its databases and performs worse at retrieving the\nexact structure, noting that this is to be expected. Spec2Mol evaluates against CSI:FingerID\nusing similarity rather than exact match as a metric, but to proxy dark chemical space only\nevaluates on the set of spectra for which SIRIUS fails to predict the correct molecular formula.\nThis disadvantages CSI:FingerID since SIRIUS often correctly predicts molecular formulas\neven of unknown molecules, and CSI:FingerID relies heavily on accurate molecular formula\npredictions.\nIn this work we take a more relevant and stringent evaluation approach, for the first time\nevaluating de novostructure prediction in dark chemical space. We evaluate MS2Mol on a\nnovel set of spectra from 226 molecules that are naturally occurring but whose structures\nare not contained in structural databases. This mimics directly the intended use case forde\nnovo methods. We term this dataset EnvedaDark (for “dark chemical space”). Further, we\nreport as our primary performance metrics accuracy with respect to two Tanimoto similarity\nthresholds representing meaningful similarity and close match similarity, which were defined\nto match blinded expert chemist annotations of prediction usefulness for the purposes of\ndrug development prioritization. We include both spectral library search (modified cosine\nsimilarity) and molecular library search (CSI:FingerID) as baselines. We are not able to\nbenchmark against previousde novomodels since, as of writing, no otherde novomethod\nhas a working public implementation.\nOn EnvedaDark, MS2Mol predicts a structure to within meaningful similarity of the actual\nmolecule for 62% of spectra, and 21% to within close match, exceeding the highest database\n4\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nretrieval baselines by 44% and 95% relative accuracy, respectively at those thresholds. We\nevaluate MS2Mol’s confidence model, which enriches the accuracy on meaningfully-similar\nand close-match thresholds to 98% and 63%, respectively, for the top 10% most confident\npredictions. We further evaluate MS2Mol on two sets of known molecules: CASMI-2022 and a\nnovel set of spectra experimentally gathered from 454 known natural products, which we call\nEnvedaLight. We show that despite database methods excelling at retrieving exact matches,\nMS2Mol performs comparably to database matches at predicting meaningfully similar or\nclose matched analogs even on known molecules. This introduces the possibility of using a\nsingle structure elucidation model to predict both known and unknown molecules in complex\nmixtures.\n2 Results\n2.1 MS2Mol generates predicted chemical structures using a trans-\nformer encoder/decoder model\nMS2Mol castsde novostructure prediction from MS/MS data as a neural machine translation\nproblem to map from the \"language\" of MS/MS fragments into the language of small\nmolecules, as defined by SMILES strings. Natural language frameworks have been observed to\nbe valuable for interpretation of mass spectra [26, 8], since the meaning of mass fragments are\ncontextually dependent on the presence and absence of other potentially distant fragments,\nand the fragments are composed into an overall spectrum in a similar way to words in a\nsentence. The development of transformer encoder-decoder architectures in particular [27]\nsignificantly improved machine translation models by enabling more efficient computation\nwhile allowing the learning of complex and long ranged dependencies. MS2Mol uses the\nBART implementation of a transformer based encoder-decoder architecture [25, 28].\nInput mass spectra consist of triples of the form {precursor m/z, fragment m/z array, intensity\narray}, where the precursor m/z is a positive real number corresponding to the mass-to-charge\nratio of the unfragmented ion, the fragment m/z array is an array of positive real numbers\nthat correspond to the mass-to-charge ratios of the MS/MS fragments, and the intensity\narray is an array of positive real numbers corresponding to the intensity of the fragments. In\nanalogy with natural language processing, MS/MS fragments are represented as a language\nwith a vocabulary of mass values. Input spectra are encoded as pairs of integer and fractional\npart tokens corresponding to masses and sorted in descending order by intensity with the\nprecursor mass in first position, as shown in Figure 1. This allows a smaller overall vocabulary\nfor a given mass resolution than previous work that has tokenized spectra into mass bins (e.g.\n[9]).\nThe output structures are encoded as SMILES string representations of chemical structures\n[22] using byte pair encoding (BPE), a method for finding a high coverage vocabulary of\nsubstrings in natural language processing [29] through iterative combining of high-frequency\npairs of tokens into single tokens. In the context of molecule generation, this results in a\ntoken vocabulary that contains common molecular substructures and other common SMILES\nelements like ring and branch closures encoded as single tokens, learned from the data rather\n5\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nFigure 1: MS2Mol generates predicted chemical structures of unknown molecules from dark\nchemical space using their fragmentation spectra.a) Overview of approaches to structure\nelucidation. Common approaches to identification of small molecules from their MS/MS\nspectra include matching to spectral reference libraries (top) and information retrieval\nfrom candidate databases of known structures (middle), for which the relevant metabolite\ndatabases contain on the order of104 and 105 structures, respectively. In contrast, accurate\nelucidation of the vast majority of natural metabolites (108-1010) requires de novo structure\nprediction. b) An illustration of byte-pair encoded (BPE) substructure learning for molecule\ngeneration. Similar to BPE in natural language, tokens (masses) that are commonly adjacent\nare combined into single new tokens. Those tokens may then be further paired with .\nThe process proceeds iteratively, and the resulting vocabulary contains common structural\nelements of the molecules in the training set encoded as single tokens.c) Conceptual overview\nof MS2Mol encoder/decoder. Spectra are sorted by intensity then tokenized separately into\ninteger and decimal parts, which are then converted to learned fragment embeddings. The\nspectrum, which includes a probabilistically-masked precursor mass, is then passed into a\ntransformer encoder/decoder. Decoding is accomplished using beam search to produce a\nranked set of predicted molecular formulas and chemical structures represented as byte-pair\nencoded SMILES.\n6\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nthan predefined. This shortens the overall output length and reduces the chances for error\nduring autoregressive generation of structures.\nThe mass of the unfragmented ion, called the precursor mass, contains valuable information\non the identity of the molecule. For example, molecular formula can be disambiguated to a\nlarge degree using an accurate precursor mass. However, training on MS/MS data is prone to\noverfitting if the precursor mass from the MS1 spectrum is naively included in the spectrum.\nThis is because over the training set, the precursor mass is unique or nearly unique for many\ncompounds, allowing the model to memorize the output as a function of precursor mass. To\nlearn from the precursor mass without overfitting, we randomly mask the precursor mass\nwith 50% probability, and leave it unmasked at inference time.\nA further complication of available MS/MS libraries is that certain compounds have far more\nspectra associated with them than others. To avoid overfitting to such compounds, we weight\nthe training objective to account for the multiplicity of spectra per compound by using a\nmodified cross entropy loss, described in Section 4.\nMS2Mol is designed to predict chemical structures without ground truth molecular formulas,\nas those are typically not known in discovery scenarios. However, the output of MS2Mol\nconsists of molecular formula followed by chemical structure. This allows for the case in\nwhich the ground truth formula is known or can be accurately predicted. Since the output is\ngenerated autoregressively, prompting the output with the ground truth molecular formula\nallows the chemical structure to be partially conditioned on the correct formula, which\nincreases accuracy. See D\nTo train MS2Mol, we constructed a dataset of1, 020, 431 MS/MS spectra paired with42, 995\nstructures obtained by merging standard commercially available and public datasets spanning\ninstrument types, ion modes, collision energies, and other parameters [7, 30, 31, 32, 33, 34],\nsupplemented with a dataset of33, 634 internally-generated reference spectra from6, 124\npurified natural products, for a total of961, 865 spectra from49, 119 structures. We further\nsupplemented the experimental data with weak supervision using publicly available simulated\nmass spectra generated by CFM-ID 4.0 from natural products contained in the LOTUS\ndatabase [35, 36, 12]. See Section 4 for further training details.\nAblation studies of each of these choices are presented in the Appendix.\n2.2 MS2Mol predicts unknown structures with higher accuracy than\nspectral library search and molecular library search\nIn order to assess performance on dark chemical space, or compounds that are not presently\ncontained in common molecular databases or annotated spectral libraries, we constructed\na dataset of 1010 spectra from 226 purified “novel” natural products across three collision\nenergies and seven possible ion adducts, where we define novelty as compounds whose\nstructures are not contained in common structural repositories Pubchem [11] or COCONUT\n[5], and therefore not available for database search methods or as training data at the time\nof writing. We term this dataset EnvedaDark.\n7\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nFigure 2: MS2Mol outperforms both spectral reference search and molecule retrieval on pre-\ndicting structures of unknown natural products at multiple similarity thresholds.a) Example\nstructural elucidation using three methods. A test spectrum is gathered experimentally from\na sample molecule whose structure is not in a database, then top-1 structure prediction is\nperformed usingde novoprediction (MS2Mol, top), spectral reference search (modified cosine\nsimilarity, middle), or molecular database retrieval (CSI:FingerID, bottom).b) Examples\ndemonstrating the expert annotations of pairs of actual and predicted structures that were\nto define meaningful similarity and close match Tanimoto similarity thresholds (see also\nAppendix). c) Top-k and top-1 accuracy for the meaningfully similar criterion (see main\ntext) of >0.4 Tanimoto similarity between ground truth and the predicted structure.d)\nTop-k and top-1 similarity between the ground truth and the predicted structure for the close\nmatch criterion (see main text) of >0.675 Tanimoto similarity.e) Top-k and top-1 similarity\nbetween the ground truth and the predicted structure for exact InChiKey-14 match (two\ndimensional structure). The curves for the two baseline methods are exactly overlaid.\n8\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nTo evaluate performance accuracy, we adopt as our primary metrics “meaningfully similar”\nand “close-match” accuracy. We note that common compound identification metrics often\nconsider exact match success metrics [17, 21, 13, 18], and we report these as well. However,\nwhile exact match metrics may be suited to evaluating the ability of database search methods\nto produce the exact two dimensional structure from a predefined set of candidate structures,\nwhen evaluating prediction accuracy on test spectra from dark chemical space, exact-match\nmetrics bias against database methods, which cannot, by definition, produce an exact match\nprediction corresponding to a structure outside of its databases. Furthermore, in many\napplications including discovery of novel natural products, a relevant metric of success is\nwhether the prediction is a close enough approximation of the actual molecule to be useful for\na given application. Given these observations, we adopt as our primary evaluation framework\nmeasuring the fraction of molecules for which the prediction meets or surpasses a suitable\nstructure similarity threshold.\nTo obtain automated metrics that assess whether a prediction is sufficiently similar to\nthe ground truth molecule to be useful for guiding decision making, we fit two thresholds\nof Tanimoto similarity (between RDKit topological fingerprints [37]) to expert chemist\nannotations of pairs of predicted versus actual structures, where predicted structures were\ngenerated either from previous generations of MS2Mol, CSI:FingerID, or were chosen randomly\nfrom the training set as a control. 1288 such pairs were sequentially shown to six expert\nchemists. The chemists were aware of the composition of the set, but blinded as to the source\nof the predictions, and scored pairs of annotations as 1) not similar, 2) meaningfully similar\nbut with errors, and 3) close match. (See the Appendix for a screenshot of the annotation\ntool and examples of expert annotations). We chose a Tanimoto similarity threshold of\n0.675 to represent “close match accuracy” because it predicts the overall rate of close match\npredictions correctly. As shown in the Appendix, the threshold that correctly predicts the\nclass balance for close match also balances precision and recall of the similarity scores with\nrespect to the chemist annotations. Likewise, we chose Tanimoto similarity of 0.4 to represent\n“meaningful similarity”, using the upper 95% confidence bound of chemist annotations as\na conservative threshold to minimize erroneously calling \"not similar\" predictions as being\nmeaningfully similar, which is a more common error in the lower Tanimoto similarity range.\nSee Figure 2 and the Appendix for samples of chemist annotations and bootstrap fitting of\nTanimoto similarity thresholds.\nWe compare MS2Mol’sde novogeneration approach with standard alternatives in spectral and\nmolecule database search – see Figure 2 and Table 1. While it would be ideal to benchmark\nagainst otherde novostructure prediction methods, as of writing, MSNovelist [21], MassGenie\n[23], and Spec2Mol [24] lack functioning public implementations. We note that while neither\nreference lookup nor molecule database search were intended to predict novel structures,\nnovel molecules are nonetheless highly prevalent in nature, and to predict their structures, a\nreasonable alternative tode novomethods is to use database retrieval to find close analogs.\nFor spectral library search, we use modified cosine using the matchms [38] implementation\nwith a spectral reference library consisting of the public and commercially available data\ndescribed in Section 2.1. We also compare to CSI:FingerID, a state-of-the art molecular\nsearch tool implemented in the SIRIUS software suite [17], and the tool which resulted in\n9\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nthe best annotation performance in the most recent Critical Assessment of Small Molecule\nIdentification (CASMI) contest [18]. CSI:FingerID searches molecular databases by using\nmass spectra to predict a suite of molecular substructures, then searches molecular databases\nfor molecules with similar substructure profiles.\nWe evaluate both the top-scoring predictions of each method and the top-k predictions (up\nto k = 25) for each of the three methods at the “meaningfully similar” and “close match”\nthresholds defined above. We also evaluate “exact match” prediction (minus stereochemistry),\ndefined as an exact string match of the first 14 digits of the respective InChiKeys for the\npredicted and actual structures.\nMS2Mol performs strictly better than the baseline methods at all three similarity thresholds\non the EnvedaDark dataset. Using the above threshold criteria, MS2Mol’s top predictions are\nat least meaningfully similar for 62.1% of spectra, compared to 42.9% and 31.0%, respectively,\nfor the top predictions from CSI:FingerID and modified cosine reference search, while being at\nleast close-matched for 21.4% of spectra, compared to 11.0% and 7.2% for CSI:FingerID and\nmodified cosine reference search, respectively. For only 1.6% (16 spectra from 7 molecules)\ndoes MS2Mol predict an exact structure match, compared to 0% for the other two, where 0%\nis expected since the EnvedaDark molecules are not found in those databases.\nFurthermore, more predictions per spectra increase the likelihood of predicting a better match.\nThe top-25 predictions from MS2Mol contain a meaningfully-similar prediction for 87.6%\nof spectra (up from 62.1% top-1), and a close match prediction for 36.8% (up from 21.4%\ntop-1). These improvements between top-25 and top-1 suggest further predictive value to be\ngained by accurate re-ranking of relatively small numbers ofde novopredictions. (Figure 2\nand Table 1).\nSince MS2Mol’s full training set contains spectra generated under the same experimental\nsetting from which EnvedaDark spectra were derived, we also evaluate a version of MS2Mol\nthat was not trained on internal spectra. We call this model MS2Mol PA (“MS2Mol publicly\navailable”); performance of this model is represented with a dotted line in Figure 2). We\nobserve that training on internal spectra provides a lift in performance, which demonstrates\nthe benefits of training on in-domain labeled spectra for real-world applications. However, we\nshow that MS2Mol still comfortably outperforms the baselines even without internal spectra\nin the training set.\n2.3 Performance analysis of MS2Mol\nWe further investigate MS2Mol by examining trends in the performance of predictions on\nEnvedaDark, noting potential strengths and weaknesses of MS2Mol in predicting natural\nproducts in dark chemical space. Firstly, we observe that MS2Mol is able to accurately\npredict structures even if molecules have fairly complicated extended structures with repeating\nsubunits, as is relatively common for natural products; see Figure 3a. When examining\ninaccurate predictions, we find spectra from “darker” chemical space, i.e. spectra whose\nstructures are dissimilar to everything in the training set.\nTo further investigate how the “darkness” of chemical space affects the performance of MS2Mol,\n10\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nFigure 3: Performance analysis of MS2Mol. a) Examples of good MS2Mol predictions.\nGround truth structure, predicted structure, and the closest molecule in the training set are\nshown for two examples from the test set, representative of cases where MS2Mol predicted an\nexactly or approximately correct structure. The upper example shows a case where MS2Mol\npredicted the structure exactly correct despite no exact match present in the training data.\nThe lower example demonstrates that MS2Mol can predict well even for relatively complex\nstructures. b) Examples of bad MS2Mol predictions. Ground truth structure, predicted\nstructure, and the closest molecule in the training set shown for examples from EnvedaDark,\nrepresentative of cases where MS2Mol predicted a structure with low Tanimoto similarity\nto the actual structure. The upper case demonstrates the difficulty of predicting structures\nfar away from anything in the training set. The lower case demonstrates a potential failure\nmode of MS2Mol in discriminating between linear and cyclic structures.c) Mean Tanimoto\nsimilarity between predicted and ground truth molecules from EnvedaDark (line) over bins\nof similarity between the ground-truth molecule to the training set of annotated spectra,\noverlaid with a histogram of spectrum counts across the same similarity bins.d) Mean\nTanimoto similarity on a test set of natural products across 16 common natural product\nclasses. Left numbers indicate numbers of distinct compounds represented in each class.\n11\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nwe examine the performance of MS2Mol binned by the Tanimoto similarity between the\nground truth structure and the closest molecule in the training set (excluding the simulated\nspectra). As with many machine learning systems, we observe that prediction accuracy is\nhighly correlated with proximity of the unknowns to elements in the training set. The average\nsimilarity of predictions to ground truth is nearly 3x higher for spectra from the most similar\n(>=0.94 Tanimoto similarity) structures to train than for the least similar (between 0.44\nand 0.50 Tanimoto Similarity). We further note a difference in performance across natural\nproduct classes as predicted by NP Classifier [39], with flavonoids, monoterpenoids, and\nsteroids having the highest Tanimoto similarities, while macrolides, cyclic peptides, and fatty\nacids had the lowest. The latter result reinforces our observations regarding cyclic structures.\n2.4 Confidence modeling enables practical use of MS2Mol\nFor many machine learning applications, particularly those in which poor predictions can\nbe costly, it is desirable to not only have aggregate accuracy metrics but to also estimate\nthe reliability of each prediction. This allows expert decision makers to segment predictions\nby confidence and potentially act only on those that pass a quality threshold. To enable\nthis, in addition to the structure prediction model we trained a separate confidence model\nthat predicts the Tanimoto similarity between the MS2Mol predicted structure to the ground\ntruth structure.\nThe confidence model is a gradient boosting machine [40] with input features derived from\nthe MS/MS spectrum (such as the number of peaks and the precursor m/z), properties of\nthe predicted structure (such as the number of heteroatoms), structural properties predicted\ndirectly from the MS/MS spectra by a property prediction model as in [10], and MS2Mol\nmodel outputs (such as the log probability of the generated token sequence). More details of\nthe confidence model training are given in Section 4 and the Appendix.\nTo evaluate the confidence model, we binned predictions on EnvedaDark into confidence\ndeciles (Figure 4a). We find the top 10% most confident predictions achieve a 63.4% close-\nmatch accuracy and a 98% meaningful similarity accuracy, compared to the 21% and 62%,\nrespectively, across all confidence levels. Furthermore, we find the confidence model to be\nwell-calibrated in the sense that, within the binned deciles, the actual similarities are close to\nthe predicted similarities (Figure 4b). The confidence model achieves 0.13 mean absolute error\nbetween the true and predicted Tanimoto similarity, with anR2 of 0.4. We next inspected the\nfeatures of the confidence model most associated with better predictions, using permutation\nbased feature importance [41] (Figure 4c). Feature importance calculations depend heavily\non methods and data properties such as collinearity, but the resulting feature importance\nshows a large dependence on mass difference features, which is chemically reasonable and\npoints to the possibility that generative methods that constrain mass more effectively could\nbe a powerful advance in the future.\n2.5 Evaluating MS2Mol on known chemical space\nIn previous sections, we introduced the first evaluation of ade novo structure prediction\ntechnology on dark chemical space. As a baseline, we compared it to molecular and spectral\n12\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nFigure 4: Confidence model performance. a) The fraction of predictions with similarity\ngreater than 0.675 and greater than 0.4 as a function of confidence deciles in EnvedaDark. The\ntop 10% highest predicted similarities correspond to predictions that are over 60% accurate\nat the 0.675 threshold.b) The confidence model accurately predicts the Tanimoto similarity\nat all confidence deciles. Each pair of bars compares the true mean Tanimoto similarities\nwith the predicted similarities grouped by decile bins of the predictions. The slight optimism\nin the confidence model is due to the difference in domain between the confidence model\ntraining set and EnvedaDark.c) The relative importance of features used in the confidence\nmodel using permutation importance. If the feature name has a (C), that indicates that\nthe feature is calculated from the predicted structure. “Diff” represents a difference between\ncalculated and observed, or in the case where there is no direct observation, the property\nvalue predicted using the property prediction model. “Diff squared” is the square difference\nof the calculated and the observed/predicted properties. The top features are dominated by\nmass difference features, showing that models that are able to predict structures with higher\nmass fidelity are a promising avenue for future research. For a full description of the features\nused in the confidence model, see Section 4 and the Appendix.\n13\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nlibrary search intended to assign known structures to unknown spectra. In this section, we\nreverse the above scenario to ask how well MS2Mol performs on spectra from known molecules\ndespite the fact that MS2Mol does not benefit from the reduction in search space afforded\nby limiting the search to structures contained in compound databases. This is a challenge\nsetting, as the model is being evaluated outside of its intended use case.\nWe evaluate MS2Mol, CSI:FingerID and Modified Cosine spectral reference search on two\nevaluation sets. The first is the CASMI 2022 data set [18]. For the second evaluation set\nof known molecules, we created an additional test set that we call EnvedaLight, comprised\nof 1856 spectra from 454 molecules profiled in our own lab whose structures are available\nin standard molecular databases, but whose spectra are not contained in spectral reference\nlibraries. The results are summarized in Table 1.\nOn both test sets, CSI:FingerID outperforms MS2Mol at retrieving the exact match: 13%\nto 9% and 11% to 2% for CASMI and EnvedaLight, respectively. This is an expected\nresult, as CSI:FingerID is a database retrieval method evaluated on molecules known to be\nin its database. What is perhaps surprising, however, is that the results are more mixed\nwhen considering similarity thresholds rather than exact match. On CASMI, MS2Mol and\nCSI:FingerID are essentially equal on close-match accuracy for all top-k, while MS2Mol\noutperforms CSI:FingerId for meaningful-match accuracy. On the EnvedaLight test set,\nMS2Mol outperforms CSI:FingerID and modified cosine similarity on close-match accuracy\nfor all k >= 2 both with and without training on any internal data. When training on\nin-domain data, MS2Mol outperforms by at least 6 points across allk values.\nThus, when considering heterogeneous complex samples containing both known and unknown\nmolecules, use of database retrieval andde novo methods may hinge on the application:\nknown molecules will be better annotated with the exactly-correct structure using database\nretrieval, with unknown molecules better annotatedde novo. In this way they can be\nconsidered complementary. However, the relative comparability of performance at close-\nmatch and meaningfully-similar threshold accuracy raises the intriguing possibility thatde\nnovo methods may perform well as a single model on heterogeneous samples in applications\nwhere close-match accuracy is sufficient.\n3 Conclusion\nHere we have presented MS2Mol, a end-to-end molecular structure prediction model that\naccurately predicts chemical structures directly from MS/MS spectra. Importantly, it is a\ntrue generative,de novostructure prediction model that does not rely on compounds existing\nin any database of known or proposed structures.\nFor the first time to our knowledge, we systematically benchmark performance on the task\nof predicting structures of unknown molecules whose structures are not found in common\ndatabases. We demonstrate that MS2Mol outperforms current methods by a wide margin,\nindicating thatde novomethods can be powerful additions to search methods. We note that\nwhile our results are promising, structure elucidation is far from solved.\nThere is significant room for improvement, particularly at predicting exact structures. We\n14\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nEnvedaLight\nModel MM@1 MM@10 MM@25CM@1 CM@10 CM@25EM@1 EM@10 EM@25\nMS2Mol 0.73 0.88 0.92 0.37 0.51 0.57 0.02 0.08 0.08\nMS2Mol PA 0.64 0.83 0.87 0.28 0.43 0.48 0.02 0.04 0.05\nCosine 0.15 0.64 0.81 0.02 0.10 0.16 0.01 0.02 0.02\nCSI:FingerID 0.55 0.77 0.82 0.30 0.41 0.47 0.11 0.26 0.32\nCASMI 2022\nMS2Mol 0.64 0.81 0.85 0.36 0.48 0.52 0.09 0.12 0.13\nMS2Mol PA 0.63 0.79 0.83 0.29 0.43 0.49 0.07 0.10 0.10\nCosine 0.45 0.66 0.73 0.24 0.37 0.41 0.07 0.08 0.08\nCSI:FingerID 0.58 0.71 0.75 0.35 0.48 0.53 0.13 0.29 0.32\nEnvedaDark\nMS2Mol 0.62 0.83 0.88 0.21 0.32 0.37 0.02 0.02 0.02\nMS2Mol PA 0.52 0.75 0.80 0.15 0.26 0.30 0.01 0.01 0.01\nCosine 0.31 0.61 0.73 0.07 0.13 0.17 0.00 0.00 0.00\nCSI:FingerID 0.43 0.69 0.75 0.11 0.19 0.21 0.00 0.00 0.00\nTable 1: Evaluation of MS2Mol and other methods on all test sets. MS2Mol PA denotes\nMS2Mol trained only on publicly available (ie not including internally-generated spectra),\nand all other models are as described in the text. The results are for the metrics “Meaningful\nMatch” (MM), “Close Match” (CM) and “Exact Match” (EM) as described in the text. All\nmetrics are assessed according to the best of a list of retrieved candidates for list lengths\n(1, 10, 25). On all test sets, MS2Mol and MS2Mol PA outperform for meaningful matches\n(MM), even when compared to molecules with known chemical structures. For close match\nstructures, both variants of MS2Mol perform comparably to methods designed for known\nchemical space, and outperform substantially on dark chemical space. On known molecules\nCSI:FingerID outperforms on exact match prediction. On dark chemical space, the intended\napplication domain of MS2Mol, MS2Mol outperforms all competitive methods for top-k\naccuracy for all metrics, even without in-domain training data.\n15\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nnote that, when considering that dark chemical space in the natural world is orders of\nmagnitude larger than known molecules or spectral reference libraries, even a modest rate of\npredicting dark space molecules with high confidence can have a very large impact on the\ntotal number of molecules that can be identified.\nMS2Mol can be improved in many ways. The most promising avenue is to scale up data using\nboth experimentally-generated spectra and synthetic data. Improvements to the accuracy\nand particularly the scalability ofin silicospectrum prediction models may well enable future\ntraining on orders of magnitude more synthetic spectra [42,43]. In this work we did not explore\npretraining on chemical structures as other methods have, but that remains a promising\npossibility. The presence of large repositories of unannotated spectra like GNPS raises the\npossibility of making use of unlabeled spectra as well. Finally, mass errors in the generated\nmolecules are an obvious prediction failure mode, and training or decoding approaches that\nincorporate mass knowledge more intelligently may improve upon the performance of the\nsystem described here.\nBecause mass spectrometry data is highly variable in its processing and chemical space is\ndiverse, comparisons of methods in structure prediction are intrinsically uncertain. A method\nthat performs comparatively well in one benchmarking setting may perform poorly in another,\nreversing rankings. Some methods may be more sensitive to noise in the precursor mass\nmeasurement, or favor settings with more or fewer peaks, or different segments of molecular\nspace. Because of this variance, the performance of a method on real data is often difficult\nto identify prospectively, and continues to depend on use case, data processing choices,\ninstrument precision, and other factors.\nMS2Mol successfully identifies close analogs and exact matches of compounds that have\nnever before been described or stored in major databases. By applying the confidence model,\naccurate annotations can often be identified. Considering that even conservative estimates\nsuggest that most of chemical space is still unknown, MS2Mol is an important step toward\nfurther illuminating the small molecule chemistry of life.\n4 Methods\n4.1 Datasets\nThe makeup of the spectra from publicly available data sources is described in Section 2.1.\nWe compile the CASMI dataset as outlined in Section G. To prepare the data for training\nand evaluation, we process spectra by sorting the peaks by intensity and retaining the top\n256 peaks. We further drop spectra with fewere than five peaks. We normalize structures\nby removing stereochemistry, selecting the largest ion where the smiles included salts, and\nconverting to a canonicalized tautomer for each structure using RDKit.\n16\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\n4.1.1 Experimental settings and MS/MS library acquisition for Analyticon\nlibrary\nPurified natural products were purchased from AnalytiCon Discovery (Potsdam, Germany).\nThe compounds were pooled according to different mass ranges and transferred using a\nHamilton Star liquid handling system to 384 low dead volume (LDV) plates. Samples were\nreconstituted in 50:50 Methanol/Water (v/v) and directly injected from the 384 well plates\ninto the LC-MS/MS system. Method blank and quality control samples were inserted across\nall chromatographic runs.\nThe Waters ACQUITY UPLC system was run with a methanol/water gradient at 30°C\nwith a total run time of 7 minutes using a 1.7µm, 2.1 x 50 mm Waters ACQUITY Premier\nBEH C18 reversed phase column. The timsTOF Pro 2 mass spectrometer (Bruker Daltonics,\nBremen, Germany) was equipped with a VIP-HESI ion source (dry gas temperature 220°C)\nand data was acquired from 20-1300 m/z in positive and negative ionization mode. Tandem\nmass spectra were recorded at three different CID voltages (20, 40, 60 eV).\nThe MS/MS spectra were processed by an in-house developed data processing pipeline. The\nsoftware combines feature finding with AWS Athena and SQL queries across multiple data\nsets in parallel. MS/MS spectra were extracted across multiple adduct ion forms ([M+FA-\nH]-, [M+Cl]-, [M-H]-, [2M-H]-, [2M+FA-H]-, [M-H2O-H]-, [M+Br]-, [M+NH4]+, [2M+H]+,\n[M+H]+, [M+K]+, [M+Na]+, [2M+Na]+, [M-H2O+H]+) and individual microscans per\nMS/MS features were merged and an intensity threshold applied to remove noise peaks.\nMS/MS spectra were then exported as MSP, CSV and in JSON format with associated\nstructures in SMILES and InChiKey, adduct information, ion mode and additional meta data\nsuch as precursor mass error.\nFor the purposes of computing metrics in this paper we restricted to [M-H]-, [M+H]+,\n[M+NH4]+, [M+Na]+, [M+Cl]-, [M+K]+, and [M-H2O+H]+ adducts, which are the standard\nadducts for the SIRIUS software. Spectra were gathered in both positive and negative ion\nmode, at collision energies 20, 40, and 60 eV.\nA subset of 226 of these compounds were not found in the main structural libraries Pubchem\nand COCONUT ([11, 5]. These compounds were used for the evaluation of dark chemical\nspace.\n4.2 CSI:FingerID\nFor all CSI:FingerID results, we used SIRIUS version 5.6.3 (Bright Giant, GmbH, Jena,\nGermany). Query data was prepared as an .mgf file. Each spectrum contained a separate\nentry for MS1 (containing isotope masses and intensities gathered internally through Enveda’s\nfeature calling software) spectra and associated MS/MS spectra. In keeping with all other\nresults, MS/MS spectra were limited to the most intense 256 fragments. Each molecule was\nrepresented by at most one spectrum from each available (collision energy, adduct) pair. Both\npositive and negative ion mode spectra were included. Spectra were evaluated separately, not\nmerged across ion modes, collision energies, or adducts. No timeout was used.\nSIRIUS was set to use DB formulas from the Bio Database only, with all possible default\n17\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nionizations. Instrument was Q-TOF with a MS2 mass accuracy of 10ppm. All other settings\nwere default for batch compute. CSI:FingerID predictions were calculated with Fallback\nadducts including [M-H]-, [M+H]+, [M+NH4]+, [M+Na]+, [M+Cl]-, [M+K]+, and [M-\nH2O+H]+ and search DBs was set to the Bio Database. Spectra for which CSI:FingerID\nreturned no predicted structures were counted as not passing the requisite Tanimoto similarity\nthreshold for the purposes of calculating accuracy.\n4.3 MS2Mol training\nWe use the Hugging Face implementation of the facebook/bart-base model [25, 44]. The\nmodel is trained using the Adam optimizer [45] and teacher forcing [46]. We train the model\nfor 20 epochs with a batch size of 512 and a constant learning rate of 5e-5.\nIn order to avoid biasing the model to predict the structures that are over-represented in\nour dataset (i.e. have many spectra associated with them), we weight each training example\ninversely proportional to the number of times each structure occurs in the training set.\nWhile the precursor m/z provides important signal pertaining to the molecular formula and\nstructure of the underlying compound, early experiments with prepending the precursor m/z\nto the input found that the model can become too reliant on it while ignoring information\ncontained in the fragmentation spectra. We obtained our best results by randomly including\nthe precursor m/z as part of the input 50% of the time and requiring the model to predict\nthe structure without it otherwise. At inference time we always include the precursor m/z as\npart of the input.\nTo tune the hyperparameters of the model, we used random hyperparameter search [47] as\nimplemented in the Ray Tune library [48]. Details of the search space and parameters chosen\nare in the Appendix.\nSee the Appendix for ablation studies on model design and dataset composition.\n4.4 Reranker model training\nThe reranker model is a gradient boosted machine [40] that was trained as a “learning to\nrank” model with a normalized discounted cumulative gain (ndcg) loss [49] using the xgboost\npackage [50]. To train the reranker model, we split the overall MS2Mol training dataset\ninto two structure-disjoint subsets, call them A and B. Set B consisted of publicly available\nspectra corresponding to 11,602 structures and internally-generated spectra corresponding to\n667 structures, for a total of 95,949 spectra. We first trained a version of MS2Mol on set A,\nand then used it to generate structure predictions on set B. Set B was then used to train the\nreranker model. Reranker hyperparameters were selected via 100 iterations of random search,\nusing 5% of set B as a validation set, and the average Tanimoto similarity of the top-ranked\nprediction to the true structure as the validation metric. See the Appendix for further details\nabout this training process.\n18\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\n4.5 Confidence model training\nThe confidence model is likewise a gradient boosted machine [40] that was trained as a\nregression model to predict the Tanimoto similarity between the true structure and the\nMS2Mol prediction. The training set and hyperparameter search space were the same as\nthose used to train the reranker model. See Section F in the Appendix for more details.\n4.6 Inference\nAt inference time we use a beam search decoding strategy with 25 beams, beyond which\nperformance no longer improves. The model outputs a sequence of tokens that represent the\npredicted molecular formula and then the predicted structure. The beam search gives us a\nranked list of 25 possible structures, encoded as BPE tokens of molecular “subwords” [29].\nWe decode these to deepSMILES [51], decode the deepSMILES to SMILES [22], and then use\nRDKit [37] to check if the SMILES strings correspond to valid molecules. We then employ\nthe reranker model to order the 25 candidate structures, throwing out any invalid SMILES\npredictions. The confidence model is then applied to the top-ranked prediction.\nMS2Mol supports additional functionality that we do not evaluate in the main text. When\nthe molecular formula is known at inference time, one can optionally require the beam search\nto output the correct molecular formula. Since each successive output token is conditioned on\nthe previous outputs, this makes the structure prediction conditional on the given molecular\nformula and can improve predictive accuracy. Although we do not utilize this functionality in\nour main results, we do show the effect of formula-conditioned structure prediction in Section\nD of the Appendix.\n5 Acknowledgements\nWe gratefully acknowledge Martin Hoffmann, Marcus Ludwig (Bright Giant GmbH, Jena,\nGermany) and Kai Duhrkop for answering our questions and assisting with benchmarking\nCSI:FingerID. We also acknowledge the Enveda Chemistry team for annotations.\nReferences\n[1] Ricardo R da Silva, Pieter C Dorrestein, and Robert A Quinn. Illuminating the dark\nmatter in metabolomics.Proceedings of the National Academy of Sciences, 112(41):12549–\n12550, 2015.\n[2] Atanas G Atanasov, Sergey B Zotchev, Verena M Dirsch, and Claudiu T Supuran.\nNatural products in drug discovery: advances and opportunities.Nature reviews Drug\ndiscovery, 20(3):200–216, 2021.\n[3] Farit Mochamad Afendi, Taketo Okada, Mami Yamazaki, Aki Hirai-Morita, Yukiko\nNakamura, Kensuke Nakamura, Shun Ikeda, Hiroki Takahashi, Md Altaf-Ul-Amin,\nLatifah K Darusman, et al. Knapsack family databases: integrated metabolite–plant\n19\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nspecies databases for multifaceted plant research.Plant and Cell Physiology, 53(2):e1–e1,\n2012.\n[4] Shiva Abdollahi Aghdam and Amanda May Vivian Brown. Deep learning approaches\nfor natural product discovery from plant endophytic microbiomes. Environmental\nmicrobiome, 16(1):1–20, 2021.\n[5] Maria Sorokina, Peter Merseburger, Kohulan Rajan, Mehmet Aziz Yirik, and Christoph\nSteinbeck. Coconut online: collection of open natural products database.Journal of\nCheminformatics, 13(1):1–13, 2021.\n[6] John J Irwin, Khanh G Tang, Jennifer Young, Chinzorig Dandarchuluun, Benjamin R\nWong, Munkhzul Khurelbaatar, Yurii S Moroz, John Mayfield, and Roger A Sayle.\nZinc20—a free ultralarge-scale chemical database for ligand discovery. Journal of\nchemical information and modeling, 60(12):6065–6073, 2020.\n[7] Mingxun Wang, Jeremy J Carver, Vanessa V Phelan, Laura M Sanchez, Neha Garg,\nYao Peng, Don Duy Nguyen, Jeramie Watrous, Clifford A Kapono, Tal Luzzatto-Knaan,\net al. Sharing and community curation of mass spectrometry data with global natural\nproducts social molecular networking.Nature biotechnology, 34(8):828–837, 2016.\n[8] Florian Huber, Lars Ridder, Stefan Verhoeven, Jurriaan H Spaaks, Faruk Diblen, Simon\nRogers, andJustinJJVanDerHooft. Spec2vec: Improvedmassspectralsimilarityscoring\nthrough learning of structural relationships.PLoS computational biology, 17(2):e1008724,\n2021.\n[9] Florian Huber, Sven van der Burg, Justin JJ van der Hooft, and Lars Ridder.\nMs2deepscore: a novel deep learning similarity measure to compare tandem mass\nspectra. Journal of cheminformatics, 13(1):84, 2021.\n[10] Gennady Voronov, Rose Lightheart, Joe Davison, Christoph A Krettler, David Healey,\nand Thomas Butler. Multi-scale sinusoidal embeddings enable learning on high resolution\nmass spectrometry data.arXiv preprint arXiv:2207.02980, 2022.\n[11] Sunghwan Kim, Paul A Thiessen, Evan E Bolton, Jie Chen, Gang Fu, Asta Gindulyte,\nLianyi Han, Jane He, Siqian He, Benjamin A Shoemaker, et al. Pubchem substance and\ncompound databases. Nucleic acids research, 44(D1):D1202–D1213, 2016.\n[12] Fei Wang, Jaanus Liigand, Siyang Tian, David Arndt, Russell Greiner, and David S\nWishart. Cfm-id 4.0: more accurate esi-ms/ms spectral prediction and compound\nidentification. Analytical chemistry, 93(34):11692–11700, 2021.\n[13] Liu Cao, Mustafa Guler, Azat Tagirdzhanov, Yi-Yuan Lee, Alexey Gurevich, and Hosein\nMohimani. Moldiscovery: learning mass spectrometry fragmentation of small molecules.\nNature Communications, 12(1):1–13, 2021.\n[14] Sebastian Wolf, Stephan Schmidt, Matthias Müller-Hannemann, and Steffen Neumann.\nIn silico fragmentation for computer assisted identification of metabolite mass spectra.\nBMC bioinformatics, 11:1–12, 2010.\n20\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\n[15] Samuel Goldman, John Bradshaw, Jiayi Xin, and Connor W Coley. Prefix-tree decoding\nfor predicting mass spectra from molecules.arXiv preprint arXiv:2303.06470, 2023.\n[16] Samuel Goldman, Janet Li, and Connor W Coley. Generating molecular fragmentation\ngraphs with autoregressive neural networks.arXiv preprint arXiv:2304.13136, 2023.\n[17] Kai Dührkop, Huibin Shen, Marvin Meusel, Juho Rousu, and Sebastian Böcker. Searching\nmolecular structure databases with tandem mass spectra using csi: Fingerid.Proceedings\nof the National Academy of Sciences, 112(41):12580–12585, 2015.\n[18] Oliver Fiehn. Critical Assessment of Small Molecule Identification 2022.http://http:\n//www.casmi-contest.org/2022/index.shtml/, 2022. [Online; accessed 12-December-\n2022].\n[19] Samuel Goldman, Jeremy Wohlwend, Martin Stražar, Guy Haroush, Ramnik J Xavier,\nand Connor W Coley. Annotating metabolite mass spectra with domain-inspired chemical\nformula transformers.bioRxiv, pages 2022–12, 2022.\n[20] Martin A Hoffmann, Louis-Félix Nothias, Marcus Ludwig, Markus Fleischauer, Emily C\nGentry, Michael Witting, Pieter C Dorrestein, Kai Dührkop, and Sebastian Böcker. High-\nconfidence structural annotation of metabolites absent from spectral libraries.Nature\nBiotechnology, 40(3):411–421, 2022.\n[21] Michael A Stravs, Kai Dührkop, Sebastian Böcker, and Nicola Zamboni. Msnovelist: De\nnovo structure generation from mass spectra.Nature Methods, pages 1–6, 2022.\n[22] David Weininger. Smiles, a chemical language and information system. 1. introduction\nto methodology and encoding rules. Journal of chemical information and computer\nsciences, 28(1):31–36, 1988.\n[23] Aditya Divyakant Shrivastava, Neil Swainston, Soumitra Samanta, Ivayla Roberts,\nMarina Wright Muelas, and Douglas B Kell. Massgenie: A transformer-based deep\nlearning method for identifying small molecules from their mass spectra.Biomolecules,\n11(12):1793, 2021.\n[24] Eleni Litsa, Vijil Chenthamarakshan, Payel Das, and Lydia Kavraki. Spec2mol: An\nend-to-end deep learning framework for translating ms/ms spectra to de-novo molecules.\n2021.\n[25] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed,\nOmer Levy, Ves Stoyanov, and Luke Zettlemoyer. Bart: Denoising sequence-to-sequence\npre-training for natural language generation, translation, and comprehension.arXiv\npreprint arXiv:1910.13461, 2019.\n[26] Justin Johan Jozias van Der Hooft, Joe Wandy, Michael P Barrett, Karl EV Burgess, and\nSimon Rogers. Topic modeling for untargeted substructure exploration in metabolomics.\nProceedings of the National Academy of Sciences, 113(48):13738–13743, 2016.\n[27] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N\nGomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need.Advances in\nneural information processing systems, 30, 2017.\n21\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\n[28] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, An-\nthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et al. Transformers:\nState-of-the-art natural language processing. InProceedings of the 2020 conference on\nempirical methods in natural language processing: system demonstrations, pages 38–45,\n2020.\n[29] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare\nwords with subword units. InProceedings of the 54th Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Papers), pages 1715–1725, 2016.\n[30] SS Mehta. Massbank of north america (mona): An open-access, auto-curating mass\nspectral database for compound identification in metabolomics presentation, 2020.\n[31] Yuji Sawada, Ryo Nakabayashi, Yutaka Yamada, Makoto Suzuki, Muneo Sato, Akane\nSakata, Kenji Akiyama, Tetsuya Sakurai, Fumio Matsuda, Toshio Aoki, et al. Riken\ntandem mass spectral database (respect) for phytochemicals: a plant-specific ms/ms-\nbased data resource and database.Phytochemistry, 82:38–45, 2012.\n[32] Hisayuki Horai, Masanori Arita, Shigehiko Kanaya, Yoshito Nihei, Tasuku Ikeda,\nKazuhiro Suwa, Yuya Ojima, Kenichi Tanaka, Satoshi Tanaka, Ken Aoshima, et al.\nMassbank: a public repository for sharing mass spectral data for life sciences.Journal\nof mass spectrometry, 45(7):703–714, 2010.\n[33] Anzor Mikaia, Principal Edward White V EI, Vladimir Zaikin EI, Damo Zhu EI,\nO David Sparkman EI, Pedatsur Neta, Igor Zenkevich RI, Peter Linstrom, Yuri Mirokhin,\nDmitrii Tchekhovskoi, et al. Nist standard reference database 1a.Standard Reference\nData, NIST, Gaithersburg, MD, USA https://www. nist. gov/srd/nist-standard-reference-\ndatabase-1a, 2014.\n[34] Colin A Smith, Grace O’Maille, Elizabeth J Want, Chuan Qin, Sunia A Trauger,\nTheodore R Brandon, Darlene E Custodio, Ruben Abagyan, and Gary Siuzdak. Metlin:\na metabolite mass spectral database.Therapeutic drug monitoring, 27(6):747–751, 2005.\n[35] Adriano Rutz, Maria Sorokina, Jakub Galgonek, Daniel Mietchen, Egon Willighagen,\nArnaud Gaudry, James G Graham, Ralf Stephan, Roderic Page, Jiří Vondrášek, et al.\nThe lotus initiative for open knowledge management in natural products research.Elife,\n11:e70780, 2022.\n[36] Pierre-Marie Allard, Tiphaine Péresse, Jonathan Bisson, Katia Gindro, Laurence Mar-\ncourt, Van Cuong Pham, Fanny Roussi, Marc Litaudon, and Jean-Luc Wolfender.\nIntegration of molecular networking and in-silico ms/ms fragmentation for natural\nproducts dereplication. Analytical chemistry, 88(6):3317–3323, 2016.\n[37] Greg Landrum et al. Rdkit: A software suite for cheminformatics, computational\nchemistry, and predictive modeling.Greg Landrum, 8, 2013.\n[38] Florian Huber, Stefan Verhoeven, Christiaan Meijer, Hanno Spreeuw, Efraín Castilla,\nCunliang Geng, Justin JJ van der Hooft, Simon Rogers, Adam Belloum, Faruk Diblen,\net al. matchms-processing and similarity evaluation of mass spectrometry data.Journal\nof Open Source Software, 5(52), 2020.\n22\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\n[39] Hyun Woo Kim, Mingxun Wang, Christopher A Leber, Louis-Félix Nothias, Raphael\nReher, Kyo Bin Kang, Justin JJ Van Der Hooft, Pieter C Dorrestein, William H\nGerwick, and Garrison W Cottrell. Npclassifier: A deep neural network-based structural\nclassification tool for natural products.Journal of Natural Products, 84(11):2795–2807,\n2021.\n[40] Jerome H Friedman. Greedy function approximation: a gradient boosting machine.\nAnnals of statistics, pages 1189–1232, 2001.\n[41] Leo Breiman. Random forests.Machine learning, 45:5–32, 2001.\n[42] Michael Murphy, Stefanie Jegelka, Ernest Fraenkel, Tobias Kind, David Healey, and\nThomas Butler. Efficiently predicting high resolution mass spectra with graph neural\nnetworks. arXiv preprint arXiv:2301.11419, 2023.\n[43] Christoph A Krettler and Gerhard G Thallinger. A map of mass spectrometry-based in\nsilico fragmentation prediction and compound identification in metabolomics.Briefings\nin Bioinformatics, 22(6):bbab073, 2021.\n[44] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,\nAnthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et al. Hug-\ngingface’s transformers: State-of-the-art natural language processing.arXiv preprint\narXiv:1910.03771, 2019.\n[45] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. 2015.\n[46] Ronald J Williams and David Zipser. A learning algorithm for continually running fully\nrecurrent neural networks.Neural computation, 1(2):270–280, 1989.\n[47] James Bergstra and Yoshua Bengio. Random search for hyper-parameter optimization.\nJournal of machine learning research, 13(2), 2012.\n[48] Richard Liaw, Eric Liang, Robert Nishihara, Philipp Moritz, Joseph E Gonzalez, and Ion\nStoica. Tune: A research platform for distributed model selection and training.arXiv\npreprint arXiv:1807.05118, 2018.\n[49] Kalervo Järvelin and Jaana Kekäläinen. Cumulated gain-based evaluation of ir techniques.\nACM Trans. Inf. Syst., 20(4):422–446, oct 2002.\n[50] Tianqi Chen, Tong He, Michael Benesty, Vadim Khotilovich, Yuan Tang, Hyunsu Cho,\nKailong Chen, Rory Mitchell, Ignacio Cano, Tianyi Zhou, et al. Xgboost: extreme\ngradient boosting. R package version 0.4-2, 1(4):1–4, 2015.\n[51] Noel O’Boyle and Andrew Dalke. Deepsmiles: an adaptation of smiles for use in\nmachine-learning of chemical structures. 2018.\n[52] Philippe Schwaller, Theophile Gaudin, David Lanyi, Costas Bekas, and Teodoro Laino.\n“found in translation”: predicting outcomes of complex organic chemistry reactions using\nneural sequence-to-sequence models.Chemical science, 9(28):6091–6098, 2018.\n[53] Gennady Voronov, Abe Frandsen, Brian Bargh, David Healey, Rose Lightheart, Tobias\nKind, Pieter Dorrestein, Viswa Colluru, and Thomas Butler. Ms2prop: A machine\n23\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nlearning model that directly predicts chemical properties from mass spectrometry data\nfor novel compounds.bioRxiv, pages 2022–10, 2022.\n[54] Yuanyue Li, Tobias Kind, Jacob Folz, Arpana Vaniya, Sajjan Singh Mehta, and Oliver\nFiehn. Spectral entropy outperforms ms/ms dot product similarity for small-molecule\ncompound identification. Nature Methods, 18(12):1524–1531, 2021.\n[55] G Richard Bickerton, Gaia V Paolini, Jérémy Besnard, Sorel Muresan, and Andrew L\nHopkins. Quantifying the chemical beauty of drugs.Nature chemistry, 4(2):90–98, 2012.\n[56] Peter Ertl and Ansgar Schuffenhauer. Estimation of synthetic accessibility score of\ndrug-like molecules based on molecular complexity and fragment contributions.Journal\nof cheminformatics, 1(1):1–11, 2009.\n[57] Steven H Bertz. The first general index of molecular complexity.Journal of the American\nChemical Society, 103(12):3599–3601, 1981.\n[58] Scott A Wildman and Gordon M Crippen. Prediction of physicochemical parameters by\natomic contributions.Journal of chemical information and computer sciences, 39(5):868–\n873, 1999.\nA Datasets and Code Availability\nCode for training and deploying MS2Mol, a version of MS2Mol trained on open data, and the\nEnvedaDark and EnvedaKnown benchmarking datasets will be made publicly available via\ngithub repository at the time of publication. We hope the community will find these datasets\nand the model useful for benchmarking and research purposes.\nB Disclosures\nAll authors except PCD and KJM are employed by Enveda Biosciences, PCD is an advisor\nto Cybele, consulted for MSD animal health in 2023, and he is a Co-founder and scientific\nadvisor for Ometa Labs, Arome, and Enveda with prior approval by UC San Diego. This\nwork is part of Enveda’s drug discovery platform.\nC Ablations\nWe explore the impact of different architecture and dataset designs on MS2Mol. To facilitate\nexperiments, we use the un-reranked MS2Mol model trained on our full training dataset as\nthe baseline, and all ablation models are similarly evaluated without the final reranking step.\nFor each ablation, we evaluate model performance on three test sets and report the fraction\nof predicted structures whose Tanimoto similarity to the correct structure exceeds 0.4 and\n0.675. See Table 2.\n24\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nAblation EnvedaDark EnvedaLight CASMI\nMS2Mol 0.62 / 0.21 0.73 / 0.37 0.64 / 0.36\nMS2Mol_un-reranked 0.64 / 0.19 0.70 / 0.35 0.62 / 0.32\nno_precursor_masking 0.57 / 0.15 0.68 / 0.33 0.57 / 0.27\nfull_precursor_masking 0.58 / 0.20 0.69 / 0.35 0.59 / 0.30\nunweighted_loss 0.62 / 0.17 0.70 / 0.34 0.61 / 0.31\nsingle_m/z_token 0.62 / 0.21 0.71 / 0.35 0.61 / 0.31\nno_formula_prepending 0.58 / 0.22 0.70 / 0.36 0.57 / 0.31\nno_bpe 0.06 / 0.00 0.08 / 0.00 0.09 / 0.02\nno_internal 0.53 / 0.15 0.65 / 0.26 0.63 / 0.30\nno_lotus 0.62 / 0.17 0.69 / 0.35 0.61 / 0.31\nno_lotus_no_internal 0.50 / 0.12 0.63 / 0.26 0.63 / 0.29\nTable 2: MS2Mol ablation evaluations on three test sets. For each ablation and test set,\ntwo numbers are reported: the fraction of predictions with Tanimoto similarity to the true\nstructure greater than 0.4 and 0.675.\nranked vs. un-reranked The top two lines of Table 2 compare MS2Mol with and without\nthe final reranking step. On five out of the six metrics, we see that the reranker provides\nimproved predictions. As mentioned above, each subsequent ablation model is evaluated\nwithout reranking, and so should be compared to MS2Mol_un-reranked.\nno_precursor_masking For this ablation, we set the masking probability of the precursor\nm/z tokens to 0, so that the model can always access these tokens during both training\nand inference. This can potentially lead to the model over-fitting to the precursor m/z or\neven memorizing which structure in the training set is associated with a given m/z. Such\nover-fitting is especially problematic when the test set contains novel compounds that have\nsimilar masses to compounds in the training set. Indeed, we see that this ablation performs\nuniformly worse than the baseline on our evaluation sets.\nfull_precursor_masking Here we set the masking probability of the precursor m/z\ntokens to 1 for both training and inference, so that the model never has access to these tokens,\nand must predict the structure entirely from the MS/MS spectrum peaks. One would expect\nthis to negatively impact model performance, since the precursor m/z is a key attribute of\nthe structure. On the other hand, the precursor m/z can show up as a peak in the MS/MS\nspectrum, and so is sometimes redundant. We observe that fully masking the precursor m/z\nnegatively impacts model performance on all metrics except for the 0.675 Tanimoto similarity\nthreshold for EnvedaDark and EnvedaLight. This suggests that the baseline model may still\nbe somewhat over-fitting to the precursor m/z, which is especially impactful when trying to\nidentify truly novel compounds that aren’t found in the training set. Note also that fully\nmasking out the precursor m/z leads to uniformly better performance than never masking it\nduring training.\n25\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nunweighted_loss The baseline MS2Mol model weights the training loss for each MS/MS\nspectrum in the training set according to the inverse frequency of its molecular structure in\nthe training set, which is a common technique for addressing class imbalance in prediction\ntasks. For this ablation, we weight the training loss for each spectrum equally, thereby\nallowing highly-represented compounds in the training set to exert more influence on the\nmodel updates during training. We observe that this unweighted loss function leads to a\nmodel with slightly worse performance than the baseline, confirming that addressing class\nimbalance in the training set is beneficial.\nsingle_m/z_token In this ablation, we represent each m/z (including the precursor m/z\nand the MS/MS peaks) with a single token corresponding to its value rounded to a single\ndecimal place. By contrast, the baseline MS2Mol model represents each m/z value with two\ntokens, one for its integer part and one for its fractional part. The single-token representation\nleads to a larger vocabulary and potentially sparser coverage for each token in the training\nset: for example, there may be only a handful of MS/MS spectra containing a rounded m/z\nof 513.3, which may hinder the model’s ability to learn a robust embedding for this token.\nOn the other hand, a single token representation does reduce the sequence length for the\nMS/MS spectra, which can improve computational speed. We didn’t observe meaningful\ncomputational performance differences between the two tokenization schemes. However,\nthe single-token representation does lead to slightly better performance compared to the\nbaseline for 2 out of the 6 reported metrics. The optimal way to represent MS/MS spectra in\ntransformer models remains an interesting open problem.\nno_formula_prepending For this ablation, we remove the molecular formula tokens\nfrom the label sequence during training. This means the training signal is derived only from\nthe (tokenized) SMILES strings rather than from both the molecular formulas and SMILES\nstrings. Removing the molecular formula label also precludes molecular-formula-conditional\ninference, as discussed in Section D. It’s not clear a priori whether including the molecular\nformula in the label at train time will benefit model performance beyond enabling conditional\ninference. On the one hand, predicting the molecular formula is an easier task than predicting\nthe full molecular structure, and a common intermediate step when trying to elucidate the\nstructure, so guiding the model to first predict the formula and then further predict the\nfull SMILES string is somewhat natural. On the other hand, it’s also sensible to align the\ntraining process as closely as possible with the inference task, which in this case is simply\nstructure prediction. We observe that removing the molecular formula tokens from the\ntraining labels improves model performance on 2 out of the 6 reported metrics. This suggests\nthat either choice is viable, but as we elaborate in Section D, our baseline MS2Mol design\nenables additional functionality that can be beneficial in certain scenarios.\nno_bpe It has become standard practice in NLP and beyond to employ byte-pair encoding\n(BPE) and related tokenization schemes in conjunction with transformer models, as we do in\nour MS2Mol model. For this ablation, we remove the BPE step and represent the SMILES\nstrings as simple single-atom token sequences. In particular, we split each SMILES string\nusing a simple regular expression given in [52]. We do not convert the SMILES strings to\n26\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\ndeepSMILES in this case. We find that omitting BPE causes a drastic drop in performance.\nIn many cases, no valid SMILES strings are generated, and in the other cases, they are usually\nnot structurally similar to the true compound. We leave it to future work to investigate what\ndrives this difference.\nno_internal In this ablation, we remove the 33,634 internally-generated spectra from the\ntraining set. As expected, this significantly degrades model performance on EnvedaDark\nand EnvedaLight, both of which are composed of similarly internally-generated spectra.\nFor CASMI, the close-match accuracy is higher when training on internal data. These\nresults confirm the intuitive point that the model performs better for spectra that have\nexperimentally-similar examples in the training set. Note that the 33,634 internal spectra\nwe include are only a small fraction of the entire training set, but the model is still able to\neffectively learn how to generalize on these spectra while not compromising performance on\nunrelated test sets like CASMI.\nno_lotus Similar to the no_internal ablation, here we remove the in-silico LOTUS spectra\nfrom the training set. Since these spectra are not experimental, we don’t expect them to be\nvery spectrally similar to the test sets. Rather, the likely benefit of the LOTUS spectra is\nto increase the chemical representation in the training set and enable the model to learn to\ngenerate a larger diversity of compounds. We find that omitting LOTUS indeed degrades\nmodel performance slightly across the board.\nno_lotus_no_internal This ablation simply excludes both the in-silico LOTUS spectra\nand the internal-generated experimental spectra from the training set. In other words, this\nmodel is trained only on publicly and commercially available experimental MS/MS spectra.\nWe see that this model performs worse by a decent margin compared to the baseline on five\nout of six metrics. When comparing this model to the no_internal model, we see that it\nperforms somewhat worse on all evaluation sets, particularly EnvedaDark. This shows the\nbenefit of using in-silico spectra to augment the training set, especially when the test set is\nquite different from the experimental train set structurally and experimentally.\nD Molecular formula conditioning\nIn many cases, it is possible to accurately predict the molecular formula for a given MS/MS\nspectrum. MS2Mol can utilize this partial information by generating a SMILES string\nconditioned on both the MS/MS spectrum and the molecular formula. This functionality is\npossible due to our inclusion of the molecular formula tokens in the label sequence during\ntraining along with the autoregressive generation process of transformer models. Table 3\nshows the results of conditioning MS2Mol predictions on the true molecular formula. Such\nconditional generation leads to significantly more accurate predictions across the board. We\nemphasize that in this experiment, we are using the true molecular formula. In practice, one\nmust first predict the molecular formula, and conditioning on inaccurate formula predictions\ncan degrade the structure predictions.\n27\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nTrue Formula Conditioning EnvedaDark EnvedaLight CASMI\nno 0.64 / 0.19 0.70 / 0.35 0.62 / 0.32\nyes 0.70 / 0.23 0.75 / 0.43 0.68 / 0.36\nTable 3: Benefit of conditioning MS2Mol predictions on ground truth molecular formulas. For\neach test set, two numbers are reported: the fraction of predictions with Tanimoto similarity\nto the true structure greater than 0.4 and 0.675.\nParameter Selected value Candidate range\nmax_input_peaks 256 [64, 128, 256]\nstructure_bpe_vocab 256 [64, 128, 256]\nlearning_rate 2.82 × 10−4 [10−5 - 10−3]\nweight_decay 0.0 [0.0, 0.01, 0.1]\nbatch_size 1024 [512, 1024]\nd_model 768 [384, 768]\nencoder_layers 6 [3, 6]\ndecoder_layers 3 [3, 6]\nencoder_ffn_dim 3072 [512, 1024, 3072]\ndecoder_ffn_dim 3072 [512, 1024, 3072]\nencoder_attn_heads 12 [6, 12]\ndecoder_attn_heads 6 [6, 12]\ndropout 0.2 [0.1, 0.15, 0.2]\nTable 4: Hyperparameters and hyperparameter search space for the main model.\nE Hyperparameters\nThe architecture of our model is taken from the NLP literature. However, the domain\nof MS/MS spectra and molecular structures is significantly different from that of natural\nlanguage. As such, it is necessary to adapt the model hyperparameters to our task. While\nthere are many potential hyperparameters to tune in the BART model, we considered the\nsearch space shown in Table 4, which also lists the selected parameters. The algorithm used\nfor hyperparmeter search is described in Section 4.\nF Reranker and confidence models\nThe reranker and confidence models utilize a suite of features derived from the MS2Mol\nprediction and model outputs, the original input MS/MS spectrum, as well as structural\nproperty predictions calculated directly from the MS/MS spectrum as in [53].\nThe features based on MS2Mol model outputs are as follows:\n• log probability of the generated sequence\n28\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\n• beam rank of the predicted structure\n• length of predicted SMILES string\n• molecular weight of predicted structure\nThe features based on the input MS/MS spectrum are as follows:\n• difference and squared difference between the experimental precursor m/z and the mass\nof the predicted structure, and whether this difference matches a known adduct\n• spectral entropy of the MS/MS spectrum [54]\n• number of peaks in the MS/MS spectrum\nIn addition to the above features, we also make use of a separate model from [53] that\naccurately and directly predicts molecular properties (but not the full molecular structure)\nfrom the MS/MS spectrum. We emphasize that the property prediction model used here\nwas trained solely on publicly and commercially available data, and never had access to\ninternally-generated data. This property prediction model can often produce predictions\nquite close to the corresponding properties of the ground-truth molecule, and so it provides a\nvaluable indication of the accuracy of the MS2Mol structure prediction. To utilize this fact,\nwe include as features the difference and squared difference between the MS2Mol structure\nprediction value and the directly-predicted value, along with the raw MS2Mol structure\nprediction value, for the following properties:\n• polar surface area\n• quantitative estimate of drug likeness [55]\n• synthetic accessibility score [56]\n• BertzCT complexity [57]\n• atomic logP [58]\n• number of hydrogen bond acceptors\n• fraction of sp3 hybridized carbons\n• number of hetero atoms\n• number of rotatable bonds\n• number of aliphatic rings\n• number of aromatic rings\nTo train the confidence and reranker models, we used the hyperparameters and search space\ndefined in Table 5. Hyperparameters for the confidence model were evaluated by the chosen\neval_metric while the reranking model hyperparameters were evaluated by reranking on a\nsmall validation set and measuring the average Tanimoto similarity to ground-truth of the\ntop-ranked predictions. The confidence model was trained with a mean squared error loss\n29\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nParameter Confidence value Reranker value Candidate range\nlearning_rate .1 .01 [.01, .05, .1, .2]\ncolsample_bytree .8 .4 [.1, .2, .4, .6, .8, 1.0]\nmax_depth 12 8 [2,4,8,12,16],\nsubsample .95 .75 [.65,.75,.85,.95]\neval_metric ‘rmse’ ‘mae’ [’mae’, ’rmse’]\nTable 5: Hyperparameters and hyperparameter search space for the confidence and reranker\nmodels.\nwhile the reranker model was trained with a normalized discounted cumulative gain (ndcg)\nloss [49].\nG CASMI dataset preparation\nThe CASMI dataset we use in this work is extracted from CASMI 2022 trial1. The original\ndataset is given as a collection of mzML files containing MS/MS runs collected in both positive\nand negative ionization mode and under three collision energies. For each of 500 selected\ncompounds, the retention time, precursor m/z, and mzML file are given. To extract the\nMS/MS spectrum for a given compound, we search in the specified mzML file for all MS/MS\nspectra whose precursor m/z is within 0.005 Da of the given value and whose retention time\nis within 0.1 minutes of the given value, and then select the matching spectrum with the\nhighest total intensity. These spectra are then further processed in the same way as our other\ndatasets.\nWe also extract the MS1 isotope envelopes for the 500 compounds as follows. For each\ncompound, extract from the specified mzML file the MS1 spectrum corresponding to its\nMS/MS spectrum, then identify the monoisotopic peak by selecting the most intense peak\nwithin a window of 0.05 Da around the given precursor m/z, and finally search for up to three\nadditional isotopic peaks at1 × iso_gap, 2 × iso_gap, and3 × iso_gap Da greater than the\nprecursor m/z (within a tolerance of 0.05 Da), whereiso_gap is 1.003354835 divided by the\ncharge of the precursor ion. These isotopic envelopes are given as input for the CSI:FingerID\nbenchmark on CASMI.\nH Annotation tool for molecular similarity annotations\nand sample annotations\nThe annotation tool for molecular similarity is shown in Figure 5. We also show a sample of\n25 chemist annotations of similarity across diverse molecules and annotation values, including\na couple of random predictions in Figure 5.\n1https://fiehnlab.ucdavis.edu/casmi/casmi-2022-results\n30\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nFigure 5: The annotation tool, including annotation guidelines. Annotations were over\na broad range of molecules, sampled from the large dataset of publicly available spectral\nlibraries.\n31\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nFigure 5: 30 example annotations with 10 randomly sampled from each possible annotation\nscore. Within the columns, ground truth is on the left, the predicted structure is on the right,\nand the Tanimoto similarity is in between.\n32\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nI Tanimoto threshold derivations from Chemist annota-\ntions\nTo arrive at the definitions of “meaningful” match and “close match” from chemist annotations,\nwe scored predictions of chemical structures as a match if\ntanimoto_sim(fppred, fpgroundtruth ) > t (1)\nwhere t is a real number between 0 and 1. Exact matches require agreement between the\nfirst 14 characters of the InChiKeys. Equation 1 can be used to predict the annotations of\nchemists shown above based on Tanimoto similarity.\nTo select the values oft, we chose a threshold where the rate of positive predictions from\nthe similarity threshold model of Equation 1 matches the rate of positive annotations from\nthe chemists. This choice coincides with selecting a threshold where precision and recall are\nequal. This follows from using the values of precision and recall as estimated probabilities,\nPrec = Pr (C = P| ˆC = P) (2)\nRec = Pr ( ˆC = P|C = P) (3)\nwhere C is the true class (positive or negative, e.g. a close match or not as annotated by\nchemists), P indicates positives, andˆC indicates the estimate of the predictor. In this case\nthe prediction is a positive if the similarity of the molecules exceeds the thresholdt. Therefore,\nˆC is a function of the thresholdt. The probabilistic definitions of precision and recall are\nthen connected by Bayes’ theorem,\nPr (C = P| ˆC = P) =Pr ( ˆC = P|C = P)P(C = P)\nP( ˆC = P)\n(4)\nIt then follows immediately from Equation 4 that to match the rate of positive predictions\nfrom the model in Equation 1 to the rate of positive annotations from chemist annotations,\nthe thresholdt must be chosen such that precision and recall are equal.\nWe chose two values of the parametert corresponding to two success criteria (Figure 6). The\nfirst criterion was whether the prediction was likely to be scored as a “3” (Close match). The\nsecond criterion was whether the prediction was likely to be scored as a “2” (meaningfully\nsimilar) or greater. We bootstrapped by annotator, and then by annotation to get estimates\nof error. For the “close match”, or “3” annotation criterion, we selected the precision-recall\ncross over point, rounded to 0.025. The result is the 0.675 threshold reported in the main\ntext.\nFor “meaningful match”, or “2+” annotations, we took a more cautious approach. This is\nbecause for lower thresholds, errors are much more likely to be molecules that would be\nannotated as “1”, or actually misleading (see Figure 6). We therefore dropped all annotators\nwho annotated any random examples as >1, and selected the upper confidence band of the\n95% bootstrap confidence interval as the resulting threshold, and rounded to the nearest 0.1.\nThis provides a conservative estimate of the rate of meaningful matches, while maximally\n33\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\ncriterion threshold precision recall “1” errors\nannotation=3 0.675 0.79 0.81 0.004\nannotation>1 0.4 0.92 0.71 0.08\nTable 6: Metrics for the selected similarity thresholds for meaningful and close match.\nPrecision, recall, and rate of “1” errors, which are the identification of predictions as successes\nthat the annotators label as meaningless or misleading\nsuppressing the particularly impactful error of identifying a prediction as meaningful match\nwhen it is in fact meaningless or actually misleading. Metrics for both thresholds are in Table\n6\nWe finally note that the Tanimoto similarity thresholds for close and meaningful matches\ncannot be directly compared to similarity thresholds for analog search in databases of\nmolecules, even with the same underlying fingerprint. This observation emerges from analyzing\nthe similarities and annotation scores of random pairs of unrelated molecules that were inserted\nas controls in our annotation exercise. As described above, annotators were shown pairs of\nmolecules and asked to rate their similarity as in Figure 5. Approximately 10% of those pairs\nwere random control pairs. We separated the control pairs from the pairs where one of the\npair was a prediction of the other based on MS/MS data. We then analyzed how the average\nannotator rating changed as a function of Tanimoto similarity for both groups. We found\nthat for a given Tanimoto similarity, annotators scored the predictions meaningfully higher\nthan they scored the control pairs (Figure 6). These results suggest that Tanimoto similarity\ndoes not capture all aspects of similarity that are meaningful to practicing chemists and are\ncaptured in the annotations. It also indicates that the similarity thresholds derived in the\npresent article should not be expected to generalize perfectly to other contexts.\n34\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0\nFigure 6: a) Visualization of the precision and recall of Tanimoto similarity based predictions\nof chemist annotations as a function of the Tanimoto threshold. The light colored lines\ncorrespond to the annotator and annotation level bootstrap analysis described in the text,\nwhile the heavy lines correspond to the the primary sample. The vertical lines correspond to\nthe optimal threshold computations as well as the 95% confidence intervals. We select the\nrounded uppper confidence level for the threshold. b) The rate at which annotations scored\nas “1”, or misleading/incorrect occur as a function of Tanimoto similarity threshold. For each\nthreshold, this is the rate at which they are completely incorrect, and score predictions that\nare meaningless as meaningful matches or close matches. By the time the threshold of 0.675,\nfor close match, is reached, this happens at only a very low rate. For meaningful match,\nchoosing the upper confidence band for the threshold brings the error rate for meaningless\nannotations down to below 10%. c) How annotators rate predictions as a function of Tanimoto\nsimilarity, split by whether the prediction came from a prediction technology (non-random), or\nthe prediction is simply an unrelated random structure (random), inserted into the annotation\nas a control. We see that for any given Tanimoto similarity in the range spanned by our data,\nthat the annotators rate the real predictions substantially higher than the random controls.\nThis indicates that the Tanimoto similarity scores of the real predictions to the ground truth\nmolecular structures cannot be simply compared to the similarity scores between random\npairs of molecules. The limited range of similarities on the x-axis is because there were not\nenough high similarity random predictions to extend the analysis to higher similarities.\n35\nhttps://doi.org/10.26434/chemrxiv-2023-vsmpx ORCID: https://orcid.org/0000-0002-9584-9757 Content not peer-reviewed by ChemRxiv. License: CC BY-NC 4.0",
  "topic": "Chemical space",
  "concepts": [
    {
      "name": "Chemical space",
      "score": 0.8555580377578735
    },
    {
      "name": "Bottleneck",
      "score": 0.6385588645935059
    },
    {
      "name": "Benchmarking",
      "score": 0.6062976717948914
    },
    {
      "name": "Computer science",
      "score": 0.5353897213935852
    },
    {
      "name": "Identification (biology)",
      "score": 0.46784743666648865
    },
    {
      "name": "Transformer",
      "score": 0.4449373483657837
    },
    {
      "name": "Mass spectrum",
      "score": 0.4425103962421417
    },
    {
      "name": "Drug discovery",
      "score": 0.44228291511535645
    },
    {
      "name": "Data mining",
      "score": 0.42670485377311707
    },
    {
      "name": "Computational biology",
      "score": 0.3329177796840668
    },
    {
      "name": "Mass spectrometry",
      "score": 0.26703059673309326
    },
    {
      "name": "Chemistry",
      "score": 0.24756169319152832
    },
    {
      "name": "Bioinformatics",
      "score": 0.2287600040435791
    },
    {
      "name": "Physics",
      "score": 0.22065207362174988
    },
    {
      "name": "Biology",
      "score": 0.15056383609771729
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Marketing",
      "score": 0.0
    },
    {
      "name": "Embedded system",
      "score": 0.0
    },
    {
      "name": "Chromatography",
      "score": 0.0
    },
    {
      "name": "Botany",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Business",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210137457",
      "name": "Enveda Therapeutics (United States)",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I36258959",
      "name": "University of California, San Diego",
      "country": "US"
    }
  ]
}