{
    "title": "Unsupervised Domain Adaptation for Remote Sensing Semantic Segmentation with Transformer",
    "url": "https://openalex.org/W4303980685",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2108213129",
            "name": "Weitao Li",
            "affiliations": [
                "University of Electronic Science and Technology of China"
            ]
        },
        {
            "id": "https://openalex.org/A2096256333",
            "name": "Hui Gao",
            "affiliations": [
                "University of Electronic Science and Technology of China"
            ]
        },
        {
            "id": "https://openalex.org/A1969291462",
            "name": "Yi Su",
            "affiliations": [
                "University of Electronic Science and Technology of China"
            ]
        },
        {
            "id": "https://openalex.org/A4303990296",
            "name": "Biffon Manyura Momanyi",
            "affiliations": [
                "University of Electronic Science and Technology of China"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W1903029394",
        "https://openalex.org/W1901129140",
        "https://openalex.org/W2560023338",
        "https://openalex.org/W2964309882",
        "https://openalex.org/W3170841864",
        "https://openalex.org/W6797399245",
        "https://openalex.org/W3200870516",
        "https://openalex.org/W3175294391",
        "https://openalex.org/W3026575546",
        "https://openalex.org/W3035294798",
        "https://openalex.org/W3195315815",
        "https://openalex.org/W2024886312",
        "https://openalex.org/W2151730289",
        "https://openalex.org/W3096831136",
        "https://openalex.org/W2963444790",
        "https://openalex.org/W2962793481",
        "https://openalex.org/W2767657961",
        "https://openalex.org/W2963958441",
        "https://openalex.org/W2963107255",
        "https://openalex.org/W3157967435",
        "https://openalex.org/W4206533855",
        "https://openalex.org/W4293103418",
        "https://openalex.org/W4323316568",
        "https://openalex.org/W2963073217",
        "https://openalex.org/W2895281799",
        "https://openalex.org/W6792004750",
        "https://openalex.org/W3120562181",
        "https://openalex.org/W3120804725",
        "https://openalex.org/W2412782625",
        "https://openalex.org/W3217147624",
        "https://openalex.org/W4307823382",
        "https://openalex.org/W2944223741",
        "https://openalex.org/W3005680577",
        "https://openalex.org/W2562319768",
        "https://openalex.org/W2964285681",
        "https://openalex.org/W1849277567",
        "https://openalex.org/W4229494842",
        "https://openalex.org/W2970971581",
        "https://openalex.org/W2108598243",
        "https://openalex.org/W2962772649",
        "https://openalex.org/W3211490618",
        "https://openalex.org/W3139430233"
    ],
    "abstract": "With the development of deep learning, the performance of image semantic segmentation in remote sensing has been constantly improved. However, the performance usually degrades while testing on different datasets because of the domain gap. To achieve feasible performance, extensive pixel-wise annotations are acquired in a new environment, which is time-consuming and labor-intensive. Therefore, unsupervised domain adaptation (UDA) has been proposed to alleviate the effort of labeling. However, most previous approaches are based on outdated network architectures that hinder the improvement of performance in UDA. Since the effects of recent architectures for UDA have been barely studied, we reveal the potential of Transformer in UDA for remote sensing with a self-training framework. Additionally, two training strategies have been proposed to enhance the performance of UDA: (1) Gradual Class Weights (GCW) to stabilize the model on the source domain by addressing the class-imbalance problem; (2) Local Dynamic Quality (LDQ) to improve the quality of the pseudo-labels via distinguishing the discrete and clustered pseudo-labels on the target domain. Overall, our proposed method improves the state-of-the-art performance by 8.23% mIoU on Potsdam→Vaihingen and 9.2% mIoU on Vaihingen→Potsdam and facilitates learning even for difficult classes such as clutter/background.",
    "full_text": null
}