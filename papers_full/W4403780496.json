{
  "title": "MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models",
  "url": "https://openalex.org/W4403780496",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2333383402",
      "name": "Li Haoxuan",
      "affiliations": [
        "University of Electronic Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A2631847528",
      "name": "Yang Zheng-mao",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2751294225",
      "name": "Ma, Yunshan",
      "affiliations": [
        "National University of Singapore"
      ]
    },
    {
      "id": "https://openalex.org/A2098185351",
      "name": "Bin Yi",
      "affiliations": [
        "National University of Singapore",
        "Tongji University"
      ]
    },
    {
      "id": "https://openalex.org/A2093908790",
      "name": "Yang Yang",
      "affiliations": [
        "University of Electronic Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A3005059581",
      "name": "Chua, Tat-Seng",
      "affiliations": [
        "National University of Singapore"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4361287583",
    "https://openalex.org/W4385895960",
    "https://openalex.org/W6810081322",
    "https://openalex.org/W4396843610",
    "https://openalex.org/W4367046600",
    "https://openalex.org/W4396816283",
    "https://openalex.org/W4385934203",
    "https://openalex.org/W4394862951",
    "https://openalex.org/W3182741322",
    "https://openalex.org/W3118202953",
    "https://openalex.org/W4385562558",
    "https://openalex.org/W4221126228",
    "https://openalex.org/W4252076394",
    "https://openalex.org/W6600339963",
    "https://openalex.org/W3211777899",
    "https://openalex.org/W3153389197",
    "https://openalex.org/W4402683894",
    "https://openalex.org/W4300579117",
    "https://openalex.org/W2950393809",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4312407537",
    "https://openalex.org/W2997585029",
    "https://openalex.org/W4377130690"
  ],
  "abstract": "We study an emerging and intriguing problem of multimodal temporal event forecasting with large language models. Compared to using text or graph modalities, the investigation of utilizing images for temporal event forecasting has not been fully explored, especially in the era of large language models (LLMs). To bridge this gap, we are particularly interested in two key questions of: 1) why images will help in temporal event forecasting, and 2) how to integrate images into the LLM-based forecasting framework. To answer these research questions, we propose to identify two essential functions that images play in the scenario of temporal event forecasting, i.e., highlighting and complementary. Then, we develop a novel framework, named MM-Forecast. It employs an Image Function Identification module to recognize these functions as verbal descriptions using multimodal large language models (MLLMs), and subsequently incorporates these function descriptions into LLM-based forecasting models. To evaluate our approach, we construct a new multimodal dataset, MidEast-TE-mm, by extending an existing event dataset MidEast-TE-mini with images. Empirical studies demonstrate that our MM-Forecast can correctly identify the image functions, and further more, incorporating these verbal function descriptions significantly improves the forecasting performance. The dataset, code, and prompts are available at https://github.com/LuminosityX/MM-Forecast.",
  "full_text": "MM-Forecast: A Multimodal Approach to Temporal Event\nForecasting with Large Language Models\nHaoxuan Li\nUniversity of Electronic Science and\nTechnology of China\nChengdu, China\nlhx980610@gmail.com\nZhengmao Yang\nZhejiang University\nHangzhou, China\nzmyang4671@zju.edu.cn\nYunshan Ma\nNational University of Singapore\nSingapore\nyunshan.ma@u.nus.edu\nYi Bin‚àó\nTongji University\nShanghai, China\nNational University of Singapore\nSingapore\nyi.bin@hotmail.com\nYang Yang\nUniversity of Electronic Science and\nTechnology of China\nChengdu, China\nyang.yang@uestc.edu.cn\nTat-Seng Chua\nNational University of Singapore\nSingapore\ndcscts@nus.edu.sg\nAbstract\nWe study an emerging and intriguing problem of multimodal tem-\nporal event forecasting with large language models. Compared to\nusing text or graph modalities, the investigation of utilizing im-\nages for temporal event forecasting has not been fully explored,\nespecially in the era of large language models (LLMs). To bridge\nthis gap, we are particularly interested in two key questions of: 1)\nwhy images will help in temporal event forecasting, and 2) how to\nintegrate images into the LLM-based forecasting framework. To\nanswer these research questions, we propose to identify two essen-\ntial functions that images play in the scenario of temporal event\nforecasting, i.e., highlighting and complementary . Then, we\ndevelop a novel framework, named MM-Forecast. It employs an\nImage Function Identification module to recognize these functions\nas verbal descriptions using multimodal large language models\n(MLLMs), and subsequently incorporates these function descrip-\ntions into LLM-based forecasting models. To evaluate our approach,\nwe construct a new multimodal dataset, MidEast-TE-mm, by ex-\ntending an existing event dataset MidEast-TE-mini with images.\nEmpirical studies demonstrate that our MM-Forecast can correctly\nidentify the image functions, and further more, incorporating these\nverbal function descriptions significantly improves the forecast-\ning performance. The dataset, code, and prompts are available at\nhttps://github.com/LuminosityX/MM-Forecast.\nCCS Concepts\n‚Ä¢ Information systems ‚ÜíMultimedia and multimodal re-\ntrieval; ‚Ä¢ Computing methodologies ‚ÜíTemporal reasoning.\n‚àóYi Bin is the corresponding author (Email: yi.bin@hotmail.com)\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nMM ‚Äô24, October 28-November 1, 2024, Melbourne, VIC, Australia\n¬© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 979-8-4007-0686-8/24/10\nhttps://doi.org/10.1145/3664647.3681593\nKeywords\nTemporal Event Forecasting, Multimodal Event Forecasting, Multi-\nmodal Large Language Model\nACM Reference Format:\nHaoxuan Li, Zhengmao Yang, Yunshan Ma, Yi Bin, Yang Yang, and Tat-\nSeng Chua. 2024. MM-Forecast: A Multimodal Approach to Temporal Event\nForecasting with Large Language Models. In Proceedings of the 32nd ACM\nInternational Conference on Multimedia (MM ‚Äô24), October 28-November\n1, 2024, Melbourne, VIC, Australia.ACM, New York, NY, USA, 16 pages.\nhttps://doi.org/10.1145/3664647.3681593\n1 Introduction\nTemporal event forecasting aims to predict future events according\nthe observed events in history. The forecasting of critical events,\nsuch as pandemic outbreak, civil unrest, and international con-\nflicts, can help shape policies in advance and minimize potential\nimpacts [50]. Due to its great potential application value, temporal\nevent forecasting [14, 23, 28, 30] has garnered increasing attention\nfrom both the academic and industrial community. Despite promis-\ning progress, current methods have ignored the rich multimodal\ninformation, e.g., images, leaving this an unexplored research gap.\nWith the enormous success of LLMs, an increasing number\nof studies [4, 16, 24, 27, 44, 46, 49] have been exploring LLMs to\ntackle the temporal event forecasting problem. These pioneering\nworks explore the application of LLMs in the task of temporal\nevent forecasting, leveraging techniques such as in-context learning\n(ICL) [16, 49], instruction tuning [27, 44], and retrieval-augmented\ngeneration (RAG) [4, 37]. Compared to LLM-based methods, tradi-\ntional methods have several shortcomings in terms of effectiveness,\nflexibility, and scalability. Specifically, traditional non-LLM meth-\nods [15, 22, 29, 30, 33], whether based on structured or unstruc-\ntured data, typically require large-scale well-annotated datasets.\nMoreover, model selection is often a challenge for these traditional\nmethods due to high computational costs. Additionally, traditional\nmethods generally require separate training for different datasets,\nas a result, they often struggle to make fast adaptationw.r.t.frequent\nchanging in dataset and temporal shifts. Therefore, applying LLMs\nto the task of temporal event forecasting is a worthwhile direction\nto explore [16]. However, all of the existing LLM-based methods\narXiv:2408.04388v1  [cs.MM]  8 Aug 2024\nMM ‚Äô24, October 28-November 1, 2024, Melbourne, VIC, Australia Haoxuan Li et al.\nHamas-led groups committed ‚Äònumerous war crimes‚Äô\nPalestinian militants move towards the border fence with Israel \nfrom Khan Younis in the southern Gaza Strip on October 7.\n‚ÄúAtrocities do not justify atrocities,‚Äù Sawyer said. ‚Äú‚Ä¶‚Ä¶, That‚Äôs in \nthe interests of both Palestinians and Israelis.‚Äù\nHamas-led armed groups committed \n‚Äúnumerous war crimes and crimes against \nhumanity‚Äù against civilians during the ‚Ä¶‚Ä¶\nHighlight\nUkraine faces retreat without US aid, Zelensky says\nThe president said Ukraine‚Äôs options depend on what Congress \ndecides.  ‚ÄúWe can‚Äôt waste time anymore.  Ukraine can‚Äôt be a \npolitical issue between the parties,‚Äù he said.\nUkrainian soldiers fired rockets at Russian troops\nUkrainian forces would have to cede \nfurther territory ‚Ä¶‚Ä¶ to Congress to pass a \nmultibillion-dollar package.\nComplementary\nEnd\nFigure 1: Illustration of our motivation about why images\nwill help in temporal event forecasting. We identify two es-\nsential functions of images, i.e., highlighting and complemen-\ntary. By offering auxiliary highlighting or complementary\ninformation, images enhance the understanding of temporal\nevents, thus boosting the forecasting performance.\nonly consider a single modality, such as text [ 16] or graph [ 27],\nwhile ignoring the prevalent visual modality, i.e., images. Some\nprevious works [19, 20] have justified that images are helpful in\nmultimodal event detection [20] and extraction [21, 41], while none\nof them investigate images‚Äô utility in temporal event forecasting.\nTo bridge this gap, we aim to integrate images into temporal\nevent forecasting and construct multimodal temporal event fore-\ncasting models. However, it is a non-trivial objective due to the\nfollowing challenges. First, it is necessary to clarify the function\nbetween visual information and other modal information, i.e., the\ninterplay between visual and non-visual modalities. Next, we need\nto figure out how the function between two modalities can con-\ntribute to the task of temporal event forecasting. Second, previous\nworks [41] that explores the image function typically require large\namounts of labeled training data. Additionally, images serve differ-\nent functions for different specific tasks, so these methods often\nstruggle to generalize effectively to other task definitions. Therefore,\nthere is a pressing need to design an effective method to identify\nthe function between modalities and seamlessly integrating them\ninto LLM-based forecasting models.\nTo address the aforementioned challenges, we propose a novel\nframework for multimodal temporal event forecasting, named as\nMM-Forecast. Specifically, we identify two essential functions of\nimages, i.e., highlighting and complementary. As illustrated in Fig-\nure 1, when the function of associated image is highlighting, the\nimage plays the role of emphasizing the key events. In contrast,\nwhen the function of associated image is complementary, the image\nprovides supplementary information that complements the textual\ncontent. In order to recognize these two types of functions, we\npropose an Image Function Identification module that is based on\nMultimodal LLMs (MLLMs) due to their superior multimodal under-\nstanding and reasoning capabilities in zero-shot settings [18]. This\nproposed module is designed to recognize the function of images in\nhistorical events, and then transform this information into verbal\ndescriptions that can be seamlessly integrated into the LLM-based\nevent forecasting model. Equipping this Image Function Identifica-\ntion module into the overall framework, we integrate it into two dis-\ntinct LLM-based forecasting models,i.e., one based on the in-context\nlearning (ICL) method [16], and the other based on the retrieval-\naugmented generation (RAG) technique [17]. In order to evaluate\nour approach, we construct an exploratory dataset by incorporating\nimages into an existing dataset MidEast-TE-mini [4]. We name this\nnew dataset MidEast-TE-multimodal (short as MidEast-TE-mm).\nIn the final evaluation, with the enhancement of visual information,\nthe temporal event forecasting task achieves superior forecasting\naccuracy compared to the unimodal approach. The experimental\nresults illustrate that our method accurately recognizes the function\nof images in various aspects. Furthermore, the findings demonstrate\nthat multimodal temporal forecasting represents a potential and\npromising research direction worthy of further exploration. The\nmain contributions are as follows:\n‚Ä¢To the best of our knowledge, this is the first comprehensive study\nof exploring visual information for temporal event forecasting in\nthe era of LLMs.\n‚Ä¢We identify two main functions that images play in temporal\nevent forecasting, and design a framework to recognise and inte-\ngrate visual information into LLM-based forecasting models.\n‚Ä¢Extensive experiments justify that our framework is able to iden-\ntify the functions of images and visual information can enhance\nthe performance of temporal event forecasting. Furthermore,\nthese findings have led to several noteworthy and promising\ndirections for future research.\n2 Related Works\nWe survey the related works of temporal event forecasting and\nLLMs for event analysis.\n2.1 Temporal Event Forecasting\nTemporal event forecasting centers on predicting future event oc-\ncurrences based on historical events, and the typical approaches\ncan be categorized by event format: time series, structured, and\nunstructured events. Regarding the time series paradigm, existing\nworks [2, 23, 31] typically represent events as an ordered sequence\nof data points that describe the progression of actions or occur-\nrences. However, this paradigm inherently fails to represent multi-\nple relationships among entities. Alternatively, another branch of\nworks [8, 15, 22, 29, 33, 36, 38, 45] focus on the prediction of struc-\ntured events, i.e., using graph to represent events, which is known\nas temporal knowledge graph (TKG). Recent works[29, 30] intro-\nduce context into temporal event forecasting models, enhancing\nthe prediction performance by elaborating the event‚Äôs occurrence\nsituation. In addition, several studies have explored the use of un-\nstructured textual representations of temporal events, where each\natomic event is generated from multi-document summaries [ 11]\nor event chains [13]. Nonetheless, all of them design forecasting\nMM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models MM ‚Äô24, October 28-November 1, 2024, Melbourne, VIC, Australia\nmodels relying on single modality data. Some works [ 21, 41] ex-\nplore the image utility in event extraction task, while none of them\ninvestigate images‚Äô utility in temporal event forecasting.\n2.2 LLMs for Event Analysis\nThe tremendous success of LLMs in recent years, exemplified by\nChatGPT and its numerous successors [5, 6, 42, 48], has inspired\nresearchers to explore the application of these powerful models\nto various event-related tasks [4, 7, 16, 24, 46, 49]. One area of re-\nsearch focuses on temporal understanding, where LLMs are tested\nfor the task of temporal event ordering or storyline understand-\ning [32, 47, 51]. More works focus on leveraging LLMs to tackle\nthe typical task of temporal reasoning [ 39, 43], while the task of\nforecasting receives much less attention. Deng et al.[7] surveyed\nthe recent advances in event modeling, ranging from graph neural\nnetworks to LLMs. Specifically, GENTKG [24] improves the selec-\ntion of historical event inputs by a temporal logical rule-based re-\ntrieval strategy. Beyond specific methods, more works are focusing\non benchmarking LLMs‚Äô capability in temporal event forecasting.\nZhang et al.[49] propose a method to evaluate the proficiency of\nLLMs in handling temporal dynamics and understanding extensive\ntext through three distinct tasks. And Ye et al. [46] introduce a\nnovel benchmarking environment designed to rigorously assess\nand advance the capabilities of LLM agents for international event\nforecasting over time. Furthermore, Chang et al.[4] propose a uni-\nfied dataset of structured and unstructured data, and systematically\nevaluates LLM-based methods on the task of text-involved temporal\nevent forecasting. However, these existing LLM-based methods still\nsolely rely on single-modality data, potentially missing valuable\ninformation from other modalities, such as images. With the suc-\ncess of LLMs, MLLMs, such as LLaVA [25], and Gemini [40], have\nemerged as promising means for unifying visual and textual modal-\nities. These MLLMs have demonstrated impressive performance\ngain across various visual-language tasks [ 1, 3, 10, 25], suggest-\ning their potential in the task of temporal event forecasting by\nleveraging visual information.\n3 Our Approach: MM-Forecast\nThe overall framework of our proposed approach is depicted in\nFigure 2. We first formally define the multimodal temporal event\nforecasting task in Section 3.1. Second, we specifically introduce the\nkey module of Image Function Identification in Section 3.2. Finally,\nwe elaborate on how to integrate the recognized image functions\ninto LLM-based forecasting models in Section 3.3.\n3.1 Problem Formulation\nTo give formal definition of the problem, we separate it into two sub-\ntasks given the different representations of historical information.\nStructured Event Forecasting (Graph 1). This formulation de-\nfines each event as a quadruple (ùë†,ùëü,ùëú,ùë° ), which is also called an\natomic event, where ùë†,ùëü,ùëú,ùë° corresponds to the subject, relation2,\nobject, and timestamp. At each timestamp ùë°, all the quadruples\nform an event graph, denoted asùê∫ùë° = {(ùë†,ùëü,ùëú,ùë° )}ùëÅ, where ùëÅ is the\nnumber of events at timestamp ùë°. Recent work[30] introduces the\n1\"Graph\" is interchangeably used to represent this setting.\n2Relation and event type are interchangeably used in this work\nconcept of complex event (CE) into the structured event represen-\ntation by document clustering, elaborating the event‚Äôs occurrence\nsituation or context. Specifically, each atomic event is extended\nfrom a quadruple to a quintuple, i.e., (ùë†,ùëü,ùëú,ùë°,ùëê ), where ùë† ‚àà E,\nùëü ‚ààR , ùëú ‚ààE , and ùëê ‚ààC represent the subject, relation, object,\nand CE, respectively; E, Rand Care the entity set, relation set\nand complex context set. Correspondingly, the event graph at each\ntimestamp will be extended as ùê∫ùë° = {(ùë†,ùëü,ùëú,ùë°,ùëê )}ùëÅ. Furthermore,\nin addition event graph, there are images associated with struc-\ntured events, denoted as ùëâùë° = {ùë£1,ùë£2,...,ùë£ ùëö}ùëÄ\nùëö=1, where ùëÄ is the\nnumber of images at timestamp ùë°. Finally, the structured event\nforecasting task can then be formulated as follows: given the histor-\nical event graphs ùê∫<ùë° = {ùê∫0,ùê∫1,...,ùê∫ ùë°‚àí1}and associated images\nùëâ<ùë° = {ùëâ0,ùëâ1,...,ùëâùë°‚àí1}before timestamp ùë°, and a query (ùë†,ùëü,ùë° )or\n(ùë†,ùëú,ùë° ), the goal is to predict the missing object ùëú or relation ùëü.\nUnstructured Event Forecasting (Text3). In addition to the struc-\ntured event representation, we also consider the unstructured event\nrepresentation, where the historical information is represented in\nthe form of textual sub-events, i.e., ùê¥ùë° = {ùëé1,ùëé2,...,ùëé ùëò}ùêæ\nùëò=1 and\nùê¥ùë° ‚àà A, where ùëéùëò denotes the k-th textual sub-events and A\ndenotes the corpus of textual sub-events. The textual sub-events\nare obtained by summarizing the content of news articles. Similar\nto structured event forecasting, textual sub-events have associ-\nated images, denoted as ùëâ<ùë° = {ùëâ0,ùëâ1,...,ùëâùë°‚àí1}. The unstructured\nevent forecasting task can be formulated as: given the historical\ntextual sub-events ùê¥<ùë° = {ùê¥0,ùê¥1,...,ùê¥ ùë°‚àí1}and associated images\nùëâ<ùë° = {ùëâ0,ùëâ1,...,ùëâùë°‚àí1}before timestamp ùë°, and a query (ùë†,ùëü,ùë° )or\n(ùë†,ùëú,ùë° ), the goal is to predict the missing object ùëú or relation ùë†.\n3.2 Image Function Identification\nIdentifying the function of images in the temporal event forecast-\ning is the key to utilize multimodal visual information. In news\narticles, images play a vital role not only in attracting readers but\nalso in completing and enriching the textual content, especially\nkey event content. We will identify the image functions into three\ncategories, i.e., highlighting, complementary, and irrelevant, during\nthe dataset construction stage. Excluding the irrelevant images, the\nothers serve distinct roles in the temporal event forecasting task. We\npropose an Image Function Identification module to recognize these\nfunctions as verbal descriptions using MLLMs, and subsequently\nincorporate these function descriptions into LLM-based forecasting\nmodels. Specifically, when the function of associated image is high-\nlighting, the visual elements directly support and highlight the key\nsub-events described in the text. These \"highlighting\" sub-events,\nsubstantiated by corroborating information across modalities, can\nbe identified as key events. To determine which sub-event is a key\nevent, we leverage the MLLMs to analyze the images and sub-events\nfrom multiple aspects, including main objects, celebrities, activities,\nenvironment, and labeled items. In cases where the function of\nassociated image is complementary, the visual content contains\ninformation that supplements and extends what is covered in the\nnews text. To more effectively extract the relevant supplementary\ninformation, we consider the following aspects: 1) identify the main\nsubject of the image as the central point, 2) directly relate the ex-\ntracted information to the news event in the article, 3) prioritize the\n3\"Text\" is interchangeably used to represent this setting.\nMM ‚Äô24, October 28-November 1, 2024, Melbourne, VIC, Australia Haoxuan Li et al.\nMLLM\nHighlighting and  Complementary\nùëª ùëΩ\nHistorical Events (Input)\ntext-sub-events associated images\n: highlighting : complementary\nImage Function Identification Temporal Event Forecasting\nUnstructured\n‚Ä¶ ‚Ä¶ ‚Ä¶‚Ä¶ ‚Ä¶\nùíïùüé ùíïùüè ùíïùíå‚àíùüè\n User:\nResponse:\n[Query]: (s, r, ?, t)\n[Key events]:\n[Related events]:\n[Compl events]:\n[Options]:    A. xxx  B. xxx  ‚Ä¶  E. xxx  F.xxx\nB. xxx\nor\nICL RAG\ngraph-sub-events associated images\nStructured\n‚Ä¶ ‚Ä¶ ‚Ä¶‚Ä¶ ‚Ä¶\nùíïùüé ùíïùüè ùíïùíå‚àíùüè\n User:\nResponse:\n[Query]: (s, r, ?, t)\n[Key events]:\n[Related events]:\n[Compl events]:\n[Options]:    A. xxx  B. xxx  ‚Ä¶  E. xxx  F.xxx\nA. xxx\nor\nICL RAG\n: verbal description of the functions\n: highlighting : complementary\n: verbal description of the functions\nFigure 2: The schematic overview of MM-Forecast. By consuming historical events in either format of unstructured or structured\ninput (left), our image function identification module (middle) recognizes the image functions as verbal descriptions, which are\nthen feed into LLM-based forecasting model (right). Our framework is versatile to handle both structured and unstructured\nevents, meanwhile, it is compatible to popular LLM components for event forecasting, i.e., ICL and RAG.\nmost newsworthy visual elements, 4) ensure all information comes\ndirectly from the provided news article without fabrication, and 5)\naim for a concise summary using clear language. By analyzing the\ninterplay between visual images and textual content within news\narticles, we can gain a more comprehensive understanding of the\nunderlying events and better contextualize the temporal evolution\nof historical events. Ultimately, the prompts utilized in making\npredictions are shown below:\nSYSTEM:\nYou are an assistant to perform event forecasting\nwith the following rules:\n1. The atomic event is the basic unit describing a spec-\nific event, typically presented in the form of a quadru-\nple (S, R, O, T), where S represents the subject, R repre-\nsent the relation, O represents the object, and T repres-\nents the relative time.\n2. When formulating the ultimate prediction, the preemi-\nnent factor to be meticulously weighed and scrutinized\nis the [Key Events]. Complementing this paramount consi-\nderation is the [Related events], which, though ancilla-\nry in nature, serves as a valuable adjunct, furnishing\npertinent contextual details and auxiliary insights to\nfortify the predictive analysis.\n3. Given a query of (S, R, T) in the future and the list\nof historical events until t, event forecasting aims to\npredict the missing object.\nUSER:\n[Query]: (S, O/R, T)\n[Key Events]: xxx.\n[Related Events]: xxx.\n[Options]: A.xxx B.xxx C.xxx D.xxx E.xxx\nThe key events are explicitly highlighted within the prompts, while\ncomplementary information is provided as additional relevant events.\n3.3 Forecasting Framework\nGiven there are few established studies of using LLMs for event\nforecasting, we consider two representative approaches, i.e., In-\ncontext Learning (ICL) [16] and Retrieval Augmented Generation\n(RAG) [17]. Each of these two methods can accept both structured\nand unstructured historical input, and answer the structured fore-\ncasting questions.\n3.3.1 In-context Learning (ICL). In-context learning leverages both\nintrinsic and extrinsic factors to construct historical events. Specif-\nically, the intrinsic factors of an event are related to its inherent\nelements, particularly the subject. In contrast, the extrinsic factors\nare driven by the contextual environment surrounding the event.\nTherefore, whether the data is structured or unstructured, we con-\nstruct the historical events based on the subject and the complex\nevent, separately. The details are as follows:\nMM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models MM ‚Äô24, October 28-November 1, 2024, Melbourne, VIC, Australia\n‚Ä¢Structured Data. For structured data, the method takes the dis-\ncrete event graph as the input. To capture the intrinsic factors,\nwe use the subject of the current event as a guiding clue to con-\nstruct the historical event graph Gùë†\n<ùë° = {ùê∫ùë†\n0,ùê∫ùë†\n1,...,ùê∫ ùë†\nùë°‚àí1}, where\nùê∫ùë†\nùë° represents historical events graph at timestamp ùë° with the\nsame subject as the current event. To account for the extrinsic\nfactors, we construct the historical event graph from the complex\nevent, i.e. Gùëê\n<ùë° = {ùê∫ùëê\n0,ùê∫ùëê\n1,...,ùê∫ ùëê\nùë°‚àí1}, where ùê∫ùëê\nùë° represents histor-\nical events graph at timestamp ùë° with the same complex event\nas the current event. Finally, with the highlighting and comple-\nmentary functions of the images, the input historical event graph\nis Gùëñùëõùëùùë¢ùë° = [Gùëò,Gùëü,Gùëê], where Gùëñùëõùëùùë¢ùë° ‚ààGùë†\n<ùë°\n√êGùëê\n<ùë° and Gùëò\ndenotes the key events, Gùëü represents the remaining events, and\nGùëê corresponds to the complementary events, respectively.\n‚Ä¢Unstructured Data. For unstructured data, the method takes\nthe textual sub-events as input. Firstly, we identify the events\nby the historical events graph from the subject and complex\nevent and find the corresponding textual sub-events set Aùë†\n<ùë° =\n{ùê¥ùë†\n0,ùê¥ùë†\n1,...,ùê¥ ùë†\nùë°‚àí1}and Aùëê\n<ùë° = {ùê¥ùëê\n0,ùê¥ùëê\n1,...,ùê¥ ùëê\nùë°‚àí1}through the re-\nlationships between textual sub-events and graph sub-events.\nThen, with the highlighting and complementary functions of\nthe images, the input historical textual sub-events are similarly\nAùëñùëõùëùùë¢ùë° = [Aùëò,Aùëü,Aùëê], where Aùëñùëõùëùùë¢ùë° ‚ààAùë†\n<ùë°\n√êAùëê\n<ùë° and Aùëò de-\nnotes the key events, Aùëü represents the remaining events, and\nAùëê corresponds to the complementary events, respectively.\n3.3.2 Retrieval Augmented Generation (RAG). Despite the rich in-\nformation provided by in-context learning methods, the inherent\nnature of the temporal event means that the existing historical event\nstill contains substantial noise. Inspired by the recent research of\nRAG [17], we also adopt the retrieve-then-generate paradigm to find\nthe most relevant historical events to mitigate the problem of noise.\nSimilar to ICL methods, we utilize two forms of data representation,\nstructured data and unstructured data:\n‚Ä¢Structured Data. Due to the structured nature of the data repre-\nsentation, the event graphs adhered to a unified quintuple format.\nTherefore, we first retrieve the entities that have interacted with\nthe subject of the query event. Once we have obtained the related\nentity set, we can construct the history with the historical events\nwhere the subject or object is within this set. Similarly, through\nthe function of images, the retrieval process also contains key\nevents and complementary events.\n‚Ä¢Unstructured Data. Unlike structured data, we can use the em-\nbedding techniques to directly retrieve relevant news events from\na set of historical news articles for the unstructured data. Follow-\ning this, we filter historical news events based on timestamps,\neliminating outdated and irrelevant events. We also select the key\nevents and complement information based on the images, which\nwill be input according to the prompts described in Section 3.2,\nand finally obtain the prediction results.\n4 Experiments\nWe conduct experiments to evaluate the proposed approach, and\nanswer the following research questions:\n‚Ä¢RQ1: What is the overall performance of temporal event fore-\ncasting methods by including visual information?\n‚Ä¢RQ2: How do the highlighting and complementary functions of\nimages affect the forecasting performance?\n‚Ä¢RQ3: How do different LLM backbones as well as fine-tuning\naffect the performance?\n4.1 Experimental Settings\nWe introduce the experimental settings, including the dataset, the\nmethods compared, and the implementation details.\n4.1.1 Dataset. We build our dataset based on MidEast-TE-mini [4],\nwhich includes structured atomic events and news articles. We\naim to add images that correspond to the events in the dataset,\nhence we will have the data in visual modality. An intuitive way is\nto download the web page according to the URL provided by the\noriginal dataset. However, the original web page always contains\na lot of irrelevant images, such as advertisement images, that are\ncumbersome and difficult to be accurately filtered out. Instead of\ndirectly solving this problem, we propose an alternative solution\nthat we use Google Image Search4 to search the images using the\nnews article title as the query. Among the returned images, we select\nthe top-ranked ones as the associated images of the news article. In\norder to further filter out irrelevant images, we instruct the Gemini-\n1.0-Pro-Vision model to determine the relevance of images to news\narticles. We give three options: highlighting, complementary and\nirrelevant. Highlighting means that the images and the content\nof the news are highly matched, and complementary means that\nthe image has supplementary meaning to the content of the news.\nImages beyond these two are regarded as irrelevant. We further\nremove images that are classified as irrelevant. Finally, we name\nour dataset as MidEast-TE-multimodal, short as MidEast-TE-mm.\n4.1.2 Compared Methods. The compared methods are categorised\ninto non-LLM-based methods and LLM-based methods. For non-\nLLM-based methods, only text or graph modalities are involved,\nsince these methods architecture are fixed. We train the models on\nthe training set, selecting the best-performing model based on the\nvalidation set results, and obtain the final results of the testing set.\nFor LLM-based methods, we use the proprietary LLMs due to their\nsuperior performance compared to open-source LLMs. Therefore,\ntesting is generally done in a zero-shot manner, i.e., directly test\nthem on the testing set. The specific methods are shown below:\n‚Ä¢ConvTransE [36]: This method employs a convolutional neu-\nral network (CNN) and a translational operation to capture the\nrelational patterns within triplet data.\n‚Ä¢RGCN [35]: RGCN leverages a graph convolutional neural net-\nwork (GCN) to capture the diverse relations between entities.\n‚Ä¢RE-GCN [22]: RE-GCN utilizes a combination of GCN and recur-\nrent neural network (RNN) to capture both the relational patterns\nand temporal dynamics.\n‚Ä¢LoGo [ 30]: This method models relationships within and be-\ntween complex events from both local and global perspectives.\n‚Ä¢GPT-3.5-Turbo7: The GPT-3.5-turbo model is the prevalent iter-\nation of the GPT (Generative Pre-trained Transformer) language\nmodel developed by OpenAI5.\n4https://images.google.com/\n5https://openai.com/\nMM ‚Äô24, October 28-November 1, 2024, Melbourne, VIC, Australia Haoxuan Li et al.\nTable 1: Performance (accuracy) comparison between zero-shot LLM-based methods and the non-LLM methods in both\nsettings of object entity prediction and relation prediction. For LLM-based methods, we include multiple backbones with two\nrepresentative forecasting method, i.e., ICL and RAG. Results of our methods are highlighted with grey backgrounds, where the\nkey novelty lies in we leverage images by the Image Function Identification module.\nModel Type/Backbone Forecasting Model Multimodal Model Object Entity Prediction Relation Prediction\nText Graph Text Graph\nNon-LLM\nConvTransE [36] Uni-modal N/A 0.3737 N/A 0.7327\nRGCN [35] Uni-modal N/A 0.3777 N/A 0.7203\nRE-GCN [22] Uni-modal N/A 0.3879 N/A 0.7333\nLoGo [30] Uni-modal N/A 0.3969 N/A 0.7406\nGemini-1.0-Pro-Vision6 ICL [16] MLLM 6 0.3023 0.3319 0.5541 0.6085\nRAG [17] MLLM 6 0.3305 0.3465 0.5769 0.5848\nGemini-1.0-Pro6\nICL [16] Uni-modal 0.3312 0.3657 0.5900 0.6257\nMM-Forecast (ours) 0.3527 0.3837 0.6087 0.6324\nRAG [17] Uni-modal 0.3340 0.3669 0.6081 0.5866\nMM-Forecast (ours) 0.3425 0.3692 0.6121 0.5991\nGPT-3.5-Turbo7\nICL [16] Uni-modal 0.3063 0.3431 0.4847 0.5345\nMM-Forecast (ours) 0.3414 0.3522 0.5317 0.5521\nRAG [17] Uni-modal 0.3272 0.3397 0.4943 0.4666\nMM-Forecast (ours) 0.3652 0.3647 0.5152 0.5113\n‚Ä¢Gemini-1.06: Gemini-1.0 is a cutting-edge family of multimodal\nmodels developed by the Gemini Team at Google.\n4.1.3 Implementation Details. To ensure the reproducibility, we\nfixed the temperature parameter of the proprietary LLMs used to\n0 and set the seed parameter to a constant value. When making\nforecasting, we limit the maximum output token length to 256 to pre-\nvent invalid responses. To ensure fairness across the experiments,\nthe history that can be retrieved is set to 30 days. Notably, the re-\ntrieval models that we employ include: BM25 [34], Contriever [12],\nand LlamaIndex [26]. Additionally, considering the limitation of\nthe context window, we further restrict the maximum number of\nsub-events in the historical context to 50. Following previous meth-\nods [4], we employ the Accuracy (Acc) as the evaluation metric.\n4.2 Performance Comparison (RQ1)\nWe analyze our model‚Äôs performance, by comparing various base-\nline methods on different experimental settings, different input\nforms, and different retrieval models.\n4.2.1 Performance w.r.t.Various Settings. The overall performance\ncomparison is presented in the Table 1. To comprehensively ex-\nplore and evaluate methods, we conduct experiments across multi-\nple dimensions, including the format of data representation (Text\nor Graph), the construction of historical information (RAG-based\nor ICL-based), and the prediction objective (Object or Relation).\nClearly, we have the following observations.\n6https://ai.google.dev/models/gemini\n7https://platform.openai.com/docs/models/gpt-3-5-turbo\nTable 2: The results of using different retrieval models.\nRetriever Gemini-1.0-Pro GPT-3.5-Turbo\nBM25 [34] 0.3272 0.3318\nContriver [12] 0.3335 0.3431\nLlamaIndex [26] 0.3425 0.3652\nFirst, enhancing LLM-based methods with visual information\nconsistently improves their accuracy across all experimental set-\ntings. This demonstrates that our proposed MM-Forecast makes\neffective use of visual information, leading to a better contextual un-\nderstanding of historical information. Hence, our method strength-\nens the inference ability of LLM and makes more accurate event\nforecasting performance.\nSecond, even though the performances of all LLM-based methods\nhave been improved, they still under-perform the traditional Non-\nLLM based methods. The reason is that LLM-based methods are\ntested in zero-shot manner, while the Non-LLM methods, which\nfollow supervised learning, are still competitive. Notably, by using\nour MM-Forecast method, LLM-based methods can achieve close\nor even better performance than Non-LLM methods for the object\nentity prediction task.\nThird, the relation prediction task exhibits higher accuracy com-\npared to the object entity prediction task. This suggests that the\nforecasting of entities is more challenging than relations. There\nare a few potential reasons for this. First, the set of entities (5909)\nis much larger than the set of relation types (267), so predicting\nspecific entities is inherently more difficult given the larger candi-\ndate pool. Second, we deem that the information implied in entities\nis more explicit. Thus when two entities are given for a relation\nMM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models MM ‚Äô24, October 28-November 1, 2024, Melbourne, VIC, Australia\n0.23\n0.26\n0.29\n0.32\n0.35\n0.38\nGPT-3.5-Turbo-Object\n0.44\n0.46\n0.48\n0.5\n0.52\n0.54\n0.56\nGPT-3.5-Turbo-Relation\nbaseline (none) complementary highlighting both (ours)\nFigure 3: Ablation study of each type of image functions.\nprediction, it is easier than when the subject and relation are given\nfor an object prediction.\n4.2.2 Performance w.r.t. Directly Using Images. To illustrate the\nlimitations of existing MLLMs in the task of temporal event forecast-\ning, we also conduct experiments using the Gemini-1.0-Pro-Vsion\nmodel [40] and directly consuming the images in the sub-events.\nSpecifically, this approach leverages the inherent image understand-\ning capabilities of the Gemini-1.0-Pro-Vision model, which embeds\nimage patches as features and seamlessly concatenates thes image\nfeatures with textual features. From Table 1, we can observe that the\naccuracy of using images directly is not only lower than our MM-\nForecast, but also even worse than the method using only textual\ndata (Uni-modal methods). This illustrates that existing proprietary\nMLLMs still struggle to make effective event forecasting with mul-\ntiple images, and reflects the superiority of our MM-Forecast.\n4.2.3 Performance w.r.t. Various Retrieval Models. The choice of\nretrieval model may have a significant impact on forecasting. The\nexperiments here involve only unstructured event forecasting, since\nthe structured approach employs retrieval based on keyword search\ntechniques. To explore the effect of retrieval model, we adopt three\ndifferent retrieval models, i.e., BM25 [34], Contriver [12], and LLa-\nmaIndex [26], then equip them into our forecasting framework,\nand obtain the forecasting results. From the results in Table 2, we\ncan observe that the performance progressively improves by us-\ning stronger retrieval models, with LLamaIndex performing the\nbest, followed by Contriver, and then BM25. These results verify\nthat stronger retrieval capabilities lead to better forecasting per-\nformance, suggesting that retrieval-oriented method design is a\npromising direction for future research. This phenomenon is con-\nsistent with the observation concluded from recent works [4].\n4.3 Study of the Image Functions (RQ2)\n4.3.1 Effects of Image Functions. We conduct ablation experiments\nfor the highlighting and complementary function of images. The\nresults are shown in Figure 3. First, the model that leverages both\nthe highlighting of key events and the complementary information\nperforms the best across the experimental settings. In addition,\nthe performance of the model with only key events highlighted is\nsub-optimal. This illustrates the effectiveness of the highlighting\nTable 3: The accuracy of image function identification.\nData-Type GPT-4-Vision Human\nText Graph Text Graph\nHighlighting 0.68 0.68 0.73 0.83\nComplementary 0.88 0.93 0.87 0.86\nTable 4: Result comparison between using our identified and\nrandomly-assigned image functions.\nModel Settings Object Relation\nText Graph Text Graph\nGPT-3.5-Turbo Random 0.3284 0.3394 0.5156 0.5249\nOurs 0.3414 0.3522 0.5317 0.5521\nfunction of images, and it elicit the fact that highlighting and com-\nplementary reinforce each other to achieve even better prediction\nresults. Second, we can observe that in some settings (Text-ICL, Text-\nRAG), the performances of the model with only complementary\ninformation are even worse than the baseline model. The possible\nreason for this is that the offering of complementary information\nalso introduces more noise and therefore leads the degradation\nof performance. Third, the performance of RAG-based method is\nobviously worse than the ICL-based method in the relation predic-\ntion task, meanwhile, such performance gap does not exist in the\nentity prediction task. This is may because that relation prediction\nis easier than object entity prediction, as mentioned in section 4.2.1.\nAs a result, ICL-based historical events may already contain enough\ninformation to make accurate relation prediction, whereas the re-\ntrieval model may not retrieve relevant information instead.\n4.3.2 Analysis of the Image Function Identification. In addition\nto overall forecasting performance analysis, we conduct in-depth\nstudy to directly assess the efficacy of highlighting and comple-\nmentary function. Specifically, we design additional experiments\nat the data level and prompt level to further verify the function\nof images. At the data level, we randomly sample 100 images of\ntwo categories respectively, and then judge the correctness of the\nclassification by the powerful MLLM GPT-4-Vision 8. As shown in\nTable 3, both classification of highlighting and complementary func-\ntions show high accuracy. Furthermore, we can observe that the\naccuracy of highlighting is lower than that of complementary on all\nsettings, which should be due to its more strict definition. The high\naccuracy of image functions in both LLM and human identification\nindicate that the images we used can indeed play the highlighting\nand complementary functions. In addition to direct assessment of\nthe quality of image function identification, we conduct another\nablation study by replacing our identified functions with randomly\nselected sub-events. Looking into the forecasting results in Table 4,\nrandom selection of sub-events leads to a decrease in forecasting\naccuracy, indicating that correct image function identification is\ncrucial to the forecasting.\n8https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4\nMM ‚Äô24, October 28-November 1, 2024, Melbourne, VIC, Australia Haoxuan Li et al.\nUser:\nResponse:\n[Query]:\n \n[Related events]: ‚Ä¶‚Ä¶.\n[Options]:    A. xxx  B. xxx  ‚Ä¶\nB. xxx\n(Abdel Fattah Al-\nSisi , Makhdoom \nShah Mahmood \nQureshi, 2191)\nBefore Highlighting\nUser:\nResponse:\n[Query]:\n \n[Options]:    A. xxx  B. xxx  ‚Ä¶  E. xxx  F.xxx\nA. Make optimistic comment\n(Abdel Fattah Al-Sisi , Makhdoom Shah \nMahmood Qureshi, 2191)\nAfter Highlighting\n[Key events]: \nQureshi called on President \nAbdel Fattah Al Sisi and \nreiterated Pakistan's desire to \nfurther strengthen and \ndiversify bilateral ties.\nUser:\nResponse:\n[Query]:\n \n[Related events]: ‚Ä¶‚Ä¶.\n[Options]:    A. xxx  B. xxx  ‚Ä¶\nC. xxx\n(Ahmed El Sewedy , \nMakhdoom Shah \nMahmood Qureshi, \n2191)\nBefore Complementary\nUser:\nResponse:\n[Query]:\n \n[Options]:    A. xxx  B. xxx  ‚Ä¶  E. xxx  F.xxx\nE. Host a visit\n(Ahmed El Sewedy , Makhdoom Shah Mahmood \nQureshi, 2191)\nAfter Complementary\n[Related events]: A meeting between \nthe leaders of Pakistan, Iran, and Saudi \nArabia. Pakistani Prime Minister Imran \nKhan meets with Iranian President Hassan \nRouhani and Saudi Arabia's Crown Prince \nMohammed bin Salman to discuss \nregional tensions and promote diplomacy.\nFigure 4: Case study: two examples that when considering highlighting and complementary functions of images, our method\nyields better forecasting results compared with the baselines.\nFinally, on top of quantitative evaluation, we conduct qualitative\nanalysis and demonstrate two examples in Figure 4. The first image\nemphasizes the event of Makhdoom Shah Mahmood Qureshi‚Äôs visit\nto Abdel Fattah Al-Sisi, highlighting their efforts to strengthen and\ndiversify bilateral relations. This highlighting function leads to a\ncorrect prediction of the event type. The second image provides\nsupplementary information about the meeting between the two\npoliticians, enabling an accurate prediction of the question.\n4.4 Performance on Open-source and\nFine-tuned LLMs (RQ3)\nAll of the above LLM-based forecasting backbones are implemented\nusing proprietary LLMs in the zero-shot manner without any fine-\ntuning. We are interested in how our method performs on open-\nsource LLMs, especially finetuned open-source LLMs. Addressing\nthis intriguing question, we select one of the most popular open-\nsource LLMs, i.e., Vicuna-7b, to replace the forecasting backbone\nLLM in our framework, with both zero-shot manner and fine-tune\nfollowing typical instruction tuning with QLoRA [9]. The results\nof object entity prediction are presented in Table 5, which also in-\ncludes the best results for proprietary LLMs and non-LLM methods.\nWe observe that the zero-shot performance of Vicuna-7B is worse\nthan its corresponding performance on proprietary LLMs, owing to\nthe inherent capacity gap. However, after fine-tuning, Vicuna-7B\nachieves substantial performance gains, not only surpassing the\nproprietary LLMs but also outperforming all the non-LLM methods.\nIn addition to fine-tuning the LLMs on object entity prediction,\nwe also fine-tuning on the relation prediction task, as shown in\nTable 6. In both the text and the graph settings, the relation predic-\ntion results are consistent with the entity prediction,i.e., fine-tuned\nLLMs achieve the best performance. These results demonstrate the\nsignificant potential of fine-tuning LLMs for the temporal event\nforecasting task.\n5 Conclusion and Future Work\nIn this paper, we studied an emerging and interesting problem of\nmultimodal temporal event forecasting. We identified two essen-\ntial image functions in the scenario of temporal event forecasting,\ni.e., highlighting and complementary. Then, we introduced MM-\nForecast, a novel framework that leverages visual information to\nTable 5: Performance of fine-tuned LLMs and its comparison\nwith proprietary LLMs and non-LLM methods.\nModel Vicuna-7b LLM Non-LLM\nzero-shot MM-Forecast-text-h 0.2723 0.3527 N/A\nMM-Forecast-graph-h 0.2502 0.3837 N/A\nfine-tune MM-Forecast-text-h 0.4490 N/A N/A\nMM-Forecast-graph-h 0.5480 N/A 0.3969\nTable 6: Performance of FT LLMs on the relation prediction.\nModel Vicuna-7b LLM Non-LLM\nMM-Forecast-text-h 0.7809 0.6087 N/A\nMM-Forecast-graph-h 0.7901 0.6324 0.7406\nenhance temporal event forecasting. By recognizing the highlight-\ning and complementary functions of images and translating them\ninto verbal descriptions, we were able to seamlessly integrate this\nvisual information into LLM-based forecasting models. Ultimately,\nthis enabled the integration of visual information to enhance tem-\nporal event forecasting task.\nLooking ahead, there are numerous avenues for future work to\naddress the key challenges. In particular, we would like to high-\nlight three distinct aspects that warrant further exploration. First,\nmulti-images relationship need to be considered. There are inher-\nent relationships between images in related historical events, and\nthese relationships are also important for event forecasting. Second,\nseeing is believing. Images have significant effects on the event\nforecasting task rather than accuracy improvement, that is credibil-\nity or trustability. Third, our current solution is still a multi-step\npipeline, while devising an end-to-end approach using MLLMs is\nintriguing to explore in the future.\nAcknowledgments\nThis work is partially supported by the National Natural Science\nFoundation of China under grant 62220106008, U20B2063 and 62102070.\nThis work is also partially supported by Sichuan Science and Tech-\nnology Program under grant 2023NSFSC1392. This research is also\nsupported by Asian Institute of Digital Finance and NExT Research\nCenter.\nMM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models MM ‚Äô24, October 28-November 1, 2024, Melbourne, VIC, Australia\nReferences\n[1] Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana\nHasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, et al.\n2022. Flamingo: a visual language model for few-shot learning. In NeurIPS.\n[2] Daniel M Benjamin, Fred Morstatter, Ali E Abbas, Andres Abeliuk, Pavel Atanasov,\nStephen Bennett, Andreas Beger, Saurabh Birari, David V Budescu, Michele\nCatasta, et al . 2023. Hybrid forecasting of geopolitical events. AI Magazine\n(2023).\n[3] Yi Bin, Haoxuan Li, Yahui Xu, Xing Xu, Yang Yang, and Heng Tao Shen. 2023.\nUnifying two-stream encoders with transformers for cross-modal retrieval. In\nProceedings of the 31st ACM International Conference on Multimedia. 3041‚Äì3050.\n[4] He Chang, Chenchen Ye, Zhulin Tao, Jie Wu, Zhengmao Yang, Yunshan Ma,\nXianglin Huang, and Tat-Seng Chua. 2024. A Comprehensive Evaluation of Large\nLanguage Models on Temporal Event Forecasting.arXiv preprint arXiv:2407.11638\n(2024).\n[5] Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang,\nLianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica,\nand Eric P. Xing. 2023. Vicuna: An Open-Source Chatbot Impressing GPT-4 with\n90%* ChatGPT Quality. https://lmsys.org/blog/2023-03-30-vicuna/\n[6] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav\nMishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Se-\nbastian Gehrmann, et al. 2023. Palm: Scaling language modeling with pathways.\nJournal of Machine Learning Research24, 240 (2023), 1‚Äì113.\n[7] Songgaojun Deng, Maarten de Rijke, and Yue Ning. 2024. Advances in Human\nEvent Modeling: From Graph Neural Networks to Language Models. (2024).\n[8] Tim Dettmers, Pasquale Minervini, Pontus Stenetorp, and Sebastian Riedel. 2018.\nConvolutional 2D Knowledge Graph Embeddings. In AAAI. AAAI Press, 1811‚Äì\n1818.\n[9] Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. 2023.\nQLoRA: Efficient Finetuning of Quantized LLMs. CoRR abs/2305.14314 (2023).\n[10] Yujuan Ding, Yunshan Ma, Wenqi Fan, Yige Yao, Tat-Seng Chua, and Qing Li.\n2024. Fashionregen: Llm-empowered fashion report generation. In Companion\nProceedings of the ACM on Web Conference 2024. 991‚Äì994.\n[11] Demian Gholipour Ghalandari, Chris Hokamp, Nghia The Pham, John Glover, and\nGeorgiana Ifrim. 2020. A Large-Scale Multi-Document Summarization Dataset\nfrom the Wikipedia Current Events Portal. In Proceedings of the 58th Annual\nMeeting of the Association for Computational Linguistics, Dan Jurafsky, Joyce\nChai, Natalie Schluter, and Joel Tetreault (Eds.). Association for Computational\nLinguistics, Online, 1302‚Äì1308. https://doi.org/10.18653/v1/2020.acl-main.120\n[12] Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bo-\njanowski, Armand Joulin, and Edouard Grave. 2021. Unsupervised dense in-\nformation retrieval with contrastive learning. arXiv preprint arXiv:2112.09118\n(2021).\n[13] Yizhu Jiao, Ming Zhong, Jiaming Shen, Yunyi Zhang, Chao Zhang, and Jiawei\nHan. 2023. Unsupervised Event Chain Mining from Multiple Documents. In\nWWW. ACM, 1948‚Äì1959.\n[14] Woojeong Jin, Rahul Khanna, Suji Kim, Dong-Ho Lee, Fred Morstatter, Aram\nGalstyan, and Xiang Ren. 2021. ForecastQA: A Question Answering Challenge\nfor Event Forecasting with Temporal Text Data. In ACL/IJCNLP (1). Association\nfor Computational Linguistics, 4636‚Äì4650.\n[15] Woojeong Jin, Meng Qu, Xisen Jin, and Xiang Ren. 2020. Recurrent Event\nNetwork: Autoregressive Structure Inferenceover Temporal Knowledge Graphs.\nIn EMNLP (1). Association for Computational Linguistics, 6669‚Äì6683.\n[16] Dong-Ho Lee, Kian Ahrabian, Woojeong Jin, Fred Morstatter, and Jay Pujara. 2023.\nTemporal Knowledge Graph Forecasting Without Knowledge Using In-Context\nLearning. In EMNLP. Association for Computational Linguistics, 544‚Äì557.\n[17] Patrick S. H. Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir\nKarpukhin, Naman Goyal, Heinrich K√ºttler, Mike Lewis, Wen-tau Yih, Tim Rock-\nt√§schel, Sebastian Riedel, and Douwe Kiela. 2020. Retrieval-Augmented Genera-\ntion for Knowledge-Intensive NLP Tasks. In NeurIPS.\n[18] Chunyuan Li, Zhe Gan, Zhengyuan Yang, Jianwei Yang, Linjie Li, Lijuan Wang,\nJianfeng Gao, et al. 2024. Multimodal foundation models: From specialists to\ngeneral-purpose assistants. Foundations and Trends¬Æ in Computer Graphics and\nVision 16, 1-2 (2024), 1‚Äì214.\n[19] Haoxuan Li, Yi Bin, Junrong Liao, Yang Yang, and Heng Tao Shen. 2023. Your\nnegative may not be true negative: Boosting image-text matching with false\nnegative elimination. In Proceedings of the 31st ACM International Conference on\nMultimedia. 924‚Äì934.\n[20] Jun Li, Yi Bin, Liang Peng, Yang Yang, Yangyang Li, Hao Jin, and Zi Huang.\n2024. Focusing on Relevant Responses for Multi-modal Rumor Detection. IEEE\nTransactions on Knowledge and Data Engineering(2024).\n[21] Manling Li, Ruochen Xu, Shuohang Wang, Luowei Zhou, Xudong Lin, Chenguang\nZhu, Michael Zeng, Heng Ji, and Shih-Fu Chang. 2022. CLIP-Event: Connecting\nText and Images with Event Structures. In CVPR. IEEE, 16399‚Äì16408.\n[22] Zixuan Li, Xiaolong Jin, Wei Li, Saiping Guan, Jiafeng Guo, Huawei Shen,\nYuanzhuo Wang, and Xueqi Cheng. 2021. Temporal Knowledge Graph Rea-\nsoning Based on Evolutional Representation Learning. In SIGIR. ACM, 408‚Äì417.\n[23] Yuxuan Liang, Haomin Wen, Yuqi Nie, Yushan Jiang, Ming Jin, Dongjin Song,\nShirui Pan, and Qingsong Wen. 2024. Foundation Models for Time Series Analysis:\nA Tutorial and Survey. arXiv preprint arXiv:2403.14735(2024).\n[24] Ruotong Liao, Xu Jia, Yunpu Ma, and Volker Tresp. 2023. GenTKG: Generative\nForecasting on Temporal Knowledge Graph. CoRR abs/2310.07793 (2023).\n[25] Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. 2024. Visual instruc-\ntion tuning. In NeurIPS.\n[26] Jerry Liu. 2022. LlamaIndex. https://doi.org/10.5281/zenodo.1234\n[27] Ruilin Luo, Tianle Gu, Haoling Li, Junzhe Li, Zicheng Lin, Jiayi Li, and Yujiu\nYang. 2024. Chain of History: Learning and Forecasting with LLMs for Temporal\nKnowledge Graph Completion. CoRR abs/2401.06072 (2024).\n[28] Shangwen Lv, Fuqing Zhu, and Songlin Hu. 2020. Integrating external event\nknowledge for script learning. In Proceedings of the 28th International Conference\non Computational Linguistics. 306‚Äì315.\n[29] Yunshan Ma, Chenchen Ye, Zijian Wu, Xiang Wang, Yixin Cao, and Tat-Seng\nChua. 2023. Context-aware Event Forecasting via Graph Disentanglement. In\nKDD. ACM, 1643‚Äì1652.\n[30] Yunshan Ma, Chenchen Ye, Zijian Wu, Xiang Wang, Yixin Cao, Liang Pang, and\nTat-Seng Chua. 2023. Structured, Complex and Time-complete Temporal Event\nForecasting. CoRR abs/2312.01052 (2023).\n[31] Fred Morstatter. 2021. RCT-B. (2021). https://doi.org/10.7910/DVN/ROTHFT\n[32] Qiang Ning, Hao Wu, Rujun Han, Nanyun Peng, Matt Gardner, and Dan Roth.\n2020. TORQUE: A Reading Comprehension Dataset of Temporal Ordering Ques-\ntions. In EMNLP. 1158‚Äì1172. https://doi.org/10.18653/v1/2020.emnlp-main.88\n[33] Namyong Park, Fuchen Liu, Purvanshi Mehta, Dana Cristofor, Christos Faloutsos,\nand Yuxiao Dong. 2022. EvoKG: Jointly Modeling Event Time and Network\nStructure for Reasoning over Temporal Knowledge Graphs. In WSDM. ACM,\n794‚Äì803.\n[34] Stephen Robertson, Hugo Zaragoza, et al . 2009. The probabilistic relevance\nframework: BM25 and beyond. Foundations and Trends¬Æ in Information Retrieval\n3, 4 (2009), 333‚Äì389.\n[35] Michael Sejr Schlichtkrull, Thomas N. Kipf, Peter Bloem, Rianne van den Berg,\nIvan Titov, and Max Welling. 2018. Modeling Relational Data with Graph Con-\nvolutional Networks. In ESWC (Lecture Notes in Computer Science, Vol. 10843).\nSpringer, 593‚Äì607.\n[36] Chao Shang, Yun Tang, Jing Huang, Jinbo Bi, Xiaodong He, and Bowen Zhou.\n2019. End-to-End Structure-Aware Convolutional Networks for Knowledge Base\nCompletion. In AAAI. AAAI Press, 3060‚Äì3067.\n[37] Jiashuo Sun, Chengjin Xu, Lumingyuan Tang, Saizhuo Wang, Chen Lin, Yeyun\nGong, Heung-Yeung Shum, and Jian Guo. 2023. Think-on-Graph: Deep and\nResponsible Reasoning of Large Language Model with Knowledge Graph. CoRR\nabs/2307.07697 (2023).\n[38] Zhiqing Sun, Zhi-Hong Deng, Jian-Yun Nie, and Jian Tang. 2019. RotatE: Knowl-\nedge Graph Embedding by Relational Rotation in Complex Space. InICLR (Poster).\nOpenReview.net.\n[39] Qingyu Tan, Hwee Tou Ng, and Lidong Bing. 2023. Towards Benchmarking and\nImproving the Temporal Reasoning Capability of Large Language Models. In\nACL. Association for Computational Linguistics, 14820‚Äì14835. https://doi.org/\n10.18653/v1/2023.acl-long.828\n[40] Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste\nAlayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth,\net al. 2023. Gemini: a family of highly capable multimodal models. arXiv preprint\narXiv:2312.11805 (2023).\n[41] Meihan Tong, Shuai Wang, Yixin Cao, Bin Xu, Juanzi Li, Lei Hou, and Tat-Seng\nChua. 2020. Image Enhanced Event Detection in News Articles. In AAAI. AAAI\nPress, 9040‚Äì9047.\n[42] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne\nLachaux, Timoth√©e Lacroix, Baptiste Rozi√®re, Naman Goyal, Eric Hambro, Faisal\nAzhar, Aur√©lien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lam-\nple. 2023. LLaMA: Open and Efficient Foundation Language Models. CoRR\nabs/2302.13971 (2023).\n[43] Yuqing Wang and Yun Zhao. 2023. TRAM: Benchmarking Temporal Reasoning\nfor Large Language Models. (2023). arXiv:2310.00835\n[44] Wenjie Xu, Ben Liu, Miao Peng, Xu Jia, and Min Peng. 2023. Pre-trained Lan-\nguage Model with Prompts for Temporal Knowledge Graph Completion. In ACL\n(Findings). Association for Computational Linguistics, 7790‚Äì7803.\n[45] Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. 2015. Em-\nbedding Entities and Relations for Learning and Inference in Knowledge Bases.\nIn ICLR (Poster).\n[46] Chenchen Ye, Ziniu Hu, Yihe Deng, Zijie Huang, Mingyu Derek Ma, Yanqiao\nZhu, and Wei Wang. 2024. MIRAI: Evaluating LLM Agents for Event Forecasting.\narXiv preprint arXiv:2407.01231(2024).\n[47] Michael Zhang and Eunsol Choi. 2021. SituatedQA: Incorporating Extra-\nLinguistic Contexts into QA. In EMNLP.\n[48] Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui\nChen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al. 2022. Opt:\nOpen pre-trained transformer language models. arXiv preprint arXiv:2205.01068\n(2022).\nMM ‚Äô24, October 28-November 1, 2024, Melbourne, VIC, Australia Haoxuan Li et al.\n[49] Zhihan Zhang, Yixin Cao, Chenchen Ye, Yunshan Ma, Lizi Liao, and Tat-Seng\nChua. 2024. Analyzing Temporal Complex Events with Large Language Models?\nA Benchmark towards Temporal, Long Context Understanding. arXiv preprint\narXiv:2406.02472 (2024).\n[50] Liang Zhao. 2021. Event prediction in the big data era: A systematic survey.ACM\nComputing Surveys (CSUR)54, 5 (2021), 1‚Äì37.\n[51] Ben Zhou, Daniel Khashabi, Qiang Ning, and Dan Roth. 2019. ‚ÄúGoing on a vaca-\ntion‚Äù takes longer than ‚ÄúGoing for a walk‚Äù: A Study of Temporal Commonsense\nUnderstanding. In EMNLP. 3363‚Äì3369. https://doi.org/10.18653/v1/D19-1332\nMM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models MM ‚Äô24, October 28-November 1, 2024, Melbourne, VIC, Australia\nA Appendix\nA.1 Prompts: Image Function\nIn this section, we show all the prompts that need to be used in the\nimage function identification module. As show in Table 7, the first\nrow is the prompt for image function recognition, which is mainly\nfrom the perspective of the subject background and the specific\nevent to judge the function of the image. The last two rows are the\nprompts of the different functions of the images to achieve their\nrespective functions and transform their information into verbal\ndescriptions. Eventually, the verbal information will be integrated\ninto the LLM-based event forecasting model.\nA.2 Case study: Image Function\nTo further illustrate that our approach does indeed identify truly\nkey events and the required complementary information, we pro-\nvide additional examples. In the first example of the highlighting\nfunction, the image directly depicts Ocasio-Cortez, with the back-\nground appearing to be the Congressional sites, thereby empha-\nsizing the relevant key event. Correspondingly, the key event also\nmentions the relationship between Congress and Ocasio-Cortez.\nConsequently, an accurate prediction is achieved. In the second\nexample of the highlighting function, the key event highlighted\nby the image directly mentions the disqualification of Ali Larijani\nfrom the election, which perfectly aligns with the results that need\nto be predicted and the information provided to present those re-\nsults. For the first example of complementary functions, the image\nprovides information about the signing of a free trade agreement\nbetween Turkey and the United Kingdom. While enhanced trade\nhas the potential to lead to employment and economic growth,\nthe image offers complementary information on the role of labor.\nTherefore, an accurate forecast is achieved. In the second example\nabout the complementary function, the image shows Bernie Sanders\nwho is a democratic progressive socialist like Ocasio-Cortez. They\nshare many commonalities and connections to Congress, which\ncan provide supplementary information to more accurately predict\nthe outcome. Through these examples, the distinct functions of\nhighlighting key events and providing complementary information\nare elucidated, substantiating the effectiveness of our approach in\nleveraging multimodal information for accurate temporal event\nforecasting.\nMM ‚Äô24, October 28-November 1, 2024, Melbourne, VIC, Australia Haoxuan Li et al.\nUser:\nResponse:\n[Query]: (Ocasio-Cortez, Demand material aid, 2281)\n[Related events]:\n[Date]1272:\n* New York congressional candidate Alexandria Ocasio-Cortez has made several claims about the economy and other issues that have been disputed by fact-checkers.\n* The Washington Post has disputed her claim that unemployment is low because everyone has two jobs, noting that the number of people working two jobs has remained steady at around 5 percent in recent years.\n* The Post and Politifact have also disputed her claim that ICE is required to fill 34,000 beds with detainees every single night, calling it an \"urban legend.\"\n* The Post has also disputed her claim that a recent study found Medicare-for-all would cut health expenditures, noting that the study found the plan would raise government expenditures by $32.6 trillion over 10 \nyears.\n* Ocasio-Cortez has also made questionable statements on how she would pay for her big spending agenda, including claiming that the military received a $700 billion dollar budget increase last year, which Politfact \nhas rated as \"false.\"\n* Ocasio-Cortez has pushed back against the critics, claiming that they shrugged off GOP Sen. James Inhofe's 2015 decision to bring a snowball to the Senate floor in a debate about climate change.\n[Date]2005:\n* Bernie Sanders, a progressive Democratic socialist, has expressed his top priority is beating Donald Trump in November.\n* Sanders and fellow progressive Democratic socialist Alexandria Ocasio-Cortez are slated to speak at the Democratic National Convention where they will throw the progressive wing support behind Biden's \npresidency.\n* Biden announced last week that California Senator Kamala Harris would be joining him on his presidential ticket.\n* Harris has the most liberal voting record over the last year of any senator currently serving in Congress.\n* Trump has bashed Harris, claiming she is more liberal than Sanders and would be 'running' the White House as vice president.\n[Date]2005:\n* Rep. Alexandria Ocasio-Cortez has emerged as a key figure in bridging the ideological gap between the Democratic Party establishment and the more populist camp represented by Sen. Bernie Sanders.\n* Ocasio-Cortez is scheduled to speak at the Democrats' virtual convention, providing an unusual platform for a first-term lawmaker and self-described democratic socialist.\n* The proposed Democratic platform includes a host of progressive priorities, including a public health insurance option, guaranteed early childhood education, and a $15 minimum wage.\n* The platform also embraces several positions in common with the task force report that Ocasio-Cortez co-chaired, including carbon-free electricity production by 2035 and net-zero emissions in the agriculture \nsector.\n* Republicans are seeking to portray Biden as in thrall to the far left, hoping to link vulnerable centrist Democrats to the most liberal voices in their party.\n* Ocasio-Cortez's influence on the party platform has put Biden in a position to better appeal to the progressives who may not have been enthusiastic about him during the primaries.\n* Ocasio-Cortez is uniquely suited to play an outsize role on the campaign trail, as a prominent member of the Congressional Hispanic Caucus, the youngest woman ever elected to Congress, and a social media \nmegastar.\n‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶..\n[Options]:    \nA: Unidentified actors  B: Congress  C: Gaza  D: Menendez E: 104 new immigrants from North America F: Unspecified group\nF: Unspecified group\nBefore Highlighting\nUser:\nResponse:\nB: Congress\nAfter Highlighting\n[Query]: (Ocasio-Cortez, Demand material aid, 2281)\n[Key events]:\n[Date]1272:\n* Ocasio-Cortez has pushed back against the critics, claiming that they shrugged off GOP Sen. James Inhofe's 2015 decision to bring a snowball to the Senate floor in a debate about climate change.\n‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶..\n[Related events]:\n[Date]1272:\n* New York congressional candidate Alexandria Ocasio-Cortez has made several claims about the economy and other issues that have been disputed by fact-checkers.\n* The Washington Post has disputed her claim that unemployment is low because everyone has two jobs, noting that the number of people working two jobs has remained steady at around 5 percent in recent years.\n* The Post and Politifact have also disputed her claim that ICE is required to fill 34,000 beds with detainees every single night, calling it an \"urban legend.\"\n* The Post has also disputed her claim that a recent study found Medicare-for-all would cut health expenditures, noting that the study found the plan would raise government expenditures by $32.6 trillion over 10 \nyears.\n* Ocasio-Cortez has also made questionable statements on how she would pay for her big spending agenda, including claiming that the military received a $700 billion dollar budget increase last year, which Politfact \nhas rated as \"false.\"\n[Date]2005:\n* Bernie Sanders, a progressive Democratic socialist, has expressed his top priority is beating Donald Trump in November.\n* Sanders and fellow progressive Democratic socialist Alexandria Ocasio-Cortez are slated to speak at the Democratic National Convention where they will throw the progressive wing support behind Biden's \npresidency.\n* Biden announced last week that California Senator Kamala Harris would be joining him on his presidential ticket.\n* Harris has the most liberal voting record over the last year of any senator currently serving in Congress.\n* Trump has bashed Harris, claiming she is more liberal than Sanders and would be 'running' the White House as vice president.\n[Date]2005:\n* Rep. Alexandria Ocasio-Cortez has emerged as a key figure in bridging the ideological gap between the Democratic Party establishment and the more populist camp represented by Sen. Bernie Sanders.\n* Ocasio-Cortez is scheduled to speak at the Democrats' virtual convention, providing an unusual platform for a first-term lawmaker and self-described democratic socialist.\n* The proposed Democratic platform includes a host of progressive priorities, including a public health insurance option, guaranteed early childhood education, and a $15 minimum wage.\n* The platform also embraces several positions in common with the task force report that Ocasio-Cortez co-chaired, including carbon-free electricity production by 2035 and net-zero emissions in the agriculture \nsector.\n* Republicans are seeking to portray Biden as in thrall to the far left, hoping to link vulnerable centrist Democrats to the most liberal voices in their party.\n* Ocasio-Cortez's influence on the party platform has put Biden in a position to better appeal to the progressives who may not have been enthusiastic about him during the primaries.\n* Ocasio-Cortez is uniquely suited to play an outsize role on the campaign trail, as a prominent member of the Congressional Hispanic Caucus, the youngest woman ever elected to Congress, and a social media \nmegastar.\n‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶..\n[Options]:    \nA: Unidentified actors  B: Congress  C: Gaza  D: Menendez E: 104 new immigrants from North America F: Unspecified group\nFigure 5: The case study of highlighting function of image.\nMM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models MM ‚Äô24, October 28-November 1, 2024, Melbourne, VIC, Australia\nUser:\nResponse:\n[Query]: (The Guardian Council, Veto, 2289)\n[Related events]:\n[Date]1828:\n* Iranians voted on Friday to elect a new parliament.\n* Many Iranians chose to abstain from voting due to disappointment with the government and its hollow promises.\n* A survey by the Institute for Social Studies at Tehran University in early February indicated that less than one out of four Iranians in Tehran would vote, in contrast to a 62% turnout in 2016.\n* Women activists in Iran called for an election boycott to protest the regime's brutal handling of demonstrators.\n* Iranians have faced economic hardship due to US sanctions and the government's \"maximum resistance\" policy.\n* Iranian security forces brutally cracked down on protests against the economic crisis, with parliamentarians remaining silent.\n* The Iranian regime needs legitimacy, and a high turnout is crucial for Khamenei to interpret as a sign of trust in the political system.\n* The Guardian Council barred almost 9,000 candidates from participating in the polls, including 92 incumbent members of parliament, mostly reformist politicians.\n[Date]2273:\n* Iran opened the door for candidacies for the upcoming presidential vote.\n* President Hassan Rouhani rejected the decision of the Guardian Council to study the candidates‚Äô applications.\n* The Guardian Council specified that ‚Äúall nominees must be between 40 and 70 years of age, hold at least a master‚Äôs degree or its equivalent, have experience of at least four years in managerial posts... and have \nno criminal record‚Äù.\n* The new terms come in implementation of a 2016 directive from Iran‚Äôs supreme leader Ali Khamenei for the council to clarify and ‚Äúdetermine‚Äù the requirements.\n* The updated requirements are likely to exclude some well-known figures, such as Rouhani‚Äôs telecom minister, Mohammad Javad Azari Jahromi, who is 39, or the elite Revolutionary Guards‚Äô Saeed Mohammad, \nwhose rank is below major general.\n* The increasing number of Revolutionary Guard generals who have announced their candidacy or are likely to be intending to compete in the presidential race, have raised fears of the ‚Äúmilitarization‚Äù of the \npolitical circle within the Iranian regime.\n[Date]2278:\n* Iran's election in June will determine the next president and possibly the successor of Supreme Leader Ali Khamenei.\n* Khamenei, who has been in power since 1989, is 81 years old and has several health problems.\n* The position of supreme leader is critical for the survival of the Islamic Republic and the continuation of Ayatollah Khomeini's revolutionary concept of Velayat-e Faqih.\n* The supreme leader has the final say on Iran's domestic and foreign policy and significant control over the legislative, executive and judicial systems.\n* The supreme leader also controls the IRGC, intelligence service, bonyad charitable trusts, and Setad organization.\n* The position of president can be a crucial stepping stone to succeeding the supreme leader.\n‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶..\n[Options]:    \nA: Vienna Talks  B: Khameini  C: Ali Larijani  D: Hemmati  E: Mahmoud Ahmadinejad  F: Mohsen Mehralizadeh\nB: Khameini\nBefore Highlighting\nUser:\nResponse:\nC: Ali Larijani\nAfter Highlighting\n[Query]: (The Guardian Council, Veto, 2289)\n[Key events]:\n[Date]2287:\n* Moderate conservative Ali Larijani was disqualified, potentially boosting ultraconservative judiciary chief Ebrahim Raisi's chances of winning\n.‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶..\n[Related events]:\n[Date]1828:\n* Iranians voted on Friday to elect a new parliament.\n* Many Iranians chose to abstain from voting due to disappointment with the government and its hollow promises.\n* A survey by the Institute for Social Studies at Tehran University in early February indicated that less than one out of four Iranians in Tehran would vote, in contrast to a 62% turnout in 2016.\n* Women activists in Iran called for an election boycott to protest the regime's brutal handling of demonstrators.\n* Iranians have faced economic hardship due to US sanctions and the government's \"maximum resistance\" policy.\n* Iranian security forces brutally cracked down on protests against the economic crisis, with parliamentarians remaining silent.\n* The Iranian regime needs legitimacy, and a high turnout is crucial for Khamenei to interpret as a sign of trust in the political system.\n* The Guardian Council barred almost 9,000 candidates from participating in the polls, including 92 incumbent members of parliament, mostly reformist politicians.\n[Date]2273:\n* Iran opened the door for candidacies for the upcoming presidential vote.\n* President Hassan Rouhani rejected the decision of the Guardian Council to study the candidates‚Äô applications.\n* The Guardian Council specified that ‚Äúall nominees must be between 40 and 70 years of age, hold at least a master‚Äôs degree or its equivalent, have experience of at least four years in managerial posts... and have \nno criminal record‚Äù.\n* The new terms come in implementation of a 2016 directive from Iran‚Äôs supreme leader Ali Khamenei for the council to clarify and ‚Äúdetermine‚Äù the requirements.\n* The updated requirements are likely to exclude some well-known figures, such as Rouhani‚Äôs telecom minister, Mohammad Javad Azari Jahromi, who is 39, or the elite Revolutionary Guards‚Äô Saeed Mohammad, \nwhose rank is below major general.\n* The increasing number of Revolutionary Guard generals who have announced their candidacy or are likely to be intending to compete in the presidential race, have raised fears of the ‚Äúmilitarization‚Äù of the \npolitical circle within the Iranian regime.\n[Date]2278:\n* Iran's election in June will determine the next president and possibly the successor of Supreme Leader Ali Khamenei.\n* Khamenei, who has been in power since 1989, is 81 years old and has several health problems.\n* The position of supreme leader is critical for the survival of the Islamic Republic and the continuation of Ayatollah Khomeini's revolutionary concept of Velayat-e Faqih.\n* The supreme leader has the final say on Iran's domestic and foreign policy and significant control over the legislative, executive and judicial systems.\n* The supreme leader also controls the IRGC, intelligence service, bonyad charitable trusts, and Setad organization.\n* The position of president can be a crucial stepping stone to succeeding the supreme leader.\n.‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶..\n[Options]:    \nA: Vienna Talks  B: Khameini  C: Ali Larijani  D: Hemmati  E: Mahmoud Ahmadinejad  F: Mohsen Mehralizadeh\nFigure 6: The case study of highlighting function of image.\nMM ‚Äô24, October 28-November 1, 2024, Melbourne, VIC, Australia Haoxuan Li et al.\nUser:\nResponse:\n[Query]: (Turkey, Workforce, 2304)\n[Related events]:\n[Date]2067:\n* Armenia and Azerbaijan accused each other of violating a new ceasefire on Sunday, the second attempt in a week to halt fighting over Nagorno-Karabakh.\n* The new ceasefire deal was announced after a missile hit a residential area of Azerbaijan's second city Ganja, killing 13 people including children.\n* Armenia's defence ministry said Azerbaijani forces had violated the new ceasefire only minutes after it took effect, firing artillery shells and rockets.\n* Azerbaijan's defence ministry accused Armenian forces of firing artillery and mortar shells and of launching early morning attacks along the frontline.\n* Armenia said on Sunday that Azerbaijan had \"categorically rejected\" an attempt mediated by the International Committee of the Red Cross to withdraw wounded soldiers from the front.\n* Azerbaijan said it was in talks with the ICRC and was prepared to unilaterally hand over some bodies of Armenian servicemen.\n* UN chief Antonio Guterres on Sunday called on both sides to respect the new ceasefire and condemned the attacks on civilians, in particular Saturday's deadly missile strike on Ganja.\n* The European Union's top diplomat Joseph Borrell also deplored the violations of the truce and appealed for an end on attacks on civilians.\n* The clashes over Karabakh that erupted on September 27 have left more than 700 dead, including scores of civilians on both sides.\n[Date]2070:\n* Turkey is the main instigator of the current Karabakh war, involved in every step of the Azerbaijani war plan.\n* Satellite imagery revealed the presence of Turkish F-16 fighter jets in Azerbaijan, used against Armenian forces.\n* Turkey has been shuttling mercenaries and jihadists from Syria and Libya into the conflict zone, including members of the Syrian Nusra Front.\n* Turkish President Recep Tayyip Erdogan has made his geopolitical ambitions well-known, seeking to transform the conflict into a major regional war.\n* Erdogan aims to use the war to send a message to Russia and potentially supplant its influence in the Caucasus with Turkish influence.\n* Iran is also a target of Erdogan's move, as he seeks to turn insults into injuries.\n* Turkey and Azerbaijan held joint war games before the conflict, involving Turkish F-16 jets and various artillery and air-defense systems.\n* Azerbaijan's objective was to surround the territory of the former Soviet-era Nagorno-Karabakh Autonomous Oblast, but faced stiff Armenian resistance.\n* Baku and Ankara resorted to shelling cities and towns and targeting civilians, with Stepanakert suffering the most.\n* The strategy of deliberately targeting civilians is a tactic used by Erdogan against the Kurds in Turkey, Syria, and Iraq.\n‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶..\n[Options]:    \nA: Return, release persons  B: Provide aid  C: Threaten to use unconventional attack including terrorist\nC: Threaten to use unconventional attack including terrorist\nBefore Complementary\nUser:\nResponse:\nB: Provide aid\nAfter Complementary\n[Query]: (Turkey, Workforce, 2304)\n[Key events]:\n‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶..\n[Related events]:\n[Date]2067:\n* Armenia and Azerbaijan accused each other of violating a new ceasefire on Sunday, the second attempt in a week to halt fighting over Nagorno-Karabakh.\n* The new ceasefire deal was announced after a missile hit a residential area of Azerbaijan's second city Ganja, killing 13 people including children.\n* Armenia's defence ministry said Azerbaijani forces had violated the new ceasefire only minutes after it took effect, firing artillery shells and rockets.\n* Azerbaijan's defence ministry accused Armenian forces of firing artillery and mortar shells and of launching early morning attacks along the frontline.\n* Armenia said on Sunday that Azerbaijan had \"categorically rejected\" an attempt mediated by the International Committee of the Red Cross to withdraw wounded soldiers from the front.\n* Azerbaijan said it was in talks with the ICRC and was prepared to unilaterally hand over some bodies of Armenian servicemen.\n* UN chief Antonio Guterres on Sunday called on both sides to respect the new ceasefire and condemned the attacks on civilians, in particular Saturday's deadly missile strike on Ganja.\n* The European Union's top diplomat Joseph Borrell also deplored the violations of the truce and appealed for an end on attacks on civilians.\n* The clashes over Karabakh that erupted on September 27 have left more than 700 dead, including scores of civilians on both sides.\n[Date]2070:\n* Turkey is the main instigator of the current Karabakh war, involved in every step of the Azerbaijani war plan.\n* Satellite imagery revealed the presence of Turkish F-16 fighter jets in Azerbaijan, used against Armenian forces.\n* Turkey has been shuttling mercenaries and jihadists from Syria and Libya into the conflict zone, including members of the Syrian Nusra Front.\n* Turkish President Recep Tayyip Erdogan has made his geopolitical ambitions well-known, seeking to transform the conflict into a major regional war.\n* Erdogan aims to use the war to send a message to Russia and potentially supplant its influence in the Caucasus with Turkish influence.\n* Iran is also a target of Erdogan's move, as he seeks to turn insults into injuries.\n* Turkey and Azerbaijan held joint war games before the conflict, involving Turkish F-16 jets and various artillery and air-defense systems.\n* Azerbaijan's objective was to surround the territory of the former Soviet-era Nagorno-Karabakh Autonomous Oblast, but faced stiff Armenian resistance.\n* Baku and Ankara resorted to shelling cities and towns and targeting civilians, with Stepanakert suffering the most.\n* The strategy of deliberately targeting civilians is a tactic used by Erdogan against the Kurds in Turkey, Syria, and Iraq.\n[Date] 2194:\n* Signing of a free trade agreement between Turkey and the United Kingdom. Turkish Trade Minister Ruhsar Pekcan and UK International Trade Secretary Liz Truss signing the UK-Turkey Free Trade Agreement \nin Ankara, Turkey, on December 29, 2020.\n‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶..\n[Options]:    \nA: Return, release persons  B: Provide aid  C: Threaten to use unconventional attack including terrorist\nFigure 7: The case study of complementary function of image.\nMM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models MM ‚Äô24, October 28-November 1, 2024, Melbourne, VIC, Australia\nUser:\nResponse:\n[Query]: (Ocasio-Cortez, Demand material aid, 2281)\n[Related events]:\n[Date]1272:\n* New York congressional candidate Alexandria Ocasio-Cortez has made several claims about the economy and other issues that have been disputed by fact-checkers.\n* The Washington Post has disputed her claim that unemployment is low because everyone has two jobs, noting that the number of people working two jobs has remained steady at around 5 percent in recent years.\n* The Post and Politifact have also disputed her claim that ICE is required to fill 34,000 beds with detainees every single night, calling it an \"urban legend.\"\n* The Post has also disputed her claim that a recent study found Medicare-for-all would cut health expenditures, noting that the study found the plan would raise government expenditures by $32.6 trillion over 10 years.\n* Ocasio-Cortez has also made questionable statements on how she would pay for her big spending agenda, including claiming that the military received a $700 billion dollar budget increase last year, which Politfact has \nrated as \"false.\"\n* Ocasio-Cortez has pushed back against the critics, claiming that they shrugged off GOP Sen. James Inhofe's 2015 decision to bring a snowball to the Senate floor in a debate about climate change.\n[Date]2005:\n* Bernie Sanders, a progressive Democratic socialist, has expressed his top priority is beating Donald Trump in November.\n* Sanders and fellow progressive Democratic socialist Alexandria Ocasio-Cortez are slated to speak at the Democratic National Convention where they will throw the progressive wing support behind Biden's presidency.\n* Biden announced last week that California Senator Kamala Harris would be joining him on his presidential ticket.\n* Harris has the most liberal voting record over the last year of any senator currently serving in Congress.\n* Trump has bashed Harris, claiming she is more liberal than Sanders and would be 'running' the White House as vice president.\n[Date]2005:\n* Rep. Alexandria Ocasio-Cortez has emerged as a key figure in bridging the ideological gap between the Democratic Party establishment and the more populist camp represented by Sen. Bernie Sanders.\n* Ocasio-Cortez is scheduled to speak at the Democrats' virtual convention, providing an unusual platform for a first-term lawmaker and self-described democratic socialist.\n* The proposed Democratic platform includes a host of progressive priorities, including a public health insurance option, guaranteed early childhood education, and a $15 minimum wage.\n* The platform also embraces several positions in common with the task force report that Ocasio-Cortez co-chaired, including carbon-free electricity production by 2035 and net-zero emissions in the agriculture sector.\n* Republicans are seeking to portray Biden as in thrall to the far left, hoping to link vulnerable centrist Democrats to the most liberal voices in their party.\n* Ocasio-Cortez's influence on the party platform has put Biden in a position to better appeal to the progressives who may not have been enthusiastic about him during the primaries.\n* Ocasio-Cortez is uniquely suited to play an outsize role on the campaign trail, as a prominent member of the Congressional Hispanic Caucus, the youngest woman ever elected to Congress, and a social media megastar.\n‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶..\n[Options]:    \nA: Unspecified group  B: Menendez  C: Gaza  D: Unidentified actors  E: 104 new immigrants from North America  F: Congress\nA: Unspecified group\nBefore Complementary\nUser:\nResponse:\nF: Congress\nAfter Complementary\n[Query]: (Ocasio-Cortez, Demand material aid, 2281)\n[Key events]:\n‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶..\n[Related events]:\n[Date]1272:\n* New York congressional candidate Alexandria Ocasio-Cortez has made several claims about the economy and other issues that have been disputed by fact-checkers.\n* The Washington Post has disputed her claim that unemployment is low because everyone has two jobs, noting that the number of people working two jobs has remained steady at around 5 percent in recent years.\n* The Post and Politifact have also disputed her claim that ICE is required to fill 34,000 beds with detainees every single night, calling it an \"urban legend.\"\n* The Post has also disputed her claim that a recent study found Medicare-for-all would cut health expenditures, noting that the study found the plan would raise government expenditures by $32.6 trillion over 10 years.\n* Ocasio-Cortez has also made questionable statements on how she would pay for her big spending agenda, including claiming that the military received a $700 billion dollar budget increase last year, which Politfact \nhas rated as \"false.\"\n* Ocasio-Cortez has pushed back against the critics, claiming that they shrugged off GOP Sen. James Inhofe's 2015 decision to bring a snowball to the Senate floor in a debate about climate change.\n[Date]2005:\n* Bernie Sanders, a progressive Democratic socialist, has expressed his top priority is beating Donald Trump in November.\n* Sanders and fellow progressive Democratic socialist Alexandria Ocasio-Cortez are slated to speak at the Democratic National Convention where they will throw the progressive wing support behind Biden's presidency.\n* Biden announced last week that California Senator Kamala Harris would be joining him on his presidential ticket.\n* Harris has the most liberal voting record over the last year of any senator currently serving in Congress.\n* Trump has bashed Harris, claiming she is more liberal than Sanders and would be 'running' the White House as vice president.\n[Date]2005:\n* Rep. Alexandria Ocasio-Cortez has emerged as a key figure in bridging the ideological gap between the Democratic Party establishment and the more populist camp represented by Sen. Bernie Sanders.\n* Ocasio-Cortez is scheduled to speak at the Democrats' virtual convention, providing an unusual platform for a first-term lawmaker and self-described democratic socialist.\n* The proposed Democratic platform includes a host of progressive priorities, including a public health insurance option, guaranteed early childhood education, and a $15 minimum wage.\n* The platform also embraces several positions in common with the task force report that Ocasio-Cortez co-chaired, including carbon-free electricity production by 2035 and net-zero emissions in the agriculture sector.\n* Republicans are seeking to portray Biden as in thrall to the far left, hoping to link vulnerable centrist Democrats to the most liberal voices in their party.\n* Ocasio-Cortez's influence on the party platform has put Biden in a position to better appeal to the progressives who may not have been enthusiastic about him during the primaries.\n* Ocasio-Cortez is uniquely suited to play an outsize role on the campaign trail, as a prominent member of the Congressional Hispanic Caucus, the youngest woman ever elected to Congress, and a social media megastar.\n[Date] 2194:\n* Bernie Sanders, a progressive Democratic socialist, is shown in the image with a stern expression on his face. He is wearing glasses and a dark suit jacket, with an American flag in the background.\n‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶..\n[Options]:    \nA: Unspecified group  B: Menendez  C: Gaza  D: Unidentified actors  E: 104 new immigrants from North America  F: Congress\nFigure 8: The case study of complementary function of image.\nMM ‚Äô24, October 28-November 1, 2024, Melbourne, VIC, Australia Haoxuan Li et al.\nTable 7: Prompts of image function identification module.\nIdentification\nYou are a professional news writer.\nPlease judge the relationship between images and news based on the following rules:\n1. Final judgment please choose between [highlighting, complementary, irrelevant].\n2. The relationship between an image and a news article is highlighting if the image‚Äôs subject matter and depicted\nevent are highly related to the news and the specific event shown in the image is already mentioned in detail in\nthe article‚Äôs description.\n3. The relationship between an image and a news article is complementary if the image‚Äôs overall theme and\nbackground information are highly related to the news, but the specific event depicted in the image is not\nmentioned in detail in the article, and the visual information in the image can complement the news story as\na whole.\n4. Except in cases where the relationship is highlighting or complementary, in other cases, the relationship\nbetween the image and the text is irrelevant.\nHighlighting\nYou are a professional news writer.\nPlease determine which sub-event in the news the image is most relevant to based on the following rules:\n1. For the final judgement, please answer with the serial number of the sub-event. For example: [The number of\nthe sub-event most relevant to the image is 1.]\n2. Identify the main subjects or objects prominently featured in the image. Sub-events that provide details,\nbackground information or context directly about these central visual elements are highly relevant.\n3. If people are depicted, identify who those individuals are. Sub-events involving those particular people should\ntake priority.\n4. Analyze the overall activities, actions, emotions or mood being portrayed in the image. Relevant sub-events\nlikely delve into similar situations, occurrences or sentiments illustrated.\n5. Take note of the specific location, setting or environment depicted in the image. Prioritize sub-events that\ndiscuss that geographic area, type of place, or related events.\n6. Look for any text, logos, labeled items or signs visible in the image content. Sub-events elaborating on the\norganizations, companies, products or public figures represented by those texts are applicable.\nComplementary\nYou are a professional news writer.\nPlease extract the image information according to the following rules based on the content of the provided news:\n1. Extract the image information as a sub-event. Instead of multiple sub-events.\n2. The phrases: [In the image], [The image shows], [In the picture], [The image is], [In the photo], etc, should\nnever appear in the summarised sub-event.\n3. Identify the primary focus or subject of the image that represents the core piece of information being conveyed.\nThis main subject should serve as the central point around which the image information is extracted.\n4. Directly relate the extracted image information to the associated news event covered in the article. The image\nsummary should complement and enhance the understanding of the news content, not introduce unrelated\ninformation.\n5. Prioritize and emphasize the most newsworthy and significant details visible in the image. These could include\nspecific actions, emotions, or identifying characteristics of the main subject.\n6. Ensure that all information included in the image summary originates directly from the provided image\nand news article. Avoid introducing fabricated content, speculative details.\n7. Aim for a succinct summary, using clear and straightforward language. Avoid excessive detail or subjective\ncommentary.\n8. Maintain an objective and impartial tone when describing the image. Avoid inserting personal opinions or\ninterpretations.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7186744213104248
    },
    {
      "name": "Event (particle physics)",
      "score": 0.5524279475212097
    },
    {
      "name": "Artificial intelligence",
      "score": 0.39238300919532776
    },
    {
      "name": "Natural language processing",
      "score": 0.3545325994491577
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ]
}