{
  "title": "Patient agency and large language models in worldwide encoding of equity",
  "url": "https://openalex.org/W4410217157",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2034145168",
      "name": "Antonis A. Armoundas",
      "affiliations": [
        "Harvard University",
        "Broad Institute",
        "Massachusetts Institute of Technology",
        "Massachusetts General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A1371930176",
      "name": "Joseph Loscalzo",
      "affiliations": [
        "Massachusetts Institute of Technology",
        "Brigham and Women's Hospital",
        "Broad Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2034145168",
      "name": "Antonis A. Armoundas",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1371930176",
      "name": "Joseph Loscalzo",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2232839779",
    "https://openalex.org/W2122407370",
    "https://openalex.org/W4205500817",
    "https://openalex.org/W4392238077",
    "https://openalex.org/W4398252146",
    "https://openalex.org/W4403873023",
    "https://openalex.org/W4402713326",
    "https://openalex.org/W4402909345",
    "https://openalex.org/W4404918847",
    "https://openalex.org/W4405967085",
    "https://openalex.org/W4393335480",
    "https://openalex.org/W4405275313",
    "https://openalex.org/W4402697698",
    "https://openalex.org/W4405764234",
    "https://openalex.org/W4389697049",
    "https://openalex.org/W4401943355",
    "https://openalex.org/W4403880728",
    "https://openalex.org/W4225959938",
    "https://openalex.org/W2150353123",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4221106857",
    "https://openalex.org/W4386272230",
    "https://openalex.org/W2083384763",
    "https://openalex.org/W4385476863",
    "https://openalex.org/W4389325518",
    "https://openalex.org/W4402827393",
    "https://openalex.org/W4389520749",
    "https://openalex.org/W4376133468",
    "https://openalex.org/W4319663047",
    "https://openalex.org/W4311991135",
    "https://openalex.org/W4221149706",
    "https://openalex.org/W4377009978",
    "https://openalex.org/W6847076894",
    "https://openalex.org/W4405721544",
    "https://openalex.org/W4404130284",
    "https://openalex.org/W4401664916",
    "https://openalex.org/W4405384981"
  ],
  "abstract": "Large language models progressively result in improved ways of patient engagement and access to healthcare, reaching both an exciting and concerning time, as they no longer serve solely as a guide to clinicians, but, for the first time enable patients to make decisions that directly affect their health. We present the benefits and risks of this paradigm-shift in the practice of medicine, that offers the possibility of promoting health equity.",
  "full_text": "npj |digital medicine Perspective\nPublished in partnership with Seoul National University Bundang Hospital\nhttps://doi.org/10.1038/s41746-025-01598-y\nPatient agency and large language models\nin worldwide encoding of equity\nCheck for updates\nAntonis A. Armoundas1,2 & Joseph Loscalzo2,3\nLarge language models progressively result in improved ways of patient engagement and access to\nhealthcare, reaching both an exciting and concerning time, as they no longer serve solely as a guide to\nclinicians, but, for theﬁrst time enable patients to make decisions that directly affect their health. We\npresent the beneﬁts and risks of this paradigm-shift in the practice of medicine, that offers the\npossibility of promoting health equity.\nIn sociology,agencyis generally deﬁned as an individual’s capacity to engage\nthe social world1,o rt h ee fﬁcacy of human action2.I nt h i sp a p e r ,patient\nagency is deﬁned as the patient’s capacity to engage efﬁciently with, act on,\nand assume responsibility oftheir state of health. TheMerriam-Webster\ndictionary deﬁnes equity as, “fairness or justice in the way people are\ntreated.”\nNew artiﬁcial intelligence (AI)-based technologies such as large lan-\nguage models (LLMs) can progressively result in improved ways of deli-\nvering healthcare that enhance patient access, personalization, and\nengagement. With LLMs, we are rapidly reaching both an exciting and\nconcerning time for healthcare, where AI technologies of today will no\nlonger solely have an augmenting\n3 or even perhaps a guiding4 role in the\nclinician’s care arsenal, but, rather, enable the patient to become her own\nclinician.\nTo ensure that LLM-based technologies reach their full potential,\nhowever, it is important that intere s t e ds t a k e h o l d e r se n g a g ei na ni n\ndepth discussion regarding their bene ﬁt s ,r i s k s ,a n dl i m i t a t i o n s .\nTherefore, the present manuscript attempts to offer the beneﬁts and\nrisks of a paradigm-shift in the practice of medicine that promotes\nhealth equity worldwide.\nBeneﬁts of the use of LLMs in promoting patient agency\nPatient beneﬁts of LLMs\nLarge language models carry an as yet unknown potential to facilitate the\nhealthcare-involved stakeholders to focus their care around patients’needs\nby improving access, engagement, and patient agency. However, LLMs,\nsimilar to other AI-based technologies, also present signiﬁcant challenges\nassociated with patient privacy, security, bias, and accountability that have\nto be taken into consideration\n5,6. Because LLMs are able to formulate\ncomprehensible responses to complex inquiries, they offer an opportunity\nto advance healthcare delivery in all health- and digitally-literate patients\nworldwide, irrespective of where they live and their social determinants of\nhealth.\nEnhancing access to care\nLarge language models have opened a new window into a vast landscape of\nnew possibilities regarding the quality of care that patients can access and\nhow they access it. LLMs can simplify the description of medical conditions,\nassist in drafting medical documents, create training programs and pro-\ncesses, and streamline research processes, and may potentially transform\nhealthcare by enhancing diagnostics, medical writing, education, and pro-\nject management\n7,8.\nEnhancing precision medicine\nLLMs offer functionality (e.g., text-to-speech) which may enhance access to\ncare for patients with disabilities, and they can also accurately translate\noutput to languages, thusmaking healthcare more accessible to individuals\nand their special needs worldwide.\nFor many years, clinicians and industrial stakeholders have investi-\ngated novel ways to deliver personalized care; however, factors such\nshortages of clinicians, budget constraints, and over-burdened systems have\nlargely prevented these efforts from achieving these goals. LLMs can analyze\nlarge volumes of patient data, such as genetics\n9,10,l i f e s t y l e11,E H R12,13,a n d\nmedications14,15, and, therefore, they may enhance precision medicine by\nidentifying potential risks, suggest preventive strategies, and develop per-\nsonalized treatment plans for patients with chronic or rare conditions16.\nPromoting patient engagement and outcomes\nIt has been recognized that increased patient engagement, resulting in\npatients taking more ownership of their health-related decisions, often leads\nto better outcomes. Consequently, patients who adopt better adherence to\ntheir treatment plans more frequently acquire and attain effective preventive\nactions, which eventually result in improved short- and long-term\noutcomes.\nLLMs have the transformative potential to be powerful allies in pro-\nmoting patient engagement\n17,18. By enhancing personalized patient educa-\ntion, access to understandable medicalinformation, and clinical decision\n1Cardiovascular Research Center, Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA.2Broad Institute, Massachusetts Institute of\nTechnology, Cambridge, MA, USA.3Division of Cardiovascular Medicine, Channing Division of Network Medicine, Department of Medicine, Brigham and Women’s\nHospital, Harvard Medical School, Boston, MA, USA. e-mail: armoundas.antonis@mgh.harvard.edu\nnpj Digital Medicine|           (2025) 8:258 1\n1234567890():,;\n1234567890():,;\nsupport; by facilitating patient-clinician communication or understanding a\nconsent form; by providing personalized health plans and coaching; by\nextracting key information from patient or clinician notes; and by\nempowering self-management, and supporting shared decision-making,\nLLMs can help create a more patient-centered, proactive, and equitable\nhealthcare experience. However, responsible development, ethical imple-\nmentation, and a focus on human connection are crucial to realizing these\nbeneﬁts and ensuring that LLMs truly empower and engage patients in\ntheir care.\nPromoting patient agency in shared decision-making\nPatient agency refers to“the abilities and capabilities of patients to act,\ncontribute, inﬂuence, and make decisions about their healthcare”19.I t\ndepends on both the readiness and inclination of patients to take part in care\ndecisions, and the barriers sustainedby healthcare providers, as well as\ntraditional services and systems, that limit such engagement\n19.S h a r e d\ndecision-making involves a concerted practice that includes a patient and\nher healthcare team working togetherto reach joint decisions, which are\nbased on the patient’s informed preferences and clinical evidence\n19.\nDespite increased appreciation of the signiﬁcance of health-literacy at a\npolicy and global level20,21, and given that the practice of medicine today is\nmore patient-centered than in the past, many clinicians believe that it is the\npatients’responsibility to improve health literacy rather than the respon-\nsibility of the clinician to adapt their communication and educational\nmethods to the different health-literacy levels and needs of their patients. A\ncofounding of this situation is the confusion regarding health- and digital-\nliteracy, which, while they are related, they are intrinsically different.\nIn the dawn of today’s worldwide digital transformation\n22, the generally\naccepted assumption has been that digitally-literate people are also health-\nliterate; however, while digital literacy is a valuable asset and contributing\nfactor to health literacy in today’s digital age, it is not a guarantee or direct\nsubstitute for health literacy. Being digitally literate makes iteasierto access\nhealth information, but it does notautomatically ensure someone can\nunderstand, evaluate,a n dapply that information effectively in a health\ncontext\n23.\nWhile digital technologies have enabled and facilitated increased\naccess to health-information and h ealthcare applications, not all\nindividuals will have the knowledge or the capacity to access them\neffectively 24. Thus, for health-literacy to be achieved, patients not only\nneed accurate information they can trust, but they also need sufﬁcient\nskills to identify accurate and reliable sources of information within the\nenormous available array of resources to which they are now exposed\nthrough LLMs.\nThus, one can frame the patient-centered changes empowered by\nLLMs in terms of: (i)values and preferences--patients may prioritize\ncertain outcomes or aspects of care differently than clinicians (e.g.,\nquality of life vs. longevity, natural remedies vs. aggressive interventions);\n(ii) understanding of their condition--they have done their research,\nformed opinions, and have speciﬁc needs and questions; and (iii)prac-\ntical limitations--they might have constraints related to lifestyle,ﬁnan-\nces, time, social support, or personal beliefs that impact their ability to\nadhere to certain treatment plans; a patient might intellectually under-\nstand and even agree with a plan, but practically, it might be very difﬁcult\nfor them to adopt and implement it, in their daily life.\nAs patients become increasingly more health-literate worldwide, it\nappears that there will be a need for compromise between an LLM’s\noptimal clinical care(or from a medical perspective,best course of action),\nand what patients feel they need and are able to achieve that will be\ndependent on the level of risk a patient is willing to accept, as well as the\nseverity of the illness. Eventually, improved awareness of a patient’s\nhealth should facilitate and enhance more effective communication and\nmore fruitful engagement with the patient’s clinicians. At the systems\nlevel, relevant infrastructures and processes also need to be in place to\nsupport such a system (comprised of health-literate physicians, specia-\nlists, and other health care providers).\nPromoting patient agency in individual decision-making\nWhile improving health literacy has been a stated objective20,21,t h e r ea r e\naspects of health-literacy, such as the understanding of risk and beneﬁt,\nneeded in a discussion of treatment choices and the resulting decision-\nmaking that may not always be feasible or even available.\nEventually, improved patient levels of health-literacy result in a better\nunderstanding of their disease and the available types of treatment, and\nrender them better equipped to care for themselves, even if they are not able\nto have immediate access to therapies from which they could beneﬁt.\nAssuming broad-band internet access exists, such beneﬁts could be realized\nin remote areas, for example, in Africa, Central and South-East Asia, Central\nand Latin America, where the under-resourced medical systems and the\nremoteness of some areas may force people to prioritize resources and travel,\nin order to see a specialist.\nIn conclusion, given that LLMs offer a real and growing capacity for\nhealth-education, knowledge, and competency that could advance patient\nempowerment and agency, their integration and adoption by healthcare\nservices and structures could minimize patient- or physician-driven medical\nerrors (Box1). While patients are becoming the drivers of this transfor-\nmation, such a process will require their participation, worldwide, in leading\nroles in determining strategy, making policy and governance, and in\nbuilding and sharing practices and evidence such that patient empower-\nment and engagement become broader and deeper at all levels (i.e., edu-\ncation, research, care, regulation, governance, etc.).\nRisks of the use of LLMs in promoting patient agency\nHealth care providers should also strive to understand the potential beneﬁts,\nrisks, and ramiﬁc a t i o n so fL L M si no r d e rt og u i d ep a t i e n t sa p p r o p r i a t e l y\nwhen possible. Similarly, patientsand their relatives who may seek“expert”\nopinion in LLMs should be mindful of the limitations and risks of these\ntechnologies, as well as their lesser capacity compared to an expert in\nunderstanding and appreciating the information they have been provided\n(Box 1).\nUsing LLMs with caution\nDespite LLMs’growing utility in assisting diagnosis and improving patient-\nphysician communication, challenges persist, including limitations in\ncontextual understanding, assessment of risk, and degree of reliance. While\nan explosion in LLM-related research has focused on improving medical\nwriting, diagnostics, and communication, there has been a need for careful\nvalidation of medical knowledge, as well as ethical concerns with respect to\nhow that knowledge is integrated into traditional medical practice.\nIt is imperative that all stakeholders not become overly-enthusiastic\nwith the potential utility of LLMs in healthcare. We must always keep in\nmind that the ultimate focus of any new technology is to facilitate the\ndelivery of medical care in a way that improves patient outcomes while\nprotecting human dignity (i.e., by respecting privacy and safety). Therefore,\nit is vital that we are transparent aboutthe potential limitations and risks\nassociated with the use of LLMs.\nAccuracy, accessibility and completeness\nAccurate and accessible medical information is key to successful patient-\ncentered care. Obtaining relevant risk and beneﬁt information on treatment\nalternatives ensures optimal health outcomes for patients and their relatives\nseeking reliable information that they can understand and trust about a\nspeciﬁc medical condition or treatment.\nOwing to the inherent nature of LLMs, algorithms that generate an\noutput by relying on analysis of vast amounts of text, they run the risk of\nincluding biased views and inaccuracies in their outputs. Bias may manifest\nitself when, for example, LLMs draw conclusions from a data source in\nwhich certain population demographics are underrepresented\n3,4.O fp a r t i -\ncular concern are so-called LMM hallucinations, which can potentially be\nharmful to patients by delivering inaccurate diagnoses or recommending\nimproper treatment options\n8. To guard against such problems, it is essential\nthat LLMs, like other AI tools, are subject to rigorous pre-market evaluation\nhttps://doi.org/10.1038/s41746-025-01598-y Perspective\nnpj Digital Medicine|           (2025) 8:258 2\nBox 1 | Patient Beneﬁt sa n dR i s k sf r o mU s i n gL L M s\n1. Enhanced access to \ninforma/g415on and educa/g415on\nby providing, 24/7 instant and understandable health \ninforma/g415on, support and preliminary guidance, \nregardless of loca/g415on,  personalized health educa/g415on \ntailored to individual needs \n2. Improved diagnos/g415c and \ntreatment experience\nby providing, faster and more accurate diagnoses,  more \npersonalized and evidence-based treatment \nrecommenda/g415ons,  access to expert-level knowledge, \nregardless of loca/g415on or specialist availability \n3. Enhanced pa/g415ent support \nand self-management\nby providing, personalized health coaching and wellness \nsupport,  improved chronic disease management,  \nemo/g415onal support and reduced anxiety (for some \npa/g415ents) \n4. Increased pa/g415ent \nempowerment and agency\nby providing, greater control over health informa/g415on and \ndecisions, breaking down language and communica/g415on \nbarriers, and poten/g415ally reduced healthcare costs\n(indirectly)\n Poten/g415al Pa/g415ent Risks from Using LLMs  \n Poten/g415al Pa/g415ent Beneﬁts from Using LLMs  \n1. Inaccuracy and unreliability\nof informa/g415on  \nmay result in, misinforma/g415on resul/g415ng in delayed or \nincorrect diagnosis, inappropriate treatment choices, \nand poten/g415al harm from following inaccurate advice \n2. Bias and discrimina/g415on \nmay result in, unequal access to quality care, \nmisdiagnosis or mistreatment due to biased LLM models, \nperpetua/g415on of health dispari/g415es, and culturally \ninappropriate healthcare experiences \n3. Privacy and security\nrelated concerns   \nmay result in, loss of privacy, exposure of sensi/g415ve health \ninforma/g415on, poten/g415al misuse of data, and erosion of \ntrust in healthcare systems using LLMs \n4. Over-reliance and \ndehumaniza/g415on of care \nmay result in, subop/g415mal care decisions due to over-\nreliance on LLMs, reduced empathy and human \nconnec/g415on in healthcare interac/g415ons, and a \ndepersonalized care experience \n5. Lack of clinical valida/g415on \nand regulatory oversight \nmay result in, exposure to unproven and poten/g415ally \nunsafe technologies, lack of clear accountability in case \nof LLM-related harm, and erosion of public trust in AI-\ndependent healthcare applica/g415ons, due to inadequate \nregula/g415on \n6. Lack of accessibility and \nequity  \nmay result in, exacerba/g415on of exis/g415ng health inequi/g415es \nif access to and usability of LLM-based healthcare tools is \nnot equitable across all popula/g415ons \nhttps://doi.org/10.1038/s41746-025-01598-y Perspective\nnpj Digital Medicine|           (2025) 8:258 3\nand post-market monitoring4. One way to accomplish this is by including\nmedical professionals (the“e x p e r th u m a ni nt h el o o p”concept) throughout\nthe development, evaluation, and deployment of LLMs in clinical practice.\nPrivacy and security\nSimilarly to traditional AI-based healthcare technologies, LMM developers\nand stakeholders must recognize and address patient privacy and security\nconcerns. LLM developers must be as transparent as possible, without\ncompromising on model performance,with patients and the industry about\nthe functionality of their algorithms andthe potential associated risks (e.g.,\ncompromise patient privacy) they may present\n3. The collection, processing,\nstorage, and sharing of sensitive patient information raise signiﬁcant privacy\nconcerns, with at least one major concern being the risk of unauthorized\naccess or data security breaches\n25. As LLMs interact increasingly with\npatients and healthcare providers, they may increasingly collect and store\nnatural history health information (i.e., medical history, test results, diag-\nnoses, other sensitive data, etc) that need to be safeguarded.\nWith multimodal patient data collection, another privacy concern\ninvolves the non-trivial risk of patient re-identiﬁcation26.E v e ni ft h ed a t a\ncollected undergo complete de-identiﬁcation, it has been shown that it is still\npossible that individuals can be re-identiﬁed by linking medical with other\nnon-medical available data27.\nBias and accountability\nWhile a clinician may be aware as to whether an AI algorithm is suitable for\nuse in a particular case of a speciﬁc patient, patient-driven use of LLMs for\nmedical decisions may be vulnerable to bias or bias in the training data\n3,4.F o r\nthat matter, OpenAI explicitly states in its terms of use that it assumes no\nresponsibility for the content generated by GPT\n28, making it clear that the\nburden of error falls entirely on the user. This inevitably poses the question\nof who will be held accountable in case of an inaccurate or inappropriate\noutput leading to harm, blurring the lines of accountability and\nresponsibility\n3.\nThus, if a patient adopts LLMs for medical advice, it is essential that she\ninvestigates the diversity of the employed LLM training data, and be\nappropriately cautious about that advice. Ensuring high visibility of LLMs\n(i.e., pertinent to their guidelines and warnings) and ensuring that users have\nsufﬁcient understanding of the effectiveness of these tools in order to assess\nthe reliability of their recommendations is of paramount importance.\nClinician responsibility\nLLMs may provide signiﬁcant beneﬁts to patients, as noted previously, but\nwill also require signiﬁcant oversight from clinicians to monitor for\nabnormalities, communicate with patients, and update treatment strategies\nbased upon new information. For clinicians and healthcare systems to\nincorporate these technologies into clinical practice, it will be necessary for\nthe administrative burden to be recognized by payers and compensated\nappropriately. This will be a major challenge for systems built on legacy\nwithout interoperability and adaptability\n5,29, and for smaller organizations\nthat may not have the resources to permit such transformations and\nmodernizations.\nLLM performance“Ups” and “Downs”\nWhile Google Search has been the most frequent outlet for patient-driven\nmedical learning and guidance, ChatGPT performed better than Google\nSearch when questioned on general medical knowledge. Importantly,\nhowever, it scored worse when it was asked healthcare-related\nrecommendations\n30.\nIn a study aimed at evaluating its ability to generate a differential\ndiagnosis (DDx) alone or as an aid to clinicians, a Google LLM optimized for\ndiagnostic reasoning evaluated in 302 challenging, real-worldNew England\nJournal of Medicinecase reports exhibited standalone performance that\nexceeded that of unassisted clinicians. The DDx score was higher for clin-\nicians assisted by the Google LLM compared to clinicians assisted by con-\nventional search engines and standard medical resources. Furthermore,\nclinicians assisted by the Google LLM arrived at more comprehensive dif-\nferential lists than those working without its assistance, suggesting that the\nL L Mc o u l de m p o w e rc l i n i c i a n sa n dp a t i e n t s’ access to specialist-level\nexpertise\n31.\nIncidentally, the prevailing view that the incessant LLM scale-up (i.e.,\nincrease of their complexity and data volume that have been trained, as well\nas computational infrastructure) will render them more potent andﬂexible\nhas not proven correct since larger and more instructable LLMs may have\nbecome less reliable in addressing areas of low difﬁculty\n32.I na d d i t i o n ,w h i l e\nearly LLMs often avoid user questions, scaled-up models tend to give a\nseemingly logical yet incorrect answer much more often, including errors on\ndifﬁcult questions that humans often overlook\n32. These observations\nunderscore the need for a new conceptualstrategy, design, and development\nof general-purpose AI, particularly in the high-valued healthcare area, where\na distribution of predictable errors is needed32.\nImportantly, the text generated by LLMs may also have the tendency to\nproduce hallucinations due to a variety of reasons, such as unreliable\nsources\n33, probabilistic generation34, biased training data35, insufﬁcient\ncontext34, and self-contradictions33. Researchers have suggested that these\nlimitations can be overcome by training these algorithms using datasets\nfrom healthcare domains, e.g., EHR data like GatorTron36,37, or LLM con-\nstraining using medical datasets like Med-PaLM 238 and Flan-PaLM39.\nConclusions\nThe World Health Organization has deﬁned equity as the absence of\navoidable, unfair, or remediable differences among groups of people, whether\nt h eg r o u p sa r ed eﬁned socially, economically, demographically, or\ngeographically40. In order for health equity to be achieved, every citizen should\nhave a reasonable opportunity to gainaccess to fully available healthcare.\nWhile application of AI in medicine has been proposed as the\n“democratizer” of health care, thus reducing worldwide disparities and\nimproving health equity, LLMs offer even a more radical transformation in\nthe delivery of health care by increasing patient agency in the patient-\nclinician relationship, and for theﬁrst time enabling patients to make\nmedical decisions by and for themselves. Additionally, LLMs may (i) shift\nfocus to health and prevention, empowering individuals to manage their\nhealth proactively, potentially reducing reliance on reactive, expensive\nhealthcare interventions; and (ii) expand access to personalized health\nsupport by providing continuous, affordable, and personalized health\ncoaching and monitoring to individuals, regardless of their location or\nsocioeconomic status. By contrast, such tectonic shifts in health care are not\ncoming without risks that may endanger patient well-being.\nThe implications of the aforementioned discussion in the clinician-\npatient relationship are as follows: (i)Healthcare is expected to become more\npatient-centered--Clinicians are expected to move beyond simply present-\ning “the best” medical option, and engage in shared decision-making,\nunderstanding and respecting patient values and practical limitations; (ii)\nDiscourse is key— Instructive, formal, extended and effective expression of\nthought is crucial for bridging the gap between clinical expertise and patient\nunderstanding, ensuring patients are truly informed to participate in\ncompromise and decision-making; (iii)“O p t i m a lc l i n i c a lc a r e”--From an\nLLM point of view,optimal careis a more nuanced concept, as it might be\nredeﬁned in the future to include not only medical effectiveness, but also\npatient satisfaction, adherence, and quality of life, acknowledging the\npatient’s perspective as integral to successful healthcare; and (iv)Training\nfor healthcare professionals needs to adapt to this rapidly changing envir-\nonment--Medical education needs to continue to emphasize communica-\ntion skills, shared decision-making techniques, and understanding patient\nperspectives, alongside traditional medical knowledge, but must do so in the\ncontext of this important element of the new health ecosystem. Thus, a\npositive and necessary shift in healthcare systems and philosophies towards\ngreater patient involvement and personalized approaches is evolving. It is,\ntherefore, crucial to acknowledge the complexity of balancing clinical\nexpertise with patient autonomy and to underscore the importance of open\ncommunication and shared decision-making in this evolving landscape.\nhttps://doi.org/10.1038/s41746-025-01598-y Perspective\nnpj Digital Medicine|           (2025) 8:258 4\nTherefore, LLMs hold further promise for democratizing healthcare by\nimproving access, affordability, and efﬁciency, and by breaking down lan-\nguage barriers and cultural competency. They can empower patients and\nclinicians alike, eliminate impediments to information and care, and poten-\ntially transform healthcare delivery, especially for underserved populations.\nThe challenges in integrating LLMs in the important patient-physician\nrelationship\n41 or in exclusive patient decision making involve the unleveled\nrelationships between patients, clinicians, and other healthcare profes-\nsionals, services, and systems, the failure to recognize the added value of\nhealth-literate patients, and the often observed conservative and inﬂexible\nhierarchical cultures that are resistant to change. Healthcare structures and\nsettings further contribute to the uneven relationships between patients and\nclinicians during shared decision making, which often result in failure to\nrecognize the patient’s experience and in building trust.\nIt appears that progressively LLMs will level patients’health literacy\nneeded to improve patient agency and autonomy, leading to improved\npatient-physician mutual acceptanceand respect. In order to augment the\nunderstanding of these ideas and theirassociated challenges, subsequent\nsteps should involve the close investigation of the events, patterns, and\nstructures identiﬁed as barriers to patient agency in this manuscript,\nrecognizing the irreplaceability of human medical professional knowledge\nand experience, while also emphasizing the importance of integrating AI\ntechnologies with human expertise.\nData availability\nNo datasets were generated or analyzed during the current study.\nReceived: 6 December 2024; Accepted: 30 March 2025;\nReferences\n1. Emirbayer, M. & Mische, A. What is agency?Am. J. Sociol.103,\nhttps://doi.org/10.1086/231294 (1998).\n2. Sewell, W. H. J. A Theory of Structure: Duality, Agency, and\nTransformation. Am. J. Sociol.98,1 – 29 (1992).\n3. Bazoukis, G. et al. The inclusion of augmented intelligence in\nmedicine: A framework for successful implementation.Cell Rep. Med.\n3, 100485 (2022).\n4. Armoundas, A. A. et al. Use of Artiﬁcial Intelligence in Improving\nOutcomes in Heart Disease: A Scientiﬁc Statement From the\nAmerican Heart Association.Circulation https://doi.org/10.1161/CIR.\n0000000000001201 (2024).\n5. Armoundas, A. A. et al. Data Interoperability for Ambulatory\nMonitoring of Cardiovascular Disease: A Scientiﬁc Statement From\nthe American Heart Association.Circ. Genom Precis. Med.17,\ne000095 (2024).\n6. Bota, P., Thambiraj, G., Bollepalli, S. C. & Armoundas, A. A. Artiﬁcial\nIntelligence Algorithms in Cardiovascular Medicine: An Attainable\nPromise to Improve Patient Outcomes or an Inaccessible\nInvestment?. Curr. Cardiol. Rep.https://doi.org/10.1007/s11886-\n024-02146-y (2024).\n7. Burton, J. W. et al. How large language models can reshape collective\nintelligence. Nat. Hum. Behav.8, 1643– 1655 (2024).\n8. Tam, T. Y. C. et al. A framework for human evaluation of large language\nmodels in healthcare derived from literature review.NPJ digital Med.\n7, 258 (2024).\n9. Garcia, B. T. et al. Improving Automated Deep Phenotyping Through\nLarge Language Models Using Retrieval Augmented Generation.\nmedRxiv https://doi.org/10.1101/2024.12.01.24318253 (2024).\n10. Li, W. et al. From Text to Translation: Using Language Models to\nPrioritize Variants for Clinical Review.medRxiv https://doi.org/10.\n1101/2024.12.31.24319792 (2024).\n11. Abbasian, M. et al. Foundation metrics for evaluating effectiveness of\nhealthcare conversations powered by generative AI.NPJ Digital Med.\n7, 82 (2024).\n12. Chen, L. C. et al. Assessing Large Language Models for Oncology\nData Inference From Radiology Reports.JCO Clin. Cancer Inf.8,\ne2400126 (2024).\n13. Goh, R. et al. Large language models can effectively extract stroke\nand reperfusion audit data from medical free-text discharge\nsummaries. J. Clin. Neurosci.129, 110847 (2024).\n14. Liu, X. H., Lu, Z. H., Wang, T. & Liu, F. Large language models\nfacilitating modern molecular biology and novel drug development.\nFront Pharm.15, 1458739 (2024).\n15. Sridharan, K. & Sivaramakrishnan, G. Unlocking the potential of\nadvanced large language models in medication review and\nreconciliation: A proof-of-concept investigation.Explor Res Clin. Soc.\nPharm. 15, 100492 (2024).\n16. Pearson, T. A. et al. The Science of Precision Prevention: Research\nOpportunities and Clinical Applications to Reduce Cardiovascular\nHealth Disparities.JACC Adv.\n3, https://doi.org/10.1016/j.jacadv.\n2023.100759 (2024).\n17. Wen, B. et al. Leveraging Large Language Models for Patient\nEngagement: The Power of Conversational AI in Digital Health.\nPreprint athttp://arxiv.org/abs/2406.13659 (2024).\n18. Aydin, S., Karabacak, M., Vlachos, V. & Margetis, K. Large language\nmodels in patient education: a scoping review of applications in\nmedicine. Front. Med.11, https://doi.org/10.3389/fmed.2024.\n1477898 (2024).\n19. Bok, A., Noone, D. & Skouw-Rasmussen, N. Patient agency: key\nquestions and challenges– A report from the 1st workshop of the EHC\nThink Tank Workstream on Patient Agency.J. Haemoph. Pract.9,\n27– 35 (2022).\n20. WHO. Improving health literacyhttps://www.who.int/activities/\nimproving-health-literacy (2024).\n21. EU. Making Europe Health Literate by 2025: Seven Actions to Promote\nHealth Literacy and Self-Care in the Digital Era.(EU, 2018-2019).\n22. Narayan, S. M. et al. Personalized Framework to Increase Access to\nDigital Health Technologies– Global Perspectives to Encode Health\nEquity. Nat. Rev. Cardiol.(2025). In Press\n23. Norman, C. D. & Skinner, H. A. eHealth Literacy: Essential Skills for\nConsumer Health in a Networked World.J. Med. Internet Res.8,e 9\n(2006).\n24. Singhal, K. et al. Large language models encode clinical knowledge.\nNature 620, 172– 180 (2023).\n25. Naik, N. et al. Legal and Ethical Consideration in Artiﬁcial Intelligence in\nHealthcare: Who Takes Responsibility?.Front. Surg.9, 862322 (2022).\n26. Spector-Bagdady, K. et al. Principles for Health Information\nCollection, Sharing, and Use: A Policy Statement From the American\nHeart Association.Circulation 148, 1061– 1069 (2023).\n27. El Emam, K., Jonker, E., Arbuckle, L. & Malin, B. A systematic review of\nre-identiﬁcation attacks on health data.PloS One6, e28071 (2011).\n28. OpenAI. Terms of usehttps://openai.com/en-GB/policies/row-terms-\nof-use/ (2024).\n29. Chahal, C. A. A. et al. Data Interoperability and Harmonization in\nCardiovascular Genomic and Precision Medicine.Circ. GPM, (2025).\nIn Press\n30. Ayoub, N. F., Lee, Y. J., Grimm, D. & Divi, V. Head-to-Head\nComparison of ChatGPT Versus Google Search for Medical\nKnowledge Acquisition.Otolaryngol. Head. Neck Surg.170,\n1484– 1491 (2024).\n31. McDuff, D. et al. Towards accurate differential diagnosis with large\nlanguage models. Preprint athttp://arxiv.org/abs/2312.00164 (2023).\n32. Zhou, L. et al. Larger and more instructable language models become\nless reliable.\nNature 634,6 1– 68 (2024).\n33. Manakul, P., Liusie, A. & Gales, M. J. F. Zero-resource blackbox\nhallucination detection for generative large language models. Preprint\nat http://arxiv.org/abs/2303.08896 (2023).\n34. Salvagno, M., Taccone, F. & Gerli, A. Artiﬁcial intelligence\nhallucinations. Crit. Care27,1 – 2 (2023).\nhttps://doi.org/10.1038/s41746-025-01598-y Perspective\nnpj Digital Medicine|           (2025) 8:258 5\n35. Mbakwe, A., Lourentzou, I., Celi, L., Mechanic, O. & Dagan, A.\nChatGPT passing USMLE shines a spotlight on theﬂaws of medical\neducation. PLOS Digital Health2, e0000205 (2023).\n36. Kraljevic, Z. et al. Foresight -- Generative Pretrained Transformer\n(GPT) for Modelling of Patient Timelines using EHRs. Preprint athttp://\narxiv.org/abs/2212.08072 (2023).\n37. Yang, X. et al. Gatortron: A large clinical language model to unlock\npatient information from unstructured electronic health records.\nPreprint athttp://arxiv.org/abs/2203.03540 (2022).\n38. Singhal, K. et al. Towards expert-level medical question answering\nwith large language models. Preprint athttp://arxiv.org/abs/2305.\n09617 (2023).\n39. Chung, H. W. et al. Scaling instruction-ﬁnetuned language models.\nPreprint athttp://arxiv.org/abs/2210.11416 (2022).\n40. WHO. Closing the health equity gap: Policy options and opportunities\nfor action, (WHO, 2013).\n41. Cudjoe, T. K. M. & Kotwal, A. A. Can Machine Learning Help Us\nUnderstand Social Connection and Its Impact on Health?.JAMA\nNetw. Open7, e2451545– e2451545 (2024).\nAcknowledgements\nA.A.A. is funded, in part, by the Institute of Precision Medicine\n(17UNPG33840017) of the American Heart Association, the RICBAC\nFoundation, NIH grants 1 R01 HL135335-01, 1 R01 HL161008-01, 1 R21\nHL137870-01, 1 R21EB026164-01 and 3R21EB026164-02S1. J.L. is fun-\nded, in part, by NIH grants 5 R01 HL155107, 1 R01 HL166137, and U01\nHG007691; by American Heart Association grants AHA957729 and\nAHA24MERIT1185447; and EU Horizon Health 2021 grant 101057619.\nAuthor contributions\nA.A.A. and J.L. wrote the manuscript. Both authors have reviewed the\nmanuscript.\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nCorrespondenceand requests for materials should be addressed to\nAntonis A. Armoundas.\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nPublisher’s noteSpringer Nature remains neutral with regard to jurisdictional\nclaims in published maps and institutional afﬁliations.\nOpen AccessThis article is licensed under a Creative Commons\nAttribution-NonCommercial-NoDerivatives 4.0 International License,\nwhich permits any non-commercial use, sharing, distribution and\nreproduction in any medium or format, as long as you give appropriate\ncredit to the original author(s) and the source, provide a link to the Creative\nCommons licence, and indicate if you modiﬁed the licensed material. You\ndo not have permission under this licence to share adapted material\nderived from this article or parts of it. The images or other third party\nmaterial in this article are included in the article’s Creative Commons\nlicence, unless indicated otherwise in a credit line to the material. If material\nis not included in the article’s Creative Commons licence and your intended\nuse is not permitted by statutory regulation or exceeds the permitted use,\nyou will need to obtain permission directly from the copyright holder. To\nview a copy of this licence, visithttp://creativecommons.org/licenses/by-\nnc-nd/4.0/\n.\n© The Author(s) 2025\nhttps://doi.org/10.1038/s41746-025-01598-y Perspective\nnpj Digital Medicine|           (2025) 8:258 6",
  "topic": "Equity (law)",
  "concepts": [
    {
      "name": "Equity (law)",
      "score": 0.6682372093200684
    },
    {
      "name": "Agency (philosophy)",
      "score": 0.5131283402442932
    },
    {
      "name": "Encoding (memory)",
      "score": 0.4839085042476654
    },
    {
      "name": "Business",
      "score": 0.38531798124313354
    },
    {
      "name": "Computer science",
      "score": 0.3637896776199341
    },
    {
      "name": "Artificial intelligence",
      "score": 0.1755467653274536
    },
    {
      "name": "Political science",
      "score": 0.17506253719329834
    },
    {
      "name": "Sociology",
      "score": 0.12732353806495667
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Social science",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I107606265",
      "name": "Broad Institute",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I136199984",
      "name": "Harvard University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210087915",
      "name": "Massachusetts General Hospital",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I63966007",
      "name": "Massachusetts Institute of Technology",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I1283280774",
      "name": "Brigham and Women's Hospital",
      "country": "US"
    }
  ]
}