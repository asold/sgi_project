{
  "title": "Enabling action crossmodality for a pretrained large language model",
  "url": "https://openalex.org/W4394989737",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5095821157",
      "name": "Anton Caesar",
      "affiliations": [
        "Hamburg University of Technology",
        "Universität Hamburg"
      ]
    },
    {
      "id": "https://openalex.org/A2114573405",
      "name": "Ozan Ozdemir",
      "affiliations": [
        "Hamburg University of Technology",
        "Universität Hamburg"
      ]
    },
    {
      "id": "https://openalex.org/A2120270348",
      "name": "Cornelius Weber",
      "affiliations": [
        "Universität Hamburg",
        "Hamburg University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2184296992",
      "name": "Stefan Wermter",
      "affiliations": [
        "Universität Hamburg",
        "Hamburg University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5095821157",
      "name": "Anton Caesar",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2114573405",
      "name": "Ozan Ozdemir",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2120270348",
      "name": "Cornelius Weber",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2184296992",
      "name": "Stefan Wermter",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W6810334672",
    "https://openalex.org/W6640773114",
    "https://openalex.org/W6851009546",
    "https://openalex.org/W6810081322",
    "https://openalex.org/W6929472799",
    "https://openalex.org/W6850503672",
    "https://openalex.org/W6842751340",
    "https://openalex.org/W6796581206",
    "https://openalex.org/W6809509765",
    "https://openalex.org/W4224912544",
    "https://openalex.org/W6794127432",
    "https://openalex.org/W6746635820",
    "https://openalex.org/W6850890382",
    "https://openalex.org/W6735377749",
    "https://openalex.org/W6849898756",
    "https://openalex.org/W4321493657",
    "https://openalex.org/W3195535318",
    "https://openalex.org/W6769627184",
    "https://openalex.org/W6838557027",
    "https://openalex.org/W6839500177",
    "https://openalex.org/W6843759960",
    "https://openalex.org/W4361216821",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W6852999659",
    "https://openalex.org/W6800875267",
    "https://openalex.org/W4388999655",
    "https://openalex.org/W4389665575",
    "https://openalex.org/W3205423339",
    "https://openalex.org/W4377164404",
    "https://openalex.org/W1566405224",
    "https://openalex.org/W4321177655",
    "https://openalex.org/W4366850747",
    "https://openalex.org/W4385430679",
    "https://openalex.org/W4303648971",
    "https://openalex.org/W1861492603",
    "https://openalex.org/W4307323375",
    "https://openalex.org/W4311642023",
    "https://openalex.org/W4226107112",
    "https://openalex.org/W4323537342",
    "https://openalex.org/W4323667155",
    "https://openalex.org/W4318718936",
    "https://openalex.org/W4385473486",
    "https://openalex.org/W1583837637",
    "https://openalex.org/W4225323055",
    "https://openalex.org/W4319988532",
    "https://openalex.org/W4385327621",
    "https://openalex.org/W4229005866",
    "https://openalex.org/W4247924304",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4378174011",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4226177592",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W4307079201"
  ],
  "abstract": "Natural language processing and vision tasks have seen large improvements recently through the rise of Transformer architectures. The high performing large language models (LLMs) benefit from large textual datasets that are numerously available online. However, action and bidirectional action-language tasks are less developed, as these require more specific and labelled data. Therefore, we aim at enabling these robotic action capabilities for a pretrained LLM, while maintaining high efficiency with regards to the required training time and data size. To achieve this, we split up a Transformer-based LLM and insert a multimodal architecture into it. Specifically, we split a pretrained T5 LLM between its encoder and decoder parts, to insert a crossmodal Transformer component of a Paired Transformed Autoencoders (PTAE) bidirectional action-language model. The experiments are conducted on a new dataset, consisting of unimodal language translation and crossmodal bidirectional action-language translation. The natural language capabilities of the original T5 are reestablished efficiently by training the crossmodal Transformer, which requires only one 5.7 millionth of the T5 model's original training data. Furthermore, the new model, called CrossT5, achieves high accuracy for the vision and language guided robotic action tasks. By design, the CrossT5 agent acts robustly when tested with language commands not included in the dataset. The results demonstrate that this novel approach is successful in combining the advanced linguistic capabilities of LLMs with the low-level robotic control skills of vision-action models. The code is available at this URL: https://github.com/samsoneko/CrossT5.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8148578405380249
    },
    {
      "name": "Transformer",
      "score": 0.7073954343795776
    },
    {
      "name": "Machine translation",
      "score": 0.5183538198471069
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5143297910690308
    },
    {
      "name": "Natural language processing",
      "score": 0.48580193519592285
    },
    {
      "name": "Crossmodal",
      "score": 0.4799899756908417
    },
    {
      "name": "Language model",
      "score": 0.4622369408607483
    },
    {
      "name": "Encoder",
      "score": 0.45184987783432007
    },
    {
      "name": "Natural language",
      "score": 0.4484748840332031
    },
    {
      "name": "Speech recognition",
      "score": 0.3857255280017853
    },
    {
      "name": "Human–computer interaction",
      "score": 0.36313748359680176
    },
    {
      "name": "Visual perception",
      "score": 0.14286914467811584
    },
    {
      "name": "Perception",
      "score": 0.13769656419754028
    },
    {
      "name": "Engineering",
      "score": 0.08971092104911804
    },
    {
      "name": "Psychology",
      "score": 0.07579401135444641
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I884043246",
      "name": "Hamburg University of Technology",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I159176309",
      "name": "Universität Hamburg",
      "country": "DE"
    }
  ],
  "cited_by": 3
}