{
    "title": "Large Language Models for Intent-Driven Session Recommendations",
    "url": "https://openalex.org/W4389762725",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2133977345",
            "name": "Sun Zhu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2225103864",
            "name": "Liu Hongyang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2061122083",
            "name": "Qu, Xinghua",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2367276253",
            "name": "Feng Kai-dong",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1967442656",
            "name": "WANG Yan",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2004222228",
            "name": "Ong Yew Soon",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4387848851",
        "https://openalex.org/W2626454364",
        "https://openalex.org/W4387561141",
        "https://openalex.org/W4367046963",
        "https://openalex.org/W2964694324",
        "https://openalex.org/W4284702430",
        "https://openalex.org/W4250607653",
        "https://openalex.org/W3094495518",
        "https://openalex.org/W4306317036",
        "https://openalex.org/W4388481614",
        "https://openalex.org/W3098231197",
        "https://openalex.org/W4224940316",
        "https://openalex.org/W3101707147",
        "https://openalex.org/W4362706980",
        "https://openalex.org/W4379093238",
        "https://openalex.org/W2795199972",
        "https://openalex.org/W4384641232",
        "https://openalex.org/W3183393276",
        "https://openalex.org/W4213298164",
        "https://openalex.org/W4386728933",
        "https://openalex.org/W4283700788",
        "https://openalex.org/W2964926209",
        "https://openalex.org/W4224325635",
        "https://openalex.org/W2469952266",
        "https://openalex.org/W4367047075",
        "https://openalex.org/W2971196067",
        "https://openalex.org/W2746011824",
        "https://openalex.org/W3080292067",
        "https://openalex.org/W4367047034",
        "https://openalex.org/W2171279286",
        "https://openalex.org/W4386729281",
        "https://openalex.org/W4224324925",
        "https://openalex.org/W4364380022",
        "https://openalex.org/W4284713631",
        "https://openalex.org/W2963367478",
        "https://openalex.org/W2964044287",
        "https://openalex.org/W3178328486",
        "https://openalex.org/W4292719636",
        "https://openalex.org/W4281483047",
        "https://openalex.org/W4368755500",
        "https://openalex.org/W2512965516",
        "https://openalex.org/W4388184858",
        "https://openalex.org/W4387846600",
        "https://openalex.org/W1652763299",
        "https://openalex.org/W4384656781",
        "https://openalex.org/W4321485796",
        "https://openalex.org/W3172512543",
        "https://openalex.org/W4386729952",
        "https://openalex.org/W4376654514",
        "https://openalex.org/W4385966010",
        "https://openalex.org/W4389520756",
        "https://openalex.org/W4299286960",
        "https://openalex.org/W3173365306",
        "https://openalex.org/W4386081001",
        "https://openalex.org/W2937556626",
        "https://openalex.org/W4284686273",
        "https://openalex.org/W3106433415",
        "https://openalex.org/W3101201690",
        "https://openalex.org/W3166827814",
        "https://openalex.org/W4386728930",
        "https://openalex.org/W1553290137"
    ],
    "abstract": "Intent-aware session recommendation (ISR) is pivotal in discerning user intents within sessions for precise predictions. Traditional approaches, however, face limitations due to their presumption of a uniform number of intents across all sessions. This assumption overlooks the dynamic nature of user sessions, where the number and type of intentions can significantly vary. In addition, these methods typically operate in latent spaces, thus hinder the model's transparency.Addressing these challenges, we introduce a novel ISR approach, utilizing the advanced reasoning capabilities of large language models (LLMs). First, this approach begins by generating an initial prompt that guides LLMs to predict the next item in a session, based on the varied intents manifested in user sessions. Then, to refine this process, we introduce an innovative prompt optimization mechanism that iteratively self-reflects and adjusts prompts. Furthermore, our prompt selection module, built upon the LLMs' broad adaptability, swiftly selects the most optimized prompts across diverse domains. This new paradigm empowers LLMs to discern diverse user intents at a semantic level, leading to more accurate and interpretable session recommendations. Our extensive experiments on three real-world datasets demonstrate the effectiveness of our method, marking a significant advancement in ISR systems.",
    "full_text": "Large Language Models for Intent-Driven Session\nRecommendations\nZhu Sun1,2,âˆ—, Hongyang Liu3,âˆ—, Xinghua Qu4,â€ , Kaidong Feng5, Yan Wang3, Yew-Soon Ong1,6\n1Center for Frontier AI Research, A*STAR, Singapore\n2 Institute of High Performance Computing, A*STAR, Singapore\n3Macquarie University, Australia\n4Shanda Group AI Lab, Singapore\n5Yan Shan University, China\n6Nanyang Technological University, Singapore\n* denotes co-first authors; â€ denotes corresponding author: teddy.qu@shanda.com\nABSTRACT\nIntent-aware session recommendation (ISR) is pivotal in discerning\nuser intents within sessions for precise predictions. Traditional\napproaches, however, face limitations due to their presumption of\na uniform number of intents across all sessions. This assumption\noverlooks the dynamic nature of user sessions, where the number\nand type of intentions can significantly vary. In addition, these\nmethods typically operate in latent spaces, thus hinder the modelâ€™s\ntransparency. Addressing these challenges, we introduce a novel\nISR approach, utilizing the advanced reasoning capabilities of large\nlanguage models (LLMs). First, this approach begins by generating\nan initial prompt that guides LLMs to predict the next item in a\nsession, based on the varied intents manifested in user sessions.\nThen, to refine this process, we introduce an innovative prompt\noptimization mechanism that iteratively self-reflects and adjusts\nprompts. Furthermore, our prompt selection module, built upon\nthe LLMsâ€™ broad adaptability, swiftly selects the most optimized\nprompts across diverse domains. This new paradigm empowers\nLLMs to discern diverse user intents at a semantic level, leading\nto more accurate and interpretable session recommendations. Our\nextensive experiments on three real-world datasets demonstrate\nthe effectiveness of our method, marking a significant advancement\nin ISR systems.\nCCS CONCEPTS\nâ€¢ Information systems â†’Recommender systems; â€¢ Comput-\ning methodologies â†’Neural networks .\nKEYWORDS\nSession-based Recommendation, User Intents, Large Language Mod-\nels, Prompt Optimization\n1 INTRODUCTION\nSession-based recommendation (SR) [5, 14, 20, 25, 57] aims to pre-\ndict the next interacted item based on short anonymous behavior\nsessions. Typically, different sessions may unveil diverse user in-\ntents [50]. Figure 1 illustrates two real sessions in Amazon Elec-\ntronic dataset [34], where the first session in (a) reflects one main\npurpose, i.e., shopping for laptop and accessories, whereas the sec-\nond one in (b) is associated with two major intents, i.e., shopping\nfor laptop protectors and camera accessories, respectively. However,\nmost public datasets do not include explicit intents of a session as\n(a) Session 1 - Laptop and accessories \n(b) Session 2 - Laptop protectors in green border and camera accessories in pink border  \nFigure 1: Examples of user sessions with various intents.\nit may be intrusive and disruptive to ask users about their current\nsession purposes directly [35]. Hence, intent-aware session recom-\nmendation (ISR) has emerged to capture the latent user intents\nwithin a session, thus enhancing the accuracy of SR.\nSpecifically, early studies in ISR [26, 32, 51] primarily constrain\nsessions to a single purpose or goal, such as shopping for a laptop\nand accessories in Figure 1(a). However, this simplistic assumption\ndoesnâ€™t always hold in real-world scenarios, where a session may in-\nvolve diverse items for various purposes, as illustrated in Figure 1(b).\nIt thus poses barriers for such methods seeking further performance\nimprovements. Consequently, various approaches have been devel-\noped to model multiple intentions within a session, e.g., IDSR [9],\nMCPRN [50], and NirGNN [ 23]. Despite the success, they suffer\nfrom two major limitations. First, they rely on an unrealistic as-\nsumption that all sessions possess a consistent and fixed number\nof intentions, treating this as a hyper-parameter. Second, they are\nlimited to learning latent intentions solely within the embedding\nspace, greatly impeding the transparency of ISR. Such limitations\nthus further hinder these approaches from delivering more accurate\nand comprehensible recommendations.\nFortunately, the rise of large language models (LLMs) has opened\nup unprecedented opportunities in the field of ISR. LLMs, armed\nwith advanced reasoning capabilities, have found widespread ap-\nplication in general recommendation scenario [4, 11, 16, 43], but\nhave been relatively underexplored in the context of SR. In the\nlimited body of research on SR, LLMs are generally employed in\ntwo distinct ways, namely in-context learning (ICL) [21, 49] and\nparameter-efficient fine-tuning [3, 64]. However, LLMs cannot fully\nrealize their potential through simple ICL (e.g., zero-shot prompt-\ning [49]). While fine-tuning LLMs holds promise, it grapples with\nchallenges stemming from computational demands and the avail-\nability of open-source LLMs.\narXiv:2312.07552v1  [cs.CL]  7 Dec 2023\nZhu Sun et al.\nTherefore, we propose a simple yet effective paradigm to exploit\nthe power of LLMs for more effective ISR from the perspective of\nprompt optimization (abbreviated as PO4ISR). It is equipped with\nPrompt Initialization (PromptInit), Prompt Optimization (Promp-\ntOpt), and Prompt Selection (PromptSel). In particular, PromptInit\naims to create an initial prompt that guides LLMs to dynamically\nunderstand session-level user intents, and predict the next item\naccordingly. Inspired by the study on automatic prompt optimiza-\ntion [38] in natural language processing (NLP), PromptOpt seeks\nto automatically optimize the initial prompt with self-reflection. To\nbe specific, the LLM is required to offer reasoning rooted in the\nidentified errors to improve (refine and augment) the initial prompt.\nThe performance of improved prompts is then assessed with UCB\nbandits [1], thereby helping shortlist promising prompt candidates\nfor an iterative optimization. Lastly, PromptSel prioritizes the selec-\ntion of optimized prompts by utilizing the robust generalizability\nof LLMs across diverse domains, aiming to maximize accuracy im-\nprovements. As such, PO4ISR can efficiently direct LLMs to infer\nand comprehend dynamic user intents at a semantic level, resulting\nin more accurate and understandable SR.\nContributions. Our main contributions lie three-fold. (1) We in-\ntroduce a simple yet powerful paradigm â€“ PO4ISRâ€“ to utilize the\ncapabilities of LLMs for enhanced ISR through prompt optimization.\n(2) The PO4ISR paradigm, composed of prompt initialization, opti-\nmization, and selection modules, empowers LLMs to semantically\ncomprehend varying user intents in a session, resulting in more\naccurate and comprehensible SR. (3) Experiments on real-world\ndatasets demonstrate that PO4ISR significantly outperforms base-\nlines with an average improvement of 57.37% and 61.03% on HR\nand NDCG, respectively. Meanwhile, several insightful observa-\ntions are gained, for example, (a) PO4ISR yields promising accuracy\nwith only a small number of training samples; (b) PO4ISR exhibits\nadvanced generalizability and excels in cross-domain scenarios;\n(c) PO4ISR showcases superior strength on sparser datasets with\nshorter sessions compared; however, it might exhibit increased hal-\nlucination tendencies with sparser datasets; (d) the performance of\nPO4ISR shows a positive correlation with the quality of the initial\nprompt, and lower-quality initial prompts tend to yield more signif-\nicant improvements; and (f) a streamlined description and subtask\ndivision can enhance the quality of initial prompts.\n2 RELATED WORK\nWe first provide an overview of the development of session-based\nrecommendation (SR). Then, intent-aware session recommendation\n(ISR) is introduced, followed by the LLM-based SR.\n2.1 Session-based Recommendation\nEarly works employ conventional methods, such as frequent sequen-\ntial patterns [2, 60], session-level item-similarity (e.g., SKNN [22,\n33]), Markov chain (e.g., FPMC [42]) and random walk [10]. Later,\nrecurrent neural networks (RNN) have been applied to handle longer\nsequences assuming that adjacent items in a session are sequen-\ntially dependent. GRU4Rec [18] is the representative model, which\nhas been further extended using, e.g., data augmentation [48, 52],\nnew losses [17], parallel architecture with item features [19], and\ncross-session information transfer [41]. Subsequently, the attention\nmechanism has been introduced in SR to relax this assumption\nby emphasizing more informative items in sessions [44], such as\nNARM [26] and STAMP [32]1. To better model the high-order transi-\ntion among items, graph neural network (GNN) based methods have\nbeen recently designed to generate more accurate item embeddings\nfrom the session graph, such as SR-GNN [ 54], FGNN [ 40], GC-\nSAN [56], GSL4Rec [53], GNG-ODE [13], KMVG [6], and ADRL [7].\nBesides, many studies propose to better leverage both the intra-\nand inter-session information, e.g., GCE-GNN [51], HG-GNN [36],\nDGNN [12], SPARE [37], CGSR [62], and HADCG [45]. Meanwhile,\nother works (e.g., ğ‘†2-DHCN [55] and CoHHN [66]) employ hyper-\ngraphs to enhance item representations for SR.\n2.2 Intent-aware Session Recommendation\nAn essential line of research learns the intents hidden in the session\nfor accurate SR. Early studies assume items inside a session are\nassociated with one (implicit) purpose. In particular, NARM [26]\nextracts the last hidden state as the session representation and ap-\nplies an attention mechanism on all hidden states to learn the userâ€™s\nintention. STAMP [32] explicitly emphasizes the current interest re-\nflected by the last click to capture the hybrid features of current and\ngeneral interests from previous clicks via an attention network. SR-\nGNN [54], GC-SAN [56], GCE-GNN [51] and TAGNN [63] model\neach session as graph-structured data and apply GNN to learn the\nrepresentations of user intents with attention networks. LESSR [8]\nlearns local and global interests to represent user intent by easing\nthe information loss issue. MSGAT [39] uses similar sessions to ef-\nficiently generate the session intent representation. Nonetheless, a\nsession may encompass items with varying intentions. Thus, solely\nmodeling the main intent could lead to information loss, potentially\nhurting the performance of SR.\nConsequently, recent studies endeavor to learn multiple intents\nfor more effective SR. Specifically, NirGNN [23] learns dual intents\nby exploiting attention mechanisms and data distribution in the ses-\nsion graph. MCPRN [50] designs mixture-channel purpose routing\nnetworks to detect the purposes of each item in a session and assign\nthem to the corresponding channels. IDSR [9] projects the item rep-\nresentation into multiple spaces indicating various intentions and\nemploys self-attention within each space to capture distinct inten-\ntions. HIDE [29] splits an item embedding into multiple chunks to\nrepresent various intentions and then organizes items in a session\nwith hyperedges to help learn the associated intents. MIHSG [12]\nand Atten-Mixer [65] learn multi-granularity consecutive user in-\ntents to generate more accurate session representations. STAGE [28]\nand ISCON [35] capture the impact of multiple intrinsic intents\nfor better SR. DAGNN [58] extracts session demands over the item\ncategory space to capture semantically correlated categories. How-\never, they make an impractical assumption that all sessions have a\nuniform and fixed number of intentions. Moreover, most of them\ncan only learn latent intents, thus restricting the transparency of SR.\nIn contrast, we aim to leverage the advanced reasoning capabilities\nof LLMs to uncover varying numbers of semantic intents within a\nsession for more accurate and comprehensible SR.\n1Our study focuses on session-based recommendation. Therefore, some popular\nsequential-based recommendation approaches, e.g., Bert4Rec [46] and SASRec [24]\nare out of our scope. Please refer to [61] for the detailed difference between session-\nand sequential-based recommendation.\nLLMs for Intent-Driven Session Recommendation\nLLM\nInitial Prompt\nPrompt 1\nInput Data\nPrompt 2\nError CaseError CaseError Case\nPrompt Initilization\nCollect Error Cases\nInfer Reasons\nPrompt 3\nLLM\nInfer Reasons\nRefine Prompt\nPrompt 4\nLLM\nRefined Prompt\nPrompt 5\nRefine\nPrompt\nAugment Prompt\nPrompt 6\nAugment Prompt\nLLM\nAugmented Prompt\nPrompt 7\nRefined Prompt\nPrompt 5\nImproved PromptsEvaluate\nPrompts\nOptimal Prompt\nTop-1\nOptimal Prompt\nTop-\nOptimized Prompts\nIteratively\nUpdate\nUCB\nBandits\nsamplesamplesample\nOptimal Prompt\nBundle: Top-1\nOptimal Prompt\nGames: Top-1\nOptimal Prompt\nML-1M: Top-1\nBundleGamesML-1M\nCross-Domain Prompt Selection\nOptimal Prompt\nGames: Top-1\nTraining\nSessions\nTraining\nSessions\nTraining\nSessions\nFigure 2: The overall architecture of our proposed PO4ISR paradigm.\n2.3 LLM-based Session Recommendation\nLLMs have achieved remarkable achievements for general recom-\nmendation [4, 11, 16, 43]. To the best of our knowledge, NIR [49]\nis the only one that adopts zero-shot prompting for SR, and most\nmethods target sequential recommendation [ 15]. Among them,\nsome leverage the in-context learning (ICL) capability of LLMs,\nfor instance, Hou et al. [21] use LLMs as rankers by designing se-\nquential, recency-based and ICL prompting. Others align LLMs for\nrecommendation via parameter-efficient fine-tuning. To be specific,\nBIGRec [3] employ LLMs in an all-rank scenario by grounding LLMs\nto the recommendation and actual item spaces. TransRec [30] iden-\ntifies fundamental steps of LLM-based recommendation to bridge\nthe item and language spaces. GPT4Rec [ 27] generates multiple\nqueries given item titles in a userâ€™s history with beam search and\nthen retrieves items for recommendation by searching these queries\nwith a search engine. LlamaRec [64] uses an ID-based sequential rec-\nommender as the retriever to generate candidates and then designs\na verbalizer to transform LLM output as the probability distribution\nfor ranking. Moreover, RecInterpreter [59] examines the capacity\nof LLMs to decipher the representation space of sequential recom-\nmenders with sequence-recovery and -residual tasks.\nHowever, the potential of LLMs cannot be utilized solely through\nsimple ICL (e.g., [49]). While fine-tuning LLMs for recommendation\nshows promising results, it is constrained by the computational\ndemands and availability of open-source LLMs. Instead, we intro-\nduce a new paradigm for ISR by automatically optimizing prompts,\nwhich efficiently guides LLMs to semantically comprehend the vary-\ning user intents within a session, thereby enhancing the accuracy\nand understandability of SR.\n3 THE PROPOSED METHOD\nThis section introduces the PO4ISR paradigm, a simple yet power-\nful framework inspired by the work [38] in the area of NLP. It is\nspecifically designed to efficiently guide LLMs in comprehending\nvarying user intents at a semantic level, with the goal of enhancing\nthe accuracy and transparency of SR.\nFramework Overview. Figure 2 illustrates the overall framework,\nmainly composed of three key components. Specifically, Prompt Ini-\ntialization (PromptInit) is tasked with generating an initial prompt\nthat directs LLMs in dynamically comprehending semantic user\nintents at the session level within a session. Subsequently, Prompt\nOptimization (PromptOpt) aims to evaluate, refine, augment, and\noptimize the initial prompt through self-reflection (i.e., inferring\nreasons from the collected error cases). Lastly, Prompt Selection\n(PromptSel) is designed to properly select optimized prompts by ex-\nploiting the robust generalizability of LLMs across diverse domains,\nthus maximizing the accuracy enhancements of SR.\n3.1 Prompt Initialization (PromptInit)\nGiven a session, we first create an initial prompt for the task de-\nscription. It seeks to guide LLMs in understanding the varying\nuser intents at the semantic level, which thus empowers LLMs to\nmake more accurate and comprehensible recommendations. The\ntask description is demonstrated in Prompt 1 which divides the\nSR task into four subtasks by using the planning strategy [ 67].\nThen, Prompt 1 is used to guide ChatGPT2 to predict the next item\nbased on the historical (training) user sessions fed by Prompt 2. For\nease of understanding, we take one training session as an example,\nthat is, the current session interactions: [1. \"Zenana Womenâ€™s Cami\nSets\", 2. \"Monster Tattoos\", 3. \"I Love You This Much Funny T-rex\nAdult T-shirt\", 4. \"Breaking Bad Menâ€™s Logo T-Shirt\", 5. \"Sofia the\nFirst Sofiaâ€™s Transforming Dress\", 6. \"Lewis N. Clark 2-Pack Neon\nLeather Luggage Tag\", 7. \"Russell Athletic Womenâ€™s Stretch Capri\",\n8. \"US Traveler New Yorker 4 Piece Luggage Set Expandable\", 9. \"Soffe\nJuniors Football Capri\"]. The target (ground truth) item \"Itâ€™s You\nBabe Mini Cradle, Medium\" is ranked at position 19 out of 20 items\n2Without a further statement, it is based on GPT-3.5-turbo.\nZhu Sun et al.\nin the candidate set. After using the initial prompt, the target item\nholds the 16th position in the re-ranked candidate set.\n3.2 Prompt Optimization (PromptOpt)\nPromptOpt strives to evaluate, refine, augment, and optimize the\ninitial task description prompt with an iterative self-reflection. The\ndetailed process is elaborated in what follows.\nCollecting Error Cases . We randomly sample a batch ( ğ‘ğ‘¡) of\nsessions from training sessions (ğ‘) and guide ChatGPT to predict\nthe next items with the initial prompts. Afterwards, we evaluate\nthe recommendation outcomes, considering sessions where the\ntarget item ranks in the bottom half of the re-ranked candidate set\nas error cases. Following this rule, the example session mentioned\nin Section 3.1 is an error case, since the ranking position of the\ntarget item by using the initial prompt is 16 out of 20 candidates.\nThese error cases, indicating that the corresponding prompts do not\neffectively guide LLMs in performing the SR task, will be utilized\nto further refine the prompts. We use ğ‘ğ‘’ (0 â‰¤ğ‘ğ‘’ â‰¤ğ‘ğ‘¡) to denote\nthe total number of such error cases for each batch.\nInferring Reasons. Understanding the reasons behind these col-\nlected error cases would greatly aid in refining the prompts, conse-\nquently enhancing recommendation performance. Thus, we lever-\nage the self-reflection ability of ChatGPT, that is, asking ChatGPT\nto reconsider and offer justifications rooted in the identified errors.\nInspired by [38], we adopt Prompt 3 to generate ğ‘ğ‘Ÿ reasons for\neach of the ğ‘ğ‘’ error cases, where the â€˜error_caseâ€™ includes the user\nsession and candidate item set. Below demonstrates the generated\nreasons for one error case.\nâ€¢ One reason why the prompt could have gotten these examples\nwrong is that it assumes that the userâ€™s interactive intent can be\naccurately inferred based solely on the items within each combina-\ntion. However, the prompt does not provide any information about\nthe userâ€™s preferences, tastes, or previous interactions. Without this\ncontext, it is difficult to accurately infer the userâ€™s intent from the\nitems alone.\nâ€¢ Another reason is that the prompt does not specify how the combi-\nnations of items within the session should be discovered. It assumes\nthat the combinations are already known and provided as input.\nHowever, in real-world scenarios, discovering meaningful combina-\ntions of items from a userâ€™s session interactions can be a complex\ntask. The prompt does not provide any guidance on how to perform\nthis discovery process, which can lead to incorrect results.\nRefining Prompts. With the inferred ğ‘ğ‘Ÿ reasons for each error\ncase, we now ask ChatGPT to refine the current prompt accordingly\nusing Prompt 4. One example of the refined prompt is illustrated as\nPrompt 5. By comparing the initial task description (Prompt 1) and\nthe refined Prompt 5, we can easily note that the initial prompt is\nimproved by considering two aspects: (1) user preference and taste\nand (2) the definition of item combinations. These two aspects are\nexactly consistent with the inferred reasons by ChatGPT.\nAugmenting Prompts. With the refined prompts, we further ask\nChatGPT to augment prompts (Prompt 7 is an example of aug-\nmentation) with the same semantic meanings using Prompt 6. Ac-\ncordingly, for the ğ‘ğ‘’ error cases, we finally obtain 2ğ‘ğ‘’ improved\nprompts through refinement and augmentation. These prompts\nwill be further utilized for an iterative optimization based on their\nrecommendation performance, as introduced in what follows.\nPrompt 1: Task Description\nBased on the userâ€™s current session interactions, you need to\nanswer the following subtasks step by step:\n1 Discover combinations of items within the session, where\nthe size of combinations can be one or more.\n2 Based on the items within each combination, infer the\nuserâ€™s interactive intent for each combination.\n3 Select the intent from the inferred ones that best represent\nthe userâ€™s current preferences.\n4 Based on the selected intent, please rerank the items in\nthe candidate set according to the possibility of potential\nuser interactions and show me your ranking results with\nthe item index.\nNote that the order of all items in the candidate set must\nbe provided, and the items for ranking must be within the\ncandidate set.\nPrompt 2: Input Data\nCurrent session interactions: {[idx. \"item title\", ... ]}\nCandidate item set: {[idx. \"item title\", ... ]}\nPrompt 3: Inferring Reasons for Errors\nIâ€™m trying to write a zero-shot recommender prompt.\nMy current prompt is {prompt}.\nBut this prompt gets the following example wrong: {er-\nror_case}, give {ğ‘ğ‘Ÿ} reasons why the prompt could have gotten\nthis example wrong.\nWrap each reason with <START> and <END>.\nPrompt 4: Refining Prompts with Reasons\nIâ€™m trying to write a zero-shot recommender prompt.\nMy current prompt is {prompt}.\nBut this prompt gets the following example wrong: {er-\nror_case}.\nBased on the example the problem with this prompt is that\n{reasons}.\nBased on the above information, please write one improved\nprompt. The prompt is wrapped with <START> and <END>.\nThe new prompt is:\nEvaluating Prompts. From the pool of 2ğ‘ğ‘’ prompts, identifying\nthe most efficient ones with the best recommendation accuracy\nis crucial. One greedy way is to evaluate their performance with\nall historical user sessions. However, this may be quite computa-\ntionally expensive. To improve the efficiency, we employ the upper\nconfidence bound (UCB) Bandits [ 38] to efficiently estimate the\nperformance. In particular, it iteratively samples one prompt based\non its estimated performance and then evaluates the prompt on\nLLMs for Intent-Driven Session Recommendation\na random batch of training sessions ( ğ‘ğ‘¡), and finally updates its\nperformance based on the observed performance. The process is\ndepicted by Algorithm 1, where the reward is calculated by the\nNDCG measuring the ranking position of the target item; and ğ›¾\nis the exploration parameter. With UCB Bandits, we can quickly\nobtain the estimated performance of the 2ğ‘ğ‘’ prompts.\nPrompt 5: The Refined Prompt\nGiven the userâ€™s current session interactions, you need to\nanswer the following subtasks step by step:\n1 Identify any patterns or relationships between the items\nwithin the session.\n2 Based on the identified patterns, infer the userâ€™s interac-\ntive intent within each combination of items.\n3 Consider the userâ€™s preferences, tastes, or previous in-\nteractions to select the intent that best represents their\ncurrent preferences.\n4 Rerank the items in the candidate set according to the\nlikelihood of potential user interactions. Provide the rank-\ning results with the item index.\nEnsure that the order of all items in the candidate set is given,\nand the items for ranking are within the candidate set.\nPrompt 6: Augmenting Prompts\nGenerate a variation of the following prompt while keeping\nthe semantic meaning.\nInput: {refined_prompt}.\nOutput:\nPrompt 7: The Augmented Prompt\nPlease follow these steps to answer the subtasks based on the\nuserâ€™s current session interactions:\n1 Analyze the session items to find any patterns or rela-\ntionships.\n2 Use the identified patterns to determine the userâ€™s inter-\nactive intent for each combination of items.\n3 Take into account the userâ€™s preferences, tastes, or previ-\nous interactions to choose the intent that best represents\ntheir current preferences.\n4 Rank the items in the candidate set according to the like-\nlihood of potential user interactions. Provide the ranking\nresults along with the item index.\nMake sure to include all items in the candidate set and only\nrank items within the candidate set.\nIterative Optimization. Based on UCB Bandits, we then iteratively\noptimize the prompts [38]. According to the estimated performance\nğ‘…, we select the Top-ğ‘ğ‘œ prompts and carry these promising prompts\nforward to the subsequent iteration. Specifically, we first use the\nTop-ğ‘ğ‘œ prompts to replace the prompts in the previous iteration,\nand then conduct the series of tasks, i.e., collecting error cases,\ninferring reasons, refining, augmenting, and evaluating prompts,\nAlgorithm 1: UCB-Bandits\nInput: prompt set P, training session set S, sampled session size ğ‘ğ‘¡ ,\nmaximum epoch ğ¸1, reward function ğ‘“(Â·);\nOutput: the estimated performance ğ‘…[P];\n// Initialization\n1 for each ğ‘ğ‘– âˆˆP do\n2 ğ‘…[ğ‘ğ‘– ]= 0 ; // initial estimated performance of ğ‘ğ‘–\n3 ğ‘†[ğ‘ğ‘– ]= 0 ; // initial frequency of ğ‘ğ‘– being evaluated\n4 for ğ‘’1 = 1; ğ‘’1 â‰¤ğ¸1; ğ‘’1 ++do\n5 Sample ğ‘ğ‘– â†arg maxğ‘\n\u0012\nğ‘…[ğ‘]+ğ›¾\nâˆšï¸ƒ\nğ‘™ğ‘œğ‘” (ğ‘’1)\nğ‘† [ğ‘]\n\u0013\n;\n6 Randomly sample Sğ‘¡ âŠ‚S where |Sğ‘¡ |= ğ‘ğ‘¡ ;\n7 ğ‘Ÿ[ğ‘ğ‘– ]= 0 ; // the initial accumulated reward\n8 for each ğ‘  âˆˆSğ‘¡ do\n9 ğ‘Ÿ[ğ‘ğ‘– ]â† ğ‘Ÿ[ğ‘ğ‘– ]+ ğ‘“(ğ‘ğ‘–,ğ‘ ); // evaluate ğ‘ğ‘– with ğ‘“(Â·)\n// Update evaluation frequency and performance\n10 ğ‘†[ğ‘ğ‘– ]â† ğ‘†[ğ‘ğ‘– ]+ğ‘ğ‘¡ ;\n11 ğ‘…[ğ‘ğ‘– ]â† ğ‘…[ğ‘ğ‘– ]+ ğ‘Ÿ [ğ‘ğ‘– ]\nğ‘ğ‘¡ ;\n12 return ğ‘…[P];\nas described in Algorithm 2. This iterative loop fosters incremental\nenhancements and exploration among various promising prompt\ncandidates. Prompt 8 is an example of an optimized prompt with the\nbest-estimated performance in the final iteration. After applying it\non the example session mentioned in Section 3.1, the target item\nhas been re-ranked to the 11th position, advancing eight positions\nfrom its previous placement in the candidate set.\nPrompt 8: The Optimized Prompt\nPlease follow these steps to answer the given subtasks:\n1 Analyze the combinations of items in the userâ€™s session,\nconsidering any patterns or criteria.\n2 Deduce the userâ€™s interactive intent within each combi-\nnation, taking into account their previous interactions\nand preferences.\n3 Determine the most representative intent from the in-\nferred ones that aligns with the userâ€™s current preferences.\n4 Reorder the items in the candidate set based on the\nselected intent, considering potential user interactions.\nPlease provide the ranking results with item index.\nRemember to provide the order of all items in the candidate\nset and ensure that the items for ranking are within the\ncandidate set. Take into consideration the relevance of the\nitems in the current session interactions to the candidate set,\nand incorporate the userâ€™s preferences and history into the\nrecommendations.\n3.3 Prompt Selection (PromptSel)\nAt the end of the iterative optimization, we have the Top-ğ‘ğ‘œ prompts.\nAccordingly, one straightforward way is to choose the Top-1 prompt\nas the final selection due to its superior overall performance. How-\never, we notice that although a majority of sessions achieve their\npeak accuracy with the Top-1 prompt, a subset of them displays the\nbest performance with other Top prompts. This can be verified by\nFigure 3, which shows the performance gap between the Top-1 and\nTop-2 prompts on the validation sessions across three real-world\nZhu Sun et al.\nAlgorithm 2: Iterative-Optimization\nInput: S,ğ‘ğ‘¡ ,ğ‘ğ‘œ,ğ¸1,ğ¸2,ğ‘“ (Â·);\nOutput: the optimized prompt set Pğ‘œ ;\n1 Eâ†âˆ… , Pğ‘œ â†ğ‘_init;\n2 for ğ‘’2 = 1; ğ‘’2 â‰¤ğ¸2; ğ‘’2 ++do\n3 ËœPâ†âˆ… ;\n4 for each ğ‘ğ‘– âˆˆPğ‘œ do\n5 Randomly sample Sğ‘¡ âŠ‚S where |Sğ‘¡ |= ğ‘ğ‘¡ ;\n6 for each ğ‘  âˆˆSğ‘¡ do\n7 if ğ‘ is an error case then\n8 Eâ†E .ğ‘ğ‘ğ‘ğ‘’ğ‘›ğ‘‘(ğ‘ ); // collect error cases\n9 for each ğ‘  âˆˆE,|E| = ğ‘ğ‘’ do\n10 Generate ğ‘ğ‘Ÿ reasons; // infer reasons\n11 ğ‘ğ‘–ğ‘Ÿ â†ğ‘ğ‘– &ğ‘ğ‘Ÿ reasons; // refine prompt\n12 ğ‘ğ‘–ğ‘ â†ğ‘ğ‘–ğ‘Ÿ ; // augment prompt\n13 ËœP.ğ‘ğ‘ğ‘ğ‘’ğ‘›ğ‘‘(ğ‘ğ‘–ğ‘Ÿ ,ğ‘ğ‘–ğ‘ );\n14 ğ‘…[ËœP]â† UCB-Bandits( ËœP,S,ğ‘ğ‘¡ ,ğ¸1,ğ‘“ (Â·)); // evaluate prompts\n15 Pğ‘œ â†Top-ğ‘ğ‘œ of ËœPbased on ğ‘…[ËœP]; // update prompts\n16 return Pğ‘œ ;\n1 25 50 75 100\nâˆ’1\nâˆ’0.5\n0\n0.5\n1\nSession Index\nPerformance Gap w.r.t. NDCG@5\nML-1M\nGames\nBundle\nFigure 3: Performance of Top-1&-2 prompts (same domain).\ndatasets in the domains of movie, games, and e-commerce (with\nbundled products)3. From the results, itâ€™s evident that there are\ndata points positioned where the gap is less than zero, signifying\nthat the Top-2 prompt surpasses the Top-1 prompt in some cases.\nThus, one can come up with potential solutions: (1) ensemble all top\nprompts to get the compensation results; and (2) train a classifier\nto select the best top prompt for each session. Nevertheless, we em-\npirically discovered that (1) fails to yield promising results because\nthe enhancements in the subset do not offset the declines in the\nmajority; while (2) heavily relies on the accuracy of the classifier,\nthus bringing in extra uncertainty to the final performance.\nFortunately, the robust generalizability of LLMs inspires us to\nexplore the cross-domain performance of these optimized prompts.\nSpecifically, Figure 4 depicts the performance of the Top-1 prompts\nfrom the three domains across the three datasets, for instance,\nâ€˜Opt-Gamesâ€™ (in purple) refers to the Top-1 prompt in the games\ndomain. From the figure, we can easily notice that Opt-Games\nconsistently performs the best not only in its games domain but\nalso in the other two domains. One possible explanation could be\nattributed to the Games dataset having the shortest average session\nlength (refer to the â€˜Avg. Session Lengthâ€™ in Table 1) alongside\na moderate level of sparsity (see â€˜Density Indicatorâ€™ in Table 1).\nThese factors collectively alleviate the challenge of identifying the\noptimal prompt to capture crucial and unique information, thereby\n3The details of the datasets utilized in our study are introduced in Section 4.1.1.\nTable 1: Statistics of datasets. â€˜Density Indicatorâ€™ refers to\nthe average frequency of each item appearing in the dataset,\ncalculated as (#Sessions Ã—Avg. Session Length)/#Items.\n#Items #Sessions Avg. Session Length Density Indicator\nML-1M 3,416 784,860 6.85 1573.86\nGames 17,389 100,018 4.18 24.04\nBundle 14,240 2,376 6.73 1.12\nML-1MGamesBundle0\n0.1\n0.2NDCG@1\nML-1MGamesBundle\n0.2\n0.3NDCG@5\nOpt-ML-1MOpt-GamesOpt-Bundle\nFigure 4: Performance of Top-1 prompt (cross-domain).\nenhancing the overall performance of SR. Accordingly, we select\nthe Opt-Games as the final prompt for all domains, the efficacy of\nwhich is verified in Section 4.2.\n4 EXPERIMENTS AND RESULTS\nWe conduct extensive experiments to answer five research ques-\ntions4. (RQ1) Does PO4ISR outperform baselines? (RQ2) How do\ndifferent components affect PO4ISR? (RQ3) How do essential pa-\nrameters affect PO4ISR? (RQ4) How does PO4ISR provide compre-\nhensible SR? (RQ5) Is there any limitation of PO4ISR?\n4.1 Experimental Setup\n4.1.1 Datasets. We use three real-world datasets from various do-\nmains. In particular, MovieLen-1M (ML-1M)5 contains usersâ€™ ratings\nof movies. Games is one subcategory from the Amazon dataset [34],\ncontaining usersâ€™ ratings towards various video games. Bundle [47]\ncontains session data for three subcategories (Electronic, Clothing,\nand Food) of Amazon, where the intents for each session are ex-\nplicitly annotated via crowdsourcing workers. Table 1 shows the\nstatistics of the datasets. For ML-1M and Games, we chronologically\norder the rated items into a sequence for each user and then divide\nit into sessions by day. For each dataset, we split the sessions into\ntraining, validation, and test sets with a ratio of 8:1:1, i.e., 80% of\nthe initial sessions are treated as training sets; the subsequent 10%\nas the validation set; and the final 10% as the test set.\n4.1.2 Baselines. We compare our proposed PO4ISR with ten base-\nlines, which can be classified into three types. The first type is the\nconventional methods . Mostpop recommends the most popular\nitems; SKNN [22] recommends session-level similar items; and\nFPMC [42] is the matrix factorization method with the first-order\nMarkov chain. The second type is the deep learning-based meth-\nods, which can be categorized into single-intent and multi-intent\nbased ones . NARM [26] is an RNN-based model with the attention\nmechanism to capture the main purpose from the hidden states;\nSTAMP [32] learns the general intention of users by emphasizing\nthe effect of the last item in the context; GCN-GNN [51] uses both\n4Our code and data are available at https://github.com/llm4sr/PO4ISR\n5https://grouplens.org/datasets/movielens/\nLLMs for Intent-Driven Session Recommendation\nTable 2: Performance comparison on all datasets, where the best and runner-up results are highlighted in bold and marked by\nâ€˜*â€™; â€˜-â€™ means a very small value; and â€˜Improveâ€™ indicates the relative improvements comparing the best and runner-up results.\nData Metrics Conventional Methods Single-Intent Methods Multi-Intent Methods LLM Methods Improve ğ‘-valueMostPop SKNN FPMC NARM STAMP GCE-GNN MCPRN HIDE Atten-Mixer NIR PO4ISR\nML-1M\nHR@1 0.0004 0.1270 0.1132 0.1692* 0.1584 0.1312 0.1434 0.1498 0.1490 0.0572 0.2000 18.20% 4.3ğ‘’âˆ’3\nHR@5 0.0070 0.3600 0.3748 0.5230* 0.5078 0.4748 0.4788 0.4998 0.4932 0.2326 0.5510 5.35% 5.9ğ‘’âˆ’2\nNDCG@1 0.0004 0.1270 0.1132 0.1692* 0.1584 0.1312 0.1434 0.1498 0.1490 0.0572 0.2000 18.20% 4.3ğ‘’âˆ’3\nNDCG@5 0.0053 0.2530 0.2464 0.3501* 0.3367 0.3044 0.3157 0.3256 0.3216 0.1436 0.3810 8.83% 3.5ğ‘’âˆ’3\nGames\nHR@1 â€“ 0.0020 0.0498 0.0572 0.0556 0.0692 0.0522 0.0696 0.0530 0.1168* 0.2588 121.58% 6.4ğ‘’âˆ’5\nHR@5 â€“ 0.0020 0.2564 0.2574 0.2586 0.2744 0.2416 0.2694 0.2472 0.3406* 0.5866 72.23% 3.5ğ‘’âˆ’5\nNDCG@1 â€“ 0.0020 0.0498 0.0572 0.0556 0.0692 0.0522 0.0696 0.0530 0.1168* 0.2588 121.58% 6.4ğ‘’âˆ’5\nNDCG@5 â€“ 0.0020 0.1508 0.1534 0.1555 0.1701 0.1432 0.1662 0.1475 0.2310* 0.4313 86.71% 7.3ğ‘’âˆ’6\nBundle\nHR@1 â€“ â€“ 0.0398 0.0322 0.0365 0.0360 0.0360 0.0458 0.0525 0.0975* 0.1697 74.05% 2.0ğ‘’âˆ’5\nHR@5 0.0042 â€“ 0.2475 0.2322 0.2352 0.2237 0.2352 0.2585 0.2644 0.2832* 0.4328 52.82% 2.6ğ‘’âˆ’4\nNDCG@1 â€“ â€“ 0.0398 0.0322 0.0365 0.0360 0.0360 0.0458 0.0525 0.0975* 0.1697 74.05% 2.0ğ‘’âˆ’5\nNDCG@5 0.0021 â€“ 0.1395 0.1303 0.1339 0.1267 0.1490 0.1495 0.1549 0.1939* 0.3040 56.78% 3.4ğ‘’âˆ’5\nlocal and global graphs to learn item representation thus obtaining\nthe main intent of the session; MCPRN [50] models usersâ€™ mul-\ntiple purposes to get the final session representation; HIDE [29]\nsplits the item embedding into multiple chunks, with each chunk\nrepresenting a specific intention to learn diverse intentions within\ncontext; and Atten-Mixer [65]: learns multi-granularity consecu-\ntive user intents to generate more accurate session representations.\nThe last type is the LLM-based method . NIR [49] adopts zero-shot\nprompting for the next item recommendation.\n4.1.3 Parameter Settings. We use Optuna (optuna.org) to automat-\nically find out the optimal hyperparameters of all methods with 50\ntrails. In particular, the maximum training epoch is set as 100 with\nthe early stop mechanism. The search space for batch size, item\nembedding size, and learning rate are {64,128,256},{32,64,128}\nand {10âˆ’4,10âˆ’3,10âˆ’2}, respectively. For SKNN, ğ¾ is searched from\n{50,100,150}. For NARM, the hidden size and layers are searched in\n[50,200]stepped by 50 and in {1,2,3}, respectively. For GCE-GNN,\nthe number of hops, and the dropout rate for global and local ag-\ngregators are respectively searched in {1,2},[0,0.8]stepped by 0.2,\nand {0,0.5}. For MCPRN, ğœ and the number of purpose channels\nare separately searched in {0.01,0.1,1,10}and {1,2,3,4}. For HIDE,\nthe number of factors is searched in {1,3,5,7,9}; the regularization\nand balance weights are searched in {10âˆ’5,10âˆ’4,10âˆ’3,10âˆ’2}; the\nwindow size is searched in [1,10]stepped by 1; and the sparsity\ncoefficient is set as 0.4. For Atten-Mixer, the intent level ğ¿ and\nthe number of attention heads are respectively searched in [1,10]\nstepped by 1 and in {1,2,4,8}. For PO4ISR, ğ‘ = 50,ğ‘ğ‘¡ = 32,ğ‘ğ‘Ÿ =\n2,ğ‘ğ‘œ = 4,ğ¸1 = 16,ğ¸2 = 2; and we randomly select 8 prompts as the\ninput of the UCB Bandits in each iteration.\n4.1.4 Evaluation Metrics. Following state-of-the-arts [49, 50, 61],\nHR@K and NDCG@K are adopted as the evaluation metrics. We\nset ğ¾ = 1/5 since most users tend to prioritize the quality of items\nappearing at the top positions in real scenarios [ 31]. Generally,\nhigher metric values indicate better ranking results. For a fair com-\nparison, the candidate size of all methods is set as 20 following\nNIR [49]; all non-LLM baselines are trained with 150 randomly sam-\npled sessions from the training set, while PO4ISR uses the subset\nof 50 sessions. This is because although PO4ISR uses 50 sessions\nto optimize prompts in each domain, it considers the performance\nfrom (three) diverse domains for the final prompt selection. For\nnon-LLM baselines, it is non-trivial to use the cross-domain per-\nformance to select the best models. This also helps showcase the\nsuperior advantages of LLMs on generalization. To manage the\nAPI call cost, for ML-1M and Games, we randomly sample 1000\nsessions from the validation set and test set, respectively. For robust\nperformance, we repeat the test procedure five times where each\ntime we set different seed values (i.e., 0, 10, 42, 625, and 2023) to\ngenerate different candidate sets. Finally, we report the average\nresults as presented in Table 2.\n4.2 Results and Analysis\n4.2.1 Overall Comparison (RQ1). Table 2 shows the performance\nof all methods on the three datasets. Several findings are noted.\n(1) Regarding conventional methods (CMs), the model-based\nFPMC performs the best on sparser datasets Games and Bundles,\nwhile is slightly defeated by SKNN on the denser dataset ML-1M\n(see â€˜Density Indicatorâ€™ in Table 1). This exhibits the strong ca-\npability of model-based methods in learning sequential patterns\nwith sparse data. (2) For single-intent methods (SIMs), each gains\nits best performance on different datasets, e.g., NARM excels on\nML-1M, whereas GCE-GNN wins on Games. Generally, GCE-GNN\nshowcases advantages on shorter sessions with sparser datasets\n(e.g., Games). This is because such sessions do not contain sufficient\nlocal information, thus requiring global information (graph) to com-\npensate. Conversely, NARM performs well on longer sessions with\ndenser datasets (e.g., ML-1M), since such sessions possess substan-\ntial information (e.g., frequent patterns) making the fusion of global\ninformation potentially noisy. (3) Concerning multi-intent meth-\nods (MIMs), MCPRN displays the poorest performance across all\ndatasets, as limited training data hinders the learning of proper pa-\nrameters for multiple RNN channels. Besides, HIDE exceeds Atten-\nMixer on relatively denser datasets (ML-1M and Games) but lags\non the sparsest Bundle. (4) Among LLM-based methods (LLMMs),\nPO4ISR outperforms NIR, corroborating our prior assertion that\nbasic in-context learning fails to fully exploit LLMs, thereby em-\nphasizing the superiority of our prompt optimization paradigm.\nOverall, CMs underperform SIMs or MIMs, underscoring the\nimportance of capturing user intents for improved SR. The vic-\ntory of MIMs over SIMs on Bundle validates the effectiveness of\nZhu Sun et al.\nTable 3: The results of ablation study across all datasets on the test set (seed 0).\nML-1M Games Bundle\nInitial Top-1 EnSame EnCross PO4ISR Initial EnSame EnCross PO4ISR Initial Top-1 EnSame EnCross PO4ISR\nHR@1 0.1430 0.2070 0.1120 0.1070 0.2110 0.0790 0.1540 0.1090 0.2600 0.0504 0.1176 0.0294 0.0840 0.1933\nHR@5 0.4150 0.5130 0.4130 0.4250 0.5730 0.3510 0.5250 0.4410 0.5960 0.2437 0.3193 0.1891 0.2689 0.4454\nNDCG@1 0.1430 0.2070 0.1120 0.1070 0.2110 0.0790 0.1540 0.1090 0.2600 0.0504 0.1176 0.0294 0.0840 0.1933\nNDCG@5 0.2823 0.3662 0.2693 0.2640 0.3975 0.2110 0.3574 0.2779 0.4381 0.1396 0.2202 0.1119 0.1745 0.3183\nML-1MGamesBundle0\n0.1\n0.2HR@1\nML-1MGamesBundle\n0.3\n0.4\n0.5\n0.6HR@5\nML-1MGamesBundle0\n0.1\n0.2NDCG@1\nML-1MGamesBundle0.1\n0.2\n0.3\n0.4NDCG@5\nOpt-ML-1MOpt-GamesOpt-Bundle\nFigure 5: Performance of Top-1 prompt from each domain in the cross-domain scenario on the test set (seed 0).\nmulti-intent learning. However, some of the SIMs (e.g., NARM)\nsurpass MIMs (e.g., MCPRN) on ML-1M and Games, suggesting\nthat fixed numbers of intents might constrain the capability of\nMIMs. LLMMs exhibit strength on sparser datasets compared to\ndenser ones (e.g., NIR on Games vs. ML-1M), and shorter sessions\ncompared to longer ones (e.g., NIR on Games vs. Bundles). Similar\ntrends are also observed in PO4ISR, where the average improve-\nment (12.65%) on ML-1M is smaller than that (100.55%) on Games.\nThis demonstrates the advanced ability of LLMs to address the data\nsparsity issue. Lastly, our PO4ISR consistently achieves the best\nperformance among all baselines, with an average improvement of\n57.37% and 61.03% on HR and NDCG, respectively.\n4.2.2 Ablation Study (RQ2). To verify the efficacy of different com-\nponents, we compare PO4ISR with its four variants. In particular,\nâ€˜Initialâ€™ means we only use the initial prompt without optimization\nfor each domain; â€˜Top-1â€™ means we merely adopt the Top-1 prompt\nwithin each domain; â€˜EnSameâ€™ means we ensemble the ranking\nresults of both Top-1 and -2 prompts within each domain; â€˜EnCrossâ€™\nmeans we ensemble the ranking results of Top-1 prompts across all\ndomains. The performance is shown in Table 3. Three observations\nare noted: (1) Initial performs worse than Top-1, which indicates\nthe effectiveness of iterative prompt optimization; (2) both EnSame\nand EnCross underperform Top-1, implying that simply ensembling\nthe top prompts either within the same domain or across differ-\nent domains cannot efficiently improve the performance; and (3)\nPO4ISR with the Top-1 prompt in the games domain consistently\nachieves the best performance across all datasets, showcasing the\nefficacy of our cross-domain prompt selection strategy. This is fur-\nther confirmed by Figure 5, presenting the performance of Top-1\nprompt from each domain in the cross-domain scenario.\n4.2.3 Parameter Analysis (RQ3). We further investigate the impact\nof important hyperparameters on PO4ISR. First, we examine the\nimpact of different initial prompts. To this end, we substitute the\ninitial task description (Prompt 1) with Prompt 9 incorporating two\nmajor changes: (1) we use â€˜preferencesâ€™ to replace â€˜intentionsâ€™, and\nthe two terms have the same meanings in the context of ISR, and\n(2) we simplify the four subtasks into two subtasks. The results are\npresented in Table 4 (rows 1-3 vs. rows 4-6), where we note that\ndirectly using Prompt 9 achieves better performance than using\nPrompt 1; meanwhile, the corresponding Top-1 prompt optimized\nbased on Prompt 9 outperforms the Top-1 prompt optimized based\non Prompt 1. This indicates that (1) simplified descriptions and\nsubtasks division can improve the quality of the initial prompt,vice\nversa; (2) the quality of the initial prompts positively affects the final\nperformance; (3) regardless of the quality of initial prompts, they\ncan be largely enhanced with iterative optimization; (4) the lower-\nquality initial prompt yields larger overall improvements; and (5)\nthe performance of PO4ISR presented in Table 2 is not the upper\nbound, and can be further improved with better initial prompts,\nshowcasing its great potential. Besides, we study the impact of\nbatch size ğ‘ğ‘¡ on the final performance by varying its values in\n{16,32}, and the results are presented in Table 4 (row 2 vs. row 7).\nAccordingly, we find that ğ‘ğ‘¡ = 32 is the optimal setting.\nPrompt 9: Task Description\nBased on the userâ€™s current session interactions, you need to\nanswer the following tasks:\n1 Please infer the userâ€™s preferences, considering that the\nuser may have one or multiple preferences.\n2 Based on inferred preferences, please rerank the items in\nthe candidate set according to the possibility of potential\nuser interactions and show me your ranking results with\nthe item index.\nNote that the order of all items in the candidate set must\nbe provided, and the items for ranking must be within the\ncandidate set.\n4.2.4 Visualization (RQ4). To illustrate the results generated by\nPO4ISR, we randomly sample one test session from Bundle as shown\nin Figure 6. Given the historical session, PO4ISR first detects four\ncombinations of items, including [ğ‘–1,ğ‘–2,ğ‘–8],[ğ‘–3,ğ‘–4,ğ‘–6],[ğ‘–5,ğ‘–7],[ğ‘–9].\nThe corresponding intents for each combination are (1) \"this com-\nbination includes gummi bears, chamomile tea, and rosehip with\nhibiscus tea; the user might be interested in snacks and beverages\nLLMs for Intent-Driven Session Recommendation\nTable 4: Results of parameter analysis on Bundle (seed 0).\nHR@1 HR@5 NDCG@1 NDCG@5\nPrompt 1 (Initial) 0.0504 0.2437 0.0504 0.1396\nTop-1 (ğ‘ğ‘¡ = 32) 0.1176 0.3193 0.1176 0.2202\nImprove 133.33% 31.02% 133.33% 57.74%\nPrompt 9 (Initial) 0.1008 0.2479 0.1008 0.1706\nTop-1 (ğ‘ğ‘¡ = 32) 0.1807 0.3739 0.1807 0.2744\nImprove 79.27% 50.83% 79.27% 60.84%\nTop-1 (ğ‘ğ‘¡ = 16) 0.1008 0.2857 0.1008 0.1860\nImprove (vs. Prompt 1) 100% 17.23% 100% 33.24%\nFigure 6: The case study on Bundle.\nfor relaxation or enjoyment\"; (2) \"this combination includes organic\ninfant formula, organic baby food, and organic baby food pouches;\nthe userâ€™s intent seems to be focused on organic and healthy op-\ntions for infants\"; (3) \"this combination includes Sriracha hot sauce\nand green hot sauce; the userâ€™s intent appears to be related to spicy\ncondiments or sauces\" and (4) \"this combination includes green su-\nperfood capsules; the userâ€™s intent might be to explore or maintain\na healthy lifestyle\". Then it identifies and outputs the most impor-\ntant intent: \"based on the given combinations, the intent related to\norganic and healthy options for infants (Combination 2) seems to\nbe the most specific and focused\". Finally, it furnishes a re-ranked\nrecommendation list, positioning the ground truth item \"Earthâ€™s\nBest Organic Baby Food, Spaghetti With Cheese\" (highlighted in\na red-dot circle) from its initial 11th rank within the candidate set\nto the topmost position. In summary, the case study validates that\nPO4ISR can help provide more comprehensible recommendations.\n4.2.5 Discussion on Hallucination (RQ5). Despite the success of\nPO4ISR on the SR task, it showcases limitations due to the inherent\nissue of LLMs. One issue is that PO4ISR may generate hallucination\nfor some sessions (e.g., the response does not contain the ranking\nlist or the ground truth item is not included in the ranking list),\nalthough we add hard constraints in the prompt such as \"the order\nof all items in the candidate set must be provided, and the items for\nranking must be within the candidate set \". Table 5 illustrates the ratio\nTable 5: Ratio of sessions with hallucination (seed 0).\nOpt-ML-1M Opt-Games Opt-Bundle Average\nML-1M 0.30% 0.10% 0.30% 0.23%\nGames 8.30% 6.80% 6.00% 7.03%\nBundle 7.56% 9.66% 10.92% 9.38%\nAverage 5.39% 5.52% 5.74% 5.55%\nTable 6: Performance with and without JSON on Bundle.\nOpt-ML-1M Opt-Games Opt-Bundle\n+JSON -JSON +JSON -JSON +JSON -JSON\nHR@1 0.0546 0.1429 0.0504 0.1933 0.0756 0.1176\nHR@5 0.2227 0.3361 0.2185 0.4454 0.2395 0.3193\nNDCG@1 0.0546 0.1429 0.0504 0.1933 0.0756 0.1176\nNDCG@5 0.1336 0.2355 0.1289 0.3183 0.1531 0.2202\nRatio 7.14% 7.56% 8.82% 9.66% 9.66% 10.92%\nof sessions having hallucinations on the test sets using the Top-1\nprompt from each domain across the three datasets. Two major\nobservations can be noted. (1) The ratio is at its lowest on ML-1M\nbut peaks on Bundle (emphasized in blue). This discrepancy likely\nstems from ML-1M having the highest average repeat frequency\nof items across sessions, whereas Bundle exhibits the lowest trend\n(see Table 1). The frequent appearance of items in various sessions\nmay simplify the pattern recognition process, thus reducing task\ncomplexity to some extent. Additionally, Bundleâ€™s diverse range of\nelectronics, clothing, and food products elevates the complexity of\nthe SR task compared to the more focused ML-1M dataset. (2) The\noptimal prompts from different domains show comparable perfor-\nmance as highlighted in pink. On average, there are around 5.55%\nsessions with hallucination, implying that further performance en-\nhancements can be obtained by addressing this issue and exhibiting\nthe latent potential of LLMs for SR (note that the HR and NDCG\nvalues are set as 0 for sessions with hallucination).\nTo alleviate the hallucination issue, we involve JSON mode6 in\nthe response to better control the output by adding the constraint as:\nProvide the ranking results for the candidate set using JSON format,\nfollowing this format without deviation: [\"Item ID\": \"correspond item\nindex\", \"Item Title\": \"correspond Item Title\"] . Table 6 illustrates the\nperformance contrast of PO4ISR on Bundle, with and without the\nJSON mode in the response, which indicates that employing JSON\nmode marginally reduces bad cases, yet significantly compromises\nrecommendation accuracy. Contrarily, we find most such cases can\nbe better eased by using GPT-4 with less compromised accuracy.\n5 CONCLUSION\nInspired by the reasoning capability of LLMs, we introduce a new\nparadigm â€“ PO4ISR â€“ for intent-aware session recommendation.\nIt aims to discover varying numbers of semantic intents hidden\nin different sessions for more accurate and comprehensible rec-\nommendations through iterative prompt optimization. Specifically,\nthe Prompt Initialization module first creates the initial prompt\nto instruct LLMs to predict the next item by inferring varying in-\ntents reflected in a session. Then, the prompt optimization module\nis devised to optimize prompts with iterative self-reflection in an\nautomatic manner. Finally, the prompt selection module seeks to\n6https://platform.openai.com/docs/guides/text-generation/json-mode\nZhu Sun et al.\nappropriately select optimal prompts based on the robust generaliz-\nability of LLMs across diverse domains. Extensive experiments on\nreal-world datasets show the superiority of PO4ISR against other\ncounterparts. Furthermore, several insightful discoveries are made\nto guide subsequent studies in this area.\nREFERENCES\n[1] Jean-Yves Audibert, SÃ©bastien Bubeck, and RÃ©mi Munos. 2010. Best arm identifi-\ncation in multi-armed bandits.. In Proceedings of the 23rd Annual Conference on\nLearning Theory (COLT) . 41â€“53.\n[2] Jay Ayres, Jason Flannick, Johannes Gehrke, and Tomi Yiu. 2002. Sequential\npattern mining using a bitmap representation. In Proceedings of the 8th ACM\nSIGKDD International Conference on Knowledge Discovery and Data Mining (KDD) .\n429â€“435.\n[3] Keqin Bao, Jizhi Zhang, Wenjie Wang, Yang Zhang, Zhengyi Yang, Yancheng\nLuo, Fuli Feng, Xiangnaan He, and Qi Tian. 2023. A bi-step grounding para-\ndigm for large language models in recommendation systems. arXiv preprint\narXiv:2308.08434 (2023).\n[4] Keqin Bao, Jizhi Zhang, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He.\n2023. Tallrec: an effective and efficient tuning framework to align large language\nmodel with recommendation. In Proceedings of the 17th ACM Conference on\nRecommender Systems (RecSys) . 1007â€“1014.\n[5] Jingfan Chen, Guanghui Zhu, Haojun Hou, Chunfeng Yuan, and Yihua Huang.\n2022. AutoGSR: Neural architecture search for graph-based session recommen-\ndation. In Proceedings of the 45th International ACM SIGIR Conference on Research\nand Development in Information Retrieval (SIGIR) . 1694â€“1704.\n[6] Qian Chen, Zhiqiang Guo, Jianjun Li, and Guohui Li. 2023. Knowledge-enhanced\nMulti-View Graph Neural Networks for Session-based Recommendation. In\nProceedings of the 46th International ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval (SIGIR) . 352â€“361.\n[7] Qian Chen, Jianjun Li, Zhiqiang Guo, Guohui Li, and Zhiying Deng. 2023.\nAttribute-enhanced dual channel representation learning for session-based rec-\nommendation. In Proceedings of the 32nd ACM International Conference on Infor-\nmation and Knowledge Management (CIKM) . 3793â€“3797.\n[8] Tianwen Chen and Raymond Chi-Wing Wong. 2020. Handling information loss\nof graph neural networks for session-based recommendation. In Proceedings of\nthe 26th ACM SIGKDD International Conference on Knowledge Discovery and Data\nMining (KDD) . 1172â€“1180.\n[9] Wanyu Chen, Pengjie Ren, Fei Cai, Fei Sun, and Maarten de Rijke. 2020. Improv-\ning end-to-end sequential recommendations with intent-aware diversification.\nIn Proceedings of the 29th ACM International Conference on Information and\nKnowledge Management (CIKM) . 175â€“184.\n[10] Minjin Choi, Jinhong Kim, Joonseok Lee, Hyunjung Shim, and Jongwuk Lee.\n2022. S-Walk: accurate and scalable session-based recommendation with random\nwalks. In Proceedings of the 15yh ACM International Conference on Web Search\nand Data Mining (WSDM) . 150â€“160.\n[11] Sunhao Dai, Ninglu Shao, Haiyuan Zhao, Weijie Yu, Zihua Si, Chen Xu, Zhongx-\niang Sun, Xiao Zhang, and Jun Xu. 2023. Uncovering chatgptâ€™s capabilities in\nrecommender systems. In Proceedings of the 17th ACM Conference on Recom-\nmender Systems (RecSys) . 1126â€“1132.\n[12] Jiayan Guo, Yaming Yang, Xiangchen Song, Yuan Zhang, Yujing Wang, Jing Bai,\nand Yan Zhang. 2022. Learning multi-granularity consecutive user intent unit\nfor session-based recommendation. In Proceedings of the 15th ACM International\nConference on Web Search and Data Mining (WSDM) . 343â€“352.\n[13] Jiayan Guo, Peiyan Zhang, Chaozhuo Li, Xing Xie, Yan Zhang, and Sunghun Kim.\n2022. Evolutionary preference learning via graph nested gru ode for session-\nbased recommendation. In Proceedings of the 31st ACM International Conference\non Information and Knowledge Management (CIKM) . 624â€“634.\n[14] Qilong Han, Chi Zhang, Rui Chen, Riwei Lai, Hongtao Song, and Li Li. 2022.\nMulti-faceted global item relation learning for session-based recommendation.\nIn Proceedings of the 45th International ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval (SIGIR) . 1705â€“1715.\n[15] Jesse Harte, Wouter Zorgdrager, Panos Louridas, Asterios Katsifodimos, Diet-\nmar Jannach, and Marios Fragkoulis. 2023. Leveraging large language models\nfor sequential recommendation. In Proceedings of the 17th ACM Conference on\nRecommender Systems (RecSys) . 1096â€“1102.\n[16] Zhankui He, Zhouhang Xie, Rahul Jha, Harald Steck, Dawen Liang, Yesu Feng,\nBodhisattwa Majumder, Nathan Kallus, and Julian Mcauley. 2023. Large language\nmodels as zero-shot conversational recommenders. In Proceedings of the 32nd\nACM International Conference on Information and Knowledge Management (CIKM) .\nJust Accepted.\n[17] BalÃ¡zs Hidasi and Alexandros Karatzoglou. 2018. Recurrent neural networks with\ntop-k gains for session-based recommendations. In Proceedings of the 27th ACM\nInternational Conference on Information and Knowledge Management (CIKM) .\n843â€“852.\n[18] BalÃ¡zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk.\n2016. Session-based recommendations with recurrent neural networks. In Pro-\nceedings of the 4th International Conference on Learning Representations (ICLR) .\n[19] BalÃ¡zs Hidasi, Massimo Quadrana, Alexandros Karatzoglou, and Domonkos\nTikk. 2016. Parallel recurrent neural network architectures for feature-rich\nsession-based recommendations. In Proceedings of the 10th ACM Conference on\nRecommender Systems (RecSys) . 241â€“248.\n[20] Yupeng Hou, Binbin Hu, Zhiqiang Zhang, and Wayne Xin Zhao. 2022. Core:\nsimple and effective session-based recommendation within consistent represen-\ntation space. In Proceedings of the 45th International ACM SIGIR Conference on\nResearch and Development in Information Retrieval (SIGIR) . 1796â€“1801.\n[21] Yupeng Hou, Junjie Zhang, Zihan Lin, Hongyu Lu, Ruobing Xie, Julian McAuley,\nand Wayne Xin Zhao. 2023. Large language models are zero-shot rankers for\nrecommender systems. arXiv preprint arXiv:2305.08845 (2023).\n[22] Dietmar Jannach and Malte Ludewig. 2017. When recurrent neural networks\nmeet the neighborhood for session-based recommendation. In Proceedings of the\n11th ACM Conference on Recommender Systems (RecSys) . 306â€“310.\n[23] Di Jin, Luzhi Wang, Yizhen Zheng, Guojie Song, Fei Jiang, Xiang Li, Wei Lin,\nand Shirui Pan. 2023. Dual intent enhanced graph neural network for session-\nbased new item recommendation. In Proceedings of the ACM Web Conference\n(TheWebConf). 684â€“693.\n[24] Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential rec-\nommendation. In 2018 IEEE International Conference on Data Mining (ICDM) .\n197â€“206.\n[25] Siqi Lai, Erli Meng, Fan Zhang, Chenliang Li, Bin Wang, and Aixin Sun. 2022.\nAn attribute-driven mirror graph network for session-based recommendation.\nIn Proceedings of the 45th International ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval (SIGIR) . 1674â€“1683.\n[26] Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, and Jun Ma. 2017.\nNeural attentive session-based recommendation. In Proceedings of the 2017 ACM\non Conference on Information and Knowledge Management (CIKM) . 1419â€“1428.\n[27] Jinming Li, Wentao Zhang, Tian Wang, Guanglei Xiong, Alan Lu, and Gerard\nMedioni. 2023. GPT4Rec: A generative framework for personalized recommen-\ndation and user interests interpretation. arXiv preprint arXiv:2304.03879 (2023).\n[28] Yinfeng Li, Chen Gao, Xiaoyi Du, Huazhou Wei, Hengliang Luo, Depeng Jin,\nand Yong Li. 2022. Spatiotemporal-aware Session-based Recommendation with\nGraph Neural Networks. In Proceedings of the 31st ACM International Conference\non Information and Knowledge Management (CIKM) . 1209â€“1218.\n[29] Yinfeng Li, Chen Gao, Hengliang Luo, Depeng Jin, and Yong Li. 2022. Enhancing\nhypergraph neural networks with intent disentanglement for session-based\nrecommendation. In Proceedings of the 45th International ACM SIGIR Conference\non Research and Development in Information Retrieval (SIGIR) . 1997â€“2002.\n[30] Xinyu Lin, Wenjie Wang, Yongqi Li, Fuli Feng, See-Kiong Ng, and Tat-Seng\nChua. 2023. A Multi-facet Paradigm to Bridge Large Language Model and\nRecommendation. arXiv preprint arXiv:2310.06491 (2023).\n[31] Hongyang Liu, Zhu Sun, Xinghua Qu, and Fuyong Yuan. 2021. Top-aware\nrecommender distillation with deep reinforcement learning. Information Sciences\n(INS) 576 (2021), 642â€“657.\n[32] Qiao Liu, Yifu Zeng, Refuoe Mokhosi, and Haibin Zhang. 2018. STAMP: short-\nterm attention/memory priority model for session-based recommendation. In\nProceedings of the 24th ACM SIGKDD International Conference on Knowledge\nDiscovery and Data Mining (KDD) . 1831â€“1839.\n[33] Malte Ludewig and Dietmar Jannach. 2018. Evaluation of session-based recom-\nmendation algorithms. User Modeling and User-Adapted Interaction (UMUAI) 28\n(2018), 331â€“390.\n[34] Jianmo Ni, Jiacheng Li, and Julian McAuley. 2019. Justifying recommendations\nusing distantly-labeled reviews and fine-grained aspects. In Proceedings of the\n2019 Conference on Empirical Methods in Natural Language Processing and the 9th\nInternational Joint Conference on Natural Language Processing (EMNLP-IJCNLP) .\n188â€“197.\n[35] Sejoon Oh, Ankur Bhardwaj, Jongseok Han, Sungchul Kim, Ryan A Rossi, and\nSrijan Kumar. 2022. Implicit session contexts for next-item recommendations. In\nProceedings of the 31st ACM International Conference on Information and Knowl-\nedge Management (CIKM) . 4364â€“4368.\n[36] Yitong Pang, Lingfei Wu, Qi Shen, Yiming Zhang, Zhihua Wei, Fangli Xu, Ethan\nChang, Bo Long, and Jian Pei. 2022. Heterogeneous global graph neural networks\nfor personalized session-based recommendation. In Proceedings of the 15th ACM\nInternational Conference on Web Search and Data Mining (WSDM) . 775â€“783.\n[37] Andreas Peintner, Amir Reza Mohammadi, and Eva Zangerle. 2023. SPARE:\nShortest path global item relations for efficient session-based recommendation.\nIn Proceedings of the 17th ACM Conference on Recommender Systems (RecSys) .\n58â€“69.\n[38] Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, and Michael Zeng.\n2023. Automatic prompt optimization with \"gradient descent\" and beam search.\narXiv preprint arXiv:2305.03495 (2023).\n[39] Shutong Qiao, Wei Zhou, Junhao Wen, Hongyu Zhang, and Min Gao. 2023. Bi-\nchannel multiple sparse graph attention networks for session-based recommen-\ndation. In Proceedings of the 32nd ACM International Conference on Information\nLLMs for Intent-Driven Session Recommendation\nand Knowledge Management (CIKM) . 2075â€“2084.\n[40] Ruihong Qiu, Jingjing Li, Zi Huang, and Hongzhi Yin. 2019. Rethinking the item\norder in session-based recommendation with graph neural networks. In Pro-\nceedings of the 28th ACM International Conference on Information and Knowledge\nManagement (CIKM) . 579â€“588.\n[41] Massimo Quadrana, Alexandros Karatzoglou, BalÃ¡zs Hidasi, and Paolo Cremonesi.\n2017. Personalizing session-based recommendations with hierarchical recurrent\nneural networks. In Proceedings of the 11th ACM Conference on Recommender\nSystems (RecSys) . 130â€“137.\n[42] Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factor-\nizing personalized markov chains for next-basket recommendation. In Proceed-\nings of the 19th International Conference on World Wide Web (WWW) . 811â€“820.\n[43] Scott Sanner, Krisztian Balog, Filip Radlinski, Ben Wedin, and Lucas Dixon.\n2023. Large language models are competitive near cold-start recommenders for\nlanguage-and item-based preferences. In Proceedings of the 17th ACM Conference\non Recommender Systems (RecSys) . 890â€“896.\n[44] Wenzhuo Song, Shoujin Wang, Yan Wang, Kunpeng Liu, Xueyan Liu, and Ming-\nhao Yin. 2023. A counterfactual collaborative session-based recommender system.\nIn Proceedings of the ACM Web Conference (TheWebConf) . 971â€“982.\n[45] Jiajie Su, Chaochao Chen, Weiming Liu, Fei Wu, Xiaolin Zheng, and Haoming\nLyu. 2023. Enhancing hierarchy-aware graph networks with deep dual clustering\nfor session-based recommendation. In Proceedings of the ACM Web Conference\n(TheWebConf). 165â€“176.\n[46] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang.\n2019. BERT4Rec: Sequential recommendation with bidirectional encoder rep-\nresentations from transformer. In Proceedings of the 28th ACM International\nConference on Information and Knowledge Management (CIKM) . 1441â€“1450.\n[47] Zhu Sun, Jie Yang, Kaidong Feng, Hui Fang, Xinghua Qu, and Yew Soon Ong. 2022.\nRevisiting bundle recommendation: datasets, tasks, challenges and opportunities\nfor intent-aware product bundling. In Proceedings of the 45th International ACM\nSIGIR Conference on Research and Development in Information Retrieval (SIGIR) .\n2900â€“2911.\n[48] Yong Kiam Tan, Xinxing Xu, and Yong Liu. 2016. Improved recurrent neural\nnetworks for session-based recommendations. In Proceedings of the 1st Workshop\non Deep Learning for Recommender Systems . 17â€“22.\n[49] Lei Wang and Ee-Peng Lim. 2023. Zero-Shot next-item recommendation using\nlarge pretrained language models. arXiv preprint arXiv:2304.03153 (2023).\n[50] Shoujin Wang, Liang Hu, Yan Wang, Quan Z Sheng, Mehmet Orgun, and Long-\nbing Cao. 2019. Modeling multi-purpose sessions for next-item recommendations\nvia mixture-channel purpose routing networks. In Proceedings of International\nJoint Conference on Artificial Intelligence (IJCAI) .\n[51] Ziyang Wang, Wei Wei, Gao Cong, Xiao-Li Li, Xian-Ling Mao, and Minghui\nQiu. 2020. Global context enhanced graph neural networks for session-based\nrecommendation. In Proceedings of the 43rd International ACM SIGIR Conference\non Research and Development in Information Retrieval (SIGIR) . 169â€“178.\n[52] Zhidan Wang, Wenwen Ye, Xu Chen, Wenqiang Zhang, Zhenlei Wang, Lixin\nZou, and Weidong Liu. 2022. Generative session-based recommendation. In\nProceedings of the ACM Web Conference (TheWebConf) . 2227â€“2235.\n[53] Chunyu Wei, Bing Bai, Kun Bai, and Fei Wang. 2022. Gsl4rec: Session-based\nrecommendations with collective graph structure learning and next interaction\nprediction. In Proceedings of the ACM Web Conference (TheWebConf) . 2120â€“2130.\n[54] Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, and Tieniu Tan. 2019.\nSession-based recommendation with graph neural networks. In Proceedings of\nthe AAAI Conference on Artificial Intelligence (AAAI) , Vol. 33. 346â€“353.\n[55] Xin Xia, Hongzhi Yin, Junliang Yu, Qinyong Wang, Lizhen Cui, and Xiangliang\nZhang. 2021. Self-supervised hypergraph convolutional networks for session-\nbased recommendation. In Proceedings of the AAAI Conference on Artificial Intel-\nligence (AAAI), Vol. 35. 4503â€“4511.\n[56] Chengfeng Xu, Pengpeng Zhao, Yanchi Liu, Victor S Sheng, Jiajie Xu, Fuzhen\nZhuang, Junhua Fang, and Xiaofang Zhou. 2019. Graph contextualized self-\nattention network for session-based recommendation. In Proceedings of Interna-\ntional Joint Conference on Artificial Intelligence (IJCAI) , Vol. 19. 3940â€“3946.\n[57] Heeyoon Yang, YunSeok Choi, Gahyung Kim, and Jee-Hyong Lee. 2023. LOAM:\nImproving Long-tail Session-based Recommendation via Niche Walk Augmen-\ntation and Tail Session Mixup. In Proceedings of the 46th International ACM\nSIGIR Conference on Research and Development in Information Retrieval (SIGIR) .\n527â€“536.\n[58] Liqi Yang, Linhan Luo, Lifeng Xin, Xiaofeng Zhang, and Xinni Zhang. 2022.\nDAGNN: Demand-aware graph neural networks for session-based recommenda-\ntion. In Proceedings of the 45th International ACM SIGIR Conference on Research\nand Development in Information Retrieval (SIGIR) .\n[59] Zhengyi Yang, Jiancan Wu, Yanchen Luo, Jizhi Zhang, Yancheng Yuan, An Zhang,\nXiang Wang, and Xiangnan He. 2023. Large language model can interpret latent\nspace of sequential recommender. arXiv preprint arXiv:2310.20487 (2023).\n[60] Ghim-Eng Yap, Xiao-Li Li, and Philip S Yu. 2012. Effective next-items recom-\nmendation via personalized sequential pattern mining. In Proceedings of the\n17th International Conference on Database Systems for Advanced Applications\n(DASFAA). 48â€“64.\n[61] Qing Yin, Hui Fang, Zhu Sun, and Yew-Soon Ong. 2023. Understanding diversity\nin session-based recommendation. ACM Transactions on Information Systems\n(TOIS) 42, 1 (2023), 1â€“34.\n[62] Dianer Yu, Qian Li, Hongzhi Yin, and Guandong Xu. 2023. Causality-guided\ngraph learning for session-based recommendation. In Proceedings of the 32nd\nACM International Conference on Information and Knowledge Management (CIKM) .\n3083â€“3093.\n[63] Feng Yu, Yanqiao Zhu, Qiang Liu, Shu Wu, Liang Wang, and Tieniu Tan. 2020.\nTAGNN: Target attentive graph neural networks for session-based recommenda-\ntion. In Proceedings of the 43rd International ACM SIGIR Conference on Research\nand Development in Information Retrieval (SIGIR) . 1921â€“1924.\n[64] Zhenrui Yue, Sara Rabhi, Gabriel de Souza Pereira Moreira, Dong Wang, and Even\nOldridge. 2023. LlamaRec: Two-stage recommendation using large language\nmodels for ranking. In The 1st Workshop on Personalized Generative AI @CIKM\n(PGAI).\n[65] Peiyan Zhang, Jiayan Guo, Chaozhuo Li, Yueqi Xie, Jae Boum Kim, Yan Zhang,\nXing Xie, Haohan Wang, and Sunghun Kim. 2023. Efficiently leveraging multi-\nlevel user intent for session-based recommendation via atten-mixer network.\nIn Proceedings of the Sixteenth ACM International Conference on Web Search and\nData Mining (WSDM) . 168â€“176.\n[66] Xiaokun Zhang, Bo Xu, Liang Yang, Chenliang Li, Fenglong Ma, Haifeng Liu, and\nHongfei Lin. 2022. Price does matter! modeling price and interest preferences\nin session-based recommendation. In Proceedings of the 45th International ACM\nSIGIR Conference on Research and Development in Information Retrieval (SIGIR) .\n1684â€“1693.\n[67] Denny Zhou, Nathanael SchÃ¤rli, Le Hou, Jason Wei, Nathan Scales, Xuezhi\nWang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, et al . 2023.\nLeast-to-most prompting enables complex reasoning in large language models.\nIn Proceedings of the 17th International Conference on Learning Representations\n(ICLR)."
}