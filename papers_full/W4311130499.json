{
    "title": "Assessment of chemistry knowledge in large language models that generate code",
    "url": "https://openalex.org/W4311130499",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2105096877",
            "name": "Andrew D. White",
            "affiliations": [
                "University of Rochester"
            ]
        },
        {
            "id": "https://openalex.org/A2298549838",
            "name": "Glen M. Hocky",
            "affiliations": [
                "New York University"
            ]
        },
        {
            "id": "https://openalex.org/A2888500310",
            "name": "Heta A. Gandhi",
            "affiliations": [
                "University of Rochester"
            ]
        },
        {
            "id": "https://openalex.org/A3153332890",
            "name": "Mehrad Ansari",
            "affiliations": [
                "University of Rochester"
            ]
        },
        {
            "id": "https://openalex.org/A2566604316",
            "name": "Sam Cox",
            "affiliations": [
                "University of Rochester"
            ]
        },
        {
            "id": "https://openalex.org/A3041959245",
            "name": "Geemi P. Wellawatte",
            "affiliations": [
                "University of Rochester"
            ]
        },
        {
            "id": "https://openalex.org/A4311130878",
            "name": "Subarna Sasmal",
            "affiliations": [
                "New York University"
            ]
        },
        {
            "id": "https://openalex.org/A2167460620",
            "name": "Ziyue Yang",
            "affiliations": [
                "University of Rochester"
            ]
        },
        {
            "id": "https://openalex.org/A3171243909",
            "name": "Kangxin Liu",
            "affiliations": [
                "New York University"
            ]
        },
        {
            "id": "https://openalex.org/A2133605956",
            "name": "Yuvraj Singh",
            "affiliations": [
                "New York University"
            ]
        },
        {
            "id": "https://openalex.org/A3211103814",
            "name": "Willmor J. Peña Ccoa",
            "affiliations": [
                "New York University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W6702248584",
        "https://openalex.org/W6600109629",
        "https://openalex.org/W6603976542",
        "https://openalex.org/W2981852735",
        "https://openalex.org/W6600950960",
        "https://openalex.org/W6600505529",
        "https://openalex.org/W6785515443",
        "https://openalex.org/W6612613465",
        "https://openalex.org/W6602430550",
        "https://openalex.org/W6678156880",
        "https://openalex.org/W6811433222",
        "https://openalex.org/W4224060952",
        "https://openalex.org/W4281557260",
        "https://openalex.org/W2963096510",
        "https://openalex.org/W4226485558",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W4288805334",
        "https://openalex.org/W1965092590",
        "https://openalex.org/W1975147762",
        "https://openalex.org/W4385572894",
        "https://openalex.org/W4281763794",
        "https://openalex.org/W4288804596",
        "https://openalex.org/W4223908421",
        "https://openalex.org/W4378189609",
        "https://openalex.org/W2899070097",
        "https://openalex.org/W3171707284",
        "https://openalex.org/W4221143046",
        "https://openalex.org/W4281690148",
        "https://openalex.org/W4285178342",
        "https://openalex.org/W3099878876",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W4287024925",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W4226278401",
        "https://openalex.org/W3177813494",
        "https://openalex.org/W4281619372",
        "https://openalex.org/W4280597794",
        "https://openalex.org/W3198449425",
        "https://openalex.org/W2938704169",
        "https://openalex.org/W3034723486",
        "https://openalex.org/W2560511802",
        "https://openalex.org/W3098605233",
        "https://openalex.org/W2980282514",
        "https://openalex.org/W3118781290",
        "https://openalex.org/W4288089799"
    ],
    "abstract": "In this work, we investigate the question: do code-generating large language models know chemistry? Our results indicate, mostly yes. To evaluate this, we produce a benchmark set of problems, and evaluate these models based on correctness of code by automated testing and evaluation by experts. We find recent LLMs are able to write correct code across a variety of topics in chemistry and their accuracy can be increased by 30 percentage points via prompt engineering strategies, like putting copyright notices at the top of files. These dataset and evaluation tools are open source which can be contributed to or built upon by future researchers, and will serve as a community resource for evaluating the performance of new models as they emerge. We also describe some good practices for employing LLMs in chemistry. The general success of these models demonstrates that their impact on chemistry teaching and research is poised to be enormous.",
    "full_text": "Assessment of chemistry knowledge in large language models that generate code\nAndrew D. White,1, ∗ Glen M. Hocky,2, 3, † Heta A. Gandhi,1 Mehrad Ansari,1 Sam Cox,1 Geemi P.\nWellawatte,4 Subarna Sasmal,2 Ziyue Yang,1 Kangxin Liu,2 Yuvraj Singh,2 and Willmor J. Peña Ccoa2\n1Department of Chemical Engineering, University of Rochester\n2Department of Chemistry, New York University\n3Simons Center for Computational Physical Chemistry, New York University\n4Department of Chemistry, University of Rochester\n(Dated: December 9, 2022)\nIn this work, we investigate the question: do code-generating large language models know chem-\nistry? Our results indicate, mostly yes. To evaluate this, we produce a benchmark set of problems,\nand evaluate these models based on correctness of code by automated testing and evaluation by\nexperts. We find recent LLMs are able to write correct code across a variety of topics in chemistry\nand their accuracy can be increased by 30 percentage points via prompt engineering strategies, like\nputting copyright notices at the top of files. These dataset and evaluation tools are open source\nwhich can be contributed to or built upon by future researchers, and will serve as a community\nresource for evaluating the performance of new models as they emerge. We also describe some good\npractices for employing LLMs in chemistry. The general success of these models demonstrates that\ntheir impact on chemistry teaching and research is poised to be enormous.\nSIGNIFICANCE ST A TEMENT\nLargelanguagemodels(LLMs)cangeneratefunctional\ncomputer code. We assess the inherent ability of these\nmodels to solve problems in the domain of chemistry, and\nalso investigate whether intrinsic “knowledge” of chem-\nistry is contained within LLMs. All the models evaluated\nhere show some ability to solve chemistry problems, in-\ncluding equations, chemical structures, units, and princi-\nples. As LLMs become more available, it leads us to ask\nwhat more will researchers be able to do, and what more\ncan we ask from students in classes, if repetitive tasks\nare easily solved using these approaches.\nI. INTRODUCTION\nLarge language models (LLMs) are multi-billion pa-\nrameter transformer neural networks1 that are trained\non enormous collections of documents (corpus) without\nsupervision or labels.2 LLMs can do multiple tasks like\nclassifying natural language, translating text, and doc-\nument search. Perhaps the most remarkable task of\nLLMs is to complete an input string of text; via this\nmechanism (called causal language modeling), LLMs can\nwrite unit tests, document function, write code from a\ndoc string, answer questions, and complete stoichiomet-\nric equations.3,4\nWe previously discussed the outlook of LLMs in\nchemistry.5 In the few months since then, LLMs have\nbeen both developed for specific chemistry problems6,7\nand general LLMs have been applied in chemistry.8,9 An\n∗ andrew.white@rochester.edu\n† hockyg@nyu.edu\nopen question for LLMs such as GPT-3,3 T5,10 or GPT-\nneo11 that are trained on very large and varied textual\ndata is if they can be applied in domains like chemistry,\nwhich have specialized language and knowledge. In our\ninitial work,5 we found relationships between SMILES\nand natural language is possible with GPT-3. SMILES\nis the the standard method of representing molecules as\nstrings.12 It is even possible to loosely edit structures via\nnatural language (see Fig. 6).13,14 However, the extent\nto which LLMs can be directly applied in chemistry in\nthe broad context of research and teaching is unexplored.\nThe large amount of specific domain knowledge required\nto solve chemistry problems may limit applicability of\ngeneral LLMs. For example, recent work has found that\nknowledge of the periodic table of elements requires very\nhigh parameter counts.4\nRecent comparisons of LLMs that generate code can\nbe found Ref 15. Here, we focus our study on whether\nLLMs that generate code16 can be applied to chemistry\ntasks of a computational nature (both computational\nchemistry problems, and general tasks which can be ex-\npressed as simple computer programs, such as ranking\nelementsbyionicradius). MostLLMsthatgeneratecom-\nputer code are causal decoder-only models16–18—a user\nprovides a sequence of text (called the prompt) and it\nproposes a continuation of the text (the completion).19\nThere are LLMs trained on code that can infill or match\nencoder/decoder natural language to code like Code-\nBERT,20 but they are typically used for embedding code\nfor tasks like classification, document retrieval, or trans-\nlating code to natural language. Because it is not rea-\nsonable to use encoder-decoder or encoder-only models\nto generate code or answer questions with open-ended\nlength, thispaperexploressolelydecoder-onlycausallan-\nguage models.\nEvaluating LLMs’ knowledge of chemistry should\nbe distinguished from capability to reason or under-\nstand. LLMs can make compelling completions, but\n2\nare incapable of reasoning and demonstrate superficial\nunderstanding.21,22 Our goal is to evaluate LLMs’ abil-\nity to correlate natural language, equations, code, and\nheuristics of chemistry.\nII. METHODS\nWe have compiled a categorized set of chemistry\nand related example prompts for benchmarking code-\ngenerating LLMs in a public repository.23 To generate\nthese problems, we first decided upon a list of categories\nof chemistry and chemical engineering knowledge, listed\nin Tab. I, and set a goal of having at least 10 examples in\neach category for our initial database of problems. Mem-\nbers of our research groups (the authors on this paper),\nwho we consider to have sufficient expertise in these ar-\neas due to formal schooling, research, and teaching expe-\nrience, contributed the prompts and reference solutions\nfor these categories.\nThe examples in this table span a range of topics that\nwe consider common questions across chemistry fields.\nThere is some representation of computational chemistry\nresearch topics (categories corresponding to performing\nchemical simulations (sim), analyzing molecular dyan-\nmics simulations (md), chemical informatics (cheminf),\nand some of quantum mechanics (qm)), but this con-\nstitutes less than half of the initial prompts created by\nus. The rest correspond to typical questions that one\nmight encounter in general chemistry (genchem), bio-\nchemistry (bio), physical chemistry (thermodynamics,\nquantum mechanics, spectroscopy), and in laboratory\nclasses (plotting and statistics).\nWithin this set of topics, some examples were labeled\nas only expert evaluable, where automated evaluation is\ninfeasible or insufficient (e.g. plotting). The total num-\nber of examples is 84, of which 25 were expert evaluable,\nand the accuracy is 72% for the best performing model.\nThere is a strong correlation between model parame-\nter count and accuracy,24 so we focus only on the largest\nmodels with more than 1B parameters. The architec-\ntures of models are all decoder-only like GPT-33 with\nthe ability to insert completions,25 (except when noted).\nThe first model is a GPT-3 12B fine-tuned on code\n(Codex) abbreviated as “cushman.” It is known ascode-\ncushman-001 in the OpenAI API26. This is modified\nfrom the original Austin et al.16 somewhat and is de-\nscribed as “a stronger, multilingual version of the Codex\n12B model.”27. We also used code-davinci-002, ab-\nbreviated as “davinci.” This model is part of the cate-\ngory of “GPT-3.5” models that are derived from GPT-\n3.28 The number of parameters in davinci-class models\nis not public information, but may match the 175B pa-\nrameters of the model described in the GPT-3.5 paper.29\nFinally, we also considered the recent text-davinci-\n003 model which is derived from code-davinci-002\nwith a reinforcement-learning adaption from human user\nfeedback29 – although this model became available only\nafter human evaluation (below) was complete, so that\nour analysis is reported only on automated evaluations.\nThis model is denoted as ‘davinci3’ here.\nThe “incoder” models are two models from Fried et\nal.17 trained on code only. We chose incoder because it is\nabletoinfillcodeinadditiontocompletingcodeprompts,\nwhich gives a more direct comparison, and it has gener-\nally good performance. Lastly, we consider the ‘codegen’\nmodel,30 which is another decoder-only model trained on\na similar dataset to ‘incoder’. It was not trained for in-\nfilling, because it was designed for back-and-forth code\nsynthesis with natural language. Although it is not ex-\nactly analogous to the other models, it is one of very few\ncompetitive models that can generate working code, and\nso we include it here for comparison.30\nRecent benchmarks show davinci is best or nearly the\nbestongeneralprogrammingtasks. 15,31 Incoderwasused\nas implemented in HuggingFace transformers.32 To avoid\nlibrary changes since 2021 influencing accuracy, our eval-\nuations are done using the python version and packages\nfrom June 2021. The chosen date was based on reported\ntraining range from Ref. 31 and comes before training\ntime of Ref. 17.\nWhen developing example prompts and solutions,\nthe prompts were tested and modified using davinci.\nSome prompt engineering was inevitable through this\nprocess.3,33,34 However, prompts were not designed to get\na correct answer and some prompts (e.g., two atom har-\nmonic oscillator) were never correctly completed. We do\nemphasize that the reported accuracy is not one would\nexpect of the first prompt constructed on-the-fly for a\ngiven problem. Rather, they are constructed to answer\n“how much chemistry do these LLMs know?” These fig-\nures should not be construed as upper bounds either,\nas recent work on prompt engineering shows that multi-\nple steps (sometimes known as using “scratchpads”)18 or\neliciting multiple steps can further improve accuracy.28\nFollowing Chen et al.,31 a prompt completion is ac-\ncurate if the code functions correctly, not if it matches\na reference implementation. Most examples have both\na prompt and unit tests. Expert evaluable prompts for\nwhich there are not unit tests are not reported in the\naccuracy, unless specified. Five completions were gen-\nerated via top-k sampling35 and multiple temperatures\nat T = 0.05, 0.2, 0.5 (softmax scaling). We explored nu-\ncleus sampling,36 but found it to be no different than\nadjusting temperature for balancing diversity and cor-\nrectness of completions. We chosek = 5 for all models,\nexcept for incoder-6B where GPU memory limitations\nprevented sampling more thank = 1. Thus, those re-\nsults may be slightly inflated since accuracy is reported\non only a most likely output. Error bars in all plots\nare 95% confidence intervals generated from bootstrap\nresampling across top-k.\nExpert evaluation was performed onk = 3 outputs of\ndavinci (T = 0.2, “insert” context) and accessed through\na web interface.37 Each example contains a link to a cus-\ntom Google form which could be used to evaluate that\n3\nPrompt\nimport numpy as np\ndef run_mc(n_steps, T, k):\n    \"\"\"\n    This function performs metropolis monte carlo sampling of a harmonic \n    potential at temperature T and returns the trajectory\n    \"\"\"\n    [insert]\n    return traj\nInserted code - output (1)\n    traj = np.zeros(n_steps)\n    traj[0] = np.random.uniform(-1, 1)\n    for i in range(1, n_steps):\n*       x_new = np.random.uniform(-1, 1)\n        dE = 0.5*k*(x_new**2 - traj[i-1]**2)\n        if dE < 0:\n            traj[i] = x_new\n        else:\n            if np.random.uniform(0, 1) < np.exp(-dE/T):\n                traj[i] = x_new\n            else:\n                traj[i] = traj[i-1]\n(2) x_new = traj[i-1] + np.random.randn()\n(3) x_new = np.random.normal(traj[i-1], 1)\nFIG. 1. Example prompt and code generated for database example ‘mc_harmonic’ . Full output is the prompt with ‘[insert]’\nreplaced by code in lower box. The asterisk indicates a line that is faulty. Inset box shows equivalent lines from two other\nsolutions that are correct, if not necessarily optimal. This example is discussed in Sec. III A.\nTopic N expert incoder codegen davinci davinci3\nbio 13 2 0% 29% 43% (0%) 1 86%\ncheminf 10 0 20% 20% 50% 50%\ngenchem 11 0 29% 86% 86% 86%\nmd 11 3 0% 13% 63% (81%) 88%\nplot 10 10 – – – (57%) –\nqm 8 3 20% 60% 100% (59%) 100%\nsim 8 5 0% 0% 100% (64%) 100%\nspect 11 1 30% 20% 50%(12%) 40%\nstats 11 1 40% 80% 70% (88%) 60%\nthermo 10 0 10% 10% 80% 70%\ntotal 84 2 23 17% 35% 72% (57%) 75%\nTABLE I. The number of prompts by topic and best accuracy\nachievable in this work. “expert” is the number within a topic\nthat must be evaluated by an expert. We used the “copy-\nright” context for incoder-6B, “authority” for codegen-16B,\nand “insert” for davinci and T = 0.2 (best for all models).\nResults are averaged across top- k sampling and/or multiple\nexpert evaluators. 1expert evaluator scores are in parentheses.\n2some prompts appear in multiple topics. The abbreviations\nof topics are biochemistry (bio), cheminformatics (cheminf),\ngeneral chemistry (genchm), molecular dynamics & simula-\ntion (md), quantum mechanics (qm), methods of simulation\n(sim), spectroscopy (spect), statistics (stats), and thermody-\nnamics (thermo).\nexample, with results saved in a spreadsheet. The multi-\nple choice questions in the form were: “Is this question:\nEasy; Medium; Hard”, “Is the solution: Perfect; Correct\nbut not perfect; Runs and is almost correct; Does not\nrun but is almost correct; Is far from correct.” There\nwas also a box for extra comments. This evaluation did\nbreakout more detailed information like alignment be-\ntween prompt and completion or hazards of completion,\nlike recently proposed in Khlaaf.38 The full set of evalu-\nations, with personally identifiable information (student\nemails) removed, is available as a comma separated value\n(CSV) file in the Supporting Information. To make a\nnumerical evaluation of this data in Fig. 3, we assigned\nscores from 1–5 with 5 being the best (“Perfect”) and 1\nbeing the worst (“Is far from correct”). To compute an\noverall accuracy as reported in Tab. I, we assigned “Per-\nfect”, and “Correct but not perfect” a value of 1.0, and\nall others 0.0, then computed the mean score for each\nprompt separately. It should be noted that each assessor\nhad a different level of expertise on each topic, as well\nas a different level of python programming experience,\nalthough we feel all were sufficiently expert to evaluate\neach prompt with sufficient authority.\nIII. RESUL TS\nA. Example problems\nTo illustrate the kinds of tasks and impressive (if not\nalways correct) results produced by LLMs, we show the\noutput for one ‘sim’ category tasks in Fig. 1. To stan-\ndardize our tasks, each tasks is phrased as a function to\nbefilledin, asinthetopbox. Thispromptincludesafirst\nline which loads the numerical python (numpy39) library,\nwhich gives additional ‘context’ (see below). The rest of\nthe information for the LLM is contained in two places,\nthe names of the variables given as inputs ‘n_steps’, ‘T’,\n‘k’, and a comment string which says what the function\n4\nPrompt\nInserted code - output (4)\nimport math\nimport sys\ndef claussius(HVap, T1, P1, T2):\n   \"\"\"\n   This function returns the phase \n   transition pressure at temperature T2 \n   given a heat of vaporization HVap, \n   and and reference temperature and \n   pressure T1 and P1\n   \"\"\"\n   [insert]\n   return P2\n   P2 = P1*math.exp((HVap/8.314)*\n                   ((1/T1)-(1/T2)))\nFIG. 2. Example prompt and code generated for the database\nexample ‘claussius’ . Full output is the prompt with ‘[insert]’\nreplaced by code in lower box. Davinci passed our automated\ncheck for this example on three out of five tries.\ndoes/should do. In this case, the function should perform\nMetropolis Monte Carlo for a harmonic potential. Im-\nplicit in the instruction by the creator is that k represents\nthespringconstant, andsothiscodeshouldproducesam-\nples from the energy functionU(x) = 1/2k(x−x0)2, with\nx0 = 0 since it was not specified as an input, and also\nthat reduced units are used, such that Boltzmann’s con-\nstant kB = 1.0. We can see that—with quite minimal\ninstruction—the code in the output is correct except for\nan error on the line indicated with a ‘*’; in this line,\nthe position of the particle is completely resampled from\nscratch on the range [-1,1). This code would actually be\nfine if the system were constrained to be within a box of\nlength 2, and in the limit ofk >> 1 it will also appear\nto give correct results. The inset shows the equivalent\nline in two other outputs of the model, both of which\nare acceptable; one displaces the position by a Gaussian\nrandom number with µ = 0 and σ2 = 1, and the sec-\nond chooses a new position from a Gaussian with mean\ncentered at the current position andσ2 = 1. Note that\nneither of these is optimized for the choice of (k,T), as\nσ2 = 1 may be too large or too small to be efficient, de-\npendingonthespringconstantandtemperature. Finally,\ninoneoftheothertwooutputsforthisexample(available\nin the SI or on the results website),k is interpreted as\nBoltzmann’s constant, and the harmonic system is given\na spring constant of 1.0 implicitly; this is a reasonable re-\nsult of the model. It illustrates how the author must be\ncareful about what is implicit in their prompt and what\nis stated explicitly (e.g. here, that T is temperature).\nFig. 2 shows an additional example to highlight how\nthe davinci-codex model internally contains knowledge\nof chemistry topics (in this case, general chemistry per-\ntaining to phase equilibrium). The output shows that\nthe model “knows” the relevant rearrangement of the\nClaussius-Clapeyron equation, and returns the appro-\npriate result, assuming that the heat of vaporization\n(‘Hvap’) was given in joules/mol.\nB. Expert evaluations\nDavinci, the best performing model, does have broad\nknowledge of equations and common calculations across\nmultiple domains of chemistry. Table I gives the overall\naccuracy across the topics, models, and expert evaluable\ntopics. Both models can correctly answer prompts across\na range of topics, with davinci doing best. About 30 per-\ncentage points of accuracy is from prompt engineering,\nwhich is discussed further below.\nOn average, the accuracy on human evaluable topics is\nlower, reflecting their increased difficulty. These prompts\ninclude tasks like writing an input file for NWChem,40\nimplementing a Monte Carlo simulation of a harmonic\noscillator (Fig. 1), and generating a complex multi-panel\nplot. Fig. 3 shows a breakdown of difficulty from the\nindividual evaluations. There is a balance of easy and\nhard prompts in the dataset, as judged by experts. Our\nprimary result here is that the accuracy of the model is\nnegatively correlated with perceived prompt difficulty, as\nmight be expected but did not necessarily have to be the\ncase. We did not do any randomization or controls; each\nevaluator was able to see all prompts and all outputs, and\nso we acknowledge that scores could be biased by factors\nsuch as the order of the prompts on the website, and the\norder that results for a given prompt were presented on\nthe website. In the rest of this article, we focus only on\nprompts whose correctness can be evaluated by compar-\nison with an expected solution in an automated fashion.\nEasy Medium Hard\nIs this question\n0\n2\n4\n6Result quality\nn=300 n=242 n=108\nFIG. 3. 650 evaluations of davinci completions by the nine\ncoauthors who are postdoctoral scholars or Ph.D. students\nin chemistry or chemical engineering. Scoring is described in\nSec. II. We find that the typical result quality (white dot)\ndrops from ‘Perfect,’ to ‘Correct but not perfect’, to ‘Runs\nand is almost correct’ as perceived difficulty increased.\n5\n0\n1Accuracy\nstats\n thermo\n cheminf\n bio\n spectroscopy\nnone\ncustominsert\ncopyrightauthority\n0\n1Accuracy\nmd\nnone\ncustominsert\ncopyrightauthority\ngenchem\nnone\ncustominsert\ncopyrightauthority\nqm\nnone\ncustominsert\ncopyrightauthority\nsim\nmodel\ncodegen-16B\nincoder-6B\ncushman\ndavinci\ndavinci3\nFIG. 4. A comparison of accuracy of the LLMs compared in this study across different contexts, broken down by category.\nAdding context – short comments/imports – generally improves accuracy across topic and model. Error bars are 95% confidence\nintervals from bootstrapping across individual prompts, temperature, and from multiple completions.\nC. How to improve performance\nThere is a large accuracy gain when using basic prompt\nengineering strategies. Fig. 4 shows the effect of different\n“contexts” on accuracy across models. A context here is\ncode prepended before all prompts, or all prompts within\na topic. The contexts are given both in the Supporting\nInformation and our accompanying code. “Custom” in-\ncludes two pieces: some imports related to the topic (e.g.,\nrdkit41 for cheminf) and a single example to teach the\nmodel how to indicate the end of a prompt completion.\nThe imports are not just to prevent errors due to failure\nto include relevant libraries — they influence the com-\npletions and give context. For example, a “structure”\nafter importing rdkit means a bonded arrangement of\natoms; in contrast, a structure after importingopenmm42\n(a molecular dynamics simulation code) would implicitly\nmean a 3D arrangement of atoms, e.g. obtained from a\nPDB file.\nThe completion example is a one line statement (e.g.,\nprinting version number of imported package) with a\ncomment above and#end below. This causes the LLM to\nend completions with#end. We tried to ad-hoc look for\ncertain keywords such as new functiondefs, returns, or\ncomments as completion ends, but these heuristics were\noften violated. The completion example is significant for\nthe cushman model, which can only do completions but\nnot insertions. For davinci and the incoder models, we\ncan replace this with the “insert” contexts which have\nthe same imports but use a model capability to infill at\na special insert token (as in Fig. 1). Avoiding our com-\npletion example in the context seems to be insignificant\nfor davincni, but important for incoder.\nLLMs seem to be very very very susceptible to condi-\ntioning contexts like adding the word “very” many times\nto improve a completion43 or stating that the code “has\nno bugs.” We explored this in our benchmarks in two\nways. We tried inserting copyright notices and found\nin Figs. 4 and 5 that it does significantly improve accu-\nracy at higher temperatures. This makes intuitive sense;\nlowering temperature makes the LLM choose more likely\ncompletions and a copyright notice would more often be\nincluded with standard/quality code, thus giving a simi-\nlar effect to lowering temperature. The best performing\nmodel/temperature combination was not improved be-\ncause it already had a low temperature. We also tried\ninserting the statement “This is written by an expert\nPython programmer” as suggested by Austin[44] , and\nsaw slightly less improvement. Similar recent work has\nfoundcontextorspecificphrases(e.g., “let’sthinkstepby\nstep”) that elicit chain-of-thought outputs can give large\naccuracyimprovements.28,45 Friedet al. [17] ,Wei et al. [34]\nhave recently explored using metadata, including popu-\nlarity of code, as a mechanism to condition completions,\nso that we do not need to use ad-hoc prompt engineering.\nInterestingly, the results from davinci3 show that the im-\nprovements to the NLP model through human feedback\nremoved some of the observed sensitivity29 to prompt\nengineering on our examples.\n0.0\n0.5Accuracy\ncodegen-16B model incoder-6B model\nnone\ncustominsert\ncopyrightauthority\ncushman model\nnone\ncustominsert\ncopyrightauthority\n0.0\n0.5Accuracy\ndavinci model\nnone\ncustominsert\ncopyrightauthority\ndavinci3 model\ntemperature\n0.05\n0.2\n0.5\nFIG. 5. Comparison of context effect across models and tem-\nperatures. Having a custom context is most important. Note\nthat insert, copyright, and authority include the “custom”\ncontext. Error bars are 95% confidence intervals from boot-\nstrapping across individual prompts, temperature, and from\nmultiple completions. Cushman and codegen cannot do in-\nsertions.\n6\nAside from contexts, there are a few strategies to en-\nsure a prompt aligns the intent of a user with the com-\npletion. If the prompt contains programming mistakes or\nspelling mistakes, then the completion will be of similar\nquality. So a correctly spelled and intelligible prompt is\nnecessary.\nThe LLM tries to agree with each word in the prompt.\nIf a prompt is a function declaration and uses the phrase\n“compute the moment”, the model will probably not re-\nturn the value. Thus, the word “return” should be used.\nIf a package is imported in the prompt, the model will\ntry to make use of it. This can lead to problems if many\npackages are imported – it can be unexpected as to which\npackages the model will use, or the model thinks it must\nuse all of them.\nA major source of the errors in some of the categories\nsuch as ‘md’ is the proper use of functions from a package\nsuchas mdtraj, inparticular, improperknowledgeofhow\nmany and what type of values are returned by that func-\ntion; this could be a simple error or due to training on an\nearlier version of the module; these results may be able\nto be improved in the future by ‘fine tuning’ the LLM\non examples from a particular package that is frequently\nused in one’s work, or by adding additional context.\nD. Molecular structures\nOur goal is to evaluate how much chemistry LLMs\nknow. Besides evaluating tasks that can be expressed\nas programs, we also explored whether LLMs can con-\nnect natural language directly with molecular structures.\nWe tested both InstructGPT29 and davinci in these ex-\namples, but found InstructGPT to work better. Nei-\nther could convert from molecular SMILES to name of\nmolecule, as demonstrated with 0% accuracy on 100 ran-\ndom molecules from pubchem46 when we tried SMILES\nlength of less than 60 characters (relatively small/simple\nmolecules). The attempt from InstructGPT is shown in\nthe Supporting Information. InstructGPT was able to\nconvert a sentence describing a molecule into SMILES,\nas shown with examples in Fig. 6. InstructGPT is able\nto connect functional groups from SMILES to natural\nlanguage. The molecules are not exact matches, but\nthere is some correlation (e.g., oxygen near ring for\nphenol, amine). It is also able to correlate molecular\nproperties like lipophilicity with SMILES. InstructGPT\nrarely generates invalid SMILES; only the first molecule\nin Fig. 6 had a single invalid character (see Supporting\nInformation for SMILES). It appears that InstructGPT\nor other LLMs could be trained/fine-tuned on the con-\nnection between natural language and chemical struc-\ntures. Recently, specific models that can translate be-\ntweenmolecularstructureandnaturallanguagehavealso\nbeen trained from scratch.47\nFIG. 6. Generating molecules with InstructGPT (text-\ndavinci-002). Prompts are shown in annotations. The\nstrongly lipophilic molecule is C 505, a polystyrene that is in-\ndeed strongly lipophilic. Most examples contain mistakes, but\nwere mostly valid. The top-left example had an ambiguous\nring indicator index which was removed prior to drawing. All\nstructures do not match prompt exactly (indicated by crossed-\nicon), but do have details correlated with the prompt.\nE. Discussion\nDavinci seems to not reason well about computational\nchemistry. If we prompt davinci to use to a “highly ac-\ncurate single-point” quantum calculation inpyscf,48 it\nwill frequently use relativistic Hartree-Fock regardless of\nthe property being computed because it has memorized\nthat “relativistic” is associated with accurate. Another\nexample is in the “force constant” prompt which is meant\nto compute the force constant for a two-atom harmonic\noscillator with different masses given a wavelength. Per-\nhaps because this is an unusual variant of a common\nquestion (converting between force constant and wave-\nlength), davinci always fails on this question and is un-\nable to rearrange the equation to take a harmonic mean\nof masses.\nDavinci may also hallucinate functions that do not ex-\nist. If a difficult prompt is given, for example “return\nthe residual dipole couplings given a SMILES string,”\nthe model will simply try to use a non-existent method\nMolToRDC. As reported previously,21 LLMs are not able\nto do chemical reasoning when completing prompts.\nWe’d like to anecdotally note that the LLMs could per-\nform many of the benchmark problems if the natural lan-\nguage was in Chinese, German, or Spanish. We did not\nexplore this in depth, but a few example prompts written\nin Mandarin can be found in the Supporting Information.\nThe use of LLMs with prompts that are not in English\n7\nmay be a valuable tool for lowering the barrier to em-\nploying computational tools for those who are not native\nEnglish speakers, and who therefore may have a harder\ntime interpreting documentation and programming fo-\nrums.\nIV. CONCLUSIONS\nLLMs are now easily available via tools like tabnine49\nor copilot.50 We’ve found high accuracy on computa-\ntional chemistry questions, and it is inevitable that stu-\ndents and researchers will begin using these tools. From\nour results, high accuracy should be expected with rea-\nsonable prompts. Tricks like inserting copyright notices\nat the top of a source file seems to be another way\nto improve accuracy, although fine-tuning with human\nfeedback mitigates this effect29 as seen in davinci3. We\nfound that humans are able to gauge accuracy for easy\nto medium prompts, but care should be taken if using\ncompletions of difficult prompts. The seeming inability\nto generate syntactically invalid code means LLMs of-\nten producesomething, but it is up to the user to assess\nit. We also found somewhat unexpected capabilities like\ngenerating molecules from natural language and accurate\ncompletions with non-English prompts. For a broader\ndiscussion of what impact this will have on education,\nwe refer the interested reader to our earlier perspective\narticle.5\nACKNOWLEDGMENTS\nResearch reported in this work was supported by\nthe National Institute of General Medical Sciences of\nthe National Institutes of Health under award number\nR35GM137966 (to ADW) and R35GM138312 (to GMH).\nHAG was supported by NSF award 1751471. MA, SC,\nand ZY were supported by NIH award R35GM137966.\nGPW was supported by NSF award 1764415 SS and YS\nwere partially supported by NIH award R35GM138312,\nWJPC by R35GM138312-02S1, and KL partially by De-\npartment of Energy award DESC0020464. SS and KL\nwere also partially supported by the Simons Foundation\nGrant No. 839534. We thank Drs. Sanjib Paul, David\nGomez, and Navneeth Gokul who also contributed some\nexamples to the repository.\nAUTHOR CONTRIBUTIONS\nADW and GMH wrote NLCC software and designed\nnlcc-database, website, and human evaluation form.\nThey contributed examples to the nlcc-data repository\nand performed data analysis. All other authors con-\ntributed examples to the nlcc-data repository, partici-\npated in the expert evaluation, and assisted in writing\nthe manuscript.\nV. SUPPOR TING INFORMA TION\nSupporting figures, tables, and text are included in\nthe Supporting Information. Accuracy data is avail-\nable as comma separated value files. Contexts are avail-\nable as a markup file. The completions as HTML\npresented to expert evaluators is available at DOI:\n10.5281/zenodo.6800475.\n[1] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit,\nL. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin,\nAttention is all you need, Adv. Neural Inf. Process Syst.\n30 (2017).\n[2] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, Bert:\nPre-training of deep bidirectional transformers for lan-\nguage understanding, arXiv preprint arXiv:1810.04805\n(2018).\n[3] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Ka-\nplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry,\nA. Askell, et al. , Language models are few-shot learners,\nAdv. Neural Inf. Process Syst. 33, 1877 (2020).\n[4] A. Srivastava, A. Rastogi, A. Rao, A. A. M. Shoeb,\nA. Abid, A. Fisch, A. R. Brown, A. Santoro, A. Gupta,\nA. Garriga-Alonso, et al. , Beyond the imitation game:\nQuantifying and extrapolating the capabilities of lan-\nguage models, arXiv preprint arXiv:2206.04615 (2022).\n[5] G. M. Hocky and A. D. White, Natural language process-\ning models that automate programming will transform\nchemistry research and teaching, Digital Discovery 1, 79\n(2022).\n[6] S. Wang, Y. Guo, Y. Wang, H. Sun, and J. Huang,\nSmiles-bert: large scale unsupervised pre-training for\nmolecular property prediction, in Proceedings of the 10th\nACM international conference on bioinformatics, com-\nputational biology and health informatics (2019) pp.\n429–436.\n[7] N. Frey, R. Soklaski, S. Axelrod, S. Samsi, R. Gomez-\nBombarelli, C. Coley, and V. Gadepally, Neural scaling\nof deep chemical models, ChemRxiv 10.26434/chemrxiv-\n2022-3s512 (2022).\n[8] D. Flam-Shepherd, K. Zhu, and A. Aspuru-Guzik, Lan-\nguage models can learn complex molecular distributions,\nNat. Commun. 13, 1 (2022).\n[9] J. Ross, B. Belgodere, V. Chenthamarakshan, I. Padhi,\nY. Mroueh, and P. Das, Do large scale molecular lan-\nguage representations capture important structural in-\nformation?, arXiv preprint arXiv:2106.09553 (2021).\n[10] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang,\nM. Matena, Y. Zhou, W. Li, P. J. Liu, et al. , Exploring\nthe limits of transfer learning with a unified text-to-text\ntransformer., J. Mach. Learn. Res. 21, 1 (2020).\n8\n[11] L. Gao, S. Biderman, S. Black, L. Golding, T. Hoppe,\nC. Foster, J. Phang, H. He, A. Thite, N. Nabeshima,\net al. , The pile: An 800gb dataset of diverse text\nfor language modeling, arXiv preprint arXiv:2101.00027\n(2020).\n[12] D. Weininger, Smiles, a chemical language and informa-\ntion system. 1. introduction to methodology and encod-\ning rules, J. Chem. Inf. Comput. Sci. 28, 31 (1988).\n[13] C. Nantasenamat, “would be cool to have gpt-3 generate\nnew chemical structures in smiles notation?”, Twitter ,\n1516794237391863810 (2022).\n[14] A. D. White, “as suggested by @thedataprof, gpt-3 can\nactually generate molecules. very clever idea! prompt was\n”the smiles for this drug-like molecular are:”, Twitter ,\n1516795519284228106 (2022).\n[15] F. F. Xu, U. Alon, G. Neubig, and V. J. Hellendoorn, A\nsystematic evaluation of large language models of code,\nin Proceedings of the 6th ACM SIGPLAN International\nSymposium on Machine Programming (2022) pp. 1–10.\n[16] J. Austin, A. Odena, M. Nye, M. Bosma, H. Michalewski,\nD. Dohan, E. Jiang, C. Cai, M. Terry, Q. Le, et al. ,\nProgram synthesis with large language models, arXiv\npreprint arXiv:2108.07732 (2021).\n[17] D. Fried, A. Aghajanyan, J. Lin, S. Wang, E. Wal-\nlace, F. Shi, R. Zhong, W.-t. Yih, L. Zettlemoyer, and\nM. Lewis, Incoder: A generative model for code infilling\nand synthesis, arXiv preprint arXiv:2204.05999 (2022).\n[18] E. Nijkamp, B. Pang, H. Hayashi, L. Tu, H. Wang,\nY. Zhou, S. Savarese, and C. Xiong, A conversational\nparadigm for program synthesis, arXiv preprint (2022).\n[19] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei,\nI. Sutskever, et al. , Language models are unsupervised\nmultitask learners, OpenAI blog 1, 9 (2019).\n[20] Z. Feng, D. Guo, D. Tang, N. Duan, X. Feng, M. Gong,\nL. Shou, B. Qin, T. Liu, D. Jiang, et al., Codebert: A pre-\ntrained model for programming and natural languages,\narXiv preprint arXiv:2002.08155 (2020).\n[21] E. M. Bender and A. Koller, Climbing towards nlu: On\nmeaning, form, and understanding in the age of data, in\nProceedings of the 58th annual meeting of the association\nfor computational linguistics (2020) pp. 5185–5198.\n[22] E. M. Bender, T. Gebru, A. McMillan-Major, and\nS. Shmitchell, On the dangers of stochastic parrots: Can\nlanguage models be too big?\n , in Proceedings of the\n2021 ACM Conference on Fairness, Accountability, and\nTransparency (2021) pp. 610–623.\n[23] https://github.com/ur-whitelab/nlcc-data.\n[24] P. Liang, R. Bommasani, T. Lee, D. Tsipras, D. Soylu,\nM. Yasunaga, Y. Zhang, D. Narayanan, Y. Wu, A. Ku-\nmar, et al. , Holistic evaluation of language models, arXiv\npreprint arXiv:2211.09110 (2022).\n[25] M. Bavarian, H. Jun, N. Tezak, J. Schulman,\nC. McLeavey, J. Tworek, and M. Chen, Efficient training\nof language models to fill in the middle, arXiv preprint\narXiv:2207.14255 (2022).\n[26] Openai.com.\n[27] Https://beta.openai.com/docs/model-index-for-\nresearchers.\n[28] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwa-\nsawa, Large language models are zero-shot reasoners,\narXiv preprint arXiv:2205.11916 (2022).\n[29] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wain-\nwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama,\nA. Ray, et al. , Training language models to fol-\nlow instructions with human feedback, arXiv preprint\narXiv:2203.02155 (2022).\n[30] E. Nijkamp, B. Pang, H. Hayashi, L. Tu, H. Wang,\nY. Zhou, S. Savarese, and C. Xiong, A conversa-\ntional paradigm for program synthesis, arXiv preprint\narXiv:2203.13474 (2022).\n[31] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. d. O. Pinto,\nJ. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brock-\nman, et al. , Evaluating large language models trained on\ncode, arXiv preprint arXiv:2107.03374 (2021).\n[32] T. Wolf, L. Debut, V. Sanh, J. Chaumond, C. Delangue,\nA. Moi, P. Cistac, T. Rault, R. Louf, M. Funtowicz,\net al. , Huggingface’s transformers: State-of-the-art natu-\nral language processing, arXiv preprint arXiv:1910.03771\n(2019).\n[33] S. H. Bach, V. Sanh, Z.-X. Yong, A. Webson, C. Raffel,\nN. V. Nayak, A. Sharma, T. Kim, M. S. Bari, T. Fevry,\net al. , Promptsource: An integrated development envi-\nronment and repository for natural language prompts,\narXiv preprint arXiv:2202.01279 (2022).\n[34] J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. Chi,\nQ. Le, and D. Zhou, Chain of thought prompting elic-\nits reasoning in large language models, arXiv preprint\narXiv:2201.11903 (2022).\n[35] A. Fan, M. Lewis, and Y. Dauphin, Hierarchical neu-\nral story generation, arXiv preprint arXiv:1805.04833\n(2018).\n[36] A. Holtzman, J. Buys, L. Du, M. Forbes, and Y. Choi,\nThe curious case of neural text degeneration, arXiv\npreprint arXiv:1904.09751 (2019).\n[37] https://ur-whitelab.github.io/nlcc-data/.\n[38] H. Khlaaf, A hazard analysis framework for code\nsynthesis large language models, arXiv preprint\narXiv:2207.14157 (2022).\n[39] C. R. Harris, K. J. Millman, S. J. Van Der Walt, R. Gom-\nmers, P. Virtanen, D. Cournapeau, E. Wieser, J. Taylor,\nS. Berg, N. J. Smith, et al. , Array programming with\nnumpy, Nature 585, 357 (2020).\n[40] M. Valiev, E. J. Bylaska, N. Govind, K. Kowalski, T. P.\nStraatsma, H. J. J. Van Dam, D. Wang, J. Nieplocha,\nE. Aprà, T. L. Windus, et al., Nwchem: A comprehensive\nand scalable open-source solution for large scale molecu-\nlar simulations, Comp. Phys. Comm. 181, 1477 (2010).\n[41] G. Landrum et al. , Rdkit: A software suite for chemin-\nformatics, computational chemistry, and predictive mod-\neling, Greg Landrum (2013).\n[42] P. Eastman, J. Swails, J. D. Chodera, R. T. McGibbon,\nY. Zhao, K. A. Beauchamp, L.-P. Wang, A. C. Sim-\nmonett, M. P. Harrigan, C. D. Stern, et al. , Openmm\n7: Rapid development of high performance algorithms\nfor molecular dynamics, PLoS Comp. Biol. 13, e1005659\n(2017).\n[43] P. Isola, “language-conditional models can act a bit like\ndecision transformers, in that you can prompt them with\na desired level of “reward” . e.g., want prettier #dalle\ncreations? ”just ask” by adding ”[very]^n beautiful”:”,\nTwitter , 1532189616106881027 (2022).\n[44] J. Austin, “we found that code models get better when\nyou prompt them with i’m an expert python program-\nmer. the new anthropic paper did something similar,\nprefixing the model’s response with i’ve tested this\nfunction myself so i know that it’s correct:, Twitter ,\n1515063524258627586 (2022).\n9\n[45] Y. Bai, A. Jones, K. Ndousse, A. Askell, A. Chen, N. Das-\nSarma, D. Drain, S. Fort, D. Ganguli, T. Henighan,\net al., Training a helpful and harmless assistant with rein-\nforcement learning from human feedback, arXiv preprint\narXiv:2204.05862 (2022).\n[46] S. Kim, J. Chen, T. Cheng, A. Gindulyte, J. He, S. He,\nQ. Li, B. A. Shoemaker, P. A. Thiessen, B. Yu, et al. ,\nPubchem 2019 update: improved access to chemical\ndata, Nucleic Acids Res. 47, D1102 (2019).\n[47] C. Edwards, T. Lai, K. Ros, G. Honke, and H. Ji, Trans-\nlation between molecules and natural language, arXiv\npreprint arXiv:2204.11817 (2022).\n[48] Q. Sun, T. C. Berkelbach, N. S. Blunt, G. H. Booth,\nS. Guo, Z. Li, J. Liu, J. D. McClain, E. R. Sayfutyarova,\nS. Sharma, et al. , Pyscf: the python-based simulations of\nchemistry framework, Wiley Interdiscip. Rev. Comput.\nMol. Sci. 8, e1340 (2018).\n[49] https://www.tabnine.com/.\n[50] https://github.com/features/copilot."
}