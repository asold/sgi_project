{
  "title": "Large corpora and large language models: a replicable method for automating grammatical annotation",
  "url": "https://openalex.org/W4409292340",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A3008941337",
      "name": "Cameron Morin",
      "affiliations": [
        "Université Paris Cité"
      ]
    },
    {
      "id": "https://openalex.org/A3179840304",
      "name": "Matti Marttinen Larsson",
      "affiliations": [
        "University of Gothenburg"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4383045305",
    "https://openalex.org/W3034723486",
    "https://openalex.org/W4410521180",
    "https://openalex.org/W4328101245",
    "https://openalex.org/W4391578379",
    "https://openalex.org/W2999309192",
    "https://openalex.org/W4321445671",
    "https://openalex.org/W4391162965",
    "https://openalex.org/W4402036612",
    "https://openalex.org/W4402889170",
    "https://openalex.org/W3015131830",
    "https://openalex.org/W2117823388",
    "https://openalex.org/W4401611741",
    "https://openalex.org/W2810140910",
    "https://openalex.org/W4406337689",
    "https://openalex.org/W4400569093",
    "https://openalex.org/W4284885183",
    "https://openalex.org/W4392517661",
    "https://openalex.org/W4402101192",
    "https://openalex.org/W2070205520",
    "https://openalex.org/W3195573486",
    "https://openalex.org/W6888885402",
    "https://openalex.org/W4394958222",
    "https://openalex.org/W4307977375",
    "https://openalex.org/W3208028458",
    "https://openalex.org/W4403309762",
    "https://openalex.org/W4390011054",
    "https://openalex.org/W4389954479",
    "https://openalex.org/W4391166218",
    "https://openalex.org/W4387372743",
    "https://openalex.org/W4367369313",
    "https://openalex.org/W4388185044",
    "https://openalex.org/W4389966798",
    "https://openalex.org/W4389520697",
    "https://openalex.org/W4321649710",
    "https://openalex.org/W4399300622",
    "https://openalex.org/W3106272061"
  ],
  "abstract": "Abstract Much linguistic research relies on annotated datasets of features extracted from text corpora, but the rapid quantitative growth of these corpora has created practical difficulties for linguists to manually clean and annotate large data samples. In this paper, we present a method that leverages large language models for assisting the linguist in grammatical annotation through prompt engineering, training, and evaluation. We apply this methodological pipeline to the case study of formal variation in the English evaluative verb construction “ consider X (as) (to be) Y”, based on the large language model Claude 3.5 Sonnet and data from Davies’s NOW and Sketch Engine’s EnTenTen21 corpora. Overall, we reach a model accuracy of over 90 % on our held-out test samples with only a small amount of training data, validating the method for the annotation of very large quantities of tokens of the construction in the future. We discuss the generalizability of our results for a wider range of case studies of grammatical constructions and grammatical variation and change, underlining the value of AI copilots as tools for future linguistic research, notwithstanding some important caveats.",
  "full_text": "Cameron Morin and Matti Marttinen Larsson*\nLarge corpora and large language models: a\nreplicable method for automating\ngrammatical annotation\nhttps://doi.org/10.1515/lingvan-2024-0228\nReceived November 15, 2024; accepted March 5, 2025; published online April 10, 2025\nAbstract: Much linguistic research relies on annotated datasets of features extracted from text corpora, but\nthe rapid quantitative growth of these corpora has created practical diﬃculties for linguists to manually clean\nand annotate large data samples. In this paper, we present a method that leverages large language models for\nassisting the linguist in grammatical annotation through prompt engineering, training, and evaluation. We\napply this methodological pipeline to the case study of formal variation in the English evaluative verb con-\nstruction “consider X( a s )( t ob e )Y”, based on the large language model Claude 3.5 Sonnet and data from\nDavies’sN O Wa n dS k e t c hE n g i n e’s EnTenTen21 corpora. Overall, we reach a model accuracy of over 90 % on\nour held-out test samples with only a small amount of training data, validating the method for the annotation\nof very large quantities of tokens of the construction in the future. We discuss the generalizability of our\nr e s u l t sf o raw i d e rr a n g eo fc a s es t u d i e so fg r a m m a t i c a lconstructions and grammatical variation and change,\nunderlining the value of AI copilots as tools for future linguistic research, notwith s t a n d i n gs o m ei m p o r t a n t\ncaveats.\nKeywords: corpus linguistics; grammatical variation; artiﬁcial intelligence; large language models; annotation\n1 Introduction\nCorpus linguistic research typicallyworks with vast quantities of data, which appear to have only kept growing\nsince the 1990s and the early 2000s in the context of the“quantitative turn” undergone by theﬁeld (Kortmann\n2021). Researchers across linguistics have borne witness to a“march of data” underpinned by access to larger\nsources and improvements in the technological means to process data and build datasets, among other factors\n(Coats and Laippala 2024). For corpus-based research speciﬁcally, this means that linguists have gained access\nto increasingly massive corpora of natural language, in English and other languages. Notable examples include\nthe advent of big web-based corpora, such as the 20.1-billion word NOW corpus (Davies 2016) or the multi-\nlingual TenTen corpora availab l ei nS k e t c hE n g i n e( K i l g a r iﬀ et al. 2014); large corpora of social media data such\nas Twitter and YouTube (Bonilla et al. 2024; Coats 2023; Grieve et al. 2018; Morin and Coats 2023; Morin and\nGrieve 2024); and corpora spanning an increasingly wide typological scope of regional varieties and registers\n(Dunn 2020).\nThis radical shift in linguistic methodology has brought with it the unique asset of providing enough syn-\nchronic data to collect quantitatively representative samples of language phenomena from vast areas around the\nglobe. However, this evolution has also come with an outstanding practical problem, which represents the core\nissue considered in this paper. When faced with such large quantities of data, it is often necessary to manually\nclean overwhelming quantities of tokens. As an example of this issue, let us introduce the case study at the heart of\nthis paper, which involves the verbconsider in English.Consider is a verb that can be found in a number of larger\ngrammatical constructions, one of which is an evaluative use introducing an evaluation or judgement of\n*Corresponding author: Matti Marttinen Larsson, University of Gothenburg, Gothenburg, Sweden,\nE-mail: matti.marttinen.larsson@gu.se. https://orcid.org/0000-0002-6224-7872\nCameron Morin,Université Paris Cité, Paris, France. https://orcid.org/0000-0001-7079-449X\nLinguistics Vanguard 2025; aop\nOpen Access. © 2025 the author(s), published by De Gruyter. This work is licensed under the Creative Commons Attribution 4.0\nInternational License.\nsomething or someone (Jacques 2022).1 Although there is little previous research on the evaluativeconsider\nconstruction in English, it appears to display variation in its morphosyntactic realizations, with at least three\noptions, exempliﬁed in (1) from the 2012 blog section of the Corpus of Contemporary American English (COCA;\nDavies 2008– ). Theﬁrst is a bare realization of the verb directly followed by the subject complement, as in (1a). The\nsecond is a realization with the prepositionas making the object complement indirect, as in (1b). The third is a\nrealization with an inﬁnitival clauseto beintroducing a predicative complement, as in (1c).\n(1) a. Cain isconsidered a master of American hard boiled crimeﬁction (…)\nb. By the way, I alsoconsider Zelda IIas one of my favorites (…)\nc. Since heconsiders himself to bea man of God, one would think he would know that it is clearly stated in\nthe Bible that a Christian is NEVER to question the faith of another.\nThe relationship between these three variants is unclear and has not been explained in previous research. For\nexample, one relevant question that surfaces is whether the competing constructions are semantically, prag-\nmatically, or socially distinct (cf. Leclercq and Morin 2023). It has also been suggested by dictionaries of English\nusage such as Merriam-Webster that“the consider + as construction is becoming less and less common”, and that\nthe bare form appears to be the most idiomatic variant (Britannica Dictionary n.d.). We could therefore pursue a\ndiachronic line of enquiry and analyse potential language change in historical corpora.\nThe questions raised above would generally call for a corpus-based study. Crucially, however, the researcher\nmay well be hard-pressed to conduct such a study when attempting to collect relevant data on theconsider\nconstruction from large corpora. Indeed, searching the lemmatized form CONSIDER in the EnTenTen21 corpus\nusing Sketch Engine, weﬁnd no fewer than 18 million tokens, which far exceeds any human capacity to sort\nthrough. A common solution to this quantitative issue is to either extract a random sample from the corpora and\nproceed with the annotation of a more manageable amount of data, or to annotate data automatically using\nnatural language processing (NLP) techniques (e.g., spaCy; Honnibal and Montani 2017). However, in the case of\nthe consider construction, the problem remains that uses of the verb as an evaluative construction are far from\nexhausting all possible instances ofconsider hits. Indeed, the evaluative construction coexists with another\nprominent use ofconsider as a cognition verb,\n2 as shown in examples (2a)– (2c) (again, taken from the blog section\nof COCA; Davies 2008– ). In these examples,consider means ‘take into account’, ‘believe/think’, and‘contemplate’,\nrespectively.\n(2) a. Please consider all classes when punching number in to spread-sheet and designing new items.\nb. Perhaps Turbine justconsidered that his work was done as all the systems were in place (…)\nc. I hope heconsiders running in 2016!!\nTo get a sense of how diﬃcult it is toﬁnd the evaluative construction in an unsorted collection of data points, we\nextracted a random sample of 200 tokens of CONSIDER from the EnTenTen2021 corpus (see supplementary\nmaterial). Following a manual clean of this sample, out of these 200 tokens, only 11.5 % were found to be true\npositives, that is, actual data of interest for the research questions at hand.\nAs we hope to have made clear by this point, a dedicated corpus-based study of a grammatical construction\nsuch asconsider poses a signiﬁcant methodological challenge, and this is likely to hold for many other types of\nconstructions in English and other languages. It is indeed often a time-consuming, fatigue-generating, and hence\ncognitively ineﬃcient (Brazaitis and Status 2023) preliminary task to sift through large samples of data in search\nof the construction of interest. This challenge can be compounded by the amount of variation in patterns\n1 Jacques (2022: 178– 179) refers to these as“estimative” and conﬂates multiclausal [consider + complementizer that + clause] con-\nstructions with the evaluative monoclausal [consider X as Y]. Our analysis diﬀers in this regard. First, it seems to us that the two types\ndiﬀer semantically and pragmatically: whereas monoclausal [consider X as Y] directly introduces an evaluation, classiﬁcation, or\njudgement about something or someone, multiclausal [consider + complementizer that + clause] involves deliberation and is more\nindirect. This is why we consider the latter a use ofconsider as a cognition verb rather than evaluative. Second, they are structurally\nhighly distinct. We do therefore not consider multiclausalconsider to form part of the envelope of variation.\n2 See, for instance, the inclusion of the verbconsider in a glossary of cognitive verbs by the Queensland Curriculum and Assessment\nAuthority (2018).\n2 Morin and Marttinen Larsson\nco-occurring with the construction. For instance, any corpus-based inquiry of evaluativeconsider would need to\ninclude its potential interaction with passive constructions, in addition to the three morphosyntactic realizations\npresented above. This would give us no less than six sets of requests to handle simultaneously.\nTaking the example ofconsider, in this paper we showcase a methodological solution to these problems which\nmakes use of large language models (LLMs). In particular, we show that LLMs can be trained to more quickly,\nmore eﬃciently, and perhaps even more reliably deal with cleaning and annotation tasks for studies of gram-\nmatical constructions and grammatical variation. Notably, we outline a sequence of steps which can be taken to\nautomatically annotate large quantities of evaluativeconsider constructions, based on the key processes of\nprompt engineering, training, and evaluation. Our case study makes use of the LLM Claude 3.5 Sonnet (Anthropic\n2024a) and data from the NOW corpus and Sketch Engine’s EnTenTen21 corpus. Our ultimate goal in this paper is\ntwofold:\n(1) To build a replicable methodological pipeline that can be repurposed for the automatic annotation of a wide\narray of grammatical constructions in English and other languages\n(2) To substantially improve the quality of annotation and“quality of life” of future corpus studies of gram-\nmatical constructions, using LLMs as“copilots for linguists” (Torrent et al. 2024)\nThe rest of the paper is structured as follows. In Section 2, we brieﬂy review existing research on the use of LLMs\nas tools for linguistic studies. In Section 3, we take the case ofconsider constructions to delineate a replicable\nmethod for the automatic, supervised annotation of grammatical data, broken down into three main steps:\nprompt engineering (pre)training, and evaluation. Section 4 concludes on the generalizability of ourﬁndings and\nsome future directions for LLM-assisted research in grammatical variation and change, in addition to noting\nsome important caveats for an appropriate and responsible use of the method.\n2 Large language models\nThe use of LLMs in linguistics represents a booming research domain with a wide array of applications and\nquestions. To mention but a couple of examples, LLMs have sparked important theoretical discussions of their\npotential similarities with cognitive models of human linguistic processing, knowledge, and use (e.g., Cuskley\net al. 2024; Goldberg 2024; Leivada et al. 2024; Piantadosi 2023; Weissweiler et al. 2023); and they have been applied\nfor modelling processes of sociolinguistic variation (e.g., Grieve et al. 2025; Hekkel et al. 2024; Lilli 2023; Massaro\nand Samo 2023). In this section, we focus speciﬁcally on studies that have investigated how LLMs can be leveraged\nas “copilots for linguists” (Torrent et al. 2024), as long as they are handled with caution and carefully supervised\n(Denning et al. 2024; Ollion et al. 2023; see also Section 4).\nOne of the most popular LLMs for automatic data annotation in linguistics is ChatGPT (e.g., GPT-4; OpenAI\n2024). Pioneering studies have suggested that ChatGPT can be an eﬀective and reliable tool for a range of diﬀerent\ntopics, such as sentiment analysis (Belal et al. 2023), the evaluation of corpus annotation schemes in treebanks\n(Akkurt et al. 2024), and the annotation of pragmatic and discourse related phenomena in corpora (Yu et al. 2024).\nIn this paper, we use the LLM Claude 3.5 Sonnet (Anthropic 2024a; henceforth“Claude”), which has seen a rise in\nusage for NLP studies, including in comparison with ChatGPT (e.g., Caruccio et al. 2024; Kholodna et al. 2024).\nNLP-oriented LLMs such as spaCy (Honnibal and Montani 2017) already include speciﬁc features to assist\ncomputational linguists in the annotation of various types of data. However, there exist no user-friendly meth-\nodological pipelines for grammatical annotation that are accessible to the linguistic community at large. This is\nprecisely the gap that we seek toﬁll with this paper: not only do we seek to introduce an AI-assisted method for the\nannotation of speciﬁc grammatical constructions and their variation patterns for theﬁrst time, but we also seek to\nintroduce a method that is accessible to a maximally wide usership, given that it does not require advanced skills\nin coding, unlike with computational linguistic methods such as spaCy. Indeed, Claude, similarly to ChatGPT, is a\nconversational AI that is accessible through a chat interface, as opposed to spaCy; the key skills to master for the\nuser, then, are training and prompting. Prompt engineering consists in designing and reﬁning text inputs to an\nLarge corpora and large language models 3\nLLM for it to learn from mistakes and“reason better” (OpenAI and Ekin 2023; Shengnan et al. 2024). For the\nspeciﬁc task of automatic linguistic annotation, prompt engineering is essential, as it enables the researcher to\nsupervise and improve the accuracy of the LLM in completing the task. We outline a methodological pipeline for\nthis task in the next section.\n3 Automating grammatical annotation: an iterative process applied\nto consider\nIn this study, we built an iterative process in Anthropic’s Claude3 (used in November 2024) to design a pipeline for\nthe automatic annotation of grammatical variation in evaluative constructions with the verbconsider. The\niterative process ties in with the LLM’s ability to“learn” from mistakes (Wei et al. 2022): by working through\nexamples of corpus data on a case-by-case basis in the chat interface during the training phase, Claude gains an\nincreasingly better understanding of the classiﬁcation criteria and reﬁnes the instructions through training. This\ntraining is contained within the realms of the project, and it does not extend further; in other words, the\ncapabilities acquired and applied by Claude are constrained to a particular conversation and cannot be accessed\nthrough another chat outside of that chat (Anthropic 2024b).\nIn what follows, we outline the main steps involved in an automatic annotation pipeline in Claude. We also\ndiscuss diﬀerent strategies that can be used to enhance Claude’s performance. These strategies are all based on\nAnthropic’s guideBuild with Claude(Anthropic n.d.), which is the main source for the rest of this section.\n3.1 Prompting\nThe ﬁrst step of the pipeline consists in prompt engineering, that is, the formulation of input prompts that help\nelicit the desired response from Claude (Anthropic n.d.; White et al. 2023). The full prompt designed for the present\ncase study can be found in the supplementary material. LLMs such as Claude are highly sensitive to the\nformulation of prompts; therefore, we propose four design principles:\n(1) Make the prompt clear, speciﬁc, and contextualized: This involves explaining (a) what type and purpose of the\ntask Claude should perform (e.g., classiﬁcation), as well as what constitutes a successful task completion (e.g.,\nthe desired accuracy level); (b) speciﬁc instructions in sequential steps, such as bullet points or numbered\nlists; and (c) telling Claude in clear and explicit terms what type of classiﬁcation it should return (e.g.,\nLLM-based grading) and how the outcome will be evaluated.\n(2) Include examples: This involves providing a small number of on-point examples in the prompts, which allows\nClaude to better understand the type of classiﬁcations that are involved in the task prior to (pre)training.\n(3) Include XML tags: This involves helping Claude process the prompts more accurately. Some useful tags\ninclude <example> </example> and <examples> </examples> to wrap examples; <instructions> </in-\nstructions> to wrap speciﬁc instructions that Claude should consider; and <thinking> </thinking> to wrap\nstep-by-step Chain of Thought prompting (see below).\n(4) Tell Claude to think: When Claude is explicitly instructed to reason about its classiﬁcation and to“think step\nby step”, it breaks down the classiﬁcation process into a step-by-step process. This is referred to as Chain of\nThought prompting, which signiﬁcantly increases Claude’s performance in dealing with complex and\ndemanding tasks.\nWe now turn to the iterative process underlying Claude’s data classiﬁcation.\n3 Claude is available for free, but a professional plan can also be purchased to access the LLM at higher rate limits.\n4 Morin and Marttinen Larsson\n3.2 Pretraining, iterative training, validation, and evaluation\nFigure 1 illustrates the pipeline that we utilized in the present study. A key feature of our approach is that LLMs\nsuch as Claude receive substantial beneﬁts in performance through iterative reﬁnement. This involves the\nsynergy between training and validation, which can be repeated until a desirable accuracy is reached. The second\npart of the pipeline is thus iterative, consisting of a back-and-forth training process.\nFirst, we fed Claude with a dataset of approximately 500 pre-classiﬁed corpus sentences ofconsider that\ncontained a binary classiﬁcation (evaluative vs. non-evaluative, extracted from the NOW corpus). These obser-\nvations needed to contain data that accurately reﬂects the target, including edge cases (e.g., irrelevant and\nambiguous sentences; Anthropic n.d.). At this point, Claude was instructed to think4 about how the data had been\nclassiﬁed, and to think step by step to arrive at a conclusion regarding whether it would have classiﬁed the data in\nFigure 1: Methodological pipeline for LLM-assisted annotation of linguistic data.\n4 The use of cognition-related terms such asunderstand, think, andreason in reference to LLMs is intended as a convenient shorthand\nrather than a claim about their cognitive capacities and should be interpreted metaphorically rather than as an assertion of human-like\ncognition (cf. Bender and Koller 2020; Hazra et al. 2024; Kambhampati 2024).\nLarge corpora and large language models 5\nthe same manner, considering the provided instructions. Claude was also encouraged to ask questions and make\ncomments.\nThe second step involved two sub-processes:“supervised training” and “unsupervised classiﬁcation” with\nvalidation. Claude wasﬁrst instructed to provide a classiﬁcation of a training set with 100consider sentences.\nWorking in batches of 20– 25 sentences, Claude was encouraged to think step by step and include <thinking> </\nthinking> and <answer> </answer> for each classiﬁcation. For each batch, Claude received corrective feedback\nfrom the user, informing Claude of what classiﬁcations were wrong and why they were wrong. Each round of\ncorrective feedback constituted input that Claude used as its basis for further reﬁnement of classiﬁcation criteria,\nleading to an increasingly higher accuracy.\nFollowing the supervised training, the next step involved the unsupervised classiﬁcation of 100 unseen\nsentences. After having evaluated the unsupervised classiﬁcations (which had an accuracy of 67 %), Claude\nreceived feedback (e.g., level of accuracy, examples of misclassiﬁcations, new instructions clarifying any mis-\nunderstandings). This iterative training and validation cycle was repeated until Claude achieved the desired level\nof accuracy, with each round of classiﬁcations always providing unseen data. Importantly, throughout the\nconversations, opportunities emerged for Claude to propose new guidelines of analysis, decision criteria, com-\nments, and questions, which could constitute valuable clues to determine whether Claude had understood the\nassignment correctly. The user can correct Claude at any point of the interaction, allowing Claude to update its\nknowledge within the scope of the conversation.\nFinally, for the case study at hand, following pretraining, supervised training, and unsupervised training,\nClaude was instructed to classify this dataset while taking into account the reﬁnements that it had gained from the\nprevious rounds and it was presented with 101 more sentences for validation. For this validation dataset, Claude\nreached an accuracy of 93 % (94/101). Theﬁnal evaluation was made on a dataset of 102consider sentences that\nwere annotated blindly to Claude’s output. The evaluation metrics, which indicate a strong performance, are\npresented in Table 1.5 The process from pretraining to evaluation took approximately 60 min to complete,\nillustrating the substantial time-saving value of the methodological pipeline.\n4 Conclusion, caveats, and outlook\nIn this paper, we presented a methodological pipeline leveraging a large language model for the automatic\nannotation of grammatical data, based on the case study of the evaluativeconsider construction in English. By\nfollowing the key steps of prompt engineering, iterative training, and evaluation, we succeeded in building a\nmodel that was successful at automatically annotating unseen samples of the construction with a high rate of\naccuracy. In the speciﬁc case of evaluativeconsider, we are now able to address at scale the research questions\nsketched in Section 1: are the three evaluative variants equally common in present-day English, and if so, are they\nequivalent in meaning? Over time, do weﬁnd shifts in frequencies of these variants, and could we be dealing with\nTable : Evaluation of Claude’s binary classiﬁcation of (non-)evaluativeconsider.\nAccuracy  %( /)\nPrecision . %\nRecall . %\nF score . %\nMatthews correlation coeﬃcient .\n5 On 24 February 2025, a new Claude Sonnet model was released (Claude 3.7 Sonnet). To assess the direct replicability of our training,\nwe utilized the transcript and data used in Phases 1 and 2 (see Figure 1) as input in Claude 3.7 Sonnet, ensuring that it got the exact same\ninput andﬁne-tuning as the model reported on in this paper. This was done on a diﬀerent computer in another country, on another user\naccount (this time, CM’s account rather than MML’s). We subsequently fed Claude 3.7 Sonnet with the same evaluation dataset that we\nused to evaluate 3.5 (reported on in this paper). This rendered highly similar evaluation scores: accuracy 92 %; precision 94 %; recall\n85 %; F1 score 89 %; Matthews correlation coeﬃcient 0.83.\n6 Morin and Marttinen Larsson\na case of grammaticalization towards reduction (i.e., shortening,consider as> consider Ø; Britannica Dictionary\nn.d.; Levshina 2022; Marttinen Larsson 2024) or towards enhancement (i.e., lengthening,consider as/Ø> consider\nto be; Levshina 2022; Marttinen Larsson in press)?\nFrom a more general standpoint, in this paper we put forward this annotation method as a replicable one,\nwhich linguists can use for the analysis of other grammatical constructions, in English and in other languages. The\nindividual parameters, instructions, and evaluation criteria are of course bound to vary depending on the speciﬁc\nconstruction under study. In addition, it is reasonable to assume that some languages (especially English) will be\neasier to study than others depending on the amount of available training data in LLMs. Overall, however, we\nbelieve that this pipeline can be used as a tool for any linguist interested in analysing grammatical constructions\nwith large amounts of corpus data and the assistance of an AI copilot.\nThis paper has focused on a number of clear advantages presented by the method for future research, but\nthere are also a number of caveats to be made.\nFirst, the method presented in this paper oﬀers a new approach to corpus annotation, but it is not intended to\nreplace more traditional processes involving one or multiple annotators, particularly for tasks involving semantic\nor pragmatic ambiguity in linguistic constructions. In this study, we focused on a relatively clear-cut formal case,\nwhere inter-annotator disagreement is likely to be minimal. However, for more complex semantic classiﬁcations,\nit remains to be explored how LLMs such as Claude perform (for early work in this direction, see Yu et al. 2024).\nSecond, this paper focused on the use of one speciﬁc LLM, namely Claude, for the elaboration and the\nexecution of the methodological pipeline which we put forward. However, the choice of LLM for prompt-based\nannotation may be a crucial factor, as diﬀerent models have distinct training data and optimization strategies that\ncan inﬂuence their performance. While some models, such as ChatGPT, undergo reinforcement learning to reﬁne\ntheir outputs in ways that obscure the original distribution, others, like LLaMA, avoid such adjustments but still\nhave opaque training data. Transparent models such as Pythia oﬀer the advantage of allowing researchers to\nexamine potential training biases directly. In this study, we focused on Claude because it provides a powerful and\naccessible chat-based interface that does not require programming expertise, making it a practical tool for\nlinguists seeking to repurpose this method for their own research. Moreover, the systematic prompt engineering\nand training steps in our approach help mitigate potential biases in Claude’s training data. Future research could\nexplore how diﬀerent models, particularly those with transparent training data, compare in their ability to\nperform annotation tasks reliably.\nThird, another concern pertains to the legal aspects of training LLMs on corpus data. Given that some LLMs\nlearn from the input they receive, utilizing input data that contains sensitive information or that is in some way\naccess-restricted could be problematic. It therefore seems imperative that the type of data that researchers feed\ninto an LLM is duly considered before any LLM-assisted annotation task is initiated. Similarly, the type of LLM\nutilized in such tasks is also important from a legal standpoint, as some explicitly state that they do not use the\nreceived input or generated outputs to train their model. Claude’s policy of not utilizing user interactions as input\nrepresents an advantage in this respect.\nFourth, this approach raises new questions worth exploring. Since our study proposes a pipeline for anno-\ntating variable phenomena, it is crucial to consider that many such phenomena reﬂect ongoing language change.\nThe incoming variant may be marginal, causing a construction to exhibit both central and peripheral uses, which\ncould make it harder for the LLM to correctly identify peripheral cases. This issue relates to two aspects of the\ndata: (i) the distribution of“conventional” versus “incipient” variants across contexts; and (ii) the distinction\nbetween “easier” and more complex occurrences (edge cases; cf. Section 3). One such edge case arises when\nintervening material separatesconsider from its complement clause, complicating identiﬁcation (cf. Gibson 1998).\nHowever, the boundary between centre and edge is often unclear, making it diﬃcult to deﬁne a stratiﬁed sample\nfor training and evaluation. Instead, we include a representative corpus sample in training, ensuring the LLM\nlearns the envelope of variation. If edge cases are pervasive, they will be reﬂected in the training data. Regarding\nvariant distribution, careful design of training data is necessary. If prior research indicates ongoing change, and\nthe study involves incipient change or diachronic analysis, future work could mitigate this issue by using\nstratiﬁed training data– for example, data from diﬀerent time periods or a balanced distribution across variants.\nIn addition, evaluation metrics are critical. Given the likelihood of imbalance in diachronic or variationist studies,\nLarge corpora and large language models 7\nit is essential to consider all dimensions of the confusion matrix, not just correct classiﬁcations. We use the\nMatthews correlation coeﬃcient for this purpose (Table 1; see also Chicco and Jurman 2020; Marttinen Larsson\n2023).6\nFinally, a similar question concerns LLMs’ ability to classify language change in meaning rather than form:\ncan they accurately identify forms exhibiting layering due to ongoing change? While beyond this study’s scope,\nrecent research has explored this with other LLMs. Bonilla et al. (2025) analyse how Spanish BERT (BETO)\ninterprets literalmente ‘literally’, which is undergoing grammaticalization. Over time, this adverb has shifted\nfrom involving word-by-word denotation to developing increasingly expressive meanings (viz. intensiﬁcation of\nhyperbole, and truth-value emphasis). Using local interpretable model-agnostic explanations and Universal\nDependencies, Bonilla et al. (2025) examine BETO’s classiﬁcation of these three meanings andﬁnd that, while\nBETO struggles with the most grammaticalized and more“pragmatic” uses, it still performs well in classifying\nthese non-etymological meanings. Moreover, it relies on cues symptomatic of grammaticalization, such as\nincreased syntactic ﬂexibility and broader modiﬁcation of part-of-speech tags. This suggests that BETO quite\neﬀectively identiﬁes semantic layering despite formal stability. Future research should examine how other LLMs,\nsuch as Claude, perform on similar tasks.\nWith these considerations in mind, we feel that the following guidelines could serve as a basis for future\nresponsible and carefully calibrated applications of the LLM-assisted pipeline outlined in this study:\n– The training data should accurately reﬂect the data that the LLM will classify. For instance, it would not be\nappropriate to use training data from spoken informal corpora for a classiﬁcation task that will be performed\non written formal data, unless the empirical issue at hand is to assess performance diﬀerences that may be\nattributable to inter-register variability. The same concern applies to time periods, dialectal varieties, and so\non.\n– LLMs should not be used blindly. They should only come into play after substantial preparatory work on\nthe grammatical construction, including a comprehensive understanding of the envelope of variation\nand its possible edge cases. Only following these steps can the LLM be responsibly used for annotation\ntasks.\n– The brittle nature of prompt engineering should be kept in mind. LLMs are highly sensitive to wording. This\npaper hopes to inspire careful elaboration during prompt engineering, but caution is required.\n– While more research is needed to determine LLMs’ classiﬁcation performance on a greater variety of\nlinguistic phenomena, it seems that, as it currently stands, prompt-based LLM classiﬁcation using chatbot\ninterfaces (e.g., Claude) is perhaps most sensibly used for more straightforward classiﬁcation tasks (such as\nclassifying diﬀering surface realizations ofconsider), whereas other more semantically and pragmatically\ncomplex expressions require due caution and perhaps even more rigorous training and evaluation.\nSome remaining questions that were beyond the scope of this paper constitute important future directions. For\none, the present paper focused on illustrating the use of LLMs for extracting relevant data among large quantities\nof corpus occurrences. Future research should ascertain the performance of Claude in annotating predictor\nvariables of potential relevance in subsequent analyses. Moreover, designing a comparative study of the per-\nformance of Claude with that of other well-known, user-friendly LLMs, such as ChatGPT, is a desirable venture for\nthe optimization of the method introduced here. Furthermore, a more direct comparison between the perfor-\nmance of these LLMs and humans on comparable samples of corpus data may highlight their value for prolonged\nannotation sessions, which will necessarily result in accumulated fatigue for the annotator. For the time being,\nhowever, we hope to have shown that the methodology sketched here already reaches satisfactory levels of\naccuracy, and represents suﬃciently valuable cost eﬃciencies in time, energy, and data quality consistency, to be\nseriously considered in future linguistic studies of this type.\n6 Matthews correlation coeﬃcient is an evaluation metric particularly apt for dealing with unbalanced data, because it not only takes\ninto account the percentage of true predictions (accuracy) nor the harmonic mean between precision and recall (F1), but it also takes\ninto account negative elements (Chicco and Jurman 2020).\n8 Morin and Marttinen Larsson\nSupplementary material\nThe pretraining data, annotated datasets, and prompt histories for the case study of the paper are available on an\nOSF database at https://doi.org/10.17605/OSF.IO/TYJZ6.\nAcknowledgements: We would like to thank Jesper Håkansson for his sustained support and advice on training\nand prompt engineering using Claude 3.5 Sonnet.\nReferences\nAkkurt, Furkan, Onur Gungor, Büşra Marşan, Tunga Gungor, Balkiz Ozturk Basaran, Arzucan Özgür & Susan Uskudarli. 2024. Evaluating the\nquality of a corpus annotation scheme using pretrained language models.LREC-COLING 20246504– 6514. Turin: European Language\nResources Association (ELRA) https://aclanthology.org/2024.lrec-main.577.pdf (accessed 10 March 2025).\nAnthropic. 2024a. Claude 3.5 Sonnet [large language model]. https://claude.ai/ (accessed 15 November 2024).\nAnthropic. 2024b. Collaborate with Claude on projects. 2024. https://www.anthropic.com/news/projects (accessed 15 November 2024).\nAnthropic. n.d. Build with Claude. https://docs.anthropic.com/en/docs/build-with-claude/ (accessed 15 November 2024).\nBelal, Mohammed, James She & Simon Wong. 2023. Leveraging ChatGPT as text annotation tool for sentiment analysis.ArXiv https://doi.org/\n10.48550/arXiv.2306.17177.\nBender, Emily & Alexander Koller. 2020. Climbing towards NLU: On meaning, form, and understanding in the age of data. InProceedings of the\n58th annual meeting of the association for computational linguistics, 5185– 5198. Association for Computational Linguistics. https://\naclanthology.org/2020.acl-main.463/(accessed 10 March 2025).\nBonilla, Johnatan Esteban Huerfano, Laura M. Merino Hernández & Larsson Matti Marttinen. In press (2025). BERT’s interpretation\nof literalmente ‘literally’: What deep learning models can tell us about synchronic layering and diachronic shifts.Cognitive Semantics\n11(1). 1– 30.\nBonilla, Johnatan, Laura Margarita Merino Hernández & Miriam Bouzouita. 2024. YouTube corpora creation for morphosyntactic analysis of\nCanarian Spanish: The pluralization of the existential verb‘haber’ (‘there is/are’). InPaper presented at the inter-varietal applied corpus\nstudies (IVACS) biennial conference. University of Cambridge.\nBrazaitis, Marius & Andrius Satas. 2023. Regular shot-duration breaks do not prevent mental fatigue and decline in cognitive eﬃciency in\nhealthy young men during an oﬃce-like simulated mental working day: An EEG study.International Journal of Psychophysiology188.\n33– 46.\nBritannica Dictionary. n.d. Ask the editor:“Consider” and “consider as”. https://www.britannica.com/dictionary/eb/qa/consider-and-\nconsider-as (accessed 25 February 2025).\nCaruccio, Loredana, Stefano Cirillo, Giuseppe Polese, Giandomenico Solimando, Shanmugan Sundaramurthy & Genoveﬀa Tortora. 2024.\nClaude 2.0 large language model: Tackling a real-world classiﬁcation problem with a new iterative prompt engineering approach.\nIntelligent Systems with Applications21. https://doi.org/10.1016/j.iswa.2024.200336.\nChicco, Davide & Giuseppe Jurman. 2020. The advantages of the Matthews correlation coeﬃcient (MCC) over F1 score and accuracy in binary\nclassiﬁcation evaluation.BMC Genomics21(6). https://doi.org/10.1186/s12864-019-6413-7.\nCoats, Steven. 2023. Dialect corpora from YouTube. In Beatrix Russe, Nina Dumrukcic & Ingo Kleiber (eds.).Language and linguistics in a\ncomplex world,7 9– 102. Berlin: Mouton de Gruyter.\nCoats, Steven & Veronika Laippala (eds.). 2024.Linguistics across disciplinary borders: The march of data. London: Bloomsbury.\nCuskley, Christine, Rebecca Woods & Molly Flaherty. 2024. The limitations of large language models for understanding human language and\ncognition. Open Mind: Discoveries in Cognitive Science8. 1058–\n1083.\nDavies, Mark. 2008. The Corpus of Contemporary American English (COCA). https://www.english-corpora.org/coca/ (accessed 15 November\n2024).\nDavies, Mark. 2016. The NOW corpus (news on the web). https://www.english-corpora.org/now/(accessed 15 November 2024).\nDenning, Joseph, Xiaohan Guo, Bryor Snefjella & Idan Blank. 2024. Do large language models know who did what to whom?Proceedings of the\nAnnual Meeting of the Cognitive Science Society46. https://escholarship.org/uc/item/35x5m9cm (accessed 10 March 2025).\nDunn, Jonathan. 2020. Mapping languages: The corpus of global language use.Language Resources and Evaluation54. 999– 1018.\nGibson, Edward. 1998. Linguistic complexity: Locality of syntactic dependencies.Cognition 68(1). 1– 76.\nGoldberg, Adele. 2024. Usage-based constructionist approaches and large language models.Constructions and Frames16(2). 220– 254.\nGrieve, Jack, Andrea Nini & Diansheng Guo. 2018. Mapping lexical innovation on American social media.Journal of English Linguistics46(4).\n293– 319.\nGrieve, Jack, Sara Bartl, Matteo Fuoli, Jason Grafmiller, Weihang Huang, Alejandro Jawerbaum, Akira Murakami, Marcus Perlman,\nDana Roemling & Bodo Winter. 2025. The sociolinguistic foundations of language modeling.Frontiers in Artiﬁcial Intelligence7. 1– 18.\nLarge corpora and large language models 9\nHazra, Rishi, Gabriele Venturato, Pedro Zuidberg Dos Martires & Luc de Raedt. 2024. Can large language models reason? A characterization\nvia 3-SAT.ArXiv https://arxiv.org/abs/2408.07215.\nHekkel, Valerie, Driederike Schulz & Marta Lupica Spagnolo. 2024. Nous fêterons’ or ‘On va fêter’? Mimicking age-sensitive variation with\nChatGPT. AI-Linguistica 1(1). 1– 36.\nHonnibal, Matthew & Ines Montani. 2017. spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks,\nand incremental parsing. https://spacy.io/(accessed 10 March 2025).\nJacques, Guillaume. 2022. Estimative constructions in cross-linguistic perspective.Linguistic Typology27(1). 157– 194.\nKambhampati, Subbarao. 2024. Can large language models reason and plan?Annals of the New York Academy of Sciences1534(1). 15– 18.\nKholodna, Nataliia, Sahib Julka, Mohammad Khodadadi, Muhammed Nurullah Gumus & Michael Granitzer. 2024. LLMs in the loops:\nLeveraging large language model annotations for active learning in low-resource languages.ArXiv https://arxiv.org/abs/2404.02261\n(accessed 15 November 2024).\nKilgariﬀ, Adam, Vít Baisa, Jan Bušta, Miloš Jakubíček, Vojtěch Kovář, Jan Michelfeit, Pavel Rychlý & Vít Suchomel. 2014. The Sketch engine: Ten\nyears on.Lexicography 1(1). 7– 36.\nKortmann, Bernd. 2021. Reﬂecting on the quantitative turn in linguistics.Linguistics 59(5). 1207– 1226.\nLeclercq, Benoît & Cameron Morin. 2023. No equivalence: A new principle of no synonymy.Constructions 15(1). https://doi.org/10.24338/cons-\n535.\nLeivada, Evelina, Vittoria Dentella & Fritz Günther. 2024. Evaluating the language abilities of humans vs large language models: Three caveats.\nBiolinguistics 18. https://doi.org/10.5964/bioling.14391.\nLevshina, Natalia. 2022.Communicative eﬃciency: Language structure and use. Cambridge: Cambridge University Press.\nLilli, Silvia. 2023. ChatGPT-4 and Italian dialects: Assessing linguistic competence.Umanista Digitale16. 235– 263.\nMarttinen Larsson, Matti. 2023. Modelling incipient probabilistic grammar change in real time: The grammaticalisation of possessive\npronouns in European Spanish locative adverbial constructions.Corpus Linguistics and Linguistic Theory19(2). 177– 206.\nMarttinen Larsson, Matti. 2024. Probabilistic reduction and constructionalization: A usage-based diachronic account of the diﬀusion and\nconventionalization of the Spanishla de queconstruction. Cognitive Linguistics35(4). 579– 602.\nMarttinen Larsson, Matti. In press. Pathways of actualization across regional varieties and the real-time dynamics of syntactic change.\nLanguage Variation and Change.\nMassaro, Angelapia & Giuseppe Samo. 2023. Prompting metalinguistic awareness in large language models: ChatGPT and bias eﬀects on the\ngrammar of Italian and Italian varieties.Verbum 14. 1– 13.\nMorin, Cameron & Steven Coats. 2023. Double modals in Australian and New Zealand English.World Englishes. Advance online publication\nhttps://doi.org/10.1111/weng.12639.\nMorin, Cameron & Jack Grieve. 2024. The semantics, sociolinguistics, and origins of double modals in American English: New insights from\nsocial media.PLoS One19(1). https://doi.org/10.1371/journal.pone.0295799.\nOllion, Etienne, Rubing Shen, Ana Macanovic & Arnault Chatelain. 2023. ChatGPT for text annotation? Mind the hype!. https://doi.org/10.\n31235/osf.io/x58kn (accessed 15 November 2024).\nOpenAI. 2024. ChatGPT-4, version 4.0 [Large language model]. https://chat.openai.com (accessed 15 November 2024).\nOpenAI & Ekin, Sabit. 2023. Prompt engineering for ChatGPT: A quick guide to techniques, tips, and best practices.TechRxiv https://doi.org/10.\n36227/techrxiv.22683919.v2 (accessed 15 November 2024).\nPiantadosi, Steven. 2023. Modern language models refute Chomsky’s approach to language. In Edward Gibson & Moshe Pollak (eds.).From\nﬁeldwork to linguistic theory: A tribute to Dan Everett, 353– 414. Berlin: Language Science Press.\nQueensland Curriculum and Assessment Authority. 2018. Glossary of cognitive verbs: General syllabuses: Queensland Government. https://\nwww.qcaa.qld.edu.au/downloads/senior-qce/common/snr_glossary_cognitive_verbs.pdf (accessed 6 February 2025).\nShengnan, An, Zexiong Ma, Zeqi Lin, Nanning Zheng, Jian-Guang Lou & Weizhu Chen. 2024. Learning from mistakes makes LLMs better\nreasoner. ArXiv https://doi.org/10.48550/arXiv.2310.20689 (accessed 15 November 2024).\nTorrent, Tiago Timponi, Thomas Hoﬀmann, Arthur Lorenzi Almeida & Mark Turner. 2024.Copilots for linguists. Cambridge: Cambridge\nUniversity Press.\nWei, Jason, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le & Denny Zhou. 2022. Chain-of-thought\nprompting elicits reasoning in large language models. InProceedings of the 36th international conference on neural information processing\nsystems, 24824– 24837. Red Hook, NY: Curran Associates. https://dl.acm.org/doi/10.5555/3600270.3602070.\nWeissweiler, Leonie, Valentin Hofmann, Anjali Kantharuban, Anna Cai, Ritam Dutt, Amey Hengle, Anubha Kabra, Atharva Kulkarni,\nAbhishek Vijayakumar, Haofei Yu, Hinrich Schütze, Kemal Oﬂazer & David R. Mortensen. 2023. Counting the bugs in ChatGPT’s wugs: A\nmultilingual investigation into the morphological capabilities of a large language model. In Bouamor Houda, Juan Pino & Kalika Bali\n(eds.). Proceedings of the 2023 Conference on empirical Methods in natural language processing, 6508– 6524. Singapore: Association for\nComputational Linguistics.\nWhite, Jules, Quchen Fu, Sam Hays, Michael Sandborn, Carlos Olea, Henry Gilbert, Ashraf Elnashar, Jesse Spencer-Smith & Douglas Schmidt.\n2023. A prompt pattern catalog to enhance prompt engineering with ChatGPT.ArXiv https://doi.org/10.48550/arXiv.2302.11382\n(accessed 15 November 2024).\nYu, Danni, Luyang Li, Hang Su & Matteo Fuoli. 2024. Assessing the potential of LLM-assisted annotation for corpus-based pragmatics and\ndiscourse analysis: The case of apology.International Journal of Corpus Linguistics29(4). 534– 561.\n10 Morin and Marttinen Larsson",
  "topic": "Annotation",
  "concepts": [
    {
      "name": "Annotation",
      "score": 0.7323372960090637
    },
    {
      "name": "Computer science",
      "score": 0.7105539441108704
    },
    {
      "name": "Natural language processing",
      "score": 0.6592046618461609
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5989089012145996
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I204730241",
      "name": "Université Paris Cité",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I881427289",
      "name": "University of Gothenburg",
      "country": "SE"
    }
  ],
  "cited_by": 2
}