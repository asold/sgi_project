{
  "title": "OAG-BERT: Towards a Unified Backbone Language Model for Academic Knowledge Services",
  "url": "https://openalex.org/W4290875442",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2097346119",
      "name": "Xiao Liu",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2123677600",
      "name": "Da Yin",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2695970991",
      "name": "Jingnan Zheng",
      "affiliations": [
        "National University of Singapore"
      ]
    },
    {
      "id": "https://openalex.org/A2134539954",
      "name": "Xingjian Zhang",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A1972955069",
      "name": "Peng Zhang",
      "affiliations": [
        "Zhipu AI (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2096440077",
      "name": "Hong-xia Yang",
      "affiliations": [
        "Alibaba Group (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2157080782",
      "name": "Yuxiao Dong",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2098032575",
      "name": "Jie Tang",
      "affiliations": [
        "Tsinghua University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2572352603",
    "https://openalex.org/W2801930304",
    "https://openalex.org/W2970771982",
    "https://openalex.org/W2743104969",
    "https://openalex.org/W2911926823",
    "https://openalex.org/W2998385486",
    "https://openalex.org/W2103467726",
    "https://openalex.org/W2160992478",
    "https://openalex.org/W2964301473",
    "https://openalex.org/W3081168214",
    "https://openalex.org/W2970641574",
    "https://openalex.org/W3012615229",
    "https://openalex.org/W1932742904",
    "https://openalex.org/W2062340319",
    "https://openalex.org/W2022322548",
    "https://openalex.org/W2164948578",
    "https://openalex.org/W3002924435",
    "https://openalex.org/W2807953821",
    "https://openalex.org/W2021985945",
    "https://openalex.org/W2952205826",
    "https://openalex.org/W2925770972",
    "https://openalex.org/W2809279178",
    "https://openalex.org/W2167467982",
    "https://openalex.org/W2408569144",
    "https://openalex.org/W2962915085",
    "https://openalex.org/W2914796493",
    "https://openalex.org/W3173151551",
    "https://openalex.org/W1973938657"
  ],
  "abstract": "Academic knowledge services have substantially facilitated the development of the science enterprise by providing a plenitude of efficient research tools. However, many applications highly depend on ad-hoc models and expensive human labeling to understand scientific contents, hindering deployments into real products. To build a unified backbone language model for different knowledge-intensive academic applications, we pre-train an academic language model OAG-BERT that integrates both the heterogeneous entity knowledge and scientific corpora in the Open Academic Graph (OAG) -- the largest public academic graph to date. In OAG-BERT, we develop strategies for pre-training text and entity data along with zero-shot inference techniques. In OAG-BERT, we develop strategies for pre-training text and entity data along with zero-shot inference techniques. Its zero-shot capability furthers the path to mitigate the need of expensive annotations. OAG-BERT has been deployed for real-world applications, such as the reviewer recommendation function for National Nature Science Foundation of China (NSFC) -- one of the largest funding agencies in China -- and paper tagging in AMiner. All codes and pre-trained models are available via the CogDL toolkit.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7018800973892212
    },
    {
      "name": "Language model",
      "score": 0.4752599895000458
    },
    {
      "name": "Natural language processing",
      "score": 0.3413781523704529
    }
  ]
}