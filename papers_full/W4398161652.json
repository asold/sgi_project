{
  "title": "Large language model based framework for automated extraction of genetic interactions from unstructured data",
  "url": "https://openalex.org/W4398161652",
  "year": 2024,
  "authors": [
    {
      "id": null,
      "name": "Gill, Jaskaran",
      "affiliations": [
        "Federation University"
      ]
    },
    {
      "id": null,
      "name": "Chetty, Madhu",
      "affiliations": [
        "Federation University"
      ]
    },
    {
      "id": "https://openalex.org/A4317004189",
      "name": "Lim, Suryani",
      "affiliations": [
        "Federation University"
      ]
    },
    {
      "id": "https://openalex.org/A2210693846",
      "name": "Hallinan Jennifer",
      "affiliations": [
        "Federation University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2097352005",
    "https://openalex.org/W2976765180",
    "https://openalex.org/W2564387948",
    "https://openalex.org/W2125077974",
    "https://openalex.org/W2232370058",
    "https://openalex.org/W3033077186",
    "https://openalex.org/W3048664136",
    "https://openalex.org/W3045642779",
    "https://openalex.org/W2751754833",
    "https://openalex.org/W2530395991",
    "https://openalex.org/W2157380537",
    "https://openalex.org/W1931477211",
    "https://openalex.org/W2097960255",
    "https://openalex.org/W3093891978",
    "https://openalex.org/W3165832785",
    "https://openalex.org/W3086711114",
    "https://openalex.org/W2911489562",
    "https://openalex.org/W2794309877",
    "https://openalex.org/W2594818524",
    "https://openalex.org/W1850865022",
    "https://openalex.org/W1987170279",
    "https://openalex.org/W4297809627",
    "https://openalex.org/W6748512862",
    "https://openalex.org/W3131198033",
    "https://openalex.org/W2966739934",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W3128513378",
    "https://openalex.org/W3107048485",
    "https://openalex.org/W3204102400",
    "https://openalex.org/W3146499039",
    "https://openalex.org/W2951675429",
    "https://openalex.org/W3027982260",
    "https://openalex.org/W3079935470",
    "https://openalex.org/W3186054896",
    "https://openalex.org/W2032069669",
    "https://openalex.org/W1473718842",
    "https://openalex.org/W2613831280",
    "https://openalex.org/W2886936867",
    "https://openalex.org/W2512456704",
    "https://openalex.org/W2773368817",
    "https://openalex.org/W2560748602",
    "https://openalex.org/W2166111585",
    "https://openalex.org/W2148004186",
    "https://openalex.org/W2251713149",
    "https://openalex.org/W1986704581",
    "https://openalex.org/W2960293113",
    "https://openalex.org/W2795129839",
    "https://openalex.org/W1990794790",
    "https://openalex.org/W2762699776",
    "https://openalex.org/W2155142785",
    "https://openalex.org/W2786559064",
    "https://openalex.org/W4256466821",
    "https://openalex.org/W2963706121",
    "https://openalex.org/W2809349863",
    "https://openalex.org/W2971258845",
    "https://openalex.org/W4287687350"
  ],
  "abstract": "Extracting biological interactions from published literature helps us understand complex biological systems, accelerate research, and support decision-making in drug or treatment development. Despite efforts to automate the extraction of biological relations using text mining tools and machine learning pipelines, manual curation continues to serve as the gold standard. However, the rapidly increasing volume of literature pertaining to biological relations poses challenges in its manual curation and refinement. These challenges are further compounded because only a small fraction of the published literature is relevant to biological relation extraction, and the embedded sentences of relevant sections have complex structures, which can lead to incorrect inference of relationships. To overcome these challenges, we propose GIX, an automated and robust G ene I nteraction E x traction framework, based on pre-trained Large Language models fine-tuned through extensive evaluations on various gene/protein interaction corpora including LLL and RegulonDB. GIX identifies relevant publications with minimal keywords, optimises sentence selection to reduce computational overhead, simplifies sentence structure while preserving meaning, and provides a confidence factor indicating the reliability of extracted relations. GIX’s Stage-2 relation extraction method performed well on benchmark protein/gene interaction datasets, assessed using 10-fold cross-validation, surpassing state-of-the-art approaches. We demonstrated that the proposed method, although fully automated, performs as well as manual relation extraction, with enhanced robustness. We also observed GIX’s capability to augment existing datasets with new sentences, incorporating newly discovered biological terms and processes. Further, we demonstrated GIX’s real-world applicability in inferring E . coli gene circuits.",
  "full_text": "RESEA RCH ARTICL E\nLarge language model based framework for\nautomated extraction of genetic interactions\nfrom unstructured data\nJaskaran Kaur Gill\nID\n1\n*, Madhu Chetty\n1\n*, Suryani Lim\n1\n, Jennifer Hallinan\n1,2\n1 Health Innovation and Transforma tion Centre, Federation Universit y, Ballarat, Victoria, Austral ia,\n2 BioThink , Brisbane, Queens land, Australia\n* jaskaranka urgill@student s.federation. edu.au (JKG); madhu.chetty @federati on.edu.au (MC)\nAbstract\nExtracting biological interactions from published literature helps us understand complex bio-\nlogical systems, accelerate research, and support decision-making in drug or treatment\ndevelopment. Despite efforts to automate the extraction of biological relations using text\nmining tools and machine learning pipelines, manual curation continues to serve as the gold\nstandard. However, the rapidly increasing volume of literature pertaining to biological rela-\ntions poses challenges in its manual curation and refinement. These challenges are further\ncompounded because only a small fraction of the published literature is relevant to biological\nrelation extraction, and the embedded sentences of relevant sections have complex struc-\ntures, which can lead to incorrect inference of relationships. To overcome these challenges,\nwe propose GIX, an automated and robust Gene Interaction Extraction framework, based\non pre-trained Large Language models fine-tuned through extensive evaluations on various\ngene/protein interaction corpora including LLL and RegulonDB. GIX identifies relevant publi-\ncations with minimal keywords, optimises sentence selection to reduce computational over-\nhead, simplifies sentence structure while preserving meaning, and provides a confidence\nfactor indicating the reliability of extracted relations. GIX’s Stage-2 relation extraction\nmethod performed well on benchmark protein/gene interaction datasets, assessed using\n10-fold cross-validatio n, surpassing state-of-the-art approaches. We demonstrated that the\nproposed method, although fully automated, performs as well as manual relation extraction,\nwith enhanced robustness. We also observed GIX’s capability to augment existing datasets\nwith new sentences, incorporating newly discovered biological terms and processes. Fur-\nther, we demonstrated GIX’s real-world applicability in inferring E. coli gene circuits.\nIntroduction and motivation\nThe scientific literature holds significant biological insights about issues such as disease-caus-\ning mutations, health intervention methods, genome analysis, and potential drug targets. In\nthis research, we focused on the inference of transcriptional regulatory behaviour by identify-\ning genome-wide relationships among macromolecular entities such as genes, proteins, and\nRNAs [1]. The identification of such relations is relevant in developing accurate computational\nPLOS ONE\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 1 / 22\na1111111111\na1111111111\na1111111111\na1111111111\na1111111111\nOPEN ACCESS\nCitation: Gill JK, Chetty M, Lim S, Hallinan J (2024)\nLarge language model based framewo rk for\nautomate d extraction of genetic interaction s from\nunstructure d data. PLoS ONE 19(5): e0303231.\nhttps://do i.org/10.1371/j ournal.pone .0303231\nEditor: Michal Ptaszyns ki, Kitami Institute of\nTechnology , JAPAN\nReceived: September 26, 2023\nAccepted: April 23, 2024\nPublished: May 21, 2024\nPeer Review History: PLOS recognize s the\nbenefits of transpar ency in the peer review\nprocess; therefore, we enable the publication of\nall of the content of peer review and author\nresponse s alongside final, published articles. The\neditorial history of this article is available here:\nhttps://doi.o rg/10.1371/jo urnal.pone.0 303231\nCopyright: © 2024 Gill et al. This is an open access\narticle distributed under the terms of the Creative\nCommons Attributi on License, which permits\nunrestricted use, distribution , and reproduction in\nany medium, provide d the original author and\nsource are credited .\nData Availabilit y Statement: The GIX framework\ncode, pseudocod e, dataset s, extracte d relations,\nmodels, and relevant data used in this study are\navailable on GitHub at https://githu b.com/\nJaskaranKau rGill1/Gene-I nteraction-Ex traction.\nmodels of genetic networks, providing insights into disease progression, intracellular func-\ntions, and drug behaviour.\nThe automated acquisition of prior knowledge from unstructured text is crucial but chal-\nlenging, given the exponential growth in the published literature due to recent technological\nadvancements in scientific research [2]. Medline (PubMed) reported a doubling of indexed\narticles on Gene Regulatory Networks in the last decade, reflecting increased interest in under-\nstanding genomic interactions at a cellular level, both experimentally and computationally [3].\nDespite the huge number of papers available, only those with experimentally observed tran-\nscriptional links are relevant to the extraction of relationships among biological entities. Fur-\nther, only sections containing key sentences can be used for identifying biological interactions.\nThese sentences reference multiple biological entities, and have complex structures comprising\nseveral clauses and technical terminology [4]. Biological experiments are susceptible to errors\nduring data collection, demanding substantial efforts to establish the relevance and authentic-\nity of extracted regulations. Thus, most structured databases such as TRANSFAC [5] and Reg-\nulonDB [6], rely on human experts to pre-process scientific papers, extract domain-related\nrelations, and authenticate the information [7].\nManually curating genomic repositories and annotating genetic relationships from litera-\nture is time-consuming and challenging [8]. Traditional reading and summarising lack scal-\nability, are subject to personal interpretations, and are time-consuming. Automating the pre-\nprocessing of scientific literature and post-processing of extracted information using Natural\nLanguage Processing (NLP) techniques can address these limitations. Several researchers have\nstudied automating pre-processing and post-processing for accurately extracting relations\nfrom unstructured data. Most pre-processing techniques involve the extraction of all available\nabstracts within a specific timeline from online resources such as PubMed [9–11]. However,\nthese steps, while effective in domains with simple concepts and interactions, prove inefficient\nin the complex biological domain, with entity relations specific to organisms, cell function, or\ndisease conditions.\nIn the relation extraction (RE) stage following pre-processing, statistical methods aim to\ncapture entity relationships through feature extraction [1]. Approaches such as sentence sim-\nplification [12], link grammar parsing [13], and a combination of vector and tree-based kernels\n[14] enhance protein-protein interaction (PPI) relation extraction in simpler sentences. How-\never, these methods face limitations in handling complex biological sentences, and simplifica-\ntion can lead to overfitting and information loss. These methods heavily depend on tools like\nMedPost (a POS tagger) or existing biological knowledge bases. Fundel et al. [15] reported that\nmost of the false interactions predicted by RelEx, a rule-based parse tree NLP technique, are\ndue to incorrectly tagged entities, POS-label error, or insufficient rule-based sentence con-\nstruction. Recently introduced pre-trained neural network models provide substantial benefits\nwhen capturing both syntactic and semantic information, surpassing the capabilities of\nmachine learning methods and word embedding techniques [16–18]. Despite the specific bio-\nmedical training of BioBERT (a pre-trained Bert-based model), its improvement in relation\nextraction tasks is marginal [19]. The complex sentence structure describing causal depen-\ndency still limits the applicability of RE techniques. Despite rigorous pre-processing and RE,\ninferred interactions may still contain noisy entities, inaccurate predictions, and conditional\nrelations. A post-processing step such as unsupervised clustering [20] and confidence level cal-\nculation [21], if integrated with prior knowledge and model prediction confidence, can further\nrefine results by eliminating falsely predicted named entities and relations.\nResearchers have tackled different stages of relation extraction from the literature, including\npre-processing, post-processing, and relation extraction itself. However, there is no overarch-\ning framework that comprehensively addresses all aspects of biological relation extraction.\nPLOS ONE\nGene interaction extraction framewo rk\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 2 / 22\nFunding: The author(s) received no specific\nfunding for this work.\nCompeting interests : The authors have declared\nthat no competing interests exist.\nWhile specific tools and technologies may evolve or change over time, a well-designed frame-\nwork offers a stable underlying structure, methodology, or approach. To this end, we propose\nsystematic, automated and robust Gene Interaction Extraction (GIX), that efficiently identifies\nrelevant publications with minimal keywords, optimises sentence selection, and provides a\nconfidence factor for the reliability of extracted biological relations. GIX is a novel three-stage\nframework for Gene Interaction Extraction, involving: (i) Pre-processing; (ii) Relation extrac-\ntion; and (iii) Post-processing. Leveraging the fine-tuned pre-trained domain-specific NLP\nmodels, GIX is designed to optimally extract regulatory links among genes/proteins in a set of\nabstracts from PubMed. It automates all of the processes required for biological RE, and elimi-\nnates the manual intervention required to gather and transform problem-specific data into an\nacceptable RE format. The pre-processing phase involves an abstract search for target-network\ninformation, selecting sentences on transcriptional regulation to eliminate irrelevant text,\nreduce computational overload, and improve accuracy. In the Relation Extraction stage, we\nharness the biological contextual understanding of BioBERT and BERN2 (a pre-trained Bert-\nbased Bio-named entity recognition model). Additionally, an entity-labelling schema is pro-\nposed to enhance the accuracy of relation prediction. This schema works by reducing sentence\ncomplexity without compromising grammatical structure, avoiding information loss. In post-\nprocessing, BERN2 and tailored NLP techniques refine extracted biological relational entity\nnames, incorporating a novel confidence measure to authenticate regulations and sources and\nimprove accuracy by eliminating false positives.\nSeveral experiments were performed using datasets including BioInfer [22], HPRD50 [15],\nIEPA [23], and LLL [24]. The proposed RE model (Stage-2 of the framework) achieved a sig-\nnificant improvement of 13.7% in F-Score for HPRD50 compared to the previous best-per-\nforming method. GIX, achieved superior performance in RE from dataset LLL and database\nRegulonDB. In experiments with LLL, our results showed that our GIX framework not only\nachieved optimum accuracy but also reported multiple relation dictating sentences per regula-\ntion, as opposed to the single-sentence per relation manner common in benchmark datasets.\nThe structure of the paper is as follows: an overview of the relevant preliminaries is pro-\nvided in the \"Background\" section. The \"Methods\" section details the processes and models\nused in our three-staged GIX framework. In the \"Results\" section, we cover the experimental\nsetup of benchmark datasets, present their respective results, and discuss the outcomes. Lastly,\nthe \"Conclusion\" section concludes the paper and explores future directions.\nBackground\nUnstructured text and relation extraction\nStructured data, such as tables and databases, have a consistent layout and predictable pattern.\nIn contrast, unstructured data such as written and spoken text lacks a predefined structure,\nmaking it difficult to process [25]. These data can consist of diverse languages, and contain\ngrammatical errors, abbreviations, and context-dependent meanings. It is difficult to retrieve\nonly relevant data, because of the size of datasets, the diversity of publications, and the rapid\nevolution of multidisciplinary fields. Efforts to standardise vocabulary in biomedical literature,\nsuch as MeSH, help tackle unstructured data by assigning terms, aiding in information\nretrieval and relation extraction, thereby enhancing biomedical research. RE is more challeng-\ning than named entity recognition or classification, due to the lack of explicit markers for rela-\ntionships and the complex contextual dependencies between entities, which make it hard to\naccurately identify and extract the underlying relationships from unstructured text. RE tasks\ncan be classified into one of two categories: (1) rule-based methods which identify pre-defined\npatterns; and (2) machine-learning (ML) models which treat RE as a classification problem\nPLOS ONE\nGene interaction extraction framewo rk\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 3 / 22\n[26]. ML based RE approaches have been further classified into kernel-based, feature-based,\nand deep learning (DL) categories. Various ML methods have been used to extract regulations\namong genes and gene products However, building and training RE models is a complex and\ntime-consuming task, as the models need to be trained using a large dataset. Advanced NLP\ntechniques, including text mining, RE, and named entity recognition, have proved very effec-\ntive in extracting meaningful information from complex and variable unstructured text [27].\nPre-trained large language models\nIn recent years, pre-trained models based on NLP techniques have been shown to work effec-\ntively with unstructured text, and have been used in a range of applications. Being pre-trained\non large data, they require little or no training. Well known large language models (LLM) such\nas Embeddings from Language Models (ELMO) [28] and Bidirectional Encoder Representa-\ntions from Transformers (BERT) [29] are pre-trained on massive amounts of text data, allow-\ning them to learn rich linguistic patterns and semantics. ELMO introduced contextual word\nembeddings, in which each word representation is dynamically generated based on the sur-\nrounding context. BERT is a transformer-based model that learns bidirectional contextual rep-\nresentations of words. Both ELMO and BERT models have demonstrated excellent\nperformance across various NLP tasks, including named entity recognition, part-of-speech\ntagging, sentiment analysis, and RE [30–33]. However, BERT has been shown to surpass\nELMO in performance, as it learns bidirectional contextual representations, enabling a deeper\nunderstanding of semantic relationships [34]. The domain-specific LLMs perform RE by cap-\nturing specific knowledge, thus improving accuracy. BioBERT, the BERT model optimized for\nbiomedical text mining, is domain-specific, and is pre-trained on PubMed abstracts and PMC\narticles [19]. BioBERT can easily be fine-tuned to perform text extraction tasks, and has been\nsuccessfully applied to tasks such as the allocation of phenotypes to protein-protein interac-\ntions and the extraction of drug-drug interactions [35,36]. It has outperformed other state-of-\nthe-art NLP-based RE methods in the biological domain [19].\nNamed entity recognition\nNamed entity recognition (NER) and biological NER (BioNER), identifies biological entities\nsuch as genes, proteins, diseases, drugs, and miRNAs [37]. BioNER methods fall into one of\nthree categories: (1) knowledge-based; (2) rule-based; or (3) machine learning [38]. A knowl-\nedge-based approach uses an existing database or dictionary to identify known entities. Such\nmethods are simple to implement, but limit NER tagging to known entities [39]. The rule-\nbased approach tends to overfit and fails to generalise, and thus is ineffective when applied to\nall cases. State-of-the-art machine learning techniques use POS tags and apply grammatical\nstructure and interdependencies within a text to conveniently identify the named entities.\nGene and protein names have been labelled using a combination of conditional random fields\n(CRF) and bidirectional long short-term memory (LSTM) architecture [40]. ML models such\nas Support Vector Machines (SVMs) and hidden Markov models have been used for BioNER.\nAlthough ML techniques perform better than other traditional methods, they require a large\namount of manually annotated training data [38]. Pre-trained language models such as Bio-\nBERT can be fine-tuned to easily perform BioNER without needing a large amount of training\ndata. BERN2, a BioNER tool reported in 2022, not only supports NER, but also allows named\nentity normalization (NEN). NEN allows mapping recognised named entities to a common or\ncanonical form ensuring uniform representation of named entities. BERN2 has outperformed\nexisting BioNER tools, including BERN, on several applications, including the identification of\ndiseases, drugs, species, genes, and proteins.\nPLOS ONE\nGene interaction extraction framewo rk\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 4 / 22\nDatasets\nSome of the comprehensive repositories of curated protein and genetic interactions collected\nfrom the scientific literature are BioInfer [22], HPRD50 [15], IEPA [23], and LLL [24]. These\nresources are commonly used as benchmark datasets with which to study RE [15,41,42]. BioIn-\nfer contains a total of 9,666 full dependency annotations of gene, protein, and RNA regulations\nfrom 1,100 sentences. HPRD50 includes 50 abstracts from Human Protein Reference Database\n(HPRD) for direct regulation relation annotation. IEPA, is an Interaction Extraction Perfor-\nmance Assessment of 300 abstracts using two named biochemical entities. LLL, the Learning\nLanguage in Logic challenge, contains 330 gene/protein interactions labelled as regulatory\nfrom 77 unique sentences. Processing these datasets for RE requires a combination of\nadvanced NLP techniques, domain knowledge, and careful pre-processing to handle the wide\nrange of interaction types, varying sentence structures, and the need to disambiguate entities\nand their relationships.\nRegulonDB is a manually annotated, publicly available database containing transcriptional\nregulations in Escherichia coli, also known as E. coli [6]. The database contains transcription\nfactor (TF) regulations including TF-gene, TF- transcriptional unit, TF-operon, and TF-TF.\nEach regulation is classified as weak or strong based on the type of experiment used to identify\nthe interaction. For instance, a ChIP analysis with statistical validation is considered to provide\nstronger evidence than ChIP-chip only or ChIP-sequence analysis.\nMethods\nThis section addresses the improvement of the prediction accuracy of genetic interactions\nusing the published literature. We propose an automated framework involving two Large Lan-\nguage Models (LLM)—BioBERT and BERN2—which are pre-trained on a large corpus of bio-\nlogical data. The overall architecture of the proposed LLM based framework is presented in\nFig 1. The framework has three stages: (i) Stage-1: Pre-processing; (ii) Stage-2: Relation extrac-\ntion; and (iii) Stage-3: Post-processing. The pre-processing and post-processing stages in GIX\nplay a crucial role in addressing the inherent imbalance in biological datasets. In a sentence\nwith 2 entities, the number of potential relationships, taking direction into consideration is\nFig 1. Schematic of fully automa ted relatio n extraction using an LLM based GIX framework. The white blocks\nsignify the processes , and the grey blocks indicate the tools utilised within those processes .\nhttps://d oi.org/10.1371/j ournal.pon e.0303231.g0 01\nPLOS ONE\nGene interaction extraction framewo rk\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 5 / 22\ntwo. As the number of entities in a sentence increase, the possible relationships amongst them\ncan grow exponentially. However, the number of true relationships does not grow at a similar\npace, thereby, leading to a situation when the number of non-interactions far exceed the num-\nber of interactions and resulting to imbalance dataset. The pre-processing (Stage-1) and post-\nprocessing stages (Stage-2) in GIX are designed to recognise non-relation entity pairs, to\ndecrease the number of sentences classified as true negatives. This reduces the gap between the\ntwo classes, which contributes to the imbalance, thereby enhancing the overall performance\nand accuracy of relation extraction. We begin with the explanation for each component of\nStage-1.\nPre-processing\nIn Stage-1, we pre-process the input publications to extract only highly relevant text. This task\nis challenging because genomic transcriptional regulations can differ between organisms, and\nmolecular entities may behave differently under different cell conditions. We formulated a\nsearch criterion which ensured the extracted literature’s association to the specified condi-\ntional parameters. Known attributes of the target network, such as the organism and cell func-\ntion, were included to in narrow down the search to closely related literature. As published\npapers often include a keywords section that helps indexers, these were also used to establish\nrelevance. Multi-cellular organisms may exhibit different regulatory relations under different\ncell conditions; thus, the use of additional criteria can significantly improve the quality of\nobtained literature, thereby improving the accuracy and relevancy of extracted relations. The\nchosen set of keywords used for this study is outlined in the experiment section under \"Selec-\ntion of Keywords.\"\nThe Bio.Entrez module facilitates data retrieval from PubMed, a comprehensive biomedical\nliterature database [43]. To find relevant PubMed articles, we crafted a search query using\nPubMed Bio.Entrez utilities. The PubMed search query requires a set of keywords and speci-\nfies the maximum number of documents to retrieve, resulting in a list of PubMed IDs ranked\nby relevance according to the provided keywords. With the retrieved PubMed IDs, we used\nthe web scraping tool BeautifulSoup [44], a Python library, to extract titles and abstracts from\nthe papers on PubMed. The set of abstracts obtained using the selected keywords is further\nprocessed to eliminate those papers which do not contain a reference to the organism, either\nin its full form, or as abbreviations.\nSentence tokenization. We split the final set of abstracts into individual sentences using\nPunkt sentence tokenizer from the Natural Language Toolkit (NLTK) [45]. Punkt is a pre-\ntrained unsupervised machine learning model designed for detecting sentence boundaries.\nThen the tokenized sentences undergo two consecutive sentence elimination processes: the\nfirst utilises a fine-tuned BioBERT (biobert_v1.1_pubmed) classification model, and the sec-\nond involves BERN2, as detailed in the subsequent sections.\nSentence eliminator 1. Sentence eliminator 1 identifies and removes sentences that do\nnot discuss a regulatory interaction. A fine-tuning dataset was created from annotated PPI cor-\npus sentences. The specific datasets used for fine-tuning and testing in each experiment are\noutlined in the results sections. To create the fine-tuning dataset, sentences dictating at least\none regulatory relationship receive a positive classification label, while the rest are labelled as\nnegative. Once finetuned, the BioBERT model evaluates test sentences, assigning a classifica-\ntion of 0 if there are no genetic interactions or if the sentence discusses non-regulation, and 1\nif the sentence contains a relational context of a gene/protein interaction. Sentences classified\nas 0 are eliminated, while those classified as 1 undergo further evaluation for the presence of\nnamed entities.\nPLOS ONE\nGene interaction extraction framewo rk\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 6 / 22\nSentence eliminator 2. For the second sentence elimination step, since at least two enti-\nties are involved in a regulatory relationship, all sentences that contain fewer than two gene or\nprotein entities are excluded. This elimination is carried out using BERN2, without any addi-\ntional fine-tuning, to recognise gene and protein entities in a sentence. BERN2 can be imple-\nmented through their RESTFUL API [46]. For each sentence, BERN2 produces a JSON list of\nannotations, containing the entity phrase, its entity type, and a probability score. Sentences are\neliminated if the annotation list contains fewer than two gene/protein entities.\nRelation extraction\nIn Stage-2 of GIX, we used BERN2 for NER and fine-tuned BioBERT for relation classification.\nThrough fine-tuning on expert-annotated data, pre-trained models efficiently transfer general\nlanguage knowledge to domain-specific tasks, resulting in improved task performance and\nadaptability. In this work, our goal was to extract binary relations according to their suitability\nfor comparison, interpretability, and scalability. To extract binary relations, each entity pair in\na sentence is substituted with a label to clearly identify both the agent and target entities\ninvolved in the relationship. Sentence eliminator-2, filters out sentences with fewer than two\ngene/protein entities, so the sentences undergoing processing for relation classification invari-\nably contain a minimum of two gene/protein entities, irrespective of the presence or absence\nof an actual relationship. The labelling criteria remain consistent for all sentences before rela-\ntion extraction. To extract binary relations, each entity pair in a sentence is substituted with a\nlabel to clearly identify both the agent and target entities involved in the relationship. The first\nentity of a pair is replaced with $GENE_AGENT# and the latter is substituted with $GENE_-\nTARGET#. The selected entity labels are descriptive, unique, and ensure consistency. Despite\nthe advantages of selected labels, the structural complexity and presence of multiple entities in\nbiological sentences can hinder the sequence classifier model’s ability to recognize the labeled\nentities. To address this issue, any entity in a sentence other than the current pair is replaced\nwith the word “BLANK”, so that the model can easily identify the pair in consideration during\nclassification. For example, in Fig 2, three genes—SigK, GerE, and ykvP—appear in the sen-\ntence, and for the gene pair Sigk ($GENE_AGENT#) and ykvP ($GENE_TARGE T#) the\nremaining third gene is labelled BLANK. BioBERT, pre-trained on biomedical data, has a con-\ntextual understanding of complex biological terms and is able to manage this style of labelling.\nWhile the selected labelling tags ($GENE_TARGET#, $GENE_AGENT#) in complex sen-\ntences may not effectively highlight the target of the classification task and thereby limit model\nperformance, anonymizing the entities additional to the tagged pair using “BLANK” effectively\nsuppresses the unwanted entity without altering the lexical and semantical structure of the\nsentence.\nThe output of the RE process is a set of entity pairs from BioBERT, with classification pre-\ndiction values varying between 0 and 1.\nPost-processing\nThe extracted relations may still contain wrongly predicted interactions or entities, due to the\nbiological complexity of the relationships. We cannot assume that all stated relations in\nFig 2. Illustration of NER tagging in sentences with multiple gene or gene products.\nhttps://d oi.org/10.1371/j ournal.pon e.0303231.g0 02\nPLOS ONE\nGene interaction extraction framewo rk\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 7 / 22\npublished text are necessarily correct. Positive results are more likely to be published than neg-\native or inconclusive results. This bias can lead to an overrepresentation of certain findings,\nwhich can skew the domain knowledge. Studies with small sample sizes, which are not repre-\nsentative of a larger population, may contain results that are unreliable or not generalizable.\nAdditionally, even though our entity labelling schema aims to identify the controlling ($GEN-\nE_AGENT#) and child ($GENE_TARGET#) entities in a relationship, not all sentences clearly\nindicate the direction of the interaction. In such cases, information about known controlling\nentities, such as regulatory genes or transcriptional factors, in the target network can help\nidentify the direction of the relation. In the post-processing stage, we therefore evaluate the\ntrueness of each extracted relation based on several factors, including whether the relation was\nextracted from multiple documents, its existence in online repositories, and whether it involves\na known regulator.\nRefinement. The entire three-step refinement process is illustrated in Fig 3.\nBefore establishing well-known true regulations, the extracted relational entity names are\nrefined. During NER, BERN2 may recognize a group of words or phrases as the named entity.\nFor instance, consider the following sentence:\n“The Dnak suppressor protein interacts with molecular chaperones to assist in protein folding\nand prevent misfolding or aggregation.”\nThe phrase “Dnak suppressor protein” is identified as a gene/protein entity by BERN2,\nhelping to reduce the structural complexity of the sentence. However, we need to extract only\nthe entity name “Dnak” to successfully group regulations extracted from different research\npapers. To extract just the entity name, we split the phrases and process the individual words\nfor NER using BERN2 (Fig 4). As depicted in example (ii) in Fig 4, the BERN2 tagged entity\nmay not contain the entity name at all. Such entity relations are incomplete, and thus should\nbe eliminated. For larger datasets, the use of BERN2 to process each word in an entity name\ncan become computationally expensive. To address this issue, we created a list of the most\nrepetitive non-entity words (available on the Gene-Interaction-Extractio n GitHub repository\nFig 3. Entity name refinement.\nhttps://d oi.org/10.1371/j ournal.pon e.0303231.g0 03\nFig 4. Gene name refinemen t using BERN2.\nhttps://d oi.org/10.1371/j ournal.pon e.0303231.g0 04\nPLOS ONE\nGene interaction extraction framewo rk\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 8 / 22\nhttps://github.com/JaskaranKa urGill1/Gene-Interaction-Extract ion) reflecting which non-\nentity words are most frequently removed before passing on to BERN2.\nIf BERN2 is unable to recognise the gene/protein name from a phrase without the adjoining\nwords, the refined entities which return null names are checked to detect any missing genes or\nproteins. Most gene/protein names consist of letters, numbers, and symbols that may not con-\nform to typical English language words, leading the spellchecker to flag them as potentially\nmisspelled. Thus, the checking is done by using the word spell check tool from Textblob [47]\nto label individual words in entity names and identify incorrectly spelled words. If a word in\nan entity is incorrectly spelt, it is considered to be a protein or gene name, whereas if it is cor-\nrectly spelt, it is assumed to be descriptive. The output of the refinement process is a set of\nentity-pairs composed only of gene or protein names.\nConfidence factor. We developed a new measure, the Confidence Factor CF\ne\na\ne\nt\n, to indi-\ncate the likelihood of existence of each of the interactions identified as existing between the\nagent/controller entity e\na\nand the target entity e\nt\n. For each entity pair e\na\ne\nt\n, its corresponding\nCF\ne\na\ne\nt\nis computed as follows.\nCF\ne\na\ne\nt\n¼\nX\nn\ns¼1\nv\ns\nþ K\nX\nM\nT ¼1\nP\nT\ne\na\ne\nt\nð1Þ\n¼ CF\n1\nþ K ∗CF\n2\nP\ne\na\ne\nt\n¼\n1; e\na\nis know n age nt but rel atio n e\na\ne\nt\nis unkn own\n3; e\na\ne\nt\nis know n rel atio n\n0; oth erw ise\nð2Þ\n8\n>\n<\n>\n:\nHere, the variable n denotes the total number of unique sentences obtained from GIX pre-\ndicting e\na\ne\nt\n, i.e. the regulation between e\na\nand e\nt\n. The variable v\ns\nis the RE classifier prediction\nof regulation e\na\ne\nt\n, of the s\nth\nsentence. It is obtained as the Stage-2 output of the GIX and has a\nvalue between 0 and 1. The parameter P\ne\na\ne\nt\nrepresents the prior knowledge about both the\nagent entity (e\na\n) and its interaction (e\na\ne\nt\n) with the target entity e\nt\n. The constant M is the total\nnumber of curated databases under consideration. K is a factor balancing the influence of\nterms\nP\nn\ns¼1\nv\ns\nand\nP\nM\nT ¼1\nP\nT\ne\na\ne\nt\n(also referred to as CF\n1\nand CF\n2\n). As shown in Fig 5, the discrete\nvariable P\ne\na\ne\nt\nof Eq 2 can acquire three different values for three different conditions, namely,\n(i) If e\na\nis known to be a controller gene and the relation e\na\ne\nt\nis unknown, P\ne\na\ne\nt\n= 1; (ii) If e\na\ne\nt\nis\na known relation, the value of P\ne\na\ne\nt\nis given a higher value of 3 compared to (i) accounting for\nthe presence of two entities and a connecting arc; (iii) For other conditions, P\ne\na\ne\nt\n= 0.\nFig 5. Role of prior knowle dge component CF\n2\nwith respect to CF\n1\non overall confid ence factor C F\ne\na\ne\nt\n. (i) No prior\nknowled ge is available (ii) e\na\nis a known controlling entity but e\na\ne\nt\nis an unknown relation (iii) e\na\ne\nt\nis a known relation.\nhttps://d oi.org/10.1371/j ournal.pon e.0303231.g0 05\nPLOS ONE\nGene interaction extraction framewo rk\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 9 / 22\nA specific regulation can appear multiple times in each sentence. For example, in the\nsentence\n“The study found that the upregulation of TrpE was associated with an increased expression\nof trpR in the cell line, and this TrpE -dependent trpR expression initiates the enzyme\nactivity.”\nThe relation between TrpE and trpR appears twice with two different values of v\ns\n. In such\nsituations, the average value of v\ns\nis considered. Previously curated annotations of a genetic\ninteraction can also be used to validate the correctness of the GIX’s extracted relation. The\nmanually curated databases cite multiple published papers reporting genomic interactions. For\ninstance, RegulonDB confirms the transcriptional interaction between TF CRP-cyclic-AMP\nand its target genes deoC, deoA, deoB, and deoD, from 16 sources. Similarly, interactions con-\nfirmed from a higher number of experimental and/or analytical sources will have a higher\nCF\ne\na\ne\nt\nand thus, are more likely to be true. A threshold value (CF\ne\na\ne\nt\n= γ) is defined, and all reg-\nulations with CF\ne\na\ne\nt\n<γ are treated as false positive. The final output of the framework will be a\nset of highly confident extracted entity pairs and their corresponding CF\ne\na\ne\nt\nvalues, represent-\ning the accuracy of the retrieved relationships.\nResults\nWe first describe the experimental setup, including the hyperparameter configuration and eval-\nuation metrics used. Subsequently, we discuss the selection of keywords for the extraction of\nrelevant information from the target-related literature. We conducted three independent exper-\niments to assess the effectiveness of GIX. The first experiment (Exp1) demonstrated the Rela-\ntion Extraction Capability (Stage-2) of the GIX framework using four well-known benchmark\ndatasets for gene/protein interactions. The second experiment (Exp2) evaluated automated\nextraction using GIX against the manual curation of a benchmark dataset. The third experi-\nment (Exp3) evaluated GIX against the manual curation of a real-world database of transcrip-\ntional regulations. Finally, as a demonstration of the significance of GIX-extracted relations\nwith their confidence factors, we used the relations for constructing gene regulatory networks.\nExperimental setup\nWe implemented our models using PyTorch transformers: an open-source library for machine\nand deep learning models [48]. The framework was written in Python 3.10.11 in Google Colab\nPro. The hyper-parameters setup for the BioBERT model is given in Table 1. We trained our\nmodel on Google Colab using a GPU (Tesla P100-PCIE-16GB) with a BertAdam optimizer.\nTable 1. Hyperpar ameters used for the RE classificat ion model.\nHyper-par ameters Value\nModel biobert_v 1.1_pubmed\nToken max length 256/ 512 depending on the average length of sentences of the dataset\nOptimizer BertAdam\nBatch Size 8\nNumber of epochs 10 / 20 dependi ng on the dataset size.\nLearnin g rate (BertAdam ) 2e-5\nWarmup (BertAdam ) 0.1\nLearning rate decay (Weight decay rate) 0.01\nhttps://d oi.org/10.1371/j ournal.pon e.0303231.t00 1\nPLOS ONE\nGene interaction extraction framewo rk\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 10 / 22\nTo assess the model performance, the metrics Recall (R), Precision (P), and F-score (F)\nwere evaluated. Recall and Precision provide complementary insights into the performance of\na model. Recall measures the proportion of relevant instances correctly identified, while Preci-\nsion represents the accuracy of the model’s positive predictions. The F-score provides a bal-\nanced assessment of a model’s performance by considering both Precision and Recall, offering\na single metric with which to evaluate classification accuracy.\nSelection of keywords\nThe choice of the correct set of keywords is crucial to GIX performance in target-related litera-\nture search. Our choice was based on predefining certain attributes of the required output.\nThese attributes specify the type of relation being extracted, determining whether they pertain\nto a particular organism or a specific cell function. Incorporating these attributes makes the\nkeyword selection process effective in focusing our search on finding literature directly related\nto specific aspects of the target network. We identified frequently used keywords in published\npapers related to genetic entity regulation and interaction. Fig 6 depicts the 20 most repeated\nkeywords among papers used by RegulonDB for the manual extraction of the transcriptional\nrelations of Escherichia coli. The name of the organism embodying the regulatory system is the\nmost repeated keyword, and is thus included as one of the preferred keywords. Other impor-\ntant words—“gene regulation”, “gene expression”, “transcriptome”, “transcription factor”, “regu-\nlation”, and “posttranscriptional regulation”—which are repeated frequently are also included\nas search terms. Thus, the selected set of keywords for this research is the combination of the\ncommon words “gene regulation gene expression transcriptional” and the name of the target\norganism.\nExp1- Relation extraction capability (Stage-2) of the GIX framework\nThe performance of our RE with its improved entity-labelling schema (Stage-2 of the GIX\nframework, referred as GIX RE) was investigated using four well-known benchmark gene/pro-\ntein interaction datasets: BioInfer, HPRD50, IEPA, and LLL. The distribution of positively and\nnegatively annotated sentences for these four datasets is given in Table 2.\nFig 6. Top 20 most repeated keywords included in papers referenced by RegulonDB for TF-bind ing sites.\nhttps://d oi.org/10.1371/j ournal.pon e.0303231.g0 06\nPLOS ONE\nGene interaction extraction framewo rk\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 11 / 22\nTo evaluate a model’s performance and generalisation ability, we employed the widely used\n10-fold cross validation provided by the KFold library from Scikit-Learn [49] to each of the\nfour datasets (HPRD50, BioInfer, IEPA and LLL). In brief, the method involves dividing the\ndataset into 10 equal subsets, with 9 subsets used for fine-tuning and the isolated 10\nth\nsubset\nused for testing. For each dataset, the process is repeated 10 times using a different fold as the\ntest set, and each time, the relation classification model gets fine-tuned from scratch (original\nsetting). The overall accuracy is determined by averaging the results from the 10 individual\nexperiments (folds) conducted on each dataset (shown in Fig 7). This ensures comprehensive\nevaluation across diverse data samples, contributing to the model’s robustness and generalisa-\nbility. This approach has been commonly used in several state-of-the-art methods in different\ndomains including Biological relation extraction,e.g. Bi-LSTM [50], MCCNN [51], GK [52],\nNHGK [53], EDG ([54], PIPE [42], WWSK [55], RCNN [56], DNN [57], RNN + CNN [56]\nand iLSTM+tAttn [41]. We used a token length of 256 for BioInfer, HPRD50, IEPA, and LLL.\nThe smaller datasets, HPRD50, IEPA, and LLL, required 20 epochs for fine-tuning, whereas\nthe larger dataset,\n,\nBioInfer, achieved stability in just 10 epochs. The performance of the pro-\nposed RE with the improved entity-labelling schema (Stage 2 of GIX), compared with other\nstate-of-the-art methods, is given in Table 3.\nGIX outperformed all RE methods/models in Precision, Recall, and F-score for all four\ndatasets: BioInfer, HPRD50, IEPA, and LLL. GIX produced a significant improvement of 12%\nin Precision on HPRD50 compared to the previous best model. BioBERT’s improved perfor-\nmance in biological RE compared to traditional models like CNN and LSTM can be attributed\nto its pre-training on biological text, capturing contextual word representations, and transfer\nlearning capabilities. The combination of BERN2’s ability for normalization of named entities,\nalong with the proposed anonymization of entities reduces sentence complexity without alter-\ning the lexical structure, and thus contributes to enhancing the model’s accuracy of prediction.\nThe robustness of the superior performance of GIX was further confirmed by its consistent\nperformance across all four datasets.\nTable 2. Distributio n of positive and negative classification s in five benchm ark PPI corpora .\nDataset Positive Negative Unique Sentences\nBioInfer 2534 7132 1100\nIEPA 335 482 486\nHPRD50 163 270 145\nLLL 164 166 77\nhttps://d oi.org/10.1371/j ournal.pon e.0303231.t00 2\nFig 7. The 10-fold cross-va lidation process for evaluating the relation extraction capability (Stage-2) of the GIX. Here, each\niteration consists of equally divided 10 folds of the dataset, where 9 folds (white blocks) are used for fine-tunin g, and the 10th fold\n(grey block) is used for testing. The overall performan ce ( Ɵ ) is obtained by averaging the performance of each iteration ( Ɵ i). The\nnotations P, R and F represent Precision, Recall, and F-score.\nhttps://d oi.org/10.1371/j ournal.pon e.0303231.g0 07\nPLOS ONE\nGene interaction extraction framewo rk\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 12 / 22\nExp2- comparison of GIX with manual curation of a benchmark dataset\nThe objective of this experiment was to evaluate the performance of GIX in capturing genetic\nrelations against a manually curated benchmark dataset. We experimented using the known\ntarget network information for the LLL dataset. The other three datasets, IEPA, HPRD50 and\nBioInfer, contain generic interactions involving different organisms, including humans and\nmodel organisms, while the relations present in the fourth dataset, LLL, are confined to a single\nbacterial species, Bacillus subtilis. In GIX, fine-tuning is required for both the Sentence Elimina-\ntor 1 (Stage-1) and Relation Classification (Stage-2), as they use a variant of the BioBERT\nmodel. As given in Table 4, the fine-tuning was performed using sentences from the HPRD50,\nBioInfer, and IEPA datasets, while the testing was done using the independent LLL dataset. The\nLLL dataset contains sentences containing genetic interactions of type action, regulation, bind-\ning, and promotion of cell transcription activity in B. subtilis. The keywords used to extract\ninformation from PubMed about transcription in B. subtilis from the abstracts of published lit-\nerature were “Bacillus subtilis gene expression regulation transcriptional”. The maximum num-\nber of retrieved articles was set to 1000, so that only highly relevant papers were extracted.\nThe search for transcriptional regulations in Bacillus subtilis returned 371 abstracts contain-\ning 2,865 sentences. The Sentence Eliminator-1 and Sentence Eliminator-2 rejected 1,184 and\n692 sentences, respectively, leaving 989 sentences for RE. The process extracted 1,120 relations\nfrom these sentences. Through the refinement step in the GIX post-processing stage, the\nextracted relations were further processed and condensed into 706 interactions (shown in Fig 8).\nTable 3. Ten-fold cross-va lidation results (%) P: Precision; R: Recall; F: F-score.\nMethods BioInfe r HPRD50 IEPA LLL\nP R F P R F P R F P R F\nDNN [57] 53.9 72.9 61.6 58.7 92.4 71.3 71.8 79.4 74.2 76.0 91.0 81.4\nBi-LSTM [50] 87.0 87.4 87.2 - - - - - - - - -\nRNN + CNN [58] 56.7 67.3 61.3 69.6 82.7 75.1 64.3 65.8 63.4 72.5 87.2 76.5\nMCCNN [51] 81.3 78.1 79.6 - - - - - - - - -\nGK [52] 56.7 67.2 61.3 69.6 82.7 75.1 64.3 65.8 63.4 72.5 87.2 76.5\nCK [59] 65.7 71.1 68.1 67.5 78.6 71.7 68.5 76.1 70.9 77.6 86 80.1\nNHGK [53] 59.3 68.1 63.4 72.4 79.8 75.3 67.8 85.3 74.6 86.2 92.1 89.1\nEDG [54] 57.6 59.9 58.7 69.9 76.2 72.9 76.7 83.3 79.9 92.1 78.2 84.6\nPIPE [42] 68.6 70.3 69.4 62.5 83.3 71.4 63.8 81.2 71.5 73.2 89.6 80.6\nWWSK [55] 61.8 54.2 57.6 66.7 69.2 67.8 73.7 71.8 72.9 76.9 91.2 82.4\niLSTM+tA ttn [41] 88.9 89.3 89.1 78.6 78.7 78.5 81.7 82.3 81.3 84.8 84.3 84.2\nRCNN [56] 87.4 86.5 86.9 74.9 82.8 77.7 71.6 80.6 75.5 80.5 87.2 83.2\nGIX RE 91.1 92.9 92.0 91.5 93.3 92.2 89.4 89.5 88.9 93.9 92.4 93.9\nhttps://do i.org/10.1371/j ournal.pone .0303231.t003\nTable 4. Dataset used for fine-tunin g of BioBERT models for RE classification and sentence eliminatio n 1.\nExperimen ts Relation extract ion\nclassificat ion\nDataset Experim ent with benchmark dataset\n(Exp2): LLL\nExperimen t real-world databas e (Exp3):\nRegulonD B\nPositive Negative\nLLL x 164 166\nIEPA x x 335 482\nHPRD50 x x 163 270\nBioInfer x x 2000 2500\nhttps://d oi.org/10.1371/j ournal.pon e.0303231.t00 4\nPLOS ONE\nGene interaction extraction framewo rk\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 13 / 22\nTo calculate CF\ne\na\ne\nt\nusing Eq 1, prior information about known regulators and regulations\nwas obtained from Subtiwiki [60], a comprehensive online resource and database dedicated to\nthe bacterium Bacillus subtilis. As depicted in Fig 9, we observed that the CF\ne\na\ne\nt\nof the majority\nof relations when not considering prior knowledge, lay between 0.9 and 1. To achieve a bal-\nanced impact of prior knowledge and literature-based extraction on the overall CF, we set K to\nFig 8. GIX’s extract ion process for Bacillus subtilis relations illustratin g outputs at each step (dark grey blocks) and inputs\nsuch as datasets , database s, or target -specific keywords (light grey blocks).\nhttps://doi. org/10.1371/j ournal.pone .0303231.g008\nFig 9. Confidence factor (CF\ne\na\ne\nt\n) of the extract ed relations for Bacillus subtilis distribut ion of C F\ne\na\ne\nt\nwith and without prior knowle dge.\nhttps://do i.org/10.1371/j ournal.pone .0303231.g0 09\nPLOS ONE\nGene interaction extraction framewo rk\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 14 / 22\n1. The impact of the CF\ne\na\ne\nt\nis evident in Fig 9, which shows an increase in the number of rela-\ntions within higher CF\ne\na\ne\nt\nintervals with the activation of the prior knowledge component.\nAfter incorporating the prior knowledge component, the threshold value, γ, for CF\ne\na\ne\nt\nwas set\nat 0.88. This setting was experimentally determined after performing ROC curve analysis to\nidentify the best trade-off between true positive rate and false positive rate (shown in Fig 10).\nWith γ = 0.88, 590 interactions were extracted.\nTable 5 displays the results of two experiments labeled as Exp2-(i) GIX-RE (only relation\nextraction model) and Exp2-(ii) GIX (Full Framework). In experiment Exp2-(i), only the rela-\ntion extraction model of GIX, corresponding to Stage-2 of the framework, is utilised. The data-\nsets used for fine-tuning of the relation classification model for experiment Exp2-(i) include\nHPRD50, IEPA, and BioInfer while LLL dataset is used for testing. In experiment Exp2-(ii),\nthe full GIX framework is under investigation. Here, the fine-tuning datasets consist of\nHPRD50, IEPA, and BioInfer. While the testing dataset comprises of sentences extracted from\nPubMed related to Bacillus Subtilis regulatory interactions. These two experiments demon-\nstrate that GIX, using just a few target-related keywords instead of the manually refined and\nformatted sentences was able to maintain a similar level of accuracy of extracted interactions\nwithout losing any of the sentences. The GIX framework is therefore robust, because, despite\nthe elimination of a large number (2,109) of sentences during pre-processing and the loss of\nFig 10. ROC curve analysi s used to determ ine the optimum threshold (γ) using relatio ns extracted using GIX\nfrom 77 sentences in the LLL dataset.\nhttps://d oi.org/10.1371/j ournal.pon e.0303231.g0 10\nTable 5. Performance comparis on of relation extraction from LLL sentences (i) using the GIX RE model and LLL sentences from the dataset, and (ii) using the GIX\nFramewor k and target-related keywords .\nMethod Precision Recall F-score Numbe r of instances confirmin g true interact ions found\nGIX RE (LLL– 330 sentences ) 86.30 79.35 81.29 130\nGIX (Full Framewo rk) 86.30 79.35 81.29 255\nhttps://do i.org/10.1371/j ournal.pone .0303231.t005\nPLOS ONE\nGene interaction extraction framewo rk\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 15 / 22\nalmost half of the interactions due to post-processing refinement, there was no loss of informa-\ntion when using GIX. Furthermore, 130 out of 164 true interactions were confirmed 255 times\nby GIX by extracting the same interactions from multiple sentences, demonstrating its ability\nto leverage several sources for identifying true regulations. As a result, we augmented the data-\nset with an additional 125 sentences with labelled entities containing LLL’s true regulations.\nThis experiment also demonstrated GIX’s proficiency in efficiently enriching benchmark data-\nsets with sentences containing newly introduced terminologies, biological processes, and\nrelationships.\nWe observed a difference between model accuracies when fine-tuning and testing sentences\nbelong to the same dataset (LLL) and when the model was fine-tuned on non-LLL data (BioIn-\nfer, HPRD50, and IEPA) and tested on LLL. The disparities in accuracies can be attributed to\ndifferences in the fine-tuning data. The use of non-related datasets in Exp2 is realistic because\nin the real-world, often, the data is not always truly aligned with the training dataset. In past,\nthe attempts by researchers at generalisation have been less successful with their accuracies\ndecreasing significantly. For instance, in ([41], the model that was trained using only BioInfer\nand tested on LLL exhibited a low accuracy of 33.50%. In contrast, our proposed model has a\nPrecision of 86.30% which is a slight decrease from Exp1 but still higher than other models.\nCombination of diverse non-related datasets (BioInfer, IEPA and HPRD50) has led to better\ngeneralisation and hence improved performance.\nExp3- comparison of GIX with manual curation of a real-world database\nWe used E. coli interactions available in the database RegulonDB to evaluate GIX’s ability to\nautomatically extract TF-gene, TF-transcriptional unit, TF-operon, and TF-TF regulations. The\nextracted relationships are validated using known relations from RegulonDB, ensuring accuracy,\nand the overall confidence factor is adjusted based on this ground truth for evaluating GIX-\nbased relationships against manually curated ones by RegulonDB. The database maintains refer-\nences to articles for each curated interaction. The corpus neither records the article segment\n(such as Abstract, Introduction, or Conclusions) nor the sentences used to report the interaction.\nTo evaluate the performance of GIX, we compared the accuracy of extraction of regulations by\nGIX with the RegulonDB regulations that had been curated from abstracts. We identified 578\nunique interactions in 554 associated papers that mention the entities (gene/protein name) in at\nleast one sentence of the abstract. For sake of convenience, throughout the paper, these 578 inter-\nactions are referred as abstract-level relations. The datasets used for fine-tuning the Sentence\nEliminator– 1 (Stage-1) and the Relation Classification (Stage-2) were the four available bench-\nmark datasets, BioInfer, HPRD50, IEPA and LLL. The testing dataset was formulated using sen-\ntences not found in the fine-tuning data sets. These sentences were extracted by GIX through\nkeyword-based extraction from PubMed. The sentences comprising the testing dataset, obtained\nfrom published literature, are related to E. coli, while the benchmark datasets used for fine-tuning\nrepresent different domains. For example, the IEPA dataset is focused on biochemical relations\nand the LLL is dedicated to Bacillus subtilis. Thus, there is no overlap between the content of\nthese four datasets and the E. coli-related sentences used for testing. The keywords used to extract\nthe abstracts of published literature describing E. coli transcription from PubMed were “E coli\nEscherichia coli gene expression regulation transcriptional”. To ensure the extraction of only\nhighly relevant papers, the maximum number of retrieved articles was set to 1000. As in the pre-\nvious experiment, we determined the threshold value γ for CF, which was set at 1.5. The inputs\nand outputs of each process in GIX for Exp3 are depicted in Fig 11.\nAs depicted in Fig 12, in the absence of prior knowledge, the CF\n1\nassociated with the major-\nity of relations is distributed within the ranges [0, 2] and [4,10]. As per Eq 2, CF\n2\nwill vary\nPLOS ONE\nGene interaction extraction framewo rk\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 16 / 22\nbetween 0 and 3. To balance the influence of prior knowledge and extraction based on existing\nliterature on the cumulative CF, we set the parameter K to 2, after averaging the higher values\nwithin the ranges of CF\n1\nand subsequently dividing by the maximum value of CF\n2\n. To com-\npute the CF\ne\na\ne\nt\nvalue using Eq 1 and validate the extracted relations, we used the regulatory\ninteractions TF-TF, TF-operon, TF-gene, TF-TU, and the regulators annotated in RegulonDB\nas prior knowledge.\nWe retrieved 954 abstracts containing 7,358 sentences. During pre-processing, 4,022 sen-\ntences were eliminated, leaving 3,336 sentences The RE stage extracted 8,014 positive entity\npairs from within these 3,336 sentences. After post-processing refinement, we extracted 2,866\ninteractions. Upon evaluating the extracted relations against the 578 abstract-level interactions,\n456 interactions were accurately identified. An additional 622 GIX extracted regulations were\nconfirmed by relationships from RegulonDB that have not been annotated from abstracts of\nFig 11. GIX’s extraction process for Escherichia coli relations illustratin g the outputs at each step (dark grey\nblocks) and inputs such as datasets, databas es, or target-specif ic keywords (light grey blocks).\nhttps://d oi.org/10.1371/j ournal.pon e.0303231.g0 11\nFig 12. (i) Confid ence factor (CF\ne\na\ne\nt\n) pertaining to the extracted relations for the E. coli distribution CF\ne\na\ne\nt\nof without\nprior knowled ge (PR) (ii) the percentage of relations extracted whose confidence factor CF\ne\na\ne\nt\nwas influenced by prior\nknowled ge.\nhttps://d oi.org/10.1371/j ournal.pon e.0303231.g0 12\nPLOS ONE\nGene interaction extraction framewo rk\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 17 / 22\nreferenced literature. Of the regulations extracted by GIX, 92% were influenced by prior\nknowledge in their computed CF. Fig 12 shows that a significant number of relations with\nhigh confidence values are either known relations or have a known controlling entity. The\ninteraction yielding the highest confidence value, of 24.65, was CytR!CRP. The high confi-\ndence value of the extracted relations provides a strong certainty in the accuracy and reliability\nof the extracted information.\nApplication of GIX\nTranscriptional regulation relations automatically extracted using GIX are important for\nunderstanding biological processes, particularly in the area of gene regulatory network infer-\nence. In this section, we demonstrate the way in which the output generated by GIX can serve\nnot only as a basis for the inference of Gene Regulatory Networks (GRNs) but can also incor-\nporate. CF\ne\na\ne\nt\nto provide valuable information about the reliability of each interaction.\nFor GRN inference, we chose the top 500 GIX-extracted transcriptional regulations of\nE. coli obtained in Experiment Exp3. The selection was based on the CF\ne\na\ne\nt\nassigned to each\nrelation. We used Cytoscape [61], an open-source software platform, to visualize the network\n(Fig 13). With the confidence factor of each relation used as its corresponding weight, an arc\nappears thicker for higher CF\ne\na\ne\nt\n. The node size corresponds directly to the in-degree of the\nnode. The GRN can help understand the complex regulatory mechanisms governing gene\nexpression in E. coli. These networks can also serve as prior knowledge for reconstructing\nGRNs using more advanced computational methodologies and address the excessive computa-\ntional overhead.\nBiological circuits offer valuable insights into molecular-level interactions, especially within\nGRNs. From the presented GRN network for E. coli, entities CRP, fnr, CytR, fis, MarA, csgD\nstand out as the key regulatory genes, regulating 77 genes among themselves. Identifying con-\ntroller genes is crucial as they govern gene expression, influencing cell state and offer help in\ndeveloping targeted treatments for genetic disorders like cancer. GRNs exhibit sparsity, evi-\ndent in the presented network where 334 genes exhibit only 500 interactions. Further, it may\nalso be noted that due to the high cost of wet lab experiments to determine interactions,\nexhaustive exploration of relationships among thousands of genes becomes impractical. While\nsignificant efforts have been made to develop advanced computational methods for inferring\nrelationships using gene expression data, yet the noisy and scarce nature of the data poses\nFig 13. Network diagram of 500 extracted E. coli gene/protei n relations visualiz ed using Cytosc ape [61].\nhttps://d oi.org/10.1371/j ournal.pon e.0303231.g0 13\nPLOS ONE\nGene interaction extraction framewo rk\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 18 / 22\nseveral challenges in achieving improved accuracy and efficiency. Integrating relationships\nobtained via GIX as a-priori knowledge in the reconstruction process can significantly reduce\nconvergence time, enhance overall accuracy, and facilitate the discovery of new relations. This\niterative process, once refined, allows for cost-effective high-throughput experiments targeting\nspecific entities, reducing the overall expense of uncovering crucial relationships.\nConclusions\nGIX (Gene Interaction Extraction), our systematic and robust relation extraction framework,\nfocuses on mining biological entity interactions from journal paper abstracts using domain-\nspecific strategies and pre-trained attention-based models. The methodology underlying the\nGIX framework involves three stages: (i) pre-processing, (ii) relation extraction, and (iii) post-\nprocessing. The pre-processing stage uses a selection of keywords to obtain abstracts of highly\nrelevant literature. Sentences that do not contain functional interactions and entity pairs are\nautomatically excluded at this stage. In the relation extraction stage, the pre-trained large lan-\nguage models BERN2 and BioBERT are used for NER and RE. The associated entity-labelling\nschema reduces sentence complexity and improves model prediction accuracy. The post-pro-\ncessing stage refines the extracted relations by removing incorrectly recognised entities and\nassigns a novel confidence factor to quantify the correctness of an extracted relation. This con-\nfidence factor depends on both the information from multiple documents that corroborate a\ngiven regulatory relationships, and the pre-existing knowledge available from manually\ncurated databases. The performance of GIX was validated using four benchmark datasets of\ngene/protein interactions. GIX’s relation extraction ability surpassed the performance of previ-\nous state-of-the-art methods. GIX’s performance against manually curated datasets and reposi-\ntories was robust. We also observed the ability of GIX to augment existing datasets with new\nsentences from abstracts of published literature containing newly discovered terminologies\nand biological processes. The application of GIX to infer an E. coli gene regulatory network\ndemonstrated its ability to work effectively with real world data.\nDespite the rapid execution and high performance of pre-trained domain-specific large lan-\nguage models, the RE techniques described in the existing literature remain primarily confined\nto paper abstracts. The title, author list, affiliation, abstract, and keywords are easily available\non Medline’s PubMed repository. Designing a method to automatically extract text from the\nbody of the paper may require source-specific code, authentication requirements and addi-\ntional permissions to run data-scraping web services. Therefore, automatically extracting\npieces of text from the body of the paper is relatively a more complex task than extracting text\nfrom abstracts. While the proposed method has focused on extracting relations using abstracts\nof publications, the approach is generic, and it can be easily extended for extracting relations\nusing entire documents. For future work, we aim to extend GIX’s applicability by seamlessly\nintegrating extracted genetic relationships as prior knowledge for improved GRN reconstruc-\ntion. Additionally, we will explore GIX’s ability to identify multi-sentential relationships, pro-\nviding a more comprehensive understanding of complex biological interactions.\nAuthor Contributions\nConceptualization: Jaskaran Kaur Gill, Madhu Chetty.\nData curation: Jaskaran Kaur Gill.\nFormal analysis: Jaskaran Kaur Gill, Madhu Chetty.\nInvestigation: Jaskaran Kaur Gill.\nPLOS ONE\nGene interaction extraction framewo rk\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 19 / 22\nMethodology: Jaskaran Kaur Gill, Madhu Chetty.\nSupervision: Madhu Chetty, Suryani Lim, Jennifer Hallinan.\nValidation: Jaskaran Kaur Gill.\nVisualization: Jaskaran Kaur Gill.\nWriting – original draft: Jaskaran Kaur Gill.\nWriting – review & editing: Jaskaran Kaur Gill, Madhu Chetty, Suryani Lim, Jennifer\nHallinan.\nReferences\n1. Zhou D, Zhong D, He Y. Biomedic al Relation Extraction : From Binary to Complex . Computationa l and\nmathematic al methods in medicine. 2014; 2014: 298473 –18. https://doi.or g/10.115 5/2014/298473\nPMID: 252148 83\n2. Zhang Y, Lin H, Yang Z, Wang J, Sun Y, Xu B, et al. Neural network-b ased approa ches for biomedi cal\nrelation classificat ion: A review. Journal of Biomedic al Informatics. 2019; 99: 103294. https://doi. org/\n10.1016/ j.jbi.2019.103 294 PMID: 31557530\n3. Corlan AD. Medline trend: automated yearly statistic s of PubMed results for any query. [Online]. ; 2004\n[cited 2023 Jan 15. Availab le from: http://dan.c orlan.net/m edline-tren d.html.\n4. Singhal A, Leaman R, Catlett N, Lember ger T, McEntyre J, Polson S, et al. Pressing needs of biomedi -\ncal text mining in biocura tion and beyond: opportunitie s and challeng es. Databas e. 2016; 2016:\nbaw161.\n5. Fogel GB, Weekes DG, Varga G, Dow ER, Craven AM, Harlow HB, et al. A statistical analysis of the\nTRANSF AC database . BioSystems . 2005; 81(2): 137–154. https://doi. org/10.1016/j .biosyst ems.2005.\n03.003 PMID: 15941617\n6. Gama-Ca stro S, Salgado H, Santos-Z avaleta A, Ledezma- Tejeida D, Muñiz-Ra scado L, Garcı ´ a-Sotelo\nJS, et al. RegulonDB version 9.0: high-level integration of gene regulat ion, coexpression , motif cluster-\ning and beyond. Nucleic acids research. 2016; 44(D1): D133–143 . https://doi.o rg/10.1093/na r/gkv1156\nPMID: 265277 24\n7. Hong L, Lin J, Li S, Wan F, Yang H, Jiang T, et al. A novel machine learning framework for automated\nbiomedi cal relation extraction from large-sc ale literature repositories. Nature Machine Intelligenc e.\n2020; 2: 347–35 5.\n8. Jung H, Lee BG. Research trends in text mining: Semantic network and main path analysis of selected\njournals. Expert Systems with Applications . 2020; 162.\n9. Sangrak Lim JK. Chemic al–gene relation extraction using recursive neural network. Database. 2018;\n2018.\n10. Sanger M, Leser U. Large-s cale entity representatio n learning for biomedi cal relationship extraction.\nBioinformat ics. 2021;: 236–242. https://doi. org/10.1093/b ioinform atics/btaa67 4 PMID: 327264 11\n11. Karaa WBA, Mannai M, Dey N, Ashour AS, Olariu I. Gene-Dis ease-Food Relation Extraction from Bio-\nmedical Database. In Procee dings of the 7th internationa l workshop soft computing applications (SOFA\n2016); 2018.\n12. Miwa M, Sætre R, Miyao Y, Tsujii J. Entity-Fo cused Sentence Simplifi cation for Relation Extraction . In\nProceedings of the 23rd International Conferen ce on Comp utational Linguisti cs; 2010; Coling 2010.\n13. Phuong TM, Lee D, Lee KH. Learning Rules to Extract Protein Interactio ns from Biomedic al Text.\nAdvances in Knowled ge Discovery and Data Mining. 2003;: 148–158.\n14. Chowdhury MFM, Lavelli A. Impact of less skewed distributions on efficiency and effectivenes s of bio-\nmedical relation extraction. Proceedings of coling 2012: Posters. 2012.\n15. Fundel K, Ku ¨ ffner R, Zimmer R. RelEx—Relat ion extraction using dependenc y parse trees. Bioinfor-\nmatics. 2007; 23(3): 365–371. https://doi.or g/10.109 3/bioinformat ics/btl616 PMID: 17142812\n16. Zhou W, Huang K, Ma T, Huang J. Document-Lev el Relation Extraction with Adaptive Threshol ding and\nLocalized Context Pooling. In In Proceedings of the AAAI conferen ce on artificia l intelligence; 2021.\np. 14612–146 20.\n17. Akkasi A, Moens MF. Causal relationship extraction from biomedical text using deep neural models: A\ncomprehe nsive survey. Journal of biomedi cal informati cs. 2021; 119: 103820. https://d oi.org/10.101 6/j.\njbi.2021.103 820 PMID: 34044157\nPLOS ONE\nGene interaction extraction framewo rk\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 20 / 22\n18. Yang S, Yoo S, Jeong O. DeNE RT-KG: Named Entity and Relation Extraction Model Using DQN,\nKnowled ge Graph, and BERT. Appl. Sci. 2020; 10: 6429.\n19. Lee J, Yoon W, Kim S, Kim D, Kim S, So CH, et al. BioBER T: a pre-traine d biomedica l language repre-\nsentation model for biomedi cal text mining. Bioinform atics. 2020; 36(4): 1234–1240. https:// doi.org/10.\n1093/bioinfo rmatics/btz682 PMID: 31501885\n20. Panyam NC, Verspoor K, Cohn T, Rama mohanarao K. Exploitin g graph kernels for high performan ce\nbiomedi cal relation extraction. J Biomed Semant. 2018; 9(7). https://doi.or g/10.1186/s 13326-017-\n0168-3 PMID: 293823 97\n21. Lamurias A, Clarke LA, Couto FM. Extracting microRNA -gene relations from biomedica l literat ure using\ndistant supervisio n. PLoS ONE. 2017; 12(3): e01719 29. https://doi.or g/10.137 1/journal.po ne.0171929\nPMID: 282639 89\n22. Pyysalo S, Ginter F, Heimonen J, Bjo ¨ rne J, Boberg J, Ja ¨ rvinen J, et al. BioInfer: a corpus for information\nextraction in the biomedi cal domain. BMC bioinformatic s. 2007; 8(1): 50–50. https:// doi.org/10.11 86/\n1471-2105- 8-50 PMID: 17291334\n23. Airola A, Pyysalo S, Bjorne J, Pahikkala T, Ginter F, Salakoski T. A graph kernel for protein-prote in\ninteractio n extraction. In Proceedings of the workshop on current trends in biomedica l natural language\nprocessing ; 2008. p. 1–9.\n24. Ne ´ dellec C. Learning language in logic—genic interaction extraction challenge . In Learning language in\nlogic worksh op (LLL05); 2005: ACM-Assoc iation for Computing Machiner y.\n25. Zhang Q, Chen M, Liu L. A Review on Entity Relation Extraction . In Second Internationa l Conferen ce\non Mechanical, Control and Comput er Engineeri ng (ICMCCE) ; 2017. p. 178–183.\n26. Onye SC, Akkeleş A, Dimililer N. Review of Biomedica l Relation Extraction . European Internat ional\nJournal of Science and Technolo gy. 2017; 6(1).\n27. Nasar Z, Jaffry SW, Malik MK. Named Entity Recogn ition and Relation Extraction : State- of-the-Art.\nACM Computing Surveys. 2021; 54(1): 1–39.\n28. Maslennikov a E. ELMo Word Represent ations For News Protection. CLEF (Workin g Notes). 2019.\n29. Devlin J, Chang MW, Lee K, Toutanova K. BERT: Pre-train ing of Deep Bidirec tional Transforme rs for\nLanguage Understand ing. arXiv preprint arXiv:1810.04 805. 2018.\n30. Acheampo ng FA, Nunoo-Men sah H, Chen W. Transforme r models for text-base d emotion detection: a\nreview of BERT-ba sed approaches . Artificial Intelligenc e Review. 2021;: 1–41.\n31. Cohn C. BERT Efficacy on Scientifi c and Medical Dataset s: A Systematic Literature Review. DePaul\nUniversity . 2020.\n32. Affi M, Latiri C. BE-BLC : BERT-ELM O-Based Deep Neural Network Archite cture for English Named\nEntity Recognition Task. Procedia Computer Science. 2021; 192: 168–181.\n33. Selvarajah J, Nawarathna RD. A Lucrative Model for Identifying Potenti al Adverse Effects from Biomed-\nical Texts by Augmenting BERT and ELMo. In Singapore S, editor. Proceedings of International Confer-\nence on Sustainable Expert System s: ICSES 2020.; 2021.\n34. Peng Y, Yan S, Lu Z. Transfer Learning in Biomedic al Natural Languag e Processing: An Evaluation of\nBERT and ELMo on Ten Benchmark ing Datasets. arXiv preprint arXiv:1 906.05474. 2019.\n35. Zhu Y, Li L, Lu H, Zhou A, Qin X. Extracting drug-drug intera ctions from texts with BioBERT and multiple\nentity-awar e attention s. Journal of biomedi cal informati cs. 2020; 106: 103451 . https://doi.or g/10.1016/ j.\njbi.2020.103 451 PMID: 32454243\n36. Elangovan A, Davis M, Verspo or K. Assigning function to protein-pr otein interaction s: a weakly super-\nvised BioBERT based approach using PubMed abstracts . arXiv preprint arXiv:2008.08 727. 2020.\n37. Song B, Li F, Liu Y, Zeng X. Deep learning methods for biomedi cal named entity recognition: a survey\nand qualitativ e comparison . Briefings in Bioinform atics. 2021; 22(6). https://doi.or g/10.1093/ bib/\nbbab282 PMID: 34308472\n38. Zhu F, Patumchar oenpol P, Zhang C, Yang Y, Chan J, Meechai A, et al. Biomed ical text mining and its\napplicatio ns in cancer resear ch. Journal of Biomedical Informatics . 2013; 46(2): 200–211. https:/ /doi.\norg/10.1016/ j.jbi.2012.10.0 07 PMID: 23159498\n39. Song M, Kim WC, Lee D, Heo GE, Kang KY. PKDE4 J: Entity and relation extraction for public knowl-\nedge discovery. Journal of Biomedic al Informatics. 2015; 57: 320–332. https://do i.org/10.1016 /j.jbi.\n2015.08. 008 PMID: 26277115\n40. Gridach M. Character -level neural network for biomedical named entity recognition. Journal of Biomedi-\ncal Informatics . 2017; 70: 85–91. https://doi.or g/10.1016 /j.jbi.2017.05.00 2 PMID: 28502909\n41. Ahmed M, Islam J, Samee MR, Mercer RE. Identifying Protein-P rotein Interactio n using Tree LSTM\nand Structured Attentio n. In 2019 IEEE 13th interna tional conferenc e on semantic computing (ICSC);\n2019. p. 224–23 1.\nPLOS ONE\nGene interaction extraction framewo rk\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 21 / 22\n42. Chang YC, Chu CH, Su YC, Chen CC, Hsu WL. PIPE: a protein-pr otein interacti on passage extraction\nmodule for BioCreative challeng e. Database: the journal of biological database s and curation . 2016;\n2016: 101.\n43. Biopytho n. Bio.Entrez–B iopython 1.76 documentati on. [Online] .; 2022 [cited 2023 August 16. Available\nfrom: https://biopytho n.org/d ocs/1.76/api /Bio.Entrez .html.\n44. Soup. B. A Python library for pulling data out of HTML and XML files. [Online] .; 2023 [cited 2023 August\n6. Available from: https://www .crummy.co m/softwar e/Beautif ulSoup/.\n45. Hardeni ya N, Perkins J DC, Joshi N, Mathur I Natural Langua ge Processin g: Python and NLTK: Packt\nPublishing Ltd.; 2016.\n46. Sung M, Jeong M, Choi Y, Kim D, Lee J, Kang J. BERN2 docume ntation. [Online].; n.d. [cited 2023\nAugust 6. Available from: http://bern2.k orea.ac.kr /documentati on.\n47. Loria S. textblob Documentat ion.; 2018.\n48. Rothman D. Transfor mers for Natural Language Processin g: Packt Publishing, Limited; 2021.\n49. Scikit-lea rn. KFold. In Scikit-learn: Machine Learning in Python. [Online].; n.d. [cited 8 August 2023.\nAvailable from: https://sci kit-learn.org /stable/modu les/gener ated/sklear n.model_ selection.K Fold.html.\n50. Hsieh YL, Chang YC, Chang NW, Hsu WL. Identifying protein-prote in intera ctions in biomedi cal litera-\nture using recurrent neural networks with long short-te rm memory. In Proceedings of the eighth interna-\ntional joint conferen ce on natural language processing (volume 2: short papers); 2017. p. 240–24 5.\n51. Quan C, Hua L, Sun X, Bai WRO. Multichann el Convolution al Neural Network for Biologic al Relation\nExtraction . BioMed resear ch internationa l. 2016; 2016: 1850404–10. https://d oi.org/10.115 5/2016/\n1850404 PMID: 28053977\n52. Airola A, Pyysalo S, Bjo ¨ rne J, Pahikkala T, Ginter F, Salakoski T. All-paths graph kernel for protein-pr o-\ntein interacti on extraction with evaluatio n of cross-corpu s learning. BMC bioinfo rmatics. 2008; 9(11):\nS2–S2. https://doi.or g/10.118 6/1471-2105 -9-S11-S 2 PMID: 19025688\n53. Zhang Y, Lin H, Yang Z, Li Y. Neighbor hood hash graph kernel for protein–pr otein interacti on extraction.\nJournal of biomedi cal informati cs. 2011; 44(6): 1086–1092. https://d oi.org/10.101 6/j.jbi.20 11.08.011\nPMID: 218848 22\n54. Peng Y, Gupta S, Wu CH, Vijay-Shan ker K. An extended dependenc y graph for relation extraction in\nbiomedi cal texts. In Proceedings of BioNLP 15; 2015. p. 21–30.\n55. Kim S, Yoon J, Yang J, Park S. Walk-w eighted subsequen ce kernels for protein-pr otein interaction\nextraction. BMC bioinform atics. 2010; 11(1): 107. https://doi.or g/10.118 6/1471-2105 -11-107 PMID:\n20184736\n56. Zhang H, Guan R, Zhou F, Liang Y, Zhan ZH, Huang L, et al. Deep Residual Convolution al Neural Net-\nwork for Protein-Protei n Interactio n Extraction . IEEE access. 2019; 7: 89354–8936 5.\n57. Zhang H, Guan R, Zhou F, Liang Y, Zhan ZH, Huang L, et al. ‘A protein-pr otein interaction extraction\napproach based on deep neural network. IEEE access. 2019; 7: 89354–893 65.\n58. Zhang Y, Lin H, Yang Z, Wang J, Zhang S, Sun Y, et al. A hybrid model based on neural networks for\nbiomedi cal relation. Journal of biomedi cal informati cs. 2018; 81: 83–92.\n59. Miwa M, Sætre R, Miyao Y, Tsujii J. Protein–pr otein interacti on extraction by leveraging multiple kernels\nand parsers. International journal of medical informatics (Shannon, Ireland. 2009; 78(12): e39–e46.\nhttps://doi.or g/10.101 6/j.ijmedinf .2009.04.010 PMID: 19501018\n60. Zhu B, Stu ¨ lke J. SubtiWi ki in 2018: from genes and proteins to functional network annotati on of the\nmodel organism Bacillus subtilis. Nucleic Acids Research. 2018; 46(D1): D743–D748. https://d oi.org/\n10.1093/ nar/gkx908 PMID: 29788229\n61. Smoot ME, Ono K, Ruscheins ki J, Wang PL, Ideker T. Cytoscape 2.8: new features for data integration\nand network visualization . Bioinfo rmatics. 2011; 27(3): 431–432. https:// doi.org/10.10 93/\nbioinforma tics/btq675 PMID: 21149340\nPLOS ONE\nGene interaction extraction framewo rk\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03032 31 May 21, 2024 22 / 22",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.634167492389679
    },
    {
      "name": "Computational biology",
      "score": 0.4330849349498749
    },
    {
      "name": "Data extraction",
      "score": 0.42858532071113586
    },
    {
      "name": "Natural language processing",
      "score": 0.4277638792991638
    },
    {
      "name": "Data science",
      "score": 0.36640244722366333
    },
    {
      "name": "Data mining",
      "score": 0.34476351737976074
    },
    {
      "name": "MEDLINE",
      "score": 0.2528057396411896
    },
    {
      "name": "Biology",
      "score": 0.22846299409866333
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I149672521",
      "name": "Federation University",
      "country": "AU"
    }
  ]
}