{
  "title": "Potential of Large Language Models in Health Care: Delphi Study",
  "url": "https://openalex.org/W4394967854",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2080582034",
      "name": "Kerstin Denecke",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2108155485",
      "name": "Richard May",
      "affiliations": []
    },
    {
      "id": null,
      "name": "LLMHealthGroup",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2146318818",
      "name": "Octavio Rivera-Romero",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4385381606",
    "https://openalex.org/W4385227045",
    "https://openalex.org/W4381715962",
    "https://openalex.org/W4309111272",
    "https://openalex.org/W3092557781",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W3184604253",
    "https://openalex.org/W2950670227",
    "https://openalex.org/W3010328141",
    "https://openalex.org/W4377292302",
    "https://openalex.org/W3095092693",
    "https://openalex.org/W2900065283",
    "https://openalex.org/W4362641141",
    "https://openalex.org/W4385380523",
    "https://openalex.org/W4361204578",
    "https://openalex.org/W4386845850",
    "https://openalex.org/W4361289889",
    "https://openalex.org/W4282916947",
    "https://openalex.org/W3158454357",
    "https://openalex.org/W3136425357",
    "https://openalex.org/W2029912930",
    "https://openalex.org/W2583504027",
    "https://openalex.org/W2044829446",
    "https://openalex.org/W2070047223",
    "https://openalex.org/W2098724465",
    "https://openalex.org/W2103020125",
    "https://openalex.org/W2032654667",
    "https://openalex.org/W2940867124",
    "https://openalex.org/W3132098331",
    "https://openalex.org/W2147072925",
    "https://openalex.org/W2733328613",
    "https://openalex.org/W2154482020",
    "https://openalex.org/W1979290264",
    "https://openalex.org/W2004878847",
    "https://openalex.org/W2587777701",
    "https://openalex.org/W2260766877",
    "https://openalex.org/W4352978370",
    "https://openalex.org/W4360605142",
    "https://openalex.org/W4320801519",
    "https://openalex.org/W3161430317",
    "https://openalex.org/W3130502265",
    "https://openalex.org/W3191402931",
    "https://openalex.org/W4224214847",
    "https://openalex.org/W4210514210",
    "https://openalex.org/W4293280152",
    "https://openalex.org/W4388521769",
    "https://openalex.org/W4286629483",
    "https://openalex.org/W4320921249",
    "https://openalex.org/W4280488363",
    "https://openalex.org/W4311487064",
    "https://openalex.org/W4283455080",
    "https://openalex.org/W4205865577",
    "https://openalex.org/W3196012986",
    "https://openalex.org/W3153651148",
    "https://openalex.org/W4368362817",
    "https://openalex.org/W4297845970"
  ],
  "abstract": "Background A large language model (LLM) is a machine learning model inferred from text data that captures subtle patterns of language use in context. Modern LLMs are based on neural network architectures that incorporate transformer methods. They allow the model to relate words together through attention to multiple words in a text sequence. LLMs have been shown to be highly effective for a range of tasks in natural language processing (NLP), including classification and information extraction tasks and generative applications. Objective The aim of this adapted Delphi study was to collect researchersâ€™ opinions on how LLMs might influence health care and on the strengths, weaknesses, opportunities, and threats of LLM use in health care. Methods We invited researchers in the fields of health informatics, nursing informatics, and medical NLP to share their opinions on LLM use in health care. We started the first round with open questions based on our strengths, weaknesses, opportunities, and threats framework. In the second and third round, the participants scored these items. Results The first, second, and third rounds had 28, 23, and 21 participants, respectively. Almost all participants (26/28, 93% in round 1 and 20/21, 95% in round 3) were affiliated with academic institutions. Agreement was reached on 103 items related to use cases, benefits, risks, reliability, adoption aspects, and the future of LLMs in health care. Participants offered several use cases, including supporting clinical tasks, documentation tasks, and medical research and education, and agreed that LLM-based systems will act as health assistants for patient education. The agreed-upon benefits included increased efficiency in data handling and extraction, improved automation of processes, improved quality of health care services and overall health outcomes, provision of personalized care, accelerated diagnosis and treatment processes, and improved interaction between patients and health care professionals. In total, 5 risks to health care in general were identified: cybersecurity breaches, the potential for patient misinformation, ethical concerns, the likelihood of biased decision-making, and the risk associated with inaccurate communication. Overconfidence in LLM-based systems was recognized as a risk to the medical profession. The 6 agreed-upon privacy risks included the use of unregulated cloud services that compromise data security, exposure of sensitive patient data, breaches of confidentiality, fraudulent use of information, vulnerabilities in data storage and communication, and inappropriate access or use of patient data. Conclusions Future research related to LLMs should not only focus on testing their possibilities for NLP-related tasks but also consider the workflows the models could contribute to and the requirements regarding quality, integration, and regulations needed for successful implementation in practice.",
  "full_text": null,
  "topic": "Health care",
  "concepts": [
    {
      "name": "Health care",
      "score": 0.5682728290557861
    },
    {
      "name": "Health informatics",
      "score": 0.5350419878959656
    },
    {
      "name": "Strengths and weaknesses",
      "score": 0.5138773918151855
    },
    {
      "name": "Context (archaeology)",
      "score": 0.44764068722724915
    },
    {
      "name": "Documentation",
      "score": 0.43350574374198914
    },
    {
      "name": "Delphi method",
      "score": 0.4320400059223175
    },
    {
      "name": "Psychology",
      "score": 0.3860844373703003
    },
    {
      "name": "Medical education",
      "score": 0.3805026412010193
    },
    {
      "name": "Artificial intelligence",
      "score": 0.37327146530151367
    },
    {
      "name": "Computer science",
      "score": 0.367153525352478
    },
    {
      "name": "Medicine",
      "score": 0.31109341979026794
    },
    {
      "name": "Nursing",
      "score": 0.2773382067680359
    },
    {
      "name": "Public health",
      "score": 0.26168563961982727
    },
    {
      "name": "Social psychology",
      "score": 0.14812156558036804
    },
    {
      "name": "Political science",
      "score": 0.1362573504447937
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    }
  ]
}