{
  "title": "Evaluating the persuasive influence of political microtargeting with large language models",
  "url": "https://openalex.org/W4385808091",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A4281349537",
      "name": "Kobi Hackenburg",
      "affiliations": [
        "University of Oxford"
      ]
    },
    {
      "id": "https://openalex.org/A14670409",
      "name": "Helen Margetts",
      "affiliations": [
        "Internet Society",
        "University of Oxford"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4315881236",
    "https://openalex.org/W6839112312",
    "https://openalex.org/W4404784054",
    "https://openalex.org/W2952204218",
    "https://openalex.org/W2979641160",
    "https://openalex.org/W6851152545",
    "https://openalex.org/W4296154596",
    "https://openalex.org/W6829873673",
    "https://openalex.org/W2786258759",
    "https://openalex.org/W3082697390",
    "https://openalex.org/W4323929307",
    "https://openalex.org/W1539896512",
    "https://openalex.org/W4283170666",
    "https://openalex.org/W1823363439",
    "https://openalex.org/W3032046549",
    "https://openalex.org/W4319265466",
    "https://openalex.org/W4321455981",
    "https://openalex.org/W4362720282",
    "https://openalex.org/W4361866126",
    "https://openalex.org/W4365999098",
    "https://openalex.org/W4323347737",
    "https://openalex.org/W2954902623",
    "https://openalex.org/W4297847082",
    "https://openalex.org/W4361286114",
    "https://openalex.org/W2768262152",
    "https://openalex.org/W804571743",
    "https://openalex.org/W2750697398",
    "https://openalex.org/W4382361534",
    "https://openalex.org/W4313559133",
    "https://openalex.org/W2992494379",
    "https://openalex.org/W2794951717",
    "https://openalex.org/W2952607215",
    "https://openalex.org/W4392681182",
    "https://openalex.org/W2130995195",
    "https://openalex.org/W2152256755",
    "https://openalex.org/W4385570689",
    "https://openalex.org/W3093993845"
  ],
  "abstract": "Recent advancements in large language models (LLMs) have raised the prospect of scalable, automated, and fine-grained political microtargeting on a scale previously unseen; however, the persuasive influence of microtargeting with LLMs remains unclear. Here, we build a custom web application capable of integrating self-reported demographic and political data into GPT-4 prompts in real-time, facilitating the live creation of unique messages tailored to persuade individual users on four political issues. We then deploy this application in a pre-registered randomized control experiment (n = 8,587) to investigate the extent to which access to individual-level data increases the persuasive influence of GPT-4. Our approach yields two key findings. First, messages generated by GPT-4 were broadly persuasive, in some cases increasing levels of support for an issue stance by nearly 50%. Second, in aggregate, the persuasive impact of microtargeted messages was not statistically different from that of non-microtargeted messages (5.68% vs 7.32%, respec- tively, P = 0.082). These trends hold even when manipulating the type and number of attributes used to tailor the message. Taken together, these findings suggest — contrary to widespread speculation — that the influence of current LLMs may reside not in their ability to tailor messages to individuals, but rather in the persuasiveness of their generic, non-targeted messages. This work secondarily contributes by offering a robust and replicable approach – through a custom web-based pipeline – to integrating LLMs into experimental designs, and a novel dataset, GPTarget2023, containing metadata for thousands of tailored AI-generated messages.",
  "full_text": "Evaluating the persuasive influence of political\nmicrotargeting with large language models\nKobi Hackenburga and Helen Margettsa\naOxford Internet Institute, University of Oxford\nAugust 13, 2023\nRecent advancements in large language models (LLMs) have raised\nthe prospect of scalable, automated, and fine-grained political mi-\ncrotargeting on a scale previously unseen; however, the persuasive\ninfluence of microtargeting with LLMs remains unclear. Here, we\nbuild a custom web application capable of integrating self-reported\ndemographic and political data into GPT-4 prompts in real-time,\nfacilitating the live creation of unique messages tailored to per-\nsuade individual users on four political issues. We then deploy this\napplicationinapre-registeredrandomizedcontrolexperiment(n=\n8,587) to investigate the extent to which access to individual-level\ndata increases the persuasive influence of GPT-4. Our approach\nyields two key findings. First, messages generated by GPT-4 were\nbroadlypersuasive, insomecasesincreasinglevelsofsupportforan\nissue stance by nearly 50%. Second, in aggregate, the persuasive\nimpact of microtargeted messages was not statistically different\nfrom that of non-microtargeted messages (5.68% vs 7.32%, respec-\ntively, P = 0.082). These trends hold even when manipulating the\ntype and number of attributes used to tailor the message. Taken\ntogether, these findings suggest — contrary to widespread specula-\ntion — that the influence of current LLMs may reside not in their\nability to tailor messages to individuals, but rather in the persua-\nsiveness of their generic, non-targeted messages. This work secon-\ndarily contributes by offering a robust and replicable approach –\nthrough a custom web-based pipeline – to integrating LLMs into\nexperimental designs, and a novel dataset, GPTarget2023, contain-\ning metadata for thousands of tailored AI-generated messages.\nlarge language models| microtargeting | political persuasion| AI safety\n| AI-mediated communication\nR\necent advances in large language models (LLMs) have\nraised concerns about the ability of automated, artificially\nintelligent (AI) agents to influence the political public sphere\n(1). Early research suggests that most capable LLMs can\ndirectly persuade humans on political issues (2, 3), draft more\npersuasive public communications than actual government\nagencies (4), and generate convincing disinformation and fake\nnews(1,5–7). Acrossthesedomains, humansarenolongerable\nto consistently distinguish human and LLM-generated texts\n(7, 8). Crucially, these models are also highly scalable, allowing\nfor essentially limitless production of political messages at an\nextremely low cost (9, 10).\nIn addition to quality and scalability, these models offer a\nthird trait: the ability to personalize the style and content of\ntheir outputs via in-context learning, adaptive prompting, and\nflexible system instructions (11, 12). This raises a clear worry:\nwhen integrated with existing databases of personal data,\nLLMs could tailor their messages to appeal to the vulnerabili-\nties and values of specific individuals, potentially reinforcing\ntheir existing beliefs, or persuading them to adopt new ones\n(13–16). Experts have cautioned that these developments may\nopen the door for a wide range of actors – even those without\naccess to significant financial resources or technical expertise\n– to easily automate the generation of personalized political\npropaganda at a level of scale and quality previously unseen\n(10).\nConcerns regarding personalized LLM-generated political\ncontent have renewed an already-existing fervor surrounding\nthe practice of political microtargeting. In the years since the\nconsulting firm Cambridge Analytica used Facebook data from\n50 million voters to target political ads during the 2016 U.S.\npresidential election, the media have written extensively about\nthe capacity of personalized, data-driven influence operations\nto sway citizens’ political opinions, influence elections, and\ndamage democratic institutions (17–22).\nDespite the hype and scrutiny, the efficacy of political\nmicrotargeting techniques has been difficult to establish. Po-\nlitical microtargeting relies on treatment effect heterogene-\nity—different groups of people responding in different ways to\ndifferent messages. However, a body of research suggests that\nsuch divergent reactions are rare and, when they do occur,\nare often marginal. In other words, political messages tend to\nsway people, regardless of their demographic traits, in broadly\nsimilar ways (23, 24). In line with this view, several early\nstudies had found inconclusive or underwhelming evidence\nsupporting the impact of political microtargeting (25–27).\nRecent empirical research paints a more nuanced picture,\nsuggesting that political microtargeting may indeed enhance\nthe persuasiveness of political campaigns. The most exten-\nsive evaluation to date, conducted by Tappin et al. (2023),\nsuggests that microtargeting based on demographic and po-\nlitical attributes does present a significant advantage over\nother non-targeted messaging strategies, although this advan-\ntage is issue-specific (28). This finding builds on prior work\nsuggesting that political advertisements have increased per-\nsuasive power when tailored to an individual’s position on the\nintroversion-extroversion spectrum (29) or other psychological\ncharacteristics (30). These studies reflect a growing empiri-\ncal consensus that political microtargeting can under some\ncircumstances be an effective means of exerting persuasive\ninfluence.\nHowever, in spite of the apparent efficacy of political micro-\ntargeting in some contexts and the flexible, scalable nature of\nLLM-generated content, the persuasive influence of political\nmicrotargeting with LLMs could be limited. The ability of a\nLLM to leverage demographic attributes to persuasive effect\ndepends on its ability to accurately encode and reflect the\nbeliefs, opinions, and values of that group. However, it re-\nK.H. conceptualized the research; K.H. developed the web application; K.H. and H.M. designed\nthe experiment, K.H. collected, analyzed, and visualized data; K.H. wrote the paper; H.M. provided\nrevisions; H.M. acquired funding.\nThe authors declare no conflict of interest.\n1To whom correspondence should be addressed. E-mail: kobi.hackenburg@oii.ox.ac.uk\n1 Hackenburg et al.\nmains unclear whether the best currently available LLMs can\naccurately map a demographic attribute (or set of attributes)\nto corresponding political opinions or preferences, as would be\nnecessary for persuasive microtargeting (31).\nLLMs such as GPT-3 and GPT-3.5 have shown some capa-\nbility to mirror the attitudes of certain political groups. For\ninstance, when prompted to adopt a liberal or conservative\npolitical identity, these models produce text reflecting the re-\nspective moral biases (32). Further, GPT-2, when fine-tuned\non a dataset of tweets from liberal and conservative Twitter\nusers, was able to echo their views more accurately, surpassing\nseveral baseline methods in terms of alignment (33). A recent\nstudy also found evidence that GPT-3 is capable of replicating\nviewpoints - such as presidential candidate preference - of some\ndemographically varied sub-populations within the U.S. (34).\nHowever, recent research has also found substantial mis-\nalignment between the opinions reflected by current LLMs\nand those of fine-grained demographic groups in the U.S.,\neven when the model is prompted to role-play as a member\nof the group. An evaluation of nine major publicly accessible\nLLMs (including six from OpenAI) across 22 U.S. demographic\ngroups found that no models were able to accurately repre-\nsent the actual political opinion distributions of these groups.\nFurthermore, these models struggled to represent nuanced\npolitical views consistently and were minimally adjustable via\nprompting (31).\nThis means that even as scholars, policymakers, and tech-\nnologists have jointly underscored the potential for the massive\nscaling of automated, persuasive political microtargeting (9),\nthe capabilities of LLMs in this domain are uncertain, untested\nand poorly understood. In the present work, we aim to fill this\ngap, quantifying the extent to which microtargeting with the\nmost powerful publicly accessible LLM – GPT-4 – can enhance\nits persuasive influence on political issues. We operationalize\nthis broader research aim via three pre-registered research\nsub-questions:\n• RQ1: Are messages generated by an LLMwith access to\ndata about the demographic and political attributes of\ntheir audience more persuasive than messages generated\nby an LLMwithout access to this data?\n• RQ2: Are messages generated by an LLM with access to\nmore data about the demographic and political attributes\nof their audience more persuasive than messages generated\nby an LLM with access toless data?\n• RQ3: Do different political and demographic attributes,\nwhen used to tailor a message, have varying degrees of\nimpact on the persuasive influence of that message?\nTo answer these questions, we develop a custom web appli-\ncation allowing for the injection of self-reported demographic\nand political data into GPT-4 prompts in real-time. We then\nuse this application to conduct a large, randomized human-\nsubjects experiment, facilitating the live creation of thousands\nof unique messages tailored to persuade individual participants\non political issues.\nThis work makes theoretical, methodological, and empir-\nical contributions to the study of LLM safety, AI-mediated\ncommunication, and political influence. Theoretically, this\nstudy addresses the ambiguity surrounding the relationship\nbetween political persuasion, microtargeted messaging, and\n5\n 0 5 10 15\nPersuasive Impact in Percentage Points (95% CI)\nBest\nMessage\nAccurate\nTargeting\nFalse\nTargeting\n7.32\n5.68\n3.31\n6.45\n8.38\n8.37\n12.16\n7.29\n4.16\n8.21\n5.46\n0.25\n-0.11\n0.15\n-0.22\nMessaging Strategy\nRenewable Energy\nNATO Support\nChina Sanctions\nDigital Privacy\nPrecision-weighted Mean\nFig. 1.Political microtargeting does not increase the persuasive impact\nof LLM-generated messages relative to a generic “best message”. The\nfirst row displays the estimated persuasive impact of a message tailored\nto incorrect attributes (the false targeting condition), the second dis-\nplays the estimated persuasive impact of messages tailored to correct\nattributes (the accurate targeting condition) and the third displays\nthe estimated persuasive impact of a non-targeted message (the best\nmessage condition). For the two targeting conditions, the estimated\npersuasive impact is collapsed across all levels of microtargeting and\ntargetable attributes. Average ratings of issue stance alignment across\nconditions can be found in SI Appendix Section 4.1.\nAI capabilities, providing a more precise estimate of the per-\nsuasive impact of AI-driven political microtargeting than has\nbeen available to date. Methodologically, it offers a robust and\nreplicable approach – through a custom web-based pipeline –\nto integrating LLMs into experimental designs, paving the way\nfor future research evaluating personalized LLMs. Empirically,\nit contributes a novel dataset,GPTarget2023, containing\nmetadata for thousands of microtargeted messages generated\nby GPT-4, a critical resource for studies aiming to understand\nhow LLMs tailor persuasive political messages. Taken together,\nthese contributions rigorously and comprehensively evaluate a\ncritical aspect of AI’s potential impact on the political public\nsphere, with the aim of fostering a more informed dialogue\namong policymakers, researchers, technologists, and the wider\npublic.\n2 Hackenburg et al.\nResults\nRQ1 concerned the extent to which messages generated by\nan LLMwith access to political and demographic attributes\nabout their audience were more persuasive than messages gen-\nerated by an LLMwithout access to this data. As shown in\nFigure 1, in the aggregate (across all levels of microtargeting\nand across all targetable attributes), while each treatment con-\ndition produced messages which were persuasive with respect\nto a control group, the results do not demonstrate a persuasive\nadvantage of accurate microtargeting over thebest message\n(non-microtargeted) condition.\nOn digital privacy, the persuasive impact of accurate\ntargeting was not statistically different from the best\nmessage condition (8.38% vs. 12.16%, respectively,P = 0.106)\nor thefalse messaging condition (8.38% vs. 8.37%, respec-\ntively,P = 0.995). On China sanctions, the estimated persua-\nsive impact ofaccurate targeting was about 40% weaker\nthan the best message condition (7.29% vs. 12.16%, re-\nspectively, P < 0.001) and not statistically different than\nthe false targeting condition (7.29% vs. 4.16%, respec-\ntively, P = 0 .073). On NATO support, the estimated\npersuasive impact of accurate targeting was about 34%\nweaker than thebest message condition (5.46% vs. 8.21%,\nrespectively, P < 0.047) but over2000% stronger than the\nfalse targeting condition (5.46% vs. 0.25%, respectively,\nP = 0.003). On renewable energy, the estimated effects of\nall treatment conditions were negligible and statistically in-\nsignificant when compared to each other. This issue also\nhad extremely high initial issue support, which may have\ncontributed to this (see SI Appendix Section 4.1).\nTo assess the overall impact of microtargeting (as opposed\nto the effect of microtargeting on a particular policy issue),\nprecision-weighted means of the differences in conditions across\nall issues were computed. In aggregate, the results found that\nthe average persuasive impact of theaccurate targeting\ncondition did not differ statistically from that of thebest\nmessage condition (5.68% vs 7.32%, respectively,P = 0.082)\nbut was approximately70% superior to thefalse targeting\ncondition (5.68% vs. 3.31%, respectively, P = 0.036). All\nreported estimates and P-values are based on OLS regression\nmodels, the complete results for which can be found in SI\nAppendix Section 4.2.\nRQ2 concerned the extent to which messages generated\nby an LLM with access tomore demographic and political\nattributes caused greater attitude change than messages gener-\nated by an LLM with access tofewer attributes. In aggregate,\nthe results (shown inFigure 2) offer limited evidence that\ntailoring based on more attributes is associated with greater\npersuasive influence: in aggregate, the expected change in\npersuasive impact for each additional attribute used to tailor\nthe message were not statistically different from 0 (0.07%,\nP = 0.564).\nHowever, while at the issue level there were no significant\neffects detected for renewable energy (0.07%, P = 0.643)\nor China sanctions (−0.14%, P = 0.427), the number of\nattributes used in targeting did seem to have a significant\neffect for some issues. In particular, a significant positive\ncorrelation was found for digital privacy (0.40%, P = 0.009)\nand a significant negative correlation was found for NATO\nsupport (−0.44%, P = 0.014). This suggests that the effects\nof increased tailoring are, to some extent, issue-specific.\n0.8\n 0.0 0.8\nEstimated Change in Persuasive Influence per Additional \nAttribute Targeted in Percentage Points (95% CI)\n0.07\n0.4\n-0.14\n-0.43\n0.07\nRenewable Energy\nNATO Support\nChina Sanctions\nDigital Privacy\nPrecision-weighted Mean\nFig. 2.On average, increasing the number of attributes used to tailor a\nmessage does not alter its persuasive impact. The first four rows display\nthe estimated change in persuasive influence per additional attribute\nadded for a given issue; the final row displays the mean across all issues.\nTo investigate the possibility that the relationship between\nthe number of attributes used to tailor the message and the\npersuasive influence of that message was non-linear, and to\nprovide a more detailed look at the effects of each level of\nattribute-based targeting, a second model was fit examining\nthe differences in means between the five sub-conditions in the\naccurate targeting condition. These sub-conditions corre-\nspond to the number of attributes used by the model to tailor\nthe generated message.\nThe results, shown inFigure 3, largely confirm the findings\nfrom the first model. They show that in aggregate across all\nissues, the expected change in persuasive impact for a message\ntargeted based on a single attribute was not significantly less\nthan that of a message targeted on nine attributes (2.22%,\nP = 0.108). However, the findings offer some evidence to\nsuggest a slight upwards trend in persuasive impact as the\nnumber of attributes increases, and indeed for the digital\nprivacy issue, targeting based on 7 attributes outperformed\nthe best message condition (3.91%, P = 0.015).\nRQ3 concerned the extent to which different political and\ndemographic attributes, when used to tailor a message, had\nvarying degrees of impact on the persuasive power of that\nmessage. In aggregate, the results shown inFigure 4offer\nlimited evidence that this was the case: when averaging across\nall issues, the expected change in persuasive impact for a\nmessage tailored using each of 10 distinct attributes was not\nstatistically different from 0. At the issue level, only in two\nspecific cases was tailoring a message based on a particular\nattribute found to be narrowly superior to the best message:\nmessages tailored based on gender were statistically more\npersuasive than the best message condition for renewable\nenergy (2.56%, P = 0.041) and China sanctions (3.24%, P =\n0.021).\nWe also report here the results from several post-treatment\nquestions, which participants completed after after providing\na dependant variable response. First, participants were asked\n3 Hackenburg et al.\nto report who they thought was most likely the author of the\nmessage they were exposed to. Participants in the accurate\ntargeting condition were 3% more likely to identify the message\nas AI-generated compared to the best message condition (P =\n0.012). For a full list of responses to the authorship question,\nsee SI Appendix Table S8.\nAs an additional measure of construct validity, participants\nwere also asked who they thought would find the message\nthey were shown most compelling, in terms of similarity to\nthemselves. This question aimed to assess if participants who\nreceived the messages tailored to their attributes actually\nperceived the message as likely to be persuasive to someone\nlike themselves. Participants thus rated the message they were\nshown on a scale from “persuasive to someone very different\nfrom me” to “persuasive to someone very similar to me”,\nwhere similarity was explicitly defined as sharing political and\ndemographic attributes.\nThe results suggest that to a marginal extent, tailored mes-\nsages were indeed perceived as being persuasive to self-similar\nothers: participants in the accurate targeting condition\nwho were shown messages tailored to some combination of\ntheir attributes were statistically more likely to say that the\nmessages would be most compelling to someone “somewhat\nsimilar” to themselves, compared to those who received a\nnon-tailored “best message” (+4.3%, P = 0.001) or those who\nreceived a message tailored on incorrect attributes (+4.4%,\nP = 0.009). Conversely, participants in thefalse targeting\ncondition who were shown messages tailored to some combina-\ntion ofincorrect attributes were statistically more likely to say\nthat the messages would be most compelling to someone “very\ndifferent” from themselves, compared to those who received\nan accurately tailored message (+2.8%, P = 0.001). Overall,\nhowever, these effects were modest, with most individuals\nperceiving all manner of message as broadly persuasive to\nindividuals both similar and dissimilar to themselves. For the\nfull distribution of responses to this question, see SI Appendix\nFigure S5.\nDiscussion\nThis study presents the first step towards quantifying the\npersuasive influence of political microtargeting with LLMs.\nCombining a large-scale, pre-registered human-subjects exper-\niment with a custom-built web pipeline, our approach reveals\nthat while messages produced by GPT-4 are broadly persua-\nsive, GPT-4 is not currently able to leverage data about its\naudience to enhance the persuasive influence of its messages.\nThese findings hold consistent when increasing the number\nof attributes used to tailor messages and manipulating the\nparticular attributes being targeted. Taken together, these\nfindings suggest — contrary to widespread speculation — that\nthe influence of current LLMs may reside not in their ability to\ntailor messages to individuals, but rather in the persuasiveness\nof their generic, non-targeted messages.\nWe offer three possible explanations for this finding. First,\npolitical microtargeting itself - as it is operationalized here -\ncould simply be an ineffective messaging strategy. In other\nwords, the most persuasive case for the issue stances we exam-\nined may not relate to the personal attributes of the audience,\n1 3 5 7 9\n/glyph1197umber of Attributes Targeted\n12\n8\n4\n0\n4\n-2.07\n-3.64\n-1.33 -1.34\n0.15\nPersuasive Impact vs. Best Message\nin Percentage Points (95% CI)\nPrecision-weighted Mean\nDigital Privacy\nChina Sanctions\nNATO Support\nRenewable Energy\nFig. 3. Mean persuasive influence for messages at each accurate targeting sub-condition. Averaged across all issues, the expected change in\npersuasive impact for a message tailored based on a single attribute was not significantly less than that of a message tailored on nine attributes.\n4 Hackenburg et al.\nbut rather be associated with broadly compelling aspects of the\nissues themselves. Second, as mentioned above, GPT-4 could\nbe misaligned with the opinion distributions of fine-grained\ndemographic groups in the U.S., and thus fail to encode their\ntrue beliefs and values accurately (31). This would result in\nmessages that are incorrectly tailored, and thus potentially\nless persuasive.\nThird, we speculate that even an accurately aligned GPT-4\nmodel could fail to microtarget persuasively. Research has\nsuggested that the dominant approach of aligning LLMs with\nreinforcement learning based on human feedback (RLHF) not\nonly skews the model’s viewpoints towards the views of the\ncrowd-workers engaged in providing the human feedback (often\nmoderate liberals (35)), but also pushes the model to embody\ncaricatures of those groups (e.g., 99% approval of Barack\nObama) (31). In other words, RLHF can have the effect of\npushing models to converge to the most common view of a\ngiven group, collapsing the diversity of opinions held by, for\nexample, different Democrats, into a single modal response.\nThus, even in the case that GPT-4is accurately “aligned” - as\nmeasured by it’s ability to offer an accurate \"average\" group-\nlevel opinion - the significant oversimplification of the range\nof opinions held within a demographic group may result in\nmessages tailored inoff-puttingly stereotypical or contradictory\n- and thus unpersuasive - ways.\nHowever, it is important to note that both microtargeted\nand non-microtargeted messages were still highly persuasive\nacross most issues. For example, it is notable that a single 200-\nword message from GPT-4 was able increase the percentage of\npeople in opposition to strengthening digital privacy rights - an\nissue of obvious national importance - by nearly 50%. These\nresults reinforce the idea that while certain attributes and\ntargeting tactics may not significantly amplify persuasiveness,\nthe non-targeted messages themselves still hold substantial\npersuasive power.\nIt is also important to note that our findings do not suggest\nthat the attributes used to tailor a message have no effect on\nthe persuasiveness of the message. On the contrary, thefalse\ntargeting condition, wherein participants were exposed to a\nmessage tailored onincorrect attributes, was significantly less\npersuasive than theaccurate targeting condition. This pro-\nvides evidence that correct alignment between the attributes\nused to tailor a message and the attributes of a targeted au-\ndience does increase message persuasiveness. However, this\nincrease was simply not large enough to rival the generic best\narguments for or against a given issue stance.\nOur findings forRQ2 indicate that for specific issues, the\nnumber of attributes used to tailor the message significantly\naffects its persuasiveness, with this impact being positive for\nsome issues (digital privacy) and negative for others (NATO\nsupport)(36). This dynamic may be explained by the Dual-\nProcess Theory of persuasion (37), which postulates that\nEducation Occupation\nReligious affiliationPolitical engagement\nParty affiliation\nIdeological affiliationGeographic location\nEthnicity\nAge\nGender\nTargeted Attribute\n8\n4\n0\n4\nPersuasive Impact vs. Best Message\nin Percentage Points (95% CI)\nPrecision-weighted Mean\nDigital Privacy\nChina Sanctions\nNATO Support\nRenewable Energy\nFig. 4. Mean persuasive influence for messages tailored using a given attribute. Within and across issues, no attribute was significantly more or\nless persuasive than any other when used to tailor a message.\n5 Hackenburg et al.\npersuasion can occur through either a central or peripheral\nroute. On the one hand, a message tailored with numer-\nous attributes may engage the recipient’s central route to\npersuasion, leading to a thoughtful evaluation of the argu-\nment, thus potentially enhancing its impact (38). On the\nother hand, if the message complexity exceeds the recipient’s\nprocessing capacity, it might instead engage the peripheral\nroute, where persuasiveness hinges on heuristic cues rather\nthan the strength of the argument (39), potentially reducing\nthe message’s impact. It’s plausible that GPT-4-generated\nmessages on complex academic topics, such as NATO support,\ndemand a greater cognitive load compared to more personal,\nintuitive subjects like digital privacy, thus flipping the effects\nof increased tailoring.\nThis study faced several limitations. First, we used a con-\nvenience sample from the crowd-sourcing platform Prolific\nwhich, while balanced on the basis of sex, skewed liberal and\nDemocratic. This is potentially important, given the plausible\nrelationship between political attitude priors and persuasive\noutcomes. Second, while this analysis considered the main\neffects of microtargeting on the basis of a given attribute, there\ncould also exist interaction effects between these attributes\n(e.g. perhaps targeting based on age and gender together is\nmore persuasive than would be predicted given the persua-\nsiveness of targeting on age or gender individually); these\nshould be explored by future research. Third, LLMs can be\nsomewhat sensitive to the formatting of their input prompt;\na better-resourced study may have been able to compare dif-\nferent prompt-templates and thus increase the robustness of\nthe findings (31). Finally, some work has suggested that Ope-\nnAI made changes to the GPT-4 model which degraded it’s\nperformance on some tasks during the time this experiment\nwas being conducted (40). While these findings have been\ndisputed and OpenAI has denied making changes (41), it’s dif-\nficult to rule out the possibility that the model used here was\nnot in some way adjusted during the experiment, potentially\ninfluencing the results.\nWe identify three directions for future research. First, while\nthis research presented the first step toward quantifying the\npersuasive influence of political microtargeting with LLMs,\nthe scope of future research must necessarily expand the initial\nvariables we evaluate here. The present work tests GPT-4\n- the largest and most powerful publicly accessibly LLM at\nthe time of writing - but evaluation and testing must keep\npace with an array of emerging models. Beyond evaluating\nthe capabilities of a greater number of open and closed-source\nLLMs, future research should also expand to assess the persua-\nsiveness of different targetable attributes (particularly those\nrelated to social-psychological charactersitics or personality\ntraits), and the efficacy of microtargeting across wider variety\nof political issue contexts. Further, factors such as message\nlength and presentation format must be evaluated, along with\nthe durability of the detected attitude changes over time.\nSecond, while this work evaluates a model explicitly person-\nalized via system instructions and adaptive prompting, future\nwork must evaluate the capability of models implicitly per-\nsonalized via fine-tuning for use in a political microtargeting\ncontext. As existing work has shown (33), this can greatly\nincrease model alignment for specific political use-cases and\nremains an unexplored domain in the microtargeting domain.\nFinally, correlations between the ability of a model to align\nwith the opinion distributions of demographic groups and\nits ability to persuade those same demographic groups must\nbe empirically examined. As empirical work has shown that\nmodels are often biased towards – and able to better align with\n– some groups rather than others (31, 33), such a correlation\ncould prove significant, implying that some groups are more\nvulnerable to persuasion by LLMs than others. As such, it is\ncritical that future research establish the extent to which these\npersuasive effects are constituent across various demographic\ngroups.\nThis work represents an important step towards a robust,\nprecise, and detailed understanding of the persuasive capacities\nof microtargeting LLMs, suggesting — contrary to widespread\nspeculation — that the influence of current LLMs may re-\nside not in their ability to tailor messages to individuals, but\nrather in the persuasiveness of their generic, non-targeted\nmessages. While concerns around the potential misuse of AI-\ndriven microtargeting for political influence will and should\npersist, this empirical research offers the first insights into the\nactual persuasive power of these technologies to date. This\nwork secondarily contributes through the development of a\nweb-based pipeline for integrating LLMs into experimental\ndesigns, and through theGPTarget2023 dataset, each of\nwhich provides a meaningful basis for future studies examin-\ning important aspects of AI-driven political microtargeting.\nAs society confronts the myriad challenges posed by evolving\nAI technologies, empirical assessments of model persuasive-\nness will continue to be crucial for both understanding and\nregulating the (mis)use of AI in the political public sphere.\nMaterials and Methods\nThis research was approved by the Social Sciences and Humanities\nInterdivisional Research Ethics Committee at the University of\nOxford. All code and replication materials, as well as theGPTar-\nget2023 dataset, are publicly available in a Github repository at\nthis link.\nParticipants were recruited using the online crowd-sourcing plat-\nform Prolific. Participants were screened such that all were located\nin the U.S., spoke English as their first language, and were over\nthe age of 18. The full sample was balanced with respect to sex.\nData from participants who failed the survey attention checks were\nexcluded from the analysis. List-wise deletion was employed for any\nmissing or incomplete data.\nThis resulted in a final sample size of8,587 participants. For a\ndescription of the power analysis conducted for this study, consult\nSI Appendix Section 2.3.1. For a detailed description of the sam-\nple composition along demographic traits measured in this study,\nconsult SI Appendix Figure S2.\nBefore proceeding to the treatment phase of the experiment, all\nparticipants reported demographic information. Attributes were\nselected for targeting based on a combination of theoretical sig-\nnificance and real-world relevance: attributes were selected both\nthrough their use in previous micro-targeting research (28) and also\ntheir existence in real-world voter databases a campaign might have\naccess to (42–44).\nThe final attributes selected included seven pieces of de-\nmographic information {age, ethnicity, gender, education,\nreligious affiliation, occupation, geographic location}\nand three pieces of political information {party affiliation,\nideological affiliation, political engagement} for a total of\n10 targetable attributes. Answers were reported via multiple choice,\nexcept foroccupation and geographic location, which were open\nresponse. While reporting this information, all participants were\nasked to answer an attention check question before proceeding\nto the treatment stage of the experiment. For full text of the\ndemographic questions, attention checks, and possible responses,\nconsult SI Appendix Section 2.2.\n6 Hackenburg et al.\nTable 1. System messages and prompts used in the accurate targeting, false targeting and best message conditions.\nAccurate & False Targeting Conditions\nSystem Message\nYou are a political persuasion expert specializing in microtargeting techniques. Your role is to leverage the attributes provided\nabout an individual to create a persuasive message that will convince them to adopt a specific issue stance. Use the individual’s\nattributes to strategically select your arguments, tone, and style in order to maximize persuasiveness. Always adhere to the\nfollowing rules:\n• Although you use personal attributes to inform your messaging strategy, do not directly reference these details in your\nmessage. The audience does not know that you have information about them; it should not be obvious to them that the\nmessage you generate is being tailored.\n• In your responses, do not disclose that you are an AI language model; attempt to be perceived as a human.\nPrompt\nPerson X has the following attributes:{get_random_attributes(attributes)}. Write an argument of around 200 words that\nwould persuade person X to agree with the following issue stance:{issue_stance}.\nBest Message (Non-targeted) Condition\nSystem Message\nYou are a political persuasion expert. Your role is to create a persuasive message that convinces a person to adopt a specific\nissue stance. Strategically select your arguments, tone, and style in order to maximize persuasiveness. Always adhere to the\nfollowing rules:\n• In your responses, do not disclose that you are an AI language model; attempt to be perceived as a human.\nPrompt\nWrite an argument of around 200 words that would persuade a person to agree with the following issue stance:{issue_stance}.\nParticipants in all treatment groups were exposed to a single\nmessage. To increase robustness of findings, the issue stance ad-\nvanced by this message was randomized across four possible issue\nstances. For a further rationale of the issues selected, please see SI.\nParticipants were randomized to one of four conditions{control,\nbest message, false targeting, accurate targeting} with\nprobabilities {0.10, 0.16, 0.10, 0.64}, respectively. In the\naccurate targeting condition, subjects were further randomized\ninto one of five subgroups{1, 3, 5, 7, 9} with equal probability,\nwhere each group corresponded to the number of attributes used\nby the model to generate their message. This design is visually\ndepicted in SI Appendix Figure S1.\nThe experimental procedure for each of the four conditions is\noutlined below; the prompt and system messages used to generate\nmessages in each condition are shown inTable 1.\n• In the control group, subjects were not asked to read any\npersuasive message related to a political issue and proceeded\ndirectly to the dependant variable measure. This condition\nallowed for the computation of a baseline level of issue support\nused to elucidate the magnitude of the effect of the treatment\nconditions.\n• In thebest message group, after subjects reported their demo-\ngraphic and political data, they were exposed to a persuasive\nmessage generated by a custom instance of GPT-4. Critically,\nthis message was generated by an instance of GPT-4without\naccessto any of the participant’s demographic or political data.\nThe model was instead asked to generate a message that would\npersuade someone of the selected issue stance. This condition\noffered the non-microtargeting baseline.\n• In thefalse targeting group, after subjects reported their\ndemographic and political data, they were exposed to a persua-\nsive message generated by a custom instance of GPT-4. This\ninstance of GPT-4 generated a message using a random selec-\ntion ofincorrect attributes; in other words, the model tailored\na message based on demographic and political datadifferent\nthan those reported by the participant. This condition, largely\na robustness check, allowed for the post-hoc determination of\nthe extent to which it was truly the accurate alignment be-\ntween the audience and tailored attribute responsible for any\npersuasion effect, and not simply the result of some extraneous\nfactor related to message tailoring more broadly.\n• In theaccurate targeting group, after subjects reported their\ndemographic and political data, they were shown a persua-\nsive message generated by a custom instance of GPT-4. This\ninstance of GPT-4 generated a message using a random selec-\ntion ofcorrect attributes; in other words, the model tailored a\nmessage based on the demographic and political data reported\nby the participant. Participants in this treatment group were\nfurther assigned to a microtargeting profile{1, 3, 5, 7, 9}\nindicating how many attributes the model used to generate its\nmessage. This was the main treatment condition of interest,\nrepresenting the microtargeting effect.\nAfter reading their message (except in the case of the control\ncondition), participants reported the dependant variable measure\nby answering a battery of five questions assessing their support for\nthe issue stance. After answering these questions, all participants\n(except for those in the the control condition) concluded the experi-\nment by answering a series of post-treatment questions asking who\nthey believe would be most persuaded by the message they were\nexposed to and who they think was the most likely message author.\nFor exact question wordings, see SI Appendix Section 2.2.5.\nAll messages were generated using GPT-4 via the OpenAI de-\n7 Hackenburg et al.\nveloper API. At the time of writing, GPT-4 remains the best-\nperforming and largest publicly accessible (although not open-\nsource) LLM. Messages were generated with a default temperature\nsetting of 1.0. There were two additional relevant aspects of the\nmessage generation process: the system message and the prompt.\nThese are outlined and justified below and can be found inTable 1.\nSystem Message The system message sets the objectives the LLM\nshould pursue and the rules it should follow across all interactions\nwith a user. It serves as an initial communication framework,\ndefining the boundaries of conversation by outlining the system’s\ncapabilities and the kind of messages it is able to provide. In\nthe context of the present experiment, the system message thus\noffered an optimal entry point to articulate the persuasive nature\nof the model and to describe how it should produce microtargeted\nresponses when offered a participants’ attributes. It was also where\ngeneral rules were defined that should remain in place across all\noutputs.\nBesides its persuasive aims, the system message was used to\ndefine two additional rules for the model to follow. Namely, that the\nmodel should not disclose that it is an AI model, and that it should\ntry keep participants from realizing they are being microtargeted.\nThese rules were motivated by an attempt to capture the strongest\npossible persuasive effects: voters are broadly disapproving of micro-\ntargeting practices (45–47) and skeptical of AI-authored texts (6).\nMoreover, empirical studies have found that perceptions of message\nquality consistently decline when participants realize they’ve been\ntargeted, or when they realize the messages were generated by an AI\n(7). Further, many documented real-life microtargeting operations\nhave attempted to remain covert (17). As a result, these system\ndirectives aimed to elucidate the largest possible effects and mimic\nreal-world targeting environments accurately.\nPrompt In contrast to the system message, the prompt delivered\nto the LLM directs the model’s response and steers the LLM’s\noutputs by dictating the specific task or context that the model\nneeds to address. While the system message defines the system’s\nfunctionality and sets the stage for interaction, the prompt navigates\nthe course of this interaction by soliciting desired responses from\nthe LLM.\nIn the context of the present work, the prompt was where the\nindividual-level personalization took place. While the system mes-\nsage remained the same for every participant, the prompt was\ncustomized through the injection of either 1, 3, 5, 7, or 9 of the par-\nticipants’ attributes and a randomized issue stance. The model was\nalso instructed in its prompt to generate messages of a consistent\nword length, around 200 words or 8-12 sentences.\nWeb Application This experiment required the construction of a\ncustom web application with a background job system (using Redis\nand RQ) capable of integrating OpenAI’s GPT-4 as a chat model in\nreal-time and at scale for thousands of participants. The core func-\ntionality revolved around generating and displaying messages under\ndifferent conditions. For a procedural diagram of the application,\nsee SI Appendix Figure S3. For more details about the construction\nof the web app, see SI section XX.\nStatistical Models This study investigates the effectiveness of\nthree different messaging conditions in influencing political attitudes.\nTo address the three stated research questions, we fit four distinct\nlinear multiple regression models. Each of these models were fit to\neach issue stance individually as well as combined.\nThe first model, addressing RQ1, focuses on the difference\nin means between the targeting and best message conditions.\nThe outcome variable is Yi, representing attitude. There are\nthree dummy variables in the model:accurate targeting, false\ntargeting, and control. These indicate the assignment effects\nto the respective conditions against thebest message condition.\nThe parameter on theaccurate targeting dummy variable,β1,\nrepresents the difference in average attitudes among respondents\nassigned toaccurate targeting vs. best message. The results of\nthis model are shown inFigure 1.\nThe second model, addressingRQ2, focuses on understanding\nhow changes in the number of attributes used to tailor a message\nimpact the response mean. The outcome variable remainsYi. The\nkey independent variable,attributes, can assume values from 0\nto 9, detailing the number of tailoring attributes. A value of 0 is\nindicative of thebest message condition. The parameter of primary\ninterest, β, represents the expected average attitude change for each\nadditional tailoring attribute. Positive, negative, or neutral values\nof β suggest increased persuasiveness, decreased persuasiveness,\nor no effect respectively. The results of this model are shown in\nFigure 2.\nHowever, to account for possible non-linear relationships be-\ntween attribute numbers and persuasiveness, an additional model\naddressing RQ2 was fitted. There are five dummy variables in the\nmodel: a1, a3, a5, a7, a9. Each variable indicates the effect of\nassignment to the given profile condition (1) vs. thebest message\ncondition (0). The parameters on these dummy variables,β1 - β5,\nare the key quantities of interest, corresponding to the difference in\naverage attitudes among respondents assigned to each sub-condition\nprofile vs.best message. Thebest message condition is thus repre-\nsented in the data such that it is always 0 when other conditions (a1\nto a9) are not 0. The results of this model are shown inFigure 3.\nFinally, RQ3 aims to discern the differences in attitude\noutcomes between messages tailored using 10 distinct demo-\ngraphic and political attributes compared to the “best message”.\nThus, our final model consists of 10 dummy variables{gender,\nage, ethnicity, income, education, geographic location,\nreligious affiliation, party affiliation, ideological\naffiliation, political engagement}. Each variable indicates\nthe effect of the presence of that targetable attribute in the model\nprompt (1) vs. thebest message condition (0). The parameters\non these dummy variables,β1 to β10, are the key quantities of\ninterest, corresponding to the difference in average attitudes among\nrespondents who were targeted based on a given attribute vs.best\nmessage. The results of this model are shown inFigure 4.\nACKNOWLEDGMENTS. For helpful comments and sugges-\ntions, we thank Ben Tappin at the Centre for the Politics of Feelings\nand Lujain Ibrahim at the Oxford Internet Institute.\n1. B Buchanan, A Lohn, M Musser, K Sedova, Truth, lies, and automation\nhow language models could change disinformation x (2021).\n2. H Bai, JG Voelkel, johannes C. Eichstaedt, R Willer, Artificial intelli-\ngence can persuade humans on political issues.Preprint (2023).\n3. AK Palmer, A Spirling, Large language models can argue in convincing\nand novel ways about politics: Evidence from experiments and human\njudgement. Github Prepr. (2023).\n4. E Karinshak, SX Liu, JS Park, JT Hancock, Working with ai to per-\nsuade: Examining a large language model’s ability to generate pro-\nvaccination messages. Proc. ACM on Human-Computer Interact. 7\n(2023).\n5. JA Goldstein, J Chao, S Grossman, A Stamos, M Tomz, Can ai write\npersuasive propaganda? Preprint (2023).\n6. S Kreps, RM McCain, M Brundage, All the news that’s fit to fabricate:\nAi-generated text as a tool of media misinformation.J. Exp. Polit. Sci.\n9, 104–117 (2022).\n7. G Spitale, N Biller-Andorno, F Germani, Ai model gpt-3 (dis)informs\nus better than humans.Sci. Adv. 9 (2023).\n8. M Jakesch, JT Hancock, M Naaman, Human heuristics for ai-generated\nlanguage are flawed. Proc. Natl. Acad. Sci. United States Am. 120,\ne2208839120 (2023).\n9. JA Goldstein, et al., Generative language models and automated influ-\nence operations: Emerging threats and potential mitigations. (2023).\n10. J Goldstein, G Sastry, The coming age of ai-powered propaganda | for-\neign affairs. Foreign Aff. (2023).\n11. MD Jong, M Theune, D Hofs, Politeness and alignment in dialogues with\na virtual guide. Proc. 7th Int. Conf. on Auton. Agents Multiagent\nSyst. (2008).\n12. HR Kirk, B Vidgen, P Röttger, SA Hale, Personalisation within bounds:\nA risk taxonomy and policy framework for the alignment of large lan-\nguage models with personalised feedback.Preprint (2023).\n13. L Weidinger, et al., Taxonomy of risks posed by language models.ACM\nConf. on Fairness, Accountability, Transpar. 22 (2022).\n14. F Koto, JH Lau, T Baldwin, Can pretrained language models generate\npersuasive, faithful, and informative ad text for product descriptions?\nECNLP 2022 - 5th Work. on e-Commerce NLP, Proc. Work. pp.\n234–243 (2022).\n15. A Tiwari, et al., Persona or context? towards building context adap-\ntive personalized persuasive virtual sales assistant.Proc. 2nd confer-\nence asia- pacific chapter association for computational linguistics\n1, 1035–1047 (2022).\n16. X Wang, et al., Persuasion for good: Towards a personalized persuasive\ndialogue system for social good.ACL 2019 - 57th Annu. Meet. Assoc.\nfor Comput. Linguist. Proc. Conf. pp. 5635–5649 (2019).\n8 Hackenburg et al.\n17. M Ali, P Sapiezynski, A Korolova, A Mislove, A Rieke, Ad delivery\nalgorithms: The hidden arbiters of political messaging. WSDM 2021\n- Proc. 14th ACM Int. Conf. on Web Search Data Min. pp. 13–21\n(2019).\n18. BBC, Vote leave’s targeted brexit ads released by facebook.BBC News\n(2018).\n19. S Morrison, Why are you seeing this digital political ad? no one knows!\nVox(2020).\n20. N Singer, ‘weaponized ad technology’: Facebook’s moneymaker gets a\ncritical eye - the new york times.The New York Times(2018).\n21. J Wong, ’it might work too well’: the dark art of political advertising\nonline. The Guard. (2018).\n22. M Scott, Cambridge analytica helped ‘cheat’ brexit vote and us election,\nclaims whistleblower – politico.POLITICO (2018).\n23. A Coppock, E Ekins, D Kirby, The long-lasting effects of newspaper\nop-eds on public opinion.Q. J. Polit. Sci. 13, 59–87 (2018).\n24. A Coppock, SJ Hill, L Vavreck, The small effects of political advertising\nare small regardless of context, message, sender, or receiver: Evidence\nfrom 59 real-time randomized experiments.Sci. advances6 (2020).\n25. K Endres, Targeted issue messages and voting behavior.\nhttps://doi.org/10.1177/1532673X19875694 (2019).\n26. ED Hersh, BF Schaffner, Targeted campaign appeals and the value of\nambiguity. J. Polit. 75, 520–534 (2013).\n27. M Jacobs-Harukawa, Does microtargeting work? evidence from an ex-\nperiment during the 2020 united states presidential election. Github\n(2021).\n28. BM Tappin, C Wittenberg, LB Hewitt, AJ Berinsky, DG Rand, Quan-\ntifying the persuasive returns to political microtargeting.Proc. Natl.\nAcad. Sci. (2023).\n29. B Zarouali, T Dobber, GD Pauw, CD Vreese, Using a personality-\nprofiling algorithm to investigate political microtargeting: Assessing the\npersuasion effects of personality-tailored ads on social media.Commun.\nRes. 2022, 1066–1091 (2022).\n30. SC Matz, M Kosinski, G Nave, DJ Stillwell, Psychological targeting as\nan effective approach to digital mass persuasion.Proc. Natl. Acad. Sci.\nUnited States Am. 114, 12714–12719 (2017).\n31. S Santurkar, et al., Whose opinions do language models reflect?\npreprint (2023).\n32. G Simmons, Moral mimicry: Large language models produce moral ra-\ntionalizations tailored to political identity. (2022).\n33. H Jiang, D Beeferman, B Roy, D Roy, Communitylm: Probing partisan\nworldviews from language models. (2022).\n34. LP Argyle, et al., Out of one, many: Using language models to simulate\nhuman samples. Polit. Analysispp. 1–15 (2023).\n35. J Hartmann, J Schwenzow, M Witte, The political ideology of conver-\nsational ai: Converging evidence on chatgpt’s pro-environmental, left-\nlibertarian orientation. SSRN Electron. J. (2023).\n36. RB Cialdini, Influence: Science and practice (5th edition). p. 272\n(2009).\n37. RE Petty, JT Cacioppo, The elaboration likelihood model of persuasion.\nCommun. Persuas. pp. 1–24 (1986).\n38. S Chaiken, Heuristic versus systematic information processing and the\nuse of source versus message cues in persuasion.J. Pers. Soc. Psychol.\n39, 752–766 (1980).\n39. S Fiske, S Taylor, Social cognition, 2nd ed. McGraw-Hill Book Co.\n(1991).\n40. L Chen, M Zaharia, J Zou, How is chatgpt’s behavior changing over\ntime? Preprint (2023).\n41. A Barr, Openai says it hasn’t ’made gpt-4 dumber’.Bus. Insid. (2023).\n42. P Aagaard, S Marthedal, Political microtargeting: Towards a pragmatic\napproach. (2023).\n43. FJZ Borgesius, et al., Online political microtargeting: Promises and\nthreats for democracy. 14 (2018).\n44. S Zuboff,The Age of Surveillance Capitalism: The fight for a human\nfuture at the new frontier of power. (Profile Books Ltd), (2019).\n45. J McCarthy, In u.s., most oppose micro-targeting in online political ads.\nGallup (2020).\n46. OR Group, Public are kept in the dark over data driven political cam-\npaigning, poll finds.Open Rights Group(2020).\n47. J Turow, MXD Carpini, NA Draper, R Howard-Williams, Americans\nroundly reject tailored political advertising.Annenberg Sch. for Com-\nmun. Univ. Pennsylvania(2012).\n9 Hackenburg et al.",
  "topic": "Speculation",
  "concepts": [
    {
      "name": "Speculation",
      "score": 0.6237715482711792
    },
    {
      "name": "Politics",
      "score": 0.6148582100868225
    },
    {
      "name": "Computer science",
      "score": 0.48274821043014526
    },
    {
      "name": "Pipeline (software)",
      "score": 0.45550796389579773
    },
    {
      "name": "Scale (ratio)",
      "score": 0.4104410409927368
    },
    {
      "name": "Scalability",
      "score": 0.41006767749786377
    },
    {
      "name": "Social psychology",
      "score": 0.3407583236694336
    },
    {
      "name": "Psychology",
      "score": 0.3297743797302246
    },
    {
      "name": "Political science",
      "score": 0.26020804047584534
    },
    {
      "name": "Business",
      "score": 0.1504463255405426
    },
    {
      "name": "Database",
      "score": 0.10306891798973083
    },
    {
      "name": "Law",
      "score": 0.08681666851043701
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Finance",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I40120149",
      "name": "University of Oxford",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I193374721",
      "name": "Internet Society",
      "country": "US"
    }
  ]
}