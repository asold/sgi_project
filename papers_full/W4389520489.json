{
  "title": "Conversational Recommender System and Large Language Model Are Made for Each Other in E-commerce Pre-sales Dialogue",
  "url": "https://openalex.org/W4389520489",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2099387669",
      "name": "Yuanxing Liu",
      "affiliations": [
        "Harbin Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2119756314",
      "name": "Weinan Zhang",
      "affiliations": [
        "Harbin Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2100991568",
      "name": "Yifan Chen",
      "affiliations": [
        "Harbin Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2127686377",
      "name": "Yuchi Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4207844108",
      "name": "Haopeng Bai",
      "affiliations": [
        "Harbin Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2107454313",
      "name": "Fan Feng",
      "affiliations": [
        "Harbin Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2130656240",
      "name": "Hengbin Cui",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2100492699",
      "name": "Yong-Bin Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2096786427",
      "name": "Wanxiang Che",
      "affiliations": [
        "Harbin Institute of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3153507763",
    "https://openalex.org/W4376652761",
    "https://openalex.org/W4283324387",
    "https://openalex.org/W4366327277",
    "https://openalex.org/W3168867926",
    "https://openalex.org/W3211527163",
    "https://openalex.org/W4389524458",
    "https://openalex.org/W3113741750",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W3105781833",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W3002226419",
    "https://openalex.org/W4362515116",
    "https://openalex.org/W4375959421",
    "https://openalex.org/W3204463216",
    "https://openalex.org/W3185784178",
    "https://openalex.org/W3101718968",
    "https://openalex.org/W4284671671",
    "https://openalex.org/W2952215380",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W4361193179",
    "https://openalex.org/W4366733551",
    "https://openalex.org/W4284682806",
    "https://openalex.org/W3031414376",
    "https://openalex.org/W4308198680",
    "https://openalex.org/W4404752313",
    "https://openalex.org/W3177331119",
    "https://openalex.org/W2970236742",
    "https://openalex.org/W3021703952",
    "https://openalex.org/W2976444281",
    "https://openalex.org/W3100790518",
    "https://openalex.org/W4283026156",
    "https://openalex.org/W3197381498",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W2963367478",
    "https://openalex.org/W2997662139",
    "https://openalex.org/W3035355914",
    "https://openalex.org/W3199824684",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4285294723",
    "https://openalex.org/W3014901735",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4303443398",
    "https://openalex.org/W3204697369",
    "https://openalex.org/W4311642023",
    "https://openalex.org/W4292779060"
  ],
  "abstract": "E-commerce pre-sales dialogue aims to understand and elicit user needs and preferences for the items they are seeking so as to provide appropriate recommendations. Conversational recommender systems (CRSs) learn user representation and provide accurate recommendations based on dialogue context, but rely on external knowledge. Large language models (LLMs) generate responses that mimic pre-sales dialogues after fine-tuning, but lack domain-specific knowledge for accurate recommendations. Intuitively, the strengths of LLM and CRS in E-commerce pre-sales dialogues are complementary, yet no previous work has explored this. This paper investigates the effectiveness of combining LLM and CRS in E-commerce pre-sales dialogues, proposing two collaboration methods: CRS assisting LLM and LLM assisting CRS. We conduct extensive experiments on a real-world dataset of E-commerce pre-sales dialogues. We analyze the impact of two collaborative approaches with two CRSs and two LLMs on four tasks of E-commerce pre-sales dialogue. We find that collaborations between CRS and LLM can be very effective in some cases.",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 9587–9605\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nConversational Recommender System and Large Language Model\nAre Made for Each Other in E-commerce Pre-sales Dialogue\nYuanxing Liu1 Wei-Nan Zhang1† Yifan Chen1 Yuchi Zhang1 Haopeng Bai1\nFan Feng2 Hengbin Cui2 Yongbin Li2 Wanxiang Che1\n1Research Center for Social Computing and Information Retrieval\nHarbin Institute of Technology, China\n2Independent, China\n{yxliu, wnzhang, yfchen, yczhang, hpbai, car}@ir.hit.edu.cn\n{fengfan.blender, alexcui.chb, liyb821}@gmail.com\nAbstract\nE-commerce pre-sales dialogue aims to under-\nstand and elicit user needs and preferences for\nthe items they are seeking so as to provide\nappropriate recommendations. Conversational\nrecommender systems (CRSs) learn user rep-\nresentation and provide accurate recommen-\ndations based on dialogue context, but rely\non external knowledge. Large language mod-\nels ( LLMs) generate responses that mimic\npre-sales dialogues after fine-tuning, but lack\ndomain-specific knowledge for accurate rec-\nommendations. Intuitively, the strengths of\nLLM and CRS in E-commerce pre-sales di-\nalogues are complementary, yet no previous\nwork has explored this. This paper investigates\nthe effectiveness of combining LLM and CRS\nin E-commerce pre-sales dialogues, proposing\ntwo collaboration methods: CRS assisting LLM\nand LLM assisting CRS. We conduct exten-\nsive experiments on a real-world dataset of E-\ncommerce pre-sales dialogues. We analyze the\nimpact of two collaborative approaches with\ntwo CRSs and two LLMs on four tasks of E-\ncommerce pre-sales dialogue. We find that col-\nlaborations between CRS and LLM can be very\neffective in some cases.\n1 Introduction\nE-commerce pre-sales dialogue refers to a dialogue\nbetween a user and a customer service staff be-\nfore the purchase action (Chen et al., 2020; Zhao\net al., 2021). A high-quality pre-sales dialogue\ncan greatly increase the purchase rate of a user.\nHowever, there are many challenges to providing a\nhigh-quality pre-sales dialogue service (Liu et al.,\n2023b). Refine. Figure 1 shows an example of\nan e-commerce pre-sales dialogue. The bot needs\nto interact with the user, understanding the user’s\nneeds and responding with understandable words.\nAdditionally, it should offer appropriate recommen-\ndations and elicit further preferences from the user.\n†Corresponding author.\nFigure 1: Example of E-commerce pre-sales dialogue.\nConversational recommender systems ( CRSs)\naim to learn relationships between user preferences\nand candidate product representations to provide\naccurate recommendations (Li et al., 2018) and\ngenerate responses related to recommended prod-\nucts (Liang et al., 2021). However, understanding\nuser preferences from dialogues relies heavily on\nexternal knowledge (Chen et al., 2019), e.g. DBpe-\ndia and ConceptNet. With an external knowledge\nbase, CRS is able to recognize the entities present\nin the context, but it still has difficulty understand-\ning the semantic information within the context.\nLarge language models (LLMs), which have nu-\nmerous parameters pre-trained on a large amount\nof data, possess a wealth of knowledge that en-\nables people to interact with them using natural\nlanguage (Brown et al., 2020; Ouyang et al., 2022).\nWith supervised fine-tuning tasks, LLMs can han-\ndle diverse user needs descriptions in pre-sales di-\nalogues. However, LLMs lack information about\ncandidate products, which makes them not suitable\nfor providing domain-specific recommendations.\n9587\nWhat will happen when LLMs and CRSs col-\nlaborate? In this paper, we explore two types\nof collaborations between LLMs and CRSs in E-\ncommerce pre-sales dialogues: (i) LLM assisting\nCRS. (ii) CRS assisting LLM. When a LLM assists\na CRS, we append the generated response of the\nLLM to the input of the CRS. For the recommenda-\ntion task, we incorporate the representation of the\nproduct predicted by the LLM into the calculation\nof the user representation. When a CRS assists a\nLLM, we append the predictions of the CRS to the\ninput of the LLM. For the recommendation task,\nwe insert the recommendation list, while the other\ntasks insert the text.\nSpecifically, we explore the effectiveness of col-\nlaborations on a real-world dataset of E-commerce\npre-sales dialogues, namely U-NEED (Liu et al.,\n2023b). U-NEED contains pre-sales dialogues in\nfive top categories and supports four key tasks\nin E-commerce pre-sales dialogue: (i) pre-sales\ndialogue understanding (ii) user needs elicita-\ntion (iii) user needs-based recommendation and\n(iv) pre-sales dialogue generation. We select two\npopular open source LLMs, ChatGLM-6B and\nChinese-Alpaca-7B, as well as two latest CRSs,\nBart-based CRS and CPT-based CRS. We report\nexperimental results for each combination of col-\nlaborations on the four challenging tasks. Experi-\nmental results demonstrate that the collaboration\nbetween LLM and CRS is effective on three tasks:\npre-sales dialogue understanding, user needs elici-\ntation and user needs-based recommendation.\nMain contributions of this paper are as follows:\n• To the best of our knowledge, we are the\nfirst to explore collaboration between LLM\nand CRS in a real-world scenario, namely E-\ncommerce pre-sales dialogue.\n• We propose methods for two types of collab-\norations between LLMs and CRSs, i.e., CRS\nassisting LLM and LLM assisting CRS.\n• Extensive experimental results on a real-world\nE-commerce pre-sales dialogue dataset indi-\ncate the effectiveness and potential of collabo-\nrations between LLMs and CRSs.\n2 Related Work\nWe review the related work along two lines: (i) con-\nversational recommendation and (ii) large language\nmodels (LLMs) for recommendation.\n2.1 Conversational recommendation\nConversational recommender systems (CRSs) aim\nto provide real-time recommendations based on\nusers’ dynamic preferences through natural lan-\nguage interactions (Gao et al., 2021; Jannach et al.,\n2021). Early work focus on: (i) question-based user\npreference elicitation (Zou et al., 2020; Hu et al.,\n2022a), (ii) multi-turn conversational recommenda-\ntion strategies (Lei et al., 2020a,b), (iii) exploration–\nexploitation trade-offs (Fu et al., 2021; Wong et al.,\n2021; Zhang et al., 2020), (iv) user preference mod-\neling with external knowledge (Zhou et al., 2022;\nChen et al., 2019; Ma et al., 2021; Zhou et al., 2021;\nRen et al., 2022), (v) dialogue strategies (Liu et al.,\n2020; Zhou et al., 2020; Hayati et al., 2020) and\n(vi) generating persuasive responses (Liang et al.,\n2021). Recently, some work (Deng et al., 2023;\nWang et al., 2022a,b) utilize pre-trained language\nmodels (PLMs) as the foundation to build unified\nCRSs, capable of performing various tasks using a\nsingle model, instead of multiple components.\nThe emergence of LLMs has undoubtedly im-\npacted CRS-related researches. However, previous\nwork barely explores the collaboration between\nconversational language models and CRSs on tasks\nrelated to conversational recommendation. We in-\nvestigate the collaboration between LLM and CRS\nin E-commerce pre-sales dialogues.\n2.2 LLMs for recommendation\nLarge language models ( LLMs), such as GPT-\n3 (Brown et al., 2020), InstructGPT (Ouyang\net al., 2022), PaLM (Chowdhery et al., 2022),\nBloom (Scao et al., 2022), LLaMA (Touvron et al.,\n2023) and GLM (Du et al., 2022), have gained at-\ntention for their natural language understanding\nand generation capabilities (Zhao et al., 2023). Re-\ncent studies have examined the performance of\nChatGPT (OpenAI, 2022) in tasks such as pas-\nsage re-ranking (Sun et al., 2023) and recommenda-\ntion (Wang et al., 2023; Liu et al., 2023a). ChatGPT\nhas also been applied to domains like augmenting\nrecommender systems (Gao et al., 2023). Addition-\nally, Friedman et al. (2023) propose a roadmap for\nutilizing LLM to build a controllable and explain-\nable CRS for YouTube videos.\nDifferent from previous work using LLM to en-\nhance CRS, we systematically investigate the ef-\nfectiveness of combining LLM and CRS, i.e., LLM\nassisting CRS and CRS assisting LLM, which pro-\nvides insights for future research on CRSs.\n9588\nFigure 2: A comparison of the three types of collaboration between a CRS and a LLM. We explore the collaboration\nbetween LLM and CRS, i.e., LLM assisting CRS and CRS assisting LLM, and we compare the three in detail in §5.\n3 Method\n3.1 Overview\nIn this paper, we explore the collaboration of a\nconversational recommender system (CRS) and a\nlarge language model (LLM). Figure 2 provides an\nillustration of our collaboration framework.\nLLM assisting CRS. We leverage the prediction\nresults of a LLM to support a CRS. Initially, we\nfine-tune a LLM using pre-sales dialogues, follow-\ning the method described in Section 3.2. Subse-\nquently, we incorporate the prediction results of\nthe fine-tuned large model into the training process\nof the CRS, via prompts and vectors. For a detailed\ndescription, refer to Section 3.5.\nCRS assisting LLM. We utilize the prediction re-\nsults of a CRS to assist a LLM. Initially, we train\na CRS using pre-sales dialogues, following the ap-\nproach outlined in Section 3.3. Subsequently, we\nintegrate the prediction results of the trained CRS\ninto the instructions and inputs to optimize the pro-\ncess of fine-tuning the LLM. For further details,\nsee Section 3.4.\nIn this paper, we explore the effectiveness of col-\nlaboration by analyzing the impact of collaboration\nbetween CRS and LLM on the performance of four\ntasks in E-commerce pre-sales dialogue (Liu et al.,\n2023b). These tasks include: (i) pre-sales dialogue\nunderstanding (ii) user needs elicitation (iii) user\nneeds-based recommendation and (iv) pre-sales di-\nalogue generation. Due to space constraints, we\nprovide detailed definitions of these tasks in Ap-\npendix A.\n3.2 LLMs for E-commerce pre-sales dialogue\nWe introduce the method of fine-tuning a large\nlanguage model (LLM) using pre-sales dialogues.\nInstruction data. Each sample within the train-\ning, validation, and test sets consists of “instruc-\ntion”, “input” and “output”. The “instruction” com-\nprises several sentences that introduce the task’s\nobjective. The “input” contains the necessary in-\nformation for completing the task. For instance,\nin the case of a user needs-based recommenda-\ntion task, the “input” encompasses the user’s needs,\ncandidate products, and related product knowledge.\nThe “output” remains consistent with the original\ntask. Figure 3 shows an example of the instruction\ndata corresponding to the user needs elicitation\ntask. Additional examples of various tasks can be\nfound in Appendix F. Note that the original user\nneeds-based recommendation task involves numer-\nous candidates, with each product possessing exten-\nsive attribute knowledge, the “input” surpasses the\nmaximum input length permitted by LLMs. Con-\nsequently, in practice, we limit the number of can-\ndidates to 20.\nBase LLMs and fine-tuning. We select ChatGLM\nand Chinese-Alpaca-7B as base LLMs due to their\nopenness and commendable performance in Chi-\nnese basic semantic understanding. ChatGLM is an\nopen bilingual language model built upon General\nLanguage Model (GLM) framework (Zeng et al.,\n2023), with 6.2 billion parameters.1 LLaMA (Tou-\nvron et al., 2023) is a decoder-only, foundational\nlarge language model based on the transformer ar-\nchitecture (Vaswani et al., 2017). The Chinese\nLLaMA model is an extension of the original\nLLaMA model, incorporating an expanded Chinese\nvocabulary and undergoing secondary pre-training\nusing Chinese data (Cui et al., 2023). We adopt\nthe Chinese Alpaca model, which builds upon the\naforementioned Chinese LLaMA model by incor-\nporating instruction data for fine-tuning.2 To carry\nout the fine-tuning process, we follow the official\nmethod provided by ChatGLM6B/Chinese-Alpaca-\nPlus-7B, using LoRA (Hu et al., 2022b).\n1https://github.com/THUDM/ChatGLM\n2https://github.com/ymcui/\nChinese-LLaMA-Alpaca\n9589\n3.3 CRSs for E-commerce pre-sales dialogue\nWe introduce the method of train a conversa-\ntional recommender system (CRS) for pre-sales di-\nalogues. We adopt UniMIND (Deng et al., 2023) as\nour base CRS, as it focus on multiple tasks in con-\nversational recommendation. The recommendation\ncandidates for UniMIND are movies. The movie ti-\ntle can be generated based on the prompt. However,\nin E-commerce pre-sales dialogue, the recommen-\ndation candidate is the product ID, which is diffi-\ncult to be decoded directly. Therefore, for the user\nneeds-based recommendation task we follow a tra-\nditional user representation-based approach (Kang\nand McAuley, 2018).\nPrompts. Following Deng et al. (2023), we de-\nfine the inputs and outputs of the four tasks us-\ning a unified sequence-to-sequence paradigm. We\nuse five special tokens to indicate information seg-\nments: (i) [user] indicates the utterance of the user.\n(ii) [system] indicates the response from customer\nservice staff. (iii) [understand] indicates the needs\ncontained in the user utterance, i.e., attributes and\nattribute values. (iv) [elicit] indicates the attributes\nthat the customer service staff plans to ask about\nuser preferences. (v) [recommend] indicates the\nitems that have been recommended by customer\nservice staff. For instance, the original input X can\nbe represented as follows:\nXU = [user] u1 [understand] d1 [system] s1 [understand]\nd2 . . .[user] ui\nXS = [user] u1 [understand] d1 [system] s1 [understand]\nd2 . . .[system] si\nXA = [user] u1 [understand] d1 [elicit] a1 [system] s1\n[understand] d2 . . .[user] ui\nXR = [user] u1 [understand] d1 [recommend] e1\n[system] s1 [understand] d2 . . .[user] ui\nXG = [user] u1 [understand] d1 [system] s1 [understand]\nd2 . . .[user] ui[elicit] a1 [recommend] e1\nwhere ui is the i-th utterance of the user, si is the\ni-th response of customer service staff, di is the\ni-th user needs, ai is the i-th attribute to be asked,\nand eiis the i-th recommended product. We adopt\nnatural language prompt (Raffel et al., 2020) to\nindicate each task:\nZU = “Identify attributes and values:”\nZA = “Select an attribute to ask:”\nZG = “Generate a response:”\nLoss functions. Following UniMIND (Deng et al.,\n2023), we design a unifiedCRS with prompts learn-\ning and multitask learning for pre-sales dialogues.\nLθ = E(X,Y,Z)∼D\nL∑\nl=1\nlog pθ(yl|y<l,X,Z), (1)\nwhere D= {DU, DA, DG}denote the train-set for\nthree tasks: pre-sales dialogue understanding, user\nneeds elicitation and pre-sales dialogue generation.\nAnd L is the length of the generated sequence. For\nuser needs-based recommendation task, the recom-\nmendation probability and loss function are defined\nas follows:\nri = CLS(ei, Enc(XR)) (2)\nLR = −\n|E|∑\ni=1\neilog ri, (3)\nwhere ei is the trainable item embedding, E is\ncollection of candidate products and ri is recom-\nmendation probability. CLS(·) is a classifier, we\napply linear layer in practice. And Enc(·) is the en-\ncoder, we adopt two versions: BART (Lewis et al.,\n2020) and CPT (Shao et al., 2021).\nTraining process. We train a CRS in two stages.\nIn the first stage we train a CRS only on the user\nneeds-based recommendation task, i.e., L= LR.\nSince BART and CPT do not have pre-sales conver-\nsation knowledge, this step aims to warm up CRS.\nIn the second stage we continue to train a CRS on\nall four tasks, i.e., L= LR + Lθ.\n3.4 Collaboration 1: CRS assisting LLM\nWe introduce the method of CRS assisting LLM.\nInitially, we train a CRS model following the ap-\nproach outlined in Section 3.3. Subsequently, we\nenrich the original instructions and inputs of a LLM\nby incorporating the prediction outcomes from the\nCRS model. Finally, we fine-tune the LLM, as\nexplained in § 3.3, utilizing the augmented instruc-\ntions and inputs.\nEnhanced instruction and input. We convert the\noutput of a trained CRS into text and incorporate it\ninto the input of LLM. We add additional instruc-\ntion, i.e., completing the task requires considering\nthe results of the CRS. An example is shown in\nthe upper right corner of Figure 3. Note that in the\nuser needs-based recommendation task, CRS can\noutput a list of recommendations along with cor-\nresponding recommendation scores. We rank the\n9590\nFigure 3: An example of collaboration between CRS and LLM on the user needs elicitation task. Left side shows\nthe input and output of the task. The middle displays data used to fine-tune a LLM and train a CRS independently.\nThe right side shows two cases of combining the two. Collaboration content is highlighted in red italics.\ncandidates according to their scores and include the\nranking to the input of LLM. For other tasks, we\nonly consider the final output of the trained CRS.\n3.5 Collaboration 2: LLM assisting CRS\nWe introduce the method of LLM assisting CRS.\nInitially, we fine-tune a LLM model using the tech-\nnique described in Section 3.2. Subsequently, we\nemploy the prediction outcomes from LLM to en-\nhance the prompt and user representation in the\nCRS model. Finally, we train a CRS model as\noutlined in § 3.3.\nEnhanced prompts. We use the prediction results\nof LLM to enhance the prompts of CRS.\nX′\nU = [user] u1 [understand] d1 [system] s1 [understand]\nd2 . . .[user] ui[LLM] ˆai, ˆvi\nX′\nS = [user] u1 [understand] d1 [system] s1 [understand]\nd2 . . .[system] si[LLM] ˆai, ˆvi\nX′\nA = [user] u1 [understand] d1 [elicit] a1 [system] s1\n[understand] d2 . . .[user] ui[LLM] ˆai\nX′\nG = [user] u1 [understand] d1 [system] s1 [understand]\nd2 . . .[user] ui[elicit] a1 [recommend] e1 [LLM] ˆsi\nFor X′\nU and X′\nS, ˆai and ˆvi are attributes and values\ninvolved in utterance identified byLLM for the i-th\nturn. For X′\nA, ˆai is the attribute in user needs elici-\ntation for the i-th turn. For X′\nG, ˆsi is the response\nfor the pre-sales dialogue generation task generated\nby LLM.\nEnhanced representation. For recommendation\ntask, we consider the embedding of the product\nrecommended by the fine-tuned LLM:\nr′\ni = CLS(ei, Enc(XR), ˆei) (4)\nL′\nR = −\n|E|∑\ni=1\neilog r′\ni, (5)\nwhere ˆei is the embedding of the product recom-\nmended by the fine-tuned LLM.\n4 Experimental Settings\n4.1 Research questions\nTo guide the remaining part of this paper, we set up\ntwo research questions:\n• Are LLM and CRS complementary? Does\nthe combination of LLM and CRS improve\nperformance?\n• How does the combination of CRS and LLM\nperform on different tasks and different cat-\negories? What are the differences between\ndifferent collaboration methods?\nIn the Results and Analysis section, we systemati-\ncally examine the outcomes of each task to answer\nthe aforementioned two research questions.\n4.2 Dataset\nWe conduct experiments on U-NEED (Liu et al.,\n2023b). U-NEED consists of 7,698 fine-grained an-\nnotated pre-sales dialogues, which consist of 1662,\n1513, 1135, 1748, and 1640 dialogues in Beauty,\nPhones, Fashion, Shoes and Electronics categories\nrespectively. We follow the partition of the training\nset, validation set and test set proposed in U-NEED.\n9591\nTable 1: Performance of baseline methods on pre-sales dialogue understanding task in 3 typical categories: Beauty,\nFashion and Shoes. Baseline results marked with * are taken from U-NEED (Liu et al., 2023b). CLLM is short for\nChatGLM and ALLM is short for Chinese-Alpaca. BCRS is short for UniMIND(BART) and CCRS is short for\nUniMIND(CPT). The best results are highlighted in bold.\nBeauty Shoes Phones All 5 categories\nMethods P R F1 P R F1 P R F1 P R F1\nBert* 0.5355 0.6284 0.5782 0.5851 0.7020 0.6382 0.4212 0.5384 0.4726 0.4549 0.5652 0.5041\nBert+CRF* 0.6731 0.6802 0.6766 0.7302 0.7703 0.7497 0.5620 0.5923 0.5768 0.6688 0.6530 0.6608\nBert+BiLSTM+CRF* 0.7282 0.7481 0.7380 0.7870 0.8101 0.7984 0.6701 0.6990 0.6843 0.6892 0.6875 0.6884\nNo collaboration\nUniMIND(BART) 0.6443 0.6000 0.6085 0.7711 0.7417 0.7483 0.7522 0.7406 0.7407 0.7188 0.6933 0.6978\nUniMIND(CPT) 0.5994 0.5420 0.5565 0.7468 0.6836 0.6889 0.7110 0.6907 0.6959 0.6807 0.6451 0.6539\nChatGLM 0.7858 0.7797 0.7777 0.8265 0.8307 0.8248 0.7805 0.7792 0.7760 0.7968 0.7936 0.7910\nChinese-Alpaca 0.7409 0.7310 0.7316 0.8032 0.7868 0.7899 0.7363 0.7178 0.7238 0.7568 0.7378 0.7425\nLLM assisting CRS\nCLLM-BCRS 0.6502 0.5848 0.6004 0.7725 0.7171 0.7318 0.7504 0.7152 0.7246 0.7173 0.6665 0.6796\nCLLM-CCRS 0.6101 0.5346 0.5545 0.7663 0.7218 0.7338 0.7183 0.6976 0.7018 0.7023 0.6539 0.6666\nALLM-BCRS 0.6255 0.5688 0.5835 0.7746 0.7120 0.7302 0.7311 0.7108 0.7159 0.7088 0.6653 0.6765\nALLM-CCRS 0.5730 0.5307 0.5410 0.7048 0.6658 0.6768 0.6833 0.6635 0.6691 0.6629 0.6277 0.6369\nCRS assisting LLM\nBCRS-CLLM 0.7900 0.7879 0.7824 0.8521 0.8511 0.8473 0.8222 0.8220 0.8179 0.8105 0.8065 0.8033\nCCRS-CLLM 0.7940 0.7926 0.78780.8372 0.8378 0.8326 0.7911 0.7866 0.7847 0.7927 0.7897 0.7864\nBCRS-ALLM 0.7772 0.7462 0.7542 0.8062 0.7690 0.7770 0.7662 0.7160 0.7311 0.7700 0.7310 0.7414\nCCRS-ALLM 0.7600 0.7272 0.7354 0.8036 0.7621 0.7738 0.7392 0.6978 0.7086 0.7569 0.7168 0.7276\n4.3 Baseline methods\nFor each task, baseline methods consist of typical\nmethods, CRS methods and LLM methods.\nTypical methods. We select typical meth-\nods for the four tasks following (Liu et al.,\n2023b). Specifically, we select Bert, Bert+CRF,\nBert+BiLSTM+CRF as baselines for pre-sales di-\nalogue. For user needs elicitation task, we se-\nlect DiaMultiClass and DiaSeq as baselines. For\nuser needs-based recommendation task, we choose\nBert, SASRec, TG-CRS. And we select GPT-2\nand KBRD as baseline methods for pre-sales dia-\nlogue generation task. For the limited space, we\nput the description of each typical methods in the\nAppendix B. We select UniMIND(BART) (Deng\net al., 2023) and UniMIND(CPT) as CRS meth-\nods. For LLM methods, we select ChatGLM (Zeng\net al., 2023) and Chinese-Alpaca (Cui et al., 2023).\nFor combination of LLM and CRS, we define eight\nvariants. We put the description of each variant in\nthe Appendix C.\n4.4 Evaluation metrics\nWe adopt the evaluation metrics used in U-\nNEED (Liu et al., 2023b). Specifically, we select\nprecision, recall and f1 score as evaluation metrics\nfor pre-sales dialogue understanding and user needs\nelicitation. For user needs-based recommendation\ntask, we choose Hit@K and MRR@K. And we\nadopt automatic and human evaluation for pre-sales\ndialogue generation task. For automatic evaluation,\nwe use Distinct-n. And for human evaluation, we\nmeasure the informativeness and relevance of gen-\nerated response. For the limited space, we put the\ndescription of each metric in the Appendix D.\n5 Results and Analysis\nWe conduct extensive experiments to explore the\nperformance of collaborations of LLMs and CRSs\non four tasks. We analyze impacts of collaborations\non each task in turn.\n5.1 Impacts of collaborations on pre-sales\ndialogue understanding\nBased on Table 1 we have the following observa-\ntions: (i) LLMs perform well in understanding\nuser needs. ChatGLM substantially outperforms\nclassical baseline methods and CRSs on all met-\nrics in all categories. The second best method is\nChinese-Alpaca, which outperforms the strongest\nbaseline method, Bert+BiLSTM+CRF, on most\nmetrics. We attribute this to the strong capabil-\nity of the LLMs for dialogue understanding. (ii) In\ncollaborations with CRSs, LLMs perform even\nbetter in understanding user needs.BCRS-CLLM\noutperforms ChatGLM in all category and all met-\nrics, especially in Shoes and Phones. Similarly\nwe observe that BCRS-ALLM outperforms Chine-\nse-Alpaca in some metrics. By carefully comparing\n9592\nTable 2: Performance of baseline methods on user needs elicitation task in 3 typical categories: Beauty, Fashion and\nShoes. Baseline results marked with * are taken from U-NEED (Liu et al., 2023b). CLLM is short for ChatGLM and\nALLM is short for Chinese-Alpaca. BCRS is short for UniMIND(BART) and CCRS is short for UniMIND(CPT).\nThe best results are highlighted in bold.\nBeauty Shoes Phones All 5 categories\nP R F1 P R F1 P R F1 P R F1\nDiaMultiClass* 0.4037 0.7228 0.50540.33610.41310.3423 0.45340.52120.4585 0.32220.49660.3662\nDiaSeq* 0.4761 0.4272 0.4424 0.3992 0.3305 0.3498 0.4414 0.3789 0.3966 0.3555 0.2996 0.3153\nNo collaboration\nUniMIND(BART) 0.4979 0.4305 0.4518 0.4367 0.3827 0.3927 0.5513 0.4973 0.5061 0.4301 0.3881 0.3943\nUniMIND(CPT) 0.4022 0.3575 0.3657 0.4388 0.3774 0.3906 0.4946 0.4432 0.4515 0.4021 0.3575 0.3657\nChatGLM 0.4348 0.4057 0.4055 0.4054 0.3496 0.3621 0.4712 0.4541 0.4441 0.3683 0.3422 0.3380\nChinese-Alpaca 0.2723 0.2362 0.2475 0.4020 0.3440 0.3588 0.4946 0.4613 0.4604 0.3513 0.3132 0.3191\nLLM assisting CRS\nCLLM-BCRS 0.51060.4413 0.4617 0.4510 0.38370.4016 0.57030.49820.5168 0.45180.39630.4095\nCLLM-CCRS 0.4128 0.3405 0.3583 0.45310.3735 0.3955 0.5243 0.4541 0.4737 0.4056 0.3405 0.3583\nALLM-BCRS 0.4702 0.4149 0.4289 0.4490 0.3827 0.3969 0.5297 0.4865 0.4863 0.4258 0.3866 0.3903\nALLM-CCRS 0.4043 0.3362 0.3574 0.4490 0.3661 0.3884 0.5505 0.4928 0.5009 0.4138 0.3519 0.3671\nCRS assisting LLM\nBCRS-CLLM 0.4908 0.4319 0.4450 0.3918 0.3280 0.3429 0.4923 0.4788 0.4645 0.4190 0.3723 0.3796\nCCRS-CLLM 0.4092 0.3766 0.3783 0.4082 0.3439 0.3590 0.4495 0.4356 0.4211 0.4020 0.3710 0.3704\nBCRS-ALLM 0.2660 0.2383 0.2428 0.2490 0.1914 0.2067 0.2568 0.2432 0.2378 0.2350 0.1904 0.1994\nCCRS-ALLM 0.1681 0.1489 0.1539 0.2388 0.1826 0.1951 0.2027 0.1874 0.1823 0.2071 0.1632 0.1730\nthe results of the four combinations of “CRS assist-\ning LLM” with the results of the four methods of\n“No collaboration”, we find that a better perform-\ning CRS improves the performance, while a worse\nperforming CRS degrades the performance. Since\nLLMs are usually very sensitive to inputs, we think\nthat the former may provide useful reference infor-\nmation to complement what the LLMs do not take\ninto account. The latter, on the other hand, may\nbring in noises that disturb the judgments of the\nLLMs. (iii) The improvement in understanding\nuser needs brought by the collaboration of CRS\nto LLMs varies across categories.In the Shoes\nand Phones categories, BCRS-CLLM significantly\noutperforms ChatGLM with the collaborations of\nCRSs. While in the Beauty category, BCRS-CLLM\nhas only a minor improvement compared to Chat-\nGLM. We think this may be due to the fact that user\nneeds in the Beauty category are usually focused\non specific attributes such as “skin type”.\n5.2 Impacts of collaborations on user needs\nelicitation\nBased on Table 2 we have the following observa-\ntions: (i) LLMs do not exhibit superb performance\non user needs elicitation.On the average results\nof the 5 categories, UniMIND(BART) achieves the\nbest performance, followed by the classical method\nDialMultiClass and UniMIND(CPT). Moreover,\nDiaMultiClass beats all the methods on Recall met-\nrics in Beauty, Shoes, and Mobile categories. This\nindicates that in E-commerce pre-sales dialogue,\nthe performance of methods that make decisions\nwith the help of generative models, e.g. BART\nand LLMs, is somewhat limited. DialMultiClass\ndoesn’t require a large number of parameters and\ndoesn’t need to be trained for a long period of\ntime. Compared to making decisions with LLMs,\nDialMultiClass still has considerable strengths in\nreal-world production environments. (ii) Collabo-\nrations between ChatGLM and UniMIND (BART)\ncan improve their respective performance in user\nneeds elicitation.Specifically, CLLM-BCRS out-\nperforms UniMIND(BART) on all metrics for\nall categories. Moreover, CLLM-BCRS beats\nall methods on six metrics. Similarly, BCRS–\nCLLM outperforms ChatGLM in all categories ex-\ncept Shoes. Specifically, BCRS-CLLM achieves\na 12.3% improvement over ChatGLM on the av-\nerage F1 score across all 5 categories. Based\non this, we see that the output of ChatGLM are\nbeneficial for UniMIND(BART) and vice versa.\n(iii) Chinese-Alpaca and ChatGLM exhibit ma-\njor differences in their performance in collabo-\nrations with CRSs. Specifically, CCRS-ALLM\nand BCRS-ALLM achieve the worst and second–\nworst performance on almost all metrics in all cat-\negories. This implies that the predicted results\nof CRSs cause a large disruption to Chinese-Al-\npaca. The two combinations of CRSs assisting\n9593\nTable 3: Performance of baseline methods on user needs-based recommendation task in 3 typical categories: Beauty,\nFashion and Shoes. H@K and M@K refer to Hit@K and MRR@K. Acc. refers to accuracy. CLLM is short for\nChatGLM and ALLM is short for Chinese-Alpaca. BCRS is short for UniMIND(BART) and CCRS is short for\nUniMIND(CPT). Since LLM methods only recommend 1 product, H@5 and M@5 cannot be calculated. The best\nresults are highlighted in bold.\nBeauty Shoes Phones All 5 categories\nAcc. H@5 M@5 Acc. H@5 M@5 Acc. H@5 M@5 Acc. H@5 M@5\nBert 0.0123 0.0185 0.0141 0.0046 0.0138 0.0072 0.0326 0.0688 0.0463 0.0118 0.0215 0.0151\nSASRec 0.1108 0.2831 0.1711 0.0399 0.1121 0.0668 0.0761 0.2681 0.1475 0.0976 0.2532 0.1556\nTG-CRS 0.1323 0.3354 0.2034 0.1275 0.2396 0.1692 0.2564 0.4928 0.3347 0.1744 0.3074 0.2244\nNo collaboration\nUniMIND(BART) 0.2154 0.6246 0.3654 0.2458 0.5315 0.3483 0.3478 0.6449 0.4608 0.2398 0.5440 0.3510\nUniMIND(CPT) 0.2554 0.62460.39150.2826 0.5438 0.3779 0.3043 0.6594 0.4460 0.2639 0.5617 0.3737\nChatGLM 0.2123 - - 0.3810 - - 0.0580 - - 0.2226 - -\nChinese-Alpaca 0.1415 - - 0.3917 - - 0.0036 - - 0.2157 - -\nLLM assisting CRS\nCLLM-BCRS 0.2462 0.6062 0.3741 0.2565 0.5376 0.3594 0.3804 0.7536 0.5204 0.2623 0.5617 0.3694\nCLLM-CCRS 0.25850.6308 0.3913 0.2657 0.5438 0.3690 0.4058 0.7138 0.5319 0.2768 0.5665 0.3835\nALLM-BCRS 0.2554 0.6092 0.3822 0.2550 0.5223 0.3554 0.3587 0.76810.5196 0.2623 0.5606 0.3721\nALLM-CCRS 0.2430 0.63690.3747 0.27500.5515 0.3788 0.43120.76090.5959 0.2822 0.5832 0.3919\nCRS assisting LLM\nBCRS-CLLM 0.1600 - - 0.2442 - - 0.3478 - - 0.2264 - -\nCCRS-CLLM 0.1785 - - 0.2642 - - 0.3043 - - 0.2479 - -\nBCRS-ALLM 0.2000 - - 0.2458 - - 0.3297 - - 0.2307 - -\nCCRS-ALLM 0.2369 - - 0.2688 - - 0.2754 - - 0.2532 - -\nChatGLM, i.e., BCRS-CLLM and CCRS-CLLM,\nhowever, perform well. We think that the differ-\nences between ChatGLM and Chinese-Alpaca in\ncollaborating with CRSs come from their base mod-\nels and fine-tuning data.\n5.3 Impacts of collaborations on user\nneeds-based recommendation\nBased on Table 3 we have the following observa-\ntions: (i) LLMs show the potential for user need-\ns-based recommendation.Specifically, LLMs, i.e.,\nChinese-Alpaca and ChatGLM, achieve the best\nand second best performance significantly outper-\nforming all the methods on the Accuracy in Shoes\ncategory, respectively. They also achieve perfor-\nmance over classical methods on the results of all\n5 categories. Based on this, we think that LLMs\ncan somewhat provide suitable recommendations\nwhen the candidate range is small (the number of\ncandidate products in Table 3 is 20). (ii) With\nthe collaboration ofLLMs, the recommendation\nperformance ofCRSs can be improved.Specifi-\ncally, on the average results across all 5 categories,\nALLM-CCRS achieves 6.9%, 3.8%, and 4.9% im-\nprovements on Accuracy, Hit@5, and MRR@5,\nrespectively, compared to UniMIND (CPT). Sim-\nilarly, on average results across all 5 categories,\nALLM-BCRS achieves 9.4%, 3.0%, and 6.0% im-\nprovements on Accuracy, Hit@5, and MRR@5,\nrespectively, when compared to UniMIND(BART).\nNote that LLMs provide recommendations in a\ndifferent way than CRSs do. LLMs provide rec-\nommendations relying on given inputs, i.e., a rec-\nommended product is semantically related to user\nneeds in some way. CRSs, on the other hand,\nmodel a representation of both and learn the im-\nplicit relationship between the two to compute the\nprobability of a product being recommended. The\nabove improvements are only that CRSs consider\nthe representations of the recommended products\ngiven by the LLMs. We believe that collabora-\ntions between LLMs and CRSs on recommenda-\ntion tasks go far beyond this and are a direction\nworth exploring. (iii) With collaborations with\nCRSs, LLMs can achieve comparable recommen-\ndation performance. Specifically, in the Phones\ncategory, ChatGLM and Chinese-Alpaca have very\npoor recommendation performance. In contrast,\nthe four methods of “CRS assisting LLM” achieve\nthe performance close to that of CRSs. Based on\nthis, we think that when the recommendation per-\nformance of LLMs is very poor in a certain do-\nmain, a collaborative approach could make LLMs\nto achieve performance close to that of CRSs.\n9594\nTable 4: Performance of baseline methods on pre-sales dialogue generation task in 3 typical categories: Beauty,\nFashion and Shoes. CLLM is short for ChatGLM and ALLM is short for Chinese-Alpaca. BCRS is short for\nUniMIND(BART) and CCRS is short for UniMIND(CPT). Info. and Rel. refer to informativeness and relevance.\nThe best results are highlighted in bold.\nBeauty Shoes Phones All 3 categories\nDist-1 Rel. Info. Dist-1 Rel. Info. Dist-1 Rel. Info. Dist-1 Rel. Info.\nGPT-2 0.6195 1.8800 1.8400 0.6504 2.1933 2.1467 0.6305 1.9867 1.8067 0.6335 2.0200 1.9311\nKBRD 0.5753 2.9933 2.5067 0.5639 3.3467 2.8800 0.6034 3.1000 2.7533 0.5809 3.1467 2.7133\nNo collaboration\nUniMIND(BART) 0.8611 3.7933 3.3600 0.8897 3.9133 3.6933 0.8299 3.6667 3.6200 0.8521 3.7911 3.5578\nUniMIND(CPT) 0.8578 3.7333 3.2600 0.9080 3.9333 3.7800 0.84723.8000 3.74000.8583 3.8222 3.5933\nChatGLM 0.8169 3.7467 3.4533 0.8594 3.7000 3.4400 0.8411 3.6200 3.4533 0.8152 3.6889 3.4489\nChinese-Alpaca 0.91313.6667 3.24670.91243.8733 3.66670.91093.6733 3.61330.89273.7378 3.5089\nLLM assisting CRS\nCLLM-BCRS 0.8686 3.8467 3.4933 0.8986 3.9133 3.7600 0.8460 3.7267 3.6000 0.8611 3.82893.6178\nCLLM-CCRS 0.8633 3.7667 3.50000.8975 3.9267 3.7200 0.8568 3.6267 3.5267 0.8587 3.7734 3.5822\nALLM-BCRS 0.8700 3.7667 3.4000 0.8959 3.9200 3.78670.8505 3.7333 3.6533 0.8650 3.8067 3.6133\nALLM-CCRS 0.8792 3.8467 3.4467 0.9086 3.9933 3.78670.8640 3.6400 3.5933 0.8699 3.8267 3.6089\nCRS assisting LLM\nBCRS-CLLM 0.8371 3.6867 3.3867 0.8735 3.9400 3.7667 0.8544 3.6733 3.5800 0.8365 3.7667 3.5778\nCCRS-CLLM 0.8324 3.5000 3.0867 0.8714 3.9200 3.7800 0.8355 3.5933 3.4533 0.8256 3.6711 3.4400\nBCRS-ALLM 0.8910 3.6933 3.2200 0.9011 3.7867 3.6133 0.9040 3.6067 3.5400 0.8804 3.6956 3.4578\nCCRS-ALLM 0.8898 3.86003.3400 0.8951 3.9333 3.6733 0.8988 3.7400 3.5667 0.88263.84443.5267\n5.4 Impacts of collaborations on pre-sales\ndialogue generation\nBased on Table 4 we have the following obser-\nvations: (i) CRSs and LLMs show comparable\nperformance in pre-sales dialogue generation.In\nShoes, Beauty, and Phones categories, Chinese-Al-\npaca achieves the best performance on Dist-1. This\nindicates that Chinese-Alpaca can generate more\ndiverse responses. While in most cases, the re-\nsponses generated by CRSs are more relevant and\ninformative than those generated by LLMs. In ad-\ndition, neither the LLMs nor the CRSs generate\nresponses that beat the ground truth responses pro-\nvided by customer service staff. (ii)Collaborations\nbetween LLMs andCRSs show marginal effects\non pre-sales dialogue generation. Specifically,\nthe methods of collaborations between LLMs and\nCRSs, i.e., “LLM assisting CRS” and “CRS assist-\ning LLM”, achieve the best performance on most\nof the metrics. However, the improvement from\ncollaboration is marginal compared to CRSs or\nLLMs. We believe this may be due to the fact that\nLLMs and UniMIND are relatively close in their\napproaches to generating responses, i.e., both are\nbased on pre-trained language models and prompts.\nTherefore, collaborations between two similar ap-\nproaches does not have much impact. In future\nwork, we plan to consider CRSs that focus on gen-\nerating persuasive reasons for recommendations,\ne.g., NTRDs that introduce words related to the\nrecommended items in the decoding process. In-\ntuitively, collaborations between such CRSs and\nLLMs may work out well.\n6 Conclusions and Future Work\nIn this paper, we investigated the integration of con-\nversational recommender systems (CRS) and large\nlanguage models (LLM) in E-commerce pre-sales\ndialogues. Specifically, we proposed two collabo-\nration strategies: “CRS assisting LLM” and “LLM\nassisting CRS”. We evaluate the effectiveness of\nthese collaborations between two LLMs and two\nCRSs on four tasks related to E-commerce pre-\nsales dialogues. Through extensive experiments\nand careful analysis, we found that the collabora-\ntion between CRS and LLM can be highly effective\nin certain scenarios, providing valuable insights\nfor both research and practical applications in E-\ncommerce pre-sales dialogues. Additionally, our\nfindings can inspire exploration of collaborations\nbetween general large models and private small\nmodels in other domains and areas.\nFor future work, we plan to examine the collab-\noration between LLMs and CRSs across various\ncategories. For instance, a CRS within the Shoes\ncategory could provide information to a LLM in\nthe Fashion category, resulting in a recommended\ncombination such as a dress, pants, and shoes.\n9595\nLimitations\nOne limitation of our work is that our findings\nmay only apply to large language models (LLMs)\naround 7B parameters. In this work, we select two\nLLMs that are widely used, namely ChatGLM-6B\nand Chinese-Alpaca-7B. Related work reveals that\nthere is some variation in the capability of LLMs\nwith different parameter sizes (Wei et al., 2022).\nFor LLMs with more parameters, such as 100B,\nmore GPU resources and time are needed to ex-\nplore the effects of combining CRSs and LLMs. In\naddition, LLMs are constantly being updated. Re-\ncently ChatGLM2-6B and Chinese-Alpaca2-13B\nhave been open sourced.3 They show better perfor-\nmance than ChatGLM-6B and Chinese-Alpaca-7B\non multiple benchmarks, and may have higher re-\nsults on E-commerce pre-sales dialogues as well.\nHowever, we believe that the combination ofLLMs\nand CRSs is still worth researching.\nEthics Statement\nIn this paper, we explore the effectiveness of com-\nbining LLM and CRS on e-commerce pre-sales\nconversations. We are committed to using and mod-\nify U-NEED dataset only for research purposes and\nnot for commercial exploitation. Our proposed ap-\nproach does not generate harmful content or raise\nethical issues.\nAcknowledgments\nWe thank the anonymous reviewers for their help-\nful comments. This work is supported by the Na-\ntional Key Research and Development Program\n(No. 2022YFF0902100) and National Natural Sci-\nence Foundation of China (No. 62076081 and No.\n61936010).\nReferences\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. Advances in neural information processing\nsystems, 33:1877–1901.\nMeng Chen, Ruixue Liu, Lei Shen, Shaozu Yuan,\nJingyan Zhou, Youzheng Wu, Xiaodong He, and\nBowen Zhou. 2020. The JDDC corpus: A large-scale\nmulti-turn Chinese dialogue dataset for E-commerce\ncustomer service. In Proc. of LREC.\n3https://github.com/THUDM/ChatGLM2-6B\nhttps://github.com/ymcui/Chinese-LLaMA-Alpaca-2\nQibin Chen, Junyang Lin, Yichang Zhang, Ming Ding,\nYukuo Cen, Hongxia Yang, and Jie Tang. 2019. To-\nwards knowledge-based recommender dialog system.\nIn Proc. of EMNLP.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts, Paul\nBarham, Hyung Won Chung, Charles Sutton, Sebas-\ntian Gehrmann, et al. 2022. Palm: Scaling language\nmodeling with pathways.\nYiming Cui, Ziqing Yang, and Xin Yao. 2023. Efficient\nand effective text encoding for chinese llama and\nalpaca.\nZhenjin Dai, Xutao Wang, Pin Ni, Yuming Li, Gangmin\nLi, and Xuming Bai. 2019. Named Entity Recogni-\ntion Using BERT BiLSTM CRF for Chinese Elec-\ntronic Health Records. In Proc. - 2019 12th Int.\nCongr. Image Signal Process. Biomed. Eng. Infor-\nmatics, CISP-BMEI 2019, pages 0–4.\nYang Deng, Wenxuan Zhang, Weiwen Xu, Wenqiang\nLei, Tat-Seng Chua, and Wai Lam. 2023. A unified\nmulti-task learning framework for multi-goal conver-\nsational recommender systems. ACM Transactions\non Information Systems, 41(3):1–25.\nJacob Devlin, Ming Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. NAACL HLT 2019 - 2019 Conf. North\nAm. Chapter Assoc. Comput. Linguist. Hum. Lang.\nTechnol. - Proc. Conf., 1:4171–4186.\nZhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding,\nJiezhong Qiu, Zhilin Yang, and Jie Tang. 2022. Glm:\nGeneral language model pretraining with autoregres-\nsive blank infilling. In Proceedings of the 60th An-\nnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 320–335.\nLuke Friedman, Sameer Ahuja, David Allen, Terry Tan,\nHakim Sidahmed, Changbo Long, Jun Xie, Gabriel\nSchubiner, Ajay Patel, Harsh Lara, et al. 2023. Lever-\naging large language models in conversational rec-\nommender systems.\nZuohui Fu, Yikun Xian, Yaxin Zhu, Shuyuan Xu, Ze-\nlong Li, Gerard de Melo, and Yongfeng Zhang. 2021.\nHoops: Human-in-the-loop graph reasoning for con-\nversational recommendation. In Proc. of SIGIR.\nChongming Gao, Wenqiang Lei, Xiangnan He, Maarten\nde Rijke, and Tat-Seng Chua. 2021. Advances and\nchallenges in conversational recommender systems:\nA survey. AI Open, 2:100–126.\nYunfan Gao, Tao Sheng, Youlin Xiang, Yun Xiong,\nHaofen Wang, and Jiawei Zhang. 2023. Chat-rec:\nTowards interactive and explainable llms-augmented\nrecommender system.\nShirley Anugrah Hayati, Dongyeop Kang, Qingxi-\naoyang Zhu, Weiyan Shi, and Zhou Yu. 2020. IN-\nSPIRED: Toward sociable recommendation dialog\nsystems. In Proc. of EMNLP.\n9596\nChenhao Hu, Shuhua Huang, Yansen Zhang, and Yubao\nLiu. 2022a. Learning to infer user implicit preference\nin conversational recommendation. In Proceedings\nof the 45th International ACM SIGIR Conference on\nResearch and Development in Information Retrieval,\nSIGIR ’22, page 256–266, New York, NY , USA. As-\nsociation for Computing Machinery.\nEdward J Hu, Phillip Wallis, Zeyuan Allen-Zhu,\nYuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen,\net al. 2022b. Lora: Low-rank adaptation of large\nlanguage models. In International Conference on\nLearning Representations.\nDietmar Jannach, Ahtsham Manzoor, Wanling Cai, and\nLi Chen. 2021. A Survey on Conversational Recom-\nmender Systems. ACM Comput. Surv., 54(5).\nWang Cheng Kang and Julian McAuley. 2018. Self-\nAttentive Sequential Recommendation. In Proc. -\nIEEE Int. Conf. Data Mining, ICDM, volume 2018-\nNovem, pages 197–206. IEEE.\nWenqiang Lei, Xiangnan He, Yisong Miao, Qingyun\nWu, Richang Hong, Min-Yen Kan, and Tat-Seng\nChua. 2020a. Estimation-action-reflection: Towards\ndeep interaction between conversational and recom-\nmender systems. In Proc. of WSDM.\nWenqiang Lei, Gangyi Zhang, Xiangnan He, Yisong\nMiao, Xiang Wang, Liang Chen, and Tat-Seng Chua.\n2020b. Interactive path reasoning on graph for con-\nversational recommendation. In Proc. of KDD.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVeselin Stoyanov, and Luke Zettlemoyer. 2020. Bart:\nDenoising sequence-to-sequence pre-training for nat-\nural language generation, translation, and comprehen-\nsion. In Proceedings of the 58th Annual Meeting of\nthe Association for Computational Linguistics, pages\n7871–7880.\nRaymond Li, Samira Ebrahimi Kahou, Hannes Schulz,\nVincent Michalski, Laurent Charlin, and Chris Pal.\n2018. Towards deep conversational recommenda-\ntions. In Proc. of NeurIPS.\nZiming Li, Julia Kiseleva, and Maarten de Rijke. 2020.\nRethinking supervised learning and reinforcement\nlearning in task-oriented dialogue systems. In Find-\nings of the Association for Computational Linguistics:\nEMNLP 2020, pages 3537–3546, Online. Association\nfor Computational Linguistics.\nZujie Liang, Huang Hu, Can Xu, Jian Miao, Yingy-\ning He, Yining Chen, Xiubo Geng, Fan Liang, and\nDaxin Jiang. 2021. Learning neural templates for\nrecommender dialogue system. In Proc. of EMNLP.\nJunling Liu, Chao Liu, Renjie Lv, Kang Zhou, and Yan\nZhang. 2023a. Is chatgpt a good recommender? a\npreliminary study.\nYuanxing Liu, Weinan Zhang, Baohua Dong, Yan Fan,\nHang Wang, Fan Feng, Yifan Chen, Ziyu Zhuang,\nHengbin Cui, Yongbin Li, and Wanxiang Che. 2023b.\nU-need: A fine-grained dataset for user needs-centric\ne-commerce conversational recommendation. In Pro-\nceedings of the 46th International ACM SIGIR Con-\nference on Research and Development in Information\nRetrieval, SIGIR ’23, page 2723–2732, New York,\nNY , USA. Association for Computing Machinery.\nZeming Liu, Haifeng Wang, Zheng-Yu Niu, Hua Wu,\nWanxiang Che, and Ting Liu. 2020. Towards conver-\nsational recommendation over multi-type dialogs. In\nProc. of ACL.\nWenchang Ma, Ryuichi Takanobu, and Minlie Huang.\n2021. CR-walker: Tree-structured graph reasoning\nand dialog acts for conversational recommendation.\nIn Proc. of EMNLP.\nOpenAI. 2022. Introducing chatgpt.\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\nCarroll Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, et al.\n2022. Training language models to follow instruc-\ntions with human feedback. Advances in Neural\nInformation Processing Systems, 35:27730–27744.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, Ilya Sutskever, et al. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog, 1(8):9.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer. The Journal of Machine Learning Research,\n21(1):5485–5551.\nZhaochun Ren, Zhi Tian, Dongdong Li, Pengjie Ren,\nLiu Yang, Xin Xin, Huasheng Liang, Maarten de Ri-\njke, and Zhumin Chen. 2022. Variational reasoning\nabout user preferences for conversational recommen-\ndation. In Proceedings of the 45th International ACM\nSIGIR Conference on Research and Development in\nInformation Retrieval , SIGIR ’22, page 165–175,\nNew York, NY , USA. Association for Computing\nMachinery.\nTeven Le Scao, Angela Fan, Christopher Akiki, El-\nlie Pavlick, Suzana Ili ´c, Daniel Hesslow, Roman\nCastagné, Alexandra Sasha Luccioni, François Yvon,\nMatthias Gallé, et al. 2022. Bloom: A 176b-\nparameter open-access multilingual language model.\nYunfan Shao, Zhichao Geng, Yitao Liu, Junqi Dai, Hang\nYan, Fei Yang, Li Zhe, Hujun Bao, and Xipeng Qiu.\n2021. Cpt: A pre-trained unbalanced transformer for\nboth chinese language understanding and generation.\nFábio Souza, Rodrigo Nogueira, and Roberto Lotufo.\n2019. Portuguese Named Entity Recognition using\nBERT-CRF.\n9597\nWeiwei Sun, Lingyong Yan, Xinyu Ma, Pengjie Ren,\nDawei Yin, and Zhaochun Ren. 2023. Is chatgpt\ngood at search? investigating large language models\nas re-ranking agent.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal\nAzhar, Aurelien Rodriguez, Armand Joulin, Edouard\nGrave, and Guillaume Lample. 2023. Llama: Open\nand efficient foundation language models.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Proc. of NeurIPS.\nLingzhi Wang, Huang Hu, Lei Sha, Can Xu, Daxin\nJiang, and Kam-Fai Wong. 2022a. RecInDial: A uni-\nfied framework for conversational recommendation\nwith pretrained language models. In Proceedings of\nthe 2nd Conference of the Asia-Pacific Chapter of the\nAssociation for Computational Linguistics and the\n12th International Joint Conference on Natural Lan-\nguage Processing (Volume 1: Long Papers), pages\n489–500, Online only. Association for Computational\nLinguistics.\nXiaolei Wang, Xinyu Tang, Wayne Xin Zhao, Jingyuan\nWang, and Ji-Rong Wen. 2023. Rethinking the evalu-\nation for conversational recommendation in the era\nof large language models.\nXiaolei Wang, Kun Zhou, Ji-Rong Wen, and Wayne Xin\nZhao. 2022b. Towards unified conversational rec-\nommender systems via knowledge-enhanced prompt\nlearning. In Proceedings of the 28th ACM SIGKDD\nConference on Knowledge Discovery and Data Min-\ning, KDD ’22, page 1929–1937, New York, NY , USA.\nAssociation for Computing Machinery.\nJason Wei, Yi Tay, Rishi Bommasani, Colin Raffel,\nBarret Zoph, Sebastian Borgeaud, Dani Yogatama,\nMaarten Bosma, Denny Zhou, Donald Metzler, Ed H.\nChi, Tatsunori Hashimoto, Oriol Vinyals, Percy\nLiang, Jeff Dean, and William Fedus. 2022. Emer-\ngent abilities of large language models. Transactions\non Machine Learning Research . Survey Certifica-\ntion.\nChi-Man Wong, Fan Feng, Wen Zhang, Chi-Man V ong,\nHui Chen, Yichi Zhang, Peng He, Huan Chen, Kun\nZhao, and Huajun Chen. 2021. Improving conver-\nsational recommender system by pretraining billion-\nscale knowledge graph. In 2021 IEEE 37th Interna-\ntional Conference on Data Engineering (ICDE).\nAohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang,\nHanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu,\nWendi Zheng, Xiao Xia, et al. 2023. Glm-130b:\nAn open bilingual pre-trained model. In Proc. of\nICLR. International Conference on Learning Repre-\nsentations, ICLR.\nXiaoying Zhang, Hong Xie, Hang Li, and John C. S. Lui.\n2020. Conversational contextual bandit: Algorithm\nand application. In Proc. of WWW.\nNan Zhao, Haoran Li, Youzheng Wu, Xiaodong He, and\nBowen Zhou. 2021. The jddc 2.0 corpus: A large-\nscale multimodal multi-turn chinese dialogue dataset\nfor e-commerce customer service.\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,\nXiaolei Wang, Yupeng Hou, Yingqian Min, Beichen\nZhang, Junjie Zhang, Zican Dong, Yifan Du, Chen\nYang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang,\nRuiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu,\nPeiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023. A\nsurvey of large language models.\nJinfeng Zhou, Bo Wang, Ruifang He, and Yuexian\nHou. 2021. CRFR: Improving conversational rec-\nommender systems via flexible fragments reasoning\non knowledge graphs. In Proc. of EMNLP.\nKun Zhou, Yuanhang Zhou, Wayne Xin Zhao, Xiaoke\nWang, and Ji-Rong Wen. 2020. Towards topic-guided\nconversational recommender system. In Proc. of\nCOLING.\nYuanhang Zhou, Kun Zhou, Wayne Xin Zhao, Cheng\nWang, Peng Jiang, and He Hu. 2022. C2-crs: Coarse-\nto-fine contrastive learning for conversational recom-\nmender system. In Proc. of WSDM.\nJie Zou, Yifan Chen, and Evangelos Kanoulas. 2020.\nTowards question-based recommender systems. In\nProc. of SIGIR.\nA Pre-sales Dialogue Tasks\nTo evaluate the performance of CRSs, LLMs and\ntheir collaborations in E-commerce scenarios, we\nadopt four challenging tasks proposed in U-NEED\ndataset (Liu et al., 2023b). The four challeng-\ning tasks are: (i) pre-sales dialogue understand-\ning (ii) user needs elicitation (iii) user needs-based\nrecommendation and (iv) pre-sales dialogue gener-\nation.\nPre-sales dialogue understanding aims to under-\nstand utterances of both users and customer service\nstaff. First, identify the attributes that are related to\nproducts. And second, extract preferences related\nto the identified attributes. For example, when a\nuser says, “Which of your thermal underwear is the\nwarmest? Recommend one?” This task aims to ob-\ntain semantic frames { (“Functional requirement”,\n“Warmest”), (“Category”, “Thermal underwear”)\n}, where “Functional requirement” and “Category”\nare attributes related to products. “Warmest” and\n“Thermal underwear” are preferences.\nUser needs elicitation aims to select attributes\nthat can elicit more information about user needs.\n9598\nThe inputs for this task are the dialogue context\nand the identified user needs, i.e., { (“Functional\nrequirement”, “Warmest”), (“Category”, “Thermal\nunderwear”) }. The output is a set of attributes,\ne.g., {“Category”, “Price”}.\nUser needs-based recommendation aims to rec-\nommend products that satisfy explicit and implicit\nuser needs. Explicit user needs refer to the needs\nand preferences expressed by the user in the on-\ngoing dialogue, i.e., { (“Functional requirement”,\n“Warmest”), (“Category”, “Thermal underwear”)\n}. Implicit user needs are related to user behav-\niors outside of the pre-sales dialogue. Users usu-\nally view some items before starting a dialogue\nwith the customer service staff. In addition, they\nbrowse through items while talking to customer\nservice staff. Such behaviors can reflect implicit\nuser needs to some extent. The inputs to this task\nare explicit and implicit user needs, i.e., identified\nsemantic frames and user behaviors, and the output\nis a collection of items.\nPre-sales dialogue generation aims to generate\na response based on given information about user\nneeds. Information consists of a collection of at-\ntributes and a collection of items. The collection\nof attributes is the output of the user needs elici-\ntation task, i.e., the attributes that may elicit more\ninformation about the user’s needs. The collec-\ntion of items is the output of the user needs-based\nrecommendation task, i.e., items that satisfy the\ncurrent user needs. The inputs to this task are the\ndialogue context, the collection of attributes and\nthe collection of items. The output is a response,\nwhich may be a query asking a question about an\nattribute, e.g.,“What are your requirements for the\nthermal underwear?” or a recommendation reason\nfor recommending an item, e.g., “Recommended\nitem: 655398643290. This one is seamless and\nmade of double-sided fleece. You can take a look.”\nB Baselines for Pre-sales Dialogue Tasks\nFollowing Liu et al. (2023b), we (i) select Bert (De-\nvlin et al., 2019), Bert+CRF (Souza et al., 2019)\nand Bert+BiLSTM+CRF (Dai et al., 2019) as base-\nlines for the pre-sales dialogue understanding task;\n(ii) select DiaMultiClass (Li et al., 2020) and Di-\naSeq (Li et al., 2020) as baselines for the user\nneeds elicitation task; (iii) select Bert (Devlin et al.,\n2019), SASRec (Kang and McAuley, 2018) and\nTG-CRS (Zhou et al., 2020) as baselines for the\nuser needs-based recommendation task; (iv) and se-\nlect GPT-2 (Radford et al., 2019) and KBRD (Chen\net al., 2019) as baselines for the pre-sales dialogue\ngeneration task.\nFor the pre-sales dialogue understanding task,\nBert, Bert+CRF, and Bert+BiLSTM+CRF adopt\nthe sequence labeling approach to identify the se-\nmantic frames. Bert considers only the representa-\ntion of the input utterance. Bert+CRF takes into ac-\ncount the sequential relationships of the predicted\ntags in addition to the representation of the input\nutterance. Whereas Bert+BiLSTM+CRF adds bidi-\nrectional information encoding after obtaining the\nrepresentation of the input and considers the se-\nquential relationships of the predicted tags to com-\npute the probability of each tag.\nFor the user needs elicitation task, DiaMulti-\nClass and DiaSeq employ a multi-label classifi-\ncation approach to determine the collection of at-\ntributes.DiaMultiClass computes the probability of\neach attribute based on the representation of the\ninputs.DiaSeq computes the probability of each at-\ntribute based on the sequential relationship between\nsemantic frames.\nThe baseline for the user needs-based recom-\nmendation task is Bert, SASRec and TG-CRS. Bert\ncalculates the probability of an item based on the\nrepresentation of the input. SASRec calculates the\nprobability of an item based on the sequential re-\nlationships of user behaviors. TG-CRS considers\nboth dialogue context and sequential user behav-\niors.\nFor the pre-sales dialogue generation task, the\nbaselines are GPT-2 and KBRD. GPT-2 is a com-\nmonly used pre-trained language model for the dia-\nlogue generation task. KBRD utilizes a switching\nmechanism to introduce tokens related to the rec-\nommended items during the decoding of responses.\nC Combinations of LLMs and CRSs\nWe define four variants of LLM assists CRS:\n• CLLM-BCRS refers that ChatGLM assists\nBART-based CRS.\n• CLLM-CCRS refers that ChatGLM assists\nCPT-based CRS.\n• ALLM-BCRS refers that Chinese-Alpaca as-\nsists BART-based CRS.\n• ALLM-CCRS refers that Chinese-Alpaca as-\nsists BART-based CRS.\n9599\nWe define four variants of CRS assists LLM:\n• BCRS-CLLM refers that BART-based CRS\nassists ChatGLM.\n• CCRS-CLLM refers that CPT-based CRS as-\nsists ChatGLM.\n• BCRS-ALLM refers that BART-based CRS\nassists Chinese-Alpaca.\n• CCRS-ALLM refers that CPT-based CRS as-\nsists Chinese-Alpaca.\nD Evaluation Metrics\nFollowing Liu et al. (2023b), for the pre-sales di-\nalogue understanding and user needs elicitation\ntasks, we set Precision, Recall and F1 score as\nevaluation metrics. Precision is the proportion of\ncorrectly selected tags to the total number of se-\nlected tags. Recall is the ratio of correctly selected\ntags to the original number of correct tags. The F1\nscore is calculated by taking the harmonic mean of\nprecision and recall.\nRegarding the user needs-based recommenda-\ntion task, the evaluation metrics in U-NEED (Liu\net al., 2023b) are Hit@10, Hit@50 and MRR@50.\nDue to the limitation of the input length of LLMs,\nwhere each product contains attributes and attribute\nvalues, we can provide a maximum of 20 candidate\nproducts. Therefore, in order to compare whether\nthe collaborative approach improves the perfor-\nmance of CRSs, we measure Accuracy (Hit@1),\nHit@5 and MRR@5. The Hit@K metric represents\nthe proportion of relevant items that are present in\nthe top-K results out of all the relevant items. The\nMRR@K score is determined by taking the aver-\nage of the reciprocal ranks of the top-K items in\na ranking. If an item does not appear in the top-K\npositions, its reciprocal rank is set to 0.\nThe evaluation metrics for the pre-sales dialogue\ngeneration task are Distinct@1, Informativeness\nand Relevance. Distinct@1 is computed as the av-\nerage of the fraction of distinct 1-grams out of all\n1-grams in a response. Distinct@1 measures the\ndiversity of generated responses. Informativeness\nand relevance are for human evaluation. We ran-\ndomly sample 100 dialogues and we recruit 12 an-\nnotators to evaluate 1400 responses from 14 meth-\nods on these 100 dialogues. Informativeness is\ncalculated as the average informativeness of all gen-\nerated responses. Relevance is determined as the\naverage relevance degree of all generated responses.\nThe annotators evaluate the extent to which a gener-\nated response includes information about the prod-\nuct, as compared to the ground truth. The score\nof informativeness and relevance ranges from 1\nto 5, and we calculate the average score from all\nannotators to obtain the final score.\nE Implementation Details\nWe implement CRSs based on UniMIND. 4 The\ncode is available online. 5 For CRSs, we use a\nNVIDIA A100-SXM4-80GB gpu and train model\nfor 10 epochs, with a duration of approximately 12\nhours. For LLMs, we use a NVIDIA A100-SXM4-\n80GB gpu and train model for 3 epochs, with a\nduration of approximately 9 hours.\nF Examples of Fine-tuning LLMs\nWe give examples of the instructions, inputs, and\noutputs used to fine-tune the LLMs for each task in\nTables 5, 6, 7, and 8, respectively.\nG Examples of Collaborations of CRSs\nand LLMs\nWe show examples of inputs (instructions) for col-\nlaborations between CRSs and LLMs on pre-sales\ndialogue understanding and generation tasks in Fig.\n4 and Fig. 5, respectively.\n4https://github.com/dengyang17/UniMIND\n5https://github.com/LeeeeoLiu/LLM-CRS\n9600\nFigure 4: An example of collaboration between CRS and LLM on the pre-sales dialogue understanding task. Left\nside displays data used to fine-tune a LLM and train a CRS independently. The right side shows two cases of\ncombining the two. Collaboration content is highlighted in red italics.\nFigure 5: An example of collaboration between CRS and LLM on the pre-sales dialogue generation task. Left side\ndisplays data used to fine-tune a LLM and train a CRS independently. The right side shows two cases of combining\nthe two. Collaboration content is highlighted in red italics.\n9601\nTable 5: Three examples of fine-tuning LLMs for pre-sales dialogue understanding task in Appliance, Beauty and\nFashion categories.\nExample Translation\nInstruction 结合大家电行业售前对话，识\n别当前用户或者客服输入中涉\n及的商品相关的属性值和对应\n的属性。针对用户输入，需要\n识别出属性和属性值。客服输\n入中属性值可能为空。\nCombined with the pre-sales dialogue in Appliance\ncategory, identify the product-related attribute values\nand corresponding attributes involved in the input of\nthe current user or customer service. For user input,\nattributes and attribute values need to be identified.\nThe attribute value in the customer service input may\nbe empty.\nInput 售前对话：用户：帮我推荐一\n款普通洗衣机，性价比高，皮\n实耐用的，不要烘干功能的当\n前输入：客服：波轮还是滚筒\n呢\nPre-sale dialogue: User: Help me recommend an or-\ndinary washing machine with high cost performance,\ndurable leather, and no drying function Current input:\nCustomer service: Wave wheel or drum\nOutput 洗衣机类型：波轮;洗衣机类\n型：滚筒\nwashing machine type: wave wheel; washing machine\ntype: drum\nInstruction 结合美妆行业售前对话，识别\n当前用户或者客服输入中涉及\n的商品相关的属性值和对应的\n属性。针对用户输入，需要识\n别出属性和属性值。客服输入\n中属性值可能为空。\nCombined with the pre-sales dialogue in Beauty cate-\ngory, identify the product-related attribute values and\ncorresponding attributes involved in the input of the\ncurrent user or customer service. For user input, at-\ntributes and attribute values need to be identified. The\nattribute value in the customer service input may be\nempty.\nInput 售前对话：用户：你们店\n有没有套装[SEP]客服：您想\n要什么类型的呢[SEP]用户：\n补 水[SEP]客 服 ： 水 乳 吗亲\n亲[SEP]用 户 ： 嗯 ， 需 要 水\n乳[SEP]客服：亲亲需要祛痘的\n吗[SEP]用户：需要祛痘的 当\n前输入：客服：亲亲是想解决\n红肿痘痘还是闭口的么\nPre-sale dialogue: User: Do you have a set in your\nstore? [SEP] Customer service: What type do you\nwant? [SEP] User: Hydration [SEP] Customer service:\nDo you want milk? Kiss [SEP] User: Well, I need\nwater Milk[SEP]Customer service: Kiss, do you need\nto get rid of acne[SEP]User: Need to get rid of acne\nCurrent input: Customer service: Do you want to solve\nred, swollen, pimples or keep your mouth shut?\nOutput 肌肤问题：红肿痘痘;肌肤问\n题：闭口\nskin problem: redness, swelling and acne; skin prob-\nlem: shut up\nInstruction 结合鞋类行业售前对话，识别\n当前用户或者客服输入中涉及\n的商品相关的属性值和对应的\n属性。针对用户输入，需要识\n别出属性和属性值。客服输入\n中属性值可能为空。\nCombined with the pre-sales dialogue in Fashion cate-\ngory, identify the product-related attribute values and\ncorresponding attributes involved in the input of the\ncurrent user or customer service. For user input, at-\ntributes and attribute values need to be identified. The\nattribute value in the customer service input may be\nempty.\nInput 售前对话：用户：还有没有其\n他款推荐[SEP]客服：要什么材\n质的呢亲爱哒[SEP]用户：就是\n冰丝的那种[SEP]客服：仅发送\n商品链接[SEP]客服：这个是莫\n代尔材质冰丝触感的[SEP]客\n服：仅发送商品链接[SEP]客\n服：这个是冰丝材质的[SEP]用\n户：冬天了穿哪款好点当前输\n入：用户：我儿子就喜欢穿金\n利来这个牌子的\nPre-sale dialogue: User: Do you have any other rec-\nommendations? [SEP] Customer service: What ma-\nterial do you want, dear? [SEP] User: It’s the ice silk\none [SEP] Customer service: Only send product links\n[SEP] Customer service : This is made of modal mate-\nrial with ice silk touch [SEP] Customer service: Only\nsend product links [SEP] Customer service: This is\nmade of ice silk [SEP] User: Which one is better to\nwear in winter Current input: User: My son I like to\nwear the brand of Jinlilai.\nOutput 人群：儿子;品牌：金利来 Crowd: Son; Brand: Goldlion\n9602\nTable 6: Three examples of fine-tuning LLMs for user needs elicitation task in Appliance, Beauty and Fashion\ncategories.\nExample Translation\nInstruction 依据大家电行业售前对话，\n选择一系列的属性，来引导用\n户提供更多关于需求的偏好信\n息。结果中可以包含属性值，\n也可以不包含属性值。\nAccording to the pre-sales dialogue in Appliance cat-\negory, select a series of attributes to guide users to\nprovide more preference information about needs. At-\ntribute values may or may not be included in the result.\nInput 售前对话：用户：帮我推荐一\n款普通洗衣机，性价比高，\n皮实耐用的，不要烘干功能\n的[SEP]客服：波轮还是滚筒\n呢[SEP]用户：滚筒的[SEP]用\n户：功能简单的[SEP]客服：\n仅发送商品链接[SEP]客服：仅\n发送商品链接[SEP]用户：有小\n天鹅的吗[SEP]客服：(1)专属\n净柔洗程序，柔和洗护爱衣，\n独特的全方位按摩，如同手洗\n般轻柔、揉搓间为衣物重塑洁\n净与柔软；(2)95度高温煮洗，\n扫净藏于衣物纤维中的病毒细\n菌，长效杀菌灭毒，99.9%健\n康除菌(3)wifi手机远程控制，\n随时随地，想穿就穿(4)特色羽\n绒服洗，分多段进水，洗涤节\n拍柔和，预防羽绒服漂浮水面\n或破损，洗护均匀，贴心呵\n护(5)BLDC变频电机，脱水更\n快更彻底，洁净少残留[SEP]用\n户：波轮的哪款性价比高？皮\n实耐用\nPre-sale conversation: User: Help me recommend\nan ordinary washing machine with high cost perfor-\nmance, durable leather, and no drying function [SEP]\nCustomer service: Wave wheel or drum [SEP] User:\nDrum [SEP] User: Simple function [SEP] Customer\nservice: Only send product links [SEP] Customer ser-\nvice: Only send product links [SEP] User: Do you\nhave Little Swan? Azimuth massage, as gentle as\nwashing by hand, reshape the cleanliness and softness\nof the clothes between rubbing; (2)Boil and wash at 95\ndegrees high temperature, sweep away the viruses and\nbacteria hidden in the fibers of the clothes, long-term\nsterilization and disinfection, 99.9% healthy steriliza-\ntion (3)Wifi mobile phone remote control , anytime,\nanywhere, you can wear it as you want (4)Wash the\nspecial down jacket, enter the water in multiple stages,\nthe washing cycle is soft, prevent the down jacket\nfrom floating on the water or damage, even washing\nand care, caring (5)BLDC inverter motor, dehydration\nis faster and more thorough, clean and less residue\n[SEP ] User: Which one of the wave wheel is more\ncost-effective? Durable\nOutput 价位 Price\nInstruction 依据美妆行业售前对话，选择\n一系列的属性，来引导用户提\n供更多关于需求的偏好信息。\n结果中可以包含属性值，也可\n以不包含属性值。\nAccording to the pre-sales dialogue in Beauty category,\nselect a series of attributes to guide users to provide\nmore preference information about needs. Attribute\nvalues may or may not be included in the result.\nInput 售前对话：用户：你们店有没\n有套装\nPre-sale dialogue: User: Do you have any suits in your\nstore?\nOutput 功效 Efficacy\nInstruction 依据服装行业售前对话，选择\n一系列的属性，来引导用户提\n供更多关于需求的偏好信息。\n结果中可以包含属性值，也可\n以不包含属性值。\nAccording to the pre-sales dialogue in Fashion cat-\negory, select a series of attributes to guide users to\nprovide more preference information about needs. At-\ntribute values may or may not be included in the result.\nInput 售前对话：用户：还有没有其\n他款推荐\nPre-sale dialogue: User: Do you have any other rec-\nommendations?\nOutput 材质 Material\n9603\nTable 7: An example of fine-tuning LLMs for user needs-based recommendation task in Fashion category.\nExample Translation\nInstruction 根据服装行业售前对话中用户表达\n的需求和偏好信息以及候选商品信\n息，从候选商品A-T中选择最有可\n能满足用户需求、偏好的商品推荐\n给用户。\nAccording to the demand and preference information\nexpressed by the user in the pre-sales dialogue in\nFashion category and the candidate product informa-\ntion, the product that is most likely to meet the user’s\nneeds and preferences is selected from the candidate\nproducts A-T and recommended to the user.\nInput 售前对话：用户：还有没有其他\n款推荐[SEP]客服：要什么材质的\n呢亲爱哒[SEP]用户：就是冰丝的\n那种 各候选商品对应的属性和属\n性值：A的价格区间是高，功能需\n求是舒适，季节是夏，性别是男，\n服装厚度是薄款，材质是冰丝、棉\n质、莫代尔，款式是平角、无痕、\n简单，类目是男平角内裤[SEP]B的\n价格区间是高[SEP]C的价格区间\n是高[SEP]D的价格区间是高，性\n别是男，类目是睡衣/家居服套\n装[SEP]E的价格区间是高[SEP]F的\n价格区间是中，功能需求是保\n暖，季节是秋，性别是女，类目\n是保暖套装[SEP]G的价格区间是\n高[SEP]H的价格区间是高[SEP]I的\n价格区间是高，功能需求是保暖，\n性别是女，服装厚度是薄款，类\n目是保暖套装[SEP]J的价格区间是\n高[SEP]K的价格区间是高[SEP]L的\n价格区间是高[SEP]M的价格区间是\n高[SEP]N的价格区间是高[SEP]O的\n价格区间是高[SEP]P的价格区间是\n高[SEP]Q的价格区间是高[SEP]R的\n价格区间是高[SEP]S的价格区间是\n高[SEP]T的价格区间是高，款式\n是v领，类目是保暖套装\nPre-sale dialogue: User: Do you have any other rec-\nommendations [SEP] Customer service: What ma-\nterial do you want? Dear [SEP] User: It is the kind\nof ice silk The attributes and attribute values corre-\nsponding to each candidate product: A The price\nrange is high, the functional requirement is comfort-\nable, the season is summer, the gender is male, the\nclothing thickness is thin, the material is ice silk, cot-\nton, modal, the style is boxer, no trace, simple, and\nthe category is men’s boxer underwear [SEP] The\nprice range of B is high [SEP] The price range of C is\nhigh [SEP] The price range of D is high, the gender is\nmale, and the category is pajamas/home service sets\n[SEP] The price range of E is high [ The price range\nof SEP]F is medium, the functional requirement is\nto keep warm, the season is autumn, the gender is\nfemale, and the category is thermal suits. The price\nrange of [SEP]G is high. The price range of [SEP]H\nis high.[SEP]I The price range is high, the functional\nrequirement is to keep warm, the gender is female,\nthe clothing thickness is thin, and the category is ther-\nmal suit [SEP]J, the price range is high[SEP]K, the\nprice range is high[SEP]L It is high [SEP] the price\nrange of M is high [SEP] the price range of N is high\n[SEP] the price range of O is high [SEP] the price\nrange of P is high [SEP] the price range of Q is high\n[SEP] The price range of R is high [SEP] the price\nrange of S is high [SEP] the price range of T is high,\nthe style is v-neck, and the category is thermal suit\nOutput A A\n9604\nTable 8: Three examples of fine-tuning LLMs for pre-sales dialogue generation task in Appliance, Beauty and\nFashion categories.\nExample Translation\nInstruction 根据大家电行业售前对话中已获取的信\n息、引导用户需求的属性、满足用户需\n求的商品信息，生成回应用户需求且用\n户容易理解的通俗回复。\nAccording to the information obtained in the pre-sales\ndialogue in Appliance category, the attributes that guide\nthe user’s needs, and the product information that meets\nthe user’s needs, generate a popular reply that responds to\nthe user’s needs and is easy for the user to understand.\nInput 售前对话：用户：帮我推荐一款普通\n洗衣机，性价比高，皮实耐用的，\n不要烘干功能的[SEP]客服：波轮还是\n滚筒呢[SEP]用户：滚筒的[SEP]用户：\n功能简单的[SEP]客服：仅发送商品链\n接[SEP]客服：仅发送商品链接[SEP]用\n户：有小天鹅的吗[SEP]客服：(1)专属净\n柔洗程序，柔和洗护爱衣，独特的全方\n位按摩，如同手洗般轻柔、揉搓间为衣\n物重塑洁净与柔软；(2)95度高温煮洗，\n扫净藏于衣物纤维中的病毒细菌，长效\n杀菌灭毒，99.9%健康除菌(3)wifi手机远\n程控制，随时随地，想穿就穿(4)特色羽\n绒服洗，分多段进水，洗涤节拍柔和，\n预防羽绒服漂浮水面或破损，洗护均\n匀，贴心呵护(5)BLDC变频电机，脱水\n更快更彻底，洁净少残留[SEP]用户：波\n轮的哪款性价比高？皮实耐用已获取\n的用户需求偏好信息：品类：洗衣机、\n功能需求：皮实耐用、不要烘干、功能\n简单、皮实耐用、款式：性价比高、性\n价比高、洗衣机类型：滚筒、波轮、品\n牌：小天鹅引导用户需求的属性：价\n位：\nPre-sale conversation: User: Help me recommend an\nordinary washing machine with high cost performance,\ndurable leather, and no drying function [SEP] Customer\nservice: Wave wheel or drum [SEP] User: Drum [SEP]\nUser: [SEP] Customer service with simple functions: only\nsend product links [SEP] customer service: only send\nproduct links [SEP] user: do you have Little Swan? The\nall-round massage is as gentle as hand washing, and the\nrubbing will reshape the cleanliness and softness of the\nclothes; (2)Boil and wash at 95 degrees high temperature,\nsweep away the virus bacteria hidden in the fibers of the\nclothes, long-term sterilization and disinfection, 99.9%\nhealthy sterilization (3)wifi mobile phone Remote con-\ntrol, you can wear it anytime, anywhere (4)Special down\njacket washing, multi-stage water intake, gentle washing\ncycle, prevent down jacket from floating or damaged, even\nwashing and care, caring (5)BLDC frequency conversion\nmotor, dehydration is faster and more thorough, clean and\nless residue [SEP] User: Which one of the wave wheel\nis more cost-effective? Durable Leather Acquired user\ndemand preference information: category: washing ma-\nchine, functional requirements: durable leather, no drying,\nsimple function, durable leather, style: cost-effective, cost-\neffective, washing machine type: drum, pulsator, brand:\nLittle Swan Attributes to guide user needs: Price:\nOutput 预算多少呢亲 How much is the budget?\nInstruction 根据美妆行业售前对话中已获取的信\n息、引导用户需求的属性、满足用户需\n求的商品信息，生成回应用户需求且用\n户容易理解的通俗回复。\nAccording to the information obtained in the pre-sales\ndialogue in Beauty category, the attributes that guide the\nuser’s needs, and the product information that meets the\nuser’s needs, generate a popular reply that responds to the\nuser’s needs and is easy for the user to understand.\nInput 售前对话：用户：你们店有没有套装已\n获取的用户需求偏好信息：品类：套装\n引导用户需求的属性：功效：\nPre-sales dialogue: User: Do you have suits in your store\nAcquired user demand preference information: Category:\nSet Attributes to guide user needs: Function:\nOutput 您想要什么类型的呢 what type do you want\nInstruction 根据服装行业售前对话中已获取的信\n息、引导用户需求的属性、满足用户需\n求的商品信息，生成回应用户需求且用\n户容易理解的通俗回复。\nAccording to the information obtained in the pre-sales\ndialogue in Fashion category, the attributes that guide the\nuser’s needs, and the product information that meets the\nuser’s needs, generate a popular reply that responds to the\nuser’s needs and is easy for the user to understand.\nInput 售前对话：用户：还有没有其他款推荐\n已获取的用户需求偏好信息：款式：引\n导用户需求的属性：材质：\nPre-sale dialogue: User: Do you have any other recommen-\ndations? Obtained user demand preference information:\nStyle: Attributes that guide user demand: Material:\nOutput 要什么材质的呢亲爱哒 What material do you want dear?\n9605",
  "topic": "Recommender system",
  "concepts": [
    {
      "name": "Recommender system",
      "score": 0.7604587078094482
    },
    {
      "name": "Computer science",
      "score": 0.756492018699646
    },
    {
      "name": "Context (archaeology)",
      "score": 0.6636329889297485
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.6060237884521484
    },
    {
      "name": "E-commerce",
      "score": 0.5843225717544556
    },
    {
      "name": "Representation (politics)",
      "score": 0.5627663135528564
    },
    {
      "name": "Work (physics)",
      "score": 0.4641633629798889
    },
    {
      "name": "Collaborative filtering",
      "score": 0.4479043185710907
    },
    {
      "name": "Natural language processing",
      "score": 0.33448734879493713
    },
    {
      "name": "World Wide Web",
      "score": 0.3306858539581299
    },
    {
      "name": "Knowledge management",
      "score": 0.324951708316803
    },
    {
      "name": "Political science",
      "score": 0.06104561686515808
    },
    {
      "name": "Mechanical engineering",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Politics",
      "score": 0.0
    },
    {
      "name": "Engineering",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I204983213",
      "name": "Harbin Institute of Technology",
      "country": "CN"
    }
  ],
  "cited_by": 9
}