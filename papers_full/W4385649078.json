{
    "title": "MFD: Multi-Feature Detection of LLM-Generated Text",
    "url": "https://openalex.org/W4385649078",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A5100738665",
            "name": "Zhendong Wu",
            "affiliations": [
                "Hangzhou Dianzi University"
            ]
        },
        {
            "id": "https://openalex.org/A5084472313",
            "name": "Hui Xiang",
            "affiliations": [
                "Hangzhou Dianzi University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2963671871",
        "https://openalex.org/W6600586173",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W2951080837",
        "https://openalex.org/W6730126202",
        "https://openalex.org/W6600421821",
        "https://openalex.org/W6848955896",
        "https://openalex.org/W2983040767",
        "https://openalex.org/W2948975009",
        "https://openalex.org/W2981852735",
        "https://openalex.org/W3035390927",
        "https://openalex.org/W4360891421",
        "https://openalex.org/W4297677265",
        "https://openalex.org/W4318351452",
        "https://openalex.org/W4361193535",
        "https://openalex.org/W4317553041",
        "https://openalex.org/W4378771263",
        "https://openalex.org/W3101891351",
        "https://openalex.org/W4327810158",
        "https://openalex.org/W4322718191",
        "https://openalex.org/W2969958763",
        "https://openalex.org/W4318149317",
        "https://openalex.org/W4288089799",
        "https://openalex.org/W2965373594",
        "https://openalex.org/W4288334893",
        "https://openalex.org/W3156309620",
        "https://openalex.org/W4380352302",
        "https://openalex.org/W4380357688",
        "https://openalex.org/W3013843954",
        "https://openalex.org/W4311642023"
    ],
    "abstract": "Abstract With the rapid development of large language models, their powerful capabilities have led to their rapid popularity in society. However, it not only brings great convenience to people’s life and work but also provides a favorable tool for criminals to carry out malicious behaviors. Therefore, to prevent the malicious use of large language models, there is a growing demand for a detector that can efffciently discriminate texts generated by large language models. In this paper, Multi-Feature Detection (MFD), a new zero-shot method, is introduced. MFD comprehensively considers log-likelihood, log-rank, entropy, and LLM-Deviation. LLM-Deviation is a new statistical feature proposed in this paper and has a clear distribution difference between texts generated by LLMs and those written by humans. Experiments show MFD is more effective than the existing zero-shot method. MFD improves the detection performance by 1.02 F1 score on average on the HC3-English dataset. In generalization ability, MFD is also very competitive compared with the existing zero-shot method.",
    "full_text": "MFD: Multi-Feature Detection of LLM-Generated\nText\nZhendong Wu  (  wzd@hdu.edu.cn )\nHangzhou Dianzi University\nHui Xiang \nHangzhou Dianzi University\nArticle\nKeywords:\nPosted Date: August 9th, 2023\nDOI: https://doi.org/10.21203/rs.3.rs-3226684/v1\nLicense:   This work is licensed under a Creative Commons Attribution 4.0 International License.  \nRead Full License\nAdditional Declarations: No competing interests reported.\nMFD: Multi-Feature Detection of LLM-Generated Text\nHui Xiang1 and Zhendong Wu1,*\n1 Hangzhou Dianzi University , Hangzhou, China\n* wzd@hdu.edu.cn\nABSTRACT\nWith the rapid development of large language models, their powerful capabilities have led to their rapid popularity in society .\nHowever, it not only brings great convenience to people’s life and work but also provides a favorable tool for criminals to carry\nout malicious behaviors. Therefore, to prevent the malicious use of large language models, there is a growing demand for a\ndetector that can efﬁciently discriminate texts generated by large language models. In this paper, Multi-Feature Detection (MFD),\na new zero-shot method, is introduced. MFD comprehensively considers log-likelihood, log-rank, entropy , and LLM-Deviation.\nLLM-Deviation is a new statistical feature proposed in this paper and has a clear distribution difference between texts generated\nby LLMs and those written by humans. Experiments show MFD is more effective than the existing zero-shot method. MFD\nimproves the detection performance by 1.02 F1 score on average on the HC3-English dataset. In generalization ability , MFD is\nalso very competitive compared with the existing zero-shot method.\nIntroduction\nIn recent years, large language models (LLMs) are developing rapidly . LLMs such as ChatGPT 1 , LLaMa 2 , and BLOOM 3 have\nshown powerful capabilities in dialogue generating, question answering, information retrieval, content continuation, literature\nauthoring, etc. They also can generate code, debug code, and generate comments for code. The recently released GPT -4 4 not\nonly achieves further improvements in performance on various tasks of natural language processing but also is a multi-modal\nmodel. The emergence of large language models has had an impact and inﬂuence on human society .\nHowever, misuse of LLMs can lead to many negative consequences. Firstly , LLMs occasionally exhibit various undesirable\nbehaviors. For instance, LLMs may copy harmful or biased content or produce so-called hallucinating outputs by fabricating\nnon-existent or false facts. Secondly , users may use it for unethical purposes. For example, students can use LLMs to complete\npapers and assignments, and malicious actors can use LLMs to generate spam, fake news, and fake reviews 5 . So, the misuse of\nLLMs is harmful to education and society 6 .\nT o solve the above problems, previous researchers designed many detection methods to discriminate between LLM-\ngenerated texts and human-written texts. The existing detection methods can fall into three categories: the PLM-based methods,\nthe feature-based methods, and the LLM-based methods. PLM-based methods 6– 10 mainly distinguish LLM-generated texts\nfrom human-written texts by ﬁne-tuning the encoder-only pre-trained models (PLMs), such as BERT 11 , RoBERT a12 , etc.\nFeature-based methods 6, 13– 16 distinguish based on the distribution difference of a statistical feature between LLM-generated\ntext and human-written text, such as perplexity , log-likelihood, rank, entropy , negative curvature, and so on. LLM-based\nmethods\n17– 20 can distinguish by watermarking the text generated by LLMs or recording all the text generated by LLMs for\nretrieval.\nEach of these three category of methods has its advantages and disadvantages. Although PLM-based methods can achieve\ngood performance, ﬁne-tuning the pre-trained model to ensure its high performance is often necessary for each new LLM or\nnew dataset, which is expensive. LLM-based methods are only feasible for LLM developers, not for third parties. Feature-based\nmethods, also known as zero-shot methods, require no additional ﬁne-tuning of the pre-trained model and support third-party\nimplementations. However, the statistical features are calculated based on the probability distribution of tokens. The LLM that\ncan access the probability distribution of tokens names the white-box model, otherwise the black-box model. Thus feature-based\nmethods are mainly applicable to the white-box model. While for the black-box model, a conventional approach is using the\nwhite-box model as a proxy model.\nTherefore, this paper mainly considers methods based on statistical features and introduces a new zero-shot method called\nMulti-Feature Detection (MFD). MFD comprehensively considers log-likelihood, log-rank, entropy , and LLM-Deviation,\nand uses the neural network model as the classiﬁcation model. Experiments show MFD effectively improves the detection\nperformance. LLM-Deviation is a new statistical feature introduced in this paper, which can measure the difference between the\ndetected text and the text generated by the LLMs in the ideal state. There is a clear distribution difference in LLM-Deviation\nbetween LLM-generated texts and human-written texts. About experiments, the in-domain and out-of-domain tests are\nperformed on ﬁve datasets (ﬁnance, medicine, open_qa, reddit_eli5, and wiki_csai) contained in HC3-English 7 . In addition,\nout-of-domain tests are also conducted on three datasets (TruthfulQA, SQuAD1, NarrativeQA) used by He et al. (2023) 8 .\nFinally , to further analyze several factors that determine the detection performance of MFD, some ablation studies are carried\nout. All experiments are performed on MGTBench 8 .\nIn summary , our contributions are as follows:\n• Multi-Feature Detection (MFD), a new zero-shot method, is introduced. MFD is more accurate in detecting LLM-\ngenerated text than SOT A in the existing zero-shot method. On the HC3-English dataset, the detection performance is\nincreased by 1.02 F1 score on average.\n• LLM-Deviation, a new statistical feature, is proposed. LLM-Deviation has a clear distribution difference between texts\ngenerated by LLMs and texts written by humans. LLM-generated texts typically have smaller LLM-Deviation than\nhuman-written texts.\n• Evaluating the generalization ability of MFD, the result shows MFD’s generalization ability is also competitive with\nexisting zero-shot methods.\n• What factors can determine the detection performance of MFD is analyzed through ablation studies.\nRelated Work\nThe LLM-generated text detection problem is usually regarded as a binary classiﬁcation problem. The existing detection\nmethods can fall into three categories: the PLM-based methods, the feature-based methods, and the LLM-based methods.\nPLM-based methods ﬁne-tune the pre-trained model through supervised learning to detect the text generated by LLMs. The\ntraining dataset consists of LLM-generated text and human-written text. Solaiman et al. (2019) 6 developed a GPT -2 Detector by\nﬁne-tuning RoBER T a to detect text generated by GPT -2. The training set consists of texts generated by GPT -2 and those written\nby humans. Guo et al. (2023) 7 built the HC3 dataset, which contains text generated by ChatGPT and text written by humans,\nand used this dataset to ﬁne-tune RoBERT a to develop the ChatGPT Detector. He et al. (2023) 8 developed an LM Detector\nobtained by ﬁne-tuning BERT . The dataset used for ﬁne-tuning contains three question-answering datasets, each containing\ngenerated text from six LLMs and text written by humans. According to the different characteristics of long and short texts,\nTian et al. (2023) 9 proposed a Multiscale Positive-Unlabeled (MPU) training framework based on Positive-Unlabeled (PU)\nlearning. This framework mainly ﬁne-tunes the pre-trained model by transforming the detection problem of LLM-generated\ntext into a partial PU learning problem. Antoun et al. (2023) 10 ﬁne-tuned the XLM-R 21 (a multi-lingual RoBERT a model)\nwith the translated HC3-English dataset to develop a multi-language ChatGPT detector. The detector with ﬁne-tuning of the\npre-trained model has good performance. However, Bakhtin et al. (2019) 22 ; Uchendu et al. (2020) 23 pointed out that detectors\nobtained by ﬁne-tuning pre-trained models tend to overﬁt their in-domain datasets or source models. Therefore, ﬁne-tuning a\nnew detector is usually indispensable for achieving high detection performance in each new dataset or LLM.\nFeature-based methods mainly discriminate between LLM-generated and human-written texts by the distribution difference\nof statistical features. Firstly , the text is input into LLM to obtain the corresponding statistical features. Then these statistical\nfeatures are used to train a detector. Gehrmann et al. (2019) 14 proposed the statistical features can be the probability of each\nword in the text, the absolute rank of the probability of each word, or the entropy of the predicted distribution of words at each\nposition, and developed a visualization tool for the probability distribution, rank distribution and entropy distribution of text\nwords to help humans detect the text generated by LLMs. Mitchell et al. (2023) 15 proposed a hypothesis: the log-likelihood of\ntext generated by LLMs after a small amount of rewriting will tend to be lower than the original text, while human-written text\ncan be higher or lower than the original text. And DetectorGPT was built based on this assumption. Su et al. (2023) 16 proposed\ntwo new zero-shot methods. One, DetectLLM-LRR, uses the Log-Likelihood Log-Rank Ratio as a statistical feature. The other\none, DetectLLM-NPR, is based on DetectGPT and uses log-rank instead of log-likelihood.\nLLM-based methods must access the model architecture of LLMs, so only LLM developers can implement it, and it is not\nfeasible for third parties. Abdelnabi and Fritz (2021) 17 proposed the Adversarial W atermarking Transformer (A WT), which is\nan end-to-end model that encodes information by learning word substitutions and their positions, thus hiding watermarks in the\ntext. Grinbaum and Adomaitis (2022) 18 proposed to use a code based on equidistant letter sequences to watermark the text\ngenerated by LLMs. Kirchenbauer et al. (2023) 19 proposed to generate watermarked text by using \"green\" tokens as much\nas possible during the sampling process. These \"green\" tokens are randomly selected before LLMs generate each word. In\naddition to watermarking techniques, Krishna et al. (2023) 20 proposed to have the LLMs record each generated text and store it\nin a database. If there is a text in the database whose semantic similarity with the detected text exceeds the threshold, it means\nthe detected text is the text generated by the LLMs.\n2/10\nFigure 1. The overview of MFD.\nA Robust LLM-generated Text Detection Method – Multi-Feature Detection\nIn general, every LLM designed and trained by the developer has a certain style of text. These styles can be learned by text\nstatistical feature analysis, and then recognized by lightweight detection models. Previous zero-shot methods usually consider\nonly one statistical feature, such as perplexity , probability , rank, and entropy 6, 14, 15 . Even for the latest zero-shot method,\nDetectLLM-LRR16 , researchers deﬁne the connection between probability and rank by themselves and integrate these two\nstatistical features into one statistical feature. Therefore, the previous zero-shot methods are vulnerable to statistical feature\ndistribution shifts. Given the above phenomenon, inspired by ensemble learning, this paper proposes multi-feature detection.\nMulti-feature detection can be more robust than single-feature detection because even if one of the statistical features has\na distribution shift problem, the other statistical features can compensate for the problem. At the same time, there must be\nconnections among various statistical features, which makes multi-feature detection have better detection performance than\nsingle-feature detection. The connections are not easily discoverable and represented, but neural network models can learn\ndeeper connections between statistical features, which are relatively stable and not easily disturbed. In summary , the multi-\nfeature detector obtained by learning the deep statistical features of the text can take more accurate and robust LLM-generated\ntext detection performance. Based on the above motivation, Multi-Feature Detection (MFD), a new zero-shot method, is\nintroduced in this section. And the speciﬁc design of MFD is as follows.\nMulti-Feature Detection\nSpeciﬁcally , MFD can fall into two modules: input features and classiﬁcation model.\nRegarding input features, the features should show differences between LLM-generated and human-written texts. Previous\nstudies have found distributional differences in log-likelihood, log-rank, and entropy between texts generated by LLMs and\nthose written by humans. LLM-generated texts generally have higher log-likelihood, smaller log-rank, and lower entropy\nthan human-written texts. Therefore, MFD uses log-likelihood, log-rank, entropy , and LLM-Deviation as input features.\nLLM-Deviation is a new statistical feature proposed in this paper and described in the LLM-Deviation subsection. The\nlog-likelihood, log-rank, and entropy follow the setting of previous works 6, 14, 15 . The log-likelihood is deﬁned as\nlog likelihood = 1\nt\nt\n∑\ni=1\nlog pθ (xi |x<i ), (1)\nthe log-rank is deﬁned as\nlog rank = 1\nt\nt\n∑\ni=1\nlog rθ (xi |x<i ), (2)\n3/10\nFigure 2. LLM-Deviation distribution plots of texts of ﬁve datasets in HC3-English.\nthe entropy is deﬁned as\nent ro py= − 1\nt\nt\n∑\ni=1\n∑\nw\npθ (xi = w|x<i )log pθ (xi = w|x<i ), (3)\nwhere pθ (xi |x<i ) denotes the probability of token xi , rθ (xi |x<i ) ≥ 1 denotes the absolute rank of probability of token xi , both\nare calculated by LLM according tokens before position i of text X = (x1 ,x2 ,. . . ,xt ). Since the source of the detected text\nis uncertain, and many LLMs are black-box models, a white-box model is usually used as the proxy model to compute the\nstatistical features of the detected text. While among all white-box models, GPT -2 is not very large in scale and can be deployed\non the local computer. Therefore, MFD uses GPT -2 as the proxy model to calculate the four statistical features.\nRegarding the classiﬁcation model, the neural network model is selected as the classiﬁcation model because neural network\nmodels can ﬁnd and describe the connections among statistical features better than machine learning classiﬁcation models. The\nlarger the neural network model scale, the more expensive it is to train. In the case of a small number of input features, there is\nno need to design too deep a neural network model. Therefore, the number of neurons in the hidden layer is limited to 4,8,16,\nand the number of layers of the hidden layer is limited in the range between 1 and 4. After conducting a series of experiments,\nMFD’s classiﬁcation model uses a 5-layer neural network model for trading off the performance and time of the detector. The\nneural network model consists of one input layer, three hidden layers, and one output layer. The input layer is composed of 4\nneurons. Each hidden layer is composed of 16 neurons and ReLU activation functions. And the ﬁnal output layer is composed\nof 1 neuron and Sigmoid activation functions.\nT o sum up, MFD uses log-likelihood, log-rank, entropy , and LLM-Deviation as input features and uses a neural network\nas the classiﬁcation model. MFD ﬁrst uses GPT -2 as a proxy model to calculate four statistical features of the detected texts\n(log-likelihood, log-rank, entropy , and LLM-Deviation). Then the four statistical features are input into the neural network\nmodel and go through three hidden layers. Finally , the output layer outputs the probability that the detected text is text generated\nby LLMs. The detected text is LLM-generated if the output probability is above 0.5, else human-written. See Figure 1 for an\noverview of MFD. In the Experiment section, the results show MFD is a better detection method than the existing zero-shot\nmethods.\n4/10\nLLM-Deviation\nLLM-Deviation is deﬁned as\nLLM Deviat ion= 1\nt\nt\n∑\ni=1\n(log rθ (xi |x<i ))2 , (4)\nwhere rθ (xi |x<i ) ≥ 1 denotes the absolute rank of probability of token xi , which calculated by LLM according tokens before\nposition i of text X = (x1 ,x2 ,. . . ,xt ).\nThe output tokens of LLMs in the ideal case all have the smallest rank, then the average log-rank of the text is 0. Therefore,\nLLM-Deviation represents the variance of the log-rank of the detected text tokens in case enforcing zero as the mean, which\ncan evaluate the deviation of the detected text and the text generated by the LLMs in the ideal state. In general, LLM-Deviation\nof the LLM-generated texts is smaller than the human-written texts, as shown in Figure\n2. Thus, LLM-Deviation can be used as\na statistical feature to distinguish texts generated by LLMs from texts written by humans.\nExperiment\nIn this section, the experimental setting is described ﬁrst. Then, the evaluation results and ablation studies are analyzed.\nDatasets & Metrics\nThe experimental dataset is HC3-English from the Human ChatGPT Comparison Corpus (HC3) 7 . HC3-English contains ﬁve\ndatasets: ﬁnance, medicine, open_qa, reddit_eli5, and wiki_csai. Each dataset consists of questions, human responses, and\nChatGPT responses. When performing in-domain tests on each dataset, the training set consists of 80% of the dataset, and the\ntest set consists of the remaining 20%. While performing out-of-domain tests on each dataset, the training set consists of 80%\nof the dataset, and the test set consists of 20% of every dataset in other four datasets. In addition, out-of-domain tests are also\nconducted on the three datasets used by He et al. (2023) 8 , namely TruthfulQA, SQuAD1, and NarrativeQA.\nFollowing previous works (Gehrmann et al., 2019 14 ; Mitchell et al., 2023 15 ), the metric to measure the performance of the\ndetector is the F1 score. A greater F1 score indicates a better performance of the detector.\nZero-Shot Methods\nThe following zero-shot methods are used as baseline models:\nLog Likelihood: First, this method uses an LLM to calculate the probability of each token xi in the text X = (x1 ,x2 ,. . . ,xt ),\nthen uses the average log-probability of each token in the text as a statistical feature. This value is larger, and the probability\nthat the detected text is LLM-generated text is higher.\nLog Rank: According to the probability distribution of each token in detected text X = (x1 ,x2 ,. . . ,xt ), the absolute rank of\neach token can be calculated. This method uses the average log-rank of each token in the detected text as a statistical feature.\nThis value is smaller, and the probability that the detected text is LLM-generated text is higher.\nEntropy: The average entropy of the probability distribution of each token in the detected text is used as the statistical\nfeature. The smaller this value is, the higher the probability .\nGL TR: The rank of each token in the detected text is ﬁrst obtained. Then all tokens in the detected text are divided into four\ngroups according to their rank with 10, 100, and 1000 as boundaries. Finally , the percentage of the number of tokens contained\nin these four groups is taken as a set of statistical features. This set of statistical features is used as input to a classiﬁer, which\noutputs the probability that the detected text is a text generated by LLMs.\nDetectGPT : Firstly , the perturbation model generates several perturbed texts of the detected text. The average difference\nbetween the log probabilities of the original text and several perturbed texts is then measured and perceived as a statistical\nfeature.\nDetectLLM-LRR: In this method, the statistical feature is the Log-Likelihood Log-Rank Ratio of the detected text.\nExperimental Details\nFollowing previous works, the binary classiﬁcation model is the logistic regression model. However, due to resource constraints,\nGPT2-medium is selected as the LLM for computing the probability distribution for each token in the text, and the maximum\ntoken length of the text is limited to 512. For DetectGPT , the perturbation model is T5-large 24 , and the maximum number of\nperturbed texts is 10. In addition, we ﬁnd the two detectors built by Su et al. (2023) 16 , DetectLLM-LRR and DetectLLM-NPR,\nhave the problem of zero denominator, so add a smoothing term ε = 10− 8 to the denominator when using Detect-LRR as the\nbaseline model.\n5/10\nT able 1. In-domain tests. Comparison of MFD to other zero-shot method baselines in terms of F1 score. Bold indicates the\nbest results between different methods.\nMethod ﬁnance medicine open_qa reddit_eli5 wiki_csai average\nLog Likelihood 97.59 99.40 94.09 98.53 95.91 97.10\nLog Rank 97.34 99.40 95.28 98.44 96.49 97.39\nEntropy 93.62 96.59 88.57 93.14 79.27 90.24\nGL TR 97.47 99.00 94.97 98.34 95.98 97.15\nDetectGPT 83.92 90.24 57.14 89.20 87.03 81.51\nDetectLLM-LRR 96.69 98.58 95.44 97.82 95.58 96.82\nMFD(ours) 98.60 99.60 97.07 99.40 97.39 98.41\nFigure 3. The left plot represents the proportion of texts in the dataset that are longer than 512. The right plot represents the\nnumber of texts in the dataset.\nEvaluation Results\nIn-Domain\nT able 1 shows the comparison results of MFD and the six zero-shot methods introduced above on each of the ﬁve in-domain\ndatasets. It can be seen MFD achieves the best performance on all ﬁve datasets. The average performance of MFD is 1.02 F1\nscore higher than the SOT A of the existing zero-shot methods. In addition, all zero-shot methods achieve the best performance\non the medicine dataset. And, except for entropy , the other methods achieve the worst performance on the open_qa dataset.\nThrough analyzing the datasets, the result shown in Figure 3, we guess it is because the proportion of texts that are more than\n512 tokens in the medicine dataset is the smallest among datasets of similar size, while open_qa is the largest. Moreover,\nalthough the proportion of texts that are more than 512 tokens in the reddit_eli5 dataset is the largest among all datasets, due to\nthe largest dataset size leads to the largest amount of data used for training, which makes up for this problem to a certain extent.\nThus almost all zero-shot methods achieve the second-best performance on the reddit_eli5.\nOut-of-Domain\nT o evaluate the generalization ability of MFD, MFD compares with the above six zero-shot methods on out-of-domain datasets.\nThe results are shown in T able 2. The performance of MFD on out-of-domain datasets is very competitive compared with the\nexisting zero-shot methods. Whether the training set is ﬁnance or medicine, MFD obtains the best average performance on the\nout-of-domain datasets. In addition, detectors trained on different datasets may have different transferability to other datasets.\nThis ﬁnding suggests the choice of the dataset used to train inﬂuences the detector generalization ability . An interesting ﬁnding\nis that detector trained on the B dataset may has better performance on the A dataset than the detector trained on the A dataset.\nFor example, the Entropy detector trained in ﬁnance, reddit_eli5, or wiki_csai dataset has better detection performance on the\nmedicine test set than the Entropy detector trained in the medicine dataset. The speciﬁc reasons can be further explored.\nT o further investigate the generalization ability of the zero-shot methods, all the zero-shot methods are ﬁrst trained on the\n6/10\nT able 2. Out-of-domain tests. Comparison of MFD to other zero-shot method baselines in terms of F1 score. Bold indicates\nthe best results between different methods.\nT rain T est Log Likelihood Log Rank Entropy GL TR DetectGPT DetectLLM-LRR MFD(ours)\nﬁnance\nmedicine 99.19 98.99 96.93 98.17 90.50 93.59 98.59\nopen_qa 90.29 91.51 86.88 89.77 55.53 95.53 91.12\nreddit_eli5 98.65 98.59 88.65 98.26 89.81 97.70 99.06\nwiki_csai 94.32 95.40 79.55 94.62 83.46 95.55 95.70\naverage 95.61 96.12 88.00 95.21 79.83 95.59 96.12\nmedicine\nﬁnance 95.67 94.61 92.50 94.51 84.41 92.51 97.49\nopen_qa 86.50 87.13 85.71 87.13 55.98 91.33 88.27\nreddit_eli5 97.91 96.79 92.08 97.30 89.54 94.30 98.65\nwiki_csai 90.57 90.08 80.31 89.60 84.60 93.33 94.35\naverage 92.66 92.15 87.65 92.13 78.63 92.87 94.69\nopen_qa\nﬁnance 95.91 96.93 87.48 97.95 82.23 94.74 95.63\nmedicine 92.21 92.21 85.25 97.53 88.55 81.71 90.07\nreddit_eli5 89.38 93.28 63.84 96.66 88.03 93.91 87.69\nwiki_csai 92.83 93.83 61.78 96.12 80.49 91.77 90.51\naverage 92.58 94.06 74.59 97.06 84.83 90.53 90.97\nreddit_eli5\nﬁnance 97.05 97.10 91.65 97.05 83.56 97.03 98.04\nmedicine 99.60 99.39 96.84 98.79 88.43 94.94 97.61\nopen_qa 89.27 90.63 83.75 89.27 51.49 95.55 83.24\nwiki_csai 93.58 94.59 79.01 94.08 83.64 95.60 96.83\naverage 94.87 95.43 87.81 94.80 76.78 95.78 93.93\nwiki_csai\nﬁnance 97.94 97.83 93.59 97.71 74.05 96.70 97.72\nmedicine 97.95 97.74 97.13 98.16 80.48 93.82 97.14\nopen_qa 92.16 93.68 87.64 91.68 40.38 95.33 88.45\nreddit_eli5 97.15 98.26 85.97 97.99 81.37 97.78 98.62\naverage 96.30 96.88 91.08 96.39 69.06 95.91 95.48\nT able 3. Out-of-domain tests. All zero-shot methods are trained on ﬁnance and then transferred to TruthfulQA, SQuAD1, and\nNarrativeQA. The evaluation metric is the F1 score.\nT est Log Likelihood Log Rank Entropy GL TR DetectGPT DetectLLM-LRR MFD(ours)\nTruthfulQA 80.00 77.74 50.69 79.58 76.12 66.93 82.28\nSQuAD1 6.76 5.48 7.95 13.41 20.78 5.19 6.63\nNarrativeQA 3.80 3.80 0 4.88 26.82 1.12 9.38\nﬁnance dataset and then transferred to the three datasets used by He et al. (2023) 8 : TruthfulQA, SQuAD1, and NarrativeQA.\nT able 3 shows all zero-shot methods perform poorly on SQuAD1 and NarrativeQA. This ﬁnding suggests none of these zero-shot\nmethods are truly universal detectors. W e believe the inherent distribution differences among different types of datasets, the\ndifferences that may exist in text generation rules among different LLMs, and the differences in additional conditions when the\nsame LLM generates text make developing a general detector very difﬁcult.\nAblation Studies\nT o explore the components that affect the performance of MFD, the possible effect caused by different choices of the\nclassiﬁcation model is analyzed ﬁrst. Then, the possible effect caused by the composition of input features of the classiﬁcation\nmodel is analyzed.\nDeep Learning or Machine Learning\nBy evaluating the detection performances of the two different MFDs, the effect that may result from different choices of the\nclassiﬁcation model is analyzed. One uses the logistic regression model from machine learning as the classiﬁcation model,\ncalled MFD, and the another uses the neural network model from deep learning, called MFD-M. T able\n4 shows the MFD\nperformed the best on all ﬁve datasets. The average performance of MFD on ﬁve datasets is 0.65 F1 score better than MFD-M.\nBecause the logistic regression model represents a linear relationship, while the neural network model represents a nonlinear\n7/10\nT able 4. The F1 score of detection performance of detectors using two different classiﬁcation models. Bold indicates the best\nresults between different methods.\nMethod ﬁnance medicine open_qa reddit_eli5 wiki_csai average\nMFD-M 98.10 99.20 95.45 98.95 97.09 97.76\nMFD 98.60 99.60 97.07 99.40 97.39 98.41\nT able 5. A verage F1 score on the HC3-English dataset. The best performance is indicated in bold.\nFeature HC3-English average F1 scorelog-likelihood log-rank entropy LLM-Deviation\n/enc-33/enc-37/enc-37/enc-37 96.86\n/enc-37/enc-33/enc-37/enc-37 97.15\n/enc-37/enc-37/enc-33/enc-37 90.42\n/enc-33/enc-33/enc-37/enc-37 97.47\n/enc-33/enc-37/enc-33/enc-37 98.04\n/enc-37/enc-33/enc-33/enc-37 98.06\n/enc-33/enc-33/enc-33/enc-37 98.37\n/enc-33/enc-33/enc-33/enc-33 98.41\nrelationship, the relationships among the statistical features log-likelihood, log-rank, entropy , and LLM-Deviation are more\nlikely nonlinear. And the use of a neural network model can better capture the nonlinear characteristics among them.\nFeatures\nBy removing part input features of MFD, then measuring the average performance of MFD in the ﬁve datasets, whether three\ninput features of MFD (log-likelihood, log-rank, and entropy) are all necessary can be analyzed. T able 5 shows the results.\nRemoving either of the three statistical features reduces the detection performance of MFD. And the performance of removing\nany two statistical features is worse than the performance of removing any one statistical feature. Therefore, these several\nstatistical features can complement each other. And the detection performance of MFD can achieve the best only when these\nseveral statistical features are all present. In addition, removing entropy has a prominent impact on the detection performance\nof MFD. The log-likelihood and entropy ensemble and the log-rank and entropy ensemble improve performance better than the\nlog-likelihood and log-rank ensemble. Because log-rank is essentially the same as log-likelihood, both are based on a general\nrule of LLMs to generate text–select tokens with high probability as outputs, while entropy is according to the entire probability\ndistribution. But there is still a difference between log-likelihood and log-rank. The log-likelihood is based on probability ,\nwhile the log-rank on rank. Even for the same rank, it is possible to have different probabilities. Similarly , with the same\nprobability , it is possible to have different ranks. So the composition of log-likelihood and log-rank is also beneﬁcial to improve\nperformance.\nThen, to analyze whether LLM-Deviation, the custom statistical feature, plays a role in MFD, MFD with and without\nLLM-Deviation are evaluated on the HC3-English dataset in the average performances. The last two columns of T able 5 show\nthat LLM-Deviation is effective in improving the performance of MFD. The average detection performance of MFD with\nLLM-Deviation as an input feature in ﬁve datasets is 0.04 F1 score better than the MFD without LLM-Deviation as an input\nfeature.\nConclusion\nIn this paper, Multi-Feature Detection (MFD), a new zero-shot method, is introduced. MFD takes four statistical features,\nlog-likelihood, log-rank, entropy , and LLM-Deviation, into account and uses the neural network model as the classiﬁcation\nmodel. Among these statistical features, LLM-Deviation is a new statistical feature proposed in this paper, which has a clear\ndistribution difference between texts generated by LLMs and those written by humans. T exts generated by LLMs often have\nsmaller LLM-Deviation than texts written by humans. Experiments show MFD achieves state-of-the-art performance on the\nHC3-English dataset. In generalization ability , MFD is also competitive compared with existing zero-shot methods. Moreover,\nthe relationships among log-likelihood, log-rank, entropy , and LLM-Deviation are more likely nonlinear. And these statistical\nfeatures complement each other and are all necessary for MFD to perform at its best.\n8/10\nLimitations\nDue to the inherent distribution differences among different types of datasets, the differences that may exist in text generation\nrules among different LLMs, and the differences in additional conditions when the same LLM generates text, developing a\ngeneral detector is extremely difﬁcult. However, training a new detector for each case is expensive. Therefore, in the future, the\ngeneralization ability of the detector is an issue to be further solved.\nData availability\nThe datasets generated during and/or analyzed during the current study are available from the corresponding author on\nreasonable request.\nReferences\n1. OpenAI. Chatgpt: Optimizing language models for dialogue. https://openai.casa/blog/chatgpt/ (2022).\n2. T ouvron, H. et al. Llama: Open and efﬁcient foundation language models. arXiv preprint arXiv:2302.13971 (2023).\n3. Scao, T . L. et al. Bloom: A 176b-parameter open-access multilingual language model. arXiv preprint arXiv:2211.05100\n(2022).\n4. OpenAI. Gpt-4 technical report. ArXiv abs/2303.08774 (2023).\n5. Adelani, D. I. et al. Generating sentiment-preserving fake online reviews using neural language models and their human-and\nmachine-based detection. In Advanced Information Networking and Applications: Proceedings of the 34th International\nConference on Advanced Information Networking and Applications (AINA-2020), 1341–1354 (Springer, 2020).\n6. Solaiman, I. et al. Release strategies and the social impacts of language models. arXiv preprint arXiv:1908.09203 (2019).\n7. Guo, B. et al. How close is chatgpt to human experts? comparison corpus, evaluation, and detection. arXiv preprint\narXiv:2301.07597 (2023).\n8. He, X., Shen, X., Chen, Z., Backes, M. & Zhang, Y . Mgtbench: Benchmarking machine-generated text detection. arXiv\npreprint arXiv:2303.14822 (2023).\n9. Tian, Y . et al. Multiscale positive-unlabeled detection of ai-generated texts. arXiv preprint arXiv:2305.18149 (2023).\n10. Antoun, W ., Mouilleron, V ., Sagot, B. & Seddah, D. T owards a robust detection of language model generated text: Is\nchatgpt that easy to detect? ArXiv abs/2306.05871 (2023).\n11. Devlin, J., Chang, M.-W ., Lee, K. & T outanova, K. BERT: Pre-training of deep bidirectional transformers for language\nunderstanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational\nLinguistics: Human Language T echnologies, V olume 1 (Long and Short P apers), 4171–4186, DOI: 10.18653/v1/N19-1423\n(Association for Computational Linguistics, Minneapolis, Minnesota, 2019).\n12. Liu, Y . et al. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692 (2019).\n13. Tian, E. Gptzero. https://gptzero.me/faq (2022).\n14. Gehrmann, S., Strobelt, H. & Rush, A. GL TR: Statistical detection and visualization of generated text. In Proceedings\nof the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations , 111–116, DOI:\n10.18653/v1/P19-3019 (Association for Computational Linguistics, Florence, Italy , 2019).\n15. Mitchell, E., Lee, Y ., Khazatsky , A., Manning, C. D. & Finn, C. Detectgpt: Zero-shot machine-generated text detection\nusing probability curvature. arXiv preprint arXiv:2301.11305 (2023).\n16. Su, J., Zhuo, T . Y ., W ang, D. & Nakov , P . Detectllm: Leveraging log rank information for zero-shot detection of\nmachine-generated text. arXiv preprint arXiv:2306.05540 (2023).\n17. Abdelnabi, S. & Fritz, M. Adversarial watermarking transformer: T owards tracing text provenance with data hiding. 2021\nIEEE Symp. on Secur. Priv. (SP) 121–140 (2020).\n18. Grinbaum, A. & Adomaitis, L. The ethical need for watermarks in machine-generated language. ArXiv abs/2209.03118\n(2022).\n19. Kirchenbauer, J. et al. A watermark for large language models. ArXiv abs/2301.10226 (2023).\n20. Krishna, K., Song, Y ., Karpinska, M., Wieting, J. & Iyyer, M. Paraphrasing evades detectors of ai-generated text, but\nretrieval is an effective defense. ArXiv abs/2303.13408 (2023).\n9/10\n21. Conneau, A. et al. Unsupervised cross-lingual representation learning at scale. In Annual Meeting of the Association for\nComputational Linguistics (2019).\n22. Bakhtin, A. et al. Real or fake? learning to discriminate machine from human generated text. ArXiv abs/1906.03351\n(2019).\n23. Uchendu, A., Le, T ., Shu, K. & Lee, D. Authorship attribution for neural text generation. In Proceedings of the 2020\nConference on Empirical Methods in Natural Language Processing (EMNLP) , 8384–8395, DOI: 10.18653/v1/2020.\nemnlp-main.673 (Association for Computational Linguistics, Online, 2020).\n24. Raffel, C. et al. Exploring the limits of transfer learning with a uniﬁed text-to-text transformer. J. Mach. Learn. Res. 21\n(2020).\nAcknowledgements\nThis study is supported by National Natural Science Foundation of China (No. 61772162), Key Projects of NSFC Joint Fund of\nChina (No. U1866209), The Royal Society , International Exchanges 2018 Cost Share (China) Grant (No.IEC \\NSFC\\181300).\nAuthor contributions statement\nAll authors conceived the experiments, H.X. conducted the experiments, All authors analyzed the results. All authors reviewed\nthe manuscript.\nAdditional information\nCompeting interests: The authors declare no competing interests.\n10/10"
}