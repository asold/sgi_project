{
  "title": "Large Language Models in Randomized Controlled Trials Design",
  "url": "https://openalex.org/W4395670097",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2065359256",
      "name": "Nan Liu",
      "affiliations": [
        "Duke-NUS Medical School"
      ]
    },
    {
      "id": "https://openalex.org/A2326964429",
      "name": "Jin Liyuan",
      "affiliations": [
        "Duke-NUS Medical School"
      ]
    },
    {
      "id": "https://openalex.org/A3100970948",
      "name": "Jasmine Chiat Ling Ong",
      "affiliations": [
        "Singapore General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A5094209147",
      "name": "Elangovan Kabilan",
      "affiliations": [
        "Singapore Eye Research Institute",
        "Singapore National Eye Center"
      ]
    },
    {
      "id": "https://openalex.org/A2347612689",
      "name": "Yuhe Ke",
      "affiliations": [
        "Singapore General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A4313225896",
      "name": "Alexandra Pyle",
      "affiliations": [
        "Singapore General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A1994121145",
      "name": "Daniel Ting",
      "affiliations": [
        "Singapore Eye Research Institute",
        "Singapore National Eye Center"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2137813178",
    "https://openalex.org/W3181446845",
    "https://openalex.org/W3110364326",
    "https://openalex.org/W2789816271",
    "https://openalex.org/W2962411443",
    "https://openalex.org/W4392762955",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4386257899",
    "https://openalex.org/W4387597556",
    "https://openalex.org/W4387703131",
    "https://openalex.org/W6853626694",
    "https://openalex.org/W4382182493",
    "https://openalex.org/W4365503932",
    "https://openalex.org/W4380730209",
    "https://openalex.org/W6852868368",
    "https://openalex.org/W4387034825",
    "https://openalex.org/W4385682300",
    "https://openalex.org/W4385374442",
    "https://openalex.org/W4392016947",
    "https://openalex.org/W2032541700",
    "https://openalex.org/W2095674834",
    "https://openalex.org/W2171811563",
    "https://openalex.org/W1931781407",
    "https://openalex.org/W6600548291",
    "https://openalex.org/W6838461927",
    "https://openalex.org/W4294763143",
    "https://openalex.org/W4388608412",
    "https://openalex.org/W4385564201",
    "https://openalex.org/W4385640801",
    "https://openalex.org/W4312107392",
    "https://openalex.org/W4379094566",
    "https://openalex.org/W4283026156",
    "https://openalex.org/W4386794413",
    "https://openalex.org/W4378232928"
  ],
  "abstract": "<title>Abstract</title> We investigate the potential of large language models (LLMs) in enhancing the design of randomized controlled trials (RCTs) to address challenges related to generalizability, recruitment diversity, and failure rates. We selected 20 RCTs for analysis, including both completed and ongoing studies, with a focus on their design aspects such as eligibility criteria, recruitment strategies, interventions, and outcomes measurement. Our evaluation revealed that LLMs can design RCT with 72% overall accuracy. Qualitative assessments indicated that LLM-generated designs were clinically aligned, scoring above 2 on a Likert scale across safety, accuracy, objectivity, pragmatism, inclusivity, and diversity domains. The results highlight LLM's capability to avoid critical safety and ethical issues, suggesting its potential as an assistive tool in RCT design to improve generalizability and reduce failure rates. However, expert oversight and regulatory measures are emphasized as essential to ensure patient safety and ethical conduct in clinical research.",
  "full_text": "Page 1/10\nLarge Language Models in Randomized ControlledTrials Design\nNan Liu  \n \nDuke-NUS Medical School https://orcid.org/0000-0003-3610-4883\nLiyuan Jin \nDuke-NUS Medical School\nJasmine Chiat Ling Ong \nSingapore General Hospital https://orcid.org/0000-0001-6916-5960\nElangovan Kabilan \nSingapore National Eye Centre, Singapore Eye Research Institute\nYuhe Ke \nDepartment of Anesthesiology, Singapore General Hospital, Singapore\nAlexandra Pyle \nSingapore General Hospital\nDaniel Ting \nSingapore Eye Research Institute, Singapore National Eye Centre https://orcid.org/0000-0003-2264-7174\nBrief Communication\nKeywords:\nPosted Date: April 26th, 2024\nDOI: https://doi.org/10.21203/rs.3.rs-4254962/v1\nLicense:     This work is licensed under a Creative Commons Attribution 4.0 International License.   Read Full\nLicense\nAdditional Declarations: There is NO Competing Interest.\nPage 2/10\nAbstract\nWe investigate the potential of large language models (LLMs) in enhancing the design of randomized controlled\ntrials (RCTs) to address challenges related to generalizability, recruitment diversity, and failure rates. We selected\n20 RCTs for analysis, including both completed and ongoing studies, with a focus on their design aspects such as\neligibility criteria, recruitment strategies, interventions, and outcomes measurement. Our evaluation revealed that\nLLMs can design RCT with 72% overall accuracy. Qualitative assessments indicated that LLM-generated designs\nwere clinically aligned, scoring above 2 on a Likert scale across safety, accuracy, objectivity, pragmatism,\ninclusivity, and diversity domains. The results highlight LLM's capability to avoid critical safety and ethical issues,\nsuggesting its potential as an assistive tool in RCT design to improve generalizability and reduce failure rates.\nHowever, expert oversight and regulatory measures are emphasized as essential to ensure patient safety and\nethical conduct in clinical research.\nMain\nRandomized controlled trials (RCT), serve as the backbone of modern evidence-based clinical practice. RCT\nprovides a carefully controlled environment to investigate cause-effect relationships between intervention and\noutcomes. Landmark RCTs often inform clinical practice. However, trial designs face criticisms of poor\ngeneralizability from \u0000xed eligibility criteria1, lack of diversi\u0000cation in recruitment2, and practical implementation\nconcerns1. Patients with complex co-morbidities or late-stage disease excluded from phase III trials fail to bene\u0000t\nfrom breakthrough discoveries in real-world practice. Thus, challenges need to be addressed to maximize the yield\nof each study. High failure rate of clinical trials is a key stumbling block in drug development pipelines. RCTs\nfailure rate has been reported for various reasons3–5, including safety and toxicity concerns, poor accrual and\nrecruitment challenges, logistics, and funding. Of which, a key contributory factor to failure of phase III trials is an\nine\u0000cient patient selection process6. Failure of clinical trials bears signi\u0000cant implications for both drug\ndevelopment companies and patients. Clinical research remains the most expensive and time-consuming process\nof drug development, costing up to a billion dollars of investment and taking more than a decade of work to bring\na new drug into market7. Reform of clinical research is much needed to accelerate this process.\nLarge language models (LLMs) have recently emerged as an e\u0000cient tool in various clinical tasks8 with\ncomparable clinical alignment to human experts9. As a result, LLMs tools are expected to assist clinical practice\nranging from basic healthcare related administrative work 10, educational chatbot for medical knowledge11,12, to\nadvance clinical notes generation13–15, complex clinical cases diagnosis16, and patient triaging17. Recently, there\nis increasing interest in LLM applications in clinical trials18–21. Generative AI introduced new paradigms in drug\ndevelopment, from the design and validation of novel pharmaceutical compounds to eligibility screening of\npatients for clinical trials18–20. These approaches show promise in streamlining clinical research but fail to\naddress problems related to trial design and generalizability of RCTs including eligibility criteria, diversi\u0000cation\nand practicability. RCTs provide the highest level of scienti\u0000c evidence of therapeutic interventions and, their\ndesign requires in-depth clinical understanding and rigorous scienti\u0000c methodologies22–24. In this study, we\nexplore and validate the use of LLMs as a pilot application for e\u0000cient and clinically aligned RCT design, to help\nimprove study generalizability and reduce failure rate.\nPage 3/10\nWe \u0000rst selected GPT-4-Turbo-Preview as LLM in our current study. We then randomly selected 20 parallel-arm\nRCTs (Phase III or IV): 10 completed RCTs, with results published in leading clinical journals (JAMA, Nature\nMedicine, NEJM, and The Lancet); and 10 ongoing RCTs registered on ClinicalTrials.gov. To mitigate the risks of\nLLM’s pretraining utilization on such studies, we used studies published or newly registered after January 2024\n(after GPT-4-Turbo-Preview pretraining date of December 2023). We extracted the respective study designs from\nClinicalTrials.gov (information cross-checked against publication if available), to serve as our ground truth. We\nprovided the LLM with the following inputs: O\u0000cial Titles, Brief Summaries, Study Type, Study Phase, Study\nDesign, Conditions and Intervention/Treatment. We then prompted the LLM for the following outputs: Eligibility\nCriteria (Inclusion and Exclusion Criteria), Recruitment (Sex/Gender and Age), Arm/Intervention (Active and\nControl Arms), and Outcomes Measurement (Measurement design and Measurement time frame).\nWe quantitatively evaluated the accuracy (degree of agreement) of the LLM's outputs by comparing them with the\nclinically de\u0000ned ground truth. We created a qualitative assessment metric to evaluate both LLM and ground truth\ndesigns. This metric comprised of safety, clinical accuracy, objectivity (bias), pragmatic (adapted from PRECIS-2\nguidance)25, inclusivity and diversity (adapted from United States Food and Drug Administration (FDA) draft\nguidance to clinical trial design)2 measured on a three-point Likert Scale (1 is the worst, 3 is the best). For selected\nongoing RCT studies, we performed a blinded qualitative evaluation without knowledge of ground truth designs to\nprovide a more objective analysis.\nOur results showing LLM demonstrated 72% accuracy in overall RCT designs (Fig. 1). Speci\u0000cally, it showed high\nagreement in Recruitment and Arm/Intervention, with accuracy of 88% and 93%, respectively. However, it\ndemonstrated discrepancies in designing Eligibility Criteria and Outcomes Measurement, with accuracy of 55%\nand 53%, respectively. We observed marginal difference in accuracy between LLM outputs and published RCTs\nand ongoing RCTs except improvement in exclusion criteria designs on latest RCTs. We employed statistical\nanalysis using natural language processing (NLP) based methods, including BLEU26, ROGUE-L27 and METEOR28,\nfor corresponding LLM outputs, presented in Supplementary Method eTable 2. Qualitatively, LLM designs\nproduced comparable clinical alignment in RCT design compared to ground truth, with Likert scales scoring\nabove 2 points across all domains (Fig. 2).\nOur \u0000ndings suggest that LLM, represented by GPT-4-Turbo-Preview in this study, can replicate RCT designs with\nreasonable clinical alignment. LLM was able to match RCTs with over 80% accuracy in designing Recruitment\nrequirements and Active/Control Intervention. When assessed qualitatively, we observed marginal difference in\noverall clinical accuracy of LLM design compared with ground truth, highlighting multiple accepted clinical\ndecisions related to RCT design. Upon qualitative analysis, LLM RCT designs closely aligned documented\nconsensus in safe, accurate, and objective domains, while showing enhanced diversity and pragmatism. Notably,\ndiversity and pragmatism are key determinants of LLM generalizability and reasons for RCT failure. Additionally,\nLLM could avoid critical safety and ethical issues identi\u0000ed in the ground truth from the analysis of the selected\nregistered ongoing RCTs.\nRCTs serve key roles in clinical practice, and inclusivity has been heavily emphasized by FDA29 to ensure\nconsistently high-quality design that is scienti\u0000cally justi\u0000able. Current results highlight the potential role in LLM\nfor such an important design principle. Unique attributes of LLM architecture bring distinct advantages over\nconventional deep learning and NLP in text-based comprehension capabilities. General-purpose LLMs like GPT-4\ncan perform tasks with little or no task-speci\u0000c \u0000ne-tuning. Emergent properties set them apart from conventional\nPage 4/10\nmachine learning or deep learning models, simulating clinical reasoning and inferential skills across diverse\ndisciplines30,31. The large knowledge corpus in pre-training dataset of LLMs enabled stochastic responses to\ntasks that are non-deterministic in nature, such as in clinical trial design. Existing clinical trial related LLM studies,\npresented in Table 1, have only focused on preliminary text classi\u0000cation task and are mostly limited to last\ngeneration LLM, such as BERT32. With rapid advancement in LLM development and taking advantage of LLM’s\naccessibility and e\u0000ciency as demonstrated in current study, it holds great promise as an assistive tool for RCT\ndesign. In our quantitative analysis, LLMs could recommend study designs using gold standard control groups\nand appropriate active group intervention. We infer that LLM was capable of recommending most commonly\nused comparator arms for trials of similar nature and discipline; logical deduction of active intervention dosage\nregimen based on pre-clinical or phase I/II published studies captured in its knowledge corpus. Recommended\nexclusion criteria and outcome measurement time frames differed to a greater extent between LLM-designed\ntrials and actual published design. These design elements often vary widely across different studies and\nintervention tested in real-world. Qualitatively, the overall safety and clinical accuracy of these reported\ndifferences was not compromised signi\u0000cantly. Coupled with further tailored RCT designs through prompting with\nLLMs regarding various patient and condition-related concerns, as well as \u0000nancial and pragmatic challenges, the\ncurrent pilot LLM-based RCT framework is expected to improve generalizability, enhance patient recruitment, and\nreduce RCT failure rates.\nExpert oversight remains essential for ensuring patient safety and a nuanced understanding of clinical context.\nPractical considerations such as availability of funding, ease of patient recruitment and alternative trial designs\nsuch as open-label, cross-over or pragmatic trials were not considered in this study. General-purpose LLM used in\nour study is also limited by lack of knowledge on unpublished data from in-house experiments, an important\nconsideration in clinical trial design. Furthermore, careful regulatory measures are required to ensure the safety,\nprivacy, and ethical conduct of RCTs.\nMethods\nDataset\nWe randomly selected 10 published RCTs across various medical specialties, published in leading clinical\njournals, and 10 ongoing registered RCTs listed on ClinicalTrial.gov. This set includes Phase III (N = 15) and Phase\nIV (N = 5) studies, all of which are placebo-controlled trials and were either published or \u0000rst registered between\nJanuary and February 2024. Details of the dataset are presented in eTable 1 (Supplementary text).\nLarge Language Model\nIn this current study, we selected GPT-4-Turbo-Preview. We chose a Temperature of 0.2 to balance replicability and\nclinical rigor. Detailed prompts and example output are presented in eFigure 1 and eFigure 2 (supplementary text),\nrespectively.\nQuantitative Evaluation\nWe \u0000rst collect ground truth for published studies from publication (cross-examined with corresponding study\nfrom ClinicalTrials.gov), and recent registered ongoing trials from ClinicalTrials.gov. For outputs with numerical or\ncategorical answers, such as gender or age in recruitment and measurement time frame in outcome measures, we\nde\u0000ne correct answers as completely matching numerical values in ground truth. For outputs with clinical\nPage 5/10\nanswers, such as eligibility criteria, active and control arm in intervention and measurement design in outcome\nmeasures, we de\u0000ned correct answers if clinically align with ground truth. Speci\u0000cally, for eligibility criteria\ndesigns, the accuracy of was determined by numbers of matched LLM designs divided by total number of\neligibility criteria LLM has listed.\nQuantitative Evaluation\nWe used a metric comprised of safety, clinical accuracy, objectivity (bias), pragmatic (adapted from PRECIS-2\nguidance), inclusivity and diversity (adapted from United States Food and Drug Administration (FDA) draft\nguidance to clinical trial design) measured on a three-point Likert Scale (1 is the worst, 3 is the best).\nStatistical analysis\nWe employed average, non-weighted NLP based objective scoring, including BLEU, ROGUE-L and METEOR, for\nLLM outputs. Details are represented in eTable 2 (Supplementary text).\nDeclarations\nEthics statement and informed consent\nAs current study is retrospective in nature, and no real patient was involved in current research, regulatory\napproval and informed consent is not applicable. Human clinical experts received no compensation for rating.\nReferences\n1. Nichol A, Bailey M, Cooper D, behalf of the POLAR O. Challenging issues in randomised controlled trials.\nInjury. 2010;41:S20-S23.\n2. Gray DM, Nolan TS, Gregory J, Joseph JJ. Diversity in clinical trials: an opportunity and imperative for\ncommunity engagement. The Lancet Gastroenterology & Hepatology. 2021;6(8):605-607.\n3. Stensland KD, DePorto K, Ryan J, et al. Estimating the rate and reasons of clinical trial failure in urologic\noncology. Elsevier; 2021:154-160.\n4. Wong CH, Siah KW, Lo AW. Estimation of clinical trial success rates and related parameters. Biostatistics.\n2019;20(2):273-286.\n5. Pretorius S, Grignolo A. Phase III trial failures: Costly, but preventable. 2016;\n\u0000. Arti\u0000cial Intelligence for Clinical Trial Design: Trends in Pharmacological Sciences.\n2024;doi:doi:10.1016/j.tips.2019.05.005\n7. Hutson M. How AI is being used to accelerate clinical trials. Nature Index. Nature. 2024-03-13\n2024;627(8003)doi:doi:10.1038/d41586-024-00753-x\n\u0000. Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF, Ting DSW. Large language models in\nmedicine. Nature medicine. 2023;29(8):1930-1940.\n9. Singhal K, Azizi S, Tu T, et al. Large language models encode clinical knowledge. Nature.\n2023;620(7972):172-180.\n10. Karakas C, Brock D, Lakhotia A. Leveraging ChatGPT in the Pediatric Neurology Clinic: Practical\nConsiderations for Use to Improve E\u0000ciency and Outcomes. Pediatric Neurology. 2023;148:157-163.\nPage 6/10\n11. Wójcik S, Rulkiewicz A, Pruszczyk P, Lisik W, Pobo ż y M, Domienik-Kar ł owicz J. Reshaping medical education:\nPerformance of ChatGPT on a PES medical examination. Cardiology Journal. 2023;\n12. Klang E, Portugez S, Gross R, et al. Advantages and pitfalls in utilizing arti\u0000cial intelligence for crafting\nmedical examinations: a medical education pilot study with GPT-4. BMC Medical Education. 2023;23\n13. Waisberg E, Ong J, Masalkhi M, et al. GPT-4 and ophthalmology operative notes. Annals of Biomedical\nEngineering. 2023:1-3.\n14. Sun Z, Ong H, Kennedy P, et al. Evaluating GPT-4 on impressions generation in radiology reports. Radiology.\n2023;307(5):e231259.\n15. Zhou Z. Evaluation of ChatGPT's capabilities in medical report generation. Cureus. 2023;15(4)\n1\u0000. Kanjee Z, Crowe B, Rodman A. Accuracy of a Generative Arti\u0000cial Intelligence Model in a Complex Diagnostic\nChallenge. JAMA. 2023;\n17. Waisberg E, Ong J, Zaman N, et al. GPT-4 for triaging ophthalmic symptoms. Eye. 2023:1-2.\n1\u0000. Ghim J-L, Ahn S. Transforming clinical trials: the emerging roles of large language models. Translational and\nClinical Pharmacology. 2023;31(3):131.\n19. Wong C, Zhang S, Gu Y, et al. Scaling clinical trial matching using large language models: A case study in\noncology. PMLR; 2023:846-862.\n20. Jin Q, Wang Z, Floudas CS, Sun J, Lu Z. Matching patients to clinical trials with large language models.\nArXiv. 2023;\n21. Tayebi Arasteh S, Han T, Lot\u0000nia M, et al. Large language models streamline automated machine learning for\nclinical studies. Nature Communications. 2024;15(1):1603.\n22. Moher D, Hopewell S, Schulz KF, et al. CONSORT 2010 explanation and elaboration: updated guidelines for\nreporting parallel group randomised trials. Bmj. 2010;340\n23. Schulz KF, Altman DG, Moher D. CONSORT 2010 statement: updated guidelines for reporting parallel group\nrandomised trials. Journal of Pharmacology and pharmacotherapeutics. 2010;1(2):100-107.\n24. Chan A-W, Tetzlaff JM, Gøtzsche PC, et al. SPIRIT 2013 explanation and elaboration: guidance for protocols\nof clinical trials. Bmj. 2013;346\n25. Loudon K, Treweek S, Sullivan F, Donnan P, Thorpe KE, Zwarenstein M. The PRECIS-2 tool: designing trials\nthat are \u0000t for purpose. bmj. 2015;350\n2\u0000. Papineni K, Roukos S, Ward T, Zhu W-J. Bleu: a method for automatic evaluation of machine translation.\n2002:311-318.\n27. Lin C-Y. Rouge: A package for automatic evaluation of summaries. 2004:74-81.\n2\u0000. Banerjee S, Lavie A. METEOR: An automatic metric for MT evaluation with improved correlation with human\njudgments. 2005:65-72.\n29. Food, Administration D. Evaluating inclusion and exclusion criteria in clinical trials. 2020.\n30. Singhal K, Azizi S, Tu T, et al. Large language models encode clinical knowledge. Nature. Jul 12\n2023;doi:10.1038/s41586-023-06291-2\n31. Wei J, Tay Y, Bommasani R, et al. Emergent Abilities of Large Language Models. 2022/06/15 2022;\n32. Devlin J, Chang M-W, Lee K, Toutanova K. Bert: Pre-training of deep bidirectional transformers for language\nunderstanding. arXiv preprint arXiv:181004805. 2018;\nPage 7/10\n33. Li J, Wei Q, Ghiasvand O, et al. A comparative study of pre-trained language models for named entity\nrecognition in clinical trial eligibility criteria from multiple corpora. BMC Medical Informatics and Decision\nMaking. 2022;22(Suppl 3):235.\n34. Datta S, Lee K, Paek H, et al. AutoCriteria: a generalizable clinical trial eligibility criteria extraction system\npowered by large language models. Journal of the American Medical Informatics Association.\n2024;31(2):375-385.\n35. Yang Y, Jayaraj S, Ludmir E, Roberts K. Text Classi\u0000cation of Cancer Clinical Trial Eligibility Criteria. American\nMedical Informatics Association; 2023:1304.\n3\u0000. J M, I L, I D, K C, H BS. ChatGPT for Sample-Size Calculation in Sports Medicine and Exercise Sciences: A\nCautionary Note. International journal of sports physiology and performance. 08/03/2023\n2023;18(10)doi:10.1123/ijspp.2023-0109\n37. Wang Y, Wang Y, Peng Z, Zhang F, Zhou L, Yang F. Medical text classi\u0000cation based on the discriminative pre-\ntraining model and prompt-tuning. Digital Health. 2023;9:20552076231193213.\n3\u0000. Wang S, Š uster S, Baldwin T, Verspoor K. Predicting publication of clinical trials using structured and\nunstructured data: model development and validation study. Journal of Medical Internet Research.\n2022;24(12):e38859.\nTable\nPage 8/10\nTable 1\nExisting LLM applications in clinical trials related studies. We used the following search strategy We used thefollowing literature search strategy: ((\"clinical trials as topic\"[MeSH Terms] OR \"randomized controlled trials astopic\"[MeSH Terms] OR \"clinical trial\"[Title/Abstract]) AND (\"arti\u0000cial intelligence\"[MeSH Terms] OR \"generative ai\"[Title/Abstract] OR \"language model\"[Title/Abstract])) AND (2022:2024[pdat]). We restricted search to articlespublished in PubMed between 1st January 2022 and 1st April 2024. We screened a total of 575 articles fromPubMed and included a \u0000nal of 6 publications. We included peer-reviewed articles investigating the performanceof generative AI models applied in the conduct of clinical trials or randomized controlled trials. We excludedreview papers and studies that did not report any model performance. Legend: BERT: Bidirectional EncoderRepresentations from Transformers, GPT: Generative Pre-trained Transformer, AUC: area under the receiveroperating characteristic (ROC) curve, ACC: Accuracy\nStudies LLMApplication LLMBaseModel\nTrainingor PromptTechnique\nSourceofTrainingDataset\nTestingDatasetSampleSize\nEvaluationMetricsUsed\nModelPerformance\nAcomparativestudy of pre-trainedlanguagemodels fornamed entityrecognition inclinical trialeligibilitycriteria frommultiple\ncorpora33\nEligibilityScreening BERT Pre-training Interviewdata 470/230/1000\nF1 0.72/ 0.84/0.62\nAutoCriteria:ageneralizableclinical trialeligibilitycriteriaextractionsystempowered bylargelanguage\nmodels34\nEligibilityScreening GPT 4 Zero-shot clinicaltrial text 180Trials F1 0.90\nTextClassi\u0000cationof CancerClinical TrialEligibility\nCriteria35\nEligibilityScreening BERT Zero-shot Registry 764Trials ACC 0.27–0.95\nChatGPT forSample-SizeCalculation inSportsMedicine andExerciseSciences: ACautionary\nNote36\nSample SizeCalculation GPT 4 Few-shots Registry 4 Trials ACC 0.75\nPage 9/10\nStudies LLMApplication LLMBaseModel\nTrainingor PromptTechnique\nSourceofTrainingDataset\nTestingDatasetSampleSize\nEvaluationMetricsUsed\nModelPerformance\nMedical textclassi\u0000cationbased on thediscriminativepre-trainingmodel andprompt-\ntuning37\nAssist TrialOutcomeMeasurement\nBERT Pre-training Interviewdata 5127Outcomeentities\nACC 0.86\nPredictingPublication ofClinical TrialsUsingStructuredandUnstructuredData: ModelDevelopmentandValidation\nStudy38\nTrialOutcomePrediction\nBERT Zero-shot Registry 76,950Trials F1 0.70\nFigures\n\nPage 10/10\nFigure 1\nLLM outputs coherence (matching with ground truth) on 20 testing RCT studies (10 published RCTs and 10\nongoing registered RCTs).\nFigure 2\nA: Qualitative metric for 10 published RCTs. B. Qualitative metric for 10 ongoing registered RCTs.\nSupplementary Files\nThis is a list of supplementary \u0000les associated with this preprint. Click to download.\nSupplementaryText.docx",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.4943671226501465
    },
    {
      "name": "Randomized controlled trial",
      "score": 0.43920937180519104
    },
    {
      "name": "Medicine",
      "score": 0.12733349204063416
    },
    {
      "name": "Surgery",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210126319",
      "name": "Duke-NUS Medical School",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I2251586001",
      "name": "Singapore General Hospital",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I4210116917",
      "name": "Singapore Eye Research Institute",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I2799299286",
      "name": "Singapore National Eye Center",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I285663978",
      "name": "Weatherford College",
      "country": "US"
    }
  ],
  "cited_by": 3
}