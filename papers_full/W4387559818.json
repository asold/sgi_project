{
  "title": "MindfulDiary: Harnessing Large Language Model to Support Psychiatric Patients' Journaling",
  "url": "https://openalex.org/W4387559818",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A308967967",
      "name": "Kim, Taewan",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Bae, Seolyeong",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2512213158",
      "name": "Kim Hyun Ah",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Lee, Su-woo",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3137801727",
      "name": "Hong， Hwajung",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1210637971",
      "name": "Yang Chan-Mo",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2175854503",
      "name": "Kim， Young Ho",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3136599046",
    "https://openalex.org/W3085717248",
    "https://openalex.org/W4383679928",
    "https://openalex.org/W3206079177",
    "https://openalex.org/W1999144584",
    "https://openalex.org/W2985954675",
    "https://openalex.org/W4386721614",
    "https://openalex.org/W4303427132",
    "https://openalex.org/W1979290264",
    "https://openalex.org/W3164718925",
    "https://openalex.org/W4317757464",
    "https://openalex.org/W3088653102",
    "https://openalex.org/W2582664174",
    "https://openalex.org/W2889335577",
    "https://openalex.org/W3155584966",
    "https://openalex.org/W2142556291",
    "https://openalex.org/W4366591012",
    "https://openalex.org/W4302356030",
    "https://openalex.org/W2025611158",
    "https://openalex.org/W1993028205",
    "https://openalex.org/W2027624180",
    "https://openalex.org/W2395048880",
    "https://openalex.org/W2767558581",
    "https://openalex.org/W4378470708",
    "https://openalex.org/W4225388974",
    "https://openalex.org/W4383422217",
    "https://openalex.org/W34277621",
    "https://openalex.org/W2621378336",
    "https://openalex.org/W2866044803",
    "https://openalex.org/W2170207495",
    "https://openalex.org/W4386977932",
    "https://openalex.org/W4210722449",
    "https://openalex.org/W4309674289",
    "https://openalex.org/W2118377505",
    "https://openalex.org/W4285722314",
    "https://openalex.org/W2096965732",
    "https://openalex.org/W2559582770",
    "https://openalex.org/W3036406130",
    "https://openalex.org/W3031532441",
    "https://openalex.org/W3203321135",
    "https://openalex.org/W3036060683",
    "https://openalex.org/W2941663933",
    "https://openalex.org/W3183473388",
    "https://openalex.org/W4385157257",
    "https://openalex.org/W3015322406",
    "https://openalex.org/W2157985609",
    "https://openalex.org/W2253311584",
    "https://openalex.org/W4236549169",
    "https://openalex.org/W62051475",
    "https://openalex.org/W349893698",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2940562610",
    "https://openalex.org/W2154684451",
    "https://openalex.org/W4385623654",
    "https://openalex.org/W2750766457",
    "https://openalex.org/W2977128309",
    "https://openalex.org/W2774223171",
    "https://openalex.org/W2290835535",
    "https://openalex.org/W2554749924",
    "https://openalex.org/W3036236864",
    "https://openalex.org/W2941540847",
    "https://openalex.org/W4221105509",
    "https://openalex.org/W2998548486",
    "https://openalex.org/W2799097429",
    "https://openalex.org/W4226055518",
    "https://openalex.org/W2623779865",
    "https://openalex.org/W4381104068",
    "https://openalex.org/W4396721126",
    "https://openalex.org/W2013025260",
    "https://openalex.org/W4385473492",
    "https://openalex.org/W2589021616",
    "https://openalex.org/W2002514548",
    "https://openalex.org/W4366548345",
    "https://openalex.org/W2079769881",
    "https://openalex.org/W4320838518",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2537935735",
    "https://openalex.org/W4297801719",
    "https://openalex.org/W4366819510",
    "https://openalex.org/W2937284856",
    "https://openalex.org/W3174098556",
    "https://openalex.org/W3029922759",
    "https://openalex.org/W2066042060",
    "https://openalex.org/W4367310920",
    "https://openalex.org/W2895995041",
    "https://openalex.org/W2032947214",
    "https://openalex.org/W4396219010",
    "https://openalex.org/W1965148737",
    "https://openalex.org/W136483523"
  ],
  "abstract": "In the mental health domain, Large Language Models (LLMs) offer promising new opportunities, though their inherent complexity and low controllability have raised questions about their suitability in clinical settings. We present MindfulDiary, a mobile journaling app incorporating an LLM to help psychiatric patients document daily experiences through conversation. Designed in collaboration with mental health professionals (MHPs), MindfulDiary takes a state-based approach to safely comply with the experts' guidelines while carrying on free-form conversations. Through a four-week field study involving 28 patients with major depressive disorder and five psychiatrists, we found that MindfulDiary supported patients in consistently enriching their daily records and helped psychiatrists better empathize with their patients through an understanding of their thoughts and daily contexts. Drawing on these findings, we discuss the implications of leveraging LLMs in the mental health domain, bridging the technical feasibility and their integration into clinical settings.",
  "full_text": "MindfulDiary: Harnessing Large Language Model\nto Support Psychiatric Patients’ Journaling\nTaewan Kim∗\nKAIST\nRepublic of Korea\ntaewan@kaist.ac.kr\nSeolyeong Bae†\nGIST\nRepublic of Korea\npeixueying@gmail.com\nHyun Ah Kim\nNAVER Cloud\nRepublic of Korea\nhyunah.kim@navercorp.com\nSu-woo Lee\nWonkwang Univ. Hospital\nRepublic of Korea\naiesw@naver.com\nHwajung Hong\nKAIST\nRepublic of Korea\nhwajung@kaist.ac.kr\nChanmo Yang‡\nWonkwang Univ. Hospital,\nWonkwang University\nRepublic of Korea\nychanmo@wku.ac.kr\nYoung-Ho Kim‡\nNAVER AI Lab\nRepublic of Korea\nyghokim@younghokim.net\nFigure 1: MindfulDiary consists of two components: the patient interface and the expert interface: (1) Patient interface aids\nusers in daily journaling, offering prompt questions through conversations and crafting summaries in a diary-like format. (2)\nClinician Dashboard features a dashboard that visualizes data from patient records, facilitating its use during consultations.\n(Refer to our supplementary video for the user interaction.)\nABSTRACT\nLarge Language Models (LLMs) offer promising opportunities in\nmental health domains, although their inherent complexity and low\ncontrollability elicit concern regarding their applicability in clinical\n∗Taewan Kim conducted this work as a research intern at NAVER AI Lab.\n†Seolyeong Bae conducted this work as an engineering intern at NAVER Cloud.\n‡Co-corresponding authors.\nPermission to make digital or hard copies of part or all of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for third-party components of this work must be honored.\nFor all other uses, contact the owner/author(s).\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA\n© 2024 Copyright held by the owner/author(s).\nACM ISBN 979-8-4007-0330-0/24/05.\nhttps://doi.org/10.1145/3613904.3642937\nsettings. We present MindfulDiary, an LLM-driven journaling app\nthat helps psychiatric patients document daily experiences through\nconversation. Designed in collaboration with mental health profes-\nsionals, MindfulDiary takes a state-based approach to safely comply\nwith the experts’ guidelines while carrying on free-form conversa-\ntions. Through a four-week field study involving 28 patients with\nmajor depressive disorder and five psychiatrists, we examined how\nMindfulDiary facilitates patients’ journaling practice and clinical\ncare. The study revealed that MindfulDiary supported patients in\nconsistently enriching their daily records and helped clinicians\nbetter empathize with their patients through an understanding of\ntheir thoughts and daily contexts. Drawing on these findings, we\ndiscuss the implications of leveraging LLMs in the mental health\ndomain, bridging the technical feasibility and their integration into\nclinical settings.\narXiv:2310.05231v2  [cs.HC]  22 Feb 2024\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Taewan Kim, Seolyeong Bae, Hyun Ah Kim, Su-woo Lee, Hwajung Hong, Chanmo Yang, and Young-Ho Kim\nCCS CONCEPTS\n• Human-centered computing → Empirical studies in HCI ;\nNatural language interfaces .\nKEYWORDS\njournaling, chatbot, mental health, clinical setting, psychiatric pa-\ntient, large language models\nACM Reference Format:\nTaewan Kim, Seolyeong Bae, Hyun Ah Kim, Su-woo Lee, Hwajung Hong,\nChanmo Yang, and Young-Ho Kim. 2024. MindfulDiary: Harnessing Large\nLanguage Model to Support Psychiatric Patients’ Journaling. In Proceedings\nof the CHI Conference on Human Factors in Computing Systems (CHI ’24),\nMay 11–16, 2024, Honolulu, HI, USA. ACM, New York, NY, USA, 20 pages.\nhttps://doi.org/10.1145/3613904.3642937\n1 INTRODUCTION\nJournals serve as a written record of an individual’s past events,\nthoughts, and feelings, allowing genuine expression [89, 90]. Jour-\nnaling helps people describe experiences and express emotions re-\nlated to both negative [70, 71] and positive experiences (e.g., growth\npotential) [9, 35], thereby reducing stress, anxiety, and depression.\nPrior work has shown the advantages of journaling in clinical men-\ntal health contexts, as journals frequently capture patients’ daily\nexperiences, symptoms, and other contextual data that are chal-\nlenging to gather during brief hospital visits [27, 100]. Furthermore,\nthese patient journals can enhance mental health professionals\n(MHPs) comprehension of their patient’s conditions, leading to\nimproved treatment quality [95]. However, writing about one’s past\nfeelings and thoughts can be a complex process because people\ndiffer in their ability to understand, identify, and verbalize their\nemotions [78]. In addition, patient under psychotherapy struggle\nwith constructing a narrative and understanding their past [23, 72].\nConversational AIs, or chatbots, have the potential as an alter-\nnative form of journaling, easing the collection of personal data.\nResearchers in the field of Human-Computer Interaction (HCI)\nhave shown that chatbots can help individuals articulate and share\ntheir daily experiences. For instance, chatbots to elicit people’s\nself-disclosure can ease the process of emotional expression by pro-\nviding a safe and supportive environment for individuals to share\ntheir experiences and emotions [16, 52, 53, 68]. Furthermore, a ma-\nchine’s inherent trait of not showing fatigue can make people more\nconfident to share their stories truthfully and comfortably [44, 68].\nHowever, existing chatbot prototypes have commonly employed\nrule-based or retrieval-driven approaches [1], which have limited\ncapability of generating versatile responses following up serendip-\nitous topics during conversation [38, 41, 51]. This trend presents\nmissed opportunities and a lack of understanding regarding conver-\nsational AIs that assist with journaling by suggesting, questioning,\nand empathizing based on the user’s diverse experiences.\nThe recent achievement of Natural Language Processing in large\nlanguage models (LLMs) opened up new opportunities for boot-\nstrapping chatbots that can carry on more naturalistic conversa-\ntion [8, 14, 41, 77, 94]. Their capabilities accelerated the develop-\nment of chatbots in varied topics that can benefit from open-ended\nconversation, such as regular check-up calls [8, 41], personal health\ntracking [94], and personal events and emotions [80]. Despite such\nopportunities, LLMs’ inherent uncertainty in control of response\ngeneration calls for precautions to handle unintended or inaccurate\nresponses [26, 41, 47, 93]. If applied to clinical and mental health\ndomains, LLM’s behaviors should be designed in collaboration with\ndomain experts regarding the relevance and safety of responses.\nIn this work, we present a case of collaborative design, develop-\nment, and evaluation of an LLM-infused conversational AI system\ndesigned to facilitate the self-reflection of patients and commu-\nnication with MHPs. We designed and developed MindfulDiary\n(Figure 1), which consists of (1) a mobile conversational AI with\nwhich patients can converse about daily experiences and thoughts\nand (2) a web dashboard that allows MHPs to review their patients’\ndialogue history with the AI. MindfulDiary incorporates LLMs to\ngenerate a response, prompting patients differently according to the\nconversational phase. The conversation records are automatically\nsummarized and presented on a clinician dashboard so MHPs can\nobtain insights about the patient.\nAs a multi-disciplinary research team, which included HCI re-\nsearchers, AI engineers, and psychiatrists, we iteratively designed\nMindfulDiary and conducted a four-week field study involving\n28 psychiatric patients diagnosed with major depressive disorder\n(MDD) and five psychiatrists who care for them. During the study,\nthe patients freely used MindfulDiary to record daily conversations,\nand the psychiatrists used the clinician dashboard during regular\nclinical visits. Through this study, we found that the versatility,\nnarrative-building capability, and diverse perspectives provided by\nMindfulDiary assisted patients in consistently enriching their daily\nrecords. Furthermore, MindfulDiary supported patients in over-\ncoming the challenges of detailed record-keeping and expression,\noften hindered by feelings of apathy and cognitive burdens. The\npsychiatrists reported that enhanced records provided by Mind-\nfulDiary offered a more nuanced understanding of their patients,\nfostering empathy. In addition, MindfulDiary supplemented their\nconsultation by eliciting candid thoughts from patients that may\nbe invasive to be asked by the MHPs.\nThe key contributions of this work are:\n(1) Design and development of MindfulDiary, an LLM-driven jour-\nnal designed to document psychiatric patients’ daily experiences\nthrough naturalistic conversations, designed in collaboration\nwith MHPs.\n(2) Empirical findings from a four-week field study involving 28\npatients and five psychiatrists, demonstrating how Mindful-\nDiary supported patients in keeping their daily logs and as-\nsisted psychiatrists in monitoring and comprehending patient\nstates. We also explore how MindfulDiary enhances the qual-\nity of patient-provider communication, emphasizing the role\nof LLMs in prompting deeper self-exploration, which can be\ninstrumental in clinical settings.\n(3) Implications for designing and instrumenting LLM-infused con-\nversational AIs in clinical mental health settings.\nMindfulDiary: Harnessing Large Language Model to Support Psychiatric Patients’ Journaling CHI ’24, May 11–16, 2024, Honolulu, HI, USA\n2 RELATED WORK\nIn this section, we cover related work in three parts: (1) Journaling\nfor self-reflection and mental Health, (2) Journaling as patient-\ngenerated health data in clinical settings, and (3) Conversational\nagents for mental health.\n2.1 Journaling for Self-Reflection and Mental\nHealth\nJournaling—recording various personal matters ranging from obser-\nvations and travels to overall daily experiences and thoughts [76]—\ntakes place in various forms, including letter-style entries reminis-\ncent of Anne Frank’s diary or more traditional prose. By narrating\npersonal experiences and innermost feelings in a journal, people dis-\ncover insights upon reflecting on their past events [89, 90], thereby\nimproving mental wellness and quality of life [ 9, 70, 71, 91]. Re-\nsearchers have found that journaling impacts mental health by\nfostering emotional inhibition [69], cognitive processing [36], and\n“freeing up” cognitive load [45, 74].\nBeyond traditional pen and paper, research in HCI has explored\nhow technology can augment a journaling method in articulating\npast emotions and experiences (e.g., [4, 10, 24, 37, 37, 42, 46]). Early\nstudies in journaling focused on how technology can assist users in\nbetter documenting past events and experiences from life-logging\nperspectives [24, 37, 42]. For example, SenseCam has been proposed\nas a wearable ubiquitous computing device that utilizes camera\nsensor data to not only record but also reflect on the wearer’s daily\nlife [37]. Subsequently, various attempts have been made to utilize\ncontextual data and cues such as activity levels [ 46], mood [10],\nlocation, and photos [4] in journaling context.\nFurthermore, HCI researchers have investigated ways to improve\na journaling method to encourage users to express themselves in\na manner that is more comfortable [34], engaging [58], and hon-\nest [68]. For example, Park et al. found that conversational agents\ncreate a social-like environment, encouraging self-reflection and en-\nhancing expressive writing [68]. Furthermore, social support from\nonline communities has been found to increase user participation in\njournaling activities [58]. Gonzales et al. [34] proposed an approach\nto mitigate the discomfort of revisiting negative memories using\nthe sound generated from the data for more pleasurable [34].\nOur work extends this line of research to enhance the journaling\nexperience with technology. Specifically, we explore the potential\nof interactive dialogue with LLMs as a new format for journaling,\nallowing psychiatric patients to explore and reflect on their past\nexperiences and emotions. To this end, we leverage a conversational\nagent as a complementary tool for assisting patients by providing\nprompt questions to engage users in deeper and more detailed\ndocumentation and reflection [46]. We particularly investigate how\nour approach plays a role in clinical settings as patient-generated\nhealth data, which we will cover in the following.\n2.2 Journaling as Patient-Generated Health\nData in Clinical Settings\nPatient-Generated Health Data (PGHD)—defined as “health-related\ndata, such as health history, symptoms, biometric readings, treatment\nhistory, lifestyle choices, and other pertinent details, created, recorded,\nor gathered by patients” [81]—has increasingly become an essen-\ntial tool in clinical settings to capture authentic, real-time insights\ninto patients‘ health. Studies have shown that PGHD can enhance\ncommunication between patients and MHPs and offer contextual\ninformation about patients, thereby heightening MHPs’ awareness\nof patient health outside regular clinical visits [20, 55, 64]. For in-\nstance, photo journaling improved patient-provider communication\nfor the management and treatment of irritable bowel syndrome by\nfacilitating more effective discussions during treatment [18].\nWithin the mental health domain, PGHD range from structured\nmental health assessments (e.g., anxiety, depression) to more un-\nstructured data, including mood-related symptoms and social inter-\nactions tracking (e.g., social media use, number of calls)[6, 21, 63].\nPatient diaries or journals–“instructing the patient to write down\none’s symptoms and other information related to one’s daily life to\ndiscuss them during clinical appointments” [27, 100]–can particu-\nlarly be useful in mental health contexts as it can offer rich, self-\ndocumented insights, which could improve MHPs‘ understanding\nof their patients [ 95]. Despite the benefits of patient journaling,\npeople often struggle with starting their entries, sticking to con-\nsistent journaling routines, and structuring their reflections [89].\nFurther, writing about emotions and past experiences can be intri-\ncate, as individuals vary in their capacity to recognize, interpret,\nand articulate their feelings [ 49, 57, 78]. For some, especially in\npsychotherapy, crafting a narrative that describes one’s life journey\ncan be a challenging process [23, 72].\nIn this work, we aim to lower the barrier of journaling for pa-\ntients by allowing them to carry on casual conversations with an\nAI instead of plain open-ended text writing. We demonstrate the\npotential of these dialogues as a source of PGHD in clinical settings\nto facilitate individual self-reflection and enhance communication\nbetween patients and MHPs.\n2.3 Conversational Agents for Mental Health\nThe field of AI has proposed significant innovations in medical set-\ntings, such as aiding clinical decision-making and diagnosis [11, 60].\nIn a mental health domain, Natural Language Processing (NLP)\ntechniques have been widely applied to venues that demand hu-\nman language comprehension and generation for patient support\nand treatment [15, 22]. Since caring mental health often involves\ncounseling, conversational agents, also known as chatbots, have\nparticularly stood out in the mental health domain [1, 3]. Studies\nhave demonstrated the potential of chatbots in facilitating different\ntypes of therapy, such as cognitive behavioral therapy [28, 29, 39],\nexpressive writing [68], behavioral reinforcement [39], and solution-\nfocused therapy [29]. Prior work has also shown that chatbots could\nease the burden of disclosing sensitive information. Studies indi-\ncated that individuals may feel more comfortable communicating\nwith chatbots because of the social stigma involved in communicat-\ning with human beings [52, 53, 68]. Furthermore, these approaches\ncan help overcome temporal and spatial constraints, offering mental\nhealth support that is accessible at any time and anywhere [16].\nEarly mental health therapy chatbots predominantly relied upon\nrule-based or retrieval-based approaches [ 1, 2]. While these ap-\nproaches provide a high level of control over the conversational\nflow, they fall short of carrying on open-ended conversations; that\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Taewan Kim, Seolyeong Bae, Hyun Ah Kim, Su-woo Lee, Hwajung Hong, Chanmo Yang, and Young-Ho Kim\nis, the chatbots neither respond to serendipitous topics nor offer\nversatile responses that are outside the scope of design [31, 38, 51].\nIn the mental health context, these limitations may impact the\nquality of the chatbot’s caring behaviors as their messages tend\nto be general [ 38, 68]. Recent LLMs have suggested a new para-\ndigm of bootstrapping chatbots [93, 94]. LLM-driven chatbots tend\nto produce human-like, context-aware responses for unseen top-\nics [65, 94]. Consequently, LLM-driven chatbots excel in facilitating\nopen-domain dialogues and engaging in unscripted interactions [8],\noffering flexibility and adaptability in conversations [73, 86], espe-\ncially in complex scenarios like mental health support. For instance,\nGPT-3.5 demonstrates empathetic traits, such as recognizing emo-\ntions and offering emotionally supportive replies in various situa-\ntions, predominantly in healthcare settings [84]. In certain cases,\nthese models appear to have potential in tasks that involve empa-\nthy, showing promising results when compared to humans [7, 25].\nGiven these early findings, LLM-driven chatbots in the public health\nsector may offer some support in alleviating emotional burden and\nloneliness among isolated individuals, though this area is still un-\nder exploration [41]. Additionally, the integration of LLMs with\nhuman efforts in creating mental health peer support messages\ncould potentially lead to more empathetic conversations [82].\nHowever, LLMs suffer from inherent challenges tied to their\ntransformer-based architecture [92]. One key issue is the explain-\nability of the model output: it is challenging to discern how this\n‘black box’ model interprets a given input prompt. As a result, de-\nsigners struggle to predict both the LLM’s understanding of the\ninput and the subsequent messages it might produce [54]. For in-\nstance, a chatbot leveraging GPT-2 for mental health therapy occa-\nsionally generated non-word sentences or produced more negative\noutputs than positive ones [93]. Replika, an LLM-driven applica-\ntion intended for mental well-being, has occasionally displayed\nharmful content and exhibited inconsistent conversational styles,\nundermining its role as a long-term companion [59].\nThese findings highlight two implications for LLM-infused sys-\ntems in clinical settings. First, human oversight and moderation are\ncritical when using LLMs in clinical settings [93]. To ensure safe\nand ethical instrumentation of LLMs for mental health patients, this\nwork involves MHPs to reflect domain experts’ perspectives [88] in\ndeveloping an LLM-driven chatbot system. Second, it is necessary\nto enhance the controllability of an LLM [41, 97] to better follow\nthe intended conversational design. As one exemplar approach to\nenhance LLM’s controllability, yet not a conversational domain, AI\nChains break down a complex task into multiple, simpler sub-tasks\nso that individual LLM inferences can work in better reliability [96].\nSimilarly, in our system, the chatbot operates using state-based\nprompting, where a model prompt contains the instruction focused\nsolely on the current state, which is part of an overarching conver-\nsational protocol. By simplifying the model prompts, we intended\nthe generated responses to safely and reliably comply with the\nMHP’s guidelines for interacting with the patients.\nIn summary, our work leverages LLMs in two key components:\nFirst, we use an LLM to power a chatbot for patient journaling.\nSecond, the clinician dashboard incorporates LLMs for various\nNLP tasks, such as text summarization and classification, to visu-\nalize summarized insights ( e.g., [5, 32]) that are noteworthy for\nMHP’s treatment. Through this collaborative approach involving\nclinicians, our work explores a unique design space for designing\ndeploying LLM-driven chatbots in the mental health domain, aim-\ning to improve communication between patients and providers by\nfacilitating the recording of daily experiences, which act as a bridge\nfor a better understanding of patients.\n3 FORMATIVE STUDY: FOCUS GROUP\nINTERVIEW\nTo inform the design of MindfulDiary, we first conducted a Focus\nGroup Interview (FGI) with MHPs. The goal of the FGI was to un-\nderstand MHPs’ perspectives, expectations, values, and precautions\nin utilizing LLMs in the clinical mental health context. Based on this\nunderstanding, we aimed to design the functions and interactions\nthat the system should provide. This was an essential process in\nour overall approach, not just technology-centered system design,\nbut creating a system meaningful to users and stakeholders [87].\n3.1 Procedure and Analysis\nWe distributed recruitment flyers in the Department of Psychiatry\nat a local university hospital, inviting Mental Health Professionals\n(MHPs) working in departments of psychiatry and mental health\ncare centers to participate. We recruited six MHPs (E1–6; two males\nand four females)—four clinical psychologists and two psychiatrists\nwhose careers varied from 1 to 11 years. Four were clinical psy-\nchologists responsible for counseling and daily monitoring and\nintervention of at-risk patient groups in local mental health centers\nand university hospitals, and two were psychiatrists in charge of\noutpatient and inpatient ward treatment in the psychiatry depart-\nment of university hospitals (see Table 1).\nWe invited participants to two 1-hour remote sessions on Zoom.\nTwo researchers participated in the sessions. We first provided an\noverview of language model technologies and LLM’s natural lan-\nguage understanding and generation capabilities until we shared a\ncommon understanding of the principles, applications, opportuni-\nties, and limitations of LLMs. Considering that we were designing\na system for individuals with mental health challenges, we thor-\noughly covered the drawbacks of LLMs, such as uncertainty in\ncontrol and hallucinations.\nAfter the overview, we went through group discussions on how\nLLMs could be utilized in the current patient treatment process.\nAs a probe, we asked participants a focused set of questions on\n(1) the challenges MHPs currently face during patient treatment\nand counseling sessions, and (2) their expectations and envisioned\nopportunities of LLMs’ role in clinical mental health settings. We\nsought to understand the experts’ perspectives through questions\nsuch as, ‘What are the difficulties or challenges patients face in their\ndaily lives between treatments (or counseling)? ’, ‘What are the impor-\ntant considerations in self-care that patients perform in their daily\nlives?’, and ‘What questions or conversational techniques do you use\nto encourage patients to share about their daily lives and moods? ’. The\nsession was video recorded and later transcribed. We open-coded\nthe transcripts to identify emerging themes. In the following, we\ncover the findings from the FGI.\nMindfulDiary: Harnessing Large Language Model to Support Psychiatric Patients’ Journaling CHI ’24, May 11–16, 2024, Honolulu, HI, USA\nTable 1: Demographic of FGI Participants (E1–6).\nCode Gender Age Job title Years of Experience\nE1 F 34 Clinical psychologist 2 years\nE2 F 30 Clinical psychologist 1 year\nE3 F 38 Clinical psychologist 9 years\nE4 F 36 Clinical psychologist 11 years\nE5 M 35 Psychiatrist 2 years\nE6 M 40 Psychiatrist 10 years\n3.2 Findings from the Interviews\n3.2.1 Challenges in Eliciting Responses from Patients with Depres-\nsion. Participants indicated that eliciting disclosure from patients’\ninner thoughts during a limited consultation time requires signif-\nicant effort. Many patients with depression experience difficulty\ndescribing and expressing their feelings and thoughts to providers\ndue to a sense of apathy, which is a common psychiatric symptom\ninvolved in Major Depressive Disorder: “In the consultation room,\neven if they sit like this, they often just remain silent for a long time. ”\n(E5) Thus, providers often end up spending a substantial amount\nof time asking standardized and repetitive questions about mood,\nsleep, and major events to understand patients’ current states.\nParticipants also noted that they had their patients engaged\nin paper-based diary writing methods but most demonstrated low\nparticipation rates and low engagement:“We tried a diary method on\npaper(in the inpatient ward), and several patients did write. What we\nsaw was quite trivial, like, ‘I just felt bad today. ’ But we learned there\nwere significant events upon consultation, like having a big argument\nwith other patients, which they did not record. Because patients with\ndepression, or those who have had suicidal or self-harming incidents,\noften have a dulled state in expressing their emotions or feel apathetic,\nthey tend to find such expressions very difficult. ” (E3)\n3.2.2 LLMs as a Bridge for Enhanced Patient Communication. Our\nparticipants envisioned LLMs as a transformative tool in mental\nhealth care, particularly for enhancing interactions with patients\nwho struggle to express themselves. They recognized that the natu-\nral and flexible conversational abilities of LLMs could bridge com-\nmunication gaps, offering a more nuanced understanding of pa-\ntients’ conditions. This could be particularly beneficial in cases\nwhere patients have difficulty articulating their feelings due to\nsymptoms like apathy or social phobia. Additionally, participants\nnoted that using LLMs could be significantly more interactive and\nengaging than traditional paper-based approaches, potentially in-\ncreasing compliance and participation in the therapeutic process.\nParticipants especially underscored the importance of capturing\nthe continuum of thoughts leading up to a particular emotional\nstate, such as fear, in the journaling process. They envisioned the\nneed for using LLMs to introspect deeper into the patient’s psyche,\nrevealing underlying thoughts and emotions that the patient might\nnot be consciously aware of. E5 mentioned, \"It would be good if the\njournal continuously records the flow of thoughts. For example, it\nwould be beneficial to document the various thoughts and detailed\nreasons leading up to certain feelings like fear. Like, ’I feel scared\nwhen I’m in a place with many people, ’ and then digging deeper into\n’Why do I feel scared?’—I think a process that gets more specific\nlike this would be good. \" This approach not only aids in a more\ncomprehensive self-examination but also enriches the therapeutic\ndialogue between the patient and the MHP.\n3.2.3 LLMs for Analytical Insights and Personalized Mental Health\nSupport. The participants further suggested that LLMs could ana-\nlyze journal entries to identify key themes, words, or sentiments\nexpressed over time, offering patients tangible feedback on their\nemotional patterns and progress. Such analytical capabilities could\nempower patients with a greater sense of control and awareness of\ntheir mental health journey, potentially motivating them towards\nself-management and active participation in their treatment. Addi-\ntionally, the analysis could assist MHPs in a deeper understanding\nof their patient’s emotional states and thought processes by exam-\nining the tone, choice of words, and speech or writing patterns. The\nparticipants envisioned that insights derived from LLMs about pa-\ntient journaling habits could inform MHPs about the most effective\ncounseling approaches for each individual. They suggested, \"Ob-\nserving how patients react to different forms of communication can\nprovide valuable information. Some patients might find solace in sim-\nple reassurance, while others may benefit from more straightforward,\ntargeted feedback. \"\n3.3 Improvements after the Interviews\nBased on the lessons from the FGI, we refined the initial concept of\nMindfulDiary. We leveraged the conversational abilities of LLMs\nto help patients document their daily experiences between clinical\nvisits. MHPs had access to the collected data to inform their clinical\ndecision-making. Furthermore, both MHPs and the research team\nconcur that LLMs should not act solely as the primary intervention\ndue to their inherent limitations but should function as supportive\ntools for clinical consultations. The subsequent section outlines the\ndesign and development process of our system.\n4 MINDFULDIARY\nInformed by the findings from FGI with MHPs, we designed and\ndeveloped MindfulDiary, which consists of two main components:\n(1) a patient mobile app for daily record-keeping and (2) a clinician\ndashboard that allows professionals to access and use these daily\nrecords in a clinical setting (See Figure 1). Below, we present a\nfictional usage scenario to demonstrate how the system works.\nJane, diagnosed with chronic anxiety, frequently grapples with\npanic attacks. To keep track of her daily experiences, her psychiatrist\nrecommends trying MindfulDiary as part of her treatment plan.\nEvery evening, Jane converses with the MindfulDiary app regard-\ning her daily activities, emotions, and thoughts. The AI leads the\nconversation with Jane by asking prompted and follow-up questions\nabout her day. After a session, the app summarizes the dialogue into\na journal-style essay, on which she can revisit and reflect later. She\ncan explore the summarized essays whenever she wants to reflect on\npast events or thoughts.\nThree weeks later, during a consultation, her psychiatrist uses the\nexpert interface of MindfulDiary to review a data-driven summary of\nJane’s entries. The data helped the psychiatrist identify patterns that\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Taewan Kim, Seolyeong Bae, Hyun Ah Kim, Su-woo Lee, Hwajung Hong, Chanmo Yang, and Young-Ho Kim\nFigure 2: Main screens of the MindfulDiary app. (a) The main screen, (b) the journaling screen, (c) the summary screen shown\nwhen the user submitted the journal dialogue, and (d) the review screen displaying the user’s past journal.\nJane’s anxiety often spikes during her work commute. Based on this\ninsight, the psychiatrist refines advice and introduces specific coping\nstrategies, fostering a more personalized approach to care.\n4.1 MindfulDiary App\nThe MindfulDiary app for patients aims to support people who\nmight have difficulty journaling due to apathy and cognitive load\nthrough naturalistic conversation driven by an LLM. The app con-\nsists of a home screen containing an introduction and guide to the\nsystem (Figure 2a), a journal writing screen (Figure 2b, 2c), and a\nscreen to review the diary entries (Figure 2d).\n4.1.1 Journaling User Interface. Figure 3 illustrates the overall use\nflow of the journaling session, which begins with a Pre-Journaling\nAssessment (Figure 3- 1○) that asks to fill out a questionnaire for\nmental health. The questionnaire comprised the modified PHQ-\n9 [48] and a custom open-ended question inquiring about recent\nattempts of self-harm or suicide. This assessment prevents users\nwho provided any clues of suicidal or self-harm from journaling on\nthe same day. (We cover this feature in detail in Section 5.4.)\nOn the next screen, the user converses with MindfulDiary, doc-\numenting the events of the day (See Figure 2b). After three turns,\nMindfulDiary provides a summary of the conversation as an essay.\nUsers can edit this automatically generated summary any time.\nWhen the user ends the session by pressing the end button (Fig-\nure 2b, bottom), MindfulDiary displays daily mental health insights\nalongside the diary content on the summary screen (See Figure 2c).\nUsers can also leave a reflection message there. Lastly, users can\nbrowse their past records in the Diary Review menu (See Figure 2d).\n4.1.2 Conversation Design. We designed the chatbot’s conversa-\ntional behavior based on insights from psychiatry literature [66, 67],\nwhich covers foundational techniques and considerations for con-\nducting clinical interviews. We also incorporated the hands-on\nclinical experiences of practicing psychiatrists.\nAs a result, we designed the conversation of a journaling session\nto follow a sequence of three stages: Rapport building , Exploration,\nand Wrap-up. The Rapport Building state is an ice-breaker, cen-\ntered on casual exchanges about a user’s day. In this state, the\nassistant also shares bits of information to encourage users’ open-\nness. This approach is based on previous research findings that a\nchatbot’s self-disclosure positively impacts user disclosure [52] and\nleverages the natural story-building ability of LLMs [99]. Overall,\nin this stage, our goal is to create an environment where users can\ncomfortably share their stories. As we progress to theExploration\nstate, the emphasis shifts to a comprehensive understanding of\nthe user’s daily events, feelings, and thoughts, facilitated by a mix\nof open-ended and closed-ended queries that ensure users remain\nengaged and in control of the dialogue. While open-ended queries\nare intended to facilitate increase the expression of feelings and\nemotion and less judgemental, closed-ended queries is for specific\nand detailed description of the experiences [66, 67].The conversa-\ntion then transitions to the Wrap-up, emphasizing completion and\nensuring users have fully voiced their experiences while the system\nremains empathetic and receptive to any lingering topics.\nBesides the three main stages, we also incorporated the Sensi-\ntive Topic state that handles the most sensitive subjects, such as\nself-harm or suicidal ideation. When this state is triggered, psychi-\natrists receive instant notifications. This allows them to oversee\nthe conversation in real-time and step in to assist the patient if\nMindfulDiary: Harnessing Large Language Model to Support Psychiatric Patients’ Journaling CHI ’24, May 11–16, 2024, Honolulu, HI, USA\nFigure 3: Use flow of MindfulDiary’s journaling session: (1) Pre-Journaling Assessment: Users undergo a mental health survey\nusing the modified PHQ-9 [ 48] before using MindfulDiary; (2) Users converse with MindfulDiary, documenting their day; (3)\nSummary Presentation: After three turns, MindfulDiary presents a diary-styled summary of the conversation so far, which\ncan also be edited by the user. Users can continue the conversation as they want. (4) Session Closure: Once all processes are\ncompleted, MindfulDiary displays today’s mental health and diary content, concluding the journaling session.\nnecessary. Here, the system begins by empathizing with the user,\nrecognizing their struggles, and offering a reassuring message. Fol-\nlowing this, the system gently probes the depth of their suicidal or\nself-harm thoughts. If the user expresses intense or specific plans re-\nlated to self-harm or suicide, the system urges them to seek prompt\nassistance, either at a hospital or via the local helpline.\n4.1.3 Conversational Pipeline. Lengthy and complex input prompts\nfor LLMs are known to cause poor task performance [14] by partly\nomitting latent concepts [96]. To steer the LLM to comply with the\nconversational design we intended diligently, we designed Mindful-\nDiary’s dialogue system as a state machine. Each conversation stage\nis carried on with a dedicated input prompt, which is more succinct\nand clear than a single master prompt containing instructions for\nall stages.\nFigure 4 illustrates our conversation pipeline that runs each time\na new user message is received. The pipeline incorporates two LLM-\ndriven modules, a dialogue analyzer and the response generator .\nThe dialogue analyzer handles the stage transition, returning\nthe stage suggestion—whether to stay or move to a new stage—and\na summary paragraph of the current dialogue from the current dia-\nlogue information. The dialogue analyzer receives an input prompt\nthat consists of the current number of turns in the conversation\n(progress level), the most recent stage information, and a list of\ncriteria for recommending each stage (See 2○in Figure 4). Based on\nthis information, the underlying LLM performs a summarization\ntask that yields a summarized paragraph of the current dialogue, a\nrecommendation for the next stage based on the summary, turns,\nand the most recent stage information. For example, the system\ndecides to move to the Wrap-up stage when the user expresses a\ndesire to conclude or say goodbye.\nThe system then formulates an LLM prompt, combining a ded-\nicated prompt for the current stage, the dialogue summary, and\nthe recent six messages (i.e., three turn pairs) (See 3○in Figure 4).\nReceiving the prompt as an input, the response generator gener-\nates an AI message. The stage prompt consists of the description of\nthe task that the LLM is supposed to perform in the current stage,\nand the speaking rules describing the attitude that the module\nexhibits in the conversation. For example, the task description of\nExploration stage instructs to “ask questions that encourage\nusers to reflect on their personal stories regarding\ndaily events, thoughts, emotions, challenges, and etc.”\nThe speaking rules for the Rapport-building stage instruct to keep\nconversations simple and friendly and reply in an empathetic way.\n4.2 Pilot Evaluation\nTo ensure that MindfulDiary is reliable and safe for conversing\nwith psychiatric patients, we underwent multiple rounds of pilot\nevaluation. First, we invited five psychiatrists and three clinical psy-\nchologists to test the conversational pipeline. The experts provided\nfeedback on the instructions in the model prompts, focusing on\ntheir clinical relevance and the embedded terminology and strate-\ngies. Then, the experts inspected the chatbot’s behavior by chatting\nwith it while role-playing as a patient persona. In particular, we\nexamined the chatbot’s reactions to subtle implications of suicide\nor self-harm in user messages.\nAfter iterating on the conversational pipeline, we conducted a\npilot lab study with five patients admitted to a university hospital\nbut about to be discharged soon. To ensure safety against risky mes-\nsages from an LLM, we used a test platform where the participant’s\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Taewan Kim, Seolyeong Bae, Hyun Ah Kim, Su-woo Lee, Hwajung Hong, Chanmo Yang, and Young-Ho Kim\nFigure 4: Structure of MindfulDiary’s conversational pipeline. (1) Users respond to MindfulDiary’s messages. (2) The recent\nturn count, current state, and whole user-MindfulDiary dialogue are fed into Dialogue Analyzer. (3) Using the output of\nDialogue Analyzer, a designated state prompt, a summary of dialogue (containing overall dialogue context), and the latest three\nconversation turns are fed into Response Generator. The resulting response is then displayed to the user. Both the Dialogue\nAnalyzer and Response Generator operate based on the GPT-4 LLM.\nclinician monitored the generated messages in real-time, approving\nthem or sending better messages manually.\n4.3 Clinician Dashboard\nThe clinician dashboard (c.f., Supplementary video) is a desktop ap-\nplication designed to facilitate monitoring patient’s journal entries\nand to provide analysis of the entries to help clinicians identify\nsignificant events, reactions, and emotions. The dashboard consists\nof the following components:\nUser Engagement. This section visualizes the participant’s overall\nengagement with MindfulDiary, including the number of journals\nwritten, the date and time they were written, and their length.\nThe modified PHQ-9 scores for each session are also visualized,\nallowing professionals to track the user’s mental health trends\nusing a validated tool.\nJournals. This section displays the content of the journals written\nby patients. The information is presented in a card format, where\neach card offers a summary of the journal, including timestamps,\ntotal time taken to write the journal, and associated PHQ-9 score.\nThe interaction logs between the patient and MindfulDiary are also\nprovided in this section.\nInsights. To assist professionals in browsing through the diary, this\nsection visualizes (1) a word cloud to understand frequent terms\nthat the participant used at a glance, (2) a summary of major events\nto highlight significant happenings and (3) summary of emotions\nto gauge the mood based on user input. When a specific period is\nselected for review, a comprehensive summary is generated. We\nused GPT-4 for most summarization tasks. To generate the word\nfrequency data for the word cloud, we combined GPT-4 and a Ko-\nrean morphological analysis package named Kiwi [50] to filter only\nnouns and verbs from the GPT output. Due to the limitations of\nlanguage model-driven analysis, there might be occasional inaccu-\nracies in the generated content. First-time users of this interface\nare alerted about possible inaccuracies. An in-interface tooltip also\nreminds users that the summarized outcomes might not be accurate.\n4.4 Technical Implementation\nMindfulDiary’s interface is developed using React, a JavaScript-\nbased framework. The server, responsible for interfacing with the\nLLM and overseeing database operations, is implemented in Python.\nGoogle Firebase handles user authentication, data storage, and re-\ntrieval tasks. The conversational capabilities of MindfulDiary are\npowered by gpt-4, accessible through OpenAI’s API1. We specif-\nically used gpt-4-0613 model. For parameter setting, we consis-\ntently set the temperature to 0.7 and both a presence penalty and\nfrequency penalty to 0.5.\n5 FIELD DEPLOYMENT STUDY\nUsing MindfulDiary, we conducted a four-week field deployment\nstudy with 28 patients undergoing outpatient treatment. Through\nthe study, we aimed to explore how patients and MHPs utilize\nMindfulDiary and what opportunities and challenges arise from its\nreal-world use. The study protocol was approved by the Institutional\nReview Board of a university hospital.\n5.1 Recruitment\nWe targeted outpatients from the Department of Mental Health at\na University Hospital. Participants were selected based on specific\ncriteria: (1) those who had been diagnosed with MDD and (2) those\nwho did not exhibit heightened impulsive tendencies or harbor spe-\ncific intentions towards self-harm or suicide. Key exclusion criteria\n1https://platform.openai.com/docs/guides/gpt/chat-completions-api\nMindfulDiary: Harnessing Large Language Model to Support Psychiatric Patients’ Journaling CHI ’24, May 11–16, 2024, Honolulu, HI, USA\nincluded a history of psychotic disorders, substance-related disor-\nders, neurodevelopmental disorders, and neurological disorders.\nEligible participants were identified through evaluations conducted\nby psychiatrists. Flyers and consent forms were distributed to eligi-\nble patients. For minors, the consent form process was adhered to\nonly when they were accompanied by a guardian at the hospital.\nWe compensated participants on a weekly basis of participation:\nFor participating every seven days from the starting date, partic-\nipants received 15,000 KRW (approx. 11 USD). If they completed\nthe entire four-week study process, they received 20,000 KRW as\na bonus (i.e., 80,000 KRW—approx. 60 USD—in total). We did not\ntie the number of dialogue entries to the compensation to ensure\nnatural data entry behavior.\nTable 2: Demographic of MindfulDiary participants (P1–28).\nThe table presents gender, age, and the severity of depressive\nsymptoms represented by CES-DC (Center for Epidemiologic\nStudies Depression Scale for Children), which assesses symp-\ntoms of depression in children and adolescents. Scores were\ncategorized as follows: below 16 as Minimal , 16 and above\nas Mild , and 25 or higher as Severe [17].\nAlias Gender Age Severity of depressive symptoms (CES-DC)\nP1 F 16 Minimal\nP2 F 19 Mild\nP3 M 17 Minimal\nP4 F 17 Severe\nP5 F 14 Severe\nP6 F 17 Severe\nP7 F 16 Minimal\nP8 F 14 Mild\nP9 M 16 Mild\nP10 F 16 Severe\nP11 F 19 Severe\nP12 M 19 Severe\nP13 F 19 Mild\nP14 M 18 Severe\nP15 M 24 Minimal\nP16 F 12 Severe\nP17 F 15 Severe\nP18 F 17 Mild\nP19 F 23 Severe\nP20 M 17 Minimal\nP21 M 19 Severe\nP22 M 17 Minimal\nP23 F 28 Severe\nP24 M 17 Minimal\nP25 M 19 Minimal\nP26 F 19 Severe\nP27 M 15 Mild\nP28 F 14 Severe\nAs a minimum requirement for study completion, we instructed\nthe participants not to miss four consecutive days without convers-\ning with MindfulDiary. If a participant missed three consecutive\ndays, an experimenter sent a reminder. In cases where participants\ndid not respond to these reminders, their participation in the study\nwas discontinued. This procedure was implemented to ensure active\nmonitoring and communication. Considering that our system is de-\nsigned for individuals with mental health challenges, it was crucial\nto maintain contact with participants and ensure their adherence\nto the study protocol.\nInitially, 36 patients started using MindfulDiary. During the de-\nployment, eight dropped out as they did not meet the minimum\ndata collection requirement. These participants were disengaged\nfrom MindfulDiary due to the lack of time or decreased interest.\nAs a result, 28 participants (P1–28; 11 males and 17 females) com-\npleted the 4-week field study and were included in the analysis.\nThe majority of participants were adolescents and adults, with ages\nranging from 12 to 28 years, with an average age of 17.6 (𝑆𝐷 = 3.26).\nTable 2 presents the demographic details and severity of depres-\nsive symptoms of the study participants. These scores are derived\nfrom psychiatric evaluations conducted within one week before\nthe starting dates.\n5.2 Procedure\nFigure 5 illustrates the procedure of the field deployment study. All\ninterviews took place remotely on Zoom.\n5.2.1 MindfulDiary App. We deployed the MindfulDiary app to our\npatient participants. The patient protocol consisted of three parts:\n(1) an introductory session, (2) deployment, and (3) interviews.\nIntroductory Session. We first invited each participant to a remote\nintroductory session. A researcher went through our study goal, the\nmotivation of the MindfulDiary system, and the overall procedure\nof the study. We then played a demo video demonstrating how to\nuse the MindfulDiary app. The session took about 15 minutes.\nDeployment. The day following the introductory session, partic-\nipants started using MindfulDiary for four weeks. We instructed\nparticipants to engage with the app whenever they have anything\nnoteworthy but encouraged them to use it at the end of the day.\nWe collected all data from their interactions with the MindfulDiary\nand the raw input content and outputs from the LLM. We asked our\nparticipants to fill out online surveys three times, at the beginning\nof Week 1, after Week 2, and after the deployment, to measure\nparticipants’ mental health status and their self-help capability in\nmanaging their mental health. The surveys utilized the PHQ-9 [48],\nGAD-7 [85], and Coping Strategies Scale [98]. (The survey results\nfrom the scale are outside the scope of this investigation.)\nMid-study and Debriefing Interviews. We conducted two 15-\nminute interviews, after the second and fourth weeks, with each\nparticipant to understand their experiences and learn how they\nused MindfulDiary on a daily basis. Considering the characteristics\nof depression patients, who may struggle to focus for long periods\nof time, the interview session was divided into two shorter sessions.\n5.2.2 Clinician Dashboard. Most patient participants had a clinical\nvisit during Week 2 through Week 4 of the deployment period. We\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Taewan Kim, Seolyeong Bae, Hyun Ah Kim, Su-woo Lee, Hwajung Hong, Chanmo Yang, and Young-Ho Kim\nFigure 5: Procedure of the four-week field deployment study: A four-week exploration into the utilization of MindfulDiary by\noutpatient patients, encompassing daily use, and its integration into clinical decision-making. We note that some participants\ndid not have a follow-up visit during the experimental period. The surveys are outside the scope of this work’s investigation.\ndeployed MindfulDiary’s clinician dashboard to five psychiatrists\nwho are in charge of the participants.\nDeployment of Clinician Dashboard in Clinic. We provided\ninstructions to clinicians covering the main components of the\nclinician dashboard and how to interact with them. To explore the\nopportunities and limitations of the dashboard, we did not offer\nexplicit instructions for utilizing the clinician dashboard in their\nworkflow. However, we advised psychiatrists to be cautious with\nthe LLM-driven analysis due to potential inaccuracies, emphasiz-\ning the importance of verifying data through the interaction logs.\nThe psychiatrists autonomously utilized the clinician dashboard,\nmaking sure it didn’t disrupt their current treatment methods and\npreparation routines.\nDebriefing Interviews. We interviewed psychiatrists who treated\nthe patient participants to understand how they used the clinician\ndashboard in clinical settings. We further gathered feedback from\nthe psychiatrists on the opportunities and limitations of Mindful-\nDiary, as well as suggestions for improvements. The interviews\nwith the psychiatrists were conducted offline for about one hour\nafter the deployment study concluded.\n5.3 Analysis\nTo explore participants’ usage patterns with MindfulDiary, we first\nconducted a descriptive statistics analysis. To determine any shifts\nin participants’ adherence over time, we examined weekly writ-\ning frequencies using a one-way repeated measures ANOVA (RM-\nANOVA) with Greenhouse-Geisser correction. To gain a deeper\nqualitative understanding of the messages produced by Mindful-\nDiary and interviews with patients and psychiatrists, we used open\ncoding paired with thematic analysis [ 13]. For a more in-depth\nqualitative analysis of the messages produced by MindfulDiary\nand the interviews with patients and psychiatrists, we employed\nopen coding paired with thematic analysis [13]. All interviews were\naudio-recorded and transcribed for this purpose.\nThe qualitative analysis was conducted by the first author, a\nPhD student in HCI, who open-coded the interview transcripts\nand interaction log data through multiple rounds of iteration. An-\nother author who holds a PhD degree in HCI also contributed to\nthis coding process. Following the initial coding, two psychiatrists\nreviewed the coded data to provide clinical insights and ensure\nthe accuracy of interpretations. Through discussions among the\nresearch team, including these diverse perspectives, overarching\nthemes were identified, enhancing the depth and validity of our\nqualitative findings.\n5.4 Ethical Considerations\nConducting this study, we are fully aware of the inherent risks\nassociated with our research, particularly given the characteristics\nof participants diagnosed with MDD. To mitigate the risks, we first\ncarefully screened participants, relying on evaluations conducted by\npsychiatrists. Individuals displaying heightened impulsive tenden-\ncies or harboring specific intentions towards self-harm or suicide\nwere excluded from the study. In addition, participants were asked\nto take the PHQ-9 before interacting with MindfulDiary, along with\nan additional set of questions probing their recent attempts at self-\nharm or suicide. If a participant’s response to question number 9 of\nthe PHQ-9, regarding suicidal/self-harm thoughts, scored ‘moderate\nor higher’ or if any recent suicide attempt was verified, the system\npivoted to provide content geared towards alleviating anxiety and\nreducing stress rather than proceeding with the standard system.\nIn such a case, a real-time alert was also sent to psychiatrists. Lastly,\nif sensitive themes frequently surfaced in a participant’s input dur-\ning the study, their interactions with the system were temporarily\nhalted. Psychiatrists subsequently re-evaluated such participants\nto assess the viability of their ongoing participation. During our\nexperiment, for the case of P11, mentions of repetitive suicide and\nself-harm were detected. Consequently, an expert contacted the\nparticipant, the experiment was suspended for three days, and after\na re-evaluation in an outpatient clinic, we resumed the system use\nwith P11.\nFurther, to mitigate potential risks from the LLMs’ outputs, we\nembraced an iterative design methodology. The system’s interac-\ntions underwent repeated assessments to ensure it generated safe,\nnon-harmful outputs. In addition, in the first week of each par-\nticipant’s system use, all interactions between participants and\nMindfulDiary were observed in real time. To facilitate this process,\nMindfulDiary: Harnessing Large Language Model to Support Psychiatric Patients’ Journaling CHI ’24, May 11–16, 2024, Honolulu, HI, USA\nWeek 1\nWeek 2\nWeek 3\nWeek 4\nP3\n27\nP28\n27\nP2\n26\nP19\n26\nP1\n25\nP5\n24\nP11\n24\nP21\n21\nP23\n21\nP25\n21\nP6\n19\nP16\n19\nP4\n17\nP7\n17\nP10\n17\nP24\n16\nP9\n15\nP17\n15\nP18\n15\nP26\n15\nP8\n13\nP12\n13\nP22\n13\nP15\n12\nP13\n11\nP20\n11\nP27\n11\nP14\n10\n# of days with dialogue\nWeekday\nWeekend\nFigure 6: Overview of daily engagement of participants with MindfulDiary. The colored squares denote the days that participants\nconversed with MindfulDiary, with darker colors indicating weekend days. The bar charts on the right visualize the total\nnumber of days with interaction against the four-week study period. Participants are sorted by the number of days with\ninteraction.\nwhen a participant started the session, the research team received\na notification email. This notification included real-time monitor-\ning links and reports of the survey responses that participants\nanswered before each session. After the first week, user interac-\ntions and MindfulDiary were reviewed within a 12-hour window.\nDuring the review process, if an interaction contained sensitive con-\ntent (specifically, terms pre-defined as sensitive by psychiatrists),\nthe psychiatrists on our research team assessed the situation and\ncontacted the affected participants if necessary.\nLastly, given that we were handling the patients’ personal and\nsensitive data, ensuring the secure protection and management of\ndata was critical. Therefore, during the study, we utilized the Google\nFirebase authentication service to manage the user authentication\nprocess for participants. We were thus able to ensure that only\nauthorized personnel had access to the data, and any attempts\nat unauthorized access could be promptly detected and managed.\nAfter the field study, all data was separated from personal identifiers\nto maintain anonymity.\n6 RESULTS\nIn this section, we report the results of the field study in four parts:\n(1) Journaling adherence, (2) Dialogue patterns, (3) Patients’ perspec-\ntives on MindfulDiary, and (4) MHPs’ perspectives of MindfulDiary\nfor clinical settings.\n6.1 Journaling Adherence\nFigure 6 summarizes the daily engagement of participants with\nMindfulDiary over the course of four weeks. The colored squares\ndenote the days that participants conversed with MindfulDiary (i.e.,\ndays with interaction). Across four weeks, participants submitted\n501 journal entries (17.90 entries per participant on average), 0.62\nentries on average per day (more than once every two days). 22\nout of 28 participants used MindfulDiary more than once every\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Taewan Kim, Seolyeong Bae, Hyun Ah Kim, Su-woo Lee, Hwajung Hong, Chanmo Yang, and Young-Ho Kim\nTable 3: Categorization of LLM’s strategies for generating prompts to encourage user reflection, including descriptions and\nexemplar questions. Strategies include Emotional Exploration, Activity Exploration, In-depth follow-up, and Future Plan\nExploration with associated descriptions and examples\nCategory Description Example\nEmotional\nexploration\nMessages that further inquire about the user’s emotional state,\nmood, and condition.\n“How did you feel after meeting her?”\n“Can you tell me how this situation makes you feel?”\nActivity exploration Messages exploring the user’s experiences or activities. These\nquestions delve into more objective and factual content.\n“What kind of exercise do you do?”\n“Lunch with a friend sounds nice. What did you eat?”\nIn-depth follow-up Messages that help delve into the root causes or reasons related\nto mood, feeling, or specific situations.\n“Since when have you felt this overshadowed mood?”\n“If you feel confused, what might be the reason?”\nFuture plan\nexploration\nMessages inquiring about how the user reacted to or plans to\nrespond to the events or emotions they mentioned.\n“That situation must have been challenging. Have you\nconsidered any solutions?”\n“What have you done to alleviate the loneliness, even\njust a bit?”\ntwo days. Participants generally engaged with the app at a regular\nfrequency, but we note that their engagement was also affected by\nthe three-day-miss reminder and their visit to the clinic between\nWeek 2 and 4. Each journaling session lasted an average of 438\nseconds (around 7 minutes) but with notable individual variability\n(𝑆𝐷 = 225.97). Each journal dialogue included messages with an\naverage of 105.6 syllable count (𝑆𝐷 = 49.41). Our analysis did not\nreveal significant differences in either the participants’ input length\n(𝐹(1.735,46.85) = 2.718, 𝑝 = .084) or writing time (𝐹(2.417,65.25) =\n2.549, 𝑝 = .076) across the four different time points, as determined\nby the RM-ANOVA test. This suggests that users mostly retained a\nsteady level of engagement during the four-week study.\n6.2 Dialogue Patterns\nParticipants and MindfulDiary exchanged a total of 4,410 messages\n(i.e., 2,205 pairs of the AI and participant’s messages) during the\nfield study. Each session consisted of 10.82 messages (𝑆𝐷 = 2.70).\nMost exchanges between the AI and participants were carried on\nfor an exploration of patients’ daily lives and emotions, as well as\nfor casual conversations. In terms of the stage of the conversation,\n62% (2,732 messages) of the messages were from Exploration, 30%\n(1220 messages) for Rapport building, and 6% (282 messages) for\nSensitive topic. Only a small amount of messages were accounted\nfor Wrapping up (62 messages) or not selected (14 messages).\nTo understand the contents that MindfulDiary generated, we\ndelved deep into the content it generated. 72% of the AI messages\ntook the form of questions, aiming to elicit responses about users’\ndaily experiences and emotions. We identified and categorized the\nprimary strategies that MindfulDiary employed to assist patients’\njournaling. There were four strategies employed by the LLM: Emo-\ntional Exploration, Activity/Behavior Exploration, In-depth Follow-up\n& Countermeasures , and Future Plan Exploration . For a comprehen-\nsive breakdown of these strategies, along with their descriptions\nand exemplar questions, refer to Table 3.\nThe average length of participants’ responses was 29.42 syllable\ncounts, with a median of 20 (𝑆𝐷 = 35.9). This suggests a left-skewed\ndistribution, where many participants gave shorter responses and\na smaller number provided considerably longer answers, causing a\nhigh variation. The minimum response length was one character,\nand the maximum was 559 syllable counts. We further conducted\na qualitative analysis of these responses, seeking to identify the\nthemes present in users’ interactions with the LLM. This allowed\nus to understand the scope and topics of the daily records that\nMindfulDiary collected from the patients.\nParticipants interacting with MindfulDiary conveyed a range of\ntopics (see Table 4). They described a spectrum of emotional states ,\nfrom negative feelings like exhaustion and anxiety to positive senti-\nments of pride and joy.Events and activities were recounted, offering\ninsights into their daily routines, such as walking during school\ntimes or decreased activity post-vacation. They also sharedthoughts\nand beliefs , sometimes related to current events, revealing patterns\nlinked to mental health, like feelings of exclusion and loneliness. Re-\ngarding perceived health status , comments spanned from immediate\nailments, such as headaches, to long-term health challenges. Dis-\ntorted perceptions about their body included content on excessive\ndieting. Specifically, participants frequently discussed medications,\nrevealing not just their physical reactions but also their perceptions\nand behaviors toward them. Some expressed concerns over the\ntaste, while others mentioned adverse reactions from intake, like\ndiscomfort after swallowing multiple pills at once. Lastly, the realm\nof relationships & interactions had participants highlighting both\nthe challenges and supports in their interpersonal connections, re-\nvealing their significant impact on mental well-being, from conflicts\nand trust issues to moments of affirmation and encouragement.\n6.3 Patients’ Perspectives on MindfulDiary\nOverall, participants viewed MindfulDiary as a space where they\ncould open up and share their stories, feeling a sense of empathy\nfrom the system. Participants particularly found the dialogue-driven\ninteractions with MindfulDiary useful. One participant, P15, men-\ntioned, “If it was just about recording daily activities or emotions\nlike a regular diary, it might have been less engaging, and I could’ve\nfound it tedious or might not have persisted for long. But this felt like\nhaving a conversation with AI, which added an element of fun and\nkept me engaged in continuous use. ” Such a dialogue-driven journal-\ning process aided participants in maintaining consistent records\nand helped in forming a habit consistent with our user engagement\nanalysis. P7 stated, “I liked chatting with the AI at first, so I kept\nusing it. The more I used it, the more it became a habit. ”\nMindfulDiary: Harnessing Large Language Model to Support Psychiatric Patients’ Journaling CHI ’24, May 11–16, 2024, Honolulu, HI, USA\nTable 4: Summary of Participants’ Input Messages: Categories include Emotional States, Events & Activities, Thoughts & Beliefs,\nPerceived Health Status, and Relationships & Interactions with associated descriptions and examples\nCategory Description Example\nEmotional states\nThe emotions that participants documented in their daily\nlives encompassed a broad spectrum, ranging from nega-\ntive and depressive sentiments.\n“I’m so exhausted, I feel like I’m reaching my limit soon. ”\n“I’m very worried, scared, and anxious. ”\nEvents and activities The mentions of events, tasks, or activities they partici-\npated in or witnessed, such as exam periods or travel.\n“When I attended school, I got some walking in, but after\nvacation, I don’t have much reason to go out, leading to a\ndecreased activity level. ”\nThoughts and beliefs\nThe thoughts, values, beliefs, and convictions they usually\nheld. Including characteristic thought patterns related to\nmental health, such as distorted thinking.\n“I feel like someone is talking behind my back somewhere;\nthey don’t like my actions and seem to exclude me. ”\nPerceived health status\nThe physical state and health concerns, misconceptions\nabout their health, reactions to medications, revealing their\nperceptions, behaviors related to drug intake.\n“I’ll starve and exercise to lose weight!”\n“I just took my medicine, but it seems to be getting tasteless. ”\nRelationships & interactions\nThe contents about relationships with others. Difficulties\nstemming from interpersonal relationships, as well as the\nsupport and affirmation received from those around them.\n“I hated seeing my brother being happy. Forcing a cheerful\ntone also irked me. ”\n6.3.1 Broad Conversational Range: The Versatility in Documenting\nDiverse Interests. Our participants appreciated the LLM’s flexibility\nand naturalness in responding to various utterances, topics, and sit-\nuations. Such broad conversational capabilities of the LLM provided\nparticipants with a space where they could document a variety of\nsubjects tailored to individual interests and preferences. In our\nstudy, participants interacted with the LLM on diverse topics rang-\ning from games, webcomics, novels, and movies (see Dialogue 1) to\nhobbies like Pilates (see Dialogue 2), allowing them to create richer\nand more personal records. P3 remarked, “AI systems that I have\nused in the past could only respond to specific words, but it is amazing\nhow this one can respond to all sorts of things. ”\nP15\nIn the afternoon, I watched movies with my family. We watched two\nfilms, Asura and The Witness, which were both quite interesting and\nthrilling.\nAI\nWatching movies with family probably made it more enjoyable.\n’Asura’ and ’The Witness’, must have been exciting to watch, since\nthey are both known for their strong stories!\nDialogue 1.Dialogue snippet from P15\n6.3.2 Expanding Views: Enriching Entries with Varied Perspectives.\nParticipants also valued the diverse and new perspectives that LLM-\ngenerated responses offered, as those helped participants reflect\non their struggles, daily events, and emotions from various angles.\nDialogue 3 shows how the system helps the participant to view the\nchallenges of studying from the perspective of the satisfaction felt in\ngaming. This influence helped participants diverge from ruminating\non depressive feelings. P12 mentioned, “Sometimes when you note\ndown emotions, that’s the only thought that comes to mind. Beyond\nthat, I don’t remember much. Since MindfulDiary uses AI, my thoughts\nflow more easily, and I like it when it asks about different perspectives\nor topics. ”.\nP5 I’ve been dancing to exercise, but I don’t think it’s enough.\nAI Dance is a fun and nice form of exercise. But if you feel it’s lacking,\nWhy do you think you feel that way?\nP5 I want to exercise by learning from others, like in Pilates.\nAI You’ve become interested in Pilates. Can you tell me what makes\nPilates interesting to you?\nP5 I would like to do Pilates, but I can’t because there’s nowhere to do it.\nAI That must be a difficult situation. What about exercising at home?\nThere are many Pilates videos available.\nP5 I hadn’t thought of following along with videos.\nDialogue 2.Dialogue snippet from P5\nAI Such ordinary days accumulate to form our daily lives. What\nemotions do you feelwhen you study or play games?\nP2\nI don’t like studying, but I’m working hard dreaming about the college\nI want to go to. Games are, of course, fun and I feel proud when my\ncharacter grows.\nAI So, studying can be seen as an investment for the future.\nP2 Right, studying is an investment for the future.\nAI How does it feel when your game character grows? Can you bring\nthat feeling to studying too?\nP2\nThe feeling of my game character growing makes me proud, as if I’ve\nachieved something. I feel the same pride when I complete my daily\nstudy goals.\nAI How about continuing to study with that sense of pride? Could it\nbring the same sense of achievement?\nP2 Based on this pride, I plan to focus more on my studies. It won’t be\neasy, but setting clear goals can lead to faster achievements.\nDialogue 3.Dialogue snippet from P2\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Taewan Kim, Seolyeong Bae, Hyun Ah Kim, Su-woo Lee, Hwajung Hong, Chanmo Yang, and Young-Ho Kim\n6.3.3 Probing for Depth: Prompt Questions in Detailed Reflection.\nMindfulDiary’s question-driven journaling process was also valued\nby participants as it assisted them with the process of daily reflec-\ntions and documentation. Compared to their past experiences of\njournaling, where they had to reflect on their daily life by them-\nselves, participants appreciated that MindfulDiary made the jour-\nnaling process less daunting. P27 said, “Because I have to rely solely\non my thoughts when I write alone, I sometimes get stuck. But when I\nwas unsure about how to write, the AI helped me. I liked that part. ” .\nThe questions posed by MindfulDiary also guided participants in\ndocumenting their daily lives in a more detailed manner by asking\ntheir thoughts and feelings about a particular event (See Dialogue 4).\nSuch probing allowed for richer, more in-depth entries. P13 shared,\n“I used to write diaries on my own and just wrote whatever came to\nmind. MindfulDiary, however, helped me write in more detail because\nof the specific questions. ”\n[...]\nP13 I felt so pathetic and wanted to know why I was acting this way.\nAI It must have been really tough to go through such feelings. Does this\nhappen often?\nP13 It seems to have gotten worse recently.\nAI I see. Do you have any thoughts on why it’s getting worse?\nP13 Lately, I’ve been mentally exhausted and stressed a lot.\nAI That sounds really difficult. Can you tell me the sources of your\nstress?\nP13 Issues with my dorm, relationships with my friends, and worries\nabout the future.\nAI It must be hard with all these concerns overlapping. What’s the most\npressing issue for you right now?\nP13 These days, I am very concerned about my relationships with friends.\nAI I understand your worries about friendships. What is your biggest\nconcern?e\nP13 I feel like people are talking behind my back, disliking my actions,\nand excluding me from gatherings, which makes me feel very lonely.\n[...]\nDialogue 4.Dialogue snippet from P13\n6.3.4 Building Narratives: Structuring Daily Reflections with Mind-\nfulDiary. MindfulDiary’s capabilities, such as generating contex-\ntualized follow-up questions and summarizing the conversation,\nmade the process easier for participants who struggled to organize\ndaily thoughts and events underpsychotherapy [23]. In their past\nexperiences, our participants expressed difficulties in journaling\nbecause of disjointed thoughts, a lack of clarity in ideas, or incon-\nsistencies in their stories. However, with the support of the LLM\nin the MindfulDiary, these challenges were addressed, motivating\nthem to record their daily lives persistently. P3 remarked, “ I often\nhad trouble putting sentences In the past, I would worry about writing\nthe next part. But with this tool, I just tell the story of my day, and\nit seamlessly continues and wraps it up, presenting a well-structured\ndiary entry. That’s its biggest advantage. \" (See Dialogue 5)\n[...]\nP3 The most memorable thing today was my dad eating the cake and\nfood I made yesterday and saying it was delicious.\nAI How was the experience of making the cake? Did you enjoy it?\nP3 The tough day turned to be enjoyable.\nAI Can you describe more about that feeling of happiness?\nP3 I felt a bit disappointed and tired while doing it, but when my dad\nliked it, I felt like I did something great and it made me happy.\n[...]\n[Generated Diary]\n“Today was a day without any special worries. The most\nmemorable thing was my dad eating and complimenting\nthe cake and food I made yesterday. That moment turned\na somewhat exhausting and difficult day into a joyful\none. My father’s praise gave me a great sense of joy\nand pride. It might be a wrong thought, but I felt\nreally great, like I am an amazing person, which was\nso nice.”\nDialogue 5.Dialogue snippet from P3\n6.4 MHPs’ Perspectives on MindfulDiary for\nClinical Mental Health Settings\nIn this section, we describe how MHPs utilized the clinician dash-\nboard and the benefits and drawbacks of the system they reported,\ndrawing on the debriefing interviews with the psychiatrists.\n6.4.1 Utilization of MindfulDiary in Clinic. During the deployment\nstudy, psychiatrists reviewed the journal entries from their patients\nevery morning when they reviewed the medical charts of patients\nwhom they would meet on the day. Depending on the severity and\nthe focal concerns of the patient, psychiatrists spent about 5 to 10\nminutes per patient reviewing the MindfulDiary data. After check-\ning trends primarily through PHQ-9 in the clinician dashboard,\npsychiatrists read summaries about events and documented emo-\ntions. If there were spikes or drops in the PHQ-9 or events/emotions,\nthey checked the actual dialogues.\n6.4.2 Percevied Benefits of MindfulDiary for Enhanced Patient In-\nsight and Empathetic Engagement. All of the psychiatrists empha-\nsized the critical value of an expert interface based on information\nrecorded in the daily lives of patients. Specifically, E3 highlighted\nMindfulDiary’s value in that it consistently aids in recording daily\nentries, allowing them to utilize more detailed patient data during\noutpatient visits. “Patients, with the support of AI, can logically con-\ntinue their narratives, ensuring more dialogue than a typical (paper-\nbased) diary. This definitely aids me in my consultations. ” (E3). In this\nsection, we further report on how MindfulDiary has been helpful\nin the clinical practice of psychiatrists.\nEnhancing Understanding and Empathy toward Patients. Psy-\nchiatrists indicated that MindfulDiary helped them gain a deeper\nunderstanding and empathy about their patients. They perceived\nthat MindfulDiary served as a questioner that could elicit more\nobjective and genuine responses from patients. Psychiatrists ap-\npreciated that the LLM was able to pose questions that might be\nMindfulDiary: Harnessing Large Language Model to Support Psychiatric Patients’ Journaling CHI ’24, May 11–16, 2024, Honolulu, HI, USA\nsensitive or burdensome for them to ask, such as patients’ nega-\ntive perceptions of their parents. E4 said: “There are times when\nit’s challenging to counter a patient’s narrative or offer an opposing\nperspective. For example, if a patient speaks very negatively about\ntheir mother, and we ask, ‘Didn’t she treat you well when you were\nyounger?’, the patient might react aggressively, thinking, ‘Why is\nthe therapist taking my mother’s side?’ However, since the LLM is a\nmachine, such concerns are minimized. ” .\nInsights from Everyday Perspectives Outside Clinical Visits.\nPsychiatrists valued that MindfulDiary provided them with an un-\nderstanding of patients’ conditions that would be difficult to gain\nduring outpatient visits. For instance, E1 appreciated that Mindful-\nDiary provided them with insights into patients’ positive feelings\nand experiences, which is typically difficult to obtain during clinical\nconsultations. “Usually, when patients come for a consultation, they\ntalk about bad experiences. Few people come to psychiatry to say, ‘I’ve\nbeen doing well. ’ Even if they have good things to say, they usually\ndon’t bring them up. But I was happy to see that there were many\npositive statements in these records, like ’I did that and felt good. ’\nEspecially in depression, the presence or absence of positive emotions\nis crucial. It’s a good sign if they show such positive responses. ” . E2\nenvisioned its potential application to medication management,\nwhich is another critical aspect of psychiatric care. He thought\nthese records could be used as a window into understanding how\npatients react to and perceive medications. For patients undergoing\ndrug therapy,“If the primary treatment method is pills, but they don’t\nseem to have an effective response or there’s a decline in medication\nacceptance, I could potentially understand the reasons for it through\nthis diary. ” (E2).\nUnderstanding Patient Progress Through Consistent Record-\nKeeping. Feedback from patients highlighted that interactions with\nMindfulDiary made it easier for patients to maintain a consistent\nrecord, as it mitigated the challenges associated with recording.\nPsychiatrists perceived that having consistent daily data offered\nthem opportunities to observe trends in a patient’s condition. E2\nsaid: “From our perspective as clinicians, even though we might only\nsee a patient once a month, having access to a record of how they’ve\nbeen throughout the month would allow us to track their progress,\nwhich is highly beneficial. ” . In particular, the ability to examine\nchanges not only through quantitative tools like the PHQ-9 but\nalso using a qualitative approach can offer a comprehensive under-\nstanding and shed light on the mechanisms influencing a patient’s\nmental health.\n6.4.3 Perceived Concerns about MindfulDiary. While MHPs gen-\nerally appraised the utility of the MindfulDiary positively, they\nalso raised concerns regarding the integration of MindfulDiary into\nclinical settings.\nSignificance of Tone and Manner in Patient Data Analysis.\nAlthough patient data summarized and extracted in the expert\ninterface effectively aided in understanding the patient, experts\nthought that the summarized texts would not convey the patient’s\ntone, pace, and other nuances, which are integral to the Mental\nStatus Examination (MSE) that clinicians utilize. However, MHPs\nidentified the opportunity to perform such analysis from the raw\ndata that patients entered. As the MSE measures objective and\nquantitative aspects, incorporating such an analysis could make\nsignificant improvements in understanding the patient. E1 said, “In\nthe same way as P14, understanding the tone of this patient may also\nbe possible. That’s because we use something called psychiatric MSE,\nwhere we observe more than just the patient’s appearance, such as\ntone, pace, and more. Even a short analysis of one’s linguistic behavior\nwould be great. ”\nPotential Misuses and Concerns around MindfulDiary. In our\nfield study, one patient participant perceived the MindfulDiary as a\nchannel to convey their intentions and situations to their psychi-\natrist. Specifically, the participant, P9, talked to their psychiatrist,\n“Have you seen what I wrote?\" , which indicated that the patient\nwas actively attempting to share their current state and situation\nthrough MindfulDiary. In spite of the fact that such usage did not\nseem problematic per se, one psychiatrist raised concerns about\nthe possibility that patients with borderline personality disorders\nmight misuse MindfulDiary as a weapon to manipulate others, such\nas their providers and parents. “In some cases, people self-harm out\nof genuine distress, but others do it to manipulate others, instilling\nguilt in them so they’ll do what they want. There are some patients\nwho write about their distress with sincerity, while there are some\nwho exaggerate their distress in order to get attention. ” For patients\nexhibiting symptoms of schizophrenia or delusions, there was a\nconcern that MindfulDiary’s feature of revisiting past entries could\nact as a feedback loop, developing and amplifying their delusions.\nE2 said, “This diary lets you revisit and organize your past actions. For\nschizophrenia patients with delusions or unique beliefs, referencing\npast writings might reinforce their pre-existing delusions. Reaffirm-\ning ’Yes, I’m right’ can be problematic. The LLM’s summaries could\nexacerbate these delusions if they emphasize distorted content. ”\n7 DISCUSSION\nIn this study, we present MindfulDiary, an LLM-driven journal de-\nsigned to document the daily experiences of psychiatric patients\nthrough naturalistic conversations. Here, we reflect on the opportu-\nnities presented by LLM-driven journaling for psychiatric patients\nand discuss considerations for integrating an LLM-driven patient\nsystem into the clinical setting.\n7.1 Guiding Patient Journaling through\nConversations Offering Diverse Perspectives\nOur study highlighted the potential of MindfulDiary in clinical set-\ntings, mainly where adherence to interventions is important [62].\nCore symptoms of depression, such as loss of energy, difficulty\nin carrying out mental processes, and feelings of apathy, often\ncontribute to lower adherence to a professional’s advice or inter-\nvention [43]. Clinicians who participated in our FGI also highlighted\nthese challenges in motivating patients to utilize the diary writing\napp. Our findings demonstrated that MindfulDiary helped miti-\ngate these challenges by transforming the conventional journaling\nprocess into engaging conversations. Using MindfulDiary, users\nwere able to engage in conversations with the system by answering\nprompts and questions, which made them feel the journaling pro-\ncess was more accessible and intriguing. This active participation\nensures that the users are not overwhelmed by the task and are\nguided in documenting their feelings and experiences more richly.\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Taewan Kim, Seolyeong Bae, Hyun Ah Kim, Su-woo Lee, Hwajung Hong, Chanmo Yang, and Young-Ho Kim\nDepression often locks patients into negative and rigid thought\npatterns [12]. Such patterns, resistance to change established thought\nparadigms, can severely limit a patient’s ability to perceive issues\nfrom multiple angles, leading to a harsh self-judgment [ 61]. Our\nstudy highlighted that the varied perspectives offered by LLM-\ndriven chatbots like MindfulDiary could help challenge such fixed\nviewpoints [33]. By prompting users to revisit their initial evalua-\ntions or suggest alternative viewpoints, these chatbots could help\nbreak the cycle of cognitive rigidity. While our research underscores\nthe promising role of LLM-driven chatbots in assisting psychiatric\npatients’ journaling process, it’s essential to note that these are\npreliminary findings. More work is needed to substantiate these\nfindings in a clinical context.\n7.2 MindfulDiary as a Facilitator for Fostering\nPatient-Provider Communication\nStudies have suggested that sharing the data captured via chat-\nbots with others, such as health professionals and family members,\ncould further serve as an effective mediator that helps convey more\ntruthful information [52, 56]. For instance, patients consistently\ndisplayed deep self-disclosure through chatbots, whether or not\nthey intended to share their inputs with health professionals [52].\nAligned with prior work on PGHD [ 20, 64], MHPs in our study\nalso perceived that MindfulDiary has shed light on patients’ daily\nevents, emotions, and thoughts that might have been difficult to\ngain through regular clinical visits. This data offered MHPs valuable\ninsights into the patient’s experiences and context.\nBuilding on these findings, we could expand the potential pre-\nsented by MindfulDiary in patient-provider communication. In the\nfield of personal health informatics, existing research highlights\nthe role of technology, such as photo journaling, in managing con-\nditions like Irritable Bowel Syndrome. This tool not only empowers\npatients to record their daily experiences more effectively but also\nfosters enhanced collaboration between patients and healthcare\nproviders [18, 79]. Such tools serve as vital artifacts in negotiat-\ning the boundaries of patient-provider interactions (i.e., boundary\nnegotiating artifacts) [19].\nThis work adds a new dimension to this discussion by showing\nhow LLM-assisted journaling lowers barriers to generating health\ndata in daily life and fosters patient understanding. Specifically, we\nfound that through this system, patients and providers can collabo-\nratively reflect on mental health conditions. In the context of the\nstage-based model of personal informatics, the patient module in\nour MindfulDiary helps patients reduce the burden of collecting\ndaily data and supports deeper recording. The expert module’s dash-\nboard allows for the combined and transformed processes of diary\ndata, survey data, and quantitative engagement data, supporting\nMHPs’ integration and reflection. Collaborative data generation and\nutilization with patients can enable care that reflects the patient’s\nvalues and the characteristics of their daily life. These insights serve\nas a basis for patient-provider collaboration.\nHowever, our study findings underscore the importance of care-\nful consideration in the clinical integration of systems like Mind-\nfulDiary. While we did not observe patients exaggerating their\nconditions or needs, this potential issue was raised as a concern\nby MHPs. They expressed apprehension about the possibility that\nsharing journal content with MHPs through MindfulDiary might\nlead some patients to exaggerate their conditions or needs. This\nconcern highlights the need to consider not only the design of chat-\nbots that facilitate patient disclosure behavior but also the complex\ndynamics between patients and providers in clinical settings. It\nis crucial to address these dynamics to ensure the effective and\nsafe use of such technologies in mental health care. The growing\nprevalence of chatbots in mental health domains emphasizes the\nneed for a holistic approach to their design and implementation.\nWe highlight that engineers and MHPs need to collaborate closely,\nensuring that these tools are not only technically sound but also\ntailored to meet the intricate dynamics of clinical settings [87].\n7.3 Considerations for Integrating LLMs into\nClinical Settings\nIn this section, we discuss the consideration for integrating LLMs\ninto clinical mental health settings, drawing insights from the de-\nsign and evaluation of MindfulDiary.\nAligning Domain Experts’ Expectations of LLMs. Developing\nand deploying MindfulDiary, we learned that aligning MHPs’ ex-\npectations with the capabilities and limitations of LLMs involves\nsignificant challenges. The capability of generative language mod-\nels to improve mental health is difficult to measure in comparison\nwith AI models in other medical domains, where objective metrics\ncan determine performance. For instance, in medical imaging, AI\ncan be evaluated based on its accuracy in identifying target diseases\nfrom MRI scans, using precise numerical percentages of correct\nidentifications [83]. On the other hand, in the realm of mental\nhealth chatbots, gauging success is more nuanced, as it involves\nsubjective interpretations of emotional well-being and psychologi-\ncal improvement, which cannot be easily quantified or compared\nin the same straightforward manner. This challenge is amplified in\nmental health, where soft skills like rapport building and emotional\nobservation are important [ 30]. The use of LLMs in the mental\nhealth field is emerging, but little has been said about evaluating\nor defining the performance of models that are tailored to mental\nhealth. Our iterative evaluation process involving MHPs could in-\nform researchers about how to develop and evaluate LLM-mediated\nmental health technology. When integrating into the clinical setting,\nthis evaluation is also necessary for anticipating who the system\nwould target and for what purpose it would be used. Hence, we\nadvocate that engineers and researchers should carefully consider\nhow to assist domain experts, who may lack AI expertise, in fully\nand accurately grasping the role and operation of LLM. It is also\ncrucial for researchers and engineers to collaborate closely with\nthese professionals to ensure the technology aligns with therapeutic\nneeds and best practices [87].\nTailored LLM Evaluation for Clinical Mental Health Domains.\nThe domain of mental health, which our study addresses, is char-\nacterized by the vulnerability of its target user group. The content\ndiscussed within this domain is often emotionally charged and\nsensitive. Therefore, prioritizing user safety becomes even more\nessential in this domain than in others. Considering the sensitivity\nof the domain, during our evaluation process, MHPs thoroughly\ntested the LLM’s output by trying out conversations on various\nsensitive topics in both implicit and explicit ways, drawing upon\nMindfulDiary: Harnessing Large Language Model to Support Psychiatric Patients’ Journaling CHI ’24, May 11–16, 2024, Honolulu, HI, USA\ntheir clinical experiences. The contents the MHPs input were much\nmore diverse and wide-ranging than what engineers could gener-\nate during the development. Additionally, MHPs showed concern\nthat the hallucinations of the LLM could reinforce or expand the\ndelusions of patients with delusional disorders. We highlight that\ndeveloping evidence-based tests or benchmark sets to anticipate\nthe behavior of the language models in collaboration with MHPs is\ncritical when leveraging LLMs for clinical mental health settings.\nIncorporating Perspectives of MHPs in Testing and Monitoring.\nConsidering the caveats of current LLMs [47], it is critical to involve\nMHPs when deploying LLM-driven systems for patients in men-\ntal health contexts. While planning the field deployment study of\nMindfulDiary, we identified specific roles that MHPs could play. In\nthe pre-use phase, MHPs should determine the suitability of users\nand facilitate the onboarding process with patients. During the\nmid-use phase, they should closely monitor interactions with the\nLLM and be prepared to intervene in cases of crises or unexpected\nuse scenarios. Furthermore, they can offer or adjust treatments\nperiodically based on long-term data. Additionally, they should\nregularly re-evaluate the continued use of the system. While some\nof these tasks should carefully be designed not to burden MHPs too\nmuch, it is important that LLMs do not make autonomous decisions\nabout patients (e.g., diagnosis, prescription, or crisis management)\nbut instead operate under professional oversight.\nProviding Safeguards for Hallucinated LLM Generations. Our\nclinician dashboard provided various summarized information, such\nas word cloud, aggregating multiple dialogue entries so that the\nclinician quickly grasps the gist of the dialogues. Although we un-\nderwent intensive testing with the LLM-driven data summarizer,\nthe LLM-driven data processing may still suffer from inaccuracies,\nbiases, and misinterpretation [40, 75] of patient sentiments or con-\ntext, which could adversely affect treatment decisions and patient\nwell-being. To mitigate such drawbacks of LLMs in our study, we\nprovided sufficient guidance to MHPs, cautioning them that the\nLLM-generated information they receive may be error-prone. How-\never, in real-world settings, MHPs might accept the outputs of LLM\nwithout much attention. Therefore, when involving LLM-driven\ndata processing, the system should foster careful reviewing of the\ncontent based on the expertise of MHPs. For example, future sys-\ntems could incorporate features like highlighting in vivo phrases\nthat were directly mentioned by patients and signify key aspects of\ntheir experience and feelings. By contrasting the in vivo phrases\nwith the LLM’s original text, the system can encourage MHPs to\nput more scrutiny on the LLM’s original interpretation, which may\ncontain errors, and the actual inputs spoken by patients.\n7.4 Limitations and Future Work\nOur recruitment method could impact the generalizability of our\nfindings, as we recruited the patient participants for our field study\nfrom a single university hospital. Although we aimed to recruit\npatients with diverse types and levels of symptoms, our participants\nare not representative samples of psychiatric patients. They were\nyoung (mostly adolescents) and consulted by a fixed number of psy-\nchiatrists. While this work is just a first step toward designing an\nLLM-driven journaling app for psychiatric patients, further investi-\ngation is necessary with subjects from various backgrounds. To im-\nplement our pipeline, we used OpenAI’s GPT API, which provided\nthe most capable LLM at the time of our study and was accessible\nvia commercial API. As GPT models are continually updated, later\nmodels may not yield the same conversational behavior. To gener-\nalize the performance of our conversational pipeline design, future\nwork is needed to compare multiple versions of MindfulDiary with\ndifferent underlying LLMs.\n8 CONCLUSION\nIn this paper, we designed MindfulDiary to assist psychiatric pa-\ntients undergoing outpatient treatment with journaling in their\ndaily lives. Keeping the clinical mental health setting in mind, our\nsystem was developed in collaboration with MHPs, from the initial\nconcept building to the design of LLM’s conversation flow and eval-\nuation. MindfulDiary leverages a stage-based LLM-driven chatbot,\nenabling patients to interact through prompt questions and answers,\nwhile complying with guidelines based on MHPs and literature. We\nconducted a field deployment study with 28 patients over 4 weeks.\nWe found that the versatility, narrative-building capability, and\ndiverse perspectives provided by MindfulDiary assisted patients\nin consistently enriching their daily records. The enriched records\nfrom MindfulDiary provided psychiatrists with deeper insights,\nenhancing their understanding and empathy toward their patients.\nWe hope that this research provides a case study and insight into\nthe development of an LLM-driven chatbot for mental health that is\nclinically relevant and reflects the needs and experiences of MHPs.\nACKNOWLEDGMENTS\nWe thank our study participants for their time and efforts. We\nalso thank Eunkyung Jo and Yubin Choi for providing feedback\non the early draft of this paper. This work was supported through\na research internship at NAVER AI Lab, and in part supported\nby a grant of the Korea Health Technology R&D Project through\nthe Korea Health Industry Development Institute (KHIDI), funded\nby the Ministry of Health & Welfare, Republic of Korea (grant\nnumber : HI22C1962) and by the National Research Foundation\nof Korea grant funded by the Ministry of Science and ICT (No.\n2022R1G1A1009100).\nREFERENCES\n[1] Alaa A. Abd-alrazaq, Mohannad Alajlani, Ali Abdallah Alalwan, Bridgette M.\nBewick, Peter Gardner, and Mowafa Househ. 2019. An overview of the features\nof chatbots in mental health: A scoping review. International Journal of Medical\nInformatics 132 (2019), 103978. https://doi.org/10.1016/j.ijmedinf.2019.103978\n[2] Alaa A Abd-Alrazaq, Mohannad Alajlani, Ali Abdallah Alalwan, Bridgette M\nBewick, Peter Gardner, and Mowafa Househ. 2019. An overview of the features\nof chatbots in mental health: A scoping review. International Journal of Medical\nInformatics 132 (2019), 103978.\n[3] Alaa A Abd-Alrazaq, Mohannad Alajlani, Nashva Ali, Kerstin Denecke, Brid-\ngette M Bewick, and Mowafa Househ. 2021. Perceptions and opinions of patients\nabout mental health chatbots: scoping review. Journal of medical Internet re-\nsearch 23, 1 (2021), e17828.\n[4] Apple Inc. 2024. Getting Started with the Weather App on iPhone. https:\n//support.apple.com/ko-kr/guide/iphone/iph0e5ca7dd3/ios. Accessed: 2024-02-\n15.\n[5] Riku Arakawa, Hiromu Yakura, and Masataka Goto. 2023. CatAlyst: Domain-\nExtensible Intervention for Preventing Task Procrastination Using Large\nGenerative Models. In Proceedings of the 2023 CHI Conference on Human\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Taewan Kim, Seolyeong Bae, Hyun Ah Kim, Su-woo Lee, Hwajung Hong, Chanmo Yang, and Young-Ho Kim\nFactors in Computing Systems (<conf-loc>, <city>Hamburg</city>, <coun-\ntry>Germany</country>, </conf-loc>) (CHI ’23) . Association for Computing\nMachinery, New York, NY, USA, Article 157, 19 pages. https://doi.org/10.1145/\n3544548.3581133\n[6] Elizabeth Austin, Jenney R Lee, Dagmar Amtmann, Rich Bloch, Sarah O\nLawrence, Debbe McCall, Sean Munson, and Danielle C Lavallee. 2020. Use of\npatient-generated health data across healthcare settings: implications for health\nsystems. JAMIA open 3, 1 (2020), 70–76.\n[7] John W Ayers, Adam Poliak, Mark Dredze, Eric C Leas, Zechariah Zhu, Jessica B\nKelley, Dennis J Faix, Aaron M Goodman, Christopher A Longhurst, Michael\nHogarth, et al. 2023. Comparing physician and artificial intelligence chatbot\nresponses to patient questions posted to a public social media forum. JAMA\ninternal medicine (2023).\n[8] Sanghwan Bae, Donghyun Kwak, Sungdong Kim, Donghoon Ham, Soyoung\nKang, Sang-Woo Lee, and Woomyoung Park. 2022. Building a role specified\nopen-domain dialogue system leveraging large-scale language models. arXiv\npreprint arXiv:2205.00176 (2022).\n[9] Karen A. Baikie, Liesbeth Geerligs, and Kay Wilhelm. 2012. Expressive writing\nand positive writing for participants with mood disorders: An online randomized\ncontrolled trial. Journal of Affective Disorders 136, 3 (2012), 310–319. https:\n//doi.org/10.1016/j.jad.2011.11.032\n[10] David Bakker and Nikki Rickard. 2018. Engagement in mobile phone app\nfor self-monitoring of emotional wellbeing predicts changes in mental health:\nMoodPrism. Journal of affective disorders 227 (2018), 432–442.\n[11] Andrew L Beam and Isaac S Kohane. 2016. Translating artificial intelligence\ninto clinical care. Jama 316, 22 (2016), 2368–2369.\n[12] Aaron T Beck. 1979. Cognitive therapy and the emotional disorders . Penguin.\n[13] Virginia Braun and Victoria Clarke. 2006. Using thematic analysis in psychology.\nQualitative research in psychology 3, 2 (2006), 77–101.\n[14] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,\nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot learners. Advances in neural\ninformation processing systems 33 (2020), 1877–1901.\n[15] Rafael A Calvo, David N Milne, M Sazzad Hussain, and Helen Christensen. 2017.\nNatural language processing in mental health applications using non-clinical\ntexts. Natural Language Engineering 23, 5 (2017), 649–685.\n[16] Gillian Cameron, David Cameron, Gavin Megaw, Raymond Bond, Maurice\nMulvenna, Siobhan O’Neill, Cherie Armour, and Michael McTear. 2019. Assess-\ning the usability of a chatbot for mental health care. In Internet Science: INSCI\n2018 International Workshops, St. Petersburg, Russia, October 24–26, 2018, Revised\nSelected Papers 5 . Springer, 121–132.\n[17] Seong-Jin CHO, Hong-Jin JEON, Moo-Jin KIM, Jang-Kyu KIM, Uk-Seon KIM, In-\nKyoon LYOO, and Maeng-Je CHO. 2001. Prevalence and correlates of depressive\nsymptoms among the adolescents in an urban area in Korea. Journal of Korean\nNeuropsychiatric Association (2001), 627–639.\n[18] Chia-Fang Chung. 2017. Supporting Patient-Provider Communication and\nEngagement with Personal Informatics Data. In Proceedings of the 2017 ACM\nInternational Joint Conference on Pervasive and Ubiquitous Computing and Pro-\nceedings of the 2017 ACM International Symposium on Wearable Computers (Maui,\nHawaii) (UbiComp ’17) . Association for Computing Machinery, New York, NY,\nUSA, 335–338. https://doi.org/10.1145/3123024.3123197\n[19] Chia-Fang Chung, Kristin Dew, Allison Cole, Jasmine Zia, James Fogarty, Julie A.\nKientz, and Sean A. Munson. 2016. Boundary Negotiating Artifacts in Personal\nInformatics: Patient-Provider Collaboration with Patient-Generated Data. In\nProceedings of the 19th ACM Conference on Computer-Supported Cooperative Work\n& Social Computing (San Francisco, California, USA) (CSCW ’16) . Association\nfor Computing Machinery, New York, NY, USA, 770–786. https://doi.org/10.\n1145/2818048.2819926\n[20] Deborah J Cohen, Sara R Keller, Gillian R Hayes, David A Dorr, Joan S Ash, and\nDean F Sittig. 2016. Integrating patient-generated health data into clinical care\nsettings or clinical decision-making: lessons learned from project healthdesign.\nJMIR human factors 3, 2 (2016), e5919.\n[21] George Demiris, Sarah J Iribarren, Katherine Sward, Solim Lee, and Rumei Yang.\n2019. Patient generated health data use in clinical practice: a systematic review.\nNursing Outlook 67, 4 (2019), 311–330.\n[22] Dina Demner-Fushman, Wendy W Chapman, and Clement J McDonald. 2009.\nWhat can natural language processing do for clinical decision support? Journal\nof biomedical informatics 42, 5 (2009), 760–772.\n[23] Daniel A Donnelly and Edward J Murray. 1991. Cognitive and emotional changes\nin written essays and therapy interviews. Journal of Social and Clinical psychol-\nogy 10, 3 (1991), 334–350.\n[24] Chris Elsden, Abigail C. Durrant, and David S. Kirk. 2016. It’s Just My History\nIsn’t It? Understanding Smart Journaling Practices. In Proceedings of the 2016\nCHI Conference on Human Factors in Computing Systems (San Jose, California,\nUSA) (CHI ’16) . Association for Computing Machinery, New York, NY, USA,\n2819–2831. https://doi.org/10.1145/2858036.2858103\n[25] Zohar Elyoseph, Dorit Hadar-Shoval, Kfir Asraf, and Maya Lvovsky. 2023. Chat-\nGPT outperforms humans in emotional awareness evaluations. Frontiers in\nPsychology 14 (2023), 1199058.\n[26] Faiza Farhat. 2023. ChatGPT as a complementary mental health resource: a\nboon or a bane. Annals of Biomedical Engineering (2023), 1–4.\n[27] Mayara Costa Figueiredo, Yunan Chen, et al. 2020. Patient-generated health\ndata: dimensions, challenges, and open questions. Foundations and Trends ® in\nHuman–Computer Interaction 13, 3 (2020), 165–297.\n[28] Kathleen Kara Fitzpatrick, Alison Darcy, and Molly Vierhile. 2017. Deliv-\nering Cognitive Behavior Therapy to Young Adults With Symptoms of De-\npression and Anxiety Using a Fully Automated Conversational Agent (Woe-\nbot): A Randomized Controlled Trial. JMIR Mental Health 4, 2 (2017), e19.\nhttps://doi.org/10.2196/mental.7785\n[29] Russell Fulmer, Angela Joerin, Breanna Gentile, Lysanne Lakerink, Michiel\nRauws, et al. 2018. Using psychological artificial intelligence (Tess) to relieve\nsymptoms of depression and anxiety: randomized controlled trial. JMIR mental\nhealth 5, 4 (2018), e9782.\n[30] Glen O. Gabbard and Holly Crisp-Han. 2017. The Early Career Psychiatrist\nand the Psychotherapeutic Identity. Academic Psychiatry 41, 1 (2017), 30–34.\nhttps://doi.org/10.1007/s40596-016-0627-7\n[31] Jianfeng Gao, Michel Galley, and Lihong Li. 2018. Neural Approaches to Con-\nversational AI. In Proceedings of the 56th Annual Meeting of the Association for\nComputational Linguistics: Tutorial Abstracts . Association for Computational\nLinguistics, Melbourne, Australia, 2–7. https://doi.org/10.18653/v1/P18-5002\n[32] Simret Araya Gebreegziabher, Zheng Zhang, Xiaohang Tang, Yihao Meng,\nElena L. Glassman, and Toby Jia-Jun Li. 2023. PaTAT: Human-AI Collabo-\nrative Qualitative Coding with Explainable Interactive Rule Synthesis. In Pro-\nceedings of the 2023 CHI Conference on Human Factors in Computing Systems .\nhttps://doi.org/10.1145/3544548.3581352\n[33] Katy Ilonka Gero, Vivian Liu, and Lydia Chilton. 2022. Sparks: Inspiration\nfor Science Writing using Language Models. Designing Interactive Systems\nConference (2022), 1002–1019. https://doi.org/10.1145/3532106.3533533\n[34] Amy L. Gonzales, Tiffany Y. Ng, OJ Zhao, and Geri Gay. 2010. Motivating\nExpressive Writing with a Text-to-Sound Application. In Proceedings of the\nSIGCHI Conference on Human Factors in Computing Systems (Atlanta, Georgia,\nUSA) (CHI ’10) . Association for Computing Machinery, New York, NY, USA,\n1937–1940. https://doi.org/10.1145/1753326.1753618\n[35] Adam J. Guastella and Mark R. Dadds. 2009. Sequential Growth in Cognitive-\nbehavioral Emotion-processing: A Laboratory Study. Cognitive Therapy and\nResearch 33, 4 (2009), 368–374. https://doi.org/10.1007/s10608-008-9199-5\n[36] Kent D Harber, James W Pennebaker, and S Christianson. 1992. Overcoming\ntraumatic memories. The handbook of emotion and memory: Research and theory\n(1992), 359–387.\n[37] Steve Hodges, Lyndsay Williams, Emma Berry, Shahram Izadi, James Srinivasan,\nAlex Butler, Gavin Smyth, Narinder Kapur, and Ken Wood. 2006. SenseCam: A\nretrospective memory aid. In UbiComp 2006: Ubiquitous Computing: 8th Interna-\ntional Conference, UbiComp 2006 Orange County, CA, USA, September 17-21, 2006\nProceedings 8 . Springer, 177–193.\n[38] Minlie Huang, Xiaoyan Zhu, and Jianfeng Gao. 2020. Challenges in Building\nIntelligent Open-Domain Dialog Systems. ACM Trans. Inf. Syst. 38, 3, Article 21\n(apr 2020), 32 pages. https://doi.org/10.1145/3383123\n[39] Becky Inkster, Shubhankar Sarda, and Vinod Subramanian. 2018. An Empathy-\nDriven, Conversational Artificial Intelligence Agent (Wysa) for Digital Mental\nWell-Being: Real-World Data Evaluation Mixed-Methods Study. JMIR mHealth\nand uHealth 6, 11 (2018), e12106. https://doi.org/10.2196/12106\n[40] Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii,\nYe Jin Bang, Andrea Madotto, and Pascale Fung. 2023. Survey of hallucination\nin natural language generation. Comput. Surveys 55, 12 (2023), 1–38.\n[41] Eunkyung Jo, Daniel A. Epstein, Hyunhoon Jung, and Young-Ho Kim. 2023.\nUnderstanding the Benefits and Challenges of Deploying Conversational AI\nLeveraging Large Language Models for Public Health Intervention. In Pro-\nceedings of the 2023 CHI Conference on Human Factors in Computing Systems\n(<conf-loc>, <city>Hamburg</city>, <country>Germany</country>, </conf-\nloc>) (CHI ’23) . Association for Computing Machinery, New York, NY, USA,\nArticle 18, 16 pages. https://doi.org/10.1145/3544548.3581503\n[42] Vaiva Kalnikaite and Steve Whittaker. 2012. Synergetic recollection: how to\ndesign lifelogging tools that help locate the right information. In Human-\ncomputer interaction: the agency perspective . Springer, 329–348.\n[43] Sidney H Kennedy. 2022. Core symptoms of major depressive disorder: relevance\nto diagnosis and treatment. Dialogues in clinical neuroscience (2022).\n[44] Junhan Kim, Yoojung Kim, Byungjoon Kim, Sukyung Yun, Minjoon Kim, and\nJoongseek Lee. 2018. Can a Machine Tend to Teenagers’ Emotional Needs?\nA Study with Conversational Agents. In Extended Abstracts of the 2018 CHI\nConference on Human Factors in Computing Systems (Montreal QC, Canada)\n(CHI EA ’18) . Association for Computing Machinery, New York, NY, USA, 1–6.\nhttps://doi.org/10.1145/3170427.3188548\n[45] Kitty Klein and Adriel Boals. 2001. Expressive Writing Can Increase Working\nMemory Capacity. Journal of Experimental Psychology: General 130, 3 (2001),\n520–533. https://doi.org/10.1037/0096-3445.130.3.520\nMindfulDiary: Harnessing Large Language Model to Support Psychiatric Patients’ Journaling CHI ’24, May 11–16, 2024, Honolulu, HI, USA\n[46] Rafal Kocielnik, Lillian Xiao, Daniel Avrahami, and Gary Hsieh. 2018. Reflection\nCompanion: A Conversational System for Engaging Users in Reflection on\nPhysical Activity. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 2, 2,\nArticle 70 (jul 2018), 26 pages. https://doi.org/10.1145/3214273\n[47] Diane M. Korngiebel and Sean D. Mooney. 2021. Considering the possibilities and\npitfalls of Generative Pre-trained Transformer 3 (GPT-3) in healthcare delivery.\nnpj Digital Medicine 4, 1 (2021), 93. https://doi.org/10.1038/s41746-021-00464-x\n[48] Kurt Kroenke, Robert L Spitzer, and Janet BW Williams. 2001. The PHQ-9:\nvalidity of a brief depression severity measure. Journal of general internal\nmedicine 16, 9 (2001), 606–613.\n[49] Richard D Lane, Donald M Quinlan, Gary E Schwartz, Pamela A Walker, and\nSharon B Zeitlin. 1990. The Levels of Emotional Awareness Scale: A cognitive-\ndevelopmental measure of emotion. Journal of personality assessment 55, 1-2\n(1990), 124–134.\n[50] Minchul Lee. 2022. Kiwi, Korean Intelligent Word Identifier . https://doi.org/10.\n5281/zenodo.7041425\n[51] Minha Lee, Sander Ackermans, Nena van As, Hanwen Chang, Enzo Lucas, and\nWijnand IJsselsteijn. 2019. Caring for Vincent: A Chatbot for Self-Compassion. In\nProceedings of the 2019 CHI Conference on Human Factors in Computing Systems .\nACM, Glasgow Scotland Uk, 1–13. https://doi.org/10.1145/3290605.3300932\n[52] Yi-Chieh Lee, Naomi Yamashita, and Yun Huang. 2020. Designing a Chatbot\nas a Mediator for Promoting Deep Self-Disclosure to a Real Mental Health\nProfessional. Proc. ACM Hum.-Comput. Interact. 4, CSCW1, Article 31 (may\n2020), 27 pages. https://doi.org/10.1145/3392836\n[53] Yi-Chieh Lee, Naomi Yamashita, Yun Huang, and Wai Fu. 2020. \"I Hear You, I\nFeel You\": Encouraging Deep Self-Disclosure through a Chatbot. In Proceedings\nof the 2020 CHI Conference on Human Factors in Computing Systems (Honolulu,\nHI, USA) (CHI ’20) . Association for Computing Machinery, New York, NY, USA,\n1–12. https://doi.org/10.1145/3313831.3376175\n[54] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and\nGraham Neubig. 2023. Pre-train, prompt, and predict: A systematic survey\nof prompting methods in natural language processing. Comput. Surveys 55, 9\n(2023), 1–35.\n[55] Ross J Lordon, Sean P Mikles, Laura Kneale, Heather L Evans, Sean A Mun-\nson, Uba Backonja, and William B Lober. 2020. How patient-generated health\ndata and patient-reported outcomes affect patient–clinician relationships: A\nsystematic review. Health Informatics Journal 26, 4 (2020), 2689–2706. https:\n//doi.org/10.1177/1460458220928184\n[56] Kai Lukoff, Taoxi Li, Yuan Zhuang, and Brian Y Lim. 2018. TableChat: mobile\nfood journaling to facilitate family support for healthy eating. Proceedings of\nthe ACM on Human-Computer Interaction 2, CSCW (2018), 1–28.\n[57] Olivier Luminet, Bernard Rimé, R Michael Bagby, and Graeme Taylor. 2004. A\nmultimodal investigation of emotional responding in alexithymia. Cognition\nand emotion 18, 6 (2004), 741–766.\n[58] Haiwei Ma, C. Estelle Smith, Lu He, Saumik Narayanan, Robert A. Giaquinto,\nRoni Evans, Linda Hanson, and Svetlana Yarosh. 2017. Write for Life: Persisting\nin Online Health Communities through Expressive Writing and Social Support.\nProc. ACM Hum.-Comput. Interact. 1, CSCW, Article 73 (dec 2017), 24 pages.\nhttps://doi.org/10.1145/3134708\n[59] Zilin Ma, Yiyang Mei, and Zhaoyuan Su. 2023. Understanding the Benefits and\nChallenges of Using Large Language Model-based Conversational Agents for\nMental Well-being Support. arXiv (2023). https://doi.org/10.48550/arxiv.2307.\n15810 arXiv:2307.15810\n[60] Farah Magrabi, Elske Ammenwerth, Jytte Brender McNair, Nicolet F De Keizer,\nHannele Hyppönen, Pirkko Nykänen, Michael Rigby, Philip J Scott, Tuulikki\nVehko, Zoie Shui-Yee Wong, et al. 2019. Artificial intelligence in clinical decision\nsupport: challenges for evaluating AI and practical implications. Yearbook of\nmedical informatics 28, 01 (2019), 128–134.\n[61] Donatella Marazziti, Giorgio Consoli, Michela Picchetti, Marina Carlini, and\nLuca Faravelli. 2010. Cognitive impairment in major depression. European\njournal of pharmacology 626, 1 (2010), 83–86.\n[62] Peter Musiat, Catherine Johnson, Melissa Atkinson, Simon Wilksch, and Tracey\nWade. 2022. Impact of guidance on intervention adherence in computerised in-\nterventions for mental health problems: a meta-analysis. Psychological Medicine\n52, 2 (2022), 229–240. https://doi.org/10.1017/S0033291721004621\n[63] Jodie Nghiem, Daniel A Adler, Deborah Estrin, Cecilia Livesey, Tanzeem Choud-\nhury, et al. 2023. Understanding Mental Health Clinicians’ Perceptions and\nConcerns Regarding Using Passive Patient-Generated Health Data for Clinical\nDecision-Making: Qualitative Semistructured Interview Study. JMIR Formative\nResearch 7, 1 (2023), e47380.\n[64] Shantanu Nundy, Chen-Yuan E Lu, Patrick Hogan, Anjuli Mishra, and Monica E\nPeek. 2014. Using patient-generated health data from mobile technologies for\ndiabetes self-management support: provider perspectives from an academic\nmedical center. Journal of diabetes science and technology 8, 1 (2014), 74–82.\n[65] OpenAI, Inc. 2022. ChatGPT. https://chat.openai.com\n[66] Ekkehard Othmer and Sieglinde C Othmer. 2002. The clinical interview using\nDSM-IV-TR: Vol 1: Fundamentals. American Psychiatric Publishing, Inc.\n[67] Ekkehard Othmer and Sieglinde C Othmer. 2002. The clinical interview using\nDSM-IV-TR: Vol. 2: The difficult patient. American Psychiatric Publishing, Inc.\n[68] SoHyun Park, Anja Thieme, Jeongyun Han, Sungwoo Lee, Wonjong Rhee,\nand Bongwon Suh. 2021. “I wrote as if I were telling a story to someone\nI knew. ”: Designing Chatbot Interactions for Expressive Writing in Mental\nHealth. Designing Interactive Systems Conference 2021 (2021), 926–941. https:\n//doi.org/10.1145/3461778.3462143\n[69] James W Pennebaker. 1985. Traumatic experience and psychosomatic disease:\nExploring the roles of behavioural inhibition, obsession, and confiding.Canadian\nPsychology/Psychologie canadienne 26, 2 (1985), 82.\n[70] James W Pennebaker. 1997. Writing about emotional experiences as a therapeu-\ntic process. Psychological science 8, 3 (1997), 162–166.\n[71] James W Pennebaker and Cindy K Chung. 2011. Expressive writing: Connections\nto physical and mental health. (2011).\n[72] James W Pennebaker and Janel D Seagal. 1999. Forming a story: The health\nbenefits of narrative. Journal of clinical psychology 55, 10 (1999), 1243–1254.\n[73] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya\nSutskever, et al. 2019. Language models are unsupervised multitask learners.\nOpenAI blog 1, 8 (2019), 9.\n[74] Gerardo Ramirez and Sian L Beilock. 2011. Writing about testing worries boosts\nexam performance in the classroom. science 331, 6014 (2011), 211–213.\n[75] Vipula Rawte, Amit Sheth, and Amitava Das. 2023. A survey of hallucination in\nlarge foundation models. arXiv preprint arXiv:2309.05922 (2023).\n[76] Tara Riddell, Jane Nassif, Ana Hategan, and Joanna Jarecki. 2020. Healthy Habits:\nPositive Psychology, Journaling, Meditation, and Nature Therapy. Humanism\nand Resilience in Residency Training: A Guide to Physician Wellness (2020), 439–\n472.\n[77] Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan\nLiu, Jing Xu, Myle Ott, Eric Michael Smith, Y-Lan Boureau, and Jason Weston.\n2021. Recipes for Building an Open-Domain Chatbot. In Proceedings of the\n16th Conference of the European Chapter of the Association for Computational\nLinguistics: Main Volume . Association for Computational Linguistics, Online,\n300–325. https://doi.org/10.18653/v1/2021.eacl-main.24\n[78] Peter Salovey and John D Mayer. 1990. Emotional intelligence. Imagination,\ncognition and personality 9, 3 (1990), 185–211.\n[79] Jessica Schroeder, Jane Hoffswell, Chia-Fang Chung, James Fogarty, Sean Mun-\nson, and Jasmine Zia. 2017. Supporting Patient-Provider Collaboration to Iden-\ntify Individual Triggers Using Food and Symptom Journals. InProceedings of the\n2017 ACM Conference on Computer Supported Cooperative Work and Social Com-\nputing (Portland, Oregon, USA) (CSCW ’17). Association for Computing Machin-\nery, New York, NY, USA, 1726–1739. https://doi.org/10.1145/2998181.2998276\n[80] Woosuk Seo, Chanmo Yang, and Young-Ho Kim. 2023. ChaCha: Leveraging\nLarge Language Models to Prompt Children to Share Their Emotions about\nPersonal Events. arXiv:2309.12244 [cs.HC]\n[81] Michael Shapiro, Douglas Johnston, Jonathan Wald, and Donald Mon. 2012.\nPatient-generated health data. RTI International, April 813 (2012), 814.\n[82] Ashish Sharma, Inna W Lin, Adam S Miner, David C Atkins, and Tim Althoff.\n2023. Human–AI collaboration enables more empathic conversations in text-\nbased peer-to-peer mental health support. Nature Machine Intelligence 5, 1\n(2023), 46–57.\n[83] Dinggang Shen, Guorong Wu, and Heung-Il Suk. 2017. Deep learning in medical\nimage analysis. Annual review of biomedical engineering 19 (2017), 221–248.\n[84] Vera Sorin, Danna Brin, Yiftach Barash, Eli Konen, Alexander Charney, Girish\nNadkarni, and Eyal Klang. 2023. Large language models (llms) and empathy-a\nsystematic review. medRxiv (2023), 2023–08.\n[85] Robert L Spitzer, Kurt Kroenke, Janet BW Williams, and Bernd Löwe. 2006. A\nbrief measure for assessing generalized anxiety disorder: the GAD-7. Archives\nof internal medicine 166, 10 (2006), 1092–1097.\n[86] Michael J. Tanana, Christina S. Soma, Patty B. Kuo, Nicolas M. Bertagnolli,\nAaron Dembe, Brian T. Pace, Vivek Srikumar, David C. Atkins, and Zac E. Imel.\n2021. How do you feel? Using natural language processing to automatically rate\nemotion in psychotherapy. Behavior Research Methods 53, 5 (2021), 2069–2082.\nhttps://doi.org/10.3758/s13428-020-01531-z\n[87] Anja Thieme, Maryann Hanratty, Maria Lyons, Jorge E Palacios, Rita Marques,\nCecily Morrison, and Gavin Doherty. 2022. Designing Human-Centered AI\nfor Mental Health: Developing Clinically Relevant Applications for Online\nCBT Treatment. ACM Transactions on Computer-Human Interaction (2022).\nhttps://doi.org/10.1145/3564752\n[88] John Torous, Nicole M Benson, Keris Myrick, and Gunther Eysenbach. 2023.\nFocusing on Digital Research Priorities for Advancing the Access and Quality\nof Mental Health. JMIR Mental Health 10 (April 2023), e47898. https://doi.org/\n10.2196/47898\n[89] Cheryl Travers. 2011. Unveiling a reflective diary methodology for exploring\nthe lived experiences of stress and coping. Journal of Vocational Behavior 79, 1\n(2011), 204–216. https://doi.org/10.1016/j.jvb.2010.11.007\n[90] Philip M. Ullrich and Susan K. Lutgendorf. 2002. Journaling about stress-\nful events: Effects of cognitive processing and emotional expression. An-\nnals of Behavioral Medicine 24, 3 (2002), 244–250. https://doi.org/10.1207/\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Taewan Kim, Seolyeong Bae, Hyun Ah Kim, Su-woo Lee, Hwajung Hong, Chanmo Yang, and Young-Ho Kim\ns15324796abm2403_10\n[91] Allison Utley and Yvonne Garza. 2011. The Therapeutic Use of Journaling\nWith Adolescents. Journal of Creativity in Mental Health 6, 1 (2011), 29–41.\nhttps://doi.org/10.1080/15401383.2011.557312\n[92] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,\nAidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you\nneed. Advances in neural information processing systems 30 (2017).\n[93] Lu Wang, Munif Ishad Mujib, Jake Williams, George Demiris, and Jina Huh-\nYoo. 2021. An Evaluation of Generative Pre-Training Model-based Therapy\nChatbot for Caregivers. arXiv (2021). https://doi.org/10.48550/arxiv.2107.13115\narXiv:2107.13115\n[94] Jing Wei, Sungdong Kim, Hyunhoon Jung, and Young-Ho Kim. 2024. Lever-\naging Large Language Models to Power Chatbots for Collecting User Self-\nReported Data. Proc. ACM Hum.-Comput. Interact. 8, CSCW1, Article 87 (apr\n2024), 35 pages. https://doi.org/10.1145/3637364\n[95] Danny TY Wu, Chen Xin, Shwetha Bindhu, Catherine Xu, Jyoti Sachdeva,\nJennifer L Brown, and Heekyoung Jung. 2020. Clinician perspectives and design\nimplications in using patient-generated health data to improve mental health\npractices: mixed methods study. JMIR formative research 4, 8 (2020), e18123.\n[96] Tongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022. AI Chains: Trans-\nparent and Controllable Human-AI Interaction by Chaining Large Language\nModel Prompts. In Proceedings of the 2022 CHI Conference on Human Fac-\ntors in Computing Systems (New Orleans, LA, USA) (CHI ’22) . Association for\nComputing Machinery, New York, NY, USA, Article 385, 22 pages. https:\n//doi.org/10.1145/3491102.3517582\n[97] J.D. Zamfirescu-Pereira, Heather Wei, Amy Xiao, Kitty Gu, Grace Jung,\nMatthew G Lee, Bjoern Hartmann, and Qian Yang. 2023. Herding AI Cats:\nLessons from Designing a Chatbot by Prompting GPT-3. In Proceedings of the\n2023 ACM Designing Interactive Systems Conference (, Pittsburgh, PA, USA,) (DIS\n’23). Association for Computing Machinery, New York, NY, USA, 2206–2220.\nhttps://doi.org/10.1145/3563657.3596138\n[98] Jian Zhao, Elaine Chapman, Stephen Houghton, and David Lawrence. 2022.\nDevelopment and validation of a Coping Strategies Scale for use in Chinese\ncontexts. Frontiers in Psychology 13 (2022), 845769.\n[99] Zoie Zhao, Sophie Song, Bridget Duah, Jamie Macbeth, Scott Carter, Mon-\nica P Van, Nayeli Suseth Bravo, Matthew Klenk, Kate Sick, and Alexandre\nL. S. Filipowicz. 2023. More Human than Human: LLM-Generated Narratives\nOutperform Human-LLM Interleaved Narratives. In Proceedings of the 15th\nConference on Creativity and Cognition (Virtual Event, USA) (C&C ’23) . As-\nsociation for Computing Machinery, New York, NY, USA, 368–370. https:\n//doi.org/10.1145/3591196.3596612\n[100] Haining Zhu, Joanna Colgan, Madhu Reddy, and Eun Kyoung Choe. 2016. Shar-\ning patient-generated data in clinical practices: an interview study. In AMIA\nAnnual Symposium Proceedings , Vol. 2016. American Medical Informatics Asso-\nciation, 1303.",
  "topic": "Journaling file system",
  "concepts": [
    {
      "name": "Journaling file system",
      "score": 0.9550805687904358
    },
    {
      "name": "Conversation",
      "score": 0.747468888759613
    },
    {
      "name": "Mental health",
      "score": 0.608709454536438
    },
    {
      "name": "Psychology",
      "score": 0.5337304472923279
    },
    {
      "name": "Bridging (networking)",
      "score": 0.42418113350868225
    },
    {
      "name": "Psychotherapist",
      "score": 0.3260413110256195
    },
    {
      "name": "Psychiatry",
      "score": 0.3248922824859619
    },
    {
      "name": "Computer science",
      "score": 0.16854652762413025
    },
    {
      "name": "Communication",
      "score": 0.0
    },
    {
      "name": "Database",
      "score": 0.0
    },
    {
      "name": "Data file",
      "score": 0.0
    },
    {
      "name": "Computer network",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I2801339556",
      "name": "Government of the Republic of Korea",
      "country": "KR"
    }
  ]
}