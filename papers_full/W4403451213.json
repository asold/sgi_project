{
  "title": "How can large language models assist with a FRAM analysis?",
  "url": "https://openalex.org/W4403451213",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2687613052",
      "name": "M. Å ujan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A223651381",
      "name": "D. Slater",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2495613034",
      "name": "E Crumpton",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4324316215",
    "https://openalex.org/W4389803273",
    "https://openalex.org/W6640461127",
    "https://openalex.org/W2039536655",
    "https://openalex.org/W2952379916",
    "https://openalex.org/W4379259169",
    "https://openalex.org/W4361289889",
    "https://openalex.org/W4391069573",
    "https://openalex.org/W6796221871",
    "https://openalex.org/W6637674681",
    "https://openalex.org/W4200090760",
    "https://openalex.org/W2998175747",
    "https://openalex.org/W4386867830",
    "https://openalex.org/W4385392091",
    "https://openalex.org/W3026255602",
    "https://openalex.org/W4387599176",
    "https://openalex.org/W3093236631",
    "https://openalex.org/W2950846481",
    "https://openalex.org/W2087615533",
    "https://openalex.org/W4382182601",
    "https://openalex.org/W4308252184",
    "https://openalex.org/W2908201961",
    "https://openalex.org/W4324387439",
    "https://openalex.org/W4389524159",
    "https://openalex.org/W4367595583",
    "https://openalex.org/W4246256082",
    "https://openalex.org/W1480210583",
    "https://openalex.org/W2758387230",
    "https://openalex.org/W4367318783",
    "https://openalex.org/W4213132190",
    "https://openalex.org/W1781458262"
  ],
  "abstract": "Large Language Models (LLMs) are transforming the way in which people interact with artificial intelligence. In this paper we explore how safety professionals might use LLMs for a FRAM analysis. We use interactive prompting with Google Bard / Gemini and ChatGPT to do a FRAM analysis on examples from healthcare and aviation. Our exploratory findings suggest that LLMs afford safety analysts the opportunity to enhance the FRAM analysis by facilitating initial model generation and offering different perspectives. Responsible and effective utilisation of LLMs requires careful consideration of their limitations as well as their abilities. Human expertise is crucial both with regards to validating the output of the LLM as well as in developing meaningful interactive prompting strategies to take advantage of LLM capabilities such as self-critiquing from different perspectives. Further research is required on effective prompting strategies, and to address ethical concerns.",
  "full_text": null,
  "topic": "Poison control",
  "concepts": [
    {
      "name": "Poison control",
      "score": 0.5723404884338379
    },
    {
      "name": "Human factors and ergonomics",
      "score": 0.4724814295768738
    },
    {
      "name": "Computer science",
      "score": 0.4514563977718353
    },
    {
      "name": "Injury prevention",
      "score": 0.43451473116874695
    },
    {
      "name": "Occupational safety and health",
      "score": 0.433544397354126
    },
    {
      "name": "Engineering",
      "score": 0.41902655363082886
    },
    {
      "name": "Forensic engineering",
      "score": 0.33946743607521057
    },
    {
      "name": "Medical emergency",
      "score": 0.24436530470848083
    },
    {
      "name": "Medicine",
      "score": 0.16527169942855835
    },
    {
      "name": "Pathology",
      "score": 0.0
    }
  ],
  "institutions": [],
  "cited_by": 7
}