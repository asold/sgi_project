{
    "title": "BBO-CFAT: Network Intrusion Detection Model Based on BBO Algorithm and Hierarchical Transformer",
    "url": "https://openalex.org/W4394586042",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A5052622257",
            "name": "Tingyao Jiang",
            "affiliations": [
                "China Three Gorges University"
            ]
        },
        {
            "id": "https://openalex.org/A5030086140",
            "name": "Xiaobo Fu",
            "affiliations": [
                "China Three Gorges University"
            ]
        },
        {
            "id": "https://openalex.org/A5100749649",
            "name": "Min Wang",
            "affiliations": [
                "China Three Gorges University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W6683814163",
        "https://openalex.org/W1543815398",
        "https://openalex.org/W2106442760",
        "https://openalex.org/W3042855339",
        "https://openalex.org/W2957352360",
        "https://openalex.org/W2996008843",
        "https://openalex.org/W2996763767",
        "https://openalex.org/W3013549383",
        "https://openalex.org/W3106212564",
        "https://openalex.org/W3010957669",
        "https://openalex.org/W3026601682",
        "https://openalex.org/W2986887798",
        "https://openalex.org/W2805382685",
        "https://openalex.org/W4286511238",
        "https://openalex.org/W3198200730",
        "https://openalex.org/W2168081761",
        "https://openalex.org/W2625046642",
        "https://openalex.org/W2759043405",
        "https://openalex.org/W2734779510",
        "https://openalex.org/W2768426510",
        "https://openalex.org/W3001364574",
        "https://openalex.org/W2742495185",
        "https://openalex.org/W4210743106",
        "https://openalex.org/W3151784567",
        "https://openalex.org/W3021740526",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W3215290057",
        "https://openalex.org/W3184127157",
        "https://openalex.org/W4283318673",
        "https://openalex.org/W4323275401",
        "https://openalex.org/W4312950730",
        "https://openalex.org/W6800388583",
        "https://openalex.org/W3179240416",
        "https://openalex.org/W4383503751",
        "https://openalex.org/W3016266335",
        "https://openalex.org/W3017293089",
        "https://openalex.org/W4315781229",
        "https://openalex.org/W4313654696",
        "https://openalex.org/W4321016094",
        "https://openalex.org/W3110975658",
        "https://openalex.org/W4387666455",
        "https://openalex.org/W4311064426",
        "https://openalex.org/W4213361588",
        "https://openalex.org/W4281252868",
        "https://openalex.org/W1995678176",
        "https://openalex.org/W3178719887",
        "https://openalex.org/W4353057854",
        "https://openalex.org/W3203415565",
        "https://openalex.org/W4210814081",
        "https://openalex.org/W2926701059",
        "https://openalex.org/W3047132966",
        "https://openalex.org/W4293211096",
        "https://openalex.org/W2947334153",
        "https://openalex.org/W4283658889",
        "https://openalex.org/W2952313066",
        "https://openalex.org/W6789172296",
        "https://openalex.org/W6784745743",
        "https://openalex.org/W6797233888",
        "https://openalex.org/W3093143205",
        "https://openalex.org/W3171954428",
        "https://openalex.org/W2159698298",
        "https://openalex.org/W3194203264",
        "https://openalex.org/W3123636359"
    ],
    "abstract": "In today&#x2019;s network environments, vulnerable to cyber threats such as hackers and viruses, intrusion detection technology is considered the most effective means of detection and defense. Deep neural networks are commonly used in intrusion detection technology. However, improving the model&#x2019;s ability to extract feature information and reducing computational space while retaining local feature information are critical challenges that need to be addressed. To tackle these issues, this paper proposes a model named BBO-CFAT, which combines the Biogeography-Based Optimization algorithm (BBO) for feature selection and an improved Transformer model for preserving context information and reducing computational space. Specifically, the BBO-CFAT model employs a roulette selection method to control the operations of migration and mutation operators. It utilizes feature information entropy to weight updates of adaptive variables in these operators, thereby enhancing the credibility of feature selection. Furthermore, the Transformer framework is hierarchically designed to facilitate the acquisition of context information. Additionally, depthwise separable convolutions are employed to reduce computational space, thereby improving computational efficiency and training speed. Experimental evaluations using the CIC-IDS2017 and NSL-KDD datasets demonstrate promising accuracies for BBO-CFAT on both datasets, achieving 99.1&#x0025; and 97.5&#x0025; accuracy, respectively, surpassing the performance of comparative experiments. Overall, the BBO-CFAT model provides a comprehensive solution to the challenges of intrusion detection, effectively balancing feature preservation, computational efficiency, and training accuracy.",
    "full_text": "Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000.\nDigital Object Identifier 10.1 109/ACCESS.2023.1 120000\nBBO-CFAT:Network intrusion detection model\nbased on BBO algorithm and hierarchical\ntransformer\nTINGYAO JIANG1, XIAOBO FU2, and Min Wang3\n1College of Computer and Information Technology, China Three Gorges University, Yichang, China.\n2School of Electronic Information, Hubei Three Gorges Polytechnic, Yichang 443002, China.\nCorresponding author: Xiaobo Fu (e-mail: 202108120021004@ctgu.edu.cn).\nThis work has been supported by the National Natural Science Foundation of China, number 61872221.\nABSTRACT In today’s network environments vulnerable to cyber threats like hackers and viruses, intrusion\ndetection technology is considered the most effective means of detection and defense. Deep neural networks\nare commonly used in intrusion detection technology. However, improving the model’s ability to extract\nfeature information and reducing computational space while retaining local feature information are critical\nchallenges that need to be addressed.To tackle these issues, this paper proposes a model named BBO-\nCFAT, which combines the Biogeography-Based Optimization algorithm (BBO) for feature selection and an\nimproved Transformer model for preserving context information and reducing computational space. Specif-\nically, the BBO-CFAT model employs a roulette selection method to control the operations of migration and\nmutation operators. It utilizes feature information entropy to weight updates of adaptive variables in these\noperators, thereby enhancing the credibility of feature selection. Furthermore, the Transformer framework is\nhierarchically designed to facilitate the acquisition of context information. Additionally, depthwise separable\nconvolutions are employed to reduce computational space, thereby improving computational efficiency\nand training speed.Experimental evaluations using the CIC-IDS2017 and NSL-KDD datasets demonstrate\npromising accuracies for BBO-CFAT on both datasets, achieving 99.1% and 97.5% accuracy, respectively,\nsurpassing the performance of comparative experiments.Overall, the BBO-CFAT model provides a com-\nprehensive solution to the challenges of intrusion detection, effectively balancing feature preservation,\ncomputational efficiency, and training accuracy.\nINDEX TERMS Intrusion Detection, BBO, Transformer, Feature Selection\n1. INTRODUCTION\nIn recent years, there has been rapid development in computer\nand Internet technology. Internet technology has become an\nindispensable element of people’s daily lives, facilitating on-\nline payment, ticket and hotel room bookings, and network\ncommunication, fundamentally transforming the way people\nlive. However, during the early stages, cyberspace lacked\nrobust establishment, as evidenced in prior studies [1], creat-\ning favorable conditions for illicit intrusion. Ensuring timely\ndetection of network intrusion is crucial for safeguarding\ndigital infrastructure, mitigating economic losses, and main-\ntaining overall security. While traditional intrusion defense\ntechniques, such as firewalls, identity security authentication,\nand access control, can offer protection against specific intru-\nsion methods [2] [3], intrusion detection techniques (IDS) are\nconsidered the most effective in detecting attacks and ensur-\ning network security. IDS can be categorized into four main\ntypes: network-based intrusion detection systems (NIDS),\nhost-based intrusion detection systems (HIDS), signature-\nbased intrusion detection systems (SIDS), and anomaly-based\nintrusion detection systems (AIDS).\nNetwork intrusion detection technology is the main focus\nof this paper, with NIDS primarily detecting network traffic\nto determine attack paths [4]. Because machine learning and\ndeep learning can leverage big data to learn and predict\nspecific functionalities, advancements in the field of machine\nlearning and deep learning technologies have been introduced\ninto the domain of network intrusion detection. Common\nmachine learning methods such as Random Forest (RF) [5],\nDecision Tree (DT) [6], Naive Bayes (NB) [7], and Support\nVector Machine (SVM) [8] have been used to create NIDS\nmodels. In contrast, deep learning models with deeper and\nVOLUME 11, 2023 1\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386405\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nmore extensive structures demonstrate higher effectiveness in\nfeature extraction. For instance, Longaris et al. [9] introduced\nan autoencoder-based Long Short-Term Memory (LSTM)\nmodel to identify anomalous behavior in networks . On the\nother hand, Fernandez et al. [10] proposed a model based on\nDeep Neural Networks (DNN) and tested its robustness . El-\nnakib et al. [48] introduced an Enhanced Intrusion Detection\nModel (EIDM) using deep learning techniques, which effec-\ntively identified unauthorized access, anomalies, and mali-\ncious activities in Internet of Things (IoT) networks through\nattention mechanisms or transfer learning . Choobdar et al.\n[49] addressed intrusion detection and multi-class classifica-\ntion issues in software-defined networks by extracting useful\nfeatures from network traffic data using stacked autoencoder\ntechnology. This method enables effective differentiation be-\ntween normal traffic and malicious behavior . Olimov et al.\n[55] proposed a novel unsupervised learning method based on\ngraph Laplacian matrix for anomaly detection and localiza-\ntion. This method effectively detects and localizes anomalies\nusing graph structural information without relying on labeled\nanomaly data. It demonstrates outstanding performance and\naccuracy across various datasets, highlighting its effective-\nness.\nThis paper primarily investigates intrusion detection tech-\nnology using deep neural networks, which, when combined\nwith hybrid models and increased network depth to enhance\ndetection capabilities, also expose certain issues. These in-\nclude high redundancy and high-dimensional imbalances in\nthe data, optimization of how models preserve local feature\nextraction and computational efficiency, and ensuring accu-\nrate completion of feature selection to ensure the importance\nof selected features.\nTo address these issues, we have proposed a series of meth-\nods and techniques. We introduce an enhanced feature selec-\ntion method designed to preserve crucial features. Second,\nour improved Transformer model not only advances feature\ninformation extraction but also takes into account global fea-\nture information and contextual information between layers,\nleading to improved computational efficiency.\nThe paper is organized as follows: In Section II, we provide\nan overview of the background knowledge related to feature\nselection and intrusion detection models as presented in the\nexisting literature. Section III elaborates on the proposed\nmethod and its associated parameters. Section IV offers in-\nsights into the experimental results. Finally, in Section V ,\nwe summarize the contributions of this paper and outline\npotential directions for future research.\n2. RELATED WORK\nThis section summaries the algorithms and research relevant\nto this study.\n2.1 FEATURE SELECTION\nFeature selection often directly impacts the model’s effective-\nness, so it is necessary to perform feature selection prior to\nnetwork training to ensure global optimality during training.\nMafarja et al. [11] proposed an improved feature selection\nmethod based on the Whale Optimisation Algorithm (WOA).\nThe method introduced the V-shaped and S-shaped meth-\nods to the WOA algorithm for improved feature selection\nwhile dealing with high dimensionality. Alamiedy et al. [12]\nproposed an improved intrusion detection model based on\nmulti-objective grey wolf optimization, which uses GWO as\na method to obtain the most practical features and support\nvector machine to predict Dos attack, Probe attack, R2L\nattack model, and U2R attack, and obtained 93.64%, 91.01%,\n57.72%, 53.7% prediction results.However, the model is not\nbalanced with a dataset, so the difference in prediction re-\nsults obtained with different amounts of data is noticeable.\nLiu et al. [13] used Improved Social Spider Optimization\n(ISSO) algorithm to achieve feature extraction and selection\nin intrusion detection.Yaseen et al. [14] proposed a feature\nfusion superposition integration mechanism (MFFSEM) for\ndetecting anomalous behavior. Mainly, multiple integrated\nfeature datasets are constructed by association and correlation\nbetween the fundamental datasets to meet the requirements of\nanomalous behavior detection. Halim et al. [15] proposed an\nenhanced feature selection method (GbFS) based on genetic\nalgorithms to improve the accuracy of classifiers.\nSimon et al. [16] proposed a biogeographic optimization-\nbased (BBO) algorithm, the algorithm presented in this\npaper is derived from the study of biological species\nand geographical principles, primarily aimed at address-\ning high-dimensional, multi-objective optimization prob-\nlems.Guendouzi et al. [17] used BBO for feature selection\nwork and verified the credibility of the feature selection work.\n2.2 INTRUSION DETECTION MODEL\nIn recent years, machine and deep learning have been widely\nused in intrusion detection and achieved good experimental\nresults. Most traditional machine learning methods are based\non supervised learning models [18]–[20]. Bhattacharya et al.\n[21] used Principal Component Analysis (PCA) and the Fire-\nfly algorithm to design a new classification model for intru-\nsion detection. The model first reduces the dimensionality of\nthe data using the PCA-Firefly algorithm and then completes\nthe data classification using the XGBoost algorithm. Chang\net al. [22] verified that the Random Forest algorithm can be\nused to select the essential data features and completes the\nclassification of the experimental data using Support Vector\nMachine.\nAs the network data becomes high dimensional as the\nnumber of users increases, the training accuracy of tradi-\ntional machine learning decreases. Ding et al. [23] proposed a\nmodel based on KNN and Generative Adversarial Networks\n(TACGAN), which first uses the K-nearest neighbor method\nfor effective downsampling, then uses TACGAN for over-\nsampling and finally mixes the two types of data for data\nbalancing. Kan et al. [24] proposed an intrusion detection\nsystem based on multi-scale convolutional neural networks\n(CNNs) for networked communication. Furthermore, the pro-\nposed model has a faster convergence speed than AdaBoost\n2 VOLUME 11, 2023\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386405\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nand recurrent neural networks (RNN). Xu et al. [25] designed\na deep neural network (DNN) detection framework FC-Net,\nwhich divides the model into feature extraction and compar-\nison networks. The model learns the feature maps used for\nclassification and then determines whether they are of the\nsame class through the comparison network. Vaswani et al.\n[26] proposed Transformer which has been rapidly applied in\nvarious fields due to its robust feature extraction capabilities.\nLi et al. [27] proposed combining extended convolutional\nneural networks with different expansion rates with Trans-\nformer to obtain coarse and fine-grained information and\nimprove the model’s generalization ability. Chen et al. [28]\nproposed GTA, which includes a connection learning strategy\nand influence propagation convolutional kernel multi-branch\nattention mechanism. Tuli et al. [29] proposed TranAD based\non Transformer’s encoder and focus score for robust multi-\nmodel feature extraction and adversarial training. Han et al.\n[30] proposed an intrusion detection model, GTID, which\nleverages N-Gram frequency for contextual information, inte-\ngrates a time-aware transformer to capture the time intervals\nbetween data packets, and performs classification based on\nlearned time features. This approach addresses the issues of\ninformation loss and feature dimensionality caused by feature\nextraction. Guo et al. [31] designed a CMT network with a\nhierarchically connected structure so that contextual hierar-\nchical information can be retained. Wu et al. [32] designed\nFastformer, which changes the multi-head attention mecha-\nnism compared to the traditional Transformer model, i.e., the\ntraditional multi-head attention mechanism is derived by dot\nproduct, which increases the computational difficulty. The\nFastformer model uses additive attention to compute atten-\ntion. This makes the calculation faster and easier. Ullah et al.\n[33] designed a DL-based IDS to detect and classify attacks\nin IoT networks. The proposed convolutional neural network\n(CNN) model is validated using the BoT-IoT, IoT Network In-\ntrusion, MQTT-IoT-IDS2020, and IoT-23 intrusion detection\ndata sets. Experimental results show that this method has high\nclassification accuracy. However, the method uses the DL\nmethod for data training, which requires a lot of computing\nresources and memory resources, and is not suitable for the\nIoT. Rakhmonov et al. [34] firstly, generate anomaly images,\nand then transfer critical feature information from the network\nto the novice network using knowledge distillation technique,\nforming an end-to-end anomaly detection method, which\nyields impressive results. A. Kim et al. [35] introduced a\nhybrid model combining CNN and LSTM networks to extract\nfeatures from real-time HTTP traffic. Through training, this\nmodel effectively differentiated complex attacks and accu-\nrately analyzed unknown web-based attacks.F. Alin et al. [36]\nproposed a hierarchical deep learning approach for intrusion\ndetection. Henry et al. [37] The author proposes a technique\nthat combines CNN and GRU, in which different CNN-GRU\ncombination sequences are proposed to optimize network pa-\nrameters. The results indicate significant improvements, with\nmany network attacks detected with an accuracy of 98.73%\nand an FPR rate of 0.075. Altunay [38], A deep learning\narchitecture combining CNN and LSTM was introduced to\ndetect intrusions in IoT networks, and the accurate detection\nsuccess rate for attack types in the dataset was effectively\nevaluated. Additionally, Sharma et al. [39] A filter-based\nfeature selection deep neural network model was proposed,\nwhich removed highly correlated features and generated a few\nattack data using GANs to balance the dataset.\nIn summary, while significant research has been conducted\non feature selection and deep intrusion detection models,\nchallenges remain. Feature selection encounters issues re-\ngarding the scientific selection of feature subsets, while deep\nintrusion models suffer from large volume, time-consuming\ntraining, and ineffective global feature extraction. Therefore,\nthis paper proposes enhancements through an improved BBO\nalgorithm to enhance the scientific selection of feature subsets\nand an improved Transformer to retain global feature infor-\nmation, thereby improving computational efficiency.\n3. METHODOLOGY\nThis article aims to solve the problem of high latitude data,\nimprove the scientificity of feature selection, preserve the\nglobal feature information of feature extraction, and improve\ncomputational speed. We propose a deep network intrusion\ndetection model based on BBO feature selection method and\nTransformer encoder. The model consists of three stages:\nfirst, preprocessing the raw data, using unilateral selection\n(OSS) and boundary SMOTE to upsample and downsample\nthe raw data, and then using WGANs network to generate\na small amount of attack data; Subsequently, the improved\nBBO algorithm is used to rank the data features and retain the\nhigher ranked features as features in the new dataset, which\nare then passed on to the training model; Finally, the designed\nnetwork model is used for data classification training. The\nframework of the model process is shown in Figure 1:\nFIGURE 1. The flowchart exhibits the sequence of operations, from the\ninitial application of the BBO to the subsequent utilization of the\nTransformer architecture for feature selection.\n3.1 DATA PREPROCESSING\nThe data preprocessing primarily aims to balance the dataset\nto enhance the intrusion detection model’s ability to rec-\nVOLUME 11, 2023 3\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386405\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nognize and classify all categories, thereby improving the\nmodel’s generalization and application effectiveness. In our\nexperiments, we utilized the CIC-IDS2017 and NSL-KDD\ndatasets, both characterized by high dimensionality and data\nimbalance. To mitigate the impact of the dataset on training\nperformance, we employed a combination of one-sided se-\nlection (OSS) and boundary BiSMOTE sampling techniques\nto balance the dataset.This method involves undersampling\nto retain minority classes and reduce the quantity of major-\nity classes, followed by oversampling using BiSMOTE with\nweighted settings to further sample the data. This step may\nintroduce noise and boundary data issues. Additionally, we\nutilized WGANs networks to synthesize attack instances of\nminority classes, further balancing the dataset. This sampling\napproach helps avoid generating boundary data and reduces\nthe impact of noise during the sampling process. Tables 1 and\n2 display the results of processing the two datasets.\nTABLE 1. Dataset results processed by CIC-IDS2017\nIndex New labels Old labels old total new total\n1 Normal Benign 2095057 199880\n2 Botrnet Force FTP-PAtator,SSH-Patator 9150 9150\n3 Dos/DDos\nDDos,Dos GoldenEye,\nDos,Dos Hulk,Heartbleed\nDos Slowhttpest\nDos slowlories\n321770 199667\n4 Infiltration Infiltration 36 2000\n5 Portscan PortScan 90694 90694\n6 Web Attack\nWeb Attack-Brute Force\nWeb Attack-Sql Injection\nWeb Attack-XSS\n2143 2143\n7 Brute ARES Bot 1948 1948\n3.2 IMPROVED BBO FEATURE SELECTION METHOD\nDeep learning plays a crucial role in the field of network\nintrusion detection technology, primarily owing to the multi-\nlayered neural network models’ ability to capture extensive\nfeature information and automatically conduct feature learn-\ning. However, efficiently utilizing neural networks to focus\non significant data features for feature learning can enhance\ntesting accuracy. Therefore, this study proposes an improved\nBBO algorithm for data feature selection.\nIn the BBO algorithm, species can migrate between is-\nlands, with each island termed a habitat. Each habitat rep-\nresents a species’ range and is characterized by its Habitat\nSuitability Index (HSI), which indicates the quality of life\nTABLE 2. Dataset results processed by NSL-KDD.\nType old records new records\nNormal 13449 9960\nProbing 2289 9804\nR2L 209 6000\nU2R 11 2500\nDos 9234 9234\nwithin the habitat. HSI is determined by Suitability Index\nVariables (SIV), influenced by specific habitat conditions\nsuch as rainfall, species diversity, and habitat size. Habitats\nwith high HSI values feature high species saturation, display-\ning low immigration rates and high emigration rates, whereas\nhabitats with low HSI values often harbor fewer species,\nleading to low emigration rates and high immigration rates.\nFigure 2 illustrates data related to habitats with immigration\nand emigration rates.\nFIGURE 2. Distribution of species in the habitat.\nIn this algorithm, each data category in the original dataset\nis treated as an independent habitat, represented by a binary\ncarrier with SIV (Suitability Index Variables), and the initial\nfeature values are set to all zeros to signify the transformation.\nSubsequently, migration and mutation rates are computed\nfor each habitat, and migration or mutation thresholds are\nestablished. During migration or mutation operations, instead\nof comparing the migration or mutation rates of each habitat\nthrough traditional random number generation, the entropy\nof the habitat to be migrated or mutated is calculated as\na weight against the migration or mutation rate. Then, this\nweight is compared with the initial habitat threshold using a\nroulette selection method, and each habitat is updated after\neach migration or mutation operation, ensuring that each up-\ndate considers the information of the population. The specific\noperations are as follows: when performing migration and\nmutation operations, we need to use the roulette selection\nmethod to select the SIV[i] to be operated on, obtain its\nentropy value, and compare it with the migration rate. The\ncalculation method for entropy is shown in Formula 1:\nprob[i] =−\nX\nP(xi)logP(xi) (1)\nWhere xi ∈ Rm×n represents the i-th attribute value, P(xi)\ndenotes the probability of the i-th SIV , then using the infor-\nmation entropy as weights to update the value of SIVs[i], the\nspecific calculation is as shown in Formula 2:\nSIV ′[k] =SIV [k] +prob[i] ∗ (SIV [i] − SIV [k]) (2)\n4 VOLUME 11, 2023\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386405\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nTABLE 3. CIC-IDS2017 feature subset filtered by BBO.\nRanks Features Ranks Features\n1 ECE Flag Count 31 Fwd Packet Length Min\n2 RST Flag Count 32 Init_Win_bytes_forward\n3 Fwd Avg Packets/Bulk 33 Fwd IAT Min\n4 Bwd Avg Bulk Rate 34 Packet Length Variance\n5 Bwd URG Flags 35 Init_Win_bytes_backward\n6 Bwd Avg Bytes/Bulk 36 Active Max\n7 Fwd URG Flags 37 Destination Port\n8 Bwd Avg Packets/Bulk 38 Min Packet Length\n9 Fwd Avg Bulk Rate 39 Total Fwd Packets\n10 CWE Flag Count 40 Flow Duration\n11 Fwd Avg Bytes/Bulk 41 Bwd IAT Min\n12 Bwd PSH Flags 42 Total Length of Bwd Packets\n13 Fwd PSH Flags 43 Flow IAT Min\n14 SYN Flag Count 44 Fwd Packet Length Std\n15 URG Flag Count 45 Total Backward Packets\n16 FIN Flag Count 46 Avg Bwd Segment Size\n17 Active Std 47 Total Length of Fwd Packets\n18 Fwd Packet Length Min 48 Average Packet Size\n19 ACK Flag Count 49 Fwd IAT Mean\n20 Subflow Fwd Bytes 50 Bwd Packet Length Min\n21 Fwd IAT Total 51 Active Min\n22 Active Mean 52 Bwd IAT Std\n23 Flow IAT Std 53 Idle Mean\n24 Bwd Packets/s 54 Fwd Packet Length Mean\n25 Max Packet Length 55 Packet Length Mean\n26 Flow IAT Max 56 PSH Flag Count\n27 Fwd IAT Std 57 Subflow Fwd Packets\n28 Idle Max 58 Bwd Packet Length Std\n29 Flow IAT Mean 59 Down/Up Ratio\n30 Bwd Packet Length Max 60 Fwd Packets/s\nTABLE 4. NSL-KDD feature subset filtered by BBO.\nRanks Features Ranks Features\n1 src_bytes 7 dst_host_same_src_port_rate\n2 dst_bytes 8 dst_host_srv_diff_host_rate\n3 dst_host_count 9 dst_host_serror_rate\n4 dst_host_srv_count 10 dst_host_srv_serror_rate\n5 dst_host_same_srv_rate 11 dst_host_rerror_rate\n6 dst_host_diff_srv_rate 12 dst_host_srv_rerror_rate\nWhere i is the information entropy of the i-th feature after\nroulette selection, prob is the information entropy of the i-th\nfeature, SIV[i] is the most weighted of the SIVs, and SIV[j]\nis the least weighted of the SIVs. After several rounds of\nselection, the performance of the SIVs is obtained.\nThe distribution of features can be visualized, and the final\nranking of features in the CIC-IDS 2017 dataset and the NSL-\nKDD can be derived.as shown in Table 3 and Table 4:\n3.3 CFAT\nAfter feature selection, the dataset retains the most crucial\nfeature values, enabling subsequent model training to focus\non these key features. To preserve global feature information\nand further enhance the model’s computational efficiency, we\npropose the CFAT model. This model redesigns the network\narchitecture into a hierarchical structure, connecting various\nlayers and employing CNN networks between layers to facil-\nitate information flow. Additionally, it incorporates the LPU\nmodule into the multi-head attention mechanism, aiming to\npreserve contextual information and establish residual con-\nnections with the results of using linear addition to com-\npute attention vectors, promoting the fusion of features into\nglobal vectors. To further reduce computational complexity,\nthe multi-head attention mechanism utilizes deep separable\nconvolutional networks to decrease computational space and\nimprove computation speed. The network model of CFAT is\nillustrated in Figure 3.\nIn the traditional Transformer network, given an input of\nsize R mxn, the original multi-head attention mechanism first\ngenerates Query, Key, and Value matrices. By performing dot\nproduct operations between Query and Key, it produces a\nweight matrix of size R mxn, as shown in Equation (3).\nAttn(Q, K, V ) =Softmax(QKT\n√dk\n)V (3)\nWhere dk is the number of columns of the Q,K matrix, i.e.,\nthe vector dimension.\nIn this paper, we first utilize a new dataset E ∈ R Nxd,\nwhere N is the query length and d is the dimensionality ob-\ntained after feature selection. This dataset is transformed into\nlinear sequences Q, K, and V through linear transformations.\nThe dimensions of the generated Q, K, and V matrices are\nQ, K, V ∈ R Nxd, where Q = [q1, q2, q3, ...,qd ], K =\n[k1, k2, k3, ...,kd ], and V = [v1, v2, v3, ...,vd ]. To enhance\nthe interaction efficiency between data queries, keys, and\nvalues, and to reduce the complexity of computing attention,\nwe adopt an additive attention mechanism. This mechanism\nenables retrieval of crucial information in linear complexity.\nTherefore, we first use the additive attention mechanism to\ntransform queries, keys, and values into q, k, and v respec-\ntively, each of dimension q, k, v ∈ Rd, to retain contextual\ninformation. Specifically, the attention weight for the i-th\nquery vector is computed as shown in Equation (4).\nαi = exp(W T\nq qi/\n√\nd\nPN\nj=1 exp(W Tq qi/\n√\nd)\n(4)\nWhere Wq ∈ Rd is a learnable parameter vector, thus the\nglobal query vector is computed as shown in Equation (5).\nq =\nNX\ni=1\nαiqi (5)\nIn the subsequent steps, the obtained global vector interacts\nwith the Key matrix to retain the contextual information from\nthe previous part. Thus, a global vector \"k\" containing context\ninformation is obtained. The i-th variable in this matrix is\ndenoted as pi = q · Ki, allowing for the calculation of the\nattention weight for the i-th key vector, as shown in Equation\n(6).\nβi = exp(W T\nk′ pi/√dk\nPN\nj=1 exp(W T\nk′ pi/√dk )\n(6)\nWhere W ′\nk ∈ Rd is a learnable parameter vector, thus the\nglobal query vector is as shown in Equation (7).\nk =\nNX\ni=1\nβipi (7)\nVOLUME 11, 2023 5\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386405\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nFIGURE 3. CFAT network model\nBy applying depth separable convolution with a stride of\nK′, represented as DWConv(K), where K′ ∈ R(N/k2∗dk ) , the\ncomputational space is compressed by a factor of k, resulting\nin the acceleration of the calculation of the K-V interaction\nvector. This approach underscores the advantages of utilizing\ndepth separable convolution, which significantly enhances\nthe computational efficiency of the K-V interaction vector,\ndenoted as ui.\nSimilarly, vector weights for the i-th value vector can be\nobtained, and computational space can be compressed using\nkxk depth-separable convolution, as shown in Equation 8.\nγi = exp(W T\nV ′ ti/√dv\nPN\nj=1 exp(W T\nV ′ ti/√dv)\n(8)\nWhere W(v′) ∈ Rd is a learnable parameter vector, and ti\nis obtained by taking the dot product of the global variable k\nand Vi. Thus, the global query vector is as shown in Equations\n9 and 10:\nv =\nNX\ni=1\nγiti (9)\nV ′ = DWConv(V ) ∈ R\nN\nV 2 ∗dv (10)\nThen the K-V interaction vector ui is calculated with the\nexpression ui = k ∗ vi. Finally, the output is obtained by\nsumming with the original query vector. The structure is\nshown in Figure 4.\n4. EXPERIMENTS\n4.1 EVALUATION METRICS\nThe experiment is calculated from Table 5.\nThe True Positive (TP) samples are those with a positive\ntrue category, and the model correctly predicts them as pos-\nitive. True Negative (TN) samples are those with a negative\ntrue category, and the model correctly predicts them as nega-\ntive.\nFIGURE 4. The data is first transformed into linear vectors and context\ninformation is compressed into global vectors. Subsequently, key-value\npairs are compressed using depth separable convolution to reduce\ncomputational space.\nThe experiment employs various evaluation metrics,\nnamely Accuracy, Precision, Recall, and F1-score. Accuracy\ndenotes the model’s capability to correctly classify samples in\nrelation to the overall sample size. Precision reflects the ratio\nof true positive predictions to the total number of samples\npredicted as positive. Recall indicates the proportion of true\n6 VOLUME 11, 2023\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386405\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nTABLE 5. Temperature and wildlife count in the three areas covered by\nthe study.\nReal\nPrejected Positive Negative\nPositive TP FN\nNegative FP TN\npositive samples to the total samples that should have been\naccurately classified as positive. The F1-score is a harmo-\nnized mean that balances Precision and Recall. The formula\nfor each evaluation metric is as follows:\nAccuracy = TP + TN\nTP + TN + FN + FP (11)\nPrecision = TP\nTP + TN (12)\nRecall = TP\nTP + FN (13)\nF1score = 2 × Precision × Recall\nPrecision + Recall (14)\nIn the multiclass task, the accuracy of the multiclassifi-\ncation is obtained by dividing the number of all correctly\nclassified data by the total number of data, shown in (14). Pre-\ncision, Recall, and F1 Score are calculated separately for each\ncategory, and then these values are summed and averaged\nto obtain the evaluation criteria for the multiclassification\ntask.For example, Precision is calculated as shown in (15):\nAccuracymulti =\nPn\ni=1 TPiPn\ni=1(TPi) +FPi\n(15)\nPrecisionmulti =\nPn\ni=1 Pi\nn (16)\n4.2 PARAMETER SETTINGS\nThe difference in hyperparameters affects the model’s conver-\ngence speed and the experiment’s accuracy. The hyperparam-\neter settings for this experiment are shown in Table 6 below:\nTABLE 6. Table of hyperparameter settings.\nParameters Values\nBatchSize 512\nDrop 0.1\nqkv_bias True\nratio_ffn 3.6\ninput_channels 3\nd_models [256,64,128,256,512]\nnum_heads 1,2,4,8\nrs_ratio 8,4,2,1\nepoch 50\nIn this experiment, the CFAT model employs the Adam op-\ntimizer to optimize model parameters, adjusting the learning\nrate, and utilizes CrossEntropyLoss as the loss function.\nTABLE 7. Comparative feature selection experiments based on the\nCIC-IDS2017 dataset.\nReference Method Accuracy(%)\nZegarra et al [41] TabNet 97.03\nYao R et al [42] XGBoost 91.06\nKareem et al [43] GTO-BSA 98.79\nJeyaselvi, M. et al [44] EXPSO-STFA 95.65\nProposed BBO 99.1\nTABLE 8. Comparative feature selection experiments based on the\nNSL-KDD dataset.\nReference Method Accuracy(%)\nYaseen et al [45] differential evalution 80.15\nYao R et al [42] XGBoost 91.06\nKareem et al [43] GTO-BSA 95.59\nIngre et al [46] CFS+ANN 79.9\nProposed BBO 97.5\n4.3 FEATURE SELECTION EXPERIMENT AND ANALYSIS\nIn this section, we compare the BBO feature selection method\nwith the latest feature selection methods. Our aim is to il-\nlustrate their similarities, highlight the unique advantages\noffered by our method, and reflect the algorithm’s superior-\nity through accuracy. The experimental results are shown in\nTable 7 and Table 8.\nThe experimental results presented in Tables 7 and 8\ndemonstrate that the proposed feature selection method\nachieved significant improvements in accuracy on both\ndatasets, outperforming other comparative experiments. This\nsuggests the feasibility and superiority of our proposed algo-\nrithm in feature selection compared to some existing methods.\nParticularly notable improvements were observed, especially\non the NSL-KDD dataset.\n4.4 EXPERIMENTAL RESULTS AND ANALYSIS\nTo evaluate the feasibility of the proposed model on the\ndatasets and assess its robustness in real-world scenar-\nios, we conducted anomaly detection and prediction ex-\nperiments on two datasets. In this study, we explored\nthe superiority of the model by combining machine\nlearning with deep learning models, including common\ndeep composite models such as BiLSTM-DNN (BD),\nMultiAttention-BiLSTM-DNN (MBD), Transformer-DNN\n(TD), Position-Transformer-DNN (PTD), and Encoder-\nBiLSTM-DNN (EBD). To further validate the feasibility\nof the proposed model, recent intrusion detection models\nwere selected for comparison. This experiment was imple-\nmented using PyTorch in Python and executed on a computer\nequipped with an NVIDIA GeForce RTX 3080Ti graphics\ncard. The experimental results of different models on the two\ndatasets are shown in Tables 9, Tables10.\nThe above table demonstrates that the proposed model per-\nforms well on various performance metrics, surpassing most\nof the control experiments. It is noteworthy that the activa-\ntion function Wib-ReLU, proposed by Olimov [40], was em-\nployed in this experiment. This activation function addresses\nVOLUME 11, 2023 7\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386405\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nTABLE 9. Comparison of experimental results of different algorithms on\nthe CIC-IDS2017 dataset\nModel classification indicators%\nAccuracy Precision Recall F1-score\nSVM 0.660 0.401 0.401 0.368\nLR 0.685 0.715 0.423 0.418\nNB 0.346 0.299 0.611 0.199\nBD 0.980 0.753 0.793 0.767\nMBD 0.650 0.539 0.551 0.545\nTD 0.986 0.966 0.904 0.927\nPTD 0.963 0.829 0.708 0.734\nEBD 0.956 0.643 0.553 0.551\nCFAT 0.991 0.972 0.941 0.945\nTABLE 10. Comparison of experimental results of different algorithms on\nthe NSL-KDD dataset\nModel classification indicators%\nAccuracy Precision Recall F1-score\nSVM 0.767 0.865 0.612 0.749\nLR 0.778 0.868 0.631 0.764\nNB 0.807 0.875 0.580 0.821\nBD 0.864 0.876 0.845 0.882\nMBD 0.875 0.882 0.901 0.710\nTD 0.851 0.955 0.762 0.847\nPTD 0.875 0.929 0.861 0.876\nEBD 0.879 0.950 0.841 0.887\nCFAT 0.975 0.945 0.948 0.921\nthe issue of increasing activation mean through weight initial-\nization, thereby facilitating smoother model training. Figures\n5 and 6 depict the performance of each model in training and\ntesting on two datasets.\nFurthermore, for a better assessment of the model’s predic-\ntive accuracy, reference can be made to the confusion matrices\ndepicted in Figures 7 and 8.To further validate the feasibility\nTABLE 11. Below is a comparison of CFAT with other intrusion detection\nmodels on the CIC-IDS2017 dataset.\nReference Method Accauary(%)\nMehedi et al [47] LeNet 98.10\nElnakib et al [48] EIDM 95.00\nChoobdar et al [49] DT 98.38\nJaradat et al [50] DT 98.50\nOurs CFAT 99.10\nTABLE 12. Below is a comparison of CFAT with other intrusion detection\nmodels on the NSL-KDD dataset.\nReference Method Accauary(%)\nVinayakumar et al [51] DNN 78.50\nGamage et al [52] LSTM 77.26\nAlazab et al [53] CossimMFO+DT 89.70\nJie et al et al [54] SingleSVM 97.39\nOurs CFAT 97.5\nTABLE 13. Performance gains obtained for different modules on\nCIC-IDS2017 dataset,✓indicates that the corresponding module has been\nadded to the method\nTransformer DWconv ReLU wib-ReLu Accaury(%)\n✓ 96.5\n✓ ✓ 97.6\n✓ ✓ ✓ 97.5\n✓ ✓ ✓ 99.1\nTABLE 14. Performance gains obtained for different modules on\nNSL-KDD dataset,✓indicates that the corresponding module has been\nadded to the method\nTransformer DWconv ReLU wib-ReLu Accaury(%)\n✓ 90.2\n✓ ✓ 93.2\n✓ ✓ ✓ 84.5\n✓ ✓ ✓ 97.5\nof the proposed model, a comparison is conducted with prior\nstudies. As shown in Table 11 and Table 12.\n4.5 ABLATION EXPERIMENTS\nTables 13 and 14 summarize the performance of differ-\nent modules on the two datasets. The experimental results\ndemonstrate that each module is compatible, and the com-\nbination effect yields the best results. Additionally, the data\nin the tables indicate that the performance of the Wib-ReLU\nactivation function [40] is superior to ReLU. This activation\nfunction addresses the issue of increasing the activation func-\ntion mean through weight initialization. Ultimately, CFAT\nachieved an improvement of over 5% in accuracy.\nFIGURE 5. Comparison display of each model in the CIC-IDS2017 dataset.\n4.6 SCALABILITY\nAccording to Keuper et al. [56], two specific bottlenecks in\ndeep neural networks are communication overhead and ma-\ntrix operations. However, this paper eliminates the obstacles\nto scalability caused by matrix operations by changing the\nmethod of computing attention weights using a linear additive\ncalculation instead of matrix operations. Additionally, in our\n8 VOLUME 11, 2023\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386405\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nFIGURE 6. Comparison display of each model in the NSL-KDD dataset.\nFIGURE 7. The Confusion matrix of the CIC-IDS2017 dataset\nFIGURE 8. The Confusion matrix of the NSL-KDD dataset\nreal-world deployment scenarios, the entire training set can\nbe stored on local SSDs at each worker node, avoiding the\noverhead of accessing data during communication.\nFurthermore, due to the uncertainty of population size,\nthe dimensionality of system state representation dynami-\ncally changes, which limits the scalability of deep models.\nHowever, the feature fusion method of attention mechanisms\ncan adapt to dynamic changes in real-world scenarios and\nassign different weights to nodes in reality. There has been a\nlot of research on achieving scalability through self-attention\nmechanisms, which has been applied in real-world scenarios\nby Hu et al. [57], Zhang et al. [58], and Zhou et al. [59].\n5. CONCLUSIONS\nThis paper introduces an improved BBO algorithm for feature\nselection in two datasets, employing the CFAT model for\nanomaly detection and prediction. Based on the utilization\nof Transformer’s multi-head attention mechanism to acquire\nglobal feature information, CFAT redesigns a hierarchical\nconnection structure to preserve both upper and lower-level\nfeature information. Additionally, deep separable convolu-\ntions are employed to enhance the multi-head attention mech-\nanism and further reduce computational complexity. Com-\npared to the contrast experimental models used in this study,\nCFAT demonstrates significant improvements in all perfor-\nmance metrics, thereby better fulfilling the tasks of anomaly\ndetection and prediction. However, it is noteworthy that both\ndatasets exhibit severe imbalance, which is addressed in this\nstudy by utilizing OSS and Borderline-SMOTE methods. Al-\nthough effective, there remains room for further optimization\nin future research. Future studies may explore binary text\nclassification solutions for detecting malicious traffic and\nstrategies for achieving real-time detection tasks.\nDATA AVAILABILITY\nThe data that support the findings of this study are openly\navailable in Canadian Institute of Cybersecurity (CIC)\nResearch Project at http://205.174.165.80/CICDataset/CIC-\nIDS-2017/.\nCONFLICTS OF INTEREST\nThe authors affirm that they have no conflicts of interest with\nrespect to the publication of this paper.\nREFERENCES\n[1] Bahareh Gholipour Goodarzi, Hamid Jazayeri, and Soheil Fateri. Intrusion\ndetection system in computer network using hybrid algorithms (svm and\nabc). Journal of Advances in Computer Research, 5(4):43–52, 20\n[2] Dong Seong Kim, Ha-Nam Nguyen, Syng-Yup Ohn, and Jong Sou Park.\nFusions of ga and svm for anomaly detection in intrusion detection sys-\ntem. In Advances in Neural Networks–ISNN 2005: Second International\nSymposium on Neural Networks, Chongqing, China, May 30-June 1, 2005,\nProceedings, Part III 2, pages 415–420. Springer, 2\n[3] Nong Ye, Syed Masum Emran, Qiang Chen, and Sean Vilbert. Multivariate\nstatistical analysis of audit trails for host-based intrusion detection. IEEE\nTransactions on computers, 51(7):810–820, 20\n[4] Minh Tuan Nguyen and Kiseon Kim. Genetic convolutional neural network\nfor intrusion detection systems. Future Generation Computer Systems,\n113:418–427, 2020.\n[5] Yongcheng Duan, Xin Li, Xue Yang, and Le Yang. Network security\nsituation factor extraction based on random forest of information gain. In\nProceedings of the 4th International Conference on Big Data and Comput-\ning, pages 194–197, 2019.\n[6] Lincy Elizebeth Jim and Jim Chacko. Decision tree based ais strategy for\nintrusion detection in manet. In TENCON 2019-2019 IEEE Region 10\nConference (TENCON), pages 1191–1195. IEEE, 2019.\n[7] B Gohil Narendrasinh and Dwivedi Vdevyas. Flbs: Fuzzy lion bayes\nsystem for intrusion detection in wireless communication network. Journal\nof Central South University, 26(11):3017–3033, 2019.\nVOLUME 11, 2023 9\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386405\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\n[8] Hao Zhang, Yongdan Li, Zhihan Lv, Arun Kumar Sangaiah, and Tao\nHuang. A real-time and ubiquitous network attack detection based on\ndeep belief network and support vector machine. IEEE/CAA Journal of\nAutomatica Sinica, 7(3):790–799, 2020.\n[9] Stefano Longari, Daniel Humberto Nova Valcarcel, Mattia Zago, Michele\nCarminati, and Stefano Zanero. Cannolo: An anomaly detection system\nbased on lstm autoencoders for controller area network. IEEE Transactions\non Network and Service Management, 18(2):1913–1924, 2020.\n[10] Gabriel C Fernández and Shouhuai Xu. A case study on using deep learning\nfor network intrusion detection. In MILCOM 2019-2019 IEEE Military\nCommunications Conference(MILCOM), pages 1–6. IEEE, 2019.\n[11] Majdi Mafarja, Ali Asghar Heidari, Maria Habib, Hossam Faris, Thaer\nThaher, and Ibrahim Aljarah. Augmented whale feature selection for iot\nattacks: Structure, analysis and applications. Future Generation Computer\nSystems, 112:18–40, 2020.\n[12] Taief Alaa Alamiedy, Mohammed Anbar, Zakaria NM Alqattan, and\nQusay M Alzubi. Anomaly-based intrusion detection system using multi-\nobjective grey wolf optimisation algorithm. Journal of Ambient Intelli-\ngence and Humanized Computing, 11:3735–3756, 2020.\n[13] Liqun Liu, Bing Xu, Xiaoping Zhang, and Xianjun Wu. An intrusion\ndetection method for internet of things based on suppressed fuzzy clus-\ntering. EURASIP Journal on Wireless Communications and Networking,\n2018(1):1–7, 2018.\n[14] Wathiq Laftah Al-Yaseen, Ali Kadhum Idrees, and Faezah Hamad Alma-\nsoudy. Wrapper feature selection method based differential evolution and\nextreme learning machine for intrusion detection system. Pattern Recogni-\ntion, 132:108912, 2022.\n[15] Zahid Halim, Muhammad Nadeem Yousaf, Muhammad Waqas, Muham-\nmad Sulaiman, Ghulam Abbas, Masroor Hussain, Iftekhar Ahmad, and\nMuhammad Hanif. An effective genetic algorithm-based feature selec-\ntion method for intrusion detection systems. Computers & Security,\n110:102448, 2021.\n[16] Dan Simon. Biogeography-based optimization. IEEE transactions on evo-\nlutionary computation, 12(6):702–713, 2008.\n[17] Wassila Guendouzi and Abdelmadjid Boukra. Gab-bbo: Adaptive bio-\ngeography based feature selection approach for intrusion detection. Inter-\nnational Journal of Computational Intelligence Systems, 10(1):914–935,\n2017.\n[18] Dimitrios Papamartzivanos, Félix Gómez Mármol, and Georgios Kam-\nbourakis. Dendron: Genetic trees driven rule induction for network\nintrusion detection systems. Future Generation Computer Systems,\n79:558–574, 2018.\n[19] Setareh Roshan, Yoan Miche, Anton Akusok, and Amaury Lendasse.\nAdaptive and online network intrusion detection system using cluster-\ning and extreme learning machines. Journal of the Franklin Institute,\n355(4):1752–1779, 2018.\n[20] Tarfa Hamed, Rozita Dara, and Stefan C Kremer. Network intrusion de-\ntection system based on recursive feature addition and bigram technique.\ncomputers & security, 73:137–155,2018.\n[21] Sweta Bhattacharya, Praveen Kumar Reddy Maddikunta, Rajesh Kaluri,\nSaurabh Singh, Thippa Reddy Gadekallu, Mamoun Alazab, and Usman\nTariq. A novel pca-firefly based xgboost classification model for intrusion\ndetection in networks using gpu. Electronics, 9(2):219, 2020.\n[22] Yaping Chang, Wei Li, and Zhongming Yang. Network intrusion detec-\ntion based on random forest and support vector machine. In 2017 IEEE\ninternational conference on computational science and engineering (CSE)\nand IEEE international conference on embedded and ubiquitous computing\n(EUC), volume 1, pages 635–638. IEEE, 2017.\n[23] Hongwei Ding, Leiyang Chen, Liang Dong, Zhongwang Fu, and Xiaohui\nCui. Imbalanced data classification: A knn and generative adversarial\nnetworks-based hybrid approach for intrusion detection. Future Generation\nComputer Systems, 131:240–254, 2022.\n[24] Xiu Kan, Yixuan Fan, Zhijun Fang, Le Cao, Neal N Xiong, Dan Yang,\nand Xuan Li. A novel iot network intrusion detection approach based\non adaptive particle swarm optimization convolutional neural network.\nInformation Sciences, 568:147–162, 2021.\n[25] Congyuan Xu, Jizhong Shen, and Xin Du. A method of few-shot network\nintrusion detection based on meta-learning framework. IEEE Transactions\non Information Forensics and Security, 15:3540–3552, 2020.\n[26] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion\nJones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is\nall you need. Advances in neural information processing systems, 30, 2017.\n[27] Yifan Li, Xiaoyan Peng, Jia Zhang, Zhiyong Li, and Ming Wen. Dct-\ngan: Dilated convolutional transformer-based gan for time series anomaly\ndetection. IEEE Transactions on Knowledge and Data Engineering, 2021.\n[28] Zekai Chen, Dingshuo Chen, Xiao Zhang, Zixuan Yuan, and Xiuzhen\nCheng. Learning graph structures with transformer for multivariate\ntime-series anomaly detection in iot. IEEE Internet of Things Journal,\n9(12):9179–9189, 2021.\n[29] Shreshth Tuli, Giuliano Casale, and Nicholas R Jennings. Tranad: Deep\ntransformer networks for anomaly detection in multivariate time series\ndata. arXiv preprint arXiv:2201.07284, 2022.\n[30] Xueying Han, Susu Cui, Song Liu, Chen Zhang, Bo Jiang, and Zhigang Lu.\nNetwork intrusion detection based on n-gram frequency and time-aware\ntransformer. Computers & Security, 128:103171, 2023.\n[31] Jianyuan Guo, Kai Han, Han Wu, Yehui Tang, Xinghao Chen, Yunhe\nWang, and Chang Xu. Cmt: Convolutional neural networks meet vision\ntransformers. In Proceedings of the IEEE/CVF Conference on Computer\nVision and Pattern Recognition, pages 12175–12185, 2022.\n[32] Chuhan Wu, Fangzhao Wu, Tao Qi, Yongfeng Huang, and Xing Xie.\nFastformer: Additive attention can be all you need. arXiv preprint\narXiv:2108.09084, 2021.\n[33] I. Ullah and Q. H. Mahmoud, “Design and development of a deep learning-\nbased model for anomaly detection in IoT networks,” IEEE Access, vol. 9,\npp. 103906–103926, 2021\n[34] Rakhmonov, Akhrorjon Akhmadjon Ugli et al. “Extensive Knowledge\nDistillation Model: An End-to-End Effective Anomaly Detection Model\nfor Real-Time Industrial Applications.” IEEE Access 11 (2023): 69750-\n69761.\n[35] Aechan Kim, Mohyun Park, and Dong Hoon Lee. Ai-ids: Application\nof deep learning to real-time web intrusion detection. IEEE Access,\n8:70245–70261, 2020.\n[36] Francois Alin, Amine Chemchem, Florent Nolot, Olivier Flauzac, and\nMichaël Krajecki. Towards a hierarchical deep learning approach for in-\ntrusion detection. In Machine Learning for Networking: Second IFIP TC 6\nInternational Conference, MLN 2019, Paris, France, December 3–5, 2019,\nRevised Selected Papers 2, pages 15–27. Springer, 2020.\n[37] Henry, Azriel et al. “Composition of Hybrid Deep Learning Model and\nFeature Optimization for Intrusion Detection System.” Sensors (Basel,\nSwitzerland) 23 (2023): n. pag.\n[38] Altunay, Hakan Can and Zafer Albayrak. “A hybrid CNN + LSTMbased\nintrusion detection system for industrial IoT networks.” Engineering Sci-\nence and Technology, an International Journal (2023): n. pag.\n[39] Bhawana Sharma, , Lokesh Sharma, Chhagan Lal, Satyabrata Roy.\n\"Anomaly based network intrusion detection for IoT attacks using deep\nlearning technique\". Comput. Electr. Eng. 107. (2023): 108626.\n[40] Olimov, Bekhzod et al. “Weight initialization based-rectified linear unit\nactivation function to improve the performance of a convolutional neural\nnetwork model.” Concurrency and Computation: Practice and Experience\n33 (2020): n. pag.\n[41] Zegarra Rodríguez, Demóstenes et al. “Attentive transformer deep learning\nalgorithm for intrusion detection on IoT systems using automatic Xplain-\nable feature selection.” PLOS ONE 18 (2023): n. pag.\n[42] Yao, Ruizhe et al. “A CNN-transformer hybrid approach for an intrusion\ndetection system in advanced metering infrastructure.” Multimedia Tools\nand Applications 82 (2022): 19463-19486.\n[43] Kareem, Saif Salah et al. “An Effective Feature Selection Model Using\nHybrid Metaheuristic Algorithms for IoT Intrusion Detection.” Sensors\n(Basel, Switzerland) 22 (2022): n. pag.\n[44] Jeyaselvi, M. et al. “A highly secured intrusion detection system for IoT us-\ning EXPSO-STFA feature selection for LAANN to detect attacks.” Cluster\nComputing 26 (2022): 559-574.\n[45] Al-Yaseen, Wathiq Laftah et al. “Wrapper feature selection method based\ndifferential evolution and extreme learning machine for intrusion detection\nsystem.” Pattern Recognit. 132 (2022): 108912.\n[46] B. Ingre, A. Yadav, Performance analysis of NSL-KDD dataset using ANN,\nin:2015 international conference on signal processing and communication\nengineering systems, IEEE, 2015, pp. 92–96.\n[47] Mehedi, Sk. Tanzir et al. “Deep Transfer Learning Based Intrusion Detec-\ntion System for Electric Vehicular Networks.” Sensors (Basel, Switzerland)\n21 (2021): n. pag.\n[48] Elnakib, Omar et al. “EIDM: deep learning model for IoT intrusion detec-\ntion systems.” The Journal of Supercomputing 79 (2023): 13241 - 13261.\n[49] Choobdar, Padideh et al. “Detection and Multi-Class Classification of\nIntrusion in Software Defined Networks Using Stacked Auto-Encoders and\n10 VOLUME 11, 2023\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386405\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nCICIDS2017 Dataset.” Wireless Personal Communications 123 (2021):\n437 - 471.\n[50] Jaradat, Ameera Saleh et al. “Network intrusion detection system: machine\nlearning approach.” Indonesian Journal of Electrical Engineering and Com-\nputer Science (2022): n. pag.\n[51] R. Vinayakumar, M. Alazab, K. P. Soman, P. Poornachandran, A. AlNem-\nrat, and S. Venkatraman, “Deep learning approach for intelligent intrusion\ndetection system”, IEEE Access, vol 7, pp 41525–41550, 2019.\n[52] S. Gamage and J. Samarabandu, “Deep learning methods in network\nintrusion detection: A survey and an objective comparison”, Journal of\nNetwork and Computer Applications, vol 169, pp 102767, 2020.\n[53] Alazab, M. , et al. \"A new intrusion detection system based on Moth-Flame\nOptimizer algorithm.\" Expert Syst. Appl. 210(2022):118439.\n[54] Gu, Jie , et al. \"A novel approach to intrusion detection using SVM\nensemble with feature augmentation.\" (2019).\n[55] Olimov, Bekhzod et al. “UzADL: Anomaly detection and localization us-\ning graph Laplacian matrix-based unsupervised learning method.” Comput.\nInd. Eng. 171 (2022): 108313.\n[56] Keuper, Janis , and F. J. Pfreundt . \"Distributed Training of Deep Neural\nNetworks: Theoretical and Practical Limits of Parallel Scalability.\" IEEE\n(2016).\n[57] Hu S Y , Zhu F D, Chang X J, et al. UPDeT: Universal multi-agent rein-\nforcement learning via policy decoupling with transformers[J/OL]. 2021,\narXiv: 2101.08001.\n[58] Zhang T J, Xu H Z, Wang X L, et al. Multi-agent collaboration via reward\nattribution decomposition[J/OL]. 2020, arXiv: 2010.08531.\n[59] Zhou T Z, Zhang F B, Shao K, et al. Cooperative multi-agent transfer learn-\ning with level-adaptive credit assignment[J/OL]. 2021, arXiv: 2106.00517.\nTINGYAO JIANGwas born in 1969. He is a pro-\nfessor and a doctoral supervisor at the College\nof Computer and Information Technology in the\nChina Three Gorges University. He received his\nmaster’s degree in 2001 and his PhD in 2004\nat the school of computer science & technology,\nHuazhong University of Science and Technol-\nogy. His research interests include artificial intelli-\ngence, and information security.\nXIAOBO FU is currently studying for a master’s\ndegree at the School of Computer Information,\nChina Three Gorges University. Research interests\ninclude deep learning and computer science.\nMIN WANG was born in 1983. She is a lecturer\nat the School of Electronic Information, Hubei\nThree Gorges Polytechnic. She received her mas-\nter’s degree in 2009 at the College of Computer\nand Information Technology in the China Three\nGorges University. Her research interests include\nmachine learning and information security.\nVOLUME 11, 2023 11\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386405\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/"
}