{
  "title": "Creating and Comparing Dictionary, Word Embedding, and Transformer-Based Models to Measure Discrete Emotions in German Political Text",
  "url": "https://openalex.org/W4283688409",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2106796896",
      "name": "Tobias Widmann",
      "affiliations": [
        "Aarhus University"
      ]
    },
    {
      "id": "https://openalex.org/A3104796061",
      "name": "Maximilian Wich",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A2106796896",
      "name": "Tobias Widmann",
      "affiliations": [
        "Aarhus University"
      ]
    },
    {
      "id": "https://openalex.org/A3104796061",
      "name": "Maximilian Wich",
      "affiliations": [
        "Technical University of Munich"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2079823081",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W3033187248",
    "https://openalex.org/W2112994583",
    "https://openalex.org/W2956747517",
    "https://openalex.org/W3159574466",
    "https://openalex.org/W2159383898",
    "https://openalex.org/W2945604148",
    "https://openalex.org/W3160678122",
    "https://openalex.org/W2166223025",
    "https://openalex.org/W4398618744",
    "https://openalex.org/W2111865765",
    "https://openalex.org/W1966458114",
    "https://openalex.org/W2171970128",
    "https://openalex.org/W3034323190",
    "https://openalex.org/W2797669327",
    "https://openalex.org/W2948248330",
    "https://openalex.org/W6736575291",
    "https://openalex.org/W2095655043",
    "https://openalex.org/W2954211942",
    "https://openalex.org/W2145016159",
    "https://openalex.org/W2493916176",
    "https://openalex.org/W2895021214",
    "https://openalex.org/W2521348577",
    "https://openalex.org/W1614298861",
    "https://openalex.org/W2912215939",
    "https://openalex.org/W4398387079",
    "https://openalex.org/W2093738325",
    "https://openalex.org/W2151543699",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W2013413196",
    "https://openalex.org/W2160660844",
    "https://openalex.org/W2134972645",
    "https://openalex.org/W2883453492",
    "https://openalex.org/W2132041136",
    "https://openalex.org/W2040467972",
    "https://openalex.org/W2896902574",
    "https://openalex.org/W3080084198",
    "https://openalex.org/W4385681388",
    "https://openalex.org/W2568636341",
    "https://openalex.org/W2487770199",
    "https://openalex.org/W2111975591",
    "https://openalex.org/W2848303245",
    "https://openalex.org/W3040245432",
    "https://openalex.org/W2072514260",
    "https://openalex.org/W2157684370",
    "https://openalex.org/W1590495275",
    "https://openalex.org/W2955724683",
    "https://openalex.org/W2991253660",
    "https://openalex.org/W2996035354",
    "https://openalex.org/W2250857917",
    "https://openalex.org/W2785013156",
    "https://openalex.org/W632139601",
    "https://openalex.org/W2320012450",
    "https://openalex.org/W2986154550",
    "https://openalex.org/W2780932362",
    "https://openalex.org/W1971222444",
    "https://openalex.org/W2794635328",
    "https://openalex.org/W28957472",
    "https://openalex.org/W3103365499",
    "https://openalex.org/W2489406233",
    "https://openalex.org/W3103187652",
    "https://openalex.org/W1543632889"
  ],
  "abstract": "Abstract Previous research on emotional language relied heavily on off-the-shelf sentiment dictionaries that focus on negative and positive tone. These dictionaries are often tailored to nonpolitical domains and use bag-of-words approaches which come with a series of disadvantages. This paper creates, validates, and compares the performance of (1) a novel emotional dictionary specifically for political text, (2) locally trained word embedding models combined with simple neural network classifiers, and (3) transformer-based models which overcome limitations of the dictionary approach. All tools can measure emotional appeals associated with eight discrete emotions. The different approaches are validated on different sets of crowd-coded sentences. Encouragingly, the results highlight the strengths of novel transformer-based models, which come with easily available pretrained language models. Furthermore, all customized approaches outperform widely used off-the-shelf dictionaries in measuring emotional language in German political discourse.",
  "full_text": "CreatingandComparingDictionary,Word\nEmbedding,andTransformer-BasedModelsto\nMeasureDiscreteEmotionsinGerman\nPoliticalText\nTobiasWidmann 1andMaximilianWich 2\n1DepartmentofPoliticalScience,AarhusUniversity,BartholinsAllé7,8000Aarhus,Denmark.Email: widmann@ps.au.dk\n2DepartmentofInformatics,TechnicalUniversityMunich,Boltzmannstraße3,85748Garching,Germany.\nEmail:maximilian.wich@tum.de\nAbstract\nPreviousresearchonemotionallanguagereliedheavilyonoff-the-shelfsentimentdictionariesthatfocus\non negative and positive tone. These dictionaries are often tailored to nonpolitical domains and use\nbag-of-words approaches which come with a series of disadvantages. This paper creates, validates, and\ncomparestheperformanceof(1)anovelemotionaldictionaryspecificallyforpoliticaltext,(2)locallytrained\nword embedding models combined with simple neural network classifiers, and (3) transformer-based\nmodelswhichovercomelimitationsofthedictionaryapproach.Alltoolscanmeasureemotionalappeals\nassociatedwitheightdiscreteemotions.Thedifferentapproachesarevalidatedondifferentsetsofcrowd-\ncoded sentences. Encouragingly, the results highlight the strengths of novel transformer-based models,\nwhich come with easily available pretrained language models. Furthermore, all customized approaches\noutperform widely used off-the-shelf dictionaries in measuring emotional language in German political\ndiscourse.\nKeywords: text-as-data,emotions,politicaltext,dictionary,wordembeddings,transformermodels\n1. Introduction\nOver the last decades, emotions and affect have increasingly moved onto the center stage\nin political science. Even though citizens have been traditionally regarded as rational actors\n(Downs1957)anddemocratictheoryperceivedemotionsashindrancestofindingoptimalsolu-\ntions(Berelson1952),recentresearchemphasizestheinevitabilityofemotionsinpoliticalthinking\nandbehavior.Emotionalresponsesinfluencenotonlyhowcitizensformbeliefsandattitudes,but\nalsowhethertheyparticipateinpoliticsandwhotheyvotefor(Brader 2006;Healy,Malhotra,and\nMo2010;Marcus,Neuman,andMacKuen 2000;Valentino etal. 2011;Vasilopoulos etal. 2018).\nWith the rise of the Internet, the availability of political text significantly changed and the\nanalysisoflargetextdatasetsisbecomingthenewnormal(GrimmerandStewart 2013;Soroka,\nYoung,andBalmas 2015).Onemethodwidelyusedbyresearcherstomeasureemotionallanguage\nin text is sentiment analysis (measuring positive and/or negativevalence). However, language\ncanalsoengenderdifferenttypesofemotions(PennebakerandFrancis 1996;Roseman,Abelson,\nandEwing 1986).Furthermore,researchhasshownthatthesedifferentemotionsdifferstarklyin\ntheirbehavioraleffects(e.g.,DruckmanandMcDermott 2008;LernerandKeltner 2000;Valentino\netal. 2011;Vasilopoulos etal. 2018).Thisemphasizestheneedofmovingbeyondmerevalence\ntowardanalyzinglanguageassociatedwithspecificemotions.Yet,theavailabilityofemotional\ndictionariesishighlylimited.\nFurthermore, until recently, sentiment analysis in social sciences almost exclusively relied\nonabag-of-wordsordictionaryapproach.Eventhoughthisapproachhasanumberofdistinct\nadvantages (fast, cheap, and easy to replicate), it also comes with a series of disadvantages.\nPoliticalAnalysis(2023)\nvol.31:626–641\nDOI:10.1017/pan.2022.15\nPublished\n29June2022\nCorrespondingauthor\nTobiasWidmann\nEditedby\nJeffGill\n©TheAuthor(s),2022.Published\nbyCambridgeUniversityPress\nonbehalfoftheSocietyfor\nPoliticalMethodology.Thisisan\nOpenAccessarticle,distributed\nunderthetermsoftheCreative\nCommonsAttributionlicence\n(https://creativecommons.org\n/licenses/by/4.0/),whichpermits\nunrestrictedre-use,distribution,\nandreproductioninany\nmedium,providedtheoriginal\nworkisproperlycited.\n626\nhttps://doi.org/10.1017/pan.2022.15\n Published online by Cambridge University Press\nFirst,dictionariesareoftentailoredtoaspecificdomain(e.g.,e-commerce)andlanguagecontext\n(predominantlyEnglish).Thus,applyingoff-the-shelfdictionariestootherdomainscanleadto\npoor results (González-Bailón and Paltoglou2015). Second, bag-of-words approaches analyze\nwordswithoutcontextualinformation.Yet,excludingcontextleadstoalossofinformationthat\notherwisecouldimproveaccuracy(GrimmerandStewart 2013).Novelmodelsrelyingonword(or\nsentence)embeddingscanovercomethislimitationbylearningthemeaningoftermsthrough\nco-occurring words. Recent studies applying these approaches show promising (Rheault and\nCochrane2019;Rudkowsky etal. 2018),yetthepotentialofthisapproachinthefieldofdiscrete\nemotionsneedsfurtherinvestigation.\nThe goal of this study is therefore twofold. First, we set out to create and validate a novel\nemotionaldictionary(“ed8”)thatmovesbeyondvalencetomeasurelanguageassociatedwith\neightdifferentdiscreteemotions.Furthermore,thisdictionaryisspecificallytailoredtopolitical\nlanguage in a non-English-language context (German). In a second step, we move beyond the\nbag-of-words approach and create new tools to measure emotional appeals in political com-\nmunication:locallytrainedwordembeddingscombinedwithasimpleneuralnetworkclassifier\nandatransformer-basedmodel(ELECTRA,“EfficientlyLearninganEncoderthatClassifiesToken\nReplacements Accurately”). To do so, we use approximately 10,000 crowd-coded sentences in\nGermantoprovidetrainingandtestdataforthemachinelearningclassifiers.Wesubsequently\ncomparetheperformanceofthethreenewtools(ed8dictionary,wordembedding-basedneural\nnetworkclassifiers,andtransformer-basedmodel)createdinthisstudytofreelyavailableoff-the-\nshelfdictionaries.Toincreasethevalidityofourtools,wefurtherconductaseriesofrobustness\ntestsincludinganadditionaldatasetofcrowd-codedsentencesandacasestudyforhypotheses\ntesting.\n1\nIndoingso,thispaperentailsaseriesofimportantcontributions:First,itprovidesthreenew\ntoolstomeasurediscreteemotionalappealsinpoliticalcommunication.Furthermore,rigorous\nvalidationtestsshowthatnoveltransformer-basedmodelsaresuperiortoallotherapproaches\ninmeasuringdiscreteemotionalappeals.Thisfindingisreassuringasitshowsthatpretrained\ntransformer-based models, which can be easily applied to other languages and domains, out-\nperformcostlierandmoretime-consumingtoolsintheanalysisofpoliticaltext.Lastly,allthree\ncustomized tools of this study significantly improve the measurement of emotional language\ncompared to widely used off-the-shelf dictionaries. This last finding emphasizes the need for\ncautionwhenrelyingonresultscomputedbyready-to-usedictionaries.\n2. PreviousWorkonAffectiveLanguageinPoliticalText\nAutomated sentiment analysis of textual data is one way to study the emotive language of\npolitical communication. Recent studies suggest that political parties use emotive rhetoric in\nastrategicmanner,dependingontheirpolicypositions(Kosmidis et al.2019),thestateofthe\neconomy(Crabtree etal. 2020),orthetemporaldirectionofpoliticalstatements(Müller 2020).\nTo measure the emotional content of political messages, these studies rely predominantly on\nsentimentdictionariesthatmeasurepositiveandnegativevalenceoftextusingpredefinedlistsof\nvocabulary.Amongthemostwidelyuseddictionariesis,forinstance,theLinguisticInquiryWord\nCount(LIWC)dictionaryfromthefieldofpsychology(Pennebaker,Francis,andBooth 2001).Yet,\nthereexistsanabundanceofotherdictionariesfromdifferentfields(BradleyandLang 1999;Hu\nandLiu 2004;Nielsen 2011;Stone etal. 1962;YoungandSoroka 2012).Eventhoughtheydifferin\nthedisciplinetheywerecreatedfor,theselexicahavetwothingsincommon:First,theymainly\nmeasurepositiveversusnegativevalence.Second,theyuseabag-of-wordsapproachtomeasure\nsentiment,ignoringcontextualinformationofwords.\n1 ReplicationcodeforthisarticleisavailableinWidmannandWich( 2021)at https://doi.org/10.7910/DVN/C9SAIX.\nTobiasWidmannandMaximilianWich /barAltPoliticalAnalysis 627\nhttps://doi.org/10.1017/pan.2022.15\n Published online by Cambridge University Press\n2.1. MovingBeyondValence\nResearchinpoliticalpsychologyrevealedthatdifferentemotions,evenofthesamevalence,can\ninfluenceimportantpoliticalprocessesdifferently(Brader 2006;DruckmanandMcDermott 2008;\nLernerandKeltner 2000;Valentino etal. 2011;Vasilopoulos etal. 2018).Moreover,researchhas\nprovidedproofthatdiscreteemotionscanbetransmittedthroughtext.Encounteringemotion-\nallychargedwordsoremotion-specificappraisalpatternsintextcantriggerdiscreteemotional\nresponseswhichthen,inturn,cancarryemotion-dependentconsequencesforinformationpro-\ncessing,politicalattitudes,andpoliticalbehavior(see,e.g.,KühneandSchemer 2015;Nabi 2003).\nThus,basedonthisresearch,thisstudycontendsthatitisnotenoughtosimplyanalyzewhether\npartiesorpoliticiansusenegativeorpositivetone.Instead,weargueitisnecessarytoanalyzetext\nfordiscreteemotionalrhetoricsinceitcanleadtodistinctpoliticalconsequences.\nYet,despitetheirimportance,onlyasmallnumberofstudieslookatdiscreteemotions(e.g.,\nBack,Küfner,andEgloff 2011;Soroka etal. 2015;Tumasjan etal. 2010).Existingstudiesoftenfall\nbackonavailableoff-the-shelfdictionaries,forexample,theLIWCdictionary.TheLIWCincludes\ncategoriesforanger,anxiety,andsadness.TheNRCdictionary(MohammadandTurney 2013),\nanother available off-the-shelf dictionary, includes categories for eight different emotions and\nfeelings. Yet, none of these lexicons are tailored to the analysis of political speeches. Political\nlanguage, however, uses specific vocabulary with specific interpretations (Rheaultet al.2016).\nWhilepriorresearchshowsthatthesedictionariescanconstituteusefultoolstoanalyzedifferent\naspectsofpoliticallanguage(Jordan etal. 2019;Proksch etal. 2019),morethoroughinvestigation\nis necessary to see whether this is also true in the field of discrete emotions. Furthermore,\nmanydictionariesarecreatedprimarilyfortheEnglish-languagecontext,eventhoughsomeof\nthemprovidetranslatedversions.Forinstance,theNRCdictionaryisavailableinmorethan100\nlanguages,relyingonGoogleTranslateforautomatictranslation.TheLIWCdictionary,ontheother\nhand,wasmanuallyadaptedtootherlanguagesbypayingcloseattentiontolanguage-specific\ncharacteristicsandvocabulary(fortheGermanversion,seeMeier etal. 2018).\nNevertheless,theapplicationofdictionariestootherlanguagecontextsanddomainsrepre-\nsents a concern that has been brought up numerous times by social scientists while stressing\ntheneedforcustomizedtools(González-BailónandPaltoglou 2015;GrimmerandStewart 2013;\nHaselmayer and Jenny2017; Rheaultet al.2016; Sorokaet al.2015; Young and Soroka2012).\nThus,thisstudywillcreateanoveldictionary(“ed8”)thatistailoredtopoliticalcommunication\ninGerman.Usingcrowd-codedsentencesasabenchmark,wewillcompareitsperformancewith\ntwowidelyusedoff-the-shelfdictionariesthatareavailableforGermanlanguageandmeasure\nspecificemotions:theLIWCdictionaryandtheNRCdictionary.\n2.2. MovingBeyondaBag-of-Words\nPriorresearchmeasuringaffectivelanguageinpoliticalcommunicationreliedpredominantlyon\nthebag-of-wordsapproach.Yet,bag-of-wordsrepresentationoftextperceiveswordsasindepen-\ndentoftheircontextandignoresthewordorderoftext.Recentdevelopmentsinnaturallanguage\nprocessing,suchaswordembeddings(Mikolov etal.2013),generatednewwaystoavoidthisform\nofinformationreduction.\nWord embedding models learn the meaning of words by taking the context of words into\nconsideration, and thus they consider the semantic relations between words. To do so, they\ntransform words into numerical vectors that can be represented in a multidimensional space.\nWithinthisspace,wordsthatcarrysimilarmeaningarepositionedclosertoeachother,andwords\nwithdissimilarmeaningarepositionedfurtherapart.Asaresult,distancesbetweenwordvectors\nbecomeinformativeaboutthemeaningofwords.\nRecently,anincreasingnumberofstudiesusesuchwordembeddingsforvariousapplications,\nsuchasmeasuringsentiment(Rudkowsky etal. 2018),trackingthechangingmeaningofpolitical\nTobiasWidmannandMaximilianWich /barAltPoliticalAnalysis 628\nhttps://doi.org/10.1017/pan.2022.15\n Published online by Cambridge University Press\nFigure1. Overviewoverthethreedifferentapproaches.\nconceptsovertime(Kozlowski,Taddy,andEvans 2019),ormeasuringpartisanship(Rheaultand\nCochrane2019).Basedonthis,theapplicationofwordembeddingsappearspromising,butneeds\ntobeinvestigatedandcomparedmorecarefully,especiallyinthefieldofdiscreteemotions.\nAdownsideofwordembeddingsis,however,thatawordalwayshasthesamerepresentation\n(embedding)independentlyfromthesentencethatitappearsin.Letustakethefollowingtwo\nsentencesasexamples:(1)Isitonthebankoftheriverand(2)Iborrowmoneyfromthebank.Itis\nobviousthat“bank”hastwodifferentmeaningshere.However,thewordembeddingof“bank”is\nthesame.Toaddressthisissueandintegratetheactualcontextofaword,languagerepresentation\nmodelsbasedondeepneuralnetworkarchitecturesweredeveloped.Trainedonlargeamountsof\ntextdata,theyproviderepresentationsofsentencesortextsandnotonlyofaword.Aprominent\nrepresentativeofthesemodelsisbidirectionalencoderrepresentationsfromtransformers(BERT),\nwhichsetnewstandardswhenreleased(Devlin etal. 2019).\nSincethen,transformer-basedmodelsareanelementarypartoftheresearchinnaturallan-\nguage processing, and they provide state-of-the-art performance in several natural language\nunderstandingbenchmarks,suchasparaphraseidentificationandsentimentanalysis(e.g.,He\net al.2020).Inthisstudy,weuseboththewordembeddingandthetransformer-basedmodel\napproach. First, the word embedding approach serves us to extend the ed8 dictionary with\nnewvocabulary.Second,weusethewordembeddingsandcombinethemwithasimpleneural\nnetwork to train a classification model on crowd-coded training sentences. Third, we train a\ntransformer-basedclassificationmodel—amorecomplexneuralnetwork—toidentifyemotional\nappeals in political communication. Subsequently, we compare all three approaches. Figure1\nillustratesthedifferentapproachesinthisstudy.\n3. ThreeWaystoMeasureDiscreteEmotionalLanguage\n3.1. ed8:CreatingaNovelEmotionalDictionary\nInordertocomparethebag-of-wordstootherapproaches,wefirstneedtocreateanewdictionary\ntailored to German political communication (“ed8”). The novel ed8 dictionary is capable of\nmeasuringlanguageassociatedwitheightdifferentemotions:anger,fear,disgust,sadness,joy,\nenthusiasm,pride,andhope.Additionalinformationontheimportanceoftheseemotionscanbe\nfoundinOnlineAppendixA.\nTheed8dictionaryisbasedonthe“augmenteddictionary”(Rauh 2018),aGermansentiment\ndictionary that reliably discriminates between positive and negative tone in German political\nlanguage. Yet, it cannot differentiate between discrete emotions. Thus, we first extended the\nTobiasWidmannandMaximilianWich /barAltPoliticalAnalysis 629\nhttps://doi.org/10.1017/pan.2022.15\n Published online by Cambridge University Press\naugmenteddictionarywithemotionalcategoriesthatattributewordstotheeightdifferentemo-\ntionsmentionedabove.Alltermshavebeenmanuallyreviewedand—ifsuitable—attributedto\noneormoreofthedifferentemotionalcategories.Duringthisstep,alltermsthatcarryaclear\nvalence(positiveornegative)butarenotassociatedwithoneoftheeightemotionshavebeen\ndismissed. Important to note is that not all terms are necessarily emotional terms (such as\nemotionally charged adjectives), but rather words that hint toward the presence of a specific\nemotional appeal that might be appraised by humans as such. This makes the ed8 dictionary\ncomparablylongerthanotherdictionaries(fortheGermanLIWC,seeMeier etal. 2018).However,\nwechosethisapproachsincepreviousresearchindicatedthatdiscreteemotionscannotonlybe\nmeasuredbycountingemotionaladjectives.Relyingpredominantlyonadjectiveshasbeenfound\ntobesuccessfulinotherclassificationtasks,yettheclassificationofdiscreteemotionsrequires\nmoresituationalinformation(Wang etal. 2012).\nFromthetotalof30,070wordformsincludedintheaugmenteddictionary,19,091termshave\nbeenmanuallyassignedtooneormoreemotionalcategoriesinthefirststep.Inanextstep,an\nadditional1,491emotionalterms(includinginflections)havebeenaddedusingwordembeddings.\nWordembeddingsrepresentaconvenientwayoffindingsynonymsastheunderlyingalgorithm\npositionswordswithsimilarmeaningclosetooneanotherinamultidimensionalspace.Thus,\nwefirstlyidentifiedstrongemotionalwordsfromeachcategoryandthenusedtheembeddings\nto display their 50 “nearest” words, based on their numerical word vectors. From this list of\nsynonyms,wemanuallyselectedwordsthatweresuitableandnotyetpartofthedictionaryand\naddedthese(andtheirreflections)totherespectivecategory(examplesofthesewordscanbe\nfoundinOnlineAppendixA).\nThus,thenewed8dictionaryconsistsofatotalof20,582terms.OnlineAppendixApresents\ninformation about the length of the individual emotional categories, example terms for each\nemotion,andmoredetailsonnegationcontrol.Furthermore,itshowstheresultsofanintercoder\nreliabilitytestusingatrainedcodertoreplicatetheattributionoftermstoemotionalcategories\nonasmallersample.\nPreprocessing steps include the complete removal of numbers and punctuation as well as\nsettingtheremainingtermstolowercase.Ourdictionarydoesnotincludewordlemmasbecause\nwe want to build a dictionary that can be used without much effort and independently from\ncomputationalresources.IntegratingmorecomplexNaturalLanguageProcessing(NLP)strategies\n(e.g.,lemmatizing,morecomplexnegationrules)requiresmorecomplexpreprocessingandinfer-\nencingsteps,goingbeyondsearchingandcountingoccurrencesofwordsandrequiringtechnical\nskills(LiebeckandConrad 2015;Wartena 2019).\nTocalculatethefinalemotionalscores,thewordlistsareappliedtothetextcorpustofind\nandcountemotionalwords.Tocreatecomparablescoresindependentofthelengthofagiven\ndocument,normalizedemotionalscoresarecreated,thatis,dividingtheemotionalscoresbythe\nwordcountofeachdocument.Wefollowedthestrategyoftheaugmenteddictionary(Rauh 2018)\nandexcludedstopwordsfromthecalculationofthenormalizedemotionalscores,renderingthe\nscoresmoreevenlydistributed.However,tomakesurethattheremovalofstopwordsdoesnot\nbiasourresults,wereplicatedpartsoftheanalysiswithemotionalscorescalculatedincludingall\nterms(seeOnlineAppendixL).\n3.2. CreatingWordEmbeddingsandNeuralNetworkClassifiers\n3.2.1. CollectingandAnnotatingDataset. Tocreatewordembeddingsandtrainclassificationmodels,\nitisnecessarytoobtainlargetextcorpora.Forthispurpose,wecollectednearly2millionGerman-\nlanguagedocumentsfrompoliticalcommunicationofthreevariouscountries(Germany,Austria,\nandSwitzerland)anddifferenttextsources(Facebook,Twitter,pressreleases,andparliamentary\nspeeches).Thedocumentshavebeencollectedmanually,exceptBundestagspeechesincluded\nTobiasWidmannandMaximilianWich /barAltPoliticalAnalysis 630\nhttps://doi.org/10.1017/pan.2022.15\n Published online by Cambridge University Press\nin ParlSpeechV2 (Rauh and Schwalbach2020). These types of political communications have\nbeenchosenduetotheirrelevanceforlargepartsofthecitizenry:Pressreleases(Schaffner 2006)\nandparliamentaryspeeches(ProkschandSlapin 2012)areregularlypickedupbynewsmedia\nand reach thereby larger audiences. Furthermore, Facebook and Twitter represent two of the\nmost important social media networks for political discussions. Facebook is by far the largest\nsocialnetworkintheGermanmarket(Statista 2020).Moreover,Facebookisthemainsocialmedia\nplatformforpoliticalpartiesinGermany,especiallyforradicalparties(ArzheimerandBerning\n2019).Twitterissignificantlysmallerbutoftenusedbypoliticalelitestocommunicateandsetthe\nagenda(Barberáetal. 2019).Theembeddingsarethereforetrainedonalargeanddiversedataset\nofpoliticalsentenceswhichshouldmakethemmore“robust”andlesscorpus-specific.\nThis“transformation”datasetisalreadysuitedforcreatingwordembeddingmodelsaftersome\npreprocessingstepsofthedocuments(e.g.,lowercasingandremovingpunctuation).Incontrast,\nmachinelearningclassificationmodels—aformofsupervisedlearning—requirescodeddata.That\nmeans that human coders have to annotate the data according to the classification task. The\nmodelslearnfromtheannotateddatapatternstodifferentiatebetweenthedifferentclasses(e.g.,\nangerandjoy).\nOurannotateddataconsistof10,000crowd-codedsentences.The10,000sentencesstemfrom\ntwoimportantsourcesofpoliticalcommunication:GermanparliamentaryspeechesandGerman\npoliticalparties’officialFacebookaccounts(seeOnlineAppendixBforadetaileddescriptionofthe\ndatausedinthecrowd-codingprocess).ThesentenceswerecodedbyannotatorsfromaGerman\ncrowd-workingplatformcalled“Crowdguru,”whichissimilartoAmazon’sMechanicalTurk.The\n10,000sentenceswerethencompiledintomicrotasks(humanintelligencetasks[HITs])consisting\nof10sentenceseach.EveryHITwascodedbyfivedifferentcoders,whichhasbeenshowntoresult\ninenoughjudgmentspersentencetoachievereasonableprecision(Benoit et al.2016).Online\nAppendixBprovidesthecodebookandadditionalinformationonqualitycontrolmechanisms,\nthecrowd-codingplatform,andadiscussiononethicalconcernsofcrowd-sourcing.\nThetotalamountofsentencesusedinthestudyis9,898sentences,afterremovingallsentences\nthathavebeencodedasincomprehensiblebytwoormorecoders.Subsequently,thesesentences\nweresplitintwoportions:90%serveastrainingdataand10%astestdata.\n3.2.2. CreatingWordEmbeddings. Tocreatelocallytrainedwordembeddings,weusethe“transfor-\nmationdata”describedaboveinordertotransformwordsintotheirembeddings.Thisdataset\nneedstobesufficiently largein ordertoproduce useful results(Spirling andRodriguez 2022).\nConsequently, researchers can resort to pretrained embeddings trained on vast amounts of\ntextdata.Theseready-to-usecorpora(e.g.,Al-Rfou’,Perozzi,andSkiena 2013;Bojanowski etal.\n2017;Mikolov etal. 2017)donotinvolveanyadditionalcomputingtimeandoftenachievehigh\naccuracy.Ontheotherhand,researcherscanalsotrainmodelslocallybyusingcontext-specific\n(e.g.,political)datatocreatethewordembeddings.However,thisapproachcanbeexpensive\nandtime-consumingandthereforenotalwaysfeasible.SpirlingandRodriguez( 2022)compared\nbothapproachesandshowedthattheyachievedcomparableresults.Wedecidedtotrainword\nembeddingslocallybecauseintuitivelythetransformationdatashouldbeassimilartothecorpus\nofinterestaspossible.However,wealsoreplicatedtheanalysiswithpretrainedwordembeddings.\nOnlineAppendixEpresentstheseadditionaltests.Thefindingsindicatethatadvancedpretrained\nwordrepresentationscanachievecomparableresultsaslocallytrainedembeddings.\nTolocallytrainthewordembeddings,weusedtheRpackage rword2vec,whichimplements\nGoogle’s word2vec algorithm (Mikolovet al.2013). The word2vec algorithm has been widely\nused in NLP tasks to improve performance of previous approaches (Mikolovet al.2017). The\npackagerword2vecembedseachwordin100dimensions.Thismeansthatworddistancesare\ncomputedina100-dimensionalvectorspace.Furthermore,weoptedforaskip-grammodelthat\nTobiasWidmannandMaximilianWich /barAltPoliticalAnalysis 631\nhttps://doi.org/10.1017/pan.2022.15\n Published online by Cambridge University Press\npredictscontextwordsgivenaspecifictargetword.Intermsofpreprocessing,wetransformedthe\ntransformationdatatolowercaseandremovedlinks,hashtags,numbers,andpunctuation.\nAfterthewordembeddingmodelshavebeentrained,weusedthemintwodifferentways:to\nexpandtheexistinged8dictionary(describedabove)andasawaytotrainsimpleneuralnetwork\nclassifiers.\n3.2.3. TrainingSimpleNeuralNetworkClassifier. Tobuildourfirstmachinelearningmodel,wefollowed\ntheprocedureofRudkowsky etal. (2018).Beforetrainingouractualmodel,weappliedarange\nofpreprocessingstepstoconvertthetestdocumentsintovectorsthatcanbeprocessedbythe\nalgorithm.Wefirstlymatchedourwordembeddingswithfeaturesinthetrainingdataset.Inorder\ntoachievehighaccuracy,wepreprocessedthetrainingdatacorpustomatchasmanytermsfrom\nthe training data with the word embeddings. Fewer matching word embeddings per sentence\ndecreasestheaccuracyoftheemotionalprediction.Thus,weonlyremovedasmallnumberof\nwordsduringthepreprocessingprocess(onlyGermanstopwords),transformedwordstolower\ncases,andusedstemming.Afterward,wematchedeachtrainingsentencewiththeirrespective\nwordembeddings.Wethenaveragedallretrievedwordembeddingspersentencebycalculating\nthemeanvectorforeachdimension,providinguswithsentenceembeddings.\nAfterallsentenceshavebeentransformedintotheircorrespondingembeddings,amachine\nlearningclassifierisappliedtolearnemotionalappealsbasedonthemeanvectorsandthehuman\nannotation of the training sentences. To do so, we firstly tested a series of different classifiers\n(Random Forest, Lasso, Naïve Bayes, and Neural Network) which are widely used in statistical\nlearning(James etal. 2013).TheresultsofthesetestscanbefoundinOnlineAppendixF.Finally,\nwe opted for a neural network using thekeras library for R, which achieved the best results.\nHyperparametersettingsofourneuralnetworkmodelscanbefoundinOnlineAppendixC.After\ntheneuralnetworkmodelshavebeentrained,weapplytheclassifierstothe10%testdataandlet\nthemevaluatewhetherasentencecontainsemotionalappealsornot.\n3.3. TrainingTransformer-BasedClassifier\nAfter building classification models with simple neural network architecture, we trained a\ntransformer-based classification model, which is currently state-of-the-art in natural language\nprocessing.Thetransformed-basedmodelsarehighlycomplexandverylargeneuralnetworks.\nThey are pretrained on corpora that contain billions of words, similar to word embeddings.\nHowever,incontrasttowordembeddings,theycontaincomplexlanguagemodelsthatproduce\ncontextualized embeddings for entire documents (e.g., one or several sentences). These\npretrainedmodelscanthenbeusedtotrainaclassificationmodelbasedonindividualdata.\nWedecidedtouseELECTRA,anextendedBERTversion,insteadoftheclassicalBERTmodel\n(Clarketal.2020).Therearetworeasonsforthisdecision.First,ELECTRAoutperformscomparable\nBERT models on several benchmarks (Clarket al.2020). Second, the German ELECTRA model\nthatisprovidedbytheGermanNLPGroupandthatweuseforourstudyoutperformsequivalent\nBERTmodelsinsimilartextclassificationtasksinGerman.\n2 Anotherdifferencetotheprevious\narchitectureisthatwetrainonlyonemodelforallemotionsandnotonemodelforeachemotion.\nThatmakesthemodeleasiertouseforotherresearchers.\nThemodelhas12layers,ahiddenstatesizeof768andintotal110millionparameters.Weused\nthesametrain/testsplitofthedataasforthesimpleneuralnetworkarchitecture.Wewithheld\n10%ofthetrainingsetasthevalidationset.Incontrasttothepreviousmodel,wedidnotapplyany\nprocessingstepstothesentencesbecausethisisdonebythetokenizerofthetransformer-based\nmodel.Wetrainedthemodelforfourepochswithalearningrateof5e-5andchosethebestmodel\n2 Themodelisprovidedhere: https://huggingface.co/german-nlp-group/electra-base-german-uncased.\nTobiasWidmannandMaximilianWich /barAltPoliticalAnalysis 632\nhttps://doi.org/10.1017/pan.2022.15\n Published online by Cambridge University Press\noftheseepochsasthefinalmodel.Toidentifythebestmodel,wedefinedourownlossfunction.\nTheproblemofthemultilabelclassificationmodelisthattheperformancesonthedifferentlabels\ncanbeveryunbalancedifonelabeliseasiertobepredictedthanothers.Tocompensateforthis,\nwedefinedthelossasfollows:\nLoss=\n/summationdisplay.1\ni ∈Emotions\n(1−F 1i )•2.\nThedoubleweightingcausesthatlabelsthatarehardertopredictarenotneglected.Forthe\ntransformer-basedmodel,weusedthePythonlibrary“Transformers”providedbyHuggingFace\n(Wolfetal. 2020).Furtherdetailsonthetrainingprocessandthehyperparameterscanbefound\ninOnlineAppendixC.\nTo measure the performance of all three approaches, we calculate precision, recall, and F1\nscores.Thesearetypicalmeasurementsinmachinelearning-basedclassificationtasks.Recallis\ntheratioofcorrectlypredictedobservationstothetotalamountoftrueobservations(indicates\nthenumberoffalsenegatives).Precision,ontheotherhand,istheratioofcorrectlypredicted\nobservationstothetotalpredictedobservations(indicatesthenumberoffalsepositives).TheF1\nscoreisdefinedastheharmonicmeanofrecallandprecision:\nF 1=2 ×(Recall×Precision)/(Recall+Precision).\n4. Results\nInthefirststep,wecomparetheresultsofthethreedifferentapproacheswhileusingthehuman-\ncodedtestsentencesas“true”data.Foraninitialcomparison,weforcedthecontinuousemotional\nscores computed by the dictionary to a binary variable, which reflects the output of the two\nmachinelearningapproachesandthecodingdecisionthehumancodersfacedduringthecrowd-\ncodingprocess.Asentencehasbeenperceivedas“emotional,”assoonasonehumancodercoded\nitassuch.\nTable1showstheresultsforthethreedifferentapproaches.The“actual”columnshowshow\nmanysentenceshavebeenjudgedas“emotional”byhumancoders(thecombinednumbersof\nthiscolumncanbegreaterthantheactualsizeofthetestsetsinceonesentencecanincludemulti-\npleemotions).The“predict”columnrepresentsthenumberofsentencesclassifiedas“emotional”\nbythedifferenttools.\nAscanbeseen,therearesubstantivedifferencesbetweendifferentemotionsandbetweenthe\nthreedifferentapproaches.FocusingonF1scores,itbecomesobviousthatthetransformer-based\n(ELECTRA)modeloutperformsthedictionaryapproachandthesimplewordembeddingapproach\nbyfar.Forallemotionsunderscrutiny,theELECTRAmodelshowshigherF1scorescomparedto\ntheotherapproaches.Thedifferencesaresubstantivelylargewiththetransformer-basedmodel\nachievinginaverage18-pointhigherF1scoresthantheed8dictionary.Eventhoughthedifferences\naresomewhatsmaller,thetransformer-basedapproachstilloutperformsthelocallytrainedword\nembeddingsapproachwithF1scoresbeinginaverageninepointshigher.“ReceivingOperating\nCharacteristic” (ROC) curves and confusion matrices for these classifications are reported in\nOnlineAppendixG.\nTheresultsalsoindicatethatthelocallytrainedwordembeddingapproachoutperformsthe\ndictionary approach, even though the differences are not as large as for the ELECTRA model.\nFurthermore,inOnlineAppendixE,wereplicatethisanalysisusingpretrainedwordembeddings.\nAscanbeseen,theadvancedwordrepresentations(Bojanowski etal. 2017;Mikolov etal. 2017)\nachieveacomparableperformanceasthelocallytrainedembeddings.Thisfindingshowshow\neasily available pretrained embeddings can achieve better results than tediously created, cus-\ntomizeddictionaries.\nTobiasWidmannandMaximilianWich /barAltPoliticalAnalysis 633\nhttps://doi.org/10.1017/pan.2022.15\n Published online by Cambridge University Press\nTable1. Precision,recall,andF1scoresforthethreedifferentapproaches.\nEmotions Actual Predicted Precision Recall F1\ned8dictionary\nAnger 508 281 0 .83 0 .46 0 .59\nFear 189 287 0 .43 0 .66 0 .52\nDisgust 86 182 0 .30 0 .63 0 .40\nSadness 201 289 0 .41 0 .59 0 .48\nJoy 143 179 0 .46 0 .58 0 .52\nEnthusiasm 220 248 0 .44 0 .50 0 .47\nPride 158 247 0 .31 0 .48 0 .38\nHope 305 303 0 .53 0 .53 0 .53\nWord-embeddings-basedneuralnetworkapproach\nAnger 508 500 0 .80 0 .78 0 .79\nFear 189 152 0 .61 0 .49 0 .55\nDisgust 86 67 0 .60 0 .47 0 .52\nSadness 201 122 0 .70 0 .42 0 .53\nJoy 143 92 0 .68 0 .44 0 .54\nEnthusiasm 220 176 0 .64 0 .51 0 .57\nPride 158 123 0 .52 0 .41 0 .46\nHope 305 265 0 .69 0 .60 0 .64\nTransformer-based(ELECTRA)approach\nAnger 508 495 0 .85 0 .83 0 .84\nFear 189 221 0 .60 0 .70 0 .64\nDisgust 86 89 0 .61 0 .63 0 .62\nSadness 201 181 0 .64 0 .57 0 .60\nJoy 143 122 0 .70 0 .59 0 .64\nEnthusiasm 220 242 0 .62 0 .68 0 .65\nPride 158 151 0 .61 0 .58 0 .60\nHope 305 352 0 .68 0 .78 0 .73\nLookingatdifferencesbetweenemotions,onecanobservethatsomeemotionsshowclearly\nhigherF1scorescomparedtoothers.Angerandhope,forinstance,showthehighestF1scores\namong all emotions for each of the three approaches. These differences can be potentially\nexplainedbythehigherlevelofoccurrencesoftheseemotionsinthetrainingandtestdata.Online\nAppendixDshowsthatangerandhopealsoexhibitthehighestoccurrencesinthetrainingand\ntestdata,asjudgedbyhumancoders.Figure 2graphicallydisplaystherelationshipbetweenthe\nnumberofoccurrencesofdifferentemotionsandtheF1scoreoftheELECTRAmodel.\nWetestthisrelationshipfurtherbycomparingtheperformanceofthedifferentapproachesfor\nsentencesfromdifferenttextsources(Facebookpostsvs.legislativespeeches).Wedosobecause\nthereisreasontoexpectdifferencesinemotionalitybetweendifferenttexttypes.Theresultsof\nthecomparisonbetweensourcesarereportedinOnlineAppendixH.SupplementaryTableH.1\nshows that all three tools exhibit higher performance for Facebook sentences, in comparison\nto legislative speeches (with the exception of anger for the ELECTRA model). Looking at the\nemotionaloccurrencesinthetestdatabytextsource(“actual”columnsinSupplementaryTable\nH.2),itbecomesclearthattheoccurrencesarealsohigherforFacebooksentences(again,with\ntheexceptionofangerwherethenumbersarerelativelyequal).Thus,thisfindingemphasizesthe\nneedforhigh-qualitytrainingandtestdataforemotionclassification,whichhasbeenstressedby\npreviousliterature(Wang etal. 2012).\nTobiasWidmannandMaximilianWich /barAltPoliticalAnalysis 634\nhttps://doi.org/10.1017/pan.2022.15\n Published online by Cambridge University Press\nFigure2. RelationshipbetweenlevelofemotionaloccurrencesandF1scoreoftheELECTRAmodel.\nOverall,themainanalysisindicatesthatthetransformer-basedELECTRAmodelachievesbyfar\nthebestresultsinmeasuringdiscreteemotionalappeals.Thesefindingsspeakfortheleveraging\nof novel deep learning techniques to further improve the accuracy of currently widely used\nmethodsintextanalysis.\n4.1. Off-the-ShelfDictionaries\nInanextstep,wecomparetheresultsofthenewlycreatedtoolstofreelyavailabledictionaries.\nAsmentionedabove,theLIWCandtheNRCEmoLexareoff-the-shelfdictionariesoftenappliedin\npoliticalscienceresearch.Theyincludenotonlygeneralcategoriesforpositiveandnegativetone,\nbutalsocategoriesfordiscreteemotions.\nWeappliedbothoff-the-shelfdictionariestothe10%testdatathatwealsousedtovalidate\nthe three new tools (including sentences from both Facebook and legislative speeches). The\nprecision,recall,andF1scoresfortheLIWCandtheNRCdictionariesareshowninTable 2.Ascan\nbeseen,bothdictionaries,LIWCandNRC,showsubstantivelylowerF1scorescomparedtothe\nnovelapproachescreatedinthisstudy.ThehighestF1scorefortheLIWCdictionaryis0.40,forthe\nNRCdictionary0.25.TheautomaticallytranslatedGermanversionoftheNRCEmoLexdictionary\nshowsthelowestscores,withanF1scoreof0.09fordisgust.InOnlineAppendixI,wepresent\ntheconfusionmatricesofthisclassification.Furthermore,wereplicatethesameexercisewith\nthecomplete9,898sentences,becauseasplitbetweentrainingandtestdataisnotnecessary\nfordictionaries.Theresultsremainverysimilar.\nLastly,weconductanadditionalexercise,inwhichwemakeuseofthecontinuousscaleof\nthe ed8 dictionary in order to see whether higher emotional dictionary scores correlate with\nstrongeragreementonemotionsbyhumancoders.TheresultsarereportedinOnlineAppendix\nI.Thegraphsillustratehowtheed8dictionarycansignificantlydiscriminatebetweendifferent\ncategoriesofhumanagreement/disagreement.\n4.2. RobustnessTests\nTo test the robustness of the novel tools created in this study, we run a series of robust-\nness tests. First, we replicated the main analysis with a new set of approximately 10,000\nTobiasWidmannandMaximilianWich /barAltPoliticalAnalysis 635\nhttps://doi.org/10.1017/pan.2022.15\n Published online by Cambridge University Press\nTable2. Precision,recall,andF1scoresfortheLinguisticInquiryWordCount(LIWC)andNRCdictionaries.\nEmotions Actual Predicted Precision Recall F1\nLIWCdictionary\nAnger 508 178 0 .77 0 .27 0 .40\nFear 189 84 0 .40 0 .18 0 .25\nSadness 201 93 0 .48 0 .22 0 .31\nNRCdictionary\nAnger 508 73 0 .81 0 .12 0 .20\nFear 189 97 0 .37 0 .19 0 .25\nDisgust 86 48 0 .13 0 .07 0 .09\nSadness 201 116 0 .32 0 .18 0 .23\nJoy 143 64 0 .31 0 .14 0 .19\ncrowd-codedsentences. This second set of crowd-coded sentences has not been presampled.\nInstead, it consistsof randomly selected sentencesfrom German political Facebook posts and\nlegislativespeeches.Thereasonforthisexerciseisthatpresamplingusingtheed8dictionary(asin\nthecaseofthemainanalysis)canintroduceastrongbiasforthisspecifictoolwhiledisadvantaging\ntheoff-the-shelfdictionaries.Theresultsofthisexerciseandadditionalinformationcanbefound\nin Online Appendix J. The tables indicate that the novel ed8 dictionary is still outperforming\nfreely available off-the-shelf dictionaries. Yet, it becomes obvious that the performance for all\ndictionariessubstantivelydecreased,whichindicatesthattheresultsofthemainanalysiswere\ninfluencedbythepresamplingstrategy.Ontheotherhand,thesuperiorityofthetransformer-\nbasedmodelcomparedtotheremainingapproachesbecomesevenmorestriking.Theseresults\nareimportantastheyillustratetheperformanceofthedifferenttoolsina“real-lifesetting,”that\nresearchersapplyingthesetoolstonewdatawouldencounter.\nAsasecondrobustnesstest,wemanipulatethenumberofcoderspercrowd-codedsentence.\nBasedonthestudybyBenoitandco-authors(Benoit et al.2016),webasedourmainanalysis\nonfivecrowdjudgementspersentenceinthefirst10,000sentences.Now,wewanttofindout\nwhetherfivejudgementspersentenceisenoughtoestablishreliableandvalidestimates.Forthe\nsecond10,000crowd-codedsentences,wethereforetookonehalf(5,000sentences)asideand\nletthesesentencesbecodedby10crowdcoderseach.Thenwedrawonrandomsubsamples\nfrom these 5,000 sentences to estimate F1 scores as a function of crowd coders per sentence.\nWedosobybootstrapping1,000setsofsubsampleswithreplacementforeach nrangingfrom\nofn=1to n=10coderspersentence.ThenwecalculatemeanF1scoresforeach nandforeach\napproach(ed8,wordembeddings,andELECTRA).OnlineAppendixKpresentstheresultsofthis\nexerciseindetail.While,formostemotions,increasingthenumberofcrowdjudgmentswillstill\nslightlyimprovetheF1scores,weconcludethatfivecrowdjudgementspersentencerepresentsa\nsufficientnumber,especiallywhenjudgedfromacost–benefitperspective.\nFinally, as a last exercise, we provide an application example which shows how the tools\nprovidedinthisstudycanbeusedforhypothesistesting.Inthecasestudy,weanalyzemorethan\n12,000pressreleasesofsixGermanpoliticalparties.Theresultsofthisexercisearereportedin\nOnlineAppendixM.\n5. Conclusion\nThisarticlepresentstoolstomeasurediscreteemotionalappealsinpoliticaltext.Increasedinter-\nestintheaffectivesideofpoliticshasledscholarsinpoliticalscienceandinpoliticalcommunica-\ntiontoinvestigatehowdifferentpoliticalactorsuseemotionalrhetoricintheircommunication.\nYet, a majority of freely available tools measuring emotive language are tailored toward the\nTobiasWidmannandMaximilianWich /barAltPoliticalAnalysis 636\nhttps://doi.org/10.1017/pan.2022.15\n Published online by Cambridge University Press\nEnglish-languagecontext,focuspredominantlyonpositiveversusnegativesentiment,andrely\nonthebag-of-wordsapproach.\nThe approaches presented and validated in this paper move beyond valence to measure\ndiscrete emotional appeals. In total, we created and compared three different tools: a novel\nemotionaldictionary(ed8),simpleneuralnetworkclassifiersbasedonwordembeddings,anda\ntransformer-basedmodel.Alltoolscanmeasureemotionalappealsassociatedwitheightdiscrete\nemotions.Furthermore,thepresentedtoolsaretailoredtotheGermanlanguage.Thus,thisstudy\nadds to the availability of validated tools for measuring discrete emotions in the non-English\npoliticalcontext.\nAnothercontributionofthisstudyisthatitshowshownewtransformer-basedclassification\nmodelscanbeusedtoanalyzepoliticaltextsregardingtheirdiscreteemotionalappeals.Itthere-\nforeaddstoastrandofliteraturethatinvestigatesthepossibilitiesofapplyingnovelembedding\nmodelsinpoliticaltextanalysis(Kozlowski etal. 2019;RheaultandCochrane 2019;Rudkowsky\net al.2018). Yet, this study introduces new state-of-the-art NLP models which, to the best of\nourknowledge,havehadlittleapplicationtodateintheanalysisofpoliticaltext.Thefindings\nindicate promising results: The validation tests show that the novel transformer-based model\nclearlyoutperformsallotherapproaches(includingdictionariesandstandardwordembedding\napproaches)foreachemotionunderscrutiny.Itfurtherachievesverygoodresultscomparedto\nrelated,recenttextanalysisstudiesinpoliticalscience(usingembeddingstomeasuresentiment;\nRudkowskyetal. 2018)orotherfields(emotionanalysis;Demszky etal. 2020;Xu etal. 2020).Even\nthough the ed8dictionary mightcomewitha numberofadvantages,asitis easierandfaster\ntoimplementandrequireslesscomputingpower,italsoshowssignificantlylowerperformance.\nResearchersshouldthereforechoosetheirtooldependingontheirresearchgoal:Whilethebag-\nof-wordsapproachcanprovideaquickoverviewofemotionallanguagewhich,however,requires\nextensivechecking,theELECTRAmodelachieveshigheraccuracyatthepriceofmoreresource-\nintensiveapplication.\nFurthermore,theresultsindicatethatthenoveltoolscreatedinthisstudyachievesignificantly\nhigherperformanceintheclassificationofdiscreteemotionalappealscomparedtofreelyavail-\nableoff-the-shelfdictionaries.Thisfindingstressestheneedforcautionwhenrelyingonready-\nto-use dictionaries. While these dictionaries have been found to perform adequately for some\nclassification tasks (for analytical thinking, see Jordanet al.2019; and for sentiment analysis,\nsee Prokschet al.2019), the findings of this study point toward poor results in the field of\ndiscreteemotions.Thearticlethereforereiteratespreviouscallsforcustomizedtextanalysistools\n(González-BailónandPaltoglou 2015;GrimmerandStewart 2013;HaselmayerandJenny 2017;\nRheaultetal. 2016;Soroka etal. 2015;YoungandSoroka 2012).\nInthisrespect,thisstudypresentsencouragingresults.Whilecreatingnewtask-specificdic-\ntionaries is laborious, the other two approaches can be easily applied to other domains and\ntasks.First,inregardtothe“standard”wordembeddingapproach,additionaltestsinthisarticle\nshow that advanced pretrained word embeddings (e.g., Bojanowskiet al.2017;M i k o l o vet al.\n2017) achieve results comparable to the locally trained word embeddings. Thus, when relying\non the word embedding approach, scholars do not need to invest time and money to collect\nlarge text corpora and compute models, but can instead employ cheap and readily available\nembeddings.Second,thetransformer-basedapproach,whichsurpassedallothertools,comes\nwith a pretrained language model that can be easily fine-tuned for a classification task. It is\nthereforeeasilyapplicabletootherdomains.\nInaddition,word-embedding-basedandtransformer-basedmodelsareavailableinamulti-\ntudeoflanguages(forSpanish,seeCanete etal.2020;forEnglish,seeClark etal.2020;forSwedish,\nseeMalmsten,Börjeson,andHaffenden 2020;andforFrench,seeMartin etal. 2019).Eventhough\nthisarticledealswiththeclassificationofdiscreteemotionallanguageinGerman,itcanserve\nTobiasWidmannandMaximilianWich /barAltPoliticalAnalysis 637\nhttps://doi.org/10.1017/pan.2022.15\n Published online by Cambridge University Press\nasaframeworktocreatesimilartoolsforotherlanguageswhichpotentiallyachieveevenbetter\nperformances.Domain-specificcompoundnouns,conjugatedverbs,anddeclinedwords—which\narecommonintheGermanlanguagebutnotinotherlanguages(e.g.,English)—mightdecrease\ntheperformanceoftheembeddingapproachesinthisstudy.\nHowever,wewouldliketopointoutthatallautomatedtoolspresentedinthisstudyshouldbe\nusedwithsubstantialcaution.Asthefindingsshow,therearesubstantivedifferencesintheability\noftheautomatedapproachestodetectspecificemotions.While,forsomeemotions,thetools\nachieveconsistentlygoodresults,thedetectionofothersischallenging.Relatedly,theresultsdo\nnotonlyvarybetweenemotions,butalsobetweentexttypes.Eventhoughweexpectvariationin\nthelevelofemotionalappealsbetweendifferentcommunicationchannels,itcouldalsobethat\nemotionsareexpresseddifferentlyindifferentsettings.Yet,machinelearningclassifierstrained\nononespecifictexttypemightnotnecessarilybeabletocapturethesedifferences.Thissuggests\nthat researchers might arrive at different results and draw different conclusions when relying\non data from different communication channels. This cautionary note does not only apply to\nemotiondetection.Researchersusingautomatedtextanalysistoolsinordertoinvestigateany\nfine-grainedconceptneedextensivevalidationstepsastheperformanceofautomatedmethods\nonnewdatasetscannotbeguaranteed(GrimmerandStewart 2013).Thesevalidationstepscould\nentailthereplicationoffindingsusingaseriesoftextanalysistools(Schoonvelde,Schumacher,\nandBakker 2019)oramorequalitativeanalysisoftheresults,bylookingatsmallersamplesof\ntextdata.Applyingthetoolsblindlytodifferenttextsfordifferentpurposescanleadtobiasedor\nsimplywrongresults.Thisbecomesevenmoreurgent,ofcourse,oncetoolsarebeingtransferred\ntodifferentdomains.\nThemainlimitationofthisstudy,whichscholarswhowanttoconductsimilaranalysesshould\nbewaryof,concernsthesizeofthetrainingandtestdata.Inordertomakeuseofthefullpotential\nofthedifferentmachinelearningapproaches,researchersneedtoobtainlargesetsoftestand\ntrainingdata.Thisstudyreliesonarelativelysmallsampleofemotion-relevanttrainingandtest\nsentences,atleastforsomeemotions.Futureresearchcouldthereforeexplorethepossibilityof\nautomaticallycreatedtrainingdatatoovercomethecostsofhumanannotation(Wang etal.2012).\nAnotherlimitationofourapproachisthatourtrainingandtestdatawereannotatedonsentence\nlevel,andourclassificationmodelsworkonthesamelevel.Bydoingso,wemighthavemissed\nemotionalappealscausedbythecontextofthecompletetext(e.g.,theentirespeech).Future\nresearchcouldaddressthisbymovingfromsentenceleveltoparagraphlevelordocumentlevel.\nThelastlimitationaddressesinternalandexternalvalidity.Eventhoughwehaveevaluatedour\nmodels on additional 10,000 sentences that were not part of the original training and test set\n(seeOnlineAppendixK),externalvalidityremainslimitedfortworeasons.First,theadditional\ndatacomefromthesamesourcesandcanthereforepotentiallyentailthesamebiases.Second,\nclassification performance (precision, recall, and F1 score) is on average lower on the 10,000\nadditionalsentences.Adeviationbetweentheclassificationperformanceontheoriginaltestset\nandanewdataset(theadditional10,000sentences)indicatesthatthemodelperformsworseina\nreal-lifescenario,meaningthegeneralizabilityissomewhatlimited.Nevertheless,ourresultson\nthenewdatasetarepromisingandconfirmourapproach.\nTheselimitationsnotwithstanding,thisarticleprovidesnewtoolsfortheresearchcommunity\ntoanalyzeemotionalrhetoricinpoliticaltext.Itfurtherillustrateshowpoliticalscientistscanuse\nnewdeeplearningmethodstoimprovetheaccuracyofpoliticaltextanalysis.\nAcknowledgments\nThe authors would like to thank Hanspeter Kriesi and Vicente Valentim for their continuous\nsupportthroughoutthecreationofthisstudy.Furthermore,theauthorswouldliketothankTimo\nSeidl, Johannes Rothe, Kenneth Benoit, participants of the Young Scholars in Computational\nTobiasWidmannandMaximilianWich /barAltPoliticalAnalysis 638\nhttps://doi.org/10.1017/pan.2022.15\n Published online by Cambridge University Press\nSocialScienceWorkshopattheUniversityofZurich2020,theeditorialteamofPoliticalAnalysis\nandthefouranonymousreviewersfortheirhelpanddetailedcommentsonearlierversionsofthe\nmanuscript.\nFundingStatement\nThis work was supported by the Early Stage Researcher Grant from the European University\nInstitute,VillaSanfelice,50014SanDomenicodiFiesole,Italy.\nConflictsofInterest\nThereisnoconflictofinteresttodisclose.\nDataAvailabilityStatement\nReplicationcodeforthisarticleisavailableinWidmannandWich( 2021)athttps://doi.org/10.7910/\nDVN/C9SAIX.\nSupplementaryMaterials\nToviewsupplementarymaterialforthisarticle,pleasevisit http://doi.org/10.1017/pan.2022.15.\nReferences\nAl-Rfou’,R.,B.Perozzi,andS.Skiena.2013.“Polyglot:DistributedWordRepresentationsforMultilingual\nNLP.”InProceedingsoftheSeventeenthConferenceonComputationalNaturalLanguageLearning ,\n183–192.https://arxiv.org/abs/1307.1662\nArzheimer,K.,andC.C.Berning.2019.“HowtheAlternativeforGermany(AfD)andTheirVotersVeeredtothe\nRadicalRight,2013–2017.” ElectoralStudies 60:102040. https://doi.org/10.1016/j.electstud.2019.04.004\nBack,M.D.,A.C.P.Küfner,andB.Egloff.2011.“‘AutomaticorthePeople?’:AngeronSeptember11,2001,and\nLessonsLearnedfortheAnalysisofLargeDigitalDataSets.” PsychologicalScience 22(6):837–838.\nhttps://doi.org/10.1177/0956797611409592\nBarberá,P.,etal.2019.“WhoLeads?WhoFollows?MeasuringIssueAttentionandAgendaSettingby\nLegislatorsandtheMassPublicusingSocialMediaData.” AmericanPoliticalScienceReview 113(4):\n883–901.https://doi.org/10.1017/S0003055419000352\nBenoit,K.,D.Conway,B.E.Lauderdale,M.Laver,andS.Mikhaylov.2016.“Crowd-SourcedTextAnalysis:\nReproducibleandAgileProductionofPoliticalData.” AmericanPoliticalScienceReview 110(2):278–295.\nhttps://doi.org/10.1017/S0003055416000058\nBerelson,B.1952.“DemocraticTheoryandPublicOpinion.” ThePublicOpinionQuarterly 16(3):313–330.\nBojanowski,P.,E.Grave,A.Joulin,andT.Mikolov.2017.“EnrichingWordVectorswithSubwordInformation.”\nTransactionsoftheAssociationforComputationalLinguistics5(June):135–46.\nhttps://doi.org/10.1162/tacl_a_00051.\nBrader,T.2006. CampaigningforHeartsandMinds:HowEmotionalAppealsinPoliticalAdsWork .Chicago:\nUniversityofChicagoPress.\nBradley,M.M.,andP.J.Lang.1999.“AffectiveNormsforEnglishWords(ANEW):InstructionManualand\nAffectiveRatings.”TechnicalreportC-1,TheCenterforResearchinPsychophysiology.\nCanete,J.,G.Chaperon,R.Fuentes,andJ.Pérez.2020.“SpanishPre-TrainedBertModelandEvaluation\nData.”InPML4DCatICLR2020 .https://users.dcc.uchile.cl/~jperez/papers/pml4dc2020.pdf\nClark,K.,M.-T.Luong,Q.V.Le,andC.D.Manning.2020.“ELECTRA:Pre-TrainingTextEncodersas\nDiscriminatorsRatherthanGenerators.”Preprint,arXiv:2003.10555[Cs].\nCrabtree,C.,M.Golder,T.Gschwend,andI.H.Indriđason.2020.“ItIsNotOnlyWhatYouSay,ItIsAlsoHow\nYouSayIt:TheStrategicUseofCampaignSentiment.” TheJournalofPolitics 82(3):1044–1060.\nhttps://doi.org/10.1086/707613\nDemszky,D.,D.Movshovitz-Attias,J.Ko,A.Cowen,G.Nemade,andS.Ravi.2020.“GoEmotions:ADatasetof\nFine-GrainedEmotions.”Preprint,arXiv:2005.00547[Cs].\nDevlin,J.,M.-W.Chang,K.Lee,andK.Toutanova.2019.“BERT:Pre-TrainingofDeepBidirectional\nTransformersforLanguageUnderstanding.”Preprint,arXiv:1810.04805[Cs].\nDowns,A.1957. AnEconomicTheoryofDemocracy .NewYork:Harper.\nDruckman,J.N.,andR.McDermott.2008.“EmotionandtheFramingofRiskyChoice.” PoliticalBehavior 30\n(3):297–321.\nGonzález-Bailón,S.,andG.Paltoglou.2015.“SignalsofPublicOpinioninOnlineCommunication:A\nComparisonofMethodsandDataSources.” TheANNALSoftheAmericanAcademyofPoliticalandSocial\nScience659(1):95–107. https://doi.org/10.1177/0002716215569192\nTobiasWidmannandMaximilianWich /barAltPoliticalAnalysis 639\nhttps://doi.org/10.1017/pan.2022.15\n Published online by Cambridge University Press\nGrimmer,J.,andB.M.Stewart.2013.“TextasData:ThePromiseandPitfallsofAutomaticContentAnalysis\nMethodsforPoliticalTexts.” PoliticalAnalysis 21(3):267–297.\nHaselmayer,M.,andM.Jenny.2017.“SentimentAnalysisofPoliticalCommunication:Combininga\nDictionaryApproachwithCrowdcoding.” Quality&Quantity 51(6):2623–2646.\nhttps://doi.org/10.1007/s11135-016-0412-4\nHe,P.,X.Liu,J.Gao,andW.Chen.2020.“Deberta:Decoding-EnhancedBertwithDisentangledAttention.”\nPreprint,arXiv:2006.03654.\nHealy,A.J.,N.Malhotra,andC.H.Mo.2010.“IrrelevantEventsAffectVoters’EvaluationsofGovernment\nPerformance.”ProceedingsoftheNationalAcademyofSciences 107(29):12804–12809.\nhttps://doi.org/10.1073/pnas.1007420107\nHu,M.,andB.Liu.2004.“MiningandSummarizingCustomerReviews.”In ProceedingsoftheTenthACM\nSIGKDDInternationalConferenceonKnowledgeDiscoveryandDataMining ,168–177.\nhttps://dl.acm.org/doi/abs/10.1145/1014052.1014073\nJames,G.,D.Witten,T.Hastie,andR.Tibshirani.2013. AnIntroductiontoStatisticalLearning ,SpringerTexts\ninStatistics,103.NewYork:Springer. https://doi.org/10.1007/978-1-4614-7138-7\nJordan,K.N.,J.Sterling,J.W.Pennebaker,andR.L.Boyd.2019.“ExaminingLong-TermTrendsinPolitics\nandCultureThroughLanguageofPoliticalLeadersandCulturalInstitutions.” ProceedingsoftheNational\nAcademyofSciences 116(9):3476–3481. https://doi.org/10.1073/pnas.1811987116\nKosmidis,S.,S.B.Hobolt,E.Molloy,andS.Whitefield.2019.“PartyCompetitionandEmotiveRhetoric.”\nComparativePoliticalStudies 52(6):811–837. https://doi.org/10.1177/0010414018797942\nKozlowski,A.C.,M.Taddy,andJ.A.Evans.2019.“TheGeometryofCulture:AnalyzingMeaningthroughWord\nEmbeddings.”AmericanSociologicalReview 84(5):905–949. https://doi.org/10.1177/0003122419877135\nKühne,R.,andC.Schemer.2015.“TheEmotionalEffectsofNewsFramesonInformationProcessingand\nOpinionFormation.”CommunicationResearch 42(3):387–407.\nLerner,J.S.,andD.Keltner.2000.“BeyondValence:TowardaModelofEmotion-SpecificInfluenceson\nJudgementandChoice.” Cognition&Emotion 14(4):473–493.\nLiebeck,M.,andS.Conrad.2015.“IWNLP:InverseWiktionaryforNaturalLanguageProcessing.”In\nProceedingsofthe53rdAnnualMeetingoftheAssociationforComputationalLinguisticsandthe7th\nInternationalJointConferenceonNaturalLanguageProcessing(Volume2:ShortPapers) ,editedbyC.Zong\nandM.Strube,414–418.Beijing:AssociationforComputationalLinguistic.\nhttps://doi.org/10.3115/v1/P15-2068\nMalmsten,M.,L.Börjeson,andC.Haffenden.2020.“PlayingwithWordsattheNationalLibraryof\nSweden–MakingaSwedishBERT.”Preprint,arXiv:2007.01658.\nMarcus,G.E.,W.R.Neuman,andM.MacKuen.2000. AffectiveIntelligenceandPoliticalJudgment .Chicago:\nUniversityofChicagoPress.\nMartin,L.,B.Muller,P.J.O.Suárez,Y.Dupont,L.Romary,É.V.delaClergerie,D.Seddah,andB.Sagot.2019.\n“Camembert:ATastyFrenchLanguageModel.”Preprint,arXiv:1911.03894.\nMeier,T.,R.L.Boyd,J.W.Pennebaker,M.R.Mehl,M.Martin,M.Wolf,andA.B.Horn.2018.“‘ LIWCauf\nDeutsch’:TheDevelopment,Psychometrics,andIntroductionofDE- LIWC2015.”Preprint,PsyarXiv.\nhttps://doi.org/10.31234/osf.io/uq8zt\nMikolov,T.,K.Chen,G.Corrado,andJ.Dean.2013.“EfficientEstimationofWordRepresentationsinVector\nSpace.”Preprint,arXiv:1301.3781[Cs].\nMikolov,T.,E.Grave,P.Bojanowski,C.Puhrsch,andA.Joulin.2017.“AdvancesinPre-TrainingDistributed\nWordRepresentations.”Preprint,arXiv:1712.09405[Cs].\nMohammad,S.M.,andP.D.Turney.2013.“CrowdsourcingaWord–EmotionAssociationLexicon.”\nComputationalIntelligence29(3):436–65. https://doi.org/10.1111/j.1467-8640.2012.00460.x.\nMüller,S.2020.“TheTemporalFocusofCampaignCommunication.” JournalofPolitics 84:585–590.\nNabi,R.L.2003.“ExploringtheFramingEffectsofEmotion:DoDiscreteEmotionsDifferentiallyInfluence\nInformationAccessibility,InformationSeeking,andPolicyPreference?” CommunicationResearch 30(2):\n224–247.\nNielsen,F.Å.2011.“ANewANEW:EvaluationofaWordListforSentimentAnalysisinMicroblogs.”Preprint,\narXiv:1103.2903[Cs].\nPennebaker,J.W.,andM.E.Francis.1996.“Cognitive,Emotional,andLanguageProcessesinDisclosure.”\nCognitionandEmotion 10(6):601–626. https://doi.org/10.1080/026999396380079\nPennebaker,J.W.,M.E.Francis,andR.J.Booth.2001.“LinguisticInquiryandWordCount:LIWC2001.”\nMahway:LawrenceErlbaumAssociates 71(2001):2001.\nProksch,S.-O.,W.Lowe,J.Wäckerle,andS.Soroka.2019.“MultilingualSentimentAnalysis:ANewApproach\ntoMeasuringConflictinLegislativeSpeeches.” LegislativeStudiesQuarterly 44(1):97–131.\nhttps://doi.org/10.1111/lsq.12218\nProksch,S.-O.,andJ.B.Slapin.2012.“InstitutionalFoundationsofLegislativeSpeech.”\nAmericanJournalof\nPoliticalScience 56(3):520–537. https://doi.org/10.1111/j.1540-5907.2011.00565.x\nRauh,C.2018.“ValidatingaSentimentDictionaryforGermanPoliticalLanguage—AWorkbenchNote.”\nJournalofInformationTechnology&Politics 15(4):319–343.\nhttps://doi.org/10.1080/19331681.2018.1485608\nTobiasWidmannandMaximilianWich /barAltPoliticalAnalysis 640\nhttps://doi.org/10.1017/pan.2022.15\n Published online by Cambridge University Press\nRauh,C.,andJ.Schwalbach.2020.“TheParlSpeechV2DataSet:Full-TextCorporaof6.3Million\nParliamentarySpeechesintheKeyLegislativeChambersofNineRepresentativeDemocracies[DataSet].”\nHarvardDataverse. https://doi.org/10.7910/DVN/L4OAKN\nRheault,L.,K.Beelen,C.Cochrane,andG.Hirst.2016.“MeasuringEmotioninParliamentaryDebateswith\nAutomatedTextualAnalysis.” PLoSOne 11(12):e0168843. https://doi.org/10.1371/journal.pone.0168843\nRheault,L.,andC.Cochrane.2019.“WordEmbeddingsfortheAnalysisofIdeologicalPlacementin\nParliamentaryCorpora.”PoliticalAnalysis 28:112–133. https://doi.org/10.1017/pan.2019.26\nRoseman,I.,R.P.Abelson,andM.F.Ewing.1986.“EmotionandPoliticalCognition:EmotionalAppealsin\nPoliticalCommunication.”In PoliticalCognition,editedbyR.R.LauandD.O.Sears,279–294.Hillsdale,\nNJ:LawrenceErlbaumAssociates.\nRudkowsky,E.,M.Haselmayer,M.Wastian,andM.Jenny.2018.“MorethanBagsofWords:Sentiment\nAnalysiswithWordEmbeddings.” CommunicationMethodsandMeasures 12:140–157.\nSchaffner,B.F.2006.“LocalNewsCoverageandtheIncumbencyAdvantageintheUSHouse.” Legislative\nStudiesQuarterly 31(4):491–511.\nSchoonvelde,M.,G.Schumacher,andB.N.Bakker.2019.“FriendswithTextasDataBenefits:Assessingand\nExtendingtheUseofAutomatedTextAnalysisinPoliticalScienceandPoliticalPsychology.” Journalof\nSocialandPoliticalPsychology 7(1):124–143. https://doi.org/10.5964/jspp.v7i1.964\nSoroka,S.,L.Young,andM.Balmas.2015.“BadNewsorMadNews?SentimentScoringofNegativity,Fear,\nandAngerinNewsContent.” TheANNALSoftheAmericanAcademyofPoliticalandSocialScience 659(1):\n108–121.https://doi.org/10.1177/0002716215569217\nSpirling,A.,andP.L.Rodriguez.2022.“WordEmbeddings:WhatWorks,WhatDoesn’t,andHowtoTellthe\nDifferenceforAppliedResearch.” TheJournalofPolitics 84:53.\nStatista.2020.SocialMedia—MarktanteilederPortaleinDeutschland2020.Statista. https://de.statista.\ncom/statistik/daten/studie/559470/umfrage/marktanteile-von-social-media-seiten-in-deutschland/.\nStone,P.J.,R.F.Bales,J.Z.Namenwirth,andD.M.Ogilvie.1962.“TheGeneralInquirer:AComputerSystem\nforContentAnalysisandRetrievalBasedontheSentenceasaUnitofInformation.” BehavioralScience\n7(4):484–498. https://doi.org/10.1002/bs.3830070412\nTumasjan,A.,T.O.Sprenger,P.G.Sandner,andI.M.Welpe.2010.“PredictingElectionswithTwitter:What\n140.”CharactersRevealaboutPoliticalSentiment ,8.\nValentino,N.A.,T.Brader,E.W.Groenendyk,K.Gregorowicz,andV.L.Hutchings.2011.“ElectionNight’s\nAlrightforFighting:TheRoleofEmotionsinPoliticalParticipation.” TheJournalofPolitics 73(1):156–170.\nVasilopoulos,P.,G.E.Marcus,N.A.Valentino,andM.Foucault.2018.“Fear,Anger,andVotingfortheFar\nRight:EvidenceFromtheNovember13,2015ParisTerrorAttacks.” PoliticalPsychology 40(4):679–704.\nhttps://doi.org/10.1111/pops.12513\nWang,W.,L.Chen,K.Thirunarayan,andA.P.Sheth.2012.“HarnessingTwitter‘BigData’forAutomatic\nEmotionIdentification.”In 2012InternationalConferenceonPrivacy,Security,RiskandTrustand2012\nInternationalConferenceonSocialComputing ,587–592.IEEE.\nhttps://doi.org/10.1109/SocialCom-PASSAT.2012.119\nWartena,C.2019.“AProbabilisticMorphologyModelforGermanLemmatization.”In Proceedingsofthe15th\nConferenceonNaturalLanguageProcessing(KONVENS2019) ,40–49.\nhttps://serwiss.bib.hs-hannover.de/frontdoor/index/index/docId/1527\nWidmann,T.,andM.Wich.2021.“ReplicationDatafor:CreatingandComparingDictionary,Word\nEmbedding,andTransformer-BasedModelstoMeasureDiscreteEmotionsinGermanPoliticalText[Data\nSet].”HarvardDataverse. https://doi.org/10.7910/DVN/C9SAIX\nWolf,T.,etal.2020.“Transformers:State-of-the-ArtNaturalLanguageProcessing.”In Proceedingsofthe\n2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing:SystemDemonstrations ,38–45.\nAssociationforComputationalLinguistics. https://aclanthology.org/2020.emnlp-demos.6\nXu,P.,Z.Liu,G.I.Winata,Z.Lin,&P.Fung.2020.“EmoGraph:CapturingEmotionCorrelationsusingGraph\nNetworks.”Preprint,arXiv:2008.09378[Cs].\nYoung,L.,andS.Soroka.2012.“AffectiveNews:TheAutomatedCodingofSentimentinPoliticalTexts.”\nPoliticalCommunication 29(2):205–231. https://doi.org/10.1080/10584609.2012.671234\nTobiasWidmannandMaximilianWich /barAltPoliticalAnalysis 641\nhttps://doi.org/10.1017/pan.2022.15\n Published online by Cambridge University Press",
  "topic": "German",
  "concepts": [
    {
      "name": "German",
      "score": 0.8413946628570557
    },
    {
      "name": "Transformer",
      "score": 0.6456997990608215
    },
    {
      "name": "Measure (data warehouse)",
      "score": 0.6392967700958252
    },
    {
      "name": "Computer science",
      "score": 0.5986078381538391
    },
    {
      "name": "Natural language processing",
      "score": 0.5414478778839111
    },
    {
      "name": "Word (group theory)",
      "score": 0.5267184376716614
    },
    {
      "name": "Politics",
      "score": 0.5259085893630981
    },
    {
      "name": "Word embedding",
      "score": 0.4997403621673584
    },
    {
      "name": "Embedding",
      "score": 0.49420931935310364
    },
    {
      "name": "Linguistics",
      "score": 0.4536227583885193
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4335190951824188
    },
    {
      "name": "Speech recognition",
      "score": 0.420118123292923
    },
    {
      "name": "Political science",
      "score": 0.13894441723823547
    },
    {
      "name": "Data mining",
      "score": 0.1001797616481781
    },
    {
      "name": "Philosophy",
      "score": 0.09931236505508423
    },
    {
      "name": "Law",
      "score": 0.05823040008544922
    },
    {
      "name": "Physics",
      "score": 0.05296546220779419
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I204337017",
      "name": "Aarhus University",
      "country": "DK"
    },
    {
      "id": "https://openalex.org/I62916508",
      "name": "Technical University of Munich",
      "country": "DE"
    }
  ]
}