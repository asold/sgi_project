{
  "title": "Applying Large Language Models to Power Systems: Potential Security Threats",
  "url": "https://openalex.org/W4392543779",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2772038327",
      "name": "Jiaqi Ruan",
      "affiliations": [
        "Hong Kong Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A2318092400",
      "name": "Gaoqi Liang",
      "affiliations": [
        "Harbin Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2102854265",
      "name": "Huan Zhao",
      "affiliations": [
        "Nanyang Technological University"
      ]
    },
    {
      "id": "https://openalex.org/A2124436185",
      "name": "Guolong Liu",
      "affiliations": [
        "Chinese University of Hong Kong, Shenzhen"
      ]
    },
    {
      "id": "https://openalex.org/A3118574745",
      "name": "Xianzhuo Sun",
      "affiliations": [
        "Hong Kong Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A2051089761",
      "name": "Jing Qiu",
      "affiliations": [
        "University of Sydney"
      ]
    },
    {
      "id": "https://openalex.org/A2100931749",
      "name": "Zhao Xu",
      "affiliations": [
        "Hong Kong Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A2068103183",
      "name": "Fushuan Wen",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2145909561",
      "name": "Zhao Yang Dong",
      "affiliations": [
        "Nanyang Technological University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3108423167",
    "https://openalex.org/W4385190659",
    "https://openalex.org/W6787335730",
    "https://openalex.org/W3203321135",
    "https://openalex.org/W4283170666",
    "https://openalex.org/W2920646469",
    "https://openalex.org/W2319367234",
    "https://openalex.org/W4318830296",
    "https://openalex.org/W3133702157",
    "https://openalex.org/W4382723369",
    "https://openalex.org/W4386934476",
    "https://openalex.org/W3087958975"
  ],
  "abstract": "Applying large language models (LLMs) to modern power systems presents a promising avenue for enhancing decision-making and operational efficiency. However, this action may also incur potential security threats, which have not been fully recognized so far. To this end, this article analyzes potential threats incurred by applying LLMs to power systems, emphasizing the need for urgent research and development of countermeasures.",
  "full_text": "1\nApplying Large Language Models to Power\nSystems: Potential Security Threats\nJiaqi Ruan, Member, IEEE,Gaoqi Liang, Member, IEEE,Huan Zhao, Member, IEEE,\nGuolong Liu, Member, IEEE,Xianzhuo Sun, Member, IEEE,Jing Qiu, Senior Member, IEEE,Zhao Xu, Senior\nMember, IEEE,Fushuan Wen, Fellow, IEEE,and Zhao Yang Dong, Fellow, IEEE\nAbstract—Applying large language models (LLMs) to mod-\nern power systems presents a promising avenue for enhancing\ndecision-making and operational efficiency. However, this action\nmay also incur potential security threats, which have not been\nfully recognized so far. To this end, this article analyzes po-\ntential threats incurred by applying LLMs to power systems,\nemphasizing the need for urgent research and development of\ncountermeasures.\nIndex Terms—Power systems, large language models, security\nthreats.\nI. I NTRODUCTION\nI\nN the dynamically evolving landscape of the power sector,\ncharacterized by a growing reliance on renewable energy\nsources and the integration of diverse grid-connected enti-\nties, the complexity and openness of power systems have\nintensified [1]. This evolution presents substantial challenges\nfor power system operators who are tasked with intricate\nscheduling decisions within an ever-expanding operational\nscope. As such, the deployment of large language models\n(LLMs) [2]—sophisticated deep learning frameworks trained\non extensive text corpora—has emerged as a transformative\nsolution. These models excel in understanding and generating\nhuman-like linguistic expressions, equipping operators with\nThis work was supported in part by the Research Grants Council of the\nHong Kong Special Administrative Region under Grant AoE/P-601/23-N; in\npart by the General Research Fund of the Hong Kong Special Administrative\nRegion under Grant PolyU15209322; in part by PolyU under Grant 1-YWCV\nand Grant 1-W29V , and in part by Shenzhen Natural Science Fund in\nthe Stable Support Plan Program under Grant GXWD20231128112434001.\n(Corresponding authors: Gaoqi Liang; Zhao Xu.)\nJiaqi Ruan and Xianzhuo Sun are with the Department of Electrical and\nElectronic Engineering, The Hong Kong Polytechnic University, Hong Kong\nSAR, China (e-mail: jiaqi.ruan@polyu.edu.hk; xianzsun@polyu.edu.hk).\nGaoqi Liang is with the School of Mechanical Engineering and Automation,\nHarbin Institute of Technology, Shenzhen, Shenzhen 518055, China (e-mail:\nlianggaoqi@hit.edu.cn).\nGuolong Liu is with the School of Science and Engineering, The Chinese\nUniversity of Hong Kong, Shenzhen, Shenzhen 518172, China (e-mail:\nliuguolong@cuhk.edu.cn).\nJing Qiu is with the School of Electrical and Information Engineer-\ning, The University of Sydney, Sydney, NSW 2006, Australia (e-mail:\njeremy.qiu@sydney.edu.au).\nZhao Xu is with the Department of Electrical and Electronic Engineering\nand the Research Institute of Smart Energy, The Hong Kong Polytechnic\nUniversity, Hong Kong SAR, China (e-mail: eezhaoxu@polyu.edu.hk).\nFushuan Wen is with the College of Electrical Engineering, Zhejiang\nUniversity, Hangzhou 310027, China (e-mail: fushuan.wen@gmail.com).\nHuan Zhao and Zhao Yang Dong are with the School of Electrical and\nElectronic Engineering, Nanyang Technological University, Singapore 639798\n(e-mail: huan.zhao@ntu.edu.sg; zy.dong@ntu.edu.sg).\ntailored tools for managing complex scenarios more effec-\ntively.\nThe integration of LLMs signifies a significant advancement\nin addressing the complexities and decision-making challenges\nof modern power systems. With capabilities in natural lan-\nguage processing, image recognition, and time series analysis\n[3], LLMs can act as a powerful, multifaceted tool for navigat-\ning power systems in a complex data milieu. They enhance the\nextraction of critical information from vast datasets, strength-\nening the foundations of scheduling and decision-making\noptimization. Leveraging their robust analytical and logical\nreasoning capabilities, LLMs facilitate intelligent data retrieval\nand question-answering, enabling the analysis of various in-\nputs such as historical load data, weather forecasts, and real-\ntime news. This significantly contributes to the formulation of\nsophisticated optimization strategies. Moreover, LLMs enrich\nhuman-computer interactions [4] within power systems, allow-\ning for intuitive presentations of complex data and operational\nstates, thereby supporting operators in making well-informed,\nhigh-quality decisions. The application of LLMs in power\nsystems not only enhances dispatch accuracy and efficiency\nbut also highlights their role in improving system adaptability\nand stability, opening new avenues for research and promising\ncommercial prospects.\nHowever, alongside the growing interest from major power\ngroups in developing tailored LLMs for power systems, this\napplication also introduces significant security concerns [5].\nWhile LLMs offer numerous benefits, their deployment within\nincreasingly open power systems can also lead to potential\nsecurity threats, particularly in data security and decision-\nmaking stability. Currently, there is a notable gap in research\nand investigation into these issues. This article aims to address\nthis gap by providing an in-depth analysis of potential threats\nposed by LLM applications in power systems, thereby en-\nriching the understanding within both academic and industrial\ncommunities and steering the development of more secure\nLLMs for power system applications.\nII. P OTENTIAL THREATS OF LARGE LANGUAGE MODELS\nIN POWER SYSTEMS\nA. Large Language Models in Power Systems\nAs traditional power systems evolve into cyber-physical\npower systems (CPPS), the integration of advanced infor-\nmation and communication technology with physical power\nsystems enables real-time perception, rapid response, and\nThis is the Pre-Published Version.\nThe following publication J. Ruan et al., \"Applying Large Language Models to Power Systems: Potential Security Threats,\" in IEEE Transactions on \nSmart Grid, vol. 15, no. 3, pp. 3333-3336, May 2024 is available at https://doi.org/10.1109/TSG.2024.3373256.\n© 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, \nincluding reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to \nservers or lists, or reuse of any copyrighted component of this work in other works.\n2\nPhysical System\nCyber System\nLarge Language Model\nControl flowInformation flow\nDecision \nsupport\nData \nanalysis\nCyber-physical Power System\nFig. 1. Illustration of applying the large language model to the cyber-physical\npower system.\nintelligent scheduling [6]. In this context, the introduction of\nLLMs emerges as a crucial advancement towards enhancing\nthe intelligence features of CPPS and optimizing power system\noperations. As illustrated in Fig. 1, LLM can play a critical role\nin analyzing data derived from the physical system, meanwhile\naiding in decision-making processes in the cyber system.\nPrior to the application of LLMs in power systems, it is\nrequired to develop tailored LLMs that synergize advanced\nartificial intelligence training methodologies with extensive\ndomain-specific knowledge pertaining to power systems. This\nprocess initiates with the collection and preparation of a\ncomprehensive dataset, tailored to the industry’s requirements,\nfollowed by the fine-tuning of a robust base model to under-\nstand and generate language contactable to power systems.\nThis necessitates not only technical expertise in machine\nlearning and natural language processing but also a deep\nunderstanding of the power system’s unique challenges and\nnuances. Subsequent to the training phase, the focus shifts\nto rigorous testing and validation to ensure the model’s ac-\ncuracy and practicality in real-world scenarios. With their\ndeep understanding and generation of human language, LLMs\nprovide unique advantages in multimodal data analysis, natural\nlanguage processing, and intelligent decision support in power\nsystems.\nWithin the CPPS architecture, LLMs primarily function in\nthe cyber system’s information and application layers. In the\ninformation layer, they process and analyze substantial data\nfrom sensors, smart meters, and other devices. For instance,\nLLMs can analyze historical and real-time load data, weather\ninformation, and user behaviors to forecast electricity demand.\nIn the application layer, LLMs assist in decision-making and\noptimizing power system operations, generating scheduling\nstrategies and providing valuable insights to power system\noperators. Furthermore, through natural language processing\ntechnology, LLMs can enhance human-machine interaction,\ncontributing significantly to the overall intelligence of CPPS.\nDespite these benefits, the integration of LLMs into CPPS\nmay also face potential security threats due to modern power\nsystems’ ever-evolving openness and complexity. This is a\ndeparture from traditional optimization-based decision-making\nmodels in power systems, which are typically characterized by\ntheir interpretability, transparency, and specificity. The security\nthreats associated with LLMs include their potential misuse in\ncyberattacks, susceptibility to data tampering, and implications\nfor system stability. At the same time, the decision-making\nprocess of LLMs often lacks transparency, which could impact\nthe stability and security of the power system during critical\nmoments. Therefore, a deeper investigation into these potential\nthreats is essential for the safe operation of CPPS.\nB. Potential Threats Incurred by Applying Large Language\nModels\nThe integration of LLMs in power systems may incur\nvarious types of security threats, such as data privacy, opera-\ntional integrity, and system vulnerabilities. These threats could\nmaterialize through several mechanisms as follows.\n1) Privacy invasion through large language models:The\napplication of LLM in power systems may pose security risks\nregarding data privacy. Although the advanced data processing\nand analysis capabilities of LLM significantly improve the\noperational efficiency of the power system, they may also\npose risks for privacy breaches. This is mainly due to LLMs\nbeing designed to improve collaboration efficiency across\nvarious departments within the power system and often being\ndeployed as resources widely accessible within the system.\nSuch extensive accessibility makes LLMs potential targets for\nattackers. Once attackers gain access, they can use LLMs’\nintelligent question-answering system to obtain sensitive in-\nformation about the power system, such as operational data,\ncontrol strategies, and even security protocols. This kind of\nprivacy theft not only violates data security but also may\nenable attackers to launch more complex attacks, such as false\ndata injection attacks (FDIAs).\nSince FDIA was first proposed in 2009, it has been a hot\nresearch topic in academia [7]. However, the implementation\nof FDIA comes with a strong assumption, wherein attackers\nhave knowledge of the power system’s real-time operational\nconditions, at least partially, to devise effective strategies [8].\nTraditionally, obtaining such information has been a significant\nbarrier for attackers, making it difficult to fulfill in reality.\nHowever, with LLMs in future power systems, this barrier may\nbe significantly lowered. Attackers could use LLMs to obtain\ndetailed operational information and then use this to design\nFDIA strategies that undermine the power system’s stability.\nTherefore, while LLMs enhance power system intelligence and\nefficiency, they also introduce privacy breach risks that could\nbe exploited in sophisticated cyberattacks like FDIA. Potential\nmitigation strategies may include limiting the access of LLMs\nto sensitive operational data and employing data sanitization\ntechniques. This involves filtering and modifying the opera-\ntional data in a way that remains useful for legitimate purposes\nbut becomes ineffective for designing FDIA strategies, thereby\nreducing the security risk of data privacy breaches.\n3\n2) Deteriorated performance in large language models:\nAs ultra-large-scale neural networks, LLMs require substantial\ncomputational resources and training investment to ensure per-\nformance [9]. Once deployed in power systems, maintaining\ntheir performance becomes crucial. However, a shift in the\nLLM’s internal parameters could lead to long-term inappro-\npriate or incorrect decision-making for the power system,\nwhich breaches the operational integrity. The threat of such\noperational integrity-relevant performance degradation may\narise from two main aspects.\nFirstly, if the data set (including training, validation, and\ntest sets) is maliciously altered during the training or fine-\ntuning process, LLMs might learn inaccurate or misleading\ninformation. Such errors could lead to deviations in the final\nmodel parameters, impacting decision-making accuracy and\nreliability [10]. Secondly, there is a risk of direct tampering\nwith LLM’s internal parameters. If attackers can access and\nmodify these parameters post-deployment [11], the LLM’s\noutput could significantly deviate from expectations, reduc-\ning decision-making effectiveness and potentially leading to\nserious operational issues.\nIn both scenarios, deteriorating LLM performance may lead\nto erroneous decisions in power system operations, threaten-\ning system stability and efficiency. Therefore, securing LLM\ndata and model parameters is crucial to prevent performance\ndegradation. This necessitates strict security measures at all\ntraining, deployment, and operational stages to uphold LLM’s\nintegrity and reliability.\n3) Threats from semantic divergence: LLM deployment\ncan coordinate operations across various departments and\noperators, boosting the overall efficiency of the power sys-\ntem. However, this also means that numerous terminals can\ncommunicate with the LLM, generating human-machine in-\nteractions and creating many interfaces with a high degree\nof openness. In such an open environment, some interfaces\nmight be exposed to attackers. As LLMs can interact with\na large number of operators through intelligent question-\nanswering, attackers may exploit these exposed interfaces to\nlaunch semantic divergence attacks (SDAs), incurring security\nthreats toward systemic vulnerabilities.\nSDAs can be carried out in two ways. The first involves\naltering the LLM’s input data ( i.e., query semantics) to elicit\nirrelevant or misleading answers. For example, a query about\n”real-time load” might be manipulated to produce results for\n”historical load” instead. The second method involves directly\naltering LLM’s outputs to create divergent answer semantics.\nRegardless of the method, SDAs can lead to operators\nreceiving incorrect or misleading information, which could\nthen be used in decision-making for power system operations.\nThis misinformation could significantly affect the reliability\nand efficiency of the power system. Therefore, monitoring and\nprotecting LLM inputs and outputs is essential in preventing\nSDAs. It is necessary to implement strict data validation\nand security protocols within the power system to ensure\ninformation accuracy and consistency, preventing attackers\nfrom exploiting LLMs as a tool to attack the power system.\n4) Denial of service for large language models:Denial of\nservice (DoS) attacks [12] pose a serious threat to LLMs,\nincreasing power systems’ security threats in systemic vul-\nnerabilities. These attacks occur when LLMs receive requests\nexceeding their processing capabilities, rendering the LLM\nunusable, overloaded, or slow to respond. The DoS attacks can\nvary, with the most common form being the inundation of the\nLLM with numerous query requests, depleting computational\nresources. Beyond ordinary request flooding, attackers might\nalso design particularly complex or lengthy queries, causing\nthe LLM to consume excessive computational resources in\nprocessing a single request. The consequences of DoS attacks\nare severe as they impact the LLM’s immediate response\ncapabilities and can paralyze the entire system.\nIn power systems, this implies that critical decision-support\nand data analysis functions might be unavailable when needed.\nFor instance, in emergencies, if operators depend on LLMs for\nrapid response or decision analysis, a DoS attack could cause\ndelayed or erroneous decisions, affecting the power system’s\nstable operation and safety. Moreover, DoS attacks might be\nused as part of other attack strategies, such as a diversion or to\nmask more severe attack activities. Therefore, enhancing LLM\nsecurity, especially against DoS attacks, is crucial for the safe\noperation of power systems. This may include effective traffic\nmanagement, monitoring mechanisms, and designing LLMs\nwith the capacity to resist such attacks.\nIII. C ONCLUSION AND SUGGESTIONS\nWhile LLMs are expected to significantly enhance the op-\nerational efficiency and decision-making capabilities in future\npower systems, they also introduce new security threats, rang-\ning from data privacy breaches to susceptibility to cyber threats\nlike SDAs and DoS attacks. Addressing these security chal-\nlenges necessitates a comprehensive, multi-dimensional frame-\nwork. Fundamental to this is the development of inherently\nsecure LLM architectures, the implementation of sophisticated\nanomaly detection methodologies, and the establishment of\nrobust LLM frameworks. Compliance with evolving cyberse-\ncurity standards and data protection legislation throughout the\nlifecycle of LLMs is also imperative.\nIn mitigating these emerging security risks, the adoption\nof flexible security policies and regulations is crucial, sup-\nplemented by human-in-the-loop strategies to fortify LLMs\nagainst evolving security threats. Interdisciplinary collabora-\ntion and empirical validation through real-world testing are\nessential in underpinning these strategies. Such endeavors are\ncritical for the progressive adaptation of power systems, facili-\ntating their seamless integration with the advanced capabilities\nof LLMs while ensuring stringent security and reliability\nstandards.\nFor stakeholders in the power sector, prioritizing enhanced\ncybersecurity measures, data protection protocols, and ethical\nusage guidelines for LLMs is of utmost importance. It is\nrequired to foster a culture of security awareness and prepared-\nness, through comprehensive employee training and collabo-\nrative efforts with other industries and governmental entities.\nRegular risk assessments, meticulous monitoring, and periodic\nsystem updates are imperative to counter potential security\nthreats associated with LLMs. This holistic framework is es-\nsential for applying LLMs to future power systems, aiming to\n4\nbalance the exploitation of LLMs’ potential with the mitigation\nof associated security threats. Continual research, proactive\nimplementation, and the development of secure, transparent\nLLM systems in alignment with regulatory standards are key\nto maintaining this equilibrium.\nREFERENCES\n[1] D. Wang, F. Chen, B. Meng, X. Hu, and J. Wang, “Event-based secure\nH∞ load frequency control for delayed power systems subject to\ndeception attacks,” Applied Mathematics and Computation, vol. 394,\np. 125788, Apr. 2021.\n[2] S. Porsdam Mann, B. D. Earp, N. Møller, S. Vynn, and J. Savulescu,\n“AUTOGEN: A Personalized Large Language Model for Academic\nEnhancement—Ethics and Proof of Principle,” The American Journal\nof Bioethics, vol. 23, no. 10, pp. 28–41, Oct. 2023.\n[3] N. Carlini, F. Tram `er, E. Wallace, M. Jagielski, A. Herbert-V oss, K. Lee,\nA. Roberts, T. Brown, D. Song, ´U. Erlingsson, A. Oprea, and C. Raffel,\n“Extracting Training Data from Large Language Models,” in 30th\nUSENIX Security Symposium (USENIX Security 21), 2021, pp. 2633–\n2650.\n[4] T. Wu, M. Terry, and C. J. Cai, “AI Chains: Transparent and Controllable\nHuman-AI Interaction by Chaining Large Language Model Prompts,”\nin Proceedings of the 2022 CHI Conference on Human Factors in\nComputing Systems, ser. CHI ’22. New York, NY , USA: Association\nfor Computing Machinery, Apr. 2022, pp. 1–22.\n[5] L. Weidinger, J. Uesato, M. Rauh, C. Griffin, P.-S. Huang, J. Mellor,\nA. Glaese, M. Cheng, B. Balle, A. Kasirzadeh, C. Biles, S. Brown,\nZ. Kenton, W. Hawkins, T. Stepleton, A. Birhane, L. A. Hendricks,\nL. Rimell, W. Isaac, J. Haas, S. Legassick, G. Irving, and I. Gabriel,\n“Taxonomy of Risks posed by Language Models,” in Proceedings of the\n2022 ACM Conference on Fairness, Accountability, and Transparency,\nser. FAccT ’22. New York, NY , USA: Association for Computing\nMachinery, Jun. 2022, pp. 214–229.\n[6] H. Wang, J. Ruan, B. Zhou, C. Li, Q. Wu, M. Q. Raza, and G.-\nZ. Cao, “Dynamic Data Injection Attack Detection of Cyber Physical\nPower Systems With Uncertainties,” IEEE Transactions on Industrial\nInformatics, vol. 15, no. 10, pp. 5505–5518, Oct. 2019.\n[7] G. Liang, J. Zhao, F. Luo, S. R. Weller, and Z. Y . Dong, “A Review\nof False Data Injection Attacks Against Modern Power Systems,” IEEE\nTransactions on Smart Grid, vol. 8, no. 4, pp. 1630–1638, Jul. 2017.\n[8] J. Ruan, G. Fan, Y . Zhu, G. Liang, J. Zhao, F. Wen, and Z. Y .\nDong, “Super-Resolution Perception Assisted Spatiotemporal Graph\nDeep Learning Against False Data Injection Attacks in Smart Grid,”\nIEEE Transactions on Smart Grid, vol. 14, no. 5, pp. 4035–4046, Sep.\n2023.\n[9] E. M. Bender, T. Gebru, A. McMillan-Major, and S. Shmitchell, “On the\nDangers of Stochastic Parrots: Can Language Models Be Too Big?” in\nProceedings of the 2021 ACM Conference on Fairness, Accountability,\nand Transparency, ser. FAccT ’21. New York, NY , USA: Association\nfor Computing Machinery, Mar. 2021, pp. 610–623.\n[10] J. Ruan, G. Liang, J. Zhao, H. Zhao, J. Qiu, F. Wen, and Z. Y .\nDong, “Deep learning for cybersecurity in smart grids: Review and\nperspectives,” Energy Conversion and Economics, vol. 4, no. 4, pp. 233–\n251, 2023.\n[11] L. Yang, G. Liang, Y . Yang, J. Ruan, P. Yu, and C. Yang, “Adversarial\nfalse data injection attacks on deep learning-based short-term wind speed\nforecasting,” IET Renewable Power Generation, 2023.\n[12] A. Huseinovi ´c, S. Mrdovi ´c, K. Bicakci, and S. Uludag, “A Survey\nof Denial-of-Service Attacks and Solutions in the Smart Grid,” IEEE\nAccess, vol. 8, pp. 177 447–177 470, 2020.",
  "topic": "Risk analysis (engineering)",
  "concepts": [
    {
      "name": "Risk analysis (engineering)",
      "score": 0.6291826963424683
    },
    {
      "name": "Action (physics)",
      "score": 0.5548155903816223
    },
    {
      "name": "Electric power system",
      "score": 0.520338773727417
    },
    {
      "name": "Computer security",
      "score": 0.5132967829704285
    },
    {
      "name": "Computer science",
      "score": 0.4794858396053314
    },
    {
      "name": "Power (physics)",
      "score": 0.4405658543109894
    },
    {
      "name": "Business",
      "score": 0.2995394468307495
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I14243506",
      "name": "Hong Kong Polytechnic University",
      "country": "HK"
    },
    {
      "id": "https://openalex.org/I204983213",
      "name": "Harbin Institute of Technology",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I172675005",
      "name": "Nanyang Technological University",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I4210116924",
      "name": "Chinese University of Hong Kong, Shenzhen",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I129604602",
      "name": "The University of Sydney",
      "country": "AU"
    },
    {
      "id": "https://openalex.org/I76130692",
      "name": "Zhejiang University",
      "country": "CN"
    }
  ],
  "cited_by": 40
}