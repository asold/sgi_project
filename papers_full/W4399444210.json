{
    "title": "Knowledge Accuracy and Reducing Hallucinations in LLMs via Dynamic Domain Knowledge Injection",
    "url": "https://openalex.org/W4399444210",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A5099053000",
            "name": "Roman Capellini",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A5099053001",
            "name": "Frank Atienza",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A5099053002",
            "name": "Melanie Sconfield",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4390736801",
        "https://openalex.org/W4399199820",
        "https://openalex.org/W4396225444",
        "https://openalex.org/W4386409617",
        "https://openalex.org/W4389672268",
        "https://openalex.org/W4392366668",
        "https://openalex.org/W4385337322",
        "https://openalex.org/W4392756413",
        "https://openalex.org/W4392593764",
        "https://openalex.org/W4384561707",
        "https://openalex.org/W4396665116",
        "https://openalex.org/W4383982659",
        "https://openalex.org/W4393319504",
        "https://openalex.org/W3199761064",
        "https://openalex.org/W4396851234",
        "https://openalex.org/W4391143839",
        "https://openalex.org/W4395082149",
        "https://openalex.org/W4398196557",
        "https://openalex.org/W4394999670",
        "https://openalex.org/W4399154003",
        "https://openalex.org/W4396675319",
        "https://openalex.org/W4399009725",
        "https://openalex.org/W3035204084",
        "https://openalex.org/W4377820893",
        "https://openalex.org/W4388691793",
        "https://openalex.org/W4396762959"
    ],
    "abstract": "<title>Abstract</title> Natural language processing has seen substantial progress with the development of highly sophisticated models capable of understanding and generating human-like text. However, a persistent challenge remains in enhancing the accuracy of these models when dealing with domain-specific knowledge, particularly in avoiding hallucinations or generating plausible but incorrect information. The dynamic domain knowledge injection mechanism introduced in this research represents a significant advancement by allowing continuous integration and prioritisation of specialised information, thereby improving the model's performance and reliability. By dynamically adjusting the hidden weights of GPT-Neo based on domain relevance and accuracy, the modified model achieved higher precision, recall, and F1-scores, and exhibited reduced hallucination rates across diverse domains such as cybersecurity, medical information, financial data, and legal documents. A comprehensive evaluation framework, including benchmark creation and performance metrics, validated the effectiveness of the approach, demonstrating that dynamic domain knowledge injection can substantially enhance the utility of large language models in specialised fields. The results highlight the transformative potential of this method, offering a robust pathway for the development of more accurate and contextually aware language models. Detailed analysis and ablation studies further elucidate the contributions of each component within the modification process, providing critical insights into the optimisation and future applications of this innovative approach.",
    "full_text": null
}