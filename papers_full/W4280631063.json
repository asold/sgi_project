{
    "title": "Context-Aware Abbreviation Expansion Using Large Language Models",
    "url": "https://openalex.org/W4280631063",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2108262222",
            "name": "Shanqing Cai",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2024951123",
            "name": "Subhashini Venugopalan",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A94795586",
            "name": "Katrin Tomanek",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2179871709",
            "name": "Ajit Narayanan",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2096086574",
            "name": "Meredith Morris",
            "affiliations": [
                "Google (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A1966693102",
            "name": "Michael Brenner",
            "affiliations": [
                "Google (United States)"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2529137305",
        "https://openalex.org/W4220681721",
        "https://openalex.org/W2133990837",
        "https://openalex.org/W4287024925",
        "https://openalex.org/W2071063602",
        "https://openalex.org/W2051780479",
        "https://openalex.org/W2949461276",
        "https://openalex.org/W2801748224",
        "https://openalex.org/W4226399820",
        "https://openalex.org/W4205991051",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W2962911229",
        "https://openalex.org/W2125320996",
        "https://openalex.org/W3155584966",
        "https://openalex.org/W1037603465",
        "https://openalex.org/W2071436133",
        "https://openalex.org/W2913443447",
        "https://openalex.org/W3173402768",
        "https://openalex.org/W2072918497",
        "https://openalex.org/W2506397550",
        "https://openalex.org/W2908298133",
        "https://openalex.org/W2579504323",
        "https://openalex.org/W2963532001",
        "https://openalex.org/W2963250244",
        "https://openalex.org/W4287900772",
        "https://openalex.org/W4288089799",
        "https://openalex.org/W2761590056",
        "https://openalex.org/W2110228239",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W4205989973",
        "https://openalex.org/W2107287104",
        "https://openalex.org/W2081393932",
        "https://openalex.org/W2766018131",
        "https://openalex.org/W2950444459",
        "https://openalex.org/W2153756411",
        "https://openalex.org/W4385468994",
        "https://openalex.org/W2985067290",
        "https://openalex.org/W4293569541"
    ],
    "abstract": "Shanqing Cai, Subhashini Venugopalan, Katrin Tomanek, Ajit Narayanan, Meredith Morris, Michael Brenner. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2022.",
    "full_text": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics:\nHuman Language Technologies, pages 1261 - 1275\nJuly 10-15, 2022 ©2022 Association for Computational Linguistics\nContext-Aware Abbreviation Expansion Using Large Language Models\nShanqing Cai∗ Subhashini Venugopalan∗ Katrin Tomanek\nAjit Narayanan Meredith Ringel Morris Michael P. Brenner\nGoogle Research\n{cais,vsubhashini}@google.com\nAbstract\nMotivated by the need for accelerating text en-\ntry in augmentative and alternative communi-\ncation (AAC) for people with severe motor im-\npairments, we propose a paradigm in which\nphrases are abbreviated aggressively as primar-\nily word-initial letters. Our approach is to\nexpand the abbreviations into full-phrase op-\ntions by leveraging conversation context with\nthe power of pretrained large language mod-\nels (LLMs). Through zero-shot, few-shot, and\nﬁne-tuning experiments on four public conver-\nsation datasets, we show that for replies to the\ninitial turn of a dialog, an LLM with 64B pa-\nrameters is able to accurately expand over 70%\nof phrases with abbreviation length up to 10,\nleading to an effective keystroke saving rate of\nup to 77 % on these expansions. Including a\nsmall amount of context in the form of a single\nconversation turn more than doubles abbrevia-\ntion expansion accuracies compared to having\nno context, an effect that is more pronounced\nfor longer phrases. Additionally, the robust-\nness of the models against typo noise can be\nenhanced through ﬁne-tuning on noisy data.\n1 Introduction\nThe prevalent paradigm of text entry on computing\ndevices is sequential typing of characters. Word\ncompletion and prediction can theoretically save\nup to 40-50% keystrokes when 3-5 predictions\nare provided (Trnka and McCoy, 2008; Fowler\net al., 2015). This reduces the motor and cogni-\ntive demand of entering text, especially on devices\nwhere typing is difﬁcult, e.g., phones. In AAC\nuse cases such as eye-gaze keyboards for severely\nmotor-impaired individuals, the cost per keystroke\nis so high that there is a desire to save as many\nkeystrokes as possible. Gaze-typing requires the\nuser to precisely control the direction and timing of\ngaze for each keystroke, resulting in an extremely\nlow text-entry speed of 8-10 words per minute and\n∗equal contribution\nFigure 1: Our approach to abbreviation expansion based on an\nLLM with context compared to one without. The conversation\ncontext (e.g., a previous turn of conversation) along with the\nabbreviation of the intended phrase form the LLM’s input.\nSampled continuations from the model are ﬁltered to discard\nthose that do not match the abbreviation. Top-5 options after\nsorting by frequency are presented.\nseverely limiting real-time communication (Waller,\n2019). A text-entry paradigm with substantially\nhigher keystroke saving rate (KSR) can reduce mo-\ntor demand and thereby beneﬁt AAC usage in real-\ntime communication.\nOne potential paradigm is \"SMS language\",\na spontaneously-evolved system for saving\nkeystrokes in which each word is abbreviated as\na single letter, such as in the well-known abbrevi-\nations sg for sounds goodand ttyl for talk to you\nlater (Anjaneyulu, 2013). SMS language features\na high KSR (75-80%), but is limited by its small\nclosed set of common phrases of mostly six words\nor shorter. Its abbreviation scheme is not applied to\nlonger or less frequent phrases because such abbre-\nviations would be hard for the recipient to decipher.\nFor example, the abbreviation iipitb is highly am-\nbiguous and may represent many possible phrases,\ne.g., it is pouring in the bayand it is pretty in the\nbackyard (see Figure 1 for more examples). Some\nexisting AAC systems support abbreviation expan-\nsion (e.g., Tobii), but are limited by hardcoded,\n1261\nclosed phrase sets.\nThe current study is based on the insight that\nalthough decoding open-set phrases from abbre-\nviations is hard without contextdue to ambiguity,\nproviding conversational context signiﬁcantly con-\nstrains the space of likely phrases as shown by\nthe example in Fig.1 ( it is playing in the back-\nyard). Hence we propose a high-KSR abbrevia-\ntion scheme that focuses on conversational scenar-\nios. We apply this scheme to three existing dialog\ndatasets and create datasets for abbreviation expan-\nsion (AE).\nThis allows us to study whether LLMs, trained\non web text including conversational data, can en-\nable AE and beneﬁt from added context. We take a\n64B parameter LLM and compare zero-shot, few-\nshot, and ﬁne-tuning performance on the AE task.\nAdditionally, we simulate typing noise to study\ntolerance of the approach to typos. The main con-\ntributions of our work are:\n1. Demonstrating the potential of abbreviation\nexpansion using LLMs aided by conversational\ncontext for highly-abbreviated text entry, while\nmeasuring the effects of different amounts of con-\ntext and different dialog turns.\n2. Describing a high-KSR abbreviation scheme,\na method for simulating typing noise, and conver-\nsation datasets based on these.\n3. Comparing zero-shot, few-shot, and model\nﬁne-tuning approaches for the AE task and their\ntolerance to typo noise.\n2 Related Work\nAbbreviation expansion for text entry. Previ-\nous research on aiding text entry through AE used\nabbreviation schemes such as using only content\nwords (Demasco and McCoy, 1992), discarding\ncertain vowels and consonants (Shieber and Nelken,\n2007), and ﬂexible letter saving schemes (Pini et al.,\n2010; Adhikary et al., 2021; Gorman et al., 2021).\nSpontaneous abbreviations schemes primarily omit\nvowels, repeating consonants, last characters, and\nspaces, and lead to modest KSR (e.g., 25-40%\nin Willis et al. 2005, and 21% in Adhikary et al.\n2021.) The low KSR of such schemes can be at-\ntributed to the implicit need for a human reader\nto decode the phrases without signiﬁcant cogni-\ntive burden. N-gram models and neural language\nmodels (LMs) have been applied to expanding ab-\nbreviations for these relatively low-KSR schemes.\nBy using LSTM models and context, Gorman et al.\n(2021) achieve a word error rate of 1.5%. Adhikary\net al. (2021) report a 24.2% top-5 sentence error\nrate decoding abbreviations using an RNN to aug-\nment an n-gram LM. Our presented approach is a\nstep towards using automation and context to ex-\npand abbreviations at a higher KSR that is close to\nthat of SMS language.\nLarge language model prompting and ﬁne-\ntuning. Our approach builds on prior work on\nLLMs including few-shot prompting, ﬁne-tuning,\nand conversation models (Raffel et al., 2019;\nBrown et al., 2020; Adiwardana et al., 2020;\nRoller et al., 2020). We focus primarily on few-\nshot prompting (Brown et al., 2020) and ﬁne-\ntuning (Ruder, 2021). Few-shot prompting uses a\ntext description of a task along with a small number\nof examples for the task in the input text in order\nto elicit desired task responses from an LLM. In\nthe zero-shot scenario, no examples are provided.\nPrompting involves no updates to the model pa-\nrameters. Model ﬁne-tuning requires more data\ncompared to prompting, but often leads to higher\ntask accuracy than prompt engineering (e.g., Austin\net al. 2021; Lester et al. 2021). For our AE task,\ndata for ﬁne-tuning can be synthesized from exist-\ning conversation datasets based on an abbreviation\nscheme (Sec. 3). Thus, we explore both prompting\nand ﬁne-tuning and compare their performance.\nAssisting text entry with context. Textual con-\ntexts have been exploited to aid email writing (Kan-\nnan et al., 2016; Chen et al., 2019). For text en-\ntry in AAC, Wisenburn and Higginbotham (2008)\ndemonstrated that providing noun phrases from a\nconversation partner’s speech as selection options\nincreases text-entry speed by 36.7%. Adhikary et al.\n(2019) concluded that with currently-attainable ac-\ncuracy of ASR, partner speech can be valuable in\nimproving language modeling for AAC text entry.\nShen et al. (2022) used a ﬁne-tuned GPT-2 model\n(Radford et al., 2019) to expand bags of keywords\ninto full phrases in conversational contexts based\non the ConvAI2 dataset (Dinan et al., 2020) and\nreported a KSR of 77% at a word error rate thresh-\nold of 0.65. Our current study differs from the\nprevious studies in the following aspects. First, we\nprovide an abbreviation scheme to allow greater\nuser control over the exact phrase structure and\nwording. Second, we performed detailed quantita-\ntive analysis of the combined predictive power of\nstate-of-the-art LLMs and context awareness.\n1262\n3 Methodology\nAbbreviation Scheme. Our abbreviation\nscheme differs from previous studies in that we\noptimize for KSR and do not expect a human\nreader to be able to easily decode the abbreviations.\nAdditionally, it offers the beneﬁt that each given\nphrase is mapped to a ﬁxed abbreviation. The\ndetailed rules for abbreviating phrases are:\n1. Each word is abbreviated as its initial letter,\nunless the word contains an apostrophe (i.e., con-\ntraction), in which case the word is split at the\napostrophe and the initial letters from the splits are\ntaken (e.g., can’t–> ct). This prevents abbrevia-\ntions that are otherwise identical but semantically\nopposite (e.g., can vs. can’t).\n2. All letters in the abbreviation are lowercase.\n3. Arabic numerals in a sentence are preserved\n(e.g., see you at 10 o’clock–> sya10oc).\n4. Sentence-ﬁnal punctuation are removed. Mid-\nsentence punctuation and special characters (e.g., #\nand $) are preserved to help constrain the structure\nof the sentence (e.g., OK, but be quick.–> o,bbq).\n3.1 Datasets for context-aware AE\nWe study modiﬁed versions of existing dialog\ndatasets, which we converted for the context-aware\nAE task. We also describe how we simulate typos.\nDatasets. Table 1 summarizes the four datasets.\nWe use their original train/dev/test splits in our ex-\nperiments. The Turk Dialogues dataset (Vertanen,\n2017) consists of crowd-sourced dialogs, each of\nwhich is exactly six turns in length. The dataset has\ntypos and grammatical errors. We manually cor-\nrect these and refer to the corrected dataset asTurk\nDialogues Corrected (TDC).1 We use three more\ndatasets, DailyDialog (Li et al., 2017), a dataset of\neveryday conversations; the Cornell Movie Dia-\nlogues (CMD) (Danescu-Niculescu-Mizil and Lee,\n2011) based on movie scripts, and the Turk AAC\ndataset (TAC) (Vertanen and Kristensson, 2011).\nFor evaluation on out-of-domain dialogs, we use\nthe TaskMaster-1 Self Dialogs (TMSD) dataset\n(Byrne et al., 2019), a corpus of dialogs written by\ncrowdworkers for task-oriented scenarios such as\nordering pizza. TMSD is used only for evaluation\nand not for training or validation of the models. For\nDailyDialog, we remove 228 dialogues from the\n1The corrected version is available in the ﬁle\nturk_dialogues_corrected.txt in Supplemental Data\ntest split that are duplicate with conversations in the\ntrain split (see Appendix A), which leads to what\nwe call the DailyDialog Corrected (DDC) dataset.\nNo correction is applied to the other datasets. The\nTAC dataset contains only isolated phrases without\nany conversational-turn context. Hence we use it\nonly for training. In all of our experiments, we com-\nbine data from the training splits of all four datasets\nwhen ﬁne-tuning models. We perform evaluations\non the TDC, DDC, CMD, and TMSD datasets. The\nTDC dataset is chosen as our primary benchmarks\nbecause of its strict six-turn dialog structure.\nModiﬁcations for the AE task. The above-\nmentioned datasets are typically used to study\ndialog generation. For our scenario, we con-\nvert each turn of the conversation in these\ndatasets into the following canonical format:\nContext: {Content of the contextual turn}\nShorthand: {Abbreviation of next turn}\nFull: {Expanded content of next turn}\nContext: {Would you like to sit down?}\nShorthand: {n,imfsu}\nFull: {No, I’m ﬁne standing up}\nFor the AE task, the context consists of one or\nmore previous dialog turns. When context is absent\n(e.g., for the opening turn), the context part is\nomitted. For a multi-turn dialog, the nth (1-based)\nexample contains the ﬁrst (n - 1) dialog turns as the\ncontext as well as the shorthand and the full form\nof the nth turn. Thus, a 6-turn conversation yields\nsix examples for the AE task. When multiple\nsentences are present in a single turn, we use only\nthe ﬁrst sentence for expansion; when a turn is\nused as context, all available sentences are used.\nTable 2 shows examples generated from all six\nturns of a dialog from TDC. Each dialog in the\nTDC, DDC, and CMD datasets yields several\nexamples covering different amount of context.\nWe create only 0-context-turn examples for the\nTAC dataset since it contains only isolated phrases.\nText-entry noise in AE datasets. As with our\nAE scheme, the introduction of noise to the datasets\nis also motivated by the AAC text entry use case,\nand in particular eye-gaze typing, which is error\nprone (Feit et al., 2017). Here, misclicks occur\nfrequently and must be taken into account when\ndesigning a gaze-driven text entry system. In order\nto simulate the noise, we model eye-gaze typing\nas uncorrelated 2D Gaussian distributions around\nthe intended key (Azenkot and Zhai, 2012). To\n1263\ntrain dev test\nDataset #conv. #examples Avg. tokens #conv. #examples Avg. tokens #conv. #examples Avg. tokens\nTurk Dialogues Corrected (TDC)859 5,154 54.4 ±24.0 280 1,680 54.5 ±24.3 280 1,680 55.0 ±24.7\nTurk AAC (TAC) 5,019 5,019 20.5 ±4.3 559 559 20.9 ±4.4 565 565 20.1 ±4.0\nDailyDialog Corrected (DDC)11,188 87,170 101.1 ±77.0 823 6,498 98.9 ±72.3 772 5,852 96.7 ±69.2\nCornell Movie Dialog (CMD)66,848 244,798 68.3 ±71.8 8,645 31,272 65.5 ±67.4 7,444 27,429 69.8 ±76.2\nTable 1: Summary of datasets with number of conversations (conv.), examples, and average tokens (mean±1 SD in number of\nSentencePiece tokens) used in our experiments for the context-aware AE task.\nOriginal dialog AE example AE example (noise σ=0.3)\nWould you like to sit down?\nNo, I’m ﬁne standing up\nAre you sure you don’t\nwant to sit down?\nBeen sitting all day. Work was\njust one meeting after another.\nOh, I’m sorry. I don’t enjoy\nwork days like that.\nIt feels good to stretch\nmy legs a bit.\n0-turn context: Shorthand: {wyltsd}.\nFull: {Would you like to sit down?}\n1-turn context: Context: {Would\nyou like to sit down?}. Shorthand:\n{n,imfsu}. Full: {No, I’m ﬁne stand-\ning up}\n···\n5-turn context: Context: {Would you\nlike to sit down?} {No, I’m ﬁne stand-\ning up} {Are you sure you don’t want to\nsit down?} {Been sitting all day. Work\nwas just one meeting after another.}\n{Oh, I’m sorry. I don’t enjoy work\ndays like that.}. Shorthand: {ifgtsm-\nlab}. Full: {It feels good to stretch my\nlegs a bit.}\n0-turn context: Shorthand: {wy!tsd}.\nFull: {Would you like to sit down?}\n1-turn context: Context: {Would\nyou like to sit down?}. Shorthand:\n{n,infsu}. Full: {No, I’m ﬁne stand-\ning up}\n···\n5-turn context: Context: {Would you\nlike to sit down?} {No, I’m ﬁne stand-\ning up} {Are you sure you don’t want to\nsit down?} {Been sitting all day. Work\nwas just one meeting after another.}\n{Oh, I’m sorry. I don’t enjoy work days\nlike that.}. Shorthand: {ifgtsm oab}.\nFull: {It feels good to stretch my legs a\nbit.}\nTable 2: An example dialog and the generated AE examples without and with typo noise. The six-turn dialog is an excerpt from\nthe train split of the TDC dataset. In the 3rd column, the typos in abbreviation are marked in red.\nFigure 2: Keyboard layout for simulating noise in AE key-\npresses. The circles on the f key show 1σaround the mean\nfor σ ∈{0.3,0.5}in the 2D Gaussian distributions used to\nmodel typing noise.\nsimulate noise in the abbreviation input, we use a\nsimpliﬁed rectangular-grid qwerty keyboard layout\nwith 30 keys arranged in three rows and 10 columns.\nThe keys are 1×1 squares with no gaps in between.\nThe keystrokes for an intended key are drawn from\n2D Gaussian distribution centered on the center of\nthe intended key and standard deviations denoted\nσ equal in the two spatial dimensions. To model\ndifferent levels of noise, we use three values of\nσ: 0.0 (i.e., no-typo baseline), 0.3, and 0.5, which\ncorresponds to 0%, 13%, and 44% character error\nrates, respectively. Examples with simulated typos\nare shown in Table 2.\n3.2 Large Language Model\nOne of our goals is to test whether zero-shot and\nfew-shot prompting of LLMs are effective at the\nAE task without the need for supervised ﬁne-tuning.\nPrompting is the method of eliciting desired task-\nspeciﬁc responses from an LLM by including a\nnatural-language description of the task and/or\ninput-output examples of the task in the input string\nfor an LLM, without altering the model’s weights\n(Brown et al., 2020). Zero- and few-shot prompting\ndiffer in whether any examples are included in the\nprompt to the LLM. For this, we use a decoder-\nonly Transformer language model (Vaswani et al.,\n2017) from the LaMDA (Thoppilan et al., 2022)\nfamily of models. Our experiments are based\non the 64B parameter model, unless otherwise\nspeciﬁed. This model has 32 Transformer layers,\nwith dmodel = 8192, dff = 65536, h = 128,\ndk = dv = 128. The model was pre-trained on\n2.97B public web documents, Wikipedia, and di-\nalogs. The training data was tokenized with the\nSentencePiece vocabulary (Kudo and Richardson,\n2018) of size 32K. We call this the BaseLLM.\nWe also developed ﬁne-tuned versions of this\nmodel for the AE task. The ﬁne-tuning uses ex-\namples in the format as shown in Table 2. Since\nthe BaseLLM is a decoder only model, and we\nuse both the context and abbreviation as triggers\nto the model during inference, we modify the loss\nto only be calculated on the tokens of the AE tar-\nget, i.e. the full form to be predicted in the pair\nof curly brackets after \"Full:\". For both training\nand inference, we split the characters in the ab-\nbreviation with spaces to force SentencePiece to\n1264\nuse per-character IDs. We tune 2 two models, FT-\nLLM on the combined AE datasets without typos,\nand FTnoise-LLM on the version with simulated\ntypos. Both use early stopping on a dev set consist-\ning of combined examples from the dev splits of\nTAC and TDC (Table 1).\n4 Experiments\nModels. We use and compare the following mod-\nels in our different experiment settings.\nLook-Up Table (LUT). As a straight-forward,\nnon-ML baseline, we compile a dictionary of\n375,298 sentence-level abbreviations from the train\nsplits of the datasets in Table 1. Each abbreviation\nmaps to one or more phrases with their frequencies,\nleading to 447,249 unique abbreviation-sentence\npairs. During evaluation, we map the query abbrevi-\nation to the top-5 expansion phrases (by frequency)\nby using the dictionary and breaking ties randomly.\nBaseLLM (from Sec. 3.2). We study the\nBaseLLM in the zero-shot and few-shot (specif-\nically 4-shot) settings 3. The four examples are\nselected from the train split of the TDC dataset (see\nAppendix B). We quantify the variability of the\nmodel on a sets of 856 4-example sequences from\nthe train split of the TDC dataset. The best per-\nforming one on the dev set is denoted BaseLLM∗.\nFTnoise-LLM tuned on simulated typos with\nnoise level σ = 0.3 (see Appendix C), and FT-\nLLM tuned on AE data without noise as described\nin Sec. 3.2 are additional models we compare to.\nT5 encoder-decoder . For comparison with\nsmaller models, we use the T5 encoder-decoder\nsmall (60M), large (770M), and 3B parameter\nmodels ﬁne-tuned on AE data without noise, iden-\ntical to FT-LLM.\nWe evaluate the ﬁne-tuned models in the set-\nting without any explicit natural language instruc-\ntions (denoted “no instr.”) unless mentioned oth-\nerwise. For all models, we perform random sam-\npling with temperature=1.0 over the top_k=40 can-\ndidates with the highest logits at each step. We\ndecode 128 samplesfor each abbreviation unless\notherwise speciﬁed. For each model and evaluation\nsetting we report the standard deviations (SDs) of\nmetrics over 3 repeated runs.\n2Appendix D and F provide details on ﬁne-tuning and\ndiscuss the effect of character splitting.\n3The prompts are preﬁxed with the natural language in-\nstruction “Given acronym, write the full phrase.” when there’s\nno context or “Given previous turn(s) of conversation and\nacronym of reply, write the full phrase.” when there is context.\nAbbv.length TDC (dev)TDC (test)DDC (test)CMD (test)TMSD (test)\n1-2 85 (5.1%) 105 (6.2%)166 (21.5%)2,003 (26.9%)176 (22.9%)3-4 324 (19.3%)293 (17.4%)168 (21.8%)1,753 (23.6%)109 (14.2%)5-6 454 (27.0%)439 (26.1%)152 (19.7%)1,396 (18.8%)113 (14.7%)7-8 339 (20.2%)376 (22.4%)118 (15.3%)851 (11.4%)129 (16.8%)9-10 221 (13.2%)218 (13.0%)64 (8.3%)528 (7.1%)111 (14.4%)\n1-10 1,423 (84.7%)1,431 (85.2 %)668 (86.5%)6,531 (87.8%)638 (82.9%)\nTable 3: Datasets used for evaluation sliced by abbreviation\nlengths. Number of dialog turns in each range and their per-\ncentage (in parentheses) as compared to the total are noted.\nStudies. For the BaseLLM, we study the vari-\nance in performance based on the prompt selection.\nFor all the models, we sample multiple responses\nfor each query, hence we study the effect of number\nof responses sampled on AE accuracy and latency.\nWe also compare the performance of the models\nwith varying amounts of conversation context and\nwith no context. To study the effect of typos, we\ncompare the performance of the models on the\nnoise induced AE dataset. To measure the impact\nof model size on accuracy and latency, we also ﬁne-\ntune and evaluate performance of the decoder-only\nLaMDA models with fewer than 64B parameters,\nspeciﬁcally 4B, 8B, and 27B parameters. All these\nmodels were trained on the same data, so that the\nmodel size consitutes the only difference.\nEvaluation. We only evaluate on conversation\nqueries with abbreviation length ≤ 10 charac-\nters. This encompasses the majority (85 %) of\nthe dialog turns from the original dataset (Table\n3). Where applicable, we prepend the following\nnatural-language instruction to the model input for\nthe AE task: \"Given previous turn(s) of conversa-\ntion and acronym of reply, write the full phrase.\"\nBefore calculating performance metrics, we ﬁl-\nter the model’s responses: we remove sentence-\nﬁnal punctuation, standardize whitespace to one\nspace, lower-case, de-duplicate, and ﬁlter for pre-\ncise match of the abbreviation. The responses that\npass the ﬁltering are sorted by descending count.\nFor evaluation with noise, we do ﬁltering to allow\nmatches to nearby characters on the keyboard.\nMetrics. Accuracy measures whether any re-\nsponse expansion exactly matches the ground truth\n(with standardized letter-casing and whitespace,\nand discarded ﬁnal punctuation). Additionally, we\nmeasure BLEU score (Papineni et al., 2002) us-\ning the SacreBLEU library (Post, 2018) as a more\nﬁne-grained metric for the similarity between AE\noptions and the ground truth. For both metrics, we\nreport performance in the top-5 responses after they\nare sorted based on frequency.\nKey Stroke Savings (KSR) measures the num-\n1265\nTDC-test TDC-test+noise (σ=0.3) DDC-test CMD-test TMSD-testModel Acc.@5 BLEU@5Acc.@5 BLEU@5Acc.@5 BLEU@5Acc.@5 BLEU@5Acc.@5 BLEU@5\nLook-Up Table (LUT)14.3±0.2 23.6±0.1 10.5±0.0 15.8±0.7 48.1±0.2 55.4±0.3 30.9±0.1 39.2±0.1 29.3±0.1 34.7±0.1T5-small (60M) 42.7±0.5 59.9±0.1 21.2±0.1 36.1±0.3 69.1±0.5 78.1±0.6 38.7±0.0 50.4±0.1 50.7±0.3 64.8±0.5T5-large (770M) 55.2±0.6 68.6±0.4 27.3±0.6 40.9±0.3 74.2±0.1 81.7±0.1 41.2±0.0 52.6±0.1 57.1±0.1 70.1±0.2T5-3B (3B) 59.4±0.4 72.8±0.1 26.9±0.8 41.9±0.7 77.6±0.5 83.9±0.5 43.5±0.1 54.8±0.2 59.5±0.2 72.5±0.3BaseLLM∗64B (best,4shot) 43.7±1.2 54.9±0.5 38.1±0.1 42.0±0.5 38.4±0.4 43.3±0.6 22.5±0.2 25.9±0.1 32.0±0.7 36.2±0.3FT-LLM 64B (no instr.)74.4±1.0 81.8±0.8 44.5±0.7 55.0±0.3 75.1±0.6 82.1±0.6 48.1±0.1 57.9±0.2 62.0±0.3 73.9±0.2FTnoise-LLM 64B (no instr.)72.3±0.9 81.1±0.5 60.9±0.3 71.4±0.5 74.8±0.4 82.1±0.3 47.5±0.1 57.3±0.1 63.3±0.1 74.4±0.2\nTable 4: Comparing models (from Sec. 4) on the AE task on turn-2 given turn-1 as context. We report accuracy and BLEU score\nat top-5, as percentages, std. dev. computed on 3 runs. Higher is better, values in bold are highest in each column.\nber of saved keystrokes compared to the full length\nof the phrase. Note, however, that AE succeeds\nonly for a subset of the cases, while for others the\ntop-5 options do not contain the intended phrase.\nHence we compute two types of KSR:\nKSRall, computed on all phrases, is deﬁned as\nKSRall =\n\n\n\n(\n1 −\nLabbrev\nLfull\n)\n× 100, if in top-5.\n(\n1 −\nLabbrev+Lfull\nLfull\n)\n× 100, otherwise.\n(1)\nwhere Labbrev and Lfull are the character lengths\nof the abbreviation and full phrase, respectively. In\nother words, if a phrase has a matching option in the\ntop-5, we calculate the KSR as the percentage of\nkeypresses saved by using the abbreviation. If the\nground truth is not in top-5, we add a penalty term\n(Lfull ) to account for the need to enter the phrase\nby starting anew character-by-character, leading to\na negative KSR. KSRall is calculated by averaging\nover all phrases in an experiment. KSRsuccess, is\ncalculated by averaging over only the subset of\nphrases with exact matches and uses the ﬁrst case\nin Equation 1.\n5 Results\nWe present the main results comparing the models\non all datasets in Table 4 and then highlight results\nfrom speciﬁc experiments.\nThe accuracy of LLMs at expanding word-\ninitial abbreviations is enhanced by ﬁne-tuning.\nTable 4 compares the performance of all the mod-\nels on the abbreviation expansion (AE) task4. The\ndata shown in the table are for AE on the 2nd turn\nof a dialog that utilizes the 1st turn as the context,\nwhich focuses on our main hypothesis regarding\nthe effect of context on AE.\nIt’s noteworthy that the BaseLLM∗, which has\nseen just four examples in its prompt (unlike the\nother models), shows performance that exceeds\nthe look-up table (LUT) baseline in many cases,\n4Appendix Tab. 8 reports performance on dev split of the\nTDC (TDC-dev) which was used for hyperparameter tuning.\ndemonstrating the versatility of LLMs. The higher\nscores of the LUT on DailyDialogs (DDC) and Cor-\nnell Movie Dialogues (CMD) datasets are indica-\ntive of the high percentage of similar phrases in the\ntrain and test sets of the datasets. Unsurprisingly,\nthe ﬁne-tuned models (FT-LLM , FTnoise-LLM,\nand T5 models) far outperform even the best4-shot\nBaseLLM∗, achieving 74-77% top-5 exact-match\naccuracy on the TDC and DDC datasets in the ab-\nsence of typo noises. The accuracies are lower on\nthe CMD dataset (comprised of movie scripts.) The\nout-of-domain evaluation on the TaskMaster Self\nDialogs (TMSD) dataset also showed accuracies\nlower than the TDC and DDC datasets, but higher\nthan the results from the CMD dataset.\nFine-tuning and tolerance to noise. For condi-\ntions that involve simulated typo noise in the ab-\nbreviation input, FTnoise-LLM shows superior per-\nformance compared to other models (see the col-\numn \"TDC-test + noise\" in Table 4.) Interestingly,\nthe performance of the BaseLLM∗ doesn’t drop as\nmuch as any of the ﬁne-tuned models - T5 or FT-\nLLM - in this setting. However, while FT-LLM still\noutperforms BaseLLM on the noisy abbreviations,\nthe smaller T5 models fail to do so.\nContext is critical for AE accuracy Figure 3\nshow how the AE accuracy of FT-LLM varies when\ndifferent amounts of context from previous turns\nof the conversation are provided. Compared to\nhaving no context (dash-dotted curve), including\njust one previous turn of context (dashed curve)\napproximately doubles accuracy. Using the full\ncontext (all dialog turns from the 1 st to the (n-\n1)th, solid curve) leads to further improvements\nindicating that prior turns carry useful information\nfor the AE task.\nCompared to the 1st turn, AE under no context\non subsequent turns (2nd-6th) shows signiﬁcantly\nworse accuracy. This is due to the fact that the\nﬁrst turn consists of conversation starters that are\neasier to predict without context. Overall, irrespec-\ntive of context, the accuracy of AE decreases as\n1266\nFigure 3: AE accuracy of FT-LLM, evaluated (inference only)\nwith different amounts of input context (different curves) on\ndifferent dialog turns (x-axis) on the TDC dev set. With all\nturns as context (solid blue curve) or just the previous turn\nas context (dashed orange curve), the model considerably\noutperforms the setting where no context is provided (dot-\ndash green) with the abbreviation query.\nFigure 4: AE accuracy as a function of abbreviation length\n(AL). The results shown are from FT-LLM evaluated with no\nprompt. Different colors of bars show AE on the 1st and 2nd\nturns of the dialog in the TDC dev split, with 0 and 1 previous\nturn as the context. The 1-2 bin contains no 1st-turn examples.\nthe number conversation turns increases, indicating\nincreasing difﬁculty in predicting the full phrases\nfrom the abbreviation as the dialogs progress. How-\never, including full context during inference still\nachieves accurate expansions for 60%-70% of the\ncases on the later turns.\nEffect of context is more pronounced on\nlonger abbreviations. When performance is\nsliced by the abbreviation length (Figure 4), accu-\nracy without context decreases sharply and nearly\nmonotonically with increasing abbreviation length,\nregardless of whether it’s the opening turn or the\n2nd turn. With context however, the accuracy\nremains higher and decreases more slowly with\nabbreviation length, extending the approximately\n80% or higher accuracy into longer phrase lengths.\nThe variability and usefulness of few-shot\nprompts decreases after model tuning. Here\nwe focus on how much the LLM beneﬁts from\nAcc.@top-5 BaseLLM FT-LLM\n4-shot prompt 31.71 ± 4.83 74.43 ± 1.79\n0-shot prompt 37.10 ± 1.38 77.10 ± 0.38\nNo instr. 14.00 ± 1.01 76.65 ± 1.06\nTable 5: Mean and standard deviation of Accuracy@top-5 for\nthe BaseLLM and FT-LLM over 856 different 4-shot prompts\nfrom the TDC train set, 3 repeated runs under 0-shot prompts\n(instruction only) and No instr. (i.e., neither instructions nor\nexamples), based on AE on turn-2 given turn-1 as context.\nFigure 5: Increasing number of samples from the LLMs im-\nproves top-5 exact-match accuracy. FT-LLMs, even with\nfewest samples and smallest model size, outperform the\nBaseLLM∗.\nprompting before and after ﬁne-tuning. The ﬁrst\nrow of Table 5 compares AE accuracies from\ndifferent 4-shot prompts on the TDC dataset for\nBaseLLM and FT-LLM. We use the 856 example\nabbreviation-expansion pairs from the train split of\nthe TDC dataset, using four conversation examples\nfor the prompt at a time. The BaseLLM shows a\nlarge variance in performance depending on the\nselected examples in the prompt by as much as\nSD = 4.83. The best 4-shot prompt for BaseLLM\noutperforms the 0-shot prompt, despite the fact that\nthe average 4-shot prompt accuracy is lower. There-\nfore for BaseLLM we report the results from the\nbest 4-shot prompt (BaseLLM∗). By contrast, the\nﬁne-tuned model (FT-LLM) shows signiﬁcantly\nlower prompt-related variance ( SD = 1.79) in\naddition to a 2.3-fold increase in the mean accu-\nracy. Moreover, FT-LLM is able to perform the AE\ntask with only a natural-language prompt without\nexamples (0-shot prompt) and even without any\ninstruction (“No instr.”) at average accuracies that\nare more than 1 SD above that of 4-shot prompting.\nThe “No instr.” setting is attractive due to its sim-\nplicity (no need to search for or hand-engineer a\nprompt) and reduced latency (due to shorter input\npreﬁx lengths). Given these results, we use the\n“No instr.” as the default setting and for all other\nexperiments on FT-LLM and FTnoise-LLM.\n1267\nDataset-split AE task KSRall KSRsuccess\nTDC-test 1st turn (no context)37.1±0.19 76.8±0.04\n2st turn (with context)49.0±0.99 73.5±0.03\nDDC-test 1st turn (no context)20.0±1.15 74.6±0.04\n2st turn (with context)49.0±0.60 72.9±0.04\nTable 6: KSR computed on all phrases and only phrases with\nmatching AE options. The data in this table is computed on\nthe results from FT-LLM.\nIncreasing number of decoded samples im-\nproves accuracy at the cost of latency. Latency\nis important for interactive text-entry applications.\nDuring sampled decoding, the LLMs generate 128\ncontinuations of length 16 tokens for a batch of\npreﬁx length 256 with a median latency of 0.568 s\n(interquartile range: 0.16 s).\nThis latency is close to typical dwell time of\neye-gaze keyboards (Majaranta and Räihä, 2007)\nand hence could be acceptable for the eye-gaze\ntyping use cases. Figure 5 shows the effect of in-\ncreasing the number of continuations sampled from\nthe LLMs. As expected, increasing sample count\nfrom 128 to 2048 improves top-5 accuracy for both\nBaseLLM* (with 4-shot prompts) and FT-LLM (no\ninstr.). Improved accuracy comes at the cost of in-\ncreased latency.5 BaseLLM beneﬁts signiﬁcantly\nmore from increasing sample count than FT-LLM.\nComparison of model sizes Figure 5 also com-\npares ﬁne-tuned models of different sizes (4B, 8B,\n27B, and 64B). With model ﬁne-tuning, the ac-\ncuracy increases monotonically with increasing\nnumber of parameters. Interestingly, even with the\nfewest samples (128), ﬁne-tuned models of all sizes\noutperform the larger (64B) model under few-shot\nlearning. Amongst the encoder-decoder T5 models\n(Table 4) larger models signiﬁcantly outperform\nsmaller ones. As observed for the decoder-only\nmodels, the smaller ﬁne-tuned T5 models outper-\nform the few-shot BaseLLM in almost all cases\nexcept when the input consists of typos.\nKeystroke saving rates. KSR can be considered\nas a proxy measure of usability of the approach\nfor AAC use-cases. KSRsuccess values are in the\nrange of 73-77% for the 1st and 2nd turns of di-\nalogs in the TDC and DDC datasets (Table 6), indi-\ncating that our proposed AE scheme does indeed\nlead to high KSRs. Values of KSRall are lower,\nreﬂecting the penalties for when a perfect match\nis not achieved. However, with context, KSRall\n5Note, that it is possible to cut down latency by paralleliz-\ning sampling, however this might increase hardware require-\nments at inference time.\nFigure 6: AE accuracy with and without typo noise in the\ninput abbreviation. We compare the accuracies of the models\nﬁne-tuned without and with noise. Each curve shows the\naverage top-5 accuracy in the 2nd turns of the dialogs in the\ntest split of the TDC dataset.\napproaches 50% and is higher compared to no con-\ntext (20%-37%). Note that KSRall is extremely\nconservative as it does not consider (a) the possi-\nbility of using the information already contained in\nthe abbreviation to \"recover from AE failure\" (e.g.,\nby letting the user specify a word and invoke the\nLLM again) or (b) the fact that word completion\nand prediction may still be utilized even if the user\nfalls back to sequential text entry.\nFine-tuning with noise improves typo tolerance.\nFigure 6 compares the AE accuracies of LLMs\nﬁne-tuned with and without noise (FTnoise-LLM\nand FT-LLM). While both models show decreasing\nAE accuracies with increasing amounts of typos,\nFTnoise-LLM is much more robust showing lesser\ndrop in performance. Further, on noise-free inputs\n(σ=0), FTnoise-LLM shows only slight accuracy\ndeterioration compared to FT-LLM. We also ﬁnd\nthat typo tolerance, for both FT-LLM and FTnoise-\nLLM, is more pronounced with context than with-\nout.\nCross-domain generalization. We use the\nTMSD dataset to compare and evaluate the\nperformance of models on conversation domains\nnot seen in training. In Table 4 we can observe\nthat few-shot prompting does fall behind the\nsimple Look-Up Table baseline on DDC and CMD\ndatasets. However, when we evaluate the models\non cross-domain TMSD dataset of dialogs we can\nobserve that the ﬁne-tuned and few-shot models do\ngeneralize better to unseen domains and perform\nbetter than the baseline look-up.\n6 Discussion\nQualitative analysis of AE failures. As indi-\ncated by the relatively high BLEU scores in Table 4\n1268\n(>80%), there are many expansions in the top-5\noptions that are \"near misses\". Appendix Table\n7 shows a few examples of such near misses, in\nwhich the options differ from the the ground-truth\nphrase by only a semantically-similar word (e.g.,\n“yes” vs. “yeah”, “head out” vs. “head over”.) Fu-\nture studies need to investigate the frequency and\nUX acceptability of such near-miss AE options.\nBut their existence implies that exact-match ac-\ncuracy reported above slightly underestimates the\npractical effectiveness of the models. Another cat-\negory of AE failures involve phrases that contain\ncertain proper nouns. The last four examples in Ta-\nble 7 show such cases in which the model correctly\nexpands all the words but a proper noun. When\nsuch errors occur, the model tends to predict more\ncommon proper nouns, which is likely a reﬂection\nof the higher frequency of the predicted nouns in\nthe model’s pre-training and ﬁne-tuning datasets.\nThe beneﬁt of AE relative to sequential text en-\ntry. Word completion and prediction incur scan-\nning cost: users scan the options in order to deter-\nmine whether any of them match their intention,\nwhich has a detrimental effect on speed that needs\nto be overcome by the high quality of the options\n(Trnka et al., 2009). Although the speed of AE-\nbased text entry remains to be quantiﬁed in future\nstudies, we point out that: (1) AE removes over-\nhead of scanning for options in between keystrokes,\n(2) there are fewer characters to examine or correct\nwhen typing, both of which may offer speed-ups in\naddition to the higher KSR afforded by AE.\nAlthough the current study is motivated by and\nfocuses on the AAC use case, our paradigm of ab-\nbreviated text entry may be applicable to text input\non touch screens as well. The AE approach of the\ncurrent study can be regarded as a variation of con-\ntextual prediction of user text (Kannan et al., 2016;\nChen et al., 2019) that affords greater ﬂexibility in\nmessage content at the trade-off of requiring spec-\niﬁcation of the message with a small number of\nkeystrokes.\nFuture directions. We found ﬁne-tuning to be\nsigniﬁcantly better than prompting in terms of (a)\naccuracy (for both scenarios with and without typo-\nnoise) and also (b) exhibit lower latency as we\nachieve better results with fewer samples. Future\nwork should investigate the differences in laten-\ncies between the encoder-decoder architecture and\ndecoder-only models. For training efﬁciency, in-\nstead of ﬁne-tuning, it will also be worth investigat-\ning strategies such as prompt tuning (Lester et al.,\n2021) that continue to keep the model frozen, but\nlearn some additional parameters for the task.\nEven in the best case scenario models can fail\nto ﬁnd accurate expansions6 among the top-5 op-\ntions. Recovering from such failures is important\nfor AAC use cases. Future studies should con-\nsider options for partial speciﬁcations of one or\nmore words or selection of some words from the\navailable options. Once the recovery from failure\nis proven in ofﬂine analysis, user studies are re-\nquired to validate and quantify the actual beneﬁt\nof the AE text-entry paradigm in lab and real-life\nsettings. Integration with UI approaches is also\nan essential direction, e.g., speeding up eye-gaze\ntyping such as cascading dwell time and dwell-free\nparadigms (Mott et al., 2017; Kristensson and Ver-\ntanen, 2012).\n7 Conclusion\nIn this work we proposed a high-KSR form\nof abbreviation expansion to dramatically save\nkeystrokes for severely-disabled users. We use it to\nsynthesize three datasets for the AE task. Based on\nextensive experiments using few-shot prompting\nand model tuning we demonstrate that across the\ndatasets, ﬁne-tuned LLMs can accurately predict\nexpansions for 48-77% of phrases that are replies\nto initial turns of dialogs and exhibit KSRs in the\nrange of 73-77% for the correctly predicted expan-\nsions, thus pointing at a promising direction for\nfuture user studies of contextual and abbreviated\ntext entry based on LLMs. Models evaluated with\nconversation context show signiﬁcantly higher ac-\ncuracy than without, thus supporting our hypothesis\nthat context is the key to effective abbreviated text\nentry in conversational settings. Furthermore, ﬁne-\ntuning with simulated typos substantially improves\ntolerance to noise in abbreviation.\n8 Acknowledgements\nWe would like to thank Shumin Zhai and Michael\nTerry for feedback on a draft of this work, Yanping\nHuang for pointers on model inference, as well as\nJames Stout, Bob MacDonald, Julie Cattiau, and\nMaarten Bosma for their support. We are grateful\nto Team Gleason for their active involvement and\nfeedback in the development of this work.\n6see Appendix G for analysis\n1269\n9 Ethical Considerations, Limitations,\nand Societal Impact\nAccelerating augmentative and alternative com-\nmunication (AAC) can enhance quality of life of\npeople with extremely limited mobility by facili-\ntating increased social participation and indepen-\ndence (Caligari et al., 2013). While the beneﬁts of\nAE may be large for this population, we note that\nthis approach may have risks.\nThe primary risk of AE is errors in expansions\nthat substantially misrepresent the intent of the\nspeaker in a way that might cause harm to them-\nselves or others (e.g., failure to correctly convey\ncritical health information, insertion of offensive\nlanguage.) The abbreviation expansions may also\nreﬂect biases in the underlying language model\n(e.g., perpetuating stereotypes by more frequently\nsuggesting male pronouns than female, Weidinger\net al. 2021.)\nA more subtle risk is when expansions miss the\nground-truth phrase closely (see Table 7), which\nmay accurately convey content but reduce the\nspeaker’s sense of autonomy and authentic self-\nexpression. Prior work (e.g., Kane et al. 2017) has\nshown that people with ALS highly value AAC that\npreserves and facilitates authentic identity expres-\nsion. Providing speakers with multiple AE options\nto choose from and requiring user conﬁrmation be-\nfore voicing an expansion are design options that\ncan mitigate these risks. Model ﬁne-tuning to im-\nprove safety or personalization to the end-user’s\ncommunication style are additional risk-mitigation\napproaches.\nBeyond enhancing communication speed, an-\nother intended beneﬁt of AE is the potential to\nreduce fatigue associated with gaze-based AAC by\nreducing keystrokes; however, a risk of our sys-\ntem is that if errors in AE are frequent for a given\nuser (perhaps due to eye tracker miscalibration or\nlong-tail abbreviation use) then these savings could\nbe outweighed by the need to correct errors, inad-\nvertently increasing fatigue. User studies to bet-\nter understand error rates in practice, as well as\nfuture work designing interfaces to simplify AE\nerror correction, are important for minimizing this\nrisk. Similarly, our abbreviations scheme’s simple\ndesign based on ﬁrst letters aims to minimize cog-\nnitive load; however, user studies with the target\npopulation using instruments such as NASA’s Task\nLoad Index7 would be required to verify that AE\n7https://humansystems.arc.nasa.gov/\ndoes not cognitively strain end-users.\nReferences\nJiban Adhikary, Jamie Berger, and Keith Vertanen.\n2021. Accelerating text communication via abbrevi-\nated sentence input. In Proceedings of the 59th An-\nnual Meeting of the Association for Computational\nLinguistics and the 11th International Joint Confer-\nence on Natural Language Processing (Volume 1:\nLong Papers), pages 6574–6588.\nJiban Adhikary, Robbie Watling, Crystal Fletcher, Alex\nStanage, and Keith Vertanen. 2019. Investigat-\ning speech recognition for improving predictive aac.\nIn Proceedings of the Eighth Workshop on Speech\nand Language Processing for Assistive Technolo-\ngies, pages 37–43.\nDaniel Adiwardana, Minh-Thang Luong, David R So,\nJamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang,\nApoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu,\net al. 2020. Towards a human-like open-domain\nchatbot. arXiv preprint arXiv:2001.09977.\nThotapally Anjaneyulu. 2013. A glossary: usage ab-\nbreviations of mobile phone sms. ETC: A Review of\nGeneral Semantics, 70(2):141–171.\nJacob Austin, Augustus Odena, Maxwell Nye, Maarten\nBosma, Henryk Michalewski, David Dohan, Ellen\nJiang, Carrie Cai, Michael Terry, Quoc Le, et al.\n2021. Program synthesis with large language mod-\nels. arXiv preprint arXiv:2108.07732.\nShiri Azenkot and Shumin Zhai. 2012. Touch be-\nhavior with different postures on soft smartphone\nkeyboards. In Proceedings of the 14th interna-\ntional conference on Human-computer interaction\nwith mobile devices and services, pages 251–260.\nTom B Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. arXiv preprint arXiv:2005.14165.\nBill Byrne, Karthik Krishnamoorthi, Chinnadhurai\nSankar, Arvind Neelakantan, Daniel Duckworth,\nSemih Yavuz, Ben Goodrich, Amit Dubey, Andy\nCedilnik, and Kyu-Young Kim. 2019. Taskmaster-1:\nToward a realistic and diverse dialog dataset. arXiv\npreprint arXiv:1909.05358.\nMarco Caligari, Marco Godi, Simone Guglielmetti,\nFranco Franchignoni, and Antonio Nardone. 2013.\nEye tracking communication devices in amyotrophic\nlateral sclerosis: impact on disability and quality of\nlife. Amyotroph Lateral Scler Frontotemporal De-\ngener, 14(7-8):546–552.\ngroups/tlx/\n1270\nMia Xu Chen, Benjamin N Lee, Gagan Bansal, Yuan\nCao, Shuyuan Zhang, Justin Lu, Jackie Tsay, Yinan\nWang, Andrew M Dai, Zhifeng Chen, et al. 2019.\nGmail smart compose: Real-time assisted writing.\nIn Proceedings of the 25th ACM SIGKDD Interna-\ntional Conference on Knowledge Discovery & Data\nMining, pages 2287–2295.\nCristian Danescu-Niculescu-Mizil and Lillian Lee.\n2011. Chameleons in imagined conversations:\nA new approach to understanding coordination\nof linguistic style in dialogs. arXiv preprint\narXiv:1106.3077.\nPatrick W Demasco and Kathleen F McCoy. 1992.\nGenerating text from compressed input: An intelli-\ngent interface for people with severe motor impair-\nments. Communications of the ACM, 35(5):68–78.\nEmily Dinan, Varvara Logacheva, Valentin Malykh,\nAlexander Miller, Kurt Shuster, Jack Urbanek,\nDouwe Kiela, Arthur Szlam, Iulian Serban, Ryan\nLowe, et al. 2020. The second conversational in-\ntelligence challenge (convai2). In The NeurIPS’18\nCompetition, pages 187–208. Springer.\nAnna Maria Feit, Shane Williams, Arturo Toledo, Ann\nParadiso, Harish Kulkarni, Shaun Kane, and Mered-\nith Ringel Morris. 2017. Toward everyday gaze in-\nput: Accuracy and precision of eye tracking and im-\nplications for design. In Proceedings of the 2017\nChi conference on human factors in computing sys-\ntems, pages 1118–1130.\nAndrew Fowler, Kurt Partridge, Ciprian Chelba, Xiao-\njun Bi, Tom Ouyang, and Shumin Zhai. 2015. Ef-\nfects of language modeling and its personalization\non touchscreen typing performance. In Proceedings\nof the 33rd annual ACM conference on human fac-\ntors in computing systems, pages 649–658.\nKyle Gorman, Christo Kirov, Brian Roark, and Richard\nSproat. 2021. Structured abbreviation expansion in\ncontext. arXiv preprint arXiv:2110.01140.\nNorman Jouppi, Cliff Young, Nishant Patil, and David\nPatterson. 2018. Motivation for and evaluation\nof the ﬁrst tensor processing unit. IEEE Micro,\n38(3):10–19.\nShaun Kane, Meredith Ringel Morris, Ann Paradiso,\nand Jon Campbell. 2017. \"at times avuncular and\ncantankerous, with the reﬂexes of a mongoose\": Un-\nderstanding self-expression through augmentative\nand alternative communication devices. In Proceed-\nings of CSCW 2017.\nAnjuli Kannan, Karol Kurach, Sujith Ravi, Tobias\nKaufmann, Andrew Tomkins, Balint Miklos, Greg\nCorrado, Laszlo Lukacs, Marina Ganea, Peter\nYoung, et al. 2016. Smart reply: Automated re-\nsponse suggestion for email. In Proceedings of the\n22nd ACM SIGKDD International Conference on\nKnowledge Discovery and Data Mining, pages 955–\n964.\nPer Ola Kristensson and Keith Vertanen. 2012. The\npotential of dwell-free eye-typing for fast assistive\ngaze communication. In Proceedings of the sym-\nposium on eye tracking research and applications,\npages 241–244.\nTaku Kudo and John Richardson. 2018. Sentencepiece:\nA simple and language independent subword tok-\nenizer and detokenizer for neural text processing.\narXiv preprint arXiv:1808.06226.\nBrian Lester, Rami Al-Rfou, and Noah Constant. 2021.\nThe power of scale for parameter-efﬁcient prompt\ntuning. arXiv preprint arXiv:2104.08691.\nYanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang\nCao, and Shuzi Niu. 2017. Dailydialog: A manually\nlabelled multi-turn dialogue dataset. arXiv preprint\narXiv:1710.03957.\nPäivi Majaranta and Kari-Jouko Räihä. 2007. Text\nentry by gaze: Utilizing eye-tracking. Text entry\nsystems: Mobility, accessibility, universality, pages\n175–187.\nMartez E Mott, Shane Williams, Jacob O Wobbrock,\nand Meredith Ringel Morris. 2017. Improving\ndwell-based gaze typing with dynamic, cascading\ndwell times. In Proceedings of the 2017 CHI Con-\nference on Human Factors in Computing Systems,\npages 2558–2570.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic eval-\nuation of machine translation. In Proceedings of the\n40th annual meeting of the Association for Compu-\ntational Linguistics, pages 311–318.\nStefano Pini, Sangmok Han, and David R Wallace.\n2010. Text entry for mobile devices using ad-hoc ab-\nbreviation. In Proceedings of the International Con-\nference on Advanced Visual Interfaces, pages 181–\n188.\nMatt Post. 2018. A call for clarity in reporting bleu\nscores. arXiv preprint arXiv:1804.08771.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, Ilya Sutskever, et al. 2019. Lan-\nguage models are unsupervised multitask learners.\nOpenAI blog, 1(8):9.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2019. Exploring the limits\nof transfer learning with a uniﬁed text-to-text trans-\nformer. arXiv preprint arXiv:1910.10683.\nStephen Roller, Emily Dinan, Naman Goyal, Da Ju,\nMary Williamson, Yinhan Liu, Jing Xu, Myle Ott,\nKurt Shuster, Eric M Smith, et al. 2020. Recipes\nfor building an open-domain chatbot. arXiv preprint\narXiv:2004.13637.\nSebastian Ruder. 2021. Recent Advances in Lan-\nguage Model Fine-tuning. http://ruder.io/\nrecent-advances-lm-fine-tuning .\n1271\nNoam Shazeer and Mitchell Stern. 2018. Adafactor:\nAdaptive learning rates with sublinear memory cost.\nIn International Conference on Machine Learning,\npages 4596–4604. PMLR.\nJunxiao Shen, Boyin Yang, John J Dudley, and Per Ola\nKristensson. 2022. Kwickchat: A multi-turn dia-\nlogue system for aac using context-aware sentence\ngeneration by bag-of-keywords. In 27th Interna-\ntional Conference on Intelligent User Interfaces,\npages 853–867.\nStuart M Shieber and Rani Nelken. 2007. Abbreviated\ntext input using language modeling. Natural Lan-\nguage Engineering, 13(2):165–183.\nRomal Thoppilan, Daniel De Freitas, Jamie Hall,\nNoam Shazeer, Apoorv Kulshreshtha, Heng-Tze\nCheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du,\net al. 2022. Lamda: Language models for dialog\napplications. arXiv preprint arXiv:2201.08239.\nTobii. How to create an abbreviation expansion in\ncompass. https://us.tobiidynavox.\ncom/blogs/support-articles/\nhow-to-create-an-abbreviation-\\\nexpansion-in-compass. Accessed: 2022-04-\n22.\nKeith Trnka, John McCaw, Debra Yarrington, Kath-\nleen F McCoy, and Christopher Pennington. 2009.\nUser interaction with word prediction: The effects\nof prediction quality. ACM Transactions on Accessi-\nble Computing (TACCESS), 1(3):1–34.\nKeith Trnka and Kathleen F McCoy. 2008. Evaluat-\ning word prediction: framing keystroke savings. In\nProceedings of ACL-08: HLT, Short Papers, pages\n261–264.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in neural information pro-\ncessing systems, pages 5998–6008.\nKeith Vertanen. 2017. Towards improving predictive\naac using crowdsourced dialogues and partner con-\ntext. In Proceedings of the 19th International ACM\nSIGACCESS Conference on Computers and Accessi-\nbility, pages 347–348.\nKeith Vertanen and Per Ola Kristensson. 2011. The\nimagination of crowds: conversational aac lan-\nguage modeling using crowdsourcing and large data\nsources. In Proceedings of the 2011 Conference on\nEmpirical Methods in Natural Language Processing,\npages 700–711.\nAnnalu Waller. 2019. Telling tales: unlocking the po-\ntential of aac technologies. International journal\nof language & communication disorders, 54(2):159–\n169.\nLaura Weidinger, John Mellor, Maribeth Rauh, Conor\nGrifﬁn, Jonathan Uesato, Po-Sen Huang, Myra\nCheng, Mia Glaese, Borja Balle, Atoosa Kasirzadeh,\nZac Kenton, Sasha Brown, Will Hawkins, Tom\nStepleton, Courtney Biles, Abeba Birhane, Julia\nHaas, Laura Rimell, Lisa Anne Hendricks, William\nIsaac, Sean Legassick, Geoffrey Irving, and Iason\nGabriel. 2021. Ethical and social risks of harm from\nlanguage models.\nTim Willis, Helen Pain, and Shari Trewin. 2005. A\nprobabilistic ﬂexible abbreviation expansion system\nfor users with motor disabilities. In Accessible De-\nsign in the Digital World Conference 2005, pages\n1–9.\nBruce Wisenburn and D Jeffery Higginbotham. 2008.\nAn aac application using speaking partner speech\nrecognition to automatically produce contextually\nrelevant utterances: Objective results. Augmentative\nand Alternative Communication, 24(2):100–109.\n1272\nAppendix\nA Removal of duplicate dialogs from the\nDailyDialog dataset\nWe observed that the DailyDialog dataset (Li et al.,\n2017) contains a signiﬁcant number of dialogs in\nits dev (validation) and test splits that are identical\nor nearly identical to the dialogs found in its train\nsplit. We determined two dialogs to be duplicate\nby using the following criterion:\n1. If both dialogs consist of the same number\nof turns and the corresponding turns are all\nidentical (case-insensitive), or\n2. If both dialogs consist of the same number\nof turns and there are three or more turns at\nwhich both dialogs contain identical text (case-\ninsensitive).\nSee the ﬁle daily_dialog_deduplications.csv in\nSupplemental Data for a list of the 177 dialogs in\nthe dev split and the 228 dialogs in the test splits\nthat are found to be duplicates with the train split\nand hence are removed from our DailyDialog Cor-\nrected (DDC) dataset.\nB 4- shot examples for BaseLLM∗\nWe select four consecutive dialogues from the 859\nexamples from train split of the TDC dataset (Verta-\nnen, 2017) while varying the starting conversation,\nwhich yields 859 − 4 + 1 = 856different 4-shot\nprompt sets.\nC Tuning on noisy data vs. accuracy\nPreliminary experiments have shown that σ= 0.3\nis a good trade-off between accuracy gains on noisy\ndata and losses on non-noisy data.\nD Model ﬁne-tuning details\nOur model ﬁne-tuning uses the AdaFactor opti-\nmizer (Shazeer and Stern, 2018). The nominal\nbatch size 16 is made more efﬁcient through ex-\nample packing (Raffel et al., 2019), leading to an\naverage effective batch size of approximately 200\nexamples under a maximum sequence length of\n1024 tokens. We used TPUv3s (Jouppi et al., 2018)\nwith a conﬁguration of 4x8 for the LLM ﬁne-tuning.\nOur ﬁne-tuning recipe applies a constant, low learn-\ning rate of5×10−5 and a dropout rate of0.2, which\nhelps to prevent early overﬁtting. Early stopping is\nbased on a dev set consisting of combined examples\nfrom the dev splits of the TAC and TDC datasets.\nWe ﬁnd the best checkpoint after 2100 and 1800\ntraining steps for the FT-LLM and FTnoise-LLM\nmodels, respectively, which amounts to approxi-\nmately 1-1.2 epochs of training. We ran a small\nset of hyperparameter tuning experiments, varying\nbatch size, learning rate and dropout and chose the\nbest setting based on the TAC+TDC dev set.\nE Computation cost\nFine-tuning of the 64B LLM uses TPU v3 with a\n4x8 conﬁguration, i.e., 32 TPUs. FT-LMM and\nFTnoise-LLM are each trained for approximately\n2100 and 1800 steps, respectively. The training\ntime is approximately 3 hours. This leads to a\nmodel ﬁne-tuning budget of 32 x 3 = 96 TPU *\nhour per model.\nEvaluation and inference on the 64B LLM uses\nTPU v3 with a 4x4 conﬁguration, i.e., 16 TPUs.\nEach example (batch size = 128 samples) takes\n0.653 s. This leads to 16 × 0.568/128 = 0.071\nTPU × second per sample.\nF Splitting characters in abbreviations.\nPilot experiments showed the importance of pro-\ngrammatically inserting spaces between characters\nin the abbreviations. Since the vocabulary used by\nthe LaMDA models is fairly large (32k entries),\nunless we enforce character-level splitting, subse-\nquences of multiple characters in many abbrevia-\ntions will be combined into spurious tokens, lead-\ning to slightly reduced AE accuracy.\nG Recovery from failure - analysis\nIn the best scenario of replying to a question, the\nﬁne-tuned LLM is capable of predicting the correct\nphrase expansion approximately 81% of the times\nwith top-5 options and sufﬁcient sampling (Figure\n5). Hence the model will fail to ﬁnd the correct\nexpansion at least 19% of the cases.\nH Inference latencies of different\nLaMDA model sizes\nIn Figure H we compare the latencies during infer-\nence time for the decoder-only models of different\nsizes. Compared to the 4B model, the 27B model\nshows 1.5x latency, while the 64B model shows\n2.2x latency. While the latency increase is quite\nsigniﬁcant, this analysis shows that we cannot sub-\nstitute the 64B model with a smaller model (e.g.,\n1273\n# Context Abbreviation Ground truth Non-matching expansion options\n1 Awesome! My favorite\nweather!\nswhottwp Shall we head over to the water\npark?\nshall we head out to the water park\n2 Can we go out for a drive? ygstc Yeah go start the car yes go start the car\nyes go straight to church\nyes go settle the children\nyeah get some tunes cranked\nyes go straight to chicago\n3 i took a lot of courses, such\nas philosophy, logic, ethics,\naesthetics, etc\nwcdylb which course did you like best what courses do you like best\nwhat courses did you like best\nwhat course do you like best\nwhat course did you like best\nwhich courses did you like best\n4 it’s hard to be optimistic\nabout things with the way the\neconomy’s headed... the\ntrade deﬁcit is getting larger,\nconsumption’s down, i really\nthink we’re headed for a\nrecession\ntehbsfawn the economy has been stagnant\nfor a while now\nthe economy has been slowing for a\nwhile now\nthe economy has been sluggish for a\nwhile now\nthe economy has been strong for a\nwhile now\nthe economy has been slow for a while\nnow\nthe economy has been suffering for a\nwhile now\n5 What is your name? mnir My name is Rey my name is robert\nmy name is rebecca\nmy name is richard\nmy name is rose\nmy name is roy\n6 hey, isabelle... l Logan lisa\nlinda\nlook\nlillian\nliz\n7 so, paula, where are you from imfc,o i’m from canada, originally i’m from china, ok\ni’m from california, originally\ni’m from california, ok\ni’m from california, okay\ni’m from california, obviously\n8 hey sandra, what’s wrong?\nyou look furious\nivhiwt i’ve had it with Tim i’ve had it with this\ni’ve had it with them\ni’ve heard it was true\ni’ve had it with that\ni’ve had it with these\nTable 7: Examples of failed AE. Examples #1-4 show AE options that miss the ground-truth phrase closely. The cases highlighted\nin boldface have near identical meaning to the ground truth, but differ only in details of a single word. Examples #5-8 show AE\noptions that match the ground truth except for the a proper noun.\n1274\nTDC-dev\nModel Acc.@5 BLEU@5\nLook-Up Table (LUT) 16.9±0.2 25.2 ±0.2\nT5-small (60M) 37.8±0.0 59.2 ±0.5\nT5-large (770M) 48.2±0.0 69.1 ±0.5\nT5-3B (3B) 53.9±0.0 72.3 ±0.5\nBaseLLM∗ (best,4shot) 43.0±1.0 52.0 ±1.4\nFT-LLM (no instr.) 76.7±1.1 83.9 ±0.5\nFTnoise-LLM (no instr.)75.8±0.7 83.4 ±0.2\nTable 8: Comparing models (from Sec. 4) on the AE task\non turn-2 given turn-1 as context. We report accuracy and\nBLEU score at top-5, as percentages, std. dev. computed on\n3 runs. Higher is better, values in bold are highest in each\ncolumn. The TDC-dev set was used for model selection before\nevaluation on test sets.\nFigure 7: Inference latencies for different sizes of the LaMDA\nmodel (4B, 8B, 27B, and 64B.) The latencies are shown as\nbox plots.\nby increasing the number of samples) in a way that\nimproves latency without signiﬁcantly harming the\nAE accuracy (compare the AE accuracies in Fig-\nure 5.)\n1275"
}