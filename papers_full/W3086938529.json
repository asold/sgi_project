{
  "title": "Generating accurate assert statements for unit test cases using pretrained transformers",
  "url": "https://openalex.org/W3086938529",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2231495793",
      "name": "Michele Tufano",
      "affiliations": [
        "Microsoft Research (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A3086233478",
      "name": "Dawn Drain",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2627672354",
      "name": "Alexey Svyatkovskiy",
      "affiliations": [
        "Microsoft Research (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A1981173961",
      "name": "Neel Sundaresan",
      "affiliations": [
        "Microsoft Research (United Kingdom)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2682664750",
    "https://openalex.org/W2901721765",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W1971650562",
    "https://openalex.org/W3161997752",
    "https://openalex.org/W2963347649",
    "https://openalex.org/W1988757916",
    "https://openalex.org/W2077273779",
    "https://openalex.org/W2950368691",
    "https://openalex.org/W3005628256",
    "https://openalex.org/W2626778328",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2981852735",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W184125818",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W2950813464",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W2973529529",
    "https://openalex.org/W2982399380",
    "https://openalex.org/W3100026183",
    "https://openalex.org/W1965194038",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W3105903381",
    "https://openalex.org/W4394638297",
    "https://openalex.org/W2514713644",
    "https://openalex.org/W2896457183"
  ],
  "abstract": "Unit testing represents the foundational basis of the software testing\\npyramid, beneath integration and end-to-end testing. Automated software testing\\nresearchers have proposed a variety of techniques to assist developers in this\\ntime-consuming task. In this paper we present an approach to support developers\\nin writing unit test cases by generating accurate and useful assert statements.\\nOur approach is based on a state-of-the-art transformer model initially\\npretrained on an English textual corpus. This semantically rich model is then\\ntrained in a semi-supervised fashion on a large corpus of source code. Finally,\\nwe finetune this model on the task of generating assert statements for unit\\ntests. The resulting model is able to generate accurate assert statements for a\\ngiven method under test. In our empirical evaluation, the model was able to\\npredict the exact assert statements written by developers in 62% of the cases\\nin the first attempt. The results show 80% relative improvement for top-1\\naccuracy over the previous RNN-based approach in the literature. We also show\\nthe substantial impact of the pretraining process on the performances of our\\nmodel, as well as comparing it with assert auto-completion task. Finally, we\\ndemonstrate how our approach can be used to augment EvoSuite test cases, with\\nadditional asserts leading to improved test coverage.\\n",
  "full_text": "Generating Accurate Assert Statements for Unit\nTest Cases using Pretrained Transformers\nMichele Tufano, Dawn Drain, Alexey Svyatkovskiy, Neel Sundaresan\nMicrosoft\nRedmond, W A, USA\nEmail: {mitufano, dadrain, alsvyatk, neels}@microsoft.com\nAbstract—Unit testing represents the foundational basis of the\nsoftware testing pyramid, beneath integration and end-to-end\ntesting. Automated software testing researchers have proposed a\nvariety of techniques to assist developers in this time-consuming\ntask.\nIn this paper we present an approach to support developers\nin writing unit test cases by generating accurate and useful\nassert statements. Our approach is based on a state-of-the-art\ntransformer model initially pretrained on an English textual\ncorpus. This semantically rich model is then trained in a semi-\nsupervised fashion on a large corpus of source code. Finally, we\nﬁnetune this model on the task of generating assert statements\nfor unit tests.\nThe resulting model is able to generate accurate assert state-\nments for a given method under test. In our empirical evaluation,\nthe model was able to predict the exact assert statements written\nby developers in 62% of the cases in the ﬁrst attempt. The results\nshow 80% relative improvement for top-1 accuracy over the\nprevious RNN-based approach in the literature. We also show the\nsubstantial impact of the pretraining process on the performances\nof our model, as well as comparing it with assert auto-completion\ntask. Finally, we demonstrate how our approach can be used to\naugment EvoSuite test cases, with additional asserts leading to\nimproved test coverage.\nIndex Terms—Software Testing, Deep Learning, Software\nMaintenance\nI. I NTRODUCTION\nSoftware testing is recognized as one of the most crucial,\nchallenging, and expensive parts of the software lifecycle. It\ncomes as no surprise that the software testing research commu-\nnity has invested signiﬁcant effort in designing approaches that\naim at supporting or automating software testing activities. An\nexample of this endeavor is the work targeting the automatic\ngeneration of unit tests [ 1], [2]. While these works represent\na notable achievement towards the goal of automated testing,\nthey come with several limitations, recently highlighted by\nstudies in industrial settings [3], [4].\nOne of the major challenges these tools aim to overcome is\nthe generation of accurate assert statements, which have been\nfound to be often incomplete or inadequate to properly test\nthe behavior of a software component. Generating meaningful\nassert statements is one of the key challenges in automatic test\ncase generation [5]. Assert statements represent the basic blocks\nof software testing, used by developers to check conditions or\nstates in a program and reason about program correctness.\nWatson et al. recently proposed ATLAS [ 5], an RNN-based\napproach which aims at learning from thousands of unit test\nmethods how to generate meaningful assert statements. Inspired\nby this work, we improve upon it in substantial ways.\nIn this paper we present an approach to generate accurate\nassert statements based on state-of-the-art transformer model\nand relying on transfer learning to achieve best-in-class\nperformances, predicting the correct assert in 62% of the cases\nin the very ﬁrst attempt, which represents an 80% relative\nimprovement for top-1 accuracy over the previous work [5].\nTransfer learning is a technique which ﬁrst trains a model in\nan unsupervised fashion on large quantities of unlabeled data,\nand then ﬁnetunes on a downstream task like classiﬁcation or\ntranslation. This technique has emerged as a standard route to\nachieve state-of-the-art results in natural language processing\n(NLP) tasks, obtaining higher performance and requiring much\nless resources than training each task from scratch [ 6], [7], [8].\nThe intuitive explanation for this success is that a model which\nlearns to generate text or ﬁll in blanks will have developed\nbiases reﬂected in the data which can help it learn to perform\nparticular language tasks faster and with higher performance.\nIn this paper, we extend this idea to source code as a language\nfor a task of automated assert statement generation. We pretrain\na sequence-to-sequence transformer model on a large source\ncode and English language corpora, and ﬁnetune it on an assert\nstatement generation task.\nIn our extensive empirical evaluation we assess several\nproperties of our approach, such as intrinsic model metrics\nas well as extrinsic metrics related to the generated asserts.\nFinally, we evaluate the proposed approach in a scenario where\nit is used to support automated test case generation tools, such\nas EvoSuite, by augmenting the test cases with the assert\nstatements generated by our approach.\nTo summarize, this paper provides the following contribu-\ntions:\n• An approach that generates accurate assert statements\nbased on a sequence-to-sequence transformer model. Our\napproach can predict the correct assert in 62% of the\ncases in the very ﬁrst attempt, and reaches up to 84%\ncorrectness when allowing the model to suggest more\nasserts.\n• We empirically demonstrate the beneﬁts of pretraing on\nboth English and source code corpora for the downstream\nassert generation task, resulting in performance improve-\nment in terms of variety of intrinsic metrics such as BLEU\nscore, validation loss, and syntactic correctness.\narXiv:2009.05634v1  [cs.SE]  11 Sep 2020\nEnglish Pretraining\n Code Pretraining\n Asserts Finetuning\nBART Transformer\nBART Scratch\nBART English\nModels Evaluation\nBART English+Code\nBART English\nBART Scratch\nBART Code\nFig. 1. Overview of the Model Training Process. Starting from a BART Transformer model, we perform English and Source Code pretraining, and ﬁnetune\nthe models on the Assert generation task. We obtain four different models based on the level of pretraining performed.\n• We investigate how our proposed approach can be used\nto augment existing test cases, such as those generated\nby EvoSuite, with additional assert statements that lead\nto test coverage improvements.\nII. A PPROACH\nFigure 1 provides an overview of the training pipeline we\nfollowed in building our models specialized in assert statement\ngeneration.\nWe begin with the state-of-the-art BART Transformer (Sec.\nII-A) which will serve as the reference architecture for our\nmodels. We employ two pretraining stages: English Pretraining\n(Sec. II-B) where we perform semi-supervised pretraining on a\nlarge corpus of English text; Code Pretraining (Sec. II-C) where\nthe model is pretrained on Java source code. Next, we perform\nthe ﬁnetuning on the task of generating assert statements for\nunit test cases (Sec. II-D), relying on a labelled dataset of test\ncases and method under tests. Finally, we evaluate variants\nof the models (Sec. II-E) obtained with different levels of\npretraining indicated with different arrows in Figure 1.\nA. BART Transformer\nBART [9] is a denoising autoencoder which utilizes the stan-\ndard sequence-to-sequence transformer architecture from [ 10],\nsubstituting ReLUs with GeLU activation functions.\nWe select the BART model architecture because it facil-\nitates ﬁnetuning for downstream translation task of assert\nstatement generation, providing a more advanced set of noising\ntransformations, which include token masking, token deletion,\ninﬁlling and statement permutation. The model is pretrained\nby corrupting documents and optimizing the cross-entropy loss\nbetween the decoder’s output and the original input sequence.\nWe pretrain the BART large model architecture, having 12\nlayers in the encoder and decoder. The model is trained in\nmixed-precision, using Adam stochastic optimization procedure\nwith ϵ= 10−6, and β1 = 0.9, β2 = 0.98 optimizer parameters;\nwe apply inverse square root learning rate schedule with the\nbase learning rate of 0.0001, a warmup period of 5000 update\nsteps, and the local gradient accumulation with a frequency of\n4 update steps.\nB. English Pretraining\nIn this stage we pretrain a model in a semi-supervised fashion\non a large corpus of English text, with the goal of learning\nsemantic and statistical properties of natural language.\n1) Dataset: The pretraining is performed for 40 epochs on\n160GB of English text extracted from books, Wikipedia, and\nnews articles [11], comprising a total of X lines of text.\n2) Training Strategy: BART is trained in an unsupervised\nmanner. Given corrupted text, its objective is to reconstruct\nthe original text. The particular type of noise used in this\nwork involves masking 30% of all tokens, with masks covering\nspans of tokens with lengths following a Poisson distribution\nparameterized by λ= 3, as well as permuting all sentences.\nC. Code Pretraining\nIn this stage we pretrain a model on source code corpus\nwritten in Java language, with the goal of learning syntax and\nproperties of source code.\n1) Dataset: We collect this code corpus dataset by crawling\nall public, non-fork Java repositories on GitHub with at least 50\nstars. We then deduplicate at the ﬁle-level using a hash function.\nAfter ﬁltering based for permissive licenses and ﬁltering out\nbased on heuristics like the fraction of non-ascii characters,\nwe are left with 25GB of training data from the 26,000 repos.\nFor pretraining validation, we use the 239 test Java repos from\nCodeSearchNet [12], which comprise 600MB.\n2) Training Strategy: A similar pretraining strategy to\nEnglish pretraining is employed. The source code ﬁles are\ncorrupted by deleting 20% of all tokens independently and\nrotating half of all documents. This pretraining is performed\nfor 10 epochs.\nD. Asserts Finetuning\nIn this stage we ﬁnetune a model on the task of generating\nassert statements for unit test cases. Speciﬁcally, we represent\nthis task as a translation task, where the source is the partially\nwritten unit test along with the method under test, and the\ntarget is the correct assert statement that the developer wrote\nfor that unit test.\n1) Dataset: To perform the ﬁnetuning, we rely on the\npublicly available dataset of unit test methods used to evaluate\nATLAS [ 5]. This dataset is comprised of Test Methods\n(i.e., methods within a unit test case), Focal Methods ( i.e., the\nmethods under test), and Asserts ( i.e., the assert statements\nwithin the Test Methods).\nThis dataset has been mined from more than 9 thousand\nopen-source GitHub projects containing unit test cases deﬁned\nwith JUnit. The authors ﬁrst extract methods beginning with\nthe @Test annotation as candidate Test Methods. From these\ncandidate methods the authors select those that specify a single\nassert statement. Next, for each Test Method they pinpoint the\nFocal Method ( i.e., the method that the current Test Method\nis testing) using a heuristic [ 13] which looks at last method\ninvocation before (or within) the assert statement. Finally, each\nTest Method is modiﬁed by replacing the Assert statement with\na placeholder <AssertPlaceholder>.\nEach data point in the dataset is referred to as a Test-\nAssert Pair (TAP), and can be seen as a triplet TAPi =\n{tm′\ni,fmi,ai}where tm′\ni is the Test Method where the assert\nstatement has been replaced with a placeholder, fmi is the\nFocal Method, and ai is the assert statement. This data is\norganized as a parallel corpus, a common format for machine\ntranslation tasks, where the source sentence si = {tm′\ni + fmi}\nis the concatenation of the Test Method and Focal Method,\nwhile the target sentence ti = ai is the assert statement to\npredict. Figure 2 provides an example of a TAP. The test method\ntmi is testLength() and its corresponding focal method\nfmi is length(). The test method creates two sets of bits and\ncheck that their length is the same, using the assertEquals\nstatement. The source sentence is the concatenation of the test\nmethod and focal method, where the assert statement is replaced\nwith a placeholder. The corresponding target output is the assert\nto be predicted.\nFor our models, we use the raw version of the dataset –\ncorpus comprising the original source code tokens – rather\nthan the abstract version (where some tokens are replaced\nwith IDs), since we aim to exploit the rich semantics of all\nthe variable and method names. We keep the original split\nof the dataset in training, validation, and testing sets (80%,\n10%, 10%) for a fair comparison. Table I reports the number\nof instances in the dataset.\n2) Training Strategy: The ﬁnetuning process is a translation\ntask, where we train the model to learn the mapping si →ti\nas a conditional probability P(ai|tm′\ni + fmi).\nDuring training we use the cross entropy loss and the Adam\noptimizer and monitor the loss on the validation set for early\nstopping.\nWe use shared vocabulary embeddings between Encoder and\nDecoder for optimizations reasons [ 10], [14] and because our\ninput and output language is the same ( i.e., Java source code).\nE. Model Variants\nAt the end of these stages, we obtain four different variants\nof the model, based on the level of pretraining performed:\nTest Method {tmi}\npublic void testLength() {\nBitSet bset = new BitSet();\nImmutableBitSet ibset = new ImmutableBitSet(bset);\nAssert.assertEquals(bset.length(), ibset.length());\n}\nFocal Method {fmi}\npublic int length() {\nreturn this .bitSet.length();\n}\nSource: {tm′\ni + fmi}\npublic void testLength() {\nBitSet bset = new BitSet();\nImmutableBitSet ibset = new ImmutableBitSet(bset);\n<AssertPlaceHolder>;\n}\npublic int length() {\nreturn this .bitSet.length();\n}\nTarget: {ai}\nAssert.assertEquals(bset.length(), ibset.length())\nFig. 2. Example of a Test-Assert Pair (TAP)\nThe source is formed by concatenating the partial test case (without assert)\nand the focal method. The target is the assert statement to generate.\n• BART_Scratch: A model which has not been pretrained on\nany corpus but directly ﬁnetuned on the assert generation\ntask. This model represents the orange line in Figure 1.\n• BART_English: A model which has been pretrained on the\nEnglish corpus and then ﬁnetuned for the assert generation\ntask. This model represents the green line in Figure 1.\n• BART_Code: A model pretrained on the source code\ncorpus, then ﬁnetuned on the assert generation task. This\nmodel represents the purple line in Figure 1.\n• BART_English+Code: A model pretrained ﬁrst on English\nand further pretrained on source code corpus, then ﬁne-\ntuned on the assert generation task. This model represents\nthe blue line in Figure 1.\nIII. E XPERIMENTAL DESIGN\nThe goal of our empirical study is to determine if our\napproach can generate accurate assert statements for unit test\ncases, in one or very few attempts. We investigate whether\nour approach outperforms the previous RNN-based approach\nATLAS [5]. Additionally we explore the impact of different\npretrainings on the assert generation performances as well as\nthe effect of incorporating the focal method in the input to the\nmodel.\nOur experiments aims at answering the research questions\ndescribed in the following paragraphs.\nRQ1: How does our approach compare with ATLAS?\nWe compare the performances of our models against ATLAS\n[5], the RNN-based approach available in the literature. Specif-\nically, to ensure fair comparison, we perform the ﬁnetuning\nprocess of our models on the exact same training set, and\nevaluate and compare the performances on the same test set. To\ncompare the models’ performances we use the top-k accuracy\nmetric, which measures the accuracy of a model with different\nnumber of attempted predictions. In particular, if the target\nassert statement ai for the i-th input in the test set, is in\nthe top-k predictions of the model, we count it as a correct\nprediction at k. Similarly to ATLAS [ 5], we experiment with\nk= {1,..., 50}with a maximum beam size of 50.\nRQ2: What is the effect of the pretraining process on\nthe assert generation task?\nWe investigate whether pretraining our models on English\ncorpus, on source code, and both corpora has any noticeable\nimpact on the downstream performances of the models on\nthe assert generation task. In particular, we compare the\nBART_Scratch model, which has not been pretrained on any\ncorpus, against BART_English which was pretrained on English\ncorpus, BART_Code which was pretrained on source code, and\nBART_English+Code which was pretrained on both English\nand source code. This comparison is performed considering:\n• Extrinsic metrics: the top-k accuracy on the assert gener-\nation task;\n• Intrinsic metrics: (i) best validation loss and the number of\ntraining steps required to reach it (e.g., faster convergence);\n(ii) BLEU4 score, a common metric for machine trans-\nlation tasks, evaluated on the test set; (iii) the syntactic\ncorrectness of the generated asserts, determined using a\nJava Parser.\nRQ3: What is the effect of the Focal Method on the\nperformance of the model?\nIn Section II-D we described the ﬁnetuning process, where\nthe input to the Encoder is the concatenation {tm′\ni + fmi}of\nthe Test Method tm′\ni and Focal Method fmi. In this research\nquestion our goal is to understand the effect on performances\nof the Focal Method as input to the model, when generating\nthe assert statements. In particular, we select our best model\nobtained from RQ1 and RQ2 and compare against an equivalent\nmodel ( i.e., same preprocessing steps) but ﬁnetuned on a\nparallel corpus that does not contain the focal method, trying to\nlearn the probability P(ai|tm′\ni). Speciﬁcally, this can be seen\nas an auto-completion task, where the source is the partially\nwritten test method tm′\ni and the expected target output is the\nassert ai. We compare the performances of the models with\nor without the focal method in terms of top-k accuracy on the\ntest set.\nRQ4: What is the quality of the generated asserts?\nIn the last research question we investigate the quality of\nthe assert statements generated by the model. We manually\nanalyze instances of correct predictions as well as inspecting\nthose that do not match with the target assert statement. We\nreport qualitative examples and discussion.\nRQ5: Can our approach be used to improve automati-\ncally generated test cases?\nThe goal of this research question is to provide a preliminary\ninvestigation on the potential beneﬁts of using our approach\nto improve automated test case generation tools, such as\nTABLE I\nDATASETS USED FOR ENGLISH AND SOURCE CODE PRETRAINING ,\nAND ASSERT FINETUNING\nSet English Source Code Asserts\nTrain 160GB 25GB 150,523\nValid - 600MB 18,816\nTest - - 18,815\nTotal 160GB 25GB 188,154\nEvoSuite. Speciﬁcally, we aim at enhancing test cases generated\nby EvoSuite by inserting additional asserts generated by our\napproach. We evaluate the potential beneﬁts in terms of test\ncoverage boost and qualitative discuss the additional asserts.\nFor this investigation we select a small but reproducible\ntestbed using defects4j. We rely on defects4j since it provides\na reliable infrastructure to generate, compile, execute, and\nevaluate test cases. Speciﬁcally, we select Lang-1-f, which\nrepresents the ﬁxed version of the ﬁrst bug in the defects4j\ncollection belonging to the project Apache Commons Lang.\nTo generate test cases with EvoSuite, we use the de-\nfects4j built-in command gen_tests.pl -g evosuite\n-p Lang -v 1f. This command invokes EvoSuite test gener-\nation on the ﬁrst ﬁxed revision of Lang, which will generate test\ncases for the class affected by the bug ( i.e., NumberUtils).\nWe let EvoSuite generate test cases for 500 seconds ( ∼8\nminutes) and compute the test coverage using defects4j which\nrelies on Cobertura, singularly for each test case.\nNext, we select the 18 unique focal methods of the class,\nwithout considering overloaded copies of the methods, and the\ncorresponding test cases generated by EvoSuite. We select a\nsingle best test case for each of the focal methods. Once we\nhave the mapped test case pair, we generate additional assert\nstatements for each of the pair using our approach. Speciﬁcally,\nfor each focal method we generate the top-10 predictions and\nselect a single assert from them, which we insert as the last\nstatement within the EvoSuite test case. Finally, we execute the\nnewly augmented test cases and recompute the test coverage\nfor each of them.\nIV. E XPERIMENTAL RESULTS\nIn this section we report and discuss the results of our\nempirical study.\nRQ1: How does our approach compare with ATLAS?\nFigure 3 reports the top-k accuracy for our four variations\nof the model as well as for ATLAS. The x-axis represents the\nk value, ranging from 1 to 50, while the y-axis indicates the\npercentage of correct asserts in the test set. For ATLAS we\nreport the results as they appear in the original work [ 5], by\nconsidering the best model ( i.e., Abstract Model). It is worth\nnoting that the ATLAS line is shaped as a step-function because\nthe authors reports only the value of k with 5 step increment\n(e.g., 1,5,10,... ), while we computed the top-k accuracy at\neach integer value k from 1 to 50, hence the smoother curve.\n0 10 20 30 40 50\nTop-K\n30\n40\n50\n60\n70\n80% Correct Asserts BART_English+Code\nBART_English\nBART_Code\nBART_Scratch\nATLAS\nFig. 3. Top-K Accuracy Results.\nComparing our four BART model variants against ATLAS\nThe results show that our models outperform ATLAS at\nany k value. In particular, BART_English+Code can correctly\npredict the target assert statement (originally written by the\ndeveloper) in 62% of the cases in just the ﬁrst attempt. This\nrepresents an 80% relative improvement over the top-1 ATLAS\naccuracy of 27%.\nThe impressive results on the top-1 accuracy are particularly\nimportant in terms of usability and applicability of this\napproach beyond research, in actual development environments.\nPractically, developers would obtain accurate and relevant\nassert statements in one or very few suggestions, without the\nneed of going through a long list while discarding incorrect\nrecommendations.\nSummary for RQ1. Our approach outperforms ATLAS with\na relative improvement of 80% on top-1 accuracy.\nRQ2: What is the effect of the pretraining process on\nthe assert generation task?\nExtrinsic Metrics: Figure 3 shows a massive gap between the\nperformance of the model whiteout pretraining ( BART_Scratch)\ncompared to the models with English ( BART_English), source\ncode (BART_Code), and both ( BART_English+Code) pretrain-\ning. Speciﬁcally, the performance gap between BART_Scratch\nand the models with single pretraining phase ( BART_Code\nor BART_English) is 22-25%, while the gap between\nBART_English and BART_English+Code is 1.54-2.25%, in\nfavor of the model which was pretrained on both English and\nsource code.\nThese results highlight the importance of pretraining on the\nperformance of downstream tasks. It is particularly striking the\neffect of pretraining on natural language English text over a\ndownstream task involving source code. This result emphasizes\nthe signiﬁcance of having a model which understands the\nsemantics of variable and method names in the code.\nWhile additional pretraining on source code appears to have\nTABLE II\nACCURATE PREDICTIONS\nTop-K ATLAS BART_Scratch BART_Code BART_English BART_English+Code\n1 4968 (26.40%) 7106 (37.77%) 11183 (59.44%) 11430 (60.75%) 11754 (62.47%)5 7857 (41.76%) 9522 (50.61%) 13996 (74.39%) 14244 (75.71%) 14665 (77.94%)10 8812 (46.83%) 10055 (53.44%) 14576 (77.47%) 14839 (78.87%) 15200 (80.79%)15 9291 (49.38%) 10304 (54.76%) 14811 (78.72%) 15096 (80.23%) 15423 (81.97%)20 9554 (50.78%) 10461 (55.60%) 14982 (79.63%) 15238 (80.99%) 15541 (82.60%)25 9764 (51.89%) 10582 (56.24%) 15063 (80.06%) 15339 (81.53%) 15639 (83.12%)30 9918 (52.71%) 10693 (56.83%) 15140 (80.47%) 15407 (81.89%) 15716 (83.53%)35 10068 (53.51%) 10763 (57.20%) 15207 (80.82%) 15478 (82.26%) 15786 (83.90%)40 10179 (54.10%) 10833 (57.58%) 15274 (81.18%) 15530 (82.54%) 15849 (84.24%)45 10247 (54.46%) 10903 (57.95%) 15347 (81.57%) 15586 (82.84%) 15912 (84.57%)50 10327 (54.89%) 10979 (58.35%) 15392 (81.81%) 15615 (82.99%) 15944 (84.74%)\na limited impact on performances, compared to pretraining only\non English, it still delivers consistent improvements, which\ncould potentially be higher on bigger test sets.\nIntrinsic Metrics: In terms of intrinsic metrics, Figure 4\nshows the cross-entropy loss on the validation set during\ntraining for the four model variations. Similarly to what\nobserved with the extrinsic metric, we note a substantial\ngap between the model without pretraining ( BART_Scratch)\ncompared to the two models with English ( BART_English),\nsource code ( BART_Code) and both ( BART_English+Code)\npretraining. Comparing the English only and the English+Code\nmodels, the additional pretraining on source code has three\nevident effects: (i) lower initial loss (0.21 vs 0.31); (ii) lower\nbest loss (0.13 vs 0.15); (iii) faster convergence (∼2500 training\nsteps earlier).\nTable III reports the intrinsic metrics computed for the four\nmodel variations. Speciﬁcally, BART_English+Code obtains\nthe best BLEU4 and validation loss. Regarding the syntactic\ncorrectness, the model pretrained on both English and source\ncode obtains the best value for the top single prediction,\nhowever when computing the correctness considering the top\n25, and 50 generated asserts for each input in the test set,\nthe model pretrained exclusively on source code achieves the\nhighest correctness score. This result is somewhat predictable,\nsince BART_Code has been pretrained and ﬁnetuned exclusively\non source code, thus it should have the most consistent results\nin terms of syntax.\nOverall, we observe a signiﬁcant positive effect of pretraining\non English and source code for both extrinsic and intrinsic\nmetrics. While additional pretraining on source code appears\nto have a smaller impact than English pretraining alone, it is\nworth noting that we observe consistent improvements across\nall the analyzed metrics, corroborating the beneﬁcial effect of\nthe source code pretraining. Additionally, the small gap could\nbe due to the nature of the downstream task, where the output\nis a single-line assert statement, which could closely resemble\na natural language sentence.\nSummary for RQ 2. Pretraining has a signiﬁcant positive\neffect on the downstream performances. Pretrainig on English\ntext boosts the performances of 23-25%, while further\npretraining on source code can yield additional ∼2% im-\nprovement.\n2500 5000 7500 10000 12500 15000 17500 20000\nTraining Step\n100\nValidation Loss (log scale)\nBART_Scratch\nBART_English\nBART_Code\nBART_English+Code\nFig. 4. Validation Loss obtained during Assert ﬁnetuning for our four BART\nmodel variants\nTABLE III\nINTRINSIC EVALUATION METRICS\nMetric BART_Scratch BART_Code BART_English BART_English+Code\nBLEU4 72.40 84.24 84.13 85.35\nValidation Loss 0.67 0.17 0.15 0.13\nSyntax Top-1 99.54% 99.56% 99.57% 99.58%\nSyntax Top-25 92.97% 94.05% 93.01% 93.96%\nSyntax Top-50 85.05% 88.12% 87.07% 87.26%\nRQ3: What is the effect of the Focal Method on the\nperformances of the model?\nTo answer this research question, we compared the model\nthat achieves the best performances in RQ 1 and RQ 2 –\nBART_English+Code – against a similar model ( i.e., same\npretraining phases) but with different ﬁnetuning. Speciﬁcally,\nwe selected the same model checkpoint after the source code\npretraining, and ﬁntuned the model on a modiﬁed dataset\nwithout the Focal Method as input. Figure 5 shows the top-k\naccuracy of the models with (solid line) and without (dashed\nline) the Focal Method. The results show that the model which\ntakes as input the Focal Method is more accurate in generating\nassert statements in ∼10% of the cases. That is, there are\ncertain assert statement that are not covered by the model w/o\nFocal Method, even when 50 different predictions are generated.\nThis result highlight the essential information provided by the\nFocal Method to inform the model on generating speciﬁc assert\nstatements.\nSummary for RQ 3. The Focal Method provides essential\ninformation which allows the model to generate ∼10%\nmore accurate asserts compared to a generic auto-completion\nmodel.\nRQ4: What is the quality of the generated asserts? To\nanswer this research question we analyze and discuss examples\nof generated assert statements. Figure 6 provides examples of\n0 10 20 30 40 50\nTop-K\n55\n60\n65\n70\n75\n80\n85% Correct Asserts\nw/ Focal Method\nw/o Focal Method\nFig. 5. Top-K Accuracy - Comparing our model trained with or without the\nFocal Method as input\ncommon, complex, and equivalent assert statements generated\nby our best model BART_English+Code. The list of common\nasserts comprises statements that are correctly predicted by the\nmode (i.e., match the original assert) which are often found\nin test cases in different contexts. For example, these asserts\nusually check that the result is equal to the expected\nvalue, or that a given list contains an element that was\npreviously added. These types of asserts are usually predicted\nin the very ﬁrst attempts of the model. While these represent\nsimple assert statements, they still require the model to detect\nthe variables used within the test/focal method and their\nrelationship.\nThe list of complex assert statements showcase some of the\nchallenging asserts correctly predicted by the model. These\nasserts involve multiple method calls, parameters, attributes,\nand variables that are less common.\nThe list of equivalent assert statements show generated\nasserts that do not exactly match with the target assert\n(i.e., these are not counted as correct asserts in the top-k\naccuracy), but they are equivalent to the developer’s assert. For\nexample, the model suggests to get the class literal directly\nwith AbstractService.class, while the developer uses\nthe method getClass() which, in turn, uses the same class\nliteral. In another instance, the developer checks that status\n== 0 is true, while the model suggests an equivalent check\nwith assertEquals(0, status). Similarly, the model\nsuggests to use assertSame on two objects, rather than the\n== equivalence. Note that for all these cases, the model was\neventually able to predict the correct assert ( i.e., perfect match)\nin the subsequent attempts.\nFinally, Figure 7 reports two complete examples with source\nand target, correctly predicted by the model. In the ﬁrst example,\nthe generated assert checks that the event object created\nwith the eventFactory is of the correct class instance. In\nthe second example, the model generates a complex assert\nstatement involving numerical literals and variables previously\nused to set-up the testing environment. Additionally, the\nCommon Assert Statements\nassertEquals(expected, result)\nassertSame(rows, actual)\nassertNotNull(client)\nassertTrue(list.contains(element))\nassertArrayEquals(expected, values)\nassertEquals(1, result.getSize())\nComplex Assert Statements\nassertEquals(0, zero.getPartialDerivative(n), epsilon [ n ])\nassertThat(emptySession.getEnd(), CoreMatchers.equalTo(date))\nassertEquals(container.getSoundEffects().read(0), Sound.ENTITY_CAT_HISS)\nEquivalent Assert Statements\ntarget: assertNull(sm.get(serviceStub.getClass()))\npredicted: assertNull(sm.get(AbstractService.class))\ntarget: assertTrue( status == 0)\npredicted: assertEquals(0, status)\ntarget: assertEquals(user.getSNetVisibility(), visibility)\npredicted: assertEquals(visibility, user.getSNetVisibility())\ntarget: assertTrue( ps1 == ps2)\npredicted: assertSame(ps1, ps2)\nFig. 6. Examples of generated asserts\nCommon assert statements found in different contexts\nComplex assert statement involving multiple method calls and parameters\nEquivalent assert statements to the original target statement\nexample in Figure 2 described in Sec. II-D was also correctly\npredicted by the model in the very ﬁrst attempt.\nThese results highlight the need for additional metrics beyond\nsimple accuracy. In particular, metrics that can recognize and\ndiscern cases where the generated assert statement is different\nyet equivalent to the one created by human developers, as well\nas non-equivalent asserts that are also correct in that context.\nAdditionally, there could be many locations in the code where\nthe developers did not introduce assert statements but the\nmodel could suggest reasonable ones, which are currently not\nuncovered in the quantitative metrics. The main goal of this\nresearch question was precisely to ﬁll this gap with a qualitative\nand manual analysis.\nSummary for RQ4. Our models can generate common assert\nstatements as well as complex ones involving method calls,\nparameters, and unusual variables. In several cases, the model\ngenerates equivalent assert statements to the developer’s\nassert.\nRQ5: Can our approach be used to improve automati-\ncally generated test cases? Table IV reports the absolute (and\npercentage) line and condition coverage at class-level, for each\nof the 18 public methods considered in the experiment. The\ntable shows the results for the original EvoSuite test cases, those\naugmented by our model, as well as the delta improvement in\nthe last column.\nFor 13 out of 18 methods, our approach generated asserts that\nimproved the line and/or condition coverage between 1-3 more\nlines and 1-4 additional condition coverage. For 4 methods our\napproach generated correct asserts which did not improve the\ncoverage, while for one method ( i.e., createBigDecimal)\nour approach did not generate any correct assert within the\nSource: {tm′\ni + fmi}\npublic void createBeginNwhinInvocation() {\nEvent event = eventFactory.createBeginNwhinInvocation();\n<AssertPlaceHolder>;\n}\npublic BeginNwhinInvocationEvent createBeginNwhinInvocation() {\nreturn new BeginNwhinInvocationEvent();\n}\nTarget: {ai}\nAssert.assertTrue( event instanceof BeginNwhinInvocationEvent)\nSource: {tm′\ni + fmi}\npublic void simpleInsertTest() {\nLRU lru = LRU(5, true);\nfor(int i = 0; i < 5; i ++) {\naddAndExpectNoEviction(lru,(100 + i));\n}\nfor(int i = 5; i < 10; i ++) {\naddAndExpectEviction(lru,(100 + i),(( 100 + i) - 5));\n}\nfor(int i = 5; i < 10; i ++) {\n<AssertPlaceHolder>;\n}\n}\npublic boolean exists( long) { return m_lruMap.containsKey(id); }\nTarget: {ai}\nAssert.assertTrue(lru.exists( 100 + i))\nFig. 7. Two Complete Examples of perfect predictions\ntop-10 predictions.\nFigure 8 shows all the generated asserts which have been\nused to augment the EvoSuite test cases, in the same order as the\nmethods reported in table IV. We can notice that the ﬁrst three\nasserts invoke the focal method with an actual numerical value,\nwhich results in additional test coverage, since the original\nEvoSuite test case tested the same focal methods with a null or\nempty string, resulting in the execution of a different branch.\nThe ﬁfth assert, related to the focal method toDouble invokes\nthe focal method using a non-numerical string \"foo\", and\ncovering three additional lines and one more condition in the\nfocal method, w.r.t. the EvoSuite test case.\nLet us now focus on the four assert statements that did not\nimprove the coverage, corresponding to the focal methods\nmin and max, shown as the sixth to the third from the\nbottom of ﬁgure 8. Three of these asserts simply perform\nadditional checks on the return variables used by EvoSuite,\nnamely long0, float0, byte0. These asserts do not\ninvoke the focal method, thus not resulting in additional\ncoverage, but instead focus on testing additional properties\nof the retun values. Finally, the assert assertEquals(4,\nNumberUtils.min(4, 5, 7)) correctly invokes the fo-\ncal method and asserts the correct behavior, but executes lines\nand branches already tested by the original test case (with\ndifferent values).\nOverall, these results show that our approach can be helpful\nin augmenting existing or automatically generated test cases\nwith additional accurate assert statements. In most of the cases\nreported in our experiment, we found the asserts to slightly\nimprove the test coverage.\nTABLE IV\nTEST COVERAGE ANALYSIS\nAUGMENTING EVOSUITE ’S TEST CASES WITH ASSERTS GENERATED BY OUR APPROACH\nFocal Method EvoSuite EvoSuite + Our Approach Delta Improvement\nLines Conditions Lines Conditions Lines Conditions\ntoInt(String) 21 (5.6%) 1 (0.3%) 22 (5.9%) 2 (0.6%) +1 +1\ntoLong(String, long) 20 (5.3%) 1 (0.3%) 21 (5.6%) 2 (0.6%) +1 +1\ntoFloat(String, float) 20 (5.3%) 1 (0.3%) 21 (5.6%) 2 (0.6%) +1 +1\ntoDouble(String, double) 20 (5.3%) 1 (0.3%) 23 (6.1%) 2 (0.6%) +3 +1\ntoByte(String, byte) 20 (5.3%) 1 (0.3%) 21 (5.6%) 2 (0.6%) +1 +1\ntoShort(String, short) 20 (5.3%) 1 (0.3%) 21 (5.6%) 2 (0.6%) +1 +1\ncreateFloat(String) 20 (5.3%) 1 (0.3%) 21 (5.6%) 2 (0.6%) +1 +1\ncreateDouble(String) 20 (5.3%) 1 (0.3%) 21 (5.6%) 2 (0.6%) +1 +1\ncreateInteger(String) 20 (5.3%) 1 (0.3%) 21 (5.6%) 2 (0.6%) +1 +1\ncreateLong(String) 20 (5.3%) 1 (0.3%) 21 (5.6%) 2 (0.6%) +1 +1\ncreateBigInteger(String) 28 (7.5%) 8 (2.4%) 28 (7.5%) 9 (2.7%) - +1\ncreateBigDecimal(String) 22 (5.9%) 3 (0.9%) - - - -\nmin(long[]) 27 (7.2%) 6 (1.8%) 27 (7.2%) 6 (1.8%) - -\nmin(int, int, int) 22 (5.9%) 2 (0.6%) 22 (5.9%) 2 (0.6%) - -\nmax(float[]) 28 (7.5%) 7 (2.1%) 28 (7.5%) 7 (2.1%) - -\nmax(byte, byte, byte) 23 (6.1%) 2 (0.6%) 23 (6.1%) 2 (0.6%) - -\nisDigits(String) 20 (5.3%) 1 (0.3%) 23 (6.1%) 5 (1.5%) +3 +4\nisNumber(String) 44 (11.7%) 29 (8.6%) 45 (12.0%) 31 (9.2%) +1 +2\nSummary for RQ 5. Our approach can be used to augment\nexisting test cases, such as those generated by EvoSuite, with\nadditional assert statements. Our experiments show that these\nasserts can lead to improved test coverage.\nV. D ISCUSSION & FUTURE WORK\nOur experimental analysis showed promising results of our\napproach in generating accurate assert statements for unit test\ncases. For our future work, we envision two possible scenarios\nwhere we can deploy our model with the goal of improving\nautomation in software testing activities.\nA. Supporting Developers in writing Test Cases\nOur approach could be used to support developers in writing\ntest cases more efﬁciently, by suggesting assert statements while\ndeﬁning the test case. In this scenario, we plan to implement our\napproach as plugin for an IDE, which is then used by developers\nwhile writing code as a code completion tool. Our approach\ncould work side-by-side existing code completion approaches,\nsuch as Pythia [ 15]. The results of RQ 3 clearly shows that\nour approach is more accurate than standard code completion,\nleading us to suggest a hybrid approach. In this hybrid approach,\na standard code completion tool would perform inference on\nour model when the developer is writing test cases.\nB. Improving Automated Test Case Generation Tools\nThe results of RQ 5 show that our approach can be used to\naugment test cases generated by automated test case generation\ntools, such as EvoSuite, Randoop, and Agitar. In this scenario,\nour approach could be integrated within an automated test case\ngeneration tool, or used as an external tool which augment and\nrevises assert statements in the newly generated test cases.\nGenerated Assert\nassertEquals(5, NumberUtils.toInt(\"5\"))\nassertEquals(1, NumberUtils.toLong(\"1\", 1))\nassertEquals(6, NumberUtils.toFloat(\"6\", 6), 0);\nassertNotNull(NumberUtils.toDouble(\"foo\", 1.0));\nassertEquals(1, NumberUtils.toByte(\"1\",(( byte)(1))));\nassertEquals(15, NumberUtils.toShort(\"15\",(( short )(15))));\nassertNotNull(NumberUtils.createFloat(\"1\"))\nassertNotNull(NumberUtils.createDouble(\"1\"));\nassertNotNull(NumberUtils.createInteger(\"1\"));\nassertNotNull(NumberUtils.createLong(\"1\"));\nassertEquals(BigInteger.valueOf(1), NumberUtils.createBigInteger(\"1\"));\n-\nassertNotNull(long0);\nassertEquals(4, NumberUtils.min(4, 5, 7));\nassertTrue(( float0 == 0.0F));\nassertTrue(( byte0 == 5));\nassertTrue(NumberUtils.isDigits(\"1\"));\nassertTrue(NumberUtils.isNumber(\"1\"))\nFig. 8. Assert statements generated by our approach for Lang-1-f\nThese asserts are used to augment existing EvoSuite’s test cases leading to\ncoverage improvement\nVI. T HREATS TO VALIDITY\nThreats to construct validity concern the relationship be-\ntween theory and observation and are mainly related to the\nmeasurements we performed. In this context, data leakage\ncould represent a threat to the validity of our study. Data\nleakage refers to the unintentional and accidental sharing of\ndata between the training and test sets. In our case, the threat\narises during the pretraining stage on large amount of source\ncode, where the model may have observed similar code to\nwhat found in the ﬁnetuning test set. We mitigated this threat\nby constructing the ﬁnetuning process differently from the\npretraining, where the code is organized in a dissimilar fashion.\nSpeciﬁcally, during the pretraining the test method did not\ncontain the placeholder, and was not adjacent to the focal\nmethod. We empirically validated the mitigation of the threat\nby evaluating the pretrained model (without ﬁnetuning) on\nthe test set, in order to observe its performances. The results\nshow that the model was not able to generate correct assert\nstatements, thus conﬁrming the our hypothesis. It is also worth\nto note that data leakage is avoided within the ﬁnetuning dataset\n(i.e., training, validation, test sets)\nInternal validity threats concern factors internal to our\nstudy that could inﬂuence our results. The performance of\nour approach depends on the hyperparameter conﬁguration\nand pretraining process. We did not perform hyperparameter\nsearch since these large models require substantial training time,\nhowever, we reuse conﬁgurations suggested in the literature.\nWe experiment with different pretraining stages and report the\nresults of our experiments.\nThreats to external validityconcern the generalization of our\nﬁndings. In our context, the threat arises when comparing our\nBART Transformer model (with 400M trainable parameters)\nagainst the RNN-based model (with 4M trainable parameters)\nhaving different capacity and number of parameters. While we\nnote that comparing models with the same number of param-\neters could yield different results, the authors of ATLAS [ 5]\ndid not observe improvements when increasing the number of\nlayers and units of the Encoder-Decoder architecture. Moreover,\nwe rely on the existing literature comparing Transformer and\nRNN architectures.\nVII. R ELATED WORK\nOur work is related to several existing approaches in the\narea of automated software testing. In particular, there is a\nclass of approaches that aims at generating tests methods and\nsynthesizing assert statements, such as Evosuite [ 1], Randoop\n[2], and Agitar [ 16]. Among these, Evosuite is one of the most\npopular tools for test generation in Java. It relies on mutation\ntesting in order to generate appropriate assert statements.\nSpeciﬁcally, it ﬁrst introduce mutants within the method under\ntest, then it attempts to generate asserts with the goal of killing\nthe aforementioned mutants. During this process, Evosuite\noptimizes towards maximizing the number of killed mutants\nwhile generating as few asserts as possible. Randoop generates\nassert statements by relying on user-speciﬁed contracts. These\nstatements are then reﬁned using random testing and analyzing\nexecution traces of the statement it creates.\nThe major difference between these works and our approach\nis the learning component. Speciﬁcally, the aforementioned\nworks rely on handcrafted rules or heuristics to generate assert\nstatements, for example via predeﬁned mutations. Instead,\nwe aim to learn from developers’ code what are the assert\nstatements that are more effective for the particular context\n(i.e., test case and focal method).\nAdditionally, recent works have shed light on the importance\nof generating accurate and complex assert statements to detect\nreal faults in the system [ 3], [4]. In particular, Almasi et al.[3]\nshows that, while Evosuite and Randoop were able to uncover\nseveral faults in real programs, nearly half of the undetected\nfaults could have been detected with a more appropriate assert\nstatement [3], [5].\nThese limitations motivated the work from Watson et al.[5],\nwhere the authors proposed an RNN-based approach ATLAS\nwhich aims at generating meaningful assert statements by\nlearning from developers’ code. Inspired by this work, we\nimprove upon it in several substantial ways. First, we employ\na different and more advanced deep learning architecture based\non transformer models. Second, differently from ATLAS, we\ntake advantage of English and source code semi-supervised\npretraining to signiﬁcantly boost the performances of the\nmodels on the assert generation task. Lastly, we investigate\nqualitative cases and intrinsic metrics as well as the effect of\nthe focal method, which provides additional beneﬁcial context\nto the model. These contributions culminated into an approach\nthat signiﬁcantly outperforms the previous work [ 5], with an\n80% relative improvement in top-1 accuracy.\nOur work is related to a broad set of literature on transfer\nlearning [17], unsupervised language model pretraining [ 18],\n[6], and denoising pretraining [ 7], [19], [9]. In this paper, we\nextend these ideas to source code as a language, combining\nEnglish and source code pretraining modes, ﬁne-tuning on\na downstream translation task from the automated software\nengineering domain.\nVIII. C ONCLUSION\nIn this paper we presented an approach for generating\naccurate assert statements for unit test cases. The core of our\napproach is based on a state state-of-the-art transformer model\nwhich has been pretrained, in a semi-supervised fashion, on\nboth English and source code corpora. This pretraning process\nallows to learn the semantics of the natural language and its\nwords as well as the syntax of the source code. The model\nwas then ﬁnetuned on the assert generation task, which we\nrepresent as a translation task, where the input is the focal\nmethod along with the partially generated test case, and the\noutput is the desired assert statement.\nThe resulting model is able to generate accurate assert\nstatements, with a 62% top-1 accuracy, matching the exact\nassert statement originally wrote by the developer. This\nrepresents an 80% relative improvement over the previous\nRNN-based approach [5].\nIn our empirical evaluation, we experimented with different\npretraining levels, showing the beneﬁcial impact of pretraining\non both English and source code in terms of extrinsic and\nintrinsic metrics. We qualitatively analyzed the assert statements\npredicted by our model, and identiﬁed both common and\ncomplex asserts. Interestingly, we found many cases in which\nthe predicted assert statement did not syntactically match the\noriginal statement, yet was semantically equivalent and correct.\nFinally, we empirically demonstrate how our proposed approach\ncan be used to augment existing test cases, such as those\ngenerated by EvoSuite, with additional assert statements that\nlead to test coverage improvements.\nWe believe that these results are particularly important in\nterms of the usability and applicability of this approach beyond\nresearch, in actual development environments. Practically,\ndevelopers would obtain accurate and relevant assert statements\nin one or very few suggestions, allowing them to write complete\nand robust test cases.\nREFERENCES\n[1] G. Fraser and A. Arcuri, “Evosuite: automatic test suite generation for\nobject-oriented software,” in Proceedings of the 19th ACM SIGSOFT\nsymposium and the 13th European conference on Foundations of software\nengineering, 2011, pp. 416–419.\n[2] C. Pacheco and M. D. Ernst, “Randoop: feedback-directed random testing\nfor java,” inCompanion to the 22nd ACM SIGPLAN conference on Object-\noriented programming systems and applications companion, 2007, pp.\n815–816.\n[3] M. M. Almasi, H. Hemmati, G. Fraser, A. Arcuri, and J. Benefelds,\n“An industrial evaluation of unit test generation: Finding real faults in a\nﬁnancial application,” in 2017 IEEE/ACM 39th International Conference\non Software Engineering: Software Engineering in Practice Track (ICSE-\nSEIP). IEEE, 2017, pp. 263–272.\n[4] S. Shamshiri, “Automated unit test generation for evolving software,” in\nProceedings of the 2015 10th Joint Meeting on Foundations of Software\nEngineering, 2015, pp. 1038–1041.\n[5] C. Watson, M. Tufano, K. Moran, G. Bavota, and D. Poshyvanyk, “On\nlearning meaningful assert statements for unit test cases,” arXiv preprint\narXiv:2002.05800, 2020.\n[6] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever,\n“Language models are unsupervised multitask learners,” 2019.\n[7] J. Devlin, M. Chang, K. Lee, and K. Toutanova, “BERT: pre-training\nof deep bidirectional transformers for language understanding,” CoRR,\nvol. abs/1810.04805, 2018. [Online]. Available: http://arxiv.org/abs/1810.\n04805\n[8] Z. Yang, Z. Dai, Y . Yang, J. G. Carbonell, R. Salakhutdinov, and\nQ. V . Le, “Xlnet: Generalized autoregressive pretraining for language\nunderstanding,” CoRR, vol. abs/1906.08237, 2019. [Online]. Available:\nhttp://arxiv.org/abs/1906.08237\n[9] M. Lewis, Y . Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy,\nV . Stoyanov, and L. Zettlemoyer, “Bart: Denoising sequence-to-sequence\npre-training for natural language generation, translation, and comprehen-\nsion,” 2019.\n[10] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones,\nA. N. Gomez, L. Kaiser, and I. Polosukhin, “Attention is all\nyou need,” CoRR, vol. abs/1706.03762, 2017. [Online]. Available:\nhttp://arxiv.org/abs/1706.03762\n[11] Y . Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis,\nL. Zettlemoyer, and V . Stoyanov, “Roberta: A robustly optimized bert\npretraining approach,” arXiv preprint arXiv:1907.11692, 2019.\n[12] H. Husain, H.-H. Wu, T. Gazit, M. Allamanis, and M. Brockschmidt,\n“Codesearchnet challenge: Evaluating the state of semantic code search,”\narXiv preprint arXiv:1909.09436, 2019.\n[13] A. Qusef, R. Oliveto, and A. De Lucia, “Recovering traceability links\nbetween unit tests and classes under test: An improved method,” in 2010\nIEEE International Conference on Software Maintenance. IEEE, 2010,\npp. 1–10.\n[14] O. Press and L. Wolf, “Using the output embedding to improve\nlanguage models,” CoRR, vol. abs/1608.05859, 2016. [Online]. Available:\nhttp://arxiv.org/abs/1608.05859\n[15] A. Svyatkovskiy, Y . Zhao, S. Fu, and N. Sundaresan, “Pythia: ai-assisted\ncode completion system,” in Proceedings of the 25th ACM SIGKDD\nInternational Conference on Knowledge Discovery & Data Mining, 2019,\npp. 2727–2735.\n[16] Agitar, “Utilizing Fast Testing to Transform Java Development into an\nAgile, Quick Release, Low Risk Process,” http://www.agitar.com/, 2020.\n[17] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y . Zhou,\nW. Li, and P. J. Liu, “Exploring the limits of transfer learning with a\nuniﬁed text-to-text transformer,” 2019.\n[18] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever,\n“Language models are unsupervised multitask learners,” 2018. [Online].\nAvailable: https://d4mucfpksywv.cloudfront.net/better-language-models/\nlanguage-models.pdf\n[19] Y . Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis,\nL. Zettlemoyer, and V . Stoyanov, “Roberta: A robustly optimized BERT\npretraining approach,” CoRR, vol. abs/1907.11692, 2019. [Online].\nAvailable: http://arxiv.org/abs/1907.11692",
  "topic": "Unit testing",
  "concepts": [
    {
      "name": "Unit testing",
      "score": 0.8600298166275024
    },
    {
      "name": "Computer science",
      "score": 0.7495180368423462
    },
    {
      "name": "Integration testing",
      "score": 0.6464074850082397
    },
    {
      "name": "Software testing",
      "score": 0.5992865562438965
    },
    {
      "name": "Software",
      "score": 0.4924827516078949
    },
    {
      "name": "Software engineering",
      "score": 0.4883567988872528
    },
    {
      "name": "Software performance testing",
      "score": 0.48234671354293823
    },
    {
      "name": "White-box testing",
      "score": 0.4756892919540405
    },
    {
      "name": "Regression testing",
      "score": 0.45844176411628723
    },
    {
      "name": "Test strategy",
      "score": 0.45588716864585876
    },
    {
      "name": "System testing",
      "score": 0.4440743029117584
    },
    {
      "name": "Keyword-driven testing",
      "score": 0.44110727310180664
    },
    {
      "name": "Manual testing",
      "score": 0.4348491430282593
    },
    {
      "name": "Transformer",
      "score": 0.4205891489982605
    },
    {
      "name": "Task (project management)",
      "score": 0.4131145477294922
    },
    {
      "name": "Software construction",
      "score": 0.3173787593841553
    },
    {
      "name": "Software development",
      "score": 0.24468666315078735
    },
    {
      "name": "Programming language",
      "score": 0.22107762098312378
    },
    {
      "name": "Engineering",
      "score": 0.1698342263698578
    },
    {
      "name": "Systems engineering",
      "score": 0.16578930616378784
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ]
}