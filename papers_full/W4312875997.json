{
  "title": "Depression Classification From Tweets Using Small Deep Transfer Learning Language Models",
  "url": "https://openalex.org/W4312875997",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2022813117",
      "name": "Muhammad Rizwan",
      "affiliations": [
        "Islamia University of Bahawalpur"
      ]
    },
    {
      "id": "https://openalex.org/A3124981006",
      "name": "Muhammad Faheem Mushtaq",
      "affiliations": [
        "Islamia University of Bahawalpur"
      ]
    },
    {
      "id": "https://openalex.org/A2752687206",
      "name": "Urooj Akram",
      "affiliations": [
        "Islamia University of Bahawalpur"
      ]
    },
    {
      "id": "https://openalex.org/A1974751255",
      "name": "Arif Mehmood",
      "affiliations": [
        "Islamia University of Bahawalpur"
      ]
    },
    {
      "id": "https://openalex.org/A2155509093",
      "name": "Imran Ashraf",
      "affiliations": [
        "Yeungnam University"
      ]
    },
    {
      "id": "https://openalex.org/A2043387338",
      "name": "Benjamin Sahelices",
      "affiliations": [
        "Universidad de Valladolid"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4210455994",
    "https://openalex.org/W3167856512",
    "https://openalex.org/W3039554467",
    "https://openalex.org/W4224326655",
    "https://openalex.org/W3128585438",
    "https://openalex.org/W3033913896",
    "https://openalex.org/W3211095765",
    "https://openalex.org/W4220967417",
    "https://openalex.org/W4283812015",
    "https://openalex.org/W3120217483",
    "https://openalex.org/W6791330069",
    "https://openalex.org/W3114498488",
    "https://openalex.org/W3131775586",
    "https://openalex.org/W3205067936",
    "https://openalex.org/W6768851824",
    "https://openalex.org/W3174510164",
    "https://openalex.org/W3098576111",
    "https://openalex.org/W6768086466",
    "https://openalex.org/W2970454332",
    "https://openalex.org/W6774738212",
    "https://openalex.org/W3013908145",
    "https://openalex.org/W6797854001",
    "https://openalex.org/W3158216587",
    "https://openalex.org/W2211796614",
    "https://openalex.org/W6768021236",
    "https://openalex.org/W6796091637",
    "https://openalex.org/W3087974299",
    "https://openalex.org/W3167958315",
    "https://openalex.org/W3108841905",
    "https://openalex.org/W3117866035",
    "https://openalex.org/W4210254834",
    "https://openalex.org/W3036832155",
    "https://openalex.org/W2987972786",
    "https://openalex.org/W3136657289",
    "https://openalex.org/W3023618320",
    "https://openalex.org/W4200046541",
    "https://openalex.org/W4220956908",
    "https://openalex.org/W2946396904",
    "https://openalex.org/W1537829113",
    "https://openalex.org/W2413533038",
    "https://openalex.org/W2802043748",
    "https://openalex.org/W6726540210",
    "https://openalex.org/W3032158497",
    "https://openalex.org/W2927148761",
    "https://openalex.org/W2068262947",
    "https://openalex.org/W3129150560",
    "https://openalex.org/W2786026536",
    "https://openalex.org/W2613843855",
    "https://openalex.org/W2528658358",
    "https://openalex.org/W6733198759",
    "https://openalex.org/W2585682391",
    "https://openalex.org/W2996428491",
    "https://openalex.org/W3105966348",
    "https://openalex.org/W3081141044",
    "https://openalex.org/W3169008558",
    "https://openalex.org/W3134304069",
    "https://openalex.org/W3006963874",
    "https://openalex.org/W2978017171",
    "https://openalex.org/W2520730796",
    "https://openalex.org/W3211787299"
  ],
  "abstract": "Depression detection from social media texts such as Tweets or Facebook comments could be very beneficial as early detection of depression may even avoid extreme consequences of long-term depression i.e. suicide. In this study, depression intensity classification is performed using a labeled Twitter dataset. Further, this study makes a detailed performance evaluation of four transformer-based pre-trained small language models, particularly those having less than 15 million tunable parameters i.e. Electra Small Generator (ESG), Electra Small Discriminator (ESD), XtremeDistil-L6 (XDL) and Albert Base V2 (ABV) for classification of depression intensity using Tweets. The models are fine-tuned to get the best performance by applying different hyperparameters. The models are tested by classification of depression intensity of labeled tweets for three label classes i.e. ‘severe’, ‘moderate’, and ‘mild’ by downstream fine-tuning the parameters. Evaluation metrics such as accuracy, F1, precision, recall, and specificity are calculated to evaluate the performance of the models. Comparative analysis of these models is also done with a moderately larger model i.e. DistilBert which has 67 million tunable parameters for the same task with the same experimental settings. Results indicate that ESG outperforms all other models including DistilBert due to its better deep contextualized text representation as it gets the best F1 score of 89% with comparatively less training time. Further optimization of ESG is also proposed to make it suitable for low-powered devices. This study helps to achieve better classification performance of depression detection as well as to choose the best language model in terms of performance and less training time for Twitter-related downstream NLP tasks.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7835155725479126
    },
    {
      "name": "Transfer of learning",
      "score": 0.6619454622268677
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6058627963066101
    },
    {
      "name": "Natural language processing",
      "score": 0.5501773953437805
    },
    {
      "name": "Machine learning",
      "score": 0.33759862184524536
    }
  ]
}