{
  "title": "Artificial neural network language models predict human brain responses to language even after a developmentally realistic amount of training",
  "url": "https://openalex.org/W4301594491",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2627691546",
      "name": "Eghbal A Hosseini",
      "affiliations": [
        "McGovern Institute for Brain Research",
        "Institute of Cognitive and Brain Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2779585871",
      "name": "Martin Schrimpf",
      "affiliations": [
        "McGovern Institute for Brain Research",
        "Institute of Cognitive and Brain Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2191328178",
      "name": "Yian Zhang",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2145255766",
      "name": "Samuel Bowman",
      "affiliations": [
        "New York University"
      ]
    },
    {
      "id": "https://openalex.org/A2232124804",
      "name": "Noga Zaslavsky",
      "affiliations": [
        "McGovern Institute for Brain Research",
        "Institute of Cognitive and Brain Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2071363772",
      "name": "Evelina Fedorenko",
      "affiliations": [
        "Harvard University",
        "Institute of Cognitive and Brain Sciences",
        "McGovern Institute for Brain Research"
      ]
    },
    {
      "id": "https://openalex.org/A2627691546",
      "name": "Eghbal A Hosseini",
      "affiliations": [
        "McGovern Institute for Brain Research",
        "Institute of Cognitive and Brain Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2779585871",
      "name": "Martin Schrimpf",
      "affiliations": [
        "McGovern Institute for Brain Research",
        "Institute of Cognitive and Brain Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2191328178",
      "name": "Yian Zhang",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2145255766",
      "name": "Samuel Bowman",
      "affiliations": [
        "New York University"
      ]
    },
    {
      "id": "https://openalex.org/A2232124804",
      "name": "Noga Zaslavsky",
      "affiliations": [
        "Institute of Cognitive and Brain Sciences",
        "McGovern Institute for Brain Research"
      ]
    },
    {
      "id": "https://openalex.org/A2071363772",
      "name": "Evelina Fedorenko",
      "affiliations": [
        "Institute of Cognitive and Brain Sciences",
        "Harvard University",
        "McGovern Institute for Brain Research"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6853400716",
    "https://openalex.org/W2974597461",
    "https://openalex.org/W2537240939",
    "https://openalex.org/W2605717780",
    "https://openalex.org/W3023116953",
    "https://openalex.org/W2407291067",
    "https://openalex.org/W4205805705",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W2971683016",
    "https://openalex.org/W2105824687",
    "https://openalex.org/W4212828284",
    "https://openalex.org/W6801699001",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2483390977",
    "https://openalex.org/W2096462008",
    "https://openalex.org/W3036699898",
    "https://openalex.org/W2155034734",
    "https://openalex.org/W4382404227",
    "https://openalex.org/W2119728020",
    "https://openalex.org/W2789930594",
    "https://openalex.org/W2970648593",
    "https://openalex.org/W3033502539",
    "https://openalex.org/W2605959375",
    "https://openalex.org/W4220949944",
    "https://openalex.org/W2978950289",
    "https://openalex.org/W1998674455",
    "https://openalex.org/W4289638300",
    "https://openalex.org/W2276591486",
    "https://openalex.org/W3034510440",
    "https://openalex.org/W3213709737",
    "https://openalex.org/W2128246772",
    "https://openalex.org/W2805003518",
    "https://openalex.org/W2058373514",
    "https://openalex.org/W4231242566",
    "https://openalex.org/W6772383348",
    "https://openalex.org/W4372353056",
    "https://openalex.org/W4288368497",
    "https://openalex.org/W1991825895",
    "https://openalex.org/W2886663262",
    "https://openalex.org/W4221076233",
    "https://openalex.org/W4293463901",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2616551000",
    "https://openalex.org/W1632114991",
    "https://openalex.org/W3129717984",
    "https://openalex.org/W3100481436",
    "https://openalex.org/W6727099177",
    "https://openalex.org/W4361766487",
    "https://openalex.org/W1995672192",
    "https://openalex.org/W3105478389",
    "https://openalex.org/W4283643570",
    "https://openalex.org/W2782213998",
    "https://openalex.org/W3198757395",
    "https://openalex.org/W2571093196",
    "https://openalex.org/W2888625409",
    "https://openalex.org/W1965511524",
    "https://openalex.org/W3210923133",
    "https://openalex.org/W4285083025",
    "https://openalex.org/W2997938465",
    "https://openalex.org/W3213177139",
    "https://openalex.org/W2161498332",
    "https://openalex.org/W2481432072",
    "https://openalex.org/W2108010971",
    "https://openalex.org/W2946417913",
    "https://openalex.org/W2947012833",
    "https://openalex.org/W4366003941",
    "https://openalex.org/W2971016963",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W2973957133",
    "https://openalex.org/W4207085713",
    "https://openalex.org/W3033254023",
    "https://openalex.org/W1969221307",
    "https://openalex.org/W2969343193",
    "https://openalex.org/W1566289585",
    "https://openalex.org/W4291792732",
    "https://openalex.org/W3099668342",
    "https://openalex.org/W4220952562"
  ],
  "abstract": "Abstract Artificial neural networks have emerged as computationally plausible models of human language processing. A major criticism of these models is that the amount of training data they receive far exceeds that of humans during language learning. Here, we use two complementary approaches to ask how the models’ ability to capture human fMRI responses to sentences is affected by the amount of training data. First, we evaluate GPT-2 models trained on 1 million, 10 million, 100 million, or 1 billion words against an fMRI benchmark. We consider the 100-million-word model to be developmentally plausible in terms of the amount of training data given that this amount is similar to what children are estimated to be exposed to during the first 10 years of life. Second, we test the performance of a GPT-2 model trained on a 9-billion-token dataset to reach state-of-the-art next-word prediction performance on the human benchmark at different stages during training. Across both approaches, we find that (i) the models trained on a developmentally plausible amount of data already achieve near-maximal performance in capturing fMRI responses to sentences. Further, (ii) lower perplexity—a measure of next-word prediction performance—is associated with stronger alignment with human data, suggesting that models that have received enough training to achieve sufficiently high next-word prediction performance also acquire representations of sentences that are predictive of human fMRI responses. In tandem, these findings establish that although some training is necessary for the models’ predictive ability, a developmentally realistic amount of training (∼100 million words) may suffice.",
  "full_text": null,
  "topic": "Perplexity",
  "concepts": [
    {
      "name": "Perplexity",
      "score": 0.6837530136108398
    },
    {
      "name": "Computer science",
      "score": 0.679816484451294
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.5775156021118164
    },
    {
      "name": "Language model",
      "score": 0.5486429929733276
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5342273712158203
    },
    {
      "name": "Artificial neural network",
      "score": 0.51677405834198
    },
    {
      "name": "Word (group theory)",
      "score": 0.47240108251571655
    },
    {
      "name": "Machine learning",
      "score": 0.4405917227268219
    },
    {
      "name": "Natural language processing",
      "score": 0.43267500400543213
    },
    {
      "name": "Speech recognition",
      "score": 0.3414463400840759
    },
    {
      "name": "Linguistics",
      "score": 0.08163923025131226
    },
    {
      "name": "Geography",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Geodesy",
      "score": 0.0
    }
  ]
}