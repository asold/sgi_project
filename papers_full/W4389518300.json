{
  "title": "Investigating the Effect of Discourse Connectives on Transformer Surprisal: Language Models Understand Connectives, Even So They Are Surprised",
  "url": "https://openalex.org/W4389518300",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2100964018",
      "name": "Yan Cong",
      "affiliations": [
        "Purdue University West Lafayette"
      ]
    },
    {
      "id": "https://openalex.org/A791988515",
      "name": "Emmanuele Chersoni",
      "affiliations": [
        "Hong Kong Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A4288889815",
      "name": "Yu Yin Hsu",
      "affiliations": [
        "Hong Kong Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A2113929840",
      "name": "Philippe Blache",
      "affiliations": [
        "Aix-Marseille Université"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4385573517",
    "https://openalex.org/W4385572952",
    "https://openalex.org/W3210694367",
    "https://openalex.org/W2942054564",
    "https://openalex.org/W4238909500",
    "https://openalex.org/W4399639995",
    "https://openalex.org/W4385572451",
    "https://openalex.org/W2165256085",
    "https://openalex.org/W2149537128",
    "https://openalex.org/W2052742452",
    "https://openalex.org/W2054125330",
    "https://openalex.org/W2964226791",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4317838060",
    "https://openalex.org/W4238158851",
    "https://openalex.org/W2915085887",
    "https://openalex.org/W2962961857",
    "https://openalex.org/W2964842699",
    "https://openalex.org/W3044438666",
    "https://openalex.org/W1536620489",
    "https://openalex.org/W4289552613",
    "https://openalex.org/W3177377367",
    "https://openalex.org/W2948947170",
    "https://openalex.org/W4221154823",
    "https://openalex.org/W3118781290",
    "https://openalex.org/W2071119661",
    "https://openalex.org/W2145679566",
    "https://openalex.org/W2327873341",
    "https://openalex.org/W4385718071",
    "https://openalex.org/W2946417913",
    "https://openalex.org/W2565756058",
    "https://openalex.org/W3103816537",
    "https://openalex.org/W4288351520",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3115433372",
    "https://openalex.org/W3212496002",
    "https://openalex.org/W2095102476",
    "https://openalex.org/W3102485638",
    "https://openalex.org/W2978017171"
  ],
  "abstract": "International audience",
  "full_text": "Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP, pages 222–232\nDecember 7, 2023. ©2023 Association for Computational Linguistics\n222\nInvestigating the Effect of Discourse Connectives on Transformer Surprisal:\nLanguage Models Understand Connectives;Even SoThey Are Surprised\nYan Cong\nPurdue University\ncong4@purdue.edu\nEmmanuele Chersoni\nThe Hong Kong Polytechnic University\nemmanuelechersoni@gmail.com\nYu-Yin Hsu\nThe Hong Kong Polytechnic University\nyu-yin.hsu@polyu.edu.hk\nPhilippe Blache\nAix-Marseille University\nphilippe.blache@univ-amu.fr\nAbstract\nAs neural language models (NLMs) based on\nTransformers are becoming increasingly dom-\ninant in natural language processing, several\nstudies have proposed analyzing the semantic\nand pragmatic abilities of such models.\nIn our study, we aimed at investigating the ef-\nfect of discourse connectives on NLMs with\nregard to Surprisal scores. We did this by fo-\ncusing on the English stimuli of an experimen-\ntal dataset, in which the expectations about an\nevent in a discourse fragment could be reversed\nby a concessive or a contrastive connective.\nBy comparing the Surprisal scores of several\nNLMs, we found that bigger NLMs show\npatterns similar to humans’ behavioral data\nwhen a concessive connective is used, while\nconnective-related effects tend to disappear\nwith a contrastive one. We have additionally\nvalidated our findings with GPT-Neo using an\nextended dataset, and results mostly show a\nconsistent pattern.\n1 Introduction\nPsychologists and cognitive scientists have claimed\nthat understanding a discourse involves construct-\ning a situation model; that is, a dynamic mental\nrepresentation of the state of affairs denoted by the\ntext (Van Dijk and Kintsch, 1983; Zwaan and Rad-\nvansky, 1998). Extensive evidence has shown that\nhumans use a general knowledge of events and their\nconnections to anticipate upcoming input in the pro-\ncess of language comprehension (McRae and Mat-\nsuki, 2009). In this sense, discourse connectives\nmight play an important role in updating human sit-\nuation models and in modulating our expectations\nabout \"what is coming next\", because concessive\n(such as even so) and contrastive connectives (such\nas however) signal to the comprehender that the up-\ncoming proposition is going to contradict what was\npreviously said, or negate the previous expectations\n(Xiang and Kuperberg, 2015).\nExperimental studies have shown that such con-\nnectives have a facilitating effect on human sen-\ntence processing (Asr and Demberg, 2020), es-\npecially when humans are processing incoherent\nwords and scenarios (Xiang and Kuperberg, 2015).\nConsider the following example taken from Xiang\nand Kuperberg (2015), in which the concessive\nconnective even socauses an effect of expectation\nreversal:\n(1) Liz took the test and failed it. Even so, she\nwent home and celebrated wildly.\nGiven the scenario described in the first sentence\n(failing a test), the underlined verb in the second\nsentence is surprising and unexpected. However,\nafter including a connective reversing the readers’\nexpectations, examples like (1) are considered as\ncoherent by human speakers.\nThe recent literature on natural language process-\ning (NLP) has shown an increasing interest in the\nuse of Surprisal scores (Hale, 2001; Levy, 2008)\ncomputed by neural language models (NLMs)\nto account for sentence processing phenomena\n(Futrell et al., 2018; Van Schijndel and Linzen,\n2018; Wilcox et al., 2018), including facilitation\n(Michaelov and Bergen, 2020, 2022a,b; Michaelov\net al., 2023) and interference effects (Cong et al.,\n2023) in online sentence processing. However,\nto the best of our knowledge, no studies have at-\ntempted to model the facilitation effects of conces-\nsive and contrastive connectives at different levels\nof discourse coherence thus far.\nIn our study, we aim to fill this research gap by\ninvestigating the effect of discourse connectives on\nNLMs’ Surprisal scores. First, we focus on the con-\ncessive connective even so, and on the contrastive\nconnective however as an alternative.\nBased on the whole discourse, we first computed\nthe Surprisal scores for target words using NLMs to\nobserve the extent to which they were affected by\n223\nthe coherence of the stories. We found that NLMs,\nand particularly the larger models, show patterns\nthat are quite similar to human behavioral data.\nMoreover, we noticed that the connective-related\neffects do not show up with contrastive connective,\nsuggesting that the NLMs are sensitive to the dif-\nference between connective types: the semantics\nof concessive connectives entails a reversal of pre-\nvious expectations about an upcoming event that\nis not conveyed by contrastive connectives. Using\nour biggest model, GPT-Neo, we ran additional\nanalysis adding more connectives of the two types\nand computing the Surprisal scores either in an\ninter-sentential and an intra-sentential setting. The\nresults were mostly consistent with our first experi-\nment, corroborating the previous findings.\n2 Related Work\n2.1 NLM Estimation of Word Surprisal\nTransformer-based NLMs (Vaswani et al., 2017;\nDevlin et al., 2019; Radford et al., 2019) have be-\ncome increasingly popular in NLP research, and\na number of studies designed tests to investigate\ntheir actual linguistic abilities (Tenney et al., 2019a;\nJawahar et al., 2019; Tenney et al., 2019b). Some\nof these studies have specifically analyzed the Sur-\nprisal scores computed by the models, to under-\nstand the extent to which they are sensitive to lin-\nguistic phenomena that have been shown to affect\nhuman sentence processing. For example, Misra\net al. (2020) investigated the predictions of BERT\nin a setting aimed at reproducing human semantic\npriming; they reported that BERT was indeed sensi-\ntive to “priming”, and predicted a word with lower\nSurprisal values when the context included a re-\nlated word as opposed to an unrelated one. Using a\nsimilar methodology, Cho et al. (2021) modeled the\npriming effect of verb aspect on the prediction of\ntypical event locations, finding that BERT outputs\nlower Surprisal scores for typical locations. How-\never, differently from humans, it does so regardless\nof verb aspect.\nMichaelov and Bergen (2022a) investigated the\nissue of collateral facilitation; that is, a scenario\nwhen anomalous words in a sentence are processed\nmore easily by humans due to the presence of\nsemantically related words in the context. They\ncompared the Surprisal scores obtained from sev-\neral Transformers NLMs and found that most of\nthem reproduced the same significant differences\nbetween the conditions that were observed by hu-\nmans’ behaviors. Michaelov et al. (2023) used\nNLM surprisal scores to replicate the effect of the\ndiscourse context in reducing the N400 amplitude\nfor anomalous words, using the Dutch stimuli in\nthe experiments by Nieuwland and Van Berkum\n(2006).1\n2.2 Discourse Connectives in NLP\nThe importance of connectives in NLP research\nis due to the fact that they lexicalize specific dis-\ncourse relations (Braud and Denis, 2016; Ma et al.,\n2019). During the acquisition of annotations for\ndiscourse-parsing tasks, the connectives sometimes\nprovide a clue to the discourse relations, which are\nsometimes implicit. In such cases, human anno-\ntators are asked to insert the connective that they\nconsider to be more appropriate (Yung et al., 2019).\nKo and Li (2020) proposed to investigate GPT-\n2’s linguistic competence in terms of discourse\ncoherence by testing the model’s ability to produce\nthe correct connectives, when given a discourse re-\nlation linking two clauses. Using both organic gen-\neration and fine-tuned scenarios, they observed that\nGPT-2 did not always generate coherent discourse,\nalthough the generations were better aligned with\nhuman behavior in the fine-tuned scenario.\nPandia et al. (2021) evaluated several NLMs on\nthe prediction of the correct connectives in contexts\nthat required Gricean-like pragmatic knowledge\nand in which a specific connective would corre-\nspond to an implicature. For example, in cases\nsuch as Maggie did the paperwork by handand the\ncompany bought new computers, which is to say,\nMaggie did the paperwork by hand [MASK] the\ncompany bought new computers., the model had\nto predict before in the [MASK] position to show\nan understanding that the implied meaning of and\nin this context was and then). The authors showed\nthat, when controlling strictly for low-level lexical\nand syntactic cues, the models performed at chance\nlevel at best.\nIn contrast to previous studies, we did not ask the\nNLMs to predict a missing connective in a cloze\n1The N400 is one of the most widely studied component\nin the literature on event-related potentials (ERP). The N400\ncomponent is a negative-going deflection that peaks around\n400 milliseconds after presentation of the stimulus word and,\nalthough there are different interpretations of its meaning,\nthere is a general agreement among researchers that it may\nrepresent a sort of brain signature of semantic complexity\n(Hagoort, 2003). Therefore, a reduced N400 amplitude due\nto the presence of semantically-related words in the discourse\ncontext can be interpreted as a facilitation effect.\n224\nsetting; instead, we analyzed the impact of a con-\ncessive/contrastive connective on the model’s ex-\npectations for a given event, which might be co-\nherent or not with the scenario. In practical terms,\nthis translates into analyzing the Surprisal of the\nmodel at the verb in the subordinate clause: we\npredict that if the model is linguistically competent\nand can identify coherence correctly, the coherent\nitems should be assigned lower Surprisal scores.\n3 Experimental Settings\n3.1 Dataset\nWe used the English stimuli provided by Xiang and\nKuperberg (2015), who designed 180 sets of two-\nsentence discourse items, each with four conditions\nas in (2) (45 scenarios per condition). The target\nword (underlined) appeared in the final sentence.\n(2) a. Liz had a history exam on Monday.\nShe took the test andaced it. She went\nhome and celebrated wildly. ( Plain,\nCoherent)\nb. Liz had a history exam on Mon-\nday. She took the test and failed it.\nShe went home and celebrated wildly.\n(Plain, Incoherent)\nc. Liz had a history exam on Monday.\nShe took the test andfailed it. Even so,\nshe went home and celebrated wildly.\n(Even so, Coherent)\nd. Liz had a history exam on Monday.\nShe took the test and aced it. Even so,\nshe went home and celebrated wildly.\n(Even so, Incoherent)\nWe also created alternative versions of (2-c) and\n(2-d) by replacing Even so with However. Note\nthat, as however is a contrastive connective, its\nsemantics signals an upcoming contrast, but not\nnecessarily the denial of previously-held expecta-\ntions as in concessive relations (Izutsu, 2008), and\nthus, it was interesting for us to test and compare\nthe consistency of the reversal effect.\nXiang and Kuperberg (2015) collected cloze\nprobabilities and typicality judgments for their\nitems (Table 1). The coherent items had the high-\nest cloze probability scores and coherence ratings,\nwhereas the incoherent items had the lowest ones.\nThe coherent even-so items exhibited significantly\nlower cloze probability and coherence ratings than\nthe plain coherent ones did; while the incoherent\neven-so items were rated as more plausible than\nScenario type Cloze probability Coherence\nCoherent 0.42 4.8\nIncoherent 0.03 1.7\nEven-so Coherent 0.31 3.3\nEven-so Incoherent 0.04 2.4\nTable 1: Summary table for the human data in Xiang\nand Kuperberg (2015). Cloze probability is represented\nas the proportion of total responses from 40 participants.\n5: very coherent; 1: incoherent.\nthe plain incoherent ones, the difference was not\nsignificant.\nTheir EEG experiment showed some differences\nfrom the behavioral data: The N400 component for\nthe target verb was more reduced in the coherent\neven-so items (i.e., lower processing costs), com-\npared to the plain coherent ones, while incoherent\nitems with even-so showed higher processing costs\nthan the plain incoherent ones at the target verb,\neliciting a P600 component.2\n3.2 Language Models\nFor the models in this paper, we use the imple-\nmentation of Minicons (Misra, 2022) 3, which is\nan open source library that provides a standard\nAPI for behavioral and representational analyses\nof NLMs. We experimented with three variants of\nautoregressive LMs of different sizes: the original\nGPT-2 Base, with 124 million parameters (Radford\net al., 2019); DistilGPT-2 with 82 million param-\neters (Sanh et al., 2019), which was trained as a\nstudent network with the supervision of GPT-2;\nand our biggest model GPT-Neo, with 1.3 billion\nparameters (Gao et al., 2020; Black et al., 2021).\nUsing autoregressive NLMs, we computed the\nSurprisal scores for the targets in the stimuli - the\ncritical verb in the final clause. Notice that, in the\nfour conditions of the same item, the verb to be\npredicted is always the same. More formally, the\nSurprisal for the target T in the context C (Surp)\nwas computed as:\nSurp(wt) =−logP (wt|w1...t−1) (1)\nWhen wt was tokenized into multiple subword\ntokens, we simply used the average of the subword\n2The P600 is positive-going wave peaking around 600 ms\nafter the presentation of a stimulus word. In online sentence\nprocessing studies, it is generally associated with the presence\nof syntactic anomalies and structural reprocessing (Osterhout\nand Holcomb, 1993; Luck, 2014).\n3https://github.com/kanishkamisra/\nminicons-experiments\n225\nGPT-2 DistilGPT-2 GPT-Neo\nIntercept *** *** ***\nDisCohere *** *** ***\nDisConn ** *** ***\nlength *\nDisCohere:\nDisConn *** *** ***\nTable 2: Even sodataset: Summary table for the signifi-\ncance scores of different predictors of Surp. Notation:\n∗ = p <0.05, ∗∗ = p <0.01, ∗ ∗ ∗= p <0.001.\nGPT-2 DistilGPT-2 GPT-Neo\nIntercept *** *** ***\nDisCohere *** *** ***\nDisConn\nlength *\nDisCohere:\nDisConn * ***\nTable 3: However dataset: Summary table for signifi-\ncance scores of the different predictors of Surp.\ntokens probabilities.4 However, we found that this\nhappens only for the 14% of the target verbs in the\ndataset (only 23 out of 163 targets are not included\nin the models’ vocabulary).\nFor each NLM, we fitted a linear mixed-effects\nmodel using the Surprisals ( Surp) of the target\nverbs as the dependent variable. The independent\nvariables include: the coherence of the discourse\nDisCohere (coherent vs. incoherent), the presence\nof discourse connectives DisConn (with connec-\ntive vs. plain/without connective), their interaction\n(DisCohere:DisConn), and the token length of the\nstimulus (length). We used the ID of the items\n(ITEM_ID) as the random intercept in our mod-\nels. We used the lmerTest package (Kuznetsova\net al., 2017) for model fitting and results; finally,\nthe pairwise comparisons with Tukey adjustment\nwere carried out by means of the EMMEANS pack-\nage (Lenth, 2019) in R.\n4 Results\nFor the original Even sodata (Table 2), our results\nrevealed that all three NLMs showed significant\nsensitivity to the coherence of the discourse (DisCo-\nhere) and to the presence of connectives (DisConn).\nInteraction effects were found in all the NLMs, and\nonly GPT-Neo showed effects on length. Interest-\ningly, the replacement of Even sowith However\ncaused the DisConn effects to disappear in all the\nNLMs (Table 3). Interaction effects were found\n4Upon request of the reviewers, results for the experiment\nwith the sum of the Surprisal scores instead of the average can\nbe found in the Appendix.\nGPT-2 DistilGPT-2 GPT-Neo\nCohereNoconn\nCohereConn -0.45* -0.426* -0.89***\nIncohereNoconn\nIncohereConn 0.365* 0.475*** 0.716***\nIncohereConn\nCohereConn 0.23 -0.205 0.539**\nIncohereNoconn\nCohereNoconn 1.044*** 0.695*** 2.144***\nTable 4: Even sodataset: Summary table for the esti-\nmate and the p-values of the pairwise comparisons.\nGPT-2 DistilGPT-2 GPT-Neo\nCohereNoconn\nCohereConn -0.49* -0.211 -1.228***\nIncohereNoconn\nIncohereConn -0.151 0.047 0.066\nIncohereConn\nCohereConn 0.715*** 0.455*** 0.857***\nIncohereNoconn\nCohereNoconn 1.054*** 0.712*** 2.15***\nTable 5: However dataset: Summary table for the esti-\nmate and p-values of the pairwise comparisons.\nin GPT-2 and GPT-Neo, and again, only GPT-Neo\nshowed sensitivity to length.\nThe pairwise comparisons examining the effects\nof Even so at each level of Coherence (Table 4)\nshowed that, for all the models, there is a decrease\nof Surprisals from Even socoherent scenarios (con-\ndition c.) to plain coherent scenarios (condition a.),\nand an increase of Surprisals from Even soinco-\nherent scenarios (condition d.) to plain incoherent\nscenarios (condition b.). Pairwise comparisons ex-\namining effects of Coherence at each level of Even\nso showed a significant increase of Surprisals from\nEven socoherent scenarios (condition c.) to Even\nso incoherent scenarios (condition d.) only with\nGPT-Neo. All the NLMs showed an increase of\nSurprisals from plain coherent scenarios (condition\na.) to plain incoherent ones (condition b.).\nFewer significant effects were found after replac-\ning Even sowith However (Table 5). Regarding\nthe effects of However at each level of Coherence,\nGPT-2 and GPT-Neo revealed a decrease of Sur-\nprisals from However coherent scenarios (condi-\ntion c.) to plain coherent scenarios (condition a.).\nAll NLMs showed no significant effects of Sur-\nprisals from However incoherent condition (con-\ndition d.) to plain incoherent condition (condition\nb.). As for the effects of Coherence at each level\nof However, all the NLMs showed an increase of\nSurprisals from However coherent condition (con-\ndition c.) to However incoherent condition (condi-\ntion d.), and an increase of Surprisals from plain\n226\nGPT-2 DistilGPT-2 GPT-Neo\nDisCohere ✓ ✓ ✓\nDisConn ✓ ✓ ✓\nDisCohere:\nat each level of\nDisConn\n✓\nDisConn:\nat each level of\nDisCohere\n✓ ✓ ✓\nTable 6: Even so dataset: Comparison of effects be-\ntween Human behavioral results and NLMs Surprisals.\nNotation: ✓ = alignment with Human in significance\nand direction of the effect.\ncoherent condition (condition a.) to plain incoher-\nent condition (condition b.).\nComparing the outcome with the study by Xiang\nand Kuperberg (2015), one can observe that the\nmodel scores tend to align with human typicality\njudgements (cf. Table 1), and the largest one (i.e.\nGPT-Neo) shows the same effect pattern (cf. Table\n6). A difference, however, is that all the NLMs\nassign significantly higher Surprisals to plain inco-\nherent items than Even soincoherent ones.\nOur results suggest that NLMs are sensitive to\nthe expectation reversal determined by connectives.\nBesides the human-like pattern in the distribution\nof the Surprisal scores for the Even sodataset, it is\nalso noticeable that replacing the connective with\nHowever makes the connective-related effects dis-\nappear. This is coherent with the intuition and\nthe claims made in formal semantics literature, for\nwhich However simply introduces a semantic op-\nposition, while Even soadditionally presupposes\nan expectation being denied (Karttunen and Peters,\n1979; Izutsu, 2008).\n4.1 Extended Study\nOur experiments on Surprisal suggest that our\nlarger NLM, GPT-Neo, shows similar patterns to\nhumans behavioral data with the concessive con-\nnective even so. Interestingly, all NLMs show dis-\ntinct patterns with concessive and contrastive con-\nnective, with no connective-related effects when\nhowever is used. This might be due to the fact that\ncontrastive connectivesper sejust indicate a seman-\ntic opposition, but differently from concessive ones,\nthey do not necessarily deny an expectation about\nan event. However, one might ask if the NLMs\nwould consistently score the discourse items even\nwhen using different concessive or contrastive con-\nnectives.\nTo verify this, we extended our study with GPT-\nNeo: 1) we selected more connectives for the two\ngroups, a) but, yetand still for the contrastive group\nand b) nonetheless, neverthelessand regardless for\nthe concessive one; in each item of the original\nstimuli by Xiang and Kuperberg (2015), we re-\nplaced the original even soconnectives with the\nnew ones, obtaining 6 new datasets (one for each\nof the newly-introduced connectives); 2) NLMs\npredictions have been shown to be extremely sen-\nsitive even to small changes in the input (Jiang\net al., 2020); in our case, the predictions might\nhave been affected by the fact that the connectives\nalways appeared in a new sentence after a full stop\n(inter-sentential setting). Therefore, we also carry\nout the experiment after replacing the final full\nstop of the second sentence with a comma (intra-\nsentential setting), and lower-casing the discourse\nconnectives, as it can be seen in Example (3):\n(3) a. Liz took the test and failed it. Even so,\nshe went home and celebrated wildly.\n(inter-sentential)\nb. Liz took the test and failed it, even so,\nshe went home and celebrated wildly.\n(intra-sentential)\nOur choice of connectives was based on Webber\net al. (2019), which describes and annotatesbut, yet,\nstill as contrastive connectives that share the same\nsyntax and semantics as however, and nonetheless,\nnevertheless, regardlessas concessive connectives\nthat introduce events in the same manner as even\nso does. Moreover, using those connectives it was\neasy to modify our stimuli by replacing the original\neven soand maintaining at the same time the same\nword order and syntax of the experimental items.\nThe procedure for computing the Surprisal\nscores with the NLMs and running the linear mixed\nmodels is the same of Section 3.2, but this time we\nonly used GPT-Neo, as it was the model with the\nmost similar pattern to human behavioral data.\nAs shown in Tables 7-8, the results suggest\nthat the pattern found in inter-sentential even\nso/however mostly gets reproduced across differ-\nent inter-/intra-sentential connectives. still is the\nconnective that shows more discrepancy: as intra-\nsentential connective, we found connectives (Dis-\nConn) effects, which were absent in however. It\nis interesting to notice that the presence or not of\nthe DisConn effect is what sets apart the two sets\nof connectives: similarly to even so, nevertheless,\nnonetheless and regardless all display significant\n227\nFigure 1: Boxplots of the GPT-Neo Surprisals for all the inter-/intra-sentential connectives (mean of the scores\nis marked in yellow). Notation: A (red): IMPLAUS_CONN; B (blue): IMPLAUS_NOCONN; C (green):\nPLAUS_CONN; D (purple): PLAUS_NOCONN.\n228\neven so nevertheless nonetheless regardless still yet but however\nIntercept *** *** *** *** *** *** *** ***\nDisCohere *** *** *** *** *** *** *** ***\nDisConn *** * * ***\nlength * * * * * ** *\nDisCohere:\nDisConn *** *** *** *** *** *** *** ***\nTable 7: Extended INTER dataset: Summary table for the significance scores of different predictors of Surp using\nGPT-Neo. Notation: ∗ = p <0.05, ∗∗ = p <0.01, ∗ ∗ ∗= p <0.001.\neven so nevertheless nonetheless regardless still yet but however\nIntercept *** *** *** *** *** *** *** ***\nDisCohere *** *** *** *** *** *** *** ***\nDisConn *** ** ** *** ***\nlength * * * *** ** * ** *\nDisCohere:\nDisConn *** *** *** *** *** *** *** ***\nTable 8: Extended INTRA dataset: Summary table for the significance scores of different predictors of Surp using\nGPT-Neo. Notation: ∗ = p <0.05, ∗∗ = p <0.01, ∗ ∗ ∗= p <0.001.\neffects, while the contrastive connectives yet and\nbut do not. Still represents the exception to this pat-\ntern, and a possible reason might be its ambiguity,\nas this word can appear as a noun, an adjective, a\nverb or an adverb, besides its connective usage.\nThe scores for all settings can be visualized\nin Figure 1. Across connectives types, GPT-Neo\nshowed the highest Surprisals scores in the inco-\nherent without connectives (IMPLAUS _NOCONN )\ncondition, whereas the lowest scores were ob-\nserved in the coherent without connectives\n(PLAUS _NOCONN ) condition. We did not find a lot\nof variance across conditions. We also observed a\nfew outliers, mostly occurring in the coherent with\nconnectives (PLAUS _CONN ) condition.\nWe conducted follow-up comparisons and sum-\nmarized our results in Table 9. In most cases, for\nmain and interaction effects, GPT-Neo’s behavior\nacross concessive connectives aligned well with\neven soin both the statistical significance and direc-\ntion of the effects. A discrepancy was found in the\nfollow-up comparisons: the inter-/intra-sentential\nregardless did not align well with even sofor the\ncoherence effects with respect to connectives (Dis-\nCohere: at each level of DisConn).\nSimilarly to still, we speculate that a possible\nreason could be the ambiguity of this word, as\nregardless can appear in a sentence as an adjective\nor as a preposition (with the meaning of in spite\nof/despite), and thus it might lead the NLM to less\naccurate predictions. Interestingly, and differently\nfrom the other concessive, it can be noticed from\nFigure 1 (in the first boxplots of the second and of\nthe fourth row) that with the regardless connective\nthe IMPLAUS_CONN items (red boxes) tend to\nhave similar, or lower Surprisal scores than the\nPLAUS_CONN ones (green boxes).\nConcerning contrastive connectives, inter-/intra-\nsentential but did not align with however for the\nconnectives effects with respect to coherence (Dis-\nConn: at each level of DisCohere). Additionally,\nour findings indicate that intra-sentential still did\nnot align with however regarding coherence effects\n(DisCohere: at each level of DisConn), and that\ninter-sentential yet did not align with however re-\ngarding connective effects (DisConn: at each level\nof DisCohere). In general, contrastive connectives\nare less consistent with regard to the pattern found\nin the original experiment, showing that, for how\nthe stimuli were built, the denial of expectations\nintroduced by a concessive connective is an im-\nportant cue for modulating the coherence of the\ncontinuation of the story.\n5 Conclusion\nIn our paper, we proposed an analysis of the Sur-\nprisal scores of NLMs on the target verbs of a psy-\ncholinguistic dataset where the items differed by\nthe coherence of the discourse, and by the inclu-\nsion of a connective reversing the expectations on\nthe verb. We found that our NLMs show patterns\nthat are quite similar to human behavioral data, in\nparticular the biggest model, GPT-Neo. More in-\nterestingly, in all models the effects related to the\nconnective disappear when a contrastive connec-\ntive is used to replace the concessive one. This\n229\nnevertheless nonetheless regardless still yet but\nAlign with inter-sentential even so Align with inter-sentential however\nDisCohere ✓ ✓ ✓ ✓ ✓ ✓\nDisConn ✓ ✓ ✓ ✓ ✓\nDisCohere:\nat each level of\nDisConn\n✓ ✓ ✓ ✓ ✓\nDisConn:\nat each level of\nDisCohere\n✓ ✓ ✓ ✓\nAlign with intra-sentential even so Align with intra-sentential however\nDisCohere ✓ ✓ ✓ ✓ ✓ ✓\nDisConn ✓ ✓ ✓ ✓ ✓\nDisCohere:\nat each level of\nDisConn\n✓ ✓ ✓ ✓\nDisConn:\nat each level of\nDisCohere\n✓ ✓ ✓ ✓ ✓\nTable 9: Extended dataset: comparing GPT-Neo Surprisal scores across connectives. Notation: ✓ = aligned in\nsignificance and direction of the effect.\nsuggests that the concessive connective leads to an\nexpectation reversal for the upcoming verb, while\nthe contrastive one does not, coherently with pre-\nvious descriptions of connectives from the formal\nsemantics literature (Karttunen and Peters, 1979;\nIzutsu, 2008).\nGiven that the psycholinguistic dataset we used\nin our modeling is relatively small for NLP settings\nand limited to two connectives, we additionally\nconstructed an extended datasets to validate our\nfindings. We extended our investigation in two\nways: expanding the dataset by varying the setting\nin which the connective was found (inter- or intra-\nsentential) and connectives themselves, including\nsix more contrastive/concessive connectives. Our\nresults indicate that the findings even soare mostly\nconsitent, as they generalize across settings and\nconcessive connectives.\nWe acknowledge that there are some significant\nlimitations in our current investigations. First, we\nhave human data only for even so in the inter-\nsentential setting, for which we could establish\nan interpretation baseline. There is no behavioral\nor neural data for all the other connectives. This\nimplies that we interpreted some of our findings\nbased on intuitions about discourse connectives,\nassuming that the human behavioral pattern will be\nsimilar for other concessive types. We recognize\nthat this is an important limitation to the cognitive\nplausibility of our evaluation, and for future re-\nsearch we plan to collect more human judgements\nfor discourse connectives, possibly including also\nlanguages other English.\nSecond, our analysis was mainly focused on\ncomparing Surprisal scores to human behavioral\npatterns (or, by extension, to the patterns found in\nthe original experiment with concessive connec-\ntives), but we did not apply any advanced inter-\npretability method to identify which specific in-\nput tokens influence the predictions for the target\nverb. More direct evidence for the causal role of\ndiscourse connectives in reversing the predictions\ncould be obtained, for example, by analyzing the\nchanges of the probability rank of the verb in the\ntarget position; or by applying contrastive explana-\ntions to sentences differing only for the presence\nof connectives (Yin and Neubig, 2022).\nAcknowledgements\nThis research was funded by the PROCORE grant\nat the Hong Kong Polytechnic University (project\n3-RABX, \"Exploring the Influence of Discourse\nConnectives on the Predictions of Humans and Pre-\ntrained Language Models\"). We would also like\nto thank their three anonymous reviewers for their\nconstructive feedback.\nReferences\nFatemeh Torabi Asr and Vera Demberg. 2020. Inter-\npretation of Discourse Connectives Is Probabilistic:\nEvidence from the Study of But and Although. Dis-\ncourse Processes, 57(4):376–399.\nSid Black, Gao Leo, Phil Wang, Connor Leahy,\nand Stella Biderman. 2021. GPT-Neo: Large\nScale Autoregressive Language Modeling with Mesh-\nTensorflow. zenodo.org.\n230\nChloé Braud and Pascal Denis. 2016. Learning\nConnective-based Word representations for Implicit\nDiscourse Relation Identification. In Proceedings of\nEMNLP.\nWon Ik Cho, Emmanuele Chersoni, Yu-Yin Hsu, and\nChu-Ren Huang. 2021. Modeling the Influence of\nVerb Aspect on the Activation of Typical Event Lo-\ncations with BERT. In Findings of ACL-IJCNLP.\nYan Cong, Emmanuele Chersoni, Yu-Yin Hsu, and\nAlessandro Lenci. 2023. Are Language Models Sen-\nsitive to Semantic Attraction? A Study on Surprisal.\nIn Proceedings of *SEM.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\nDeep Bidirectional Transformers for Language Un-\nderstanding. In Proceedings of NAACL.\nRichard Futrell, Ethan Wilcox, Takashi Morita, and\nRoger Levy. 2018. RNNs as Psycholinguistic Sub-\njects: Syntactic State and Grammatical Dependency.\narXiv preprint arXiv:1809.01329.\nLeo Gao, Stella Biderman, Sid Black, Laurence Gold-\ning, Travis Hoppe, Charles Foster, Jason Phang, Ho-\nrace He, Anish Thite, Noa Nabeshima, et al. 2020.\nThe Pile: An 800GB Dataset of Diverse Text for Lan-\nguage Modeling. arXiv preprint arXiv:2101.00027.\nPeter Hagoort. 2003. Interplay Between Syntax and\nSemantics During Sentence Comprehension: ERP\nEffects of Combining Syntactic and Semantic Viola-\ntions. Journal of Cognitive Neuroscience, 15(6):883–\n899.\nJohn Hale. 2001. A Probabilistic Earley Parser as a\nPsycholinguistic Model. In Proceedings of NAACL.\nMitsuko Narita Izutsu. 2008. Contrast, Concessive, and\nCorrective: Toward a Comprehensive Study of Oppo-\nsition Relations. Journal of Pragmatics, 40(4):646–\n675.\nGanesh Jawahar, Benoît Sagot, and Djamé Seddah.\n2019. What Does BERT Learn about the Structure\nof Language? In Proceedings of ACL.\nZhengbao Jiang, Frank F Xu, Jun Araki, and Graham\nNeubig. 2020. How Can We Know What Language\nModels Know? Transactions of the Association for\nComputational Linguistics, 8:423–438.\nLauri Karttunen and Stanley Peters. 1979. Conventional\nImplicature. In Presupposition, pages 1–56. Brill.\nWei-Jen Ko and Junyi Jessy Li. 2020. Assessing Dis-\ncourse Relations in Language Generation from GPT-\n2. In Proceedings of INLG.\nAlexandra Kuznetsova, Per B. Brockhoff, and Rune\nH. B. Christensen. 2017. lmerTest Package: Tests in\nLinear Mixed Effects Models. Journal of Statistical\nSoftware, 82(13):1–26.\nRussell Lenth. 2019. emmeans: Estimated Marginal\nMeans, aka Least-Squares Means. R Package Ver-\nsion 1.4.2.\nRoger Levy. 2008. Expectation-based Syntactic Com-\nprehension. Cognition, 106(3):1126–1177.\nSteven J Luck. 2014. An Introduction to the Event-\nrelated Potential Technique. MIT Press.\nMingyu Derek Ma, Kevin K Bowden, Jiaqi Wu, Wen\nCui, and Marilyn Walker. 2019. Implicit Discourse\nRelation Identification for Open-domain Dialogues.\nIn Proceedings of ACL.\nKen McRae and Kazunaga Matsuki. 2009. People Use\ntheir Knowledge of Common Events to Understand\nLanguage, and Do So as Quickly as Possible. Lan-\nguage and Linguistics Compass, 3(6):1417–1429.\nJames A Michaelov and Benjamin K Bergen. 2020.\nHow Well Does Surprisal Explain N400 Amplitude\nunder Different Experimental Conditions? In Pro-\nceedings of CONLL.\nJames A Michaelov and Benjamin K Bergen. 2022a.\nCollateral Facilitation in Humans and Language Mod-\nels. In Proceedings of CONLL.\nJames A Michaelov and Benjamin K Bergen. 2022b.\n’Rarely’a Problem? Language Models Exhibit In-\nverse Scaling in their Predictions Following ’Few’-\ntype Quantifiers. arXiv preprint arXiv:2212.08700.\nJames A Michaelov, Seana Coulson, and Ben-\njamin K Bergen. 2023. Can Peanuts Fall in Love\nwith Distributional Semantics? arXiv preprint\narXiv:2301.08731.\nKanishka Misra. 2022. minicons: Enabling Flexi-\nble Behavioral and Representational Analyses of\nTransformer Language Models. arXiv preprint\narXiv:2203.13112.\nKanishka Misra, Allyson Ettinger, and Julia Taylor\nRayz. 2020. Exploring BERT’s Sensitivity to Lex-\nical Cues using Tests from Semantic Priming. In\nFindings of EMNLP.\nMante S Nieuwland and Jos JA Van Berkum. 2006.\nWhen Peanuts Fall in Love: N400 Evidence for the\nPower of Discourse. Journal of Cognitive Neuro-\nscience, 18(7):1098–1111.\nLee Osterhout and Phillip J Holcomb. 1993. Event-\nrelated Potentials and Syntactic Anomaly: Evidence\nof Anomaly Detection During the Perception of Con-\ntinuous Speech. Language and Cognitive Processes,\n8(4):413–437.\nLalchand Pandia, Yan Cong, and Allyson Ettinger.\n2021. Pragmatic Competence of Pre-trained Lan-\nguage Models through the Lens of Discourse Con-\nnectives. In Proceedings of CONLL.\n231\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nModels are Unsupervised Multitask Learners. In\nOpen-AI Blog.\nVictor Sanh, Lysandre Debut, Julien Chaumond, and\nThomas Wolf. 2019. DistilBERT, a Distilled Version\nof BERT: Smaller, Faster, Cheaper and Lighter. In\nProceeding of the NeurIPS EMC2Workshop.\nIan Tenney, Dipanjan Das, and Ellie Pavlick. 2019a.\nBERT Rediscovers the Classical NLP Pipeline. In\nProceedings of ACL.\nIan Tenney, Patrick Xia, Berlin Chen, Alex Wang, Adam\nPoliak, R Thomas McCoy, Najoung Kim, Benjamin\nVan Durme, Samuel R Bowman, Dipanjan Das, et al.\n2019b. What Do You Learn from Context? Prob-\ning for Sentence Structure in Contextualized Word\nRepresentations. arXiv preprint arXiv:1905.06316.\nTeun Adrianus Van Dijk and Walter Kintsch. 1983.\nStrategies of Discourse Comprehension. Academic\nPress New York.\nMarten Van Schijndel and Tal Linzen. 2018. Modeling\nGarden Path Effects without Explicit Hierarchical\nSyntax. In Proceedings of CogSci.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention Is All\nYou Need. Advances in Neural Information Process-\ning Systems, 30.\nBonnie Webber, Rashmi Prasad, Alan Lee, and Aravind\nJoshi. 2019. The Penn Discourse Treebank 3.0 An-\nnotation Manual. Philadelphia, University of Penn-\nsylvania, 35:108.\nEthan Wilcox, Roger Levy, Takashi Morita, and Richard\nFutrell. 2018. What Do RNN Language Mod-\nels Learn about Filler-gap Dependencies? arXiv\npreprint arXiv:1809.00042.\nMing Xiang and Gina Kuperberg. 2015. Reversing\nExpectations during Discourse Comprehension. Lan-\nguage, Cognition and Neuroscience, 30(6):648–672.\nKayo Yin and Graham Neubig. 2022. Interpreting Lan-\nguage Models with Contrastive Explanations. In\nProceedings of EMNLP.\nFrances Yung, Vera Demberg, and Merel Scholman.\n2019. Crowdsourcing Discourse Relation Annota-\ntions by a Two-step Connective Insertion Task. In\nProceedings of the ACL Linguistic Annotation Work-\nshop.\nRolf A Zwaan and Gabriel A Radvansky. 1998. Situa-\ntion Models in Language Comprehension and Mem-\nory. Psychological Bulletin, 123(2):162.\nA Appendix\nUpon request of the reviewers, we additionally re-\nrun the experiment by computing the sum of the\nSurprisal scores of the subtokens (Surp-sum) for\nout-of-vocabulary target verbs, instead of taking\nthe average.The findings are summarized in Tables\n10-11.\nThe results mostly show consistent patterns.\nCompared with the average of the surprisals of\nthe subtokens (Tables 7-8), with the sum the Dis-\nConn effect in inter-sentential nevertheless disap-\npears, while weakly-significant DisConn effects\nappear for the inter-sentential still and for the intra-\nsententials yet and however.\n232\neven so nevertheless nonetheless regardless still yet but however\nIntercept *** *** *** *** *** *** *** ***\nDisCohere *** *** *** *** *** *** *** ***\nDisConn *** ** ** ***\nlength * *\nDisCohere:\nDisConn *** *** *** *** *** *** *** ***\nTable 10: Extended INTER dataset: Summary table for the significance scores of different predictors of Surp-sum\nusing GPT-Neo. Notation: ∗ = p <0.05, ∗∗ = p <0.01, ∗ ∗ ∗= p <0.001.\neven so nevertheless nonetheless regardless still yet but however\nIntercept *** *** *** *** *** *** *** ***\nDisCohere *** *** *** *** *** *** *** ***\nDisConn *** *** *** *** *** * *\nlength * ** ** ** *\nDisCohere:\nDisConn *** *** *** *** *** *** *** ***\nTable 11: Extended INTRA dataset: Summary table for the significance scores of different predictors of Surp-sum\nusing GPT-Neo. Notation: ∗ = p <0.05, ∗∗ = p <0.01, ∗ ∗ ∗= p <0.001.",
  "topic": "Transformer",
  "concepts": [
    {
      "name": "Transformer",
      "score": 0.6468425989151001
    },
    {
      "name": "Computer science",
      "score": 0.6069135069847107
    },
    {
      "name": "Natural language processing",
      "score": 0.5671038031578064
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5498315691947937
    },
    {
      "name": "Natural language",
      "score": 0.41833579540252686
    },
    {
      "name": "Linguistics",
      "score": 0.39910152554512024
    },
    {
      "name": "Psychology",
      "score": 0.38387563824653625
    },
    {
      "name": "Engineering",
      "score": 0.07606199383735657
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I219193219",
      "name": "Purdue University West Lafayette",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I14243506",
      "name": "Hong Kong Polytechnic University",
      "country": "HK"
    },
    {
      "id": "https://openalex.org/I21491767",
      "name": "Aix-Marseille Université",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I1294671590",
      "name": "Centre National de la Recherche Scientifique",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I4210166510",
      "name": "Laboratoire Parole et Langage",
      "country": "FR"
    }
  ],
  "cited_by": 2
}