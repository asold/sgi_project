{
    "title": "A clinician-based comparative study of large language models in answering medical questions: the case of asthma",
    "url": "https://openalex.org/W4409825185",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A2126366521",
            "name": "Yong Yin",
            "affiliations": [
                "Shanghai Children's Medical Center",
                "Shanghai Jiao Tong University"
            ]
        },
        {
            "id": "https://openalex.org/A2097663438",
            "name": "Mei Zeng",
            "affiliations": [
                "Shanghai Children's Medical Center",
                "Shanghai Jiao Tong University"
            ]
        },
        {
            "id": "https://openalex.org/A2144412678",
            "name": "Hansong Wang",
            "affiliations": [
                "Shanghai Children's Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2114944853",
            "name": "Haibo Yang",
            "affiliations": [
                "Shanghai Children's Medical Center"
            ]
        },
        {
            "id": null,
            "name": "Caijing Zhou",
            "affiliations": [
                "Shanghai Children's Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2029655770",
            "name": "Feng Jiang",
            "affiliations": [
                "Shanghai Children's Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2158707720",
            "name": "Shufan Wu",
            "affiliations": [
                "Shanghai Children's Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A5101367135",
            "name": "Tingyue Huang",
            "affiliations": [
                "Shanghai Children's Medical Center"
            ]
        },
        {
            "id": null,
            "name": "Shuahua Yuan",
            "affiliations": [
                "Shanghai Jiao Tong University",
                "Shanghai Children's Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2097372184",
            "name": "Jilei Lin",
            "affiliations": [
                "Shanghai Children's Medical Center",
                "Shanghai Jiao Tong University"
            ]
        },
        {
            "id": "https://openalex.org/A2141810806",
            "name": "Mingyu Tang",
            "affiliations": [
                "Shanghai Children's Medical Center",
                "Shanghai Jiao Tong University"
            ]
        },
        {
            "id": "https://openalex.org/A2236336589",
            "name": "Jiande Chen",
            "affiliations": [
                "Shanghai Children's Medical Center",
                "Shanghai Jiao Tong University"
            ]
        },
        {
            "id": "https://openalex.org/A1895920807",
            "name": "Bin Dong",
            "affiliations": [
                "Shanghai Children's Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2758698167",
            "name": "Jiajun Yuan",
            "affiliations": [
                "Shanghai Children's Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A1978506503",
            "name": "Dan Xie",
            "affiliations": [
                "Shanghai Children's Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2126366521",
            "name": "Yong Yin",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2097663438",
            "name": "Mei Zeng",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2144412678",
            "name": "Hansong Wang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2114944853",
            "name": "Haibo Yang",
            "affiliations": []
        },
        {
            "id": null,
            "name": "Caijing Zhou",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2029655770",
            "name": "Feng Jiang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2158707720",
            "name": "Shufan Wu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A5101367135",
            "name": "Tingyue Huang",
            "affiliations": []
        },
        {
            "id": null,
            "name": "Shuahua Yuan",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2097372184",
            "name": "Jilei Lin",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2141810806",
            "name": "Mingyu Tang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2236336589",
            "name": "Jiande Chen",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1895920807",
            "name": "Bin Dong",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2758698167",
            "name": "Jiajun Yuan",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1978506503",
            "name": "Dan Xie",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4317356459",
        "https://openalex.org/W2949174534",
        "https://openalex.org/W2754219300",
        "https://openalex.org/W2029286390",
        "https://openalex.org/W3023997891",
        "https://openalex.org/W4381587418",
        "https://openalex.org/W4394956892",
        "https://openalex.org/W4392928544",
        "https://openalex.org/W4387500346",
        "https://openalex.org/W2887021901",
        "https://openalex.org/W4380730209",
        "https://openalex.org/W3146345129",
        "https://openalex.org/W2972320421",
        "https://openalex.org/W3174167596",
        "https://openalex.org/W4319662928",
        "https://openalex.org/W4386045865",
        "https://openalex.org/W4361289889",
        "https://openalex.org/W4377010360"
    ],
    "abstract": "Objective This study aims to evaluate and compare the performance of four major large language models (GPT-3.5, GPT-4.0, YouChat, and Perplexity) in answering 32 common asthma-related questions. Materials and methods Seventy-five clinicians from various tertiary hospitals participated in this study. Each clinician was tasked with evaluating the responses generated by the four large language models (LLMs) to 32 common clinical questions related to pediatric asthma. Based on predefined criteria, participants subjectively assessed the accuracy, correctness, completeness, and practicality of the LLMs' answers. The participants provided precise scores to determine the performance of each language model in answering pediatric asthma-related questions. Results GPT-4.0 performed the best across all dimensions, while YouChat performed the worst in all dimensions. Both GPT-3.5 and GPT-4.0 outperformed the other two models, but there was no significant difference in performance between GPT-3.5 and GPT-4.0 or between YouChat and Perplexity. Conclusion GPT and other large language models can answer medical questions with a certain degree of completeness and accuracy. However, clinical physicians should critically assess internet information, distinguishing between true and false data, and should not blindly accept the outputs of these models. With advancements in key technologies, LLMs may one day become a safe option for doctors seeking information.",
    "full_text": "EDITED BY\nThomas F. Heston,\nUniversity of Washington, United States\nREVIEWED BY\nMasaomi Motegi,\nJikei University School of Medicine, Japan\nDalal Alabdulmohsen,\nKing Faisal University, Saudi Arabia\nRunhan Shi,\nFudan University, China\n*\nCORRESPONDENCE\nDan Xie\nxie_dan1980@163.com\nBin Dong\ndongbin@scmc.com.cn\nJiajun Yuan\nyuanjiajun@scmc.com.cn\n† These authors have contributed equally to\nthis work\nRECEIVED 10 July 2024\nACCEPTED 07 April 2025\nPUBLISHED 25 April 2025\nCITATION\nYin Y, Zeng M, Wang H, Yang H, Zhou C,\nJiang F, Wu S, Huang T, Yuan S, Lin J, Tang M,\nChen J, Dong B, Yuan J and Xie D (2025) A\nclinician-based comparative study of large\nlanguage models in answering medical\nquestions: the case of asthma.\nFront. Pediatr. 13:1461026.\ndoi: 10.3389/fped.2025.1461026\nCOPYRIGHT\n© 2025 Yin, Zeng, Wang, Yang, Zhou, Jiang,\nWu, Huang, Yuan, Lin, Tang, Chen, Dong, Yuan\nand Xie. This is an open-access article\ndistributed under the terms of theCreative\nCommons Attribution License (CC BY). The\nuse, distribution or reproduction in other\nforums is permitted, provided the original\nauthor(s) and the copyright owner(s) are\ncredited and that the original publication in\nthis journal is cited, in accordance with\naccepted academic practice. No use,\ndistribution or reproduction is permitted\nwhich does not comply with these terms.\nA clinician-based comparative\nstudy of large language models in\nanswering medical questions:\nthe case of asthma\nYong Yin\n1,2,3,4†\n, Mei Zeng\n2†\n, Hansong Wang\n5†\n, Haibo Yang\n1\n,\nCaijing Zhou\n1\n, Feng Jiang\n1\n, Shufan Wu\n1\n, Tingyue Huang\n1\n,\nShuahua Yuan\n2\n, Jilei Lin\n2,3,4\n, Mingyu Tang\n2\n, Jiande Chen\n2\n,\nBin Dong\n3,4,6*, Jiajun Yuan\n3,4,7* and Dan Xie\n1*\n1Department of Respiratory Medicine, Hainan Branch, Shanghai Children's Medical Center, School of\nMedicine, Shanghai Jiao Tong University, Sanya, China,2Department of Respiratory Medicine, Shanghai\nChildren’s Medical Center, Shanghai Jiao Tong University School of Medicine, Shanghai, China,\n3Pediatric AI Clinical Application and Research Center, Shanghai Children’s Medical Center, Shanghai,\nChina, 4Shanghai Engineering Research Center of Intelligence Pediatrics (SERCIP), Shanghai, China,\n5Department of Performance, Shanghai Children’s Medical Center, Shanghai Jiao Tong University\nSchool of Medicine, Shanghai, China,6Department of Discipline Inspection and Supervision, Shanghai\nChildren’s Medical Center, Shanghai Jiao Tong University School of Medicine, Shanghai, China,\n7Medical Department of Shanghai Children’s Medical Center, Shanghai Jiao Tong University School of\nMedicine, Shanghai, China\nObjective: This study aims to evaluate and compare the performance of four\nmajor large language models (GPT-3.5, GPT-4.0, YouChat, and Perplexity) in\nanswering 32 common asthma-related questions.\nMaterials and methods: Seventy-ﬁve clinicians from various tertiary hospitals\nparticipated in this study. Each clinician was tasked with evaluating the\nresponses generated by the four large language models (LLMs) to 32 common\nclinical questions related to pediatric asthma. Based on predeﬁned criteria,\nparticipants subjectively assessed the accuracy, correctness, completeness,\nand practicality of the LLMs’ answers. The participants provided precise scores\nto determine the performance of each language model in answering pediatric\nasthma-related questions.\nResults: GPT-4.0 performed the best across all dimensions, while YouChat\nperformed the worst in all dimensions. Both GPT-3.5 and GPT-4.0\noutperformed the other two models, but there was no signiﬁcant difference in\nperformance between GPT-3.5 and GPT-4.0 or between YouChat and\nPerplexity.\nConclusion: GPT and other large language models can answer medical\nquestions with a certain degree of completeness and accuracy. However,\nclinical physicians should critically assess internet information, distinguishing\nbetween true and false data, and should not blindly accept the outputs of\nthese models. With advancements in key technologies, LLMs may one day\nbecome a safe option for doctors seeking information.\nKEYWORDS\nlarge language models (LLMs), pediatric asthma, medical question answering, clinical\ndecision support, AI in healthcare\nTYPE Original Research\nPUBLISHED 25 April 2025\nDOI 10.3389/fped.2025.1461026\nFrontiers inPediatrics 01 frontiersin.org\n1 Introduction\nAsthma is a major chronic respiratory disease worldwide,\naffecting the health and quality of life of millions of people. In a\nmultinational, multicenter studyinvolving 453,473 subjects, it was\nfound that 6.3% of children, 7.9% of adolescents, and 3.4% of\nadults were diagnosed with asthma by a doctor. Moreover, in\nmiddle-to-low-income countries, many individuals with severe\nasthma symptoms were not using inhaled corticosteroids (1). In\nChina, 15.5% of asthma patients reported at least one emergency\nroom visit, and 7.2% of patients reported at least one hospitalization\ndue to worsening respiratory symptoms (2). Despite receiving high-\nintensity treatment, most children with poorly controlled symptoms\ncan achieve improved asthma control when they adhere to the basic\nprinciples of asthma management (3). Frequent and severe asthma\nattacks can be fatal, and effective asthma management and\ntreatment require close cooperation between patients, doctors, and\ncaregivers. Therefore, improving the provision of accurate health\ninformation and personalized counseling is crucial for the self-\nmanagement of asthma patients.\nA survey of online health behaviors of Americans revealed that\nmore than one-third of Americans turn to the Internet to diagnose\nhealth problems (4). Large Language Models (LLMs), such as GPT,\nare AI tools designed to process and generate text. They have been\nwidely applied to various tasks and have demonstrated excellent\nperformance in the medical ﬁeld (5). LLMs will increasingly be\nused for information retrieval, automated summarization of\nliterature notes, answering medical questions, and even as\ninteractive tools in medical education (6, 7). This not only helps\npatients access important disease-related information more\nquickly but also supports the decision-making process of\nhealthcare professional (8). However, Information errors, privacy\nissues, and ethical challenges and potential harm to patient care\nremain signiﬁcant challenges (9). Ethical issues, including data\nprivacy and breaches, must be addressed. In both medical and\nnon-medical education, students are vulnerable to\nmisinformation, hindering the development of critical thinking\nskills. The lack of mechanisms to ensure the accuracy of LLM\noutputs limits their use in clinical settings, where misinformation\ncan have fatal consequences (7).\nIn this study, we aim to evaluate and compare the performance\nof four selected Large Language Models (GPT-3.5, GPT-4.0,\nYouChat, and Perplexity) in answering clinical questions related\nto pediatric asthma. The evaluation includes four dimensions:\naccuracy, precision, completeness, and practicality, combined\nwith insights from professionals for a comprehensive assessment.\nOur ﬁndings may provide valuable insights into the clinical\napplication of LLMs as medical auxiliary tools and promote\nclinical decision-making.\n2 Article type\nThis study is an Original Research Article that evaluates and\ncompares the performance of four major large language models\n(GPT-3.5, GPT-4.0, YouChat, and Perplexity) in answering 32\ncommon asthma-related questions.\n3 Material and methods\n3.1 Model selection\nBased on previous research, user volume, and training\nmethodologies, this study selected four models for investigation:\nChatGPT 3.5, ChatGPT 4.0, YouChat, and Perplexity. ChatGPT 3.5\nand ChatGPT 4.0 were trained on predeﬁned datasets and did not\nconnect to the internet after their launch. ChatGPT 4.0 utilizes a\nmore extensive and diverse pre-training dataset compared to\nChatGPT 3.5, along with advanced training techniques such as\nmore effective model optimization algorithms and smarter\nparameter initialization methods. The version of YouChat used in\nthis study is the basic version, which extends ChatGPT 3.5 by\nintegrating an internet search function. Similarly, the Perplexity\nversion used is the basic one, functioning as an AI-powered search\nengine that combines proprietary language models with real-time\nweb retrieval to generate responses.\n3.2 Question selection and answering with\nlarge language models\nThe equations should be inserted in editable format from the\nequation editor. We selected 32 common asthma-related questions\nfrom the article “One hundred key issues on Chinese Children’s\nAsthma Action Plan” published in the Chinese Journal of Practical\nPediatrics to test the model (10). On the one hand, these questions\nwere selected after consultation with three pediatric respiratory\nasthma experts and re ﬂected the main aspects of asthma\nmanagement, such as diagnosis, treatment, prevention and follow-\nup. On the other hand, the selection process was designed to cover\nessential topics related to the concerns of clinicians and patients\nand their families in the clinical setting. All questions were posed\nand recorded in Chinese, and we translated them into English for\npresentation (seeTable 1). The prompt for all models was set as:\n“Assume you are an expert in the ﬁeld of pediatrics, and the\nfollowing questions are all related to pediatrics. Please answer the\nfollowing questions in less than 500 words.” The questions were\ninputted in the exact same order and content for all models. To\nensure consistency and eliminate potential inﬂuence on clinician\nratings, we manually removed all hyperlinks, quotation marks, and\nweb-related formatting from all model responses. All answers were\npresented in a uniform plain textformat and model identities were\nanonymized. This standardization ensured that assessments were\nbased solely on the accuracy, correctness, completeness, and utility\nof the content, and not on the presence or absence of supporting\nlinks or reference formats. To evaluate the internal stability of the\nmodels, we created ﬁve dialogues using the same input method.\nThe project team members jointly assessed the stability of theﬁve\nresponses, and the results were recorded on a ten-point scale, with\na minimum of 1 and a maximum of 10.\nYin et al. 10.3389/fped.2025.1461026\nFrontiers inPediatrics 02 frontiersin.org\n3.3 Model evaluation dimensions\nThis study designed the questionnaire from the perspective of\ndoctors. The questionnaire evaluates the responses of different\nmodels based on four dimensions: “accuracy,”“ correctness,”\n“completeness,” and “practicality.”“ Accuracy” is deﬁned as the\ndegree to which the model’s answer is relevant to the question,\nreﬂecting the model ’s ability to understand the user ’s query.\n“Correctness” refers to the extent to which the model’s answer\naligns with the clinical experience and guidelines of the\nrespondents. “Completeness” is deﬁned as the thoroughness of\nthe model ’s answer compared to clinical experience and\nguidelines. “Practicality” refers to the extent to which the model’s\nanswer is applicable in daily clinical practice, re ﬂecting the\nmodel’s ability to solve real-world problems. The results are\nrecorded on a ten-point scale, with“unable to answer” responses\nscored as 0 and other answers scored between 1 and 10. The\ndeﬁnitions of the four evaluation dimensions are placed on the\nﬁrst page of the questionnaire to clearly inform the respondents\nand facilitate accurate evaluation.\n3.4 Questionnaire design\nEach questionnaire contained thirty-two questions, arranged in\nthe same order, with answers generated by different large language\nmodels. Participants were instructed to provide clear and\nunambiguous answers based on existing clinical guidelines. The\nfour model-generated answers for each question were presented\nin random order, and participants were not informed which\nmodel corresponded to each answer. To improve the quality of\nquestionnaire completion, we set a time limit for answering the\nquestions. The questionnaires were then distributed in paper\nform to 75 clinicians and collected uniformly. This study was\nconducted from January to May 2024.\n3.5 Participant inclusion\nThe evaluators in this study met the following criteria: (1) Hold\na Master’s degree in medicine or higher; (2) be under 60 years of\nage; (3) Have worked in the pediatric department of a\ntertiary hospital.\n3.6 Questionnaire quality control\nWe implemented quality control for the questionnaires based\non the following criteria: (1) Assigning a high score to responses\nwith obvious errors/de ﬁciencies was considered one quality\ncontrol anomaly; (2) Completing the questionnaire in less than\n2 h was counted as one quality control anomaly; (3) Having\nthree responses with clearly outlier scores was counted as one\nquality control anomaly. If there were fewer than three such\nscores, it was counted as three instances. A sample was deemed\nto have failed quality control if it exhibited ﬁve instances of\nquality control anomalies. Only samples that passed quality\ncontrol were included in the analysis.\n3.7 Inter-rater reliability analysis\nTo assess the consistency of raters in rating different models,\nwe conducted an inter-rater reliability analysis using the\nIntraclass Correlation Coefﬁcient (ICC). The ICC is a widely\nused metric to measure the level of agreement between raters\nwhen rating continuous data. In this study, ICC values were\ncalculated for four rating aspects — accuracy, completeness,\nTABLE 1 Questions used to test the performance of LLMs.\n32 Questions Related to Childhood Asthma\nQuestion 1 What is asthma?\nQuestion 2 Is asthma hereditary?\nQuestion 3 What are the differences and similarities between asthma in\nchildren and adult asthma?\nQuestion 4 What are the clinical features of asthma in children?\nQuestion 5 How is bronchial asthma in children diagnosed?\nQuestion 6 Can recurrent wheezing in infancy develop into asthma?\nQuestion 7 What are the comorbid conditions of asthma?\nQuestion 8 What impact does allergic rhinitis (AR) have on asthma?\nQuestion 9 What are the common tests for childhood asthma?\nQuestion 10 Can childhood asthma be cured?\nQuestion 11 Does long-term ICS treatment affect the growth and development\nof children?\nQuestion 12 Which children with asthma are eligible for allergen speciﬁc\nimmune therapy (AIT)?\nQuestion 13 Which children with asthma are eligible for biological treatments\nsuch as monoclonal antibodies?\nQuestion 14 Why is it important to manage asthma in children?\nQuestion 15 Why should children with asthma have regular follow-up visits to\nthe hospital? How often should these visits occur?\nQuestion 16 What are the main components of follow-up visits for children\nwith asthma?\nQuestion 17 What are the early preventive measures for asthma?\nQuestion 18 What are common allergens? Why do children with asthma need\nallergen testing?\nQuestion 19 What are dust mites? How can dust mite allergies be prevented?\nQuestion 20 Which pet dander is likely to cause allergies?\nQuestion 21 How can pollen allergies be managed?\nQuestion 22 Can children with asthma receive vaccinations?\nQuestion 23 What is the relationship between asthma attacks and upper\nrespiratory infections?\nQuestion 24 Can children with asthma exercise? How should they exercise?\nQuestion 25 Can exercise induce asthma attacks? How can exercise-induced\nasthma attacks be prevented?\nQuestion 26 What climate changes are likely to trigger asthma attacks? How\ncan these be prevented?\nQuestion 27 What are the adverse effects of cigarette smoke exposure on\nchildren with asthma? How can this be prevented?\nQuestion 28 What factors are likely to cause acute asthma attacks during\noutdoor activities or travel?\nQuestion 29 What signs can predict an acute attack of asthma in children?\nQuestion 30 How can the severity of an acute asthma attack in children be\nassessed?\nQuestion 31 How can severe acute asthma attacks be prevented?\nQuestion 32 What emergency medications should be readily available at home\nor nearby for children with asthma?\nYin et al. 10.3389/fped.2025.1461026\nFrontiers inPediatrics 03 frontiersin.org\ncorrectness and practicality— using different models. Higher ICC\nvalues indicate better agreement between raters. Theﬁnal results\nare shown inSupplementary Figure S1, where it can be observed\nthat Perplexity and YouChat provided the most consistent\nratings, with ICC values ranging from 0.85 –0.91 across all\naspects, indicating a high level of inter-rater agreement. In\ncontrast, GPT-4.0 showed the greatest variation in raters’ scores,\nparticularly for Correctness and Practicality.\n3.8 Statistical analysis\nAll data analysis was conducted using R 4.3.3. To\ncomprehensively understand the responses of the four major\nlanguage models to asthma-related clinical questions, we\ncalculated the average score for each question answered by each\nmodel and presented the results through bar charts. Next, we\ncalculated the average score for each model across all evaluative\ndimensions per question to examine the distinct responses\nprovided by each model. Sankey diagrams were used to describe\nthe commonalities and differences in cumulative scores for the\ntop ﬁve and bottom ﬁve questions among the four models. To\nassess differences between the models, we ﬁrst determined the\naverage score for each question across different models and then\nperformed hypothesis testing using Tukey ’s post hoc test. We\nthen used Tukey’s post hoc test to compare the performance of\nthe four models across various dimensions. Finally, we utilized\nTukey’s post hoc test to evaluate the signiﬁcance of differences\nwithin each model across different dimensions.\n4 Results\n4.1 Questionnaire distribution and recall\nThe research distributed a total of 75 questionnaires, all of\nwhich were returned and passed quality control, yielding a\nqualiﬁcation rate of 100%.\n4.2 Evaluation of LLMs’ performance\nTable 1lists all the questions included in the 32 questionnaires.\nFigure 1 shows the ﬂowchart of the study. Figure 2 shows the\nresponses of the large language models (LLMs) to all questions.\nIn the questionnaires, the median score for all questions\nanswered by the LLMs was 7.9, with the highest scores for\nquestions 26, 14, 2, 16, and 18, and the lowest scores for\nquestions 6, 12, 22, 13, and 4. This indicates that the LLMs\nperformed excellently in addressing the genetic causes,\nmanagement strategies, and prevention of childhood asthma, but\nshowed some weaknesses in addressing the clinical\ncharacteristics, early diagnosis, and speciﬁc treatments (such as\nallergen-speciﬁc immunotherapy and monoclonal antibody\ntreatments) for childhood asthma.\nFigure 3 displays the scores of different models on each\nquestion. ChatGPT 3.5 and ChatGPT 4.0 had higher median\nscores, both at 8.1, while Perplexity and YouChat had lower\nmedian scores, at 7.7 and 7.6, respectively.\nFigure 4illustrates the differences and similarities between the\ntop ﬁve and bottomﬁve questions answered by the various models.\nOur ﬁndings indicate that multiple models demonstrated\nproﬁciency in answering questions 2, 14, 18, and 26, suggesting\nthat LLMs are more adept at addressing questions related to\ngenetic causes, management measures, and the prevention of\nchildhood asthma. The GPT 4.0 demonstrated particular\nproﬁciency in responding to the questions with the highest\nscores. However, in the case of the questions with the lowest\nscores, multiple models exhibited less impressive performance on\nquestions 6, 12, 22, and 32. This indicates that the LLMs (even\nwith GPT 4.0) were less adept at answering questions pertaining\nto early identi ﬁcation and prevention of childhood asthma,\npersonalized treatment, prevention, and emergency\ncare management.\n4.3 Comparison in different dimensions of\neach model\nFigure 5illustrates the average scores of different models across\nall questions. GPT 3.5 and GPT 4.0 signiﬁcantly outperformed\nPerplexity and You Chat, exhibiting more stable and higher\nscores. There was no signi ﬁcant difference in performance\nbetween GPT 3.5 and GPT 4.0, with their median scores being\nnearly identical. Similarly, there was no signi ﬁcant difference\nbetween Perplexity and You Chat, with their median scores being\nclose to each other.\nFigure 6 shows that the GPT-4.0 performed better on all four\nassessment dimensions, although statistical analyses showed no\nsigniﬁcant difference between the GPT-4.0 and GPT-3.5.\nConversely, YouChat had the lowest performance in all aspects,\nputting it at a disadvantage compared to the other three models.\nFIGURE 1\nFlowchart.\nYin et al. 10.3389/fped.2025.1461026\nFrontiers inPediatrics 04 frontiersin.org\n5 Discussions\nArtiﬁcial intelligence is increasingly being applied in various\nmedical projects, including radiological image analysis ( 11),\naiding diagnosis in complex cases (12), personalized treatment\n(13), anesthesia depth monitoring and control ( 14), and drug\ndevelopment and utilization (15). A study evaluated ChatGPT’s\nperformance on the United States Medical Licensing\nExamination (USMLE), and the results showed that ChatGPT\nmet or nearly met the passing threshold without any specialized\ntraining or reinforcement (16). The LLM demonstrated strong\nperformance in making ﬁnal diagnoses across 36 clinical cases,\nachieving an accuracy rate of 76.9% (17). Importantly, compared\nto other decision support tools, LLMs not only incorporate more\npatient-speciﬁc information to generate more targeted\nrecommendations but also encourage brainstorming, prompting\ndoctors to consider diagnoses and treatments they might\notherwise overlook. These results suggest that large language\nmodels may have the potential to aid in medical education and\nassist in clinical decision-making.\nIn this study, all the major language models performed well in\nanswering a range of clinically relevant questions, with particular\nexcellence in the areas of asthma causes, treatment and\nprevention. This is probably because these topics are of greater\npublic interest and there are more sources of information\navailable, resulting in more training data and consequently\nhigher scores. For asthma diagnosis and new treatments, the\nLLMs showed less stable performance, indicating a need for\nmore recent data training in these areas.\nGPT and other large language models can answer medical\nquestions with a certain degree of completeness and accuracy. Our\nresults indicate that while GPT-4.0 demonstrated the highest scores\nacross all dimensions, the statistical analysis revealed no signiﬁcant\ndifference between GPT-4.0 and GPT-3.5. This suggests that both\nmodels perform comparably in medical question answering, and the\nchoice between them may depend on factors beyond numerical\nscores. Despite this, we still recommend GPT-4.0 due to its\nqualitative advantages over GPT-3.5, including a larger database,\nmore advanced training data, improved model architecture, and\nbetter integration with clinical guidelines. These factors enable GPT-\n4.0 to understand and generate more accurate and effective\ninformation. Additionally, qualitative feedback from clinicians\nsuggests that GPT-4.0 provides smoother and more contextually\nrelevant responses, making it more reliable in real-world medical\nscenarios. In the top ﬁve questions (Question 5: Is asthma\nhereditary? Question 8: What is the impact of allergic rhinitis (AR)\non asthma? Question 25: Can exercise induce asthma attacks? How\nto prevent exercise-induced asthma attacks? Question 26: What\nclimate changes can trigger asthma attacks? How to prevent them?\nQuestion 27: What adverse effects does cigarette exposure have on\nchildren with asthma? How to prevent them?), GPT-4.0 did an\nexcellent job of answering questions about asthma heredity, triggers,\nand preventive measures. However, GPT-4.0 showed weaker\ncapabilities in handling questions related to asthma management\nFIGURE 2\nThe average score of each question for all models.\nYin et al. 10.3389/fped.2025.1461026\nFrontiers inPediatrics 05 frontiersin.org\nFIGURE 4\nSankey diagram of the questionnaire.\nFIGURE 3\nThe average score of each question for different models.\nYin et al. 10.3389/fped.2025.1461026\nFrontiers inPediatrics 06 frontiersin.org\n(vaccination) and treatment strategies (including emergency,\nimmunotherapy, or biologic treatments). For some new asthma\ntreatments, such as desensitization therapy and monoclonal antibody\ntherapies, future model training should emphasize updating the\ndatabase in these areas. If LLMs could be trained by reliable experts,\nit could rapidly improve and transform the dissemination of medical\nknowledge. Providing more and more disease information through\nLLMs could help address the growing prevalence of asthma.\nAlthough YouChat performed the worst of all models, it\nsigniﬁcantly outperformed the other three models in answering\nquestions about accurately diagnosing asthma (Question 9: What\nare common tests for childhood asthma?) and identifying and\nmanaging allergens (Question 18: What are common allergens?\nWhy do children with asthma need allergen testing?). These\ninterventions are complementary and form a systematic approach to\ncomprehensive asthma management, demonstrating that each\nmodel has strengths in different aspects of disease management.\nHowever, there are several limitations to this study. First, the\nsample size is relatively small (75 doctors), which may affect\nthe generalizability of the results. Second, there may be biases in the\nquestionnaire design, as the selection and phrasing of questions could\ninﬂuence the models’ responses. Additionally, this study focuses\nsolely on pediatric asthma questions, different medical domains\nmight yield different results. Future research could expand the\nsample size and diversity of questions to improve the generalizability\nand reliability of theﬁndings. It may also consider evaluating the\nmodels’ performance in various medicalﬁelds (e.g., hypertension,\nFIGURE 5\nComparison of average scores across all dimensions between models.\nFIGURE 6\nComparison of average scores across different dimensions between models.\nYin et al. 10.3389/fped.2025.1461026\nFrontiers inPediatrics 07 frontiersin.org\ndiabetes) to gain a comprehensive understanding of their potential\napplications in medicine. Furthermore, research could explore ways\nto further enhance the training data and model architecture to\nimprove their performance in specializedﬁelds. Although the models\nperformed well in this study, in practice, LLMs may give incorrect\nresponses when faced with prompts that do not have a single correct\nanswer, and if they present these responses in a convincing manner,\nusers might believe their accuracy (18). Therefore, in practical use,\ndoctors should use LLMs as supplementary and enhanced support\nrather than relying solely on their responses (19).\nWhile ourﬁndings suggest that large language models (LLMs) such\nas GPT-4.0 have great potential as tools for clinical decision support, it\nis important to recognize the ethical risks and challenges they pose—\nparticularly the risk of misinformation. For example, if an LLM\nsuggests the use of an outdated or contraindicated asthma\nmedication without considering the clinical context, this could lead\nto harmful outcomes-especially if the recommendation is followed\nwithout expert review. From an ethical perspective, the use of LLMs\nalso raises questions about responsibility and accountability. Unlike\nhuman clinicians, LLMs do not have intent, awareness, or\nprofessional responsibility, making it difﬁcult to determine who is\nliable if AI-generated content causes harm. In addition, LLMs\nresponses may reﬂect biases in their training data or generate\ninformation that sounds accurate but not to. To mitigate these risks,\nseveral strategies should be implemented: (1) Human oversight: All\nLLM-generated content should be reviewed by qualiﬁed healthcare\nprofessionals before being used in clinical practice. (2) Transparency\nand interpretability: Developers should improve how LLMs explain\ntheir answers and ensure that the system canﬂag low-conﬁdence or\nuncertain answers. (3) User training: Clinicians and other users\nshould be trained to understand the limitations of LLMs and to use\ntheir results critically. (4) Ongoing monitoring: The performance of\nLLMs should be regularly reviewed in real-world settings to ensure\ncontinued safety and accuracy.\nBased on the above, doctors still need to receive proper education\nand continuously update their knowledge through various traditional\nevidence-based educational methods. It is crucial to apply critical\nthinking to the information provided by LLMs and regard it as a\nsupplement to their clinical knowledge and experience. Otherwise,\nclinicians can be easily misled. Currently, whether in terms of data\nor training, large language models do not seem capable of replacing\nthe unique intellectual abilities of humans. Clinicians need to be\nvery vigilant and apply all evaluative and critical measures to the\ninformation provided before establishing such tools as support for\nclinical decision-making. In the future, with advancements in key\ntechnologies and the resolution of diagnostic blind spots and data\nprivacy issues, large language models have the potential to become\nimportant tools for improving human healthcare.\n6 Conclusion\nGPT and other large language models can answer medical\nquestions with a certain degree of completeness and accuracy.\nHowever, clinical physicians should critically assess internet\ninformation, distinguishing between true and false data, and\nshould not blindly accept the outputs of these models. With\nadvancements in key technologies, LLMs may one day become a\nsafe option for doctors seeking information.\nData availability statement\nThe raw data supporting the conclusions of this article will be\nmade available by the authors, without undue reservation.\nAuthor contributions\nYY: Writing – original draft, Writing – review & editing,\nConceptualization, Data curation, Formal analysis, Software,\nVisualization. MZ: Writing– original draft, Writing – review &\nediting, Conceptualization, Data curation, Formal analysis, Software,\nVisualization. HW: Writing– original draft, Writing– review &\nediting, Conceptualization, Data curation, Formal analysis, Software,\nVisualization. HY: Investigation, Writing– review & editing, Data\ncuration, Formal analysis, Supervision. CZ: Investigation, Writing–\nreview & editing, Data curation, Formal analysis, Software. FJ:\nInvestigation, Supervision, Writing– review & editing, Data curation,\nFormal analysis. SW: Investigation, Supervision, Writing– review &\nediting, Data curation, Formal analysis. TH: Data curation, Formal\nanalysis, Investigation, Supervision, Writing– review & editing. SY:\nData curation, Formal analysis, Investigation, Supervision, Writing–\nreview & editing. JL: Data curation, Formal analysis, Investigation,\nSupervision, Writing– review & editing. MT: Data curation, Formal\nanalysis, Investigation, Supervision, Writing– review & editing. JC:\nData curation, Formal analysis, Investigation, Supervision, Writing–\nreview & editing. BD: Conceptualization, Data curation, Validation,\nSupervision, Writing – review & editing. JY: Data curation,\nValidation, Conceptualization, Supervision, Writing – review &\nediting. DX: Conceptualization, Data curation, Validation,\nSupervision, Writing– original draft, Writing– review & editing.\nFunding\nThe author(s) declare thatﬁnancial support was received for\nthe research and/or publication of this article. This work was\nsupported by Fundamental Research Funds for the Central\nUniversities (YG2024ZD20), Fundamental Research Funds for the\nCentral Universities (YG2024QNB25), Fundamental Research Funds\nfor the Central Universities (YG2022QN095), Shanghai Municipal\nHealth Commission Healthcare Industry Clinical Research Special\nProject (20224Y0180); Shanghai Municipal Science and Technology\nCommission ‘Yangfan Plan’ (23YF1425100); Pudong New Area\nScience, Technology Development Fund Livelihood Research Special\nFund Healthcare Project (PKJ2023-Y50), Shanghai Pudong New\nArea Science and Technology Development Fund Livelihood\nResearch Special Fund Healthcare Project (PKJ2023-Y49) and\nThree-year action plan for strengthening the construction of the\npublic health system in Shanghai (GWVI- 11.2- YQ58).\nYin et al. 10.3389/fped.2025.1461026\nFrontiers inPediatrics 08 frontiersin.org\nConﬂict of interest\nThe authors declare that the research was conducted in the\nabsence of any commercial or ﬁnancial relationships that could\nbe construed as a potential conﬂict of interest.\nPublisher’s note\nAll claims expressed in this article are solely those of the\nauthors and do not necessarily represent those of their afﬁliated\norganizations, or those of the publisher, the editors and the\nreviewers. Any product that may be evaluated in this article, or\nclaim that may be made by its manufacturer, is not guaranteed\nor endorsed by the publisher.\nSupplementary material\nThe Supplementary Material for this article can be found\nonline at: https://www.frontiersin.org/articles/10.3389/fped.2025.\n1461026/full#supplementary-material\nReferences\n1. García-Marcos L, Chiang C-Y, Asher MI, Marks GB, El Sony A, Masekela R, et al.\nAsthma management and control in children, adolescents, and adults in 25 countries:\na global asthma network phase I cross-sectional study.Lancet Glob Health. (2023)\n11(2):e218–e28. doi: 10.1016/S2214-109X(22)00506-X\n2. Huang K, Yang T, Xu J, Yang L, Zhao J, Zhang X, et al. Prevalence, risk factors,\nand management of asthma in China: a national cross-sectional study.Lancet. (2019)\n394(10196):407–18. doi: 10.1016/S0140-6736(19)31147-X\n3. Pike KC, Levy ML, Moreiras J, Fleming L. Managing problematic severe asthma:\nbeyond the guidelines.Arch Dis Child. (2018) 103(4):392–7. doi: 10.1136/archdischild-\n2016-311368\n4. Kuehn BM. More than one-third of US individuals use the internet to self-\ndiagnose. JAMA. (2013) 309(8):756–7. doi: 10.1001/jama.2013.629\n5. Schwalbe N, Wahl B. Artiﬁcial intelligence and the future of global health.Lancet.\n(2020) 395(10236):1579–86. doi: 10.1016/S0140-6736(20)30226-9\n6. Tian S, Jin Q, Yeganova L, Lai P-T, Zhu Q, Chen X, et al. Opportunities and\nchallenges for ChatGPT and large language models in biomedicine and health.Brief\nBioinform. (2023) 25(1):bbad493. doi: 10.1093/bib/bbad493\n7. Lucas HC, Upperman JS, Robinson JR. A systematic review of large language models\nand their implications in medical education.Med Educ. (2024) 58(11):1276–85. doi: 10.\n1111/medu.15402\n8. Liu S, McCoy AB, Wright AP, Carew B, Genkins JZ, Huang SS, et al. Leveraging\nlarge language models for generating responses to patient messages-a subjective\nanalysis. J Am Med Inform Assoc. (2024) 31(6):1367–79. doi: 10.1093/jamia/ocae052\n9. Clusmann J, Kolbinger FR, Muti HS, Carrero ZI, Eckardt J-N, Laleh NG, et al.\nThe future landscape of large language models in medicine.Commun Med (Lond).\n(2023) 3(1):141. doi: 10.1038/s43856-023-00370-1\n10. Diseases CNCRCfR, Cooperative Group of Asthma tSGoR, the Society of\nPediatrics, Chinese Medical Association, Pediatrics CMEACo, Pediatrics\nCMDACoR, Pediatrics CRHACo, Pediatrics CN-GMIACo, et al. One hundred key\nissues on Chinese children ’s asthma action plan. Chin J Pract Pediatr . (2021)\n36(7):491–513.\n11. Savadjiev P, Chong J, Dohan A, Vakalopoulou M, Reinhold C, Paragios N,\net al. Demystiﬁcation of AI-driven medical image interpretation: past, present and\nfuture. Eur Radiol. (2019) 29(3):1616–24. doi: 10.1007/s00330-018-5674-x\n12. Kanjee Z, Crowe B, Rodman A. Accuracy of a generative artiﬁcial intelligence\nmodel in a complex diagnostic challenge.JAMA. (2023) 330(1):78–80. doi: 10.1001/\njama.2023.8288\n13. Bhinder B, Gilvary C, Madhukar NS, Elemento O. Artiﬁcial intelligence in\ncancer research and precision medicine.Cancer Discov. (2021) 11(4):900–15.\n14. Hashimoto DA, Witkowski E, Gao L, Meireles O, Rosman G. Arti ﬁcial\nintelligence in anesthesiology: current techniques, clinical applications, and\nlimitations. Anesthesiology\n. (2020) 132(2):379 –94. doi: 10.1097/ALN.\n0000000000002960\n15. Liu Z, Roberts RA, Lal-Nag M, Chen X, Huang R, Tong W. AI-based language\nmodels powering drug discovery and development. Drug Discov Today . (2021)\n26(11):2593–607. doi: 10.1016/j.drudis.2021.06.009\n16. Kung TH, Cheatham M, Medenilla A, Sillos C, De Leon L, Elepaño C, et al.\nPerformance of ChatGPT on USMLE: potential for AI-assisted medical education\nusing large language models.PLOS Digit Health. (2023) 2(2):e0000198.\n17. Rao A, Pang M, Kim J, Kamineni M, Lie W, Prasad AK, et al. Assessing the\nutility of ChatGPT throughout the entire clinical work ﬂow: development and\nusability study. J Med Internet Res. (2023) 25:e48659. doi: 10.2196/48659\n18. Lee P, Bubeck S, Petro J. Beneﬁts, limits, and risks of GPT-4 as an AI Chatbot for\nmedicine. N Engl J Med. (2023) 388(13):1233–9. doi: 10.1056/NEJMsr2214184\n19. Mello MM, Guha N. ChatGPT and physicians’ malpractice risk. JAMA Health\nForum. (2023) 4(5):e231938. doi: 10.1001/jamahealthforum.2023.1938\nYin et al. 10.3389/fped.2025.1461026\nFrontiers inPediatrics 09 frontiersin.org"
}