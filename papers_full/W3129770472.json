{
    "title": "Hate-Alert@DravidianLangTech-EACL2021: Ensembling strategies for Transformer-based Offensive language Detection",
    "url": "https://openalex.org/W3129770472",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A5089249992",
            "name": "Debjoy Saha",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5045300929",
            "name": "Naman Paharia",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5045600140",
            "name": "Debajit Chakraborty",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5090711711",
            "name": "Punyajoy Saha",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5020991141",
            "name": "Animesh Mukherjee",
            "affiliations": [
                null
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2056132907",
        "https://openalex.org/W3030198970",
        "https://openalex.org/W2967734965",
        "https://openalex.org/W2908510526",
        "https://openalex.org/W3154077674",
        "https://openalex.org/W2970971581",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W2116873850",
        "https://openalex.org/W1836465849",
        "https://openalex.org/W3032237992",
        "https://openalex.org/W3000571327",
        "https://openalex.org/W2783792814",
        "https://openalex.org/W3119308520",
        "https://openalex.org/W3099624838",
        "https://openalex.org/W2095705004",
        "https://openalex.org/W2595653137",
        "https://openalex.org/W2983040767",
        "https://openalex.org/W2980282514",
        "https://openalex.org/W2493916176",
        "https://openalex.org/W3119228675",
        "https://openalex.org/W2097554207",
        "https://openalex.org/W3039838634",
        "https://openalex.org/W2160685721",
        "https://openalex.org/W3003266841",
        "https://openalex.org/W3012507282"
    ],
    "abstract": "Social media often acts as breeding grounds for different forms of offensive content. For low resource languages like Tamil, the situation is more complex due to the poor performance of multilingual or language-specific models and lack of proper benchmark datasets. Based on this shared task, Offensive Language Identification in Dravidian Languages at EACL 2021, we present an exhaustive exploration of different transformer models, We also provide a genetic algorithm technique for ensembling different models. Our ensembled models trained separately for each language secured the first position in Tamil, the second position in Kannada, and the first position in Malayalam sub-tasks. The models and codes are provided.",
    "full_text": "Hate-Alert@DravidianLangTech-EACL2021: Ensembling strategies for\nTransformer-based Offensive language Detection\nDebjoy Saha , Naman Paharia , Debajit Chakraborty,\nPunyajoy Saha, Animesh Mukherjee\nIndian Institute of Technology, Kharagpur, India\nsahadebjoy10@iitkgp.ac.in, namanpaharia.27@gmail.com, debajit15@iitkgp.ac.in\npunyajoys@iitkgp.ac.in, animeshm@cse.iitkgp.ac.in\nAbstract\nSocial media often acts as breeding grounds\nfor different forms of offensive content. For\nlow resource languages like Tamil, the situ-\nation is more complex due to the poor per-\nformance of multilingual or language-speciﬁc\nmodels and lack of proper benchmark datasets.\nBased on this shared task “Offensive Lan-\nguage Identiﬁcation in Dravidian Languages”\nat EACL 2021, we present an exhaustive ex-\nploration of different transformer models, We\nalso provide a genetic algorithm technique for\nensembling different models. Our ensembled\nmodels trained separately for each language se-\ncured the ﬁrst position in Tamil, the second\nposition in Kannada, and the ﬁrst position in\nMalayalam sub-tasks. The models and codes\nare provided1.\n1 Introduction\nSocial media platforms have become a prominent\nway of communication, be it for acquiring infor-\nmation or promotion of business2. While we can-\nnot deny the positives, there are some ill conse-\nquences of social media as well. Bad actors of-\nten use different social media platforms by post-\ning tweets/comments that insult others by targeting\ntheir culture and beliefs. In social media, such posts\nare collectively known as offensive language (Chen\net al., 2012). To reduce offensive content, differ-\nent social media platforms like YouTube have laid\ndown moderation policies and employ moderators\nfor maintaining civility in their platforms. Re-\ncently, the moderators are ﬁnding it difﬁcult (New-\nton, 2019) to continue the moderation due to the\never-increasing volume of offensive data. Hence,\nplatforms are looking toward automatic modera-\ntion systems. For instance, Facebook (Robertson,\n1https://github.com/Debjoy10/Hate-Alert-\nDravidianLangTech\n2https://www.webfx.com/internet-marketing/social-\nmedia-marketing-advantages-and-disadvantages.html\n2020) is proactively removing a large part of the\nharmful content from its platform, even before the\nusers report them. There are concerns by different\npolicy-makers that these automatic moderation sys-\ntems may be erroneous 3. Situation for countries\nlike India is more complex, as courts often face\ndilemma while interpreting harmful content and\nsocial platforms like Facebook are often unable to\ntake necessary actions4. Hence, more effort is re-\nquired to detect and mitigate offensive language in\nthe Indian social media.\nRecently, different shared tasks like HASOC\n20195 have been launched to understand hateful\nand offensive language in Indian context but it is\nlimited to Hindi and English mostly. A sub-task in\nHASOC 20206 aimed to detect offensive posts in\na code-mixed dataset. Extending that task further,\nthe organisers of this shared task have put together\na large dataset of 43919, 7772, 20010 posts in three\nDravidian languages – Tamil, Kannada, Malayalam\nrespectively, to further advance research on offen-\nsive posts in these languages. In this paper, we aim\nto build algorithmic systems that can detect offen-\nsive posts. Contributions of our paper are two-fold.\nFirst, we investigate how the current state-of-the-\nart multilingual language models perform on these\nlanguages. Second, we demonstrate how we can\nuse ensembling techniques to improve our classiﬁ-\ncation performance.\n2 Related Work\nOffensive language has been studied in the research\ncommunity for a long time, One of the earliest\n3https://www.forbes.com/sites/johnkoetsier/2020/06/09/300000-\nfacebook-content-moderation-mistakes-daily-report-says/\n4https://www.npr.org/2020/11/27/939532326/facebook-\naccused-of-violating-its-hate-speech-policy-in-india\n5https://hasocﬁre.github.io/hasoc/2019/index.html\n6https://sites.google.com/view/dravidian-codemix-\nﬁre2020/overview\narXiv:2102.10084v1  [cs.CL]  19 Feb 2021\nClassiﬁers Tamil Kannada Malayalam\nTrain Dev Test Train Dev Test Train Dev Test\nNot-offensive 25425 3193 3190 3544 426 427 14153 1779 1765\nOffensive-untargeted 2906 356 368 212 33 33 191 20 29\nOffensive-targeted-individual 2343 307 315 487 66 75 239 24 27\nOffensive-targeted-group 2557 295 288 329 45 44 140 13 23\nOffensive-targeted-other 454 65 71 123 16 14 - - -\nNot-in-indented-language 1454 172 160 1522 191 185 1287 163 157\nTotal 35139 4388 4392 6217 777 778 16010 1999 2001\nTable 1: Dataset statistics for languages Tamil, Kannada and Malayalam for all splits Train, Dev and Test\nstudies (Chen et al., 2012) tried to detect offensive\nusers by using lexical syntactic features generated\nfrom their posts. Although, they provided an efﬁ-\ncient framework for future research, their dataset\nwas small for any conclusive evidence. Davidson\net al. curated one of the largest dataset contain-\ning both offensive and hate speech. The authors\nfound that one of the issues with their best per-\nforming models was that they could not distinguish\nbetween hate and offensive posts. In order to miti-\ngate this, subsequent research (Pitsilis et al., 2018)\ntried to use deep learning to identify offensive lan-\nguage in English and found that recurrent neural\nnetworks (RNNs) are quite effective this task. Re-\ncently, the research community has begun to focus\non offensive language detection in other low re-\nsourced languages like Danish (Sigurbergsson and\nDerczynski, 2019), Greek (Pitenis et al., 2020) and\nTurkish (C ¸¨oltekin, 2020). In the Indian context,\nthe HASOC 2019 shared task (Mandl et al., 2019)\nwas a signiﬁcant effort in that direction, where the\nauthors developed a dataset of hate and offensive\nposts in Hindi and English. The best model in this\ncompetition used an ensemble of multilingual trans-\nformers, ﬁne-tuned on the given dataset (Mishra\nand Mishra, 2019). In Dravidian part of HASOC\n2020, Renjit and Idicula used an ensemble of deep\nlearning and simple neural networks to identify of-\nfensive posts in Manglish (Malayalam in roman\nfont).\nTransformer based language models are becom-\ning quite popular in the past few years. Recently,\ndifferent multilingual models like XLM-RoBERTa\n(Conneau et al., 2019), multilingual-BERT (Devlin\net al., 2018), MuRIL 7 and Indic-BERT (Conneau\net al., 2019) have been introduced to facilitate NLP\nresearch in different languages. Often in differ-\nent machine learning pipeline, ensembling differ-\nent classiﬁcation outcomes helps in getting better\n7https://tfhub.dev/google/MuRIL/1\nperformance (Alonso et al., 2020; Renjit and Idic-\nula, 2020; Mishra and Mishra, 2019). Rather than\nselecting the models for the ensemble manually,\ngenetic algorithms (GA) are used to optimise the\nweights of different classiﬁers, to improve the en-\nsemble performance on the development set. GA-\nbased ensembling techniques have previously been\nused in the hate speech domain for architecture and\nhyperparamter search Madukwe et al. (2020).\n3 Dataset description\nThe shared task on Offensive Language Iden-\ntiﬁcation in Dravidian Languages-EACL 2021\n(Chakravarthi et al., 2021) is based on a post clas-\nsiﬁcation problem with an aim to moderate and\nminimise offensive content in social media. The\nobjective of the shared task is to develop method-\nology and language models for code-mixed data\nin low-resource languages, as models trained on\nmonolingual data fail to comprehend the semantic\ncomplexity of a code-mixed dataset.\nDataset: The Dravidian offensive code-\nmixed language dataset is available for Tamil\n(Chakravarthi et al., 2020b), Kannada (Hande\net al., 2020) and Malayalam (Chakravarthi et al.,\n2020a). The data provided is scraped entirely\nfrom the YouTube comments of a multilingual\ncommunity where code-mixing is a prevalent\nphenomenon. The dataset contains rows of text and\nthe corresponding labels from the list not-offensive,\noffensive-untargeted, offensive-targeted-individual,\noffensive-targeted-group, offensive-targeted-other,\nor not-in-indented-language. Final evaluation\nscore was calculated using weighted F1-score\nmetric on a held-out test dataset.\nWe present the dataset statistics in Table 1.\nPlease note that the Malayalam split of the dataset\ncontained no instances of ’Offensive-targeted-\nother’ label, so classiﬁcation is done using 5 la-\nbels only, instead of the original six labels. In\norder to understand the amount of misspelt and\ncode-mixed words, we compare with an existing\npure language vocabulary available in the Dakshina\ndataset (Roark et al., 2020). We ﬁnd the propor-\ntion of out-of-vocabulary (OOV) words (including\ncode-mixed, English and misspelt words) in the\ndataset as 85.55%, 84.23% and 83.03% in Tamil,\nMalayalam and Kannada respectively.\n4 Methodology\nIn this section, we discuss the different parts of the\npipeline that we followed to detect offensive posts\nin this dataset.\n4.1 Machine learning models\nAs a part of our initial experiments, we used several\nmachine learning models to establish a baseline per-\nformance. We employed random forests, logistic\nregression and trained them with TF-IDF vectors.\nThe best results were obtained on ExtraTrees Clas-\nsiﬁer (Geurts et al., 2006) with 0.70, 0.63 and 0.95\nweighted F1-scores on Tamil, Kannada and Malay-\nalam respectively. As we will notice further, these\nperformances were lower than single transformer\nbased model. Hence, the simple machine learning\nmodels were not used in the subsequent analysis.\n4.2 Transformer models\nOne of the issues with simple machine learning\nmodels is the inability to learn the context of a\nword based on its neighbourhood. Recent trans-\nformer based architectures are capable of captur-\ning this context, as established by their superior\nperformance in different downstream tasks. For\nour purpose, we ﬁne-tuned different state-of-the-\nart multilingual BERT models on the given datasets.\nThis includes XLM-RoBERTa (Conneau et al.,\n2019), multilingual-BERT (Devlin et al., 2018) 8,\nIndic BERT and MuRIL9. We also pretrain XLM-\nRoberta-Base on the target dataset for 20 epochs\nusing Masked Language Modeling, to capture the\nsemantics of the code-mixed corpus. This addi-\ntional pretrained BERT model was also used for\nﬁne-tuning. In addition, all models were ﬁne-tuned\n8XLM-Roberta-Base, 270M parameters, trained on data\nfrom 100 languages; Multilingual-BERT-Base, 179M parame-\nters, trained on data from the top 104 languages.\n9Originally released by Google, MuRIL (Multilin-\ngual Representations for Indian Languages) is a BERT\nmodel pre-trained on code-mixed data from 17 Indian\nlanguages https://huggingface.co/simran-kh/\nmuril-cased-temp\nClassiﬁers Tamil Kannada Malayalam\nDev Test Dev Test Dev Test\nXLMR-base (A) 0.77 0.76 0.69 0.70 0.97 0.96\nXLMR-large 0.78 0.77 0.69 0.71 0.97 0.97\nXLMR-C (B) 0.76 0.76 0.70 0.73 0.97 0.97\nmBERT-base (C) 0.73 0.72 0.69 0.70 0.97 0.96\nIndicBERT 0.73 0.71 0.62 0.66 0.96 0.95\nMuRIL 0.75 0.74 0.67 0.67 0.96 0.96\nDistilBERT 0.74 0.74 0.68 0.69 0.96 0.95\nCNN 0.71 0.70 0.60 0.61 0.95 0.95\nCNN + A + C 0.78 0.76 0.71 0.70 0.97 0.97\nCNN + A + B 0.78 0.77 0.71 0.71 0.97 0.97\nCNN + B + C 0.77 0.76 0.71 0.72 0.97 0.97\nTable 2: Weighted F1-score comparison for trans-\nformer, CNN and fusion models on Dev and Test\nsplits (XLMR-C refers to the custom-pretrained XLM-\nRoberta-Base Classiﬁer).\nBERT_11-D CNN BERT_2\n FastText Tokenizer\nData\nFusion Classifier Head\nEmbedding Fusion Layer (1664 x 1)\n(128 x 1) (768 x 1) (768 x 1)\nFigure 1: Our fusion model architecture for two BERT\nmodels. Note that 768×1 embedding sizes are used for\nthe BERT-base models. Embeddings size of 1024 × 1\nis used for BERT-large models.\nseparately using unweighted and weighted cross-\nentropy loss functions (Mannor et al., 2005). For\ntraining, we use HuggingFace (Wolf et al., 2019)\nwith PyTorch (Paszke et al., 2019). We use the\nAdam adaptive optimizer (Loshchilov and Hutter,\n2019) with an initial learning rate of 1e-5. Train-\ning is stopped by early stopping if macro-F1 score\nof the development split of the dataset does not\nincrease for 5 epochs.\n4.3 Fusion models\nConvolution neural networks are able to capture\nneighbourhood information more effectively. One\nof the previous state-of-the-art model to detect hate\nspeech was CNN-GRU (Zhang et al., 2018), We\npropose a new BERT-CNN fusion classiﬁer where\nwe train a single classiﬁcation head on the con-\ncatenated embeddings from different BERT and\nModel Sets Tamil Kannada Malayalam\nDev Test Dev Test Dev Test\nTransformers 0.80 0.78 0.74 0.73 0.98 0.97\nF-models 0.79 0.77 0.73 0.73 0.98 0.97\nR-models 0.79 0.78 0.75 0.74 0.97 0.97\nOverall 0.80 0.78 0.75 0.74 0.98 0.97\nTable 3: Weighted-F1 score comparison for GA-\nweighted ensemble for transformers category, Fu-\nsion models(F-models) and Random seed models(R-\nmodels)\nCNN models. BERT models were initialised with\nthe ﬁne-tuned weights in the former section and\nthe weights were frozen. The number of BERT\nmodels in a single fusion model was kept ﬂexible\nwith maximum number of models ﬁxed to three,\ndue to memory limitation. For the CNN part, we\nuse the 128-dim ﬁnal layer embeddings from CNN\nmodels trained on skip-gram word vectors using\nFastText (Bojanowski et al., 2017)10. FastText vec-\ntors worked the best among other word embeddings\nlike LASER (Artetxe and Schwenk, 2019). For the\nfusion classiﬁer head, we use a feed-forward neural\nnetwork having four layers with batch normaliza-\ntion (Ioffe and Szegedy, 2015) and dropout (Srivas-\ntava et al., 2014) on the ﬁnal layer. The predictions\nwere generated from a softmax layer of dimension\nequal to the number of classes. We present the\ndetails of the pipeline in Figure 1.\n4.4 Ensembling strategies\nEnsemble of different models often turn out better\npredictors than using a single classiﬁer. Standard\nprediction averaging ensembles will not perform\nwell, since some models might be weak predic-\ntors in the mix of different models. One of the\nstrategies to reduce the inﬂuence of weak mod-\nels is using weights for different models based on\ntheir performance. Genetic algorithm (GA) based\ntechniques (Madukwe et al., 2020) are one of the\npopular ways to set the weights of different models\nin an ensemble. Our approach is similar to that in-\ntroduced in Zhou et al. (2001), except that instead\nof selecting the models with the highest weights\nfor the ﬁnal ensemble, we directly use the weights\nto compute the weighted average ensemble.\nAnother issue with neural networks is the per-\nformance is dependent on the initial random seeds.\nWith pretrained models like BERT, most of the\n10https://fasttext.cc/docs/en/\nunsupervised-tutorial.html\nweights are ﬁxed only in the ﬁnal layer (classiﬁca-\ntion head). Past research (McCoy et al., 2020) has\nshown that even the initialisation of this ﬁnal layer\ncan affect the ﬁnal performance by large margins.\nHence, we take 10 different random seeds to train\nthe models and then pass all the models to the GA\npipeline. We perform this operation for two of the\nbest models in Table 2.\n5 Results and conclusion\nWe observe that among the individual transformer\nmodels, the best performance is obtained using\nXLM-RoBERTa-large (XLMR-large) in the Tamil\ndataset and Custom XLM-RoBERTa-base (XLMR-\nC) in the Kannada dataset. For Malayalam dataset,\nboth the former models perform similarly. The\nhigher performance of XLM-RoBERTa (Artetxe\nand Schwenk, 2019) models can be attributed to\nthe fact that they are pretrained using a parallel\ncorpus (same corpus in different languages). Fur-\nther pretraining with our dataset helps in further\nimprovement of the performance in the Kannada\ndataset. We did not use the XLM-R large model fur-\nther due to limited GPU space. Next, we note the\nperformance of the fusion models, which perform\nalmost similarly across different combinations.\nWhen we use different random seeds, the per-\nformance of multilingual BERT models varied\naround 2-3% across different languages. For XLM-\nRoBERTa models the variation was more (around\n15-20%). Table 3 shows the ensemble performance\nof different categories of models and all the mod-\nels combined. GA-optimised weighted ensembling\nimproves the ﬁnal model scores by a 1-2% across\ndatasets of different languages which ﬁnally helped\nus to rank higher in the leader board.\nIn this shared task, we evaluated different trans-\nformer based architectures and introduced differ-\nent ensembling strategies. We found that XLM-\nRoBERTa models usually perform better than other\ntransformer models, although their performance is\nhighly variable across different random seeds. GA\nbased ensembling helps us in further improving\nthe models. Our immediate next step will be to\ninvestigate the reason behind lower performance\nof IndicBERT and MuRIL which are speciﬁcally\ntrained for Indian context.\nReferences\nPedro Alonso, Rajkumar Saini, and Gy ¨orgy Kov ´acs.\n2020. Hate speech detection using transformer en-\nsembles on the hasoc dataset. In International\nConference on Speech and Computer , pages 13–21.\nSpringer.\nMikel Artetxe and Holger Schwenk. 2019. Mas-\nsively multilingual sentence embeddings for zero-\nshot cross-lingual transfer and beyond. Transac-\ntions of the Association for Computational Linguis-\ntics, 7:597–610.\nPiotr Bojanowski, Edouard Grave, Armand Joulin, and\nTomas Mikolov. 2017. Enriching word vectors with\nsubword information. Transactions of the Associa-\ntion for Computational Linguistics, 5:135–146.\nBharathi Raja Chakravarthi, Navya Jose, Shardul\nSuryawanshi, Elizabeth Sherly, and John Philip Mc-\nCrae. 2020a. A sentiment analysis dataset for code-\nmixed Malayalam-English. In Proceedings of the\n1st Joint Workshop on Spoken Language Technolo-\ngies for Under-resourced languages (SLTU) and\nCollaboration and Computing for Under-Resourced\nLanguages (CCURL) , pages 177–184, Marseille,\nFrance. European Language Resources association.\nBharathi Raja Chakravarthi, Vigneshwaran Murali-\ndaran, Ruba Priyadharshini, and John Philip Mc-\nCrae. 2020b. Corpus creation for sentiment anal-\nysis in code-mixed Tamil-English text. In Pro-\nceedings of the 1st Joint Workshop on Spoken\nLanguage Technologies for Under-resourced lan-\nguages (SLTU) and Collaboration and Computing\nfor Under-Resourced Languages (CCURL) , pages\n202–210, Marseille, France. European Language Re-\nsources association.\nBharathi Raja Chakravarthi, Ruba Priyadharshini,\nNavya Jose, Anand Kumar M, Thomas Mandl,\nPrasanna Kumar Kumaresan, Rahul Ponnusamy,\nHariharan V , Elizabeth Sherly, and John Philip Mc-\nCrae. 2021. Findings of the shared task on Offen-\nsive Language Identiﬁcation in Tamil, Malayalam,\nand Kannada. In Proceedings of the First Workshop\non Speech and Language Technologies for Dravid-\nian Languages. Association for Computational Lin-\nguistics.\nY . Chen, Y . Zhou, S. Zhu, and H. Xu. 2012. Detecting\noffensive language in social media to protect adoles-\ncent online safety. In 2012 International Conference\non Privacy, Security, Risk and Trust and 2012 In-\nternational Confernece on Social Computing, pages\n71–80.\nYing Chen, Yilu Zhou, Sencun Zhu, and Heng Xu.\n2012. Detecting offensive language in social media\nto protect adolescent online safety. In 2012 Inter-\nnational Conference on Privacy, Security, Risk and\nTrust and 2012 International Confernece on Social\nComputing, pages 71–80. IEEE.\nC ¸ a˘grı C ¸¨oltekin. 2020. A corpus of turkish offensive\nlanguage on social media. In Proceedings of the\n12th Language Resources and Evaluation Confer-\nence, pages 6174–6184.\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzm´an, Edouard Grave, Myle Ott, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2019. Unsupervised\ncross-lingual representation learning at scale. arXiv\npreprint arXiv:1911.02116.\nThomas Davidson, Dana Warmsley, Michael Macy,\nand Ingmar Weber. 2017. Automated hate speech\ndetection and the problem of offensive language. In\nProceedings of the International AAAI Conference\non Web and Social Media, volume 11.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. arXiv preprint arXiv:1810.04805.\nPierre Geurts, Damien Ernst, and Louis Wehenkel.\n2006. Extremely randomized trees. Mach. Learn.,\n63(1):3–42.\nAdeep Hande, Ruba Priyadharshini, and Bharathi Raja\nChakravarthi. 2020. KanCMD: Kannada\nCodeMixed dataset for sentiment analysis and\noffensive language detection. In Proceedings of the\nThird Workshop on Computational Modeling of Peo-\nple’s Opinions, Personality, and Emotion’s in Social\nMedia, pages 54–63, Barcelona, Spain (Online).\nAssociation for Computational Linguistics.\nSergey Ioffe and Christian Szegedy. 2015. Batch nor-\nmalization: Accelerating deep network training by\nreducing internal covariate shift. In International\nconference on machine learning , pages 448–456.\nPMLR.\nIlya Loshchilov and Frank Hutter. 2019. Decoupled\nweight decay regularization.\nK. J. Madukwe, X. Gao, and B. Xue. 2020. A ga-based\napproach to ﬁne-tuning bert for hate speech detec-\ntion. In 2020 IEEE Symposium Series on Computa-\ntional Intelligence (SSCI), pages 2821–2828.\nThomas Mandl, Sandip Modha, Prasenjit Majumder,\nDaksh Patel, Mohana Dave, Chintak Mandlia, and\nAditya Patel. 2019. Overview of the hasoc track at\nﬁre 2019: Hate speech and offensive content identiﬁ-\ncation in indo-european languages. In Proceedings\nof the 11th forum for information retrieval evalua-\ntion, pages 14–17.\nShie Mannor, Dori Peleg, and Reuven Rubinstein.\n2005. The cross entropy method for classiﬁcation.\nIn Proceedings of the 22nd International Conference\non Machine Learning , ICML ’05, page 561–568,\nNew York, NY , USA. Association for Computing\nMachinery.\nR Thomas McCoy, Junghyun Min, and Tal Linzen.\n2020. Berts of a feather do not generalize together:\nLarge variability in generalization across models\nwith similar test set performance. In Proceedings of\nthe Third BlackboxNLP Workshop on Analyzing and\nInterpreting Neural Networks for NLP , pages 217–\n227.\nShubhanshu Mishra and Sudhanshu Mishra. 2019. 3id-\niots at hasoc 2019: Fine-tuning transformer neu-\nral networks for hate speech identiﬁcation in indo-\neuropean languages. In FIRE (Working Notes) ,\npages 208–213.\nCasey Newton. 2019. Google and youtube\nmoderators speak out on the work\nthat’s giving them ptsd - the verge.\nhttps://www.theverge.com/2019/12/16/21021005/google-\nyoutube-moderators-ptsd-accenture-violent-\ndisturbing-content-interviews-video. (Accessed on\n01/24/2021).\nAdam Paszke, Sam Gross, Francisco Massa, Adam\nLerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca\nAntiga, et al. 2019. Pytorch: An imperative\nstyle, high-performance deep learning library. arXiv\npreprint arXiv:1912.01703.\nZeses Pitenis, Marcos Zampieri, and Tharindu Ranas-\ninghe. 2020. Offensive language identiﬁcation in\ngreek. arXiv preprint arXiv:2003.07459.\nGeorgios K Pitsilis, Heri Ramampiaro, and Helge\nLangseth. 2018. Detecting offensive language\nin tweets using deep learning. arXiv preprint\narXiv:1801.04433.\nSara Renjit and Sumam Mary Idicula.\n2020. Cusatnlp@hasoc-dravidian-codemix-\nﬁre2020:identifying offensive language from\nmanglishtweets.\nBrian Roark, Lawrence Wolf-Sonkin, Christo Kirov,\nSabrina J. Mielke, Cibu Johny, Isin Demirsahin, and\nKeith Hall. 2020. Processing south asian languages\nwritten in the latin script: the dakshina dataset.\nAdi Robertson. 2020. Facebook says ai has\nfueled a hate speech crackdown - the verge.\nhttps://www.theverge.com/2020/11/19/21575139/facebook-\nmoderation-ai-hate-speech. (Accessed on\n01/24/2021).\nGudbjartur Ingi Sigurbergsson and Leon Derczynski.\n2019. Offensive language and hate speech detection\nfor danish. arXiv preprint arXiv:1908.04531.\nNitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,\nIlya Sutskever, and Ruslan Salakhutdinov. 2014.\nDropout: A simple way to prevent neural networks\nfrom overﬁtting. Journal of Machine Learning Re-\nsearch, 15(56):1929–1958.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, R ´emi Louf, Morgan Fun-\ntowicz, et al. 2019. Huggingface’s transformers:\nState-of-the-art natural language processing. arXiv\npreprint arXiv:1910.03771.\nZiqi Zhang, D. Robinson, and Jonathan Tepper. 2018.\nDetecting hate speech on twitter using a convolution-\ngru based deep neural network.\nZhi-Hua Zhou, Jian-Xin Wu, Yuan Jiang, and Shi-Fu\nChen. 2001. Genetic algorithm based selective neu-\nral network ensemble. In Proceedings of the 17th\nInternational Joint Conference on Artiﬁcial Intelli-\ngence - Volume 2 , IJCAI’01, page 797–802, San\nFrancisco, CA, USA. Morgan Kaufmann Publishers\nInc."
}