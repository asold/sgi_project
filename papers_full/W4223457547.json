{
    "title": "Prosit Transformer: A transformer for Prediction of MS2 Spectrum Intensities",
    "url": "https://openalex.org/W4223457547",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A3090096298",
            "name": "Markus Ekvall",
            "affiliations": [
                "KTH Royal Institute of Technology",
                "Science for Life Laboratory"
            ]
        },
        {
            "id": "https://openalex.org/A2160329241",
            "name": "Patrick Truong",
            "affiliations": [
                "Science for Life Laboratory",
                "KTH Royal Institute of Technology"
            ]
        },
        {
            "id": "https://openalex.org/A3098010236",
            "name": "Wassim Gabriel",
            "affiliations": [
                "Technical University of Munich"
            ]
        },
        {
            "id": "https://openalex.org/A2170584016",
            "name": "Mathias Wilhelm",
            "affiliations": [
                "Technical University of Munich"
            ]
        },
        {
            "id": "https://openalex.org/A2031682453",
            "name": "Lukas Kall",
            "affiliations": [
                "Science for Life Laboratory",
                "KTH Royal Institute of Technology"
            ]
        },
        {
            "id": "https://openalex.org/A3090096298",
            "name": "Markus Ekvall",
            "affiliations": [
                "KTH Royal Institute of Technology",
                "Science for Life Laboratory"
            ]
        },
        {
            "id": "https://openalex.org/A2160329241",
            "name": "Patrick Truong",
            "affiliations": [
                "Science for Life Laboratory",
                "KTH Royal Institute of Technology"
            ]
        },
        {
            "id": "https://openalex.org/A3098010236",
            "name": "Wassim Gabriel",
            "affiliations": [
                "Technical University of Munich"
            ]
        },
        {
            "id": "https://openalex.org/A2170584016",
            "name": "Mathias Wilhelm",
            "affiliations": [
                "Technical University of Munich"
            ]
        },
        {
            "id": "https://openalex.org/A2031682453",
            "name": "Lukas Kall",
            "affiliations": [
                "KTH Royal Institute of Technology",
                "Science for Life Laboratory"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3195038684",
        "https://openalex.org/W3161702043",
        "https://openalex.org/W3147452949",
        "https://openalex.org/W2017955281",
        "https://openalex.org/W2887566220",
        "https://openalex.org/W3208719333",
        "https://openalex.org/W3133209323",
        "https://openalex.org/W2053943711",
        "https://openalex.org/W2991106430",
        "https://openalex.org/W1635348144",
        "https://openalex.org/W2947763854",
        "https://openalex.org/W2952971539",
        "https://openalex.org/W3167897985",
        "https://openalex.org/W3013398083",
        "https://openalex.org/W3166142427",
        "https://openalex.org/W3203588026",
        "https://openalex.org/W3155214885",
        "https://openalex.org/W3213043847",
        "https://openalex.org/W2971227267"
    ],
    "abstract": "Machine learning has been an integral part of interpreting data from mass spectrometry (MS)-based proteomics for a long time. Relatively recently, a machine-learning structure appeared successful in other areas of bioinformatics, Transformers. Furthermore, the implementation of Transformers within bioinformatics has become relatively convenient due to transfer learning, i.e., adapting a network trained for other tasks to new functionality. Transfer learning makes these relatively large networks more accessible as it generally requires less data, and the training time improves substantially. We implemented a Transformer based on the pretrained model TAPE to predict MS2 intensities. TAPE is a general model trained to predict missing residues from protein sequences. Despite being trained for a different task, we could modify its behavior by adding a prediction head at the end of the TAPE model and fine-tune it using the spectrum intensity from the training set to the well-known predictor Prosit. We demonstrate that the predictor, which we call Prosit Transformer, outperforms the recurrent neural-network-based predictor Prosit, increasing the median angular similarity on its hold-out set from 0.908 to 0.929. We believe that Transformers will significantly increase prediction accuracy for other types of predictions within MS-based proteomics.",
    "full_text": null
}