{
    "title": "MultiRAG: A Knowledge-Guided Framework for Mitigating Hallucination in Multi-Source Retrieval Augmented Generation",
    "url": "https://openalex.org/W4413360566",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A2099791789",
            "name": "Wenlong Wu",
            "affiliations": [
                "Nanjing University of Aeronautics and Astronautics"
            ]
        },
        {
            "id": "https://openalex.org/A2124602852",
            "name": "Haofen Wang",
            "affiliations": [
                "Tongji University"
            ]
        },
        {
            "id": "https://openalex.org/A2127977893",
            "name": "Bohan Li",
            "affiliations": [
                "Nanjing University of Aeronautics and Astronautics"
            ]
        },
        {
            "id": "https://openalex.org/A2425536699",
            "name": "Huang Peixuan",
            "affiliations": [
                "Nanjing University of Aeronautics and Astronautics"
            ]
        },
        {
            "id": "https://openalex.org/A2400131028",
            "name": "Xinzhe Zhao",
            "affiliations": [
                "Nanjing University of Aeronautics and Astronautics"
            ]
        },
        {
            "id": "https://openalex.org/A1999883254",
            "name": "Lei Liang",
            "affiliations": [
                "Public Knowledge"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4385573021",
        "https://openalex.org/W4396722757",
        "https://openalex.org/W4396723267",
        "https://openalex.org/W4390692489",
        "https://openalex.org/W4396759394",
        "https://openalex.org/W4396757562",
        "https://openalex.org/W4392237971",
        "https://openalex.org/W4396643377",
        "https://openalex.org/W4406610757",
        "https://openalex.org/W4391807376",
        "https://openalex.org/W4410636953",
        "https://openalex.org/W4396722534",
        "https://openalex.org/W4409206472",
        "https://openalex.org/W4412889733",
        "https://openalex.org/W2998159437",
        "https://openalex.org/W4404181391",
        "https://openalex.org/W4396601316",
        "https://openalex.org/W1521736627",
        "https://openalex.org/W2073545563",
        "https://openalex.org/W2155160033",
        "https://openalex.org/W2889787757",
        "https://openalex.org/W3115947671",
        "https://openalex.org/W3179923213",
        "https://openalex.org/W4393152682",
        "https://openalex.org/W2169585110",
        "https://openalex.org/W4402671091",
        "https://openalex.org/W4389518784",
        "https://openalex.org/W4402671555"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) has emerged as a promising solution to address hallucination issues in Large Language Models (LLMs). However, the integration of multiple retrieval sources, while potentially more informative, introduces new challenges that can paradoxically exacerbate hallucination problems. These challenges manifest primarily in two aspects: the sparse distribution of multi-source data that hinders the capture of logical relationships and the inherent inconsistencies among different sources that lead to information conflicts. To address these challenges, we propose MultiRAG, a novel framework designed to mitigate hallucination in multi-source retrieval-augmented generation through knowledge-guided approaches. Our framework introduces two key innovations: (1) a knowledge construction module that employs multi-source line graphs to efficiently aggregate logical relationships across different knowledge sources, effectively addressing the sparse data distribution issue; and (2) a sophisticated retrieval module that implements a multi-level confidence calculation mechanism, performing both graph-level and node-level assessments to identify and eliminate unreliable information nodes, thereby reducing hallucinations caused by inter-source inconsistencies. Extensive experiments on four multi-domain query datasets and two multi-hop QA datasets demonstrate that MultiRAG significantly enhances the reliability and efficiency of knowledge retrieval in complex multi-source scenarios. \\textcolor{blue}{Our code is available in https://github.com/wuwenlong123/MultiRAG.",
    "full_text": "MultiRAG: A Knowledge-guided Framework for\nMitigating Hallucination in Multi-source Retrieval\nAugmented Generation\nWenlong Wu 1, Haofen Wang 2, Bohan Li 1,3,4B, Peixuan Huang 1, Xinzhe Zhao 1 and Lei Liang 5\n1College of Artificial Intelligence, Nanjing University of Aeronautics and Astronautics,\nKey Laboratory of Brain-Machine Intelligence Technology, Ministry of Education\n2College of Design & Innovation, Tongji University\n3Key Laboratory of Intelligent Decision and Digital Operation, Ministry of Industry and Information Technology\n4Collaborative Innovation Center of Novel Software Technology and Industrialization\n5Ant Group Knowledge Graph Team\nEmail: {wuwenlong, bhli, peixuanh, xinzhe zhao}@nuaa.edu.cn\ncarter.whfcarter@gmail.com, leywar.liang@antgroup.com\nAbstract—Retrieval Augmented Generation (RAG) has\nemerged as a promising solution to address hallucination issues\nin Large Language Models (LLMs). However, the integration\nof multiple retrieval sources, while potentially more informative,\nintroduces new challenges that can paradoxically exacerbate hal-\nlucination problems. These challenges manifest primarily in two\naspects: the sparse distribution of multi-source data that hinders\nthe capture of logical relationships and the inherent inconsisten-\ncies among different sources that lead to information conflicts.\nTo address these challenges, we propose MultiRAG, a novel\nframework designed to mitigate hallucination in multi-source\nretrieval-augmented generation through knowledge-guided ap-\nproaches. Our framework introduces two key innovations: (1)\na knowledge construction module that employs multi-source\nline graphs to efficiently aggregate logical relationships across\ndifferent knowledge sources, effectively addressing the sparse\ndata distribution issue; and (2) a sophisticated retrieval module\nthat implements a multi-level confidence calculation mecha-\nnism, performing both graph-level and node-level assessments\nto identify and eliminate unreliable information nodes, thereby\nreducing hallucinations caused by inter-source inconsistencies.\nExtensive experiments on four multi-domain query datasets\nand two multi-hop QA datasets demonstrate that MultiRAG\nsignificantly enhances the reliability and efficiency of knowledge\nretrieval in complex multi-source scenarios. Our code is available\nin https://github.com/wuwenlong123/MultiRAG.\nIndex Terms—Retrieval Augmented Generation, Large Lan-\nguage Models, Multi-source Retrieval, Knowledge Graphs, Hal-\nlucination Mitigation\nI. I NTRODUCTION\nLarge Language Models (LLMs) have achieved remarkable\nsuccess in handling a variety of natural language processing\ntasks, attributable to their robust capabilities in understanding\nand generating language and symbols [1]. In knowledge-\nintensive retrieval tasks, Retrieval Augmented Generation\n(RAG) has become a standardized solution paradigm [2]–\n[4]. Previous works [5]–[11] have made significant strides in\nWenlong Wu and Haofen Wang contributed equally to this work.\nBohan Li is the corresponding author.\naddressing the inherent knowledge limitations of LLMs. By\nintroducing external knowledge bases, it has markedly im-\nproved the accuracy and fidelity of LLM responses. However,\nrecent studies have highlighted a significant drawback: the\nretrieval results of RAG are imperfect, including irrelevant,\nmisleading, and even malicious information, ultimately leading\nto inaccurate LLM responses.\nTo address these limitations, the synergy between LLMs\nand Knowledge Graphs (KGs) has been proposed to achieve\nmore efficient information retrieval [12]. On one hand, KG\ncan efficiently store data with fixed characteristics (such\nas temporal KGs, event KGs, etc.), thereby enhancing the\nprocessing capabilities of LLMs on specific data [13]–[20].\nOn the other hand, the collaboration between LLMs and\nKGs has significantly improved performance in multi-hop and\nmulti-document question answering, including the credibility\nand interpretability of retrieval [21]. Furthermore, LLM-KG\ncollaborative methods have also provided the latest solutions\nfor knowledge-intensive retrieval tasks [22]–[26], propelling\nthe deep reasoning capabilities of RAG.\nNevertheless, existing frameworks still fail to account for\nthe complexity of real-world data. Although RAG can mitigate\nthe generation of hallucinations, these hallucinations often\nstem from the internal knowledge of LLMs [27]–[29]. Incon-\nsistent information sources and unreliable retrieval methods\ncan still lead to retrieval biases and hallucinations in LLMs.\nThis issue becomes particularly pronounced when dealing with\ninformation retrieval tasks that involve multi-source knowl-\nedge, where hallucinations are more prominent. Research [30]\nindicates that approximately 70% of retrieved paragraphs do\nnot directly contain the correct query answers but instead\ninclude information indirectly related to the answers, causing\nmisguidance and comprehension bias in LLMs.\nBuilding upon the categorization of hallucinations in re-\ntrieval [9], we outlines the three most common types of\nhallucinations encountered in multi-source data retrieval:\narXiv:2508.03553v1  [cs.IR]  5 Aug 2025\nFig. 1: Single-source Retrieval & Multi-source Retrieval\n1) Inter-source data inconsistency : Discrepancies be-\ntween different data sources can lead to conflicting\ninformation, causing hallucinations in LLMs.\n2) Redundancy of similar data : There often exists data\nthat is highly similar and semantically equivalent across\nmultiple data sources, which can impose significant\ncomputational overhead on retrieval.\n3) Incomplete inference paths : Forming a comprehensive\ninference path from different data sources is challenging.\nExisting retrievers often fail to capture the complete\nlogical associations within multiple data sources.\nFig. 1 vividly illustrates the differences between single-\nsource and multi-source data retrieval through CA981 flight\nanalysis. The sparse distribution and inconsistency of data\nare unique issues in multi-source data retrieval, leading to\nsevere hallucination bias in LLMs. Against this backdrop, we\nfocus on addressing the issue of retrieval hallucinations in\nmulti-source data retrieval to empower knowledge-augmented\ngeneration. This work primarily explores the following two\nfundamental challenges:\n1) Sparse Distribution of Multi-source Data : Multi-\ndomain queries require fusing structured (SQL tables),\nsemi-structured (JSON logs), and unstructured data (text\nreports). Due to the variability in data storage formats\nand sparsity, the connectivity between knowledge ele-\nments is low, making it difficult for RAG systems to\neffectively capture logical associations across sources,\nthereby affecting the recall rate and quality of retrieval\nresults.\n2) Inter-source Data Inconsistency: Conversely, the inher-\nent diversity in knowledge representations across multi-\nsource data often leads to inconsistencies in retrieved\nfragments. These discrepancies may induce information\nconflicts during retrieval processes, thereby compromis-\ning response accuracy. This challenge becomes particu-\nlarly pronounced in domain-specific complex reasoning\nand multi-hop question answering tasks.\nTo address these issues above, we propose MultiRAG, a\nnovel framework designed to mitigate hallucination in multi-\nsource retrieval augmented generation through knowledge-\nguided approaches. Initially, we introduce multi-source line\ngraphs for rapid aggregation of knowledge sources to tackle\nissues arising from sparse data distribution. Subsequently,\nbased on these integrated multi-source line graphs, we propose\na multi-level confidence calculation method to ensure the\nreliability of multi-source data queries. This approach not only\nenhances query efficiency but also strengthens the accuracy of\nresults, providing an effective solution for the multi-source\nknowledge-guided RAG.\nThe contributions of this paper are summarized as follows:\n1) Multi-source Knowledge Aggregation : In the knowl-\nedge construction module, we introduce multi-source\nline graphs as a data structure for rapid aggregation\nand reconstruction of knowledge structures from mul-\ntiple query-relevant data sources. This effectively cap-\ntures inter-source data dependencies within chunk texts,\nthereby providing a unified and centralized representa-\ntion of multi-source knowledge.\n2) Multi-level Confidence Calculation: In the retrieval\nmodule, we perform graph-level and node-level con-\nfidence calculations on the extracted knowledge sub-\ngraphs. The aim is to filter out and eliminate low-quality\nsubgraphs and inconsist retrieval nodes, ultimately en-\nhancing the quality of text embedded in context to\nalleviate retrieval hallucinations.\n3) Experimental Validation and Performance Compar-\nison: We conducted extensive experiments on existing\nmulti-source retrieval datasets and two complex Q&A\ndatasets, comparing our approach with existing state-of-\nthe-art(SOTA) methods. This demonstrated the robust-\nness and accuracy of our proposed method in retrieval\nperformance. Particularly in multi-source data retrieval\ntasks, our method significantly outperforms other SOTA\nmethods by more than 10%.\nII. PRELIMINARY\nIn the field of Knowledge-Guided RAG, the primary chal-\nlenges include efficiently accessing relevant knowledge and\nachieving reliable retrieval performance. This section intro-\nduces the core elements of our approach and precisely defines\nthe problems we address.\nLet Q = {q1, q2, . . . , qn} be the set of query instances,\nwhere each qi corresponds to a distinct query. Let E =\n{e1, e2, . . . , em} be the set of entities in the knowledge graph,\nwhere each ej represents an entity. Let R = {r1, r2, . . . , rp}\nbe the set of relationships in the knowledge graph, where each\nrk represents a relationship. Let D = {d1, d2, . . . , dt} be the\nset of documents, where each dl represents a document. We\ndefine the knowledge-guided retrieval enhancement generation\nproblem as follows:\narg max\ndi∈D\nLLM(qi, di),\nX\nej∈E\nX\nrk∈R\nKG(ej, rk, di) (1)\nwhere LLM (qi, dl) denotes the score of the relevance be-\ntween query qi and document dl assessed by the LLM, and\nKG(ej, rk, dl) represents the degree of match between entity\nej, relationship rk, and document dl.\nFurthermore, we optimize the knowledge construction and\nretrieval modules by introducing multi-source line graphs\nto accelerate knowledge establishment and enhance retrieval\nrobustness. Specifically, the proposed approach is formally\ndefined as follows:\nDefinition 1. Multi-source data fusion. Given a set of\nsources H, the data D = {d, name, c, meta} exists, where\nd represents the domain of data, c represents the content of\nthe data file, name represents the file/attribute name, and\nmeta represents the file metadata. Through a multi-source\ndata fusion algorithm, we can obtain normalized data ˆD =\n{id, d, name, jsc, meta,(cols index)}. Here, id represents\nthe unique identifier for normalization, d indicates the domain\nwhere the data file is located, name denotes the data file\nname, meta denotes the file metadata, and jsc denotes the file\ncontent stored using JSON-LD. If the stored data is structured\ndata or other data formats that can use a columnar storage\nmodel, the column index cols index of all attributes will also\nbe stored for rapid retrieval and query. Fig. 2 provides an\nexample of JSON-LD format.\nDefinition 2. Multi-source line graph [31]. Given a multi-\nsource knowledge graph G and a transformed knowledge graph\nG′ (multi-source line graph, MLG), the MLG satisfies the\nfollowing characteristics:\n1) A node in G′ represents a triplet.\n2) There is an associated edge between any two nodes in\nG′ if and only if the triples represented by these two\nnodes share a common node.\nBased on the definition, it can be inferred that MLG\nachieves high aggregation of related nodes, which can greatly\nimprove the efficiency of data retrieval and accelerate subse-\nquent retrieval and query algorithms.\nDefinition 3. Multi-source homologous data . For any\ntwo nodes υ1 and υ2 in G, they are defined as multi-source\nhomologous if and only if they belong to the same retrieval\ncandidate set in a single search.\nDefinition 4. Homologous node and homologous sub-\ngraph. Given a set of mult-domain homologous data SV =\n{υi}n\ni=1 in the knowledge graph G, we define the homologous\ncenter node as snode = {name, meta, num, C(v)}, the set\nof homologous nodes as Usnode, and the set of homologous\nedges as Esnode. Here, name represents the common attribute\nname, meta denotes the identical file metadata, num indicates\nthe number of homologous data instances, and C(v) represents\nthe data confidence. We define the association edge between\nsnode and υi as ei = {wi}n\ni=1, where wi represents the weight\nFig. 2: Data format of JSON-LD\nof node υi in the data confidence calculation. Thus, the ho-\nmologous center node and SG together form the homologous\nsubgraph subSG.\nDefinition 5. Homologous triple line graph . For all\nhomologous subgraphs within the knowledge graph G, they\ncollectively constitute the homologous knowledge graph SG.\nBy performing a linear graph transformation on the homolo-\ngous knowledge graph, we obtain the homologous triple line\ngraph SG′.\nBy constructing a homologous triple line graph, multi-\nsource homologous data are aggregated into a single sub-\ngraph, centered around homologous nodes, enabling rapid\nconsistency checks and conflict feedback for homologous\ndata. Additionally, the knowledge graph contains a significant\nnumber of isolated nodes (i.e., nodes without homologous\ndata), which are also incorporated into the homologous triple\nline graph.\nDefinition 6. Candidate graph confidence and candidate\nnode confidence. For a query Q(q, G) on the knowledge graph\nG, the corresponding Homologous line graph SG′ is obtained.\nThe candidate graph confidence is an estimation of the con-\nfidence in the candidate Homologous subgraph, assessing the\noverall credibility of the candidate graph; the candidate node\nconfidence is an assessment of the confidence in individual\nnode to determine the credibility of single attribute node.\nIII. M ETHODOLOGY\nA. Framework of MultiRAG\nThis section elaborates on the implementation approach\nof MultiRAG. As shown in Fig. 3, the first step involves\nsegmenting and extracting multi-source data to construct the\ncorresponding MLG, achieving preliminary aggregation of\nmulti-source data; the second step requires reconstructing the\nMLG and performing subgraph extraction to identify candi-\ndate homologous subgraphs, ensuring consistent storage of\nhomologous data for subsequent hallucination assessment; the\nthird step involves calculating the graph-level and node-level\nconfidence of the candidate subgraphs, eliminating low-quality\nnodes to enhance the credibility of the response, and returning\nthe extracted trustworthy subgraphs to the LLM to form the\nfinal answer. Finally, integrating the aforementioned steps\nto form the Multi-source Line Graph Prompting algorithm,\nMKLGP.\nB. Multi-source Line Graph Construction\nThe MultiRAG method initially employs an adapter struc-\nture to integrate multi-source data and standardize its storage\nFig. 3: Framework of MultiRAG, including three modules.\nformat. For practical application scenarios, data is directly\nobtained from various non-homologous formats and trans-\nformed into a unified, normalized representation. Specifically,\nfile names and metadata are parsed, and the domains to which\nthe files belong are categorized. Subsequently, the data content\nis parsed and stored in JSON-LD format, thereby transforming\nit into linked data. Finally, unique identifiers are assigned to\nthe data, resulting in normalized datasets.\nSpecifically, a unique adapter is designed for each distinct\ndata format to facilitate data parsing. Although the imple-\nmentation frameworks of these adapters are largely similar,\nit is essential to differentiate between the parsing processes\nfor structured, semi-structured, and unstructured data.\nFor structured data, parsing involves storing tabular informa-\ntion in JSON format, where attribute variables within the file\nare managed using a Decomposition Storage Model (DSM).\nThis approach enables the extraction of all attribute informa-\ntion for consistency checks through the use of column indices.\nIn the case of semi-structured data, parsing corresponds to\nstoring tree-shaped data in JSON format with multi-layer\nnested structures. This data format lacks column indices and\ndoes not support fast retrieval, necessitating the use of tree or\ngraph retrieval algorithms, such as DFS, for efficient searching.\nFinally, for unstructured data, the focus is currently limited to\ntextual information, which is stored directly. Subsequent steps\ninvolve leveraging LLMs for entity and relationship extraction\ntasks to obtain the relevant information.\nThe final integration of multi-source data can be expressed\nby the following formula:\nDFusion =\nn[\ni=1\nAi(Di) (2)\nwhere Ai ∈ {Adastru, Adasemi-s, Adaunstru}, representing\nthe adapter parsing functions for structured data, semi-\nstructured data, and unstructured data, respectively. Di ∈\n{Dstru, Dsemi-s, Dunstru} represents the original datasets of struc-\ntured data, semi-structured data, and unstructured data, respec-\ntively.\nThrough the parsed data DFusion = {Eq, Rq}, we further\nextracts key information and links it to the knowledge graph.\nThe knowledge construction process involves three key phases\nimplemented through the OpenSPG framework 1 [26], [32],\nin which we use the Custom Prompt module2 to integrate\nLLM-based knowledge extraction.\nFor entity recognition, we utilize the ner.py prompts within\nthe kag/builder/prompt/default directory. We first define\nrelevant entity types in the schema. Then, by adjusting the\nexample.input and example.output in the ner.py prompts, we\nguide the LLM-based SchemaFreeExtractor to identify\nentities accurately.\nIn relationship extraction, the triple.py prompts play a\ncrucial role. We define relationships in the schema and use\nthe triple prompt in the SchemaFreeExtractor. The\ninstruction in triple.py ensures that the extracted Subject-\nPredicate-Object(SPO) triples are related to the entities in the\nentity list, enabling effective relationship extraction.\nRegarding attribute extraction, we rely on the entity stan-\ndardization prompts in std.py. After entity recognition, the\nstd prompt in the SchemaFreeExtractor standardizes\nthe entities and helps in extracting their attributes. We mod-\nify the example.input, example.named entities, and exam-\nple.output in std.py according to our data characteristics to\noptimize the attribute extraction process. Through these steps\nof customizing and applying OpenSPG’s prompts, we achieve\nefficient knowledge extraction.\n1https://github.com/OpenSPG/openspg\n2https://openspg.yuque.com/\nFig. 4: Example of multi-source line graph transformation\nThe following formula describes the data extraction process:\nKB =\nX\nDi\n({e1, e2, ..., em}\nG\n{r1, r2, ..., rn}) (3)\nC. Homologous Subgraph Matching\nAfter the preliminary extraction of information, the next\nstep is to identify the multi-source homologous data group set\nSVs and the isolated point set LVs. This process begins by\ninitializing the unvisited node set Uunvisited = V, while setting\nthe homologous data group SVs = ∅ and the isolated point\nset LVs = ∅. By traversing all nodes and retrieving node\ninformation from various domains, for matched homologous\ndata, construct the homologous node sgi and its corresponding\nassociated edge ei, and add them to the homologous node set\nUsg and edge set Esg, respectively. After the traversal, add\n(Usg, Esg) to SVs. If no homologous data is obtained after one\nround of traversal, add the node to the isolated point set LVs.\nAfter the traversal is completed, the node will be removed\nfrom the Uunvisited set. The time complexity of homologous\nsubgraph matching is O(n log n), where n is the number of\nnodes in the knowledge graph G.\nFor each homologous subgraph in SVs, homologous linear\nknowledge subgraph subSG′i is constructed by utilizing the\nhomologous node set Usg and the homologous edge set Esg.\nSubsequently, all subSG′i and the isolated point set LVs are\naggregated to obtain the homologous linear knowledge graph\nSG′. It should be noted that SG′ is solely used for consistency\nchecks and retrieval queries of homologous data; other types\nof queries still conducts operations on the original knowledge\ngraph G.\nHere, we provide a simple example of a homologous triple\nline graph. As shown in Fig. 4, a homologous node is asso-\nciated with 4 homologous data points. After transformation\ninto a triple line graph, it forms a complete graph of order 4,\nindicating that the four triples are pairwise homologous.\nD. Multi-level Confidence Computing\nWe define the candidate data from different domains ob-\ntained in a single retrieval as multi-source homologous data.\nThese data have been extracted into a homologous line graph\nfor temporary storage. Although targeting the same query\nobject, they often provide inconsistent reference answers. Con-\nsidering the varying retrieval errors, the multi-level confidence\ncalculation method is adpoted in this framework. First, the\nconfidence of individual homologous line graphs is calculated,\nfollowed by the confidence of each candidate node, to deter-\nmine the final set of answer candidates.\n1) Graph-Level Confidence Computing: In the first stage,\na confidence calculation method based on mutual information\nentropy is introduced to assess the confidence of homologous\nline graphs. The core idea of this method is that if two nodes\nwith the same attributes in a homologous line graph are close\nin content, their similarity is high, and thus their confidence is\nalso high; conversely, if they are not, their confidence is low.\nLet G be a homologous line graph, and N(G) be the set of\nnodes in the graph. For any two nodes vi, vj ∈ N(G) with\nthe same attributes, the similarity S(vi, vj) between them is\ndefined based on the calculation method of mutual information\nentropy. The mutual information entropy I(vi, vj) measures\nthe interdependence of the attribute content of the two nodes,\nand its calculation formula is:\nI(vi, vj) =\nX\nx∈Vi\nX\ny∈Vj\np(x, y) log( p(x, y)\np(x)p(y)) (4)\nwhere Vi and Vj are the sets of attribute values for nodes vi\nand vj, respectively, p(x, y) is the joint probability distribution\nof vi taking attribute value x and vj taking attribute value y,\nand p(x) and p(y) are the marginal probability distributions\nof x and y, respectively.\nThe similarity S(vi, vj) can be defined as the normalized\nform of mutual information entropy to ensure that its value\nlies within the interval [0, 1]:\nS(vi, vj) = I(vi, vj)\nH(Vi) +H(Vj) (5)\nwhere H(Vi) and H(Vj) are the entropies of the attribute value\nsets of nodes vi and vj, respectively, calculated as:\nH(V ) =−\nX\nx∈V\np(x) logp(x) (6)\nSubsequently, the confidence C(G) of the homologous line\ngraph G can be determined by calculating the average simi-\nlarity S(vi, vj) of all node pairs in the graph:\nC(G) = 1\n|N(G)|2 − |N(G)|\nX\nvi∈N(G)\nX\nvj∈N(G)\nj̸=i\nS(vi, vj) (7)\nwhere |N(G)| denotes the number of nodes in the graph.\nNotably, a homologous line graph exhibiting high confi-\ndence demonstrates that its constituent nodes maintain strong\nattribute-level consistency across their content representations.\n2) Node-Level Confidence Computing: In the second phase,\nthe confidence of individual node C(v) is calculated, which\ntakes into account the node’s consistency, authority, and his-\ntorical confidence. The following are the detailed calculation\nmethods and formulas.\nAlgorithm 1 Multi-level Confidence Computing Algorithm\n1: procedure CONFIDENCE COMPUTING (v, D)\n2: Sn(v) ← Equation (8)\n3: AuthLLM(v) ←Equation (10)\n4: Authhist(v) ←Equation (11)\n5: A(v) ←Equation (9)\n6: C(v) ← Sn(v) +A(v)\n7: return C(v)\n8: end procedure\n9: procedure MCC( G, Q, D)\n10: SVs ← ∅, LVs ← ∅\n11: Uunvisited ← V\n12: while Uunvisited ̸= ∅ do\n13: v ← pop a node from Uunvisited\n14: for all D ∈ D do\n15: if v ∈ Data(Q, subSGi) then\n16: C(v) ← Confidence Computing(v, D)\n17: if C(v) > θthen\n18: Usg ← Usg ∪ {v}\n19: Esg ← Esg ∪ {ei}\n20: else\n21: LVs ← LVs ∪ {v}\n22: end if\n23: end if\n24: end for\n25: if Usg ̸= ∅ then\n26: SVs ← SVs ∪ (Usg, Esg)\n27: Usg ← ∅, Esg ← ∅\n28: end if\n29: end while\n30: return SVs, LVs\n31: end procedure\na) Node Consistency Score: The node consistency score\nS(v) reflects the consistency of the node across different data\nsources. We use mutual information entropy to calculate the\nsimilarity between node pairs, thereby assessing consistency.\nFor a node v, its consistency score can be expressed as:\nSn(v) = 1\n|N(v)|\nX\nu∈N(v)\nS(v, u) (8)\nwhere N(v) is the set of nodes with the same attributes as\nnode v, and S(v, u) is the similarity between nodes v and u\nas defined in Equation 5.\nb) Node Authority Score: Authority score is divided into\ntwo parts: the node’s authority assessed by the LLM and the\nnode’s historical authority. This score reflects the importance\nand authenticity of the node. Additionally, we use an expert\nLLM to comprehensively evaluate the authority of the node.\nThe node’s authority score A(v) can be calculated using the\nfollowing formula:\nA(v) =α · AuthLLM (v) + (1− α) · Authhist(v) (9)\nAlgorithm 2 Multi-source Knowledge Line Graph Prompting\n1: procedure MKLGP( q)\n2: Eq, Rq ← Logic Form Generation (q)\n3: Dq ← Multi Document Extraction (Vq)\n4: SG′ ← Prompt(Dq)\n5: SVs, LVs ← MCC(SG′, q, Dq)\n6: Cnodes, GA ← Prompt(SVs, LVs)\n7: Answer ← Generating Trustworthy Answers (Cnodes, GA)\n8: return Answer\n9: end procedure\nwhere α is a weight coefficient that balances the contributions\nof LLM-assessed authority and historical authority, satisfying\n0 ≤ α ≤ 1.\nBenefiting from the calculation idea of knowledge credibil-\nity in the PTCA [33], AuthLLM(v) is assessed by the global\ninfluence and local connection strength of the node. The LLM\ncan comprehensively calculate the credibility of knowledge\nby integrating the association strength between entities, entity\ntype information, and multi-step path information.\nAutmLLM (v) = 1\n1 +e−β·CLLM(v) (10)\nwhere CLLM(v) is the authority score provided by the LLM\nfor node v is the average value of all nodes’ CLLM(v), and β\nis a parameter that controls the steepness of the scoring curve.\nc) Historical Authority: Authhist(v) is an authority score\nbased on the node’s historical data. Inspired by Zhu’s work\n[34], we expect to use the credibility of historical data sources\nand current query-related data for incremental estimation.\nAuthhist(v) =\nH ·P rh(D) +P\nυp∈Dυ[q] P r(υp)\nH + |Data(q, subSG′i)| (11)\nwhere H is the number of entities provided by data source D\nfor all historical queries, P rh(D) is the historical credibility\nof data source D, Dυ[q] is the set of correct answers, and\nData(q, subSG′i) is the query-related data obtained from the\nmulti-source line subgraph.\nUltimately, we designed the multi-level confidence comput-\ning algorithm, MCC, to calculate the credibility of the data\nsources in the homologous subgraph, ensuring the quality of\nthe knowledge graph embedded in the LLM. The algorithm is\nshown in Algorithm1.\nIt should be noted that the MCC algorithm does not directly\nprovide the final graph confidence and node confidence; these\nvalues must be obtained through prompt to achieve the ulti-\nmate results.\nE. Multi-source knowledge line graph prompting\nWe propose the Multi-source Knowledge Line Graph\nPrompting (MKLGP) algorithm for multi-source data retrieval.\nGiven a user query q, LLM is firstly employed to extract the\nintent, entities, and relationships from q, and generates the cor-\nresponding logical relationships. The dataset then undergoes\nmulti-document filtering to derive text chunks, followed by\nconstructing a Multi-source Line Graph (MLG) for knowledge\naggregation. Further, it matches homogeneous subgraphs and\nutilizes the MCC algorithm to obtain a set of credible query\nnodes and isolated points SVs, LVs. Finally, by leveraging\nthe prompt, the graph confidence is obtained, and the node\nconfidence is calculated to enhance the credibility of the\nanswer. The results are then embedded into the context of\nthe LLM to generate a credible retrieval answer.\nIV. E XPERIMENTS\nThis section will conduct experiments and performance\nanalysis on the construction of homologous line graphs and the\nmulti-level confidence calculation modules. Baseline methods\nwill be compared with other SOTA multi-document retrieval\nQA methods, data fusion methods, and KBQA methods.\nExtensive experiments will be conducted to assess the robust-\nness and efficiency of MultiRAG, which aims to answer the\nfollowing questions.\n• Q1: How does the retrieval recall performance of Multi-\nRAG compare with other data fusion models and SOTA\ndata retrieval models?\n• Q2: What are the respective impacts of data sparsity and\ndata inconsistency on the quality of retrieval recall?\n• Q3: How effective are the two modules of MultiRAG\nindividually?\n• Q4: How is the performance of MultiRAG in multi-hop\nQ&A datasets after incorporating multi-level confidence\ncalculation?\n• Q5: What are the time costs of the various modules in\nMultiRAG?\nA. Experimental Settings\na) Datasets: To validate the efficiency of multi-source\nline graph construction and its enhancement of retrieval\nperformance, the article conducts multi-source data fusion\nexperiments on four real-world benchmark datasets [35]–[37],\nas is shown in Table I. (1) The movie dataset comprises movie\ndata collected from 13 sources. (2) The book dataset includes\nbook data from 10 sources. (3) The flight dataset gathers\ninformation on over 1200 flights from 20 sources. (4) The\nstock dataset collects transaction data for 1000 stock symbols\nfrom 20 sources. In the experiments, we issue 100 queries for\neach of the four datasets to verify their retrieval efficiency.\nIt is noteworthy that the Movies dataset and the Flights\ndataset are relatively dense, while the Books dataset and the\nStocks dataset are relatively sparse, which can impact the\nmodel’s performance.\nAdditionally, to validate the robustness of the MultiRAG on\ncomplex Q&A datasets, we selected two multi-hop question\nanswering datasets, HotpotQA [38] and 2WikiMultiHopQA\n[39]. Both datasets are constructed based on Wikipedia doc-\numents, allowing us to utilize a consistent document corpus\nand retriever to provide external references for LLMs. Con-\nsidering the constraints of experimental costs, we conducted a\nsubsample analysis on 300 questions from the validation sets\nof each experimental dataset.\nTABLE I: Statistics of the datasets preprocessed\nDatasets Data source Sources Entities Relations Queries\nMovies\nJSON(J) 4 19701 45790\n100KG(K) 5 100229 264709\nCSV(C) 4 70276 184657\nBooks\nJSON(J) 3 3392 2824\n100CSV(C) 3 2547 1812\nXML(X) 4 2054 1509\nFlights CSV(C) 10 48672 100835 100\nJSON(J) 10 41939 89339\nStocks CSV(C) 10 7799 11169 100\nJSON(J) 10 7759 10619\nb) Evaluation Metrics: To assess effectiveness, we adopt\nthe F1 score as the evaluation metric for the data fusion results,\nfollowing previous experimental metrics [37], [40]–[42]. The\nF1 score is the harmonic mean of precision (P) and recall (R),\ncalculated as follows:\nF1 = 2× P × R\nP + R (12)\nFurthermore, to evaluate the retrieval credibility of MKLGP\nAlgorithm, we utilize the recall metric, specifically Recall@K,\nto assess performance at three distinct stages: before subgraph\nfiltering, before node filtering, and after node filtering. In\naddition, we employ the query response time T (measured\nin seconds) as an evaluative metric to verify the efficiency of\nknowledge aggregation.\nc) Hyper-parameter Settings: For all baselines, we care-\nfully adjusted the parameters according to the characteristics\nof MultiRAG. All methods were implemented in a Python\n3.10 and CUDA 11.6 environment. Except for the experiments\nusing GPT-3.5-Turbo for CoT, the rest of the work utilized\nLlama3-8B-Instruct as the base model. For each different\ndata format, after slicing into Chunks, we stored the slice\nnumbers, data source locations, and transformed triple nodes\nin the multi-source line graph using JSON-LD format, thereby\nenabling simple cross-indexing.\nFor hyperparameter settings, the temperature parameter β\nwas set to 0.5. The number of entities in historical queries\nwas initialized to 50, the initial node confidence threshold was\ndefined as 0.7, and the graph confidence threshold was set\nto 0.5. All experiments were conducted on a device equipped\nwith an Intel(R) Core(TM) Ultra 9 185H 2.30GHz and 512GB\nof memory.\nd) Baseline Models: To demonstrate the superiority of\nthe MultiRAG method, we compare it with basic data fusion\nmethods and SOTA methods, including the multi-document\nquestion-answering methods and knowledge base question-\nanswering methods.\nThanks to Zhu’s work3 [34], we compare with the following\nbaseline methods:\n3https://github.com/JunHao-Zhu/FusionQuery\nTABLE II: Comparison with baseline methods and SOTA methods for multi-source knowledge fusion\nDatasets Data\nsource\nData Fusion Methods (Baseline) SOTA Methods Our Method\nTF LTM IR-CoT MDQA ChatKBQA FusionQuery MCC\nF1/% Time/s F1/% Time/s F1/% Time/s F1/% Time/s F1/% Time/s F1/% Time/s F1/% Time/s\nMovies\nJ/K 37.1 9717 41.4 1995 43.2 1567 46.2 1588 45.1 3809 53.2 122.4 52.6 98.3\nJ/C 41.9 7214 42.9 1884 45.0 1399 44.5 1360 42.7 3246 52.7 183.1 54.3 75.1\nK/C 37.8 2199 41.2 1576 37.6 1014 45.2 987 40.4 2027 42.5 141.0 49.1 86.0\nJ/K/C 36.6 11225 40.8 2346 41.5 2551 49.8 2264 44.7 5151 53.6 137.8 54.8 157\nBooks\nJ/C 40.2 1017 42.4 195.3s 35.2 147.6 55.7 124.2 56.1 165.0 58.5 22.7 63.5 13.66\nJ/X 35.5 1070 35.6 277.7 36.1 178.7 55.1 115.6 54.7 200.1 57.9 20.6 63.1 13.78\nC/X 43.0 1033 44.1 232.6 42.6 184.5 57.2 115.6 55.6 201.4 60.3 21.5 64.2 13.54\nJ/C/X 37.3 2304 41.0 413.2 40.4 342.6 56.4 222.6 57.1 394.1 59.1 47.0 66.8 27.4\nFlights C/J 27.3 6049 79.1 14786 58.3 214.0 76.5 360 76.8 376 74.2 20.2 74.9 80\nStocks C/J 68.4 2.30 19.2 1337 64.8 53.3 65.2 78.4 64.0 88.9 68.0 0.33 78.6 12.1\n* The F1 score is for Q1 and time is for Q5.\n* Bold represents the optimal metrics, while underlined text indicates the sub-optimal metrics. The same applies to the following text.\n1) TruthFinder(TF) [37]: the classic iterative data fusion\nmethod.\n2) LTM [42]: the probabilistic data fusion method.\n3) CoT [43] is a foundational approach that involves step-\nby-step reasoning to reach a conclusion, we use GPT-\n3.5-Turbo as the base model.\n4) Standard RAG [2] is a method that combines the\nstrengths of retrieval and generation models to answer\nquestions.\nMoreover, we also summerize these SOTA methods below:\n• IRCoT [44] is an advanced method that refines the\nreasoning process through iterative retrieval.\n• ChatKBQA [45] is a conversational interface-based\nmethod for knowledge base question answering.\n• MDQA [46] is a method designed to extract answers\nfrom multiple documents effectively.\n• FusionQuery [34] is a SOTA method based on the\nefficient on-demand fusion query framework.\n• RQ-RAG [47] is a method that integrates external docu-\nments and optimizes the query process to handle complex\nqueries.\n• MetaRAG [9] is a method that employs metacognitive\nstrategies to enhance the retrieval process.\ne) Dataset Preprocessing: To better align the datasets\nwith real-world application scenarios and to demonstrate the\napplicability of the proposed method to multi-source data,\nwe have split and reconstructed the four datasets into three\ncategories of data formats: tabular data (structured data),\nnested JSON data (semi-structured data), and XML data (semi-\nstructured data), stored respectively in csv, json, and xml file\nformats. We also retained some data directly stored in KG\nformat. Table I displays the detailed statistics after the dataset\ndivision.\nB. Evaluation of Multi-source Knowledge Aggregation (MKA)\nQ1: How does the retrieval recall performance of Mul-\ntiRAG compare with other data fusion models and SOTA\ndata retrieval models?\nTo validate the effectiveness of the multi-source knowledge\naggregation module (MKA) in MultiRAG, we assess it using\nF1 scores and query times across four multi-source query\ndatasets. By substituting the fusion query algorithm with\ndifferent baseline models and SOTA models, multiple sets of\nexperimental results are botained to evaluate its performance in\nmulti-domain querying. Table II summarizes the data querying\nperformance of MKLGP and baselines on the four datasets;\nQ1 focuses solely on the F1 scores of the methods, which\nincludes four data fusion methods and three SOTA methods\nthat support data fusion.\nTable II demonstrates that the MCC module outperforms all\ncomparative models across four datasets. Experimental results\nindicate that it achieves an F1 score that is more than 10%\nhigher than the best baseline data fusion model and obtains\nsuperior performance compared to other baselines. The MV\nmethod performs poorly on all datasets because it can only\nreturn a single answer for a query, which fails to accommodate\nthe common scenario where a query has multiple return\nvalues. For instance, a movie or a book typically has multiple\ndirectors or authors. However, the majority of methods show\nsignificantly better performance on the Movies and Flights\ndatasets than on the Books and Stocks datasets. This is\nbecause the Movies and Flights datasets are inherently denser,\nand previous SOTA models can match or outperform our\napproach in situations where knowledge is abundant, which\nis acceptable. In contrast, on the more sparse Books and\nStocks datasets, our method achieves an average improvement\nof more than 10% over SOTA methods.\nQ2: What are the respective impacts of data sparsity\nand data inconsistency on the quality of retrieval recall?\nMultiRAG demonstrates good robustness in scenarios of\nvarying data sparsity and inconsistency. To validate it, we\nconducted experiments from the following two perspectives. 1)\nSparsity of multi-source data: We applied 30%, 50%, and 70%\nrandom relationship masking to four pre-processed datasets,\nTABLE III: Ablation experiments of multi-source knowledge aggregation(MKA) and multi-level confidence computing(MCC)\nDatasets Source MultiRAG w/o MKA w/o Graph Level w/o Node Level w/o MCC\nF1/% QT/s PT/s F1/% QT/s PT/s F1/% QT/s PT/s F1/% QT/s PT/s F1/% QT/s PT/s\nMovies\nJ/K 52.6 25.7 62.64 48.2 2783 62.64 45.3 50.1 58.2 38.7 21.3 0.31 31.6 25.7 0.28\nJ/C 54.3 12.7 61.36 49.1 1882 61.36 46.8 28.9 57.4 40.2 10.5 0.29 30.5 12.7 0.29\nK/C 49.1 31.6 64.40 45.5 4233 64.40 42.7 65.3 61.8 35.9 28.4 -0.27 33.1 31.6 -0.29\nJ/K/C 54.8 39.2 60.8 47.5 4437 60.8 48.1 75.6 56.2 41.5 35.8 0.30 34.7 39.2 0.32\nBooks\nJ/C 63.5 1.19 2.47 57.1 11.9 2.47 55.2 4.7 2.12 49.8 0.92 0.18 43.4 1.19 0.22\nJ/X 63.1 1.22 2.56 59.3 11.7 2.62 54.7 5.1 2.24 48.3 0.89 0.19 42.6 1.22 0.22\nC/X 64.2 1.16 2.38 55.3 8.39 2.38 53.9 3.9 2.05 47.1 0.85 0.16 41.0 1.16 0.17\nJ/C/X 66.8 1.31 3.07 57.2 15.8 3.08 59.4 6.3 2.89 52.7 1.12 0.21 36.4 1.31 0.20\nFlights C/J 74.9 29.8 109.9 72.2 NAN 109.9 68.3 142.7 98.5 61.4 25.3 0.85 52.1 29.8 1.07\nStocks C/J 78.6 2.72 5.36 69.6 450.8 5.36 72.1 8.9 4.12 65.3 1.98 0.15 45.4 2.72 0.17\nTABLE IV: Performance comparison on HotpotQA and\n2WikiMultiHopQA datasets\nMethod HotpotQA 2WikiMultiHopQA\nPrecision Recall@5 Precision Recall@5\nStandard RAG 34.1 33.5 25.6 26.2\nGPT-3.5-Turbo+CoT 33.9 47.2 35.0 45.1\nIRCoT 41.6 41.2 42.3 40.9\nChatKBQA 47.8 42.1 46.5 43.7\nMDQA 48.6 52.5 44.1 45.8\nRQ-RAG 51.6 49.3 45.3 44.6\nMetaRAG 51.1 49.9 50.7 52.2\nMultiRAG 59.3 62.7 55.7 61.2\nmaking the connections between data sparser while ensuring\nthat the query answers are still retrievable. 2) Consistency of\nmulti-source data: We added 30%, 50%, and 70% of triple\nincrements (the new triples are copies of the original triples)\nto the four pre-processed datasets, and completely shuffled\nthe relationship edges of the added triples to disrupt the\nconsistency of multi-source data. Subsequently, we employed\nMultiRAG to experiment with datasets under both perturbation\nschemes.\nFirstly, to address data sparsity, we conducted experiments\non MultiRAG (Ours) and ChatKBQA (SOTA). The experi-\nmental results demonstrate that MultiRAG exhibits significant\nrobustness when faced with the challenge of data sparsity.\nSpecifically, after applying 30%, 50%, and 70% relationship\nmasking, the F1 score of MultiRAG on the Books dataset only\ndropped from 66.8% to 60.0%. On the Stocks dataset, its F1\nscore decreased from 78.6% to 71.0%, which have been shown\nin Fig.5b and Fig.5d. These moderate decreases indicate that\nMultiRAG can effectively maintain its performance even when\na substantial number of relationships are masked.\nIn contrast, ChatKBQA’s performance decline under the\nsame conditions is more significant. On the Books dataset,\nChatKBQA’s F1 score dropped from 59.1% to 53.0%, and\non the Stocks dataset, its F1 score decreased from 68.0% to\n62.0%. This outcome reveals the challenges ChatKBQA faces\nwhen dealing with sparse data, especially when a large number\nof data connections are masked, significantly impacting its\nperformance.\nNext, we conducted robustness experiments on multi-source\ndata consistency. We perturbed the Books and Stocks datasets\nto varying degrees to test the performance changes of Mul-\ntiRAG and ChatKBQA when data consistency is disrupted.\nThe experimental results show that MultiRAG demonstrates\nexcellent robustness in the face of data consistency disrup-\ntion, while ChatKBQA’s performance declines rapidly under\nperturbation.\nSpecifically, as is shown in Fig. 5a, on the Movies dataset,\nwe added 30%, 50%, and 70% triple increments to the original\ndataset and randomized the relationship edges of the added\ntriples. The results show that MultiRAG’s F1 score slightly\ndecreased from 54.8% to 52.1%, 51.5%, and 49.9%, while\nChatKBQA’s F1 score significantly dropped from 53.6% to\n51.6%, 47.2%, and 40.8%. On the Flights dataset shown in\nFig. 5c, we performed the same perturbation operations, and\nMultiRAG’s F1 score slightly decreased from 74.9% to 73.4%,\n72.9%, and 71.4%, while ChatKBQA’s F1 score substantially\ndropped from 74.2% to 69.7%, 64.3%, and 55.8%.\nThese results indicate that even when data consistency is\nseverely compromised, MultiRAG can still maintain a high\nlevel of performance stability, whereas ChatKBQA’s perfor-\nmance is more sensitive to disruptions in data consistency.\nC. Evaluation of Multi-level Confidence Computing\nCalculating the confidence of subgraphs and nodes to filter\ntrustworthy answers is of significant demand in critical do-\nmains such as finance and law. Considering the high temporal\nand spatial overhead of directly calculating the confidence\nof all nodes, we draw inspiration from the workflow of\nrecommendation systems, mimicking the process of coarse and\nfine ranking, and adopt the multi-level confidence computing\nmethod to filter credible nodes and enhance retrieval perfor-\n(a) F1 Score in Movies\n (b) F1 Score in Books\n (c) F1 Score in Flights\n (d) F1 Score in Stocks\nFig. 5: Experimental results of Q2, where (a) and (b) display the multi-source data sparsity experiments, and (c) and (d) display\nthe multi-source data consistency experiments.\n(a) Efficiency-Accuracy Tradeoff of Movies Dataset\n (b) Efficiency-Accuracy Tradeoff of Books Dataset\nFig. 6: F1 score and Query Time of Movies and Books with corruption level 0%, 10%, 30%, 50%, 70% in different sources\nmance. Calculating the credibility of homologous subgraphs\nallows us to preliminarily determine whether the subgraphs\ncontaining answers can generate highly credible answers.\nFor subgraphs with low confidence, more nodes need to be\nextracted to ensure the robustness of the overall retrieval; for\nsubgraphs with high confidence, only 1-2 nodes are required\nto generate the correct answer.\nQ3: How effective are the two modules of MultiRAG\nindividually?\na) Ablation Study on Component Effectiveness: The\nMKA module achieves significant efficiency-accuracy synergy\nthrough its MLG architecture. As shown in Table III, MLG\nconstruction introduces modest preprocessing time (12.7s-\n39.2s) while delivering 10-100× query acceleration. Specifi-\ncally, the flight dataset shows QT reduction from computa-\ntional infeasibility (marked NAN) to 29.8s through MLG’s\ncompact structure. Concurrently, MKA sustains consistent\naccuracy improvements. Removing MKA causes F1 drops\nof 7.3% on Movies and 9.6% on Books, demonstrating\nMLG’s effectiveness in connecting fragmented knowledge\nacross sources.\nThe MCC module exhibits more significant effects on\nperformance and hallucination control. Disabling MCC causes\ndrastic F1 degradation of 20.1% on Movies and 33.2% on\nStocks, with PT values indicating increased hallucination risks.\nThis validates MCC’s critical role in eliminating unreliable\ninformation through hierarchical confidence computation.\nb) Hierarchical Analysis of MCC: Stratified ablation\nreveals the complementary roles of graph-level and node-level\ncomputations. For Movies (J/K/C configuration), removing\ngraph-level filtering reduces F1 to 48.1% (+13.4% vs MCC-\ndisabled) with QT increasing to 75.6s (+93% vs full frame-\nwork). Conversely, disabling node-level computation yields\n41.5% F1 (+6.8% vs baseline), showing graph-level filtering\nalone cannot resolve local conflicts. The complete MCC\nframework achieves 54.8% F1 by synergistically combining\nboth layers.\nError analysis shows distinct failure patterns: 38.7% errors\nunder graph-level removal (Movies J/K) stem from cross-\nsource inconsistencies, while 52.7% failures with node-level\nremoval (Books J/C/X) originate from local authority issues.\nThis confirms the functional specialization—graph-level en-\nsures global consistency, node-level verifies local credibility.\nFig.7 demonstrates that an optimal balance between effi-\nciency and accuracy is achieved at α = 0.5, where the hybrid\nweighting of LLM-assessed authority and historical authority\npeaks with an F1 score of 67.7% and balanced query time.\nSpecifically, increasing α towards 1.0, which emphasizes the\nLLM, reduces query time from 83.2 seconds ( α = 0.0) to 51.8\nseconds ( α = 1.0) by minimizing historical data validation.\nConversely, the F1 score follows a non-monotonic pattern,\nreaching its maximum at α = 0.5 before declining as reliance\non either the LLM or historical data becomes excessive.\nThis equilibrium leverages the LLM’s contextual adaptability\n(AuthLLM) while maintaining the stability of expert systems\n(Authhist), as evidenced by a 62.4% reduction in errors during\nablation studies when both components are utilized. By avoid-\ning complete dependence on the LLM ( α ̸= 1.0) and integrat-\ning probabilistic LLM inferences with deterministic historical\npatterns through multi-level confidence computing (Eq.9), the\nTABLE V: Case Study\nQuery: ”What is the real-time status of Air China flight CA981 from Beijing Capital International Airport (PEK) to New York John F. Kennedy Airport (JFK)?”\nData SourcesStructured CA981, PEK, JFK, Delayed, 2024-10-01 14:30Semi-structured {”flight”: ”CA981”, ”delayreason”: ”Weather”, ”source”: ”AirChina”}Unstructured ”Typhoon Haikui impacts PEK departures after 14:00.”\nMKA Module Structured parsing: Flight attributes mappingLLM extraction:(CA981, DelayReason, Typhoon) @0.87\nMLG Subgraph\nCA981(Flight)\nPEK(Origin) JFK(Destination)\nDelayed(Status)\nOn-time(User Claim) Typhoon(Cause)\nAirChina APP(Source)\nAfter 14:00+(Impact Time)ForumUser123(Source)\nDeparture\nDestination\nConflict\nStatus\nReason\nSource\nEffectiveSource\nMCC Module With GCC: Graph confidence=0.71 (Threshold=0.5), Filtered: ForumUser123 (0.47)Without GCC: Unfiltered conflict=2 subgraphs\nLLM Context Trusted: CA981.Status=Delayed (0.89), DelayReason=Typhoon (0.85)Conflicts: ForumUser123:On-time (0.47), WeatherAPI:Clear (0.52)\nFinal Answer Correct: ”CA981 delayed until after 14:30 due to typhoon”\nHallucinated: ”CA981on-time with possible delay after 14:30”\nmethodology enhances robustness against data sparsity and\nnoise, particularly in the Books and Stocks datasets.\nFig. 7: Influence of hyperparameter α on multi-source retrieval\nQ4: How is the performance of MultiRAG in multi-hop\nQ&A datasets after incorporating multi-level confidence\ncalculation?\nTo assess the validity of the multi-level confidence com-\nputing method in reducing hallucinations generated by large\nmodels and enhancing the credibility of Q&A systems, we\ncompare the Recall@5 scores of different methods on the\nHotpotQA and 2WikiMultiHopQA datasets.\nThe outcome of Table IV indicates that the multi-level\nconfidence computing method not only demonstrates a higher\naverage Recall@5 score but also maintains a lower standard\ndeviation compared to traditional methods. This suggests that\nthe multi-level confidence computing method is more con-\nsistent in its performance across different queries, leading to\nfewer hallucinations and more reliable Q&A responses. The\nlower standard deviation is a testament to the robustness of\nthe mechanism in handling the variability in data and the\ncomplexity of the queries.\nFurthermore, we performed a detailed error analysis to iden-\ntify the types and frequency of hallucinations in the responses\ngenerated by the different methods. The results showed that\nthe multi-level confidence computing method significantly\nreduced the frequency of hallucinations, particularly in the\ncases where the context was ambiguous or the information\nwas not readily available in the knowledge base.\nQ5: What are the time costs of the two modules in\nMultiRAG?\nIntuitively, MLG aggregates homologous data from several\nsources, ensuring the density of the retrieval subgraphs without\nthe need to traverse and store an excessive number of invalid\nnodes, thereby significantly reducing the time cost associated\nwith traversing and querying in traditional knowledge graphs.\nFurthermore, although the SOTA methods are not specifi-\ncally tailored for low-resource, high-noise data scenarios, they\nstill exhibit considerable robustness and retrieval performance\nin such environments. Both the MDQA and ChatKBQA mod-\nels employ LLM-based data retrieval approaches, with the\nprimary temporal and spatial overheads focusing on token\nconsumption and LLM-based searching.\nIn contrast, MultiRAG concentrates its overhead on the\nconstruction of the MLG. While in the original context of the\nMLG, construction times are often within seconds and highly\nefficient, the introduction of an LLM still incurs additional\ntemporal costs due to text generation, which remains accept-\nable. Ultimately, these methods all demonstrate satisfactory\nretrieval performance; however, due to the inherent noise in the\ndatasets, improvements in the accuracy of question-answering\nare somewhat limited.\nD. Case Study\nMultiRAG’s effectiveness in multi-source integration is\ndemonstrated through a real-world flight status query for\n”CA981 from Beijing to New York”. As detailed in Table\nV, case study exemplifies MultiRAG’s unique strength in\ntransforming fragmented, conflicting inputs into trustworthy\nanswers through systematic source weighting and consensus\nmodeling.\nFirstly, MultiRAG integrated three data formats: structured\ndeparture schedules, semi-structured delay codes from airline\nsystems, and unstructured weather alerts. The MKA mod-\nule extracted key relationships (flight-delay-typhoon) with a\nconfidence score of 0.87. Subsequently, the MCC module\nresolved conflicts through hierarchical verification by filter-\ning out low-reliability sources, such as user forums (con-\nfidence score of 0.47), while prioritizing data from air-\nlines (confidence score of 0.89) and weather reports. This\ndual-layer validation—combining automated threshold checks\n(graph confidence of 0.71) with LLM-simulated expert reason-\ning—enabled the precise reconciliation of contradictory depar-\nture time claims. Ultimately, the system generated the verified\nconclusion, ”Delayed until after 14:30 due to typhoon,” while\nsuppressing the inconsistent ”on-time” report.\nE. Restrictive Analysis\nLastly but not least, we acknowledge several limitations\ninherent in our current framework.\n1) Lack of optimization of text chunk segmentation.\n2) Reliance on LLM-based expert evaluation, which may\nintroduce potential security vulnerabilities.\n3) Focuses on eliminating factual hallucinations but lacks\nhandling of symbolic hallucinations.\nV. R ELATED WORK\nA. Graph-Structured Approaches for Hallucination Mitigation\nRecent advancements have demonstrated unique advantages\nof graph structures in mitigating hallucinations within RAG\nsystems. MetaRAG [9] establishes knowledge association ver-\nification through meta-cognitive graph reasoning paths, en-\nhancing self-correction mechanisms in multi-hop QA. Graph-\nCoT [48] innovatively leverages Graph Neural Networks to\nestablish bidirectional connections between KGs and the latent\nspace of LLMs. In result, it reduces factual inconsistencies\nby 37% on KGQA benchmarks. Inspired by neurobiology,\nHippoRAG [23] constructs offline memory graphs with a\nneural indexing mechanism, decreasing retrieval latency to\none-eighth of traditional methods. While ToG 2.0 [25] further\nadvances this field by introducing a graph-context co-retrieval\nframework that dynamically balances structured and unstruc-\ntured evidence, resulting in a 29% reduction in hallucination\nrates compared to unimodal approaches.\nUnlike prior approaches that primarily focus on unimodal\nconfidence calculations, MultiRAG achieves superior halluci-\nnation mitigation through the adaptive filtering of conflicting\nsubgraphs (GCC module) while maintaining multi-domain\nlogical associations via its novel knowledge aggregation mech-\nanism (MKA module).\nB. Heterogeneous Graph Fusion for RAG\nThe fusion of multi-source heterogeneous data relies on\nadvanced graph representation techniques. FusionQuery [34]\nenhances cross-domain retrieval precision by integrating het-\nerogeneous graphs and computing dynamic credibility evalu-\nations. The Triple Line Graph [31] addresses the challenge of\nknowledge fragmentation by systematically aggregating cross-\ndomain relationships, leading to Multi-source Line Graph\nproposed in this paper. Additionally, leveraging the structured\nrepresentation advantages of KAG [26] in knowledge-guided\nretrieval, we achieve a unified representation approach for\nmulti-source KGs, underscoring the importance of heteroge-\nneous graph fusion in real-world applications.\nC. Hallucination Benchmark and Confidence-Aware Comput-\ning\nThe evaluation of hallucinations in LLMs and associated\nconfidence calculation methods are crucial for mitigating\nhallucinations. HaluEval [49] offers 5,000 annotated samples\nacross five error categories, but lacks granularity for relational\nhallucinations. RefChecker [50] implements triple decomposi-\ntion for fine-grained detection, improving precision by 26.1%\nover sentence-level methods. RAGTruth [51] contains nearly\n18,000 RAG-generated responses with detailed manual annota-\ntions including word-level hallucination intensities. However,\ndiverse and complex data sources continue to challenge exist-\ning evaluation frameworks.\nVI. CONCLUSION\nIn this work, we introduce MultiRAG, a framework de-\nsigned to mitigate hallucination in multi-source knowledge-\naugmented generation. To address hallucinations arising from\ndata sparsity and inconsistency, we propose two key inno-\nvations: multi-source knowledge aggregation and multi-level\nconfidence calculation. The introduction of multi-source line\ngraphs enables efficient cross-domain data aggregation, en-\nhancing knowledge connectivity and retrieval performance.\nMeanwhile, our multi-level confidence computing module\nadaptively filter out low-quality subgraphs and unreliable\nnodes. Future work will explore more challenging aspects of\nhallucination mitigation, particularly in multimodal retrieval\nand ultra-long text reasoning, to better adapt generative re-\ntrieval systems to real-world, open multi-source environments.\nVII. ACKNOWLEDGEMENT\nThis work is supported by the National Natural Science\nFoundation of China (62176185, U23B2057), and the “14th\nFive-Year Plan” Civil Aerospace Pre-research Project of China\n(D020101).\nREFERENCES\n[1] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin,\nC. Zhang, S. Agarwal, K. Slama, A. Ray et al. , “Training language\nmodels to follow instructions with human feedback,” Advances in neural\ninformation processing systems , vol. 35, pp. 27 730–27 744, 2022.\n[2] P. Lewis, E. Perez, A. Piktus, F. Petroni, V . Karpukhin, N. Goyal,\nH. K ¨uttler, M. Lewis, W.-t. Yih, T. Rockt ¨aschel et al. , “Retrieval-\naugmented generation for knowledge-intensive nlp tasks,” Advances in\nNeural Information Processing Systems , vol. 33, pp. 9459–9474, 2020.\n[3] K. Guu, K. Lee, Z. Tung, P. Pasupat, and M. Chang, “Retrieval\naugmented language model pre-training,” in International conference\non machine learning . PMLR, 2020, pp. 3929–3938.\n[4] Y . Gao, Y . Xiong, X. Gao, K. Jia, J. Pan, Y . Bi, Y . Dai, J. Sun,\nH. Wang, and H. Wang, “Retrieval-augmented generation for large\nlanguage models: A survey,” arXiv preprint arXiv:2312.10997 , vol. 2,\n2023.\n[5] G. Izacard and E. Grave, “Leveraging passage retrieval with gener-\native models for open domain question answering,” arXiv preprint\narXiv:2007.01282, 2020.\n[6] G. Izacard, P. Lewis, M. Lomeli, L. Hosseini, F. Petroni, T. Schick,\nJ. Dwivedi-Yu, A. Joulin, S. Riedel, and E. Grave, “Few-shot\nlearning with retrieval augmented language models,” arXiv preprint\narXiv:2208.03299, vol. 2, no. 3, 2022.\n[7] Z. Jiang, L. Gao, J. Araki, H. Ding, Z. Wang, J. Callan, and G. Neubig,\n“Retrieval as attention: End-to-end learning of retrieval and reading\nwithin a single transformer,” arXiv preprint arXiv:2212.02027 , 2022.\n[8] P. Lewis, E. Perez, A. Piktus, F. Petroni, V . Karpukhin, N. Goyal,\nH. K ¨uttler, M. Lewis, W.-t. Yih, T. Rockt ¨aschel et al. , “Retrieval-\naugmented generation for knowledge-intensive nlp tasks,” Advances in\nNeural Information Processing Systems , vol. 33, pp. 9459–9474, 2020.\n[9] Y . Zhou, Z. Liu, J. Jin, J.-Y . Nie, and Z. Dou, “Metacognitive retrieval-\naugmented large language models,” in Proceedings of the ACM on Web\nConference 2024, 2024, pp. 1453–1463.\n[10] H. Zeng, C. Luo, B. Jin, S. M. Sarwar, T. Wei, and H. Zamani, “Scalable\nand effective generative information retrieval,” in Proceedings of the\nACM on Web Conference 2024 , 2024, pp. 1441–1452.\n[11] W. Wu, H. Yin, N. Wang, M. Xu, X. Zhao, Z. Yin, Y . Liu, H. Wang,\nY . Ding, and B. Li, “A cross-domain heterogeneous data query frame-\nwork via collaboration of large language models and knowledge graphs,”\nJournal of Computer Research and Development , vol. 62, no. 3, pp.\n605–619, 2025.\n[12] S. Pan, L. Luo, Y . Wang, C. Chen, J. Wang, and X. Wu, “Unifying\nlarge language models and knowledge graphs: A roadmap,” IEEE\nTransactions on Knowledge and Data Engineering , 2024.\n[13] L. Luo, Y .-F. Li, G. Haffari, and S. Pan, “Reasoning on graphs: Faith-\nful and interpretable large language model reasoning,” arXiv preprint\narXiv:2310.01061, 2023.\n[14] J. Wang, K. Sun, L. Luo, W. Wei, Y . Hu, A. W.-C. Liew, S. Pan, and\nB. Yin, “Large language models-guided dynamic adaptation for temporal\nknowledge graph reasoning,” arXiv preprint arXiv:2405.14170 , 2024.\n[15] Q. Sun, K. Huang, X. Yang, R. Tong, K. Zhang, and S. Poria,\n“Consistency guided knowledge retrieval and denoising in llms for zero-\nshot document-level relation triplet extraction,” in Proceedings of the\nACM on Web Conference 2024 , 2024, pp. 4407–4416.\n[16] M. Zamiri, Y . Qiang, F. Nikolaev, D. Zhu, and A. Kotov, “Benchmark\nand neural architecture for conversational entity retrieval from a knowl-\nedge graph,” in Proceedings of the ACM on Web Conference 2024, 2024,\npp. 1519–1528.\n[17] Y . Li, G. Zang, C. Song, X. Yuan, and T. Ge, “Leveraging semantic\ninformation for enhanced community search in heterogeneous graphs,”\nData Science and Engineering , vol. 9, no. 2, pp. 220–237, 2024.\n[18] Y . Hu, C. Chen, B. Deng, Y . Lai, H. Lin, Z. Zheng, and J. Bian,\n“Decoupling anomaly discrimination and representation learning: self-\nsupervised learning for anomaly detection on attributed graph,” Data\nScience and Engineering , vol. 9, no. 3, pp. 264–277, 2024.\n[19] Z. Li, X. Wang, J. Zhao, W. Guo, and J. Li, “Hycube: Efficient\nknowledge hypergraph 3d circular convolutional embedding,” IEEE\nTransactions on Knowledge and Data Engineering , 2025.\n[20] Z. Li, C. Wang, X. Wang, Z. Chen, and J. Li, “Hje: joint convolutional\nrepresentation learning for knowledge hypergraph completion,” IEEE\nTransactions on Knowledge and Data Engineering , vol. 36, no. 8, pp.\n3879–3892, 2024.\n[21] L. Luo, Y .-F. Li, G. Haffari, and S. Pan, “Reasoning on graphs: Faith-\nful and interpretable large language model reasoning,” arXiv preprint\narXiv:2310.01061, 2023.\n[22] D. Edge, H. Trinh, N. Cheng, J. Bradley, A. Chao, A. Mody, S. Truitt,\nand J. Larson, “From local to global: A graph rag approach to query-\nfocused summarization,” arXiv preprint arXiv:2404.16130 , 2024.\n[23] B. J. Guti ´errez, Y . Shu, Y . Gu, M. Yasunaga, and Y . Su, “Hipporag: Neu-\nrobiologically inspired long-term memory for large language models,”\narXiv preprint arXiv:2405.14831 , 2024.\n[24] C. Mavromatis and G. Karypis, “Gnn-rag: Graph neural retrieval for\nlarge language model reasoning,” arXiv preprint arXiv:2405.20139 ,\n2024.\n[25] S. Ma, C. Xu, X. Jiang, M. Li, H. Qu, C. Yang, J. Mao, and J. Guo,\n“Think-on-graph 2.0: Deep and faithful large language model reasoning\nwith knowledge-guided retrieval augmented generation,” arXiv preprint\narXiv:2407.10805, 2024.\n[26] L. Liang, M. Sun, Z. Gui, Z. Zhu, Z. Jiang, L. Zhong, Y . Qu, P. Zhao,\nZ. Bo, J. Yang et al., “Kag: Boosting llms in professional domains via\nknowledge augmented generation,” arXiv preprint arXiv:2409.13731 ,\n2024.\n[27] W. Ding, J. Li, L. Luo, and Y . Qu, “Enhancing complex question\nanswering over knowledge graphs through evidence pattern retrieval,”\nin Proceedings of the ACM on Web Conference 2024 , 2024, pp. 2106–\n2115.\n[28] X. Wang, Z. Chen, H. Wang, Z. Li, W. Guo et al. , “Large language\nmodel enhanced knowledge representation learning: A survey,” arXiv\npreprint arXiv:2407.00936, 2024.\n[29] Y . Gao, Y . Xiong, W. Wu, Z. Huang, B. Li, and H. Wang, “U-niah:\nUnified rag and llm evaluation for long context needle-in-a-haystack,”\narXiv preprint arXiv:2503.00353 , 2025.\n[30] F. Wang, X. Wan, R. Sun, J. Chen, and S. ¨O. Arık, “Astute rag:\nOvercoming imperfect retrieval augmentation and knowledge conflicts\nfor large language models,” arXiv preprint arXiv:2410.07176 , 2024.\n[31] V . Fionda and G. Pirr `o, “Learning triple embeddings from knowledge\ngraphs,” in proceedings of the AAAI conference on artificial intelligence,\nvol. 34, no. 04, 2020, pp. 3874–3881.\n[32] P. Yi, L. Liang, D. Zhang, Y . Chen, J. Zhu, X. Liu, K. Tang, J. Chen,\nH. Lin, L. Qiu, and J. Zhou, “Kgfabric: A scalable knowledge graph\nwarehouse for enterprise data interconnection,” Proc. VLDB Endow. ,\nvol. 17, no. 12, p. 3841–3854, Aug. 2024.\n[33] X. ZHANG, W. SUN, and H. W ANG, “Evaluation of knowledge\ncredibility based on knowledge representation learning,” Computer En-\ngineering, vol. 47, no. 7, pp. 44–54, 2021.\n[34] J. Zhu, Y . Mao, L. Chen, C. Ge, Z. Wei, and Y . Gao, “Fusionquery:\nOn-demand fusion queries over multi-source heterogeneous data,” Pro-\nceedings of the VLDB Endowment , vol. 17, no. 6, pp. 1337–1349, 2024.\n[35] X. Li, X. L. Dong, K. Lyons, W. Meng, and D. Srivastava, “Truth\nfinding on the deep web: Is the problem solved?” arXiv preprint\narXiv:1503.00303, 2015.\n[36] X. L. Dong, L. Berti-Equille, and D. Srivastava, “Integrating conflicting\ndata: the role of source dependence,” Proceedings of the VLDB Endow-\nment, vol. 2, no. 1, pp. 550–561, 2009.\n[37] X. Yin, J. Han, and P. S. Yu, “Truth discovery with multiple conflicting\ninformation providers on the web,” in Proceedings of the 13th ACM\nSIGKDD international conference on Knowledge discovery and data\nmining, 2007, pp. 1048–1052.\n[38] Z. Yang, P. Qi, S. Zhang, Y . Bengio, W. W. Cohen, R. Salakhutdinov, and\nC. D. Manning, “Hotpotqa: A dataset for diverse, explainable multi-hop\nquestion answering,” arXiv preprint arXiv:1809.09600 , 2018.\n[39] X. Ho, A.-K. D. Nguyen, S. Sugawara, and A. Aizawa, “Constructing a\nmulti-hop qa dataset for comprehensive evaluation of reasoning steps,”\narXiv preprint arXiv:2011.01060 , 2020.\n[40] X. Lin and L. Chen, “Domain-aware multi-truth discovery from con-\nflicting sources,” Proceedings of the VLDB Endowment , vol. 11, no. 5,\npp. 635–647, 2018.\n[41] Y . Wang, N. Lipka, R. A. Rossi, A. Siu, R. Zhang, and T. Derr,\n“Knowledge graph prompting for multi-document question answering,”\nin Proceedings of the AAAI Conference on Artificial Intelligence, vol. 38,\nno. 17, 2024, pp. 19 206–19 214.\n[42] B. Zhao, B. I. Rubinstein, J. Gemmell, and J. Han, “A bayesian approach\nto discovering truth from conflicting sources for data integration,” arXiv\npreprint arXiv:1203.0058, 2012.\n[43] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V . Le,\nD. Zhou et al. , “Chain-of-thought prompting elicits reasoning in large\nlanguage models,” Advances in neural information processing systems ,\nvol. 35, pp. 24 824–24 837, 2022.\n[44] H. Trivedi, N. Balasubramanian, T. Khot, and A. Sabharwal, “Interleav-\ning retrieval with chain-of-thought reasoning for knowledge-intensive\nmulti-step questions,” ArXiv, vol. abs/2212.10509, 2022.\n[45] H. Luo, Z. Tang, S. Peng, Y . Guo, W. Zhang, C. Ma, G. Dong,\nM. Song, W. Lin et al., “Chatkbqa: A generate-then-retrieve framework\nfor knowledge base question answering with fine-tuned large language\nmodels,” arXiv preprint arXiv:2310.08975 , 2023.\n[46] Y . Wang, N. Lipka, R. A. Rossi, A. Siu, R. Zhang, and T. Derr,\n“Knowledge graph prompting for multi-document question answering,”\nin Proceedings of the AAAI Conference on Artificial Intelligence, vol. 38,\nno. 17, 2024, pp. 19 206–19 214.\n[47] C.-M. Chan, C. Xu, R. Yuan, H. Luo, W. Xue, Y . Guo, and J. Fu,\n“Rq-rag: Learning to refine queries for retrieval augmented generation,”\narXiv preprint arXiv:2404.00610 , 2024.\n[48] B. Jin, C. Xie, J. Zhang, K. K. Roy, Y . Zhang, Z. Li, R. Li, X. Tang,\nS. Wang, Y . Meng, and J. Han, “Graph chain-of-thought: Augment-\ning large language models by reasoning on graphs,” in Findings of\nthe Association for Computational Linguistics: ACL 2024 , L.-W. Ku,\nA. Martins, and V . Srikumar, Eds. Bangkok, Thailand: Association for\nComputational Linguistics, Aug. 2024, pp. 163–184.\n[49] J. Li, X. Cheng, W. X. Zhao, J.-Y . Nie, and J.-R. Wen, “Halueval:\nA large-scale hallucination evaluation benchmark for large language\nmodels,” arXiv preprint arXiv:2305.11747 , 2023.\n[50] X. Hu, D. Ru, L. Qiu, Q. Guo, T. Zhang, Y . Xu, Y . Luo, P. Liu,\nY . Zhang, and Z. Zhang, “Refchecker: Reference-based fine-grained\nhallucination checker and benchmark for large language models,” arXiv\npreprint arXiv:2405.14486, 2024.\n[51] C. Niu, Y . Wu, J. Zhu, S. Xu, K. Shum, R. Zhong, J. Song, and T. Zhang,\n“RAGTruth: A hallucination corpus for developing trustworthy retrieval-\naugmented language models,” in Proceedings of the 62nd Annual\nMeeting of the Association for Computational Linguistics (Volume 1:\nLong Papers), L.-W. Ku, A. Martins, and V . Srikumar, Eds. Bangkok,\nThailand: Association for Computational Linguistics, Aug. 2024, pp.\n10 862–10 878."
}