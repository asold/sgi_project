{
    "title": "Opportunities, challenges, and future directions of large language models, including ChatGPT in medical education: a systematic scoping review",
    "url": "https://openalex.org/W4392863142",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2096009489",
            "name": "Xiaojun Xu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2152718357",
            "name": "Yixiao Chen",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1964595189",
            "name": "Jing Miao",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1964595189",
            "name": "Jing Miao",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4389164161",
        "https://openalex.org/W4315797044",
        "https://openalex.org/W4385406146",
        "https://openalex.org/W4390271853",
        "https://openalex.org/W4388910129",
        "https://openalex.org/W4387602412",
        "https://openalex.org/W4387662141",
        "https://openalex.org/W4316671929",
        "https://openalex.org/W4390342439",
        "https://openalex.org/W4368367885",
        "https://openalex.org/W4388813824",
        "https://openalex.org/W2891378911",
        "https://openalex.org/W4319460874",
        "https://openalex.org/W4379056517",
        "https://openalex.org/W4385900159",
        "https://openalex.org/W4380884071",
        "https://openalex.org/W4386245324",
        "https://openalex.org/W4366692100",
        "https://openalex.org/W4385827193",
        "https://openalex.org/W4327946446",
        "https://openalex.org/W4362513839",
        "https://openalex.org/W4378229839",
        "https://openalex.org/W4385431333",
        "https://openalex.org/W4387829826",
        "https://openalex.org/W4383371673",
        "https://openalex.org/W4321499561",
        "https://openalex.org/W4386770320",
        "https://openalex.org/W4387516812",
        "https://openalex.org/W4378527660",
        "https://openalex.org/W4385551533",
        "https://openalex.org/W4319662928",
        "https://openalex.org/W4380291159",
        "https://openalex.org/W4386935603",
        "https://openalex.org/W4377030497",
        "https://openalex.org/W4383371705",
        "https://openalex.org/W4365443059",
        "https://openalex.org/W4386330105",
        "https://openalex.org/W4387144847",
        "https://openalex.org/W4379508361",
        "https://openalex.org/W4390751193",
        "https://openalex.org/W4389235809",
        "https://openalex.org/W4385568225",
        "https://openalex.org/W4387744236",
        "https://openalex.org/W4387500346",
        "https://openalex.org/W4386033478",
        "https://openalex.org/W4376108530",
        "https://openalex.org/W4387706149",
        "https://openalex.org/W4376866715",
        "https://openalex.org/W4380291947",
        "https://openalex.org/W2745950184",
        "https://openalex.org/W2098523432",
        "https://openalex.org/W4388551821",
        "https://openalex.org/W4367051110",
        "https://openalex.org/W4317390716",
        "https://openalex.org/W4379793093",
        "https://openalex.org/W4387363029",
        "https://openalex.org/W4315498620"
    ],
    "abstract": "Background: ChatGPT is a large language model (LLM) based on artificial intelligence (AI) capable of responding in multiple languages and generating nuanced and highly complex responses. While ChatGPT holds promising applications in medical education, its limitations and potential risks cannot be ignored.Methods: A scoping review was conducted for English articles discussing ChatGPT in the context of medical education published after 2022. A literature search was performed using PubMed/MEDLINE, Embase, and Web of Science databases, and information was extracted from the relevant studies that were ultimately included.Results: ChatGPT exhibits various potential applications in medical education, such as providing personalized learning plans and materials, creating clinical practice simulation scenarios, and assisting in writing articles. However, challenges associated with academic integrity, data accuracy, and potential harm to learning were also highlighted in the literature. The paper emphasizes certain recommendations for using ChatGPT, including the establishment of guidelines. Based on the review, 3 key research areas were proposed: cultivating the ability of medical students to use ChatGPT correctly, integrating ChatGPT into teaching activities and processes, and proposing standards for the use of AI by medical students.Conclusion: ChatGPT has the potential to transform medical education, but careful consideration is required for its full integration. To harness the full potential of ChatGPT in medical education, attention should not only be given to the capabilities of AI but also to its impact on students and teachers.",
    "full_text": "www.jeehp.org 1\n(page number not for citation purposes)\nJournal of Educational Evaluation\nfor Health Professions\nJ Educ Eval Health Prof 2024;21:6 • https://doi.org/10.3352/jeehp.2024.21.6\neISSN: 1975-5937\nOpen Access\nReview\nOpportunities, challenges, and future directions of large language \nmodels, including ChatGPT in medical education: a systematic \nscoping review\nXiaojun Xu*, Yixiao Chen, Jing Miao \nDivision of Hematology/Oncology, Children’s Hospital, Zhejiang University School of Medicine, National Clinical Research Centre for Child Health, Zhejiang, China  \nBackground: ChatGPT is a large language model (LLM) based on artificial intelligence (AI) capable of responding in multiple languages and generating nu-\nanced and highly complex responses. While ChatGPT holds promising applications in medical education, its limitations and potential risks cannot be ignored. \nMethods: A scoping review was conducted for English articles discussing ChatGPT in the context of medical education published after 2022. A literature \nsearch was performed using PubMed/MEDLINE, Embase, and Web of Science databases, and information was extracted from the relevant studies that were ul-\ntimately included. \nResults: ChatGPT exhibits various potential applications in medical education, such as providing personalized learning plans and materials, creating clinical \npractice simulation scenarios, and assisting in writing articles. However, challenges associated with academic integrity, data accuracy, and potential harm to \nlearning were also highlighted in the literature. The paper emphasizes certain recommendations for using ChatGPT , including the establishment of guidelines. \nBased on the review, 3 key research areas were proposed: cultivating the ability of medical students to use ChatGPT correctly, integrating ChatGPT into teach-\ning activities and processes, and proposing standards for the use of AI by medical students. \nConclusion: ChatGPT has the potential to transform medical education, but careful consideration is required for its full integration. T o harness the full poten-\ntial of ChatGPT in medical education, attention should not only be given to the capabilities of AI but also to its impact on students and teachers. \nKeywords: Artificial intelligence; Data accuracy; Medical students; Medical education; Attention  \n2024 Korea Health Personnel Licensing Examination Institute \nThis is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, \nand reproduction in any medium, provided the original work is properly cited.\n*Corresponding email: \nxuxiaojun@zju.edu.cn\nEditor: Sun Huh, Hallym University, Korea\nReceived: January 12, 2024 \nAccepted: March 5, 2024\nPublished: March 15, 2024\nThis article is available from: \nhttp://jeehp.org\nOpportunities, challenges, and future directions of large language models,\nincluding ChatGPT in medical education: a systematic scoping review\nUsing ChatGPT appropriately\nSuggestions\nApplications \nand benefits\nRisk and \nlimitations\nPotential harms to learningImproving teaching quality\nMedical exam preparation Academic integrity\nIntegrating ChatGPT \ninto teaching Establishing guidelines\nPersonalized \nlearning plans\nAccuracy, \nreliability\n\n(page number not for citation purposes)\nJ Educ Eval Health Prof 2024;21:6 • https://doi.org/10.3352/jeehp.2024.21.6\nwww.jeehp.org 2\nIntroduction \nRationale \nThe ChatGPT , launched in November 2022, is a large language \nmodel (LLM) based on artificial intelligence (AI). T rained on ex-\ntensive text datasets in multiple languages, it possesses the capa-\nbility to generate human-like responses [1]. Since ChatGPT came \nout, the scientific community’s opinions have been mixed. On the \none hand, ChatGPT helps to improve efficiency in academic \nwriting [2-4]. On the other hand, it is limited by its training data-\nsets, leading to seemingly reasonable yet erroneous outputs [5,6]. \nOther potential concerns include privacy breaches and the dis-\nsemination of misinformation [5,7,8]. In the healthcare domain, \nChatGPT has demonstrated significant value, aiding in clinical di-\nagnosis and decision-making, the provision of personalized \nhealthcare, drug development, and the analysis of large clinical \ndatasets [9,10]. However, its applications in medical education \nhave received limited exploration despite its vast potential. Given \nthe substantial amount of information and concepts that medical \nstudents need to grasp, this area is interesting and worthy of ex-\nploration. \nObjectives \nThis paper conducted a scoping review of existing literature dis-\ncussing ChatGPT in the context of medical education, extracts \nkey points regarding the advantages and disadvantages of \nChatGPT in medical education. We also aim to provide a founda-\ntion for future research and offer feasible insights and evidence for \nfurther exploration in this domain. \nMethods \nEthics statement \nThis was a literature-based study; therefore, neither approval \nfrom the institutional review board nor informed consent was re-\nquired. \nStudy design \nThis study conducted a scoping review, described in accor -\ndance with the Preferred Reporting Items for Systematic Reviews \nand Meta-Analyses Extension for Scoping Reviews (PRIS -\nMA-ScR) guidelines [11]. \nProtocol and registration \nAn internal review protocol was developed, but was neither reg-\nistered nor published (Supplement 1). \nEligibility criteria \nOur primary research questions were: what are the potential \nbenefits and limitations of ChatGPT in medical education, and \nwhat are the future directions? We aimed to guide future research \nby searching the literature on the application of ChatGPT in med-\nical education, delineating its potential application value, and as-\nsessing challenges and limitations. \nInclusion criteria: articles or preprints discussing ChatGPT in \nthe context of medical education; written in English; and, pub-\nlished between January 1, 2022 and November 30, 2023. Exclu-\nsion criteria: non-English writing; articles focusing solely on \nnon-clinical medical education (e.g., nursing, pharmacy, and den-\ntistry); and articles unrelated to medical education. \nInformation sources and search \nThe databases included PubMed/MEDLINE, Embase, and \nWeb of Science. As ChatGPT gained widespread acceptance and \napplication after 2022, the search timeframe was limited from Jan-\nuary 1, 2022, to November 30, 2023. The search statement can be \nfound in Supplement 2. Two reviewers independently conducted \na systematic search. \nSelection of sources of evidence \nArticle selection was independently conducted by 2 authors, \nand discrepancies were resolved through independent review by a \nthird author ( J.M.). A final consensus was reached through au-\nthor meetings. \nThe search results from PubMed/MEDLINE, Embase, and \nWeb of Science were imported into EndNote X9 (Clarivate), gen-\nerating a total of 1,066 records. Initially, 451 duplicate records \nwere excluded, followed by title and abstract screening, resulting \nin the exclusion of 420 irrelevant articles. Subsequently, full-text \nscreening was performed on the remaining 195 articles, with 15 \narticles excluded due to unavailability of full texts. Additionally, 2 \narticles did not focus on ChatGPT , 64 articles solely addressed \nnon-physician education, and one article was not in English, re-\nsulting in the inclusion of 113 articles (Fig. 1). \nData charting process and data items \nA specialized search was conducted for each included article, \nextracting the following information: article type (preprint, re-\nsearch article, review, commentary, etc.); potential applications \nand benefits of ChatGPT in medical education; potential risks \nand limitations of ChatGPT in medical education; and sugges-\ntions on the application of ChatGPT in medical education. \n(page number not for citation purposes)\nJ Educ Eval Health Prof 2024;21:6 • https://doi.org/10.3352/jeehp.2024.21.6\nwww.jeehp.org 3\nCritical appraisal of individual sources of evidence \nThe primary emphasis of the research is on a comprehensive \nscoping review rather than an in-depth analysis of individual \nsources of evidence. In order to maintain overall coherence and \nthematic consistency in the study, the decision was made to fore-\ngo a detailed evaluation of individual sources of evidence. \nSynthesis of results \nThematic analysis was conducted of the extracted data. Initially, \nopen coding was performed on the content in the extraction table, \nfollowed by the creation of axial codes to categorize existing \ncodes. The data were then recoded into primary and secondary \nthemes decided through discussion. We focused on the potential \napplications and limitations of ChatGPT in medical education \nand related suggestions (Supplement 3). \nResults \nSelection of sources of evidence \nAs shown in Fig. 1, we initially identified 1,066 records through \ndatabase searches, and after comprehensive screening, a total of \n113 articles were included. \nCharacteristics of the sources of evidence \nThe majority of articles (101/113, 89.4%) mentioned the po-\ntential applications or benefits of ChatGPT in medical education. \nFurthermore, 61.9% of the articles (70/113) mentioned the po-\ntential risks and limitations of ChatGPT in medical education. \nRegarding the types of articles, 37.2% (42/113) of records were \noriginal research articles.\nCritical appraisal within sources of evidence \nThe primary focus of this review was to provide a comprehen-\nsive overview of existing literature and to synthesize information \nand present a broader understanding of the topic, rather than con-\nducting an in-depth critical appraisal of individual sources. There-\nfore, a critical appraisal of sources of evidence was not done. \nResults of individual sources of evidence  \nThe relevant data from the included studies are summarized in \nSupplement 4.  \nSynthesis of results  \nPotential applications and benefits of ChatGPT in medical education \nEnabling novel learning approaches through ChatGPT \nA substantial amount of literature emphasized the enormous \nFig. 1. The flow diagram of searching and screening for articles on ChatGPT in medical education.\nRecords identified from:\n- Databases (n=3)\n- Registers (n=1,066)\nRecords screened (n=615)\nArticles sought for retrieval (n=195)\nFull-text articles assessed for eligibility \n(n=180)\nFull-text articles included in review \n(n=113)\nDuplicate records removed (n=451)\nRecords excluded\n- Title/abstracts not relevant (n=420)\nArticles not retrieved (n=15)\nFull-text articles excluded:\n- Did not focus on ChatGPT (n=2)\n-  Did not focus on medical education \n(n=64)\n- Not English (n=1)\nIdentificationScreeningIncluded\nIdentification of studies via databases and registers\n(page number not for citation purposes)\nJ Educ Eval Health Prof 2024;21:6 • https://doi.org/10.3352/jeehp.2024.21.6\nwww.jeehp.org 4\npotential of ChatGPT in assisting students in acquiring medical \nknowledge and problem-solving. Students can ask ChatGPT spe-\ncific medical questions and swiftly obtain accurate and personal-\nized answers to help them build their knowledge base [12]. \nChatGPT’s powerful capabilities of information collection and \nsummarization can improve the efficiency of students’ knowledge \nretrieval, simplify the learning process, save time, and allow better \nfocus on learning [13-15]. Additionally, ChatGPT is convenient \nto use and instant to access. It can support medical students’ learn-\ning through mobile applications [16]. \nMany articles also highlighted the significant potential of \nChatGPT in meeting the personalized needs of learners, providing \na personalized learning experience [17]. Developing personalized \nlearning plans and learning materials, as well as providing tailored \nfeedback to learners, are potential application avenues to explore \n[18]. Moreover, several articles discussed the use of ChatGPT as a \npotential writing or research assistant [19]. ChatGPT not only \nholds great potential in assisting with literature reviews and sum-\nmaries [20], but it can also help non-native English speakers im-\nprove their writing skills and provide comprehensive translations \nof foreign-language content [21] (Fig. 2, Supplement 3). \nImproving teaching quality through ChatGPT \nThe potential application of ChatGPT for improving teaching \nquality has been most frequently mentioned is creating realistic \nclinical simulation scenarios for medical students [22,23]. It not \nonly aids medical students in transitioning quickly from pre-clini-\ncal to clinical states [24], but also provides a safe and controlled \nenvironment for practicing clinical skills [17,22]. Simulated sce-\nnarios can be used as in-class tests as a time-efficient way of evalu-\nating students’ abilities [17,19] and addressing the shortage of \nstandardized patients [25]. Given ChatGPT’s interactive capabili-\nties, its enormous potential is foreseeable in assisting medical stu-\ndents in improving doctor-patient communication skills, helping \nto improve communication skills [26]. \nA significant number of articles emphasized the substantial val-\nue of ChatGPT for application as an auxiliary teaching tool \n[17,22,23,27]. ChatGPT can be used for innovating teaching \nmethods, such as flipped classrooms and problem-based learning \n[28], aiding in the development of curricula and teaching plans \n[23], establishing interactive teaching environments [27], and \neven serving as a virtual assistant to reduce teachers’ workload \n[29,30] (Fig. 2, Supplement 3). \nMedical exam performance and exam preparation with ChatGPT \nSeveral studies focused on ChatGPT’s performance in medical \nknowledge tests, including licensing examinations for physicians, \nanesthesia, ophthalmology, neurology, and other specialty exam-\ninations [31-34]. Overall, ChatGPT demonstrated passing scores \nin most countries’ licensing and specialty exams, but generally \nscored only slightly above the passing line, and did not achieve ac-\ncuracy rates above 95% in any licensing exam. Some studies inves-\ntigated ChatGPT’s performance on different types of questions, \nrevealing poorer performance in advanced judgment and multiple \nFig. 2. Summary of potential applications and advantages of ChatGPT based on the included records.\nThe potential applications and advantages of ChatGPT\nSimplify the learning process\nDevelop personalized learning plans and materials\nAssist in identifying issues during learning\nQuickly access medical knowledge and answer questions \nOvercome language barriers\nImprove learning efficiency and save time.\nAccess instantly and use portably\nAid in writing and research\nCultivate critical thinking and analytical skills \nCreate realistic clinical practice simulation scenarios \nHelp enhance doctor-patient communication skills\nAn excellent supplementary teaching tool \nEstablish an interactive teaching environment\nPractitioner exams\nProfessional exams\nCreate medical exam questions\nAssist students in self-directed learning\nNew learning methods \nEnhance teaching quality\nMedical exam performance and preparation\n2010 15 2550\n(page number not for citation purposes)\nJ Educ Eval Health Prof 2024;21:6 • https://doi.org/10.3352/jeehp.2024.21.6\nwww.jeehp.org 5\nlogical inference questions [35]. \nSome scholars believe that ChatGPT can be applied to self-di-\nrected learning and exam preparation, such as helping students re-\nview, facilitating group learning, and creating exam simulation \nquestions [31,32,36,37] (Fig. 2, Supplement 3).  \nPotential risks and limitations of ChatGPT in medical education  \nAcademic integrity and ethical issues \nNumerous scholars expressed concerns about potential threats \nto academic integrity posed by ChatGPT and its potential misuse \n[22,28,38]. Many potential advantages of ChatGPT can also be \npotential avenues for unethical behavior. For example, ChatGPT \nmay be used for cheating in exams to get higher scores [16]. Stu-\ndents might plagiarize content generated by ChatGPT in their pa-\npers, affecting their critical thinking abilities and academic integri-\nty [5]. Additionally, ChatGPT may pose potential threats to ethi-\ncal issues [22,39]. ChatGPT may trigger issues related to data pri-\nvacy, patient privacy, student and teacher privacy, intellectual \nproperty, and so forth [13,22,39], and some scholars even pro-\nposed the possibility of bioweapon creation and reinforcement of \nauthoritarian regimes [40]. Currently, there is a lack of specific \nregulations or guidelines to guide the use of ChatGPT [13] (Fig. \n3, Supplement 3). \nIssues of accuracy and reliability \nIssues related to ChatGPT’s accuracy and reliability were de-\ntailed in many articles, with 48 articles (42.5%) stating that \nChatGPT may generate incorrect information and facilitate the \nspread of misinformation, including but not limited to providing \nincorrect or controversial medical advice, inaccurately explaining \nmedical concepts, low accuracy rates, unspecified citations, lack of \nconsistency, and generating seemingly reasonable but incorrect \nanswers [5,28,39]. Several authors emphasized that ChatGPT’s \nknowledge base is limited by its training data and cannot provide \nthe latest information [28,41]. Furthermore, ChatGPT performs \npoorly on open-ended and multiple logical inference questions \n[42]. \nAdditionally, ChatGPT may fabricate information, and it is \nchallenging to identify when it generates fabricated information \n[43]. Moreover, ChatGPT may have potential algorithmic biases, \nleading to discriminatory behavior and stereotypes, potentially re-\nsulting in unfair treatment of certain groups and perpetuating ex-\nisting inequalities in the healthcare system [28,39] (Fig. 3, Sup-\nplement 3). \nPotential harms to learning \nSome literature pointed out the adverse effects on the learning \nprocess due to ChatGPT . Over-reliance on ChatGPT may hinder \nthe cultivation of critical thinking and clinical reasoning abilities \nFig. 3. Summary of the potential risks and limitations of ChatGPT based on the included records.\nInvolves enthical concerns\nLacks relevant regulations\nIssues of cheating\nAcademic plagiarism or fraud\nPerforms poorly on open-ended and reasoning questions\nInformation constrained by the trainning dataset\nFabrication of information\nBias\nIncorrect information\nLack of cultivation and guidance in practical experience\nAffects critical thinking\nOverreliance\nThe potential risks and limitations of ChatGPT\nAcademic integrity and ethical issues\nAccuracy and reliability\nPotential hazards to learning\n4020 3010 3515 2550\n(page number not for citation purposes)\nJ Educ Eval Health Prof 2024;21:6 • https://doi.org/10.3352/jeehp.2024.21.6\nwww.jeehp.org 6\nin medical students [44,45]. Moreover, an excessive emphasis on \nAI-based learning opportunities may reduce interpersonal inter-\naction and engagement, which are foundational for learning and \nhoning practical skills [46]. In addition, ChatGPT exhibits vary-\ning degrees of proficiency in different language environments, \nwith its best performance in handling English texts but still facing \nchallenges when dealing with non-English questions [41] (Fig. 3, \nSupplement 3). \nRecommendations for medical students and teachers \nRecommendations for medical students \nDue to the potential risks and limitations of ChatGPT , many \nscholars advise medical students to use ChatGPT cautiously and \nverify the accuracy and reliability of generated information, such \nas cross-referencing with textbooks [37]. Students should use \nChatGPT in an ethical and secure manner and disclose the use of \nAI-generated content in academic work (Fig. 4, Supplement 3). \nRecommendations for teachers \nMany articles emphasized that teachers should instruct students \non how to use ChatGPT , including informing them of the limita-\ntions and advantages of AI, guiding them on how to discern the \nfeasibility, authenticity, and accuracy of information provided by \nAI, and adhering to ethical and moral standards [47,48]. Before \nusing ChatGPT for teaching assistance or applications, teachers \nmust verify its safety, reliability, and repeatability and assess its im-\npact on the content and quality of teaching to prevent adverse ef-\nfects on the teaching process [39,48]. Moreover, considering the \nimpact of ChatGPT on traditional assignments and assessments, \nit is recommended that teachers establish diverse assessment \nmethods to evaluate students’ abilities, such as using presenta-\ntions, practical assessments, and face-to-face exams [39,48]. \nCurrently, the use of ChatGPT is mainly constrained by its ac-\ncuracy and reliability issues. Some scholars suggest augmenting \nChatGPT’s capabilities, such as addressing algorithmic biases, ex-\npanding the training dataset, improving its proficiency in different \nlanguage environments, and increasing the consistency of re -\nsponses [41,49] (Fig. 4, Supplement 3). \nDiscussion \nSummary of evidence \nChatGPT , as a novel AI technology, is in a prevailing trend of \npopularization and applications in medical education. However, \nthis trend has also brought numerous challenges. Understanding \nhow ChatGPT may contribute to medical education is crucial for \nconducting in-depth research and optimizing its role in this context. \nIn this review of the latest research on ChatGPT in medical edu-\ncation, we have outlined its advantages and limitations. However, \nthese factors are not independent but interact with each other, po-\ntentially amplifying or diminishing their impacts. For instance, \nChatGPT can assist in constructing realistic clinical simulation \nscenarios, enhancing teaching quality, and improving students’ \npractical skills. Nonetheless, if errors from ChatGPT are intro-\nduced during this process, it may lead to the failure of teaching ac-\ntivities and even jeopardize patients’ safety. Moreover, synergies \nexist among ChatGPT's advantages. For example, medical text-\nbooks, considered the gold standard for medical knowledge, have \nlimitations such as being outdated and potentially containing inac-\ncuracies [50]. Leveraging ChatGPT’s writing capabilities to syn-\nFig. 4. Summary of advice for medical students and teachers based on the included records.\nEstablish diverse assessment methods to evaluate students' abilities\nValidate ChatGPT performance before utilization\nEnhance ChatGPT performance\nGuide students in the proper use of ChatGPT\nStudents should verify the accuracy and reliability of generated information\n2010 1550\nAdvice\n(page number not for citation purposes)\nJ Educ Eval Health Prof 2024;21:6 • https://doi.org/10.3352/jeehp.2024.21.6\nwww.jeehp.org 7\nthesize the latest medical research into timely educational content \ncan help students stay up-to-date with the latest developments. \nLimitations \nThis article has certain limitations that should be considered \nwhen interpreting the current review results. Firstly, the literature \nsearch was restricted to articles published in English, potentially \nexcluding some relevant non-English literature, leading to selec-\ntion bias. Secondly, documents that were inaccessible were ex-\ncluded, which, although in small numbers, could result in missing \nrelevant data. Given that the search for this review concluded on \nNovember 30, 2023, and literature on the application of \nChatGPT in medical education is rapidly growing, further re -\nsearch and reviews are necessary. \nSuggestion \nFuture research should delve into the complex dynamic rela-\ntionships between the advantages and limitations of ChatGPT in \nmedical education. A more detailed examination of the interplay \nbetween these aspects will contribute to realizing the potential of \nChatGPT in medical education and proactively addressing associ-\nated risks. Based on this, we propose 3 future research directions: \nfirst, cultivating the ability of medical students to use ChatGPT \ncorrectly; second, integrating ChatGPT into teaching activities \nand processes; and third, proposing standards for the use of AI by \nmedical students. \nCultivating the ability of medical students to use ChatGPT \nappropriately \nAs the use of ChatGPT continues to become more widespread, \nthe most relevant challenge for medical students is the ability to \nuse AI, which involves understanding the strengths and limita-\ntions of AI, critically evaluating generated information, and using \nAI responsibly [5,19,22,48]. While many articles emphasize the \nimportance of guiding medical students in developing these skills, \nthere is currently a lack of dedicated courses specifically tailored \nto ChatGPT . \nDeveloping courses related to the use of ChatGPT for medical \nstudents is crucial. An essential aspect of these courses should be \nassisting medical students in dealing with potential inaccuracies \nand unreliability in ChatGPT-generated content. ChatGPT may \ngenerate erroneous and fabricated information, and its knowledge \nis limited to the training dataset [5,48,49]. Furthermore, the inac-\ncuracy of AI can be improved, but not completely eliminated. As \ninaccuracies are still present in medical textbooks, the gold stan-\ndard of medical knowledge [50], information generated by \nChatGPT based on existing knowledge cannot completely elimi-\nnate those errors [51]. Therefore, helping medical students cope \nwith potential inaccuracies and unreliability in ChatGPT-generat-\ned content should involve at least 2 aspects. Firstly, students should \nbe helped to develop the ability to assess the accuracy and quality \nof information from any source. Evaluating the accuracy and quali-\nty of information may be a new challenge, but fundamentally, it \nshould be similar to the previous assessment of the quality of med-\nical literature, involving assessments of author credibility, source \nevaluation, and external reviews. However, ChatGPT does not pro-\nvide citation sources, leading to a new challenge. Secondly, medical \nstudents should be instructed on how to draw correct conclusions \nin situations of data misinformation, absence, or inaccuracy. \nIntegrating ChatGPT into teaching activities and processes \nChatGPT has the potential to create realistic clinical simulation \nscenarios and build interactive teaching environments; therefore, \nit can be applied in various innovative teaching methods \n[22,39,52]. While this could revolutionize medical education, \ncareful consideration is necessary to determine whether these \nchanges are beneficial for clinical teaching rather than solely fo-\ncusing on efficiency or economic benefits. For example, using \nChatGPT in clinical simulation scenarios can help medical stu-\ndents transition rapidly from pre-clinical to clinical states, alleviat-\ning shortages of standardized patients. However, it must be ac-\nknowledged that the excessive use of ChatGPT in medical educa-\ntion may hinder the development of medical students’ critical \nthinking and clinical reasoning skills [17,28,38], potentially im-\npairing their practical abilities [38], which could pose a threat to \npatient safety. Therefore, any AI medical teaching program should \nundergo rigorous validation and assessment before widespread \nimplementation, with research conducted in controlled and re-\nal-world learning scenarios [31]. \nEstablishing guidelines for the use of AI \nNumerous articles express concerns about the potential risks of \nChatGPT regarding academic integrity and ethical issues, includ-\ning plagiarism, cheating on exams, privacy breaches, and damage \nto intellectual property [28,39,48]. Instances already exist where \nAI has been used to generate summaries and academic papers \n[53,54]. Therefore, there is an urgent need to establish guidelines \nfor the use of ChatGPT in medical education. These guidelines \nshould encompass accountability systems, ethical considerations, \nprivacy, and moral and integrity issues [55]. Scholars have pro-\nposed the incorporation of 4 major ethical principles into the inte-\ngration of AI into medical education: autonomy, fairness, \nnon-malfeasance, and beneficence. However, specific guidelines \nfor the use of AI still require further research. \n(page number not for citation purposes)\nJ Educ Eval Health Prof 2024;21:6 • https://doi.org/10.3352/jeehp.2024.21.6\nwww.jeehp.org 8\nConclusion \nThe transformative potential that ChatGPT brings to medical \neducation is undeniable, yet its complete integration into medical \neducation requires further exploration and in-depth consider -\nation. While existing literature theoretically speculates on the \nprospects of ChatGPT in medical education, there is still a lack of \nsufficient empirical research to guarantee its effectiveness and ra-\ntionality in medical education. Therefore, further research needs \nto be conducted on ways of cultivating medical students’ ability to \nuse ChatGPT correctly, integrating ChatGPT into teaching activ-\nities and processes, and establishing guidelines for the use of AI. \nT o unleash the maximum potential of ChatGPT in medical edu-\ncation, attention needs to be directed not only toward the capabil-\nities of AI but also toward its impact on students and educators \nthemselves. \nORCID \nXiaojun Xu: https://orcid.org/0000-0003-1388-2535; Yixiao \nChen: https://orcid.org/0009-0004-0944-337 4; Jing Miao: \nhttps://orcid.org/0000-0002-2825-0648\nAuthors’ contributions \nConceptualization: XJX. Methodology/formal analysis: XJX, \nJM, YXC. Visualization: JM,YXC. Project administration: XJX, \nJM, YXC. Writing–original draft: JM, YXC. Writing–review & ed-\niting: XJX, JM, YXC. \nConflict of interest \nNo potential conflict of interest relevant to this article was re-\nported. \nFunding \nNone. \nData availability \nNot applicable. \nAcknowledgments \nNone. \nSupplementary materials \nSupplementary files are available from Harvard Dataverse: \nhttps://doi.org/10.7910/DVN/OXK5VE\nSupplement 1. The internal review protocol.  \nSupplement. 2. Search queries terms in PubMed, Web of Science, \nand Embase for articles or preprints discussing on ChatGPT in \nthe context of medical education, written in English, and pub -\nlished between January 1, 2022 and November 30, 2023.  \nSupplement 3. Primary theme, sub-themes, representative quota-\ntions, and relevant papers from the 113 included articles.  \nSupplement 4. The list of 113 included papers.  \nSupplement 5. Audio recording of the abstract. \nReferences \n1. Ghassemi M, Birhane A, Bilal M, Kankaria S, Malone C, Mol-\nlick E, Tustumi F. ChatGPT one year on: who is using it, how \nand why? Nature 2023;624:39-41. https://doi.org/10.1038/\nd41586-023-03798-6\n2. Deng J, Lin Y. The benefits and challenges of ChatGPT: an \noverview. Front Comput Intell Syst 2022;2:81-83. https://doi.\norg/10.54097/fcis.v2i2.4465\n3. Kim TW. Application of artificial intelligence chatbots, includ-\ning ChatGPT , in education, scholarly work, programming, and \ncontent generation and its prospects: a narrative review. J Educ \nEval Health Prof 2023;20:38. https://doi.org/10.3352/jee-\nhp.2023.20.38 \n4. Hultgren C, Lindkvist A, Ozenci V , Curbo S. ChatGPT (GPT-\n3.5) as an assistant tool in microbial pathogenesis studies in \nSweden: a cross-sectional comparative study. J Educ Eval Health \nProf 2023;20:32. https://doi.org/10.3352/jeehp.2023.20.32 \n5. Alam F, Lim MA, Zulkipli IN. Integrating AI in medical educa-\ntion: embracing ethical usage and critical understanding. Front \nMed (Lausanne) 2023;10:1279707. https://doi.org/10.3389/\nfmed.2023.1279707 \n6. Ignjatovic A, Stevanovic L. Efficacy and limitations of ChatGPT \nas a biostatistical problem-solving tool in medical education in \nSerbia: a descriptive study. J Educ Eval Health Prof 2023;20:28. \nhttps://doi.org/10.3352/jeehp.2023.20.28 \n7. Huh S. Are ChatGPT’s knowledge and interpretation ability \ncomparable to those of medical students in Korea for taking a par-\nasitology examination?: a descriptive study. J Educ Eval Health \nProf 2023;20:1. https://doi.org/10.3352/jeehp.2023.20.1 \n8. Lee H, Park S. Information amount, accuracy, and relevance of \ngenerative artificial intelligence platforms’ answers regarding \nlearning objectives of medical arthropodology evaluated in En-\n(page number not for citation purposes)\nJ Educ Eval Health Prof 2024;21:6 • https://doi.org/10.3352/jeehp.2024.21.6\nwww.jeehp.org 9\nglish and Korean queries in December 2023: a descriptive study. \nJ Educ Eval Health Prof 2023;20:39. https://doi.org/10.3352/\njeehp.2023.20.39\n9. Dave T , Athaluri SA, Singh S. ChatGPT in medicine: an over-\nview of its applications, advantages, limitations, future pros-\npects, and ethical considerations. Front Artif Intell 2023;6: \n1169595. https://doi.org/10.3389/frai.2023.1169595 \n10. T orres-Zegarra BC, Rios-Garcia W, Nana-Cordova AM, Artea-\nga-Cisneros KF, Chalco XC, Ordonez MA, Rios CJ, Godoy \nCA, Quezada KL, Gutierrez-Arratia JD, Flores-Cohaila JA. Per-\nformance of ChatGPT , Bard, Claude, and Bing on the Peruvian \nNational Licensing Medical Examination: a cross-sectional \nstudy. J Educ Eval Health Prof 2023;20:30. https://doi.\norg/10.3352/jeehp.2023.20.30 \n11. T ricco AC, Lillie E, Zarin W, O’Brien KK, Colquhoun H, Levac \nD, Moher D, Peters MD, Horsley T , Weeks L, Hempel S, Akl \nEA, Chang C, McGowan J, Stewart L, Hartling L, Aldcroft A, \nWilson MG, Garritty C, Lewin S, Godfrey CM, Macdonald \nMT , Langlois EV , Soares-Weiser K, Moriarty J, Clifford T , Tun-\ncalp O, Straus SE. PRISMA Extension for Scoping Reviews \n(PRISMA-ScR): checklist and explanation. Ann Intern Med \n2018;169:467-473. https://doi.org/10.7326/M18-0850\n12. Gilson A, Safranek CW, Huang T , Socrates V , Chi L, T aylor RA, \nChartash D. How does ChatGPT perform on the United States \nMedical Licensing Examination (USMLE)?: the implications \nof large language models for medical education and knowledge \nassessment. JMIR Med Educ 2023;9:e45312. https://doi.\norg/10.2196/45312 \n13. Ho WL, Koussayer B, Sujka J. ChatGPT: friend or foe in medi-\ncal writing?: an example of how ChatGPT can be utilized in \nwriting case reports. Surg Pract Sci 2023;14:100185. https://\ndoi.org/10.1016/j.sipas.2023.100185 \n14. Dhanvijay AK, Pinjar MJ, Dhokane N, Sorte SR, Kumari A, \nMondal H. Performance of large language models (ChatGPT , \nBing Search, and Google Bard) in solving case vignettes in phys-\niology. Cureus 2023;15:e42972. https://doi.org/10.7759/cu-\nreus.42972 \n15. Valiente Fernandez M, Delgado Moya FP , Lesmes Gonzalez de \nAledo A, Martin Badia I, Orejon Garcia L. T eaching tools in \ncritical care: chatGPT . Med Intensiva (Engl Ed) 2023;47:480-\n481. https://doi.org/10.1016/j.medine.2023.04.006\n16. Vignesh R, P radeep P , Balakrishnan P . A tete-a-tete with \nChatGPT on the impact of artificial intelligence in medical edu-\ncation. Med J Malaysia 2023;78:547-549. \n17. Jeyaraman M, K SP , Jeyaraman N, Nallakumarasamy A, Yadav S, \nBondili SK. ChatGPT in medical education and research: a \nBoon or a Bane? Cureus 2023;15:e44316. https://doi.org/10. \n7759/cureus.44316 \n18. Corsello A, Santangelo A. May artificial intelligence influence \nfuture pediatric research?: the case of ChatGPT . Children (Ba-\nsel) 2023;10:757. https://doi.org/10.3390/children10040757 \n19. Wang X, Gong Z, Wang G, Jia J, Xu Y, Zhao J, Fan Q, Wu S, Hu \nW, Li X. ChatGPT performs on the Chinese National Medical \nLicensing Examination. J Med Syst 2023;47:86. https://doi.\norg/10.1007/s10916-023-01961-0\n20. Sallam M. ChatGPT utility in healthcare education, research, \nand practice: systematic review on the promising perspectives \nand valid concerns. Healthcare (Basel) 2023;11:887. https://\ndoi.org/10.3390/healthcare11060887\n21. Hosseini M, Gao CA, Liebovitz D, Carvalho A, Ahmad FS, Luo \nY, MacDonald N, Holmes K, Kho A. An exploratory survey \nabout using ChatGPT in education, healthcare, and research. \nmedRxiv [Preprint] 2023 Apr 3. https://doi.org/10.1101/20 \n23.03.31.23287979\n22. T sang R. Practical applications of ChatGPT in undergraduate \nmedical education. J Med Educ Curric Dev 2023;10:  \n23821205231178449. https://doi.org/10.1177/23821205231 \n178449 \n23. Arachchige ASPM. Early applications of ChatGPT in medical \npractice, education and research. Clin Med (Lond) 2023;23: \n429-430. https://doi.org/10.7861/clinmed.Let.23.4.2 \n24. Scherr R, Halaseh FF, Spina A, Andalib S, Rivera R. ChatGPT \ninteractive medical simulations for early clinical education: case \nstudy. JMIR Med Educ 2023;9:e49877. https://doi.org/10. \n2196/49877  \n25. Liu X, Wu C, Lai R, Lin H, Xu Y, Lin Y, Zhang W. ChatGPT: \nwhen the artificial intelligence meets standardized patients in \nclinical training. J T ransl Med 2023;21:447. https://doi.org/ \n10.1186/s12967-023-04314-0  \n26. Sallam M. The utility of ChatGPT as an example of large lan-\nguage models in healthcare education, research and practice: \nsystematic review on the future perspectives and potential lim-\nitations. MedRxiv [Preprint] 2023 Feb 21. https://doi.org/10. \n1101/2023.02.19.23286155\n27. Ilgaz HB, Celik Z. The significance of artificial intelligence plat-\nforms in anatomy education: an experience with ChatGPT and \nGoogle Bard. Cureus 2023;15:e45301. https://doi.org/10.77 \n59/cureus.45301\n28. Sahu PK, Benjamin LA, Singh Aswal G, Williams-Persad A. \nChatGPT in research and health professions education: chal-\nlenges, opportunities, and future directions. Postgrad Med J \n2023;100:50-55. https://doi.org/10.1093/postmj/qgad090 \n29. Calleja-Lopez JR, Rivera-Rosas CN, Ruibal-T avares E. Impact \nof ChatGPT and artificial intelligence in the contemporary \n(page number not for citation purposes)\nJ Educ Eval Health Prof 2024;21:6 • https://doi.org/10.3352/jeehp.2024.21.6\nwww.jeehp.org 10\nmedical landscape. Arch Med Res 2023;54:102835. https://doi.\norg/10.1016/j.arcmed.2023.05.003 \n30. Waikel RL, Othman AA, Patel T , Hanchard SL, Hu P , T eken-\ndo-Ngongang C, Duong D, Solomon BD. Generative Methods \nfor Pediatric Genetics Education. medRxiv [Preprint] 2023 \nAug 2. https://doi.org/10.1101/2023.08.01.23293506  \n31. Kung TH, Cheatham M, Medenilla A, Sillos C, De Leon L, Ele-\npano C, Madriaga M, Aggabao R, Diaz-Candido G, Maningo J, \nT seng V . Performance of ChatGPT on USMLE: potential for \nAI-assisted medical education using large language models. \nPLOS Digit Health 2023;2:e0000198. https://doi.org/10.13 \n71/journal.pdig.0000198 \n32. Ali R, T ang OY, Connolly ID, Fridley JS, Shin JH, Zadnik Sulli-\nvan PL, Cielo D, Oyelese AA, Doberstein CE, T elfeian AE, Go-\nkaslan ZL, Asaad WF. Performance of ChatGPT , GPT-4, and \nGoogle Bard on a neurosurgery oral boards preparation ques-\ntion bank. Neurosurgery 2023;93:1090-1098. https://doi.\norg/10.1227/neu.0000000000002551 \n33. Jiao C, Edupuganti NR, Patel PA, Bui T , Sheth V . Evaluating the \nartificial intelligence performance growth in ophthalmic knowl-\nedge. Cureus 2023;15:e45700. https://doi.org/10.7759/cu-\nreus.45700 \n34. Shay D, Kumar B, Bellamy D, Palepu A, Dershwitz M, Walz JM, \nSchaefer MS, Beam A. Assessment of ChatGPT success with \nspecialty medical knowledge using anaesthesiology board ex-\namination practice questions. Br J Anaesth 2023;131:e31-e34. \nhttps://doi.org/10.1016/j.bja.2023.04.017 \n35. Cuthbert R, Simpson AI. Artificial intelligence in orthopaedics: \ncan Chat Generative Pre-trained T ransformer (ChatGPT) pass \nSection 1 of the Fellowship of the Royal College of Surgeons \n(T rauma & Orthopaedics) examination? Postgrad Med J 2023; \n99:1110-1114. https://doi.org/10.1093/postmj/qgad053 \n36. Perera Molligoda Arachchige AS. Large language models \n(LLM) and ChatGPT: a medical student perspective. Eur J \nNucl Med Mol Imaging 2023;50:2248-2249. https://doi.\norg/10.1007/s00259-023-06227-y \n37. Ahn S. A use case of ChatGPT in a flipped medical terminology \ncourse. Korean J Med Educ 2023;35:303-307. https://doi.\norg/10.3946/kjme.2023.269 \n38. Preiksaitis C, Rose C. Opportunities, challenges, and future di-\nrections of generative artificial intelligence in medical educa-\ntion: scoping review. JMIR Med Educ 2023;9:e48785. https://\ndoi.org/10.2196/48785 \n39. Karabacak M, Ozkara BB, Margetis K, Wintermark M, Bisdas S. \nThe advent of generative language models in medical educa-\ntion. JMIR Med Educ 2023;9:e48163. https://doi.org/10.21 \n96/48163 \n40. Davies NP , Wilson R, Winder MS, Tunster SJ, McVicar K, \nThakrar S, Williams J, Reid A. ChatGPT sits the DFPH exam: \nlarge language model performance and potential to support \npublic health learning. BMC Med Educ 2024;24:57. https://\ndoi.org/10.1186/s12909-024-05042-9 \n41. Fang C, Wu Y, Fu W, Ling J, Wang Y, Liu X, Jiang Y, Wu Y, Chen \nY, Zhou J, Zhu Z, Yan Z, Yu P , Liu X. How does ChatGPT-4 \npreform on non-English national medical licensing examina-\ntion?: an evaluation in Chinese language. PLOS Digit Health \n2023;2:e0000397. https://doi.org/10.1371/journal.pdig.000 \n0397 \n42. Wang H, Wu W, Dou Z, He L, Yang L. Performance and explo-\nration of ChatGPT in medical examination, records and educa-\ntion in Chinese: pave the way for medical AI. Int J Med Inform \n2023;177:105173. https://doi.org/10.1016/j.ijmedinf.2023. \n105173 \n43. Currie GM. GPT-4 in nuclear medicine education: does it out-\nperform GPT-3.5? J Nucl Med T echnol 2023;51:314-317. \nhttps://doi.org/10.2967/jnmt.123.266485 \n44. Clusmann J, Kolbinger FR, Muti HS, Carrero ZI, Eckardt JN, \nLaleh NG, Loffler CM, Schwarzkopf SC, Unger M, Veldhuizen \nGP , Wagner SJ, Kather JN. The future landscape of large lan-\nguage models in medicine. Commun Med (Lond) 2023;3:141. \nhttps://doi.org/10.1038/s43856-023-00370-1 \n45. Liaw W, Chavez S, Pham C, T ehami S, Govender R. The haz-\nards of using ChatGPT: a call to action for medical education \nresearchers. PRiMER 2023;7:27. https://doi.org/10.22454/\nPRiMER.2023.295710 \n46. Feng S, Shen Y. ChatGPT and the future of medical education. \nAcad Med 2023;98:867-868. https://doi.org/10.1097/\nACM.0000000000005242 \n47. Lenihan D. Three effective, efficient, and easily implementable \nways to integrate A.I. into medical education. Cureus \n2023;15:e47204. https://doi.org/10.7759/cureus.47204 \n48. Abd-Alrazaq A, AlSaad R, Alhuwail D, Ahmed A, Healy PM, \nLatifi S, Aziz S, Damseh R, Alabed Alrazak S, Sheikh J. Large \nlanguage models in medical education: opportunities, challeng-\nes, and future directions. JMIR Med Educ 2023;9:e48291. \nhttps://doi.org/10.2196/48291 \n49. Webb JJ. Proof of concept: using ChatGPT to teach emergency \nphysicians how to break bad news. Cureus 2023;15:e38755. \nhttps://doi.org/10.7759/cureus.38755 \n50. T ez M, Yildiz B. How reliable are medical textbooks? J Grad \nMed Educ 2017;9:550. https://doi.org/10.4300/JGME-D-17- \n00209.1 \n51. Jager LR, Leek JT . An estimate of the science-wise false discov-\nery rate and application to the top medical literature. Biostatis-\n(page number not for citation purposes)\nJ Educ Eval Health Prof 2024;21:6 • https://doi.org/10.3352/jeehp.2024.21.6\nwww.jeehp.org 11\ntics 2014;15:1-12. https://doi.org/10.1093/biostatistics/kxt007 \n52. Park J. Medical students’ patterns of using ChatGPT as a feed-\nback tool and perceptions of ChatGPT in a Leadership and \nCommunication course in Korea: a cross-sectional study. J \nEduc Eval Health Prof 2023;20:29. https://doi.org/10.3352/\njeehp.2023.20.29 \n53. Gao CA, Howard FM, Markov NS, Dyer EC, Ramesh S, Luo Y, \nPearson AT . Comparing scientific abstracts generated by \nChatGPT to real abstracts with detectors and blinded human \nreviewers. NPJ Digit Med 2023;6:75. https://doi.org/10.1038/\ns41746-023-00819-6 \n54. Stokel-Walker C. ChatGPT listed as author on research papers: \nmany scientists disapprove. Nature 2023;613:620-621. https://\ndoi.org/10.1038/d41586-023-00107-z \n55. Busch F, Adams LC, Bressem KK. Biomedical ethical aspects \ntowards the implementation of artificial intelligence in medical \neducation. Med Sci Educ 2023;33:1007-1012. https://doi.\norg/10.1007/s40670-023-01815-x  "
}