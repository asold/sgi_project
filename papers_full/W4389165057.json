{
  "title": "Augmenting interpretable models with large language models during training",
  "url": "https://openalex.org/W4389165057",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2099907328",
      "name": "Chandan Singh",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2802059649",
      "name": "Armin Askari",
      "affiliations": [
        "University of California, Berkeley"
      ]
    },
    {
      "id": "https://openalex.org/A2106722673",
      "name": "Rich Caruana",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2104437897",
      "name": "Jian-Feng Gao",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2099907328",
      "name": "Chandan Singh",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2802059649",
      "name": "Armin Askari",
      "affiliations": [
        "University of California, Berkeley"
      ]
    },
    {
      "id": "https://openalex.org/A2106722673",
      "name": "Rich Caruana",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2104437897",
      "name": "Jian-Feng Gao",
      "affiliations": [
        "Microsoft (United States)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6778883912",
    "https://openalex.org/W6702248584",
    "https://openalex.org/W2502949459",
    "https://openalex.org/W4290667583",
    "https://openalex.org/W1961953963",
    "https://openalex.org/W2100960835",
    "https://openalex.org/W4386756982",
    "https://openalex.org/W1810499140",
    "https://openalex.org/W4381889417",
    "https://openalex.org/W3137125108",
    "https://openalex.org/W3099836851",
    "https://openalex.org/W6602334313",
    "https://openalex.org/W6754669440",
    "https://openalex.org/W2891575196",
    "https://openalex.org/W1546425147",
    "https://openalex.org/W2163455955",
    "https://openalex.org/W2251939518",
    "https://openalex.org/W4297023538",
    "https://openalex.org/W3090556797",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W4236137412",
    "https://openalex.org/W2911964244",
    "https://openalex.org/W4285178342",
    "https://openalex.org/W2282821441",
    "https://openalex.org/W6834628200",
    "https://openalex.org/W2344975321",
    "https://openalex.org/W3210923133",
    "https://openalex.org/W4308341600",
    "https://openalex.org/W4212828284",
    "https://openalex.org/W1996796871",
    "https://openalex.org/W2035983506",
    "https://openalex.org/W2887280559",
    "https://openalex.org/W6912439787",
    "https://openalex.org/W6675354045",
    "https://openalex.org/W3022120663",
    "https://openalex.org/W2963626623",
    "https://openalex.org/W2962739339",
    "https://openalex.org/W2604736517",
    "https://openalex.org/W6604796190",
    "https://openalex.org/W1981276685",
    "https://openalex.org/W6600291810",
    "https://openalex.org/W2048231652",
    "https://openalex.org/W2744365997",
    "https://openalex.org/W3158829558",
    "https://openalex.org/W6676769703",
    "https://openalex.org/W2295598076",
    "https://openalex.org/W2126292488",
    "https://openalex.org/W1678356000",
    "https://openalex.org/W6631839975",
    "https://openalex.org/W2910705748",
    "https://openalex.org/W2091144449",
    "https://openalex.org/W3173436762",
    "https://openalex.org/W2332488709",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W2964204621",
    "https://openalex.org/W2951576127",
    "https://openalex.org/W3165015862",
    "https://openalex.org/W2792641098",
    "https://openalex.org/W2765813195",
    "https://openalex.org/W2811104224",
    "https://openalex.org/W6779243538",
    "https://openalex.org/W4386075969",
    "https://openalex.org/W4389520444",
    "https://openalex.org/W6885172986",
    "https://openalex.org/W3105604018",
    "https://openalex.org/W4385570594",
    "https://openalex.org/W2981852735",
    "https://openalex.org/W1552847225",
    "https://openalex.org/W2070246124",
    "https://openalex.org/W2143017621",
    "https://openalex.org/W2157355630",
    "https://openalex.org/W2999615587",
    "https://openalex.org/W2945976633",
    "https://openalex.org/W4296412277",
    "https://openalex.org/W4386096102"
  ],
  "abstract": null,
  "full_text": "Article https://doi.org/10.1038/s41467-023-43713-1\nAugmenting interpretable models with large\nlanguage models during training\nChandan Singh 1 , Armin Askari2,R i c hC a r u a n a1 &J i a n f e n gG a o1\nRecent large language models (LLMs), such as ChatGPT, have demonstrated\nremarkable prediction performance for a growing array of tasks. However,\ntheir proliferationinto high-stakes domains and compute-limited settings has\ncreated a burgeoning need for interpretability and efﬁciency. We address this\nneed by proposing Aug-imodels, a framework for leveraging the knowledge\nlearned by LLMs to build extremely efﬁcient and interpretable prediction\nmodels. Aug-imodels use LLMs duringﬁtting but not during inference,\nallowing complete transparency and often a speed/memory improvement of\ngreater than 1000x for inference compared to LLMs. We explore two instan-\ntiations of Aug-imodels in natural-language processing: Aug-Linear, which\naugments a linear model with decoupl e de m b e d d i n g sf r o ma nL L Ma n dA u g -\nTree, which augments a decision tree with LLM feature expansions. Across a\nvariety of text-classiﬁcation datasets, both outperform their non-augmented,\ninterpretable counterparts. Aug-Lin e a rc a ne v e no u t p e r f o r mm u c hl a r g e r\nmodels, e.g. a 6-billion parameter GPT-J model, despite having 10,000x fewer\nparameters and being fully transparent. We further explore Aug-imodels in a\nnatural-language fMRI study, where they generate interesting interpretations\nfrom scientiﬁc data.\nLarge language models (LLMs) have demonstrated remarkable pre-\ndictive performance across a growing range of diverse tasks1– 3.H o w -\never, their proliferation has led to two burgeoning problems. First, like\nmost deep neural nets, LLMs have become increasingly difﬁcult to\ninterpret, often leading to them being characterized as black boxes\nand debilitating their use in high-stakes applications such as science\n4,\nmedicine5, and policy-making6. Moreover, the use of black-box models\nsuch as LLMs has come under increasing scrutiny in settings where\nusers require explanations or where models struggle with issues such\nas fairness\n7 and regulatory pressure8. Second, black-box LLMs have\ngrown to massive sizes, incurring enormous energy costs9 and making\nthem costly and difﬁcult to deploy, particularly in low-compute set-\ntings (e.g., edge devices).\nAs an alternative to large black-box models, transparent models,\nsuch as linear models and decision trees10 can maintain complete\ninterpretability. Additionally, transparent models tend to be dramati-\ncally more computationally efﬁcient than LLMs. While transparent\nmodels can sometimes perform as well as black-box LLMs11– 14, in many\nsettings (such as natural language processing (NLP)), there is often a\nconsiderable gap between the performance of transparent models and\nblack-box LLMs.\nWe address this gap by proposing augmented-interpretable\nmodels (Aug-imodels), a framework to leverage the knowledge\nlearned by LLMs to build extremely interpretable and efﬁcient models.\nSpeciﬁcally, we deﬁne an Aug-imodel as a method that leverages an\nLLM toﬁt an interpretable model but does not use the LLM during\ninference. This allows complete transparency and often a substantial\nefﬁciency improvement (both in terms of speed and memory). Aug-\ni m o d e l sc a na d d r e s ss h o r t c o m i n g si ne x i s t i n gt r a n s p a r e n tm o d e l sb y\nusing the world knowledge present in modern LLMs, such as infor-\nmation about feature correlations.\nWe explore two instantiations of Aug-imodels: (i) Aug-Linear,\nwhich augments a linear model with decoupled embeddings from an\nLLM and (ii) Aug-Tree, which augments a decision tree with improved\nfeatures generated by calling an LLM (see Fig.1). At inference time,\nboth are completely transparent and efﬁcient: Aug-Linear requires\nReceived: 28 July 2023\nAccepted: 17 November 2023\nCheck for updates\n1Microsoft Research, Redmond, WA, USA.2University of California, Berkeley, Berkeley, CA, USA.e-mail: chansingh@microsoft.com\nNature Communications|         (2023) 14:7913 1\n1234567890():,;\n1234567890():,;\nonly summing coefﬁcients from a ﬁxed dictionary while Aug-Tree\nrequires checking for the presence of keyphrases in an input.\nThis allows for complete inspection of a model ’s decision-\nmaking process, unlike post hoc explanations, which are often\nunfaithful\n11,15,16.\nAcross a variety of natural-language-processing datasets, both\nproposed Aug-imodels outperform their non-augmented counter-\nparts. Aug-Linear can even outperform much larger models, (e.g., a\n6-billion parameter Generative pretrained transformer model, GPT-J\n17),\ndespite having 10,000x fewer parameters and no nonlinearities. We\nfurther explore Aug-imodels in a natural-language fMRI context, where\nwe ﬁnd that they can predict well and generate interesting inter-\npretations. In what follows, the section“Results” shows results for\npredictive performance and interpretation, the section“Discussion”\nincludes a discussion, and the section“Methods” formally introduces\nAug-imodels.\nResults\nExperimental setup for evaluating text-classiﬁcation\nperformance\nTable 1 shows the datasets we study: four widely used text-\nclassiﬁcation datasets spanning different domains (e.g., classifying\nthe emotion of tweets18, the sentiment ofﬁnancial news sentences19,o r\nthe sentiment of movie reviews20, 21), and one scientiﬁc text regression\ndataset (described in section“fMRI results: analyzing fMRI data with\nAug-imodels”)22. Across datasets, the number of unique ngrams grows\nquickly from unigrams to bigrams to trigrams. Moreover, many\nngrams appear very rarely, e.g., in the Financial Phrasebank (FPB)\ndataset, 91% of trigrams appear only once in the training dataset.\nWe compare Aug-Linear to four interpretable baseline models:\nBag of ngrams, TF-IDF (Term frequency-inverse document\nfrequency)\n23,G l o V E24 (we use the pre-trained Glove embeddings\ntrained on Common Crawl containing 840 billion tokens, 2.2 million\nvocab-size, cased, 300-dimensional vectors), and a model trained on\nBERT embeddings for each unigram in the input (which can be viewed\nas running Aug-Linear with only unigrams). We use BERT (bert-base-\nuncased)\n3 as the LLM for extracting embeddings, afterﬁnetuning on\neach dataset; see Supplementary Table 1 for details on all models and\ndownloadable checkpoints. In each case, a model isﬁtv i ac r o s s -\nvalidation on the training set (to tune the amount ofℓ2 regularization\nadded) and its accuracy is evaluated on the test set.\nWe compare Aug-Tree to two decision-tree baselines: CART10 and\nID325, and we use bigram features. In addition to individual trees, weﬁt\n“not good \nmovie”\nnot\ngood\nmovie\nnot good\ngood movie\n(i) Extract\nngrams (iii) Sum (iv) Linear\nmodel\nnegative \nprediction\n(ii) Fixed-size\nembeddings emb(not)\nemb(good)\nemb(good movie)\n… w\na Fit model with summed, isolated ngrams\nwT emb(not)\nAssign each unique \nngram a scalar coefficient\nnot :\nnot good :\nb Convert to additive model\ninteresting :\nwT emb(not good)\nwT emb(interesting)\n… …\n……\nAug-LinearAug-Tree\nnot good\nLLM\nLLM bad, poor, awful, nasty, dull, \nunpleasant, …, horrendous\nc Fit tree with augmented keyphrases\n(ii) Screen phrases by\nperformance\nbad, poor, dull\nnot good\nbad, poor, dull\ngreat actor\ntom hanks, dicaprio, …\n(i) Generate concise\nrelated phrases\ninteresting sci-fi\nfuturistic, prescient, …\nvery funny\nhilarious, ROFL, …\nscenic\nartistic, picturesque, …\nnot funny\nlackluster writing, bad jokes, …\nnice plot\nplot-twist, gripping story, …\nd Augment keyphrase with LLM\nFig. 1 | Aug-imodels use an LLM to augment an interpretable model during\nﬁtting but not inference (toy example for movie-review classiﬁcation). aAug-\nLinear ﬁts an augmented linear model by extractingﬁxed-size embeddings for\ndecoupled ngrams in a given sequence, summing them, and using them to train a\nsupervised linear model.b At test-time, Aug-Linear can be interpreted exactly as a\nlinear model. A linear coefﬁcient for each ngram in the input is obtained by taking\nthe dot product between the ngram’s embedding and the shared vectorw. c Aug-\nTree improves each split of a decision tree duringﬁtting byd augmenting each\nkeyphrase found by CART with similar keyphrases generated by an LLM.\nTable 1 | Overview of datasets studied here\nFPB Rotten\ntomatoes\nSST2 Emotion fMRI\nSamples (train) 2313 8530 67,349 16,000 9461\nSamples (val) 1140 1066 872 2000 291\nClasses 3 2 2 6 Regression\nUnigrams 7169 16,631 13,887 15,165 4980\nBigrams 28,481 93,921 72,501 106,201 27,247\nTrigrams 39,597 147,426 108,800 201,404 46,834\nTrigrams that\nappear only once\n91% 93% 13% 89% 71%\nThe number of ngrams grows quickly with the size of the ngram.\nArticle https://doi.org/10.1038/s41467-023-43713-1\nNature Communications|         (2023) 14:7913 2\nbagging ensembles, where each tree is created using a bootstrap\ns a m p l et h es a m es i z ea st h eo r i g i n a ld a t a s e t( a sd o n ei nR a n d o m\nForest\n26) and has depth 8. This hurts interpretability but can improve\npredictive performance and calibration. For simplicity, we run Aug-\nLinear only in a binary classiﬁcation setting; to do so, we take two\nopposite classes from each multi-class dataset (Negative/Positive for\nFPB and Sadness/Joy for Emotion).\nAug-Linear text-classiﬁcation performance\nFigure 2a shows the test accuracy of Aug-Linear as a function of the\nngram size used for computing features. Aug-Linear outperforms the\ninterpretable baselines, achieving a considerable increase in accuracy\nacross three of the four datasets. Notably, Aug-Linear accuracy\nincreases with ngram size, whereas the accuracy of baseline methods\ndecreases or plateaus. This is likely due to Aug-Linearﬁtting only a\nﬁxed-size parameter vector, helping to prevent overﬁtting.\nTable 2 shows the test accuracy results for various models when\nchoosing the size of ngrams via cross-validation. Compared with\ninterpretable baselines, Aug-Linear shows considerable gains on three\nof the datasets and only a minor gain on the tweet dataset (Emotion),\nlikely because this dataset requiresﬁtting less high-order interactions.\nCompared with the zero-shot performance of the much larger\nGPT models (6-billion parameter GPT-J\n17 and 175-billion parameter\nGPT-3, text-davinci-0021). Accuracy for GPT models is computed\nby averaging over human-written prompts taken from\nPromptSource\n27; see details in Supplementary section 1). Aug-Linear\noutperforms GPT-J. Aug-Linear lags slightly behind GPT-3 for binary\nclassiﬁcation problems (Rotten Tomatoesand SST2) but outperforms\nGPT-3 for multi-class classiﬁcation problems (FPB and Emotion). The\nbest black-box baseline (a BERTﬁnetuned model) outperforms Aug-\nLinear by 4%– 6% accuracy. This is potentially a reasonable tradeoff in\nsettings where interpretability, speed, or memory bottlenecks are\ncritical.\nAt inference time, it may be useful to use Aug-Linear on relatively\neasy samples (for interpretability/memory/speed/cost-saving) but\nrelegate difﬁcult samples to a black-box model. To study this setting,\nwe predict each sample with a 2-step procedure. First, we predict the\nsample with Aug-Linear. If its prediction conﬁdence is high (the pre-\ndicted probability for the top class is above some threshold), we return\nthe Aug-Linear prediction. Otherwise, we predict the sample using the\nblack-box model. If Aug-Linear is well-calibrated, it should perform\nwell in this setting, since it can relegate the samples where it performs\npoorly to the black-box model (here, we use Finetuned BERT as the\nblack-box model).\nFigure 2b shows the accuracy of the entire test set in this setting.\nWe vary the conﬁdence threshold that decides whether to predict\nusing Aug-Linear or Finetuned BERT; this results in a curve showing\naccuracy as a function of the percentage of samples predicted with\nAug-Linear. Since Aug-Linear predictions are well-calibrated (see Sup-\nplementary Fig. 1), rather than the accuracy linearly interpolating\nbetween Aug-Linear and BERT, a large percentage of samples can be\npredicted with Aug-Linear while incurring little to no drop in accuracy.\nFig. 2 | Text-classiﬁcation accuracy for Aug-Linear. aTest accuracy as a function\nof ngram size. As the ngram size (i.e., the number of tokens in the ngram) increases,\nthe gap between Aug-Linear and the baselines grows. Averaged over three random\ncross-validation splits; error bars are standard errors of the mean (many are within\nthe points).b Accuracy when predicting using a 2-step procedure: uses Aug-Linear\npredictions on samples for which Aug-Linear is conﬁdent and Finetuned BERT\npredictions on the remaining samples. A large percentage of samples can be\naccurately predicted with Aug-Linear without a signiﬁcant drop in performance.\nTable 2 | Test accuracy for different models\nFPB Rotten tomatoes SST2 Emotion AVG\nOurs Aug-Linear 92.8 ± 0.37 81.6 ± 0.05 86.9 ± 0.10 89.5 ± 0.03 87.7\nInterpretable baselines Bag of ngrams 85.0 ± 0.11 75.0 ± 0.09 82.8 ± 0.00 89.0 ± 0.09 83.0\nTF-IDF 84.9 ± 0.16 75.9 ± 0.06 83.4 ± 0.11 89.2 ± 0.04 83.4\nGloVe 80.5 ± 0.06 78.7 ± 0.03 80.1 ± 0.10 73.1 ± 0.09 78.1\nBERT unigram embeddings 86.4 ± 0.13 76.8 ± 0.19 81.7 ± 0.07 87.2 ± 0.06 83.0\nBlack-box baselines BERT ﬁnetuned 98.0 87.5 92.4 93.6 92.9\nGPT-3 39.6 ± 1.6 82.7 ± 3.3 90.5 ± 3.9 45.1 ± 4.1 64.5\nGPT-J 27.0 ± 1.9 58.9 ± 3.1 58.4 ± 2.8 19.3 ± 1.9 40.9\nAug-Linear yields improvements over interpretable baselines and is competitive with some black-box baselines. See results for more datasets in Supplementary Table 3. Errors show standard error of\nthe mean over 3 random data splits (or 3 different prompts for GPT models).\nArticle https://doi.org/10.1038/s41467-023-43713-1\nNature Communications|         (2023) 14:7913 3\nFor example, when using Aug-Linear on 50% of samples, the average\ndrop in test accuracy is only 0.0053.\nIn cases involving inference memory/speed, Aug-Linear can be\nconverted to a dictionary of coefﬁcients, whose size is the number of\nngrams that appeared in training (see Table1). For a trigram model,\nthis yields roughly a 1000x reduction in model size compared to\nthe ~110 million trainable parameters in BERT, with much room for\nfurther size reduction (e.g., simply removing coefﬁcients for trigrams\nthat appear only once yields another 10-fold size reduction). Inference\nis nearly instantaneous, as it requires looking up coefﬁcients in a dic-\ntionary and then a single sum (and does not require a GPU).\nSupplementary section 1.1 explores accuracy/efﬁciency tradeoffs.\nFor example, Aug-Linear performance degrades gracefully when the\nmodel is compressed by removing its smallest coefﬁcients. In fact, the\ntest accuracy of Aug-Linear models trained with 4-grams on theEmo-\ntion and Financial phrasebank datasets actually improves after\nremoving 50% of the original coefﬁcients (Supplementary Fig. 2A).\nAdditionally, one can vary the size of ngrams used at test-time without\nsevere performance drop, potentially enabling compressing the model\nby orders of magnitude (see Supplementary Figs. 2B and 3). For\nexample, whenﬁtting a model with 4-grams and testing with 3-grams,\nthe average performance drop is ~2%.\nSupplementary Table 2 shows how generalization accuracy\nchanges when the LLM used to extract embeddings for Aug-Linear is\nvaried (e.g., using GPT-2, RoBERTA, or LlaMa), or different layers/\nngram selection techniques are used. Supplementary Table 3 shows\nresults for more multi-class datasets and when varying tokenization\nschemes. Across the variations, embeddings fromﬁnetuned models\nand larger models tend to yield better results.\nAug-Tree text-classiﬁcation performance\nWe now investigate the predictive performance of Aug-Tree, measured\nby the test ROC AUC on the previous text-classiﬁcation datasets\naltered for binary classiﬁcation. Note that the performance of all tree-\nbased methods on the studied datasets is below the performance of\nthe GLM methods in the section“Aug-Linear text-classiﬁcation per-\nformance” (see Supplementary Table 7 for a direct comparison).\nNevertheless, Aug-Tree models maintain potential advantages, such as\nstoring far fewer parameters, clustering important features together,\nand better modeling long-range interactions.\nFigure3a shows the performance of Aug-Tree as a function of tree\ndepth compared to decision-tree baselines. Aug-Tree shows\nimprovements that are sometimes small (e.g., forFinancial phrase-\nbank) and sometimes relatively large (e.g., forEmotion). Figure 3b\nshows the performance of a bagging ensemble of trees with different\ntree methods used as the base estimator. Here, using Aug-Tree shows a\nreliable and signiﬁcant gain across all datasets compared to ensembles\nof baseline decision-tree methods. This suggests that LLM augmenta-\ntion may help to diversify or decorrelate individual trees in the\nensemble. Supplementary Table 6 shows variations of different\nhyperparameters for Aug-Tree, such as using embeddings or dataset-\nspeciﬁc prompts to expand keyphrases.\nInterpretation results: interpretingﬁtted models\nIn this section, we interpretﬁtted Aug-imodels. Weﬁrst inspect an Aug-\nLinear modelﬁtted using unigram and bigram features on theSST2\ndataset which achieves 84% test accuracy. Next, we analyze the key-\nphrase expansions made inﬁtted Aug-Tree bagging ensembles.\nA ﬁtted Aug-Linear model can be interpreted for a single predic-\ntion (i.e., getting a score for each ngram in a single input, as in Fig.1)o r\nfor an entire dataset (i.e., by inspecting itsﬁtted coefﬁcients). Figure4a\nvisualizes theﬁtted Aug-Linear coefﬁcients (i.e., the contribution to the\nprediction w\nTϕ(xi)) with the largest absolute values across the SST2\ndataset. To show a diversity of ngrams, we show everyﬁfth ngram. The\nﬁtted coefﬁcients are semantically reasonable and many contain\nstrong interactions (e.g.,not veryis assigned to be negative whereas\nwithout resorting is assigned to be positive). This form of model\nvisualization allows a user to audit the model with prior knowledge.\nNote that the coefﬁcient for an ngram, e.g.,not bad(positive) is not\nsimply the sum of its constituent ngrams:not (negative) and bad\n(negative), see Supplementary Fig 5. Moreover, these coefﬁcients are\nexact and therefore avoid summarizing interactions, making them\nconsiderably more faithful than post hoc methods, such as LIME\n28 and\nSHAP29 (see Supplementary section 1.2 for a comparison).\nFigure 4bc o m p a r e st h eﬁtted Aug-Linear coefﬁcients to human-\nlabeled sentiment phrase scores for unigrams/bigrams in SST (note:\nthese continuous scores are separate from the binary sentence labels\nused for training in the SST2 dataset). Both are centered, so that 0 is\nneutral sentiment and positive/negative values correspond to positive/\nnegative sentiment, respectively. There is a strong positive correlation\nbetween the coefﬁcients and the human-labeled scores (Spearman\nrank correlationρ = 0.63), which considerably improves over coefﬁ-\ncients from a bag-of-bigrams model trained on SST2 (ρ =0 . 3 9 ) .\nOne strength of Aug-Linear is its ability to infer linear coefﬁcients\nfor ngrams that were not seen during training. Whereas baseline\nmodels generally assign each unknown ngram the same coefﬁcient\n(e.g., 0), Aug-Linear can effectively assign these new ngrams accurate\ncoefﬁcients. As one example, Fig.4c shows that the Aug-Linear model\ntrained only on bigrams in Fig.4a, b can automatically infer coefﬁcients\nfor trigrams (which were notﬁt during training). The inferred coefﬁ-\ncients are semantically meaningful, even capturing three-way interac-\ntions, such asnot very amusing.T os h o wad i v e r s i t yo fn g r a m s ,w es h o w\nFig. 3 | Aug-Tree text-classiﬁcation performance.Test performance as a function ofa tree depth for individual trees andb number of estimators in a bagging ensemble.\nValues are averaged over 3 random dataset splits; error bars show the standard error of the mean (many are within the points).\nArticle https://doi.org/10.1038/s41467-023-43713-1\nNature Communications|         (2023) 14:7913 4\nevery 20th ngram. Figure4ds h o w st h ec o e fﬁcients compared to the\nhuman-labeled SST phrase sentiment for all trigrams in SST. Again,\nthere is a strong correlation, where the Aug-Linear coefﬁcients achieve\na rank correlationρ = 0.71, which even outperforms the bag-of-words\nmodel directly trained on trigrams (ρ =0 . 4 9 ) .\nA ﬁtted Aug-Tree model can be easily interpreted for a single\nprediction (i.e., by inspecting the ngrams that triggered relevant splits)\nor by visualizing the entire tree (e.g., Fig.1c). Here, we additionally\nanalyze how well each ngram found by CART matches the augmented\nngrams found by the LLM; the better this match is, the easier it is to\ninterpret a split.\nTable 3 shows examples of the ngrams that were most frequently\naugmented whenﬁtting a bagging ensemble of 40 Aug-Tree s to the\nfour text-classiﬁcation datasets in Table1. Added ngrams seem quali-\ntatively reasonable, e.g., the keyphrasegood expands toﬁne, highly,\nsolid,..., valuable. We evaluate how well the expansions match the\noriginal CART ngram via human evaluation scores. Human evaluators\nare given the original ngram and the added ngrams, then instructed\n“You are given a keyphrase along with related keyphrases. On a scale of\n1 (worst) to 5 (best), how well do the related keyphrases match the\nexample keyphrase?” Human evaluation scores are averaged over 3\nPh.D. students in machine learning not afﬁliated with the study and 15\nrandom ngrams from each dataset. Table3 shows that the average\nhuman score for splits in each dataset is consistently greater than 4.\nThis is substantially higher than the baseline score of 1.3 assigned by\nh u m a ne v a l u a t o r sw h e n1 5n g r a m sa n de x p a n s i o n sa r er a n d o m l y\npaired and evaluated. Supplementary Table 5 gives more details on\nngram expansions.\nfMRI Results: analyzing fMRI data with Aug-imodels\nWe now explore Aug-imodels in a real-world neuroscience context. A\ncentral challenge in neuroscience is understanding how and where\nsemantic concepts are represented in the brain. To meet this chal-\nlenge, one line of study predicts the response of different brain voxels\n(i.e., small regions in space) to natural-language stimuli. We analyze\ndata from a recent study in which the authors collect functional MRI\n(fMRI) responses as human subjects listen to hours of narrative\nstories\n22. The fMRI responses studied here contain 95,556 voxels from\nTable 3 | Examples of most frequently augmented ngrams for each dataset whenﬁtting an ensemble of 40 Aug-Tree\nDataset Human score Example CART ngram Added ngrams\nSST2 4.6 ± 0.1 good ﬁne, highly, solid, worthy, pleasing, satisfactory, outstanding, honorable, unwavering, valuable,...\nbest most remarkable, outstanding, superb, ﬂawless, splendid, superlative, exceptional,\nimpeccable,...\nRT 4.4 ± 0.1 dull dreary, uninteresting, lackluster, listless, lifeless, uninspired, wearisome, drab, joylessly,...\nbad unpleasant, dire, despicable, terrible, heinous, disgusting, vile, putrid, atrocious, nasty, poor,...\nEmotion 4.4 ± 0.2 miserable gloomy, disillusioned, pathetic, doomed, agonized, despairing, pointless, despondent,...\nsorry embarrassed, sorrowful, remorseful, excuse, unsatis ﬁed, guilt, regretful, forgive, apologies,...\nFPB 4.2 ± 0.2 increased widened, consolidated\nfell slipped, slumped, diminished, plunged, dropped, weakened, lost ground\nHuman scores measure the similarity between an ngram and its expansion. They range from 1 (worst match) to 5 (best match), and the baseline score when ngrams and expansions are randomly\npaired and evaluated is 1.3 ± 0.1. Error bars show the standard error of the mean.\nFPB Financial Phrasebank,RT rotten tomatoes.\nFig. 4 | Interpreting Aug-Linear.Top and bottom contributing ngrams to an Aug-\nLinear model trained on SST2 bigrams area qualitatively semantically accurate and\nb match human-labeled phrase sentiment scores. For the same Aug-Linear model,\nwhich is trained only on bigrams, inferred trigrams coefﬁcients arec qualitatively\nsemantically accurate andd match human-labeled phrase sentiment scores.\nArticle https://doi.org/10.1038/s41467-023-43713-1\nNature Communications|         (2023) 14:7913 5\na single subject, with 9461 time points used for training/cross-valida-\ntion and 291 time points used for testing. We predict the continuous\nresponse for each voxel at each time point using the 20 words that\nprecede the time point. We skip the most recent 4 words due to\naccount for a time delay in the fMRI BOLD response. Seminal work on\nt h i st a s kf o u n dt h a tl i n e a rm o d e l so fw o r dv e c t o r sc o u l de f f e c t i v e l y\npredict voxel responses\n30, and more recent work shows that LLMs can\nfurther improve predictive performance31, 32. Aug-Linear is well-suited\nto this task, as it combines low-level word information with the con-\ntextualized information present in higher-order ngrams, both of which\nhave been found to contribute to fMRI representations of text\n33.\nFigure 5a visualizes the voxels in the cortex which are better\npredicted by Aug-Linear than BERT. The improvements are often\nspatially localized within well-studied brain regions such as the audi-\ntory cortex (AC). Figure5b shows that the test performance for Aug-\nLinear (measured by the Pearson correlation coefﬁcient ρ)o u t p e r -\nforms the black-box BERT baseline. Supplementary section 3 gives\nfurther data details and comparisons, e.g., Aug-Linear also outper-\nforms other linear baselines.\nGoing beyond prediction performance, Fig.5ci n v e s t i g a t e sa\nsimple example of how Aug-Linear could help interpret an underlying\nbrain region. Weﬁrst select the voxel which is best predicted by Aug-\nLinear (achieving a test correlation of 0.76) and then visualize the\nlargest ﬁtted Aug-Linear coefﬁcients for that voxel. These correspond\nto which ngrams increase the activity of the fMRI voxel the most.\nInterestingly, these ngrams qualitatively correspond to under-\nstandable concepts:questioning, e.g.,“are you sure”, often combined\nwith disbelief/incredulity,e . g .“wow I never”. Figure 5d shows two\nexamples of voxels that are better predicted by Aug-Tree than Aug-\nLinear (Aug-Tree yields test correlations of 0.35 and 0.36). These two\nvoxels are both related to someone speaking, but they seem to depend\non interactions between the noun (me or you)a n dt h ev e r b(says). To\nelicit a large response both must be present, something which is dif-\nﬁcult to capture in additive models, even with ngrams, since these\nwords may not be close together in a sentence.\nThis interpretation approach could be applied more rigorously to\ngenerate hypotheses for text inputs that activate brain regions, and\nthen test them with follow-up fMRI experiments.\nDiscussion\nAug-imodels provide a promising direction towards future methods\nthat reap the beneﬁts of both LLMs and transparent models in NLP:\nhigh accuracy along with interpretability/efﬁciency. This potentially\nopens the door for introducing LLM-augmented models in high-stakes\ndomains, such as medical decision-making and in new applications on\ncompute-limited hardware. Aug-imodels are currently limited to\napplications for which an effective LLM is available, and thus may not\nwork well for very esoteric NLP tasks. However, as LLMs improve, the\npredictive performance of Aug-imodels should continue to improve\nand expand to more diverse NLP tasks. More generally, Aug-imodels\ncan be applied to domains outside of NLP where effective foundation\nmodels are available (e.g., computer vision or protein engineering).\nThough helpful, Aug-imodels are limited by their transparent\nmodel form and cannot capture some complex interactions that LLMs\ncan model. To remedy this, Aug-imodels could be readily extended\nbeyond linear models and trees to improve transparent models such as\nrule lists, prototype-based models, symbolic models, and rule sets with\nLLM augmentation during training time. In all these cases, LLM aug-\nmentation could use LLM embeddings (as is done in Aug-Linear), use\nLLM generations (as is done in Aug-Tree), or use LLMs in new ways.\nAug-Linear could be extended to nonlinearly transform the embed-\nding for each ngram with a model before summing to obtain theﬁnal\nprediction, similar to the nonlinearity present in generalized additive\nmodels (GAMs) such as the explainable boosting machine\n34,. Addi-\ntionally, Aug-Linear couldﬁt long-range interaction terms as opposed\nto only ngrams. Aug-Tree could leverage domain knowledge to engi-\nneer more meaningful prompts for expanding ngrams or for extract-\ning relevant ngrams. Both models can be further studied to improve\ntheir compression (potentially with LLM-guided compression techni-\nques) or to extend their capabilities to tasks beyond classiﬁcation/\nFig. 5 | Aug-imodels prediction performance and interpretation for fMRI vox-\nels. aMap of the difference between the performance of Aug-Linear and BERT for\nfMRI voxel prediction across the cortex. Positive values (red) show where Aug-\nLinear outperforms BERT, measured by correlation on the test set.b Aug-Linear\noutperforms BERT when averaging across all voxels, or just over the 1%/5% with the\nhighest test correlations. Standard errors of the mean are all less than 0.0015.\nc Example Aug-Linear model for a single voxel, visualized with the top Aug-Linear\ncoefﬁcients. d Example Aug-Tree model for two voxels.\nArticle https://doi.org/10.1038/s41467-023-43713-1\nNature Communications|         (2023) 14:7913 6\nregression, such as sequence prediction or outlier detection. We hope\nthat the introduction of Aug-imodels can help push improved per-\nformance prediction into high-stakes applications, improve inter-\npretability for scientiﬁc data, and reduce unnecessary energy/\ncompute usage.\nMethods\nIn this section, the section“Limitations of existing transparent meth-\nods” overviews the limitations of existing transparent methods, sec-\ntion “Aug-Linear method description” introduces Aug-Linear, and the\nsection “Aug-Tree method description” introduces Aug-Tree.\nLimitations of existing transparent methods\nWe are given a dataset ofn natural-language stringsXtext and corre-\nsponding labelsy 2 Rn. In transparent modeling, often each stringx is\nrepresented by a bag-of-words, in which each featurexi is a binary\nindicator (or count) of the presence of a single token (e.g., the word\ngood). To model interactions between tokens, one can instead use a\nbag-of-ngrams representation, whereby each feature is formed by\nconcatenating multiple tokens (e.g., the phrasenot good). Using a bag-\nof-ngrams representation mapsX\ntext to a feature matrixX 2 Rn × p,\nwhere p is the number of unique ngrams inXtext. While this repre-\nsentation enables interpretability, the number of ngrams in a dataset\ngrows exponentially with the size of the ngram (how many tokens it\ncontains) and the vocab-size; even for a modest vocab-size of 10,000\ntokens, the number of possible trigrams is already 10\n12. This makes it\ndifﬁcult for existing transparent methods to model all trigrams with-\nout overﬁtting. Moreover, existing transparent methods completely\nfail to learn about ngrams not seen in the training set.\nPreliminaries: linear models. We build on generalized linear models,\nor GLMs35, which take the form:\ngðE½y/C138Þ = β0 +\nXp\ni =1\nβi /C1 xi ð1Þ\nwhere ðx1,x2, ... ,xpÞ are the input features (i.e., ngrams),y is the target\nvariable,g(⋅) is the link function (e.g., logistic function) and eachβi is a\nscalar coefﬁcient. Due to the function’s additivity, the contribution of\neach feature can be interpreted independently.\nPreliminaries: decision trees.C A R T10 ﬁts a binary decision tree via\nrecursive partitioning. When growing a tree, CART chooses for each\nnode t the split s that maximizes the impurity decrease in the\nresponses y.F o rag i v e nn o d et, the impurity decrease has the\nexpression\n^Δðs, t, yÞ :=\nX\nxi2t\nhy i, /C22yt\n/C0/C1\n/C0\nX\nxi2tL\nh\n/C0\nyi, /C22ytL\n/C1\n/C0\nX\nxi2tR\nh\n/C0\nyi, /C22ytR\n/C1\n, ð2Þ\nwhere tL and tR denote the left and right child nodes oft respectively,\nand /C22yt ,/C22ytL\n,/C22ytR\ndenote the mean responses in each of the nodes. For\nclassiﬁcation, h( ⋅ , ⋅ ) corresponds to the Gini impurity, and for\nregression,h( ⋅ , ⋅ ) is the mean-squared error. Each splits is a partition\nof the data based on a feature inX. To grow the tree, the splitting\nprocess is repeated recursively for each child node until a stopping\ncriteria (e.g., a max depth) is satisﬁed. At inference time, we predict the\nresponse of an example by following its path from the root to a leaf and\nthen predicting with the mean value found in that leaf.\nAug-Linear method description\nTo remedy the issues with the GLM model in Eq. (1), we propose Aug-\nLinear, an intuitive model which leverages a pre-trained LLM to extract\na feature representationϕ(xi)f o re a c hi n p u tn g r a mxi. This allows\nlearning only a single linear weight vectorw with aﬁxed dimension\n(which depends on the embedding dimension produced by the LLM),\nregardless of the number of ngrams. As a result, Aug-Linear can learn\nefﬁciently as the number of input features grows, and can also infer\ncoefﬁcients for unseen features. The ﬁtted model is still a GLM,\nensuring that the model can be precisely interpreted as a linear func-\ntion of its inputs:\ngðE½y/C138Þ = β + w\nT X\ni\nϕðxiÞ ð3Þ\nFitting Aug-Linear resembles learning a linear layer on top of word\nembeddings24,36,37, but instead uses LLM ngram embeddings to better\ncompare the semantics/interactions present within an ngram. Aug-\nLinear is also similar to the approach ofﬁnetuning a single linear layer\non top of LLM embeddings\n38, but instead separately extracts/embeds\neach ngram to keep the contributions to the prediction strictly\nadditive across ngrams (see Fig.1a):\n(i) Extracting ngrams: To ensure input ngrams are interpretable,\nngrams are constructed using a word-level tokenizer (here,\nspaCy\n39) .W es e l e c tt h es i z eo fn g r a m st ob eu s e dv i ac r o s s -\nvalidation.\n(ii) Extracting embeddings: Each ngram is separately fed through the\nLLM to retrieve aﬁxed-size embedding. When feeding each ngram\nthrough, we apply the standard preprocessing and tokenizer used\nby the LLM. For example, when the LLM is BERT\n3,w ep r e p e n d\n[CLS] to the ngram, append[SEP] to it, and use BERT’sw o r d -\npiece tokenizer to process the resulting string into tokens (note\nthat this splits an ngram into many tokens). We then average over\nthe dimension corresponding to the number of tokens to yield a\nﬁxed-size embedding (a common alternative for bi-directional\n(masked) language models is to use the embedding for a special\ntoken, i.e.,[CLS], but we aim to keep the approach here more\ngeneral).\n(iii) Summing embeddings: The embeddings of each ngram in the\ninput are summed to yield a singleﬁxed-size vector, ensuring\nadditivity of theﬁnal model.\n(iv) Fitting theﬁnal linear model to make predictions: A linear model is\nﬁt on the summed embedding vector. We choose the link function\ng to be the logit function (or the softmax for multi-class) for\nclassiﬁcation and the identity function for regression. In both\ncases, we addℓ\n2 regularization over the parametersw in Eq. (3)\nand minimize the loss (cross-entropy for classiﬁcation, mean-\nsquared error for regression) using Limited memory BFGS\n(optimization is performed using scikit-learn\n40).\nComputational considerations.D u r i n gﬁtting, Aug-Linear is inex-\npensive toﬁt as (1) the pre-trained LLM is not modiﬁed in any way, and\ncan be any existing off-the-shelf model and (2) Aug-Linear only\nrequiresﬁtting aﬁxed-size linear model. After training, the model can\nbe converted to a dictionary of scalar coefﬁcients for each ngram,\nwhere the coefﬁcient is the dot product between the ngram ’s\nembedding and theﬁtted weight vectorw (Fig. 1b). This makes infer-\nence extremely fast and converts the model to have size equal to the\nnumber ofﬁtted ngrams. When new ngrams are encountered at test-\ntime, the coefﬁcients for these ngrams can optionally be inferred by\nagain taking the dot product between the ngram’s embedding and the\nﬁtted weight vectorw.\nAug-Tree method description\nAug-Tree improves upon a CART decision tree by augmenting features\nwith generations from an LLM. This helps capture correlations\nbetween ngrams, including correlations with ngrams that are not\npresent in the training data. Aug-Tree does not modify the objective in\nEq. (2) but rather modiﬁes the procedure forﬁtting each individual\nsplit s (Fig. 1d). While CART restricts each split to a single ngram, Aug-\nArticle https://doi.org/10.1038/s41467-023-43713-1\nNature Communications|         (2023) 14:7913 7\nTree lets each split ﬁt a disjunction of ngrams (e.g., ngram1∨\nngram2∨ngram3). The disjunction allows a split to capture sparse\ninteractions, such as synonyms in natural language. This can help\nmitigate overﬁtting by allowing individual splits to capture concrete\nconcepts, rather than requiring many interacting splits.\nWhen ﬁtting each split, Aug-Tree starts with the ngram which\nmaximizes the objective in Eq. (2), just as CART would do, e.g.,not\ngood. Then, we query an LLM to generate similar ngrams to include in\nthe split, e.g.,bad, poor, awful,..., horrendous.S p e c iﬁcally, we query\nGPT-3 (text-davinci-003)\n1 with the promptGenerate 100 concise\nphrases that are very similar to the keyphrase:\\nKeyphrase: “{key-\nphrase}”\\n1. and parse the outputs into a list of ngrams. We greedily\nscreen each ngram by evaluating the impurity of the split when\nincluding the ngram in the disjunction; we then exclude any ngram\nthat increases the split’s impurity, resulting in a shortened list of\nngrams, e.g.,bad, poor, dull.\nComputational considerations. As opposed to Aug-Linear, Aug-Tree\nuses an LLM API rather than LLM embeddings, which may be more\ndesirable depending on access to compute. The number of LLM calls\nrequired is proportional to the number of nodes in the tree. During\ninference, the LLM is no longer needed, and making a prediction\nsimply requires checking an input for the presence of speciﬁc ngrams\nalong one path in the tree. Storing an Aug-Linear model requires\nmemory proportional to the number of raw strings associated with\ntree splits, usually substantially reducing memory over the already\nsmall Aug-Linear model. We explore variations of Aug-Tree (such as\nusing LLM embeddings rather than an API) in Supplementary section 2.\nBackground and related work\nImproving linear models with neural networks. There is a large lit-\nerature on additive models being used for interpretable modeling. This\nincludes GAMs\n41, which have achieved strong performance in various\ndomains by modeling individual component functions/interactions\nusing regularized boosted decision trees\n34 and more recently using\nneural networks42. However, existing GAM methods are limited in their\nability to model the high-order feature interactions that arise in NLP.\nMeanwhile, NLP has seen great success in models which build strong\nword-level representations, e.g., word2vec36,37,G l o V e24, FastText43,a n d\nELMo44. By replacing such models with LLM embeddings, Aug-Linear\nenables easily modeling ngrams of different lengths without training a\nnew model. Moreover, unlike earlier methods, LLMs can incorporate\ninformation about labels into the embeddings (e.g., byﬁrst ﬁnetuning\nan LLM on a downstream prediction task).\nDecision trees. There is a long history of greedy methods forﬁtting\ndecision trees, e.g., CART\n10 or ID325. More recent work has explored\nﬁtting trees via global optimization rather than greedy algorithms45– 47;\nthis can improve performance given aﬁx e dt r e es i z eb u ti n c u r sah i g h\ncomputational cost. Other recent studies have improved trees after\nﬁtting through regularization\n48 or iterative updates49. Some recent\nworks have studied using trees as a way to guide large language\nmodels\n50,51. Beyond trees, there are many popular classes of rule-based\nmodels, such as rule sets52, rule lists53,54,a n dt r e es u m s14. Aug-Tree\naddresses a common problem shared by rule-based approaches:\nmodeling the sparse, correlated features that are common in tasks\nsuch as text classiﬁcation.\nBeyond ﬁtting a single tree, tree ensembles such as Random\nForest\n26, gradient-boosted trees55, XGBoost56,a n dB A R T57,h a v ea l l\nshown strong predictive performance in diverse settings. These\nensembling approaches are compatible with Aug-Tree, as they can be\nused as the base estimator in any of these approaches.\nInterpreting features and feature interactions. Related to this work is\npost hoc methods that aim to help understand a black-box model, i.e.,\nby providing feature importances using methods such as LIME28,\nSHAP58, and others59,60. Slightly more related are works that aim to\nexplain feature interactions or transformations in neural networks61– 63\nHowever, all these methods lose some information by summarizing\nthe model and suffer from issues with summarizing interactions64,65.\nAlternative forms of explanation exist speciﬁcally for NLP, such as\nextractive rationales66,67, natural-language explanations for individual\npredictions68,69, and more recently LLM-generated explanations (e.g., a\nchain of thought70). All these methods fail to explain the modelas a\nwhole and are again less reliable than having a fully transparent model\n(e.g., explanations are often unfaithful15,16).\nInterpreting/distilling neural networks. Alternatively, one can\ninvestigate whether an LLM’s learned representations via probing71,72\nor by directly analyzing a model’s internal weights and activations73– 75.\nThe work here is related to studies that aim to make neural networks\nmore interpretable. For example, models can make predictions by\ncomparing inputs to prototypes\n76,77, by predicting intermediate inter-\npretable concepts 78– 80, using LLMs to extract prompt-based\nfeatures81,82, distilling a neural network into a mostly transparent\nmodel83,84 or distilling into a fully transparent model (e.g., adaptive\nwavelets12 or an additive model85). Separately, many works use neural\nnetwork distillation to build more efﬁcient (but still black-box) neural\nnetwork models, e.g., refs.86,87.\nReporting summary\nFurther information on research design is available in the Nature\nPortfolio Reporting Summary linked to this article.\nData availability\nAll data is available open-source and instructions for downloading the\ndata are available at github.com/microsoft/augmented-interpretable-\nmodels. Text-classiﬁcation datasets can be downloaded from hug-\ngingface using the huggingface idsdair-ai/emotion, rotten_tomatoes,\nsst2,a n dﬁnancial_phrasebank. fMRI data are accessible fromhttps://\ngithub.com/HuthLab/deep-fMRI-dataset. PromptSource prompts\nused as a baseline can be found athttps://github.com/bigscience-\nworkshop/promptsource.\nCode availability\nCode for running all experiments (as well as applying Aug-imodels in\nnew settings) is available at github.com/microsoft/augmented-inter-\npretable-models and on Zenodo at https://zenodo.org/records/\n10118975. Code uses python 3.8 and huggingface datasets 2.12.0,\nhuggingface transformers 4.29.0\n88– 100, sklearn 1.2.040, and OpenAI API\ntext-davinci-003.\nReferences\n1. Brown, T. et al. Language models are few-shot learners.Adv.\nNeural Inf. Process. Syst.33,1 8 7 7–1901 (2020).\n2. Bubeck, S. et al. Sparks of artiﬁcial general intelligence:\nearly experiments with GPT-4.https://arxiv.org/abs/2303.\n12712 (2023).\n3. Devlin, J., Chang, M.-W., Lee, K., &Toutanova, K. Bert: Pre-training\nof deep bidirectional transformers for language understanding.\nhttps://arxiv.org/abs/1810.04805(2018).\n4. Angermueller, C., Pärnamaa, T., Parts, L. & Stegle, O. Deep\nlearning for computational biology.Mol. Syst. Biol.12, 878 (2016).\n5. Kornblith, A. E. et al. Predictability and stability testing to assess\nclinical decision instrument performance for children after blunt\ntorso trauma.PLOS Digit. Healthhttps://doi.org/10.1371/journal.\npdig.0000076(2022).\n6. Brennan, T. & Oliver, W. L. The emergence of machine learning\ntechniques in criminology.Criminol. Public Policy12,\n551–562 (2013).\nArticle https://doi.org/10.1038/s41467-023-43713-1\nNature Communications|         (2023) 14:7913 8\n7 . D w o r k ,C . ,H a r d t ,M . ,P i t a s s i ,T . ,R e i n g o l d ,O . ,&Z e m e l ,R .F a i r n e s s\nthrough awareness. In:Proceedings of the 3rd Innovations in\nTheoretical Computer Science Conference.2 1 4–226 (ACM, 2012).\n8. Goodman, B. & Flaxman, S. European union regulations on algo-\nrithmic decision-making and a“right to explanation”. https://arxiv.\norg/abs/1606.08813(2016).\n9. Bommasani, R., Soylu, D., Liao, T. I., Creel, K. A., & Liang, P. Eco-\nsystem graphs: the social footprint of foundation models.https://\narxiv.org/abs/2303.15772(2023).\n1 0 . B r e i m a n ,L . ,F r i e d m a n ,J .H . ,O l s h e n ,R .A . ,&S t o n e ,C .J .Classiﬁ-\ncation and Regression Trees. Wadsworth and Brooks, Monterey,\nCA. https://www.routledge.com/Classiﬁcation-and-Regression-\nTrees/Breiman-Friedman-Stone-Olshen/p/book/\n9780412048418(1984).\n11. Rudin, C. et al. Interpretable machine learning: Fundamental\nprinciples and 10 grand challenges.https://arxiv.org/abs/2103.\n11251 (2021).\n12. Ha, W., Singh, C., Lanusse, F., Upadhyayula, S., & Yu, B. Adaptive\nwavelet distillation from neural networks through interpretations.\nAdv. Neural Inf. Process. Syst. 34 https://arxiv.org/abs/2107.\n09145 (2021).\n13. Mignan, A. & Broccardo, M. One neuron versus deep learning in\naftershock prediction.Nature 574,1 –3( 2 0 1 9 ) .\n1 4 . T a n ,Y .S . ,S i n g h ,C . ,N a s s e r i ,K . ,A g a r w a l ,A . ,&Y u ,B .F a s ti n t e r -\npretable greedy-tree sums (ﬁgs). https://arxiv.org/abs/2201.\n11931 (2022).\n15. Adebayo, J. et al. Sanity checks for saliency maps.Adv. Neural Inf.\nProcess. Syst.9505–9515 https://arxiv.org/abs/1810.\n03292 (2018).\n1 6 . T u r p i n ,M . ,M i c h a e l ,J . ,P e r e z ,E . ,&B o w m a n ,S .R .L a n g u a g e\nmodels don’t always say what they think:Unfaithful explanations\nin chain-of-thought prompting.https://arxiv.org/abs/2305.\n04388 (2023).\n17. Wang, B. & Komatsuzaki, A. GPT-J-6B: a 6 billion parameter auto-\nregressive language model.https://github.com/kingoﬂolz/mesh-\ntransformer-jax(2021).\n18. Saravia, E., Liu, H.-C.T., Huang, Y.-H., Wu, J. & Chen, Y.-S. Carer:\nContextualized affect representations for emotion recognition. In:\nProceedings of the 2018 Conference on Empirical Methods in\nNatural Language Processing.3 6 8 7–3697 (2018).\n19. Malo, P., Sinha, A., Korhonen,P., Wallenius, J. & Takala, P. Good\ndebt or bad debt: detecting semantic orientations in economic\ntexts. J. Assoc. Inf. Sci. Technol. 65 https://arxiv.org/abs/1307.\n5336 (2014).\n20. Pang, B. & Lee, L. Seeing stars: exploiting class relationships\nfor sentiment categorization with respect to rating scales. In:\nProceedings of the ACL. https://arxiv.org/abs/cs/0506075\n(2005).\n21. Socher, R. et al. Recursive deep models for semantic composi-\ntionality over a sentiment treebank. In:Proceedings of the 2013\nConference on Empirical Methodsin Natural Language Processing.\n1631–1642 (Association for Computational Linguistics, 2013).\n22. LeBel, A. et al. A natural language fmri dataset for voxelwise\nencoding models.bioRxiv https://www.biorxiv.org/content/10.\n1101/2022.09.22.509104v1(2022).\n23. Jones, K. S. A statistical interpretation of term speciﬁcity and its\napplication in retrieval.J. Documentation60, 493–502 (2021).\n24. Pennington, J., Socher, R., & Manning, C.D. Glove: global\nvectors for word representation. In:Proceedings of the 2014\nConference on Empirical Methods in Natural Language Pro-\ncessing (EMNLP). 1532– 1543 (Association for Computational\nLinguistics, 2014).\n25. Quinlan, J. R. Induction of decision trees.Mach. Learn.1,\n81–106 (1986).\n26. Breiman, L. Random forests.Mach. Learn.45,5 –32 (2001).\n27. Bach, S.H. et al. Promptsource: an integrated development\nenvironment and repository for natural language prompts.\nhttps://arxiv.org/abs/2202.01279(2022).\n28. Ribeiro, M.T., Singh, S., Guestrin, C. Why should I trust you?:\nExplaining the predictions of any classiﬁer. In:Proceedings of the\n22nd ACM SIGKDD International Conference on Knowledge Dis-\ncovery and Data Mining.1 1 3 5–1144 (ACM, 2016).\n29. Lundberg, S. & Lee, S.-I. An unexpected unity among methods for\ninterpreting model predictions.https://arxiv.org/abs/1611.\n07478 (2016).\n30. Huth, A. G., De Heer, W. A., Grifﬁths, T. L., Theunissen, F. E. &\nGallant, J. L. Natural speech reveals the semantic maps that tile\nhuman cerebral cortex.Nature 532,4 5 3–458 (2016).\n31. Schrimpf, M. et al. The neural architecture of language: Integrative\nmodeling converges on predictive processing.P r o c .N a t lA c a d .\nSci. USA118, 2105646118 (2021).\n32. Antonello, R.J. & Huth, A. Predictive coding or just feature dis-\ncovery? an alternative account of why language modelsﬁtb r a i n\ndata. Neurobiol. Lang. 3,1 –39 (2022).\n33. Caucheteux, C. & King, J.-R. Brains and algorithms partially con-\nverge in natural language processing.Commun. Biol.5\n,\n1–10 (2022).\n34. Caruana, R.et al. Intelligiblemodels for healthcare: Predicting\npneumonia risk and hospital 30-day readmission. In:Proceedings\nof the 21th ACM SIGKDD International Conference on Knowledge\nDiscovery and Data Mining.1 7 2 1–1730 (ACM, 2015).\n35. McCullagh, P. & Nelder, J. A. Generalized linear models.J. Am.\nStat. Assoc.88, 698 (1993).\n36. Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. Dis-\ntributed representations of words and phrases and their compo-\nsitionality.Adv. Neural Inf. Process. Syst.26 https://arxiv.org/abs/\n1310.4546(2013).\n37. Mikolov, T., Chen, K., Corrado, G., & Dean, J. Efﬁcient estimation of\nword representations in vector space.https://arxiv.org/abs/1301.\n3781 (2013).\n38. Tan, C.et al. A survey on deep transfer learning. In:Artiﬁcial Neural\nNetworks and Machine Learning–ICANN 2018: 27th International\nConference on Artiﬁcial Neural Networks, Rhodes, Greece, Octo-\nber 4–7, 2018, Proceedings, Part III 27.2 7 0–279 (Springer, 2018).\nSpringer.\n39. Honnibal, M., Montani, I., Van Landeghem, S., & Boyd, A. Spacy:\nIndustrial-strength natural language processing in python.\nZenodo https://doi.org/10.5281/zenodo.3701227(2020).\n40. Pedregosa, F. et al. Scikit-learn: machine learning in python.J.\nMach. Learn. Res.12,2 8 2 5–2830 (2011).\n41. Hastie, T. & Tibshirani, R. Generalized additive models.Stat. Sci.1,\n297–318 (1986).\n42. Agarwal, R. et al. Neural additive models: Interpretable machine\nlearning with neural nets.Adv. Neural Inf. Process. Syst.34,\n4699–4711 (2021).\n43. Joulin, A., Grave, E., Bojanowski, P., & Mikolov, T. Bag of tricks for\nefﬁcient text classiﬁcation. https://arxiv.org/abs/1607.\n01759 (2016).\n44. Peters, M. E. et al. Deep contextualized word representations. In:\nProceedings of the 2018 Conference of the North American\nChapter of the Association for Computational Linguistics: Human\nLanguage Technologies, Volume 1 (Long Papers). 2227–2237. New\nOrleans, Louisiana (Association for Computational Linguis-\ntics, 2018).\n45. Lin, J., Zhong, C., Hu, D., Rudin, C., & Seltzer, M. Generalized and\nscalable optimal sparse decision trees. In:International Con-\nference on Machine Learning.6 1 5 0–6160 (PMLR, 2020).\n46. Hu, X., Rudin, C., & Seltzer, M. Optimal sparse decision trees.Adv.\nNeural Inf. Process. Syst. (NeurIPS)https://arxiv.org/abs/1904.\n12847\n(2019).\nArticle https://doi.org/10.1038/s41467-023-43713-1\nNature Communications|         (2023) 14:7913 9\n47. Bertsimas, D. & Dunn, J. Optimal classiﬁcation trees.Mach. Learn.\n106,1 0 3 9–1082 (2017).\n48. Agarwal, A., Tan, Y. S., Ronen, O., Singh, C. & Yu, B. Hier-\narchical shrinkage: improving the accuracy and interpret-\nability of tree-based methods.https://arxiv.org/abs/2202.\n00858 (2022).\n49. Carreira-Perpinán, M. A. & Tavallali, P. Alternating optimization of\ndecision trees, with application to learning sparse oblique trees.\nAdvances in Neural Information Processing Systems.V o l .3 1\n(ACM, 2018).\n5 0 . M o r r i s ,J .X . ,S i n g h ,C . ,R u s h ,A .M . ,G a o ,J . ,&D e n g ,Y .T r e e\nprompting: efﬁcient task adaptation withoutﬁne-tuning.https://\narxiv.org/abs/2310.14034(2023).\n51. Yao, S. et al. Tree of thoughts:deliberate problem solving with\nlarge language models.https://arxiv.org/pdf/2305.10601.\npdf (2023).\n52. Friedman, J. H. & Popescu, B. E. Predictive learning via rule\nensembles.Ann. Appl. Stat.2,9 1 6–954 (2008).\n53. Angelino, E., Larus-Stone, N., Alabi, D., Seltzer, M., & Rudin, C.\nLearning certiﬁably optimal rule lists for categorical data.https://\narxiv.org/abs/1704.01701(2017).\n5 4 . S i n g h ,C . ,N a s s e r i ,K . ,T a n ,Y .S . ,T a n g ,T .&Y u ,B .i m o d e l s :ap y t h o n\npackage forﬁtting interpretable models.J. Open Source Softw.6,\n3192 (2021).\n55. Freund, Y. et al. Experiments with a new boosting algorithm. In:\nIcml,v o l .9 6 .1 4 8–156 (Citeseer, 1996).\n56. Chen, T. & Guestrin, C. Xgboost: a scalable tree boosting system.\nIn: Proceedings of the 22nd Acm Sigkdd International Conference\non Knowledge Discovery and Data Mining.7 8 5–794 (ACM, 2016).\n5 7 . C h i p m a n ,H .A . ,G e o r g e ,E .I .&M c C u l l o c h ,R .E .B a r t :B a y e s i a n\nadditive regression trees.Ann. Appl. Stat.4,2 6 6–298 (2010).\n58. Lundberg, S. M. et al. Explainable AI for trees: from local expla-\nnations to global understanding.https://arxiv.org/abs/1905.\n04610 (2019).\n59. Friedman, J. H. Greedy function approximation: a gradient\nboosting machine.Ann. Stat. 29, 1189–1232 (2001).\n60. Devlin, S., Singh, C., Murdoch, W.J., & Yu, B. Disentangled attri-\nbution curves for interpreting random forests and boosted trees.\nhttps://arxiv.org/abs/1905.07631(2019).\n61. Janizek, J. D., Sturmfels, P. & Lee, S.-I. Explaining explanations:\naxiomatic feature interactions for deep networks.J. Mach. Learn.\nRes. 22,1 0 4–1 (2021).\n62. Singh, C., Murdoch, W.J., & Yu, B. Hierarchical interpretations\nfor neural network predictions.International Conference on\nLearning Representations,V o l .2 6https://arxiv.org/abs/1806.\n05337 (2019).\n63. Singh, C. et al. Transformation importance with applications to\ncosmology.https://arxiv.org/abs/2003.01926(2020).\n64. Rudin, C. Please stop explaining black box models for high stakes\ndecisions.https://arxiv.org/abs/1811.10154(2018).\n6 5 . M u r d o c h ,W .J . ,S i n g h ,C . ,K u m b i e r ,K . ,A b b a s i - A s l ,R .&Y u ,B .\nDeﬁnitions, methods, and applications in interpretable machine\nlearning.P r o c .N a t lA c a d .S c i .U S A116, 22071–22080 (2019).\n66. Zaidan, O. & Eisner, J. Modeling annotators: A generative\napproach to learning from annotator rationales. In:Proceedings of\nthe 2008 Conference on Empirical Methods in Natural Language\nProcessing.3 1–40 (ACM, 2008).\n67. Sha, L., Camburu, O.-M. & Lukasiewicz, T. Learning from the best:\nRationalizing predictions by adversarial information calibration.\nIn: AAAI,1 3 7 7 1–13779.https://doi.org/10.1609/aaai.v35i15.\n17623(2021).\n68. Hendricks, L.A. et al. Generating visual explanations. In:European\nConference on Computer Vision.3 –19 (Springer, 2016).\n69. Camburu, O.-M., Rocktäschel, T., Lukasiewicz, T. & Blunsom, P.\ne-snli: Natural language inference with natural language\nexplanations.Adv. Neural Inf. Process. Syst.31 https://arxiv.org/\nabs/1812.01193(2018).\n70. Wei, J. et al. Chain-of-thought prompting elicits reasoning in large\nlanguage models.Adv. Neural Inf. Process. Syst.35,\n24824–24837 (2022).\n71. Conneau, A., Kruszewski, G., Lample, G., Barrault, L., & Baroni, M.\nWhat you can cram into a single vector: Probing sentence\nembeddings for linguistic properties.https://arxiv.org/abs/1805.\n01070 (2018).\n72. Liu, F. & Avci, B. Incorporating priors with feature attribution on\ntext classiﬁcation. https://arxiv.org/abs/1906.08286(2019).\n73. Wang, X., Xu, X., Tong, W., Roberts, R. & Liu, Z. Inferbert: a\ntransformer-based causal inference framework for enhancing\npharmacovigilance.Front. Artif. Intell.4, 659622 (2021).\n74. Olah, C. et al. The buildingblocks of interpretability.Distill 3,\n10 (2018).\n75. Meng, K., Bau, D., Andonian, A. & Belinkov, Y. Locating and editing\nfactual knowledge in GPT.https://arxiv.org/abs/2202.\n05262 (2022).\n7 6 . L i ,O . ,L i u ,H . ,C h e n ,C . ,&R u d i n ,C .D e e pl e a r n i n gf o rc a s e - b a s e d\nreasoning through prototypes: a neural network that explains its\npredictions. In:Proceedings of the AAAI Conference on Artiﬁcial\nIntelligence,v o l .3 2( A A A IP r e s s m2 0 1 8 ) .\n77. Chen, C. et al. This looks like that: deep learning for interpretable\nimage recognition.\nAdv. Neural Inf. Process. Syst. 32 https://arxiv.\norg/abs/1806.10574(2019).\n78. Koh, P.W et al. Concept bottleneck models. In:International\nConference on Machine Learning.5338–5348 (PMLR, 2020).\n79. Yang, Y. et al. Language in a bottle: Language model guided\nconcept bottlenecks for interpretable image classiﬁcation.\nhttps://arxiv.org/abs/2211.11158(2022).\n80. Ghosh, S. et al. Dividing and conquering a blackbox to a mixture of\ninterpretable models: route, interpret, repeat.https://arxiv.org/\nabs/2307.05350(2023).\n81. Yuksekgonul, M., Wang, M., & Zou, J. Post-hoc concept bottleneck\nmodels. https://arxiv.org/abs/2205.15480(2022).\n82. McInerney, D.J., Young, G., Meent, J.-W. & Wallace, B.C. Chill:\nzero-shot custom interpretable feature extraction from clinical\nnotes with large language models.https://arxiv.org/abs/2302.\n12343 (2023).\n83. Frosst, N. & Hinton, G. Distilling a neural network into a soft\ndecision tree.https://arxiv.org/abs/1711.09784(2017).\n8 4 . Z a r l e n g a ,M . E . ,S h a m s ,Z .&J a m n i k ,M .E fﬁcient decompositional\nrule extraction for deep neural networks.https://arxiv.org/abs/\n2111.12628(2021).\n8 5 . T a n ,S . ,C a r u a n a ,R . ,H o o k e r ,G . ,K o c h ,P .&G o r d o ,A .\nLearning global additive explanations for neural nets using\nmodel distillation. ICLR 2019 Conference Blind Submis-\nsion (2018).\n86. Hinton, G., Vinyals, O., & Dean, J. Distilling the knowledge in a\nneural network.https://arxiv.org/abs/1503.02531(2015).\n8 7 . S a n h ,V . ,D e b u t ,L . ,C h a u m o n d ,J .&W o l f ,T .D i s t i l b e r t ,ad i s t i l l e d\nversion of bert: smaller, faster, cheaper and lighter.https://arxiv.\norg/abs/1910.01108(2019).\n88. Wolf, T. et al. Huggingface’s transformers: state-of-the-art\nnatural language processing. https://arxiv.org/abs/1910.\n03771 (2019).\n89. Hazourli, A. Financialbert-a pretrained language model forﬁnan-\ncial text mining.https://doi.org/10.13140/RG.2.2.34032.\n12803 (2022).\n90. Morris, J. X. et al. Textattack: a framework for adversarial attacks,\ndata augmentation, and adversarial training in nlp.https://arxiv.\norg/abs/2005.05909(2020).\n91. Akl, H.A., Mariko, D., & De Mazancourt, H. Yseop atﬁnsim-3\nshared task 2021: Specializingﬁnancial domain learning\nArticle https://doi.org/10.1038/s41467-023-43713-1\nNature Communications|         (2023) 14:7913 10\nwith phrase representations. https://arxiv.org/abs/2108.\n09485 (2021).\n92. Liu, Y. et al. Roberta: a robustly optimized bert pretraining\napproach.https://arxiv.org/abs/1907.11692(2019).\n93. Su, H. et al. One embedder, any task: Instruction-ﬁnetuned text\nembeddings.https://arxiv.org/abs/2212.09741(2022).\n94. Radford, A. et al. Language models are unsupervised multitask\nlearners.OpenAI Blog1,9( 2 0 1 9 ) .\n95. Touvron, H. et al. Llama: Open and efﬁcient foundation language\nmodels. https://arxiv.org/abs/2302.13971(2023).\n96. Raffel, C. et al. Exploring the limits of transfer learning with a\nuniﬁed text-to-text transformer.J .M a c h .L e a r n .R e s .21,\n1–67 (2020).\n97. Zhang, X., Zhao, J., LeCun, Y. Character-level convolutional net-\nworks for text classiﬁcation. Adv. Neural Inf, Process. Syst.28\nhttps://arxiv.org/abs/1509.01626(2015).\n98. Lehmann, J. et al. Dbpedia– a large-scale, multilingual\nknowledge base extracted from wikipedia.Semant. Web. 6,\n167– 195 (2015).\n99. Li, X. & Roth, D. Learning question classiﬁers. In:COLING 2002:\nThe 19th International Conference on Computational Linguistics.\nhttps://doi.org/10.3115/1072228.1072378(2002).\n100. Loper, E. & Bird, S. Nltk: The natural language toolkit.https://arxiv.\norg/abs/cs/0205028(2002).\nAuthor contributions\nC.S. and A.A. additionally carried out the experiments and analysis. C.S.,\nA.A., R.C., and J.G. participated in the development of ideas, reviewing\nof results, and writing and editing the manuscript.\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nSupplementary informationThe online version contains\nsupplementary material available at\nhttps://doi.org/10.1038/s41467-023-43713-1.\nCorrespondenceand requests for materials should be addressed to\nChandan Singh.\nPeer review informationNature Communicationsthanks the anon-\nymous reviewers for their contribution to the peer review of this work. A\npeer reviewﬁle is available.\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nPublisher’s noteSpringer Nature remains neutral with regard to jur-\nisdictional claims in published maps and institutional afﬁliations.\nOpen AccessThis article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as\nlong as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons license, and indicate if\nchanges were made. The images or other third party material in this\narticle are included in the article’s Creative Commons license, unless\nindicated otherwise in a credit line to the material. If material is not\nincluded in the article’s Creative Commons license and your intended\nuse is not permitted by statutory regulation or exceeds the permitted\nuse, you will need to obtain permission directly from the copyright\nholder. To view a copy of this license, visithttp://creativecommons.org/\nlicenses/by/4.0/.\n© The Author(s) 2023\nArticle https://doi.org/10.1038/s41467-023-43713-1\nNature Communications|         (2023) 14:7913 11",
  "topic": "Interpretability",
  "concepts": [
    {
      "name": "Interpretability",
      "score": 0.9015246033668518
    },
    {
      "name": "Inference",
      "score": 0.7753914594650269
    },
    {
      "name": "Computer science",
      "score": 0.6642740964889526
    },
    {
      "name": "Variety (cybernetics)",
      "score": 0.6621586084365845
    },
    {
      "name": "Decision tree",
      "score": 0.5372357964515686
    },
    {
      "name": "Machine learning",
      "score": 0.5219199657440186
    },
    {
      "name": "Artificial intelligence",
      "score": 0.49779176712036133
    },
    {
      "name": "Transparency (behavior)",
      "score": 0.4561260938644409
    },
    {
      "name": "Tree (set theory)",
      "score": 0.4361770749092102
    },
    {
      "name": "Language model",
      "score": 0.4357723295688629
    },
    {
      "name": "Data science",
      "score": 0.39948078989982605
    },
    {
      "name": "Natural language processing",
      "score": 0.3767791986465454
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Computer security",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1290206253",
      "name": "Microsoft (United States)",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I95457486",
      "name": "University of California, Berkeley",
      "country": "US"
    }
  ],
  "cited_by": 38
}