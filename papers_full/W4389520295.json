{
    "title": "LLM-in-the-loop: Leveraging Large Language Model for Thematic Analysis",
    "url": "https://openalex.org/W4389520295",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A4224674437",
            "name": "Shih-Chieh Dai",
            "affiliations": [
                "The University of Texas at Austin"
            ]
        },
        {
            "id": "https://openalex.org/A2055343036",
            "name": "Aiping Xiong",
            "affiliations": [
                "Pennsylvania State University"
            ]
        },
        {
            "id": "https://openalex.org/A4209219196",
            "name": "Lun-Wei Ku",
            "affiliations": [
                "Academia Sinica"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4281557260",
        "https://openalex.org/W2983493784",
        "https://openalex.org/W2950504429",
        "https://openalex.org/W3126574961",
        "https://openalex.org/W4387606052",
        "https://openalex.org/W4385571232",
        "https://openalex.org/W4360978668",
        "https://openalex.org/W4304195432",
        "https://openalex.org/W4384662964",
        "https://openalex.org/W2053154970",
        "https://openalex.org/W4385567149",
        "https://openalex.org/W4378189609",
        "https://openalex.org/W2136480620",
        "https://openalex.org/W4221143046",
        "https://openalex.org/W1979290264",
        "https://openalex.org/W4226399820",
        "https://openalex.org/W4389636360",
        "https://openalex.org/W2013378101",
        "https://openalex.org/W3215074405",
        "https://openalex.org/W4366548345",
        "https://openalex.org/W4377865052",
        "https://openalex.org/W3135877859",
        "https://openalex.org/W4385571157",
        "https://openalex.org/W1734706406",
        "https://openalex.org/W4320516905",
        "https://openalex.org/W3071709344",
        "https://openalex.org/W4311642023",
        "https://openalex.org/W2245858136",
        "https://openalex.org/W2803876882",
        "https://openalex.org/W4322718191",
        "https://openalex.org/W3004787609",
        "https://openalex.org/W3035119815",
        "https://openalex.org/W4224308101",
        "https://openalex.org/W4292779060"
    ],
    "abstract": "Thematic analysis (TA) has been widely used for analyzing qualitative data in many disciplines and fields. To ensure reliable analysis, the same piece of data is typically assigned to at least two human coders. Moreover, to produce meaningful and useful analysis, human coders develop and deepen their data interpretation and coding over multiple iterations, making TA labor-intensive and time-consuming. Recently the emerging field of large language models (LLMs) research has shown that LLMs have the potential replicate human-like behavior in various tasks: in particular, LLMs outperform crowd workers on text-annotation tasks, suggesting an opportunity to leverage LLMs on TA. We propose a human–LLM collaboration framework (i.e., LLM-in-the-loop) to conduct TA with in-context learning (ICL). This framework provides the prompt to frame discussions with a LLM (e.g., GPT-3.5) to generate the final codebook for TA. We demonstrate the utility of this framework using survey datasets on the aspects of the music listening experience and the usage of a password manager. Results of the two case studies show that the proposed framework yields similar coding quality to that of human coders but reduces TA's labor and time demands.",
    "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 9993–10001\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nLLM-in-the-loop: Leveraging Large Language Model for Thematic\nAnalysis\nShih-Chieh Dai1 Aiping Xiong2 Lun-Wei Ku3\n1 University of Texas at Austin 2Pennsylvania State University 3Academia Sinica\n1sjdai@utexas.edu 2axx29@psu.edu 3lwku@iis.sinica.edu.tw\nAbstract\nThematic analysis (TA) has been widely used\nfor analyzing qualitative data in many disci-\nplines and fields. To ensure reliable analysis,\nthe same piece of data is typically assigned to at\nleast two human coders. Moreover, to produce\nmeaningful and useful analysis, human coders\ndevelop and deepen their data interpretation\nand coding over multiple iterations, making TA\nlabor-intensive and time-consuming. Recently\nthe emerging field of large language models\n(LLMs) research has shown that LLMs have\nthe potential replicate human-like behavior in\nvarious tasks: in particular, LLMs outperform\ncrowd workers on text-annotation tasks, sug-\ngesting an opportunity to leverage LLMs on\nTA. We propose a human–LLM collaboration\nframework (i.e., LLM-in-the-loop) to conduct\nTA with in-context learning (ICL). This frame-\nwork provides the prompt to frame discussions\nwith a LLM (e.g., GPT-3.5) to generate the final\ncodebook for TA. We demonstrate the utility\nof this framework using survey datasets on the\naspects of the music listening experience and\nthe usage of a password manager. Results of\nthe two case studies show that the proposed\nframework yields similar coding quality to that\nof human coders but reduces TA’s labor and\ntime demands. 1\n1 Introduction\nBraun and Clarke (2006) propose thematic analysis\n(TA) to identify themes that represent qualitative\ndata (e.g. free-text response). TA, which relies on\nat least two human coders with relevant expertise\nto run the whole process, is widely used in qualita-\ntive research (QR). However, TA is labor-intensive\nand time-consuming. For instance, for an in-depth\nunderstanding of the data, coders require multiple\nrounds of discussion to resolve ambiguities and\nachieve consensus.\n1The code repository is publicly available at:\nhttps://github.com/sjdai/LLM-thematic-analysis\nLarge language models (LLMs) have ad-\nvanced artificial intelligence (AI) tremendously re-\ncently (Brown et al., 2020; Chowdhery et al., 2022;\nScao et al., 2022; Touvron et al., 2023). Prompt-\ning techniques such as in-context learning (ICL),\nchain-of-thought, and reasoning and action elicit\ndecent results on various natural language process-\ning (NLP) tasks (Wei et al., 2022; Kojima et al.,\n2022; Suzgun et al., 2022; Yao et al., 2023). LLM-\nbased applications continue to multiply, including\nCopilot for programming,2 LaMDA for dialogue\ngeneration (Thoppilan et al., 2022), and ChatGPT.3\nIndeed, several studies show that LLMs outperform\nhuman annotator performance on crowdsourcing\ntasks (Gilardi et al., 2023; Chiang and Lee, 2023;\nZiems et al., 2023), which indicates a potential op-\nportunity to leverage LLMs for TA. Thus, in this\nwork, we address the research question: can NLP\ntechniques (i.e., LLMs) enhance the efficiency of\nTA?\nWe loop ChatGPT to act as a machine coder\n(MC) and work with a human coder (HC) on TA.\nFollowing Braun and Clarke (2006), we leverage\nICL to design the prompt for each step. The HC\nfirst becomes familiar with the data, after which\nthe MC extracts the initial codes based on the re-\nsearch question and free-text responses. Next, the\nMC groups the similar initial codes into represen-\ntative codes representing the responses and which\nanswer the research question. We design a discus-\nsion prompt for the MC and HC to use to refine\nthe codes. The discussion ends once the HC and\nMC come to agreement, after which the codebook\nis generated. Following the TA procedure, the HC\nand MC utilize the codebook to code the responses\nand calculate the inner-annotator agreement (IAA)\nto measure the quality of the work. See Section 3\nfor detailed information.\nWe study the effectiveness of this human–LLM\n2https://github.com/features/copilot\n3https://openai.com/blog/chatgpt\n9993\nAction: Delete\nReason: I deleted the \"Reflective \nand Mood-setting Songs\", … codes, \nsince they are all covered under \n\"Emotional and Relatable Songs\"\nInitial \nCodes\nExemplars\nData\nCodes\nInner-Annotator-Agreement\nData\nAnnotated \nData\nAnnotated \nData\nCodebook\nDecision: Agree\nReason: These codes can be \nmerged into the 'Emotional and \nRelatable Songs' code as they all \nrelate to emotional responses.\nStep 1. \nData Familiarization & \nExemplar Generation\nStep 2. \nInitial Code Generation\nData\nStep 3. \nCode Refinement &\nInitial Codebook Generation\nExemplars\nStep 4. \nTheme Identification & Evaluation \nThemes\nHuman GPT\nFigure 1: Workflow of the LLM-in-the-Loop Framework.\ncollaboration framework by adopting the frame-\nwork on two cases: Music Shuffle (MS), a sur-\nvey measuring aspects of music listening experi-\nences (Sanfilippo et al., 2020) and Password Man-\nager (PM), a survey on password manager us-\nage (Mayer et al., 2022). Considering the LLM\ninput size limitations, we randomly divided the re-\nsponses of PM into two separate pools and applied\none pool for codebook generation. Subsequently,\nwe sampled responses from both pools for final cod-\ning and IAA calculation. The results suggest that\nthe proposed LLM-in-the-loop framework yields\nwork quality comparable to two HCs.\nThe contributions of this work are as follows:\n1) we propose a human–LLM collaboration frame-\nwork for TA; 2) we design a loop to facilitate dis-\ncussions between a human coder and a LLM; 3)\nwe propose a solution for long-text qualitative data\nwhen using a LLM for TA.\n2 Background and Related Work\nGiven the substantial amount of free-text responses,\nit seems obvious that NLP techniques can be poten-\ntial solutions to facilitate TA. Existing work tends\nto rely on topic modeling to extract key topics that\nrepresent the data (Leeson et al., 2019; Jelodar\net al., 2020). Another approach is clustering: for\ninstance, Oyebode et al. (2021) extract phrases, cal-\nculate their sentiment scores, and group the phrases\ninto themes based on their sentiment polarity. Guet-\nterman et al. (2018) cluster phrases by their Wu–\nPalmer similarity scores (Wu and Palmer, 1994).\nModels can be trained to learn how humans\ncode (Rietz et al., 2020). Human–AI collaboration\nframeworks for TA have been proposed (Gauthier\nand Wallace, 2022; Gebreegziabher et al., 2023;\nJiang et al., 2021).\nQR and NLP researchers are now exploring the\nopportunity to leverage LLMs for TA. Xiao et al.\n(2023) investigate the use of LLMs to support\ndeductive coding: they combine GPT-3 with an\nexpert-drafted codebook. Gao et al. (2023) pro-\npose a user-friendly interface for collaborative qual-\nitative analysis, leveraging LLMs for initial code\ngeneration and to help in decision-making. Paoli\n(2023) studies the potential usage of ChatGPT for\nTA following the six TA phases proposed by Braun\nand Clarke (2006). In the theme refinement phase,\nthe author generates three versions of themes by\nmodifying the temperature parameter,4 after which\nthe themes are reviewed by a HC (the author).\nCoding can be divided into inductive coding and\ndeductive coding. Inductive coding is a bottom-up\nprocess of developing a codebook, and deductive\ncoding is a top-down process in which all data\n4The temperature parameter determines the output\nrandomness: higher values yield more random output.\nhttps://platform.openai.com/docs/api-reference/\nchat/create\n9994\nFigure 2: An exemplar for initial code extraction. Green\ndepicts the quoted sentence, blue indicates the definition\nof a code, and red represents the code.\nis coded using the codebook. We complete both\ninductive and deductive coding via human–AI col-\nlaboration and showcase the feasibility of our ap-\nproach using two existing open-access datasets.\n3 Human–LLM Collaboration\nFramework\nFigure 1 illustrates the framework, which consists\nof four steps.\nData Familiarization and Exemplar Generation\nWe used in-context learning (ICL) to design the\nparadigm of prompt for the initial code extrac-\ntion (Garg et al., 2022). To write the exemplars\nfor initial code extraction, the HC must be familiar\nwith the qualitative data. Each HC produces four to\neight exemplars, following Min et al. (2022). Each\nexemplar includes a response for an open-ended\nquestion and the associated actions. Given a free-\ntext response may contain multiple codes, we think\n“step by step” and “code by code” that were in-\nspired by chain-of thought (CoT) prompting (Wei\net al., 2022; Kojima et al., 2022). To code a re-\nsponse, the format of an action is “quote refers to\ndefinition of the code. Thus, we got a code:\ncode”. Figure 2 shows one instance. The quote is\nthe sentence in the response that is related to the\ncode.\nInitial Code Generation At this step, codes are\nextracted that capture the semantic and latent mean-\nings of the free-text responses at a fine granularity.\nThe core of the prompt is the exemplar generated\nin the first step. The prompt also contains the task\ngoal and the open-ended question, which provide\nthe MC with a clear understanding of the purpose\nof the study. The prompts we used are shown in\nAppendix D.\nCode Refinement and Initial Codebook Genera-\ntion The model groups the similar initial codes\ninto certain codes which the MC and HC begin to\nrefine. Step 3 in Figure 1 illustrates a cycle of the\ndiscussion process. First an HC reviews the codes\nand edits the codes if necessary. If the HC modifies\nany code, he/she states the changes and provides\nthe rationales behind them. After evaluating the\nchanges and the rationales, the MC indicates agree-\nment or disagreement with explanations. The HC\nthen reviews the MC’s responses and revises the\ncode if needed. The HC initiates a new cycle by\nediting the codes and providing justification. Such\nrefinement continues until the HC and MC are both\nsatisfied with the result. The refined codes are then\nused to generate the initial codebook.\nTheme Identification and Evaluation The MC\nand HC generate the final codebook by identify-\ning the themes of the codes. MC and HC code\nthe whole qualitative data according to the final\ncodebook. Cohen’s κagreement (Cohen, 1960) is\ncalculated to evaluate the work quality of the MC\nand HC.\n4 Evaluation\n4.1 Metrics\nThe inner-annotator agreement (IAA) is the main\nmethod for evaluating the quality of coding (Krip-\npendorff, 2011). IAA measures the clarity and\ninterpretability of a codebook among the coders.\nA higher IAA suggests the codebook is clear and\neffectively captures the meaning of the data. We\nuse Cohen’s κto compare the results of the two\ndatasets. In addition, to evaluate whether the codes\nfrom our framework meet the research goal of the\noriginal work, we treat the codes generated by the\nauthors of the two datasets as the gold label. We\ncalculate the cosine similarity between codes devel-\noped by us and those proposed by the original au-\nthors. We used the text-embedding-ada-002 em-\nbedding provided by OpenAI to embed the codes\nand then calculated their cosine similarity.\n4.2 Setting\nMS In our case study, we focused on the first-\nasked question because the authors mentioned that\nsome participants provided the same or similar an-\nswers to all four questions. The sampled question\nis “What’s the first thing that comes into your mind\nabout this track?” Preprocessing yielded 35 re-\nsponses for our study.\n9995\nMusic Shuffle Password Manager\nAll Seen Unseen All\nHC + MC 0.87 0.8 0.82 0.81\nCoder3+ MC 0.54 0.47 0.34 0.47\nCoder3+ HC 0.62 0.48 0.38 0.43\nGold 0.66 – – 0.77\nTable 1: Cohen’s κof the two cases. The HC, MC, and\nCoder 3 used the same codebook for final coding. Seen\nand Unseen indicate the data was sampled from the\nresponses used or not used for developing the codebook,\nwhere All means Seen + Unseen.\nMS PM\nSimilarity0.8864 0.8895\nAccuracy 0.84 0.83\nRecall 0.72 0.87\nTable 2: Cosine similarity, accuracy, and recall between\nthe codes extracted by our framework and the dataset’s\nauthors.\nPM Of the eight open-ended questions, we se-\nlected the first question—“Please describe how you\nmanage your passwords across accounts”—as this\nquestion is general, and seems to have elicited bet-\nter responses. Due to the GPT input limitations,\nwe could not feed all the data into GPT-3.5. Thus\nwe randomly sampled 100 responses for codebook\ndevelopment. Such leveraging of partial responses\nfor codebook development has been used by San-\nfilippo et al. (2020). We used the 100 responses for\ncodebook development and in the evaluation phase\nwe sampled 20 samples from the two data pools for\nlabeling and IAA calculation, respectively.\nFollowing the MS and PM workflow, we de-\nveloped a codebook using our framework with a\nHC and the MC for each case. The HC and MC\ncoded all the responses. We invited another coder\n(Coder 3) to code the responses using both code-\nbooks developed by the HC and MC. The detailed\ninformation of the datasets is in Appendix C.\n4.3 Results and Discussion\nThe results are presented in Table 1: HC + MC\nindicate Cohen’s κof HC and MC annotated data,\nand Coder 3 + MC and Coder 3 + HC represent\nCohen’s κ of Coder 3 and MC labeled data and\nCoder 3 and HC labeled data, respectively. We\ntreat the result of the original studies as the gold\nstandard for reference. Table 2 shows the result of\ncosine similarity, accuracy, and recall.\nLLM is suited for thematic analysis. The re-\nsults of the MS case study suggest that HC+MC\nachieves the best agreement compared to all other\nsettings, where the κof HC+MC is 0.87 (almost\nperfect agreement), and that of Gold is 0.66 (sub-\nstantial agreement). Further, even though the κ\ndecreases in the Coder 3 settings, Coder 3+MC and\nCoder 3+HC still exhibit similar agreement com-\npared to Gold: The κof Coder 3+MC and Coder\n3+HC are 0.54 (moderate to substantial agreement)\nand 0.62 (substantial agreement), respectively. This\nindicates that our framework achieves reasonable\nperformance. In the results of the PM case study,\nHC+MC (κ = 0.81: almost perfect agreement)\noutperforms Gold ( κ = 0.77: substantial agree-\nment). The cosine similarity also shows that the\nMC-extracted codes capture the semantic meaning\nof the codes provided by the authors of the datasets.\nWe thus conclude that the human–LLM collabo-\nration framework can perform as well as the two\nhuman coders on thematic analysis, but with one\nhuman coder instead of two, which reduces labor\nand time demands.\nA discrepancy discussion process might be neces-\nsary. The relatively poorer results of Coder 3 still\nindicate a nearly fair to moderate agreement. Theκ\nof Coder 3+MC and Coder 3+HC are (0.47, 0.48),\n(0.34, 0.38), and (0.47, 0.43) for the three condi-\ntions (i.e., Seen, Unseen, and All) , respectively.\nThe PM authors mentioned that if the agreement\nis lower than κ =0.7, they discussed the result\nand started a new coding round to re-code the data.\nThey indicated an average 1.5 rounds of re-coding.\nSimilarly, our results indicate a need for such a\nmechanism. We leave this as future work.\nDeveloping the codebook using partial data is\na feasible approach. In the Unseen condition,\nthe HC+MC agreement is high (κ= 0.82: almost\nperfect agreement). Additionally, the cosine simi-\nlarity between the codes extracted by MC and the\ngold codes provided by the authors of the dataset is\n0.8895, which indicates the codes effectively cap-\nture the semantic meaning of the gold codes. These\nresults imply that using partial data for codebook\ndevelopment is a viable way to address LLM input\nsize limitations for TA.\n4.4 Error Analysis\nTo investigate why the IAA dropped significantly\nin the results of Coder 3 with MC and HC, we pull\n9996\nMS PM\nAmbiguity5 9\nGranularity8 7\nDistinction9 14\nTotal 22 30\nTable 3: The number of mismatched responses in each\ncategory in the two different datasets.\nMS (All)PM (Seen) PM (Uneen) PM (All)\nMC+Coder30.54/0.560.47/0.72 0.34/0.50 0.47/0.62\nHC+Coder30.62/0.720.48/0.69 0.38/0.54 0.43/0.62\nTable 4: The number before “/” is the IAA calculated\nby code, and the number after “/” represents the IAA\ncalculated by theme.\nthe sample that they coded differently and the code-\nbook. We found three major reasons: Ambiguity,\nGranularity, and Distinction that led the low IAA\nof Coder 3 with MC and HC. Table 3 is the analy-\nsis of the samples that the three coders (MC, HC,\nCoder 3) coded differently.\nAmbiguity Ambiguity indicates that the coders\ncoded the different codes that actually belong to\nthe same theme. For instance, “Digital Notes” and\n“Notes” are both under the theme “Written Records\nand Notes.” Given a free-text response, “Keep them\nin a notes tab on my phone”, the coders might code\nthis response as “Digital Notes” or “Notes.” These\ntwo codes belong to the same theme and are correct\nbut would drop the IAA if one coder selects “Digi-\ntal notes” and the other selects “Notes.” We found\nthat among 22 mismatched responses 5 of them\nin MS dataset were due to the ambiguity of the\ncodes. In PM dataset, 9 out of 30 are categorized\nas the reason. To further confirm if the ambiguity\nof the codes influences the IAA, we calculated the\nIAA based on the theme. Table 4 represents the re-\nsult. The result suggests that all the IAA improved,\nwhich indicates that the ambiguity of the codes is\none factor leading to the low IAA.\nGranularity Granularity denotes the granularity\nof the coding work. We found that HC and MC\ncoded more finely than the Coder 3 in 8 out of 22\nand 7 out of 30 mismatched responses in MS and\nPM, respectively. For instance, for the response,\n“Sleeping, calm I saved it because I liked the way\nit sounded, I thought it would be a good song to\nfall asleep to. I enjoy listening to this song because\nit sounds sweet, like a cute sweet not cool sweet.”\nBoth HC and MC coded this response as “Positive”,\n“Relaxing”, and “sleep-inducing”, where Coder 3\nmissed the “Positive”.\nDistinction The other mismatched responses are\ndue to the coders assigning different codes for a\ngiven response. This could be a result of their\nvaried familiarity with the responses and the code-\nbook, leading them to interpret the response or\ncode differently. For instance, Coder 3 stated that\nsometimes it is hard to find a code that fits the re-\nsponse. As a result, Coder 3 can only identify the\nmost appropriate code for the response.\nOverall, we identified the three main factors that\nled the IAA drop significantly for Coder 3 with\nMC and HC. However, we argue that thematic anal-\nysis is inherently subjective and biased since the\ncoders must align to the research questions when\nmaking the codebooks (Braun and Clarke, 2006;\nVaismoradi et al., 2016). They generated the code-\nbook based on their expertise in the topic of the\nresponses and the research goal. Moreover, such\nsubjective nature is not specific to our work. In-\nstead, it is common for any thematic analysis. It is\narguable whether bias is a drawback for thematic\nanalysis since the goal is to provide a way to un-\nderstand the collected free-text data. For instance,\neven though the codebooks in our study are biased,\nthey have captured the semantic meaning of the\ndata to the research questions, and the cosine simi-\nlarity between our codebooks and the codebooks\nfrom the dataset is high (0.8864 and 0.8895). The\niterative nature of codebook generation leads the\ncodebook to be less biased. As we mentioned in\nthe discussion section, a discrepancy discussion\nprocess might be a solution to improve the IAA.\n5 Conclusion\nWe propose a framework for human–LLM collabo-\nration (i.e., LLM-in-the-loop) for thematic analysis\n(TA). The result of two case studies suggests that\nour proposed collaboration framework performs\nwell for TA. The human coder and machine coder\nexhibit almost perfect agreement (κ= 0.87 in Mu-\nsic Shuffle and κ = 0.81 in Password Manager),\nwhere the agreement reported by the dataset au-\nthors are κ= 0.66 for Music Shuffle and κ= 0.77\nfor Password Manager. We also address the LLM\ninput size limitation by using partial data for code-\nbook development, with results that suggest this is\na feasible approach.\nLimitations\nThere are four main limitations in this work.\n9997\nPrompts While we designed specific prompts\nfor each step that successfully elicited the desired\noutput to achieve our goals, it is important to note\nthat we cannot claim these prompts to be the most\noptimal or correct ones. As mentioned by Wei et al.\n(2022), there is still rooms to explore the potential-\nity of prompt to elicit better outputs from LLMs.\nWe believe that there might be better versions of\nprompts that can achieve better outcomes.\nApplication The survey or interview data might\nnot be able to be put into a third-party platform like\nOpenAI. Specifically, certain Institutional review\nboards (IRB) may have regulations that the data\nshould be stored on the institution’s server. This is\nespecially relevant for data that involves sensitive\ninformation, such as health-related studies. There-\nfore, the users have to check the IRB document\nor any regulations before they use our method for\nthematic analysis.\nModel We only studied the cases on GPT-3.5,\nwhile many off-shelf LLMs are available 5. There-\nfore, we can not guarantee using other LLMs\ncan achieve the comparable result. However, we\nhave demonstrated the effectiveness of our pro-\nposed framework with GPT-3.5. Future work\ncould adopt this framework to other Open-sources\nLLMs, such as Falcon (Almazrouei et al., 2023)\nand LLaMA (Touvron et al., 2023). However, the\ncomputational resources and cost might be the po-\ntential limitations.\nData The dataset, Music Shuffle, was published\nin 2020, while the training data for GPT-3.5 extends\nuntil September 2021. Therefore, GPT might have\nencountered or been trained on a similar dataset\nbefore. However, as most of the data are regulated\nby the IRB and the privacy concerns, it is challeng-\ning to find a dataset containing the raw responses\ndata and codebook for reuse. Therefore, we still de-\ncided to select this dataset for our study. The other\ndataset, Password Manager, was published in 2022,\nwhich does not have the concern, and our proposed\nmethod also performs well on this dataset.\nEthics Statement\nThe datasets we used in this work are all public for\nreuse. All the data do not contain privacy-sensitive\ninformation. Therefore, we used these two datasets\nwith OpenAI GPT3.5 model. However, the other\n5https://github.com/Hannibal046/Awesome-LLM\nusers need to confirm with their IRB before they\nused the proposed method for thematic analysis.\nAcknowledgements\nWe thank Katie Zhang and Zekun Cai for helping\nus with the thematic coding tasks. We thank Yi-\nLi Hsu for fruitful discussions. Thanks as well to\nthe anonymous reviewers for their helpful sugges-\ntions. The works of Aiping Xiong were in part\nsupported by NSF awards #1915801, #1931441\nand #2121097. This work is supported by the Na-\ntional Science and Technology Council of Taiwan\nunder grants 111-2634-F-002-022- and 112-2222-\nE-001-004-MY2.\nReferences\nEbtesam Almazrouei, Hamza Alobeidli, Abdulaziz Al-\nshamsi, Alessandro Cappelli, Ruxandra Cojocaru,\nMerouane Debbah, Etienne Goffinet, Daniel Hes-\nlow, Julien Launay, Quentin Malartic, Badreddine\nNoune, Baptiste Pannier, and Guilherme Penedo.\n2023. Falcon-40B: an open large language model\nwith state-of-the-art performance.\nVirginia Braun and Victoria Clarke. 2006. Using the-\nmatic analysis in psychology. Qualitative Research\nin Psychology, 3(2):77–101.\nVirginia Braun and Victoria Clarke. 2012. Thematic\nanalysis. American Psychological Association.\nVirginia Braun and Victoria Clarke. 2019. Reflecting\non reflexive thematic analysis. Qualitative Research\nin Sport, Exercise and Health, 11(4):589–597.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. Advances in Neural information Processing\nSystems, 33:1877–1901.\nCheng-Han Chiang and Hung-yi Lee. 2023. Can large\nlanguage models be an alternative to human evalua-\ntions? arXiv preprint arXiv:2305.01937.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, et al. 2022. Palm: Scaling\nlanguage modeling with pathways. arXiv preprint\narXiv:2204.02311.\nJacob Cohen. 1960. A coefficient of agreement for\nnominal scales. Educational and psychological mea-\nsurement, 20(1):37–46.\nJie Gao, Yuchen Guo, Gionnieve Lim, Tianqin Zhang,\nZheng Zhang, Toby Jia-Jun Li, and Simon Tangi Per-\nrault. 2023. Collabcoder: A gpt-powered workflow\nfor collaborative qualitative analysis.\n9998\nShivam Garg, Dimitris Tsipras, Percy S Liang, and Gre-\ngory Valiant. 2022. What can transformers learn\nin-context? a case study of simple function classes.\nAdvances in Neural Information Processing Systems,\n35:30583–30598.\nRobert P Gauthier and James R Wallace. 2022. The\ncomputational thematic analysis toolkit. Proceed-\nings of the ACM on Human-Computer Interaction,\n6(GROUP):1–15.\nSimret Araya Gebreegziabher, Zheng Zhang, Xiaohang\nTang, Yihao Meng, Elena L Glassman, and Toby Jia-\nJun Li. 2023. Patat: Human-ai collaborative qualita-\ntive coding with explainable interactive rule synthe-\nsis. In Proceedings of the 2023 CHI Conference on\nHuman Factors in Computing Systems, pages 1–19.\nFabrizio Gilardi, Meysam Alizadeh, and Maël Kubli.\n2023. Chatgpt outperforms crowd-workers for text-\nannotation tasks.\nTimothy C Guetterman, Tammy Chang, Melissa De-\nJonckheere, Tanmay Basu, Elizabeth Scruggs, and\nVG Vinod Vydiswaran. 2018. Augmenting qualita-\ntive text analysis with natural language processing:\nmethodological study. Journal of Medical Internet\nResearch, 20(6):e231.\nHamed Jelodar, Yongli Wang, Rita Orji, and Shucheng\nHuang. 2020. Deep sentiment classification and topic\ndiscovery on novel coronavirus or covid-19 online\ndiscussions: Nlp using lstm recurrent neural network\napproach. IEEE Journal of Biomedical and Health\nInformatics, 24(10):2733–2742.\nJialun Aaron Jiang, Kandrea Wade, Casey Fiesler, and\nJed R Brubaker. 2021. Supporting serendipity: Op-\nportunities and challenges for human-ai collaboration\nin qualitative analysis. Proceedings of the ACM on\nHuman-Computer Interaction, 5(CSCW1):1–23.\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\ntaka Matsuo, and Yusuke Iwasawa. 2022. Large lan-\nguage models are zero-shot reasoners. In ICML 2022\nWorkshop on Knowledge Retrieval and Language\nModels.\nKlaus Krippendorff. 2011. Agreement and information\nin the reliability of coding. Communication Methods\nand Measures, 5(2):93–112.\nWilliam Leeson, Adam Resnick, Daniel Alexander, and\nJohn Rovers. 2019. Natural language processing\n(nlp) in qualitative public health research: a proof of\nconcept study. International Journal of Qualitative\nMethods, 18:1609406919887021.\nPercy Liang, Rishi Bommasani, Tony Lee, Dimitris\nTsipras, Dilara Soylu, Michihiro Yasunaga, Yian\nZhang, Deepak Narayanan, Yuhuai Wu, Ananya Ku-\nmar, et al. 2022. Holistic evaluation of language\nmodels. arXiv preprint arXiv:2211.09110.\nPeter Mayer, Collins W. Munyendo, Michelle L.\nMazurek, and Adam J. Aviv. 2022. Why users\n(don’t) use password managers at a large educational\ninstitution. In 31st USENIX Security Symposium\n(USENIX Security 22), pages 1849–1866, Boston,\nMA. USENIX Association.\nSewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe,\nMike Lewis, Hannaneh Hajishirzi, and Luke Zettle-\nmoyer. 2022. Rethinking the role of demonstrations:\nWhat makes in-context learning work? In EMNLP.\nOladapo Oyebode, Chinenye Ndulue, Ashfaq Adib, Di-\nnesh Mulchandani, Banuchitra Suruliraj, Fidelia An-\nulika Orji, Christine T Chambers, Sandra Meier, and\nRita Orji. 2021. Health, psychosocial, and social\nissues emanating from the covid-19 pandemic based\non social media comments: Text mining and thematic\nanalysis approach. JMIR Med Inform, 9(4):e22734.\nStefano De Paoli. 2023. Can large language mod-\nels emulate an inductive thematic analysis of semi-\nstructured interviews? an exploration and provoca-\ntion on the limits of the approach and the model.\nK Andrew R Richards and Michael A Hemphill. 2018.\nA practical guide to collaborative qualitative data\nanalysis. Journal of Teaching in Physical education,\n37(2):225–231.\nTim Rietz, Peyman Toreini, and Alexander Maedche.\n2020. Cody: An interactive machine learning sys-\ntem for qualitative coding. In Adjunct Proceedings\nof the 33rd Annual ACM Symposium on User Inter-\nface Software and Technology, UIST ’20 Adjunct,\npage 90–92, New York, NY , USA. Association for\nComputing Machinery.\nKatie Rose M Sanfilippo, Neta Spiro, Miguel Molina-\nSolana, and Alexandra Lamont. 2020. Do the shuffle:\nExploring reasons for music listening through shuf-\nfled play. PLoS One, 15(2):e0228457.\nTeven Le Scao, Angela Fan, Christopher Akiki, El-\nlie Pavlick, Suzana Ili ´c, Daniel Hesslow, Roman\nCastagné, Alexandra Sasha Luccioni, François Yvon,\nMatthias Gallé, et al. 2022. Bloom: A 176b-\nparameter open-access multilingual language model.\narXiv preprint arXiv:2211.05100.\nMirac Suzgun, Nathan Scales, Nathanael Schärli, Se-\nbastian Gehrmann, Yi Tay, Hyung Won Chung,\nAakanksha Chowdhery, Quoc V . Le, Ed H. Chi,\nDenny Zhou, and Jason Wei. 2022. Challenging\nbig-bench tasks and whether chain-of-thought can\nsolve them.\nRomal Thoppilan, Daniel De Freitas, Jamie Hall,\nNoam Shazeer, Apoorv Kulshreshtha, Heng-Tze\nCheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du,\nYaGuang Li, Hongrae Lee, Huaixiu Steven Zheng,\nAmin Ghafouri, Marcelo Menegali, Yanping Huang,\nMaxim Krikun, Dmitry Lepikhin, James Qin, Dehao\nChen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts,\nMaarten Bosma, Vincent Zhao, Yanqi Zhou, Chung-\nChing Chang, Igor Krivokon, Will Rusch, Marc\n9999\nPickett, Pranesh Srinivasan, Laichee Man, Kathleen\nMeier-Hellstern, Meredith Ringel Morris, Tulsee\nDoshi, Renelito Delos Santos, Toju Duke, Johnny So-\nraker, Ben Zevenbergen, Vinodkumar Prabhakaran,\nMark Diaz, Ben Hutchinson, Kristen Olson, Ale-\njandra Molina, Erin Hoffman-John, Josh Lee, Lora\nAroyo, Ravi Rajakumar, Alena Butryna, Matthew\nLamm, Viktoriya Kuzmina, Joe Fenton, Aaron Co-\nhen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-\nArcas, Claire Cui, Marian Croak, Ed Chi, and Quoc\nLe. 2022. Lamda: Language models for dialog appli-\ncations.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro,\nFaisal Azhar, et al. 2023. Llama: Open and effi-\ncient foundation language models. arXiv preprint\narXiv:2302.13971.\nMojtaba Vaismoradi, Jacqueline Jones, Hannele Tu-\nrunen, and Sherrill Snelgrove. 2016. Theme devel-\nopment in qualitative content analysis and thematic\nanalysis.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V Le,\nand Denny Zhou. 2022. Chain of thought prompt-\ning elicits reasoning in large language models. In\nAdvances in Neural Information Processing Systems.\nFrederick Joseph Wertz. 2011. Five ways of doing\nqualitative analysis: Phenomenological psychology,\ngrounded theory, discourse analysis, narrative re-\nsearch, and intuitive inquiry. Guilford Press.\nZhibiao Wu and Martha Palmer. 1994. Verbs semantics\nand lexical selection. In Proceedings of the 32nd\nAnnual Meeting on Association for Computational\nLinguistics, ACL ’94, page 133–138, USA. Associa-\ntion for Computational Linguistics.\nZiang Xiao, Xingdi Yuan, Q. Vera Liao, Rania Ab-\ndelghani, and Pierre-Yves Oudeyer. 2023. Support-\ning qualitative analysis with large language models:\nCombining codebook with GPT-3 for deductive cod-\ning. In 28th International Conference on Intelligent\nUser Interfaces. ACM.\nShunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak\nShafran, Karthik Narasimhan, and Yuan Cao. 2023.\nReAct: Synergizing reasoning and acting in language\nmodels. In International Conference on Learning\nRepresentations (ICLR).\nCaleb Ziems, William Held, Omar Shaikh, Jiaao Chen,\nZhehao Zhang, and Diyi Yang. 2023. Can large lan-\nguage models transform computational social sci-\nence?\nA Qualitative Research and Thematic\nAnalysis\nQualitative research, which uses techniques such as\ninterviews and open-ended survey questions to col-\nlect free-text responses (Wertz, 2011; Richards and\nHemphill, 2018), has been widely used to identify\npatterns of meanings and gain insight from partici-\npants via analysis of qualitative data. One common\nmethod for analyzing qualitative data is thematic\nanalysis (Braun and Clarke, 2006, 2012, 2019). For\nreliable coding, at least two human coders must\n1) become familiar with the data, 2) generate a\ncodebook, and 3) iteratively code the data until an\nacceptable inter-rater agreement level is reached.\nThus TA is labor-intensive and time-consuming.\nB Model and Parameters\nWe used OpenAI’s gpt-3.5-turbo-16k LLM as\nGPT outperforms other LLMs on various NLP\ntasks (Liang et al., 2022). Second, although\nGPT-4 is smarter than and superior to GPT-3.5,\nand the input context size of GPT-4 (32,768 for\ngpt-4-32k) is longer than that for GPT-3.5 (16,384\nfor gpt-3.5-turbo-16k), there are more con-\nstraints on GPT-4.6 For instance, the tokens per\nminute (TPM) limit for GPT-4 is 40,000, whereas\nthat for GPT-3.5 is 180,000 (gpt-3.5-turbo-16k).\nAlso, as GPT-4 is still in beta, not everyone can ac-\ncess it. Finally, GPT-3.5 remains a powerful LLM\ncompared to others, and it is cheaper.\nWe follow OpenAI’s default parameter settings\nexcept the temperature, which we set to 0 to ensure\nour study is reproducible. 0 indicates low output\nrandomness: hence the model is less creative.\nC Datasets\nMusic Shuffle (MS) This dataset facilitates re-\nsearch on salient aspects when people listen to mu-\nsic on their personal devices. The survey includes\nfour open-ended questions, and comprises 397 par-\nticipants. The authors combined all the responses\nof the four questions for TA.\nPassword Manager (PM) This is a record of\npassword manager usage and general password\nhabits at George Washington University (GWU).\nThe survey includes eight open-ended questions,\ncomprising 277 participants from GWU’s faculty,\nstaff, and student body. In the original study, one\ncoder coded all the responses and developed the\ncodebook. Later, another coder coded 20% of the\nresponses and calculated Cohen’s κ. Our selected\nsurvey questions has 280 responses (n= 280).\n6https://platform.openai.com/docs/guides/\nrate-limits/overview\n10000\nD Prompts\nPrompt: Initial Codes Generation\nTask: {The goal of the study}\nHere are examples for how to generate the codes. For each\nexample, you will see one response with the codes step by\nstep.\nThese responses are the answer of the question: {Survey\nQuestion}.\nEach generated code have the format: ’ quote ’ refers to\n/mentions ’ definition of the code ’. Therefore, we got a\ncode: ’ Code ’.\nExemplars: {4 to 8 exemplars}\nPrompt 1: The prompt for initial codes generation.\nPrompt: Code Grouping\nHere is the survey question: {Survey Question}\n{Initial Codes}\nPlease organize the codes into themes in JSON format.\nEnsure that each code belongs to only one theme. Assign\na name to each theme.\nIf there are any duplicate codes, please merge them into a\nsingle entry.\nThe expected output format should follow this structure:\n<Name of the theme>: <List of codes and their definition\nbelonging to the theme>\nPrompt 2: The prompt for grouping the codes.\nPrompt: Code Refinement\nHere is your version.\n{Themes proposed by the Machine Coder }\nHere is the revised version.\n{Revised Themes by the Human Coder }\n{Actions and Reasons by the Human Coder }\nWhat do you think?\nPlease generate the revised themes.\nPlease list the parts with which you agree and disagree and\nthe reason in JSON.\nPrompt 3: The prompt for discussion.\n10001"
}