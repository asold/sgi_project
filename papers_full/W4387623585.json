{
    "title": "Machine Translation as an Underrated Ingredient? Solving Classification Tasks with Large Language Models for Comparative Research",
    "url": "https://openalex.org/W4387623585",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2230497790",
            "name": "Ákos Máté",
            "affiliations": [
                "Centre for Social Sciences"
            ]
        },
        {
            "id": "https://openalex.org/A2542597578",
            "name": "Miklós Sebók",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A3198318220",
            "name": "Lukasz Wordliczek",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2285376604",
            "name": "Dariusz Stolicki",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2057960464",
            "name": "Ádám Feldmann",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4318067207",
        "https://openalex.org/W4200425490",
        "https://openalex.org/W2165698076",
        "https://openalex.org/W1821462560",
        "https://openalex.org/W4287867774",
        "https://openalex.org/W2015897410",
        "https://openalex.org/W3094423068",
        "https://openalex.org/W2939455697",
        "https://openalex.org/W3034879881",
        "https://openalex.org/W2130942839",
        "https://openalex.org/W2515855575",
        "https://openalex.org/W22861983",
        "https://openalex.org/W3215499059",
        "https://openalex.org/W2095655043",
        "https://openalex.org/W2980282514",
        "https://openalex.org/W1566289585",
        "https://openalex.org/W2963736842",
        "https://openalex.org/W2980708516",
        "https://openalex.org/W3035390927",
        "https://openalex.org/W2953300870",
        "https://openalex.org/W2789327660",
        "https://openalex.org/W2319803923",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W3159574466",
        "https://openalex.org/W2753354158",
        "https://openalex.org/W2126204609",
        "https://openalex.org/W2952638691",
        "https://openalex.org/W3102531321",
        "https://openalex.org/W2063306646",
        "https://openalex.org/W586888039",
        "https://openalex.org/W3173162544",
        "https://openalex.org/W3101913037",
        "https://openalex.org/W2133564696",
        "https://openalex.org/W2512924740",
        "https://openalex.org/W4200255763",
        "https://openalex.org/W3035032094",
        "https://openalex.org/W4383912341",
        "https://openalex.org/W3082928416",
        "https://openalex.org/W3193973912",
        "https://openalex.org/W2037604136",
        "https://openalex.org/W3125108001",
        "https://openalex.org/W3103677861",
        "https://openalex.org/W2032158738",
        "https://openalex.org/W4288089799",
        "https://openalex.org/W2950938254",
        "https://openalex.org/W2050841503",
        "https://openalex.org/W4248927742",
        "https://openalex.org/W2978017171",
        "https://openalex.org/W3168865595",
        "https://openalex.org/W3046484722",
        "https://openalex.org/W4293350112",
        "https://openalex.org/W2795986449",
        "https://openalex.org/W3195577433",
        "https://openalex.org/W3034824379",
        "https://openalex.org/W2101234009",
        "https://openalex.org/W3015468748",
        "https://openalex.org/W3001279689",
        "https://openalex.org/W2965373594",
        "https://openalex.org/W2157331557"
    ],
    "abstract": "While large language models have revolutionised computational text analysis methods, the field is still tilted towards English language resources. Even as there are pre-trained models for some \"smaller\" languages, the coverage is far from universal, and pre-training large language models is an expensive and complicated task. This uneven language coverage limits comparative social research in terms of its geographical and linguistic scope. We propose a solution that sidesteps these issues by leveraging transfer learning and open-source machine translation. We use English as a bridge language between Hungarian and Polish bills and laws to solve a classification task related to the Comparative Agendas Project (CAP) coding scheme. Using the Hungarian corpus as training data for model fine-tuning, we categorise the Polish laws into 20 CAP categories. In doing so, we compare the performance of Transformer-based deep learning models (monolinguals, such as BERT, and multilinguals such as XLM-RoBERTa) and machine learning algorithms (e.g., SVM). Results show that the fine-tuned large language models outperform the traditional supervised learning benchmarks but are themselves surpassed by the machine translation approach. Overall, the proposed solution demonstrates a viable option for applying a transfer learning framework for low-resource languages and achieving state-of-the-art results without requiring expensive pre-training.",
    "full_text": null
}