{
  "title": "Distillation Matters: Empowering Sequential Recommenders to Match the Performance of Large Language Models",
  "url": "https://openalex.org/W4396606321",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2132100124",
      "name": "Yu Cui",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2006442482",
      "name": "Feng Liu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2101269086",
      "name": "PengBo Wang",
      "affiliations": [
        "University of Electronic Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A2555354974",
      "name": "Bohao Wang",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2107027196",
      "name": "Heng Tang",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2100896176",
      "name": "Yi Wan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A754385464",
      "name": "Jun Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2109687789",
      "name": "Jiawei Chen",
      "affiliations": [
        "Zhejiang University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4386728933",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W3178835722",
    "https://openalex.org/W4310416255",
    "https://openalex.org/W3153906321",
    "https://openalex.org/W3092103025",
    "https://openalex.org/W4394973476",
    "https://openalex.org/W2783944588",
    "https://openalex.org/W3004127093",
    "https://openalex.org/W3105472188",
    "https://openalex.org/W4400531810",
    "https://openalex.org/W3034368386",
    "https://openalex.org/W3045200674",
    "https://openalex.org/W4367047145",
    "https://openalex.org/W4290944002",
    "https://openalex.org/W4392846385",
    "https://openalex.org/W6839053282",
    "https://openalex.org/W4396736140",
    "https://openalex.org/W3093502611",
    "https://openalex.org/W3172187472",
    "https://openalex.org/W2963367478",
    "https://openalex.org/W3208976105",
    "https://openalex.org/W2996931760",
    "https://openalex.org/W4387848745",
    "https://openalex.org/W4400525124",
    "https://openalex.org/W4396758737",
    "https://openalex.org/W4400531852",
    "https://openalex.org/W1968165559",
    "https://openalex.org/W6852797925",
    "https://openalex.org/W4396758712",
    "https://openalex.org/W3084798277",
    "https://openalex.org/W4392490033",
    "https://openalex.org/W2984100107",
    "https://openalex.org/W4400526723",
    "https://openalex.org/W2783272285",
    "https://openalex.org/W2808847742",
    "https://openalex.org/W4224325975",
    "https://openalex.org/W4396735686",
    "https://openalex.org/W4404545798",
    "https://openalex.org/W4396722619",
    "https://openalex.org/W4392367398",
    "https://openalex.org/W3133849783",
    "https://openalex.org/W4224325518",
    "https://openalex.org/W4384625746",
    "https://openalex.org/W2743289088",
    "https://openalex.org/W4312551924",
    "https://openalex.org/W4396723256",
    "https://openalex.org/W3093907268",
    "https://openalex.org/W4396734745"
  ],
  "abstract": "Owing to their powerful semantic reasoning capabilities, Large Language Models (LLMs) have been effectively utilized as recommenders, achieving impressive performance. However, the high inference latency of LLMs significantly restricts their practical deployment. To address this issue, this work investigates knowledge distillation from cumbersome LLM-based recommendation models to lightweight conventional sequential models. It encounters three challenges: 1) the teacher's knowledge may not always be reliable; 2) the capacity gap between the teacher and student makes it difficult for the student to assimilate the teacher's knowledge; 3) divergence in semantic space poses a challenge to distill the knowledge from embeddings. To tackle these challenges, this work proposes a novel distillation strategy, DLLM2Rec, specifically tailored for knowledge distillation from LLM-based recommendation models to conventional sequential models. DLLM2Rec comprises: 1) Importance-aware ranking distillation, which filters reliable and student-friendly knowledge by weighting instances according to teacher confidence and student-teacher consistency; 2) Collaborative embedding distillation integrates knowledge from teacher embeddings with collaborative signals mined from the data. Extensive experiments demonstrate the effectiveness of the proposed DLLM2Rec, boosting three typical sequential models with an average improvement of 47.97%, even enabling them to surpass LLM-based recommenders in some cases.",
  "full_text": "Distillation Matters: Empowering Sequential Recommenders\nto Match the Performance of Large Language Models\nYu Cui\nZhejiang University\nHangzhou, China\n12321228@zju.edu.cn\nFeng Liu\nOPPO Research Institute\nShenzhen, China\nliufeng4hit@gmail.com\nPengbo Wang\nUniversity of Electronic Science and\nTechnology of China\nChengdu, China\n2021080902021@std.uestc.edu.cn\nBohao Wang\nZhejiang University\nHangzhou, China\nbohao.wang@zju.edu.cn\nHeng Tang\nZhejiang University\nHangzhou, China\ntangheng23@zju.edu.cn\nYi Wan\nOPPO Research Institute\nShenzhen, China\nwanyi@oppo.com\nJun Wang\nOPPO Research Institute\nShenzhen, China\njunwang.lu@gmail.com\nJiawei Chenâˆ—\nZhejiang University\nThe State Key Laboratory of\nBlockchain and Data Security\nHangzhou, China\nsleepyhunt@zju.edu.cn\nABSTRACT\nOwing to their powerful semantic reasoning capabilities, Large\nLanguage Models (LLMs) have been effectively utilized as recom-\nmenders, achieving impressive performance. However, the high\ninference latency of LLMs significantly restricts their practical de-\nployment. To address this issue, this work investigates knowledge\ndistillation from cumbersome LLM-based recommendation mod-\nels to lightweight conventional sequential models. It encounters\nthree challenges: 1) the teacherâ€™s knowledge may not always be\nreliable; 2) the capacity gap between the teacher and student makes\nit difficult for the student to assimilate the teacherâ€™s knowledge;\n3) divergence in semantic space poses a challenge to distill the\nknowledge from embeddings.\nTo tackle these challenges, this work proposes a novel distilla-\ntion strategy, DLLM2Rec, specifically tailored for knowledge distil-\nlation from LLM-based recommendation models to conventional\nsequential models. DLLM2Rec comprises: 1)Importance-aware rank-\ning distillation , which filters reliable and student-friendly knowl-\nedge by weighting instances according to teacher confidence and\nstudent-teacher consistency; 2) Collaborative embedding distillation\nintegrates knowledge from teacher embeddings with collaborative\nsignals mined from the data. Extensive experiments demonstrate\nthe effectiveness of the proposed DLLM2Rec, boosting three typical\nâˆ—Corresponding author.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nRecSys â€™24, October 14â€“18, 2024, Bari, Italy\nÂ© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 979-8-4007-0505-2/24/10. . . $15.00\nhttps://doi.org/10.1145/3640457.3688118\nsequential models with an average improvement of 47.97%, even\nenabling them to surpass LLM-based recommenders in some cases.\nCCS CONCEPTS\nâ€¢ Information systems â†’Recommender systems.\nKEYWORDS\nSequential Recommendation, Large language Model, Knowledge\nDistillation\nACM Reference Format:\nYu Cui, Feng Liu, Pengbo Wang, Bohao Wang, Heng Tang, Yi Wan, Jun\nWang, and Jiawei Chen. 2024. Distillation Matters: Empowering Sequential\nRecommenders to Match the Performance of Large Language Models. In\n18th ACM Conference on Recommender Systems (RecSys â€™24), October 14â€“18,\n2024, Bari, Italy. ACM, New York, NY, USA, 11 pages. https://doi.org/10.\n1145/3640457.3688118\n1 INTRODUCTION\nLarge Language Models (LLMs) have showcased remarkable capabil-\nities in content comprehension, generation, and semantic reasoning\n[1, 5, 59]. Recently, LLMs have sparked a surge of interest within\nthe domain of Recommender Systems (RS). Various research efforts\nhave been devoted to harnessing LLMs to augment traditional rec-\nommendation models, serving as encoders for user/item features or\nas supplementary knowledge bases [23, 24, 49, 50]. To fully exploit\nthe reasoning ability of LLMs in RS, another line of research is\nto directly prompt or fine-tune LLMs to function as specialized\nrecommenders. Owing to their inherent semantic reasoning capa-\nbilities, these LLM-based recommendation methods have achieved\nimpressive performance. For instance, as shown in Table 1, the\nrepresentative model BIGRec [3] has demonstrated approximately\narXiv:2405.00338v3  [cs.IR]  20 Aug 2024\nRecSys â€™24, October 14â€“18, 2024, Bari, Italy Cui et al.\n41.44% improvements on average over the state-of-the-art conven-\ntional sequential model ( i.e., DROS [75]) on the typical Amazon\nGames and Toys datasets.\nDespite their effectiveness, LLM-based recommenders face se-\nrious inference inefficiency issues, posing substantial challenges\nto their practical applications. For example, as Table 1 shows, the\nwidely used LLaMA2-7B model requires an astonishing three hours\nto perform a single inference for tens of thousands of users with\n4x A800 GPUs. This inefficiency is exacerbated when scaling up\nto serve millions of users concurrently in practical industrial RS,\nwhere responses are required within seconds. This motivates a\ncrucial research question: how can we maintain low inference la-\ntency as conventional recommenders while leveraging the excellent\nperformance of LLM-based recommenders?\nTo tackle this challenge, we propose employing knowledge dis-\ntillation (KD) for acceleration â€” i.e., distilling the knowledge from\na complex LLM-based recommendation model (teacher) to a light-\nweight conventional recommendation model (student). KD has been\nsuccessfully applied in many domains [2, 8, 22], and has been proven\neffective in transferring knowledge from a large model to a smaller\none. This strategy could capitalize on the effectiveness of LLM-\nbased recommenders while maintaining low inference costs. It also\npotentially integrates the capabilities of conventional models in cap-\nturing collaborative signals with the semantic reasoning prowess\nof LLMs. While the ideal is promising, distillation is non-trivial due\nto the fundamentally different mechanisms between the teacher\nand student models. LLMs primarily rely on content understanding\nand capturing semantic correlations for making recommendations,\nwhereas conventional models depend on collaborative signals de-\nrived from usersâ€™ historical behaviors. This divergence introduces\nseveral challenges:\n1) Teacher Knowledge Reliability: LLM-based models may\nnot consistently outperform conventional models in all cases. Our\nempirical studies suggest that in over 30% of cases, a conventional\nmodel could even outperform an LLM-based model, indicating that\nthe knowledge from the teacher is not always reliable. Moreover,\nthe LLM may encounter the issue of notorious hallucination and\ngenerate poor recommendations.\n2) Model Capacity Gap: As demonstrated by recent work on KD\n[13], the substantial difference in model size often makes it difficult\nfor the student to assimilate the teacherâ€™s knowledge. Given the\nsimple architecture of the conventional models, they may struggle\nto fully inherit the semantic reasoning ability of the teacher, and\noverloading the student with teacher knowledge might impair its\nown ability in collaborative filtering.\n3) Semantic Space Divergence: Aligning embeddings for distil-\nlation, which has been demonstrated effective, presents significant\nchallenges for this problem. LLMs model users/items primarily\nbased on content, while conventional models derive users/items\nembeddings from collaborative signals. The vast semantic differ-\nences between these approaches mean that directly aligning their\nembeddings can be counterproductive, potentially disrupting the\nstudentâ€™s original embedding space and weakening its ability to\ncapture collaborative signals.\nTo tackle these challenges, we propose DLLM2Rec, designed to\neffectively distill knowledge from LLM-based recommenders to\nconventional recommenders. DLLM2Rec contains:\nTable 1: Recommendation performance and inference time-\ncost of BIGRec compared with DROS on Amazon Games\nand Toys datasets. Note that BIGRec is a typical LLM-based\nrecommender with LlaMA-7B and DROS is a state-of-the-art\nsequential recommendation method.\nDataset Model HR@20 NDCG@20 Inference time\nDROS 0.0473 0.0267 1.8s\nBIGRec 0.0532 0.0341 2.3 Ã—104ð‘ Games\nGain +12.47% +27.72% âˆ’1.3 Ã—106%\nDROS 0.0231 0.0144 1.6s\nBIGRec 0.0420 0.0207 1.1 Ã—104sToys\nGain +81.82% +43.75% âˆ’6.8 Ã—105%\n1) Importance-aware ranking distillation. Rather than di-\nrectly aligning the ranking lists between the teacher and student,\nwe highlight reliable and student-friendly instances for distillation\nby introducing importance weights. This approach evaluates the\nsemantic similarity between the responses given by LLMs and the\ntarget positive items, with less similarity indicating lower response\nquality and suggesting such instances should be downweighted in\ndistillation. Additionally, inspired by the â€œwisdom of the crowdâ€,\nwe leverage the model consistency between student and teacher to\nevaluate the importance of an instance, prioritizing instances where\ndiverse models agree on higher item rankings. Such instances are\nalso relatively easy and friendly to the student models, helping the\nstudent to assimilate the knowledge from the teacher.\n2) Collaborative embedding distillation. To bridge the se-\nmantic gap between the embedding spaces of the teacher and stu-\ndent, we employ a learnable projector (e.g., MLPs) to map original\nembeddings from teachers to the studentâ€™s embedding space. More-\nover, diverging from directly aligning the student embeddings with\nthe teacherâ€™s projected embeddings, we introduce a flexible offset\nterm that captures collaborative signals, further integrated with\nthe teacherâ€™s projected embeddings to generate enriched student\nembeddings. This design effectively leverages the knowledge from\nthe teacher while preserving its capacity to capture collaborative\nsignals.\nThe main contributions of our work are summarized as follows:\nâ€¢Highlighting the inference inefficiency issue of LLM-based rec-\nommendation model and advocating the use of knowledge distil-\nlation for acceleration.\nâ€¢Proposing DLLM2Rec which leverages importance-aware rank-\ning distillation and collaborative embedding distillation to trans-\nfer reliable and student-friendly knowledge from LLM-based\nmodels to conventional recommendation models.\nâ€¢Conducting extensive experiments to demonstrate the effective-\nness of DLLM2Rec, enabling lightweight conventional models to\nkeep pace with sophisticated LLM-based models.\n2 PRELIMINARIES\nIn this section, we elaborate on sequential recommendation, and\nintroduce BIGRec, a representative LLM-based recommender.\nDistillation Matters: Empowering Sequential Recommenders\nto Match the Performance of Large Language Models RecSys â€™24, October 14â€“18, 2024, Bari, Italy\n2.1 Sequential Recommendation\nThis work focuses on sequential recommendation, which has se-\ncured a pivotal role in various modern recommendation systems\nand attracted significant research interest. In a sequential recom-\nmender system with a user set Uand an item set I, a userâ€™s\nhistorical interactions can be organized in chronological order\nsð‘¡ð‘¢ = (ð‘–1,ð‘–2,...,ð‘– ð‘¡ âˆ’1)where ð‘–ð‘˜ âˆˆI represents the ð‘˜-th item that\nthe user ð‘¢ interacted with. We remark that in this paper we may\nshorten the notation sð‘¡ð‘¢ as s for clear presentation. The task of\nsequential recommendation is to predict the next item ð‘–ð‘¡ that the\nuser is likely to interact with.\nSequential Recommendation Model. Existing models in this\ndomain primarily adopt representation learning paradigms. These\nmethods first utilize an item encoder to map itemsâ€™ features ð‘¥ð‘– (e.g.,\nIDs, titles) into their representations eð‘– :\neð‘– = ItemEncoder(ð‘¥ð‘– ) (1)\nwhere ItemEncoder(.) can be implemented by various architectures,\ne.g., an embedding layer to encode item ID or BERT [14] to encode\nitem text.\nWith the item embeddings, user behaviors can be further en-\ncoded by a sequential encoder:\nes = SeqEncoder(Zs) (2)\nwhere Zs denotes the encoded item embedding sequence of s, i.e.,\nZs = (eð‘–1 ,eð‘–2 ,..., eð‘–ð‘¡âˆ’1 ). SeqEncoder(.) represents the sequence\nencoder and can be implemented by GRUs [21], Transformer [31],\nor other architectures.\nGiven the sequence and item embeddings, the final prediction\nË†ð‘¦sð‘– can be generated via the dot product [46] or MLPs [47], which is\nthen utilized to retrieve recommendations. Let ð‘–âˆ—s (shorten as ð‘–âˆ—) be\nthe ground-truth item of the sequences that the userð‘¢will interact\nwith at the next step, the model can be trained via various losses,\ne.g., binary cross-entropy [51]:\nLð‘Ÿ = âˆ’\nâˆ‘ï¸\nsâˆˆÎ“\n\u0012\nlog ðœŽ(Ë†ð‘¦sð‘–âˆ—)+\nâˆ‘ï¸\nð‘— âˆˆð‘‚âˆ’\nlog(1 âˆ’ðœŽ(Ë†ð‘¦sð‘— ))\n\u0013\n(3)\nwhere ðœŽ(.)denotes the Sigmoid function; Î“ denotes the set of se-\nquences used for model training; andð‘‚âˆ’denotes the set of sampled\nnegative items.\n2.2 Brief on BIGRec\nRecently LLM-based recommendation attracts great attention. Pre-\ndominantly, this body of work formulates the recommendation\ntask using natural language prompts and employs large language\nmodels to generate personalized recommendations [25]. This study\nsimply take the representative model BIGRec [3] for empirical anal-\nysis. The selection of BIGRec is justified not only by its availability\nas an open-source tool but also by its demonstrated effectiveness.\nFurthermore, BIGRec embodies the fundamental elements of LLM-\nbased recommendation and many methods can be considered as\nfurther extensions of such paradigm [ 54, 67]. It is also notewor-\nthy that BIGRec has been employed by recent studies [43, 44] as a\nrepresentative model for analysis.\nTo be specific, BIGRec organizes usersâ€™ historical behaviors in\nnatural language and employs instruction-tuning to fine-tune LLMs,\nTable 2: The ratio of cases where BIGRec outperforms DROS\nto cases where BIGRec underperforms DROS on NDCG@20.\nDataset Condition Relative Ratio\nBIGRec > DROS 53.90%Games BIGRec < DROS 46.10%\nBIGRec > DROS 40.90%MovieLens BIGRec < DROS 59.10%\nBIGRec > DROS 66.67%Toys BIGRec < DROS 33.33%\nas illustrated in Figure 1. During the inference stage, BIGRec gener-\nates item descriptions (e.g., titles) for recommendations. Consider-\ning that these descriptions may not always correspond to existing\nitems, BIGRec incorporates a grounding paradigm that matches\ngenerated item descriptions to existing items based on content sim-\nilarity. Formally, letzð‘”s and zð‘– represent the token embeddings of\ngenerated descriptions and the descriptions of item ð‘–, respectively.\nBIGRec computes their L2 distance for grounding as follows:\nð‘‘sð‘– = ||zð‘”s âˆ’zð‘– ||2 (4)\nBased on ð‘‘sð‘– , BIGRec ranks items and retrieve the K-nearest items\nas recommendations.\n3 METHODOLOGY\nIn this section, we first outline the challenges associated with dis-\ntilling knowledge from Large LLM-based recommendation models\nto conventional models (subsection 3.1). Following this, we delve\ninto the specifics of our proposed DLLM2Rec (subsections 3.2).\n3.1 Motivations\nIn this subsection, we aim to conduct a thorough analysis to eluci-\ndate the challenges of distillation, thereby motivating our proposed\nmethod. These challenges can be categorized into three aspects:\nTeacher Knowledge Reliability. By examining the recommen-\ndation results from a typical LLM-based model, BIGRec, and a state-\nof-the-art sequential model, DROS, on three real-world datasets,\nwe empirically discover that the LLM-based model may not consis-\ntently surpass the conventional model in all test cases. In fact, as\ndepicted in Table 2, BIGRec may underperform DROS in over 30%\nof cases across all three datasets. This observation implies that the\nteacherâ€™s knowledge may not always be reliable and could poten-\ntially be detrimental. The reliability of the teacherâ€™s knowledge in\ndistillation must be validated.\nModel Capacity Gap. Recent research suggests that the perfor-\nmance of a student model diminishes as the gap in size between\nthe teacher and student models increases [ 27]. This challenge is\neven more pronounced in our scenario, where the student model\ncomprises a million-level parameters while the teacher model has\nbillion-level parameters. Additionally, the teacher and student mod-\nels employ fundamentally different recommendation mechanisms.\nWe notice a significant discrepancy in their recommended items\nâ€” the average number of overlapped items in their Top-20 recom-\nmendations is less than 3.15% across the three datasets as shown in\nTable 3. It is implausible to expect the student to fully assimilate\nthe teacherâ€™s knowledge and fully inherit the teacherâ€™s ability on\nRecSys â€™24, October 14â€“18, 2024, Bari, Italy Cui et al.\nTable 3: Ratio of overlapped items in Top-20 recommenda-\ntions between BIGRec and DROS. Additionally, we present\nthe percentage of these items that are actual hits. For compar-\native analysis, we detail the values specific to items unique\nto either BIGRecâ€™s or DROSâ€™s recommendations.\nDataset Rec. Space Items Ratio Hit Items\nBIGRec only 96.01% 0.21%\nDROS only 96.01% 0.18% Games\nOverlapped 3.99% 1.61%\nBIGRec only 95.94% 0.19%\nDROS only 95.94% 0.35% MovieLens\nOverlapped 4.06% 2.16%\nBIGRec only 98.95% 0.17%\nDROS only 98.95% 0.08% Toys\nOverlapped 1.05% 3.74%\nsemantic reasoning. Overloading the student with the teacherâ€™s\nknowledge may even impair the studentâ€™s inherent capacity to cap-\nture collaborative signals. Our empirical study, as shown in Table 5,\ndemonstrates that existing knowledge distillation strategies usually\nyield limited improvements and can sometimes even be counter-\nproductive. Thus, the development of a distillation strategy that is\nfriendly to the student model is crucial.\nSemantic Space Divergence. It is noteworthy that LLM-based\nmodels characterize users/items mainly based on their contents,\nwhile conventional models derive users/items embeddings mainly\nfrom collaborative signals. It means the teacher and student adopt\nentirely different semantic frameworks. Blind alignment of their\nsemantic spaces for distillation could prove counterproductive. As\nobserved in Table 5, two representative knowledge distillation meth-\nods, Hint [2] and HTD [30], which distill through embeddings, often\nperform worse than the original student model without knowledge\ndistillation. While embedding distillation has proven effective in\nmany domains, it should be specifically designed for this task.\n3.2 Proposed Distillation Strategy: DLLM2Rec\nIn order to address the aforementioned challenges, this work pro-\nposes DLLM2Rec, with leveraging importance-aware ranking dis-\ntillation and collaborative embedding distillation.\n3.2.1 Importance-aware Ranking Distillation. This module builds\nupon the conventional ranking distillation [57] while additionally\nintroducing importance weights to emphasize reliable and student-\nfriendly instances. Specifically, we employ the following distillation\nloss:\nLð‘‘ = âˆ’\nâˆ‘ï¸\nsâˆˆÎ“\nâˆ‘ï¸\nð‘–âˆˆOð‘‡\nð‘¤sð‘– log ðœŽ(Ë†ð‘¦sð‘– ) (5)\nwhere Oð‘‡ denotes the Top-K recommendations returned by the\nteacher model, and ð‘¤ð‘ ð‘– denotes the distillation weight. In this work,\nwe choose ð¾ = 10 as a default value, but this can be tuned for\noptimal performance. The objective is straightforward â€” we select\nthe highly ranked items from the teacher as a positive to guide the\nlearning of the student, so that these candidate items can also be\nrecommended by the student. However, given that the teacherâ€™s\nrecommendations may not always be beneficial, we introduce an\nimportance weight that considers the following three aspects:\n1) Position-aware weights ð‘¤ð‘\nsð‘– . Inheriting from [57], ranking\npositions are also considered in DLLM2Rec. The motivation is from\nthe ranking alignment that we would like to push a candidate item\nhigher if the item also occupies a higher position in the teacherâ€™s\nranking list. Formally, we use:\nð‘¤ð‘\nsð‘– âˆexp(âˆ’ð‘Ÿð‘– /ð›½) (6)\nwhere ð‘Ÿð‘– denotes the position of item ð‘–in the ranking list returned\nby the teacher, and ð›½ is the hyperparameter adjusting the shape of\nthe weight distribution.\n2) Confidence-aware weights ð‘¤ð‘\nsð‘– . Given the importance of\nextracting reliable teacher knowledge, we leverage ð‘¤ð‘\nsð‘– to indicate\nreliability. Specifically, we measure the quality of descriptions gen-\nerated by LLMs by assessing the content distance between the\ngenerated descriptions and the content of the ground-truth item:\nð‘¤ð‘\nsð‘– âˆexp(âˆ’ð‘‘sð‘–âˆ—/ð›½)\nð‘‘sð‘–âˆ— = ||zð‘”s âˆ’zð‘–âˆ—||2 (7)\nwhere ð‘‘sð‘–âˆ—measures the embedding distance between the generated\nitem description zð‘”s and the target ground-truth item zð‘–âˆ—, where\nthe embeddings can be generated via LLMs encoder. A smaller dis-\ntance suggests a higher quality of the generated description as it\naligns more closely with the targets. Conversely, a larger gap sug-\ngests lower confidence, indicating that LLMs may risk generating\nincorrect or nonsensical information.\n3) Consistency-aware weights ð‘¤ð‘ \nsð‘– . Inspired by the â€œwisdom\nof the crowdâ€, we use model consistency between the student and\nteacher to assess the importance of an instance. As suggested by\nrecent work on bagging [ 15, 76], when diverse models reach a\nconsensus on one prediction, its reliability increases. In RS, our\nempirical studies (Table 3) also shows that the items that are con-\ncurrently recommended by teacher and student are more likely to\nbe positive. This insight allows us to formulate consistency-aware\nweights as follows:\nð‘¤ð‘œ\nsð‘– =\n\u001a 1, ð‘– âˆˆOð‘‡ âˆ©Oð‘†\n0, ð‘– âˆ‰ Oð‘‡ âˆ©Oð‘† (8)\nwhere Oð‘‡ and Oð‘† denote the sets of Top-K recommendation items\nreturned by the teacher and student, respectively. We assign higher\nweights to those overlapping items (i.e., ð‘– âˆˆOð‘‡ âˆ©Oð‘† ).\nAnother advantage for up-weighting those overlapped items is\nthat they are relatively easy and friendly for student learning. By\nexamining the gradient of the distillation loss:\nðœ•Lð‘‘\nðœ•Ë†ð‘¦sð‘–\n= ð‘¤sð‘–ðœŽ(âˆ’Ë†ð‘¦sð‘– ) (9)\nit is evident that instances with larger Ë†ð‘¦sð‘– , i.e., higher positions in\nthe student ranking lists, will have smaller gradient magnitudes.\nThis suggests that higher-ranked instances are more easily assim-\nilated by the student model, as the student does not require to\nmake extensive change. Upweighting these instances makes the\nknowledge distillation process more conducive to student learning.\nWe integrate these three aspects into the ranking distillation\nwith a simple linear combination:\nð‘¤sð‘– = ð›¾ð‘ Â·ð‘¤ð‘\nsð‘– +ð›¾ð‘ Â·ð‘¤ð‘\nsð‘– +ð›¾ð‘œ Â·ð‘¤ð‘œ\nsð‘– (10)\nDistillation Matters: Empowering Sequential Recommenders\nto Match the Performance of Large Language Models RecSys â€™24, October 14â€“18, 2024, Bari, Italy\n1 2 nâ€¦\nRanking \nPosition\nâ€¦0.9 0.7 0.3\nRanking \nConfidence\n0 0â€¦1.0\nRanking \nConsistency\nPrompt\nInteraction \nSequence\nâ€œNioh 3â€\nGrounding\nRecommendation Space\nLLM CF\nð’ŠðŸ\nð’Šð’ˆð’”\nð’ŠðŸ’\nEmbedding Space\nð’ŠðŸ\nð’ŠðŸ\nð’ŠðŸ’\nð’ŠðŸ\nTop-n Ranking List\nð’ŠðŸ ð’ŠðŸ â€¦ ð’ŠðŸ’\nRank:\nItem:\n1 2 nâ€¦\n1. â€œNioh 2â€\n2. â€œElden Ringâ€\n3. â€œDark Souls 3â€\nN. â€œBloodborneâ€Fine-tuned LLM\nTokenizer\nLLM-based Recommender\nCollaborative\nEmbedding Distillation\n+\nâ€¦\nEmbedding\nLayer\nSequential \nModel\nTop-N Ranking List\nImportance-aware\nRanking Distillation\nConventional Recommender\nGenerated\nDescriptions\nUser Embedding\nTop-N Ranking List\nSimilarity\n1. Item 129\n2. Item 542\n3. Item 217\nN. Item 826\nâ€¦\nPosition-aware Weights\nConfidence-aware Weights\nConsistency-aware Weights\nÃ—|  |\nÃ—|  |\nEmbedding Space\nOffset\nÃ—|  |\nMLP\nFigure 1: Illustration the proposed DLLM2Rec that distills the knowledge from the LLM-based recommenders to the conventional\nrecommenders, with leveraging importance-aware ranking distillation and collaborative embedding distillation.\nwhere ð›¾ð‘,ð›¾ð‘,ð›¾ð‘œ are hyperparameters balancing their contributions.\nThe ultimate objective of our DLLM2Rec is:\nL= Lð‘Ÿ +ðœ†ð‘‘ Lð‘‘ (11)\nwhere ðœ†ð‘‘ balances the contributions from the recommendation and\ndistillation losses.\nInterestingly, some recent work [34, 57] consider to up-weight\nthe instances which has larger ranking discrepancy between student\nand teacher. This strategy is ineffective in this task, as it would\nincrease the distillation unreliability and difficulty. Our DLLM2Rec\nadopts contrary strategy and would yield better performance as\ndemonstrated in our experiments.\n3.2.2 Collaborative Embedding Distillation. Embedding distillation\nhas proven effective in many domains, yet it requires careful design\nin this context, given that the teacher and student possess quite\ndifferent semantic spaces. To tackle this, we adopt a collaborative\nparadigm. Specifically, we first employ a learnable projector (e.g.,\nMLPs) to map original item embeddings from the teacher to the\nstudentâ€™s embedding space to bridge the semantic gap:\nzð‘\nð‘– = ð‘”(zð‘– ) (12)\nwhere zð‘– denotes the textual embedding of item ð‘–encoded by the\nLLM-based recommender; ð‘”(.)denotes a learnable projector func-\ntion, which can be implemented via MLPs.\nwe further introduce a flexible offset termbð‘– for each item, which\nis integrated with the teacherâ€™s projected embeddings to generate\nenriched student embeddings:\neð‘›ð‘’ð‘¤\nð‘– = ð‘“(zð‘\nð‘– ,bð‘– ) (13)\nwhere bð‘– is a learnable vector designed to capture the collaborative\nsignals from user behavior data. ð‘“(.)denotes a function combining\nthe distilled information from the teacher and the information\nmined from the data. ð‘“(.)can be implemented via various ways,\ne.g., concatenate, MLPs. In our experiments, we find that simple\nlinear combinations suffice to yield satisfactory performance. Such\ncollaborative approach allows our model to leverage the powerful\nknowledge from the teacher while preserving its capacity to capture\ncollaborative signals.\nRemarkably, the distilled student is as efficiency as the\noriginal one during the inference . It only requires to leverage\nLLMs in model training, while directly utilize the well-trained and\nempowered student model for online service.\n4 EXPERIMENTS\nOur experiments address the following research questions:\nâ€¢RQ1 : Does DLLM2Rec outperform existing distillation strate-\ngies? How does the empowered student model perform?\nâ€¢RQ2 : What are the impacts of different components of DLLM2Rec\non its performance?\nâ€¢RQ3 : How do hyperparameters influence DLLM2Rec?\n4.1 Experiment Settings\n4.1.1 Datasets. Three conventional datasets:Amazon Video Games ,\nMovieLens-10M, and Amazon Toys and Games were utilized in our\nexperiments 1,2 . These datasets include user behavior sequences\nand item content. For fair comparisons, we closely adhered to the\npreprocessing methods used in recent work [3, 75]. We organized\nthe interaction sequences in ascending order of timestamps to par-\ntition each dataset into training, validation, and testing sets with\nratios of 8:1:1. Given that MovieLens-10M contains an excessive\nnumber of sequences, which could not be processed by LLM-based\nrecommenders, we sampled 100,000 sequences for training and\n10,000 for testing, the sampling strategy also adopted by [3]. The\ndataset statistics are presented in Table 4.\n4.1.2 Baselines. The following strategies are compared:\n1https://jmcauley.ucsd.edu/data/amazon/\n2https://grouplens.org/datasets/movielens/10m/\nRecSys â€™24, October 14â€“18, 2024, Bari, Italy Cui et al.\nTable 4: Statistics of the datasets.\nDatasets Games MovieLens Toys\n#Users 55,223 69,878 19,412\n#Items 17,408 10,681 11,924\n#Interactions 497,577 1,320,000 167,597\nDensity 0.05176% 0.1769% 0.07241%\nKnowledge Distillation Strategies for Recommendation:\nHint [2], HTD [30] are two representative methods that distill\nknowledge through teacher embeddings; RD [57], CD [33], RRD\n[29], DCD [34] and UnKD [8] distill information from the teachersâ€™\nranking lists. Readers may refer to the related work for more details\nabout these strategies.\nLLM-enhanced Recommendation Methods: We selected KAR\n[70] and LLM-CF [54] for comparisons as they are open-sourced,\nclosely related, and state-of-the-art.KAR leverages LLMs as knowl-\nedge base to enhance the profile of users and items, while LLM-CF\nuses LLMs to generate a base of chains of thought, which are further\nretrieved to enhance sequential models.\nFor fair comparisons, we integrated these methods into three\nrepresentative sequential models: GRU4Rec [21], SASRec [31], and\nDROS [75], which are either well-known or state-of-the-art. For\nthe teacher model, we consistently used the LLM-based model\nBIGRec [3], due to its availability as an open-source tool and its\ndemonstrated effectiveness.\n4.1.3 Evaluation Metrics. We employed two widely-used metrics\nHR@K and NDCG@K to evaluate performance. Here we simply\nset K to 20 as recent work [20], and observed similar results with\nother choices of ð¾.\n4.1.4 Implementation Details. All methods are implemented with\nPyTorch and run on 4 Nvidia A800 GPUs. We set ð›½ = 1.0,ð›¾ð‘ =\n0.3,ð›¾ð‘ = 0.5,ð›¾ð‘œ = 0.1 across all datasets, as these settings were\nfound sufficient to generate good performance, although fine-tuning\ncould further enhance model performance. The influence of these\nhyperparameters on model performance is also presented in Figure\n2. Adam [32] was used as the optimizer with a tuned learning rate\nof 0.001, a batch size of 256, and weight decay tuned in {1e-4, 1e-5,\n1e-6, 1e-7, 0}, ðœ†ð‘‘ in {0.1, 0.2, ..., 1.0}. We set the embedding size to\n64 and the dropout ratio to 0.1. Our code is available on 3.\nFor all compared methods, we closely followed the settings sug-\ngested by their original papers. We also finely tuned their hyper-\nparameters to ensure their optimum. Specifically, for BIGRec, we\nimplemented it with LLaMA2 [59] as suggested by the authors.\n4.2 Performance Comparison (RQ1)\nThe overall experimental results are presented in Table 5.\nComparing with students. The improvements brought by\nDLLM2Rec are impressive, achieving an average improvement of\n47.97% over the original students across three datasets and two\nmetrics. Furthermore, these improvements are consistent under\nall conditions. These results clearly validate the effectiveness of\nDLLM2Rec in distilling useful knowledge from the teacher to en-\nhance the student models.\n3https://github.com/istarryn/DLLM2Rec\nComparing with exising KDs. DLLM2Rec consistently out-\nperformed all KD baselines across all datasets and metrics. This\nresult clearly validates the effectiveness of DLLM2Rec, with lever-\naging reliable and student-friendly distillation strategies. We also\nobserved that some KD methods, e.g., Hint and HTD, showed a\nnegative impact on recommendation performance compared to the\noriginal student model. This could be attributed to the large seman-\ntic gap between the teacher and student models. Additionally, some\nadvanced KD methods like UnKD, DCD, HTD, and RRD may be\ninferior to the basic RD in some scenarios. This could be attributed\nto these advanced KD methods adopting more complex distillation\nstrategies, increasing the difficulty for the student to digest the\nknowledge.\nComparing with exising LLM-enhanced methods. DLLM2Rec\nconsistently outperformed KAR and LLM-CF. This result validates\nthe effectiveness of our distillation paradigm. Compared with KAR\nand LLM-CF, our distillation strategy effectively leverages the pow-\nerful recommendation capabilities of LLMs and directly transfers\nthese merits to the student models. Compared with the Chain of\nThought (CoT) utilized by LLM-CF, our distillation strategy di-\nrectly utilizes the teacherâ€™s embeddings and recommendation re-\nsults, which could be more easily digested by the student models.\nComparing with the teacher. Table 6 shows the performance\nand efficiency comparison of the student model empowered by\nour DLLM2Rec with the teacher model BIGRec. To our surprise,\nthe empowered lightweight student can even surpass the complex\nteacher model using LLMs. This result can be attributed to our\ndesign â€” we target letting the student digest the knowledge from\nthe teacher while maintaining its own capacity to capture collab-\norative signals. Additionally, considering the inference efficiency,\nthe empowered student still maintains low inference latency, while\nthe BIGRec requires an unacceptably long inference time. This\nresult validates that our DLLM2Rec can indeed address a crucial\nproblemâ€”maintaining excellent performance akin to LLM-based\nrecommenders while ensuring low inference latency.\nBesides, we conducted additional experiments to determine the\nratio of overlapping items between the teacher and student mod-\nels. As shown in Table 7, the post-distillation student model can\neffectively assimilate the teacher knowledge. Furthermore, it is\nimportant to note that the post-distillation student model may\nnot entirely replicate the teacherâ€™s recommendations, given that\nthe potential unreliability of teacher knowledge and the inherent\nteacher-student capacity gap.\n4.3 Ablation Study (RQ2)\nWe conducted an ablation study on different datasets to study the\ncontributions of each component of DLLM2Rec. For the importance-\naware ranking distillation, we removed the entire component (ð‘¤/ð‘œ ð‘Žð‘™ð‘™ð‘Ÿ ),\nposition-aware weights ð‘¤ð‘\nsð‘– , confidence-aware weights ð‘¤ð‘\nsð‘– , and\nconsistency-aware weights ð‘¤ð‘œ\nsð‘– , respectively. The results are pre-\nsented in Table 8. For the collaborative embedding distillation, we\nremoved the entire component (ð‘¤/ð‘œ ð‘Žð‘™ð‘™ð‘’ ), the offset term, respec-\ntively, and tested the performance when replacing this module with\nexisting embedding distillation strategies including Hint and HTD.\nThe results are presented in Table 9.\nDistillation Matters: Empowering Sequential Recommenders\nto Match the Performance of Large Language Models RecSys â€™24, October 14â€“18, 2024, Bari, Italy\nTable 5: Performance comparisons of DLLM2Rec with existing KD methods and LLM-enhanced strategies. The best performance\nis bold while the runner-up is underlined. Gain.S denotes the improvement of DLLM2Rec over the student; while Gain.B\ndenotes the improvement of DLLM2Rec over the best baseline.\nBackbone Model Games MovieLens Toys\nHR@20 NDCG@20 HR@20 NDCG@20 HR@20 NDCG@20\nTeacher BIGRec 0.0532 0.0341 0.0541 0.0370 0.0420 0.0207\n+None 0.0305 0.0150 0.0608 0.0236 0.0172 0.0081\n+Hint 0.0284 0.0120 0.0646 0.0240 0.0128 0.0058\n+HTD 0.0299 0.0128 0.0578 0.0229 0.0155 0.0062\n+RD 0.0398 0.0177 0.0667 0.0254 0.0157 0.0076\n+CD 0.0306 0.0149 0.0699 0.0256 0.0126 0.0052\n+RRD 0.0359 0.0163 0.0657 0.0243 0.0215 0.0097\n+DCD 0.0427 0.0190 0.0666 0.0263 0.0262 0.0114\n+UnKD 0.0370 0.0170 0.0607 0.0226 0.0235 0.0114\nKAR 0.0307 0.0149 0.0603 0.0229 0.0184 0.0079\nLLM-CF 0.0393 0.0174 0.0677 0.0246 0.0132 0.0058\n+DLLM2Rec 0.0446 0.0205 0.0815 0.0308 0.0281 0.0118\nGain.S +46.17% +36.94% +34.05% +30.43% +63.88% +42.18%\nGRU4Rec\nGain.B +4.56% +7.64% +16.60% +16.80% +7.40% +1.27%\n+None 0.0346 0.0190 0.0626 0.0228 0.0207 0.0130\n+Hint 0.0358 0.0151 0.0576 0.0216 0.0242 0.0103\n+HTD 0.0343 0.0152 0.0569 0.0214 0.0209 0.0097\n+RD 0.0513 0.0225 0.0778 0.0310 0.0397 0.0164\n+CD 0.0396 0.0231 0.0712 0.0265 0.0232 0.0151\n+RRD 0.0479 0.0202 0.0633 0.0244 0.0325 0.0158\n+DCD 0.0455 0.0211 0.0723 0.0275 0.0375 0.0175\n+UnKD 0.0447 0.0219 0.0667 0.0247 0.0335 0.0174\nKAR 0.0381 0.0198 0.0565 0.0221 0.0215 0.0131\nLLM-CF 0.0559 0.0251 0.0837 0.0295 0.0335 0.0152\n+DLLM2Rec 0.0600 0.0262 0.0840 0.0323 0.0409 0.0177\nGain.S +73.55% +38.25% +34.19% +41.91% +97.68% +36.38%\nSASRec\nGain.B +7.36% +4.40% +0.36% +4.34% +3.02% +1.19%\n+None 0.0473 0.0267 0.0852 0.0363 0.0231 0.0144\n+Hint 0.0531 0.0240 0.0791 0.0306 0.0302 0.0135\n+HTD 0.0489 0.0238 0.0722 0.0289 0.0275 0.0137\n+RD 0.0585 0.0310 0.0950 0.0383 0.0424 0.0220\n+CD 0.0474 0.0270 0.0802 0.0336 0.0238 0.0156\n+RRD 0.0590 0.0293 0.0788 0.0338 0.0424 0.0212\n+DCD 0.0531 0.0273 0.0821 0.0348 0.0432 0.0211\n+UnKD 0.0448 0.0209 0.0728 0.0297 0.0375 0.0195\nKAR 0.0586 0.0318 0.0859 0.0352 0.0255 0.0156\nLLM-CF 0.0635 0.0293 0.0963 0.0351 0.0385 0.0178\n+DLLM2Rec 0.0751 0.0331 0.1063 0.0437 0.0463 0.0225\nGain.S +58.77% +23.90% +24.77% +20.41% +100.43% +56.35%\nDROS\nGain.B +18.27% +4.03% +10.38% +14.24% +7.07% +2.16%\nAs can be seen, both distillation components are important â€”\nremoving the importance-aware ranking distillation or the collabo-\nrative embedding distillation would result in performance drops.\nDelving deeper into the ranking distillation, we observe that de-\nveloping the confidence-aware and consistency-aware weights are\nindeed helpful. For embedding distillation, we observe that the\ndeveloped offset term is also important. More interestingly, by re-\nplacing the entire embedding distillation strategy with Hint and\nHTD, we observed quite poor performance. This could be attributed\nto the large semantic gap between the teacher and student models.\nBlindly aligning the embeddings may harm the modelâ€™s semantic\nspace. It could be even worse than directly inheriting the projected\nspace from the teacher.\n4.4 Hyperparameter Sensitivity (RQ3)\nFigure 2 illustrates performance of DLLM2Rec with different hyper-\nparameters (ðœ†ð‘‘,ð›¾ð‘,ð›¾ð‘,ð›¾ð‘œ ). While we observed some fluctuations,\nthe general trend is that the modelâ€™s performance would increase\nat the beginning and then drop as these parameters increase. This\nresult validates the effectiveness of the corresponding components\nthat each hyperparameter controls. But over-emphasizing one com-\nponent would incur performance drops as it relatively declines the\nRecSys â€™24, October 14â€“18, 2024, Bari, Italy Cui et al.\nTable 6: Performance and efficiency comparison of BIGRec\nand DLLM2Rec on different datasets.\nDataset Model HR@20 NDCG@20 Inference time\nGames\nBIGRec 0.0532 0.0341 2.3 Ã—104s\nDLLM2Rec 0.0751 0.0331 1.8s\nGain +37.41% -2.99% +1.3 Ã—106%\nMovieLens\nBIGRec 0.0541 0.0370 1.8 Ã—104s\nDLLM2Rec 0.1063 0.0437 1.7s\nGain +96.49% +18.18% +1.1 Ã—106%\nToys\nBIGRec 0.0420 0.0207 1.1 Ã—104s\nDLLM2Rec 0.0463 0.0225 1.6s\nGain +10.24% +8.70% +6.8 Ã—105%\nTable 7: Overlapping ratio on Top-20 items.\nDatasets Before-distillation Post-distillation\nGames 3.99% 10.88%\nMovieLens 4.06% 10.15%\nToys 1.05% 14.56%\nTable 8: Ablation Study on ranking distillation.\nDataset Model HR@20 NDCG@20\nGames\nw/o ð‘Žð‘™ð‘™ð‘Ÿ 0.0661 0.0301\nw/o ð‘¤ð‘\nsð‘– 0.0697 0.0301\nw/o ð‘¤ð‘\nsð‘– 0.0733 0.0300\nw/o ð‘¤ð‘œ\nsð‘– 0.0568 0.0311\nDLLM2Rec 0.0751 0.0331\nMovieLens\nw/o ð‘Žð‘™ð‘™ð‘Ÿ 0.0917 0.0364\nw/o ð‘¤ð‘\nsð‘– 0.1037 0.0429\nw/o ð‘¤ð‘\nsð‘– 0.0986 0.0398\nw/o ð‘¤ð‘œ\nsð‘– 0.1047 0.0430\nDLLM2Rec 0.1063 0.0437\nToys\nw/o ð‘Žð‘™ð‘™ð‘Ÿ 0.0386 0.0177\nw/o ð‘¤ð‘\nsð‘– 0.0406 0.0200\nw/o ð‘¤ð‘\nsð‘– 0.0430 0.0205\nw/o ð‘¤ð‘œ\nsð‘– 0.0445 0.0208\nDLLM2Rec 0.0463 0.0225\ncontribution from others. Finely tuning these hyperparameters for\nbest balance could achieve optimal performance.\n5 RELATED WORK\n5.1 LLMs for Recommendation System\nThere are primarily two approaches to utilizing LLMs in RS: LLMs\ndirectly as recommenders [3, 4, 36, 77] and LLMs enhancing con-\nventional recommenders [48, 70, 74].\nLLMs as recommenders. Initial efforts explored the zero-shot\ncapabilities of LLMs in recommendation by structuring the rec-\nommendation tasks as language prompts [17, 25, 45, 64, 68]. Sub-\nsequently, to adapt LLMs to recommendation tasks, instruction-\ntuning or fine-tuning has been widely adopted, showing promising\nresults [3, 4, 26, 36â€“39, 52, 62, 78, 79]. This research primarily fo-\ncuses on how to enhance LLMs to better suit recommendation\ntasks. For instance, some studies aim to minimize the semantic\nTable 9: Ablation Study on embedding distillation.\nDataset Model HR@20 NDCG@20\nGames\nw/o ð‘Žð‘™ð‘™ð‘’ 0.0649 0.0323\nw/o offset 0.0700 0.0298\nHint 0.0563 0.0244\nHTD 0.0568 0.0246\nDLLM2Rec 0.0751 0.0331\nMovieLens\nw/o ð‘Žð‘™ð‘™ð‘’ 0.0999 0.0420\nw/o offset 0.1061 0.0425\nHint 0.0861 0.0344\nHTD 0.0874 0.0341\nDLLM2Rec 0.1063 0.0437\nToys\nw/o ð‘Žð‘™ð‘™ð‘’ 0.0379 0.0194\nw/o offset 0.0405 0.0195\nHint 0.0358 0.0159\nHTD 0.0349 0.0157\nDLLM2Rec 0.0463 0.0225\nGamesMovieLensToys\nð€ð’… ðœ¸ð’‘ ðœ¸ð’„ ðœ¸ð’\n0.0290\n0.0310\n0.0330\n0 0.1 0.3 0.5 1\n0.0290\n0.0310\n0.0330\n0 0.1 0.3 0.5 1\n0.0410\n0.0430\n0.0450\n0 0.1 0.3 0.5 1\n0.0410\n0.0430\n0.0450\n0 0.1 0.3 0.5 1\n0.0290\n0.0310\n0.0330\n0 0.1 0.3 0.5 1\n0.0390\n0.0420\n0.0450\n0 0.1 0.3 0.5 1\n0.0180\n0.0200\n0.0220\n0 0.1 0.3 0.5 1\n0.0180\n0.0200\n0.0220\n0 0.1 0.3 0.5 1\n0.0160\n0.0190\n0.0220\n0 0.1 0.3 0.5 1\n0.0290\n0.0310\n0.0330\n0.1 0.3 0.5 0.8 1\n0.0400\n0.0420\n0.0440\n0.1 0.3 0.5 0.8 1\n0.0180\n0.0200\n0.0220\n0.1 0.3 0.5 0.8 1\nNDCG@20NDCG@20NDCG@20\nFigure 2: Sensitivity analysis w.r.t. ðœ†ð‘‘ , ð›¾ð‘ , ð›¾ð‘ and ð›¾ð‘œ .\ngap between recommendations and natural language [3, 6, 23, 28,\n40, 55, 66, 72, 81, 84], such as the approach taken by BIGRec [ 3],\nwhich uses a grounding strategy to map LLM descriptions to recom-\nmended items. Others focus on improving LLMsâ€™ ability to model\nlong-sequence interactions [18, 41, 82], identify noisy items [61]\nand some attempt to reduce training overhead [44]. While effective,\nthese methods often suffer from significant inference inefficiency,\nlimiting their practical application. Although some studies have\ntried to mitigate inference latency through pre-storage techniques\n[18] or knowledge distillation [ 67], the gain of [ 18] is generally\nmodest and [67] is utilized to distill a huge LLMs (e.g., GPT-115B)\nto a relatively smaller LLMs (e.g., Llama-7B). Even small Llama-7B\nis hard to deploy in practical.\nLLMs enhancing conventional recommenders. Existing meth-\nods mainly employ LLMs as supplementary knowledge bases [48,\n70, 74] or as encoders for users/items [50, 63, 69] to improve con-\nventional recommenders. For instance, KAR [70] utilizes LLMs as\nexternal knowledge bases to better profile users and items within\nthe recommender system. RLMRec [ 50] encodes user and item\nprofiles into semantic representations and aligns embeddings gen-\nerated by conventional models with those from LLMs; Wei et al. [69]\nexploit LLMs to uncover new relationships within graphs. However,\ncompared to direct LLM-based recommenders, these methods do\nnot fully leverage the semantic reasoning capabilities of LLMs for\nDistillation Matters: Empowering Sequential Recommenders\nto Match the Performance of Large Language Models RecSys â€™24, October 14â€“18, 2024, Bari, Italy\nmaking recommendations. CSRec [74] incorporates the common\nsense extracted from LLM to alleviate the data sparsity issue.\nTo capitalize on the reasoning ability of teachers, some efforts\nhave attempted to use chains of thought (CoT) data generated by\nLLMs to enhance conventional models [54, 67]. However, given the\nrelatively simple architecture of conventional models, it is notably\ndifficult for these systems to assimilate the complex knowledge\nfrom CoT data. Furthermore, CoT is typically used as a feature\nfor a sequence, indicating that CoT for a new sequence should\nbe produced during inference, which would be time-consuming.\nWhile some approaches attempt to retrieve similar CoT from other\nuser-item pairs [54], such approximations may hurt accuracy.\nDiffering from these methods, our distillation strategy capitalizes\non the superiority of LLMs as recommenders, transferring their ex-\nceptional recommendation capabilities to conventional models. Our\napproach involves direct distillation on embeddings and ranking\nlists, which are easily assimilated by conventional models without\nincurring additional computational overhead during inference.\n5.2 Sequential Recommendation\nSequential recommendation [7, 12, 35, 53, 71] takes into account\nthe sequence or order of interactions to predict what a user might\nprefer next. Existing Sequential RS use sequence generation models,\nsuch as RNNs [ 21] or Transformers [ 11, 31, 75], to model user\ninteraction sequences. For example, GRU4Rec [ 21] employs the\nGRU to handle session-based data, while Caser [56] uses CNN to\nmodel interaction data on multiple levels. SASRec [31] introduces\nattention mechanism to automatically learn the weights of different\ninteraction items, and DROS [ 75] leverage distributional robust\noptimization in sequential recommendation and achieves state-of-\nthe-art performance. Some other methods focus on the intrinsic\nbiases [9, 10, 42, 80] and distribution shifts [ 60] within RS. Most\ncurrent LLM for RS methods also adopt the setting of sequential\nrecommendation [3, 4]. The readers may refer to the excellent\nsurvey [16, 65] for more details.\n5.3 Knowledge Distillation in RS\nKnowledge distillation (KD) is a promising model compression tech-\nnique that transfers the knowledge from a large teacher model into\nthe target compact student model [19], and they have been widely\napplied in recommendation systems to reduce inference latency. RD\n[57] treated the top-N ranked items as positive for training a student\nmodel; CD [33] utilized soft labels to create positive and negative\ndistillation instances; Soft labels also considered by RRD [29] to cre-\nate the list-wise distillation loss function; DCD [34] built distillation\nloss on both user-side and item-side; UnKD [8] addresses popularity\nbias in distillation. The hidden knowledge among the middle layer\nof teachers are also considered in some methods. For example, Hint\n[22] and RRD [ 29] extracted knowledge of teachersâ€™ embedding\nvia Fitnet and expert network; HTD [30] distilled the topological\nknowledge with the relations in the teacher embedding space. Some\nresearcher also study to distill knowledge from a huge LLMs (e.g.,\nChatGPT) to a relatively smaller LLMs (e.g., LLaMA-7B) in the rec-\nommendation scenarios. Besides model compression, KD is also\nused to integrate knowledge among different models [58, 73, 83].\nFor example, some researchers [83] consider to integrate knowl-\nedge from multiply pre-trained models into the student. To the best\nof our knowledge, the study of distilling LLM-based recommenders\ninto conventional recommenders remains untouched.\n6 CONCLUSION\nThis work studies on distilling knowledge from LLM-based recom-\nmenders to conventional recommenders. The distillation encoun-\nters three challenges including potential unreliable teacher Knowl-\nedge, teacher-student capacity gap and semantic space divergence.\nTo tackle this problem, we propose DLLM2Rec with leveraging\nimportance-aware ranking distillation and collaborative embedding\ndistillation for reliable and student-friendly distillation process. Ex-\ntensive experiments demonstrate that DLLM2Rec can effectively\nenhance the performance of three typical lightweight conventional\nmodels, with an average improvement of 47.97%, enabling them to\nkeep pace with sophisticated LLM-based models.\nACKNOWLEDGMENTS\nThis work is supported by the National Natural Science Foundation\nof China (62372399) and the advanced computing resources pro-\nvided by the Supercomputing Center of Hangzhou City University.\nREFERENCES\n[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Floren-\ncia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal\nAnadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774\n(2023).\n[2] Romero Adriana, Ballas Nicolas, K Samira Ebrahimi, Chassang Antoine, Gatta\nCarlo, and Bengio Yoshua. 2015. Fitnets: Hints for thin deep nets. Proc. ICLR 2, 3\n(2015), 1.\n[3] Keqin Bao, Jizhi Zhang, Wenjie Wang, Yang Zhang, Zhengyi Yang, Yancheng\nLuo, Fuli Feng, Xiangnaan He, and Qi Tian. 2023. A bi-step grounding para-\ndigm for large language models in recommendation systems. arXiv preprint\narXiv:2308.08434 (2023).\n[4] Keqin Bao, Jizhi Zhang, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan\nHe. 2023. Tallrec: An effective and efficient tuning framework to align large\nlanguage model with recommendation. InProceedings of the 17th ACM Conference\non Recommender Systems . 1007â€“1014.\n[5] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,\nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot learners. Advances in neural\ninformation processing systems 33 (2020), 1877â€“1901.\n[6] Yuwei Cao, Nikhil Mehta, Xinyang Yi, Raghunandan Keshavan, Lukasz Heldt,\nLichan Hong, Ed H Chi, and Maheswaran Sathiamoorthy. 2024. Aligning\nLarge Language Models with Recommendation Knowledge. arXiv preprint\narXiv:2404.00245 (2024).\n[7] Jianxin Chang, Chen Gao, Yu Zheng, Yiqun Hui, Yanan Niu, Yang Song, Depeng\nJin, and Yong Li. 2021. Sequential recommendation with graph neural networks.\nIn Proceedings of the 44th international ACM SIGIR conference on research and\ndevelopment in information retrieval . 378â€“387.\n[8] Gang Chen, Jiawei Chen, Fuli Feng, Sheng Zhou, and Xiangnan He. 2023. Unbi-\nased knowledge distillation for recommendation. In Proceedings of the Sixteenth\nACM International Conference on Web Search and Data Mining . 976â€“984.\n[9] Jiawei Chen, Hande Dong, Yang Qiu, Xiangnan He, Xin Xin, Liang Chen, Guli\nLin, and Keping Yang. 2021. AutoDebias: Learning to debias for recommendation.\nIn Proceedings of the 44th International ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval . 21â€“30.\n[10] Jiawei Chen, Hande Dong, Xiang Wang, Fuli Feng, Meng Wang, and Xiangnan\nHe. 2023. Bias and debias in recommender system: A survey and future directions.\nACM Transactions on Information Systems 41, 3 (2023), 1â€“39.\n[11] Sirui Chen, Jiawei Chen, Sheng Zhou, Bohao Wang, Shen Han, Chanfei Su, Yuqing\nYuan, and Can Wang. 2024. SIGformer: Sign-aware Graph Transformer for\nRecommendation. In Proceedings of the 47th International ACM SIGIR Conference\non Research and Development in Information Retrieval . 1274â€“1284.\n[12] Xu Chen, Hongteng Xu, Yongfeng Zhang, Jiaxi Tang, Yixin Cao, Zheng Qin, and\nHongyuan Zha. 2018. Sequential recommendation with user memory networks.\nRecSys â€™24, October 14â€“18, 2024, Bari, Italy Cui et al.\nIn Proceedings of the eleventh ACM international conference on web search and\ndata mining . 108â€“116.\n[13] Jang Hyun Cho and Bharath Hariharan. 2019. On the efficacy of knowledge\ndistillation. In Proceedings of the IEEE/CVF international conference on computer\nvision. 4794â€“4802.\n[14] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert:\nPre-training of deep bidirectional transformers for language understanding.arXiv\npreprint arXiv:1810.04805 (2018).\n[15] Shangchen Du, Shan You, Xiaojie Li, Jianlong Wu, Fei Wang, Chen Qian, and\nChangshui Zhang. 2020. Agree to disagree: Adaptive ensemble knowledge dis-\ntillation in gradient space. advances in neural information processing systems 33\n(2020), 12345â€“12355.\n[16] Hui Fang, Danning Zhang, Yiheng Shu, and Guibing Guo. 2020. Deep learning\nfor sequential recommendation: Algorithms, influential factors, and evaluations.\nACM Transactions on Information Systems (TOIS) 39, 1 (2020), 1â€“42.\n[17] Yunfan Gao, Tao Sheng, Youlin Xiang, Yun Xiong, Haofen Wang, and Jiawei\nZhang. 2023. Chat-rec: Towards interactive and explainable llms-augmented\nrecommender system. arXiv preprint arXiv:2303.14524 (2023).\n[18] Binzong Geng, Zhaoxin Huan, Xiaolu Zhang, Yong He, Liang Zhang, Fajie Yuan,\nJun Zhou, and Linjian Mo. 2024. Breaking the length barrier: Llm-enhanced CTR\nprediction in long textual user behaviors. In Proceedings of the 47th International\nACM SIGIR Conference on Research and Development in Information Retrieval .\n2311â€“2315.\n[19] Jianping Gou, Baosheng Yu, Stephen J Maybank, and Dacheng Tao. 2021. Knowl-\nedge distillation: A survey. International Journal of Computer Vision 129, 6 (2021),\n1789â€“1819.\n[20] Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng\nWang. 2020. Lightgcn: Simplifying and powering graph convolution network for\nrecommendation. In Proceedings of the 43rd International ACM SIGIR conference\non research and development in Information Retrieval . 639â€“648.\n[21] BalÃ¡zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk.\n2015. Session-based recommendations with recurrent neural networks. arXiv\npreprint arXiv:1511.06939 (2015).\n[22] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015. Distilling the knowledge in\na neural network. arXiv preprint arXiv:1503.02531 (2015).\n[23] Yupeng Hou, Zhankui He, Julian McAuley, and Wayne Xin Zhao. 2023. Learning\nvector-quantized item representation for transferable sequential recommenders.\nIn Proceedings of the ACM Web Conference 2023 . 1162â€“1171.\n[24] Yupeng Hou, Shanlei Mu, Wayne Xin Zhao, Yaliang Li, Bolin Ding, and Ji-Rong\nWen. 2022. Towards universal sequence representation learning for recommender\nsystems. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Dis-\ncovery and Data Mining . 585â€“593.\n[25] Yupeng Hou, Junjie Zhang, Zihan Lin, Hongyu Lu, Ruobing Xie, Julian McAuley,\nand Wayne Xin Zhao. 2024. Large language models are zero-shot rankers for\nrecommender systems. In European Conference on Information Retrieval . Springer,\n364â€“381.\n[26] Zhiyu Hu, Yang Zhang, Minghao Xiao, Wenjie Wang, Fuli Feng, and Xiangnan\nHe. 2024. Exact and Efficient Unlearning for Large Language Model-based\nRecommendation. arXiv:2404.10327 [cs.IR]\n[27] Tao Huang, Shan You, Fei Wang, Chen Qian, and Chang Xu. 2022. Knowledge\ndistillation from a stronger teacher. Advances in Neural Information Processing\nSystems 35 (2022), 33716â€“33727.\n[28] Meng Jiang, Keqin Bao, Jizhi Zhang, Wenjie Wang, Zhengyi Yang, Fuli Feng,\nand Xiangnan He. 2024. Item-side Fairness of Large Language Model-based\nRecommendation System. In Proceedings of the ACM on Web Conference 2024 .\n4717â€“4726.\n[29] SeongKu Kang, Junyoung Hwang, Wonbin Kweon, and Hwanjo Yu. 2020. DE-RRD:\nA knowledge distillation framework for recommender system. In Proceedings of\nthe 29th ACM International Conference on Information & Knowledge Management .\n605â€“614.\n[30] SeongKu Kang, Junyoung Hwang, Wonbin Kweon, and Hwanjo Yu. 2021. Topol-\nogy distillation for recommender system. In Proceedings of the 27th ACM SIGKDD\nConference on Knowledge Discovery & Data Mining . 829â€“839.\n[31] Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recom-\nmendation. In 2018 IEEE international conference on data mining (ICDM) . IEEE,\n197â€“206.\n[32] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-\nmization. arXiv preprint arXiv:1412.6980 (2014).\n[33] Jae-woong Lee, Minjin Choi, Jongwuk Lee, and Hyunjung Shim. 2019. Collabora-\ntive distillation for top-N recommendation. In 2019 IEEE International Conference\non Data Mining (ICDM) . IEEE, 369â€“378.\n[34] Youngjune Lee and Kee-Eung Kim. 2021. Dual correction strategy for rank-\ning distillation in top-n recommender system. In Proceedings of the 30th ACM\nInternational Conference on Information & Knowledge Management . 3186â€“3190.\n[35] Jiacheng Li, Yujie Wang, and Julian McAuley. 2020. Time interval aware self-\nattention for sequential recommendation. In Proceedings of the 13th international\nconference on web search and data mining . 322â€“330.\n[36] Lei Li, Yongfeng Zhang, and Li Chen. 2023. Prompt distillation for efficient llm-\nbased recommendation. In Proceedings of the 32nd ACM International Conference\non Information and Knowledge Management . 1348â€“1357.\n[37] Weitao Li, Junkai Li, Weizhi Ma, and Yang Liu. 2024. Citation-Enhanced Genera-\ntion for LLM-based Chatbots. arXiv:2402.16063 [cs.CL]\n[38] Xinyi Li, Yongfeng Zhang, and Edward C Malthouse. 2023. Exploring fine-tuning\nchatgpt for news recommendation. arXiv preprint arXiv:2311.05850 (2023).\n[39] Zelong Li, Jianchao Ji, Yingqiang Ge, Wenyue Hua, and Yongfeng Zhang. 2024.\nPAP-REC: Personalized Automatic Prompt for Recommendation Language Model.\narXiv:2402.00284 [cs.IR]\n[40] Jiayi Liao, Sihang Li, Zhengyi Yang, Jiancan Wu, Yancheng Yuan, Xiang Wang,\nand Xiangnan He. 2024. Llara: Large language-recommendation assistant. In\nProceedings of the 47th International ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval . 1785â€“1795.\n[41] Jianghao Lin, Rong Shan, Chenxu Zhu, Kounianhua Du, Bo Chen, Shigang Quan,\nRuiming Tang, Yong Yu, and Weinan Zhang. 2024. Rella: Retrieval-enhanced\nlarge language models for lifelong sequential behavior comprehension in recom-\nmendation. In Proceedings of the ACM on Web Conference 2024 . 3497â€“3508.\n[42] Siyi Lin, Chongming Gao, Jiawei Chen, Sheng Zhou, Binbin Hu, and Can Wang.\n2024. How Do Recommendation Models Amplify Popularity Bias? An Analysis\nfrom the Spectral Perspective. arXiv preprint arXiv:2404.12008 (2024).\n[43] Xinyu Lin, Wenjie Wang, Yongqi Li, Fuli Feng, See-Kiong Ng, and Tat-Seng Chua.\n2023. A multi-facet paradigm to bridge large language model and recommenda-\ntion. arXiv preprint arXiv:2310.06491 (2023).\n[44] Xinyu Lin, Wenjie Wang, Yongqi Li, Shuo Yang, Fuli Feng, Yinwei Wei, and Tat-\nSeng Chua. 2024. Data-efficient Fine-tuning for LLM-based Recommendation.\nIn Proceedings of the 47th International ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval . 365â€“374.\n[45] Qijiong Liu, Nuo Chen, Tetsuya Sakai, and Xiao-Ming Wu. 2023. A first look at\nllm-powered generative news recommendation. arXiv preprint arXiv:2305.06566\n(2023).\n[46] Takeshi Ogita, Siegfried M Rump, and Shinâ€™ichi Oishi. 2005. Accurate sum and\ndot product. SIAM Journal on Scientific Computing 26, 6 (2005), 1955â€“1988.\n[47] Allan Pinkus. 1999. Approximation theory of the MLP model in neural networks.\nActa numerica 8 (1999), 143â€“195.\n[48] Jiarui Qin, Weiwen Liu, Ruiming Tang, Weinan Zhang, and Yong Yu. 2024. D2K:\nTurning Historical Data into Retrievable Knowledge for Recommender Systems.\narXiv preprint arXiv:2401.11478 (2024).\n[49] Shashank Rajput, Nikhil Mehta, Anima Singh, Raghunandan Hulikal Keshavan,\nTrung Vu, Lukasz Heldt, Lichan Hong, Yi Tay, Vinh Tran, Jonah Samost, et al.\n2024. Recommender systems with generative retrieval. Advances in Neural\nInformation Processing Systems 36 (2024).\n[50] Xubin Ren, Wei Wei, Lianghao Xia, Lixin Su, Suqi Cheng, Junfeng Wang, Dawei\nYin, and Chao Huang. 2024. Representation learning with large language models\nfor recommendation. In Proceedings of the ACM on Web Conference 2024 . 3464â€“\n3475.\n[51] Usha Ruby and Vamsidhar Yendapalli. 2020. Binary cross entropy with deep\nlearning technique for image classification. Int. J. Adv. Trends Comput. Sci. Eng 9,\n10 (2020).\n[52] Wentao Shi, Xiangnan He, Yang Zhang, Chongming Gao, Xinyue Li, Jizhi Zhang,\nQifan Wang, and Fuli Feng. 2024. Large Language Models are Learnable Planners\nfor Long-Term Recommendation. In Proceedings of the 47th International ACM\nSIGIR Conference on Research and Development in Information Retrieval . 1893â€“\n1903.\n[53] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang.\n2019. BERT4Rec: Sequential recommendation with bidirectional encoder rep-\nresentations from transformer. In Proceedings of the 28th ACM international\nconference on information and knowledge management . 1441â€“1450.\n[54] Zhongxiang Sun, Zihua Si, Xiaoxue Zang, Kai Zheng, Yang Song, Xiao Zhang,\nand Jun Xu. 2024. Large Language Models Enhanced Collaborative Filtering.\narXiv preprint arXiv:2403.17688 (2024).\n[55] Juntao Tan, Shuyuan Xu, Wenyue Hua, Yingqiang Ge, Zelong Li, and Yongfeng\nZhang. 2024. IDGenRec: LLM-RecSys Alignment with Textual ID Learning.\nIn Proceedings of the 47th International ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval . 355â€“364.\n[56] Jiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommenda-\ntion via convolutional sequence embedding. In Proceedings of the eleventh ACM\ninternational conference on web search and data mining . 565â€“573.\n[57] Jiaxi Tang and Ke Wang. 2018. Ranking distillation: Learning compact ranking\nmodels with high performance for recommender system. In Proceedings of the\n24th ACM SIGKDD international conference on knowledge discovery & data mining .\n2289â€“2298.\n[58] Ye Tao, Ying Li, Su Zhang, Zhirong Hou, and Zhonghai Wu. 2022. Revisiting graph\nbased social recommendation: A distillation enhanced social graph network. In\nProceedings of the ACM Web Conference 2022 . 2830â€“2838.\n[59] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yas-\nmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhos-\nale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv\nDistillation Matters: Empowering Sequential Recommenders\nto Match the Performance of Large Language Models RecSys â€™24, October 14â€“18, 2024, Bari, Italy\npreprint arXiv:2307.09288 (2023).\n[60] Bohao Wang, Jiawei Chen, Changdong Li, Sheng Zhou, Qihao Shi, Yang Gao, Yan\nFeng, Chun Chen, and Can Wang. 2024. Distributionally Robust Graph-based\nRecommendation System. In Proceedings of the ACM on Web Conference 2024 .\n3777â€“3788.\n[61] Bohao Wang, Feng Liu, Jiawei Chen, Yudi Wu, Xingyu Lou, Jun Wang, Yan Feng,\nChun Chen, and Can Wang. 2024. LLM4DSR: Leveraing Large Language Model for\nDenoising Sequential Recommendation. arXiv preprint arXiv:2408.08208 (2024).\n[62] Hangyu Wang, Jianghao Lin, Bo Chen, Yang Yang, Ruiming Tang, Weinan Zhang,\nand Yong Yu. 2024. Towards Efficient and Effective Unlearning of Large Language\nModels for Recommendation. arXiv:2403.03536 [cs.IR]\n[63] Hangyu Wang, Jianghao Lin, Xiangyang Li, Bo Chen, Chenxu Zhu, Ruiming\nTang, Weinan Zhang, and Yong Yu. 2023. ALT: Towards Fine-grained Alignment\nbetween Language and CTR Models for Click-Through Rate Prediction. arXiv\npreprint arXiv:2310.19453 (2023).\n[64] Lei Wang and Ee-Peng Lim. 2023. Zero-shot next-item recommendation using\nlarge pretrained language models. arXiv preprint arXiv:2304.03153 (2023).\n[65] Shoujin Wang, Liang Hu, Yan Wang, Longbing Cao, Quan Z Sheng, and Mehmet\nOrgun. 2019. Sequential recommender systems: challenges, progress and\nprospects. arXiv preprint arXiv:2001.04830 (2019).\n[66] Yidan Wang, Zhaochun Ren, Weiwei Sun, Jiyuan Yang, Zhixiang Liang, Xin Chen,\nRuobing Xie, Su Yan, Xu Zhang, Pengjie Ren, et al. 2024. Enhanced Generative\nRecommendation via Content and Collaboration Integration. arXiv preprint\narXiv:2403.18480 (2024).\n[67] Yuling Wang, Changxin Tian, Binbin Hu, Yanhua Yu, Ziqi Liu, Zhiqiang Zhang,\nJun Zhou, Liang Pang, and Xiao Wang. 2024. Can Small Language Models be\nGood Reasoners for Sequential Recommendation?. In Proceedings of the ACM on\nWeb Conference 2024 . 3876â€“3887.\n[68] Zhefan Wang, Weizhi Ma, and Min Zhang. 2024. To Recommend or Not: Recom-\nmendability Identification in Conversations with Pre-trained Language Models.\narXiv:2403.18628 [cs.IR]\n[69] Wei Wei, Xubin Ren, Jiabin Tang, Qinyong Wang, Lixin Su, Suqi Cheng, Jun-\nfeng Wang, Dawei Yin, and Chao Huang. 2024. Llmrec: Large language models\nwith graph augmentation for recommendation. In Proceedings of the 17th ACM\nInternational Conference on Web Search and Data Mining . 806â€“815.\n[70] Yunjia Xi, Weiwen Liu, Jianghao Lin, Jieming Zhu, Bo Chen, Ruiming Tang,\nWeinan Zhang, Rui Zhang, and Yong Yu. 2023. Towards open-world recommen-\ndation with knowledge augmentation from large language models.arXiv preprint\narXiv:2306.10933 (2023).\n[71] Xu Xie, Fei Sun, Zhaoyang Liu, Shiwen Wu, Jinyang Gao, Jiandong Zhang, Bolin\nDing, and Bin Cui. 2022. Contrastive learning for sequential recommendation. In\n2022 IEEE 38th international conference on data engineering (ICDE) . IEEE, 1259â€“\n1273.\n[72] Wentao Xu, Qianqian Xie, Shuo Yang, Jiangxia Cao, and Shuchao Pang. 2024.\nEnhancing Content-based Recommendation via Large Language Model. arXiv\npreprint arXiv:2404.00236 (2024).\n[73] Zixuan Xu, Penghui Wei, Weimin Zhang, Shaoguo Liu, Liang Wang, and Bo Zheng.\n2022. Ukd: Debiasing conversion rate estimation via uncertainty-regularized\nknowledge distillation. In Proceedings of the ACM Web Conference 2022 . 2078â€“\n2087.\n[74] Shenghao Yang, Weizhi Ma, Peijie Sun, Min Zhang, Qingyao Ai, Yiqun Liu, and\nMingchen Cai. 2024. Common Sense Enhanced Knowledge-based Recommenda-\ntion with Large Language Model. arXiv preprint arXiv:2403.18325 (2024).\n[75] Zhengyi Yang, Xiangnan He, Jizhi Zhang, Jiancan Wu, Xin Xin, Jiawei Chen, and\nXiang Wang. 2023. A generic learning framework for sequential recommenda-\ntion with distribution shifts. In Proceedings of the 46th International ACM SIGIR\nConference on Research and Development in Information Retrieval . 331â€“340.\n[76] Shan You, Chang Xu, Chao Xu, and Dacheng Tao. 2017. Learning from multiple\nteacher networks. InProceedings of the 23rd ACM SIGKDD international conference\non knowledge discovery and data mining . 1285â€“1294.\n[77] Jizhi Zhang, Keqin Bao, Wenjie Wang, Yang Zhang, Wentao Shi, Wanhong Xu,\nFuli Feng, and Tat-Seng Chua. 2024. Prospect Personalized Recommendation on\nLarge Language Model-based Agent Platform. arXiv:2402.18240 [cs.IR]\n[78] Junjie Zhang, Ruobing Xie, Yupeng Hou, Wayne Xin Zhao, Leyu Lin, and Ji-Rong\nWen. 2023. Recommendation as instruction following: A large language model\nempowered recommendation approach. arXiv preprint arXiv:2305.07001 (2023).\n[79] Wenlin Zhang, Xiangyang Li, Yuhao Wang, Kuicai Dong, Yichao Wang, Xinyi\nDai, Xiangyu Zhao, Huifeng Guo, Ruiming Tang, et al. 2024. Tired of Plugins?\nLarge Language Models Can Be End-To-End Recommenders. arXiv preprint\narXiv:2404.00702 (2024).\n[80] Zihao Zhao, Jiawei Chen, Sheng Zhou, Xiangnan He, Xuezhi Cao, Fuzheng Zhang,\nand Wei Wu. 2022. Popularity bias is not always evil: Disentangling benign and\nharmful bias for recommendation. IEEE Transactions on Knowledge and Data\nEngineering 35, 10 (2022), 9920â€“9931.\n[81] Bowen Zheng, Yupeng Hou, Hongyu Lu, Yu Chen, Wayne Xin Zhao, and Ji-\nRong Wen. 2023. Adapting large language models by integrating collaborative\nsemantics for recommendation. arXiv preprint arXiv:2311.09049 (2023).\n[82] Zhi Zheng, Wenshuo Chao, Zhaopeng Qiu, Hengshu Zhu, and Hui Xiong. 2024.\nHarnessing large language models for text-rich sequential recommendation. In\nProceedings of the ACM on Web Conference 2024 . 3207â€“3216.\n[83] Jieming Zhu, Jinyang Liu, Weiqi Li, Jincai Lai, Xiuqiang He, Liang Chen, and\nZibin Zheng. 2020. Ensembled CTR prediction via knowledge distillation. In\nProceedings of the 29th ACM International Conference on Information & Knowledge\nManagement. 2941â€“2958.\n[84] Yaochen Zhu, Liang Wu, Qi Guo, Liangjie Hong, and Jundong Li. 2024. Collab-\norative large language model for recommender systems. In Proceedings of the\nACM on Web Conference 2024 . 3162â€“3172.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.5741389989852905
    },
    {
      "name": "Language model",
      "score": 0.5492704510688782
    },
    {
      "name": "Distillation",
      "score": 0.5370937585830688
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3594120144844055
    },
    {
      "name": "Natural language processing",
      "score": 0.3549966812133789
    },
    {
      "name": "Chemistry",
      "score": 0.13724097609519958
    },
    {
      "name": "Chromatography",
      "score": 0.11481711268424988
    }
  ],
  "institutions": []
}