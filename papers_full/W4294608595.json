{
  "title": "An Ensemble of Arabic Transformer-based Models for Arabic Sentiment Analysis",
  "url": "https://openalex.org/W4294608595",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5051844529",
      "name": "Ikram El Karfi",
      "affiliations": [
        "Mohammed V University"
      ]
    },
    {
      "id": "https://openalex.org/A5073155664",
      "name": "Sanaa El Fkihi",
      "affiliations": [
        "Mohammed V University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2345922844",
    "https://openalex.org/W2621199241",
    "https://openalex.org/W2407132801",
    "https://openalex.org/W3033291431",
    "https://openalex.org/W2968098022",
    "https://openalex.org/W6769318315",
    "https://openalex.org/W3199422761",
    "https://openalex.org/W4281756552",
    "https://openalex.org/W3200511119",
    "https://openalex.org/W3135298183",
    "https://openalex.org/W4287548279",
    "https://openalex.org/W3133440961",
    "https://openalex.org/W3008110149",
    "https://openalex.org/W3106433641",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2901922204",
    "https://openalex.org/W2250594687",
    "https://openalex.org/W2964323432",
    "https://openalex.org/W2575929989",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W4287824654",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W6931450662",
    "https://openalex.org/W3035390927",
    "https://openalex.org/W6843858628",
    "https://openalex.org/W2970814728",
    "https://openalex.org/W2043287290",
    "https://openalex.org/W2574075017",
    "https://openalex.org/W2250522473",
    "https://openalex.org/W2947201856",
    "https://openalex.org/W2982567551",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4287285119",
    "https://openalex.org/W4297663785",
    "https://openalex.org/W3116641301"
  ],
  "abstract": "In recent years, sentiment analysis has gained momentum as a research area. This task aims at identifying the opinion that is expressed in a subjective statement. An opinion is a subjective expression describing personal thoughts and feelings. These thoughts and feelings can be assigned with a certain sentiment. The most studied sentiments are positive, negative, and neutral. Since the introduction of attention mechanism in machine learning, sentiment analysis techniques have evolved from recurrent neural networks to transformer models. Transformer-based models are encoder-decoder systems with attention. Attention mechanism has permitted models to consider only relevant parts of a given sequence. Making use of this feature in encoder-decoder architecture has impacted the performance of transformer models in several natural language processing tasks, including sentiment analysis. A significant number of Arabic transformer-based models have been pre-trained recently to perform Arabic sentiment analysis tasks. Most of these models are implemented based on Bidirectional Encoder Representations from Transformers (BERT) such as AraBERT, CAMeLBERT, Arabic ALBERT and GigaBERT. Recent studies have confirmed the effectiveness of this type of models in Arabic sentiment analysis. Thus, in this work, two transformer-based models, namely AraBERT and CAMeLBERT have been experimented. Furthermore, an ensemble model has been implemented to achieve more reasonable performance.",
  "full_text": "(IJACSA) International Journal of Advanced Computer Science and Applications, \nVol. 13, No. 8, 2022 \n561 | P a g e  \nwww.ijacsa.thesai.org \nAn Ensemble of Arabic Transformer-based Models \nfor Arabic Sentiment Analysis \nIkram El Karfi, Sanaa El Fkihi \nENSIAS, Mohammed V University, Rabat, Morocco \n \n \nAbstract—In recent years, sentiment analysis has gained \nmomentum as a research area. This task  aims at identifying the \nopinion that is expressed in a subjective statement. An opinion is \na subjective expression describing personal thoughts and feelings. \nThese thoughts and feelings can be assigned with a certain \nsentiment. The most studied sentiments  are positive, negative, \nand neutral. Since the introduction of attention mechanism in \nmachine learning, sentiment analysis techniques have evolved \nfrom recurrent neural networks to transformer models. \nTransformer-based models are encoder -decoder systems w ith \nattention. Attention mechanism has permitted models to consider \nonly relevant parts of a given sequence. Making use of this \nfeature in encoder -decoder architecture has impacted the \nperformance of transformer models in several natural language \nprocessing tasks, including sentiment analysis. A significant \nnumber of Arabic transformer -based models have been pre -\ntrained recently to perform Arabic sentiment analysis tasks . \nMost of these models are implemented based on Bidirectional \nEncoder Representations fr om Transformers (BERT)  such as \nAraBERT, CAMeLBERT,  Arabic ALBERT  and GigaBERT. \nRecent studies have confirmed the effectiveness of this type of \nmodels in Arabic sentiment analysis. Thus, in this work, two \ntransformer-based models, namely AraBERT and CAMeLBE RT \nhave been experimented. Furthermore, an ensemble model has \nbeen implemented to achieve more reasonable performance. \nKeywords—Transformers; BERT; ensemble learning ; Arabic \nsentiment analysis \nI. INTRODUCTION \nGiven the tremendous amounts of Arabic digital content \nthat has been produced in the last couple of years, an increasing \nnumber of research works have been devoted to the automatic \nprocessing of this language. In this regard, different techniques \nhave been used to classify a specific text. Many studies have \naddressed this task by making use of basic machine learning \nmodels such as Naïve Bayes (NB) and Support Vector \nMachine (SVM). The authors in [1] addressed Arabic text \nclassification using SVM a nd NB combined with the N -gram \nfeature. The best accuracy of SVM was achieved without the \nN-gram, as for NB the best accuracy was achieved when the N-\ngram feature was considered.  Whereas the authors in  [2] \nintroduced their Arab ic Jordanian twitter corpus, then \nevaluated N-grams and stemming techniques together with TF-\nIDF or TF weighting schemes. Experiments have been carried \nout by making use of SVM and NB. Results showed that \ntraining SVM model on top of stems and bigrams usin g TF -\nIDF could give better performance compared to NB model. In \na similar work [3], the authors performed sentiment analysis on \nArabizi text which is Arabic text written in Latin alphabets. For \nexperimentation purposes, the authors used NB and SVM \nclassifiers. Besides, they evaluated the filtering step, which \nconsists of removing stop words and mapping emojis to their \ncorresponding Arabic words. Results indicated that SVM \nmodel outperformed NB model. However, filtering step did not \ngreatly improve the accuracy. \nRecently deep learning models such as Convolutional \nNeural Network (CNN) and Long Short -Term Memory \n(LSTM) have proven to be efficient for analyzing Arabic \ncontent. Many researchers have relied on deep learning models \nto tackle  Arabic sentiment analysis task. In [4] performed a \nbinary sentiment classification in Arabic. Initially, they applied \npreprocessing to clean input texts. Next, a wo rd embedding \nlayer has been used to represent texts as numerical vectors to \nbe fed to the LSTM layer. Finally, a SoftMax layer followed to \npredict the polarity of the text. The experiments showed quite \ngood results with an accuracy ranging from 80% to 82%.  In \nanother work [5] the authors made an empirical comparison \nbetween deep l earning models (LSTM, CNN) and other \nmachine learning models for both binary and multiclass \nclassification using different datasets. The paper showed that \ndeep learning models are effective for larger datasets. In \ncontrast, basic machine learning algorithm s perform well on \nsmaller datasets. \nMore recently, with the increasing popularity of \ntransformer models, sentiment analysis task has been \nsignificantly improved in terms of performance. Transformer \nmodels have replaced deep learning models and achieved state-\nof-the-art results on many automatic language processing tasks \nsuch as sentiment analysis [6], named ent ity recognition [7], \nquestion answering [8], and many other tasks. \nThe ineffectiveness of the existing methods  performing \nsentiment analysis in Arabic is the main motivation for \nproposing a transfor mer-based ensemble method.  In the last \nfew years transformer language models alone led to significant \nimprovements in sentiment analysis. Hence, making use of the \nadvantages of this type of models to investigate more reliable \napproaches is indeed necessary to tackle sentiment  analysis in \nArabic being a morphologically rich language. In this paper, \nwe propose an ensemble model that combines the strengths of \ntwo transformer language models. \nMany different disciplines have made significant use of \nensemble approaches to address text classification. However, \nthere is relatively few studies on the use of ensemble methods \nin Arabic sentiment analysis. The primary goal in this paper is \nto propose an ensemble model that combines two base \ntransformer models namely AraBERT and CAMeLBERT into \na single model. To the best of our knowl edge this is the first \n(IJACSA) International Journal of Advanced Computer Science and Applications, \nVol. 13, No. 8, 2022 \n562 | P a g e  \nwww.ijacsa.thesai.org \nstudy that investigates the ensemble of transformer-based \nmodels in  Arabic sentime nt analysis. Experimental results \ndemonstrate that the proposed ensemble method outperforms \nstand-alone classifiers and majority voting ensemble model. \nThe rest of this paper is structured as follows . Related \nworks will be introduced in Section II. The overall proposed \nmethodology will be discussed in Section III. Experiments and \nresults are given in Section IV. Then conclusions are drawn in \nSection V. \nII. RELATED WORK \nGiven the effectiveness of transformer-based models, there \nhave been various transformer models used in Arabic \nsentiment analysis. The widely utilized models are \nMultilingual BERT, AraBERT, and MARBERT [9]. The \nauthor in [10] addressed sentiment analysis in Modern \nStandard Arabic (MSA) and other Arabic dialects such as \nLevantine, Egyptian, and Gulf. The author opted for three-way \nclassification according to three scales (positive, neutral, and \nnegative) and using different algorithms, namely: Naive Bayes \nclassifiers (NB), Support Vector Machine (SVM), Random \nForest Classifier, and BERT model (Bidirectional Encoder \nRepresentations from Transformers). The best re sults are \nobtained with BERT model reaching an accuracy score of more \nthan 83%. The author in [11] addressed sarcasm and sentiment \ndetection using two variants of transformer -based models, \nnamely AraELECTRA and AraBERT. Evaluation results \nshowed that AraBERT perform s the best in terms of accuracy \nfor both sarcasm and sentiment detection. In a similar work, \n[12] addressed the same tasks: sarcasm detection and sentiment \nanalysis. The authors h ave examined six BERT -based models \nincluding: MARBERT [13], QARiB [14], AraBERTv02 [15], \nGigaBERTv3 [16], Arabic BERT [17], and mBERT [18]. \nMARBERT achieved promising results for both tasks. \nSeveral studies in the literature investigated ensemble \nmethods in Arabic sentiments analysis. The authors in [19] \ninvestigated different deep learning models to improve Arabic \nsentiment analysis accuracy. The authors proposed an \nensemble model combining a Convolutional Neu ral Network \n(CNN) model and a Long Short -Term Memory (LSTM) \nmodel. To evaluate their model, they used the ASTD dataset  \n[20] which consists of 10000 tweets. In this work, they focused \nonly on opinion classification, hence the objective class tweets \nwere removed. To construct their ensemble model, they \nexperimented different CNN models and LSTM models with \ndifferent hyper -parameters. The best CNN model is obtained \nby configuring the parameter fully connected layer size to 100. \nAs for LSTM, the best model is obtained by using a dropout \nrate of 0.2, based on the best CNN model and the best LSTM \nmodel they built an ensemble model where the final predicted \nclass is obtained using soft voting. Results show that the \nensemble model achieved better results in terms of accuracy \nand F1 -score compared to LSTM model and CNN model.  In \nanother study [21] , t he authors  introduced their approach to \naddress three SemEval related sentiment analysis subtasks in \nArabic. First Subtask (A) address es Message Polarity \nClassification, then Subtask (B) address es Topic-Based \nMessage Polarity Classification, finally Subtask (D) which \naddresses Tweet quantification. The authors proposed two \nsystems, the first is developed using their previous proposed \nsentiment analyzer [22] based on a scored lexicon. The second \nsystem is an ensemble of three different classifiers namely \nConvolutional Neural Network using Word2 vec, Multilayer \nPerceptron and Logistic Regression. Using voting between the \nthree classifiers the authors determined the final outcome. \nEvaluation results showed that their systems outperformed all \nthe other systems by achieving an accuracy of 0.58 and 0.77 on \nSubtask A and Subtask B respectively, as for Subtask D their \nsystem outperformed the other systems as well by achieving \n0.127 in terms of KLD score. \nIt seems clear that none of the existing ensemble methods \nhas addressed Arabic sentiment analysis by making use of \ntransformer language models. Accordingly, this study will be \nfocusing on investigating the use of transformer language \nmodels in Arabic sentiment classification as well as proposing \nan ensemble technique  based on transformer models  to \nenhance classification accuracy. \nIII. PROPOSED METHODOLOGY \nThis section presents the methodology proposed in this \npaper. We will be  discussing the background of transformer -\nbased models and the models adopted in this work. Then, \ndescribe the proposed ensemble model architecture. \nA. Background \nA variety of neural network architectures have been \nproposed and used for text classification tasks, including \nsentiment classification. Among these numerous architectures, \nthe best adapted architecture to sequential data is recurren t \nneural networks (RNNs). They have demonstrated to be \neffective on data where elements order is important. For \nexample, in a sentence, the order in which words occur has a \nsignificant impact on the meaning of that sentence. Since its \nintroduction, RNNs have been the state-of-the-art for capturing \nand processing dependencies in sequences. Nevertheless, it \nalso has its drawbacks, it has been proved that RNNs cannot \nprocess large sequences of text such as long paragraphs. \nMoreover, in practice, data is proces sed sequentially, which \nmakes it difficult to perform parallel computing using RNNs. \nRecently, a new architecture called Transformers has been \nintroduced. Similar to RNNs, transformers use attention \nmechanism and inherit the encoder -decoder architecture of the \nsequence-to-sequence models to deal with sequential data. \nHowever, its architecture does not involve recurrent networks \nin order to speed up the training process. Transformers were \nfirstly introduced by [23], and they were initially designed to \nperform transl ation. As illustrated below in Fig.  1, a \ntransformer consists of two blocks, on the left, the encoder \nstack, and on the right, the decoder stack.  The encoder stack is \nmade up of a multi -head self -attention layer and a fully \nconnected feed forward network. In addition to these two \nlayers, the decoder stack has one more layer called the masked \nmulti-head attention layer. As transformer architecture does not \nrely on recurrence, word position is not provided. To preserve \nthis information positional encoding technique has been \nintroduced. In addition to the input embedding vector, a \npositional vector with the same dimension as the input \nembedding vector is added to capture the context of a word in a \nsentence. \n(IJACSA) International Journal of Advanced Computer Science and Applications, \nVol. 13, No. 8, 2022 \n563 | P a g e  \nwww.ijacsa.thesai.org \n \nFig. 1. Transformer Architecture [23]. \nTransformer-based models include three types of models: \nencoder-only, decoder-only, and encoder -decoder, following a \nbrief introduction to each type of transformers, its architecture \nand its applications. \n1) Encoder-only models: In this type of transformers only \nthe encoder part is needed. A vector representing the input \nsequence is fed to the first  encoder block that consists  of a bi-\ndirectional self -attention layer and a feed -forward layer, the \noutput of this block is passed to the following encoder block, \nwhich itself is composed of two layers. Each encoder block \ntries to enrich the embedding vector with contextual \ninformation. The final encoder block outputs the last \ncontextual enc oding. This type of transformer  is suitable for \ntasks such as text classification or named entity recognition. \nThe most popular examples of this type of models are: BERT \n[18], ELECTRA [24], and RoBERTA [25]. \n2) Decoder-only models: In decoder models only decoder \nstack is used. It consists of N identical decoder blocks; a \nsingle decoder block is composed of three layers. The first \nlayer is a masked multi -head attention layer, in which future \ninformation is masked and only previous positions in the input \nsequence have att ention. Similarly, to the enco der block, the \nnext layers are  multi-head self -attention layer s and a fully \nconnected feed-forward network. Decoder -only based models \nare also called autoregressive models and are more suited for \ntasks such as text generation. The most widely used models \ntrained with decoder -only architectures are GPT (Generative \nPre-trained Transformer) [26]. \n3) Encoder-decoder models : Also called sequence -to-\nsequence models, this type of models is implemented using \nboth blocks: encoder block and decoder block. In the encoder \nblock, the whole sequence is considered, w hereas in the \ndecoder block for a given word, only the words that precede \nare considered. Encoder -decoder models are best suited for \ntasks that involve the input of a sequence of items (words, \nletters, etc.) and then outputs another sequence. This \narchitecture can be applied in the case of machine translation \nor question answering, where a sequence of words is treated \nsequentially and the result is also a sequence of words. \nRecently, many encoder -decoder bas ed models have been \nintroduced. \nB. Transformer Language Models for Arabic \nTransformers were initially introduced as a novel \narchitecture for translation. Ever since, they have been mostly \nused for natural language processing. In sentiment analysis \ntask, pretrained transformer language architectures have \nsignificantly improved the performance of models. Each model \nhas its own size and trained on different type of datasets. Table \nI summarizes the most applied  models in Arabic text \nclassification. \nIn this paper, we have selected some of the most effective \nArabic transformation models in sentiment analysis in Arabic. \nEach of these models is based on different architectures and \ntrained using different Arabic variants. Hereafter, we discuss \neach of the selected models and their architecture. \n1) AraBERT [27] pretrained BERT model using a \npretrained dataset of 70 million sentences, collected from \nWikipedia dumps, Arabic news websites and two large \ncorpora: Abulkhair Arabic Corpus [31] and OSIAN [32]. \nAraBERT comes in two versions AraBERTv0.1 and \nAraBERTv1. In this study AraBERTv0.2 is used for \nexperiments. \nTABLE I. SUMMARY OF ARABIC PRETRAINED MODELS \nModel name Ref Size Source Data \ntype Parameters \nMultilingual \nBERT [18] - Wikipedia MSA 110M \nAraBERT [27] 24GB \nWikipedia+ \nAbulkhair \nCorpus+ \nOSIAN+ news \nwebsites \nMSA 136M(base) \n371M(large) \nArabicBERT  [17] 95GB \nWikipedia+ \nOSCAR+ other \nsources \nMSA/ \nDialect \n110M(base) \n340M(large) \nCAMeLBERT [28] 167B \nGigaword+ \nAbulkhair \nCorpus+ \nOSIAN+ \nWikipedia+ \nOSCAR+ \ndialectal \ncorpora+ \nOpenITI corpus \nMSA /  \nDialect/ \nClassical \n17.3B \nMARBERT [13] 128GB Twitter API MSA/ \nDialect 160M \nArabic \nALBERT [29] - OSCAR+ \nWikipedia MSA \n12M(base) \n18M(large) \n60M(xlarge) \nGigaBERT [16] \n - \nGigaword+ \nWikipedia+ \nOSCAR \nMSA 125M \nXLM-\nRoBERTa [30] 2.5TB CommonCrawl MSA 270M(base) \n550M(large) \n\n(IJACSA) International Journal of Advanced Computer Science and Applications, \nVol. 13, No. 8, 2022 \n564 | P a g e  \nwww.ijacsa.thesai.org \n2) CAMeLBERT [28] implemented their Arabic pre -\ntrained language model on top of three variants of Arabic: \nModern Standard Arabic (MSA ), dialectal Arabic, and \nclassical Arabic. The authors evaluated the proposed model by \nmaking use of 12 datasets to address five tasks: Named Entity \nRecognition, POS tagging, sentiment analysis, dialect \nidentification, and poetry classification. \nC. Ensemble Models \nEnsemble learning is a technique that combines multiple \nmachine learning models to improve the performance of the \nlearning model and achieve a higher accuracy score than would \nbe achieved by any single model in the ensemble. In this study, \ntwo ensemb le techniques have been evaluated. The first \ntechnique is the majority voting. It is the most commonly used \ntechnique for ensemble learning. The second technique is \nbased on calculating the sum of raw outputs of each model in \nthe ensemble. \n1) Majority voting: In majority voting, the final output of \nthe ensemble model is determined by counting for each class \nthe number of votes of multiple models. The class with the \nmajority of votes is predicted. \n2) The proposed method SUM:  As illustrated in Fig.  2, \nthat represents the proposed ensemble model. Firstly, a  raw \ntext is fed to the model as input , then transform ed into vector \nrepresentation so that it can be processed  with encoder -\ndecoder approach. Then the d ecoder-block of each model \noutputs probabilities for each class. Finally, t he output is \nobtained by calculating the weighted sum of the probabilities \nfrom the same class, then for each class, the argmax operation \nis applied to find the class with higher probability value. \nFor a given text, let        and        denote the \nprobabilities predicted with AraBERT model for the class \nNegative and the class Positive respectively. Whereas, \n        and         denote the probabilities predicted with \nCAMeLBERT model for the class Negative and the class \nPositive respectively. For each class, the final probability is \nobtained by calculating the weighted sum of both probabilities, \nnamely the probability given with AraBERT model and \nCAMeLBERT model. Weights values are not selected \nrandomly, the main reason of selecting weight values 0 , 7 and \n0, 3  for CAMeLBERT and AraBERT respectively, is that \nCAMeLBERT model tend to perform well on the majority of \nthe datasets (see Table II). Thus, we considered 70% of the \nprobability generated by CAMeLBERT model and 30% of the \nprobability generated by AraBERT model. The final \nprobabilities are calculated using the following equations: \n                                 \n                                 \nNext, the final output corresponds to the index with higher \nprobability value. \n                                    \nTherefore, if the output index is 0, the model will assign to \nthe input text the class Negative, and if the output index is 1 the \nmodel will assign Positive. \n \nFig. 2. The Architecture of the Proposed Ensemble Model (SUM). \nTABLE II. ACCURACY RESULTS OF DIFFERENT MODELS ON THREE PUBLICALY AVAILABLE ARABIC DATASETS \n Negative class Positive class Accuracy Macro-F1 Precision Recall F1-score Precision Recall F1-score \nTwitter Dataset  Abdulla et al. (SVM) [33] - - - - - - 87.2 - \nUnbalanced \nDahou et al. (CNN) [34] - - - - - - 85.01 - \nAraBERT 94.03 96.43 95.21 96.32 93.85 95.06 95.14 95.14 \nCAMeLBERT 94.97 96.43 95.70 96.35 94.87 95.61 95.65 95.65 \nMajority Voting 93.24 98.47 95.78 98.37 92.82 95.51 95.65 95.65 \nSUM (ours) 95.02 96.22 96.22 97.37 94.87 96.10 96.16 96.16 \n\n(IJACSA) International Journal of Advanced Computer Science and Applications, \nVol. 13, No. 8, 2022 \n565 | P a g e  \nwww.ijacsa.thesai.org \nBalanced \nDahou et al. (CNN) [34] - - - - - - 86.3 - \nAraBERT 95.52 95.52 96.00 95.14 96.17 95.65 95.83 95.83 \nCAMeLBERT 96.30 90.55 93.33 90.26 96.17 93.12 93.23 93.23 \nMajority Voting 94.58 95.52 95.05 95.03 93.99 94.51 94.78 94.78 \nSUM (ours) 97.87 91.54 94.60 91.33 97.81 94.46 94.53 94.53 \nGold Dataset \n Refaee and Rieser (SVM) [35] - - - - - 87.74 -  \nUnbalanced \nDahou et al. (CNN) [34] - - - - - 75.8 -  \nAraBERT 94.72 87.99 91.23 73.51 87.18 79.77 87.77 85.50 \nCAMeLBERT 94.63 90.69 92.62 78.03 86.54 82.07 89.54 87.34 \nMajority Voting 93.20 94.12 93.66 84.21 82.05 83.12 90.78 88.39 \nSUM (ours)  94.36 90.20 92.23 77.01 85.90 81.21 89.01 86.72 \nBalanced \nDahou et al. (CNN) [34] - - - - - - 73.8 - \nAraBERT 85.80 83.73 84.76 85.71 87.57 86.63 85.75 86.63 \nCAMeLBERT 86.83 87.35 87.09 88.59 88.11 88.35 87.75 87.72 \nMajority Voting 82.97 90.96 86.78 91.12 83.24 87.01 86.89 86.89 \nSUM (ours) 87.95 87.95 87.69 89.13 88.65 88.89 88.32 88.29 \nASTD Dataset \nUnbalanced \nDahou et al. (CNN) [34] - - - - - - 79.07 - \nAraBERT 93.38 85.30 89.16 71.67 86.00 78.18 85.51 83.67 \nCAMeLBERT 91.47 89.63 90.54 77.07 80.67 78.83 86.92 84.68 \nMajority Voting 90.37 91.93 91.14 80.56 77.33 78.91 87.53 85.03 \nSUM (ours) 92.42 87.90 90.10 74.85 83.33 78.86 86.52 84.48 \nBalanced \nDahou et al. (CNN) [34] - - - - - - 75.9 - \nAraBERT 86.90 83.44 85.14 85.71 88.76 87.21 86.25 86.17 \nCAMeLBERT 87.76 85.43 86.58 87.28 89.35 88.30 87.50 87.44 \nMajority Voting 83.95 90.07 86.90 90.51 84.62 87.46 87.19 87.18 \nSUM (ours) 89.80 87.42 88.59 89.02 91.12 90.06 89.38 89.32 \nIV. EXPERIMENTS \nIn this section, we discuss the implemented models and \ntheir results. Two transformer language models are \nexperimented namely C AMeLBERT and AraBERT, an \nensemble of these two models , as well as  majority voting \nensemble model. \nA. Dataset \nFor experimentation  purposes, in this work  we consider  \nfour datasets of different sizes and sources. The first dataset is \nTwitter dataset collected by Abdulla et al,. [33] composed of \nabout 2000 tweets, written in MSA and Jordanian dialect . And \nconsisted of 958 negative tweets and 993 positive tweets.  The \nsecond dataset is Arabic Gold -Standard Twitter dataset \ncollected by Refaee and Rieser [35] composed of 6512 tweets, \ndivided in three classes: Negative, neutral, and positive. The \nnegative class contains 1941 tweets, the neutral class contains \n3694, and the positive class contains 876 tweets. In this study \nwe perform a bin ary classification, thus only Positive and \nnegative classes are utilized.  The third dataset is Arabic \nsentiment tweets dataset (ASTD)  proposed by [19] which \ncontains 1000 6 tweets written in MSA and Arabic dialect . \nTweets are labeled as one of four classes: negative, positive, \nneutral, and objective. As this  study focuses on binary \nclassification only positive and negative tweets are considered. \nAfter data preprocessing, we are left with 1684 negative tweets \nand 799 positive tweets. The fourth dataset is a dataset that we \nhave proposed in a previous work [36] which is consisted of \n1299 Modern Standard Arabic books reviews wit h a balance \nbetween positive and negative reviews. Reviews are collected \nfrom Goodreads website and annotated manually. After data \ncollection, each given text is decomposed into tokens. Then, \nArabic stop words are filtered out as they do not hold any \ninformation. The next step is normalization, where elongation, \nhamza, and diacritics are removed. Finally, all emoticons and \nemojis are deleted based on a preselected list of the most \ncommonly used emoticons and emojis. \nB. Results \nTo investigate the effectiveness of the proposed ensemble \nmodel three models have been implemented, including two \ntransformer language -based models: AraBERT and \nCAMeLBERT and majority voting model . All models are \ntrained on the same training set, which represents 80% of the \nwhole dataset, and tested on the same test ing set composed of \nthe 20% remaining data.  For each of the four datasets t he \nmodels are trained and tested on both balanced and unbalanced \ndatasets. Performance results of the proposed ensemble method \nare compared with stand -alone models and majority vot ing \nensemble model. The models are evaluated using accuracy, F1-\nscore, precision and recall metrics. The mathematical formulas \nof each of the used metrics is defined as follows: \n              \n             \n            \n      \n         \n      \n                      \n                 \n(IJACSA) International Journal of Advanced Computer Science and Applications, \nVol. 13, No. 8, 2022 \n566 | P a g e  \nwww.ijacsa.thesai.org \nWhere, TP, FP, TN, and FN refer to “True Positive”, “False \nPositive”, “True Negative”, and “False Negative” respectively. \nTable II shows the performance of each model on balanced \nand unbalanced datasets compared to existing models. As can \nbe seen , it is clear that ensemble models provide remarkable \nimprovement over baseline models. Majority voting model has \nachieved the best accu racy score on unbalanced Gold dataset \nwith an accuracy score of 90.78% followed by our ensemble \nmodel with 89.01% , whereas on Twitter, and ASTD datasets \nthe best accuracy score is achieved by our  proposed ensemble \nmodel SUM. On Twitter dataset SUM model ac hieved an \naccuracy score of 96.16% with unbalanced dataset followed by \nmajority voting model and CAMeLBERT model with the same \naccuracy score of 95.65%. As for ASTD dataset our proposed \nmodel outperformed all other models by achieving the first best \naccuracy score of 89.38% on balanced dataset, the second-best \naccuracy score is achieved by majority voting model with \n87.53% on unbalanced dataset. \nThe results of all proposed models on our dataset are shown \non Table III. AraBERT model has achieved better results than \nCAMeLBERT in terms of accuracy and F1-score. On the other \nhand, the performance of ensemble models varies from one \nmodel to another. Compared to the proposed ensemble model, \nmajority voting model has failed to improve the p erformance. \nIt has achieved an accuracy of 94.98% against an accuracy of \n95.75% achieved by AraBERT. Whereas, our proposed \nensemble model has reached the best results in terms of \naccuracy and F1-score. The mediocre performance of majority \nvoting may be exp lained by the size of the dataset and  the \nnumber of combined models. \nTABLE III. COMPARISON OF DIFFERENT MEASURES OF PERFORMANCE ON \nOUR DATASET \nModel Accuracy F1-score Recall Precision \nAraBERT 95.75 95.72 96.09 95.35 \nCAMeLBERT 92.66 92.66 93.75 91.60 \nMajority Voting 94.98 94.78 92.19 97.52 \nSUM (ours) 96.53 96.50 96.88 96.12 \nIn summary, the best results have been achieved by our \nproposed ensemble model on balanced datasets. Thus, i t is \nobvious from the conducted comparative experiments that \ntraining models on balanced data can improve classification \nperformance, it can help models to learn better and achieve \nbetter accuracy results. \nV. CONCLUSION \nIn this work, we have implemented an ensemble model \nbased on two transformer language models, namely AraBERT \nand CAMeLBERT. The proposed ensemble model was \nevaluated on top of our balanced dataset composed of modern \nstandard Arabic book reviews. In addition, to investigate more \nthe performance of our proposed mo del it has been trained on \ntop of three other datasets namely Twitter dataset, Gold dataset \nand ASTD dataset. Compared to majority voting and the two \nstand-alone transformer-based models, our proposed ensemble \nmodel has achieved the highest  score of  accuracy and F 1 \nmetrics on all datasets. In this paper, we have proposed a \ndomain-independent model, the proposed ensemble model has \nachieved state -of-the-art on several datasets of different \nsources and domains. Thus, researchers can adopt our proposed \nmodel to  address sentiment analysis in Arabic  regardless of \ndata type (MSA/Dialect) and domain. To continue working \ntowards improving the model’s performance, for future work, \nwe plan to experiment more transformer models, combine \nmultiple models and evaluate all possible combinations to \ndetermine the optimized model. Finally, we will be considering \nincreasing the size of our training set as accuracy increases \nwith the size of training data. \nREFERENCES \n[1] H. Al -Rubaiee, R. Qiu, and D. Li, “Identifying Mubasher software \nproducts through sentiment analysis of Arabic tweets,” 2016 Int. Conf. \nInd. Informatics Comput. Syst., pp. 1–6, 2016. \n[2] K. M. Alomari, H. M. Elsherif, and K. Shaalan, “Arabic tweets \nsentimental analysis using machine learning,” in Lecture Notes in \nComputer Science (including subseries Lecture Notes in Artificial \nIntelligence and Lecture Notes in Bioinformatics), 2017, vol. 10350 \nLNCS, pp. 602–610, doi: 10.1007/978-3-319-60042-0_66. \n[3] R. Duwairi, M. Faqeeh, M. Wardat, and A. Alrabadi, “Sentiment \nanalysis for Arabizi text,” 2016, pp. 127 –132, doi: \n10.1109/IACS.2016.7476098. \n[4] A. Albayati and A. Al -Araji, “Arabic Sentiment Analysis (ASA) Using \nDeep Learning Approach,” Univ. Baghdad Eng. J., vol. 26, pp. 85 –93, \n2020, doi: 10.31026/j.eng.2020.06.07. \n[5] A. Soufan, “Deep learning for sentiment analysis of Arabic text,” 2019, \ndoi: 10.1145/3333165.3333185. \n[6] M. Hoang, O. A. Bihorac, and J. Rouces, “Aspect -Based Sentiment \nAnalysis using BERT,” 2019. \n[7] U. Naseem, M. Khushi, V. Reddy, S. Rajendran, I. Razzak, and J. Kim, \n“BioALBERT: A Simple and Effective Pre -trained Language Model for \nBiomedical Named Entity Recognition,” in 2021 International Joint \nConference on Neural Networks (IJCNN), 2021, pp. 1 –7, doi: \n10.1109/IJCNN52387.2021.9533884. \n[8] W. Yoon, J. Lee, D. Kim, M. Jeong, and J. Kang, “Pre-trained Language \nModel for Biomedical Question Answering BT - Machine Learning and \nKnowledge Discovery in Databases,” 2020, pp. 727–740. \n[9] A. S. Alammary, “BERT Models for Arabic Text Classification: A \nSystematic Review,” Appl. Sci., vol. 12, no. 11, p. 5720, 2022. \n[10] S. Bilal, “A Linguistic System for Predicting Sentiment in Arabic \nTweets,” in 2021 3rd International Conference on Natural Language \nProcessing (ICNLP), 2021, pp. 134 –138, doi: \n10.1109/ICNLP52887.2021.00028. \n[11] A. Wadhawan, “Arabert a nd farasa segmentation based approach for \nsarcasm and sentiment detection in arabic tweets,” arXiv Prepr. \narXiv2103.01679, 2021. \n[12] A. Abuzayed and H. Al -Khalifa, “Sarcasm and Sentiment Detection In \n{A}rabic Tweets Using {BERT} -based Models and Data \nAugmentation,” in Proceedings of the Sixth Arabic Natural Language \nProcessing Workshop, Apr. 2021, pp. 312 –317, [Online]. Available: \nhttps://aclanthology.org/2021.wanlp-1.38. \n[13] M. Abdul -Mageed, A. Elmadany, and E. M. B. Nagoudi, “ARBERT \n&amp; MARBERT: Deep Bidirectional Transformers for Arabic,” 2021, \ndoi: 10.48550/ARXIV.2101.01785. \n[14] A. Abdelali, S. Hassan, H. Mubarak, K. Darwish, and Y. Samih, “Pre -\nTraining BERT on Arabic Tweets: Practical Considerations,” 2021. \n[15] W. Antoun, F. Baly, and H. Hajj, “AraBERT: Transformer-based Model \nfor Arabic Language Understanding,” in Proceedings of the 4th \nWorkshop on Open-Source Arabic Corpora and Processing Tools, with a \nShared Task on Offensive Language Detection, May 2020, pp. 9 –15, \n[Online]. Available: https://aclanthology.org/2020.osact-1.2. \n[16] W. Lan, Y. Chen, W. Xu, and A. Ritter, “An Empirical Study of Pre -\ntrained Transformers for {A}rabic Information Extraction,” in \nProceedings of the 2020 Conference on Empirical Methods in Natural \n(IJACSA) International Journal of Advanced Computer Science and Applications, \nVol. 13, No. 8, 2022 \n567 | P a g e  \nwww.ijacsa.thesai.org \nLanguage Processing (EMNLP), Nov. 2020, pp. 4727 –4734, doi: \n10.18653/v1/2020.emnlp-main.382. \n[17] A. Safaya, M. Abdullatif, and D. Yuret, “{KUISAIL} at {S}em{E}val -\n2020 Task 12: {BERT} -{CNN} for Offensive Speech Identification in \nSocial Media,” in Proceedings of the Fourteenth Workshop on Semantic \nEvaluation, Dec. 2020, pp. 2054–2059, doi: 10.18653/v1/2020.semeval-\n1.271. \n[18] J. Devlin, M. W. Chang, K. Lee, and K. Toutanova, “BERT: Pre -\ntraining of deep bidirectional transformers for language understanding,” \nin NAACL HLT 2019 - 2019 Conference of the North American \nChapter of the Association for Computational Linguistics: Human \nLanguage Technologies - Proceedings of the Conference, Jun. 2019, vol. \n1, pp. 4171–4186, doi: 10.18653/v1/N19-1423. \n[19] M. Heikal, M. Torki, and N. El -Makky, “Sentiment Analysis of Arabic \nTweets u sing Deep Learning,” Procedia Comput. Sci., vol. 142, pp. \n114–122, 2018, doi: 10.1016/j.procs.2018.10.466. \n[20] M. Nabil, M. Aly, and A. F. Atiya, “ASTD: Arabic sentiment tweets \ndataset,” in Conference Proceedings - EMNLP 2015: Conference on \nEmpirical Methods i n Natural Language Processing, Sep. 2015, pp. \n2515–2519, doi: 10.18653/v1/d15-1299. \n[21] S. R. El -Beltagy, M. El Kalamawy, and A. B. Soliman, “NileTMRG at \nSemEval-2017 Task 4: Arabic Sentiment Analysis,” in Proceedings of \nthe 11th International Workshop on Sema ntic Evaluation (SemEval -\n2017), Aug. 2017, pp. 790–795, doi: 10.18653/v1/S17-2133. \n[22] S. R. El-Beltagy, “NileULex: A phrase and word level sentiment lexicon \nfor Egyptian and modern standard Arabic,” in Proceedings of the 10th \nInternational Conference on Language Resources and Evaluation, LREC \n2016, 2016, pp. 2900–2905. \n[23] A. Vaswani et al., “Attention is All you Need,” in Advances in Neural \nInformation Processing Systems, 2017, vol. 30, [Online]. Available: \nhttps://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053\nc1c4a845aa-Paper.pdf. \n[24] K. Clark, M.-T. Luong, Q. V Le, and C. D. Manning, “ELECTRA: Pre -\ntraining Text Encoders as Discriminators Rather Than Generators.” \narXiv, 2020, doi: 10.48550/ARXIV.2003.10555. \n[25] Y. Liu et al., “RoBERTa: A Robustly Optimized  BERT Pretraining \nApproach.” arXiv, 2019, doi: 10.48550/ARXIV.1907.11692. \n[26] A. Radford and K. Narasimhan, “Improving Language Understanding \nby Generative Pre-Training,” 2018. \n[27] W. Antoun, F. Baly, and H. Hajj, “{A}ra{BERT}: Transformer -based \nModel for {A}rabic Language Understanding,” in Proceedings of the 4th \nWorkshop on Open-Source Arabic Corpora and Processing Tools, with a \nShared Task on Offensive Language Detection, May 2020, pp. 9 –15, \n[Online]. Available: https://aclanthology.org/2020.osact-1.2. \n[28] G. Inoue, B. Alhafni, N. Baimukan, H. Bouamor, and N. Habash, “The \nInterplay of Variant, Size, and Task Type in {A}rabic Pre -trained \nLanguage Models,” in Proceedings of the Sixth Arabic Natural \nLanguage Processing Workshop, Apr. 2021, pp. 92 –104, [Online]. \nAvailable: https://aclanthology.org/2021.wanlp-1.10. \n[29] A. Safaya, “Arabic -ALBERT.” Zenodo, Aug. 2020, doi: \n10.5281/zenodo.4718724. \n[30] A. Conneau et al., “Unsupervised Cross-lingual Representation Learning \nat Scale,” in Proceedings of the 58th Annual Meeting of the Ass ociation \nfor Computational Linguistics, Jul. 2020, pp. 8440 –8451, doi: \n10.18653/v1/2020.acl-main.747. \n[31] I. A. El -khair, “1.5 billion words Arabic Corpus,” ArXiv, vol. \nabs/1611.0, 2016, [Online]. Available: http://arxiv.org/abs/1611.04033. \n[32] I. Zeroual, D. Goldhahn, T. Eckart, and A. Lakhouaja, “{OSIAN}: Open \nSource International {A}rabic News Corpus - Preparation and \nIntegration into the {CLARIN} -infrastructure,” in Proceedings of the \nFourth Arabic Natural Language Processing Workshop, Aug. 2019, pp. \n175–182, doi: 10.18653/v1/W19-4619. \n[33] N. A. Abdulla, N. A. Ahmed, M. A. Shehab, and M. Al -Ayyoub, \n“Arabic sentiment analysis: Lexicon -based and corpus -based,” in 2013 \nIEEE Jordan Conference on Applied Electrical Engineering and \nComputing Technologies, AEECT 2013, 2013 , pp. 1 –6, doi: \n10.1109/AEECT.2013.6716448. \n[34] A. Dahou, S. Xiong, J. Zhou, M. H. Haddoud, and P. Duan, “Word \nembeddings and convolutional neural network for Arabic sentiment \nclassification,” in COLING 2016 - 26th International Conference on \nComputational Lin guistics, Proceedings of COLING 2016: Technical \nPapers, Dec. 2016, pp. 2418 –2427, [Online]. Available: \nhttps://www.aclweb.org/anthology/C16-1228. \n[35] E. Refaee and V. Rieser, “An Arabic twitter corpus for subjectivity and \nsentiment analysis,” in Proceedings of  the 9th International Conference \non Language Resources and Evaluation, LREC 2014, 2014, pp. 2268 –\n2273. \n[36] I. El Karfi, S. El Fkihi, and R. Faizi, “A spectral clustering -based \napproach for sentiment classification in modern standard Arabic,” in \nMCCSIS 2018 - Multi Conference on Computer Science and \nInformation Systems; Proceedings of the International Conferences on \nBig Data Analytics, Data Mining and Computational Intelligence 2018, \nTheory and Practice in Modern Computing 2018 and Connected Sma, \n2018, pp. 59 –65, [Online]. Available: https://www.scopus.com/ \ninward/record.uri?eid=2-s2.0-85054167622%5C&partnerID=40%5C \n&md5=101982324dd788664f052d2919012106. ",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8641918897628784
    },
    {
      "name": "Transformer",
      "score": 0.8046408891677856
    },
    {
      "name": "Sentiment analysis",
      "score": 0.8042914271354675
    },
    {
      "name": "Encoder",
      "score": 0.666425347328186
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5653032064437866
    },
    {
      "name": "Arabic",
      "score": 0.5437094569206238
    },
    {
      "name": "Natural language processing",
      "score": 0.5332484245300293
    },
    {
      "name": "Artificial neural network",
      "score": 0.4738136827945709
    },
    {
      "name": "Feeling",
      "score": 0.43597516417503357
    },
    {
      "name": "Machine learning",
      "score": 0.3905886709690094
    },
    {
      "name": "Speech recognition",
      "score": 0.3526327311992645
    },
    {
      "name": "Linguistics",
      "score": 0.13419181108474731
    },
    {
      "name": "Voltage",
      "score": 0.10376322269439697
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Psychology",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Social psychology",
      "score": 0.0
    }
  ]
}