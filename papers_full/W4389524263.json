{
  "title": "Probing the “Creativity” of Large Language Models: Can models produce divergent semantic association?",
  "url": "https://openalex.org/W4389524263",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2110597416",
      "name": "Honghua Chen",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2045850292",
      "name": "Nai Ding",
      "affiliations": [
        "Zhejiang University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4367189299",
    "https://openalex.org/W4304191715",
    "https://openalex.org/W4385734232",
    "https://openalex.org/W4385571053",
    "https://openalex.org/W3183248212",
    "https://openalex.org/W4361204756",
    "https://openalex.org/W4316829915",
    "https://openalex.org/W4224035735",
    "https://openalex.org/W2938704169",
    "https://openalex.org/W2081580037",
    "https://openalex.org/W4378765257",
    "https://openalex.org/W4294170691",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W3166509103",
    "https://openalex.org/W3154046074",
    "https://openalex.org/W3164994912",
    "https://openalex.org/W4366341216",
    "https://openalex.org/W2257979135",
    "https://openalex.org/W3097607794",
    "https://openalex.org/W4285118702",
    "https://openalex.org/W2171960331",
    "https://openalex.org/W2001610569",
    "https://openalex.org/W4240861134",
    "https://openalex.org/W2493916176",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W4384920109",
    "https://openalex.org/W4387453630",
    "https://openalex.org/W3183150006",
    "https://openalex.org/W2963096510",
    "https://openalex.org/W4360836968",
    "https://openalex.org/W2252211741",
    "https://openalex.org/W1525100564",
    "https://openalex.org/W4255825300",
    "https://openalex.org/W3081924543",
    "https://openalex.org/W4318919287",
    "https://openalex.org/W2136350371",
    "https://openalex.org/W4285294723",
    "https://openalex.org/W4386827094"
  ],
  "abstract": "Large language models possess remarkable capacity for processing language, but it remains unclear whether these models can further generate creative content. The present study aims to investigate the creative thinking of large language models through a cognitive perspective. We utilize the divergent association task (DAT), an objective measurement of creativity that asks models to generate unrelated words and calculates the semantic distance between them. We compare the results across different models and decoding strategies. Our findings indicate that: (1) When using the greedy search strategy, GPT-4 outperforms 96% of humans, while GPT-3.5-turbo exceeds the average human level. (2) Stochastic sampling and temperature scaling are effective to obtain higher DAT scores for models except GPT-4, but face a trade-off between creativity and stability. These results imply that advanced large language models have divergent semantic associations, which is a fundamental process underlying creativity.",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 12881–12888\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nProbing the “Creativity” of Large Language Models: Can Models Produce\nDivergent Semantic Association?\nHonghua Chen and Nai Ding∗\nKey Laboratory for Biomedical Engineering of Ministry of Education,\nCollege of Biomedical Engineering and Instrument Sciences,\nZhejiang University / Hangzhou, China\n{honghuachen,ding_nai}@zju.edu.cn\nAbstract\nLarge language models possess remarkable ca-\npacity for processing language, but it remains\nunclear whether these models can further gen-\nerate creative content. The present study aims\nto investigate the creative thinking of large\nlanguage models through a cognitive perspec-\ntive. We utilize the divergent association task\n(DAT), an objective measurement of creativity\nthat asks models to generate unrelated words\nand calculates the semantic distance between\nthem. We compare the results across differ-\nent models and decoding strategies. Our find-\nings indicate that: (1) When using the greedy\nsearch strategy, GPT-4 outperforms 96% of\nhumans, while GPT-3.5-turbo exceeds the av-\nerage human level. (2) Stochastic sampling\nand temperature scaling are effective to obtain\nhigher DAT scores for models except GPT-4,\nbut face a trade-off between creativity and sta-\nbility. These results imply that advanced large\nlanguage models have divergent semantic asso-\nciations, which is a fundamental process under-\nlying creativity.1\n1 Introduction\nLarge language models (LLMs) have exhibited un-\nparalleled mastery of natural language (Bubeck\net al., 2023). The primary capacity of producing the\nmost probable next word is broadly generalizable\nto many language tasks, suggesting underlying cog-\nnitive abilities beyond specialized linguistic rules\nand patterns. There is observation that LLMs may\npossess reasoning abilities which is a core aspect of\nintelligence, including decision-making (Binz and\nSchulz, 2023) and theory of mind (Moghaddam and\nHoney, 2023). Meanwhile, there is also increas-\ning interest in exploring LLMs’ creativity, which\nis closely related to intelligence (Frith et al., 2021).\nCreative use of language, such as metaphor and\n∗Corresponding author\n1We release our code at https://github.com/\nDingNLab/probing_creativity\nFigure 1: Creativity from the perspective of language\ndistribution. Creative thoughts need to be novel and\nvaluable, which need cognitive control to inhibit com-\nmon tokens and remote association to find valuable\ntokens.\nhumor, is important during communication. Ope-\nnAI (2023) has reported GPT-4’s ability to under-\nstand jokes, while subsequent works show limited\ncapacity for LLMs to generate or explain humor\n(Jentzsch and Kersting, 2023; Hessel et al., 2023).\nAs creativity is essential to the development of art,\nscience, and everyday life for human (Gabora and\nKaufman, 2010), it is non-trivial if models could\nproduce creative content. Regarding to the curse of\nrecursion for LLMs that training on generated data\nmakes models collapse, one promising solution\nmight be the novel language distribution through\ncreative generation (Shumailov et al., 2023). But\nsince LLMs represent word meaning and predict\nthe next word in context, it seems paradoxical that\nsuch models could create ideas not seen in training.\nHere, we empirically investigate the creativity of\nLLMs by examining models’ ability to generate\ndivergent concepts.\nA general definition of creativity is the ability to\ncreate something both novel and valuable (Runco\nand Jaeger, 2012). According to the dual-process\ntheory of creativity (Beaty et al., 2014), creative\nthinking relies on remote association while inhibit-\ning common ideas (Figure 1). Because of the intrin-\nsic complexity, creativity is universally accepted\nto be unique to human beings, while models are\n12881\nregarded as great predictors to master the existing\ndistribution but not qualified creators to generate\nnew distribution. However, there have been evi-\ndences of models possessing creativity in differ-\nent domains. For artistic creation, deep generative\nmodels reveals exquisite painting skills (Ramesh\net al., 2022). For algorithms, models are able\nto generate original and superhuman strategies in\nboard game (Silver et al., 2016).\nAs for language models, creativity is an emerg-\ning concern. Since GPT-2 (Radford et al., 2019),\nlanguage models are able to naturally produce an-\nswers given a prompt, even for open-ended and cre-\native generation tasks (Kaddour et al., 2023). How-\never, when generating texts from these probabilistic\nmodels, decoding strategy has a prominent effect\non the quality of result. Decoding strategies that\nsearch for the highest-probability words tend to pro-\nduce texts that is dull and repetitive (Zhang et al.,\n2021), while stochastic strategies, which randomly\nsample from models, generate texts with better hu-\nman preference (DeLucia et al., 2021; Holtzman\net al., 2020). These texts have human-like informa-\ntion distribution, which are viewed as informative\nand interesting (Meister et al., 2022). Despite this,\nstochastic strategies are distinct from human. The\ndecoding process is probabilistic and independent,\nwhile humans produce language under elaborated\ncognitive control, especially for creative generation.\nCreative and nonsense contents are both infrequent\nduring next word prediction that cannot be simply\ndistinguished via sampling strategies (Figure 1).\nThus, it is unclear whether LLMs genuinely have\ncreativity during modeling, and whether decoding\nstrategies help.\nTo answer both of these questions, we evaluate\nthe creativity of LLMs. Specifically, we use an ob-\njective semantic measurement, the divergent asso-\nciation task (DAT), which asks models to generate\nunrelated nouns and compute the pairwise seman-\ntic distance between them (Olson et al., 2021). In\nsummary, we make the following contributions:\n• Investigate the creativity of LLMs and com-\npare the results with human.\n• Explore the effect of decoding strategies on\nthe creative generation of LLMs.\n2 Measuring Creativity\nA direct measure of creativity is relying on experts\nto judge the creative quality of products. Several\nFigure 2: The DAT paradigm and example responses.\nstudies assessed LLMs’ creativity on artistic and\nscientific creation (Crothers et al., 2023; Park et al.,\n2023). However, two elements of creativity, nov-\nelty and value, are both relative and ambiguous\nduring evaluation. Human ratings are affected by\nsubjective surprise and domain knowledge, and\nthus differ from each other.\nThere are other methods based on domain-\ngeneral cognitive process of creativity.2 Divergent\nthinking, i.e., generating a large variety of solu-\ntions from an open-ended point, is an indicator\nfor creative thinking (Beaty et al., 2014). One of\nthe most widely used tasks on divergent thinking\nis the alternate use task (AUT), which asks par-\nticipants to generate unusual uses of objects (e.g.,\na brick) (Guilford, 1964). Previous studies used\nAUT to measure the creativity of LLMs (Summers-\nStay et al., 2023; Haase and Hanel, 2023), but the\nevaluation is sample-dependent that the scores are\nvarious across the selected objects. AUT also relies\non humans to rate the creativity of generated uses.\nMoreover, AUT has the the risk of data leakage that\nthe answers are confounded by the uses recorded\nin the training data.\nCreativity has long been linked to the flexibility\nof semantic retrieval (Zhang et al., 2023). An alter-\nnative to probe creativity is through the structure of\nsemantic memory, which can be automatically and\nreproducibly assessed (Beaty et al., 2021; Beaty\nand Johnson, 2021). The DAT, among these meth-\nods, is valid and reliable that closely correlates with\nother metrics of creativity (Olson et al., 2021). Dif-\nferent from measuring semantic similarity as usual,\nthe DAT prompts participants to reject related as-\nsociations and produce unrelated nouns (Figure 2).\nFormally, given n words and their word embed-\n2Other components of creativity, such as emotion and mo-\ntivation, are not considered in this study.\n12882\ndings {v1,..., vn}, the DAT can be calculated as\nthe average cosine distance as follows:\nDAT = 100\nn(n−1)\nn∑\ni,j\ni̸=j\n(1 −cos (vi,vj)) (1)\nIn this study, we apply the DAT to assess the\ncreativity of LLMs, but before that it is necessary\nto evidence the applicability of this method. Basi-\ncally, the validity of DAT for humans comes with\nthe bias that humans retrieve semantics exploit-\ning their semantic networks. The semantic net-\nworks of humans reveal the semantic representa-\ntions about the world, which are also reflected in\nthe language distribution of human corpus. Thus,\nLLMs pre-trained on the corpus should exhibit\nthe similar bias. The semantic networks are also\nneeded for LLMs to accomplish general language\ntasks. Empirically, previous studies showed that\nlanguage models have similar patterns of semantic\nactivations with humans (Lake and Murphy, 2020;\nDigutsch and Kosinski, 2023). Additionally, con-\nsidering these studies assessing the semantic activa-\ntions differently from the present study, we provide\nanother analysis to validate the DAT for LLMs.\nIt is noteworthy that possessing similar semantic\nnetworks is not equivalent to being equally cre-\native. Although the semantic networks of humans\nare roughly consistent, the ability to produce re-\nmote associations is challenging and largely varies\namong humans.\n3 Experiment Setup\n3.1 Models\nWe studied five recent LLMs with different sizes,\nincluding GPT-4 (OpenAI, 2023) and GPT-3.5-\nTurbo (OpenAI, 2022) from OpenAI, Oasst-Llama-\n30B (Köpf et al., 2023) and Vicuna-13B (Chiang\net al., 2023) fine-tuned from Llama (Touvron et al.,\n2023), and ChatGLM-6B based on GLM (Du et al.,\n2022).3 GPT-4 and GPT-3.5-Turbo have advanced\nperformance through pre-train and RLHF (Ouyang\net al., 2022), while other models are trained by fine-\ntuning foundation models on collected instructions.\n3.2 Decoding strategy\nFor deterministic algorithms, we use greedy search\nthat choose the most probable token at each decod-\n3Specifically, we use the following versions: gpt-4-0314,\ngpt-3.5-turbo-0301, oasst-sft-7-llama-30b, Vicuna-13b-delta-\nv1.1 and chatglm-6b-v1.0.\ning step. For stochastic algorithms, we use top- p\nsampling (Holtzman et al., 2020) that limit the sam-\npling space to the top-pmost likely tokens at each\ndecoding step, truncating the undesirable tail of dis-\ntribution. We set p= 0.9 with temperature t= 0.7\nfor top-psampling. Then we adjust different set-\ntings of tto study the effect of temperature. For\neach model, we collect enough samples to ensure\nthe results convergent (Appendix A).\n3.3 DAT\nIn DAT, we ask models to generate 10 unrelated\nnouns. we constrain the models to generate only\nnouns to isolate the semantical distances from syn-\ntactic effects. We use the zero-shot prompt in Fig-\nure 2 that is consistent with the study for humans\n(Olson et al., 2021). We filter out the answers with\ninvalid words, e.g., verbs. Then we select the first\nseven valid words that models provide, and com-\npute the DAT score via Eq. (1).4\nWe use GLoVe (Pennington et al., 2014) to cal-\nculate semantic distance (Figure 3a). In previous\nstudies which also used semantic space to evaluate\ncreativity, GLoVe was proved to be effective (Beaty\nand Johnson, 2020). We have also experimented\nWord2Vec (Mikolov et al., 2013) and Fasttext (Bo-\njanowski et al., 2016), and found results similar\n(with the correlation coefficient of 0.82 and 0.91\nrespectively).\nThe word vectors also encode word frequency\nthat rare words have unstable semantic distance for\nthe lack of training (Schnabel et al., 2015). Thus,\nwe also compute the average surprisal (negative log\nword frequency) to study this potential effect.\nTo compare the result of models with humans,\nwe use the data collected on 8572 participants.5 We\nalso randomly sample nouns from Wordnet (Miller,\n1995) as a situation without the bias of semantic\nnetwork.\n3.4 Validating DAT\nAs mentioned in Section 2, we set two additional\nprompts for comparison: (1) Base: write 10 nouns,\nand (2) Random: write 10 nouns randomly. We\nhypothesize that LLMs generate semantically as-\nsociated words if not instructed, but can also have\ndivergent associations under the DAT prompt.\n4The number of seven is consistent with Olson et al. 2021\nbecause most answers have at least seven valid words, and\nresults are stable using over seven words.\n5The data and code of DAT for human is available at\nhttps://osf.io/vjazn/.\n12883\nFigure 3: The DAT for humans and models. (a) The distance matrix of words generated by GPT-4 and GPT-3.5-turbo.\nThe average distance is defined as the DAT. (b) The DAT of models and human. (c) The percentile of models’ DAT\nagainst human results.\n4 Result\nThe DAT results are shown in Figure 3. Using\ngreedy search, GPT-4 achieves the highest DAT\nof 89.1, surpassing 96.1% of humans, and GPT-\n3.5-Turbo attains a DAT of 80.8 that is above the\naverage human-level (Figure 3c). Other models per-\nform less well with lower DAT, which are roughly\nproportional to the size of models. When using\ntop-psampling, models other than GPT-4 are ca-\npable of getting the DAT much higher than greedy\nsearch, but they also become unstable that probably\ngenerate answers with low DAT scores (Figure 3b).\nWe also report the relation between the DAT\nand surprisal in Figure 4. 6 Theoretically, sur-\nprisal is corresponding to the novelty that is an\nelement of creativity, and the original DAT met-\nric including word frequency effect is valid for\nhuman as well (Olson et al., 2021). But as men-\ntioned in Section 3.3, word frequency might be\na confounding variable when calculating seman-\ntic distance. Indeed, we find two variables highly\nrelevant for human and random baselines (also\nsee Appendix B). For models, the results of top-p\nsampling have homogeneous slopes with two base-\nlines, but their intercepts and surprisal distributions\nare different. GPT-4 and GPT-3.5-Turbo exceed\nthe average human DAT under the same surprisal,\nwhile other models fall short. Despite Vicuna-13B\n6The DAT and surprisal for more LLMs are shown in\nAppendix C\nFigure 4: Relationship between the DAT and surprisal.\nRimmed points show the results of greedy search. The\ncontour indicates the 95% confidence interval of hu-\nmans.\nand Chatglm-6B have similar distributions of sur-\nprisal, the former generates words more divergently.\nOasst-Llama-30B defeats Vicuna-13B on the DAT,\nbut this might be explained by the capacity or ten-\ndency to generate rarer words. To clarify this effect,\nwe control the surprisal for DAT in Appendix D.\nThe results are similar that GPT-4 and GPT-3.5-\nTurbo outperform average human performance, but\nthe superiority of GPT-4 is attenuated.\n12884\nFigure 5: Effect of temperature tuning. The bands indi-\ncate the standard deviations.\nWe further investigate the effect of temperature\n(Figure 5). Temperature is a widely deployed pa-\nrameter for creative or original generation in prac-\ntice that high temperature skews the distribution\nshape towards low-probability tokens (Ackley et al.,\n1985; Fan et al., 2018). We vary the tempera-\nture from 0.1 to 1 and found its positive effect\nfor models except GPT-4. However, the effect is\nlimited, and high temperature will also bring insta-\nbility and produce invalid answers. As for GPT-4,\nhigh-probability tokens are well aligned with high-\nquality answers.\nIn the relationship between the DAT and sur-\nprisal, we find a naive algorithm that samples nouns\nfrom Wordnet can outperform the majority of hu-\nmans and models (Figure 4). It is because the\nalgorithm has no constrains of the language distri-\nbution, which also means it can barely accomplish\ngeneral language tasks. Although LLMs have ex-\nhibited striking mastery of natural language, we\nwonder whether they process the semantics differ-\nently with humans and the DAT test is accordingly\ninvalid as well. Thus, we compare the DAT with\nBase and Random conditions (figure 6). We show\nthat if not instructed, LLMs tend to produce more\nrelated words. When instructed with the prompts\nof Random and the DAT, LLMs can modulate the\nlanguage distributions to be more divergent.\nThese results indicate that LLMs have the po-\ntential to generate divergent content with instruc-\ntion, but with the flaw of not inhibiting common\nwords. Stochastic decoding strategy is helpful for\npromoting remote association, but since the cre-\native and nonsense content are both infrequent, it\ncannot accurately produce high-quality content. 7\n7Previous psychological researches reported similar result\nthat mild imperfection of attention is related to higher creativ-\nity (Abraham, 2014).\nFigure 6: The DAT scores of 3 conditions.\nHowever, advanced LLMs show the implicit con-\ntrol of modulating the probability distribution and\nstably generating divergent answers. Stochastic\ndecoding strategy may even degrade performances\nfor introduced randomness.\n5 Conclusion\nIn this work, we provide a creativity evaluation\nusing a divergent semantic task. This task reveals\ndistinguishable results across various LLMs and\ndecoding strategies. We find GPT-4 demonstrates\nadvanced human-level creativity stably, while GPT-\n3.5-turbo exceeds the average human level. For\ndecoding methods, stochastic decoding strategy is\neffective but not enough for creative generation.\nLimitation\nCreativity is a deeply debated concept. We selec-\ntively evaluate the “little-C” (creativity in every-\nday life) that is a general capacity, instead of the\n“big-C” (marvelous creative product) which is rare\neven for human. Measuring creativity is also con-\ntroversial that requires evaluations from multiple\nperspectives, principles, and analysis. Thus, the re-\nsults of this study cannot be directly generalized to\nall language generation tasks. We also limited the\nrange of this study within self-contained creativity,\nwhereas another crucial aspect of AI’s creativity is\nhuman-AI co-creation. We leave these for future\nwork.\nAcknowledgement\nWe thank Mark Sun and the anonymous reviews\nfor their thoughtful helps and suggestions. This\nwork was supported by STI2030-Major Projects\n2021ZD0204105 and Fundamental Research Funds\nfor the Central Universities 226-2023-00091.\n12885\nReferences\nAnna Abraham. 2014. Creative thinking as orchestrated\nby semantic processing vs. cognitive control brain\nnetworks. Frontiers in human neuroscience, 8:95.\nDavid H. Ackley, Geoffrey E. Hinton, and Terrence J.\nSejnowski. 1985. A learning algorithm for boltz-\nmann machines. Cognitive Science, 9(1):147–169.\nRoger E. Beaty and Dan R. Johnson. 2021. Automating\ncreativity assessment with SemDis: An open plat-\nform for computing semantic distance. Behavior\nResearch Methods, 53(2):757–780.\nRoger E. Beaty and Dan Richard Johnson. 2020. Au-\ntomating creativity assessment with semdis: An open\nplatform for computing semantic distance. Behavior\nResearch Methods, 53:757 – 780.\nRoger E. Beaty, Paul J. Silvia, Emily C. Nusbaum,\nEmanuel Jauk, and Mathias Benedek. 2014. The\nroles of associative and executive processes in cre-\native cognition. Memory & Cognition, 42(7):1186–\n1197.\nRoger E. Beaty, Daniel C. Zeitlen, Brendan S. Baker,\nand Yoed N. Kenett. 2021. Forward flow and creative\nthought: Assessing associative cognition and its role\nin divergent thinking. Thinking Skills and Creativity,\n41:100859.\nMarcel Binz and Eric Schulz. 2023. Using cognitive\npsychology to understand GPT-3. Proceedings of the\nNational Academy of Sciences, 120(6):e2218523120.\nPiotr Bojanowski, Edouard Grave, Armand Joulin, and\nTomas Mikolov. 2016. Enriching word vectors with\nsubword information. Transactions of the Associa-\ntion for Computational Linguistics, 5:135–146.\nSébastien Bubeck, Varun Chandrasekaran, Ronen El-\ndan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Pe-\nter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg,\nHarsha Nori, Hamid Palangi, Marco Tulio Ribeiro,\nand Yi Zhang. 2023. Sparks of Artificial General\nIntelligence: Early experiments with GPT-4. arXiv\ne-prints, page arXiv:2303.12712.\nWei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng,\nZhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan\nZhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion\nStoica, and Eric P. Xing. 2023. Vicuna: An Open-\nSource Chatbot Impressing GPT-4 with 90%* Chat-\nGPT Quality.\nEvan Crothers, Herna L. Viktor, and Nathalie Japkow-\nicz. 2023. In BLOOM: Creativity and Affinity in\nArtificial Lyrics and Art. In The AAAI-23 Workshop\non Creative AI Across Modalities.\nAlexandra DeLucia, Aaron Mueller, Xiang Lisa Li, and\nJoão Sedoc. 2021. Decoding Methods for Neural\nNarrative Generation. In Proceedings of the 1st Work-\nshop on Natural Language Generation, Evaluation,\nand Metrics (GEM 2021) , pages 166–185, Online.\nAssociation for Computational Linguistics.\nJan Digutsch and Michal Kosinski. 2023. Overlap in\nmeaning is a stronger predictor of semantic activa-\ntion in GPT-3 than in humans. Scientific Reports,\n13(1):5035.\nZhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding,\nJiezhong Qiu, Zhilin Yang, and Jie Tang. 2022. GLM:\nGeneral Language Model Pretraining with Autore-\ngressive Blank Infilling. In Proceedings of the 60th\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 320–335,\nDublin, Ireland. Association for Computational Lin-\nguistics.\nAngela Fan, Mike Lewis, and Yann Dauphin. 2018. Hi-\nerarchical Neural Story Generation. In Proceedings\nof the 56th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 889–898, Melbourne, Australia. Association\nfor Computational Linguistics.\nEmily Frith, Daniel B. Elbich, Alexander P. Christensen,\nMonica D. Rosenberg, Qunlin Chen, Michael J. Kane,\nPaul J. Silvia, Paul Seli, and Roger E. Beaty. 2021.\nIntelligence and creativity share a common cognitive\nand neural basis. Journal of Experimental Psychol-\nogy: General, 150:609–632.\nLiane Gabora and Scott Barry Kaufman. 2010. Evolu-\ntionary approaches to creativity. In The Cambridge\nHandbook of Creativity, pages 279–300. Cambridge\nUniversity Press, New York, NY , US.\nJ. Pv Guilford. 1964. Some new looks at the nature of\ncreative processes. Contributions to mathematical\npsychology. New York: Holt, Rinehart & Winston.\nJennifer Haase and Paul H. P. Hanel. 2023. Artifi-\ncial muses: Generative artificial intelligence chatbots\nhave risen to human-level creativity.\nJack Hessel, Ana Marasovic, Jena D. Hwang, Lillian\nLee, Jeff Da, Rowan Zellers, Robert Mankoff, and\nYejin Choi. 2023. Do Androids Laugh at Electric\nSheep? Humor “Understanding” Benchmarks from\nThe New Yorker Caption Contest. In Proceedings\nof the 61st Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 688–714, Toronto, Canada. Association for\nComputational Linguistics.\nAri Holtzman, Jan Buys, Li Du, Maxwell Forbes, and\nYejin Choi. 2020. The curious case of neural text de-\ngeneration. In International Conference on Learning\nRepresentations.\nSophie Jentzsch and Kristian Kersting. 2023. Chatgpt\nis fun, but it is not funny! humor is still challenging\nlarge language models.\nJean Kaddour, Joshua Harris, Maximilian Mozes, Her-\nbie Bradley, Roberta Raileanu, and Robert McHardy.\n2023. Challenges and Applications of Large Lan-\nguage Models. ArXiv:2307.10169 [cs].\n12886\nAndreas Köpf, Yannic Kilcher, Dimitri von Rütte,\nSotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens,\nAbdullah Barhoum, Nguyen Minh Duc, Oliver\nStanley, Richárd Nagyfi, Shahul ES, Sameer Suri,\nDavid Glushkov, Arnav Dantuluri, Andrew Maguire,\nChristoph Schuhmann, Huu Nguyen, and Alexan-\nder Mattick. 2023. OpenAssistant Conversations –\nDemocratizing Large Language Model Alignment.\nArXiv:2304.07327 [cs].\nBrenden M. Lake and Gregory L. Murphy. 2020. Word\nmeaning in minds and machines. Psychological re-\nview.\nClara Meister, Gian Wiher, Tiago Pimentel, and Ryan\nCotterell. 2022. On the probability–quality paradox\nin language generation. In Proceedings of the 60th\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 2: Short Papers), pages 36–45,\nDublin, Ireland. Association for Computational Lin-\nguistics.\nTomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S.\nCorrado, and Jeffrey Dean. 2013. Distributed repre-\nsentations of words and phrases and their composi-\ntionality. In Neural Information Processing Systems.\nGeorge A. Miller. 1995. WordNet: a lexical database\nfor English. Communications of the ACM, 38(11):39–\n41.\nShima Rahimi Moghaddam and Christopher J. Honey.\n2023. Boosting Theory-of-Mind Performance in\nLarge Language Models via Prompting.\nJay A. Olson, Johnny Nahas, Denis Chmoulevitch, Si-\nmon J. Cropper, and Margaret E. Webb. 2021. Nam-\ning unrelated words predicts creativity. Proceedings\nof the National Academy of Sciences, 118(25).\nOpenAI. 2022. Introducing ChatGPT.\nOpenAI. 2023. GPT-4 Technical Report.\nArXiv:2303.08774 [cs].\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\nCarroll Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, John\nSchulman, Jacob Hilton, Fraser Kelton, Luke Miller,\nMaddie Simens, Amanda Askell, Peter Welinder,\nPaul F. Christiano, Jan Leike, and Ryan Lowe. 2022.\nTraining language models to follow instructions with\nhuman feedback. Advances in Neural Information\nProcessing Systems, 35:27730–27744.\nYang Jeong Park, Daniel Kaplan, Zhichu Ren, Chia-Wei\nHsu, Changhao Li, Haowei Xu, Sipei Li, and Ju Li.\n2023. Can chatgpt be used to generate scientific\nhypotheses?\nJeffrey Pennington, Richard Socher, and Christopher\nManning. 2014. Glove: Global Vectors for Word\nRepresentation. In Proceedings of the 2014 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing (EMNLP), pages 1532–1543, Doha, Qatar.\nAssociation for Computational Linguistics.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog, 1(8):9.\nAditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey\nChu, and Mark Chen. 2022. Hierarchical text-\nconditional image generation with clip latents.\nMark A. Runco and Garrett J. Jaeger. 2012. The Stan-\ndard Definition of Creativity. Creativity Research\nJournal, 24(1):92–96.\nTobias Schnabel, Igor Labutov, David Mimno, and\nThorsten Joachims. 2015. Evaluation methods for\nunsupervised word embeddings. In Proceedings of\nthe 2015 Conference on Empirical Methods in Nat-\nural Language Processing, pages 298–307, Lisbon,\nPortugal. Association for Computational Linguistics.\nIlia Shumailov, Zakhar Shumaylov, Yiren Zhao, Yarin\nGal, Nicolas Papernot, and Ross Anderson. 2023.\nThe curse of recursion: Training on generated data\nmakes models forget.\nDavid Silver, Aja Huang, Chris J. Maddison, Arthur\nGuez, Laurent Sifre, George van den Driessche, Ju-\nlian Schrittwieser, Ioannis Antonoglou, Veda Pan-\nneershelvam, Marc Lanctot, Sander Dieleman, Do-\nminik Grewe, John Nham, Nal Kalchbrenner, Ilya\nSutskever, Timothy Lillicrap, Madeleine Leach, Ko-\nray Kavukcuoglu, Thore Graepel, and Demis Hass-\nabis. 2016. Mastering the game of go with deep neu-\nral networks and tree search. Nature, 529(7587):484–\n489. Number: 7587 Publisher: Nature Publishing\nGroup.\nDouglas Summers-Stay, Clare R. V oss, and\nStephanie M. Lukin. 2023. Brainstorm, then\nSelect: A Generative Language Model Improves\nIts Creativity Score. In The AAAI-23 Workshop on\nCreative AI Across Modalities.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal\nAzhar, Aurelien Rodriguez, Armand Joulin, Edouard\nGrave, and Guillaume Lample. 2023. LLaMA:\nOpen and Efficient Foundation Language Models.\nArXiv:2302.13971 [cs].\nHugh Zhang, Daniel Duckworth, Daphne Ippolito, and\nArvind Neelakantan. 2021. Trading Off Diversity\nand Quality in Natural Language Generation. In\nProceedings of the Workshop on Human Evaluation\nof NLP Systems (HumEval) , pages 25–33, Online.\nAssociation for Computational Linguistics.\nJingyi Zhang, Kaixiang Zhuang, Jiangzhou Sun, Cheng\nLiu, Li Fan, Xueyang Wang, Jing Gu, and Jiang Qiu.\n2023. Retrieval flexibility links to creativity: evi-\ndence from computational linguistic measure. Cere-\nbral Cortex, 33(8):4964–4976.\n12887\nA Selecting sample size for each model\nFigure 7 shows the sample size to generate sta-\nble results using top- p sampling for each model.\nWith confidence coefficient α = 0.05, standard\ndeviation ˆσ and error ϵ = 1, we choose N >\n(λα ×ˆσ/ϵ)2 = 1.962 ×ˆσ2. We find larger mod-\nels (GPT-4 and GPT-3.5-Turbo) generate answers\nmore stably.\nFigure 7: Results of the DAT across different sample\nsizes. The bands indicate the standard deviations.\nB Results of the DAT and surprisal on\nhuman and random and baselines\nFigure 8 shows the results of the DAT and surprisal\non human and random baselines. We find positive\nrelationship between surprisal and the DAT. Ran-\ndom baseline is a strong baseline that has maximal\nremote association (uniform distribution) despite\nwithout inhibition. Even so, we find some people\nsurpass random baseline and approach ceiling DAT\nat specific section of surprisal.\nFigure 8: Results of the DAT and surprisal on human\nand random baseline. Contours indicate the 95% confi-\ndence intervals.\nC Result of the DAT and surprisal for\nmore models using greedy search\nFigure 9 shows the results of the DAT and surprisal\nfor more LLMs using greedy search.\nFigure 9: Results of the DAT and surprisal for more\nLLMs. The contour indicate the 95% confidence inter-\nval.\nD Controlling surprisal as a confounding\nvariable\nConsidering the potential influence of word fre-\nquency on measuring semantic distance, we control\nsurprisal (Figure 10 ). The results are similar as\nbefore that GPT-4 and GPT-3.5-Turbo outperform\naverage human performance, while other models\nare below average human level. However, GPT-4\nas well as Oasst-Llama-30B lose their superiorities\nbecause their high DAT scores partially depend on\ngenerating rarer words.\nFigure 10: Results of the DAT when controlling sur-\nprisal as a confounding variable.\n12888",
  "topic": "Creativity",
  "concepts": [
    {
      "name": "Creativity",
      "score": 0.8376998901367188
    },
    {
      "name": "Computer science",
      "score": 0.6777946352958679
    },
    {
      "name": "Perspective (graphical)",
      "score": 0.6069151163101196
    },
    {
      "name": "Task (project management)",
      "score": 0.5613538026809692
    },
    {
      "name": "Association (psychology)",
      "score": 0.5086982846260071
    },
    {
      "name": "Face (sociological concept)",
      "score": 0.48365652561187744
    },
    {
      "name": "Natural language processing",
      "score": 0.47892650961875916
    },
    {
      "name": "Artificial intelligence",
      "score": 0.463315486907959
    },
    {
      "name": "Cognition",
      "score": 0.44829535484313965
    },
    {
      "name": "Semantics (computer science)",
      "score": 0.43857455253601074
    },
    {
      "name": "Cognitive psychology",
      "score": 0.376666784286499
    },
    {
      "name": "Psychology",
      "score": 0.2749483287334442
    },
    {
      "name": "Linguistics",
      "score": 0.1675940454006195
    },
    {
      "name": "Social psychology",
      "score": 0.09812536835670471
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Psychotherapist",
      "score": 0.0
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I76130692",
      "name": "Zhejiang University",
      "country": "CN"
    }
  ]
}