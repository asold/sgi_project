{
  "title": "LLM-Based Policy Generation for Intent-Based Management of Applications",
  "url": "https://openalex.org/W4389077350",
  "year": 2023,
  "authors": [
    {
      "id": null,
      "name": "Dzeparoska, Kristina",
      "affiliations": [
        "University of Toronto"
      ]
    },
    {
      "id": "https://openalex.org/A2748457934",
      "name": "Lin Jieyu",
      "affiliations": [
        "University of Toronto"
      ]
    },
    {
      "id": "https://openalex.org/A2750391455",
      "name": "Tizghadam, Ali",
      "affiliations": [
        "University of Toronto"
      ]
    },
    {
      "id": "https://openalex.org/A4287204365",
      "name": "Leon-Garcia, Alberto",
      "affiliations": [
        "University of Toronto"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4384157915",
    "https://openalex.org/W3036961695",
    "https://openalex.org/W3175380024",
    "https://openalex.org/W4384158036",
    "https://openalex.org/W2606832948",
    "https://openalex.org/W3214744430",
    "https://openalex.org/W3023027202",
    "https://openalex.org/W2968168257",
    "https://openalex.org/W1990911977",
    "https://openalex.org/W2997290241",
    "https://openalex.org/W6810081322",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W6850625674",
    "https://openalex.org/W4290996461",
    "https://openalex.org/W4205640019",
    "https://openalex.org/W4320015874",
    "https://openalex.org/W3038272788",
    "https://openalex.org/W4312980540",
    "https://openalex.org/W6798005000",
    "https://openalex.org/W3002683348",
    "https://openalex.org/W2734941459",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4385245566"
  ],
  "abstract": "Automated management requires decomposing high-level user requests, such as\\nintents, to an abstraction that the system can understand and execute. This is\\nchallenging because even a simple intent requires performing a number of\\nordered steps. And the task of identifying and adapting these steps (as\\nconditions change) requires a decomposition approach that cannot be exactly\\npre-defined beforehand. To tackle these challenges and support automated intent\\ndecomposition and execution, we explore the few-shot capability of Large\\nLanguage Models (LLMs). We propose a pipeline that progressively decomposes\\nintents by generating the required actions using a policy-based abstraction.\\nThis allows us to automate the policy execution by creating a closed control\\nloop for the intent deployment. To do so, we generate and map the policies to\\nAPIs and form application management loops that perform the necessary\\nmonitoring, analysis, planning and execution. We evaluate our proposal with a\\nuse-case to fulfill and assure an application service chain of virtual network\\nfunctions. Using our approach, we can generalize and generate the necessary\\nsteps to realize intents, thereby enabling intent automation for application\\nmanagement.\\n",
  "full_text": "LLM-based policy generation for intent-based\nmanagement of applications\nKristina Dzeparoska∗\nDepartment of Electrical and Computer Engineering\nUniversity of Toronto\nToronto, Ontario\nkristina.dzeparoska@mail.utoronto.ca\nJieyu Lin∗\nDepartment of Electrical and Computer Engineering\nUniversity of Toronto\nToronto, Ontario\njieyu.lin@mail.utoronto.ca\nAli Tizghadam\nDepartment of Electrical and Computer Engineering\nUniversity of Toronto\nToronto, Ontario\nali.tizghadam@utoronto.ca\nAlberto Leon-Garcia\nDepartment of Electrical and Computer Engineering\nUniversity of Toronto\nToronto, Ontario\nalberto.leongarcia@utoronto.ca\nAbstract—Automated management requires decomposing\nhigh-level user requests, such as intents, to an abstraction that the\nsystem can understand and execute. This is challenging because\neven a simple intent requires performing a number of ordered\nsteps. And the task of identifying and adapting these steps (as\nconditions change) requires a decomposition approach that can-\nnot be exactly pre-defined beforehand. To tackle these challenges\nand support automated intent decomposition and execution,\nwe explore the few-shot capability of Large Language Models\n(LLMs). We propose a pipeline that progressively decomposes\nintents by generating the required actions using a policy-based\nabstraction. This allows us to automate the policy execution by\ncreating a closed control loop for the intent deployment. To do so,\nwe generate and map the policies to APIs and form application\nmanagement loops that perform the necessary monitoring, analy-\nsis, planning and execution. We evaluate our proposal with a use-\ncase to fulfill and assure an application service chain of virtual\nnetwork functions. Using our approach, we can generalize and\ngenerate the necessary steps to realize intents, thereby enabling\nintent automation for application management.\n1\nI. I NTRODUCTION\nThe growing heterogeneous and distributed resources that\nsupport the plethora of services and applications can be chal-\nlenging to manage, in particular considering dynamic environ-\nments and strict application requirements such as availability,\nsecurity, and reliability. Human-based operations are prone\nto error, and time- and cost-sensitive. Automation is highly\ndesirable to relieve administrators from repetitive and tedious\nmanagement tasks, thereby keeping OpEx low, and focusing\ntheir attention on more complex problems. Recent advances\nin ML and AI can be leveraged to simplify these management\nefforts.\n*equal contribution\n1This article has been accepted for publication in 2023 19th International\nConference on Network and Service Management (CNSM), 3rd International\nWorkshop on Analytics for Service and Application Management (AnServApp\n2023), DOI: 10.23919/CNSM59352.2023.10327837\nAn intent defines a set of operational goals (that a system\nshould meet) and outcomes (that a system should deliver),\nwithout specifying how to achieve or implement them [1].\nIntent-based networking (IBN) or intent-based management\nseek to automate network and management tasks by allowing\nthe system to accept and realize user intents. Intents bring two\nmain requirements that are categorized by functionality into\nintent fulfillment and intent assurance. The former includes:\nfunctions such as translation, decomposition and execution;\nabstractions that capture system hierarchy (from top-level\napplications to low-level infrastructure devices) and provide a\nlogical view to support the intent-related functions. To ensure\nthat intents are continuously met during their life-cycle, and to\nprevent ”intent drift” [1], intent assurance requires the system\nto monitor and adapt the intent deployment accordingly. Fi-\nnally to close the loops for assurance and fulfillment, negative\nfeedback control loops can couple the required steps for the\nnecessary measurements, decisions and control.\nLarge Language Models (LLMs) provide powerful capa-\nbilities for Natural Language Processing (NLP) tasks, such\nas understanding, generating, and classification of text data.\nThis makes LLMs attractive as a solution in translation and\ndecomposition in intent processing. Moreover, LLM models\nare trained on massive datasets, which allows a model to learn\nand understand the contextual relationship in natural language\ndata. This is beneficial for intent-based management because\nis provides the ability to learn and adapt the steps required\nto realize intents. In this paper, we leverage the few-shot\nlearning capability of LLMs to generate progressively the steps\nto realize an intent. This approach can generalize to unseen\nintents and support dynamic environments, where pre-defined\nsequences of actions would fail.\nWe use a policy-based approach to capture and model\nthe relevant abstractions at each level of the management\nhierarchy. Our goal is to automatically decompose intents\ninto a sequence of policies that when executed will deploy\narXiv:2402.10067v1  [cs.DC]  22 Jan 2024\nthe intent. Our focus is on the capabilities of generic large\nlanguage models for intent-based application management.\nWe developed ”Emergence”, an intent based management\nsystem. In order to realize the notion that an intent specifies\n”what the user wishes the system to do, without specifying\nhow”, we implemented an LLM pipeline for progressive\ndecomposition of intents into policies, and then use mapping\nfunctions for policy-to-API resolution. Through this pipeline,\nEmergence determines the ”how” part of the intent. This\nallows Emergence to then proceed with intent deployment,\nand to support intent fulfillment and assurance.\nWe use a language model to understand natural language\ndata and context in order to derive the steps to realize an\nintent. These steps enable our system to gather the necessary\nmonitoring data, analyze the data based on current environ-\nment conditions, and accordingly create and execute a plan\nto deploy the intent onto the infrastructure. To link these\nsteps and execute the policies, we use feedback control loops\n(MAPE-K, monitor-analyze-plan-execute and knowledge [2]).\nWe evaluate Emergence in an intent use-case that involves a\nvirtual network function (VNF) service chain with high avail-\nability, consisting of a deep packet inspection tool and a load-\nbalancer. Our use-case demonstrates both intent fulfillment\nand assurance, by taking appropriate actions when issues are\ndetected to ensure that the intent is continuously met during\nits life-cycle.\nOur contributions in this paper are:\n• Propose the use of LLMs with few-shot learning for\nprogressive decomposition of intents into policies to\nsupport intent-based application management.\n• Evaluate the system on a cloud testbed and demonstrate\nintent fulfillment and assurance.\n• Discuss opportunities of generic LLMs for intent-based\nmanagement.\nII. B ACKGROUND AND RELATED WORK\nResearch in intent-based systems has focused on differ-\nent requirements, scopes, architectures, and approaches for\nthe intent-related tasks. Efforts by standardization bodies\nsuch as Internet Engineering Task Force (IETF), European\nTelecommunications Standards Institute (ETSI), International\nTelecommunication Union (ITU), and TM Forum, as well\nas in academia have considered the use of ML/AI, closed\ncontrol loops, abstractions (formal intent languages, policy\nmodels, etc.). Recent surveys discuss these research efforts,\nrequirements, and challenges [3]–[5].\nNatural-language processing (NLP) is required to translate\nand formalize intents. Recurrent neural networks, such as long\nshort-term memory (LSTM), have been used to translate in-\ntents [6]–[10]. These models extract the necessary information\nfrom the intent, which is then mapped to an abstraction model\nor language that the system understands in order to process\nthe intent. For example, LUMI [6] uses bidirectional LSTMs\nto extract entities and translate intents into an intent language\n(NILE), and then into configuration commands. LUMI has a\nchat-based interface (Google Dialogflow) for users to express\ntheir intents to the system. Other chat-based proposals include:\niNDIRA [11] uses NLP to construct semantic RDF graphs to\nunderstand, interact, and create the required network services;\nEVIAN [12], an extension of iNDIRA, uses the RASA NLP\ntool to translate intents. RASA is also used in [13], and\nDialogflow is used in [14] and [8].\nLarge language models (LLMs) such as GPT ( [15], [16]),\nPaLM [17] and LLaMA [18] are transformer-based models\nwith impressive capabilities for NLP tasks. These models\nare trained using massive amounts of text data, and have\nbillions of parameters. While both LSTMs and LLMs handle\ncontext in text, LLMs typically outperform LSTMs in large-\nscale language tasks due to a self-attention mechanism [19],\nthat provides a more flexible way of handling long-range\ndependencies in text. Moreover, LLMs are capable of few-shot\nlearning [16], which allows the model to learn to perform a\nnew task by simply training the model with several examples\nfor a given task at hand. ChatGPT by OpenAI uses the\nGenerative Pretrained Transformer (GPT) language model to\ngenerate responses to natural language inputs. Although these\nmodels are not trained for intent-based management tasks,\nthey can be useful tools for intent processing due to their\ncapabilities for few-shot learning. In [20], we explored this\ncapability to decompose intents into a set of Python APIs.\nHere, we leverage LLMs for intent to policy decomposition.\nAbstraction languages allow the modeling of an intent to\na formal model that the system can understand. Languages\nproposed for intent modeling include, NILE [6], SNIL [8],\nLAI [21]. We use the formal policy framework from our prior\nwork, [22] that allows us to model policies at different levels\nof abstractions across the system hierarchy. To promote the\nadoption of our policy framework, we created a mapping to\nthe Metro Ethernet Forum Policy Driven Orchestration Model\n(MEF PDO) [23], which is extensive and Y ANG-defined to\nsupport automation.\nIII. M ETHODOLOGY\nWe now describe the Emergence system for management of\nintent-based applications. In this paper we focus on the LLM\npipeline to decompose intents into a policy-based abstraction\nthat can be mapped to APIs for intent execution and deploy-\nment. Figure 1 gives an overview of the pipeline and its three\nstages. Each uses an LLM with few-shot learning. The first\nstage classifies intents into types known by the system. The\nsecond stage decomposes the intent and type into policies.\nThe third stage validates the policies for omissions or errors\nin the policy format, as well as for the correct ordering of\npolicies. Before discussing the pipeline in detail, we describe\nour policy-based abstraction.\nA. Policy model functional abstraction\nWe use a policy-based approach to provide the abstractions\nneeded at each level of the system hierarchy. We defined a\nformal policy framework in [22], to model different types of\npolicies (e.g., utility, goal, action) at different levels of abstrac-\ntions, and detect and resolve conflicts across the hierarchy.\nFig. 1. Pipeline overview: 1) classify intents to known intent types, 2) progressively decompose intents and generate policies: map each policy to an API,\nexecute the API and return the result to the LLM, 3) validate the policies. The resulting policy tree represents the sequence of derived policies from the intent.\nOur model formally defines Policy ⃗P as:\n⃗P = (D, E, A,⃗C). (1)\nwhere D denotes the policy definer that defines the policy, E\nis an entity or a group of entities that enforce the policy, and\nA is an action. ⃗C is a vector of constraints that apply to action\nA with regards to resources ( ⃗R), temporal ( ⃗T) and spatial ( ⃗S)\nconstraints, defined as:\n⃗C = (⃗R, ⃗T, ⃗S). (2)\nFor each policy ⃗P, we define policy metadata that includes the\npolicy ID, domain, expiration date, priority, and autonomic\npermission. To support implementation of our policies in\norder to execute and deploy intents, we have created mapping\nfunctions to convert our policies to our APIs and to the MEF\nPDO model.\nB. Intent Decomposition using few-shot learning\nOur goal is to decompose intents into policies with actions\nthat correspond to a MAPE-K closed control loop. We use our\npolicy model as an abstraction and train a generic LLM (Ope-\nnAI’s ChatGPT) using few-shot learning to generate policies\nfor user intents. In the few-shot part, we pass to the LLM\nan input message that generally contains: definitions (e.g.,\npolicy model) and descriptions, examples of intents and their\ncorresponding intent types and policy sequences, and LLM\nbehaviour specification (e.g., to act as a MAPE-K sequential\npolicy generator). We find that LLMs can generalize well and\nlearn to decompose intents, even with just a couple of intent\nto policy examples.\nThe generated policies represent the ordered sequence of\npolicies to process and deploy an intent at a given time. We\nrefer to this sequence as a policy tree (an example tree is\nshown in Figure 1). As an example, for an intent that calls\nfor the creation of a small virtual machine, the following\npolicy (one of the required policies) is needed to check for\navailability of 1 small virtual machine in Domain1: P =\n(avail, vm, zone= Domain1, size= small, count= 1).\nTo train the LLM we represent the policy as a JSON object as\nfollows: {”action” : ”avail :, ”resource” : ”vm”, ”zone” :\n”Domain1”, ”size” : ”small”, ”count” : 1}. This allows us\nto train the LLM to output the policies in the same format (key-\nvalue pairs), making it easier to integrate them into code. For\nexample, a dictionary data structure in Python allows us to map\nthe policy action to an API and include the remaining policy\nattributes. We note that we purposefully omit the Definer and\nEnforcer attributes from the policies for clarity. The Definer\nis the user or application that creates or manages the intent,\nand the Enforcer is the MAPE component that enforces the\npolicy. For example, for the above policy, the Definer is\n”Administrator” and the Enforcer is ”Analyze”.\n1) Intent Classification Stage: The first pipeline stage uses\nan LLM to classify intents into one or more intent types\nsupported by our system. To train the LLM with few-shot\nlearning, we provided the intent types supported in our system,\nexamples of intents and their corresponding intent types,\nand LLM behaviour specification (e.g., to act as an intent\nclassifier). An intent may contain one or more intent types.\nFor example, the intent: ”Create a small monitored VM\nin domain 1. ” is classified to the following types: create\nresource, schedule health check. The first type is for the set of\npolicies to create the VM. The second type is for the health\ncheck, since a VM cannot be monitored without having this\ncheck. Other intent types include: deploy service, start service,\nstop service, run service, discover resource, collect resource,\npublish resource, validate resource , etc. Figure 2 shows the\noutput of the classification results for three different intents.\nFig. 2. Example intent to intent type classification for the first stage.\n2) Progressive intent decomposition Stage: The second\npipeline uses an LLM to progressively decompose intents\ninto policies based on each policy’s execution result. The\nLLM is trained with few-shot learning to learn the steps\n(i.e., actions) required to deploy an intent, in a MAPE-\nbased fashion. For this, we provide the LLM with the policy\ndefinition, system supported actions, and example resources\nand constraints. Examples are shown in Figure 3. We also\nprovide typical sequences of actions required for the different\nintent types our system supports. For example, for the intent\ntype create resource, the sequence of actions per MAPE com-\nponent is: Monitor=[get], Analyze=[avail], Plan=[reserve],\nExecute=[create, validate] . To help the model learn how to\napply the above, we provide a couple of examples of intents,\nwith their respective intent types and policies. In Figure 4 we\nshow a few-shot training example that is provided to the LLM\nto learn the intent to policy progressive decomposition process.\nLastly, we specify the model’s behaviour by instructing the\nmodel to act as a MAPE-K policy generator that outputs\npolicies progressively, and uses the provided policy execution\nresult to determine the next policy.\nIn our implementation, once the LLM generates a policy,\nwe use mapping functions to convert the policy into an API.\nWe then execute the API, and provide the result to the LLM.\nNext the LLM proceeds with the next policy until it derives\nthe complete working sequence of actions (i.e., policy tree).\nDepending on the results and current conditions, the LLM\ncan either conclude with an ”END” message (indicating a\nsuccessful intent completion), or an ”ERROR” message.\n3) Intent Validation Stage: The last stage uses an LLM\nto validate the policy tree obtained from stage 2. We trained\nthe validation LLM by modifying the prompt used for the\ndecomposition LLM (stage 2), and included examples of\nincorrect policy sequences, and example corrections. This\ntrains the LLM to look for any omissions or errors in the\npolicy attributes, as well as incorrect policy sequences.\nIn the second stage of the pipeline, we test the policy\nexecution in a digital twin environment. We provide the intent,\nintent type, and generated policies to the validation LLM.\nOnce we have the final version of our policies, if any policies\nwere modified in stage 3, we test the intent again in our digital\ntwin. If there are no issues, we can safely deploy the intent\nFig. 3. Example policy actions, resources, and constraints.\nFig. 4. Few-shot training example for progressive decomposition of an Intent\nand its corresponding Intent type.\nin the production environment. we have a dedicated project\nfor the digital twin within our testbed, so we can test policy\ndeployments without affecting other domains.\nIV. E VALUATION AND USE-CASE\nWe evaluated the pipeline for intent-to-policy decomposition\nand execution in an intent use-case with intent fulfillment and\nassurance. The intent in the use-case is to deploy a service\nfunction chain that consists of Deep Packet Inspection, load-\nbalancer, and two web servers. The intent is:”Deploy a service\nfunction chain with high availability in Domain1 consisting\nof: a medium vm for the dpi service, a medium vm for the\nload-balancer service, and 2 small vms for the web servers. ”\nWe conduct our experiment using OpenStack in the SA VI\ntestbed which is composed of multiple domains, projects and\nregions. For example, the region we use to deploy the intent\nhas more than 23 physical servers that provide 800 vCPUs,\n4TB RAM, and close to 200TB storage. We performed 5 trials\nfor the fulfillment, and for the assurance, and we report on the\naverage time to fulfill and assure the use-case intent. We use\nthe ChatGPT API (GPT3.5 and GPT4 models) for the LLM\nfew-shot training and intent pipeline.\nA. Intent Fulfillment\nTo fulfill the intent, we pass it through the pipeline in Figure\n1. We first classify the intent and then obtain the following\nintent types: create resource, deploy service, availability. Next,\nthe intent and types are provided to the second stage, and\nprogressively decomposed into policies. For each decomposed\nFig. 5. Progressive policy generation and execution for intent fulfillment. Intent: ”Deploy a service function chain with high availability in Domain1 consisting\nof: a medium vm for the dpi service, a medium vm for the load-balancer service, and 2 small vms for the web servers”. Intent type: create resource, deploy\nservice, availability.\nFig. 6. Progressive policy generation and execution for intent assurance (second scenario).\npolicy, we map the policy to the corresponding API, and\nprovide the result of the execution to the LLM. The API is\nbased on the policy action, and policy resource and constraints\nare provided as parameters to the API. Figure 5 shows the\nresult of this stage. In summary, the LLM outputs policies\nto gather necessary data, check resource availability, make a\nreservation request, create and validate resources, deploy the\nservice function chain, and creates policies to enable monitor-\ning for high availability (i.e., schedule a health check, and set\nup notifications). If these actions complete successfully, the\nintent can be safely deployed (given that the validation stage\nalso completes successfully).\nB. Intent Assurance\nTo demonstrate assurance, we intentionally shut off the\nDPI VM to trigger the assurance. This was captured by\nthe health check, which sent a notification about the state\nof the monitored VMs to the Application Manager module\n(AppManagement). This module detects the intent drift (the\nstate of the DPI VM is ”Shutdown”, as opposed to ”Running”),\nand passes this message to the LLM to fix the intent. To test\nTABLE I\nINTENT EVALUATION ANALYSIS\nExecution Time (s) Number of policies\nIntent Fulfillment 338.9 11\nIntent Assurance 1 13.2 2\nIntent Assurance 2 85.7 10\nthe assurance capability of the LLM, we test two scenarios. In\nthe first scenario, we let the LLM successfully perform a start\naction for the DPI VM. In this case, two policies are executed:\nstart the VM, and validate the VM. In the second case, we\nprovide a negative result when trying to perform the start\naction, and in turn the LLM generates additional assurance-\nrelated policies: delete the VM, get necessary data and check\nresource availability again, make a reservation request, create\nand validate the VM, and last, update the service function\nchain. The result of the second scenario is shown in Figure 6.\nC. Evaluation Results and Analysis\nThe results from fulfillment and assurance are shown in\nFigures 7 and 8 respectively. We report the average times and\nthe number of generated policies to fulfill and assure the intent\n(for both assurance scenarios) in Table I. The execution results\nmostly depend on the time our testbed APIs take to complete\n(e.g., create VM). The time to receive a response using the\nChatGPT API is mostly negligible. Although not immediately\nevident, the policies help us quantify the hidden complexities\nwhen working with intents. For example, to fulfill the use-\ncase intent, 11 policies were generated, and these policies are\nessentially defining the main logic for how to realize the intent.\nConsidering that the policies get mapped to API calls, this\nmeans our policies abstract even more lines of code executed\nthrough the API calls.\nOne important aspect of an intent-based system is the\nability to generalize well, meaning that the system can handle\nmodified and unseen intents. From our evaluations, we find\nthat the LLM can handle this requirement well. For example,\nthe intent used for the few-shot example was simpler and\nhad different requirements compared to the use-case intent.\nHowever, the LLM was able to learn from the provided context\n(few-shot learning), such that it can generalize and decompose\nintents with unseen requirements. These results indicate that\ngeneric LLMs are very promising for intent-based applications\nand management.\nFig. 7. Result of the intent fulfillment.\nFig. 8. Result of the intent assurance.\nV. D ISCUSSION AND OPPORTUNITIES\nWe now discuss our insights and additional LLM opportuni-\nties for intent-based applications, lessons learned, limitations,\nand future work.\nA. LLMs for additional conversions\nIn this paper, we demonstrated that LLMs can be used\nto decompose intents into a high-level abstraction, such as\na policy. Per our policy framework, the policies specify the\nactions, resources, and constraints to be applied. However,\nto execute these policies, we either need to map them to a\nlanguage that supports implementation, such as Y ANG (e.g.,\nto the MEF PDO policy model), or to a corresponding API.\nIn this work, we use separate mapping functions in our\nimplementation to map policies into APIs. However, an LLM\ncan also be trained to be able to convert policies into other\nformal languages, including programmable code, e.g., Python\nAPIs. The benefit of deriving the policies first, is that it allows\nus to obtain the intent workflow, i.e., the set of steps to fulfill\nor assure intents in a MAPE loop.\nIn our prior work (Emergence), we use a set of pre-\ndefined Finite State Machines (FSM) to execute policies.\nHowever, it would be more beneficial to be able to dynamically\ngenerate these FSMs. In this manner, the system would be\nable to execute new, unseen intents, provided that the required\nfunctions (e.g., APIs) are available. One approach to creating\ndynamic, on-demand FSMs, would be to train a generic LLM\nto create Boolean-Logic Decision Trees from the policies, and\nthen convert these trees into Finite State Machines.\nB. Lessons Learned\nAn important consideration for LLMs with few-shot learn-\ning include over-training and under-training. It is worth noting\nthat we do not modify the weights of the model, but instead\nprovide descriptions, definitions, and usage examples as input\nto the model, so that the underlying Transformer architecture\ncan learn to decompose intents into policies. The goal is to\nbe able to train the model to generalize well, in order to\nconsistently generate policies that are correct and work as\nintended. To help generalize better, before a new intent is\nreceived, we clear the conversation history, and we send the\ntraining prompt to the model. If the training prompt contains\ntoo many details, it can confuse the LLM, or it can cause the\nLLM to output exactly as per the prompt (even if incorrect).\nIf there is too little information, the LLM can begin to deviate\nand create new attributes or entities (e.g., actions, constraints,\nresources) that are irrelevant to the system.\nIn this paper, we provide simple results back to the LLM\nupon the execution of a policy, for example, a Boolean value\n(True, False). If more information is provided to the model,\nsuch as some details from the execution, then the LLM could\nmodify the policy constraints accordingly in an attempt to meet\nthe intent. For example, if a policy asks for a large size VM,\nor a specific version of an image, and these are not available,\nthen, if the LLM receives information about other available\nsizes and images as part of the result, the LLM will select\nthe best option, e.g., a medium VM, and an image version as\nclose as possible to the original intent version requested. This\nshows that we can further improve the reasoning logic for the\nLLM, for example by embedding specific algorithms as part\nof the few-shot training. In this way, the LLM can play an\neven bigger role in management.\nC. Limitations and Future Work\nAlthough we demonstrated that a generic large language\nmodel can be very efficient in decomposing intents using few-\nshot learning, there are a number of challenges to consider:\n• Validation is important to ensure that the policies capture\nthe desired behaviour. This requires validating the poli-\ncies in terms of the format, proper sequence, correctness\nand omissions of attributes. For this, we can train an LLM\nto look for these types of issues. Second, we need to\ncheck for logic and algorithmic issues. For this, we can\nleverage FSMs to ensure correct state transitions, and that\nthe final state matches the intent’s desired state. Finally,\nit is desirable to use a combination of simulators and\nemulators to create a real digital twin environment.\n• The transformer model comes with context length limita-\ntion, i.e., the number of tokens that the model can attend\nto. This limits how far the transformer can look back\nin the conversation history. As such, this also limits the\nsize of the training prompt. However, recent models are\nincreasing the context limit, e.g., GPT3.5 supports 4096\ntokens, and GPT4 variants offer 8k or 32k.\n• The Boolean results provided to the LLM can inadver-\ntently cause the LLM to relax some important constraints,\nor even start generating policies that deviate from the\nuser’s intent (i.e., beyond the scope) as the LLM tries to\n”desperately” meet the intent. Therefore, it is important\nto carefully craft the intent, for example by using specific\npointer words such as shall, must, should to ”limit” the\nLLM’s efforts. For example, consider an intent to use a\npath between two nodes with some specific requirements.\nIf such a path is not available currently, the LLM might\ntry to use actions such as engineering the traffic, or even\nthe network, if the previous attempt fails. This is a major\noverreaction to a simple intent.\nVI. C ONCLUSIONS\nIn this paper, we focused on leveraging a generic LLM\nin our Emergence system for intent-based management and\napplications. Specifically, we proposed using LLMs with few-\nshot learning to enable progressive policy generation, driven\nby policy execution results. We considered both intent ful-\nfillment and assurance, and our results indicate that LLMs are\nvery promising in attaining our goal to enable automatic intent\ndecomposition for application management.\nREFERENCES\n[1] A. Clemm, L. Ciavaglia, L. Z. Granville, and J. Tantsura, “Intent-Based\nNetworking - Concepts and Definitions,” RFC 9315, Oct. 2022.\n[Online]. Available: https://www.rfc-editor.org/info/rfc9315\n[2] J. Kephart and D. Chess, “The vision of autonomic computing,” Com-\nputer, vol. 36, no. 1, pp. 41–50, 2003.\n[3] A. Leivadeas and M. Falkner, “A survey on intent-based networking,”\nIEEE Communications Surveys & Tutorials, vol. 25, no. 1, pp. 625–655,\n2023.\n[4] E. Zeydan and Y . Turk, “Recent advances in intent-based networking: A\nsurvey,” in2020 IEEE 91st Vehicular Technology Conference (VTC2020-\nSpring), 2020, pp. 1–5.\n[5] L. Pang, C. Yang, D. Chen, Y . Song, and M. Guizani, “A survey on\nintent-driven networks,” IEEE Access, vol. 8, pp. 22 862–22 873, 2020.\n[6] A. S. Jacobs, R. J. Pfitscher, R. H. Ribeiro, R. A. Ferreira, L. Z.\nGranville, W. Willinger, and S. G. Rao, “Hey, lumi! using natural\nlanguage for {intent-based} network management,” in 2021 USENIX\nAnnual Technical Conference (USENIX ATC 21) , 2021, pp. 625–639.\n[7] Y . Ouyang, C. Yang, Y . Song, X. Mi, and M. Guizani, “A brief survey\nand implementation on refinement for intent-driven networking,” IEEE\nNetwork, vol. 35, no. 6, pp. 75–83, 2021.\n[8] M.-T.-A. Nguyen, S. B. Souihi, H.-A. Tran, and S. Souihi, “When nlp\nmeets sdn : an application to global internet exchange network,” in ICC\n2022 - IEEE International Conference on Communications , 2022, pp.\n2972–2977.\n[9] C. Yang, X. Mi, Y . Ouyang, R. Dong, J. Guo, and M. Guizani, “Smart\nintent-driven network management,” IEEE Communications Magazine ,\nvol. 61, no. 1, pp. 106–112, 2023.\n[10] N. Vedula, N. Lipka, P. Maneriker, and S. Parthasarathy, “Open intent\nextraction from natural language interactions,” in Proceedings of The\nWeb Conference 2020, 2020, pp. 2009–2020.\n[11] M. Kiran, E. Pouyoul, A. Mercian, B. Tierney, C. Guok, and I. Monga,\n“Enabling intent to configure scientific networks for high performance\ndemands,” Future Generation Computer Systems , vol. 79, pp. 205–214,\n2018.\n[12] H. Mahtout, M. Kiran, A. Mercian, and B. Mohammed, “Using machine\nlearning for intent-based provisioning in high-speed science networks,”\nin Proceedings of the 3rd International Workshop on Systems and\nNetwork Telemetry and Analytics , 2020, pp. 27–30.\n[13] C. H. Cesila, R. P. Pinto, K. S. Mayer, A. F. Escall ´on-Portilla, D. A. A.\nMello, D. S. Arantes, and C. E. Rothenberg, “Chat-ibn-rasa: Building\nan intent translator for packet-optical networks based on rasa,” in 2023\nIEEE 9th International Conference on Network Softwarization (NetSoft),\n2023, pp. 534–538.\n[14] M. Bezahaf, E. Davies, C. Rotsos, and N. Race, “To all intents\nand purposes: Towards flexible intent expression,” in 2021 IEEE 7th\nInternational Conference on Network Softwarization (NetSoft), 2021, pp.\n31–37.\n[15] OpenAI, “Gpt-4 technical report,” 2023.\n[16] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal,\nA. Neelakantan, P. Shyam, G. Sastry, A. Askell et al., “Language mod-\nels are few-shot learners,” Advances in neural information processing\nsystems, vol. 33, pp. 1877–1901, 2020.\n[17] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts,\nP. Barham, H. W. Chung, C. Sutton, S. Gehrmann et al., “Palm: Scaling\nlanguage modeling with pathways,” arXiv preprint arXiv:2204.02311 ,\n2022.\n[18] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux,\nT. Lacroix, B. Rozi `ere, N. Goyal, E. Hambro, F. Azhar et al. ,\n“Llama: Open and efficient foundation language models,” arXiv preprint\narXiv:2302.13971, 2023.\n[19] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nŁ. Kaiser, and I. Polosukhin, “Attention is all you need,” Advances in\nneural information processing systems , vol. 30, 2017.\n[20] J. Lin, K. Dzeparoska, A. Tizghadam, and A. Leon-Garcia, “Apple-\nseed: Intent-based multi-domain infrastructure management via few-\nshot learning,” in 2023 IEEE 9th International Conference on Network\nSoftwarization (NetSoft). IEEE, 2023, pp. 539–544.\n[21] B. Tian, X. Zhang, E. Zhai, H. H. Liu, Q. Ye, C. Wang, X. Wu, Z. Ji,\nY . Sang, M. Zhanget al., “Safely and automatically updating in-network\nacl configurations with intent language,” in Proceedings of the ACM\nSpecial Interest Group on Data Communication , 2019, pp. 214–226.\n[22] K. Dzeparoska, N. Beigi-Mohammadi, A. Tizghadam, and A. Leon-\nGarcia, “Towards a self-driving management system for the automated\nrealization of intents,” IEEE Access, vol. 9, pp. 159 882–159 907, 2021.\n[23] “MEF Standard (95), Policy Driven Orchestration (PDO),” Metro\nEthernet Forum, July 2021. [Online]. Available: https://www.mef.net/\nwp-content/uploads/MEF-95.pdf",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8461238145828247
    },
    {
      "name": "Abstraction",
      "score": 0.6596614718437195
    },
    {
      "name": "Task (project management)",
      "score": 0.6506021022796631
    },
    {
      "name": "Pipeline (software)",
      "score": 0.6303489804267883
    },
    {
      "name": "Decomposition",
      "score": 0.6302232146263123
    },
    {
      "name": "Software deployment",
      "score": 0.6235985159873962
    },
    {
      "name": "Automation",
      "score": 0.5531653761863708
    },
    {
      "name": "Software engineering",
      "score": 0.47014978528022766
    },
    {
      "name": "Service (business)",
      "score": 0.4640658497810364
    },
    {
      "name": "Distributed computing",
      "score": 0.4540286362171173
    },
    {
      "name": "Simple (philosophy)",
      "score": 0.4144028127193451
    },
    {
      "name": "Programming language",
      "score": 0.25529617071151733
    },
    {
      "name": "Systems engineering",
      "score": 0.12802338600158691
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Mechanical engineering",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Economy",
      "score": 0.0
    },
    {
      "name": "Engineering",
      "score": 0.0
    },
    {
      "name": "Epistemology",
      "score": 0.0
    },
    {
      "name": "Ecology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I185261750",
      "name": "University of Toronto",
      "country": "CA"
    }
  ]
}