{
  "title": "A predictive language model for SARS-CoV-2 evolution",
  "url": "https://openalex.org/W4405686552",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A3153043443",
      "name": "Enhao Ma",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2103628873",
      "name": "Xuan Guo",
      "affiliations": [
        "Tsinghua University",
        "Shenzhen Bay Laboratory"
      ]
    },
    {
      "id": "https://openalex.org/A2433265817",
      "name": "Mingda Hu",
      "affiliations": [
        "Beijing Fengtai Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2106018743",
      "name": "Peng-Hua Wang",
      "affiliations": [
        "UConn Health"
      ]
    },
    {
      "id": "https://openalex.org/A2045332956",
      "name": "Xin Wang",
      "affiliations": [
        "Beijing Fengtai Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2100316019",
      "name": "Congwen Wei",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2091798863",
      "name": "Gong Cheng",
      "affiliations": [
        "Shenzhen Bay Laboratory",
        "Beijing Fengtai Hospital",
        "Tsinghua University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3046463683",
    "https://openalex.org/W4281687993",
    "https://openalex.org/W4292230072",
    "https://openalex.org/W4315865871",
    "https://openalex.org/W4225492776",
    "https://openalex.org/W4297231396",
    "https://openalex.org/W4283831060",
    "https://openalex.org/W3126729284",
    "https://openalex.org/W4324380305",
    "https://openalex.org/W4293746450",
    "https://openalex.org/W3089439163",
    "https://openalex.org/W3088823112",
    "https://openalex.org/W4317212025",
    "https://openalex.org/W4220777055",
    "https://openalex.org/W4309730059",
    "https://openalex.org/W4283026725",
    "https://openalex.org/W3144701084",
    "https://openalex.org/W3166142427",
    "https://openalex.org/W3121000782",
    "https://openalex.org/W4210651320",
    "https://openalex.org/W1971784866",
    "https://openalex.org/W3193682077",
    "https://openalex.org/W2461540377",
    "https://openalex.org/W4318203485",
    "https://openalex.org/W4296211388",
    "https://openalex.org/W4376223660",
    "https://openalex.org/W4311278799",
    "https://openalex.org/W4387540805",
    "https://openalex.org/W4380577051",
    "https://openalex.org/W4210494137",
    "https://openalex.org/W4226357916",
    "https://openalex.org/W4309686974",
    "https://openalex.org/W4312173692",
    "https://openalex.org/W4311359167",
    "https://openalex.org/W4310828358",
    "https://openalex.org/W4367838604",
    "https://openalex.org/W2921374350",
    "https://openalex.org/W4220889269",
    "https://openalex.org/W4304731451",
    "https://openalex.org/W2071336075",
    "https://openalex.org/W3152577942",
    "https://openalex.org/W4226470088",
    "https://openalex.org/W4312019047",
    "https://openalex.org/W4224950216",
    "https://openalex.org/W3126567347"
  ],
  "abstract": null,
  "full_text": "ARTICLE OPEN\nA predictive language model for SARS-CoV-2 evolution\nEnhao Ma1, Xuan Guo1,2 ✉, Mingda Hu3, Penghua Wang 4, Xin Wang3, Congwen Wei3 ✉ and Gong Cheng 1,2 ✉\nModeling and predicting mutations are critical for COVID-19 and similar pandemic preparedness. However, existing predictive\nmodels have yet to integrate the regularity and randomness of viral mutations with minimal data requirements. Here, we develop a\nnon-demanding language model utilizing both regularity and randomness to predict candidate SARS-CoV-2 variants and mutations\nthat might prevail. We constructed the“grammatical frameworks” of the available S1 sequences for dimension reduction and\nsemantic representation to grasp the model’s latent regularity. The mutational proﬁle, deﬁned as the frequency of mutations, was\nintroduced into the model to incorporate randomness. With this model, we successfully identiﬁed and validated several variants\nwith signiﬁcantly enhanced viral infectivity and immune evasion by wet-lab experiments. By inputting the sequence data from\nthree different time points, we detected circulating strains or vital mutations for XBB.1.16, EG.5, JN.1, and BA.2.86 strains before their\nemergence. In addition, our results also predicted the previously unknown variants that may cause future epidemics. With both the\ndata validation and experiment evidence, our study represents a fast-responding, concise, and promising language model,\npotentially generalizable to other viral pathogens, to forecast viral evolution and detect crucial hot mutation spots, thus warning\nthe emerging variants that might raise public health concern.\nSignal Transduction and Targeted Therapy          (2024) 9:353 ; https://doi.org/10.1038/s41392-024-02066-x\nINTRODUCTION\nSevere acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has\nsparked waves of coronavirus disease 2019 (COVID-19) pandemics,\nposing an ongoing threat to global health.\n1,2 Despite the\npersistent effort to develop vaccines, antiviral drugs, and antibody\ntherapies, a signiﬁcant obstacle for current COVID-19 pharmaceu-\ntical interventions arises from the rapid mutations in SARS-CoV-2\nproteins, especially the spike (S) protein.\n3– 5 Multiple mutations in\nSARS-CoV-2 proteins emerged as the pandemic progressed,6 some\nof which increased the virus’s binding afﬁnity to ACE2 and evade\nimmunity.7– 11 The viral protein mutations result in the evolution of\nthe virus, thereby partly driving the spread of successive\npandemic waves.12– 15 As a highly concerning lineage, Omicron\nemerged in November 2021, and its subvariant BA.1 rapidly\nsubstituted the prevailing Delta strains.\n16 Subsequently, multiple\nOmicron subvariants, including BA.2, BA.4, BA.5, BQ.1, XBB, CH1.1,\nEG.5, JN.1, KP.2, KP.3, XDV.1, and LN.1 promptly rise into the stage\nof the world, developing even stronger host immune evasion\nproperties.\n2,17,18 Given the ongoing mutations in SARS-CoV-2 and\nthe presence of several VOI (variants of interest), the ability to\npredict key mutations that contribute to immune escape and viral\ninfectivity is of utmost importance for disease prevention.\nBiomedicine is undergoing a revolutionary change, thanks to\nthe technological advancements of artiﬁcial intelligence. Studies\nhave represented the available viral sequences as letter strings\n19\nand assessed the grammar and semantic ﬁtness of the present\nsequences using natural language processing (NLP). 20– 23 For\ninstance, Hie et al. have demonstrated that the same principles\nused to train a language model on a sequence of English words\ncan also be applied to a sequence of amino acids. As a mutant\nvirus must retain its infectivity and evolutionaryﬁtness to escape,\nit must adhere to a“grammar” of biological rules.\n21 In a similar\nvein, we analogize the protein motifs and domains to human\nlanguages, such as words, phrases, and sentences, for modeling\nanalysis and prediction. Like all other species, though mutation\noccurs inevitably, proteins in viruses like SARS-CoV-2 still have\ntheir more conservative sites and less conservative sites. By\nanalyzing the amino acid features of mutation occurrence, some\nstudies predicted the mutations that preserve infectivity and\nﬁtness, potentially revealing the mutations with more preva-\nlence.\n6,24 For instance, all Omicron subvariants, including the most\nrecent JN.1 and EG.5, possess the K417N substitution, which\nfacilitates the virus to escape from humoral immunity,9 suggesting\nthat this mutation may persist in future variants. Nevertheless,\nmutations also occur in a random pattern,25 resulting in speciﬁc\nmutations in a short period. The F486V, K444T, and F456L\nmutations, for example, were rarely found in BA.1, BA.2, BA.4,\nand BA.5 Omicron subvariants but emerged rapidly in the\nsubsequent prevalent subvariants (e.g., BQ.1 and BQ.1.1).\n26\nGiven the limitations of current studies in predicting mutations\nbased solely on present viral sequences,6 our research designs a\ndelicate language model, named the semantic model for variants\nevolution prediction (SVEP), incorporating both the conservative\nregularity and unconservative randomness of combinatorial\nmutations to forecast the sequences of upcoming SARS-CoV-2\nvariants. It allows us to forecast the sequences of upcoming SARS-\nCoV-2 variants without the need for information on phylogenetic\ntrees, deep mutational scanning (DMS), or 3D protein structure.\nReceived: 22 August 2024 Revised: 5 November 2024 Accepted: 13 November 2024\n1School of Basic Medical Science, Tsinghua University, 30 Shuangqing Rd., Haidian District, Beijing 100084, China;2Institute of Infectious Diseases, Shenzhen Bay Laboratory,\nGuangqiao Rd., Guangming District, Shenzhen, Guangdong 518000, China; 3Beijing Institute of Biotechnology, 20 Dongdajie, Fengtai District, Beijing 100071, China and\n4Department of Immunology, School of Medicine, University of Connecticut Health Center, Farmington, CT 06030, USA\nCorrespondence: Xuan Guo (15210418734@163.com) or Congwen Wei (weicongwen@aliyun.com) or Gong Cheng (gongcheng@mail.tsinghua.edu.cn)\nThese authors contributed equally: Enhao Ma, Xuan Guo.\nwww.nature.com/sigtransSignal Transduction and Targeted Therapy\n© The Author(s) 2024\n1234567890();,:\nWe then validated our predictions using an HIV-1 pseudovirus\nassay incorporating SARS-CoV-2 S protein.\nTwo major barriers to eliminating or alleviating the continuous\nexplosion of COVID-19 and other viral pandemics are pathogens’\nnature of constant mutation and the prolonged time consumption of\nvaccine development. The latter causes the updated vaccine to be\nunable to catch up with the viral mutation rate. Therefore, predicting\nthe potential variants that would prevail is crucial for the vaccines to\nkeep pace with the viral mutation, similar to the “Red Queen\nHypothesis.” The structure of our model signiﬁcantly enhances data\nprocessing efﬁciency and reduces the consumption of computational\nresources, enabling the model to more effectively simulate combi-\nnatorial mutations. Therefore, our model has a unique advantage for\npredicting the emerging variants in a timely manner, aiding the fast\nresponse of vaccine development. Moreover, the results of this study\nprovide potential insights into future SARS-CoV-2 variants, thereby\nsigniﬁcantly contributing to the development of COVID-19 interven-\ntions and potentially extendingto other potential pandemics.\nRESULTS\nEstablishing a language model for the combinatorial mutations in\nSARS-CoV-2 Omicron sequences\nThere are mainly three main steps for our model construction,\nwhich are the derivation of“grammatical framework” to construct\ndata’s regularity, the introduction of the “mutational proﬁle” to\nincorporate random mutations, and a screening model to exclude\nthe sequences with minimal likelihood to emerge in the real-\nworld. Initially, we collected the sequences of the S1 peptide in\nSARS-CoV-2 Omicron variants from April 15th, 2022, to September\n15th, 2022, and then performed multiple sequence alignments.\nInterestingly, September 2022 is the time when theﬁrst omicron\nwaves ended, and April 2022 is the time when the BA.2 wave is at\nits peak. The Omicron S1 sequence data from the 14th to the\n685th residues\n1 for those ﬁve months were subsequently\nextracted as the dataset-1 (Supplementary Fig. 1a). Subsequently,\nto separate the conservative and unconservative part of the S\nprotein and further reduce the data dimension space, we deﬁned\nthe stability of an amino acid site in S1 sequences by Three Days’\nFrequency (TDF), which is the percentage of amino acid for a\nresidue site within three successive days. The residue with the\nhighest TDF was deﬁned as the dominant residue of each residue\nsite (Supplementary Fig. 2a). Compared to other deﬁnitions of\nconservation such as the phylogenic tree, the concept of TDF\nallows us to include the latent information into account just as\nother techniques, and it is much easier and faster than\nconstructing the phylogenetic tree since we need a validated\nmodel for the tree construction which costs time. The sites\nexhibiting signiﬁcant variation ( > 0.09) in the TDF of the dominant\nresidue over time were identiﬁed as the“hot spots” (Fig. 1a and\nSupplementary Fig. 2b, c). As a result, we deﬁned 84 hot spots and\n588 non-hot spots in the S1 sequences of SARS-CoV-2 Omicron\n(Supplementary Fig. 2d). To reduce further the dimension of the\nhot spot data and mimic the natural human language, we decided\nto employ a clustering approach. We initially grouped the related\nhot spots, forming the“word clusters,” and subsequently grouped\nthe “word clusters ” into “sentence clusters ” and “sentence\nclusters” into “paragraph clusters” (Fig. 1a and Supplementary\nFigs. 3– 5). The“word clusters,”“ sentence clusters,” and “paragraph\nclusters” comprised the so-called “grammatical frameworks” of\ndataset-1 (Fig.1a and Supplementary Fig. 6). Noteworthy,“words,”\n“sequences,” and “paragraphs” structures could capture the long-\nrange interaction between nucleic acids as they are deﬁned and\nclustered by shared latent pattern but not the physical distance in\nthe sequences. The frameworks served as a simpli ﬁ\ned and\nstructured representation of the hot spot data, enabling us to\nanalyze the regularity of the combinatorial mutations in the\nS1 sequences of the Omicron variant more effectively and\nintuitively. Thus, the model can grab the data’s latent pattern\nand the conservative information more ef ﬁciently from the\nvariants’ evolution, easing the model’s processing time.\nWe construct the regularity based on the framework after\nderiving “grammatical frameworks” from the inputting dataset-1\n(Fig. 1a and Supplementary Fig. 6). To simulate the amino acids at\neach hot spot, we employed the Monte Carlo (MC) simulation,\nknown for generating random outcomes based on occurrence\nfrequencies, to simulate the amino acids at each hot spot (Fig.1a).\nIn the dataset-1, we observed that each amino acid was frequently\nassociated with a speciﬁc set of co-occurring amino acids within\neach cluster, forming the collocation of amino acids (Fig.1a). This\ncollocation is seen within each level of“word cluster,”“ sentence\ncluster,” and “paragraph cluster”. The simulation is thus based on\nthe constructed“framework” (See in Methods). To ensure that the\ngenerated amino acids align with the observed conditional\nfrequency and adhere to the co-occurrence patterns in dataset-\n1, we constrained the collocations of amino acids within each\ncluster (Fig.1a). For example, as the combination of amino acids I\nand G had never appeared together in one cluster, we would\nexclude the possibility of this collocation during the simulation.\nConsidering co-occurrence patterns of mutations within the same\ncluster enhanced the accuracy of the generated amino acids\nwithin each cluster. By incorporating these constraints and\nutilizing the MC simulation technique, we grant our model with\nthe regularity of combinatorial mutations (Fig.1a).\nDespite the regularity in viral evolution, combinatorial muta-\ntions also include random events, and without including the\nrandomness, the model could only generate sequences that have\nalready emerged. There needs to be more than just identifying the\nregularity pattern of viral evolution to build a prediction model.\nThus, we aim to simulate the randomness of the mutations by\nintroducing a new variable named mutational proﬁle to generate\ncombinatorial mutations (Fig.1b). Mutational proﬁle is deﬁned as\na variable that determines the frequency of mutations. It refers to\nthe combined effect of all the mutational processes that resulted\nin the accumulation of the observed mutations, yet we might\nknow what those latent effects are and how they interact to\nprovide theﬁnal mutation frequency. The mutational proﬁle drives\nthe occurrence of random mutations and thus generates a wide\nvariety of possible viral sequences that may or may not have\nappeared before. Subsequently, we assessed the evolutionary\nﬁtness of the combinatorial mutations to dataset-1 by a language\nmodel to identify and remove the sequences with lowerﬁtness,\nthat is, unlikely to be a natural sequence.\n21 For example, the\nsequence must obey the latent“grammar” of biological rules to\nachieve high ﬁtness. The Bi-directional Long Short-Term Memory\n(Bi-LSTM) language model, capable of accessing the information\nforward and backward to capture more latent features compared\nto regular LSTM,\n21 was trained based on the inputting data,\ndataset-1 in that case (Fig.1b). By inputting the amino acids, the\nBi-LSTM model generated an emotional score representing how\nwell the sequence aligns with the training data (Fig. 1b). The\n“paragraph clusters” with a negative emotional score, indicating\nlower ﬁtness to the training data, were deﬁned as sequences with\n“syntax errors” and removed as they were unlikely to represent the\nlatent pattern of the viral evolution. This screening process\nallowed us to retain only the sequences with higher ﬁtness,\nensuring that the generated sequences adhered to the“gramma-\ntical frameworks” and accurately represented the regularity and\nrandomness of combinatorial mutations. Thus, our evolutionary\nlanguage model represents a potential tool for understanding the\nregularity and randomness of mutations.\nValidating the language model with existing SARS-CoV-2 variants\nand predicting potential future SARS-CoV-2 variants\nAfter establishing this evolutionary language model and before\nmaking the prediction, we need to conduct a comprehensive\nA predictive language model for SARS-CoV-2 evolution\nMa et al.\n2\nSignal Transduction and Targeted Therapy           (2024) 9:353 \nvalidation for our model using the available SARS-CoV-2 Omicron\nvariants. The validation aims to determine whether our model\ncould accurately represent the regularity of combinatorial muta-\ntions in sequences in dataset-1 after clustering into the\n“grammatical framework. ” We wanted to check if we could\nsimulate dataset-1 back using the“grammatical framework” after\nthe dimension reduction to prove that our model retained most of\nthe essential information of data. For this purpose, we performed\nFig. 1 Modeling the combinatorial mutations in SARS-CoV-2 Omicron sequences.a The schematic diagram for determining the“grammatical\nframeworks” and modeling the sequences in dataset-1 based on the“grammatical frameworks”. The orange solid circles denote the hot spots.\nThe black, green, and blue dashed circles denote the“word clusters,”“ sentence clusters,” and “paragraph clusters,” respectively, and they\nformed the so-called “grammatical framework.” Monte Carlo simulation simulates the residues at each hot spot with the constraint of\ncollocation of amino acids. For example, as the combination of amino acids I and G had never appeared together in one cluster, we would\nexclude the possibility of this collocation.b The schematic diagram for modeling the future sequences. Mutational proﬁle is introduced to\nchange the occurrence frequency of mutation at hot spots (for example, change the occurrence frequency of mutation from 0.3 to 0.5). Bi-\nLSTM language models are used for screening to exclude the generated sequences with lowﬁtness based on the prior data. The input data\nwere the amino acids within a“paragraph cluster”. The output layer exports a positive or negative score of the amino acid cluster, and only the\nsequences with positive scores are outputted\nA predictive language model for SARS-CoV-2 evolution\nMa et al.\n3\nSignal Transduction and Targeted Therapy           (2024) 9:353 \n10,000 simulations at each hot spot using the model to generate\nsequences based on the framework built on dataset-1. During the\nvalidation process, the simulated sequences were compared to\nthe actual variants observed in dataset-1 to evaluate how well the\nmodel-generated sequences aligned with the real-world viral\nsequences. The results showed that 67.7% of the simulated\nsequences matched the sequences in dataset-1, meaning only\n32.3% of them did not match with any known lineages, indicating\nthat the model successfully captured the underlying regularity of\ncombinatorial mutations (Fig. 2a). For here, variants are not\nlineages as different variants might be included in the same\nlineage or sublineage. The identiﬁed variants, such as BA.5.2.1,\nBA.2.12.1, BA.2, BA.5.1.10, BA.4.1, and BA.2.3, were consistent with\nthose observed in dataset-1 as they are also the dominant variants\nduring the time-frame of dataset-1 (Fig.2a, b and Supplementary\nFig. 1a), further supporting the predicting capacity of this model.\nMoreover, the results showed that the top three simulated\nvariants, BA.2.12.1, BA.5.2.1, and BA.2, were also the top three\nvariants in the real dataset-1 (Fig.2b and Supplementary Fig. 7a).\nThis successful alignment between the simulated and observed\nvariants in dataset-1 demonstrated that the virus evolutionary\nlanguage model could accurately represent the regularity of\ncombinatorial amino acid mutations present in the given dataset.\nAfter validation, we conducted a retrospective study using only\ninformation available before the pandemic to make predictions.\nWe thus evaluated whether our model could represent the\nrandomness of combinatorial mutations by introducing and\ncontrolling the variable mutational pro ﬁle, representing the\noccurrence frequency of mutation. That is, we want to examine\nthe prediction capacity of our model. We still conducted 10,000\nsimulations at each hot spot, but now we changed their mutation\nfrequency and used the Bi-LSTM language model for screening.\nThis screening process is the best choice for our model after\nbenchmarking (Supplementary Fig. 8). After we retrieved the\nFig. 2 The validation of virus evolutionary language model and the prediction based on dataset-1. a, b The validation of the virus\nevolutionary language model without introducing a variable mutational proﬁle. a 10,000 variants were generated by simulation based on the\n“grammatical framework,” and we checked whether the simulated variants could represent the variants of real data. The larger the circle, the\nmore numbers of this variant are simulated, and each circle denotes a unique Omicron variant that might belong to the same lineage.b The\nschematic pattern of the prevailed variants during the timeframe of dataset-1 represents the real distribution pattern of the variants in that\nera. The variants belonging to the same lineage/sublineages are endowed with the same color in (a, b). c, d Using the evolutionary language\nmodel with a variable mutational proﬁle to make predictions.c The variants were generated by 10,000 simulations using the model, but now\nmutational proﬁle incurs random mutations.d The frequencies of the top 10 variants predicted by the model during the timeframe of dataset-\n2 (September 16th, 2022, to May 10th, 2023), right after the time period of input dataset-1. The models in (a– d) were developed based on\ndataset-1, and the prediction result is veriﬁed by the data in dataset-2\nA predictive language model for SARS-CoV-2 evolution\nMa et al.\n4\nSignal Transduction and Targeted Therapy           (2024) 9:353 \nsimulated results using the model that only contained input data\nbefore September 16th, 2022 (dataset-1), we compared them with\ndataset-2, the actual S1 data of variants that emerged between\nSeptember 16th, 2022, and May 10th, 2023 (Supplementary Fig.\n1b). We collected the sequences of the S1 subunit in SARS-CoV-2\nOmicron variants from that period and then performed multiple\nsequence alignments. After evaluating the precited sequences\nagainst the actual variants in dataset-2, we found that 70% of the\nsimulated sequences could be assigned to speci ﬁc Omicron\nsubvariants, including BA.4, BA.5.1.10, BA.4.6, BA.5, BA.5.5, and\nBA.2 which emerge soon after the prediction (Fig.2c). We can see,\nfor the several variants we predicted most, which means they are\nthe variants that are most likely to emerge according to our\nmodel, they take up about 50% proportion of all emerged variants\nduring late 2022 (Fig.2d). Additionally, we successfully predict the\nunseen BF, BE, and BQ subvariants, which were not present in\ndataset-1 but emerged after the timeframe of input data, is a\nsigniﬁcant validation of the predictive capabilities of our model\n(Fig. 2c and Supplementary Fig. 7b). The prediction of known and\npreviously unknown subvariants indicated that our model could\nelucidate viral evolution and predict future SARS-CoV-2 variants.\nBy introducing the mutational pro ﬁle into the model, we\nsigniﬁcantly extended the ability to forecast the regularity and\nrandomness in mutations, thereby indicating future viral variants.\nUpdating the SARS-CoV-2 variant data for predicting potential\nSARS-CoV-2 variants by the language model\nPredicting future SARS-CoV-2 variants or inﬂuential amino acids’\nresidue mutation is of signi ﬁcance as it allows more time to\ndevelop proactive responses at earlier stages of viral spread,\npotentially mitigating the impact of new variants on public\nhealth.\n6 Building upon the previous success of our language\nmodel of SARS-CoV-2 evolution in shedding light on viral\nevolution and accurately predicting future variants, we next aim\nto update our prediction for potential future variants based on the\nsequences that emerged between September 2022 and May 2023\n(dataset-2) and between May 2023 and October 2023 (dataset-3).\nPreviously, weﬁrst predicted the future variants based on dataset-\n1, yet it might be outdated for the present epidemic status.\nRepeating the prediction based on dataset-2 and dataset-3 would\ngrant us insight into the near future’s viral evolution, providing a\npractical application for our model and also further validating the\nmodel’s integrity. We employed the exact modeling and validation\napproach used previously to accomplish the prediction.\nTo begin, we still conducted 10,000 simulations based on the\nconstructed “grammatical framework” built by dataset-2 without\nintroducing the mutational proﬁle, thereby focusing on validating\nthe regularity of the mutation s. Similarly, we compared our\nsimulated results against the variants present in the raw data\n(dataset-2) to assess how well the model-generated sequences\naligned with the actual variants. Approximately 40% of the simulated\nsequences matched the variants observed in dataset-2. Notably, the\nmajority of these matched sequences were XBB.1.5, BQ.1.1, BA.5.2.1,\nBA.4.6, and BF.7 subvariants (Fig.3a). In both the simulated results\nand dataset-2, XBB.1.5 emerged as the most frequent Omicron\nlineage, followed by the BQ and BF subvariants (Fig. 3ba n d\nSupplementary Fig. 7c). We thus successfully simulate back the\ndataset-2 from the constructed “grammatical framework”.T h e s e\nresults prove that our language model could effectively represent\nthe regularity of the amino acid mutations present in the sequences\nin dataset-2, keeping the vital information after dimension reduction.\nLikewise, after validation, we perform the prediction and test\nour predicted results against the variants that emerged after the\ntimeframe of dataset-2. For this purpose, we collected the\nsequences of S1 peptide in SARS-CoV-2 Omicron variants from\nMay 15th, 2023, to October 31st, 2023 (dataset-3), and then\nperformed multiple sequence alignments (Supplementary Fig. 1c).\nWe chose October 2023 as the end period of our dataset since it is\ntime just before the emergence of current VOIs, JN.1 and BA.2,86.\nBy comparing the predicted sequences based on dataset-2 with\nthe actual sequence in dataset-3, the dataset including the\nsequence data after the period of dataset-2, we found that the\nXBB.1.5 Omicron subvariant was prevalent in both the simulated\nresults and real data dataset-3 (Fig.3c, d), and XBB.1.5 was known\nas the dominant strain for the summer of 2023. We found out that\nthe top 5 variants predicted by our model based on dataset-2 take\nup about 40% proportion of all emerged variants from May 2023\nto October 2023 (Fig. 3d). Furthermore, the model successfully\nsimulated the emergence of previously unseen Omicron subvar-\niants in dataset-3, including XBB.1.16, XBB.2.3, GB.2, FL.2.3, and\nEG.5 (Fig.3c). XBB.1.16 and EG.5 later became the dominant strain\nand once VOC (now VOI).\n2 We successfully predict them before\ntheir emergence. The ability to predict Omicron subvariants not\npresent in the training dataset (dataset-2) and emerged in the\nlater real-world demonstrates the capacity of the model to\nforecast potential vital variants. To further investigate these\npredicted variants, we analyzed the amino acids at each hot spot\nfor these unknown predicted variants (Fig. 3e). Notably, the\nfrequency of some predicted mutations, such as E180V, V252G,\nand K478R, increased between May 16th, 2023, and July 1st, 2023\n(Fig. 3d and Supplementary Fig. 9). These results validate the\ncapacity of our predicted model for effectively predicting\nemerging mutations and variants.\nAs the COVID-19 pandemic turns into a new stage of co-\nexistence, the evolution trend of the virus switches from disease\nseverity into transmissibility. Several mutants with enhanced\nimmune escape capacity become concerned, including BA.2.86\nand JN.1. After examining our model from two different datasets\nextracted from two different time points, we have already proved\nand validated the efﬁcacy and accuracy of our model. However, a\nmost recent update is now required to provide a hint about the\npost-emergency stage. We thus ran our model for the third time\nbut now on a more recent dataset-3, including the spike data\nbefore the emergence of either JN.1 or BA.2.86. As a result, we\nfound that even though we did not predict the complete\nsequence of those two variants within the 10,000 output\nsequences, we did predict about half of all essential mutations\nfor them, including D339H, G446S, L452W, and F486P (Fig. 3f).\nConsequently, before their emergence, we successfully predicted\nfuture concerned variants, including BF.7, BQ.1, XBB.1.16, and EG.5.\nFor those variants that incur an extraordinary amount of mutation\nand unseen deletion or even insertion, which makes them hard to\npredict, our model still extracts most of their vital mutation. By\nintroducing the mutational proﬁle into the model, we simulate\nboth the regularity and the randomness of the mutations.\nPredicted variants show signiﬁcantly enhanced infectivity\nTo further validate the robustness of our model, we conducted a\nwet experiment, a crucial step to test its efﬁcacy in real-world\nscenarios. We selected ourﬁrst prediction from dataset-1 for our\nviral infectivity and immune evasion studies. Based on the\nprediction result of theﬁrst timeframe, we carefully handpicked\nthe top 100 sequences that were most likely to emerge in the\nfuture for our further experimental evaluation and residue\nmutation analysis (Fig. 4a). We chose 100 sequences, each of\nwhich had been generated at least 5 times, a number we deemed\nsufﬁcient for our model to identify them as potentially highly\ntransmissible sequences. These 100 sequences, denoted with\nnumbers from 1 to 100, were then synthesized and cloned\naccordingly to generate S-expressing plasmids. After the cloning\nand plasmid propagation in theE. coli system, 100 pseudoviruses\nfor each 100 predicted S1 protein were constructed by plasmid\ntransfection in HEK-293T cells (Fig. 4a). The liquid spectrometry\nmeasuring the binding afﬁnity of ACE2 receptor protein revealed\nthat most of the constructed pseudoviruses with low luciferase\nluminescence (RLU) value also corresponded with a low binding\nA predictive language model for SARS-CoV-2 evolution\nMa et al.\n5\nSignal Transduction and Targeted Therapy           (2024) 9:353 \nafﬁnity (Supplementary Fig. 10). Excluding the pseudoviruses with\nextremely low RLU and binding af ﬁnity, 83 out of 100\npseudoviruses were deemed suitable for our infectivity study.\nBefore proceeding with the infectivity analysis, we implemented\np24 quantiﬁcation to precisely standardize the concentration of all\npseudoviruses. This meticulous step was essential to ensure that\nthe same amount of pseudoviruses were cocultured with ACE2\nreceptors for measurement. The 50% tissue culture infectious dose\n(TCID50) values for the infection assay were obtained and\ncompared according to the Reed-Muench method for each\npseudovirus. The results revealed 10 out of 83 pseudoviruses\nwith sequence numbers #2, #36, #37, #41, #56, #65, #73, #76, #82,\nA predictive language model for SARS-CoV-2 evolution\nMa et al.\n6\nSignal Transduction and Targeted Therapy           (2024) 9:353 \nand #98 that exhibited signiﬁcantly enhanced infectivity when\ncompared with BA.5 sequences (Fig.4b). Among them, variant #98\ndemonstrated the highest relative infectivity with an average level\nof 5-fold compared to that of BA.5. These precise results\nunderscore the potential impact of our research in predicting\nvariants with greater infectivity, the ones that are more likely to\npose a threat in the future. The amino acid sequences of those 100\nvariants are included in the supplementary.\nPredicted variants exhibit increased immune evasion\nBesides the viral infectivity of the predicted variants, another\ncharacteristic of concern that deserves further evaluation and\nrelates to viralﬁtness is the neutralization escape of the variants. In\nour study, we recruited 48 volunteers for blood donation, all of\nwhom shared a similar immune background of recovered patients\nvaccinated with a WHO-approved Ad5-vectored SARS-CoV-2\nvaccine. We then performed a serum antibody neutralization\nassay to examine the immune evasion for each predicted\nsequence by coculturing the serum, pseudoviruses, and ACE2-\nexpressing HEK-293T cells together (Fig. 4a). The pseudoviruses\nthat failed to be neutralized by the anti-sera and infected more\n293 T cells were the ones that desired more attention. The\ngeometric mean of the ratios of each sequence to BA.5 for EC50\ntiter is thus set as a baseline control for comparison. In\nconsequence, compared to that of the BA.5 variant, 15 potential\nvariants were discovered with signiﬁcantly lower half maximal\neffective concentration (EC50) value, including sequences #8, #21,\n#22, #50, #52, #55, #60, #65, #67, #82, #88, #91, #94, #96, and #98,\nyet those results were illustrated by preliminary studies adopting\nonly 12 blood samples (Fig. 4c). When including all 40 eligible\nhuman blood samples, we discovered only 6 predicted variants\n#50, #52, #55, #65, #67, and #82 showed a signiﬁcantly increased\ncapacity of immune evasion (Fig.4d). To be noticed, the difference\nin the immune evasion is below 2-fold, yet the difference is still\nsigniﬁcant. The immune escape capacities of variants #15 and #99\nwere also signi ﬁcantly higher for the latter case, yet their\ndifferences were below 1.3-fold.\nTaking into account the sequence matching, we found that\namong those 6 sequences with enhanced immune evasion\ncapacity, sequences #55 and #67 matched the lineages of BQ.1\nand BQ.1.12, respectively. As BQ.1 and BQ.1.12 were dominant\nvariants of late 2022, thisﬁnding further exempliﬁed the accuracy\nand reliability of our prediction model. Interestingly, BQ.1 and\nBQ.1.12 variants were not included in our input dataset and only\nemerged after the construction of our model. These results\nveriﬁed that our model is able to predict not only enhanced\ninfectivity but also immune evasion, providing a strong founda-\ntion for future research and understanding of SARS-CoV-2 variants.\nPredicted variants share vital mutations with circulating Omicron\nvariants\nThe previous evaluations on viral infectivity and immune evasion\nrevealed several vital mutations in S1 sequence that might be\nrelated to viral ﬁtness. As mentioned, we retrieved 10 predicted\nsequences of signiﬁcantly enhanced infectivity and 6 sequences of\nincreased immune evasion capacity. To further elucidate the\nevolutionary relationships and potential functional implications of\nSARS-CoV-2 variants, we constructed a comprehensive phyloge-\nnetic tree incorporating both prevalent and predicted variants\n(Fig. 5a). We found that sequences # 65 and #82 were included in\nboth groups of immune escape and infectivity, illustrating their\npotential to emerge in the future. By analyzing the residue\nmutations that occurred in those variants, we discovered several\ncommon mutations, including R346T, K444T, N460K, R452Q, R685\ndeletion, and N658S. More precisely, we found that R346T, R685\ndeletion, L452Q, and N658S sites appeared more frequently in\ninfectivity-enhancing sequences, while K444T and N460K were\ndetected more often in antibody evasion-enhancing sequences.\nThe structural analysis of the BA.5 S protein illustrated that most of\nthem had only a minimum effect on the protein structure\n(Supplementary Fig. 11).\nAmong the residue mutations we detected above, some of\nthem were consistent with previousﬁndings, which exempliﬁed\ntheir importance to viral evolution and thus might require greater\nattention. For instance, previous studies have reported R346T,\nK444T, and N460K as convergent mutations with enormous\ngrowth advantages and were mutated in at leastﬁve independent\nOmicron lineages, the major COVID-19 lineages since 2022.\n27,28\nBesides residue spots 346, 444, and 460, residue spot 452 was also\nincluded in this list of important mutation sites,28 so the detection\nof R452Q also backed the reliability of our model. For our study,\namong 6 predicted variants with enhanced immune escape,\n83.3% of them (5/6) presented K444T and N460K mutations.\nSimilarly, for 10 predicted variants of signi ﬁcantly enhanced\ninfectivity, 50% of them (5/10) adopted the R346T mutation. These\nﬁndings illustrate that N460K and K444T mutations are highly\ncorrelated to the immune escape, and R346T mutation is\ncorrelated with viral infectivity. Importantly, our model, built\nbefore September 2022, was able to accurately predict future\nmutations of interest in the Omicron S protein (Fig. 5b),\ndemonstrating its potential for future surveillance efforts. Inter-\nestingly, sequence #65 contained all 3 mutations of greatest\ninterest, which deserve more attention in future surveillance of\nOmicron variants.\nK444T is one of the major Spike mutations of interest for SARS-\nCoV-2 Omicron variants BQ.1 and CH1.1. Due to their tremendous\nimpact on global health, WHO once escalated BQ.1 as one of the\nvariants of interest (VOI) and CH1.1 as one of the variants under\nmonitoring.\n2 As there are currently no SARS-CoV-2 variants\nmeeting the VOC criteria, VOI and variants under monitoring\n(VUM) at their time are the ones that raise the most attention,\nunderscoring the importance of detecting this mutation by our\nmodel. Moreover, residue mutations R346T and N460K are more\nimportant as they are not only major Spike mutations of interest\nfor BQ.1 lineage but also for the XBB lineage, including variants\nXBB.1.9.1, XBB.1.15, and XBB.1.16 (Fig.5a).\nBenchmarking shows the model’s unique advantages and\ncomparable accuracy\nThe wet-lab veriﬁcation might not be sufﬁcient for validating the\nefﬁcacy of our work. Without elaborate benchmarks and\ncomparisons with other models, it is hard to exemplify the\nFig. 3 Updating the SARS-CoV-2 variant data for predicting potential future.a, b The validation of the virus evolutionary language model\nwithout introducing a variable mutational proﬁle. a 10,000 variants were generated by simulation based on the“grammatical framework”. The\nlarger the circle, the more numbers of this variant are simulated, and each circle denotes a unique Omicron variant.b The schematic pattern of\nthe prevailed variants during the timeframe of dataset-2, representing the real distribution pattern of the variants in that era. The same\nvariants are endowed with the same color in (a, b). c, d Using the evolutionary language model with a variable mutational proﬁle to make the\nprediction. c The variants were generated by 10,000 simulations using the model but including mutational proﬁle to incur random mutations.\nd The frequencies of the top 5 variants predicted by the model from May 11st, 2023, to July 1st, 2023, right after the time period of input\ndataset-2. e The frequencies of the amino acids at each hot spot generated by the model with a variable mutational proﬁle. The models in\n(a– d) were developed based on dataset-2, and the prediction result is veriﬁed by the data after dataset-2.f The mutations in Omicron variants\nand the predicted results by the virus evolutionary language model based on dataset-3.e, f del denotes the amino acid deletion\nA predictive language model for SARS-CoV-2 evolution\nMa et al.\n7\nSignal Transduction and Targeted Therapy           (2024) 9:353 \nFig. 4 The experimental evaluation of the model-predicted SARS-CoV-2 spike variants.a The schematic diagram of the wet-lab experiments\nfor plasmid synthesis, pseudoviruses construction, infectivity measurement, and neutralization assay.b The percent infectivity of predicted\nvariants compared to that of BA.5 variant, which represented by TCID50 values. The TCID50 value of BA.5 is set as 100%. The PNAb titers\nmeasured by the relative ratio of EC50 values of predicted variants/BA.5 for 12 blood samples (c) and 40 blood samples (d). The EC50 value of\nBA.5 sequence is set as 1, and the measurement is geometric mean\nA predictive language model for SARS-CoV-2 evolution\nMa et al.\n8\nSignal Transduction and Targeted Therapy           (2024) 9:353 \nadvantages and drawbacks of our model. In this case, we select\nthree decent and respective works also focusing on SARS-CoV-2\nevolution and a random generator for our comparison.\nTEMPO. TEMPO, a transformer-based mutation prediction frame-\nwork, is a fantastic model that utilizes phylogenetic tree-based\nsampling to capture the temporal information and transformer to\npredict the mutation probability of sites.\n29 There are similarities\nand differences in features between our model and TEMPO. For a\ncommon advantage, we could both predict mutation sites, and\nboth models take the temporal information into account to\nincrease the model’s accuracy. TEMPO has the unique advantage\nof including phylogenetic information in the model, which helps it\nunderstand what occurred throughout evolution,\n29 while our\nmodel deﬁnes “TDF” to incorporate the temporal variable. Our\nmodel, in such cases, provides an alternative choice for TEMPO\nand could be used in the initial stage of a pandemic when no\nphylogenetic information is available.\nThe most essential benchmark comparison is the comparison of\nperformance. As the available dataset for TEMPO and our training\ndata for ourﬁrst prediction is about to be in a similar timeframe,\nwe thus decided to compare the prediction sites generated by our\nﬁrst prediction and TEMPO. We successfully included 10 out of 16\nhigh-probability (p ≥ 0.5) predicted mutation sites mentioned by\nTEMPO. This result is comparable to TEMPO’s own prediction of 12\nout of 16.\n29 Furthermore, our model also identi ﬁed several\nmutation sites not included by TEMPO, demonstrating its unique\ncapabilities.\nFig. 5 The residue mutation analysis of the concerned sequences outputted by the prediction model.a The multiple sequence alignment and\nphylogenetic tree of the 10 viral infectivity enhanced sequences and 6 immune evasion capacity increased sequences with R346T, K444T, and\nN460K residue mutations labelled.b Average daily prevalence of SARS-CoV-2 variants with labeling of residue mutation sites 346, 444, and 460\nA predictive language model for SARS-CoV-2 evolution\nMa et al.\n9\nSignal Transduction and Targeted Therapy           (2024) 9:353 \nBrian’s LSTM. Based on two major components, grammar (or\nsyntax) and meaning (or semantics), Hie et al. constructed an\nunsupervised NLP model to predict the viral escape capacity for\ndifferent mutations and used three different viruses to examine\nthe model’s validity.\n21 As outputs, this model could give out two\nscores for each mutation combination (semantic and grammar).\nThe “semantic” component refers to the amplitude (or extent) of\nthe change of the viral sequence, while the “grammar”\ncomponent refers to the viral ﬁtness. The mutations and the\ncombinatorial mutations with high semantic scores represent a\nlarge shift from the original viral sequence, and the high grammar\nscore represents high ﬁtness resulting from the mutations. Hie\nbelieves that the mutations that score high for both components\nare likely to be the mutations that lead to immune escape.\nTo compare our model with Brian’s model, we used Brian’s\nmodel to test the mutation combinations of the top\n10,000 sequences predicted from dataset-1 (which we believe to\nbe the top 10,000 variants that are likely to emerge after the time\ndataset-1 is collected). As a result, we found 9566/10,000 (95.66%)\nof the sequences have higher semantic scores, 6388 (63.88%) of\nthe sequences have higher grammar scores, and 6,034 (60.34%) of\nthem have both higher semantic and grammar scores when\ncompared to the dominant variants in the timeframe of the input\ndata (dataset-1). This result helps to validate that our model is\nconsistent with Brian’s LSTM model, and the essential variants\npredicted by our model are also the concerned variants for\nBrian’s model.\nEVEscape. EVEscape, with its unique combination of deep\nlearning and ﬁtness predictions, quanti ﬁes the viral escape\npotential of given mutations at scale.\n30 Its distinct advantage\nover other models is its independence from information from\nsurveillance sequencing, experimental scans, or three-dimensional\nstructures of antibodies to make predictions.30 This advantage is\nparticularly crucial in providing an early warning time critical for\nvaccine development. Likewise, our model, operating as an early\nalarm for potentially prevailing variants, could signiﬁcantly impact\nvaccine development by making predictions solely based on\nsequence data.\nAs EVEscape does not generate new sequences or mutation\nsites but predicts the immune escape potential and antibody\nafﬁnity for a given mutation, we could not compare our model\nwith EVEscape directly. Instead, we tested the top 100 sequences\npredicted from dataset-1 and dataset-2 using EVEscape. Our\nmodel believed those sequences to have high immune evasion\nand low antibody afﬁnity. As a result, 79% of sequences predicted\nfrom dataset-1 and 81% of sequences predicted from dataset-2\nsurpass the dominant variants in the timeframe of that dataset in\nimmune escape capacity (Fig.6a and Supplementary Fig. 12). For\nfurther veri ﬁcation, we increase the samples to the top\n10,000 sequences and the consistent result is shown. About 65%\nof the sequences score higher than the prevailing strain at that\nperiod. This alignment with EVEscape further validates the\naccuracy of our model, instilling con ﬁdence in its predictive\ncapabilities.\nMLAEP. The Machine Learning-guided Antigenic Evolution Pre-\ndiction (MLAEP) is a novel approach that combines “structure\nmodeling, multi-task learning, and genetic algorithms” to predict\nviral immune escape and antibody afﬁnity.\n31 This unique model,\nsimilar in function to EVEscape, provides a score of immune\nevasion and, uniquely, a score of antibody afﬁnity. By leveraging\nthe existing RBD region sequence information and Deep Mutation\nScanning (DMS) dataset, MLAEP enhances its accuracy, albeit with\nthe need for additional information.\nSimilarly, we input the top 100 predicted sequences into MLAEP\nto examine our model’s performance. These sequences represent\nthe most likely variants that could emerge in the future. For the\nsequences predicted by dataset-1, 74% of our predicted sequence\nachieve a higher immune evasion score, and 71% of them achieve\na higher ACE2 binding score than that of BA.2, BA.4, and BA.5, the\ndominant strain in the timeframe of our input dataset (Fig.6b, c).\nMoreover, for the sequences predicted by dataset-2, 82% of them\nachieve a higher ACE2 afﬁnity and immune escape capacity with\nthe dominant strain XBB.1.5 of the timeframe for dataset-2. That is\nto say, our prediction is also consistent with MLAEP, so the\nsequences with warning potential predicted by us are also\nacknowledged by other models including Brian’s LSTM, MLAEP,\nand EVEscape.\nOur model stands out with its unique advantage of extensive\nwet-lab validation, a testament to its reliability. Though both\nMLAEP and EVEscape included pseudovirus neutralization assays,\nthe assays were not performed by the researchers themselves.\nUnlike the three mentioned models, which utilized only a few wet-\nlab data from other studies, we took the initiative to synthesize\n100 generated sequences and construct pseudovirus assays\n(Supplementary Table 1). Each sequence was rigorously examined\nwith 50 serum samples from recovered patients, ensuring the\nhighest level of reliability in our results and conclusions.\nOur model also circumvents the requirement of sophisticated,\nhard-to-obtain data such as phylogenetic trees, deep mutational\nscanning data, and protein 3D structure (Supplementary Table 2).\nBy leveraging a “grammatical framework” for dimension reduc-\ntion, our model operates efﬁciently with a relatively small amount\nof sequence data ( ~ 3 months’ data) and minimal computational\npower (personal desktop). A more intuitional description of the\ndifference in computational burden between our models and the\nabove models is that our model only needs CPU for prediction,\nyet all other models likely utilized GPU for prediction. This user-\nfriendly approach empowers researchers with a fast-responding,\npioneer method for early-stage pandemic warning.\nRandom generator. One last interesting comparison would be\nthat against a random generator. We generated 100 sequences\nusing the random generator and compared them with the top 100\npredicted sequences from dataset-1. As we ’ve seen, our\n100 sequences contained several convergent mutations (R346T,\nK444T, and N460K) with signiﬁcant growth advantages, observed\nin later emerging variants like BQ.1, CH1.1, XBB1.15, and XBB1.16.\nFor our 100 predicted sequences, we found that 40 of them\ncontained R346T, 8 contained K444T, and 6 contained N460K. In\ncontrast, none of the 100 sequences generated by the random\ngenerator contained R346T or N460K, and only one contained\nK444T mutation, likely by chance (Supplementary Fig. 13).\nImportantly, our generated sequences included 10 out of 16\nhigh-probability (p ≥ 0.5) predicted mutation sites that appeared\nin mid-2022, while the random generator’s predictions included\nnone of them. These comparisons underscore the accuracy of our\nmodel and validate that our prediction results are not\ncoincidental.\nIn conclusion, our model stands out when compared to TEMPO,\nEVEscape, Brian’s LSTM, and the random generator. It demon-\nstrates several unique advantages and consistent accuracy,\nexemplifying the efﬁcacy of the model.\nDISCUSSION\nThe COVID-19 pandemic caused by SARS-CoV-2 continues to\nspread globally.\n1,2 Mutations in viral proteins occurred in a\nrandom pattern,23 yet studies have summarized the regularity of\nmutations using the available viral sequences. Recent studies\nemployed natural language processing to model the viral\nescape\n20,32 and revealed the escape mutations as those that\nmaintain viral infectivity but cause a virus to appear different to\nthe immune system.21 A study deﬁned and evaluated the scores\nfor existing amino acid mutations in available viral sequences,\nA predictive language model for SARS-CoV-2 evolution\nMa et al.\n10\nSignal Transduction and Targeted Therapy           (2024) 9:353 \nrevealing mutations that could contribute to future prevalent\nvariants.6 In this study, we collected and determined the regularity\nof combinatorial mutations based on the SARS-CoV-2 S1 protein\nsequences in a given dataset. Nevertheless, some random\nmutations were rarely detected in the available viral sequences\nand arose rapidly over a short period. The low frequency of these\nmutations hindered the ability of modeling to predict these\nmutations.\n6,33 To overcome this problem, we introduced a\nmutational proﬁle to the model to simulate the randomness of\nthe mutations, thus allowing the model to simulate future variants.\nSince the SARS-CoV-2 viral protein continues to undergo\nmutations, predicting future variants is crucial for developing\ntreatments before the impending pandemic.6,21 We predicted the\nvariants using our model based on different datasets collected\nFig. 6 The comparison of the predicted results with other models.a EVEscape’s escape score of the 100 predicted sequences from our model.\nThe higher value represents the higher immune evasion capacity.b MLAEP’s escape score of the 100 predicted sequences from our model.\nThe lower value represents the higher immune evasion capacity.c MLAEP’s ACE2 binding score of the 100 predicted sequences from our\nmodel. The higher value represents the higher ACE2 afﬁnity. The 100 sequences predicted by our model in (a– c) are based on dataset-1, and\nthe dominant variant BA.5 (marked red) during the era of dataset-1 is used for comparison\nA predictive language model for SARS-CoV-2 evolution\nMa et al.\n11\nSignal Transduction and Targeted Therapy           (2024) 9:353 \nfrom different time points and tested the results against the\nvariants in datasets, including those that appeared after those\ntime points. The results indicated that we successfully predicted\nvariants including BQ.1, BF.7, BE.1.1, XBB.1.16, XBB.1.16.2, GB.2,\nFL.2.3, and EG.5 before their emergence. Natural recombination\nendows this variant with exclusive survival advantages, including\nenhanced transmissibility, additional Spike mutation and viral\nsignature, and intensi ﬁed antibody and immune evasion.\n34,35\nDuring the process of this work, some of the predicted variants\nhave caused epidemics and pandemics. The XBB.1.16 subvariant,\nfor example, was prevalent in India by the end of March 2023 and\nshowed enhanced immune evasion. 36– 38 In addition to these\nOmicron variants, our results predicted the previously unknown\nviral variants that may cause future COVID-19 pandemics. For\nexample, EG.5 only appeared about 6 months after we made the\nprediction. For the variants that include too many mutations,\ndeletions, and even insertions, such as BA.2.86 and JN.1, though\nwe did not attain the variants themselves, we could still\nsuccessfully predict the variants with D339H, G446S, L452W, and\nF486P mutations, the essential residue mutation for them. The\nmodel could be improved to include unseen deletion and\ninsertion into consideration, which might allow us to predict\nvariants such as JN.1 and BA.2.86 successfully. Ourﬁndings still\nverify our model ’s ability to predict essential and somewhat\nconservative mutations for a highly unpredictable variant.\nFrom our 100 predicted and synthesized Spike sequences, we\nretrieved 10 variants with signiﬁcantly enhanced viral infectivity\nand 6 variants with signi ﬁcantly increased immune escape\ncapacity. Moreover, we also detected that most of our\n100 sequences had high binding afﬁnity for hACE2 and infectivity.\nThese results exemplify our model’s capacity to predict variants\nwith relatively high vitalﬁtness that may potentially emerge and\nbecome a concern in the near future. Overall, our study offers a\nvirus evolution model to generate predictions for future SARS-\nCoV-2 variants and essential amino acid substitutions with only\nsequence information. Those features are rarely shown in other\nmodels, including TEMPO, MLAEP, and EVEscape. For TEMPO,\nphylogenetic information can be challenging to obtain as it\nrequires vast amounts of sequence data and an accurate tree\nmodel trained from the data. By including “Three Days ’\nFrequency” (TDF) in model construction, our model also grabs\nthe temporal information without needing phylogenetic trees.\nMoreover, our model can give out the speciﬁc type of mutation\nand hence could output the whole sequence instead of sites. For\nEVEscape, information is required in addition to mere sequences,\nsuch as 3D conformations (without antibodies). This conformation\nmight not be easy to obtain by cryo-TEM or accurately predicted\nby a well-trained model with sufﬁcient protein information. MLAEP\nutilizes the existing RBD region sequence information and Deep\nMutation Scanning (DMS) dataset for the prediction, yet the\nexperimental scan data such as DMS is also hard to attain,\nespecially in the early stage of the pandemic.\nAs mentioned, our model is based merely on the sequence\ninformation and appeared mutation. Focusing on only the RBD\nregion instead of the whole S1 subunit further increases the\ncomputational power and speed. In such cases, we sacriﬁce some\nof the prediction accuracy for the model’s simplicity. The model’s\nsimplicity allows us to respond to viral outbreaks more swiftly and\nrequires far less computational power and pioneer wet-lab\nexperiments. As the signiﬁcant mutation emerges much earlier\nbefore its prevalence, the increased computational speed allows\nus to update our model more timely and might identify the crucial\nmutation before its prevalence. The early warning of the\npotentially contagious variants provides insight for developing\nvaccines and answers the question of which sorts of antigen\npeptides the vaccines should target.\nIn conclusion, the low requirement of computational power and\ndata types endows our model with the capacity to provide\nwarnings in the early stage of a pandemic. Our model is thus\ntimely and highly upgradeable, and the modeling results could\noffer insights into persistent COVID-19 pandemics and vaccine\ndevelopment. Hence, if sufﬁcient sequence data is available, this\nmodel might also be generalized to predict mutations in other\nvirus sequences. The focus on only hot spots undermines the\npredictive capability of our model, so in future studies, we will\nconsider integrating a more dynamic approach to account for\npossible mutations in non-hot spot regions.\nMATERIALS AND METHODS\nSARS-CoV-2 Omicron viral protein sequence dataset\nThe SARS-CoV-2 Omicron variant spike sequences collected from\nApril 15th, 2022, to October 31st, 2023, were downloaded from\nthe NCBI Virus Database (https://www.ncbi.nlm.nih.gov/labs/virus/\nvssi/). We only considered Spike sequences between 1173 and\n1273 lengths. Multiple sequence alignment was subsequently\nperformed by Muscle 5 ( http://www.drive5.com/muscle/). S1\nprotein sequences from the 14th to the 685th residues1 were\nextracted as a dataset:\ndataset-1: sequences collected from 2022.4.15 to 2022.9.15\ndataset-2: sequences collected from 2022.9.16 to 2023.5.10\ndataset-3: sequences collected from 2023.5.15 to 2023.10.31.\nDatasets-1, dataset-2, and dataset-3 each have 441,083, 275,509,\nand 67,946 viral sequences. The sequences in dataset-1 belonged\nto BA.2, BA.4, BA.5, and their subvariants (Supplementary Fig. 1a).\nMost of the sequences in dataset-2 belonged to the BA.5, BQ, XBB,\nand their subvariants (Supplementary Fig. 1b). Most sequences in\ndataset-3 belonged to the FL, HV.1, XBB., EG. and their subvariants\n(Supplementary Fig. 1c).\nModeling procedure\nDetermination of “grammatical frameworks” of a given dataset .\nPrior to commencing the modeling process, a crucial step involves\nestablishing the “grammatical frameworks” inherent within the\nprovided dataset. We deﬁned the Three Days’ Frequency (TDF) of\na speciﬁc as the percentage of this amino acid for a residue site\nwithin three successive days. Here the deletion was treated as an\namino acid. The insertion of amino acids was not taken into\naccount during the overall modeling process. The dominant\nresidue of each site was de ﬁned as the amino acid with the\nhighest TDF (Supplementary Figs. 2a, 14a, and 15a). Using the\nPandas Python package,\n39 the TDF time series data of the\ndominant amino acid for each site of the sequences in dataset-1,\ndataset-2, and dataset-3 were calculated (Supplementary Figs. 2b,\n14b, and 15b). Then we determined the“grammatical frameworks”\nof the hot spots in each dataset, as explained below.\n(1) Screening for the hot spots. The hot spots were deﬁned as\nsites where the difference between the maximum TDF (y\nmax)\nand the minimum TDF (ymin) of the dominant residue was\ngreater than 0.09 (ymax - ymin > 0.09) and where more than\none amino acid appeared (Supplementary Figs. 2c, 14c, and\n15c). Based on dataset-1, dataset-2, and dataset-3, 84, 26,\nand 30 hot spots were identiﬁed, respectively (Supplemen-\ntary Figs. 2d, 14d, and 15d). At each hot spot, the maximum\nvalue of each TDF time series data was applied to\nstandardize the time series data. Sites within the S1 protein\nthat did not meet the criteria for designation as‘hot spots’\nwere categorized as “non-hot spots” (Supplementary Figs.\n2d, 14d, and 15d).\n(2) Determination of the“word clusters.” The “word clusters”\nwere deﬁned as the clusters of the TDF time series data with\na similar trend. The TDF time series data of the dominant\namino acid at different hot spots were clustered using the\nprotocol reported in prior study.\n40 The hierarchical cluster-\ning built a hierarchy of clusters and yielded the number of\nA predictive language model for SARS-CoV-2 evolution\nMa et al.\n12\nSignal Transduction and Targeted Therapy           (2024) 9:353 \nclusters (Nc) (Supplementary Figs. 3a, 16a, and 17a). The\nK-means cluster analysis divided the TDF data into Nc\nclusters, assigning each sample to the cluster with the\nclosest mean TDF values. The K-means cluster results are\nshown in Supplementary Figs. 3b, 16b, and 17b. IBM SPSS\nStatistics 26 software was utilized to complete the above\ncluster analysis.\n(3) Dimension reduction of the“word clusters” time series\ndata. The number of hot spots within the“word clusters”\nranged from 1 to 39 (dataset-1), from 1 to 7 (dataset-2), and\nfrom 1 to 15 (dataset-3), respectively. The cluster analysis\ninput data should be column vectors. In order to further\ncluster the “word clusters” into “sentence clusters”, the\n“word clusters” with multiple hot spots must be converted\nto column vectors. The principal component analysis (PCA)\n41\nwas employed to reduce the dimension of the TDF time\nseries data within each “word cluster”. MATLAB R2020b\n(MathWorks, US) was used to perform the PCA. After PCA,\nthe TDF time series data within each “word cluster” was\nreduced to a column vector. The maximum value in each\ncolumn vector was then applied to standardize the“word\nclusters” time series data.\n(4) Determination of the“sentence clusters.” The “sentence\nclusters” were deﬁned as the clusters of the“word clusters”\ntime series data with a similar trend. The “word clusters”\ntime series data were clustered by the hierarchical clustering\nand K-means approaches using IBM SPSS Statistics 26 soft-\nware. The values ofN\nc detected by the hierarchical cluster\napproach for the three datasets were shown in Supplemen-\ntary Figs. 4a, 18a, and 19a. Using the“word clusters” time\nseries data and Nc as input data, the K-means cluster\nanalysis was able to determine the“sentence clusters”.\n(5) Dimension reduction of the “sentence clusters” time\nseries data. To further cluster the“sentence clusters” into\n“paragraph clusters”, the “sentence clusters” with multiple\nhot spots must be reduced to column vectors using PCA.41\nMATLAB R2020b was applied to conduct the PCA. The\nmaximum value of each column vector was then applied to\nthe “sentence clusters ” time series data in order to\nstandardize it.\n(6) Determination of the “paragraph clusters”. The “para-\ngraph clusters” were deﬁned as the cluster of the“sentence\nclusters” time series data with a similar trend. The time\nseries data of “sentence clusters” were clustered by the\nhierarchical and K-means approaches using IBM SPSS\nStatistics 26 software (Supplementary Figs. 5a, 20a, and\n21a). The K-means cluster analysis was used to determine\nthe “paragraph clusters”.\nAfter the above cluster analysis, the dimensions of the TDF time\nseries data of the hot spots in dataset-1, dataset-2, and dataset-3\nwere reduced. The “grammatical frameworks ” of dataset-1\n(Supplementary Fig. 6), dataset-2 (Supplementary Fig. 22) and\ndataset-3 (Supplementary Fig. 23) were compromised by the\n“word clusters,”“ sentence clusters,” and “paragraph clusters”.\nAmino acid simulation based on the“grammatical frameworks”\nThe “grammatical frameworks ” of dataset-1, dataset-2, and\ndataset-3 have divided the S1 protein sites into hot spots and\nnon-hot spots and further reduced the dimension of hot spots\ninto “word clusters,”“ sentence clusters,” and “paragraph clusters.”\nWe assumed that each non-hot spot conserved the dominant\namino acid and that it could not change. Then we simulated the\namino acids at the hot spots of the S1 protein based on the\n“grammatical frameworks.” The occurrence frequency of an event\nwas deﬁned by dividing the number of trials in which it occurred\nby the total number of trials. The Monte Carlo (MC) simulation\napproach can generate a variety of potential outcomes based on\nthe occurrence frequency of an event. It is widely used in\nmodeling the processes such as CO\n2 emission,42 the structure of\nproteins,43 and the structure of Zeolite.44 This paper employed the\nMC approach to simulate the amino acids at the hot spots.\nMATLAB R2020b was used to conduct the MC simulation\n(Supplementary Fig. 24), and its procedure is described in detail\nbelow.\n(1) Simulation of the amino acids at each hot spot. The mean\nTDF of an amino acid was determined by dividing the total\nTDF of an amino acid by the total number of TDF. Only\namino acids with a mean TDF greater than 0.02 were\nconsidered in the simulation of amino acids at hot spots.\nThe mean TDF was applied as the occurrence frequency to\ngenerate the amino acids at each hot spot (Supplementary\nFig. 25). Here the deletion was treated as an amino acid. We\nused the randsrc function in MATLAB R2020b to generate\nthe amino acids at each hot spot. The input data of the\nrandsrc function were the dimension of the output matrix (1,\n1), the amino acids, and the occurrence frequency of the\namino acids: randsrc(1, 1, [double(‘amino acid 1’), double(‘-\namino acid 2’); the occurrence frequency of amino acid 1,\nthe occurrence frequency of amino acid 2]). We deﬁned the\nnumber of simulations num= 10,000. In each simulation, an\namino acid was generated by the randsrc function at each\nhot spot.\n(2) Constraint of the collocation of amino acids within each\n“word cluster”. The prevalent residue at a hot spot was\ndeﬁned as the amino acid with a mean TDF over 0.2\n(Supplementary Fig. 26). We observed that in each cluster, a\nprevalent residue was associated with a speciﬁc set of amino\nacids, which was deﬁned as the collocation of amino acids\n(Supplementary Fig. 27). For instance, site 1 and site 2\nconstituted a “paragraph cluster”. For site 1, the prevalent\nresidues were assumed to be I and T. Conditional frequency\nP(A | B) refers to the probability that event A will occur under\nthe condition that event B has already occurred. P(site 2= S|\nsite 1= I) and P(site 2= G|site 1= T) were greater than 0.9.\nConsequently, “IS” and “TG” were the collocations of amino\nacids for site 1 and site 2. When a prevalent residue was\ngenerated at a hot spot within a “word cluster ”, the\nconditional frequency (CF) of the amino acids at other hot\nspots was calculated based on all datasets. The Pandas\nPython package\n40 was used to calculate the CF. The amino\nacids at other hot spots were subsequently constrained\nbased on the CF by the randsrc function in MATLAB R2020b:\nIf the amino acid at the hot spot 1= I\nThe amino acid at the hot spot 2= randsrc(1, 1,[double\n(‘S’),double(‘G’); 0.9683, 0.0317])\nIf the amino acid at the hot spot 1= T\nThe amino acid at the hot spot 2= randsrc(1, 1,[double\n(‘S’),double(‘G’); 0.9097, 0.0903])\n(3) Constraint of the collocation of“word clusters” within\neach “sentence cluster”.W ed eﬁned the TDF of a“word\ncluster” as the percentage of an amino acid cluster within\nthe “word cluster” among its total amino acid clusters in\nthree successive days. The mean TDF of a“word cluster” was\ndetermined by dividing the total TDF of a“word cluster” by\nthe number of TDF. The prevalent “word clusters” were\nidentiﬁed as clusters with a mean TDF higher than 0.2. When\na prevalent “word cluster” was generated, the CF of the\namino acid clusters at other“word clusters” was calculated\nbased on the dataset. The amino acids at other “word\nclusters” were subsequently constrained based on the CF\nusing the randsrc function in MATLAB R2020b.\n(4) Constraint of the collocation of “sentence clusters”\nwithin each “paragraph cluster”. The TDF of a“\nsentence\ncluster” was deﬁned as the percentage of an amino acid\nA predictive language model for SARS-CoV-2 evolution\nMa et al.\n13\nSignal Transduction and Targeted Therapy           (2024) 9:353 \ncluster within a “sentence cluster” among its total amino\nacid clusters in three successive days. The mean TDF of a\n“sentence cluster” was determined by dividing the total TDF\nof a“sentence cluster” by the number of TDF. The prevalent\n“sentence cluster” was identiﬁed as the “sentence cluster”\nwith a mean TDF higher than 0.2. When a prevalent\n“sentence cluster” was generated, the amino acids in other\n“sentence clusters” were subsequently constrained based on\nthe CF using the randsrc function in MATLAB R2020b.\nMutation simulation with the mutational proﬁle\nThe “mutational proﬁle”,d eﬁned as the occurrence frequency of\nmutations, was incorporated into the amino acid simulation model\nin order to simulate future mutations at the hot spots.\n(1) Mutation simulation with the mutational pro ﬁle.W e\nintroduced a mutation ﬂag to the model: the mutation\noccurred when the mutationﬂag was generated during the\nsimulation. Thus, the mutational proﬁle was the occurrence\nfrequency of the mutation ﬂag. The deletion was not\nconsidered in the mutation simulation. The more mutable\nhot spots were de ﬁned as those with more than one\nprevalent residue (mean TDF > 0.2). The mutational proﬁle\nof the more mutable and other hot spots was set to a high\nvalue (0.9) and a medium value (0.5), respectively (Supple-\nmentary Fig. 28). The randsrc function in MATLAB R2020b\nwas used to simulate the mutations at each hot spot. The\ninput data of the randsrc function were the dimension of\nthe output matrix (1, 1), the amino acids and mutationﬂag,\nand the occurrence frequency of the amino acids and\nmutation ﬂag: randsrc(1, 1, [double(‘amino acid 1’), dou-\nble(‘amino acid 2’), mutationﬂag; the occurrence frequency\nof amino acid 1, the occurrence frequency of amino acid 2,\nthe mutational proﬁle]). The number of simulations (num)\nwas 10,000.\nWe calculated a D-value as the difference between the\nlast and ﬁrst three days\n” frequency of each amino acid. The\noriginal residue at a hot spot was deﬁned as the amino acid\nwith a mean TDF greater than 0.02 (Supplementary Fig. 29).\nIf more than one amino acid at a hot spot had a mean TDF\ngreater than 0.02, the residue with a negative D-value was\nidentiﬁed as the original residue (Supplementary Fig. 29). An\navailable mutation was deﬁned as a residue other than the\noriginal residue and the deletion for a site. When a mutation\nﬂag was detected, the percentage of an available mutation\nfor a site was employed as the occurrence frequency to\ngenerate the mutation. The randsrc function in MATLAB\nR2020b was applied to simulate the mutations at each hot\nspot. The input data of the randsrc function were the\ndimension of the output matrix (1, 1), the available\nmutations, and the occurrence frequency of the available\nmutations: randsrc(1, 1, [double( ‘available mutation 1 ’),\ndouble(‘available mutation 2’); the occurrence frequency of\navailable mutation 1, the occurrence frequency of available\nmutation 2]). Then the amino acids were constrained based\non the CF.\n(2) LSTM model scoring of the mutations. The mutations\nwere generated at the hot spots in the mutation simulation\nin previous steps. Nonetheless, further evaluation was\nrequired for the combinatorial amino acids at hot spots\nwithin each “paragraph cluster ” when the mutation\noccurred. The language model learned the occurrence\nfrequency of a word or sentence given its sequence context\nof a paragraph.\n21 The Bi-directional Long Short-Term\nMemory (Bi-LSTM) language model could access both left\nand right contexts and export an emotional score of the\nsequences (Fig. 1b). In this study, the Bi-LSTM language\nmodels were trained based on dataset-1, dataset-2, or\ndataset-3 to calculate the emotional scores of the “para-\ngraph clusters” when detecting a mutation. Following is an\nexplanation of the modeling procedure.\nThe Bi-LSTM language model architecture is shown in Fig.\n1b. An input layer, two LSTM layers, and an output layer\ncompromised the Bi-LSTM language model.\n21 The input\ndata of the Bi-LSTM model were the amino acid clusters in\neach “paragraph cluster ”. The input data excluded the\nclutters consisting of original amino acids and the clusters\nconsisting only of deletions. The Bi-LSTM layer has two LSTM\nlayers, accessing both left and right sequence contexts (Fig.\n1b). The emotional scores for amino acid clusters with\noccurrence frequencies above and below 0.001 were set to\n1 and 0, respectively. The output data of the Bi-LSTM model\nwere the emotional score of each“paragraph cluster”. 5,000\nepochs were trained in each Bi-LSTM language model.\nWhen detecting a mutation in the simulation process, the\nemotional score of the cluster was output by the trained Bi-\nLSTM language model. The mutations were regenerated if\nthe “paragraph clusters” had a negative emotional score.\nOnly “paragraph clusters” with a positive emotional score\nwere output.\n(3) Output the simulation results of the amino acids. The\namino acids at hot spots were simulated based on the\n“grammatical frameworks” with a mutational proﬁle. The\namino acid simulation results were output in accordance\nwith the S1 protein site order (14\nth-685th).\nBi-LSTM construction\nThe Bi-directional Long Short-Term Memory (Bi-LSTM) language\nmodel could access both left and right contexts and export an\nemotional score of the sequences. The forward and backward\nhidden vector sequences of the Bi-LSTM model is generated as\nfollows:\nh!\nt ¼Hðw\nx h!xt þw h!h!h!\nt/C0 1 þb h!Þ (1)\nh \nt ¼Hðw\nx h xt þw h h h \ntþ1 þb h Þ (2)\nIn which h!\nt and ht\n are the forward and backward hidden\nvector sequences,H is the activation function,xt is the input layer,\nb h!and b h are the forward and backward biases, w\nx h ,w\nx h!,\nw h!h!, and w h h are the weight matrices.\nThe ﬁnal output sequenceht can be calculated by Eq. (3):\nht ¼∂ h!\nt þβ h \nt (3)\nIn whichα and β are the weight matrices corresponding to the\nforward and backward hidden vectors.\nSpike plasmid construction and cloning\nWe used the full-length BA.5 sequence as our template and\nexcluded the EcoRI (G^AATTC) and NheI (G^CTAGC) cleavages site\nfor codon optimization. We also need to maintain the 702-704\ncodons to be GAGAATTCC for EcoRI cleavage. We inserted a\nhomologous sequence on the 5’ end of the sequences, which\nwould include an EcoRI cleavage site (GAATTC), a Kozak sequence\n(GCCACC) for stability, and part of the pCAGGs carrier’s sequence\n(CTGTCTCATCATTTTGGCAAA). Similarly, on the 3’ end, we added a\nNheI cleavage site (G^CTAGC) and another carrier ’s sequence\n(AGATCTTTTTCCCTCTGCCAAAA). After the above sequences have\nbeen synthesized accordingly, via homologous recombination, we\ninserted this full-length BA.5 sequence into the pCAGGs carrier, a\nA predictive language model for SARS-CoV-2 evolution\nMa et al.\n14\nSignal Transduction and Targeted Therapy           (2024) 9:353 \ncommon carrier for SARS-CoV-2 variants. We obtained a new\ntemplate for the later S1 protein subunit synthesis. Likewise, for\neach predicted S1 protein sequence, we also excluded the EcoRI\n(G^AATTC) and NheI (G^CTAGC) cleavages site for codon\noptimization. On the 5’ end, we also inserted a pCAGGs carrier’s\nsequence (CTGTCTCATCATTTTGGCAAA), an EcoRI cleavage site\n(GAATTC), and a Kozak sequence (GCCACC). Hence, we added an\noptimized nucleic acid sequence with 13 codons\n(MFVFLVLLPLVSS) for 5’ end. For the 3’ end, we kept the sequence\nto be the same as that of the full-length BA.5. After the sequences’\nsynthesis and the ampliﬁcation of the S1 subunit sequence by PCR\n(Polymerase Chain Reaction), we used EcoRI to cleave the BA.5\nplasmid and by homologous recombination we inserted the\nS1 subunit into the pCAGGs carrier with S2 unit on it. In such\ncases, we acquired plasmids with full-length spike protein that\nhad different S1 sequences but the same S2 sequence. The\nadvantage of this cloning protocol was that it used the autologous\ncleavage sequence EcoRI for cleavage and did not introduce an\nexogenous sequence that might inﬂuence our study result.\nProduction and titration of pseudotyped variants\nHEK293T cells were diluted to 2.5 × 105 cells/mL and inoculated\ninto 6-well plates with 4 mL per well, then incubated at 37 °C with\n5% CO\n2 overnight until the conﬂuency for adherent cells reached\n90%. The spike protein expression plasmids were cotransfected\nwith the HIV-1 backbone plasmid in a ratio of 1:150 into\nHEK293T cells with the Turbofect transfection reagent (Thermo\nScientiﬁc, Waltham, MA, USA). The supernatants containing\npseudotyped viruses were collected at 24, 48, and 72 hours after\ntransfection and centrifuged, then divided into aliquots and\ncryopreserved at −80 °C.\nThe amount of pseudotyped virus prepared was quanti ﬁed\nusing ELISA methods by the QuickTiter™ Lentivirus Titer Kit (CELL\nBIOLABS, VPK-107), and the pseudotyped viruses were diluted to\nthe same concentration based on the HIV p24 level, and then were\nthreefold serially diluted for a total of nine dilutions, each with six\nreplicate wells. After dilution, hACE2-293T cells diluted in DMEM\nsupplemented with 10% FBS were added at 2.5 × 104 cells/well\nand incubated at 37 °C and 5% CO\n2. The pseudotyped HIV-1\nparticles encodeﬁreﬂy luciferase in their lentiviral vector genome,\nso by measuring theﬂuorescence intensity, we could record the\nrelative quantity of ACE2-bound, spike-expressed pseudovirus.45\nAfter a 48 h incubation, the luciferase luminescence (RLU) was\ndetected by a microplate luminescence detector (TECAN. SPARK\n10 M) using Bright-Lite detection reagent (Vazyme, DD1204), and\nthe 50% tissue culture infectious dose (TCID50) of the pseudo-\ntyped virus was calculated according to the Reed-Muench\nmethod.\nPseudovirus-based neutralization assays\nPseudovirus-based neutralization assays were performed using\nthe human immunode ﬁciency virus (HIV) pseudotyped virus\nproduction system. Genes encoding the full-length spike proteins\nof predicted variants and Omicron BA.5 variant (hCoV-19/South\nAfrica/NICD-N35214/2022, GISAID EPI_ISL_11542270) were human\ncodon optimized and inserted into the pCAGGS vector.\nHEK293T cells were inoculated into cell dishes and allowed to\ngrow overnight at 37 °C and 5% CO\n2. The HIV-vectored pNL4-\n3.Luc.R-E- and spike protein-expressing plasmids were co-\ntransfected with TurboFect transfection reagent (Thermo Scien-\ntiﬁc). Supernatants were collected 24-, 48-, and 72-hours post-\ntransfection, ﬁltered, aliquoted and frozen at−80 °C before use.\nNeutralizing activity in each sample was measured with a serial\ndilution approach. Each sample was serially diluted 3-fold in\nduplicate from 1:30 to 1:7290 in complete DMEM before\nincubation with the titrated pseudovirus SARS-CoV-2 (105 RLU\nper well) for 1 hour prior to the addition of 2 × 104 293T-ACE2\ncells. Following a 48 h incubation period at 37 °C and 5% CO\n2,\nluciferase activity was determined with the Brite-LiteTM Luciferase\nAssay System (Vazyme) using the GloMax® Navigator Microplate\nLuminometer (Promega). EC50 neutralization titers were calcu-\nlated using the Reed-Muench method. The lower limit of detection\n(LLOD) was 30, and titers below the LLOD were set to 15.\nFlow cytometry\nFor S protein expression and conformational veri ﬁcation,\n293 T cells were seeded into 24-well plates (Corning) and\ntransfected with 0.5 μg of plasmids encoding full-length SARS-\nCoV-2 S protein or its mutants using Lipo3000 reagent (Invitrogen,\nL3000015). After cultivation at 37 °C for 36 h, the medium was\nremoved, and cells were collected using PBS containing 0.02%\nEDTA. Cells were washed with PBS by centrifugation at 600 × g for\n5 min and then incubated with 5μg/mL ﬂuorescein isothiocyanate\n(FITC) (Sigma, F4274) -labelled recombinant ACE2 protein (Sino\nBioligical, 10108-H08B) at 37 °C for 1 h. Cells were washed and\nanalyzed on a FACSCanto IIﬂow cytometer (BD Biosciences).\nDonor vaccination and blood sampling\nFifty healthy adults were vaccinated with the aerosolized\nadenovirus type-5 vector-based COVID-19 vaccine (Ad5-nCoV)\nand were infected with SARS-CoV-2 Omicron variants around\n2022/12 when the BA.5 and BQ.1 variants were dominant. Blood\nsamples, including plasma and PBMCs, were collected at least\n3 weeks after the fully recovered illustrated by the nucleic acid test\n(NCT). All donors provided written informed consent, and this\nstudy was approved by the Medical Ethics Committee. PBMCs\nwere separated from blood samples using Ficoll density gradient\ncentrifugation (Tianjinhaoyang Biological Manufacture), and the\nblood samples were slowly transferred above equal-volume\nlymphocyte separation medium. After centrifugation at 800 × g\nfor 30 min, PBMCs were collected, washed twice with PBS,\nresuspended in cell freezing medium (90% FBS and 10% dimethyl\nsulfoxide (DMSO)), and stored at−80 °C until use.\nPhylogenetic tree construction of SARS-CoV-2 variants\nThe variant strains of the phylogenetic tree were selected based\non their demonstrated increase in infectivity, escape ability, or\nboth. These include eight strains with enhanced infectivity,ﬁve\nstrains with augmented escape ability, and two strains exhibiting\nboth attributes. The selected compared strains encompass the\nwild-type Wuhan-Hu-1 (WT), as well as prevalent variants\nincluding BA.1.1_UJJ91847.1, BA.2_UZT65727.1, BA.5_UXR22400.1,\nBF.7_UXM55527.1, BQ.1_UYI38611.1, XBB.1.5_WBA68774.1,\nXBB.1.9_WDB06325.1, XBB.1.16_WFD66465.1.\nAverage daily prevalence of SARS-CoV-2 variants\nTo evaluate the prevalence of the identiﬁed pivotal mutation sites\nin real-world, we conducted analysis of the average daily\nprevalence of SARS-CoV-2 variants on a global scale. The data\nwas sourced from the genomic reports provided by Outbreak.info\n(https://outbreak.info/), a platform known for its scalable and\ndynamic surveillance of SARS-CoV-2 variants and mutations. The\nprevalence of the “S:R346T, S:K444T, S:N460K ” variant was\ncalculated by dividing the number of cases of the variant by the\ntotal number of cases for each 7 days (from Jan 2020 to June\n2023). The error bands show the 95% binomial proportion\nconﬁdence interval calculated using Jeffrey’s interval.\n3D structure illustration of spike protein and the structural change\nanalysis\nThe protein structure information of BA.5 spike protein was\nretrieved from protein databank (PDB) website ( https://\nwww.rcsb.org) with PDB code 7xnq. Due to the lack of structure\nin furin cleavage site, the missing structure was predicted and\ncompleted by Phyre2 website ( https://www.sbg.bio.ic.ac.uk/\n~phyre2). The completed structure was uploaded in Missense\nA predictive language model for SARS-CoV-2 evolution\nMa et al.\n15\nSignal Transduction and Targeted Therapy           (2024) 9:353 \n3D ( http://missense3d.bc.ic.ac.uk/) for predicting the effect of\nstructural changes introduced by each amino acid substitution.\nSequence alignment and Model Comparison\nSequence alignment and BLAST are based on Geneious Prime\n(version 2024.0.05). The EVEscape model is downloaded from the\nGithub repository ( https://github.com/OATML-Markslab/\nEVEscape), and the MLAEP model also from the Github repository\n(https://github.com/WHan-alter/MLAEP). Python 3.9 and Jupyter\nNotebook 9.6.4 are used to construct random generators and\ndiscover mutants from a given sequence. We choose BA.2 as the\noriginal sequence for the random generator as it is the most\ndominant variant during the timeframe of dataset-1, so we can\ncompare it with sequences generated by dataset-1 by our model.\nStatistical analysis\nIn the present study, GraphPad Prism 8.0 was used for statistical\ncalculations and data plotting. For infectivity experiment, TCID50\nvalue differences between the BA.5 control and the predicted\nsamples were evaluated by Mann‒Whitney U test. For neutraliza-\ntion assay, differences of EC50 were analyzed by paired-t test. All\ntests were two-tailed, unless otherwise indicated. We considered a\nthreshold p-value < 0.05 to indicate statistical signiﬁcance, and the\nsigniﬁcance values were set as *.\nDATA AVAILABILITY\nThe source data that support theﬁndings of this study are upon request or available\nat Github repositoryhttps://github.com/athirma/SVEP.\nMATERIALS AVAILABILITY\nCorrespondence and requests for materials should be addressed to G.C. (gong-\ncheng@mail.tsingua.edu.cn). For unexpected missing messages, alternative contacts\ncould be C.W. (weicongwen@aliyun.com), E.M. (meh20@mail.tsinghua.edu.cn), X.G.\n(15210418734@163.com), P.W. (pewang@uchc.edu).\nCODE AVAILABILITY\nThe source code that support the ﬁndings of this study are available at Github\nrepository https://github.com/athirma/SVEP.\nACKNOWLEDGEMENTS\nWe thank the core facilities of the Center for Life Sciences and Center of Biomedical\nAnalysis for technical assistance (Tsinghua University). We acknowledge the Protein\nPreparation and Characterization Core Facility of Tsinghua University Branch of China\nNational Center for Protein Sciences Beijing and Zi Yang for providing the facility\nsupport. We thank Xiangyang Chi, Xiaodong Zai, Zhe Zhang, and Pengfei Fan for their\nhelp in experiment conduction and models’ validation. This work was funded by\ngrants from the National Natural Science Foundation of China (32188101,\n81961160737, and 31825001) to G.C., the National Key Research and Development\nPlan of China (2021YFC2300200, 2020YFC1200104, 2021YFC2302405,\n2022YFC2303200, and 2022YFC2303400), Tsinghua-Foshan Innovation Special Fund\n(TFISF) (2022THFS6124), Shenzhen San-Ming Project for Prevention and Research on\nVector-borne Diseases (SZSM201611064), Shenzhen Science and Technology Project\n(JSGG20191129144225464) to G.C. Shenzhen Medical Research Fund (2404002),\nInnovation Team Project of Yunnan Science and Technology Department\n(202105AE160020), and the Yunnan Cheng gong expert workstation\n(202005AF150034) to G.C. This work is alsoﬁnancially supported by XPLORER PRIZE\nfrom Tencent Foundation.\nAUTHOR CONTRIBUTIONS\nG.C. and X.G. came up with the perception of the study. X.G. and E.M. prepared the\ndata and constructed the prediction model. X.G., E.M., M.H., and X.W. revised and\nupdated the model. G.C. and C.W. designed the wet experiments. E.M. and C.W.\ncollected and analyzed the experiment data. X.G., E.M., P.W., and G.C. prepared the\nmanuscript. G.C., P.W., X.G., E.M., and M.H. revised and polished the paper. All authors\nhave read and approved the article.\nADDITIONAL INFORMATION\nSupplementary information The online version contains supplementary material\navailable at https://doi.org/10.1038/s41392-024-02066-x.\nCompeting interests:The authors declare no competing interests.\nREFERENCES\n1. Huang, Y., Yang, C., Xu, X. F., Xu, W. & Liu, S. W. Structural and functional prop-\nerties of SARS-CoV-2 spike protein: potential antivirus drug development for\nCOVID-19. Acta Pharmacol. Sin.41, 1141– 1149 (2020).\n2. WHO. WHO Coronavirus (COVID-19) Dashboard.https://covid19.who.int.\n3. Tai, W. et al. Development of a ferritin-based nanoparticle vaccine against the\nSARS-CoV-2 Omicron variant.Sig. Transduct. Target. Ther.7, 173 (2022).\n4. Aldridge, R. W. et al. SARS-CoV-2 antibodies and breakthrough infections in the\nVirus Watch cohort.Nat. Commun. 13, 4869 (2022).\n5. Souza, T. M. L. et al. Preclinical development of kinetin as a safe error-prone SARS-\nCoV-2 antiviral able to attenuate virus-induced inﬂammation. Nat. Commun. 14,\n199 (2023).\n6. Maher, C. M. et al. Predicting the mutational drivers of future SARS-CoV-2 variants\nof concern. Sci. Trans. Med.14, 3445 (2022).\n7. Jian, F. et al. Further humoral immunity evasion of emerging SARS-CoV-2 BA.4\nand BA.5 subvariants.Lancet Infect. Dis.22, 1535– 1537 (2022).\n8. Wang, Q. et al. Antibody evasion by SARS-CoV-2 Omicron subvariants BA.2.12.1,\nBA.4 and BA.5.Nature 608, 603– 608 (2022).\n9. Wang, Z. et al. mRNA vaccine-elicited antibodies to SARS-CoV-2 and circulating\nvariants. Nature 592, 616– 622 (2021).\n10. Flemming, A. SARS-CoV-2 variant evades antibodies whilst maintainingﬁtness.\nNat. Rev. Immunol.21, 136 (2021).\n11. Zhu, A. et al. Antigenic characteriza tion of SARS-CoV-2 Omicron subvariants\nXBB.1.5, BQ.1, BQ.1.1, BF.7 and BA.2.75.2. Sig. Transduct. Target Ther. 8, 125\n(2023).\n12. Taft, J. M. et al. Deep mutational learning predicts ACE2 binding and antibody\nescape to combinatorial mutations in the SARS-CoV-2 receptor-binding domain.\nCell 185, 4008– 4022 (2022).\n13. Kaufer, A. M., Theis, T., Lau, K. A., Gray, J. L. & Rawlinson, W. D. Laboratory\nbiosafety measures involving SARS-CoV-2 and the classiﬁcation as a Risk Group 3\nbiological agent. Pathology 52, 790– 795 (2020).\n14. Nie, J. et al. Quantiﬁcation of SARS-CoV-2 neutralizing antibody by a pseudotyped\nvirus-based assay. Nat. Protoc. 15, 3699– 3715 (2020).\n15. Carabelli, A. M. et al. SARS-CoV-2 variant biology: immune escape, transmission\nand ﬁtness. Nat. Rev. Microbiol.21, 162–\n177 (2023).\n16. Nyberg, T. et al. Comparative analysis of the risks of hospitalisation and death\nassociated with SARS-CoV-2 omicron (B.1.1.529) and delta (B.1.617.2) variants in\nEngland: A cohort study.Lancet 399, 1303– 1312 (2022).\n17. Xiang, T., Wang, J. & Zheng, X. The humoral and cellular immune evasion of SARS-\nCoV-2 Omicron and sub-lineages.Virol. Sin. 37, 786– 795 (2022).\n18. Cao, Y. et al. BA.2.12.1, BA.4 and BA.5 escape antibodies elicited by Omicron\ninfection. Nature 608, 593– 602 (2022).\n19. Ofer, D., Brandes, N. & Linial, M. The language of proteins: Nlp, machine\nlearning & protein sequences. C o m p u t .S t r u c t .Biotechnol. J. 19,1 7 5 0– 1758\n(2021).\n20. Bepler, T. & Berger, B. Learning the protein language: Evolution, structure, and\nfunction. Cell Syst. 12, 654– 669 (2021).\n21. Hie, B. et al. Learning the language of viral evolution and escape.Science 371,\n284– 288 (2021).\n22. Li, J., Wu, Y. N., Zhang, S., Kang, X. P. & Jiang, T. Deep learning based on biolo-\ngically interpretable genome representation predicts two types of human\nadaptation of SARS-CoV-2 variants.Brief. Bioinform. 23, bbac036 (2022).\n23. Strait, B. J. & Dewey, T. G. The shannon information entropy of protein sequences.\nBiophys. J. 71, 148– 155 (1996).\n24. Zahradník, J. et al. SARS-CoV-2 variant prediction and antiviral drug design are\nenabled by RBD in vitro evolution.Nat. Microbiol. 6, 1188– 1198 (2021).\n25. Sanjuán, R. & Domingo-Calap, P. Mechanisms of viral mutation.Cell Mol. Life Sci.\n73, 4433– 4448 (2016).\n26. Zhu, K. L. et al. Durability of neutralization against Omicron subvariants after\nvaccination and breakthrough infection.Cell Rep. 42, 112075 (2023).\n27. Cao, Y. et al. Imprinted SARS-CoV-2 humoral immunity induces convergent\nOmicron RBD evolution.Nature 614, 521– 529 (2023).\n28. Ito, J. et al. Convergent evolution of SARS-CoV-2 Omicron subvariants leading to\nthe emergence of BQ.1.1 variant.Nat. Commun. 14, 2671 (2023).\n29. Zhou, B. et al. Tempo: A transformer-based mutation prediction framework for\nSARS-COV-2 evolution. Comput. Biol. Med.152, 106264 (2023).\n30. Thadani, N. N. et al. Learning from prepandemic data to forecast viral escape.\nNature 622, 818– 825 (2023).\nA predictive language model for SARS-CoV-2 evolution\nMa et al.\n16\nSignal Transduction and Targeted Therapy           (2024) 9:353 \n31. Han, W. et al. Predicting the antigenic evolution of SARS-COV-2 with deep\nlearning. Nat. Commun. 14, 3478 (2023).\n32. Hie, B. L., Yang, K. K. & Kim, P. S. Evolutionary velocity with protein language\nmodels predicts evolutionary dynamics of diverse proteins.Cell Syst.13, 274– 285\n(2022).\n33. Amicone, M. et al. Mutation rate of SARS-CoV-2 and emergence of mutators\nduring experimental evolution.Evol. Med. Public. Hlth.10, 142– 155 (2022).\n34. Qu, P. et al. Enhanced neutralization resistance of SARS-CoV-2 Omicron subvariants\nBQ.1, BQ.1.1, BA.4.6, BF.7, and BA.2.75.2.Cell Host Microbe31,9 – 17 (2022).\n35. Mohapatra, R. K. et al. Renewed global threat by the novel SARS-CoV-2 variants\n‘XBB, BF.7, BQ.1, BA.2.75, BA.4.6’: A discussion.Front. Virol. 2,1 – 5 (2022).\n36. Wang, Q. et al. Alarming antibody evasion properties of rising SARS-CoV-2 BQ\nand XBB subvariants.Cell 186, 279– 286 (2022).\n37. Uraki, R. et al. Humoral immune evasion of the omicron subvariants BQ.1.1 and\nXBB. Lancet Infect. Dis.23,3 0– 32 (2023).\n38. Yamasoba, D. et al. Virological characteristics of the SARS-CoV-2 omicron\nXBB.1.16 variant. Lancet Infect. Dis.23, 655– 656 (2023).\n39. McKinney, W. P. Pandas: a foundational python library for data analysis and\nstatistics. Python High. Perform. Sci. Comput.14,1 – 9 (2011).\n40. Madgwick, R. et al. Multi-isotope analysis reveals that feasts in the Stonehenge\nenvirons and across Wessex drew people and animals from throughout.Br. Sci.\nAdv. 5, 6078 (2019).\n41. Jolliffe, I. T. Principal Component Analysis (second ed.), Springer– Verlag, New\nYork, NY (2002).\n42. van Marle, M. J. E. et al. New land-use-change emissions indicate a declining CO2\nairborne fraction. Nature 603, 450– 454 (2022).\n43. Bryant, P. et al. Predicting the structure of large protein complexes using\nAlphaFold and Monte Carlo tree search.Nat. Commun. 13, 6028 (2022).\n44. Baerlocher, C. et al. Unraveling the Perplexing Structure of the Zeolite SSZ-57.\nScience 333, 1134– 1137 (2011).\n45. Chen, M. & Zhang, X. E. Construction and applications of SARS-CoV-2 pseudo-\nviruses: a mini review.Int. J. Biol. Sci.17, 1574– 1580 (2021).\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long as you give\nappropriate credit to the original author(s) and the source, provide a link to the Creative\nCommons licence, and indicate if changes were made. The images or other third party\nmaterial in this article are included in the article’s Creative Commons licence, unless\nindicated otherwise in a credit line to the material. If material is not included in the\narticle’s Creative Commons licence and your intended use is not permitted by statutory\nregulation or exceeds the permitted use, you will need to obtain permission directly\nfrom the copyright holder. To view a copy of this licence, visit http://\ncreativecommons.org/licenses/by/4.0/.\n© The Author(s) 2024\nA predictive language model for SARS-CoV-2 evolution\nMa et al.\n17\nSignal Transduction and Targeted Therapy           (2024) 9:353 ",
  "topic": "Randomness",
  "concepts": [
    {
      "name": "Randomness",
      "score": 0.7663566470146179
    },
    {
      "name": "Mutation",
      "score": 0.5295038223266602
    },
    {
      "name": "Computational biology",
      "score": 0.5287786722183228
    },
    {
      "name": "Computer science",
      "score": 0.48038846254348755
    },
    {
      "name": "Biology",
      "score": 0.42803749442100525
    },
    {
      "name": "Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)",
      "score": 0.4164830446243286
    },
    {
      "name": "Coronavirus disease 2019 (COVID-19)",
      "score": 0.41414502263069153
    },
    {
      "name": "Genetics",
      "score": 0.33888494968414307
    },
    {
      "name": "Medicine",
      "score": 0.18203112483024597
    },
    {
      "name": "Mathematics",
      "score": 0.1579795479774475
    },
    {
      "name": "Gene",
      "score": 0.1395038366317749
    },
    {
      "name": "Statistics",
      "score": 0.10427796840667725
    },
    {
      "name": "Infectious disease (medical specialty)",
      "score": 0.10024330019950867
    },
    {
      "name": "Disease",
      "score": 0.09032002091407776
    },
    {
      "name": "Pathology",
      "score": 0.0
    }
  ]
}