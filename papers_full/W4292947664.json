{
    "title": "A Multimodal Transformer: Fusing Clinical Notes with Structured EHR Data for Interpretable In-Hospital Mortality Prediction",
    "url": "https://openalex.org/W4292947664",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A5078077401",
            "name": "Weimin Lyu",
            "affiliations": [
                "Stony Brook University"
            ]
        },
        {
            "id": "https://openalex.org/A5019670923",
            "name": "Xinyu Dong",
            "affiliations": [
                "Stony Brook University"
            ]
        },
        {
            "id": "https://openalex.org/A5086498395",
            "name": "Rachel Wong",
            "affiliations": [
                "Stony Brook University"
            ]
        },
        {
            "id": "https://openalex.org/A5073393494",
            "name": "Songzhu Zheng",
            "affiliations": [
                "Stony Brook University"
            ]
        },
        {
            "id": "https://openalex.org/A5039009576",
            "name": "Kayley Abell-Hart",
            "affiliations": [
                "Stony Brook University"
            ]
        },
        {
            "id": "https://openalex.org/A5100704639",
            "name": "Fusheng Wang",
            "affiliations": [
                "Stony Brook University"
            ]
        },
        {
            "id": "https://openalex.org/A5100408397",
            "name": "Chao Chen",
            "affiliations": [
                "Stony Brook University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3026430905",
        "https://openalex.org/W3101973032",
        "https://openalex.org/W3125541356",
        "https://openalex.org/W2396881363",
        "https://openalex.org/W2158946857",
        "https://openalex.org/W3034266838",
        "https://openalex.org/W3017637887",
        "https://openalex.org/W2139865360",
        "https://openalex.org/W3094595351",
        "https://openalex.org/W2204794060",
        "https://openalex.org/W2612992329",
        "https://openalex.org/W3092301826",
        "https://openalex.org/W3184022450",
        "https://openalex.org/W2116451916",
        "https://openalex.org/W3095791468",
        "https://openalex.org/W2911489562",
        "https://openalex.org/W2504897554",
        "https://openalex.org/W3038139858",
        "https://openalex.org/W3195594441",
        "https://openalex.org/W3090266264",
        "https://openalex.org/W3113263159"
    ],
    "abstract": "Deep-learning-based clinical decision support using structured electronic health records (EHR) has been an active research area for predicting risks of mortality and diseases. Meanwhile, large amounts of narrative clinical notes provide complementary information, but are often not integrated into predictive models. In this paper, we provide a novel multimodal transformer to fuse clinical notes and structured EHR data for better prediction of in-hospital mortality. To improve interpretability, we propose an integrated gradients (IG) method to select important words in clinical notes and discover the critical structured EHR features with Shapley values. These important words and clinical features are visualized to assist with interpretation of the prediction outcomes. We also investigate the significance of domain adaptive pretraining and task adaptive fine-tuning on the Clinical BERT, which is used to learn the representations of clinical notes. Experiments demonstrated that our model outperforms other methods (AUCPR: 0.538, AUCROC: 0.877, F1:0.490).",
    "full_text": "American Medical Informatics Association (AMIA) Annual Symposium 2022\nA M ULTIMODAL TRANSFORMER : F USING CLINICAL\nNOTES WITH STRUCTURED EHR D ATA FOR INTER -\nPRETABLE IN-HOSPITAL MORTALITY PREDICTION\nWeimin Lyu1, Xinyu Dong1, Rachel Wong1, Songzhu Zheng1, Kayley Abell-Hart1,\nFusheng Wang1, Chao Chen1\n1 Stony Brook University, NY , USA\nABSTRACT\nDeep-learning-based clinical decision support using structured electronic health\nrecords (EHR) has been an active research area for predicting risks of mortality and\ndiseases. Meanwhile, large amounts of narrative clinical notes provide complemen-\ntary information, but are often not integrated into predictive models. In this paper,\nwe provide a novel multimodal transformer to fuse clinical notes and structured\nEHR data for better prediction of in-hospital mortality. To improve interpretability,\nwe propose an integrated gradients (IG) method to select important words in clinical\nnotes and discover the critical structured EHR features with Shapley values. These\nimportant words and clinical features are visualized to assist with interpretation of\nthe prediction outcomes. We also investigate the signiﬁcance of domain adaptive\npretraining and task adaptive ﬁne-tuning on the Clinical BERT, which is used to\nlearn the representations of clinical notes. Experiments demonstrated that our\nmodel outperforms other methods (AUCPR: 0.538, AUCROC: 0.877, F1:0.490).\n1 I NTRODUCTION\nElectronic health record (EHR) systems are widely used in the United States(Henry et al., 2016) and\nthe large amount of EHR data generated provides an opportunity for machine learning based predictive\nmodeling to improve clinical decision support. In particular, deep learning based techniques(Dalal\net al., 2021; Schwartz et al., 2021), have been used for prediction of in-hospital mortality(Kong et al.,\n2020; Li et al., 2021), diagnoses(Dong et al., 2019; Yang & Wu, 2021), length of stay(Cai et al.,\n2016), readmission(Teo et al., 2021).\nEHRs include structured data and clinical notes, which are often unstructured(Zheng et al., 2017).\nStructured clinical variables, such as the vital signals (e.g., heart rate, respiration rate, tempera-\nture, and blood pressure), can be easily converted to time series data and are well explored by\nresearchers(Sheikhalishahi et al., 2020; Rocheteau et al., 2021; Si et al., 2021). For example, Haru-\ntyunyan et al.(Harutyunyan et al., 2019) establishes a benchmark on how to pre-process the MIMIC\nIII dataset, and proposed various baselines for different tasks, e.g., Logistic Regression, Random\nForest, Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), and Convolutional\nNeural Network (CNN). Dong et al.(Dong et al., 2019) develops a machine learning based opioid\noverdose prediction method with different clinical variables. Unstructured clinical notes are often in\nfree narrative form, but contain complementary and rich contextual information, such as a patient’s\nsymptoms, disease course and treatment(Lee et al., 2020). Though the normally pre-trained natural\nlanguage model Bidirectional Encoder Representations from Transformers (BERT)(Devlin et al.,\n2019) cannot handle speciﬁc clinical notes, there are different variants of BERTs(Harutyunyan et al.,\n2019; Gururangan et al., 2020; Alsentzer et al., 2019), that are pretrained on biomedical and clinical\ndata, which can better handle clinical notes. For example, Clinical BERT(Huang et al., 2019) pretrains\nthe BERT using MIMIC III clinical notes with masked language modeling (MLM) and next sentence\nprediction (NSP), to predict hospital readmission. BEHRT(Li et al., 2020) incorporates age and\nposition information when modeling the clinical notes. BioBERT(Lee et al., 2020) is pretrained\n1\narXiv:2208.10240v2  [cs.CL]  9 May 2023\nAmerican Medical Informatics Association (AMIA) Annual Symposium 2022\non biomedical notes like PubMed abstracts and PubMed Central full-text articles to signiﬁcantly\nimprove biomedical text mining task performance. BioRoberta(Gururangan et al., 2020) points out\nthat in-domain pretraining leads to performance gains. Clinical BERT(Huang et al., 2019) uses a\ndomain-speciﬁc model to improve performance on three common clinical NLP tasks. BLURB(Gu\net al., 2021) benchmark is a recent work that released state-of-the-art pretrained and task-speciﬁc\nmodels for the community. Despite these advances, how to leverage and interpret the information\nincluded in unstructured clinical notes remains a challenging problem.\nMultimodal fusion is a promising direction to address the aforementioned challenge. However, naively\nconcatenating features from different modalities might result in worse performances(Ramachandram\n& Taylor, 2017). It is challenging to embed data from the structured clinical variables and unstructured\nclinical notes together because they are two totally different domains. Siet al.(Si et al., 2021) provides\na comprehensive survey on deep representation learning from single and multiple domains of EHR\ndata. Some works merely extract features from structured and unstructured data separately, and then\nconcatenate the two features(Zhang et al., 2020). For example, Khadangaet al.(Khadanga et al., 2019)\nextracts clinical notes with convolutional neural networks and incorporates time series data to improve\nthe performance. Deznabi et al.(Deznabi et al., 2021) models two modalities with Long short-term\nmemory (LSTM) and BERT. Yanget al.(Yang & Wu, 2021) implements Multimodal Adaptation Gate\n(MAG)(Rahman et al., 2020) techniques to best utilize information from two modalities. Teixeira\net al.(Teixeira et al., 2017) tested different combinations of several different modalities. Huang\net al.(Huang et al., 2020) discuss fusion strategies of structured data and imaging data. However,\nthese methods naively concatenate without considering complexity of modality and time information.\nWhile transformers are gaining popularity for use in different domains, there is limited work using\ntransformers on EHR based predictive modeling.\nIn this paper, we propose a multimodal transformer to fuse time series data from clinical variables\nwith textual information from clinical notes to boost performance of in-hospital mortality prediction.\nWe leverage clinical notes to provide auxiliary information by adjusting the representation from\ntwo modalities to a sharable space across different times, then jointly learn the representation\nfrom two modalities. Further, we implement the transformer on the time series EHR data to fully\nconsider the information across time, combined with the ﬁne-tuned Clinical BERT model, which\nis a novel application of EHR feature representation learning. We also show that pre-training of\nvarious BERT models results in different prediction ability with regard to clinical tasks, and the\nBERT models ﬁne-tuned on the speciﬁc in-hospital prediction task brings further performance\nimprovements. Furthermore, we extend our ﬁne-tuned Clinical BERT model with the integrated\ngradients (IG) method to interpret and visualize the important words in clinical notes. Our results\ndemonstrate that by leveraging the clinical notes, our proposed Multimodal Transformer provides\nhighly promising prediction results (with AUCPR: 0.538, AUCROC: 0.877, F1:0.490). To our best\nknowledge, our Multimodal Transformer is the ﬁrst work utilizing the transformer block to fuse\nclinical notes information and clinical variable information, while including time series EHR data.\n2 M ETHODS\n2.1 S TUDY DATASET\nWe extract inpatient EHR data from the Medical Information Mart for Intensive Care (MIMIC-III)\ndataset(Johnson et al., 2016). The clinical variables are pre-processed as time series signals from ICU\ninstruments following Harutyunyan et al.(Harutyunyan et al., 2019) benchmark setup. Seventeen\nclinical variables remained after preprocessing: capillary reﬁll rate; diastolic blood pressure; fraction\ninspired oxygen; the eye opening, motor response, verbal response, and total value of the Glasgow\nComa Scale; glucose; heart rate; height; mean blood pressure; oxygen saturation; respiratory rate;\nsystolic blood pressure; temperature; weight; and pH.\nFor the clinical notes, similar to the setup from Khadanga et al.(Khadanga et al., 2019), we extract\nnotes from the NOTEEVENTS.csv ﬁle, and remove all clinical notes that do not have any chart time\nassociated and remove patients that do not have any clinical notes. While Khadanga et al.kept only\nthe ﬁrst visit for each patient, we treat every visit as a single sample. Therefore, in the following\npaper, we use ‘patient’ to indicate ‘visit’. After the above data processing, our dataset for in-hospital\nmortality prediction contains 14068 training samples, 3086 validation samples, and 3107 test samples.\n2\nAmerican Medical Informatics Association (AMIA) Annual Symposium 2022\nTable 1: Four BERT models and their respective corpora used for pretraining. Initialized model\nindicates the starting point before pretraining.\nPretrained Model Pretraining Corpora Initialized Model Domain\nBERT English Wikipedia, BooksCorpus General\nBioRoBERTa S2ORC RoBERTa Biomedical\nBioBERT PubMed Abstracts, PMC Full-text articles BERT Biomedical\nClinical BERT MIMIC notes BioBERT Biomedical\nDue to this step, our results are not directly comparable to the benchmark from Harutyuanyan et\nal.(Harutyunyan et al., 2019).\nFigure 1: An example of MIMIC III EHR data for ICU patients, containing two modalities: clinical\nvariables and clinical notes. The clinical variables can be further split into categorical and numerical\nvariables, while the clinical notes are domain speciﬁc text.\n2.2 S INGLE MODEL EMBEDDING\nWe aim to predict in-hospital mortality with multi-modal EHR data. First, we process two single\nmodalities (clinical notes and clinical variables) separately to obtain the initialized embeddings from\nthe raw data. We introduce Notes Embedding and Variables Embedding to achieve the initialized\nsingle modality embedding.\nClinical Notes Embedding.Though BERT models dominate increasing numbers of domains in\nNLP, BERT-based models do not necessarily offer strong clinical text mining ability with regard\nto a speciﬁc clinical task. Rather, the power of BERT-family models relies on domain adaptive\npretraining and task adaptive ﬁne-tuning. Pre-training on proper clinical biomedical corpora enables\nthe BERT-based model to better learn clinical contextual meaning representations, and ﬁne-tuning on\ndownstream tasks can further boost this ability and establish a specialized Clinical BERT model. To\nillustrate this point, we compare the representation ability of four different BERT models (Table 1)\nusing only single clinical notes modality, namely BERT(Devlin et al., 2019), BioBERT(Lee et al.,\n2020), BioRoBERTa(Gururangan et al., 2020), Clinical BERT(Huang et al., 2019), pertained on four\ntypes of corpora, respectively English Wikipedia / BooksCorpus, PubMed Abstracts / PMC Full-text\narticles (initialized from BERT), S2ORC,33 and entire MIMIC III notes (initialized from BioBERT).\nDetailed results are shown in Table 4.\nWe select Clinical BERT(Huang et al., 2019) as our pre-trained language model since it is a more\nproper domain-speciﬁc model trained on all MIMIC-III clinical notes. We further ﬁne-tune the\nClinical BERT with the in-hospital mortality prediction task on MIMIC-III, called MIMIC BERT\n(MBERT), which enables the Clinical BERT to learn better clinical speciﬁc contextual embeddings\non speciﬁc MIMIC data. For each patient, we extract an embedding of the clinical notes for every\nassociated hour to represent the clinical notes data with time information. In the following experi-\nments, we freeze the weights of MBERT when extracting unstructured clinical notes embeddings in\nmultimodal transformer, since the MBERT already preserves a good clinical meaning representation.\nClinical Variables Embedding.Given that clinical variables contain numerical and categorical data,\nwe apply one-hot encoding to the clinical variables, illustrated in Figure 2. Following Harutyunyan’s\nsetup, the 17 clinical variables are embedded to a 76-dimension time series embedding after the\n3\nAmerican Medical Informatics Association (AMIA) Annual Symposium 2022\nFigure 2: An illustration of Clinical Variables Encoding.\none-hot encoding. The categorical variables are converted to one-hot vectors while the numerical\nvariables are converted to a single continuous value.\nFor a formal mathematical representation, we denote the clinical notes data as Xnotes ∈RL×D1 ,\nwhere L represents the length of ICU stay counted by hours, and D1 represents the maximum\nlength of clinical notes. And we denote the clinical variables data as Xts ∈RL×D2 , where D2\nrepresents the number of variables. The clinical notes are embedded with Fine-tuned Clinical\nBERT (MBERT), as Enotes = MBERT (Xnotes), and the clinical variables are embedded as\nEts = V ariable_Encoding(Xts).\n2.3 M ULTIMODAL EMBEDDING\nWe introduce a transformer to integrate two different modalities. Speciﬁcally, we introduce three\nencoders inside the transformer block: Notes Encoder and Time Series (TS) Encoder for clinical notes\nand clinical variables modalities separately, and Multimodal (MM) Encoder to fuse two modalities\nwhile projecting them into a shared space:\nEncoders. (1) Notes Encoder. Given that the clinical notes embedding Enotes is already well\npresented, we only use a single linear layer to project Enotes to a universal space. (2) Time Series\n(TS) Encoder. Since the clinical variables embedding contains simple numerical and categorical\ninformation, we also use linear layers to project Ets to a universal space. (3) Multimodal (MM)\nEncoder. We do not simply concatenate the clinical notes and clinical variables because the two\nmodalities are conceptually different. We use a Multimodal Encoder to compact the two different\nmodalities into a universal space before we feed them into the transformer model, so that the\ninformation from clinical notes and clinical variables can be jointly learned. The formal mathematical\nrepresentation is as follows:\nInotes = Encodernotes(Enotes)\nIts = Encoderts(Ets)\nIMM = EncoderMM (Enotes ⊕Ets)\n(1)\nwhere ⊕denotes concatenate operation, Inotes ∈RL×D3 , Its ∈RL×D4 , IMM ∈RL×D5 denotes\noutputs from associate encoders, and D3, D4, D5 represent the corresponding embedding dimension.\nTransformer. Our transformer block is the key to handle time series embeddings and integrate\nknowledge. The transformer is a popular model developed for natural language processing (NLP),\nand has emerged as a promising tool in other domains. In LSTM, if the time sequence is too long,\nthen when the information is passed to the ﬁnal timestamp, the model forgets the information in the\nearlier timestamps. The powerful attention mechanism in the transformer enables the model to better\nleverage the information from all the timestamps. However, more research is needed to determine\nhow best to apply the transformer in clinical tasks, especially when using multimodal data. We\nsuccessfully implement the transformer in our study to show the capability of the transformer model.\nIn the NLP context, if one sentence has 48 tokens after tokenization, then the input of the NLP model\nwould be a 48-length sequence. Similarly, in the clinical time series context, we treat each hour as\none token. Since we consider the ﬁrst 48 hours in the ICU, there are 48 ‘tokens’ for one patient. In\nFigure 3, the multimodal embedding of one patient is shown. The position embedding encodes the\ntime information. In this way, the transformer block is able to consider information from all the time\n4\nAmerican Medical Informatics Association (AMIA) Annual Symposium 2022\nFigure 3: An illustration of the Transformer architecture. A. Adding the position embedding to\nconsider time information. B. Details of the transformer block. The fused transformer embedding\nis fed into the transformer encoder, and we only select the ‘T0’ token as the ﬁnal multimodal\nrepresentation.\nFigure 4: An illustration of the Transformer block.\nsequences when learning the representations. We use sinusoidal positional embedding in our model.\nSimilar to the NLP techniques, we insert the ‘CLS’ token at the beginning of the time sequences and\nuse the T0 as the ﬁnal multimodal representation. Figure 4 illustrates the detailed architecture of the\nwhole transformer block, with a formal mathematical presentation:\nIMultimodal = Transformer (IMM )\nThen we concatenate the multimodal representations IMultimodal and notes embedding Enotes to get\nthe ﬁnal prediction:\nPred = MLP (IMultimodal ⊕Enotes)\n2.4 O VERVIEW ARCHITECTURE\nThe overall architecture of our Multimodal Transformer is shown in Figure 5.\nImplementation. In our experiment, a rectiﬁed linear unit (ReLU) function is used as the non-\nlinear projection function across different layers to prevent vanishing gradient and sparse activation\n5\nAmerican Medical Informatics Association (AMIA) Annual Symposium 2022\nFigure 5: The overview architecture of our proposed Multimodal Transformer.\nTable 2: Statistics of the post-processed MIMIC III data for the in-hospital mortality prediction task.\nTrain Validation Test\nNegative 12216 2682 2748\nPositive 1852 404 359\nTotal 14068 3086 3107\nproblems. The sigmoid function is applied in the last layer. We use cross entropy loss and L2\nregularization as the loss function and the Adam optimization to minimize the loss. We use Python\nProgramming Language (Version3.8). Models are implemented with Python Pytorch(Paszke et al.,\n2019) and HuggingFace Transformers(Wolf et al., 2019). The training was performed on an NVIDIA\nRTX A5000 (24GB RAM).\n3 R ESULTS\n3.1 P REDICTION RESULTS ANALYSIS\nWe predict in-hospital mortality based on the ﬁrst 48 hours of an ICU stay, which is a binary\nclassiﬁcation task. We use the same train-test setting deﬁned in the benchmark(Harutyunyan et al.,\n2019) with 15% of the training data as a validation set, and similar to Khadanga et al.(Khadanga\net al., 2019), we remove all clinical notes that do not have any chart time associated and patients that\ndo not have any clinical notes. The statistics on the post-processed data are shown in Table 2.\nTo comprehensively evaluate the performance of our model, we compute the metrics AUCROC,\nAUCPR, and F1. As the dataset is imbalanced, other metrics such as accuracy, recall, and precision\nmay be misleading. We run all experiments ﬁve times with different initialization and report the mean\nand standard deviation of the results.\nResults in Table 3 demonstrate that our models outperform other methods in classifying in-hospital\nmortality. We achieve an AUCPR score of 0.538, an AUCROC score of 0.877, and an F1 score of\n0.490.\nTable 3: Experiment Results of different methods on MIMIC III In-Hospital Mortality Prediction\nTask.\nPrediction Model AUCPR AUCROC F1\nOnly Variables LSTM 0.460(±0.013) 0.821(±0.006) 0.392(±0.038)\nTransformer 0.473(±0.011) 0.827(±0.005) 0.406(±0.025)\nOnly Notes MBERT 0.482(±0.012) 0.851(±0.005) 0.382(±0.079)\nFusion MBERT+LSTM 0.508(±0.002) 0.859(±0.001) 0.478(±0.023)\nMultimodal Transformer (Ours)0.538(±0.004) 0.877(±0.001) 0.490(±0.036)\n6\nAmerican Medical Informatics Association (AMIA) Annual Symposium 2022\nTable 4: Experiments on various Pre-trained and Fine-tuned BERTs. Use only MIMIC III clinical\nnotes for in-hospital mortality prediction without considering clinical variables information. Freeze\nindicates only training the ﬁnal classiﬁer while keeping the BERT models unchanged. Fine-tuned\nindicates ﬁne-tuning the BERTs for the in-hospital mortality downstream task.\nAUCPR AUCROC F1 AUCPR AUCROC F1\nFreeze Fine-tuned\nBERT 0.182(±0.016) 0.649(±0.020) 0(±0) 0.417(±0.023) 0.829(±0.005) 0.342(±0.054)\nBioRoBERTa 0.182(±0.013) 0.661(±0.016) 0(±0) 0.455(±0.010) 0.841(±0.005) 0.419(±0.044)\nBioBERT 0.191(±0.005) 0.664(±0.011) 0(±0) 0.444(±0.027) 0.843(±0.006) 0.377(±0.045)\nClinical BERT0.265(±0.006) 0.731(±0.004) 0(±0) 0.482(±0.012) 0.851(±0.005) 0.382(±0.079)\nIn the following section, we ﬁrst investigate variants of BERT models with regard to pretraining and\nﬁne-tuning. Then, we visualize the important words in clinical notes by Integrated Gradient. Finally,\nwe analyze the important clinical variables with the Shapley value(Lundberg & Lee, 2017).\n3.2 DOMAIN ADAPTIVE PRETRAINING AND TASK ADAPTIVE FINE -TUNING ON BERT MODELS\nIn order to show the importance of domain adaptive pretraining and task adaptive ﬁne-tuning in\nBERTs, we conduct an ablation study with only the pretrained models versus with ﬁne-tuning using a\nsingle modality - clinical notes. The results are shown in Table 4. As expected, the general-purpose\n‘BERT’ achieves the poorest result, whereas the MBERT achieves the best performance. These\nexperiments suggest that clinical notes with proper trained language model are able to provide\nhelpful information in clinical tasks, which enables deep learning techniques to leverage rich textual\ninformation to better understand the patient situation.\n3.3 C LINICAL NOTES VISUALIZATION AND INTERPRETATION\nTo provide an interpretation for the clinical notes and to better visualize the information, we evaluated\nthe words that were important for prediction in our MBERT model using Integrated Gradients\n(IG)(Sundararajan et al., 2017). We apply the IG method to study the problem of attributing the\nprediction of a deep network to its input features, as an attempt towards explaining individual\npredictions. IG is computed based on the gradient of the prediction outputs considering the input\nwords. Higher IG values indicate that a word is more important to the model’s prediction, while\nsmaller IG values indicate that a word is less important. We compute the IG value of all tokens in\nthe clinical notes for all patients in the test data, and list the tokens with the highest IG values. Note\nthat due to the BERT tokenization mechanism, the inputs are tokens instead of words. For example,\nthe phrase “the patient has been extubated” would be tokenized to “the patient has been ex##tub\n##ated” as the input. To make the results more readable, we remove all the numbers, tokens that\nonly have one or two characters, and separators in post processing. The tokens and their IG values\nare evaluated by a clinician for their clinical meaningfulness for mortality prediction. The tokens are\nsorted by those that are “Clinically Meaningful Indicators” of symptoms, prognosis, or care; “Unclear\nTokens” which are difﬁcult to attribute a single meaning to; and Headers/Common Words that are\nparts of structured notes or ubiquitously words used in medical notes, illustrated in Figure 6.\nSeveral words with high IG values appear to be parts of structured headers, such as “medical\ncondition,” “diagnosis” or “impression,” so are categorized separately from text that was unstructured.\nAdditional words that are used ubiquitously in clinical notes, such as “year,” “old,” and “with” are\nalso categorized separately as they were less likely to distinguish prognostic differences. Evaluating\nthe top 20 clinically meaningful indicators that are important for mortality prediction, there are some\ninteresting observations for clinical interpretation. “Pain”, which is the indicator most important for\nprediction, is a common symptom in ICU care and can correlate with disease severity or disability.\nIndicators 2-6 correspond to pulmonary pathology, and the attribution of high importance to these\nindicators is in line with severity of respiratory illness and the need for ICU level care such as\nmechanical ventilation. Other indicators, such as “fever” or “seizure”, are manifestations of acute\nillness, which could also have prognostic signiﬁcance in predicting mortality. Clinical indicators such\nas “status,” “commands,” “mental,” and “agitation” corresponded to mental status, and as delirium is\nassociated with worse prognosis, it is not surprising that these indicators have prognostic importance\nin prediction.35,36 Additional words such as “care” had multiple contexts when reviewing the notes;\n7\nAmerican Medical Informatics Association (AMIA) Annual Symposium 2022\nFigure 6: Top 20 Features Integrated Gradient Values Sorted for interpretability. The results come\nfrom patients in test data.\nphrases such as “plan of care” or “resp care” are often used as headers, but used in other contexts it\ncould be interpreted as a poor prognostic signal (e.g. “withdrawal of care”) or a favorable prognostic\nsignal (e.g. “ response to care”).\nFigure 7.A is the word cloud visualization of the top 200 important words. We select the top 10\nwords with highest IG in every note, and compute all the notes. Says there are 10000 notes, then\nthere would be 10*10000 top words (repeatable), and we compute the frequency of each unique word.\nThe font size reﬂects the frequency. Figure 7.B is a demo illustration of word importance among the\nclinical notes.\nFigure 7: A: Word Cloud for clinical tokens with high IG values. Larger font indicates the word is\nmore likely to appear as a top-ten IG value in clinical notes. B: Illustration of word importance in\nclinical notes based on IG value. The darker green color indicates the words that are more important\n(higher IG value) to the prediction, while the black color is background color.\n3.4 C LINICAL VARIABLES FEATURE ANALYSIS\nNext, we implement Shapley values to rank the important clinical variables. Shapley values(Lundberg\n& Lee, 2017) involve a game theory-based approach to explain the prediction of deep learning models.\nThey measure the contribution of a given feature value to the difference from the actual prediction\nto the mean prediction. The top 10 out of 17 clinical variables (Figure 8) show that for structured\nEHR data, the highest ranked variables also correlate with disease severity and poorer prognosis.\nThese variables represent clinically important information such as mental status using the Glasgow\nComa Scale, respiratory status and oxygenation, and hemodynamic measurements. They also provide\ninterpretability of the directionality of impact for continuous variables, with poor prognostic variables\nlike higher need for supplemental oxygen (Fraction inspired oxygen) increasing the likelihood for\n8\nAmerican Medical Informatics Association (AMIA) Annual Symposium 2022\npredicting death, and favorable prognostic variables, like higher blood systolic and blood pressure\ndecreasing the likelihood of predicting death.\nFigure 8: Top 10 Features of Clinical Variables based on Shapley Value.\n3.5 D ISCUSSION\nVast clinical datasets provide the opportunity for deep learning techniques to study the problem of\nin-hospital mortality prediction. Compared to previous related work, which mostly considers single\nmodality or only naively concatenates embeddings from different modalities, our work demonstrates\na novel way to integrate multimodal knowledge and leverage clinical notes information for better\npredictions. To our best knowledge, this is the ﬁrst work utilizing a transformer block to fuse clinical\nnotes and clinical variable information while dealing with time series data in EHR data. We also\nconduct comprehensive experiments to demonstrate that our proposed method outperforms other\nmethods by achieving high performance (AUCPR: 0.538, AUCROC: 0.877, F1:0.490).\nThe way we project two different modalities, unstructured clinical notes and structured clinical\nvariables, into a universal shareable space with a transformer block is very efﬁcient to leverage\nclinical notes and integrate clinical information. Meanwhile, the novel application of transformers on\nclinical data enables the model to consider information from all other time stamps when fusing the\nmultimodal information because of the unique attention mechanism in the transformer block.\nThe ablation study of domain adaptive pretraining and task adaptive ﬁne-tuning on various BERTs\nveriﬁes the signiﬁcance of pretraining and ﬁne-tuning when we implement the BERT models on\nnatural language text, especially on domain-speciﬁc clinical notes.\nThe analysis and visualization of important words in clinical notes also provide interesting ﬁndings.\nThe ranking of words by IG values provides face validity that many of the important words used for\nprediction are clinically related to diseases or processes that are prognostically important, such as\nseverity of respiratory disease or mental status. Other words, such as “care,” may be used in multiple\ncontexts, and are more difﬁcult to interpret as isolated words. Lastly, the clinical meaning of multiple\nwords can change signiﬁcantly with negation, such as “crackles” indicating abnormal lung exam\nﬁndings, and “not crackles” indicating a normal lung exam. In the future, we will employ techniques\nlike the NegEx algorithm(Chapman et al., 2001) to consider negation of key words to better explain\nthe clinical words’ meaning.\n3.6 C ONCLUSION\nIn this paper, we demonstrate a novel transformer based model, Multimodal Transformer, to leverage\nclinical notes and fuse multimodal knowledge from clinical data. To our knowledge, we are the ﬁrst to\nimplement a transformer block to integrate both clinical notes and clinical variables while considering\nthe time series information. The results demonstrate that our proposed Multimodal Transformer\noutperforms other methods. Additionally, we conduct different studies to further investigate the\nimportance of domain adaptive pretraining and task adaptive ﬁne-tuning for the Clinical BERTs. We\nalso provide methods to interpret and visualize the important words in clinical notes using IG and\nShapley methods, which demonstrate interesting ﬁndings on important features in clinical variables.\n9\nAmerican Medical Informatics Association (AMIA) Annual Symposium 2022\nREFERENCES\nEmily Alsentzer, John R Murphy, Willie Boag, Wei-Hung Weng, Di Jin, Tristan Naumann,\nand Matthew McDermott. Publicly available clinical bert embeddings. arXiv preprint\narXiv:1904.03323, 2019.\nXiongcai Cai, Oscar Perez-Concha, Enrico Coiera, Fernando Martin-Sanchez, Richard Day, David\nRoffe, and Blanca Gallego. Real-time prediction of mortality, readmission, and length of stay\nusing electronic health record data. Journal of the American Medical Informatics Association, 23\n(3):553–561, 2016.\nWendy W Chapman, Will Bridewell, Paul Hanbury, Gregory F Cooper, and Bruce G Buchanan. A\nsimple algorithm for identifying negated ﬁndings and diseases in discharge summaries. Journal of\nbiomedical informatics, 34(5):301–310, 2001.\nAnuj K Dalal, Nicholas Piniella, Theresa E Fuller, Denise Pong, Michael Pardo, Nathaniel Bessa,\nCatherine Yoon, Stuart Lipsitz, and Jeffrey L Schnipper. Evaluation of electronic health record-\nintegrated digital health tools to engage hospitalized patients in discharge preparation. Journal of\nthe American Medical Informatics Association, 28(4):704–712, 2021.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep\nbidirectional transformers for language understanding. In NAACL-HLT (1), 2019.\nIman Deznabi, Mohit Iyyer, and Madalina Fiterau. Predicting in-hospital mortality by combining\nclinical notes with time-series data. In Findings of the Association for Computational Linguistics:\nACL-IJCNLP 2021, pp. 4026–4031, 2021.\nXinyu Dong, Sina Rashidian, Yu Wang, Janos Hajagos, Xia Zhao, Richard N Rosenthal, Jun Kong,\nMary Saltz, Joel Saltz, and Fusheng Wang. Machine learning based opioid overdose prediction\nusing electronic health records. In AMIA Annual Symposium Proceedings, volume 2019, pp. 389.\nAmerican Medical Informatics Association, 2019.\nYu Gu, Robert Tinn, Hao Cheng, Michael Lucas, Naoto Usuyama, Xiaodong Liu, Tristan Naumann,\nJianfeng Gao, and Hoifung Poon. Domain-speciﬁc language model pretraining for biomedical\nnatural language processing. ACM Transactions on Computing for Healthcare (HEALTH), 3(1):\n1–23, 2021.\nSuchin Gururangan, Ana Marasovi ´c, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey,\nand Noah A Smith. Don’t stop pretraining: adapt language models to domains and tasks. arXiv\npreprint arXiv:2004.10964, 2020.\nHrayr Harutyunyan, Hrant Khachatrian, David C Kale, Greg Ver Steeg, and Aram Galstyan. Multitask\nlearning and benchmarking with clinical time series data. Scientiﬁc data, 6(1):1–18, 2019.\nJ Henry, Yuriy Pylypchuk, Talisha Searcy, and Vaishali Patel. Adoption of electronic health record\nsystems among us non-federal acute care hospitals: 2008–2015. ONC data brief, 35(35):2008–\n2015, 2016.\nKexin Huang, Jaan Altosaar, and Rajesh Ranganath. Clinicalbert: Modeling clinical notes and\npredicting hospital readmission. arXiv preprint arXiv:1904.05342, 2019.\nShih-Cheng Huang, Anuj Pareek, Saeed Seyyedi, Imon Banerjee, and Matthew P Lungren. Fusion\nof medical imaging and electronic health records using deep learning: a systematic review and\nimplementation guidelines. NPJ digital medicine, 3(1):1–9, 2020.\nAlistair EW Johnson, Tom J Pollard, Lu Shen, Li-wei H Lehman, Mengling Feng, Mohammad\nGhassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G Mark. Mimic-iii, a\nfreely accessible critical care database. Scientiﬁc data, 3(1):1–9, 2016.\nSwaraj Khadanga, Karan Aggarwal, Shaﬁq Joty, and Jaideep Srivastava. Using clinical notes with\ntime series data for icu management. arXiv preprint arXiv:1909.09702, 2019.\nGuilan Kong, Ke Lin, and Yonghua Hu. Using machine learning methods to predict in-hospital\nmortality of sepsis patients in the icu. BMC medical informatics and decision making, 20(1):1–10,\n2020.\n10\nAmerican Medical Informatics Association (AMIA) Annual Symposium 2022\nJinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, and Jaewoo\nKang. Biobert: a pre-trained biomedical language representation model for biomedical text mining.\nBioinformatics, 36(4):1234–1240, 2020.\nFuhai Li, Hui Xin, Jidong Zhang, Mingqiang Fu, Jingmin Zhou, and Zhexun Lian. Prediction model\nof in-hospital mortality in intensive care unit patients with heart failure: machine learning-based,\nretrospective analysis of the mimic-iii database. BMJ open, 11(7):e044779, 2021.\nYikuan Li, Shishir Rao, José Roberto Ayala Solares, Abdelaali Hassaine, Rema Ramakrishnan,\nDexter Canoy, Yajie Zhu, Kazem Rahimi, and Gholamreza Salimi-Khorshidi. Behrt: transformer\nfor electronic health records. Scientiﬁc reports, 10(1):1–12, 2020.\nScott M Lundberg and Su-In Lee. A uniﬁed approach to interpreting model predictions. Advances in\nneural information processing systems, 30, 2017.\nAdam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style,\nhigh-performance deep learning library. Advances in neural information processing systems, 32,\n2019.\nWasifur Rahman, Md Kamrul Hasan, Sangwu Lee, Amir Zadeh, Chengfeng Mao, Louis-Philippe\nMorency, and Ehsan Hoque. Integrating multimodal information in large pretrained transformers.\nIn Proceedings of the conference. Association for Computational Linguistics. Meeting, volume\n2020, pp. 2359. NIH Public Access, 2020.\nDhanesh Ramachandram and Graham W Taylor. Deep multimodal learning: A survey on recent\nadvances and trends. IEEE signal processing magazine, 34(6):96–108, 2017.\nEmma Rocheteau, Catherine Tong, Petar Veli ˇckovi´c, Nicholas Lane, and Pietro Liò. Predicting\npatient outcomes with graph representation learning. arXiv preprint arXiv:2101.03940, 2021.\nJessica M Schwartz, Amanda J Moy, Sarah C Rossetti, Noémie Elhadad, and Kenrick D Cato.\nClinician involvement in research on machine learning–based predictive clinical decision support\nfor the hospital setting: A scoping review.Journal of the American Medical Informatics Association,\n28(3):653–663, 2021.\nSeyedmostafa Sheikhalishahi, Vevake Balaraman, and Venet Osmani. Benchmarking machine\nlearning models on multi-centre eicu critical care dataset. Plos one, 15(7):e0235424, 2020.\nYuqi Si, Jingcheng Du, Zhao Li, Xiaoqian Jiang, Timothy Miller, Fei Wang, W Jim Zheng, and\nKirk Roberts. Deep representation learning of patient data from electronic health records (ehr): A\nsystematic review. Journal of Biomedical Informatics, 115:103671, 2021.\nMukund Sundararajan, Ankur Taly, and Qiqi Yan. Axiomatic attribution for deep networks. In\nInternational conference on machine learning, pp. 3319–3328. PMLR, 2017.\nPedro L Teixeira, Wei-Qi Wei, Robert M Cronin, Huan Mo, Jacob P VanHouten, Robert J Carroll,\nEric LaRose, Lisa A Bastarache, S Trent Rosenbloom, Todd L Edwards, et al. Evaluating electronic\nhealth record data sources and algorithmic approaches to identify hypertensive individuals.Journal\nof the American Medical Informatics Association, 24(1):162–171, 2017.\nKareen Teo, Ching Wai Yong, Joon Huang Chuah, Yan Chai Hum, Yee Kai Tee, Kaijian Xia, and\nKhin Wee Lai. Current trends in readmission prediction: An overview of approaches. Arabian\njournal for science and engineering, pp. 1–18, 2021.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi,\nPierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et al. Huggingface’s transformers:\nState-of-the-art natural language processing. arXiv preprint arXiv:1910.03771, 2019.\nBo Yang and Lijun Wu. How to leverage multimodal ehr data for better medical predictions? arXiv\npreprint arXiv:2110.15763, 2021.\n11\nAmerican Medical Informatics Association (AMIA) Annual Symposium 2022\nDongdong Zhang, Changchang Yin, Jucheng Zeng, Xiaohui Yuan, and Ping Zhang. Combining\nstructured and unstructured data for predictive models: a deep learning approach. BMC medical\ninformatics and decision making, 20(1):1–11, 2020.\nShuai Zheng, James J Lu, Nima Ghasemzadeh, Salim S Hayek, Arshed A Quyyumi, Fusheng Wang,\net al. Effective information extraction framework for heterogeneous clinical reports using online\nmachine learning and controlled vocabularies. JMIR medical informatics, 5(2):e7235, 2017.\n12"
}