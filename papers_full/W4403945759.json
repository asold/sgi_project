{
  "title": "Clinical information extraction for lower-resource languages and domains with few-shot learning using pretrained language models and prompting",
  "url": "https://openalex.org/W4403945759",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A4365971237",
      "name": "Phillip Richter-Pechanski",
      "affiliations": [
        "University Hospital Heidelberg",
        "Institute for Medical Informatics and Biostatistics",
        "German Center for Infection Research",
        "German Centre for Cardiovascular Research",
        "Heidelberg University",
        "Klaus Tschira Foundation"
      ]
    },
    {
      "id": "https://openalex.org/A3210805565",
      "name": "Philipp Wiesenbach",
      "affiliations": [
        "German Centre for Cardiovascular Research",
        "University Hospital Heidelberg",
        "Heidelberg University",
        "Klaus Tschira Foundation",
        "German Center for Infection Research",
        "Institute for Medical Informatics and Biostatistics"
      ]
    },
    {
      "id": null,
      "name": "Dominic Mathias Schwab",
      "affiliations": [
        "University Hospital Heidelberg",
        "Heidelberg University"
      ]
    },
    {
      "id": "https://openalex.org/A2611158625",
      "name": "Christina Kiriakou",
      "affiliations": [
        "University Hospital Heidelberg",
        "Heidelberg University"
      ]
    },
    {
      "id": "https://openalex.org/A2690297165",
      "name": "Nicolas Geis",
      "affiliations": [
        "University Hospital Heidelberg",
        "Heidelberg University",
        "Institute for Medical Informatics and Biostatistics"
      ]
    },
    {
      "id": "https://openalex.org/A2084769255",
      "name": "Christoph Dieterich",
      "affiliations": [
        "Klaus Tschira Foundation",
        "Heidelberg University",
        "Institute for Medical Informatics and Biostatistics",
        "German Center for Infection Research",
        "University Hospital Heidelberg",
        "German Centre for Cardiovascular Research"
      ]
    },
    {
      "id": "https://openalex.org/A2113562383",
      "name": "Anette Frank",
      "affiliations": [
        "Heidelberg University"
      ]
    },
    {
      "id": "https://openalex.org/A4365971237",
      "name": "Phillip Richter-Pechanski",
      "affiliations": [
        "University Hospital Heidelberg",
        "German Centre for Cardiovascular Research",
        "Heidelberg University",
        "Institute for Medical Informatics and Biostatistics",
        "German Center for Infection Research",
        "Klaus Tschira Foundation"
      ]
    },
    {
      "id": "https://openalex.org/A3210805565",
      "name": "Philipp Wiesenbach",
      "affiliations": [
        "University Hospital Heidelberg",
        "Institute for Medical Informatics and Biostatistics",
        "Heidelberg University",
        "Klaus Tschira Foundation",
        "German Center for Infection Research",
        "German Centre for Cardiovascular Research"
      ]
    },
    {
      "id": null,
      "name": "Dominic Mathias Schwab",
      "affiliations": [
        "Heidelberg University",
        "University Hospital Heidelberg"
      ]
    },
    {
      "id": "https://openalex.org/A2611158625",
      "name": "Christina Kiriakou",
      "affiliations": [
        "Heidelberg University",
        "University Hospital Heidelberg"
      ]
    },
    {
      "id": "https://openalex.org/A2690297165",
      "name": "Nicolas Geis",
      "affiliations": [
        "University Hospital Heidelberg",
        "Heidelberg University",
        "Institute for Medical Informatics and Biostatistics"
      ]
    },
    {
      "id": "https://openalex.org/A2084769255",
      "name": "Christoph Dieterich",
      "affiliations": [
        "Klaus Tschira Foundation",
        "German Centre for Cardiovascular Research",
        "Heidelberg University",
        "German Center for Infection Research",
        "University Hospital Heidelberg",
        "Institute for Medical Informatics and Biostatistics"
      ]
    },
    {
      "id": "https://openalex.org/A2113562383",
      "name": "Anette Frank",
      "affiliations": [
        "Heidelberg University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3173617765",
    "https://openalex.org/W4388184238",
    "https://openalex.org/W3215186939",
    "https://openalex.org/W3172642864",
    "https://openalex.org/W3114950584",
    "https://openalex.org/W4310568840",
    "https://openalex.org/W3154435685",
    "https://openalex.org/W2057399676",
    "https://openalex.org/W2156235098",
    "https://openalex.org/W2911489562",
    "https://openalex.org/W4221150520",
    "https://openalex.org/W3098267758",
    "https://openalex.org/W6854692045",
    "https://openalex.org/W4388725043",
    "https://openalex.org/W2958747773",
    "https://openalex.org/W2993873509",
    "https://openalex.org/W4385163750",
    "https://openalex.org/W2194321275",
    "https://openalex.org/W3173777717",
    "https://openalex.org/W4387500346",
    "https://openalex.org/W4386566916",
    "https://openalex.org/W6734194636",
    "https://openalex.org/W6798057236",
    "https://openalex.org/W2565495132",
    "https://openalex.org/W4319730829",
    "https://openalex.org/W2942398427",
    "https://openalex.org/W6838431322",
    "https://openalex.org/W2282821441",
    "https://openalex.org/W4365211688",
    "https://openalex.org/W3160638507",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W4365514966",
    "https://openalex.org/W3216866458",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4394673535",
    "https://openalex.org/W3034917890",
    "https://openalex.org/W1728842521",
    "https://openalex.org/W4402671681",
    "https://openalex.org/W3214556263",
    "https://openalex.org/W4308590518",
    "https://openalex.org/W3153427360",
    "https://openalex.org/W4386701122",
    "https://openalex.org/W38597370",
    "https://openalex.org/W2989759966",
    "https://openalex.org/W3034238904",
    "https://openalex.org/W2958089299",
    "https://openalex.org/W6810081322",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W3096580779",
    "https://openalex.org/W2980708516",
    "https://openalex.org/W6858023062",
    "https://openalex.org/W2114039834",
    "https://openalex.org/W3080429061",
    "https://openalex.org/W4308760226",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4212774754",
    "https://openalex.org/W4244726083",
    "https://openalex.org/W2612690371",
    "https://openalex.org/W4385757404",
    "https://openalex.org/W3185341429",
    "https://openalex.org/W2516809705"
  ],
  "abstract": "Abstract A vast amount of clinical data are still stored in unstructured text. Automatic extraction of medical information from these data poses several challenges: high costs of clinical expertise, restricted computational resources, strict privacy regulations, and limited interpretability of model predictions. Recent domain adaptation and prompting methods using lightweight masked language models showed promising results with minimal training data and allow for application of well-established interpretability methods. We are first to present a systematic evaluation of advanced domain-adaptation and prompting methods in a lower-resource medical domain task, performing multi-class section classification on German doctorâ€™s letters. We evaluate a variety of models, model sizes (further-pre)training and task settings, and conduct extensive class-wise evaluations supported by Shapley values to validate the quality of small-scale training data and to ensure interpretability of model predictions. We show that in few-shot learning scenarios, a lightweight, domain-adapted pretrained language model, prompted with just 20 shots per section class, outperforms a traditional classification model, by increasing accuracy from $48.6\\%$ to $79.1\\%$ . By using Shapley values for model selection and training data optimization, we could further increase accuracy up to $84.3\\%$ . Our analyses reveal that pretraining of masked language models on general-language data is important to support successful domain-transfer to medical language, so that further-pretraining of general-language models on domain-specific documents can outperform models pretrained on domain-specific data only. Our evaluations show that applying prompting based on general-language pretrained masked language models combined with further-pretraining on medical-domain data achieves significant improvements in accuracy beyond traditional models with minimal training data. Further performance improvements and interpretability of results can be achieved, using interpretability methods such as Shapley values. Our findings highlight the feasibility of deploying powerful machine learning methods in clinical settings and can serve as a process-oriented guideline for lower-resource languages and domains such as clinical information extraction projects.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6809730529785156
    },
    {
      "name": "Shot (pellet)",
      "score": 0.5856455564498901
    },
    {
      "name": "Natural language processing",
      "score": 0.5729631185531616
    },
    {
      "name": "Resource (disambiguation)",
      "score": 0.5447477102279663
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5193413496017456
    },
    {
      "name": "Information extraction",
      "score": 0.4918403625488281
    },
    {
      "name": "One shot",
      "score": 0.44068315625190735
    },
    {
      "name": "Engineering",
      "score": 0.09703609347343445
    },
    {
      "name": "Mechanical engineering",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Computer network",
      "score": 0.0
    },
    {
      "name": "Organic chemistry",
      "score": 0.0
    }
  ]
}