{
  "title": "Enhancing Privacy and Security in Large-Language Models: A Zero-Knowledge Proof Approach",
  "url": "https://openalex.org/W4393077197",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2529699849",
      "name": "Shridhar Singh",
      "affiliations": [
        "University of KwaZulu-Natal"
      ]
    },
    {
      "id": "https://openalex.org/A2529699849",
      "name": "Shridhar Singh",
      "affiliations": [
        "University of KwaZulu-Natal"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4206683875",
    "https://openalex.org/W2884599530",
    "https://openalex.org/W6633872374",
    "https://openalex.org/W6601403687",
    "https://openalex.org/W6799775034",
    "https://openalex.org/W2739273093",
    "https://openalex.org/W6610928041",
    "https://openalex.org/W1975245149",
    "https://openalex.org/W2152005134",
    "https://openalex.org/W2785078146",
    "https://openalex.org/W4321472314",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W3022540164",
    "https://openalex.org/W3096609273",
    "https://openalex.org/W3122507327",
    "https://openalex.org/W2471959228",
    "https://openalex.org/W1517916985",
    "https://openalex.org/W3194918904",
    "https://openalex.org/W4367000527",
    "https://openalex.org/W2120154759",
    "https://openalex.org/W4320843360",
    "https://openalex.org/W3215514448"
  ],
  "abstract": "The explosive growth of Large-Language Models (LLMs), particularly Generative Pre-trained Transformer (GPT) models, has revolutionised fields ranging from natural language processing to creative writing. Yet, their reliance on vast, often unverified data sources introduces a critical vulnerability: unreliability and security concerns. Traditional GPT models, while impressive in their capabilities, struggle with limited factual accuracy and susceptibility to manipulation by biased or malicious data. This poses a significant risk in professional and personal environments where sensitive or mission-critical data is paramount. This work tackles this challenge head-on by proposing a novel approach to enhance GPT security and reliability: leveraging Zero-Knowledge Proofs (ZKPs). Unlike traditional cryptographic methods that require sensitive data exchange, ZKPs allow one party to convincingly prove the truth of a statement, without revealing the underlying information. In the context of GPTs, ZKPs can validate the legitimacy and quality of data sources used in GPT computations, combating data manipulation and misinformation. This ensures trustworthy outputs, even when incorporating third-party data (TPD). ZKPs can securely verify user identities and access privileges, preventing unauthorised access to sensitive data and functionality. This protects critical information and promotes responsible LLM usage. ZKPs can identify and filter out manipulative prompts designed to elicit harmful or biased responses from GPTs. This safeguards against malicious actors and promotes ethical LLM development. ZKPs facilitate training specialised GPT models on targeted datasets, resulting in deeper understanding and more accurate outputs within specific domains. This allows the creation of ‘expert-GPT’ applications in specialised fields like healthcare, finance, and legal services. The integration of ZKPs into GPT models represents a crucial step towards overcoming trust and security barriers. Our research demonstrates the viability and efficacy of this approach, with our ZKP-based authentication system achieving promising results in data verification, user control, and malicious prompt detection. These findings lay the groundwork for a future where GPTs, empowered by ZKPs, operate with unwavering integrity, fostering trust and accelerating ethical AI development across diverse domains.",
  "full_text": "  \nEnhancing Privacy and Security in Large-Language Models: A Zero-\nKnowledge Proof Approach \nShridhar Singh \nUniversity of KwaZulu-Natal, Westville, South Africa \n217008024@stu.ukzn.ac.za \nAbstract: The explosive growth of Large -Language Models (LLMs), particularly Generative Pre -trained Transformer (GPT) \nmodels, has revolutionised fields ranging from natural language processing to creative writing. Yet, their reliance on vast, \noften unverified data sources introduces a critical vulnerability: unreliability and security concerns. T raditional GPT models, \nwhile impressive in their capabilities, struggle with limited factual accuracy and susceptibility to manipulation by biased o r \nmalicious data. This poses a significant risk in professional and personal environments where sensitive or  mission-critical \ndata is paramount. This work tackles this challenge head -on by proposing a novel approach to enhance GPT security and \nreliability: leveraging Zero -Knowledge Proofs (ZKPs). Unlike traditional cryptographic methods that require sensitive da ta \nexchange, ZKPs allow one party to convincingly prove the truth of a statement, without revealing the underlying information. \nIn the context of GPTs , ZKPs can validate the legitimacy and quality of data sources used in GPT computations, combating \ndata manipulation and misinformation. This ensures trustworthy outputs, even when incorporating third- party data (TPD). \nZKPs can securely verify user identities and access privileges, preventing unauthorised access to sensitive data and \nfunctionality. This protects critical information and promotes responsible LLM usage. ZKPs can identify and filter out \nmanipulative prompts designed to elicit harmful or biased responses from GPTs. This safeguards against malicious actors and \npromotes ethical LLM development. ZKPs facilitate training specialised GPT models on targeted datasets, resulting in deeper \nunderstanding and more accurate outputs within specific domains. This allows the creation of ‘expert -GPT’ applications in \nspecialised fields like healthcare, finance, and legal services. The integration of ZKPs into GPT models represents a crucial \nstep towards overcoming trust and security barriers. Our research demonstrates the viability and efficacy of this approach, \nwith our ZKP -based authentication system achieving promising results in data verific ation, user control, and malicious \nprompt detection. These findings lay the groundwork for a future where GPTs, empowered by ZKPs, operate with unwavering \nintegrity, fostering trust and accelerating ethical AI development across diverse domains. \nKeywords: Z\n ero-Knowledge Proof (ZKP), Succinct Non-interactive Argument of Knowledge (SNARK), Large- Language Model \n(LLM), Generative Pre-trained Transformer (GPT) \n1. Introduction \nGenerative Pre-trained Transformer (GPT) architecture advanced the field of artificial intelligence by allowing \nLarge-Language Models (LLMs) to recognise patterns in their training data and generate new content based on \nthose characteristics (Shi et al, 2023) . However, t he rapid growth of GPT LLMs flooding the industry exposed  \nweaknesses affecting LLMs architecture. These weaknesses target the objectivity, trust, and reliability of LLMs \nthereby reducing the trustworthiness of responses . This increases the LLMs susceptibility to exploits poisoning \ntraining data  and malicious prompt engineering tactics t hat manipulate the LLM into divulging sensitive \ninformation or delivering harmful responses (Shi et al, 2023, Wang et al, 2023, Shen et al, 2023). \nFurther, limitations in the lack of domain-specific data created the need to supplement the base training data to \ngain access to up -to-date information and ability to use post -training alignment, creating ‘expert -GPT’ \napplications, making the LLM more useful in domain-specific applications (OpenAI, 2023). Thus, third-party data \n(TPD) is injected to supplement the LLMs knowledgebase either from internet sources or, in privatised use-cases, \nlocal knowledgebases (OpenAI, 2023). Since TPD are the preferred source when the LLM computes its response, \nthis increases the risk of vulnerability leading to unreliable responses  (Shi et al, 2023).  \nKang et al (2023) investigate the  instruction-following procedure of LLMs stating it has a dual-use with \ncapabilities for malicious or nefarious behaviour. Their study concludes that attacks can bypass the state-of-the-\nart content filtering processes LLMs are equipped with and call for a formalised def ence mechanism against \nthreats to LLMs. Ahmed & Kashmoola (2021) state that data poisoning is a concern in the accelerated adoption \nof AI technologies and the risks associated with such attacks targeting Deep Neural Networks (which are utilised \nby LLMs) pose a significant risk during the training proce ss. In their experiments, malicious data was utilised to \nfalsify results and reduce the accuracy of outcomes. The difficult detection of these complex “smart model ” \nattacks allows them to cause significant damange to the AI model , handing over control to an unauthorised \nparty. They conclude that the reliability level of sources must be increased through the use of mathematical and \nstatistical methods. \n574 \nProceedings of the 19th International Conference on Cyber Warfare and Security, ICCWS 2024\nShridhar Singh \nTherefore, these limitations pose a gap in the current literature and require further research. The expansion to \nincorporate more data and utilise GPT architecture in business environments is inevitable and increases the risks \nof information tamper and misrepresentation. Thus, the consequences of unreliable data or unauthorised users \ncan have widespread repercussions  leading to spread of misinformation, creation of deep -fakes and other \nharmful content, exposure of sensitive or mission -critical data, and dat abase infection and corruption, among \nothers. It is vital that this gap be filled to ensure authenticity of LLM computations.  \nHimeur et al (2022) explore a method to protect sensitive information mined by recommender systems using \nblockchain technology.  In a similar regard, we look to replicate some of this functionality by utilising a proof \nsystem that has been popularised by Blockchain Technology, Zero- Knowledge Proofs (ZKPs)  (Sun et al, 2021) . \nZKPs are a modular and scalable proof system that can verify transactions without leaking any sensitive data. \nZKPs also ensure that once a transaction is complete, there is a mechanism to  validate the authenticity of the \ntransaction.  \nIn this paper we combine the progress in Z ero-Knowledge (zk) cryptography and GPT AI models to determine a \nsolution to the challenges mentioned above . The research has not examined the use of Zero -Knowledge Proofs \nfor LLM validation. Additionally, there has been no work to date suggesting examining TPD supplied to an LLM. \nThis is a massive gap in the knowledgebase as LLMs trained on data that is falsified can generate untrustworthy \nresponses (Kang et al, 2023). \n1.1 Research Goals \nThis paper aims to introduce zk -based LLMs (zk -LLMs) as a viable solution to challenges faced by the LLM \nindustry. To achieve this, we highlight 3 research questions we feel are beneficial in addressing why zk-LLMs are \nviable and provide backing through experimentation in this regard. This paper also sets out future work and \nlimitations to encourage future expansion of this concept. \nOur goal with this research is to create a framework for developing zk- LLMs. We achieved this by creat ing a \nprototype zk-LLM application using this framework that will serve as our basis for experimentation. This zk-LLM \nwill demonstrate the capabilities and variations that ZKPs can unlock when authenticating and securing \noperations performed by LLMs.  \nThis framework applies the zk prototype to privatised LLM environments where more flexibility is given to \nconduct experiments. As such, the research acknowledges the current advancements in LLM attack detection \nby AI leaders and proposes a different approach surrounding ZKP -equipped LLMs. \nResearch questions (RQs) \nRQ1. What factors can contribute as secure authentication methods to ensure prompt and user  integrity and \nreliability through ZK Protocols? \nRQ2. What are the potential risks and challenges of implementing zero-knowledge proof techniques in LLMs, and \nhow can they be mitigated? \nRQ3. How can zero -knowledge proof techniques be used to validate the accuracy and trustworthiness of \nresponses generated by LLMs? \n2. Overview of Zero-Knowledge Proofs \nZero-knowledge Proofs (ZKPs) are cryptographic proofs used to prove to a verifier , V, that a prover, P,  knows \nsome knowledge or secret, without revealing that secret itself (Wu & Wang, 2014). This validation invokes a \ntrust-based protocol whereby the prover must  provide convincing evidence to justify  their claim to know a \nsecret, without revealing any sensitive information  to the verifier (Lipmaa, 2016). This ideology is based on the \nnotion that the verifier must not have gained any more knowledge after completing the proving procedure than \nit had before (Fiege et al, 1987; Rosen, 2004).   \nTechniques like Common Reference String (CRS) aim to provide a trusted third- party TP at the start of the \nvalidation process where TP can access privileged information and assure V that P’s claim is indeed valid (Groth, \n2018). Further development of the CRS around generating the TP led to the introduction of the zero-knowledge \nSuccinct Non-interactive Argument of Knowledge (zk -SNARK) protocol (Ben -Sasson et al, 2017; Groth, 2018) – \nwhich will be utilised to construct zk proofs in this research. \n575 \nProceedings of the 19th International Conference on Cyber Warfare and Security, ICCWS 2024\nShridhar Singh \n \nzk-SNARKs have significant interest in Blockchain (Groth, 2018) where authenticity validation is vital. zk-SNARKS \nhas proven to be an efficient protocol without being computationally expensive (Ben -Sasson et al, 2017) . zk-\nSNARKS can therefore lend its versatility to prove for users and sources being authentic , and data indeed \nrepresenting relevant domain knowledge to aid in computing responses of LLMs.  \n3. Methodology \nIn section 1.1. above, we introduce d the zk-LLM framework and application. This section briefly describes the \nprocess of constructing a ZKP for zk- GPT (our zk- LLM application), translating the high -level principles into \ncomputational code. We define a framework for constructing zk-LLMs and our intention with this framework is \nto provide a basis for our design and experiments whilst aiding future development.  \n3.1 ZKP Framework \nSince this paper introduces zk -LLMs, there is no existing framework to create proofs or to conduct zk-\nexperiments. Therefore, this section establishes a theoretical framework for constructing zk -LLMs, serving as a \nblueprint for our implementation in zk-GPT and paving the way for future developments.  \nObjective with the framework: \n• Determine a standardised procedure for proving the legitimacy of a user.  \n• Determine the authorised addition of source data. \n• Extract relevant source data to provide a response to user prompts.  \n• Prevent malicious actions targeting the LLM. \nTable 1: Framework for creating zk-LLMs. \nZKP Framework for creating zk-LLMs \n Description \nUser \nAuthentication \nFunction:  \n• Utilising ZKPs to identify users without revealing sensitive information (e.g. passwords) \nthrough mathematical formulas or data structures. \nImplementation:  \n• Mathematical formulas or secure data structures for group membership or individual \ncredentials. \n• ZKPs to prove knowledge of a secret key or membership in a certain group. \nPrompt \nAnalysis \nFunction:  \n• Examining user prompts before LLM processing to assess relevance and prevent malicious \ncontent using secure hashing and encryption techniques.  \nImplementation:  \n• Secure hashing and encryption techniques for prompt analysis without storing sensitive \ndata. \n• ZKPs to prove that a prompt meets predefined criteria (e.g. length, format, content \nrestrictions). \nSource Data \nVerification \nFunction: \n• Employing ZKPs to verify the integrity and trustworthiness of training data and source \ndocuments, ensuring anonymity while preventing malicious content. \nImplementation: \n• ZKPs to prove that data has been correctly processed and anonymised. \n• Verification restricted to designated users involved in data curation. \nSource Data \nRelevance \nFiltering \nFunction: \n• Leveraging ZKPs to identify and prioritise the most relevant source data for LLM responses, \nimproving accuracy and reducing unnecessary information overload. \nImplementation: \n• Scoring systems based on prompt-specific relevance, potentially using ZKPs to prove that \nthe highest -scoring data was selected without revealing sensitive information about the \nscoring process. \n576 \nProceedings of the 19th International Conference on Cyber Warfare and Security, ICCWS 2024\nShridhar Singh \n3.2 zk-GPT Setup  \nzk-GPT builds upon the localGPT (PromptEngineer, 2024) platform to perform on-device LLM computations and \nutilises the Llama-2 7b-GPTQ model. Choosing stability and reliability over bleeding -edge efficiency guided our \ntechnology selection for ZKP implementation. This prioritises security and user privacy while ensuring verifiable \ncomputation. \nCircom: We chose Circom (Iden3, 2023), a dedicated language for zk-SNARK circuits, for its succinct and efficient \nexpression of constraints. This makes the zk-circuit compact and optimised for proof generation and verification. \nProof System Selection: Established protocols like Groth16 and Powers of Tau were preferred over cutting-edge \nalternatives. Groth16 offers cryptographic soundness and succinct proofs, while Powers of Tau facilitates \nefficient ceremony execution. This combination prioriti ses proven security and reliability over potential \nefficiency gains from newer protocols. \nCircuit Implementation : SnarkJS, a companion tool bundled with Circom, plays a crucial role. It binds the zk -\ncircuit using the R1CS (Rank-1 Constraint) vector, ensuring data integrity and tracking variable relationships. \nFurthermore, SnarkJS handles Groth16 witness generation in a trusted setup. This trusted setup allows for \nsecure proof generation without compromising the zk-circuit's secrecy. \nProof Generation & Verification: Following circuit binding and witness generation, SnarkJS performs Powers of \nTau ceremonies alongside Groth16 proof generation and verification. This culminates in an exportable \nverification key, enabling anyone to independently verify the proof without needing the original circuit or \nwitness. \nTable 2: Breakdown of the zk-SNARK process within zk-GPT. \nzk-SNARK process within zk-GPT \nStep Description \nzk-circuit Filters legitimate values from illegitimate ones, ensuring valid calculations and rejecting any \nunexpected outcomes. \n \nProof System \nSelection \nGroth16 and Powers of Tau protocols chosen for their established security and reliability. \nCircuit \nImplementation \nCircom and SnarkJS facilitate circuit creation and efficient proof generation/verification. \nBinding & Witness \nGeneration \nSnarkJS binds the circuit for data integrity and generates Groth16 witnesses in a trusted setup. \nProof Generation & \nVerification \nSnarkJS performs Powers of Tau ceremonies and Groth16 verification, exporting a verification \nkey. \nCompletion Successful verification allows LLM operation to resume. \n \n \nFigure 1: A depiction of the process for a user’s prompt interacting with zk-GPT architecture \n577 \nProceedings of the 19th International Conference on Cyber Warfare and Security, ICCWS 2024\nShridhar Singh \n \nTrade-offs: While established technologies offer proven security and reliability, we acknowledge the potential \nefficiency gains achievable with cutting- edge options. Future research could explore utilising newer protocols \nwhile maintaining zk-GPT's core security guarantees. \n3.3 Testing Methodology \nThis section details three sets of experiments designed to address the RQs outlined in section 1.1: \n• Stage 1 – User Authority Analysis  \nStage 1 experiments  examined two RQs (RQ1 – Secure Authentication and User Integrity and RQ2  – Risks and \nMitigations). This stage tests the ability of ZKPs to authenticate users and differentiate authorised access levels. \nIt aims to verify user IDs, prevent unauthorised actions, and detect intruders while preserving user anonymity \nin closed systems. This directly addresses  RQ1 by demonstrating how ZKPs can contribute to secure \nauthentication and user integrity.  This stage also plays a role in mitigating potential risks identified in RQ2 by \npreventing unauthorised access and data disclosure. \n• Stage 2 – Supplemental Data Relevance  \nThis stage focuses on addressing RQ3 by showing how ZKPs can validate the accuracy and trustworthiness of \nLLM responses. It demonstrates how the system filters irrelevant information and ensures the LLM utilises only \nrelevant supplemental data for response  generation, thereby increasing the reliability and factual basis of \noutputs. \n• Stage 3 – Risks and Mitigations \nThis stage directly tackles RQ2 by demonstrating how ZKPs can detect and prevent malicious user actions that \naim to harm the LLM or compromise its responses. Examples could include attempts to force sensitive \ninformation disclosure or manipulate the LLM's outputs. \n4. Results \n4.1 User Authority Analysis (RQ1) \nRQ1: What factors can contribute as secure authentication methods to ensure prompt and user integrity and \nreliability through ZK Protocols? \nStage 1 experiments assessed the factors that contribute to secure authentication of  prompt and user integrity \nand reliability by evaluat ing the effectiveness of ZKPs in securing user authentication and role -based access \ncontrol in zk-GPT. These experiments were conducted over 100 iterations and these tests aimed to: \n• Verify user IDs and differentiate authorised access levels (admin vs. normal user). \n• Prevent unauthorised login attempts and protect sensitive data. \n• Maintain user anonymity in closed systems. \nThe zk-circuit successfully identified and rejected all unauthoris ed attempts (40/40), including those designed \nto mimic admin or normal user access ( 15 admin, 15 normal). Authori sed users (30 admin + 30 normal) \nconsistently experienced successful logins and privilege separation (modifying supplemental data exclusively for \nadmins). These results strongly support the use of ZKPs for secure authentication and access control in LLMs.  \nTable 3: User Authority Analysis over 100 Iterations \nUser Authority Analysis \nUser Level Description Successful Login Unsuccessful Login \nAdmin User 30 15 \nNormal User 30 15 \nForeign User 0 10 \nTotal Attempts 60 40 \n4.2 Supplemental Data Relevance (RQ2) \nRQ2: What are the potential risks and challenges of implementing zero-knowledge proof techniques in LLMs, and \nhow can they be mitigated? \n578 \nProceedings of the 19th International Conference on Cyber Warfare and Security, ICCWS 2024\nShridhar Singh \nStage 2 assessed zk-GPT's ability to utilis e relevant source data based on user prompts. We conducted 80 \nexperiments using a sample set of 40 research papers across four domains (Zero-Knowledge Proofs, Generative \nAI, Recommender Systems, Blockchain). Each experiment retrieved a user prompt and identified relevant papers \nfor response generation. These relevant papers were embedded and used to supplement zk -GPT with domain-\nspecific knowledge. The category for scoring this stage is as follows: \n• Related papers: Accurately answered the prompt (8 for Zero -Knowledge Proofs, 7 for Generative AI, \n3 for Recommender Systems, 4 for Blockchain). \n• Unrelated papers: Used in computation but didn't contribute significantly  to response generation (2 \nfor Zero-Knowledge Proofs, 3 for Generative AI). \n• Hallucinations: Papers not provided in the experiment, either retrieved by zk -GPT or generated (0 \nacross all domains). \nTable 4: Total Papers Sampled for Response Computation over 80 Iterations  \nSupplemental Data Relevance \nPrompt Parameters Related Papers Unrelated Papers Hallucinations \nZero-Knowledge Proofs 8 2 0 \nGenerative AI 7 3 0 \nRecommender Systems 3 0 0 \nBlockchain 4 0 0 \nTotal Papers Referenced 22 5 0 \nNote that fewer papers were referenced than provided due to overlapping domain coverage within related \nsubsets. zk-GPT effectively prioritised the most relevant papers based on the prompt. \n4.3 Malicious Prompt Detection (RQ3) \nRQ3: How can zero -knowledge proof techniques be used to validate the accuracy and trustworthiness of \nresponses generated by LLMs? \nStage 3 focused on zk-GPT's resilience against malicious prompt injection attacks and ran for 60 iterations. Stage \n3 tests its ability to  detect prompts aiming to disclose sensitive information or manipulate its knowledge  and \nprevent execution of such prompts, preserving LLM integrity. Stage 3 ran for 40 iterations and contained a \ndataset of 200 prompt injection keywords ( tailored to the dataset) equipped the proof system to analyse  \nprompts before execution.  \n• Malicious: 28/30 malicious prompts were flagged and execution terminated. \n• Non-malicious: 27/30 non-malicious prompts were correctly identified. \n• False positives/negatives: These results showed 3 false positive matches and 2 false negative matches, \nindicating an acceptable error rate for accidental flagging/missed detections. \nTable 5: Total Prompts Investigated for Malicious Intent over 60 Iterations. \nMalicious Intent \nPrompt Type Successful Unsuccessful False Positive False Negative \nMalicious 28 2 - 2 \nNon-Malicious 27 3 3 - \nTotal Attempts 60 5 - - \nThese experiments demonstrate the significant potential of ZKPs in securing LLMs. User authentication, data \nrelevance filtering, and malicious prompt detection all demonstrated  high accuracy and effectiveness. Further \nresearch can refine parameter optimi sation and address complex scenarios, but these results pave the way for \ntrustworthy and secure LLM deployment. \n5. Discussion \nThis section delves into the implications of our experiments, dissecting the benefits and challenges of employing \nZKPs in LLMs, as addressed by our three research questions (RQs). \n579 \nProceedings of the 19th International Conference on Cyber Warfare and Security, ICCWS 2024\nShridhar Singh \n \n5.1 Secure Authentication and User Integrity (RQ1) \nZKPs demonstrate how they enhance secure authentication practices and uphold user integrity in LLMs through \ntwo key mechanisms: zero-knowledge user identification, and role-based access control. \n• Zero-knowledge User Identification \nInstead of vulnerable password- based verification of traditional identification systems , zk- circuits verify user \nidentity without revealing any sensitive information. This anonymi ses users in closed systems and prevents \nunauthorised access by enforcing proof-of-identification based on mathematical binary hash function that \nverifies the identity of a user without explicitly exposing the user. Thus, the zk-verifier gains no new knowledge \nabout the user, other than what is already provided by the user-role. \n• Role-based Access Control \nAdditionally, using a zk-circuit enforces access restrictions based on user roles  and prohibit attempts to access \nzk-GPT made by users  not belonging to a ny user-group.  These restrictions extend to the functions  users can \nperform whilst interacting with zk -GPT. This safeguards sensitive information and ensures that only authorised \nusers can perform privileged actions. For example, a dmin-level users have additional privileges for interacting \nwith source data which includes adding or modifying supplemental data  to the knowledgebase whilst normal  \nusers are only permitted to chat with the LLM.  \nOur Stage 1 experiments achieved a 100% success rate in identifying and rejecting unauthorised  user attempts \nwhilst allowing access to authorised users . Th us, thereby validating the effectiveness of ZKPs for secure \nauthentication and access control in LLMs. \n5.2 Risks and Mitigations in LLMs (RQ2) \nIdentified as some of the potential risks of d eploying ZKPs in LLMs were challenges in computational overhead, \ndata availability and context, and malicious prompt injection.  \n• Computation Overhead \nZKP verification requires that the LLM halt execution and provide data to the zk -circuit. This requires additional \ncomputational resources, potentially impacting the fluidity of the LLMs responsiveness. Our experiments \ndemonstrated a slight decrease in user experience due to embedded zk-proof checks during conversation flow. \n• Data Availability and Context \nLarge datasets may pose challenges in retrieving the required amount of relevant information or understanding \nthe context of a specific user prompt. We mitigated this by implementing a fixed context window to determine \nrelevancy of source data based on initial prompts. However, this approach sacrifices  analysing nuances in \nprompts for efficiency, requiring further research for handling diverse topics and refined information requests.  \n• Malicious Prompt Injection \nDishonest users might utilise prompt engineering tactics to craft prompts containing malicious instructions to \nmanipulate the LLM. Our Stage 3 experiments demonstrated the feasibility of using ZKPs to detect such prompts \nwith a 91.6% accuracy rate. Analysing  prompts for malicious intent before execution allows for fine- tuning this \ndefence mechanism based on organisational needs and user access levels. \n5.3 Validating LLM Response Accuracy (RQ3): \nZKPs contribute to the accuracy and trustworthiness of LLM responses in several ways:  \n• Data Relevance Filtering \nBy analysing document relevance through word frequency and scoring, ZKPs ensure the LLM utilise s only the \nmost relevant data for response generation. This eliminates unnecessary information overload and reduces the \nrisk of misleading or inaccurate responses. \n• Source Data Credibility \nCombining user authorisation with ZKP verification guarantees that only credible source  data are added to the \nLLM's knowledge base. This minimi ses the risk of data corruption or falsification and improves the overall \ntrustworthiness of responses. \n580 \nProceedings of the 19th International Conference on Cyber Warfare and Security, ICCWS 2024\nShridhar Singh \n• Verification of Data Integrity \nZKPs can assess whether source data has been altered after embedding, providing a reliable verification \nmechanism for data integrity. This strengthens trust in the LLM's responses by assuring users that the underlying \ninformation remains uncorrupted. \nOur Stage 2 experiments demonstrated  a significant response accuracy (81.4%) when using ZKPs for data \nrelevance filtering. This demonstrates the effectiveness of ZKPs in enhancing the reliability and factuality of LLM \noutputs. \nOverall, these experiments highlight the significant potential of ZK Ps in addressing crucial security and trust \nconcerns surrounding LLMs. While challenges remain in optimising performance and handling diverse scenarios, \nfurther research and development promise even greater effectiveness in securing LLMs and ensuring the \nintegrity of their responses. \n6. Limitations and Future Work \n6.1 Limitations \nWhile our experiments demonstrate the promise of ZKPs for securing LLMs, there are areas for improvement . \nHighlighted below are areas to improve the zk -circuit and should also be noted as developments in the field of \nZero-Knowledge Proof computations. \n• Circuit flexibility : The current zk -circuit accepts predefined inputs with fixed constraints. Any \ndeviations require circuit modifications, limiting adaptability. To address this, we envision a generic \ncircuit with variable input ranges capable of handling diverse data formats and structures. \n• Hashing optimisation: The ZKP relies on SHA256 hashing, which becomes inefficient for larger circuits. \nImplementing Poseidon hashing, known for its speed and efficiency, could significantly improve proof \ngeneration and verification processes. \n• Trusted vs. untrusted setups : Groth16 is the chosen algorithm for zk -SNARK circuits but requires a \ntrusted setup with exposed witnesses. Untrusted setups like PLONK would eliminate witness exposure \nand enhance security without impacting verification. \n6.2 Future Work \nFuture work in this area is promising as ZKPs are versatile and can be adapted to solve different problems. Thus, \nZKPs extends beyond our present research, opening doors to exciting possibilities . Here are some proposed \nexamples where ZKPs can prove beneficial to the development of LLMs: \n• Securing public internet data : LLMs increasingly rely on web sources, but verifying data \ntrustworthiness remains a challenge. TPD-based ZKPs can validate data provenance and ensure LLMs \nare fed with reliable information. \n• Zero-knowledge news verification: Malicious news and propaganda pose a significant threat. Utilising \nZKPs to authenticate news articles could safeguard LLM recommendations and promote responsible \ninformation dissemination. \n• ZKPs in education : Ethical concerns surround the use of LLMs in education. Employing ZKPs for \nplagiarism detection and knowledge assessment could foster academic integrity and enhance learning \nexperiences. \nBy addressing the limitations and exploring these promising avenues, we can further unlock the potential of ZKPs \nto revolutionise LLM security, reliability, and ethical applications. \n7. Conclusion \nThis research explored the potential of Zero -Knowledge Proofs (ZKPs) to address critical trust concerns \nsurrounding Large-Language Models (LLMs). We have demonstrated significant progress in mitigating challenges \nthat erode user confidence in LLM responses through the use and development of zk-LLMs and a framework for \nutilising ZKPs for secure authentication, data validation, and prompt analysis . Our experiments yielded \ncompelling evidence supporting the efficacy of zk-LLMs in addressing our key research questions and establishes \nthe zk-LLM framework for secure LLM deployment in controlled environments. ZKPs effectively mitigated threats \nthrough data relevance filtering and malicious prompt detection  reducing risk of data corruption, \nmisinformation, and LLM manipulation whilst ensuring reliable source data is referenced  to enhance the trust \nof LLM outputs.  \n581 \nProceedings of the 19th International Conference on Cyber Warfare and Security, ICCWS 2024\nShridhar Singh \n \nWhile these results are promising, we acknowledge the limitations in the current zk -circuit and encourage \nopportunities for further refinement by providing avenues for future research such as: circuit flexibility, hashing \noptimisation, and exploring untrusted ZKP setups. Beyond internal optimi sation, the potential of zk- LLMs \nextends its versatility to diverse applications, including securing internet data, news verification , and ZKP s use \nin plagiarism detection. In conclusion, this research has established zk-LLMs as a promising solution for bridging \nthe trust gap in LLM deployment. By continually refining the framework and exploring its diverse applications, \nwe can unlock a future where LLMs operate with verifiable integrity, empowering informed decision-making and \nethical outcomes across various domains. The path forward lies in embracing continuous exploration and \ncollaboration, paving the way for a future where LLMs are not feared for their limitations, but celebrated for \ntheir ability to enhance trust, transparency, and ethical AI development.  \nReferences \nAhmed, I. M. and Kashmoola, M. Y., 2021. Threats on machine learning technique by data poisoning attack: A survey. In \nAdvances in Cyber Security: Third International Conference, ACeS 2021, Penang, Malaysia, August 24-25, 2021, \nRevised Selected Papers 3, pp 586-600. Springer Singapore, 2021. \nBen-Sasson, E., Chiesa, A., Tromer, E. and Virza, M. (2017) Scalable Zero Knowledge Via Cycles of Elliptic Curves. \nAlgorithmica, 79, pp 1102-1160. \nCoutaeu, G. (2017) Zero-knowledge proofs for secure computation. (Doctoral dissertation, Univerite Paris sciences et \nlettres). \nFiege, U., Fiat, A. and Shamir, A. (1987) Zero knowledge proofs of identity. In Proceedings of the nineteenth annual ACM \nsymposium on Theory of computing, pp 210-217. \nGoldreich, O., Micali, S. and Wigderson, A. (1987) How to Prove All NP Statements in Zero-Knowledge. Springer Berlin \nHeidelberg, pp 171-185. \nGoldwasser, S. and Kalai, Y. T. (2003) On the (in) Security of the Fiat-Shamir paradigm. IEEE, pp 102-113. \nGroth, J. K. (2018) July. Updatable and universal common reference strings with applications to zk-SNARKs. Cham: Springer \nInternational Publishing, pp. 698-728. \nHimeur, Y. et al. (2022) Blockchain-based Recommender Systems: Applications, Challenges, and Future Opportunities. \nComputer Science Review, Vol. 42, 100439. \nIden3 (2023). Circom. GitHub Repository https://github.com/iden3/circom.  \nKang, D. et al., 2023. Exploiting Programmatic Behavior of LLMs: Dual-Use Through Standard Security Attacks. arXiv \npreprint arXiv:2302.05733. \nLipmaa, H. (2016) Prover-Efficient Commit-And-Prove Zero-Knowledge SNARKs. Springer, pp 185-206. \nOpenAI, 2023. GPT-4 Technical Report. ArXiv:2303.08774, Vol. 3, pp 1-100. \nPromptEngineer (2024). localGPT. GitHub Repository https://github.com/PromtEngineer/localGPT.  \nRosen, A. (2004) A note on constant-round zero-knowledge proofs for NP. Springer Berlin Heidelberg, pp. 191-202. \nShi, J., Liu, Y., Zhou, P. and Sun, L. (2023) BadGPT: Exploring Security Vulnerabilities of ChatGPT via Backdoor Attacks to \nInstructGPT. arXiv preprint arXiv:2304.12298. \nSun, X., Yu, F.R., Zhang, P., Sun, Z., Xie, W. and Peng, X., 2021. A survey on zero-knowledge proof in blockchain. IEEE \nnetwork, 35(4), pp 198-205. \nWu, H. and Wang, F. (2014) A Survey of Noninteractive Zero Knowledge Proof System and its Applications. The Scientific \nWorld Journal, Vol. 2014, Article ID 560484, 7 pages. \nZhang, J., Fang, Z., Zhang, Y. and Song, D. (2020) Zero knowledge proofs for decision tree predictions and accuracy. In \nProceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security pp 2039-2053. \nZhang, S., Yao, L., Sun, A. and Tay, Y., 2019. Deep learning based recommender system: A survey and new perspectives. \nACM computing surveys (CSUR) 52, no.1, pp 1-38. \nZhou, C. et al., 2023. A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT. arXiv \npreprint arXiv:2302.09419. \n582 \nProceedings of the 19th International Conference on Cyber Warfare and Security, ICCWS 2024",
  "topic": "Zero-knowledge proof",
  "concepts": [
    {
      "name": "Zero-knowledge proof",
      "score": 0.9360703229904175
    },
    {
      "name": "Computer science",
      "score": 0.5986034870147705
    },
    {
      "name": "Zero (linguistics)",
      "score": 0.552474856376648
    },
    {
      "name": "Computer security",
      "score": 0.5272411704063416
    },
    {
      "name": "Internet privacy",
      "score": 0.43783169984817505
    },
    {
      "name": "Proof of concept",
      "score": 0.4273325204849243
    },
    {
      "name": "Theoretical computer science",
      "score": 0.3282877802848816
    },
    {
      "name": "Cryptography",
      "score": 0.23413720726966858
    },
    {
      "name": "Linguistics",
      "score": 0.1318683922290802
    },
    {
      "name": "Philosophy",
      "score": 0.07381370663642883
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I95023434",
      "name": "University of KwaZulu-Natal",
      "country": "ZA"
    }
  ]
}