{
    "title": "Mental-LLM",
    "url": "https://openalex.org/W4392503764",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2591701682",
            "name": "Xuhai Xu",
            "affiliations": [
                "Massachusetts Institute of Technology",
                "University of Washington"
            ]
        },
        {
            "id": "https://openalex.org/A3001877916",
            "name": "Bingsheng Yao",
            "affiliations": [
                "Rensselaer Polytechnic Institute"
            ]
        },
        {
            "id": "https://openalex.org/A2158379996",
            "name": "Yuanzhe Dong",
            "affiliations": [
                "Stanford University"
            ]
        },
        {
            "id": "https://openalex.org/A2946817508",
            "name": "Saadia, Gabriel",
            "affiliations": [
                "Massachusetts Institute of Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2111112795",
            "name": "Hong Yu",
            "affiliations": [
                "University of Massachusetts Lowell"
            ]
        },
        {
            "id": "https://openalex.org/A2790815588",
            "name": "James Hendler",
            "affiliations": [
                "Rensselaer Polytechnic Institute"
            ]
        },
        {
            "id": "https://openalex.org/A2074001427",
            "name": "Marzyeh Ghassemi",
            "affiliations": [
                "Massachusetts Institute of Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2111246749",
            "name": "Anind K. Dey",
            "affiliations": [
                "University of Washington"
            ]
        },
        {
            "id": "https://openalex.org/A2130203649",
            "name": "Dakuo Wang",
            "affiliations": [
                "Northeastern University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2977128309",
        "https://openalex.org/W3036236864",
        "https://openalex.org/W3184144760",
        "https://openalex.org/W4385573087",
        "https://openalex.org/W4376133361",
        "https://openalex.org/W2748635631",
        "https://openalex.org/W2101807845",
        "https://openalex.org/W2157035150",
        "https://openalex.org/W2739819123",
        "https://openalex.org/W2937284856",
        "https://openalex.org/W3013908145",
        "https://openalex.org/W2252191003",
        "https://openalex.org/W2252031683",
        "https://openalex.org/W1537829113",
        "https://openalex.org/W2889391310",
        "https://openalex.org/W2104925568",
        "https://openalex.org/W2106686523",
        "https://openalex.org/W2182854643",
        "https://openalex.org/W2402700",
        "https://openalex.org/W2405042511",
        "https://openalex.org/W3007384022",
        "https://openalex.org/W2897583329",
        "https://openalex.org/W4386415037",
        "https://openalex.org/W2911378332",
        "https://openalex.org/W3192247156",
        "https://openalex.org/W2489334776",
        "https://openalex.org/W2985355520",
        "https://openalex.org/W2597891111",
        "https://openalex.org/W2741216199",
        "https://openalex.org/W3202915159",
        "https://openalex.org/W2914514892",
        "https://openalex.org/W2613843855",
        "https://openalex.org/W4379769651",
        "https://openalex.org/W3103163889",
        "https://openalex.org/W4366591012",
        "https://openalex.org/W4384520874",
        "https://openalex.org/W4379259169",
        "https://openalex.org/W4297328641",
        "https://openalex.org/W3031532441",
        "https://openalex.org/W1968199606",
        "https://openalex.org/W2898390306",
        "https://openalex.org/W4384520651",
        "https://openalex.org/W3162081707",
        "https://openalex.org/W2252128283",
        "https://openalex.org/W4386352630",
        "https://openalex.org/W4224326626",
        "https://openalex.org/W2076151421",
        "https://openalex.org/W4220883868",
        "https://openalex.org/W3004493409",
        "https://openalex.org/W2277876591",
        "https://openalex.org/W2888487925",
        "https://openalex.org/W201361503",
        "https://openalex.org/W4210736086",
        "https://openalex.org/W2898410082",
        "https://openalex.org/W2087564028",
        "https://openalex.org/W2755222014",
        "https://openalex.org/W4312811953",
        "https://openalex.org/W4360765018",
        "https://openalex.org/W2900152803",
        "https://openalex.org/W3154272574",
        "https://openalex.org/W4317757464",
        "https://openalex.org/W2795743556",
        "https://openalex.org/W2739681832",
        "https://openalex.org/W2927148761",
        "https://openalex.org/W2998535576",
        "https://openalex.org/W2094553285",
        "https://openalex.org/W3030790076",
        "https://openalex.org/W2972890723",
        "https://openalex.org/W3148026034",
        "https://openalex.org/W4319837253",
        "https://openalex.org/W3178912721",
        "https://openalex.org/W4297039634",
        "https://openalex.org/W4285288845",
        "https://openalex.org/W4288087261",
        "https://openalex.org/W4396723505",
        "https://openalex.org/W2990138404"
    ],
    "abstract": "Advances in large language models (LLMs) have empowered a variety of applications. However, there is still a significant gap in research when it comes to understanding and enhancing the capabilities of LLMs in the field of mental health. In this work, we present a comprehensive evaluation of multiple LLMs on various mental health prediction tasks via online text data, including Alpaca, Alpaca-LoRA, FLAN-T5, GPT-3.5, and GPT-4. We conduct a broad range of experiments, covering zero-shot prompting, few-shot prompting, and instruction fine-tuning. The results indicate a promising yet limited performance of LLMs with zero-shot and few-shot prompt designs for mental health tasks. More importantly, our experiments show that instruction finetuning can significantly boost the performance of LLMs for all tasks simultaneously. Our best-finetuned models, Mental-Alpaca and Mental-FLAN-T5, outperform the best prompt design of GPT-3.5 (25 and 15 times bigger) by 10.9% on balanced accuracy and the best of GPT-4 (250 and 150 times bigger) by 4.8%. They further perform on par with the state-of-the-art task-specific language model. We also conduct an exploratory case study on LLMs' capability on mental health reasoning tasks, illustrating the promising capability of certain models such as GPT-4. We summarize our findings into a set of action guidelines for potential methods to enhance LLMs' capability for mental health tasks. Meanwhile, we also emphasize the important limitations before achieving deployability in real-world mental health settings, such as known racial and gender bias. We highlight the important ethical risks accompanying this line of research.",
    "full_text": null
}