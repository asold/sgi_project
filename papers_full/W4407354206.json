{
  "title": "Leveraging Large Language Models for High-Quality Lay Summaries: Efficacy of ChatGPT-4 with Custom Prompts in a Consecutive Series of Prostate Cancer Manuscripts",
  "url": "https://openalex.org/W4407354206",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5113106633",
      "name": "Emily Rinderknecht",
      "affiliations": [
        "University of Regensburg"
      ]
    },
    {
      "id": "https://openalex.org/A4289790463",
      "name": "Anna Schmelzer",
      "affiliations": [
        "Barmherzige Brüder Klinikum St. Elisabeth in Straubing"
      ]
    },
    {
      "id": "https://openalex.org/A3014149051",
      "name": "Anton Kravchuk",
      "affiliations": [
        "Barmherzige Brüder Klinikum St. Elisabeth in Straubing"
      ]
    },
    {
      "id": "https://openalex.org/A4227221158",
      "name": "Christopher Goßler",
      "affiliations": [
        "University of Regensburg"
      ]
    },
    {
      "id": "https://openalex.org/A2151797704",
      "name": "Johannes Breyer",
      "affiliations": [
        "University of Regensburg"
      ]
    },
    {
      "id": "https://openalex.org/A1861920010",
      "name": "Christian Gilfrich",
      "affiliations": [
        "Barmherzige Brüder Klinikum St. Elisabeth in Straubing"
      ]
    },
    {
      "id": "https://openalex.org/A2163965421",
      "name": "Maximilian Burger",
      "affiliations": [
        "University of Regensburg"
      ]
    },
    {
      "id": "https://openalex.org/A3069736619",
      "name": "Simon Engelmann",
      "affiliations": [
        "University of Regensburg"
      ]
    },
    {
      "id": "https://openalex.org/A3094008719",
      "name": "Veronika Saberi",
      "affiliations": [
        "University of Regensburg"
      ]
    },
    {
      "id": null,
      "name": "Clemens Kirschner",
      "affiliations": [
        "University of Regensburg"
      ]
    },
    {
      "id": null,
      "name": "Dominik Winning",
      "affiliations": [
        "Barmherzige Brüder Klinikum St. Elisabeth in Straubing"
      ]
    },
    {
      "id": "https://openalex.org/A1976992298",
      "name": "Roman Mayr",
      "affiliations": [
        "University of Regensburg"
      ]
    },
    {
      "id": "https://openalex.org/A1964848594",
      "name": "Christian Wülfing",
      "affiliations": [
        "Asklepios Klinik Altona"
      ]
    },
    {
      "id": "https://openalex.org/A2297166384",
      "name": "Hendrik Borgmann",
      "affiliations": [
        "Medizinische Hochschule Brandenburg Theodor Fontane"
      ]
    },
    {
      "id": "https://openalex.org/A2045534990",
      "name": "Stephan Buse",
      "affiliations": [
        "Alfried Krupp Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2122468997",
      "name": "Maximilian Haas",
      "affiliations": [
        "University of Regensburg"
      ]
    },
    {
      "id": "https://openalex.org/A2117760123",
      "name": "Matthias May",
      "affiliations": [
        "Barmherzige Brüder Klinikum St. Elisabeth in Straubing"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6763522533",
    "https://openalex.org/W2803347846",
    "https://openalex.org/W4381245408",
    "https://openalex.org/W4379341789",
    "https://openalex.org/W2749105991",
    "https://openalex.org/W3168659129",
    "https://openalex.org/W4400966294",
    "https://openalex.org/W198355451",
    "https://openalex.org/W4383302386",
    "https://openalex.org/W4400642559",
    "https://openalex.org/W4402671278",
    "https://openalex.org/W4388347957",
    "https://openalex.org/W2949322907"
  ],
  "abstract": "Clear and accessible lay summaries are essential for enhancing the public understanding of scientific knowledge. This study aimed to evaluate whether ChatGPT-4 can generate high-quality lay summaries that are both accurate and comprehensible for prostate cancer research in Current Oncology. To achieve this, it systematically assessed ChatGPT-4’s ability to summarize 80 prostate cancer articles published in the journal between July 2022 and June 2024 using two distinct prompt designs: a basic “simple” prompt and an enhanced “extended” prompt. Readability was assessed using established metrics, including the Flesch–Kincaid Reading Ease (FKRE), while content quality was evaluated with a 5-point Likert scale for alignment with source material. The extended prompt demonstrated significantly higher readability (median FKRE: 40.9 vs. 29.1, p &lt; 0.001), better alignment with quality thresholds (86.2% vs. 47.5%, p &lt; 0.001), and reduced the required reading level, making content more accessible. Both prompt designs produced content with high comprehensiveness (median Likert score: 5). This study highlights the critical role of tailored prompt engineering in optimizing large language models (LLMs) for medical communication. Limitations include the exclusive focus on prostate cancer, the use of predefined prompts without iterative refinement, and the absence of a direct comparison with human-crafted summaries. These findings underscore the transformative potential of LLMs like ChatGPT-4 to streamline the creation of lay summaries, reduce researchers’ workload, and enhance public engagement. Future research should explore prompt variability, incorporate patient feedback, and extend applications across broader medical domains.",
  "full_text": null,
  "topic": "Medicine",
  "concepts": [
    {
      "name": "Medicine",
      "score": 0.7150661945343018
    },
    {
      "name": "Prostate cancer",
      "score": 0.6238243579864502
    },
    {
      "name": "Series (stratigraphy)",
      "score": 0.5832455158233643
    },
    {
      "name": "Quality (philosophy)",
      "score": 0.4961024224758148
    },
    {
      "name": "Medical physics",
      "score": 0.3594875633716583
    },
    {
      "name": "Cancer",
      "score": 0.3268287181854248
    },
    {
      "name": "Natural language processing",
      "score": 0.3256133198738098
    },
    {
      "name": "Computer science",
      "score": 0.28816595673561096
    },
    {
      "name": "Internal medicine",
      "score": 0.13265931606292725
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Epistemology",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    }
  ]
}