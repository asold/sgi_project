{
  "title": "Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers",
  "url": "https://openalex.org/W3043424630",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A2599468099",
      "name": "Kostadin Mishev",
      "affiliations": [
        "Saints Cyril and Methodius University of Skopje"
      ]
    },
    {
      "id": "https://openalex.org/A2751403202",
      "name": "Ana Gjorgjevikj",
      "affiliations": [
        "Saints Cyril and Methodius University of Skopje"
      ]
    },
    {
      "id": "https://openalex.org/A127838069",
      "name": "Irena Vodenska",
      "affiliations": [
        "Boston University"
      ]
    },
    {
      "id": "https://openalex.org/A2046594439",
      "name": "Lubomir T. Chitkushev",
      "affiliations": [
        "Boston University"
      ]
    },
    {
      "id": "https://openalex.org/A2065201609",
      "name": "Dimitar Trajanov",
      "affiliations": [
        "Saints Cyril and Methodius University of Skopje"
      ]
    },
    {
      "id": "https://openalex.org/A2599468099",
      "name": "Kostadin Mishev",
      "affiliations": [
        "Saints Cyril and Methodius University of Skopje"
      ]
    },
    {
      "id": "https://openalex.org/A2751403202",
      "name": "Ana Gjorgjevikj",
      "affiliations": [
        "Saints Cyril and Methodius University of Skopje"
      ]
    },
    {
      "id": "https://openalex.org/A127838069",
      "name": "Irena Vodenska",
      "affiliations": [
        "Saints Cyril and Methodius University of Skopje"
      ]
    },
    {
      "id": "https://openalex.org/A2046594439",
      "name": "Lubomir T. Chitkushev",
      "affiliations": [
        "Saints Cyril and Methodius University of Skopje"
      ]
    },
    {
      "id": "https://openalex.org/A2065201609",
      "name": "Dimitar Trajanov",
      "affiliations": [
        "Saints Cyril and Methodius University of Skopje"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W1678356000",
    "https://openalex.org/W2753259282",
    "https://openalex.org/W2093866254",
    "https://openalex.org/W2794284562",
    "https://openalex.org/W2295598076",
    "https://openalex.org/W4205947740",
    "https://openalex.org/W2963026768",
    "https://openalex.org/W2091432990",
    "https://openalex.org/W2964243274",
    "https://openalex.org/W2973088264",
    "https://openalex.org/W2963918774",
    "https://openalex.org/W6629028937",
    "https://openalex.org/W6679775712",
    "https://openalex.org/W6772752637",
    "https://openalex.org/W2923841521",
    "https://openalex.org/W6753840640",
    "https://openalex.org/W2965968319",
    "https://openalex.org/W1566289585",
    "https://openalex.org/W6759455113",
    "https://openalex.org/W6767182473",
    "https://openalex.org/W6768021236",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W6682691769",
    "https://openalex.org/W6768851824",
    "https://openalex.org/W6769263558",
    "https://openalex.org/W2493916176",
    "https://openalex.org/W6769311223",
    "https://openalex.org/W1546425147",
    "https://openalex.org/W6749879876",
    "https://openalex.org/W2783819197",
    "https://openalex.org/W2964236337",
    "https://openalex.org/W2104246439",
    "https://openalex.org/W2250966211",
    "https://openalex.org/W6685053522",
    "https://openalex.org/W1832693441",
    "https://openalex.org/W2470673105",
    "https://openalex.org/W2740721704",
    "https://openalex.org/W2790589292",
    "https://openalex.org/W2892137778",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W6752788575",
    "https://openalex.org/W6748176785",
    "https://openalex.org/W6640212811",
    "https://openalex.org/W2962739339",
    "https://openalex.org/W2783122809",
    "https://openalex.org/W2904055881",
    "https://openalex.org/W6747248625",
    "https://openalex.org/W2214603282",
    "https://openalex.org/W3015942869",
    "https://openalex.org/W3124888963",
    "https://openalex.org/W3125952890",
    "https://openalex.org/W1975428268",
    "https://openalex.org/W2130440015",
    "https://openalex.org/W2038466413",
    "https://openalex.org/W6713582272",
    "https://openalex.org/W2766176255",
    "https://openalex.org/W2914767245",
    "https://openalex.org/W2979472088",
    "https://openalex.org/W2797713804",
    "https://openalex.org/W6679434410",
    "https://openalex.org/W2785939461",
    "https://openalex.org/W6749489859",
    "https://openalex.org/W1965235124",
    "https://openalex.org/W6766673545",
    "https://openalex.org/W6755207826",
    "https://openalex.org/W4249906708",
    "https://openalex.org/W2138293190",
    "https://openalex.org/W6631190155",
    "https://openalex.org/W2912723748",
    "https://openalex.org/W6674330103",
    "https://openalex.org/W2795257215",
    "https://openalex.org/W6603405191",
    "https://openalex.org/W1809255060",
    "https://openalex.org/W2074384921",
    "https://openalex.org/W6638911773",
    "https://openalex.org/W1983578042",
    "https://openalex.org/W2963626623",
    "https://openalex.org/W1662133657",
    "https://openalex.org/W6632775526",
    "https://openalex.org/W3124698732",
    "https://openalex.org/W2882319491",
    "https://openalex.org/W6636510571",
    "https://openalex.org/W2963691546",
    "https://openalex.org/W82712395",
    "https://openalex.org/W4294367149",
    "https://openalex.org/W1924770834",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W3035390927",
    "https://openalex.org/W3122886537",
    "https://openalex.org/W2978017171",
    "https://openalex.org/W1836521361",
    "https://openalex.org/W2407776548",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4294170691",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2914120296",
    "https://openalex.org/W2996428491",
    "https://openalex.org/W2133564696",
    "https://openalex.org/W2095705004",
    "https://openalex.org/W2880875857",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2170240176",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W2131744502",
    "https://openalex.org/W1614298861",
    "https://openalex.org/W3133994440",
    "https://openalex.org/W2888160375",
    "https://openalex.org/W3167958315",
    "https://openalex.org/W4300485781",
    "https://openalex.org/W2963355447",
    "https://openalex.org/W2794557536",
    "https://openalex.org/W1549869922",
    "https://openalex.org/W2786464815"
  ],
  "abstract": "Financial and economic news is continuously monitored by financial market participants. According to the efficient market hypothesis, all past information is reflected in stock prices and new information is instantaneously absorbed in determining future stock prices. Hence, prompt extraction of positive or negative sentiments from news is very important for investment decision-making by traders, portfolio managers and investors. Sentiment analysis models can provide an efficient method for extracting actionable signals from the news. However, financial sentiment analysis is challenging due to domain-specific language and unavailability of large labeled datasets. General sentiment analysis models are ineffective when applied to specific domains such as finance. To overcome these challenges, we design an evaluation platform which we use to assess the effectiveness and performance of various sentiment analysis approaches, based on combinations of text representation methods and machine-learning classifiers. We perform more than one hundred experiments using publicly available datasets, labeled by financial experts. We start the evaluation with specific lexicons for sentiment analysis in finance and gradually build the study to include word and sentence encoders, up to the latest available NLP transformers. The results show improved efficiency of contextual embeddings in sentiment analysis compared to lexicons and fixed word and sentence encoders, even when large datasets are not available. Furthermore, distilled versions of NLP transformers produce comparable results to their larger teacher models, which makes them suitable for use in production environments.",
  "full_text": "Received June 13, 2020, accepted July 1, 2020, date of publication July 16, 2020, date of current version July 29, 2020.\nDigital Object Identifier 10.1 109/ACCESS.2020.3009626\nEvaluation of Sentiment Analysis in Finance:\nFrom Lexicons to Transformers\nKOSTADIN MISHEV\n 1, ANA GJORGJEVIKJ\n 1, IRENA VODENSKA2, LUBOMIR T. CHITKUSHEV2,\nAND DIMITAR TRAJANOV\n 1, (Member, IEEE)\n1Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University, 1000 Skopje, North Macedonia\n2Financial Informatics Lab, Metropolitan College, Boston University, Boston, MA 02215, USA\nCorresponding author: Kostadin Mishev (kostadin.mishev@ﬁnki.ukim.mk)\nThis work was supported in part by the Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University, Skopje.\nABSTRACT Financial and economic news is continuously monitored by ﬁnancial market participants.\nAccording to the efﬁcient market hypothesis, all past information is reﬂected in stock prices and new infor-\nmation is instantaneously absorbed in determining future stock prices. Hence, prompt extraction of positive\nor negative sentiments from news is very important for investment decision-making by traders, portfolio\nmanagers and investors. Sentiment analysis models can provide an efﬁcient method for extracting actionable\nsignals from the news. However, ﬁnancial sentiment analysis is challenging due to domain-speciﬁc language\nand unavailability of large labeled datasets. General sentiment analysis models are ineffective when applied\nto speciﬁc domains such as ﬁnance. To overcome these challenges, we design an evaluation platform\nwhich we use to assess the effectiveness and performance of various sentiment analysis approaches, based\non combinations of text representation methods and machine-learning classiﬁers. We perform more than\none hundred experiments using publicly available datasets, labeled by ﬁnancial experts. We start the\nevaluation with speciﬁc lexicons for sentiment analysis in ﬁnance and gradually build the study to include\nword and sentence encoders, up to the latest available NLP transformers. The results show improved\nefﬁciency of contextual embeddings in sentiment analysis compared to lexicons and ﬁxed word and sentence\nencoders, even when large datasets are not available. Furthermore, distilled versions of NLP transformers\nproduce comparable results to their larger teacher models, which makes them suitable for use in production\nenvironments.\nINDEX TERMS Sentiment analysis, ﬁnance, natural language processing, text representations, deep-\nlearning, encoders, word embedding, sentence embedding, transfer-learning, transformers, survey.\nI. INTRODUCTION\nThe latest advances in Natural Language Processing (NLP)\nhave received signiﬁcant attention due to their efﬁciency\nin language modeling. These language models are ﬁnding\napplications in various industries as they provide powerful\nmechanisms for real-time, reliable, and semantic-oriented\ntext analysis. Sentiment analysis is one of the NLP tasks that\nleverages language modeling advancements and is achiev-\ning improved results. According to the Oxford University\nPress dictionary, 1 sentiment analysis is deﬁned as the pro-\ncess of computationally identifying and categorizing opin-\nions expressed in a text, primarily to determine whether\nthe writer’s attitude towards a particular topic or product is\n1https://lexico.com\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was K. C. Santosh\n.\npositive, negative, or neutral. Sentiment analysis is becoming\nan essential tool for transforming emotions and attitudes into\nactionable information.\nDesigning and building deep-learning-based sentiment\nanalysis models require substantial datasets for training and\ntesting. While there are several large, publicly available\nsentiment-annotated datasets, they are mostly related to prod-\nucts and movies. Many sentiment analysis models [1]–[4]\nuse these datasets and achieve good performance in related\ndomains. However, the application of these models in differ-\nent domains is challenging because each domain has a unique\nset of words for emotion expression.\nThe ﬁnancial domain is characterized by a unique vocab-\nulary, which calls for domain-speciﬁc sentiment analysis.\nPrices observed in ﬁnancial markets reﬂect all available\ninformation related to traded assets [5], hence new informa-\ntion allows stakeholders to make well-informed and timely\n131662 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/VOLUME 8, 2020\nK. Mishevet al.: Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers\ndecisions. The sentiments expressed in news and tweets inﬂu-\nence stock prices and brand reputation, hence, constant mea-\nsurement and tracking of these sentiments is becoming one of\nthe most important activities for investors. Studies have used\nsentiment analysis based on ﬁnancial news to forecast stock\nprices [6]–[8], foreign exchange and global ﬁnancial market\ntrends [9], [10] as well as to predict corporate earnings [11].\nGiven that the ﬁnancial sector uses its own jargon, it is\nnot suitable to apply generic sentiment analysis in ﬁnance\nbecause many of the words differ from their general meaning.\nFor example, ‘‘liability’’ is generally a negative word, but\nin the ﬁnancial domain it has a neutral meaning. The term\n‘‘share’’ usually has a positive meaning, but in the ﬁnancial\ndomain, share represents a ﬁnancial asset or a stock, which\nis a neutral word. Furthermore, ‘‘bull’’ is neutral in general,\nbut in ﬁnance, it is strictly positive, while ‘‘bear’’ is neutral in\ngeneral, but negative in ﬁnance. These examples emphasize\nthe need for development of dedicated models, which will\nextract sentiments from ﬁnancial texts.\nSentiment analysis in ﬁnance has become an important\nresearch topic, connecting quantitative and qualitative mea-\nsures of ﬁnancial performance. A seminal study by Loughran\nand McDonald [12] shows that word lists developed for\nother disciplines misclassify common words in ﬁnancial\ntexts. Hence, Loughran and McDonald created an expert\nannotated lexicon of positive, negative, and neutral words\nin ﬁnance, which better reﬂect sentiments in ﬁnancial texts.\nIn [13], the authors introduce a Twitter-speciﬁc lexicon,\nwhich, in combination with the DAN2 machine learning\napproach, produces more accurate sentiment classiﬁcation\nresults than support vector machine (SVM) approach while\nusing the same Twitter-speciﬁc lexicon.\nMachine learning methods for sentiment extraction have\nbeen applied on datasets of tweets or news [14]–[18]. In [15],\nthe authors use various machine-learning binary classiﬁers\nto obtain StockTwits tweets sentiments. They show that the\nSVM classiﬁer is more accurate compared to Decision Trees\nand Naïve Bayes classiﬁer. In [16], Atzeni et al. test the\nperformance of various regression models in combination\nwith statistical and semantic methods for feature extraction\nto predict a real-valued sentiment score in micro-blogs and\nnews headlines, and show that semantic methods improve\nclassiﬁcation accuracy.\nResearchers have used lexicon-based approaches in com-\nbination with machine-learning models. The authors in [18]\nshow that such combinations are more efﬁcient for senti-\nment extraction than using single models. However, regular\nmachine-learning methods are unable to extract complex fea-\ntures and to keep the order of words in a sentence. These tasks\nrequire the use of deep-learning approaches, which allow for\ncomplex feature extraction, location identiﬁcation, and order\ninformation [19].\nDeep-learning methods [20] use a cascade of multiple lay-\ners of non-linear processing units for complex feature extrac-\ntion and transformation. Each successive layer uses the output\nfrom the previous layer as input, thus extracting complex\nfeatures which in many cases can be useful for generating\nlearning patterns and relationships beyond immediate neigh-\nbors in the sequence. Many studies conﬁrm the efﬁciency\nof deep-learning models, including recurrent neural network\n(RNN) [21], [22], convolutional neural networks [23]–[25]\nand attention mechanism [19], [26] in sentiment extraction\nin ﬁnance. The great success of deep-learning approaches\nin NLP is mainly due to the introduction and improvement\nof text representation methods, such as word [27]–[29] and\nsentence encoders [30]–[33]. These convert words/sentences\ninto vector representation, making them suitable as input for\nneural networks. These representations keep the semantic\ninformation coded into words and sentences, which is crucial\nfor sentiment extraction.\nRecent developments in NLP, deep-learning, and transfer-\nlearning have signiﬁcantly improved the sentiment extrac-\ntion from ﬁnancial news and texts [17], [34]–[37]. In [35],\nYang et al. incorporate inductive transfer-learning meth-\nods such as ULMFiT [38] for sentiment analysis in\nﬁnance, and the results show improvements in senti-\nment classiﬁcation compared to traditional transfer-learning\napproaches. The superior performance of recent NLP\ntransformers, BERT and RoBERTA, in sentiment analy-\nsis is evaluated in [37], where the effectiveness of using\nthe RoBERTa model is compared to dictionary-based\nmodels.\nStudies have used sentiment analysis based on ﬁnancial\nnews to forecast stock prices [6]–[8], foreign exchange and\nglobal ﬁnancial market trends [9], [10] as well as to predict\ncorporate earnings [11].\nThis paper aims to survey approaches to sentiment\nanalysis, including combinations of machine-learning and\ndeep-learning models with lexicon-based feature extrac-\ntion methods and word and sentence encoders, up to the\nmost recent NLP transformers. The goal is to apply these\napproaches to ﬁnance. We evaluate and compare model effec-\ntiveness when trained under same conditions and on the same\ndataset. The main contribution of this paper is the develop-\nment of an evaluation platform, which we use to assess the\nperformance of NLP methodologies for text feature extrac-\ntion in ﬁnance.\nWe show that recent advances in deep-learning and\ntransfer-learning methods in NLP increase the accuracy of\nsentiment analysis based on ﬁnancial headlines. Moreover,\nour results indicate that lexicon-based approaches can be\nefﬁciently replaced by modern NLP transformers.\nThe rest of the paper is organized as follows. Section II\nprovides an overview of NLP methods for text representation:\nlexicon-based and statistical, as well as word and sentence\nencoders. Section III presents NLP transformers, their archi-\ntectures and objectives, as a separate group of deep-learning\nmodels for text classiﬁcation, which we evaluate in extrac-\ntion of ﬁnance text sentiments. Section IV describes the\ndataset that we created to evaluate text representation meth-\nods. Section V presents the evaluation platform that we build\nfor measuring model performances. Section VI reports the\nVOLUME 8, 2020 131663\nK. Mishevet al.: Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers\nresults, and section VII concludes the paper and considers\nfuture applications.\nII. TEXT REPRESENTATION METHODS\nA. LEXICON-BASED KNOWLEDGE EXTRACTION\nLexicon-based sentiment analysis methods rely on domain-\nspeciﬁc knowledge represented as a lexicon or dictionary.\nThe process of sentiment calculation is based on identifying\nand keeping words that hold useful information while remov-\ning words that are not related to sentiments in ﬁnance.\nCommonly used lexicons and dictionaries in ﬁnance are\nGeneral Inquirer (GI), Harvard IV-4 (HIV4) [39], Diction\n[40], [41], and Loughran and McDonald’s (LM) [12] word\nlists.\nTo infer the sentiment, we evaluate the Loughran-\nMcDonald lexicon (a ﬁnancial lexical rule-based tool) and the\ngeneral-purpose Harvard IV-4 dictionary (general sentiment\ndictionary). We calculate the sentiment polarity using the\nLydia system [42]. Each of the words in the sentences is\ncategorized into either a positive or a negative group based\non its sentiment in the lexicon (Eq. 1). If polarity>0, then the\nsentence is classiﬁed as positive, and if polarity<0, then the\nsentence is classiﬁed as negative.\nPolarity =Pos −Neg\nPos +Neg (1)\nWhen using machine-learning (ML) and deep-learning\n(DL) classiﬁers, we extract the headline features by replacing\nthe words in the sentence with the sentiment value, speci-\nﬁed in the dictionary. Next, we input the newly generated\nsequence into the neural network to classify the text. The\nDL’s output soft-max layer calculates the probability that the\nsequence belongs to either the positive or negative sentiment\nlabels.\nB. STATISTICAL METHODS\n1) COUNT VECTORS\nCount Vectorizer (CV) is a simple statistical approach to\ntext representation which converts a collection of text doc-\numents into a matrix of token counts, thus reducing the entire\nsentence into a single vector. The positions in the vector\nrepresent the number of appearances of each word in the\nsentence. The CV algorithm performs feature extraction by\nusing a vocabulary of words (tokens) which can be built\nfrom the same text corpus, or input manually (a-priori) from\nan external resource. The vocabulary limits the number of\nfeatures which can be extracted from the text.\nThe CV approach for text representation has some draw-\nbacks. First, the ordering information gets lost due to the\nmethodology for term ‘‘squeezing.’’ Second, the contextual\ninformation of the sentence is hidden, although it is crucial\nfor sentiment extraction. These issues can be partially solved\nby using n-gram vectorizers where two, three or more consec-\nutive words are put together in order to form tokens. Another\nissue with CV is that it shadows the important words that hold\ndecision-making features for classiﬁers, because it pays more\nattention to general, frequent words such as ‘‘like,’’ ‘‘but,’’\nand, ‘‘or,’’ which do not add meaningful information. As a\nresult, important text features may vanish, which calls for\nmore sophisticated algorithms.\n2) TF-IDF TERM WEIGHTING\nTF-IDF (Term frequency - inverse document frequency) is\nan algorithm for statistical measurement, which evaluates\nthe relevance of a word in a document within a corpus\nof documents. It addresses the feature-vanishing issue of\nCV algorithms by re-weighting the count frequencies of the\nwords (tokens) in the sentence according to the number of\nappearances of each token. The algorithm works by multi-\nplying two metrics: term frequency (TF), which calculates\nthe number of occurrences of a term in the sequence (Eq.3),\nand inverse document frequency (IDF), which penalizes the\nfeature count of the term if it appears in more sentences within\nthe corpus (Eq.4),\ntﬁdf (t,d,D) =tf (t,d) ·idf (t,D) (2)\ntf (t,d) =log(1 +freq(t,d)) (3)\nidf (t,D) =log( N\ncount(d ∈D :t ∈d)) (4)\nwhere t denotes the term, d denotes the document, D denotes\nthe corpus of documents and N is the total number of\ndocuments.\nIn this study, we assess the feature extraction perfor-\nmance of the uni-gram and 2-gram count vectorizers as\nwell as the TF-IDF term weighting in combination with\nmachine-learning classiﬁers and deep-neural networks.\nC. WORD ENCODERS\nStatistical features do not provide semantics of the contex-\ntually close words, which means that words with similar\nmeaning will not have similar codes. Many NLP tasks such\nas sentiment analysis, question-answering and text generation\nrequire detailed semantic knowledge that is not provided by\nCV and TF-IDF. To overcome these challenges, researchers\nhave introduced word encoders [43] to convert discrete words\ninto high-dimensional vectors composed of real numbers,\nusing a procedure called word embedding. Word encoders\nhelp with understanding the context of the sentences, which\nimproves the extracted features. These models are based on\nthe principle of distributional hypothesis [44], in which the\nmeaning of words is evidenced by the context. This approach\nestablishes a new area of research in NLP called distribu-\ntional semantics, which is the core of many contemporary\nNLP techniques, including word encoders. These methods\nare called distributional semantic models (DSM), also known\nin the literature as vector space or semantic space models of\nmeaning [45]–[47].\nThe word encoders classify the words that appear in the\nsame context as semantically similar to one another, hence\nassigning similar vectors to them. This retained semantic\ninformation is very useful for classiﬁers or neural networks.\n131664 VOLUME 8, 2020\nK. Mishevet al.: Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers\nFIGURE 1. Word2Vec CBOW and Skip-Grams architectures [43].\nIn this section, we provide an overview of the most popular\nword encoders: Word2Vec [43], GloVe [28] and FastText\n[29], [48], which exemplify different approaches in modeling\nword embeddings.\n1) Word2Vec\nIn 2013, a team of researchers at Google, led by Tomas\nMikolov, introduced the breakthrough model for word rep-\nresentation called Word2Vec [27], [43], which marked the\nbeginning of a spectacular evolution in NLP. Mikolov and his\ncollaborators proposed two model architectures for comput-\ning continuous vector representations of words by using the\nunsupervised approach: Continuous Bag-of-Words (CBOW)\nand Continuous Skip-gram Model (Fig. 1). The CBOW archi-\ntecture predicts the current word based on the context, while\nin the Skip-Gram architecture, the distributed representation\nof the input word is used to predict the context [43]. The\nauthors show the effectiveness of the proposed methodology\nexperimentally, using several NLP applications, including\nsentiment analysis. Additionally, they demonstrate that the\nSkip-gram architecture gives more accurate results for large\ndatasets because it generates more general contexts.\nThe main drawback of Word2Vec is its inability to handle\nunknown or out-of-vocabulary (OOV) words. If the model\nhas not encountered a word before, it will be unable to inter-\npret it or build a vector for it. Additionally, Word2Vec does\nnot support shared representations at sub-word level, which\nmeans that it will create two completely different vector\nrepresentations for words which are morphologically similar,\nlike agree/agreement or worth/worthwhile [29].\nIn our analysis, we use a pre-trained version of Word2Vec\non the Google News corpus, which contains almost 3 million\nEnglish words represented by 300-dimensional vectors.\n2) GloVe\nIn 2014, a team of researchers at Stanford University pro-\nposed GloVe, an improved methodology for word encoding,\nbased on a solid mathematical approach [28]. GloVe over-\ncomes the drawbacks of Word2Vec in the training phase,\nimproving the generated embeddings. It emphasizes the\nimportance of considering the co-occurrence probabilities\nbetween the words rather than single word occurrence prob-\nabilities themselves. The model combines two classes of\nmethods for distributed word representations: global matrix\nfactorization and Skip-grams are used to extract better fea-\ntures by examining the relationships between words. The\nglobal matrix factorization method can capture the overall\nstatistics and relationships between words. On the other hand,\nWord2Vec Skip-gram’s method is efﬁcient in extracting the\nlocal context and capturing the word analogy. Both meth-\nods are successfully incorporated into the GloVe encoder,\nthus outperforming Word2Vec in many NLP tasks. GloVe\nis widely used as a word encoder for NLP-based sentiment\nanalysis [49]–[51].\n3) FastText\nIn 2016, the Facebook research laboratory introduced a\nnovel method for word encoding called FastText, which\ntackles the generalization problem of unknown words [29],\n[48]. FastText differs from previous models in its ability\nto build word embeddings at a deeper level by harnessing\nsub-words and characters. In this method, words become a\ncontext and word embedding is calculated based on com-\nbinations of lower-level embeddings. Each word is repre-\nsented as a bag of character n-grams. For example, the word\n‘‘ﬁnance,’’ given n = 3, will be represented by the fol-\nlowing character n-grams: <ﬁ,ﬁn,ina,nan,anc,nce,ce >.\nThe main algorithm behind FastText is Word2Vec. Learning\nthe sub-word information enables training of embeddings\non smaller datasets and generalization to unknown words.\nFastText shows improved results in text classiﬁcation [52],\neven in structurally rich languages such as Turkish [53] and\nArabic [54], which require morphological analysis instead of\nassigning a distinct vector to each word.\nWe evaluate pre-trained FastText vectors in order to assess\ntheir performance on ﬁnancial texts. We use the wiki-\nnews-300d-1M pre-trained model, which wraps 1 million\nword vectors trained on Wikipedia’s 2017 corpus and the\nstatmt.org2 news dataset, where each embedding consists\nof 300 dimensions.\n4) ELMo\nIn 2018, a team of researchers at Allen Institute for Artiﬁ-\ncial Intelligence developed an advanced word encoder called\nELMo (Embeddings from Language Models) [55], whose\nword embeddings are learned from a deep bidirectional lan-\nguage model (biLM), pre-trained on large corpora of textual\ndata. The essential feature, which makes ELMo different\nfrom previous word encoders, is that it produces contextual\nword embeddings considering the whole context in which\nthe word is used. Hence, we can obtain different embed-\nding for the same word in a different context, a major\nimprovement from previous encoders, which always pro-\nduce a static embedding. To tackle out-of-vocabulary (OOV)\ntokens, ELMo uses character-derived embedding, leveraging\nthe morphological clues of words, thus improving the quality\nof word representations.\n2http://statmt.org/\nVOLUME 8, 2020 131665\nK. Mishevet al.: Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers\nD. SENTENCE ENCODERS\nIn 2014, the idea of encoding entire sentences surpassed\nword encoding. The primary purpose of sentence encoders\nis to learn ﬁxed-length feature vectors that encode the syntax\nand semantic properties of variable-length sentences. While a\nsimple sentence embedding model can be built by averaging\nthe individual word embeddings for every word of the sen-\ntence, this approach loses the inherent context and sequence\nof words as valuable information that should be retained in\nmany tasks.\nThe main weakness of using sentence encoders to han-\ndle variable-length text input is related to the ﬁxed size of\nthe produced vectors. Long and short sentences are treated\nequally, producing the same number of extracted features,\nthus diluting the embeddings.\nIn this section, we outline recent and most prevalent sen-\ntence encoders [2], [30]–[33], to assess their ability to extract\nimportant features in sentence representation of ﬁnancial\nheadlines.\n1) Doc2Vec\nIn 2014, the ﬁrst successful sentence encoder, Doc2Vec\n[30] introduced an approach for representing variable-length\nfragments of texts (sentences, paragraphs, and documents)\nas ﬁxed-size dense vectors, a.k.a. paragraph vectors. These\nvectors are trained to predict words in documents. Their\nprimary goal is to make an appropriate distributed repre-\nsentation of large texts, overcoming the weaknesses of bag-\nof-words methods. Paragraph vectors combine word vectors\nto build phrase-level or sentence-level representations. They\nepitomize a distributed memory model, holding the context\nof the paragraph and contributing to the prediction task of the\nnext word in combination with word vectors. Additionally,\nparagraph vectors can be used as features for the paragraph,\nwhich can be fed as input to a classiﬁer or to a neural network,\nmaking them appropriate for evaluation of sentiment anal-\nysis in ﬁnancial headlines. To obtain sentence embeddings,\nwe use a Doc2Vec approach, which is pre-trained on English\nWikipedia texts.\n2) SKIP-THOUGHT VECTORS\nSkip-Thought Vectors [31] are models that use encoder-\ndecoder architecture for sequence modeling based on unsu-\npervised learning. These models use continuity of texts,\nextracted from books, to train an encoder-decoder method.\nThe model tries to reconstruct the surrounding sentences of an\nencoded passage in order to remap their syntactic and seman-\ntic meaning into similar vector representations. The encoder\ngenerates a sentence vector, and the decoder is used to gen-\nerate the surrounding sentences. The model uses a Recur-\nrent Neural Networks (RNN) encoder with Gated Recurrent\nUnit (GRU) [56] activations, and an RNN decoder uses a\nconditional GRU. The use of the attention layer provides\nfor a dynamic change of the source sentence representation.\nFIGURE 2. InferSent training scheme [32].\nDepending on the encoder type, two separate models are\ntrained: uni-skip and bi-skip. Uni-skip passes sentences in the\ncorrect order and extracts 2400 features. The Bi-skip model\nuses two encoders. One of them passes the sentence in the cor-\nrect order and the other passes the sentence in reverse order,\nextracting a total of 2400 features. Due to their generative\nnature, Skip-Thought vectors are appropriate and effective for\nneural machine translation and classiﬁcation tasks. The main\nshortcoming of this approach is the arduous task assigned\nto the decoder [57], as the next sentence prediction requires\nmodeling aspects that are, in most cases, irrelevant to the\nmeaning of the sentence.\n3) InferSent\nInferSent [32] is a supervised approach to learning sentence\nembeddings using natural language inference (NLI) data.\nNLI captures universally useful features, thus learning uni-\nversal sentence embeddings in a supervised manner. The\ntraining dataset used by this model is the Stanford Natu-\nral Language Inference (SNLI) dataset that contains 570k\nhuman-generated English sentence pairs, manually anno-\ntated with one of the three labels: entailment, contradiction,\nor neutral.\nFig. 2 shows a shared encoder used for encoding the\npremise u and the hypothesis v. In order to extract relations\nbetween u and v, three matching methods are applied: con-\ncatenation ( u,v), element-wise product u ∗v and absolute\nelement-wise difference |u −v|. Next, the resulting feature\nvector is applied as input to the 3-class classiﬁer to evaluate\nthe relationship between u and v based on the extracted\nfeatures. Experimentally, the best architecture for the encoder\nis shown to be the BiLSTM network with max pooling. This\napproach outperforms Skip-Thought vectors in many NLP\ntasks.\nIn our study, we assess the performances of two publicly\navailable versions of InferSent. The ﬁrst version is trained\nwith Stanford’s GloVe as word encoder and the second is\ntrained with Facebook’s FastText.\n131666 VOLUME 8, 2020\nK. Mishevet al.: Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers\nFIGURE 3. USE based on DAN architecture [2].\n4) UNIVERSAL SENTENCE ENCODER\nIn March 2018, Google researchers published their ﬁrst ver-\nsion of a model which converts variable-length sentences into\n512-dimensional vectors, called Universal Sentence Encoder\n(USE) [2]. The model is able to embed not only sentences,\nbut also words and entire paragraphs. USE uses the concept\nof transfer-learning to leverage the knowledge extracted from\nlarge datasets to improve the results when limited training\ndata is available.\nWe evaluate the USE encoder, which is based on Deep\nAveraging Network (DAN) architecture as shown in Fig.3.\nInput embeddings for words and bi-grams are ﬁrst averaged\nand then passed through a feed-forward deep neural net-\nwork (DNN) to produce sentence embeddings. The compu-\ntational time is linear in the length of the input sentence.\nUSE models are trained on a variety of data sources:\nWikipedia, news, question-answer pages, and discussion\nforums. These models are based on transfer-learning exper-\niments with several datasets to evaluate the efﬁciency of the\nencoder. The results show that sentence encoders outperform\ntransfer-learning methodologies that use word-level embed-\ndings alone.\nThe main issues with USE (DAN model) are related to the\nuse of averaging techniques that cannot recognize negation\nphrases like ‘‘not good.’’ This refers to using contextualized\nembeddings, which considers the inﬂuence of other words in\nproducing sentence embedding.\nIn our analysis, we assess the two latest versions of\nUSE (4 and 5) that can be found at the TensorFlow Hub\nrepository.3\n5) LANGUAGE-AGNOSTIC SENTENCE REPRESENTATIONS\n(LASER)\nIn 2019, Facebook researchers [33] introduced an architec-\nture for universal language-agnostic multilingual sentence\nrepresentations (LASER) for 93 languages by using a single\nBiLSTM encoder with a shared Byte Pair Encoding (BPE)\nvocabulary for different languages. The main contribution\nof the LASER methodology is that it provides a framework\nfor zero-shot transfer-learning. LASER leverages one model,\ntrained on one language, to be used in another language\nFIGURE 4. LASER architecture [33].\nwithout the need for pre-training. This is accomplished by\nLASER’s ability to bring semantically similar sentences,\nwritten in different languages, close to each other in the\nembedding space.\nSentence embeddings are obtained by applying a\nmax-pooling operation to the output of the BiLSTM encoder.\nThe same encoder is used for all 93 languages. The byte-pair\nencoding (BPE) vocabulary is learned based on the con-\ncatenation of all training corpora, hence, it does not require\nspeciﬁc information about the input language. LASER’s\nencoder architecture, illustrated in Fig. 4, is shown to be\nefﬁcient even for low-resource languages.\nIn this study, we evaluate LASER on English texts, though\nthe same model that we build here can be used for sentiment\nanalysis in texts written in the other 92 languages supported\nby LASER.\nIII. NLP TRANSFORMERS\nThe pre-trained word and sentence embeddings show good\nperformance for NLP tasks due to their ability to retain the\nsemantics and the syntax of the words in the sentence. The\ntransfer-learning task, in this case, allows for the information\nthat has been learned from unlabeled data to be used in tasks\nwith relatively small labeled data to achieve higher accu-\nracy. Although such embeddings have proven to be powerful,\nthey lack context-based mutability. Word2Vec, GloVe, and\nFastText use ﬁxed embeddings for each of the words, thus\nproducing one-to-one mapping, which in many cases is not\nappropriate and requires additional attention. Recent research\nstudies have proposed methods that produce different embed-\ndings for the same word, taking into consideration speciﬁc\ncontexts [3], [55], [58]. As an illustration of context impor-\ntance, we analyze the following two sentences that contain\nthe word ‘‘Apple’’: ‘‘Apple Inc performed well this year. ’’\nand ‘‘Apple fruits are exported to various countries. ’’ In the\nﬁrst sentence, Apple refers to the technology company Apple,\nheadquartered in the US, while in the second sentence, apple\nrefers to the fruit, with a completely different meaning. The\nencoders, however, will produce the same encoding for both\nwords regardless of the contexts. This problem highlights the\nneed for contextualized embeddings for the word ‘‘Apple. ’’\nA. NLP TRANSFORMER ARCHITECTURE\nA transformer represents an architecture that transforms one\nsequence into another by using two models: encoder and\ndecoder. Unlike previously described standard sequence-to-\nsequence models, which are based on LSTM/GRU units,\nthe paper ‘‘Attention is All You Need’’ [59] introduces a\nVOLUME 8, 2020 131667\nK. Mishevet al.: Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers\nFIGURE 5. The Transformer architecture [59].\nnovel, breakthrough transformer architecture based solely\non multi-headed self-attention mechanisms. There are three\nreasons for choosing self-attention instead of recurrent\nlayer: computational complexity, parallelization, and learning\nlong-range dependencies between words in the sequence, all\nof which are crucial for building contextualized embeddings.\nBy using this approach, transformers have shown improved\nresults in machine translation and other related tasks.\nThis method uses positional embedding to remember the\norder of words in the sequence. The main building blocks\nin the encoder/decoder modules are Multi-Head Attention\nand Feed Forward layers, as shown in the Attention-based\ntransformer architecture (Fig.5).\nThe scaled dot-product attention mechanism is described\nby equations 5 and 6.\na =softmax(QKT\n√n ) (5)\nIn Eq.5, the attention weights a represent the inﬂuence of\neach word in the sequence (Q) by all the other words (K) in\nthe same sequence. Q is a matrix that contains the query\n(vector representation of one word in the sequence), K are\nall keys (all vector representations of all the words in the\nsequence) and n is dimensionality of the query/key vectors.\nThe softmax function is used to ensure that weights a have a\ndistribution between 0 and 1. Considering a, a self-attention is\ncalculated by using Eq.6, which represents a weighted sum of\nvalues (V), where V is the vector obtained from the encoder.\nAttention(Q,K,V ) =aV (6)\nA multi-head attention mechanism calculates the scaled\ndot-product attention multiple times in parallel. The inde-\npendent outputs are concatenated and linearly transformed\ninto expected dimensions. Multi-head attention is obtained by\nusing Eq. 7:\nMultiHead(Q,K,V ) =[head1,head2,... headh]W O (7)\nEach of the headi can be calculated by Eq. 8:\nheadi =Attention(QW Q\ni ,KW K\ni ,VW i\nV ) (8)\nwhere W Q\ni , W K\ni , W i\nV and W O are parameter matrices, which\nthe model needs to learn. Multi-head attentions have an\nimportant role in obtaining the contextual embeddings when\nusing NLP transformers.\nA pre-training phase is an unsupervised learning approach\nwhere an unlabeled text corpus is introduced into the trans-\nformer architecture to produce text representations based on\nan objective function used by the transformer. This is a rel-\natively expensive task, but the learned token or generic sen-\ntence representations can be used in many other tasks using\ntransfer-learning. Later, the representation can be ﬁne-tuned\nin order to recognize the speciﬁcs of the task and to achieve\nbetter results. Fine-tuning is performed by adding an addi-\ntional dense layer after the last hidden state, recommended for\nusing transformers in classiﬁcation and regression tasks [3].\nThe transformer performs supervised learning (ﬁne-tuning)\non the labeled sentiment dataset, which is relatively inexpen-\nsive compared to pre-training.\nNLP transformers are applicable to many different text\nclassiﬁcation problems, such as binary sentiment classiﬁca-\ntion, which we use in our analysis.\n1) BERT\nIn 2018, Devlin et al. [3] leveraged the transformer\narchitecture to introduce a revolutionary language represen-\ntation model, called BERT (Bidirectional Encoder Repre-\nsentations from Transformers). This model started the new\nera in NLP, with state-of-the-art performance achieved on\nmost NLP tasks. BERT leverages the unsupervised learning\napproach to pre-train deep bidirectional representations from\nlarge unlabeled text corpora by using two new pre-training\nobjectives — masked language model (MLM) and next sen-\ntence prediction (NSP). BERT overcomes the limitation of\nprevious language models, which incorporate only unidirec-\ntional representations of words in sentences. It builds a bidi-\nrectional masked language model, which predicts randomly\nmasked words in the sentence, enriching the contextual infor-\nmation of the words.\nBERT is based on conventional, auto-regressive (AR) lan-\nguage modeling. The process of pre-training is performed\nby maximizing the likelihood between the tokens x in a\ntext sequence x =[x1,..., xT ]. Let ˆx denote the same text\nsentence with masked tokens and\nx be an array of masked\ntokens. The training objective for BERT is to reconstruct x\n131668 VOLUME 8, 2020\nK. Mishevet al.: Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers\nfrom ˆx by Eq.9:\nmax\nθ\nlog pθ(x|ˆx) ≈\nT∑\nt=1\nmt log pθ(xt|ˆx)\n=\nT∑\nt=1\nmt log exp (Hθ(ˆx)T\nt e(xt ))∑\nx′exp(Hθ(ˆx)Tt e(x′)) (9)\nwhere,\n• e(x′) denotes the embedding of the token x;\n• mt =1, if xt token of the text sequence x is masked;\n• Hθ is a Transformer which transforms each token of text\nsequence into a hidden vector.\nBERT assumes that all masked tokens x are mutually inde-\npendent, which is the main rationale behind the approxi-\nmation of the joint conditional probability p(x,ˆx) in Eq.9.\nAnother advantage that differentiates BERT from previous\nAR methods is the ability to increase the context information\nHθ(x)t by accessing the tokens placed on the left and the right\nside of token t.\nBERT has two versions: BERT-base, with 12 encoder lay-\ners, hidden size of 768, 12 multi-head attention heads and\n110M parameters in total; and BERT-large, with 24 encoder\nlayers, hidden size of 1024, 16 multi-head attention heads and\n340M parameters. Both of these models have been trained on\nEnglish Wikipedia and BookCorpus [60].\n2) FinBERT\nFinBERT [61] is a version of BERT intended for the ﬁnance\ndomain. It is pre-trained on a ﬁnancial text corpus which con-\nsists of 1.8M news articles from Reuters TRC2 dataset, pub-\nlished between 2008 and 2010. Compared to other pre-trained\nversions of BERT, FinBERT model has achieved a 15%\nimprovement in accuracy in text classiﬁcation tasks specif-\nically applied to ﬁnancial texts.\n3) XLNet\nThe XLNet model, developed by Google Brain and Carnegie\nMellon University, addresses the disadvantages of BERT,\nimproves its architectural design for pre-training, and pro-\nduces results that outperform BERT in 20 different tasks.\nIt utilizes a generalized AR model where the next token is\ndependent on all previous tokens, thus avoiding corrupted\ninput caused by masking of the words, performed by BERT.\nThe limitations of BERT include neglecting the dependency\nbetween masked tokens as it assumes that they are mutually\nindependent variables. On the other hand, XLNet considers\nthese tokens in the process of context building and assumes\nthat masked words are mutually dependent.\nAdditionally, XLNet uses Permutation Language Model-\ning (PLM) to capture bidirectional context by maximizing\nthe expected log-likelihood of a sequence given all possible\npermutations of words in a sentence. This means that XLNet\nenriches the contextual information of each position by lever-\naging the tokens from all the other positions found on the\nleft and on the right sides of the token. Speciﬁcally, for a\nsequence x of length T , there are T !different orders on which\nthe algorithm performs auto-regressive factorizations.\nLet ZT be the set of permutations of the words in a sentence\nof length T. x z<t denotes the ﬁrst t −1 elements of the\npermutation z ∈ZT . The PLM objective is given in Eq. 10.\nmax\nθ\nEz∼Z\n|z|∑\nt=c+1\nlog pθ(xzt |xz<t ) (10)\nThe hyperparameter c can be derived from the hyperpa-\nrameter K, where c =|z|(K −1)/K, and it represents the\ncutting-point of the division of vector z into non-target z ≤c\nand target z >c subsequences.\nAs shown in Eq.9 and Eq.10, both BERT and XLNet\nperform partial prediction, due to optimization. The main dif-\nference lies in the choice of tokens used for context modeling.\nBERT predicts the masked tokens, assuming that targets are\nmutually independent, while XLNet predicts the last token in\na factorization order z >c.\nThe following example [Wells,Fargo,is,a,bank,in,USA]\nexplains the difference. Assume that our goal is to predict\n‘‘Wells Fargo.’’ In order to use [Wells, Fargo] as prediction\ntargets, BERT masks them, and XLNet samples the factor-\nization order [is,a,bank,in,USA,Wells,Fargo]. Using Eq. 9,\nBERT will compute:\nJBERT =log p(Wells|is,a,bank,in,USA)\n+log p(FARGO|is,a,bank,in,USA) (11)\nUsing Eq. 10, XLNet will compute:\nJXLNet =log p(Wells|is,a,bank,in,USA)\n+log p(FARGO|Wells,is,a,bank,in,USA)\n(12)\nThese examples show that both BERT and XLNet compute\nthe objective differently. XLNet captures important depen-\ndencies between prediction targets, such as (Wells, Fargo),\nwhich BERT omits. Hence, XLNet combines the advantages\nof AR and auto-encoding methods by using a generalized AR\npre-training approach with a permutation language modeling\nobjective, in order to improve the results in NLP.\n4) XLM\nThe Cross-lingual Language Model (XLM) [62] has a\ntransformer architecture that is mainly used for modeling\ncross-lingual features. XLM is pre-trained using several\nobjectives:\n• Causal Language Modeling (CLM) - next token\nprediction.\n• Masked Language Modeling (MLM) - approach similar\nto BERT’s objective for masking random tokens in the\nsentence.\n• Translation Language Modeling (TLM) - supervised\napproach, which harnesses parallel streams of textual\ndata written in different languages in order to improve\ncross-lingual pre-training support.\nVOLUME 8, 2020 131669\nK. Mishevet al.: Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers\nIn our analysis, we use XLM for text classiﬁcation tasks to\nperform sentiment analysis of texts in English. We explore\nbi-directional context of the tokens in sentences to per-\nform Masked Language Modeling (MLM), which is the best\napproach for our evaluation task.\n5) ALBERT\nTo overcome the shortcomings of using large pre-training\nnatural language representations such as GPU/TPU, mem-\nory limitations, and longer training times, in 2019 Google\nResearch and Toyota Technological Institute jointly released\na new model that introduces BERT’s smaller and more scal-\nable successor, called ALBERT [63]. ALBERT is based\non two-parameter reduction methods: cross-layer parameter\nsharing and sentence ordering objectives, in order to lower\nmemory consumption and increase the training speed of\nBERT. ALBERT outperforms BERT in several tasks, includ-\ning text classiﬁcation [64]. ALBERT uses a signiﬁcantly\nreduced number of parameters in sentiment analysis, com-\npared to BERT and XLNet.\n6) RoBERTa\nThe RoBERTa model, introduced by the Facebook research\nteam in 2019 [4], offers an alternative optimized ver-\nsion of BERT. Retrained on a dataset ten times larger,\nwith improved training methodology and different hyper-\nparameters, RoBERTa removes the Next Sentence Predic-\ntion (NSP) objective and adds dynamic masking of words\nduring the training epochs. These changes and features show\nbetter performances compared to BERT in many NLP tasks,\nincluding text classiﬁcation.\n7) DistilBERT\nDistilBERT, introduced in October 2019 [65], is based on a\nmethodology that reduces the size of a BERT model by 40%,\nwhile retaining 97% of its language understanding capa-\nbilities and being 60% faster. The technique that produces\na compression of the original model is known as knowl-\nedge distillation. The compact (student) model is trained to\nreproduce the full output distribution of the larger (teacher)\nmodel or ensemble of models. Rather than training with a\ncross-entropy over the hard-targets (one-hot encoding of the\nclasses), the student obtains the knowledge based on a dis-\ntillation loss over the soft-target probabilities of the teacher.\nThe distillation loss Lce is calculated by using the Eq. 13.\nLce =\n∑\ni\nti ∗log(si) (13)\nwhere ti and si are the estimated probabilities of the teacher\nand student respectively. This objective results in a richer\ntraining signal, since soft-target probabilities enforce stricter\nconstraints compared to a single hard-target.\nWe assess the performances of three distilled ver-\nsions (students) of the following transformers (teachers):\nBERT-base-cased, BERT-base-uncased, and RoBERTa-base.\n8) XLM-RoBERTa\nThe XLM-RoBERTa (XLM-R) [66] model is a multilingual\nmodel trained on one hundred different languages by using\n2.5TB of ﬁltered CommonCrawl data and it is based on Face-\nbook’s RoBERTa model. XLM-R achieves solid performance\ngains for a wide range of cross-lingual transfer tasks, includ-\ning text classiﬁcation. Additionally, XLM-RoBERTa offers\na possibility of multilingual modeling without decreasing\nper-language performance, which makes it more attractive for\nevaluation compared to other transformers.\nXLM-R follows the XLM approach [62], trained with a\nMasked Language Modeling (MLM) objective with minor\nchanges to the hyper-parameters of the original XLM model.\nIn our analysis, we evaluate the performance of two\ndifferent pre-trained XLM-R models: XLM −Rbase and\nXLM −RLarge, which differ in the size of their parameters.\n9) BART\nIn October 2019, the Facebook research team published a\nnovel transformer called BART [67] with an architecture sim-\nilar to both BERT [3] and GPT2 (Generative Pre-Training 2)\n[68]. BART outperforms other transformers in generation\ntasks such as text summarizing and question answering.\nBART leverages the advantages of the bidirectional encoder\nfrom BERT and the GPT AR decoder. The auto-regressive\napproach means that GPT considers left to right dependence\nof the words in a sentence, which makes it more appropriate\nfor text-generation compared to BERT. BART’s encoder and\ndecoder are connected by cross-attention. Each decoder layer\nperforms attention over the ﬁnal hidden state of the encoder\noutput. This mechanism enables the model to generate output\nthat is closely connected to the original input.\nThe ﬁne-tuned model concatenates the input sentence with\nthe end of sequence (EOS) token and passes these compo-\nnents as input to the BART encoder and decoder. The repre-\nsentation of the EOS token is used to classify the sentiment\nexpressed in the sentence. In this study, we ﬁne-tune BART\nand adapt it to sentiment analysis in ﬁnance.\nIV. DATASETS\nWe use publicly available datasets that have been labeled\nby ﬁnancial experts to perform a reliable evaluation of\nthe ML models in predicting sentiments of ﬁnancial head-\nlines. We perform binary classiﬁcations to designate each\nof the sentences as bullish (positive) or bearish (negative),\nas described in the following subsections.\nA. FINANCIAL PHRASE BANK\nThe Financial Phrase-Bank dataset [69] consists of 4845\nEnglish sentences selected randomly from ﬁnancial news\nfound on the LexisNexis database. These sentences have been\nannotated by 16 experts with a background in ﬁnance and\nbusiness. The annotators were asked to give labels according\nto how they think the information in the sentence might\ninﬂuence the mentioned company’s stock price. The dataset\n131670 VOLUME 8, 2020\nK. Mishevet al.: Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers\nTABLE 1. Datasets statistics.\nalso includes information regarding the agreement levels on\nsentences among annotators. All sentences are annotated with\nthree labels: Positive, Negative, and Neutral. The distribution\nof sentiment labels is presented in Table 1.\nB. SemEval 2017 TASK 5\nThe second dataset used in this paper is provided by the\nSemEval-2017 task ‘‘Fine-Grained Sentiment Analysis on\nFinancial Microblogs and News’’ [70]. The Financial News\nStatements and Headlines dataset consists of 2510 news head-\nlines, gathered from different publicly available sources such\nas Yahoo Finance. Each headline (instance) is annotated by\nthree independent ﬁnancial experts, and a sentiment score,\nin the range between -1 and 1, is assigned to each statement.\nA score of -1 means that the statement (message) is bearish\nor very negative, and a score of 1 means that the statement\nis bullish or very positive. We convert these sentiment scores\ninto sentiment labels (bullish/bearish). The conversion pro-\ncess is performed by using Eq. 14.\nL =\n\n\n\nBullish, if score >0\nBearish, if score <0\nNeutral, if score =0\n(14)\nAfter the conversion, the number of sentences per label is\npresented in Table 1.\nThe dataset used for evaluation is a combination of both\ndatasets. To address the imbalance between positive and\nnegative sentences, we perform a balancing by extract-\ning 1093 positive and another 1093 negative sentences, which\nwe merge into one dataset. Additionally, we shufﬂe the\ndatasets and we set aside stratiﬁed 80% of all sentences\nas a training and stratiﬁed 20% of the remaining sentences\nas a validation set. At the end, our balanced training set\nincludes 1748 samples, and a balanced validation set consist-\ning of 438 samples.\nC. DATA PRE-PROCESSING\nFinancial headlines, similar to other real world text data,\nare likely to be inconsistent, incomplete and contain errors.\nHence, to prepare the data, we perform initial pre-processing\nthat includes tokenization, stop-word removal, and stem-\nming. Additionally, we extract the named entities (organiza-\ntions and people) from the headlines and replace them with\ntheir general nouns. For example, Microsoft is replaced with\n<CMPY>, or London with <CITY>.\nWe impose a min-max length of sentences to 3-64 words.\nAfter this initial ﬁltering, we obtain the distributions of the\nFIGURE 6. Distribution of number of words in training set.\nFIGURE 7. Distribution of number of words in validation set.\nnumber of words per sentence for the training set (Fig. 6) and\nfor the validation set (Fig. 7).\nWhen evaluating lexicon-based and word encoders,\nwe perform left padding to sentences in order to ﬁx their\nsize, due to their variable length. Considering the maximum\nsize of the sentences given in Figs. 6 and 7, we pad them\nto 64 word length. When using sentence encoders, we do not\npad the sequences due to the ability of the sentence encoders\nto encode sentences to ﬁxed-size vectors.\nV. SENTIMENT ANALYSIS PLATFORM\nWe evaluate the sentiment analysis methods by using the\ngeneral platform, consisting of ﬁve phases shown in Fig. 8,\nas follows:\n• In the ﬁrst phase, we create our working dataset based on\nthe Financial Phrase Bank and the SemEval 2017 dataset.\n• In the second phase we apply data pre-processing func-\ntions as described in subsection IV-C.\n• The third phase performs text encoding by using various\ntext representation methods in order to extract features\nfrom the pre-processed texts. We evaluate the following\ntext representation methods: domain lexicons, statistical\nmodels for feature extraction, word encoders, sentence\nencoders and NLP transformers.\nVOLUME 8, 2020 131671\nK. Mishevet al.: Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers\nFIGURE 8. Sentiment analysis platform architecture.\nTABLE 2. Average performances of models grouped by text representation method.\n• In the fourth phase, these embeddings are fed as input\nto various machine-learning or deep-learning classiﬁers,\nthus enabling us to evaluate many encoding-classiﬁer\ncombinations.\n131672 VOLUME 8, 2020\nK. Mishevet al.: Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers\nTABLE 3. Lexical Rule-based approach results.\n• In the ﬁfth phase, we compare the real and predicted\nlabels using several binary classiﬁcation performance\nmetrics.\nThe sentiment analysis platform is implemented in Python\n3.6. The shallow models are developed using Tensorﬂow\nKeras [71] while the pre-trained versions of NLP transform-\ners are retrieved from the Hugging Face repository [72].\nThe sentiment analysis modules are published at the GitHub\nrepository.4\n4https://github.com/f-data/ﬁnSENT\nIn the following subsections, we present the details of\nmachine-learning and deep-learning classiﬁers, ﬁne-tuning\nof NLP transformers and evaluation metrics.\nA. MACHINE-LEARNING CLASSIFIERS\nIn our evaluation analysis, we use two machine-learning\nclassiﬁers: Support Vector Classiﬁer (SVC), as a represen-\ntative of Support Vector Machines (SVM), and an Extreme\nGradient Boosting (XGB) [73], [74], as a representative of\ngradient-boosted decision trees. We chose the XGB model\nVOLUME 8, 2020 131673\nK. Mishevet al.: Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers\nTABLE 4. Statistical methods results.\nbecause it has achieved impressive results in many Kaggle\ncompetitions, in the structured data category. When using\nthe ML classiﬁers, we perform a GridSearch approach for\nretrieving the best hyper-parameters.\nB. DEEP-NEURAL NETWORKS (DNN)\nDeep-learning methods [75] are achieving outstanding results\nin many ﬁelds, including: signal processing [76], computer\nvision [77], speech processing [78]–[80] and text classiﬁca-\ntion [81].\nThe text representations and the features extracted from\nthe evaluation methods are fed as input into Convolutional\nNeural Networks (CNN) [23] and Recurrent Neural Net-\nworks (RNN) [82] in order to proceed with the classiﬁcation.\nWhile RNN networks work well in sequence modeling and\ncapturing long-term dependencies, CNN networks are more\nefﬁcient in capturing spatial or temporal correlations and in\nreducing data dimensionality.\nIn order to improve the architecture of previous DNN net-\nworks, novel mechanisms have been introduced. One of them\nis the Attention mechanism [83], which helps RNN networks\nfocus on speciﬁc parts of the input sequence, facilitating\nthe learning and improving the prediction. The Attention\nmechanism is widely used in encoder-decoder architectures\ndue to its ability to highlight important parts of the contextual\ninformation.\nBidirectional RNN networks are often used to collect fea-\ntures from both directions. A forward RNN − →h gathers token\nfeatures from the start (x 1) to the end (x n), while the backward\nRNN ← −h processes the tokens in reverse direction, from (x n)\nto (x1). The resulting hidden state h uses both sets of features\nconcatenating − →h and ← −h as shown in Eq.15:\nhi =− →hi ⊕← −hi (15)\nwhere ⊕denotes the concatenation function.\nIn our analysis, we used shallow RNN and CNN networks\nin order to evaluate the features from text representations.\nThese shallow neural networks consist of three main layers:\nthe input (embedding) layer, the hidden layer, and the output\nlayer. The input layer uses text representation methods (lexi-\ncons/word or sentence encoders) to extract the feature vectors\nfrom the headlines. It then gives the vector as an input to the\nrecurrent or convolutional hidden layer to extract complex\nfeatures from the text representation methods. The output\nlayer uses a softmax activation function to make the ﬁnal\nclassiﬁcation. We then add an attention layer after the hidden\nlayer to evaluate its effectiveness. Furthermore, we build an\nadditional group of GRU and LSTM networks, which support\nbidirectional feature extraction, to assess their performance\nin ﬁnance-based sentiment analysis as described in [84]. and\nwe use binary cross-entropy loss function when training the\nmodels. The ADAM (Adaptive Learning Rate) optimization\nalgorithm [85] is used to ﬁnd optimal weights in the networks.\nWe use a maximum of one hundred training epochs for all\nDL models. We impose early stopping when the validation\nloss does not diminish after ten epochs to prevent over-ﬁtting.\nFinally, we use dropout layer as regularization in the CNN\nnetwork [86].\nC. MODEL FINE-TUNING\nTo evaluate NLP transformers, we use pre-trained mod-\nels from the Hugging Face’s repository [72]. For ﬁnBERT,\nwe use the language model trained on TRC2 dataset, pub-\nlished on the GitHub repository. 5 We ﬁne-tune the trans-\nformers with the training dataset by adding only one dense\nlayer after the last hidden state. The dense layer outputs\nthe probabilities of sentence classiﬁcation. Transformer’s\nhyper-parameter settings during the ﬁne-tuning phase are not\nmodel agnostic and they are directly related to the quality of\nthe model.\nD. EVALUATION METRICS\nWe evaluate the models for sentiment analysis of ﬁnancial\nheadlines, and present the results chronologically, based on\nthe models’ publication date. We ﬁrst evaluate lexicon-based\nmethods, using Harvard IV-4 and Loughran-McDonald dic-\ntionaries. Next, we evaluate word encoders as pioneers in\n5https://github.com/ProsusAI/ﬁnBERT\n131674 VOLUME 8, 2020\nK. Mishevet al.: Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers\nTABLE 5. Fixed word embedding encoders results.\nVOLUME 8, 2020 131675\nK. Mishevet al.: Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers\nTABLE 6. Sentence encoders.\nmodern NLP feature engineering approaches. Here, we use\nword encoders with shallow RNN architectures, described\nin Section V. Subsequently, we examine the performance\nof sentence encoders with a shallow dense layer and CNN\narchitectures. Finally, we measure the efﬁciency of the latest\nNLP transformers, described in Section III.\nAs a main evaluation metric, we chose Matthews Corre-\nlation Coefﬁcient (MCC) (16), where TP and TN are True\nPositive and True Negative samples accordingly, and FP and\nFN are the False Positive and False Negative number of\nsamples which are misclassiﬁed.\nMCC = tp ∗tn−fp ∗fn\n√(tp +fp)(fn +tn)(fp +tn)(tp +fn) (16)\nMCC is widely used in assessing binary classiﬁcation\nperformance with a range between -1 (completely wrong\nbinary classiﬁer) and 1 (completely accurate binary classi-\nﬁer). It takes into consideration true and false positives and\n131676 VOLUME 8, 2020\nK. Mishevet al.: Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers\nTABLE 7. Contextual word embedding encoders results.\nnegatives, thus providing a balanced measure, which can be\nused even if the classes have different sample sizes.\nVI. RESULTS AND DISCUSSION\nIn this section, we present the model evaluation results.\nIn Table 3, we report on the performance of the\nlexicon-based models by using hand-crafted feature engi-\nneering, based on the Loughran-McDonald (LM) ﬁnan-\ncial and general Harvard IV-4 dictionaries. We perform\nthe evaluations by using the Lydia system polarity detec-\ntion, machine-learning classiﬁers, and deep-learning mod-\nels, as described in previous sections. As expected, the\nLoughran-McDonald features outperform the Harvard IV-4\ngeneral-purpose sentiment analysis dictionary. Hence, fea-\nture extraction with a domain-speciﬁc dictionary is a better\napproach for sentiment analysis tasks. The best perform-\ning model is the XGB classiﬁer using LM features, achiev-\ning MCC=0.327. Additionally, we ﬁnd that RNN networks\noutperform CNN and fully-connected dense networks. The\nimproved results are due to the RNN networks’ ability to\nremember sequential data, which is crucial for classiﬁca-\ntion of sentences. Furthermore, the bidirectional context and\nattention layer improve the results when used in combination\nwith RNN networks.\nIn Table 4, we present the results of the experiments per-\nformed on features extracted from statistical methods. We use\nML classiﬁers and a deep neural network classiﬁer based\non fully connected dense layers. These methods show good\nresults, achieving an MCC score of 0.667, almost twice as\ngood as the lexicon-based methods.\nIn Table 5, we present the evaluation results of the word\nencoders. Generally, the best score is achieved when using\nStanford’s GloVe with Bidirectional GRU and attention layer\n(MCC=0.704). Here, the attention layer increases the MCC\nscore by 0.04 compared to the BiGRU method without the\nattention layer (MCC=0.666). Additionally, the evaluated\nword encoders achieve better results when used with RNN\nnetworks, which further learn the context from the attention\nlayer. In all tests, the GRU units outperform the LSTM units.\nThe features extracted from word encoders are signiﬁ-\ncantly better compared to the features extracted by using\nlexicons and dictionaries. Furthermore, the word encoders\nperform better than statistical methods for feature extraction,\nwhich implies that incorporating semantic meaning into the\nword representation is useful for classiﬁcation.\nThe results obtained from the evaluation of sentence\nencoders are presented in Table 6. InferSent, developed by\nFacebook, is the best performing sentence-based encoder.\nIts version 2 uses a simple architecture composed of\nVOLUME 8, 2020 131677\nK. Mishevet al.: Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers\nTABLE 8. Transformers results.\nfully connected dense layers which averages FastText word\nembeddings, thus outperforming Doc2Vec, Universal Sen-\ntence Encoder (USE), Skip-Thought-Vectors, and LASER.\nAdditionally, InferSent outperforms the word encoder Fast-\nText, which implies that the InferSent’s algorithm for averag-\ning the word embeddings has superior efﬁciency for sentence\ncontext representation. Furthermore, we ﬁnd that the FastText\nversion of InferSent outperforms the GloVe version of Inter-\nSent. When using sentence vector representation, ML classi-\nﬁers are more effective than CNN and a fully connected dense\nnetwork.\nIn Table 7, we present the results of the ﬁrst contextual\nword encoder, ELMo, which we evaluate in combination with\nML classiﬁers (SVC, XGB) and DL classiﬁer models (Dense,\nCNN and RNN). ELMo embeddings outperform the evalu-\nated word encoders with ﬁxed embeddings. This conﬁrms the\nhypothesis that contextual word vectors extract better features\nthan the ﬁxed ones. Additionally, concatenated vectors of\n131678 VOLUME 8, 2020\nK. Mishevet al.: Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers\nFIGURE 9. Sentiment analysis models’ performances grouped by text representation method. On the chart, the top of the line for each model is the\nmaximum, the bottom is the minimum and the white rectangle is the average performance per group. The numbers in the brackets represent the\ngroup of the text representation method, where (1) - lexicon-based methods, (2) - statistical methods, (3) - word encoders, (4) - sentence encoder,\n(5) NLP Transformer.\nwords embeddings in combination with BiGRU network and\nan attention layer outperform the other ML and DL networks.\nWe also evaluate the popular NLP transformers which sup-\nport text classiﬁcation. We ﬁne-tune them with training data\nin order to bias the embeddings towards ﬁnancial sentiment\nanalysis. All transformer architectures outperform word and\nsentence encoders, as shown in Table 8. Hence, contextu-\nalized embeddings perform semantic tasks better than their\nnon-contextualized counterparts. Among the family of BERT\ntransformers, BERT-Large-uncased achieves the best score\nin classiﬁcation, with MCC=0.859. Although FinBERT was\npre-trained on Reuters ﬁnancial texts, it does not perform as\nwell as the other pre-trained versions of BERT, which use\nWikipedia and BookCorpus as text corpora for pre-training.\nRoBERTa’s dynamic masking increases the efﬁciency of\nthe BERT algorithm by 0.023. DistilBERT retains more than\n95% of the accuracy while having 40% fewer parameters.\nA distilled version of RoBERTa achieves as good results as\nBERT-large while using half the parameters of the teacher\nRoBERTa-base model. Among the ALBERT family of trans-\nformers, ALBERT-xxlarge pre-trained model outperforms\nthe other ALBERT versions, obtaining MCC=0.881. Addi-\ntionally, ALBERT outperforms the BERT model. The\ncross-language model (XLM) also outperforms BERT and\nXLNet. XLM-MLM-en-2048 achieves the best result, with\nMCC=0.863, among all XLM versions. Finally, the latest\nNLP transformer, Facebook’s BART, outperforms all the\nother NLP transformers when applied to ﬁnance data, achiev-\ning the best MCC score of 0.895.\nWe show the performances of text representation\napproaches in Table 2, while the performance of each method\nchronologically is shown in Fig. 9.\nVII. CONCLUSION\nThis paper presents a comprehensive chronological study\nof NLP-based methods for sentiment analysis in ﬁnance.\nThe study begins with the lexicon-based approach, includes\nword and sentence encoders and concludes with recent NLP\ntransformers. The NLP transformers show superior perfor-\nmances compared to the other evaluated approaches. The\nmain progress in sentiment analysis accuracy is driven by\nthe text representation methods, which feed the semantic\nVOLUME 8, 2020 131679\nK. Mishevet al.: Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers\nmeaning of the words and sentences into the models. The\nresults achieved by the best models are comparable to expert’s\nopinion. The evaluations were performed on a relatively small\ndataset of approximately 2000 sentences. Even though the\ndataset is not large, we obtained good results, suggesting\nthat this approach is appropriate for domains where large\nannotated data is not available.\nDistilled versions (Distilled-BERT and Distilled-\nRoBERTa) of NLP transformers achieve text classiﬁca-\ntion performances comparable to their large, uncompressed\nteacher models. Hence, they can be effectively used in text\nclassiﬁcation production environments, where the need for\nlight-weight, responsive, energy-efﬁcient and cost-saving\nmodels is essential.\nThe results of this study can be applied in areas such\nas ﬁnance, where decision-making is based on senti-\nment extraction from massive textual datasets. The ﬁnd-\nings imply that selected models can be successfully used\nfor forecasting stock market trends and corporate earnings,\ndecision-making in securities trading and portfolio manage-\nment, brand reputation management as well as fraud detection\nand regulation [87]–[89].\nAlthough this approach was constructed for sentiment\nanalysis in the ﬁnance domain, it can be extended to other\nareas such as healthcare, legal and business analytics.\nAPPENDIX A\nRESULTS\nSee Tables 3–8.\nREFERENCES\n[1] A. Yenter and A. Verma, ‘‘Deep CNN-LSTM with combined kernels from\nmultiple branches for IMDb review sentiment analysis,’’ in Proc. IEEE 8th\nAnnu. Ubiquitous Comput., Electron. Mobile Commun. Conf. (UEMCON),\nOct. 2017, pp. 540–546.\n[2] D. Cer, Y . Yang, S.-Y . Kong, N. Hua, N. Limtiaco, R. St. John, N. Constant,\nM. Guajardo-Cespedes, S. Yuan, C. Tar, Y .-H. Sung, B. Strope, and\nR. Kurzweil, ‘‘Universal sentence encoder,’’ 2018, arXiv:1803.11175.\n[Online]. Available: http://arxiv.org/abs/1803.11175\n[3] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, ‘‘BERT: Pre-training\nof deep bidirectional transformers for language understanding,’’ 2018,\narXiv:1810.04805. [Online]. Available: http://arxiv.org/abs/1810.04805\n[4] Y . Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis,\nL. Zettlemoyer, and V . Stoyanov, ‘‘RoBERTa: A robustly optimized\nBERT pretraining approach,’’ 2019, arXiv:1907.11692. [Online]. Avail-\nable: http://arxiv.org/abs/1907.11692\n[5] B. G. Malkiel, ‘‘The efﬁcient market hypothesis and its critics,’’ J. Econ.\nPerspect., vol. 17, no. 1, pp. 59–82, Feb. 2003.\n[6] M.-Y . Day and C.-C. Lee, ‘‘Deep learning for ﬁnancial sentiment analysis\non ﬁnance news providers,’’ in Proc. IEEE/ACM Int. Conf. Adv. Social\nNetw. Anal. Mining (ASONAM), Aug. 2016, pp. 1127–1134.\n[7] L. Dodevska, V . Petreski, K. Mishev, A. Gjorgjevikj, I. V odenska,\nL. Chitkushev, and D. Trajanov, ‘‘Predicting companies stock price direc-\ntion by using sentiment analysis of news articles,’’ in Proc. 15th Annu.\nInt. Conf. Comput. Sci. Educ. Comput. Sci., Fulda, Germany, Jul. 2019,\npp. 37–42.\n[8] W. Souma, I. V odenska, and H. Aoyama, ‘‘Enhanced news sentiment\nanalysis using deep learning methods,’’ J. Comput. Social Sci., vol. 2, no. 1,\npp. 33–46, Jan. 2019.\n[9] S. F. Crone and C. Koeppel, ‘‘Predicting exchange rates with sentiment\nindicators: An empirical evaluation using text mining and multilayer\nperceptrons,’’ in Proc. IEEE Conf. Comput. Intell. Financial Eng. Econ.\n(CIFEr), Mar. 2014, pp. 114–121.\n[10] C. Curme, H. E. Stanley, and I. V odenska, ‘‘Coupled network approach\nto predictability of ﬁnancial market returns and news sentiments,’’ Int. J.\nTheor. Appl. Finance, vol. 18, no. 7, Nov. 2015, Art. no. 1550043.\n[11] K. Mishev, A. Gjorgjevikj, I. V odenska, L. Chitkushev, W. Souma, and\nD. Trajanov, ‘‘Forecasting corporate revenue by using deep-learning\nmethodologies,’’ in Proc. Int. Conf. Control, Artif. Intell., Robot. Optim.\n(ICCAIRO), May 2019, pp. 115–120.\n[12] T. Loughran and B. Mcdonald, ‘‘When is a liability not a liability? Textual\nanalysis, dictionaries, and 10-ks,’’ J. Finance, vol. 66, no. 1, pp. 35–65,\nFeb. 2011.\n[13] M. Ghiassi, J. Skinner, and D. Zimbra, ‘‘Twitter brand sentiment analysis:\nA hybrid system using n-gram analysis and dynamic artiﬁcial neural\nnetwork,’’Expert Syst. Appl., vol. 40, no. 16, pp. 6266–6282, Nov. 2013.\n[14] N. Li, X. Liang, X. Li, C. Wang, and D. D. Wu, ‘‘Network environment\nand ﬁnancial risk using machine learning and sentiment analysis,’’ Hum.\nEcological Risk Assessment, Int. J., vol. 15, no. 2, pp. 227–252, Apr. 2009.\n[15] G. Wang, T. Wang, B. Wang, D. Sambasivan, Z. Zhang, H. Zheng, and\nB. Y . Zhao, ‘‘Crowds on wall street: Extracting value from collaborative\ninvesting platforms,’’ in Proc. 18th ACM Conf. Comput. Supported Coop-\nerat. Work Social Comput. CSCW, 2015, pp. 17–30.\n[16] M. Atzeni, A. Dridi, and D. R. Recupero, ‘‘Fine-grained sentiment analysis\non ﬁnancial microblogs and news headlines,’’ in Semantic Web Challenges.\nCham, Switzerland: Springer, 2017, pp. 124–128.\n[17] S. Agaian and P. Kolm, ‘‘Financial sentiment analysis using machine\nlearning techniques,’’ Int. J. Investment Manage. Financial Innov., vol. 3,\npp. 1–9, 2017.\n[18] S. Sohangir, N. Petty, and D. Wang, ‘‘Financial sentiment lexicon analy-\nsis,’’ in Proc. IEEE 12th Int. Conf. Semantic Comput. (ICSC), Jan. 2018,\npp. 286–289.\n[19] S. Sohangir, D. Wang, A. Pomeranets, and T. M. Khoshgoftaar, ‘‘Big data:\nDeep learning for ﬁnancial sentiment analysis,’’ J. Big Data, vol. 5, no. 1,\np. 3, Dec. 2018.\n[20] L. Zhang, S. Wang, and B. Liu, ‘‘Deep learning for sentiment analysis: A\nsurvey,’’Wiley Interdiscipl. Rev., Data Mining Knowl. Discovery, vol. 8,\nno. 4, 2018, Art. no. e1253.\n[21] D. Tang, B. Qin, and T. Liu, ‘‘Document modeling with gated recurrent\nneural network for sentiment classiﬁcation,’’ in Proc. Conf. Empirical\nMethods Natural Lang. Process., 2015, pp. 1422–1432.\n[22] K. Sheng Tai, R. Socher, and C. D. Manning, ‘‘Improved semantic repre-\nsentations from tree-structured long short-term memory networks,’’ 2015,\narXiv:1503.00075. [Online]. Available: http://arxiv.org/abs/1503.00075\n[23] Y . Kim, ‘‘Convolutional neural networks for sentence classiﬁcation,’’\n2014, arXiv:1408.5882. [Online]. Available: http://arxiv.org/abs/1408.\n5882\n[24] X. Zhang, J. Zhao, and Y . LeCun, ‘‘Character-level convolutional networks\nfor text classiﬁcation,’’ in Proc. Adv. Neural Inf. Process. Syst. , 2015,\npp. 649–657.\n[25] R. Johnson and T. Zhang, ‘‘Deep pyramid convolutional neural networks\nfor text categorization,’’ in Proc. 55th Annu. Meeting Assoc. Comput.\nLinguistics (Long Papers), vol. 1, 2017, pp. 562–570.\n[26] Z. Yang, D. Yang, C. Dyer, X. He, A. Smola, and E. Hovy, ‘‘Hierarchical\nattention networks for document classiﬁcation,’’ in Proc. Conf. North\nAmer. Chapter Assoc. Comput. Linguistics, Hum. Lang. Technol., 2016,\npp. 1480–1489.\n[27] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean, ‘‘Distributed\nrepresentations of words and phrases and their compositionality,’’ in Proc.\nAdv. Neural Inf. Process. Syst., 2013, pp. 3111–3119.\n[28] J. Pennington, R. Socher, and C. Manning, ‘‘Glove: Global vectors for\nword representation,’’ in Proc. Conf. Empirical Methods Natural Lang.\nProcess. (EMNLP), 2014, pp. 1532–1543.\n[29] P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov, ‘‘Enriching word\nvectors with subword information,’’ Trans. Assoc. Comput. Linguistics,\nvol. 5, pp. 135–146, Dec. 2017.\n[30] Q. Le and T. Mikolov, ‘‘Distributed representations of sentences and\ndocuments,’’ in Proc. Int. Conf. Mach. Learn., 2014, pp. 1188–1196.\n[31] R. Kiros, Y . Zhu, R. R. Salakhutdinov, R. Zemel, R. Urtasun, A. Torralba,\nand S. Fidler, ‘‘Skip-thought vectors,’’ in Proc. Adv. Neural Inf. Process.\nSyst., 2015, pp. 3294–3302.\n[32] A. Conneau, D. Kiela, H. Schwenk, L. Barrault, and A. Bordes, ‘‘Super-\nvised learning of universal sentence representations from natural lan-\nguage inference data,’’ 2017, arXiv:1705.02364. [Online]. Available:\nhttp://arxiv.org/abs/1705.02364\n131680 VOLUME 8, 2020\nK. Mishevet al.: Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers\n[33] M. Artetxe and H. Schwenk, ‘‘Massively multilingual sentence embed-\ndings for zero-shot cross-lingual transfer and beyond,’’ Trans. Assoc. Com-\nput. Linguistics, vol. 7, pp. 597–610, Mar. 2019.\n[34] X. Man, T. Luo, and J. Lin, ‘‘Financial sentiment analysis(FSA): A sur-\nvey,’’ in Proc. IEEE Int. Conf. Ind. Cyber Phys. Syst. (ICPS), May 2019,\npp. 617–622.\n[35] S. Yang, J. Rosenfeld, and J. Makutonin, ‘‘Financial aspect-based sen-\ntiment analysis using deep representations,’’ 2018, arXiv:1808.07931.\n[Online]. Available: http://arxiv.org/abs/1808.07931\n[36] C.-H. Du, M.-F. Tsai, and C.-J. Wang, ‘‘Beyond word-level to\nsentence-level sentiment analysis for ﬁnancial reports,’’ in Proc. IEEE\nInt. Conf. Acoust., Speech Signal Process. (ICASSP), May 2019,\npp. 1562–1566.\n[37] L. Zhao, L. Li, and X. Zheng, ‘‘A BERT based sentiment analysis\nand key entity detection approach for online ﬁnancial texts,’’ 2020,\narXiv:2001.05326. [Online]. Available: http://arxiv.org/abs/2001.05326\n[38] J. Howard and S. Ruder, ‘‘Universal language model ﬁne-tuning for\ntext classiﬁcation,’’ 2018, arXiv:1801.06146. [Online]. Available: http://\narxiv.org/abs/1801.06146\n[39] P. J. Stone, D. C. Dunphy, and M. S. Smith, The General Inquirer: A\nComputer Approach to Content Analysis. Oxford, U.K.: MIT Press, 1966.\n[40] J. L. Rogers, A. Van Buskirk, and S. L. C. Zechman, ‘‘Disclosure tone and\nshareholder litigation,’’ Accounting Rev., vol. 86, no. 6, pp. 2155–2183,\nNov. 2011.\n[41] A. K. Davis, W. Ge, D. Matsumoto, and J. L. Zhang, ‘‘The effect of\nmanager-speciﬁc optimism on the tone of earnings conference calls,’’ Rev.\nAccounting Stud., vol. 20, no. 2, pp. 639–673, Jun. 2015.\n[42] W. Zhang and S. Skiena, ‘‘Trading strategies to exploit blog and news\nsentiment,’’ inProc. 4th Int. AAAI Conf. Weblogs Social Media, May 2010,\npp. 1–4.\n[43] T. Mikolov, K. Chen, G. Corrado, and J. Dean, ‘‘Efﬁcient estimation of\nword representations in vector space,’’ 2013, arXiv:1301.3781. [Online].\nAvailable: http://arxiv.org/abs/1301.3781\n[44] Z. S. Harris, ‘‘Distributional structure,’’ Word, vol. 10, nos. 2–3,\npp. 146–162, Aug. 1954.\n[45] T. K. Landauer and S. T. Dumais, ‘‘A solution to Plato’s problem: The latent\nsemantic analysis theory of acquisition, induction, and representation of\nknowledge.,’’Psychol. Rev., vol. 104, no. 2, p. 211, 1997.\n[46] M. Sahlgren, ‘‘The word-space model: Using distributional analysis\nto represent syntagmatic and paradigmatic relations between words in\nhigh-dimensional vector spaces,’’ Ph.D. dissertation, Dept. Comput. Lin-\nguistics, Stockholm Univ., Stockholm, Sweden, 2006.\n[47] P. D. Turney and P. Pantel, ‘‘From frequency to meaning: Vector space\nmodels of semantics,’’ J. Artif. Intell. Res., vol. 37, pp. 141–188, Feb. 2010.\n[48] A. Joulin, E. Grave, P. Bojanowski, and T. Mikolov, ‘‘Bag of tricks for\nefﬁcient text classiﬁcation,’’ in Proc. 15th Conf. Eur. Chapter Assoc.\nComput. Linguistics, Short Papers, vol. 2, 2017, pp. 427–431.\n[49] Y . Sharma, G. Agrawal, P. Jain, and T. Kumar, ‘‘Vector representation\nof words for sentiment analysis using GloVe,’’ in Proc. Int. Conf. Intell.\nCommun. Comput. Techn. (ICCT), Dec. 2017, pp. 279–284.\n[50] P. Lauren, G. Qu, J. Yang, P. Watta, G.-B. Huang, and A. Lendasse,\n‘‘Generating word embeddings from an extreme learning machine for\nsentiment analysis and sequence labeling tasks,’’ Cognit. Comput., vol. 10,\nno. 4, pp. 625–638, Aug. 2018.\n[51] S. M. Rezaeinia, R. Rahmani, A. Ghodsi, and H. Veisi, ‘‘Sentiment analysis\nbased on improved pre-trained word embeddings,’’ Expert Syst. Appl.,\nvol. 117, pp. 139–147, Mar. 2019.\n[52] T. Mikolov, E. Grave, P. Bojanowski, C. Puhrsch, and A. Joulin, ‘‘Advances\nin pre-training distributed word representations,’’ 2017, arXiv:1712.09405.\n[Online]. Available: http://arxiv.org/abs/1712.09405\n[53] R. Velioglu, T. Yildiz, and S. Yildirim, ‘‘Sentiment analysis using learning\napproaches over emojis for turkish tweets,’’ in Proc. 3rd Int. Conf. Comput.\nSci. Eng. (UBMK), Sep. 2018, pp. 303–307.\n[54] A. A. Altowayan and A. Elnagar, ‘‘Improving arabic sentiment analysis\nwith sentiment-speciﬁc embeddings,’’ in Proc. IEEE Int. Conf. Big Data\n(Big Data), Dec. 2017, pp. 4314–4320.\n[55] M. E. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee,\nand L. Zettlemoyer, ‘‘Deep contextualized word representations,’’ 2018,\narXiv:1802.05365. [Online]. Available: http://arxiv.org/abs/1802.05365\n[56] J. Chung, C. Gulcehre, K. Cho, and Y . Bengio, ‘‘Empirical evalua-\ntion of gated recurrent neural networks on sequence modeling,’’ 2014,\narXiv:1412.3555. [Online]. Available: http://arxiv.org/abs/1412.3555\n[57] L. Logeswaran and H. Lee, ‘‘An efﬁcient framework for learning sen-\ntence representations,’’ 2018, arXiv:1803.02893. [Online]. Available:\nhttp://arxiv.org/abs/1803.02893\n[58] A. Akbik, D. Blythe, and R. V ollgraf, ‘‘Contextual string embeddings for\nsequence labeling,’’ in Proc. 27th Int. Conf. Comput. Linguistics, 2018,\npp. 1638–1649.\n[59] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nL. Kaiser, and I. Polosukhin, ‘‘Attention is all you need,’’ in Proc. Adv.\nNeural Inf. Process. Syst., 2017, pp. 5998–6008.\n[60] Y . Zhu, R. Kiros, R. Zemel, R. Salakhutdinov, R. Urtasun, A. Torralba,\nand S. Fidler, ‘‘Aligning books and movies: Towards story-like visual\nexplanations by watching movies and reading books,’’ in Proc. IEEE Int.\nConf. Comput. Vis. (ICCV), Dec. 2015, pp. 19–27.\n[61] D. Araci, ‘‘FinBERT: Financial sentiment analysis with pre-trained lan-\nguage models,’’ 2019, arXiv:1908.10063. [Online]. Available: http://arxiv.\norg/abs/1908.10063\n[62] G. Lample and A. Conneau, ‘‘Cross-lingual language model pretrain-\ning,’’ 2019, arXiv:1901.07291. [Online]. Available: http://arxiv.org/abs/\n1901.07291\n[63] Z. Lan, M. Chen, S. Goodman, K. Gimpel, P. Sharma, and R. Soricut,\n‘‘ALBERT: A lite BERT for self-supervised learning of language rep-\nresentations,’’ 2019, arXiv:1909.11942. [Online]. Available: http://arxiv.\norg/abs/1909.11942\n[64] M. A. Al-Garadi, Y .-C. Yang, H. Cai, Y . Ruan, K. O’Connor,\nG. Gonzalez-Hernandez, J. Perrone, and A. Sarker, Text Classiﬁcation\nModels for the Automatic Detection of Nonmedical Prescription\nMedication Use from Social Media. Cold Spring Harbor Laboratory\nPress, 2020. [Online]. Available: https://www.medrxiv.org/content/early/\n2020/04/17/2020.04.13.20064089.full.pdf, doi: 10.1101/2020.04.13.\n20064089.\n[65] V . Sanh, L. Debut, J. Chaumond, and T. Wolf, ‘‘DistilBERT, a dis-\ntilled version of BERT: Smaller, faster, cheaper and lighter,’’ 2019,\narXiv:1910.01108. [Online]. Available: http://arxiv.org/abs/1910.01108\n[66] A. Conneau, K. Khandelwal, N. Goyal, V . Chaudhary, G. Wenzek,\nF. Guzmán, E. Grave, M. Ott, L. Zettlemoyer, and V . Stoyanov,\n‘‘Unsupervised cross-lingual representation learning at scale,’’ 2019,\narXiv:1911.02116. [Online]. Available: http://arxiv.org/abs/1911.02116\n[67] M. Lewis, Y . Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy,\nV . Stoyanov, and L. Zettlemoyer, ‘‘BART: Denoising sequence-to-\nsequence pre-training for natural language generation, translation, and\ncomprehension,’’ 2019, arXiv:1910.13461. [Online]. Available: http://\narxiv.org/abs/1910.13461\n[68] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever,\n‘‘Language models are unsupervised multitask learners,’’ OpenAI Blog ,\nvol. 1, no. 8, p. 9, 2019.\n[69] P. Malo, A. Sinha, P. Korhonen, J. Wallenius, and P. Takala, ‘‘Good debt\nor bad debt: Detecting semantic orientations in economic texts,’’ J. Assoc.\nInf. Sci. Technol., vol. 65, no. 4, pp. 782–796, Apr. 2014.\n[70] K. Cortis, A. Freitas, T. Daudert, M. Huerlimann, M. Zarrouk, S. Hand-\nschuh, and B. Davis, ‘‘SemEval-2017 task 5: Fine-grained sentiment\nanalysis on ﬁnancial microblogs and news,’’ in Proc. 11th Int. Workshop\nSemantic Eval. (SemEval-), 2017, pp. 519–535.\n[71] F. Chollet. (2015). Keras. [Online]. Available: https://keras.io\n[72] T. Wolf et al., ‘‘HuggingFace’s transformers: State-of-the-art natural lan-\nguage processing,’’ 2019, arXiv:1910.03771. [Online]. Available: http://\narxiv.org/abs/1910.03771\n[73] J. H. Friedman, ‘‘Greedy function approximation: A gradient boosting\nmachine,’’Ann. Statist., vol. 29, no. 5, pp. 1189–1232, 2001.\n[74] T. Chen and C. Guestrin, ‘‘XGBoost: A scalable tree boosting sys-\ntem,’’ in Proc. 22nd ACM SIGKDD Int. Conf. Knowl. Discovery\nData Mining (KDD), San Francisco, CA, USA. New York, NY , USA:\nACM, 2016, pp. 785–794. [Online]. Available: http://doi.acm.org/10.1145/\n2939672.2939785, doi: 10.1145/2939672.2939785.\n[75] L. Deng and D. Yu, ‘‘Deep learning: Methods and applications,’’\nFound. Trends Signal Process., vol. 7, nos. 3–4, pp. 197–387,\nJun. 2014.\n[76] D. Yu and L. Deng, ‘‘Deep learning and its applications to signal and\ninformation processing [exploratory DSP],’’ IEEE Signal Process. Mag.,\nvol. 28, no. 1, pp. 145–154, Jan. 2011.\n[77] A. V oulodimos, N. Doulamis, A. Doulamis, and E. Protopapadakis, ‘‘Deep\nlearning for computer vision: A brief review,’’ Comput. Intell. Neurosci.,\nvol. 2018, pp. 1–13, Feb. 2018.\n[78] L. Deng, G. Hinton, and B. Kingsbury, ‘‘New types of deep neural network\nlearning for speech recognition and related applications: An overview,’’\nin Proc. IEEE Int. Conf. Acoust., Speech Signal Process., May 2013,\npp. 8599–8603.\nVOLUME 8, 2020 131681\nK. Mishevet al.: Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers\n[79] J. Shen, R. Pang, R. J. Weiss, M. Schuster, N. Jaitly, Z. Yang, Z. Chen,\nY . Zhang, Y . Wang, R. Skerrv-Ryan, R. A. Saurous, Y . Agiomvrgiannakis,\nand Y . Wu, ‘‘Natural TTS synthesis by conditioning wavenet on MEL\nspectrogram predictions,’’ in Proc. IEEE Int. Conf. Acoust., Speech Signal\nProcess. (ICASSP), Apr. 2018, pp. 4779–4783.\n[80] W. Ping, K. Peng, A. Gibiansky, S. O. Arik, A. Kannan, S. Narang,\nJ. Raiman, and J. Miller, ‘‘Deep voice 3: Scaling text-to-speech with convo-\nlutional sequence learning,’’ 2017, arXiv:1710.07654. [Online]. Available:\nhttp://arxiv.org/abs/1710.07654\n[81] G. Liu and J. Guo, ‘‘Bidirectional LSTM with attention mechanism and\nconvolutional layer for text classiﬁcation,’’ Neurocomputing, vol. 337,\npp. 325–338, Apr. 2019.\n[82] P. Liu, X. Qiu, and X. Huang, ‘‘Recurrent neural network for text clas-\nsiﬁcation with multi-task learning,’’ 2016, arXiv:1605.05101. [Online].\nAvailable: http://arxiv.org/abs/1605.05101\n[83] D. Bahdanau, K. Cho, and Y . Bengio, ‘‘Neural machine translation by\njointly learning to align and translate,’’ 2014, arXiv:1409.0473. [Online].\nAvailable: http://arxiv.org/abs/1409.0473\n[84] K. Mishev et al., ‘‘Performance evaluation of word and sentence embed-\ndings for ﬁnance headlines sentiment analysis,’’ in ICT Innovations 2019.\nBig Data Processing and Mining (Communications in Computer and\nInformation Science), vol. 1110, S. Gievska and G. Madjarov, Eds. Cham,\nSwitzerland: Springer, 2019, pp. 161–172.\n[85] D. P. Kingma and J. Ba, ‘‘Adam: A method for stochastic optimiza-\ntion,’’ 2014, arXiv:1412.6980. [Online]. Available: http://arxiv.org/abs/\n1412.6980\n[86] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and\nR. Salakhutdinov, ‘‘Dropout: A simple way to prevent neural networks\nfrom overﬁtting,’’ J. Mach. Learn. Res., vol. 15, no. 1, pp. 1929–1958,\n2014.\n[87] T. Rao and S. Srivastava, ‘‘Analyzing stock market movements using\ntwitter sentiment analysis,’’ Tech. Rep., 2012.\n[88] J. Smailović, M. Grčar, N. Lavrač, and M. Žnidaršič, ‘‘Predictive sentiment\nanalysis of tweets: A stock market application,’’ in Proc. Int. Workshop\nHum.-Comput. Interact. Knowl. Discovery Complex, Unstructured, Big\nData. Berlin, Germany: Springer, 2013, pp. 77–88.\n[89] X. Li, H. Xie, L. Chen, J. Wang, and X. Deng, ‘‘News impact on stock price\nreturn via sentiment analysis,’’ Knowl.-Based Syst., vol. 69, pp. 14–23,\nOct. 2014.\nKOSTADIN MISHEV received the bachelor’s\ndegree in informatics and computer engineering\nand the master’s degree in computer networks\nand e-technologies degree from Saints Cyril and\nMethodius University, Skopje, in 2013 and 2016,\nrespectively, where he is currently pursuing the\nPh.D. degree. He is also a Teaching and a Research\nAssistant with the Faculty of Computer Science\nand Engineering, Saints Cyril and Methodius Uni-\nversity. His research interests include data science,\nnatural language processing, semantic Web, enterprise application architec-\ntures, Web technologies, and computer networks.\nANA GJORGJEVIKJ received the bachelor’s\ndegree in computer science and engineering and\nthe master’s degree in computer networks and\ne-technologies from Saints Cyril and Methodius\nUniversity, Skopje, in 2010 and 2014, respectively,\nwhere she is currently pursuing the Ph.D. degree in\nthe domain of data science, with particular focus\non deep learning and natural language processing.\nShe has been working as a Software Engineer,\nsince 2010. Her research interests include data\nscience, machine learning, natural language processing, and knowledge\nrepresentation.\nIRENA VODENSKA received the B.S. degree in\ncomputer information systems from the University\nof Belgrade, the Ph.D. degree in econophysics (sta-\ntistical ﬁnance) from Boston University, and the\nM.B.A. degree from the Owen Graduate School\nof Management, Vanderbilt University. She is cur-\nrently an Associate Professor of ﬁnance and the\nDirector of ﬁnance programs with the Boston\nUniversity’s Metropolitan College. Her research\nfocuses on network theory and complexity science\nin macroeconomics. She conducts a theoretical and applied interdisciplinary\nresearch using quantitative approaches for modeling interdependences of\nﬁnancial networks, banking system dynamics, and global ﬁnancial crises.\nMore speciﬁcally, her research focuses on modeling of early warning indi-\ncators and systemic risk propagation throughout interconnected ﬁnancial\nand economic networks. She also studies the effects of news announcement\non ﬁnancial markets, corporations, ﬁnancial institutions, and related global\neconomic systems. She uses neural networks and deep learning methodolo-\ngies for natural language processing to text mine important factors affecting\ncorporate performance and global economic trends. She teaches Invest-\nment Analysis and Portfolio Management, International Finance and Trade,\nFinancial Regulation and Ethics, and Derivatives Securities and Markets at\nBoston University. She is also a Chartered Financial Analyst (CFA) charter\nholder. As a Principal Investigator (PI) for Boston University, she has won\ninterdisciplinary research grants awarded by the European Commission, EU,\nU.S. Army Research Ofﬁce, and the National Science Foundation, USA.\nLUBOMIR T. CHITKUSHEV received the\nDipl.Ing. degree in electrical engineering from\nthe University of Belgrade, the M.Sc. degree in\nbiomedical engineering from the Medical Col-\nlege of Virginia, VCU, and the Ph.D. degree in\nbiomedical engineering from Boston University.\nHe is currently an Associate Professor of computer\nscience with the Boston University’s Metropolitan\nCollege, where he serves as the Director of health\ninformatics and health sciences and the Associate\nDean of academic affairs. His research activity is focused on modeling of\ncomplex systems, computer network security and architecture, and biomed-\nical and health informatics. He is also the founder of the Health Informatics\nProgram, Boston University, and a founding member of Boston University’s\nRINA Laboratory, where Recursive Inter-Network Architecture (RINA) was\nintroduced as efﬁcient, scalable, and secure approach to Internet architecture.\nHe is also a Co-Founder and the Associate Director of the Center for Reliable\nInformation Systems and Cyber Security (RISCS), Boston University, which\ncoordinates research on reliable and secure computational systems and\ninfrastructure and information assurance education. He has served as the\nPrincipal Investigator for Boston University on research grants awarded by\nthe European Commission, EU, the National Security Agency, USA, and the\nU.S. Department of Justice. He has also served as a Reviewer with the U.S.\nNational Science Foundation.\nDIMITAR TRAJANOV(Member, IEEE) received\nthe Ph.D. degree. He is currently a Professor\nand the Head of the Department of Informa-\ntion Systems and Network Technologies, Faculty\nof Computer Science and Engineering, Ss. Cyril\nand Methodius University, Skopje. He is also the\nLeader of Regional Social Innovation Hub estab-\nlished, in 2013, as a co-operation between UNDP\nand the Faculty of Computer Science and Engi-\nneering. He is the author of more than 150 journal\nand conference papers and seven books. He has been involved in more\nthan 60 research and industrial projects, mostly as the Project Leader. His\nresearch interests include data science, machine learning, NLP, FinTech,\nsemantic Web, open data, sharing economy, social innovation, e-commerce,\nentrepreneurship, technology for development, mobile development, and\nclimate change.\n131682 VOLUME 8, 2020",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7868872880935669
    },
    {
      "name": "Sentiment analysis",
      "score": 0.7749110460281372
    },
    {
      "name": "Unavailability",
      "score": 0.6273960471153259
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5641824007034302
    },
    {
      "name": "Sentence",
      "score": 0.5627742409706116
    },
    {
      "name": "Transformer",
      "score": 0.5594028830528259
    },
    {
      "name": "Encoder",
      "score": 0.4767288267612457
    },
    {
      "name": "Stock market",
      "score": 0.44357407093048096
    },
    {
      "name": "Natural language processing",
      "score": 0.43641749024391174
    },
    {
      "name": "Machine learning",
      "score": 0.4264293611049652
    },
    {
      "name": "Financial market",
      "score": 0.4106108844280243
    },
    {
      "name": "Finance",
      "score": 0.33865487575531006
    },
    {
      "name": "Economics",
      "score": 0.09111914038658142
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Reliability engineering",
      "score": 0.0
    },
    {
      "name": "Horse",
      "score": 0.0
    },
    {
      "name": "Engineering",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I76245029",
      "name": "Saints Cyril and Methodius University of Skopje",
      "country": "MK"
    },
    {
      "id": "https://openalex.org/I111088046",
      "name": "Boston University",
      "country": "US"
    }
  ],
  "cited_by": 276
}