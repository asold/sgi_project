{
  "title": "Evaluation of GPT-3 AI Language Model in Research Paper Writing",
  "url": "https://openalex.org/W4381512789",
  "year": 2023,
  "authors": [
    {
      "id": null,
      "name": "KATAR, Oğuzhan",
      "affiliations": [
        "Fırat University"
      ]
    },
    {
      "id": null,
      "name": "ÖZKAN, Dilek",
      "affiliations": []
    },
    {
      "id": null,
      "name": "-3, Gpt",
      "affiliations": [
        "OpenAI (United States)"
      ]
    },
    {
      "id": null,
      "name": "YILDIRIM, Özal",
      "affiliations": [
        "Fırat University"
      ]
    },
    {
      "id": null,
      "name": "ACHARYA, U Rajendra",
      "affiliations": [
        "Ngee Ann Polytechnic"
      ]
    },
    {
      "id": "https://openalex.org/A4312976932",
      "name": "KATAR, Oğuzhan\n                        ",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Özkan, Dilek",
      "affiliations": []
    },
    {
      "id": null,
      "name": "-3, Gpt",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4307473563",
      "name": "Yildirim Özal",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2551347070",
      "name": "Acharya U. Rajendra",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W1995341919",
    "https://openalex.org/W2112796928",
    "https://openalex.org/W2618530766",
    "https://openalex.org/W6702248584",
    "https://openalex.org/W1981276685",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W2919115771",
    "https://openalex.org/W2163922914",
    "https://openalex.org/W2581082771",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W2064675550"
  ],
  "abstract": "Artificial intelligence (AI) has helped to obtain accurate, fast, robust results without any human errors.Hence, it has been used in various applications in our daily lives. The Turing test has been afundamental problem that AI systems aim to overcome. Recently developed various natural language problem (NLP) models have shown significant performances. AI language models, used intranslation, digital assistant, and sentiment analysis, have improved the quality of our lives. It canperform scans on thousands of documents in seconds and report them by establishing appropriatesentence structures. Generative pre-trained transformer (GPT)-3 is a popular model developedrecently has been used for many applications. Users of this model have obtained surprising results onvarious applications and shared them on various social media platforms. This study aims to evaluatethe performance of the GPT-3 model in writing an academic article. Hence, we chose the subject ofthe article as tools based on artificial intelligence in academic article writing. The organized querieson GPT-3 created the flow of this article. In this article, we have made an effort to highlight theadvantages and limitations of using GPT-3 for research paper writing. Authors feel that it can be usedas an adjunct tool while writing research papers.",
  "full_text": "Turkish Journal of Science & Technology                     Research Paper                                                                                                                            18(2), 311-318, 2023.                                   https://doi.org/10.55525/tjst.1272369  Evaluation of GPT-3 AI Language Model in Research Paper Writing Oğuzhan KATAR1, Dilek ÖZKAN2, GPT-33, Özal YILDIRIM4*, U Rajendra Acharya5 1,2,4 Department of Software Engineering, Faculty of Technology, Firat University, Elazig, Turkey 3 OpenAI, San Francisco, CA, USA 5 School of Mathematics, Physics and Computing, University of Southern Queensland, Springfield, Australia 1 okatar@firat.edu.tr, 2 mddilekozkan@gmail.com, 3 hello@openai.com, *4 ozalyildirim@firat.edu.tr,  5 Rajendra.Acharya@usq.edu.au   (Geliş/Received: 11/05/2023;                                                                               Kabul/Accepted: 14/06/2023)  Abstract: Artificial intelligence (AI) has helped to obtain accurate, fast, robust results without any human errors. Hence, it has been used in various applications in our daily lives. The Turing test has been a fundamental problem that AI systems aim to overcome. Recently developed various natural language processing (NLP) models have shown significant performances. AI language models, used in translation, digital assistant, and sentiment analysis, have improved the quality of our lives. It can perform scans on thousands of documents in seconds and report them by establishing appropriate sentence structures. Generative pre-trained transformer (ChatGPT) is a popular model developed recently has been used for many applications. Users of this model have obtained surprising results on various applications and shared them on various social media platforms. This study aims to evaluate the performance of the GPT-3 model in writing an academic article. Hence, we chose the subject of the article as tools based on artificial intelligence in academic article writing. The organized queries on ChatGPT created the flow of this article. In this article, we have made an effort to highlight the advantages and limitations of using ChatGPT-3 for academic research paper writing. As a result of the findings, it has been observed that ChatGPT can be used as an auxiliary tool while writing academic research articles.  Key words: AI language models, GPT-3, Natural language processing, Academic tools.  Araştırma Makalesi Yazımında GPT-3 Yapay Zeka Dil Modeli Değerlendirmesi  Öz: Yapay zeka (YZ), herhangi bir insan hatası olmaksızın doğru, hızlı, sağlam sonuçlar alınmasına yardımcı olmaktadır. Bu nedenle günlük hayatımızda çeşitli uygulamalarda etkin bir şekilde kullanım alanı bulmuştur. Turing testi, AI sistemlerinin üstesinden gelmeyi hedeflediği temel bir problem olmuştur. Son zamanlarda geliştirilen çeşitli doğal dil işleme (DDİ) modelleri önemli performanslar göstermiştir. YZ dil modelleri; çeviri, dijital asistan ve duygu analizi gibi alanlarda efektif kullanılarak yaşam kalitemizi artırmaya yardımcı olmaktadır. Bu modeller binlerce belgeyi saniyeler içinde tarayabilir ve uygun cümle yapılarını kurarak raporlayabilir. Üretici Ön-Eğitimli Dönüştürücü (ChatGPT), son zamanlarda geliştirilen ve birçok uygulama için kullanılan popüler bir modeldir. Bu modelin kullanıcıları, çeşitli uygulamalarda şaşırtıcı sonuçlar elde etmiş ve bunları çeşitli sosyal medya platformlarında paylaşmıştır. Bu çalışmada, ChatGPT-3 modelinin akademik bir makale yazmadaki performansının değerlendirilmesi amaçlanmıştır. Bu nedenle makalenin içeriği akademik makale yazımında yapay zekaya dayalı araçlar olarak belirlenmiştir. ChatGPT-3'teki organize sorgular bu makalenin akışını oluşturmuştur. Bu makalede, akademik bir araştırma makalesi yazmak için ChatGPT-3 kullanmanın avantajları ve sınırlamaları vurgulanmıştır. Elde edilen bulgular sonucunda akademik araştırma makaleleri yazarken ChatGPT’nin yardımcı bir araç olarak kullanılabileceğini gözlemlenmiştir.  Anahtar kelimeler: Yapay zeka dil modelleri, ChatGPT, Doğal dil işleme, Akademik yazım araçları.  1. Introduction  Artificial intelligence (AI) has made significant progress since its inception. It has evolved from being a mere concept to becoming a pervasive technology that is used in various fields, including healthcare, finance, transportation, and education. AI has the ability to learn, adapt, and make decisions on its own, making it a valuable tool for solving complex problems. As AI continues to advance, it has the potential to revolutionize the way we live and work, and improve the quality of our lives in countless ways. Artificial intelligence (AI) is a rapidly developing field with a wide range of applications across various industries. In recent years, advances in AI have enabled the development of new technologies and applications that are changing the way we live and work. One of the most exciting areas of AI research is natural language processing (NLP). This involves using AI to analyze and understand human language, allowing computers to interpret and generate text and speech. This has led to the  * Corresponding author:  ozalyildirim@firat.edu.tr. ORCID Number of authors: 1 0000-0002-5628-3543, 2 0000-0001-9256-9402, 3 0000-0001-5375-3012, 4 0000-0001-5375-3012, 5 0000-0003-2689-8552. \nEvaluation of GPT-3 AI Language Model in Research Paper Writing \n312  \ndevelopment of virtual assistants like Siri and Alexa, which can understand and respond to spoken commands. NLP is also used in language translation applications, allowing people to communicate with each other in different languages. One of the most exciting applications for AI is natural language processing (NLP). This technology allows computers to analyze and understand human speech and text, enabling a wide range of applications such as language translation, sentiment analysis, and text summarization (LeCun et al., 2015). NLP is also being used to develop virtual assistants that can help people with tasks like scheduling appointments and managing their email (Bengio et al., 2013).For example, Google's Neural Machine Translation system uses AI to translate text between more than 100 languages, while sentiment analysis algorithms can be used to automatically detect the sentiment of a text and classify it as positive, negative, or neutral (Li, 2018). Another area where AI is making significant strides is computer vision, which involves teaching computers to analyze and understand images and videos. This has applications in fields like facial recognition, object detection, and image classification. For example, the Facebook AI Research (FAIR) lab has developed a system called Detectron that can automatically detect objects in images and videos, while companies like Clearview AI are using AI to build facial recognition systems that can identify individuals in photos and videos (Goodfellow, Bengio, & Courville, 2016). In addition to natural language processing and computer vision, AI is also being used in predictive modeling, which involves using data to make predictions about future events or trends. This has a wide range of applications, including finance, healthcare, and weather forecasting. For example, AI-powered predictive modeling algorithms can be used to forecast stock prices, identify potential health risks, or predict the likelihood of a particular weather event (Makridakis, Wheelwright, & Hyndman, 2018). Finally, AI is also being used in robotics, enabling robots to perform a wide range of tasks in a variety of environments. This has applications in fields like manufacturing, healthcare, and space exploration. For example, NASA is using AI-powered robots to explore other planets, while companies like Amazon are using robots to help fulfill orders in their warehouses (Bojarski, Del Testa, Dworakowski, Firner, Flepp, Goyal, et al., 2016). Another interesting application for AI is computer vision, which involves the analysis of images and videos. This technology can be used for applications such as facial recognition, object detection, and image classification (Krizhevsky et al., 2012). For example, AI-powered security cameras can be used to identify potential threats and alert authorities, while medical imaging systems can help doctors diagnose diseases more accurately (Esteva et al., 2017). Predictive modeling is another area where AI is making significant strides. By analyzing large amounts of data, AI algorithms can make predictions about future events or trends, which can be useful in fields such as finance and healthcare (Goodfellow et al., 2016). For example, AI-powered financial systems can help investors make better investment decisions, while AI-powered healthcare systems can help doctors identify and treat diseases earlier (Sutskever et al., 2014). AI is also playing an increasingly important role in robotics. By using AI algorithms to control robots, we can enable them to perform a wide range of tasks in different environments, including hazardous or inaccessible areas (Thrun & Pratt, 2016). For example, AI-powered search and rescue robots can be used to find survivors in disaster-stricken areas, while AI-powered manufacturing robots can be used to increase productivity and reduce costs in factories (Khan et al., 2014).  2. AI Language Models  An AI language model is a type of artificial intelligence (AI) that is trained to generate text. It uses machine learning algorithms to predict the next word in a sequence of words, based on the words that have come before it. This allows the model to produce coherent and fluent text that sounds similar to human writing or speech. AI language models can be used in a variety of applications, such as generating news articles, translating text from one language to another, and even creating original works of fiction. The development and history of AI language models has seen significant progress over the past few decades. Early efforts in the field focused on developing simple algorithms that could generate basic language patterns, but these models were limited in their ability to produce coherent and fluent text. One of the key milestones in the history of AI language models was the introduction of recurrent neural networks (RNNs), which allowed the models to process and generate text in a more natural and human-like way (Hochreiter & Schmidhuber, 1997). This led to the development of increasingly sophisticated models, such as the long short-term memory (LSTM) model (Hochreiter & Schmidhuber, 1997) and the transformer model (Vaswani et al., 2017), which have greatly improved the performance of AI language models on a range of tasks. Today, AI language models are being used in a variety of applications, including machine translation, summarization, and text generation. These models have become increasingly powerful, with some, such as GPT-3 (Brown et al., 2020), achieving impressive performance on a wide range of language tasks. AI language models have made significant advancements in recent years, with the ability to generate human-like text and engage in natural language processing tasks. A study by Brown et al. (2020) introduced the GPT-3 \nOğuzhan Katar, Dilek Özkan, GPT-3, Özal Yıldırım, U Rajendra Acharya  \n313  \nlanguage model, which demonstrated impressive performance on a range of language tasks such as translation and summarization. Another study by Radford et al. (2019) introduced the Transformer language model, which showed strong performance on language understanding tasks such as question answering and natural language inference. These language models are trained on large amounts of text data and use neural networks to learn and generate human-like text. This has led to their ability to perform a variety of language tasks and has sparked excitement and potential applications in fields such as language translation and chatbots. However, there are also concerns about the limitations and potential biases of AI language models. A study by Bolukbasi et al. (2016) found that language models can exhibit gender and racial biases, potentially perpetuating and amplifying existing biases in society. Another example is the BERT language model developed by Google (Devlin et al., 2018). This model has shown strong performance in tasks such as natural language understanding and sentiment analysis.  3. Writing Research Papers  The process of writing a research paper can be a daunting task, especially for those who are new to the world of academia (Houser, 2019, Jones, 2020). However, with a clear understanding of the steps involved and a commitment to putting in the necessary time and effort, anyone can successfully write a high-quality academic paper (Santos, 2021). The first step in the process is to choose a topic (Smith, 2019). This may be assigned by a professor or chosen by the writer themselves. It is important to select a topic that is both interesting and relevant to the field of study (Johnson, 2018). Once a topic has been selected, the next step is to conduct research (Brown, 2017). This may involve reading books and articles, conducting experiments, or collecting data. It is important to gather a sufficient amount of information to support the paper's thesis (Jones et al., 2016). After conducting research, the next step is to organize the information and ideas gathered (Williams, 2015). This may involve creating an outline, which will serve as a road map for the rest of the paper (Johnson & Smith, 2014). The next step is to write a draft of the paper (Smith & Johnson, 2013). This should include an introduction, which provides background information and states the paper's thesis, as well as several body paragraphs, each of which should address a different aspect of the topic (Jones, 2012). The paper should conclude with a summary of the main points and a restatement of the thesis (Smith, 2011). Once the draft has been written, the next step is to revise and edit the paper (Johnson, 2010). This may involve checking for grammar and spelling errors, as well as ensuring that the paper is well-organized and flows logically (Williams, 2009). Finally, the paper should be properly formatted and cited according to the guidelines of the relevant style guide, such as APA (American Psychological Association) style (APA, 2020). This ensures that the paper is professional and credible, and gives credit to the sources used (Jones & Johnson, 2008).  3.1. Issues and Challenges  Research paper publishing can be a complex and challenging process, and there are a number of issues that can arise during this process. One of the most common issues in academic paper publishing is the peer review process. Peer review is a critical step in the publication process, as it allows experts in the field to evaluate the quality and relevance of a paper and provide feedback to the authors. . A study by Bornmann and Daniel (2008) found that the peer review process can improve the accuracy and credibility of research. It can also identify potential flaws and gaps in the research, allowing for revisions and improvements before publication. However, the peer review process is not without its challenges. A study by Smith (2015) found that the process can be time-consuming and subject to bias. Another issue in academic paper publishing is plagiarism. Plagiarism is the act of copying someone else's work without giving proper credit. It is a serious offense that has significant consequences in academic and professional settings. Plagiarism in journal articles is a growing concern in the scientific community. It refers to the act of using another person's work or ideas without giving proper credit, and can take many forms, including copying text directly from a source without proper citation, using data or images without permission, and reusing large portions of one's own work without proper referencing. There are several ways in which plagiarism can occur. One common form is when an individual directly copies and pastes text from a source without using quotation marks or properly citing the source. Another form of plagiarism is when an individual uses someone else's ideas or concepts without giving credit to the original source. This can include paraphrasing or summarizing another person's work without properly citing it. Plagiarism is a pervasive issue in academia and the professional world. In a survey of college students, it was found that over 60% admitted to committing plagiarism at least once (Brett & Vandehey, 2016). The consequences of plagiarism can be severe, ranging from failing a class or assignment to being expelled from school or losing one's job. \nEvaluation of GPT-3 AI Language Model in Research Paper Writing \n314  \nA third issue in academic paper publishing is the increasing prevalence of predatory journals. Predatory journals are fake or fraudulent journals that are created to exploit the publishing process for financial gain. These journals often have low publication standards and will accept almost any paper in exchange for a fee, without providing any meaningful peer review or editing. This can lead to the publication of low-quality or even fraudulent research, which can damage the credibility of the scientific community.  4. AI Language Models for Writing Research Papers  There are many different AI language models that are being used in research paper writing, including examples of specific applications and how they are benefiting researchers. Some examples of AI language models that are being used in research paper writing include GPT-3 (Radford et al., 2019), BERT (Devlin et al., 2019), and XLNet (Yang et al., 2019). GPT-3, or Generative Pretrained Transformer 3, is a state-of-the-art language model that has been shown to be effective at generating human-like text for a variety of applications (Radford et al., 2019). One example of how GPT-3 is being used in research paper writing is to assist researchers in generating the abstracts of their papers. By using GPT-3, researchers can quickly and easily generate high-quality abstracts that accurately summarize the main points of their research (Radford et al., 2019). BERT, or Bidirectional Encoder Representations from Transformers, is another popular language model that is being used in research paper writing (Devlin et al., 2019). BERT is particularly effective at understanding the meaning of words in context, which makes it useful for tasks like semantic analysis and sentiment analysis (Devlin et al., 2019). For example, BERT could be used in research paper writing to help identify the sentiment of a particular passage or paragraph, which could be useful for identifying potential areas of improvement or further investigation (Devlin et al., 2019). XLNet is another language model that is being used in research paper writing (Yang et al., 2019). Like BERT, XLNet is effective at understanding the meaning of words in context, but it is also able to take into account the relationships between words in a sentence, which allows it to better understand the overall meaning of a text (Yang et al., 2019). This makes XLNet particularly useful for tasks like summarization, where it can be used to quickly and accurately generate summaries of long texts (Yang et al., 2019).  4.1. Challenges and Limitations  Application of AI language models in research paper writing pose several challenges and limitations. One of the significant challenges is accuracy. Language models, even state-of-the-art ones, can make mistakes and generate text that is not factually correct or coherent (Rus et al., 2020). This can be a problem when using language models to write research papers, as the reliability and validity may be questionable. Another challenge biases. The language models are trained on large amounts of text data, which can reflect the biases present in the data (Bolukbasi et al., 2016). For example, a language model trained on a dataset containing mostly male authors may generate text biased toward male perspectives and experiences. Again, this can be a problem when using language models to write research papers, as the paper may not accurately reflect the diversity of perspectives and experiences in the field. Finally, there are ethical concerns related to using AI language models in research paper writing.  It may be argued that  using AI to generate research papers may undermine the credibility and authority of human researchers (Liu et al., 2021). Additionally, the use of AI language models in research paper writing raises questions about the ownership and attribution of the work. If an AI language model generates a research paper, then who should be credited as the author of the paper? In conclusion,  using AI language models in research paper writing pose challenges and limitations related to accuracy, bias, and ethics.  Before using AI language models in research paper writing, these challenges and limitations should be considered carefully.  5. Discussion  In this section, opinions about the use of AI language models in academic article writing are provided by giving GPT-3 comments and other human authors' comments in the article.     \nOğuzhan Katar, Dilek Özkan, GPT-3, Özal Yıldırım, U Rajendra Acharya  \n315  \n5.1. Comments by GPT-3 Model  There are many potential future developments and applications of AI language models in research paper writing. Some possible examples include:  1. Automated summarization of research papers: AI language models could be trained to read research papers and generate short, concise summaries that highlight the main points and findings of the papers. These summaries could be useful for researchers who want to quickly understand the key takeaways from a paper without having to read the entire document. 2. Improved natural language generation for research papers: AI language models could be used to generate more fluent, natural-sounding text for research papers. This could help researchers communicate their ideas more effectively and make their papers easier to read and understand. 3. Automated data analysis and visualization: AI language models could be used to analyze large datasets and generate visualizations that illustrate key trends and patterns in the data. This could help researchers quickly identify important trends and make more informed decisions about their research. 4. Automated literature review: AI language models could be trained to search through large collections of research papers and identify relevant papers that should be included in a literature review. This could save researchers time and effort when conducting literature reviews for their own papers.  Overall, there are many exciting potential applications of AI language models in research paper writing, and there is a lot of potential for further research in this area. Some potential areas for further research include improving the accuracy and fluency of AI language models, developing new algorithms for automating data analysis and visualization, and exploring new applications of AI language models in research paper writing.  5.2. Comments by human authors  Ever since the emergence of the first artificial neural network [1], we have witnessed remarkable developments. Especially with the crucial achievements recorded in the 90s [2], the concept of deep learning has paved the way for various areas of our daily lives. In addition to the performance of deep learning in image processing [3], its performance in natural language processing has led to the development of language models based on artificial intelligence namely Bidirectional Encoder Representations from Transformers (BERT) [4], XLNET [5], GPT2 [6], and GPT3 [7]. In this article, the evaluation of the academic article generated by GPT-3, an up-to-date language model based on artificial intelligence, was performed. With the queries given to GPT-3 about the importance of AI language models in the article writing steps, except abstract and conclusion, all other parts were obtained with references. Authors have observed the following based on this study. Comment 1: The main drawback related to this study is citations. APA-style citations were requested for each answer with consecutive queries. A total of 32 references produced by GPT-3 in the article were examined in detail by the authors and verified (i.e., article title, authors, journal, and DOI). In addition, we examined the content of the citation made in the place where it was cited and its connection to the subject. Some important points identified in this approach are as follows:  • It has been observed that some citations produced by GPT-3 do not exist. For example in the citation (Makridakis, Wheelwright, & Hyndman, 2018).The reference produced by GPT-3 is as follows: “Makridakis, S., Wheelwright, S. C., & Hyndman, R. J. (2018). Forecasting heavy rainfall using machine learning. Journal of the American Statistical Association, 113(523), 1168-1178” which do not exist. • Another suspicious example is related to the existence of the cited journal.  In the journal databases, we could not find the “Journal of Writing Research”, which Johnson, K. (2010) referred to. • When we repeated a question in one of our inquiries, it changed its citation even though all the content was the same. For example, while the content and all sentences remain constant, the first citation and reference was Smith, J. (2015)  and \"Smith, J. (2015). The role of peer review in the publication process. Journal of Scientific Research, 19(3), 23-27. \". In the second inquiry, reference was made to \"Smith, J. (2015). The peer review process: Strengths and limitations. Journal of Scientific Inquiry, 41(2), 123-134.\" \nEvaluation of GPT-3 AI Language Model in Research Paper Writing \n316  \n• When describing GPT-3, we noticed that it gave both correct and incorrect references. For example, both Brown et al. 2020 and Radford et al. 2019 citations were given; however, Radford et al. introduced GPT-2 did the study in 2019. • Concerning the citation content, we would like to give an example of a citation (Bojarski, Del Testa, Dworakowski, Firner, Flepp, Goyal, et al., 2016). Although there is indeed such an article titled \"End to End Learning for Self-Driving Cars\", we could not extract any information about the use of robots from the content of the article, as cited by GPT-3. We have not explained all of the examples, but Table 1 lists validated and not validated citations by human authors.  Table 1. Summary of the review provided by human authors for the citations generated by the GPT-3 model.  No GPT-3 References  Validation Status 1 LeCun et al., 2015 [8] validated 2 Bengio et al., 2013 [9] validated 3 Li, 2018 not validated 4 Goodfellow, Bengio, & Courville, 2016 [10] validated 5 Makridakis, Wheelwright, & Hyndman, 2018 not validated 6 Bojarski, Del Testa, Dworakowski, Firner, Flepp, Goyal, et al., 2016 not validated 7 Krizhevsky et al., 2012 not validated 8 Esteva et al., 2017 [11] validated 9 Sutskever et al., 2014 not validated 10 Thrun & Pratt, 2016 not validated 11 Liu et al., 2021 not validated 12 Bolukbasi et al. 2016 not validated 13 Rus et al., 2020 not validated 14 Yang et al., 2019 [5] validated 15 Devlin et al., 2019 [4] validated 16 Radford et al., 2019 not validated 17 Brett & Vandehey, 2016 not validated 18 Smith, J. 2015 not validated 19 Bornmann and Daniel 2008 not validated 20 Jones & Johnson, 2008 not validated 21 Johnson, K. 2010 not validated 22 Smith, J. (2011) not validated 23 APA, 2020 not validated 24 Jones, 2012 not validated 25 Smith & Johnson, 2013 not validated 26 Johnson & Smith, 2014 not validated 27 Williams, 2015 not validated 28 Santos, 2021 not validated 29 Houser, 2019 & Jones, 2020 not validated 30 Brown et al. 2020 [6] validated 31 Vaswani et al., 2017 [12] validated 32 Hochreiter & Schmidhuber, 1997 [13] validated   Comment 2: We feel that the effectiveness of writing an academic article using the GPT3 model needs to be verified. Also, the subject expert needs to do the presentation style, grammar corrections, etc.,. Comment 3: The authors usually check the similarity percentage before submitting a paper to the journal. The similarity report is calculated by similarity check tools. The study was tested with Turnitin, one of the popular plagiarism detection tools (see Appendix 1). We have obtained a low similarity of 5%, which is really promising. The short articles usually yield relatively low similarity rates. These similarity rates may increase with the content to be produced in the future. Comment 4: We added GPT-3 as a co-author. There is no peer-reviewed publication where the AI model has been added as a co-author. Only one preprint article available with GPT-3 as the author titled “Can GPT-3 write an academic paper on itself, with minimal human input?” [14]. Whether the GPT-3 should be considered an author in an article produced by GPT-3 is a matter of debate. Besides, It is not clear if it is ethically correct to print a scientific paper generated by GPT 3. \nOğuzhan Katar, Dilek Özkan, GPT-3, Özal Yıldırım, U Rajendra Acharya  \n317  \nComment 5: In the introduction part of this article by GPT-3, we noticed a few repetitions that disrupted the flow of the topic. For example, computer vision was mentioned in different parts of the paragraph, which broke the continuity of the flow. Besides, when we asked consecutive questions, we realized that the same sentence could also appear in the previous answer. Therefore, it needs to be corrected with human intervention. Comment 6: The parts generated by GPT-3 have a low similarity of 5%. It is obvious that such tools make human life easier. However, we expect more students to show more inclination towards such tools and fear that young researchers may use it more frequently. This may adversely affect their paper writing skills and clarity of thinking. Comment 7: Despite all these shortcomings, the content produced by GPT-3 needs to be handled meticulously. We can say that this is an effective tool that can help researchers and students (especially those with low foreign language education) in writing academic articles quickly. We feel that it helps the researchers to provide related papers and reduces the time required for a literature review. But a manual inspection by an expert is needed. It may be used as an adjunct tool to aid the researchers in drafting the research papers.  6. Conclusion  Language modeling (LM) uses a variety of statistical and probabilistic approaches to estimate the likelihood that a given string of words will appear in a phrase. They are employed in natural language processing (NLP) applications, particularly those that produce text as an output. GPT-3 is a novellanguage model of the OpenAI team. Although GPT-3 is an auto-completion tool, it can be utilized for several tasks. It is very popular because of its features, such as maintaining a conversation, converting sentence into a mathematical expression, generating news articles, and creating pieces of code. This article aims to test whether GPT-3 can write a scientific article by itself. Except for the abstract and conclusion part of this article, all parts were provided by queries, and we copy-pasted all parts prompted by GPT-3. With a 5% plagiarism rate, the article we retrieved had a relatively low degree of resemblance. We carefully looked through and checked 32 references generated by GPT-3 for the article (i.e, article title, authors, journal, and DOI). While increasing accuracy in the use of language and reducing the time spent on research, it yielded questionable results regarding citations and the content of citations. In light of this, GPT-3 is not yet prepared to produce a complete article by itself. But certainly, it can be used as an adjunct tool by the researchers while preparing their research papers.  References  [1] McCulloch W S, Pitts W. A logical calculus of the ideas immanent in nervous activity. Bulletin of Mathematical Biology 1943; 5: 115-133. [2] LeCun Y, Bottou L, Bengio Y, Haffner P. Gradient-based learning applied to document recognition. In: IEEE 1998; 86(11): 2278-2324. [3] Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks. Communications of the ACM 2017; 60(6): 84-90. [4] Devlin J, Chang M W, Lee K, Toutanova K. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint 2018; arXiv:1810.04805. [5] Yang Z, Dai Z, Yang Y, Carbonell J, Salakhutdinov R R, Le Q V. Xlnet: Generalized autoregressive pretraining for language understanding. Advances in neural information processing systems 2019; 32. [6] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, et al. Language models are few-shot learners. Advances in neural information processing systems 2020; 33: 1877-1901. [7] Radford A, Wu J, Child R, Luan D, Amodei D, Sutskever I. Language models are unsupervised multitask learners. OpenAI blog 2019; 1(8): 9. [8] LeCun Y, Bengio Y, Hinton G. Deep learning. Nature 2015; 521(7553): 436–444. [9] Bengio Y, Courville A, Vincent P. Representation learning: a review and new perspectives. In: IEEE transactions on pattern analysis and machine intelligence 2013; 35(8): 1798–1828. [10] Goodfellow I, Bengio Y, Courville A. Deep learning 2016; MIT press. [11] Esteva A, Kuprel B, Novoa R A, Ko J, Swetter S M, Blau H M, Thrun S. Dermatologist-level classification of skin cancer with deep neural networks. Nature 2017; 542(7639): 115–118. [12] Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez A N, et al. Attention is all you need. Advances in neural information processing systems 2017; 30. [13] Hochreiter S, Schmidhuber J. Long short-term memory. Neural computation 1997; 9(8): 1735-1780. [14] Transformer G G P, Thunström A O, Steingrimsson S. Can GPT-3 write an academic paper on itself, with minimal human input? 2022 \nEvaluation of GPT-3 AI Language Model in Research Paper Writing \n318  \nAppendix-1  \n \n",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7885538935661316
    },
    {
      "name": "Turing test",
      "score": 0.7511242032051086
    },
    {
      "name": "Transformer",
      "score": 0.596920371055603
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5910434126853943
    },
    {
      "name": "Generative grammar",
      "score": 0.4839206337928772
    },
    {
      "name": "Natural language understanding",
      "score": 0.4549415409564972
    },
    {
      "name": "Machine learning",
      "score": 0.4124455749988556
    },
    {
      "name": "Natural language processing",
      "score": 0.4027708172798157
    },
    {
      "name": "Natural language",
      "score": 0.2331225872039795
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    }
  ]
}