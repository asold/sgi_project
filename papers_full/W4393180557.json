{
  "title": "Prompt Optimization Methods for Large Language Models with Long Text Input",
  "url": "https://openalex.org/W4393180557",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A1974685580",
      "name": "Yi Ren",
      "affiliations": [
        "Chinese Academy of Sciences",
        "Institute of Software"
      ]
    },
    {
      "id": "https://openalex.org/A2149478250",
      "name": "Shoubin Li",
      "affiliations": [
        "Chinese Academy of Sciences",
        "Institute of Software"
      ]
    },
    {
      "id": "https://openalex.org/A1974685580",
      "name": "Yi Ren",
      "affiliations": [
        "Chinese Academy of Sciences",
        "Institute of Software"
      ]
    },
    {
      "id": "https://openalex.org/A2149478250",
      "name": "Shoubin Li",
      "affiliations": [
        "Institute of Software",
        "Chinese Academy of Sciences"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6739901393",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W2626804490",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W3185300501",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4286987939",
    "https://openalex.org/W4321392130",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4226399820",
    "https://openalex.org/W4226058124"
  ],
  "abstract": "When faced with long text input, the generated results from large language models sometimes fail to meet user expectations. Due to the length and complexity of the input content, users often do not know how to modify the input to obtain the desired results. To address this dilemma, we propose a Prompt optimization method for large language models with long text input. This method determines the influence weights of different semantic segments on the results, providing guidance for users to generate desired text using large language models. Experimental results show that by evaluating the importance of different semantic segments in military question-answering system text and improving the input content, the quality and usability of the generated military question-answering text can be enhanced.",
  "full_text": "Prompt Optimization Methods for Large Language\nModels with Long Text Input\nYi Ren 1 and Shoubin Li 1\n1The Institute of Software, Chinese Academy of Sciences\nrenyi@iscas.ac.cn\nAbstract—When faced with long text input, the generated\nresults from large language models sometimes fail to meet user\nexpectations. Due to the length and complexity of the input\ncontent, users often do not know how to modify the input to\nobtain the desired results. To address this dilemma, we propose\na Prompt optimization method for large language models with\nlong text input. This method determines the influence weights of\ndifferent semantic segments on the results, providing guidance\nfor users to generate desired text using large language models.\nExperimental results show that by evaluating the importance\nof different semantic segments in military question-answering\nsystem text and improving the input content, the quality and\nusability of the generated military question-answering text can\nbe enhanced.\nIndex Terms—Long text input, Large language model, Prompt,\nQuestion-answering system\nI. I NTRODUCTION\nLarge language models, as a product of the combination of\n”big data + high computing power + strong algorithms,” are a\ncollection of implicit knowledge extracted from massive train-\ning data. In particular, large language models represented by\nChatGPT have demonstrated outstanding performance in the\nfield of text generation. However, when using large language\nmodels for text generation, especially when the user input\ninformation is lengthy, if the content generated by the large\nlanguage model does not meet the user’s expectations, users\nusually attempt to modify the input to guide the large language\nmodel to generate content that aligns with their expectations.\nNevertheless, due to the length of the input text, users find\nit challenging to grasp the key points when modifying the\ninput. Even after multiple adjustments, the desired output\nresults may still not be obtained which is shown in Figure\n11. To solve this problem, this paper proposes a Prompt\noptimization method for large language models with long\ntext input. This method determines the influence weights of\ndifferent semantic segments on the results, providing guidance\nfor users to generate desired text using large language models.\nOn this basis, this paper applies the method to the generation\nof military forum question-answering system text to verify its\neffectiveness.\nMilitary forum question-answering systems serve as an\nimportant entry point for military enthusiasts to quickly learn\nabout past battles and weapons and equipment, playing a cru-\ncial role in military education. They assist relevant personnel\nin understanding and analyzing past battles and equipment,\nenabling them to quickly and accurately acquire relevant\nknowledge and experience. This paper combines the Prompt\noptimization method for large language models with long text\ninput and the generation of military content, aiming to explore\nthe impact of different input semantic segments on the gener-\nation of military content text, assisting military enthusiasts in\nutilizing large language models to obtain military information\nquickly and accurately.\nII. R ELATED CONCEPTS OF MILITARY\nQUESTION -ANSWERING SYSTEMS\nQuestion-answering systems for military forums are becom-\ning increasingly complex and intelligent. Wang Xiaoming and\nLi Xiaohong [1] studied the key technologies involved, such as\nmulti-round dialogue for mining users’ deep information needs\nand semantic matching for precise interaction with knowledge\ngraphs. The construction of knowledge graphs is also gaining\nattention, with Liu Xiaoming [2] exploring methods suitable\nfor building military domain knowledge graphs. Meanwhile,\nin the context of big data, traditional matching methods face\nchallenges, and Michael Gray [3] proposed deep semantic\nmatching techniques for better knowledge association. It is\nevident that research on military forum question-answering\nsystems has begun to take shape, and key technologies are\ncontinuously developing. In the future, it will be necessary to\nbuild even larger knowledge graphs, achieve dynamic knowl-\nedge updates, and enable multi-round dialogue mechanisms to\nreflect personalized user interest models, making the question-\nanswering services more intelligent.\nIII. C OMPOSITION OF MILITARY QUESTION -ANSWERING\nSYSTEMS\nMilitary question-answering systems are complex and pre-\ncise frameworks designed to accurately parse user queries\nand provide comprehensive answers. The system first uses a\nquestion parsing module to understand the user’s query intent\nand key points, identifying the question type and extracting\nkey entities. The subsequent content encoding module is\nresponsible for constructing and continuously enriching the\nmilitary domain knowledge graph and providing necessary\nknowledge support by computing entity embedding vectors.\nThis process ensures the system’s deep understanding of the\nmilitary domain and accurate encoding of information.\nThe matching and retrieval module employs decision tree-\nbased algorithms to achieve deep semantic matching with the\nknowledge graph, effectively retrieving and linking to the most\nCopyright: © 2024 The Author(s); CC BY-NC 4.0. © 2024 IJETAA. All rights reserved.\nV olume1, Issue2 International Journal of Emerging Technologies and Advanced Applications Feb,2024\nFig. 1. How to make efficient changes to long text input\nrelevant information, ensuring that the answers provided to\nusers are highly relevant to their queries. Once the necessary\ninformation is retrieved, the reply generation module begins\nits work, organizing the reply framework and utilizing a rich\ncorpus for training to generate complete and accurate answers.\nTo provide more personalized services, the user interest\nmodeling module analyzes users’ historical topic interest\npreferences, enabling personalized information provision. Fur-\nthermore, the knowledge adjustment module relies on user\nfeedback to promptly update and adjust the knowledge graph,\nensuring the timeliness and accuracy of the system’s content.\nThe smooth operation of this entire process ensures that the\nmilitary question-answering system can effectively meet users’\nqueries for military information and provide high-quality per-\nsonalized services.\nIV. R ELATED WORK\nA. Large Language Models\nIn 2018, OpenAI proposed the GPT (Generative Pre-\nTraining Transformer) model [4], which uses the Decoder part\nof the Transformer [5] architecture with certain modifications\nmade to the original Decoder. However, due to the difficulty\nof the generative direction, its performance was not as good\nas the BERT model [6] proposed by the Google team in the\nsame year. Subsequently, the OpenAI team proposed GPT2\n[7], which expanded the model parameters from 117 million to\n1.5 billion and the training data from 5GB to 40GB compared\nto GPT. The larger model brought better results, and OpenAI\nshifted its focus to zero-shot learning. GPT2 demonstrated\nexcellent performance in zero-shot learning, but still had gaps\ncompared to traditional models. In GPT3, OpenAI changed\nzero-shot learning to few-shot learning [8]. GPT3’s parameter\nscale is over a hundred times that of GPT2, reaching an\nastonishing 175 billion, while the training data expanded a\nthousandfold to 45TB. From a performance perspective, GPT3\ncan generate news articles that are difficult for humans to\ndistinguish as being generated by a model. However, from\nthe perspective of safety and other aspects, GPT3 still has\nnumerous issues: GPT3 cannot guarantee the correctness of\nits output and may generate negative or even harmful infor-\nmation. In 2022, OpenAI combined RLHF (Reinforcement\nLearning from Human Feedback) [9] with GPT3 and proposed\nInstructGPT [10]. RLHF technology can help models better\nunderstand human instructions and ensure that the generated\ncontent is useful and harmless.\nB. Prompt Tuning\nWhen fine-tuning for downstream tasks, there may be cases\nwhere the gap between the downstream task objective and the\npre-training objective is too large, resulting in insignificant\ntraining effects. To address this, GPT3 proposed a fine-tuning\nparadigm called Prompt-Tuning [8].\nSo far, three Prompt techniques have been proposed and\nproven to have good effects: In-Context Learning (ICL),\nInstruction Fine-tuning (IFT), and Chain-of-Thought (CoT).\nIn May 2020, OpenAI first introduced the concept of In-\nContext Learning in GPT3, which selects a small number of\nlabeled samples from the training set and designs task-relevant\ninstruction templates to guide the generation of corresponding\nresults for test samples. However, this method suffers from\nhigh variance and instability. In October 2021, Google released\nFLAN [11] and proposed Instruction Fine-tuning. The data\nfor IFT is typically a collection of human-written instructions\nand instruction instances guided by language models. These\ninstruction data consist of three main components: instruction,\ninput, and output. For a given instruction, there can be multiple\ninput and output instances. To enhance the ability of large\nmodels to solve mathematical reasoning problems, in 2022,\nGoogle released LAMDA (137B) [12] and introduced the\nChain-of-Thought mechanism. By providing the model with\nreasoning step prompts, the model learns to think and reason\nstep by step like humans, enabling it to possess basic reasoning\ncapabilities and ultimately solve simple or even relatively\ncomplex mathematical problems.\nC. Generating Military Question-Answering Systems Using\nKnowledge Graphs\nCurrently, most information generation methods applied in\nmilitary question-answering systems use intelligent algorithms\nto realize the mapping from concept models to simulation\nscenarios. For example, knowledge graph techniques [13] are\nused to complete the generation of simulation scenarios; by\nrepresenting concepts of weapons and equipment and combat\nactions in the combat domain, a domain knowledge base is\nhttps://ijetaa.com/article/view/109/ - 2 - ISSN : 3006− 2985\nV olume1, Issue2 International Journal of Emerging Technologies and Advanced Applications Feb,2024\nFig. 2. Flowchart of experimental method\nestablished, and military question-answering text is generated\nusing intelligent mapping algorithms and semantic reasoning\nmethods based on semantic similarity and field similarity\n[14]; XMLSchema is used to compose the elements of mili-\ntary question-answering deduction models, Backus-Naur Form\ngrammar is used to establish formatted description templates\nfor each component element, and military question-answering\ntext is generated through mapping [15], or programs are used\nto load electronic nautical charts and military symbol libraries\nto describe the battlefield situation and combat tasks on a two-\ndimensional plane, further generating military information text\n[16].\nV. P ROMPT OPTIMIZATION METHOD\nThis paper designs a Prompt optimization method for large\nlanguage models with long text input. By detecting the influ-\nence weights of each semantic segment in the input long text\non the output of the large model, it guides users to precisely\nmodify the input content to obtain the desired output. The\nflowchart of this method is shown in Figure 2.\nA. Semantic Segmentation of Long Text\nIn this method, the collected text data needs to be prepro-\ncessed first to remove parts of the text data that do not meet\nthe input requirements.\nThe preprocessed text data is input into the Seqmodel\n[17] for semantic segmentation. Seqmodel is a semantic\nsegmentation model based on the BERT architecture that\ncan effectively utilize contextual information for precise text\nsegmentation. Compared with traditional methods, Seqmodel\ncan simultaneously process more sentences and model longer\nFig. 3. Seqmodel Model Architecture [17]\ncontext and dependencies between sentences through the self-\nattention mechanism. The architecture of the Seqmodel is\nshown in Figure 3.\nB. Semantic Segment Influence Weight Algorithm\nThe long text after semantic segmentation is input into\nthe large language model to obtain the output results. Then,\nthrough manual evaluation, the influence weights of different\nhttps://ijetaa.com/article/view/109/ - 3 - ISSN : 3006− 2985\nV olume1, Issue2 International Journal of Emerging Technologies and Advanced Applications Feb,2024\nsemantic segments on the output are calculated to help users\nmore efficiently modify the input to obtain the desired output.\nSpecifically, this paper uses a weight calculation method\nbased on keyword hits. The calculation method is as follows:\nFor the i-th semantic segment of the long text input, in\nkeywords appearing in it are manually selected, and each\noccurrence of these keywords in the output is recorded as\na hit. Define the total number of hits of the keywords in\nthe i-th input semantic segment in the output text as Shoti.\nIn a long text input composed of n semantic segments, the\noutput influence weight of the i-th input semantic segment is\nShotiPi=1nShoti\n. By sorting the obtained influence weights, the\ninput semantic segments with the greatest influence on the\noutput can be determined.\nVI. E XPERIMENT\nUsing the battle mentioned in the composition of the mil-\nitary question-answering system in Chapter 2 as an example,\nit involves parts such as the combat background, objectives,\nforce composition, combat preparations, basic tactics of each\nparty, combat plans, combat actions, etc. The content involved\nin these components overlaps. To clarify the format of the\nmilitary information text in the experiment, this paper defines\nits format before using the large language model to generate\nthe military information text. This paper summarizes the above\nparts into the following six parts: combat background, force\ndeployment, combat objectives, combat plan, combat process,\nand combat results. The summarized mapping relationship is\nshown in Figure 4.\nA. Experimental Data and Preprocessing\nIn terms of experimental data, this paper obtained 30 battle-\nrelated texts from forums. Since the combat plan, combat\nprocess, and combat results are the generated content of the\nlarge language model and cannot be used as input, these\ncontents are removed during the preprocessing stage.\nB. Experimental Process\nThe preprocessed text data is input into the Seqmodel for\nsemantic segmentation.\nThe segmented text by Seqmodel is input into the large\nlanguage model to obtain the output results of the large\nlanguage model.\nFinally, the influence weights of different input semantic\nsegments on the generation of battle text are calculated ac-\ncording to the output influence weight algorithm defined in\nthis paper.\nC. Algorithm Effectiveness Verification\nThis paper verifies the effectiveness of the proposed algo-\nrithm by modifying the input semantic segments with higher\ninfluence weights. Specifically, new content is added to the\ninput semantic segments with larger weights, and the changes\nin the model-generated results are observed.\nIf the generated results of the large language model do not\ncontain content related to the added input information, it can-\nnot be determined whether the added information in the input\nsemantic segment is utilized by the large language model. This\npaper defines the modification of the input semantic segment\nin this case as an invalid modification.\nIf the generated results of the large language model only\ncontain content related to the added input information but do\nnot generate new content related to the battle but unrelated\nto the added information, this paper defines the modification\nof the input semantic segment in this case as a non-important\nmodification.\nIf the generated results of the model not only contain\ncontent related to the added input information but also generate\nnew content related to the battle but unrelated to the added\ninformation, this paper defines the modification of the input\nsemantic segment in this case as an important modification.\nIf the modifications made to the input semantic segments\nwith higher influence weights during the experiment are al-\nways important modifications, while the modifications made\nto the input semantic segments with lower influence weights\nare always non-important modifications or even invalid mod-\nifications, it can be considered that the algorithm proposed in\nthis paper is effective.\nVII. E XPERIMENTAL RESULTS\nThrough experiments on 30 battle texts, the experimental\nresults are obtained as shown in Table I.\nTABLE I\nEXPERIMENTAL RESULTS\nSemantic Segment Name Influence Weight\nCombat Objectives 47%\nForce Deployment 38%\nCombat Background 15%\nThe experimental results show that the two semantic seg-\nments of combat objectives and force deployment are relatively\nimportant for using large models to generate battle text.\nScenario designers can improve the quality of the generated\nbattle text by focusing on describing the combat objectives\nand force deployment parts.\nThis paper provides a comparison example of combat objec-\ntives. Figure 5 shows the generated results without a detailed\ndescription of the combat objectives semantic segment.\nOnly the combat objectives semantic segment is modified,\nwhile the other input semantic segments remain unchanged.\nThe generation effect is shown in Figure 6.\nThe generated results in Figure 6 not only contain content\nrelated to the added input information but also generate\nnew content related to the battle but unrelated to the added\ninformation, such as electronic warfare, which aligns with the\ndefinition of important modification in Chapter 5 of this paper.\nVIII. C ONCLUSION\nThis paper proposes a Prompt optimization method for large\nlanguage models with long text input, aiming to help users\nbetter utilize large models to generate desired text by detecting\nthe influence weights of different semantic segments in the\ninput on the output of the large model. At the same time,\nhttps://ijetaa.com/article/view/109/ - 4 - ISSN : 3006− 2985\nV olume1, Issue2 International Journal of Emerging Technologies and Advanced Applications Feb,2024\nFig. 4. Mapping maps for the definition of military ideograms\nhttps://ijetaa.com/article/view/109/ - 5 - ISSN : 3006− 2985\nV olume1, Issue2 International Journal of Emerging Technologies and Advanced Applications Feb,2024\nFig. 5. Military Identified Text Generation Results I\nhttps://ijetaa.com/article/view/109/ - 6 - ISSN : 3006− 2985\nV olume1, Issue2 International Journal of Emerging Technologies and Advanced Applications Feb,2024\nFig. 6. Military Intended Text Generation Results II\nhttps://ijetaa.com/article/view/109/ - 7 - ISSN : 3006− 2985\nV olume1, Issue2 International Journal of Emerging Technologies and Advanced Applications Feb,2024\nthis paper verifies the effectiveness of the method through\nexperiments on generating battle text.\nThe method proposed in this paper also has potential\napplication value in other fields besides battle text generation.\nBy determining the influence weights of different semantic\nsegments in the input, users can better understand the impor-\ntance of various parts of the input text, thereby improving\nthe effect of generated text. In future work, the semantic\nsegmentation method can be improved to achieve finer-grained\nsegmentation. Furthermore, more efficient algorithms can be\nproposed to calculate the influence weights of different seman-\ntic segments. In summary, this research provides new ideas\nand methods for the application of large language models in\nthe field of text generation and promotes further research and\ndevelopment in related fields.\nREFERENCES\n[1] Wang X.M. and Li X.L. Research on Key Technologies of Forum-\nOriented Question-Answering Systems. Computer Systems & Applica-\ntions, 2023, 32(2): 12-15.\n[2] Liu X.M. Exploration of Military Knowledge Graph Construction Meth-\nods. Journal of Intelligence, 2023, 35(1): 5-10.\n[3] Gray M. Deep Semantic Matching Technology in Big Data Environment.\nJournal of Software, 2023, 34(3): 405-412.\n[4] Radford A., Narasimhan K., Salimans T., et al. Improving language\nunderstanding by generative pre-training. 2018.\n[5] Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need. In\nAdvances in neural information processing systems 2017, 30.\n[6] Devlin J., Chang M.W., Lee K., et al. Bert: Pre-training of deep\nbidirectional transformers for language understanding. arXiv preprint\narXiv:1810.04805, 2018.\n[7] Radford A., Wu J., Child R., et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 2019, 1(8): 9.\n[8] Brown T., Mann B., Ryder N., et al. Language models are few-shot\nlearners. In Advances in neural information processing systems 2020,\n33: 1877-1901.\n[9] Christiano P.F., Leike J., Brown T., et al. Deep reinforcement learning\nfrom human preferences. In Advances in neural information processing\nsystems 2017, 30.\n[10] Ouyang L., Wu J., Jiang X., et al. Training language models to follow\ninstructions with human feedback. In Advances in Neural Information\nProcessing Systems 2022, 35: 27730-27744.\n[11] Wei J., Bosma M., Zhao V .Y ., et al. Finetuned language models are\nzero-shot learners. arXiv preprint arXiv:2109.01652, 2021.\n[12] Thoppilan R., De Freitas D., Hall J., et al. Lamda: Language models\nfor dialog applications. arXiv preprint arXiv:2201.08239, 2022.\n[13] Ge B., Tan Z., Zhang Y ., et al. Research on Military Knowledge Graph\nConstruction Technology. Journal of Command and Control, 2016, 2(4):\n302-308.\n[14] Tian X.Y ., Zeng G.X., Gao Y .B., et al. Research on Model Reuse\nTechnology Based on Semantic Matching and Combination. Journal of\nSystem Simulation, 2021, 33(12): 1-10.\n[15] Xiao B., Wu J.P. A Formalized Description Method for Simulation\nDeduction Scenarios and an Instantiation Method for Deduction Models.\nPatent: 202310281676, 2023-09-08.\n[16] Hou G.C. and Yang L. Research on Generation and Application Tech-\nnology of Simulation Deduction Scenarios for Naval Battles. Ship\nElectronic Engineering, 2019, 39(7): 4.\n[17] Zhang Q., Chen Q., Li Y ., et al. Sequence Model with Self-Adaptive\nSliding Window for Efficient Spoken Document Segmentation. In IEEE\nASRU 2021.\nhttps://ijetaa.com/article/view/109/ - 8 - ISSN : 3006− 2985",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.568555474281311
    },
    {
      "name": "Natural language processing",
      "score": 0.39855480194091797
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3223280906677246
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I19820366",
      "name": "Chinese Academy of Sciences",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210128818",
      "name": "Institute of Software",
      "country": "CN"
    }
  ]
}