{
  "title": "Enhanced pre-recruitment framework for clinical trial questionnaires through the integration of large language models and knowledge graphs",
  "url": "https://openalex.org/W4412686857",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A3114285660",
      "name": "Chen Zihang",
      "affiliations": [
        "Shanghai University of Engineering Science"
      ]
    },
    {
      "id": "https://openalex.org/A2041084816",
      "name": "Liu Liang",
      "affiliations": [
        "Zhongshan Hospital",
        "Fudan University"
      ]
    },
    {
      "id": "https://openalex.org/A2429615152",
      "name": "Su Qian-Min",
      "affiliations": [
        "Shanghai University of Engineering Science"
      ]
    },
    {
      "id": "https://openalex.org/A5093873852",
      "name": "Cheng Gaoyi",
      "affiliations": [
        "Shanghai University of Engineering Science"
      ]
    },
    {
      "id": "https://openalex.org/A2359060809",
      "name": "Huang Jihan",
      "affiliations": [
        "Shanghai University of Traditional Chinese Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A1909470079",
      "name": "Li Ying",
      "affiliations": [
        "Longhua Hospital Shanghai University of Traditional Chinese Medicine",
        "Shanghai University of Traditional Chinese Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A3114285660",
      "name": "Chen Zihang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2041084816",
      "name": "Liu Liang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2429615152",
      "name": "Su Qian-Min",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5093873852",
      "name": "Cheng Gaoyi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2359060809",
      "name": "Huang Jihan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1909470079",
      "name": "Li Ying",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4376955689",
    "https://openalex.org/W3028146832",
    "https://openalex.org/W4313545038",
    "https://openalex.org/W3093637141",
    "https://openalex.org/W4364360969",
    "https://openalex.org/W4375858605",
    "https://openalex.org/W3096919712",
    "https://openalex.org/W4380608846",
    "https://openalex.org/W3012312333",
    "https://openalex.org/W3120083395",
    "https://openalex.org/W4381092249",
    "https://openalex.org/W4377820139",
    "https://openalex.org/W6832433369",
    "https://openalex.org/W4394975332",
    "https://openalex.org/W2975956387",
    "https://openalex.org/W4308337697",
    "https://openalex.org/W3128360639",
    "https://openalex.org/W2583020087",
    "https://openalex.org/W4310480020",
    "https://openalex.org/W4377093271",
    "https://openalex.org/W4387744047",
    "https://openalex.org/W4388891053",
    "https://openalex.org/W4385682300",
    "https://openalex.org/W3093150592",
    "https://openalex.org/W2980507720",
    "https://openalex.org/W3010563230",
    "https://openalex.org/W4396999789",
    "https://openalex.org/W4389988161",
    "https://openalex.org/W4385215110",
    "https://openalex.org/W4386875608",
    "https://openalex.org/W4386726412",
    "https://openalex.org/W4386732074",
    "https://openalex.org/W4399439184",
    "https://openalex.org/W4396529913",
    "https://openalex.org/W4404486407",
    "https://openalex.org/W4361807050"
  ],
  "abstract": "The recruitment of participants for clinical trials has traditionally been a passive and challenging process, leading to difficulties in acquiring a sufficient number of qualified participants in a timely manner. This issue has impeded advancements in medical research. However, recent years have seen the evolution of knowledge graphs and the introduction of large language models (LLMs), providing innovative approaches for the pre-screening and recruitment phases of clinical trials. These developments promise enhanced recruitment efficiency and increased participant involvement. To ensure the safety and efficacy of clinical trials, it is crucial to establish precise inclusion and exclusion criteria for participant selection. This paper introduces a method to optimize the pre-recruitment stage by utilizing these criteria in conjunction with the cutting-edge capabilities of knowledge graphs and LLMs. The enhanced strategy includes the automated generation of questionnaires, algorithmic evaluation of eligibility, supplemental query-response functions, and a broader participant screening reach. The application of this framework yielded a detailed clinical trial recruitment questionnaire that accurately encompasses all necessary criteria. Its JSON output is noteworthy for its precision and reliability, achieving an impressive 90% accuracy rate in summarizing patient responses. Additionally, the questionnaire's ancillary question-and-answer feature complies with stringent legal and ethical standards, meeting the requirements for practical deployment. This study validates the practicality and technological soundness of the presented approach. Utilizing this framework is expected to enhance the efficiency of trial recruitment and the level of patient participation.",
  "full_text": "Enhanced pre-recruitment \nframework for clinical trial \nquestionnaires through the \nintegration of large language \nmodels and knowledge graphs\nChen Zihang1, Liu Liang2,5, Su Qianmin1, Cheng Gaoyi1, Huang Jihan3 & Li Ying4\nThe recruitment of participants for clinical trials has traditionally been a passive and challenging \nprocess, leading to difficulties in acquiring a sufficient number of qualified participants in a timely \nmanner. This issue has impeded advancements in medical research. However, recent years have \nseen the evolution of knowledge graphs and the introduction of large language models (LLMs), \nproviding innovative approaches for the pre-screening and recruitment phases of clinical trials. These \ndevelopments promise enhanced recruitment efficiency and increased participant involvement. To \nensure the safety and efficacy of clinical trials, it is crucial to establish precise inclusion and exclusion \ncriteria for participant selection. This paper introduces a method to optimize the pre-recruitment \nstage by utilizing these criteria in conjunction with the cutting-edge capabilities of knowledge graphs \nand LLMs. The enhanced strategy includes the automated generation of questionnaires, algorithmic \nevaluation of eligibility, supplemental query-response functions, and a broader participant screening \nreach. The application of this framework yielded a detailed clinical trial recruitment questionnaire \nthat accurately encompasses all necessary criteria. Its JSON output is noteworthy for its precision and \nreliability, achieving an impressive 90% accuracy rate in summarizing patient responses. Additionally, \nthe questionnaire’s ancillary question-and-answer feature complies with stringent legal and ethical \nstandards, meeting the requirements for practical deployment. This study validates the practicality \nand technological soundness of the presented approach. Utilizing this framework is expected to \nenhance the efficiency of trial recruitment and the level of patient participation.\nKeywords Large Language Model, Knowledge Graph, Questionnaire, Clinical Trial, Inclusion and Exclusion \nCriteria\nInclusion and exclusion criteria are essential to ensure the validity of clinical trials. These criteria specify the \neligibility of potential participants, distinguishing between appropriate and inappropriate candidates. Often, \nthe complexity of the eligibility criteria communicated in public recruitment materials can discourage patient \nparticipation due to a lack of understanding of the details of the trial. In addition, patient recruitment is based \non referrals from healthcare professionals and direct recruitment efforts. Busy healthcare providers may find it \nchallenging to devote extra time to recruitment activities 1,2. Patient recruitment presents a significant obstacle \nto clinical trial progress, with roughly 80% of trials facing enrollment deficits that undermine statistical power \nand increase financial costs3–5. Recent strategies have incorporated social media platforms to enhance traditional \nrecruitment methods, using their expansive reach and interactive nature to enlarge the pool of participants \nand improve sample diversity6,7. Nonetheless, current recruitment approaches for clinical trials remain rather \npassive, signaling a pressing need for innovative developments in the pre-recruitment phase to facilitate the \nseamless progression of clinical trials.8–11.\n1School of Electronic and Electrical Engineering, Shanghai University of Engineering Science, ShangHai, China. \n2Institute of Clinical Science, Zhongshan Hospital, Fudan University, ShangHai, China. 3Center for Drug Clinical \nResearch, Shanghai University of Traditional Chinese Medicine, ShangHai, China. 4Department of Hepatology \nLonghua Hospital, Shanghai University of Traditional Chinese Medicine, ShangHai, China. 5Liu Liang contributed \nequally to this work. email: suqm@sues.edu.cn\nOPEN\nScientific Reports |        (2025) 15:27398 1| https://doi.org/10.1038/s41598-025-11876-0\nwww.nature.com/scientificreports\n\nThe rapid advancement of large language model (LLM) technology has led researchers and healthcare \nprofessionals to explore its vast potential applications in clinical practice 12. Jimyung Park 13and his team \nintroduced the C2Q 3.0 system, which employs three GPT-4 prompts to extract concepts, generate SQL queries, \nand facilitate reasoning. The system’s reasoning prompts underwent extensive evaluations by three experts, who \nassessed them based on readability, accuracy, coherence, and usability. Hamer 14 et al. implemented a strategy \nthat combined one-shot prompts, selection reasoning, and thought-chaining techniques to evaluate LLM \nperformance across ten patient records, focusing on identifying eligibility criteria, judging patient compliance \nwith specific criteria, classifying overall patient suitability for clinical trials, and determining the necessity of \nfurther physician screening. Mauro Nievas 15 and his team used GPT-4 to create a dedicated synthetic dataset, \nenabling effective fine-tuning under constrained data settings. They released an annotated evaluation dataset \nand the fine-tuned clinical trial LLM-Trial-LLAMA for public utilization. Qiao Jin 16 et al. proposed TrialGPT, \nan innovative framework that utilizes LLMs for predicting patient eligibility levels and providing rationales, \nranking, and filtering clinical trials based on patient free-text notes. This framework was validated using three \npublic cohorts, which included 184 patients and 18,238 annotated clinical trials.\nIn terms of the effectiveness of prerecruitment questionnaires, several studies have demonstrated their \nvalue17,18. Weiss19 developed the COPD Screening Questionnaire (SCSQ), which identifies high-risk patients \nthrough a self-assessment tool and effectively pre-screens individuals who need pulmonary function tests, thus \nimproving the early detection rate of COPD. Melo 20 evaluated the usability and patient feedback of the STO \ntool in public dental university clinics and confirmed that the questionnaire is an important tool in dental pre-\nscreening. It helps optimize the dental pre-screening process, reducing travel and saving costs. Mark21 validated \nthe STOP-Bang questionnaire as a preoperative screening tool for obstructive sleep apnea (OSA), confirming its \nhigh sensitivity and discriminatory ability in effectively ruling out severe OSA. This paper primarily demonstrates \nthe feasibility of the framework from a technical perspective.\nIn the initial planning phase, we conducted field surveys and discovered that patient data in electronic \nhealth records (EHR) or hospital systems may have timeliness issues. Additionally, the level of detail in the \nrecords varies depending on the attending physician. This heterogeneity complicates the direct matching of data \nwith specific participation criteria. Furthermore, large language models are constrained by input length limits \nand may only process a finite subset of data, which introduces potential inaccuracies in the analysis, posing a \nchallenge for practical application22,23.\nTo address these issues, this paper proposes a solution to establish a one-to-one correspondence among \n“participation criteria-questionnaire-answers” . Knowledge graphs are used to aid large language models in \nconstraining the scope of knowledge, ensuring the accuracy of generated content24–26. With the aid of a knowledge \ngraph, an LLM constructs a questionnaire tailored to each recruitment criterion and subsequently evaluates \npatient eligibility based on the submitted responses. This integrated solution combines the capabilities of large \nlanguage models with knowledge graph technology to streamline processes, enabling automated questionnaire \ngeneration, automatic analysis and summarization of responses. This framework aims to implement automated \nand semi-automated methods to assist recruitment personnel in screening patients more quickly and effectively. \nBy accelerating the initiation of clinical trials and shortening recruitment cycles, the framework seeks to save \ntime and costs for research projects. In addition, medical professionals can also make appropriate adjustments \nto their recruitment strategies based on the collected questionnaire results.\nMethods\nThis section provides a detailed overview of the proposed solution’s architecture and workflow, including the \nconstruction of a clinical trial knowledge graph, the formulation of prompts, the automated generation of \nquestionnaires, the assessment of participation eligibility, and the development of an automated QA system \nempowered by the knowledge graph.\nScheme design\nAs depicted in Fig. 1, During the recruitment process, patients are initially screened based on structured data \nfrom the hospital’s patient management system or EHR (such as age, gender, and symptoms) to determine a \ncertain number of candidates. Recruiters can then expand the recruitment scope based on the relationships \nbetween symptoms in the knowledge graph to ensure sufficient patient participation in the clinical trial. \nSubsequently, a large language model (LLM) transforms the inclusion and exclusion criteria for clinical trials \ninto questionnaires, which are then disseminated to potential participants through phone calls, text messages, \nor emails. In order to ensure informed consent and privacy protection for the patients, we make sure to obtain \nclear consent from the patients before starting the questionnaire, and their privacy and data security will be \nfully protected. This helps to build trust with the patients and lessen their concerns. Additionally, we will clearly \ninform the patients about the voluntary and anonymous nature of the questionnaire, ensuring they know they \nhave the option not to participate and that their responses will be treated confidentially. At the same time, we \nplan to provide links to resources for psychological support and counseling within the questionnaire, so that \npatients can obtain additional help if needed.\nThe rationale for employing a knowledge graph in this paper is twofold: first, it limits the scope of information \nto minimize inaccuracies generated by large language models; secondly, the versatility of the knowledge graph \nextends to its application in intelligent Q&A and recommendation systems27,28.\nFigure 2 illustrates the primary functions of the graph service, notably symptom correlation, knowledge \nacquisition, and intelligent question-answering. The large language model service features capabilities such \nas questionnaire creation and evaluation of eligibility based on entry criteria. For data storage, two databases \nare utilized: Neo4j, which stores clinical trial information, and MySQL, which holds patients’ personal data. \nFurthermore, the data layer is positioned to incorporate future assets, such as training sets of question-answer \nScientific Reports |        (2025) 15:27398 2| https://doi.org/10.1038/s41598-025-11876-0\nwww.nature.com/scientificreports/\npairs for private models, personal patient details, and other clinical trial data. On the operational front, the \nservices offered include management of the questionnaire database, clinical trial data administration, and the \nhandling of Electronic Health Records (EHR).\nKnowledge graph construction\nThis study obtained clinical trial data related to Fudan University by sending HTTP requests to the API of \nclinicaltrials.gov, totaling 579 recruitment records. These records are stored in JSON file format and serve as the \ndata foundation for constructing a knowledge graph.\nBased on the data collected, we designed nine entity types: Recruitment_Project, Condition, Sponsor, \nCollaborator, Intervention_Product, Combination_Product, Intervention_Devices, Intervention_Drugs, and \nOther_Interventions. Correspondingly, nine relationship types were established as indicated in Table 1. These \ntypes of entities are the core features of clinical trial registration data. The entity type Recruitment_Project \nis characterized by attributes such as Inclusion Criteria, Exclusion Criteria, Funding Type, Study Type, Brief \nSummary, Study Title, Primary Outcome Measures, and Phases. The resulting knowledge graph is illustrated in \nFig. 3.\nThe knowledge graph operates as the foundational infrastructure for the proposed solution. It specializes \nin retrieving relevant information from the ‘Inclusion Criteria’ and ‘Exclusion Criteria’ attributes of the \nFig. 2. Technical architecture.\n \nFig. 1. Recruitment workflow diagram.\n \nScientific Reports |        (2025) 15:27398 3| https://doi.org/10.1038/s41598-025-11876-0\nwww.nature.com/scientificreports/\n‘Recruitment_Project’ entity, facilitating data provision for the construction of recruitment questionnaires by \nthe Large Language Modelling (LLM) mechanism.\nNeo4j is a graph database that uses a graphical data structure to express knowledge as a set of nodes and edges. \nIn this structure, nodes represent entities, while edges represent relationships between entities. The construction \nand storage process of knowledge graph are as follows29: \n 1. Collect relevant professional data from ClinicalTrials.gov, and parse it according to the types of the obtained \ndata, then store it as structured data.\n 2. The Neo4j database is accessed via the Py2neo interface.\n 3. Key entities and relationships are identified and extracted from the organized data. Nodes and relationships \nare then created utilizing Py2neo’s ‘graph.merge()‘ function.\n 4. Corresponding entities and relationships are generated in the database.\n 5. The established entities and relationships are then stored within the Neo4j database.\nFig. 3. Clinical Trial Knowledge Graph.\n \nStarting Node Type Relationship Ending Node Type\nRecruitment_Project HAS_CONDITION Condition\nRecruitment_Project HAS_SPONSORS Sponsor\nRecruitment_Project COLLABORATES_WITH Collaborator\nRecruitment_Project HAS_INTERVENTION_PRODUCE Produce\nRecruitment_Project HAS_INTERVENTION_Conbination_Product Conbination_Product\nRecruitment_Project HAS_INTERVENTION_Devices Devices\nRecruitment_Project HAS_INTERVENTION_Drugs Drugs\nRecruitment_Project HAS_INTERVENTION_Other Other_INTERVENTION\nRecruitment_Project HAS_INTERVENTION_Dietary_supplement Dietary_supplement\nCondition Related_Symptomsr Condition\nTable 1. Entity-Relationship.\n \nScientific Reports |        (2025) 15:27398 4| https://doi.org/10.1038/s41598-025-11876-0\nwww.nature.com/scientificreports/\nLarge language model\nThe proposed solution utilizes prompt learning techniques in conjunction with large language models (LLMs), \nwhich have shown remarkable capabilities in reasoning and comprehension tasks. By employing prompt \nengineering, LLMs efficiently automate a variety of tasks. Specifically, this solution integrates the capabilities of \nboth GLM-3-Turbo, GLM-4, qwen-turbo and llama3-70b-instruct models to leverage their respective strengths. \nIt experiments with different prompts and adjusting parameters like top_p and temperature to improve output \naccuracy and stability.30,31.\nFurthermore, this study employs Prompt Engineering to design and adjust input prompts, guiding the \nLLM to generate more accurate and targeted output. The Participation Criteria section can be dynamically \ninput, allowing the generation of different questionnaires based on various Participation Criteria. Taking the \nrecruitment of liver disease with the number NCT05442632 as an example. The participation criteria can be \ndynamically replaced with other participation criteria. As shown in Table 2 The design of the prompts in this \nstudy involves four key components: \n 1. Task Description.\n 2. Participation criteria.\n 3. Output format example.\n 4. Examples of output results.\nApplication process\nThe Questionnaire Generation and Application Process, depicted in Fig. 4, entails identifying patients with \ncorresponding diseases and symptoms, followed by disseminating LLM-generated clinical trial recruitment \nquestionnaires to these patients via email, SMS, and other communication methods 32. Upon completion of \nthe questionnaire, an LLM evaluates the patients’ responses to ascertain their compliance with the recruitment \ncriteria. Patients who satisfy the criteria are advanced to preliminary recruitment, where they undergo additional \nexaminations to verify their eligibility based on more comprehensive criteria33–36.\nPreliminary screening of patients based on symptoms\nMedical researchers or team institutions can utilize the structured information already present in electronic \nhealth record systems or hospital information systems, such as age and gender, to preliminarily screen patients \nand identify a suitable group of patients.\nAfter the knowledge graph is constructed, staff members can visualize the relationships between entities \nthrough Neo4j’s intuitive graphical interface. Based on their expertise, they can appropriately expand the \nrecruitment scope or adjust the recruitment strategies in accordance with relevant information.\nGeneration of recruitment questionnaires\nThe development of recruitment questionnaires harnesses the synergistic application of knowledge graphs \ncombined with advanced large language model (LLM) technologies. This integrated system is adept at \nautonomously producing customized questionnaires for diverse clinical trial endeavors. It benefits from the \ndynamic enhancements and extensions of the knowledge graph database. The completion of the recruitment \nquestionnaire serves not only to ascertain patients’ willingness to participate but also allows the feedback gathered \nto assist clinical trial personnel in promptly adjusting their recruitment strategies. Figure 4 elucidates the process \nof creating recruitment questions for clinical trials through steps 1 to 4, which are described subsequently:\nStep 1: Clinical trial inclusion and exclusion criteria for specific diseases and medications are rapidly retrieved \nvia a search within the knowledge graph.\nStep 2 to 3: Input the participation criteria into the ‘Participation Criteria’ field as indicated in Table 2, then \nformulate a prompt that directs the LLM to accurately generate a questionnaire in the JSON format. The resulting \nquestionnaires from various models are exhibited in Table 3.\nStep 4: The “question” field contains the generated question, and “type” indicates the question category, \nwhere 0 represents a fill-in-the-blank question and 1 represents a true-or-false (judgment) question. For true-\nor-false questions, provide corresponding “options” . The finalized questionnaire is displayed via web or mobile \napplication interfaces in a format that is accessible and convenient for users.\nComposition type Content\nParticipation Criteria 1. Adults, both male and female, aged 18 and older; 2.Patients prepared to receive hepatectomy; 3.Platelet count between 50 and 100 billion per liter; \n4.Children with a Pugh score of A or B (7 or less); 5.Life expectancy of at least three months; 6.Normal Bone marrow hematopoiesis and renal function;\nTask Description Generate English questions corresponding to each small point based on the above content, and ask the patient a moderate number of questions. There \nmust be both true and false questions, as well as fill in the blank questions. Generate the questions directly and do not repeat them.\nOutput Format\nOutput in JSON format [“question”: “” , “type”: “” , “option”: []] (Note: Fill-in-the-blank questions have a type of 1, true-false questions have a type of 2, \n“question” refers to the question itself, “type” indicates the type of the question, and “option” refers to the available choices). Only JSON content will be \noutput without generating any other content.\nExample of output\nFor example, inclusion criteria: 1. 60 years or more at time of transplantation. 2 Acute leukemia. 3. yelodysplastic syndrome. 4. \nyeloproliferative neoplasm. Output results: [“question”:“What is your age at the time of transplantation?” ,“type”:1,“option”:“” ,“question”:“Do \nyou have acute leukemia?” ,“type”:2,“option”:[“Y es” ,“No”],“question”:“Have you been diagnosed with myelodysplastic \nsyndrome?” ,“type”:2,“option”:[“Y es” ,“No”],“question”:“Have you been diagnosed with myeloproliferative neoplasm?” ,“type”:2,“option”:[“Y es” ,“No”]]\nTable 2. The composition of prompt.\n \nScientific Reports |        (2025) 15:27398 5| https://doi.org/10.1038/s41598-025-11876-0\nwww.nature.com/scientificreports/\nAdmission and qualification criteria assessment\nTo achieve a precise match with the admission criteria, the system produces inquiries that align seamlessly with \neach specific criterion. This method enhances the large language models’ capacity to understand and assess \ninformation, improving the accuracy in evaluating a patient’s eligibility. The evaluation procedure, depicted in \nsteps 5 to 7 in Fig. 4, unfolds as follows:\nStep 5: After a patient completes and submits the initial screening questionnaire prepared for the clinical \nstudy, the page data is parsed via JSON and concatenated into the “Patient’s responses” section within the prompt \nshown in Table 4. This, together with the criteria, serves as the context for a large language model to determine \nwhether the patient is eligible for participation. Table 4 presents an example of using Qwen-Turbo and GLM-3-\nTurbo to assess whether the patient fulfills the participation criteria based on the large language model.\nStep 6: The patient’s responses are combined with the corresponding inclusion and exclusion criteria for each \nquery and fed into the large language model for comprehensive analysis. This prompt configuration is detailed \nin Table 4.\nStep 7: After processing the data, the large language model yields a JSON-formatted response that determines \nthe patient’s adherence to the trial’s selection norms. Should the patient qualify, the recruitment team will prompt \nfurther assessments to confirm their suitability for the trial. Table 4 illustrates the analytical outcomes and data \noutputs generated by different models.\nModel Generate Questions\nGLM-3-Turbo\n{ “question”: “ Are you male or female?” , “type”: 2, “option”: [“1. Male” , “2. Female”] }, { “question”: “How old are you?” , “type”: 1, }, { “question”: “ Are you \nprepared to receive a hepatectomy?” , “type”: 2, “option”: [“1. Y es” , “2. No”] }, { “question”: “What is your platelet count?” , “type”: 1, }, { “question”: “What is \nyour Child-Pugh score?” , “type”: 1, }, { “question”: “How long is your expected survival time?” , “type”: 1, }, { “question”: “Is your bone marrow hematopoiesis \nnormal?” , “type”: 2, “option”: [“1. Y es” , “2. No”] }, { “question”: “Is your renal function normal?” , “type”: 2, “option”: [“1. Y es” , “2. No”] }, { “question”: “ Are you \nable to provide voluntary participation and written informed consent?” , “type”: 2, “option”: [“1. Y es” , “2. No”] }\nQwen-Turbo\n{“question”: “ Are you at least 18 years old?” , “type”: 2, “option”: [“Y es” , “No”]}, {“question”: “ Are you scheduled to undergo a hepatectomy?” , “type”: 2, \n“option”: [“Y es” , “No”]}, {“question”: “What is your platelet count (in billion per liter)?” , “type”: 1, “option”: “”}, {“question”: “Is your Child-Pugh score A or B \n(7 or less)?” , “type”: 2, “option”: [“Y es” , “No”]}, {“question”: “What is your expected life expectancy (in months)?” , “type”: 1, “option”: “”}, {“question”: “Do you \nhave normal bone marrow hematopoiesis?” , “type”: 2, “option”: [“Y es” , “No”]}, {“question”: “Do you have normal renal function?” , “type”: 2, “option”: [“Y es” , \n“No”]}, {“question”: “ Are you voluntarily participating in this study and have you provided written informed consent?” , “type”: 2, “option”: [“Y es” , “No”]}\nTable 3. Comparison of Questionnaire generation effectiveness.\n \nFig. 4. Questionnaire Generation and Application Process.\n \nScientific Reports |        (2025) 15:27398 6| https://doi.org/10.1038/s41598-025-11876-0\nwww.nature.com/scientificreports/\nResults\nThis paper employs four models: GLM-3-turbo, GLM-4 37, llama3-70b-instruct 38 and qwen_turbo 39, with \nparameter adjustments and prompt modifications specifically for the GLM-3-turbo model. Evaluation metrics \ninclude accuracy, BLEU, ROUGE-1, ROUGE-2, and ROUGE-L. The evaluation involves simulating patient \nresponses using a large model and assessing patient eligibility with input from 2 medical professionals and 3 \nmedical students.\nJSON format accuracy represents the correctness of the questionnaire’s JSON format and indicates whether \nthe questionnaire can be successfully visualized in practical applications. BLEU, ROUGE-1, ROUGE-2, and \nROUGE-L are widely employed evaluation metrics in natural language processing 40,41, primarily for assessing \nthe quality of machine-generated text. Higher values for these metrics generally indicate better text quality and \nless need for manual revision.\nAmong the 579 clinical trial registration entries retrieved by searching for Fudan University as the sponsor \non ClinicalTrials.gov, 17 entries were found to have incomplete data. Consequently, during the experimental \nvalidation phase of this study, 562 corresponding pre-recruitment questionnaires were automatically generated \nbased on the remaining 562 clinical trial registration entries. Each questionnaire contains approximately 10 \nquestions on average, facilitating the staff ’s swift design of a patient-friendly final version.\nIn terms of accuracy in JSON format, the performance of these four models was 98.57%, 89.33%, 100% \nand 99.28%, respectively. The llama3-70b-instruct model performs better in terms of questionnaire generation \nquality and accuracy in determining participation eligibility.\nIn Table 6, a comparison is presented of the GLM-3-turbo model’s accuracy in Json format, total number \nof questions, BLEU score, ROUGE-1, ROUGE-2, and ROUGE-L performance under various temperature \nvalues and top values. According to Table 6, reducing the temperature parameter judiciously can lead to a lower \nnumber of generated questions. Additionally, integrating sample questions into the prompts markedly improves \nthe accuracy of the JSON file and the total quantity of generated questions.\n Accuracy = TP\nTP + FP  (1)\nThe summary accuracy reflects the precision of the system’s automatic evaluation of patients’ eligibility to \nparticipate after they complete the questionnaire. To more comprehensively assess the accuracy of test eligibility, \nthis method employed Large Language Model (LLM) technology to simulate 85 patients independently \ncompleting questionnaires. These 85 questionnaires, each reflecting the unique conditions of the patients, were \nused to evaluate the accuracy of LLMs in eligibility assessment. As shown in Table 5, the GLM-3-turbo, GLM-4, \nllama3-70b-instruct and qwen_turbo models achieved accuracy rates of 89.28%, 91.39%, 92.85% and 91.66%, \nrespectively, in summarizing the responses to the questionnaires.\nWhen assessing patient eligibility for participation, the llama3-70b-instruct model exhibited superior \nperformance, with its accuracy generally meeting the requirements of practical applications.\nDiscussion\nThe method introduced in this article can achieve automatic generation of pre recruitment questionnaires for \nclinical trials. After patients complete the questionnaire, the Large Language Model (LLM) evaluates whether \nthey meet the recruitment criteria and quantifies the number of patients who meet the criteria. Subsequently, \neligible patients will be invited by recruiters to undergo professional examinations to confirm their suitability. \nThis method combines LLM with knowledge graph technology to improve the efficiency of clinical trial \nrecruitment and simplify workflow.\nThe robust generation of questionnaires and the effectiveness of their response judgments have been \nsatisfactorily validated in practical applications. In addition, this method enables precise customization of \nquestionnaires for various diseases and clinical trial environments. By adjusting the prompt appropriately, \nsuch as adding examples, the output quality of the questionnaire can be significantly improved. Adjusting the \nparameters of the questionnaire appropriately will result in a more detailed breakdown based on the inclusion \nand exclusion criteria.\nType Data\nPrompt\nInclusion criteria: 1. Adults, both male and female, aged 18 and older; 2.Patients prepared to receive hepatectomy; 3.Platelet count between \n50 and 100 billion per liter; 4.Children with a Pugh score of A or B (7 or less); 5.Life expectancy of at least three months; 6.Normal Bone \nmarrow hematopoiesis and renal function; 7.Voluntary participation and written informed consent; Patient’s responses: Q:Are you at least 18 \nyears old? A: Y es. Q:Are you scheduled to undergo hepatectomy? A: Y es. Q: What is your platelet count? (Please provide a numerical value) A: \n60 ∗ 109/L. Q:Is your Child-Pugh score A or grade B (7 or less)? A: Y es. Q: What is your expected life expectancy? (Please provide a numerical \nvalue in months) A: 2 months. Q: Do you have normal bone marrow hematopoiesis? A: Y es. Q: Do you have normal renal function? A: Y es. Q: \nAre you voluntarily participating in this study and have you provided written informed consent? A: Y es. Please assess whether the patient meets \nthe enrollment criteria based on the provided content and return the findings in JSON format. The “result” should indicate the decision, while \n“reason” should specify the grounds for any non-compliance. correctNumber represents the number of participation criteria met.\nQwen-Turbo { “result”: “Does not meet enrollment criteria” , “reason”: “The patient’s expected life expectancy is 2 months, which is less than the required \nminimum of 3 months. ” , “correctNumber”: 6 }\nGLM-3-Turbo {“result”: “No” , “reason”: “The patient’s expected life expectancy is less than the required 3 months for inclusion. ” , “correctNumber”:“6”}\nTable 4. Intelligent judgment of questionnaire responses.\n \nScientific Reports |        (2025) 15:27398 7| https://doi.org/10.1038/s41598-025-11876-0\nwww.nature.com/scientificreports/\nRegarding the accuracy of summarization, there are issues with unclear descriptions and ambiguous content \nin the inclusion and exclusion criteria of the questionnaire. Although this does not impact the generation of the \nquestionnaire, it will directly reduce the accuracy of patient participation in eligibility assessment.\nOverall, the JSON format questionnaire generated by large language models has high stability and can \ncomprehensively cover all inclusion and exclusion criteria. In addition, the accuracy of patient participation \nqualification assessment based on the content of the questionnaire is also high. Therefore, the methods \nintroduced in this article are valuable for practical scenarios.\nConclusions\nThis solution significantly improves recruitment efficiency, primarily by expediting the development of \nrecruitment questionnaires. By incorporating prompts to guide Large Language Models (LLMs), it enables \nautomatic eligibility assessment based on preset criteria and patient responses, ensuring a high degree of \naccuracy.\nTo further implement the solution proposed in this article, we plan to introduce a human feedback mechanism. \nThrough this mechanism, patients can offer valuable insights and suggestions regarding the questionnaire survey \nprocess, thereby facilitating continuous improvement and optimization of recruitment methods. Additionally, \nto safeguard patient privacy, our questionnaire employs an anonymous and multiple-choice design, ensuring \nthat patients’ answers are independent of their personal identity. This approach not only protects patient privacy \nbut also provides valuable information for healthcare professionals, assisting them in more effectively recruiting \npatients.\nLooking ahead, our goal is to refine the use of EHRs and strengthen privacy protections via enhanced LLMs. \nBy standardizing the input of inclusion and exclusion criteria, we will improve the precision of questionnaire \nanalysis, thereby facilitating the conduct of clinical trials and advancing medical research.\nMetric/\nSituation Default Temperature 0.5 Temperature 0.7 Temperature 0.85 Prompt without examples Top 0.4\nNumber of \nquestions 5394 5409 5392 5360 6211 5352\nJSON Format 98.57% 96.97% 97.86% 96.08% 73.01% 97.33%\nBLEU-5 0.3857 0.6611 0.6399 0.6239 0.3571 0.6773\nP 0.4812 0.7730 0.7643 0.7482 0.5463 0.7831\nROUGE-1 R 0.4530 0.7765 0.7667 0.7574 0.6919 0.7824\nF1 0.4528 0.7677 0.7579 0.7448 0.5975 0.7759\nP 0.2797 0.6521 0.6408 0.6220 0.3791 0.6693\nROUGE-2 R 0.2670 0.6547 0.6414 0.6294 0.4974 0.6689\nF1 0.2643 0.6467 0.6340 0.6180 0.4188 0.6625\nP 0.4541 0.7482 0.7376 0.7219 0.5120 0.7590\nROUGE-L R 0.4271 0.7513 0.7406 0.7298 0.6431 0.7585\nF1 0.4272 0.7431 0.7320 0.7184 0.5583 0.7522\nTable 6. Evaluation of Generated Questionnaires.\n \nMetric/Model GLM-3-turbo GLM-4 llama3-70b-instruct qwen_turbo\nSummary \naccuracy 89.73% 91.39% 92.85% 91.66%\nJSON Format 98.57% 89.33% 100% 99.28%\nBLEU-5 0.3857 0.3732 0.3836 0.3127\nP 0.5679 0.5660 0.6323 0.5171\nROUGE-1 R 0.6582 0.6373 0.5794 0.5898\nF1 0.6000 0.5869 0.5943 0.5389\nP 0.3803 0.3794 0.4315 0.3184\nROUGE-2 R 0.4434 0.4317 0.3972 0.3639\nF1 0.4011 0.3934 0.4049 0.3302\nP 0.5216 0.5223 0.5801 0.4630\nROUGE-L R 0.6039 0.5864 0.5328 0.5271\nF1 0.5508 0.5408 0.5459 0.4823\nTable 5. Model comparison and analysis.\n \nScientific Reports |        (2025) 15:27398 8| https://doi.org/10.1038/s41598-025-11876-0\nwww.nature.com/scientificreports/\nData availability\nThe datasets used and / or analyzed during the current study are available from the corresponding author on \nreasonable request. The partialtial code can be obtained by contacting author.thor.\nReceived: 14 January 2025; Accepted: 14 July 2025\nReferences\n 1. Ismail, A., Al-Zoubi, T., El Naqa, I. & Saeed, H. The role of artificial intelligence in hastening time to recruitment in clinical trials. \nBone Joint Res. 5(1), 20220023 (2023) https://doi.org/10.1259/bjro.20220023\n 2. Chaudhari, N., Ravi, R., Gogtay, N. J. & Thatte, U. M. Recruitment and retention of the participants in clinical trials: challenges and \nsolutions. Perspect. Clin. Res. 11, 64–69. https://doi.org/10.4103/picr.PICR_206_19 (2020).\n 3. Su, Q., Cheng, G. & Huang, J. A review of research on eligibility criteria for clinical trials. Clin. Exp. Med. 23(6), 1867–1879.  h t t p s \n: / / d o i . o r g / 1 0 . 1 0 0 7 / s 1 0 2 3 8 - 0 2 2 - 0 0 9 7 5 - 1     (2023).\n 4. Darmawan, I., Bakker, C., Brockman, T. A., Patten, C. A. & Eder, M. The role of social media in enhancing clinical trial recruitment: \nScoping review. J. Med. Internet Res. 22(10), 22810. https://doi.org/10.2196/22810 (2020).\n 5. Barten, T. R. M., Staring, C. B., Hogan, M. C., Gevers, T. J. G. & Drenth, J. P . H. Expanding the clinical application of the polycystic \nliver disease questionnaire: determination of a clinical threshold to select patients for therapy. HPB 25(8), 890–897.  h t t p s : / / d o i . o r \ng / 1 0 . 1 0 1 6 / j . h p b . 2 0 2 3 . 0 4 . 0 0 4     (2023).\n 6. Tsai, M.-L., Ong, C. W . & Chen, C.-L. Exploring the use of large language models (llms) in chemical engineering education: \nBuilding core course problem models with chat-gpt. Education for Chemical Engineers 44, 71–95.  h t t p s : / / d o i . o r g / 1 0 . 1 0 1 6 / j . e c e . 2 0 \n2 3 . 0 5 . 0 0 1     (2023).\n 7. Brøgger-Mikkelsen, M., Ali, Z., Zibert, J. R., Andersen, A. D. & Thomsen, S. F . Online patient recruitment in clinical trials: \nSystematic review and meta-analysis. J. Med. Internet Res. 22(11), 22179. https://doi.org/10.2196/22179 (2020).\n 8. Weng, C. & Embi, P .J. In: Richesson, R.L., Andrews, J.E., Fultz Hollis, K. (eds.) Informatics Approaches to Participant Recruitment, \npp. 219–229. Springer, Cham (2023). https://doi.org/10.1007/978-3-031-27173-1_12\n 9. Applequist, J. et al. A novel approach to conducting clinical trials in the community setting: utilizing patient-driven platforms and \nsocial media to drive web-based patient recruitment. BMC Med. Res. Methodol. 20(1), 58.  h t t p s : / / d o i . o r g / 1 0 . 1 1 8 6 / s 1 2 8 7 4 - 0 2 0 - 0 0 9 \n2 6 - y     (2020).\n 10. Wang, D., Wang, L., Zhang, Z., Wang, D., Zhu, H., Gao, Y ., Fan, X. & Tian, F . “brilliant ai doctor” in rural clinics: Challenges in ai-\npowered clinical decision support system deployment. In: Proceedings of the 2021 CHI Conference on Human Factors in Computing \nSystems. CHI ’21. Association for Computing Machinery, New Y ork, NY , USA (2021). https://doi.org/10.1145/3411764.3445432\n 11. Cai, L. Z. et al. Performance of generative large language models on ophthalmology board-style questions. Am. J. Ophthalmol. 254, \n141–149. https://doi.org/10.1016/j.ajo.2023.05.024 (2023).\n 12. Peng, Y ., Rousseau, J. F ., Shortliffe, E. H. & Weng, C. Ai-generated text may have a role in evidence-based medicine. Nat. Med. \n29(7), 1593–1594. https://doi.org/10.1038/s41591-023-02366-9 (2023).\n 13. Park, J. et al. Criteria2query 3.0: Leveraging generative large language models for clinical trial eligibility query generation. Available \nat SSRN 4637800\n 14. Hamer, D.M., Schoor, P ., Polak, T.B. & Kapitan, D. Improving patient pre-screening for clinical trials: Assisting physicians with \nlarge language models. arXiv preprint arXiv:2304.07396 (2023)\n 15. Nievas, M., Basu, A., Wang, Y . & Singh, H. Distilling Large Language Models for Matching Patients to Clinical Trials. J. Am. Med. \nInform. Assoc. 31 (9), 1953–1963(2023)\n 16. Jin, Q., Wang, Z., Floudas, C.S., Sun, J. & Lu, Z. Matching patients to clinical trials with large language models.  arXiv:2307.15051ArXiv, \n2307–150512 https://doi.org/10.1038/d41586-019-02871-3 (2023).\n 17. Trombini-Souza, F . et al. Knee osteoarthritis pre-screening questionnaire (kops): cross-cultural adaptation and measurement \nproperties of the brazilian version—kops brazilian version. Advances in Rheumatology 62, 40 (2022).\n 18. Yingchankul, N. et al. Functional-belief-based alcohol use questionnaire (fbaq) as a pre-screening tool for high-risk drinking \nbehaviors among young adults: A northern thai cross-sectional survey analysis. Int. J. Environ. Res. Public Health.  18(4), 1536 \n(2021).\n 19. Weiss, G. et al. Development and validation of the salzburg copd-screening questionnaire (scsq): a questionnaire development and \nvalidation study. NPJ Prim. Care Respir. Med. 27(1), 4 (2017).\n 20. De Melo, T. S., De Albuquerque Pacheco, G., Souza, De Castro De. & M.I., Figueiredo, K.,. A dental pre-screening system: usability \nand user perception. The International Society for Telemedicine and eHealth 11(1), 1–7 (2023).\n 21. Hwang, M. et al. Validation of the stop-bang questionnaire as a preoperative screening tool for obstructive sleep apnea: a systematic \nreview and meta-analysis. BMC Anesthesiol. 22(1), 366 (2022).\n 22. Liu, H., Peng, Y . & Weng, C. How good is chatgpt for medication evidence synthesis?. Stud. Health Technol. Inform. 302, 1062–\n1066. https://doi.org/10.3233/shti230347 (2023).\n 23. Truhn, D., Reis-Filho, J. S. & Kather, J. N. Large language models should be used as scientific reasoning engines, not knowledge \ndatabases. Nat. Med. 29(12), 2983–2984. https://doi.org/10.1038/s41591-023-02594-z (2023).\n 24. Wang, C. et al. keqing: knowledge-based question answering is a nature chain-of-thought mentor of LLM (2023)\n 25. Zhang, G. et al. Leveraging generative ai for clinical evidence summarization needs to achieve trustworthiness (2023)  h t t p s : / / d o i . \no r g / 1 0 . 4 8 5 5 0 / a r X i v . 2 3 1 1 . 1 1 2 1 1     [cs.AI]\n 26. Wong, C. et al. Scaling clinical trial matching using large language models: A case study in oncology (2023)\n 27. Zhang, R. et al. Drug repurposing for covid-19 via knowledge graph completion. J. Biomed. Inform. 115, 103696.  h t t p s : / / d o i . o r g / 1 \n0 . 1 0 1 6 / j . j b i . 2 0 2 1 . 1 0 3 6 9 6     (2021).\n 28. Liu, A., Huang, Z., Lu, H., Wang, X. & Yuan, C. Bb-kbqa: Bert-based knowledge base question answering. In: Chinese Computational \nLinguistics: 18th China National Conference, CCL 2019, Kunming, China, October 18–20, 2019, Proceedings, pp. 81–92. Springer, \nBerlin, Heidelberg (2019). https://doi.org/10.1007/978-3-030-32381-3_7\n 29. Han, X. et al. Overview of the ccks 2019 knowledge graph evaluation track: Entity, relation, event and qa (2020)  h t t p s : / / d o i . o r g / 1 0 \n. 4 8 5 5 0 / a r X i v . 2 0 0 3 . 0 3 8 7 5       \n 30. Yuan, J., Tang, R., Jiang, X. & Hu, X. Large language models for healthcare data augmentation: An example on patient-trial \nmatching. AMIA Annu. Symp. Proc. 2023, 1324–1333 (2023).\n 31. Yuan, M. et al. Large language models illuminate a progressive pathway to artificial healthcare assistant: A review (2023)\n 32. Ortner, V . K. et al. Accelerating patient recruitment using social media: Early adopter experience from a good clinical practice-\nmonitored randomized controlled phase i/iia clinical trial on actinic keratosis. Contemp. Clin. Trials Commun. 37, 101245.  h t t p s : / \n/ d o i . o r g / 1 0 . 1 0 1 6 / j . c o n c t c . 2 0 2 3 . 1 0 1 2 4 5     (2024).\n 33. Guan, Z. et al. CohortGPT: An enhanced GPT for participant recruitment in clinical study (2023)\n 34. Y ang, Z. et al. Talk2Care: Facilitating asynchronous patient-provider communication with large-language-model (2023)\nScientific Reports |        (2025) 15:27398 9| https://doi.org/10.1038/s41598-025-11876-0\nwww.nature.com/scientificreports/\n 35. Soumen, P ., Manojit, B., Aminul, I. M. & Chiranjib, C. Chatgpt or llm in next-generation drug discovery and development: \npharmaceutical and biotechnology companies can make use of the artificial intelligence-based device for a faster way of drug \ndiscovery and development. Int. J. Surg. 109(12), 4382–4384. https://doi.org/10.1097/JS9.0000000000000719 (2023).\n 36. Sawant, S., Madathil, K. C., Molloseau, M. & Obeid, J. Overcoming recruitment hurdles in clinical trials: An investigation of \nremote consenting modalities and their impact on workload, workflow, and usability. Appl. Ergon. 114, 104135.  h t t p s : / / d o i . o r g / 1 0 \n. 1 0 1 6 / j . a p e r g o . 2 0 2 3 . 1 0 4 1 3 5     (2024).\n 37. GLM, T. et al. Chatglm: A family of large language models from glm-130b to glm-4 all tools. arXiv preprint arXiv:2406.12793 \n(2024).\n 38. Siriwardhana, S., McQuade, M., Gauthier, T., Atkins, L., Neto, F .F ., Meyers, L., Vij, A., Odenthal, T., Goddard, C. & MacCarthy, M., \net al. Domain adaptation of llama3-70b-instruct through continual pre-training and model merging: A comprehensive evaluation. \narXiv preprint arXiv:2406.14971 (2024).\n 39. Y ang, A.  et al. Qwen2. 5 technical report. arXiv preprint arXiv:2412.15115 (2024).\n 40. Corredor Casares, J.: Large language model evaluation. B.S. thesis, Universitat politècnica de catalunya (2025).\n 41. Briman, M.K.H. & Yildiz, B. Beyond rouge: A comprehensive evaluation metric for abstractive summarization leveraging similarity, \nentailment, and acceptability. Int. J. Artif. Intell. Tools. 33 (05), 2450017 https://doi.org/10.1142/S0218213024500179(2024).\nAcknowledgements\nWe sincerely thank the Science and Technology Innovation 2030 - Major Project of 1“New Generation Artistic \nIntelligence” (2020AAAA0109300) and the Shanghai Municipal Administration of Traditional Chinese Medi -\ncine Clinical Project (2020LP018) for their support and encouragement. This paper has greatly benefited from \nthe insights provided by these funding sources. Additionally, we extend our gratitude to all colleagues who \nparticipated in this project.\nAuthor contributions\nZiHang Chen:Conceptualization,Methodology,Writing- Original Draft. Liang Liu:Writing - Review. QianMin \nSu: Supervision,Funding acquisition. GaoYi Cheng: Writing - Review & Editing,Investigation. JiHan Huang: \nResources,Supervision. Ying Li:Resources.\nFunding\nThis work was supported by Science and Technology Innovation 2030 - Major Project of “New Generation Ar-\ntistic Intelligence (2020AAAA0109300)” and Shanghai Municipal Administration of Traditional Chinese Med-\nicine Clinical Project (2020LP018).\nDeclarations\nCompeting interests\nThe authors declare no competing interests.\nEthical approval\nNot applicable. The data used in this framework consists of open-source data and patient data simulated by \nlarge language models.\nConsent to participate\nAll authors disclosed no relevant relationships.\nAdditional information\nCorrespondence and requests for materials should be addressed to S.Q.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\nOpen Access  This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives \n4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in \nany medium or format, as long as you give appropriate credit to the original author(s) and the source, provide \na link to the Creative Commons licence, and indicate if you modified the licensed material. Y ou do not have \npermission under this licence to share adapted material derived from this article or parts of it. The images or \nother third party material in this article are included in the article’s Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence \nand your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to \nobtain permission directly from the copyright holder. To view a copy of this licence, visit  h t t p : / / c r e a t i v e c o m m o \nn s . o r g / l i c e n s e s / b y - n c - n d / 4 . 0 /     .  \n© The Author(s) 2025 \nScientific Reports |        (2025) 15:27398 10| https://doi.org/10.1038/s41598-025-11876-0\nwww.nature.com/scientificreports/",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.5383708477020264
    },
    {
      "name": "Knowledge graph",
      "score": 0.4631110727787018
    },
    {
      "name": "Natural language processing",
      "score": 0.3518446087837219
    },
    {
      "name": "Data science",
      "score": 0.3469078838825226
    },
    {
      "name": "Knowledge management",
      "score": 0.343050479888916
    },
    {
      "name": "Information retrieval",
      "score": 0.27058786153793335
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I141962983",
      "name": "Shanghai University of Engineering Science",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I24943067",
      "name": "Fudan University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I157773358",
      "name": "Sun Yat-sen University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210128921",
      "name": "The First Affiliated Hospital, Sun Yat-sen University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210127074",
      "name": "Zhongshan Hospital",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210098460",
      "name": "Shanghai University of Traditional Chinese Medicine",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210101984",
      "name": "Longhua Hospital Shanghai University of Traditional Chinese Medicine",
      "country": "CN"
    }
  ]
}