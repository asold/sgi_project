{
  "title": "Exploring Large Language Model for Graph Data Understanding in Online Job Recommendations",
  "url": "https://openalex.org/W4393147839",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2511265932",
      "name": "Likang Wu",
      "affiliations": [
        "Bose (United States)",
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A2143624175",
      "name": "Zhaopeng Qiu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2008445811",
      "name": "Zhi Zheng",
      "affiliations": [
        "Bose (United States)",
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A2698367452",
      "name": "Hengshu Zhu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2136372366",
      "name": "Enhong Chen",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A2511265932",
      "name": "Likang Wu",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A2143624175",
      "name": "Zhaopeng Qiu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2008445811",
      "name": "Zhi Zheng",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A2698367452",
      "name": "Hengshu Zhu",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4367694290",
    "https://openalex.org/W3088684606",
    "https://openalex.org/W4280586754",
    "https://openalex.org/W4385571886",
    "https://openalex.org/W3149985273",
    "https://openalex.org/W4376654514",
    "https://openalex.org/W6774931820",
    "https://openalex.org/W4387848891",
    "https://openalex.org/W4376311940",
    "https://openalex.org/W2989031759",
    "https://openalex.org/W2133401789",
    "https://openalex.org/W3103410128",
    "https://openalex.org/W2798507773",
    "https://openalex.org/W3175529606",
    "https://openalex.org/W2890410227",
    "https://openalex.org/W2808631100",
    "https://openalex.org/W3122499344",
    "https://openalex.org/W4292420207",
    "https://openalex.org/W4311414359",
    "https://openalex.org/W4376312626",
    "https://openalex.org/W4387757693",
    "https://openalex.org/W3012871709",
    "https://openalex.org/W4383472964",
    "https://openalex.org/W4379251438",
    "https://openalex.org/W4386728933",
    "https://openalex.org/W3093581739",
    "https://openalex.org/W4382239710",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W3168867926",
    "https://openalex.org/W3198650159",
    "https://openalex.org/W4365211555",
    "https://openalex.org/W3159723170"
  ],
  "abstract": "Large Language Models (LLMs) have revolutionized natural language processing tasks, demonstrating their exceptional capabilities in various domains. However, their potential for graph semantic mining in job recommendations remains largely unexplored. This paper focuses on unveiling the capability of large language models in understanding behavior graphs and leveraging this understanding to enhance recommendations in online recruitment, including promoting out-of-distribution (OOD) applications. We present a novel framework that harnesses the rich contextual information and semantic representations provided by large language models to analyze behavior graphs and uncover underlying patterns and relationships. Specifically, we propose a meta-path prompt constructor that aids LLM recommender in grasping the semantics of behavior graphs for the first time and design a corresponding path augmentation module to alleviate the prompt bias introduced by path-based sequence input. By facilitating this capability, our framework enables personalized and accurate job recommendations for individual users. We evaluate the effectiveness of our approach on comprehensive real-world datasets and demonstrate its ability to improve the relevance and quality of recommended results. This research not only sheds light on the untapped potential of large language models but also provides valuable insights for developing advanced recommendation systems in the recruitment market. The findings contribute to the growing field of natural language processing and offer practical implications for enhancing job search experiences.",
  "full_text": "Exploring Large Language Model for Graph Data Understanding\nin Online Job Recommendations\nLikang Wu1,2, Zhaopeng Qiu2, Zhi Zheng1,2, Hengshu Zhu2 ‚àó, Enhong Chen1 ‚àó\n1 University of Science and Technology of China\n2 Career Science Lab, BOSS Zhipin\n{wulk,zhengzhi97}@mail.ustc.edu.cn, {zhpengqiu,zhuhengshu}@gmail.com, cheneh@ustc.edu.cn\nAbstract\nLarge Language Models (LLMs) have revolutionized nat-\nural language processing tasks, demonstrating their excep-\ntional capabilities in various domains. However, their poten-\ntial for graph semantic mining in job recommendations re-\nmains largely unexplored. This paper focuses on unveiling\nthe capability of large language models in understanding be-\nhavior graphs and leveraging this understanding to enhance\nrecommendations in online recruitment, including promoting\nout-of-distribution (OOD) applications. We present a novel\nframework that harnesses the rich contextual information and\nsemantic representations provided by large language mod-\nels to analyze behavior graphs and uncover underlying pat-\nterns and relationships. Specifically, we propose a meta-path\nprompt constructor that aids LLM recommender in grasping\nthe semantics of behavior graphs for the first time and design\na corresponding path augmentation module to alleviate the\nprompt bias introduced by path-based sequence input. By fa-\ncilitating this capability, our framework enables personalized\nand accurate job recommendations for individual users. We\nevaluate the effectiveness of our approach on comprehensive\nreal-world datasets and demonstrate its ability to improve the\nrelevance and quality of recommended results. This research\nnot only sheds light on the untapped potential of large lan-\nguage models but also provides valuable insights for devel-\noping advanced recommendation systems in the recruitment\nmarket. The findings contribute to the growing field of nat-\nural language processing and offer practical implications for\nenhancing job search experiences.\nIntroduction\nOnline recruitment recommendations aim to suggest rele-\nvant job opportunities to job seekers based on their prefer-\nences and qualifications, improving the chances of matching\nthe right employment. With the exponential growth of online\nrecruitment platforms and the need for efficient and person-\nalized job search experiences, the development of effective\njob recommendation systems has become crucial.\nIn online recruitment systems, job postings and resumes\nare written in natural language. Traditional approaches have\ntreated job-resume matching as a supervised text-matching\nCopyright ¬© 2024, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\n*Corresponding Author.\n‚Ä†During the BOSS Zhipin internship period.\nproblem using paired data for training (Qin et al. 2018; Shen\net al. 2018). However, online recruitment platforms often\nsuffer from sparse interaction data, with job postings attract-\ning only a few candidates on average (Ramanath et al. 2018).\nTo address this, recent studies (Bian et al. 2020; Yang et al.\n2022) have explored the use of behavior graphs to capture\nhigh-order interactions and alleviate the sparse interaction\nissue. These behavior graphs leverage message passing to\nenhance the understanding of user preferences.\nUnlike many general recommendation tasks, it is easy to\nfind that textual understanding forms the backbone of job\nrecommendation, and behavior modeling contributes to the\npersonalized module. In our work, we strive to overcome\nthe accuracy limitations of job recommenders by enhanc-\ning the semantic richness of textual representations. Inspired\nby several recent successful recommendations based on text\npre-training (Wu et al. 2023), we introduce a large language\nmodel (LLM) as the foundational framework for job recom-\nmendation that directly generates targets. Adopting this ap-\nproach is not only beneficial but also intuitive. For instance,\nout-of-distribution items usually appear in recruitment mar-\nkets since new job demands are constantly emerging, such as\nprompt engineers for generative models. This issue is more\ncomplex than traditional cross-domain tasks (Zhao et al.\n2023; Jiang et al. 2023; Yu et al. 2023). The powerful se-\nmantic mining ability and extensive external knowledge of\nLLMs augment the generation and associative power of rec-\nommenders, which is able to generate reasonable recom-\nmendation results for the hard OOD items.\nHowever, the existing learning schema of LLM recom-\nmender cannot understand the non-textual behavior graph\nwhich weakens the personalized recommendation ability for\ndifferent job seekers. To tackle this challenge, we propose\na meta-path prompt constructor to encode the interaction in-\nformation of graph into the natural language prompt. Specif-\nically, in such a heterogeneous behavior graph, each meta-\npath composed of various types of nodes and edges can be\ntransferred into a description naturally since each type indi-\ncates a specific and meaningful interaction, e.g., interview,\nconversation, etc. Along this line, for each job seeker, the\nLLM captures the high-order interaction feature to augment\nher personality with the meta-path prompt.\nBased on the above analysis, we explore the inclusion\nof graph data understanding in large language model-based\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n9178\nrecommendations for the first time. An efficient large lan-\nguage model named GLRec (Graph-understanding LLM\nRecommender) is proposed to optimize the recommended\nquality of job recommendation, which is fine-tuned with\nLoRa (Hu et al. 2021) on our constructed instruction\ndataset for aligning the gap between pre-trained knowledge\nand actual recruitment domain. Especially, our exploration\npresents two valuable and important findings that largely in-\nfluence the graph understanding strategy of LLM: (i). Dif-\nferent paths would present different weights for the model\ndecision. (ii). The position bias of the order of path prompts\nbrings unstable answers. For these issues, we carefully de-\nsign path shuffling, adaptive path selector, and their hybrid\npath augmentation mechanism to mitigate the adverse ef-\nfects posed by varying path prompts. The main contributions\ncould be summarized as follows:\n‚Ä¢ To our best knowledge, we are the first to implement\nthe fine-tuned large language model as job recommender,\nwhich promotes matching accuracy via the semantic\nrichness and massive knowledge of LLM.\n‚Ä¢ We propose the meta-path prompt constructor that lever-\nages LLM recommender to comprehend behavior graphs\nfor the first time and design a corresponding path aug-\nmentation module to alleviate the prompt bias.\n‚Ä¢ We conduct sufficient experiments on real-world recruit-\nment datasets, and the experimental results and visual-\nization cases show the superiority of our model.\nRelated Work\nJob Recommendation\nJob Recommendation has been extensively studied in the\nliterature (Kenthapadi, Le, and Venkataraman 2017). Early\nmethods handled this problem (Lu, El Helou, and Gillet\n2013) relying on collaborative filtering assumptions. Ex-\nisting research focused more on text-matching technology.\nThey have been proposed to encode job and resume in-\nformation. For example, (Shen et al. 2018) utilized CNN\nfor encoding, while (Qin et al. 2018) leveraged RNN and\nBiLSTM to capture sequential information. (Yan et al.\n2019) introduced a profiling memory to learn latent pref-\nerence representation by interacting with both job and re-\nsume. (Luo et al. 2019) explored the effectiveness of ad-\nversarial training for job-resume matching. In addition to\nthe aforementioned research, some researchers considered\nmulti-granularity interactions. The ranking-based loss can\nbe used to capture multi-level interactions as supervision\nsignals (Le et al. 2019). (Fu et al. 2021) proposed a bilateral\nmulti-behavior sequence model to describe users‚Äô dynamic\npreferences. These approaches highlighted the importance\nof considering various interaction patterns and incorporating\nadditional user information to improve the quality of job rec-\nommendations. However, online recruitment platforms fre-\nquently encounter challenges due to sparse interaction data,\nresulting in job postings attracting only a limited number of\ncandidates on average (Ramanath et al. 2018). Recent stud-\nies (Bian et al. 2020; Yang et al. 2022) have investigated the\nutilization of behavior graphs to capture high-order interac-\ntions and alleviate the problem of sparse interactions.\nLarge Language Models for Recommendation\nLLMs can extract high-quality textual features and use\nexternal knowledge to improve recommenders. A review\nby (Wu et al. 2023) categorized LLM-based recommenda-\ntion systems into discriminative and generative models. Dis-\ncriminative models align pre-trained models like BERT with\ndomain-specific data through fine-tuning. (Qiu et al. 2021;\nWu et al. 2021a) proposed a pre-training and fine-tuning\napproach to learn user representations, leveraging content-\nrich domains to complement users‚Äô sparse behavior data.\nAdditionally, some research explored training strategies like\nprompt tuning. (Penha and Hauff 2020) leveraged BERT‚Äôs\nMasked Language Modeling (MLM) head to uncover its\nunderstanding of item genres using cloze-style prompts.\nPrompt4NR (Zhang and Wang 2023) pioneered the appli-\ncation of the prompt learning paradigm for news recom-\nmendation. Generative models usually translate recommen-\ndation tasks as natural language tasks, and then apply tech-\nniques such as in-context learning (Hou et al. 2023; Dai et al.\n2022), prompt tuning (Kang et al. 2023; Bao et al. 2023),\nand instruction tuning (Zhang et al. 2023; Cui et al. 2022)\nto adapt LLMs to directly generate the recommendation re-\nsults. Compared to discriminative models, generative mod-\nels have better natural language generation capabilities. In\nthe recruitment area, there was a generative model which de-\nveloped LLM with RLHF to generate potential JDs for more\nexplainable recommendations (Zheng et al. 2023). However,\ndespite their successes, LLM recommenders have a glaring\nlimitation: they lack the ability to comprehend graph data,\nwhich impedes their potential for personalized adaptation.\nMethodology\nPreliminary\nProblem Formulation Consider a set of candidates C =\n{c1, c2, . . . , cn1 } and a set of jobs J = {j1, j2, . . . , jn2 },\nwhere n1 and n2 represent the total number of candidates\n(job seekers) and jobs, respectively. Each candidate and job\nare associated with textual documents that describe their re-\nsumes and job requirements. They are also linked to a col-\nlection of directed interaction records (such as interviewing\nand discussing) within the recruitment platform. These in-\nteractions are formally represented as Aci = {ci ‚Üí j‚Ä≤|ci ‚àà\nC, j‚Ä≤ ‚àà J }and Ajk = {jk ‚Üí c‚Ä≤|jk ‚àà J, c‚Ä≤ ‚àà C}, indi-\ncating the directed interactions initiated by candidate ci or\nemployer jk (referred to as a job). Our objective is to predict\nthe compatibility between a job posting and a candidate.\nGenerative Large Language Models Generative LLMs\nare powerful language models capable of generating coher-\nent and contextually relevant text. Models like GPT-3 and\nGPT-4 are trained on vast amounts of text data, enabling\nthem to produce human-like text in response to a given\nprompt or input. Fine-tuning is a common adaption strategy\nto align the target of pre-trained model and domain-specific\napplications, such as two popular paradigms of prompt tun-\ning, and instruction tuning. For all these tuning methods,\nthey have an equal final objective loss of autoregressive\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n9179\nPrompt ConstructorHeterogeneous BehaviorGraphJob SeekerJDInteractionMeta-path\nShuffle Mechanism\nPath Soft SelectorLLM ‚Ä¶\n ?Weighted Path Embedding + Instruction TuningHybrid\nProfileJDTask\nMeta-pathPrompt Embedding\nPath Prompt of Job Seeker\nLLMToken Embedding\nWeight\nPath Soft Selector\nLoRA GLRec\nPath Prompt of Job Seeker\nMeta-path Prompt(1)(2)(3)\n(2)(3)(1)Random\n√óùëötimesShuffle Mechanism\nùëê!\"#$%&'\"%(ùëó!)%**+,%ùëê-ùëê!interviewed for position ùëó!. This position discussed with a job seeker ùëê\"Prompt Constructor\nFigure 1: The framework of GLRec for job recommendation.\ntraining as follows:\nLf = max\nŒò\nX\n(x,y)‚ààT\n|y|X\nt=1\nlog (PŒò (yt | x, y<t)) , (1)\nTaking instruction tuning as an example, which designs and\nconstructs instruction data to restrict the output scope and\nformat. x and y represent the ‚ÄúInstruction Input‚Äù and ‚ÄúIn-\nstruction Output‚Äù in the self-instruct data, respectively, e.g.,\nInstruction Input: ‚ÄúDo you like this item?‚Äù, Instruction Out-\nput: ‚ÄúYes. ‚Äù. And yt is the t-th token of the y, y<t represents\nthe tokens before yt, Œò is the original parameters of LLM,\nand T is the training set.\nTask-specific Instruction In our work, we design two job\nrecommendation tasks to test the LLM recommender fol-\nlowing existing related work (Bao et al. 2023), i.e., point-\nwise and pair-wise job matching. Here we introduce our de-\nsigned template for the sample in our dataset, where infor-\nmation related to privacy and business has been filtered. As-\nsume there is a job seeker called candidate whose Candidate\nProfile Prompt and recommended JD Prompt are defined as:\nCandidate Profile Prompt:Age: 25, Education: Bachelor‚Äôs\ndegree, Graduation School: XXX University, Major: Com-\nputer Applied Science, Work Experience: 2 years.\nJD Prompt: Position: Full Stack Engineer, Educational Re-\nquirement: Bachelor‚Äôs degree, Work Experience: 1-3 years,\nSkill Requirements: HTML/JAVA/Spring Boot/SQL.\nFor the point-wise task, we let the LLM recommender learn\nto predict the satisfaction of a candidate with a recom-\nmended job. The instruction is designed as:\nPoint-wise Instruction: You are a recommender, determin-\ning whether a candidate would be satisfied with the recom-\nmended job. Please answer with ‚ÄúYes. ‚Äù or ‚ÄúNo. ‚Äù.\nFor the pair-wise task, we let the LLM recommender learn to\njustify the preference of a candidate for a recommended job\npair. Given two jobs‚Äô JD Prompt ‚ÄúA‚Äù and ‚ÄúB‚Äù, the instruction\nis designed as:\nPair-wise Instruction:You are a recommender, determining\nwhich position will match the candidate. Please answer with\n‚Äú[A]. ‚Äù or ‚Äú[B]. ‚Äù.\nWith the above-designed prompts, LLM is able to adapt\nto a domain recommendation situation. Note that, to ensure\nthe stability of training, we append the JD prompt to the end\nof the ground truth to increase the predicted length. To fur-\nther fuse interaction knowledge, as shown in Figure 1, we\nwill illustrate the understanding part of graph data for LLM:\nbehavior meta-path prompt generation.\nBehavior Meta-path Prompt Generation\nTo equip LLM with the ability to comprehend interactive\nrelationships in graph data, we propose a meta-path-based\nprompt constructor to obtain prompt inputs that represent\nlocal subgraphs. Before delving into the details of our ap-\nproach, it is necessary to provide a formal introduction to\nheterogeneous graph and meta-path (Wu et al. 2021b).\nDefinition 1. Heterogeneous Graph. G = (V, E), consists\nof an object set V and a link set E. G is also associated with\na node type mapping function œï : V ‚Üí Vand a link type\nmapping function œà : E ‚Üí E. V and E denote the sets of\npredefined object types and link types, where |V| + |E| > 2.\nDefinition 2. Meta-path. A meta-path P is defined as a\npath in the form ofV1\nE1\n‚àí ‚Üí V2\nE2\n‚àí ‚Üí ¬∑¬∑¬∑\nEl\n‚àí ‚Üí Vl+1 (abbreviated\nas V1V2 ¬∑¬∑¬∑V l+1), which describes a composite relationE1 ‚ó¶\nE2 ‚ó¶ ¬∑¬∑¬∑ ‚ó¶ El between objects V1 and Vl+1, where ‚ó¶ denotes\nthe composition operator on relations.\nHeterogeneous graphs are more diverse and complex in\nterms of their semantics compared to homogeneous graphs.\nMeta-paths are commonly used techniques to mine and rep-\nresent the interaction semantics within them. In the context\nof online recruitment, the interactions between job seekers\nand job positions, which involve different types of behav-\niors, form a behavior graph. This behavior graph is a typi-\ncal heterogeneous graph, where different node types include\nCandidate, JD, and different edge types include messaging,\ninterviewing, matching, and more.\nDue to the unique and defined semantics of each type of\nedge in the behavior graph, it is natural to consider trans-\nferring the graph data format meta-path to a natural lan-\nguage description which is acceptable for the large language\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n9180\n1\nLLM\nYes\n2\n1\n 2\n2\n 1\nNoNoYes\nCase 1\nCase 2Case 3\nCase 4\nCandidate Profile Prompt: Age: 25, Education: Bachelor, Graduation School: XXXX University, Major: Computer Applied Science, Work Experience: 2 years.\nMeta-path Prompt 1: The candidate interacted with a position for JA V A, which requires a JA V A Development/Full Stack/Spring/Management background. This position discussed with a job seeker specializing in Computer Science,‚Ä¶\n1\n2Meta-path Prompt 2: The candidate interacted with a position for Automation, which requires a Python/C++/Automation Development background. This pos-itiondiscussed with a job seeker specializing Information Management,...JDPrompt: Position Title: Full Stack Engineer, Educational Requirements: Coll-ege, Work Experience: 1-3 years,Skills Required: HTML/JA V A/Spring Boot/SQL\nTask-specific Instruction: You are a recommendation system, determining whet-her a candidate would be satisfied with the recommended job position. Please answer with \"Yes.\" or \"No.\"\nFigure 2: The real cases of path weight and position bias of\nmeta-path prompt input for LLM.\nmodel. We only need to predefine the prompt template ac-\ncording to the appeared edges in a path and then fill in\nthe template with the resume or job description informa-\ntion. For instance, given a typical meta-path c1\ninterview\n‚àí ‚àí ‚àí ‚àí ‚àí ‚àí ‚Üí\nj1\nmessage\n‚àí ‚àí ‚àí ‚àí ‚àí ‚Üíc2. The prompt template is constructed as:\nMeta-path Prompt: c1 interviewed for position j1. This po-\nsition discussed with a job seeker c2.\nThe node information, i.e., the keywords of descriptions\nof candidates or JD (keywords can be extracted via LLM\nto compress context length), then will be filled in the meta-\npath prompt template to generate the final prompt data in\nour dataset. We add padding to keep the length of each path\nconsistent. The real case can be referred to in Figure 2. In\naddition, to avoid too similar meta-paths leading to redun-\ndancy, we define a simple similarity metric as follows,\nSi,j = |Pi ‚à© Pj|\n|Pi ‚à™ Pj|, P i, Pj ‚àà Œ¶P , (2)\nwhere Œ¶P denotes the set of sampled paths for a candidate.\nPi, Pj indicates two meta-paths in Œ¶P . |Pi ‚à©Pj| is the num-\nber of tokens that exist simultaneously in two paths,Pi ‚à™Pj\nis the union of them. We ensure that Si,j ‚â§ Œ≥ between the\nfinal selected M paths and 0 ‚â§ Œ≥ ‚â§ 1 is a hyperparameter.\nPath Debiasing and Soft Selection Different from the\ntraditional network embedding, sequence-based meta-path\nprompts would lead to two challenges for LLM to under-\nstand the candidates‚Äô behavior sub-graph.\nChallenge 1. Influence of Path Weight . Different meta-\npaths would present different weights for the model decision.\nChallenge 2. Position Bias of Path Prompt . The position\nbias of the order of path prompts brings unstable answers.\nThese two challenges appeared when recognizing the pre-\ntrained large language model as a recommender, which hin-\nders the effective modeling of semantic relationships in\nthe graph by LLM recommendation models. To provide a\nmore intuitive explanation, we extracted a real-world case\nfrom the log of a popular recruitment platform and visual-\nized them in Figure 2. Specifically, for a job seeker in the\nIT industry, given his Candidate Profile Prompt, Meta-path\nPrompt 1, and Meta-path Prompt 2, we further feed the LLM\nwith a Task-specific Instruction belonging to point-wise rec-\nommendation. The LLM recommender is expected to output\nthe decision of ‚ÄúYes‚Äù or ‚ÄúNo‚Äù to present the preference of the\ncandidate. Challenge 1 corresponds to Case 1 and Case 2 in\nthis figure. We can find that the same profile and task de-\nscription with different behavior meta-paths forces LLM to\nmake different predictions. Obviously, the diversity of tech-\nnology stacks in Path 1 reveals the candidate‚Äôs preference for\nfull-stack development, and compared to Path 2, the back-\nground of path-related job seeker is more close to our candi-\ndate. Therefore, for this candidate, Path 1 is evidently more\nimportant for the final decision. For Challenge 2, if we con-\nstruct the input sequence as Case 3, i.e., the order is meta-\npath prompt 1 ‚Üí meta-path prompt 2, the LLM outputs the\nwrong answer ‚ÄúNo‚Äù. But with a reverse path prompt order,\nthe LLM is able to provide an accurate prediction. Similar\nto the widely known position bias of candidate items (Wu\net al. 2023), the position of context prompt clearly misleads\nthe model to generate unstable outputs.\nTo address the negative impact of these two challenges on\nthe recommendation results, we carefully design an augmen-\ntation module specifically for the meta-path prompt, which\nconsists of three concise but effective strategies. The first\nstrategy is Shuffle Mechanism . When preparing domain\ndata for the model‚Äôs supervised fine-tuning (SFT), for each\nsample that contains multiple paths, we randomly shuffle\nthe meta-path prompts in the sample m times. Here m de-\nnotes the conducted times of shuffling. This data augmen-\ntation technique allows the model to learn semantic invari-\nance patterns from different combinations of paths, lead-\ning to more stable results. It enhances the robustness of the\nmodel without introducing redundant information. The sec-\nond strategy is Path Soft Selector. In this work, we regard\nthe path sampling process in Behavior Meta-path Prompt\nGeneration as a hard selection to heuristic selects seman-\ntically rich paths. The Path Soft Selector is used to further\nadaptively assign a learned weight distribution to the con-\nstructed meta-path prompts. Firstly, for a given meta-path\nprompt Mi, i‚àà {1, 2, ..., M} (M denotes the number of\npaths), we obtain the LLM word embedding et of each to-\nken t ‚àà Mi. So, the meta-path embedding Hi of Mi can be\nobtained via a mean pooling as follows,\nHi = 1\n|Mi|\nX\nt‚ààMi\net, i ‚àà {1, 2, ..., M}. (3)\nThen we propose a soft selector to calculate the weight for\neach meta-path embedding as:\nŒ±i = softmax(WaHi) = exp(WaHi)PM\nj=1 exp(WaHj)\n, (4)\nwhere Wa ‚àà R1√óde is a trainable parameter, and de de-\nnotes the dimension of Ei. To avoid the training collapse\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n9181\ncaused by changed value scale, we utilize a controller pa-\nrameter Œª ‚àà (0, 0.5] to update word embeddings in Eq. (5).\nÀÜet = et + Œª ¬∑ Œ±iet, t ‚àà Mi, (5)\nCompared with most existing tuned or non-tuned LLM mod-\nels, our prompt augmentation mechanism considers phrase-\nbased attention to distinguish different paths. Actually, this\nsimple solution can be transferred to other similar situations,\nsuch as weighed sentence embeddings.\nWhat‚Äôs more, the third strategy is theHybrid Mechanism\nwhich implements Shuffle Mechanism and Path Soft Selec-\ntor simultaneously. This hybrid module is expected to ad-\ndress the both two challenges. We will evaluate these three\nstrategies in the experiment section.\nLLM Instruction Tuning and Recommendation\nIn this subsection, we will introduce the instruction tun-\ning and recommendation process, which aims to align the\nused LLM with the recommendation task effectively and ef-\nficiently. For instruction tuning, we follow the general su-\npervised fine-tuning method to minimize the autoregressive\nloss calculated by ground truth and corresponding LLM out-\nput. In our work, we mask the loss position of the prompt\npart. Specific prompt format, task-specific instruction, and\nground truth have been introduced in the Preliminary sec-\ntion. However, direct fine-tuning of the entire model can be\ncomputationally intensive and time-consuming. To address\nthis, we propose a lightweight fine-tuning strategy using\nLoRA, which involves freezing the pre-trained model pa-\nrameters and introducing trainable rank decomposition ma-\ntrices into each layer of the Transformer architecture. This\napproach facilitates lightweight fine-tuning while reducing\nGPU memory consumption. And the final learning objective\ncan be computed as follows:\nLf = max\nŒòL\nX\n(x,y)‚ààT\n|y|X\nt=1\nlog (PŒò+ŒòL (yt | ex, y<t)) , (6)\nwhere ŒòL is the LoRA parameters and we only update\nLoRA parameters during the training process. Note that, dif-\nferent from existing fine-tuning frameworks for recommen-\ndation systems, we replace their token input x by the em-\nbedding ex in Eq. (6), since we update the prompt token\nembedding in the soft selector.\nAs for the recommendation process, since the trained\nmodel has learned the output format of our defined ground\ntruth after several SFT alignment steps. So our designed an-\nswer parsing is a simple way. We catch the softmax prob-\nability of label generation (the token used to denote label,\nsuch as ‚ÄúYes./No.‚Äù or ‚Äú[A]/[B]‚Äù in our work ) in the position\nof model‚Äôs output corresponding to that in the ground truth.\nAlong this line, the final prediction probability is calculated.\nExperiments\nExperimental Settings\nDatasets. We conduct experiments on two datasets RecrX\nand RecrY with different scales which are collected from a\nreal-world and large online recruitment platform in China\nDataset # Candidates\n# Jobs # Match # Interaction\nRecrX 12,440 19,318\n23,879 54,147\nRecrY 18,260 26,576\n47,725 119,529\nTable 1: The statistics of datasets.\nto assess recommendation methods. The datasets were con-\nstructed from the online logs and contained two kinds of be-\nhavior: Match and Interaction, corresponding to the match-\ning set and interaction set mentioned in Problem Formula-\ntion. Besides, each candidate (and job) is associated with a\ndescriptive text (i.e., resume or job description). The overall\nstatistics are shown in Table 1. From the statistical data, it\ncan be seen that job recommendation is a sparsely interac-\ntive scenario. The segmentation ratio of the training set and\ntesting set is 5:1. Note that all sensitive or private informa-\ntion has been filtered out from the data.\nBaseline. To provide a comprehensive evaluation of our\nGLRec model, we compare it against both LLM-based\nand related representative job recommendation methods.\nRobertaRec (Liu et al. 2019): Candidate resume and JD\ntext are encoded into fixed-length vectors using RoBERTa\nand then used to calculate similarity scores, enabling per-\nsonalized recommendations. HGT (Hu et al. 2020): Het-\nerogeneous Graph Transformer is a powerful graph learn-\ning model which propagates the embeddings (initialized\nby RoBERTa) of candidates and jobs on graph to capture\nhigh-order interactions. DPGNN (Yang et al. 2022): The\nadvanced job recommender Dual-Perspective GNN incor-\nporates two different nodes for each candidate (or job) to\nmodel the two-way selection preference. TALLrec (Bao\net al. 2023): An advanced fine-tuned LLM recommender\nthat uses instruction tuning on self-instruct data with users‚Äô\nhistorical interactions. We change its backbone to BELLE\nthe same as ours for the Chinese corpus.\nEvaluation Metric. We evaluate the two tasks using the\nconventional metric: Area Under the Receiver Operating\nCharacteristic (AUC), as our two tasks can be transferred to\nbinary classification problems. We do not employ ranking-\nbased metrics because, during the fine-tuning process, the\ntext sequence output of LLM requires ground truth for item\norder sequences, which, in reality, doesn‚Äôt exist.\nImplementation Details. In this paper, we utilize\nBELLE-LLaMA-7B (Ji et al. 2023) as the pre-trained\nLLM backbone due to its expanded Chinese vocabulary.\nThe instruction-tuning and model inference, using LoRa,\nare conducted on Tesla A100 80G GPUs. To ensure\nconsistent sequence inputs within each batch (batch size\nis 32), we apply padding to sequences with a maximum\nlength of 512. Our approach incorporates the meta-path\nprompt and user-specific task instructions as model inputs\nfor personalized recommendations. In our experiments,\nwe investigate the impact of different numbers of paths,\nspecifically M ‚àà [0, 1, 2, 3], for GLRec, and the shuffled\ntimes m = 2 for M ‚â• 2. In our work, we select paths with\n3 nodes because they offer a balance between meaningful\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n9182\nTask Point-wise Pair\n-wise\nSplit Random OOD position OOD JD Random\nDataset RX R\nY RX R\nY RX R\nY RX R\nY\nRobertaRec 0.710 0.734 0.503 0.528 0.506 0.536 0.727 0.740\nHGT 0.744 0.756 0.572 0.595 0.576 0.593 0.747 0.751\nDPGNN 0.727 0.743 0.596 0.603 0.588 0.617 0.744 0.756\nT\nALLrec 0.842‚àó 0.829‚àó 0.770‚àó 0.788‚àó 0.766‚àó 0.798‚àó 0.849‚àó 0.825‚àó\nGLRec 0.891 0.876 0.810 0.843 0.814 0.852 0.905 0.883\nImprov\ne ‚Üë 18.4% 14.1% 25.2% 28.3% 26.4% 29.8% 15.5% 13.2%\nTable 2: Job recommendation performance of AUC on test set, where ‚àó indicates the best result among baselines. Improve ‚Üë\nrefers to the average enhancement achieved by GLRec in comparison to the baseline models. RX (RY) indicates RecrX (RecrY).\n(a) RecrX\n (b) RecrY\nFigure 3: The impact of meta-path number on performance.\nsemantics and minimal redundancy with the experimental\nfeedback. Further details regarding the path prompt and\ninstructions can be found in the Methodology section.\nAdditionally, both RobertaRec and HGT have a token em-\nbedding dimension of 768, and HGT utilizes mean pooling\nto obtain the initial node embedding. For all methods, we\noptimize model parameters using the Adam (Kingma and\nBa 2014) optimizer with a default learning rate of 1e-4,\nminimizing the MSE loss as the optimization objective. For\nthe hyperparameters of update controller Œª and similarity\nthreshold Œ≥, we set Œª = 0.1 and Œ≥ = 0.3 according to the\nexperimental feedback. We release the code of model‚Ä°.\nPerformance Comparison\nQuantitative Comparison. We conduct quantitative per-\nformance experiments on two datasets. As mentioned in\nthe task definition in Section Methodology, the point-wise\nand pair-wise settings are implemented for evaluation. We\nalso explore the influence of the OOD situation on dif-\nferent models. The experimental split settings of Random,\nOOD\nposition, and OOD JD are introduced below:\n‚Ä¢ Random: We randomly split the training and testing\ndataset based on the interaction records of each user.\n‚Ä¢ OOD\nposition: The intersection on JD‚Äôs ‚Äújob position‚Äù\nfeature between training set and testing set is empty.\n‚Ä¢ OOD JD: The intersection on JD items between the\ntraining set and the testing set is empty.\n‚Ä°https://github.com/WLiK/GLRec\nOur experimental results are reported in Table 2. Over-\nall, our proposed GLRec model achieves the best perfor-\nmance among all baselines. There are distinctive score gaps\nbetween GLRec and all baselines according to the improve-\nment in Table 2. It demonstrates the superiority and adapt-\nability of the large-scale model framework that incorporates\nrelationship understanding and extensive semantic knowl-\nedge in the job recommendation scenario. What‚Äôs even\nmore exciting is that GLRec demonstrates impressive per-\nformance on OOD tasks. While its performance may de-\ncline slightly compared to the random setting, our model\nachieves a significant breakthrough compared to other mod-\nels, which essentially results in near-random guessing. This\nphenomenon illustrates the necessity of utilizing knowl-\nedge association for model generalization. Going deeper\ninto the part of baselines, the graph-based HGT and DPGNN\noutperform the conventional dual-tower matching model\n(RobertaRec) in the context of job recommendation, which\nfurther proves the significance of learning relationships.\nWhat‚Äôs more, we find that most models perform better on\nthe pair-wise task than that of point-wise task. That is to\nsay, directly determining whether an item is suitable is more\nchallenging than comparing its priority with another item.\nQualitative Comparison. To give a more intuitive visu-\nalization, some qualitative comparison results produced by\nmodels are shown in Table 3. Specifically, the first two rows\nare straightforward, allowing multiple models to predict ac-\ncurately. In the third row, solely using the user‚Äôs profile\nisn‚Äôt sufficient for prediction. It‚Äôs crucial to note that the\nJA V A position (Node 1) the user interacted with aligns well\nwith the target job in skill requirements. Consequently, only\nTALLrec and GLRec produced correct predictions. The fi-\nnal row emphasizes the significance of higher-order interac-\ntions, i.e., path, in LLM recommendations. Although there‚Äôs\na perceived mismatch between the candidate‚Äôs finance ma-\njor and the target job, interactions within the testing engineer\nand fintech sectors provide nuanced hints. For such complex\ncases, while the TALLrec model, relying on past behaviors,\nerrs, only the GLRec model predicts correctly.\nThe Impact of Meta-path Number\nWe investigate the impact of meta-path number on the ef-\nfectiveness of GLRec. Here we evaluate the point-wise per-\nformance on Random setting using AUC for different num-\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n9183\nCandidate Node 1\n(Job) Node 2\n(Job Seeker) Tar\nget Job GT Rob T\nALL GLRec\nBachelor‚Äôs\ndegree,\nComputer Science,\n3 years of work\nexperience, skills...\nFront-end De\nveloper,\nSkill requirements:\nJavaScript / HTML5 /\nVue\nBachelor‚Äôs\ndegree,\nComputer Applications\nTech, Work experi-\nence: 2 years, skills...\nJav\na, Qualification: Bachelor‚Äôs\ndegree, 5-10 years experience,\nSkill requirements: Java/System\nArchitecture/Database\nNo No No\nNo\nBachelor‚Äôs\ndegree,\nBusiness Administra-\ntion, 9 years of work\nexperience, skills...\nProject Assistant,\nSkill\nrequirements:\nProject Engineering\nManagement\nBachelor‚Äôs\ndegree, In-\nternational Economics,\n3 years of work experi-\nence, skills...\nProject Assistant,\nQualification:\nBachelor‚Äôs degree, 3 years or\nmore, Skill requirements: Project\nEngineering Management\nYes Yes\nYes Yes\nBachelor‚Äôs\ndegree,\nComputer Applica-\ntions Tech, 2 years of\nexperience, skills...\nJA\nV A, Skill require-\nments: JA V A / Spring\n/ Team Management\nExperience\nAssociate‚Äôs\ndegree, In-\nternet of Things Tech,\n4 years of work experi-\nence, skills...\nFull Stack,\nQualification: Asso-\nciate‚Äôs degree, 1-3 years of work\nexperience, Skill requirements:\nJA V A / Spring / HTML\nYes No Y\nes Yes\nBachelor‚Äôs\ndegree,\nFinance, 10 years\nof work experience,\nskills...\nFunction T\nesting,\nSkill requirements:\nSoftware Testing / Re-\nquirement Alignment\nBachelor‚Äôs\ndegree, Fi-\nnancial Engineering, 2\nyears of work experi-\nence, skills...\nTest\nEngineer, Qualification:\nBachelor‚Äôs degree, 3 years of\nwork experience, Skill require-\nments: Functional/Unit Testing\nYes No No\nYes\nTable 3: Some representative cases of our implemented models in the performance comparison experiment. Node 1 and Node\n2 denote the nodes in a sampled meta-path of Candidate. RobRec denotes RobertaRec, and GT denotes Ground Truth.\n(a) 2 paths\n (b) 3 paths\nFigure 4: The Impact of Bias of Meta-path Prompt.\nbers of meta-paths, ranging from 0 to 3. We also input the\nmeta-path prompt (removing extra instruction text for fea-\nture conciseness) into RobertaRec for comparison. From the\nline graph of Figure 3, we can observe the following trends:\n‚Ä¢ For GLRec, the results consistently increase as the num-\nber of meta-paths increases.\n‚Ä¢ One notable observation is the significant improvement\nin GLRec‚Äôs performance when transitioning from 0\nmeta-paths to 1 meta-path, and achieving the peak with\nonly 2 or 3 meta-paths. The core increases from 0.71 to\n0.88, indicating a substantial boost in recommendation\neffectiveness. This improvement suggests that the chain-\nof-thought ability of the LLM, inspired by in-context\nlearning, plays a crucial role in GLRec‚Äôs performance.\n‚Ä¢ For RobertaRec, which does not incorporate behavior\ngraph understanding, the values remain relatively stable\nacross different meta-path numbers. The reason is that\ndiscriminative BERT-based model lacks the ability to ef-\nfectively understand prompts like generative LLMs.\nThe results indicate that the inclusion of behavior graph un-\nderstanding through meta-path prompt has a significant pos-\nitive impact on the effectiveness of GLRec.\nThe Impact of Bias of Meta-path Prompt\nDue to the sequential nature of language model input, the\nconstruction of multi-path prompt sequences results in a\nhuman-induced position bias, or order bias, which disrupts\nthe final decision-making of LLM model. Additionally, this\ninput pattern does not allow the model to learn the impor-\ntance of semantic information in different paths. Therefore,\nwe design a path shuffle mechanism, a path soft selector, and\na hybrid mechanism combining both to enhance the model‚Äôs\nunderstanding of path information and mitigate bias. The ex-\nperimental results on RecrX are reported in Figure 4. Here\nthe metric is AUC and the task is point-wise setting.\nAccording to Figure 4, our three strategies can all surpass\nthe original input without path prompt augmentation in both\ntwo sub-experiments, which proves the necessity of path de-\nbiasing. Although the shuffle mechanism and soft selector\nhave their own advantages and disadvantages in two differ-\nent path scale experiments, both can relatively improve the\nquality of the results. And the hybrid module of both can\nbring more stable results, indicating that it is indeed nec-\nessary for the model to consider the position factors of in-\nput meta-paths and the influencing factors of different path\nprompts on decision-making in experiments, in order to cope\nwith actual recommendation scenarios. Actually, in other\nsimilar scenarios, such as the input for LLM consists of\nmultiple sentence prompts without prior order, our proposed\nshuffle mechanism and the soft selector can both play a cer-\ntain role in enhancing the robustness of model training.\nConclusion\nIn conclusion, we introduced GLRec, a pioneering job rec-\nommendation model that seamlessly integrated large lan-\nguage models (LLMs) with behavior graph comprehen-\nsion. The innovative meta-path prompt constructor effec-\ntively translated the intricate interaction details into natu-\nral language prompts, thereby refining personalized recom-\nmendation strategies. In the testing stage, rigorous evalua-\ntions affirmed GLRec‚Äôs efficacy, highlighting its dominant\nperformance across real-world datasets. This investigation\nnot only propelled the evolution of LLM-centric recommen-\ndations but also charted fresh avenues for harnessing graph\ndata in enhancing the personalized capabilities of LLMs.\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n9184\nAcknowledgments\nThis research was partially supported by grants from Na-\ntional Key Research and Development Program of China\n(Grant No. 2021YFF0901003).\nReferences\nBao, K.; Zhang, J.; Zhang, Y .; Wang, W.; Feng, F.; and\nHe, X. 2023. TALLRec: An Effective and Efficient Tuning\nFramework to Align Large Language Model with Recom-\nmendation. CoRR, abs/2305.00447.\nBian, S.; Chen, X.; Zhao, W. X.; Zhou, K.; Hou, Y .; Song,\nY .; Zhang, T.; and Wen, J.-R. 2020. Learning to match jobs\nwith resumes from sparse interaction data using multi-view\nco-teaching network. In Proceedings of the 29th ACM Inter-\nnational Conference on Information & Knowledge Manage-\nment, 65‚Äì74.\nCui, Z.; Ma, J.; Zhou, C.; Zhou, J.; and Yang, H. 2022.\nM6-Rec: Generative Pretrained Language Models are Open-\nEnded Recommender Systems. CoRR, abs/2205.08084.\nDai, D.; Sun, Y .; Dong, L.; Hao, Y .; Sui, Z.; and Wei, F.\n2022. Why Can GPT Learn In-Context? Language Mod-\nels Secretly Perform Gradient Descent as Meta-Optimizers.\nCoRR, abs/2212.10559.\nFu, B.; Liu, H.; Zhu, Y .; Song, Y .; Zhang, T.; and Wu,\nZ. 2021. Beyond matching: Modeling two-sided multi-\nbehavioral sequences for dynamic person-job fit. In\nDatabase Systems for Advanced Applications: 26th Inter-\nnational Conference, DASFAA 2021, Taipei, Taiwan, April\n11‚Äì14, 2021, Proceedings, Part II 26, 359‚Äì375. Springer.\nHou, Y .; Zhang, J.; Lin, Z.; Lu, H.; Xie, R.; McAuley,\nJ. J.; and Zhao, W. X. 2023. Large Language Models\nare Zero-Shot Rankers for Recommender Systems. CoRR,\nabs/2305.08845.\nHu, E. J.; Shen, Y .; Wallis, P.; Allen-Zhu, Z.; Li, Y .; Wang,\nS.; Wang, L.; and Chen, W. 2021. Lora: Low-rank adaptation\nof large language models. arXiv preprint arXiv:2106.09685.\nHu, Z.; Dong, Y .; Wang, K.; and Sun, Y . 2020. Heteroge-\nneous graph transformer. In Proceedings of the web confer-\nence 2020, 2704‚Äì2710.\nJi, Y .; Deng, Y .; Gong, Y .; Peng, Y .; Niu, Q.; Ma, B.; and\nLi, X. 2023. BELLE: Be Everyone‚Äôs Large Language model\nEngine. https://github.com/LianjiaTech/BELLE.\nJiang, J.; Zhao, H.; He, M.; Wu, L.; Zhang, K.; and Fan,\nJ. 2023. Knowledge-Aware Cross-Semantic Alignment for\nDomain-Level Zero-Shot Recommendation. In Proceedings\nof the 32nd ACM International Conference on Information\nand Knowledge Management, 965‚Äì975.\nKang, W.; Ni, J.; Mehta, N.; Sathiamoorthy, M.; Hong, L.;\nChi, E. H.; and Cheng, D. Z. 2023. Do LLMs Understand\nUser Preferences? Evaluating LLMs On User Rating Predic-\ntion. CoRR, abs/2305.06474.\nKenthapadi, K.; Le, B.; and Venkataraman, G. 2017. Per-\nsonalized Job Recommendation System at LinkedIn: Practi-\ncal Challenges and Lessons Learned. In Proceedings of the\nEleventh ACM Conference on Recommender Systems.\nKingma, D. P.; and Ba, J. 2014. Adam: A method for\nstochastic optimization. arXiv preprint arXiv:1412.6980.\nLe, R.; Hu, W.; Song, Y .; Zhang, T.; Zhao, D.; and Yan, R.\n2019. Towards effective and interpretable person-job fitting.\nIn Proceedings of the 28th ACM International Conference\non Information and Knowledge Management, 1883‚Äì1892.\nLiu, Y .; Ott, M.; Goyal, N.; Du, J.; Joshi, M.; Chen, D.;\nLevy, O.; Lewis, M.; Zettlemoyer, L.; and Stoyanov, V .\n2019. Roberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nLu, Y .; El Helou, S.; and Gillet, D. 2013. A recommender\nsystem for job seeking and recruiting website. In Proceed-\nings of the 22nd International Conference on World Wide\nWeb.\nLuo, Y .; Zhang, H.; Wen, Y .; and Zhang, X. 2019. Re-\nsumegan: An optimized deep representation learning frame-\nwork for talent-job fit via adversarial learning. In Proceed-\nings of the 28th ACM international conference on informa-\ntion and knowledge management, 1101‚Äì1110.\nPenha, G.; and Hauff, C. 2020. What does BERT know\nabout books, movies and music? Probing BERT for Con-\nversational Recommendation. In RecSys, 388‚Äì397. ACM.\nQin, C.; Zhu, H.; Xu, T.; Zhu, C.; Jiang, L.; Chen, E.; and\nXiong, H. 2018. Enhancing person-job fit for talent recruit-\nment: An ability-aware neural network approach. In The\n41st international ACM SIGIR conference on research & de-\nvelopment in information retrieval, 25‚Äì34.\nQiu, Z.; Wu, X.; Gao, J.; and Fan, W. 2021. U-BERT: Pre-\ntraining User Representations for Improved Recommenda-\ntion. In AAAI, 4320‚Äì4327. AAAI Press.\nRamanath, R.; Inan, H.; Polatkan, G.; Hu, B.; Guo, Q.;\nOzcaglar, C.; Wu, X.; Kenthapadi, K.; and Geyik, S. C.\n2018. Towards deep and representation learning for talent\nsearch at linkedin. In Proceedings of the 27th ACM Interna-\ntional Conference on Information and Knowledge Manage-\nment, 2253‚Äì2261.\nShen, D.; Zhu, H.; Zhu, C.; Xu, T.; Ma, C.; and Xiong, H.\n2018. A joint learning approach to intelligent job interview\nassessment. In IJCAI, volume 18, 3542‚Äì3548.\nWu, C.; Wu, F.; Yu, Y .; Qi, T.; Huang, Y .; and Xie, X.\n2021a. Userbert: Contrastive user model pre-training. arXiv\npreprint arXiv:2109.01274.\nWu, L.; Li, Z.; Zhao, H.; Liu, Q.; Wang, J.; Zhang, M.; and\nChen, E. 2021b. Learning the implicit semantic representa-\ntion on graph-structured data. In Database Systems for Ad-\nvanced Applications: 26th International Conference, DAS-\nFAA 2021, Taipei, Taiwan, April 11‚Äì14, 2021, Proceedings,\nPart I 26, 3‚Äì19. Springer.\nWu, L.; Zheng, Z.; Qiu, Z.; Wang, H.; Gu, H.; Shen, T.;\nQin, C.; Zhu, C.; Zhu, H.; Liu, Q.; et al. 2023. A Survey\non Large Language Models for Recommendation. arXiv\npreprint arXiv:2305.19860.\nYan, R.; Le, R.; Song, Y .; Zhang, T.; Zhang, X.; and Zhao,\nD. 2019. Interview Choice Reveals Your Preference on the\nMarket: To Improve Job-Resume Matching through Profil-\ning Memories. In Proceedings of the 25th ACM SIGKDD\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n9185\nInternational Conference on Knowledge Discovery & Data\nMining.\nYang, C.; Hou, Y .; Song, Y .; Zhang, T.; Wen, J.-R.; and\nZhao, W. X. 2022. Modeling Two-Way Selection Prefer-\nence for Person-Job Fit. In Sixteenth ACM Conference on\nRecommender Systems.\nYu, Y .; Liu, Q.; Wu, L.; Yu, R.; Yu, S. L.; and Zhang, Z.\n2023. Untargeted attack against federated recommendation\nsystems via poisonous item embeddings and the defense.\nIn Proceedings of the AAAI Conference on Artificial Intel-\nligence, volume 37, 4854‚Äì4863.\nZhang, J.; Xie, R.; Hou, Y .; Zhao, W. X.; Lin, L.; and Wen, J.\n2023. Recommendation as Instruction Following: A Large\nLanguage Model Empowered Recommendation Approach.\nCoRR, abs/2305.07001.\nZhang, Z.; and Wang, B. 2023. Prompt Learning for News\nRecommendation. arXiv preprint arXiv:2304.05263.\nZhao, C.; Zhao, H.; Li, X.; He, M.; Wang, J.; and Fan,\nJ. 2023. Cross-Domain Recommendation via Progressive\nStructural Alignment. IEEE Transactions on Knowledge\nand Data Engineering.\nZheng, Z.; Qiu, Z.; Hu, X.; Wu, L.; Zhu, H.; and Xiong, H.\n2023. Generative Job Recommendations with Large Lan-\nguage Model. arXiv:2307.02157.\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n9186",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6075263023376465
    },
    {
      "name": "Data science",
      "score": 0.48000186681747437
    },
    {
      "name": "Graph",
      "score": 0.4501292407512665
    },
    {
      "name": "Theoretical computer science",
      "score": 0.2881319224834442
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I126520041",
      "name": "University of Science and Technology of China",
      "country": "CN"
    }
  ],
  "cited_by": 46
}