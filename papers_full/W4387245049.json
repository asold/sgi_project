{
    "title": "A Conceptual Framework for Subdomain Specific Pre-Training of Large Language Models for Green Claim Detection",
    "url": "https://openalex.org/W4387245049",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A4316972903",
            "name": "Wayne Moodaley",
            "affiliations": [
                "University of Johannesburg"
            ]
        },
        {
            "id": "https://openalex.org/A2793736102",
            "name": "Arnesh Telukdarie",
            "affiliations": [
                "University of Johannesburg"
            ]
        },
        {
            "id": "https://openalex.org/A4316972903",
            "name": "Wayne Moodaley",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2793736102",
            "name": "Arnesh Telukdarie",
            "affiliations": [
                "University of Johannesburg"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3034640977",
        "https://openalex.org/W4220918998",
        "https://openalex.org/W3130294547",
        "https://openalex.org/W3029489574",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W4287029154",
        "https://openalex.org/W3046375318",
        "https://openalex.org/W4287812619",
        "https://openalex.org/W3195432942",
        "https://openalex.org/W3141026600",
        "https://openalex.org/W4210275888",
        "https://openalex.org/W4212810721",
        "https://openalex.org/W3102372119",
        "https://openalex.org/W3178301733",
        "https://openalex.org/W4224238808",
        "https://openalex.org/W3121560857",
        "https://openalex.org/W3008110089",
        "https://openalex.org/W4311728218",
        "https://openalex.org/W2556144780",
        "https://openalex.org/W2553425616",
        "https://openalex.org/W4296250683",
        "https://openalex.org/W2802994264",
        "https://openalex.org/W2179496157",
        "https://openalex.org/W4224442790",
        "https://openalex.org/W3211024016",
        "https://openalex.org/W4283219089",
        "https://openalex.org/W4298110867"
    ],
    "abstract": "Detection of false or misleading green claims (referred to as “greenwashing”) within company sustainability disclosures is challenging for a number of reasons, which include the textual and qualitative nature, volume, and complexity of such disclosures. In recent years, notable progress made in the fields of artificial intelligence and specifically, large language models (LLMs), has showcased the capacity of these tools to effectively analyse extensive and intricate textual data, including the contents of sustainability disclosures. Transformer-based LLMs, such as Google’s BERT architecture, were trained on general domain text corpora. Subsequent research has shown that further pre-training of such LLMs on specific domains, such as the climate or sustainability domains, may improve performance. However, previous research often uses text corpora that exhibit significant variation across topics and language and which often consist of heterogeneous subdomains. We therefore propose a conceptual framework for further pre-training of transformer based LLMs using text corpora relating to specific sustainability subdomains i.e. subdomain specific pre-training. We do so as a basis for the improved performance of such models in analysing sustainability disclosures. The main contribution is a conceptual framework to advance the use of LLMs for the reliable identification of green claims and ultimately, greenwashing.&#x0D; Keywords: greenwashing, artificial intelligence, sustainability, sustainability reporting, sustainability disclosures.",
    "full_text": "European Journal of Sustainable Development (2023), 12, 4, 319-329               ISSN: 2239-5938 \nDoi: 10.14207/ejsd.2023.v12n4p319 \n \n|1Senior Lecturer in Accounting and Financial Management at the Johannesburg Business School, University \nof Johannesburg. \n2Professor of Digital Business at the Johannesburg Business School, University of Johannesburg.  \n \n \n \nA Conceptual Framework for Subdomain Specific Pre -\nTraining of Large Language Models for Green Claim \nDetection \n \nBy Wayne Moodaley1, Arnesh Telukdarie2 \n \n \nAbstract  \nDetection of false or misleading green claims (referred to as “greenwashing”) within company \nsustainability disclosures is challenging for a number of reasons, which include the textual and \nqualitative nature, volume, and complexity of such disclosures. In recent years, notable progress made \nin the fields of artificial intelligence and specifically, large language models (LLMs), has showcased the \ncapacity of these tools to effectively analyse extensive and intricate textual data, including the contents \nof sustainability disclosures. Transformer -based LLMs, such as Google’s BERT architecture, were \ntrained on general domain text corpora. Subsequent research has shown that further pre -training of \nsuch LLMs on specific domains, such as the climate or sustainabil ity domains, may improve \nperformance. However, previous research often uses text corpora that exhibit significant variation \nacross topics and language and which often consist of heterogeneous subdomains. We therefore \npropose a conceptual framework for furt her pre -training of transformer based LLMs using text \ncorpora relating to specific sustainability subdomains i.e. subdomain specific pre -training. We do so \nas a basis for the improved performance of such models in analysing sustainability disclosures. The \nmain contribution is a conceptual framework to advance the use of LLMs for the reliable identification \nof green claims and ultimately, greenwashing. \n \nKeywords: greenwashing, artificial intelligence, sustainability, sustainability reporting, sustainability disclosures. \n \n \n1. Introduction \n \n Companies are facing growing pressure from investors, customers, and other \nstakeholders around the world to provide transparency regarding the impact of their \noperations on environmental, social, and governance (ESG) factors, and their efforts and \nperformance in dealing with ESG and climate challenges (JSE Limited, 2021).  \nThe increased stakeholder focus on sustainability has resulted in increased pressure on \ncompanies to present an image of sustainability and corporate citizenship. This has \nmanifested in a trend of deceptive disclosures regarding company sustainability practices \nand performance – referred to as “greenwashing” – has emerged (Siano et al., 2017).  \nGreenwashing, as the European Commission states, “misleads market actors and does not \ngive due advantage to those companies that are making the effort to green their products \nand activities. It ultimately leads to a less green economy” (European Commission, 2020). \nThe implication is that greenwashing threatens the objectives of both company \n320                                                    European Journal of Sustainable Development (2023), 12, 4, 319-329 \nPublished  by  ECSDEV,  Via dei  Fiori,  34,  00172,  Rome,  Italy                                                     http://ecsdev.org \nsustainability initiatives, as well as the objectives of sustainability reporting, given the \nincongruence of the practice of greenwashing with those objectives.  \nDetection of greenwashing within company sustainability disclosures is challenging, for a \nnumber of reasons which include the textual and qualitative nature of company disclosures \nand the volume and complexity of such disclosures (In & Schumacher, 2021) (Macpherson \net al., 2021).  \nRapid and sustained progress made in the field of artificial intell igence (AI), and LLMs \nwhich use natural language processing (NLP), has demonstrated the ability of these \ntechnologies to effectively analyse large volumes of frequently complex text corpora, \nincluding those containing or consisting of sustainability disclosures.  \nMore recently, the emergence of pre -trained transformer-based large language models \n(LLMs), such as Google’s BERT architecture, has fundamentally transformed the practice \nand use of NLP techniques. The innovative aspect of the architecture lies in its utilization \nof a bi-layer transformer architecture, which incorporates an attention -based mechanism \nto effectively capture contextual relationships among words. This enables the achievement \nof unsupervised learning by integrating both text input and ou tput within a decoder -\nencoder framework.  \nTransformer models have brought about a new era in NLP, where these models undergo \na \"pre-training\" phase on semi-supervised tasks prior to fine-tuning for downstream tasks \n– an approach that enables the models to acquire a broader understanding of language \npatterns and structures, thereby enhancing their performance on specific tasks \n(Gururangan et al., 2020). The work of Devlin et al (2019) and Huang et al  (2023) have \nhighlighted the ability of these LLMs i n evaluating analyse extensive and intricate textual \ninformation, including sustainability disclosures. \nWhile LLMs trained on domain -specific corpora have been shown to provide superior \nperformance, there is no literature which explores subdomain specific pretraining of LLMs \n– this despite the fact that numerous studies, such as that conducted by Trewartha et al \n(2022) and Zheng (2022), demonstrate that fine -tuning models with more specific pre -\ntraining leads to enhanced performance outcomes. We therefo re develop a subdomain -\nspecific conceptual framework for LLMs pretrained on subdomain -specific text corpora, \nspecifically in relation to the analysis of sustainability disclosures for greenwashing \ndetection. \n \n2. Overview of related work \n  \n2.1. Sustainability reporting and greenwashing \n  Sustainability reporting is a term used to describe various forms of reporting on \nsustainability factors. According to Jestratijevic (2022) et al. sustainability reporting refers \nto a company's “voluntary, non -financial disclosure of the social and environmental \nimpacts of their business.” In contrast, greenwashing is “an umbrella term for a variety of \nmisleading communications and practices that intentionally or not, induce false positive \nperceptions of an organization's environmental performance” (Nemes et al., 2022). Lyon \nand Maxwell (2011) define greenwashing as “selective disclosure of positive information \nabout a company’s environmen tal or social performance, without full disclosure of \n                                               W. Moodaley, A. Telukdarie                                                              321 \n© 2023 The Authors. Journal Compilation    © 2023 European Center of Sustainable Development.  \n \nnegative information on these dimensions, so as to create an overly positive corporate \nimage”. \nThe detrimental effects of greenwashing on sustainability efforts have been widely \nacknowledged by numerous industry and regulatory agencies and stakeholders. Testa et al. \n(2015) affirm this when stating that that greenwashing undermines both \"corporate \naccountability” and “the credibility of environmental initiatives\". Greenwashing poses a \nthreat to the precision, dependability, and openness of company sustainability disclosures \ndue to the fundamental difference between a company's disclosure (and signal ling) to \nstakeholders about its ESG performance, and its practices. This discrepancy is described \nby Steiner et al. (2018) as the \"incongruence between the reputational intention and the \nactual, real sustainability performance of the company.\" The practi ce of greenwashing \nposes a threat to a diverse range of stakeholders, from public entities, to consumers, \nregulators, shareholders, and potential investors. \n \n2.2. Greenwashing \n  Greenwashing encompasses a broad spectrum of misleading practices, ranging \nfrom outright lies or false claims, to vague statements, selective or omitted disclosures, \nunsubtantiated claims, empty or exaggerated claims, and even use of environmental jargon \nthat is difficult to understand. (de Freitas Netto et al., 2020; Nemes et al., 2022).  \nThis diversity is acknowledged in the academic literature relating to the field. de Freitas \nNetto et al (2020) differentiate between firm -level and product level environmental or \ngreen claims, whilst also situating greenwashing within extant litera ture which defines \ngreenwashing in terms of selective disclosures or decoupling behaviours. Nemes et al \n(2022) develop an integrated greenwashing taxonomy, which include, inter alia, \nunsubstantiated claims, claims that are vague, broad or poorly understo od, claims that \nexaggerate achievements, and claims that use jargon that consumers are unable to parse or \nverify. In light of the widely publicised Volkswagen emissions scandal, in which \nVolkswagen deliberately manipulated vehicle emissions tests results u sing in -house \nsoftware, Siano et al (2017)  propose an extension of the greenwashing taxonomy to \ninclude a new category, “deceptive manipulation”. \nExamples of greenwashing span the spectrum from the “deceptive manipulation” by \nVolkswagen, involving infor mation relating to software that was not initially publicly \navailable, to the European Commission’s study of product and advertising green claims by \ncompanies, which found that that 53.3% of the items analysed “provide vague, misleading \nor unfounded information on products’ environmental characteristics”(Pimonenko et al., \n2020)(European Commission, 2023). Other examples include Li et al’s (2022)examination \nof the gap between fossil fuel companies’ decarbonisation communications and actions, \nusing keyw ord analysis, and categorisation of pledge s and actions found in company \nsustainability disclosures. \n \n2.3. Greenwashing detection \n  Despite the significant negative impact that greenwashing may have, its detection \nin company sustainability disclosures remains challenging. The increase in company \nsustainability information makes it more challenging for stakeholders to manually analyse \nsustainability reports and detect greenwashing (Pimonenko et al., 2020) . There is both \n322                                                    European Journal of Sustainable Development (2023), 12, 4, 319-329 \nPublished  by  ECSDEV,  Via dei  Fiori,  34,  00172,  Rome,  Italy                                                     http://ecsdev.org \nmore information for stakeholders to analyse, and that information has become more \ncomplex (Macpherson et al., 2021) . The challenge is compounded when such analyses \nconsider multiple companies’ reports across multiple time -periods (Ning et al., 2021) . \n(2021)Lastly, the textual and qualitative nature of sustainability reporting has in the past \nmade the analysis of such reports to identify greenwashing more challenging (Luccioni et \nal., 2020).  \nHowever, dramatic advancements in AI tools such as machine learning and natural \nlanguage processing (NLP) techniques present the means and opportunity to analyse large \nvolumes of complex company sustainability disclosures  (Luccioni & Palacios, 2019). The \nvalue of NLP in assessing large quantities of text -based sustainability disclosures is \nreflected in the research of Smeuninx et al (2016) , who applied NLP to a “2.75 -million-\nword corpus” to characterize the language of sus tainability reports across specific \ndimensions. A significant contribution by Kotzian involves the proposition of \nmethodologies for employing AI integrated with machine -learning techniques within the \narea of Corporate Social Responsibility (CSR) to identif y instances of CSR non -\ncompliance.  \nWhile greenwashing may take various forms, a crucial first step in the detection of \ngreenwashing in company sustainability disclosures is the identification of specific \nsustainability-related disclosures; and the second is the identification of environmental \nclaims, commonly referred to “green claims”, made by companies within those disclosures \n(Kobti et al., 2021)  (Stammbach et al., 2022) . While the identification of sustainability -\nrelated disclosures may seem trivial in theory, in practice, such identification is challenging \nand time consuming due to the volume and complexity of information disclosed by \ncompanies across time periods. \n \n2.4. Large language models \n  The BERT model and its successors, such as ROBERTA, were trained using large \ngeneral text corpora, such as Wikipedia or other Web sources, which contain information \nfrom variety of domains, hereinafter referred to as “general domain” (Zheng et al., 2022). \nThese models provide superior performance in relation to earlier word embedding models, \nsuch as Word2Vec or GLOVE, for downstream tasks such as text classification or \nsentiment analysis (Devlin et al., 2019) (Webersinke et al., 2022) An important limitation \nof these models is, however, their use of general domain text corpora, which, from a \nsemantic and vocabulary perspective, may differ to the semantics and vocabulary of the \ndataset assessed for downstream tasks. \nBuilding on these models, Gururangan et al (2020) showed that further pre-training on a \nspecific domain produced better performance on downstream tasks than LLMS trained \non general domain text corpora, such as BERT. This in turn has led to a trend of domain-\nadaptive or domain -specific pre-training within the literature, where BERT architecture \nbased models are subjected to further pre-training using text corpora drawn from a specific \ndomain, hereinafter referred to as the “main-domain”. Huang et al. (2023) use the BERT \nmodel created by Devlin et al (2019) as a base for further unsupervised pre-training on a \ntext corpus created from analysts’ reports in the financial domain. The resulting model, \nFinbert, is tailored to the finance domain. The model, after being fine -tuned on the \ndownstream task of sentiment analysis, outperforms other deep learning algorithms such \n                                               W. Moodaley, A. Telukdarie                                                              323 \n© 2023 The Authors. Journal Compilation    © 2023 European Center of Sustainable Development.  \n \nas long short -term memory and convolutional neural network LLMs. Other examples \ninclude MatBERT, pretrained on the materials science domain; ClimateBert, pre -trained \non the climat e-related domain, and PubmedBert pre -trained on biomedical domain \n(Huang et al., 2023)    (Gu et al., 2021) (Webersinke et al., 2022).  \nThese domain -specific pre -trained models have been shown to provide superior \nperformance, when compared to general domain models fine-tuned only for downstream \ntasks, when tackling downstream tasks such as text classification or sentiment analysis  \n(Huang et al., 2023). Sanchez et al (2022) find that pre-training BERT models on specific \ndomain text data or corpora  yields superior performance to BERT models trained on \ngeneral corpora and fine-tuned for downstream tasks. \n \n2.5. Pre-trained LLMs in the sustainability domain \n  Luccioni et al (2020) researched the use of NLP to quickly identify sustainability \ndisclosures using the Task Force on Climate -Related Financial Disclosures (T CFD) \nframework, and in so doing developed an NLP tool, Climate QA to meet that objective. \nTo do so, a RoBERTa model was pretrained on a text corpus that included both financial \nand sustainability information, sourced from Global Reporting Initiative and Edgar \ndatabases. Bingler et al (2021) developed and used a pre-trained RoBERTa based language \nmodel, ClimateBert, to identify TCFD disclosures in more than eight-hundred companies \napplying TCFD. The model used a text corpus consisting of company webpages, TCFD \nreports, sustainability reports, and annual reports.  Webersinke et al developed a different \nClimateBert model, pre-trained on specific and general climate-related text.  Cojoianu et al \n(2020) as part of their research developed Greenwatch.ai to monitor the authenticity of \nclimate-friendly green claims relating to greenhouse gas (GHG) emissions.  \nThe variation in text corpora used for each of these studies illustrates the diversity of the \nsustainability-domain from a language perspective, and similarly, how large and diverse \neven main domain corpora used to train these models can be. \n \n2.6. Subdomains \n  Text corpora used for pre-training LLMs, even if related to a main domain, may \nexhibit significant internal heterogeneity or consist of subdomains, which in essence \nrepresent a different data distribution to that of the main domain (Zheng et al., 2022). As \nnoted by Aharoni et al (2020), language exhibits substantial variability across classes, \ncategories, and topics. \nSubdomains may arise based on the source of the text. For example, text corpora from \nsustainability-related news articles differ to academic research articles, which in turn differ \nto company -created sustainability reports and analysts’ reports. Another source of \nsubdomains relates to taxonomies, typologies, and topics. For example, text corpora drawn \nfrom sustainability -related disclosures created in terms of the TCFD disclosures may \nexhibit differences to those drawn from Global Reporting Initiative Standards. Each of \nthese specific elements, such as text source or typology, represent a subdomain within the \nbroader climate domain. Another e xample relates to sub -categories within the climate \ndisclosures domain, such as biodiversity, renewable energy, water and emissions. \nDespite these linguistic nuances and their possible impact on the performance of LLMs \nwithin a specific domain, current lit erature does not provide sufficient resolution on the \n324                                                    European Journal of Sustainable Development (2023), 12, 4, 319-329 \nPublished  by  ECSDEV,  Via dei  Fiori,  34,  00172,  Rome,  Italy                                                     http://ecsdev.org \npotential to extend the pre -training of pre -trained LLMs using subdomain -specific \ncorpora. To address this, we develop a conceptual framework for subdomain -specific \npretraining of BERT based LLMs using sustainability subdomain-specific text corpora. \n \n2.7. Summary \n  Extant literature indicates that AI tools such as LLMS provide the potential for \nthe rapid, automatic identification of specific green claims within company sustainability \ndisclosures. This potential exists within the confines of the current capabilities of LLMs, \nas well the data available, such as publicly available company sustainability disclosures. In \naddition, because of the range of types and forms of greenwashing, including deceptive \nmanipulation examples such as the Volkswagen emissions scandal, LLMs do not provide \na panacea for greenwashing detection. However, a crucial first step on the road to reliable \nand efficient greenwashing detection is automated identification of green claims within  \nlarge volumes of sustainability disclosures, for which a conceptual framework utilising \nLLMS for targeted, sub -domain specific identification of green claims in this regard is \ndeveloped. \n \n3. Research methodology: Conceptual Framework \n \n  The conceptual framework extends the previous attempts discovered in the \nliterature relating to domain-specific pretraining. The goal is the creation of a pre -trained \nLLM, further pretrained on a subdomain specific text corpus – hereinafter referred to as \nan SPM – capable of identifying sustainability -related statements that are specific to the \nsubdomain. The sequencing workflow for the model is shown in Figure 1 below: \nMain domain \nmodel\nText corpora \nattributes\n• Distinct \nsubdomain\n• Vocabulary \noverlap < 55%\n• Sufficiently large\nModel \nenhancement\nEnhanced \nmain domain \nmodel\nModel pre-training\nModel vocabulary \nenhancements\n• Adding of tokens \nfor words \npresent in \nsubdomain but \nnot main domain\nModel pretraining \n• Uses unlabeled \nSTC dataset\nPre-trained \nsubdomain \nmodel\nModel downstream \ntask training\n• Text \nclassification \ntask\n• Uses labelled \nsubdomain-\nspecific dataset\nSubdomain-\nspecific \npretrained \nmodel\nMain domain\nModel\nModel attributes\n• BERT-based \nmodel\n• Pre-trained on \nmain-domain \ntext corpus\nDownstream task \ntraining\n1a) Model \narchitecture \nselection\n1b) Subdomain \nspecific text \ncorpus (STC) \ncreation\n \nFigure 1: Sequencing workflow for model \n                                               W. Moodaley, A. Telukdarie                                                              325 \n© 2023 The Authors. Journal Compilation    © 2023 European Center of Sustainable Development.  \n \n \n3.1. Text corpora creation \nThe first step in the con ceptual model is the selection of an appropriate \nsubdomain text corpora (STC). Previous literature reflects models trained on text corpora \nfrom specific main domains (e.g. materials science domain, financial domain etc .) rather \nthan subdomains. For example, Finbert is trained on the general financial domain, rather \nthan on a specific subdomain of that domain, such as IFRS disclosures. \nGiven the significant effect of the choice of text corpora on the training and performance \nof a selected model demonstrated by other studies, the definition of the characteristics of \nthe subdomain is critical. Therefor for this step, subdomains within sustainability \ndisclosures are constructed. The STC should reflect a distinct subdomain of the specific \ndomain. For example, text corpora drawn from sustainability disclosures created in terms \nof Global Reporting Initiative (GRI) standards would represent a subdomain within the \nbroader sustainability disclosures main domain. The text corpora should also be \nsufficiently large to enable better model performance and to make full use of the selected \nmodel architecture’s capabilities. \nThe degree of vocabulary overlap of the subdomain text corpora, and the main domain \ntext corpora previously used to train the selected model should be asse ssed. Consistent \nwith the approaches of previous domain -specific pretraining, a vocabulary overlap of no \nmore than 55% is recommended to ensure sufficient differences in vocabulary between \nthe subdomain and main domain texts (Sanchez & Zhang, 2022) (Gururangan et al., 2020) \n(Huang et al., 2023; Webersinke et al., 2022).  \n3.2. Model architecture selection \nA concurrent first step in the conceptual framework is the selection of an \nappropriate base model architecture to be used for the creating on the extended model. \nThis conceptual framework builds on the previous demonstrated successes of pretrained \ntransformer based LLMS. This step therefore involves the selection of an appropriate pre-\ntrained transformer based LLM that has previously been pre-trained on the sustainability \ndomain (e.g. ClimateBert, ESGBert etc .). The selected model (main domain model or \nMDM) would then be further pre-trained on a subdomain-specific text corpora specifically \ncreated to extend the selected model. \n \n3.3. Model enhancement \nThe chosen model (MDM) is further enhanced by increasing the model \nvocabulary. This consists of the inclusion of words specific to the STC not present in the \noriginal MDM vocabulary. This is consistent with the work of Webersinke et al. (2022) \nwho find mode l performance improvements as a result of using this technique. \nSpecifically, tokens for words present in the STC and not in the specific domain are added \nto the model’s vocabulary. \n \n3.4. Model pre-training \nThe next step is the pre-training of the model. The selected enhanced vocabulary \nMDM is trained on the large, unlabeled STC, thereby extending the approach first \nproposed by Devlin et al (2019) and modified by Gururangan et al. (2020). In essence, this \ninvolves subdomain -specific pretraining of the selec ted model – which in turn was \n326                                                    European Journal of Sustainable Development (2023), 12, 4, 319-329 \nPublished  by  ECSDEV,  Via dei  Fiori,  34,  00172,  Rome,  Italy                                                     http://ecsdev.org \npreviously trained on a main domain text corpus. The model is also pre -trained on a \ndownstream task, namely, text classification. The results and performance of the extended \nmodel is assessed, based on the loss on a validation  set from the STC. The results and \nperformance are assessed and compared in relation to the results and performance of the \nMDM on the same task, as well as the BERT model underlying the MDM. \n \n3.5. Downstream task training \nLastly, the model is trained (fine-tuned) on a downstream task namely binary text \nclassification. We select binary text classification as our goal is for the model to classify \nbetween text that relates to the subdomain, and text which does not form part of or relate \nto the subdomain. \nThis step requires a labelled subdomain -specific dataset, with each class labelled. Such a \ndataset may be constructed or sourced from existing public repositories. For example, the \nopen-source LLM repository, Huggingface.co, contains a number of LLMs with \nsustainability related labelled datasets that could be used. Again, the performance of the \nmodel in executing the downstream task may be compared to that of the MDM and the \nBERT model underlying the MDM.  \nAs noted by Devlin et al (2019), the hyperparameters for fine-tuning would depend on the \ntask, though the authors suggest epochs of 2, 4, or 6 with batch sizes of 16 or 32 for \nunderlying original BERT model. However, in practice, we find a wide range of \nhyperparameters across pre -trained models in the li terature (Friederich et al., 2021; \nStammbach et al., 2022) , and therefore suggest hyperparameters that are tailored to both \nthe model architecture, text corpus, processing power availability and requirements, and \nplanned environmental impact. \n \n3.6. Model outputs \nThe results of the MDM pretrained on the subdomain specific text corpora are \nthen evaluated and compared from an F1 score perspective and a cross entropy loss \nperspective for the binary text classification task across the three models evaluated: \n- BERT Model (general domain) \n- MDM (main domain) \n- SPM (subdomain-specific and fine-tuned for text classification downstream task) \nOther models may also be chosen for comparison or for a baseline. \n \n4. Discussion \n   \n  The aim of the conceptual framework presen ted is the creation of the SPM i.e. \nthe use of a model architecture previously trained on the main domain, further pre-trained \non the subdomain, and fine -tuned for the downstream task of text classification. This \nresults in a model, SPM, trained more speci fically to identify items within a specific \nsustainability disclosure subdomain. This is the first step toward identifying green claims, \nas once sustainability disclosures are classified as being within the subdomain by the SPM, \nthis narrows the search for  green claims within that subdomain. As the SPM model \narchitecture is an LLM, this paves the way for large datasets to be efficiently parsed to \nallow for such classification and to reduce the time required to identify green claims within \n                                               W. Moodaley, A. Telukdarie                                                              327 \n© 2023 The Authors. Journal Compilation    © 2023 European Center of Sustainable Development.  \n \nsubdomain-specific sustainability disclosures. The result of the text classification task is, in \nessence, a labelled dataset showing text which is classified as in-subdomain or outside the \nsubdomain. That labelled dataset may be used for further studies relating to the use of \nfurther pre-trained LLMS for green claim detection. \n \n5. Conclusion \n \n5.1. Contribution \n  We propose a conceptual framework for an extended domain-specific pre-trained \nmodel, further trained on a specific subdomain. We do so in order to tackle the issue of \ngreenwashing within sustainability disclosures. Within relevant literature, we find that \ngreenwashing is often difficult to detect as a result of the vast volume and complexity of \nsustainability disclosures, and because there exists a wide-range of greenwashing or green \nclaim typologies. However, we also find within the literature that AI tool s such as LLMs \nprovide the potential to automate the identification of green claims. The accuracy of the \noutputs of such models relies on the correct choice of model, as well as the process by \nwhich such models are trained. Crucially, the general domain or  domain-specific text \ncorpora used for training LLMs significantly affect the output of these models. We find \nwithin the literature that domains for text corpora used for pre -training such LLMs are \namorphous and often not clearly delineated. We therefore p ropose, as part of the \nconceptual framework, the creation of subdomain specific text corpora, taking into \naccount the heterogeneity of general domain, or domain-specific, text corpora. \nThe conceptual framework provides the following contributions:  \n- the extension of existing BERT-based model architectures previously pre-trained on \nsustainability-related disclosures, \n- a conceptual understanding of the criteria required for selection of subdomain specific \ntext, \n- the creation of subdomain-specific text corpora for model pre-training, \n- the creation of a subdomain specific BERT -based model pre-trained on subdomain \nspecific text (the SPM), and \n- an SPM fine -tuned for the downstream task of text classification, capable of \nidentifying subdomain-specific text. \nThese contributions extend those found in current literature. Finally, we envisage that the \noutput of the text classification task of the SPM is a labelled dataset, providing binary class \nlabels indicating whether specific text is in-subdomain or not.  \n \n5.2. Limitations \n  An inherent limitation of the model, which results from applying the developed \nconceptual framework, is that the model created as a result of further pre-training, is based \nupon the training dataset, which may initially be limited. However, we expect the size and \navailability of such datasets to expand over time as the framework is applied in further \nresearch. A second limitation is that BERT models are based on single word or subword \nassociations. That being said, an inherent benefit is that  BERT models generate bi -\ndirectional contextualised word embeddings. Lastly, we note that any model created by \napplying the conceptual framework would not be suitable for detecting green claims \n328                                                    European Journal of Sustainable Development (2023), 12, 4, 319-329 \nPublished  by  ECSDEV,  Via dei  Fiori,  34,  00172,  Rome,  Italy                                                     http://ecsdev.org \nrelating to all forms of greenwashing, but would, given the na ture of the subdomain and \nconceptual framework, relate to green claims arising from specific subdomains. \n \n6. Acknowledgments \n \n  The authors would like to acknowledge the professional support of the University \nof Johannesburg’s Johannesburg Business School. \nReferences \nAharoni, R., & Goldberg, Y. (2020). Unsupervised Domain Clusters in Pretrained Language Models . Proceedings of \nthe 58th Annual Meeting of the Association for Computational Linguistics . \nhttp://dx.doi.org/10.18653/v1/2020.acl-main.692 \nBingler, J. A., Kraus, M ., & Leippold, M. (2021). Cheap Talk and Cherry -Picking: What ClimateBert has to say on \nCorporate Climate Risk Disclosures . Finance Research Letters, 47(B), 102776. \nhttps://doi.org/10.1016/j.frl.2022.102776 \nCojoianu, T., Hoepner, A. , Ifrim, G., & Lin, Y. (2020, June 15).  Greenwatch-shing: Using AI to Detect \nGreenwashing. AccountancyPlus - CPA Ireland. https://ssrn.com/abstract=3627157 \nde Freitas Netto, S. V., Sobral, M. F. F., Ribeiro, A. R. B., & Soares, G. R. da L. (2020). Concepts and forms of \ngreenwashing: a systematic review . Environmental Sciences Europe, 32(1), 1 –12. \nhttps://doi.org/10.1186/s12302-020-0300-3 \nDevlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of Deep Bidirectional Transformers \nfor Language Understanding. 2019 Conference of the North American Chapter of the Association for \nComputational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), \n4171–4186. https://doi.org/10.18653/v1/N19-1423 \nEuropean Commission. (2020). Environmental performance of products & businesses – substantiating claims . \nhttps://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12511-Environmental-\nperformance-of-products-businesses-substantiating-claims/public-consultation_en \nEuropean Commission. (2023, March 22). Proposal for a Directive on green claims . \nhttps://environment.ec.europa.eu/publications/proposal-directive-green-claims_en \nFriederich, D., Kaack, L. H., Luccioni, A., & Steffen, B. (2021). Automated Identification of Climate Risk Disclosures \nin Annual Corporate Reports. https://doi.org/10.48550/arXiv.2108.01415 \nGu, Y. U., Tinn, R., Cheng, H., Lucas, M., Usuyama, N., Liu, X., Naumann, T., Gao, J., Poon, H., & Gu, Y. \n(2021). Domain-Specific Language Model Pretraining for Biome dical Natural Language Processing . ACM \nTransactions on Computing for Healthcare, 3(1), 1–23. https://doi.org/10.1145/3458754 \nGururangan, S., Marasović, A., Swayamdipta, S., Lo, K., Beltagy, I., Downey, D., & Smith, N. A. (2020, July). \nDon’t Stop Pretrainin g: Adapt Language Models to Domains and Tasks . Proceedings of the 58th Annual \nMeeting of the Association for Computational Linguistics. \nhttps://doi.org/10.48550/arXiv.2004.10964 \nHuang, A. H., Wang, H., & Yang, Y. (2023 ). FinBERT: A Large Language Model for  Extracting Information from \nFinancial Text. Contemporary Accounting Research, 40(2), 806–841. https://doi.org/10.1111/1911-\n3846.12832 \nIn, S. Y., & Schumacher, K. (2021). Carbonwashing: A New Type of Carbon Data-Related ESG Greenwashing. SSRN \nElectronic Journal. https://doi.org/10.2139/SSRN.3901278 \nJestratijevic, I., Uanhoro, J. O., & Creighton, R. (2022). To disclose or not to disclose? Fashion brands’ strategies for \ntransparency in sustainability reporting . Journal of Fashion Marketing and Management, 26(1), 36 –50. \nhttps://doi.org/https://doi.org/10.1108/JFMM-09-2020-0182 \nJSE Limited. (2021). Leading the way for a better tomorrow JSE Sustainability Disclosure Guidance . \nhttps://www.jse.co.za/sites/default/files/media/documents//JSE%20Sustainability%20Disclosu\nre%20Guidance%202021_SPS.pdf \nKobti, J., Schmitt, V., & Woloszyn, V. (2021). Towards Automatic Green Claim Detection; Towards Automatic Green \nClaim Detection. Proceedings of the 13th Annual Meeting of the Forum for Information Retrieval \nEvaluation. https://doi.org/10.1145/3503162.3503163 \n                                               W. Moodaley, A. Telukdarie                                                              329 \n© 2023 The Authors. Journal Compilation    © 2023 European Center of Sustainable Development.  \n \nLi, M., Trencher, G., & Asuka, J. (2022). The clean energy claims of BP, Chevron, ExxonMobil and Shell: A mismatch \nbetween discourse, actions and investments . PL oS ONE, 17(2), e0263596. \nhttps://doi.org/10.1371/journal.pone.0263596 \nLuccioni, A., Baylor, E., & Duchene, N. (2020). Analyzing Sustainability Reports Using Natural Language Processing. \nhttps://doi.org/10.48550/arxiv.2011.08073 \nLuccioni, A., & Palacios, H. (2019). Using Natural Language Processing to Analyze Financial Climate Disclosures . \nhttps://s3.us-east-1.amazonaws.com/climate-change-ai/papers/icml2019/34/paper.pdf \nLyon, T. P., & Maxwell, J. W. (2011). Greenwash: Corporate Environmental Disclosure under Threat of Audit . Journal \nof Economics & Manag ement Strategy, 20(1),  3–41. https://doi.org/10.1111/J.1530 -\n9134.2010.00282.X \nMacpherson, M., Gasperini, A., & Bosco, M. (2021). Implications for Artificial Intelligence and ESG Data . SSRN \nElectronic Journal. https://doi.org/10.2139/SSRN.3863599 \nNemes, N., Scanlan, S. J., Smith, P., Smith, T., Aronczyk, M., Hill, S., Lewis, S. L., Montgomery, A. W., \nTubiello, F. N., & Stabinsky, D. (2022). An Integrated Framework to Assess Greenwashing. Sustainability, \n14(8), 4431. https://doi.org/10.3390/su14084431 \nNing, X., Yim, D., & Khuntia, J. (2021). Online Sustainability Reporting and Firm Performance: Lessons Learned from \nText Mining. Sustainability, 13(3), 1069. https://doi.org/10.3390/SU13031069 \nPimonenko, T., Bilan, Y., Horák, J., Starchenko, L., & Gajda, W. (2020 ). Green Brand of Companies and \nGreenwashing under Sustainable Development Goals . Sustainability, 12(4),  1679. \nhttps://doi.org/10.3390/SU12041679 \nSanchez, C., & Zhang, Z. (2022). The Effects of In -domain Corpus Size on pre -training BERT . \nhttps://doi.org/10.48550/arXiv.2212.07914 \nSiano, A., Vollero, A., Conte, F., & Amabile, S. (2017). “More than words”: Expanding the taxonomy of greenwashing \nafter the Volkswagen scandal . Journal of Business Research, 71, 27 –37. \nhttps://doi.org/10.1016/j.jbusres.2016.11.002 \nSmeuninx, N., De Clerck, B., & Aerts, W. (2016). Measuring the Readability of Sustainability Reports: A Corpus-Based \nAnalysis Through Standard Formulae and NLP. International Journal of Business Communication, 57(1), \n52–85. https://doi.org/10.1177/2329488416675456 \nStammbach, D., Zurich, E., Webersinke, N., Bingler, J. A., Kraus, M., & Leippold, M. (2022). A dataset for \ndetecting real-world environmental claims. https://doi.org/10.3929/ethz-b-000568978 \nSteiner, G., Geissler, B., Schreder, G., & Zenk, L. (20 18). Living sustainability, or merely pretending? From explicit \nself-report measures to implicit cognition . Sustainability Science, 13(4),  1001–1015. \nhttps://doi.org/10.1007/s11625-018-0561-6 \nTesta, F., Boiral, O., & Iraldo, F. (2015 ). Internalization of Environmental Practices and Institutional Complexity: Can \nStakeholders Pressures Encourage Greenwashing? . Journal of Business Ethics, 147 (2), 287 –307. \nhttps://doi.org/10.1007/S10551-015-2960-2 \nTrewartha, A., Walker, N., Huo, H., Lee, S., Cruse, K., Dagdelen, J., Dunn, A., Persson, K. A., Ceder, G., & \nJain, A. (2022 ). Quantifying the advantage of domain -specific pre-training on named entity recognition tasks in \nmaterials science. Patterns, 3(4), 100488. https://doi.org/10.1016/j.patter.2022.100488 \nWebersinke, N., Kraus, M., Bingler, J., & Leippold, M. (2022). CLIMATEBERT: A Pretrained Language Model \nfor Climate-Related Text. SSRN Electronic Journal. https://doi.org/10.2139/ssrn.4229146 \nZheng, Z., Lu, X. Z., Chen, K. Y., Zhou, Y. C., & Li n, J. R. (2022). Pretrained domain-specific language model for \nnatural language processing tasks in the AEC domain . Computers in Industry , 142, 103733. \nhttps://doi.org/10.1016/j.compind.2022.103733 \n \n \n \n \n "
}