{
  "title": "nlpUP at SemEval-2019 Task 6: A Deep Neural Language Model for Offensive Language Detection",
  "url": "https://openalex.org/W2954775299",
  "year": 2019,
  "authors": [
    {
      "id": "https://openalex.org/A2092795848",
      "name": "Jelena Mitrović",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2952276991",
      "name": "Bastian Birkeneder",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2789226822",
      "name": "Michael Granitzer",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3212777144",
    "https://openalex.org/W2252278997",
    "https://openalex.org/W2170240176",
    "https://openalex.org/W2900796872",
    "https://openalex.org/W2922580172",
    "https://openalex.org/W1677182931",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W2963012544",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W1924770834",
    "https://openalex.org/W2962977603",
    "https://openalex.org/W2340954483",
    "https://openalex.org/W3013027210",
    "https://openalex.org/W2585712495",
    "https://openalex.org/W4300849630",
    "https://openalex.org/W2740168486",
    "https://openalex.org/W2157331557",
    "https://openalex.org/W2752756221",
    "https://openalex.org/W2964121744",
    "https://openalex.org/W4242076805",
    "https://openalex.org/W2741065173",
    "https://openalex.org/W2595653137",
    "https://openalex.org/W2806872289"
  ],
  "abstract": "This paper presents our submission for the SemEval shared task 6, sub-task A on the identification of offensive language. Our proposed model, C-BiGRU, combines a Convolutional Neural Network (CNN) with a bidirectional Recurrent Neural Network (RNN). We utilize word2vec to capture the semantic similarities between words. This composition allows us to extract long term dependencies in tweets and distinguish between offensive and non-offensive tweets. In addition, we evaluate our approach on a different dataset and show that our model is capable of detecting online aggressiveness in both English and German tweets. Our model achieved a macro F1-score of 79.40% on the SemEval dataset.",
  "full_text": "Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019), pages 722–726\nMinneapolis, Minnesota, USA, June 6–7, 2019. ©2019 Association for Computational Linguistics\n722\nnlpUP at SemEval-2019 Task 6: A Deep Neural Language Model for\nOffensive Language Detection\nJelena Mitrovi´c, Bastian Birkeneder, Michael Granitzer\nFaculty of Computer Science and Mathematics\nUniversity of Passau, Germany\njelena.mitrovic@uni-passau.de | birkeneder@fim.uni-passau.de\nmichael.granitzer@uni-passau.de\nAbstract\nThis paper presents our submission for the\nSemEval shared task 6, sub-task A on the\nidentiﬁcation of offensive language. Our pro-\nposed model, C-BiGRU, combines a Convolu-\ntional Neural Network (CNN) with a bidirec-\ntional Recurrent Neural Network (RNN). We\nutilize word2vec to capture the semantic sim-\nilarities between words. This composition al-\nlows us to extract long term dependencies in\ntweets and distinguish between offensive and\nnon-offensive tweets. In addition, we evaluate\nour approach on a different dataset and show\nthat our model is capable of detecting online\naggressiveness in both English and German\ntweets. Our model achieved a macro F1-score\nof 79.40% on the SemEval dataset.\n1 Introduction\nThe ever-increasing amount of user-generated data\nintroduces new challenges in terms of automatic\ncontent moderation, especially regarding hate\nspeech and offensive language detection. User\ncontent mostly consists of microposts, where the\ncontext of a post can be missing or inferred only\nfrom current events. The challenge of automatic\nidentiﬁcation and detection of online aggressive-\nness has therefore gained increasing popularity in\nthe scientiﬁc community over the last years.\nSeveral recent workshops and conferences such\nas TRAC (Kumar et al., 2018), ALW2 (Fi ˇser\net al., 2018), and GermEval (Wiegand et al., 2018)\nshow the growing importance of this subject. The\nSemEval 2019 shared task 6 (Zampieri et al.,\n2019b) further addresses this topic by introduc-\ning the Offensive Language Identiﬁcation Dataset\n(OLID), which consists of tweets, labeled with\na three-level annotation model (Zampieri et al.,\n2019a). Sub-task A is composed of a binary clas-\nsiﬁcation problem of whether a tweet in the dataset\nis offensive or not. Sub-task B focuses on differ-\nent categories of offensive language and the goal\nof sub-task C is to identify the targeted individual\nof an offensive tweet.\nIn the following paper, we present our contri-\nbution to sub-task A. After the related work sec-\ntion, we outline our conducted experiments in\nsection 3 and further describe the used baseline\nmodel, as well as the submitted model. In sec-\ntion 4 we report the results of our experiments\non the OLID dataset and the additionally used\nGermEval dataset. Section 5 discusses our results\nand section 6 concludes our work and describes\npossible future work.\n2 Related Work\nSeveral methods and models have been presented\nin literature over the last decade to address the\npredicament of identifying hate speech, offensive\nlanguage, and online aggressiveness. In the fol-\nlowing section, we present the most notable con-\ntributions related to our work.\nThe tweets collected by Davidson et al. (2017)\nwere divided into Hate, Offensive, and Neither.\nTheir proposed algorithm uses unigram, bigram,\nand trigram tokens as features, weighted by the re-\nspective TF-IDF, as well as Part-of-Speech (POS)\ntagging and different metrics to determine the\nreadability and sentiment of a tweet. Logistic-\nregression and linear SVM result in the best per-\nformance for a wide range of assessed classiﬁers.\nNobata et al. (2016) collected comments from Ya-\nhoo! Finance and News articles over a time period\nof one year and labeled them as either ’Abusive’\nor ’Clean’. They experimented with various dif-\nferent features, including n-gram, linguistic, syn-\ntactic, and distributional semantics features.\nVarious approaches utilized deep learning mod-\nels for text categorization. Zhang et al. (2015) pro-\nposed a character-level convolutional network for\ntext classiﬁcation on large-scale datasets. Their\nnetwork uses 1-dimensional convolutional ﬁlters\nto extract features from different character embed-\n723\ndings. Gamb ¨ack and Sikdar (2017) further exper-\nimented with convolutional networks in the con-\ntext of online hate speech classiﬁcation. Their re-\nsearch work compares different types of convolu-\ntional models, namely character-level, word vec-\ntors with a pretrained word2vec (w2v) model, ran-\ndomly generated word vectors, and w2v in combi-\nnation with character n-grams. The results of their\nexperiments suggest that w2v embeddings are the\nmost suitable for this task. Zhang et al. (2018) sug-\ngest an architecture similar to our network, where\na convolutional ﬁlter extracts features from pre-\ntrained word embeddings. After max pooling, the\nfeature maps are processed using a unidirectional\nGRU. Their model is compared to a bag-of-n-gram\nmodel on various multi-class hate speech datasets\nand shows promising results. A detailed survey\non different architectures, methods and features\nfor offensive language detection is provided by\nSchmidt and Wiegand (2017).\n3 System Description\nIn addition to Twitter data provided by the or-\nganizers of the SemEval shared task, we further\nevaluate our approach on German tweets from the\nGermEval (2018) shared task. The OLID dataset\ncontains 13,240 tweets, with 4,400 offensive and\n8,840 non-offensive tweets (66.77% offensive,\n33.23% non-offensive). Similarly, the GermEval\ndataset contains 5,009 tweets, divided into 1,688\noffensive and 3,321 non-offensive tweets (66.30%\noffensive, 33.70% non-offensive). To compensate\nfor the imbalanced class distributions and weigh\neach class equally, we choose the macro averaged\nF1-score of both classes as our main evaluation\nmetric. From both data sets we use 10% of our\ntweets as test set. The remaining tweets are split\ninto 90% training set and 10% validation set. We\nconduct a stratiﬁed 10-fold cross-validation on the\ntraining and validation set to prevent overﬁtting\nand to validate our model.\nThe pretrained w2v model, which is used to\ninitialize the weights of our embedding layer, re-\nsulted from the work of Godin et al. (2015). The\nw2v model for the GermEval dataset originates\nfrom our previous work (2018).\nFor comparison to our proposed model, a token\nbag-of-n-gram model composed of unigrams, bi-\ngrams, and trigrams weighted by their TF-IDF is\nused as baseline approach. We subsequently ana-\nlyze the performance of different classiﬁers on the\nresulting feature space.\nWe have used the packages keras, scikit-learn,\ngensim, and nltk for preprocessing and the imple-\nmentation of our models.\n3.1 Preprocessing\nTweets are ﬁrst tokenized and converted to lower-\ncase. We constrain repeated character sequences\nto length 3 and replace all longer character se-\nquences. HTML character encodings are replaced\nby their corresponding literal or token representa-\ntion (e.g. ‘&amp;’ translates to ‘and’). Tokens are\nfurther split if they enclose a set of special char-\nacters (‘\\’, ‘/’, ‘&’, ‘-’). Since hashtags are of-\nten used to replace contextually important words\nmid-sentence, we split hashtags in the actual hash-\nsymbol and the following string to keep the se-\nmantic information of a hashtag (e.g. ‘ Brainless\n#Liberal Stooge Ocasio-Cortez’).\n3.2 Baseline Model\nA TF-IDF bag-of-words model as baseline ap-\nproach is chosen to evaluate the performance of\nour model. We limit our feature space to the\n10,000 most frequently used unigrams, bigrams,\nand trigrams in a corpus. Furthermore, we stem\neach token in the preprocessing phase and remove\nstopwords. We compare the performance of sev-\neral classiﬁers, namely multinomial Naive Bayes\n(NB), SVM, Decision Tree (DT), and Logistic Re-\ngression (LogR) and conduct a grid search to opti-\nmize our hyper-parameters.\n3.3 C-BiGRU\nAfter the preprocessing step, we construct a dictio-\nnary which maps all unique tokens to their num-\nber of occurrences in the respective corpus. To-\nkens which appear only once in a corpus are dis-\nregarded and treated as unknown token. As a next\nstep, we construct the weighting matrix Wm×dim\nfor our embedding layer, where dim is the dimen-\nsion of the used w2v model and m the number of\nunique tokens ti, i∈{1, ..., m}. The word vector\nof ti is stored in W if the token is represented in\nthe w2v model. If ti has no pretrained word vector,\nwe generate a random vector drawn from the uni-\nform distribution within\n[\n−\n√\n6\ndim ,\n√\n6\ndim\n]\nas sug-\ngested by He et al. (2015). We ﬁx the maximum\nlength of a sentence to 150 tokens, longer se-\nquences are clipped at the end and shorter se-\nquences are padded with a masking token.\n724\nThe convolutional layer of our classiﬁer con-\nsists of (k ×128) 1-dimensional ﬁlters, where k\nis the number of different window sizes. These\nwindow sizes range from 2 to 5 and allow the ex-\ntraction of n-gram features. The padding of the\ninput is kept constant, resulting in the same output\nsequence length as the input. We further choose\nReLu as activation function. The resulting feature\nmaps are concatenated and passed towards the re-\ncurrent layer.\nGated Recurrent Units (GRU) as initially pro-\nposed by Cho et al. (2014) are used in RNNs\nto capture long-term dependencies of input se-\nquences. Similar to Long Short-Term Mem-\nory (LSTM) units (Hochreiter and Schmidhuber,\n1997) GRU are able to overcome the vanishing\ngradient problem by using a gating mechanism.\nGRU have shown to achieve comparable results to\nLSTM in sequence modeling tasks and are able to\noutperform the latter on smaller data sets (Chung\net al., 2014). The recurrent layer in our model\nconsists of a bidirectional GRU, where the con-\ncatenated feature maps, which resulted from the\nconvolutional layer, are used as input for the GRU\nlayer. Simultaneously, the reversed copy of the in-\nput sequence is used for the second GRU layer.\nBoth GRU layers return a hidden state for each\nprocessed feature map. The output of both lay-\ners is then concatenated. We set the length of the\nreturned hidden states to 64 for both layers, result-\ning in an output space of (150 ×128) neurons.\nAfterwards, a global max pooling layer reduces\nthe output space to (1 ×128) nodes. The follow-\ning fully-connected layer consists of 32 neurons,\nwhich connect to a single output neuron. The out-\nput neuron utilizes thesigmoid activation function.\nTo additionally prevent overﬁtting, we include\ntwo dropout layers with a dropout rate of 0.2; one\nafter the embedding layer and another one after\nthe fully-connected layer. Furthermore, we adopt\nearly stopping and use 10% of the training data\nas validation split. We use cross entropy as error\nfunction for our model and the optimizer ‘adam’\nto update our network weights (Kingma and Ba,\n2014). The batch size for the gradient update is\nset to 32. A schema of our proposed model is il-\nlustrated in Figure 1.\n4 Results\nFor the comparison model, the SVM performs best\non the OLID dataset with an F1-score of 70.22%\naveraged over a 10-fold cross-validation. The\nSVM also shows the best results on the GermEval\ndataset with an F1-score of 66.61%. The evalua-\ntion on the test set results in 66.78% F1-score for\nthe GermEval gold test set. The evaluation of the\nbaseline model for the OLID gold test set is not\npossible at the time of writing, since the gold test\ndata have not yet been released.\nThe C-BiGRU achieved a 76.28% F1-score on\nthe OLID and a 71.13% F1-score on the GermEval\ndataset on average over a 10-fold cross-validation.\nOn the OLID gold test set, our model achieved\nan F1-score of 79.40%. The evaluation on the\nGermEval gold test data resulted in a 72.41% F1-\nscore. An overview of all results can be found in\nTable 1. Figure 2 shows the confusion matrix of\nour submitted predictions for the SemEval shared\ntask.\nBaseline C-BiGRU\nCV gold CV gold\nOLID 70.22% - 76.28% 79.40%\nGermEval 66.61% 66.78% 71.13% 72.41%\nTable 1: All results in table form (CV = cross-\nvalidation; gold = gold test set).\nFigure 1: Representation of the proposed classiﬁer.\n725\nFigure 2: Confusion Matrix of the OLID gold test set,\nsub-task A. Depicted are instances and normalized val-\nues.\n5 Discussion\nThe presented model continues our work on the\nidentiﬁcation of offensive German tweets (2018).\nWe were able to improve our proposed model by\nadjusting the architecture of the recurrent layer in\nour neural network. By using a bidirectional GRU\ninstead of a unidirectional LSTM, we are able to\ncapture past and future information about the in-\nput sequence and exploit the better performance\nof GRU networks on smaller datasets. Further-\nmore, we return the hidden states for each feature\nmap instead of returning only the last hidden state.\nThis allows us to extract higher-level sequentially\ndependent features from each concatenated feature\nmap.\nOur experiments show that our suggested model\noutperforms the baseline model on both datasets.\nThe difference between the F1-scores for the En-\nglish and German dataset might be attributed to\nthe smaller size of the German training set, which\ncontains only about 5,000 tweets. The discrepancy\nbetween the results of our cross-validation and\nachieved score on the OLID test set might be ex-\nplained by the small amount of test tweets, which\nmay lead to imprecise results for the submitted\nruns.\nBy utilizing w2v as features, we are able to limit\nextensive and language speciﬁc preprocessing.\n“@USER Lolol God he is such an\na**hole.”\nIn this example, the vector representation of\n“a**hole” has a high cosine similarity (0.63) to the\nvector representation of “asshole”, which allows\nour model to classify this tweet as offensive. On\nthe contrary, our approach falls short when con-\nfronted with indirect insults.\n“@USER @USER Im sure the air that\nhe is breathing is also bad.”\nOur model wrongly predicts a non-offensive tweet\nin this instance.\nThe detection of offensive, hateful, racist,\nand/or sexist user behavior in social media still\nproves to be a challenge. Even for humans, it\ncan be problematic to identify offensive microp-\nosts, since these posts can be ambiguous and de-\npendant on the personal mindset of a reader. Ross\net al. (2017) show that it can be difﬁcult to mea-\nsure the agreement of annotators about hate speech\nin the light of the European refugee crisis. They\nconclude that instead of a classiﬁcation problem,\na regression model with an average offensiveness\nscore of multiple annotators might be more suit-\nable for this task. Furthermore, it can be difﬁcult\nto grasp the full context of an arbitrary tweet. With\nonly excerpts of a conversation, the context and\ntrue intention of the author may be difﬁcult to de-\ntermine.\n6 Conclusion and Future Work\nIn this paper, we describe our submitted model for\nthe SemEval shared task 6 and evaluation meth-\nods for the identiﬁcation of online aggressiveness\nin social media microposts. Our model achieves\ngood results in the two evaluated datasets. For\nthe OLID dataset which contains English tweets,\na macro F1-score of 79.40% is reached, while our\nnetwork resulted in an F1-score of 72.41 % on\nthe GermEval dataset, which consists of German\ntweets.\nWe plan to evaluate our approach on more\ndatasets to further investigate the potential of our\nmodel for different languages. One such set is\nthe TRAC dataset, which contains aggression-\nannotated Facebook posts and comments in Hindi.\nFurthermore, we want to examine whether addi-\ntional features such as character-level embeddings\nor POS tagging will improve our results. Inclusion\nof ﬁgurative language detection has proved to en-\nhance many NLP tasks, such as argument mining\nand so-called hidden hate speech (Mitrovi ´c et al.,\n2017), which is also one of our future directions.\n726\nReferences\nBastian Birkeneder, Jelena Mitrovi ´c, Julia Niemeier,\nLeon Teubert, and Siegfried Handschuh. 2018. up-\nInf - Offensive Language Detection in German\nTweets. In Proceedings of the GermEval 2018\nWorkshop, pages 71 – 78.\nKyunghyun Cho, Bart Van Merri ¨enboer, Caglar Gul-\ncehre, Dzmitry Bahdanau, Fethi Bougares, Holger\nSchwenk, and Yoshua Bengio. 2014. Learning\nphrase representations using rnn encoder-decoder\nfor statistical machine translation. arXiv preprint\narXiv:1406.1078v3.\nJunyoung Chung, Caglar Gulcehre, KyungHyun Cho,\nand Yoshua Bengio. 2014. Empirical evaluation of\ngated recurrent neural networks on sequence model-\ning. arXiv preprint arXiv:1412.3555.\nThomas Davidson, Dana Warmsley, Michael Macy,\nand Ingmar Weber. 2017. Automated hate speech\ndetection and the problem of offensive language.\narXiv preprint arXiv:1703.04009.\nDarja Fi ˇser, Ruihong Huang, Vinodkumar Prab-\nhakaran, Rob V oigt, Zeerak Waseem, and Jacqueline\nWernimont. 2018. Proceedings of the 2nd workshop\non abusive language online (alw2). In Proceedings\nof the 2nd Workshop on Abusive Language Online\n(ALW2).\nBj¨orn Gamb ¨ack and Utpal Kumar Sikdar. 2017. Us-\ning convolutional neural networks to classify hate-\nspeech. In Proceedings of the First Workshop on\nAbusive Language Online, pages 85–90.\nFr´ederic Godin, Baptist Vandersmissen, Wesley\nDe Neve, and Rik Van de Walle. 2015. Multimedia\nlab @ acl wnut ner shared task: Named entity recog-\nnition for twitter microposts using distributed word\nrepresentations. In Proceedings of the Workshop on\nNoisy User-generated Text, pages 146–153.\nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian\nSun. 2015. Delving deep into rectiﬁers: Surpass-\ning human-level performance on imagenet classiﬁ-\ncation. In Proceedings of the IEEE international\nconference on computer vision, pages 1026–1034.\nSepp Hochreiter and J ¨urgen Schmidhuber. 1997.\nLong short-term memory. Neural computation,\n9(8):1735–1780.\nDiederik P Kingma and Jimmy Ba. 2014. Adam: A\nmethod for stochastic optimization. arXiv preprint\narXiv:1412.6980.\nRitesh Kumar, Atul Kr. Ojha, Marcos Zampieri, and\nShervin Malmasi. 2018. Proceedings of the ﬁrst\nworkshop on trolling, aggression and cyberbullying\n(trac-2018). In Proceedings of the First Workshop\non Trolling, Aggression and Cyberbullying (TRAC-\n2018). Association for Computational Linguistics.\nJelena Mitrovi ´c, Cliff O’Reilly, Miljana Mladenovi ´c,\nand Siegfried Handschuh. 2017. Ontological repre-\nsentations of rhetorical ﬁgures for argument mining.\nArgument & Computation, 8(3):267–287.\nChikashi Nobata, Joel Tetreault, Achint Thomas,\nYashar Mehdad, and Yi Chang. 2016. Abusive lan-\nguage detection in online user content. In Proceed-\nings of the 25th international conference on world\nwide web, pages 145–153. International World Wide\nWeb Conferences Steering Committee.\nBj¨orn Ross, Michael Rist, Guillermo Carbonell, Ben-\njamin Cabrera, Nils Kurowsky, and Michael Wo-\njatzki. 2017. Measuring the reliability of hate\nspeech annotations: The case of the european\nrefugee crisis. arXiv preprint arXiv:1701.08118.\nAnna Schmidt and Michael Wiegand. 2017. A survey\non hate speech detection using natural language pro-\ncessing. In Proceedings of the Fifth International\nWorkshop on Natural Language Processing for So-\ncial Media, pages 1–10.\nMichael Wiegand, Melanie Siegel, and Josef Ruppen-\nhofer. 2018. Overview of the germeval 2018 shared\ntask on the identiﬁcation of offensive language.Aus-\ntrian Academy of Sciences, Vienna September 21,\n2018.\nMarcos Zampieri, Shervin Malmasi, Preslav Nakov,\nSara Rosenthal, Noura Farra, and Ritesh Kumar.\n2019a. Predicting the Type and Target of Offensive\nPosts in Social Media. In Proceedings of NAACL.\nMarcos Zampieri, Shervin Malmasi, Preslav Nakov,\nSara Rosenthal, Noura Farra, and Ritesh Kumar.\n2019b. SemEval-2019 Task 6: Identifying and Cat-\negorizing Offensive Language in Social Media (Of-\nfensEval). In Proceedings of The 13th International\nWorkshop on Semantic Evaluation (SemEval).\nXiang Zhang, Junbo Zhao, and Yann LeCun. 2015.\nCharacter-level convolutional networks for text clas-\nsiﬁcation. In Advances in neural information pro-\ncessing systems, pages 649–657.\nZiqi Zhang, David Robinson, and Jonathan Tepper.\n2018. Detecting hate speech on twitter using a\nconvolution-gru based deep neural network. In Eu-\nropean Semantic Web Conference, pages 745–760.\nSpringer.",
  "topic": "SemEval",
  "concepts": [
    {
      "name": "SemEval",
      "score": 0.9394744634628296
    },
    {
      "name": "Computer science",
      "score": 0.8786282539367676
    },
    {
      "name": "Offensive",
      "score": 0.8683412075042725
    },
    {
      "name": "Word2vec",
      "score": 0.7814505100250244
    },
    {
      "name": "Convolutional neural network",
      "score": 0.7470935583114624
    },
    {
      "name": "Artificial intelligence",
      "score": 0.7052363753318787
    },
    {
      "name": "Task (project management)",
      "score": 0.6545068621635437
    },
    {
      "name": "Natural language processing",
      "score": 0.6090853214263916
    },
    {
      "name": "Recurrent neural network",
      "score": 0.5282772183418274
    },
    {
      "name": "Language identification",
      "score": 0.5115276575088501
    },
    {
      "name": "Identification (biology)",
      "score": 0.4332507252693176
    },
    {
      "name": "Language model",
      "score": 0.4280547797679901
    },
    {
      "name": "Artificial neural network",
      "score": 0.4055190980434418
    },
    {
      "name": "Natural language",
      "score": 0.2079693078994751
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Embedding",
      "score": 0.0
    },
    {
      "name": "Botany",
      "score": 0.0
    }
  ]
}