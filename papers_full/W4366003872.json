{
  "title": "A Doctor's Guide to Foundation Models",
  "url": "https://openalex.org/W4366003872",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5089208747",
      "name": "Giovanni Briganti",
      "affiliations": [
        "University of Mons"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4224945225",
    "https://openalex.org/W7017626301",
    "https://openalex.org/W4365143687",
    "https://openalex.org/W4318574514",
    "https://openalex.org/W4294559022",
    "https://openalex.org/W4243601807",
    "https://openalex.org/W3012041784",
    "https://openalex.org/W4362569225",
    "https://openalex.org/W4308609991",
    "https://openalex.org/W3003667836",
    "https://openalex.org/W4283654598",
    "https://openalex.org/W4298088068",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W2382099189",
    "https://openalex.org/W4323356796"
  ],
  "abstract": "The rapid advancement of artificial intelligence (AI) has led to the emergence of foundation models as powerful tools for various applications, including healthcare. These large-scale machine learning models, such as GPT and LLaMA have demonstrated potential for improving patient outcomes and transforming medical practice. However, healthcare professionals without a background in data science may find it challenging to understand and utilize these models effectively. This paper aims to provide an accessible introduction to foundation models for healthcare professionals, discussing their core concepts, relevant applications in healthcare, ethical considerations, challenges, and future directions. By offering a comprehensive overview of foundation models, I hope to foster a more informed and collaborative future between healthcare professionals and data scientists, ultimately driving better patient care and medical advancements.",
  "full_text": "A Doctor’s Guide to Foundation Models\nGiovanni Briganti1\n1Chair of AI and Digital Medicine, University of Mons, Avenue du Champs de Mars\n6, 7000 Mons, Belgium\nApril 15, 2023\nAbstract\nThe rapid advancement of artiﬁcial intelligence (AI) has led to the emergence of foun-\ndation models as powerful tools for various applications, including healthcare. These\nlarge-scale machine learning models, such as GPT and LLaMA have demonstrated po-\ntential for improving patient outcomes and transforming medical practice. However,\nhealthcare professionals without a background in data science may ﬁnd it challenging\nto understand and utilize these models eﬀectively. This paper aims to provide an ac-\ncessible introduction to foundation models for healthcare professionals, discussing their\ncore concepts, relevant applications in healthcare, ethical considerations, challenges, and\nfuture directions. By oﬀering an overview of foundation models, I hope to foster a more\ninformed and collaborative future between healthcare professionals and data scientists,\nultimately driving better patient care and medical advancements.\nKeywords: Foundation models, Medical AI, Regulation, Digital healthcare, AI ethics\nThis work has not yet been peer-reviewed.\n1 Introduction\nIn recent years, artiﬁcial intelligence (AI) has made remarkable advancements in various ﬁelds,\nincluding healthcare (1). Among these developments, foundation models have emerged as a\npowerful tool for generating, understanding, and manipulating human-like text. These mod-\nels hold great promise for revolutionizing medical practice and improving patient outcomes\n(2). However, healthcare professionals without a background in data science may ﬁnd it\nchallenging to understand and utilize these models eﬀectively.\nThe purpose of this paper is to provide healthcare professionals with an accessible intro-\nduction to foundation models, particularly those without a background in data science or AI.\nThe paper aims to explain core concepts, highlight relevant applications in healthcare, and\naddress ethical considerations and challenges. The scope of the paper is to provide a solid\nfoundation for healthcare professionals to explore the potential of these models in their own\npractice and collaborate with data scientists and AI experts.\n1\nThe growing adoption of AI in healthcare underscores the need for medical practitioners\nto be aware of and understand the implications of foundation models. As these models con-\ntinue to evolve and ﬁnd their way into various aspects of medical practice, it is crucial for\nhealthcare professionals to be prepared for their potential impact on diagnostics, treatment\nplanning, research, and patient care. By providing an accessible introduction to foundation\nmodels, this paper aims to facilitate a more informed and collaborative future for healthcare\nprofessionals and data scientists alike.\n2 Foundation Models: An Overview\n2.1 Core Concepts\nFoundation models are large-scale machine learning models that serve as a base for various AI\napplications. They are pre-trained on extensive amounts of data, often from diverse sources,\nto develop a comprehensive understanding of human language, relationships, and patterns.\nThese models can then be ﬁne-tuned for speciﬁc tasks, enabling them to generate high-quality\noutputs in a wide range of domains, including healthcare (3).\nThe core concepts of foundation models include:\n- Pre-training: This phase involves training the model on large-scale datasets, which\nallows the model to learn language patterns, grammar, and contextual relationships.\n- Fine-tuning: After pre-training, the model is ﬁne-tuned on task-speciﬁc data to adapt\nits knowledge to the speciﬁc domain, such as medical diagnostics or treatment planning.\n- Transfer learning: This concept refers to the ability of foundation models to leverage\nknowledge acquired during pre-training and apply it to new, related tasks, thus reducing the\nneed for extensive training data for each task.\nSuch concepts may be hard to grasp at ﬁrst for healthcare professionals, so let us make\nan example for healthcare data.\nFoundation models are ﬁrst pre-trained on a large-scale medical dataset, including diverse\nsources like electronic health records, medical literature, and clinical trial reports. After pre-\ntraining, the models are ﬁne-tuned on healthcare-speciﬁc applications, such as medical diag-\nnosis or treatment recommendation, by learning from task-speciﬁc data. For instance, let’s\nconsider a pre-trained healthcare foundation model ﬁne-tuned for analyzing patient-reported\nsymptoms to suggest potential diagnoses. The ﬁne-tuning process involves training the model\non a dataset of anonymized patient-reported symptoms and corresponding diagnoses, allow-\ning it to adapt its general medical knowledge to this speciﬁc task. The resulting patient\nsymptom analysis model can then be used by healthcare professionals to generate a ranked\nlist of potential diagnoses, helping to expedite the diagnostic process and improve patient\ncare. Transfer learning allows us to leverage the knowledge acquired during pre-training and\nﬁne-tuning to adapt the model to a related but distinct task. For example, we can further\nﬁne-tune the patient symptom analysis model on a new dataset containing patient-reported\nsymptoms, diagnoses, and eﬀective treatment options. This process enables the model to\nassociate speciﬁc diagnoses with their corresponding treatments, building upon its existing\nknowledge of patient-reported symptoms and medical conditions.\nThe resulting treatment recommendation model can then be used by healthcare profes-\nsionals to suggest personalized treatment options for their patients based on their reported\n2\nsymptoms and conﬁrmed diagnosis. The AI-generated list of potentially eﬀective treatments\ncan support more informed treatment decisions and tailored patient care.\nAs a step-by-step reasoning, we would have:\nStep 1: Pre-training the Foundation Model\n- Collect a large-scale medical dataset containing diverse sources of medical text, including\nelectronic health records, medical literature, and clinical trial reports.\n- Clean and preprocess the data to remove personally identiﬁable information (PII) for\npatient privacy.\n- Pre-train a foundation model, such as a transformer-based architecture (e.g., GPT),\non this dataset to learn the syntax, semantics, and contextual relationships within medical\nlanguage.\n- Evaluate the pre-trained model on medical language understanding tasks (e.g., named\nentity recognition or medical text classiﬁcation) and save it as a pre-trained healthcare foun-\ndation model.\nStep 2: Fine-tuning the Model for Patient-Reported Symptoms Analysis\n- Collect a dataset of patient-reported symptoms and their corresponding diagnoses from\nanonymized electronic health records or clinical case studies.\n- Fine-tune the pre-trained healthcare foundation model on this dataset to associate\nspeciﬁc symptoms and symptom combinations with their corresponding medical conditions.\n- Evaluate the ﬁne-tuned model on a separate dataset of patient-reported symptoms and\ndiagnoses, and save it as a patient symptom analysis model if it demonstrates satisfactory\nperformance.\nStep 3: Transfer Learning for Treatment Recommendation\n- Collect a dataset containing patient-reported symptoms, corresponding diagnoses, and\neﬀective treatment options from anonymized electronic health records or clinical case studies.\n- Leverage transfer learning to further ﬁne-tune the patient symptom analysis model on\nthe new dataset, allowing it to associate speciﬁc diagnoses with their corresponding eﬀective\ntreatments.\n- Evaluate the adapted model on a separate dataset containing patient-reported symp-\ntoms, diagnoses, and eﬀective treatments. Save it as a treatment recommendation model if\nit demonstrates satisfactory performance.\nIn this example, the pre-training process involves learning general medical language un-\nderstanding from a large-scale dataset. Fine-tuning focuses on adapting this knowledge to\na speciﬁc task, in this case, analyzing patient-reported symptoms to suggest potential diag-\nnoses. Transfer learning enables the model to build upon its existing knowledge and adapt\nto a related but distinct task, such as predicting the most eﬀective treatment options for a\npatient based on their reported symptoms and diagnosed medical condition.\nIt is crucial to emphasize that AI-generated suggestions should be treated as a supple-\nmentary tool, with healthcare professionals using their clinical expertise and judgment to\nmake the ﬁnal diagnosis and treatment decisions.\n2.2 Brief history of foundation models\nThe development of foundation models has been shaped by several breakthroughs in AI\nresearch over the years. Some of the key milestones include:\n3\n- Feedforward Neural Networks (1980s): These early models laid the groundwork for more\ncomplex architectures that would follow.\n- Recurrent Neural Networks (RNNs, 1990s): RNNs were designed to handle sequences of\ndata, such as text, and became a building block for many natural language processing (NLP)\nmodels.\n- Word Embeddings (2000s): Techniques such as Word2Vec and GloVe represented words\nas high-dimensional vectors, capturing semantic relationships, and improving NLP perfor-\nmance.\n- Attention Mechanisms (2010s): Attention mechanisms, such as those used in Trans-\nformer models, helped overcome some limitations of RNNs by focusing on relevant parts of\nthe input data, leading to improved performance on complex tasks.\n- GPT and BERT (2018): The introduction of GPT (Generative Pre-trained Transformer)\nand BERT (Bidirectional Encoder Representations from Transformers) marked a signiﬁcant\nstep forward in foundation models’capabilities, with both models setting new benchmarks in\nNLP tasks. 2023 marked the acceleration of such models, as the new version of GPT, GPT-4,\na multi-modal (i.e., accepting text and image inputs) foundation model has been released,\ndirectly causing a boost in the number of AI apps based on these foundation models.\n2.3 Notable examples\nSome of the most well-known foundation models include:\n- GPT (OpenAI): GPT is a series of generative pre-trained transformer models, with\nGPT-4 being the latest and most advanced version at the time of this paper. GPT models\nexcel at generating human-like text and have been applied in various domains, including\nhealthcare (3).\n- Bard (Google): Bard is an experimental conversational AI service powered by Google’s\nLanguage Model for Dialogue Applications (LaMDA). It aims to combine the world’s knowl-\nedge with the intelligence and creativity of large language models to provide responses (4).\n- LLaMA: Meta has released LLaMA, a state-of-the-art foundational large language model\naimed at helping researchers advance their work in AI. Smaller, more performant models like\nLLaMA democratize access to the research community and require less computing power for\ntesting and exploration (2).\nThese foundation models have paved the way for a new era of AI applications, with\nsigniﬁcant potential for improving healthcare outcomes and advancing medical knowledge.\n3 Applications in Healthcare\n3.1 Medical diagnostics\nFoundation models have shown promise in assisting healthcare professionals with diagnosing\nmedical conditions. By analyzing patient data, such as medical history, symptoms, and\ntest results, these models can generate diﬀerential diagnoses and suggest further tests or\ninterventions. This helps reduce diagnostic errors, expedite the process, and enhance the\noverall quality of care.\n4\n3.2 Treatment planning and optimization\nAI-driven models can support the development of personalized treatment plans by considering\npatient-speciﬁc factors and analyzing large volumes of medical literature (5). They can assist\nin optimizing treatment strategies, predicting treatment response, and identifying potential\nadverse eﬀects. This enables healthcare professionals to make more informed decisions and\ntailor treatments to individual patients, ultimately improving outcomes.\n3.3 Medical research and drug discovery\nFoundation models can be employed to facilitate medical research by automating the ex-\ntraction of relevant information from scientiﬁc literature, identifying patterns in data, and\ngenerating hypotheses (6). They can also accelerate drug discovery by predicting molecular\nproperties, identifying potential drug candidates, and suggesting new chemical structures (7).\nThis expedites the research process and helps bring new therapies to market more eﬃciently.\n3.4 Health monitoring and personalized medicine: towards better digital\ntwins\nWearable devices and sensors generate vast amounts of data that can be processed by foun-\ndation models to monitor patients’ health and detect potential issues early. These models\ncan identify patterns in biometric data, predict disease progression, and provide personalized\nrecommendations for lifestyle interventions. This empowers patients to take a more active\nrole in their health and fosters a more proactive approach to healthcare. Coupled with be-\nhavioral data, patient reported outcomes and experience measures (PROMS/PREMS), as\nwell as hospital data, foundational models pave the way for next-generation digital twins for\npatients (8–10).\n3.5 Medical imaging\nAI-driven models have made signiﬁcant strides in medical imaging, such as analyzing X-\nrays, MRIs, and CT scans. Foundation models can be ﬁne-tuned to identify and classify\nabnormalities in medical images, thereby assisting radiologists and clinicians in diagnosing\nconditions more accurately and eﬃciently. This can lead to early detection and intervention,\nimproving patient outcomes and reducing healthcare costs (11).\n3.6 Generalist Medical AI\nMoor et al. (12) have proposed the concept of Generalist Medical AI (GMAI), that encom-\npasses various applications of AI in healthcare, aiming to enhance patient care and improve\nclinical workﬂows. Some potential applications include: 1) bedside decision support, where\nGMAI models assist clinicians in making informed decisions by providing data summaries, ex-\nplanations, and treatment recommendations; 2) interactive note-taking, where GMAI models\nhelp reduce administrative tasks by drafting documents for clinicians to review and approve;\n3) chatbots for patients, enabling personalized support and advice outside clinical settings;\nand 4) text-to-protein generation, where GMAI models design protein sequences and struc-\ntures based on textual prompts, potentially accelerating drug discovery and development.\n5\n4 Ethical considerations\n4.1 Privacy and security\nData privacy is a signiﬁcant concern in healthcare, as patient data contains sensitive personal\ninformation. Ensuring the proper handling, storage, and transmission of such data is essential\nwhen using foundation models. Healthcare professionals should be aware of relevant regula-\ntions, such as HIPAA and GDPR, and work with data scientists to implement appropriate\ndata protection measures (13).\n4.2 Bias and fairness in healthcare AI\nBias in AI models can result from biased training data or inherent biases in algorithms. In\nhealthcare, biased AI models may lead to unfair treatment or misdiagnoses, disproportion-\nately aﬀecting certain populations. It is crucial for healthcare professionals to be aware of\npotential biases and collaborate with data scientists to ensure fairness and equitable outcomes\nfor all patients.\n4.3 Informed consent, safety, and transparency\nPatients have the right to know when AI models are being used in their care and to under-\nstand the implications of these models on their treatment. Healthcare professionals should\nensure that patients are adequately informed about the role of AI in their care and that\nthey have the opportunity to ask questions and provide informed consent. To ensure the\nsafety and well-being of users, it is crucial that foundation models either undergo rigorous\nclinical validation to demonstrate their accuracy and reliability, or inform citizens that use\nthem without the supervision of healthcare professionals that they have not been validated.\nClinical validation would involve subjecting the models to extensive testing and assessment\nby healthcare professionals to ensure their eﬃcacy in real-world medical scenarios (5). In\ncases where the AI models have not been validated, it is essential that users are made aware\nof the potential limitations and risks associated with using these systems. Clear communi-\ncation regarding the validation status of foundation models can help users make informed\ndecisions about their use and better understand the potential implications on their health\nand well-being.\n4.4 Professional responsibility and decision-making\nWhile foundation models can oﬀer valuable insights and support, healthcare professionals\nmust remember that they ultimately hold responsibility for patient care. It is essential to\ncritically evaluate AI-generated recommendations, use professional judgment, and maintain\nopen communication with patients to ensure that decisions are made in the best interest of\nthe individual patient.\n6\n5 Challenges and Limitations\n5.1 Quality of training data\nThe performance of foundation models depends on the quality and representativeness of\nthe data they are trained on. In healthcare, high-quality and diverse data is crucial to\nensure accurate and generalizable results. However, obtaining and curating such data can\nbe challenging, given issues related to data privacy, consent, and varying data collection\npractices (14).\n5.2 Interpretability and explainability\nFoundation models can act as ”black boxes”, making it diﬃcult to understand how they\narrive at speciﬁc conclusions or recommendations. In healthcare, where decision-making has\nsigniﬁcant consequences, it is essential for professionals to understand the rationale behind\nAI-generated outputs. Developing more interpretable and explainable models remains an\nongoing challenge in the ﬁeld (15).\n5.3 Generalizability and real-world performance\nWhile foundation models may demonstrate impressive performance in controlled research\nsettings, their real-world performance can vary. Factors such as data quality, model limi-\ntations, and diﬀerences in patient populations may impact the generalizability of AI-driven\ninsights. Healthcare professionals should be cautious when applying these models in practice\nand consider validating their performance on local or domain-speciﬁc data.\n5.4 Legal and regulatory concerns\nThe AI Act proposed for Europe (16), the more comprehensive and speciﬁc regulatory at-\ntempt at AI, has been met with The AI Act’s has been met with skepticism (17), as its focus\non healthcare is mostly limited to references to the Medical Devices Regulation (MDR) and\nIn Vitro Diagnostic Medical Devices Regulation (IVDR). The AI Act classiﬁes medical AI un-\nder the MDR or IVDR as high-risk if it requires a third-party conformity assessment. Other\nhigh-risk AI uses in healthcare include emergency ﬁrst response services dispatching and risk\nassessment in life and health insurance. Medical AI could be classiﬁed as unacceptable risk\nif they involve vulnerable groups. However, if medical AI does not meet the high-risk or un-\nacceptable risk criteria, it falls into the minimal risk category. The MDR currently remains\nthe most relevant approach to regulating AI-based medical devices under the AI Act (17).\nSome countries have (temporarily) halted certain foundation models (18).\nAs AI becomes more integrated into healthcare, legal and regulatory issues will likely arise.\nThese may include questions around liability for AI-driven recommendations, data protection\nrequirements, and the need for standardized AI evaluation protocols. Healthcare professionals\nshould stay informed about the evolving legal landscape and engage in discussions around\nthe responsible use of AI in their practice.\n7\n6 Conclusions\nAs research in AI and foundation models continues to progress, we can expect new models\nwith improved performance, interpretability, and applicability in healthcare. These advance-\nments may lead to even more accurate diagnoses, personalized treatments, and a deeper\nunderstanding of complex medical conditions.\nThe successful integration of foundation models into healthcare requires close collabora-\ntion between healthcare professionals and data scientists (1). By working together, they can\ndevelop models that address the unique challenges and requirements of the medical domain,\nultimately leading to better patient outcomes.\nFoundation models hold great promise for telemedicine and global health applications.\nThey can help bridge the gap in access to healthcare resources by providing remote diagnostic\nsupport, treatment planning, and health monitoring services. By leveraging these models,\nhealthcare professionals can expand their reach and provide care to underserved populations,\nimproving health equity worldwide.\nIn conclusion, the future of foundation models in healthcare is promising, with many\nopportunities for improving patient care and advancing medical knowledge. As healthcare\nprofessionals become more familiar with these models and their potential, they can harness\ntheir power to transform healthcare and deliver better outcomes for patients around the globe.\nReferences\n1. Briganti G, Le Moine O. Artiﬁcial Intelligence in Medicine: Today and Tomorrow.\nFront Med [Internet]. 2020 [cited 2020 Feb 11];7.\n2. Touvron H, Lavril T, Izacard G, Martinet X, Lachaux MA, Lacroix T, et al. Llama:\nOpen and eﬃcient foundation language models. ArXiv Prepr ArXiv230213971. 2023;\n3. OpenAI. GPT-4 Technical Report [Internet]. arXiv; 2023 [cited 2023 Apr 15]. Avail-\nable from: http://arxiv.org/abs/2303.08774\n4. An important next step on our AI journey [Internet]. Google. 2023 [cited 2023 Apr\n15]. Available from: https://blog.google/technology/ai/bard-google-ai-search-updates/\n5. Briganti G. Intelligence artiﬁcielle : une introduction pour les cliniciens. Rev Mal\nRespir [Internet]. 2023 Mar 7 [cited 2023 Mar 23].\n6. Briganti G. On the Use of Bayesian Artiﬁcial Intelligence for Hypothesis Generation\nin Psychiatry. Psychiatr Danub. 2022;34(Suppl 8):201–6.\n7. M´endez-Lucio O, Nicolaou C, Earnshaw B. MolE: a molecular foundation model for\ndrug discovery [Internet]. arXiv; 2022 [cited 2023 Apr 15].\n8. Far SB, Rad AI. Applying Digital Twins in Metaverse: User Interface, Security and\nPrivacy Challenges. J Metaverse. 2022 Jun 30;2(1):8–15.\n9. Rasheed A, San O, Kvamsdal T. Digital twin: Values, challenges and enablers from a\nmodeling perspective. Ieee Access. 2020;8:21980–2012.\n10. Jones D, Snider C, Nassehi A, Yon J, Hicks B. Characterising the Digital Twin: A\nsystematic literature review. CIRP J Manuf Sci Technol. 2020;29:36–52.\n11. Ranschaert ER, Morozov S, Algra PR. Artiﬁcial intelligence in medical imaging:\nopportunities, applications and risks. Springer; 2019.\n12. Moor M, Banerjee O, Abad ZSH, Krumholz HM, Leskovec J, Topol EJ, et al. Foun-\ndation models for generalist medical artiﬁcial intelligence. Nature. 2023;616(7956):259–65.\n8\n13. Sajid A, Abbas H. Data privacy in cloud-assisted healthcare systems: state of the art\nand future challenges. J Med Syst. 2016;40(6):155.\n14. Mashouﬁ M, Ayatollahi H, Khorasani-Zavareh D, Boni TTA. Data quality in health\ncare: main concepts and assessment methodologies. Methods Inf Med. 2023;\n15. Dwivedi R, Dave D, Naik H, Singhal S, Omer R, Patel P, et al. Explainable AI (XAI):\nCore ideas, techniques, and solutions. ACM Comput Surv. 2023;55(9):1–33.\n16. Proposal for a REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE\nCOUNCIL LAYING DOWN HARMONISED RULES ON ARTIFICIAL INTELLIGENCE\n(ARTIFICIAL INTELLIGENCE ACT) AND AMENDING CERTAIN UNION LEGISLA-\nTIVE ACTS [Internet]. 2021.\n17. Palmieri S, Goﬃn T. A Blanket That Leaves the Feet Cold: Exploring the AI Act\nSafety Framework for Medical AI. Eur J Health Law. 2023 Feb 7;1(aop):1–22.\n18. Intelligenza artiﬁciale: il Garante blocca ChatGPT. Raccolta illecita di dati personali.\nAssenza di sistemi per la veriﬁca dell’et`a dei minori [Internet]. [cited 2023 Apr 15].\n9",
  "topic": "Foundation (evidence)",
  "concepts": [
    {
      "name": "Foundation (evidence)",
      "score": 0.848373532295227
    },
    {
      "name": "Health care",
      "score": 0.6692426204681396
    },
    {
      "name": "Engineering ethics",
      "score": 0.5376530885696411
    },
    {
      "name": "Health professionals",
      "score": 0.4790552854537964
    },
    {
      "name": "Scale (ratio)",
      "score": 0.463853120803833
    },
    {
      "name": "Data science",
      "score": 0.41596490144729614
    },
    {
      "name": "Computer science",
      "score": 0.4030272960662842
    },
    {
      "name": "Knowledge management",
      "score": 0.3577539920806885
    },
    {
      "name": "Engineering",
      "score": 0.29295530915260315
    },
    {
      "name": "Political science",
      "score": 0.17283794283866882
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I130929987",
      "name": "University of Mons",
      "country": "BE"
    }
  ]
}