{
  "title": "Large Language Models are legal but they are not: Making the case for a powerful LegalLLM",
  "url": "https://openalex.org/W4389524036",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A4379126839",
      "name": "Thanmay Jayakumar",
      "affiliations": [
        "Visvesvaraya National Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5093278345",
      "name": "Fauzan Farooqui",
      "affiliations": [
        "Visvesvaraya National Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A4379126840",
      "name": "Luqman Farooqui",
      "affiliations": [
        "Visvesvaraya National Institute of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3176443126",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3198651167",
    "https://openalex.org/W3204112174",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W4389519438",
    "https://openalex.org/W4385574011",
    "https://openalex.org/W3017246378",
    "https://openalex.org/W3099950029",
    "https://openalex.org/W4287704453",
    "https://openalex.org/W4385573298",
    "https://openalex.org/W3015468748",
    "https://openalex.org/W4386907303",
    "https://openalex.org/W4327522884",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2964110616",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4385571145",
    "https://openalex.org/W3035390927",
    "https://openalex.org/W4389403907",
    "https://openalex.org/W4327810667",
    "https://openalex.org/W4377121468",
    "https://openalex.org/W4283810944",
    "https://openalex.org/W4379468930",
    "https://openalex.org/W4380352277",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W3105238007",
    "https://openalex.org/W4386435778"
  ],
  "abstract": "Realizing the recent advances from Natural Language Processing (NLP) to the legal sector poses challenging problems such as extremely long sequence lengths, specialized vocabulary that is usually only understood by legal professionals, and high amounts of data imbalance. The recent surge of Large Language Models (LLM) has begun to provide new opportunities to apply NLP in the legal domain due to their ability to handle lengthy, complex sequences. Moreover, the emergence of domain-specific LLMs has displayed extremely promising results on various tasks. In this study, we aim to quantify how general LLMs perform in comparison to legal-domain models (be it an LLM or otherwise). Specifically, we compare the zero-shot performance of three general-purpose LLMs (ChatGPT-3.5, LLaMA-70b and Falcon-180b) on the LEDGAR subset of the LexGLUE benchmark for contract provision classification. Although the LLMs were not explicitly trained on legal data, we observe that they are still able to classify the theme correctly in most cases. However, we find that their mic-F1/mac-F1 performance are upto 19.2/26.8% lesser than smaller models fine-tuned on the legal domain, thus underscoring the need for more powerful legal-domain LLMs.",
  "full_text": "Proceedings of the Natural Legal Language Processing Workshop 2023, pages 223–229\nDecember 7, 2023 ©2023 Association for Computational Linguistics\nLarge Language Models are legal but they are not: Making the case for a\npowerful LegalLLM\nThanmay Jayakumar, Fauzan Farooqui∗, Luqman Farooqui∗\nVisvesvaraya National Institute of Technology, Nagpur, India\n{thanmayjayakumar, fauzanfarooqui7, luqmanfarooqui99}@gmail.com\nAbstract\nRealizing the recent advances in Natural Lan-\nguage Processing (NLP) to the legal sector\nposes challenging problems such as extremely\nlong sequence lengths, specialized vocabulary\nthat is usually only understood by legal pro-\nfessionals, and high amounts of data imbal-\nance. The recent surge of Large Language\nModels (LLM) has begun to provide new op-\nportunities to apply NLP in the legal domain\ndue to their ability to handle lengthy, com-\nplex sequences. Moreover, the emergence of\ndomain-specific LLMs has displayed extremely\npromising results on various tasks. In this study,\nwe aim to quantify how general LLMs per-\nform in comparison to legal-domain models\n(be it an LLM or otherwise). Specifically, we\ncompare the zero-shot performance of three\ngeneral-purpose LLMs (ChatGPT-3.5, LLaMA-\n2-70b, and Falcon-180b) on the LEDGAR sub-\nset of the LexGLUE benchmark for contract\nprovision classification. Although the LLMs\nwere not explicitly trained on legal data, we\nobserve that they are still able to classify the\ntheme correctly in most cases. However, we\nfind that their mic-F1/mac-F1 performance is\nupto 19.2/26.8% lesser than smaller models\nfine-tuned on the legal domain, thus underscor-\ning the need for more powerful legal-domain\nLLMs.\n1 Introduction\nLegal professionals typically deal with large\namounts of textual information on a daily basis\nto make well-informed decisions in their practice.\nThis can become very tedious and demanding due\nto the overwhelming amount of data they must man-\nage and the meticulous attention to detail necessary\nto maintain the required precision in their work.\nThanks to the rise of LLMs, many tasks such as\nsentiment analysis, named entity recognition, in-\nformation retrieval, etc. can now be handled by\n*These authors contributed equally\nneural models. Though this holds true for the legal\ndomain as well (Sun, 2023), they aren’t used to\nmake direct decisions. Nevertheless, these auto-\nmated systems that produce legal predictions and\ngenerations, are predominantly useful as advisory\ntools for legal practitioners that can augment their\ndecision-making process.\nTransformers (Vaswani et al., 2017) have be-\ncome the de facto method for many text classi-\nfication and multiple choice question answering\ntasks. BERT (Devlin et al., 2019), a transformer-\nencoder, and its derived models like RoBERTa (Liu\net al., 2019) are commonly employed in legal NLP\ntasks. Pre-training such models on legal corpora\ncan help a model adapt to a specific domain by fine-\ntuning it with domain-specific data. LegalBERT\n(Chalkidis et al., 2020) is one such BERT model\nthat was trained on legal-oriented data. CaseLaw-\nBERT (Zheng et al., 2021), PoL-BERT (Henderson\net al., 2022), and LexLM (Chalkidis et al., 2023)\nare a few more BERT-based variants pre-trained for\nthe legal domain. Although they show remarkable\nperformance on various legal tasks in comparison\nwith general-purpose BERT models, one limit of\nthese models is that BERT’s input size can only\nincorporate a maximum of 512 tokens. For short\nsequences this may seem enough, but in the case\nof long documents which is commonly found in\nthe legal domain, where input texts can go over\n5000 tokens (and requiring even more in few-shot\nsettings), it can be a severe drawback as a lot of\nimportant information will get truncated.\nDue to this limit, BERT-based models aren’t em-\nployed as-is in long-document tasks. Typically,\nmethods like hierarchical attention are utilized\nwhere the long document is split into segments\nof max length (512 in the case of BERT mod-\nels) and these segments are independently encoded.\nThese segment embeddings are then aggregated\nwith stacked transformers to get the overall encod-\ning of the entire document. Similarly, recurrent\n223\ntransformers (Dai et al., 2019; Yang et al., 2019;\nDing et al., 2021) were proposed to process long\ndocuments by encoding its representation from in-\ndividual segments in a recurrent fashion. Sparse\nattention is another method that has been proposed\nto tackle long sequence inputs (Ainslie et al., 2020;\nZaheer et al., 2020). Longformer (Beltagy et al.,\n2020) uses a combination of local and global at-\ntention mechanisms to save on computational com-\nplexity and enables the processing of up to 4096\ntokens. A number of other works (Dai et al., 2022;\nMamakas et al., 2022) show that transformer-based\narchitectures that can capture longer text boast ma-\njor benefits, even more so when augmented with\nstrategies like sparse-attention and hierarchical net-\nworks. This again underlines an important direction\nfor verbose legal datasets. Our contributions can\nbe summarized as follows:\n• We conduct experiments to compare and ana-\nlyze the zero-shot performance of three gen-\neral LLMs to start-of-the-art in-domain mod-\nels on the LEDGAR subset of LexGLUE\n(Chalkidis et al., 2022). We analyze our re-\nsults and provide insights for further research.\n• We provide an overview of the most recent\nLLM research, the benchmarks and datasets\ndeveloped for legal NLP, the challenges faced\nwhen applying them to legal tasks, and pop-\nular approaches that try to solve them. We\nbelieve this to be a useful primer for anyone\nlooking to get a bird’s eye view of the field.\n2 Related Work\nIn this section, we outline the relevant research on\nLLMs, efforts using them for legal domain tasks,\nand finally the benchmarks and datasets.\n2.1 Large Language Models\nOpenAI GPT: GPT (Generative Pre-trained\nTransformer) (Radford et al., 2019; Brown et al.,\n2020) and the popular ChatGPT variant developed\nby OpenAI are a family of transformer-decoder\npre-trained with a vast amount of text data to\nperform generative and language modeling tasks\nand allows a reasonable context length sufficient to\ncarry out long-document processing. For instance,\nGPT 3.5 allows a maximum of 4096 tokens, and\nGPT 4 allows a stunning maximum of 32,768,\nideal for data consisting of long sequences.\nGoogle PaLM : PaLM (Pathways Language\nModel) (Chowdhery et al., 2022; Anil et al., 2023)\nis an LLM having 540 billion parameters that was\ntrained on the Pathways architecture. Although\nPaLM was initially trained to handle sequence\nlengths of up to 2048 tokens, it was increased to\n8096 in the 340 billion parameter PaLM 2 for a\nlonger comprehension of the input.\nMeta LLaMA: LLaMA (Large Language\nModel Meta AI) (Touvron et al., 2023) is a\ncollection of foundation language models ranging\nfrom 7 billion to 70 billion parameters. It was\npre-trained natively on 2048 input tokens, but\nrecent research has shown that the context length\nof LLMs can be extended efficiently with minimal\ntraining steps (Peng et al., 2023) and they have\nreleased two variations of LLaMA boasting a\ncontext length of 64k and 128k respectively.\nTII Falcon1: As of the time of writing, this\nwork by Technology Innovation Institute (TII) is\nnot yet published but the model has been released\nby them. It boasts of being the largest open-source\nmodel to date of writing having 180 billion\nparameters, and also the highest ranking model on\nthe Huggingface Leaderboard. It includes models\nwith 180B, 40B, 7.5B, and 1.3B parameters,\ntrained on TII’s RefinedWeb dataset (Penedo et al.,\n2023).\n2.2 LLMs on the legal domain\nLexGPT: (Lee, 2023) finetune GPT-J models\non the Pile of Law dataset (Henderson et al.,\n2022) and experiment with generative models\nfor legal classification tasks. They observe that\nfine-tuning such out-of-the-box GPTs do not\nbeat the state-of-the-art and in fact, provides low\nperformance compared to discriminative models.\nThis insightfully shows the need to bridge the gap\nbetween powerful LLMs for the legal domain.\nPolicyGPT: This work (Tang et al., 2023)\ndemonstrates how LLMs in zero-shot settings can\nperform remarkably well in text classification of\nprivacy policies on several baseline LLMs. This\npoints out how a LegalLLM may hold promise in\nenhancing performance on other general tasks.\nZero-and-Few-shot GPT: (Chalkidis, 2023)\n1https://falconllm.tii.ae/falcon.html\n224\nFigure 1: The frequency distributions of the 100 LEDGAR labels in the original LEDGAR test set from LexGLUE\n(left); and in our sampled test set of 1000 examples (right)\nconduct experiments most similar to ours. This\nstudy evaluates the performance of ChatGPT on\nthe LexGLUE benchmark in both zero-shot and\nfew-shot settings (for the latter, examples were\ngiven in the instruction prompt, which seems to\nbenefit the model when the number of examples\nand labels are around the same). They find that\nChatGPT performs very well, but severely lacks in\nperformance compared to smaller models trained\non in-domain datasets.\nResonating these findings, the work of (Savelka,\n2023) investigates how an LLM (a GPT model)\nperforms on a semantic annotation task in the\nzero-shot setting, without being fine-tuned on\nin-domain datasets. The LLM is primed with\na short sentence description of each annotation\nlabel and is tasked with labeling a short span of\ntext. They observe that while the LLM performs\nsurprisingly well given the zero-shot setting, its\nperformance was still far off from the model that\nwas trained on the in-domain data. In summary,\nboth these studies highlight the potential fine-tuned\nLLMs can bring to the legal domain.\n2.3 Datasets and Benchmarks\nLexGLUE: (Chalkidis et al., 2022) present\na unified evaluation framework to benchmark\nmodels. The datasets and tasks were curated from\nother sources of data considering various factors\ninto account such as availability, size, difficulty,\netc. They present scores of various Pre-trained\nLanguage Models (PLMs) on their benchmark.\nWhile doing so, they point out interesting results\nthat suggest that PLMs fine-tuned on legal\ndatasets and tasks do perform better, albeit PLMs\nfine-tuned on only one sub-domain don’t improve\non performance on the same sub-domain. Put\ntogether, their observations point out the need for\na general LegalLLM (powerful enough to outper-\nform other models on all criteria of the benchmark).\nLegalBench: (Guha et al., 2023) This\nbenchmark comprises 162 tasks representing six\ndistinct forms of legal reasoning and outlines\nan empirical evaluation of 20 LLMs. They\ndemonstrate how LegalBench supports easing\ncommunication between legal professionals and\nLLM developers by using the IRAC framework\nin the case of American law. They observe that\nLLMs typically perform better on classification\ntasks than application-based ones. They also find\nthat for some tasks, in-context examples are not\nrequired, or only marginally improve performance.\nThey thus conclude that the task performance in\nLLMs is mostly driven by the task description used\nin the prompt.\nPile of Law: (Henderson et al., 2022) The\nsurge in LLM development emphasizes the need\nfor responsible practices in filtering out biased,\nexplicit, copyrighted, and confidential content\nduring pre-training. Present methodologies are ad\nhoc and do not account for context. This paper\noutlines a method for filtering in the legal domain\nthat handles the trade-offs. Thus, Pile of Law, a\n225\ngrowing 256GB dataset of open-source English\nlegal and administrative data was introduced to aid\nin legal tasks. It allows for the understanding of\ngovernment-established content filtering guidelines\nand illustrates various ways to learn responsible\ndata filtering from the law.\nMultiLegalPile: (Chalkidis et al., 2021)\nThe MultiLegalPile is a 689 GB substantial dataset\nthat spans 24 EU languages across 17 jurisdictions.\nIt addresses the scarce availability of multilingual\npre-training data in specific domains such as law,\nencompassing diverse legal data sources with\nvarying licenses. With further pre-training of\nXLM-R models (Conneau et al., 2019), the study\nattains new SotA results on LEXTREME (Niklaus\net al., 2023). The transformation of the XLM-R\nbase model into a Longformer yields a fresh SotA\nin four LEXTREME datasets. In certain languages,\nmonolingual models substantially outperform the\nXLM-R base model, achieving language-specific\nSotA in five languages. In LexGLUE, English\nmodels secure SotA in five of seven tasks.\n3 Experimental Setup and Results\nIn this section, we describe our experimental ap-\nproach, along with specifics of our evaluations.\n3.1 Dataset and Metrics\nWe use the LEDGAR subset of the LexGLUE\nbenchmark for our experiments due to its readiness\nto work on LLMs (for example, the other datasets\ndo not have the label names; only the label in-\ndices are provided). Given a provision contract, the\nmodel is expected to classify the contract from 100\ngiven labels of EDGAR themes. As mentioned,\nthere is a high imbalance of data in datasets con-\ntaining legal corpora. In particular, refer to Figure\n1 for the label distribution in the LEDGAR subset\nof the LexGLUE benchmark. This could result in\ndifficulties such as biased models, poor generaliza-\ntion, and classification scores due to data imbalance.\nTo overcome these difficulties and enhance model\nevaluations, typically the F1-score is reported for\nsuch models instead of accuracy. The macro-F1\nscore is an even better metric in the case of data\nimbalance compared to micro-F1, and it is due to\nthis reason that the macro-F1 scores are typically\nlower than the micro-F1 on legal tasks.\nAs for the sequence lengths, (Chalkidis, 2023)\nreport the average token length of the instruction-\nfollowing examples in all the LexGLUE subsets\n- the highest being 3.6k tokens. This restricts the\ncapability of LLM performance due to truncation\nas noted earlier, and this is also highlighted in the\nstudy - few-shot settings could not be evaluated\nfor datasets having averaged token length of more\nthan 2k for a single example, and in many cases,\nthe prompts were already truncated up to 4k tokens\n(the maximum limit of ChatGPT). The average\ntoken length of the LEDGAR subset is 0.6k.\n3.2 Setup\nFor our experiments, we use the LEDGAR sub-\nset of the LexGLUE dataset. As baselines, we\ntake three LLMs - ChatGPT (GPT-3.5), LLaMA-2\n(70b), and Falcon (180b). As the models are very\nlarge, we use Huggingface Chat for LLaMA and\nFalcon. Due to this constraint, we only evaluated\non a subset of 1,000 examples. However, we made\nsure that the subset had a label frequency distri-\nbution close to the original dataset 1 so that the\nevaluations may be generalized as much as possi-\nble.\nWe use zero-shot prompting to evaluate the\nabove-mentioned LLMs, building on their bene-\nfit as explained earlier by other works (Tang et al.,\n2023; Guha et al., 2023). However, in the custom\ninstructions (in ChatGPT) and system instructions\n(in Huggingface) we entered the list of EDGAR\ntheme classes that the model should choose from.\nIn the same fashion, to ensure that the model does\nnot generate anything out of the list, we explicitly\nmentioned this as an instruction. The exact instruc-\ntions that we use are provided in the appendix.\nModel mic. F1 mac. F1 # params.\nFalcon-Chat 70.9 60.7 180b\nChatGPT 70.6 58.7 175b\nLLaMA-Chat 70.4 59.6 70b\nLexGPT 83.9 74.0 6b\nLegalBERT 88.2 83.0 0.11b\nTable 1: Comparison of general LLMs (first three mod-\nels, tested on a zero-shot setting) to models fine-tuned\non legal-domain datasets (last two). The current Legal-\nLLM is LexGPT, but the much smaller LegalBERT\nshows state-of-the-art performance on LEDGAR.\n3.3 Results and Discussion\nFor our experiments, we use three baseline general-\npurpose chat variants - ChatGPT-3.5, Falcon-180b,\n226\nand LLaMA-2-70b - and present the results in Ta-\nble 1. General-purpose LLMs perform less well\nthan smaller in-domain models. The best gen-\neral LLM, Falcon-Chat, performs 19.2% mic-F1\nand 26.8% mac-F1 lower than the best in-domain\nmodel, LegalBERT, which itself is much smaller\nthan the LexGPT, the LegalLLM. Our findings echo\nthat of (Chalkidis, 2023).\nNotably, for class labels with only one exam-\nple in our sampled test set, the three chat-variants\nsurprisingly show the same results: they fail to\npredict them correctly excepting the Qualification\nlabel (the others being Assigns, Books, Powers, and\nSanctions. Similarly, Indemnity is always misclas-\nsified as Indemnifications (three examples in total).\nFurther, labels that are semantically similar are dif-\nficult for the models to handle since they frequently\nmislabel such contract provision themes. For ex-\nample, (Taxes, Tax Withholdingsand Withholdings)\nis almost always labeled as Tax Withholdings by\nall the models. (Jurisdictions, Submission To Juris-\ndiction, Consent To Jurisdiction) is almost always\nlabeled as Submission To Jurisdiction in the case\nof ChatGPT and Jurisdiction in the case of Falcon\nand LLaMA. As for ( Applicable Laws, Govern-\ning Laws, Compliance With Laws ), we observe\nthat Governing Laws was easiest to predict with\nan average accuracy of 90%, and Compliance With\nLaws with 80%, butApplicable Laws performs very\npoorly with 0% accuracy for LLaMA and Falcon\nand 20% for ChatGPT - predicting only one from\na total of 5 samples correctly. However, in the case\nof (Payments, Fees, Interests the models seem to\npredict them correctly in about 60% of the cases,\nwith Payments appearing at least once for Fees and\nInterests. On average, only 95 of the 100 classes in\nthe reference labels are present in the predictions.\n3.4 Subjective Analysis\nOur findings highlight that the perceived advan-\ntages LLMs have over BERT-based models (such\nas the sheer amount of large parameters, extended\ncontext length, and the amount of pre-training\nknowledge), cannot substitute for the obvious edge\nin-domain data gives to the much smaller mod-\nels. Even when the LLM is trained so (LexGPT),\nit couldn’t perform as well as the discriminative\nmodel (LegalBERT). This could be expected as\nthe latter is more naturally suited for the bench-\nmark’s classification tasks than generative models\nwhich are prone to issues like hallucination. Our\nlabel-wise findings seem to support this too.\nHowever, the current legal benchmarks are lim-\nited to NLU tasks. In general, it would be ideal\nto have a powerful LegalLLM that can perform\nboth generative and discriminative tasks. Our find-\nings show that there is a unique challenge in the\nlegal domain: if we have to build a better Legal-\nLLM, we need to find better methods to take ad-\nvantage of the in-domain legal data for LLMs as\nsimply fine-tuning it isn’t enough. As the authors\nof LexGPT mention, reinforcement learning from\nhuman feedback could be extremely helpful in im-\nproving LexGPT, providing ways for the first Legal-\nLLM to produce state-of-the-art results.\nHowever, if we limit the application of legal\nmodels to NLU tasks, our findings turn optimistic.\nThe results show that the LLMs’ ability to process\nlarge context may not be necessary for classifica-\ntion - we hypothesize this could be because verbose\nlegal text could turn out to have very similar seman-\ntic content, so the additional context may not be\nuseful. This hypothesis could be echoed by find-\nings from (Shaikh et al., 2020), who show that a\ncareful selection of a handful of textual features\nin a verbose dataset is strong enough to help sta-\ntistical models achieve high accuracies for binary\nclassification.\nThis in fact should be good news, as it means le-\ngal practitioners can avoid having to use or train un-\nnecessarily large or expensive models (both carbon-\nwise and cost-wise). Much smaller in-domain mod-\nels like LegalBERT are nevertheless superior and\nshould be used for practical applications, as also\nsuggested by (Chalkidis, 2023)\n4 Conclusion\nIn this work, we examine three general-purpose\nLLMs’ zero-shot performance on a multi-class\ncontract provision classification task using the\nLEDGAR dataset of LexGLUE. Our study shows\nthat these LLMs, even though aren’t explicitly\ntrained in legal data, can still demonstrate re-\nspectable theme classification performance. The\nresults highlight the need for better LegalLLMs\nadapted to the specifics of the legal industry, which\nhas been underexplored compared to other domains.\nIn light of this, we also present a review of related\ndatasets and models, which we hope will help get\nan overview of the field.\n227\nReferences\nJoshua Ainslie, Santiago Ontanon, Chris Alberti, Va-\nclav Cvicek, Zachary Fisher, Philip Pham, Anirudh\nRavula, Sumit Sanghai, Qifan Wang, and Li Yang.\n2020. ETC: Encoding long and structured inputs in\ntransformers. In Proceedings of the 2020 Conference\non Empirical Methods in Natural Language Process-\ning (EMNLP), pages 268–284, Online. Association\nfor Computational Linguistics.\nRohan Anil, Andrew M Dai, Orhan Firat, Melvin John-\nson, Dmitry Lepikhin, Alexandre Passos, Siamak\nShakeri, Emanuel Taropa, Paige Bailey, Zhifeng\nChen, et al. 2023. Palm 2 technical report. arXiv\npreprint arXiv:2305.10403.\nIz Beltagy, Matthew E Peters, and Arman Cohan. 2020.\nLongformer: The long-document transformer. arXiv\npreprint arXiv:2004.05150.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. Advances in neural information processing\nsystems, 33:1877–1901.\nIlias Chalkidis. 2023. Chatgpt may pass the bar exam\nsoon, but has a long way to go for the lexglue bench-\nmark. arXiv preprint arXiv:2304.12202.\nIlias Chalkidis, Manos Fergadiotis, and Ion Androut-\nsopoulos. 2021. MultiEURLEX - a multi-lingual and\nmulti-label legal document classification dataset for\nzero-shot cross-lingual transfer. In Proceedings of\nthe 2021 Conference on Empirical Methods in Natu-\nral Language Processing, pages 6974–6996, Online\nand Punta Cana, Dominican Republic. Association\nfor Computational Linguistics.\nIlias Chalkidis, Manos Fergadiotis, Prodromos Malaka-\nsiotis, Nikolaos Aletras, and Ion Androutsopoulos.\n2020. LEGAL-BERT: The muppets straight out of\nlaw school. In Findings of the Association for Com-\nputational Linguistics: EMNLP 2020 , pages 2898–\n2904, Online. Association for Computational Lin-\nguistics.\nIlias Chalkidis, Nicolas Garneau, Catalina Goanta,\nDaniel Katz, and Anders Søgaard. 2023. LeXFiles\nand LegalLAMA: Facilitating English multinational\nlegal language model development. In Proceedings\nof the 61st Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 15513–15535, Toronto, Canada. Association\nfor Computational Linguistics.\nIlias Chalkidis, Abhik Jana, Dirk Hartung, Michael\nBommarito, Ion Androutsopoulos, Daniel Katz, and\nNikolaos Aletras. 2022. LexGLUE: A benchmark\ndataset for legal language understanding in English.\nIn Proceedings of the 60th Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n1: Long Papers), pages 4310–4330, Dublin, Ireland.\nAssociation for Computational Linguistics.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, et al. 2022. Palm: Scaling\nlanguage modeling with pathways. arXiv preprint\narXiv:2204.02311.\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzmán, Edouard Grave, Myle Ott, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2019. Unsupervised\ncross-lingual representation learning at scale. arXiv\npreprint arXiv:1911.02116.\nXiang Dai, Ilias Chalkidis, Sune Darkner, and Desmond\nElliott. 2022. Revisiting transformer-based models\nfor long document classification. In Findings of the\nAssociation for Computational Linguistics: EMNLP\n2022, pages 7212–7230, Abu Dhabi, United Arab\nEmirates. Association for Computational Linguistics.\nZihang Dai, Zhilin Yang, Yiming Yang, Jaime Car-\nbonell, Quoc Le, and Ruslan Salakhutdinov. 2019.\nTransformer-XL: Attentive language models beyond\na fixed-length context. In Proceedings of the 57th\nAnnual Meeting of the Association for Computational\nLinguistics, pages 2978–2988, Florence, Italy. Asso-\nciation for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nSiYu Ding, Junyuan Shang, Shuohuan Wang, Yu Sun,\nHao Tian, Hua Wu, and Haifeng Wang. 2021.\nERNIE-Doc: A retrospective long-document model-\ning transformer. In Proceedings of the 59th Annual\nMeeting of the Association for Computational Lin-\nguistics and the 11th International Joint Conference\non Natural Language Processing (Volume 1: Long\nPapers), pages 2914–2927, Online. Association for\nComputational Linguistics.\nNeel Guha, Julian Nyarko, Daniel E Ho, Christopher\nRé, Adam Chilton, Aditya Narayana, Alex Chohlas-\nWood, Austin Peters, Brandon Waldon, Daniel N\nRockmore, et al. 2023. Legalbench: A collabo-\nratively built benchmark for measuring legal rea-\nsoning in large language models. arXiv preprint\narXiv:2308.11462.\nPeter Henderson, Mark Krass, Lucia Zheng, Neel Guha,\nChristopher D Manning, Dan Jurafsky, and Daniel\nHo. 2022. Pile of law: Learning responsible data\nfiltering from the law and a 256gb open-source legal\ndataset. Advances in Neural Information Processing\nSystems, 35:29217–29234.\n228\nJieh-Sheng Lee. 2023. Lexgpt 0.1: pre-trained\ngpt-j models with pile of law. arXiv preprint\narXiv:2306.05431.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nDimitris Mamakas, Petros Tsotsi, Ion Androutsopou-\nlos, and Ilias Chalkidis. 2022. Processing long legal\ndocuments with pre-trained transformers: Modding\nLegalBERT and longformer. In Proceedings of the\nNatural Legal Language Processing Workshop 2022,\npages 130–142, Abu Dhabi, United Arab Emirates\n(Hybrid). Association for Computational Linguistics.\nJoel Niklaus, Veton Matoshi, Pooja Rani, Andrea\nGalassi, Matthias Stürmer, and Ilias Chalkidis.\n2023. Lextreme: A multi-lingual and multi-task\nbenchmark for the legal domain. arXiv preprint\narXiv:2301.13126.\nGuilherme Penedo, Quentin Malartic, Daniel Hesslow,\nRuxandra Cojocaru, Alessandro Cappelli, Hamza\nAlobeidli, Baptiste Pannier, Ebtesam Almazrouei,\nand Julien Launay. 2023. The refinedweb dataset\nfor falcon llm: outperforming curated corpora with\nweb data, and web data only. arXiv preprint\narXiv:2306.01116.\nBowen Peng, Jeffrey Quesnelle, Honglu Fan, and En-\nrico Shippole. 2023. Yarn: Efficient context window\nextension of large language models. arXiv preprint\narXiv:2309.00071.\nAlec Radford, Jeff Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners.\nJaromir Savelka. 2023. Unlocking practical applica-\ntions in legal domain: Evaluation of gpt for zero-shot\nsemantic annotation of legal texts. arXiv preprint\narXiv:2305.04417.\nRafe Athar Shaikh, Tirath Prasad Sahu, and Veena\nAnand. 2020. Predicting outcomes of legal cases\nbased on legal factors using classifiers. Procedia\nComputer Science, 167:2393–2402.\nZhongxiang Sun. 2023. A short survey of viewing\nlarge language models in legal aspect. arXiv preprint\narXiv:2303.09136.\nChenhao Tang, Zhengliang Liu, Chong Ma, Zihao Wu,\nYiwei Li, Wei Liu, Dajiang Zhu, Quanzheng Li, Xi-\nang Li, Tianming Liu, et al. 2023. Policygpt: Au-\ntomated analysis of privacy policies with large lan-\nguage models. arXiv preprint arXiv:2309.10238.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro,\nFaisal Azhar, et al. 2023. Llama: Open and effi-\ncient foundation language models. arXiv preprint\narXiv:2302.13971.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. Advances in neural information processing\nsystems, 30.\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-\nbonell, Russ R Salakhutdinov, and Quoc V Le. 2019.\nXlnet: Generalized autoregressive pretraining for lan-\nguage understanding. Advances in neural informa-\ntion processing systems, 32.\nManzil Zaheer, Guru Guruganesh, Kumar Avinava\nDubey, Joshua Ainslie, Chris Alberti, Santiago On-\ntanon, Philip Pham, Anirudh Ravula, Qifan Wang,\nLi Yang, et al. 2020. Big bird: Transformers for\nlonger sequences. Advances in neural information\nprocessing systems, 33:17283–17297.\nLucia Zheng, Neel Guha, Brandon R Anderson, Peter\nHenderson, and Daniel E Ho. 2021. When does pre-\ntraining help? assessing self-supervised learning for\nlaw and the casehold dataset of 53,000+ legal hold-\nings. In Proceedings of the eighteenth international\nconference on artificial intelligence and law, pages\n159–168.\nA Custom Prompt\nFor reproducibility, we present the prompts that\nwe use for all our experiments. The following is\nthe entry to the Custom Instructions setting of\nChatGPT. For HuggingChat, we simply provide\nboth the instructions to the Custom System Prompt\nbox.\nWhat would you like ChatGPT to know\nabout you to provide better responses?I want\nyou to be an EDGAR contract provision classifier.\nGiven a contract provision, you should correctly\nidentify the EDGAR theme. Do not give any\nexplanations.\nHow would you like ChatGPT to respond?\nOne answer from the following list: [ {{paste the\nlist here}} ]. Do not give an option that is not in\nthe list.\n229",
  "topic": "Vocabulary",
  "concepts": [
    {
      "name": "Vocabulary",
      "score": 0.6057926416397095
    },
    {
      "name": "Computer science",
      "score": 0.5871374607086182
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.5732718110084534
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.5617764592170715
    },
    {
      "name": "Natural language processing",
      "score": 0.5074202418327332
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4445386230945587
    },
    {
      "name": "Language model",
      "score": 0.4100847542285919
    },
    {
      "name": "Linguistics",
      "score": 0.15610462427139282
    },
    {
      "name": "Geography",
      "score": 0.13269078731536865
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Geodesy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I167153416",
      "name": "Visvesvaraya National Institute of Technology",
      "country": "IN"
    }
  ]
}