{
    "title": "Feasibility of large language models for CEUS LI-RADS categorization of small liver nodules in patients at risk for hepatocellular carcinoma",
    "url": "https://openalex.org/W4405560434",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2116466230",
            "name": "Jiayan Huang",
            "affiliations": [
                "Sichuan University",
                "West China Hospital of Sichuan University"
            ]
        },
        {
            "id": "https://openalex.org/A2111018549",
            "name": "Rui Yang",
            "affiliations": [
                "Sichuan University",
                "West China Hospital of Sichuan University"
            ]
        },
        {
            "id": "https://openalex.org/A2117993376",
            "name": "Xiaotong Huang",
            "affiliations": [
                "West China Hospital of Sichuan University",
                "Sichuan University"
            ]
        },
        {
            "id": "https://openalex.org/A2788958744",
            "name": "Keyu Zeng",
            "affiliations": [
                "West China Hospital of Sichuan University",
                "Sichuan University"
            ]
        },
        {
            "id": "https://openalex.org/A2100197731",
            "name": "Yan Liu",
            "affiliations": [
                "Panzhihua University"
            ]
        },
        {
            "id": "https://openalex.org/A1954526174",
            "name": "Jun Luo",
            "affiliations": [
                "Sichuan Academy of Medical Sciences & Sichuan Provincial People's Hospital"
            ]
        },
        {
            "id": "https://openalex.org/A146307737",
            "name": "Andrej Lyshchik",
            "affiliations": [
                "Thomas Jefferson University Hospital",
                "Jefferson University Hospitals"
            ]
        },
        {
            "id": "https://openalex.org/A2057686425",
            "name": "Qiang Lu",
            "affiliations": [
                "Sichuan University",
                "West China Hospital of Sichuan University"
            ]
        },
        {
            "id": "https://openalex.org/A2116466230",
            "name": "Jiayan Huang",
            "affiliations": [
                "Sichuan University",
                "West China Hospital of Sichuan University"
            ]
        },
        {
            "id": "https://openalex.org/A2111018549",
            "name": "Rui Yang",
            "affiliations": [
                "West China Hospital of Sichuan University",
                "Sichuan University"
            ]
        },
        {
            "id": "https://openalex.org/A2117993376",
            "name": "Xiaotong Huang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2788958744",
            "name": "Keyu Zeng",
            "affiliations": [
                "Sichuan University",
                "West China Hospital of Sichuan University"
            ]
        },
        {
            "id": "https://openalex.org/A2100197731",
            "name": "Yan Liu",
            "affiliations": [
                "Panzhihua University",
                "Panzhihua Central Hospital",
                "Sichuan University",
                "West China Hospital of Sichuan University"
            ]
        },
        {
            "id": "https://openalex.org/A1954526174",
            "name": "Jun Luo",
            "affiliations": [
                "Sichuan Academy of Medical Sciences & Sichuan Provincial People's Hospital"
            ]
        },
        {
            "id": "https://openalex.org/A146307737",
            "name": "Andrej Lyshchik",
            "affiliations": [
                "Thomas Jefferson University Hospital",
                "Jefferson University Hospitals"
            ]
        },
        {
            "id": "https://openalex.org/A2057686425",
            "name": "Qiang Lu",
            "affiliations": [
                "West China Hospital of Sichuan University",
                "Sichuan University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4387964910",
        "https://openalex.org/W2900431092",
        "https://openalex.org/W3213277274",
        "https://openalex.org/W2747718548",
        "https://openalex.org/W2600895295",
        "https://openalex.org/W4395049422",
        "https://openalex.org/W4392703844",
        "https://openalex.org/W4390919701",
        "https://openalex.org/W4362522726",
        "https://openalex.org/W4376640725",
        "https://openalex.org/W4396510754",
        "https://openalex.org/W3037886579",
        "https://openalex.org/W2163486683",
        "https://openalex.org/W3172005333",
        "https://openalex.org/W3129849042",
        "https://openalex.org/W6685337412",
        "https://openalex.org/W2990629462",
        "https://openalex.org/W3044977887",
        "https://openalex.org/W2961105574",
        "https://openalex.org/W2171662722",
        "https://openalex.org/W4385970122",
        "https://openalex.org/W4366330503"
    ],
    "abstract": "Background Large language models (LLMs) offer opportunities to enhance radiological applications, but their performance in handling complex tasks remains insufficiently investigated Purpose To evaluate the performance of LLMs integrated with Contrast-enhanced Ultrasound Liver Imaging Reporting and Data System (CEUS LI-RADS) in diagnosing small (≤20mm) hepatocellular carcinoma (sHCC) in high-risk patients. Materials and Methods From November 2014 to December 2023, high-risk HCC patients with untreated small (≤20mm) focal liver lesions (sFLLs), were included in this retrospective study. ChatGPT-4.0, ChatGPT-4o, ChatGPT-4o mini, and Google Gemini were integrated with imaging features from structured CEUS LI-RADS reports to assess their diagnostic performance for sHCC. The diagnostic efficacy of LLMs for small HCC were compared using McNemar test. Results The final population consisted of 403 high-risk patients (52 years ± 11, 323 men). ChatGPT-4.0 and ChatGPT-4o demonstrated substantial to almost perfect intra-agreement for CEUS LI-RADS categorization (κ values: 0.76-1.0 and 0.7-0.94, respectively), outperforming ChatGPT-4o mini (κ values: 0.51-0.72) and Google Gemini (κ values: -0.04-0.47). ChatGPT-4.0 had higher sensitivity in detecting sHCC than ChatGPT-4o (83%-89% vs. 70%-78%, p &amp;lt; 0.02) with comparable specificity (76%-90% vs. 83%-86%, p &amp;gt; 0.05). Compared to human readers, ChatGPT-4.0 showed superior sensitivity (83%-89% vs. 63%-78%, p &amp;lt; 0.004) and comparable specificity (76%-90% vs. 90%-95%, p &amp;gt; 0.05) in diagnosing sHCC. Conclusion LLM integrated with CEUS LI-RADS offers potential tool in diagnosing sHCC for high-risk patients. ChatGPT-4.0 demonstrated satisfactory consistency in CEUS LI-RADS categorization, offering higher sensitivity in diagnosing sHCC while maintaining comparable specificity to that of human readers.",
    "full_text": "Feasibility of large language\nmodels for CEUS LI-RADS\ncategorization of small liver\nnodules in patients at risk for\nhepatocellular carcinoma\nJiayan Huang1, RuiYang1, XiaotongHuang1, KeyuZeng1,\nYan Liu2, JunLuo3, AndrejLyshchik4* and QiangLu1*\n1West China Hospital of Sichuan University, Chengdu, China,2Department of Ultrasound, Afﬁliated\nHospital of Panzhihua University, Panzhihua, China,3Department of Ultrasound, Sichuan Academy of\nMedical Sciences and Sichuan Provincial People’s Hospital, Chengdu, China,4Thomas Jefferson\nUniversity Hospital , Jefferson University Hospitals, Philadelphia, PA, United States\nBackground: Large language models (LLMs) offer opportunities to enhance\nradiological applications, but their performance in handling complex tasks\nremains insufﬁciently investigated\nPurpose: To evaluate the performance of LLMsintegrated with Contrast-enhanced\nUltrasound Liver Imaging Reporting and Data System (CEUS LI-RADS) in diagnosing\nsmall (≤20mm) hepatocellular carcinoma (sHCC) in high-risk patients.\nMaterials and Methods: From November 2014 to December 2023, high-risk\nHCC patients with untreated small (≤20mm) focal liver lesions (sFLLs), were\nincluded in this retrospective study. ChatGPT-4.0, ChatGPT-4o, ChatGPT-4o\nmini, and Google Gemini were integrated with imaging features from structured\nCEUS LI-RADS reports to assess their diagnostic performance for sHCC. The\ndiagnostic efﬁcacy of LLMs for small HCC were compared using McNemar test.\nResults: The ﬁnal population consisted of 403 high-risk patients (52 years ± 11, 323\nmen). ChatGPT-4.0 and ChatGPT-4o demonstrated substantial to almost perfect\nintra-agreement for CEUS LI-RADS categorization (k values: 0.76-1.0 and 0.7-0.94,\nrespectively), outperforming ChatGPT-4o mini (k values: 0.51-0.72) and Google\nGemini (k values: -0.04-0.47). ChatGPT-4.0 had higher sensitivity in detecting sHCC\nthan ChatGPT-4o (83%-89% vs. 70%-78%,p < 0.02) with comparable speciﬁcity\n(76%-90% vs. 83%-86%,p > 0.05). Compared to human readers, ChatGPT-4.0\nshowed superior sensitivity (83%-89% vs. 63%-78%,p < 0.004) and comparable\nspeciﬁcity (76%-90% vs. 90%-95%,p > 0.05) in diagnosing sHCC.\nConclusion: LLM integrated with CEUS LI-RADS offers potential tool in diagnosing\nsHCC for high-risk patients. ChatGPT-4.0 demonstrated satisfactory consistency\nin CEUS LI-RADS categorization, offering higher sensitivity in diagnosing sHCC\nwhile maintaining comparable speciﬁcity to that of human readers.\nKEYWORDS\nhepatocellular carcinoma (HCC), large language model (LLM), diagnosis, CEUS\n(Contrast-enhanced ultrasound), ultrasound\nFrontiers inOncology frontiersin.org01\nOPEN ACCESS\nEDITED BY\nAbdullah Esmail,\nHouston Methodist Hospital, United States\nREVIEWED BY\nJonathan Soldera,\nUniversity of Caxias do Sul, Brazil\nShao Bo Duan,\nHenan Provincial People’s Hospital, China\n*CORRESPONDENCE\nAndrej Lyshchik\nAndrej.Lyshchik@jefferson.edu\nQiang Lu\nluqiang@scu.edu.cn\nRECEIVED 18 October 2024\nACCEPTED 22 November 2024\nPUBLISHED 18 December 2024\nCITATION\nHuang J,Yang R,Huang X,Zeng K,Liu Y,\nLuo J,Lyshchik A andLu Q (2024) Feasibility\nof large language models for CEUS LI-RADS\ncategorization of small liver nodules in\npatients at risk for hepatocellular carcinoma.\nFront. Oncol. 14:1513608.\ndoi: 10.3389/fonc.2024.1513608\nCOPYRIGHT\n©2 0 2 4H u a n g ,Y a n g ,H u a n g ,Z e n g ,L i u ,L u o ,\nLyshchik and Lu. This is an open-access article\ndistributed under the terms of theCreative\nCommons Attribution License (CC BY).The\nuse, distribution or reproduction in other\nforums is permitted, provided the original\nauthor(s) and the copyright owner(s) are\ncredited and that the original publication in\nthis journal is cited, in accordance with\naccepted academic practice. No use,\ndistribution or reproduction is permitted\nwhich does not comply with these terms.\nTYPE Original Research\nPUBLISHED 18 December 2024\nDOI 10.3389/fonc.2024.1513608\nIntroduction\nL i v e rc a n c e ri st h es i x t hm o s tc o m m o nc a n c e ra n dt h et h i r d\nleading cause of cancer-related deaths worldwide, with over 830,000\ndeaths in 2020 and rising mortality rates ( 1). Among all the\npathological subtypes of liver cancer, hepatocellular carcinoma\n(HCC) accounts for the majority of cases. However, due to the\ncomplex dual blood supply to liver and the multistage process of\nHCC, radiological diagnosis of HCC remains challenging (2). Notably,\nthe early diagnosis of HCC, especially for tumors measuring 2 cm or\nsmaller in diameter (small HCC), due to it offers more treatment\noptions, reduced risk of complications and better prognosis (3).\nThe Contrast-enhanced Ultrasound Liver Imaging Reporting and\nData System (CEUS LI-RADS) released by American College of\nRadiology (ACR)aims to improve the accuracy and consistency of\nHCC diagnosis in patients at high-risk (4, 5). The implementation of\nstructured reporting in radiology plays a pivotal role in improving\ncommunication, fostering collaboration among medical practitioners,\nand standardizing reporting language across institutions ( 6).\nMoreover, the characterization of focal liver lesions (FLLs) using\nCEUS LI-RADS, based on imaging features derived from B-mode\nand multiphasic CEUS enhancement patterns, establishes a robust\nfoundation for the application of artiﬁcial intelligence (AI) in imaging\ndiagnosis. Large Language Models (LLM) represent a specialized AI\napplication that focuses on comprehending and generating text\nresembling human-like language. Recently conducted research on\nthe interaction strategy between humans and LLM has shown\npromising results in terms of LLM-agreement and diagnostic\naccuracy for predicting benign andmalignant thyroid nodules using\nthe ACR Thyroid Imaging Reporting and Data System (TI-RADS) (7).\nAmid signiﬁcant advancements in LLMs, AI chatbots like\nChatGPT have gained increasing attention across various ﬁelds\n(8). The Chatbot (primarily ChatGPT 4.0) has showed potential in\ntransforming unstructured free-text reports into organized formats\n(6, 9). However, the impressive capability of LLMs in rapid and\nstandardized language processing notwithstanding, concerns have\nincreasingly arisen regarding the assessment of their agreement and\naccuracy in generating prompt output. The subjective question-\nanswering format may inadvertently be in ﬂuenced by existing\nbiases and disparities, thereby overlooking crucial aspects of\ntransparency and accuracy when investigating the applications of\nLLMs (7, 10). Notably, LLMs such as ChatGPT 4.0 do not support\nconcurrent recognition or processing of multiple images. Given that\nthis approach is more practical for handling natural language, the\nmedical application of LLMs, particularly in processing radiology\nreports, represents a critical and cutting-edge area of research at the\nforefront of LLM advancements (6–9, 11). Despite the promising\nefﬁcacy of LLMs demonstrated by a rapidly emerging plethora of\nstudies, their potential in aiding real-world clinical applications\nremains controversial.\nTo our knowledge, the performance of LLMs in classifying FLLs\nbased on CEUS LI-RADS reports, p articularly regarding their\noutput LLMs-agreement and accuracy, has not been previously\nreported. Thus, the purpose of our study was to evaluate the intra-\nand inter-agreement of four publicly available LLMs (Google\nGemini, ChatGPT-4.0, ChatGPT-4o, and ChatGPT-4o mini) in\nCEUS LI-RADS categorization using structured CEUS reports from\npatients with small FLLs. Moreover, the diagnostic accuracy of\nLLMs in diagnosing small HCC was also investigated, using a\ncomposite reference standard as previously described (\n12).\nMaterials and methods\nThis retrospective study was approved by the ethics committee\nof West China Hospital of Sichuan University, and written\ninformed consent was waived. To consecutively collect\nparticipants, 172 samples in this study were drawn from our\nprevious investigation (12). Ultrasound images of these patients\nwere used to develop structured reports for LLMs, while in the\nearlier research, they were used for evaluating the diagnostic\naccuracy of CEUS LI-RADS (version 2017).\nStudy design\nThis study investigated four publicly available LLM chatbots,\nincluding three versions of ChatGPT (ChatGPT-4.0, ChatGPT-4o,\nChatGPT-4o mini) and Google Gemini. Ultrasound images of small\nfocal liver lesions (sFLLs) were assessed by six certiﬁed ultrasound\nradiologists with 3 to 20 years of liver CEUS experience using CEUS\nLI-RADS (Version 2017). Structured reports were then rendered\nand entered into LLMs for prompt CEUS LI-RADS categorization.\nThree output rounds (with an extra round if completely\ninconsistent) were performed to evaluate the intra-agreement of\nLLM in sFLLs categorization, with a majority vote deciding theﬁnal\nCEUS LI-RADS category. To avoid space-time impact, outputs were\nspaced three days apart. The diagnostic efﬁcacy of LLMs for sHCC\nwas compared by analyzing reports from readers with varying\nexpertise. Furthermore, the best-performing LLM was compared\nto human readers and a convolutional neural network (CNN)\nmodel in diagnosing sHCC (Figure 1).\nPatient selection and reference standard\nConsecutive patients underwent hepatic CEUS examinations\nwere retrospectively collected from November 2014 to December\n2023. The inclusion criteria were:(a) aged 18 or older;(b) HCC risk\nfactors involving cirrhosis or chronic hepatitis B (HBV); (c)\nuntreated hepatic nodules ≤20 mm on imaging (ultrasound, CT\nor MRI);(d) less than two sFLLs, with the larger tumor selected for\nanalysis to minimize the impact of multiple injections on contrast\nenhancement. Exclusio n criteria included: (a) indeterminate\npathology, contrast-enhanced CT/MRI results, or incomplete\nfollow-up; (b) poor-quality ultrasound images. HCC risk factors\nHuang et al. 10.3389/fonc.2024.1513608\nFrontiers inOncology frontiersin.org02\nwere deﬁned as any cause of cirrhosis and/or HBV, per the\nAmerican Association for the Study of Liver Diseases guidelines\n(13). Patients with a history of HCC treatment were excluded to\nminimize the inﬂuence from post-treatment changes.\nThis study used a composite reference standard as previously\ndescribed in our earlier investigation (12). In brief, all lesions were\ndiagnosed by histopathology, while contrast-enhanced CT/MRI were\nused for LR-1 or LR-5 nodules. Diagnosis for LR-2, LR-3, and LR-4\nnodules involved imaging follow-up (≥12 months), pathology, or\nmultidisciplinary recommendat ions, while LR-M lesions were\ndiagnosed by histopathology. The processing of the CEUS\nexamination is detailed inSupplementary Material Appendix S1.\nCEUS LI-RADS category assignment\nby LLMs\nAfter independent review of the images by radiologists, a separate\nradiologist translated the structured reports, including patients’\nclinical and ultrasound characteristics, from Chinese to English.\nThen, the reports were input into ChatGPT-4o mini ( 14),\nChatGPT-4o (15), ChatGPT-4.0 (16) and Google Gemini (17)f o r\nprompt CEUS LI-RADS classiﬁcation. LLMs were integrated with\nCEUS LI-RADS reports to evaluate their agreement and diagnostic\nperformance in diagnosing sHCC, since LLMs currently cannot\ninterpret multiple images directly. The CEUS LI-RADS\nFIGURE 1\nGraphical representation of study design. Overall, LLMs were integrated with structured reports based on the CEUS LI-RADS for diagnosing sHCC (the top\nbox). First, the LLMs' agreement was evaluated by comparing intra-LLM consistency, with the most frequently voted category used for further inter-LLMs\nagreement assessment (the middle box). Second, the diagnostic performance of the LLMs was assessed in comparison to human readers utilizing CEUS LI-\nRADS (Ver. 2017) for diagnosing sHCC, as well as compared to a CNN model (the bottom box). LLMs, large language models; CEUS LI-RADS, Contrast-\nenhanced Ultrasound Liver Imaging Reporting and Data System; sHCC, small hepatocellular carcinoma; CNN, convolutional neural network.\nHuang et al. 10.3389/fonc.2024.1513608\nFrontiers inOncology frontiersin.org03\nclassiﬁcation process for human readers and LLMs is detailed in\nSupplementary Material Appendix S2and Supplementary Figure S1.\nEnd-to-end CNN model of small FLLs\nEnd-to-end CNN models involvingbaseline and multiphase CEUS\nimages were developed for sHCC diagnosis. Patients were randomly\ndivided into training (59.8%, 241 of 403) and validation sets (40.2%,\n162 of 403). The diagnostic efﬁcacy of the CNN for sHCC was\nevaluated using the validation cohort. Algorithm and network\nstructures were established as described in previous investigations (7,\n18). Due to the characterization of FLLs according to CEUS LI-RADS,\nwhich incorporates imaging fe atures from both baseline and\nmultiphasic CEUS images, results were derived by integrating\noutputs from each modality using a weighted averaging method. The\nCNN was developed using ultrasound images of sFLLs, with tumor\nsegmentation performed by a radiologist with three years of liver CEUS\nexperience, utilizing MITK Workbench (https://docs.mitk.org/nightly/\nindex.html). The model was built and executed in Python (version\n3.10.3; Python Software Foundation, Wilmington, Delaware, USA).\nDetailed information regarding network structures and parameters\nis provided in Supplementary Material Appendix S3 ,\nSupplementary Figure S2and Supplementary Table S1.\nStatistical analysis\nFleiss’Kappa and Cohen’s Kappa tests were used to assess intra-\nand inter-LLM agreements, respectively. A best-of-three strategy\nwas used to identify the prefe rred LLM category for sFLLs.\nAgreement strength was classi ﬁed using the Landis and Koch\nscale: 0-0.20 as poor; 0.21-0.40 as fair; 0.41-0.60 as moderate;\n0.61-0.80 as substantial; and 0.81-1.00 as almost perfect.\nLR-5 category is designated for predicting HCC according to\nCEUS LI-RADS, whereas LR-4, LR-5, and LR-M are categorized as\nindicative of malignancy (19). The diagnostic performance of LLMs,\nhuman readers, and CNN strategy for sHCC was assessed by\ncalculating sensitivity, speci ﬁcity, accuracy and area under the\nreceiver operating characteristic curve (AUC) based on standard\nprocedures (12). Sensitivity, speciﬁcity, and accuracy were compared\namong LLMs, between LLMs and human readers, and between LLMs\nand CNNs using the McNemar test. AUCs for sHCC were compared\namong LLMs, human readers, and CNN using DeLong test.\nStatistical analyses were conducted using R packages (R 4.1.2\n[Puppy Cup], The R Foundation, Vienna, Austria) and MedCalc\nsoftware (MedCalc22.030, Ostend, Belgium). A P-value less than.05\nindicated statistical signiﬁcance.\nResults\nPatients and liver nodule characteristics\nA total of 1612 representative ultrasound images, including B-\nmode, arterial phase, portal phase, and late phase images (one\nrepresentative image per phase), were obtained from 403 patients at\nrisks of HCC with sFLLs (Figure 2). Of the 403 patients (mean age,\n52.3 years ± 10.8; age range, 21–81 years), 323 (80.1%) were men.\nThe mean size of sFLLs was 16.1 mm ± 3.4. Clinical features of\npatients involving age, gender, liver disease etiology, nodule size,\nand pathological results are exhibited in Table 1. Based on the\ncomposite reference standard, 263 liver nodules were proved by\npathology, 65 by follow-up, and 75 by contrast enhanced CT or\nMRI (including 42 HCC and 33 hemangioma). The median follow-\nup period was 15.2 months (range 12–41 months). The constitution\nof 403 sFLLs and the distribution of CEUS LI-RADS categories, as\ndetermined by human readers and LMMs, are depicted inFigure 3.\nIntra- and inter-LLM Agreement on CEUS\nLI-RADS categorization for small FLLs\nThe distributions of intra-LLM agreement and inter-LLM\nagreement are presented inTable 2. ChatGPT-4.0 and ChatGPT-\n4o demonstrated substantial to almost perfect intra-agreement in\nthe CEUS LI-RADS classiﬁcation assignment among radiologists\nwith varying levels of liver CEUS experience (k value = 0.76-1[95%\nCI: 0.69, 1], and 0.7-0.94 [95% CI: 0.55, 0.99] for ChatGPT-4.0, and\nChatGPT 4o, respectively). There was moderate to substantial intra-\nagreement for ChatGPT-4o mini, withk values ranging from 0.51\nto 0.72 (95% CI: 0.33 to 0.79). However, apart from moderate\nagreement for a junior radiologist, Google Gemini demonstrated\npoor to fair intra-LLM agreement for the other radiologists (k value\n= -0.04 to 0.47 [95% CI: -0.32, 0.6]).\nAs for the inter-LLM agreement evaluation, GPT-4.0 and GPT-\n4o achieved substantial to almost perfect agreement for both the\njunior and senior radiologists (k value = 0.7-0.86 [95% CI: 0.58,\n0.97]), and substantial agreement for the expert radiologists (k value\n= 0.63-0.69 [95% CI: 0.4, 0.79]), respectively. ChatGPT-4o mini\nshowed fair to moderate agreement with ChatGPT-4.0 (k value =\n0.27-0.55 [95% CI: 0.05, 0.69]) involving all readers, whereas poor\nto substantial agreement with ChatGPT-4o (k value = 0.16-0.66\n[95% CI: -0.15, 0.92]). There was poor to fair agreement between\nGoogle Gemini and ChatGPT, including version 4o mini, 4.0 and\n4o, withk values ranging from -0.3 to 0.55 (95% CI: -0.47 to 0.67),\nregardless of the radiologist’s expertise.\nFIGURE 2\nStudy populationﬂowchart. US, ultrasound; HCC, hepatocellular\ncarcinoma; FLL, focal liver lesion.\nHuang et al. 10.3389/fonc.2024.1513608\nFrontiers inOncology frontiersin.org04\nDiagnostic efﬁcacy of ChatGPT-4.0 and\nChatGPT-4o in predicting small HCC\nThe diagnostic performance of LLMs in diagnosing sHCC is\nshown inTable 3and Supplementary Table S2. Since ChatGPT-4.0\nshowed comparable intra-LLM and superior inter-LLM agreement\nto other LLMs, its diagnostic performance was evaluated in greater\ndetail. In a human-LLM interaction context, ChatGPT-4.0\ndemonstrated superi or sensitivity compared to ChatGPT-4o\nacross all readers levels, achieving 83% [95% CI: 73%, 90%]\nversus 70% [95% CI: 59%, 79%] for junior radiologists ( p =\n0.007), 86% [95% CI: 78%, 92%] versus 77% [95% CI: 68%, 84%]\nfor senior radiologists (p = 0.02), and 90% [95% CI: 81%, 95%]\nversus 78% [95% CI: 67%, 87%] for expert radiologists (p = 0.004),\nrespectively. However, ChatGPT-4.0 and ChatGPT-4o exhibited\ncomparable speciﬁcity in differentiating sHCC from non-HCC.\nRegarding diagnostic accurac y, ChatGPT-4.0 demonstrated\nsuperior performance compared to ChatGPT 4o for senior (87%\n[95% CI: 81%, 92%] vs 79% [95% CI: 72%, 85%],p = 0.009) and\nexpert radiologists (90% [95% CI: 83%, 94%] vs 80% [95% CI: 72%,\n87%], p = 0.001). However, they showed comparable performance\nfor junior radiologists (81% [95% CI: 73%, 88%] vs 74% [95% CI:\n65%, 82%], p = 0.12). Similarly, the AUC for ChatGPT-4.0 was\nhigher for senior and expert radiologists (p = 0.01 and p = .001,\nrespectively), but comparable for junior radiologists, when\ncompared with ChatGPT-4o.\nPerformance of human-LLM interaction,\nCEUS LI-RADS and CNN strategy in\ndiagnosing small HCC\nTable 4 shows the diagnostic ef fectiveness for sHCC by\nChatGPT-4.0, human readers using CEUS LI-RADS, and a CNN\nstrategy. ChatGPT-4.0 achieved signiﬁcantly higher sensitivities of\n83% (95% CI: 73%, 90%), 86% (95% CI: 78%, 92%), and 89% (95%\nCI: 81%, 95%) for junior, senior, and expert radiologists,\nrespectively, compared to human readers with corresponding liver\nCEUS expertise, who demonstrated sensitivities of 63% (95% CI:\n52%, 73%) (p <.001), 69% (95% CI: 60%, 78%) (p < 0.001), and 78%\n(95% CI: 67%, 86%) (p = 0.004). Besides, ChatGPT-4.0 had similar\nspeciﬁcity (76%-90% [95% CI: 56%, 97%] vs 90%-95% [95% CI:\n73%, 99%]) to that of human readers, with all P-values above.05. As\nfor accuracy, ChatGPT-4.0 achieved 81% (95% CI: 73%, 88%) for\nthe junior radiologist and 87% (95% CI: 81%, 91%) for the senior\nradiologist, outperforming human readers who showed accuracies\nof 70% (95% CI: 61%, 78%) for the junior radiologist (p = 0.007) and\n79% (95% CI: 72%, 85%) for the senior radiologist (p = 0.004),\nrespectively. Notably, ChatGPT-4.0 showed comparable accuracy to\nthat of the expert radiologist (90% [95% CI: 83%, 94%] vs 84% [95%\nCI: 76%, 90%],p =0.07) and AUC (0.89 [95% CI: 0.83, 0.95] vs 0.86\n[95% CI: 0.79, 0.92],p = 0.20). Examples of LLMs for the CEUS LI-\nRADS category for sHCC are presented inFigures 4and 5.\nTABLE 1 Clinicopathological characteristics of patients.\nCharacteristic Value\nSex\nMen 323 (80.1)\nWoman 80 (19.9)\nMean age (y)* 52.3 ± 10.8 (21 –81)\nMean nodule size (mm)* 16.2 ± 3.4 (0.7 –2)\nLiver disease etiologic cause\nHBV 374 (92.8)\nHCV 11 (2.7)\nHBV and HCV 6 (1.5)\nPBC 1 (0.2)\nAlcohol 4 (1)\nUnknown etiology 7 (1.7)\nCirrhosis 162 (40.2)\nPathologic Analysis\nHCC 223 (55.3)\nWell differentiated 5 (1.2)\nModerately differentiated 161 (40)\nPoorly differentiated 57 (14.1)\nDN/RN 21 (5.2)\nFNH 2 (0.5)\nHemangioma 3 (0.7)\nICC 8 (2)\ncHCC-CCA 2 (0.5)\nMetastasis 1 (0.2)\nReactive lymphoid hyperplasia 1 (0.2)\nBiliary adenoma 1 (0.2)\nNEN 1 (0.2)\nNo pathologic analysis\nContrast-enhanced CT or MRI\nHCC 42 (10.4)\nHemangioma 33 (8.2)\nFollow-up\n< 50% size increase in 12 months 62 (15.4)\n≥50% size increase in 12 months 3 (0.7)\nUnless otherwise indicated, data are liver nodules or patients (n=403) and data in parentheses\nare percentages. Mean data are ± standard deviation. HBV, hepatitis B virus; HCV, hepatitis C\nvirus; PBC, primary biliary cirrhosis; HCC, hepatocellular carcinoma; DN, dysplastic nodule;\nRN, regenerative nodule; FNH, focal nod ular hyperplasia; ICC, intrahepatic\ncholangiocarcinoma; cHCC-CCA, combined hep atocellular-cholangiocarcinoma; NEN,\nneuroendocrine neoplasm.\n*Data in parentheses are range.\nHuang et al. 10.3389/fonc.2024.1513608\nFrontiers inOncology frontiersin.org05\nThe CNN model showed higher sensitivity at 96% (95% CI:\n91%, 97%) compared to 86% (95% CI: 77%, 91%) for ChatGPT-4.0\nwith CEUS LI-RADS (p = 0.004), but lower speciﬁcity at 29% [95%\nCI: 82%, 87%] versus 87% [95% CI: 74%, 94%] (p= < 0.001).\nMoreover, ChatGPT-4.0 exhibited superior accuracy and AUC\ncompared to the CNN model, with an accuracy of 86% (95% CI:\n79%, 91%) versus 75% (95% CI: 67%, 81%,p = 0.01), and an AUC of\n0.86 (95% CI: 0.80, 0.91) versus 0.63 (95% CI: 0.55, 0.70,p < 0.001).\nAdditionally, the diagnostic performance of ChatGPT-4.0,\nhuman readers using CEUS LI-RADS, and a CNN model for\nmalignant sFLLs was investigated, as shown in Supplementary\nTable S3. Supplementary Table S4 presents the performance of\nChatGPT-4o, ChatGPT-4o mini and Genimi in differentiating\nmalignant from benign sFLLs.\nDiscussion\nIn this study, we investigated the intra- and inter-agreement, as\nwell as the diagnostic accuracy of four popular large language\nmodels (LLMs) in diagnosing small hepatocellular carcinoma\n(sHCC) in high-risk patients. ChatGPT-4.0 and ChatGPT-4o\nFIGURE 3\nPathological composition and CEUS LI-RADS categories of liver nodules classiﬁed by human reader and LLMs.(A) Pie chart depicts the pathological\ncomposition of 403 small FLLs according to the reference standard.(B) Horizontal stacked bar chart illustrates the distribution of CEUS LI-RADS\ncategories for small FLLs as assigned by both LLMs and human readers using CEUS LI-RADS category. CEUS LI-RADS, Contrast-enhanced\nUltrasound Liver Imaging Reporting and Data System; FLL, focal liver lesions; LLMs, large language models; HCC, hepatocellular carcinoma; FNH,\nfocal nodular hyperplasia; ICC, intrahepatic cholangiocarcinoma; DN, dysplastic Nodule; RN, regenerative Nodule; cHCC-ICC, combined\nhepatocellular-cholangiocarcinoma.\nTABLE 2 Intra-LLMs and Inter-LLMs agreements for CEUS LI-RADS category assignments.\nAgreement evaluation\nHuman-LLM Interaction\nJunior Radiologist Senior Radiologist Expert Radiologist\n121212\nIntra-LLM agreement*\nGemini -0.04 (-0.32-0.5) 0.47 (0.36-0.6) 0.3 (0.15-0.46) -0.03 (-0.1-0.1) 0.26 (0.12-0.41) 0.07 (-0.1-0.28)\nGPT-4o mini 0.71 (0.35, 0.93) 0.72 (0.65, 0.79) 0.68 (0.56, 0.77) 0.59 (0.49, 0.69) 0.62 (0.5, 0.72) 0.51 (0.33, 0.67)\nGPT-4.0 1 (1-1) 0.84 (0.8-0.88) 0.88 (0.83-0.9) 0.76 (0.69-0.83) 0.9 (0.86-0.93) 0.95 (0.92-0.97)\nGPT-4o 0.94 (0.82-0.99) 0.78 (0.7-0.84) 0.73 (0.63-0.8) 0.8 (0.74-0.85) 0.85 (0.79-0.9) 0.7 (0.55-0.81)\nInter-LLM agreement†\nGemini vs GPT-4o mini -0.14 (-0.7, 0.6) 0.55 (0.41, 0.67) 0.13 (-0.1, 0.36) -0.3 (-0.47, -0.1) -0.05 (-0.3, 0.2) -0.14 (-0.4, 0.2)\nGemini vs GPT-4.0 0.01 (-0.63-0.67) 0.27 (0.09-0.4) 0.06 (-0.18-0.3) -0.2 (-0.4-0.02) 0.14 (-0.1-0.35) 0.15 (-0.16-0.44)\nGemini vs GPT-4o 0.04 (-0.61-0.68) 0.18 (-0.01-0.4) 0.23 (-0.01-0.4) -0.05 (-0.2-0.2) 0.04 (-0.2-0.27) 0.16 (-0.15-0.44)\nGPT-4o mini vs GPT-4.0 0.41 (-0.3, 0.84) 0.35 (0.18, 0.5) 0.55 (0.36, 0.69) 0.48 (0.32, 0.62) 0.27 (0.05, 0.47) 0.34 (0.04, 0.58)\nGPT-4o mini vs GPT-4o 0.66 (0.04, 0.92) 0.19 (-0.01-0.4) 0.47 (0.26, 0.63) 0.34 (0.16, 0.5) 0.25 (0.02, 0.45) 0.16 (-0.15, 0.4)\nGPT-4.0 vs GPT-4o 0.86 (0.50-0.97) 0.7 (0.58-0.78) 0.83 (0.7-0.89) 0.71 (0.6-0.8) 0.69 (0.55-0.79) 0.63 (0.4-0.78)\nThree levels of radiologists individually generated 403 CEUS LI-RSDS reports, along with a prompt output of a CEUS LI-RADS category. Data arek values, and data in parentheses are 95% CIs.\nLLM, large language model; CEUS LI-RADS, contrast-enhanced US Liver Imaging Reporting and Data System.\n*Kappa values calculated as described by Fleiss’k for the Intra-LLM agreement and their 95% CIs.\n†Kappa values calculated as described by Cohen’k for the Inter-LLM agreement and their 95% CIs.\nHuang et al. 10.3389/fonc.2024.1513608\nFrontiers inOncology frontiersin.org06\nshowed substantial to almost perfect intra-agreement (k = 0.76-1\nand 0.7-0.94, respectively) and higher inter-agreement than other\nLLMs (k = 0.63-0.86). In human-LLM interactions using CEUS LI-\nRADS, ChatGPT-4.0 demonstrated comparable speciﬁcity (76%-\n90%) across radiologists with varying levels of liver CEUS expertise,\nsimilar to ChatGPT-4o (83%-86%). However, ChatGPT-4.0\noutperformed ChatGPT-4o with a sensitivity of 83%-89% versus\n70%-78%, p ≤ 0.02. Notably, ChatGPT-4.0 demonstrated superior\nsensitivity, ranging from 83% to 89% compared to 63% to 78% for\nhuman readers ( p ≤ 0.004), in diagnosing sHCC. Moreover,\nChatGPT-4.0 with CEUS LI-RADS outperformed CNN models in\npredicting sHCC with AUC of 0.86 versus 0.63 (p < 0.001). Overall,\nChatGPT-4o mini and Google Gemini showed poor intra- and\ninter-LLM agreement and lower diagnostic efﬁcacy in diagnosing\nsHCC compared to ChatGPT-4.0 and ChatGPT-4o.\nCurrently, the primary focus of LLMs in the diagnostic imaging\nﬁeld is on processing text data, though research is now extending\nthese models to multimodal tasks (such as combining image and\ntext processing) (20, 21). The CEUS LI-RADS released by ACR\nprovides a diagnostic framework for assessing the risk of HCC in\npatients at risk. However, imaging early-stage HCC, particularly\nlesions under 2 cm is challenging (22). We previously determined\nthat CEUS LI-RADS effectively characterizes sFLLs (12), while the\ninteraction between LLMs and CEUS LI-RADS in diagnosing liver\nnodules, especially sFLLs, remains unexplored. By removing\nspatiotemporal interference factors, we found that ChatGPT-4.0\nand ChatGPT-4o achieved superior repeatability in CEUS LI-RADS\ncategorization among the four LLMs. GPT-4o mini is characterized\nby faster processing and superior intelligence compared to\nChatGPT-3.5. However, similar to Google Gemini, it\ndemonstrates poor reproducibility in CEUS LI-RADS\nTABLE 3 Comparison of ChatGPT 4.0 and ChatGPT 4o in predicting\nsmall HCC versus Non-HCC.\nDiagnostic\nPerformance\nHuman-LLM Interaction\nJunior\nRadiologist\nSenior\nRadiologist\nExpert\nRadiologist\nSensitivity (%)\nGPT-4.0 83 (72/87) 86 (93/108) 89 (69/77)\nGPT-4o 70 (61/87) 77 (83/108) 78 (60/77)\np Value 0.007 0.02 0.004\nSpeciﬁcity (%)\nGPT-4.0 76 (22/29) 89 (56/63) 90 (35/39)\nGPT-4o 86 (25/29) 83 (52/63) 85 (33/39)\np Value 0.38 0.34 0.50\nAccuracy (%)\nGPT-4.0 81(94/116) 87 (149/171) 90 (104/116)\nGPT-4o 74 (86/116) 79 (135/171) 80 (93/116)\np Value 0.12 0.009 0.001\nAUC\nGPT-4.0 0.79 (0.71, 0.86) 0.88 (0.82, 0.92) 0.89 (0.83, 0.95)\nGPT-4o 0.78 (0.70, 0.85) 0.79 (0.73, 0.86) 0.81 (0.73, 0.88)\np Value 0.79 0.01 0.001\nData in parentheses for the sensitivity, speciﬁcity and accuracy are numerator/denominator;\ndata in parentheses for the AUC are 95% con ﬁdence intervals. p values present the\ncomparison of performance between ChatGPT 4.0 and ChatGPT 4o in predicting small\nHCC using the same input generated by the same radiologist. LLM, large language model;\nHCC, hepatocellular carcinoma, AUC = area under a receiver operating characteristic curve.\nTABLE 4 Diagnostic performance of ChatGPT-4.0, human reader, and US Images-based CNN model in predicting small HCC versus Non-HCC.\nDiagnostic\nPerformance SEN (%) p Value SPE (%) p Value ACC (%) p Value AUC ‡ p Value\nChatGPT-4.0 vs Human Reader\nChatGPT-4.0\nJunior Radiologist 83 (72/87) <0.001* 76 (22/29) 0.13* 81 (94/116) 0.007* 0.79 (0.71, 0.86) 0.46*\nSenior Radiologist 86 (93/108) <0.001* 89 (56/63) 0.13* 87 (149/171) 0.004* 0.88 (0.82, 0.92) 0.03*\nExpert Radiologist 89 (69/77) 0.004* 90 (35/39) 0.50* 90 (104/116) 0.07* 0.89 (0.83, 0.95) 0.20*\nHuman Reader with CEUS LI-RADS\nJunior Radiologist 63 (55/87) 90 (26/29) 70 (81/116) 0.76 (0.68, 0.84)\nSenior Radiologist 69 (75/108) 95 (60/63) 79 (135/171) 0.82 (0.76, 0.88)\nExpert Radiologist 78 (60/77) 95 (60/77) 84 (97/116) 0.86 (0.79, 0.92)\nChatGPT-4.0 vs CNN\nChatGPT-4.0 86 (94/110) 0.004 † 87 (45/52) <0.001 † 86 (139/162) 0.01 † 0.86 (0.8, 0.91) <0.001 †\nCNN 96 (106/110) 29 (15/52) 75 (121/162) 0.63 (0.55, 0.7)\nUnless otherwise indicated, data in parentheses are numerators/denominators. CNN, convolutional neural network; HCC, hepatocellular carcinoma; SEN, sensitivity; SPE, speciﬁcity; ACC,\naccuracy; AUC, area under a receiver operating characteristic curve.\n*p values present the comparison of performance between ChatGPT-4.0 and the human reader who generated the original structured CEUS LI-RADS reports.\n†pvalues are for comparing the diagnostic performance between ChatGPT-4.0 and CNN model.\n‡Data in parentheses are 95% conﬁdence intervals.\nHuang et al. 10.3389/fonc.2024.1513608\nFrontiers inOncology frontiersin.org07\nclassiﬁcation. This is of considerable signiﬁcance because the stable\nand reliable grasp of the CEUS LI-RADS system by LLMs could\npotentially establish a foundation for their clinical\ndiagnostic applications.\nNotably, human-LLM inter action with ChatGPT-4.0\noutperformed the radiologists who generated the original\nstructured CEUS LI-RADS reports in sensitivity and accuracy in\ndiagnosis sHCC. Interestingly, we observed that, 15.8% (43 of 272)\nof sHCC were classiﬁed as LR-M by human readers, and of these,\n88.4% (38 of 43) were assigned to LR-5 by ChatGPT-4.0. Previous\nstudies have shown that early washout within 60 seconds — an\nessential LR-M feature— is the main factor causing many HCC\ncases to be classiﬁed as LR-M (23–25). In the study by Zheng et al,\nthe investigators found that of 354 LR-M nodules, 224 (63%) were\nHCC (23). By recategorizing nodules displaying early washout and\nwithout punched-out before 5 minutes into LR-5, the sensitivity\nFIGURE 4\nResponses for a CEUS LI-RADS LR-M category small liver lesion classiﬁed by LLMs. This lesion was classiﬁed as CEUS LI-RADS LR-5 category by\nChatGPT-4o (A), ChatGPT-4.0(B), Google Gemini(D), however, it was assigned to LR-4 by ChatGPT-4o mini(C). The lesion was conﬁrmed as a\nmoderately-differentiated HCC by histopathology. CEUS LI-RADS, Contrast-enhanced Ultrasound Liver Imaging Reporting and Data System; LLMs,\nlarge language models; HCC, hepatocellular carcinoma.\nHuang et al. 10.3389/fonc.2024.1513608\nFrontiers inOncology frontiersin.org08\ncould elevate from 75% (1141 of 1513) to 85% (1283 of 1513) (P\n<.001), and accuracy from 81% to 87% (P <.001). Although we have\ndemonstrated that ChatGPT-4.0 understands the CEUS LI-RADS\nsystem and recognizes early washout as a typical feature of LR-M, it\ncontinues to classify nodules showing hyper-enhancement in\narterial phase followed by early washout as LR-5. ChatGPT-4.0\nseems to incorporate recent research and does not strictly classify a\ncase as LR-M if washout occurs within 60 seconds. This could be the\ncore reason why ChatGPT-4.0 demonstrated higher sensitivity\ncompared to human readers using CEUS LI-RADS criteria.\nConsidering the “black box” nature of LLMs, ongoing efforts are\nessential to address issues such as clearly explaining how decisions\nFIGURE 5\nResponses for a CEUS LI-RADS LR-4 category small liver lesion classiﬁed by LLMs. The lesion was classiﬁed as CEUS LI-RADS LR-5 category by\nChatGPT-4o (A) and Google Gemini(D). However, it was categorized as LR-4 and LR-3 by ChatGPT-4.0(B) and ChatGPT-4o mini, respectively. The\nlesion was conﬁrmed as a poorly-differentiated HCC by histopathology. CEUS LI-RADS, Contrast-enhanced Ultrasound Liver Imaging Reporting and\nData System; LLMs, large language models; HCC, hepatocellular carcinoma.\nHuang et al. 10.3389/fonc.2024.1513608\nFrontiers inOncology frontiersin.org09\nare derived. The aforementionedﬁnding highlights the valuable role\nof LLMs in enhancing the accuracy of diagnoses made by\nradiologists, not only for senior ultrasound practitioners but also\nfor senior practitioners to make more comprehensive judgements.\nDespite the innovative application of LLM in diagnosing sHCC\nwith CEUS LI-RADS, our study has some limitations. First, the\nLLM task relied only on structured CEUS LI-RADS reports,\nlimiting access to full imaging and clinical information about the\npatients. Second, the sample sizes for certain CEUS LI-RADS\ncategories, especially LR-2, were small, likely due to the\ninfrequent use of CEUS for liver nodules under 1 cm in routine\npractice. Third, our study focused on≤2 cm sFLLs in high-risk\npatients, which limited the number of participants, and the lack of\nsufﬁcient follow-up led to additional exclusions. The COVID-19\npandemic and related control measures further reduced patient\nenrollment, with only 5, 11, and 15 patients being included in 2020,\n2021, and 2022, respectively.\nIn conclusion, large language models (LLMs) showed signiﬁcant\npotential in diagnosing small hepatocellular carcinoma (sHCC) in\nhigh-risk patients when integ rated with the CEUS LI-RADS.\nChatGPT-4.0 and ChatGPT-4o demonstrated satisfactory\nreproducibility with ChatGPT-4.0 outperforming ChatGPT-4o,\nChatGPT-4o Mini, and Google Gemini in diagnostic efﬁcacy. It is\nworth noting that ChatGPT-4.0 identiﬁed the‘early washout’feature\nwould not rule out LR-5, which may be the core reason for its\nsuperior sensitivity and accuracy in detecting sHCC compared to\nhuman readers using CEUS LI-RADS. This highlights the need for\ncontinuous data review, model re ﬁnement, and improved\ntransparency and explainability of LLM decision-making.\nData availability statement\nThe original contributions presented in the study are included\nin the article/Supplementary Material. Further inquiries can be\ndirected to the corresponding authors.\nAuthor contributions\nJH: Methodology, Resources, Software, Writing– original draft.\nRY: Resources, Software, Writing– original draft. XH: Data curation,\nInvestigation, Writing – review & editing. KZ: Formal analysis,\nWriting – review & editing. YL: Formal analysis, Writing– review\n& editing. JL: Resources, Software, Writing– review & editing. AL:\nSupervision, Validation, Writing – review & editing. QL:\nConceptualization, Funding acquisition, Supervision, Writing –\nreview & editing.\nFunding\nThe author(s) declare ﬁnancial support was received for the\nresearch, authorship, and/or publication of this article. This study\nwas supported by the National Natural Science Foundation of\nChina (Grant No. 82171952).\nAcknowledgments\nWe extend our sincere gratitude to Mr. Xin Zhang, M.D. for his\nstatistical analysis and construction of CNN models in this study.\nFigures 4 and 5 are prompt responses generated by ChatGPT-4o\n(OpenAI; https://platform.openai. com/docs/models/gpt-4o/ ),\nChatGPT-4.0 (OpenAI; https://platform.openai.com/docs/models/\ngpt-4-and-gpt-4-turbo/ ), ChatGPT-4o mini (OpenAI; https://\nplatform.openai.com/do cs/models/gpt-4o-mini/ ), and Google\nGemini (Google; https://gemini.google.com/). We used ChatGPT-\n4.0 to reﬁne the language and proofread the manuscript. All authors\nassume full responsibility for the publication’s content.\nConﬂict of interest\nThe authors declare that the research was conducted in the\nabsence of any commercial orﬁnancial relationships that could be\nconstrued as a potential conﬂict of interest.\nGenerative AI statement\nThe authors declare that Generative AI was used in the creation\nof this manuscript. In this study, we used LLMs to render prompt\nresponses for CEUS LI-RADS categorization.Figures 4, 5 show the\nprompt responses generated by ChatGPT-4o (OpenAI; https://\nplatform.openai.com/docs/m odels/gpt-4o/), ChatGPT-4.0\n(OpenAI; https://platform.openai .com/docs/models/gpt-4-and-\ngpt-4-turbo/), ChatGPT-4o mini (OpenAI; https://platform.\nopenai.com/docs/models/gpt-4o-mini/ ), and Google Gemini\n(Google; https://gemini.google.com/). We used ChatGPT-4.0 to\nreﬁne the language and proofread the manuscript.\nPublisher’s note\nAll claims expressed in this article are solely those of the authors\nand do not necessarily represent those of their af ﬁliated\norganizations, or those of the publisher, the editors and the\nreviewers. Any product that may be evaluated in this article, or\nclaim that may be made by its manufacturer, is not guaranteed or\nendorsed by the publisher.\nSupplementary material\nThe Supplementary Material for this article can be found online\nat: https://www.frontiersin.org/articles/10.3389/fonc.2024.1513608/\nfull#supplementary-material\nHuang et al. 10.3389/fonc.2024.1513608\nFrontiers inOncology frontiersin.org10\nReferences\n1. Singal AG, Kanwal F, Llovet JM. Global trends in hepatocellular carcinoma\nepidemiology: implications for screening, prevention and therapy.Nat Rev Clin Oncol.\n(2023) 20:864–84. doi: 10.1038/s41571-023-00825-3\n2. Quaglia A. Hepatocellular carcinoma: a review of diagnostic challenges for the\npathologist. J Hepatocell Carcinoma. (2018) 5:99–108. doi: 10.2147/JHC.S159808\n3. Reig M, Forner A, Rimola J, Fàbrega JF, Burrel M, Criadoet AG, et al. BCLC\nstrategy for prognosis prediction and treatment recommendation: The 2022 update.J\nHepatol. (2022) 76:681–93. doi: 10.1016/j.jhep.2021.11.018\n4. Wilson SR, Lyshchik A, Piscaglia, Cosgrove D, Jang HJ, Sirlin C, et al. CEUS LI-\nRADS: algorithm, implementation, and key differences from CT/MRI.Abdom Radiol\n(NY). (2018) 43:127–42. doi: 10.1007/s00261-017-1250-0\n5. Piscaglia F, Wilson SR, Lyshchik, Cosgrove D, Dietrich CF, Jang HJ, et al. American\nCollege of Radiology Contrast Enhanced Ultrasound Liver Imaging Reporting and Data\nSystem (CEUS LI-RADS) for the diagnosis of Hepatocellular Carcinoma: a pictorial essay.\nUltraschall Med. (2017) 38:320–4. doi: 10.1055/s-0042-124661\n6. Gu K, Lee JH, Shin J, Hwang JA, Min JH, Jeong WK, et al. Using GPT-4 for LI-\nRADS feature extraction and categorization with multilingual free-text reports.Liver\nInt. (2024) 44:1578–87. doi: 10.1111/liv.15891\n7. Wu SH, Tong WJ, Li MD, Hu HT, Lu XZ, Huang ZR, et al. Collaborative\nenhancement of consistency and accuracy in US diagnosis of thyroid nodules using\nlarge language models.Radiology. (2024) 310:e232255. doi: 10.1148/radiol.232255\n8. Bhayana R. Chatbots and large language models in radiology: A practical primer\nfor clinical and research applications.Radiology. (2024) 310:e232756. doi: 10.1148/\nradiol.232756\n9. Adams LC, Truhn D, Busch F, Kader A, Niehues SM, Makowski MR, et al.\nLeveraging GPT-4 for post hoc transformation of free-text radiology reports into\nstructured reporting: A multilingual feasibility study.Radiology. (2023) 307:e230725.\ndoi: 10.1148/radiol.230725\n10. Bhayana R, Krishna S, Bleakney RR. Performance of chatGPT on a radiology\nboard-style examination: insights into current strengths and limitations.Radiology.\n(2023) 307:e230582. doi: 10.1148/radiol.230582\n11. Cozzi A, Pinker K, Hidber, Zhang TY, Bonomo L, Gullo RL, et al. BI-RADS\ncategory assignments by GPT-3.5, GPT-4, and google bard: A multilanguage study.\nRadiology. (2024) 311:e232133. doi: 10.1148/radiol.232133\n12. Huang JY, Li JW, Lu Q, Luo Y, Lin L, Shi YJ, et al. Diagnostic Accuracy of CEUS\nLI-RADS for the Characterization of Liver Nodules 20 mm or Smaller in Patients at\nRisk for Hepatocellular Carcinoma. Radiology. (2020) 294:329 –39. doi: 10.1148/\nradiol.2019191086\n13. Bruix J, Sherman M. Management of hepatocellular carcinoma. Hepatology.\n(2005) 42:1208–36. doi: 10.1002/hep.20933\n14. GPT-4o mini. OpenAI. Available online at: https://platform.openai.com/docs/\nmodels/gpt-4o-mini/ (Accessed July 5-16, 2024).\n15. GPT-4o. OpenAI. Available online at: https://platform.openai.com/docs/models/\ngpt-4o/ (Accessed July 5-16, 2024).\n16. GPT-4. OpenAI. Available online at: https://platform.openai.com/docs/models/\ngpt-4-and-gpt-4-turbo/ (Accessed July 5-16, 2024).\n17. Google Genimi. Available online at: https://gemini.google.com/ (Accessed July\n5-16, 2024).\n18. Peng S, Liu Y, Lv W, Liu LZ, Zhou Q, Yang H, et al. Deep learning-based artiﬁcial\nintelligence model to assist thyroid nodule diagnosis and management: a multicentre\ndiagnostic study. Lancet Digit Health. (2021) 3:e250\n–9. doi: 10.1016/S2589-7500(21)\n00041-8\n19. Khanna G, Chavhan GB, Schooler GR, Fraum TJ, Alazraki AL, Squires HJ, et al.\nDiagnostic performance of LI-RADS version 2018 for evaluation of pediatric hepatocellular\ncarcinoma.Radiology. (2021) 299:190–9. doi: 10.1148/radiol.2021203559\n20. Liu HT, Li CY, Wu QY, Lee YJ.Visual instruction tuning. (2023), arXiv:2304.08485.\ndoi: 10.48550/arXiv.2304.08485\n21. Awadalla A, Gao I, Gardner J, Hessel J, Hanafy Y, Zhu WR, et al.Openﬂamingo:\nAn open-source framework for training large autoregressive vision-language models.\n(2023), arXiv:2308.01390. doi: 10.48550/arXiv.2304.08485\n22. Nakashima O, Sugihara S, Kage M, Kojiro M. Pathomorphologic characteristics\nof small hepatocellular carcinoma a: a special reference to small hepatocellular\ncarcinoma with indistinct margins.Hepatology. (1995) 22:101–5.\n2 3 . Z h e n gW ,L iQ ,Z o uX B ,W a n gJ W ,H a nF ,L iF ,e ta l .E v a l u a t i o no fc o n t r a s t -\nenhanced US LI-RADS version 2017: application on 2020 liver nodules in patients\nwith hepatitis B infection. Radiology . (2019) 294:299 – 307. doi: 10.1148/\nradiol.2019190878\n24. Huang JY, Li JW, Ling WW, Li T, Luo Y, Liu JB, et al. Can contrast enhanced\nultrasound differentiate intrahepatic c holangiocarcinoma from hepatocellular\ncarcinoma. World J Gastroenterol. (2020) 26:3938–51. doi: 10.3748/wjg.v26.i27.3938\n25. Li F, Li Q, Liu Y, Han J, Zheng W, Huang YN, et al. Distinguishing intrahepatic\ncholangiocarcinoma from hepatocellular carcinoma in patients with and without risks:\nthe evaluation of the LR-M criteria of contrast-enhanced ultrasound liver imaging\nreporting and data system version 2017.Eur Radiol. (2020) 30:461–70. doi: 10.1007/\ns00330-019-06317-2\nHuang et al. 10.3389/fonc.2024.1513608\nFrontiers inOncology frontiersin.org11"
}