{
    "title": "TurnGPT: a Transformer-based Language Model for Predicting Turn-taking in Spoken Dialog",
    "url": "https://openalex.org/W3094393093",
    "year": 2020,
    "authors": [
        {
            "id": "https://openalex.org/A4281448283",
            "name": "Ekstedt, Erik",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A3161246944",
            "name": "Skantze, Gabriel",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2970971581"
    ],
    "abstract": "Syntactic and pragmatic completeness is known to be important for turn-taking prediction, but so far machine learning models of turn-taking have used such linguistic information in a limited way. In this paper, we introduce TurnGPT, a transformer-based language model for predicting turn-shifts in spoken dialog. The model has been trained and evaluated on a variety of written and spoken dialog datasets. We show that the model outperforms two baselines used in prior work. We also report on an ablation study, as well as attention and gradient analyses, which show that the model is able to utilize the dialog context and pragmatic completeness for turn-taking prediction. Finally, we explore the model’s potential in not only detecting, but also projecting, turn-completions.",
    "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 2981–2990\nNovember 16 - 20, 2020.c⃝2020 Association for Computational Linguistics\n2981\nTurnGPT: a Transformer-based Language Model for Predicting\nTurn-taking in Spoken Dialog\nErik Ekstedt\nKTH Speech, Music and Hearing\nStockholm, Sweden\nerikekst@kth.se\nGabriel Skantze\nKTH Speech, Music and Hearing\nStockholm, Sweden\nskantze@kth.se\nAbstract\nSyntactic and pragmatic completeness is\nknown to be important for turn-taking predic-\ntion, but so far machine learning models of\nturn-taking have used such linguistic informa-\ntion in a limited way. In this paper, we intro-\nduce TurnGPT, a transformer-based language\nmodel for predicting turn-shifts in spoken di-\nalog. The model has been trained and evalu-\nated on a variety of written and spoken dialog\ndatasets. We show that the model outperforms\ntwo baselines used in prior work. We also re-\nport on an ablation study, as well as attention\nand gradient analyses, which show that the\nmodel is able to utilize the dialog context and\npragmatic completeness for turn-taking predic-\ntion. Finally, we explore the model’s potential\nin not only detecting, but also projecting, turn-\ncompletions.\n1 Introduction\nThe taking of turns is one of the most fundamental\naspects of dialog. Since it is difﬁcult to speak and\nlisten at the same time, the participants need to co-\nordinate who is currently speaking and when the\nnext speaker can start. Traditionally, spoken dialog\nsystems have rested on a very simplistic model of\nturn-taking, where a certain amount of silence (e.g.\n700ms) is used as an indicator that the turn is com-\nplete. This often results in interruptions or sluggish\nresponses, depending on where the threshold is set.\nIn human-human interaction, it is clear that much\nmore sophisticated mechanisms are used, where\nthe speakers rely on turn-taking cues (involving\nprosody and linguistic cues, as well as gaze and\ngestures) to detect, and even project, turn comple-\ntions (Sacks et al., 1974; Gravano and Hirschberg,\n2011; Levinson and Torreira, 2015).\nMore sophisticated models of turn-taking, based\non machine learning, have been proposed (Meena\net al., 2014; Johansson and Skantze, 2015; Skantze,\n2017; Masumura et al., 2019). Typically, these\nmodels rely on the various multi-modal features\nthat have been found to facilitate the coordination\nof turn-taking. Since dialog is primarily driven by\nthe exchange of meaningful contributions, where\neach contribution often constitutes some dialog act,\nlinguistic information should intuitively play a ma-\njor role in turn-taking. However, so far, the rep-\nresentations of linguistic features have been fairly\nsimplistic, and some models rely solely on prosody\n(Ward et al., 2018; Lala et al., 2019). One explana-\ntion for this is that the complex semantic and prag-\nmatic functions that the ”linguistic cues” should\nreﬂect, and which can be expected to regulate turn-\ntaking, are non-trivial for machine learning models\nto capture, especially since they often depend on\nthe preceding dialog context.\nIn this paper, we introduce TurnGPT, a\ntransformer-based language model for turn-taking\nprediction. Based on Open AI’s GPT-2 (Radford\net al., 2019), and ﬁne-tuned on various dialog\ndatasets, it predicts possible turn-completion points\nin dialog, based on linguistic features (words) alone.\nTransformer-based language models have been\nshown to perform well on several NLP tasks (Rad-\nford et al., 2019). Recent developments in chatbots\nhave also shown that they can produce meaningful\nutterances in dialog, and thus seem to have a fairly\nstrong representation of the dialog context (Wolf\net al., 2019b). Through ablation studies and model\ninspection, we analyse how important the linguistic\ncontext is for turn-taking prediction. We evaluate\nthe model using both written and spoken dialog\ndatasets. However, as this paper is focused solely\non modelling the linguistic aspect of turn-taking,\nwe do not investigate the contribution of other im-\nportant features, such as prosody, and leave the\ncombination of such cues with our model for future\nwork. Thus, our baselines are the linguistic parts\nof turn-taking models proposed in previous work.\n2982\n2 Background\nOne of the most inﬂuential early accounts of the\norganization of turn-taking is the one proposed by\nSacks et al. (1974). Their model is based on the\nobservation that since the dialog is not known in ad-\nvance, it has to be coordinated in a ﬂexible manner\nas it evolves. Overwhelmingly, one speaker talks\nat a time; occurrences of more than one speaker at\na time are common, but brief. Transitions (from\none turn to the next) with very little gap and no\noverlap are common. Based on these observations,\nthey propose that turns can be constructed from\n”Turn-constructional units” (TCU). After each such\nunit, there is a ”Transition-relevant place” (TRP),\nwhere a turn-shift can (but does not have to) occur,\ndepending on whether the current speaker actively\nselects the next speaker, or if some other speaker\nself-selects.\nSeveral studies have investigated the cues that\ncould be used by the listener to distinguish\nTRPs (”turn-yielding cues”) from non-TRPs (”turn-\nholding cues”) (Duncan and Niederehe, 1974; Gra-\nvano and Hirschberg, 2011). For example, in a\nface-to-face setting, speakers tend to not look at\nthe listener during an utterance, but then shift the\ngaze towards the addressee when yielding the turn\n(Kendon, 1967). Several studies have also investi-\ngated prosodic cues for turn-taking, including into-\nnation, duration, loudness and voice quality (Ward,\n2019).\nFrom a linguistic perspective, the notion of\n”completeness” is important, as a complete lin-\nguistic unit (such as a sentence) is more likely\nto be turn-yielding than an incomplete sentence\nor phrase. Ford and Thompson (1996) analysed\nlinguistic units for turn-taking and proposed two\nlevels of units: syntactic and pragmatic. Syntactic\ncompletion, in this context, does not have to be a\ncomplete sentence. Neither is a syntactic phrase\n(like a nominal phrase) necessarily syntactically\ncomplete. They deﬁne an utterance to be syntacti-\ncally complete if ”in its discourse context, it could\nbe interpreted as a complete clause, that is, with an\novert or directly recoverable predicate” (p. 143).\nThis includes ”elliptical clauses, answers to ques-\ntions, and backchannel responses”. The syntactic\ncompletion is judged incrementally as the utter-\nance unfolds. Figure 1 shows a (made-up) example\nwhich illustrates this notion. As can be seen, in\nthis account, the turn-initial adverb of time ”yes-\nterday” is not syntactically complete (as there is\nA: yesterday we met / in the park /\nB: okay / when / will you meet / again /\nA: tomorrow /\nFigure 1: Example of syntactic completeness (marked\nby /).\nnot yet any ”overt or directly recoverable predi-\ncate”), whereas ”tomorrow” is, which illustrates\nthe dependence on the dialog context. As pointed\nout by Ford and Thompson (1996), while syntac-\ntic completion might be necessary for a TRP, it is\nnot sufﬁcient. Thus, they also introduce the notion\nof pragmatic completeness, which is deﬁned as ”a\ncomplete conversational action within its speciﬁc\nsequential context” (p. 150), and corresponds to\nTRPs. This deﬁnition is not very precise, and is\nlikely to depend on a fair amount of common sense.\nIn the example above, while ”when will you meet”\nis syntactically complete, the question is unlikely\nto end there, given the preceding context, and is\ntherefore not pragmatically complete.\nIn their analysis, Ford and Thompson (1996)\nalso argue that the ﬁnal intonation contour plays an\nimportant role in signalling pragmatic completion,\nwhere these may be ambiguous. This has also been\nveriﬁed in controlled experiments (B ¨ogels and Tor-\nreira, 2015). However, as pointed out by several\nresearchers (Levinson and Torreira, 2015; Ward,\n2019), turn-ﬁnal prosody cannot (by itself) explain\nthe majority of split-second turn-shifts (around\n200ms) that are typically found in data, as the lis-\ntener would not have time to react, prepare and ex-\necute a response. The response time would then be\naround 600-1500ms (Levinson and Torreira, 2015).\nThus, the listener is likely to prepare the response\nahead of time and project the turn-completion. For\nthis, they most likely depend on units which are\nmore feasible to project, such as syntactic and prag-\nmatic units.\nEven though syntactic and pragmatic complete-\nness are intuitively important for turn-taking, it is\nnot clear how they should be modelled. So far,\nmost prediction models of turn-shifts have used\na very simplistic account of syntactic completion,\nsuch as the ﬁnal part-of-speech tags (Gravano and\nHirschberg, 2011; Meena et al., 2014; Johansson\nand Skantze, 2015). More recent models of turn-\ntaking have used LSTMs to encode linguistic in-\nformation, such as part-of-speech (Skantze, 2017),\nwords (Roddy et al., 2018) or senones (Masumura\net al., 2019). Although several of these studies have\n2983\nfound that linguistic information contribute to the\nperformance (compared to only using prosody), the\nperformance gain is not as big as what could be\nexpected. This calls for the exploration of more\npowerful linguistic models for turn-taking.\n3 Approach\nA problem when modelling TRPs is that they are\nnot overtly present in the data, only actual turn-\nshifts are. One approach could be to manually\nannotate TRPs (cf. Meena et al. 2014; Lala et al.\n2019), but this is of course very labour intensive.\nOne could also question the binary notion of TRPs\n— a continuous (or probabilistic) notion seems to be\nmore plausible, where transition-relevance varies\nbetween highly inappropriate to highly appropri-\nate (Johansson and Skantze, 2015). In this view, a\nstrong TRP should be statistically associated with\nmore turn-shifts. Thus, a probabilistic notion of\nTRPs should be possible to infer from actual turn-\nshifts in data, just like a language model (the prob-\nability of a word in context) can be inferred from\nactual language use.\nGiven this notion, we include turn-shifts as spe-\nciﬁc tokens in the vocabulary of a language model\nand learn their distribution, along with the other to-\nkens, over conversational data in a language model\nsetup. We focus on dialog data and include two\nseparate turn-shift tokens for each of the speakers,\nwhich are inserted at the beginning of each speaker\nturn. A dialog is then a sequence of turns separated\nby these turn-shift tokens. After training, the prob-\nabilities associated to the turn-shift tokens can be\nviewed as the probability of a TRP. Note, however,\nthat the model not only predicts turn-shifts, but\nmakes predictions over all tokens in the vocabulary,\nthus retaining its function as a language model.\nThe problem of organizing turn-taking primarily\nconcerns spoken language, where response time\nand ﬂuency has a big impact on the quality of the\ninteraction. However, the process of recording and\ntranscribing spoken dialog is expensive and time\nconsuming. There are also privacy issues regard-\ning recorded speech, which makes audio data less\naccessible than their written counterpart. Since\nour focus in this paper is on linguistic aspects of\nturn-taking, we investigate the use of both written\nand spoken dialog data. Although the language use\nis different for spoken vs. written language, we\nbelieve that pragmatic TRPs exist and overlap (to\nsome extent) for both types. A clear difference,\nhowever, is that spoken language lack punctuation\nand capitalization, which are not typically avail-\nable for spoken dialog systems (unless inferred by\na transcriber or ASR). Our goal is to learn the dis-\ntributions over TRPs using linguistic data, without\nthe need to rely on punctuation or capitalization.\n4 Model\nWe use a transformer-based (Vaswani et al., 2017),\nuni-directional language model: the GPT-2 (Rad-\nford et al., 2019) from OpenAI. Transformer mod-\nels have made a huge impact on NLP research over\nthe past years and was chosen because of their\nstrong performance on language generation.\nOur model can be seen as a modiﬁed version\nof the TransferTransfo (Wolf et al., 2019b) model,\nwhich performed well in the ConvAI21 challenge.\nIn their work, they ﬁne-tuned a GPT (Radford et al.,\n2018) model on a particular dialog task with the ad-\ndition of three tokens, one task-speciﬁc and one for\neach speaker. Transformer-based language mod-\nels commonly use at least two types of embed-\ndings, a word and a positional embedding. The\nword embedding encodes the relevant words and\nthe positional encodes their order. TransferTransfo\nused an additional dialog state embedding consist-\ning of the task speciﬁc token and a speaker token\nfor each location, corresponding to the relevant\nspeaker. Training was done using cross-entropy\nloss and a next-sentence prediction loss. In our\nwork, we omit the task-speciﬁc token and the next\nsentence prediction loss.\nTurnGPT is a GPT2-based transformer using\nthree kinds of embeddings: word, position and\nspeaker id. The speaker tokens are included in the\nlanguage modelling task and the TRP probability\npredictions are deﬁned as the maximum assigned\noutput probability over the speaker tokens. Please\nrefer to the code2 for further details.\nWe ﬁnetune two different pre-trained models,\nnamely GPT-2 (Radford et al., 2019) trained on\nWebText, and DialoGPT (Zhang et al., 2019) by\nMicrosoft, which is based on GPT-2 but ”trained\non 147M conversation-like exchanges extracted\nfrom Reddit comments”. We used the pretrained\nmodels available from the transformers (Wolf et al.,\n2019a) library using PyTorch (Paszke et al.). For\nour experiments, we only used the smallest models\n(the GPT-2-base and the DialoGPT-small), both\n1http://convai.io/\n2https://github.com/ErikEkstedt/TurnGPT\n2984\n#Dialogs #Turns #Words/Turn #Unique Words\nAssistant\nTaskmaster 30.4K 542K 9.2 43.7K\nMultiWoZ 10.4K 1.3M 13.5 18.8K\nMetaLWoZ 37.9K 432K 7.3 37.2K\nCCPE 500 10.1K 14.4 5K\nWritten Social Persona 10.9K 162K 10.1 20.3K\nDailyDialog 13.1K 116.4K 10.1 22.2K\nSpontaneous Spoken Maptask 128 11.4K 12.8 2.2K\nSwitchboard 2.4K 106.6K 28.1 27K\nTable 1: Dataset statistics.\nwith 12 layers, 12 heads and 768 hidden units.\nWe compare TurnGPT against two baselines\nwhich correspond to linguistic models which have\nbeen used in previous research (as reviewed above).\nFirst, we train a simple statistical model on part-of-\nspeech (POS) bigrams. For each pair of consecu-\ntive POS tags, we get an associated probability of\na speaker shift. Second, we train an LSTM model\n(Hochreiter and Schmidhuber, 1997) with up to\nthree layers with a hidden size of 768. The LSTM\nbaseline is trained directly as a binary turn-shift\nclassiﬁer, given the preceding sequence of words.\n5 Data\nWe collect eight dialog datasets with varying char-\nacteristics, which we have grouped into three major\ncategories. The ﬁrst, and largest, group (called As-\nsistant) are task-oriented dialog system corpora,\nwhich represent dialog between a user and an au-\ntomated assistant (where the user typically queries\nthe assistant for information). These datasets were\nprimarily collected through Wizard-of-Oz (WoZ)\nand self-written dialog (i.e., where one person is\nwriting an imagined dialog), through a crowdsourc-\ning platform:\n•The Taskmaster (Byrne et al., 2019) dataset\n(self-written and WoZ using a TTS).\n•MetaLWOZ, the dataset for DSTC-8 Track 2\n“Fast Domain Adaptation” (Lee et al., 2019)\n(WoZ).\n•The Multiwoz 2.1 (Eric et al., 2019) is an\nupdate to the Multiwoz (Budzianowski et al.,\n2018) dataset (written WoZ).\n•The Coached Conversational Preference Elici-\ntation (Radlinski et al., 2019), CCPE, dataset\n(WoZ using a TTS). This dataset differs from\nthe previous in that the system tries to extract\ninformation from the user, as opposed to the\nother way around.\nThe second group of datasets (called Written So-\ncial) contains human-human written dialogs that\nare more open and social in nature:\n•The Persona dataset (Zhang et al., 2018) con-\nsists of dialogs where two crowdworkers are\ngiven the task of trying to get to know each\nother, based on a given set of persona at-\ntributes (e.g. ”I like to ski. I am vegetarian”).\n•The DailyDialog dataset (Li et al., 2017) con-\ntains dialogs extracted from web pages for\nEnglish learners. The dataset includes a va-\nriety of topics (relationships, tourism, work,\npolitics, etc). The dataset was intended to\nresemble dialogs human would have in their\n”daily life”.\nThe third type of collected data is that of Sponta-\nneous Spokendialog between two humans:\n•Maptask (Anderson et al., 1991) is a task-\noriented dataset where a ”guide” explains a\ndeﬁned route on a map to a ”follower” which\ntries to draw that path on their map.\n•Switchboard (Godfrey et al., 1992) contains\nmore open-ended telephone dialogs, con-\nstrained only by a given topic (e.g. recycling).\nTable 1 shows the basic statistics over each of the\neight datasets. All datasets were also combined to\ncreate a Full dataset. Each dataset was split into\ntraining, validation and test sets, using predeﬁned\nsplits if available, or else a random split of (90/5/5).\n5.1 Data Extraction\nThe dialogs were extracted from the different cor-\npora. For each turn, a speaker token was inserted\n2985\nat the start (speaker1 or speaker2). Punctua-\ntions (,.:;!?) were removed, and all characters\nwere made lower case. The words were encoded by\na bytepair encoding (BPE) vocabulary (Sennrich\net al., 2016) used in the respective pretrained mod-\nels. This method splits words into subwords, and\nthe ﬁnal vocabulary consists of 50,261 tokens.\nFor all datasets, except Maptask and Switch-\nboard, the turns were explicitly given by the struc-\nture of the data. Since the Spontaneous Spoken\ndatasets contain a fair amount of overlap and have\nno clearly deﬁned turns, a custom turn extraction\npolicy was implemented: First, backchannels were\ndeﬁned by a set of candidates (e.g ”mm”, ”mhm”,\netc) and removed from the dialog if they were spo-\nken in isolation, separated by more than a second\nfrom other utterances made by the same speaker.\nSecond, IPUs (Inter-pausal units) were deﬁned as\nutterances separated by less than 500ms. IPUs\nof one speaker, spoken completely inside an IPU\nmade by the other speaker, were omitted. Third,\na sequence of turns was created by merging all\nconsecutive IPUs from one speaker, separated by\nmutual silence, into a single turn. The turns were or-\ndered by time, ignoring any overlap between them.\nThese turns were then treated the same way as for\nthe rest of the datasets.\nFor the POS baseline we used the NLTK (Bird\net al., 2009) library to extract POS tags from the\nextracted dialogs.\n6 Experiment\n6.1 Training\nWe trained the models on both the Assistant and\nFull training sets using the cross-entropy loss. The\nmodels with the lowest validation loss were then\nused for testing. The TurnGPT models used the\nAdamW optimizer and the default hyperparameters\nof the transformer library.\nThe LSTM baseline used the same tokens pro-\nvided by the GPT-2 model but trained on the bi-\nnary prediction of the next token being a turn-shift\nor not, using a sigmoidal output activation on the\nmean squared error loss. The LSTM model utilized\nthe AdamW optimizer included in PyTorch, with a\nweight decay of 0.01, dropout of 0.1, and a learning\nrate of 6.25e-5. We used up to three hidden layers\nfor the LSTM and chose the one that performed\nbest on the validation sets, which was the 2-layer\nLSTM.\n6.2 Evaluation\nThe best performing models on the validation sets\nwere used to evaluate the performance on the test\nsets. Each model have associated probabilities re-\nlated to turn-shifts. For the transformer-based mod-\nels, we chose the maximum speaker token output\nprobability at each time step as the probability of a\nTRP. Since the LSTM baseline was directly trained\nas a turn-shift classiﬁer, the output could be used\ndirectly as a TRP probability. The POS baseline\nfollows the same reasoning. The chosen evaluation\ncritera was the balanced accuracy (bAcc) over true\nand false turn-shifts. This metric was chosen be-\ncause of the imbalanced classes (there are many\nmore word tokens than turn-shifts). The bAcc is\ndeﬁned by\nbAcc = TPR + TNR\n2 ∈[0.5, 1], (1)\nwhere TPR and TNR is the true positive rate (pos-\nitive recall) and the true negative rate respectively.\nThe lowest value is 0.5, which is achieved by al-\nways guessing on one class, and the highest is 1\n(100% accuracy over both classes).\nTo use the models as classiﬁers, a threshold was\nused to discretize the probabilities into two classes,\nwhere a probability over the threshold was regarded\nas a turn-shift. We used independent thresholds for\neach model that yielded the highest test score. The\nresults are shown in Table 2. As can be seen, the\nTurnGPT models achieved the best results on all\ndatasets. Both GPT-2 and DialogGPT yielded sim-\nilar performance. When evaluated on the Spoken\nand Written datasets, the models also beneﬁt from\ntraining on the Full dataset (where these are in-\ncluded). This shows that the language use across\nthese datasets indeed differ, and that it is important\nto train the models on different types of corpora.\nOverall, turn-shift predictions on the Spoken and\nWritten datasets are more challenging, which can\nbe explained by their more spontaneous nature.\nA sample visualization over the TRP probabili-\nties for the example in Figure 1, as yielded by the\nLSTM and TurnGPT models, is shown in Figure\n2. First, this ﬁgure shows how a more probabilistic\nnotion of TRPs is intuitively more compelling than\na binary notion. Second, the example clearly illus-\ntrates some of the beneﬁts of the TurnGPT model\nover the LSTM model. The LSTM model gives a\nfairly high probability of a TRP after ”yesterday”,\nand somewhat high after ”tomorrow”. Without\n2986\nAssistant Spoken Written\nAssistant\nPOS 0.696 0.659 0.733\nLSTM 0.866 0.690 0.795\nTurnGPT 0.913 0.789 0.875\n0.912* 0.784* 0.877*\nFull\nPOS 0.750 0.675 0.732\nLSTM 0.869 0.748 0.83\nTurnGPT 0.913 0.823 0.905\n0.913* 0.823* 0.906*\nTable 2: The bAcc on different test sets, with mod-\nels trained on the Assistant and Full training sets.\nTurnGPT entries with (*) indicates the DialoGPT ver-\nsion.\nconsidering the previous context, these should in-\ndeed be fairly equivalent. The TurnGPT model,\non the other hand, correctly separates these two in-\nstances, presumably because it has a better model\nof the context. Similarly, the LSTM model (but\nnot TurnGPT) assigns a fairly high probably for a\nTRP after ”when will you meet”, indicating that it\nis sensitive to syntactic, but perhaps not pragmatic,\ncompleteness, in the sense of Ford and Thompson\n(1996).\nFigure 2: TRP probabilities associated with the con-\nstructed sample in Figure 1.\n6.3 Context Ablation\nIn order to bring further insight into the importance\nof context, we perform an ablation study, varying\nthe amount of context available to the model. For\nthis, we only use turns that have a minimum of 4\npreceding turns. For context 0, only the current\nturn is given as input, but for context 4, the current\nturn and the 4 preceding turns are used as input.\nThe evaluation is done over all suitable turns. The\nresults are shown in Figure 3.\nFor TurnGPT, the performance increases with\nthe amount of context. The biggest drop in perfor-\nmance happens when going from some context to\nno context. We note that the LSTM classiﬁer shows\na similar behaviour, but to a less extent, and actu-\nally improves the performance slightly when going\nfrom a single context turn to zero on the Written\ndataset.\nFigure 3: The bAcc score for the TurnGPT model and\nthe LSTM baseline trained on the full dataset.\nTo visualize how the TurnGPT model might\nchange its prediction depending on the available\ncontext, we include a visualization over the con-\nstructed sample in Figure 4. After the last word\n”tomorrow”, we note how having no context vs.\nsome context changes the prediction for a turn-\nshift considerably. In other words, the model has\nlearned that a turn-initial ”tomorrow”, by itself, is\nvery unlikely to be the end of a turn. However,\ninterpreted in the context of the preceding question,\nthe probability is much higher.\nFigure 4: TurnGPT predictions for varying context over\nthe constructed sample in Figure 1. The blue bars are\nonly given the current turn as input. The orange bars\nfurther includes the previous context turn and the red\nincludes the two previous turns (which is only relevant\nfor the last turn).\n6.4 Model Inspection\nWe further investigate the contextual impact by\nlooking at the attention mechanism inherent in any\ntransformer-based model. Inspired by the work of\nClark et al. (2019), we extract the attention over all\n2987\ntrue turn-shift tokens where the model assigned a\nturn-shift probability over 0.2. We added together\nthe attention contribution over each of the 5 most\nrecent turns (the current turn and 4 context turns).\nThe output token part of the model may attend\nto all previous tokens (including itself). Each turn\nhas varying amounts of preceding tokens, and to\nbetter understand the attention over the most recent\ncontext, we normalize over the 5 most recent turns.\nIn other words, the attention contributions for the\nlast 5 turns will sum up to 1 (for any individual\nsample). The distributions over turn attention is\nshown in Figure 5. The current turn contains, on\naverage, around 70% of the contextual attention,\nwhich is reasonable given that most information\nregarding turn-shifts are expected to be in the cur-\nrent turn. The remaining 30% still constitute a\nsubstantial contribution, which further strengthen\nthe conclusion that dialog context is important.\nFigure 5: The normalized distributions over turn atten-\ntion for the last ﬁve turns, including the current.\nIn addition to the attention we investigate the\nimportance the model puts on the last 5 turns by\ncalculating the Integrated Gradient (IG) (Sundarara-\njan et al., 2017). The integrated gradient technique\nis useful for investigating the effect the input has\non any particular output. In this case that can be\ninterpreted as how much any word contributes to-\nwards a turn-shift prediction. As further described\nin Sundararajan et al. (2017), this method requires a\ndeﬁnition of a baseline. We tried the recommended\nzero word vector as a baseline, but found that the\nunk (unknown) token worked better. The speaker\ntokens were considered ﬁxed and were kept intact\nin the IG calculations.\nWe are interested in the model’s behaviour when\nFigure 6: The distributions over the integrated gradient\nturn sum of the last ﬁve turns including the current. The\ngradient was calculated with respect to the last token in\nthe current turn.\nit predicts a turn-shift to be likely. We chose only\ntargets at true turn-shift locations with a predicted\nturn-shift probability over 0.2, the same value used\nin the attention analysis. The IG contribution val-\nues were averaged over each of the 5 most recent\nturns. Because this approach requires much com-\nputation, we randomly chose 500 dialogs from the\nfull test set and calculated 2 targets in each dialog\nfor a total of 1000 integrated gradients. The results\nare shown in Figure 6.\nThe integrated gradient shows both positive and\nnegative contributions. The ﬁrst turn is mostly pos-\nitive and indicates that the immediate context con-\ntributes, on average, positively towards predicting\na turn-shift. For example given that the last words\nform a question, each of the ”question” words ar-\nguably contribute positively towards a turn-shift.\nHowever, the preceding turns contribute more\nnegatively, thus decreasing the likelihood of a turn\nshift at the target. One potentital explanation for\nthis is that the context provides evidence that a\nsyntactic completion is not a pragmatic completion.\nHowever, this hypothesis needs to be investigated\nfurther in future work.\n6.5 Future Prediction\nAn interesting aspect of learning the distributions\nof turn-shifts through a language model setup is the\nability to generate text and inspect possible futures.\nThis is done by sampling from the output distri-\nbution of the model in an autoregressive manner,\nand then count the number of tokens until a gener-\n2988\nated speaker-token. In a dialog system, this would\nallow the model to estimate the time until a turn\ncompletion, and thereby open up for models that\ncan project (and not just detect) turn completions.\nThis would give the system more time to prepare\na response and be able to respond with almost no\ngap, similar to human-human dialog.\nAlthough we leave this to be further explored\nin future work, we perform a simple experiment\nhere to evaluate the feasibility of the idea. As an\nexample, we again use the dialog from Figure 1,\nand sample over the cumulative output distribution\nunder 0.9, for a maximum length of 50 tokens.\nThe histograms in Figure 7 show the predicted\nnumber of tokens left in the turn, generated over\n1000 samples. We note that during the ﬁrst turn,\nthe model is biased to produce longer sequences,\nas there is no context that provides any constraints.\nHowever, already in the second turn this behaviour\nchanges, and the predictions become much shorter,\nwhich further adds to the notion that turn-shift pre-\ndiction is informed by context. In this speciﬁc ex-\nample, we also note that the predicted turn comple-\ntions decrease in length and becomes more stable\nthe closer we get to the end of the turn.\n7 Conclusions and Discussion\nIn this paper, we presented a model for turn-shift\nprediction by formulating the problem as a lan-\nguage modelling task. We introduced TurnGPT, a\nmodel which is a ﬁnetuned GPT-2 transformer im-\nbued with special turn-shift tokens. The model per-\nformed better than baselines used in previous work.\nThrough an ablation study and model inspection,\nwe showed that this is partly thanks to the strong\nrepresentation of context that prior models lack,\ni.e., the model’s ability to identify pragmatic (and\nnot just syntactic) completion. We also showcased\nthe model’s ability to generate possible futures as a\nway of predicting upcoming turn-shifts.\nAs we are addressing spoken dialog, this work\nshould be seen as an important step towards a more\npowerful turn-taking model that takes both linguis-\ntic information, as well as prosody and other cues\n(such as gaze and gestures) into account. As argued\nin the linguistic literature (Ford and Thompson,\n1996; B¨ogels and Torreira, 2015), prosodic informa-\ntion can be important to further disambiguate prag-\nmatic completion. However, we argue that previous\nmodels that have combined linguistic and prosodic\ncues (cf. Meena et al. 2014; Skantze 2017; Roddy\nFigure 7: Histograms over predicted turn lengths with\na generated sample shown as text. The text may be read\nfrom the token on the ﬁrst y-axis down to any token of\ninterest and then continue reading left to right. Turns\nare separated by the dashed lines.\net al. 2018; Masumura et al. 2019) have used too\nsimplistic models of linguistic turn-constructional\nunits. The integration of prosodic information with\na model like TurnGPT is an important topic for\nfuture work.\nTurnGPT could also be interesting not just from\na dialog system perspective; further model inspec-\ntion and ablation studies could also be used to iden-\ntify more exactly how certain words contribute to\nturn-completion predictions. This can potentially\ngive insights into how humans manage to coordi-\nnate their turn-taking in spoken interaction with\neach other.\nAcknowledgements\nThis work is supported by the Swedish research\ncouncil (VR) project CORDIAL (2013-1403) and\nthe SSF project COIN.\n2989\nReferences\nAnne H. Anderson, Miles Bader, Ellen Gurman Bard,\nElizabeth Boyle, Gwyneth Doherty, Simon Garrod,\nStephen Isard, Jacqueline Kowtko, Jan McAllister,\nJim Miller, Catherine Sotillo, Henry S. Thompson,\nand Regina Weinert. 1991. The hcrc map task cor-\npus. Language and Speech, 34(4):351–366.\nSteven Bird, Ewan Klein, and Edward Loper.\n2009. Natural Language Processing with Python.\nO’Reilly Media.\nSara B ¨ogels and Francisco Torreira. 2015. Listeners\nuse intonational phrase boundaries to project turn\nends in spoken interaction. Journal of Phonetics,\n52:46–57.\nPaweł Budzianowski, Tsung-Hsien Wen, Bo-Hsiang\nTseng, I ˜nigo Casanueva, Stefan Ultes, Osman Ra-\nmadan, and Milica Ga ˇsi´c. 2018. MultiWOZ - a\nlarge-scale multi-domain wizard-of-Oz dataset for\ntask-oriented dialogue modelling. In Proceedings of\nthe 2018 Conference on Empirical Methods in Nat-\nural Language Processing, pages 5016–5026, Brus-\nsels, Belgium. Association for Computational Lin-\nguistics.\nBill Byrne, Karthik Krishnamoorthi, Chinnadhurai\nSankar, Arvind Neelakantan, Daniel Duckworth,\nSemih Yavuz, Ben Goodrich, Amit Dubey, Kyu-\nYoung Kim, and Andy Cedilnik. 2019. Taskmaster-\n1: Toward a realistic and diverse dialog dataset.\nKevin Clark, Urvashi Khandelwal, Omer Levy, and\nChristopher D. Manning. 2019. What does BERT\nlook at? an analysis of BERT’s attention. In Pro-\nceedings of the 2019 ACL Workshop BlackboxNLP:\nAnalyzing and Interpreting Neural Networks for\nNLP, pages 276–286, Florence, Italy. Association\nfor Computational Linguistics.\nS Duncan and G Niederehe. 1974. On signalling that\nit’s your turn to speak. Journal of Experimental So-\ncial Psychology, 10(3):234–247.\nMihail Eric, Rahul Goel, Shachi Paul, Abhishek Sethi,\nSanchit Agarwal, Shuyang Gao, and Dilek Hakkani-\nT¨ur. 2019. Multiwoz 2.1: Multi-domain dialogue\nstate corrections and state tracking baselines. CoRR,\nabs/1907.01669.\nC Ford and S Thompson. 1996. Interactional units\nin conversation: syntactic, intonational, and prag-\nmatic resources for the management of turns, Stud-\nies in interactional sociolinguistics 13, chapter 3.\nCambridge University Press, Cambridge.\nJohn J. Godfrey, Edward C. Holliman, and Jane Mc-\nDaniel. 1992. Switchboard: Telephone speech cor-\npus for research and development. In Proceed-\nings of the 1992 IEEE International Conference on\nAcoustics, Speech and Signal Processing - Volume 1,\nICASSP’92, page 517–520, USA. IEEE Computer\nSociety.\nAgustın Gravano and Julia. Hirschberg. 2011. Turn-\ntaking cues in task-oriented dialogue. Computer\nSpeech & Language, 25(3):601–634.\nSepp Hochreiter and J ¨urgen Schmidhuber. 1997.\nLong short-term memory. Neural Comput. ,\n9(8):1735–1780.\nMartin Johansson and Gabriel Skantze. 2015. Opportu-\nnities and Obligations to take turns in collaborative\nmulti-party human-robot interaction. In Proceed-\nings of SIGDIAL, pages 305–314.\nA Kendon. 1967. Some functions of gaze direction in\nsocial interaction. Acta Psychologica, 26:22–63.\nDivesh Lala, Koji Inoue, and Tatsuya Kawahara. 2019.\nSmooth turn-taking by a robot using an online con-\ntinuous model to generate turn-taking cues. In ICMI\n2019 - Proceedings of the 2019 International Con-\nference on Multimodal Interaction, pages 226–234.\nAssociation for Computing Machinery, Inc.\nSungjin Lee, Hannes Schulz, Adam Atkinson, Jianfeng\nGao, Kaheer Suleman, Layla El Asri, Mahmoud\nAdada, Minlie Huang, Shikhar Sharma, Wendy Tay,\nand Xiujun Li. 2019. Multi-domain task-completion\ndialog challenge. In Dialog System Technology\nChallenges 8.\nStephen C. Levinson and Francisco Torreira. 2015.\nTiming in turn-taking and its implications for pro-\ncessing models of language. Frontiers in Psychol-\nogy, 6(JUN).\nYanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang\nCao, and Shuzi Niu. 2017. DailyDialog: A manu-\nally labelled multi-turn dialogue dataset. InProceed-\nings of the Eighth International Joint Conference on\nNatural Language Processing (Volume 1: Long Pa-\npers), pages 986–995, Taipei, Taiwan. Asian Federa-\ntion of Natural Language Processing.\nRyo Masumura, Tomohiro Tanaka, Atsushi Ando, Ryo\nIshii, Ryuichiro Higashinaka, and Yushi Aono. 2019.\nNeural Dialogue Context Online End-of-Turn Detec-\ntion.\nRaveesh Meena, Gabriel Skantze, and Joakim\nGustafson. 2014. Data-driven models for timing\nfeedback responses in a Map Task dialogue system.\nComputer Speech and Language, 28(4):903–922.\nAdam Paszke, Sam Gross, Francisco Massa, Adam\nLerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca\nAntiga, Alban Desmaison, Andreas Kopf, Edward\nYang, Zachary DeVito, Martin Raison, Alykhan Te-\njani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang,\nJunjie Bai, and Soumith Chintala. Pytorch: An\nimperative style, high-performance deep learning li-\nbrary. In Advances in Neural Information Process-\ning Systems 32.\n2990\nAlec Radford, Karthik Narasimhan, Tim Salimans, and\nIlya Sutskever. 2018. Improving language under-\nstanding by generative pre-training. Technical re-\nport, OpenAI.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nBlog, 1(8):9.\nFilip Radlinski, Krisztian Balog, Bill Byrne, and\nKarthik Krishnamoorthi. 2019. Coached conversa-\ntional preference elicitation: A case study in un-\nderstanding movie preferences. In Proceedings of\nthe Annual SIGdial Meeting on Discourse and Dia-\nlogue.\nMatthew Roddy, Gabriel Skantze, and Naomi Harte.\n2018. Investigating Speech Features for Continuous\nTurn-Taking Prediction Using LSTMs. In Proceed-\nings of Interspeech, Hyderabad, India.\nH Sacks, Emanuel Schegloff, and G Jefferson. 1974.\nA simplest systematics for the organization of turn-\ntaking for conversation. Language, 50:696–735.\nRico Sennrich, Barry Haddow, and Alexandra Birch.\n2016. Neural machine translation of rare words\nwith subword units. In Proceedings of the 54th An-\nnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 1715–\n1725, Berlin, Germany. Association for Computa-\ntional Linguistics.\nGabriel Skantze. 2017. Towards a general, continu-\nous model of turn-taking in spoken dialogue using\nlstm recurrent neural networks. In Proceedings of\nthe 18th Annual SIGdial Meeting on Discourse and\nDialogue, pages 220–230, Saarbr ˜Acken, Germany.\nAssociation for Computational Linguistics.\nMukund Sundararajan, Ankur Taly, and Qiqi Yan. 2017.\nAxiomatic attribution for deep networks. In Pro-\nceedings of the 34th International Conference on\nMachine Learning, volume 70 of Proceedings of\nMachine Learning Research, pages 3319–3328, In-\nternational Convention Centre, Sydney, Australia.\nPMLR.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In I. Guyon, U. V . Luxburg, S. Bengio,\nH. Wallach, R. Fergus, S. Vishwanathan, and R. Gar-\nnett, editors, Advances in Neural Information Pro-\ncessing Systems 30, pages 5998–6008. Curran Asso-\nciates, Inc.\nNigel Ward. 2019. Prosodic Patterns in English Con-\nversation. Cambridge University Press.\nNigel Ward, Diego Aguirre, Gerardo Cervantes, and\nOlac Fuentes. 2018. Turn-Taking Predictions across\nLanguages and Genres Using an LSTM Recurrent\nNeural Network. In 2018 IEEE Spoken Language\nTechnology Workshop, SLT 2018 - Proceedings ,\npages 831–837. Institute of Electrical and Electron-\nics Engineers Inc.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, R’emi Louf, Morgan Funtow-\nicz, and Jamie Brew. 2019a. Huggingface’s trans-\nformers: State-of-the-art natural language process-\ning. ArXiv, abs/1910.03771.\nThomas Wolf, Victor Sanh, Julien Chaumond, and\nClement Delangue. 2019b. Transfertransfo: A trans-\nfer learning approach for neural network based con-\nversational agents. CoRR, abs/1901.08149.\nSaizheng Zhang, Emily Dinan, Jack Urbanek, Arthur\nSzlam, Douwe Kiela, and Jason Weston. 2018. Per-\nsonalizing dialogue agents: I have a dog, do you\nhave pets too? In Proceedings of the 56th An-\nnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 2204–\n2213, Melbourne, Australia. Association for Com-\nputational Linguistics.\nYizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun\nChen, Chris Brockett, Xiang Gao, Jianfeng Gao,\nJJ (Jingjing) Liu, and Bill Dolan. 2019. Dialogpt:\nLarge-scale generative pre-training for conversa-\ntional response generation. In arXiv:1911.00536."
}