{
  "title": "Automatic International Classification of Diseases Coding System: Deep Contextualized Language Model With Rule-Based Approaches",
  "url": "https://openalex.org/W4283687125",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5040535325",
      "name": "Pei‐Fu Chen",
      "affiliations": [
        "Far Eastern Memorial Hospital",
        "National Taiwan University"
      ]
    },
    {
      "id": "https://openalex.org/A5022837496",
      "name": "Kuan‐Chih Chen",
      "affiliations": [
        "Far Eastern Memorial Hospital",
        "National Taiwan University"
      ]
    },
    {
      "id": "https://openalex.org/A5103110467",
      "name": "Wei-Chih Liao",
      "affiliations": [
        "National Taiwan University"
      ]
    },
    {
      "id": "https://openalex.org/A5017526842",
      "name": "Feipei Lai",
      "affiliations": [
        "National Taiwan University"
      ]
    },
    {
      "id": "https://openalex.org/A5052511894",
      "name": "Tai-Liang He",
      "affiliations": [
        "National Taiwan University"
      ]
    },
    {
      "id": "https://openalex.org/A5080379148",
      "name": "Sheng-Che Lin",
      "affiliations": [
        "National Taiwan University"
      ]
    },
    {
      "id": "https://openalex.org/A5063747816",
      "name": "Wei-Jen Chen",
      "affiliations": [
        "National Taiwan University"
      ]
    },
    {
      "id": "https://openalex.org/A5076429069",
      "name": "Chi-Yu Yang",
      "affiliations": [
        "Far Eastern Memorial Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A5053662503",
      "name": "Yu‐Cheng Lin",
      "affiliations": [
        "Far Eastern Memorial Hospital",
        "Ministry of Health and Welfare",
        "Oriental Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5036180882",
      "name": "I-Chang Tsai",
      "affiliations": [
        "Far Eastern Memorial Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A5059475002",
      "name": "Chi-Hao Chiu",
      "affiliations": [
        "Far Eastern Memorial Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A5009887194",
      "name": "Shu-Chih Chang",
      "affiliations": [
        "Far Eastern Memorial Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A5060599903",
      "name": "Fang‐Ming Hung",
      "affiliations": [
        "Far Eastern Memorial Hospital"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W1507651605",
    "https://openalex.org/W2103519904",
    "https://openalex.org/W2998230683",
    "https://openalex.org/W2333700490",
    "https://openalex.org/W2143514833",
    "https://openalex.org/W2031213082",
    "https://openalex.org/W3030177116",
    "https://openalex.org/W2260168650",
    "https://openalex.org/W3198282417",
    "https://openalex.org/W2911489562",
    "https://openalex.org/W3099750501",
    "https://openalex.org/W3003918928",
    "https://openalex.org/W2995439439"
  ],
  "abstract": "Background The tenth revision of the International Classification of Diseases (ICD-10) is widely used for epidemiological research and health management. The clinical modification (CM) and procedure coding system (PCS) of ICD-10 were developed to describe more clinical details with increasing diagnosis and procedure codes and applied in disease-related groups for reimbursement. The expansion of codes made the coding time-consuming and less accurate. The state-of-the-art model using deep contextual word embeddings was used for automatic multilabel text classification of ICD-10. In addition to input discharge diagnoses (DD), the performance can be improved by appropriate preprocessing methods for the text from other document types, such as medical history, comorbidity and complication, surgical method, and special examination. Objective This study aims to establish a contextual language model with rule-based preprocessing methods to develop the model for ICD-10 multilabel classification. Methods We retrieved electronic health records from a medical center. We first compared different word embedding methods. Second, we compared the preprocessing methods using the best-performing embeddings. We compared biomedical bidirectional encoder representations from transformers (BioBERT), clinical generalized autoregressive pretraining for language understanding (Clinical XLNet), label tree-based attention-aware deep model for high-performance extreme multilabel text classification (AttentionXLM), and word-to-vector (Word2Vec) to predict ICD-10-CM. To compare different preprocessing methods for ICD-10-CM, we included DD, medical history, and comorbidity and complication as inputs. We compared the performance of ICD-10-CM prediction using different preprocesses, including definition training, external cause code removal, number conversion, and combination code filtering. For the ICD-10 PCS, the model was trained using different combinations of DD, surgical method, and key words of special examination. The micro F1 score and the micro area under the receiver operating characteristic curve were used to compare the model’s performance with that of different preprocessing methods. Results BioBERT had an F1 score of 0.701 and outperformed other models such as Clinical XLNet, AttentionXLM, and Word2Vec. For the ICD-10-CM, the model had an F1 score that significantly increased from 0.749 (95% CI 0.744-0.753) to 0.769 (95% CI 0.764-0.773) with the ICD-10 definition training, external cause code removal, number conversion, and combination code filter. For the ICD-10-PCS, the model had an F1 score that significantly increased from 0.670 (95% CI 0.663-0.678) to 0.726 (95% CI 0.719-0.732) with a combination of discharge diagnoses, surgical methods, and key words of special examination. With our preprocessing methods, the model had the highest area under the receiver operating characteristic curve of 0.853 (95% CI 0.849-0.855) and 0.831 (95% CI 0.827-0.834) for ICD-10-CM and ICD-10-PCS, respectively. Conclusions The performance of our model with the pretrained contextualized language model and rule-based preprocessing method is better than that of the state-of-the-art model for ICD-10-CM or ICD-10-PCS. This study highlights the importance of rule-based preprocessing methods based on coder coding rules.",
  "full_text": "Original Paper\nAutomatic International Classification of Diseases Coding System:\nDeep Contextualized Language Model With Rule-Based\nApproaches\nPei-Fu Chen1,2*, MD; Kuan-Chih Chen1,3*, MD, MSc; Wei-Chih Liao1, MSc; Feipei Lai1,4,5, PhD; Tai-Liang He4, BSc;\nSheng-Che Lin4, BSc; Wei-Jen Chen1, BSc; Chi-Yu Yang6,7, MD; Yu-Cheng Lin8,9, MD, PhD; I-Chang Tsai10, PhD;\nChi-Hao Chiu11, MS; Shu-Chih Chang12, MA; Fang-Ming Hung13,14, MD\n1Graduate Institute of Biomedical Electronics and Bioinformatics, National Taiwan University, Taipei, Taiwan\n2Department of Anesthesiology, Far Eastern Memorial Hospital, New Taipei City, Taiwan\n3Department of Internal Medicine, Far Eastern Memorial Hospital, New Taipei City, Taiwan\n4Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan\n5Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan\n6Department of Information Technology, Far Eastern Memorial Hospital, New Taipei City, Taiwan\n7Section of Cardiovascular Medicine, Cardiovascular Center, Far Eastern Memorial Hospital, New Taipei City, Taiwan\n8Department of Pediatrics, Far Eastern Memorial Hospital, New Taipei City, Taiwan\n9Department of Healthcare Administration, Oriental Institute of Technology, New Taipei City, Taiwan\n10Artificial Intelligence Center, Far Eastern Memorial Hospital, New Taipei City, Taiwan\n11Section of Health Insurance, Department of Medical Affairs, Far Eastern Memorial Hospital, New Taipei City, Taiwan\n12Medical Records Department, Far Eastern Memorial Hospital, New Taipei City, Taiwan\n13Department of Medical Affairs, Far Eastern Memorial Hospital, New Taipei City, Taiwan\n14Department of Surgical Intensive Care Unit, Far Eastern Memorial Hospital, New Taipei City, Taiwan\n*these authors contributed equally\nCorresponding Author:\nFang-Ming Hung, MD\nDepartment of Medical Affairs\nFar Eastern Memorial Hospital\nNo. 21, Sec. 2, Nanya S. Rd., Banciao Dist.\nNew Taipei City, 220216\nTaiwan\nPhone: 886 2 8966 7000\nFax: 886 2 8966 5567\nEmail: drphilip101@gmail.com\nAbstract\nBackground: The tenth revision of the International Classification of Diseases (ICD-10) is widely used for epidemiological\nresearch and health management. The clinical modification (CM) and procedure coding system (PCS) of ICD-10 were developed\nto describe more clinical details with increasing diagnosis and procedure codes and applied in disease-related groups for\nreimbursement. The expansion of codes made the coding time-consuming and less accurate. The state-of-the-art model using\ndeep contextual word embeddings was used for automatic multilabel text classification of ICD-10. In addition to input discharge\ndiagnoses (DD), the performance can be improved by appropriate preprocessing methods for the text from other document types,\nsuch as medical history, comorbidity and complication, surgical method, and special examination.\nObjective: This study aims to establish a contextual language model with rule-based preprocessing methods to develop the\nmodel for ICD-10 multilabel classification.\nMethods: We retrieved electronic health records from a medical center. We first compared different word embedding methods.\nSecond, we compared the preprocessing methods using the best-performing embeddings. We compared biomedical bidirectional\nencoder representations from transformers (BioBERT), clinical generalized autoregressive pretraining for language understanding\n(Clinical XLNet), label tree-based attention-aware deep model for high-performance extreme multilabel text classification\nJMIR Med Inform 2022 | vol. 10 | iss. 6 | e37557 | p. 1https://medinform.jmir.org/2022/6/e37557\n(page number not for citation purposes)\nChen et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\n(AttentionXLM), and word-to-vector (Word2Vec) to predict ICD-10-CM. To compare different preprocessing methods for\nICD-10-CM, we included DD, medical history, and comorbidity and complication as inputs. We compared the performance of\nICD-10-CM prediction using different preprocesses, including definition training, external cause code removal, number conversion,\nand combination code filtering. For the ICD-10 PCS, the model was trained using different combinations of DD, surgical method,\nand key words of special examination. The micro F1 score and the micro area under the receiver operating characteristic curve\nwere used to compare the model’s performance with that of different preprocessing methods.\nResults: BioBERT had an F1 score of 0.701 and outperformed other models such as Clinical XLNet, AttentionXLM, and\nWord2Vec. For the ICD-10-CM, the model had an F1 score that significantly increased from 0.749 (95% CI 0.744-0.753) to 0.769\n(95% CI 0.764-0.773) with the ICD-10 definition training, external cause code removal, number conversion, and combination\ncode filter. For the ICD-10-PCS, the model had an F1 score that significantly increased from 0.670 (95% CI 0.663-0.678) to 0.726\n(95% CI 0.719-0.732) with a combination of discharge diagnoses, surgical methods, and key words of special examination. With\nour preprocessing methods, the model had the highest area under the receiver operating characteristic curve of 0.853 (95% CI\n0.849-0.855) and 0.831 (95% CI 0.827-0.834) for ICD-10-CM and ICD-10-PCS, respectively.\nConclusions: The performance of our model with the pretrained contextualized language model and rule-based preprocessing\nmethod is better than that of the state-of-the-art model for ICD-10-CM or ICD-10-PCS. This study highlights the importance of\nrule-based preprocessing methods based on coder coding rules.\n(JMIR Med Inform 2022;10(6):e37557) doi: 10.2196/37557\nKEYWORDS\ndeep learning; International Classification of Diseases; medical records; multilabel text classification; natural language processing;\ncoding system; algorithm; electronic health record; data mining\nIntroduction\nBackground\nThe International Classification of Diseases (ICD) aims to\nsystematically record, analyze, interpret, and compare mortality\nand morbidity data collected in different areas. ICD transforms\nthe diagnosis of diseases and other health problems from text\nto alphanumeric codes, which are mixed with English letters\nand numbers [1]. ICD has become an internationally accepted\ndiagnostic classification system for epidemiological research\nand health management.\nThe World Health Organization (WHO) introduced the tenth\nrevision of the International Classification of Diseases (ICD-10)\nin the 1990s to accommodate the increasing number of diagnoses\nand related health problems [1]. The clinical modification (CM)\nand procedure coding system (PCS) of ICD-10 (ICD-10-CM\nand ICD-10-PCS) have been developed to describe more clinical\ndetails with increasing diagnosis and procedure codes and\napplied in payment methodologies, such as disease-related\ngroups in the United States [2,3]. The transition from ICD-9 to\nICD-10-CM or ICD-10-PCS expanded the number of codes.\nThere are only approximately 14,000 diagnosis codes and 3800\nprocedure codes in ICD-9, but approximately 69,000 in\nICD-10-CM and 72,000 in ICD-10-PCS [3]. The expanded\ncodes suppress productivity and increase the cost of disease\ncoding [4]. In practice, the disease coder spent more time\ninterpreting the text of the medical records to ensure the\ncorrectness of the disease [4].\nThe speed and correctness of the classification of the disease\ncoder will be affected by incomplete medical records, orders of\ndiagnosis, undetailed surgical findings, and fragmented exam\nreports. In addition, hospitals must increase their accuracy in\nterms of reimbursement. The research found that income can\nbe increased by approximately 5% with a clinician-auditor\nreview in patients discharged following an emergency admission\n[5].\nRelated Work\nIn recent years, text classification from electronic health records\n(EHR) data has been widely studied in natural language\nprocessing [6], which is a subdiscipline in the fields of artificial\nintelligence and linguistics. This field explores how to process\nand use natural language by computers into meaningful\nrepresentations and maintain the relationships of meanings\naccording to the purpose [7]. Text classification can be divided\ninto the 3 categories of binary, multiclass, and multilabel.\nAmong these, multilabel text classification outputs multiple\nlabels with one or more classes. The multilabel classification\ntask is more challenging because the number of possible\ncombinations of results is greater if the label set is larger.\nTeng et al [8] recently proposed a model predicting ICD-10-CM\nusing a medical topic mining method and a cross-textual\nattentional neural network. It had an F1 score of 0.96 in a single\nlabel of “atrial fibrillation.” However, even with the same\nmethods proposed to predict the top 50 most frequent\nICD-10-CM codes, their model had an F1 score of 0.68. This\nshows that multilabel classification is more complicated than\nsingle-label classification. Multilabel classification for\nICD-10-PCS is even more challenging owing to its sparsity.\nSubotin et al [9] proposed a model with code co-occurrence\npropensity, which improved the prediction of ICD-10-PCS with\nan F1 score from 0.50 to 0.56.\nPrevious Work\nTo facilitate the laborious and time-consuming work process,\nwe have shown that the ICD-10 autocoding system achieved\nan F1 score of 0.67 and 0.58 in CM and PCS by applying\nJMIR Med Inform 2022 | vol. 10 | iss. 6 | e37557 | p. 2https://medinform.jmir.org/2022/6/e37557\n(page number not for citation purposes)\nChen et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nword-to-vector (Word2Vec) [10]. Furthermore, we achieved a\nbetter F1 score of 0.72 and 0.62 in CM and PCS through\nbidirectional encoder representations from transformers (BERT).\nIn addition, an attention mechanism was used in this\nclassification model to visualize the importance of words used\nto train new disease coders [11].\nIn our previous work, some problems were encountered, such\nas handling the following issues. Some meaningful numbers\nused in medical terms were removed from the data sets in the\npreprocessing stage. The combination codes comprising 2\ndiagnoses in 1 code were hard to be predicted. Other than\ndischarge diagnoses, information from the discharge records\nwas not efficiently included, such as medical history,\ncomorbidity, and complication. In addition, because the writing\nof medical records was different from the original ICD-10-CM\ncode definition, training our model with the ICD-10-CM\ndefinition may be helpful.\nSurgical method records and special examination reports are\nhelpful for disease coders to determine the ICD-10-PCS.\nHowever, information from special examination reports is\nchallenging to be extracted because it is mixed with\nuninformative content, such as ultrasound, radiology, endoscopy,\nand electroencephalography. Furthermore, information from\nsurgical method records is also essential, but the combination\nalgorithm for these types of documents should be studied.\nObjective\nThis study focuses on interpreting medical records to tackle the\nproblems mentioned above because we found that the accuracy\nis limited without a rule-based approach. We propose that we\ncan make our model more accurate by adopting coding rules\nfrom experienced disease coders in our preprocess. Therefore,\nthis study aims to establish a contextual language model with\nrule-based preprocessing methods to develop a more accurate\nand explainable ICD-10 autocoding system.\nMethods\nEthical Considerations\nThis retrospective study was approved by the institutional review\nboard of the Far Eastern Memorial Hospital (109086-F and\n110028-F), which waived the requirement for informed consent.\nData Collection\nData were acquired from the electronic medical records of the\nFar Eastern Memorial Hospital, a medical center in Taiwan,\nfrom January 2018 to December 2020. The collected data\nincluded admission date, discharge date, discharge summary,\nICD-10-CM codes, and ICD-10-PCS codes. The ground-truth\nICD-10-CM or ICD-10-PCS codes were labeled by the disease\ncoders.\nData Description\nWe obtained 101,974 documents for ICD-10-CM codes and\n105,466 documents for ICD-10-PCS codes. Our discharge\nsummary contains 5 types of documents. The discharge\ndiagnoses (DD) listed the main diagnoses related to this\nhospitalization. The surgical method (SM) includes a description\nof the surgical procedures and findings. The special examination\n(SE) includes ultrasound, radiological, endoscopic, and\nelectroencephalography reports. Medical history (MH) contains\nthe process of developing the present illness and the past medical\nhistory. Comorbidity and complications (CC) included\ncomplications noted during hospitalization.\nMost of these studies included CC and MH (Figure 1). The\ncount of the 3 types of documents in each chapter of the\nICD-10-CM and ICD-10-PCS are shown in Multimedia\nAppendix 1. The chapters were determined by the first 3 codes\nof the ICD-10 labels annotated by disease coders. The maximal\nword count was up to 2342 in SE, and the mean word count\nwas up to 149 in MH (Table 1).\nFigure 1. Data counts of 5 types of documents.\nJMIR Med Inform 2022 | vol. 10 | iss. 6 | e37557 | p. 3https://medinform.jmir.org/2022/6/e37557\n(page number not for citation purposes)\nChen et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nTable 1. Word counts of 5 types of documents.\nMean word countMaximal word countDocument type\n31480Discharge diagnoses\n11487Surgical method\n862342Special examination\n149586Medical history\n5338Comorbidity and complication\nCommon Text Preprocessing\nNull or duplicate data sets and punctuation were removed using\nthe Natural Language Toolkit [12]. Non-English characters were\nremoved before further preprocessing. The text in our EHR was\nwritten in mixed English and Chinese. The Chinese part contains\nthe names of the people, places, special customs, and transferred\nhospital, and is irrelevant to the diagnosis.\nStudy Design\nWe first compared different word embedding methods. Second,\nwe compared the preprocessing methods using the\nbest-performing word embedding methods. To choose the\nbest-performing embeddings, we compared the performance of\nWord2Vec [13], label tree-based attention-aware deep model\nfor high-performance extreme multilabel text classification\n(AttentionXLM) [14], biomedical BERT (BioBERT) [15], and\nclinical generalized autoregressive pretraining for language\nunderstanding (clinical XLNet) [16] to predict ICD-10-CM with\nDD as input. BioBERT had the highest F1 score and was chosen\nto compare the following preprocessing methods for ICD-10-CM\nor ICD-10-PCS (Multimedia Appendix 2).\nThe sections used for predicting ICD-10-CM were DD, MH,\nand CC; the sections used for predicting ICD-10-PCS were DD,\nSM, and SE. The concatenated input text from these sections\nwas long and contained fewer informative components. A proper\npreprocessing method should be designed to extract helpful\ninformation from text. We randomly split the data in a 9:1 ratio\ninto training and validation sets. After the model was trained\nwith the training set, the validation set was used to compare the\neffects of the following preprocessing methods: the change in\nthe model performance of the trained definition, external cause\ncode removal, number conversion, and combination code filter,\nwhich are shown for ICD-10-CM stepwise. The model\nperformance of inputting different document section\ncombinations was compared for ICD-10-PCS, including DD,\nSM, and SE (Figure 2).\nFigure 2. Data processing flow chart and the model architecture. BioBERT: bidirectional encoder representations from transformers for biomedical\ntext mining. CLS: classification; CM: clinical modification; ICD: International Classification of Diseases; PCS: procedure coding system; T: token;\nWoutput: output weight; Wp: pooled weight.\nModel Architecture\nAfter preprocessing, the text was tokenized using the BERT\ntokenizer. The tokens for BioBERT were truncated to 512 in\nlength because of the model limit [15]. Tokens are then inputted\ninto the BioBERT. A linear layer was connected to the pooled\noutput of BioBERT with labels. The labels are one-hot\nencodings of all individual ICD-10-CM or ICD-10-PCS codes\nin our data set, which are 9876 for CM and 7204 for PCS (Figure\n2). We calculated the loss by cross entropy. We trained the\nmodel using the Adam optimizer and a learning rate of 0.00005\nuntil 100 epochs or met the early stop criteria (less than 0.0001\nchanges for 10 epochs).\nData Preprocessing for ICD-10-CM\nWe included DD, MH, and CC to train the model for\nICD-10-CM. We designed a process to include helpful\ninformation and remove less informative content. This process\ncontains several components, including the following: MH\nextraction, CC combining, ICD-10-CM definition training,\nJMIR Med Inform 2022 | vol. 10 | iss. 6 | e37557 | p. 4https://medinform.jmir.org/2022/6/e37557\n(page number not for citation purposes)\nChen et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nexternal cause code removal, number conversion, and\ncombination code filter. The effects of adding the ICD-10-CM\ndefinition, external cause code removal, number conversion,\nand combination code filter on the model performance were\ncompared with the performance before adding these processes.\nMedical History\nWe included the MH to extract chronic diseases not mentioned\nin the DD because we found that some chronic diseases, such\nas hypertension or chronic kidney disease, were not recorded\nin approximately 15% of DD in our data. Because the mean\nlength of MH is 5 times that of DD (Table 1), we only extracted\nkey words from MH instead of directly merging DD and MH.\nWe listed these key words and their ICD-10-CM codes in\nMultimedia Appendix 3. These key words were produced after\ndiscussions with disease coders. Only key words found in the\ntext in the MH will be retained for combination after the key\nword extractor is used.\nComorbidity and Complication Combining\nAlthough CC is null in smoothly discharged patients, it affects\nthe ICD-10-CM code if it is not null. ICD-10-CM codes that\nare frequently inferred from CC include nausea, vomiting,\ndiarrhea, fatigue, and pneumonia. The mean length of the CC\nwas only one-sixth of the DD (Table 1), and thus we combined\nDD with CC directly.\nICD-10-CM Definition Trained\nWe initiated our model with weights from BioBERT and trained\nthe model on the official ICD-10-CM definition by the WHO\nas the input and the respective ICD-10-CM code as the output\n[1]. The model was trained for 100 epochs with early stop\ncriteria (less than 0.0001 changes for 10 epochs). For example,\nif the output ICD-10-CM code is N39.0, the input text is “urinary\ntract infection, site not specified.”.\nExternal Cause Codes Removal\nExternal cause codes (V01-Y98) define environmental events,\ncircumstances, and conditions, such as the cause of injury,\npoisoning, and other adverse effects related to an injury.\nHowever, it is challenging for a model to predict external cause\ncodes because relevant information is seldom recorded. Because\nexternal cause codes do not affect the final disease-related group\npayment, we removed them from our labels.\nNumber Converting\nThere are numbers in our EHR, such as the date of the MH, the\nreport’s physiological value, and the header of each line. They\nwere removed because most of them were not informative for\nour classification task. However, we found that some numbers\nmay affect the ICD-10-CM or ICD-10-PCS prediction, such as\npregnancy weeks (“36 weeks gestation of pregnancy”), stage\nof chronic diseases (“stage 4 chronic kidney disease”), type of\ndisease (“type 2 diabetes mellitus”), and grade of disease\n(“follicular lymphoma grade 1” and “modified Rankin scale\n0”). Thus, we converted all the known essential numbers back\nto alphabets, such as “stage four chronic kidney disease,” “type\ntwo diabetes mellitus,” and “thirty-six weeks gestation of\npregnancy,” before removing all numbers.\nCombination Code Filter\nA combination code represents the diagnosis of one or more\ncomorbidities. For example, hypertension with various\ncomorbidities refers to different combinations of codes. To\nsolve these problems, we designed a combination code filter\n(Multimedia Appendix 4). If the input text contains\n“hypertension,” it will check whether this case has chronic\nkidney disease and heart failure. If yes, the combination code\nfilter replaces the original text with the definition of the\ncombination code. In this manner, we prevented the model from\nproviding 2 codes instead of using combination codes.\nIllustrating Preprocessing for Models Predicting\nICD-10-CM\nAn example of preprocessing the input data for the models\npredicting ICD-10-CM is shown in Figure 3. After number\nconversion, we combined DD with extracted key words from\nMH, such as “hypertension” and “chronic kidney insufficiency,”\ninto the extract summary. We then transformed the summary\nusing a combination code filter into the training data. We first\ntrained our model using the ICD-10-CM definition and then\ntrained it on the training data.\nJMIR Med Inform 2022 | vol. 10 | iss. 6 | e37557 | p. 5https://medinform.jmir.org/2022/6/e37557\n(page number not for citation purposes)\nChen et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nFigure 3. Data preprocessing framework of ICD-10-CM classification model. CM: clinical modification; CT: computed tomography; ER: emergency\nroom; ICD: International Classification of Diseases; L: lumbar; LAR: low anterior resection; OS: oculus sinister.\nData Preprocessing for ICD-10-PCS\nWe included DD, SM, and SE to train the model for the\nICD-10-PCS. In addition to DD, SM and SE provide helpful\ninformation for determining ICD-10-PCS. We trained the model\nwith DD alone, SM alone, and 3 strategies for combining DD\nwith SM and SE, and then compared their performances.\nSurgical Method\nThe mean length of SM was one-third of that of DD (Table 1).\nSM was recorded only if the patient underwent major\nprocedures. To extract the most helpful information for training\nour model, we proposed a combination of DD and SM.\nJMIR Med Inform 2022 | vol. 10 | iss. 6 | e37557 | p. 6https://medinform.jmir.org/2022/6/e37557\n(page number not for citation purposes)\nChen et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nSpecial Examination\nThe mean length of SE was 3 times that of DD (Table 1). In an\nSE report, not all examinations will have the corresponding\nICD-10-PCS codes, such as radiological examination or\nelectroencephalography. Therefore, these components should\nbe removed accordingly.\nWe designed a key word extractor to extract helpful information\nfrom SE and to avoid excessive text length. We listed these key\nwords and their ICD-10-PCS codes from high to low frequency\nin Multimedia Appendix 5. These key words were produced by\na discussion with the disease coders. Only key words found in\nthe text in the SE were retained after the key word extractor\nwas used.\nAfter extracting the key words from the SE, we used 2 different\ncombination strategies. First, we input the DD only if the patient\nhas no SM or SE. In the second method, we input the DD if the\npatient had no SM and added key words from the SE.\nIllustrating Preprocessing for Models Predicting\nICD-10-PCS\nAn example of preprocessing the input data for models\npredicting ICD-10-PCS is shown in Figure 4. We first combined\nDD with extracted key words from SE, such as “endoscope”\nand “biopsy,” into the extract summary. We then trained our\nmodel on these data to predict ICD-10-PCS.\nJMIR Med Inform 2022 | vol. 10 | iss. 6 | e37557 | p. 7https://medinform.jmir.org/2022/6/e37557\n(page number not for citation purposes)\nChen et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nFigure 4. Data preprocessing framework of ICD-10-PCS classification model. AR: aortic regurgitation; CAD: coronary arterial disease; CBD: common\nbile duct; CV: cardiovascular; EGD: esophagogastroduodenoscopy; EGJ: esophago-gastric junction; GB: gall bladder; ICD: International Classification\nof Diseases; IHD: intrahepatic duct; IV, intravenous; LA: left atrium; LV: left ventricle; LVEF: left ventricular ejection fraction; MR: mitral regurgitation;\nPCS: procedure coding system; PV: portal vein; R/O: rule out; s/p: status post; TKR: total knee replacement; TR: tricuspid regurgitation.\nPreprocessing for ICD-10-CM Label Classification\nTo compare different preprocessing methods for ICD-10-CM,\nwe included DD, MH, and CC as inputs. We compared the\nperformance of ICD-10-CM prediction using different\npreprocesses, including definition training, external cause code\nremoval, number conversion, and combination code filtering.\nPreprocessing for ICD-10-PCS Label Classification\nIn the ICD-10-PCS part of this study, DD, SM, and SE were\nincluded as inputs. We compared the prediction performance\nof the input text, including only DD, SM, and the 3 combination\nstrategies. Combination strategy 1, “SM or DD”—we input the\nDD only if the case has no SM. Combination strategy 2,\nJMIR Med Inform 2022 | vol. 10 | iss. 6 | e37557 | p. 8https://medinform.jmir.org/2022/6/e37557\n(page number not for citation purposes)\nChen et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\n“(SM+SE) or DD”—we input the DD only if the case has no\nSM or SE. Combination strategy 3, “(SM+SE) or\n(CD+SE)”—we only input DD if the case has no SM and add\nkey words of SE.\nEvaluation Metrics\nMicroprecision is the summation of true positives divided by\nthe summation of all predicted positive cases (Formula 1).\nMicrorecall is the summation of true positives divided by the\nsummation of all actual positive cases (Formula 2). The micro\nF1 score is the harmonic mean of the microrecall and\nmicroprecision, and it is an overall measure of the quality of a\nclassifier’s predictions (Formula 3). The area under the receiver\noperating characteristic curve (AUROC) was calculated by\ntaking the true-positive rate against the false-positive rate. The\nmicro-average calculates the metrics globally by considering\neach element of the label indicator matrix as a label. We chose\nthe micro F1 score and micro-AUROC to compare the model\nperformance. The F1 score, precision, recall, and AUROC are\nbootstrapped 100 times to calculate the 95% confidence interval.\nResults\nICD-10-CM Label Classification\nIn our ICD-10-CM multilabel text classification task, each case\ncontained approximately 1 to 20 codes from A00 to Z99. The\nlabel set was 9876 in the CM. In the comparison of different\nembedding models, BioBERT, Clinical XLNet, AttentionXLM,\nand Word2Vec had the F1 score of 0.701, 0.685, 0.654, and\n0.651, respectively. The BioBERT model had the highest F1\nscore and was selected for the following experiment. Table 2\nshows a comparison of the different preprocessing methods for\nthe ICD-10-CM. The baseline model had a micro F1 score of\n0.749 (95% CI 0.744-0.753). After the model was trained with\nthe definition, it had an F1 score of 0.759 (95% CI 0.754-0.763).\nAfter removing the external cause codes, converting the number\nto the alphabet, and applying a combination code filter, the\nmodel had an F1 score of 0.763 (95% CI 0.759-0.767), 0.767\n(95% CI 0.761-0.772), and 0.769 (95% CI 0.764-0.773),\nrespectively. The baseline model had the AUROC of 0.839\n(95% CI 0.835-0.842). With all the preprocessing methods used,\nthe model had an AUROC of 0.858 (95% CI 0.849-0.855).\nTable 2. Comparison of different preprocessing methods for BioBERTa model on ICDb-10-CMc. Preprocessing methods are added one by one and\n95% CIs are calculated by bootstrapping.\nAUROCd (95% CI)Microrecall (95% CI)Microprecision (95% CI)Micro F1 score (95% CI)Preprocessing method\n0.839 (0.835-0.842)0.678 (0.672-0.684)0.836 (0.832-0.840)0.749 (0.744-0.753)Baseline\n0.848 (0.845-0.851)0.696 (0.690-0.702)0.833 (0.829-0.838)0.759 (0.754-0.763)+Trained with definition\n0.849 (0.846-0.851)0.697 (0.691-0.702)0.843 (0.840-0.846)0.763 (0.759-0.767)+External cause codes removal\n0.851 (0.847-0.854)0.702 (0.695-0.708)0.845 (0.840-0.849)0.767 (0.761-0.772)+Number converting\n0.853 (0.849-0.855)0.706 (0.699-0.711)0.845 (0.841-0.850)0.769 (0.764-0.773)+Combination code filter\naBioBERT: bidirectional encoder representations from transformers for biomedical text mining.\nbICD: International Classification of Diseases.\ncCM: clinical modification.\ndAUROC: area under the receiver operating characteristic curve.\nICD-10-PCS Label Classification\nIn our ICD-10-PCS multilabel text classification task, each case\ncontained approximately 1-20 codes. The label set was 7204 in\nthe PCS. Table 3 shows a comparison of different input\ndocument combinations for the ICD-10-PCS. The models trained\nwith only DD and SM had an F1 score of 0.670 (95% CI\n0.663-0.678) and 0.618 (95% CI 0.607-0.627), respectively.\nThe model trained with combination strategies 1 (SM or DD),\n2 ([SM+SE] or DD), and 3 ([SM+SE] or [DD+SE]) had an F1\nscore of 0.714 (95% CI 0.708-0.721), 0.724 (95% CI\n0.718-0.730), and 0.726 (95% CI 0.719-0.732), respectively.\nThe models trained with only DD had the AUROC of 0.800\n(95% CI 0.796-0.805). With combination strategy 3, the model\nhad the highest AUROC of 0.831 (95% CI 0.827-0.834).\nJMIR Med Inform 2022 | vol. 10 | iss. 6 | e37557 | p. 9https://medinform.jmir.org/2022/6/e37557\n(page number not for citation purposes)\nChen et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nTable 3. Comparison of different preprocessing methods for BioBERTa model on ICDb-10-PCSc. The 95% CIs are calculated by bootstrapping.\nAUROCd (95% CI)Microrecall (95% CI)Microprecision (95% CI)Micro F1 score (95% CI)Preprocessing method\n0.800 (0.796-0.805)0.601 (0.593-0.610)0.756 (0.750-0.761)0.670 (0.663-0.678)DDe\n0.762 (0.756-0.767)0.524 (0.512-0.534)0.750 (0.741-0.762)0.618 (0.607-0.627)SMf\n0.826 (0.822-0.830)0.651 (0.644-0.660)0.790 (0.784-0.791)0.714 (0.708-0.721)SM or DD\n0.830 (0.827-0.834)0.661 (0.654-0.668)0.801 (0.794-0.808)0.724 (0.718-0.730)(SM+SEg) or DD\n0.831 (0.827-0.834)0.661 (0.654-0.669)0.803 (0.797-0.810)0.726 (0.719-0.732)(SM+SE) or (DD+SE)\naBioBERT: bidirectional encoder representations from transformers for biomedical text mining.\nbICD: International Classification of Diseases.\ncPCS: procedure coding system.\ndAUROC: area under the receiver operating characteristic curve.\neDD: discharge diagnoses.\nfSM: surgical method.\ngSE: special examination.\nDiscussion\nPrincipal Findings\nIn our study of the multilabel text classification of ICD-10-CM\nor ICD-10-PCS, each case contained 1-20 codes, and the label\nset contained up to 9876 and 7204 in CM and PCS, respectively.\nIn our previous study, the model had an F1 score of 0.71 and\n0.62 in ICD-10-CM and ICD-10-PCS [11]. In this study, we\nproposed preprocessing methods for ICD-10-CM and\nICD-10-PCS, respectively. For the ICD-10-CM, the model had\na significant F1 score increase from 0.749 (95% CI 0.744-0.753)\nto 0.769 (95% CI 0.764-0.773) and a significant AUROC\nincrease from 0.839 (95% CI 0.835-0.842) to 0.853 (95% CI\n0.849-0.855). For the ICD-10-PCS, the model had an F1 score\nthat significantly increased from 0.670 (95% CI 0.663-0.678)\nto 0.726 (95% CI 0.719-0.732) and an AUROC that significantly\nincreased from 0.800 (95% CI 0.796-0.805) to 0.831 (95% CI\n0.827-0.834).\nIn our comparison of different word embedding methods for\nICD-10-CM classification, BioBERT achieved the highest F1\nscore of 0.701 among all embedding methods. This result is\nconsistent with previous research that contextualized\nrepresentations (BERT and XLNet) showing consistent\nimprovement over noncontextualized models (Word2Vec and\nAttentionXLM) in multilabel text classification tasks [17].\nBioBERT was pretrained on PubMed abstracts and PubMed\nCentral full-text articles to improve the performance of\nbiomedical text-mining tasks [15]. Previous studies confirmed\nthat BioBERT outperformed other embedding methods in\nclassifying ICD-10-CM [11,18].\nTraining the model with the ICD-10-CM definition increased\nits F1 score from 0.749 to 0.759 (1.3%). Each ICD-10-CM code\nhas a textual description of the definition on the WHO website\n[1]. Although the text in medical records is different from the\nWHO’s definition, its semantics should approximate that\ndefinition. The results showed that training with definition\nincreased the model performance for the multilabel classification\nof clinical text. External cause code removal increases the\nmodel’s F1 score from 0.759 to 0.763 (0.5%). The improvement\nis limited because external cause codes only accounted for\n2.73% (2787/101,974) of our cases.\nThe number conversion increased the model’s F1 score from\n0.763 to 0.767 (0.5%). Number converting affected 33.3%\n(33,978/101,974) of our cases. Retaining informative numbers\nsuch as disease type, grade, stages, and pregnancy weeks helps\nthe model learn the relation of these numbers to the different\ncodes. For example, there were differences between type 1\ndiabetes mellitus (E10) and type 2 diabetes mellitus (E11),\nfollicular lymphoma grades I (C82.0) and II (C82.1), chronic\nkidney disease stages 1 (N18.1) and 4 (N18.4), and full-term\nuncomplicated delivery (O80) and preterm delivery (060). The\ncombination code filter increases the model’s F1 score from\n0.767 to 0.769 (0.2%). The rules of the combination code are\nchallenging to learn through machine learning because this text\nmay be linked to 2 different codes instead of 1 combination\ncode. With all preprocessing methods, the F1 score increased\nfrom 0.749 to 0.769 (2.6%). Our result is better than the\nstate-of-the-art model of ICD-10-CM with an F1 score of 0.68\n[8] because we designed a key word extractor and trained our\nmodel with ICD-10-CM definition, external cause code removal,\nnumber conversion, and combination code filter.\nThe trained model had the F1 score of 0.670 and 0.618 for DD\nand SM, respectively. DD is more informative for predicting\nICD-10-PCS than SM when used alone. However, the model\ntrained using combination strategy 1 (SM or DD) had an F1\nscore of 0.714. The F1 score was 6.6% and 15.5% higher than\nthat of DD alone and SM alone, respectively. The F1 score of\nthe model trained with SM alone was lower than that of the\nmodel trained with DD alone because only 58%\n(60,558/104,411) of the cases had SM compared to cases with\nDD. If a patient underwent surgery, the ICD-10-PCS codes were\ncoded according to the SM records. The model trained with\ncombination strategies 2 ([SM+SE] or DD) and 3 ([SM+SE] or\n[DD+SE]) had an F1 score of 0.724 and 0.726, respectively.\nTheir F1 scores were 1.4% and 1.7% higher than those of\nStrategy 1. Adding SE to SM or DD is effective in improving\nJMIR Med Inform 2022 | vol. 10 | iss. 6 | e37557 | p. 10https://medinform.jmir.org/2022/6/e37557\n(page number not for citation purposes)\nChen et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nthe model performance because several ICD-10-PCS codes are\ncoded according to ultrasound or endoscopic reports in SM.\nOur result is better than the state-of-the-art model of\nICD-10-PCS with an F1 score of 0.56 [9] because we designed\na key word extractor and combined DD with SM and SE.\nLimitations\nOur study had some limitations. First, the data were obtained\nfrom a single medical center. Writing habits and disease\nprevalence may vary between hospitals. Different purposes of\ncoding in different areas may also affect the labels. External\nvalidation should be conducted in future studies. Second,\nalthough we attempted to include most of the content from the\nhealth record, other parts may also contribute to the prediction,\nsuch as problem lists and progress notes. Further studies are\nrequired to manage these issues.\nConclusions\nICD-10-CM and ICD-10-PCS codes are widely applied in\nsurveillance, clinical research, and reimbursement. Because of\nthe complexity of ICD-10-CM and ICD-10-PCS, it takes\napproximately 40.4 min for a record to be coded into\nICD-10-CM or ICD-10-PCS manually [2]. This study proposed\na model with a combination of a pretrained contextualized\nlanguage model and rule-based preprocessing methods that\noutperformed the state-of-the-art models in predicting\nICD-10-CM or ICD-10-PCS. This study highlights the\nimportance of rule-based preprocessing methods based on coder\ncoding rules. In EHR, other documents are read manually to\ndetermine ICD-10-CM or ICD-10-PCS codes, such as radiology\nreports, laboratory data, and the problem list. An effective\npreprocessing method to include documents can be studied in\nthe future.\nAcknowledgments\nThis study was supported by grants from the Ministry of Science and Technology, Taiwan (Grant MOST 110-2634-F-002-032-)\nand the Far Eastern Memorial Hospital, Taiwan (Grant FEMH-2021-C-056). The sponsors had no role in the study design, data\ncollection and analysis, publication decisions, or manuscript drafting.\nAuthors' Contributions\nFL and WCL designed the study. WCL, TLH, and SCL designed and developed the system. PFC, KCC, CYY, YCL, ICT, CHC,\nSCC, and FMH collected the data. PFC and KCC conducted the experiments. WCL and PFC conducted the statistical analyses.\nPFC, KCC, and WCL drafted the manuscript. All authors reviewed the final manuscript.\nConflicts of Interest\nNone declared.\nMultimedia Appendix 1\nCounts of types of documents in each chapter of ICD-10-CM and procedure coding system (PCS). CM: clinical modification;\nICD: International Classification of Diseases.\n[DOCX File , 185 KB-Multimedia Appendix 1]\nMultimedia Appendix 2\nComparing performance and hyperparameters of different embedding models.\n[DOCX File , 124 KB-Multimedia Appendix 2]\nMultimedia Appendix 3\nICD-10-CM codes with key words in medical history. CM: clinical modification; ICD: International Classification of Diseases.\n[DOCX File , 25 KB-Multimedia Appendix 3]\nMultimedia Appendix 4\nHypertension-related combination code and amount.\n[DOCX File , 16 KB-Multimedia Appendix 4]\nMultimedia Appendix 5\nICD-10-PCS codes with key words in special examination. ICD: International Classification of Diseases; PCS: procedure coding\nsystem.\n[DOCX File , 18 KB-Multimedia Appendix 5]\nReferences\nJMIR Med Inform 2022 | vol. 10 | iss. 6 | e37557 | p. 11https://medinform.jmir.org/2022/6/e37557\n(page number not for citation purposes)\nChen et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\n1. International Classification of Diseases, 10th Revision. World Health Organization. 2015. URL: https://icd.who.int/browse10/\n2015/en [accessed 2021-08-04]\n2. Steindel SJ. International classification of diseases, 10th edition, clinical modification and procedure coding system:\ndescriptive overview of the next generation HIPAA code sets. J Am Med Inform Assoc 2010 May 01;17(3):274-282. [doi:\n10.1136/jamia.2009.001230] [Medline: 20442144]\n3. Mills R, Butler R, McCullough E, Bao M, Averill R. Impact of the transition to ICD-10 on Medicare inpatient hospital\npayments. Medicare Medicaid Res Rev 2011 Jun 06;1(2):E1-E13. [doi: 10.5600/mmrr.001.02.a02] [Medline: 22340773]\n4. Kusnoor, Blasingame MN, Williams AM, DesAutels SJ, Su J, Giuse NB. A narrative review of the impact of the transition\nto ICD-10 and ICD-10-CM/PCS. JAMIA Open 2020 Apr;3(1):126-131. [doi: 10.1093/jamiaopen/ooz066] [Medline:\n32607494]\n5. Nouraei SAR, Virk JS, Hudovsky A, Wathen C, Darzi A, Parsons D. Accuracy of clinician-clinical coder information\nhandover following acute medical admissions: implication for using administrative datasets in clinical outcomes management.\nJ Public Health (Oxf) 2016 Jun 23;38(2):352-362. [doi: 10.1093/pubmed/fdv041] [Medline: 25907271]\n6. Pivovarov, Elhadad N. Automated methods for the summarization of electronic health records. J Am Med Inform Assoc\n2015 Sep;22(5):938-947. [doi: 10.1093/jamia/ocv032] [Medline: 25882031]\n7. Chowdhury GG. Natural language processing. Ann. Rev. Info. Sci. Tech 2005 Jan 31;37(1):51-89. [doi:\n10.1002/aris.1440370103]\n8. Teng F, Ma Z, Chen J, Xiao M, Huang L. Automatic Medical Code Assignment via Deep Learning Approach for Intelligent\nHealthcare. IEEE J. Biomed. Health Inform 2020 Sep;24(9):2506-2515. [doi: 10.1109/jbhi.2020.2996937]\n9. Subotin, Davis AR. A method for modeling co-occurrence propensity of clinical codes with application to ICD-10-PCS\nauto-coding. J Am Med Inform Assoc 2016 Sep;23(5):866-871. [doi: 10.1093/jamia/ocv201] [Medline: 26911826]\n10. Wang S, Chang Y, Kuo L, Lai F, Chen Y, Yu F, et al. Using Deep Learning for Automatic Icd-10 Classification from\nFreeText Data. Eur J Biomed Inform 2020;16(1):1-10.\n11. Chen P, Wang S, Liao W, Kuo L, Chen K, Lin Y, et al. Automatic ICD-10 Coding and Training System: Deep Neural\nNetwork Based on Supervised Learning. JMIR Med Inform 2021 Aug 31;9(8):e23230 [FREE Full text] [doi: 10.2196/23230]\n[Medline: 34463639]\n12. Loper E, Bird S. NLTK: The Natural Language Toolkit. ArXiv Preprint posted online May 5, 2002.\n13. Mikolov T, Chen K, Corrado G, Dean J. Efficient Estimation of Word Representations in Vector Space. ArXiv Preprint\nposted online September 7, 2013.\n14. You, Ronghui. Attentionxml: Label tree-based attention-aware deep model for high-performance extreme multi-label text\nclassification. Advances in Neural Information Processing Systems 2019.\n15. Lee, Yoon W, Kim S, Kim D, Kim S, So CH, et al. BioBERT: a pre-trained biomedical language representation model for\nbiomedical text mining. Bioinformatics 2020 Feb 15;36(4):1234-1240. [doi: 10.1093/bioinformatics/btz682] [Medline:\n31501885]\n16. Huang K, Singh A, Chen S, Moseley E, Deng C, George N, et al. Clinical XLNet: Modeling Sequential Clinical Notes and\nPredicting Prolonged Mechanical Ventilation. ArXiv Preprint posted online November 2020. [doi:\n10.18653/v1/2020.clinicalnlp-1.11]\n17. Schumacher E, Dredze M. Learning unsupervised contextual representations for medical synonym discovery. JAMIA Open\n2019 Dec;2(4):538-546. [doi: 10.1093/jamiaopen/ooz057] [Medline: 32025651]\n18. Blanco A, Perez-de-Viñaspre O, Pérez A, Casillas A. Boosting ICD multi-label classification of health records with\ncontextual embeddings and label-granularity. Comput Methods Programs Biomed 2020 May;188:105264. [doi:\n10.1016/j.cmpb.2019.105264] [Medline: 31851906]\nAbbreviations\nAttentionXLM: label tree-based attention-aware deep model for high-performance extreme multi-label text\nclassification\nAUROC: area under the receiver operating characteristic curve\nBERT: bidirectional encoder representations from transformers\nBioBERT: bidirectional encoder representations from transformers for biomedical text mining\nCC: comorbidity and complications\nCM: clinical modification\nDD: discharge diagnoses\nEHR: electronic health records\nICD: International Classification of Diseases\nMH: medical history\nPCS: procedure coding system\nSE: special examination\nSM: surgical method\nJMIR Med Inform 2022 | vol. 10 | iss. 6 | e37557 | p. 12https://medinform.jmir.org/2022/6/e37557\n(page number not for citation purposes)\nChen et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nWHO: World Health Organization\nWord2Vec: word to vector\nXLNet: generalized autoregressive pretraining for language\nEdited by C Lovis; submitted 25.02.22; peer-reviewed by HJ Dai, C Gaudet-Blavignac, A Hasan; comments to author 18.03.22;\nrevised version received 13.05.22; accepted 12.06.22; published 29.06.22\nPlease cite as:\nChen PF, Chen KC, Liao WC, Lai F, He TL, Lin SC, Chen WJ, Yang CY, Lin YC, Tsai IC, Chiu CH, Chang SC, Hung FM\nAutomatic International Classification of Diseases Coding System: Deep Contextualized Language Model With Rule-Based Approaches\nJMIR Med Inform 2022;10(6):e37557\nURL: https://medinform.jmir.org/2022/6/e37557\ndoi: 10.2196/37557\nPMID: 35767353\n©Pei-Fu Chen, Kuan-Chih Chen, Wei-Chih Liao, Feipei Lai, Tai-Liang He, Sheng-Che Lin, Wei-Jen Chen, Chi-Yu Yang,\nYu-Cheng Lin, I-Chang Tsai, Chi-Hao Chiu, Shu-Chih Chang, Fang-Ming Hung. Originally published in JMIR Medical Informatics\n(https://medinform.jmir.org), 29.06.2022. This is an open-access article distributed under the terms of the Creative Commons\nAttribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction\nin any medium, provided the original work, first published in JMIR Medical Informatics, is properly cited. The complete\nbibliographic information, a link to the original publication on https://medinform.jmir.org/, as well as this copyright and license\ninformation must be included.\nJMIR Med Inform 2022 | vol. 10 | iss. 6 | e37557 | p. 13https://medinform.jmir.org/2022/6/e37557\n(page number not for citation purposes)\nChen et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7453370094299316
    },
    {
      "name": "Medical diagnosis",
      "score": 0.6334221959114075
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5844775438308716
    },
    {
      "name": "Medical classification",
      "score": 0.5387396216392517
    },
    {
      "name": "Diagnosis code",
      "score": 0.5139831900596619
    },
    {
      "name": "Unified Medical Language System",
      "score": 0.5085760354995728
    },
    {
      "name": "Preprocessor",
      "score": 0.49025776982307434
    },
    {
      "name": "Word2vec",
      "score": 0.48454251885414124
    },
    {
      "name": "Coding (social sciences)",
      "score": 0.47222259640693665
    },
    {
      "name": "Language model",
      "score": 0.4606589674949646
    },
    {
      "name": "Natural language processing",
      "score": 0.45910903811454773
    },
    {
      "name": "Word embedding",
      "score": 0.4576709270477295
    },
    {
      "name": "Data mining",
      "score": 0.425165593624115
    },
    {
      "name": "Machine learning",
      "score": 0.39174699783325195
    },
    {
      "name": "Medicine",
      "score": 0.16050246357917786
    },
    {
      "name": "Embedding",
      "score": 0.1310354471206665
    },
    {
      "name": "Nursing",
      "score": 0.0
    },
    {
      "name": "Pathology",
      "score": 0.0
    },
    {
      "name": "Statistics",
      "score": 0.0
    },
    {
      "name": "Environmental health",
      "score": 0.0
    },
    {
      "name": "Population",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210102996",
      "name": "Far Eastern Memorial Hospital",
      "country": "TW"
    },
    {
      "id": "https://openalex.org/I16733864",
      "name": "National Taiwan University",
      "country": "TW"
    },
    {
      "id": "https://openalex.org/I4210121532",
      "name": "Ministry of Health and Welfare",
      "country": "TW"
    },
    {
      "id": "https://openalex.org/I115980683",
      "name": "Oriental Institute of Technology",
      "country": "TW"
    }
  ],
  "cited_by": 16
}