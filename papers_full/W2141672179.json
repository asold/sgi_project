{
  "title": "Language modeling approaches to blog post and feed finding",
  "url": "https://openalex.org/W2141672179",
  "year": 2008,
  "authors": [
    {
      "id": "https://openalex.org/A2000742378",
      "name": "B.J. Ernsting",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A197647246",
      "name": "Wouter Weerkamp",
      "affiliations": [
        "University of Amsterdam",
        "Amsterdam University of the Arts"
      ]
    },
    {
      "id": "https://openalex.org/A401833296",
      "name": "Maarten de Rijke",
      "affiliations": [
        "Amsterdam University of the Arts",
        "University of Amsterdam"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2098699571",
    "https://openalex.org/W2172223751",
    "https://openalex.org/W1993972354",
    "https://openalex.org/W1503333931",
    "https://openalex.org/W1594274049",
    "https://openalex.org/W143775383",
    "https://openalex.org/W2169213601",
    "https://openalex.org/W2070740689"
  ],
  "abstract": "Abstract: We describe our participation in the TREC 2007 Blog track. In the opinion task we looked at the differences in performance between Indri and our mixture model, the influence of external expansion and document priors to improve opinion finding; results show that an out-of-the-box Indri implementation outperforms our mixture model, and that external expansion on a news corpus is very benificial. Opinion finding can be improved using either lexicons or the number of comments as document priors. Our approach to the feed distillation task is based on aggregating post-level scores to obtain a feed-level ranking. We integrated time-based and persistence aspects into the retrieval model. After correcting bugs in our post-score aggregation module we found that time-based retrieval improves results only marginally, while persistence-based ranking results in substantial improvements under the right circumstances. 1",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7490526437759399
    },
    {
      "name": "Ranking (information retrieval)",
      "score": 0.7295845150947571
    },
    {
      "name": "Task (project management)",
      "score": 0.6630551815032959
    },
    {
      "name": "Prior probability",
      "score": 0.6350865364074707
    },
    {
      "name": "Rank (graph theory)",
      "score": 0.5107488632202148
    },
    {
      "name": "Artificial intelligence",
      "score": 0.49109601974487305
    },
    {
      "name": "Language model",
      "score": 0.4800504446029663
    },
    {
      "name": "Information retrieval",
      "score": 0.4124913215637207
    },
    {
      "name": "Natural language processing",
      "score": 0.3990633189678192
    },
    {
      "name": "Machine learning",
      "score": 0.3533018231391907
    },
    {
      "name": "Bayesian probability",
      "score": 0.21111392974853516
    },
    {
      "name": "Mathematics",
      "score": 0.13478192687034607
    },
    {
      "name": "Engineering",
      "score": 0.09351569414138794
    },
    {
      "name": "Combinatorics",
      "score": 0.0
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    }
  ]
}