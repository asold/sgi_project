{
  "title": "How many biological replicates are needed in an RNA-seq experiment and which differential expression tool should you use?",
  "url": "https://openalex.org/W2321872593",
  "year": 2016,
  "authors": [
    {
      "id": null,
      "name": "Schurch, Nicholas J.",
      "affiliations": [
        "University of Dundee"
      ]
    },
    {
      "id": "https://openalex.org/A2260128261",
      "name": "Schofield Pieta",
      "affiliations": [
        "University of Dundee"
      ]
    },
    {
      "id": null,
      "name": "GierliÅski, Marek",
      "affiliations": [
        "University of Dundee"
      ]
    },
    {
      "id": "https://openalex.org/A2197102576",
      "name": "Cole, Christian",
      "affiliations": [
        "University of Dundee"
      ]
    },
    {
      "id": "https://openalex.org/A2293950143",
      "name": "Sherstnev Alexander",
      "affiliations": [
        "University of Dundee"
      ]
    },
    {
      "id": "https://openalex.org/A2182922577",
      "name": "Singh Vijender",
      "affiliations": [
        "University of Dundee"
      ]
    },
    {
      "id": null,
      "name": "Wrobel, Nicola",
      "affiliations": [
        "Edinburgh Genomics",
        "University of Edinburgh"
      ]
    },
    {
      "id": null,
      "name": "Gharbi, Karim",
      "affiliations": [
        "University of Edinburgh",
        "Edinburgh Genomics"
      ]
    },
    {
      "id": null,
      "name": "Simpson, Gordon G.",
      "affiliations": [
        "University of Dundee"
      ]
    },
    {
      "id": "https://openalex.org/A5081849258",
      "name": "Owen-Hughes Tom",
      "affiliations": [
        "University of Dundee"
      ]
    },
    {
      "id": "https://openalex.org/A2261387015",
      "name": "Blaxter, Mark",
      "affiliations": [
        "University of Edinburgh",
        "Edinburgh Genomics"
      ]
    },
    {
      "id": "https://openalex.org/A4292448582",
      "name": "Barton Geoffrey J",
      "affiliations": [
        "University of Dundee"
      ]
    },
    {
      "id": "https://openalex.org/A2260128261",
      "name": "Schofield Pieta",
      "affiliations": [
        "University of Dundee"
      ]
    },
    {
      "id": "https://openalex.org/A2203257873",
      "name": "Gierliński Marek",
      "affiliations": [
        "University of Dundee"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2152239989",
    "https://openalex.org/W2134526812",
    "https://openalex.org/W1995070233",
    "https://openalex.org/W2126824096",
    "https://openalex.org/W2148723688",
    "https://openalex.org/W2110065044",
    "https://openalex.org/W2072602203",
    "https://openalex.org/W2156631105",
    "https://openalex.org/W2140688313",
    "https://openalex.org/W2161318011",
    "https://openalex.org/W2025183726",
    "https://openalex.org/W2022590976",
    "https://openalex.org/W2053818267",
    "https://openalex.org/W4205545339",
    "https://openalex.org/W2110891968",
    "https://openalex.org/W2148454250",
    "https://openalex.org/W2165909549",
    "https://openalex.org/W3106889297",
    "https://openalex.org/W2476759571",
    "https://openalex.org/W4210450218",
    "https://openalex.org/W1996984681",
    "https://openalex.org/W2163915946",
    "https://openalex.org/W2120835288",
    "https://openalex.org/W2060289784",
    "https://openalex.org/W2048212555",
    "https://openalex.org/W1974611660",
    "https://openalex.org/W1989367702",
    "https://openalex.org/W2031073218",
    "https://openalex.org/W4239029175",
    "https://openalex.org/W2217809488",
    "https://openalex.org/W2009458183",
    "https://openalex.org/W1012963668",
    "https://openalex.org/W2114405789",
    "https://openalex.org/W2137526110",
    "https://openalex.org/W2124097252",
    "https://openalex.org/W2098734857",
    "https://openalex.org/W2142165994",
    "https://openalex.org/W2127372456",
    "https://openalex.org/W2179438025",
    "https://openalex.org/W2147109452",
    "https://openalex.org/W1490261451",
    "https://openalex.org/W1972978214",
    "https://openalex.org/W2121211805",
    "https://openalex.org/W2065776802",
    "https://openalex.org/W2132832769",
    "https://openalex.org/W2170549904",
    "https://openalex.org/W1505277071",
    "https://openalex.org/W2154563407",
    "https://openalex.org/W2029836146",
    "https://openalex.org/W2017118719",
    "https://openalex.org/W2027455260",
    "https://openalex.org/W2070494252",
    "https://openalex.org/W2107018762",
    "https://openalex.org/W2114104545",
    "https://openalex.org/W2145699080",
    "https://openalex.org/W2013532868",
    "https://openalex.org/W2064397275",
    "https://openalex.org/W2123579165",
    "https://openalex.org/W4293857795",
    "https://openalex.org/W2135256913",
    "https://openalex.org/W2074414424",
    "https://openalex.org/W1977868902",
    "https://openalex.org/W2062983176",
    "https://openalex.org/W2133707124",
    "https://openalex.org/W2161106528",
    "https://openalex.org/W1995078504",
    "https://openalex.org/W2097065948",
    "https://openalex.org/W2100305481",
    "https://openalex.org/W2155804510",
    "https://openalex.org/W2119034410",
    "https://openalex.org/W2187489563",
    "https://openalex.org/W2489161884",
    "https://openalex.org/W2035094603",
    "https://openalex.org/W2797062063",
    "https://openalex.org/W2952535963",
    "https://openalex.org/W4244877703",
    "https://openalex.org/W1523634986",
    "https://openalex.org/W1995945562",
    "https://openalex.org/W2009543464",
    "https://openalex.org/W2170778160",
    "https://openalex.org/W1974876578",
    "https://openalex.org/W2418132357",
    "https://openalex.org/W4239389126",
    "https://openalex.org/W3033539383",
    "https://openalex.org/W2899899131"
  ],
  "abstract": "RNA-seq is now the technology of choice for genome-wide differential gene expression experiments, but it is not clear how many biological replicates are needed to ensure valid biological interpretation of the results or which statistical tools are best for analyzing the data. An RNA-seq experiment with 48 biological replicates in each of two conditions was performed to answer these questions and provide guidelines for experimental design. With three biological replicates, nine of the 11 tools evaluated found only 20%–40% of the significantly differentially expressed (SDE) genes identified with the full set of 42 clean replicates. This rises to &gt;85% for the subset of SDE genes changing in expression by more than fourfold. To achieve &gt;85% for all SDE genes regardless of fold change requires more than 20 biological replicates. The same nine tools successfully control their false discovery rate at ≲5% for all numbers of replicates, while the remaining two tools fail to control their FDR adequately, particularly for low numbers of replicates. For future RNA-seq experiments, these results suggest that at least six biological replicates should be used, rising to at least 12 when it is important to identify SDE genes for all fold changes. If fewer than 12 replicates are used, a superior combination of true positive and false positive performances makes edgeR and DESeq2 the leading tools. For higher replicate numbers, minimizing false positives is more important and DESeq marginally outperforms the other tools.",
  "full_text": "How many biological replicates are needed in an RNA-seq\nexperiment and which differential expression tool should\nyou use?\nNICHOLAS J. SCHURCH,1,6 PIETÀ SCHOFIELD,1,2,6 MAREK GIERLIN´SKI,1,2,6 CHRISTIAN COLE,1,6\nALEXANDER SHERSTNEV,1,6 VIJENDER SINGH,2 NICOLA WROBEL,3 KARIM GHARBI,3\nGORDON G. SIMPSON,4 TOM OWEN-HUGHES,2 MARK BLAXTER,3 and GEOFFREY J. BARTON1,2,5\n1Division of Computational Biology, College of Life Sciences, University of Dundee, Dundee DD1 5EH, United Kingdom\n2Division of Gene Regulation and Expression, College of Life Sciences, University of Dundee, Dundee DD1 5EH, United Kingdom\n3Edinburgh Genomics, University of Edinburgh, Edinburgh EH9 3JT, United Kingdom\n4Division of Plant Sciences, College of Life Sciences, University of Dundee, Dundee DD1 5EH, United Kingdom\n5Division of Biological Chemistry and Drug Discovery, College of Life Sciences, University of Dundee, Dundee DD1 5EH, United Kingdom\nABSTRACT\nRNA-seq is now the technology of choice for genome-wide differential gene expression experiments, but it is not clear how many\nbiological replicates are needed to ensure valid biological interpretation of the results or which statistical tools are best for\nanalyzing the data. An RNA-seq experiment with 48 biological replicates in each of two conditions was performed to answer\nthese questions and provide guidelines for experimental design. With three biological replicates, nine of the 11 tools evaluated\nfound only 20%–40% of the significantly differentially expressed (SDE) genes identified with the full set of 42 clean replicates.\nThis rises to >85% for the subset of SDE genes changing in expression by more than fourfold. To achieve >85% for all SDE\ngenes regardless of fold change requires more than 20 biological replicates. The same nine tools successfully control their false\ndiscovery rate at ≲5% for all numbers of replicates, while the remaining two tools fail to control their FDR adequately,\nparticularly for low numbers of replicates. For future RNA-seq experiments, these results suggest that at least six biological\nreplicates should be used, rising to at least 12 when it is important to identify SDE genes for all fold changes. If fewer than\n12 replicates are used, a superior combination of true positive and false positive performances makesedgeR and DESeq2 the\nleading tools. For higher replicate numbers, minimizing false positives is more important andDESeq marginally outperforms\nthe other tools.\nKeywords: RNA-seq; benchmarking; differential expression; replication; yeast; experimental design; statistical power\nINTRODUCTION\nRNA-seq has now supplanted microarrays as the technology\nof choice for genome-wide differential gene expression\n(DGE) experiments. In any experimental design, selecting\nthe appropriate number of biological replicates is a trade-\noff between cost and precision. For microarray methods it\nhas been shown that low replicate experiments often have in-\nsufficient statistical power to call DGE correctly (Pan et al.\n2002) and cannot accurately measure the natural biological\nvariability (Churchill 2002). Although it is widely appreciated\nthat increasing the number of replicates in an RNA-seq ex-\nperiment usually leads to more robust results (Auer and\nDoerge 2010; Hansen et al. 2011; Busby et al. 2013; Liu\net al. 2014), the precise relationship between replicate num-\nber and the ability to correctly identify the differentially ex-\npressed genes (i.e., the statistical power of the experiment)\nhas not been fully explored.\nThe rise of RNA-seq technology has led to the develop-\nment of many tools for analyzing DGE from these data\n(e.g., Anders and Huber 2010; Hardcastle and Kelly 2010;\nRobinson et al. 2010; Wang et al. 2010; Tarazona et al.\n2011; Li et al. 2012; Lund et al. 2012; Trapnell et al. 2012;\nLeng et al. 2013; Li and Tibshirani 2013; Frazee et al. 2014;\nLaw et al. 2014; Love et al. 2014; Moulos and Hatzis 2015).\nEach tool makes assumptions about the statistical properties\ninherent to RNA-seq data and they exploit a range of normal-\nization and analysis techniques to compute the magnitude of\n6These authors contributed equally to this work.\nCorresponding authors: g.g.simpson@dundee.ac.uk, t.a.owenhughes@\ndundee.ac.uk, Mark.Blaxter@ed.ac.uk, g.j.barton@dundee.ac.uk\nArticle published online ahead of print. Article and publication date are at\nhttp://www.rnajournal.org/cgi/doi/10.1261/rna.053959.115. Freely available\nonline through theRNA Open Access option.\n© 2016 Schurch et al. This article, published in RNA, is available under a\nCreative Commons License (Attribution 4.0 International), as described at\nhttp://creativecommons.org/licenses/by/4.0/.\nRNA 22:839–851; Published by Cold Spring Harbor Laboratory Press for the RNA Society 839\n Cold Spring Harbor Laboratory Press on November 5, 2025 . Published by rnajournal.cshlp.orgDownloaded from  Cold Spring Harbor Laboratory Press on November 5, 2025 . Published by rnajournal.cshlp.orgDownloaded from  Cold Spring Harbor Laboratory Press on November 5, 2025 . Published by rnajournal.cshlp.orgDownloaded from \na DGE result and estimate its significance. Several studies\nhave generated data specifically for the purpose of testing\nthe assumptions intrinsic to DGE methods (Marioni et al.\n2008; SEQC/MAQC-III Consortium 2014), but most rely ei-\nther on RNA-seq data sets designed to test biological hypoth-\neses (Bullard et al. 2010; Rapaport et al. 2013; Seyednasrollah\net al. 2013) or simulated data (Busby et al. 2013; Soneson\n2014), or a combination of the two (Kvam et al. 2012; Li\net al. 2012; Dillies et al. 2013; Guo et al. 2013; Soneson and\nDelorenzi 2013; Burden et al. 2014). The majority of studies\nbased on analysis of experimental RNA-seq data rely on data\nfrom experiments with fewer than five replicates per condi-\ntion (Marioni et al. 2008; Bullard et al. 2010; Kvam et al.\n2012; Li et al. 2012; Busby et al. 2013; Dillies et al. 2013;\nRapaport et al. 2013; SEQC/MAQC-III Consortium 2014;\nSoneson 2014), limiting their ability to compare the perfor-\nmance of DGE tools as a function of replication.\nTwo studies explore higher replication by exploiting pub-\nlicly available RNA-seq data from 21 individual clones of\ntwo laboratory strains of mouse (Bottomly et al. 2011;\nSoneson and Delorenzi 2013; Burden et al. 2014). Burden\net al. (2014) consider false discovery rate (FDR) as the\nmain metric for ranking five tools and conclude that at least\nsix replicates per condition and multiplexing DGE tools gives\nthe best results. Soneson and Delorenzi (2013) focus on the\ndegree of concordance between tools as a metric for compar-\nison and conclude that none of the 11 tools they tested per-\nform well with fewer than three replicates. Nevertheless,\nsince the experiments are from individual mice, the data\nmay reflect interindividual variance in RNA expression as\nwell as from other aspects of the experimental protocol.\nThe same is true of studies in human that make use of data\nfrom individuals to explore higher sample replication in\nDGE (Guo et al. 2013; Seyednasrollah et al. 2013). Guo\net al. (2013) expand the replicate number by comparing six\ntools using RNA-seq data from breast cancer tumor-normal\npaired samples from 53 individuals in The Cancer Genome\nAtlas (TCGA, The Cancer Genome Atlas Research Network\n2008), using this primarily to guide the construction of a sim-\nulated data set. They conclude that all six of the tools they test\nsuffer from oversensitivity but thatedgeR represents the best\ncompromise between accuracy and speed. Seyednasrollah\net al. (2013) examine the performance of eight tools using\nmouse data (Bottomly et al. 2011) and lymphoblastoid cell\ndata from a cohort of 56 unrelated Nigerian individuals\nfrom the HapMap project (The International HapMap\nConsortium 2005). They recommendlimma and DESeq for\ndata with fewer than five replicates per condition, finding\nthat edgeR is “oversensitive”and suffers from high variability\nin its results whileSAMSeq suffers from a lack of statistical\npower with few replicates. The idea of combining DGE meth-\nods is implemented in the novel tool PANDORA, which\nweights the results of different DGE tools according to their\nperformance on test data and performs at least as well as\nthe constituent tools (Moulos and Hatzis 2015).\nIn this paper, the performance of DGE tools is evaluated\nthrough the first highly replicated RNA-seq experiment de-\nsigned specifically to test both the assumptions intrinsic to\nRNA-seq DGE tools (Gierlin ´ski et al. 2015) and to assess\ntheir performance. The paper focuses on 11 popular RNA-\nseq specific DGE tools (as judged by citations): baySeq,\ncuffdiff, DEGSeq, DESeq, DESeq2, EBSeq, edgeR (exact and\nglm modes), limma, NOISeq, PoissonSeq, and SAMSeq (see\nTable 1 for references) and assesses their performance as a\nfunction of replicate number and fold change. The study pro-\nvides general recommendations on:\nHow many replicates future RNA-seq experiments require to\nmaximize the sensitivity and accuracy of DGE identifica-\ntion and quantification.\nThe most appropriate DGE tools to use to detect DE genes in\nRNA-seq experiments with a given number of replicates.\nRESULTS\nTool-specific gold standards\nRNA was sequenced from 48 biological replicate samples of\nSaccharomyces cerevisiae in each of two well-studied experi-\nmental conditions; wild-type (WT) and a Δsnf2 mutant.\nQuality control and data processing steps reject several repli-\ncates from each condition resulting in 42 WT and 44Δsnf2\nbiological\nreplicates of“clean”data totaling∼889M aligned\nreads (see Materials and Methods for a full description on\nthe experiment, the mutant strain, the sequencing and the\nquality control and data processing steps). The data used\nfor the performance comparison here represents a best-case\nscenario for the DGE tools since biological variation within\nconditions is low (Pearson’s R > 0.97 for all pairs of repli-\ncates). In contrast, the mean Pearson’s correlation (±1 SD)\nbetween replicates using the count data for four RNA-seq\nstudies from the ReCount project (Frazee et al. 2011) show\nonly /overbarR = 0.86\n+0.09\n−0.09 (Cheung et al. 2010), /overbarR = 0.95+0.04\n−0.04\n(Bottomly et al. 2011), /overbarR = 0.89+0.07\n−0.07 (Montgomery et al.\n2010; Pickrell et al. 2010),/overbarR = 0.64+0.22\n−0.22 (Wang et al. 2008).\nThe performance of each DGE tool as a function of repli-\ncate number and expression fold change was evaluated by\ncomparing the DGE results from subsets of these replicates\nagainst the “gold standard”set of DGE results obtained for\neach tool with the full set of clean replicates. The tool-specific\ngold standards were computed by running the tool on the\nread-count-per-gene measurements from the full set of clean\ndata and marking as“significantly differentially expressed”\n(SDE) those differentially expressed genes with multiple\ntesting corrected P-values or FDRs≤0.05. These gold-stan-\ndard runs typically result in 60%–75% of the 7126 genes in\nthe Ensembl v68 (Flicek et al. 2011)S. cerevisiae annota-\ntion being identified as SDE (except forDEGSeq, NOIseq,\nand PoissonSeq, which call >80% of the genes as SDE; see\nSupplemental Figs. S4, S10, S11A).\nSchurch et al.\n840 RNA, Vol. 22, No. 6\n Cold Spring Harbor Laboratory Press on November 5, 2025 . Published by rnajournal.cshlp.orgDownloaded from \nWith the tool-specific gold standards defined, each DGE\nalgorithm was run iteratively on i repeated subselections\ndrawn from the set of clean replicates (without replacement).\nFor each of the tools, bootstrap runs were performed withi =\n100 iterations andnr =2 ,… ,40 replicates in each condition\n(cuffdiff was significantly slower than the other tools so the\nnumber of iterations was reduced toi = 30 for this tool).\nFor a given value of nr, the mean log2 transformed fold\nchange [log2(FC)] and median adjustedP-value or FDR cal-\nculated across all the bootstrap iterations was considered\nrepresentative of the measured behavior for each individual\ngene. Again, genes were marked as SDE when the adjusted\nP-value or FDR was≤0.05. From these results, true posi-\ntive, true negative, false positive, and false negative rates\n(hereafter TPR, TNR, FPR, FNR) were then calculated as a\nfunction of n\nr for four arbitrary fold-change thresholds\n( log2(FC)\n⏐⏐ ⏐\n⏐= T [ 0, 0.3, 1, 2{} ), by comparing the SDE\ngenes from each bootstrap with the SDE genes from the tool’s\ngold standard (see Materials and Methods for a detailed de-\nscription of these calculations). Intrinsic to this method of\nmeasuring each tool’s performance is the assumption that\nthe large number of replicates in the full data set will enable\neach tool to unambiguously identify the“true”differentially\nexpressed genes in the experiment.\nTool performance\nFigure 1 shows an example of the key performance data for\nedgeR (exact) (similar figures foredgeR’s generalized linear\nmodel mode and the other tools can be found in\nSupplemental Figs. S2–S12). The fraction of all genesedgeR\n(exact) calls as SDE increases as a function ofn\nr and the im-\npact of sampling effects on this fraction shrinks asnr increases\n(Fig. 1A). The TPR performance changes as a function of\nboth replicate number and fold-change threshold (Fig. 1B,\nC). However,edgeR (exact)successfully controls its FDR for\nall combinations of bothn\nr and T and the primary effect of\nincreasing the number of replicates or imposing a fold-\nTABLE 1. RNA-seq differential gene expression tools and statistical tests\nName\nAssumed\ndistribution Normalization Description Version Citations d Reference\nt-test Normal DEseq a Two-sample t-test for equal variances –– –\nlog t-test Log-normal DEseq a Log-ratio t-test –– –\nMann-Whitney None DEseqa Mann-Whitney test –– Mann and\nWhitney (1947)\nPermutation None DEseq a Permutation test –– Efron and\nTibshirani (1993a)\nBootstrap Normal DEseq a Bootstrap test –– Efron and Tibshirani\n(1993a)\nbaySeqc Negative\nbinomial\nInternal Empirical Bayesian estimate of posterior\nlikelihood\n2.2.0 159 Hardcastle and Kelly\n(2010)\nCuffdiff Negative\nbinomial\nInternal Unknown 2.1.1 918 Trapnell et al. (2012)\nDEGseqc Binomial None Random sampling model using Fisher’s\nexact test and the likelihood ratio test\n1.22.0 325 Wang et al. (2010)\nDESeqc Negative\nbinomial\nDEseqa Shrinkage variance 1.20.0 1889 Anders and Huber\n(2010)\nDESeq2c Negative\nbinomial\nDEseqa Shrinkage variance with variance based\nand Cook's distance pre-filtering\n1.8.2 197 Love et al. (2014)\nEBSeqc Negative\nbinomial\nDEseqa\n(median)\nEmpirical Bayesian estimate of posterior\nlikelihood\n1.8.0 80 Leng et al. (2013)\nedgeRc Negative\nbinomial\nTMMb Empirical Bayes estimation and either an\nexact test analogous to Fisher’s exact\ntest but adapted to over-dispersed data\nor a generalized linear model\n3.10.5 1483 Robinson et al. (2010)\nLimmac Log-normal TMM b Generalized linear model 3.24.15 97 Law et al. (2014)\nNOISeqc None RPKM Nonparametric test based on signal-to-\nnoise ratio\n2.14.0 177 Tarazona et al. (2011)\nPoissonSeqc Poisson log-\nlinear model\nInternal Score statistic 1.1.2 37 Li et al. (2012)\nSAMSeqc None Internal Mann-Whitney test with Poisson\nresampling\n2.0 54 Li and Tibshirani\n(2013)\naSee Anders and Huber (2010).\nbSee Robinson and Oshlack (2010).\ncR (v3.2.2) and bioconductor (v3.1).\ndAs reported by PubMed Central articles that reference the listed reference (December 21, 2015).\nTesting DGE tool performance on 96-reps of RNA-seq\nwww.rnajournal.org 841\n Cold Spring Harbor Laboratory Press on November 5, 2025 . Published by rnajournal.cshlp.orgDownloaded from \nchange threshold is to increase the sensitivity of the tool, con-\nverting false negatives to true positives (Fig. 1D).\nFigure 2 summarizes the performance of all 11 tools con-\nsidered in this study as a function of replicate number and\nfold-change threshold. The TPR for bootstrap subselections\nwith three replicates and no fold-change threshold (n\nr =3 ,\nT =0 ) i s∼20%–40% for all the tools exceptNOISeq and\nDEGSeq, indicating that with this few replicates these exper-\niments were unable to identify the majority of DE genes\nregardless of the tool used to analyze the data (Fig. 2A).\nDEGSeq and NOISeq both show strong TPR performance\nbut this is coupled with high FPRs ( DEGSeq: ∼17%,\nNOISeq: ∼9%). For DEGSeq in particular this originates\nfrom overestimating the number of SDE genes regardless of\nthe number of replicates (Supplemental Fig. S4A). Excluding\nDEGSeq, the TPR performance for all the remaining tools is\na strong function of fold change (Fig. 1C;Supplemental Figs.\nS2–S12C). For the highest fold-change genes (T = 2), these\ntools show TPRs ≳85% and with the exception ofcuffdiff\nalso show FPRs consistent with zero (Fig. 2E). These tools\nare successfully capturing the majority of the true differential\nexpression signals for the most strongly changing genes from\neach tool’s gold standard with as few as three replicates per\ncondition. For this cohort of high fold-change SDE genes\nthe TPR is largely insensitive to replicate number. Irrespec-\ntive of the tool, increasing the number of replicates ton\nr =\n20 for T = 2 provides only a modest increase in TPR from\n∼85% to∼95% (Figs 1B, 2F;Supplemental Figs. S2–S12B).\nIncreasing the number of replicates has a dramatic effect\non the detection rate of genes with smaller fold changes.\nFraction of significant genes\n0.0 0.2 0.4 0.6 0.8 1.0\n01 0 20 30 40\nn r\nA\nn  =r\n3\n6\n10\n20\n30\nTPR (FPR)\n0.0 0.2 0.4 0.6 0.8 1.0\nT\n0.0 0.5 1.0 1.5 2.0\nC\n0\n0.3\n1\n2\n T >\nTPR (FPR)\n0.0 0.2 0.4 0.6 0.8 1.0\n01 0 2 0 3 0 4 0\nn r\nB\nTP\nFP\nTN\nFN\n01 0 20 30 40\nn r\n0 1000 2000 3000 4000\nCounts\nD\n5000\nFIGURE 1. Statistical properties ofedgeR (exact)as a function of|log2(FC)| threshold, T, and the number of replicates,nr. Individual data points are\nnot shown for clarity; however, the points comprising the lines are each an average over 100 bootstrap iterations, with the shaded regions showing the\n1 SD limits. (A) The fraction of all (7126) genes called as SDE as a function of the number of replicates (boxplots show the median, quartiles and\n95% limits across replicate selections within a bootstrap run). (B) Mean true positive rate (TPR) as a function of nr for four thresholds\nT∈{0,0.3,1,2} (solid curves, the mean false positive rate [FPR] forT = 0 is shown as the dashed blue curve, for comparison). Data calculated for every\nΔnr =1 .(C) Mean TPR as a function ofT for nr∈{3,6,10,20,30} (solid curves, again the mean FPR fornr = 3 is shown as the dashed blue curve, for\ncomparison). Data calculated everyΔT = 0.1. (D) The number of genes called as true/false positive/negative (TP, FP, TN, and FN) as a function of\nnr. The FPR remains extremely low with increasingnr demonstrating thatedgeR is excellent at controlling its false discovery rate. Data calculated for\nevery Δnr =1 .\nSchurch et al.\n842 RNA, Vol. 22, No. 6\n Cold Spring Harbor Laboratory Press on November 5, 2025 . Published by rnajournal.cshlp.orgDownloaded from \nReducing the fold-change threshold reduces the TPR inde-\npendently of replicate number for all the tools except\nDEGSeq (Fig. 2A–D). The reduced TPR associated with a re-\nduced fold-change threshold can be recovered by increasing\nthe replicate number. For example, achieving an ∼85%\ndetection rate withedgeR (exact) for fold-change thresholds\nof T = 1, 0.3, and 0 requires∼9, 11, and\n26 replicates, respectively (Fig. 1B,C).\nFor all the tools except DEGSeq, the\nTPR performance as a function of fold-\nchange threshold has two distinct linear\nregions: a shallow linear regime at high-\nT and a steeper region at low-T (Fig.\n1C; Supplemental Figs. S2, S3, S5 –\nS12C). The transition between these\ntwo regions is a function of both the\ntool and the number of replicates. For\nedgeR (exact) with n\nr = 3, this transition\nfold-change threshold is∼0.5 and drops\nto ∼0.25 and ∼0.15 for nr = 10 and 30,\nrespectively (Fig. 1C). These transitions\nrepresent an optimal fold-change thresh-\nold to filter the data by, to maximize both\nthe quality and the utility of the data.\nThe best performing tools, DESeq,\nDESeq2, EBSeq, edgeR, and limma, suc-\ncessfully control their FPR, maintaining\nit consistently close to or below 5% ir-\nrespective of fold-change threshold or\nnumber of replicates (Figs. 1B,C, 2;\nSupplemental Figs. S5, S7, S9B,C), high-\nlighting again that the primary effect of\nincreasing replicate number is to increase\nthe sensitivity of these tools, converting\nfalse negatives to true positives (Fig. 1D;\nSupplemental Figs. S5, S7, S9D). Other\ntools are not so successful in this regard\nbut a detailed interpretation of the FPR\nfrom this test is complicated by the fact\nthat each tool is tested against its own\ngold standard. A more robust method\nfor probing the FPR performance of\nDGE tools is presented below.\nTool consistency with high\nreplicate data\nThe DGE tool performance tests de-\nscribed here assume that, given enough\nreplicates, the tools converge on the true\nunderlying differential expression signal\nin the data. This assumption was tested\nby clustering the DGE measurements\nfor each tool ’s “gold standard” along\nwith the results from five additional sim-\nple statistical tests applied to the same data (see Materials and\nMethods for a detailed description of the statistical tests). For\neach tool or test, a 7126-element long vector of 1s and 0s was\nconstructed representing whether each gene in the annotation\nwas called as SDE (adjustedP-value or FDR threshold≤0.05)\nby the tool or not. The vectors for each tool or test were\nB\nC\nDF\nAE\nFPR TPR\n0.00.5 0.0 0.5 1.0\nT>2\nFPR TPR\n0.00.5 0.0 0.5 1.0\nT>0.5\nFPR TPR\n0.00.51.0 0.0 0.5 1.0\nT>0\nsamSeq\nPoissonSeq\nNOISeq\nlimma\nedgeR - GLM\nedgeR - exact\nEBSeq\nDESeq2\nDESeq\nDEGseq\ncuffdiff\nbaySeq\nlog t-test\nn = 6r\nsamSeq\nPoissonSeq\nNOISeq\nlimma\nedgeR - GLM\nedgeR - exact\nEBSeq\nDESeq2\nDESeq\nDEGseq\ncuffdiff\nbaySeq\nlog t-test\nn = 12r\nsamSeq\nPoissonSeq\nNOISeq\nlimma\nedgeR - GLM\nedgeR - exact\nEBSeq\nDESeq2\nDESeq\nDEGseq\ncuffdiff\nbaySeq\nlog t-test\nn = 20r\nsamSeq\nPoissonSeq\nNOISeq\nlimma\nedgeR - GLM\nedgeR - exact\nEBSeq\nDESeq2\nDESeq\nDEGseq\ncuffdiff\nbaySeq\nlog t-test\nn = 3r\nFIGURE 2. Comparison of the true positive rate (TPR) and false positive rate (FPR) performance\nfor each of the DGE tools on low-, medium-, and highly replicated RNA-seq data (nr∈{3,6,12,20}\n—rows) for three |log2(FC)| thresholds (T∈{0,0.5,2}—columns). The TPRs and FPRs for each\ntool are calculated by comparing the mean number of true and false positives (TPs and FPs) cal-\nculated over 100 bootstrap iterations to the number of TPs and FPs calculated from the same tool\nusing the full clean data set (error bars are 1 SD). Although the TPRs and FPRs from each tool are\ncalculated by comparing each tool against itself rather than a tool-independent“gold standard”\n(albeit with the full clean data set), the results are comparable across tools except forDEGSeq\nwhich calls a significantly larger fraction of genes as DE for all values of T and nr\n(Supplemental Fig. S4). In general, the TPR increases with increasingnr (A–D) while both the\nTPR increases and the FPR decreases with increasingT (A,D,E,F). The TPR for bootstrap subse-\nlections with three replicates and no fold-change threshold is∼20%–40% for all the tools except\nNOISeq and DEGSeq (A). For the highest fold-change genes (T = 2), the tools show TPRs≳85%\nand, with the exception of cuffdiff also show FPRs consistent with zero ([E] NOISeq and\nPoissonSeq produce no FPs for the highest threshold genes and thus no FPR is shown for\nthem). ForT = 2, increasingnr provides only a modest increase in TPR (∼85% to∼95%) irre-\nspective of the tool (E and F). PoissonSeq and BaySeq show an increasing FPR with increasing\nnr (A–D), andcuffdiff unexpectedly shows an increase in FPR with increasingT. DESeq appears\nmore conservative than the other tools, consistently returning fewer FPs (particularly for high val-\nues ofnr [D and F]) and fewer TPs (particularly at low values ofnr [A and E]).\nTesting DGE tool performance on 96-reps of RNA-seq\nwww.rnajournal.org 843\n Cold Spring Harbor Laboratory Press on November 5, 2025 . Published by rnajournal.cshlp.orgDownloaded from \nordered by gene id and then hierarchically clustered by corre-\nlation distance with complete linkage (Fig. 3) using the R\npackage pvclust (Fig. 3; Suzuki and Shimodaira 2006).pvclust\nuses bootstrapping to compute the statistical significance of\nsubclusters within the dendrogram. Approximately unbiased\nP-value percentages (AU%— Fig. 3, bracketed values) calcu-\nlated for each branch in the clustering are an indication of\nhow robust each branch is to sampling error. Three widely\nused tools (DESeq2, edgeR [exact],a n dlimma, Table 1) are\ntightly grouped in a robust cluster with the standard statistical\ntests (Fig. 3, cluster 3).cuffdiff, DESeq, and EBSeq cluster\ntightly and are distinct from cluster 3 (Fig. 3, cluster 4).\nDespite the separation between these clusters being signifi-\ncant at the∼3% level, this is the weakest clustering observed\nin the tree, suggesting that these tools and tests are converging\non approximately the same answer, given a large number of\nreplicates. Several of the standard statistical tests are nonpara-\nmetric (Mann-Whitney, permutation and bootstrap) and use\nvery different underlying methods compared to the tools in\nthis cluster, indicating that the agreement of techniques with-\nin this group is not the result of a similar underlying method-\nology, but is likely reflective of the true differential expression\nsignal in the data.NOISeq, DEGSeq, baySeq, andedgeR (gen-\neralized linear model; hereafter GLM) form a distinct inde-\npendent cluster (Fig. 3, cluster 2) suggesting that these tools\nreach a considerably different result to those in Cluster 1.\nTesting tool false positive rates\nPerhaps the most important performance measure for RNA-\nseq differential expression tools is their false detection rate.\nThe large number of replicates in this study permits a simple\ntest of the FPR for each of the tools. Two sets ofn\nr replicates\nwere randomly selected (without replacement) from the WT\ncondition. Under the null hypothesis that there is no expres-\nsion change between these two sets, every gene identified as\nSDE is, by definition, a false positive. For each bootstrap\nrun, the fraction of the total gene set identified as SDE was\ncomputed. The distribution of this false positive fraction as\na function of the number of replicates, for each differential\nexpression tool, is shown in Figure 4. This approach shows\nthat DEGSeq, NOISeq, and SAMSeq perform poorly even\nwith a large number of replicates. DEGSeq, in particular,\nhas poor false positive performance with every bootstrap iter-\nation identifying >5% of all genes as false positives (FPs) and\na median FPR of∼50% irrespective of the number of repli-\ncates. Approximately 10% ofcuffdiff, PoissonSeq, and∼40%\nof SAMSeq bootstrap iterations identify >5% of all genes as\nFPs, suggesting that these tools are also not controlling their\nFPR well. BaySeq, DESeq, and EBSeq perform particularly\nwell in this test withedgeR, DESeq2, andlimma also perform-\ning adequately.\nDISCUSSION\nIn this work, the performance of eleven popular RNA-seq\nDGE tools has been evaluated using a highly replicated\ntwo-condition RNA-seq experiment designed specifically\nfor the purpose of benchmarking RNA-seq DGE tools on\ngenuine biological replicate data. Five of the 11 tools,\nEBSeq, edgeR (exact), DESeq, DESeq2, andlimma show excel-\nlent performance in the tests presented here. Reassuringly,\nedgeR and DESeq are the most widely used of the tools tested\nhere as measured by citations (Table 1), suggesting that the\nmajority of the RNA-seq DGE analyses in the literature are\nusing the most appropriate tools for the job. An additional\nimportant feature of these five tools (run in GLM mode) is\nthat they allow confounding experimental factors to be spec-\nified for DGE permitting them to be used even with challeng-\ning data sets. Where it is important to capture as many of\nthe truly SDE genes as possible but with a low number of rep-\nlicates (i.e., n ≲ 12), the data presented here suggestedgeR\n(exact) or DESeq2 in preference to the other tools due to\ntheir superior TP identification rate and well-controlled\nFDR at lower fold changes. All the tools perform well for\nexperiments with sufficient numbers of replicates to ensure\nPoissonSeq\nsamSeq\nlimma\nMann-Whitney\npermutation\nlog t-test\nt-test\nbootstrap\nDESeq2\nedgeR (exact)\ncuffdiff\nDESeq1\nEBSeq\nedgeR (GLM)\nNOISeq\nbaySeq\nDEGseq\n0.0 0.2 0.4 0.6 0.8\nDistance\n4 231\n(97)\n(96)\n(99)\n(99)\nFIGURE 3. Hierarchical clustering of eleven RNA-seq DGE tools and\nfive standard statistical tests using all of the full clean data set comprising\n42 WT and 44Δsnf2 replicates. For each tool, or test, a 7126-element\nlong vector of 1’s and 0’s was constructed representing whether each\ngene in the annotation was called as SDE (adjustedP-value or FDR\nthreshold ≤0.05) by the tool or not. The vectors for each tool and test\nwere then ordered by the gene id and hierarchically clustered by\nCorrelation distance with complete linkage using the R packagepvclust.\nApproximately unbiasedP-value percentages (bracketed values) calcu-\nlated for each branch in the clustering represent the support in the\ndata for the observed sub-tree clustering. AU% > 95% are strongly\nsupported by the data. AU% values are not shown for branch points\nwhere AU% = 100 for clarity. The outlier clustering of baySeq,\nDEGSeq, edgeR (GLM), andNOISeq suggest that these tools are clearly\ndistinct from the other tools. Combined with the tool performance data\nshown in Figure 2, this suggests that, given a large number of replicates,\nthe tools and tests in Cluster 1 are reliably and reproducibly converging\non a similar answer, and are likely to be correctly capturing the SDE sig-\nnal in the data.\nSchurch et al.\n844 RNA, Vol. 22, No. 6\n Cold Spring Harbor Laboratory Press on November 5, 2025 . Published by rnajournal.cshlp.orgDownloaded from \nthat the majority of the true SDE is already being captured\n(i.e., n ≳ 12); however, the marginally better FPR perfor-\nmance of DESeq suggests it should be the tool of choice in\nthis regime. Conversely, baySeq, cuffdiff, DEGSeq, NOISeq,\nPoissonSeq, andSAMSeq all show inferior performance in one\nor more areas. Table 2 summarizes the recommendations for\nchoosing RNA-seq DGE tools, based on\nthe results of these benchmarking tests.\nIt is clear from the benchmarking runs\nthat even the best tools have limited sta-\ntistical power with few replicates in each\ncondition, unless a stringent fold-change\nthreshold is imposed (Fig. 2). For all the\ntools the FPR is approximately constant\nregardless of fold-change threshold, sug-\ngesting that controlling the FNR rather\nthan the FPR is the primary justification\nfor imposing this limitation. The varia-\ntion intrinsic to any experimental proce-\ndures and protocols will result in a hard\nlower limit on the detectable fold changes\nfor biologically relevant DGE. Unfortu-\nnately, it is not possible to calculate this\nlimit here using the gene count data\nalone since it requires prior knowledge\nof actual fold changes to measure the im-\npact of experimental variance. DESeq2\nincludes an option to specify a fold-\nchange threshold for the null hypothesis\nbeing tested. In this mode the tool tests\nwhether the measured gene fold changes\nare consistent with being below this\nthreshold value (rather than being con-\nsistent with zero), providing a natural\nmechanism for incorporating a fold-\nchange threshold in a statistically mean-\ningful way. As expected, this reduces the\nnumber of genes called as SDE. Setting\nn\nr = 10 and running 100DESeq2 boot-\nstraps, the number of SDE genes called\nis reduced from 3470 to 1277 by includ-\ning a null hypothesis testing the fold-\nchange threshold of 0.5.\nWhen designing an RNA-seq experi-\nment with the primary goal of identifying\nthose SDE genes that change by more\nthan a factor of two (T = 1), three clean\nreplicates per condition may be sufficient.\nHowever, this is not the same as conduct-\ning the experiment with a total of three\nreplicates, because there is a significant\nminority chance that one or more repli-\ncates within each condition should be\nrejected (see Gierlin ´ski et al. 2015). Con-\nversely, for biological questions in which\nidentifying the majority of the DE genes is important, a low-\nreplicate experiment may not provide a sufficiently detailed\nview of the differential expression to inform the biology accu-\nrately. In these situations, it would be prudent to obtain at least\n12 clean replicates per condition allowing the identification\nof ≳90% of the truly SDE genes withT ≳ 0.3 by any of the\nlog t-test baySeq\nFP fraction\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.0\n0.1\n0.2\n0.3\n0.4\n0.0\n0.1\n0.2\n0.3\n0.4\n0.0\n0.1\n0.2\n0.3\n0.4\nDEseq2\nlimma PoissonSeq SAMSeq\nA\nedgeR - exact edgeR - GLM\nEBseq\nDEseqcuffdiff\n0.0\n0.1\n0.2\n0.3\n0.4\n0 5 10 15 20\nNumber of replicates\n5 1 01 52 0\nB\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nDEGSeq\n0 5 10 15 20\nNumber of replicates NOISeq\n0.0\n0.2\n0.4\n0.6\n0.8FP fraction\n5 1 01 52 0\nFIGURE 4. Testing false positive rate (FPR) performance: Each tool was used to call significantly\ndifferentially expressed (SDE) genes based on two artificial“conditions,”each constructed only\nfrom WT biological replicates. Genes identified as SDE are, by definition, false positives. The\nbox plots show the median, quartiles, and 95% data limits on the FPR for 100 bootstrap iterations\nof each of the eleven tools and the logt-test fornr = 3,4,..,20. The red line highlights a 5% FPR. (A)\ny-axis scale 0–0.5; (B) y-axis scale 0–1.0. In most cases the tools perform well for each bootstrap\niteration, with only a small number of iterations showing a FPR > 5%.DEGSeq, NOISeq, and\nSAMSeq consistently show a higher and more variable FPR, suggesting that they are struggling\nto control their FPR adequately.\nTesting DGE tool performance on 96-reps of RNA-seq\nwww.rnajournal.org 845\n Cold Spring Harbor Laboratory Press on November 5, 2025 . Published by rnajournal.cshlp.orgDownloaded from \ntools presented here. It is worth recalling that identifying a\ngene as SDE does not necessarily equate to identifying it as bio-\nlogically significant and that it is important to consider both\nthe magnitude of the measured fold change and existing bio-\nlogical knowledge alongside the statistical significance when\ninferring a biological significance for the results of DGE\nexperiments.\nThe experiment performed here is likely to be a best-case\nscenario and thus represents the upper limit in performance\nof the tools tested.S. cerevisiaeis one of the best-studied mod-\nel organisms in biology, with a genome that is relatively small\nand well understood and few genes containing more than a\nsingle exon. Furthermore, the experiment contains no tis-\nsue-specific gene expression and the variation between bio-\nlogical replicates is small. In an experiment with samples\nfrom individuals, or samples with higher biological variation,\nthe performance of all the DGE tools is likely to be worse.\nSimilarly, for experiments using an organism with a more\ncomplex transcriptome, the performance of all the DGE\ntools is likely to be worse due to the presence of multiple\ntranscript isoforms, anti-sense noncoding RNA transcrip-\ntion, and incomplete or poorly known annotations, particu-\nlarly for 5\n′ and 3′ UTRs (Schurch et al. 2014). Although the\nmajority of current DGE tools, including the 11 analyzed\nhere, rely on an existing genome annotation, the recently\npublished DGE toolderfinder (Frazee et al. 2014) examines\ndifferential expression for any region of a genome without\nannotations by analyzing differential expression at base pair\nresolution and grouping adjacent regions with similar signals.\nSuch annotation-free differential expression tools may well\nrepresent the future for differential gene expression studies\nwith RNA-seq data since they have the potential to mitigate\nTABLE 2. A summary of the recommendations of this paper\nTool recommended for:\n(# good replicates per\ncondition)d\nAgreement with other toolsa WT vs. WT FPRb Fold-change threshold (T)c ≤3 ≤12 >12\nDESeq Consistent Pass 0 - - Yes\n0.5 - Yes Yes\n2.0 Yes Yes Yes\nDESeq2 Consistent Pass 0 - - Yes\n0.5 Yes Yes Yes\n2.0 Yes Yes Yes\nEBSeq Consistent Pass 0 - - Yes\n0.5 - Yes Yes\n2.0 Yes Yes Yes\nedgeR (exact) Consistent Pass 0 - - Yes\n0.5 Yes Yes Yes\n2.0 Yes Yes Yes\nLimma Consistent Pass 0 - - Yes\n0.5 - Yes Yes\n2.0 Yes Yes Yes\ncuffdiff Consistent Fail\nBaySeq Inconsistent Pass\nedgeR (GLM) Inconsistent Pass\nDEGSeq Inconsistent Fail\nNOISeq Inconsistent Fail\nPoissonSeq Inconsistent Fail\nSAMSeq Inconsistent Fail\naFull clean replicate data set, see section“Tool Consistency with High Replicate Data” and Figure 3.\nbSee section“Testing Tool False Positive Rates” and Figure 4.\ncSee section“Differential Expression Tool Performance as a Function of Replicate Number.”\ndSee Figure 2.\nSchurch et al.\n846 RNA, Vol. 22, No. 6\n Cold Spring Harbor Laboratory Press on November 5, 2025 . Published by rnajournal.cshlp.orgDownloaded from \nthe impact of genome annotation on detection of differential\nexpression.\nTo the best of our knowledge, the experiment presented\nhere is the most highly replicated RNA-seq data set to date\nand the only one specifically designed for testing the process\nof calling differential expression. As such, it will be a useful\nresource for the bioinformatics community as a test-bed\nfor tool development, and for the wider biological science\ncommunity as the most detailed description of transcription\nin wild-type andΔsnf2 mutant S. cerevisiae.\nRecommendations for RNA-seq experiment design\nThe results of this study suggest the following should be con-\nsidered when designing an RNA-seq experiment for DGE:\nAt least six replicates per condition for all experiments.\nAt least 12 replicates per condition for experiments where\nidentifying the majority of all DE genes is important.\nFor experiments with <12 replicates per condition; useedgeR\n(exact) or DESeq2.\nFor experiments with >12 replicates per condition; use\nDESeq.\nApply a fold-change threshold appropriate to the number of\nreplicates per condition between 0.1≤ T ≤ 0.5 (see Fig. 2\nand the discussion of tool performance as a function of\nreplication).\nMATERIALS AND METHODS\nThe Δsnf2 mutant\nSaccharomyces cerevisiaeis one of the best-studied organisms in mo-\nlecular biology with a relatively small transcriptome and very limited\nalternative splicing and was chosen in order to give us the simplest\nRNA-seq data possible.SNF2 is the catalytic subunit of ATP-depen-\ndent chromatin remodeling SWI/SNF complex in yeast.SNF2 forms\npart of a transcriptional activator and mutation inSNF2 brings\nabout significant changes in transcription (e.g., Neigeborn and\nCarlson 1984; Stern et al. 1984; Peterson et al. 1991; Hirschhorn\net al. 1992; Peterson and Herskowitz 1992; Holstege et al. 1998;\nSudarsanam et al. 2000; Becker and Horz 2002; Gkikopoulos et al.\n2011; Ryan and Owen-Hughes 2011, and references therein).\nS. cerevisiaegrowth conditions and RNA extraction\nThe S. cerevisiae strains used in the experiment were wild type\n(BY4741 strain, WT) andΔsnf2 mutant in the same genetic back-\nground. Asynchronous WT andΔsnf2 mutant strains were streaked\nout on rich media (YPAD) to get individual colonies. For 48 repli-\ncates in both strains, single colonies were inoculated to 15 mL cul-\ntures and cells were grown to an OD600 of 0.7–0.8 (corresponding\nto approximately 10\n6 cells) at 30°C. RNA was isolated using the hot-\nphenol method (Kohrer and Domdey 1991) and cleaned up using\nthe RNeasy mini kit (Qiagen) protocol that uses Zymolyase for yeast\ncell lysis and DNase treatment to remove DNA contamination. The\namount of total RNA extracted ranged from 30.3 to 126.9 µg per\nsample. Although the amount of RNA extracted was variable, the\ndistributions were consistent with being drawn from the same pop-\nulation (Kolmogorov–Smirnov test,P = 0.16) indicating no bias in\nRNA content between WT andΔsnf2 mutant samples.\nLibrary preparation, spike-in addition, and sequencing\nThe RNA-seq experiment described here implements a“balanced\nblock design”in order to control for technical artifacts such as library\nbatch effects (Kaisers et al. 2014), barcoding biases, and lane effects\nvia randomization of the libraries (Colbourn and Dinitz 2007; Auer\nand Doerge 2010). Additionally, all the replicates include artificial\nRNA spike-in controls in order to allow external calibration of the\nRNA concentrations in each sample and of the measured fold changes\nbetween the two conditions (Jiang et al. 2011; Loven et al. 2012). The\n96 samples were prepared in batches of 24 samples with 12 of each\nstrain in each batch. Barcodes were preassigned randomly between\nthe samples with barcode IDs 1–48 assigned to theΔsnf2 mutant sam-\nples and 49–96 to the WT strain. For each batch the Illumina TruSeq\nprotocol was used to prepare the sequencing library, with the addition\nof the ERCC spike-in standard (Ambion) (Jiang et al. 2011). Briefly,\nsamples were poly(A) enriched with poly(dT) beads and 1 µL of 1:100\nspike-in added to 19.5 µL of poly(A) enriched samples. Spike-in mix 1\nwas used with theΔsnf2 mutant and mix 2 with WT. The RNA was\nthen fragmented and subsequently underwent both first and second\nstrand cDNA synthesis. The cDNA was then subjected to end repair,\n3\n′ end adenylation, and barcode sequences were added. Finally, the\nun-barcoded adapters were ligated, templates purified and finally\nthe samples were enriched via barcode-specific PCR primers. At\nthis point the quality of the libraries was examined and passed before\nbeing diluted down to 10 nM and quantified (using fluorescence-\nbased quantification) for accurate aliquoting for cluster generation\nand appropriate lane loading. Seven independent pools of the 96 bar-\ncoded samples were prepared and loaded onto seven lanes of an\nIllumina HiSeq 2000. Thus, each lane contains all 96 samples pre-\npared in four batches with different spike-in mixes in each strain.\nThe flow-cell was run for 51 cycles single-end.\nRead alignment and read-count-per-gene\nmeasurement\nThe lane data were demultiplexed and processed through Cassava\npipeline v1.8 to generate 672 fastq files comprising seven technical\nreplicates for each of the 96 biological replicates in the experiment.\nA total of∼10\n9 reads were reported with each technical replicate\nhaving between 0.8 and 2.8 × 106 reads. Aggregating the technical\nreplicates across lanes results in∼107 reads per biological replicate.\nFirst pass quality control of the reads was performed withfastQC\n(http://www.bioinformatics.bbsrc.ac.uk/projects/fastqc) for each\ntechnical replicate. The reads from each technical replicate were\nthen aligned to the Ensembl release 68 (Flicek et al. 2011)S. cerevi-\nsiae genome with bowtie2 (v2.0.0-beta7) (Trapnell and Salzberg\n2009) andTopHat2 (v2.0.5) (Trapnell et al. 2009) using the follow-\ning parameters: –max-intron-length 1000 –min-intron-length 10 –\nmicroexon-search –b2-very-sensitive –max-multihits 1. The aligned\nreads were then aggregated with htseq-count (v0.5.3p9, Anders\net al. 2015) using the Ensembl v68S. cerevisiaegenome annotation\nto give total gene read counts for all 7126 gene features for each tech-\nnical replicate. Finally, the read-count-per-gene measurements for\nTesting DGE tool performance on 96-reps of RNA-seq\nwww.rnajournal.org 847\n Cold Spring Harbor Laboratory Press on November 5, 2025 . Published by rnajournal.cshlp.orgDownloaded from \neach technical replicate were summed across sequencing lanes to\ngive read-count-per-gene for each of the 96 biological replicates,\nand these were then used to identify poorly correlating“bad”repli-\ncates within the two conditions that were then subsequently re-\nmoved from the analysis (see Gierlin ´ski et al. 2015 for a detailed\ndescription of this process). This resulted in a total of 42 WT and\n44 Δsnf2 biological replicates of“clean”read-count-per-gene data.\nTool details and considerations for differential\nexpression calculations\nMost of the DGE tools assessed here calculate both a fold change\n(typically expressed as a logarithm to base 2 of the expression ratio,\nlog\n2FC) and a statistical significance of differential expression for\neach gene. The fold change is based on the mean count across rep-\nlicates in each condition, and for many of the tools this includes\na calculation of sample-specific normalization factors based on\nthe gene read-count data. For this study, the default normalization\nfactors were used for each of the tools assessed. While there are\ndifferences between the normalizations used by these tools, it has\nbeen suggested that the details of which method is used to nor-\nmalize the data does not significantly alter the downstream DGE\nresults (Seyednasrollah et al. 2013). These normalization methods\ndo, however, rely on the assumption that the majority of genes\ndo not change their expression levels between conditions (e.g.,\nDillies et al. 2013). If this assumption is not satisfied, the measure-\nments of both DGE fold change and significance are likely to be\nincorrect.\nThe statistical significances calculated by DGE tools are usually\nbased on the null hypothesis of no expression change between the\nconditions. Calculating this significance typically relies on two key\nfactors: (i) an assumption about the probability distribution that un-\nderlies the raw read-count measurements, and (ii) being able to\naccurately measure the mean count and variance for each gene.\nDifferent tools assume different forms for the underlying read-count\ndistribution including the negative binomial ( baySeq, Cuffdiff,\nDESeq, DESeq2, EBSeq, and edgeR), beta-binomial (BBSeq), bino-\nmial (DEGSeq), Poisson (PoissonSeq), and log-normal (limma) dis-\ntributions. A few algorithms make no assumptions about the\nread-count distribution and instead take nonparametric approaches\nto testing for DGE (NOISeq and SAMSeq). Gierlin ´ski et al. (2015)\nshow that for this data the majority of gene expression is consistent\nwith both log-normal and negative binomial distributions except\nfor the lowest expression genes, for which only the negative binomial\ndistribution remains consistent with the data. For experiments with\nhigh numbers of replicates per condition (n ≳ 12), the mean and var-\niance estimators can be accurately computed directly on the data.\nHowever, many RNA-seq DGE studies rely on a low number of rep-\nlicates per condition (n ≲ 3), so several of the DGE tools (e.g.,DESeq,\nDESeq2, edgeR, limma) compensate for the lack of replication by\nmodeling the mean-variance relation and borrowing information\nacross genes to shrink the given gene’s variance toward the common\nmodel (Cui et al. 2005; De Hertogh et al. 2010; Robinson et al. 2010).\nThe stabilized variance helps avoid some of the spurious false posi-\ntives and negatives, but is strongly dependent on an assumed read\ncount distribution and on the assumptions intrinsic to the normali-\nzation of the count data, namely that the large majority of the gene\ncounts are not truly differentially expressed. For a full description\nof the measured individual gene read count distributions in these\ndata, a comparison of these with the assumptions made by DGE tools,\nand the impact this has on the DGE results, see Gierlin ´ski et al. (2015).\nGiven these methods’dependence on accurate mean and variance\nmeasurements, it is somewhat surprising that scientists would con-\ntemplate doing DGE analysis without replicated data, but for com-\npleteness we note that several DGE analysis tools advertise that\nthey can work with a single replicate per condition (Anders and\nHuber 2010; Robinson et al. 2010; Tarazona et al. 2011).\nBootstrap differential expression calculations\nA utility pipeline was written to automate the process of running each\nDGE algorithm iteratively oni repeated subselections of clean repli-\ncates. Each subselection is comprised ofn\nr replicates chosen at ran-\ndom without replacement (that is, an individual replicate can appear\nonly once within each subselection). This bootstrapping procedure\nincludes applying the default normalization for each tool where\nrelevant and possible (see section“Tool Details and Considerations\nfor Differential Expression Calculations”) and the full output for\neach tool was stored in a localsqlite database, including the log\n2 trans-\nformed fold change and the statistical significance for every expressed\ngene in the S. cerevisiae annotation. Most of the tools return\nBenjamini–Hochberg (hereafter BH; Benjamini and Hochberg\n1995) corrected P-values or FDRs as their measure of statistical\nsignificance. Genes with an adjustedP-value or FDR≤ 0.05 were\nmarked as “significantly differentially expressed” (SDE). Supple-\nmental Figure S1 shows an example of the output mean log\n2FC\nand median P-value data for the tooledgeR (exact) with nr =3 .\nFrom these data, TPRs, TNRs, FPRs, and FNRs for each tool were\ncomputed as a function of the number of replicates,nr, for four ar-\nbitrary absolute log2 fold-change thresholds, T∈{0,0.3,1,2}. A refer-\nence fold change was used for deciding whether each gene falls above\nthe thresholdT because the measured values of mean|log\n2FC| cal-\nculated for a gene varies considerably with both the tool being used\nand n\nr. These reference fold changes were defined independently of\nthe tools by applying DESeq normalization (Anders and Huber\n2010) to the read-count-per-gene data from the full clean set of bi-\nological replicates for each condition and then taking the log\n2 trans-\nformed ratio of the mean normalized read-count-per-gene for each\ncondition. For each individual DGE calculation within a bootstrap\nrun (i.e., an individual differential expression calculation with a spe-\ncific tool with a givenn\nr), each gene was called as true/false positive/\nnegative by comparing whether it was called as SDE in the bootstrap\nrun, and whether it was called as SDE in the corresponding tool-\nspecific “gold standard.” Then, taking each fold-change threshold\nin turn, the mean of the number of true/false positives/negatives\n(TP, TN, FP, FN) for genes with reference fold changes above this\nthreshold was calculated across all the individual DGE calculations\nwithin a bootstrap run. This results in a TPR, TNR, FPR, and\nFNR for a tool, for a givenn\nr and for a givenT (Equations 1–4):\nTPR(nr, T)= TP(nr, T)\nTP(nr , T)+ FN(nr, T) (1)\nFPR(nr , T)= FP(nr , T)\nFP(nr, T)+ TN(nr , T) (2)\nTNR(nr, T)= TN(nr, T)\nTN(nr, T)+ FP(nr, T) (3)\nFNR(nr , T)= FN(nr, T)\nFN(nr , T)+ TP(nr , T) (4)\nSchurch et al.\n848 RNA, Vol. 22, No. 6\n Cold Spring Harbor Laboratory Press on November 5, 2025 . Published by rnajournal.cshlp.orgDownloaded from \nUncertainties in the resulting values were calculated by propagat-\ning the standard deviations of the numbers of TPs, TNs, FPs, and\nFNs across the calculations within each bootstrap run, to reflect\nthe spread of calculated values due to the random sampling of\nreplicates.\nStandard statistical tests for differential expression\nWhen assessing the performance of each DGE tool on the full set of\nclean data, we compare the tools not only within themselves, but\nalso to the following set of standard statistical tests. For the following\nmathematical descriptions,x\ngk =( xg1k, xg2k, ... , xgnkk) is a vector\nof nk (clean) replicates for geneg and conditionk, /overbarxgk and s2\ngkare the\nmean and variance of this vector.\nt-test\nThe null hypothesis in thet-test is that the given gene under two\nconditions has the same mean count,H0 :µ g1 =µ g2. We used the\ntest statistic\ntg = /overbarxg1 − /overbarxg2/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129 /NameMe.129\ns2\ng12\n1\nn1\n+ 1\nn2\n()√ (5)\nwith common variance estimators2\ng12 = [(n1 − 1)s2\ng1\n+( n2 − 1)s2\ng2\n]/n,\nand the number of degrees of freedom isv = n1 + n2 − 2.\nLog-ratio t-test\nThis modifiedt-test is more appropriate for log-normally distribu-\nted data. The null hypothesis is lnµg1 = lnµg2. The test statistic,\ntg = ln /overbarxg1 − ln /overbarxg2/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129 /NameMe.129\ns2\ng1\nn1/overbarx2\ng1\n+\ns2\ng2\nn2/overbarx2\ng2\n√ , (6)\nis approximately distributed with t-distribution with n1 + n2 − 2\ndegrees of freedom (see Olsson 2005).\nMann-Whitney test\nThe Mann-Whitney (Mann and Whitney 1947— hereafter MW) test\nis a nonparametric test assessing if count rate in a gene under one\ncondition tends to be larger than under the other. The null hypoth-\nesis isH\n0 : Pr(xgi1 . xgj2)= 1/2, for each pair of replicatesi and j.\nP-values were calculated using normal approximation (Bellera\net al. 2010) and taking ties into account (Sheskin 2004). The MW\ntest relies on ranks, not actual data values, which makes it distribu-\ntion-free. On the other hand, when every replicate in one condition\nis larger than every replicate in the other condition, the MW test will\nreturn the sameP-value, regardless of how much the two conditions\ndiffer.\nPermutation test\nIn the permutation test, counts from both conditions are pooled to-\ngether (for each gene),x\ng =( xg1,xg2) and then randomly resampledB\ntimes without replacement fromxg, using the original sizes,n1 and\nn2. For theb-th random permutationx∗\ng1(b) and x∗\ng2\n(b) we find the\ntest statistic, D∗\ng\n(b)= /overbarx∗\ng1\n(b)− /overbarx∗\ng2\n(b), which is the difference be-\ntween the means of the two sampled vectors. This is compared\nwith the observed statisticDg = /overbarxg1 − /overbarxg2. The testP-value is the\nfraction of cases where the resampled statistic exceeds the observed\none, pg = #{|D∗\ng (b)| . |Dg |}/B (for more details, see Efron and\nTibshirani 1993a). The advantage of the permutation test is that it\ndoes not make any assumptions about the underlying distribution,\nbut rather models it directly from data. The disadvantage is that it\nrequires many replicates to build this underlying distribution, as it\nis not applicable for a typical experiment with, say, three replicates.\nBootstrap test\nThe Studentized bootstrap test described by Efron and Tibshirani\n(1993b) was used here. It estimates probability distribution of the\ntwo populations with sample sizesn\n1 and n2, under the null hypoth-\nesis of the common mean. Data are resampled with replacement to\nestimate the significance level. For theb\nth bootstrap, x∗\ng1(b) and\nx∗\ng2\n(b), the test statistic is\nt∗\ng (b)=\n/overbarx∗\ng1\n(b)− /overbarx∗\ng2\n(b)\n/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129/NameMe.129 /NameMe.129\ns∗2\ng12(b) 1\nn1\n+ 1\nn2\n()√ , b = 1, 2,... B, (7)\nwhere the common variance estimator is\ns∗2\ng12(b)= [(n1 − 1)s∗2\ng1(b)+ (n2 − 1)s∗2\ng2(b)]/(n1 + n2 − 2). This is\ncompared with the observed statistic (Equation 5). As in the permu-\ntation test, the testP-value is the fraction of cases where the resam-\npled statistic exceeds the observed one,p\ng = #{|t∗\ng (b)| . |tg |}/B.\nDATA DEPOSITION\nThe data sets supporting the results of this article are available in\nthe European Nucleotide Archive repository (ENA) (PRJEB5348,\nhttp:// www.ebi.ac.uk/ena/data/view/ERX425102). All the code for\nthis work is publicly available (https://github.com/bartongroup/\nprofDGE48).\nSUPPLEMENTAL MATERIAL\nSupplemental material is available for this article.\nACKNOWLEDGMENTS\nWe acknowledge Dr. Tom Walsh for his efforts and support in\nmanaging the software requirements for this project on our HPC\nplatform. We would like to thank Dr. Gabriele Schweikert for stim-\nulating discussions and Dr. Mike Love for his assistance in identify-\ning and correcting a bug in our software that affected the original\nDESeq2 and DEGSeq results. We acknowledge funding from the\nWellcome Trust (095062; 098439/Z/12; 92530/Z/10/Z; WT097945;\nWT092340; WT083481), the Medical Research Council (MR/\nK001744/1), and the Biotechnology and Biological Sciences\nResearch Council (BB/M004155/1; BB/H002286/1).\nAuthor contributions: N.S. participated in the conception and de-\nsign of the experiment, the DGE analysis and statistical analysis of\nthe data, and writing the manuscript. P.S. participated in the con-\nception and design of the experiment and in the DGE analysis\nand statistical analysis of the data. M.G. participated in the concep-\ntion and design of the experiment, the DGE analysis and statistical\nanalysis of the data, and in drafting the manuscript. C.C. participat-\ned in the conception and design of the experiment, the DGE analysis\nTesting DGE tool performance on 96-reps of RNA-seq\nwww.rnajournal.org 849\n Cold Spring Harbor Laboratory Press on November 5, 2025 . Published by rnajournal.cshlp.orgDownloaded from \nand statistical analysis of the data, and in drafting the manuscript. A.\nS. participated in the DGE analysis of the data. V.S. grew the yeast\nsamples and extracted the RNA for sequencing. N.W. participated\nin the QC and sequencing of the RNA samples and in incorporating\nthe ERCC spike-ins with the samples. K.G. participated in the design\nof the experiment, the QC and sequencing of the RNA samples, and\nwith incorporating the ERCC spike-ins with the samples. G.S. par-\nticipated in the design of the experiment and in drafting the manu-\nscript. T.O.H. participated in the experimental design and in\ndrafting the manuscript. M.B. participated in the design of the ex-\nperiment and in the sequencing of the RNA samples. G.J.B. partic-\nipated in the design of the experiment, in the DGE analysis and\nstatistical analysis of the data, and in writing the manuscript.\nReceived August 13, 2015; accepted February 17, 2016.\nREFERENCES\nAnders S, Huber W. 2010. Differential expression analysis for sequence\ncount data.Genome Biol11: R106.\nAnders S, Pyl PT, Huber W. 2015. HTSeq–a Python framework to work\nwith high-throughput sequencing data.Bioinformatics 31: 166–169.\nAuer PL, Doerge RW. 2010. Statistical design and analysis of RNA se-\nquencing data.Genetics 185: 405–416.\nBecker PB, Horz W. 2002. ATP-dependent nucleosome remodeling.\nAnnu Rev Biochem71: 247–273.\nBellera CA, Julien M, Hanley JA. 2010. Normal approximations to the\ndistributions of the Wilcoxon statistics: accurate to what N?\nGraphical insights.J Stat Educ18.\nBenjamini Y, Hochberg Y. 1995. Controlling the false discovery rate: a\npractical and powerful approach to multiple testing.J R Stat Soc B\n(Methodol) 57: 289–300.\nBottomly D, Walter NA, Hunter JE, Darakjian P, Kawane S, Buck KJ,\nSearles RP, Mooney M, McWeeney SK, Hitzemann R. 2011.\nEvaluating gene expression in C57BL/6J and DBA/2J mouse striatum\nusing RNA-Seq and microarrays.PLoS One6: e17820.\nBullard JH, Purdom E, Hansen KD, Dudoit S. 2010. Evaluation of stat-\nistical methods for normalization and differential expression in\nmRNA-Seq experiments.BMC Bioinformatics11: 94.\nBurden C, Qureshi S, Wilson SR. 2014. Error estimates for the analysis\nof differential expression from RNA-seq count data.PeerJ 2: e576.\nBusby MA, Stewart C, Miller CA, Grzeda KR, Marth GT. 2013. Scotty: a\nweb tool for designing RNA-Seq experiments to measure differential\ngene expression.Bioinformatics 29: 656–657.\nThe Cancer Genome Atlas Research Network. 2008. Comprehensive ge-\nnomic characterization defines human glioblastoma genes and core\npathways. Nature 455: 1061–1068.\nCheung VG, Nayak RR, Wang IX, Elwyn S, Cousins SM, Morley M,\nSpielman RS. 2010. Polymorphic cis- and trans-regulation of human\ngene expression.PLoS Biol8.\nChurchill GA. 2002. Fundamentals of experimental design for cDNA\nmicroarrays. Nat Genet32: 490–495.\nColbourn CJ, Dinitz JH. 2007. Handbook of combinatorial designs.\nChapman and Hall/Taylor and Francis, Boca Raton, FL.\nCui X, Hwang JT, Qiu J, Blades NJ, Churchill GA. 2005. Improved stat-\nistical tests for differential gene expression by shrinking variance\ncomponents estimates.Biostatistics 6: 59–75.\nDe Hertogh B, De Meulder B, Berger F, Pierre M, Bareke E,\nGaigneaux A, Depiereux E. 2010. A benchmark for statistical micro-\narra\ny data analysis that preserves actual biological and technical var-\niance. BMC Bioinformatics11: 17.\nDillies MA, Rau A, Aubert J, Hennequet-Antier C, Jeanmougin M,\nServant N, Keime C, Marot G, Castel D, Estelle J, et al. 2013. A com-\nprehensive evaluation of normalization methods for Illumina high-\nthroughput RNA sequencing data analysis. Brief Bioinform 14:\n671–683.\nEfron B, Tibshirani R. 1993a.An introduction to the bootstrap, pp. 203–\n219. Chapman and Hall, New York.\nEfron B, Tibshirani R. 1993b.An introduction to the bootstrap, pp. 220–\n224. Chapman and Hall, New York.\nFlicek P, Amode MR, Barrell D, Beal K, Brent S, Chen Y, Clapham P,\nCoates G, Fairley S, Fitzgerald S, et al. 2011. Ensembl 2011.\nNucleic Acids Res39: D800–D806.\nFrazee AC, Langmead B, Leek JT. 2011. ReCount: a multi-experiment\nresource of analysis-ready RNA-seq gene count datasets. BMC\nBioinformatics 12: 449.\nFrazee AC, Sabunciyan S, Hansen KD, Irizarry RA, Leek JT. 2014.\nDifferential expression analysis of RNA-seq data at single-base reso-\nlution. Biostatistics 15: 413–426.\nGierlin ´ ski M, Blaxter M, Cole C, Gharbi K, Owen-Hughes T,\nSchofield P, Schurch NJ, Sherstnev A, Singh V, Wrobel N, et al.\n2015. Statistical models for RNA-seq data derived from a two-con-\ndition 48-replicate experiment.Bioinformatics 31: 3625–3630.\nGkikopoulos T, Schofield P, Singh V, Pinskaya M, Mellor J, Smolle M,\nWorkman JL, Barton GJ, Owen-Hughes T. 2011. A role for Snf2-re-\nlated nucleosome-spacing enzymes in genome-wide nucleosome or-\nganization. Science 333: 1758–1760.\nGuo Y, Li CI, Ye F, Shyr Y. 2013. Evaluation of read count based RNAseq\nanalysis methods.BMC Genomics14: S2.\nHansen KD, Wu Z, Irizarry RA, Leek JT. 2011. Sequencing technology\ndoes not eliminate biological variability.Nat Biotechnol29: 572–573.\nHardcastle TJ, Kelly KA. 2010. baySeq: empirical Bayesian methods for\nidentifying differential expression in sequence count data. BMC\nBioinformatics 11: 422.\nHirschhorn JN, Brown SA, Clark CD, Winston F. 1992. Evidence that\nSNF2/SWI2 and SNF5 activate transcription in yeast by altering\nchromatin structure.Genes Dev6: 2288–2298.\nHolstege FC, Jennings EG, Wyrick JJ, Lee TI, Hengartner CJ, Green MR,\nGolub TR, Lander ES, Young RA. 1998. Dissecting the regulatory\ncircuitry of a eukaryotic genome.Cell 95: 717–728.\nThe International HapMap Consortium. 2005. A haplotype map of the\nhuman genome.Nature 437: 1299–1320.\nJiang\nL, Schlesinger F, Davis CA, Zhang Y, Li R, Salit M, Gingeras TR,\nOliver B. 2011. Synthetic spike-in standards for RNA-seq experi-\nments. Genome Res21: 1543–1551.\nKaisers W, Schwender H, Schaal H. 2014. Hierarchical clustering of\nDNA k-mer counts in RNA-seq fastq files reveals batch effects.\narXiv doi: 1405.0114.\nKohrer K, Domdey H. 1991. Preparation of high molecular weight RNA.\nMethods Enzymol194: 398–405.\nKvam VM, Liu P, Si Y. 2012. A comparison of statistical methods for de-\ntecting differentially expressed genes from RNA-seq data.Am J Bot\n99: 248–256.\nLaw CW, Chen Y, Shi W, Smyth GK. 2014. Voom: precision weights un-\nlock linear model analysis tools for RNA-seq read counts.Genome\nBiol 15: R29.\nLeng N, Dawson JA, Thomson JA, Ruotti V, Rissman AI, Smits BM,\nHaag JD, Gould MN, Stewart RM, Kendziorski C. 2013. EBSeq: an\nempirical Bayes hierarchical model for inference in RNA-seq exper-\niments. Bioinformatics 29: 1035–1043.\nLi J, Tibshirani R. 2013. Finding consistent patterns: a nonparametric\napproach for identifying differential expression in RNA-Seq data.\nStat Methods Med Res22: 519–536.\nLi J, Witten DM, Johnstone IM, Tibshirani R. 2012. Normalization, test-\ning, and false discovery rate estimation for RNA-sequencing data.\nBiostatistics 13: 523–538.\nLiu Y, Zhou J, White KP. 2014. RNA-seq differential expression stud-\nies: more sequence or more replication? Bioinformatics 30:\n301–304.\nLove MI, Huber W, Anders S. 2014. Moderated estimation of fold\nchange and dispersion for RNA-seq data with DESeq2. Genome\nBiol 15: 550.\nLoven J, Orlando DA, Sigova AA, Lin CY, Rahl PB, Burge CB,\nLevens DL, Lee TI, Young RA. 2012. Revisiting global gene expres-\nsion analysis.Cell 151: 476–482.\nSchurch et al.\n850 RNA, Vol. 22, No. 6\n Cold Spring Harbor Laboratory Press on November 5, 2025 . Published by rnajournal.cshlp.orgDownloaded from \nLund SP, Nettleton D, McCarthy DJ, Smyth GK. 2012. Detecting differ-\nential expression in RNA-sequence data using quasi-likelihood with\nshrunken dispersion estimates. Stat Appl Genet Mol Biol 11 doi:\n10.1515/1544-6115.1826.\nMann HB, Whitney DR. 1947. On a test of whether one of two random\nvariables is stochastically larger than the other.Ann Math Stat18:\n50–60.\nMarioni JC, Mason CE, Mane SM, Stephens M, Gilad Y. 2008. RNA-seq:\nan assessment of technical reproducibility and comparison with gene\nexpression arrays.Genome Res18: 1509–1517.\nMontgomery SB, Sammeth M, Gutierrez-Arcelus M, Lach RP, Ingle C,\nNisbett J, Guigo R, Dermitzakis ET. 2010. Transcriptome genetics\nusing second generation sequencing in a Caucasian population.\nNature 464: 773–777.\nMoulos P, Hatzis P. 2015. Systematic integration of RNA-Seq statistical\nalgorithms for accurate detection of differential gene expression pat-\nterns. Nucleic Acids Res43: e25.\nNeigeborn L, Carlson M. 1984. Genes affecting the regulation of SUC2\ngene expression by glucose repression inSaccharomyces cerevisiae.\nGenetics 108: 845–858.\nOlsson U. 2005. Confidence intervals for the mean of log-normal distri-\nbution. J Stat Educ13.\nPan W, Lin J, Le CT. 2002. How many replicates of arrays are required to\ndetect gene expression changes in microarray experiments? A mix-\nture model approach.Genome Biol3: research0022.\nPeterson CL, Herskowitz I. 1992. Characterization of the yeast SWI1,\nSWI2, and SWI3 genes, which encode a global activator of transcrip-\ntion. Cell 68: 573–583.\nPeterson CL, Kruger W, Herskowitz I. 1991. A functional interaction be-\ntween the C-terminal domain of RNA polymerase II and the negative\nregulator SIN1.Cell 64: 1135–1143.\nPickrell JK, Marioni JC, Pai AA, Degner JF, Engelhardt BE, Nkadori\nE, Veyrieras JB, Stephens M, Gilad Y, Pritchard JK. 2010.\nUnderstanding mechanisms underlying human gene expression var-\niation with RNA sequencing.Nature 464: 768–772.\nRapaport F, Khanin R, Liang Y, Pirun M, Krek A, Zumbo P, Mason CE,\nSocci ND, Betel D. 2013. Comprehensive evaluation of differential\ngene expression analysis methods for RNA-seq data.Genome Biol\n14: R95.\nRobinson MD, Oshlack A. 2010. A scaling normalization method for\ndifferential expression analysis of RNA-seq data.Genome Biol 11:\nR25.\nRobinson MD, McCarthy DJ, Smyth GK. 2010. edgeR: a Bioconductor\npackage for differential expression analysis of digital gene expression\ndata. Bioinformatics 26: 139–140.\nRyan DP, Owen-Hughes T. 2011. Snf2-family proteins: chromatin\nremodellers for any occasion.Curr Opin Chem Biol15: 649–656.\nSchurc\nh NJ, Cole C, Sherstnev A, Song J, Duc C, Storey KG,\nMcLean WH, Brown SJ, Simpson GG, Barton GJ. 2014. Improved\nannotation of 3\n′ untranslated regions and complex loci by combina-\ntion of strand-specific direct RNA sequencing, RNA-Seq and ESTs.\nPLoS One9: e94270.\nSEQC/MAQC-III Consortium. 2014. A comprehensive assessment\nof RNA-seq accuracy, reproducibility and information content by\nthe Sequencing Quality Control Consortium. Nat Biotechnol 32:\n903–914.\nSeyednasrollah F, Laiho A, Elo LL. 2013. Comparison of software pack-\nages for detecting differential expression in RNA-seq studies.Brief\nBioinform 16: 59–70.\nSheskin D. 2004. Handbook of parametric and nonparametric statistical\nprocedures, 3rd ed., pp. 428–431. Chapman and Hall/CRC, Boca\nRaton, FL.\nSoneson C. 2014. compcodeR—an R package for benchmarking differ-\nential expression methods for RNA-seq data. Bioinformatics 30:\n2517–2518.\nSoneson C, Delorenzi M. 2013. A comparison of methods for dif-\nferential expression analysis of RNA-seq data.BMC Bioinformatics\n14: 91.\nStern M, Jensen R, Herskowitz I. 1984. Five SWI genes are required for\nexpression of the HO gene in yeast.J Mol Biol178: 853–868.\nSudarsanam P, Iyer VR, Brown PO, Winston F. 2000. Whole-genome\nexpression analysis of snf/swi mutants ofSaccharomyces cerevisiae.\nProc Natl Acad Sci97: 3364–3369.\nSuzuki R, Shimodaira H. 2006. Pvclust: an R package for assessing\nthe uncertainty in hierarchical clustering.Bioinformatics 22: 1540–\n1542.\nTarazona S, Garcia-Alcalde F, Dopazo J, Ferrer A, Conesa A. 2011.\nDifferential expression in RNA-seq: a matter of depth.Genome Res\n21: 2213–2223.\nTrapnell C, Salzberg SL. 2009. How to map billions of short reads onto\ngenomes. Nat Biotechnol27: 455–457.\nTrapnell C, Pachter L, Salzberg SL. 2009. TopHat: discovering splice\njunctions with RNA-Seq.Bioinformatics 25: 1105–1111.\nTrapnell C, Roberts A, Goff L, Pertea G, Kim D, Kelley DR, Pimentel H,\nSalzberg SL, Rinn JL, Pachter L. 2012. Differential gene and tran-\nscript expression analysis of RNA-seq experiments with TopHat\nand Cufflinks.Nat Protoc7: 562–578.\nWang ET, Sandberg R, Luo S, Khrebtukova I, Zhang L, Mayr C,\nKingsmore SF, Schroth GP, Burge CB. 2008. Alternative isoform\nregulation in human tissue transcriptomes. Nature 456: 470–\n476.\nWang L, Feng Z, Wang X, Wang X, Zhang X. 2010. DEGseq: an R pack-\nage for identifying differentially expressed genes from RNA-seq data.\nBioinformatics 26: 136–138.\nTesting DGE tool performance on 96-reps of RNA-seq\nwww.rnajournal.org 851\n Cold Spring Harbor Laboratory Press on November 5, 2025 . Published by rnajournal.cshlp.orgDownloaded from \nErratum: How many biological replicates are needed in an RNA-seq experiment and which\ndifferential expression tool should you use?\nNICHOLAS J. SCHURCH, PIETÀ SCHOFIELD, MAREK GIERLIŃ SKI, CHRISTIAN COLE, ALEXANDER SHERSTNEV,\nVIJENDER SINGH, NICOLA WROBEL, KARIM GHARBI, GORDON G. SIMPSON, TOM OWEN-HUGHES,\nMARK BLAXTER, and GEOFFREY J. BARTON\nRNA 22: 839–851 (2016)\nIn the above-noted article, the following information should have been included in the Acknowledgments section:\n“We acknowledge funding from the Wellcome Trust (095062; 098439/Z/12; 92530/Z/10/Z; WT097945; WT092340;\nWT083481), the Medical Research Council (MR/K001744/1), and the Biotechnology and Biological Sciences Research\nCouncil (BB/M004155/1; BB/H002286/1).”\nThis article has been corrected in both the PDF and full-text HTML files online.\ndoi: 10.1261/rna.058339.116\nRNA 22:1641; Published by Cold Spring Harbor Laboratory Press for the RNA Society 1641\nERRATUM\n 10.1261/rna.053959.115Access the most recent version at doi:\n 2016 22: 839-851 originally published online March 28, 2016RNA\n  \nNicholas J. Schurch, Pietá Schofield, Marek Gierlinski, et al. \n  \nand which differential expression tool should you use?\nHow many biological replicates are needed in an RNA-seq experiment\n  \nMaterial\nSupplemental\n  \n http://rnajournal.cshlp.org/content/suppl/2016/03/28/rna.053959.115.DC1\n  \nReferences\n  \n http://rnajournal.cshlp.org/content/22/6/839.full.html#ref-list-1\nThis article cites 63 articles, 9 of which can be accessed free at:\n  \nOpen Access\n  \n Open Access option.RNAFreely available online through the \n  \nLicense\nCommons \nCreative\n.http://creativecommons.org/licenses/by/4.0/\n(Attribution 4.0 International), as described at \n, is available under a Creative Commons LicenseRNAThis article, published in \nService\nEmail Alerting\n  \n click here.top right corner of the article or \nReceive free email alerts when new articles cite this article - sign up in the box at the\n http://rnajournal.cshlp.org/subscriptions\n go to: RNATo subscribe to \n© 2016 Schurch et al.; Published by Cold Spring Harbor Laboratory Press for the RNA Society\n Cold Spring Harbor Laboratory Press on November 5, 2025 . Published by rnajournal.cshlp.orgDownloaded from ",
  "topic": "Biology",
  "concepts": [
    {
      "name": "Biology",
      "score": 0.8292770385742188
    },
    {
      "name": "Fold change",
      "score": 0.6863242387771606
    },
    {
      "name": "RNA-Seq",
      "score": 0.6579203605651855
    },
    {
      "name": "False positive paradox",
      "score": 0.5963934063911438
    },
    {
      "name": "Computational biology",
      "score": 0.5633392333984375
    },
    {
      "name": "Gene",
      "score": 0.5394002795219421
    },
    {
      "name": "RNA",
      "score": 0.5084820985794067
    },
    {
      "name": "Gene expression",
      "score": 0.5082480311393738
    },
    {
      "name": "Gene expression profiling",
      "score": 0.48884981870651245
    },
    {
      "name": "Replication (statistics)",
      "score": 0.46893003582954407
    },
    {
      "name": "False discovery rate",
      "score": 0.4558001160621643
    },
    {
      "name": "Genetics",
      "score": 0.37568747997283936
    },
    {
      "name": "Bioinformatics",
      "score": 0.3273813724517822
    },
    {
      "name": "Transcriptome",
      "score": 0.21436455845832825
    },
    {
      "name": "Statistics",
      "score": 0.16157746315002441
    },
    {
      "name": "Mathematics",
      "score": 0.09671863913536072
    },
    {
      "name": "Virology",
      "score": 0.0
    }
  ]
}