{
    "title": "Deductively coding psychosocial autopsy interview data using a few-shot learning large language model",
    "url": "https://openalex.org/W4407757890",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A3080895450",
            "name": "Elias Balt",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2911350687",
            "name": "Salim Salmi",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2156450436",
            "name": "Sandjai Bhulai",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A5116335171",
            "name": "Stefan Vrinzen",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1184593978",
            "name": "Merijn Eikelenboom",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2155653932",
            "name": "Renske Gilissen",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2365743435",
            "name": "Daan Creemers",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2002357030",
            "name": "Arne Popma",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2546379042",
            "name": "Saskia Mérelle",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2916136405",
        "https://openalex.org/W6969477430",
        "https://openalex.org/W1481723484",
        "https://openalex.org/W4387435593",
        "https://openalex.org/W4221143046",
        "https://openalex.org/W4401042286",
        "https://openalex.org/W4392193048",
        "https://openalex.org/W6851733669",
        "https://openalex.org/W6855224583",
        "https://openalex.org/W4389490285",
        "https://openalex.org/W4366548345",
        "https://openalex.org/W4386827872",
        "https://openalex.org/W4392077003",
        "https://openalex.org/W4387956898",
        "https://openalex.org/W2004261778",
        "https://openalex.org/W2152707099",
        "https://openalex.org/W2559465272",
        "https://openalex.org/W3080613857",
        "https://openalex.org/W4392168051",
        "https://openalex.org/W2056620308",
        "https://openalex.org/W6838865847",
        "https://openalex.org/W4382930233",
        "https://openalex.org/W2164777277",
        "https://openalex.org/W1566718566",
        "https://openalex.org/W4399911326",
        "https://openalex.org/W4391790090",
        "https://openalex.org/W4391591639",
        "https://openalex.org/W4386561859",
        "https://openalex.org/W4212989858",
        "https://openalex.org/W2990138404",
        "https://openalex.org/W4360978613",
        "https://openalex.org/W4385489398"
    ],
    "abstract": "Background Psychosocial autopsy is a retrospective study of suicide, aimed to identify emerging themes and psychosocial risk factors. It typically relies heavily on qualitative data from interviews or medical documentation. However, qualitative research has often been scrutinized for being prone to bias and is notoriously time- and cost-intensive. Therefore, the current study aimed to investigate if a Large Language Model (LLM) can be feasibly integrated with qualitative research procedures, by evaluating the performance of the model in deductively coding and coherently summarizing interview data obtained in a psychosocial autopsy. Methods Data from 38 semi-structured interviews conducted with individuals bereaved by the suicide of a loved one was deductively coded by qualitative researchers and a server-installed LLAMA3 large language model. The model performance was evaluated in three tasks: (1) binary classification of coded segments, (2) independent classification using a sliding window approach, and (3) summarization of coded data. Intercoder agreement scores were calculated using Cohen’s Kappa, and the LLM’s summaries were qualitatively assessed using the Constant Comparative Method. Results The results showed that the LLM achieved substantial agreement with the researchers for the binary classification (accuracy: 0.84) and the sliding window task (accuracy: 0.67). The performance had large variability across codes. LLM summaries were typically rich enough for subsequent analysis by the researcher, with around 80% of the summaries being rated independently by two researchers as ‘adequate’ or ‘good.’ Emerging themes in the qualitative assessment of the summaries included unsolicited elaboration and hallucination. Conclusion State-of-the-art LLMs show great potential to support researchers in deductively coding complex interview data, which would alleviate the investment of time and resources. Integrating models with qualitative research procedures can facilitate near real-time monitoring. Based on the findings, we recommend a collaborative model, whereby the LLM’s deductive coding is complemented by review, inductive coding and further interpretation by a researcher. Future research may aim to replicate the findings in different contexts and evaluate models with a larger context size.",
    "full_text": null
}