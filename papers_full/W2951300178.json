{
    "title": "Temporal Analysis of Language through Neural Language Models",
    "url": "https://openalex.org/W2951300178",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2108608223",
            "name": "Kim, Yoon",
            "affiliations": []
        },
        {
            "id": null,
            "name": "Chiu, Yi-I",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4304428393",
            "name": "Hanaki, Kentaro",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4288610266",
            "name": "Hegde, Darshan",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4224379263",
            "name": "Petrov, Slav",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2250775745",
        "https://openalex.org/W179875071",
        "https://openalex.org/W2106279089",
        "https://openalex.org/W2019096529",
        "https://openalex.org/W1610356397",
        "https://openalex.org/W1880262756",
        "https://openalex.org/W250892164",
        "https://openalex.org/W2017761238",
        "https://openalex.org/W2147152072",
        "https://openalex.org/W2148763605"
    ],
    "abstract": "We provide a method for automatically detecting change in language across time through a chronologically trained neural language model. We train the model on the Google Books Ngram corpus to obtain word vector representations specific to each year, and identify words that have changed significantly from 1900 to 2009. The model identifies words such as \"cell\" and \"gay\" as having changed during that time period. The model simultaneously identifies the specific years during which such words underwent change.",
    "full_text": "Temporal Analysis of Language through Neural Language Models\nYoon Kim∗ Yi-I Chiu∗ Kentaro Hanaki∗ Darshan Hegde∗ Slav Petrov⋄\n∗New York University, New York\n⋄Google Inc., New York\n{yhk255, yic211, kh1615, dh1806}@nyu.edu\nslav@google.com\nAbstract\nWe provide a method for automatically\ndetecting change in language across time\nthrough a chronologically trained neural\nlanguage model. We train the model on\nthe Google Books Ngram corpus to ob-\ntain word vector representations speciﬁc\nto each year, and identify words that have\nchanged signiﬁcantly from 1900 to 2009.\nThe model identiﬁes words such as cell\nand gay as having changed during that\ntime period. The model simultaneously\nidentiﬁes the speciﬁc years during which\nsuch words underwent change.\n1 Introduction\nLanguage changes across time. Existing words\nadopt additional senses (gay), new words are cre-\nated (internet), and some words ‘die out’ (many\nirregular verbs, such as burnt, are being replaced\nby their regularized counterparts (Lieberman et al.,\n2007)). Traditionally, scarcity of digitized histori-\ncal corpora has prevented applications of contem-\nporary machine learning algorithms—which typi-\ncally require large amounts of data—in such tem-\nporal analyses. Publication of the Google Books\nNgram corpus in 2009, however, has contributed\nto an increased interest in culturomics, wherein\nresearchers analyze changes in human culture\nthrough digitized texts (Michel et al., 2011).\nDeveloping computational methods for detect-\ning and quantifying change in language is of in-\nterest to theoretical linguists as well as NLP re-\nsearchers working with diachronic corpora. Meth-\nods employed in previous work have been var-\nied, from analyses of word frequencies to more in-\nvolved techniques (Guolordava et al. (2011); Mi-\nhalcea and Nataste (2012)). In our framework,\nwe train a Neural Language Model (NLM) on\nyearly corpora to obtain word vectors for each year\nfrom 1900 to 2009. We chronologically train the\nmodel by initializing word vectors for subsequent\nyears with the word vectors obtained from previ-\nous years.\nWe compare the cosine similarity of the word\nvectors for same words in different years to iden-\ntify words that have moved signiﬁcantly in the\nvector space during that time period. Our model\nidentiﬁes words such as cell and gay as having\nchanged between 1900–2009. The model addi-\ntionally identiﬁes words whose change is more\nsubtle. We also analyze the yearly movement of\nwords across the vector space to identify the spe-\nciﬁc periods during which they changed. The\ntrained word vectors are publicly available.1\n2 Related Work\nPreviously, researchers have computationally in-\nvestigated diachronic language change in various\nways. Mihalcea and Nastase (2012) take a super-\nvised learning approach and predict the time pe-\nriod to which a word belongs given its surrounding\ncontext. Sagi et al. (2009) use a variation of Latent\nSemantic Analysis to identify semantic change of\nspeciﬁc words from early to modern English. Wi-\njaya and Yeniterzi (2011) utilize a Topics-over-\nTime model and K-means clustering to identify\nperiods during which selected words move from\none topic/cluster to another. They correlate their\nﬁndings with the underlying historical events dur-\ning that time. Gulordava and Baroni (2011) use\nco-occurrence counts of words from 1960s and\n1990s to detect semantic change. They ﬁnd that\nthe words identiﬁed by the model are consistent\nwith evaluations from human raters. Popescu and\nStrapparava (2013) employ statistical tests on fre-\nquencies of political, social, and emotional words\nto identify and characterize epochs.\nOur work contributes to the domain in sev-\n1http://www.yoon.io\narXiv:1405.3515v1  [cs.CL]  14 May 2014\neral ways. Whereas previous work has generally\ninvolved researchers manually identifying words\nthat have changed (with the exception of Gulor-\ndava and Baroni (2011)), we are able to automat-\nically identify them. We are additionally able to\ncapture a word’s yearly movement and identify\nperiods of rapid change. In contrast to previous\nwork, we simultaneously identify words that have\nchanged and also the speciﬁc periods during which\nthey changed.\n3 Neural Language Models\nSimilar to traditional language models, NLMs in-\nvolve predicting a set of future word given some\nhistory of previous words. In NLMs however,\nwords are projected from a sparse, 1-of-V encod-\ning (where V is the size of the vocabulary) onto a\nlower dimensional vector space via a hidden layer.\nThis allows for better representation of semantic\nproperties of words compared to traditional lan-\nguage models (wherein words are represented as\nindices in a vocabulary set). Thus, words that\nare semantically close to one another would have\nword vectors that are likewise ‘close’ (as measured\nby a distance metric) in the vector space. In fact,\nMikolov et al. (2013a) report that word vectors ob-\ntained through NLMs capture much deeper level\nof semantic information than had been previously\nthought. For example, if xw is the word vector\nfor word w, they note that xapple −xapples ≈\nxcar −xcars ≈xfamily −xfamilies . That is, the\nconcept of pluralization is learned by the vector\nrepresentations (see Mikolov et al. (2013a) for\nmore examples).\nNLMs are but one of many methods to ob-\ntain word vectors—other techniques include La-\ntent Semantic Analysis (LSA) (Deerwester et al.,\n1990), Latent Dirichlet Allocation (LDA) (Blei et\nal., 2003), and variations thereof. And even within\nNLMs there exist various architectures for learn-\ning word vectors (Bengio et al. (2003); Mikolov\net al. (2010); Collobert et al. (2011); Yih et\nal. (2011)). We utilize an architecture introduced\nby Mikolov et al. (2013b), called the Skip-gram,\nwhich allows for efﬁcient estimation of word vec-\ntors from large corpora.\nIn a Skip-gram model, each word in the corpus\nis used to predict a window of surrounding words\n(Figure 1). To ensure that words closer to the cur-\nrent word are given more weight in training, dis-\nFigure 1: Architecture of a Skip-gram model (Mikolov et al.,\n2013b).\ntant words are sampled less frequently. 2 Training\nis done through stochastic gradient descent and\nbackpropagation. The word representations are\nfound in the hidden layer. Despite its simplicity—\nand thus, computational efﬁciency—compared to\nother NLMs, Mikolov et al. (2013b) note that the\nSkip-gram is competitive with other vector space\nmodels in the Semantic-Syntactic Word Relation-\nship test set when trained on the same data.\n3.1 Training\nThe Google Books Ngram corpus contains\nNgrams from approximately 8 million books, or\n6% of all books published (Lin et al., 2012). We\nsample 10 million 5-grams from the English ﬁc-\ntion corpus for every year from 1850–2009. We\nlower-case all words after sampling and restrict the\nvocabulary to words that occurred at least 10 times\nin the 1850–2009 corpus.\nFor the model, we use a window size of 4 and\ndimensionality of 200 for the word vectors. Within\neach year, we iterate over epochs until conver-\ngence, where the measure of convergence is de-\nﬁned as the average angular change in word vec-\ntors between epochs. That is, if V (y) is the vo-\ncabulary set for year y, and xw(y, e) is the word\nvector for word w in year y and epoch number e,\nwe continue iterating over epochs until,\n1\n|V (y)|\n∑\nw∈V (y)\narccos xw(y, e) ·xw(y, e−1)\n∥xw(y, e)∥∥xw(y, e−1)∥\nis below some threshold. The learning rate is set\nto 0.01 at the start of each epoch and linearly de-\ncreased to 0.0001.\n2Speciﬁcally, given a maximum window size ofW, a ran-\ndom integer R is picked from range [1, W] for each training\nword. The current training word is used to predictR previous\nand R future words.\nMost Changed Least Changed\nWord Similarity Word Similarity\nchecked 0.3831 by 0.9331\ncheck 0.4073 than 0.9327\ngay 0.4079 for 0.9313\nactually 0.4086 more 0.9274\nsupposed 0.4232 other 0.9272\nguess 0.4233 an 0.9268\ncell 0.4413 own 0.9259\nheaded 0.4453 with 0.9257\nass 0.4549 down 0.9252\nmail 0.4573 very 0.9239\nTable 1: Top 10 most/least changed words from 1900–2009,\nbased on cosine similarity of words in 2009 against their 1900\ncounterparts. Infrequent words (words that occurred less than\n500 times) are omitted.\nOnce the word vectors for year y have con-\nverged, we initialize the word vectors for yeary+1\nwith the previous year’s word vectors and train\non the y + 1data until convergence. We repeat\nthis process for 1850–2009. Using an open source\nimplementation in the gensim package, training\ntook approximately 4 days on a 2.9 GHz machine.\n4 Results and Discussion\nFor the analysis, we treat 1850–1899 as an initial-\nization period and begin our study from 1900.\n4.1 Word Comparisons\nBy comparing the cosine similarity between same\nwords across different time periods, we are able\nto detect words whose usage has changed. We are\nalso able to identify words that did not change. Ta-\nble 1 has a list of 10 most/least changed words be-\ntween 1900 and 2009. We note that almost all of\nthe least changed words are function words. For\nthe changed words, many of the identiﬁed words\nagree with intuition (e.g. gay, cell, ass). Oth-\ners are not so obvious (e.g. checked, headed, ac-\ntually). To better understand how these words\nhave changed, we look at the composition of their\nneighboring words for 1900 and 2009 (Table 2).\nAs a further check, we search Google Books\nfor sentences that contain the above words. Below\nare some example sentences from 1900 and 2009\nwith the word checked:\n1900: “However, he checked himself in time, saying —”\n1900: “She was about to say something further, but she\nchecked herself.”\n2009: “He’d checked his facts on a notepad from his back\npocket.”\n2009: “I checked out the house before I let them go inside.”\nWord Neighboring Words in\n1900 2009\ngay\ncheerful lesbian\npleasant bisexual\nbrilliant lesbians\ncell\ncloset phone\ndungeon cordless\ntent cellular\nchecked\nchecking checking\nrecollecting consulted\nstraightened check\nheaded\nhaired heading\nfaced sprinted\nskinned marched\nactually\nevidently really\naccidentally obviously\nalready nonetheless\nTable 2: Top 3 neighboring words (based on cosine similar-\nity) speciﬁc to each time period for the words identiﬁed as\nhaving changed.\nAt the risk of oversimplifying, the resulting sen-\ntences indicate that in the past, checked was more\nfrequently used with the meaning “to hold in re-\nstraint”, whereas now, it is more frequently used\nwith the meaning “to verify by consulting an au-\nthority” or “to inspect so as to determine accu-\nracy”. Given that check is a highly polysemous\nword, this seems to be a case in which the popu-\nlarity of a word’s sense changed over time.\nConducting a similar exercise for actually, we\nobtain the following sentences:\n1900: “But if ever he actually came into property, she must\nrecognize the change in his position.”\n1900: “Whenever a young gentleman was not actually\nengaged with his knife and fork or spoon —”\n2009: “I can’t believe heactually did that!”\n2009: “Our date was actually one of the most fun and\ncreative ones I had in years.”\nLike the above, this seems to be a case in\nwhich the popularity of a word’s sense changed\nover time (from “to refer to what is true or real”\nto “to express wonder or surprise”).\n4.2 Periods of Change\nAs we chronologically train the model year-by-\nyear, we can plot the time series of a word’s\ndistance to its neighboring words (from differ-\nent years) to detect periods of change. Figure 2\n(above) has such a plot for the wordcell compared\nto its early neighbors, closet and dungeon, and the\nmore recent neighbors, phone and cordless. Fig-\nure 2 (below) has a similar plot for gay.\nSuch plots allow us to identify a word’s pe-\nriod of change relative to its neighboring words,\nFigure 2: (Above) Time trend of the cosine similarity be-\ntween cell and its neighboring words in 1900 ( closet, dun-\ngeon) and 2009 ( phone, cordless). (Below) Similar plot of\ngay and its neighboring words in 1900 ( cheerful, pleasant)\nand 2009 (lesbian, bisexual).\nand thus provide context as to how it evolved.\nThis may be of use to researchers interested in\nunderstanding (say) when gay started being used\nas a synonym for homosexual. We can also iden-\ntify periods of change independent of neighboring\nwords by analyzing the cosine similarity of a word\nagainst itself from a reference year (Figure 3). As\nsome of the change is due to sampling and random\ndrift, we additionally plot the average cosine simi-\nlarity of all words against their reference points in\nFigure 3. This allows us to detect whether a word’s\nchange during a given period is greater (or less)\nthan would be expected from chance. We note\nthat for cell, the identiﬁed period of change (1985–\n2009) coincides with the introduction—and sub-\nsequent adoption—of the cell phone by the gen-\neral public.3 Likewise, the period of change for\ngay agrees with the gay movement which began\naround the 1970s (Wijaya and Yeniterzi, 2011).\n4.3 Limitations\nIn the present work, identiﬁcation of a changed\nword is conditioned on its occurring often enough\n3http://library.thinkquest.org/04oct/02001/origin.htm\nFigure 3: Plot of the cosine similarity of changed ( gay, cell)\nand unchanged ( by, than) words against their 1900 starting\npoints. Middle line is the average cosine similarity of all\nwords against their starting points in 1900. Shaded region\ncorresponds to one standard deviation of errors.\nin the study period. If a word’s usage decreased\ndramatically (or stopped being used altogether),\nits word vector will have remained the same and\nhence it will not show up as having changed.\nOne way to overcome this may be to combine\nthe cosine distance and the frequency to deﬁne a\nnew metric that measures how a word’s usage has\nchanged.\n5 Conclusions and Future Work\nIn this paper we provided a method for analyz-\ning change in the written language across time\nthrough word vectors obtained from a chronolog-\nically trained neural language model. Extending\nprevious work, we are able to not only automat-\nically identify words that have changed but also\nthe periods during which they changed. While we\nhave not extensively looked for connections be-\ntween periods identiﬁed by the model and real his-\ntorical events, they are nevertheless apparent.\nAn interesting direction of research could in-\nvolve analysis and characterization of the differ-\nent types of change. With a few exceptions, we\nhave been deliberately general in our analysis by\nsaying that a word’s usage has changed. We have\navoided inferring thetype of change (e.g. semantic\nvs syntactic, broadening vs narrowing, pejoration\nvs amelioration). It may be the case that words that\nundergo (say) a broadening in senses exhibit reg-\nularities in how they move about the vector space,\nallowing researchers to characterize the type of\nchange that occurred.\nReferences\nY . Bengio, R. Ducharme, P. Vincent. 2003. Neu-\nral Probabilitistic Language Model. Journal of Ma-\nchine Learning Research 3:1137–1155.\nD. Blei, A. Ng, M. Jordan, J. Lafferty. 2003. Latent\nDirichlet Allocation. Journal of Machine Learning\nResearch 3:993–1022.\nR. Collobert, J. Weston, L. Bottou, M. Karlen, K.\nKavukcuglu, P. Kuksa. 2011. Natural Language\nProcessing (Almost) from Scratch. Journal of Ma-\nchine Learning Research 12:2493–2537.\nS. Deerwester, S. Dumais, G. Furnas, T. Landauer, R.\nHarshman. 2011. Indexing by Latent Semantic\nAnalysis. Journal of the American Society for In-\nformation Science, 41(6):391–407.\nK. Gulordava, M. Baroni. 2011. A Distributional\nSimilarity Approach to the Detection of Semantic\nChange in the Google Books Ngram Corpus. Pro-\nceedings of the GEMS 2011 Workshop.\nE. Lieberman, J.B. Michel, J. Jackson, T. Tang, M.A.\nNowak. 2007. Quantifying the evolutionary dynam-\nics of language. Nature, 449: 716–716, October.\nY . Lin, J.B. Michel, E.L. Aiden, J. Orwant, W. Brock-\nman, S. Petrov. 2012. Syntactic Annotations for the\nGoogle Books Ngram Corpus. Proceedings of the\nAssociation for Computational Linguistics 2012.\nJ.B Michel, Y .K. Shen, A.P. Aiden, A. Veres, M.K.\nGray, J.P. Pickett, D. Hoiberg, D. Clancy, P. Norvig,\nJ. Orwant, S.Pinker, M.A. Nowak, E.L. Aiden.\n2011. Quantitative Analysis of Culture Using Mil-\nlions of Digitized Books. Science, 331(6014): 176–\n182, January.\nR. Mihalcea, V . Nastase. 2012. Word Epoch Disam-\nbiguation: Finding How Words Change Over Time.\nProceedings of the Association for Computational\nLinguistics 2012.\nT. Mikolov, M. Karaﬁat, L. Burget, J. Cernocky, S.\nKhudanpur. 2010. Recurrent Neural Network\nBased Language Model. Proceedings of Inter-\nspeech.\nT. Mikolov, W.T Yih, G. Zweig. 2013a. Linguistic\nRegularities in Continuous Space Word Representa-\ntions. Proceedings of NAACL-HLT 2013, 746–751.\nT. Mikolov, K. Chen, G. Corrado, J.Dean. 2013b. Efﬁ-\ncient Estimation of Word Representations in Vector\nSpace arXiv Preprint.\nO. Popescu, C. Strapparava. 2013. Behind the Times:\nDetecting Epoch Changes using Large Corpora. In-\nternational Joint Conference on Natural Language\nProcessing, 347–355\nE. Sagi, S. Kaufmann, B. Clark 2009. Semantic\nDensity Analysis: Comparing Word Meaning across\nTime and Phonetic Space. Proceedings of the EACL\n2009 Workshop on GEMS: 104–111.\nD.T. Wijaya, R. Yeniterzi. 2011. Understanding se-\nmantic change of words over centuries. Proceed-\nings of the 2011 international workshop on DEtect-\ning and Exploiting Cultural diversiTy on the social\nweb: 35–40.\nW. Yih, K. Toutanova, J. Platt, C. Meek. 2011. Learn-\ning Discriminative Projections for Text Similarity\nMeasures. Proceedings of the Fifteenth Confer-\nence on Computational Natural Language Learning,\n247–256."
}