{
  "title": "Knowledge-Enhanced Hierarchical Graph Transformer Network for Multi-Behavior Recommendation",
  "url": "https://openalex.org/W3207257408",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A3034975406",
      "name": "Lianghao Xia",
      "affiliations": [
        "South China University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2101072704",
      "name": "Chao Huang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2096026659",
      "name": "Yong Xu",
      "affiliations": [
        "South China University of Technology",
        "Peng Cheng Laboratory"
      ]
    },
    {
      "id": "https://openalex.org/A2014895805",
      "name": "Peng Dai",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2141978591",
      "name": "Xiyue Zhang",
      "affiliations": [
        "South China University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2096525556",
      "name": "Hongsheng Yang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2126330539",
      "name": "Jian Pei",
      "affiliations": [
        "Simon Fraser University"
      ]
    },
    {
      "id": "https://openalex.org/A2278593545",
      "name": "Liefeng Bo",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3034975406",
      "name": "Lianghao Xia",
      "affiliations": [
        "South China University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2101072704",
      "name": "Chao Huang",
      "affiliations": [
        "JDSU (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2096026659",
      "name": "Yong Xu",
      "affiliations": [
        "Computer Network Information Center",
        "South China University of Technology",
        "Peng Cheng Laboratory"
      ]
    },
    {
      "id": "https://openalex.org/A2014895805",
      "name": "Peng Dai",
      "affiliations": [
        "JDSU (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2141978591",
      "name": "Xiyue Zhang",
      "affiliations": [
        "South China University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2096525556",
      "name": "Hongsheng Yang",
      "affiliations": [
        "JDSU (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2126330539",
      "name": "Jian Pei",
      "affiliations": [
        "Simon Fraser University"
      ]
    },
    {
      "id": "https://openalex.org/A2278593545",
      "name": "Liefeng Bo",
      "affiliations": [
        "JDSU (United States)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2996863522",
    "https://openalex.org/W2563647077",
    "https://openalex.org/W6758918355",
    "https://openalex.org/W2950694221",
    "https://openalex.org/W3173924614",
    "https://openalex.org/W6601202783",
    "https://openalex.org/W2907607062",
    "https://openalex.org/W3035287707",
    "https://openalex.org/W2054141820",
    "https://openalex.org/W2937556626",
    "https://openalex.org/W6600238479",
    "https://openalex.org/W6929778926",
    "https://openalex.org/W6834284007",
    "https://openalex.org/W3206531148",
    "https://openalex.org/W2903749028",
    "https://openalex.org/W2947537487",
    "https://openalex.org/W3035539704",
    "https://openalex.org/W2409498980",
    "https://openalex.org/W3100278010",
    "https://openalex.org/W3205819092",
    "https://openalex.org/W2624431344",
    "https://openalex.org/W2253995343",
    "https://openalex.org/W3100592176",
    "https://openalex.org/W2914721378",
    "https://openalex.org/W2951570486",
    "https://openalex.org/W2945623882",
    "https://openalex.org/W2964293507",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4294558607",
    "https://openalex.org/W2788456731",
    "https://openalex.org/W3012871709",
    "https://openalex.org/W2997672513",
    "https://openalex.org/W3012735076",
    "https://openalex.org/W3104353018",
    "https://openalex.org/W2605350416",
    "https://openalex.org/W3206932362",
    "https://openalex.org/W2984100107",
    "https://openalex.org/W3173955760",
    "https://openalex.org/W2966750432",
    "https://openalex.org/W1720514416",
    "https://openalex.org/W2783944588",
    "https://openalex.org/W2626778328",
    "https://openalex.org/W2964273061",
    "https://openalex.org/W2740920897",
    "https://openalex.org/W2951045934",
    "https://openalex.org/W2963911286",
    "https://openalex.org/W2951369132"
  ],
  "abstract": "Accurate user and item embedding learning is crucial for modern recommender systems. However, most existing recommendation techniques have thus far focused on modeling users' preferences over singular type of user-item interactions. Many practical recommendation scenarios involve multi-typed user interactive behaviors (e.g., page view, add-to-favorite and purchase), which presents unique challenges that cannot be handled by current recommendation solutions. In particular: i) complex inter-dependencies across different types of user behaviors; ii) the incorporation of knowledge-aware item relations into the multi-behavior recommendation framework; iii) dynamic characteristics of multi-typed user-item interactions. To tackle these challenges, this work proposes a Knowledge-Enhanced Hierarchical Graph Transformer Network (KHGT), to investigate multi-typed interactive patterns between users and items in recommender systems. Specifically, KHGT is build upon a graph-structured neural architecture to i) capture type-specific behavior semantics; ii) explicitly discriminate which types of user-item interactions are more important in assisting the forecasting task on the target behavior. Additionally, we further integrate the multi-modal graph attention layer with temporal encoding strategy, to empower the learned embeddings be reflective of both dedicated multiplex user-item and item-item collaborative relations, as well as the underlying interaction dynamics. Extensive experiments conducted on three real-world datasets show that KHGT consistently outperforms many state-of-the-art recommendation methods across various evaluation settings. Our implementation is available in https://github.com/akaxlh/KHGT.",
  "full_text": "Knowledge-Enhanced Hierarchical Graph Transformer Network\nfor Multi-Behavior Recommendation\nLianghao Xia1, Chao Huang2*, Y ong Xu1,3,4, Peng Dai2, Xiyue Zhang1\nHongsheng Yang2, Jian Pei5, Liefeng Bo2\n1South China University of Technology, China,2JD Finance America Corporation, USA\n3Communication and Computer Network Laboratory of Guangdong, China\n4Peng Cheng Laboratory, Shenzhen, China,5Simon Fraser University, Canada\n{cslianghao.xia,zhang.xiyue}@mail.scut.edu.cn, chaohuang75@gmail.com, yxu@scut.edu.cn\n{peng.dai,hongsheng.yang,liefeng.bo}@jd.com, jpei@cs.sfu.ca\nAbstract\nAccurate user and item embedding learning is crucial for\nmodern recommender systems. However, most existing rec-\nommendation techniques have thus far focused on model-\ning users’ preferences over singular type of user-item inter-\nactions. Many practical recommendation scenarios involve\nmulti-typed user interactive behaviors (e.g., page view, add-\nto-favorite and purchase), which presents unique challenges\nthat cannot be handled by current recommendation solutions.\nIn particular: i) complex inter-dependencies across different\ntypes of user behaviors; ii) the incorporation of knowledge-\naware item relations into the multi-behavior recommen-\ndation framework; iii) dynamic characteristics of multi-\ntyped user-item interactions. To tackle these challenges, this\nwork proposes a K\nnowledge-Enhanced Hierarchical Graph\nTransformer Network (KHGT), to investigate multi-typed in-\nteractive patterns between users and items in recommender\nsystems. Speciﬁcally, KHGT is built upon a graph-structured\nneural architecture to i) capture type-speciﬁc behavior char-\nacteristics; ii) explicitly discriminate which types of user-item\ninteractions are more important in assisting the forecasting\ntask on the target behavior. Additionally, we further integrate\nthe graph attention layer with the temporal encoding strategy,\nto empower the learned embeddings be reﬂective of both ded-\nicated multiplex user-item and item-item relations, as well as\nthe underlying interaction dynamics. Extensive experiments\nconducted on three real-world datasets show that KHGT con-\nsistently outperforms many state-of-the-art recommendation\nmethods across various evaluation settings. Our implementa-\ntion code is available inhttps://github.com/akaxlh/KHGT.\nIntroduction\nRecommender systems have been widely deployed in many\nInternet services (e.g., e-commerce, online review and ad-\nvertising systems) to alleviate information overload and de-\nliver the most relevant items to users (Liu et al. 2020; Huang\net al. 2019a). In the recommendation scenario with the focus\non implicit feedback, Collaborative Filtering (CF) becomes\none of most popular paradigm which factorizes user-item\n*Corresponding author: Chao Huang\nCopyright © 2021, Association for the Advancement of Artiﬁcial\nIntelligence (www.aaai.org). All rights reserved.\ninteractions into latent representations and predicts user’s\npreference based on the projected low-dimensional embed-\ndings (Chen et al. 2020).\nMany deep neural network techniques have been devel-\noped to enhance collaborative ﬁltering architecture for non-\nlinear feature interactions. Speciﬁcally, early studies, like\nNCF (He et al. 2017) and DMF (Xue et al. 2017) utilize the\nMulti-layer Perceptron to handle the non-linear interactions.\nFurthermore, autoencoder-based methods are designed for\nmapping high-dimensional sparse user-item interactions into\nlow-dimensional dense representations (Sedhain et al. 2015;\nWu, DuBois et al. 2016). Later works investigate the use\nof graph neural network to exploit the high-order user-item\nrelations, and perform neighborhood-based feature aggrega-\ntions (Zhang et al. 2019; Wang et al. 2019c).\nAlthough these methods have shown promising results,\na deﬁciency is that they only model singular type of user-\nitem interactions, which makes them insufﬁcient to distill\nthe complex collaborative signals from the multi-typed be-\nhaviors of users (Jin et al. 2020). In particular, there typically\nexist multiple relations between user and item that exhibit\nvarious behavior characteristics in many real-world recom-\nmendation scenarios, which are particularly helpful in learn-\ning users’ preferences on the target type of behavior (Guo\net al. 2019). For example, in online retail platforms, users’\npage view and add-to-favorite activities over different items,\ncan serve as the auxiliary knowledge for assisting the fore-\ncasting task of customer purchase (target behavior). There-\nfore, it is crucial to take such inter-type behavioral inﬂuences\ninto consideration to more accurately infer user preferences.\nThere are several key technical challenges that remain\nto be solved to realize the multi-behavior recommendation.\nFirst, how to distill the user-speciﬁc collaborative signals\nfrom the multiplex user-item interaction behaviors, is a sig-\nniﬁcant challenge to tackle. In practice, type-speciﬁc behav-\nioral patterns interweave with each other in a complex man-\nner (Gao et al. 2019b), like the complementary correlations\nbetween the add-to-cart and purchase behaviors, or users’\nnegative reviews are mutually exclusive with their positive\nfeedback over the same item. Without the explicitly encod-\ning of such heterogeneous relationships between user and\nTheThi rty-Fi fth AAA ICon ferenceon A rti fi ci al Intellig ence(AAAI-21)\n4486\nitem, models may suffer from the inability of capturing the\ncomplicated inherent cross-type behavior dependencies in a\nhierarchical way.Second, another core challenge lies in the\nincorporation of knowledge-aware item semantic related-\nness into the encoding function of multi-behavioral patterns.\nThe knowledge-aware side information often contains much\nfruitful facts and contextual connections about items (Wang\net al. 2019a). It is desirable to rigorously design a joint em-\nbedding paradigm over the user-item and item-item relations\nin our multi-behavior recommendation.Third, a time-aware\nmodel is needed to better handle the temporal information\nof user-item interactions.\nThere are a handful of recent models that attempt to inte-\ngrate multi-behavioral interactive patterns for making rec-\nommendations (Jin et al. 2020; Gao et al. 2019b). How-\never, these works intend to consider multi-typed interactions\nin a relatively independent and local manner (e.g., singu-\nlar dimensional cascading correlations), and can hardly cap-\nture the high-order multiplex relationships across users and\nitems. Additionally, how to account for the side knowledge\nfrom items as well as user-item interaction dynamics, is less\nexplored in those multi-behavior recommender systems.\nIn light of these differences and challenges, we present\na general framework–K\nnowledge-Enhanced Hierarchical\nGraph Transformer Network (KHGT), for multi-behavior\nrecommendation. Particularly, at the ﬁrst stage, we develop\na multi-behavior graph transformer network which performs\nrecursive embedding propagation, to capture behavior het-\nerogeneity across users and items in an attentive aggregation\nschema. As a result, user-item and item-item relationships of\ndifferent types are enabled to maintain their speciﬁc repre-\nsentation space. To handle behavior dynamics, we inject the\ntime-aware context into the graph transformer framework\nthrough a temporal encoding strategy. In addition, to encode\nthe inter-dependencies between type-speciﬁc behavior rep-\nresentations, a multi-behavior mutual attention encoder is\nproposed to learn dependent structures of different types of\nbehaviors in a pairwise manner. Finally, a gated aggregation\nlayer is introduced to discriminate the contribution of type-\nspeciﬁc relation embeddings for making recommendations.\nThe contributions of this paper are highlighted as follows:\n• We propose a framework KHGT, which explicitly\nachieves high-order relation learning in the knowledge-\naware multi-behavior collaborative graph under the hier-\narchically structured graph transformer network.\n• To jointly integrate user- and item-wise collaborative\nsimilarities under the multi-behavior modeling paradigm\nof KHGT: i) the ﬁrst-stage graph-structured transformer\nmodule captures the type-speciﬁc user-item interactive\npatterns in a time-aware environment; ii) the second-stage\nattentive fusion network encodes the cross-type behav-\nior hierarchical dependencies and discriminates the type-\nspeciﬁc contribution, in forecasting the target behaviors.\n• We apply the proposed KHGT method to three real-world\ndatasets of movie, venue and product recommendations.\nExperiments show that our model achieves signiﬁcant\ngains over many state-of-the-art baselines from various\nlines. Furthermore, model interpretation ability is also in-\nvestigated with case studies of qualitative examples.\nPreliminaries\nWe begin with the introduction of key notations and con-\nsider a typical recommendation scenario withI users (U =\n{u\n1,...,u i,...,u I }) and J items (V = {v1,...,v j,...,v J }).\nWe further deﬁne the relevant graph-structured data as:\nUser-Item Multi-Behavior Interaction Graph.Gu. With\nthe awareness of different types of user-item interactions,\na multi-behavior interaction graph is deﬁned as: Gu =\n(U,V,E u), in which the edge setEu represents K types of\nrelations (e.g., browse, add-to-favorite, purchase) between\nuser and item. InE\nu, each edgeek\ni,j denotes that userui in-\nteracts with itemvj under the behavior type ofk.\nKnowledge-aware Item-Item Relation Graph.Gv.T oi n -\ncorporate the side information of items, we deﬁne graph\nGv =( V,Ev)to characterize multiplex dependencies across\nitems with the consideration of their external knowledge. In\nG\nv, edgeer\nj,j′ linked between itemvj and vj′ with their meta\nrelations, which is denoted as{(vj,r,v j′ )|vj,vj′ ∈ V,r ∈\nR}. Here,R indicates the set of relations which can be gen-\nerated from different aspects, such asvj and vj′ belong to\nthe same category, from the same location, or interacted with\nthe same user under the same behavior type.\nTask Formulation. Based on above deﬁnitions, we formu-\nlate the knowledge-aware multi-behavior recommendation:\nInput: the user-item multi-behavior interaction graphGu\nand the knowledge-aware item-item relation graphGv.\nOutput: a predictive model which effectively infers the\nprobability yi,j of unseen interaction between userui and\nitem vj under the target behavior type ofk.\nMethodology\nWe elaborate the details of KHGT, which investigates the\nmultiplex user-item relations in an end-to-end manner.\nAttentive Heterogeneous Message Aggregation\nIn this component, we aim to collectively capture the multi-\nbehavior user-item interactive patterns and item-item depen-\ndencies in a uniﬁed graph-structured neural network. The\noverall architecture is shown in Figure 2.\nMulti-Behavior Interactive Pattern Encoding. This\nmodule aims to aggregate the heterogeneous signals from\nmulti-behavioral patterns between the user and his/her in-\nteracted items. Towards this end, we develop an adaptive\nmulti-behavior self-attention network under a message pass-\ning paradigm with the enhancement of global behavior con-\ntext, which consists of three key modules: temporal context\nencoding scheme, information propagation and aggregation.\nTemporal Information Encoding. To capture the inﬂu-\nences between different types of user-item interactions in\na time-aware scenario, we develop a temporal context en-\ncoding scheme, to incorporate the behavior dynamics in our\nheterogeneous message aggregation architecture. In particu-\nlar, given the connectionE\nk\ni,j between user ui and item vj\nunder the behavior ofk, we map their corresponding inter-\naction timestamptk\ni,j into the time slot asτ(tk\ni,j\n), and utilize\n4487\n/g13/g16/g5/g17/g29/g31\n/g7/g17/g33/g4/g32/g35\n/g15/g30/g20/g29/g2/g10/g31/g20/g25/g1/g12/g32/g24/g31/g23/g2/g4/g20/g22/g17/g33/g23/g27/g29\n/g10/g26/g31/g20/g29/g17/g18/g31/g23/g27/g26/g1/g8/g29/g17/g28/g22\n/g11/g26/g27/g34/g24/g20/g19/g21/g20/g2/g17/g34/g17/g29/g20\n/g10/g31/g20/g25/g2/g10/g31/g20/g25/g14/g20/g24/g17/g31/g23/g27/g26/g8/g29/g17/g28/g22\n/g10/g31/g20/g25/g12/g20/g31/g17/g2/g14/g20/g24/g17/g31/g23/g27/g26\n/g36\n/g36\n/g36\n/g36\n/g36\n/g36\n/g3/g31/g31/g20/g26/g31/g23/g33/g20/g1/g9/g20/g31/g20/g29/g27/g21/g20/g26/g20/g27/g32/g30/g1\n/g12/g20/g30/g30/g17/g21/g20 /g3/g21/g21/g29/g20/g21/g17/g31/g23/g27/g26\n/g4/g20/g22/g17/g33/g23/g27/g29/g1/g9/g23/g20/g29/g17/g29/g18/g22/g23/g18/g17/g24/g1\n/g6/g20/g28/g20/g26/g19/g20/g26/g18/g35/g1/g12/g27/g19/g20/g24/g23/g26/g21\n/g1\n/g1\n/g1\n/g1\n/g9\n/g9\n/g3/g31/g31/g20/g26/g31/g23/g33/g20/g1/g9/g20/g31/g20/g29/g27/g21/g20/g26/g20/g27/g32/g30/g1\n/g12/g20/g30/g30/g17/g21/g20 /g3/g21/g21/g29/g20/g21/g17/g31/g23/g27/g26\n/g4/g20/g22/g17/g33/g23/g27/g29/g1/g9/g23/g20/g29/g17/g29/g18/g22/g23/g18/g17/g24/g1\n/g6/g20/g28/g20/g26/g19/g20/g26/g18/g35/g1/g12/g27/g19/g20/g24/g23/g26/g21\nFigure 1: The model architecture of KHGT framework.\nthe sinusoidal functions for embeddingTk\ni,j ∈ R2d genera-\ntion, which is motivated by the positional embedding frame-\nwork in Transformer (V aswani et al. 2017; Hu et al. 2020;\nWu et al. 2020).\nTk,(2l)\n(i,j) = sin( τ(tk\ni,j )\n10000\n2l\nd\n),Tk,(2l+1)\n(i,j) = cos( τ(tk\ni,j\n)\n10000\n2l+1\nd\n) (1)\nwhere the element indexs (even and odd position index)\nin the temporal information embedding are represented as\n(2l) and (2l +1 ), respectively.d is the latent dimensional-\nity. To augment the tunable ability of our temporal context\nencoding, we further apply a projection layer overTk\ni,j as:\n¯T\nk\ni,j = Tk\ni,j · Wk, Wk ∈ R2d×d. Wk is the transformation\nweights corresponding tok-th type of interactions.\nInformation Propagation Phase. We perform the time-\naware information propagation between the source and\ntarget node, over the multi-behavior user-item interaction\ngraph G\nu, with the following graph attentive mechanism:\nmk\ni←j =\nH⏐⏐\n⏐\n⏐\n⏐\n⏐\nh=1\nωh\ni,j,k ·Vh\nkpj;mk\nj←i =\nH⏐⏐\n⏐\n⏐\n⏐\n⏐\nh=1\nωh\nj,i,k ·Vh\nkpi (2)\nwhere mk\ni←j and mk\nj←i\ndenote the propagated message from\nitem vj to user ui, and fromui to vj, respectively.pj is the\nelement-wise addition between initialized item embedding\nej and the corresponding temporal context representation\n¯T\nk\ni,j. i.e., pj = ej ⊕ ¯T\nk\ni,j\n. Similar operation is applied for\nthe message from user side:pi = ei ⊕ ¯T\nk\ni,j\n. Vh\nk ∈ R\nd\nH ×d\nis the h-head projection matrix with respect to thek-th be-\nhavior type. In addition,ωh\ni,j,k, ωh\nj,i,k represent the learned\nattentive propagation weights over the constructed message\npj and pi, respectively. Formally, they are calculated as:\n¯ωh\ni,j,k = (Qh\nk pi)⊤ (Kh\nk pj )√\nd/H\n; ωh\ni,j,k = exp(¯ωh\ni,j,k)\nΣek\ni,j′ ∈Eu exp(¯ωh\ni,j′,k)\nwhere Qh\nk,Kh\nk ∈ R\nd\nH ×d are the head-speciﬁc query and key\ntransformation with respect to thek-th behavior type.\n/g24 /g24\n/g1/g7/g2 /g5/g15/g18/g8/g7/g15 /g3/g18/g17/g22/g11/g23/g22 /g3/g13/g7/g17/g17/g11/g15/g21\n/g1/g8/g2/g6/g11/g16/g19/g18/g20/g7/g15 /g3/g18/g17/g22/g11/g23/g22 /g4/g17/g9/g18/g10/g14/g17/g12\n/g6/g14/g16/g11\nFigure 2: The framework of global context enhanced param-\neter learning and behavior dynamics encoding in KHGT.\nTo incorporate the global context across different be-\nhavior types in the message passing process, we learn the\nattention-based transformation matrices Qh\nk,Kh\nk,Vh\nk\nin a\nmulti-channel parameter learning framework. To be speciﬁc,\nwe design a base transformation paradigm which consists of\nM channels of parameters,i.e., ¯Q\nh\nm, ¯K\nh\nm, ¯V\nh\nm\n(m =1 ...M).\nThey correspond to M latent projection subspaces, which\nreﬂect different aspects of the common behavior context\nacross different types. Formally, the type-speciﬁc transfor-\nmation procedure is performed with the gating mechanism:\nQh\nk =\nM∑\nm=1\nαk\nm ¯Q\nh\nm,Kh\nk =\nM∑\nm=1\nβk\nm ¯K\nh\nm,Vh\nk =\nM∑\nm=1\nγk\nm ¯V\nh\nm (3)\nwhere αk\nm,βk\nm,γk\nm are quantitative gated weights for the\nm-th channel transformation with respect to behavior type\nof k. Typically, the number of channelsM is smaller than\nthe number of behavior typesK in practice, which enables\nthe parameter-efﬁcient heterogeneous message aggregation.\nInformation Aggregation Phase.Based on the constructed\npropagated message mk\ni←j and mk\nj←i\n, we aggregate the\nneighboring information with the summation operation:\nqk\ni = f(\n∑\nvj ∈Ni\nmk\ni←j ); qk\nj = f(\n∑\nvi∈Nj\nmk\nj←i) (4)\nwhere Ni and Nj denote the neighborhood of ui and vj\nin the user-item interaction graphGu. qk\ni ,qk\nj\nare the aggre-\ngated information ofui and vj under the behavior type ofk.\nf(·) is an activation function like LeakyReLU.\nInformation Aggregation for Item-side Relations. We\nfuse the heterogeneous signals from the item-item inter-\ndependencies with the attentive aggregation:\nqr\nj = f(\n∑\nvj′ ∈Nj\nmr\nj←j′ )=\n∑\nvj′ ∈Nj\nH⏐⏐\n⏐\n⏐\n⏐\n⏐\nh=1\nωh\nj,j′,rVh\nr pj′ (5)\nwhere r is the index ofR different item-item relations and\nNj indicates the neighboring nodes ofvj over the graphGv.\nBehavior Hierarchical Dependency Modeling\nIn our multi-behavior recommendation scenarios, user be-\nhaviors with different types interact with each other in a\ncomplex and hierarchical way. To address this challenge,\ntwo questions arise: i) how do we effectively preserve mu-\ntual relations between different types of behavior; ii) how to\npromote the collaboration across different type-speciﬁc be-\nhavior representations in assisting the ﬁnal recommendation.\nOur mutual relation encoder is developed based on the\nscaled dot-product attention via learning the pairwise type-\n4488\nwise relevance scoresλi,h\nk,k′ , which is formally represented:\n˜qk\ni = MH-Att(qk\ni\n)=\nH⏐⏐\n⏐\n⏐\n⏐\n⏐\nh=1\nK∑\nk′=1\nλi,h\nk,k′ · ˜V\nh\n· qk′\ni (6)\nλi,h\nk,k\n′ =\nexp¯λi,h\nk,k\n′\n∑K\nk′=1 exp¯λi,h\nk,k′\n;¯λi,h\nk,k\n′ = (˜Q\nh\n· qk\ni )⊤ (˜K\nh\n· qk′\ni )√\nd/H\nwhere ˜Q\nh\n, ˜K\nh\n, ˜V\nh\nare learnable projection matrices of the\nh-th learning subspace. Similar operations are applied for\nupdating the item embedding˜qk\nj .\nNext, we propose to fuse the learned type-speciﬁc behav-\nior representations, by investigating the individual impor-\ntance in forecasting the target type of user interactions. We\npresent our gated fusion mechanism for conclusive represen-\ntation Φ\nj as:\nΦj =\nK∑\nk=1\nηk\nj ˜qk\nj ⊕\nR∑\nr=1\nξr\nj ˜qr\nj\n;ηk\nj = σ(¯ηk\nj );ξr\nj = σ(¯ξr\nj ) (7)\nσ(·) is the softmax function.ηk\nj and ξr\nj are the learned im-\nportance score ofk-th type of user-item interaction represen-\ntation ˜qk\ni\n, and r-th type of item-item relation representation\n˜qr\nj\n, respectively. They are formally calculated as:\n¯ηk\nj = a⊤\n0 f(˜qk\nj )+c u\n0 ;¯ηr\nj = b⊤\n0 f(˜qr\nj )+c v\n0 (8)\nf(·) denotes the multi-layer network as:f(˜qk\nj )= Bu\n1 ˜qk\nj +\nBu\n2\n∑ K\nk′=1 ˜qk\nj +cu\n1 . Parameters in our gated fusion layer are\ndenoted asa0, b0, B∗\n1, B∗\n2\n(transformations), c∗\n0 and c∗\n1\n(bias\nterms). This gating mechanism is also utilized for obtaining\nuser representationΦi over type-speciﬁc embeddings˜qk\ni .\nHigh-order Multi-Behavior Pattern Propagation.Based\non the deﬁned information propagation and aggregation\nfunctions, we capture high-order collaborative relations un-\nder the multi-behavior context (user-item interaction graph\nG\nu) in our graph neural network. The update procedure from\nthe (l)-th layer to the(l+1)-th layer is (Φ(l)\nj ∈ Rd):\nΦ(l+1)\nj ← Aggregate\ni∈Nu(j);j′∈Nv (j)\n(\nPropagate(Φl\ni,Φl\nj\n′ ,G)\n)\n(9)\nPropagate(·) is the information propagation function which\nextracts useful features from both the user-item interac-\ntions (over Eu) and item-item dependencies (over Ev).\nAggregate(·) denotes the information fusion function. The\nﬁnal embeddings are summarized cross different order-\nspeciﬁc representations as:Φj = Φ(1)\nj ⊕...⊕Φ(L)\nj .\nThe Learning Phase of KHGT\nAfter generating the conclusive representationsΦi and Φj\nfor users and items, the likelihood ofui interacting with vj\nunder the target behavior can be inferred as Pri,j = z⊤ ·\n(Φi ⊙ Φj). To perform the model optimization, we aim to\nminimize the following marginal pair-wise loss function:\nL =\nI∑\ni=1\nS∑\ns=1\nmax(0,1−Pri,ps +Pri,ns )+λ∥Θ∥ 2\nF (10)\nDataset User # Item # Interaction # Interactive Behavior Type\nYelp 19800 22734 1.4 × 106 {Tip, Dislike, Neutral, Like}\nML10M 67788 8704 9.9 × 106 {Dislike, Neutral, Like}\nOnline Retail 805506 584050 6.4 × 107 {Page View, Favorite, Cart, Purchase}\nTable 1: Statistics of the experimented datasets\nwhere I denotes the number of trained users, andS denotes\nthe number of positive-negative pairs for each user. In prac-\ntice, we randomly sampleS positive items vp1 ,vp2 ,...,v ps\nand S negative itemsvn1 ,vn2 ,...,v ns for each user. In addi-\ntion, Θ represents the set of all trainable parameters, andλ\nis the weight for the regularization term.\nSub-graph Sampling for Large-Scale Data. One key\nchallenge of graph neural architecture lies in the informa-\ntion aggregation over the entire graph in a full-batch mode,\nwhich consumes tremendous memory and computation cost.\nTo endow KHGT with the ability of handling large-scale\ndata, we develop a random-walk-based sub-graph sampling\nalgorithm over the graphG\nu and Gv, and maintain a weight\nvector during the sampling process based on node related-\nness extracted from the adjacent matrix of the graph.\nModel Complexity Analysis. Our KHGT spendsO(K ×\n(I +J)×d\n2) to calculate theQ,K,V transformations, and\nO(|E|×d) for information aggregation. For type-wise re-\nlation modeling, the most prominent computation comes\nfrom the O(K × (I + J) × d2) transformations. Overall,\nour KHGT could achieve comparable time complexity with\nthe GNN-based multi-behavior recommendation methods.\nAlso, KHGT costs moderate extra memory for the interme-\ndiate results, compared to the most existing GNN models.\nEvaluation\nThis section answers the following research questions:\n• RQ1: How doesKHGT perform compared with the vari-\nous state-of-the-art recommender systems?\n• RQ2: How do different designed modules and captured\nrelational structures contribute to the model performance?\n• RQ3: How doesKHGT work with the integration of dif-\nferent types of behavior in our heterogeneous aggregator?\n• RQ4: How doesKHGT perform w.r.t different interaction\nsparsity levels as compared to representative competitors?\n• RQ5: How doesKHGT perform with different parameter\nsettings (e.g., latent dimensionality and GNN depth)?\n• RQ6: How is the interpretation ability of ourKHGT in\ncapturing behavior inter-dependencies?\nExperimental Settings\nData Description. We show the data statistics in Table 1.\nMovieLens Data. We differentiate explicit user’s rating\nscores r (i.e., [1,..., 5]) into multiple behavior types: (1)\nr ≤ 2: dislike behavior. (2) 2<r< 4. neutral behavior. (3)\nr ≥ 4: like behavior. In this data, the target and auxiliary be-\nhaviors are set as (like) and (neutral, dislike), respectively.\nY elp Data. User’s feedbacck interactions over items in this\ndata, are projected into three behavior types by following\nthe same partition rubric of MovieLens. We regard the like\n4489\nbehavior as the target type and (dislike, neutral, tip) as aux-\niliary sources, where tip behavior indicates that users gave\ntips on their visited venues.\nOnline Retail Data. We also investigate our KHGT in a\nreal-world online retail scenario with explicit multi-typed\nuser-item interactions, i.e., page view, add-to-cart, add-to-\nfavorite and purchase. For this application, the target behav-\nior is set as purchases and the other three types of user be-\nhaviors are considered as auxiliary behavioral signals.\nFor the above applications, the knowledge-aware item-\nitem relation graphG\nv is generated with item meta-relations\nfrom two dimensions: i)vj–ui–vj′ under the behavior type\nof k; ii) the categorical relations between itemvj and vj′ .\nEvaluation Protocols. We adopt two metrics:Normalized\nDiscounted Cumulative Gain (NDCG@N) and Hit Ratio\n(HR@N) which have been widely used in recommendation\ntasks (Wang et al. 2019c; Chen et al. 2018). Note that higher\nHR and NDCG scores signal better performance. Follow-\ning the same settings in (Y u et al. 2019; Zhao et al. 2020),\nwe employ the time-aware leave-one-out evaluation to split\nthe training/test sets. The test set contains the last interactive\nitem of users and the rest of data is used for training. For\nfair and efﬁcient evaluation, each positive instance is paired\nwith randomly selected 99 non-interactive items, which is\nconsistent with the experimental settings in (Sun et al. 2019;\nHuang et al. 2019b).\nMethods for Comparison. Baselines are presented as:\nConventional Matrix Factorization Approach:\n• BiasMF (Koren, Bell, and V olinsky 2009): it enhances the\nmatrix factorization paradigm by incorporating user and\nitem bias with the corresponding implicit feedback.\nAutoencoder-based Collaborative Filtering:\n• AutoRec (Sedhain et al. 2015): it is a stacked autoencoder\narchitecture to project user-item interactions into hidden\nrepresentation unit with the data reconstruction loss.\n• CDAE (Wu, DuBois et al. 2016): it designs a denoising\nAutoencoder for user-item interaction modeling.\nNeural Network-enhanced Collaborative Filtering:\n• DMF (Xue et al. 2017): it enhances the MF with a multi-\nlayer perceptron to encode the interaction vector of users.\n• NCF (He et al. 2017): Three variants of NCF with differ-\nent interaction encoders:i.e., Multilayer perceptron (NCF-\nM), concatenated element-wise-product branch (NCF-N)\nand the ﬁxed element-wise product (NCF-G).\nNeural Auto-regressive Recommendation Methods:\n• NADE (Zheng et al. 2016): it incorporates the parameter\nsharing mechanism into the autoregressive CF model.\n• CF-UIcA (Du et al. 2018): it is a neural CF framework\nwith auto-regression on user-item correlations.\nGraph Neural Networks Collaborative Filtering:\n• ST-GCN (Zhang et al. 2019): it is a graph-structured\nencoder-decoder framework to learn latent embeddings of\nusers and items under data scarcity, via GCNs.\n• NGCF (Wang et al. 2019c): it is a message passing archi-\ntecture to exploit high-order connection relationships.\nRecommendation with Multi-Behavioral Patterns.\n• NMTR (Gao et al. 2019a): it is a multi-task recommenda-\ntion framework which explores the cascaded correlations\nbetween multiple types of user-item interactive behavior.\n• DIPN (Guo et al. 2019): this approach jointly considers\nthe behavior patterns of browsing and buying with the bi-\ndirectional recurrent network based attention mechanism.\n• NGCF\nM (Wang et al. 2019c): we integrate the multi-\nbehavioral relation learning with the neural graph collab-\norative ﬁltering model under a joint graph neural network.\n• MATN(Xia et al. 2020): it learns the type-wise interaction\ndependencies with a memory attention network.\n• MBGCN (Jin et al. 2020): it models the multi-behavior\nof users and uses graph convolutional network to perform\nbehavior-aware embedding propagation.\nKnowledge-aware Recommendation Method.\n• KGAT (Wang et al. 2019b): it investigates the high-order\nconnectivity of the semantic item relations over the col-\nlaborative knowledge graph, with GA T framework.\nParameter Settings. We implement KHGT with Tensor-\nFlow and infer the model parameters with Adam optimizer.\nOur multi-head self-attention module is conﬁgured with the\n2 heads for embedding learning. The channels of base trans-\nformations in our graph attention module is set as 2. The\nmodel training process is performed with the learning rate\nof 1e\n−3 (with decay rate of 0.96) and batch size of 32. The\nregularization strategy with the weight decay, which is cho-\nsen from the set of{0.1, 0.05, 0.01, 0.005, 0.001}. This is\napplied in the training phase to alleviate the overﬁtting issue.\nPerformance Validation (RQ1)\nWe ﬁrst present the performance of all methods in forecast-\ning the target type of user-item interactions on three datasets\nin Table 2. From the results, we observe that remarkable per-\nformance improvement can be achieved byKHGT on dif-\nferent types of datasets. Such performance gap can be at-\ntributed to the joint exploration of multi-type behavior inter-\ndependencies and the underlying knowledge-aware item col-\nlaborative signals.\nAmong various competitive methods, the recommender\nsystems (e.g., NMTR, NGCF\nM , MBGCN) which consider\nmulti-typed interactions, improve the performance as com-\npared to other baselines. This points to the positive effect of\naggregating multiplex behavioral patterns in the designed in-\nteraction encoding function. Furthermore, GNN-based neu-\nral approaches perform better than autoencoder and autore-\ngressive CF models, suggesting the rationality of exploring\nhigh-order collaborative signals over user-item relations. We\ninvestigate the ranking quality of top-kitems recommended\nby different methods ranging from 1 to 9. Table 3 lists the re-\nsults of Yelp data. We can observe that the best performance\nis always achieved byKHGT under different top-Nsettings.\n4490\nData Metric BiasMF DMF NCF-M NCF-G NCF-N AutoRec CDAE NADE CF-UIcA ST-GCN NGCF NMTR DIPN NGCFM MBGCN MA TN KGA T KHGT\nYelp HR 0.755 0.756 0.714 0.755 0.771 0.765 0.750 0.792 0.750 0.775 0.789 0.790 0.791 0.793 0.796 0.826 0.835 0.880\nNDCG 0.481 0.485 0.429 0.487 0.500 0.472 0.462 0.499 0.469 0.465 0.500 0.478 0.500 0.492 0.502 0.530 0.543 0.603\nMovieLens HR 0.767 0.779 0.757 0.787 0.801 0.658 0.659 0.761 0.778 0.738 0.790 0.808 0.811 0.825 0.826 0.847 0.817 0.861\nNDCG 0.490 0.485 0.471 0.502 0.518 0.392 0.392 0.486 0.491 0.444 0.508 0.531 0.540 0.546 0.553 0.569 0.514 0.597\nRetail HR 0.262 0.305 0.319 0.290 0.325 0.313 0.329 0.317 0.332 0.347 0.302 0.332 0.317 0.374 0.369 0.354 0.377 0.464\nNDCG 0.153 0.189 0.191 0.167 0.201 0.190 0.196 0.191 0.198 0.206 0.185 0.179 0.178 0.221 0.222 0.209 0.214 0.278\nTable 2: Performance comparison on Yelp, MovieLens, Online Retail data, in terms ofHR@k and NDCG@k (k =1 0).\nModel @1 @3 @5 @7 @9\nHR NDCG HR NDCG HR NDCG HR NDCG HR NDCG\nNADE 0.265 0.265 0.508 0.402 0.642 0.454 0.720 0.478 0.784 0.497\nCF-UIcA 0.235 0.235 0.449 0.360 0.576 0.412 0.659 0.440 0.731 0.463\nST-GCN 0.216 0.216 0.445 0.347 0.580 0.400 0.669 0.430 0.744 0.454\nNMTR 0.214 0.214 0.466 0.360 0.610 0.419 0.700 0.450 0.762 0.469\nMA TN 0.279 0.279 0.529 0.423 0.659 0.477 0.741 0.507 0.798 0.524\nKGA T 0.291 0.291 0.546 0.439 0.684 0.496 0.763 0.521 0.823 0.538\nKHGT 0.355 0.355 0.617 0.506 0.748 0.559 0.818 0.583 0.864 0.599\nTable 3: Ranking performance evaluation on Yelp dataset\nwith varying Top-Kvalue in terms ofHR@K and NDCG@K\nModel Ablation Study (RQ2)\nWe consider different model variants of KHGT from ﬁve\nperspectives and analyze their effects (as shown in Figure 3):\nType-speciﬁc Behavioral Pattern Modeling.KHGT-GA.\nWe ﬁrst evaluate the effect of our type-speciﬁc behavior se-\nmantic learning by replacing our attentive heterogeneous in-\nformation aggregation with graph convolutional network.\nBehavior Mutual Dependency Modeling.KHGT-MR. We\nremove the transformer-based mutual relation encoder to\ncapture inter-dependencies of different types of behaviors.\nCross-Type Behavioral Pattern Fusion.KHGT-BF. This\nsimpliﬁed variant directly applies the mean pooling opera-\ntion over the type-speciﬁc behavior representations, instead\nof using the designed gated fusion layer.\nTemporal Context Encoding.KHGT-Ti. This variant does\nnot include the temporal context embedding when perform-\ning information propagation in our graph transformers.\nIncorporation of Item-Item Relations.KHGT-KG. It does\nnot integrate the item-item relations in the framework.\nWe can observe that the full version of our developed\nKHGT achieves the best performance in all cases. We further\nsummarize the conclusions: (1) Modeling the type-speciﬁc\nuser-item interactive patterns in an explicit attentive way,\nis better than performing graph-structured convolutions. (2)\nThe efﬁcacy of augmenting the multi-behavior recommen-\ndation with the underlying mutual relation learning. (3) The\nnecessity of explicit discrimination for the contributions of\ntype-speciﬁc behavior patterns. (4) The positive effect of\ntemporal context information in capturing the behavior dy-\nnamics. (5) The incorporation of item external knowledge\nin our graph neural network is helpful for more accurately\nencoding user’s multi-dimensional preference.\nPerformance v.s. Multi-Behavior Integration (RQ3)\nWe conduct the ablation experiments to validate whether the\nincorporation of more diverse behavior types could boost the\nperformance. The model variants are generated with rubric\nas follows: (1) “+”behavior type indicates only using the tar-\nget behavior itself to make predictions (e.g., +like, +buy).\n(2) “-”behavior type means removing this speciﬁc type of\n(a) Yelp (b) MovieLens (c) Retail\nFigure 3: Ablation studies of sub-modules in KHGT.\n(a) Yelp-HR@k (b) Retail-HR@k\nFigure 4: Impact study of different behavior types on Yelp\nand Online Retail data, in terms ofHR@k and NDCG@k.\ninteractions (e.g., -pv: page-view, -cart: add-to-cart) in fore-\ncasting the user’s target behavior. From the results in Fig-\nure 4, KHGT using all types of interaction behaviors con-\nsistently achieves the best performance compared to other\nvariants, which suggests that more diverse behavior incorpo-\nration could improve the recommendation results with more\ncomprehensive multi-behavior knowledge.\nInﬂuences of Interaction Sparsity Degrees (RQ4)\nwe further perform experiments to evaluate the model per-\nformance with respect to different sparsity levels of user-\nitem interaction data. In particular, each user is grouped in\none of ﬁve different data sparsity degrees in terms of his/her\ninteraction density over items. The bars in the background\nof Figure 5 show the number of users which belong to the\ncorresponding sparsity levels in x-axis. We keep the total\nnumber of interaction summation of each sparsity level as\nthe same. The y-axis shows the recommendation accuracy of\nKHGT and several representative baselines. We can notice\nthat the performance gap between our approach and other\ncompetitors become more signiﬁcant as data becomes more\nsparse, which also ascertains the reasonableness ofKHGT\nin enhancing recommender systems with the capability of\nlearning complex interactive patterns, by modeling inter-\ndependencies among various types of user behaviors.\nHyperparameter Effect Investigation (RQ5)\nWe show the parameter study results ofKHGT in Figure 6.\n• Embedding Dimensionality:d. The model achieves bet-\nter performance when we increased from 4 to 16, since\na larger hidden dimension representation might be bene-\nﬁcial to capture more latent factors for user-item interac-\n4491\n(a) Retail-HR@10 (b) Retail-NDCG@10\nFigure 5: Model performance on the online Retail dataw.r .t.\ndifferent data sparsity, in terms ofHR@10 and NDCG@10.\n5 1 01 52 02 53 0−30\n−20\n−10\n0\nHidden State Dimensionalityd\nNDCG Decrease (%)\nYelp\nMovieLens\nOnline Retail\nDay Week Month Quarter\n−8\n−6\n−4\n−2\n0\nSize of Time Slots\nNDCG Decrease (%)\nYelp\nMovieLens\nOnline Retail\n00 .511 .522 .53\n−40\n−30\n−20\n−10\n0\nNumber of GNN Layers\nNDCG Decrease (%)\nYelp\nMovieLens\nOnline Retail\nFigure 6: Hyper-parameter study for the like/purchase pre-\ndiction in terms ofHR@10 and NDCG@10.\ntions. Due to the overﬁtting phenomenon, the performance\ndegrades with the further increase ofd.\n• Time Resolution of Temporal Encoding:τ(·). The best\nperformance is achieved with the projected time slot of\nweek resolution, which indicates that the weekly interac-\ntive patterns is a good trade-off between the modeling of\nuser-speciﬁc behavior dynamics and interweave correla-\ntions with others.\n• Depth of Graph Neural Network:L. By stacking more\ngraph neural layers to jointly capture the high-order user-\nitem and item-item collaborative relations, the recommen-\ndation performance is improved.KHGT with two recur-\nsive message propagation layers achieves the best results.\n• Sub-graph Sampling Scale N. Table 4 shows the per-\nformance when varying the sampled sub-graph size (mea-\nsured by # of nodes). We observe that training with smaller\nsub-graph size (training with dropout regularization to al-\nleviate overﬁtting), and relatively larger sample scale for\ntest (more graph context is provided for prediction), re-\nsults in better recommendations accuracy.\nCase Studies ofKHGT’s Explainability (RQ6)\nWe visualize the learned explicit relevance scores of our\nKHGT model for predicting purchases on retail data in Fig-\nure 7. We observe that different types of user-item interac-\ntions (4 types) and item-item relations (5 types) are corre-\nlated in a hierarchical and explainable manner (Brighter col-\nors signal higher behavior relevance). In particular, Squares\nand circles represent the learned cross-type behavior depen-\ndencies in our type-wise behavior mutual relation encoder\nand cross-type behavioral pattern fusion, respectively. Both\nﬁrst- and second-order attentive weights are presented.\nRelated Work\nRecommendation with Multi-Relation Modeling. There\nexist many recommender systems which are developed to\ncharacterize user representations, with the consideration of\ndifferent-typed relations from either user or item side (Y u\nTraining N Metric Number of Sub-graph SizeN When Testing\n20,000 30,000 50,000 70,000 90,000 110,000 130,000\n30,000 HR 0.379 0.413 0.452 0.466 0.470 0.473 0.478\n50,000 HR 0.357 0.388 0.433 0.463 0.470 0.476 0.479\n70,000 HR 0.338 0.384 0.429 0.461 0.469 0.478 0.481\nTesting Time (s) 70.3 94.1 148.8 207.8 261.6 309.3 351.7\nTable 4: Inﬂuence of the sub-graph sampling scale.\n/g5/g14/g7/g13/g1/g3/g15/g7/g10 /g2/g12/g13/g13/g7/g9/g6/g15/g8/g12/g11/g14\n/g5/g14/g7/g13/g1/g3/g15/g7/g10 /g2/g12/g13/g13/g7/g9/g6/g15/g8/g12/g11/g14\n/g3/g5/g1/g3/g5/g6\n/g2/g4/g1/g3/g5\n/g5/g14/g7/g13/g1/g3/g15/g7/g10 /g2/g12/g13/g13/g7/g9/g6/g15/g8/g12/g11/g14\n/g2/g4/g1/g3/g5\n/g5/g14/g7/g13/g1/g3/g15/g7/g10 /g2/g12/g13/g13/g7/g9/g6/g15/g8/g12/g11/g14\n/g3/g5/g1/g2/g4 /g3/g5/g1/g3/g5/g6\n/g8/g6/g7/g4/g5/g1/g2/g5\n/g9/g3/g1/g4/g5/g1/g2/g5\n/g3/g5/g1/g2/g4\n/g3/g15/g7/g10/g1/g3/g15/g7/g10 /g4/g7/g9/g6/g15/g8/g12/g11/g14\n/g3/g15/g7/g10/g1/g3/g15/g7/g10 /g4/g7/g9/g6/g15/g8/g12/g11/g14\nFigure 7: Visualized explicit relevance learned by KHGT.\net al. 2018). For example, to alleviate the data sparsity issue,\na lot of social recommender systems have been proposed to\nboost the prediction performance via integrating the user-\nuser social inﬂuential dependencies with the user-item inter-\nactive relations (Huang et al. 2021b; Fan et al. 2019). Fur-\nthermore, another paradigm of multi-relation recommenda-\ntion models leverage external knowledge graph information\nto construct different structural relations between a set of\nentities or items (Wang et al. 2019a,b). Different from them,\nthis work generalizes the joint modeling of multiplex collab-\norative relations and knowledge-aware item dependency in\nthe multi-behavior recommendation.\nGraph Neural Network Recommender Systems. With the\nrecent success of graph neural network in aggregating in-\nformation from various relational data, many graph neural\ntechniques have been proposed to learn user’s preference\nover the graph-structured data for various recommendation\ntasks, such as GraphSAGE (Hamilton, Ying et al. 2017) and\nNGCF (Wang et al. 2019c) for encoding high-order user-\nitem interactions, and GNNs for users’ sequential behavior\nmodeling (Huang et al. 2021a). Inspired by the above re-\nsearch work, we propose a new method KHGT within the\nbroader graph neural paradigm for multi-behavior recom-\nmendation, to solve its unique challenges resulting from re-\nlation heterogeneity between users and items.\nConclusion\nThis paper explicitly models type-speciﬁc user behavioral\npattern in enhancing recommender systems. We devise a\nnovel hierarchical graph transformer network, termed as\nKHGT, to perform the joint information aggregation over\nthe user-item and item-item collaborative relations in mul-\ntiple knowledge-aware behavior modalities. This reﬁnes\ntype-speciﬁc behavior representations and encode their ﬁne-\ngrained interactive preference over items. Evaluation results\non three datasets well validate our framework. Our future\nwork is to fully deploy KHGT in an online working system\nto handing the streaming data in a recursive mode.\n4492\nAcknowledgments\nWe thank the anonymous reviewers for their construc-\ntive feedback and comments. This work is supported by\nNational Nature Science Foundation of China (62072188,\n61672241), Natural Science Foundation of Guangdong\nProvince (2016A030308013), Science and Technology Pro-\ngram of Guangdong Province (2019A050510010).\nReferences\nChen, C.; Zhang, M.; Zhang, Y .; Ma, W.; Liu, Y .; and Ma, S.\n2020. Efﬁcient Heterogeneous Collaborative Filtering with-\nout Negative Sampling for Recommendation. InAAAI, vol-\nume 34, 19–26.\nChen, X.; Xu, H.; Zhang, Y .; Tang, J.; Cao, Y .; Qin, Z.; et al.\n2018. Sequential recommendation with user memory net-\nworks. In WSDM, 108–116. ACM.\nDu, C.; Li, C.; Zheng, Y .; Zhu, J.; and Zhang, B. 2018. Col-\nlaborative ﬁltering with user-item co-autoregressive models.\nIn AAAI.\nFan, W.; Ma, Y .; Li, Q.; He, Y .; Zhao, E.; Tang, J.; and Yin,\nD. 2019. Graph neural networks for social recommendation.\nIn WWW, 417–426.\nGao, C.; He, X.; Gan, D.; Chen, X.; Feng, F.; Li, Y .; Chua,\nT.-S.; and Jin, D. 2019a. Neural multi-task recommendation\nfrom multi-behavior data. InICDE, 1554–1557. IEEE.\nGao, C.; He, X.; Gan, D.; Chen, X.; Feng, F.; Li, Y .; Chua,\nT.-S.; Yao, L.; et al. 2019b. Learning to Recommend with\nMultiple Cascading Behaviors.TKDE .\nGuo, L.; Hua, L.; Jia, R.; Zhao, B.; et al. 2019. Buying\nor Browsing?: Predicting Real-time Purchasing Intent using\nAttention-based Deep Network with Multiple Behavior. In\nKDD, 1984–1992.\nHamilton, W.; Ying, Z.; et al. 2017. Inductive representation\nlearning on large graphs. InNIPS, 1024–1034.\nHe, X.; Liao, L.; Zhang, H.; et al. 2017. Neural collaborative\nﬁltering. In WWW, 173–182.\nHu, Z.; Dong, Y .; Wang, K.; et al. 2020. Heterogeneous\ngraph transformer. InWWW, 2704–2710.\nHuang, C.; Chen, J.; Xia, L.; Xu, Y .; Dai, P .; Chen, Y .;\nBo, L.; Zhao, J.; and Huang, J. 2021a. Graph-Enhanced\nMulti-Task Learning of Multi-Level Transition Dynamics\nfor Session-based Recommendation. InAAAI.\nHuang, C.; Wu, X.; Zhang, X.; Zhang, C.; et al. 2019a. On-\nline Purchase Prediction via Multi-Scale Modeling of Be-\nhavior Dynamics. InKDD, 2613–2622.\nHuang, C.; Xu, H.; Xu, Y .; Dai, P .; Lu, M.; Bo, L.; et al.\n2021b. Knowledge-aware Coupled Graph Neural Network\nfor Social Recommendation. InAAAI.\nHuang, J.; Ren, Z.; Zhao, W. X.; He, G.; Wen, J.-R.; and\nDong, D. 2019b. Taxonomy-aware multi-hop reasoning net-\nworks for sequential recommendation. InWSDM, 573–581.\nJin, B.; Gao, C.; He, X.; Jin, D.; and Li, Y . 2020. Multi-\nbehavior recommendation with graph convolutional net-\nworks. In SIGIR.\nKoren, Y .; Bell, R.; and V olinsky, C. 2009. Matrix factoriza-\ntion techniques for recommender systems. Computer (8):\n30–37.\nLiu, Y .; Xiao, Y .; Wu, Q.; Miao, C.; Zhang, J.; Zhao, B.;\net al. 2020. Diversiﬁed Interactive Recommendation with\nImplicit Feedback. InAAAI, 4932–4939.\nSedhain, S.; Menon, A. K.; Sanner, S.; and Xie, L. 2015. Au-\ntorec: Autoencoders meet collaborative ﬁltering. InWWW,\n111–112.\nSun, F.; Liu, J.; Wu, J.; Pei, C.; Lin, X.; Ou, W.; and Jiang, P .\n2019. BERT4Rec: Sequential recommendation with bidirec-\ntional encoder representations from transformer. InCIKM,\n1441–1450.\nV aswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones,\nL.; Gomez, A. N.; Kaiser, Ł.; et al. 2017. Attention is all\nyou need. InNIPS, 5998–6008.\nWang, H.; Zhang, F.; Zhang, M.; Leskovec, J.; Zhao, M.; Li,\nW.; et al. 2019a. Knowledge-aware graph neural networks\nwith label smoothness regularization for recommender sys-\ntems. In KDD, 968–977.\nWang, X.; He, X.; Cao, Y .; Liu, M.; and Chua, T.-S. 2019b.\nKgat: Knowledge graph attention network for recommenda-\ntion. In KDD, 950–958.\nWang, X.; He, X.; Wang, M.; Feng, F.; et al. 2019c. Neural\nGraph Collaborative Filtering.SIGIR .\nWu, X.; Huang, C.; Zhang, C.; et al. 2020. Hierarchically\nStructured Transformer Networks for Fine-Grained Spatial\nEvent Forecasting. InWWW, 2320–2330.\nWu, Y .; DuBois, C.; et al. 2016. Collaborative denoising\nauto-encoders for top-n recommender systems. InWSDM,\n153–162. A\nCM.\nXia, L.; Huang, C.; Xu, Y .; Dai, P .; Zhang, B.; and Bo, L.\n2020. Multiplex Behavioral Relation Learning for Recom-\nmendation via Memory Augmented Transformer Network.\nIn SIGIR, 2397–2406.\nXue, H.-J.; Dai, X.; Zhang, J.; Huang, S.; et al. 2017. Deep\nMatrix Factorization Models for Recommender Systems. In\nIJCAI, 3203–3209.\nY u, L.; Zhang, C.; Liang, S.; and Zhang, X. 2019. Multi-\norder attentive ranking model for sequential recommenda-\ntion. In AAAI, volume 33, 5709–5716.\nY u, L.; Zhang, C.; Pei, S.; et al. 2018. Walkranker: A uni-\nﬁed pairwise ranking model with multiple relations for item\nrecommendation. In AAAI.\nZhang, J.; Shi, X.; Zhao, S.; and King, I. 2019. Star-gcn:\nStacked and reconstructed graph convolutional networks for\nrecommender systems. InIJCAI.\nZhao, P .; Shui, T.; Zhang, Y .; Xiao, K.; and Bian, K. 2020.\nAdversarial Oracular Seq2seq Learning for Sequential Rec-\nommendation. In IJCAI, 1905–1911.\nZheng, Y .; Tang, B.; Ding, W.; and Zhou, H. 2016. A neural\nautoregressive approach to collaborative ﬁltering. InICML.\n4493",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8497692346572876
    },
    {
      "name": "Recommender system",
      "score": 0.7444181442260742
    },
    {
      "name": "Embedding",
      "score": 0.47999924421310425
    },
    {
      "name": "Graph",
      "score": 0.4349968135356903
    },
    {
      "name": "Information retrieval",
      "score": 0.39122307300567627
    },
    {
      "name": "Human–computer interaction",
      "score": 0.36263784766197205
    },
    {
      "name": "Artificial intelligence",
      "score": 0.31238290667533875
    },
    {
      "name": "Theoretical computer science",
      "score": 0.22417369484901428
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I90610280",
      "name": "South China University of Technology",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210136793",
      "name": "Peng Cheng Laboratory",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I18014758",
      "name": "Simon Fraser University",
      "country": "CA"
    }
  ],
  "cited_by": 205
}