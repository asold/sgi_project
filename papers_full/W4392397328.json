{
  "title": "Code Detection for Hardware Acceleration Using Large Language Models",
  "url": "https://openalex.org/W4392397328",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2909861670",
      "name": "Pablo Antonio Martinez",
      "affiliations": [
        "Huawei Technologies (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A2164303472",
      "name": "Gregorio Bernabé",
      "affiliations": [
        "Universidad de Murcia"
      ]
    },
    {
      "id": "https://openalex.org/A2101951528",
      "name": "José Manuel García",
      "affiliations": [
        "Universidad de Murcia"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6796761347",
    "https://openalex.org/W6680532216",
    "https://openalex.org/W4367185264",
    "https://openalex.org/W3030163527",
    "https://openalex.org/W6850936240",
    "https://openalex.org/W6810081322",
    "https://openalex.org/W6796783112",
    "https://openalex.org/W3036079062",
    "https://openalex.org/W3175004880",
    "https://openalex.org/W4360620450",
    "https://openalex.org/W4309468401",
    "https://openalex.org/W3015614227",
    "https://openalex.org/W2073061372",
    "https://openalex.org/W4309674289",
    "https://openalex.org/W2155893237",
    "https://openalex.org/W4379259169",
    "https://openalex.org/W6838865847",
    "https://openalex.org/W4246166885",
    "https://openalex.org/W3122286897",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W4311887664",
    "https://openalex.org/W4318620922",
    "https://openalex.org/W3115222751",
    "https://openalex.org/W6849898756",
    "https://openalex.org/W2282866165",
    "https://openalex.org/W1553894716",
    "https://openalex.org/W6810738896",
    "https://openalex.org/W4293149165",
    "https://openalex.org/W6847363464",
    "https://openalex.org/W6850886341",
    "https://openalex.org/W2035476608",
    "https://openalex.org/W6694513646",
    "https://openalex.org/W6850625674",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W6810162553",
    "https://openalex.org/W6851775633",
    "https://openalex.org/W6809646742",
    "https://openalex.org/W6850202480",
    "https://openalex.org/W4281862314",
    "https://openalex.org/W6853465110",
    "https://openalex.org/W6852874933",
    "https://openalex.org/W4283026156",
    "https://openalex.org/W4360836968",
    "https://openalex.org/W4377130677",
    "https://openalex.org/W4311000453",
    "https://openalex.org/W4321649710",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W2998704965",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W2273440736",
    "https://openalex.org/W3170863103",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4321177655",
    "https://openalex.org/W4281557260",
    "https://openalex.org/W4221161695",
    "https://openalex.org/W4362515116",
    "https://openalex.org/W4353112996",
    "https://openalex.org/W4380353763"
  ],
  "abstract": "Large language models (LLMs) have been massively applied to many tasks, often surpassing state-of-the-art approaches. While their effectiveness in code generation has been extensively studied (e.g., AlphaCode), their potential for code detection remains unexplored. This work presents the first analysis of code detection using LLMs. Our study examines essential kernels, including matrix multiplication, convolution, fast-fourier transform and LU factorization, implemented in C/C&#x002B;&#x002B;. We propose both a preliminary, naive prompt and a novel prompting strategy for code detection. Results reveal that conventional prompting achieves great precision but poor accuracy (67.5&#x0025;, 22.5&#x0025;, 79.5&#x0025; and 64&#x0025; for GEMM, convolution, FFT and LU factorization, respectively) due to a high number of false positives. Our novel prompting strategy substantially reduces false positives, resulting in excellent overall accuracy (91.2&#x0025;, 98&#x0025;, 99.7&#x0025; and 99.7&#x0025;, respectively). These results pose a considerable challenge to existing state-of-the-art code detection methods.",
  "full_text": "Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000.\nDigital Object Identifier 10.1 109/ACCESS.2023.1 120000\nCode Detection for Hardware Acceleration Using\nLarge Language Models\nPABLO ANTONIO MARTÍNEZ1, GREGORIO BERNABÉ1 and JOSÉ MANUEL GARCÍA1 (MEMBER,\nIEEE)\n1Computer Engineering Department, University of Murcia, Murcia, Spain (e-mails: pabloantonio.martinezs@um.es, gbernabe@um.es, jmgarcia@um.es)\n2\n3\nCorresponding author: Gregorio Bernabé (e-mail: gbernabe@um.es).\nGrant TED2021-129221B-I00 funded by MCIN/AEI/10.13039/501100011033 and by the ‘‘European Union NextGenerationEU/PRTR’’,\nand Grant PID2022-136315OB-I00 funded by MCIN/AEI/10.13039/501100011033/ and by ‘‘ERDF A way of making Europe’’, EU.\nABSTRACT Large language models (LLMs) have been massively applied to many tasks, often surpassing\nstate-of-the-art approaches. While their effectiveness in code generation has been extensively studied (e.g.,\nAlphaCode), their potential for code detection remains unexplored.\nThis work presents the first analysis of code detection using LLMs. Our study examines essential kernels,\nincluding matrix multiplication, convolution, fast-fourier transform and LU factorization, implemented in\nC/C++. We propose both a preliminary, naive prompt and a novel prompting strategy for code detection.\nResults reveal that conventional prompting achieves great precision but poor accuracy (67.5%, 22.5%, 79.5%\nand 64% for GEMM, convolution, FFT and LU factorization, respectively) due to a high number of false\npositives. Our novel prompting strategy substantially reduces false positives, resulting in excellent overall\naccuracy (91.2%, 98%, 99.7% and 99.7%, respectively). These results pose a considerable challenge to\nexisting state-of-the-art code detection methods.\nINDEX TERMS Code Detection, Compilers, Heterogeneous computing, High performance computing,\nLarge Language Model\nI. INTRODUCTION AND MOTIVATION\nI\nN recent years, transformer-based models have superseded\nstate-of-the-art neural network models for all kinds of\ntasks, like computer vision [1], natural language processing\n(NLP) [33], speech recognition [35] or translation [21]. One\nof the most impressives models based on the transformer\narchitecture [40] are large language models (LLMs). A LLM\nis no more than a language model trained with significantly\nlarger training data than traditional language models. In\nessence, LLMs are probability distributions over sequences\nof words. That is to say, language models aim to understand\nand generate text, just like humans do.\nLLMs are provoking impressive impact in diverse deep\nlearning fields, thanks to their impressive abilities to perform\ndiverse tasks [17], [42]. The extensive list of applications\nwhere LLMs work well implies that there may still be un-\nexplored possibilities awaiting discovery. In particular, even\nthough LLMs are proven to work for code synthesis [42],\ntheir evaluation in code detection remains unexplored. Code\ndetection involves analyzing programs to identify the algo-\nrithms they contain, which is crucial in numerous areas of\nprogramming language research. A notable application of\ncode detection is to match and replace handwritten code with\noptimized libraries.\nSpecialized hardware accelerators provide massive perfor-\nmance and energy efficiency improvements over traditional\nmicroprocessors [8]. However, there is a lot of code that is\nalready written for CPUs, so executing it on accelerators is\nnot trivial. Detecting parts of acceleratable code and replacing\nit with appropriate API calls is a novel approach to over-\ncome these issues. This technique has many advantages, like\nimproving the performance of a hardcoded implementation\nor offloading compute-heavy tasks to accelerators automati-\ncally. Many works focused on this topic [9], [13], [23], [45],\nwhich rely either on constrained-based pattern matching or\nneural network-based code detection. Those code detection\ntechniques are generally either brittle, unable to match com-\nplex code, or inefficient in recognizing code patterns. On\nthe contrary, LLMs are trained with a huge corpus of source\ncode, so code detection is a field where LLMs can potentially\noutstand.\nDespite LLM powers, it is still challenging to exploit their\nVOLUME 11, 2023 1\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3372853\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nfull capabilities because they are susceptible to the prompt.\nLLMs can suffer from different kinds of faults, like halluci-\nnation [15], which has motivated the emergence of a new dis-\ncipline called prompt engineering. Prompt engineering aims\nto build prompts for maximizing the performance of LLMs.\nHowever, depending on the specific application, different\nprompt engineering methods shall be used because not all\nwork well for every situation.\nThis paper proposes a novel methodology that leverages\nLLMs to perform code detection. More specifically, we in-\nvestigate the use of the GPT-3.5 platform and OpenAI’s API\nfor code detection tasks. To evaluate its performance, we build\na benchmark suite consisting of significant and computation-\nally intensive algorithms from computer science. Although\nthis evaluation does not cover all possible algorithms, it pro-\nvides proof of how LLMs perform at code detection. Our\nevaluation demonstrates that GPT-3.5 successfully detects a\n93% of matrix multiplication (GEMM), 100% convolution,\n100% fast-Fourier transform (FFT), and 93.3% LU factor-\nization programs. Furthermore, we evaluate GPT-3.5 using a\nbenchmark containing diverse program implementations that\ndo not include the target algorithms. This evaluation reveals\na false positive rate of 44%, 80%, 21%, and 37% for GEMM,\nconvolution, FFT, and LU factorization, respectively. We in-\nvestigate the causes of this issue and propose a novel prompt-\ning strategy for code detection using prompt engineering.\nUsing our novel proposal, we significantly reduce the false\npositive rates to 5.9% for GEMM, 1.6% for convolution, and\n0.0% for FFT and LU factorization, significantly improving\nthe accuracy. Our results affirm the viability of LLMs, specif-\nically GPT-3.5, for code detection tasks, no matter what kind\nof algorithm we want to detect. This indicates that LLMs\nhave a great potential for integration with existing compila-\ntion techniques to replace handwritten code with accelerated\nimplementations.\nThis paper makes the following contributions:\n• We present the first analysis on code detection using\nlarge language models.\n• We propose a novel prompting strategy for code detec-\ntion that drastically improves LLM performance at code\ndetection tasks.\n• We evaluate GPT-3.5 in code detection against matrix\nmultiplication, convolution, and fast-fourier-transform\nprograms, as well as several other programs to evaluate\nGPT-3.5 false positive rates.\nThe rest of this paper is organized as follows. Section II\npresents the background on prompt engineering and large lan-\nguage models, code detection techniques, and their applica-\ntions for hardware acceleration. We present our methodology\nto use GPT-3.5 API for code detection in Section III. Sec-\ntion IV shows our prompt engineering work, divided into two\napproaches, the second being a novel prompting technique for\ncode detection. In Section V we evaluate the accuracy of each\nprompting technique, showing that GPT-3.5 is indeed a code\ndetection tool for hardware acceleration. Finally, Section VI\nconcludes the work and gives hints and suggestions for future\nwork.\nII. BACKGROUND AND RELATED WORK\nA. LARGE LANGUAGE MODELS (LLMS)\nLarge Language Models (LLMs) refer to a family of language\nmodels, based on the transformer architecture [40] containing\nbillions of parameters that are trained on massive datasets\ncontaining text [42]. Generative Pre-trained Transformer 3\n(GPT-3) is a 175 billion parameter LLM released in 2020 by\nOpenAI [4]. Two years later, OpenAI released a new subclass,\nGPT-3.5, which is the base of the popular ChatGPT, a chatbot\nfine-tuned for conversations that have caused a massive shock\nin society [5], [11]. OpenAI’s last release is GPT-4 [32], a new\nversion in the GPT series, which has shown impressive results\nin many tasks, leading us to think that we are approaching\nartificial general intelligence (AGI) [5]. Other notable LLMs\ninclude Pathways Language Model (PaLM) [6] (Google) or\nLLaMA [39] (Meta).\nApplications where LLM exceeds are uncountable. From\ncoding to mathematical abilities, LLMs’ power focuses on\nnatural language tasks. One particular aspect of LLM is their\ncapability to show abilities that are not present in small mod-\nels but arise in large models [48]. Generally speaking, we can\norganize these abilities into three domains: in-context learn-\ning (ICL), instruction following and step-by-step reasoning\n(e.g., chain-of-thought) [42], [48]. ICL consists of prompt-\ning LLMs with a question in natural language description\nalong with several demonstrations and a test query [42]. In\ninstruction following, tasks are described in the form of in-\nstructions. With instruction tuning, LLMs can follow the task\ninstructions for new tasks without using explicit examples,\nthus improving their ability to generalize. Lastly, step-by-\nstep prompting includes several intermediate reasoning steps,\nwhich LLMs can use to perform complex reasoning.\nB. PROMPT ENGINEERING\nLanguage models are designed to imitate and predict the next\ntoken given a sequence of tokens as input [2], which explains\nwhy LLMs are extremely sensitive to the prompt. Thus, it is\ncrucial to understand how to provide good prompts to LLMs\nin order to achieve good-quality outputs. In this sense, prompt\nengineering covers a set of techniques to improve the commu-\nnication between humans and LLMs. Prompts are instructions\ngiven to an LLM to specify the quality and quantity of the\noutput, enforce rules in the output, etcetera. Prompting can\nactually also be considered as a form of programming an\nLLM since we are giving precise instructions of how and what\nto do [44]. In that respect, recent works have proposed new\nlanguages to aid programming of LLMs [3], [27].\nZero-shot prompting is the most straightforward prompt-\ning technique, where the prompt contains only instructions\ndescribing the task. On the contrary, few-shot prompting\nconsists of providing additional examples or demonstrations\nof the model. This technique can improve LLM performance\non complex tasks, where zero-shot prompting is not enough.\n2 VOLUME 11, 2023\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3372853\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nLike humans, LLMs are thought to be capable of perform-\ning reasoning [26]. In this line, one critical prompt engineer-\ning technique to improve reasoning is called chain-of-thought\n(CoT) [43]. With CoT, the prompt is spread out across a larger\nsequence of tokens. Instead of prompting the model with\njust the question, CoT prompts include examples of chain-\nof-thought sequences of the task. In this sense, CoT is an\ninstance of few-shot prompting, proposing a simple solution\nby modifying the answers in few-shot examples to step-by-\nstep answers [18].\nAnother relevant technique is called self-consistency [41].\nIntuitively, it is based on the idea that we, as humans, think\nin different ways. In tasks requiring reasoning, it is natural\nto have several ways to attack the problem. Self-consistency\nconsists in prompting the model using CoT multiple times to\nsample a diverse set of reasoning paths. Afterward, it selects\nthe most consistent answer by marginalizing all the available\nanswers in the answer set. This method has proved to be\neffective in several scenarios [41].\nA more complex technique, based on the previous ap-\nproaches of CoT and self-consistency is tree-of-thoughts\n(ToT) [46]. This paradigm allows LLMs to explore multiple\nreasoning paths over thoughts. In this context, a thought\nis considered a part of the final solution. ToT prompting\ninvolves defining four key aspects: how to decompose the\nintermediate process into thoughts, how to generate potential\nthoughts from each state, how to evaluate each state and what\nsearch algorithm to use. This technique has shown promising\nresults in solving complex tasks such as Game of 24, Creative\nWriting, and Crosswords [46].\nA simpler, yet crucial aspect of prompting is controlling the\nformat of the output. For example, it is useful to use delimiters\nto demarcate sections of text to be treated differently [30].\nOther techniques for controlling the output format are speci-\nfying the desired length of the output or the format and order\nin which each part of the output should be presented.\nC. PROGRAMMING HARDWARE ACCELERATORS\nSpecialized hardware accelerators provide massive perfor-\nmance and energy efficiency improvements over traditional\nmicroprocessors [8], necessary to overcome the challenges of\nincreasingly complex and compute-demanding applications.\nInstead of using one device (CPU) for everything, accel-\nerators are specialized for a given domain. The benefit of\nmicroprocessors’ generality is their ease of adaption, but at\nthe same time, it is their source of inefficiency. However, ac-\ncelerators are highly diverse [34], which makes programming\nparticularly hard.\nTo write new code for accelerators, the typical approach\nis writing software in the programming language specifically\ndesigned for that accelerator. For existing code (e.g., a pro-\ngram written in a general-purpose language) there is a better\nalternative than rewriting the program using the accelerator-\nspecific language. This alternative involves replacing parts\nof the code with calls to the accelerator API [9], [13]. By\nutilizing libraries that target the accelerator API, this ap-\nproach allows the compilation of old code, effectively using\nthe accelerator without the need for extensive code rewriting.\nTo replace accelerable parts of code with calls to an op-\ntimized library, the compiler must accomplish two distinct\ntasks. First, the compiler must detect parts of the code that\nare suitable for replacement. Second, the compiler must find\nthe mappings between the variables in the original program\nand the variables in the library. In this work, we focus on\nexploiting LLMs to achieve the first task, code detection,\nwhich discovers the accelerable parts of the code that are\ncandidates for replacement.\nD. CODE DETECTION\nCode detection approaches in the literature can be divided into\ntwo categories:\n• Constraint-based matching: Also known as pattern-\nbased matching, consists in finding constraints and pat-\nterns in the code that can be matched into a previ-\nously defined set of constraints [29]. Idiom Description\nLanguage (IDL) [13] proposed a description language\nthat allows the user to define constraints for detecting\nparticular idioms. Idioms are later translated into a set of\nconstraints over the LLVM IR [19], which are used by\nthe compiler to match the corresponding code. In [12],\nauthors also focus on idiom matching and rewriting, but\nthe idiom specification aims to be easier to understand.\nBesides, idioms are translated into MLIR [20] dialects\nrather than LLVM IR. Similarly, a pattern constraint-\nbased approach is used in KernelFaRer [9], where au-\nthors focus primarily on detecting matrix-multiplication\n(GEMM) and SYR2K kernels. Here, constraints are\nhardcoded inside the compiler, and the user can not\nmodify them. Constraint-based matching is, however,\nvery brittle and generally unable to match complex code\nstructures [23].\n• Neural embeddings: A neural network is trained to\ndetect the code. This is a more modern approach to code\ndetection [23], [45], which uses neural embeddings to\ndetect accelerateable regions. In [45] and [23], the neural\nclassifier is based on ProGraML [7], and it is trained\nusing the OJClone dataset [28], containing 105 classes\nof different algorithms, each implemented in different\nways. New algorithms not present in the dataset can be\neasily identified by adding examples of that particular\nalgorithm to the dataset, which will make the neural\nclassifier learn how to identify them. The downside of\ncurrent neural embedding proposals is their low accu-\nracy. They perform well to guide the search of a given al-\ngorithm but although they can match more complex code\nstructures, they are less reliable compared to constraint-\nbased matching.\nAbove mentioned techniques aid to find and categorize sec-\ntions of code, but they do not provide any guarantee that those\nsections are correctly identified, which can potentially lead to\nfaulty compilation. Therefore, some verification is typically\nVOLUME 11, 2023 3\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3372853\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\ncoupled with code detection to prove that the code was iden-\ntified correctly and works as expected. Besides formal veri-\nfication techniques, other approaches rely on comparing the\noutput of the code with the output of a valid program (input-\noutput validation) [23], [45]. Despite the efforts to ensure\nthe correctness of code, programmer sign-off is ultimately\nrequired.\nIII. USING GPT-3.5 TO ANALYZE CODE\nA. USING THE API\nAt the time of writing, OpenAI’s models (GPT-3.5, GPT-\n4) and Claude are the most competitive general-purpose\nLLMs [47] 1. Another LLM to consider is AlphaCode [22],\na model specifically trained to generate code. However, it\nis not publicly available, and it is limited to code genera-\ntion, not code detection. While Claude and GPT-4 are in\na limited beta (they are only accessible to those who have\nbeen granted access), GPT-3.5 (the base model for Chat-\nGPT) is publicly available [31]. In this work, we use the\ngpt-3.5-turbo-16k model (the most capable GPT-3.5\nmodel, according to OpenAI [31]) with the OpenAI API. The\n16k suffix simply indicates that this model has a 16k context\nwindow, in contrast to the standard GPT-3.5 model which\nhas a context window of 4k tokens. Having a larger context\nwindow allows to analyze larger codes that otherwise would\nnot fit in 4k or fewer tokens. We believe that the proposals\nshown in this work are applicable to any other LLM and that\nresults shall be similar.\nWe designed a simple wrapper around the OpenAI API\nwritten in Python. It is responsible for reading the source\ncode, prompting the gpt-3.5-turbo-16k model with the\ncode, and parsing the output. As we will see in Section IV,\nour prompt includes formatting instructions. However, some-\ntimes GPT-3.5 produces outputs that do not match exactly\nthe specified output format. This motivates the need for a\nsimple parser (detailed in Section IV-C), which allows our\nPython program to interpret the output (e.g., to understand\nwhen a program is correctly classified and when it is not).\nThe API can be configured with parameters such as the role\nof the temperature and nucleus sampling parameters. The role\nparameter indicates how the model should behave (acting as\nin a given role, such as system, user, assistant, or function).\nTemperature and nucleus sampling ( top_p parameter) al-\nlows for control of the sampling of the model. Both are ways\nto control the sampling, so it is recommended to alter only one\nof those, but not both. Intuitively, higher temperature values\nwill make the output more random, while lower values will\nmake it more deterministic.\nB. THE DATASET\nIn this work, we focus on detecting C/C++ codes, so all codes\nin our dataset are implemented in one of those languages. We\nidentify three key kernels in code detection works, as well\nas one uncommon kernel. GEMM is clearly the one that gets\n1Ranking available at: https://chat.lmsys.org/?leaderboard\nmost of the attention [9], [13], [23]. Fast-fourier transform\n(FFT) and convolution are also studied in the literature [23],\n[45]. We also include LU factorization codes to explore the\npossibility of extending code detection works to less common\nkernels, which could challenge GPT-3.5 detection capabili-\nties. To create the dataset, we explored GitHub C/C++ code\nperforming any of those four kernels. To better understand\nthe quality of GPT-3.5 code detection, we focused on finding\ndifferent implementations of each algorithm.\n1) GEMM\nWe identified and gathered 7 classes of matrix multiplica-\ntions:\n• Naive: Implementations with the traditional 3-loop\nstructure.\n• Unrolled: Implementation with unrolled loops.\n• Function Calls: Implementations dividing the compute\ninto different function calls.\n• Tiled: Tiled implementations.\n• Goto: Implementations using the Goto algorithm [14].\n• Strassen: Implementations using the Strassen algo-\nrithm [37].\n• Intrinsics: Implementations using Intel intrinsics.\n2) Convolution\nWe found 3 different implementations:\n• Winograd: The Winograd algorithm.\n• Direct: The direct convolution algorithm.\n• im2col+gemm: Uses a method called im2col to compute\nthe convolution using GEMM (e.g., like the Caffe frame-\nwork [16]).\n3) FFT\nWe retrieved 3 different implementations:\n• DFT: Discrete fourier transform implementations.\n• Radix-2: Computes the DFTs of the even-indexed and\nthe odd-indexed inputs separately and then combines\nboth.\n• Recursive: Recursive implementations.\n4) LU factorization\nWe analyzed 4 different implementations:\n• Naive: Naive implementations.\n• Pivoting: LU factorization with full or partial pivoting.\n• Tiled: Tiled implementations.\n• Intrinsics: Implementations using Intel intrinsics.\n5) False Positives\nAlso, we are interested in measuring the exposure of the\nmodel to false positives. Therefore, we also included pro-\ngrams not explicitly containing the four aforementioned al-\ngorithms. We differentiate this part of the dataset between\nmainstream and non-mainstream code. For the mainstream\ncode, we included the Parboil benchmark [38], a set of ap-\nplications for benchmarking the performance and throughput\n4 VOLUME 11, 2023\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3372853\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nTABLE 1. Source code dataset description (available at [24])\nCode Number of Codes Total LoC\nReal Code\nGEMM 128 11.3k\nConvolution 15 2.8k\nFFT 15 1.8k\nLU 15 1.9k\nTotal 158 16.0k\nFalse\nPositives\nParboil 10 1.4k\nCaffe 182 42.3k\nACOTSP 13 2.8k\ncpufetch 22 5.7k\nTotal 227 54.2k\nof processors, and Caffe [16], a deep learning framework.\nThose programs are somewhat popular and it is easy to find\nsimilar implementations of those applications in the wild.\nBesides, the Parboil benchmark contains a matrix-vector mul-\ntiplication, which can be helpful to understand the sensibility\nof the model, since it is a kernel very similar to matrix\nmultiplication. For the non-mainstream code, we included\ncpufetch [10], a program that gathers CPU architecture infor-\nmation, and an Ant Colony Optimization (ACO) implemen-\ntation [25]. Furthermore, for those codes that unintentionally\ncontained GEMM, convolution, FFT or LU, we removed\nthem from the dataset to make sure that those codes do not\ncontain such algorithms. A description of the dataset is shown\nin Table 1.\nC. FEEDING GPT-3.5 WITH CODE\nTo feed the model with code, we simply copy and paste the\ncode into the prompt. In other words, we use crude code\nstraight into the model. It is worth noting that LLMs have an\ninput token limit, meaning that they can only process inputs\nsmaller than their limit. If the code is larger than the token\nlimit, we identify two ways of processing the input. First,\ndecreasing the token count of the code. The idea is to reduce\nthe token count without changing the code semantics (e.g.,\nreplacing spaces with tabs). Removing comments, removing\ndead code, or reducing the length of variables and function\nnames are also viable, but they might hurt the model’s ability\nto reason about code. Second, partition the code into smaller\nparts. For example, partitioning the original program into n\npartitions. In our case, however, none of the codes surpassed\nthe 16k token limit, so we can safely feed GPT-3.5 with code\nwithout additional modifications.\nIV. PROMPT ENGINEERING\nOne of the most common tips for good prompting is to start\nwith a simple prompt and then iterate over more complex and\ncomplete prompts. Here we describe our prompt engineering\nprocess in which we started with a very first prompt and a\nsecond version of the prompt that is aimed to improve it.\nA. FIRST PROMPT\nThe first prompt is detailed in Figure 1. In this prompt, the\nkeyword * algorithm* is replaced by the specific algorithm\nFIGURE 1. First prompt.\nI want to know if the code below contains any function\nperforming a * algorithm*. Please ignore functions\nwhose definition is not visible.\nDesired format:\nYes: function name (if there is a function).\nNo (if there is no function)\nCode:‘‘‘‘‘‘\n*the actual code *\n’’’’’’\nwe are looking for. That is, * algorithm* may take the value\nof ‘‘matrix multiplication (GEMM)’’, ‘‘convolution’’, ‘‘fast\nFourier transform (FFT)’’ or ‘‘LU factorization (LU)’’. Also,\nthe keyword * the actual code * is replaced by the code itself.\nFirst, we naturally ask the model to search for the specific\nalgorithm we are interested in. We also ask the model to\nignore functions whose code is not visible. In this sense,\nwe are concerned about hallucinations. Because the model\nhas been trained with large code bases, it could have been\ntrained with the same code (at least, parts of the code) that\nwe will be analyzing. This can lead the model to think that it\nknows the code for unseen functions, which is actually wrong\nbecause supposing that a function with the same name and\narguments corresponds to another function is no more than\nan assumption.\nNext, we specify the output format. We use ‘‘Desired\noutput’’ to clearly indicate that follows the output format\nspecification. To make the output easy to parse, we ask the\nmodel to output ‘‘Yes’’ or ‘‘Not’’, followed by the name of\nthe function (or functions) in case the answer is affirmative.\nAfterward, we simply paste the code between three quotation\nmarks to delimit the beginning and end of the source code.\nB. SECOND PROMPT\nIn the first prompt, we have clearly stated the task to perform.\nThus, we expect to have good detection results when the\ncode contains any of the algorithms. However, it is not clear\nhow the prompt allows the discard of false positives or the\nreduction of hallucination effects. Hence, the second iteration\nof the prompt tries to accomplish this matter.\nWe considered using several prompt engineering tech-\nniques like chain-of-thought [18], [43], self-consistency [41],\nor tree-of-thoughts [46]. However, none of these techniques\napply to code detection. First, code detection does not follow\nany reasoning to conclude whether a code corresponds to a\nclass of algorithms or not (it is more of a classification-like\ntask). Second, all of these techniques focus on improving\nVOLUME 11, 2023 5\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3372853\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nthe reasoning capabilities of LLMs in complex tasks, not\nmitigating hallucinations. Previous works have highlighted\nthat LLMs are able to identify when they have produced a\nwrong answer [36]. This, however, requires several prompts.\nThe first one contains the task to be performed by the LLM,\nand the second, where the LLM can use self-reflection to\nidentify whether the previous answer is valid or not. This two-\nstep prompting of describing the task in a first prompt and\nrealizing that it was wrong in a second prompt inspired us to\npropose a novel prompting technique for code detection.\nFIGURE 2. Second prompt (part 1).\nCan you explain what the following code does?\nCode:‘‘‘‘‘‘\n*the actual code *\n’’’’’’\nFIGURE 3. Second prompt (part 2).\nDoes the code contain any function performing a\n*algorithm*? Please ignore functions whose definition\nis not visible.\nDesired format:\nYes: function name (if there is a function).\nNo (if there is no function)\nThe second prompt is composed of two phases which are\nshown in Figures 2 and 3. Rather than following a zero-shot\napproach (like in the first prompt) here we use two prompts.\nIn the first part, we simply ask the model to explain what is the\ncode doing. Leaving the model to freely explain what the code\ndoes works very well because it is very easy for the model to\nunderstand what the task is. Most of the time, the explanations\ngiven by the model at this step are correct (hallucinations are\nnot present, or at least are very rare). Once the model has\nanalyzed the code, we ask, in a second prompt, if the code\ncontains a given algorithm.\nPlease note the difference between this and the previous\nprompt. Previously, we asked directly whether the code con-\ntained an algorithm. Now, we ask the model to describe\nthe code and then we ask if in that ‘‘description’’ that the\nmodel gave is found the algorithm in question. In essence,\nfalse positives may arise in the first prompt (e.g., the model\nwrongly identifying parts of the code) but it is way less\nprobable than asking directly to check for the algorithm. In\ncontrast, false positives may not appear as a consequence\nof the second prompt because the model is simply reusing\nthe information previously given. Thus, we expect to reduce\nhallucination effects with this technique, while maintaining\nsimilar detection results.\nC. OUTPUT FORMATTING\nWhen the model’s output matches exactly the expected out-\nput, the wrapper does not perform any parsing. Here is a\ndescription of the rules that the wrapper applies when the\noutput does not match:\n• If the expected answer is positive, e.g.: ‘‘Yes: (func-\ntion list)’’: The wrapper removes the following sub-\nstrings from the output: ‘‘\\nNo’’, ‘‘\\n’’, ‘‘.’’, ‘‘()’’ (where\n\\n is a new line). This makes it possible to accept outputs\nthat contain outputs containing any ‘‘garbage’’.\n• If the expected answer is negative, e.g.: ‘‘No’’: The\nwrapper removes the following substrings, which we\nobserved that occasionally appear: ‘‘the code does not\ncontain any function’’, ‘‘there is no function’’, ‘‘the\ncode does not contain any function’’ and ‘‘there is no\nfunction’’.\nV. EVALUATION\nA. SETUP\nWe evaluate the GPT-3.5 model using the source code dataset\nshown in Section III-B with the two proposed prompts. More\nprecisely, we use model=‘gpt-3.5-turbo-16k’,\ntemperature=0.0, top_p=1.0 and max_tokens=512.\nThe selected model allows inputs up to 16K tokens, allowing\nus to analyze larger codes, which would not be possible with\nthe default GPT-3.5 model (which supports inputs with up\nto 4K tokens). We aim to obtain answers as deterministic\nas possible, so we set top_p to 1.0 (the default value) and\nonly modify temperature, which we set to 0. Lastly,\nmax_tokens sets the maximum number of allowed tokens\nin the output, which we limit to 512 since it is enough for the\nfirst step of the second prompt.\nIn programs with multiple valid functions (e.g., multiple\nfunctions performing a GEMM), we expect the model to find\nthe outermost function. For each prompt, we show the confu-\nsion matrix and also a summary matrix that presents how each\nalgorithm is classified. In the false positives evaluation for a\ngiven algorithm, we also include real programs from other\nalgorithms (e.g., for GEMM, we add convolution, FFT, and\nLU codes to the false positives dataset). Besides, we provide\na detailed explanation of why the model was unable to find\nthe algorithm. We identify three types of errors:\n• Error 1: GPT-3.5 thinks there is no function, where there\nis actually at least one.\n• Error 2: GPT-3.5 finds at least one function, but not the\none we are looking for (the outermost).\n• Error 3: Wrong output format (the output is right, but the\nPython wrapper is not able to parse it).\n6 VOLUME 11, 2023\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3372853\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nT N\nActual\nT (119)\n93%\n(9)\n7%\nN (121)\n44.5%\n(151)\n55.5%\nGEMM\nPredicted\nT N\n(15)\n100%\n(0)\n0%\n(310)\n80.5%\n(75)\n19.5%\nCONV\nT N\n(15)\n100%\n(0)\n0%\n(82)\n21.3%\n(303)\n78.7%\nFFT\nT N\n(14)\n93.3%\n(1)\n6.7%\n(143)\n37.1%\n(242)\n62.9%\nLU\nTABLE 2. Confusion matrices for GEMM, CONV, FFT and LU (first prompt).\nB. FIRST PROMPT\nTable 2 shows the confusion matrix for the four analyzed\nalgorithms. True positive results are excellent in all cases,\nachieving 93% in GEMM, 93.3% in LU, and 100% in convo-\nlution and FFT codes. This seems to indicate that the model\ncan confidently analyze the code and find if the algorithm is\npresent or not. Conversely, the number of false positives is\nexceedingly high in the four algorithms, and it is even more\nnotable in the case of GEMM and convolution. Alternatively,\nwe can compute the accuracy of the model as:\nAccuracy = TP + TN\nTP + TN + FP + FN\nwhich, using data from Table 2, yields a poor accuracy\nfor Convolution (22.5%), followed by LU (64%), GEMM\n(67.5%) and FFT (79.5%). Despite the high precision, the\naccuracy is severely harmed due to the high false positive\nrate. Results indicate that the model tends to answer our\nquestions affirmatively rather than reasoning about the code\nand answering accordingly.\nRegarding output consistency according to the rules set\nin the prompt, we found that the rules implemented in the\nwrapper (described in Section IV-C) are rarely triggered. For\nthe case where the expected output is affirmative, the most\nsimple rules, like removing a dot, are triggered, but not very\noften. In fact, when the output is negative, rules never get\ntriggered. This indicates that the output formatting rules in\nthe prompt work consistently well since very little parsing is\nneeded.\nTable 3 presents the type of false negatives for each algo-\nrithm. The most common case is caused by the model not giv-\ning a valid output format. Here we mostly found issues with\nC++ formatting, where our Python wrapper was expecting to\nfind the name of the function, but the model also includes\nC++ artifacts. The model answered a valid function, but not\nthe outermost function in two cases, while the rest correspond\nto the model simply answering that there were no functions\nmatching the algorithm.\nGEMM CONV FFT LU\nError 1 2 0 0 0\nError 2 2 0 0 1\nError 3 5 0 0 0\nTotal 9 0 0 1\nTABLE 3. Summary of false negatives types (first prompt).\nRegarding false positives, results show that the model gets\nconfused and identifies algorithms where they are not. It\nis worth noticing that these false positives always occur on\nfunctions that are defined and declared in the code. The only\nexception to this rule is found in Caffe, where we found that\nthe model also triggers false positives in functions that contain\n‘‘GEMM’’ in the function name, even if they are not defined\nor declared. It seems reasonable to think that such functions\nperform matrix multiplication, but if code is not available it\nis only an assumption that the model is unable to confirm.\nThis appears to be a clear example of external hallucination\nsince the model thinks to know the content of the function,\nwhich is actually unavailable. We also observed clear cases of\nhallucination in some programs where there was no function\nto detect but the model gave an output with a length equal\nto max_tokens (e.g., exhausting the output) repeating one\nfunction name over and over.\n119\n93%\n123\n96.1%\n38\n29.7%\n59\n46.1%\n15\n100%\n15\n100%\n7\n46.7%\n9\n60%\n10\n66.7%\n15\n100%\n15\n100%\n11\n73.3%\n10\n66.7%\n11\n73.3%\n2\n13.3%\n14\n93.3%\n5\n50%\n7\n70%\n2\n20%\n2\n20%\n75\n41.2%\n140\n76.9%\n29\n15.9%\n54\n29.7%\n4\n30.8%\n7\n53.8%\n4\n30.8%\n6\n46.2%\n2\n9.1%\n7\n31.8%\n0\n0%\n2\n9.1%\nGEMM\nCONV\nFFT\nLU\nParboil\nCaffe\nACOTSP\ncpufetch\nGEMM CONV FFT LU\nReal\nPredicted\nFIGURE 4. Summary of the confusion matrix (first prompt).\nFigure 4 depicts the results summary for the first prompt,\nshowing for each algorithm (GEMM, CONV , FFT, LU) in the\nx-axis, the percentage of matched programs against each code\ntype (in the y-axis). Ideally, we would like to have as high\nvalues as possible for the diagonal of the first four elements\nwhile the rest of the cells are as close to zero as possible.\nHaving high values in the diagonal indicates high true positive\nVOLUME 11, 2023 7\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3372853\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nrates, while low values in the rest of the figure indicate low\nfalse positives. In the first prompt, we find high values in the\ndiagonal, as well as in the rest of the figure. The highest false\npositive rates are found when we ask the model if a GEMM\nprogram contains any convolution (96.1%), and when we\nask if convolution or FFT programs contain GEMMs (100%\nin both cases). Results evidence that the model gets easily\nconfused when mixing GEMM and convolution (asking for\nGEMM in convolution programs and vice versa). This might\nbe motivated by the fact that both have relatively similar code\nstructures and that sometimes convolutions are implemented\nwith matrix multiplications. However, we also find surpris-\ningly high false positives when analyzing other codes. In the\nParboil benchmark, we obtain rates as high as 50% and 70%\nfor GEMM and convolution, respectively. This benchmark\nsuite contains programs for evaluating the performance of\nmicroprocessors, which also have certain similarities with\nGEMM and convolution. In Caffe, the false positive rate is\nalso high. The model gets easily confused with this code\nbecause many of them have functions containing ‘‘gemm’’\nor ‘‘conv’’ in the code. However, most of the time, they are\nsimply function calls rather than function definitions. It is\nsurprising to find that the model gets confused with these even\nthough we explicitly asked to ignore functions whose defi-\nnition is not visible. Also, sometimes functions are visible,\nbut they do not perform GEMM or convolutions explicitly\nin the code. Lastly, we also found surprisingly high false\npositive values in ACOTSP-MF and cpufetch, even though\nthose programs have in no way any similar code to GEMM\nor convolution.\nC. SECOND PROMPT\nTable 4 shows the confusion matrix using the second prompt.\nThe first thing that draws attention is the true positives. They\nare very similar to the one we had in the first prompt, but\nthey are slightly lower. However, the number of false positives\nhas decreased significantly, with only 5.9%, 1.6%, 0.0% and\n0.0% for GEMM, convolution, FFT and LU, respectively.\nThese results confirm that our prompt proposal drastically\nimproves the accuracy of the model, which raises to 91.2%,\n98%, 99.7% and 99.7%, respectively.\nIn the second prompt, we found that the rules implemented\nin the wrapper (shown in Section IV-C) are much more likely\nto be triggered than in the first prompt. Specifically, rules for\nthe case where the expected output is negative were never\ntriggered in the first prompt, but they are sometimes triggered\nin this prompt. These results indicate that the output specifi-\ncation is less robust in the second prompt compared to the\nfirst one which showed to be pretty reliable.\nWe analyze the failure reasons for the second prompt in\nTable 5. The majority of failures are found in Error 2, (e.g.,\nwhen the model finds at least one function performing a\nmatrix multiplication, but it is not the one we were expecting\nto find). Besides, we still have the same problems in GEMM\nprograms where the model does not comply with the output\nformat that we expect, which makes the wrapper unable to\nT N\nActual\nT (109)\n85.2%\n(19)\n14.8%\nN (16)\n5.9%\n(256)\n94.1%\nGEMM\nPredicted\nT N\n(13)\n86.7%\n(2)\n13.3%\n(6)\n1.6%\n(379)\n98.4%\nCONV\nT N\n(14)\n93.3%\n(1)\n6.7%\n(0)\n0%\n(385)\n100%\nFFT\nT N\n(14)\n93.3%\n(1)\n6.7%\n(0)\n0%\n(385)\n100%\nLU\nTABLE 4. Confusion matrices for GEMM, CONV, FFT and LU (second\nprompt).\nGEMM CONV FFT LU\nError 1 1 1 0 0\nError 2 11 1 1 1\nError 3 7 0 0 0\nTotal 19 2 1 1\nTABLE 5. Summary of false negatives types (second prompt).\nparse the output.\nIn the second prompt, false positives only arise when look-\ning for GEMM and convolution in Caffe, and when looking\nfor GEMM in convolution codes. As we mentioned in the first\nprompt, the model had two types of false positives in Caffe.\nThe majority were functions declared and defined in the\ncode, while a minority were undefined functions containing\n‘‘gemm’’ in the name. In the second prompt, all the false\npositives from Caffe correspond to the second class. This\nindicates that the model still hallucinates with functions that\nhave ‘‘gemm’’ in its name, while the other false negatives\nhave completely disappeared. Lastly, in convolution codes,\nwe can still find some cases where the code is purely per-\nforming a convolution but the model reports it as performing\na matrix multiplication. Sometimes, it happens because the\ncode contains a matrix multiplication inside the reported\nfunction, but it does not mean that the function performs ma-\ntrix multiplication exclusively (which is what we are asking).\nHowever, we believe that these issues should be fixed with\nmore powerful models (e.g., GPT-4) or code-specific models\n(e.g., AlphaCode)\nVI. CONCLUSIONS AND FUTURE WORK\nLarge Language Model’s scale and complexity have grown\nmassively in the last few years. ChatGPT, in particular, and\n8 VOLUME 11, 2023\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3372853\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\n109\n85.2%\n0\n0.0%\n0\n0.0%\n0\n0.0%\n3\n20%\n13\n86.7%\n0\n0.0%\n0\n0.0%\n0\n0.0%\n0\n0.0%\n14\n93.3%\n0\n0.0%\n0\n0.0%\n0\n0.0%\n0\n0.0%\n14\n93.3%\n0\n0.0%\n0\n0.0%\n0\n0.0%\n0\n0.0%\n12\n6.6%\n6\n3.3%\n0\n0.0%\n0\n0.0%\n0\n0.0%\n0\n0.0%\n0\n0.0%\n0\n0.0%\n0\n0.0%\n0\n0.0%\n0\n0.0%\n0\n0.0%\nGEMM\nCONV\nFFT\nLU\nParboil\nCaffe\nACOTSP\ncpufetch\nGEMM CONV FFT LU\nReal\nPredicted\nFIGURE 5. Summary of the confusion matrix (second prompt).\nLLMs, in general, have caused a massive impact on society\ndue to the enormous potential of these models for greatly\ndiverse natural language tasks. We also expect those models\nto keep scaling and improving in the near future, so finding\nnew applications where these models excel is key for fully\nexploiting them. A field not previously explored with LLMs\nwas code detection, which is key for many applications in pro-\ngramming language research. Particularly, it has been studied\nto achieve code lifting, a technique that consists in replacing\nhandwritten code with a call to an optimized library. Previous\nwork has approached this topic either with constraint-based\nmatching or with neural embeddings plus input/output equiv-\nalence, which can be costly for large codes.\nIn this work, we have explored the application of LLMs\nto code detection for the first time. Specifically, we evalu-\nated GPT-3.5 in code detection with matrix multiplication\n(GEMM), convolution, fast-fourier transform (FFT), and LU\nfactorization algorithms. After designing our first prompt for\ncode detection, the model showed an accuracy of 67.5%,\n22.5%, 79.5%, and 64% for GEMM, convolution, FFT, and\nLU factorization, respectively. False positives, triggered by\nhallucinations, are the reason to explain such poor results. In\nthe second prompt, we introduced a novel approach for code\ndetection that achieved an accuracy of 91.2%, 98%, 99.7%,\nand 99.7%, respectively. The new prompt drastically reduces\nthe number of false positives which, still occurring, are way\nless frequent. Despite not being trained specifically for code\ndetection, GPT-3.5 results are truly impressive, reaching an\naccuracy very close to 100%.\nRather than using raw code input, we aim to explore al-\nternative approaches in future research. Instead of analyzing\nprogram files individually, we are interested in developing\na novel methodology that focuses on analyzing the program\nfunction by function. This approach would involve creating\na dataflow graph that captures the interconnections between\nthe functions defined in the program. Adopting this approach\nwould allow us to analyze the entire code structure as opposed\nto processing one file at a time. Additionally, we are intrigued\nby the performance of other models like GPT-4 or other LLMs\ntrained specifically on source code. We anticipate that these\nmodels will achieve even better results, pushing the limits\nfurther towards achieving 100% accuracy.\nAVAILABILITY OF DATA AND MATERIALS\nThe data can be provided upon request.\nREFERENCES\n[1] Hangbo Bao, Li Dong, Songhao Piao, and Furu Wei. BEiT: BERT Pre-\nTraining of Image Transformers, 2022. arXiv: 2106.08254.\n[2] Yoshua Bengio, Réjean Ducharme, Pascal Vincent, and Christian Janvin.\nA Neural Probabilistic Language Model. Journal of Machine Learning\nResearch (JMLR), 3:1137–1155, mar 2003.\n[3] Luca Beurer-Kellner, Marc Fischer, and Martin Vechev. Prompting Is\nProgramming: A Query Language for Large Language Models. Proc. ACM\nProgram. Lang., 7(PLDI), jun 2023. doi: 10.1145/3591300.\n[4] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Ka-\nplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,\nAmanda Askell, Sandhini Agarwal, Ariel Herbert-V oss, Gretchen Krueger,\nTom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey\nWu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz\nLitwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam\nMcCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language\nModels are Few-Shot Learners, 2020. arXiv: 2005.14165.\n[5] Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke,\nEric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lund-\nberg, Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro, and Yi Zhang.\nSparks of Artificial General Intelligence: Early experiments with GPT-4,\n2023. arXiv: 2303.12712.\n[6] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma,\nGaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung,\nCharles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha\nTsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay,\nNoam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben\nHutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Is-\nard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, San-\njay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant\nMisra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David\nLuan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi,\nDavid Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanu-\nmalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica\nMoreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou,\nXuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta,\nJason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov,\nand Noah Fiedel. PaLM: Scaling Language Modeling with Pathways,\n2022. arXiv: 2204.02311.\n[7] Chris Cummins, Zacharias V . Fisches, Tal Ben-Nun, Torsten Hoefler,\nMichael F P O’Boyle, and Hugh Leather. ProGraML: A Graph-based Pro-\ngram Representation for Data Flow Analysis and Compiler Optimizations.\nIn Marina Meila and Tong Zhang, editors, Proceedings of the 38th Inter-\nnational Conference on Machine Learning , volume 139 of Proceedings of\nMachine Learning Research , pages 2244–2253. PMLR, 18–24 Jul 2021.\n[8] William J. Dally, Yatish Turakhia, and Song Han. Domain-Specific\nHardware Accelerators. Commun. ACM , 63(7):48–57, jun 2020. doi:\n10.1145/3361682.\n[9] João P. L. De Carvalho, Braedy Kuzma, Ivan Korostelev, José Nelson Ama-\nral, Christopher Barton, José Moreira, and Guido Araujo. KernelFaRer: Re-\nplacing Native-Code Idioms with High-Performance Library Calls. ACM\nTrans. Archit. Code Optim. , 18(3), jun 2021. doi: 10.1145/3459010.\n[10] Dr-Noob. cpufetch: Simple yet fancy CPU architecture fetching tool, 2023.\ndoi: 10.5281/zenodo.7902464.\n[11] Yogesh K. Dwivedi, Nir Kshetri, Laurie Hughes, Emma Louise\nSlade, Anand Jeyaraj, Arpan Kumar Kar, Abdullah M. Baabdullah,\nAlex Koohang, Vishnupriya Raghavan, Manju Ahuja, Hanaa Albanna,\nMousa Ahmad Albashrawi, Adil S. Al-Busaidi, Janarthanan Balakrishnan,\nYves Barlette, Sriparna Basu, Indranil Bose, Laurence Brooks, Dimitrios\nBuhalis, Lemuria Carter, Soumyadeb Chowdhury, Tom Crick, Scott W.\nCunningham, Gareth H. Davies, Robert M. Davison, Rahul Dé, Denis\nVOLUME 11, 2023 9\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3372853\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nDennehy, Yanqing Duan, Rameshwar Dubey, Rohita Dwivedi, John S. Ed-\nwards, Carlos Flavián, Robin Gauld, Varun Grover, Mei-Chih Hu, Marijn\nJanssen, Paul Jones, Iris Junglas, Sangeeta Khorana, Sascha Kraus, Kai R.\nLarsen, Paul Latreille, Sven Laumer, F. Tegwen Malik, Abbas Mardani,\nMarcello Mariani, Sunil Mithas, Emmanuel Mogaji, Jeretta Horn Nord,\nSiobhan O’Connor, Fevzi Okumus, Margherita Pagani, Neeraj Pandey,\nSavvas Papagiannidis, Ilias O. Pappas, Nishith Pathak, Jan Pries-Heje,\nRamakrishnan Raman, Nripendra P. Rana, Sven-V olker Rehm, Samuel\nRibeiro-Navarrete, Alexander Richter, Frantz Rowe, Suprateek Sarker,\nBernd Carsten Stahl, Manoj Kumar Tiwari, Wil van der Aalst, Viswanath\nVenkatesh, Giampaolo Viglia, Michael Wade, Paul Walton, Jochen Wirtz,\nand Ryan Wright. Opinion Paper: ‘‘So what if ChatGPT wrote it?’’\nMultidisciplinary perspectives on opportunities, challenges and implica-\ntions of generative conversational AI for research, practice and policy.\nInternational Journal of Information Management , 71:102642, 2023. doi:\n10.1016/j.ijinfomgt.2023.102642.\n[12] Vinicius Espindola, Luciano Zago, Hervé Yviquel, and Guido Araujo.\nSource Matching and Rewriting for MLIR Using String-Based Automata.\nACM Trans. Archit. Code Optim. , 20(2), mar 2023. doi: 10.1145/3571283.\n[13] Philip Ginsbach, Toomas Remmelg, Michel Steuwer, Bruno Bodin,\nChristophe Dubach, and Michael F. P. O’Boyle. Automatic Matching of\nLegacy Code to Heterogeneous APIs: An Idiomatic Approach. SIGPLAN\nNot., 53(2):139–153, mar 2018. doi: 10.1145/3296957.3173182.\n[14] Kazushige Goto and Robert A. van de Geijn. Anatomy of High-\nPerformance Matrix Multiplication. ACM Trans. Math. Softw. , 34(3), may\n2008. doi: 10.1145/1356052.1356053.\n[15] Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko\nIshii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. Survey of hallu-\ncination in natural language generation. ACM Comput. Surv. , 55(12), mar\n2023. doi: 10.1145/3571730.\n[16] Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan\nLong, Ross Girshick, Sergio Guadarrama, and Trevor Darrell. Caffe:\nConvolutional Architecture for Fast Feature Embedding, 2014. arXiv:\n1408.5093.\n[17] Jan Kocoń, Igor Cichecki, Oliwier Kaszyca, Mateusz Kochanek, Do-\nminika Szydło, Joanna Baran, Julita Bielaniewicz, Marcin Gruza, Arka-\ndiusz Janz, Kamil Kanclerz, Anna Kocoń, Bartłomiej Koptyra, Wikto-\nria Mieleszczenko-Kowszewicz, Piotr Miłkowski, Marcin Oleksy, Maciej\nPiasecki, Łukasz Radliński, Konrad Wojtasik, Stanisław Woźniak, and\nPrzemysław Kazienko. ChatGPT: Jack of all trades, master of none, 2023.\narXiv: 2302.10724.\n[18] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and\nYusuke Iwasawa. Large Language Models are Zero-Shot Reasoners, 2023.\narXiv: 2205.11916.\n[19] Chris Lattner and Vikram Adve. Llvm: a compilation framework for\nlifelong program analysis & transformation. In International Symposium\non Code Generation and Optimization, 2004. CGO 2004. , pages 75–86,\n2004. doi: 10.1109/CGO.2004.1281665.\n[20] Chris Lattner, Mehdi Amini, Uday Bondhugula, Albert Cohen, Andy\nDavis, Jacques Pienaar, River Riddle, Tatiana Shpeisman, Nicolas Vasi-\nlache, and Oleksandr Zinenko. Mlir: Scaling compiler infrastructure for\ndomain specific computation. In 2021 IEEE/ACM International Sympo-\nsium on Code Generation and Optimization (CGO) , pages 2–14, 2021. doi:\n10.1109/CGO51591.2021.9370308.\n[21] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdel-\nrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer.\nBART: Denoising Sequence-to-Sequence Pre-training for Natural Lan-\nguage Generation, Translation, and Comprehension. In Proceedings of\nthe 58th Annual Meeting of the Association for Computational Linguistics ,\npages 7871–7880. Association for Computational Linguistics, July 2020.\ndoi: 10.18653/v1/2020.acl-main.703.\n[22] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian\nSchrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix\nGimeno, Agustin Dal Lago, et al. Competition-level code generation\nwith AlphaCode. Science, 378(6624):1092–1097, 2022. doi:\n10.1126/science.abq1158.\n[23] Pablo Antonio Martínez, Jackson Woodruff, Jordi Armengol-Estapé, Gre-\ngorio Bernabé, José Manuel García, and Michael F. P. O’Boyle. Matching\nLinear Algebra and Tensor Code to Specialized Hardware Accelerators.\nIn Proceedings of the 32nd ACM SIGPLAN International Conference on\nCompiler Construction, CC 2023, page 85–97, New York, NY , USA, 2023.\nAssociation for Computing Machinery. doi: 10.1145/3578360.3580262.\n[24] Pablo Antonio Martínez, Gregorio Bernabé, and José Manuel García. GPT\nCodes Dataset, 2023. doi: 10.5281/zenodo.8154364.\n[25] Pablo Antonio Martínez and José Manuel García. ACOTSP-MF: A\nmemory-friendly and highly scalable ACOTSP approach. Engineer-\ning Applications of Artificial Intelligence , 99:104131, 2021. doi:\n10.1016/j.engappai.2020.104131.\n[26] Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpan-\ntis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick,\nJane Dwivedi-Yu, Asli Celikyilmaz, Edouard Grave, Yann LeCun, and\nThomas Scialom. Augmented Language Models: a Survey, 2023. arXiv:\n2302.07842.\n[27] Microsoft. Guidance: A guidance language for controlling large lan-\nguage models, 2023. https://github.com/microsoft/guidance (Accessed\nJune 2023).\n[28] Lili Mou, Ge Li, Lu Zhang, Tao Wang, and Zhi Jin. Convolutional\nNeural Networks over Tree Structures for Programming Language Pro-\ncessing. In Proceedings of the Thirtieth AAAI Conference on Artifi-\ncial Intelligence , AAAI’16, pages 1287–1293. AAAI Press, 2016. doi:\n10.5555/3015812.3016002.\n[29] Flemming Nielson, Hanne R. Nielson, and Chris Hankin. Principles of\nProgram Analysis. Springer Publishing Company, Incorporated, 2010. doi:\n10.1007/978-3-662-03811-6.\n[30] OpenAI. GPT best practices. https://platform.openai.com/docs/guides/\ngpt-best-practices (Accessed June 2023).\n[31] OpenAI. GPT Models. https://platform.openai.com/docs/models (Ac-\ncessed May 2023).\n[32] OpenAI. GPT-4 Technical Report, 2023. arXiv: 2303.08774.\n[33] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright,\nPamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex\nRay, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie\nSimens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and\nRyan Lowe. Training language models to follow instructions with human\nfeedback, 2022. arXiv: 2203.02155.\n[34] Biagio Peccerillo, Mirco Mannino, Andrea Mondelli, and Sandro Bartolini.\nA survey on hardware accelerators: Taxonomy, trends, challenges, and\nperspectives. Journal of Systems Architecture , 129:102561, 2022. doi:\n10.1016/j.sysarc.2022.102561.\n[35] Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine\nMcLeavey, and Ilya Sutskever. Robust Speech Recognition via Large-Scale\nWeak Supervision, 2022. arXiv: 2212.04356.\n[36] Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik\nNarasimhan, and Shunyu Yao. Reflexion: Language Agents with Verbal\nReinforcement Learning, 2023. arXiv: 2303.11366.\n[37] V olker Strassen. Gaussian elimination is not optimal. Numerische Mathe-\nmatik, 13(4):354–356, Aug 1969. doi: 10.1007/BF02165411.\n[38] John A Stratton, Christopher Rodrigues, I-Jui Sung, Nady Obeid, Li-Wen\nChang, Nasser Anssari, Geng Daniel Liu, and Wen-mei W Hwu. Parboil:\nA revised benchmark suite for scientific and commercial throughput com-\nputing. Center for Reliable and High-Performance Computing , 127:27,\n2012.\n[39] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-\nAnne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric\nHambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard\nGrave, and Guillaume Lample. LLaMA: Open and Efficient Foundation\nLanguage Models, 2023. arXiv: 2302.13971.\n[40] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion\nJones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. Attention\nis All you Need. In I. Guyon, U. V on Luxburg, S. Bengio, H. Wallach,\nR. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural\nInformation Processing Systems, volume 30. Curran Associates, Inc., 2017.\n[41] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan\nNarang, Aakanksha Chowdhery, and Denny Zhou. Self-Consistency Im-\nproves Chain of Thought Reasoning in Language Models, 2023. arXiv:\n2203.11171.\n[42] Wayne Xin Zhao and Kun Zhou and Junyi Li and Tianyi Tang and Xiaolei\nWang and Yupeng Hou and Yingqian Min and Beichen Zhang and Junjie\nZhang and Zican Dong and Yifan Du and Chen Yang and Yushuo Chen and\nZhipeng Chen and Jinhao Jiang and Ruiyang Ren and Yifan Li and Xinyu\nTang and Zikang Liu and Peiyu Liu and Jian-Yun Nie and Ji-Rong Wen. A\nSurvey of Large Language Models, 2023. arXiv: 2303.18223.\n[43] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter,\nFei Xia, Ed Chi, Quoc Le, and Denny Zhou. Chain-of-Thought Prompting\nElicits Reasoning in Large Language Models, 2023. arXiv: 2201.11903.\n[44] Jules White, Quchen Fu, Sam Hays, Michael Sandborn, Carlos Olea, Henry\nGilbert, Ashraf Elnashar, Jesse Spencer-Smith, and Douglas C. Schmidt.\n10 VOLUME 11, 2023\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3372853\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nA Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT,\n2023. arXiv: 2302.11382.\n[45] Jackson Woodruff, Jordi Armengol-Estapé, Sam Ainsworth, and Michael\nF. P. O’Boyle. Bind the Gap: Compiling Real Software to Hardware FFT\nAccelerators. In Proceedings of the 43rd ACM SIGPLAN International\nConference on Programming Language Design and Implementation , PLDI\n2022, page 687–702, New York, NY , USA, 2022. Association for Comput-\ning Machinery. doi: 10.1145/3519939.3523439.\n[46] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths,\nYuan Cao, and Karthik Narasimhan. Tree of Thoughts: Deliberate Problem\nSolving with Large Language Models, 2023. arXiv: 2305.10601.\n[47] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao\nWu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao\nZhang, Joseph E. Gonzalez, and Ion Stoica. Judging LLM-as-a-judge with\nMT-Bench and Chatbot Arena, 2023. arXiv: 2306.05685.\n[48] Barret Zoph, Colin Raffel, Dale Schuurmans, Dani Yogatama, Denny\nZhou, Don Metzler, Ed H. Chi, Jason Wei, Jeff Dean, Liam B. Fedus,\nMaarten Paul Bosma, Oriol Vinyals, Percy Liang, Sebastian Borgeaud,\nTatsunori B. Hashimoto, and Yi Tay. Emergent abilities of large language\nmodels. Transactions on Machine Learning Research (TMLR) , 2022.\nPABLO A. MARTÍNEZreceived his M.S. and Ph.D. degree in Computer\nScience from the University of Murcia in 2020 and 2023, respectively. His re-\nsearch focuses on high-performance computing, acceleration of bio-inspired\nalgorithms, acceleration of deep learning applications, and heterogeneous\ncomputing. He has published some refereed journals and conferences in these\nfields, including JCR journals like Engineering Applications of Artificial\nIntelligence. He also works as a Ph.D. assistant professor at the University\nof Murcia, teaching computer architecture.\nGREGORIO BERNABÉ received the M.S. and Ph.D. degrees in Computer\nScience from the University of Murcia (Spain) in 1997 and 2004, respec-\ntively. In 1998, he joined the Computer Engineering Department of the\nUniversity of Murcia and became an Associate Professor in May 2004. He\nhas developed several courses on Computer Structure and Computer Archi-\ntecture. He is currently working on two main research lines: Heterogeneous\ncomputing using CMP architectures, GPUs, and accelerators (XPUs), and\ndeep neural network learning process using HPC techniques to improve the\nperformance of medical applications. He has published more than 50 refereed\npapers in different journals and conferences, including JCR journals such\nas Journal of Supercomputing, Journal of Computer Methods and Programs\nin Biomedicine, Journal of Scientific Programming, International Journal of\nParallel Programming and Journal of Computational Science.\nJOSÉ M. GARCÍAis a Professor of Computer Architecture at the University\nof Murcia (Spain) and the founding member and head of the Research Group\non Parallel Architecture and Computing (GACOP). His research interest has\nalways focused on the topic of Supercomputing. It started within the line\nof the interconnection network for high-performance computing systems.\nSubsequently, research work was carried out on issues of improving the\nperformance of single-chip multiprocessors (CMPs), paying particular at-\ntention to the internal architecture of the chip, the coherence of the caches,\nand virtualization. He is currently working on two main research lines:\nHeterogeneous computing using CMP architectures, GPUs, and accelerators\n(XPUs), and Acceleration of bio-inspired algorithms, bioinformatics algo-\nrithms, and deep neural network learning process using HPC techniques.\nHe has directed eighteen Doctoral Theses and has published more than 150\nrefereed articles in international journals and conferences.Prof. García is a\nmember of HiPEAC, the European Network of Excellence in Architecture\nand High-Performance Integrated Compilation. Furthermore, he is also a\nmember of various international associations such as the IEEE and ACM.\nVOLUME 11, 2023 11\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3372853\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8112826943397522
    },
    {
      "name": "Fast Fourier transform",
      "score": 0.7244367599487305
    },
    {
      "name": "Convolution (computer science)",
      "score": 0.7008578181266785
    },
    {
      "name": "Code (set theory)",
      "score": 0.6911815404891968
    },
    {
      "name": "False positive paradox",
      "score": 0.6649048328399658
    },
    {
      "name": "Acceleration",
      "score": 0.5693439245223999
    },
    {
      "name": "Parallel computing",
      "score": 0.5476133823394775
    },
    {
      "name": "Factorization",
      "score": 0.5231443643569946
    },
    {
      "name": "Matrix decomposition",
      "score": 0.4218078851699829
    },
    {
      "name": "State (computer science)",
      "score": 0.41526052355766296
    },
    {
      "name": "Algorithm",
      "score": 0.4108262062072754
    },
    {
      "name": "Computer engineering",
      "score": 0.3283451795578003
    },
    {
      "name": "Programming language",
      "score": 0.3093981146812439
    },
    {
      "name": "Artificial intelligence",
      "score": 0.289398193359375
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.0
    },
    {
      "name": "Eigenvalues and eigenvectors",
      "score": 0.0
    },
    {
      "name": "Artificial neural network",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Classical mechanics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I80180929",
      "name": "Universidad de Murcia",
      "country": "ES"
    },
    {
      "id": "https://openalex.org/I4210160618",
      "name": "Huawei Technologies (United Kingdom)",
      "country": "GB"
    }
  ]
}