{
  "title": "Integrating Expert Knowledge into Large Language Models Improves Performance for Psychiatric Reasoning and Diagnosis",
  "url": "https://openalex.org/W4412538325",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2146284142",
      "name": "Karthik V. Sarma",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": null,
      "name": "Kaitlin E Hanss",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": "https://openalex.org/A2115697378",
      "name": "Andrew J.M. Halls",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": "https://openalex.org/A2766058590",
      "name": "Andrew Krystal",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": "https://openalex.org/A2160379227",
      "name": "Daniel F. Becker",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": "https://openalex.org/A2026190185",
      "name": "Anne L. Glowinski",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": "https://openalex.org/A284454978",
      "name": "Atul J. Butte",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": "https://openalex.org/A2146284142",
      "name": "Karthik V. Sarma",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Kaitlin E Hanss",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2115697378",
      "name": "Andrew J.M. Halls",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2766058590",
      "name": "Andrew Krystal",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2160379227",
      "name": "Daniel F. Becker",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2026190185",
      "name": "Anne L. Glowinski",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A284454978",
      "name": "Atul J. Butte",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4281687410",
    "https://openalex.org/W4401179701",
    "https://openalex.org/W4366294487",
    "https://openalex.org/W2103393020",
    "https://openalex.org/W4385970234",
    "https://openalex.org/W4399836687",
    "https://openalex.org/W4401933482",
    "https://openalex.org/W4391440996",
    "https://openalex.org/W4401917171",
    "https://openalex.org/W4389156617",
    "https://openalex.org/W2118347738",
    "https://openalex.org/W3128304793",
    "https://openalex.org/W4402193259",
    "https://openalex.org/W4376872703",
    "https://openalex.org/W4317757464",
    "https://openalex.org/W4396832979",
    "https://openalex.org/W4393284353",
    "https://openalex.org/W4403001813",
    "https://openalex.org/W4391995913",
    "https://openalex.org/W4403229099",
    "https://openalex.org/W4396691546",
    "https://openalex.org/W4385373745",
    "https://openalex.org/W4281483047"
  ],
  "abstract": "Abstract Purpose and Methods The authors sought to evaluate the performance of common large language models (LLMs) in psychiatric diagnosis, and the impact of integrating expert-derived reasoning on their performance. Clinical case vignettes and associated diagnoses were retrieved from the DSM-5-TR Clinical Cases book. Diagnostic decision trees were retrieved from the DSM-5-TR Handbook of Differential Diagnosis and refined for LLM use. Three LLMs were prompted to provide diagnosis candidates for the vignettes either by directly prompting or using the decision trees. These candidates and diagnostic categories were compared against the correct diagnoses. The positive predictive value (PPV), sensitivity, and F 1 statistic were used to measure performance. Principal Results When directly prompted to predict diagnoses, the best LLM by F 1 statistic (gpt-4o) had sensitivity of 77.6% and PPV of 43.3%. When making use of the refined decision trees, PPV was significantly increased (65.3%) without a significant reduction in sensitivity (71.8%). Across all experiments, the use of the decision trees statistically significantly increased the PPV, significantly increased the F 1 statistic in 5/6 experiments, and significantly reduced sensitivity only for the category-based evaluation in 2/3 experiments. Major Conclusions When used to predict psychiatric diagnoses from case vignettes, direct prompting of the LLMs yielded most true positive diagnoses but had significant overdiagnosis. Integrating expert-derived reasoning into the process using decision trees improved LLM performance, primarily by suppressing overdiagnosis with minimal negative impact on sensitivity. This suggests that the integration of clinical expert-derived reasoning could improve the performance of LLM-based tools in the behavioral health setting.",
  "full_text": " \n1 \n \nIntegra(ng Expert Knowledge into Large Language Models Improves \nPerformance for Psychiatric Reasoning and Diagnosis \nKarthik V Sarma MD PhD†a,b, Kaitlin E Hanss MD MPHa, Andrew J M Halls MDa, Andrew Krystal MDa, Daniel F \nBecker MDa, Anne L Glowinski MD MPEa, Atul J BuDe MD PhD*a,b \naDepartment of Psychiatry and Behavioral Sciences, University of California San Francisco, 675 18th Street, \nSan Francisco, CA 94143 \nbBakar ComputaRonal Health Sciences InsRtute, University of California San Francisco, 550 16th Street, San \nFrancisco, CA, 94143 \n* In memoriam \n† Corresponding author: \nKarthik V Sarma MD PhD \nDepartment of Psychiatry and Behavioral Sciences \nUniversity of California San Francisco \n675 18th Street, Box 3134 \nSan Francisco, CA 94143 \nkarthik.sarma@ucsf.edu \nFunding: This work was supported by the NaRonal InsRtute of Mental Health of the NaRonal InsRtutes of \nHealth [grant number R25 MH060482].  \nPrevious Presenta1on: The authors appreciated the opportunity to present early parRal components of this \nproject at the annual meeRngs of the Northern California Psychiatric Society (conference abstract/poster, \nMar 16, 2024), the American Medical InformaRcs AssociaRon (conference abstract/talk, Nov 12, 2024), the \nTechnology in Psychiatry Summit (symposium abstract/talk, Dec 7, 2024), and the American College of \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\n \n2 \n \nNeuropsychopharmacology (conference abstract/poster, Dec 10, 2024). No text, tables or ﬁgures used in \nthese presentaRons were reused for this work.  \nKeywords: diagnosis, DSM, arRﬁcial intelligence, generaRve arRﬁcial intelligence, psychiatry, reasoning, \ndecision support \n \nAbstract \nPurpose and Methods: \nThe authors sought to evaluate the performance of common large language models (LLMs) in psychiatric \ndiagnosis, and the impact of integraRng expert-derived reasoning on their performance. Clinical case \nvigneDes and associated diagnoses were retrieved from the DSM-5-TR Clinical Cases book. DiagnosRc \ndecision trees were retrieved from the DSM-5-TR Handbook of DiﬀerenRal Diagnosis and reﬁned for LLM use. \nThree LLMs were prompted to provide diagnosis candidates for the vigneDes either by directly prompRng or \nusing the decision trees. These candidates and diagnosRc categories were compared against the correct \ndiagnoses. The posiRve predicRve value (PPV), sensiRvity, and F1 staRsRc were used to measure performance. \nPrincipal Results: \nWhen directly prompted to predict diagnoses, the best LLM by F1 staRsRc (gpt-4o) had sensiRvity of 77.6% \nand PPV of 43.3%. When making use of the reﬁned decision trees, PPV was signiﬁcantly increased (65.3%) \nwithout a signiﬁcant reducRon in sensiRvity (71.8%). Across all experiments, the use of the decision trees \nstaRsRcally signiﬁcantly increased the PPV, signiﬁcantly increased the F1 staRsRc in 5/6 experiments, and \nsigniﬁcantly reduced sensiRvity only for the category-based evaluaRon in 2/3 experiments. \nMajor Conclusions: \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n3 \n \nWhen used to predict psychiatric diagnoses from case vigneDes, direct prompRng of the LLMs yielded most \ntrue posiRve diagnoses but had signiﬁcant overdiagnosis. IntegraRng expert-derived reasoning into the \nprocess using decision trees improved LLM performance, primarily by suppressing overdiagnosis with \nminimal negaRve impact on sensiRvity. This suggests that the integraRon of clinical expert-derived reasoning \ncould improve the performance of LLM-based tools in the behavioral health sejng. \n \n1. Introduc0on \nThe rapid advancement of arRﬁcial intelligence (AI)-based technologies over the course of the last decade \nhas led to dramaRc innovaRon in healthcare technology across a wide variety of funcRonal areas and clinical \ndomains. Stemming both from rapid advancements in processing hardware and theoreRcal computer \nscience, AI methods have proven parRcularly applicable to healthcare, with recent major results and novel \nproducts in radiology (Sarma et al., 2021), ophthalmology (Lim et al., 2024; Nguyen et al., 2024), emergency \nmedicine (Bains et al., 2024; Williams et al., 2024b, 2024a), and many other ﬁelds. One challenge in the use \nof AI-based approaches in behavioral health has been the challenge of working with unstructured text-based \ndata, such as provider progress notes, nursing notes, and provider interviews. Such records are generally not \nstandardized and exhibit signiﬁcant variability even within a single sejng.  \nRecent advances in generaRve AI technologies have led to the development of large language models \n(LLMs), such as OpenAI’s ChatGPT. LLMs, designed for use in natural language tasks, are text-to-text \npredicRve models trained on very large corpora of unstructured text that have shown great promise in nature \nlanguage processing and understanding. Within behavioral health, LLMs have been invesRgated for use in \ndocumentaRon review and creaRon (Tierney et al., 2024), analysis of clinical text for decision support in \ndiagnosis and treatment (Galatzer-Levy et al., 2023; So et al., 2024; Taylor et al., 2024; Xu et al., 2023), to \nassist providers’ delivery of psychotherapeuRc intervenRons (Sharma et al., 2023), and as autonomous \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n4 \n \npaRent interacRon agents (Sharma et al., 2024). The promise of LLMs, however, is predicated on the quality \nof the knowledge encoded within the models by the training process, and several studies have noted that the \nunﬁltered base models can generate dangerous or harmful responses (Grabb et al., 2024). Successive models \nhave shown improved performance on natural language tasks both because of increases in the size of their \ncorpus (i.e. the volume of pre-exisRng text used to train the models) as well as the addiRon of addiRonal \nhuman-level supervision, tuning, and model complexity.  \nThe use of large-scale corpora collected from publicly available wriDen and internet literature, \nhowever, may create limitaRons on the applicability of the model to the specialized tasks found in the \npracRce of psychiatry and behavioral health. One study of user intenRon found that 78% of paRent \nrespondents were willing to use ChatGPT for self-diagnosis (Shahsavar and Choudhury, 2023), and in our \nexperience, paRents frequently use LLMs to evaluate their own mental health concerns, provide diagnosRc \nand treatment recommendaRons, and even to provide autonomous psychotherapy, despite the potenRal \nrisks of such usages and the sRpulaRons of major vendors against using these tools for medical advice. \nFew studies have directly examined the eﬃcacy of LLMs on tasks related to knowledge or \ninterpretaRon within behavioral health. Xu et al. (2023) developed and examined the eﬃcacy of LLMs for \npredicRng mental health-related metrics from Reddit posts, ﬁnding that LLMs were able to classify and \nstraRfy suicidality and depression from these short text snippets beDer than random. Galatzer-Levy et al. \n(2023) examined the ability of the Med-PaLM 2 foundaRon model to analyze paRent interviews and case \nvigneDes and predict psychometric scores and diagnoses, ﬁnding that the model has promise in both \napplicaRons. Here, we present a study invesRgaRng 1) the ability of the GPT family of LLMs (OpenAI, San \nFrancisco, CA) to reason clinically about behavioral health and 2) the eﬃcacy of integraRng clinical expert-\nderived reasoning (through the use of decision trees) into the models to improve the accuracy of diagnosRc \npredicRon. \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n5 \n \n2. Methods \n2.1 Dataset \nThe primary dataset for this study comprised case vigneDes extracted from the DSM-5-TR Clinical Cases \n(Barnhill, 2023) book. Each example consisted of a mulR-paragraph narraRve vigneDe about a psychiatric \nclinical case and one or more DSM-5-TR (American Psychiatric AssociaRon, 2022) diagnoses assigned to the \npaRent by the author of the vigneDe (“author-designated diagnoses”). The vigneDes were organized by the \nDSM-5-TR diagnosRc category corresponding to the paRent’s primary diagnosis. A total of 106 cases were \nretrieved from the book. Cases from the secRons on EliminaRon Disorders, Gender Dysphoria, Personality \nDisorders, and Paraphilic Disorders were discarded due to these DSM categories not being covered by the \nHandbook of DiﬀerenRal Diagnosis (see below). The remaining 93 cases were split into training and tesRng \nsets (of 38 and 55 cases respecRvely), using sampling straRﬁed on primary diagnosis DSM category.  \n2.2 Inference approach and large language models \n2.2.1 Inference approach  \nTwo inference approaches were implemented and compared for this study in order to evaluate the capability \nof the study LLMs to reason clinically about mental health and to integrate external expert reasoning into its \npredicRons. In the ﬁrst approach, termed the “base” approach, the LLM was directly prompted to assign \ndiagnoses to the vigneDe, without the inclusion of outside knowledge or use of iteraRve prompRng. In the \nsecond approach, termed the “decision tree” (DT) approach, a decision tree-based inference system was \nimplemented. In this approach, the LLM is iteraRvely prompted with speciﬁc behavioral health quesRons \nregarding the input vigneDe. Candidate diagnoses are then predicted based on the answers to these \nquesRons, and then the list of candidate diagnoses is narrowed through addiRonal queries to the LLM. \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n6 \n \nPrompt templates for both approaches are shown in Table 1. The study was conducted between February \nand August 2024. \n2.2.2 Decision tree implementaRon  \nThe DSM-5-TR Handbook of DiﬀerenRal Diagnosis  (the “Handbook”) was used as the expert knowledge \nsource for the iniRal development of the decision tree prompRng model (Michael B. First, 2024). This \nhandbook consists of a series of 28 symptom-based decision trees for diagnosis. Each tree consists of a series \nof yes or no quesRons, the answers to which lead either to other quesRons or to diagnoses. All 28 trees were \nextracted and implemented as iterated yes or no prompts (“quesRon prompts”). For each tree, a one-\nparagraph prompt was wriDen describing the symptom category pertaining to the tree and asking if the \nvigneDe describes a paRent experiencing that category of symptoms (“screening prompts”). See Table 1 for \nprompt templates and Appendix A for examples. \nTo make predicRons using the decision tree model, each vigneDe was processed through each of the \n28 decision trees. First, the screening prompt for each tree was used to determine which decision trees could \nbe applicable to the vigneDe, and then for each applicable tree, the quesRon prompts were used iteraRvely, \ncollecRng diagnoses from each tree into a list of candidate diagnoses for the vigneDe. To narrow the list of \ncandidate diagnoses into the ﬁnal list of diagnoses (“model-predicted diagnoses”), the model was prompted \n(see Table 1 for template) to compare each pair of candidate diagnoses and determine if both diagnoses were \nnecessary, or if only one of them was needed. \n2.2.3 Large language models and parameters  \nFor comparison, three successive versions of the commonly used GPT family of LLMs (OpenAI, San Francisco, \nCA) were evaluated: GPT-3.5, GPT-4, and GPT-4o, the “foundaRon models.” To ensure that the models did not \nlearn from experimental inputs during the study, all queries were executed under an agreement to not use \ninputs, outputs, or any other data generated during the study for training purposes. Each query to the model \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n7 \n \nwas performed independently, without including context from other queries. AddiRonal technical detail is \navailable in Appendix B. \n2.3 Decision tree reﬁnement \nIn the ﬁrst phase of the project, the decision tree models from the Handbook were reﬁned through \nexperimentaRon on the test set. The model was iniRally implemented using the exact decision trees provided \nin the source handbook. Then, the model was used to generate iniRal predicRons on the tesRng cases. During \nthis process, each prompt and the LLM response to the prompt was logged for review. These responses were \nthen reviewed for every vigneDe. Based on this review, common themes of incorrect inferences based on the \ndecision trees were developed, and the trees, screening prompts, and quesRon prompts were then reﬁned \nbased on these common themes. The primary reﬁnement approach was to address the discovered common \nthemes through the use of known best pracRces for LLM prompt opRmizaRon, such as task decomposiRon \nand sequenRal tasking (Zhou et al., 2023) (dividing a complex task into smaller, speciﬁc tasks that are \nexecuted sequenRally; e.g., breaking “Is the paRent experiencing a Manic Episode” into a series of criterion-\nspeciﬁc quesRons).  \n2.4 Diagnosis matching and simpliﬁca;on \nTo improve the iniRal tractability of the task, facilitate ease of comparison, and match the task most closely to \nthe diagnosRc power of the decision trees from the Handbook (which makes several simpliﬁcaRons to DSM-\nbase diagnoses), all diagnoses (including author-designated and model-predicted) were systemaRcally \nsimpliﬁed using the procedure below: \n1. All DSM speciﬁers, modiﬁers and codes were removed; if auer this step diagnoses were idenRcal, they \nwere combined. \n2. All neurocogniRve disorders were collapsed into “Delirium” or “NeurocogniRve Disorder,” removing \ndisease-speciﬁc language and combining the mild and major classes. \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n8 \n \n3. All substance-speciﬁc disorders were collapsed into “Substance Use Disorder,” “Substance \nIntoxicaRon,” or “Substance Withdrawal” (removing idenRﬁcaRon of the speciﬁc substance) \n4. All breathing-related sleep disorder diagnoses (as deﬁned by the DSM Sleep-Wake Disorders secRon) \nwere combined into a single “Breathing-Related Sleep Disorder” diagnosis \n5. All “Other Speciﬁed” and “Unspeciﬁed” diagnoses were combined into single “Other Speciﬁed or \nUnspeciﬁed” diagnoses for each category  \nAuer predicRon and simpliﬁcaRon, all base model-generated diagnoses further underwent a matching \nprocess to associate it with an exact DSM-5-TR diagnosis when possible as follows:  \n1. If the diagnosis exactly matched a DSM-5-TR diagnosis, this diagnosis was used. \n2. If the diagnosis was clearly non-psychiatric (e.g., “Hypertension”) or was clearly related to a Z code \n(e.g., “Nonsuicidal Self-injury”), it was discarded. \n3. If the diagnosis was psychiatric and had a clear, unambiguously matching DSM-5-TR diagnosis, it was \nreplaced with the DSM-5-TR diagnosis (e.g., “Major Depression Disorder” to “Major Depressive \nDisorder”). \n4. If there was no clear, unambiguously matching DSM-5-TR diagnosis, either because the diagnosis was \nnot/no longer in the DSM-5-TR (e.g., “Sexual Aversion Disorder,” “Postpartum Psychosis,” or “Bullying \nVicRmizaRon”), or because the diagnosis was underspeciﬁed (e.g., “Bipolar Disorder”), the diagnosis \nwas retained (and assigned as a false posiRve). \nEach diagnosis was then also assigned a category based on the DSM-5-TR category in which the diagnosis is \nfound (e.g., “Depressive Disorders”). Unmatched diagnoses were assigned a relevant category if a clear, \nunambiguously matching category was found (e.g., “Bipolar Disorder” to “Bipolar and Related Disorders”), or \notherwise were assigned the category “Non-DSM.” \n2.5 Analysis \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n9 \n \nFor each vigneDe, base and DT model-generated inferences were created for each foundaRon model and \nthen compared to the vigneDe author-designated diagnoses. Model-generated diagnoses were scored as a \nTrue PosiRve (TP) if they matched one of the author-designated diagnoses, or otherwise as a False PosiRve \n(FP). Author-designated diagnoses were scored as a False NegaRve (FN) if there was no matching model-\ngenerated diagnosis. This scoring approach was also used for associated categories. Auer scoring, the posiRve \npredicRve value (PPV) and sensiRvity were calculated for each tesRng set vigneDe, the composite F1 \nperformance score was calculated from these scores, and then all were averaged across the dataset for \nreporRng (see Appendix C for equaRons); in circumstances where the calculaRon would cause a division by \nzero, 0 was subsRtuted for the result. For staRsRcal tesRng, the paired Student’s t-test was used. For each \nfoundaRon model, a two-tailed test was performed to compare PPV, sensiRvity and F1 between the Base and \nDT models using a signiﬁcance level of 0.05. \n3. Results \n3.1 Decision tree reﬁnement \nDecision tree reﬁnement was carried out using the 38 training set vigneDes. Nine categories for reﬁnement \nof the Handbook trees were idenRﬁed from the iniRal experiment; eight of which were based on disorder \ngroupings and one of which was used for changes to the overall tree structure. For each category, a set of \nreﬁnements was developed and implemented into the decision tree model prompRng system. Common \nreﬁnements included expanding deﬁniRons of specialized words used in behavioral health (e.g., \n“egosyntonic”) and expanding references to criteria to include the full criteria (e.g., prompRng speciﬁcally for \neach of the criteria of a Manic Episode rather than prompRng the model to determine if “criteria for a Manic \nEpisode are met”). A summary of the categories and implemented reﬁnements is presented in Table 2. \n3.2 Inferences, diagnosis matching and simpliﬁca;on \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n10 \n \nInferencing, diagnosis matching, and simpliﬁcaRon were carried out on the 55 test set vigneDes. There were \na total of 77 author-designated diagnoses and 73 author-designated categories across the test set vigneDes. \nAuer compleRng diagnosis matching, a small number of base model diagnoses were not matchable to a \nDSM-5-TR diagnosis, a DSM-5-TR Z code, or a non-psychiatric illness; three such diagnoses were noted for \ngpt-3.5, one for gpt-4, and three for gpt-4o. This represented less than 1% of the total number of predicted \ndiagnoses for each model. At the diagnosis level of speciﬁcity, the Base models predicted 161-163 diagnoses, \nwith TP , FP , and FN ranges of 55-61, 99-108, and 15-22 respecRvely; the DT models predicted 76-96 \ndiagnoses, with TP , FP , and FN ranges of 46-55, 30-42, and 22-31 respecRvely. At the category level of \nspeciﬁcity, the Base models predicted 133-135 categories, with TP , FP , and FN ranges of 68-70, 64-65, and 3-5, \nrespecRvely; the DT models predicted 67-82 categories, with 53-62, 14-20, and 11-20, respecRvely.  Diagnosis \nand category counts and classiﬁcaRons auer analysis are found in Table 3. \n3.3 Sta;s;cal analysis \nAnalysis results by foundaRon model (FM), diagnosis model (Base or DT), and level of granularity (diagnosis \nor category) are shown in Table 4. At the diagnosis level of speciﬁcity, the DT model had signiﬁcantly higher \nPPV and F1 scores than the base model (with an average increase of +22%, +0.13, respecRvely) for all FMs, \nwithout a ﬁnding of signiﬁcance for comparisons of the sensiRvity. At the category level of speciﬁcity, the DT \nmodel had signiﬁcantly higher PPV (average +20%) for all FMs but had signiﬁcantly lower sensiRvity for the \ngpt-3.5 and gpt-4 FMs (average -13% across all 3 models), leading to a signiﬁcant increase in F1 for the gpt-4 \nand gpt-4o FMs (average +0.09 across all 3 models).  \n4. Discussion \nIn this paper, we sought to evaluate the capabiliRes of the GPT family of large language models when applied \nto psychiatric reasoning and diagnosis, and to evaluate whether directly integraRng clinician-expert guidance \n(in the form of decision trees) into the models improved their psychiatric performance. To this end, we \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n11 \n \nevaluated two paradigms for uRlizing the LLMs to make diagnoses: 1) directly prompRng the models to \npredict diagnoses without access to knowledge external to the model (the Base approach), and 2) adapRng \nexpert-created diagnosRc decision trees into sequenRal prompts in order to produce candidate predicRons, \nand then prompRng the model to determine which candidates were most appropriate. Overall, we found that \nboth approaches were able to make appropriate diagnosRc predicRons, with some trade-oﬀs noted between \nthe two approaches. This ﬁnding demonstrates that the underlying foundaRon models do have psychiatric \nreasoning capabiliRes, despite not being speciﬁcally trained for this use case. \n4.1 How do LLMs perform when directly prompted to es;mate diagnoses? \nIn direct predicRon eﬀorts using the Base approach, we found that the model was able to correctly produce \nthe majority of correct diagnoses, with the sensiRvity mean ranging from 68% (gpt-3.5) to 78% (gpt-4o). This \nis concordant with the ﬁndings of Galatzer-Levy et al. (2023), who used a diﬀerent family of models in a \nrestricted subset of vigneDes and diagnoses and found 77.5% accuracy in predicRng the correct primary \ndiagnosis. When assessing whether the model predicted diagnoses in the correct DSM-5-TR category (rather \nthan whether the speciﬁc diagnoses were correct), the Base approach demonstrated impressive sensiRvity \nmeans of 91% (gpt-3.5) to 95% (gpt-4). We interpret this result as demonstraRng that the foundaRon models \nhave an inherent capacity to extract symptoms and mental health concerns from narraRves and reason about \nlikely diagnoses using this informaRon; indeed, the degree of concordance between the predicted diagnoses \nand the author-designated diagnoses is superior to that found for most of the mental disorders studied in the \nDSM-5 ﬁeld trials (Clarke et al., 2013; Regier et al., 2013) (which found pooled intraclass Kappa staRsRcs of \n0.46 for schizophrenia, 0.56 for bipolar disorder, and 0.28 for major depressive disorder).  \nHowever, we also found that fewer than half of the predicted diagnoses were correct, with a PPV mean \nranging from 35% (gpt-3.5) to 43% (gpt-4o) for speciﬁc diagnoses and 57% to 59% respecRvely for diagnosRc \ncategories.  We hypothesize that the signiﬁcant overdiagnosis rates represent the model’s limited capability \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n12 \n \nto apply criteria and clinical judgement to determine if a paRent’s symptoms meet the DSM-5-TR deﬁned \nthreshold for a behavioral health diagnosis. The authors ﬁnd the propensity of the LLMs for overdiagnosis to \nbe parRcularly concerning given the empiric prevalence in our pracRce of paRents who make use of publicly \navailable LLMs for self-diagnosis; their usage of these systems is closest to our Base approach and is likely \nsimilarly subject to the same limitaRon. Clinicians should ensure their paRents are adequately informed \nabout this risk in the use of LLMs to assist paRents in managing their own mental health. The degree of risk \nand potenRal harm may vary by paRent, and future work could study how emergent paRent-driven uses of \npublic LLMs impact both the general populaRon and people with mental disorders. Since it is likely that such \nuses will only increase as these technologies conRnue to permeate the public consciousness, the \ndevelopment of guidelines to prevent inappropriate clinical use of these technologies is of great importance. \n4.2 Does the integra;on of expert decision trees improve the diagnos;c capabili;es of \nLLMs? \nIn decision tree-based predicRon eﬀorts using the DT approach, we found the model was again able to \ncorrectly produce the majority of correct diagnoses, with sensiRvity means ranging from 59% (gpt-3.5) to \n71% (gpt-4o); we did not ﬁnd a staRsRcally signiﬁcant diﬀerence between the two approaches in sensiRvity \nscores for speciﬁc diagnoses when using the paired Student’s t-test. When looking at diagnosRc categories, \nwe did ﬁnd that for the gpt-3.5 and gpt-4 models, the DT approach had staRsRcally signiﬁcantly lower \nsensiRvity scores than the Base approach. When examining PPV, however, we found that the DT approach \ndemonstrated a staRsRcally signiﬁcant improvement for all models across speciﬁc diagnosis and diagnosRc \ncategory. This led to a signiﬁcant improvement in F1 score using the DT approach for all experiments except \nfor the evaluaRon of performance in diagnosRc category for the gpt-3.5 model. \nWe hypothesize that these results demonstrate that the integraRon of the decision trees improved \nthe capability of the model to apply diagnosRc criteria in order to determine if behavioral health symptoms \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n13 \n \nmet the threshold of a diagnosis, leading to an improvement in PPV across all experiments. The concomitant \nreducRon in sensiRvity performance is consistent with the known tradeoﬀ between the two metrics when \nincreasing the “threshold” for predicRng a posiRve class. This may also represent increasing diﬃculty in the \nmodel answering speciﬁc quesRons about diagnosRc criteria from the unstructured vigneDe (as opposed to \nthe easier task of extracRng broad symptoms). Of note, we found that signiﬁcant adaptaRon to the decision \ntree models found in the Handbook were required in order to opRmize performance for our study. This is \nconsistent with previously reported results (Nori et al., 2023; Zhou et al., 2023) that have demonstrated the \nimpact of the applicaRon of prompt engineering techniques on model performance.  \n4.3 How has the progression of GPT models impacted their performance in psychiatric \nreasoning? \nWe found that, broadly, performance tended to improve with the use of successive GPT models. The biggest \njump in performance by F1 score was between the gpt-3.5 and gpt-4 models for both approaches, with a \nmore modest increase between gpt-4 and gpt-4o. This is consistent with reported results in other \ndomains(Shahriar et al., 2024), and may reﬂect in part that changes to the foundaRon models are aimed both \nto improve performance and to reduce the cost of inference – goals that ouen require tradeoﬀs. Notably, \ninference costs are signiﬁcantly diﬀerent between the three models. These costs are priced in units of 1M \ninput and output tokens, and are $0.50/$1.50 for gpt-3.5, $10/$30 for gpt-4, and $5/$15 for gpt-4o. \nWhat are the poten1al limita1ons of this work and opportuni1es for further inves1ga1on? \nThis eﬀort represents the ﬁrst comprehensive evaluaRon of the performance of GPT models in psychiatric \ndiagnosis with and without the use of external expert guidance. ExecuRng the study required two technical \ncompromises that may represent potenRal limitaRons. In order to make use of standardized, commonly-\navailable input examples that were not designed speciﬁcally for AI applicaRons, case vigneDes were obtained \nusing the APA’s published casebook. Given that the GPT models were trained on corpora that include \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n14 \n \npublished books, it is possible that current or former versions of the casebook were included in the training \ndataset. This might have provided the models with an advantage in making diagnoses using these examples \nthat would not be present when analyzing other data. We believe that the probability of signiﬁcant inﬂuence \non our results is low due to the length of the vigneDe examples. AddiRonally, there is no published material \non the applicaRon of the Handbook decision trees on the casebook vigneDes, reducing the probability that \nmemorizaRon would aﬀect the DT results. \nAddiRonally, in order to facilitate direct comparison between author-designated diagnoses and \npredicted diagnoses, manual review was used with a standardized diagnosis simpliﬁcaRon system. This \napproach could have hidden important diﬀerences between the model’s output and the author-designated \ndiagnoses. We believe that this potenRal trade-oﬀ was worthwhile given that our goal was to evaluate the \nmodel’s ability to reason about diagnosis and make use of expert guidelines, but future eﬀorts may wish to \ninvesRgate the performance of the models in more speciﬁc areas, such as the generaRon of appropriate DSM \nspeciﬁers or in diﬀerenRaRon between types and severity of neurocogniRve disorders or substance use \ndisorders. AddiRonally, we excluded vigneDes with primary diagnoses from DSM-5-TR chapters not covered \nby the Handbook, such as personality disorders and paraphilic disorders; future eﬀorts could invesRgate the \nadaptaRon of other expert resources that apply to those areas. \nMore broadly, future eﬀorts could invesRgate the use of LLMs for other types of psychiatric reasoning. \nDSM diagnosis has limited interrater reliability (Clarke et al., 2013; Regier et al., 2013), and in the absence of \na human comparison arm, our ability to evaluate the signiﬁcance of the model’s performance is restricted. \nThe advent of LLMs and other advanced arRﬁcial intelligence-based modeling tools could allow for the \ndevelopment of new diagnosRc schema that could overcome some of the limitaRons of the DSM through the \nautomated interpretaRon of large volumes of paRent-related data. Such an approach could allow for more \nprecise quanRﬁcaRon of language-based phenotypes, moRvate new approaches for disorder subtyping, and \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n15 \n \nallow for the discovery of new links between behavioral phenotypes and neurobiological mechanisms, with \nthe overall goal of matching the right treatments to the right paRents at the right Rme. \n4.4 Conclusion \nIn this work, we have demonstrated that the GPT family of large language models has the emergent \ncapability for psychiatric reasoning and that it is able to interpret case vigneDes and apply expert guidelines \nto make diagnoses. We found that directly prompRng the models without external informaRon led the \nmodels to predict the majority of correct diagnoses, with the limitaRon of signiﬁcant overdiagnosis. We \nfound that incorporaRng adapted expert decision-tree based diagnosRc guidelines reduced overdiagnosis and \nimproved overall model performance. These results illustrate the potenRal risks and beneﬁts of the use of \nlarge language models for language analysis in behavioral health and moRvate the need for systems that \nintegrate language modeling with expert knowledge for use in clinical applicaRons. \nAcknowledgements \nWe thank the UCSF AI Tiger Team, UCSF Academic Research Services, UCSF Research InformaRon Technology, \nand the UCSF Chancellor’s Task Force for GeneraRve AI for their support in developing LLM resources used for \nthis project. This research was made possible through the use of content belonging to the American \nPsychiatric AssociaRon; express permission was obtained from the American Psychiatric AssociaRon for the \nuse of such content (DSM-5-TR Clinical Cases and DSM-5-TR Handbook of DiﬀerenRal Diagnosis (Copyright © \n2023 and 2024). American Psychiatric AssociaRon. All Rights Reserved, including rights for text and data \nmining (TDM), ArRﬁcial Intelligence (AI) training, and similar technologies). \nReferences \nAmerican Psychiatric AssociaRon, 2022. DiagnosRc and staRsRcal manual of mental disorders, ﬁuh ediRon, \ntext revision (DSM-5-TR). American Psychiatric AssociaRon Publishing, Arlington, TX. \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n16 \n \nBains, J.K., Williams, C.Y .K., Johnson, D., Schwartz, H., Sabbineni, N., BuDe, A.J., Kornblith, A.E., 2024. \nEnhancing emergency department charRng: Using GeneraRve Pre-trained Transformer-4 (GPT-4) to \nidenRfy laceraRon repairs. Acad Emerg Med. hDps://doi.org/10.1111/acem.14995 \nBarnhill, J.W. (Ed.), 2023. DSM-5-TR Clinical Cases. American Psychiatric AssociaRon Publishing, Arlington, TX. \nClarke, D.E., Narrow, W.E., Regier, D.A., Kuramoto, S.J., Kupfer, D.J., Kuhl, E.A., Greiner, L., Kraemer, H.C., 2013. \nDSM-5 Field Trials in the United States and Canada, Part I: Study Design, Sampling Strategy, \nImplementaRon, and AnalyRc Approaches. AJP 170, 43–58. \nhDps://doi.org/10.1176/appi.ajp.2012.12070998 \nGalatzer-Levy, I.R., McDuﬀ, D., Natarajan, V., Karthikesalingam, A., Malgaroli, M., 2023. The Capability of Large \nLanguage Models to Measure Psychiatric FuncRoning. hDps://doi.org/10.48550/arXiv.2308.01834 \nGrabb, D., Lamparth, M., Vasan, N., 2024. Risks from Language Models for Automated Mental Healthcare: \nEthics and Structure for ImplementaRon. hDps://doi.org/10.48550/arXiv.2406.11852 \nLim, J.I., Rachitskaya, A.V., Hallak, J.A., Gholami, S., Alam, M.N., 2024. ArRﬁcial intelligence for ReRnal \nDiseases. Asia Pac J Ophthalmol (Phila) 100096. hDps://doi.org/10.1016/j.apjo.2024.100096 \nMichael B. First, 2024. DSM-5-TR® handbook of diﬀerenRal diagnosis. American Psychiatric AssociaRon \nPublishing, Arlington, TX. \nNguyen, T., Ong, J., Masalkhi, M., Waisberg, E., Zaman, N., Sarker, P ., Aman, S., Lin, H., Luo, M., Ambrosio, R., \nMachado, A.P ., Ting, D.S.J., Mehta, J.S., Tavakkoli, A., Lee, A.G., 2024. ArRﬁcial intelligence in corneal \ndiseases: A narraRve review. Cont Lens Anterior Eye 102284. \nhDps://doi.org/10.1016/j.clae.2024.102284 \nNori, H., Lee, Y .T., Zhang, S., Carignan, D., Edgar, R., Fusi, N., King, N., Larson, J., Li, Y ., Liu, W., Luo, R., \nMcKinney, S.M., Ness, R.O., Poon, H., Qin, T., Usuyama, N., White, C., Horvitz, E., 2023. Can Generalist \nFoundaRon Models Outcompete Special-Purpose Tuning? Case Study in Medicine. \nhDps://doi.org/10.48550/arXiv.2311.16452 \nRegier, D.A., Narrow, W.E., Clarke, D.E., Kraemer, H.C., Kuramoto, S.J., Kuhl, E.A., Kupfer, D.J., 2013. DSM-5 \nField Trials in the United States and Canada, Part II: Test-Retest Reliability of Selected Categorical \nDiagnoses. AJP 170, 59–70. hDps://doi.org/10.1176/appi.ajp.2012.12070999 \nSarma, K.V., Harmon, S., Sanford, T., Roth, H.R., Xu, Z., Tetreault, J., Xu, D., Flores, M.G., Raman, A.G., Kulkarni, \nR., Wood, B.J., Choyke, P .L., Priester, A.M., Marks, L.S., Raman, S.S., Enzmann, D., Turkbey, B., Speier, \nW., Arnold, C.W., 2021. Federated learning improves site performance in mulRcenter deep learning \nwithout data sharing. Journal of the American Medical InformaRcs AssociaRon. \nhDps://doi.org/10.1093/jamia/ocaa341 \nShahriar, S., Lund, B.D., Mannuru, N.R., Arshad, M.A., Hayawi, K., Bevara, R.V.K., Mannuru, A., Batool, L., \n2024. Pujng GPT-4o to the Sword: A Comprehensive EvaluaRon of Language, Vision, Speech, and \nMulRmodal Proﬁciency. Applied Sciences 14, 7782. hDps://doi.org/10.3390/app14177782 \nShahsavar, Y ., Choudhury, A., 2023. User IntenRons to Use ChatGPT for Self-Diagnosis and Health-Related \nPurposes: Cross-secRonal Survey Study. JMIR Human Factors 10, e47564. \nhDps://doi.org/10.2196/47564 \nSharma, A., Lin, I.W., Miner, A.S., Atkins, D.C., Althoﬀ, T., 2023. Human–AI collaboraRon enables more \nempathic conversaRons in text-based peer-to-peer mental health support. Nat Mach Intell 5, 46–57. \nhDps://doi.org/10.1038/s42256-022-00593-2 \nSharma, A., Rushton, K., Lin, I.W., Nguyen, T., Althoﬀ, T., 2024. FacilitaRng Self-Guided Mental Health \nIntervenRons Through Human-Language Model InteracRon: A Case Study of CogniRve Restructuring, \nin: Proceedings of the CHI Conference on Human Factors in CompuRng Systems, CHI ’24. AssociaRon \nfor CompuRng Machinery, New York, NY , USA, pp. 1–29. hDps://doi.org/10.1145/3613904.3642761 \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n17 \n \nSo, J., Chang, J., Kim, E., Na, J., Choi, J., Sohn, J., Kim, B.-H., Chu, S.H., 2024. Aligning Large Language Models \nfor Enhancing Psychiatric Interviews through Symptom DelineaRon and SummarizaRon. \nhDps://doi.org/10.48550/arXiv.2403.17428 \nTaylor, N., Kormilitzin, A., Lorge, I., Nevado-Holgado, A., Cipriani, A., Joyce, D.W., 2024. Model development \nfor bespoke large language models for digital triage assistance in mental health care. ArRﬁcial \nIntelligence in Medicine 102988. hDps://doi.org/10.1016/j.artmed.2024.102988 \nTierney, A.A., Gayre, G., Hoberman, B., MaDern, B., Ballesca, M., Kipnis, P ., Liu, V., Lee, K., 2024. Ambient \nArRﬁcial Intelligence Scribes to Alleviate the Burden of Clinical DocumentaRon. NEJM Catalyst 5, \nCAT.23.0404. hDps://doi.org/10.1056/CAT.23.0404 \nWilliams, C.Y .K., Miao, B.Y ., Kornblith, A.E., BuDe, A.J., 2024a. EvaluaRng the use of large language models to \nprovide clinical recommendaRons in the Emergency Department. Nat Commun 15, 8236. \nhDps://doi.org/10.1038/s41467-024-52415-1 \nWilliams, C.Y .K., Zack, T., Miao, B.Y ., Sushil, M., Wang, M., Kornblith, A.E., BuDe, A.J., 2024b. Use of a Large \nLanguage Model to Assess Clinical Acuity of Adults in the Emergency Department. JAMA Netw Open \n7, e248895. hDps://doi.org/10.1001/jamanetworkopen.2024.8895 \nXu, X., Yao, B., Dong, Y ., Gabriel, S., Yu, H., Hendler, J., Ghassemi, M., Dey, A.K., Wang, D., 2023. Mental-LLM: \nLeveraging Large Language Models for Mental Health PredicRon via Online Text Data. \nhDps://doi.org/10.48550/arXiv.2307.14385 \nZhou, D., Schärli, N., Hou, L., Wei, J., Scales, N., Wang, X., Schuurmans, D., Cui, C., Bousquet, O., Le, Q., Chi, E., \n2023. Least-to-Most PrompRng Enables Complex Reasoning in Large Language Models. Presented at \nthe The Eleventh InternaRonal Conference on Learning RepresentaRons, Kigali, Rwanda. \nhDps://doi.org/10.48550/arXiv.2205.10625 \n \nTable 1. Prompt templates used for experiments. \nSystem Prompt \nI am going to give you an academic psychiatry clinical case that describes a paBent with one \nor more psychiatric DSM-5-TR diagnoses, and you are going to answer quesBons about that \ncase that I provide. \nDirect Prompt \nPlease provide me with a list of DSM-5-TR diagnoses, without speciﬁers or modiﬁers, that you \nbelieve apply to this paBent based solely on the clinical case. Please format them as a JSON \nlist Btled \"diagnoses\" with one diagnosis per entry. Do not include any other text in your \nresponse. Do not include any incorrect, inappropriate, or candidate diagnoses. For example, if \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n18 \n \nthe diagnoses are \"Insomnia Disorder\" and \"Bipolar I Disorder\", you would reply with: \n{\"diagnoses\": [\"Insomnia Disorder\", \"Bipolar I Disorder\"]} \nQuesRon Prompt \nThe clinical case is as follows: <X> \nPlease answer the following quesBon 'yes' or 'no' without explanaBon, based on the facts \nstated in the clinical case. Answer with only the words 'yes' or 'no'. If there is insuﬃcient \ninformaBon, answer 'no'. The quesBon is as follows: <Y>. \nPairwise Comparison Prompt \nThe following two DSM-5-TR diagnoses are candidate diagnoses for this paBent: <X> and <Y>. \nWe are interested in deciding if both diagnoses are necessary for the paBent, or if one of these \ntwo diagnoses is be_er explained by the other. Please respond with a list of which of these \ntwo diagnoses are necessary for the paBent in JSON format. For example, if the candidate \ndiagnoses are 'major depressive disorder' and 'adjustment disorder', respond with [\"major \ndepressive disorder\", \"adjustment disorder\"] if both diagnoses are necessary, or with either \n[\"major depressive disorder\"] or [\"adjustment disorder\"] if one diagnosis is be_er than the \nother. \n \n \n  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n19 \n \nTable 1. Findings and results of decision tree reﬁnement process by category.  \nDepressive, Bipolar and Related Disorders. The iniRal DT model was not able to reliably assess \nwhether criteria for Major Depressive Episode (MDE), Manic Episode, or Hypomanic Episode \nwere met in the absence of speciﬁcaRon (i.e., it was unable to reliably assess the quesRon \n“Were criteria met for a Manic Episode?”). To address this issue, a common set of sequenRal, \ndecomposed quesRon prompts were created to speciﬁcally assess DSM-5-TR criteria for MDE, \nManic Episode, and Hypomanic Episode. The DT model was not able to reliably diﬀerenRate \nbetween diﬀerent aﬀecRve disorders (i.e., Major Depressive Disorder vs Bipolar I Disorder) \nbecause the underlying decision trees from the Handbook provided mulRple diagnosRc \nopRons (i.e., the tree result might be “Bipolar I Disorder or Major Depressive Disorder or \nSchizoaﬀecRve Disorder” if criteria for mania were met) at leaf nodes of the tree. To address \nthis issue, a set of quesRon prompts were created to speciﬁcally diﬀerenRate between these \ndisorders. Finally, the DT model inconsistently made diagnoses for Persistent Depressive \nDisorder due to diﬀerent trees in the Handbook using diﬀerent criteria for diagnosis. To \naddress this issue, a consistent set of prompts was created to diagnose this disorder. \n \nSubstance-Related and AddicRve Disorders. The iniRal DT model ouen incorrectly diagnosed a \nSubstance Use Disorder due to apparent misinterpretaRons of the term “substance” (i.e., \ndiagnosing Pica as a Substance Use Disorder). To address this, the term “substance” was \nclariﬁed in quesRon prompts to “a substance of abuse or medicaRon.” The DT model was \nouen not able to diﬀerenRate between Substance IntoxicaRon, Substance Withdrawal, and \nOther Adverse Eﬀect of MedicaRon due to the trees in the Handbook ouen providing all of \nthese as possible diagnosRc opRons at leaf nodes. To address this, a speciﬁc set of prompts \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n20 \n \nwas created to determine which of these three diagnoses, if any, applied. AddiRonally, the DT \nmodel ouen diagnosed Substance IntoxicaRon or Withdrawal in circumstances where the \nvigneDe included a history of a past episode of intoxicaRon or withdrawal; this was addressed \nby clarifying in quesRon prompts that the diagnoses referred to “current” intoxicaRon or \nwithdrawal. \n \nObsessive-Compulsive and Related Disorders. The DT model ouen diagnosed Obsessive-\nCompulsive Disorder when an anxiety disorder diagnosis was more appropriate; this was \nfound to be due to incorrect responses to quesRon prompts that assessed whether the \npaRent had ego-dystonic thoughts and appeared to be due to the foundaRon model not \nbeing able to reliably make use of the term \"ego-dystonic.” This was addressed by adding an \nexplicit deﬁniRon to all prompts using the term. \n \nPersonality Disorders. The DT model ouen diagnosed Borderline Personality Disorder in any \nvigneDe that included menRon of self-injury; this was found to be due to the use of \ninconsistent deﬁniRons across diﬀerent trees in the Handbook. To address this issue, a \nconsistent deﬁning clause was added to all relevant quesRon prompts: “a persistent and \npervasive paDern of instability of interpersonal relaRonships, self-image, and aﬀects, and \nmarked impulsivity, beginning by early adulthood.” \n \nTrauma- and Stressor-Related Disorders. The DT model was found to diagnose Adjustment \nDisorder for almost all vigneDes; this was found to be due to the trees in the Handbook not \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n21 \n \nexplicitly making menRon of DSM-5-TR criterion C or D for Adjustment Disorder (“The stress-\nrelated disturbance does not meet the criteria for another mental disorder and is not merely \nan exacerbaRon of a preexisRng mental disorder,” and “The symptoms do not represent \nnormal bereavement and are not beDer explained by prolonged grief disorder”). To address \nthis issue, a speciﬁc set of prompts was implemented to assess for the full DSM-5-TR criteria. \n \nAnxiety Disorders. The DT model was found to inconsistently diagnose Generalized Anxiety \nDisorder; this was found to be due to inconsistent deﬁniRons used in the Handbook trees. \nThis was addressed through the development of standardized language (“excessive worry and \nanxiety about several events or situaRons, occurring more days than not for at least 6 \nmonths, about a number of diﬀerent unrelated issues, events or acRviRes”). \n \nSchizophrenia Spectrum and Other PsychoRc Disorders. The DT model was found to \ninconsistently make the diﬀerenRal diagnosis between Schizophrenia, Schizophreniform \nDisorder, and SchizoaﬀecRve Disorder; this appeared to be due to diﬃculty diﬀerenRaRng \nwhether the paRent had psychoRc symptoms in the absence of a mood episode using the \nHandbook trees. To address this, a set of decomposed, sequenRal prompts were developed to \ndiﬀerenRate between these three disorders.  \n \nSleep/Wake Disorders and Sexual DysfuncRons. The DT model was found to diagnose \nInsomnia Disorder in almost all vigneDes that included sleep disrupRon. To address this, \nexpanded language was added to the relevant quesRon prompts: “occurring at least 3 nights \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n22 \n \nper week for at least 3 months, and is not explainable by a mental disorder other than \ninsomnia disorder.” The DT model was also found to inconsistently make diagnoses in the \ntrees for insomnia, hypersomnolence, and sexual dysfuncRon; this appeared to be due to \nthese Handbook trees being designed diﬀerently than the other trees. To address this, the \ntrees were refactored to use a single quesRon prompt for each diagnosis. \n \nStructural LimitaRons. The DT model was found to miss diagnoses in circumstances where the \npaRent had more than one diagnosis with similariRes in presenRng symptoms that led \nmulRple diagnoses to be found in a single tree; this was due to the structure of the Handbook \ntrees allowing only one diagnosis per tree to be assigned. This was addressed by altering the \nimplementaRon to allow for all potenRal diagnoses in the tree to be considered, with \nstructural limitaRons only for diagnoses that are mutually exclusive. The DT model also \nproduced extra diagnoses in circumstances where the Handbook trees had leaf nodes with \nmulRple possible diagnoses (i.e., “MAJOR DEPRESSIVE DISORDER; SCHIZOHPRENIA”). This was \naddressed by adding addiRonal quesRon prompts or referrals to other trees to diﬀerenRate \nbetween the possible diagnoses. The DT model was found to inconsistently aDribute \ndisorders that were secondary to nonpsychiatric medical condiRons to primary psychiatric \ndisorders, due to an apparent inability to disRnguish between physiological eﬀects of a \nnonpsychiatric condiRon and psychological reacRons to having medical condiRons. This was \naddressed through the addiRon of speciﬁc clarifying language to relevant quesRon prompts. \nAuer making the above changes, the DT model was found to excessively make Other \nSpeciﬁed/Unspeciﬁed diagnoses. This was found to be due to altering the tree \nimplementaRon to allow all potenRal diagnoses to be considered, as the Handbook trees \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n23 \n \nwere designed to use these diagnoses as ﬁnal catch-all leaves. This was addressed by only \nallowing Other Speciﬁed/Unspeciﬁed diagnoses to be made if no other diagnoses were made \nfrom a decision tree. \n \n  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n24 \n \nTable 2. Result and classiﬁca1on counts for predicted diagnoses across experiments. Numbers reﬂect \nresults auer post-processing. FM: FoundaRon Model, TP: True PosiRves, FP: False PosiRves, FN: False \nNegaRves, DT: Decision Tree Model \n FM Model Author Dx Model Dx TP FP FN \nDiagnosis gpt-3.5 Base 77 163 55 108 22 \nDT 77 76 46 30 31 \ngpt-4 Base 77 163 61 102 16 \nDT 77 96 54 42 23 \ngpt-4o Base 77 161 62 99 15 \nDT 77 89 55 34 22 \nCategory gpt-3.5 Base 73 133 68 65 5 \nDT 73 67 53 14 20 \ngpt-4 Base 73 135 70 65 3 \nDT 73 82 62 20 11 \ngpt-4o Base 73 134 70 64 3 \nDT 73 80 62 18 11 \n \n  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n25 \n \nTable 3. Results of performance analysis of predic1ons for diagnosis and diagnos1c category, by \nexperiment. Bold text and * denote values that are staRsRcally signiﬁcantly higher by paired two-tailed t-\ntesRng between Base and DT models. FM: FoundaRon Model, PPV: PosiRve PredicRve Value, DT: Decision \nTree Model \n By Diagnosis By Category \nFM Model SensiRvity PPV F1 SensiRvity PPV F1 \ngpt-3.5 Base 68.33% 35.42% 0.4418 91.21%* 56.97% 0.6647 \nDT 59.09% 60.30%* 0.5703* 75.15% 80.91%* 0.7539 \ngpt-4 Base 77.27% 42.12% 0.5138 95.76%* 58.33% 0.6842 \nDT 70.91% 60.73%* 0.6315* 83.33% 75.15%* 0.7709* \ngpt-4o Base 77.58% 43.27% 0.5254 93.94% 59.24% 0.6870 \nDT 71.82% 65.27%* 0.6645* 84.24% 79.09%* 0.7915* \n \n  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n26 \n \nAppendices \nAppendix A. Decision Tree Promp0ng \nFor the iniRal experiments (prior to reﬁnement), quesRon prompts were created based on suggested \nlanguage in the DSM-5-TR Handbook of DiﬀerenRal Diagnosis. For example, the following is an example from \nthe “Depressed Mood” decision tree: \nAre there at least 2 weeks of depressed mood or diminished interest plus associated characterisBc \nsymptoms (e.g., changes in weight and appeBte, faBgue, feelings of worthlessness or guilt, changes in \nsleep, suicidal thoughts)? \nA screening prompt was developed for each decision tree, such as the following example from the “Self-\nInjurious Behavior” tree: \nFor the purposes of this discussion, self-injurious behavior refers to intenBonal self-inﬂicted acts to \ninjury or muBlate one's own body. This includes include cufng, burning, head banging, hair pulling, \nskin picking, self-biBng, and hifng of various parts of one’s own body, but does not include socially or \nculturally sancBoned pracBces (such as piercing or arBsBc scariﬁcaBon). It does not include behavior \nintended to end one's own life. Based on this deﬁniBon, is there evidence in the clinical case that the \npaBent has self-injurious behavior? \nAppendix B. LLM Technical Speciﬁca0ons \nFor this paper, three speciﬁc commercial large language models developed by OpenAI (San Francisco, CA) \nwere used. The models used were gpt-3.5, gpt-4-turbo, and gpt-4o. To enable reproducibility, speciﬁc model \nversions were used as follows: gpt-3.5-turbo-0125, gpt-4-0125-preview, and gpt-4o-2024-05-13. A python \ninterface was used to execute queries to the foundaRon models using the OpenAI API. All conﬁgurable \ncontent ﬁlters were turned oﬀ, and all queries were made with a temperature of 0, top_p of 1, and without \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint \n \n27 \n \nfrequency or presence penalRes. If a query returned either an error or an unparseable response, the query \nwas repeated with exponenRal backoﬀ unRl a valid response was received. All queries ulRmately produced \nparseable responses using this method, and no queries were rejected due to content ﬁltering. \nAppendix C. Performance Metric Equa0ons \nThe following equaRons were used to calculate performance metrics: \n \nEq. (C.1): 𝑃𝑃𝑉 =\n!\"\n!\"#$\" \nEq. (C.2): 𝑆𝑒𝑛𝑠𝑖𝑡𝑖𝑣𝑖𝑡𝑦 =\n!\"\n!\"#$% \nEq. (C.3): 𝐹& = 2\n\"\"'∗)*+,-.-/-.0\n\"\"'#)*+,-.-/-.0 \n \n \n \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted July 21, 2025. ; https://doi.org/10.1101/2025.07.19.25331840doi: medRxiv preprint ",
  "topic": "Overdiagnosis",
  "concepts": [
    {
      "name": "Overdiagnosis",
      "score": 0.9371602535247803
    },
    {
      "name": "Medical diagnosis",
      "score": 0.8510155081748962
    },
    {
      "name": "Statistic",
      "score": 0.6113792657852173
    },
    {
      "name": "Psychiatric diagnosis",
      "score": 0.5427283644676208
    },
    {
      "name": "Psychology",
      "score": 0.4173440635204315
    },
    {
      "name": "Medicine",
      "score": 0.41154223680496216
    },
    {
      "name": "Psychiatry",
      "score": 0.35324516892433167
    },
    {
      "name": "Internal medicine",
      "score": 0.17104795575141907
    },
    {
      "name": "Statistics",
      "score": 0.17067238688468933
    },
    {
      "name": "Pathology",
      "score": 0.15249544382095337
    },
    {
      "name": "Mathematics",
      "score": 0.12517693638801575
    },
    {
      "name": "Schizophrenia (object-oriented programming)",
      "score": 0.0
    }
  ]
}