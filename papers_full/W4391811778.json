{
  "title": "β-Variational autoencoders and transformers for reduced-order modelling of fluid flows",
  "url": "https://openalex.org/W4391811778",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A4306951877",
      "name": "Alberto Solera Rico",
      "affiliations": [
        "Universidad Carlos III de Madrid",
        "Instituto Nacional de Técnica Aeroespacial"
      ]
    },
    {
      "id": "https://openalex.org/A2462529283",
      "name": "Carlos Sanmiguel Vila",
      "affiliations": [
        "Instituto Nacional de Técnica Aeroespacial",
        "Universidad Carlos III de Madrid"
      ]
    },
    {
      "id": "https://openalex.org/A2766090285",
      "name": "Miguel Gomez Lopez",
      "affiliations": [
        "Instituto Nacional de Técnica Aeroespacial"
      ]
    },
    {
      "id": "https://openalex.org/A2111673682",
      "name": "Yuning Wang",
      "affiliations": [
        "KTH Royal Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A4367145876",
      "name": "Abdulrahman Almashjary",
      "affiliations": [
        "Illinois Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2155244845",
      "name": "Scott T. M. Dawson",
      "affiliations": [
        "Illinois Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2169096561",
      "name": "Ricardo Vinuesa",
      "affiliations": [
        "KTH Royal Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A4306951877",
      "name": "Alberto Solera Rico",
      "affiliations": [
        "Universidad Carlos III de Madrid"
      ]
    },
    {
      "id": "https://openalex.org/A2462529283",
      "name": "Carlos Sanmiguel Vila",
      "affiliations": [
        "Universidad Carlos III de Madrid"
      ]
    },
    {
      "id": "https://openalex.org/A2766090285",
      "name": "Miguel Gomez Lopez",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2111673682",
      "name": "Yuning Wang",
      "affiliations": [
        "KTH Royal Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A4367145876",
      "name": "Abdulrahman Almashjary",
      "affiliations": [
        "Illinois Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2155244845",
      "name": "Scott T. M. Dawson",
      "affiliations": [
        "Illinois Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2169096561",
      "name": "Ricardo Vinuesa",
      "affiliations": [
        "KTH Royal Institute of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2293609966",
    "https://openalex.org/W2963448313",
    "https://openalex.org/W6734852069",
    "https://openalex.org/W2921535191",
    "https://openalex.org/W2981080108",
    "https://openalex.org/W2346717862",
    "https://openalex.org/W2092398714",
    "https://openalex.org/W2973119841",
    "https://openalex.org/W2014356541",
    "https://openalex.org/W2127940547",
    "https://openalex.org/W2613314665",
    "https://openalex.org/W3048805510",
    "https://openalex.org/W2112823474",
    "https://openalex.org/W3039152077",
    "https://openalex.org/W3021544678",
    "https://openalex.org/W2987245967",
    "https://openalex.org/W4286909924",
    "https://openalex.org/W3035246486",
    "https://openalex.org/W4384029636",
    "https://openalex.org/W4386502346",
    "https://openalex.org/W4385242225",
    "https://openalex.org/W2951279763",
    "https://openalex.org/W3004360475",
    "https://openalex.org/W4306918378",
    "https://openalex.org/W3197659304",
    "https://openalex.org/W3124389259",
    "https://openalex.org/W3163453057",
    "https://openalex.org/W6600903635",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W4206706211",
    "https://openalex.org/W6788556936",
    "https://openalex.org/W3107503524",
    "https://openalex.org/W3196974791",
    "https://openalex.org/W6604190760",
    "https://openalex.org/W3172863135",
    "https://openalex.org/W6603768312",
    "https://openalex.org/W3216107495",
    "https://openalex.org/W4320732359",
    "https://openalex.org/W4283711386",
    "https://openalex.org/W2524984847",
    "https://openalex.org/W2905262640",
    "https://openalex.org/W3205571689",
    "https://openalex.org/W3160970887",
    "https://openalex.org/W2102707792",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2047425707",
    "https://openalex.org/W1981857248",
    "https://openalex.org/W4385634695",
    "https://openalex.org/W1965555277",
    "https://openalex.org/W6732629455",
    "https://openalex.org/W1633869374",
    "https://openalex.org/W2912475681",
    "https://openalex.org/W2963587345",
    "https://openalex.org/W3103516574",
    "https://openalex.org/W3104099416",
    "https://openalex.org/W3100610601",
    "https://openalex.org/W3099969702",
    "https://openalex.org/W3131838898",
    "https://openalex.org/W3104179623",
    "https://openalex.org/W3084290329",
    "https://openalex.org/W3135481891"
  ],
  "abstract": null,
  "full_text": "Article https://doi.org/10.1038/s41467-024-45578-4\nβ-Variational autoencoders and\ntransformers for reduced-order\nmodelling ofﬂuid ﬂows\nAlberto Solera-Rico 1,2, Carlos Sanmiguel Vila1,2, Miguel Gómez-López2,\nYuning Wang 3, Abdulrahman Almashjary4,S c o t tT .M .D a w s o n4 &\nRicardo Vinuesa 3\nVariational autoencoder architectures have the potential to develop reduced-\norder models for chaoticﬂuid ﬂows. We propose a method for learning\ncompact and near-orthogonal reduced-order models using a combination of a\nβ-variational autoencoder and a transformer, tested on numerical data from a\ntwo-dimensional viscousﬂow in both periodic and chaotic regimes. Theβ-\nvariational autoencoder is trained to learn a compact latent representation of\nthe ﬂow velocity, and the transformer istrained to predict the temporal\ndynamics in latent-space. Using theβ-variational autoencoder to learn disen-\ntangled representations in latent-space, we obtain a more interpretableﬂow\nmodel with features that resemble those observed in the proper orthogonal\ndecomposition, but with a more efﬁcient representation. Using Poincaré maps,\nthe results show that our method can capture the underlying dynamics of the\nﬂow outperforming other prediction models. The proposed method has\npotential applications in otherﬁelds such as weather forecasting, structural\ndynamics or biomedical engineering.\nTurbulent ﬂows are an important and ubiquitous phenomenon in\nnature and engineering, with applications ranging from aircraft design\nto weather forecasting. Understanding the behaviour ofﬂuid ﬂows is\noften challenging due to their complex spatio-temporal dynamics\ninvolving a large number of degrees of freedom and complex non-\nlinear interactions\n1. As a result, there is a growing interest in devel-\noping reduced-order models (ROMs) ofﬂuid ﬂow dynamics that can\ncapture the key underlying dynamics of theﬂow while reducing the\nproblem dimensionality2,3. Developing ROMs is one of the most pro-\nminent researchﬁelds since they facilitateﬁnding low-dimensional\nrepresentations that can be applied to perform ﬂow control\napplications4 or reduce the computational cost of numerical\nsimulations5,6. One of the most used techniques for dimensionality\nr e d u c t i o ni nt h eﬂuid-dynamics community is proper orthogonal\ndecomposition (POD), which involvesﬁnding the dominant modes of\nvariation in a given dataset and projecting the data onto a lower-\ndimensional subspace spanned by these modes. Another famous linear\napproach is the dynamic-mode decomposition (DMD), which identiﬁes\ndynamic modes that govern the evolution of the system over time\n7.\nWhile POD and DMD, as well as the extensions of these methods such\nas the spectral POD\n8 or the higher-order DMD9, have successfully\nreduced the dimensionality of someﬂows10, their optimal linear bases\nexhibit limitations when working with turbulentﬂows, which typically\ninvolve complex non-linear interactions11.\nIn recent years, machine-learning (ML) techniques have emerged\nas promising approaches for developing ROMs of ﬂuid-ﬂow\ndynamics6,12– 17. One of the potential ML techniques adopted to create\nnon-linear ROMs is the neural networks with convolutional\nReceived: 17 April 2023\nAccepted: 29 January 2024\nCheck for updates\n1Aerospace Engineering Research Group, Universidad Carlos III de Madrid, Leganés, Spain.2Subdirectorate General of Terrestrial Systems, Spanish National\nInstitute for Aerospace Technology (INTA), San Martín de la Vega, Spain.3FLOW, Engineering Mechanics, KTH Royal Institute of Technology, SE-100 44\nStockholm, Sweden.4Mechanical, Materials, and Aerospace Engineering Department, Illinois Institute of Technology, Chicago, IL 60616, USA.\ne-mail: rvinuesa@mech.kth.se\nNature Communications|         (2024) 15:1361 1\n1234567890():,;\n1234567890():,;\nautoencoder architectures18,19. These architectures comprise of both\nan encoder and a decoder trained to minimise the reconstruction error\nbetween the encoded-decoded data and the initial data. The resulting\nencoder allows obtaining a latent-space composed of non-linear\nrepresentations. Then, neural-network architectures suitable for tem-\nporal predictions\n12,20,21, such as long short-term memory (LSTM) net-\nworks, can be used to model the dynamics of the non-linear latent-\nspace, resulting in a fast surrogate model forﬂuid-ﬂow predictions.\nAmong the different autoencoder architectures, variational auto-\nencoders (VAEs) have proven to be ef f e c t i v ef o re n c o d i n gt h es p a t i a l\ninformation ofﬂuidﬂows in non-linear low-dimensional latent-spaces\n12,22.\nUnlike a standard autoencoder, a VAE architecture is based on a prob-\nabilistic framework for describing an observation in latent-space by\nincluding an additional loss term on the latent-space variables. However,\nthe low-dimensional representations obtained using these architectures\nlack the orthogonality of the classical linear-decomposition techniques.\nTo overcome this issue, theβ-VAE architecture introduced in Refs.23,24\nmodiﬁes the loss function of the VAE by adding a regularisation para-\nmeter to balance the reconstruction accuracy with regularisation and\nlatent-space disentanglement. The value of the parameterβ is chosen\nhigh enough to produce a near-orthogonal latent-space representation\nbut as small as possible to avoid increasing the reconstruction error. The\npotential of these architectures to develop a compact and near-\northogonal ROM was reported in Ref.25, where they tested this archi-\ntecture in a high-ﬁdelity simulation of a turbulentﬂow through a sim-\npliﬁed urban environment. The results showed a ROM that was able to\ncapture up to 87.36% of the original energy with onlyﬁve variables in the\nlatent-space, compared to the 32.41% obtained withﬁve POD modes.\nFor the temporal predictions, the LSTM has been shown to be an\neffective architecture in turbulentﬂows\n20,26,27.H o w e v e r ,i nt h el a t e s t\nyears, another neural-network architecture known as transformer28\nappears to have the potential to outperform the LSTM and allow the\ndevelopment of more complex ROMs. The transformer is a deep\nneural-network architecture that has gained widespread attention in\nrecent years due to their state-of-the-art performance in natural-\nlanguage-processing (NLP) tasks such as language translation\n29 or text\ngeneration30. Unlike traditional recurrent neural networks like LSTM,\nwhich process sequential data one element at a time, transformers are\ndesigned to capture long-range dependencies between elements in a\nsequence. This capability is achieved using attention mechanisms\nwhich allow the network to attend to different parts of the input\nsequence at each network layer. As a result, transformers have been\nshown to outperform previous state-of-the-art methods in several NLP\nbenchmarks, often by large margins.\nThe success of transformers in NLP has led to their application in\nother domains, including computer vision\n31,32,a u d i op r o c e s s i n g33,a n d\nrobotics34. In particular, due to their ability to capture long-range\ndependencies, transformers are particularly well suited to model\ndynamic systems35. In fact, transformers are ab l et or e p r e s e n tt h em u l t i -\nscale character of turbulence in long temporal sequences36;t h i sc a n\nonly be captured by LSTMs when separately predicting modes of dif-\nferent ranges of frequencies37. In these applications, the goal is to learn a\nlow-dimensional representation of the system that captures the\nunderlying dynamics, which can then be used to make predictions or\ngenerate new trajectories. Transformers are a promising tool for this\ntask, as they can learn complex temporal dependencies and capture\nlong-term trends in the data while allowing efﬁcient parallel processing.\nThe potential combination of autoencoder architectures, which\nenable obtaining near-orthogonal non-linear latent-spaces, with\ntransformer architectures for the dynamics of the temporal predic-\ntions, is a powerful tool that can be employed to model complexﬂows\nwith a higher level of accuracy. For this reason, in this paper, we pro-\npose aβ-VAE and transformer-based model for encoding theﬂuid-ﬂow\nvelocity ﬁelds and learning a ROM of its spatio-temporal dynamics.\nTwo ﬂow cases are analysed, namely a periodic and a chaotic\nconﬁguration of a two-dimensional, viscousﬂow over two collinearﬂat\nplates, obtained by numerical simulation. Flow past multiple bodies in\nclose conﬁguration is relevant for a range of applications, such as\nbuildings or chimneys in urban andindustrial environments, power\nlines, offshore structures, and heat exchangers. Even at relatively low\nReynolds numbers, suchﬂows can exhibit substantially more com-\nplexity thanﬂow over a single, isolated body\n38– 40.\nThe resulting latent-space ofβ-VAEs is analysed using POD as a\nreference case to analyse the resulting spatial mode features, and\ndifferent latent-spaces are tested. The temporal predictions of the\nlatent-space dynamics performed using transformer-based archi-\ntectures are compared with other ML temporal models, including\nLSTMs and Koopman with Non-linear Forcing\n41. Finally, the predictions\nare assessed using the reconstructed predictedﬁelds and Poincaré\nmaps to assess the dynamic behaviour of the resulting ROMs.\nResults\nAnalysis of the latent-spaces\nIn this section, theβ-VAE architecture and the POD are applied to two\nﬂow cases generated from a numerical simulation of a two-dimen-\nsional, viscousﬂow around two collinearﬂat plates. The characteristics\nof both cases are discussed next:\n Periodic ﬂow with Reynolds number based on the freestream\nvelocityU∞ and (single-plate) chord lengthc of Re =4 0 ,w h e r et h e\ntwo collinear plates are arranged at an angle of 90∘ with respect to\nthe incomingﬂow. Total of 1000 instantaneousﬂow ﬁelds.\n Chaotic ﬂow with Reynolds number ofRe =1 0 0 ,w h e r et h et w o\ncollinear plates are arranged at an angle of 80∘ with respect to\nthe incomingﬂow. Total of 150,000 instantaneousﬂow ﬁelds.\nIn both cases the domain where data is collected has dimensions\n96c ×2 8c, where the spatial resolution is 300 × 98 grid points with a\nuniform grid spacing. The separation between snapshots is one con-\nvective timeΔt = c/U\n∞ = tc for periodic case andΔt = c/U∞/5 =tc/5 for\nchaotic case (downsampled in both space and time from the original\nsimulations). A more detailed dataset description and a sketch of the\nﬂow conﬁg u r a t i o ni sg i v e ni nt h eM e t h o d ss e c t i o n .\nTo compare the performance ofβ-VAE and POD as deﬁned in\nMethods, we deﬁne, following Ref.25,t h ee n e r g yp e r c e n t a g eE that is\ncaptured by the low-order reconstruction as:\nE =1 /C0\nPNp\nP2\ni =1 ðui /C0 ~uiÞ2\nPNp\nP2\ni =1 u2\ni\n*+ !\n× 100%, ð1Þ\nwhere 〈 ⋅ 〉 indicates ensemble averaging in time,Np is the number grid\npoints along the spatial domainui denotes theith reference value of\nﬂuctuating component velocity and~ui its low-order reconstruction,\nrespectively.\nTo assess the orthogonality of the latent variables, we calculate\nthe correlation matrixR =( R)dxd,w h i c hi sd eﬁned as follows:\nRii =1 , Rij = Cijﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ\nCiiCjj\nq , ð2Þ\nfor all 1≤ i ≠ j ≤ d where Cij denotes the componentsi, j of the\ncovariance matrixC and d is the dimension of the latent-space. A value\nof 0 is reached when all the variables are completely uncorrelated\n(R\nij = 0) and one when they are completely correlated (Rij =1 ) . T h i s\nmetric reports the degree of correlation between the latent variables.\nThe modes have been ordered according to their cumulative\ncontribution to the reconstructed energy,E,f o l l o w i n gR e f .25.T h eﬁrst\nmode is chosen as the one with the largest individual contribution toE,\nand the next are those that have the maximum contribution when\nadded to the previous modes.\nArticle https://doi.org/10.1038/s41467-024-45578-4\nNature Communications|         (2024) 15:1361 2\nThe periodic case is used as a benchmark to validate the physical\nsoundness of theβ-VAE model representations. Thisﬂow case can be\nadequately represented only using two POD modes that can represent\nE = 98.4% of the kinetic energy of theﬂuctuations with respect to the\nbase ﬂow, as observed in Fig.1a. Figure1cr e p r e s e n t st h et w om o s t\nenergetic POD modes, which are identiﬁe da sas h e d d i n gw a k e .F o rt h e\nβ-VAE case withβ = 0.001, the results in Fig.1d show the spatial modes.\nThe β-VAE spatial modes are deﬁned as the result of using theβ-VAE\ndecoder network with an input vector,s\ni, containing a unit value in the\ndesired ith element and zero elsewhere,si = δj\ni = ð0, /C1/C1/C1 ,1, /C1/C1/C1 ,0Þ,t h a t\ngives as a result the corresponding spatialith mode. For a detailed\ndescription, the reader is referred to the Methods section. The\nreconstructed energy in this case is equal toE = 97.5%, with a cross\ncorrelation coefﬁcient, R12 = 0.0015. It is observed from Fig.1c, d that\nthe spatial modes obtained from both methods exhibit the same pat-\ntern of sheddingﬂow. The spectrum of the temporal coefﬁcients for\nboth methods is shown in the last column of Fig.1c, d. The spectra\nanalysis is from the resultingr\ni(t)a n dai(t) time coefﬁcients for theβ-\nVAE and POD, respectively. This further conﬁrms that the dynamics\nassociated with the spatial modes are also in good agreement: both\nmethods can capture the same characteristic frequency. This result\nshows that the latent-space also exhibits meaningful physical phe-\nnomena of theﬂows.\nSince the β-VAE architecture requires the user to set a latent-\nspace dimensiond, it can be argued thatd can be set to a value larger\nthan 2. However, we observed that models with larger latent-spaces\nproduce only two meaningful modes, as the remaining modes have\nnegligible values. This behaviour shows that theβ-VAE regularisa-\ntion effectively avoids the artiﬁcial creation of more modes than\nnecessary to represent the solution. In the work by Eivazi et al.\n25 it\nwas shown that the β-VAE produces compact representations of\nlatent-spaces, which suggests that these architectures may be a\ngood framework in cases that can be represented with few energetic\nphenomena.\nFig. 1 | Proof of concept analysis with periodicﬂow case. a, b Fraction of energy\nreconstructed by POD andβ-VAE as a function of number of modes.a Re =4 0 ,\nα =9 0∘,( b) Re = 100,α =8 0∘. c, d Resulting modes for theRe =4 0 ,α = 90 case: (c)\nPOD, (d) β-VAE. Theﬁrst column contains the streamwise-velocity component\nmodes sampled with a unit value, and the second one the crosswise-velocity\ncomponent. The third column represents the frequency content in the temporal\ncoefﬁcient associated with each of the modes (f\nc = U∞/c); note that in (d) this fre-\nquency content is evaluated in the latent-space.\nArticle https://doi.org/10.1038/s41467-024-45578-4\nNature Communications|         (2024) 15:1361 3\nAfter thisﬁrst assessment of the latent-spaces created by theβ-\nVAE architectures, a non-linear and higher-dimensional chaotic case at\nRe = 100 with the two collinear plates arranged at an angle of 80\n∘ with\nrespect to the incomingﬂow is tested. As well as the higher Reynolds\nnumber, the change in angle adds additional complexity to the con-\nﬁguration as the geometry is no longer symmetric with respect to the\nfreestream. In this case, the size of the latent-space is set to be as small\nas possible but large enough to allow the separation of different phy-\nsical effects in the resulting modes. In this relatively complex case, it is\nexpected toﬁnd more variety of effects in theﬂuid ﬂow, requiring a\nmore nuanced mapping to the low-dimensional latent-space, and an\nevident lack of performance of linear methods such as POD.\nTo deﬁne an appropriateβ value, different values were tested\nbetween 0.001 and 0.4 and the correlation matrix andE were cal-\nculated to evaluate the performance in both metrics with aﬁxed\nlatent-space. As previously mentioned, the value ofβ is chosen high\nenough to produce a near-orthogonal latent-space representation\nbut as small as possible to avoid increasing the reconstruction error,\nincreasing β has also been found to slightly improve the general-\nisation of the model, balancing train and test metrics. After this\nstudy, aβ = 0.05 is chosen, and an analysis of the appropriate latent-\nspace is followed. For this analysis, the loss terms from theβ-VAE are\nanalysed during the training process as reported in Fig.2a, with a\nparticular interest in the Kullback-Leibler (KL) divergence loss. The\nﬁgure shows that, as expected, the reconstruction loss is lower for\nthe β-VAE model with larger latent-spaced = 20, as more information\nis allowed to ﬂow through the autoencoder bottleneck. The less\nconstrained latent-space also allows for a lower KL divergence loss,\nmeaning the latent-space distributions are closer to standard nor-\nmal distributions. This lower KL loss also reﬂects the better ability of\nthe model to produce disentangled representations in the latent-\nspace. In this case,E=89.8% for train data andE=80.1% for test data,\nas seen in Fig.1b, indicating a good reconstruction and general-\nisation capability.\nOn the other hand, the model with a smaller latent-spaced =1 0\nconverges to a relatively higher reconstruction loss. Even the KL loss\nterm takes longer to converge during the training process because the\nbottleneck is too strict. Ford = 10, the reconstructed energyE=82.0%\nfor train data andE=61.6% for test data, reﬂect the loss of recon-\nstruction capability due to the constrained bottleneck. The informa-\ntion is compressed into a few modes with less freedom for\ndisentangled representation, a fact that implies that even for these\narchitectures, a minimum number of modes is required to obtain an\nappropriate latent-space. It was also observed that theβ-VAE archi-\ntecture tends to overﬁt the training data if the latent-space is insufﬁ-\ncient to achieve proper disentanglement. Although the model with a\nlatent-space of sized = 10 is considered valid, the loss of general-\nisation, as observed in Fig.2aw i t hap o o rp e r f o r m a n c ei nt h et e s td a t a ,\nmotivates the choice ofd = 20 for the model chosen as a reference for\nthe present study. Apart from the latent-space dimension, the choice\nof β is critical to ensure the generalisation of the latent-spaces. Lowerβ\nvalues produce a large\nE in train data but at the cost of much lowerE\nvalues in test data, which indicates overﬁtting. Increasingβ above a\ncritical value also affects the performance by not only affecting the\ndegree of disentanglement of the latent-space but also decreasing the\nmaximum E obtained, being the classical VAE architectures (β =1 )\ntested with a poor performance in both train and test data. Apart from\nthat, we have also tested a vanilla autoencoder that was unable to\ngeneralise the representation and did not produce a disentangled\nlatent-space, which reinforces the ability of theβ-VAE to perform a\nbetter generalisation\n23.\nFigure.3 shows, for theﬁrst 6 modes, theu and v components and\nthe spectrum obtained form the temporal modes associated with each\nmode, while Fig.4 shows the same quantitiesobtained using POD. The\nFig. 2 | Training and latent space analysis. aEvolution ofβ-VAE losses during training: (left) 10 modes, (right) 20 modes, (solid) train, (dashed) test. Losses are deﬁned in\nthe Methods section.b, c Correlation matrices corresponding to theβ-VAE mode coefﬁcients for the case withRe = 100,α =8 0∘.\nArticle https://doi.org/10.1038/s41467-024-45578-4\nNature Communications|         (2024) 15:1361 4\nspectral analysis of the temporal dynamics of the modes is used to\nidentify different modes representing the same physical effect and\nprovides helpful information for determining the size of the latent-\nspace, since it allows more meaningful comparison with the POD. In this\ncase, theβ-VAE spatial modes are a non-linear combination of the most\nrelevantﬂow features. Comparing theβ-VAE and POD spectra, it can be\nseen that theβ-VAE model can better separate different phenomena,\neach of which has its characteristic frequency associated with it, which\nappears as a peak in the spectrum. The different effects can be further\nisolated as individual modes by using larger latent-spaces. However, it is\nobserved that the frequencies associated with the most energetic POD\nmodes appear in theβ-VAE dynamics, suggesting the idea that theβ-VAE\nlatent-spaces canﬁnd non-linear modes that effectively represent the\ndynamics of the system. The effectof the mode disentanglement pro-\nduced by β-VAE models can be observed in the correlation matrix\nbetween the time series of each mode, Fig.2b, c. As reported, the cor-\nrelation between different modes of the time series is almost negligible\ndue to the near-orthogonal representation in the latent-space. It is\nobserved that theβ-VAE also appears to be able toﬁnd pairs of modes\nthat represent the orthogonal components of the harmonics of the\nvortex-shedding process that represents the large-scale convective\nstructures of the vortex wake studied\n42,s u c ha si nP O Dm o d e s .\nLatent-space predictor models\nIn this section, the temporal dynamics of the latent-spacer(t) for the\ncase d =1 0 a n dd = 20 are combined with different ML models to\nimplement a framework able to predict the temporal dynamics in the\nlatent-space that can be used with the decoder from theβ-VAE to\nobtain ﬂow-ﬁeld temporal predictions. With this purpose, two trans-\nformer models, self-attention28 and easy attention43, a Koopman with\nNon-linear Forcing (KNF) model41, and an LSTM network44 are imple-\nmented and compared. The KNF and LSTM models have previously\nbeen analysed and compared in Ref.27 and applied to predict the\ntemporal dynamics of a low-order model of near-wall turbulence,\nshowing that both approaches can reproduce the temporal dynamics\nof this system. Furthermore, the transformer has been used in the\ncontext of temporal predictions of turbulentﬂows in Ref.36. The four\nmodel architectures were tuned to obtain the lowest mean-squared\nerror over the validation data, with the self-attention transformer later\ndiscarded for clarity due to the signiﬁcantly better results obtained by\nthe easy-attention model.\nAll three predictor models are trained to predict the next time\nstep of a temporal sequence of previous latent-spacer(t) vectors.\nFurther details of the process and hyperparameter choice are detailed\nin the Methods section. Once trained, the models are used recursively\nto predict the next time steps. By predicting long time series, we can\ndetermine whether the model has been able to learn the system\ndynamics correctly. Fig.5 shows the reference valuesr\ni(t)o b t a i n e db y\nencoding the test data using the previously trainedβ-VAE and the\ncorrespondingpi(t) predictions from each model.\nAs expected for a chaotic dynamical system, all predictor models\ndiverge from the original trajectory after several time steps and appear\nFig. 3 | Analysis ofβ-VAE modes.Resulting β-VAE sixﬁrst spatial modes forRe =\n100,α =8 0∘ ranked according to their contribution toE.T h eﬁrst column containsu\nvalues for modes sampled withsi = 1. The second column shows thev values for the\nsame inputs. The third column represents the frequency content of each individual\nmode (fc = U∞/c).\nArticle https://doi.org/10.1038/s41467-024-45578-4\nNature Communications|         (2024) 15:1361 5\nto exhibit similar quantitative performance. To further evaluate the\ndeviation error after several time steps, the ensemble average of the L2\nerror norm to the prediction horizon is deﬁned as:\nεðΔtÞ =\nX\nd\ni =0\npiðtÞ/C0 riðtÞ\n/C0/C1 2\n ! 1=2*+\nensemble\n: ð3Þ\nThis quantity is shown in Fig.6a and the ensemble is computed over\n100 evenly spaced windows in the test data to capture the average\ntrend. This plot shows how the errorε(Δt) increases as the prediction\nhorizonΔt gets longer. It can be seen that the error growth of the easy-\nattention transformer is always one of the slowest, in particular for the\nmodels trained withΔt =0 . 2t\nc. The better behaviour of the transformer\nfor cases sampled more densely in time could be the result of a better\nability to represent the multiple time scale phenomena present in the\ndata. However, the error growth over the prediction horizon does not\nprovide any information about the long-term behaviour of the\npredictions associated with proper learning of the system dynamics.\nTherefore, this aspect is further evaluated in terms of the dynamic\nbehaviour of the system through the Poincaré-map analysis using the\npredictions for the 3000 test data time steps not seen during the\ntraining process.\nThe Poincaré map is constructed as the intersection of the latent\nvectors with the hyperplaner\n1 =0 o n t h er2 − r3 space with direction\ndr1/dt > 0, using then a probability density function (PDF) toﬁtt h e\nresulting intersection points. These distributions are plotted for the\ntrue data and the model predictions in Fig.6b– d. Thisﬁgure shows the\ncorrelation between the amplitudes of ther2 and r3 latent variables at\nthe intersection. It can be seen from theseﬁgures that the KNF models\ndo not adequately reproduce the variability of this correlation. This\nresult can be explained by the tendency of the KNF model to converge\ntowards a harmonic behaviour as the prediction progresses, which\ndoes not capture the variability in the evolution of the temporal\ncoefﬁcients that represent this chaoticﬂow. The LSTM and, above all,\nthe transformer, produce accurate predictions of the dynamics of the\nsystem using the patterns and correlations between the differentr\ni(t)\nin the latent-space learned by theβ-VAE. This comparison between\nmodels suggests that focusing only on instantaneous predictions may\nnot be the correct approach to develop ROM models based on ML\ntechniques. The choice of latent variablesr\ni(t)f o rt h i sﬁgure is moti-\nvated by the fact that these are the most relevant in terms of recon-\nstructing E. Still, this procedure was reproduced for all the\ncombinations ofr\ni(t), being the quality of the results of the Fig.6b– d\nrepresentative for all the cases. Finally, theﬁrst six probability density\nfunctions of the predicted latent-space are shown in Fig.6e, where it\ncan be seen that the transformer model is better able to capture the\nvariability of the latent-space.\nUsing the latent vectors predicted with the transformer, we can\ndevelop a ROM of the ﬂow in the latent-space that captures the\nunderlying dynamics, as shown by the Poincaré maps, and then using\nthese predictedr\ni(t) values theβ-VAE decoder network can be used to\nFig. 4 | Analysis of POD modes.POD spatial modes forRe = 100,α =8 0∘.T h eﬁrst column containsu values for each POD mode and the second column shows thev values.\nThe third column represents the frequency content of each individual modeai(t)( fc = U∞/c).\nArticle https://doi.org/10.1038/s41467-024-45578-4\nNature Communications|         (2024) 15:1361 6\nproject the predicted latent-space vector back into physical space,\ncompleting theﬂow ﬁeld prediction model. The results of this pre-\ndiction are shown in Fig.7.I nt h eﬁgure, theﬁrst column shows the\nactualt + n ﬂow ﬁeld in the dataset, the second column shows the same\nsnapshot compressed into latent-space and decompressed by theβ-\nVAE network, and the last column shows theﬁeld predicted by the\nROM created using theβ-VAE and each predictor model. To assess the\nperformance of the complete ROM model, the reconstructed energy\nover the prediction horizon is calculated using an ensemble over 50\nevenly-spaced windows in the test data. The results shown in Fig.8a\nindicate a better reconstruction ability for models usingd =2 0 , a s\nexpected due to the less restrictive autoencoder bottleneck. For the\nd = 20 case, models perform better when usingΔt = t\nc, although the\neasy-attention transformer appears to be less sensitive to theΔt used,\nas previously discussed. The KNF models fail to produce accurate\npredictions in the cases considered. As seen in Fig.8a, all predictions\nwill diverge over time as small initial ﬂuctuations in the model\naccumulate over time, to analyse if the predicted velocityﬁelds still\nreproduce the dynamics of the system, we compare the POD of the\noriginal test data with the predictedﬁelds for the same data, in Fig.8b\nthe results are compared, showing that the predictedﬁelds still pro-\nduce similar POD modes as the original data. These results reinforce\nthe quality of the reconstruction observed in Fig.7 and show that the\nmodel adequately reproduces the ﬂow dynamics, reinforcing the\nrobustness of the methodology proposed in this work.\nDiscussion\nThis study presents and evaluates a ROM framework based onβ-VAE\narchitectures to produce robust non-linear latent-spaces, combined\nwith the time-prediction model obtained by means of a transformer\narchitecture. Using a two-dimensional viscousﬂow around two colli-\nnear ﬂat plates in periodic and chaotic regimes, aﬁrst analysis of theβ-\nVAE capabilities and the latent-spaces generated using these techni-\nques is assessed and compared with the ROM obtained through POD\nFig. 5 | Temporal evolution in the latent-space.Example of a trajectory of the latent-space modes with their associated predictions by different models: (a) Re =4 0 ,\nα =9 0∘,( b) Re = 100,α =8 0∘,s i xﬁrst modes.\nArticle https://doi.org/10.1038/s41467-024-45578-4\nNature Communications|         (2024) 15:1361 7\nmodes. For the periodic case, it is observed that the same modal fea-\ntures are obtained, representing a vortex shedding with an equivalent\nnumber of energetic modes. For the chaotic case, theβ-VAE learns a\ncompact near-orthogonal latent-space that signiﬁcantly improves the\nenergy reconstruction obtained by the POD using 20 modes,E =8 9 . 8 %\nfor train data againstE = 64.4% for POD. While theβ-VAE ROM com-\nprises 20 modes, a total of 69 POD modes would be required to match\nthe result obtained by theβ-VAE (in terms ofﬂow reconstruction). The\nresulting modes from theβ-VAE analysis exhibit temporal dynamics\nwith shedding frequencies equivalent to those observed in the most\nenergetic POD modes suggesting that theβ-VAE is able to obtain non-\nlinear modes that represent the most energetic or representativeﬂow\nfeatures.\nThe latent-space generated by theβ-VAE is combined with a\ntransformer architecture to predict the temporal dynamics. Its per-\nformance is compared against other models used in previous studies,\nsuch as LSTM or KNF. The results show that the LSTM and easy-\nattention transformer models are superior to the KNF model. In par-\nticular, the inherent ability of the transformer model to learn an\ninternal representation with different frequency contents provides a\nmore robust prediction for different time steps between snapshots\ncompared to LSTM models. The analysis of the predictions shows that\nthe transformer can learn the correlations among the various temporal\ncoefﬁcients. Combining theβ-VAE and the transformer models, we\nobtain a ROM model that can produce predictions withE of 78.1% and\n64.6% at t + t\nc and t +1 0tc, respectively, for previously unseen data,\nFig. 6 | Analysis of the predictions in latent-space.Case withRe =1 0 0 ,α =8 0∘:( a)\nAverage prediction error over the prediction horizon,b– d Poincaré sections with\nplaner1 =0a n ddr1/dt > 0, black lines correspond to the original data and blue lines\nto the predicted data.e Probability density functions of predicted variables.\nb– e Case with latent-space sized =2 0a n dΔt = tc.\nArticle https://doi.org/10.1038/s41467-024-45578-4\nNature Communications|         (2024) 15:1361 8\nwhile capturing the originalﬂow patterns. This study constitutes a\nproof of concept of the capabilities of these novel ML techniques to\ngenerate compact and robust non-linear ROMs that can be employed\nto generate predictions in chaoticﬂows while capturing the most\nrelevant ﬂow features. The combination of various VAE and transfor-\nmer architectures exhibits great potential for the future of ROM\ndevelopment inﬂuid mechanics, leveraging the inherent nonlinearities\nof these techniques.\nMethods\nDataset description and pre-processing\nThe source data set is an incompressible, two-dimensional, viscous\nﬂow over two collinearﬂat plates. Numerical simulation is used to\nsolve the governing Navier– Stokes equations for thisﬂow using an\nimmersed-boundary projection method (IBPM)\n45,46.T h et w op l a t e s\nhave a chord lengthc and are separated by a gapg o ft h es a m es i z e .T h e\nfree stream velocity isU∞, and the Reynolds number,Re,i sd eﬁned\nbased on the free stream velocity and single-plate chord length. A\ndiagram of the conﬁguration of theﬂow is shown in Fig.9c.\nThe simulations are performed on a series of nested grids of\nincreasing size and decreasing resolution. Theﬁnest resolution for the\nsimulation has a grid spacing ofΔx = Δy =0 . 0 2c, and the total com-\nputational domain has dimensions of 96c ×2 8c, with the upstream\nboundary atx = − 9c. The dataset generation and its characteristics are\ndescribed in more detail in Ref.47. The time step in the dataset\n(downsampled from the simulations) was chosen to be equal to 20% of\nthe convective timeΔt = c/U\n∞/5 =tc/5, which is sufﬁcient to resolve the\ndynamics of coherent vortical structures in the wake. In order to\ninvestigate the inﬂuence of the temporal resolution in the results, a\nnumber of models were trained with one snapshot in everyﬁve, being\nFig. 7 | ROM predictedﬁelds. True, reconstructed and predictedﬁelds foru and v velocity components att +1 0tc:( a)K N F ,(b) LSTM, and (c) transformer with easy\nattention.\nArticle https://doi.org/10.1038/s41467-024-45578-4\nNature Communications|         (2024) 15:1361 9\nΔt = c/U∞ = tc. For all the models, the time series of the snapshots is\ndivided into two time series covering the respective time intervals:\n[0, t\ntrain]a n d[ttrain +1 ,tend]w h e r ettrain =2 7 ,0 0 0tc, which corresponds\nto 90% of the snapshots time series. Theﬁrst period of the data is used\nfor training, while the remaining 10% is used as test data to validate the\ngeneralisation capability of the models.\nThe dataset employed for this study is downsampled from the\noriginal mesh to a spatial resolution of 300 × 98 with a uniform grid\nFig. 8 | Analysis of predictedﬁelds. aAverageE evolution over the prediction horizon.b POD modes comparison of true and predictedﬁelds. This is shown for the case\nwith Re = 100,α =8 0∘.\nArticle https://doi.org/10.1038/s41467-024-45578-4\nNature Communications|         (2024) 15:1361 10\nspacing, to reduce the GPU requirements for training. Theﬂuctuation\ncomponents of the streamwiseu and crosswisev velocity were stacked\nas separate channels in the dataset. The values in the dataset were\nstandardised by subtracting the pixel-wise average and dividing by the\nstandard deviation for each velocity component over the entire data-\nset. The resulting dataset size was reduced to 31.7 GB and fully loaded\ninto memory during training. This approach allowed the training\nprocess to be efﬁcient while still capturing the essential features of the\nﬂuid ﬂow.\nβ-VAE implementation details\nThe variational autoencoder (VAE) described in Kingma and\nWelling48 is one of the most common architectures used in gen-\nerative models. In the basic autoencoder architecture, the inputx is\ndirectly encoded as a vectorr using the encoder E, r = EðxÞ,i na\nlower-dimensional space of sized, which can be mapped back to the\noriginal space by the decoder~x = DðrÞ, being ~x the reconstructed\noutput. A disadvantage of conventional autoencoders is the fact\nthat there are no constraints imposed on the learned latent-space.\nFig. 9 | Model architectures and case schematic. aβ-VAE encoder and decoder, (b) transformer. The dimension of the output for each layer has been indicated in each\nblock. The symbolsT and dmodel denote the time-delay, MHA denotes multi-head attention.c Schematic representation of the numerical setup.\nArticle https://doi.org/10.1038/s41467-024-45578-4\nNature Communications|         (2024) 15:1361 11\nThe lack of constraints in the generated latent-space can lead to\noverﬁtting and poor generalisation performance, especially for\nhigh-dimensional input data. In contrast, in VAE architectures the\nencoder maps input data to a parameterised prior distribution,\nusually a Gaussian distribution, in the latent-spaceμ,σ = EðxÞ, where\nμ and σ denote the mean and the standard deviation, respectively.\nThe prior Gaussian distribution encourages the model to learn a\ncompact and smooth representation of the input data. The dis-\ntribution of the latent-space is then randomly sampled, and this\nsample is decoded back into the original space by the decoder\n~x = DðsÞ, withs following a distributions ~ N(μ, σ). The architecture\ncan therefore produce different outputs for the same input data,\neach sampled from the corresponding latent distribution. The\nencoder and decoder neural networks are trained by gradient des-\ncent and backpropagation, enabled by a re-parameterisation of the\ndistribution sampling\n48. The training process for the VAE involves\nsimultaneous training of the encoder and decoder networks with a\ncompound loss functionL,\nLðxÞ =\n1\nNt\nXNt\ni =1\nðx /C0 ~xÞ2\n|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}\nReconstruction loss\n/C0 1\n2\nXd\ni =1\n1 + logðσ2\ni Þ/C0 μ2\ni /C0 σ2\ni\n/C0/C1\n|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}\nKL loss\n, ð4Þ\nwhere Nt denotes the total number of points the inx.T h eﬁrst term in\nthe loss function is the reconstruction loss,Lrec , which measures the\nmodel accuracy in reconstructing the input data from the reduced\nlatent-space representation. The second term in the loss function is the\nKullback– Leibler (KL) divergence loss\n49, LKL , which measures the\ndifference between the generated probability distribution and a prior\nprobability distribution, typically Gaussian. The overall training goal is\nto optimise the model to produce accurate reconstructions\nwhile keeping the latent distributions close to a standard normal\ndistribution.\nThe original VAE architecture was extended by Higgins et al.\n50 to\nthe β-variational autoencoder (β-VAE) architecture, which aims to\npromote disentangled representations in latent-space23.T h eβ-VAE\nloss function, deﬁned in equation (5), includes a scalar hyperparameter\nβ≥0 that modulates the trade-off between reconstruction accuracy\nand latent-space disentanglement. A higher value ofβ results in a more\ndisentangled representation but may decrease reconstruction accu-\nracy, whereas lower value ofβ may result in a more accurate recon-\nstruction but a less disentangled latent-space. As a result, by\nincorporating the β parameter into the loss function, the β-VAE\narchitecture can achieve a more interpretable and disentangled latent-\nspace, which may improve the model generalisation ability.\nLðxÞ = L\nrec /C0 β\n2 LKL : ð5Þ\nThe β-VAE architecture is adapted from Ref.25.T h ee n c o d e ri s\nused to generate the temporal modes for the latent-space repre-\nsentation using the mean vector for each time stepr(t)= μ(t). The\nmean vectors are generated by applying the encoderE to each input\ntimestep: μðtÞ,σðtÞ = EðxðtÞÞ. The spatial modes are reconstructed one\nby one:Y\ni = DðsiÞ.H e r eYi is theith spatial mode,D is the decoder andsi\nis the vector that selects the mode to be reconstructed\n(si = δj\ni = ð0, /C1/C1/C1 ,1, /C1/C1/C1 ,0Þ). Theβ-VAE architecture is sketched in Fig.9a.\nThe nature of the data determines the choice of a convolutional\nneural network (CNN) to build the encoder, since the patterns in the\nﬂow can be better captured by convolutional layers that preserve\nthe spatial relationships between points in the input. Fig.9a shows a\nrepresentation of the model. In the encoder, we use six convolu-\ntional layers with a stride of two so that each layer halves the spatial\ndimension. The spatial reduction allows the subsequent layers to\ncapture information at larger scales in the inputﬂow data, which also\nhas similarities to the multiple scales of the studied chaoticﬂow and\ncan help to represent it. The number ofﬁlters in each layer pro-\ngressively increases to preserve the informationﬂow while reducing\nthe spatial dimension. After the sixth convolutional layer, the spatial\ninformation is discarded, and a fully-connected layer is added to\ncombine the information. Finally, two parallel layers with the same\nnumber of units as the latent-space dimension are used to output\nthe mean and variance of the latent statistical distributions. During\ntraining, the distributions are sampled to generate inputs to the\ndecoder network, while only theμ(t) values are used to encode the\ntime series used later by the predictor.\nThe decoder model is designed as an almost symmetric network\nto the encoder. Latent-space samples are fed into a fully-connected\nlayer, and its output is reshaped to the same shape as the last con-\nvolutional layer in the encoder. Six transposed convolution layers are\nthen used to increase the spatial dimension with decreasing number of\nﬁlters. Aﬁnal transposed convolution layer with twoﬁlters produces\nthe two output channels. The chosen activation function is the expo-\nnential linear unit (ELU)\n51 for all layers except the last, where the acti-\nvation is linear.\nIt is well known that chaoticﬂows often involve complex, non-\nlinear interactions betweenﬂuid particles, which can lead to non-\nlinear relationships between variables. As a result, the dominant\nmodes of variability may not capture the complex, non-linear\nbehaviour of the ﬂow. This effect can be seen in Supplementary\nFig. 1, where theﬁrst input to theβ-VAE decoder network is sampled\nwith different scalar values while the remaining inputs are kept to\nzero. The mode is sampled with input values in the ranges\n1 ∈ [ − 2, 2]\nbecause during VAE training the latent-space is sampled from a near-\nstandard normal distribution, driven by the KL-loss regularisation\nduring training. The non-linear representation is evident as the\nshedding wake patterns change with the latent input value. This non-\nlinear representation allows the β-VAE architecture to reproduce\nE = 89.8% with only 20 modes. In contrast, POD only yieldsE = 64.4%\nand would require using over 69 modes to obtain a reconstruction\nabove E = 90%.\nProper orthogonal decomposition\nIn this section POD is employed as a reference to compare the\nresulting modes from theβ-VAE latent-space with those obtained\nusing this classical method. In particular, the snapshot method52 has\nbeen used for the present study. Considering the streamwise and\ncrosswise velocity components de ﬁned as U(x, t)a n d V(x, t),\nrespectively, beingx =( x, y) withx and y the streamwise and cross-\nwise coordinates andt the time. We decompose the velocity com-\nponents as:\nUðx,tÞ =\nUðxÞ + uðx,tÞ, Vðx,tÞ = VðxÞ + vðx,tÞ ð6Þ\nwhere UðxÞ and VðxÞ are the streamwise and crosswise time-averaged\nvelocity components andu(x, t)a n dv(x, t) are the streamwise and\ncrosswiseﬂuctuating velocity components. Theﬂuctuating quantities\ncan be approximated as a linear combination of basis functionsϕi(x)\nas:\nuðx,tÞ ≈\nXNm\ni =1\nau\ni ðtÞϕu\ni ðxÞ, vðx,tÞ ≈\nXNm\ni =1\nav\ni ðtÞϕv\ni ðxÞ, ð7Þ\nwhere ai(t) are time-dependent coefﬁcients andNm is the number of\nbasis functions used. Here we assume a number of imagesNt,e a c ho n e\nconsisting ofNp grid points along the spatial domainx,w i t hNt < Np.\nFollowing the snapshot method52, each image can be treated as anNp-\nArticle https://doi.org/10.1038/s41467-024-45578-4\nNature Communications|         (2024) 15:1361 12\ndimensional vector and the data can be arranged into anNt × Np\nsnapshot matrix:\nu =\nuðx1,t1Þ/C1 /C1 /C1 uðxNp\n,t1Þ\n..\n. . .\n. .\n.\n.\nuðx\n1,tNt\nÞ/C1 /C1 /C1 uðxNp\n,tNt\nÞ\n2\n66\n64\n3\n77\n75; v =\nvðx\n1,t1Þ/C1 /C1 /C1 vðxNp\n,t1Þ\n..\n. . .\n. .\n.\n.\nvðx\n1,tNt\nÞ/C1 /C1 /C1 vðxNp\n,tNt\nÞ\n2\n66\n64\n3\n77\n75:\nð8Þ\nUsing the snapshot matrix, the two-point correlation matrix can\nbe written asG = uu\nT + vvT, where the superscriptT refers to the matrix\ntranspose. Solving the eigenvalue problem ofG returns the eigenva-\nlues λi and the left and right eigenvector matrices. The left and right\neigenvector matrices are respectively the matrixΨ containing in its\ncolumns the temporal modesai(t) (which are orthonormal vectors of\nlength Nt and unitary norm) and its inverse (i.e. its transpose). Note\nthat the columns ofΨ form a basis of rankNt and that the eigenvalues\nλi are representative of the energy contribution of each mode. The\northonormal spatial modesϕn(x) can then easily be computed as\nΣu ϕu = ΨTu and Σvϕv = ΨTv,w h e r eΣu and Σv are diagonal matrices\nwhich, in eachith diagonal element, contain the streamwise and wall-\nnormal Reynolds-stress contributions of theith mode.\nFor consistency purposes, the POD is computed using the snap-\nshots time series that covers the time interval [0,ttrain].\nTime-series prediction models\nThe β-VAE encoder network generates the entire dataset latent-space\ntime series,r(t), where the snapshots time series is divided into two\ntime series that cover the following time intervals: [0,ttrain]a n d\n[ttrain +1 ,tend]w h e r ettrain =2 7 ,0 0 0tc that corresponds to the 90% of\nthe snapshots time series. Theﬁrst period of the data is used for\ntraining being the last 10% used as test data. Note that the test data\nhave not been used for training theβ-VAE and is only encoded by the\npreviously trainedβ-VAE model. The transformer model is used to\npredict the latent-space vectorr(t + 1). In the present study, we use the\ntime-delay\n53 dimension of 64 steps for temporal prediction, which\nmeans that the input to the transformer is a sequence of the previous\n64 time steps, and the output is the prediction of the next time step for\nthe latent vector in the sequence. The transformer is trained to mini-\nmise the difference between the prediction of the next time step and\nthe true data using a mean-squared-error loss function.\nA time-space embedding module is added to each input latent-\nspace vector to incorporate temporal and spatial information before\npassing it to the transformer blocks, allowing the model to distinguish\nbetween latent vectors generated at different time steps. The pooling\nlayers are designed to draw the characteristic information from time-\nseries data, facilitating the model to capture the key information of\ntemporal dynamics of the physical system. Note that we adopt stride\nsteps of two for one-dimensional average pooling and maximum\npooling.\nThe transformer model comprises a stack of transformer encoder\nblocks, each consisting of a multi-head attention block and a feed-\nforward neural network. Note that, in the present study, we employ\ntwo types of attention mechanisms: self-attention\n28 and easy\nattention43, which has demonstrated promising performance in pre-\ndicting the temporal dynamics of chaotic systems, and in our case\nsigniﬁcantly outperforms self-attention transformer. The attention\nblocks allow the model to weigh the importance of different parts of\nthe input sequence when making predictions\n54,w h i l et h ef e e d - f o r w a r d\nnetwork allows it to learn complex non-linear relationships between\nthe input and output sequences. In the present study, we use four\nheads for attention modules to implement multi-head attention and\nadopt a feed-forward dimension of 128. We adopt four transformer\nblocks to ensure the capability to identify the complex dynamics in\nlatent-space. After the transformer blocks, a one-dimensional con-\nvolutional network and a fully-connected layer are added to decode\nthe transformer output and form theﬁnal latent-space vector predic-\ntion. The architecture is illustrated in Fig.9b.\nThe LSTM model architecture includes four layers of LSTM ele-\nments, followed by a fully-connected layer of 128 neurons and aﬁnal\noutput layer matching the latent-space size. The time-delay dimension\nfor the LSTM is the same as transformer models.\nThe KNF-model implementation is based in the code from Ref.27.\nAfter the hyperparameter tuning, the number of previous time steps\nused to predict is 5, and the maximum order of the functions for\nconstruction of the forcing term is 3 for polynomial functions and 4 for\ntrigonometric functions.\nTraining setup\nThe Torch 2.0 deep-learning framework55 was used to implement the\nmodels and the training pipeline. An NVIDIA GeForce RTX 4090 and an\nNVIDIA A100 GPU were used to train theβ-VAE models and transfor-\nmer models, respectively. Training theβ-VAE model and transformer\ntook approximately 40 minutes and 100 minutes, respectively. Theβ-\nVAE model is trained using the Adam algorithm\n56. The learning rate is\nvariable with a one-cycle schedule as proposed in57, starting at 1 × 10-4,\nwith a maximum value of 2 × 10-4 at 20% of the training epochs and\ndecreasing to 5 × 10-6 at the end of the training. The model was trained\nover 1000 epochs using batch size of 256. The encoder and decoder\nnetwork have 1.06 × 10\n6 trainable parameters each. Theﬁrst 90% of the\nsnapshots time series are used for training, and the remaining are used\nfor testing the models.\nThe resulting temporal dynamics from theβ-VAE are then used to\ntrain a transformer architecture using the Adam algorithm\n56 with ϵ of\n1×1 0−8 for stability reasons. The learning rate was initially set to 1 × 10−3\nand decreased to 6.6 × 10−6 within 1,000 epochs via exponential decay\nusing a decay rate of 0.99, whereas the batch size was set to 256. Note\nthat for the case with a sampling factor of 5, we set the early-stopping\nschedule with respect to the loss, which stops the training process\nafter 50 epochs if the error value is no longer decreasing. Table1\nsummarises the employed architectures in the present study. The last\n10% of time steps are not used during training are utilised as test data.\nData availability\nAll datasets used in this study are openly available in Zenodo, acces-\nsible at:https://doi.org/10.5281/zenodo.10501215.\nCode availability\nThe codes used for this work are available at:https://github.com/KTH-\nFlowAI/beta-Variational-autoencoders-and-transformers-for-reduced-\norder-modelling-of-ﬂuid-ﬂows.\nReferences\n1. Jiménez, J. Coherent structures in wall-bounded turbulence.J. Fluid\nMech. 842,P 1( 2 0 1 8 ) .\nT a b l e1|S u m m a r yo ft h ea r c h i t e c t u r e se m p l o y e di nt h et i m e -\nseries prediction\nName Self Easy LSTM\nTime-delay (T)6 4 6 4 6 4\ndmodel 64 64 –\nFFD/Hidden 128 128 128\nNo.heads 4 4 –\nNum layers 4 4 4\nNo.Parameters 1.45 × 10\n5 1.59 × 105 4.79 × 105\nWe denote the size of time delay asT and the embedding size asdmodel, respectively. Note that\nFeed-Forward denotes the dimension of the feed-forward network in the transformer encoder\nwhile the hidden-state dimension of the LTSM layer is denoted as Hidden-State, respectively.\nArticle https://doi.org/10.1038/s41467-024-45578-4\nNature Communications|         (2024) 15:1361 13\n2. Taira, K. et al. Modal analysis ofﬂuid ﬂows: An overview.AIAA J.55,\n4013 (2017).\n3. Taira, K. et al. Modal analysis ofﬂuid ﬂows: Applications and out-\nlook. AIAA J.58, 998 (2020).\n4 . R o w l e y ,C .W .&D a w s o n ,S .T .M o d e lr e d u c t i o nf o rﬂow analysis and\ncontrol.Annual Rev. Fluid Mech.49,3 8 7( 2 0 1 7 ) .\n5. Lucia, D. J., Beran, P. S. & Silva, W. A. Reduced-order modeling: new\napproaches for computational physics.Progr. Aerospace Sci.40,\n51 (2004).\n6 . B r u n t o n ,S .L . ,N o a c k ,B .R .&K o u m o u t s a k o s ,P .M a c h i n el e a r n i n gf o r\nﬂuid mechanics.A n n u .R e v .F l u i dM e c h .52, 477 (2020).\n7. Schmid, P. J. Dynamic mode decomposition of numerical and\nexperimental data.J. Fluid Mech.656,5( 2 0 1 0 ) .\n8. Sieber, M., Paschereit, C. O. & Oberleithner, K. Spectral proper\northogonal decomposition.J. Fluid Mech.792, 798 (2016).\n9. Le Clainche, S. & Vega, J. M. Higher order dynamic mode decom-\nposition.SIAM J. Appl. Dyn. Syst.16, 882 (2017).\n10. Abreu, L. I., Cavalieri, A. V., Schlatter, P., Vinuesa, R. & Henningson,\nD. S. Spectral proper orthogonal decomposition and resolvent\nanalysis of near-wall coherent structures in turbulent pipeﬂows. J.\nFluid Mech.900, A11 (2020).\n11. Berkooz, G., Holmes, P. & Lumley, J. L. The proper orthogonal\ndecomposition in the analysis of turbulentﬂows. Annual Rev. Fluid\nMech. 25, 539 (1993).\n1 2 . E i v a z i ,H . ,V e i s i ,H . ,N a d e r i ,M .H .&E s f a h a n i a n ,V .D e e pn e u r a ln e t -\nworks for nonlinear model order reduction of unsteadyﬂows. Phys.\nFluids 32,1 0 5 1 0 4( 2 0 2 0 ) .\n13. Hijazi, S., Stabile, G., Mola, A. & Rozza, G. Data-driven pod-galerkin\nreduced order model for turbulentﬂows. J. Comput. Phys.416,\n109513 (2020).\n14. Murata, T., Fukami, K. & Fukagata, K. Nonlinear mode decomposi-\ntion with convolutional neural networks forﬂuid dynamics.J. Fluid\nMech. 882, A13 (2020).\n15. Vinuesa, R. & Brunton, S. L. Enhancing computationalﬂuid\ndynamics with machine learning.Nat. Comput. Sci.2, 358 (2022).\n16. Fukami, K., Nakamura, T. & Fukagata, K. Convolutional neural net-\nwork based hierarchical autoencoder for nonlinear mode decom-\nposition ofﬂuid ﬁeld data.Phys. Fluids32, 095110 (2020).\n17. Luo, Z. et al. Flow reconstruction from sparse sensors based on\nreduced-order autoencoder state estimation.Phys. Fluids\n35 (2023).\n18. Zhang, B. Nonlinear mode decomposition via physics-assimilated\nconvolutional autoencoder for unsteadyﬂows over an airfoil.\nPhys.Fluids35 (2023).\n19. Raj, N. A., Tafti, D. and Muralidhar, N. Comparison of reduced order\nmodels based on dynamic mode decomposition and deep learning\nfor predicting chaoticﬂow in a random arrangement of cylinders.\nPhys. Fluids35 (2023).\n20. Srinivasan, P. A., Guastoni, L., Azizpour, H., Schlatter, P. & Vinuesa,\nR. Predictions of turbulent shearﬂows using deep neural networks.\nP h y s .R e v .F l u i d s4, 054603 (2019).\n21. Maulik, R., Lusch, B. and Balaprakash, P. Reduced-order modeling\nof advection– dominated systems with recurrent neural networks\nand convolutional autoencoders.Phys. Fluids33 (2021).\n2 2 . A k k a r i ,N . ,C a s e n a v e ,F . ,H a c h e m ,E .&R y c k e l y n c k ,D .Ab a y e s i a n\nnonlinear reduced order modeling using variational autoencoders.\nFluids 7, 334 (2022).\n23. Burgess, C. P. et al. Understanding disentangling inβ-VAE, arXiv\npreprint arXiv:1804.03599(2018).\n2 4 . H i g g i n s ,I .e ta l .β-vae: Learning basic visual concepts with a con-\nstrained variational framework, inInternational conference on\nlearning representations(2017).\n25. Eivazi, H., Le Clainche, S., Hoyas, S. & Vinuesa, R. Towards extrac-\ntion of orthogonal and parsimonious non-linear modes from tur-\nbulent ﬂows. Expert Syst. Appl.202, 117038 (2022).\n26. Nakamura, T., Fukami, K., Hasegawa, K., Nabae, Y. & Fukagata, K.\nConvolutional neural network and long short-term memory based\nreduced order surrogate for minimal turbulent channelﬂow. Phys.\nFluids 33, 025116 (2021).\n27. Eivazi, H., Guastoni, L., Schlatter, P., Azizpour, H. & Vinuesa, R.\nRecurrent neural networks and Koopman-based frameworks for\ntemporal predictions in a low-order model of turbulence.Int. J. Heat\nFluid Flow90, 108816 (2021).\n28. Vaswani, A. et al. Attention is all you need, inAdvances in Neural\nInformation Processing Systems, Vol. 30, edited by Guyon, I., Lux-\nb u r g ,U .V . ,B e n g i o ,S . ,W a l l a c h ,H . ,F e r g u s ,R . ,V i s h w a n a t h a n ,S .a n d\nGarnett, R. (Curran Associates, Inc., 2017)https://proceedings.\nneurips.cc/paper/2017/ﬁle/3f5ee243547dee91fbd053c1c4a845aa-\nPaper.pdf.\n29. Yang, S., Wang, Y. and Chu, X. A survey of deep learning techniques\nfor neural machine translation,arXiv preprint arXiv:2002.07526\n(2020).\n30. Brown, T. et al. Language models are few-shot learners.Adv. Neural\nInf. Processing Syst.33,1 8 7 7( 2 0 2 0 ) .\n31. Khan, S. et al. Transformers in vision: A survey.ACM Comput. Surv.\n(CSUR) 54, 1 (2022).\n32. He, S. et al. Image captioning through image transformer, inPro-\nceedings of the Asian Conference on Computer Vision\n(ACCV) (2020).\n33. Gong, Y., Chung, Y.-A. and Glass, J. Ast: Audio spectrogram trans-\nformer, arXiv preprint arXiv:2104.01778(2021).\n3 4 . P r a k a s h ,A . ,C h i t t a ,K .a n dG e i g e r ,A .M u l t i - m o d a lf u s i o nt r a n s f o r m e r\nfor end-to-end autonomous driving, inProceedings of the IEEE/CVF\nConference on Computer Vision and Pattern Recognition(2021) pp.\n7077– 7087.\n35. Geneva, N. & Zabaras, N. Transformers for modeling physical sys-\ntems. Neural Netw.146, 272 (2022).\n36. Yousif, M. Z., Zhang, M., Yu, L., Vinuesa, R. & Lim, H. A transformer-\nbased synthetic-inﬂow generator for spatially developing turbulent\nboundary layers.J. Fluid Mech.957,A 6( 2 0 2 3 ) .\n37. Borrelli, G., Guastoni, L., Eivazi, H., Schlatter, P. & Vinuesa, R. Pre-\ndicting the temporal dynamics ofturbulent channels through deep\nlearning.Int. J. Heat Fluid Flow96, 109010 (2022).\n38. Zhou, Y. & Alam, M. M. Wake of two interacting circular cylinders: A\nreview. Int. J. Heat Fluid Flow62,5 1 0( 2 0 1 6 ) .\n3 9 . D e n g ,N . ,N o a c k ,B .R . ,M o r z yński, M. & Pastur, L. R. Low-order model\nfor successive bifurcations of theﬂuidic pinball.J. Fluid Mech.884,\nA37 (2020).\n4 0 . R e n ,C . ,C h e n g ,L . ,X i o n g ,C . ,T o n g ,F .&C h e n ,T .B i s t a b i l i t i e si nt w o\nparallel kármán wakes.J. Fluid Mech.929,A 5( 2 0 2 1 ) .\n41. Khodkar, M. & Hassanzadeh, P. A data-driven, physics-informed\nframework for forecasting the spatiotemporal evolution of chaotic\ndynamics with nonlinearities modeled as exogenous forcings.J.\nComput. Phys.440, 110412 (2021).\n42. Ma, X., Karamanos, G.-S. & Karniadakis, G. Dynamics and low-\ndimensionality of a turbulent near wake.J. Fluid Mech.410,\n29 (2000).\n43. Sanchis-Agudo, M., Wang, Y., Duraisamy, K. and Vinuesa, R. Easy\nattention: A simple self-attention mechanism for transformers,arXiv\npreprint arXiv:2308.12874(2023).\n44. Hochreiter, S. & Schmidhuber, J. Long Short-Term Memory.Neural\nComput. 9, 1735 (1997).\n45. Taira, K. & Colonius, T. The immersed boundary method: a projec-\ntion approach.J. Comput. Phys.225, 2118 (2007).\n46. Colonius, T. & Taira, K. A fast immersed boundary method using a\nnullspace approach and multi-domain far-ﬁeld boundary condi-\ntions. Comput. Meth. Appl. Mech. Eng.197,2 1 3 1( 2 0 0 8 ) .\n47. Asztalos, K. J., Almashjary, A. and Dawson, S. Galerkin spectral\nestimation of vortex-dominated wakeﬂows, arXiv preprint\narXiv:2302.06412(2023).\nArticle https://doi.org/10.1038/s41467-024-45578-4\nNature Communications|         (2024) 15:1361 14\n48. Kingma, D. P. and Welling, M. Auto-encoding variational bayes,\narXiv preprint arXiv:1312.6114(2013).\n49. Kullback, S. & Leibler, R. A. On information and sufﬁciency. Annals\nMath. Stat.22,7 9( 1 9 5 1 ) .\n50. Higgins, I. et al. beta-VAE: Learning basic visual concepts with a\nconstrained variational framework, inInternational Conference on\nLearning Representationshttps://openreview.net/forum?id=\nSy2fzU9gl(2017).\n5 1 . C l e v e r t ,D . - A . ,U n t e r t h i n e r ,T .a n dH o c h r e i t e r ,S .F a s ta n da c c u r a t e\ndeep network learning by exponential linear units (elus),arXiv\npreprint arXiv:1511.07289(2015).\n52. Sirovich, L. Turbulence and the dynamics of coherent structures. i.\ncoherent structures.Quart. Appl. Math.45, 561 (1987).\n53. Pan, S. & Duraisamy, K. On the structure of time-delay embedding in\nlinear models of non-linear dynamical systems.Chaos: An Interdisc.\nJ. Nonlinear Sci.30, 073135 (2020).\n54. Bahdanau, D., Cho, K. and Bengio, Y. Neural machine translation by\njointly learning to align and translate,arXiv preprint\narXiv:1409.0473(2014).\n55. Paszke, A. et al. Pytorch: An imperative style, high-performance\ndeep learning library,https://arxiv.org/abs/1912.01703\narXiv:1912.01703 [cs.LG] (2019).\n56. Kingma, D. and Ba, J. Adam: A method for stochastic optimization,\nInternational Conference on Learning Representations(2014).\n57. Smith, L. N. and Topin, N., Super-convergence: Very fast training of\nneural networks using large learning rates,https://arxiv.org/abs/\n1708.07120arXiv:1708.07120 [cs.LG] (2018).\nAcknowledgements\nThe authors would like to thank to Dr. Hamidreza Eivazi and Mr. Samuel\nMolina for their technical assistance in theﬁr s tp a r to ft h es t u d ya n dD r .\nSteve Brunton for his insightful suggestions. Some of the deep-learning\nmodels were trained by means of resources provided by the National\nAcademic Infrastructure for Supercomputing in Sweden (NAISS). RV\nacknowledges theﬁnancial support from ERC grant no.‘2021-CoG-\n101043998, DEEPCONTROL’. Views and opinions expressed are how-\never those of the author(s) only and do not necessarily reﬂect those of\nthe European Union or the European Research Council. Neither the\nEuropean Union nor the granting authority can be held responsible\nfor them.\nAuthor contributions\nASR: Methodology, Software, Validation, Investigation, Data Curation,\nWriting – Original Draft, Writing– Review & Editing, Visualisation. CSV:\nMethodology, Software, Validation, Investigation, Data Curation, Writing\n– Original Draft, Writing– Review & Editing, Visualisation. MAG:\nMethodology, Software, Writing– Review & Editing. YW: Methodology,\nSoftware, Validation, Writing– Review & Editing. AA: Data generation.\nSD: Data generation, Writing– Original Draft, Writing– Review & Editing\nRV: Ideation, Methodology, Writing– Review & Editing, Supervision,\nResources, Funding acquisition.\nFunding\nOpen access funding provided by Royal Institute of Technology.\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nSupplementary informationThe online version contains\nsupplementary material available at\nhttps://doi.org/10.1038/s41467-024-45578-4.\nCorrespondenceand requests for materials should be addressed to\nRicardo Vinuesa.\nPeer review informationNature Communicationsthanks David Ryck-\nelynck and the other, anonymous, reviewer(s) for their contribution to\nthe peer review of this work. A peer reviewﬁle is available.\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nPublisher’s noteSpringer Nature remains neutral with regard to jur-\nisdictional claims in published maps and institutional afﬁliations.\nOpen AccessThis article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as\nlong as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons license, and indicate if\nchanges were made. The images or other third party material in this\narticle are included in the article’s Creative Commons license, unless\nindicated otherwise in a credit line to the material. If material is not\nincluded in the article’s Creative Commons license and your intended\nuse is not permitted by statutory regulation or exceeds the permitted\nuse, you will need to obtain permission directly from the copyright\nholder. To view a copy of this license, visithttp://creativecommons.org/\nlicenses/by/4.0/.\n© The Author(s) 2024\nArticle https://doi.org/10.1038/s41467-024-45578-4\nNature Communications|         (2024) 15:1361 15",
  "topic": "Autoencoder",
  "concepts": [
    {
      "name": "Autoencoder",
      "score": 0.9759235382080078
    },
    {
      "name": "Chaotic",
      "score": 0.7098237872123718
    },
    {
      "name": "Transformer",
      "score": 0.5861784219741821
    },
    {
      "name": "Computer science",
      "score": 0.5831052660942078
    },
    {
      "name": "Representation (politics)",
      "score": 0.5664113163948059
    },
    {
      "name": "Fluid dynamics",
      "score": 0.4891281723976135
    },
    {
      "name": "Flow (mathematics)",
      "score": 0.4532793462276459
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4428718090057373
    },
    {
      "name": "Algorithm",
      "score": 0.4388037621974945
    },
    {
      "name": "Feature learning",
      "score": 0.41090840101242065
    },
    {
      "name": "Applied mathematics",
      "score": 0.3842957019805908
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.3229789733886719
    },
    {
      "name": "Artificial neural network",
      "score": 0.30440181493759155
    },
    {
      "name": "Mathematics",
      "score": 0.2933114171028137
    },
    {
      "name": "Physics",
      "score": 0.1915569305419922
    },
    {
      "name": "Mechanics",
      "score": 0.1173979640007019
    },
    {
      "name": "Geometry",
      "score": 0.08103790879249573
    },
    {
      "name": "Voltage",
      "score": 0.0733155608177185
    },
    {
      "name": "Politics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I50357001",
      "name": "Universidad Carlos III de Madrid",
      "country": "ES"
    },
    {
      "id": "https://openalex.org/I4210117279",
      "name": "Instituto Nacional de Técnica Aeroespacial",
      "country": "ES"
    },
    {
      "id": "https://openalex.org/I86987016",
      "name": "KTH Royal Institute of Technology",
      "country": "SE"
    },
    {
      "id": "https://openalex.org/I180949307",
      "name": "Illinois Institute of Technology",
      "country": "US"
    }
  ],
  "cited_by": 104
}