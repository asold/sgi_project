{
    "title": "Empowering Psychotherapy with Large Language Models: Cognitive Distortion Detection through Diagnosis of Thought Prompting",
    "url": "https://openalex.org/W4389519882",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2099334531",
            "name": "Zhi-yu Chen",
            "affiliations": [
                "Carnegie Mellon University"
            ]
        },
        {
            "id": "https://openalex.org/A2118921946",
            "name": "Yujie Lu",
            "affiliations": [
                "University of California, Santa Barbara"
            ]
        },
        {
            "id": "https://openalex.org/A2096405000",
            "name": "William Wang",
            "affiliations": [
                "University of California, Santa Barbara"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4287854610",
        "https://openalex.org/W1988505588",
        "https://openalex.org/W4385571489",
        "https://openalex.org/W3104982372",
        "https://openalex.org/W4377098551",
        "https://openalex.org/W4319793302",
        "https://openalex.org/W2977128309",
        "https://openalex.org/W2756736520",
        "https://openalex.org/W4287854531",
        "https://openalex.org/W4376988648",
        "https://openalex.org/W3036236864",
        "https://openalex.org/W4386566488",
        "https://openalex.org/W4292422436",
        "https://openalex.org/W2093410327",
        "https://openalex.org/W1752708916",
        "https://openalex.org/W4385572374",
        "https://openalex.org/W4281557260",
        "https://openalex.org/W4285138657",
        "https://openalex.org/W4327810158",
        "https://openalex.org/W4226353085",
        "https://openalex.org/W4212909683",
        "https://openalex.org/W2805240699",
        "https://openalex.org/W3209409148",
        "https://openalex.org/W4360836968",
        "https://openalex.org/W4385571217",
        "https://openalex.org/W2136715587",
        "https://openalex.org/W2209817276",
        "https://openalex.org/W2964262738",
        "https://openalex.org/W434200312",
        "https://openalex.org/W2768708444",
        "https://openalex.org/W4287887983",
        "https://openalex.org/W4206816337",
        "https://openalex.org/W4298030274",
        "https://openalex.org/W2964331476",
        "https://openalex.org/W3105869449",
        "https://openalex.org/W3166011273",
        "https://openalex.org/W4378474033",
        "https://openalex.org/W4385571694"
    ],
    "abstract": "Mental illness remains one of the most critical public health issues of our time, due to the severe scarcity and accessibility limit of professionals. Psychotherapy requires high-level expertise to conduct deep, complex reasoning and analysis on the cognition modeling of the patients. In the era of Large Language Models, we believe it is the right time to develop AI assistance for computational psychotherapy. We study the task of cognitive distortion detection and propose the Diagnosis of Thought (DoT) prompting. DoT performs diagnosis on the patient's speech via three stages: subjectivity assessment to separate the facts and the thoughts; contrastive reasoning to elicit the reasoning processes supporting and contradicting the thoughts; and schema analysis to summarize the cognition schemas. The generated diagnosis rationales through the three stages are essential for assisting the professionals. Experiments demonstrate that DoT obtains significant improvements over ChatGPT for cognitive distortion detection, while generating high-quality rationales approved by human experts.",
    "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 4295–4304\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nEmpowering Psychotherapy with Large Language Models:\nCognitive Distortion Detection through Diagnosis of Thought Prompting\nZhiyu Chen1, Yujie Lu2, and William Yang Wang2\n1Carnegie Mellon University\n2University of California, Santa Barbara\nzhiyuc@andrew.cmu.edu,\n{yujielu, william}@cs.ucsb.edu\nAbstract\nMental illness remains one of the most criti-\ncal public health issues of our time, due to the\nsevere scarcity and accessibility limit of pro-\nfessionals. Psychotherapy requires high-level\nexpertise to conduct deep, complex reasoning\nand analysis on the cognition modeling of the\npatients. In the era of Large Language Mod-\nels, we believe it is the right time to develop\nAI assistance for computational psychotherapy.\nWe study the task of cognitive distortion de-\ntection and propose the Diagnosis of Thought\n(DoT) prompting. DoT performs diagnosis on\nthe patient’s speech via three stages: subjec-\ntivity assessmentto separate the facts and the\nthoughts; contrastive reasoningto elicit the rea-\nsoning processes supporting and contradicting\nthe thoughts; and schema analysisto summa-\nrize the cognition schemas. The generated di-\nagnosis rationales through the three stages are\nessential for assisting the professionals. Experi-\nments demonstrate that DoT obtains significant\nimprovements over ChatGPT for cognitive dis-\ntortion detection, while generating high-quality\nrationales approved by human experts.\n1 Introduction\nAbout one in eight people worldwide suffer from\nmental disorders (World Health Organization,\n2022). However, such mental health conditions\nare severely underserved, due to a number of rea-\nsons including the scarcity of mental health pro-\nfessionals, poor quality of services, unaffordable\ncost, and social stigma (White and Dorman, 2001;\nSharma et al., 2020b). Treatment coverage for men-\ntal health service use ranges from 33% in high-\nincome locations to only 8% in low- and lower\nmiddle-income countries (Moitra et al., 2022). A\nrecent study from the American Psychological As-\nsociation (APA)1 found that six in ten psychologists\n“no longer have openings for new patients.”\n1https://www.theguardian.com/society/2022/nov/21/therapist-\nshortage-us-psychologists-pandemic\nTo mitigate such situations, there have been\nconsistent efforts on developing automated sys-\ntems for mental health support, such as sentiment\nanalysis (Rathje et al., 2023) and empathetic chat-\nbots (Welivita et al., 2021; Sharma et al., 2020b;\nSaha et al., 2022). However, existing works mostly\ntake shallow attempts in a heuristic manner, e.g.,\nanalyzing emotions and generating comforting re-\nsponses. There is still a significant gap for such sys-\ntems to contribute to real professional psychother-\napy, which requires deep studies of the patient’s\nthinking patterns, the establishment of cognition\nmodels, and the methods to reconstruct the cog-\nnition models. These procedures constitute the\ncore pillars in common classic therapy paradigms\nlike cognitive-behavior therapy (CBT) (Rothbaum\net al., 2000; Wright et al., 2017; Beck, 2020) and\nacceptance and commitment therapy (ACT) (Har-\nris, 2006; Hayes et al., 2011). Most data sources\nrecording the interactions between the patients and\nlicensed professionals are confidential, making it\neven more challenging to build professional assis-\ntance for psychotherapy.\nRecent progress in Large Language Model\n(LLM) development uncovers its astonishing abil-\nity in various textual reasoning tasks in zero-shot\nsetting (Kojima et al., 2022; Bang et al., 2023;\nChen, 2022). For the psychology domain, Chat-\nGPT and GPT-4 present very promising perfor-\nmance in the classic Sally-Anne test (Baron-Cohen\net al., 1985; Bubeck et al., 2023), evaluating the\nbasic theory of mind capabilities to attribute mental\nstates such as beliefs, emotions, desires, etc. We\nbelieve it is promising to further exploit such ability\nto complex mental reasoning and analysis. It is the\nright time to start developing professional, targeted,\nand systematic AI assistance for psychotherapy.\nIn this paper, we take the first step by study-\ning the task of cognitive distortion detection, the\nfirst core procedure in cognitive behavior therapy\n(CBT) (Beck, 2020). Inspired by how psychother-\n4295\nCognitive Distortion Type Interpretation Example Distorted Speech\nPersonalization Personalizing or taking up the blame for a situation, that in reality involved many\nfactors and was out of the person’s control.\nMy son is pretty quiet today. I wonder what\nI did to upset him.\nMind Reading Suspecting what others are thinking or what are the motivations behind their actions.My house was dirty when my friends came\nover, they must think I’m a slob!\nAll-or-nothing thinkingLooking at a situation as either black or white or thinking that there are only two\npossible outcomes to a situation. If I cannot get my Ph.D., then I am a total failure.\nTable 1: Three example common cognitive distortion types, taken from (Beck, 2020; Shreevastava and Foltz, 2021).\napy professionals perform nuanced diagnosis over\nthe patient’s speech, we propose the Diagnosis of\nThought (DoT) prompting. In DoT, we diagnose\nthe patient’s speech through three stages: (1) sub-\njectivity assessment, (2) contrastive reasoning, and\n(3) schema analysis. In subjectivity assessment, we\ndistinguish the patient’s subjective thoughts from\nthe objective facts; In contrastive reasoning, we\nelicit the reasoning processes supporting and op-\nposing the patient’s thoughts; Finally, in schema\nanalysis, we summarize the underlying thought\nschema and map it to the cognitive distortion types.\nWe conduct comprehensive experiments using the\nrecent top-performing LLMs. In zero-shot setting,\nDoT obtains over 10% and 15% relative improve-\nments for distortion assessment and classification,\nrespectively, on ChatGPT. Meanwhile, the gener-\nated rationales through the three stages grant full\ninterpretability for the diagnosis process, whose\nquality is further approved by human experts.\nWe unveil the great potential of empowering pro-\nfessional psychotherapy with LLM. This explo-\nration serves as a catalyst for a larger initiative; we\nextend an invitation to both AI and psychotherapy\ncommunities to come together in a collaborative ef-\nfort. Our ultimate goal is to construct professional,\nsafe, AI-driven assistance that can substantially en-\nhance mental health support systems.\n2 Cognitive Distortion Detection\nCognitive Behavior Therapy (CBT) is a well-\nestablished therapy paradigm primarily on depres-\nsion and anxiety disorders (Beck, 2020). In CBT,\ngiven the patients’ speech or written content, we\nestablish the cognitive model by building the inter-\nactions among the situations, thoughts, and emo-\ntions. Patients with mental disorders, such as de-\npression or anxiety, tend to form negative thoughts\nvery rapidly and unconsciously, leading to nega-\ntive emotions which further strengthen their overall\nnegative views and beliefs about the world.\nTo break this vicious circle, in a typical CBT\nprocess, the first core step is to identify those mal-\nadaptive negative thoughts and summarize their un-\nderlying schemas, formally known as cognitive dis-\ntortions. There are generally 10-20 common, well-\nstudied types of cognitive distortions. We present\na few types with examples in Table 1, and refer\nthe readers to Appendix A for the full list. Once\naccurately identify these cognitive distortions, CBT\ntherapists will guide the patients to justify and cor-\nrect these distortions, so as to gradually reconstruct\ntheir cognition models.\nIn the real psychotherapy process, there’s a sig-\nnificant amount of textual information including\ntherapeutic conversations and diaries, etc. Such\ninformation is often long, highly fragmented, and\ndisorganized, containing multiple types of distor-\ntions beyond the toy examples in Table 1. The task\nof cognitive distortion detection aims to automati-\ncally detect the distortion types given such textual\ninformation from the patients, in order to assist\ntherapists to enhance their efficiency and productiv-\nity. Meanwhile, such detectors can also potentially\nserve as self-assisting tools for the patients to di-\nagnose their thoughts and conduct CBT practice,\nupon meeting the robustness and safety require-\nments. Formally, cognitive distortion detection\nconsists of two steps: 1) Distortion assessment to\npredict whether the given speech contains cogni-\ntive distortions, as a binary classification problem;\nand 2) Distortion classification to predict the spe-\ncific distortion types, as a multiclass classification\nproblem.\n3 The Diagnosis of Thought Prompting\nOn discussing with psychotherapy professionals,\nwe identify the following key stages to diagnose\nthe patient’s speech to detect cognitive distortions.\nSubjectivity Assessment. The patient’s speech\nconsists of a mixture of reality (objective facts) and\ninterpretations/opinions (subjective thoughts). In\norder to perform deep analysis of distorted thinking,\nwe first need to find out which parts of the speech\nare objective facts and which parts are subjective\nthoughts. After such an assessment, we summa-\n4296\nPatient \nspeech:\n… My \nadvisor was \nquiet in our \nmeeting \ntoday, I must \nhave done \nsomething \nwrong… \nObjective facts:\nThe advisor was quiet \nin the meeting with \nthe speaker today.\nSubjective \nthoughts:\nThe speaker thinks \nhe must have done \nsomething wrong \nthat upsets his \nadvisor.\nReasoning process \nsupporting the thoughts:\nPeople often stay quiet to \nsomeone who has annoyed  \nthem. The advisor is likely to \nget angry with the speaker. \nReasoning process \ncontradicting the thoughts:\nThere may be many reasons \nmaking the advisor quiet, e.g., \nhe was just getting too tired. \nWhat’s more, he didn’t say the \nreason the speaker made him \nunhappy. \nUnderlying thought \nschema:\nThe speaker is \ntaking up the blame \nfor the situation that \nhis advisor didn’t \ntalk much in the \nmeeting. This in \nreality may involve \nmany factors out of \nthe speaker’s \ncontrol.\nDistortion \nassessment:\nYes\nDistortion \ntype:\nPersonalization\nSubjectivity assessment Contrastive reasoning Schema analysis\nFigure 1: The Diagnosis of Thought framework. We strategically prompt the LLM to go through the three diagnosis stages:\nsubjectivity assessment, contrastive reasoning, and schema analysis.\nrize the objective facts into the situations as the\nevidence base to diagnose the subjective thoughts.\nContrastive Reasoning. This stage aims to dis-\ncover how the patient ascertains the veracity of\ntheir subjective thoughts. Based on the situation,\nwe deduct the reasoning processes that supports\nand contradicts the patient’s thoughts respectively.\nBy contrasting two different interpretations based\non the same situation, we can identify the thought\nschemas more clearly.\nSchema Analysis. This stage aims to study why\nthe patient forms the specific reasoning process.\nThe term \"schema\" refers to the cognitive struc-\ntures that organize our knowledge, beliefs, and ex-\npectations. Understanding what schemas a patient\nis relying on can reveal much about their cognitive\nmode and distortions.\nWe propose the Diagnosis of Thought (DoT)\nprompting, guiding the LLM through the above\nthree stages to diagnose the patient’s speech. Fig-\nure 1 illustrates our framework. We sequentially\nprompt LLM with three questions for the three\nstages. After the LLM finishes the generation for\nall stages, we prompt it with another two questions\nasking distortion assessment and classification. See\nAppendix B for all the prompts we use.\nWith DoT prompting, we obtain fully inter-\npretable diagnosis rationales for detecting cogni-\ntive distortions. Such interpretability is vital for\nprofessionals in real applications. Serving as the\ndiagnosing assistance tool, the diagnosis rationales\nare essential for the professionals to justify the re-\nsults. More importantly, they can potentially learn\nthe nuanced thought patterns and schemas derived\nfrom the patient’s speech through the rationales.\nThis is crucial for the professionals to establish the\npatient’s cognition models more efficiently from\nthe vast amount of speech.\n4 Experimental Results\n4.1 Dataset and experimental settings\nWe experiment on the cognitive distortion detection\ndataset proposed by Shreevastava and Foltz (2021),\nwhich is annotated by experts based on the Ther-\napist QA dataset2. The dataset consists of 2,531\nexamples of patient speech annotated with ten com-\nmon types of cognitive distortions, as specified in\nAppendix A. 63.1% of the examples have cogni-\ntive distortions, which are annotated with the two\ndominant ones. We follow the same train-test split\nin (Shreevastava and Foltz, 2021). For automatic\nevaluations, we report F-1 for distortion assessment\nand weighted F-1 for distortion classification.\n4.2 Automatic Evaluation Results\nWe experiment using three of the recent represen-\ntative LLMs: ChatGPT (gpt-3.5-turbo)3, Vicuna4,\nand GPT-4 (OpenAI, 2023). For all methods, we\nfirst prompt with a general instruction specifying\nthe task and the target distortion types. We com-\npare our DoT prompting with 1) Directly generat-\ning the results, and 2) Zero-Shot CoT prompting\n(ZCoT) (Kojima et al., 2022). For Vicuna, both\nZCoT and DoT exceed the token limits for many\nexamples; we omit the results. We average over five\nruns and report mean and standard deviation for all\nexperiments. Table 2 shows our main experiment\nresults. As we can see, under the zero-shot setting,\ndue to the challenge of this task, Vicuna and Chat-\nGPT still fall behind the supervised full-training\nmodels. The proposed DoT prompting significantly\n2https://www.kaggle.com/arnmaud/therapist-qa\n3https://openai.com/blog/chatgpt\n4https://lmsys.org/blog/2023-03-30-vicuna/\n4297\nMethods\nDistortion\nAssessment\n(F-1)\nDistortion\nClassification\n(Weighted F-1)\nFull training⋆ 75.0 24.0\nVicuna 73.810.95 11.230.78\nChatGPT 73.470.58 19.241.00\nChatGPT + ZCoT 77.101.21 20.211.02\nChatGPT + DoT 81.190.11 22.250.70\nGPT-4 83.040.51 33.860.83\nGPT-4 + ZCoT 81.971.21 33.221.36\nGPT-4 + DoT 82.770.81 34.641.40\nTable 2: Main Results (Standard deviation in subscript). ( ⋆)\nresults copied from (Shreevastava and Foltz, 2021).\nMethods\nDistortion\nAssessment\n(F-1)\nDistortion\nClassification\n(Weighted F-1)\nChatGPT 73.470.58 19.241.00\nChatGPT + S1 79.621.12 18.721.95\nChatGPT + S1 + S2 80.700.48 20.111.02\nChatGPT + S1 + S2 + S381.190.11 22.250.70\nTable 3: Ablation studies on each stage of DoT: we denote\nSubjectivity Assessment as S1, Contrastive Reasoning as S2,\nand Schema Analysis as S3.\nboosts the performance of ChatGPT, with the distor-\ntion assessment score surpassing the full-training\nperformance and the distortion classification score\napproaching the full-training performance. The im-\nprovement over ZCoT demonstrates the superiority\nof our proposed strategic stages compared with ra-\ntionale generation with no guidance. Astonishingly,\nGPT-4 surpasses the full-training performance even\nby a large margin for distortion classification. On\nthe one hand, this may demonstrate the powerful\nability of GPT-4 on this task - it can already reach\na potential upper bound regardless with DoT pro-\nmoting or not; On the other hand, since the dataset\nwe use is publicly released on Kaggle and its orig-\ninal data source is from online forums, we do not\nexclude the possibility of data contamination.\nAblation Studies and Analysis. To better under-\nstand how each stage of DoT contributes to overall\nperformance, we conduct ablation studies using\nChatGPT shown in Table 3. All three stages ob-\ntain improvements for distortion assessment and\ndistortion classification. For distortion assessment,\nsubjectivity assessment (S1) gains the largest im-\nprovement, as separating objective facts and subjec-\ntive thoughts is a strong trigger to assess distortions.\nFor distortion classification, Schema Analysis (S3)\nall-or-nothingovergeneralization\nmental filter\nshould statement\nlabeling\npersonalizationmagnification\nemotional reasoning\nmind readingfortune-telling\nFigure 2: Distortion classification per class F-1.\nMethods Quality Subjectivity\nAssessment\nContrastive\nReasoning\nSchema\nAnalysis\nComprehensive68.5% 45 .0% 50 .5%\nChatGPT\n+DoT Partially good24.5% 30 .5% 27 .0%\nInvalid 7.0% 24 .5% 22 .5%\nComprehensive84.5% 69 .5% 76 .5%\nGPT4\n+DoT Partially good13.5% 25 .5% 18 .5%\nInvalid 2.0% 5 .0% 5 .0%\nTable 4: Human evaluation results for diagnosis rationales.\nobtains large improvement, as the summarized un-\nderlying thought schema can match the definition\nof the distortion types more accurately. We also\nanalyze the distortion classification results for each\ndistortion type, with results shown in Figure 2.\n4.3 Human Evaluation Results\nAs there is no reference available for the diagno-\nsis rationales, we employ psychotherapy experts\nto assess the quality of the generated rationales.\nWe hired psychotherapy professionals from Up-\nWork5, e.g., certified clinicians, counseling psy-\nchology Ph.D. students, etc. We discussed with\neach hire to reach an agreement on the payment\nfollowing a fair wage rate.\nSpecifically, we present the patient’s speech, all\nthe prompts, and the generated rationales for all\nstages to human experts. For the generated ra-\ntionales of each stage, we instruct the experts to\nchoose between: 1) Comprehensive. (Correct and\ncomprehensive.); 2) Partially good. (Reasonable\nbut not comprehensive) 3) Invalid. (Not reason-\nable.) Table 4 shows the evaluation results on 100\nexamples for DoT over ChatGPT and GPT-4. We\nemploy two experts for each evaluation and report\nthe average; The agreement rates (the percentage\nof examples the two experts gave the same rating)\nfor both evaluations are over 80%. The diagnosis\nrationales generated for all stages shows decent\n5www.upwork.com\n4298\nquality verified by the experts. See Appendix C for\nmore generation examples.\n5 Related Work\nDue to the verbal and textual nature of psychother-\napy procedures, there have been consistent efforts\nto employ NLP techniques to assist the mental\nhealth domain (Althoff et al., 2016; Abd-Alrazaq\net al., 2021, 2019; Valizadeh and Parde, 2022).\nHowever, with the knowledge gap between the two\ncommunities, most existing works take shallow\nattempts without deep investigation of the profes-\nsional psychotherapy knowledge. A majority of\nthe previous studies targets identification of com-\nmon mental health issues, such as depression and\nanxiety, from textual contents (Cohan et al., 2018;\nMacAvaney et al., 2018; Harrigian et al., 2020; Ji\net al., 2022; Zanwar et al., 2023; Juhng et al., 2023).\nAnother major category of works study therapeu-\ntic conversations with a focus on emotional/empa-\nthetic supports (Halder et al., 2017; Sharma et al.,\n2020a; Atapattu et al., 2022; Mishra et al., 2023),\nand discourse structures (Cao et al., 2019; Hsu\net al., 2023). A few more recent works have started\nto investigate deeper professional psychotherapy\nknowledge, e.g., cognitive distortion detection in\nCBT (Shreevastava and Foltz, 2021; Ding et al.,\n2022; Lybarger et al., 2022), identifying and re-\nframing unhelpful thoughts (Ziems et al., 2022;\nMaddela et al., 2023). Early famous system Eliza6\ntook the initial attempts to emulate a Rogerian\npsychotherapist. Due to its rule-based nature, the\nresponses are often reflections or rephrasings of\nthe user’s statements. If users deviate too much\nfrom expected inputs or probe its capabilities, the\nprogram may produce irrelevant or nonsensical re-\nsponses.\nRecent progress in large language model reveals\nthat ChatGPT and GPT-4 present very promising\nperformance in the classic Sally-Anne test (Baron-\nCohen et al., 1985; Bubeck et al., 2023), evaluating\nthe basic theory of mind capabilities to attribute\nmental states such as beliefs, emotions, desires, etc.\nHowever, latter works also point out the robust-\nness issue of such ability (Shapira et al., 2023). In\nour work, we are inspired by such enhanced abil-\nity and investigate the application of diagnosing\npatients’ thoughts in psychotherapy. Our experi-\nments on the real dataset, not anecdotal examples,\nshow very promising performance both in auto-\n6https://en.wikipedia.org/wiki/ELIZA\nmatic and human expert evaluation. We believe\nit is a very important future research direction to\ninvestigate the general cognitive abilities of LLM\nand make connections to the field of psychology\nand cognitive science. Theory-wise, we are eager\nto explore to what extent the LLM can simulate\nthe human cognitive functions, so as to determine\nthe role that language plays in the overall human\ncognition. Application-wise, a straightforward and\nencouraging direction should be the integration for\nassisting mental health treatment, as the motivation\nand goal of this work.\n6 Conclusion and Future Work\nThis work delved into the integration of large\nlanguage models (LLMs) within the realm of\npsychotherapy. We introduced the Diagnosis of\nThought (DoT) framework, which strategically\nprompts the LLM to produce diagnosis rationales\npertinent to the detection of cognitive distortions.\nWe believe that there exists substantial potential for\nleveraging LLMs within numerous facets of mental\nhealth support that are currently under-explored.\nOur findings, thus, not only illuminate a path to-\nwards more efficient therapy methods but also open\ndoors for future investigations to push the bound-\naries of AI’s role in mental health treatment.\nIn the domain of AI-enhanced psychotherapy,\nparticularly when harnessing the power of LLMs,\nthere are paramount challenges surrounding safety,\nrobustness, and ethical responsibilities. LLM is\nknown to generate hallucinations and biases. While\none potential usage of our system is to serve as a\nself-diagnosing/assisting tool for patients, e.g., to\nhelp the patients to recognize their own thinking\npatterns and learn how the cognitive distortions\ndeveloped, such tools should not be deployed for\ndirect patient use without the supervision of pro-\nfessionals. As we navigate the potential of LLM\nin psychotherapy, our foremost priority should re-\nmain in building systems that are safe and responsi-\nble. Concurrently, the formulation of robust ethical\nguidelines tailored to this new era becomes indis-\npensable.\nLimitations\nOne of the biggest obstacles to studying AI for\npsychotherapy is the lack of available, high-quality\ndata. Most of the datasets recording the informa-\ntion of the interactions between the patients and\nlicensed professionals are confidential due to pri-\n4299\nvacy concerns. The dataset used in this work is the\nonly one we can find publicly available for cogni-\ntive distortion detection, as its data source is from\npublic online forums. In addition to the patient’s\nspeech, the patient’s demographic information also\nplays an important role in analyzing the thought\nprocess leading to cognitive distortions. In this\ndataset, some of the patient speech include a few\ndemographic details, but pretty minimal. Beyond\nthe task of cognitive distortion detection, the same\ndata constraint issue exists for all other therapy\nstages and paradigms. This also motivates us to\nwork on building privacy-preserved systems as a\ncrucial future direction.\nEthics Statement\nThe system built in this work are never meant to\nreplace psychotherapy professionals: all system-\nproduced results need to be verified by licensed\nprofessionals. The system should not be deployed\nfor direct patient use without the supervision of\nlicensed professionals.\nThere has been a lot of discussions regarding the\nuse of LLMs for AI-driven therapy purpose. Chat-\nbots will find their most effective role in medicine\nwithin the realm of mental health, an opinion 7\nquoted from Thomas Insel, former director of the\nNational Institute of Mental Health. In the mean-\ntime, we should always take caution for such devel-\nopment. Our foremost priority should be building\nsafe and responsible applications while establish-\ning ethical and regulation standards for this new era.\nUnder the current status, the partnership between\nprofessionals and AI systems is a promising direc-\ntion for the goal to ease the burden of professionals,\nwhich is the motivation of this work.\n“Diagnosis of Thought” is an innovative ap-\nproach that harnesses the capabilities of large lan-\nguage models to enhance the field of psychotherapy.\nIt is imperative to understand that this tool is not\ndesigned for censorship or any form of invasive\nsurveillance. Instead, it aims to augment the skills\nof therapists by providing them with advanced,\ndata-driven insights into their clients’ thoughts and\nemotions. Through the efficient processing of lin-\nguistic cues and patterns, these models aid mental\nhealth professionals in formulating more precise\ndiagnoses and crafting tailored therapeutic inter-\nventions that could significantly enhance the well-\n7https://www.scientificamerican.com/article/ai-chatbots-\ncould-help-provide-therapy-but-caution-is-needed/\nbeing of individuals seeking help.\nFor all the annotations and human evaluations\npresented in this work, we hired psychotherapy pro-\nfessionals from UpWork8, e.g., certified clinicians,\ncounseling psychology Ph.D. students, etc. We dis-\ncussed with each hire to reach an agreement on the\npayment following a fair wage rate. The average\nhourly rate for all the experts is $80.\nThis project is approved by our Institutional Re-\nview Board (IRB). The data annotation is classified\nas exempt by our IRB.\nReferences\nAlaa A Abd-Alrazaq, Mohannad Alajlani, Ali Abdal-\nlah Alalwan, Bridgette M Bewick, Peter Gardner,\nand Mowafa Househ. 2019. An overview of the\nfeatures of chatbots in mental health: A scoping re-\nview. International Journal of Medical Informatics,\n132:103978.\nAlaa A Abd-Alrazaq, Mohannad Alajlani, Nashva Ali,\nKerstin Denecke, Bridgette M Bewick, and Mowafa\nHouseh. 2021. Perceptions and opinions of patients\nabout mental health chatbots: scoping review. Jour-\nnal of medical Internet research, 23(1):e17828.\nTim Althoff, Kevin Clark, and Jure Leskovec. 2016.\nLarge-scale analysis of counseling conversations: An\napplication of natural language processing to mental\nhealth. Transactions of the Association for Computa-\ntional Linguistics, 4:463–476.\nThushari Atapattu, Mahen Herath, Charitha Elvitigala,\nPiyanjali de Zoysa, Kasun Gunawardana, Menasha\nThilakaratne, Kasun de Zoysa, and Katrina Falkner.\n2022. EmoMent: An emotion annotated mental\nhealth corpus from two South Asian countries. In\nProceedings of the 29th International Conference\non Computational Linguistics, pages 6991–7001,\nGyeongju, Republic of Korea. International Com-\nmittee on Computational Linguistics.\nYejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wen-\nliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei\nJi, Tiezheng Yu, Willy Chung, et al. 2023. A multi-\ntask, multilingual, multimodal evaluation of chatgpt\non reasoning, hallucination, and interactivity. arXiv\npreprint arXiv:2302.04023.\nSimon Baron-Cohen, Alan M Leslie, and Uta Frith.\n1985. Does the autistic child have a “theory of\nmind”? Cognition, 21(1):37–46.\nJudith S Beck. 2020. Cognitive behavior therapy: Ba-\nsics and beyond. Guilford Publications.\nSébastien Bubeck, Varun Chandrasekaran, Ronen El-\ndan, Johannes Gehrke, Eric Horvitz, Ece Kamar,\n8www.upwork.com\n4300\nPeter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lund-\nberg, et al. 2023. Sparks of artificial general intelli-\ngence: Early experiments with gpt-4. arXiv preprint\narXiv:2303.12712.\nJie Cao, Michael Tanana, Zac E Imel, Eric Poitras,\nDavid C Atkins, and Vivek Srikumar. 2019. Observ-\ning dialogue in therapy: Categorizing and forecasting\nbehavioral codes. arXiv preprint arXiv:1907.00326.\nWenhu Chen. 2022. Large language models are\nfew (1)-shot table reasoners. arXiv preprint\narXiv:2210.06710.\nArman Cohan, Bart Desmet, Andrew Yates, Luca Sol-\ndaini, Sean MacAvaney, and Nazli Goharian. 2018.\nSMHD: a large-scale resource for exploring online\nlanguage usage for multiple mental health condi-\ntions. In Proceedings of the 27th International Con-\nference on Computational Linguistics, pages 1485–\n1497, Santa Fe, New Mexico, USA. Association for\nComputational Linguistics.\nXiruo Ding, Kevin Lybarger, Justin Tauscher, and\nTrevor Cohen. 2022. Improving classification of\ninfrequent cognitive distortions: Domain-specific\nmodel vs. data augmentation. In Proceedings of\nthe 2022 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies: Student Research\nWorkshop, pages 68–75, Hybrid: Seattle, Washington\n+ Online. Association for Computational Linguistics.\nKishaloy Halder, Lahari Poddar, and Min-Yen Kan.\n2017. Modeling temporal progression of emotional\nstatus in mental health forum: A recurrent neural\nnet approach. In Proceedings of the 8th Workshop\non Computational Approaches to Subjectivity, Sen-\ntiment and Social Media Analysis, pages 127–135,\nCopenhagen, Denmark. Association for Computa-\ntional Linguistics.\nKeith Harrigian, Carlos Aguirre, and Mark Dredze.\n2020. Do models of mental health based on social\nmedia data generalize? In Findings of the Associa-\ntion for Computational Linguistics: EMNLP 2020,\npages 3774–3788, Online. Association for Computa-\ntional Linguistics.\nRussell Harris. 2006. Embracing your demons: An\noverview of acceptance and commitment therapy.\nPsychotherapy in Australia, 12(4):70–6.\nSteven C Hayes, Kirk D Strosahl, and Kelly G Wilson.\n2011. Acceptance and commitment therapy: The\nprocess and practice of mindful change. Guilford\npress.\nShang-Ling Hsu, Raj Sanjay Shah, Prathik Senthil,\nZahra Ashktorab, Casey Dugan, Werner Geyer, and\nDiyi Yang. 2023. Helping the helper: Supporting\npeer counselors via ai-empowered practice and feed-\nback. arXiv preprint arXiv:2305.08982.\nShaoxiong Ji, Tianlin Zhang, Luna Ansari, Jie Fu,\nPrayag Tiwari, and Erik Cambria. 2022. Mental-\nBERT: Publicly available pretrained language models\nfor mental healthcare. In Proceedings of the Thir-\nteenth Language Resources and Evaluation Confer-\nence, pages 7184–7190, Marseille, France. European\nLanguage Resources Association.\nSwanie Juhng, Matthew Matero, Vasudha Varadarajan,\nJohannes Eichstaedt, Adithya V Ganesan, and H An-\ndrew Schwartz. 2023. Discourse-level representa-\ntions can improve prediction of degree of anxiety. In\nProceedings of the 61st Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 2:\nShort Papers), pages 1500–1511.\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\ntaka Matsuo, and Yusuke Iwasawa. 2022. Large lan-\nguage models are zero-shot reasoners. arXiv preprint\narXiv:2205.11916.\nKevin Lybarger, Justin Tauscher, Xiruo Ding, Dror Ben-\nZeev, and Trevor Cohen. 2022. Identifying distorted\nthinking in patient-therapist text message exchanges\nby leveraging dynamic multi-turn context. In Pro-\nceedings of the Eighth Workshop on Computational\nLinguistics and Clinical Psychology, pages 126–136.\nSean MacAvaney, Bart Desmet, Arman Cohan, Luca\nSoldaini, Andrew Yates, Ayah Zirikly, and Nazli Go-\nharian. 2018. RSDD-time: Temporal annotation of\nself-reported mental health diagnoses. In Proceed-\nings of the Fifth Workshop on Computational Lin-\nguistics and Clinical Psychology: From Keyboard to\nClinic, pages 168–173, New Orleans, LA. Associa-\ntion for Computational Linguistics.\nMounica Maddela, Megan Ung, Jing Xu, Andrea\nMadotto, Heather Foran, and Y-Lan Boureau.\n2023. Training models to generate, recognize,\nand reframe unhelpful thoughts. arXiv preprint\narXiv:2307.02768.\nKshitij Mishra, Priyanshu Priya, and Asif Ekbal. 2023.\nPAL to lend a helping hand: Towards building an\nemotion adaptive polite and empathetic counseling\nconversational agent. In Proceedings of the 61st An-\nnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 12254–\n12271, Toronto, Canada. Association for Computa-\ntional Linguistics.\nModhurima Moitra, Damian Santomauro, Pamela Y\nCollins, Theo V os, Harvey Whiteford, Shekhar Sax-\nena, and Alize J Ferrari. 2022. The global gap in treat-\nment coverage for major depressive disorder in 84\ncountries from 2000–2019: A systematic review and\nbayesian meta-regression analysis. PLoS Medicine,\n19(2):e1003901.\nOpenAI. 2023. Gpt-4 technical report. arXiv preprint\narXiv:2303.08774.\nSteve Rathje, Dan-Mircea Mirea, Ilia Sucholutsky, Raja\nMarjieh, Claire Robertson, and Jay J Van Bavel. 2023.\n4301\nGpt is an effective tool for multilingual psychological\ntext analysis.\nBarbara Olasov Rothbaum, Elizabeth A Meadows, Pa-\ntricia Resick, and David W Foy. 2000. Cognitive-\nbehavioral therapy.\nTulika Saha, Saichethan Reddy, Anindya Das, Sriparna\nSaha, and Pushpak Bhattacharyya. 2022. A shoulder\nto cry on: Towards a motivational virtual assistant for\nassuaging mental agony. In Proceedings of the 2022\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, pages 2436–2449.\nNatalie Shapira, Mosh Levy, Seyed Hossein Alavi,\nXuhui Zhou, Yejin Choi, Yoav Goldberg, Maarten\nSap, and Vered Shwartz. 2023. Clever hans or\nneural theory of mind? stress testing social rea-\nsoning in large language models. arXiv preprint\narXiv:2305.14763.\nAshish Sharma, Adam Miner, David Atkins, and Tim\nAlthoff. 2020a. A computational approach to un-\nderstanding empathy expressed in text-based mental\nhealth support. In Proceedings of the 2020 Confer-\nence on Empirical Methods in Natural Language\nProcessing (EMNLP), pages 5263–5276, Online. As-\nsociation for Computational Linguistics.\nAshish Sharma, Adam S Miner, David C Atkins, and\nTim Althoff. 2020b. A computational approach to un-\nderstanding empathy expressed in text-based mental\nhealth support. arXiv preprint arXiv:2009.08441.\nSagarika Shreevastava and Peter Foltz. 2021. Detecting\ncognitive distortions from patient-therapist interac-\ntions. In Proceedings of the Seventh Workshop on\nComputational Linguistics and Clinical Psychology:\nImproving Access, pages 151–158.\nMina Valizadeh and Natalie Parde. 2022. The ai doctor\nis in: A survey of task-oriented dialogue systems for\nhealthcare applications. In Proceedings of the 60th\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 6638–\n6660.\nAnuradha Welivita, Yubo Xie, and Pearl Pu. 2021. A\nlarge-scale dataset for empathetic response gener-\nation. In Proceedings of the 2021 Conference on\nEmpirical Methods in Natural Language Processing,\npages 1251–1264.\nMarsha White and Steve M Dorman. 2001. Receiving\nsocial support online: implications for health educa-\ntion. Health education research, 16(6):693–707.\nJesse H Wright, Gregory K Brown, Michael E Thase,\nand Monica Ramirez Basco. 2017. Learning\ncognitive-behavior therapy: An illustrated guide.\nAmerican Psychiatric Pub.\nSourabh Zanwar, Xiaofei Li, Daniel Wiechmann,\nYu Qiao, and Elma Kerz. 2023. What to fuse and how\nto fuse: Exploring emotion and personality fusion\nstrategies for explainable mental disorder detection.\nIn Findings of the Association for Computational\nLinguistics: ACL 2023, pages 8926–8940, Toronto,\nCanada. Association for Computational Linguistics.\nCaleb Ziems, Minzhi Li, Anthony Zhang, and Diyi\nYang. 2022. Inducing positive perspectives with text\nreframing. arXiv preprint arXiv:2204.02952.\nAppendix A: Cognitive Distortion Types\nWe list all the ten cognitive distortion types stud-\nies in this work following·(Shreevastava and Foltz,\n2021) in Table 5. Note that these ten types be-\ning studied are some common, well-studied ones.\nAs psychotherapy develops, more fine-grained and\nnew distortion types are expected to be unveiled.\nFor the cognitive distortion detection dataset pro-\nposed by Shreevastava and Foltz (2021), there are\n2,531 examples in total. We follow the original\n80% - 20% train-test split. The input patient speech\nhas an average length of 167.3 tokens, and the ten\ndistortion types are roughly equally distributed.\nAppendix B: Prompt Details\nFor all our experiments without using DoT, we\nfirst prompt the LLM with the following general\ninstructions:\nGiven a speech of a patient, our task is to 1) iden-\ntify if there is cognitive distortion in the speech; 2)\nRecognizing the specific types of the cognitive dis-\ntortion. Here we consider the following common\ndistortions: (followed by the descriptions and ex-\namples for all ten prompts in the dataset metadata\nof (Shreevastava and Foltz, 2021).\nFor all our experiments using DoT, we first\nprompt the LLM with the following general in-\nstructions:\nGiven a speech of a patient, our task is to 1) fin-\nish a few diagnose of thought questions to analyze\nthe thought patterns of the patient. Then based\non the diagnose of thought analysis, 2) identify\nif there is cognitive distortion in the speech; 3)\nRecognizing the specific types of the cognitive dis-\ntortion. Here we consider the following common\ndistortions: (followed by the descriptions and ex-\namples for all ten prompts in the dataset metadata\nof (Shreevastava and Foltz, 2021).\nThen for methods without using DoT, we prompt\nthe following two questions:\nPlease first answer: if there is cognitive distor-\ntion in the speech; Answer ’yes’ or ’no’; Please\nthen answer: Recognizing the specific types of the\ncognitive distortion in the speech. There may be\n4302\nCognitive Distortion Type Interpretation Example Distorted Speech\nPersonalization Personalizing or taking up the blame for a situation, that in reality involved manyfactors and was out of the person’s control. My son is pretty quiet today. I wonder whatI did to upset him.\nMind Reading Suspecting what others are thinking or what are the motivations behind their actions.My house was dirty when my friends cameover, they must think I’m a slob!\nOvergeneralization Major conclusions are drawn based on limited information. Last time I was in the pool I almost drowned,I am a terrible swimmer and should not go intothe water again.\nAll-or-nothing thinkingLooking at a situation as either black or white or thinking that there are only twopossible outcomes to a situation. If I cannot get my Ph.D., then I am a total failure.\nEmotional reasoningLetting one’s feeling about something overrule facts to the contrary.Even though Steve is here at work late every day,I know I work harder than anyone else at my job.\nLabeling Giving someone or something a label without finding out more about it/them. My daughter would never do anything I disapproved of.\nMagnification Emphasizing the negative or playing down the positive of a situation.My professor said he made some corrections on my paper,so I know I’ll probably fail the class.\nMental filter Placing all one’s attention o, or seeing only, the negatives of a situation.My husband says he wishes I was better at housekeeping,so I must be a lousy wife.\nShould statements\nShould statements appear as a list of ironclad rules about how a person should behave,this could be about the speaker themselves or other.It is NOT necessary that the word ’should’ or it’s synonyms(ought to, must etc.) be present in the statements containing this distortion.\nI should get all A’s to be a good student.\nFortune-telling As the name suggests, this distortion is about expecting things to happen a certain way,or assuming that thing will go badly.Counterintuitively, this distortion does not always have future tense.I was afraid of job interviews so I decided to start my own thing.\nTable 5: Common cognitive distortion types and example speech, taken from (Beck, 2020; Shreevastava and Foltz, 2021).\none type of cognitive distortion or multiple types\ninvolved. If there are multiple types, please give\nthe top 2 dominant ones. Please only give the dis-\ntortion type names separated by comma.\nFor methods using DoT, before asking this two\nquestions, we provide the following DoT prompts:\nBased on the patient’s speech, finish the follow-\ning diagnosis of thought questions: 1. what is the\nsituation? Find out the facts that are objective; what\nis the patient thinking or imagining? Find out the\nthoughts or opinions that are subjective. 2. what\nmakes the patient think the thought is true or is not\ntrue? Find out the reasoning processes that support\nand do not support these thoughts. 3. why does\nthe patient come up with such reasoning process\nsupporting the thought? What’s the underlying\ncognition mode of it?\nAppendix C: Generation Examples\nWe present some generation examples of GPT-3.5\nand GPT-4 in Figure 3.\n4303\nPatient Message: Lately I have been extremely unhappy for no apparent reason. I feel empty almost all the time. It is like nothing can give me genuine joy \nanymore. I also feel alone a lot, even though I do have friends and close friends. Whenever I try to imagine my future all I see is one full of obstacles. I have \nbecome so consumed in sadness and I do not know how to deal anymore. I feel so confused and I do not understand myself anymore.\nDiagnosis of Thought (ChatGPT):\nObjective Fact:The patient has been feeling extremely unhappy and empty lately. \nSubjective \nThought:\nNothing can give the patient genuine joy and that the future is full of \nobstacles. the patient feels confused and does not understand \nthemselves anymore.\nReasoning \nProcess \nSupporting the \nThoughts:\nReasoning \nProcess \nContradicting the \nThoughts:\nThe patient may believe that their thoughts are true because they are \nexperiencing these feelings and emotions firsthand.\nThere may not be factual evidence to support the belief that nothing \ncan give the patient genuine joy or that the future is full of obstacles. \nthe patient may be using emotional reasoning to support their beliefs.\nCognition \nSchema:\nThe patient may be experiencing a cognitive mode of negativity bias, \nwhere they tend to focus on negative experiences and thoughts rather \nthan positive ones. this may be influencing their reasoning processes, \nleading them to magnify the negative and filter out the positive aspects \nof their life and future. additionally, the patient may be struggling with \ndepression, which can impact the way they perceive themselves and \nthe world around them.\nObjective Fact:The patient has been extremely unhappy recently. The patient feels \nempty and alone most of the time. he patient has friends and close \nfriends.\nSubjective \nThought:\nThey believe nothing can bring them genuine joy anymore. They \nimagine their future full of obstacles. They feel consumed by sadness \nand confusion and no longer understand themselves.\nReasoning \nProcess \nSupporting the \nThoughts:\nReasoning \nProcess \nContradicting the \nThoughts:\nThe persistent feeling of emptiness and lack of joy might make the \npatient believe that their situation is unchanging and will remain the \nsame. They may be experiencing negative events in their lives, making \nit harder to feel hopeful about their future.\nFeeling alone even when surrounded by friends could cause them to \nthink that their friendships are not fulfilling or meaningful.\nEmotions and feelings are temporary and can change over time, so it is \nnot guaranteed that the patient will always feel this way. The patient is \naware that they do have friends, which suggests that some level of \nmeaningful connection exists. Obstacles are a natural part of life, but \nthey are not the only things present in one's future. positive events and \nachievements are also likely to occur.\nCognition \nSchema:\nEmotional reasoning: they believe that their feelings of unhappiness, \nemptiness, and loneliness are true reflections of their life's reality.\nMental filter: they are focusing on the negative aspects of their life and \nfiltering out positive experiences or memories.\nFortune-telling: they are assuming that their future will be full of \nobstacles based on their current emotions and thoughts.\nDiagnosis of Thought (GPT4):\nPatient Message: So I have no close friends at the moment probably I know some people enough just to say hi but no close one and whenever I make any \nthey go away I don’t know if its my personality the reason or the way I behave and the only friends I can gain are school friends since there is no other place \nI go to I can’t really stand myself alone. Thanks for helping.\nDiagnosis of Thought (ChatGPT):\nObjective Fact:The patient has no close friends at the moment and feels lonely.The \npatient has made acquaintances but no close friends.\nSubjective \nThought:\nThe patient feels that they are the reason for their friends leaving and \nwonders if it's their personality or behavior causing the issue. they \ncannot stand being alone.\nReasoning \nProcess \nSupporting the \nThoughts:\nReasoning \nProcess \nContradicting the \nThoughts:\nThe patient believes their thoughts to be true because they have not \nbeen able to maintain any close friendships and the pattern keeps \nrepeating itself. they may be using past experiences to support this \nbelief.\nThere may be other reasons for the loss of these friendships that the \npatient is not considering.\nCognition \nSchema:\nThe patient may be experiencing cognitive distortions such as \novergeneralization by assuming that all friendships will end up the \nsame way and mental filtering by focusing only on the negative aspects \nof their past friendships. the underlying cognition mode could be a \nnegative self-image or low self-esteem.\nObjective Fact:The patient currently does not have close friends and mainly interacts \nwith school friends. they feel lonely and seek help.\nSubjective \nThought:\nThe patient believes that their personality or behavior might be the \nreason their friendships don't last, and they are limited in opportunities \nto make new friends.\nReasoning \nProcess \nSupporting the \nThoughts:\nReasoning \nProcess \nContradicting the \nThoughts:\nThe patient might have experienced failed friendships and noticed a \npattern of people leaving their life. this leads them to question if their \npersonality or behavior is the cause.\nThe patient has not provided concrete examples or evidence that their \npersonality or behavior is the reason behind the lack of close \nfriendships. it is possible there are external factors or situational \ncircumstances that led to the loss of friendships.\nCognition \nSchema:\nThe patient might be engaging in personalization and \novergeneralization cognitive distortions. personalization because they \nseem to be taking the blame for friendships not lasting, assuming it's \ntheir fault due to their personality or behavior. overgeneralization \nbecause they are making a broad conclusion based on limited \ninformation (i.e., the assumption that their personality or behavior is the \nsole reason for the lack of close friends). this underlying cognition mode \ncould stem from low self-esteem, fear of rejection, or previous negative \nexperiences in social situations.\nDiagnosis of Thought (GPT4):\nFigure 3: Showcases of Diagnosis of Thought using ChatGPT and GPT4 given the Patient Message.\n4304"
}