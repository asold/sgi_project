{
  "title": "Assessing the Capability of Large Language Model Chatbots in Generating Plain Language Summaries",
  "url": "https://openalex.org/W4408740572",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2556512418",
      "name": "Himel Mondal",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1771882280",
      "name": "Gaurav Gupta",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2411372681",
      "name": "Pradosh Kumar Sarangi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2183572683",
      "name": "Shreya Sharma",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Pritam K Choudhary",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2337313780",
      "name": "Ayesha Juhi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2020758011",
      "name": "Anita Kumari",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2553101096",
      "name": "Shaikat Mondal",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4281978380",
    "https://openalex.org/W3208452663",
    "https://openalex.org/W4382362832",
    "https://openalex.org/W2949322907",
    "https://openalex.org/W3173498612",
    "https://openalex.org/W4384663467",
    "https://openalex.org/W4213012464",
    "https://openalex.org/W4387249771",
    "https://openalex.org/W4388832642",
    "https://openalex.org/W4390771646",
    "https://openalex.org/W4392193048",
    "https://openalex.org/W4366823941",
    "https://openalex.org/W4391536321",
    "https://openalex.org/W4386477610",
    "https://openalex.org/W2755902049",
    "https://openalex.org/W4390972832",
    "https://openalex.org/W4382774929",
    "https://openalex.org/W4281619291",
    "https://openalex.org/W4386022860",
    "https://openalex.org/W4386774345",
    "https://openalex.org/W4386831162",
    "https://openalex.org/W4399699716",
    "https://openalex.org/W4405580547",
    "https://openalex.org/W4401942545",
    "https://openalex.org/W4402628569",
    "https://openalex.org/W4386120650"
  ],
  "abstract": "Background Plain language summaries (PLSs) make scientific research accessible to a broad non-expert audience. However, crafting effective PLS can be challenging, particularly for non-native English-speaking researchers. Large language model (LLM) chatbots have the potential to assist in generating summaries, but their effectiveness compared to human-generated PLS remains underexplored. Methods This cross-sectional study compared 30 human-written PLS with LLM chatbot (viz., ChatGPT (OpenAI, San Francisco, CA), Claude (Anthropic, San Francisco, CA), Copilot (Microsoft Corp., Washington, DC), Gemini (Google, Mountain View, CA), Meta AI (Meta, Menlo Park, CA), and Perplexity (Perplexity AI, Inc., San Francisco, CA)) generated PLS. The readability of the PLS was checked by the Flesch reading (FR) ease score, and understandability was checked by the Flesch-Kincaid (FK) grade level. Three authors rated the text on seven-item predefined criteria, and their average score was used to compare the quality of the PLS. Results In comparison to human-written PLS, chatbots could generate PLS with lower FK grade levels (p-value < 0.0001) and except Copilot, all others had higher FR ease scores. The overall score of human-written PLS was 8.89±0.26. Although there was statistically significant variance among the scores (F = 7.16, p-value = 0.0012), in the post-hoc test, there was no difference between human-generated and individual chatbots-generated PLS (ChatGPT 8.8±0.34, Claude 8.89±0.33, Copilot 8.69±0.4, Gemini 8.56±0.56, Meta AI 8.98±0.23, and Perplexity 8.8±0.3). Conclusion LLM chatbots can generate PLS with better readability and a person with a lower grade of education can understand it. The PLS are of similar quality to those written by human authors. Hence, authors can generate PLS from LLM chatbots and it is particularly beneficial for researchers in developing countries. While LLM chatbots improve readability, they may introduce minor inaccuracies also. Hence, PLS generated by LLM should always checked for accuracy and relevancy.",
  "full_text": null,
  "topic": "Perplexity",
  "concepts": [
    {
      "name": "Perplexity",
      "score": 0.8407154083251953
    },
    {
      "name": "Readability",
      "score": 0.7352229952812195
    },
    {
      "name": "Chatbot",
      "score": 0.5551601648330688
    },
    {
      "name": "Plain language",
      "score": 0.5452291965484619
    },
    {
      "name": "Medicine",
      "score": 0.5025227069854736
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4971061050891876
    },
    {
      "name": "Natural language processing",
      "score": 0.4853162169456482
    },
    {
      "name": "Language model",
      "score": 0.4109388589859009
    },
    {
      "name": "Computer science",
      "score": 0.34849703311920166
    },
    {
      "name": "Linguistics",
      "score": 0.13069656491279602
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ]
}