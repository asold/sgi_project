{
    "title": "Efficient Inference Offloading for Mixture-of-Experts Large Language Models in Internet of Medical Things",
    "url": "https://openalex.org/W4399043344",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2115700479",
            "name": "Xiao-ming Yuan",
            "affiliations": [
                "Northeastern University",
                "Xidian University"
            ]
        },
        {
            "id": "https://openalex.org/A2166653684",
            "name": "WeiXuan Kong",
            "affiliations": [
                "Northeastern University"
            ]
        },
        {
            "id": "https://openalex.org/A2011892972",
            "name": "Zhenyu Luo",
            "affiliations": [
                "Northeastern University"
            ]
        },
        {
            "id": "https://openalex.org/A2126877878",
            "name": "Minrui Xu",
            "affiliations": [
                "Nanyang Technological University"
            ]
        },
        {
            "id": "https://openalex.org/A2115700479",
            "name": "Xiao-ming Yuan",
            "affiliations": [
                "Xidian University",
                "Northeastern University"
            ]
        },
        {
            "id": "https://openalex.org/A2166653684",
            "name": "WeiXuan Kong",
            "affiliations": [
                "Northeastern University"
            ]
        },
        {
            "id": "https://openalex.org/A2011892972",
            "name": "Zhenyu Luo",
            "affiliations": [
                "Northeastern University"
            ]
        },
        {
            "id": "https://openalex.org/A2126877878",
            "name": "Minrui Xu",
            "affiliations": [
                "Nanyang Technological University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3113288818",
        "https://openalex.org/W4401878796",
        "https://openalex.org/W6778883912",
        "https://openalex.org/W6810738896",
        "https://openalex.org/W6769627184",
        "https://openalex.org/W3187018546",
        "https://openalex.org/W3176617251",
        "https://openalex.org/W4308760226",
        "https://openalex.org/W4297253404",
        "https://openalex.org/W3081168214",
        "https://openalex.org/W4387321091",
        "https://openalex.org/W4386768656",
        "https://openalex.org/W3129329365",
        "https://openalex.org/W4297163704",
        "https://openalex.org/W4381194795",
        "https://openalex.org/W4381743266",
        "https://openalex.org/W4392152396",
        "https://openalex.org/W4396988239",
        "https://openalex.org/W4386275697",
        "https://openalex.org/W4386596944",
        "https://openalex.org/W4285148832",
        "https://openalex.org/W6788811087",
        "https://openalex.org/W6853920016",
        "https://openalex.org/W4381930847",
        "https://openalex.org/W4288089799",
        "https://openalex.org/W4287391717",
        "https://openalex.org/W4226278401",
        "https://openalex.org/W4292779060"
    ],
    "abstract": "Despite recent significant advancements in large language models (LLMs) for medical services, the deployment difficulties of LLMs in e-healthcare hinder complex medical applications in the Internet of Medical Things (IoMT). People are increasingly concerned about e-healthcare risks and privacy protection. Existing LLMs face difficulties in providing accurate medical questions and answers (Q&amp;As) and meeting the deployment resource demands in the IoMT. To address these challenges, we propose MedMixtral 8x7B, a new medical LLM based on the mixture-of-experts (MoE) architecture with an offloading strategy, enabling deployment on the IoMT, improving the privacy protection for users. Additionally, we find that the significant factors affecting latency include the method of device interconnection, the location of offloading servers, and the speed of the disk.",
    "full_text": null
}