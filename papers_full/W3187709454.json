{
  "title": "A Fine-Tuned Bidirectional Encoder Representations From Transformers Model for Food Named-Entity Recognition: Algorithm Development and Validation",
  "url": "https://openalex.org/W3187709454",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2145299151",
      "name": "Riste Stojanov",
      "affiliations": [
        "Saints Cyril and Methodius University of Skopje"
      ]
    },
    {
      "id": "https://openalex.org/A2921815713",
      "name": "Gorjan Popovski",
      "affiliations": [
        "Jožef Stefan Institute",
        "Jožef Stefan International Postgraduate School"
      ]
    },
    {
      "id": "https://openalex.org/A3023947710",
      "name": "Gjorgjina Cenikj",
      "affiliations": [
        "Jožef Stefan Institute",
        "Jožef Stefan International Postgraduate School"
      ]
    },
    {
      "id": "https://openalex.org/A4221875403",
      "name": "Barbara Koroušić Seljak",
      "affiliations": [
        "Jožef Stefan Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2628426685",
      "name": "Tome Eftimov",
      "affiliations": [
        "Jožef Stefan Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2145299151",
      "name": "Riste Stojanov",
      "affiliations": [
        "Saints Cyril and Methodius University of Skopje"
      ]
    },
    {
      "id": "https://openalex.org/A2921815713",
      "name": "Gorjan Popovski",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3023947710",
      "name": "Gjorgjina Cenikj",
      "affiliations": [
        "Jožef Stefan International Postgraduate School",
        "Jožef Stefan Institute"
      ]
    },
    {
      "id": "https://openalex.org/A4221875403",
      "name": "Barbara Koroušić Seljak",
      "affiliations": [
        "Jožef Stefan Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2628426685",
      "name": "Tome Eftimov",
      "affiliations": [
        "Jožef Stefan Institute"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3002881589",
    "https://openalex.org/W2621985024",
    "https://openalex.org/W2141869602",
    "https://openalex.org/W2682408236",
    "https://openalex.org/W1578843544",
    "https://openalex.org/W2800535933",
    "https://openalex.org/W2949176808",
    "https://openalex.org/W2890830728",
    "https://openalex.org/W2963339489",
    "https://openalex.org/W2404369708",
    "https://openalex.org/W2911489562",
    "https://openalex.org/W3013678667",
    "https://openalex.org/W3004047707",
    "https://openalex.org/W2604748391",
    "https://openalex.org/W2166240318",
    "https://openalex.org/W2112227057",
    "https://openalex.org/W1679133234",
    "https://openalex.org/W1034374084",
    "https://openalex.org/W2518463060",
    "https://openalex.org/W2987875462",
    "https://openalex.org/W1538085078",
    "https://openalex.org/W2905315292",
    "https://openalex.org/W2163068967",
    "https://openalex.org/W2948801580",
    "https://openalex.org/W2920887996",
    "https://openalex.org/W2131660156",
    "https://openalex.org/W2903298154",
    "https://openalex.org/W3006083204",
    "https://openalex.org/W2986127174",
    "https://openalex.org/W2104148262",
    "https://openalex.org/W3136048214",
    "https://openalex.org/W2978737311",
    "https://openalex.org/W3023545062",
    "https://openalex.org/W3012185272",
    "https://openalex.org/W3015281440",
    "https://openalex.org/W3119901886",
    "https://openalex.org/W2117539524",
    "https://openalex.org/W2963918774",
    "https://openalex.org/W1566289585",
    "https://openalex.org/W1623072288",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W2493916176",
    "https://openalex.org/W2335791510",
    "https://openalex.org/W3187709454",
    "https://openalex.org/W3105491236"
  ],
  "abstract": "Background Recently, food science has been garnering a lot of attention. There are many open research questions on food interactions, as one of the main environmental factors, with other health-related entities such as diseases, treatments, and drugs. In the last 2 decades, a large amount of work has been done in natural language processing and machine learning to enable biomedical information extraction. However, machine learning in food science domains remains inadequately resourced, which brings to attention the problem of developing methods for food information extraction. There are only few food semantic resources and few rule-based methods for food information extraction, which often depend on some external resources. However, an annotated corpus with food entities along with their normalization was published in 2019 by using several food semantic resources. Objective In this study, we investigated how the recently published bidirectional encoder representations from transformers (BERT) model, which provides state-of-the-art results in information extraction, can be fine-tuned for food information extraction. Methods We introduce FoodNER, which is a collection of corpus-based food named-entity recognition methods. It consists of 15 different models obtained by fine-tuning 3 pretrained BERT models on 5 groups of semantic resources: food versus nonfood entity, 2 subsets of Hansard food semantic tags, FoodOn semantic tags, and Systematized Nomenclature of Medicine Clinical Terms food semantic tags. Results All BERT models provided very promising results with 93.30% to 94.31% macro F1 scores in the task of distinguishing food versus nonfood entity, which represents the new state-of-the-art technology in food information extraction. Considering the tasks where semantic tags are predicted, all BERT models obtained very promising results once again, with their macro F1 scores ranging from 73.39% to 78.96%. Conclusions FoodNER can be used to extract and annotate food entities in 5 different tasks: food versus nonfood entities and distinguishing food entities on the level of food groups by using the closest Hansard semantic tags, the parent Hansard semantic tags, the FoodOn semantic tags, or the Systematized Nomenclature of Medicine Clinical Terms semantic tags.",
  "full_text": "Original Paper\nA Fine-Tuned Bidirectional Encoder Representations From\nTransformers Model for Food Named-Entity Recognition:Algorithm\nDevelopment and Validation\nRiste Stojanov1*, PhD; Gorjan Popovski2,3*, MSc; Gjorgjina Cenikj2,3*, BSc; Barbara Koroušić Seljak2*, PhD; Tome\nEftimov2*, PhD\n1Faculty of Computer Science and Engineering, Ss Cyril and Methodius, University- Skopje, Skopje, the Former Yugoslav Republic of Macedonia\n2Computer Systems Department, Jožef Stefan Institute, Ljubljana, Slovenia\n3Jožef Stefan International Postgraduate School, Ljubljana, Slovenia\n*all authors contributed equally\nCorresponding Author:\nTome Eftimov, PhD\nComputer Systems Department\nJožef Stefan Institute\nJamova Cesta 39\nLjubljana, 1000\nSlovenia\nPhone: 386 1 477 3386\nEmail: tome.eftimov@ijs.si\nAbstract\nBackground: Recently, food science has been garnering a lot of attention. There are many open research questions on food\ninteractions, as one of the main environmental factors, with other health-related entities such as diseases, treatments, and drugs.\nIn the last 2 decades, a large amount of work has been done in natural language processing and machine learning to enable\nbiomedical information extraction. However, machine learning in food science domains remains inadequately resourced, which\nbrings to attention the problem of developing methods for food information extraction. There are only few food semantic resources\nand few rule-based methods for food information extraction, which often depend on some external resources. However, an\nannotated corpus with food entities along with their normalization was published in 2019 by using several food semantic resources.\nObjective: In this study, we investigated how the recently published bidirectional encoder representations from transformers\n(BERT) model, which provides state-of-the-art results in information extraction, can be fine-tuned for food information extraction.\nMethods: We introduce FoodNER, which is a collection of corpus-based food named-entity recognition methods. It consists\nof 15 different models obtained by fine-tuning 3 pretrained BERT models on 5 groups of semantic resources: food versus nonfood\nentity, 2 subsets of Hansard food semantic tags, FoodOn semantic tags, and Systematized Nomenclature of Medicine Clinical\nTerms food semantic tags.\nResults: All BERT models provided very promising results with 93.30% to 94.31% macro F1 scores in the task of distinguishing\nfood versus nonfood entity, which represents the new state-of-the-art technology in food information extraction. Considering the\ntasks where semantic tags are predicted, all BERT models obtained very promising results once again, with their macro F1 scores\nranging from 73.39% to 78.96%.\nConclusions: FoodNER can be used to extract and annotate food entities in 5 different tasks: food versus nonfood entities and\ndistinguishing food entities on the level of food groups by using the closest Hansard semantic tags, the parent Hansard semantic\ntags, the FoodOn semantic tags, or the Systematized Nomenclature of Medicine Clinical Terms semantic tags.\n(J Med Internet Res 2021;23(8):e28229) doi: 10.2196/28229\nKEYWORDS\nfood information extraction; named-entity recognition; fine-tuning BERT; semantic annotation; information extraction; BERT;\nbidirectional encoder representations from transformers; natural language processing; machine learning\nJ Med Internet Res 2021 | vol. 23 | iss. 8 | e28229 | p. 1https://www.jmir.org/2021/8/e28229\n(page number not for citation purposes)\nStojanov et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nIntroduction\nFood is one of the most important environmental factors that\naffects human health [1]. However, even healthy and ecofriendly\nfoods can cause health problems when consumed together with\nspecific drugs or while having specific diseases. Comprehensive\ndietary assessments are required to understand how food\ninfluences our health, after considering various aspects.\nAutomating the detection of food entities is important for several\napplications such as food-drug interactions and health issues\nrelated to food.\nComputer science can greatly contribute to this research topic,\nespecially in the areas of machine learning, natural language\nprocessing (NLP), and data analysis. Data collected in studies\ncarry important information, which is not easily extracted when\nit has been gathered from different data sources. The main\nproblem is that these data are presented in different formats:\nstructured, semistructured, and unstructured. Additionally, the\ndata consist of entities from different domains such as food and\nnutrition, medicine, pharmacy, ecology, and agriculture. The\nextraction of this information allows the creation of knowledge\ngraphs [2], which represent a collection of interlinked\ndescriptions of entities—objects, events, or concepts—by using\nsemantic metadata and providing a framework for data\nintegration, unification, analytics, and sharing.\nTo create a knowledge graph, first, we should have methods\nthat can be used for information extraction, which is the task\nof automatically extracting structured information from\nunstructured textual data. In most cases, information extraction\nis performed by using named-entity recognition (NER) methods\n(ie, a subtask of information extraction), which deal with\nautomatically detecting and identifying phrases (ie, one or more\nwords [tokens]) from the text that represents the domain entities.\nLet us assume the following recipe example (Figure 1):\nFigure 1. Recipe example.\nThe phrases in bold (Figure 1) are the named entities that should\nbe recognized in the process of information extraction, and they\nshould be linked to their corresponding domain entity tag. In\nthe simplest case, they may be linked to the generic “Food”\nclass, but extracting the more specific food class by a level of\nfood group may be of higher value, because this class may\npotentially provide multiple nutrition facts that may allow new\nuse cases such as ingredient substitution.\nSeveral types of NER methods exist depending on their\nunderlying methodology: (1) dictionary-based[3], which return\nonly entities that are mentioned in the dictionary in which they\nare based; (2) rule-based [4,5], which use a dictionary in\ncombination with rules that describe the characteristics of the\nentities in the domain of interest; (3) corpus-based [6,7], which\nlearn a supervised machine learning model by using an annotated\ncorpus; (4) active learning–based[8], which use semisupervised\nlearning to train a model that does not require a large annotated\ncorpus but instead interacts with the user to query for new\nannotations that are used for iteratively improving the model;\nand (5) deep learning–based [9], which use deep neural\nnetworks to train a model that requires a large amount of\nannotated data. Nowadays, fine-tuning the bidirectional encoder\nrepresentations from transformers (BERT) [10] provides\nstate-of-the-art results in NER tasks. However, the task of\nfine-tuning the BERT model for NER requires a domain-specific\nannotated corpus.\nIn the past 2 decades, a large amount of work has been done to\naddress this problem in the biomedical domain [11-17]. All of\nthis work is supported by the existence of diverse biomedical\nvocabularies and standards such as the Unified Medical\nLanguage System [18], together with the collection of a large\namount of annotated biomedical data (eg, in the domain of\ndrugs, diseases, and other treatments) from numerous biomedical\nNLP workshops [19-26]. The existence of such resources and\ninformation extraction methods allows the creation of knowledge\ngraphs that can support the biomedical domain and clinical\npractices [27,28].\nIn contrast to the biomedical domain, the food domain is\nrelatively inadequately resourced. There are few semantic\nmodels (ie, ontologies) [29], each of which has been developed\nfor very specific applications. One such example is the Ontology\nfor Nutritional Epidemiology, which was developed to describe\ndietary food assessment [30]. Until recently, there was no\nannotated food corpus, which meant that the available food\nNERs were rule-based. Hanisch et al [4] presented a rule-based\nNER known as drNER for information extraction from\nevidence-based dietary recommendations. Food entities are\namong the domain entities of interest that are extracted.\nHowever, drNER extracts several food entities as one. This was\nimproved by developing the rule-based NER Food Information\nExtraction [31], where the rules incorporate computational\nlinguistics information in combination with food semantic\nannotations from the Hansard corpus [32]. Another way to\nperform food information extraction is to use the NCBO\n(National Center for Biomedical Ontology) annotator [33],\nwhich is a web service that annotates text by using food ontology\nconcepts that are part of the BioPortal software services [34].\nIt can be combined with the following ontologies: FoodOn [35],\nOntoFood, and SNOMED CT (Systematized Nomenclature of\nMedicine Clinical Terms) [36]. A comparison of 4 NER methods\n(Food Information Extraction, NCBO [SNOMED CT], NCBO\n[OntoFood], and NCBO [FoodOn]) is presented by Popovski\net al [37], who showed that Food Information Extraction\nprovides the best results in distinguishing food from nonfood\nJ Med Internet Res 2021 | vol. 23 | iss. 8 | e28229 | p. 2https://www.jmir.org/2021/8/e28229\n(page number not for citation purposes)\nStojanov et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nentities. The main weakness of the abovementioned NERs is\nthat they all depend on other external resources such as\ntaxonomies, ontologies, or previously developed annotators,\nwhich further can be a problem if some of the resources become\ninaccessible. This also opens new directions for future research\nregarding the development of more robust food NERs.\nAt the end of 2019, an annotated food corpus known as\nFoodBase [38] was published. The ground truth corpus consists\nof 1000 recipes, where for each recipe, the food entities\nmentioned in it are first extracted and then annotated using the\nhierarchical Hansard food semantic tags (eg, AG.01 [food],\nAG.01.h.02 [vegetables], AG.01.h.02.i [herb], AG.01.n.15\n[pastry], AE.10 [fish]). The corpus is organized according to\nthe BioC format, which is a minimalist approach for\ninteroperability for biomedical text processing [39]. The\navailability of the FoodBase corpus allowed the development\nof the first food corpus-based NER known as bidirectional long\nshort-term memory for food named-entity recognition\n(BuTTER) [40], where bidirectional long short-term memory\n(BiLSTM) in conjunction with conditional random fields (CRFs)\nand different representation learning methods have been\nexplored to develop NER that distinguishes between food versus\nnonfood entities. In addition to this, the FoodOntoMap resource\nwas published [41], where for the same entities found in\nFoodBase, the semantic tags from FoodOn, OntoFood, and\nSNOMED CT were assigned. With this, the food entities were\nnormalized to different food semantic resources, which\nadditionally links the food semantic resources.\nEnabled by the availability of several food resources that were\npublished toward the end of 2019, we introduce a fine-tuned\nBERT model that can be used for food information extraction,\ncalled as FoodNER. BERT is known to achieve state-of-the-art\nresults in NER tasks [42-44], and hence, we utilize it to develop\na more robust model for food information extraction. The\nflowchart of FoodNER is presented in Figure 2. It is developed\nusing a predefined BERT model, which can be the original\nBERT or some variation of BioBERT. Using them, fine-tuning\nis performed on the FoodBase corpus to address several different\ntasks: food or nonfood entity and 4 types of distinguishing food\nentities, depending on the semantic resource from where the\nsemantic tags are taken (ie, Hansard semantic taxonomy [done\ntwice on different hierarchical levels from the taxonomy],\nFoodOn, and SNOMED CT).\nFigure 2. Food named-entity recognition flowchart. BERT: bidirectional encoder representations from transformers; NER: named-entity recognition;\nSNOMED CT: Systematized Nomenclature of Medicine Clinical Terms.\nThe main contributions of this study are as follows:\n1. We fine-tuned different BERT models on different semantic\nresources from which the food semantic tags are taken. All\nBERT models have very promising results, obtaining around\n73.39%-78.96% macro F1 score. All in all, it represents the\nnew state-of-the-art in food information extraction.\n2. In comparison with the already existing food rule–based\n(Food Information Extraction) and corpus-based (BuTTER)\nNER methods regarding the task of distinguish between\nfood or nonfood entity, FoodNER provides similar results.\nHowever, it is more robust than the rule-based approaches\nsince it does not require the continuous availability of\nadditional external resources, which can be a problem\nregarding sustainability. Additionally, comparing it to the\ncorpus-based method BuTTER, it is the first model that can\npredict food groups instead of just distinguishing between\nfood versus nonfood entities.\n3. The source code used for fine-tuning the different FoodNER\nmodels is publicly available. All models are also included\nin FoodViz [45], which is a new tool for the visualization\nJ Med Internet Res 2021 | vol. 23 | iss. 8 | e28229 | p. 3https://www.jmir.org/2021/8/e28229\n(page number not for citation purposes)\nStojanov et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nof food annotations in text. The users can additionally select\nwhich model they want to use and annotate their data.\nIn this study, we used the FoodBase ground truth corpus for\nbuilding and evaluating FoodNER models for distinguishing\nfood versus nonfood entity as well as for distinguishing food\nentities concerning the Hansard semantic tags. The BuTTER\napproach is used as baseline for comparing the performance of\nthe FoodNER models. The FoodOntoMap extension of the\nFoodBase ground truth corpus is also used for training and\nevaluating the FoodNER models concerning the SNOMED CT\nand FoodOn semantic tags.\nMethods\nFoodBase Data Corpus\nThe FoodBase data corpus is a recently published corpus with\nfood annotations [38]. It consists of 2 versions: curated and\nuncurated. The curated version consists of 1000 recipes that are\nannotated using a rule-based NER and then manually checked\nby subject matter experts who removed the false positives and\nadded the false negatives to create a ground truth standard. It\nconsists of 200 recipes for each of the following recipe\ncategories: appetizers and snacks, breakfast and lunch, dessert,\ndinner, and drinks. The uncurated version consists of\napproximately 22,000 recipes, which are only annotated with\nthe rule-based NER, without being checked by subject matter\nexperts. The semantic tags used for annotations are taken from\nthe Hansard corpus [32,45]. To the best of our knowledge, this\nis the first corpus with such annotated food entities.\nFood Semantic Resources\nHansard Corpus\nThe Hansard corpus [32] is part of the SAMUELS (Semantic\nAnnotation and Mark-Up for Enhancing Lexical Searches)\nproject, where semantic tags are organized in a hierarchy with\n37 higher-level semantic groups. One of these groups is the\nFood and Drink, which is then split into 3 subcategories, that\nis, food, production of food, farming, and acquisition of animals\nfor food, hunting. These have 125, 36, and 13 top-level semantic\ntags, respectively.\nFoodOn Ontology\nFoodOn is a farm-to-fork ontology about food, which supports\nfood traceability [35]. It consists of information about food\nproducts, their sources, and information about preservation\nprocesses, packaging, etc. It is built to represent food-related\nentities and to provide vocabulary for nutrition, diet, and plant\nand animal agricultural rearing research. FoodOn interoperates\nwith the Open Biological and Biomedical Ontology Library and\nimports material from several ontologies covering anatomy,\ntaxonomy, geography, and cultural heritage. The ontology aims\nto cover gaps in the representation of food-related products and\nprocesses and is being applied to research and clinical data sets\nin the academia and government.\nSNOMED CT Ontology\nSNOMED CT is the most comprehensive multilingual clinical\nhealth care terminology [36]. It is a machine-readable collection\nof medical terms, where synonyms and clinical definitions are\navailable for each of the codes. It consists of information about\ndrugs, disorders, symptoms, diagnoses, procedures, body\nstructures, food, and other concepts that are related to health\ncare.\nFoodOntoMap\nFoodOntoMap is a recently published resource that is developed\nby using the FoodBase corpus [38]. It provides data\nnormalization of the food entities according to different semantic\nresources. Specifically, for each extracted entity presented in\nthe FoodBase corpus, the semantic tags from Hansard, FoodOn,\nOntoFood, and SNOMED CT are available. It is important to\nnote that the semantic tags from resources other than Hansard\nare not available for some of the extracted food entities since\nthey do not exist in the respective food ontologies themselves.\nThe food entity coverage per semantic resource is presented by\nPopovski et al [37].\nBERT\nBERT is a word representation model that achieves\nstate-of-the-art results in many NLP tasks [10]. The main idea\nof BERT is the bidirectional training of the transformer, which\nis different from previously published models that were trained\nusing just a text sequence either from left to right or from right\nto left. Many models predict the next word in a sequence, while\nBERT uses a masked model, which predicts words masked in\nrandom order. It is used for bidirectional representation learning.\nBERT follows the idea and value of transfer learning [46,47],\nstarting with pretraining a representation language model and\nthen performing fine-tuning of the model for a new learning\ntask (eg, NER, Question Answering). The same architectures\nare used in the pretraining and the fine-tuning step. The only\ndifference is in the output layers. The parameters from the\npretrained model are used as initial parameters, which are further\nfine-tuned concerning the learning task that is being solved in\nthe fine-tuning.\nPretraining of BERT\nIn this phase, we did not pretrain a BERT model on our corpus.\nInstead, we used 3 previously pretrained and publicly available\nBERT models to fine-tune them for the food NER task.\nSpecifically, the 3 BERT models that were used were the\noriginal pretrained BERT model [10], the pretrained BioBERT\nstandard model [15], and the BioBERT large model [15]. The\noriginal BERT model was trained on the BookCorpus with\naround 800 million words [48] and the English Wikipedia with\naround 2500 million words, from which only the texts were\nused, ignoring the headers, tables, and lists.\nThe BioBERT was trained to improve the model for tasks in\nthe biomedical domain since the domain consists of a large\nnumber of domain-specific proper nouns and terms, which do\nnot appear in normal texts. Different combinations of corpora\nwere experimentally used for pretraining BioBERT. The\ncombinations involved the following corpora: the BookCorpus\nand the English Wikipedia (same as the BERT model), PubMed\nabstracts with around 4500 million words, and PubMed Central\nfull-text articles with around 13,500 million words. Finally, the\nmodel pretrained on the combination using the BookCorpus,\nJ Med Internet Res 2021 | vol. 23 | iss. 8 | e28229 | p. 4https://www.jmir.org/2021/8/e28229\n(page number not for citation purposes)\nStojanov et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nthe English Wikipedia, and PubMed abstracts using the\nBERT-base cased code provided by Google is known as the\nBioBERT language representation model (ie, BioBERT\nStandard). The same combination trained using the BERT-large\ncased code provided by Google is known as BioBERT large.\nFine-Tuning BERT\nTo perform food NER, we fine-tuned the original BERT and\nthe 2 versions of the BioBERT model. In all the cases, for each\nclass, we used the IOB (inside, outside, and beginning) tagging\n[49] prediction, which is a common tagging format in\ncomputational linguistics. In this process, we used the FoodBase\ncorpus as the ground truth. However, this corpus may contain\nmultiple Hansard tags for each food phrase, and we used a few\nmethods for selecting the most representative tag for each\nphrase.\nThe fine-tuning was performed for the following tasks:\n1. Food classification: This was performed for distinguishing\nfood versus nonfood entity. In this task, we labeled all food\nphrases annotated in FoodBase with the tag FOOD and\nused this data set for training and validation.\n2. Hansard parent: This was performed for distinguishing 48\nclasses from the Hansard corpus. In this task, we selected\nparent semantic tags from the Hansard hierarchy that\ncorrespond to the food phrases in FoodBase. In cases with\nmultiple different parent tags present for the food phrase,\nwe selected the first occurring parent.\n3. Hansard closest: This was performed for distinguishing 92\nclasses from the Hansard hierarchy. In this task, for each\nfood phrase in FoodBase, we chose the closest Hansard tag\nto the food phrase being annotated. The closest tag was\nselected using the minimum cosine distance between the\nBERT embedding of the food phrase and the BERT\nembeddings of the Hansard tag labels.\n4. FoodOn: This was performed for distinguishing 205 classes,\nwhere the classes are semantic tags from the FoodOn\nontology. For each food phrase in FoodBase, we selected\nthe corresponding FoodOn class based on the FoodOntoMap\nmappings [40].\n5. SNOMED CT: This was performed for distinguishing 207\nclasses, where the classes are semantic tags from the\nSNOMED CT ontology. In this task, we also used\nFoodOntoMap [40] to obtain the SNOMED CT class for\nthe food phrase.\nIn cases of food versus nonfood entity task and the task of\ndistinguishing food entities with regard to the Hansard semantic\ntags, we have a ground truth corpus—the curated part of\nFoodBase. However, in case of FoodOn and SNOMED CT, we\nfine-tuned BERT and BioBERT only for entities that had\nsemantic tags provided by the FoodOntoMap resource (ie, not\nall food entities are presented in these 2 resources as was\npreviously explained). All semantic tags (ie, Hansard parent,\nHansard closest, FoodOn, and SNOMED CT) for each food\nentity available in the FoodBase corpus are presented by the\nFoodViz tool (see Figure 3). Finally, we ended up with 15\ndifferent fine-tuned models, 3 per task depending on the\npretrained model that was used (BERT, BioBERT Standard, or\nBioBERT large).\nFigure 3. An example of food entities available from one recipe that are present in the training data set. The entities are annotated using Hansard parent,\nHansard closest, FoodOn, Systematized Nomenclature of Medicine Clinical Terms, and OntoFood (not studied in this paper) semantic tags.\nA Baseline for Comparison: BuTTER\nTo compare the results, the Bidirectional Long Short-Term\nMemory (LSTM) model for sequence tagging with a CRF layer\n(BiLSTM-CRF) [50] was used as a baseline, which has already\nbeen shown to achieve state-of-the-art results in several NLP\ntasks such as part-of-speech tagging, chunking, and NER tasks.\nAdditionally, the BiLSTM-CRF model has been used to train\nfood NER (food versus nonfood entity) utilizing the food\nannotations available in the FoodBase corpus [38], resulting in\nBuTTER models. BuTTER consists of 2 different BiLSTM-CRF\narchitectures, each one evaluated with 3-word embedding\nmethods (ie, GloVe [51], Word2Vec [52], and FastText [53])\nand once using the word tokens for representing the textual data\nused by the input layer. The difference between the 2 BuTTER\narchitectures is that the first one is a BiLSTM-CRF model\nwithout character embeddings, while the second one has an\nadditional stacked input and embedding layer to generate\ncharacter embeddings (Char-BiLSTM-CRF). When representing\nthe textual data using the predefined vocabularies of Word2Vec,\nJ Med Internet Res 2021 | vol. 23 | iss. 8 | e28229 | p. 5https://www.jmir.org/2021/8/e28229\n(page number not for citation purposes)\nStojanov et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nGloVe, and FastText, some of the words are absent; therefore,\nout-of-vocabulary word preprocessing techniques can be applied\nto handle them. In the case when word tokens are used, the\nimpact of lemmatization on the model performance was\ninvestigated. All in all, results from 16 different BuTTER\nmodels were obtained, that is, 2 architectures × 4 textual\nrepresentations (ie, 3-word embeddings + word tokens × 2\nscenarios, that is, preprocessing applied or not). More details\nabout them can be found in the study of Comeau et al [39].\nResults\nExperiments\nIn this section, the experimental setups for fine-tuning the BERT\nand BioBERT models in each classification task are explained,\nfollowed by the experimental results obtained by the evaluation.\nWe performed 2 experiments: (1) comparison of the BERT\nmodels with the corpus-based BuTTER models presented in a\nprevious study [40] on the food versus nonfood entity task, and\n(2) presenting results for BERT models that can distinguish\nbetween different food semantic tags.\nExperimental Design\nThe experiments were performed using the Colab platform [54].\nTo fine-tune the pretrained BERT and BioBERT models,\nHuggingFace’s transformers [55] library was used with its\nBertForTokenClassification class for token level prediction.\nThis class wraps the BertModel class and adds a token-level\nclassifier on top of it, which is a linear layer that takes the last\nhidden layer of the wrapped model as input. During the training\nof the fine-tuning, the AdamW optimizer was used with a\nweight_decay_rate of 0.01. The model was trained until its\nvalidation loss did not improve in 5 consecutive epochs, with\na maximum of 100 epochs and with a scheduler to linearly\nreduce the learning rate throughout the epochs. Figure 4 presents\nthe train and validation loss per fine-tuning epoch for the\nBioBERT large model on the Hansard parent data set. The same\npattern holds for the other models, and therefore, we present\nthe learning curve only for this particular model [56].\nFigure 4. Training and validation loss per fine-tuning epoch for the bio bidirectional encoder representations from transformers large model on the\nHansard parent data set.\nFor the BiLSTM-CRF model architecture or the BuTTER\nmodels, we used the default parameters presented in the study\nof Comeau et al [39], which are also presented here:\n1. The maximum sequence length (ie, sentence length) is 50\nsince the longest sentence in the data set consists of 45\ntokens.\n2. The batch size is 256.\n3. Architecture: input layer with 50 units, embedding layer\nwith 300 units, BiLSTM layer with 50 units (total of 100\nparameters), dense (TimeDistributed) layer with 50 units,\nCRF output layer where the final output dimension is the\nnumber of classes + 1 (ie, one for padding).\nThe aforementioned architecture refers to the complete\narchitecture of the BuTTER BiLSTM-CRF model, that is, the\nmodel without character embeddings. The BuTTER\nChar-BiLSTM-CRF model contains an additional stack of input\nand embedding layers for generating the character embeddings\nand a concatenation layer for concatenating the word\nembeddings with the character embeddings. The additional\ninput layer contains 18 units, while the additional embedding\nlayer contains 20 units. Each of the BuTTER models was trained\nuntil the improvement in validation loss of 5 consecutive epochs\ndid not surpass 5*10-3, to a maximum of 1000 epochs, whichever\ncomes first.\nThe data sets used for training and testing are from the curated\nversion of FoodBase [38] transformed in IOB tagging [49]\nformat [57]. The train portion contains 81,347 tokens, while we\nreport the results with the remaining 25,828 tokens, that is,\nJ Med Internet Res 2021 | vol. 23 | iss. 8 | e28229 | p. 6https://www.jmir.org/2021/8/e28229\n(page number not for citation purposes)\nStojanov et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\napproximately 75% of the data is used for training and the rest\nis for testing of the model. The curated version of FoodBase\ncontains 1000 recipes, with 5 categories that contain 200 recipes\neach. We use 150 recipes with alphabetically smaller identifiers\nof each category for training and the rest of the recipes from\nthe category for testing. The statistics about the number of\ntokens and their classes among the different data sets are shown\nin Table 1. The “Number of different inside, outside, and\nbeginning annotations” row in this table describes the classes\nthat our model tries to predict. Since we are predicting food\nphrases, for each different food phrase class, we may have\nannotations that start with B- for the first token in the phrase,\nand I- for all the rest of the tokens. Therefore, the number of\ndifferent IOB annotations is approximately twice as large\ncomparing it to the number of phrase classes. Additionally, the\ndata sets are not balanced since the majority of the tokens are\nnot part of the food phrase, that is, they are outside tokens. The\nHansard parent data set is smaller than the others since there\nwere 4 recipes with problematic parents and we omitted them\nin the evaluation.\nTable 1. Data set statistics.\nSNOMED CTaFoodOnHansard closestHansard parentFood classificationAnnotations\n8151873017,86411,75917,937Annotated tokens (beginning and inside)\n99,02498,44588,95695,41695,416Outside tokens\n318342163633Number of different inside, outside, and\nbeginning annotations\n19619791341Number of food phrase classes\n107,175107,175106,820107,176107,175Total number of tokens\naSNOMED CT: Systematized Nomenclature of Medicine Clinical Terms.\nThe evaluation of the proposed models was done using stratified\nfive-fold cross-validation. Stratified sampling was used to\ngenerate the folds since the FoodBase corpus consists of 5\ndifferent categories of recipes. For each recipe category, 10%\nof the training set of each fold was taken sequentially out and\nused for validation.\nExperimental Results\nNext, the results for both experiments are presented, starting\nwith the comparison of the BERT models with the BuTTER\nmodels on the food versus nonfood task, followed by presenting\nthe BERT models trained for distinguishing between different\nfood semantic tags. We present the results for the macro F1\nscore. The macro averaging scheme computes each metric for\neach class independently and then calculates the mean. The\nrationale behind using macro averaging is that it conveys more\nmeaningful information when considering especially a task that\nconsists of more than two semantic tags that should be predicted\nwith heavily unbalanced data. Conversely, simple micro\naveraging provides insufficient information in tasks where more\nthan two semantic tags (ie, classes) are used, as it conflates the\ntrue positives, false positives, true negatives, and false negatives\ninto one confusion matrix and then computes the evaluation\nmetrics. Similarly, weighted averaging is biased in favor of the\nclass most represented in the data, as the weight while\ncomputing the average depends on the relative frequency of the\nclass label in the data set.\nComparison With the BuTTER Approach\nFigure 5 [39] presents the results obtained from evaluating the\nfine-tuned BERT (ie, FoodNER) by using the original pretrained\nBERT model and 2 BioBERT models in the food versus nonfood\ntask described in Methods and comparing them with the\nBuTTER results obtained for the same task. From the table, it\nfollows that the best FoodNER model is obtained by fine-tuning\nthe original pretrained BERT, resulting in a macro F1 score of\n94.31%. Additionally, comparing it with the other FoodNER\nmodels obtained by fine-tuning BioBERT large and BioBERT\nstandard, the absolute empirical differences are very small,\namounting to only 0.05% and 0.12%, respectively. Comparing\nthe FoodNER models with both BuTTER architectures\n(BiLSTM-CRF and Char-BiLSTM-CRF) when word\nembeddings are used to represent the textual data for the input\nlayer (ie, GloVe, Word2Vec, and FastText), it follows that all\nFoodNER models have better macro F1 scores by using the\nstratified 5-fold cross-validation. However, we should point\nthat the differences here are in the range from 1.74% to 4.36%.\nComparing FoodNER models with both BuTTER architectures\nwhen word tokens are used for the input layer, the BiLSTM-CRF\nwith lemmatization of the word tokens outperforms the\nFoodNER models by 0.32% and the Char-BiLSTM-CRF without\nlemmatization of the word tokens by 0.28%. We can conclude\nhere that these differences are not crucial from a practical point\nof view; therefore, we can assume that all models perform\nsimilarly. Further, we also fine-tuned BERT by using the\nBiLSTM-CRF architecture for food classification, which results\nin a similar performance of a macro F1 score of 93.30%. To\nexplore the robustness of the models, Figure 6 presents boxplots\nof the macro F1 score distributions obtained by evaluating each\nfold for each model separately. From the figure, it follows that\nall models perform well since all of them provide a macro F1\nscore greater than 87.00% for each fold. The most robust models\nare FoodNER BioBERT standard model and the BuTTER\nBiLSTM-CRF model with Word2Vec when out-of-vocabulary\npreprocessing is applied. However, comparing the results\nbetween both models, the FoodNER BioBERT standard provides\na better macro F1 score. The other models also provide robust\nresults, where the macro F1 scores obtained from different folds\ndo no vary with large deviations. It is interesting to note that\nthe best macro F1 score is obtained when BERT is fine-tuned\nJ Med Internet Res 2021 | vol. 23 | iss. 8 | e28229 | p. 7https://www.jmir.org/2021/8/e28229\n(page number not for citation purposes)\nStojanov et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nwith BiLST-CRF for one of the five folds; however, using the\nvalues from the other folds, the macro F1 score of this model\ncan vary between different folds. Thus, we can conclude that\nthe FoodNER models, which are fine-tuned BERT, BioBERT\nstandard, and BioBERT large models, provide very robust\nresults. These results also show that by using BERT,\nstate-of-the-art results for food classification can be achieved.\nFigure 5. Macro F1 scores for all considered models for the food versus nonfood entity task. Each macro F1 score is obtained by using stratified k-fold\ncross-validation (k=5). Underlined values are best per subtable, while the bold value is the best from the whole table. BERT: bidirectional encoder\nrepresentations from transformers; BiLSTM-CRF: bidirectional long short-term memory conditional random field; BuTTER: bidirectional long short-term\nmemory for food named-entity recognition; NER: named-entity recognition.\nFigure 6. Boxplots of macro F1 scores obtained by using stratified five-fold cross-validation for all considered models for the binary food classification\ntask. BERT: bidirectional encoder representations from transformers; BiLSTM-CRF: bidirectional long short-term memory conditional random field.\nJ Med Internet Res 2021 | vol. 23 | iss. 8 | e28229 | p. 8https://www.jmir.org/2021/8/e28229\n(page number not for citation purposes)\nStojanov et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nBERT Models for Recognizing Between Different Food\nSemantic Tags\nIn this experiment, we present the results of fine-tuning the\nBERT, BioBERT large, and BioBERT standard models in the\ntasks of distinguishing food entities concerning different\nsemantic models (ie, FoodOn, Hansard closest, Hansard parent,\nand SNOMED CT). We have decided to focus only on the\nBERT models since it provides state-of-the-art results in already\nall NLP NER tasks. Additionally, in Table 1, the number of\nannotated tokens and the number of classes for each task are\npresented.\nTable 2 provides the macro F1 scores for the 3 FoodNER models\n(BERT, BioBERT large, and BioBERT standard) for\ndistinguishing food entities concerning different semantic\nmodels (ie, FoodOn, Hansard closest, Hansard parent, and\nSNOMED CT). The column “epochs” provides information\nfor the number of epochs needed to fine-tune the model. From\nthe table, it is evident that all models achieved a macro F1 score\nbetween 73.39% and 78.96%. The best models for each semantic\ntag set achieved the following macro F1 scores: (1) FoodOn,\n78.13%; (2) Hansard closest, 78.96%; (3) Hansard parent,\n76.26%; and (4) SNOMED CT, 76.01%.\nKeeping in mind the number of classes we are predicting for\neach task, we can conclude that these are really promising\nresults. Additionally, the FoodNER models trained in the tasks\nof distinguish food entities concerning semantic tags on the\nlevel of food groups are the first corpus-based NERs that can\ndistinguish between different food semantic tags (ie, food\ngroups). Once more, we should emphasize that in the cases of\nFoodOn and SNOMED CT, the BERT and BioBERT models\nare tuned only on the entities that have semantic tags provided\nby the FoodOntoMap resource, in which not all food entities\nfrom the semantic resources are present.\nTable 2. Macro F1 scores for the 3 food named-entity recognition models for the tasks concerning different semantic models.\nMacro F1 score (%)EpochsaModel, semantic model\nBERTb\n78.13100FoodOn\n75.8785Hansard closest\n75.04100Hansard parent\n76.0191SNOMED CTc\nBioBERT-large\n75.5893FoodOn\n78.96100Hansard closest\n76.26100Hansard parent\n74.5195SNOMED CT\nBioBERT-standard\n74.81100FoodOn\n74.18100Hansard closest\n74.9489Hansard parent\n73.3989SNOMED CT\naThis provides information on the number of epochs needed to fine-tune the model.\nbBERT: bidirectional encoder representations from transformers.\ncSNOMED CT: Systematized Nomenclature of Medicine Clinical Terms.\nDiscussion\nPrincipal Findings\nThe models are trained on FoodBase [38], in which recipes that\nare collected from the biggest social media networks for sharing\nand discovering recipes, are annotated. Since this is a specific\ntype of text, there are some weaknesses when it comes to\napplications on texts of a different nature (eg, medical texts).\nTo address this in our future work, we plan to further retrain\nthe models on various types of documents such as dietary\nrecommendations and PubMed articles. Regardless of this, the\npresented BERT models are robust for extracting food concepts\nwhile simultaneously normalizing them to some semantic\nresource, which allows further interlinking of the entities with\nother domains (eg, health and environmental sciences). This\nwill help to improve the quality of health and clinical practices.\nThe semantic tags were selected based on the food annotations\nthat exist from the FoodBase and FoodOntoMap resources.\nHowever, in future, the FoodNER methodology may be applied\non any other annotated corpus from this domain. To bring our\nwork closer to subject matter experts from the food domain, the\nFoodNER models have been integrated in the FoodViz platform\n[45]. Figure 7 shows the interface where subject matter experts\ncan place an arbitrary recipe, select a model, and preview the\nannotated food entities. We provide highlighting of the phrases\nJ Med Internet Res 2021 | vol. 23 | iss. 8 | e28229 | p. 9https://www.jmir.org/2021/8/e28229\n(page number not for citation purposes)\nStojanov et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nin the text, as well as the tabular display of the food phrases and\ntheir annotations. Figure 7 is an example where a short\ndescription from a recipe “Heat rapeseed oil in a large Dutch\noven over high heat. Sear cubes of beef a few at a time, until\nwell browned on all sides, about 4 minutes per batch. Reserve\nbrowned beef in a bowl. Reduce heat to medium and add onion\nand garlic. Cook until soft and just beginning to brown, about\n10 minutes.” is annotated using the model fine-tuned with\nBioBERT large in the Hansard closest task. From the\nannotations provided, it is obvious that the model can recognize\nall food entities that are mentioned in the text (ie, grapeseed\noil, beef, browned beef, onion, and garlic) annotated by Hansard\nsemantic tags. This interface radically simplifies the usage of\nthe state-of-the-art models for subject matter experts in the food\ndomain, without their knowledge of the underlying details, such\nas machine learning or IOB format understanding. Additionally,\nthe current architecture of the FoodViz application allows\nintegration of new prediction models only with their upload at\nthe corresponding location in the server.\nFigure 7. Food named-entity recognition integration in FoodViz.\nConclusion\nWe present a corpus-based NER method for food information\nextraction, known as FoodNER. It is developed by fine-tuning\nthe BERT model by using 3 previously published predefined\nBERT representation language models (ie, the original BERT\nand 2 BioBERTs; standard and large). FoodNER can be used\nto extract and annotate food entities in 5 different tasks:\ndistinguishing between food versus nonfood entities and\ndistinguishing food entities on the level of food groups by using\nthe closest Hansard semantic tags, the parent Hansard semantic\ntags, the FoodOn semantic tags, or the SNOMED CT semantic\ntags. All in all, the models provide very promising results\nachieving around 93.30%-94.31% macro F1 scores in the food\nversus nonfood entity task and around 73.39%-78.96% macro\nF1 scores in the tasks where more semantic tags are recognized.\nAdditionally, the models are included in the FoodViz\nframework, which allows users to select which FoodNER model\nthey want to use for the annotation of their texts with food\nentities and additionally provides a visualization of the annotated\ndata with an opportunity to correct the false positive and false\nnegative annotations. Having such a robust state-of-the-art food\ninformation extraction method such as FoodNER will allow\nfurther research in investigating food-drug and food-disease\ninteractions, thereby providing an opportunity to start building\na food knowledge graph, including relations with health-related\nentities.\nAcknowledgments\nThis research was supported by the Slovenian Research Agency (research core grant P2-0098 and grant PR-10465), the European\nUnion’s Horizon 2020 research and innovation program (FNS-Cloud, Food Nutrition Security) (grant agreement 863059), and\nthe Ad Futura grant for postgraduate study. The information and the views set out in this publication are those of the authors and\ndo not necessarily reflect the official opinion of the European Union. Neither the European Union institutions and bodies nor any\nperson acting on their behalf may be held responsible for the use that may be made of the information contained herein.\nConflicts of Interest\nNone declared.\nReferences\n1. Johan F, Owen G. Scaling 36 solutions to halve emissions by 2030. Exponential Roadmap. 2020. URL: https:/\n/exponentialroadmap.org/wp-content/uploads/2019/09/Exponential-Roadmap-1.5-September-19-2019.pdf [accessed\n2021-05-19]\nJ Med Internet Res 2021 | vol. 23 | iss. 8 | e28229 | p. 10https://www.jmir.org/2021/8/e28229\n(page number not for citation purposes)\nStojanov et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\n2. Qiao L, Yang L, Hong D, Yao L, Zhiguang Q. Knowledge graph construction techniques. Journal of computer research\nand development 2016;53(3):582 [FREE Full text] [doi: 10.7544/issn1000-1239.2016.20148228]\n3. Zhou X, Zhang X, Hu X. MaxMatcher: Biological concept extraction using approximate dictionary lookup. 2006 Presented\nat: Pacific Rim International Conference On Artificial Intelligence; August 7-11, 2006; Guilin, China p. 1145-1149. [doi:\n10.1007/11801603_150]\n4. Hanisch D, Fundel K, Mevissen H, Zimmer R, Fluck J. ProMiner: rule-based protein and gene entity recognition. BMC\nBioinformatics 2005;6(Suppl 1):S14. [doi: 10.1186/1471-2105-6-s1-s14]\n5. Eftimov T, Koroušić Seljak B, Korošec P. A rule-based named-entity recognition method for knowledge extraction of\nevidence-based dietary recommendations. PLoS One 2017;12(6):e0179488 [FREE Full text] [doi:\n10.1371/journal.pone.0179488] [Medline: 28644863]\n6. Alnazzawi N, Thompson P, Batista-Navarro R, Ananiadou S. Using text mining techniques to extract phenotypic information\nfrom the PhenoCHF corpus. BMC Med Inform Decis Mak 2015 Jun 15;15(S2):1-10. [doi: 10.1186/1472-6947-15-s2-s3]\n7. Leaman R, Wei CH, Zou C, Lu Z. Mining patents with tmChem, GNormPlus and an ensemble of open systems. Proceedings\nof the Fifth Biocreative Challenge Evaluation Workshop. URL: https://biocreative.bioinformatics.udel.edu/media/store/\nfiles/2015/BCV2015_paper_61.pdf [accessed 2021-07-05]\n8. Settles B. Active learning literature survey. University of Wisconsin Madison. URL: https://minds.wisconsin.edu/bitstream/\nhandle/1793/60660/TR1648.pdf?sequence=1&isAllowed=y [accessed 2021-05-19]\n9. Lopez MM, Kalita J. Deep learning applied to NLP. Cornell University. URL: https://arxiv.org/abs/1703.03091 [accessed\n2021-06-24]\n10. Devlin J, Chang MW, Lee K, Toutanova K. Bert: Pre-training of deep bidirectional transformers for language understanding.\nCornell University. URL: https://arxiv.org/abs/1810.04805 [accessed 2021-06-24]\n11. Dang TH, Le HQ, Nguyen TM, Vu ST. D3NER: biomedical named entity recognition using CRF-biLSTM improved with\nfine-tuned embeddings of various linguistic information. Bioinformatics 2018 Oct 15;34(20):3539-3546. [doi:\n10.1093/bioinformatics/bty356] [Medline: 29718118]\n12. Giorgi JM, Bader GD. Transfer learning for biomedical named entity recognition with neural networks. Bioinformatics\n2018 Dec 01;34(23):4087-4094 [FREE Full text] [doi: 10.1093/bioinformatics/bty449] [Medline: 29868832]\n13. Yoon W, So CH, Lee J, Kang J. CollaboNet: collaboration of deep neural networks for biomedical named entity recognition.\nBMC Bioinformatics 2019 May 29;20(Suppl 10):249 [FREE Full text] [doi: 10.1186/s12859-019-2813-6] [Medline:\n31138109]\n14. Wang X, Zhang Y, Ren X, Zhang Y, Zitnik M, Shang J, et al. Cross-type biomedical named entity recognition with deep\nmulti-task learning. Bioinformatics 2019 May 15;35(10):1745-1752. [doi: 10.1093/bioinformatics/bty869] [Medline:\n30307536]\n15. Lee J, Yoon W, Kim S, Kim D, Kim S, So CH, et al. BioBERT: a pre-trained biomedical language representation model\nfor biomedical text mining. Bioinformatics 2020 Feb 15;36(4):1234-1240 [FREE Full text] [doi:\n10.1093/bioinformatics/btz682] [Medline: 31501885]\n16. Zhou H, Ning S, Liu Z, Lang C, Liu Z, Lei B. Knowledge-enhanced biomedical named entity recognition and normalization:\napplication to proteins and genes. BMC Bioinformatics 2020 Jan 30;21(1):35 [FREE Full text] [doi:\n10.1186/s12859-020-3375-3] [Medline: 32000677]\n17. Cho M, Ha J, Park C, Park S. Combinatorial feature embedding based on CNN and LSTM for biomedical named entity\nrecognition. J Biomed Inform 2020 Mar;103:103381 [FREE Full text] [doi: 10.1016/j.jbi.2020.103381] [Medline: 32004641]\n18. Lindberg DAB, Humphreys BL, McCray AT. The Unified Medical Language System. Yearb Med Inform 2018 Mar\n05;02(01):41-51. [doi: 10.1055/s-0038-1637976]\n19. Arighi CN, Carterette B, Cohen KB, Krallinger M, Wilbur WJ, Fey P, et al. An overview of the BioCreative 2012 Workshop\nTrack III: interactive text mining task. Database (Oxford) 2013;2013:bas056 [FREE Full text] [doi: 10.1093/database/bas056]\n[Medline: 23327936]\n20. Mao Y, Van Auken K, Li D, Arighi CN, McQuilton P, Hayman GT, et al. Overview of the gene ontology task at BioCreative\nIV. Database (Oxford) 2014;2014:bau086 [FREE Full text] [doi: 10.1093/database/bau086] [Medline: 25157073]\n21. Wei CH, Peng Y, Leaman R, Davis AP, Mattingly CJ, Li J, et al. Assessing the state of the art in biomedical relation\nextraction: overview of the BioCreative V chemical disease relation (CDR) task. Database (Oxford) 2016;2016:baw032.\n[doi: 10.1093/database/baw032]\n22. Pyysalo S, Ohta T, Rak R, Rowley A, Chun H, Jung S, et al. Overview of the Cancer Genetics and Pathway Curation tasks\nof BioNLP Shared Task 2013. BMC Bioinformatics 2015 Jun 23;16(S10):1-19. [doi: 10.1186/1471-2105-16-s10-s2]\n23. Stubbs A, Kotfila C, Uzuner. Automated systems for the de-identification of longitudinal clinical narratives: Overview of\n2014 i2b2/UTHealth shared task Track 1. J Biomed Inform 2015 Dec;58 Suppl:S11-S19 [FREE Full text] [doi:\n10.1016/j.jbi.2015.06.007] [Medline: 26225918]\n24. Deléger L, Bossy R, Chaix E, Ba M, Ferre A, Bessieres P, et al. Overview of the bacteria biotope task at bioNLP shared\ntask 2016. 2016 Presented at: Proceedings of the 4th BioNLP shared task workshop; August 12, 2016; Berlin, Germany p.\n12-22. [doi: 10.18653/v1/w16-3002]\nJ Med Internet Res 2021 | vol. 23 | iss. 8 | e28229 | p. 11https://www.jmir.org/2021/8/e28229\n(page number not for citation purposes)\nStojanov et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\n25. Cohen KB, Demner-Fushman D, Ananiadou S, Tsujii J. Biomedical natural language processing in 2017: The view from\ncomputational linguistics. The Association for Computational Linguistics. URL: https://aclanthology.org/W17-23.pdf\n[accessed 2021-06-24]\n26. Wang Y, Zhou K, Gachloo M, Xia J. An Overview of the Active Gene Annotation Corpus and the BioNLP OST 2019\nAGAC Track Tasks. 2019 Presented at: Proceedings of The 5th Workshop on BioNLP Open Shared Tasks; November 3-7,\n2019; Hong Kong p. 62-71. [doi: 10.18653/v1/d19-5710]\n27. Ernst P, Siu A, Weikum G. KnowLife: a versatile approach for constructing a large knowledge graph for biomedical\nsciences. BMC Bioinformatics 2015 May 14;16:157 [FREE Full text] [doi: 10.1186/s12859-015-0549-5] [Medline:\n25971816]\n28. Sang S, Yang Z, Liu X, Wang L, Lin H, Wang J, et al. GrEDeL: A Knowledge Graph Embedding Based Method for Drug\nDiscovery From Biomedical Literatures. IEEE Access 2019;7:8404-8415. [doi: 10.1109/access.2018.2886311]\n29. Boulos M, Yassine A, Shirmohammadi S, Namahoot C, Brückner M. Towards an “Internet of Food”: Food Ontologies for\nthe Internet of Things. Future Internet 2015 Oct 01;7(4):372-392. [doi: 10.3390/fi7040372]\n30. Yang C, Ambayo H, Baets BD, Kolsteren P, Thanintorn N, Hawwash D, et al. An Ontology to Standardize Research Output\nof Nutritional Epidemiology: From Paper-Based Standards to Linked Content. Nutrients 2019 Jun 08;11(6):1300 [FREE\nFull text] [doi: 10.3390/nu11061300] [Medline: 31181762]\n31. Popovski G, Koroušić Seljak B, Eftimov T. FoodIE: A Rule-based Named-entity Recognition Method for Food Information\nExtraction. 2019 Presented at: International Conference on Pattern Recognition Applications and Methods; February 19-21,\n2019; Prague, Czech Republic p. 915-922. [doi: 10.5220/0007686309150922]\n32. Alexander M, Anderson J. The Hansard corpus, 1803-2003. University of Glasgow. URL: https://eprints.gla.ac.uk/81804/\n[accessed 2021-05-19]\n33. Jonquet C, Shah N, Youn C, Callendar C, Storey MA, Musen M. NCBO annotator: semantic annotation of biomedical data.\nInternational Semantic Web Conference. URL: http://www.lirmm.fr/~jonquet/publications/documents/\nDemo-ISWC09-Jonquet.pdf [accessed 2021-06-24]\n34. Noy NF, Shah NH, Whetzel PL, Dai B, Dorf M, Griffith N, et al. BioPortal: ontologies and integrated data resources at the\nclick of a mouse. Nucleic Acids Res 2009 Jul;37(Web Server issue):W170-W173 [FREE Full text] [doi: 10.1093/nar/gkp440]\n[Medline: 19483092]\n35. Dooley DM, Griffiths EJ, Gosal GS, Buttigieg PL, Hoehndorf R, Lange MC, et al. FoodOn: a harmonized food ontology\nto increase global food traceability, quality control and data integration. NPJ Sci Food 2018;2:23 [FREE Full text] [doi:\n10.1038/s41538-018-0032-6] [Medline: 31304272]\n36. Donnelly K. SNOMED-CT: The advanced terminology and coding system for eHealth. Stud Health Technol Inform\n2006;121:279-290. [Medline: 17095826]\n37. Popovski G, Seljak B, Eftimov T. A Survey of Named-Entity Recognition Methods for Food Information Extraction. IEEE\nAccess 2020;8:31586-31594. [doi: 10.1109/access.2020.2973502]\n38. Popovski G, Koroušić Seljak B, Eftimov T. FoodBase corpus: a new resource of annotated food entities. Database\n2019:baz121. [doi: 10.1093/database/baz121]\n39. Comeau DC, Islamaj Doğan R, Ciccarese P, Cohen KB, Krallinger M, Leitner F, et al. BioC: a minimalist approach to\ninteroperability for biomedical text processing. Database (Oxford) 2013;2013:bat064 [FREE Full text] [doi:\n10.1093/database/bat064] [Medline: 24048470]\n40. Cenikj G, Popovski G, Stojanov R, Koroušić Seljak B, Eftimov T. BuTTER: BidirecTional LSTM for Food Named-Entity\nRecognition. 2020 Presented at: 2020 IEEE International Conference on Big Data (Big Data); December 10-13, 2020;\nVirtual p. 3550-3556. [doi: 10.1109/bigdata50022.2020.9378151]\n41. Popovski G, Koroušić Seljak B, Eftimov T. FoodOntoMap: Linking Food Concepts across Different Food Ontologies.\n2019 Presented at: 11th International Conference on Knowledge Engineering and Ontology Development; 2019; Vienna,\nAustria p. 195-202. [doi: 10.5220/0008353201950202]\n42. Akhtyamova L. Named entity recognition in Spanish biomedical literature: Short review and BERT model. 2020 Presented\nat: 26th Conference of Open Innovations Association (FRUCT); April 20-24, 2020; Yaroslavl, Russia p. 1-7. [doi:\n10.23919/fruct48808.2020.9087359]\n43. Kim J, Ko Y, Seo J. Construction of Machine-Labeled Data for Improving Named Entity Recognition by Transfer Learning.\nIEEE Access 2020;8:59684-59693. [doi: 10.1109/access.2020.2981361]\n44. Miftahutdinov Z, Alimova I, Tutubalina E. On biomedical named entity recognition: experiments in interlingual transfer\nfor clinical and social media texts. 2020 Presented at: European Conference on Information Retrieval; April 14-17, 2020;\nLisbon, Portugal p. 281-288. [doi: 10.1007/978-3-030-45442-5_35]\n45. Stojanov R, Popovski G, Jofce N, Dimitar T, Koroušić Seljak B, Eftimov T. Foodviz: Visualization of food entities linked\nacross different standards. 2020 Presented at: International Conference on Machine Learning, Optimization, and Data\nScience; July 19-23, 2020; Siena-Tuscany, Italy p. 28-38. [doi: 10.1007/978-3-030-64580-9_4]\n46. Rayson P, Archer D, Piao S, McEnery AM. The UCREL semantic analysis system. 2004 Presented at: Proceedings of the\nbeyond named entity recognition semantic labelling for NLP tasks workshop; January 2004; Lisbon, Portugal p. 7-12 URL:\nhttps://www.researchgate.net/publication/228881331_The_UCREL_semantic_analysis_system\nJ Med Internet Res 2021 | vol. 23 | iss. 8 | e28229 | p. 12https://www.jmir.org/2021/8/e28229\n(page number not for citation purposes)\nStojanov et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\n47. Russakovsky O, Deng J, Su H, Krause J, Satheesh S, Ma S, et al. ImageNet Large Scale Visual Recognition Challenge. Int\nJ Comput Vis 2015 Apr 11;115(3):211-252. [doi: 10.1007/s11263-015-0816-y]\n48. Conneau A, Kiela D, Schwenk H, Barrault L, Bordes A. Supervised learning of universal sentence representations from\nnatural language inference data. ACL Anthology 2017:1-12. [doi: 10.18653/v1/d17-1070]\n49. Zhu Y, Kiros R, Zemel R, Salakhutdinov R, Urtasun R, Torralba A, et al. Aligning books and movies: Towards story-like\nvisual explanations by watching movies and reading books. 2015 Presented at: Proceedings of the IEEE international\nconference on computer vision; December 7-13, 2015; Santiago, Chile p. 19-27. [doi: 10.1109/iccv.2015.11]\n50. Ramshaw LA, Marcus MP. Text chunking using transformation-based learning. Natural language processing using very\nlarge corpora 1999:157-176. [doi: 10.1007/978-94-017-2390-9_10]\n51. Hung Z, Xu W, Yu K. Bidirectional LSTM-CRF models for sequence tagging. Cornell University. 2015. URL: https://arxiv.\norg/abs/1508.01991 [accessed 2021-07-05]\n52. Pennington J, Socher R, Manning CD. GloVe: Global vectors for word representation. 2014 Presented at: Proceedings of\nthe 2014 conference on empirical methods in natural language processing (EMNLP); October 25-29, 2014; Doha, Qatar\np. 1532-1543. [doi: 10.3115/v1/d14-1162]\n53. Mikolov T, Chen K, Corrado G, Dean J. Efficient estimation of word representations in vector space. Cornell University.\nURL: https://arxiv.org/abs/1301.3781 [accessed 2021-07-05]\n54. Stojanov R, Popovski G, Cenikj G, Koroušić Seljak B, Eftimov T. The source code (IPython notebook). GitHub. URL:\nhttps://github.com/ds4food/FoodNer/blob/master/FoodNER.ipynb [accessed 2021-05-19]\n55. Bojanowski P, Grave E, Joulin A, Mikolov T. Enriching Word Vectors with Subword Information. TACL 2017\nDec;5:135-146. [doi: 10.1162/tacl_a_00051]\n56. Stojanov R, Popovski G, Cenikj G, Koroušić Seljak B, Eftimov T. Detailed statistics about each of the fine-tuned models.\nFoodViz with FoodNER. URL: http://foodviz.env4health.finki.ukim.mk/#/result-resources [accessed 2021-05-19]\n57. Stojanov R, Popovski G, Cenikj G, Koroušić Seljak B, Eftimov T. FoodNER. GitHub. URL: https://github.com/ds4food/\nFoodNer/tree/master/data [accessed 2021-05-19]\nAbbreviations\nBERT: bidirectional encoder representations from transformers\nBiLSTM-CRF: bidirectional long short-term memory conditional random field\nBuTTER: bidirectional long short-term memory for food named-entity recognition\nIOB: inside, outside, and beginning\nNCBO: National Center for Biomedical Ontology\nNER: named-entity recognition\nNLP: natural language processing\nSNOMED CT: Systematized Nomenclature of Medicine Clinical Terms\nEdited by R Kukafka; submitted 25.02.21; peer-reviewed by C Yang, M Torii; comments to author 08.03.21; revised version received\n13.03.21; accepted 06.05.21; published 09.08.21\nPlease cite as:\nStojanov R, Popovski G, Cenikj G, Koroušić Seljak B, Eftimov T\nA Fine-Tuned Bidirectional Encoder Representations From Transformers Model for Food Named-Entity Recognition: Algorithm\nDevelopment and Validation\nJ Med Internet Res 2021;23(8):e28229\nURL: https://www.jmir.org/2021/8/e28229\ndoi: 10.2196/28229\nPMID: 34383671\n©Riste Stojanov, Gorjan Popovski, Gjorgjina Cenikj, Barbara Koroušić Seljak, Tome Eftimov. Originally published in the Journal\nof Medical Internet Research (https://www.jmir.org), 09.08.2021. This is an open-access article distributed under the terms of\nthe Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use,\ndistribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet\nResearch, is properly cited. The complete bibliographic information, a link to the original publication on https://www.jmir.org/,\nas well as this copyright and license information must be included.\nJ Med Internet Res 2021 | vol. 23 | iss. 8 | e28229 | p. 13https://www.jmir.org/2021/8/e28229\n(page number not for citation purposes)\nStojanov et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7585597038269043
    },
    {
      "name": "Named-entity recognition",
      "score": 0.7117364406585693
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6051579713821411
    },
    {
      "name": "Natural language processing",
      "score": 0.5934587717056274
    },
    {
      "name": "Information extraction",
      "score": 0.56200110912323
    },
    {
      "name": "Transformer",
      "score": 0.5538314580917358
    },
    {
      "name": "Normalization (sociology)",
      "score": 0.514393150806427
    },
    {
      "name": "Encoder",
      "score": 0.5097677111625671
    },
    {
      "name": "Information retrieval",
      "score": 0.46852487325668335
    },
    {
      "name": "Machine learning",
      "score": 0.4290342926979065
    },
    {
      "name": "Task (project management)",
      "score": 0.3631906509399414
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Anthropology",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Sociology",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ]
}