{
  "title": "Knowledge Neurons in Pretrained Transformers",
  "url": "https://openalex.org/W3152884768",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2891250805",
      "name": "Damai Dai",
      "affiliations": [
        "Peking University"
      ]
    },
    {
      "id": "https://openalex.org/A1974723233",
      "name": "Li Dong",
      "affiliations": [
        "Peking University"
      ]
    },
    {
      "id": "https://openalex.org/A2323301275",
      "name": "Yaru Hao",
      "affiliations": [
        "Peking University"
      ]
    },
    {
      "id": "https://openalex.org/A2441688708",
      "name": "Zhifang Sui",
      "affiliations": [
        "Peking University"
      ]
    },
    {
      "id": "https://openalex.org/A2141034123",
      "name": "Baobao Chang",
      "affiliations": [
        "Peking University"
      ]
    },
    {
      "id": "https://openalex.org/A2171151462",
      "name": "Furu Wei",
      "affiliations": [
        "Peking University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2123045220",
    "https://openalex.org/W2970120757",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W3171975879",
    "https://openalex.org/W2785611959",
    "https://openalex.org/W3127227595",
    "https://openalex.org/W2950339735",
    "https://openalex.org/W4205460703",
    "https://openalex.org/W3135593154",
    "https://openalex.org/W3035390927",
    "https://openalex.org/W2605409611",
    "https://openalex.org/W1849277567",
    "https://openalex.org/W3173787059",
    "https://openalex.org/W2594633041",
    "https://openalex.org/W2336525064",
    "https://openalex.org/W2462831000",
    "https://openalex.org/W3172099915",
    "https://openalex.org/W4287824654",
    "https://openalex.org/W2908336025",
    "https://openalex.org/W2156387975",
    "https://openalex.org/W2150165932",
    "https://openalex.org/W2972498556",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2107598941",
    "https://openalex.org/W3102659883",
    "https://openalex.org/W2963382180",
    "https://openalex.org/W3044438666",
    "https://openalex.org/W2899663614",
    "https://openalex.org/W2945260553",
    "https://openalex.org/W2972324944",
    "https://openalex.org/W2971274815",
    "https://openalex.org/W2946794439",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3104163040",
    "https://openalex.org/W2946417913",
    "https://openalex.org/W3202712981",
    "https://openalex.org/W2914120296",
    "https://openalex.org/W2952809536",
    "https://openalex.org/W2970476646",
    "https://openalex.org/W2962851944",
    "https://openalex.org/W3117576675",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3007759824",
    "https://openalex.org/W3042711927"
  ],
  "abstract": "Large-scale pretrained language models are surprisingly good at recalling factual knowledge presented in the training corpus. In this paper, we present preliminary studies on how factual knowledge is stored in pretrained Transformers by introducing the concept of knowledge neurons. Specifically, we examine the fill-in-the-blank cloze task for BERT. Given a relational fact, we propose a knowledge attribution method to identify the neurons that express the fact. We find that the activation of such knowledge neurons is positively correlated to the expression of their corresponding facts. In our case studies, we attempt to leverage knowledge neurons to edit (such as update, and erase) specific factual knowledge without fine-tuning. Our results shed light on understanding the storage of knowledge within pretrained Transformers.",
  "full_text": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\nVolume 1: Long Papers, pages 8493 - 8502\nMay 22-27, 2022c‚Éù2022 Association for Computational Linguistics\nKnowledge Neurons in Pretrained Transformers\nDamai Dai‚Ä†‚Ä°‚àó, Li Dong ‚Ä°, Yaru Hao ‚Ä°, Zhifang Sui ‚Ä†, Baobao Chang ‚Ä†, Furu Wei ‚Ä°\n‚Ä†MOE Key Lab of Computational Linguistics, Peking University\n‚Ä°Microsoft Research\n{daidamai,szf,chbb}@pku.edu.cn\n{lidong1,yaruhao,fuwei}@microsoft.com\nAbstract\nLarge-scale pretrained language models are\nsurprisingly good at recalling factual knowl-\nedge presented in the training corpus (Petroni\net al., 2019; Jiang et al., 2020b). In this pa-\nper, we present preliminary studies on how fac-\ntual knowledge is stored in pretrained Trans-\nformers by introducing the concept of knowl-\nedge neurons. SpeciÔ¨Åcally, we examine the\nÔ¨Åll-in-the-blank cloze task for BERT. Given\na relational fact, we propose a knowledge at-\ntribution method to identify the neurons that\nexpress the fact. We Ô¨Ånd that the activation\nof such knowledge neurons is positively cor-\nrelated to the expression of their correspond-\ning facts. In our case studies, we attempt to\nleverage knowledge neurons to edit (such as\nupdate, and erase) speciÔ¨Åc factual knowledge\nwithout Ô¨Åne-tuning. Our results shed light\non understanding the storage of knowledge\nwithin pretrained Transformers. The code\nis available at https://github.com/\nHunter-DDM/knowledge-neurons.\n1 Introduction\nLarge-scale pretrained Transformers (Devlin et al.,\n2019; Liu et al., 2019; Dong et al., 2019; Clark\net al., 2020; Bao et al., 2020) are usually learned\nwith a language modeling objective on large-scale\ncorpora, such as Wikipedia, where exists oceans\nof factual knowledge. Pretrained language models\nnaturally play as a free-text knowledge base by pre-\ndicting texts (Bosselut et al., 2019). Petroni et al.\n(2019) and Jiang et al. (2020b) probe factual knowl-\nedge stored in pretrained language models by Ô¨Åll-\nin-the-blank cloze queries. The evaluation shows\nthat pretrained Transformers have a strong ability\nto recall factual knowledge without any Ô¨Åne-tuning.\nRoberts et al. (2020) use closed-book question an-\nswering to show that the larger a model is, the more\nknowledge it can store. However, most previous\nwork focuses on evaluating the overall accuracy of\n‚àóContribution during internship at Microsoft Research.\nSelf-Attention Layer\nFeed-Forward\nNetwork\nKnowledge\nAttribution\nKnowledge\nNeurons\n‚Ä¶ \n‚Ä¶ \nQ27\nIreland\nQ1761\nDublincapital\nP36\nFactual Knowledge\nHidden State\nFigure 1: Through knowledge attribution, we identify\nknowledge neurons that express a relational fact.\ntext-form knowledge prediction. In this paper, we\nattempt to look deeper into pretrained Transformers\nand investigate how factual knowledge is stored.\nAs shown in Figure 1, we propose a knowl-\nedge attribution method to identify the neurons\nthat express a relational fact, where such neurons\nare named knowledge neurons. SpeciÔ¨Åcally, we\nview feed-forward network (i.e., two-layer percep-\ntron) modules in Transformer as key-value memo-\nries (Geva et al., 2020). For the example in Figure 1,\nthe hidden state is fed into the Ô¨Årst linear layer\nand activates knowledge neurons; then, the second\nlinear layer integrates the corresponding memory\nvectors. The key-value-memory nature (Geva et al.,\n2020) inspires us to propose the knowledge attribu-\ntion method, which identiÔ¨Åes knowledge neurons\nin feed-forward networks by computing the contri-\nbution of each neuron to the knowledge prediction.\nExtensive analysis shows that the activation of\nthe identiÔ¨Åed knowledge neurons is positively cor-\nrelated to the knowledge expression, which shows\n8493\nFeed-Forward \nNetwork\nFFN(key)\nActivation\ninner product\nweighted sum\nFFN(val)\nFFN Output\nHidden State\nThe capital of Ireland is [MASK] \nSelf-Attention Layer\nFeed-Forward Network\nDublin\n‚Ä¶ ‚Ä¶\n‚Ä¶ ‚Ä¶\nKnowledge\nNeurons\n‚Ä¶ ‚Ä¶\nùêø√ó\nFigure 2: Illustration of how an FFN module in a Transformer block works as a key-value memory. The Ô¨Årst linear\nlayer FFN(key) computes intermediate neurons through inner product. Taking the activation of these neurons as\nweights, the second linear layer FFN(val) integrates value vectors through weighted sum. We hypothesize that\nknowledge neurons in the FFN module are responsible for expressing factual knowledge.\nthe effectiveness of the proposed knowledge at-\ntribution method. First, suppressing and ampli-\nfying knowledge neurons notably affects the ex-\npression of the corresponding knowledge. Second,\nwe Ô¨Ånd that knowledge neurons of a fact tend to\nbe activated more by corresponding knowledge-\nexpressing prompts. Third, given the knowledge\nneurons of a fact, the top activating prompts re-\ntrieved from open-domain texts usually express\nthe corresponding fact, while the bottom activating\nprompts do not express the correct relation.\nIn our case studies, we try to leverage knowl-\nedge neurons to explicitly edit factual knowledge\nin pretrained Transformers without any Ô¨Åne-tuning.\nWe present two preliminary studies: updating facts,\nand erasing relations. After identifying the knowl-\nedge neurons, we perform a knowledge surgery\nfor pretrained Transformers by directly modify-\ning the corresponding parameters in feed-forward\nnetworks. Such surgery shows promising results,\nkeeping a moderate inÔ¨Çuence on other knowledge.\nOur contributions are summarized as follows:\n‚Ä¢ We introduce the concept of knowledge neu-\nrons and propose a knowledge attribution\nmethod to identify the knowledge neurons that\nexpress speciÔ¨Åc factual knowledge in the Ô¨Åll-\nin-the-blank cloze task.\n‚Ä¢ We conduct both qualitative and quantitative\nanalysis to show that knowledge neurons are\npositively correlated to knowledge expression.\n‚Ä¢ We present preliminary studies of leveraging\nknowledge neurons to edit factual knowledge\nin Transformers, even without any Ô¨Åne-tuning.\n2 Background: Transformer\nTransformer (Vaswani et al., 2017) is one of the\nmost popular and effective NLP architectures. A\nTransformer encoder is stacked with L identical\nblocks. Each Transformer block mainly contains\ntwo modules: a self-attention module, and a feed-\nforward network (abbreviated as FFN) module. Let\nX ‚ààRn√ód denote the input matrix, two modules\ncan be formulated as follows:\nQh = XWQ\nh ,Kh = XWK\nh ,Vh = XWV\nh , (1)\nSelf-Atth(X) = softmax\n(\nQhKT\nh\n)\nVh, (2)\nFFN(H) = gelu (HW1) W2, (3)\nwhere WQ\nh ,WK\nh ,WV\nh ,W1,W2 are parameter ma-\ntrices; Self-Atth(X) computes a single attention\nhead; H, the hidden state, is given by projecting\nthe concatenation of all heads; gelu denotes the\nGELU activation function (Hendrycks and Gimpel,\n2016). For simplicity, we omit the scaling factor in\nself-attention and the bias terms.\nConnections Between Self-Attention and FFN\nComparing Equation (2) and Equation (3), we no-\ntice that the formula of FFN(¬∑) is quite similar to\nSelf-Att(¬∑), except the activation function gelu in\nFFN and softmax in self-attention. Thus, similar\nto the query-key-value mechanism in self-attention,\nit is reasonable to regard the input of the FFN as a\nquery vector, and two linear layers of the FFN as\nkeys and values, respectively. Similar observations\nare also described in (Geva et al., 2020).\n8494\n3 Identifying Knowledge Neurons\nSimilar to (Geva et al., 2020), we view FFNs in\nTransformer as key-value memories as illustrated\nin Figure 2. We hypothesize that factual knowl-\nedge is stored in FFN memories and expressed by\nknowledge neurons. In this section, we propose a\nknowledge attribution method and a reÔ¨Åning strat-\negy to identify these knowledge neurons.\n3.1 Knowledge Assessing Task\nWe employ the Ô¨Åll-in-the-blank cloze task to assess\nwhether a pretrained model knows a fact. Follow-\ning Petroni et al. (2019), each relational fact is in\nthe form of a triplet‚ü®h,r,t‚ü©, where his the head en-\ntity, tis the tail entity, and ris the relation between\nthem. Given a fact, pretrained models answer the\ncloze query x that expresses the fact but leaves\nthe tail entity as a blank. For example, given the\nfact ‚ü®Ireland, capital, Dublin‚ü©, a pos-\nsible query is ‚ÄúThe capital of Ireland is ‚Äù. We\nalso call the query a knowledge-expressing prompt.\nPetroni et al. (2019) describe that a model knows\na fact if it can predict the correct answer. In this\npaper, rather than just examining the model out-\nputs, we identify the speciÔ¨Åc knowledge neurons\nthat express factual knowledge.\n3.2 Knowledge Attribution\nInspired by Hao et al. (2021), we propose a knowl-\nedge attribution method based on integrated gradi-\nents (Sundararajan et al., 2017). Our method can\nevaluate the contribution of each neuron to knowl-\nedge predictions. In this paper, we examine FFN\nintermediate neurons for the masked token, where\nthe answer is predicted.\nGiven an input prompt x, we Ô¨Årst deÔ¨Åne the\nmodel output Px( ÀÜw(l)\ni ) as the probability of the\ncorrect answer predicted by a pretrained model:\nPx( ÀÜw(l)\ni ) = p(y‚àó|x,w(l)\ni = ÀÜw(l)\ni ), (4)\nwhere y‚àódenotes the correct answer; w(l)\ni denotes\nthe i-th intermediate neuron in the l-th FFN; ÀÜw(l)\ni\nis a given constant that w(l)\ni is assigned to.\nIn order to calculate the attribution score of a neu-\nron Attr(w(l)\ni ), we gradually change w(l)\ni from 0 to\nits original value w(l)\ni calculated by the pretrained\nmodel, and meanwhile integrate the gradients:\nAttr(w(l)\ni ) = w(l)\ni\n‚à´ 1\nŒ±=0\n‚àÇPx(Œ±w(l)\ni )\n‚àÇw(l)\ni\ndŒ±, (5)\nwhere ‚àÇPx(Œ±w(l)\ni )\n‚àÇw(l)\ni\ncalculates the gradient of the\nmodel output with regard to w(l)\ni . Intuitively, as\nŒ± changes from 0 to 1, by integrating the gradi-\nents, Attr(w(l)\ni ) accumulates the output probability\nchange caused by the change of w(l)\ni . If the neuron\nhas a great inÔ¨Çuence on the expression of a fact,\nthe gradient will be salient, which in turn has large\nintegration values. Therefore, the attribution score\ncan measure the contribution of the neuron w(l)\ni to\nthe factual expressions.\nDirectly calculating continuous integrals is in-\ntractable. We instead use Riemann approxima-\ntion ÀúAttr(w(l)\ni ) = w(l)\ni\nm\n‚àëm\nk=1\n‚àÇPx( k\nm w(l)\ni )\n‚àÇw(l)\ni\n, where\nm = 20 is the number of approximation steps.\nWith the attribution algorithm, we can identify a\ncoarse set of knowledge neurons whose attribution\nscores are greater than a threshold t.\n3.3 Knowledge Neuron ReÔ¨Åning\nIn order to identify knowledge neurons more accu-\nrately, we further propose a reÔ¨Åning strategy. Be-\nsides ‚Äútrue-positive‚Äù knowledge neurons that ex-\npress factual knowledge, the coarse set of knowl-\nedge neurons may contain ‚Äúfalse-positive‚Äù knowl-\nedge neurons that express other information (e.g.,\nsyntactic or lexical information). The reÔ¨Åning strat-\negy aims to Ô¨Ålter out these ‚Äúfalse-positive‚Äù neurons.\nFor different prompts corresponding to the same\nfact, we hypothesize that they share the same set\nof ‚Äútrue-positive‚Äù knowledge neurons, since they\nexpress the same factual knowledge. Meanwhile,\nwe hypothesize that they do not share the ‚Äúfalse-\npositive‚Äù knowledge neurons as long as the prompts\nare diverse enough. Therefore, given multiple\ndiverse prompts, we can reÔ¨Åne the coarse set of\nknowledge neurons by retaining only neurons that\nare widely shared among these prompts.\nSpeciÔ¨Åcally, given a relational fact, the complete\nprocess to identify its knowledge neurons is de-\nscribed as follows: (1) produce ndiverse prompts;\n(2) for each prompt, calculate the knowledge at-\ntribution scores of neurons; (3) for each prompt,\nretain the neurons with attribution scores greater\nthan the attribution thresholdt, obtaining the coarse\nset of knowledge neurons; (4) considering all the\ncoarse sets together, retain the knowledge neurons\nshared by more than p% prompts.\n8495\nRelations Template #1 Template #2 Template #3\nP176 (manufacturer) [X] is produced by [Y] [X] is a product of [Y] [Y] and its product [X]\nP463 (member_of) [X] is a member of [Y] [X] belongs to the organization of [Y] [X] is afÔ¨Åliated with [Y]\nP407 (language_of_work) [X] was written in [Y] The language of [X] is [Y] [X] was a [Y]-language work\nTable 1: Example prompt templates of three relations in PARA REL. [X] and [Y] are the placeholders for the head\nand tail entities, respectively. Owing to the page width, we show only three templates for each relation. Prompt\ntemplates in PARA REL produce 253,448 knowledge-expressing prompts in total for 27,738 relational facts.\n4 Experiments\n4.1 Experimental Settings\nWe conduct experiments for BERT-base-cased (De-\nvlin et al., 2019), one of the most widely-used pre-\ntrained models. It contains 12 Transformer blocks,\nwhere the hidden size is 768 and the FFN inner\nhidden size is 3,072. Notice that our method is\nnot limited to BERT and can be easily general-\nized to other pretrained models. For each prompt,\nwe set the attribution threshold tto 0.2 times the\nmaximum attribution score. For each relation, we\ninitialize the reÔ¨Åning threshold p% (Section 3.3)\nas 0.7. Then, we increase or decrease it by 0.05\nat a time until the average number of knowledge\nneurons lies in [2, 5]. We run our experiments on\nNVIDIA Tesla V100 GPUs. On average, it costs\n13.3 seconds to identify knowledge neurons for a\nrelational fact with 9 prompts.\n4.2 Dataset\nWe examine knowledge neurons through the Ô¨Åll-\nin-the-blank cloze task based on the PARA REL\ndataset (Elazar et al., 2021). PARA REL is curated\nby experts, containing various prompt templates\nfor 38 relations from the T-REx dataset (ElSahar\net al., 2018). We show some example templates\nin Table 1. For each relational fact, we Ô¨Åll in the\nhead entity in prompt templates and leave the tail\nentity as a blank to predict. In order to guarantee\nthe template diversity, we Ô¨Ålter out relations with\nfewer than 4 prompt templates and Ô¨Ånally keep\n34 relations, where each relation has 8.63 differ-\nent prompt templates on average. These prompt\ntemplates produce 253,448 knowledge-expressing\nprompts in total for 27,738 relational facts.\n4.3 Attribution Baseline\nOur baseline method takes the neuron activation\nvalue as the attribution score, i.e., Attrbase(w(l)\ni ) =\nw(l)\ni , which measures how sensitive a neuron is\nto the input. After computing attribution scores,\nwe follow the same pipeline to obtain the reÔ¨Åned\n1 2 3 4 5 6 7 8 9 10 11 12\nLayer\n40%\n30%\n20%\n10%\n0%\n10%\n20%\n30%\n40%\nPercentage\nFigure 3: Percentage of knowledge neurons identiÔ¨Åed\nby our method in each Transformer layer.\nType of Neurons Ours Baseline\nKnowledge neurons 4.13 3.96‚ãÇof intra-rel. fact pairs 1.23 2.85‚ãÇof inter-rel. fact pairs 0.09 1.92\nTable 2: Statistics of knowledge neurons. ‚ãÇdenotes\nthe intersection of knowledge neurons of fact pairs.\n‚Äúrel.‚Äù is the shorthand of relation. Our method iden-\ntiÔ¨Åes more exclusive knowledge neurons.\nknowledge neurons. For a fair comparison, we\nemploy the same method to choose the hyper-\nparameters t and p% for the baseline to ensure\nthe average number of knowledge neurons for each\nrelation lies in [2,5].\nThe method based on neuron activation is a rea-\nsonable baseline. It is motivated by FFNs‚Äôs analogy\nwith the self-attention mechanism (as described in\nSection 2), because self-attention scores are usu-\nally used as a strong attribution baseline (Kovaleva\net al., 2019; V oita et al., 2019; Hao et al., 2021).\n4.4 Statistics of Knowledge Neurons\nFigure 3 presents the layer distribution of knowl-\nedge neurons identiÔ¨Åed by our knowledge attri-\nbution method. We notice that most fact-related\nneurons are distributed in the topmost layers of pre-\ntrained Transformers. The Ô¨Ånding also agrees with\nTenney et al. (2019) and Geva et al. (2020).\nTable 2 shows statistics of knowledge neurons.\nOn average, we identify 4.13 knowledge neurons\nfor each relational fact using our knowledge attri-\nbution method, and 3.96 using the baseline method.\n8496\nP101P103P106P108P127P1303P136P1376P138P140P1412P159P176P178P19 P190P20 P264P27 P279P30 P36 P364P37 P39 P407P413P449P463P47 P495P530P740P937\n-60%\n-50%\n-40%\n-30%\n-20%\n-10%\n0%\n10%\n20%\nCorrect Probability Change Ratio\nOurs\nBaseline\nFigure 4: Results of suppressing knowledge neurons for various relations. Suppressing knowledge neurons de-\ncreases the correct probability by 29.03% on average. For the baseline, the decreasing ratio is 1.47% on average.\nP101P103P106P108P127P1303P136P1376P138P140P1412P159P176P178P19 P190P20 P264P27 P279P30 P36 P364P37 P39 P407P413P449P463P47 P495P530P740P937\n-10%\n0%\n10%\n20%\n30%\n40%\n50%\n60%\n70%\n80%\nCorrect Probability Change Ratio\nOurs\nBaseline\nFigure 5: Results of amplifying knowledge neurons for various relations. Amplifying knowledge neurons increases\nthe correct probability by 31.17% on average. For the baseline, the correct probability even decreases by 1.27%.\nTheir same order of magnitude guarantees the fair-\nness of the subsequent comparisons in the paper.\nWe also compute the knowledge neuron inter-\nsection of different relational facts. Table 2 shows\nthe average number of pair-wise knowledge neu-\nron intersections. For our proposed method, (1)\nfact pairs with the same relation (intra-relation fact\npairs) share 1.23 knowledge neurons on average;\n(2) fact pairs with different relations (inter-relation\nfact pairs) share almost no knowledge neurons. In\ncontrast, for the baseline, (3) most identiÔ¨Åed neu-\nrons are shared by intra-relation fact pairs; (4) even\na substantial portion of neurons are common for\ninter-relation fact pairs. The difference in knowl-\nedge neuron intersections suggests that our method\ncan identify more exclusive knowledge neurons.\n4.5 Knowledge Neurons Affect Knowledge\nExpression\nWe investigate how much knowledge neurons can\naffect knowledge expression in Figure 4 and Fig-\nure 5. Given a relational fact, we manipulate its\nknowledge neurons in two ways: (1) suppressing\nknowledge neurons by setting their activations to\n0; (2) amplifying knowledge neurons by doubling\ntheir activations. Then, for each relation, we plot\nthe average change ratio of the probability for the\ncorrect answer, corresponding to the manipulation.\nFor comparison, we also plot the results of manipu-\nlating baseline-identiÔ¨Åed knowledge neurons.\nFigure 4 shows that suppressing knowledge\nneurons identiÔ¨Åed by our knowledge attribution\nmethod leads to a consistent decrease (29.03% on\naverage) in the correct probability. By contrast, for\nbaseline-identiÔ¨Åed neurons, the suppressing oper-\nation has a negligible inÔ¨Çuence (1.47% decrease\non average) on the correct probability. Notably, for\nthe relation P178 (developer), the correct prob-\nability abnormally increases by using the baseline.\nAs shown in Figure 5, we have similar observa-\ntions for amplifying the knowledge neurons iden-\ntiÔ¨Åed by our knowledge attribution. We see a con-\nsistent increase (31.17% on average) in the cor-\nrect probability. By contrast, the baseline even de-\ncreases the average correct probability by 1.27%.\nIn summary, the knowledge neurons identiÔ¨Åed\nby our knowledge attribution method tend to no-\ntably affect knowledge expression. Notice that the\nabove assessment is affected by the distribution of\nknowledge neurons. For example, if the knowledge\nneurons for a relation are distributed more widely,\nwe need to manipulate more top-kneurons for bet-\nter control. We use the above experiments as a\nproof of concept while leaving precise control for\nfuture work.\n8497\nRelational Facts Neurons Top-2 and Bottom-2 Activating Prompts (Average Activation)\n‚ü® Ireland,\ncapital,\nDublin ‚ü©\nw(9)\n2141, w(10)\n1122\nTop Our trip ... in Dublin, the capital and largest city of Ireland ... (6.36)\nDublin is the capital and largest city of Ireland. (5.77)\nBottom Dublin just might be the most iconic destination in all of Ireland. (1.27)\n... in Ireland‚Äôs famed city, you can enjoy ...Dublin experience ... (-0.30)\n‚ü® Cao_Yunding,\nplace_of_birth,\nShanghai ‚ü©\nw(10)\n739 , w(10)\n1885,\nw(11)\n2876\nTop Cao Yunding was born in Shanghai in November 1989. (3.58)\nFull name: Cao Yunding ... Place of birth: Shanghai, China ... (2.73)\nBottom ... Cao Yunding (Shanghai Shenhua) is shown the red card ... (-0.30)\nShanghai Shenhua midÔ¨Åelder Cao Yunding ... (-0.31)\n‚ü® Kuwait,\ncontinent,\nAsia ‚ü©\nw(6)\n147, w(9)\n866,\nw(9)\n1461, w(10)\n1169\nTop Kuwait is thus one of the smallest countries in Asia ... (6.63)\nKuwait is a country in Western Asia ... (6.27)\nBottom This page displays all Asia Society content on Kuwait ... (-0.48)\nNoor Asia is ... distribution companies in Kuwait ... (-0.59)\nTable 3: Example relational facts along with their knowledge neurons, their top-2 and bottom-2 activating prompts,\nand the corresponding neuron activation. w(l)\ni denotes the i-th intermediate neuron at the l-th FFN. We Ô¨Åll the\nblank in each prompt with the correct answer for better readability. Owing to the page width, we show only key\nparts for overlong prompts. The top-2 activating prompts express exactly the relation, but the bottom-2 do not.\nPrompt Types Ours Baseline\nContaining head and tail (T1) 0.485 2.472\nContaining only head (T2) 0.019 2.312\nRandomly sampled (T3) -0.018 2.244\nTable 4: Average activation of knowledge neurons for\nthree types of prompts. The activation of neurons iden-\ntiÔ¨Åed by our method can distinguish the knowledge-\nexpressing prompts (T1) clearly.\n4.6 Knowledge Neurons are Activated by\nKnowledge-Expressing Prompts\nIn order to study what prompts can activate knowl-\nedge neurons, we compare the average activation of\nknowledge neurons for different types of prompts.\nBING REL Dataset We build a new dataset BIN-\nGREL by crawling the Bing search engine to collect\nnew prompts, for a more extensive comparison be-\nyond the PARA REL dataset. For each of the 27,738\nfacts in PARA REL, we crawl two types of texts: (1)\nup to ten texts containing both the head and the tail\nentities (210,217 texts crawled in total); (2) up to\nten texts containing only the head entity without\nrestricting tail entities (266,020 texts crawled in\ntotal). Following the distant supervision assump-\ntion (Mintz et al., 2009), the Ô¨Årst type of texts tends\nto express the whole relational fact, while the sec-\nond type does not. We mask tail entities for the\nÔ¨Årst type of texts to obtain knowledge-expressing\nprompts (T1). In order to conduct a controlled ex-\nperiment, we mask random words for the second\ntype of texts, forming a control group (T2). More-\nover, we employ randomly sampled prompts as\nanother control group (T3).\nResults As shown in Table 4, for our method,\nthe identiÔ¨Åed knowledge neurons are more signiÔ¨Å-\ncantly activated by knowledge-expressing prompts\n(T1 = 0.485), compared with the control groups\n(T2 = 0.019 and T3 = ‚àí0.018). By contrast, for\nthe baseline, the activation of identiÔ¨Åed neurons\ncannot distinguish three types of prompts. In ad-\ndition, since our comparison is based on the web-\ncrawled BING REL dataset, we validate the general-\nization of knowledge neurons to open-domain texts\nthat are unseen in PARA REL.\nExample Prompts In Table 3, we present exam-\nple prompts that activate knowledge neurons the\nmost and the least, respectively. Given a fact, we\nÔ¨Årst identify its knowledge neurons with our knowl-\nedge attribution method. Then, we calculate the\naverage activation of knowledge neurons for each\ncrawled prompt that contains both the head and the\ntail entities in BING REL. Finally, we demonstrate\ntwo prompts with the highest average activation\nvalues and two with the lowest (denoted as top-2\nand bottom-2 activating prompts, respectively).\nAs shown in Table 3, the top-2 activating\nprompts express exactly the corresponding rela-\ntional fact. In contrast, despite containing the\nsame head and tail entities, the bottom-2 activating\nprompts do not express the correct relation. For\nexample, although the bottom-2 activating prompts\nfor ‚ü®Ireland, capital, Dublin‚ü©express\n8498\nErased Relations Perplexity (Erased Relation) Perplexity (Other Relations)\nBefore Erasing After Erasing Before Erasing After Erasing\nP19 (place_of_birth) 1450.0 2996.0 (+106.6%) 120.3 121.6 (+1.1%)\nP27 (country_of_citizenship) 28.0 38.3 (+36.7%) 143.6 149.5 (+4.2%)\nP106 (occupation) 2279.0 5202.0 (+128.2%) 120.1 125.3 (+4.3%)\nP937 (work_location) 58.0 140.0 (+141.2%) 138.0 151.9 (+10.1%)\nTable 5: Case studies of erasing relations. The inÔ¨Çuence on knowledge expression is measured by the perplexity\nchange. The knowledge erasing operation signiÔ¨Åcantly affects the erased relation, and has just a moderate inÔ¨Çuence\non the expression of other knowledge.\nMetric Knowledge Neurons Random Neurons\nChange rate‚Üë 48.5% 4.7%\nSuccess rate‚Üë 34.4% 0.0%\n‚àÜIntra-rel. PPL‚Üì 8.4 10.1\n‚àÜInter-rel. PPL‚Üì 7.2 4.3\nTable 6: Case studies of updating facts. ‚Üëmeans the\nhigher the better, and ‚Üìmeans the lower the better.\n‚Äúrel.‚Äù is the shorthand of relation. Keeping a moder-\nate inÔ¨Çuence on other knowledge, the surgery of knowl-\nedge neurons achieves a nontrivial success rate.\ninformation like ‚ÄúDublin is a city in Ireland‚Äù, they\ndo not reÔ¨Çect thecapital relation. The examples\nsupport again that knowledge neurons are activated\nby corresponding knowledge-expressing prompts.\n5 Case Studies\nWe present two preliminary studies to demonstrate\nthe potential applications of knowledge neurons.\nWe use the case studies as a proof of concept while\nleaving precise fact editing for future work.\n5.1 Updating Facts\nBy leveraging knowledge neurons in pretrained\nmodels, we try to update a learned relational fact\nfrom ‚ü®h,r,t‚ü©to ‚ü®h,r,t‚Ä≤‚ü©.\nMethods First, we identify the knowledge neu-\nrons of ‚ü®h,r,t‚ü©. Then, we retain the knowledge\nneurons that are shared by less than 10% of intra-\nrelation facts, to reduce the inÔ¨Çuence on other\nfacts with the same relation. Finally, we directly\nmodify the corresponding value slots in FFN(val)\n(i.e., the second linear layer of FFNs; see Fig-\nure 2): FFN(val)\ni = FFN(val)\ni ‚àíŒª1t + Œª2t‚Ä≤, where\nFFN(val)\ni denotes the value slot corresponding to\nthe i-th knowledge neuron; t and t‚Ä≤are the word\nembeddings of tand t‚Ä≤, respectively; Œª1 and Œª2 are\nset to 1 and 8 in our experiments.\nSetup We conduct experiments on PARA REL.\nFor each relation, we randomly sample ten facts\nlearned by the pretrained model. For each fact\n‚ü®h,r,t‚ü©, we randomly choose a different entity t‚Ä≤\nwith the same type as t(e.g., both tand t‚Ä≤belong\nto city), and then update t‚Ä≤as the target entity.\nWe only manipulate about four top knowledge neu-\nrons as in Section 4.4. For reference purposes, we\nalso perform the same update process on the same\nnumber of random neurons.\nEvaluation Metrics We report two metrics to\nevaluate the fact updating: (1) change rate, the\nratio that the original prediction tis modiÔ¨Åed to\nanother; (2) success rate, the ratio that t‚Ä≤becomes\nthe top prediction. In addition, we measure the\ninÔ¨Çuence on other knowledge by the following two\nmetrics: (1) ‚àÜintra-relation PPL, the increase of\nperplexity on the prompts with the same relation r;\n(2) ‚àÜinter-relation PPL, the increase of perplexity\non the prompts with different relations.\nResults As shown in Table 6, the surgery of\nknowledge neurons achieves a nontrivial success\nrate for updating facts, while random neurons are\ninsufÔ¨Åcient. Moreover, we Ô¨Ånd that such manipu-\nlation has little negative inÔ¨Çuence on other knowl-\nedge predictions. It is promising that we can\nchange very few (i.e., about four in the above exper-\niments) neurons to affect certain facts in pretrained\nTransformers. We can further improve the success\nrate by including more top knowledge neurons in\nthe update process.\n5.2 Erasing Relations\nWe explore how to leverage knowledge neurons\nto erase speciÔ¨Åc relations in pretrained Trans-\nformers. SpeciÔ¨Åcally, we take four relations in\nPARA REL as examples, i.e., place_of_birth,\ncountry_of_citizenship, occupation,\nwork_location, that typically express sensi-\ntive personal information.\n8499\nMethods Given a relation r, we Ô¨Årst identify\nknowledge neurons for all relational facts with r.\nThen, we retain 20 knowledge neurons that appear\nmost frequently among these facts. Finally, we\nset the value slots in FFN(val) (see Figure 2) cor-\nresponding to these knowledge neurons to 0, i.e.,\nzero vectors.\nResults As shown in Table 5, we report model\nperplexity before and after knowledge erasing.\nWith the erasing operation, the perplexity of the re-\nmoved knowledge increases as expected. Moreover,\nthe model perplexity of other relations remains sim-\nilar. We argue that knowledge neurons provide a\npromising way to erase undesired knowledge with\nminimal efforts.\n6 Related Work\nProbing Knowledge in Pretrained Models\nMany pieces of previous work aim to measure\nknowledge stored in pretrained models. Petroni\net al. (2019) propose to retrieve knowledge in pre-\ntrained models (such as BERT) using cloze queries.\nTheir experiments show that BERT has a strong\nability to recall factual knowledge without any Ô¨Åne-\ntuning. Jiang et al. (2020b) improve the cloze\nqueries with mining-based and paraphrasing-based\nmethods. Roberts et al. (2020) propose the closed-\nbook question answering to measure how much\nknowledge a pretrained model has stored in its pa-\nrameters. Elazar et al. (2021) measure and improve\nthe consistency of pretrained models with respect\nto factual knowledge prediction. Rather than exam-\nining only the model outputs, we provide an open-\nthe-black-box analysis for the knowledge neurons\nin pretrained Transformers.\nAttribution Methods In order to open the black\nboxes of deep learning models, attribution meth-\nods aim to attribute the model output to input fea-\ntures using different measures. The product of\nthe gradients (of the output with respect to input\nfeatures) and feature values is a reasonable base-\nline (Baehrens et al., 2010; Simonyan et al., 2014).\nBesides, a set of attribution methods (Shrikumar\net al., 2017; Binder et al., 2016; Zeiler and Fergus,\n2014; Springenberg et al., 2015) back-propagate\nthe Ô¨Ånal output to input features. However, as\nstated by Sundararajan et al. (2017), none of these\nmethods can simultaneously satisfy sensitivity and\nimplementation invariance, two fundamental ax-\nioms. Taking the axioms as guidance, Sundarara-\njan et al. (2017) propose the integrated gradient\nmethod. Our knowledge attribution method is built\nupon integrated gradients.\nAnalysis of Transformer As one of the most\npopular and effective NLP architectures, Trans-\nformer (Vaswani et al., 2017) has attracted ex-\ntensive studies. Most previous work focuses on\nthe self-attention module (V oita et al., 2019; Clark\net al., 2019; Vig and Belinkov, 2019; Hao et al.,\n2021). Recently, Wu et al. (2019) and Dong et al.\n(2021) have pointed out that the feed-forward net-\nwork module also matters to Transformer. Geva\net al. (2020) attempt to connect feed-forward net-\nworks with key-value memories by qualitative anal-\nysis. In this paper, we identify and analyze knowl-\nedge neurons in feed-forward networks for given\nfactual knowledge. Moreover, we present how to\nleverage knowledge neurons to explicitly edit fac-\ntual knowledge stored in pretrained Transformers.\n7 Conclusion and Future Directions\nWe propose an attribution method to identify knowl-\nedge neurons that express factual knowledge in pre-\ntrained Transformers. We Ô¨Ånd that suppressing or\namplifying the activation of knowledge neurons\ncan accordingly affect the strength of knowledge\nexpression. Moreover, quantitative and qualitative\nanalysis on open-domain texts shows that knowl-\nedge neurons tend to be activated by the corre-\nsponding knowledge-expressing prompts. In addi-\ntion, we present two preliminary case studies that\nattempt to utilize knowledge neurons to update or\nerase knowledge in pretrained Transformers.\nDespite the effectiveness of identifying knowl-\nedge neurons, our current studies still have limita-\ntions. First, we examine knowledge neurons based\non the Ô¨Åll-in-the-blank cloze task, while knowl-\nedge can be expressed in a more implicit way. It is\nan open question whether Transformer can utilize\nstored knowledge in a generalized way, such as for\nreasoning. The interactions between knowledge\nneurons also remain under explored. Second, we\nfocus on factual knowledge for ease of evaluation,\neven though our method is also applicable for other\ntypes of knowledge. Third, we use the single-word\nblank in cloze queries for simplicity, which requires\nmulti-word extensions (Jiang et al., 2020a). Be-\nsides, an interesting future direction is to Ô¨Ågure out\nhow knowledge neurons work in multilingual pre-\ntrained Transformers (Conneau and Lample, 2019;\nConneau et al., 2020; Chi et al., 2021).\n8500\n8 Acknowledgement\nDamai Dai, Zhifang Sui, and Baobao Chang are\nsupported by the National Key Research and De-\nvelopment Program of China 2020AAA0106701\nand NSFC project U19A2065.\nReferences\nDavid Baehrens, Timon Schroeter, Stefan Harmel-\ning, Motoaki Kawanabe, Katja Hansen, and Klaus-\nRobert M√ºller. 2010. How to explain individual clas-\nsiÔ¨Åcation decisions. J. Mach. Learn. Res., 11:1803‚Äì\n1831.\nHangbo Bao, Li Dong, Furu Wei, Wenhui Wang, Nan\nYang, Xiaodong Liu, Yu Wang, Jianfeng Gao, Song-\nhao Piao, Ming Zhou, and Hsiao-Wuen Hon. 2020.\nUnilmv2: Pseudo-masked language models for uni-\nÔ¨Åed language model pre-training. In Proceedings\nof the 37th International Conference on Machine\nLearning, ICML 2020 , volume 119 of Proceed-\nings of Machine Learning Research, pages 642‚Äì652.\nPMLR.\nAlexander Binder, Gr√©goire Montavon, Sebastian\nLapuschkin, Klaus-Robert M√ºller, and Wojciech\nSamek. 2016. Layer-wise relevance propagation for\nneural networks with local renormalization layers.\nIn Proceedings of the 25th International Conference\non ArtiÔ¨Åcial Neural Networks, ICANN 2016, volume\n9887 of Lecture Notes in Computer Science , pages\n63‚Äì71. Springer.\nAntoine Bosselut, Hannah Rashkin, Maarten Sap, Chai-\ntanya Malaviya, Asli Celikyilmaz, and Yejin Choi.\n2019. COMET: commonsense transformers for au-\ntomatic knowledge graph construction. In Proceed-\nings of the 57th Conference of the Association for\nComputational Linguistics, ACL 2019 , pages 4762‚Äì\n4779. Association for Computational Linguistics.\nZewen Chi, Li Dong, Furu Wei, Nan Yang, Saksham\nSinghal, Wenhui Wang, Xia Song, Xian-Ling Mao,\nHeyan Huang, and Ming Zhou. 2021. InfoXLM: An\ninformation-theoretic framework for cross-lingual\nlanguage model pre-training. In Proceedings of the\n2021 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies, pages 3576‚Äì3588, On-\nline. Association for Computational Linguistics.\nKevin Clark, Urvashi Khandelwal, Omer Levy, and\nChristopher D. Manning. 2019. What does BERT\nlook at? an analysis of BERT‚Äôs attention. In Pro-\nceedings of the 2019 ACL Workshop BlackboxNLP:\nAnalyzing and Interpreting Neural Networks for\nNLP, pages 276‚Äì286, Florence, Italy. Association\nfor Computational Linguistics.\nKevin Clark, Minh-Thang Luong, Quoc V . Le, and\nChristopher D. Manning. 2020. ELECTRA: pre-\ntraining text encoders as discriminators rather than\ngenerators. In 8th International Conference on\nLearning Representations, ICLR 2020 . OpenRe-\nview.net.\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzm√°n, Edouard Grave, Myle Ott, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2020. Unsupervised\ncross-lingual representation learning at scale. In\nProceedings of the 58th Annual Meeting of the As-\nsociation for Computational Linguistics, ACL 2020 ,\npages 8440‚Äì8451. Association for Computational\nLinguistics.\nAlexis Conneau and Guillaume Lample. 2019. Cross-\nlingual language model pretraining. In Advances in\nNeural Information Processing Systems 32: Annual\nConference on Neural Information Processing Sys-\ntems 2019, NeurIPS 2019, pages 7057‚Äì7067.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, NAACL-HLT 2019, Volume 1 (Long\nand Short Papers) , pages 4171‚Äì4186. Association\nfor Computational Linguistics.\nLi Dong, Nan Yang, Wenhui Wang, Furu Wei, Xi-\naodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou,\nand Hsiao-Wuen Hon. 2019. UniÔ¨Åed language\nmodel pre-training for natural language understand-\ning and generation. In Advances in Neural Infor-\nmation Processing Systems 32: Annual Conference\non Neural Information Processing Systems 2019,\nNeurIPS 2019, pages 13042‚Äì13054.\nYihe Dong, Jean-Baptiste Cordonnier, and Andreas\nLoukas. 2021. Attention is not all you need: Pure\nattention loses rank doubly exponentially with depth.\nCoRR, abs/2103.03404.\nYanai Elazar, Nora Kassner, Shauli Ravfogel, Ab-\nhilasha Ravichander, Eduard H. Hovy, Hinrich\nSch√ºtze, and Yoav Goldberg. 2021. Measuring and\nimproving consistency in pretrained language mod-\nels. CoRR, abs/2102.01017.\nHady ElSahar, Pavlos V ougiouklis, Arslen Remaci,\nChristophe Gravier, Jonathon S. Hare, Fr√©d√©rique\nLaforest, and Elena Simperl. 2018. T-rex: A large\nscale alignment of natural language with knowledge\nbase triples. In Proceedings of the Eleventh Interna-\ntional Conference on Language Resources and Eval-\nuation, LREC 2018. European Language Resources\nAssociation (ELRA).\nMor Geva, Roei Schuster, Jonathan Berant, and Omer\nLevy. 2020. Transformer feed-forward layers are\nkey-value memories. CoRR, abs/2012.14913.\nYaru Hao, Li Dong, Furu Wei, and Ke Xu. 2021. Self-\nattention attribution: Interpreting information inter-\nactions inside transformer. In The Thirty-Fifth AAAI\nConference on ArtiÔ¨Åcial Intelligence. AAAI Press.\n8501\nDan Hendrycks and Kevin Gimpel. 2016. Gaussian er-\nror linear units (gelus).\nZhengbao Jiang, Antonios Anastasopoulos, Jun Araki,\nHaibo Ding, and Graham Neubig. 2020a. X-\nFACTR: multilingual factual knowledge retrieval\nfrom pretrained language models. In Proceedings\nof the 2020 Conference on Empirical Methods in\nNatural Language Processing, EMNLP 2020, pages\n5943‚Äì5959. Association for Computational Linguis-\ntics.\nZhengbao Jiang, Frank F. Xu, Jun Araki, and Graham\nNeubig. 2020b. How can we know what language\nmodels know? Transactions of the Association for\nComputational Linguistics, 8:423‚Äì438.\nOlga Kovaleva, Alexey Romanov, Anna Rogers, and\nAnna Rumshisky. 2019. Revealing the dark secrets\nof BERT. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP), pages\n4365‚Äì4374, Hong Kong, China. Association for\nComputational Linguistics.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized BERT pretraining ap-\nproach. CoRR, abs/1907.11692.\nMike Mintz, Steven Bills, Rion Snow, and Daniel Ju-\nrafsky. 2009. Distant supervision for relation extrac-\ntion without labeled data. In ACL 2009, Proceedings\nof the 47th Annual Meeting of the Association for\nComputational Linguistics and the 4th International\nJoint Conference on Natural Language Processing\nof the AFNLP , pages 1003‚Äì1011. The Association\nfor Computer Linguistics.\nFabio Petroni, Tim Rockt√§schel, Sebastian Riedel,\nPatrick S. H. Lewis, Anton Bakhtin, Yuxiang Wu,\nand Alexander H. Miller. 2019. Language mod-\nels as knowledge bases? In Proceedings of the\n2019 Conference on Empirical Methods in Natu-\nral Language Processing and the 9th International\nJoint Conference on Natural Language Processing,\nEMNLP-IJCNLP 2019, pages 2463‚Äì2473. Associa-\ntion for Computational Linguistics.\nAdam Roberts, Colin Raffel, and Noam Shazeer. 2020.\nHow much knowledge can you pack into the param-\neters of a language model? In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing, EMNLP 2020 , pages 5418‚Äì\n5426. Association for Computational Linguistics.\nAvanti Shrikumar, Peyton Greenside, and Anshul Kun-\ndaje. 2017. Learning important features through\npropagating activation differences. In Proceedings\nof the 34th International Conference on Machine\nLearning, ICML 2017 , volume 70 of Proceedings\nof Machine Learning Research , pages 3145‚Äì3153.\nPMLR.\nKaren Simonyan, Andrea Vedaldi, and Andrew Zisser-\nman. 2014. Deep inside convolutional networks: Vi-\nsualising image classiÔ¨Åcation models and saliency\nmaps. In 2nd International Conference on Learning\nRepresentations, ICLR 2014.\nJost Tobias Springenberg, Alexey Dosovitskiy, Thomas\nBrox, and Martin A. Riedmiller. 2015. Striving for\nsimplicity: The all convolutional net. In 3rd Inter-\nnational Conference on Learning Representations,\nICLR 2015.\nMukund Sundararajan, Ankur Taly, and Qiqi Yan.\n2017. Axiomatic attribution for deep networks. In\nProceedings of the 34th International Conference\non Machine Learning, ICML 2017 , volume 70 of\nProceedings of Machine Learning Research , pages\n3319‚Äì3328. PMLR.\nIan Tenney, Dipanjan Das, and Ellie Pavlick. 2019.\nBERT rediscovers the classical NLP pipeline. In\nProceedings of the 57th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 4593‚Äì\n4601, Florence, Italy. Association for Computational\nLinguistics.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems 30: Annual Conference on Neural\nInformation Processing Systems 2017 , pages 5998‚Äì\n6008.\nJesse Vig and Yonatan Belinkov. 2019. Analyzing\nthe structure of attention in a transformer language\nmodel. In Proceedings of the 2019 ACL Workshop\nBlackboxNLP: Analyzing and Interpreting Neural\nNetworks for NLP, pages 63‚Äì76, Florence, Italy. As-\nsociation for Computational Linguistics.\nElena V oita, David Talbot, Fedor Moiseev, Rico Sen-\nnrich, and Ivan Titov. 2019. Analyzing multi-head\nself-attention: Specialized heads do the heavy lift-\ning, the rest can be pruned. In Proceedings of the\n57th Conference of the Association for Computa-\ntional Linguistics, ACL 2019, pages 5797‚Äì5808. As-\nsociation for Computational Linguistics.\nFelix Wu, Angela Fan, Alexei Baevski, Yann N.\nDauphin, and Michael Auli. 2019. Pay less atten-\ntion with lightweight and dynamic convolutions. In\n7th International Conference on Learning Represen-\ntations, ICLR 2019. OpenReview.net.\nMatthew D. Zeiler and Rob Fergus. 2014. Visualiz-\ning and understanding convolutional networks. In\nProceedings of the 13th European Conference on\nComputer Vision, ECCV 2014, volume 8689 of Lec-\nture Notes in Computer Science , pages 818‚Äì833.\nSpringer.\n8502",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7576466202735901
    },
    {
      "name": "Transformer",
      "score": 0.7164371609687805
    },
    {
      "name": "Leverage (statistics)",
      "score": 0.6634392142295837
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5307495594024658
    },
    {
      "name": "Blank",
      "score": 0.5072247982025146
    },
    {
      "name": "Knowledge extraction",
      "score": 0.4809124171733856
    },
    {
      "name": "Natural language processing",
      "score": 0.48045796155929565
    },
    {
      "name": "Commonsense knowledge",
      "score": 0.478143572807312
    },
    {
      "name": "Machine learning",
      "score": 0.3542857766151428
    },
    {
      "name": "Engineering",
      "score": 0.07342806458473206
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Mechanical engineering",
      "score": 0.0
    }
  ]
}