{
  "title": "Probing for Bridging Inference in Transformer Language Models",
  "url": "https://openalex.org/W3167831019",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2741534805",
      "name": "Onkar Pandit",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2185188078",
      "name": "Yufang Hou",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2998696444",
    "https://openalex.org/W2970120757",
    "https://openalex.org/W2891688279",
    "https://openalex.org/W3034928924",
    "https://openalex.org/W2970476646",
    "https://openalex.org/W2972324944",
    "https://openalex.org/W2991265431",
    "https://openalex.org/W3034685497",
    "https://openalex.org/W2985797697",
    "https://openalex.org/W2948947170",
    "https://openalex.org/W3111372685",
    "https://openalex.org/W2910243263",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W2934842096",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2105067765",
    "https://openalex.org/W2835897745",
    "https://openalex.org/W2251489622",
    "https://openalex.org/W3117935238",
    "https://openalex.org/W3098824823",
    "https://openalex.org/W3015553975",
    "https://openalex.org/W4288631803",
    "https://openalex.org/W2963189761"
  ],
  "abstract": "We probe pre-trained transformer language models for bridging inference. We first investigate individual attention heads in BERT and observe that attention heads at higher layers prominently focus on bridging relations in-comparison with the lower and middle layers, also, few specific attention heads concentrate consistently on bridging. More importantly, we consider language models as a whole in our second approach where bridging anaphora resolution is formulated as a masked token prediction task (Of-Cloze test). Our formulation produces optimistic results without any fine-tuning, which indicates that pre-trained language models substantially capture bridging inference. Our further investigation shows that the distance between anaphor-antecedent and the context provided to language models play an important role in the inference.",
  "full_text": "Proceedings of the 2021 Conference of the North American Chapter of the\nAssociation for Computational Linguistics: Human Language Technologies, pages 4153–4163\nJune 6–11, 2021. ©2021 Association for Computational Linguistics\n4153\nProbing for Bridging Inference in Transformer Language Models\nOnkar Pandit\nUniversity of Lille, INRIA Lille,\nCNRS, Centrale Lille,UMR 9189-CRIStAL,\nF-59000, Lille, France\nonkar.pandit@inria.fr\nYufang Hou\nIBM Research Europe\nDublin, Ireland\nyhou@ie.ibm.com\nAbstract\nWe probe pre-trained transformer language\nmodels for bridging inference. We ﬁrst in-\nvestigate individual attention heads in BERT\nand observe that attention heads at higher lay-\ners prominently focus on bridging relations in-\ncomparison with the lower and middle layers,\nalso, few speciﬁc attention heads concentrate\nconsistently on bridging. More importantly,\nwe consider language models as a whole in our\nsecond approach where bridging anaphora res-\nolution is formulated as a masked token pre-\ndiction task ( Of-Cloze test). Our formulation\nproduces optimistic results without any ﬁne-\ntuning, which indicates that pre-trained lan-\nguage models substantially capture bridging\ninference. Our further investigation shows that\nthe distance between anaphor-antecedent and\nthe context provided to language models play\nan important role in the inference.\n1 Introduction\nBridging inference involves connecting conceptu-\nally related discourse entities − anaphors and an-\ntecedents (Clark, 1975). A bridging anaphor shares\nnon-identical relation with its antecedent and de-\npends on it for complete interpretation. This differs\nfrom coreference resolution which links mentions\nthat refer to the same entity (i.e., mentions in the\nsame entity share identical relations). Consider the\nfollowing example −\n“In Poland’srapid shift from socialism to an\nundeﬁned alternative, environmental issues have\nbecome a cutting edge of broader movements to\nrestructure the economy, cut cumbersome bureau-\ncracies , and democratize local politics.”\nBridging inference connects the anaphor “ the\neconomy” and its antecedent “ Poland” and de-\nduces that “the economy” speciﬁcally refers to “the\neconomy of Poland”.\nWe want to investigate if the pre-trained trans-\nformer language models capture any bridging in-\nference information. Recently there has been an in-\ncreasing interest in analyzing pre-trained language\nmodels’ ability at capturing syntactic information\n(Clark et al., 2019), semantic information (Koval-\neva et al., 2019), as well as commonsense knowl-\nedge (Talmor et al., 2020). There are also a few\nstudies focusing on probing coreference informa-\ntion in pre-tained language models (Clark et al.,\n2019; Sorodoc et al., 2020). So far, there has no\nwork on analyzing bridging, which is an important\ntype of entity referential information. We try to ﬁll\nthis gap in our work.\nWe employ two different but complementary ap-\nproaches for the probing of pre-trained transformer\nlanguage models for bridging inference. In the ﬁrst\napproach (Section 4), we investigate the core in-\nternal part of transformer models – self-attention\nheads in vanilla BERT (Devlin et al., 2019). We\nlook at the attention heads of each layer separately\nand measure the proportion of attention paid from\nanaphor to antecedent and vice versa. This captures\nthe magnitude of bridging signal corresponding to\neach attention head. We observed that attention\nheads of higher layers are more active at attend-\ning at bridging relations as well as some of the\nindividual attention heads prominently look at the\nbridging inference information.\nIn the second approach (Section 5), we treat pre-\ntrained transformer language models as a black\nbox and form bridging inference as a masked to-\nken prediction task. This formulation takes into\nconsideration the whole architecture and weights\nof the model rather than concentrating on individ-\nual layers or attention heads, thus, complementing\nour ﬁrst approach where we looked at the indi-\nvidual parts of the transformer model. For each\nbridging anaphor, we provide input as “ context\nanaphor of [MASK]” to language models and get\nthe scores of different antecedent candidates for\nmask tokens. We then select the highest scoring\ncandidate as the predicted antecedent. Surprisingly,\nthe best variation of this approach produces a high\n4154\naccuracy score of 28.05% for bridging anaphora\nresolution on ISNotes (Markert et al., 2012) data\nwithout any task-speciﬁc ﬁne-tuning of the model.\nOn the same corpus, the current state-of-the-art\nbridging anaphora resolution model BARQA (Hou,\n2020a) achieves an accuracy of 50.08%, while a\nsolid mention-entity pairwise model with carefully\ncrafted semantic features (Hou et al., 2013) pro-\nduces an accuracy score of 36.35%. This shows\nthat substantial bridging information is captured in\nthe pre-trained transformer language models.\nBridging inference requires both commonsense\nworld knowledge as well as context-dependent text\nunderstanding. The above-mentioned ﬁll-in-the-\ngap formulation for the antecedent selection task\nis ﬂexible enough to easily explore the role of dif-\nferent types of context for bridging inference. Our\nanalysis shows that pre-trained language models\ncapture bridging inference substantially however\nthe overall performance depends on the context pro-\nvided to the model. It is also observed that bigger\nlanguage models are more accurate at capturing\nbridging information.\nThis work has two main contributions. First,\nwe thoroughly investigate bridging information en-\ncoded in pre-trained language models using two\nprobing approaches (attention heads analysis and\nﬁll-in-the-gap). Second, we provide a deeper under-\nstanding of the bridging referential capabilities in\nthe current pre-trained language models. Our exper-\nimental code is available at https://github.\ncom/oapandit/probBertForbridging.\n2 Related Work\nEntity Referential Probing. Previous studies on\nentity referential probing mainly focus on corefer-\nence. Clark et al. (2019) showed that certain atten-\ntion heads in pre-trained BERT correspond well to\nthe linguistic knowledge of coreference. Particu-\nlarly, the authors found that one of BERT’s atten-\ntion heads achieves reasonable coreference resolu-\ntion performance compared to a string-matching\nbaseline and performs close to a simple rule-based\nsystem. Sorodoc et al. (2020) investigated the fac-\ntors affecting pronoun resolution in transformer\narchitectures. They found that transformer-based\nlanguage models capture both grammatical proper-\nties and semantico-referential information for pro-\nnoun resolution. Recently, Hou (2020b) analyzed\nthe attention patterns of a ﬁne-tuned BERT model\nfor information status (IS) classiﬁcation and found\nthat the model pays more attention to signals that\ncorrespond well to the linguistic features of each\nIS class. For instance, the model learns to focus\non a few premodiﬁers (e.g., “more”, “other”, and\n“higher”) that indicate the comparison between two\nentities. In this work, we focus on probing bridging,\nwhich is a more challenging entity referential rela-\ntion and one of the oldest topics in computational\nlinguistics (Clark, 1975; Bos et al., 1995; Asher\nand Lascarides, 1998).\nAttention Analysis. Recently there has been an\nincreasing interest in analyzing attention heads\nin transformer language models. Although some\nresearchers argue that attention does not explain\nmodel predictions (Jain and Wallace, 2019), analyz-\ning attention weights still can help us to understand\ninformation learned by the models (Clark et al.,\n2019). Researchers have found that some BERT\nheads specialize in certain types of syntactic rela-\ntions (Htut et al., 2019). Kovaleva et al. (2019)\nreported that pre-trained BERT’s heads encode in-\nformation correlated to FrameNet’s relations be-\ntween frame-evoking lexical units (predicates, such\nas “address”) and core frame elements (such as “is-\nsues”). In our work, we try to analyze whether cer-\ntain attention heads in a pre-trained BERT model\ncapture bridging relations between entities in an\ninput text.\nFill-in-the-gap Probing. One of the popular ap-\nproaches to probe pre-trained language models is\nﬁll-in-the-gap probing, in which the researchers\nhave constructed various probing datasets to test\na model’s ability on different aspects. Goldberg\n(2019) found that BERT considers subject-verb\nagreement when performing the cloze task. Petroni\net al. (2019) reported that factual knowledge can be\nrecovered surprisingly well from pre-trained lan-\nguage models. For instance, “JDK is developed\nby [Oracle]”. Similarly, we apply ﬁll-in-the-gap to\nprobe bridging by formulating bridging anaphora\nresolution as a of-Cloze test.\nCommonsense Knowledge Probing. A lot of\nwork has been carried out to analyze various types\nof commonsense knowledge encoded in trans-\nformer language models. Talmor et al. (2020) con-\nstructed a set of probing datasets and test whether\nspeciﬁc reasoning skills are captured by pre-trained\nlanguage models, such as age comparison and\nantonym negation. Da and Kasai (2019) found\nthat pre-trained BERT failed to encode some ab-\n4155\nstract attributes of objects, as well as visual and\nperceptual properties that are likely to be assumed\nrather than mentioned.\nIn our work, we focus on investigating the ef-\nfect of context on bridging inference using a well-\nestablished task on bridging resolution. We ex-\ntensively analyze the impacts of different contexts\nfor bridging anaphora resolution. We found that\na pre-trained BERT model achieves reasonable re-\nsults for bridging anaphora resolution by using the\nword “of” as the additional context. This indicates\nthat pre-trained language models capture certain\ncommonsense world knowledge for bridging.\n3 Methodology\nIn this paper, we mainly investigate the following\nresearch questions:\n• How important are the self-attention patterns\nof different heads for bridging anaphora reso-\nlution?\n• Whether pre-trained LMs capture information\nbeneﬁcial for resolving bridging anaphora in\nEnglish?\n• How does distance between anaphor-\nantecedent and context inﬂuence pre-trained\nlanguage models for bridging inference?\nWe designed a series of experiments to answer\nthese questions which will be detailed in the com-\ning sections. In these experiments, we used Py-\nTorch (Wolf et al., 2020) implementation of BERT-\nbase-cased, BERT-large-cased, ROBERTA-base\nand ROBERTA-large pre-trained transformer lan-\nguage models with the standard number of layers,\nattention heads, and parameters. In the attention\nhead-based experiments, we have limited our inves-\ntigation only to the BERT-base-cased model as it\nis relatively smaller compared to other models and\nﬁndings of this model can be generalized to other\nmodels as well.\nProbing Dataset We used ISNotes (Markert\net al., 2012) dataset for all experiments. We\nchoose this corpus because it contains “unrestricted\nanaphoric referential bridging” annotations among\nall available English bridging corpora (Roesiger\net al., 2018) which covers a wide range of dif-\nferent relations. ISNotes contains 663 bridging\nanaphors but only 622 anaphors have noun phrase\nFigure 1: Bridging signals with BERT-base-cased model with\nonly anaphor and antecedent sentences provided. Bridging sig-\nnals from anaphor to antecedent are shown in the ﬁrst heatmap\nand the reverse signals in the second. In both heatmaps, the\nx-axis shows the attention head number and the y-axis shows\nthe layer number.\nantecedents.1 In our experiments, we only con-\nsider these 622 anaphors for investigation. For any\nanaphor, the predicted antecedent is selected from\nthe set of antecedent candidates. This set is formed\nby considering all the mentions which occur be-\nfore the anaphor. We obtained the candidate set for\neach anaphor by considering “gold mentions” an-\nnotated in ISNotes. Further, we observed that only\n531 anaphors have antecedents in either previous 2\nsentences from the anaphor or the ﬁrst sentence of\nthe document. Therefore, in the experiments when\nantecedent candidates are considered from the win-\ndow of previous two sentences plus the document’s\nﬁrst sentence, only 531 anaphors are considered.\nIn all the experiments, accuracy is measured as the\nratio between correctly linked anaphors to the total\nanaphors used in that particular experiment (not\ntotal 663 anaphors).\n4 Probing Individual Attention Heads\nAttention heads are an important part of trans-\nformer based language models. Each layer consists\nof a certain number of attention heads depending\non the model design and each attention head as-\nsigns different attention weight from every token\nof the input sentence to all the tokens. In our ap-\nproach, we measure the attention ﬂow between\nanaphors and antecedents for each attention head\nseparately. In this experiment we investigate all the\nattention heads of every layer one-by-one. Speciﬁ-\ncally, the BERT-base-cased model used for probing\ncontains 12 layers and 12 attention heads at each\nlayer. Therefore, we investigate 144 attention heads\nfor their ability to capture bridging signals.\n1A small number of bridging antecedents in ISNotes are\nrepresented by verbs or clauses.\n4156\n(a) Anaphor-antecedent sent. distance 0\n(b) Anaphor-antecedent sent. distance 1\n(c) Anaphor-antecedent sent. distance 2\n(d) Anaphor-antecedent sent. distance between 3 and 5\n(e) Anaphor-antecedent sent. distance between 6 and 10\nFigure 2: Bridging signals in the pre-trained BERT-base-\ncased model with the input including all the sentences between\nan anaphor and its antecedent. Different heatmaps are shown\ndepending on the sentence distance between anaphor and an-\ntecedent. The ﬁrst heatmap in each row shows the signals from\nanaphor to antecedent and the second one from antecedent to\nanaphor. All the heatmaps present the attention heads on the\nx-axis and the layer numbers on the y-axis.\n4.1 Bridging Signal\nWe look for two distinct bridging signals − one\nfrom anaphor to antecedent and other from an-\ntecedent to anaphor. The bridging signal from\nanaphor to antecedent is calculated as the ratio\nof the attention weight assigned to antecedent and\nthe total cumulative attention paid to all the words\nin the input. Similarly, the bridging signal from\nantecedent to anaphor is found in a reverse way.\nThere are two difﬁculties while getting the at-\ntention weights corresponding to anaphor or an-\ntecedent. First, the anaphor or antecedent can be a\nphrase with multiple words. So, we need to decide\nhow to aggregate words’ weights. For this, we de-\ncide to consider the semantic heads of both anaphor\nand antecedent, and get the attention weight be-\ntween them. For instance, the semantic head for\n“the political value of imposing sanction against\nSouth Africa” is “value”. Most of the time, a se-\nmantic head of an NP is its syntactic head word as\nin the above example. However, for coordinated\nNPs such as “ the courts and the justice depart-\nment”, the syntactic head will be “and” which does\nnot reﬂect this NP’s semantic meaning. In such\ncases, we use the head word of the ﬁrst element as\nits semantic head (i.e., courts).\nSecondly, transformer language models use the\nwordpiece tokenizer to break words further. This\nproduces multiple tokens from a single word if\nthis word is absent from the language model’s dic-\ntionary. Here, for a bridging anaphor a and its\nhead word ah, we ﬁrst calculate the average weight\nof all word piece tokens of the head word ah to\nother words. From these weights, we consider the\nweight from the anaphor a to its antecedent (w1).\nSubsequently, we add weights from ah to all other\ntokens present in the sentence and normalize the\nweight using sentence length ( w2). Note that we\nneglected weights assigned to special tokens (i.e.\n[CLS], [SEP], [PAD], etc.,) while calculating both\nweights as previous work suggest that these spe-\ncial tokens are heavily attended in deep heads and\nmight be used as a no-op for attention heads (Clark\net al., 2019). Finally, bridging signal is measured as\nthe ratio between w1 and w2 as mentioned earlier.\n4.2 Experimental Setup\nWe provide sentences containing a bridging\nanaphor (Ana) and its antecedent ( Ante) to the\npre-trained BERT model as a single sentence with-\nout the “[SEP]” token in-between. However, an\n4157\nanaphor and its antecedent do not always lie in the\nsame or adjacent sentence(s). Therefore, we design\ntwo different experiments. In the ﬁrst setup, we\nprovide the model with only those sentences which\ncontain Ana and Ante while ignoring all the other\nsentences in-between. This setting is a bit unnatural\nas we are not following the original discourse nar-\nration. In the second setup, we provide the model\nwith sentences which contain Ana and Ante as\nwell as all the other sentences between Ana and\nAnte. Note that in both experiments we add mark-\ners to denote the anaphor and its antecedent in order\nto get exact corresponding attention weights.\n4.3 Results With Only Ana-Ante Sentences\nFor the input of only sentences containing anaphors\nand antecedents, we plot the bridging signals cor-\nresponding to each attention head separately (see\nthe heatmaps in Figure 1). The left heatmap shows\nthe signals from anaphors to antecedents and the\nright one shows the signals from antecedents to\nanaphors. Both heatmaps are based on the pre-\ntrained BERT-base-cased model. The x-axis repre-\nsents the number of attention heads from 1-12 and\nthe y-axis represents the number of layers from 1-\n12. The darker shade of the color indicates stronger\nbridging signals and brighter color indicates a weak\nsignal.\nThe plot shows that the lower layers capture\nstronger bridging signal in comparison with the\nmiddle layers with an exception at the ﬁrst attention\nhead in the ﬁfth layer. Also, the higher layers pay\nmost attention to bridging relations in comparison\nto the middle and lower layers. The observation is\nconsistent in both directions − from anaphors to\nantecedents and from antecedents to anaphors.\n4.4 Results With All Sentences\nAs stated earlier, for an anaphor, the antecedent\ncan lie in the same sentence or any previous sen-\ntence. This demands a separate investigation of\nbridging signals depending on the distance (mea-\nsured in terms of sentences) between anaphors and\nantecedents. Therefore, we plot bridging signals\ncaptured by all attention heads depending on the\ndistance between anaphors and antecedents in Fig-\nure 2.\nThe ﬁrst plot shows the signals between\nanaphors and antecedents where the distance be-\ntween them is 0 (i.e., they occur in the same sen-\ntence). The second and the third plots show the\nbridging signals between anaphors and antecedents\nin which the anaphor-antecedent sentence distance\nis 1 and 2, respectively.\nIn ISNotes, 77% of anaphors have antecedents\noccurring in the same or up to two sentences prior\nto the anaphor. The remaining anaphors have\ndistant antecedents and each distance group only\ncontains a small number of anaphor-antecedent\npairs. Therefore, we divide the remaining anaphors\ninto two coarse groups. The plots in Figure 2d\nand Figure 2e are plotted by combining anaphor-\nantecedent pairs which are apart by 3 to 5 sentences\nand 6 to 10 sentences, respectively. Note that we\ncould not plot attention signals for bridging pairs\nwith sentence distance longer than 10 sentences\nbecause of the limitation of the input size in BERT.\nWe observe that, the patterns which are visible\nwith only anaphor-antecedent sentences as the in-\nput (Section 4.3) are consistent even with consid-\nering all the sentences between anaphors and an-\ntecedents. It is clear that higher layers attend more\nto bridging relations in comparison with lower and\nmiddle layers. Also, the lower layers fail to capture\nbridging signal as the distance between anaphors\nand antecedents increases. Attention weights as-\nsigned by certain attention heads (5:1, 9:12, 11:3\nand 12:2-4) are fairly consistent. One more im-\nportant thing to observe is that as the distance be-\ntween anaphors and antecedents increases the over-\nall bridging signal decreases. This can be observed\nby looking at all the heatmaps in Figure 2 as the\nheatmaps with lower distances are on the darker\nside.\n4.5 Discussion\nBased on the results from the previous two experi-\nments, we observed that in the pre-trained BERT\nmodel, the higher layers pay more attention to\nbridging relations in comparison with the middle\nand the lower layers. This observation is in-line\nwith other studies in which the authors found that\nsimple surface features were captured in the lower\nlayers and complex phenomenons like coreference\nwere captured in the higher layers (Jawahar et al.,\n2019). Also, the overall attention decreases with\nthe increase in the distance between anaphors and\nantecedents.\nWe also observed that there are some prominent\nattention heads which consistently capture bridging\nrelations (5:1, 9:12, 11:3 and 12:2-4). In order to\ncheck which bridging relations are easier or harder\nfor these prominent attention heads to capture, we\n4158\nEasy Bridging Relations\nThe move will make the drug available free of charge for a time to children with the disease and\nsymptoms of advanced infection.\nLast year, when the rising Orange River threatened to swamp the course, the same engineers\nwho are pushing back the Atlantic rushed to build a wall to hold back the ﬂood.\nAt age eight, Josephine Baker was sent by her mother to a white woman’s houseto do chores in\nexchange for meals and a place to sleep – a place in the basement with the coal\nDifﬁcult Bridging Relations\nIn addition, Delmed, which makes and sells a dialysis solution used in treating kidney diseases, said\nnegotiations about pricing had collapsed between it and a major distributor, National Medical Care\nInc. Delmed said Robert S. Ehrlich resigned as chairman, president and chief executive.\nMr. Ehrlich will continue as a director and a consultant.\nThe night the Germans occupied all of France, Baker performed in Casablanca.\nThe Free French wore black arm bands, and when she sang “J’ai deux amours” they wept.\nMs.Rose is best on the early years and World War II.\nIn Geneva, however, they supported Iran’s proposal because it would have left the Saudi percentage\nof the OPEC total intact, and increased actual Saudi volume to nearly 5.3M barrels daily from 5M.\nSome of the proposed modiﬁcations since, however, call on Saudi Arabia to “give back” to the\nproduction-sharing pool a token 23,000 barrels .\nTable 1: Examples of easy and difﬁcult bridging relations for the prominent heads to recognize. Bridging anaphors\nare typed in boldface, antecedents in underscore.\nfurther investigated qualitatively to identify bridg-\ning pairs that get higher or lower attentions in these\nattention heads. Speciﬁcally, we consider pairs\nwhich have the bridging signal ratio (deﬁned in\nSection 4.1) more than 70% as easier bridging rela-\ntions for BERT heads to recognize. If the bridging\nsignal ratio is less than 10%, then the correspond-\ning bridging relation is considered as difﬁcult for\nBERT heads to identify. We list a few easy and\ndifﬁcult examples in Table 1. In general, we ob-\nserve that semantically closer pairs are easy for\nprominent heads to identify (e.g., house-basement,\ndisease-infection). On the other hand, pairs that are\ndistant and require more context-dependent as well\nas common-sense knowledge inference are difﬁcult\nfor the prominent heads to recognize.\n5 Fill-in-the-gap Probing: LMs as\nBridging Anaphora Resolvers\nThe transformer-based language models are trained\nwith an objective to predict the masked tokens\ngiven the surrounding context. Thus, they can also\nproduce a score for a word which can be placed at\nthe masked token in a given sentence. We make use\nof this property of the language models and pro-\npose a novel formulation to understand the bridging\nanaphora resolution capacity of the pre-trained lan-\nguage models.\n5.1 Of-Cloze Test\nThe syntactic prepositional structure (X of Y, such\nas “the door of house” or “the chairman of com-\npany”) encodes a variety of bridging relations. Pre-\nvious work has used this property to design fea-\ntures and develop embedding resources for bridg-\ning (Hou et al., 2013; Hou, 2018a,b).\nInspired by this observation, we formulate bridg-\ning anaphora resolution as a cloze task. Specif-\nically, given a bridging anaphor and its context,\nwe insert “of [MASK]” after the head word of the\nanaphor (see Example 1). We then calculate the\nprobability of each candidate to be ﬁlled as the\nmask token. The highest scoring candidate is se-\nlected as the predicted antecedent for the anaphor.\nOne of the advantages of our formulation is that we\ncan easily control the scope of the context for each\nbridging anaphor (e.g., no-context, local context or\nglobal context). This allows us to test the effect of\ndifferent types of context for bridging inference.\n(1) Original context: The survey found that over a\nthree-year period 22% of the ﬁrms said employees\nor owners had been robbed on their way to or\nfrom work or while on the job.Seventeen percent\nreported their customers being robbed.\nCloze test context: The survey found that over a\nthree-year period 22% of the ﬁrms said employees\n4159\nor owners had been robbed on their way to or from\nwork or while on the job. Seventeen percent of\n[MASK] reported their customers being robbed.\n5.2 Experimental Setup\nRecall that in our Of-Cloze test, antecedent candi-\ndates are provided and the highest scoring candi-\ndate is selected as the predicted antecedent. These\ncandidates are formed by considering mentions\nwhich are occuring prior to the anaphor. We design\ntwo different experiment sets based on the scope of\nantecedent candidates and the surrounding context.\nCandidates Scope In the ﬁrst set of experiments,\nwe consider two different sets of antecedent can-\ndidates for an anaphor a. The ﬁrst set contains\nsalient and nearby mentions as antecedent candi-\ndates. Here, mentions only from the ﬁrst sentence\nof the document, previous two sentences preceding\na and the sentence containing a are considered as\ncandidates. This setup follows previous work on\nselecting antecedent candidates (Hou, 2020a). The\nsecond set contains all mentions occurring before\nthe anaphor a from the whole document. The sec-\nond setup of forming antecedent candidates is more\nchallenging than the ﬁrst one because the number\nof candidates increases which makes selecting the\ncorrect antecedent difﬁcult.\nNext, we provide the same context for anaphors\nin both of the experiments described above. We\nconstruct the context c for the bridging anaphor\na. Precisely, c contains the ﬁrst sentence of the\ndocument, the previous two sentences occurring\nbefore a, as well as the sentence containing a. We\nreplace the head of a as “of [MASK]”.\nWe also compare this ﬁll-in-the-gap probing ap-\nproach with the attention heads-based approach for\nresolving bridging anaphors. Speciﬁcally, we use\nthe prominent heads in BERT for identifying bridg-\ning relations from Section 4. Here, we obtained\nattention weights from an anaphor head to all an-\ntecedent candidate heads by adding attentions from\nprominent heads 5:1, 9:12, 11:3, and 12:2-4. Then\nthe highest scoring candidate is predicted as the\nantecedent for the anaphor.\nContext Scope In the second set of experiments,\nwe concentrate on probing the behavior of language\nmodels at capturing bridging relations with differ-\nent contexts. We experiment with the following\nfour settings:\n• a. Only anaphor: in this setup, only the\nanaphor phrase (with “of [MASK]” being in-\nserted after the anaphor’s head word) is given\nas the input to the model.\n• b. Anaphor sentence: the sentence contain-\ning the anaphor is provided. The phrase “of\n[MASK]” is inserted after the head word of\nthe anaphor.\n• c. Ante+Ana sentence: on top of b, the sen-\ntence containing the antecedent is also in-\ncluded in the context.\n• d. More context: on top of b, the ﬁrst sentence\nfrom the document as well as the previous two\nsentences preceding the anaphor are included.\nWithout “of” Context To test the effect of the\nstrong bridging indicating signal “of ”, we further\nexecute another set of experiments. Speciﬁcally,\nWe remove “of” from “anaphorhead of [MASK]”\nand instead, provide “anaphor head [MASK]” for\neach type of the context described above.\nPerturbed Context In this setting, we perturb\nthe context by randomly shufﬂing the words in\nthe context except for the anaphor and antecedent\nphrases for each type of the context mentioned\nabove. Note that we still have the “of ” indicator in\nthis setup.\n5.3 Results and Discussion\n5.3.1 Results on Candidates Scope\nTable 2 shows the accuracy of using only thepromi-\nnent heads and our Of-Cloze test approach for\nbridging anaphora resolution. All experiments are\nbased on the same context (i.e., the sentence con-\ntaining an anaphor, the previous two sentences pre-\nceding the anaphor as well as the ﬁrst sentence\nfrom the document).\nWe ﬁnd that the Of-Cloze probing approach\nachieves higher result in comparison to the promi-\nnent attention head approach (31.64% vs. 20.15%)\nunder the same conditions. One reason might be\nthat although other attention heads do not signiﬁ-\ncantly attend to bridging relations but cumulatively\nthey are effective.\nWe also observe that in the Of-Cloze test, the re-\nsults of using salient/nearby mentions as antecedent\ncandidates are better than choosing antecedents\nfrom all previous mentions (Row (2) vs. Row (3),\nand Row (2) vs. Row (4)). This is because the\nmodel has to choose from a smaller number of can-\ndidates in the ﬁrst case as the average number of\n4160\nAntecedent\nCandidate Scope\nNo.\nAnaphors\nBERT-\nBase\nBERT-\nLarge\nRoBERTa-\nBase\nRoBERTa-\nLarge\nProminent attention heads\n(1) Salient/nearby mentions 531 20.15 - - -\nOf-Cloze Test\n(2) Salient/nearby mentions 531 31.64 33.71 34.08 34.65\n(3) All previous mentions 622 26.36 28.78 27.49 29.90\nOf-Cloze Test: Anaphors with antecedents in the provided contexts\n(4) All previous mentions 531 29.00 30.88 30.32 32.39\nOf-Cloze Test: Anaphors with antecedents outside of the provided contexts\n(5) All previous mentions 91 10.98 16.48 10.98 15.38\nTable 2: Result of selecting antecedents for anaphors with two different probing approaches ( Prominent attention\nheads and Of-Cloze Test) based on the same context. Accuracy is calculated over a different number of anaphors.\nDistance Accuracy\nsalient∗ 38.65\n0 26.92\n1 20.58\n2 17.30\n>2 10.98\nTable 3: Anaphor-antecedent distance-wise accuracy\nwith the BERT-base-cased model. ∗ indicates that the\nantecedent is in the ﬁrst sentence of the document.\nantecedent candidates are only 22 per anaphor as\nopposed to 148 in the later case.\nWe further divide 622 anaphors in Row (3) into\ntwo groups (Row (4) and Row (5) in Table 2) de-\npending on whether the corresponding antecedents\noccur in the provided contexts. It can be seen that\nthe performance is signiﬁcantly better when an-\ntecedents occur in the contexts.\nFinally, when comparing the results of each lan-\nguage model in each row separately, it seems that\nthe bigger models are always better at capturing\nbridging information. In general, the RoBERTa-\nlarge model performs better than other models ex-\ncept when antecedents do not occur in the provided\ncontexts (Row (5)).\nNote that the results in Table 2 are not calcu-\nlated over all 663 anaphors in ISNotes. There-\nfore, if the results are normalized over all anaphors\nthen we get the best result with the RoBERTa-large\nmodel (28.05%), which is reasonably ﬁne in com-\nparison with the state-of-the-art result of 50.08%\n(Hou, 2020a) given that the model is not ﬁne-tuned\nfor the bridging task.\nContext Scope with\n“of”\nwithout\n“of” perturb\nonly anaphor 17.20 5.62 -\nana sent. 22.82 7.71 10.28\nana+ante sent. 27.81 9.61 10.93\nmore context 26.36 12.21 11.41\nTable 4: Accuracy of selecting antecedents with differ-\nent types of context using BERT-of-Cloze Test.\n5.3.2 Results on Ana-Ante Distance\nWe further analyze the results of choosing an-\ntecedents obtained using the BERT-base-cased\nmodel with all previous mentions as the antecedent\ncandidate scope in our Of-Cloze test probing exper-\niment (Row (3) in Table 2) to understand the effect\nof distance between anaphors and antecedents. The\nresults are shown in Table 3.\nIn general, it seems that the accuracy decreases\nas the distance between anaphors and antecedents\nincreases except when antecedents are from the\nﬁrst sentences of the documents. This is related\nto the position bias in news articles from ISNotes.\nNormally globally salient entities are often intro-\nduced in the beginning of a new article and these\nentities are preferred as antecedents.\nThe other reason for the lower results in case\nof antecedents being away for more than two sen-\ntences might be that these antecedents are absent\nfrom the provided context.\n5.3.3 Results on Different Contexts\nThe results of experiments with different types of\ncontext are shown in Table 4. All experiments are\nbased on the BERT-base-cased model with all pre-\n4161\nvious mentions as the antecedent candidate scope.\nWe refer to this model as BERT-Of-Cloze in the\nfollowing discussion.\nIn the ﬁrst column of the table, BERT-Of-Cloze\nachieves an accuracy score of 17.20% with only\nthe anaphor information plus “of [mask]”. We can\nsee that the results improve incrementally with the\naddition of context. More speciﬁcally, the accu-\nracy score improves from 17.20% to 22.82% by\nadding sentences containing anaphors. Adding sen-\ntences which contain antecedents (ana + ante sent.)\nfurther improves the accuracy score to 27.81%. Fi-\nnally, adding more local context and the ﬁrst sen-\ntence leads to an accuracy score of 26.36%. Note\nthat compared to “ana + ante sent.”, “more context”\nrepresents a more realistic scenario in which we do\nnot assume that the antecedent position informa-\ntion is known beforehand. In general, the results in\nthe ﬁrst column of Table 4 indicate that the model\ncan leverage context information when predicting\nantecedents for bridging anaphors.\nResults reduce drastically when “of” is removed\nfrom the “anaphor of [MASK]” phrase (Table 4,\ncolumn:2) from all context scopes. Without this\nindicator, the language model cannot make sense of\ntwo adjacent tokens such as “consultant company”.\nIt is interesting to see that the results reduced\ndrastically as well when we perturb the context\nbetween the anaphor and antecedent (Table 4, last\ncolumn). This establishes the importance of mean-\ningful context for performing bridging inference\neffectively in transformer language models.\n5.4 Error Analysis: Of-Cloze test\nWe analyzed anaphor-antecedent pairs that are\nlinked wrongly by the Of-Cloze formulation and\nobserved some common erros.\nFailure at capturing sophisticated common-\nsense knowledge: We found that the pre-trained\ntransformer language model such as BERT ac-\nquires simple common-sense knowledge, there-\nfore it can link anaphor-antecedent pairs such\nas “sand–dunes” and “principal–school”. But it\nfails at capturing sophisticated knowledge, such\nas “consultant–Delmed (a company)” and “pool–\nOPEC (Organization of petroleum countries) ”.\nThis might be happening because of the rare co-\noccurrences of these pairs in the original text on\nwhich BERT is pre-trained. Also, BERT has inher-\nent limitations at acquiring such structured knowl-\nedge (Park et al., 2020).\nLanguage modelling bias: In our Of-Cloze test\nprobing, we use pre-trained transformer language\nmodels without ﬁne-tuning. As a result, the model\nﬁlls masked tokens that are ﬁt according to the lan-\nguage modeling objective, not for bridging resolu-\ntion. Thus, sometimes, the selected token perfectly\nmakes sense in the single sentence but the choice\nis incorrect in the broader context. Consider the\nexample, “Only 22% of [MASK] supported private\nsecurity patrols [...]”. BERT predicts “police” as\na suitable antecedent that produces a meaningful\nlocal sentence. However, the correct antecedent\nis “correspondents” according to the surrounding\ncontext of this sentence.\nUnsuitable formulation for set-relations: Our\nOf-Cloze formulation produces awkward phrases\nfor some bridging pairs that possess set-relations.\nConsidering a bridging pair − “One man - employ-\nees”, in this case the model should assign high\nscore for the phrase − “One man of employees”.\nBut, as this phrase is quite clumsy, BERT natu-\nrally being a language model assigns low scores\nfor these pairs.\n6 Conclusions\nWe investigated the effectiveness of pre-trained\ntransformer language models in capturing bridg-\ning relation inference by employing two distinct\nbut complementary approaches.\nIn the ﬁrst approach, we probed individual at-\ntention heads in BERT and observed that atten-\ntion heads from higher layers prominently captured\nbridging compared to the middle and lower lay-\ners and some speciﬁc attention heads consistently\nlooked for bridging relation. In our second ap-\nproach, we considered using language models for\nbridging anaphora resolution by formulating the\ntask as a Of-Cloze test. We carefully designed ex-\nperiments to test the inﬂuence of different types\nof context for language models to resolve bridg-\ning anaphors. Our results indicate that pre-trained\ntransformer language models encode substantial\ninformation about bridging.\nFinally, in this work, we only focus on under-\nstanding the capacity of the pre-trained language\nmodels for bridging inference. Based on the in-\nsights we gained from the current probing study, in\nthe future, we plan to explore how to better use pre-\ntrained transformer language models for bridging\nresolution.\n4162\nAcknowledgements\nWe thank the three anonymous reviewers for their\ncomments and feedback. This work was partially\nsupported by the French National Research Agency\nvia grant no ANR-16-CE33-0011-01 as well as\nby CPER Nord-Pas de Calais/FEDER DATA Ad-\nvanced data science and technologies 2015-2020.\nReferences\nNicholas Asher and Alex Lascarides. 1998. Bridging.\nJournal of Semantics, 15:83–113.\nJohan Bos, Paul Buitelaar, and Anne Marie Mineur.\n1995. Bridging as coercive accomodation. In Work-\ning Notes of the Edinburgh Conference on Com-\nputational Logic and Natural Language Process-\ning (CLNLP-95), Human Communications Research\nCentre, University of Edinburgh, Edinburgh, U.K.\nHerbert H. Clark. 1975. Bridging. In Proceedings of\nthe Conference on Theoretical Issues in Natural Lan-\nguage Processing, Cambridge, Mass., June 1975,\npages 169–174.\nKevin Clark, Urvashi Khandelwal, Omer Levy, and\nChristopher D. Manning. 2019. What does BERT\nlook at? an analysis of BERT’s attention. In Pro-\nceedings of the 2019 ACL Workshop BlackboxNLP:\nAnalyzing and Interpreting Neural Networks for\nNLP, pages 276–286, Florence, Italy. Association\nfor Computational Linguistics.\nJeff Da and Jungo Kasai. 2019. Cracking the contex-\ntual commonsense code: Understanding common-\nsense reasoning aptitude of deep contextual repre-\nsentations. In Proceedings of the First Workshop on\nCommonsense Inference in Natural Language Pro-\ncessing, pages 1–12, Hong Kong, China. Associa-\ntion for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 4171–4186, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\nYoav Goldberg. 2019. Assessing BERT’s syntactic\nabilities. ArXiv, abs/1901.05287.\nYufang Hou. 2018a. A deterministic algorithm for\nbridging anaphora resolution. In Proceedings of\nthe 2018 Conference on Empirical Methods in Nat-\nural Language Processing, pages 1938–1948, Brus-\nsels, Belgium. Association for Computational Lin-\nguistics.\nYufang Hou. 2018b. Enhanced word representations\nfor bridging anaphora resolution. In Proceedings of\nthe 2018 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, Volume 2 (Short Pa-\npers), pages 1–7, New Orleans, Louisiana. Associa-\ntion for Computational Linguistics.\nYufang Hou. 2020a. Bridging anaphora resolution as\nquestion answering. In Proceedings of the 58th An-\nnual Meeting of the Association for Computational\nLinguistics, pages 1428–1438, Online. Association\nfor Computational Linguistics.\nYufang Hou. 2020b. Fine-grained information status\nclassiﬁcation using discourse context-aware BERT.\nIn Proceedings of the 28th International Conference\non Computational Linguistics, Barcelona, Spain. As-\nsociation for Computational Linguistics.\nYufang Hou, Katja Markert, and Michael Strube. 2013.\nGlobal inference for bridging anaphora resolution.\nIn Proceedings of the 2013 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies ,\npages 907–917, Atlanta, Georgia. Association for\nComputational Linguistics.\nPhu Mon Htut, Jason Phang, Shikha Bordia, and\nSamuel R. Bowman. 2019. Do attention heads\nin bert track syntactic dependencies? ArXiv,\nabs/1911.12246.\nSarthak Jain and Byron C. Wallace. 2019. Attention is\nnot Explanation. In Proceedings of the 2019 Con-\nference of the North American Chapter of the Asso-\nciation for Computational Linguistics: Human Lan-\nguage Technologies, Volume 1 (Long and Short Pa-\npers), pages 3543–3556, Minneapolis, Minnesota.\nAssociation for Computational Linguistics.\nGanesh Jawahar, Benoît Sagot, and Djamé Seddah.\n2019. What does BERT learn about the structure\nof language? In Proceedings of the 57th Annual\nMeeting of the Association for Computational Lin-\nguistics, pages 3651–3657, Florence, Italy. Associa-\ntion for Computational Linguistics.\nOlga Kovaleva, Alexey Romanov, Anna Rogers, and\nAnna Rumshisky. 2019. Revealing the dark secrets\nof BERT. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP), pages\n4365–4374, Hong Kong, China. Association for\nComputational Linguistics.\nKatja Markert, Yufang Hou, and Michael Strube. 2012.\nCollective classiﬁcation for ﬁne-grained information\nstatus. In Proceedings of the 50th Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers) , pages 795–804, Jeju Island,\nKorea. Association for Computational Linguistics.\n4163\nS. Park, J. Son, S. w. Hwang, and K. Park. 2020. Bert\nis not all you need for commonsense inference. In\nICASSP 2020 - 2020 IEEE International Confer-\nence on Acoustics, Speech and Signal Processing\n(ICASSP), pages 8204–8208.\nFabio Petroni, Tim Rocktäschel, Sebastian Riedel,\nPatrick Lewis, Anton Bakhtin, Yuxiang Wu, and\nAlexander Miller. 2019. Language models as knowl-\nedge bases? In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Confer-\nence on Natural Language Processing (EMNLP-\nIJCNLP), pages 2463–2473, Hong Kong, China. As-\nsociation for Computational Linguistics.\nIna Roesiger, Arndt Riester, and Jonas Kuhn. 2018.\nBridging resolution: Task deﬁnition, corpus re-\nsources and rule-based experiments. In Proceedings\nof the 27th International Conference on Computa-\ntional Linguistics, pages 3516–3528, Santa Fe, New\nMexico, USA. Association for Computational Lin-\nguistics.\nIonut-Teodor Sorodoc, Kristina Gulordava, and\nGemma Boleda. 2020. Probing for referential\ninformation in language models. In Proceedings\nof the 58th Annual Meeting of the Association\nfor Computational Linguistics , pages 4177–4189,\nOnline. Association for Computational Linguistics.\nAlon Talmor, Yanai Elazar, Yoav Goldberg, and\nJonathan Berant. 2020. oLMpics – on what lan-\nguage model pre-training captures. Transactions of\nthe Association for Computational Linguistics, 8.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Rémi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander M. Rush. 2020.\nTransformers: State-of-the-art natural language pro-\ncessing. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Processing:\nSystem Demonstrations, pages 38–45, Online. Asso-\nciation for Computational Linguistics.",
  "topic": "Bridging (networking)",
  "concepts": [
    {
      "name": "Bridging (networking)",
      "score": 0.921864926815033
    },
    {
      "name": "Computer science",
      "score": 0.7763110995292664
    },
    {
      "name": "Inference",
      "score": 0.7703534364700317
    },
    {
      "name": "Language model",
      "score": 0.6437103748321533
    },
    {
      "name": "Natural language processing",
      "score": 0.6303982734680176
    },
    {
      "name": "Transformer",
      "score": 0.6156325340270996
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5907280445098877
    },
    {
      "name": "Security token",
      "score": 0.5700050592422485
    },
    {
      "name": "Engineering",
      "score": 0.07595136761665344
    },
    {
      "name": "Voltage",
      "score": 0.06468150019645691
    },
    {
      "name": "Computer security",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Computer network",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1294671590",
      "name": "Centre National de la Recherche Scientifique",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I1326498283",
      "name": "Institut national de recherche en sciences et technologies du numérique",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I2279609970",
      "name": "Université de Lille",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I7454413",
      "name": "École Centrale de Lille",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I4210145784",
      "name": "IBM Research - Ireland",
      "country": "IE"
    }
  ]
}