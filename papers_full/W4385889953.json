{
  "title": "Data Race Detection Using Large Language Models",
  "url": "https://openalex.org/W4385889953",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2106377209",
      "name": "Chen Le",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2599795968",
      "name": "Ding, Xianzhong",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4286951913",
      "name": "Emani, Murali",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4291220774",
      "name": "Vanderbruggen, Tristan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4286813877",
      "name": "Lin, Pei-Hung",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2153564598",
      "name": "Liao Chuan-hua",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4285815170",
    "https://openalex.org/W4386044294",
    "https://openalex.org/W4382490660",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4384434936",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W4385572142",
    "https://openalex.org/W4289827540",
    "https://openalex.org/W2973379954",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W4384643769",
    "https://openalex.org/W4323655724",
    "https://openalex.org/W4362515116",
    "https://openalex.org/W4304194220",
    "https://openalex.org/W3198685994",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3098605233",
    "https://openalex.org/W4385373622",
    "https://openalex.org/W3169573770",
    "https://openalex.org/W3177813494",
    "https://openalex.org/W4378509449",
    "https://openalex.org/W4378465262",
    "https://openalex.org/W4376167329",
    "https://openalex.org/W4308244910",
    "https://openalex.org/W4376166877",
    "https://openalex.org/W4388581500",
    "https://openalex.org/W4389519421",
    "https://openalex.org/W93759649"
  ],
  "abstract": "Large language models (LLMs) are demonstrating significant promise as an alternate strategy to facilitate analyses and optimizations of high-performance computing programs, circumventing the need for resource-intensive manual tool creation. In this paper, we explore a novel LLM-based data race detection approach combining prompting engineering and fine-tuning techniques. We create a dedicated dataset named DRB-ML, which is derived from DataRaceBench, with fine-grain labels showing the presence of data race pairs and their associated variables, line numbers, and read/write information. DRB-ML is then used to evaluate representative LLMs and fine-tune open-source ones. Our experiment shows that LLMs can be a viable approach to data race detection. However, they still cannot compete with traditional data race detection tools when we need detailed information about variable pairs causing data races.",
  "full_text": "Data Race Detection Using Large Language Models\nLe Chen\nlechen@iastate.edu\nIowa State University\nAmes, IA, USA\nLawrence Livermore National Laboratory\nLivermore, CA, USA\nXianzhong Ding\nxding5@ucmerced.edu\nUniversity of California, Merced\nMerced, CA, USA\nArgonne National Laboratory\nLemont, IL, USA\nMurali Emani\nmemani@anl.gov\nArgonne National Laboratory\nLemont, IL, USA\nTristan Vanderbruggen,\nPei-Hung Lin, Chunhua Liao\n{vanderbrugge1,lin32,liao6}@llnl.gov\nLawrence Livermore National Laboratory\nLivermore, CA, USA\nABSTRACT\nLarge language models (LLMs) are demonstrating significant promise\nas an alternate strategy to facilitate analyses and optimizations of\nhigh-performance computing programs, circumventing the need for\nresource-intensive manual tool creation. In this paper, we explore a\nnovel LLM-based data race detection approach combining prompt-\ning engineering and fine-tuning techniques. We create a dedicated\ndataset named DRB-ML, which is derived from DataRaceBench,\nwith fine-grain labels showing the presence of data race pairs and\ntheir associated variables, line numbers, and read/write informa-\ntion. DRB-ML is then used to evaluate representative LLMs and\nfine-tune open-source ones. Our experiment shows that LLMs can\nbe a viable approach to data race detection. However, they still\ncannot compete with traditional data race detection tools when we\nneed detailed information about variable pairs causing data races.\nKEYWORDS\ndata race detection, large language model, OpenMP\nACM Reference Format:\nLe Chen, Xianzhong Ding, Murali Emani, and Tristan Vanderbruggen,, Pei-\nHung Lin, Chunhua Liao. 2023. Data Race Detection Using Large Language\nModels. In Workshops of The International Conference on High Performance\nComputing, Network, Storage, and Analysis (SC-W 2023), November 12‚Äì17,\n2023, Denver, CO, USA. ACM, New York, NY, USA, 9 pages. https://doi.org/\n10.1145/3624062.3624088\n1 INTRODUCTION\nThe advent of many-core and GPU-accelerated systems has fostered\nthe need for threaded programming models, such as OpenMP and\nCUDA, to exploit intra-node parallelism effectively. However, a\nperennial challenge accompanying these programming models is\nthe risk of data races. Data races transpire when two or more threads\naccess the same memory location simultaneously in a conflicting\nPermission to make digital or hard copies of part or all of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for third-party components of this work must be honored.\nFor all other uses, contact the owner/author(s).\nSC-W 2023, November 12‚Äì17, 2023, Denver, CO, USA\n¬© 2023 Copyright held by the owner/author(s).\nACM ISBN 979-8-4007-0785-8/23/11.\nhttps://doi.org/10.1145/3624062.3624088\nmanner, without sufficient synchronization, with at least one of\nthese accesses involving a write operation. This type of bug induces\nunpredictable behaviors in code, meaning they may not consistently\nmanifest each time the code is executed, thereby exacerbating their\ndetection and resolution difficulties.\nVarious tools, such as Intel Inspector [15] and ThreadSanitizer [22],\nhave been developed to assist developers in responding to the chal-\nlenges associated with data race detection in multithreaded pro-\ngrams. Due to the fast evolution of parallel programming, these\ntools need to be constantly re-evaluated and manually updated\nto support new language features and code patterns. A dataset\nexplicitly designed for data race analysis, named DataRaceBench\n(DRB) [21], was introduced for evaluating the performance and\neffectiveness of various detection tools and methodologies.\nIn recent years, the realm of machine learning has been illu-\nminated by significant breakthroughs, particularly the emergence\nof Large Language Models (LLMs). Harnessing the power of deep\nlearning [11], LLMs have demonstrated their proficiency in compre-\nhending and generating human-like text from provided prompts.\nGiven the remarkable ability of LLMs to understand and gener-\nate text, they hold immense potential in the field of Programming\nLanguage Processing (PLP) tasks [5, 6, 18, 30]. This includes but\nis not limited to tasks such as code analysis, generation, and bug\ndetection, showcasing an exciting expansion beyond the traditional\nconfines of Natural Language Processing (NLP).\nBuilding on their numerous applications in PLP, LLMs present\npotential for deployment in the specialized area of data race detec-\ntion. We envisage that a fine-tuned LLM for data race detection\ncould discern common patterns and contexts that precipitate data\nraces. When applied to unfamiliar code, it could forecast potential\ndata race conditions, thus equipping developers with a proactive\nalert mechanism to mitigate possible risks. Compared to traditional\nstatic or dynamic analysis methods, if adequately trained, machine\nlearning approaches impose minimal human labor and runtime\noverhead and can effectively respond to a broad spectrum of data\nrace patterns. Furthermore, with their innate capability to generate\nhuman-like text, LLMs could facilitate detailed explanations about\ndetected data race conditions. Such insights could guide developers\nin discerning the underlying causes of these bugs and subsequently\naid in devising more effective resolution strategies.\narXiv:2308.07505v2  [cs.LG]  3 Oct 2023\nSC-W 2023, November 12‚Äì17, 2023, Denver, CO, USA Chen, et al.\nThe application of Large Language Models in data race detection\nrepresents a pioneering field of research. Our work commences by\ngenerating a comprehensive dataset distinctly labeled with explicit\ndata dependencies and data race information, emphasizing our com-\nmitment to ensuring the accuracy and dependability of the model‚Äôs\noutput. Subsequently, we propose novel experimental approaches\nfor data race detection using LLMs. The following contributions\ndistinguish this paper:\n(1) We have derived an innovative dataset from DataRaceBench\nfor machine learning training and large language model fine-\ntuning.\n(2) We extensively evaluate several prominent LLMs using various\nprompting techniques.\n(3) We fine-tune LLMs for the explicit task of data race detection,\nthereby enhancing their predictive accuracy.\n(4) A detailed comparative study between traditional data race\ndetection tools and LLM-based methods, highlighting their\nstrengths and weaknesses.\n2 BACKGROUND\nIn this section, we provide an overview of large language mod-\nels and their application in the context of programming language\nprocessing. We also introduce DataRaceBench.\n2.1 Large Language Models\nLarge Language Models (LLMs) are large-sized machine learning\nmodels specifically designed to perform various natural language\nprocessing tasks, such as analyzing and generating text, answering\nquestions in a conversational manner, and translating text from\none language to another. Previous work [33] observed that large-\nsized pre-trained language models exhibit behaviors distinct from\nsmaller ones (e.g., 330M-parameter BERT and 1.5B-parameter GPT-\n2) and show surprising abilities (called emergent abilities). Large\nlanguage models have emerged as revolutionary tools in machine\nlearning. The surging popularity of LLMs can be attributed to their\nversatile applicability and unparalleled performance in diverse tasks.\nLLMs have consistently outperformed traditional models, from\nenhancing natural language processing applications like sentiment\nanalysis [31] and chatbots [ 17] to aiding researchers in content\ngeneration, summarization, and translation [16, 19].\nDespite their inherent proficiency in context-dependent learning,\npre-trained LLMs often require additional training or fine-tuning\nto perform specialized or novel tasks. This process allows the mod-\nels to adapt to specific problem domains, thereby improving their\nperformance and relevance in a given context.\nIntegrating Natural Language Processing (NLP) techniques in\nProgramming Language Processing (PLP) tasks has sparked substan-\ntial interest. With applications that extend to code summarization,\ncode generation, and code similarity analysis [4, 14], this emerg-\ning field has witnessed the successful deployment of traditional\nlanguage models, underscoring the viability and potential of this\napproach [8].\nA remarkable advancement in this domain is the adaptation of\ntransformer-based language models for PLP tasks. Representative\nmodels, such as CodeBERT [13] and CodeT5 [29], epitomize this\ntrend. These models leverage a transformer architecture and are\ntrained on a wide array of programming languages to facilitate an\nextensive spectrum of programming-related tasks.\nIn the context of Large Language Models for Code (Code LLMs),\nseveral works [ 3, 9, 25] have explored pre-trained LLMs, either\ngeneral-purpose or task-specific, for PLP tasks. In this study, we\nfocus on four representative LLMs: GPT-3.5-turbo, GPT-4, Llama2-\n7b, and StarChat-beta (StarChat- ùõΩ), which demonstrate diverse\ncapabilities and applications in the sphere of code analysis and\ngeneration.\nGPT-3.5-turbo [2], engineered by OpenAI, is a state-of-the-art\nlanguage model capable of generating human-like text and com-\nprehending nuanced prompts. For our research, we employ the 16k\nversion of the model, accommodating up to 16384 input tokens.\nSucceeding GPT-3.5-turbo, GPT-4 [23] marks OpenAI‚Äôs latest and\nmost powerful offering. While GPT-4 retains the fundamental ar-\nchitecture of its predecessor, it capitalizes on expanded training\nacross a diverse range of internet text, thereby enhancing both\nthe model‚Äôs size and capabilities. Llama2 [27] is one of the latest\nmodels released by Meta. As a substantial and robust language\nmodel, it demonstrates particular strength in tasks requiring deep\nunderstanding and information synthesis. Based on StarCoder [20],\nStarChat constitutes a series of GPT-style models explicitly crafted\nfor code-related tasks. Their base models are 15.5B parameter mod-\nels trained on 80+ programming languages. StarChat-beta is the\nsecond model in this series with 16B parameters.\nAn LLM-based approach offers distinct advantages, including the\ncapacity to automatically capture common patterns across similar\nlanguages and to avoid the need for manual tool development for\nindividual languages. Compared with previous machine learning-\nbased approaches [26], LLMs can be continually fine-tuned on new\ndata, adapting to new domains or specific tasks while still retaining\ntheir broad capabilities. However, the potential of LLMs in the realm\nof data race detection has yet to be fully explored. This research\naims to probe into and unravel their capabilities in this domain.\n2.2 Data Race Detection and DataRaceBench\nProminent techniques for data race detection leverage two major\ntechniques: static and dynamic analysis. Static analysis tools such\nas Locksmith [24], RELAY [28], and ompVerify [1] inspect program\nsource code or intermediate representations (IRs) to reveal poten-\ntial data races through control flow and data dependency analysis.\nOn the other hand, dynamic analysis tools such as Inter Inspec-\ntor [15] and ThreadSanitizer [22] inspect program behavior during\nexecution by instrumenting code to monitor memory accesses in\nreal time. This is achieved by instrumenting the code to observe\nmemory access in real time. Techniques under dynamic analysis,\nsuch as lockset-based and happens-before-based detection, often\nyield better accuracy in data race detection.\nDespite the accurate output, dynamic analysis methods intro-\nduce runtime overhead and will likely miss certain race conditions\nthat are hard to trigger during testing. Static analysis methods, in\ncontrast, analyze the source code without executing it and generally\noffer faster results. Static analysis is advantageous in identifying\nrace conditions that might not manifest during dynamic testing.\nWith the massive number of threads available in the latest com-\nputing architectures, the interest in static analysis is growing to\nData Race Detection Using Large Language Models SC-W 2023, November 12‚Äì17, 2023, Denver, CO, USA\ncomplement dynamic analysis in performing race detection for\nmodern systems.\nHybrid approaches that exploit both static and dynamic analyses\nbecome promising for discerning potential data races with increased\nfidelity. Nowadays, with the breakthrough in machine learning\ntechnology [10, 12], methodologies with machine learning have\ngained traction, leveraging pattern recognition in program behavior\nor applying LLMs to enable data race detection.\nDataRaceBench (DRB) is an open-source benchmark suite me-\nthodically and quantitatively designed to evaluate data race detec-\ntion tools. It is particularly oriented towards the context of OpenMP,\na widely used parallel programming model for multithreaded ap-\nplications. More specifically, DRB contains microbenchmark pro-\ngrams both with and without data races, which are either manually\ncrafted, derived from actual scientific applications, or generated as\nautomatic optimization variants.\nDespite its effective labeling system for collected microbench-\nmarks, DRB lacks a structured dataset specifically designed for\nmachine learning training and evaluation. There is a clear demand\nfor a well-curated dataset comprising prompt-response pairs, which\nis crucial for the fine-tuning process of LLMs. Such a dataset, tailor-\nmade for machine learning applications, could significantly enhance\nthe performance and efficacy of data race detection methodologies.\n3 APPROACH\nIn this section, we elaborate on our approach by combining two\nprincipal routes designed to exploit the capabilities of Large Lan-\nguage Models for novel tasks. First, we evaluate three strategies\nfor data race detection with LLMs. Second, we fine-tune two open-\nsource LLMs for data race detection and identification of data race\nvariable pairs. As shown in Figure 1, our approach relies on the\nproposed dataset, DataRaceBench-ML. This section uses several\npopular Large Language Models, such as GPT, Llama2, and StarChat-\nbeta.\nLLMs for\nData Race\nDetection\nPrompt\nEngineering\n{basic prompt for data race\ndetection} (Listing 4, 5)\n{data dependence +\ndata race¬† detection} (Listing 6)\nBasic: data race detection\nLLM\nFine-tuning\n{data dependence}\n{data race¬† detection} (Listing 7)\nAdvanced: data race detection\n+ variable pairs\nDRB\nDRB-ML\nSTOA tool results\nFigure 1: Overview of Our Approach for Data Race Detection\nusing Large Language Models: GPT-3.5-turbo, GPT-4, Llama2,\nand StarChat-beta.\n3.1 DataRaceBench-ML Dataset\nThe quality of datasets is essential for the success of any machine-\nlearning approach. They determine the accuracy and robustness of\na model‚Äôs predictions. We processed the existing DataRaceBench\nV1.4.1 (DRB) to generate a new dataset, DataRaceBench-ML (DRB-\nML), to facilitate efficient ML model training, fine-tuning, and eval-\nuation. Each C/C++ microbenchmark from the DRB results in an\nentry in DRB-ML. Consequently, DRB-ML consists of 201 JSON\nfiles storing various key-value pairs - a direct correlation to the\nnumber of code snippets in the original DRB dataset.\nCreating the DRB-ML dataset is a multi-step process. Firstly, we\nextract labels from each code snippet in the DRB dataset and store\nthem in JSON. Table 1 illustrates the keys and their correspond-\ning values in DRB-ML JSON files, each playing a crucial role in\ntraining ML models for data race detection. The ‚Äòdata race-yes/no‚Äô\nlabel provides a binary indicator of data race conditions, while the\n‚Äòvar_pairs‚Äô label includes a list of variable pairs related to poten-\ntial data races, along with their names, locations, and operation\ntypes (‚Äòw‚Äô for write or ‚Äòr‚Äô for read). Together, these labels offer a\ncomprehensive view of the features our models need to analyze for\neffective data race detection. This step is carried out using scripts\nthat are designed to sift through code comments and metadata to\nfind relevant information. Listing 2 shows an example in DRB-ML\nlabels derived from a microbenchmark presented in Listing 1 from\nDRB. We omit the code content to better represent the paper. It is\nworth mentioning that the \"line\" value in DRB-ML is based on the\ncode without comments.\n47 /*\n48 A loop with loop - carried anti - dependence .\n49 Data race pair : a[i +1] @64 :10: R vs. a[i] @64 :5: W\n50 */\n51 # include <stdio .h>\n52 int main ( int argc , char * argv [])\n53 {\n54 int i;\n55 int len = 1000;\n56\n57 int a [1000];\n58\n59 for (i =0; i< len ; i ++)\n60 a[i]= i;\n61\n62 # pragma omp parallel for\n63 for (i =0;i< len -1 ;i ++)\n64 a[i]=a[i +1]+1;\n65\n66 printf (\"a [500]=% d\\n\", a [500] );\n67 return 0;\n68 }\nListing 1: DRB001-antidep1-orig-yes.c\n1 {\n2 \"ID\": \" 001 \",\n3 \" name \": \" DRB001 - antidep1 -orig - yes .c\",\n4 \" DRB_code \": \" ... \"\n5 \" data_race \": 1,\n6 \" trimmed_code \": \" ... \"\n7 \" code_len \": 262 ,\n8 \" data_race_label \": \"Y1\",\n9 \" var_pairs \":\n10 [\n11 \"{\nSC-W 2023, November 12‚Äì17, 2023, Denver, CO, USA Chen, et al.\nTable 1: Keys and Values in DRB-ML\nKeys Value type Description\nID int A unique index number starting from 1.\nname str The original filename of the DRB file.\nDRB_code str The original code present in DRB microbenchmarks.\ntrimmed_code str The DRB_code with all comments removed.\ncode_len int An integer value representing the string length of the trimmed code.\ndata_race int The presence of a data race is indicated by 1, and its absence by 0.\ndata_race_label str This label indicates the type of data race condition (race-yes or race-no) that DRB marks.\nvar_pairs [str]\nThis is a list of pairs of variables associated with a data race. It is empty when \"data_race\" is 0.\nEach item follows the format [VAR0, VAR1], where VAR1 depends on VAR0. Each variable is\nrepresented by a JSON string with keys in below.\npair[\"name\"] [str] Variable names.\npair[\"line\"] [int] Variable‚Äôs line number in trimmed code.\npair[\"col\"] [int] Variable‚Äôs column number in trimmed code.\npair[\"operation\"] [str] The operation performed on the variable. The value is either\n‚Äòw‚Äô (representing a write operation) or ‚Äòr‚Äô (representing a read operation).\n12 \" name \": [\"a[i +1] \", \"a[i]\"],\n13 \" line \": [64 , 64] ,\n14 \" col \": [10 , 5] ,\n15 \" operation \": [\"R\", \"W\"]\n16 }\"\n17 ]\n18 }\nListing 2: DRB-ML-001.json\nThe second step involves the creation of a data template for the\nprompt-response pairs. The prompts are formulated to guide the\nLLM in identifying data races and to provide information about\nvariables that might be causing them. The responses are simple\nlabels indicating whether a data race exists or not.\nIn the final step, we employ scripts to pull the code and the\ninformation generated in the first step. The result is a structured\nprompt-response pair for each code in the DRB-ML dataset.\nUpon completion of this process, each code snippet in the DRB-\nML dataset contains three key pieces of information: the presence\n(or absence) of a data race, pairs of variables that could cause a data\nrace, and the corresponding line numbers where these variables\nare found.\n1 {\n2 \" prompt \": \"\"\" You are an HPC expert . Examine the following\ncode and identify if there 's a data race . If a data\nrace is present , specify the variable pairs causing\nit , along with their line numbers and operations .\nCode : ... \"\"\" ,\n3 \" response \": \"\"\" Yes , the provided code exhibits data race\nissues . The data race is caused by the variable 'x'\nat line 9 and the variable 'x' at line 26. Both\ninstances involve write operations . \"\"\"\n4 }\nListing 3: Prompt-response example for DRB-ML-193\n3.2 Experiment Setup\nDataset: As outlined in Figure 1, we employ two strategies to\nevaluate the proficiency of LLMs in data race detection. First, we\nextract a subset of DRB-ML, ensuring that the data items have\ntoken sizes of less than 4k to accommodate the input sequence size\nlimits of the selected LLMs. This sub-set consists of 198 out of the\ntotal 201 entries in DRB-ML. For the prompt engineering approach,\nwe utilize the labels in the sub-set to assess the performance of\nthe LLMs. Conversely, for fine-tuning the LLMs, we rely on the\nprompt-response pairs in DRB-ML for the fine-tuning process. The\nperformance of the fine-tuned LLMs is then evaluated using the\nlabels from the dataset.\nModels: We start our experiments by employing four pre-trained\nlarge language models for data race detection. The chosen models,\nincluding GPT-3.5-turbo, GPT-4, Llama2-7b, and StarChat-beta with\n16 Billion parameters, represent a variety of architectures and are\nreputed for their performance on a range of tasks.\n3.3 Prompt Engineering for Data Race Detection\nPrompt engineering is a key technique in harnessing the power of\nLarge Language Models. It is a process wherein users tailor input\nprompts to elicit a particular response from the model. The goal is\nto craft prompts that effectively guide the model‚Äôs responses in the\ndesired direction. While it is hard to define the best prompt [34], a\nwell-designed prompt can enable the model to provide insightful,\nprecise, and contextually appropriate answers.\nFor the specific task of data race analysis using LLMs, we first\ndelineated the expectations regarding their output in the following\nscenarios:\n(1) S1. Data Race Detection: Given a code snippet, LLMs are\nexpected to decisively and concisely determine the presence of\na data race.\n(2) S2. Identification of Data Race Variables: LLMs should ana-\nlyze the code to identify the variables responsible for the data\nrace.\n(3) S3. Details on Data Race-related Variables: LLMs ought\nto disclose pertinent information concerning each involved\nvariable, including its name, its line number in the code, and\nthe specific operation (either read or write) performed on it.\nData Race Detection Using Large Language Models SC-W 2023, November 12‚Äì17, 2023, Denver, CO, USA\nWith our goals outlined, we started with two basic prompts for\ndata race detection. As an illustration, Listing 4 focuses on data\nrace detection (S1), while Listing 5 instructs the LLMs to provide\ndetails on data race variables in conjunction with their data race\ndetection findings (S1-3). Intriguingly, our preliminary experiments\nrevealed a notable variance in the data race detection outcomes,\nshown in table 2, when comparing the responses generated from\nGPT-3.5-turbo with the two basic prompts.\n1 \"\"\"\n2 You are an expert in High - Performance Computing . Examine\nthe code presented to you and ascertain if it\ncontains any data races .\n3 Begin with a concise response : either 'yes ' for the\npresence of a data race or 'no ' if absent .\n4\n5 { Code_to_analyze }\n6 \"\"\"\nListing 4: Basic Prompt 1 (BP1) template\n1 \"\"\"\n2 You are an expert in High - Performance Computing . Examine\nthe code presented to you and ascertain if it\ncontains any data races .\n3 Begin with a concise response : either 'yes ' for the\npresence of a data race or 'no ' if absent .\n4 detail each occurrence of a data race by specifying the\nvariable pairs involved , using the JSON format\noutlined below :\n5 {\n6 \" name \": Names of each pair of variables involved in a\ndata race .\n7 \" line \": line numbers of the paired variables within the\ncode .\n8 \" col \": column number of the paird variables with in their\nline .\n9 \" operation_types \": Corresponding operations , 'W' for\nwrite operation and 'R' for read operation .\n10 }\n11\n12 { Code_to_analyze }\n13 \"\"\"\nListing 5: Basic Prompt 2 (BP2) template\nTable 2: Data race detection results of GPT-3.5-turbo using\nbasic prompts 1 (BP1) and basic prompts 2 (BP2) shown in\nlisting 4 and 5, respectfully.\nPrompts TP FP TN FN Recall Precision F1\nBP1 66 55 43 34 0.660 0.545 0.597\nBP2 35 26 72 65 0.35 0.574 0.435\nThe findings showcased in Table 2 suggest that multi-task prompts\nnecessitate meticulous crafting in contrast to their simpler, more\nconcise counterparts. This observation aligns with prior research in\nprompt engineering, where \"greedy\" prompts yielded sub-optimal\nperformance [34]. Given these insights, we opted to refine our\nprompt engineering for data race detection based on Listing 4 while\naddressing the tasks of S2 and S3 through the fine-tuning approach\ndiscussed in Section 3.4.\nTo enhance the quality of prompts for data race detection, we in-\ntegrated insights from traditional tools and principles of concurrent\nprogramming. We crafted a prompt shown in Listing 6 to explicitly\ninstruct the LLMs to look for instances where two or more threads\nare simultaneously accessing the same memory location without\nproper synchronization, and at least one access is a write operation.\nOur preliminary results in table 2 show that a simple and concise\nprompt may be more efficient. Therefore, we broke the instruction\nin Listing 6 into two prompts and executed them sequentially in\na chat mode of the LLMs. This Chain-of-thoughts (COT) strategy\nintroduced by Zhang et al. [ 32] facilitates step-by-step thinking\nbefore answering a question, making each step simple and concise.\n1 \"\"\"\n2 You are an expert in High - Performance Computing ( HPC ).\nExamine the provided code to identify any data races\nbased on data dependence analysis .\n3 For clarity , a data race occurs when two or more threads\naccess the same memory location simultaneously in a\nconflicting manner , without sufficient\nsynchronization , with at least one of these accesses\ninvolving a write operation . It 's crucial to\nanalyze data dependence before determining potential\ndata races .\n4 Begin with a concise response : either 'yes ' for the\npresence of a data race or 'no ' if absent .\nListing 6: Advanced Prompt 1 (AP1) for data race detection.\nAP1 extends BP1 by giving some details of data race detection\nincluding its definition and key analysis.\n1 \"\"\" You are an expert in High - Performance Computing ( HPC ).\nAnalyze data dependence in the given code .\n2\n3 { Code_to_analyze }\n4 \"\"\"\nChain1 in AP2. Chain1 guides the LLMs to check the data\ndependence in the given code.\n1 \"\"\" A data race occurs when two or more threads access the\nsame memory location simultaneously in a\nconflicting manner , without sufficient\nsynchronization , with at least one of these accesses\ninvolving a write operation . Identify any data\nraces based on the given data dependence information\n.\n2 Begin with a concise response : either 'yes ' for the\npresence of a data race or 'no ' if absent .\n3 \"\"\"\nChain2 in AP2. With the output of Chain1 as a part of its\ninput, Chain2 focuses on the data race detection task.\nListing 7: Advanced Prompt 2 (AP2). AP2 utilizes the chain-\nof-thoughts strategy to break AP1 into a chain. Chain1 and\nChain2 are connected using LangChain‚Äôs SequentialChain.\nIn summary, we employed various prompt engineering strategies\nfor data race detection, referencing Listings 4, 5, 6, and 7.\n3.4 LLM Fine-tuning for Data Race Analysis\nSettings. The DRB-ML dataset, as detailed in Section 3.1, provides\nfoundational prompt-response templates designed specifically for\ndata race detection. Building on this, we crafted two distinct prompt-\nresponse sets from the DRB-ML templates: one for detecting data\nSC-W 2023, November 12‚Äì17, 2023, Denver, CO, USA Chen, et al.\nraces and another for identifying the associated variables. Our fine-\ntuning process follows prior works utilizing human feedback to\nenhance large language models [35].\nWe chose the Llama2-7b and StarChat-beta models as our can-\ndidate base models for fine-tuning. We employed PyTorch version\n2.01 and DeepSpeed 0.9.5 to support fine-tuning. For the Llama2-7b\nmodel, we adopted a learning rate of 2e-4, set the maximum se-\nquence length to 256, and used the Adam optimizer. Conversely, for\nthe StarChat-beta model, all settings remained consistent except\nfor a learning rate adjustment to 9.65e-6. We set the batch size\nto be 4 per GPU for training. To optimize memory usage during\nfine-tuning, we integrated QLoRA [7], setting the LoRA attention\ndimension to 64 and applying a dropout rate of 0.1. Our training\nprocess utilized the cross-entropy loss.\nFine-tuning objective. Three scenarios were introduced in Section\n3.3 for data race analysis. In the fine-tuning approach, we set two\nobjectives for LLM fine-tuning: First, LLM fine-tuning for data\nrace detection. And second, LLM fine-tuning for data race variable\nidentification.\nFine-tuning dataset. Using the DRB-ML dataset, we utilized labels\nin the DRB-ML dataset to create two sets of 198 prompt-response\npairs for data race detection and variable identification.\n‚Ä¢ Listing 8 shows an instance of prompt-response pairs de-\nrived from Listing 4 for LLM fine-tuning for basic data race\ndetection.\n‚Ä¢ Listing 9 shows an instance of prompt-response pairs derived\nfrom LLM fine-tuning for advanced data race detection with\nvariable identification.\n1 {\n2 \" prompt \":\n3 \"\"\"\n4 You are an expert in High - Performance Computing . Examine\nthe code presented to you and ascertain if it\ncontains any data races .\n5 Begin with a concise response : either \" yes \" for the\npresence of a data race or \"no\" if absent .\n6\n7 { Code_to_analyze }\n8 \"\"\" ,\n9 \" response \": \"\"\" yes \"\"\"\n10\n11 }\nListing 8: Instance of basic fine-tuning (basic-FT) prompt-\nresponse pairs for data race detection.\n1 {\n2 \" prompt \":\n3 \"\"\"\n4 You are an expert in High - Performance Computing . Examine\nthe code presented to you and ascertain if it\ncontains any data races .\n5 Detail each occurrence of a data race by specifying the\nvariable pairs involved using the JSON format\noutlined below :\n6 {\n7 \" variable_names \": Names of each pair of variables\ninvolved in a data race .\n8 \" variable_locations \": line numbers of the paired\nvariables within the code .\n9 \" operation_types \": Corresponding operations , either '\nwrite ' or 'read '.\n10 }\n11 {}\n12 \"\"\" ,\n13 \" response \":\n14 \"\"\"\n15 \" yes \",\n16 {\n17 \" data_race \": 1,\n18 \" variable_names \": [\"a[i]\" , \"a[i +1]\"] ,\n19 \" variable_locations \": [14 , 14] ,\n20 \" operation_types \": [\" write \", \" read \"]\n21 }\n22 \"\"\"\n23 }\nListing 9: Instance of advanced fine-tuning (advanced-FT)\nprompt-response pairs for advanced data race detection\n3.5 Five-fold Crossing Validation\nWe implemented a stratified k-fold cross-validation approach with\nùëò = 5 to accomplish an unbiased evaluation. This method is de-\nsigned to retain a consistent proportion of positive to negative\nsamples in each fold, mirroring the overall dataset‚Äôs structure.\nThe subset of DRB-ML used in our work showcases a distri-\nbution of roughly 50.5% positive(data race-yes) cases and 49.5%\nnegative(data race-no) cases. In crafting the 5-fold cross-validation,\neach fold is meticulously constructed to emulate this distribution.\nThis delineation averages out to each fold, accommodating about\n20 positive cases and 19.6 negative cases.\nGiven the indivisibility of data points in a practical setting, the\nallocation was determined as follows: Three of the folds were pop-\nulated with both 20 positive and 20 negative cases, making up 40\ndata points in each of these folds. The remaining two folds were as-\nsembled with 20 positive cases and 19 negative cases each, resulting\nin 39 data points for each of these folds. By adopting this stratified\n5-fold cross-validation, we provide a representative sample in each\npartition, ensuring a comprehensive and robust evaluation of LLMs.\n3.6 Evaluation Metrics\nIn our study, we assess the performance of Large Language Models\n(LLMs) by examining their outputs in the context of three scenarios,\nas detailed in Section 3.3. These scenarios‚ÄîS1, S2, and S3‚Äîserve\nas binary classification tasks, allowing us to compute the counts\nof True Positives (TP), False Positives (FP), True Negatives (TN),\nand False Negatives (FN) by comparing the LLM outputs with the\nground truth.\nTo quantify the performance of the LLMs, we utilize established\nmetrics such as recall (R), precision (P), and the F1 score (F1). Addi-\ntionally, we compute the average value (AVG) and standard devi-\nation (SD) for these metrics across 5-fold cross-validation experi-\nments.\nIt‚Äôs worth noting that the values for recall, precision, and F1\nscore‚Äîas well as their respective averages‚Äîrange from 0 to 1, with\nhigher values indicating better performance. Additionally, a lower\nstandard deviation is indicative of more consistent performance\nacross the different folds of validation, making a lower SD score\npreferable.\nData Race Detection Using Large Language Models SC-W 2023, November 12‚Äì17, 2023, Denver, CO, USA\n4 EXPERIMENTAL RESULTS\nThis section presents the outcomes of our experiments, encompass-\ning both prompt engineering and model fine-tuning exercises.\n4.1 Prompt Engineering for Data Race Detection\nLeveraging the trimmed code snippets from the DRB-ML dataset,\nwe produced a set of three prompts for every code following the\nthree prompt engineering strategies discussed in Section 3.3. As\nsuggested by the results in Table 2, we did not adopt BP2 because\nthe \"greedy\" prompts yield sub-optimal performance.\n‚Ä¢ BP1: Based on the template from Listing 4. This prompt is suc-\ncinct, directing LLMs straightforwardly to detect data races.\n‚Ä¢ AP1: Derived from Listing 6, this prompt instructs LLMs to emu-\nlate traditional tool methodologies, emphasizing data dependence\nanalysis prior to ascertaining potential data races.\n‚Ä¢ AP2: Adopting the template from Listing 7, this variant separates\nthe dual steps from AP1, adhering to a Chain-of-Thought design\napproach.\nSubsequent to the model‚Äôs output generation, we transformed\nthese outputs into prediction labels. These predictions were then\nevaluated against the definitive \"data_race\" labels found within\nDRB-ML. Comprehensive results of this assessment can be found in\nTable 3, where values in bold signify the best performance across\nall tools, while values in red denote the top-performing LLM.\nTable 3: Comparison of a representative traditional tool, Intel\nInspector, and four LLMs: GPT-3.5-turbo, GPT-4, StarChat-\nbeta, and Llama2-7b. We use three prompts: BP1, AP1, and\nAP2 to check if given codes contain data race. Values in bold\nsignify the best performance across all tools, while values in\ngreen denote the top-performing LLM.\nModel Prompt TP FP TN FN R P F1\nInspector N/A 88 44 53 11 0.889 0.667 0.762\nBP1 66 55 43 34 0.660 0.545 0.597\nAP1 63 56 42 37 0.630 0.529 0.575GPT3\nAP2 69 54 44 31 0.690 0.561 0.619\nBP1 77 28 70 23 0.770 0.733 0.751\nAP1 78 30 68 22 0.780 0.722 0.750GPT4\nAP2 78 28 68 22 0.780 0.736 0.757\nBP1 63 68 30 37 0.630 0.481 0.545\nAP1 62 67 31 38 0.620 0.481 0.541StarChat\nAP2 63 61 37 37 0.630 0.508 0.563\nBP1 65 57 41 35 0.650 0.533 0.586\nAP1 65 57 41 35 0.650 0.533 0.586Llama\nAP2 66 55 43 34 0.660 0.545 0.597\n4.2 Basic LLM Fine-tuning: Data Race Detection\nTo the best of our understanding, neither the training dataset for\nLLama2-7b nor StarChat-beta incorporates the DataRaceBench data\nupon reviewing their source. As such, we adopted the 5-fold cross-\nvalidation methodology detailed in Section 3.5 to fine-tune these\nopen-source LLMs. We employed the basic prompt-response (basic-\nFT) pairs throughout the fine-tuning and validation phases, as ex-\nemplified in Listing 8.\nTable 4 presents the results from this 5-fold cross-validation for\nthe fine-tuned StarChat-beta and LLama2-7b models. The up-arrow\nindicates the performance increase by fine-tuned models compared\nwith the original pre-trained versions.\nBroadly speaking, the fine-tuned models demonstrated enhanced\nF1 score and consistency performance. The StarChat-beta model\nregistered improvements across nearly all metrics for data race\ndetection, with the sole exception being recall consistency. Con-\nversely, while the Llama2-7b model saw a dip in its recall score, it\nexhibited advancements in other evaluation metrics.\nTable 4: Average (AVG) and Standard Deviation (SD) of Recall,\nPrecision, and F1 Score from a 5-fold cross-validation for data\nrace detection using StarChat-beta, Llama2-7b, and their fine-\ntuned (FT) models with basic-FT prompts. Green indicates\nimproved performance with fine-tuned models, while red\nsignifies decreased performance.\nModel AVG of RSD of R AVG of PSD of P AVG of F1SD of F1\nStarChat 0.630 0.045 0.482 0.041 0.546 0.039\nStarChat-FT 0.670 0.057 0.541 0.037 0.598 0.038\nLlama 0.650 0.137 0.532 0.094 0.584 0.109\nLlama-FT 0.640 0.082 0.543 0.054 0.586 0.061\n4.3 Advanced LLM Fine-tuning: Data Race\nDetection and Data Race Variable\nIdentification\nAs highlighted in the approach section, identifying data race-related\nvariable pairs and extracting their detailed information poses signif-\nicant challenges. Initially, we assessed the LLMs‚Äô performance con-\ncerning data race variable identification. Subsequently, we specif-\nically fine-tuned the StarChat-beta and Llama2-7 models for this\ntask.\nTable 5: Comparison of results of advanced data race detec-\ntion with variable identification, using four LLMs. Values in\nbold signify the best performance across all models.\nModel TP FP TN FN Recall Precision F1\nGPT3 12 54 44 88 0.120 0.182 0.145\nGPT4 14 31 67 86 0.140 0.311 0.193\nStarChat 7 66 32 93 0.070 0.096 0.081\nLlama 5 65 33 95 0.050 0.071 0.059\nTable 5 showcases the performance metrics of the selected mod-\nels before fine-tuning while Table 6 showcases the results from the\n5-fold cross-validation. The fine-tuned StarChat-beta and LLama2-\n7b models are compared to their original pre-trained versions. We\nconsistently employed the advanced-FT prompt-response pairs\nthroughout the fine-tuning and validation stages, as depicted in\nListing 9. Although the performance of the StarChat-beta model\nimproved after fine-tuning, this enhancement came with an added\ninconsistency. Conversely, the Llama2-7b model didn‚Äôt exhibit any\nsignificant improvements, potentially due to the limited training\ndataset.\nSC-W 2023, November 12‚Äì17, 2023, Denver, CO, USA Chen, et al.\nTable 6: Average (AVG) and Standard Deviation (SD) Recall,\nPrecision, and F1 score of the 5-fold crossing validation for\nthe advanced data race variable identification with StarChat-\nbeta, Llama2-7b, and the fine-tuned (FT) models. Green indi-\ncates improved performance with fine-tuned models, while\nred signifies decreased performance.\nModel AVG of RSD of R AVG of PSD of P AVG of F1SD of F1\nStarChat 0.070 0.045 0.096 0.063 0.081 0.052\nStarChat-FT 0.070 0.057 0.103 0.087 0.083 0.069\nLlama 0.050 0.050 0.085 0.087 0.063 0.064\nLlama-FT 0.050 0.050 0.092 0.086 0.064 0.063\n4.4 Observation\nThrough meticulously crafted experiments focused on data race\nanalysis using LLMs, we derived the following insights from our\nresults:\n‚Ä¢ In general, GPT-4 stands out as the premier pre-trained model for\ndata race analysis, excelling particularly in identifying data race-\nrelated variables. Nevertheless, the open-source models, namely\nStarChat-beta and Llama2-7b, demonstrate significant potential.\nWith the right fine-tuning, they could indeed surpass the GPT\nseries in data race detection capabilities.\n‚Ä¢ While traditional tools achieve superior performance in terms of\nthe F1 score when compared to LLMs, testing with the DataRaceBench\ndata indicates that GPT-4 exhibits noteworthy potential. This\nis impressive, given that GPT-4 is designed for general-purpose\ntasks and not specifically optimized for this domain.\n‚Ä¢ Our initial results, showcased in Table 2, indicate a clear trend:\nsimple and concise prompts yield better results by LLMs. Our\nextensive prompt engineering results reinforce this observation,\nas presented in Table 3. Specifically, with the exception of the\nLlama2-7b model, all other models displayed enhanced perfor-\nmance with ‚ÄôBP1‚Äô‚Äîa succinct prompt, as compared to ‚ÄôBP2‚Äô‚Äîa\nmulti-task oriented prompt, when it came to data race detection.\n‚Ä¢ Our results from fine-tuning demonstrate the potential of open-\nsource LLMs in handling data race analysis tasks.\n4.5 Challenges and Possible Solutions\nIn our exploration of data race analysis with LLMs, spanning from\ndataset preparation to LLM inference, fine-tuning, and evaluation,\nwe encountered several challenges:\n‚Ä¢ Dataset: The dataset preparation was both time-consuming and\nlabor-intensive, further complicated by the scarcity of available\ndatasets. This scarcity subsequently affected the efficacy of LLM\nfine-tuning. Potential remedies include:\n‚Äì Crawling data from open-source repositories.\n‚Äì Generating synthetic datasets tailored for training.\n‚Äì Automating the dataset processing stages using LLMs.\n‚Ä¢ Natural Language Output Processing: As text generation\nmodels, LLMs produce outputs in natural language. Parsing and\nprocessing these outputs present considerable challenges. One\napproach to mitigating this challenge is by directing LLMs to\nadhere to specific output formats. Initially, our DRB-ML dataset‚Äôs\nprompt-response pairs, as exemplified in Listing 3, contained\nnatural language outputs. We later transitioned to structured\nJSON outputs, as depicted in Listing 5. Nonetheless, not every\nLLM consistently maintains designated output formats, leading\nus to employ regular expressions for parsing.\n‚Ä¢ General Challenges for PLP with LLMs: Although LLMs have\nachieved great success in a lot of areas, their success happens\nmostly in NLP tasks. The processes of training data collection,\ntokenization, and embedding representations for the LLMs are\nall finely tuned to cater to the requirements of NLP applications.\nAdvancements in LLMs have recently incorporated programming\nlanguage source codes and language-specific content into their\ntraining datasets. However, the quality of this training data re-\nmains suboptimal. A notable issue is the inclusion of incomplete\nor incorrect code snippets that cannot be successfully compiled\nby standard compilers. This deficiency has drawn our attention,\nhighlighting the pressing need to enhance the quality of training\ndata for Programmable Language Models in the context of pro-\ngramming tasks. Addressing this challenge is imperative to fully\nempower LLMs for effective performance in PLP tasks.\n5 CONCLUSION\nIn this paper, we have explored the capabilities of large language\nmodels for the task of detecting data races in OpenMP programs. A\ndedicated dataset, DRB-ML, was created based on DataRaceBench\nto evaluate and fine-tune LLMs. The results show that LLMs have\nthe potential to become an alternative solution for data race de-\ntection. However, they cannot outperform traditional data race\ndetection tools without improved training datasets or novel code\nrepresentations that capture more code semantics.\nIn the future, we are interested in expanding DRB-ML to in-\nclude more data items using data scraping and augmentation tech-\nniques. We will also explore different modalities beyond text as\ninput, such as abstract syntax trees, dependence graphs, and control-\nflow graphs.\nACKNOWLEDGMENTS\nPrepared by LLNL under Contract DE-AC52-07NA27344(LLNL-\nCONF-853160) and supported by the U.S. Department of Energy,\nOffice of Science, Advanced Scientific Computing Research. This re-\nsearch was also funded in part by and used resources at the Argonne\nLeadership Computing Facility, which is a DOE Office of Science\nUser Facility supported under Contract DE-AC02-06CH11357\nREFERENCES\n[1] Vamshi Basupalli, Tomofumi Yuki, Sanjay Rajopadhye, Antoine Morvan, Steven\nDerrien, Patrice Quinton, and David Wonnacott. 2011. ompVerify: polyhedral\nanalysis for the OpenMP programmer. In OpenMP in the Petascale Era: 7th Inter-\nnational Workshop on OpenMP, IWOMP 2011, Chicago, IL, USA, June 13-15, 2011.\nProceedings 7 . Springer, 37‚Äì53.\n[2] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,\nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot learners. Advances in neural\ninformation processing systems 33 (2020), 1877‚Äì1901.\n[3] Le Chen, Pei-Hung Lin, Tristan Vanderbruggen, Chunhua Liao, Murali Emani,\nand Bronis de Supinski. 2023. LM4HPC: Towards Effective Language Model\nApplication in High-Performance Computing. arXiv preprint arXiv:2306.14979\n(2023).\n[4] Le Chen, Quazi Ishtiaque Mahmud, and Ali Jannesari. 2022. Multi-View Learning\nfor Parallelism Discovery of Sequential Programs. In 2022 IEEE International\nParallel and Distributed Processing Symposium Workshops (IPDPSW) . IEEE, 295‚Äì\n303.\n[5] Le Chen, Quazi Ishtiaque Mahmud, Hung Phan, Nesreen Ahmed, and Ali Jan-\nnesari. 2023. Learning to Parallelize with OpenMP by Augmented Heterogeneous\nData Race Detection Using Large Language Models SC-W 2023, November 12‚Äì17, 2023, Denver, CO, USA\nAST Representation. Proceedings of Machine Learning and Systems 5 (2023).\n[6] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira\nPinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman,\net al. 2021. Evaluating large language models trained on code. arXiv preprint\narXiv:2107.03374 (2021).\n[7] Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. 2023.\nQlora: Efficient finetuning of quantized llms. arXiv preprint arXiv:2305.14314\n(2023).\n[8] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert:\nPre-training of deep bidirectional transformers for language understanding.arXiv\npreprint arXiv:1810.04805 (2018).\n[9] Xianzhong Ding, Le Chen, Murali Emani, Chunhua Liao, Pei-Hung Lin, Tristan\nVanderbruggen, Zhen Xie, Alberto E. Cerpa, and Wan Du. 2023. HPC-GPT: Inte-\ngrating Large Language Model for High-Performance Computing. In Workshops\nof The International Conference on High Performance Computing, Network, Storage,\nand Analysis (SC-W 2023) .\n[10] Xianzhong Ding and Wan Du. 2022. Drlic: Deep reinforcement learning for\nirrigation control. In 2022 21st ACM/IEEE International Conference on Information\nProcessing in Sensor Networks (IPSN) . IEEE, 41‚Äì53.\n[11] Xianzhong Ding, Wan Du, and Alberto Cerpa. 2019. OCTOPUS: Deep rein-\nforcement learning for holistic smart building control. In Proceedings of the 6th\nACM international conference on systems for energy-efficient buildings, cities, and\ntransportation. 326‚Äì335.\n[12] Xianzhong Ding, Wan Du, and Alberto E Cerpa. 2020. Mb2c: Model-based deep\nreinforcement learning for multi-zone building control. In Proceedings of the 7th\nACM international conference on systems for energy-efficient buildings, cities, and\ntransportation. 50‚Äì59.\n[13] Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong,\nLinjun Shou, Bing Qin, Ting Liu, Daxin Jiang, et al. 2020. Codebert: A pre-trained\nmodel for programming and natural languages. arXiv preprint arXiv:2002.08155\n(2020).\n[14] Patrick Flynn, Tristan Vanderbruggen, Chunhua Liao, Pei-Hung Lin, Murali\nEmani, and Xipeng Shen. 2022. Finding Reusable Machine Learning Compo-\nnents to Build Programming Language Processing Pipelines. arXiv preprint\narXiv:2208.05596 (2022).\n[15] Intel. [n. d.]. Inspector. https://www.intel.com/content/www/us/en/developer/\ntools/oneapi/inspector.html\n[16] Marzena Karpinska and Mohit Iyyer. 2023. Large language models effectively\nleverage document-level context for literary translation, but critical errors persist.\narXiv preprint arXiv:2304.03245 (2023).\n[17] Enkelejda Kasneci, Kathrin Se√üler, Stefan K√ºchemann, Maria Bannert, Daryna\nDementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan G√ºnnemann, Eyke\nH√ºllermeier, et al. 2023. ChatGPT for good? On opportunities and challenges\nof large language models for education. Learning and Individual Differences 103\n(2023), 102274.\n[18] Bin Lei, Caiwen Ding, Le Chen, Pei-Hung Lin, and Chunhua Liao. 2023. Creating\na Dataset Supporting Translation Between OpenMP Fortran and C++ Code.arXiv\npreprint arXiv:2307.07686 (2023).\n[19] Bin Lei, Chunhua Liao, Caiwen Ding, et al. 2023. Boosting Logical Reasoning\nin Large Language Models through a New Framework: The Graph of Thought.\narXiv preprint arXiv:2308.08614 (2023).\n[20] Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov,\nChenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, et al. 2023.\nStarCoder: may the source be with you! arXiv preprint arXiv:2305.06161 (2023).\n[21] Chunhua Liao, Pei-Hung Lin, Joshua Asplund, Markus Schordan, and Ian Karlin.\n2017. DataRaceBench: a benchmark suite for systematic evaluation of data race\ndetection tools. InProceedings of the International Conference for High Performance\nComputing, Networking, Storage and Analysis . 1‚Äì14.\n[22] LLVM. 2023. THREADSANITIZER. https://clang.llvm.org/docs/ThreadSanitizer.\nhtml\n[23] OpenAI. 2023. GPT-4 Technical Report. ArXiv abs/2303.08774 (2023).\n[24] Polyvios Pratikakis, Jeffrey S Foster, and Michael Hicks. 2006. Locksmith: context-\nsensitive correlation analysis for race detection. Acm Sigplan Notices 41, 6 (2006),\n320‚Äì331.\n[25] Bo Shen, Jiaxin Zhang, Taihong Chen, Daoguang Zan, Bing Geng, An Fu, Muhan\nZeng, Ailun Yu, Jichuan Ji, Jingyang Zhao, et al . 2023. PanGu-Coder2: Boost-\ning Large Language Models for Code with Ranking Feedback. arXiv preprint\narXiv:2307.14936 (2023).\n[26] Ali TehraniJamsaz, Mohammed Khaleel, Reza Akbari, and Ali Jannesari. 2021.\nDeeprace: A learning-based data race detector. In 2021 IEEE International Confer-\nence on Software Testing, Verification and Validation Workshops (ICSTW) . IEEE,\n226‚Äì233.\n[27] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yas-\nmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhos-\nale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv\npreprint arXiv:2307.09288 (2023).\n[28] Jan Wen Voung, Ranjit Jhala, and Sorin Lerner. 2007. RELAY: static race detection\non millions of lines of code. In Proceedings of the the 6th joint meeting of the\nEuropean software engineering conference and the ACM SIGSOFT symposium on\nThe foundations of software engineering . 205‚Äì214.\n[29] Yue Wang, Weishi Wang, Shafiq Joty, and Steven CH Hoi. 2021. Codet5: Identifier-\naware unified pre-trained encoder-decoder models for code understanding and\ngeneration. arXiv preprint arXiv:2109.00859 (2021).\n[30] Daoguang Zan, Bei Chen, Fengji Zhang, Dianjie Lu, Bingchao Wu, Bei Guan,\nWang Yongji, and Jian-Guang Lou. 2023. Large language models meet NL2Code:\nA survey. In Proceedings of the 61st Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers) . 7443‚Äì7464.\n[31] Wenxuan Zhang, Yue Deng, Bing Liu, Sinno Jialin Pan, and Lidong Bing. 2023.\nSentiment Analysis in the Era of Large Language Models: A Reality Check. arXiv\npreprint arXiv:2305.15005 (2023).\n[32] Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. 2022. Automatic chain\nof thought prompting in large language models. arXiv preprint arXiv:2210.03493\n(2022).\n[33] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou,\nYingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023. A survey\nof large language models. arXiv preprint arXiv:2303.18223 (2023).\n[34] Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis,\nHarris Chan, and Jimmy Ba. 2022. Large language models are human-level\nprompt engineers. arXiv preprint arXiv:2211.01910 (2022).\n[35] Daniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario\nAmodei, Paul Christiano, and Geoffrey Irving. 2019. Fine-tuning language models\nfrom human preferences. arXiv preprint arXiv:1909.08593 (2019).",
  "topic": "Race (biology)",
  "concepts": [
    {
      "name": "Race (biology)",
      "score": 0.8621921539306641
    },
    {
      "name": "Computer science",
      "score": 0.7120128273963928
    },
    {
      "name": "Variable (mathematics)",
      "score": 0.45640599727630615
    },
    {
      "name": "Resource (disambiguation)",
      "score": 0.4444114863872528
    },
    {
      "name": "Data science",
      "score": 0.42100659012794495
    },
    {
      "name": "Mathematics",
      "score": 0.0807214081287384
    },
    {
      "name": "Botany",
      "score": 0.0
    },
    {
      "name": "Computer network",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1282105669",
      "name": "Argonne National Laboratory",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I173911158",
      "name": "Iowa State University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I1282311441",
      "name": "Lawrence Livermore National Laboratory",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I156087764",
      "name": "University of California, Merced",
      "country": "US"
    }
  ],
  "cited_by": 1
}