{
  "title": "You are what you're for: Essentialist categorization in large language models",
  "url": "https://openalex.org/W4376140095",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2100161871",
      "name": "Siying Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4376815746",
      "name": "Selena She",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2094783861",
      "name": "Tobias Gerstenberg",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1877631692",
      "name": "David Rose",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2501381563",
    "https://openalex.org/W6655721913",
    "https://openalex.org/W6675347090",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W6988138882",
    "https://openalex.org/W1546829786",
    "https://openalex.org/W2059787852",
    "https://openalex.org/W2014098443",
    "https://openalex.org/W4281387391",
    "https://openalex.org/W6802529681",
    "https://openalex.org/W1992503247",
    "https://openalex.org/W4310820245",
    "https://openalex.org/W2017294267",
    "https://openalex.org/W2073307787",
    "https://openalex.org/W2322579942",
    "https://openalex.org/W6838865847",
    "https://openalex.org/W6631002354",
    "https://openalex.org/W2077877335",
    "https://openalex.org/W6651123520",
    "https://openalex.org/W6794026535",
    "https://openalex.org/W2138360614",
    "https://openalex.org/W4291991132",
    "https://openalex.org/W6606762648",
    "https://openalex.org/W6664075238",
    "https://openalex.org/W6761208622",
    "https://openalex.org/W6806090922",
    "https://openalex.org/W6817505205",
    "https://openalex.org/W6774237542",
    "https://openalex.org/W6684930358",
    "https://openalex.org/W6755421190",
    "https://openalex.org/W4308760226",
    "https://openalex.org/W2169632366",
    "https://openalex.org/W3034912286",
    "https://openalex.org/W6838311432",
    "https://openalex.org/W2582743722",
    "https://openalex.org/W2898205717",
    "https://openalex.org/W4281557260",
    "https://openalex.org/W3111372685",
    "https://openalex.org/W4285594979",
    "https://openalex.org/W3007377003",
    "https://openalex.org/W4239829918",
    "https://openalex.org/W2020769179",
    "https://openalex.org/W3155889076",
    "https://openalex.org/W2002611576",
    "https://openalex.org/W4298190688",
    "https://openalex.org/W4235811194",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4311642023",
    "https://openalex.org/W2054030067",
    "https://openalex.org/W4232370398",
    "https://openalex.org/W3207835719",
    "https://openalex.org/W2936856346",
    "https://openalex.org/W4385767671",
    "https://openalex.org/W4242822272",
    "https://openalex.org/W4389070894"
  ],
  "abstract": "How do essentialist beliefs about categories arise? We hypothesize that such beliefs are transmitted via language. We subject large language models (LLMs) to vignettes from the literature on essentialist categorization and find that they align well with people when the studies manipulated teleological information – information about what something is for. We examine whether in a classic test of essentialist categorization – the transformation task – LLMs prioritize teleological properties over information about what something looks like, or is made of. Experiments 1 and 2 find that telos and what something is made of matter more than appearance. Experiment 3 manipulates all three factors and finds that what something is for matters more than what it’s made of. Overall, these studies suggest that language alone may be sufficient to give rise to essentialist beliefs, and that information about what something is for matters more.",
  "full_text": "You are what you’re for: Essentialist categorization in large language models\nSiying Zhang* (syzhang6@stanford.edu), Department of Psychology, Stanford University\nJingyuan S. She* (jshe@haverford.edu), Haverford College\nTobias Gerstenberg(gerstenberg@stanford.edu), Department of Psychology, Stanford University\nDavid Rose(davdrose@stanford.edu), Department of Psychology, Stanford University\n*joint first authors\nAbstract\nHow do essentialist beliefs about categories arise? We hypoth-\nesize that such beliefs are transmitted via language. We sub-\nject large language models (LLMs) to vignettes from the lit-\nerature on essentialist categorization and find that they align\nwell with people when the studies manipulated teleological in-\nformation – information about what something is for. We ex-\namine whether in a classic test of essentialist categorization –\nthe transformation task – LLMs prioritize teleological proper-\nties over information about what something looks like, or is\nmade of. Experiments 1 and 2 find that telos and what some-\nthing is made of matter more than appearance. Experiment 3\nmanipulates all three factors and finds that what something is\nfor matters more than what it’s made of. Overall, these studies\nsuggest that language alone may be sufficient to give rise to\nessentialist beliefs, and that information about what something\nis for matters more.\nKeywords: essentialism; large language models; teleology;\ncategorization; transformation.\nIntroduction\nIf you’re a deep neural network, then rotating a stop sign\nmight make you categorize it as dumbbell or a ratchet\n(Heaven, 2019). A spider on a textured background might\nlook to you like a manhole cover. And a mushroom jutting\nfrom the ground might appear to be a pretzel. But even if\nyou are a human, you rely on visual information in catego-\nrization. Tell a kindergartner that a raccoon has undergone\nsurgery so that it now looks like a skunk and they can’t help\nbut view the thing as a skunk (Keil, 1992). Ask if it would\nstill be a skunk if it’s mommy and daddy were raccoons, or\nif its babies were raccoons and you’ll likely be met with a re-\nsounding “yes”. Why would one say that a raccoon merely\nmade to look like a skunk is now a skunk? In the words of\none kindergartner: “Because it looks like a skunk, it smells\nlike a skunk, it acts like a skunk, and it sounds like a skunk.”\n(Keil, 1992, p. 188) While younger children tend to catego-\nrize things based on what they look like, older children and\nadults often go beyond mere appearance, and take into ac-\ncount more essential properties that really make a thing the\nthing that it is (Medin & Ortony, 1989; Gelman, 2003; Keil,\n1992; Atran, 1995). Essential properties are those that give\nrise to a thing’s identity and make something a member of\na kind. They are the properties we trace and expect to per-\nsist over time, even if a thing’s appearance changes radically\n(Kalish, 1995; Gelman, 2003; Rose & Nichols, 2019, 2020).\nA great deal of evidence suggests that people categorize\nthings on the basis of their essential properties (e.g., Gel-\nman & Wellman, 1991; Gelman, 2003; Keil, 1992; Newman\n& Keil, 2008; Rose & Nichols, 2019, 2020). An important\nquestion is how we come to have essentialist beliefs about\ncategories. One possibility is that language alone gives rise\nto essentialist thinking. How could we test this? Recent ad-\nvances in computational linguistics and artificial intelligence\nmay help. In particular, large language models (LLMs), due\nto their impressive ability of tracking linguistic co-occurrence\npatterns in vast amounts of data, may serve as a test bed for\nexploring whether essentialist beliefs might arise from lan-\nguage input.\nIn recent years, LLMs have achieved impressive perfor-\nmance on tasks like question-answering, sentence comple-\ntion, and coherent article generation (Brown et al., 2020).\nPiantadosi & Hill (2022) argue that LLMs may capture fun-\ndamental aspects of meaning and Weir et al. (2020) find that\nLLMs effectively infer generic concepts given their associ-\nated properties. For instance, they correctly infer “bear” given\n“has fur”, “is big”, and “have claws”. A number of studies\nhave even found that LLMs perform much like humans in eth-\nical (Jiang et al., 2021), abstract (Dasgupta et al., 2022), and\nlogical reasoning (Kojima et al., 2022). That said, many have\nargued that there is a fundamental difference between bench-\nmark successes and real reasoning abilities. For instance,\nLLMs fail in most symbolic reasoning tasks and succeed only\non a context-dependent basis (Talmor et al., 2019), mimic but\nfall short of humans’ inductive reasoning (Han et al., 2022),\nare unable to generalize well to reasoning tasks out of the\ntraining set (Zhang et al., 2022), and struggle to distinguish\nbetween impossible and unlikely real-world events (Kauf et\nal., 2022). Tasks involving reasoning seem to be especially\nchallenging for LLMs. However, essentialist categorization\nneed not involve reasoning. Language alone could fuel it and\nmay be sufficient to form essentialist beliefs.\nOur question is thus: Are LLMs more inclined to catego-\nrize on the basis of essential properties versus more superfi-\ncial properties such as a thing’s visual appearance?\nEssential properties\nWhat kinds of essential properties might be candidates for\nLLMs to draw on in categorization? Here we focus on two:\n1) teleological properties – or what something is for– and 2)\nwhat something is made of.\nTeleological properties Teleological thinking plays a cen-\ntral role in explanation (e.g., Bloom, 2007; Kelemen, 1999;\nKelemen & Rosset, 2009; Kelemen et al., 2013; Lombrozo\n& Carey, 2006; Lombrozo et al., 2007; Lombrozo & Rehder,\n2012; Foster-Hanson & Lombrozo, 2022). We often answer\n‘why’ questions by pointing out goals and purposes. Tele-\nological thinking also plays a role in people’s causal judg-\nments (Rose & Schaffer, 2017) and even matters for people’s\njudgments about whether an object exists, that is, whether\nsome collection of parts composes a whole object, and per-\nsists through changes over time (Rose, 2015; Rose & Schaf-\nfer, 2017; Rose, 2019, 2020; Rose et al., 2020). Rose (2020)\nsuggests that the central role of teleology in explanation and\njudgements of existence and persistence might arise because\nwe essentialize categories in terms of teleology.\nUtilizing classic tests of essentialist thinking, Rose &\nNichols (2019, 2020) provide support for the claim that peo-\nple essentialize a broad range of categories – from artifacts to\nnon-living natural kinds – in terms of teleology. To take just\none example, people think that bees are for making honey\nand spiders are for spinning webs (Rose & Nichols, 2019).\nAnd if a bee undergoes radical transformation so that it now\nlooks like a spider, but preserves the bee telos – that is, it still\nmakes honey – people categorize the creature as a bee. But if\nit instead changes its telos after the transformation to that of a\nspider – spinning webs – people say it’s a spider. It seems that\nwe trace the persistence of a thing’s telos across change. This\nsuggests that teleological properties are treated as essential\nproperties.\nWhat something is made ofOne important view of essen-\ntialism, one that contrasts with teleological essentialism and\nhas dominated the psychological literature for well over three\ndecades, maintains that what something is made of, what it is\nconstituted by, determines its essence (Gelman, 2003; Keil,\n1992). This view is inspired by Kripke (1972) and Putnam\n(1962), who claim that, for instance, the essence of water is\nH2O. This example, that H20 is the essence of water, is a lead-\ning example that animates the view that so called “scientific”\nproperties are the kind of properties that serve as essential\nproperties. It might be that what something is made of plays\nan important role in LLM’s essentialist categorization judg-\nments.\nEssentialized categories These two views not only dis-\nagree on what properties are essentialized but also on what\ncategories are essentialized. Those who maintain that essen-\ntial properties are associated with what something is made of\nalso maintain that only living natural kinds, such as racoons\nor kangaroos, and non-living natural kinds, such as rocks and\nlightning, are essentialized (e.g., Gelman, 2003; Keil, 1992).\nArtifacts, on this view, are not essentialized. Those who\nmaintain that teleological properties are treated as essential\nproperties, hold that living and non-living natural kinds as\nwell as artifacts, such as clocks and hotplates, are essential-\nized (e.g., Rose & Nichols, 2020).\nDo LLMs engage in essentialist categorization?\nOur question is whether LLMs are more inclined to catego-\nrize on the basis of essential properties than on the basis of de-\nscribed appearance. To test this we focus on two main tasks:\n‘transformation tasks’ and ‘nature vs. nurture tasks’. Trans-\nformation tasks involve determining whether something per-\nsists after undergoing changes in properties (e.g., Keil, 1992).\nNature vs. nurture tasks involve determining whether an an-\nimal raised by a different animal would be a member of the\nnew animal category (e.g., Gelman & Wellman, 1991). We\nwill explore LLMs’ categorization judgments on a range of\ndomains, from living and non-living natural kinds to artifacts.\nThe language models we use are OpenAI’s GPT-3 (Brown\net al., 2020) and BigScience’s BLOOM (Scao et al., 2022).\nGPT-3 is one of the best-performing general-purpose lan-\nguage models; BLOOM is the largest open multilingual lan-\nguage model. We begin by testing whether GPT-3 and\nBLOOM categorize things like people do in a set of studies\nthat have investigated essentialist thinking.\nAnalysis of Prior Work\nPlease find links to the pre-registrations, data, and anal-\nyses files here: https://github.com/cicl-stanford/\nessentialism in llms. The goal of this study was to in-\nvestigate whether the outputs from LLMs match those of peo-\nple on a set of experiments aimed at documenting essentialist\nthinking about categories.\nMethods\nMaterials We ran studies from Rose & Nichols (2019,\n2020); Gelman & Wellman (1991); Keil (1992); Waxman et\nal. (2007); Hampton et al. (2007); Barton & Komatsu (1989)\non GPT-3 and BLOOM. These studies were selected because\nthey are representative of work that has used ‘transformation\ntasks’ and ‘nature vs. nurture tasks’ to investigate essentialist\ncategorization across different domains. We also chose these\nstudies because they’re mostly text and relied little, if at all,\non visual stimuli.\nDesign and Procedure We replicated the studies from the\nselected papers as closely as possible. We followed the same\nprocedure and presented all materials from each experiment,\none by one, to both GPT-3 (Model: text-curie-001) and\nBLOOM. For each experimental condition, we queried the\ntwo language models 50 times.\nData Processing GPT-3 and BLOOM return open ended\nresponses. To process these responses, we trained GPT-3 to\nretrieve single-word responses from the full text responses.\nTo do so, we gave GPT-3 a small selection of sentences with\ncorrect item names as training data as part of the prompt. For\neach experiment condition (129 in total), we manually se-\nlected 3 sentences that we judged to be easy (e.g., “A tire.”),\nnormal (e.g.,“In this scenario, the doctors would have a tire.”),\nand difficult (e.g., “If you consider the act of cutting and\nsewing the tire to be the operation, then the doctors ended up\nTable 1: GPT-3 and BLOOM’s degree of alignment with participants’ categorization judgments in prior work. T= transforma-\ntion tasks, N = nature vs. nurture tasks. We marked each model-generated answer as correct or incorrect based on the majority\nchoice in the paper. We calculated accuracy for each study by averaging over all 50 responses generated by the LLMs.\nPaper RN2019 RN2019 RN2020 RN2020 GW1991 GW1991 Keil1992 Waxman2007 Hampton2007 BK1989\nTask T N T N T N T N T T\n# of studies 2 2 2 1 1 2 1 3 1 1\nGPT-3 accuracy 75% 69% 63% 70% 37% 19% 49% 7% 91% 72%\nBLOOM accuracy 48% 48% 59% 65% 75% 40% 42% 27% 68% 2%\nwith a boot. Doctors would see the operation as a success.”).\nWe paired these sentences with the desired single word that\nshould be retrieved (e.g., “tire”). These training data were\nappended to the beginning of the query so that GPT-3 would\nrefer to it and deliver retrieved answers to the new sentences\nthat were fed in. To test that GPT-3 was accurate at extract-\ning responses, we randomly sampled half of the responses\nand have two of the authors checked. GPT-3 performed this\nsingle-word extraction task with 99% accuracy. Responses\nthat weren’t clear, such as, “The things that hatch from the\neggs will be neither bees nor spiders”, were coded as “un-\nsure”.\nResults and Discussion\nTable 1 shows that GPT-3’s judgments were inconsistent with\nthose of human participants in some of the studies. The ex-\nceptions were the studies by Rose & Nichols (2019, 2020),\nHampton et al. (2007) and Barton & Komatsu (1989). Here\nGPT-3’s judgments were closely aligned with those of hu-\nmans. The main difference between the studies where GPT-3\ngave judgments that were inconsistent with humans and those\nconsistent with humans, is that in the cases where GPT-3\ngave consistent judgments teleological information (Rose &\nNichols, 2019, 2020; Barton & Komatsu, 1989) or infor-\nmation about what the things were made of (Barton & Ko-\nmatsu, 1989) was included. The work by Hampton et al.\n(2007) showed very high agreement. This work involved\ncases where an animal changed and now looks and acts like\na different animal. Both LLMs and humans categorize the\nthing as a different animal in that case. But this shouldn’t be\nsurprising. Indeed, this should be viewed as a control given\nthat the animals underwent total transformation.\nExperiment 1: Telos vs. Appearance\nWe found that LLMs made judgments much like people in\ncases where teleological information was provided. In this\nstudy, we continue to investigate what role teleology plays in\nLLM categorization in transformation tasks. We generated\na fresh set of pairs of items from each domain and adapted\nand simplified the transformation vignettes from (Rose &\nNichols, 2019, 2020). Below is the transformation task vi-\ngnette from Rose & Nichols’s (2019) study 1:\nSome very talented and skilled scientists, Suzy and\nAndy, decide that they are going to perform a special op-\neration on a bee. They removed its wings and antennae,\nlengthened its legs and added a new pair of legs. They\nalso inserted into the back of it something for making\nwebs and trained the animal so that it would eat insects.\nOn the same page, participants were then shown images of\na bee and a spider, indicating the thing before and after the\noperation. Participants were then told:\nAfter running some test, they found that the thing after\nthe special operation didn’t [original thing’s telos / new\nthing’s telos]. Instead, it only [new thing’s telos / origi-\nnal thing’s telos].\nThen they were asked: “To what extent do you think that\nthe thing after the special operation is [an original thing / a\nnew thing]?”\nMethods\nMaterials We generated a list of items that we expected to\nhave mutually exclusive purposes. Four items were selected\nfor each domain. Non-living natural kinds: lightning, cloud,\nsun, and soil; Living natural kinds: chicken, cow, worm, and\nbat; Artifacts: bed, microwave, lotion, and keychain. Then\nwe queried GPT-3 about each item’s telos ten times by ask-\ning, for example, “What is the purpose of a chicken?”. We se-\nlected the top mentioned answer (e.g., “A chicken’s purpose\nis to produce eggs.”) as each item’s telos in the subsequent\nexperiment. We used the following template as a prompt:\nSome very talented and skilled scientists decide that they\nare going to perform a special procedure to turn a/an\n[original thing] into a/an [new thing]. After the special\nprocedure, the thing looked like a/an [original thing /\nnew thing]. After running some tests, they found that the\nthing after the special procedure didn’t [original thing’s\ntelos / new thing’s telos]. Instead, it only [new thing’s\ntelos / original thing’s telos].\nDesign Our design was a 2 (Appearance: original, new) ×\n2 (Telos: preserved, changed) × 3 (Domain: living natural\nkind, non-living natural kind, artifact) design.\nTo control for potential order effects, we counterbalanced\nthe order of telos and appearance information in the prompt.\nWe also counterbalanced which item was turned into what.\nThere were 12 possible item pairs in each domain. GPT-3\nand BLOOM received all item pairs within a domain. We\nelicited 5 responses for each pair by condition.\nNon−living natural kind Living natural kind Artifact\noriginal new original new original new\n0%\n25%\n50%\n75%\n100%\nAppearance\nProbability saying\n that it is a new thing\nTelos preserved changed\n(a) GPT-3 Telos vs. Appearance\nNon−living natural kind Living natural kind Artifact\noriginal new original new original new\n0%\n25%\n50%\n75%\n100%\nAppearance\nProbability saying\n that it is a new thing\nMade of preserved changed (b) GPT-3 Insides vs. Appearance\nFigure 1: Experiment 1 and 2.Categorization ratings across all three domains in telos preserved (blue) and telos changed (red)\nconditions(left) and insides preserved (orange) and insides changed (green) conditions(right). The x-axis indicates whether the\nappearance of the thing after the special operation was the same (original) or changed (new).\nWe used the following model setting in this and all follow-\ning experiments. For GPT-3, we used the text-davinci-002\nmodel, set the maximum output tokens to be 50, and used\nthe default setting on everything else (Temperature = 0.7,\nmaximum length = 256, Top p = 1, Frequency penalty = 0,\nPresence penalty = 0, Best of = 1, Show probabilities = off).\nAlthough GPT-3 is able to show probabilities, we decided not\nto use this feature because GPT-3 shows probabilities by to-\nkens not by words. This makes it complicated to compute the\nprobability for single words. For BLOOM, we set the max-\nimum output token to 5, the temperature to 0.7, the length\npenalty to 1.0 and set the random seed to 2022.\nProcedure GPT-3 and BLOOM were given a case that in-\nvolved a thing undergoing a special procedure so that it either\nhad the same or different appearance and had either the orig-\ninal thing’s telos or a different telos. After the vignette, the\nLLMs were asked: “Is the thing after the special operation a\n[original thing] or a [new thing]?”\nHere is an example:\nSome very talented and skilled scientists decide that\nthey are going to perform a special procedure to turn\na chicken into a worm. After the special procedure,\nthe thing looked like a chicken. After running some\ntests, they found that the thing after the special proce-\ndure didn’t produce eggs. Instead, it only helped de-\ncompose organic matter. Is the thing after the special\noperation a chicken or a worm?\nData Processing For the current and all the following stud-\nies, we had two independent coders manually extract item\nnames from the full responses. To guarantee accuracy, we\nasked the coders to check each other’s work and discuss any\ndiscrepancies. For all the unresolved discrepancies, we as-\nsigned “unsure” as the response.\nResults\nFigure 1a shows the proportion of cases in which the model\nsaid that the transformed thing was a new thing as a func-\ntion of appearance and telos, separately for each domain.\nThroughout we analyzed the models’ responses by running\nBayesian logistic regressions using the brms (B¨urkner, 2017)\npackage in R (R Core Team, 2019). We used the emmeans\npackage (Lenth et al., 2019) to analyze differences between\nconditions. We report the medians and 95% credible inter-\nvals of the posterior distributions and call something an effect\nwhen the credible interval excludes 0. Here in Experiment 1,\nwe fit a Bayesian logistic regression model with telos, appear-\nance, and their interaction as predictors.\nAs Table 2 shows, GPT-3 was more inclined to judge that\nsomething was a new thing after the transformation when its\ntelos had changed compared to when its telos was preserved.\nLikewise, for appearance. When something changed its ap-\npearance, GPT-3 was more inclined to judge that it changed\ncategories. The effect of teleology was greater than the ef-\nfect of appearance. And it was greater for artifacts than living\nor non-living natural kinds, and for living natural kinds than\nnon-living natural kinds.\nBLOOM displayed a much weaker and more mixed pat-\ntern. It was also more inclined to judge that something was a\nnew thing when its telos changed. But in contrast to GPT-3,\nchanges in appearance didn’t affect BLOOM’s categorization\nTable 2: Experiment 1: Posterior distributions of the overall\ndifference of telos, the difference of telos across domains, the\ndifference in appearance and the difference between telos and\nappearance for GPT-3 and BLOOM. The values show medi-\nans with 95% credible intervals in brackets.\nGPT-3 Bloom\nTelos .80[.77, .83] .15[.11, .21]\nartifacts - living natural kinds .19[.12, .25] .04[−.06, .16]\nartifacts - non-living natural kinds .31[.24, .37] .04[−.07, .16]\nliving natural kinds - non-living natural kinds.12[.05, .18] .0[−.11, .11]\nAppearance .11[.09, .14] .06[.00, .10]\nTelos - Appearance .68[.64, .72] .09[.03, .16]\njudgments. The effect of teleology was greater than the effect\nof appearance. But the effect of teleology was not greater for\nany domain.\nDiscussion\nTeleological considerations play a role in LLMs categoriza-\ntion judgments when considering things that undergo radical\ntransformation. This was clearly the case for GPT-3 and less\nso for Bloom. Transformation tasks provide some of the best\nevidence of essentialist thinking. And given that GPT-3 heav-\nily relies on teleological considerations when judging cat-\negory membership across transformation, this suggests that\nlanguage models, like GPT-3, might be more inclined to take\ninto account essential properties, in this case, teleological\nproperties, than appearance in categorization. And interest-\ningly, though teleological considerations play the most pow-\nerful role in GPT-3’s judgments about artifacts undergoing\ntransformation, they also affect the categorization of non-\nliving and living natural kinds. Across a range of things,\nGPT-3 places heavy weight on teleological considerations.\nExperiment 2: Insides vs. Appearance\nExperiment 1 indicates that teleological considerations play a\nrole in essentialist categorization. But another view of essen-\ntial properties has it that what something is made of, what it is\nconstituted by, determines its essence. In this pre-registered\nstudy, we examine how LLMs respond when what something\nis made of changes or is preserved after transformation.\nMethods\nMaterials We used the same list of items as in Experi-\nment 1. We queried GPT-3 about what each item was made\nof (e.g., according to GPT-3, “Lightning is made of electrons,\nprotons and other charged particles.”) and then used that to\nvary what the things were made of in our experiment. We\nused the same vignette template but replaced telos informa-\ntion with “made of” information.\nDesign and Procedure The design and the procedure were\nthe same as in Experiment 1.\nResults\nFigure 1b shows the LLMs’ categorizations as a function of\nappearance and whether what it was made of was preserved or\nchanged, separately for the three different domains. The re-\nsults in Table 3 show that GPT-3 was more inclined to judge\nthat something that changed what it was made of was now a\nnew thing. Appearance, again, also mattered. However, what\nsomething was made of had a greater effect on categorization\nthan appearance. The effect of what something was made of\nwas greater for artifacts than living natural kinds but no differ-\nent between artifacts and non-living natural kinds. The effect\nwas smaller for living kinds than non-living natural kinds.\nBLOOM, as in Experiment 1, displayed a much weaker\nand more mixed pattern. It judged that something that\nchanged what it was made of changed categories. Appear-\nance had no effect. What something was made of didn’t have\nTable 3: Experiment 2: Posterior distributions of the overall\ndifference of “made of”, the difference of “made of” across\ndomains, the difference in appearance and the difference be-\ntween “made of” and appearance for GPT-3 and BLOOM.\nThe values show medians with 95% credible intervals in\nbrackets.\nGPT3 Bloom\nMade of .46[.42, .50] .08[.03, .12]artifacts - living natural kinds .17[.08, .25] .05[−.05, .16]artifacts - non-living natural kinds−.06[−.15, .02] −.04[−.16, .05]living natural kinds - non-living natural kinds−.23[−.32,−.14] −.11[−.22, .01]Appearance .26[.22, .30] .04[.00, .09]Made of - Appearance .20[.14, .25] .04[−.02, .10]\na greater effect on categorization than appearance and what\nsomething was made of was no different across domains.\nDiscussion\nExperiment 1 showed that teleological considerations play an\nimportant role in LLMs’ categorization. Here, we found that\nwhat something is made of also matters. In our final experi-\nment, we directly pit appearance, telos, and what something is\nmade of against one another to see what factor most strongly\naffects LLMs’ categorizations.\nExperiment 3: Telos, Insides & Appearance\nIn this last study, we combined both telos and “made of”\ninformation in the prompts to test whether LLMs favor one\ntype of information over the other when determining cate-\ngory membership. Our experiment varies whether a thing has\npreserved or changed appearance, preserved or changed what\nit is made of, and preserved or changed its telos across trans-\nformations.\nMethods\nMaterials We continued to use all items that were included\nin Experiment 1 and 2. The prompts were extended by in-\ncluding both telos and ‘made of’ information.\nDesign and Procedure Our design was a 2 (Appearance:\noriginal, new) × 2 (Telos: preserved, changed) × 2 (Made\nof: preserved, changed) × 3 (Domain: living natural kind,\nnon-living natural kind, artifact) design. The procedure was\nthe same as in Experiment 1 and 2.\nResults and Discussion\nFigure 2 shows GTP-3’s categorizations as a function of the\nmanipulated factors. As Table 4) shows, we found for GPT-3\nthat across all domains, the effect of teleology was greater\nthan the effect of what something was made of. And the effect\nof what something was made of was greater than appearance.\nBLOOM again presented a weaker, more mixed set of results.\nThe effect of teleology was only greater than what something\nwas made of for artifacts and no different for the other kinds.\nThe effect of what something was made of was greater than\nappearance for both artifacts and non-living natural kinds.\nNon−living natural kind Living natural kind Artifact\nNew appearanceOriginal appearance\npreserved changed preserved changed preserved changed\n0%\n25%\n50%\n75%\n100%\n0%\n25%\n50%\n75%\n100%\nMade of\nProbability saying it is a new thing\nTelos preserved changed\nFigure 2: Experiment 3: GPT-3 categorization ratings across\ntelos (preserved/changed) and made of (preserved/changed)\nconditions, separated by domain (columns) and appearance\ntype (rows).\nGeneral Discussion\nPeople don’t categorize things based only on their appear-\nance. They also take into account essential properties. We\nsuggested that language alone may be sufficient to commu-\nnicate such essential properties. We tested this by asking\nwhether LLMs, such as GPT-3 and BLOOM, categorize on\nthe basis of essential properties versus on the basis of a thing’s\ndescribed appearance.\nWe focused on two candidate essential properties: teleo-\nlogical properties and what something is made of. In Exper-\niment 1, we found that teleological considerations played a\ngreater role than appearance in GPT-3’s categorization judg-\nments. We also found, in Experiment 2, that what some-\nthing is made of played a greater role than what it looked\nlike. Experiment 3 pitted all factors against one another. We\nfound that teleological considerations carried more weight\nthan what something was made of, and that what something\nwas made of mattered more than its appearance. This sug-\ngests that GPT-3 prioritizes teleological properties in essen-\ntialist categorization.\nBLOOM delivered judgments that were weaker and more\nvaried than GPT-3. This isn’t surprising. GPT-3 is state-of-art\nTable 4: Experiment 3: Posterior distributions of the dif-\nference of telos effect and “made of” and the difference in\n“made of” and appearance across domains. The values show\nmedians with 95% credible intervals in brackets.\nGPT-3 Bloom\nTelos - Made of\nartifacts .74[.70, .80] .12[.04, .20]\nliving natural kinds .59[.54, .64] .06[−.01, .14]\nnon-living natural kinds.07[.02, .13] .05[−.03, .12]\nMade of - appearance\nartifacts .14[.09, .19] .17[.09, .25]\nliving natural kinds .14[.09, .19] .13[.05, .20]\nnon-living natural kinds.43[.37, .48] −.05[−.13, .03]\nand BLOOM, while having the virtue of being open source, is\nmuch more unwieldy. For instance, in querying BLOOM, one\nneeds to set serious restrictions on it to prevent it from gener-\nating rambling, borderline incoherent, book length responses.\nIn doing so, most of its responses tend to be “unsure”. Thus,\nthe results from BLOOM should be interpreted with caution.\nIn GPT-3, teleological information strongly affects how it\ncategorizes things. This provides evidence supporting the\nidea that language itself may be sufficient for transmitting\nessentialist beliefs, and that information about what some-\nthing is for may be particularly important. The fact that\nwhat something is for mattered more than what it’s made of\nwhen both are directly pitted against one another also bears\non a recent objection raised about teleological essentialism\n(Neufeld, 2021). Teleology, as the objection goes, only serves\nas a cue about insides, what something is made of, and it\nis this, not teleology, that ultimately matters in categoriza-\ntion (see also Joo & Yousif, 2022). However, we found that,\nat least for LLMs, teleology carries more weight than what\nsomething is made of even when both factors are directly pit-\nted against one another. Moreover, in our vignettes, we ex-\nplicitly stated what a thing’s telos was and what it was made\nof. This way, the concern that changes in a thing’s telos might\naffect inferences about what its made of doesn’t apply in our\ncase. We found overall that appearance had a weaker influ-\nence on categorization than information about telos and what\nthe thing was made of. This effect is particularly striking\nsince, for appearance, we directly stated what it looked like\nby using the category label (e.g. “After the special procedure,\nthe thing looked like a chicken.”) rather than only describ-\ning the differences in visual appearance (e.g. “the thing has\nfeathers and a beak.”).\nThe claim that LLMs categorize based on essential prop-\nerties is surprising. It might seem instead that mere diagnos-\nticity plays a role in LLMs categorization. But there is good\nreason for maintaining that LLMs are categorizing based on\nessences. Transformations are the classic, and arguably best,\ntest of essentialist thinking. Judging that something persists\nacross radical change provides good evidence that we treat\nthe persistence of those properties as essential. LLMs do this.\nSo this suggests they categorize on the basis of essences. Still\nthe fact that LLMs categorize based on essential properties\nsuggests that language alone transmits essentialist beliefs. Of\ncourse, this doesn’t tell us which aspects of language lead to\nessentialism. Our future work aims to address this.\nConclusion\nLanguage serves as an important vehicle for how beliefs\nabout the world are transmitted. When LLMs are asked to\ncategorize things, they don’t just care about what it looks like,\nthey care about essential properties, too. And when different\ncandidates for essential properties are pitted against one an-\nother, we find that what something is for matters more than\nwhat it’s made of. The language we learn appears to treat,\nand favor, teleological properties as essential properties.\nAcknowledgments\nTobias Gerstenberg was supported by a research grant from\nthe Stanford Institute for Human-Centered Artificial Intelli-\ngence (HAI). David Rose was supported by a Stanford Inter-\ndisciplinary Graduate Fellowship.\nReferences\nAtran, S. (1995). Causal constraints on categories and cate-\ngorical constraints on biological reasoning across cultures.\nCausal cognition: A multidisciplinary debate (pp. 205–\n233)..\nBarton, M. E., & Komatsu, L. K. (1989). Defining features\nof natural kinds and artifacts. Journal of Psycholinguistic\nResearch, 18(5), 433–447.\nBloom, P. (2007). Religion is natural. Developmental sci-\nence, 10(1), 147–151.\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D.,\nDhariwal, P., . . . Amodei, D. (2020). Language models are\nfew-shot learners. In H. Larochelle, M. Ranzato, R. Had-\nsell, M. Balcan, & H. Lin (Eds.),Advances in neural infor-\nmation processing systems(V ol. 33, pp. 1877–1901). Cur-\nran Associates, Inc.\nB¨urkner, P.-C. (2017). brms: An R package for Bayesian\nmultilevel models using Stan. Journal of Statistical Soft-\nware, 80(1), 1–28.\nDasgupta, I., Lampinen, A. K., Chan, S. C. Y ., Creswell, A.,\nKumaran, D., McClelland, J. L., & Hill, F. (2022). Lan-\nguage models show human-like content effects on reason-\ning. ArXiv, abs/2207.07051.\nFoster-Hanson, E., & Lombrozo, T. (2022). What are\nmen and mothers for? the causes and consequences of\nfunctional reasoning about social categories. In Proceed-\nings of the annual meeting of the cognitive science society\n(V ol. 44).\nGelman, S. A. (2003). The essential child: Origins of es-\nsentialism in everyday thought. Oxford Series in Cognitive\nDevelopment.\nGelman, S. A., & Wellman, H. M. (1991). Insides and\nessences: Early understandings of the non-obvious. Cog-\nnition, 38(3), 213–244.\nHampton, J. A., Estes, Z., & Simmons, S. (2007). Meta-\nmorphosis: Essence, appearance, and behavior in the cat-\negorization of natural kinds. Memory & Cognition, 35(7),\n1785–1800.\nHan, S. J., Ransom, K., Perfors, A., & Kemp, C. (2022).\nHuman-like property induction is a challenge for large lan-\nguage models. In Proceedings of the annual meeting of the\ncognitive science society(V ol. 44).\nHeaven, D. (2019). Deep trouble for deep learning. Nature,\n574(7777), 163–166.\nJiang, L., Hwang, J. D., Bhagavatula, C., Bras, R. L., Forbes,\nM., Borchardt, J., . . . Choi, Y . (2021). Delphi: Towards\nmachine ethics and norms.\nJoo, S., & Yousif, S. R. (2022). Are we teleologically essen-\ntialist? Cognitive Science, 46(11), e13202.\nKalish, C. W. (1995). Essentialism and graded membership\nin animal and artifact categories. Memory & Cognition,\n23(3), 335–353.\nKauf, C., Ivanova, A. A., Rambelli, G., Chersoni, E., She,\nJ. S., Chowdhury, Z., . . . Lenci, A. (2022). Event knowl-\nedge in large language models: the gap between the impos-\nsible and the unlikely. ArXiv, abs/2212.01488.\nKeil, F. C. (1992). Concepts, kinds, and cognitive develop-\nment. mit Press.\nKelemen, D. (1999). Why are rocks pointy? children’s pref-\nerence for teleological explanations of th natural world.\nDevelopmental psychology, 35(6), 1440.\nKelemen, D., & Rosset, E. (2009). The human function com-\npunction: Teleological explanation in adults. Cognition,\n111(1), 138–143.\nKelemen, D., Rottman, J., & Seston, R. (2013). Professional\nphysical scientists display tenacious teleological tenden-\ncies: Purpose-based reasoning as a cognitive default. Jour-\nnal of experimental psychology: General, 142(4), 1074.\nKojima, T., Gu, S. S., Reid, M., Matsuo, Y ., & Iwasawa, Y .\n(2022). Large language models are zero-shot reasoners.\nIn A. H. Oh, A. Agarwal, D. Belgrave, & K. Cho (Eds.),\nAdvances in neural information processing systems.\nKripke, S. A. (1972). Naming and necessity. In Semantics of\nnatural language(pp. 253–355). Springer.\nLenth, R., Singmann, H., Love, J., Buerkner, P., & Herve, M.\n(2019). Package ‘emmeans’.\nLombrozo, T., & Carey, S. (2006). Functional explanation\nand the function of explanation. Cognition, 99(2), 167–\n204.\nLombrozo, T., Kelemen, D., & Zaitchik, D. (2007). Inferring\ndesign: Evidence of a preference for teleological explana-\ntions in patients with alzheimer’s disease. Psychological\nScience, 18(11), 999–1006.\nLombrozo, T., & Rehder, B. (2012). Functions in biological\nkind classification. Cognitive psychology, 65(4), 457–485.\nMedin, D., & Ortony, A. (1989). Psychological essentialism.\nSimilarity and analogical reasoning, 179–195.\nNeufeld, E. (2021). Against teleological essentialism. Cog-\nnitive Science, 45(4), e12961.\nNewman, G. E., & Keil, F. C. (2008). Where is the essence?\ndevelopmental shifts in children’s beliefs about internal\nfeatures. Child development, 79(5), 1344–1356.\nPiantadosi, S., & Hill, F. (2022). Meaning without reference\nin large language models. In Neurips 2022 workshop on\nneuro causal and symbolic ai (ncsi).\nPutnam, H. (1962). The analytic and the synthetic.\nR Core Team. (2019). R: A language and environment for sta-\ntistical computing [Computer software manual]. Vienna,\nAustria.\nRose, D. (2015). Persistence through function preservation.\nSynthese, 192(1), 97–146.\nRose, D. (2019). 14 cognitive science for the revisionary\nmetaphysician. Metaphysics and Cognitive Science.\nRose, D. (2020). Mentalizing objects. Oxford Studies in\nExperimental Philosophy.\nRose, D., & Nichols, S. (2019). Teleological essentialism.\nCognitive Science, 43(4), e12725.\nRose, D., & Nichols, S. (2020). Teleological essentialism:\ngeneralized. Cognitive science, 44(3), e12818.\nRose, D., & Schaffer, J. (2017). Folk mereology is teleologi-\ncal. Experimental metaphysics, 135–186.\nRose, D., Schaffer, J., & Tobia, K. (2020). Folk teleology\ndrives persistence judgments. Synthese, 197(12), 5491–\n5509.\nScao, T. L., Fan, A., Akiki, C., Pavlick, E.-J., Ili’c,\nS., Hesslow, D., . . . Wolf, T. (2022). Bloom: A\n176b-parameter open-access multilingual language model.\nArXiv, abs/2211.05100.\nTalmor, A., Elazar, Y ., Goldberg, Y ., & Berant, J. (2019).\nolmpics-on what language model pre-training captures.\nTransactions of the Association for Computational Lin-\nguistics, 8, 743-758.\nWaxman, S., Medin, D., & Ross, N. (2007). Folkbiological\nreasoning from a cross-cultural developmental perspective:\nearly essentialist notions are shaped by cultural beliefs.De-\nvelopmental psychology, 43(2), 294.\nWeir, N., Poliak, A., & Durme, B. V . (2020). Probing neural\nlanguage models for human tacit assumptions. In S. Deni-\nson, M. Mack, Y . Xu, & B. C. Armstrong (Eds.),Proceed-\nings of the 42th annual meeting of the cognitive science\nsociety - developing a mind: Learning in humans, ani-\nmals, and machines, cogsci 2020, virtual, july 29 - august\n1, 2020.cognitivesciencesociety.org.\nZhang, H., Li, L. H., Meng, T., Chang, K.-W., & den Broeck,\nG. V . (2022). On the paradox of learning to reason from\ndata. ArXiv, abs/2205.11502.",
  "topic": "Essentialism",
  "concepts": [
    {
      "name": "Essentialism",
      "score": 0.9613075256347656
    },
    {
      "name": "Categorization",
      "score": 0.871970534324646
    },
    {
      "name": "Teleology",
      "score": 0.7576684951782227
    },
    {
      "name": "Argument (complex analysis)",
      "score": 0.5880070924758911
    },
    {
      "name": "Epistemology",
      "score": 0.5193518400192261
    },
    {
      "name": "Telos",
      "score": 0.45601537823677063
    },
    {
      "name": "Psychology",
      "score": 0.3308291733264923
    },
    {
      "name": "Philosophy",
      "score": 0.22258728742599487
    },
    {
      "name": "Chemistry",
      "score": 0.07678452134132385
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I155707491",
      "name": "Haverford College",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I97018004",
      "name": "Stanford University",
      "country": "US"
    }
  ]
}