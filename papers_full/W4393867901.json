{
    "title": "Evaluating large language models as agents in the clinic",
    "url": "https://openalex.org/W4393867901",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2223262429",
            "name": "Nikita Mehandru",
            "affiliations": [
                "University of California, Berkeley",
                "Hearst (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A4316189112",
            "name": "Brenda Y. Miao",
            "affiliations": [
                "University of California, San Francisco"
            ]
        },
        {
            "id": "https://openalex.org/A2983036355",
            "name": "Eduardo Rodriguez Almaraz",
            "affiliations": [
                "University of California, San Francisco"
            ]
        },
        {
            "id": "https://openalex.org/A2624037926",
            "name": "Madhumita Sushil",
            "affiliations": [
                "University of California, San Francisco"
            ]
        },
        {
            "id": "https://openalex.org/A284454978",
            "name": "Atul J. Butte",
            "affiliations": [
                "University of California, San Francisco"
            ]
        },
        {
            "id": "https://openalex.org/A2417429699",
            "name": "Ahmed Alaa",
            "affiliations": [
                "University of California, Berkeley",
                "Hearst (United States)",
                "University of California, San Francisco"
            ]
        },
        {
            "id": "https://openalex.org/A2223262429",
            "name": "Nikita Mehandru",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4316189112",
            "name": "Brenda Y. Miao",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2983036355",
            "name": "Eduardo Rodriguez Almaraz",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2624037926",
            "name": "Madhumita Sushil",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A284454978",
            "name": "Atul J. Butte",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2417429699",
            "name": "Ahmed Alaa",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W6852248262",
        "https://openalex.org/W4385573087",
        "https://openalex.org/W6778883912",
        "https://openalex.org/W4360836968",
        "https://openalex.org/W4361289889",
        "https://openalex.org/W4367678142",
        "https://openalex.org/W4360891289",
        "https://openalex.org/W4367191144",
        "https://openalex.org/W4387835442",
        "https://openalex.org/W4379539325",
        "https://openalex.org/W4318765555",
        "https://openalex.org/W3164718925",
        "https://openalex.org/W2171433196",
        "https://openalex.org/W2782837275",
        "https://openalex.org/W2150704630",
        "https://openalex.org/W2140491322",
        "https://openalex.org/W3187869944",
        "https://openalex.org/W4383223222",
        "https://openalex.org/W4313439128",
        "https://openalex.org/W2155736799",
        "https://openalex.org/W6860299292",
        "https://openalex.org/W4385381606",
        "https://openalex.org/W4384071683",
        "https://openalex.org/W4389519072",
        "https://openalex.org/W3087893815",
        "https://openalex.org/W4389524506",
        "https://openalex.org/W4389173934",
        "https://openalex.org/W3159623667"
    ],
    "abstract": "Recent developments in large language models (LLMs) have unlocked opportunities for healthcare, from information synthesis to clinical decision support. These LLMs are not just capable of modeling language, but can also act as intelligent “agents” that interact with stakeholders in open-ended conversations and even influence clinical decision-making. Rather than relying on benchmarks that measure a model’s ability to process clinical data or answer standardized test questions, LLM agents can be modeled in high-fidelity simulations of clinical settings and should be assessed for their impact on clinical workflows. These evaluation frameworks, which we refer to as “Artificial Intelligence Structured Clinical Examinations” (“AI-SCE”), can draw from comparable technologies where machines operate with varying degrees of self-governance, such as self-driving cars, in dynamic environments with multiple stakeholders. Developing these robust, real-world clinical evaluations will be crucial towards deploying LLM agents in medical settings.",
    "full_text": "npj |digital medicine Comment\nPublished in partnership with Seoul National University Bundang Hospital\nhttps://doi.org/10.1038/s41746-024-01083-y\nEvaluating large language models as agents\nin the clinic\nNikita Mehandru, Brenda Y. Miao, Eduardo Rodriguez Almaraz, Madhumita Sushil,\nAtul J. Butte & Ahmed Alaa\n Check for updates\nRecent developments in large language models\n(LLMs) have unlocked opportunities for healthcare,\nfrom information synthesis to clinical decision\nsupport. These LLMs are not just capable of\nmodeling language, but can also act as intelligent\n“agents” that interact with stakeholders in open-\nended conversations and even inﬂuence clinical\ndecision-making. Rather than relying on\nbenchmarks that measure a model’s ability to\nprocess clinical data or answer standardized test\nquestions, LLM agents can be modeled in high-\nﬁdelity simulations of clinical settings and should be\nassessed for their impact on clinical workﬂows.\nThese evaluation frameworks, which we refer to as\n“Artiﬁcial Intelligence Structured Clinical\nExaminations” (“AI-SCE”), can draw from\ncomparable technologies where machines operate\nwith varying degrees of self-governance, such as\nself-driving cars, in dynamic environments with\nmultiple stakeholders. Developing these robust,\nreal-world clinical evaluations will be crucial\ntowards deploying LLM agents in medical settings.\nThe release of ChatGPT, a chatbotpowered by a large language model\n(LLM), has brought LLMs into the spotlight and unlocked opportunities for\ntheir use in healthcare settings. Med-PaLM 2, Google’s medical LLM, was\nfound to consistently perform at a human expert level on medical exam-\nination questions scoring 85%\n1. While this model, part of Google’s family of\nfoundation models known as MedLM, areﬁne-tuned for the healthcare\nindustry, even large LLMs trained on openly available information from the\nInternet, not just biomedical information, have immense potential to\nimprove and augment clinical workﬂows\n2– 4. For instance, the Generative\nPre-trained Transformer-4 (GPT-4) model can generate summaries of\nphysician– patient encounters from transcripts of conversations5,a c h i e v ea\nscore of 86% on the United States Medical Licensing Examination\n(USMLE)\n6, and create clinical question-answer pairs that are largely indis-\ntinguishable from human-generated USMLE questions7. These early\ndemonstrations of GPT-4 and other LLMs on clinical tasks and benchmarks\nsuggest that these models have the potential to improve and automate\naspects of clinical tasks.\nHowever, the emergent capabilities of LLMs have signiﬁcantly\nexpanded their potential beyond conventional, standardized clinical natural\nlanguage processing (NLP) tasks that primarily revolve around text pro-\ncessing and question answering. Instead, there is a growing emphasis on\nutilizing LLMs for more complex physician- and patient-facing tasks that\nmay involve multi-step information synthesis, use of external data sources,\nhigh-level reasoning, or even simulation of clinical text and conversations\n8,9.\nIn these scenarios, LLMs should not be viewed as models of language,\nb u tr a t h e ra si n t e l l i g e n t“agents” that have internal planning capabilities that\nallow them to perform complex, multi-step reasoning or interact with tools,\ndatabases, other agents, or external users to better respond to user\nrequests\n9,10. Here, we discuss how LLM agents can be used in clinical settings,\nand challenges to the development and evaluation of these approaches.\nDevelopment of LLM agents for clinical use\nLLM agents can be developed for a variety of clinical use cases by providing\nthe LLM access to different sources of information and tools, including\nclinical guidelines, databases containing electronic health records, clinical\ncalculators, or other curated clinical software tools\n9,10. These agents can\nrespond to user requests by autonomously identifying and retrieving rele-\nvant information, or performing multi-step analyses to answer questions,\nmodel data, or produce visualizations. Different agents can also even interact\nand collaborate with each other in“multi-agent” settings to identify or check\nproposed solutions to difﬁcult problems, or to model medical conversations\nand decision-making processes\n11.\nHealthcare systems are already adopting LLMs capable of powering\nclinical agents; for instance, UC San Diego Health is working to integrate\nGPT-4 into MyChart, Epic’s online health portal, to streamline patient\nmessaging\n12. Patients also leverage publicly available chatbots (such as\nChatGPT) to better understand medical vocabulary from clinical notes, and\nsome medical centers are exploring a“virtual-ﬁrst” approach where LLMs\nassist in patient triaging\n13,14. When connected to additional sources of\ninformation and tools, the versatility and adaptability of clinical agents make\nthem well-suited in supporting both routine administrative tasks as well as\nclinical decision support.\nClinical simulations using agent-based modeling (ABM)\nTo evaluate the utility and safety of LLM-based chatbots as agents in these\napplications, we suggest the use of benchmarks that are not conﬁned to\ntraditional, narrowly-scoped assessments based on NLP benchmarks, which\nconsist of predetermined inputs and ground-truths. Instead, approaches\nfrom agent-based modeling (ABM)\n15 can be used to create a simulated\nenvironment for effective evaluati o no fL L M sa g e n t s .A B Mi sac o m p u t a -\ntional framework that simulates the actions and interactions of autonomous\nagents to provide insights into system-level behavior and outcomes. This\napproach has been used in health policy, biology, and the social sciences to\nconduct studies that simulate health behaviors and the spread of infectious\ndiseases\n16,17.\nnpj Digital Medicine|            (2024) 7:84 1\n1234567890():,;\n1234567890():,;\nABM has also been used to evaluateautonomous agents in the domain\nof self-driving cars18.I nt h i sﬁeld, simulations of real-world environments\ncontaining road obstacles, trafﬁc signals, other cars, and pedestrians can be\nused to evaluate and reﬁne the behaviors of autonomous vehicle agents as\nthey encounter these different elements19. Similarly, by simulating the\nclinical settings where LLM agents may be deployed, including patient-\nphysician interactions and hospital processes, we can use an ABM approach\nto evaluate how an LLM agent may interact with users, which tools or data\nan LLM employs to carry out user requests, and points of failure that lead to\nerroneous outputs or downstream errors.\nInterestingly, patients and physicians can also be simulated as LLM\nagents in ABM environments. Previous research has demonstrated the\nfeasibility of employing LLMs to create“interactive simulacra” that replicate\nhuman behavior\n9– 11. To develop these high-ﬁdelity simulations, data on\nphysician and patient behavior can bederived from real-world electronic\nhealth records or clinical trial data, ideally with validation from multiple\nhospital systems, and encompassing diverse patient populations. De-\nidentiﬁed datasets (e.g., MIMIC-IV, UCSF Information Commons) or\nfederated learning approaches can be used to help protect patient\nprivacy\n20,21.\nEvaluating agent-based simulations using an AI-SCE\nframework\nSimilar to standards and regulations for the autonomous driving industry,\nidentifying robust clinical guidelines and what constitutes a successful\ninteraction for healthcare LLM agents will be crucial towards fulﬁlling the\nlong-term goals of patients, providers, and other clinical stakeholders. In\nmedical education, there has been a shift from assessing students using\nstandardized testing which evaluates shallow clinical reasoning to modern\ncurricula which increasingly use Objective Structured Clinical Examination\n(OSCE)\n22. These exams assess a student’s practical skills in the clinic,\nincluding the ability to examine patients, take clinical histories, commu-\nnicate effectively, and handle unexpected situations. Google recently\ndeveloped Articulate Medical Intelligence Explorer (AMIE), a research AI\nsystem for diagnostic medical reasoning and conversations, which was\nevaluated against the performance of primary care physicians (PCPs) in the\nstyle of an OSCE\n23.\nCurrent benchmarks for clinical NLP, including MedQA (USMLE-\nstyle questions) and MedNLI, test if two clinical statements logically follow\neach other and are often also derived from standardized tests or curated\nc l i n i c a lt e x t .T h i si n f o r m a t i o n ;h o w e v e r ,i sn o tas u fﬁcient metric because it\nfails to capture the full range of capabilities demonstrated by clinical LLM\nagents\n24,25. As a result, we call for the development of Artiﬁcial Intelligence\nStructured Clinical Examinations (AI-SCEs) that can be used to assess the\nability for LLMs to aid in real-world clinical workﬂows. These AI-SCE\nbenchmarks, which may be derived from difﬁcult clinical scenarios or from\nreal-world clinical tasks, should be created with input from interdisciplinary\nteams of clinicians, computer scientists, and medical researchers. OSCEs\ntypically consist of long lists of processes or diagnoses students are graded\non. Similarly, AI-SCE benchmarks would extend beyond traditional com-\nputer science metrics, such as BLEU or ROUGE scores, that often do not\naccount for semantic meaning, and would draw from preexisting multi-turn\nbenchmarks\n26.\nT h eA I - S C Ef o r m a ts h o u l db eu s e dt oe v a l u a t eb o t ht h eo u t p u t so f\nhigh-ﬁdelity agent simulations, and intermediate steps that capture the\nagent’s reasoning process, tool usage, data curation, or interactions with\nother agents or external users. Thus, a valuable contribution of these agents\nis their ability to provide interpretability throughout the decision-making\nprocess, as opposed to at theﬁnal step\n27. These evaluations can also capture\nhow systematic addition or removal of LLM agents affects overall outcomes.\nThese evaluations should be used to inform guardrails for clinical LLMs,\nwhich have been developed for general-purpose models to constrain their\nbehavior\n28.\nOne added complexity of assessing agents using an AI-SCE format is\nthe complicated nature of many clinical tasks, where there may not be\nperfect concordance with individualhuman evaluators. We emphasize the\ncontinued need for a panel of human evaluators, and the importance of\ntesting agent outcomes on external datasets. We also recognize the\nimportance of post-deployment monitoring to ensure data distribution\nshifts do not occur over time, and to mitigate bias in model performance\n25.\nFurthermore, randomized control trials (RCTs) should be conducted to\ncompare how well these simulation environments capture real-world set-\ntings, as well as the real-world impact of LLM agents in augmenting clinical\nworkﬂows.\nAs LLMs evolve and demonstrate increasingly advanced cap-\nabilities, their involvement in clinical practice will extend beyond\nlimited text processing tasks\n29. In the near future, it may become\nnecessary to shift our benchmarks from static datasets to dynamic\nsimulation environments and transition from language modeling to\nagent modeling. Drawing inspiration fromﬁelds such as biology and\neconomics could be beneﬁcial for future LLM research and develop-\nment for clinical applications.\nNikita Mehandru 1,6, Brenda Y. Miao2,6,\nEduardo Rodriguez Almaraz 3,4,6, Madhumita Sushil 2,\nAtul J. Butte 2,5 &A h m e dA l a a1,2\n1University of California, Berkeley, 2195 Hearst Ave, Warren Hall Suite,\n120C, Berkeley, CA, USA.2Bakar Computational Health Sciences Institute,\nUniversity of California San Francisco, San Francisco, CA, USA.\n3Neurosurgery Department Division of Neuro-Oncology, University of\nCalifornia San Francisco, 400 Parnassus Avenue, 8thﬂoor, RM A808, San\nFrancisco, CA, USA.4Department of Epidemiology and Biostatistics,\nUniversity of California San Francisco, 400 Parnassus Avenue, 8thﬂoor,\nRM A808, San Francisco, CA, USA.5Department of Pediatrics, University\nof California San Francisco, San Francisco, CA, USA.6These authors\ncontributed equally: Nikita Mehandru, Brenda Y. Miao, Eduardo Rodriguez\nAlmaraz.\ne-mail: amalaa@berkeley.edu\nReceived: 25 August 2023; Accepted: 22 March 2024;\nReferences\n1. Singhal, et al. Towards expert-level medical question answering with large language models.\nPreprint athttps://arxiv.org/abs/2305.09617 (2023).\n2. Agrawal, M., Hegselmann, S., Lang, H., Kim, Y. & Sontag, D. Large Language Models are Few-\nShot Clinical Information Extractors. In2022 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP). 1998–2022 (ACL, 2022).\n3. Brown, T. B. et al. Language Models are Few-Shot Learners.In Proc. NeurIPS 2020. (2020).\n4. Bubeck, S. et al. Sparks of Artiﬁcial General Intelligence: Early experiments with GPT-4 Preprint\nat https://doi.org/10.48550/arXiv.2303.12712 (2023).\n5. Lee, P., Bubeck, S. & Petro, J. Beneﬁts, Limits, and Risks of GPT-4 as an AI Chatbot for\nMedicine. N. Engl. J. Med.388, 1233– 1239 (2023).\n6. Fleming, S. L. et al. Assessing the Potential of USMLE-Like Exam Questions Generated by GPT-\n4. 2023.04.25.23288588. Preprint athttps://doi.org/10.1101/2023.04.25.23288588 (2023).\n7. Nori, H., King, N., McKinney, S. M., Carignan, D. & Horvitz, E. Capabilities of GPT-4 on Medical\nChallenge Problems. Preprint athttps://doi.org/10.48550/arXiv.2303.13375 (2023).\n8. Dash, D. et al. Evaluation of GPT-3.5 and GPT-4 for supporting real-world information needs in\nhealthcare delivery. Preprint athttps://doi.org/10.48550/arXiv.2304.13714 (2023).\n9. Park, J. S. et al. Generative Agents: Interactive Simulacra of Human Behavior. In36th\nSymposium on User Interface Software and Technology (UIST).1 – 22 (ACM, 2023).\n10. Yang, H., Yue, S. & He, Y. Auto-GPT for Online Decision Making: Benchmarks and Additional\nOpinions. Preprint athttps://doi.org/10.48550/arXiv.2306.02224 (2023).\nnpj |digital medicine Comment\nnpj Digital Medicine|            (2024) 7:84 2\n11. Johri, S. et al. Testing the Limits of Language Models: A Conversational Framework for Medical\nAI Assessment.medRxiv https://www.medrxiv.org/content/10.1101/2023.09.12.\n23295399v2 (2023).\n12. Introducing Dr. Chatbot (2023).https://today.ucsd.edu/story/introducing-dr-chatbot.\n13. Levine, D. M. et al. The Diagnostic and Triage Accuracy of the GPT-3 Artiﬁcial Intelligence\nModel. Preprint athttps://doi.org/10.1101/2023.01.30.23285067 (2023).\n14. Korngiebel, D. M. & Mooney, S. D. Considering the possibilities and pitfalls of Generative Pre-\ntrained Transformer 3 (GPT-3) in healthcare delivery.Npj Digit. Med.4,1 – 3 (2021).\n15. Bankes, S. C. Agent-based modeling: A revolution? PNAS.https://doi.org/10.1073/pnas.\n072081299.\n16. Tracy, M., Cerdá, M. & Keyes, K. M. Agent-Based Modeling in Public Health: Current\nApplications and Future Directions.Annu. Rev. Public Health39,7 7– 94 (2018).\n17. Bonabeau, E. Agent-based modeling: Methods and techniques for simulating human systems.\nProc. Natl. Acad. Sci.99, 7280–7287 (2002).\n18. Fagnant, D. J. & Kockelman, K. M. The travel and environmental implications of shared\nautonomous vehicles, using agent-based model scenarios.Transp. Res. Part C. Emerg.\nTechnol. 40,1 – 13 (2014).\n19. Kaur, P. et al. A survey on simulators for testing self-driving cars. In2021 Fourth International\nConference on Connected and Autonomous Driving (MetroCAD)(IEEE, 2021).\n20. Radhakrishnan, L. et al. A certiﬁed de-identiﬁcation system for all clinical text documents for\ninformation extraction at scale.JAMIA Open6, ooad045 (2023).\n21. Johnson, A. E. W. et al. MIMIC-IV, a freely accessible electronic health record dataset.Sci. Data\n10, 1 (2023).\n22. Zayyan, M. Objective Structured Clinical Examination: The Assessment of Choice.Oman Med.\nJ. 26, 219– 222 (2011).\n23. Tu, et al. Towards Conversational Diagnostic AI. Preprint athttps://arxiv.org/abs/2401.\n05654 (2024).\n24. Wornow, M. et al. The shaky foundations of large language models and foundation models for\nelectronic health records.Npj Digit. Med.6,1 – 10 (2023).\n25. Singhal, K. et al. Large language models encode clinical knowledge.Nature 620,\n172– 180 (2023).\n26. Shen, H., et al. MultiTurnCleanup: A Benchmark for Multi-Turn Spoken Conversational\nTranscript Cleanup. InProceedings of the 2023 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP).9895–9903. (ACL, 2023).\n27. Chen, I. et al. Ethical machine learning in healthcare.Annu. Rev. Biomed. Data Sci.4,\n123– 144 (2021).\n28. Rebedea, Traian, et al. \"NeMo Guardrails: A Toolkit for Controllable and Safe LLM Applications\nwith Programmable Rails.\" Proceedings of the 2023 Conference on Empirical Methods in\nNatural Language Processing: System Demonstrations. 2023.\n29. Webster, P. Six ways large language models are changing healthcare.Nat. Med., 29,\n2969–2971 (2023).\nAuthor contributions\nN.M., B.Y.M., E.R.A., A.J.B., and A.A. were involved in the conception of the paper and writing of the\noriginal draft. All authors were involved in the reviewing, revising, and editing of theﬁnal draft. Allﬁrst\nco-authors made equal contribution.\nCompeting interests\nA.J.B. is a co-founder and consultant to Personalis and NuMedii; consultant to Mango Tree Cor-\nporation, and in the recent past, Samsung, 10x Genomics, Helix, Pathway Genomics, and Verinata\n(Illumina); has served on paid advisory panels or boards for Geisinger Health, Regenstrief Institute,\nGerson Lehman Group, AlphaSights, Covance, Novartis, Genentech, and Merck, and Roche; is a\nshareholder in Personalis and NuMedii; is a minor shareholder in Apple, Meta (Facebook), Alphabet\n(Google), Microsoft, Amazon, Snap, 10x Genomics, Illumina, Regeneron, Sanoﬁ,P ﬁzer, Royalty\nPharma, Moderna, Sutro, Doximity, BioNtech, Invitae, Paciﬁc Biosciences, Editas Medicine, Nuna\nHealth, Assay Depot, and Vet24seven, and several other non-health related companies and mutual\nfunds; and has received honoraria and travel reimbursement for invited talks from Johnson and\nJohnson, Roche, Genentech, Pﬁzer, Merck, Lilly, Takeda, Varian, Mars, Siemens, Optum, Abbott,\nCelgene, AstraZeneca, AbbVie, Westat, and many academic institutions, medical or disease speciﬁc\nfoundations and associations, and health systems. A.J.B. receives royalty payments throughStanford\nUniversity, for several patents and other disclosures licensed to NuMedii and Personalis. A.J.B.’s\nresearch has been funded by NIH, Peraton (as the prime on an NIH contract), Genentech, Johnson and\nJohnson, FDA, Robert Wood Johnson Foundation, Leon Lowenstein Foundation, Intervalien Foun-\ndation, Priscilla Chan and Mark Zuckerberg, the Barbara and Gerson Bakar Foundation, and in the\nrecent past, the March of Dimes, Juvenile Diabetes Research Foundation, California Governor’sO fﬁce\nof Planningand Research, CaliforniaInstitute for RegenerativeMedicine, L’Oreal,and Progenity.None\nof these entities had any bearing on the design of this study or the writing of the manuscript. All other\nauthors have no conﬂicts of interest to disclose.\nAdditional information\nCorrespondenceand requests for materials should be addressed to Ahmed Alaa.\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nPublisher’sn o t eSpringer Nature remains neutral with regard to jurisdictional claims in published maps\nand institutional afﬁliations.\nOpen AccessThis article is licensed under a Creative Commons Attribution 4.0 International\nLicense, which permits use, sharing, adaptation, distribution and reproduction in any medium or\nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link\nto the Creative Commons licence, and indicate if changes were made. The images or other third\nparty material in this article are included in the article’s Creative Commons licence, unless indicated\notherwise in a credit line to the material. If material is not included in the article’s Creative Commons\nlicence and your intended use is not permitted by statutory regulation or exceeds the permitted use,\nyou will need to obtain permission directly from the copyright holder. To view a copy of this licence,\nvisit http://creativecommons.org/licenses/by/4.0/\n.\n© The Author(s) 2024\nnpj |digital medicine Comment\nnpj Digital Medicine|            (2024) 7:84 3"
}