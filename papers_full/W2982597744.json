{
  "title": "Phenotyping of Clinical Notes with Improved Document Classification Models Using Contextualized Neural Language Models",
  "url": "https://openalex.org/W2982597744",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4288922448",
      "name": "Mulyar, Andriy",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4288510048",
      "name": "Schumacher, Elliot",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4286954371",
      "name": "Rouhizadeh, Masoud",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4223014546",
      "name": "Dredze, Mark",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2911109671",
    "https://openalex.org/W2106838048",
    "https://openalex.org/W2095705004",
    "https://openalex.org/W2525778437",
    "https://openalex.org/W2132724073",
    "https://openalex.org/W2884429606",
    "https://openalex.org/W2109206523",
    "https://openalex.org/W2927032858",
    "https://openalex.org/W2164474247",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2970854433",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2978017171",
    "https://openalex.org/W2925863688",
    "https://openalex.org/W2963716420",
    "https://openalex.org/W2939507640",
    "https://openalex.org/W2787560479",
    "https://openalex.org/W2097878768"
  ],
  "abstract": "Clinical notes contain an extensive record of a patient's health status, such as smoking status or the presence of heart conditions. However, this detail is not replicated within the structured data of electronic health systems. Phenotyping, the extraction of patient conditions from free clinical text, is a critical task which supports avariety of downstream applications such as decision support and secondary use of medical records. Previous work has resulted in systems which are high performing but require hand engineering, often of rules. Recent work in pretrained contextualized language models have enabled advances in representing text for a variety of tasks. We therefore explore several architectures for modeling pheno-typing that rely solely on BERT representations of the clinical note, removing the need for manual engineering. We find these architectures are competitive with or outperform existing state of the art methods on two phenotyping tasks.",
  "full_text": "Phenotyping of Clinical Notes with Improved\nDocument Classiﬁcation Models Using\nContextualized Neural Language Models\nAndriy Mulyar1∗ Elliot Schumacher2 Masoud Rouhizadeh3 Mark Dredze2\n1Department of Computer Science, Virginia Commonwealth University\n2Department of Computer Science, Johns Hopkins University\n3Institute for Clinical and Translational Research , Johns Hopkins University\nAbstract\nClinical notes contain an extensive record of a patient’s health status, such as smok-\ning status or the presence of heart conditions. However, this detail is not replicated\nwithin the structured data of electronic health systems. Phenotyping, the extraction\nof patient conditions from free clinical text, is a critical task which supports a\nvariety of downstream applications such as decision support and secondary use of\nmedical records. Previous work has resulted in systems which are high performing\nbut require hand engineering, often of rules Uzuner et al. [2008], Uzuner [2009].\nRecent work in pretrained contextualized language models Devlin et al. [2019]\nhave enabled advances in representing text for a variety of tasks. We therefore\nexplore several architectures for modeling phenotyping that rely solely on BERT\nrepresentations of the clinical note, removing the need for manual engineering. We\nﬁnd these architectures are competitive with or outperform existing state of the art\nmethods on two phenotyping tasks.\n1 CORRECTION\nAdded September 13, 2020\nThe original paper was published in December 2019. After publication, we identiﬁed a bug in our\ncode that resulted in an error in our reported results. This version of the paper corrects that error and\nclariﬁes some of our descriptions of the experiments.\nSpeciﬁcally:\n• We have updated the results for each architecture. The results are now lower. They still beat\nthe previous shared task results on smoking but not obesity.\n• We removed the cross-validation experiments and focused on the held out evaluation.\n• Updated the description in the methods section.\nThe original version is available on Arxiv for comparison.\n2 Introduction\nElectronic Health Record (EHR) systems contain a wealth of health information about patients,\nincluding structured data (e.g. demographics, medical codes, lab results) and unstructured text in\n∗Work performed as a visiting student at Johns Hopkins University.\n33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.\narXiv:1910.13664v2  [cs.CL]  17 Sep 2020\nFigure 1: Our model architecture for a document classiﬁer for phenomic traits based on repeated\napplication of BERT to spans in a clinical note. Working bottom-up, a document is tokenized\nand chunked into spans according to the maximum BERT sequence length. An encoding function\nf((⃗hp)) condenses the unrolled language model hidden state sequence(⃗hp). Not shown, this encoded\nrepresentation is then fed into a layer of perceptrons with sigmoid activation for classiﬁcation.\nthe form of clinical notes. While structured data includes information that characterizes medical\nconditions of the patient, it often does not include numerous characteristics of interest that are\ntypically contained in the clinical notes. For example, while a clinician may not code the smoking\nstatus of a patient, it can appear in the notes if it was discussed during the visit. Since the mention of\nsmoking status appears in unstructured text, the phrasing can vary: “The patient smokes regularly” or\n“He reports a history of smoking.” Including these characteristics as structured data can support both\nimproved patient care and secondary use of medical records.\nThe task of automatic identiﬁcation of speciﬁc phenomic traits within patients is called phenotyping.\nPhenotyping is critical to cohort selection, in which a study selects a population from an EHR system\nfor further study, e.g. men over 50 who smoke. There have been multiple shared tasks, including\nidentifying smoking status Uzuner et al. [2008] and obesity related co-morbidities Uzuner [2009],\nwhich have produced high-performing systems for obesity Ware et al. [2009], Solt et al. [2009] and\nsmoking status Clark et al. [2008], Yao et al. [2018]. While these successes are promising, the uses\nof phenotyping are vast, for which an almost unlimited number of phenomic traits can be useful\nfor patient care or cohort selection. Therefore, systems that require extensive preprocessing (e.g\nabbreviation and negation detection) or feature engineering (e.g. detection of temporal phrases)\ntargeted at speciﬁc tasks may have limited utility in supporting a diverse range of phenomic traits.\nRecent work on contextualized neural language models Devlin et al. [2019], Peters et al. [2018], Dai\net al. [2019] has led to systems which construct representations of text data that can support many\ntasks, with task speciﬁc training data only needed to train a ﬁnal prediction layer. These models have\nbeen applied in the clinical space Alsentzer et al. [2019]. However, these models – which require\nbuilding representations across the entire input – have only been used for sentences or short segments\nof text. Little work has applied these models to entire documents or entire clinical notes.\nWe develop a phenotyping system based on neural contextualized representations of language. We\nutilize a clinically ﬁne-tuned Alsentzer et al. [2019] version of BERT Devlin et al. [2019]. BERT can\nonly be applied directly to relatively short spans of text. Since the phenomic trait can be contained\nanywhere in the clinical note, we explore ways of combining BERT representations from multiple\nsegments into a single document-level representation. Recent BERT based document classiﬁcation\narchitectures Adhikari et al. [2019] are not suited for clinical notes as they consider only the ﬁrst\nfew sentences of the text thus cannot capture information relayed further into the document. We\nevaluate our approach on two domains of phenomic traits (obesity co-morbidities and smoking) and\nﬁnd that our best approach to document level modeling outperforms previous state of the art systems\non smoking.\n3 Phenotyping of Clinical Notes with BERT\nWe frame phenotyping as a classiﬁcation problem, where for each phenomic trait for a clinical note\nour system produces a label, either binary or multi-class. Our classiﬁer uses BERT to generate a\n2\nsequence of representations of the text document. This representation sequence is condensed into a\nsingle document representation and then fed to our classiﬁer. We ﬁrst describe how BERT is applied\nto the document, and then describe several methods to construct a single document representation\nfrom the BERT output.\nBERT considers a ﬁxed length of text, e.g. ℓ = 512 WordPieces/subwords, where tokens are\nsubdivided using the WordPiece algorithm Wu et al. [2016]. BERT passes these subwords through its\nmultiple transformer layers and produces both a per subword representation, as well as a representation\nmeant to summarize the entire input: CLS. We divide the clinical document into chunks, where each\nchunk is of length ℓ (with the exception of possibly the last) and is passed into BERT. The result of\nthis process is that we have a representation for each subword of input, as well as aCLS representation\nfor each text chunk. This process is shown in Figure 1.\nThe next step requires the combination of the output from each BERT segment into a single doc-\nument embedding. Previous approaches consider only the ﬁrst two sentences as the basis for the\nrepresentation Wu and Dredze [2019]. However, since the phenomic trait can be contained anywhere\nin the document, we need to combine all CLS embeddings into a single representation. Additionally,\nsince clinical notes can be of arbitrary length, we need a general method to collapse this sequence\nof segment representations into a single representation. This combination function is represented in\nFigure 1 as f((⃗hp)).\nWe consider four options forf((⃗hp)). The input to each function is a sequence of theCLS embeddings.\nEach element of the sequence itself summarizes the document segment that element encodes.\nfmean : A dimension-wise mean over all CLS embeddings.\nfI : The identity function (a concatenation of all CLS embedding).\nfTransformer : A dimension-wise max of the output sequence in the encoder layer of a Trans-\nformer Vaswani et al. [2017].\nfLSTM: The last hidden state of an LSTM run left-to-right over the CLS embeddings.\nEach of these four architectures are identical up to the choice of encoding functionf. In our proposed\narchitectures (Figure 1), we use an instance of ClinicalBERT Alsentzer et al. [2019] - a BERT\nlanguage model ﬁne-tuned over biomedical and clinical domain text. We use BERT’s maximum\nword piece input length of 512, using 510 tokens with a padding on each side. The output of each\nCLS combination function f is linearly projected (via a layer of perceptrons) into the label space\nfollowed by a sigmoid activation. This entire architecture is trained on the available training set,\nwhich updates the parameters of the linear projection and if applicable f, e.g. the encoder layer of\nthe transformer or the LSTM model parameters. During training, we randomly dropout Srivastava\net al. [2014] weights with probability .1 in the projection, use binary cross entropy loss to estimate\nthe target label distribution and only backpropagate weight updates in the last Transformer layer of\nBERT.\n3.1 Implementation details\nDuring training we utilize the BERT-base hidden size ( 768 dimensions) throughout all relevant\ninternal hidden states in the fLSTM and fTransformer architectures and a dropout probability of .1 in the\nprojection layer. During prediction we apply a given label if the sigmoid of the projections component\ncorresponding to the label exceeds a threshold of .5; otherwise, the document does not receive the\ncorresponding label. We trained all architectures on an NVIDIA Tesla M40 GPU. All architectures\ntook approximately 24 hours of wall time (with negligible CPU computation) to converge to the\nperformance reported in Table 5 on the N2C2 2006 training set and approximately 36 hours of wall\ntime to converge on the N2C2 2008 training set.\n4 Evaluation\nWe consider two clinical note phenotyping datasets released as part of shared tasks by N2C2 (formally\nnamed I2B2): 2006 Smoker Identiﬁcation Uzuner et al. [2008] and 2008 Obesity Risk Factors Uzuner\n[2009]. The datasets are publicly available. 2 Smoking consists of a single prediction task: select\nsmoking status from four ﬁne-grained options: past smoker, current smoker, non-smoker, and status\n2https://portal.dbmi.hms.harvard.edu/data-sets/\n3\nunclear. Obesity contains a label for obesity and 14 co-occurring morbidities (e.g. congestive heart\nfailure), so a clinical note can have 0 or more applicable labels. For the obesity dataset we train and\nevaluate only using the “intuitive judgments” labels as these provide the largest annotation coverage\nover the data.\nEach dataset contains a pre-deﬁned training set identical to the data available to participants during\nthe shared task competition period. We train each architecture over each respective training set, and\nreport micro-averaged F1 for each architecture on the evaluation set after 1000 training epochs (a\nsuitable number selected during development). We do not perform any additional hyper-parameter\noptimization since there is no development set. We include for comparison both the best system at\nthe shared tasks and subsequent work with CNNs for these tasks.\n5 Results and Discussion\nTable 1: Phenotyping results (micro-averagedF1) of our architectures trained on the respective shared\ntask training sets and evaluated on the evaluation sets.\nI2B2 2006: Smoking I2B2 2008: Obesity\nfmean 92.8 86.5\nfI 91.1 82 .9\nfTransformer 58.4 70 .4\nfLSTM 92.3 83 .1\nShared Task 1st Place 90.0 95 .0\nMajority Label Baseline 81.0 74 .4\nDocBert Adhikari et al. [2019] 80.2 67 .6\nCNN Wang et al. [2019] 77.0 −\nCNN + Rules Yao et al. [2018] − 96.2\nWe showcase the competitiveness of our architectures with respect to previous methods in Table 5.\nIn both shared tasks, top submissions consisted mainly of hand created regular expression and rules\nfor each label. The top performing system in I2B2 2006 Clark et al. [2008] utilized handcrafted\nregular expressions, rules and feature sets to train per-label binary support vector machines. The top\nperforming system in I2B2 2008 Ware et al. [2009] consisted of purely hand engineered rules for\neach label. As a simple baseline, we report the performance of predicting the majority occurring\nlabel across all training instances at evaluation. DocBert does not outperform either baseline. This\nis because it utilizes only the ﬁrst 510 document tokens hence cannot capture any label indicating\nsignal further into the document. For the I2B2 2006 dataset, a recent system Wang et al. [2019]\nexplored a CNN architecture with word2vec representations but did not outperform the majority\nlabel or shared task baseline. Similarly, Yao et al. [2018] utilized a CNN with word2vec alongside\nhandcrafted features to achieve state of the art performance on I2B2 2008.\nOur approach achieves state-of the art performance on smoking. The fTransformer architecture failed to\noutperform most baselines across both tasks. In both tasks,fmean, the simplest architecture, performed\nbest. To the best of our knowledge, fmean beats the state of the art on I2B2 2006 by 2.8%.\nThe multi-head attention based Transformer encoder architecturefTransformer fails to learn a useful note\nrepresentation across both tasks. We hypothesize this lower than expected performance is associated\nwith the increased model capacity introduced by the architecture relative to the low number of\ntraining instances. Additionally, the utilization of multi-head attention results in the loss of temporal\ninformation amongst document sub-chunks (ex. certain document sections always precede others)\nwhich may contribute to the observed performance reduction.\nThe mean pooling architecture outperforms more complex parameterizations on both tasks. This\nsuggests that the contextualized representation produced by BERT carries sufﬁcient trait related\nsignal through noise inducing pooling operations to dismiss the need for more complex architectures\nover the encoder.\n4\n6 Conclusion\nWe explore and contribute several document classiﬁcation architectures that combine representations\nfrom state of the art language models. We ﬁnd that treating document encoding as a sequence model-\ning task over sequential, contextualized document chunks is an effective framework for document\nrepresentation agnostic of the classiﬁcation architecture. All of our proposed architectures perform\ncompetitively with previous task baselines. Notably, we beat state of the art on a well known smoking\nstatus phenotyping task and demonstrate that simple strategies such as mean pooling are sufﬁcient\nfor training BERT based long document classiﬁers. We make our Pytorch implementation publicly\navailable 3.\nReferences\nAshutosh Adhikari, Achyudh Ram, Raphael Tang, and Jimmy Lin. Docbert: BERT for document classiﬁcation.\nCoRR, abs/1904.08398, 2019. URL http://arxiv.org/abs/1904.08398.\nEmily Alsentzer, John R. Murphy, Willie Boag, Wei-Hung Weng, Di Jin, Tristan Naumann, and Matthew\nB. A. McDermott. Publicly available clinical BERT embeddings. CoRR, abs/1904.03323, 2019. URL\nhttp://arxiv.org/abs/1904.03323.\nCheryl Clark, Kathleen Good, Lesley Jezierny, Melissa Macpherson, Brian Wilson, and Urszula Chajewska. Iden-\ntifying smokers with a medical extraction system. Journal of the American Medical Informatics Association,\n15(1):36–39, 2008.\nZihang Dai, Zhilin Yang, Yiming Yang, William W Cohen, Jaime Carbonell, Quoc V Le, and Ruslan\nSalakhutdinov. Transformer-xl: Attentive language models beyond a ﬁxed-length context. arXiv preprint\narXiv:1901.02860, 2019.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of deep bidirectional\ntransformers for language understanding. In NAACL-HLT 2019, pages 4171–4186, 2019. URL https:\n//aclweb.org/anthology/papers/N/N19/N19-1423/.\nMatthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke\nZettlemoyer. Deep contextualized word representations. arXiv preprint arXiv:1802.05365, 2018.\nIllés Solt, Domonkos Tikk, Viktor Gál, and Zsolt T Kardkovács. Semantic classiﬁcation of diseases in dis-\ncharge summaries using a context-aware rule-based classiﬁer. Journal of the American Medical Informatics\nAssociation, 16(4):580–584, 2009.\nNitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: a\nsimple way to prevent neural networks from overﬁtting. The journal of machine learning research, 15(1):\n1929–1958, 2014.\nÖzlem Uzuner. Recognizing obesity and comorbidities in sparse data. Journal of the American Medical\nInformatics Association, 16(4):561–570, 2009.\nÖzlem Uzuner, Ira Goldstein, Yuan Luo, and Isaac Kohane. Identifying patient smoking status from medical\ndischarge records. Journal of the American Medical Informatics Association, 15(1):14–24, 2008.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser,\nand Illia Polosukhin. Attention is all you need. In Advances in neural information processing systems, pages\n5998–6008, 2017.\nYanshan Wang, Sunghwan Sohn, Sijia Liu, Feichen Shen, Liwei Wang, Elizabeth J Atkinson, Shreyasee Amin,\nand Hongfang Liu. A clinical text classiﬁcation paradigm using weak supervision and deep representation.\nBMC medical informatics and decision making, 19(1):1, 2019.\nHenry Ware, Charles J Mullett, and Vasudevan Jagannathan. Natural language processing framework to assess\nclinical conditions. Journal of the American Medical Informatics Association, 16(4):585–589, 2009.\nShijie Wu and Mark Dredze. Beto, bentz, becas: The surprising cross-lingual effectiveness of bert. In Empirical\nMethods in Natural Language Processing (EMNLP), 2019.\n3https://github.com/AndriyMulyar/bert_document_classification\n5\nYonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V . Le, Mohammad Norouzi, Wolfgang Macherey, Maxim\nKrikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu,\nŁukasz Kaiser, Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George Kurian,\nNishant Patil, Wei Wang, Cliff Young, Jason Smith, Jason Riesa, Alex Rudnick, Oriol Vinyals, Greg Corrado,\nMacduff Hughes, and Jeffrey Dean. Google’s neural machine translation system: Bridging the gap between\nhuman and machine translation, 2016.\nLiang Yao, Chengsheng Mao, and Yuchen Luo. Clinical text classiﬁcation with rule-based features and\nknowledge-guided convolutional neural networks. In 2018 IEEE International Conference on Healthcare\nInformatics Workshop (ICHI-W), 2018.\n6",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7336799502372742
    },
    {
      "name": "Variety (cybernetics)",
      "score": 0.6804662942886353
    },
    {
      "name": "Task (project management)",
      "score": 0.6542760729789734
    },
    {
      "name": "Language model",
      "score": 0.5550720691680908
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5359441041946411
    },
    {
      "name": "Natural language processing",
      "score": 0.5064083337783813
    },
    {
      "name": "Machine learning",
      "score": 0.5051739811897278
    },
    {
      "name": "Health records",
      "score": 0.43063411116600037
    },
    {
      "name": "Data science",
      "score": 0.3890610933303833
    },
    {
      "name": "Health care",
      "score": 0.11607599258422852
    },
    {
      "name": "Engineering",
      "score": 0.08434903621673584
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    },
    {
      "name": "Economic growth",
      "score": 0.0
    }
  ],
  "institutions": [],
  "cited_by": 21
}