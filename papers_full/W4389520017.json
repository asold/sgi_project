{
  "title": "In What Languages are Generative Language Models the Most Formal? Analyzing Formality Distribution across Languages",
  "url": "https://openalex.org/W4389520017",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5000895797",
      "name": "Asım Ersoy",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5011968554",
      "name": "Gerson Vizcarra",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5022228276",
      "name": "Tahsin Mayeesha",
      "affiliations": [
        "North South University"
      ]
    },
    {
      "id": "https://openalex.org/A5114080909",
      "name": "Benjamin Müller",
      "affiliations": [
        "Centre Roland Mousnier",
        "Centre de Recherche en Littérature Comparée",
        "Centre de linguistique en Sorbonne",
        "Laboratoire Médiations",
        "Sciences, Normes, Démocratie",
        "Sorbonne Université",
        "Victor (Japan)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3208063159",
    "https://openalex.org/W3174685870",
    "https://openalex.org/W3105882417",
    "https://openalex.org/W4287200699",
    "https://openalex.org/W2119458502",
    "https://openalex.org/W3214250531",
    "https://openalex.org/W4289597897",
    "https://openalex.org/W2488310549",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W2467834614",
    "https://openalex.org/W149130585",
    "https://openalex.org/W2329847998",
    "https://openalex.org/W4303684595",
    "https://openalex.org/W4285186755",
    "https://openalex.org/W4377121468",
    "https://openalex.org/W1482892933",
    "https://openalex.org/W3034515982",
    "https://openalex.org/W2213817245",
    "https://openalex.org/W2972735048",
    "https://openalex.org/W2998699029",
    "https://openalex.org/W3156326119",
    "https://openalex.org/W4229005866",
    "https://openalex.org/W3184144760",
    "https://openalex.org/W2060742357",
    "https://openalex.org/W2985808321",
    "https://openalex.org/W2758334418",
    "https://openalex.org/W4281621415",
    "https://openalex.org/W3034319502",
    "https://openalex.org/W4286904372",
    "https://openalex.org/W4311642023",
    "https://openalex.org/W2997032666",
    "https://openalex.org/W2938704169",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2950888501",
    "https://openalex.org/W2109704865",
    "https://openalex.org/W2924376387",
    "https://openalex.org/W4321392130",
    "https://openalex.org/W4226155321",
    "https://openalex.org/W3207322569",
    "https://openalex.org/W2952638691",
    "https://openalex.org/W183757929",
    "https://openalex.org/W2553133705",
    "https://openalex.org/W1997305228",
    "https://openalex.org/W2330376137",
    "https://openalex.org/W4293233961",
    "https://openalex.org/W2972791412",
    "https://openalex.org/W2964321064",
    "https://openalex.org/W4285199616",
    "https://openalex.org/W4214713014",
    "https://openalex.org/W3037831233",
    "https://openalex.org/W3174681468",
    "https://openalex.org/W3172917028",
    "https://openalex.org/W3206355021",
    "https://openalex.org/W2986670783",
    "https://openalex.org/W1956103381",
    "https://openalex.org/W4285155368",
    "https://openalex.org/W3194309076",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W4283458441",
    "https://openalex.org/W4285110390",
    "https://openalex.org/W4385574250",
    "https://openalex.org/W4287854445",
    "https://openalex.org/W3103490574",
    "https://openalex.org/W4287674181",
    "https://openalex.org/W613277099",
    "https://openalex.org/W3115113481",
    "https://openalex.org/W4388676761",
    "https://openalex.org/W3133702157",
    "https://openalex.org/W2245623202",
    "https://openalex.org/W2915411073",
    "https://openalex.org/W4255825300",
    "https://openalex.org/W1554148108",
    "https://openalex.org/W3195577433",
    "https://openalex.org/W3172205429",
    "https://openalex.org/W4295955098",
    "https://openalex.org/W2242519892",
    "https://openalex.org/W3176477796",
    "https://openalex.org/W3172413486",
    "https://openalex.org/W3177468621",
    "https://openalex.org/W2986893290"
  ],
  "abstract": "Multilingual generative language models (LMs) are increasingly fluent in a large variety of languages. Trained on the concatenation of corpora in multiple languages, they enable powerful transfer from high-resource languages to low-resource ones. However, it is still unknown what cultural biases are induced in the predictions of these models. In this work, we focus on one language property highly influenced by culture: formality. We analyze the formality distributions of XGLM and BLOOM’s predictions, two popular generative multilingual language models, in 5 languages. We classify 1,200 generations per language as formal, informal, or incohesive and measure the impact of the prompt formality on the predictions. Overall, we observe a diversity of behaviors across the models and languages. For instance, XGLM generates informal text in Arabic and Bengali when conditioned with informal prompts, much more than BLOOM. In addition, even though both models are highly biased toward the formal style when prompted neutrally, we find that the models generate a significant amount of informal predictions even when prompted with formal text. We release with this work 6,000 annotated samples, paving the way for future work on the formality of generative multilingual LMs.",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 2650–2666\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nIn What Languages are Generative Language Models the Most Formal?\nAnalyzing Formality Distribution across Languages\nAsım Ersoy1∗* , Gerson Vizcarra2* , Tasmiah Tahsin Mayeesha3*, Benjamin Muller4\n1Huawei Türkiye R&D Center 2Banco de Crédito e Inversiones\n3North South University 4Sorbonne Université\nasim.ersoy1@huawei.com gersonw.vizcarra@gmail.com\ntasmiah.tahsin@northsouth.edu\nAbstract\nMultilingual generative language models\n(LMs) are increasingly fluent in a large variety\nof languages. Trained on the concatenation of\ncorpora in multiple languages, they enable pow-\nerful transfer from high-resource languages to\nlow-resource ones. However, it is still unknown\nwhat cultural biases are induced in the predictions\nof these models. In this work, we focus on one\nlanguage property highly influenced by culture:\nformality. We analyze the formality distributions\nof XGLM and BLOOM’s predictions, two pop-\nular generative multilingual language models, in\n5 languages. We classify 1,200 generations per\nlanguage as formal, informal, or incohesive and\nmeasure the impact of the prompt formality on\nthe predictions. Overall, we observe a diversity of\nbehaviors across the models and languages. For\ninstance, XGLM generates informal text in Ara-\nbic and Bengali when conditioned with informal\nprompts, much more than BLOOM. In addition,\neven though both models are highly biased toward\nthe formal style when prompted neutrally, we find\nthat the models generate a significant amount of\ninformal predictions even when prompted with\nformal text. We release with this work 6,000 an-\nnotated samples, paving the way for future work\non the formality of generative multilingual LMs.\n1 Introduction\nNatural Language Processing (NLP) systems are\nused worldwide across multiple cultures, audiences,\ncontexts, communication goals, demographics, and\nlanguages. Thus, it is essential that these models\nbe able to adapt to the sociocultural context of its\nusers. As described by Hershcovich et al. (2022),\nlinguistic style is one of the major dimensions by\nwhich cultures vary in NLP technologies.\nIn this work, we focus on formality. Formality\nis a stylistic property of language that can impact\nhow we perceive a text. It typically carries informa-\ntion about the culture of the speaker (or writer), is\nconstrained by the context of the message, and can\nimpact the communicative goal of a text (Heylighen\nand Dewaele, 1999). Generating text with a desired\n∗Equal contribution. This work was done as part of the\nFatima Fellowship mentoring program.\nlevel of formality can be useful for different NLP\napplications (Hovy and Yang, 2021). For example,\ncontrolling the tone of machine translation models\n(Sennrich et al., 2016; Niu et al., 2017; Feely et al.,\n2019), designing chatbots with formality aware-\nness to respond to user-preferred conversational\nstyle (Cox and Ooi, 2022), or assisting users to\nchange the formality level of their writings (Rao\nand Tetreault, 2018; Wang et al., 2019, 2020).\nGenerative language models have demonstrated\ncapabilities in producing cohesive texts and solving\nNLP tasks with zero/few-shot learning (Radford\net al., 2019; Brown et al., 2020b; Chowdhery et al.,\n2022; Zhang et al., 2022), even in multilingual\nscenarios (Lin et al., 2021b; Scao et al., 2022; Bar-\nbieri et al., 2022; Jiang et al., 2022; Anil et al.,\n2023). Multilingual language models are trained\nwith large amounts of text from different sources.\nThat training process could make the model bi-\nased towards a certain level of formality because of\nthe data of each language as well as cross-lingual\ntransfer (Pires et al., 2019; Libovický et al., 2020;\nMuller et al., 2021), limiting the capabilities of the\nmodel to adapt to the different cultures of an NLP\napplication.\nThis work analyzes the formality level of two\nmultilingual language models: XGLM (Lin et al.,\n2021b) and BLOOM (Scao et al., 2022), across\nfive languages, namely Arabic, Bengali, English,\nFrench, and Spanish. To do so, a native/proficient\nspeaker of each language evaluates the generation\noutputs of each model into three categories: formal,\ninformal, and incohesive. This evaluation allows us\nto analyze the generations across three different di-\nmensions: the cohesiveness of the generations,1 the\nformality bias given neutral prompts, and the for-\nmality preservation given formal/informal prompts.\nAs an example, we show in Table 1 the predictions\nof BLOOM and XGLM conditioned on the same\n1In short, we define a sequence as incohesive if it cannot\nbe evaluated as formal/informal. More details in Section 4.3\n2650\nPrompt\nGeneration\nXGLM(7.5B) BLOOM(7.1)\nNot being able to cry is also very\ndifficult\nBut people of our hopes and dreams change\nso much! There could not be a greater exam-\nple...!\nBut Anju Ghosh was the one who broke down\nin tears, her daughter said. Anju Ghosh\nreturned to work after spending time with\nher daughter. Afzal Hossain, a veteran actor\nand theater personality of the country, died\nat Tongi Government Hospital last Thursday\naround 9 pm.\nTable 1: XGLM (Lin et al., 2021a) and BLOOM (Scao et al., 2022) generating predictions of different formality\n(informal in red and formal in green) based on a Bengali formal prompt sampled from the InFormal dataset (Krishna\net al., 2022). As illustrated here, the formality of the predictions differs between XGLM and BLOOM.\nprompt in Bengali but generating text of different\nformality level. Overall, our contributions are the\nfollowing:\n• To the best of our knowledge, this is the first\nwork to analyze the formality of generative\nmultilingual language models across multi-\nple languages. While we have focused on\nspecific models and languages in this work,\nthe procedures followed to define formality,\nprompt sourcing, language generation, and\nmeasurement of how formality is preserved\nfrom prompts are generalizable to any gener-\native system and language. We open-source\n1,200 generations,2 per language, manually\nannotated as formal, informal, or incohesive.\n• We find that BLOOM generates about twice\nas long texts as XGLM. Besides, almost all\nthe generated formal sentences are longer than\nthe informal ones. Also, informal generations\nin English, French, and Spanish are charac-\nterized by being more conversational, and in\nBengali, by having more punctuation marks.\n• We find that BLOOM is significantly more\ncohesive than XGLM in English, French, and\nSpanish and performs similarly in other lan-\nguages.\n• Both XGLM and BLOOM are generally bi-\nased toward formal text when prompted in a\n2https://github.com/asimokby/\nformality-bias-analysis\nneutral way. However, both models are very\nsensitive to the formality of the prompt and\nwill generate informal text if conditioned with\nan informal prompt. This is particularly strik-\ning for Arabic: BLOOM generates dialectal\nArabic (considered informal) when prompted\nwith informal text while being extremely bi-\nased toward Modern-Standard Arabic (consid-\nered formal).\n2 Formality Across Different Languages\nWe start by defining formality in the five languages\nof our study.\nArabic The Arabic language is spoken in many\ndialects (Watson, 2011). These dialects are vari-\nants of classical or standard Arabic, which has a\nmodernized version of it called Modern Standard\nArabic (MSA). Badawi (1973), in his famous book\n“Mustawayat Al-arabiyya Al-muasira Fi Misr” The\nlevels of contemporary Arabic in Egypt, presents a\ntheory on the relationship between standard Arabic\n(Fusha) and vernacular Arabic (Ammiya) in Egypt.\nHis theory describes the situation as a continuum\nwith 5 major divisions: illiterate colloquial Ara-\nbic, educated colloquial Arabic, elevated colloquial\nArabic, modern standard Arabic, and classical Ara-\nbic. The first three divisions are Ammiya, which\nis considered informal and not necessarily gram-\nmatically correct. The last two divisions are Fusha,\nwhich is considered formal. However, the defini-\ntion of what is formal and what is informal could\ndepend on the problem at hand; for example, in one\n2651\ncase, elevated colloquial Arabic could be consid-\nered formal, while illiterate colloquial Arabic as in-\nformal. In our work, we define formality for Arabic\nas follows: a piece of text is formal if it contains no\nwords coming from any Arabic dialect which is not\nconsidered as Fusha, following (Badawi, 1973)’s\ndefinition of Fusha. For example, the following\nsentence: \\arabicquestionmark\\dalfinal\\jeemmedial\\seenmedial\\meeminitial \\behisolated\\rehfinal\\qafinitial\\alefwithhamzaaboveisolated \\noonfinal\\yehinitial\\alefwithhamzaaboveisolated(where is the closest\nmosque?) is formed of only Fasih, formal, words.\nSimilarly, a piece of text is informal if it contains a\nword coming from any dialect and not Fusha. For\nexample, \\arabicquestionmark\\dalfinal\\jeemmedial\\seenmedial\\meeminitial \\behisolated\\rehfinal\\qafinitial\\alefwithhamzaaboveisolated \\noonfinal\\yehmedial\\fehinitial— (where is the\nclosest mosque?) is informal because of the word\n\\noonfinal\\yehmedial\\fehinitial— (where) which is Egyptian Arabic.\nBengali Bengali has a complex and elaborate sys-\ntem of using pronouns to express the degrees of\nfamiliarity and formality between the participants\nin a conversation (Das, 1968; Uddin, 2019). T-\nV distinction (Brown et al., 1960) or the contex-\ntual usage of pronouns to convey varying levels\nof formality, familiarity, and politeness, which is\nfound in many Romance languages (French, Ital-\nian, Spanish, etc.), can also be seen in Bengali.\nBengali follows a tripartite form of second-person\npronouns:\n / Apni (formal) for respected\nelders and strangers,\n / Tumi (polite) for sib-\nlings/friends or familiar people and\n / Tui (in-\nformal) for those who are younger, children or very\nclose friends. The third person he / she can be trans-\nlated to\n / Tini (formal) vs\n / Se (informal),\nwhich encodes two levels of formality – honorific\nand non-honorific. Bengali pronouns can encode\nnumbers such as singular/plural, but the notion of\nformality is not changed by gender or numerical\nproperties (David, 2015).\nThe following are other considerations of for-\nmality in Bengali: (i) Texts containing a high fre-\nquency of Sanskrit-originated words can be consid-\nered formal. Agglutination/Compound words can\nbe considered more formal compared to their ana-\nlytical or elaborated forms. For instance, the words\n(formal) /\n (informal) — death\nhave the same meaning, but a different formality\n(Panda, 1992; Nagarajan, 2014; Ghosh et al., 2022).\n(ii) Bengali pronouns agree with the verb in lev-\nels of formality and there are formal and informal\nvariations of the same verb (David, 2015; Sultana,\n2016). For instance, verbs like Give, Eat, Go can\nbe written as\n (formal) or\n(informal) depending on the context. (iii) Among\nBengali speakers in Bangladesh, regional dialects\nlike Sylheti, Chakma, and Chittagonian are gener-\nally considered informal while classical Bengali\ndialect (S¯adhubh¯as¯a) or standardized Bengali di-\nalect (Cholito vasha) is considered formal (Ray\net al., 1966).\nEnglish Formality in English is commonly de-\nfined as the language style used in a given situation.\nA formal speech, for instance, has a very careful\nselection of pronunciation, words, and structure\n(Richards and Schmidt, 2013). Heylighen and De-\nwaele (1999) divide English formality into two di-\nmensions: a deep formality, characterized by the\nunderstanding of the precise meaning, avoiding am-\nbiguity; and a surface formality which focuses on\nthe rigorous selection of manners. Some recent\nworks focus on the latter to evaluate formality us-\ning the selection of words (Brooke et al., 2010) and\ndiscarding the topic (Pavlick and Tetreault, 2016).\nFollowing Liardét et al. (2019), we use the follow-\ning rules below to evaluate cohesive English text\nas informal: (i) Presence of contractions, abbre-\nviations, and colloquial expressions; (ii) presence\nof grammar infelicities, that is, unsuitable expres-\nsions, inconsistencies in writing, and misspellings;\n(iii) high occurrence of delexical verbs and phrasal\nverbs; and (iv) higher involvement of human partic-\nipants and subjective judgments, such as opinions.\nFrench Formality is typically classified in French\ninto three classes: soutenu, courant and familier\n(Gadet, 2005; Beeching et al., 2009). The register\nsoutenu is reserved for legal documents, literature,\nor when addressing someone we want to show par-\nticular respect (e.g., a judge). It usually involves\naddressing someone with the second person plural\n(called vousvoîment). The register courant corre-\nsponds to the one used in day-to-day life, for in-\nstance, when we talk to someone new which is typ-\nically neutral and includes few grammatical errors.\nThe register familier is the one used with friends,\nor within a family circle. It usually involves ad-\ndressing someone with the second singular person\ntu. It can include a large portion of grammatical\nerrors. Finally, it can also include slang and insults\nin its most vulgar form. In this work, following\nwhat was done in the XFORMAL work (Briakou\net al., 2021b), we classify generated text into two\nclasses. Soutenu is associated with the formal class\nwhile familier and courant with the informal class.\nSpanish Formality in Spanish is commonly de-\nscribed by the T-V distinctions in the singular\n2652\nsecond-person pronoun derived from Latin. Specif-\nically, there are two possible translations for the\nEnglish pronoun “you”: tú is considered informal,\nand usted is formal. Both pronouns have different\nconjugations. The formality in sentences that use\nthe singular second person is easily recognizable.\nIn the case of the other pronouns, the first person\nis often considered less polite than the third one\n(Stewart, 2001). For that reason, the third person\nis commonly used in scientific texts (Salazar et al.,\n2013). Aside from the pronouns and their conju-\ngations, according to Cépeda and Tavera (2007),\na formal text in Spanish should accomplish other\ncharacteristics such as: (i) Having no typographical\nor grammatical errors. (ii) Being a set of sentences\nreferring to the same topic. (iii) Being arranged\nin paragraphs and having a coherent correlation\nbetween ideas using appropriate connectors.\nIn our work, we check the presence of slang or\noffensive terms in a sequence to classify text as in-\nformal. Then, T/V distinction in sentences written\nusing the second person defines the formality level.\nIn a similar way, sentences written in the third per-\nson have a bigger probability of being classified\nas formal compared to the ones written in the first\nperson. The final priority is the layout: paragraph-\nstructured sequences are considered formal in more\nscenarios than conversational-structured ones.\n3 Related Work\nBiases of Generative LMs Recent literature on\nLarge Language Models (LLMs) demonstrated so-\ncial bias and prejudice against minorities (Sheng\net al., 2021; Blodgett et al., 2020; Bender et al.,\n2021; Bommasani et al., 2021; Liang et al., 2021)\nin terms of many categories including gender (Sun\net al., 2019; Cao and Daumé III, 2020; Felkner\net al., 2022), race (Davidson et al., 2019), religion\n(Abid et al., 2021; Malik et al., 2022), occupation,\npolitics and disabilities which result in the pro-\nduction of damaging content. To create multilin-\ngual bias evaluation frameworks, it has been argued\nthat careful curation of culturally aware datasets is\nneeded (Talat et al., 2022).\nMany papers have focused on measuring social\nbiases and stereotypes against historically disadvan-\ntaged groups and counteracting them for a limited\nnumber of languages like English (Nadeem et al.,\n2021; Nangia et al., 2020; Barikeri et al., 2021;\nSmith et al., 2022), French (Névéol et al., 2022),\nHindi (Malik et al., 2022), but similar work has not\nbeen done for low-resource languages like Bengali.\nTo our knowledge, the evaluation of multilingual\nmodels for measuring cultural biases like formality\nhas not been attempted so far.\nFormality Analysis Previous work in formal-\nity analysis has focused on formality classifica-\ntion (Heylighen and Dewaele, 1999; Abu Sheikha\nand Inkpen, 2010; Pavlick and Tetreault, 2016;\nDementieva et al., 2022), formality style transfer\nin English (Rao and Tetreault, 2018; Wang et al.,\n2019, 2020; Czeresnia Etinger and Black, 2019;\nMadaan et al., 2020; Yao and Yu, 2021; Briakou\net al., 2021a), and in the multilingual setting (Ko-\nrotkova et al., 2019; Briakou et al., 2021b; Krishna\net al., 2022). Formality-sensitive machine transla-\ntion to control the generation of machine translation\nmodels to target formality has received attention\nin recent years (Sennrich et al., 2016; Niu et al.,\n2017; Feely et al., 2019; Viswanathan et al., 2020;\nNiu and Carpuat, 2020; Schioppa et al., 2021) and\nbenchmark MT datasets and models have been pub-\nlished (Nadejde et al., 2022; Rippeth et al., 2022).\nRecently, several datasets with formality annota-\ntions have been introduced in English (Lahiri, 2015;\nPavlick and Tetreault, 2016; Rao and Tetreault,\n2018). XFORMAL (Briakou et al., 2021b),\nTAOCD (Zaidan and Callison-Burch, 2011) and\nInFormal (Krishna et al., 2022) extended formality\nstyle transfer to the multilingual setting. In the fol-\nlowing sections, we describe our experiments and\nresults for different languages.\n4 Experiments\nWe evaluate different dimensions of formality of\nthe generations of two popular generative multilin-\ngual language models: XGLM (Lin et al., 2021b)\nand BLOOM (Scao et al., 2022), in five languages:\nArabic, Bengali, English, Spanish, and French. We\nhypothesize that the influence of high-resource lan-\nguages in the corpus can involve biases in the for-\nmality of the whole models. To see their behavior\nin different scenarios, we employ distinct variations\nof prompt lengths and formality. In addition, we\ntweak some parameters when generating to avoid\nincohesive outputs.\nXGLM (Lin et al., 2021b) is a multilingual lan-\nguage model trained with 500 billion tokens belong-\ning to 30 languages of Common Crawl. XGLM has\nfive sizes ranging from 564 million to 7.5 billion\nparameters.\n2653\nBLOOM (Scao et al., 2022) is also a multilingual\ngenerative language model trained on around 341\nbillion tokens from a corpus of 59 languages (13\nof them are programming ones) to democratize\nhuge pre-trained language models. BLOOM was\nreleased in different sizes ranging from 560 million\nto 176 billion parameters.\nXLGM and BLOOM are decoder-only trans-\nformers pre-trained on a similar set of languages\nwith a comparable amount of data. We com-\npare checkpoints of similar size (i.e. we compare\nXGLM 2.9B with BLOOM 3B and XGLM 7.5B\nand BLOOM 7.1B3). Regarding the proportion and\ndata sources on which both models were trained,\nBLOOM was trained on a more varied set of do-\nmains than XGLM in spite of the XGLM corpus\nbeing larger. In addition, the BLOOM corpus has a\nmore balanced distribution of the amount of data of\nthe languages evaluated in this study. More details\nabout the quantity and sources of both models can\nbe found in Appendix C.\n4.1 Prompting for Formality Evaluation\nWe employ two prompting strategies to condition\nthe generation of the models. In that way, the be-\nhavior of the model in different scenarios can be\nassessed.\nShort Neutral Prompts A short prompt is com-\nposed of up to three words to condition the lan-\nguage of the output without giving any context that\ncould impact the formality level. That allows us to\nmeasure the models’ tendency to produce a certain\nformality level with a neutral input. For the lexicon\nof each language, we pick a set of common words4\n(or a combination of them to avoid the confusion\nof languages when generating) that can be used in\nboth formal and informal sentences.\nLong Informal/Formal Prompts This set of\nprompts is composed of truncated sentences ex-\ntracted from existing formal/informal sources. Us-\ning these prompts, we can verify how much the\nmodels preserve the formality level of their in-\n3We use the checkpoints and implementations fromhttps:\n//huggingface.co/models\n4http://corpus.rae.es/lfrecuencias.html,\nhttps://www.pinhok.com/kb/bengali/98/\n100-basic-bengali-vocabularies/ ,\nhttps://talkinarabic.com/arabic-words/,\nhttps://en.wikipedia.org/wiki/Most_common_words_\nin_English\nhttps://strommeninc.com/\n1000-most-common-french-words-frequency-vocabulary/\nput. The sources of the prompts include formal-\nity datasets such as GYAFC (Rao and Tetreault,\n2018), XFORMAL (Briakou et al., 2021b), InFor-\nmal (Krishna et al., 2022). We also include datasets\ncrawled from the web (Zaidan and Callison-Burch,\n2011; Cañete, 2019) and informal songs (Muñoz,\n2018).\nTable 2 presents the details of which\nwords/group of words we use as short prompts,\nand the dataset sources of the formal/informal\nprompts for each language.\nNeutral+ Formal* Informal*\nar \\aleffinal\\meemmedial\\laminitial(When/Then), \\meemfinal\\ainmedial\\nooninitial\n(Yes), \\kafisolated\\aleffinal\\noonmedial\\hehinitial(There),\n\\lamwithalefisolated\\wawfinal\\laminitial(Unless), \\wawfinal\\laminitial\n(If), \\noonfinal\\meeminitial(From), \\dalfinal\\noonmedial\\aininitial\n(At/When), \\hehfinal\\lammedial\\laminitial\\alefisolated\\wawisolated(I\nswear), \\yehfinal\\fehinitial(In), \\lamwithalefisolated\n(No)\nTAOCD\n(Zaidan\nand\nCallison-\nBurch,\n2011)\nTAOCD\n(Zaidan\nand\nCallison-\nBurch,\n2011)\nbn\n (I),\n(His/Her),\n (If),\n(It),\n (What),\n(Why),\n(He/She),\n (OK),\n(But),\n(They)\nInFormal\n(Krishna\net al.,\n2022)\nInFormal +\nMicroblog\ndataset\n(Chowd-\nhury and\nChowd-\nhury,\n2014)\nen The, I, This, He, She,\nYou, They, We, Do,\nThere\nGYAFC\n(Rao and\nTetreault,\n2018)\nGYAFC\n(Rao and\nTetreault,\n2018)\nfr C’est (It is), Ils (They),\nElles (They), Il (He),\nelle (She), ce (This),\nEst-ce que (question),\nÇa (That), Ce (This),\nDeux (Two)\nXFORMAL\n(Briakou\net al.,\n2021b)\nXFORMAL\n(Briakou\net al.,\n2021b)\nes Por la (For the), Las\n(The), Los (The), Por\nel (For the), Con unos\n(With some), Por que\nla (Why the), Se ha (It\nhad), Por su (Because\nof), Para un (For a),\nDe una (Of a)\nWikipedia\n(Cañete,\n2019)\n9322 rap\nlyrics in\nSpanish\n(filtered)\n(Muñoz,\n2018)\nTable 2: Prompts used in our experiments. +List of the\nshort prompts across the 5 languages. 10 prompts per\nlanguage are used for 10 generations sampled for each\nprompt. *Sources of the formal/informal prompts. 100\nprompts per language are sampled from these datasets.\n4.2 Generation Parameters\nDecoding parameters are essential because they\ncan directly affect a language model’s output. For\neach language, we select a set of parameters to pro-\nduce fluent text that can be appropriately evaluated.\nAll selections were chosen to impact the formality\n2654\nModel/Language Arabic Bengali English French Spanish\nXGLM(2.9B) 9.3% 8.0% 6.7% 16.0% 6.7%\nBLOOM(3B) 13.3% 4.3% 3.3% 12.0% 3.3%\nXGLM(7.5B) 8.7% 5.0% 10.0% 18.0% 7.7%\nBLOOM(7.1B) 12.3% 6.3% 3.7%* 8.7%* 2.7%*\nTable 3: % of incohesive samples out of the 1200 generated samples for each language (300 samples per model).\nPercentages are averaged across prompt types (400 neutral, 400 formal, and 400 informal prompts). Bolded values\nshow that the corresponding model is significantly better according to a permutation-based statistical test with a\np-value ≤5%.\nlevel of models as little as possible. This subsec-\ntion presents our list of generation parameters to\nreproduce our experiments.\nGlobal generation parameters We modified the\ndecoding procedures to avoid very short sentences,\ncode snippets, and outputs in other languages to\nproduce an assessable amount of outputs with a\nsignificant length to be evaluated. The parameters\nare listed in Appendix A.\nRegarding the total number of evaluated outputs,\nwe generated three sets for each evaluated model\nand language: 100 with short prompts, 100 with\nformal prompts, and 100 with informal prompts.\nThat resulted in 1200 generated outputs for each\nlanguage.\nLanguage-specific generation parameters Be-\nfore generating the sequences for formality evalu-\nation, we tweaked some logit parameters for each\nlanguage. All modifications were done to obtain\nmore fluent sequences and reduce incohesive out-\nputs such as ones with generation repetitions or\nnon-understandable text. This process was done\nwith a varied set of prompts regardless of length\nand formality level.\nWe use sampling to obtain the generation out-\nputs for both models. Three specific parameters\nwere set for both models: We settop-k to 50, which\ntruncates the number of tokens to sample from. We\nset a high top-p (Holtzman et al., 2019) to generate\ndiverse sampled tokens by cumulative frequency,\nand a high temperature (Ackley et al., 1985), which\ndoes not skew the distribution towards high proba-\nbility tokens. The specific details of the parameters\nto reproduce our experiments can be found in Ap-\npendix A.\n4.3 Formality Evaluation\nWe assessed the formality of all generated outputs.\nTo do so, one native/proficient speaker of each lan-\nguage classified all 1200 generated sequences indi-\nvidually. We opted for this evaluation procedure be-\ncause, at the time of performing the experiments, to\nour knowledge, there were no multilingual formal-\nity classifier models that included Arabic, Bengali,\nEnglish, Spanish, and French. To avoid possible bi-\nases, each generated output was annotated without\nlooking at its prompt and in a randomized order.\nAll annotations were done by the authors them-\nselves who are native speakers of the languages.\nTo validate the quality of our annotation process,\nwe also collect 3 ratings (collecting the annotations\nfrom 2 extra annotators) per sample for 50 samples\nand report the observed inter-annotator agreement\nin the Appendix in Table 7. We find the inter-\nannotator agreement to be above 59% for all the\nlanguages reported.\nThe classification categories for all languages\nare formal, informal, and incohesive. A sequence\nis classified as formal or informal according to the\nrules of each language described in section 2. The\n\"Incohesive\" label is only assigned under certain\nconditions, such as sequences written in other lan-\nguages, non-understandable text (with e.g. many\nrepeated symbol/blank tokens) that cannot be eval-\nuated for formality level, or code snippets.\n5 Results & Analysis\nWe start by analyzing the cohesiveness of each\nmodel. We then focus on the cohesive text for\nanalyzing formality.\n5.1 Cohesiveness of Generation\nAs seen in Table 3, BLOOM(7.1B) generates signif-\nicantly more cohesive texts than XGLM(7.5B) for\nEnglish, French, and Spanish with p-values under\n5%, of a permutation-based statistical test.\nInterestingly, the results in Table 3 also show that\na larger model does not necessarily lead to more\ncohesive generations. For example, BLOOM(3B)\n2655\nModel/Language Arabic Bengali English French Spanish\nXGLM(2.9B) 92% -3% 14% 41% 58%\nBLOOM(3B) 100% -6% -6% -1%* 79%\nXGLM(7.5B) 83%* 33% 8% 32% 45%\nBLOOM(7.1B) 100% -3%* -13% 14% 67%\nTable 4: % differences between formal and informal predictions (400 samples per language) sampled with neutral\nprompts. Light Gray indicates a bias toward formal generations and Dark Gray indicates a bias toward informal\ngenerations. Bolded values show that the corresponding model is significantly better (i.e. closer to 0) than the other\nmodel of the same size (based on a permutation-based test with p-value ≤5%).\ngenerates more cohesive texts than BLOOM(7.1B)\nfor Bengali and English. XGLM(2.9B) also gen-\nerates more cohesive texts than XGLM(7.5B) for\nEnglish, French, and Spanish. Is worth noting that\nwe are only evaluating cohesiveness in a binary\nway (cohesive vs. incohesive) and are not judging\nthe quality of the predictions beyond that.\nBesides, the percentage of incohesive texts is\nnoticeably higher for some languages than others\nfor both BLOOM and XGLM. For example, the\nhighest percentage of incohesive texts in the case\nof Bengali, English, and Spanish is less than or\nequal to 10%, while that percentage is higher in the\ncase of Arabic and French.\n5.2 Formality-Level Bias\nNeutral prompts, given to an assumingly unbiased\nmodel, should lead to equal distributions of formal\nand informal generations with a difference close to\nzero between both generations. However, this is not\nthe case here, as shown in Table 4. In the case of\nBengali, we see that XGLM(2.9B), BLOOM(3B),\nand BLOOM(7.1B) are almost neutral with mi-\nnor differences of -3% -6% and -3%, respectively,\nshowing bias toward informal generations. On\nthe other hand, we see XGLM(7.5B), surprisingly,\nshowing significantly more bias toward formal gen-\nerations than BLOOM(7.1B) with a difference of\n33%. Upon qualitative analysis, we found that\nmany of the generations of XGLM(7.5B) had Ben-\ngali religious Islamic text-like attributes that were\nconsidered formal during annotation, and the usage\nof hashtags or emojis was also less than the smaller\nmodel for neutral prompts.\nBLOOM, for French, continues to show less bias\nshowing only a bias of 1% toward informal genera-\ntions in the case of BLOOM(3B) and 14% towards\nformal generations in the case of BLOOM(7.1B).\nOn the other hand, XGLM(2.9B) shows signifi-\ncantly more bias than BLOOM(3B) toward formal\ngenerations with a difference of 41%. For English,\nXGLM and BLOOM both show a small bias (in\nterms of percentages) towards different directions.\nXGLM(2.9B) and XGLM(7.5B) show bias towards\nformal generations by 14% and 8% respectively.\nHowever, BLOOM(3B) and BLOOM(7.1B) dis-\nplay bias towards informal generations by 6% and\n13% respectively. After a careful review of the\npredictions, we find that French and English in-\nformal predictions of BLOOM are due to a large\nproportion of informal generated dialogs.\nBLOOM, this time for Spanish, shows extreme\nbias towards the formal generations with a dif-\nference of 79% for BLOOM(3B) and 67% for\nBLOOM(7.1B). On the other hand, XGLM ex-\nhibits less bias towards formal generations with\na difference of 58% for XGLM(2.9B) and 45% for\nXGLM(7.5B). These values indicate that both mod-\nels are influenced by formal sources. In fact, most\nof the generated sequences with short prompts have\nthe style of news and Wikipedia articles.\nA biased distribution of outputs could be rea-\nsoned by the data the model was trained on. As\nstated in BLOOM (Scao et al., 2022), the biggest\npart of the corpus for Arabic was the Arabic-\nfocused Masader repository (Alyafeai et al., 2021;\nAltaher et al., 2022), which is dominated by Mod-\nern Standard Arabic (MSA) that is considered for-\nmal (cf. section 2). This explains the extreme\nbias BLOOM(3B) and BLOOM(7.1B) show to-\nwards formal generations with a bias of 100%.\nXGLM(7.5B) similarly shows an extreme bias to-\nward formal generations, but significantly less than\nBLOOM(7.1B) with a difference of 83%.\nIn terms of model size, we notice that\nXGLM(2.9B) shows more bias towards formal or\ninformal generations than XGLM(7.5B) for all the\nlanguages except Bengali, which could indicate\nthat the bigger the XGLM model’s size, the less bi-\nased it is. On the other hand, this isn’t the case for\n2656\nModel/Language Arabic Bengali English French Spanish\nF→F% / I→I% F →F % / I→I% F →F% / I→I% F →F% / I→I% F →F% / I→I%\nXGLM(2.9B) 89.4% / 61.1% 79.8% / 100.0%* 34.0% / 94.0% 26.7% / 59.5% 85.9% / 80.2%\nBLOOM(3B) 94.2% / 55.1% 83.7% / 87.1% 29.2% / 91.7% 32.0% / 82.0%* 77.8% / 90.4%\nXGLM(7.5B) 88.6% / 76.7%* 75.5% / 98.8% 34.4% / 84.7% 54.0%*/ 75.6% 86.9% / 75.8%\nBLOOM(7.1B) 93.5% / 51.1% 74.0% / 91.9% 27.6% / 94.0%* 25.8% / 66.7% 83.8% /96.8%*\nTable 5: Formality preservation samples’ percentages for Formal / Informal prompts (800 prompts per language:\n400 formal and 400 informal). Each sample is annotated as either formal, informal, or incohesive and the percentages\nare calculated without incohesive text counts. Bolded values show that the corresponding model is significantly\nbetter according to a permutation-based statistical test with a p-value ≤5%.\nBLOOM as BLOOM(3B) is only expressing more\nbias for Bengali and Spanish, while BLOOM(7.1B)\nshows more bias for English and French.\nIn summary, the models show moderate bias for\nsome languages such as English and Bengali, ex-\ncept for XGLM(7.5B) in the case of Bengali, while\nalso showing extreme bias for other languages such\nas Arabic, French, and Spanish. This difference\nmight be caused by the fact that every language is\npresent in the data with a different percentage and\nis coming from different sources as shown in Ta-\nble 8. Overall, it is noticeable that the bias is mostly\ntoward formal generations for all the models and\nfor all the languages.\n5.3 Formality-Level Preservation\nIn this experiment, we measure how well the for-\nmality of a generation is the same as the formality\nlevel of the prompt (i.e. how well the model pre-\nserves the formality-level of the prompt). We find\nthat the formality style of the prompts is preserved\nefficiently for some languages by some models\nwhile being almost ignored in some other cases.\nFor Arabic, as we show in Table 5, BLOOM(3B)\nand BLOOM(7.1B) preserve the formality style\nof 94.2% and 93.5%, respectively, of the samples\nwhen the given prompt is formal. We note that\ndespite being highly biased toward formal text in\nArabic (as seen in section 5.2), both models are\nable to preserve the style of informal prompts, at\nleast 51.1% of the time.\nXGLM(2.9B), for Bengali, preserves the style\nof the informal prompts of significantly more sam-\nples than BLOOM(3B) with a percentage of 100%.\nBLOOM pays attention to the informal style of the\nprompts as well, unlike the case for Arabic, and\npreserves the style of 87.1% of the samples gener-\nated with BLOOM(3B) and 91.9% of the samples\ngenerated with BLOOM(7.1B).\nBoth BLOOM and XGLM, this time for English,\ndo not preserve the formal style of the prompts for\nmore than 34.4% of the samples for any model.\nHowever, they both preserve the informal style\nin at least 84.7% of the generated samples with\nBLOOM(7.1B) preserving significantly more sam-\nples than XGLM(7.5B). A similar trend follows\nfor French with both BLOOM and XGLM un-\nable to preserve the formal style for more than\n32.0% of the samples in the case of XGLM(2.9B),\nBLOOM(3B) and BLOOM(7.1B). On the other\nhand, XGLM(7.5) preserves the formal style signif-\nicantly better than BLOOM(7.1B) with a percent-\nage of 54.0%. And again the informal style is being\npreserved better with, specifically, BLOOM(3B)\nwhich preserves the style better than XGLM(2.9B)\nwith a percentage of 82%.\nThe formal and informal styles in Spanish are\npreserved consistently across the models to at\nleast 77.8% of the samples with formal prompts\nand at least 75.8% with informal prompts with\nBLOOM(7.1B) preserving the style in significantly\nmore samples than XGLM(7.5B).\nIn terms of model size, we notice that the size\nof the model is not an indicator of how well the\nmodel can preserve the formality style. For exam-\nple, BLOOM(3B) preserves the formal style better\nthan BLOOM(7.1B) for all languages except Span-\nish. In summary, we see that the informal style\nis mostly preserved well for most languages ex-\ncept with BLOOM for Arabic. The formal style,\non the other hand, is mostly preserved well for all\nlanguages except English and French.\n5.4 Typographic and Lexical Differences\nbetween Formal/Informal Generations\nWe report in Table 9 general statistics about the\ngenerated texts of each model and language by\nformality level. Results show that BLOOM gener-\n2657\nates about twice longer texts as XGLM. In terms\nof the average number of sentences per genera-\ntion, BLOOM, when the generation is informal,\ngenerates more and shorter sentences than when\nthe generation is formal. Also, informal genera-\ntions tend to have emojis as expected, especially\nin the case of Bengali. Besides, informal gener-\nations tend to have more punctuation marks than\nformal ones. Finally, the results of the average\nnumber of new lines and the average number of “-”,\nwhich are used to signal dialogues, support what\nwe mentioned earlier about BLOOM’s tendency to\ngenerate conversational text.\n6 Discussion\nFormality bias when present in multilingual mod-\nels, which are increasingly popular nowadays, can\nlead to undesirable outcomes. For example, using\n\"please\" is common among North American En-\nglish native speakers in requests, even among close\nfriends, while in Arabic, it could be considered\nawkward, if not rude, in conversations among close\nfriends (Hovy and Yang, 2021). A usage example\nof language models is solving downstream tasks\nusing prompting techniques for zero-shot learning,\nsuch as (Zhong et al., 2021)’s work on question-\nanswering. Prompting has also been used with\nlarge language models for conversational chatbots\nsuch as ChatGPT (Ouyang et al., 2022). As prompt-\ning is becoming popular, we must understand that\nprompting a model that exhibits formality bias\ncould be a barrier to getting the expected output.\nFurthermore, depending on the application, formal-\nity bias could even lead to sometimes unwanted\nmisunderstandings (Hershcovich et al., 2022) and\nconflicts if the models, for example, are not able\nto generate text in the formality style of the users’\nexpectations.\nControlling LLMs generations has been taken\ninto consideration in recent work, such as in\n(Ouyang et al., 2022), where they fine-tune a lan-\nguage model (Brown et al., 2020a) intending to\nalign the model with the intent of the users us-\ning reinforcement learning from human feedback\n(RLHF) (Christiano et al., 2017; Stiennon et al.,\n2020). Future work could analyze the impact of\nRLHF on the formality distributions present in lan-\nguage models. Furthermore, our work focused only\non two pre-trained models with up to 7B param-\neters. The same analysis could be conducted for\nlarger models such as GPT-3 and BLOOM(175B).\nFinally, the increase in the number of multilingual\nlanguage models calls for more work on their bi-\nases.\n7 Conclusion\nIn conclusion, we analyzed the formality level of\nthe generations of two large-scale generative lan-\nguage models, XGLM and BLOOM, ranging from\n2B parameters to 7B parameters. We first observed\nthe cohesiveness of the predictions. We found that\nBLOOM(7.1B) predicts significantly more cohe-\nsive text than XGLM(7.5B) for English, French,\nand Spanish. Second, we showed that, across all\nfive languages, both models tend to generate formal\ntext when prompted neutrally. Finally, we found\nthat the formality of the prompt highly impacts\nboth models. In most cases, they generate the same\nstyle as the prompt, with slight differences between\nthe models depending on the language. Our analy-\nsis is based on the annotations of 1,200 generations\nin Arabic, Bengali, English, French, and Spanish.\nWe release them with this paper opening future\navenues for modeling the formality of generative\nmultilingual language models.\n8 Limits\nIn this work, we experiment only with two models,\nXGLM and BLOOM. The limitation of computing\nresources tied us with models that have 7.5B param-\neters or less and the limitation of financial resources\nand manpower held us back from experimenting\nwith more languages. Furthermore, the generated\nsamples of each language were annotated by only\none annotator, except for English. To validate our\nmethodology we asked two extra native speakers\nof each language to annotate 50 samples per lan-\nguage. We share the observed inter-annotator agree-\nment values in Table 7 (Gwet, 2014). We find the\nobserved agreement to be above 59% for all the\nreported languages, supporting the quality of our\nannotation process. Finally, we note that despite\nthe aforementioned limitations, the methodology\nused in this study can be applied to any generative\nsystem and language.\n9 Acknowledgment\nWe thank the Fatima Fellowship 5 and Hugging\nFace for organizing and sponsoring the Fatima Re-\nsearch Fellowship program.\n5cf. https://www.fatimafellowship.com/\n2658\nReferences\nAbubakar Abid, Maheen Farooqi, and James Zou. 2021.\nPersistent anti-muslim bias in large language models.\nIn Proceedings of the 2021 AAAI/ACM Conference\non AI, Ethics, and Society, AIES ’21, page 298–306,\nNew York, NY , USA. Association for Computing\nMachinery.\nFadi Abu Sheikha and Diana Inkpen. 2010. Auto-\nmatic classification of documents by formality. In\nProceedings of the 6th International Conference\non Natural Language Processing and Knowledge\nEngineering(NLPKE-2010), pages 1–5.\nDavid H Ackley, Geoffrey E Hinton, and Terrence J Se-\njnowski. 1985. A learning algorithm for boltzmann\nmachines. Cognitive science, 9(1):147–169.\nYousef Altaher, Ali Fadel, Mazen Alotaibi, Mazen\nAlyazidi, Mishari Al-Mutairi, Mutlaq Aldhbuiub, Ab-\ndulrahman Mosaibah, Abdelrahman Rezk, Abdulraz-\nzaq Alhendi, Mazen Shal, Emad Alghamdi, Maged\nAlshaibani, Jezia Zakraoui, Wafaa Mohammed,\nKamel Gaanoun, Khalid Elmadani, Mustafa Ghaleb,\nNouamane Tazi, Raed Alharbi, and Zaid Alyafeai.\n2022. Masader plus: A new interface for exploring\n+500 arabic nlp datasets.\nZaid Alyafeai, Maraim Masoud, Mustafa Ghaleb, and\nMaged S. Al-shaibani. 2021. Masader: Metadata\nsourcing for arabic text and speech data resources.\nRohan Anil, Andrew M. Dai, Orhan Firat, Melvin\nJohnson, Dmitry Lepikhin, Alexandre Tachard Pas-\nsos, Siamak Shakeri, Emanuel Taropa, Paige Bai-\nley, Z. Chen, Eric Chu, J. Clark, Laurent El Shafey,\nYanping Huang, Kathleen S. Meier-Hellstern, Gau-\nrav Mishra, Erica Moreira, Mark Omernick, Kevin\nRobinson, Sebastian Ruder, Yi Tay, Kefan Xiao,\nYuanzhong Xu, Yujing Zhang, Gustavo Hernandez\nAbrego, Junwhan Ahn, Jacob Austin, Paul Barham,\nJan A. Botha, James Bradbury, Siddhartha Brahma,\nKevin Michael Brooks, Michele Catasta, Yongzhou\nCheng, Colin Cherry, Christopher A. Choquette-\nChoo, Aakanksha Chowdhery, C Crépy, Shachi\nDave, Mostafa Dehghani, Sunipa Dev, Jacob De-\nvlin, M. C. D’iaz, Nan Du, Ethan Dyer, Vladimir\nFeinberg, Fan Feng, Vlad Fienber, Markus Freitag,\nXavier García, Sebastian Gehrmann, Lucas González,\nGuy Gur-Ari, Steven Hand, Hadi Hashemi, Le Hou,\nJoshua Howland, An Ren Hu, Jeffrey Hui, Jeremy\nHurwitz, Michael Isard, Abe Ittycheriah, Matthew\nJagielski, Wen Hao Jia, Kathleen Kenealy, Maxim\nKrikun, Sneha Kudugunta, Chang Lan, Katherine\nLee, Benjamin Lee, Eric Li, Mu-Li Li, Wei Li,\nYaguang Li, Jun Yu Li, Hyeontaek Lim, Han Lin,\nZhong-Zhong Liu, Frederick Liu, Marcello Mag-\ngioni, Aroma Mahendru, Joshua Maynez, Vedant\nMisra, Maysam Moussalem, Zachary Nado, John\nNham, Eric Ni, Andrew Nystrom, Alicia Parrish,\nMarie Pellat, Martin Polacek, Alex Polozov, Reiner\nPope, Siyuan Qiao, Emily Reif, Bryan Richter, Parker\nRiley, Alexandra Ros, Aurko Roy, Brennan Saeta,\nRajkumar Samuel, Renee Marie Shelby, Ambrose\nSlone, Daniel Smilkov, David R. So, Daniela Sohn,\nSimon Tokumine, Dasha Valter, Vijay Vasudevan, Ki-\nran V odrahalli, Xuezhi Wang, Pidong Wang, Zirui\nWang, Tao Wang, John Wieting, Yuhuai Wu, Ke Xu,\nYunhan Xu, Lin Wu Xue, Pengcheng Yin, Jiahui Yu,\nQiaoling Zhang, Steven Zheng, Ce Zheng, Wei Zhou,\nDenny Zhou, Slav Petrov, and Yonghui Wu. 2023.\nPalm 2 technical report. ArXiv, abs/2305.10403.\nAs-Said Muhámmad Badawi. 1973. Mustawayat al-\narabiyya al-muasira fi Misr. Dar al-maarif.\nFrancesco Barbieri, Luis Espinosa Anke, and Jose\nCamacho-Collados. 2022. Xlm-t: Multilingual lan-\nguage models in twitter for sentiment analysis and\nbeyond. In Proceedings of the Thirteenth Language\nResources and Evaluation Conference, pages 258–\n266.\nSoumya Barikeri, Anne Lauscher, Ivan Vuli´c, and Goran\nGlavaš. 2021. RedditBias: A real-world resource for\nbias evaluation and debiasing of conversational lan-\nguage models. In Proceedings of the 59th Annual\nMeeting of the Association for Computational Lin-\nguistics and the 11th International Joint Conference\non Natural Language Processing (Volume 1: Long\nPapers), pages 1941–1955, Online. Association for\nComputational Linguistics.\nKate Beeching, Françoise Gadet, and Nigel Armstrong.\n2009. Sociolinguistic variation in contemporary\nfrench. Sociolinguistic Variation in Contemporary\nFrench, pages 1–272.\nEmily M. Bender, Timnit Gebru, Angelina McMillan-\nMajor, and Shmargaret Shmitchell. 2021. On the\ndangers of stochastic parrots: Can language mod-\nels be too big? In Proceedings of the 2021 ACM\nConference on Fairness, Accountability, and Trans-\nparency, FAccT ’21, page 610–623, New York, NY ,\nUSA. Association for Computing Machinery.\nSu Lin Blodgett, Solon Barocas, Hal Daumé III, and\nHanna Wallach. 2020. Language (technology) is\npower: A critical survey of “bias” in NLP. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 5454–\n5476, Online. Association for Computational Lin-\nguistics.\nRishi Bommasani, Drew A Hudson, Ehsan Adeli,\nRuss Altman, Simran Arora, Sydney von Arx,\nMichael S Bernstein, Jeannette Bohg, Antoine Bosse-\nlut, Emma Brunskill, et al. 2021. On the opportuni-\nties and risks of foundation models. arXiv preprint\narXiv:2108.07258.\nEleftheria Briakou, Sweta Agrawal, Joel Tetreault, and\nMarine Carpuat. 2021a. Evaluating the evaluation\nmetrics for style transfer: A case study in multilin-\ngual formality transfer. In Proceedings of the 2021\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 1321–1336, Online and\nPunta Cana, Dominican Republic. Association for\nComputational Linguistics.\n2659\nEleftheria Briakou, Di Lu, Ke Zhang, and Joel Tetreault.\n2021b. Olá, bonjour, salve! XFORMAL: A bench-\nmark for multilingual formality style transfer. In\nProceedings of the 2021 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\npages 3199–3216, Online. Association for Computa-\ntional Linguistics.\nJulian Brooke, Tong Wang, and Graeme Hirst. 2010.\nAutomatic acquisition of lexical formality. In Coling\n2010: Posters, pages 90–98.\nRoger Brown, Albert Gilman, et al. 1960. The pronouns\nof power and solidarity.Style in language, pages 252–\n281.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens\nWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-\nteusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020a.\nLanguage models are few-shot learners. In Ad-\nvances in Neural Information Processing Systems ,\nvolume 33, pages 1877–1901. Curran Associates,\nInc.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020b. Language models are few-shot\nlearners. Advances in neural information processing\nsystems, 33:1877–1901.\nYang Trista Cao and Hal Daumé III. 2020. Toward\ngender-inclusive coreference resolution. In Proceed-\nings of the 58th Annual Meeting of the Association\nfor Computational Linguistics, pages 4568–4595, On-\nline. Association for Computational Linguistics.\nJosé Cañete. 2019. Compilation of large spanish\nunannotated corpora= https://doi.org/10.5281/\nzenodo.3247731.\nP. Cépeda and E. Tavera. 2007. Redacción de textos for-\nmales: manual de consulta y modelos de redacción\npara escolares de 5° de secundaria. PUCP. Oficina\nCentral de Adminsión.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, et al. 2022. Palm: Scaling\nlanguage modeling with pathways. arXiv preprint\narXiv:2204.02311.\nShaika Chowdhury and Wasifa Chowdhury. 2014. Per-\nforming sentiment analysis in bangla microblog posts.\nIn 2014 International Conference on Informatics,\nElectronics & Vision (ICIEV), pages 1–6. IEEE.\nPaul F Christiano, Jan Leike, Tom Brown, Miljan Mar-\ntic, Shane Legg, and Dario Amodei. 2017. Deep\nreinforcement learning from human preferences. Ad-\nvances in neural information processing systems, 30.\nSamuel Rhys Cox and Wei Tsang Ooi. 2022. Does chat-\nbot language formality affect users’ self-disclosure?\nIn Proceedings of the 4th Conference on Conversa-\ntional User Interfaces, CUI ’22, New York, NY , USA.\nAssociation for Computing Machinery.\nIsak Czeresnia Etinger and Alan W Black. 2019. For-\nmality style transfer for noisy, user-generated con-\nversations: Extracting labeled, parallel data from\nunlabeled corpora. In Proceedings of the 5th Work-\nshop on Noisy User-generated Text (W-NUT 2019),\npages 11–16, Hong Kong, China. Association for\nComputational Linguistics.\nShishir Kumar Das. 1968. Forms of address and terms\nof reference in bengali. Anthropological Linguistics,\n10(4):19–31.\nAnne Boyle David. 2015. Descriptive Grammar of\nBangla. De Gruyter Mouton, Berlin, München,\nBoston.\nThomas Davidson, Debasmita Bhattacharya, and Ing-\nmar Weber. 2019. Racial bias in hate speech and\nabusive language detection datasets. In Proceedings\nof the Third Workshop on Abusive Language Online,\npages 25–35, Florence, Italy. Association for Com-\nputational Linguistics.\nDaryna Dementieva, Ivan Trifinov, Andrey Likhachev,\nand Alexander Panchenko. 2022. Detecting text for-\nmality: A study of text classification approaches.\narXiv preprint arXiv:2204.08975.\nWeston Feely, Eva Hasler, and Adrià de Gispert.\n2019. Controlling Japanese honorifics in English-\nto-Japanese neural machine translation. In Proceed-\nings of the 6th Workshop on Asian Translation, pages\n45–53, Hong Kong, China. Association for Computa-\ntional Linguistics.\nVirginia K. Felkner, Ho-Chun Herbert Chang, Eugene\nJang, and Jonathan May. 2022. Towards winoqueer:\nDeveloping a benchmark for anti-queer bias in large\nlanguage models. ArXiv, abs/2206.11484.\nFrançoise Gadet. 2005. Research on sociolinguistic\nstyle/Soziolinguistische Stilforschung. In Ulrich Am-\nmon, Norbert Dittmar, Karl Mattheier, and Peter\nTrudgill, editors, Sociolinguistics-Soziolinguistik, An\nInternational Handbook of the Science of Language\nand Society, volume V ol 2, pages 1353–1361. Walter\nde Gruyter.\nSamarjit Ghosh, Souvik Mukherjee, Debojyoti Roy,\nSumit Sarkar, and Debranjan Sarkar. 2022. Bangla\nlanguage processing: Sandhi. In 2022 IEEE India\nCouncil International Subsections Conference (IN-\nDISCON), pages 1–5. IEEE.\n2660\nKilem L Gwet. 2014. Handbook of inter-rater reliabil-\nity: The definitive guide to measuring the extent of\nagreement among raters. Advanced Analytics, LLC.\nDaniel Hershcovich, Stella Frank, Heather Lent,\nMiryam de Lhoneux, Mostafa Abdou, Stephanie\nBrandl, Emanuele Bugliarello, Laura Cabello Pi-\nqueras, Ilias Chalkidis, Ruixiang Cui, Constanza\nFierro, Katerina Margatina, Phillip Rust, and Anders\nSøgaard. 2022. Challenges and strategies in cross-\ncultural NLP. In Proceedings of the 60th Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers), pages 6997–7013,\nDublin, Ireland. Association for Computational Lin-\nguistics.\nFrancis Heylighen and Jean-Marc Dewaele. 1999. For-\nmality of language: definition, measurement and be-\nhavioral determinants. Interner Bericht, Center “Leo\nApostel”, Vrije Universiteit Brüssel, 4.\nAri Holtzman, Jan Buys, Li Du, Maxwell Forbes, and\nYejin Choi. 2019. The curious case of neural text de-\ngeneration. In International Conference on Learning\nRepresentations.\nDirk Hovy and Diyi Yang. 2021. The importance of\nmodeling social factors of language: Theory and\npractice. In Proceedings of the 2021 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, pages 588–602, Online. Association\nfor Computational Linguistics.\nXiaoze Jiang, Yaobo Liang, Weizhu Chen, and Nan\nDuan. 2022. Xlm-k: Improving cross-lingual lan-\nguage model pre-training with multilingual knowl-\nedge. In Proceedings of the AAAI Conference on Ar-\ntificial Intelligence, volume 36, pages 10840–10848.\nElizaveta Korotkova, Agnes Luhtaru, Maksym Del,\nKrista Liin, Daiga Deksne, and Mark Fishel. 2019.\nGrammatical error correction and style transfer via\nzero-shot monolingual translation. arXiv preprint\narXiv:1903.11283.\nKalpesh Krishna, Deepak Nathani, Xavier Garcia,\nBidisha Samanta, and Partha Talukdar. 2022. Few-\nshot controllable style transfer for low-resource mul-\ntilingual settings. In Proceedings of the 60th Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers), pages 7439–7468,\nDublin, Ireland. Association for Computational Lin-\nguistics.\nShibamouli Lahiri. 2015. Squinky! a corpus of\nsentence-level formality, informativeness, and im-\nplicature. arXiv preprint arXiv:1506.02306.\nPaul Pu Liang, Chiyu Wu, Louis-Philippe Morency, and\nRuslan Salakhutdinov. 2021. Towards understanding\nand mitigating social biases in language models. In\nInternational Conference on Machine Learning.\nCassi L Liardét, Sharyn Black, and Vani Sharren\nBardetta. 2019. Defining formality: Adapting to\nthe abstract demands of academic discourse. Journal\nof English for Academic Purposes, 38:146–158.\nJindˇrich Libovický, Rudolf Rosa, and Alexander Fraser.\n2020. On the language neutrality of pre-trained mul-\ntilingual representations. In Findings of the Associ-\nation for Computational Linguistics: EMNLP 2020,\npages 1663–1674, Online. Association for Computa-\ntional Linguistics.\nXi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu\nWang, Shuohui Chen, Daniel Simig, Myle Ott, Na-\nman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth\nPasunuru, Sam Shleifer, Punit Singh Koura, Vishrav\nChaudhary, Brian O’Horo, Jeff Wang, Luke Zettle-\nmoyer, Zornitsa Kozareva, Mona Diab, Ves Stoyanov,\nand Xian Li. 2021a. Few-shot learning with multilin-\ngual language models. ArXiv, abs/2112.10668.\nXi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu\nWang, Shuohui Chen, Daniel Simig, Myle Ott, Na-\nman Goyal, Shruti Bhosale, Jingfei Du, et al. 2021b.\nFew-shot learning with multilingual language models.\narXiv preprint arXiv:2112.10668.\nAman Madaan, Amrith Setlur, Tanmay Parekh, Barn-\nabas Poczos, Graham Neubig, Yiming Yang, Ruslan\nSalakhutdinov, Alan W Black, and Shrimai Prabhu-\nmoye. 2020. Politeness transfer: A tag and generate\napproach. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 1869–1881, Online. Association for Computa-\ntional Linguistics.\nVijit Malik, Sunipa Dev, Akihiro Nishi, Nanyun Peng,\nand Kai-Wei Chang. 2022. Socially aware bias mea-\nsurements for Hindi language representations. In\nProceedings of the 2022 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\npages 1041–1052, Seattle, United States. Association\nfor Computational Linguistics.\nBenjamin Muller, Yanai Elazar, Benoît Sagot, and\nDjamé Seddah. 2021. First align, then predict: Un-\nderstanding the cross-lingual ability of multilingual\nBERT. In Proceedings of the 16th Conference of the\nEuropean Chapter of the Association for Computa-\ntional Linguistics: Main Volume, pages 2214–2231,\nOnline. Association for Computational Linguistics.\nSamuel Muñoz. 2018. 9322 letras de rap en español,\nversion 1. https://www.kaggle.com/datasets/\nsmunoz3801/9325-letras-de-rap-en-espaol .\nMoin Nadeem, Anna Bethke, and Siva Reddy. 2021.\nStereoSet: Measuring stereotypical bias in pretrained\nlanguage models. In Proceedings of the 59th Annual\nMeeting of the Association for Computational Lin-\nguistics and the 11th International Joint Conference\non Natural Language Processing (Volume 1: Long\nPapers), pages 5356–5371, Online. Association for\nComputational Linguistics.\n2661\nMaria Nadejde, Anna Currey, Benjamin Hsu, Xing\nNiu, Marcello Federico, and Georgiana Dinu. 2022.\nCoCoA-MT: A dataset and benchmark for contrastive\ncontrolled MT with application to formality. In Find-\nings of the Association for Computational Linguistics:\nNAACL 2022, pages 616–632, Seattle, United States.\nAssociation for Computational Linguistics.\nHemalatha Nagarajan. 2014. Constraints through the\nages: Loan words in bangla. The EFL Journal ,\n5(1):41–63.\nNikita Nangia, Clara Vania, Rasika Bhalerao, and\nSamuel R. Bowman. 2020. CrowS-pairs: A chal-\nlenge dataset for measuring social biases in masked\nlanguage models. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language\nProcessing (EMNLP), pages 1953–1967, Online. As-\nsociation for Computational Linguistics.\nAurélie Névéol, Yoann Dupont, Julien Bezançon, and\nKarën Fort. 2022. French CrowS-Pairs: Extending a\nchallenge dataset for measuring social bias in masked\nlanguage models to a language other than English. In\nACL 2022 - 60th Annual Meeting of the Association\nfor Computational Linguistics, Dublin, Ireland.\nXing Niu and Marine Carpuat. 2020. Controlling neural\nmachine translation formality with synthetic super-\nvision. In Proceedings of the AAAI Conference on\nArtificial Intelligence, volume 34, pages 8568–8575.\nXing Niu, Marianna Martindale, and Marine Carpuat.\n2017. A study of style in machine translation: Con-\ntrolling the formality of machine translation output.\nIn Proceedings of the 2017 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n2814–2819, Copenhagen, Denmark. Association for\nComputational Linguistics.\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-\nroll L Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, et al.\n2022. Training language models to follow in-\nstructions with human feedback. arXiv preprint\narXiv:2203.02155.\nHemanta Ranjan Panda. 1992. Rule based\" Sandhi\nBicched\"(de-euphonization) of Bengali. Ph.D. thesis,\nIndian Statistical Institute-Kolkata.\nEllie Pavlick and Joel Tetreault. 2016. An empiri-\ncal analysis of formality in online communication.\nTransactions of the Association for Computational\nLinguistics, 4:61–74.\nTelmo Pires, Eva Schlinger, and Dan Garrette. 2019.\nHow multilingual is multilingual BERT? In Proceed-\nings of the 57th Annual Meeting of the Association for\nComputational Linguistics, pages 4996–5001, Flo-\nrence, Italy. Association for Computational Linguis-\ntics.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, Ilya Sutskever, et al. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog, 1(8):9.\nSudha Rao and Joel Tetreault. 2018. Dear sir or madam,\nmay I introduce the GY AFC dataset: Corpus, bench-\nmarks and metrics for formality style transfer. In\nProceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\nVolume 1 (Long Papers), pages 129–140, New Or-\nleans, Louisiana. Association for Computational Lin-\nguistics.\nPunya Sloka Ray et al. 1966. Bengali language hand-\nbook.\nJack C Richards and Richard W Schmidt. 2013. Long-\nman dictionary of language teaching and applied\nlinguistics. Routledge.\nElijah Rippeth, Sweta Agrawal, and Marine Carpuat.\n2022. Controlling translation formality using pre-\ntrained multilingual language models. arXiv preprint\narXiv:2205.06644.\nDanica Salazar, Aaron Ventura, and Isabel Verdaguer.\n2013. A cross-disciplinary analysis of personal and\nimpersonal features in english and spanish scientific\nwriting. Biomedical English: A corpus-based ap-\nproach, 56:121.\nTeven Le Scao, Angela Fan, Christopher Akiki, El-\nlie Pavlick, Suzana Ili ´c, Daniel Hesslow, Roman\nCastagné, Alexandra Sasha Luccioni, François Yvon,\nMatthias Gallé, et al. 2022. Bloom: A 176b-\nparameter open-access multilingual language model.\narXiv preprint arXiv:2211.05100.\nAndrea Schioppa, David Vilar, Artem Sokolov, and\nKatja Filippova. 2021. Controlling machine transla-\ntion for multiple attributes with additive interventions.\nIn Proceedings of the 2021 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n6676–6696, Online and Punta Cana, Dominican Re-\npublic. Association for Computational Linguistics.\nRico Sennrich, Barry Haddow, and Alexandra Birch.\n2016. Controlling politeness in neural machine trans-\nlation via side constraints. In Proceedings of the 2016\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, pages 35–40, San Diego,\nCalifornia. Association for Computational Linguis-\ntics.\nEmily Sheng, Kai-Wei Chang, Prem Natarajan, and\nNanyun Peng. 2021. Societal biases in language\ngeneration: Progress and challenges. In Proceedings\nof the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing\n(Volume 1: Long Papers), pages 4275–4293, Online.\nAssociation for Computational Linguistics.\nEric Michael Smith, Melissa Hall, Melanie Kambadur,\nEleonora Presani, and Adina Williams. 2022. “I’m\nsorry to hear that”: Finding new biases in language\nmodels with a holistic descriptor dataset. In Proceed-\nings of the 2022 Conference on Empirical Methods\n2662\nin Natural Language Processing, pages 9180–9211,\nAbu Dhabi, United Arab Emirates. Association for\nComputational Linguistics.\nMiranda Stewart. 2001. Pronouns of power and solidar-\nity: The case of spanish first person plural nosotros.\nNisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel\nZiegler, Ryan Lowe, Chelsea V oss, Alec Radford,\nDario Amodei, and Paul F Christiano. 2020. Learn-\ning to summarize with human feedback. Advances\nin Neural Information Processing Systems, 33:3008–\n3021.\nAsifa Sultana. 2016. Description of verb morphology\nin colloquial bangla.\nTony Sun, Andrew Gaut, Shirlyn Tang, Yuxin Huang,\nMai ElSherief, Jieyu Zhao, Diba Mirza, Elizabeth\nBelding, Kai-Wei Chang, and William Yang Wang.\n2019. Mitigating gender bias in natural language\nprocessing: Literature review. In Proceedings of the\n57th Annual Meeting of the Association for Computa-\ntional Linguistics, pages 1630–1640, Florence, Italy.\nAssociation for Computational Linguistics.\nZeerak Talat, Aurélie Névéol, Stella Rose Biderman,\nMiruna Clinciu, Manan Dey, S. Longpre, Alexan-\ndra Sasha Luccioni, Maraim Masoud, Margaret\nMitchell, Dragomir R. Radev, Shanya Sharma, Arjun\nSubramonian, Jaesung Tae, Samson Tan, Deepak R.\nTunuguntla, and Oskar van der Wal. 2022. You reap\nwhat you sow: On the challenges of bias evalua-\ntion under multilingual settings. Proceedings of Big-\nScience Episode #5 – Workshop on Challenges &\nPerspectives in Creating Large Language Models.\nMd Afaz Uddin. 2019. Second person pronouns as\nperson deixis in bengali and english: Linguistic forms\nand pragmatic functions. International Journal of\nEnglish Linguistics, 10(1):345–351.\nAditi Viswanathan, Varden Wang, and Antonina\nKononova. 2020. Controlling formality and style\nof machine translation output using automl. In Infor-\nmation Management and Big Data, pages 306–313,\nCham. Springer International Publishing.\nYunli Wang, Yu Wu, Lili Mou, Zhoujun Li, and Wenhan\nChao. 2019. Harnessing pre-trained neural networks\nwith rules for formality style transfer. In Proceedings\nof the 2019 Conference on Empirical Methods in Nat-\nural Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 3573–3578, Hong Kong,\nChina. Association for Computational Linguistics.\nYunli Wang, Yu Wu, Lili Mou, Zhoujun Li, and Wen-\nHan Chao. 2020. Formality style transfer with shared\nlatent space. In Proceedings of the 28th International\nConference on Computational Linguistics , pages\n2236–2249, Barcelona, Spain (Online). International\nCommittee on Computational Linguistics.\nJanet Watson. 2011. Arabic dialects (general article).\nZonghai Yao and Hong Yu. 2021. Improving formal-\nity style transfer with context-aware rule injection.\nIn Proceedings of the 59th Annual Meeting of the\nAssociation for Computational Linguistics and the\n11th International Joint Conference on Natural Lan-\nguage Processing (Volume 1: Long Papers), pages\n1561–1570, Online. Association for Computational\nLinguistics.\nOmar F. Zaidan and Chris Callison-Burch. 2011. The\nArabic online commentary dataset: an annotated\ndataset of informal Arabic with high dialectal con-\ntent. In Proceedings of the 49th Annual Meeting of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies, pages 37–41, Portland,\nOregon, USA. Association for Computational Lin-\nguistics.\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel\nArtetxe, Moya Chen, Shuohui Chen, Christopher De-\nwan, Mona Diab, Xian Li, Xi Victoria Lin, et al. 2022.\nOpt: Open pre-trained transformer language models.\narXiv preprint arXiv:2205.01068.\nRuiqi Zhong, Kristy Lee, Zheng Zhang, and Dan Klein.\n2021. Adapting language models for zero-shot learn-\ning by meta-tuning on dataset and prompt collections.\narXiv preprint arXiv:2104.04670.\n2663\nA Generation parameters\nWe list here the decoding parameters for both mod-\nels:\n1. We filter out the generation sequences that are\nnot natural language (i.e., code) by excluding\nfrom the generation process all the tokens that\ncontain any of the following symbols: {, }, (,\n), [, ], \\\\, <, >, |, and ; \\n.\n2. We force the model to generate at least 30\nnew subword tokens (excluding the prompt)\nto have a long enough generation sequence\nand be able to assess formality.\n3. We set a maximum of 150 new tokens of gen-\neration to avoid long outputs that could in-\nclude multiple formality variations.\n4. Length of the prompts. For the short-prompt\nsetting, we employ at most three tokens to con-\ndition the generation in the desired language.\nFor the formal/informal prompts, we use 15\nwords (based on white-space tokenization) on\naverage.\n5. Table 6 shows the language-specific genera-\ntion parameters we used for both BLOOM\nand XGLM.\nTop-k Top-p Temperature\nArabic 50 0.95 1\nBengali 50 0.95 1\nEnglish 50 0.95 1\nFrench 50 1 0.8\nSpanish 50 1 0.8\nTable 6: Language-specific generation parameters for\nboth models\nObserved Agreement\nArabic 0.62\nBengali 0.62\nEnglish 0.79\nSpanish 0.59\nTable 7: The inter-annotator agreement (IAA) values\nper language. The values, representing the observed\nagreement, are based on the annotations, of a sample of\ndata, from 3 different native annotators of each language\nfor 50 random samples.\nB Descriptive statistics of the generations\nGeneral statistics of the generations are in Table 9\nreported per language for each model and gener-\nation label pair. The table contains the following\nstatistics: the average length of the generation, the\naverage number of sentences in a generation, the\naverage length of the sentences, the average num-\nber of emojis per generation, the average number\nof punctuation marks per generation, the average\nnumber of new lines per generation, and finally, the\naverage number of the dialogue mark/dash (-) per\ngeneration.\nC XGLM and BLOOM training corpora\nWe show in Table 8 details of the languages used\nin our analysis in the training corpus of BLOOM\nand XGLM.\nD Formality Distribution\nWe visualize the annotated data for each language\nto help in seeing an overview of all the results.\nEach language is represented by a plot, see Fig-\nures 1, 2, 3, 4, and 5, with 12 bars with 3 bars\ncorresponding to each model representing the 3\nprompts types: formal informal, and neutral. Each\nbar in the plot represents 100 texts generated with\nthe corresponding model when prompted with the\ncorresponding prompt type. The colors in each\nbar represent the 3 possible annotations: formal,\ninformal, and incohesive.\n0.0 0.2 0.4 0.6 0.8 1.0\nBLOOM(7.1B)\nBLOOM(3B)\nXGLM(7.5B)\nXGLM(2.9B)\nArabic Formal\nInformal\nIncohesive\nFormal Prompt\nInformal Prompt\nNeutral Prompt\nFigure 1: Plot of the distribution of the generations for\nArabic, for each prompt type, according to their labeled\ncategories: Formal, Informal, and Incohesive. Each bar\nin the plot represents 100 generations.\n2664\nCorpus Size GiB (%) Data source domains\nXGLM BLOOM XGLM BLOOM\nar 64.34* (0.88%)\n∼92 upsampled 69.71 (4.34%) Web Web, news, books, subtitles,\nWikipedia, wikisources\nbn 11.19* (0.15%)\n∼76 upsampled 17.32 (1.15%) Web Web, Wikipedia, Wikisource,\nopen-source NLP datasets\nen 3,324.45 (45.66%) 451.64 (30.04%) Web Papers, Web, patents, books,\nsubtitles, forums, Wikipedia,\nnews\nfr 303.76 (4.17%) 193.94 (12.90%) Web Web, scholarly documents from\nall academic fields (HAL), Wik-\nisource, Wikipedia, subtitles\nes 363.83 (4.99%) 163.07 (10.84%) Web Web, subtitles, Wikipedia, news,\nmagazines\nTable 8: XGLM (Lin et al., 2021b) and BLOOM (Scao et al., 2022) quantity and data sources in pre-training corpus.\nXGLM used upsampling for some languages including Arabic and Bengali.\n0.0 0.2 0.4 0.6 0.8 1.0\nBLOOM(7.1B)\nBLOOM(3B)\nXGLM(7.5B)\nXGLM(2.9B)\nBengali Formal\nInformal\nIncohesive\nFormal Prompt\nInformal Prompt\nNeutral Prompt\nFigure 2: Plot of the distribution of the generations for\nBengali, for each prompt type, according to their labeled\ncategories: Formal, Informal, and Incohesive. Each bar\nin the plot represents 100 generations.\n0.0 0.2 0.4 0.6 0.8 1.0\nBLOOM(7.1B)\nBLOOM(3B)\nXGLM(7.5B)\nXGLM(2.9B)\nEnglish Formal\nInformal\nIncohesive\nFormal Prompt\nInformal Prompt\nNeutral Prompt\nFigure 3: Plot of the distribution of the generations for\nEnglish, for each prompt type, according to their labeled\ncategories: Formal, Informal, and Incohesive. Each bar\nin the plot represents 100 generations.\n0.0 0.2 0.4 0.6 0.8 1.0\nBLOOM(7.1B)\nBLOOM(3B)\nXGLM(7.5B)\nXGLM(2.9B)\nFrench Formal\nInformal\nIncohesive\nFormal Prompt\nInformal Prompt\nNeutral Prompt\nFigure 4: Plot of the distribution of the generations for\nFrench, for each prompt type, according to their labeled\ncategories: Formal, Informal, and Incohesive. Each bar\nin the plot represents 100 generations.\n0.0 0.2 0.4 0.6 0.8 1.0\nBLOOM(7.1B)\nBLOOM(3B)\nXGLM(7.5B)\nXGLM(2.9B)\nSpanish Formal\nInformal\nIncohesive\nFormal Prompt\nInformal Prompt\nNeutral Prompt\nFigure 5: Plot of the distribution of the generations for\nSpanish, for each prompt type, according to their labeled\ncategories: Formal, Informal, and Incohesive. Each bar\nin the plot represents 100 generations.\n2665\nArabicPrompt/Statistic Avg. Length Avg. # of sentences Avg. Length of sentences Avg. # of emojis Avg. # of punctuation marks Avg. # of new lines Avg. # of dialogue mark(-)XGLM(2.9B)−Informal175.074 1.338 130.593 0.000 6.794 0.000 0.000XGLM(2.9B)−Formal246.696 1.686 145.895 0.010 4.755 0.000 0.000BLOOM(3B)−Informal446.444 2.037 218.664 0.000 5.463 2.185 0.019BLOOM(3B)−Formal495.403 3.583 137.523 0.005 6.820 3.626 0.345XGLM(7.5B)−Informal187.345 1.471 127.023 0.000 9.391 0.000 0.000XGLM(7.5B)−Formal244.610 1.620 150.581 0.000 3.299 0.000 0.000BLOOM(7.1B)−Informal441.538 2.692 163.357 0.000 5.404 2.019 0.058BLOOM(7.1B)−Formal506.123 3.185 158.176 0.000 5.905 2.645 0.104BengaliPrompt/Statistic Avg. Length Avg. # of sent. per gen. Avg. Length of sent. Avg. # of emojis per gen. Avg. # of punctuation marks per gen. Avg. # of new lines per gen. Avg. # of dialogue mark(-)XGLM(2.9B)−Informal151.734 1.552 97.431 0.357 17.487 0.000 0.000XGLM(2.9B)−Formal164.149 1.256 130.467 0.000 3.091 0.000 0.000BLOOM(3B)−Informal413.338 2.128 193.667 0.128 11.047 1.561 0.020BLOOM(3B)−Formal384.252 1.338 286.909 0.014 5.518 1.288 0.007XGLM(7.5B)−Informal167.110 1.728 96.294 0.360 15.507 0.000 0.000XGLM(7.5B)−Formal152.767 1.248 122.199 0.008 2.880 0.000 0.000BLOOM(7.1B)−Informal419.400 1.845 226.829 0.187 13.484 2.058 0.155BLOOM(7.1B)−Formal418.500 1.198 349.046 0.000 5.063 1.127 0.008EnglishPrompt/Statistic Avg. Length Avg. # of sent. per gen. Avg. Length of sent. Avg. # of emojis per gen. Avg. # of punctuation marks per gen. Avg. # of new lines per gen. Avg. # of dialogue mark(-)XGLM(2.9B)−Informal225.720 3.332 67.047 0.005 7.518 0.000 0.000XGLM(2.9B)−Formal261.529 3.103 83.544 0.000 5.943 0.000 0.000BLOOM(3B)−Informal584.288 10.236 56.152 0.014 19.803 6.159 0.620BLOOM(3B)−Formal646.354 6.829 93.727 0.000 12.537 2.159 0.000XGLM(7.5B)−Informal241.613 3.497 68.359 0.022 8.680 0.000 0.006XGLM(7.5B)−Formal281.921 3.371 82.887 0.000 6.000 0.000 0.000BLOOM(7.1B)−Informal575.236 10.718 52.733 0.005 22.278 7.204 1.324BLOOM(7.1B)−Formal639.466 6.808 93.020 0.027 14.123 2.959 0.110FrenchPrompt/Statistic Avg. Length Avg. # of sent. per gen. Avg. Length of sent. Avg. # of emojis per gen. Avg. # of punctuation marks per gen. Avg. # of new lines per gen. Avg. # of dialogue mark(-)XGLM(2.9B)−Informal207.861 2.723 75.713 0.058 8.927 0.000 0.000XGLM(2.9B)−Formal231.435 2.652 86.646 0.000 6.861 0.000 0.000BLOOM(3B)−Informal621.216 11.869 51.417 0.006 25.562 8.273 1.051BLOOM(3B)−Formal612.727 6.125 99.197 0.000 13.909 2.205 0.034XGLM(7.5B)−Informal208.567 2.850 72.525 0.047 9.323 0.000 0.000XGLM(7.5B)−Formal235.277 2.891 80.735 0.000 7.403 0.000 0.000BLOOM(7.1B)−Informal588.804 13.375 43.091 0.006 29.667 10.583 2.607BLOOM(7.1B)−Formal637.415 6.500 97.216 0.000 15.679 2.425 0.066SpanishPrompt/Statistic Avg. Length Avg. # of sent. per gen. Avg. Length of sent. Avg. # of emojis per gen. Avg. # of punctuation marks per gen. Avg. # of new lines per gen. Avg. # of dialogue mark (-)XGLM(2.9B)−Informal222.789 2.798 78.974 0.028 9.514 0.000 0.000XGLM(2.9B)−Formal249.69 2.228 111.517 0.000 6.123 0.000 0.000BLOOM(3B)−Informal553.59 9.291 58.689 0.000 21.000 5.427 0.846BLOOM(3B)−Formal613.827 4.532 134.672 0.000 12.012 1.734 0.012XGLM(7.5B)−Informal225.454 2.981 74.957 0.019 9.870 0.000 0.000XGLM(7.5B)−Formal248.728 2.32 106.663 0.006 6.254 0.000 0.000BLOOM(7.1B)−Informal530.218 8.589 60.846 0.000 20.565 5.435 1.331BLOOM(7.1B)−Formal640.643 4.661 136.668 0.000 12.393 1.655 0.012\nTable 9: The average statistics per formal and informal generation of sequence length, number of sentences, length\nof sentences, number of emojis, number of punctuation marks, number of new lines, and number of the dialogue\nmark (“-”).\n2666",
  "topic": "Formality",
  "concepts": [
    {
      "name": "Formality",
      "score": 0.9690957069396973
    },
    {
      "name": "Computer science",
      "score": 0.7616429328918457
    },
    {
      "name": "Generative grammar",
      "score": 0.6075160503387451
    },
    {
      "name": "Natural language processing",
      "score": 0.5353835821151733
    },
    {
      "name": "Formal language",
      "score": 0.5151049494743347
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4712287187576294
    },
    {
      "name": "Linguistics",
      "score": 0.46568265557289124
    },
    {
      "name": "Concatenation (mathematics)",
      "score": 0.4610438048839569
    },
    {
      "name": "Generative model",
      "score": 0.45855870842933655
    },
    {
      "name": "Mathematics",
      "score": 0.1280648410320282
    },
    {
      "name": "Programming language",
      "score": 0.10969683527946472
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Combinatorics",
      "score": 0.0
    }
  ]
}