{
    "title": "Exploring the role of Large Language Models (LLMs) in hematology: a systematic review of applications, benefits, and limitations",
    "url": "https://openalex.org/W4395954972",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A5095921818",
            "name": "Aya Mudrik",
            "affiliations": [
                "Ben-Gurion University of the Negev"
            ]
        },
        {
            "id": "https://openalex.org/A2170298636",
            "name": "GIRISH N. NADKARNI",
            "affiliations": [
                "Icahn School of Medicine at Mount Sinai"
            ]
        },
        {
            "id": "https://openalex.org/A2049249256",
            "name": "Orly Efros",
            "affiliations": [
                "Sheba Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A1498187152",
            "name": "Benjamin S Glicksberg",
            "affiliations": [
                "Icahn School of Medicine at Mount Sinai"
            ]
        },
        {
            "id": "https://openalex.org/A1945837108",
            "name": "Eyal Klang",
            "affiliations": [
                "Icahn School of Medicine at Mount Sinai"
            ]
        },
        {
            "id": "https://openalex.org/A2513274694",
            "name": "Shelly Soffer",
            "affiliations": [
                "Rabin Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A5095921818",
            "name": "Aya Mudrik",
            "affiliations": [
                "Ben-Gurion University of the Negev"
            ]
        },
        {
            "id": "https://openalex.org/A2170298636",
            "name": "GIRISH N. NADKARNI",
            "affiliations": [
                "Icahn School of Medicine at Mount Sinai"
            ]
        },
        {
            "id": "https://openalex.org/A2049249256",
            "name": "Orly Efros",
            "affiliations": [
                "Sheba Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A1498187152",
            "name": "Benjamin S Glicksberg",
            "affiliations": [
                "Icahn School of Medicine at Mount Sinai"
            ]
        },
        {
            "id": "https://openalex.org/A1945837108",
            "name": "Eyal Klang",
            "affiliations": [
                "Icahn School of Medicine at Mount Sinai"
            ]
        },
        {
            "id": "https://openalex.org/A2513274694",
            "name": "Shelly Soffer",
            "affiliations": [
                "Rabin Medical Center"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4388085114",
        "https://openalex.org/W4387500346",
        "https://openalex.org/W4376866715",
        "https://openalex.org/W4312220150",
        "https://openalex.org/W4392782765",
        "https://openalex.org/W4386152215",
        "https://openalex.org/W4392193191",
        "https://openalex.org/W2005501262",
        "https://openalex.org/W2785704959",
        "https://openalex.org/W2077663753",
        "https://openalex.org/W6959942390",
        "https://openalex.org/W4386033569",
        "https://openalex.org/W4388487848",
        "https://openalex.org/W4386592591",
        "https://openalex.org/W4386272304",
        "https://openalex.org/W4317493089",
        "https://openalex.org/W4386306231",
        "https://openalex.org/W4391777348",
        "https://openalex.org/W4385331619",
        "https://openalex.org/W4385998042",
        "https://openalex.org/W4389505318",
        "https://openalex.org/W4391301614",
        "https://openalex.org/W4384561707",
        "https://openalex.org/W4384071683",
        "https://openalex.org/W4390571745",
        "https://openalex.org/W6854475153",
        "https://openalex.org/W2913223168",
        "https://openalex.org/W3004088204",
        "https://openalex.org/W3192540284",
        "https://openalex.org/W4383874257"
    ],
    "abstract": "ABSTRACT Rationale and Objectives Large Language Models (LLMs) have the potential to enhance medical training, education, and diagnosis. However, since these models were not originally designed for medical purposes, there are concerns regarding their reliability and safety in clinical settings. This review systematically assesses the utility, advantages, and potential risks of employing LLMs in the field of hematology. Materials and Methods We searched PubMed, Web of Science, and Scopus databases for original publications on LLMs application in hematology. We limited the search to articles published in English from December 01 2022 to March 25, 2024, coinciding with the introduction of ChatGPT. To evaluate the risk of bias, we used the adapted version of the Quality Assessment of Diagnostic Accuracy Studies criteria (QUADAS-2). Results Eleven studies fulfilled the eligibility criteria. The studies varied in their goals and methods, covering medical education, diagnosis, and clinical practice. GPT-3.5 and GPT-4’s demonstrated superior performance in diagnostic tasks and medical information propagation compared to other models like Google’s Bard (currently called Gemini). GPT-4 demonstrated particularly high accuracy in tasks such as interpreting hematology cases and diagnosing hemoglobinopathy, with performance metrics of 76% diagnostic accuracy and 88% accuracy in identifying normal blood cells. However, the study also revealed discrepancies in model consistency and the accuracy of provided references, indicating variability in their reliability. Conclusion While LLMs present significant opportunities for advancing clinical hematology, their incorporation into medical practice requires careful evaluation of their benefits and limitations.",
    "full_text": "Exploring the role of Large Language Models (LLMs) in \nhematology: a systematic review of applications, benefits, \nand limitations \n \nAya Mudrik1, Girish N Nadkarni2,4, Orly Efros3, Benjamin S Glicksberg2,4, Eyal Klang2,4*, Shelly Soffer6* \n \n1 Ben-Gurion University of the Negev, Be'er Sheva, Israel \n2 The Division of Data-Driven and Digital Medicine (D3M), Icahn School of Medicine at Mount Sinai, New \nYork, NY, United States. \n3 Sackler Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel; National Hemophilia Center and \nInstitute of Thrombosis & Hemostasis, Chaim Sheba Medical Center, Tel Hashomer, Israel. \n4 The Charles Bronfman Institute of Personalized Medicine, Icahn School of Medicine at Mount Sinai, New \nYork, NY, USA. \n6 Institute of Hematology, Davidoff Cancer Center, Rabin Medical Center, Petah-Tikva, Israel. \n \n* These authors contributed equally to this work \n \n \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\nABSTRACT \nRationale and Objectives: Large Language Models (LLMs) have the potential to enhance medical training, \neducation, and diagnosis. However, since these models were not originally designed for medical purposes, \nthere are concerns regarding their reliability and safety in clinical settings. This review systematically \nassesses the utility, advantages, and potential risks of employing LLMs in the field of hematology. \n \nMaterials and Methods: We searched PubMed, Web of Science, and Scopus databases for original \npublications on LLMs application in hematology. We limited the search to articles published in English \nfrom December 01 2022 to March 25, 2024, coinciding with the introduction of ChatGPT. To evaluate the \nrisk of bias, we used the adapted version of the Quality Assessment of Diagnostic Accuracy Studies criteria \n(QUADAS-2). \n \nResults: Eleven studies fulfilled the eligibility criteria. The studies varied in their goals and methods, \ncovering medical education, diagnosis, and clinical practice. GPT-3.5 and GPT-4's demonstrated superior \nperformance in diagnostic tasks and medical information propagation compared to other models like \nGoogle's Bard (currently called Gemini). GPT-4 demonstrated particularly high accuracy in tasks such as \ninterpreting hematology cases and diagnosing hemoglobinopathy, with performance metrics of 76% \ndiagnostic accuracy and 88% accuracy in identifying normal blood cells. However, the study also revealed \ndiscrepancies in model consistency and the accuracy of provided references, indicating variability in their \nreliability. \n \nConclusion: While LLMs present significant opportunities for advancing clinical hematology, their \nincorporation into medical practice requires careful evaluation of their benefits and limitations. \n \nKey Words: Hematology; Large Language Models; ChatGPT; Microsoft Bing; Google Bard; PaLM; \nLlaMA. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint \nINTRODUCTION \nLLMs such as OpenAI's ChatGPT, Google's Gemini, and Anthropic's Claude, are reshaping the field of text \ngeneration. Notably, ChatGPT-3.5 alone boasts more than 100 million monthly active users.1   \nLLMs are increasingly used in clinical research and practice. They serve various purposes such as simplifying \ncomplex medical terminology for patient education.2 They also support physician training and academic \nlearning through interactive tools3 and enhance diagnostic accuracy by creating predictive models from \nElectronic Health Records (EHR) data for patient outcomes.4 In hematology, a field with strict protocols and \nstandards, the potential of LLMs goes beyond simple text interactions. They could significantly reshape the \nfield.5   \nHowever, adopting LLMs, which were not initially designed for medical purposes, raises concerns regarding \ntheir reliability, including challenges in contextual understanding and interpretability, biases in the training \ndata, and ethical and regulatory issues. Doubts also persist about the dependability of their outputs for\nmaking clinical decisions.6 7 As LLMs become more common in healthcare, the necessity to test their \napplications increases. This review evaluates the application of LLMs in the field of hematology, \nsystematically assessing their benefits, limitations, and potential risks in medical training, education, and \ndiagnosis. It includes a thorough examination of studies from major databases, focusing on their use since \nthe introduction of ChatGPT. The review guides us toward cautious yet optimistic integration of LLMs into \nclinical hematology practice.  \n \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint \n \n \n \n \n \n \n \n \n \nFigure 2. Diagram of the way LLMs are developed \nTokens: Tokens are the basic units of data processed by LLMs. In the context of text, a token can be a word, part of a word or \na character.29 \nPrompt: In the context of AI, a \"prompt\" refers to the input given to a language model to initiate and guide its output \ngeneration.29 \nAutoregression: Autoregression in AI refers to the process where a model predicts the next word or sequence based on the \nprevious inputs. It operates by evaluating the probabilities of various possible continuations and selecting the most likely next \nelement in the sequence.29 \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nArtificial Intelligence (AI) \nArtificial Intelligence comprises the design and development of \nsystems or software that execute cognitive tasks usually performed \nby humans. These include reasoning, understanding language, \nrecognizing patterns, and learning from historical data.30 \nDeep Learning (DL) \nDeep Learning is a complex branch of machine learning that \nemploys multi-layer neural networks to model complex patterns in \ndata. An artificial neuron receives multiple inputs and uses an \nactivation function to generate an output. This process occurs \nacross potentially thousands of layers, enabling the network to \nlearn from vast amounts of unstructured data and perform highly \ncomplex tasks such as image recognition, speech recognition, and \nnatural language processing with remarkable accuracy.30 \nNatural Language Processing (NLP) \nNatural Language Processing is a foundational technology within \nAI that allows for the interpretation and manipulation of human \nlanguage by machines. NLP systems can carry out sophisticated \ntasks including machine translation, sentiment analysis, and \nautomatic summarization.31 \nTransformers \nTransformers represent a significant evolution in model \narchitecture for processing sequences in NLP by allowing parallel \nprocessing of input data, which drastically improves efficiency and \ntraining speeds. Transformers are integral to numerous cutting-\nedge NLP applications, serving as the underlying architecture for \nmajor models like OpenAI’s GPT series and Google's BERT. 32 \nLarge Language Models (LLMs) \nLarge Language Models are sophisticated foundational models \nthat specialize in analyzing and generating text that closely \nresembles human-written content. These models are trained on \nextensive corpora, enabling them to learn the nuanced distribution \nof language across various texts. By leveraging the transformer \narchitecture, LLMs efficiently handle long-range dependencies \nwithin the text, facilitating advanced applications such as \nautomated dialogue systems, content creation, and intricate \nanalytical tasks in fields like law and software development.33 \nExamples of LLMs are OpenAI’s GPT, Meta's Llama, Google's \nGemini (formerly called Bard) and Microsoft's Bing.  \n \n \n \nFigure 1. An Overview of Foundational Terms in the field of LLMs \nand a hierarchy diagram. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint \nMETHODS \nSearch Strategy \nA systematic review was conducted according to the Preferred Reporting Items for Systematic Reviews and \nMeta-Analyses statement (PRISMA),8 relevant guidelines from the diagnostic test accuracy extension,9 and \nthe recommendations for systematic reviews of prediction models (CHARMS checklist).10 \nA systematic search of the published literature was conducted on March 25, 2024. PubMed, Web of Science, \nand Scopus were used as databases.  \nOur search strategy targeted original studies at the intersection of LLMs and hematology, employing a set of \nsearch terms relevant to both fields. The detailed search strategy is outlined in the Supplementary \nMaterials (\"Detailed Search Terms\"). \nWe limited the search to articles published in English after December 1, 2022, to align with the introduction \nof ChatGPT, marking the first widespread release of LLMs.  \nPeer-reviewed original publications on the subject of LLMs applications in Hematology were included. We \nexcluded articles that were not related to applications of LLMs in hematology, articles that were not original, \nand conference abstracts. To ensure that we did not inadvertently exclude relevant articles, we searched the \nbibliographies of the articles included in our study.  \nThe study is registered with PROSPERO (CRD42024525241). \nStudy Selection \nTwo reviewers (AM and SS) independently screened the titles and abstracts to determine whether the studies \nmet the inclusion criteria. In unclear cases, the full-text article was reviewed. Disagreements were \nadjudicated by a third reviewer (EK). The two authors (AM and SS) independently assessed the full texts of \nthe included articles.  \nData Extraction  \nData from all included studies was collected into a standardized data extraction sheet. Data included \npublication year, LLM model types, objective, sample size, main findings, and limitations.  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint \nQuality Assessment and Risk of Bias \nTo evaluate the risk of bias, we used the adapted version of the Quality Assessment of Diagnostic Accuracy \nStudies criteria (QUADAS-2).11 \nData Synthesis  \nWe conducted a narrative synthesis of the findings from the included studies. Due to the heterogeneity in the \nstudy designs and outcomes, a meta-analysis was not implemented. Instead, we focused on summarizing the \napplications, benefits, and limitations of LLMs in Hematology as reported in the studies. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint \nRESULTS \nA total of 325 articles were retrieved in the initial search. After exclusion (Supplementary Figure 1), 11 \nstudies evaluating the application of LLMs in hematology were included.  \nThe included studies were diverse in their objectives and methodologies and covered various aspects of \nhematology including lymphoma, transfusion medicine, hemophilia, hemoglobinopathies, and stem cell \ntransplant. Categories included medical education, diagnosis, and clinical practice (Figure3).  \nAll studies were evaluated for risk of bias and applicability using the QUADAS-2 tool (Supplementary \nTable 1). Generally, the studies demonstrated a low risk of bias across the criteria of index test, reference \nstandard, and flow and timing. In some studies, the composition of the sample (patient selection criteria) \npresented an intermediate risk of bias. For example, in their article, Kumari A. et al.12 wrote 50 hematologic \nquestions that were posed to the LLMs. The authors chose which questions to ask, which might have \ninfluenced the outcomes of the study. \nThe characteristics of the studies are presented in Table 1. Objectives, reference standards, sample sizes, \nand main findings are presented in Table 2.  The strengths and limitations of LLMs as presented in the \nincluded studies are summarized in Table 3. In the following section, we detail the included studies \nseparated by theme.\nFigure 3. Applications of LLMs in Hematology in the Articles Reviewed \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint \nMedical Education \nTwo studies compared the effectiveness of ChatGPT (GPT-3.5) with Google search in answering medical \nquestions on stem cell therapy and breast implant-associated anaplastic large cell lymphoma (BIA-ALCL).13 \n14 Both studies highlighted GPT-3.5's superiority in propagating professional information.  \nIn another study by Van de Wyngaert C. et al., GPT-3.5's answers to frequently asked questions about \nhemophilia were assessed and compared to the answers found on specialized websites. GPT's responses \nwere more relevant, exhaustive, scientifically valid, and understandable, compared to the websites.15 \nWhen assessing the performance of LLMs on the Internal Medicine postgraduate knowledge of transfusion \npractice (BEST-TEST), a multiple-choice test regarding transfusion medicine, GPT-4 performed the best \nwith an average of 87% correct answers, followed by Bard (54%) and GPT-3.5 (44%).16 \nKlang et al. demonstrated GPT-3.5's utility for academic writing in thrombosis and hemostasis. The model's \nlimitations highlighted the importance of human judgment and medical expertise in the writing of academic \npapers.17  \n \nMedical Diagnosis \nKumari A. et al. compared the capability of different LLMs in solving hematology cases. GPT-3.5 \nperformed the best, achieving a score of 3.2 out of 5, followed by Google's Bard with a score of 2.2, and \nMicrosoft's Bing with 2.0.12 \nIn a study that investigated the ability of GPT models to diagnose hemoglobinopathy (Beta heterozygote, 3.7 \nhomozygote, SEA, MED, FIL, HbC or HbE heterozygote) by interpreting patients' laboratory results, GPT-4 \nachieved a diagnostic accuracy of 76%, with 97% true positives and 56% true negatives. In the same task, \nGPT-3.5 achieved an accuracy of 53%, with 75% true positives and 31% true negatives.18 \nYang et al., evaluated the potential of GPT-4 to assist with blood morphology identification. GPT-4 \nidentified normal blood cells with an accuracy of 88%, exceeding the accuracy of identifying abnormal \nblood cells at a rate of 54%. Regarding identifying abnormal cells, the accuracy of GPT-4 was slightly \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint \nhigher than that of the manual method, which was 49.5%.19 \n \nClinical practice and therapeutic recommendation  \nDuey et al. compared the recommendations of GPT-3.5 and GPT4 on thromboembolic prophylaxis in spine \nsurgery. They showed that GPT-3.5 had an accuracy rate of 33%, while ChatGPT-4.0 achieved an accuracy \nof 92%.20 \nThe performance of GPT models and Google Bard in answering common questions related to clinical \ntransfusion practice was better with explicitly phrased questions compared to those with implicit, more \n\"realistic\" phrasing. GPT-4 performed best with a score of 83% on implicit questions and 100% on explicit \nquestions. GPT-3.5 performance was the most affected by question phrasing, with a score of 17% on the \nimplicit questions and 83% on explicit questions.16 \nStephens et al. evaluated the quality of indications for irradiated blood components for TA-GVHD \nprevention, as provided by GPT models, Google Bard, and Microsoft Bing. Bing's responses were rated the \nmost accurate, with a grade of 3.75 out of 5, followed by GPT-3.5 with 3.5, GPT-4 with 3, and Bard with 3. \nGPT-4's responses were considered the most complete, receiving a completeness grade of 2.25 out of 3, \nfollowed by GPT-3.5 with 2, Bing with 1.75, and Bard with 1.5.21  \nA study by Hurley NC. et al. evaluated the recommendations of GPT models and Google Bard, regarding \nthe necessity for red blood cell transfusion, based on short case presentations. GPT-4 demonstrated the \nhighest performance, with a correct result rate of 91%. Bard performed least well, with a correct result rate \nof 45.5%.16 When assessing the capabilities of GPT-4, PaLm2, Llama2-13b, and Llama2-70b in making \ncomplex decisions in hematopoietic stem cell transplantation, only 58.8% of the LLMs' answers matched the \nexperts' positions.22 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint \n \nBenefits and limitations of LLMs in hematology \nFrom the included studies, several strengths and limitations of LLMs in hematology were identified (Table \n3, Figure 5).  \nOpinions regarding the consistency of GPT models in the field of hematology were divided. The study by \nKurstjens S. et al.18 described ChatGPT as an inconsistent model (choosing the same answer 80% of the \ntime), while referring to GPT-4 as a very consistent one (choosing the same answer 98.3% of the time). In \ncontrast, Hurley et al.16 characterize three LLMs as consistent models, with Bard, GPT-3.5, and GPT-4 \nchoosing the same answer 87%, 99%, and 97% of the time, respectively. The discrepancy highlights the \ndebate within the field regarding the reliability of these models' outputs.  \nSome studies highlighted issues with the references used by the LLMs. Three studies reported that some of \nGPT-3.5's references were fake, outdated, or contained errors.14 17 20 Another study, by Civettini et al., \nindicated that in some cases, Llama-2 and GPT-4 could not provide references.22 Duey et al. observed that \nGPT-4 did not explicitly cite any sources in its responses, thus avoiding the display of problematic \nreferences.20 Nonetheless, it is essential to observe that Bing Chat provided appropriate references in the \nstudy by Stephens et al. .21 \nFigure 4. Number of reviewed articles according \nto the type of LLM used. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint \nThree studies noted limitations in the performance of GPT models due to the large datasets used to train \nthem, which are not updated enough. One focused on GPT-3.5,17 another on GPT-4,19 a third on both.20 Van \nde Wyngaert et al. also mentioned the potential impact of this issue on ChatGPT's performance.15 \nConcerns regarding the reliability of the data were raised. GPT-3.520 and PaLm222 might derive their \nanswers from sources that are not suitable, leading to potentially incorrect responses. For example, PaLm2 \nconsistently based its responses on UpToDate (uptodate.com) information on stem cell transplantation in \nacute myeloid leukemia, not only when asked about acute myeloid leukemia but also when asked about \nacute lymphoblastic leukemia.  \nOther studies pointed out that some of LLMs' answers are not accurate enough.17 20 21 For instance, LLMs \nrecommended medications that were not indicated,16 and GPT models offered recommendations even when \nthere was insufficient evidence.20 However, additional research suggests that GPT's responses are reliable \nand based on academic sources.13 15 \nLLMs also encountered some problems when dealing with laboratory data.12 18 For example, ChatGPT \ninterpreted hemoglobin results, expressed in nmol/L, as if the concentration was in g/dL.18\nAn important strength that was observed in the reviewed articles is that LLMs offered detailed and specific \nresponses,13 14 15 19 21 written in a manner similar to common everyday language.13 Additionally, GPT \nmodels sometimes included a disclaimer advising users to seek professional medical advice for the most \naccurate information.20 21 \nFigure 5. Main Limitations and Advantages of LLMs in Hematology in the Articles Reviewed \n \n \n \nsss \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint \nDISCUSSION \nThis systematic review examines the use of Large Language Models (LLMs) such as OpenAI's ChatGPT \nand Google's Bard within the field of Hematology. It highlights the potential and the limitations of these \nmodels in enhancing medical education, advancing diagnostic accuracy, and shaping clinical practice within \nthe field.  \nEvaluation of LLMs in Medical Education, Diagnosis and Clinical Decision-making \nThe studies reviewed demonstrate that LLMs can surpass traditional electronic methods in delivering \nmedical education to both patients and physicians. For example, ChatGPT provided responses that were \nmore relevant and easier to understand than those of standard search engines and specialized medical \nwebsites.13 14 15 Patient interaction with chatbot can help patients understand their illness and treatment \noptions. It can also serve as a translator for medical terminology used by physicians. This capability suggests \nthat LLMs could play a pivotal role in democratizing access to reliable medical information, thereby \npotentially transforming medical education by making high-quality knowledge more accessible. \nIn diagnostic applications, the performance of LLMs varied, with some models achieving diagnostic \naccuracies that rival traditional methods.19 This variance underscores the importance of ongoing model \ntraining and validation to ensure that these tools provide accurate and reliable diagnostics. \nThe application of LLMs in clinical settings has shown that while they can offer accurate recommendations \nfor treatment and diagnosis, their reliability can be inconsistent.16 20 21 22 This inconsistency is particularly \nconcerning given the high stakes of medical decision-making. For instance, the studies highlighted issues \nwith the models' references14 17 20 22 and the reliability of their training data,20 22 which could lead to \nincorrect or outdated medical advice. \nMoreover, the variation in the performance of different LLMs in handling implicit versus explicit queries \nraises concerns about their practicality in real-world clinical environments, where queries may not always be \nclearly formulated.16 This limitation could affect the models' utility in emergency settings or complex cases \nwhere nuanced understanding and rapid decision-making are crucial. \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint \nThe Potential of LLMs in Hematology \nWhile LLMs are often praised for their potential to streamline operations and enhance decision-making, it is \ncrucial to acknowledge the implications of their integration into healthcare.23 24 The reliance on AI-\ngenerated knowledge could shift the focus of medical authority from trained professionals to AI systems, \naltering the power dynamics in healthcare settings. Such a shift could exacerbate existing challenges related \nto trust and accountability in medical practice.  \nAdditionally, the adoption of LLMs might lead to a homogenization of medical knowledge, as these models \nare trained primarily on existing datasets that may not fully capture the diversity of patient experiences or \nthe complexities of rare conditions.25 This could stifle innovation in medical thinking and reduce the \npersonalized nature of patient care, potentially leading to a one-size-fits-all approach that neglects individual \npatient needs and contexts. \nAnother important point is the critical understanding of how chatbots function, as the design of user prompts \ngreatly influences the responses they generate. In research settings, prompts are meticulously crafted to \nensure precision and relevance; however, this level of detail often diminishes in real-world applications. To \nsecure accurate, non-generic responses, users must clearly specify their audience and the context of their \nquestions. Considering the challenges associated with creating effective prompts, customizing LLM to meet \nthe diverse needs of hematology patients is extremely important. \nFuture Directions \nThe applications of LLMs in hematology discussed in this review are currently in their early stages, and the \nfull spectrum of their potential remains largely untapped. There is much to discover about what LLMs can \noffer to the field. There are many more subareas of hematology, such as leukemias, coagulation disorders, \nand myelodysplastic syndromes, that have not yet been studied using LLMs. Additionally, there are many \nmore tasks where LLMs could make significant contributions including, identifying adverse events, \nenriching risk prediction models, enhancing patient management, as well as improving administrative \nprocesses and compliance to guidelines.26  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint \nTo harness the benefits of LLMs while mitigating the risks, future research should focus on enhancing the \ntransparency and accountability of these models. Developing standards for the ethical use of AI in medicine, \nimproving the diversity and reliability of training datasets, and implementing robust validation processes are \ncritical steps toward responsible integration. \nFurthermore, fostering a collaborative environment where AI complements rather than replaces human \nexpertise could help maintain the essential role of medical professionals' judgment. Integrating LLMs into \nclinical practice should not diminish the value of human expertise but rather augment it, ensuring that \nmedical care remains compassionate, individualized, and informed by both human empathy and AI's \nanalytical capabilities. \nThis systematic review encounters several limitations. The small number of studies included restricts the \nability to draw broad conclusions. Variability in study tasks and methods hinders the execution of a meta-\nanalysis. Additionally, as the investigation of LLMs in this field is relatively recent, the long-term impacts \nremain uncertain. Concerns regarding the training data—specifically its lack of diversity and inherent \nbiases—could compromise the reliability of AI-generated recommendations in clinical practice. \nFurthermore, the continuous improvement in LLM technology means that the performance of an LLM noted \nin a reported study may not accurately reflect its current capabilities. For example, in December 2023, \nGoogle made some significant improvements to Bard, including renaming it to Gemini.27 Moreover,  \nIn November 2023, Elon Musk's xAI introduced a new AI model named Grok. The development team \nhighlights that Grok distinguishes itself from existing LLMs by its ability to generate responses based on \n'real-time knowledge,' a feature which provides users with the most updated information.28 \nIn conclusion,  \nWhile LLMs offer substantial opportunities for advancing hematology, it is important to recognize that the \nfield is still in its early stages, not yet addressing many diseases and potential tasks. Moreover, its \ndevelopment is limited by variability, reliability issues, and inaccuracies. As such, integrating LLMs into \nclinical practice must be navigated with careful consideration of both their potential and their pitfalls. \nBalancing innovation with caution will be key to realizing the benefits of LLMs without compromising the \nintegrity and human-centered nature of medical care.\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint \nTABLES \nTable 1. Details about the reviewed articles \n          \n          \nYear Journal/Book First Author Title Group \n2024 \nStem Cells Translational \nMedicine Chen L13 \nUsing A Google Web Search \nAnalysis to Assess the Utility of \nChatGPT in Stem Cell Therapy Medical Education \n2023 \n \n \n \nJournal of Thrombosis and \nHaemostasis \n \nKlang E17 \nEvaluation of OpenAI's large \nlanguage model as a new tool for \nwriting papers in the field of \nthrombosis and hemostasis   \n2023 Aesthetic Plastic Surgery Liu HY14 \nConsulting the Digital Doctor: \nGoogle Versus ChatGPT as Sources \nof Information on Breast Implant-\nAssociated Anaplastic Large Cell \nLymphoma and Breast Implant \nIllness   \n2023 Haemophilia Van de Wyngaert C15 \nHow good does ChatGPT answer \nfrequently asked questions about \nhaemophilia?   \n2023 \nThe Cureus Journal of Medical \nScience Kumari A12 \nLarge Language Models in \nHematology Case Solving: A \nComparative Study of ChatGPT-3.5, \nGoogle Bard, and Microsoft Bing Medical Diagnosis \n2023 \nClinical Chemistry and \nLaboratory Medicine Kurstjens S18 \nPredicting hemoglobinopathies using \nChatGPT   \n2024 \nJournal of the Chinese Medical \nAssociation Yang WH19 \nChatGPT's innovative application in \nblood morphology recognition   \n2023 British Journal of Haematology Civettini I22 \nEvaluating the performance of large \nlanguage models in haematopoietic \nstem cell transplantation decision-\nmaking Clinical Practice \n2023 The Spine Journal Duey AH20 \nThromboembolic prophylaxis in \nspine surgery: an analysis of \nChatGPT recommendations   \n2023 Transfusion Hurley NC16 \nWould doctors dream of electric \nblood bankers? Large language \nmodel-based artificial intelligence \nperforms well in many aspects of \ntransfusion medicine   \n2023 \nTransfusion Medicine Reviews \nStephens LD21 \nBattle of the (Chat)Bots: Comparing \nLarge Language Models to Practice \nGuidelines for Transfusion-\nAssociated Graft-Versus-Host \nDisease Prevention   \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint \nTable 2. A summary of the reviewed articles \n       \nMain Findings Sample Size \nReference \nStandard Objective Model Used First Author Group \nCompared to Google, \nChatGPT exhibits \nstronger capabilities in \npromoting awareness of \nstem cell therapy  20 questions Google search  \nCompared the \neffectiveness of \nChatGPT to \nGoogle in \nanswering medical \nquestions related \nto stem cell \ntherapy ChatGPT3.5 Chen L13 \nMedical \nEducation \nChatGPT3.5- 44%, \n \nChatGPT4- 87% \n \nBard 54% correct \nanswers 20 questions \nThe official exam's  \nresults \nTesting the explicit \ntransfusion \nmedicine \nknowledge of \ndifferent LLMs \nChatGPT3.5 \nChatGPT4 \nGoogle Bard Hurley NC16   \nThere are many \nlimitations in the \ncommentaries \ngenerated by ChatGPT \nwhich highlighted the \nimportance of human \njudgment and medical \nexpertise \nin the writing of \nacademic papers \nThree \ncommentaries \nA hematology \nexpert specialist in \nthrombosis and \nhemostasis \nExplore the \npotential benefits \nand restrictions of \nusing chatGPT for \nacademic writing ChatGPT3.5 Klang E17   \n(from scale of 1-5) \nChatGPT: 4.18±1.04 \n \nGoogle: 2.72±1.44 10 questions \nFive breast plastic \n surgeons \nAssess the quality \nof ChatGPT as a \npotential source of \npatient education ChatGPT3.5 Liu HY14   \n(from scale of 1-5) \nChatGPT: \nScientific validity- 4.04 \nExhaustivity- 3.94 \nRelevance- 4.01 \nUnderstandability- 4.08 \n \nWebsites: \nScientific validity- 3.55 \nExhaustivity- 2.90 \nRelevance- 3.30 \nUnderstandability- 3.62 15 questions \nTwenty \nhemophilia \nexperts \nAssess the quality \nand validity of \nChatGPT’s \nanswers to \nfrequently asked \nquestions about \nhaemophilia ChatGPT \nVan de \nWyngaert C15   \n(from scale of 1-5) \nChatGPT (3.15±1.19) \n \nBard (2.23±1.17), \n \nBing (1.98±1.01). 50 questions \nThree raters with \nexpertise in \nhematology and \nmedical education \nExploring the \ncapability of LLMs \nin solving \nhematology cases \nand conducting a \ncomparative \nanalysis of three \nLLMs \nChatGPT3.5 \nGoogle Bard \nMicrosoft Bing Kumari A12 \nMedical \nDiagnosis \nChatGPT-3.5: \nAccuracy-53%,  \nTrue Positive-75%,  \nTrue Negative-31%, \n  \nChatGPT-4.0: \nAccuracy-76%,  \nTrue Positive-97%,  \nTrue Negative-56%, 59 patients Medical diagnosis \nInvestigate the \ncapability of \nChatGPT to \ndiagnose \nhemoglobinopathy \nby interpreting the \npatient’s \nlaboratory results \nof CBC and ferritin \nvalues \nChatGPT3.5 \nChatGPT4 Kurstjens S18   \nChatGPT4: 69% \n \nManual Identification: \n71% \n38 JPEG \nimages \ndepicting 44 \nfeatures \nPublic image \ndatabase of \nAmerican Society \nof Hematology  \nInvestigate the \npotential of \nChatGPT-4 to \nassist with blood \nmorphology \nidentification ChatGPT4 Yang WH19   \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint \n \n \n \n \n \n \nLLMs- 58.8% \n \nResidents- 76.5% 150 questions \nSix bone marrow \ntransplant \nspecialists \nAssess the \ncapabilities of \nLLMs in making \ncomplex decisions \nin haematopoietic \nstem cell \ntransplantation \nChatGPT4 \nPaLm2 \nLlama2 13b \nLlama2 70b Civettini I22 Clinical Practice \nChatGPT-3.5: \nAccuracy-33% \nOver-Conclusive-50%, \nSupplemental-67% \n Incomplete-33%. \n  \nChatGPT-4.0: \nAccuracy-92%, \nOver-Conclusive-8% \nSupplemental-92% \n Incomplete-33%.  12 questions \nNorth American \nSpine Society \n(NASS) clinical \nguidelines \nEvaluate the \nrecommendations \ngiven by ChatGPT \nfor \nthromboembolic \nprophylaxis in \nspine surgery \nChatGPT3.5 \nChatGPT4 Duey AH20   \nChatGPT3.5: \nImplicit questions- 17% \nExplicit questions- 83% \n \nChatGPT4: \nImplicit questions- 83% \nExplicit questions- \n100% \n \nBard: \nImplicit questions- 33% \nExplicit questions- 33% 12 questions \nGrading rubric \ndeveloped by the \nauthors \nEvaluate the \ncapabilities of \ndifferent LLMs in \nanswering \ncommon \nquestions in \nclinical transfusion \npractice \nChatGPT3.5 \nChatGPT4 \nGoogle Bard Hurley NC16   \nChatGPT3.5- 63.6%, \n \nChatGPT4- 91% \n \nBard 45.5% 44 questions \nAABB \nrecommendations \nand a restrictive \ntransfusion \nstrategy \nEvaluate the \nrecommendations \nof different LLMs \nregarding the \nnecessity for red \nblood cell \ntransfusion, based \non short case \npresentations \nChatGPT3.5 \nChatGPT4 \nGoogle Bard Hurley NC16   \nChatGPT3.5: \nCompleteness (2/3) \nConcordance (3.5/5) \n \nChatGPT4: \nCompleteness (2.25/3) \nConcordance (3/5) \n \nGoogle Bard: \nCompleteness (1.5/3) \nConcordance (3/5) \n \nMicrosoft Bing: \nCompleteness (1.75/3) \nConcordance (3.75/5) 1 query \n4 transfusion \nmedicine \nphysicians and \nBSH guidelines \nEvaluate the \nquality of the \nindications for \nirradiation of blood \ncomponent for TA-\nGVHD prevention, \nprovided by LLMs \nand conducting a \ncomparative \nanalysis of four \nLLMs \nChatGPT3.5 \nChatGPT4 \nGoogle Bard \nMicrosoft Bing Stephens LD21   \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint \nTable3. Limitations and Advantages of LLMs in the reviewed articles \n        \nLLMs Advantages LLMs Limitations First Author Group \n• ChatGPT offered detailed and \nspecific responses. \n• GPT based its answers on \nacademic sources. \n• GPT provided answers similar to \ncommon everyday language, \nwhich are easily understood.   Chen L13 Medical Education \n  \n• Some of ChatGPT-3.5's \nreferences were fake or \ncontained errors. \n• ChatGPT-3.5 didn't base its \nanswer on the most updated \ndata. \n• Some of GPT-3.5 responses \nwere unreliable. \n• Some of GPT's answers were \ngeneral, repetitive, and didn't \nprovide specific examples. Klang E17   \n• GPT-3.5 provided high-quality \nanswers with the most important \ntopics covered \n• GPT was aware of its limitations \n• Some of ChatGPT-3.5's \nreferences were fake or \noutdated \n• GPT did not provide references Liu HY14   \n• GPT offered reliable, \nunderstandable, comprehensive \nresponses \n• GPT used relevant source of \ninformation   Van de Wyngaert C15   \n  \n• The LLMs were not accurate \nwhen handling laboratory data Kumari A12 Medical Diagnosis \n• GPT-4 responses were \nconsistent. \n• ChatGPT models \nmisinterpreted measurement \nunits \n• GPT-3.5 was inconsistent Kurstjens S18   \n• ChatGPT-4 provided additional \ninformation \n• The performance of GPT-4 was \nlimited by its training data \n•  \nGPT-4 faces challenges when \nanalyzing images with low \nresolution. Yang WH19   \n  \n• PaLm2 sometimes based its \nanswers on sources that were \nnot suitable \n• Llama and GPT-4 sometimes \ncould not provide references Civettini I22 Clinical Practice \n• GPT-4 offered a disclaimer to \nseek professional medical \nadvice for the most accurate \ninformation \n• GPT often provided \nrecommendations even when \nthere was insufficient evidence \nto make one \n• GPT 3.5 sometimes based its \nanswers on sources that were \nnot suitable \n• Some of GPT's answers were \nnot accurate enough. \n• Some of ChatGPT-3.5's \nreferences were fake \n• The performance of GPT was \nlimited by its training data Duey AH20   \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint \n \n \n \n \n \n  \n• LLMs responses were \nconsistent. \n• Bard sometimes refused to \nanswer questions \n• Bard limited the number of \nquestions permitted per 24 \nhours \n• All LLMs recommended \nmedicines that were not \nindicated Hurley NC16   \n• Bing Chat listed appropriate \nreferences \n• GPT models and Bard \nrecognized acronyms \n• GPT models offered a \ndisclaimer to seek professional \nmedical advice for the most \naccurate information \n• ChatGPT-4 listed specific \nmedications \n• The LLMs offered \nunderstandable responses \n• BingChat did not recognize \nacronyms \n• LLMs sometimes propagated \nerroneous information Stephens LD21   \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint \nREFERENCES \n1. Meyrowitsch DW, Jensen AK, Sørensen JB, Varga T V. AI chatbots and (mis)information in public health: \nimpact on vulnerable communities. Front Public Health. 2023;11:1226776. doi:10.3389/fpubh.2023.1226776 \n2. Clusmann J, Kolbinger FR, Muti HS, et al. The future landscape of large language models in medicine. \nCommunications Medicine. 2023;3(1):141. doi:10.1038/s43856-023-00370-1 \n3. Abd-Alrazaq A, AlSaad R, Alhuwail D, et al. Large Language Models in Medical Education: Opportunities, \nChallenges, and Future Directions. JMIR Med Educ. 2023;9:e48291. doi:10.2196/48291 \n4. Yang X, Chen A, PourNejatian N, et al. A large language model for electronic health records. NPJ Digit Med. \n2022;5(1):194. doi:10.1038/s41746-022-00742-2 \n5. Cascella M, Semeraro F, Montomoli J, Bellini V, Piazza O, Bignami E. The Breakthrough of Large Language \nModels Release for Medical Applications: 1-Year Timeline and Perspectives. J Med Syst. 2024;48(1):22. \ndoi:10.1007/s10916-024-02045-3 \n6. Deng J, Zubair A, Park YJ. Limitations of large language models in medical applications. Postgrad Med J. \n2023;99(1178):1298-1299. doi:10.1093/postmj/qgad069 \n7. Ullah E, Parwani A, Baig MM, Singh R. Challenges and barriers of using large language models (LLM) such as \nChatGPT for diagnostic medicine with a focus on digital pathology - a recent scoping review. Diagn Pathol. \n2024;19(1):43. doi:10.1186/s13000-024-01464-7 \n8. Moher D. Preferred Reporting Items for Systematic Reviews and Meta-Analyses: The PRISMA Statement. Ann \nIntern Med. 2009;151(4):264. doi:10.7326/0003-4819-151-4-200908180-00135 \n9. McInnes MDF, Moher D, Thombs BD, et al. Preferred Reporting Items for a Systematic Review and Meta-\nanalysis of Diagnostic Test Accuracy Studies. JAMA. 2018;319(4):388. doi:10.1001/jama.2017.19163 \n10. Moons KGM, de Groot JAH, Bouwmeester W, et al. Critical Appraisal and Data Extraction for Systematic \nReviews of Prediction Modelling Studies: The CHARMS Checklist. PLoS Med. 2014;11(10):e1001744. \ndoi:10.1371/journal.pmed.1001744 \n11. Whiting PF. QUADAS-2: A Revised Tool for the Quality Assessment of Diagnostic Accuracy Studies. Ann Intern \nMed. 2011;155(8):529. doi:10.7326/0003-4819-155-8-201110180-00009 \n12. Kumari A, Kumari A, Singh A, et al. Large Language Models in Hematology Case Solving: A Comparative Study \nof ChatGPT-3.5, Google Bard, and Microsoft Bing. Cureus. 2023;15(8):e43861. doi:10.7759/cureus.43861 \n13. Chen L, Li H, Su Y, et al. Using A Google Web Search Analysis to Assess the Utility of ChatGPT in Stem Cell \nTherapy. Stem Cells Transl Med. 2024;13(1):60-68. doi:10.1093/stcltm/szad074 \n14. Liu HY, Alessandri Bonetti M, De Lorenzi F, Gimbel ML, Nguyen VT, Egro FM. Consulting the Digital Doctor: \nGoogle Versus ChatGPT as Sources of Information on Breast Implant-Associated Anaplastic Large Cell \nLymphoma and Breast Implant Illness. Aesthetic Plast Surg. 2024;48(4):590-607. doi:10.1007/s00266-023-\n03713-4 \n15. Van de Wyngaert C, Iarossi M, Hermans C. How good does ChatGPT answer frequently asked questions about \nhaemophilia? Haemophilia. 2023;29(6):1646-1648. doi:10.1111/hae.14858 \n16. Hurley NC, Schroeder KM, Hess AS. Would doctors dream of electric blood bankers? Large language model-\nbased artificial intelligence performs well in many aspects of transfusion medicine. Transfusion (Paris). \n2023;63(10):1833-1840. doi:10.1111/trf.17526 \n17. Klang E, Levy-Mendelovich S. Evaluation of OpenAI’s large language model as a new tool for writing papers in \nthe field of thrombosis and hemostasis. J Thromb Haemost. 2023;21(4):1055-1058. \ndoi:10.1016/j.jtha.2023.01.011 \n18. Kurstjens S, Schipper A, Krabbe J, Kusters R. Predicting hemoglobinopathies using ChatGPT. Clin Chem Lab \nMed. 2024;62(3):e59-e61. doi:10.1515/cclm-2023-0885 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint \n19. Yang WH, Yang YJ, Chen TJ. ChatGPT’s innovative application in blood morphology recognition. J Chin Med \nAssoc. 2024;87(4):428-433. doi:10.1097/JCMA.0000000000001071 \n20. Duey AH, Nietsch KS, Zaidat B, et al. Thromboembolic prophylaxis in spine surgery: an analysis of ChatGPT \nrecommendations. Spine J. 2023;23(11):1684-1691. doi:10.1016/j.spinee.2023.07.015 \n21. Stephens LD, Jacobs JW, Adkins BD, Booth GS. Battle of the (Chat)Bots: Comparing Large Language Models to \nPractice Guidelines for Transfusion-Associated Graft-Versus-Host Disease Prevention. Transfus Med Rev. \n2023;37(3):150753. doi:10.1016/j.tmrv.2023.150753 \n22. Civettini I, Zappaterra A, Granelli BM, et al. Evaluating the performance of large language models in \nhaematopoietic stem cell transplantation decision-making. Br J Haematol. 2024;204(4):1523-1528. \ndoi:10.1111/bjh.19200 \n23. Omiye JA, Gui H, Rezaei SJ, Zou J, Daneshjou R. Large Language Models in Medicine: The Potentials and \nPitfalls. Ann Intern Med. 2024;177(2):210-220. doi:10.7326/M23-2772 \n24. Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF, Ting DSW. Large language models in medicine. \nNat Med. 2023;29(8):1930-1940. doi:10.1038/s41591-023-02448-8 \n25. Singhal K, Azizi S, Tu T, et al. Large language models encode clinical knowledge. Nature. 2023;620(7972):172-\n180. doi:10.1038/s41586-023-06291-2 \n26. Boonstra MJ, Weissenbacher D, Moore JH, Gonzalez-Hernandez G, Asselbergs FW. Artificial intelligence: \nrevolutionizing cardiology with large language models. Eur Heart J. 2024;45(5):332-345. \ndoi:10.1093/eurheartj/ehad838 \n27. Team G (2024) Bard becomes Gemini: try Ultra 1.0 and a new mobile app today. Google, Inc. \nhttps://blog.google/products/gemini/bard-gemini-advanced-app/. \n28. Announcing grok. Announcing grok. Accessed December 21, 2023. https://x.ai/. \n29. Naveed H, Khan AU, Qiu S, et al. A Comprehensive Overview of Large Language Models. Published online July \n12, 2023. \n30. Soffer S, Ben-Cohen A, Shimon O, Amitai MM, Greenspan H, Klang E. Convolutional Neural Networks for \nRadiologic Images: A Radiologist’s Guide. Radiology. 2019;290(3):590-606. doi:10.1148/radiol.2018180547 \n31. Sorin V, Barash Y, Konen E, Klang E. Deep Learning for Natural Language Processing in Radiology-\nFundamentals and a Systematic Review. J Am Coll Radiol. 2020;17(5):639-648. doi:10.1016/j.jacr.2019.12.026 \n32. Soffer S, Glicksberg BS, Zimlichman E, Klang E. BERT for the Processing of Radiological Reports: An Attention-\nbased Natural Language Processing Algorithm. Acad Radiol. 2022;29(4):634-635. \ndoi:10.1016/j.acra.2021.03.036 \n33. Almarie B, Teixeira PEP, Pacheco-Barrios K, Rossetti CA, Fregni F. Editorial - The Use of Large Language Models \nin Science: Opportunities and Challenges. Princ Pract Clin Res. 2023;9(1):1-4. doi:10.21801/ppcrj.2023.91.1 \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprintthis version posted April 28, 2024. ; https://doi.org/10.1101/2024.04.26.24306358doi: medRxiv preprint "
}