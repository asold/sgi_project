{
  "title": "Strength in Numbers: Estimating Confidence of Large Language Models by Prompt Agreement",
  "url": "https://openalex.org/W4385734246",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2970683929",
      "name": "Gwenyth Portillo Wightman",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2766206851",
      "name": "Alexandra DeLucia",
      "affiliations": [
        "Johns Hopkins University"
      ]
    },
    {
      "id": "https://openalex.org/A2023626662",
      "name": "Mark Dredze",
      "affiliations": [
        "Johns Hopkins University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4303648559",
    "https://openalex.org/W4281557260",
    "https://openalex.org/W3153427360",
    "https://openalex.org/W4287889468",
    "https://openalex.org/W3096331697",
    "https://openalex.org/W4288358127",
    "https://openalex.org/W4241676240",
    "https://openalex.org/W4296415471",
    "https://openalex.org/W4285178342",
    "https://openalex.org/W3105472275",
    "https://openalex.org/W3199958362",
    "https://openalex.org/W2998099211",
    "https://openalex.org/W4221161695",
    "https://openalex.org/W4224115290",
    "https://openalex.org/W2984413306",
    "https://openalex.org/W4285129823",
    "https://openalex.org/W4288482469",
    "https://openalex.org/W4320005767",
    "https://openalex.org/W3099142828",
    "https://openalex.org/W3176456866",
    "https://openalex.org/W4281748205",
    "https://openalex.org/W2431080869",
    "https://openalex.org/W4288111630",
    "https://openalex.org/W4288614645",
    "https://openalex.org/W3205068155",
    "https://openalex.org/W4299612555",
    "https://openalex.org/W2962833140",
    "https://openalex.org/W2963123047",
    "https://openalex.org/W2098824882",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W2971302374",
    "https://openalex.org/W2963675284",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4244030505",
    "https://openalex.org/W3035441651",
    "https://openalex.org/W3166986030",
    "https://openalex.org/W4304731849",
    "https://openalex.org/W2626967530",
    "https://openalex.org/W4307079201",
    "https://openalex.org/W3104939451",
    "https://openalex.org/W2963368301",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W4308244910",
    "https://openalex.org/W4225373076",
    "https://openalex.org/W2964089012",
    "https://openalex.org/W2949299379",
    "https://openalex.org/W2951682790",
    "https://openalex.org/W3172943453",
    "https://openalex.org/W2962369866",
    "https://openalex.org/W3034257552",
    "https://openalex.org/W4288243162",
    "https://openalex.org/W2933254221",
    "https://openalex.org/W3173777717",
    "https://openalex.org/W2970062726",
    "https://openalex.org/W2996848635",
    "https://openalex.org/W2971068072"
  ],
  "abstract": "Large language models have achieved impressive few-shot performance on a wide variety of tasks. However, in many settings, users require confidence estimates for model predictions. While traditional classifiers produce scores for each label, language models instead produce scores for the generation which may not be well calibrated. We compare generations across diverse prompts and show that these can be used to create confidence scores. By utilizing more prompts we can get more precise confidence estimates and use response diversity as a proxy for confidence. We evaluate this approach across ten multiple-choice question-answering datasets using three models: T0, FLAN-T5, and GPT-3. In addition to analyzing multiple human written prompts, we automatically generate more prompts using a language model in order to produce finer-grained confidence estimates. Our method produces more calibrated confidence estimates compared to the log probability of the answer to a single prompt. These improvements could benefit users who rely on prediction confidence for integration into a larger system or in decision-making processes.",
  "full_text": "Proceedings of the 3rd Workshop on Trustworthy Natural Language Processing (TrustNLP 2023), pages 326–362\nJuly 14, 2023 ©2023 Association for Computational Linguistics\nStrength in Numbers: Estimating Confidence of\nLarge Language Models by Prompt Agreement\nGwenyth Portillo Wightman and Alexandra DeLucia and Mark Dredze\nCenter for Language and Speech Processing, Johns Hopkins University\n{gwightman, aadelucia, mdredze}@jhu.edu\nAbstract\nLarge language models have achieved impres-\nsive few-shot performance on a wide variety\nof tasks. However, in many settings, users\nrequire confidence estimates for model pre-\ndictions. While traditional classifiers produce\nscores for each label, language models instead\nproduce scores for the generation which may\nnot be well calibrated. We compare generations\nacross diverse prompts and show that these can\nbe used to create confidence scores. By uti-\nlizing more prompts we can get more precise\nconfidence estimates and use response diver-\nsity as a proxy for confidence. We evaluate this\napproach across ten multiple-choice question-\nanswering datasets using three models: T0,\nFLAN-T5, and GPT-3. In addition to analyzing\nmultiple human written prompts, we automati-\ncally generate more prompts using a language\nmodel in order to produce finer-grained confi-\ndence estimates. Our method produces more\ncalibrated confidence estimates compared to\nthe log probability of the answer to a single\nprompt. These improvements could benefit\nusers who rely on prediction confidence for\nintegration into a larger system or in decision-\nmaking processes.\nhttps://github.com/JHU-CLSP/\nConfidence-Estimation-TrustNLP2023\n1 Introduction\nThe modern framing of language modeling prob-\nlems now includes the ability to perform numer-\nous tasks previously handled by specialized super-\nvised discriminative systems. For example, bi-\nnary and multi-class classification tasks can be\nframed as text generation, where a large language\nmodel (LLM) is given the input and the possi-\nble labels, and it generates the best label. More\nbroadly, many reading comprehension, reasoning,\nand question-answering (QA) tasks can be framed\nin this multiple-choice style. An advantage to fram-\ning tasks in this manner is the ability to perform\nFigure 1: A comparison of our proposed prompt agree-\nment confidence scores (2) and the commonly used log\nprobability (1). Log probability is based on a single\nprompt, while the prompt agreement confidence esti-\nmate uses multiple prompts to determine a confidence\nestimate using (2a) the log probabilities from majority\nlabel or (2b) the Rand index of label frequencies.\nfew-shot learning via in-context learning, in which\na task can be performed based on only a handful of\nexamples (Arora et al., 2022; Brown et al., 2020;\nKojima et al., 2022; Sanh et al., 2021; Zhou et al.,\n2022a). Instead of collecting a large dataset and\ninvesting time in training a new model, a user could\nutilize an existing LLM for a new task by labeling\na few examples and crafting a prompt: the input\ntemplate which instructs the model to perform the\ngiven task.\nOne challenge to utilizing LLMs in this manner\nis producing well-calibrated confidence scores for\nmodel predictions. A calibrated confidence score\naids in the interpretation of model predictions (Guo\net al., 2017) and may be crucial if models become\nintegrated into high-risk domains like healthcare\nand finance (Jiang et al., 2021). A model is consid-\nered well calibrated if its prediction probabilities\nare aligned with the actual probability of its pre-\ndictions being correct (Jiang et al., 2021). If a\nmodel says an answer has 90% confidence, then\nwe should expect it to be correct 90% of the time.\n326\nFormally, the probability that the predicted label ˆY\nis equal to the correct labelY for input X should be\nequal to the model’s predicted confidence (Nguyen\nand O’Connor, 2015). For supervised discrimina-\ntive systems, confidence scores emerge from out-\nput probabilities or normalizing model scores to\nbe between 0 and 1. For linear models, posterior\nprobability serves as a reasonable confidence score\nbecause as the amount of evidence that supports\nprediction Y increases, confidence also increases\n(Dong et al., 2018). However, prior work shows\nthat these probabilities are not well calibrated for\nnon-linear models (Johansen and Socher, 2017).\nIt is less clear how we can obtain confidence\nscores from LLMs. One approach is to use the\n(log) probability of the generation. However, these\nscores correspond to the likelihood of a text se-\nquence given some context, as opposed to the ac-\ntual probability of the label. For example, the\nmodel may assign probability mass to alternate\ngenerations that reflect the same answer (e.g. “An-\nswer A” vs. “The answer is A”). Other creative\napproaches include asking the model to generate\nstatements of confidence (e.g. “90% confidence in\nthe label”), but it is unclear how to calibrate these\nopen-ended statements (Lin et al., 2022). Model\nself-consistency can be used to identify the most\nconfident model output, but it is unclear how to\nproduce a meaningful score (Wang et al., 2022).\nInstead, we turn to another trend in LLMs: diverse\nprompts. Sanh et al. (2021) showed that by writ-\ning variations of prompts for a range of tasks, they\nproduced models better able to generalize to new\ndomains. Similarly, Chung et al. (2022) found\nthat training on a diverse set of tasks improved\nmodel performance. We consider whether measur-\ning the stability of an answer across a diverse set of\nprompts can be used to estimate model confidence.\nWe propose to measure LLM answer confidence\nby prompt agreement, whether the response of a\nmodel remains consistent across multiple prompts\nfor a given instance. We prompt an LLM with\nmultiple different prompts that instruct the model\nto perform the same task for a single input instance\nand measure the agreement of the model responses\nacross these prompts. We consider two approaches,\nrepresented in Figure 1. First, we measure the log\nprobability of the response across multiple prompts\nthat agree on the answer. Second, we measure the\ndiversity in answers across different prompts in\nthe model output, concluding that answers which\nappear in more responses have relatively higher\nconfidence. We compare these methods to the log\nprobability of the answer produced in response to\nthe official task prompt. We find that across a range\nof datasets and models, our methods consistently\nprovide more accurate estimates of confidence.\nOur contributions are as follows:\n• We show that the confidence estimate based\non multiple prompts more accurately reflects\nthe chance that a model is correct as compared\nto log probabilities from a single prompt.\n• We demonstrate these results on ten multiple-\nchoice QA datasets and three models: T0++\n(Sanh et al., 2021), FLAN-T5 XXL (Chung\net al., 2022), and GPT-3 (Brown et al., 2020).\n• We utilize automated prompt generation meth-\nods to test whether they can be used in place\nof human-authored prompts to create better\nconfidence estimates.\n2 Related Work\nWe present the relevant background concepts of in-\ncontext learning and prompt sensitivity, and then\noutline approaches to confidence estimation.\n2.1 In-Context Learning\nRecent work has shown that model performance\ncan be improved by in-context learning (ICL), in\nwhich the model is conditioned on a natural lan-\nguage instruction and several demonstrations of\nthe task (few-shots) and then completes additional\ninstances of the task by predicting what comes next\n(Radford et al., 2019; Brown et al., 2020).\nHowever, the efficacy of ICL varies depending\non the prompt. Prompts that appear semantically\nsimilar to humans can still yield different results\n(Gao et al., 2021; Schick and Schütze, 2021), and\nmany efforts have explored best practices for few-\nshot learning. Techniques have emerged to assist\nprompt engineers with creating and selecting the\nbest prompts (Sorensen et al., 2022). In addition\nto the choice of prompt, performance varies based\non the choice of training examples and the order\nof the training examples (Zhao et al., 2021). This\nsensitivity makes ICL less reliable in practice.\nChen et al. (2022) found that sensitive predic-\ntions were less likely to be accurate. This suggests\nthat a model’s predictions may be less accurate\nwhen they lack consistency (Zhou et al., 2022b),\ndefined as the model’s ability to make the same\nprediction across generations for the same input\n327\n(Wang et al., 2020). Consistency has been used\nin semi-supervised learning and ensemble learning\nto encourage predictions to be consistent across\nperturbations of the input, such as noise or para-\nphrasing (Bachman et al., 2014; Sajjadi et al., 2016;\nXie et al., 2019; Zhai et al., 2019). Consistency in-\nspires our approach to estimating confidence based\non model behavior across a set of prompts.\n2.2 Confidence Estimation\nConfidence estimation is the counterpart to uncer-\ntainty estimation, which quantifies a model’s lack\nof confidence in its predictions. Previous work\nhas shown that modeling uncertainty improves\ntask performance on neural machine translation\n(Wang et al., 2019), document quality prediction\n(Shen et al., 2019), sentiment analysis, named en-\ntity recognition, and language modeling using con-\nvolutional and recurrent neural network models (?).\nWork on model confidence estimation for NLP\nhas included a range of models–Naive Bayes and\nlogistic regression (Nguyen and O’Connor, 2015),\nneural networks (Jagannatha and yu, 2020)–and\ntasks—structured prediction (Jagannatha and yu,\n2020), natural language understanding (Desai and\nDurrett, 2020; Kamath et al., 2020; Kong et al.,\n2020), and neural machine translation systems (Ku-\nmar and Sarawagi, 2019). Kamath et al. (2020)\nfound that QA models are overconfident in out-of-\ndomain tasks when asked to answer as many ques-\ntions as possible while maintaining high accuracy.\nMore recently, this work has turned to language\nmodels, and researchers have struggled to obtain\nsensible confidence measures. Jiang et al. (2021)\nfound that language models such as T5, BART, and\nGPT-2 did not produce well-calibrated scores based\non generation probabilities for QA tasks.\nA variety of methods have been proposed to ob-\ntain calibrated confidence measures from LLMs.\nJiang et al. (2021) experiment with several calibra-\ntion methods, including fine-tuning, post hoc prob-\nability modification, or adjustment of the predicted\noutputs or inputs. Kong et al. (2020) use a regu-\nlarized fine-tuning method to obtain better calibra-\ntion for both in-distribution and out-of-distribution\ndata. Xiao et al. (2022) focus on the design choices\nfor pre-trained language model-based prediction\npipelines, suggesting that the calibration of the\nmodel depends on the choice of the fine-tuning\nloss function. Desai and Durrett (2020) demon-\nstrated a more calibrated model trained with label\nsmoothing. Unfortunately, these methods are not\nfeasible for LLMs such as GPT-3, which have al-\nready been trained and cannot be easily modified\nwithout substantial compute power or model ac-\ncess.\nAn alternative approach is to rely on post hoc cal-\nibration methods. Established techniques include\ntraining a separate, smaller model to identify in-\ncorrect predictions (Kumar and Sarawagi, 2019;\nKamath et al., 2020) or to adjust predictions (Iso-\ntonic Regression (Niculescu-Mizil and Caruana,\n2005) and forecaster (Jagannatha and yu, 2020)),\nbut these methods require a separate validation set.\nSimilarly, a validation set can also be used for tun-\ning decoding hyperparameters for better calibration,\nas in temperature scaling (Desai and Durrett, 2020;\nJiang et al., 2021). Dong et al. (2018) present met-\nrics to measure three kinds of uncertainty (model\nuncertainty, data uncertainty, and input uncertainty)\nthat may lead to miscalibration. Our work con-\ntributes to the ongoing work of calibration through\npost hoc techniques, which are still feasible for\nlarger models, particularly when we lack access to\nthe model weights or don’t have the compute to\nfine-tune the model. Instead of requiring access\nto validation sets or training external models, we\nintroduce a stand-alone method.\nOur approach utilizes a post hoc confidence es-\ntimate for a generated model prediction by mea-\nsuring agreement across multiple prompts. The\nidea of majority voting and prompts appears in\nseveral related studies. Zhou et al. (2022a) rely\non the idea that a single task can be described by\nmultiple prompts, and encourage model behavior\nto be consistent across different prompts (prompt\nconsistency). They use consistency across prompts\nto engineer new prompts as written by an LLM.\nWang et al. (2022) use self-consistency to improve\nchain-of-thought reasoning. They found a correla-\ntion between consistency and accuracy, suggesting\nthat consistency provides an estimate of how cer-\ntain the model is about its generations. Arora et al.\n(2022) use voting in their Ask Me Anything (AMA)\nprompting method to determine an input’s label\nby collecting noisy votes from a set of machine-\ngenerated prompts that vary in quality. A version of\nBARTS CORE (BARTS CORE -PROMPT ) utilizes a\nsimilar prompt-ensembling scheme (with generated\nprompts) for prompting BART to score summariza-\ntion quality (Yuan et al., 2021). These studies pro-\nvide support for our idea that majority voting can\n328\ninform confidence scores.\nFinally, Lin et al. (2022) take a unique approach\nto obtaining confidence from LLMs: they ask the\nmodel! For example, GPT-3 generates confidence\nestimates when asked to verbalize its confidence\nwith statements like “90% confidence.” While\nthese generations cannot easily be compared and\ncalibrated across tasks, it further suggests that mod-\nels have some notion of confidence.\nThe idea of model confidence is related to the\nstyle of generation and the certainty with which\na model expresses answers. Informal analyses of\nmodels, especially those focused on scientific gen-\nerations like Galactica (Taylor et al., 2022), have\nfound that models frame answers in a confident\ntone regardless of the actual factuality of the state-\nment. This observation of answer framing may be\nrelated to our task of assigning a confidence score\nto a generation.\n3 Estimating Confidence through\nMultiple Prompts\nWe propose estimating model confidence through\nmultiple prompts based on prompt agreement, i.e.,\nthe consistency among a model’s generations in\nresponse to a set of diversely worded prompts. We\nprompt the model multiple times using different\nprompts, each of which asks the model to respond\nto a given question-answer (QA) input. Intuitively,\nthe more often that different prompts favor the same\ngeneration, the greater confidence the model has\nin that generation. For example, suppose that for\na given question queried across ten prompts, the\nmodel always replies eggplant. For a second ques-\ntion queried with the same prompts, the model\nanswers potato (5 times) and eggplant, cucumber,\nsquash, carrot and kale. We would say the model\nis more confident in its answer to the first question.\nWe score confidence via prompt agreement in\ntwo ways: (1) log probabilities across multiple\nprompts and (2) answer agreement across multiple\nprompts. We compare these to a baseline of the log\nprobability of the response to a single prompt.\n3.1 Log Probabilities\nLog probability of the generation is a common\nmethod for confidence estimation (Jiang et al.,\n2021; Nguyen and O’Connor, 2015; Dong et al.,\n2018). For each instance we query the model using\nthe single, official task prompt for the dataset and\nuse the log probability of the generation.1\n3.2 Log Probabilities Across Prompts\nFor each instance, we query the model with each\navailable prompt and record the resulting answer\nand associated log probability. We compute the\nmajority label across these prompts and assign it a\nconfidence of the average log probabilities across\nthese prompts. Figure 1 shows this technique in\npractice (2a), where the model predicts A three\ntimes and B twice, making A the majority label.\nThe confidence estimate is the average of the log\nprobabilities from each time A was predicted. In\ncase of a tie, we compute the average log probabil-\nity of each tied answer and select the answer with\nthe highest average log probability.\n3.3 Answer Agreement Across Multiple\nPrompts\nA drawback to averaging the log probabilities of\nthe majority is that it does not reflect overall agree-\nment across the prompts. Consider the example\nin Figure 1, where the model predicts “A” three\ntimes and “B” twice and compare to a case where\nthe model predicts “A” three times, “B” once and\n“C” once. The model appears to be more uncertain\nin the second case, yet averaging the majority log\nprobability would yield the same score.\nWe create a confidence score that reflects an-\nswer agreement across multiple prompts. We count\nthe number of times the model predicts each an-\nswer and view this agreement list as a form of\nclustering of the prompts into answer bins. We use\nRand index (Rand, 1971), a metric that measures\nsimilarity between two clusterings, to quantify the\namount of agreement within this list. We compute\nthe Rand index between the observed “clustering”\nand the “ideal” clustering, where the model pre-\ndicts the same answer for every prompt (highest\nconfidence). This measure naturally incorporates\ncases with varying numbers of prompts.\nThe resulting Rand index is a confidence score\nfor answer agreement across multiple prompts. We\nnote that unlike our other methods, this does not\nyield a probability. We address this in our evalua-\ntion metrics below.\n1Section 4 details how we obtain these scores for each\nmodel.\n329\n4 Models\nOur confidence estimation methods are compatible\nwith multiple language models. We evaluate our\nmethods on three popular models, chosen because\nof their strong few-shot task performance, and fo-\ncus on the largest models in each model “family”\nbecause they are the highest performing.\nFor T0++ and FLAN-T5, we use the Hugging\nFace implementations locally.2\nT0++ is an 11B parameter T5-based model that\nwas trained with a multitask mixture and multiple\nprompts on 55 datasets to improve zero-shot task\ngeneralization (Sanh et al., 2021).\nFLAN-T5-XXL is an 11B parameter T5 model\n(Raffel et al., 2019) fine-tuned on 1.8k instruction\noriented tasks (Chung et al., 2022). Task fine-\ntuning (FLAN) produces state-of-the-art results on\nfew-shot performance across several benchmarks.\nGPT-3 is a 176B parameter GPT-style model\ntrained with a causal language modeling objective\n(Brown et al., 2020). We use text-davinci-002,\nan instruction-tuned version of GPT-3 (Ouyang\net al., 2022), through the OpenAI API. Due to the\nrestrictions in obtaining all token logits in a single\nAPI call, we generate a model response and match\nit to the closest answer choice for cost efficiency.\nSee Appendix A for details.\nFor each prompt and for each QA instance, we\nneed to obtain (1) the model’s selected answer from\nthe multiple-choice list and (2) the log probability\nof the selected answer. To obtain the best answer\nwe use rank scoring, which evaluates the model\nlog probability for generating each answer from\nthe multiple-choice list and selects the best option\n(Brown et al., 2020; Sanh et al., 2021). For T0++\nand FLAN-T5-XXL we use Sanh et al. (2021)’s\npublicly available evaluation code,3 modifying it\nto return log probabilities of the answers. We run\nthese models on a compute instance with 4 A100\n40GB GPUs, with a per-device batch size of 8 for\nall datasets except Dream (batch size of 1).\nFinally, we omit results for automatically gener-\nated prompts for GPT-3 due to the high financial\ncost of using the API for so many prompts. We\ninclude these results for the other methods.\n2https://huggingface.co/bigscience/T0pp and\nhttps://huggingface.co/google/flan-t5-xxl\n3https://github.com/bigscience-workshop/\nt-zero/blob/master/evaluation/run_eval.py\nFigure 2: An example of a prompt template applied to a\nQA instance.\n5 Data\nWe evaluate our method across ten multiple-choice\nquestion-answering datasets. For each dataset, we\nhave the official task prompt and a source of di-\nverse prompts for the same task. Within a dataset,\neach instance contains contextual information, a\nseries of multiple-choice answers, and annotations\nindicating the correct answer.\nWe use the following multiple-choice QA\ndatasets from the T0 training mixture (Sanh et al.,\n2021): CoS-E v1.11 (Rajani et al., 2019), Cos-\nmos QA (Huang et al., 2019), DREAM (Sun et al.,\n2019), QASC (Khot et al., 2020), Quail (Rogers\net al., 2020), Quarel (Tafjord et al., 2019a), Quartz\n(Tafjord et al., 2019b), SciQ (Welbl et al., 2017),\nSocial IQA (Sap et al., 2019), and WIQA (Tandon\net al., 2019). We exclude WikiHop (Tu et al., 2019)\ndue to the extra computational resources needed\nfor this dataset. We use only the validation splits.\n6 Prompts\nWe pair these datasets with three sources of\nprompts: the official task prompt and two sources\nfor diverse set prompts for each task. First, we use\nthe official task prompt as defined in the original\npaper for each dataset.\nSecond, we use the diverse human-authored\nprompts provided by Sanh et al. (2021). Each\nprompt is a template that contains text strings\nand placeholders to insert the question and answer\nchoices (see Figure 2). We only use the T0 prompts\nthat correspond to the original task intended by the\n330\ndataset’s authors. We refer to these as the Multi-\nple Human prompts. We apply these prompts to\nthe QA data using the PromptSource library (Bach\net al., 2022) and evaluation code for T0.3\nThird, we create a larger set of prompts through\nautomated prompt generation. While having multi-\nple prompts leads to better confidence scores, not\nevery task has multiple human-authored prompts\navailable. Furthermore, if multiple prompts are\nhelpful, perhaps a larger set would provide more\nfine-grained confidence estimates. Automatically\ngenerating prompts addresses both of these cases.\nMany methods have been proposed for automat-\nically generating LLM prompts. Most prompt gen-\neration methods assume either a single prompt for\na task (Shin et al., 2020; Zhong et al., 2021; Gao\net al., 2021) or a unique prompt for each input (Wu\net al., 2022; Zhang et al., 2022). Instead, we seek\nto generate multiple prompts for each task. We\ndraw inspiration from the iterative prompt gener-\nation process of Zhou et al. (2022b), which gen-\nerates paraphrases of a prompt by asking a LLM\nto paraphrase instructions with different prompt\ngeneration prompts (PGP). For example, by pro-\nviding an LLM the PGP “Generate a variation of\nthe following instruction while keeping the seman-\ntic meaning,” we can obtain prompt variations. We\nuse a total of 15 PGPs (listed in Table 8 in Ap-\npendix E.2), 14 of which we authored and the final\nPGP being from Zhou et al. (2022b). Figure 3\nsummarizes the prompt generation process.\nWe use this method with GPT-3\ntext-davinci-002 to generate a set of Au-\ntomatically Generated Prompts (AGPs) based\non 31 instruction statements extracted from the\nT0 prompts (listed in Table 9 in Appendix E). We\ngenerate multiple prompts for each GPT-3 query\nwith a temperature of 0.7 to allow for randomness\nand repeat each query 3 times. We obtained 465\nparaphrase queries (31 T0 instructions ×15 PGPs),\nwhich repeated 3 times gives 1395 paraphrases.\nAfter removing duplicates, the number of unique\nparaphrases per dataset varies, ranging from\n16 for WIQA to 158 for Quartz. We insert the\nparaphrased instructions into the existing dataset\ntemplates (which indicate where the question and\nanswer choice should go) to generate new prompt\ntemplates. For each dataset, we limit the total\nnumber of AGPs to 50 by random selection.\nTable 3 in Appendix C shows the number of\nprompts for each dataset: a single official prompt,\nFigure 3: We create prompts by using GPT-3 to generate\nparaphrased instructions and inserting the paraphrased\ninstructions into a dataset prompt template.\na set of Multiple Human prompts, and a larger set\nof AGPs.\n7 Evaluation\nDoes measuring confidence across multiple\nprompts yield better calibrated confidence scores?\nA common approach to measuring calibration isex-\npected calibration error (ECE)(Guo et al., 2017),\nwhich buckets the prediction probabilities and mea-\nsures the empirical accuracy of each bucket with its\naverage estimated probability (confidence).4 The\ndiscrepancy between these terms is the calibration\ngap; lower gaps indicate better calibration. ECE\nranges from 0 (perfect calibration) to 1 (lowest cal-\nibration). We utilize this method to compare log\nprobabilities obtained from a single prompt to those\nfrom multiple prompts. For each dataset, we use\n10 evenly-spaced bins and set the min and max of\nthe bins according to the minimum and maximum\naverage log probability in the dataset.\nWe measure agreement across prompts using\nRand index , which does not give normalized\nscores that can be interpreted as probabilities. We\ncould convert these scores into probability confi-\ndence scores in two ways. 1) Measure the empiri-\ncal accuracy of different ranges of Rand index on\na held-out validation set, then assign confidence\nscores based on those accuracies. The drawback\nto this approach is it requires a separate held-out\nset for calibration, which may be an unrealistic\nassumption, especially in few-shot settings. 2) Nor-\nmalize the empirical Rand index scores to form a\n4While Nixon et al. (2019) found shortcomings of ECE to\nmeasure calibration for deep learning models, it still serves as\nbest practice in this area.\n331\nprobability distribution. We experimented with this\napproach but found that how we bucketed and nor-\nmalized the scores heavily influenced ECE results,\nwhich produced an unfair evaluation setting.\nInstead, we view Rand index scores as a relative\nconfidence score between instances, where a higher\nscore means “more confident.” We propose an\nevaluation metric that considers relative confidence\nof answers between instances. We rank instances\nin a dataset according to their confidence scores\n(log probability or Rand index), with the highest\nscoring instance (e.g., largest log probability or\nRand index) at the top of the list. We evaluate each\nconfidence estimation method on how well it ranks\ncorrect predictions higher than incorrect ones.\nMost evaluation metrics for ranking are geared\ntowards an information retrieval setting where the\nnumber of items in the list can vary, different items\ncan be included by each model, only a few items\nare “relevant”, or we have close to a total ordering\nover the ranked items. Our ranked lists differ signif-\nicantly from these settings. Therefore, we choose\na simple, intuitive ranking evaluation: swapped\npairs, based on the ranking loss function from\nDíez Peláez et al. (2006); Joachims (2002). A list is\nscored based on the number of item pairs that need\nto be swapped to create a correct ordering. This\npenalizes methods that have higher confidence in\npredictions that were incorrect over correct predic-\ntions. Swapped pairs is not normalized and grows\nwith the number of items in a ranked list (from 0,\ni.e., perfect rank ordering, to n∗(n−1)\n2 , i.e., worst\nrank ordering, where n is the number of items to\nbe ranked). We report macro-averaged results by\ndividing the total swapped pairs by dataset size,\nafter filtering out any invalid predictions.5\n8 Results\nMultiple prompts provide a more calibrated\nconfidence estimate than a single prompt. Ta-\nble 1 shows the results for ECE and Swapped pairs\nacross confidence methods and models. Estimat-\ning confidence using multiple prompts consistently\nprovides a better calibrated score as compared to\nconfidence scores based on a single prompt. For\nECE, using the log probability for multiple human-\nauthored prompts always improves over a single\nprompt. Additionally, we observe that the ECE and\nswapped pairs metrics are in agreement with each\n5We experimented with other normalized methods but the\nordering of the methods were unchanged in the results.\nother; across each method and model they yield\nthe same ordering of the results, supporting our\nassertion that swapped pairs is a sufficient metric\nfor measuring relative confidence scores. This in-\ndicates that swapped pairs can be used to evaluate\ncalibration. Additionally, we observe that different\nmodels vary considerably in their scores. Specifi-\ncally, we find that T0++ and GPT-3 are much better\ncalibrated than FLAN-T5-XXL, although using our\nmethod dramatically decreases the gap. This may\nbe partly explained by the differences in model\naccuracy on these QA tasks, as discussed below.\nMeasuring confidence using prompt agreement\nwith human-authored prompts also improves over\nusing a single prompt as measured by swapped\npairs. There is not a clear winner between the log\nprobability and agreement methods, as each obtains\nthe most calibrated scores for some models. How-\never, both ways of using multiple human-authored\nresponses improve over a single prompt.\nAutomatically generated prompts show mixed\nresults. Sometimes automatically generated\nprompts improve over a single prompt (ECE on\nFLAN-T5-XXL), and sometimes they do not. We\nsuspect that this may be related to the quality of\nthe prompts. Poorly written prompts that obtain\nworse accuracy on the task give worse confidence\nscores. To test this hypothesis, for each dataset we\nselect the top 10 prompts with the highest accuracy\non the validation set. We compare the confidence\nscores from using these 10 prompts with the scores\nfrom using all AGPs. However, this filtering still\ndoes not yield consistent improvements on ECE\nor swapped pairs. There may be other factors that\nprevent automatically generated prompts from\nproducing better confidence scores. For example,\nthey may have insufficient diversity or may be\nworse in some other manner. In contrast, we know\nthat the human-authored prompts were carefully\nwritten by people who have experience prompting\nlanguage models. Despite the poor performance\nof AGPs, they still show improved performance\nover a single prompt, indicating that AGPs could\nserve as a substitute for human-authored prompts\nif human-authored prompts are not available.\nThe multiple human-written prompts method\nappears to be the most calibrated overall.\nThere is not a clear trend as to which method should\nbe used in practice. For example, Table 1 shows\nthat the best method for T0++ is Human + Mul-\n332\nECE (↓) Swapped Pairs (↓)\nConfidence Method T0++ FLAN-T5-XXL GPT-3 T0++ FLAN-T5-XXL GPT-3\nHuman Prompts\n- Single / log-prob 5.66 7.35 4.18 137.14 203.93 133.68\n- Multiple / log-prob 1.61 2.39 2.23 89.53 135.52 130.23\n- Multiple / agreement - - - 125.75 128.87 105.36\nAutomatically Generated Prompts\n- Top 10 / log-prob 6.17 4.89 - 154.05 166.81 -\n- Top 10 / agreement - - - 168.56 123.08 -\n- All / log-prob 6.20 5.23 - 153.57 169.97 -\n- All / agreement - - - 164.28 118.52 -\nTable 1: Expected Calibration Error (ECE) and Swapped Pairs results by model (T0++, FLAN-T5-XXL, GPT-3),\nprompt type (human written or automatically generated; single or multiple), and confidence estimation method (log\nprobability or agreement).\nAccuracy\nConfidence Method T0++ FLAN-T5-XXL GPT-3\nHuman Prompts\n- Single / max log-prob/agreement 0.69 0.61 0.56\n- Multiple / max log-prob 0.76 0.74 0.65\n- Multiple / agreement 0.80 0.80 0.69\nAutomatically Generated Prompts\n- Top 10 / max log-prob 0.72 0.74 -\n- Top 10 / agreement 0.72 0.75 -\n- All / max log-prob 0.71 0.72 -\n- All / agreement 0.72 0.74 -\nTable 2: Accuracy by model (T0++, FLAN-T5-XXL, GPT-3) and prompt type (human written or automatically\ngenerated; single or multiple), where the prediction is either the label with the maximum log probability or the\nmajority label. Note that because the Single prompt setting contains only one prompt, Single / max log-prob and\nSingle / agreement result in the same accuracy.\ntiple / log-prob, while AGP + All / agreement is\nbest for FLAN-T5-XXL. However, we can see that\nacross all models, using multiple prompts (typi-\ncally human-written prompts, opposed to AGPs)\nperforms the best, suggesting that it would be the\nmost promising confidence method in practice.\nHigher accuracy is linked to a larger improve-\nment in calibration. We now consider how the\naccuracy for each type of prompt is correlated with\nimprovements in calibration from using multiple\nprompts. From the accuracy results in Table 2,\nwe observe that T0++ achieves the highest accu-\nracy and is the best calibrated among the models,\nwhile FLAN-T5-XXL achieves the same level of\naccuracy with lower calibration. Using multiple\nprompts rather than a single prompt consistently re-\nsults in higher accuracies across all models, which\nmay be why T0++ is better calibrated. However, we\nfind that GPT-3 has a worse accuracy than FLAN-\nT5-XXL, yet GPT-3 is better calibrated than FLAN-\nT5-XXL according to ECE.\n9 Conclusion\nOur experiments with T0++, FLAN-T5-XXL, and\nGPT-3 suggest that prompt agreement provides\na more calibrated confidence estimate than the\ntypical approach of log probability from a single\nprompt. We find mixed results in scaling up the\nnumber of prompts using automatically generated\nprompts. Experimenting with additional prompt\ngeneration methods may enable the automatically\ngenerated prompt approach to produce even bet-\nter calibrated confidence scores. We leave this to\nfuture work.\n333\nLimitations\nThe main limitation of this work is the lack of\nhuman evaluation. Since confidence scores are\ntypically used for model explainability, a practical\nevaluation of scores from our method would be a\nhuman-in-the-loop scenario where a user is tasked\nwith understanding a system and making decisions\nbased on the output. The primary questions for this\nhuman study would be to determine if our scores\nare more useful to users than other methods, such\nas log probabilities, and would being presented\nwith confidence scores lead to different decisions.\nSecond, we focused on multiple-choice ques-\ntions, with a specific set of possible options. Since\nMC QA and classification are so similar, our analy-\nsis of many MC QA datasets is sufficient to show\nthat our method works for text classification. How-\never, there are other use cases for these models that\ndo not have pre-determined answer choices, such\nas open-ended questions or summarization.\nThird, while we supported our decision to only\nuse the largest models in each model family due to\ntheir superior performance, we acknowledge that\nreplicating our study across different model sizes\n(e.g., FLAN-T5-Small, -Base, -Large, -XL, -XXL),\nis useful for ensuring our method is robust to the\nnumber of parameters.\nFurther, we acknowledge a drawback of our\nmethod is the difficulties in comparing across other\ncalibration techniques since the Rand index scores\nare not normalized. While there are ways to normal-\nize the scores (see Section 7), we decided against\nthese methods in our evaluation because they were\neither against our zero-shot setting or heavily in-\nfluenced ECE results based on how scores were\nnormalized.\nWe leave these questions to future work.\nReferences\nSimran Arora, Avanika Narayan, Mayee F. Chen, Laurel\nOrr, Neel Guha, Kush Bhatia, Ines Chami, Frederic\nSala, and Christopher Ré. 2022. Ask Me Anything:\nA simple strategy for prompting language models.\nArXiv:2210.02441 [cs].\nStephen Bach, Victor Sanh, Zheng Xin Yong, Albert\nWebson, Colin Raffel, Nihal V . Nayak, Abheesht\nSharma, Taewoon Kim, M Saiful Bari, Thibault\nFevry, Zaid Alyafeai, Manan Dey, Andrea Santilli,\nZhiqing Sun, Srulik Ben-david, Canwen Xu, Gun-\njan Chhablani, Han Wang, Jason Fries, Maged Al-\nshaibani, Shanya Sharma, Urmish Thakker, Khalid\nAlmubarak, Xiangru Tang, Dragomir Radev, Mike\nTian-jian Jiang, and Alexander Rush. 2022. Prompt-\nSource: An integrated development environment and\nrepository for natural language prompts. In Proceed-\nings of the 60th Annual Meeting of the Association\nfor Computational Linguistics: System Demonstra-\ntions, pages 93–104, Dublin, Ireland. Association for\nComputational Linguistics.\nPhilip Bachman, Ouais Alsharif, and Doina Precup.\n2014. Learning with pseudo-ensembles.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language Models are Few-Shot Learners.\narXiv:2005.14165 [cs]. ArXiv: 2005.14165.\nYanda Chen, Chen Zhao, Zhou Yu, Kathleen McKeown,\nand He He. 2022. On the relation between sensitivity\nand accuracy in in-context learning.\nHyung Won Chung, Le Hou, Shayne Longpre, Bar-\nret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\nWang, Mostafa Dehghani, Siddhartha Brahma, et al.\n2022. Scaling instruction-finetuned language models.\narXiv preprint arXiv:2210.11416.\nShrey Desai and Greg Durrett. 2020. Calibration of\nPre-trained Transformers. arXiv:2003.07892 [cs].\nArXiv: 2003.07892.\nJorge Díez Peláez, Juan José del Coz Velasco, Anto-\nnio Bahamonde Rionda, et al. 2006. A support vec-\ntor method for ranking minimizing the number of\nswapped pairs.\nLi Dong, Chris Quirk, and Mirella Lapata. 2018. Con-\nfidence modeling for neural semantic parsing. In\nProceedings of the 56th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers), pages 743–753, Melbourne, Australia.\nAssociation for Computational Linguistics.\nTianyu Gao, Adam Fisch, and Danqi Chen. 2021.\nMaking pre-trained language models better few-shot\nlearners. In Proceedings of the 59th Annual Meet-\ning of the Association for Computational Linguistics\nand the 11th International Joint Conference on Natu-\nral Language Processing (Volume 1: Long Papers),\npages 3816–3830, Online. Association for Computa-\ntional Linguistics.\nChuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Wein-\nberger. 2017. On calibration of modern neural net-\nworks. In International Conference on Machine\nLearning, pages 1321–1330. PMLR.\n334\nLifu Huang, Ronan Le Bras, Chandra Bhagavatula, and\nYejin Choi. 2019. Cosmos qa: Machine reading com-\nprehension with contextual commonsense reasoning.\narXiv preprint arXiv:1909.00277.\nAbhyuday Jagannatha and hong yu. 2020. Calibrating\nStructured Output Predictors for Natural Language\nProcessing. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 2078–2092, Online. Association for Computa-\ntional Linguistics.\nZhengbao Jiang, Jun Araki, Haibo Ding, and Graham\nNeubig. 2021. How Can We Know When Language\nModels Know? On the Calibration of Language Mod-\nels for Question Answering. Transactions of the As-\nsociation for Computational Linguistics, 9:962–977.\nThorsten Joachims. 2002. Optimizing search engines\nusing clickthrough data. In Proceedings of the eighth\nACM SIGKDD international conference on Knowl-\nedge discovery and data mining, pages 133–142.\nAlexander Johansen and Richard Socher. 2017. Learn-\ning when to skim and when to read. In Proceedings\nof the 2nd Workshop on Representation Learning for\nNLP, pages 257–264, Vancouver, Canada. Associa-\ntion for Computational Linguistics.\nAmita Kamath, Robin Jia, and Percy Liang. 2020. Se-\nlective Question Answering under Domain Shift. In\nProceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 5684–\n5696, Online. Association for Computational Lin-\nguistics.\nTushar Khot, Peter Clark, Michal Guerquin, Peter\nJansen, and Ashish Sabharwal. 2020. Qasc: A\ndataset for question answering via sentence compo-\nsition. In Proceedings of the AAAI Conference on\nArtificial Intelligence, volume 34, pages 8082–8090.\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\ntaka Matsuo, and Yusuke Iwasawa. 2022. Large lan-\nguage models are zero-shot reasoners.\nLingkai Kong, Haoming Jiang, Yuchen Zhuang, Jie\nLyu, Tuo Zhao, and Chao Zhang. 2020. Calibrated\nLanguage Model Fine-Tuning for In- and Out-of-\nDistribution Data. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language\nProcessing (EMNLP), pages 1326–1340, Online. As-\nsociation for Computational Linguistics.\nAviral Kumar and Sunita Sarawagi. 2019. Calibration\nof encoder decoder models for neural machine trans-\nlation.\nStephanie Lin, Jacob Hilton, and Owain Evans. 2022.\nTeaching models to express their uncertainty in\nwords.\nKhanh Nguyen and Brendan O’Connor. 2015. Poste-\nrior calibration and exploratory analysis for natural\nlanguage processing models.\nAlexandru Niculescu-Mizil and Rich Caruana. 2005.\nPredicting good probabilities with supervised learn-\ning. In Proceedings of the 22nd international con-\nference on Machine learning, ICML ’05, pages 625–\n632, New York, NY , USA. Association for Comput-\ning Machinery.\nJeremy Nixon, Mike Dusenberry, Ghassen Jerfel, Tim-\nothy Nguyen, Jeremiah Liu, Linchuan Zhang, and\nDustin Tran. 2019. Measuring calibration in deep\nlearning.\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-\nroll L. Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, John\nSchulman, Jacob Hilton, Fraser Kelton, Luke Miller,\nMaddie Simens, Amanda Askell, Peter Welinder,\nPaul Christiano, Jan Leike, and Ryan Lowe. 2022.\nTraining language models to follow instructions with\nhuman feedback.\nAlec Radford, Jeff Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. 2019. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer.\nNazneen Fatema Rajani, Bryan McCann, Caiming\nXiong, and Richard Socher. 2019. Explain your-\nself! leveraging language models for commonsense\nreasoning. arXiv preprint arXiv:1906.02361.\nWilliam M Rand. 1971. Objective criteria for the evalu-\nation of clustering methods. Journal of the American\nStatistical association, 66(336):846–850.\nAnna Rogers, Olga Kovaleva, Matthew Downey, and\nAnna Rumshisky. 2020. Getting closer to ai complete\nquestion answering: A set of prerequisite real tasks.\nIn Proceedings of the AAAI conference on artificial\nintelligence, volume 34, pages 8722–8731.\nMehdi Sajjadi, Mehran Javanmardi, and Tolga Tasdizen.\n2016. Regularization with stochastic transformations\nand perturbations for deep semi-supervised learning.\nVictor Sanh, Albert Webson, Colin Raffel, Stephen H.\nBach, Lintang Sutawika, Zaid Alyafeai, Antoine\nChaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja,\nManan Dey, M. Saiful Bari, Canwen Xu, Urmish\nThakker, Shanya Sharma Sharma, Eliza Szczechla,\nTaewoon Kim, Gunjan Chhablani, Nihal Nayak, De-\nbajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang,\nHan Wang, Matteo Manica, Sheng Shen, Zheng Xin\nYong, Harshit Pandey, Rachel Bawden, Thomas\nWang, Trishala Neeraj, Jos Rozen, Abheesht Sharma,\nAndrea Santilli, Thibault Fevry, Jason Alan Fries,\nRyan Teehan, Stella Biderman, Leo Gao, Tali Bers,\nThomas Wolf, and Alexander M. Rush. 2021. Mul-\ntitask Prompted Training Enables Zero-Shot Task\nGeneralization. arXiv:2110.08207 [cs] . ArXiv:\n2110.08207.\n335\nMaarten Sap, Hannah Rashkin, Derek Chen, Ronan\nLeBras, and Yejin Choi. 2019. Socialiqa: Com-\nmonsense reasoning about social interactions. arXiv\npreprint arXiv:1904.09728.\nTimo Schick and Hinrich Schütze. 2021. Exploiting\ncloze-questions for few-shot text classification and\nnatural language inference. In Proceedings of the\n16th Conference of the European Chapter of the Asso-\nciation for Computational Linguistics: Main Volume,\npages 255–269, Online. Association for Computa-\ntional Linguistics.\nAili Shen, Daniel Beck, Bahar Salehi, Jianzhong Qi,\nand Timothy Baldwin. 2019. Modelling uncertainty\nin collaborative document quality assessment. In\nProceedings of the 5th Workshop on Noisy User-\ngenerated Text (W-NUT 2019), pages 191–201, Hong\nKong, China. Association for Computational Linguis-\ntics.\nTaylor Shin, Yasaman Razeghi, Robert L. Logan, Eric\nWallace, and Sameer Singh. 2020. Autoprompt: Elic-\niting knowledge from language models with automat-\nically generated prompts.\nTaylor Sorensen, Joshua Robinson, Christopher Rytting,\nAlexander Shaw, Kyle Rogers, Alexia Delorey, Mah-\nmoud Khalil, Nancy Fulda, and David Wingate. 2022.\nAn information-theoretic approach to prompt engi-\nneering without ground truth labels. In Proceedings\nof the 60th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers).\nAssociation for Computational Linguistics.\nKai Sun, Dian Yu, Jianshu Chen, Dong Yu, Yejin Choi,\nand Claire Cardie. 2019. Dream: A challenge data\nset and models for dialogue-based reading compre-\nhension. Transactions of the Association for Compu-\ntational Linguistics, 7:217–231.\nOyvind Tafjord, Peter Clark, Matt Gardner, Wen-tau\nYih, and Ashish Sabharwal. 2019a. Quarel: A dataset\nand models for answering questions about qualitative\nrelationships. In Proceedings of the AAAI Conference\non Artificial Intelligence , volume 33, pages 7063–\n7071.\nOyvind Tafjord, Matt Gardner, Kevin Lin, and Peter\nClark. 2019b. Quartz: An open-domain dataset of\nqualitative relationship questions. arXiv preprint\narXiv:1909.03553.\nNiket Tandon, Bhavana Dalvi Mishra, Keisuke Sak-\naguchi, Antoine Bosselut, and Peter Clark. 2019.\nWiqa: A dataset for\" what if...\" reasoning over proce-\ndural text. arXiv preprint arXiv:1909.04739.\nRoss Taylor, Marcin Kardas, Guillem Cucurull, Thomas\nScialom, Anthony Hartshorn, Elvis Saravia, Andrew\nPoulton, Viktor Kerkez, and Robert Stojnic. 2022.\nGalactica: A large language model for science. arXiv\npreprint arXiv:2211.09085.\nMing Tu, Guangtao Wang, Jing Huang, Yun Tang, Xi-\naodong He, and Bowen Zhou. 2019. Multi-hop read-\ning comprehension across multiple documents by\nreasoning over heterogeneous graphs. arXiv preprint\narXiv:1905.07374.\nLijing Wang, Dipanjan Ghosh, Maria Teresa Gonza-\nlez Diaz, Ahmed Farahat, Mahbubul Alam, Chetan\nGupta, Jiangzhuo Chen, and Madhav Marathe. 2020.\nWisdom of the ensemble: Improving consistency of\ndeep learning models.\nShuo Wang, Yang Liu, Chao Wang, Huanbo Luan, and\nMaosong Sun. 2019. Improving back-translation\nwith uncertainty-based confidence estimation. In\nProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the 9th\nInternational Joint Conference on Natural Language\nProcessing (EMNLP-IJCNLP), pages 791–802, Hong\nKong, China. Association for Computational Linguis-\ntics.\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,\nEd Chi, Sharan Narang, Aakanksha Chowdhery, and\nDenny Zhou. 2022. Self-consistency improves chain\nof thought reasoning in language models.\nJohannes Welbl, Nelson F. Liu, and Matt Gardner. 2017.\nCrowdsourcing Multiple Choice Science Questions.\nIn Proceedings of the 3rd Workshop on Noisy User-\ngenerated Text, pages 94–106, Copenhagen, Den-\nmark. Association for Computational Linguistics.\nZhuofeng Wu, Sinong Wang, Jiatao Gu, Rui Hou, Yux-\niao Dong, V . G. Vinod Vydiswaran, and Hao Ma.\n2022. Idpg: An instance-dependent prompt gener-\nation method. In North American Chapter of the\nAssociation for Computational Linguistics.\nYuxin Xiao, Paul Pu Liang, Umang Bhatt, Willie\nNeiswanger, Ruslan Salakhutdinov, and Louis-\nPhilippe Morency. 2022. Uncertainty quantification\nwith pre-trained language models: A large-scale em-\npirical analysis.\nQizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Lu-\nong, and Quoc V . Le. 2019. Unsupervised data aug-\nmentation for consistency training.\nWeizhe Yuan, Graham Neubig, and Pengfei Liu. 2021.\nBARTScore: Evaluating Generated Text as Text Gen-\neration. In Advances in Neural Information Process-\ning Systems, volume 34, pages 27263–27277. Curran\nAssociates, Inc.\nXiaohua Zhai, Avital Oliver, Alexander Kolesnikov,\nand Lucas Beyer. 2019. S4l: Self-supervised semi-\nsupervised learning.\nYue Zhang, Hongliang Fei, Dingcheng Li, and Ping Li.\n2022. PromptGen: Automatically generate prompts\nusing generative models. In Findings of the Associ-\nation for Computational Linguistics: NAACL 2022,\npages 30–37, Seattle, United States. Association for\nComputational Linguistics.\n336\nTony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and\nSameer Singh. 2021. Calibrate before use: Improv-\ning few-shot performance of language models.\nZexuan Zhong, Dan Friedman, and Danqi Chen. 2021.\nFactual probing is [MASK]: Learning vs. learning\nto recall. In Proceedings of the 2021 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, pages 5017–5033, Online. Association\nfor Computational Linguistics.\nChunting Zhou, Junxian He, Xuezhe Ma, Taylor Berg-\nKirkpatrick, and Graham Neubig. 2022a. Prompt\nconsistency for zero-shot task generalization.\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han,\nKeiran Paster, Silviu Pitis, Harris Chan, and Jimmy\nBa. 2022b. Large language models are human-level\nprompt engineers.\n337\nA Generating Predictions from GPT-3\nThe GPT-3 API does not allow direct access to all\nthe token probabilities, and the method of gathering\nlogits through multiple API calls for each answer\nchoice is cost-prohibitive. In order to perform rank\nscoring with GPT-3, we generate the best answer\nfrom the model by asking for deterministic genera-\ntions (temperature of 1) and using <|endoftext|>\nas the stop token. We take the log probability as\nthe sum of the token log probabilities up to and\nincluding the first <|endoftext|> token.\nWhile GPT-3 generally does well at following\ndirections, it often does not generate an answer\nwhich exactly matches one of the multiple-choice\noptions. We map each GPT-3 generation to one\nof the valid options by finding the answer that has\nthe greatest 1,2-gram overlap with the generation\n(after lowercasing and removing punctuation and\nwhitespace). We label a GPT-3 response as invalid\nif it has no overlap with a valid option. When eval-\nuating confidence estimates, we filter out instances\nthat resulted in at least one invalid prediction for\na prompt. See Table 10 for statistics about the\nnumber of valid GPT-3 predictions.\nB Dataset Information\nWe present information about the datasets in Ta-\nble 10: links to access to datasets on Hugging Face,\nthe size of validation split, the number of instances\nthat GPT-3 generated valid predictions for on the\nofficial prompt, and the number of instances that\nGPT-3 generated valid predictions for across all\nMultiple Human prompts.\nC Number of Prompts Per Dataset\nTable 3 shows the number of Multiple Human (MH)\nprompts and automatically generated prompts\n(AGP) per dataset. In addition to these prompts,\neach dataset has a single prompt (Official Prompt)\nwhich comes from the paper in which the dataset\nauthors introduced the dataset.\nD Confidence and Accuracy per Dataset\nD.1 Confidence\nTable 4 shows the ECE and swapped pairs re-\nsults for each dataset when using human-written\nprompts. Table 5 shows the ECE and swapped pairs\nresults for each dataset when using automatically-\ngenerated prompts.\nDataset MH AGP\nCoS-E v1.11 6 48\nCosmos QA 10 50\nDREAM 2 19\nQASC 5 50\nQuail 10 50\nQuarel 5 39\nQuartz 8 50\nSciQ 4 50\nSocial IQA 4 25\nWIQA 2 16\nTable 3: The number of Multiple Human (MH) Prompts\nand Automatically Generated Prompts (AGPs) per\ndataset.\nD.2 Accuracy\nTable 6 shows the accuracy results for each dataset\nwhen using human-written prompts. Table 7 shows\nthe accuracy results for each dataset when using\nautomatically generated prompts.\nE Automatically Generated Prompts\nE.1 Instructions Used for Prompt Generation\nIn Table 9, we list the instructions that were used\nto generate additional prompts. These instructions\ncome from the prompts used to train T0 (Sanh et al.,\n2021).\nE.2 Prompt Generation Prompts\nIn Table 8, we list the prompt generation prompts\n(PGP) that were used generate new prompts.\nWithin each PGP, we substitute an instruction from\nTable 9 in place of “{{ instruction }}” before gath-\nering a response from GPT-3.\nE.3 Paraphrased Instructions\nIn Table 11, we provide the number of paraphrased\ninstructions per dataset. We include statistics about\nthe total number of unique paraphrased instructions\nand the final number of paraphrased prompts (after\nrandomly selecting up to 50 prompts per dataset).\nIn Tables 12 to 21 we provide the paraphrased in-\nstructions for each dataset.\n338\nConfidence Method ECE ( ↓) Swapped Pairs (↓)\n(Human Prompts) T0++ FLAN-T5-XXL GPT-3 T0++ FLAN-T5-XXL GPT-3\nLog prob (single)\ncos_e 1.62 6.10 3.87 101.50 121.64 69.02\ncosmos_qa 10.83 5.17 3.59 248.92 353.44 203.20\ndream 12.05 9.73 4.87 152.08 207.76 101.71\nqasc 4.06 5.02 4.99 1.14 8.24 20.08\nquail 1.40 8.75 4.92 131.88 202.99 170.50\nquarel 4.60 7.69 5.90 28.49 32.95 14.70\nquartz 6.95 6.70 5.56 22.23 33.75 7.85\nsciq 1.09 4.36 0.94 37.39 94.10 30.56\nsocial_i_qa 2.37 12.07 3.51 219.66 209.21 42.50\nwiqa 11.59 7.94 3.69 428.07 775.16 676.66\nAverage 5.66 7.35 4.18 137.14 203.93 133.68\nLog prob (multiple)\ncos_e 1.02 1.45 1.65 51.28 104.11 43.73\ncosmos_qa 1.57 3.27 2.00 141.05 265.93 238.44\ndream 1.01 1.41 2.23 46.27 61.33 90.22\nqasc 2.06 2.85 2.64 3.06 2.85 12.99\nquail 1.02 1.11 1.54 74.99 97.23 199.40\nquarel 0.91 1.47 2.43 27.19 28.08 16.03\nquartz 1.15 1.51 2.41 8.62 9.21 5.25\nsciq 2.06 2.98 2.17 23.81 16.30 11.93\nsocial_i_qa 4.29 6.20 3.15 167.03 163.74 35.55\nwiqa 1.02 1.63 2.12 352.06 606.44 648.76\nAverage 1.61 2.39 2.23 89.53 135.52 130.23\nAgreement (multiple)\ncos_e - - - 65.32 49.25 24.56\ncosmos_qa - - - 116.60 152.34 158.99\ndream - - - 119.79 108.39 105.60\nqasc - - - 0.75 0.67 6.30\nquail - - - 94.37 84.73 91.74\nquarel - - - 31.69 22.39 14.92\nquartz - - - 11.12 6.94 3.71\nsciq - - - 5.61 5.29 6.19\nsocial_i_qa - - - 138.84 151.37 41.13\nwiqa - - - 673.39 707.31 600.43\nAverage - - - 125.75 128.87 105.36\nTable 4: Expected Calibration Error (ECE) and Swapped Pairs results for Human Prompts (single or multiple) by\nmodel (T0++, FLAN-T5-XXL, GPT-3), confidence estimation method (log probability or agreement), and dataset.\n339\nConfidence Method ECE ( ↓) Swapped Pairs (↓)\n(AGP) T0++ FLAN-T5-XXL GPT-3 T0++ FLAN-T5-XXL GPT-3\nTop 10 (log prob)\ncos_e 12.12 5.31 - 132.08 108.60 -\ncosmos_qa 11.17 8.90 - 262.76 353.77 -\ndream 1.15 1.38 - 47.25 56.94 -\nqasc 1.03 1.31 - 0.71 2.16 -\nquail 10.63 10.34 - 157.22 228.76 -\nquarel 0.95 2.37 - 27.01 30.22 -\nquartz 1.17 1.22 - 8.96 8.69 -\nsciq 0.96 1.08 - 9.34 6.15 -\nsocial_i_qa 12.08 9.01 - 217.91 216.98 -\nwiqa 10.48 7.98 - 677.22 655.82 -\nAverage 6.17 4.89 - 154.05 166.81 -\nTop 10 (agreement)\ncos_e - - - 124.88 62.92 -\ncosmos_qa - - - 254.07 226.66 -\ndream - - - 110.02 78.65 -\nqasc - - - 2.04 1.64 -\nquail - - - 225.35 144.74 -\nquarel - - - 29.81 21.06 -\nquartz - - - 15.27 9.50 -\nsciq - - - 30.51 10.33 -\nsocial_i_qa - - - 211.44 208.51 -\nwiqa - - - 682.20 466.81 -\nAverage - - - 168.56 123.08 -\nAll (log prob)\ncos_e 12.15 5.68 - 133.30 107.24 -\ncosmos_qa 11.27 9.85 - 266.24 367.09 -\ndream 1.16 1.65 - 48.56 69.55 -\nqasc 1.03 1.54 - 0.76 2.90 -\nquail 10.64 11.11 - 160.07 232.35 -\nquarel 0.94 2.22 - 27.25 30.66 -\nquartz 1.26 2.40 - 10.01 13.33 -\nsciq 0.97 1.11 - 11.45 6.16 -\nsocial_i_qa 12.10 8.92 - 216.16 214.50 -\nwiqa 10.43 7.85 - 661.90 655.91 -\nAverage 6.20 5.23 - 153.57 169.97 -\nAll (agreement)\ncos_e - - - 125.71 51.60 -\ncosmos_qa - - - 234.45 230.02 -\ndream - - - 92.89 65.07 -\nqasc - - - 0.59 0.80 -\nquail - - - 249.17 137.03 -\nquarel - - - 29.46 23.78 -\nquartz - - - 11.49 9.41 -\nsciq - - - 28.44 4.61 -\nsocial_i_qa - - - 208.03 209.52 -\nwiqa - - - 662.53 453.35 -\nAverage - - - 164.28 118.52 -\nTable 5: Expected Calibration Error (ECE) and Swapped Pairs results for Automatically Generated Prompts (AGP)\n(either 10 or all) by model (T0++, FLAN-T5-XXL, GPT-3), confidence estimation method (log probability or\nagreement), and dataset.\n340\nConfidence Method Accuracy\n(Human Prompts) T0++ FLAN-T5-XXL GPT-3\nSingle (max log-prob/agreement)\ncos_e 0.59 0.38 0.56\ncosmos_qa 0.72 0.60 0.48\ndream 0.80 0.70 0.88\nqasc 0.99 0.95 0.76\nquail 0.71 0.67 0.58\nquarel 0.59 0.60 0.70\nquartz 0.85 0.68 0.62\nsciq 0.77 0.62 0.30\nsocial_i_qa 0.34 0.33 0.35\nwiqa 0.49 0.54 0.39\nAverage 0.69 0.61 0.56\nMultiple (max log-prob)\ncos_e 0.73 0.68 0.72\ncosmos_qa 0.68 0.59 0.51\ndream 0.85 0.81 0.82\nqasc 0.98 0.96 0.80\nquail 0.77 0.77 0.62\nquarel 0.59 0.63 0.54\nquartz 0.87 0.86 0.75\nsciq 0.87 0.88 0.86\nsocial_i_qa 0.63 0.59 0.48\nwiqa 0.65 0.59 0.38\nAverage 0.76 0.74 0.65\nMultiple (agreement)\ncos_e 0.75 0.75 0.77\ncosmos_qa 0.82 0.75 0.61\ndream 0.85 0.84 0.83\nqasc 0.99 0.99 0.86\nquail 0.79 0.80 0.66\nquarel 0.60 0.63 0.56\nquartz 0.89 0.92 0.78\nsciq 0.94 0.96 0.91\nsocial_i_qa 0.71 0.70 0.52\nwiqa 0.65 0.63 0.37\nAverage 0.80 0.80 0.69\nTable 6: Accuracy by model (T0++, FLAN-T5-XXL, GPT-3) and dataset for Human Prompts (single or multiple),\nwhere the prediction is either the label with the maximum log probability or the majority label (agreement). Note\nthat because the Single prompt setting contains only one prompt, Single (max log-prob) and Single (agreement)\nresult in the same accuracy.\n341\nConfidence Method Accuracy\n(AGP) T0++ FLAN-T5-XXL GPT-3\nTop 10 (max log-prob)\ncos_e 0.62 0.72 -\ncosmos_qa 0.72 0.65 -\ndream 0.85 0.85 -\nqasc 0.99 0.98 -\nquail 0.66 0.70 -\nquarel 0.61 0.63 -\nquartz 0.88 0.88 -\nsciq 0.92 0.95 -\nsocial_i_qa 0.34 0.34 -\nwiqa 0.63 0.71 -\nAverage 0.72 0.74 -\nTop 10 (agreement)\ncos_e 0.62 0.76 -\ncosmos_qa 0.73 0.67 -\ndream 0.85 0.85 -\nqasc 0.99 0.99 -\nquail 0.66 0.71 -\nquarel 0.62 0.65 -\nquartz 0.88 0.89 -\nsciq 0.92 0.95 -\nsocial_i_qa 0.34 0.34 -\nwiqa 0.64 0.73 -\nAverage 0.72 0.75 -\nAll (max log-prob)\ncos_e 0.61 0.71 -\ncosmos_qa 0.71 0.60 -\ndream 0.85 0.83 -\nqasc 0.99 0.98 -\nquail 0.65 0.66 -\nquarel 0.60 0.61 -\nquartz 0.86 0.83 -\nsciq 0.91 0.94 -\nsocial_i_qa 0.34 0.34 -\nwiqa 0.62 0.70 -\nAverage 0.71 0.72 -\nAll (agreement)\ncos_e 0.62 0.74 -\ncosmos_qa 0.72 0.62 -\ndream 0.85 0.85 -\nqasc 0.99 0.99 -\nquail 0.66 0.67 -\nquarel 0.61 0.64 -\nquartz 0.87 0.89 -\nsciq 0.92 0.94 -\nsocial_i_qa 0.34 0.34 -\nwiqa 0.64 0.73 -\nAverage 0.72 0.74 -\nTable 7: Accuracy by model (T0++, FLAN-T5-XXL, GPT-3) and dataset for Automatically Generated Prompts\n(either top 10 or all), where the prediction is either the label with the maximum log probability or the majority label\n(agreement).\n342\nTable 8: Prompt Generation Prompts that are fed to GPT-3 in order to generate prompts. The PGP in row 1 is taken\nfrom Zhou et al. (2022b).\nID Prompt Generation Prompt\n1\nGenerate a variation of the following instruction while keeping the semantic meaning.\nInput: {{ instructions }}\nOutput:\n2\nWhat’s another way of saying \"{{ instructions }}\" while keeping the same semantic\nmeaning?\nOutput:\n3\nRephrase the following instructions while keeping the same semantic meaning.\nInput: {{ instructions }}\nOutput:\n4\nCan you tell me another way of saying the following instructions while keeping the\nsemantic meaning?\nInput: {{ instructions }}\nOutput:\n5\nParaphrase the following instructions while keeping the same semantic meaning.\nInput: {{ instructions }}\nOutput:\n6\nTell me another way of stating \"{{ instructions }}\" while keeping the same semantic\nmeaning.\nOutput:\n7\nHow can I rephrase the instructions \"{{ instructions }}\" while keeping the same\nsemantic meaning?\nOutput:\n8\nGive me a sentence that expresses the following instructions in different words.\nInput: {{ instructions }}\nOutput:\n9\nGenerate a variation of the following instruction.\nInput: {{ instructions }}\nOutput:\n10 What’s another way of saying \"{{ instructions }}\"?\nOutput:\n11\nRephrase the following instructions.\nInput:{{ instructions }}\nOutput:\n12\nCan you tell me another way of saying the following instructions?\nInput: {{ instructions }}\nOutput:\n13\nParaphrase the following instructions.\nInput: {{ instructions }}\nOutput:\n14 Tell me another way of stating \"{{ instructions }}\".\nOutput:\nContinued on next page\n343\nTable 8 – continued from previous page\nID Prompt Generation Prompt\n15 How can I rephrase the instructions \"{{ instructions }}\"?\nOutput:\n344\nTable 9: Instructions from T0 prompts (Sanh et al., 2021) that were used to generate new prompts.\nDataset Instruction\nCoS-E v1.11 Pick the option in line with common sense to answer the question.\nCoS-E v1.11 Choose the most suitable option to answer the above question.\nCoS-E v1.11 The best answer is\nCosmos QA According to the above context, choose the best option to answer the following\nquestion.\nCosmos QA According to the above context, answer the following question.\nCosmos QA Pick the best answer from the following options\nCosmos QA Read the following context and choose the best option to answer the question.\nCosmos QA Read the following context and answer the question.\nDREAM Read the following conversation and answer the question.\nQASC Given the two facts above, answer the question with the following options:\nQASC You are presented with the question and the following answer choices. Now knowing\nthe facts, choose the best answer.\nQASC\nYou are presented with the quiz. But you don’t know the answer, so you turn to\nyour teacher to ask for hints. He says the following facts. So, what’s the best\nanswer to the question?\nQuail According to the above context, choose the correct option to answer the following\nquestion.\nQuail The correct answer is\nQuail Pick the correct answer from the following options\nQuail Read the following context and choose the correct option to answer the question.\nQuarel Choose between “X” and “Y”.\nQuarel Do not use A and B to answer the question but instead, choose between “X” and “Y”.\nQuarel What is the most sensical answer between “X” and “Y”?\nQuarel Choose the answer between “X” and “Y”.\nQuarel I am testing my students’ logic.\nWhat is the answer they should choose between “X” and “Y”?\nQuartz Answer the question based on the following text.\nQuartz Answer the question below\nQuartz Given the facts below, answer the question\nQuartz Having read the above passage, choose the right answer to the following question\nQuartz Read the passage below and choose the right answer to the following question\nQuartz Use information from the paragraph to answer the question.\nSciQ Answer the following question given this paragraph\nSciQ Read this paragraph and choose the correct option from the provided answers:\nSocial IQA Which one of these answers best answers the question according to the context?\nWIQA How does the supposed perturbation influence the second effect mentioned? Answer\nby more, less or no effect.\n345\nDataset Hugging Face URL Validation Size Valid GPT-3 Predictions for OP Valid GPT-3 Predictions for MHCoS-E v1.11https://huggingface.co/datasets/cos_e/1221 947 838Cosmos QAhttps://huggingface.co/datasets/cosmos_qa/2985 2974 2624DREAM https://huggingface.co/datasets/dream2040 2040 1943QASC https://huggingface.co/datasets/qasc926 796 461Quail https://huggingface.co/datasets/quail2164 2141 1917Quarel https://huggingface.co/datasets/quarel278 277 182Quartz https://huggingface.co/datasets/quartz384 211 162SciQ https://huggingface.co/datasets/sciq1000 991 521Social IQAhttps://huggingface.co/datasets/social_i_qa1954 1751 872WIQA https://huggingface.co/datasets/wiqa6894 6894 6172\nTable 10: Dataset information: Hugging Face URL, size of validation split, number of instances that GPT-3\ngenerated valid predictions for on the official prompt (OP), and number of instances that GPT-3 generated valid\npredictions for across all Multiple Human (MH) prompts.\nDataset Unique Generated Paraphrases Final Number of Paraphrased Prompts\nCoS-E v1.11 48 48\nCosmos QA 121 50\nDREAM 19 19\nQASC 98 50\nQuail 89 50\nQuarel 75 39\nQuartz 158 50\nSciQ 61 50\nSocial IQA 25 25\nWIQA 16 16\nTable 11: The total number of unique paraphrased instructions and the final number of paraphrased prompts (up to\n50 per dataset).\n346\nTable 12: Automatically generated instructions for CoS-E v1.11.\nID Instruction\n1 Choose the option that makes the most sense to answer the question.\n2 Choose the most logical answer to the question.\n3 Choose the most practical option to answer the question.\n4 Choose the answer that makes the most sense.\n5 Choose the option that best answers the question.\n6 What is the best answer to the question above?\n7 Select the best option to answer the question.\n8 Select the option that best answers the question.\n9 What is the best answer to the question?\n10 Select the best answer for the question above.\n11 Choose the best option to answer the question.\n12 What is the best option to answer the question?\n13 Please select the option that best answers the question.\n14 Choose the best answer to the question above.\n15 The most correct answer is\n16 One possible answer is...\n17 The most accurate answer is\n18 The most accurate answer is,\nThe most precise answer is\n19 What is the best answer?\n20 The most accurate answer is the one that is closest to the correct answer\n21 Choose the option that most makes sense to answer the question.\n22 Choose the most sensible option to answer the question.\n23 What is the best option to answer the question above?\n24 Pick the best option to answer the question.\n25 Select the most appropriate response to the question above.\n26 What is the most suitable option to answer the above question?\n27 Please select the option which you believe best answers the question.\n28 Pick the best answer for the question above.\n29 What is the best response to the question?\n30 The answer that is most advantageous/ beneficial/ favorable is the best answer\n31 The most correct answer is the one that is closest to the answer key\n32 The answer that is most accurate or precise is the best answer.\n33 The most ideal answer is.\n34 Choose the option that seems most reasonable to answer the question.\n35 Choose the answer that makes the most sense given the question.\n36 The most sensible answer to the question is the one you should choose.\n37 Pick the option that you think makes the most sense to answer the question\n38 The most logical answer to the question is the best option.\n39 Please select the option which you believe is the most sensible answer to the\n40 From the given options, select the one that best answers the question.\n41 Select the option that best responds to the question.\n42 From the options below, select the one that best responds to the question\n43 There is more than one correct answer to the question. Please choose the\n44 Pick the best option to respond to the question.\n45 Choose the most appropriate option to answer the question.\nContinued on next page\n347\nTable 12 – continued from previous page\nID Instruction\n46 The most optimal answer is\n47 Choose the answer that you think is most correct.\n48 The most correct answer is the one that is most accurate and precise.\n348\nTable 13: Automatically generated instructions for Cosmos QA.\nID Instruction\n1 Read the following context and answer the question below.\n2 Read the following context and answer the question below.\nWhat does\n3 Choose the option that best answers the question based on the context above.\n4 Read the text below and answer the question that follows.\n5 Choose the most correct answer from the following options.\n6 What does the author say about the best option?\n7 What is the author’s purpose in writing this text?\n8 Which of the following is the best option to answer the question?\n9 After reading the context, answer the question.\n10 In light of the information provided, please answer the following question.\n11 What is the main idea of the text?\nThe main idea\n12 Please choose the option that best answers the question.\n13 Choose the option that best answers the question based on the information given.\n14 Read the following text and choose the best option to answer the question.\n15 Read the context and choose the best option to answer the question.\n16 To complete this task, read the text and then choose the best answer\n17 What is the most important advice from the text?\nThe most\n18 What is the best option to answer the following question, based on the\n19 Please select the option which you think is correct, based on the context\n20 Based on the information given, select the most appropriate response.\n21 Please select the option that you believe best answers the question based on the\n22 Assuming you want a similar phrase with different words:\nPlease\n23 Choose the most correct answer from the given choices.\n24 What is the answer to the question, based on the context above?\n25 Please read the following information and select the best option to answer the question\n26 According to the context above, choose the best option to answer the following\n27 In light of the information given, please answer the following question.\n28 Choose the most suitable answer from the given choices.\n29 What is the author’s opinion on the matter?\n30 Please read the following information and answer the question that follows.\n31 Choose the best answer from the following options.\n32 Choose the most accurate answer from the given choices.\n33 Based on the information given, answer the following question.\n34 Read the text below and answer the question.\n35 In light of the above information, select the most appropriate response to the\n36 Please answer the following question given the context above.\n37 Choose the most correct answer from the following choices.\n38 What are the instructions asking you to do?\nRead the following\n39 Read the text below and select the best answer to the question.\n40 What does the author say about the relationship between the two countries?\n41 What is the best answer from the following options?\nContinued on next page\n349\nTable 13 – continued from previous page\nID Instruction\n42 What’s the best answer from the following options?\n43 What is the main idea of the text?\nThe text is\n44 What is the best option?\n45 Read the following context and select the best option to answer the question.\n46 Choose the best option to answer the question based on the following context.\n47 Please select the option that best answers the question based on the context above\n48 Please read the following text and select the best answer to the question below\n49 Please answer the following question based on the information given above.\n50 Choose the best option to answer the question based on the context provided.\n350\nTable 14: Automatically generated instructions for DREAM.\nID Instruction\n1 Please read the following conversation and answer the question.\n2 What does the following conversation reveal about the speaker?\n3 Read the following conversation and answer the question below.\nWho is\n4 Read the conversation below and answer the question.\n5 What is the conversation about?\nWhat is the question about?\n6 What is the conversation about?\n7 Read the following conversation and then answer the question.\n8 Please read the conversation below and answer the question that follows.\n9 Read the conversation below and answer the question.\nWho is the\n10 Read the following conversation and answer the question.\n11 Read the following conversation and answer the question.\nWho is speaking\n12 What is the conversation about?\nWhat is the main topic of\n13 What does the conversation below reveal about the speaker?\nRead the\n14 Read the following conversation and answer the question below.\nTwo friends\n15 Please read the conversation and answer the question.\n16 Read the following conversation and answer the question.\nWho is the\n17 Read the conversation and answer the question.\n18 What is the next line in the conversation?\n19 Read the conversation below and answer the question.\nAt what time\n351\nTable 15: Automatically generated instructions for QASC.\nID Instruction\n1 You are given the quiz, but you are unsure of the answers.\n2 Based on the information provided, please select one of the following options:\n3 You are presented with a quiz, and you don’t know the answer\n4 You are given a question and the following answer choices. Choose the best\n5 Choose the best answer from the given choices, based on the information given\n6 Choose the best answer from the given choices that best aligns with the\n7 The teacher said that the answer to the question is one of the following\n8 Taking into account the two facts mentioned above, please select one of the\n9 Given the two facts above, please answer the question with one of the\n10 1. Given the two facts, answer the question with the following options\n11 You are taking a quiz and you don’t know the answer to\n12 What is the best way to answer the question given the two facts?\n13 Choose one of the following options:\n- A - B\n14 You are given the quiz, but you are unsure of the answer.\n15 Choose one of the following options based on the two facts given above.\n16 Choose one of the following options that best answers the question:\n17 Choose the answer that best fits the question, based on the information given\n18 Assuming that the average person sleeps eight hours a day, how long will\n19 The teacher provides you with the following information:\nYou are presented\n20 Choose one of the following answers:\nA) The moon orbits\n21 Based on the information given, select one of the following options:\n22 Assuming the two facts are true, which of the following is most likely\n23 Based on the two facts provided, please select from the following options to\n24 You are given the question and the following answer choices. With the information\n25 Assuming the two facts above, answer the question with the following options:\n26 You are taking a quiz and don’t know the answer to one of\n27 What is the most likely explanation for the data?\n-The\n28 Given the question and the following answer choices, select the most accurate answer\n29 What is the probability that the person is a Democrat?\nWhat\n30 The teacher provides you with the following information to help you answer the question\n31 You are given a quiz, but you are unsure of the answers.\n32 You are given a quiz, but you don’t know the answer.\n33 You are presented with a quiz, but you are unsure of the answer\n34 Read the question and the answer choices carefully, then select the most correct\n35 Assuming the aforementioned facts are accurate, please select from the following options:\n36 What is the probability that the box contains a white ball?\n37 What is the result of subtracting 4 from 9?\n-\n38 You are taking a quiz and are unsure of the answer to one of\n39 Choose the best answer from the given choices.\nContinued on next page\n352\nTable 15 – continued from previous page\nID Instruction\n40 Choose one of the following options that best answers the question based on the\n41 You are presented with the quiz. But you don’t know the answer\n42 Choose one of the following options:\na) The moon orbits\n43 Given the question and the following answer choices, select the most accurate response\n44 What’s the best answer to the question, given the following facts?\n45 Choose the best answer from the given choices that best fits the question.\n46 Choose the answer that best fits the question based on the given information.\n47 Choose the answer that best fits the question, based on the given information\n48 You are given the question and the following answer choices. Choose the best\n49 What is the conclusion based on the two facts?\n50 What is the best answer given the question and the following answer choices?\n353\nTable 16: Automatically generated instructions for Quail.\nID Instruction\n1 Choose the option that best answers the question given the context.\n2 The answer is right.\n3 Choose the option that best answers the question based on the information given.\n4 What does the author say about the relationship between the two countries?\n5 Choose the option that best answers the question below, based on the\n6 Choose the correct option to answer the following question, based on the context\n7 Please read the following text and select the appropriate answer to the question.\n8 The right answer is\n9 Choose the option that best answers the question based on the information given in\n10 Choose the correct answer from the following options.\n11 Based on the information given, select the option that best answers the question\n12 Read the following context and choose the best answer to the question.\n13 In light of the context above, please select the most appropriate option to\n14 Choose the right option from the given choices.\n15 After reading the text, select the option that best answers the question.\n16 Choose the option that answers the question based on the context above.\n17 The answer you are looking for is.\n18 After reading the following context, select the option that best answers the question\n19 Choose the correct option to answer the question based on the context.\n20 Choose the option that best answers the question based on the context.\n21 What is the best answer from the following options?\n22 Read the text above and then select the best answer to the following question\n23 Read the context below and choose the best answer to the question.\n24 Select the option that best answers the question.\n25 Read the following context and then select the best answer to the question.\n26 Read the following context and choose the correct option to answer the question.\n27 Choose the correct option to answer the following question based on the context above\n28 Based on the context above, select the appropriate option to answer the question\n29 Based on the information provided, select the most appropriate answer to the question\n30 Given the context above, please select the most appropriate answer to the\n31 In reference to the text above, please select the appropriate response to the\n32 Choose the option below that best answers the question based on the context above\n33 In reference to the context above, select the most appropriate response to the\n34 The answer that is correct is\n35 What is the best answer to the following question?\n36 Read the following context and choose the best option to answer the question.\n37 Choose the option that best answers the question.\n38 Choose the right response from the given choices.\n39 Read the provided context and select the option that best answers the question.\n40 The answer you are looking for is correct.\n41 Select the option which best answers the question based on the information provided.\n42 Choose the most accurate response from the given choices.\n43 Which of the following options best completes the sentence?\nI’m\n44 In the context above, please select the most appropriate response to the following\n45 Select the most appropriate answer from the following choices.\nContinued on next page\n354\nTable 16 – continued from previous page\nID Instruction\n46 Choose the answer that best fits the context.\n47 The answer that is correct is the one that you should select.\n48 Read the following context and select the option that best answers the question.\n49 What is the best way to respond to the following question?\n50 What does the author mean by \"a variation of the following instruction?\n355\nTable 17: Automatically generated instructions for Quarel. All Quarel prompts written for T0 (Sanh et al., 2021)\nincorporate the multiple choice options into the instruction (e.g., “Choose between X and Y”), so when generating\nprompts for Quarel, we exclude generated prompts that do not include two placeholders, X and Y .\nID Instruction\n1 You can have either \"X\" or \"Y\".\n2 What is your preference between \"X\" and \"Y\"?\n3 You can choose either \"X\" or \"Y\".\n4 You can either choose \"X\" or \"Y\".\n5 Pick either \"X\" or \"Y\".\n6 You can either have \"X\" or \"Y\".\n7 Choose either \"X\" or \"Y\".\n8 Please choose either \"X\" or \"Y\".\n9 Pick \"X\" or \"Y\".\n10 You have the option of choosing either \"X\" or \"Y\".\n11 What would you like to do, \"X\" or \"Y\"?\n14 Choose between \"X\" and \"Y\" to answer the question,\n15 Choose \"X\" or \"Y\", but not \"A\" and\n16 Choose between \"X\" and \"Y\" instead of using A and\n19 \"X\" or \"Y\"?\n20 Please choose either \"X\" or \"Y\" to answer the question\n22 Use either \"X\" or \"Y\" to answer the question,\n23 Choose either \"X\" or \"Y\" to answer the question,\n24 What is the most logical answer between \"X\" and \"Y\"?\n25 What is the most reasonable answer between \"X\" and \"Y\"?\n26 What is the most sensible answer between \"X\" and \"Y\"?\n27 Which of \"X\" and \"Y\" is the most reasonable answer\n28 Select the answer between \"X\" and \"Y\".\n29 Select the response either \"X\" or \"Y\".\n30 Choose the answer between \"X\" and \"Y\".\n31 Select the answer from the options \"X\" and \"Y\".\n32 Please pick one of the following options: \"X\" or \"Y\"\n33 Select the correct response from \"X\" or \"Y\".\n34 Choose either \"X\" or \"Y\" as your answer.\n35 Select either \"X\" or \"Y\".\n36 Choose between \"X\" and \"Y\".\n37 What is your choice between \"X\" and \"Y\"?\n38 Select either \"X\" or \"Y\" as your answer.\n39 What is the correct answer between \"X\" and \"Y\"?\n41 What is the answer they should choose between \"X\" and \"Y\"\n42 What is the correct answer between \"X\" and \"Y\" from\n43 What should the answer be between \"X\" and \"Y\" when\n44 What is the correct answer, \"X\" or \"Y\"?\n47 What is the difference between \"X\" and \"Y\"?\n356\nTable 18: Automatically generated instructions for Quartz.\nID Instruction\n1 Respond to the question using the given text as reference.\n2 Read the passage below and choose the best answer to the following question.\n3 Using the information given below, answer the question.\n4 What does the author think about people who are good at math?\n5 Based on the information given, please answer the question.\n6 What is the answer to the question, based on the information provided\n7 After reading the passage, choose the best answer to the question.\n8 Read the passage above and then select the correct answer to the question below\n9 What is the answer to the question, given the following facts?\n10 After reading the text, select the most appropriate answer to the question below\n11 What is your favorite color?\n12 What information from the paragraph can you use to answer the question?\n13 Respond to the question below.\n14 Based on the following text, answer the question.\n15 The facts are as follows:\n-The average person needs about\n16 Facts:\n1. Lisa is taller than Sarah.\n17 The question can be answered using information from the paragraph.\n18 Read the passage below and choose the right answer to the following question.\n19 Assuming the information given is true, answer the question.\n20 What does the author say about the relationship between the sun and Jupiter?\n21 Read the passage below and choose the answer to the question that best completes\n22 What is your answer to the question below?\n23 Respond to the question using the given information.\n24 What is the main idea of the following text?\n25 Given the facts that it is currently snowing outside and the temperature is\n26 What is the capital of France?\nThe capital of France is\n27 Read the text and select the correct response to the question.\n28 After reading the passage, please select the correct answer to the following question\n29 What is the author’s view on the relationship between the two countries?\n30 Read the passage below and then select the best answer to the question that\n31 After reading the passage, select the answer that best responds to the\n32 Based on the text, answer the following question.\n33 What is the probability of drawing two cards from a standard deck of cards\n34 Read the passage and then select the answer that best fits the question.\n35 What does the text say about the author’s feelings?\nThe\n36\nFacts:\nJohn is taller than Bill.\nBill is\n37 Refer to the paragraph for guidance in answering the question.\n38 Choose the right answer to the following question based on the passage you just\n39 In order to answer the question, use the information found in the paragraph\n40 Refer to the paragraph for the answer to the question.\nContinued on next page\n357\nTable 18 – continued from previous page\nID Instruction\n41 Below are the facts. Please answer the question based on them.\n42 What is the probability of being dealt a flush in poker?\n43 Please provide an answer to the question based on the text you have been\n44 Skim the passage for the answer to the following question.\n45 Choose the right answer to the following question, after reading the passage above\n46 What is the author’s purpose in writing the text?\n47 Answer the question based on the information provided.\n48 What is the value of X?\nX is the value of\n49 Choose the right answer to the following question, having read the passage above\n50 What can you infer from the text?\n358\nTable 19: Automatically generated instructions for SciQ.\nID Instruction\n1 What is the main idea of the paragraph?\nWhat is the\n2 What is the question that needs to be answered based on the given paragraph\n3 What is the question that must be answered based on the given paragraph?\n4 What does the author say about the relationship between the two countries?\n5 Read the paragraph and choose the correct option from the answers provided.\n6 Read the following paragraph and select the most appropriate answer from the given options\n7 What is the question that must be answered given the paragraph?\n8 What is the question that you need to answer based on the given paragraph\n9 Choose the correct option from the provided answers that best completes the following\n10 Read the paragraph and select the best answer from the given options.\n11 What is the main idea of this paragraph?\n12 Please read the following paragraph and select the most accurate response from the\n13 Choose the correct option from the provided answers that best completes the paragraph\n14 What is the main idea of the paragraph?\n15 What does the author say about the book?\nThe author says\n16 Read the paragraph and select the most appropriate answer from the given options\n17 What is the author’s purpose in writing this paragraph?\n18 Please answer the question below based on the given paragraph.\n19 Which of the following best completes the sentence?\n20 What is the author’s opinion of the book?\nThe author\n21 Please read the following paragraph and select the most appropriate response from the\n22 Please read the following paragraph and choose the best answer from the given options\n23 What is the main idea of the paragraph?\nAfter reading the\n24 What does the author say about the benefits of a plant-based diet\n25 Please read the following paragraph and then select the most appropriate answer from the\n26 Read the following paragraph and select the most appropriate response from the given choices\n27 Choose the option that best completes the paragraph:\nThere are four\n28 Please read the paragraph and choose the most appropriate answer from the given options\n29 What is the main idea of the paragraph?\nThe paragraph is\n30 What does the author say about the benefits of studying abroad?\n31 What does the author say about the role of government in a market economy\n32 Choose the correct answer from the options provided below the paragraph.\n33 What is the question that must be answered given the following paragraph?\n34 Choose the correct option from the provided answers that best completes the following\nparagraph\n35 Read the paragraph and select the correct option from the provided answers.\n36 Read this paragraph and choose the best option from the given answers.\n37 In what ways does the author use pathos in the essay?\n38 Read this paragraph and select the most appropriate option from the given choices.\nContinued on next page\n359\nTable 19 – continued from previous page\nID Instruction\n39 Read the paragraph and select the most accurate answer from the given choices.\n40 Read the following paragraph and choose the option that best answers the question.\n41 What is the question that you must answer based on the given paragraph?\n42 Based on the paragraph, answer the following question.\n43 Give an answer to the following question based on the given paragraph.\n44 Read the following paragraph and choose the best answer from the provided options:\n45 What is the main idea of the passage?\nThe main idea\n46 What is the main point the author is making in the paragraph?\n47 Select the correct answer from the provided options after reading the following paragraph.\n48 Read the paragraph below and choose the best answer from the provided options.\n49 Read the paragraph and choose the best answer from the provided options.\n50 What does the paragraph say about the author’s feelings towards his work?\n360\nTable 20: Automatically generated instructions for Social IQA.\nID Instruction\n1 What is the best answer to the question according to the context?\n2 What is the most accurate answer to the question given the context?\n3 Which of these answers best answers the question according to the context?\n4 What is the most accurate response to the question given the context?\n5 Which of these answers is most relevant to the question?\n6 Which of these answers is best according to the context?\n7 Which answer is the most accurate for the question given the context?\n8 Which answer is the most relevant to the question?\n9 Which answer provides the best response to the question?\n10 Which one of these answers is most relevant to the question?\n11 Which answer best fits the context of the question?\n12 What is the most accurate response to the question?\n13 Which answer is most relevant to the question?\n14 Which one of these answers is the most accurate in relation to the question\n15 Which answer best fits the question’s context?\n16 Which answer best responds to the question in the given context?\n17 Which option provides the most accurate response to the question?\n18 What is the most accurate answer to the question?\n19 Which one of these best answers the question according to the context?\n20 Which of these answers is the most relevant to the question at hand?\n21 Which of these answers best fits the question’s context?\n22 Which answer best suits the question?\n23 What is the most appropriate answer to the question?\n24 Which answer best responds to the question given the context?\n25 Which of these answers most accurately responds to the question given the surrounding context\n361\nTable 21: Automatically generated instructions for WIQA.\nID Instruction\n1 How does the supposed perturbation influence the second effect mentioned? Answer\n2 What is the extent to which the supposed perturbation influences the second\n3 What is the supposed effect of the perturbation on the second mentioned\n4 What is the supposed perturbation’s effect on the second mentioned effect\n5 What effect does the supposed perturbation have on the second mentioned effect\n6 What is the supposed perturbation?\n7 What is the extent to which the supposed perturbation affects the second\n8 How does the supposed perturbation influence the second effect mentioned? More\n9 What is the supposed perturbation’s influence on the second effect?\n10 What is the supposed impact of the perturbation on the second mentioned\n11 To what extent does the supposed perturbation affect the second mentioned outcome\n12 What is the expected effect of the perturbation on the second mentioned\n13 To what extent does the supposed perturbation influence the second effect mentioned\n14 Does the supposed perturbation have more, less, or no effect\n15 What is the supposed effect of the perturbation on the second effect\n16 What is the nature of the supposed perturbation’s influence on the\n362",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7576543092727661
    },
    {
      "name": "Confidence interval",
      "score": 0.684752345085144
    },
    {
      "name": "Proxy (statistics)",
      "score": 0.5896081328392029
    },
    {
      "name": "Language model",
      "score": 0.5785804986953735
    },
    {
      "name": "Variety (cybernetics)",
      "score": 0.4612506628036499
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4309070110321045
    },
    {
      "name": "Machine learning",
      "score": 0.41893208026885986
    },
    {
      "name": "Natural language processing",
      "score": 0.3806670010089874
    },
    {
      "name": "Statistics",
      "score": 0.36664313077926636
    },
    {
      "name": "Mathematics",
      "score": 0.13489073514938354
    }
  ]
}