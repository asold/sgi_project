{
    "title": "MentaLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models",
    "url": "https://openalex.org/W4396723505",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2668353491",
            "name": "Kai-Lai Yang",
            "affiliations": [
                "University of Manchester"
            ]
        },
        {
            "id": "https://openalex.org/A2101316507",
            "name": "Tianlin Zhang",
            "affiliations": [
                "University of Manchester"
            ]
        },
        {
            "id": "https://openalex.org/A5002529335",
            "name": "Ziyan Kuang",
            "affiliations": [
                "Jiangxi Normal University"
            ]
        },
        {
            "id": "https://openalex.org/A2126157100",
            "name": "Qianqian Xie",
            "affiliations": [
                "University of Manchester"
            ]
        },
        {
            "id": "https://openalex.org/A2098794577",
            "name": "Jimin Huang",
            "affiliations": [
                "Wuhan University"
            ]
        },
        {
            "id": "https://openalex.org/A2141504082",
            "name": "Sophia Ananiadou",
            "affiliations": [
                "University of Manchester"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4367353919",
        "https://openalex.org/W1998970095",
        "https://openalex.org/W2741004402",
        "https://openalex.org/W1556840590",
        "https://openalex.org/W2252031683",
        "https://openalex.org/W4281758439",
        "https://openalex.org/W2766194567",
        "https://openalex.org/W4313451349",
        "https://openalex.org/W4385567092",
        "https://openalex.org/W3176528293",
        "https://openalex.org/W3034999214",
        "https://openalex.org/W4285211483",
        "https://openalex.org/W4226278401",
        "https://openalex.org/W6782465632",
        "https://openalex.org/W2884244393",
        "https://openalex.org/W2987392802",
        "https://openalex.org/W3080464152",
        "https://openalex.org/W4385572634",
        "https://openalex.org/W4389523980",
        "https://openalex.org/W4229049385",
        "https://openalex.org/W3176456866",
        "https://openalex.org/W4379739792",
        "https://openalex.org/W4287674181",
        "https://openalex.org/W4287017694",
        "https://openalex.org/W4376870894"
    ],
    "abstract": "As an integral part of people's daily lives, social media is becoming a rich source for automatic mental health analysis.As traditional discriminative methods bear poor generalization ability and low interpretability, the recent large language models (LLMs) have been explored for interpretable mental health analysis on social media, which aims to provide detailed explanations along with predictions in zero-shot or few-shot settings.The results show that LLMs still achieve unsatisfactory classification performance in a zero-shot/few-shot manner, which further significantly affects the quality of the generated explanations.Domain-specific finetuning is an effective solution, but faces two critical challenges: 1) lack of high-quality training data.2) no open-source foundation LLMs.To alleviate these problems, we formally model interpretable mental health analysis as a text generation task, and build the first multi-task and multi-source interpretable mental health instruction (IMHI) dataset with 105K data samples to support LLM instruction tuning and evaluation.The raw social media data are collected from 10 existing sources covering 8 mental health analysis tasks.We prompt ChatGPT with expert-designed few-shot prompts to obtain explanations.To ensure the reliability of the explanations, we perform strict automatic and human evaluations on the correctness, consistency, and quality of generated data.Based on the IMHI dataset and LLaMA2 foundation models, we train MentaLLaMA, the first open-source instruction-following LLM series for interpretable mental health analysis on social media.We evaluate Men-taLLaMA and other advanced methods on the IMHI benchmark, the first holistic evaluation benchmark for interpretable mental health analysis.The results show that MentaLLaMA approaches state-of-the-art discriminative methods in correctness and generates human-level explanations.MentaLLaMA models also show strong generalizability to unseen tasks.The project is available at https://github.com/SteveKGYang/MentaLLaMA.",
    "full_text": null
}