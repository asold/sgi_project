{
    "title": "Blackbird language matrices (BLM), a new task for rule-like generalization in neural networks: Can Large Language Models pass the test?",
    "url": "https://openalex.org/W4389520119",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2199890295",
            "name": "Paola Merlo",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4317463334",
        "https://openalex.org/W2549835527",
        "https://openalex.org/W2011532375",
        "https://openalex.org/W4381659340",
        "https://openalex.org/W4281488135",
        "https://openalex.org/W2952828155",
        "https://openalex.org/W4389524419",
        "https://openalex.org/W4289688858",
        "https://openalex.org/W2963751529",
        "https://openalex.org/W2952208026",
        "https://openalex.org/W4386566673",
        "https://openalex.org/W4303648884",
        "https://openalex.org/W2067737176",
        "https://openalex.org/W2163922914",
        "https://openalex.org/W3159684727"
    ],
    "abstract": "How do we evaluate Large Language Models (LLMs) and determine the aspects and limits of their intelligent behaviour? It is currently conjectured that shortcomings of LLMs in multi-linguality and reasoning are due to a lack of ability to generalize. It has been argued that, instead, humans are better at generalization because they have a tendency at extracting rules from complex data. We propose a method to evaluate LLMs ability to rule-based generalization. When exposed to tests of analytic intelligence, for example the visual RAVEN IQ test, human problem-solvers identify the relevant objects in the picture and their relevant attributes and reason based on rules applied to them. Based on the induced rules, they are able to provide a generalisation and a solution to the test. An analogous language task has recently been proposed (called BLM) for LLM. In this paper, we argue that we can use this task to investigate what linguistic reasoning LLM develop, by asking them to solve some simple variants of the BLM task. We find that current state-of-the-art generative models, such as ChatGPT, can handle the task in the sense that they easily understand the instructions and can provide step-by-step reasoning that shows that it can solve two of the main cognitive hurdles: correspondence finding (object and attribute identification) and item novelty. However, overall they cannot find the correct answer, even with considerable help. In particular, they never identify the structure of the problem, exhibiting, we hypothesize, a lack of goal and subgoal management abilities, an ability that has been argued to measure differential abilities in humans. We argue that this finding supports the usefulness of the task as a method to test the limits and specific properties of generalisation ability in Large Language Models, providing an intrinsic evaluation method inspired by tests of human intelligence.",
    "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 8119–8152\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nBlackbird language matrices (BLM),\na new task for rule-like generalization in neural networks:\nCan Large Language Models pass the test?\nPaola Merlo\nUniversity of Geneva\nPaola.Merlo@unige.ch\nAbstract\nHow do we evaluate LLMs and determine\nthe aspects and limits of their intelligent be-\nhaviour?\nWhen exposed to visual tests of analytic intel-\nligence, human problem-solvers identify rules\napplied to relevant objects and attributes. Based\non the induced rules, they can generalise and\nare able to provide a solution to the test.\nAn analogous language task has recently been\nproposed (called BLM) for LLM. In this paper,\nwe use this task to investigate what linguistic\nreasoning LLM develop, by asking them to\nsolve some simple variants of the BLM task.\nWe find that current state-of-the-art generative\nmodels can handle the task: they easily under-\nstand the instructions and can provide step-by-\nstep explanations. The explanations show that\nLLMs can solve two of the main hurdles: corre-\nspondence finding (object and attribute identifi-\ncation) and item novelty. However, overall they\nstruggle to find the correct underlying global\nrules, even when they find the right answer.\nWe argue that these findings support the useful-\nness of the task as a method to test the limits\nand specific properties of generalisation abil-\nity in Large Language Models, providing an\nintrinsic evaluation method inspired by tests of\nhuman intelligence.\n1 Prologue\nHow do we evaluate LLMs, determine the aspects\nand limits of their intelligent behaviour and com-\npare them to human intelligence?\nA new trend of large-scale multi-task LLM and\nneural network evaluation has emerged that aims\nto evaluate LLM in realistic settings. In NLP we\nsee Big-bench initiatives, to better chart LLMs ca-\npabilities (Srivastava et al., 2023). In neuroscience,\na similar trend, dubbed integrative bench-marking,\nlooks at large language models as mechanistic hy-\npotheses on how the brain encodes intelligence,\nmodels that can be tested on behavioural and neu-\nral data (Schrimpf et al., 2020). Finally, another\npoint of view has been put forth recently that, to\nfurther understand the components of human intel-\nligence, one needs to study how this intelligence\nevolved, decomposing it into large-scale studies\nof primitive skills that humans share with other\nanimals (Zador et al., 2023).\nLarge scale, highly integrative, comparative ap-\nproaches are necessary: they give a bird’s eye view\nessential to map unknown territories, define bound-\naries, guide long-term trends. But we also think\nthat curated data and in-depth qualitative analyses\nof the intelligent behaviour of these models are\nneeded (Rogers, 2021).\nWe will concentrate on one such skill, one of the\ncore intelligent human abilities, the ability for ana-\nlytic rule-based generalisation. We will illustrate\nwhat tests exists for this skill and evaluate qualita-\ntively how GPTs rate on that, based on carefully\ncurated data.\n2 Rule-based generalisation\nRecent approaches to generalisation have shifted\nattention from the traditional narrow definition —\nan extension from a set of data points to new data\npoints of exactly the same nature (i.i.d. assumption)\n(Sch¨olkopf, 2019)— to out-of-distribution gener-\nalisation, be it across languages, across domains,\nor new unseen combinatorial tokens and structures\n(Hupkes et al., 2022).\nHumans are good generalizers. A large body of\nliterature of experimental work has demonstrated\nthat the human mind is predisposed to extract reg-\nularities and infer the generative rules from data,\nin a way that is distinct from the patterns of activa-\ntion of neural networks (Lakretz et al., 2019, 2021;\nSabl´e-Meyer et al., 2021; Dehaene et al., 2022).\nOne possible approach to develop more robust\nmethods, then, is to pay more attention to the de-\ncomposition of complex observations and to the\n8119\ncausal chains in the generative process that gives\nrise to the data. To discover the underlying problem\nstructure, the notion of disentanglement comes to\nthe rescue. A disentangled representation can be\ndefined as one where single latent units are sensi-\ntive to changes in single generative factors, while\nbeing relatively invariant to changes in other factors\n(Bengio et al., 2013).\nLet’s look at an illustrative example of complex\nlinguistic relations that might require discovering\nthe underlying disentangled factors and causal re-\nlations: the CAUSATIVE alternation exhibited by\nEnglish verbs, shown in (1).\n(1) The teacher opened the door.\nAGENT THEME\nThe door opened.\nTHEME\nThis alternation applies to change of state verbs,\nsuch as open, break, melt, burnamong many others,\nverbs that describe a change that affects the state\nof the undergoing participant ( the door changes\nfrom a state of being closed to a state of being\nopen). They occur in two subcategorisation frames\nthat are related to each other in a regular way: the\nobject of the transitive frame is the subject of the\nintransitive frame. This way, in terms of semantic\nroles, the subject of the transitive is an AGENT , but\nthe subject of the intransitive is a THEME .\nTo learn the structure of such a complex alter-\nnation automatically, despite the simplicity of the\nsentences, a neural network must be able to iden-\ntify and solve a set of subproblems and compose\nthem into an organised solution: (i) identify the\nelements manipulated by the alternation (teacher,\ndoor); (ii) identify the relevant attributes of these\nelements (open, closed state of door; volition of\nteacher); (iii) the object of the transitive sentence is\nthe same event participant as the subject of intran-\nsitive, that is the rules of change of the attributes\nmust be identified across the two sentences.\nTo study what factors and models lead to learn-\ning more disentangled linguistic representations,\nrepresentations that reflect the underlying linguistic\nrules of grammar, a possible approach is to develop\ncurated data on a large scale, building models to\nlearn these data and investigating the models’ be-\nhaviour.\nTo this end, a new linguistic task has been devel-\noped, (similar to the IQ test called RPM, Raven’s\nprogressive matrices for vision), called Blackbird\nLanguage Matrices (BLMs) (Merlo, 2023). BLMs\ndefine prediction tasks to learn complex linguistic\npatterns and paradigms.\nBecause this task relies on a mixture of language\nand abstract rule learning abilities, we conjecture\nthat, used in an evaluation setting, it is appropriate\nto investigate the limits and properties of linguistic\nintelligence and abilities in current state-of-the-art\nLLM, and compare them to humans.\n3 How do humans solve RPMs?\nRaven’s progressive matrices are a visual test of\nanalytic intelligence (Raven, 1938). To establish\nhow to develop human-like rule-based inference,\nit pays to survey how humans solve this kind of\nintelligence test.\n3.1 Raven’s Progressive Matrices for vision\nFigure 1: Example of progressive matrice in the visual\nworld. The task is to determine the missing element in a\nvisual pattern. Given the matrix on the left, choose the\nlast element of the matrix from the choice of elements\non the right. The matrix is constructed according to two\nrules (see text for explanation). Identifying these rules\nleads to the correct answer (marked by double edges).\nRaven’s progressive matrices (progressive be-\ncause tasks get harder) are IQ tests consisting of\na sequence of images, usually organised in a 3x3\nmatrix, called the context, connected in a logical\nsequence by underlying generative rules (Raven,\n1938). The task is to determine the missing ele-\nment, usually the last one, in this visual sequence,\nthe answer. The answer is chosen among a set of\nclosely or loosely similar alternatives. A simple\ninstance of this task, of our devising, is given in\nFigure 1: given a matrix on the left, choose the last\nelement of the matrix from a choice of elements.\nThe matrices are built according to generative rules\nthat span the whole sequence of stimuli and the an-\nswers are constructed to be similar enough that the\nsolution can be found only if the rules are identified\ncorrectly. For example in Figure 1, the matrix is\n8120\nconstructed according to two rules: Rule 1: from\nleft to right, the red dot moves one place clockwise\neach time. This pattern continues onto the next\nrow; Rule 2: from top to bottom, the blue square\nmoves one place anticlockwise each time. This pat-\ntern continues onto the next column. Identifying\nthese rules leads to the correct answer, the only cell\nthat continues the generative rules correctly. Vari-\nants of this structure organise the rules row by row,\nwith the last element of the last row as the missing\nelement.\n3.2 Measuring analytic intelligence in humans\nIn a very articulated study, Carpenter et al. (1990)\nanalyze the cognitive processes at play in Raven\nProgressive matrices tests (RPMs), as a widely\nused, nonverbal test of analytic intelligence. The\nanalysis is based on detailed performance charac-\nteristics such as think-aloud verbal protocols, eye\nfixation patterns, and errors. Of particular inter-\nest for us are the three main sources of difficulty\nthat are identified by the study: the correspondence\nproblem, goal and subgoal management, and item\nnovelty.\nFinding corresponding elements In problems\nwith multiple generative rules, the problem-solver\nmust determine which visual elements or attributes\nin the entries are governed by the same rule, a\nprocess that Carpenter and colleagues call corre-\nspondence finding. Interestingly, it is conjectured\nthat even for visual problems, people use a lin-\nguistic method to find correspondences. Namely,\nthe correspondences reflect the use of a matching-\nnames heuristic: figures with the same name might\ncorrespond to each other.\nGoal and subgoal management In recordings\nof eye movements and verbal protocols, the re-\nsearchers found signs of a demonstrably incremen-\ntal nature of the processing. The subjects solve\na problem by decomposing it into successively\nsmaller sub-problems and then proceed to solve\neach sub-problem. This brought about an incre-\nmental, and sometimes recursive, solution to the\nproblem. The induction of the rules was incre-\nmental in two respects. First of all, in problems\ncontaining more than one rule, the rules were de-\nscribed one at a time. Second, the induction of\na rule consisted of many small steps, reflected in\nthe pairwise comparison of elements in adjoining\nentries. Moreover, the verbal reports show that the\nsubject mentioned one attribute at a time and also\none rule at a time. The general result, then, is that\nthe processing is incremental, that the number of\nrule tokens affects the error rates, and that there is\na wide range of differences among individuals in\ntheir performance on this test.\nItem Novelty Variety and novelty of lexical items\nwas also found to be a source of difficulty.\nIn conclusion, the study finds that the processing\ncharacteristic that is common to all subjects is an\nincremental, re-iterative strategy for encoding and\ninducing the regularities in each problem. The\nprocesses that distinguish among individuals are\nprimarily the ability to induce abstract relations\nand the ability to dynamically manage a large set of\nproblem-solving goals in working memory. These\ntwo abilities are what distinguish, according to this\nstudy, better problem-solvers from average ones.\n4 Blackbird Language Matrices\nCONTEXTS TEMPLATE\n1 NP-sg PP1-sg VP-sg\n2 NP-pl PP1-sg VP-pl\n3 NP-sg PP1-pl VP-sg\n4 NP-pl PP1-pl VP-pl\n5 NP-sg PP1-sg PP2-sg VP-sg\n6 NP-pl PP1-sg PP2-sg VP-pl\n7 NP-sg PP1-pl PP2-sg VP-sg\n8 NP-pl PP1-pl PP2-sg VP-pl\nANSWER SET\n1 NP-sg PP1-sg et NP2 VP-sg Coord\n2 NP-pl PP1-pl NP2-sg VP-pl correct\n3 NP-sg PP1-sg VP-sg WNA\n4 NP-sg PP1-sg PP2-sg VP-pl AE\n5 NP-pl PP1-sg PP1-sg VP-pl WN1\n6 NP-pl PP1-pl PP2-pl VP-pl WN2\nFigure 2: BLM instances for verb-subject agreement,\nwith two attractors. WNA=wrong nr. of attractors;\nAE=agreement error; WN1=wrong nr. for 1st attractor\n(N1); WN2=wrong nr. for 2nd attractor (N2).\nWe propose to apply a similar test to a large lan-\nguage model. We use here the new task and data\nformat, called BLACKBIRD ’S LANGUAGE MA-\nTRICES (BLMs), proposed in Merlo et al. (2022)\nand defined formally in Merlo (2023). (See also\nAn et al. (2023); Samo et al. (2023); Merlo et al.\n(2023a) for more details on data creation for gram-\nmar problems and publicly available data).\nLike RPMs, a BLM instance consists of a con-\ntext set and an answer set. The context is a se-\nquence of sentences that encode a linguistic rule -\ne.g., subject and verb number should agree in their\nnumber independently of how many noun phrases\nintervene between them. BLMs are presented (to\n8121\nan artificial language model or to a human partici-\npant) as linguistic puzzles requiring the selection of\nthe missing sentence. In order to examine the repre-\nsentations underlying the response, the answer sets\ninclude negative examples following corrupted gen-\nerating rules. An example template is illustrated in\nFigure 2.\nFor example, the BLM problem for subject-verb\nagreement (Merlo et al., 2022; An et al., 2023) con-\nsists of a context set of seven sentences that share\nthe subject-verb agreement phenomenon, but dif-\nfer in other aspects – e.g. number of intervening\nattractors between the subject and the verb, differ-\nent grammatical numbers for these attractors, and\ndifferent clause structures. The answer set com-\nprises contrastive sentences that violate some of\nthe generative rules. Actual examples can be found\nin Section 5.\n4.1 The linguistic phenomena\nThe linguistic phenomena we have tested are\nsubject-verb number agreement, the causative al-\nternation and the sequence of tenses. In a BLM,\nthe linguistic phenomena have two levels of prop-\nerties: the external properties (E), those that are\neasily seen in the strings, and internal properties\n(I), that are only inferrable by abstraction (see for-\nmal specification in Merlo (2023) and Merlo et al.\n(2023b)).\n4.2 The agreement matrix\nThe prompt exemplified in Figure 4 shows an ex-\nample of a BLM agreement matrix. In subject-verb\nagreement the primary property is that the subject\nand the verb must match in grammatical number\n(singular and plural). A secondary property indi-\ncates that these two elements do not need to be\nlinearly adjacent, because the rule applies on the\nsyntactic structure of the sentence and not on its\nlinear order (Gulordava et al., 2018; Linzen et al.,\n2016). In this respect, intervening elements can end\nup having the effect of confounding the agreement\npattern.\nThe sequence is generated by a rule of progres-\nsion of number of attractors (one and two), a rule\nof subject-verb agreement that alternates every sen-\ntence between singular and plural of the head noun\nand a rule of number of the attractors that alter-\nnates between singular and plural with a frequency\nperiod of two. Thus, the correct answer for this\nexample is a sentence that has three noun phrases\nand a plural subject and plural first attractor and\nsingular second attractor.\n4.3 The causative matrix\nThe linguistic specification of the causative alterna-\ntion has been given in Section 2. The structure of\nthe causative matrix, shown in the prompt exempli-\nfied in Figure 5, is different from the previous one\nand it is both harder and easier than the previous\none. It is easier in that we use a property of easy\nprogressive matrices, namely the sequence of stim-\nuli is organised into subsets. And it is harder be-\ncause the rule to be learnt is more implicit and has\nno surface morphological correlate, unlike agree-\nment.\nThe first four-tuple of sentences is meant to in-\ndicate that the subject of the transitive is agentive\n(first sentence), that the subject of the intransitive\nis not necessarily agentive (second sentence), and\nthe next two sentences express the initial and final\nstate of the change of state. The second quadru-\nplet, of which the last element needs to be guessed,\nrepeats the same pattern. The sequence pattern,\nthen, is quite easy to see. But the underlying rules\nto be learnt have to do with the mapping of gram-\nmatical functions to semantic roles (subject=Agent,\nobject=theme in the transitive, subject=theme in\nthe intransitive), a notoriously difficult task in neu-\nral networks.\n4.4 The sequence-of-tense matrix\nIn this matrix, we try a different kind of\nlong-distance agreement problem, the so called\nsequence-of-tenses rule. The sequence of tenses\nrule governs the coherent use of tenses in different\nsentences. It is especially used in hypotheticals,\nwhich require subjunctive and conditional mood,\nin the present, past and future tenses. The language\nis Italian, so that the verb conjugation is clearly\nmarked morphologically, both in mood and tense,\nalso making a difference between singular and plu-\nral.\n4.5 The mixture matrix\nFinally, we try a more complex case, in which we\nhave both the sequence of tense rule and the agree-\nment rule, which in this case covers both number\nand gender agreement. The pattern template of the\ndata is shown in Figure 3. An example is shown in\nthe prompt of Figure 7. As can noticed, the agree-\nment pattern is similar to the pattern shown in Fig-\nure 2, with number agreement alternating at every\n8122\nsentence (Sg,Pl,Sg,Pl,..), the gender agreement pat-\ntern alternating every two sentences (M,M,F,F,...)\nand an intervening attractor, exhibiting no agree-\nment pattern, which is absent in the first four sen-\ntences and present in the last four sentences. Notice\nthat, in this matrix, the attractor is an incidental sen-\ntence, so it also interferes in structure and distance\nwith the sequence of tenses, by introducing a third\nverb and lengthening the distance between the ele-\nments in the tense sequence.\nCONTEXT\n1 SgM-CPas SgM-CnPr\n2 PlM-CPas PlM-CnPr\n3 SgF-CTrPas SgM-CnPas\n4 PlF-CTrPas PlM-CnPas\n5 SgM-IFut attractorPLF SgM-IFut\n6 PlM-IFutAnt attractorSgM PlM-IFut\n7 SgF-IFut attractorPlM SgF-IFut\n8 ??\nANSWERS\nA PlF-IFutAnt attractorSgF PlF-IFut\nB SgF-IFut SgF-IFut\nC SgM-CTrPas SgM-CnPas\nD PlM-IFutAnt PlM-IFut\nE SgF-CTrPas attractorSgF PlM-CTrpas\nF PlF-IFutAnt PlF-IFut\nFigure 3: Contexts and Answers patterns of the mixture\nBLM (CPas:past subjunctive; CTrPas:perfect past subjunctive;\nCnPr:present conditional; CnPas:past conditional; IFut:future\nindicative; IFutAnt:future in the past indicative).\nProperties of correct answer (A): Agr:yes, Number:Pl,\nGender:F, attractor:yes, TensePremise:IFutAnt, TenseConse-\nquent:IFut.\nViolations in answer set:\nB - attractor:no, Agr:Pl;\nC - Number:Sg, Gender:M, tense:Cpas, attractor:no;\nD - Gender:M, attractor:no;\nE - Agr:no, Number:Sg, tense:CtrPas;\nF - attractor:no.\n5 Can ChatGPT solve BLMs?\nThe initial motivation to create this kind of task is to\nstudy how to guide current state of the art systems\ntowards better generalisation. Given the current\nvery high performance of large language models,\nhowever, it needs to be established first if current\nstate of the art systems are already capable of solv-\ning this kind of task, or if it is challenging for them,\nand more importantly by which linguistic and rea-\nsoning processes they proceed to find a solution.\nIn particular, the complex mixture of grammatical\nand abductive reasoning that is involved in BLMs\nyields an interesting test set to see if current LLM\nare indeed good at the formal part of language (syn-\ntax and semantics), but weak on the functional part\n(pragmatics and reasoning), as has been recently\nargued (Mahowald et al., 2023).\nTo get a general sense if ChatGPT solves the\nproblem in the same way as human subjects solve\nRPMs, the instructions we give follow the same\nprotocols as those given to subjects in Carpenter\net al. (1990) (see Figure 4 and Figure 5). We per-\nform two tests. First, we use the publicly avail-\nable ChatGPT 3.5, in single one-day sessions, a\ndifferent day for each type of matrix, to collect\nqualitative interactions. Then we use ChatGPT-4,\nover three days, for a more systematic collection of\nquantitative results. When appropriate, we give the\nsentences in Italian to reduce the possibility that\nChatGPT has learned the structure of the problem\nfrom papers previously published on the Internet.\nWe will reach the conclusion that ChatGPT does\nnot really manage to distill the underlying rules\nof the problem, but this should not detract from\nthe first striking observation: it is entirely possi-\nble to have a series of interactive exchanges with\nChatGPT on this task in a completely coherent way.\nThis impressive result confirms the formal ability\nof current LLMs to process language. However,\nthe analysis of the interactions shows that Chat-\nGPT3.5 struggles with the rule-based nature of the\ntask, confirming that its functional ability is still\nrelatively limited. Even in its simplest form and\nwith a lot of guidance from the prompts and dia-\nlogue, the nature of the problem is not understood\nand reliable answers are not reached. Here we give\na summary of some interactions. The detailed pro-\ntocols are in the appendix. As will be shown in\nthe next section, ChatGPT4 exhibits better perfor-\nmance, as observed in many other cases, but the\noverall result is confirmed: it does not manage to\nsee the underlying rules.\n5.1 Subject-verb Agreement\nInteraction 1, 2 and 3 (reported in the appendix)\nshow that ChatGPT3.5 correctly identifies the three\nobjects (subject, first attractor, second attractor) af-\nter inspecting the context, and correctly identifies\ntheir attributes (singular, plural) after inspecting\nthe answers. Somewhat incorrectly, it comments\non the semantic coherence of the sentence. It finds\nthe right answer, but it eliminates alternatives for\nincorrect reasons. ChatGPT3.5 is not really finding\nthe ‘sequence’ notion of the context but is map-\nping each answer sentence to a set of objects and\nattributes, that it appears to have established as\nnecessary. The example matrix used is the one in\n8123\nI am going to ask you to solve a puzzle called BLM-AgrE. I will give you a list of\nsentences (numbered from 1 to 7), that I will call the context, and I will also give you a\nset of sentences (identified by capital letters) that I will call the answers. I will ask you\nto choose among the answer sentences the sentence that could be the next sentence in\nthe context list of sentences.\nI am asking you to give me the correct answer, but also to describe step by step the\nhypotheses you are entertaining while you are solving the problem.\nContext\n1 The talk on history has started later than expected.\n2 Those responsible for the right will resign.\n3 The show with the paintings has met with great success.\n4 The threats of reforms worry the doctors.\n5 The bunch of keys of the cell sits on the shelf.\n6 The studies on the effect of the drug will appear soon.\n7 The threat of reforms in the school worries the doctors.\nAnswers\nA The tablecloths on the table and the console shine in the sun.\nB The friends of the owners of the villa were sleeping on the beach.\nC The lawyers of the murderers will come back.\nD The lawyers of the murderers of the village will come back.\nE The visit of the palace of the crafts is approaching.\nF The computers with the program of the experiment are broken.\nFigure 4: Prompt instructions for interaction 3 of the\nsubject-verb agreement problem with ChatGPT 3.5. The\nresponse and other interactions are shown in the ap-\npendix. See text for a discussion.\nFigure 4. In interaction 4, we explicitly tell it to\nlook for grammatical patterns. The answer shows\nthat ChatGPT3.5 can produce a coarse syntactic\nanalysis. In interactions 5 to 8, we give more detail\nabout number agreement patterns, and that it needs\nto look for patterns across sentences.\nInteraction 9 is very interesting as, at this point,\nwe are basically giving the problem away, but still\nChatGPT3.5 cannot solve it. The answer shows\nthat it parses number agreement incorrectly, so it\nassigns the wrong number to the nouns phrases and\nconsequently cannot see the pattern. So, in inter-\naction 10, we go back to Italian, where number\nagreement is more clearly marked on the verb and\nthe noun phrases. The following interactions 10 to\n19 clearly show that even with a lot of prompting\nChatGPT3.5 is incapable of finding the global al-\nternation pattern. It seems that ChatGPT3.5 never\nreaches the right combination of accuracy in identi-\nfying number agreement patterns, and accuracy in\nseeing patterns across the sentences.\n5.2 Causative\nThe interactions about the causatives are impres-\nsive, despite the fact that a correct solution is not\nfound. This test is both harder and easier than the\nprevious one. The structure of the matrix is easier,\nas the sequence of stimuli is organised into two\nanalogous subsequences, as can be easily seen in\nFigure 5. So the solution to this puzzle requires\nfiguring out the objects, their purpose and their se-\nquence of the first four sentences and apply it to the\nI am going to ask you to solve a grammatical problem called BLM-CausE. I will give\nyou a list of English sentences (numbered from 1 to 7), that I will call the context, and\nI will also give you a set of English sentences (identified by capital letters) that I will\ncall the answers. I will ask you to choose among the answer sentences the one sentence\nthat could be the next sentence in the context list of sentences. The sentences have\nbeen generated in a rule-based manner.\nI am asking you to give me the correct answer, but also to describe step by step the\nhypotheses you are entertaining while you are solving the problem.\nContext\n1 The boy opened the door voluntarily.\n2 The door opened suddenly.\n3 The door was closed.\n4 The door is open.\n5 The cook melted the butter voluntarily.\n6 The butter melted slowly.\n7 The butter was hard.\nAnswers\nA The butter is melted.\nB The boy is open.\nC The door was open.\nD The cook is melted.\nE The butter was melted.\nFigure 5: Prompt instructions for interaction 1 of the\ncausative alternation problem with ChatGPT 3.5. The re-\nsponse and other interactions are shown in the appendix.\nSee text for a discussion.\nsentences 5-8, to find solution A. However, Chat-\nGPT does not see the pattern, both in interaction\n1, where no instruction is given and interaction 2,\nwhere instruction is given about the fact that the\nsentences should be looked at as two block. The in-\ndividual sentence by sentence explanations of what\nthe sentences in the context are supposed to show\nis however very impressive (and correct). This is\nshown in Figure 6. To verify that this apaprent\ninsightfulness does not come from simply repeat-\ning, parrot-like, snippets of the large literature on\nthis problem in English, we repeat the interaction\nItalian, where this problem is much less studied.\nThe Italian interaction repeats exactly the English\npattern of reasoning (making us think some transla-\ntion is going on internally) and no correct solution\nis found.\n5.3 Sequence of Tenses and Mixture of\nProblems\nAn example of the prompt for the sequence of\ntenses problem can be seen in the appendix. An\nexample of the prompt for the mixture of problems\nagreement and sequence of tenses is shown in Fig-\nure 7. We show interaction 1. As can be seen,\nwe specify explicitly that the solution is not to be\nfound in the logical sequence and the topics of the\nsentences.\nThe responses from ChatGPT3.5 for the se-\nquence of tenses problem, which can be inspected\nin the appendix, show that while the explanations of\nthe selection of the correct answer are not very con-\n8124\nTo solve the BLM-CausE problem, we need to analyze\nthe given context sentences and the set of answer sen-\ntences to determine the most appropriate continuation\nfor the context. Let’s go through the process step by\nstep:\nIdentify the relevant elements: In this context, we have\ntwo main elements: ”the door” and ”the butter.” We\nneed to observe the causality between these elements\nand their states. Analyze the context:\nSentence 1: The boy opened the door voluntarily. This\nsentence establishes that the boy was responsible for\nopening the door.\nSentence 2: The door opened suddenly. This sentence\nsuggests that the door opened on its own accord, without\nexternal agency.\nSentence 3: The door was closed. This sentence indi-\ncates the initial state of the door, which was closed.\nSentence 4: The door is open. This sentence reveals the\ncurrent state of the door, which is open.\nSentence 5: The cook melted the butter voluntarily. This\nsentence states that the cook caused the butter to melt.\nSentence 6: The butter melted slowly. This sentence\ndescribes the process of the butter melting.\nSentence 7: The butter was hard. This sentence states\nthe initial state of the butter, which was hard.\nConsider the answer choices: Now let’s analyze each\nanswer choice in relation to the context:\nAnswer A: The butter is melted. This answer suggests\nthat the current state of the butter is melted. However,\nit doesn’t directly relate to the given context. We don’t\nhave any information about the current state of the but-\nter.\nAnswer B: The boy is open. This answer doesn’t make\nlogical sense as it equates the boy with being open,\nwhich is unrelated to the context.\nAnswer C: The door was open. This answer corresponds\nto the progression of the door’s state as mentioned in the\ncontext. It follows the pattern established in sentences 2\nand 3, where the door opens suddenly after being closed.\nThis seems to be a reasonable continuation.\nAnswer D: The cook is melted. This answer equates the\ncook with being melted, which doesn’t make sense in\nthe context.\nAnswer E: The butter was melted. This answer corre-\nsponds to the progression of the butter’s state as men-\ntioned in the context. It follows the pattern established\nin sentences 5 and 6, where the cook causes the butter\nto melt slowly. This also seems like a plausible continu-\nation.\nFinal decision: Comparing answers C and E, both seem\nto be reasonable continuations based on the given con-\ntext. However, since the initial prompt requests choos-\ning only one answer, we need to make a decision. Con-\nsidering the sequential pattern of events in the context,\nit seems more likely that the door’s state would be the\nnext relevant topic. Therefore, the correct answer is C:\nThe door was open.\nFigure 6: Reply to interaction 1 of the causative al-\nternation problem with ChatGPT 3.5. See text for a\ndiscussion.\nI am going to ask you to solve a grammatical problem called BLM-MixI. I will give\nyou a list of Italian sentences (numbered from 1 to 7), that I will call the context, and I\nwill also give you a set of Italian sentences (identified by capital letters) that I will call\nthe answers. I will ask you to choose among the answer sentences the one sentence that\ncould be the next sentence in the context list of sentences. The sentences have been\ngenerated in a rule-based manner.\nI am asking you to give me the correct answer, but also to describe step by step the\nhypotheses you are entertaining while you are solving the problem. I am also giving\nyou a hint: This is a grammatical problem, not a logical problem. The solution does\nnot lie in finding a logical continuation, but a continuation that follows the underlying\ngrammatical patterns.\nContext\n1 Se fossi ricco, allora sarei felice.\n2 Se fossero buoni, allora non sarebbero ricchi.\n3 Se fossi stata ricca, allora non saresti stata felice.\n4 Se foste state buone, allora sareste state ricche.\n5 Se sarai bravo, indipendentemente dalle circostanze, allora sarai ricco.\n6 Se sarete stati bravi, nonostante tutto, allora sarete ricchi.\n7 Se sarai buona, tenendo conto di tanti altri fattori, allora sarai ricca.\nAnswers\nA Se sarete state buone, e con un po’ di fortuna, allora sarete ricche.\nB Se sarai buona, allora sarai felice.\nC Se fossi stato buono, allora fossi felice.\nD Se sarete stati buoni, allora sarete ricchi.\nE Se fossi stata buona, tenendo conto di tanti altri fattori, allora fossero stati felici.\nF Se sarete state buone, allora sarete ricche.\nFigure 7: Prompt instructions for interaction 1 of the\nmixture of agreement and tense sequence problems with\nChatGPT 3.5. The response and other interactions are\nshown in the appendix. See text for a discussion.\nvincing, when explicitly asked to formulate the rule,\nChatGPT correctly identifies it as the sequence of\ntense rule. It insists, however, in finding semantic\nsequentiality, which is, instead, not relevant.\nFor the mixture of the two problems, agreement\nand sequence of tenses, we see that ChatGPT3.5\ncannot even converge on a single answer. This\nis because, while it understands reasonably well\nthe relevance of the sequence of tenses, it misses\nthe agreement pattern completely, and so it cannot\neliminate many incorrect alternative answers that\ndepend on recognising this pattern.\n5.4 Discussion\nIf we map impressionistically ChatGPT’s solutions\nto the three areas in which people find difficulty\n(findings correspondences, goal and subgoal man-\nagement and item novelty), we notice that ChatGPT\nis quite good at correspondence finding, but only\nif the problem encodes a single grammatical rule.\nOtherwise, it does not manage to identify the two\npatterns in the mixture matrix. Also, it clearly per-\nforms better with lexical semantic problems than\nmorphological problems. With quite a bit of guid-\nance, it seems to be able to identify an abstract\ntemplate from lexically varied items (item novelty).\nHowever, it never manages to identify the sequence\npattern, and consequently find the answer in any of\nthe problems: this seems to be indicative of lack of\ngoal and subgoal management.\n8125\n6 Quantitative Analysis\nThe interaction illustrated in the previous section\nare a limited sample. We also developed a con-\ntrolled sample of interactions, and analyse it quan-\ntitatively. We use ChatGPT-4 (between the 28th\nand the 30th of September, 2023).\n6.1 Sample creation and quantitative\nmeasures\nThe dimensions of variation of the sample reflect\nthe properties we need to analyse. We test two sim-\nple BLMs (Caus, Agr) and the mixed BLMs that\nmerges Agreement and sequence of tense patterns\n(Mix). Each type of BLM has two versions, exhibit-\ning two levels of lexicalisation (what in other work\non BLMs has been called type I and a type III).\nType I lexicalisation uses the same lexical items\nacross all sentences in the matrix (see for example\nFigure 7), while the type III has complete lexical\nvariability (see for example Figure 4).\nFor each combination of BLM simple problem\nand lexicalisation level we create five instances,\nbuilt semi-automatically by transformation of a\nprototype with ChatGPT4 and then corrected or\nmodified. Mixed BLMs where composed by hand.\nSome examples are shown in Appendix E.1.\nThe coding protocol is developed for compara-\nbility with the quantitative analyses developed for\nhuman subjects (Carpenter et al., 1990). We follow\nthe same dimensions of evaluation (also discussed\nin the previous section): correspondence finding\n(elements and attributes), goal and subgoal manage-\nment (timing and organisation of mentions, method\nused to find answers) and item novelty (type I and\ntype III levels of lexical variation). The exact cod-\ning scheme corresponding to these concepts varies\nfor each BLM problem, and is shown in Figure 8.\n6.2 Quantitative results\nThe output were then manually analysed accord-\ning to the categories shown in Figure 8. In Table\n1, we report the summaries of the results and re-\nlated statistics. The complete results tables are\nshown in Appendix E. The complete outputs for\nall problems are provided at https://github.com/\nCLCL-Geneva/BLM-ChatGPTInteractions.\nSuccess rate The success rate is quite good, with\na high rate of correctly identified answers. Nonethe-\nless, the answers that are correct because the right\npattern has been identified are fewer, with the ex-\nCORRECTLY IDENTIFIED ELEMENTS\nCaus Subj Trans1, Obj Trans1, Subj Trans2, Obj Trans2\nAgr NP1, NP2, NP3, V\nSoT Premise, Consequent\nCORRECTLY IDENTIFIED ATTRIBUTES\nCaus V olition, Ext. Agent, CoS:Initial, CoS:Current\nAgent, Patient\nAgr Sing, Plural, Match,Mismatch\nSoT Tense, Person, Gender, Match, Mismatch\nGOAL MANAGEMENT\nAll One-at-a-Time, Pairwise, Row/Col-wise, Unordered\nFINDING ANSWERS\nAll Rule-based generation, Answer elimination\nFigure 8: Elements and attributes and problem-solving\nprocedures. Mixed problems are the union of the ele-\nments and attributes and intersection of problem-solving\nprocedures.\ntreme case being the causative alternation, which\nhas been identified as such only in one case.1\nCorrespondence finding The number of cor-\nrectly identified elements is relatively high, ranging\nfrom 73 to 89 percent, confirming that ChatGPT4\n(like 3.5) is good at correspondence finding: iden-\ntifying the aspect of the problem it needs to pay\nattention to. Comparing the ranking, best for Agr\nand worse for Mix, to the previous table of scores\nof correct answers, it can be noticed that good iden-\ntification of the objects does not guarantee propor-\ntionally good finding of the correct answer.\nThe percentage of correctly identified attributes\nis lower, showing that this aspect of the prob-\nlem is harder to identify, and particularly hard for\ncausative BLMs. This is actually not surprising,\nas the attributes of Caus-BLM are more abstract,\nwhile Agr and Mix are much visible morphologi-\ncally. This aspect of correspondence finding is a\nbetter predictor of overall performance.\nItem novelty The sensitivity to item novelty re-\nsults from comparisons of BLMs of different levels\nof lexicalisation (type I, type III). The sensitivity\nto more or fewer new lexical items seems to vary\nby problem. It appears to be, in general, true that\nmore variation in lexicalisation creates difficulty.\n1Notice that, in coding answers, we gave a full credit for\nonly partial identification of pattern. For example, we have\ncoded correct identification of the agreement pattern in most\ncases when in fact only the subject alternation pattern was\nidentified but the two-step patterns for the second NP was not\nidentified (which was in most cases).\n8126\nSUCCESS RATE\nCorrect Correct Total\nanswers patterns answers\nCaus 11 1 11\nAgr 8 9 12\nMix 9 6 10\nCORRESPONDENCE FINDING\nIdentified Tot Identified Tot\nelements (%) attributes(%)\nCaus 56 (85) 66 20 (30) 66\nAgr 43 (89) 48 42 (87) 48\nMix 44 (73) 60 72 (80) 90\nTot 143 174 134 204\nGOAL MANAGEMENT\nOrganisation of Mentions Finding Answers Tot\nOaT Prw RCw Un RbG Ael\nCaus 1 10 10 0 10 11 11\nAgr 9 3 4 2 11 12 12\nMix 5 5 10 0 6 9 10\nTot 15 18 24 2 27 32\nTable 1: Quantitative results of BLM solutions (Id’ed\nels: identified elements; Id’ed attrs: identified attributes;\nOaT: One-at-a-Time; Prw:Pairwise; RCw: Row/Col-\nwise; Un: Unordered; RbG: Rule-b generation; Ael:\nAnswer elimination).\nMore specifically, causatives BLM are quite dif-\nferent in type I and type III because the elements\nthat alternate are no longer the same NPs. Yet,\nthe results are very similar, so we do not notice a\ndifference in complexity. Agreement BLMs show\ncorrect answer for Type I in all 6 cases, but only 2\nfor type III. So lexicalisation does indeed make the\ntask harder. Also in the Mixed BLMs, type III is\nharder.\nGoal Management The quantification of aspects\nof the reasoning employed to solve the problem\nshow that the categories developed for humans ap-\nply easily here too, as the output of ChatGPT4 is\ncoherent, articulate and corresponds well to the\nexpectations. Items are inspected comparatively\nmore often than one at a time and, depending on\nthe problem, what are formulated as attempts to\nfind patterns gives rise to pairwise rules. The in-\nspection of sentences is row by row or by groups\nof rows and rarely unordered. Of the two methods\nof rule finding documented in humans, rule-based\nhypothesis followed by matching with answers and\nelimination of the incorrect ones is the most com-\nmon. Only in a few cases, in the clearly harder\nmixed BLMs, no rules were hypothesised and only\ndirectly answer elimination was attempted.\n7 Further Related Work\nTraditionally, progressive matrices as intelligence\ntests are designed by hand, but recent research in vi-\nsion that has used this task to train neural networks\nhas typically employed some structured genera-\ntive model to create a large number of questions.\nWang and Su (2015) generate RPMs using first-\norder logic, which have further inspired Barrett\net al. (2018a) to use relation-object-attribute triple\ninstantiations. Zhang et al. (2019) use the Attribute\nStochastic Image Grammar (A-SIG, proposed by\nZhu and Mumford, 2006) as the representation of\nRPMs, and have created the Relational and Ana-\nlogical Visual rEasoNing (RA VEN) dataset. The\ncontrolled construction of the context data and of\nthe contrastive answer set is crucial. In this way,\nthe learning process basically discovers how to in-\nduce the model and it makes it possible to identify\nclear dimensions of successful and unsuccessful\ngeneralisation. For example, matrices for vision\nhave shown that the best models can apply known\nabstract relationships in novel combinations, but\nfail in applying known abstract relationships to un-\nfamiliar entities (Barrett et al., 2018b).\n8 A Roadmap for the Future\nThe investigation reported here aims to prove a con-\ncept: curated data and in-depth qualitative analyses\ninspired by human intelligence tests can comple-\nment large-scale benchmarking in an interesting\nway. In particular, large-scale benchmarking based\non correlations of humans and machines does not\nenlighten us on the causal sources of behaviours,\nand instead hypothesis testing experiments need to\nbe performed. It is also interesting to collect data\nabout human and machine overt knowledge, rather\nthan phychophysical measures (eye-tracking, brain\nactivations) or internal ANN layer representations.\nA larger-scale investigation applying the curated\ndata and qualitative method presented here is how-\never also possible. We need to develop multiple\ndatasets and run several interactive experiments\nthat need then to be measured and assessed by\nproper statistical methods.\n9 Acknowledgements\nWe gratefully acknowledge the partial support of\nthis work by the Swiss National Science Foun-\ndation, through grants #51NF40 180888 (NCCR\nEvolving Language) and SNF Advanced grant\nTMAG-1 209426 to PM.\n8127\n10 Ethics Statement\nTo the best of our knowledge, there are no ethics\nconcerns with this paper.\n11 Limitations\nOur preliminary conclusions about human-machine\ncorrespondence sketch the avenue for future devel-\nopments. The work presented here is meant as\na programmatic call. The main limitations con-\ncern limitations in the BLM development, in the\nrange of examined architectures and the level of\ninternal analysis, and in the range of cognitive con-\ncepts investigated. BLMs are being developed with\nlarger-scale multi-linguality and greater variety of\nlinguistic phenomena. Work is also planned to\nstudy how they affect internal layers of LLMs.\nReferences\nAixiu An, Chunyang Jiang, Maria A. Rodriguez, Vivi\nNastase, and Paola Merlo. 2023. BLM-AgrF: A new\nFrench benchmark to investigate generalization of\nagreement in neural networks. In Proceedings of the\n17th Conference of the European Chapter of the As-\nsociation for Computational Linguistics, pages 1363–\n1374, Dubrovnik, Croatia. Association for Computa-\ntional Linguistics.\nDavid Barrett, Felix Hill, Adam Santoro, Ari Morcos,\nand Timothy Lillicrap. 2018a. Measuring abstract\nreasoning in neural networks. In Proceedings of the\n35th International Conference on Machine Learning,\nICML 2018, Stockholmsm¨assan, Stockholm, Sweden,\nJuly 10-15, 2018, volume 80 of Proceedings of Ma-\nchine Learning Research, pages 4477–4486. PMLR.\nDavid G.T. Barrett, Felix Hill, Adam Santoro, Ari S.\nMorcos, and Timothy Lillicrap. 2018b. Measuring\nabstract reasoning in neural networks. In Proceed-\nings of the 35th International Conference on Machine\nLearning, Stockholm, Sweden.\nYoshua Bengio, Aaron Courville, and Pascal Vincent.\n2013. Representation learning: A review and new\nperspectives. IEEE transactions on pattern analysis\nand machine intelligence, 35(8):1798– 1828.\nPatricia A. Carpenter, Marcel A. Just, and Peter Shell.\n1990. What one intelligence test measures: A theoret-\nical account of the processing in the Raven Progres-\nsive Matrices Test. Psychological Review, 97(3):404–\n431.\nStanislas Dehaene, Fosca Al Roumi, Yair Lakretz,\nSamuel Planton, and Mathias Sabl ´e-Meyer. 2022.\nSymbols and mental programs: a hypothesis about\nhuman singularity. Trends in Cognitive Sciences ,\n26(9):751–766.\nKristina Gulordava, Piotr Bojanowski, Edouard Grave,\nTal Linzen, and Marco Baroni. 2018. Colorless green\nrecurrent networks dream hierarchically. In Proceed-\nings of the 2018 Conference of the North American\nChapter of the Association for Computational Lin-\nguistics: Human Language Technologies, Volume 1\n(Long Papers), pages 1195–1205. Association for\nComputational Linguistics.\nDieuwke Hupkes, Mario Giulianelli, Verna Dankers,\nMikel Artetxe, Yanai Elazar, Tiago Pimentel, Chris-\ntos Christodoulopoulos, Karim Lasri, Naomi Saphra,\nArabella Sinclair, Dennis Ulmer, Florian Schottmann,\nKhuyagbaatar Batsuren, Kaiser Sun, Koustuv Sinha,\nLeila Khalatbari, Maria Ryskina, Rita Frieske, Ryan\nCotterell, and Zhijing Jin. 2022. State-of-the-art gen-\neralisation research in NLP: a taxonomy and review.\nCoRR.\nYair Lakretz, Dieuwke Hupkes, Alessandra Vergallito,\nMarco Marelli, Marco Baroni, and Stanislas Dehaene.\n2021. Mechanisms for handling nested dependen-\ncies in neural-network language models and humans.\nCognition.\nYair Lakretz, German Kruszewski, Theo Desbordes,\nDieuwke Hupkes, Stanislas Dehaene, and Marco Ba-\nroni. 2019. The emergence of number and syntax\nunits in LSTM language models. arXiv preprint\narXiv:1903.07435.\nTal Linzen, Emmanuel Dupoux, and Yoav Goldberg.\n2016. Assessing the ability of LSTMs to learn syntax-\nsensitive dependencies. Transactions of the Associa-\ntion for Computational Linguistics, 4:521–535.\nKyle Mahowald, Anna A. Ivanova, Idan A. Blank,\nNancy Kanwisher, Joshua B. Tenenbaum, and\nEvelina Fedorenko. 2023. Dissociating language\nand thought in large language models: a cognitive\nperspective. arXiv cs.CL 2301.06627.\nPaola Merlo. 2023. Blackbird language matrices (blm),\na new task for rule-like generalization in neural net-\nworks: Motivations and formal specifications. ArXiv,\ncs.CL 2306.11444.\nPaola Merlo, Aixiu An, and Maria A. Rodriguez. 2022.\nBlackbird’s language matrices (BLMs): a new bench-\nmark to investigate disentangled generalisation in\nneural networks. ArXiv, cs.CL 2205.10866.\nPaola Merlo, Chunyang Jiang, Giuseppe Samo, and Vivi\nNastase. 2023a. Blackbird language matrices tasks\nfor generalization. In GenBench: The first workshop\non generalisation (benchmarking) in NLP.\nPaola Merlo, Giuseppe Samo, Vivi Nastase, and Chun-\nyang Jiang. 2023b. Building structured synthetic\ndatasets: The case of Blackbird Language Matrices\n(BLMs). In Ninth Italian Conference on Computa-\ntional Linguistics.\nJohn C. Raven. 1938. Standardization of progressive\nmatrices. British Journal of Medical Psychology ,\n19:137–150.\n8128\nAnna Rogers. 2021. Changing the world by changing\nthe data. In Proceedings of the 59th Annual Meet-\ning of the Association for Computational Linguistics\nand the 11th International Joint Conference on Natu-\nral Language Processing (Volume 1: Long Papers),\npages 2182–2194, Online. Association for Computa-\ntional Linguistics.\nMathias Sabl´e-Meyer, Jo¨el Fagot, Serge Caparos, Timo\nvan Kerkoerle, Marie Amalric, and Stanislas De-\nhaene. 2021. Sensitivity to geometric shape regu-\nlarity in humans and baboons: A putative signature\nof human singularity. Proceedings of the National\nAcademy of Sciences, 118(16).\nGiuseppe Samo, Vivi Nastase, Chunyang Jiang, and\nPaola Merlo. 2023. BLM-s/lE: A structured dataset\nof English spray-load verb alternations for testing\ngeneralization in LLMs. In Findings of the 2023\nConference on Empirical Methods in Natural Lan-\nguage Processing.\nMartin Schrimpf, Jonas Kubilius, Michael J. Lee,\nN. Apurva Natan Murty, Robert Ajemian, and James\nJ. Di Carlo. 2020. Integrative benchmarking to ad-\nvance neurally mechanistic models of human intelli-\ngence. Neuron, 108(3).\nBernhard Sch¨olkopf. 2019. Causality for machine learn-\ning. Technical report, arXiv:1911.10500v2.\nAarohi Srivastava, Abhinav Rastogi, Abhishek Rao,\nAbu Awal Md Shoeb, Abubakar Abid, Adam\nFisch, Adam R. Brown, Adam Santoro, Aditya\nGupta, Adri `a Garriga-Alonso, Agnieszka Kluska,\nAitor Lewkowycz, Akshat Agarwal, Alethea Power,\nAlex Ray, Alex Warstadt, Alexander W. Kocurek,\nAli Safaya, Ali Tazarv, Alice Xiang, Alicia Par-\nrish, Allen Nie, Aman Hussain, Amanda Askell,\nAmanda Dsouza, Ambrose Slone, Ameet Rahane,\nAnantharaman S. Iyer, Anders Andreassen, Andrea\nMadotto, Andrea Santilli, Andreas Stuhlm¨uller, An-\ndrew Dai, Andrew La, Andrew Lampinen, Andy\nZou, Angela Jiang, Angelica Chen, Anh Vuong,\nAnimesh Gupta, Anna Gottardi, Antonio Norelli,\nAnu Venkatesh, Arash Gholamidavoodi, Arfa Tabas-\nsum, Arul Menezes, Arun Kirubarajan, Asher Mul-\nlokandov, Ashish Sabharwal, Austin Herrick, Avia\nEfrat, Aykut Erdem, Ayla Karakas ¸, B. Ryan Roberts,\nBao Sheng Loe, Barret Zoph, Bartłomiej Bojanowski,\nBatuhan ¨Ozyurt, Behnam Hedayatnia, Behnam\nNeyshabur, Benjamin Inden, Benno Stein, Berk\nEkmekci, Bill Yuchen Lin, Blake Howald, Bryan\nOrinion, Cameron Diao, Cameron Dour, Cather-\nine Stinson, Cedrick Argueta, C´esar Ferri Ram´ırez,\nChandan Singh, Charles Rathkopf, Chenlin Meng,\nChitta Baral, Chiyu Wu, Chris Callison-Burch, Chris\nWaites, Christian V oigt, Christopher D. Manning,\nChristopher Potts, Cindy Ramirez, Clara E. Rivera,\nClemencia Siro, Colin Raffel, Courtney Ashcraft,\nCristina Garbacea, Damien Sileo, Dan Garrette, Dan\nHendrycks, Dan Kilman, Dan Roth, Daniel Free-\nman, Daniel Khashabi, Daniel Levy, Daniel Mosegu´ı\nGonz´alez, Danielle Perszyk, Danny Hernandez,\nDanqi Chen, Daphne Ippolito, Dar Gilboa, David\nDohan, David Drakard, David Jurgens, Debajyoti\nDatta, Deep Ganguli, Denis Emelin, Denis Kleyko,\nDeniz Yuret, Derek Chen, Derek Tam, Dieuwke Hup-\nkes, Diganta Misra, Dilyar Buzan, Dimitri Coelho\nMollo, Diyi Yang, Dong-Ho Lee, Dylan Schrader,\nEkaterina Shutova, Ekin Dogus Cubuk, Elad Se-\ngal, Eleanor Hagerman, Elizabeth Barnes, Elizabeth\nDonoway, Ellie Pavlick, Emanuele Rodola, Emma\nLam, Eric Chu, Eric Tang, Erkut Erdem, Ernie Chang,\nEthan A. Chi, Ethan Dyer, Ethan Jerzak, Ethan\nKim, Eunice Engefu Manyasi, Evgenii Zheltonozh-\nskii, Fanyue Xia, Fatemeh Siar, Fernando Mart´ınez-\nPlumed, Francesca Happ´e, Francois Chollet, Frieda\nRong, Gaurav Mishra, Genta Indra Winata, Gerard\nde Melo, Germ ´an Kruszewski, Giambattista Paras-\ncandolo, Giorgio Mariani, Gloria Wang, Gonzalo\nJaimovitch-L´opez, Gregor Betz, Guy Gur-Ari, Hana\nGalijasevic, Hannah Kim, Hannah Rashkin, Han-\nnaneh Hajishirzi, Harsh Mehta, Hayden Bogar, Henry\nShevlin, Hinrich Sch ¨utze, Hiromu Yakura, Hong-\nming Zhang, Hugh Mee Wong, Ian Ng, Isaac Noble,\nJaap Jumelet, Jack Geissinger, Jackson Kernion, Ja-\ncob Hilton, Jaehoon Lee, Jaime Fern ´andez Fisac,\nJames B. Simon, James Koppel, James Zheng, James\nZou, Jan Koco ´n, Jana Thompson, Janelle Wing-\nfield, Jared Kaplan, Jarema Radom, Jascha Sohl-\nDickstein, Jason Phang, Jason Wei, Jason Yosin-\nski, Jekaterina Novikova, Jelle Bosscher, Jennifer\nMarsh, Jeremy Kim, Jeroen Taal, Jesse Engel, Je-\nsujoba Alabi, Jiacheng Xu, Jiaming Song, Jillian\nTang, Joan Waweru, John Burden, John Miller,\nJohn U. Balis, Jonathan Batchelder, Jonathan Be-\nrant, J ¨org Frohberg, Jos Rozen, Jose Hernandez-\nOrallo, Joseph Boudeman, Joseph Guerr, Joseph\nJones, Joshua B. Tenenbaum, Joshua S. Rule, Joyce\nChua, Kamil Kanclerz, Karen Livescu, Karl Krauth,\nKarthik Gopalakrishnan, Katerina Ignatyeva, Katja\nMarkert, Kaustubh D. Dhole, Kevin Gimpel, Kevin\nOmondi, Kory Mathewson, Kristen Chiafullo, Kse-\nnia Shkaruta, Kumar Shridhar, Kyle McDonell, Kyle\nRichardson, Laria Reynolds, Leo Gao, Li Zhang,\nLiam Dugan, Lianhui Qin, Lidia Contreras-Ochando,\nLouis-Philippe Morency, Luca Moschella, Lucas\nLam, Lucy Noble, Ludwig Schmidt, Luheng He,\nLuis Oliveros Col´on, Luke Metz, L¨utfi Kerem S ¸enel,\nMaarten Bosma, Maarten Sap, Maartje ter Hoeve,\nMaheen Farooqi, Manaal Faruqui, Mantas Mazeika,\nMarco Baturan, Marco Marelli, Marco Maru, Maria\nJose Ram´ırez Quintana, Marie Tolkiehn, Mario Giu-\nlianelli, Martha Lewis, Martin Potthast, Matthew L.\nLeavitt, Matthias Hagen, M ´aty´as Schubert, Med-\nina Orduna Baitemirova, Melody Arnaud, Melvin\nMcElrath, Michael A. Yee, Michael Cohen, Michael\nGu, Michael Ivanitskiy, Michael Starritt, Michael\nStrube, Michał Swedrowski, Michele Bevilacqua,\nMichihiro Yasunaga, Mihir Kale, Mike Cain, Mimee\nXu, Mirac Suzgun, Mitch Walker, Mo Tiwari, Mo-\nhit Bansal, Moin Aminnaseri, Mor Geva, Mozhdeh\nGheini, Mukund Varma T, Nanyun Peng, Nathan A.\nChi, Nayeon Lee, Neta Gur-Ari Krakover, Nicholas\nCameron, Nicholas Roberts, Nick Doiron, Nicole\nMartinez, Nikita Nangia, Niklas Deckers, Niklas\nMuennighoff, Nitish Shirish Keskar, Niveditha S.\n8129\nIyer, Noah Constant, Noah Fiedel, Nuan Wen,\nOliver Zhang, Omar Agha, Omar Elbaghdadi, Omer\nLevy, Owain Evans, Pablo Antonio Moreno Casares,\nParth Doshi, Pascale Fung, Paul Pu Liang, Paul Vi-\ncol, Pegah Alipoormolabashi, Peiyuan Liao, Percy\nLiang, Peter Chang, Peter Eckersley, Phu Mon\nHtut, Pinyu Hwang, Piotr Miłkowski, Piyush Patil,\nPouya Pezeshkpour, Priti Oli, Qiaozhu Mei, Qing\nLyu, Qinlang Chen, Rabin Banjade, Rachel Etta\nRudolph, Raefer Gabriel, Rahel Habacker, Ramon\nRisco, Rapha ¨el Milli `ere, Rhythm Garg, Richard\nBarnes, Rif A. Saurous, Riku Arakawa, Robbe\nRaymaekers, Robert Frank, Rohan Sikand, Roman\nNovak, Roman Sitelew, Ronan LeBras, Rosanne\nLiu, Rowan Jacobs, Rui Zhang, Ruslan Salakhut-\ndinov, Ryan Chi, Ryan Lee, Ryan Stovall, Ryan\nTeehan, Rylan Yang, Sahib Singh, Saif M. Moham-\nmad, Sajant Anand, Sam Dillavou, Sam Shleifer,\nSam Wiseman, Samuel Gruetter, Samuel R. Bow-\nman, Samuel S. Schoenholz, Sanghyun Han, San-\njeev Kwatra, Sarah A. Rous, Sarik Ghazarian, Sayan\nGhosh, Sean Casey, Sebastian Bischoff, Sebastian\nGehrmann, Sebastian Schuster, Sepideh Sadeghi,\nShadi Hamdan, Sharon Zhou, Shashank Srivastava,\nSherry Shi, Shikhar Singh, Shima Asaadi, Shixi-\nang Shane Gu, Shubh Pachchigar, Shubham Tosh-\nniwal, Shyam Upadhyay, Shyamolima, Debnath,\nSiamak Shakeri, Simon Thormeyer, Simone Melzi,\nSiva Reddy, Sneha Priscilla Makini, Soo-Hwan Lee,\nSpencer Torene, Sriharsha Hatwar, Stanislas De-\nhaene, Stefan Divic, Stefano Ermon, Stella Bider-\nman, Stephanie Lin, Stephen Prasad, Steven T. Pi-\nantadosi, Stuart M. Shieber, Summer Misherghi, Svet-\nlana Kiritchenko, Swaroop Mishra, Tal Linzen, Tal\nSchuster, Tao Li, Tao Yu, Tariq Ali, Tatsu Hashimoto,\nTe-Lin Wu, Th´eo Desbordes, Theodore Rothschild,\nThomas Phan, Tianle Wang, Tiberius Nkinyili, Timo\nSchick, Timofei Kornev, Titus Tunduny, Tobias Ger-\nstenberg, Trenton Chang, Trishala Neeraj, Tushar\nKhot, Tyler Shultz, Uri Shaham, Vedant Misra, Vera\nDemberg, Victoria Nyamai, Vikas Raunak, Vinay\nRamasesh, Vinay Uday Prabhu, Vishakh Padmaku-\nmar, Vivek Srikumar, William Fedus, William Saun-\nders, William Zhang, Wout V ossen, Xiang Ren, Xi-\naoyu Tong, Xinran Zhao, Xinyi Wu, Xudong Shen,\nYadollah Yaghoobzadeh, Yair Lakretz, Yangqiu Song,\nYasaman Bahri, Yejin Choi, Yichi Yang, Yiding\nHao, Yifu Chen, Yonatan Belinkov, Yu Hou, Yufang\nHou, Yuntao Bai, Zachary Seid, Zhuoye Zhao, Zi-\njian Wang, Zijie J. Wang, Zirui Wang, and Ziyi Wu.\n2023. Beyond the imitation game: Quantifying and\nextrapolating the capabilities of language models.\nKe Wang and Zhendong Su. 2015. Automatic genera-\ntion of raven’s progressive matrices. In Proceedings\nof the Twenty-Fourth International Joint Conference\non Artificial Intelligence, IJCAI 2015, Buenos Aires,\nArgentina, July 25-31, 2015, pages 903–909. AAAI\nPress.\nAnthony Zador, Sean Escola, Blake Richards, Bence\n¨Olveczky, Yoshua Bengio, Kwabena Boahen,\nMatthew Botvinick, Dmitri Chklovskii, Anne\nChurchland, Claudia Clopath, James DiCarlo, Surya\nGanguli, Jeff Hawkins, Konrad Koerding, Alexei\nKoulakov, Yann LeCun, Timothy Lillicrap, Adam\nMarblestone, Bruno Olshausen, Alexandre Pouget,\nCristina Savin, Terrence Sejnowski, Eero Simoncelli,\nSara Solla, David Sussillo, Andreas S. Tolias, and\nDoris Tsao. 2023. Toward next-generation artificial\nintelligence: Catalyzing the neuroai revolution. Na-\nture Communications, 14(1597).\nChi Zhang, Feng Gao, Baoxiong Jia, Yixin Zhu, and\nSong-Chun Zhu. 2019. RA VEN: A dataset for re-\nlational and analogical visual reasoning. In IEEE\nConference on Computer Vision and Pattern Recogni-\ntion, CVPR 2019, Long Beach, CA, USA, June 16-20,\n2019, pages 5317–5327. Computer Vision Founda-\ntion / IEEE.\nSong-Chun Zhu and David Mumford. 2006. A stochas-\ntic grammar of images. Found. Trends Comput.\nGraph. Vis., 2(4):259–362.\n8130\nA Agreement\nN.B. The interactions are formatted for readability. In the prompt, we provide the context and answer examples only for those\ninteractions where they change with respect to the previous interaction. ChatGPT repeats the context and answer sentences\nliterally at every interaction. For readability we have introduced ellipses, indicated with (...).\nA.1 Interaction 1\nI am going to ask you to solve a puzzle called BLM-AgrI. The language of the experiment is Italian. I will give you a list of\nsentences, that I will call the context, and I will also give you a set of sentences that I will call the answers. I will ask you to\nchoose among the answer sentences the sentence that could be the next sentence in the context list of sentences. I am asking you\nto give me the correct answer in Italian but also to describe in English step by step the hypotheses you are entertaining while you\nare solving the problem.\nContext\nIl computer col programma non funziona.\nI computer col programma non funzionano.\nIl computer coi programmi non funziona.\nI computer coi programmi non funzionano.\nIl computer col programma dell’esperimento non funziona.\nI computer col programma dell’esperimento non funzionano.\nIl computer coi programmi dell’esperimento non funziona.\nAnswers\nIl computer col programma e l’esperimento non funziona.\nI computer coi programmi dell’ esperimento non funzionano.\nIl computer col programma non funziona.\nIl computer coi programmi dell’ esperimento non funzionano.\nI computer col programma dell’ esperimento non funziona.\nI computer coi programmi degliesperimenti non funzionano.\nChatGPT\nTo solve the puzzle, I will analyze the given context and the set of answer sentences to identify the sentence that could be\nthe next one in the context. Here’s the step-by-step thought process:\nI start by examining the context sentences: (...) I observe that the context consistently mentions computer(s) and\nprogram(s), along with their functionality (funzionare or non funzionare). The addition of ”dell’esperimento” indicates\nthat the computers and programs are related to an experiment.\nMoving on to the answer sentences: (...) Comparing the answer sentences with the context, I need to find a sentence that\nfits logically and syntactically. It should mention the computer(s), program(s), and the experiment.\nThe answer sentence ”Il computer col programma e l’esperimento non funziona” doesn’t match the context because it uses\nthe singular form ”funziona” instead of the plural form ”funzionano.”\nThe answer sentence ”I computer coi programmi dell’esperimento non funzionano” is consistent with the context. It\nmaintains the plural form and correctly references the experiment.\nThe answer sentence ”Il computer col programma non funziona” matches the previous context sentence but doesn’t include\nthe experiment aspect.\nThe answer sentence ”Il computer coi programmi dell’esperimento non funzionano” aligns with the context by using the\nplural form and mentioning the experiment.\nThe answer sentence ”I computer col programma dell’esperimento non funziona” has a disagreement in number. ”I\ncomputer” is plural, while ”non funziona” is singular.\nThe answer sentence ”I computer coi programmi degli esperimenti non funzionano” incorrectly uses the singular form\n”non funziona” instead of the plural form ”non funzionano.”\nBased on this analysis, the answer sentence that could be the next in the context is ”I computer coi programmi\ndell’esperimento non funzionano.”\nCorrect answer in Italian: ”I computer coi programmi dell’esperimento non funzionano.”\n8131\nA.2 Interaction 2\nThis interaction is a minimal variant of interaction 1 to see if ChatGPT understands that attractors, the noun phrases intervening\nbetween the subject and the verb, can also be decreasing in number, depending on the structure of the matrix.\nI am going to ask you to solve a puzzle called BLM-AgrI.\nThe language of the experiment is Italian.\nI will give you a list of sentences, that I will call the context, and I will also give you a set of sentences that I will call the answers.\nI will ask you to choose among the answer sentences the sentence that could be the next sentence in the context list of sentences.\nI am asking you to give me the correct answer in Italian but also to describe in English step by step the hypotheses you are\nentertaining while you are solving the problem.\nContext\nIl computer col programma dell’esperimento non funziona.\nI computer col programma dell’esperimento non funzionano.\nIl computer coi programmi dell’esperimento non funziona.\nI computer coi programmi dell’ esperimento non funzionano.\nIl computer col programma non funziona.\nI computer col programma non funzionano.\nIl computer coi programmi non funziona.\nAnswers\nIl computer e i programmi non funzionano.\nI computer coi programmi non funzionano.\nIl computer col programma non funziona.\nIl computer coi programmi dell’esperimento non funzionano.\nI computer col programmadell’esperimento non funziona.\nI computer coi programmi degli esperimentinon funzionano.\nChatGPT\nTo solve the puzzle, I will analyze the given context and the set of answer sentences to identify the sentence that could be the\nnext one in the context. Here’s the step-by-step thought process:\nI start by examining the context sentences: (...)\nI observe that the context consistently mentions computer(s) and program(s), along with their functionality (funzionare or non\nfunzionare). The addition of ”dell’esperimento” indicates that the computers and programs are related to an experiment.\nMoving on to the answer sentences: (...)\nComparing the answer sentences with the context, I need to find a sentence that fits logically and syntactically. It should mention\nthe computer(s), program(s), and the experiment.\nThe answer sentence ”I computer e i programmi non funzionano” is grammatically correct and maintains the plural form for both\n”computer” and ”programmi.”\nThe answer sentence ”I computer coi programmi non funzionano” matches the context by using the correct form and maintaining\nthe plural form for both ”computer” and ”programmi.”\nThe answer sentence ”Il computer col programma non funzionano” has a disagreement in number. ”Il computer” is singular,\nwhile ”non funzionano” is plural.\nThe answer sentence ”Il computer coi programmi dell’esperimento non funzionano” is consistent with the context. It maintains\nthe plural form and correctly references the experiment.\nThe answer sentence ”I computer col programma dell’esperimento non funziona” has a disagreement in number. ”I computer” is\nplural, while ”non funziona” is singular.\nThe answer sentence ”I computer coi programmi degli esperimenti non funzionano” incorrectly uses the plural form ”degli\nesperimenti” instead of the singular form ”dell’esperimento” mentioned in the context.\nBased on this analysis, the answer sentence that could be the next in the context is ”I computer e i programmi non funzionano.”\nCorrect answer in Italian: ”I computer e i programmi non funzionano.”\n8132\nA.3 Interaction 3\nWe vary the words to see if ChatGPT can group objects and attributes in a more abstract way. Here, we vary all words in each\nsentence (type III data). We also number the context sentences to highlight the notion of list. We also change the language from\nItalian to English.\nI am going to ask you to solve a puzzle called BLM-AgrE. I will give you a list of sentences (numbered from 1 to 7), that I will\ncall the context, and I will also give you a set of sentences (identified by capital letters) that I will call the answers. I will ask you\nto choose among the answer sentences the sentence that could be the next sentence in the context list of sentences.\nI am asking you to give me the correct answer, but also to describe step by step the hypotheses you are entertaining while you are\nsolving the problem.\nContext\n1 The talk on history has started later than expected.\n2 Those responsible for the right will resign.\n3 The show with the paintings has met with great success.\n4 The threats of reforms worry the doctors.\n5 The bunch of keys of the cell sits on the shelf.\n6 The studies on the effect of the drug will appear soon.\n7 The threat of reforms in the school worries the doctors.\nAnswers\nA The tablecloths on the table and the console shine in the sun.\nB The friends of the owners of the villa were sleeping on the beach.\nC The lawyers of the murderers will come back.\nD The lawyers of the murderers of the village will come back.\nE The visit of the palace of the crafts is approaching.\nF The computers with the program of the experiment are broken.\nChatGPT\nTo solve the puzzle, I will analyze the given context sentences and the set of answer sentences to identify the sentence that could\nbe the next one in the context. Here’s the step-by-step thought process:\nI start by examining the context sentences: (...)\nI observe that the context sentences are unrelated to each other, discussing various topics such as a talk on history, responsible\nindividuals resigning, a successful art show, doctors’ concerns about reforms, keys on a shelf, drug studies, and the threat of\nreforms in the school.\nMoving on to the answer sentences: (...)\nConsidering the context, I look for an answer sentence that fits logically and thematically with the preceding sentences.\nThe answer sentence ”The tablecloths on the table and the console shine in the sun” does not relate to any of the previous context\nsentences or their topics.\nThe answer sentence ”The friends of the owners of the villa were sleeping on the beach” is unrelated to the context and introduces\na new scenario.\nThe answer sentence ”The lawyers of the murderers will come back” is unrelated to the context and introduces a criminal element\nnot previously mentioned.\nThe answer sentence ”The lawyers of the murderers of the village will come back” introduces a new scenario involving murderers\nand a village, which is not relevant to the context.\nThe answer sentence ”The visit of the palace of the crafts is approaching” is unrelated to the context and introduces a visit to a\npalace, which has not been mentioned before.\nThe answer sentence ”The computers with the program of the experiment are broken” is thematically consistent with the\nprevious context sentence mentioning the studies on the effect of a drug and the experiments. It introduces the concept of broken\ncomputers, which could be a logical continuation.\nBased on this analysis, the answer sentence that could be the next in the context is ”The computers with the program of the\nexperiment are broken.”\nCorrect answer: F) The computers with the program of the experiment are broken.\n8133\nA.4 Interaction 4\nLike interaction 3, we vary all the words to see if ChatGPT can group objects and attributes in a more abstract way. However,\nsince the previous interactions have shown that ChatGPT deals with the sentences based on topics and network of concepts and\ntries to solve the puzzle as a logical or semantic problem, we give it more information on the fact that it needs to focus on the\nsyntactic form of the sentences. So the instruction is slightly different, we no longer talk of puzzle, but of grammatical problem.\nThe context and answer sentences are the same as those in interaction 3.\nI am going to ask you to solve a grammatical problem called BLM-AgrE.\nI will give you a list of sentences (numbered from 1 to 7) , that I will call the context, and I will also give you a set of sentences\n(identified by capital letters) that I will call the answers.\nI will ask you to choose among the answer sentences the sentence that could be the next sentence in the context list of sentences.\nI am asking you to give me the correct answer, but also to describe step by step the hypotheses you are entertaining while you are\nsolving the problem.\nChatGPT\nTo solve the grammatical problem, I will analyze the given context sentences and the set of answer sentences to identify the\nsentence that could be the next one in the context. Here’s the step-by-step thought process:\nI start by examining the context sentences: (...)\nI observe that the context sentences are unrelated to each other, discussing various topics such as a talk on history, responsible\nindividuals resigning, a successful art show, doctors’ concerns about reforms, keys on a shelf, drug studies, and the threat of\nreforms in the school.\nMoving on to the answer sentences: (...)\nConsidering the grammatical structure of the context, I look for an answer sentence that could continue the pattern of ”The [noun\nphrase] [verb phrase].”\nThe answer sentence ”The tablecloths on the table and the console shine in the sun” does not fit the grammatical pattern of the\ncontext sentences.\nThe answer sentence ”The friends of the owners of the villa were sleeping on the beach” does not follow the grammatical\nstructure of the context.\nThe answer sentence ”The lawyers of the murderers will come back” does not match the grammatical pattern of the context.\nThe answer sentence ”The lawyers of the murderers of the village will come back” does not adhere to the grammatical structure\nof the context.\nThe answer sentence ”The visit of the palace of the crafts is approaching” does not conform to the grammatical pattern of the\ncontext.\nThe answer sentence ”The computers with the program of the experiment are broken” matches the grammatical structure of the\ncontext, which consists of ”The [noun phrase] [verb phrase].” It introduces the concept of broken computers, which could be a\nlogical continuation.\nBased on this analysis, the answer sentence that could be the next in the context is ”The computers with the program of the\nexperiment are broken.”\nCorrect answer: F) The computers with the program of the experiment are broken.\n8134\nA.5 Interaction 5\nThis is a continuation of interaction 4. We still no longer talk of puzzle but of grammar rule and try to give it more hints.\nThe answer is not correct but you are on the good path, can you try to solve the problem with a more complex structure for the\ncontext sentences?\nChatGPT\nApologies for the previous incorrect answer. Let’s approach the problem with a more complex structure for the context sentences.\nHere’s a revised step-by-step thought process:\nRe-examining the context sentences with a more complex structure: (...)\nAnalyzing the context sentences, I observe that they all follow a pattern of ”The [noun phrase] [verb phrase] [adverbial phrase].”\nMoving on to the answer sentences: (...)\nConsidering the revised grammatical structure of the context, I look for an answer sentence that adheres to the pattern of ”The\n[noun phrase] [verb phrase] [adverbial phrase].”\nThe answer sentence ”The tablecloths on the table and the console shine in the sun” matches the grammatical structure of the\ncontext and introduces the idea of shining in the sun, which can be seen as a continuation.\nThe answer sentence ”The friends of the owners of the villa were sleeping on the beach” does not align with the grammatical\nstructure of the context.\nThe answer sentence ”The lawyers of the murderers will come back” does not match the grammatical structure of the context.\nThe answer sentence ”The lawyers of the murderers of the village will come back” does not conform to the grammatical structure\nof the context.\nThe answer sentence ”The visit of the palace of the crafts is approaching” does not adhere to the grammatical pattern of the\ncontext.\nThe answer sentence ”The computers with the program of the experiment are broken” does not follow the revised grammatical\nstructure of the context.\nBased on this analysis, the answer sentence that could be the next in the context, considering the revised grammatical structure,\nis ”The tablecloths on the table and the console shine in the sun.”\nCorrect answer: A) The tablecloths on the table and the console shine in the sun.\nA.6 Interaction 6\nok, not quite there yet, let me tell you and see if you can discover the correct rules. The property you need to pay attention to is\nnumber agreement.\nChatGPT\nThank you for the additional clarification. Let’s consider number agreement as a key property to find the correct answer. Here’s\nthe revised step-by-step thought process:\nRevisiting the context sentences: (...)\nAnalyzing the context sentences, I notice that they all use the definite article ”The” followed by a noun phrase and a verb phrase.\nMoving on to the answer sentences: (...)\nConsidering the property of number agreement, I need to ensure that the noun phrase in the answer sentence matches the number\n(singular or plural) used in the context sentences.\nThe answer sentence ”The tablecloths on the table and the console shine in the sun” does not match the number agreement with\nthe singular noun phrases used in the context sentences. The noun phrase ”tablecloths on the table and the console” is plural,\nwhile the context sentences use singular noun phrases.\nThe answer sentence ”The friends of the owners of the villa were sleeping on the beach” also does not match the number\nagreement with the singular noun phrases used in the context sentences. The verb ”were” indicates a plural subject, but the\ncontext sentences use singular subjects.\nThe answer sentence ”The lawyers of the murderers will come back” does not match the number agreement with the singular\nnoun phrases used in the context sentences. The noun phrase ”lawyers of the murderers” is plural, while the context sentences\nuse singular subjects.\nThe answer sentence ”The lawyers of the murderers of the village will come back” also does not match the number agreement\nwith the singular noun phrases used in the context sentences. The noun phrase ”lawyers of the murderers of the village” is plural,\nwhile the context sentences use singular subjects.\nThe answer sentence ”The visit of the palace of the crafts is approaching” matches the number agreement with the singular\nnoun phrases used in the context sentences. The noun phrase ”visit of the palace of the crafts” is singular, matching the context\nsentences.\nThe answer sentence ”The computers with the program of the experiment are broken” matches the number agreement with the\nplural noun phrases used in the context sentences. The noun phrase ”computers with the program of the experiment” is plural,\nmatching the context sentences.\nBased on this analysis, considering the property of number agreement, the answer sentence that fits the context is ”The computers\nwith the program of the experiment are broken.”\nCorrect answer: F) The computers with the program of the experiment are broken.\n8135\nA.7 Interaction 7\nNot quite, you need to find the continuing sentence based on a pattern of number agreement.\nChatGPT\nApologies for the oversight. Let’s revisit the context and analyze the sentences while paying attention to number agreement as\nthe determining factor for finding the correct answer. Here’s the revised step-by-step thought process:\nRevisiting the context sentences: (...)\nAnalyzing the context sentences, I notice that the noun phrases in each sentence agree in number with the corresponding verb\nphrases. In other words, singular noun phrases are paired with singular verbs, and plural noun phrases are paired with plural\nverbs.\nMoving on to the answer sentences: (...)\nConsidering the property of number agreement, I need to find an answer sentence where the noun phrase agrees in number with\nthe verb phrase, similar to the pattern seen in the context sentences.\nAnswer sentences A, B, C, and D do not demonstrate number agreement with the context sentences.\nAnswer sentence E, ”The visit of the palace of the crafts is approaching,” maintains number agreement with the context sentences.\nThe noun phrase ”the visit of the palace of the crafts” is singular, matching the singular verb ”is approaching” used in the context\nsentences.\nAnswer sentence F, ”The computers with the program of the experiment are broken,” also demonstrates number agreement with\nthe context sentences. The noun phrase ”the computers with the program of the experiment” is plural, matching the plural verb\n”are broken” used in the context sentences.\nComparing the two remaining answer sentences, both E and F demonstrate number agreement with the context sentences.\nHowever, based on the context and the potential continuation of the sentences, it is more likely that the next sentence would\nrelate to the topic of the computers and the program.\nBased on this analysis, considering the pattern of number agreement and the context, the answer sentence that best fits the\ncontinuation is:\nCorrect answer: F) The computers with the program of the experiment are broken.\nA.8 Interaction 8\nLet me explain better. You need to find the continuing sentence based on a pattern of number agreement. The context gives you\na pattern within each sentence but also across all sentences, so that the continuation sentence continues the global pattern of\nagreement as well as obeying the sentence-internal pattern of agreement.\nChatGPT\nThank you for the clarification. I apologize for the misunderstanding. Let’s revisit the context and analyze the sentences while\nconsidering both the sentence-internal pattern of number agreement and the global pattern of agreement. Here’s the revised\nstep-by-step thought process:\nRevisiting the context sentences: (...)\nAnalyzing the context sentences, I observe the following patterns of number agreement:\nSentences 1, 3, 5, and 6 have singular noun phrases that agree with singular verbs. Sentences 2, 4, and 7 have plural noun phrases\nthat agree with plural verbs.\nMoving on to the answer sentences: (...)\nConsidering both the sentence-internal pattern of number agreement and the global pattern observed in the context sentences, I\nneed to find an answer sentence that continues the overall pattern of number agreement.\nAnswer sentences A, B, C, and D do not continue the global pattern of number agreement observed in the context sentences.\nAnswer sentence E, ”The visit of the palace of the crafts is approaching,” continues the sentence-internal pattern of number\nagreement by using a singular noun phrase and a singular verb. However, it does not continue the global pattern of plural noun\nphrases and plural verbs observed in the context sentences.\nAnswer sentence F, ”The computers with the program of the experiment are broken,” continues both the sentence-internal\npattern of number agreement (plural noun phrase with plural verb) and the global pattern of plural noun phrases and plural verbs\nobserved in the context sentences.\nConsidering the requirement to continue both the sentence-internal pattern and the global pattern of number agreement, answer\nsentence F aligns with the desired continuation.\nBased on this analysis, the answer sentence that follows the pattern of number agreement both within each sentence and across\nall sentences is:\nCorrect answer: F) The computers with the program of the experiment are broken.\n8136\nA.9 Interaction 9\nWe give indication that a grammatical pattern is to be found without saying which one. We switch to Italian, where gramamtical\nnumber is more salient morphologically.\nI am going to ask you to solve a grammatical problem called BLM-AgrI.\nI will give you a list of sentences (numbered from 1 to 7) , that I will call the context, and I will also give you a set of sentences\n(identified by capital letters) that I will call the answers. I will ask you to choose among the answer sentences the sentence that\ncould be the next sentence in the context list of sentences.\nYou need to find the continuing sentence based on a grammatical pattern. The context gives you a pattern within each sentence but\nalso across all sentences, so that the continuation sentence continues the global pattern as well as obeying the sentence-internal\npattern of agreement.\nI am asking you to give me the correct answer, but also to describe step by step the hypotheses you are entertaining while you are\nsolving the problem.\nContext\n1 La presentazione di storia comincia in ritardo.\n2 I responsabili della legge daranno le dimissioni.\n3 La mostra dei quadri ha incontrato grande successo.\n4 Le minaccie di riforme preoccupano i dottori.\n5 Il mazzo di chiavi della cantina pende dal gancio.\n6 Gli studi sugli effetti del farmaco appariranno presto.\n7 La frequenza di riforme nelle scuole preoccupa i dottori.\nAnswers\nA Le tovaglie sul tavolo e la credenza brillano al sole.\nB Gli amici dei proprietari della villa dormono sulla spiaggia.\nC Gli avvocati degli assassini torneranno.\nD Gli avvocati degli assassini del villaggio torneranno.\nE La visita al palazzo delle arti si avvicina.\nF I computer col programma dell’esperimento non funzionano.\nChat GPT\nTo solve the BLM-AgrI problem, I will carefully analyze the given context sentences and the provided answer options. I will\nconsider both the sentence-internal pattern of agreement and the global pattern across all sentences. Here is the step-by-step\nthought process:\nRevisiting the context sentences in Italian: (...)\nAnalyzing the context sentences, I observe the following patterns:\nSentences 1, 3, 5, and 6 have a singular noun phrase (La presentazione, La mostra, Il mazzo, Gli studi) paired with a singular\nverb phrase (comincia, ha incontrato, pende, appariranno).\nSentences 2, 4, and 7 have a plural noun phrase (I responsabili, Le minaccie, La frequenza) paired with a plural verb phrase\n(daranno, preoccupano).\nMoving on to the answer sentences: (...)\nConsidering both the sentence-internal pattern of agreement and the global pattern observed in the context sentences, I need to\nfind an answer sentence that continues both the sentence-internal and global patterns.\nAnswer sentences A, B, C, D, and E do not continue the global pattern observed in the context sentences.\nAnswer sentence F, ”I computer col programma dell’esperimento non funzionano,” continues the sentence-internal pattern of\nagreement (plural noun phrase with plural verb) observed in the context sentences. It also maintains the global pattern of plural\nnoun phrases (I computer col programma dell’esperimento) and plural verbs (non funzionano).\nConsidering the requirement to continue both the sentence-internal and global patterns of agreement, answer sentence F aligns\nwith the desired continuation.\nBased on this analysis, the answer sentence that follows the grammatical pattern both within each sentence and across all\nsentences is:\nCorrect answer: F) I computer col programma dell’esperimento non funzionano.\n8137\nA.10 Interaction 10\nGood job, but you made a mistake and then the conclusion was consequently wrong. If I tell you that ’Gli studi’ is plural can you\nretry?\nChatGPT\nApologies for the mistake. Thank you for pointing out that ”Gli studi” in sentence 6 is indeed plural. Let me revise my analysis\nbased on that information:\nRevisiting the context sentences in Italian: (...)\nAnalyzing the context sentences, I observe the following patterns:\nSentences 1, 3, 5, and 7 have a singular noun phrase paired with a singular verb phrase.\nSentences 2, 4, and 6 have a plural noun phrase paired with a plural verb phrase.\nMoving on to the answer sentences: (...)\nConsidering the patterns observed in the context sentences and the requirement to continue both the sentence-internal and global\npatterns of agreement:\nAnswer sentences A, B, C, D, and E do not continue the global pattern of number agreement observed in the context sentences.\nAnswer sentence F, ”I computer col programma dell’esperimento non funzionano,” aligns with the sentence-internal pattern\n(plural noun phrase with plural verb) observed in the context sentences. However, it does not follow the global pattern of number\nagreement because all previous sentences have a singular subject paired with a singular verb phrase.\nTherefore, considering the updated information, none of the answer sentences provided (A, B, C, D, E, F) continue the\ngrammatical pattern both within each sentence and across all sentences.\nApologies for the confusion in the previous response.\nA.11 Interaction 11\nNot quite, let me help you. The correct answer is B. Gli amici dei proprietari della villa dormono sulla spiaggia.\nKeeping in mind the information I gave you before about sentence-internal patterns and global patterns, can you explain to me\nwhy?\nChatGPT\nApologies for the confusion. Let me reevaluate the context and analyze the patterns to explain why the correct answer is B. ”Gli\namici dei proprietari della villa dormono sulla spiaggia.”\nRevisiting the context sentences: (...)\nAnalyzing the patterns:\nIn sentences 1, 3, 5, and 7, we observe a singular noun phrase paired with a singular verb phrase. In sentences 2, 4, and 6, we\nobserve a plural noun phrase paired with a plural verb phrase. Considering the answer sentences: (...)\nThe correct answer: Answer sentence B, ”Gli amici dei proprietari della villa dormono sulla spiaggia,” aligns with both the\nsentence-internal pattern and the global pattern of number agreement observed in the context sentences.\nSentence 2 in the context has a plural subject ”I responsabili della legge” paired with a plural verb phrase ”daranno le dimissioni.”\nAnswer sentence B follows the same pattern with a plural subject ”Gli amici dei proprietari della villa” paired with a plural verb\nphrase ”dormono sulla spiaggia.”\nTherefore, based on the patterns observed, sentence B continues the grammatical pattern within each sentence and maintains the\nglobal pattern of number agreement, making it the correct answer.\nA.12 Interaction 12\nCan you tell me more explicitly what is the global pattern you have observed and why sentence B is the right continuation\naccording to this pattern?\nChatGPT\nCertainly! Upon further analysis, the global pattern observed in the context sentences is the agreement of the subject noun\nphrases with the corresponding verb phrases in terms of number (singular or plural).\nThe global pattern can be summarized as follows:\nSentences 1, 3, 5, and 7 have singular subject noun phrases paired with singular verb phrases.\nSentences 2, 4, and 6 have plural subject noun phrases paired with plural verb phrases.\nIn the given context, the sentence ”Gli studi sugli effetti del farmaco appariranno presto” (Sentence 6) establishes the pattern of a\nplural subject (”Gli studi”) paired with a plural verb phrase (”appariranno presto”).\nNow let’s examine the provided answer sentences and see which one aligns with this global pattern.\nAnswer sentence B, ”Gli amici dei proprietari della villa dormono sulla spiaggia,” continues the global pattern. It consists of a\nplural subject noun phrase (”Gli amici dei proprietari della villa”) paired with a plural verb phrase (”dormono sulla spiaggia”).\nThis choice maintains the agreement of the subject noun phrase and the verb phrase, as seen in the context sentence 6, thus\nadhering to the global pattern observed.\nTherefore, based on the global pattern of number agreement, sentence B is the correct continuation in the context list of sentences.\n8138\nA.13 Interaction 13\nAccording to your reasoning also C and D should be correct because they also have plural subject matching plural verb. So why\nare they not the right answer?\nChatGPT\nYou’re absolutely correct, and I apologize for the oversight. Based on the global pattern of number agreement, both answer\nsentences C and D, ”Gli avvocati degli assassini torneranno” and ”Gli avvocati degli assassini del villaggio torneranno,” match\nthe pattern of a plural subject (”Gli avvocati degli assassini”) paired with a plural verb phrase (”torneranno”). Therefore, they\nalso satisfy the global pattern observed in the context sentences.\nAs a result, considering the information provided, answer sentences B, C, and D could all be valid continuations based on the\nglobal pattern of number agreement. It seems there might not be a unique correct answer solely based on the global pattern.\nTo determine the specific correct answer, it would be helpful to consider additional linguistic factors or constraints that might be\npresent in the puzzle. Without further information or specific instructions, it is difficult to definitively determine the correct\nanswer solely based on the global pattern of number agreement.\nA.14 Interaction 14\nThere is only one correct answer and that is B, so you correctly say, C and D might be excluded by other patterns. Can you see\nwhat they are?\nChatGPT\nApologies for the confusion earlier. Upon closer examination, there are indeed other linguistic patterns present in the context\nsentences that help us exclude answer sentences C and D as the correct continuation. Let’s analyze these patterns:\nSentence-Internal Pattern: Each sentence in the context exhibits a consistent sentence-internal pattern of number agreement\nbetween the subject noun phrase and the verb phrase. In sentences 1, 3, 5, and 7, we observe singular subject noun phrases paired\nwith singular verb phrases. In sentences 2, 4, and 6, we see plural subject noun phrases paired with plural verb phrases.\nSentence-External Pattern: The context sentences also form a broader sentence-external pattern. We notice that the subject noun\nphrases in the context sentences refer to different entities or groups, each with their own contextually specific characteristics. For\nexample, in sentence 1, ”La presentazione di storia” refers to a singular event (the talk on history). In sentence 2, ”I responsabili\ndella legge” refers to a group of individuals responsible for the law.\nApplying these patterns, we can see that answer sentences C and D, ”Gli avvocati degli assassini torneranno” and ”Gli avvocati\ndegli assassini del villaggio torneranno,” do not fit the broader sentence-external pattern established in the context. The subject\nnoun phrases in these answer sentences refer to a specific group (the lawyers of the murderers or the lawyers of the murderers\nof the village). However, this specific group is not a consistent theme or contextually relevant entity throughout the previous\ncontext sentences. Therefore, based on the sentence-external pattern, answer sentences C and D can be excluded as the correct\ncontinuation.\nIn contrast, answer sentence B, ”Gli amici dei proprietari della villa dormono sulla spiaggia,” fits both the sentence-internal\npattern of number agreement (plural subject paired with plural verb) and the broader sentence-external pattern. The subject noun\nphrase refers to a group of individuals (the friends of the owners of the villa), which aligns with the contextual theme of different\nentities being discussed in the previous sentences.\nConsidering the sentence-internal and sentence-external patterns, answer sentence B is the correct continuation that maintains\nconsistency and relevance within the given context.\n8139\nA.15 Interaction 15\nThere is only one correct answer and that is B, so you correctly say, C and D might be excluded by other patterns. Focussing\nexclusively on patterns of agreement, can you see what they are?\nChatGPT\nI apologize for the confusion earlier. Focusing exclusively on patterns of agreement, let’s analyze the sentences again to identify\nthe specific patterns at play:\nLa presentazione di storia comincia in ritardo. (Singular subject, singular verb)\nI responsabili della legge daranno le dimissioni. (Plural subject, plural verb)\nLa mostra dei quadri ha incontrato grande successo. (Singular subject, singular verb)\nLe minacce di riforme preoccupano i dottori. (Plural subject, plural verb)\nIl mazzo di chiavi della cantina pende dal gancio. (Singular subject, singular verb)\nGli studi sugli effetti del farmaco appariranno presto. (Plural subject, plural verb)\nLa frequenza di riforme nelle scuole preoccupa i dottori. (Plural subject, plural verb)\nBased on these patterns of agreement, we observe the following consistent rules:\nSingular subjects are paired with singular verbs.\nPlural subjects are paired with plural verbs.\nApplying these patterns to the answer sentences, we find that answer B, ”Gli amici dei proprietari della villa dormono sulla\nspiaggia,” adheres to the pattern of agreement. The subject ”Gli amici” (plural) is appropriately matched with the verb ”dormono”\n(plural), maintaining the pattern observed in the context sentences.\nIn contrast, answer sentences C and D, ”Gli avvocati degli assassini torneranno” and ”Gli avvocati degli assassini del villaggio\ntorneranno,” do not conform to the pattern of agreement. Although they have plural subjects (”Gli avvocati”), the verb\n”torneranno” (plural) does not match with the singular noun phrases (”degli assassini” and ”del villaggio”).\nTherefore, based solely on the patterns of agreement, answer sentence B is the correct continuation as it aligns with the consistent\npattern of number agreement observed in the context sentences.\nA.16 Interaction 16\nBoth C and D follow the rule you mention so why are you saying they do not follwo the rule?\nChatGPT\nApologies for the confusion in my previous response. You are correct that both options C and D follow the pattern of plural\nsubject-verb agreement. Therefore, they are potential valid answers based on the observed agreement rule.\nTo select the correct answer between C and D, we need to consider additional patterns or constraints within the context sentences.\nSince I do not have access to the specific global patterns or constraints you mentioned, I am unable to provide a definitive answer\nbased solely on grammatical agreement.\nIf there are other patterns or constraints related to the context sentences that can help determine the correct answer, please provide\nfurther information, and I’ll be glad to reassess and assist you accordingly.\nA.17 Interaction 17\nThe other constraints are also related to number and agreement, can you see the patterns that eliminate C and D?\nChatGPT\nApologies for the oversight. Let’s reassess the context and the remaining options (C and D) considering other patterns related to\nnumber and agreement.\nContext: (...)\nAnswers: C. Gli avvocati degli assassini torneranno.\nD. Gli avvocati degli assassini del villaggio torneranno.\nTo identify the patterns that eliminate C and D, we need to examine the agreement between the subjects and the verbs in each\noption.\nIn option C, ”Gli avvocati degli assassini torneranno” (The lawyers of the murderers will come back), the subject ”Gli avvocati”\n(The lawyers) is plural, and the verb ”torneranno” (will come back) agrees with the plural subject.\nIn option D, ”Gli avvocati degli assassini del villaggio torneranno” (The lawyers of the murderers of the village will come back),\nthe subject ”Gli avvocati” (The lawyers) is plural, and the verb ”torneranno” (will come back) also agrees with the plural subject.\nBased on the information provided, both options C and D seem to follow the pattern of number agreement within the sentences.\nHowever, if there are additional patterns or constraints related to number and agreement that apply to the context sentences as a\nwhole, please provide further details so that I can reassess and assist you more accurately.\n8140\nB Causatives\nN.B. The interactions are formatted for readability. In the prompt, we provide the context and answer examples only for those\ninteractions where they change with respect to the previous interaction.\nB.1 Interaction 1\nI am going to ask you to solve a grammatical problem called BLM-CausE. I will give you a list of English sentences (numbered\nfrom 1 to 7), that I will call the context, and I will also give you a set of English sentences (identified by capital letters) that I will\ncall the answers. I will ask you to choose among the answer sentences the one sentence that could be the next sentence in the\ncontext list of sentences. The sentences have been generated in a rule-based manner.\nI am asking you to give me the correct answer, but also to describe step by step the hypotheses you are entertaining while you are\nsolving the problem.\nContext\n1 The boy opened the door voluntarily.\n2 The door opened suddenly.\n3 The door was closed.\n4 The door is open.\n5 The cook melted the butter voluntarily.\n6 The butter melted slowly.\n7 The butter was hard.\nAnswers\nA The butter is melted.\nB The boy is open.\nC The door was open.\nD The cook is melted.\nE The butter was melted.\nChatGPT\nTo solve the BLM-CausE problem, we need to analyze the given context sentences and the set of answer sentences to determine\nthe most appropriate continuation for the context. Let’s go through the process step by step:\nIdentify the relevant elements:\nIn this context, we have two main elements: ”the door” and ”the butter.” We need to observe the causality between these elements\nand their states.\nAnalyze the context:\nSentence 1: The boy opened the door voluntarily. This sentence establishes that the boy was responsible for opening the door.\nSentence 2: The door opened suddenly. This sentence suggests that the door opened on its own accord, without external agency.\nSentence 3: The door was closed. This sentence indicates the initial state of the door, which was closed.\nSentence 4: The door is open. This sentence reveals the current state of the door, which is open.\nSentence 5: The cook melted the butter voluntarily. This sentence states that the cook caused the butter to melt.\nSentence 6: The butter melted slowly. This sentence describes the process of the butter melting.\nSentence 7: The butter was hard. This sentence states the initial state of the butter, which was hard.\nConsider the answer choices: Now let’s analyze each answer choice in relation to the context:\nAnswer A: The butter is melted. This answer suggests that the current state of the butter is melted. However, it doesn’t directly\nrelate to the given context. We don’t have any information about the current state of the butter.\nAnswer B: The boy is open. This answer doesn’t make logical sense as it equates the boy with being open, which is unrelated to\nthe context.\nAnswer C: The door was open. This answer corresponds to the progression of the door’s state as mentioned in the context. It\nfollows the pattern established in sentences 2 and 3, where the door opens suddenly after being closed. This seems to be a\nreasonable continuation.\nAnswer D: The cook is melted. This answer equates the cook with being melted, which doesn’t make sense in the context.\nAnswer E: The butter was melted.\nThis answer corresponds to the progression of the butter’s state as mentioned in the context. It follows the pattern established in\nsentences 5 and 6, where the cook causes the butter to melt slowly. This also seems like a plausible continuation.\nFinal decision: Comparing answers C and E, both seem to be reasonable continuations based on the given context. However,\nsince the initial prompt requests choosing only one answer, we need to make a decision. Considering the sequential pattern of\nevents in the context, it seems more likely that the door’s state would be the next relevant topic. Therefore, the correct answer is\nC: The door was open.\nIn summary, the step-by-step analysis led us to select answer C: The door was open as the most appropriate continuation of the\ngiven context.\n8141\nB.2 Interaction 2\nI am going to ask you to solve a grammatical problem called BLM-CausE. I will give you a list of English sentences (numbered\nfrom 1 to 7) , that I will call the context, and I will also give you a set of English sentences (identified by capital letters) that I\nwill call the answers. I will ask you to choose among the answer sentences the one sentence that could be the next sentence in\nthe context list of sentences. The sentences have been generated in a rule-based manner and follow both internal rules and a\nglobal patterns that runs across all sentences, hence the notion of sequence.\nI am asking you to give me the correct answer, but also to describe step by step the hypotheses you are entertaining while you are\nsolving the problem.\nTo solve the BLM-CausE problem with the given context and answer choices, let’s analyze the information step by step:\nIdentify the relevant elements: The relevant elements in this context are ”the boy,” ”the door,” ”the cook,” and ”the butter.”\nAnalyze the context:\nSentence 1: The boy opened the door voluntarily. This sentence establishes that the boy voluntarily performed the action of\nopening the door.\nSentence 2: The door opened suddenly. This sentence describes the door’s action of opening, seemingly without external agency.\nSentence 3: The door was closed. This sentence provides the initial state of the door, which was closed.\nSentence 4: The door is open. This sentence indicates the current state of the door, which is open.\nSentence 5: The cook melted the butter voluntarily. This sentence states that the cook caused the butter to melt through their\nvoluntary action.\nSentence 6: The butter melted slowly. This sentence describes the process of the butter melting, indicating the action happening\nover time.\nSentence 7: The butter was hard. This sentence represents the initial state of the butter, which was hard.\nConsider the answer choices:\nLet’s analyze each answer choice in relation to the context:\nAnswer A: The butter is melted. This answer suggests that the current state of the butter is melted. However, it doesn’t directly\nrelate to the given context. We don’t have any information about the current state of the butter.\nAnswer B: The boy is open. This answer doesn’t make logical sense as it equates the boy with being open, which is unrelated to\nthe context.\nAnswer C: The door was open. This answer corresponds to the logical progression of events in the context. It follows the pattern\nestablished in sentences 2 and 3, where the door opens suddenly after being closed. This seems to be a reasonable continuation.\nAnswer D: The cook is melted. This answer equates the cook with being melted, which doesn’t make sense in the context.\nAnswer E: The butter was melted. This answer corresponds to the progression of events in the context. It follows the pattern\nestablished in sentences 5 and 6, where the cook causes the butter to melt slowly. This also seems like a plausible continuation.\nFinal decision: Comparing answers C and E, both could be reasonable continuations based on the given context. However,\nconsidering the global pattern and the notion of sequence mentioned in the problem description, it seems more likely that the\nnext sentence would continue the discussion about the door’s state. Therefore, the correct answer is C: The door was open.\nIn summary, by following the step-by-step analysis, we have determined that answer C: The door was open is the most appropriate\ncontinuation of the given context.\n8142\nB.3 Interaction 3\nHere we stop the generation as it seems to be applying the same reasoning and could be using the translation.\nI am going to ask you to solve a grammatical problem called BLM-CausI. I will give you a list of Italian sentences (numbered\nfrom 1 to 7) , that I will call the context, and I will also give you a set of Italian sentences (identified by capital letters) that I will\ncall the answers. I will ask you to choose among the answer sentences the one sentence that could be the next sentence in the\ncontext list of sentences. The sentences have been generated in a rule-based manner and follow both internal rules and a global\npatterns that runs across all sentences, hence the notion of sequence.\nI am asking you to give me the correct answer, but also to describe step by step the hypotheses you are entertaining while you are\nsolving the problem.\nContext\n1 Il ragazzo apre la porta volontariamente.\n2 La porta si apre di colpo.\n3 La porta era chiusa.\n4 La porta e’ aperta.\n5 Il cuoco scioglie il burro volontariamente.\n6 Il burro si scioglie lentamente.\n7 Il burro era duro.\nAnswers\nA Il burro e’ sciolto.\nB Il ragazzo e’ aperto.\nC La porta era aperta.\nD il cuoco e’ sciolto.\nE Il burro era sciolto.\nTo solve the BLM-CausI problem with the given context and answer choices in Italian, let’s analyze the information step by step:\nIdentify the relevant elements: The relevant elements in this context are ”il ragazzo” (the boy), ”la porta” (the door), ”il cuoco”\n(the cook), and ”il burro” (the butter).\nAnalyze the context:\nSentence 1: Il ragazzo apre la porta volontariamente. (The boy opens the door voluntarily.) This sentence establishes that the boy\nvoluntarily performs the action of opening the door.\nSentence 2: La porta si apre di colpo. (The door opens suddenly.) This sentence describes the door’s action of opening, seemingly\nwithout external agency.\nSentence 3: La porta era chiusa. (The door was closed.) This sentence provides the initial state of the door, which was closed.\nSentence 4: La porta e’ aperta. (The door is open.) This sentence indicates the current state of the door, which is open.\nSentence 5: Il cuoco scioglie il burro volontariamente. (The cook melts the butter voluntarily.) This sentence states that the cook\ncauses the butter to melt through their voluntary action.\nSentence 6: Il burro si scioglie lentamente. (The butter melts slowly.) This sentence describes the process of the butter melting,\nindicating the action happening over time.\nSentence 7: Il burro era duro. (The butter was hard.) This sentence represents the initial state of the butter, which was hard.\nConsider the answer choices:\nLet’s analyze each answer choice in relation to the context:\nAnswer A: Il burro e’ sciolto. (The butter is melted.) This answer suggests that the current state of the butter is melted. However,\nit doesn’t directly relate to the given context. We don’t have any information about the current state of the butter.\nAnswer B: Il ragazzo e’ aperto. (The boy is open.) This answer doesn’t make logical sense as it equates the boy with being open,\nwhich is unrelated to the context.\nAnswer C: La porta era aperta. (The door was open.) This answer corresponds to the logical progression of events in the context.\nIt follows the pattern established in sentences 2 and 3, where the door opens suddenly after being closed. This seems to be a\nreasonable continuation.\nAnswer D: Il cuoco e’ sciolto. (The cook is melted.)\n8143\nB.4 Interaction 4\nHere we explicitly instruct ChatGPT to use Italian. The answer is in Italian, but on the one hand it is an exact translation of the\nEnglish, and secondly in one case one phrase it is not good Italian ’agenzia esterna’, but a false friend translation of ’external\nagency’.\nI am going to ask you to solve a grammatical problem called BLM-CausI. I will give you a list of Italian sentences (numbered\nfrom 1 to 7) , that I will call the context, and I will also give you a set of Italian sentences (identified by capital letters) that I will\ncall the answers. I will ask you to choose among the answer sentences the one sentence that could be the next sentence in the\ncontext list of sentences. The sentences have been generated in a rule-based manner and follow both internal rules and a global\npatterns that runs across all sentences, hence the notion of sequence.\nI am asking you to give me the correct answer, but also to describe step by step in Italian the hypotheses you are entertaining\nwhile you are solving the problem. You are not allowed to translate the sentences into English to solve the problem.\n(...)\nPer risolvere il problema BLM-CausI con il contesto e le scelte di risposta fornite in italiano, analizziamo le informazioni passo\ndopo passo:\nIdentificazione degli elementi rilevanti: Gli elementi rilevanti in questo contesto sono ”il ragazzo”, ”la porta”, ”il cuoco” e ”il\nburro”.\nAnalisi del contesto:\nFrase 1: Il ragazzo apre la porta volontariamente. Questa frase stabilisce che il ragazzo apre volontariamente la porta.\nFrase 2: La porta si apre di colpo. Questa frase descrive l’azione della porta di aprirsi improvvisamente, senza un’agenzia\nesterna.\nFrase 3: La porta era chiusa. Questa frase fornisce lo stato iniziale della porta, che era chiusa.\nFrase 4: La porta `e aperta. Questa frase indica lo stato attuale della porta, che `e aperta.\nFrase 5: Il cuoco scioglie il burro volontariamente. Questa frase afferma che il cuoco fa sciogliere il burro attraverso un’azione\nvolontaria.\nFrase 6: Il burro si scioglie lentamente. Questa frase descrive il processo di scioglimento del burro, indicando che l’azione\navviene nel tempo.\nFrase 7: Il burro era duro. Questa frase rappresenta lo stato iniziale del burro, che era duro.\nConsiderazione delle opzioni di risposta:\nAnalizziamo ogni opzione di risposta in relazione al contesto:\nRisposta A: Il burro `e sciolto. Questa risposta suggerisce che lo stato attuale del burro `e sciolto. Tuttavia, non `e direttamente\ncorrelato al contesto fornito. Non abbiamo informazioni sullo stato attuale del burro.\nRisposta B: Il ragazzo `e aperto. Questa risposta non ha senso logico in quanto equipara il ragazzo a essere aperto, cosa non\ncorrelata al contesto.\nRisposta C: La porta era aperta. Questa risposta corrisponde alla progressione logica degli eventi nel contesto. Segue il pattern\nstabilito nelle frasi 2 e 3, dove la porta si apre improvvisamente dopo essere stata chiusa. Questa sembra essere una continuazione\nragionevole.\nRisposta D: Il cuoco `e sciolto. Questa risposta equipara il cuoco a essere sciolto, cosa che non ha senso nel contesto.\nRisposta E: Il burro era sciolto. Questa risposta corrisponde alla progressione degli eventi nel contesto. Segue il pattern stabilito\nnelle frasi 5 e 6, dove il cuoco fa sciogliere il burro lentamente. Anche questa sembra una continuazione plausibile.\nDecisione finale:\nConfrontando le risposte C ed E, entrambe potrebbero essere continuazioni ragionevoli basate sul contesto fornito. Tuttavia,\nconsiderando il pattern globale e la nozione di sequenza menzionata nella descrizione del problema, sembra pi `u probabile che la\nfrase successiva continui a parlare dello stato della porta. Pertanto, la risposta corretta `e C: La porta era aperta.\nIn sintesi, seguendo l’analisi passo dopo passo, abbiamo determinato che la risposta corretta `e C: La porta era aperta, come\ncontinuazione pi`u appropriata del contesto fornito.\n8144\nB.5 Interaction 5\nHere we explicitly instruct ChatGPT in Italian (with a translation of the previous one).\nTi chieder`o di risolvere un quesito grammaticale chiamato BLM-CausI. Ti fornir`o una lista di frasi in italiano (numerata da 1 a\n7), che chiameremo contesto, e ti dar`o anche un insieme di frasi in italiano (identificate da lettere maiuscole), che chiameremo\nrisposte. Ti chieder`o di scegliere tra le frasi di risposta quella che potrebbe essere la prossima frase nella lista del contesto. Le\nfrasi sono state generate in base a regole e seguono sia regole interne che modelli globali che si applicano a tutte le frasi, da qui\nla nozione di sequenza.\nTi chiedo di darmi la risposta corretta, ma anche di descrivere passo dopo passo, in italiano, le ipotesi che stai considerando\ndurante la risoluzione del problema. Non ti `e consentito tradurre le frasi in inglese per risolvere il problema.\n(...)\nPer risolvere il problema BLM-CausI, analizziamo passo dopo passo le informazioni fornite:\nIdentificazione degli elementi rilevanti: Gli elementi rilevanti in questo contesto sono ”il ragazzo”, ”la porta”, ”il cuoco” e ”il\nburro”.\nAnalisi del contesto:\nFrase 1: Il ragazzo apre la porta volontariamente. Questa frase ci indica che il ragazzo apre la porta in modo volontario.\nFrase 2: La porta si apre di colpo. Questa frase descrive l’azione della porta che si apre improvvisamente, senza un’azione\nesterna.\nFrase 3: La porta era chiusa. Questa frase ci informa dello stato iniziale della porta, che era chiusa.\nFrase 4: La porta `e aperta. Questa frase indica lo stato attuale della porta, che `e aperta.\nFrase 5: Il cuoco scioglie il burro volontariamente. Questa frase afferma che il cuoco fa sciogliere il burro attraverso un’azione\nvolontaria.\nFrase 6: Il burro si scioglie lentamente. Questa frase descrive il processo di scioglimento del burro, indicando che avviene\ngradualmente nel tempo.\nFrase 7: Il burro era duro. Questa frase rappresenta lo stato iniziale del burro, che era duro.\nConsiderazione delle opzioni di risposta:\nAnalizziamo ogni opzione di risposta in relazione al contesto:\nRisposta A: Il burro `e sciolto. Questa risposta suggerisce che il burro `e attualmente sciolto, ma non abbiamo informazioni\nspecifiche sullo stato attuale del burro nel contesto.\nRisposta B: Il ragazzo `e aperto. Questa risposta non ha senso logico, in quanto ”aperto” si riferisce a uno stato fisico che non pu `o\nessere applicato a una persona come il ragazzo.\nRisposta C: La porta era aperta. Questa risposta segue la logica del contesto, in cui la porta si apre di colpo dopo essere stata\nchiusa. Quindi, `e una continuazione plausibile.\nRisposta D: Il cuoco `e sciolto. Questa risposta non ha senso logico, in quanto ”sciolto” si riferisce a uno stato fisico che non pu `o\nessere applicato al cuoco.\nRisposta E: Il burro era sciolto. Questa risposta corrisponde alla progressione logica degli eventi nel contesto. Dopo che il cuoco\nha sciolto il burro volontariamente, il burro si scioglie lentamente. Quindi, questa `e una continuazione coerente.\nDecisione finale:\nConfrontando le risposte C ed E, entrambe sembrano essere continuazioni plausibili basate sul contesto fornito. Tuttavia,\nconsiderando il pattern globale e la nozione di sequenza menzionati nella descrizione del problema, sembra pi `u probabile che la\nfrase successiva si riferisca allo stato della porta. Pertanto, la risposta corretta `e C: La porta era aperta.\nIn sintesi, seguendo l’analisi passo dopo passo, abbiamo determinato che la risposta corretta `e C: La porta era aperta, come\ncontinuazione pi`u appropriata del contesto fornito.\n8145\nC Sequence of Tenses\nN.B. The interactions are formatted for readability. In the prompt, we provide the context and answer examples only for those\ninteractions where they change with respect to the previous interaction. ChatGPT repeats the context and answer sentences\nliterally at every interaction. For readability we have introduced ellipses, indicated with (...).\nC.1 Interaction 1\nI am going to ask you to solve a grammatical problem called BLM-ConsecutioI. I will give you a list of Italian sentences\n(numbered from 1 to 7), that I will call the context, and I will also give you a set of Italian sentences (identified by capital letters)\nthat I will call the answers. I will ask you to choose among the answer sentences the one sentence that could be the next sentence\nin the context list of sentences. The sentences have been generated in a rule-based manner.\nI am asking you to give me the correct answer, but also to describe step by step the hypotheses you are entertaining while you are\nsolving the problem.\nContext\n1 Se fossi ricco, allora sarei felice.\n2 Se fossero buoni, allora non sarebbero ricchi.\n3 Se fosti stata ricca, allora non saresti stata felice.\n4 Se foste state buone, allora sareste state ricche.\n5 Se sarai bravo, allora avrai un gelato.\n6 Se sarete state brave, allora avrete un gelato.\n7 Se sarai stato buono, allora avrai un gelato.\nAnswers\nA Se fosti stata buona, allora avresti avuto un gelato.\nB Se fosti stata buona, allora avrai un gelato.\nC Se fosti stata buona, allora avranno avuto un gelato.\nD Se fosti stata buona, allora sarebbero stati ricchi.\nE Se fosti stata buona, allora fossero stati felici.\nChatGPT\nTo solve the grammatical problem, BLM-ConsecutioI, we need to find the sentence from the given answers that could\nlogically follow the context sentences. Let’s analyze the context and go through the hypotheses step by step.\nContext: (...)\nLet’s analyze each answer sentence and see if it fits the context:\nA. (..) This sentence is a grammatically correct conditional statement, but it doesn’t fit the context. The previous sentences\ndiscuss the condition of being rich, and this answer sentence introduces a different topic about having an ice cream.\nB. (..) This sentence is a grammatically correct conditional statement and it aligns with the previous context sentences. It\ncontinues the pattern of discussing the condition of being good and the consequence of having an ice cream.\nC. (..) This sentence doesn’t fit the context. It introduces a different subject ”they” and implies that someone other than the\nperson being addressed would have had an ice cream.\nD. (..) This sentence doesn’t fit the context. It introduces a different topic of being rich, which is not relevant to the\nprevious context sentences.\nE. (..) This sentence doesn’t fit the context. It introduces a different topic of being happy, which is not relevant to the\nprevious context sentences.\nBased on the analysis, the correct answer is B. Se fosti stata buona, allora avrai un gelato. (If you had been good, then you\nwill have an ice cream.) This sentence continues the pattern of discussing the condition of being good and the consequence\nof having an ice cream, which is consistent with the context sentences.\n8146\nC.2 Interaction 2\nI am going to ask you to solve a grammatical problem called BLM-ConsecutioI. I will give you a list of Italian sentences\n(numbered from 1 to 7), that I will call the context, and I will also give you a set of Italian sentences (identified by capital letters)\nthat I will call the answers. I will ask you to choose among the answer sentences the one sentence that could be the next sentence\nin the context list of sentences. The sentences have been generated in a rule-based manner.\nI am asking you to give me the correct answer, but also to describe step by step the hypotheses you are entertaining while you are\nsolving the problem. I am also giving you a hint: This is a grammatical problem, not a logical problem. The solution does not lie\nin finding a logical continuation, but a continuation that follows the underlying grammatical pattern.\nChatGPT\nTo solve the grammatical problem, BLM-ConsecutioI, we need to find the sentence from the given answers that could\ngrammatically follow the context sentences. Let’s analyze the context and go through the hypotheses step by step,\nconsidering the grammatical pattern.\nContext: (...)\nNow let’s analyze each answer sentence and see if it fits the grammatical pattern:\nA. (...) This sentence introduces a correct grammatical pattern and aligns with the previous context sentences. It maintains\nthe conditional structure, discussing the consequence of having had an ice cream based on being good.\nB. (...) This sentence also introduces a correct grammatical pattern and aligns with the previous context sentences. It\nmaintains the conditional structure, discussing the consequence of having an ice cream based on being good.\nC. (...) This sentence introduces a different subject ”they” and implies that someone other than the person being addressed\nwould have had an ice cream. It doesn’t fit the grammatical pattern established in the context.\nD. (...) This sentence introduces a different topic of being rich, which is not relevant to the previous context sentences. It\ndoesn’t fit the grammatical pattern established in the context.\nE. (...) This sentence introduces a different topic of being happy, which is not relevant to the previous context sentences. It\ndoesn’t fit the grammatical pattern established in the context.\nBased on the analysis, the correct answer is A. Se fosti stata buona, allora avresti avuto un gelato. (If you (feminine\nsingular) had been good, then you (feminine singular) would have had an ice cream.) This sentence maintains the\ngrammatical pattern, discussing the consequence of having had an ice cream based on being good, which is consistent with\nthe context sentences.\nC.3 Interaction 3\nIf you had to describe in your own words the grammatical rule you have applied to find the solution what would you say?\nChatGPT\nThe grammatical rule applied to find the solution is the use of conditional sentences in Italian, specifically the ”consecutio\ntemporum” or sequence of tenses. In this context, the conditional sentences follow a consistent pattern:\nThe condition is expressed using the imperfect subjunctive tense (e.g., ”se fossi,” ”se fossero”).\nThe consequence is expressed using the conditional tense (e.g., ”allora sarei,” ”allora avrai”).\nBy analyzing the context sentences and the given answers, we identified that the correct answer should maintain this\npattern. We looked for a sentence that continued the conditional structure, ensuring that the verb tenses matched the subject\nand conveyed the intended meaning. This allowed us to select the answer that adhered to the established grammatical rule\nand followed the sequence of tenses correctly.\n8147\nD Mixture Agr and Cons\nN.B. The interactions are formatted for readability. In the prompt, we provide the context and answer examples only for those\ninteractions where they change with respect to the previous interaction. ChatGPT repeats the context and answer sentences\nliterally at every interaction. For readability we have introduced ellipses, indicated with (...).\nD.1 Interaction 1\nI am going to ask you to solve a grammatical problem called BLM-MixI. I will give you a list of Italian sentences (numbered\nfrom 1 to 7), that I will call the context, and I will also give you a set of Italian sentences (identified by capital letters) that I will\ncall the answers. I will ask you to choose among the answer sentences the one sentence that could be the next sentence in the\ncontext list of sentences. The sentences have been generated in a rule-based manner.\nI am asking you to give me the correct answer, but also to describe step by step the hypotheses you are entertaining while you are\nsolving the problem. I am also giving you a hint: This is a grammatical problem, not a logical problem. The solution does not lie\nin finding a logical continuation, but a continuation that follows the underlying grammatical patterns.\nContext\n1 Se fossi ricco, allora sarei felice.\n2 Se fossero buoni, allora non sarebbero ricchi.\n3 Se fosti stata ricca, allora non saresti stata felice.\n4 Se foste state buone, allora sareste state ricche.\n5 Se sarai bravo, indipendentemente dalle circostanze, allora sarai ricco.\n6 Se sarete stati bravi, nonostante tutto, allora sarete ricchi.\n7 Se sarai buona, tenendo conto di tanti altri fattori, allora sarai ricca.\nAnswers\nA Se sarete state buone, e con un po’ di fortuna, allora sarete ricche.\nB Se sarai buona, allora sarai felice.\nC Se fosti stato buono, allora fossi felice.\nD Se sarete stati buoni, allora sarete ricchi.\nE Se fosti stata buona, tenendo conto di tanti altri fattori, allora fossero stati felici.\nF Se sarete state buone, allora sarete ricche.\nChatGPT\nTo solve the grammatical problem and determine the next sentence in the given context, let’s analyze the context and\nconsider the grammatical pattern.\nContext: (...)\nLet’s analyze each answer sentence and determine the one that follows the grammatical pattern:\nA. (...) This sentence maintains the conditional structure and aligns with the previous context sentences, introducing the\nidea of luck as a factor. It fits the grammatical pattern and could be a valid continuation.\nB. (...) This sentence introduces a different consequence of being good (happiness) instead of being rich, which deviates\nfrom the established grammatical pattern. It doesn’t fit the context.\nC. (...) This sentence doesn’t fit the grammatical pattern because it combines different verb tenses (subjunctive and\nindicative) that are inconsistent with the established pattern. It doesn’t fit the context.\nD. (...) This sentence maintains the conditional structure and aligns with the previous context sentences. It continues the\npattern of discussing the consequence of being good and being rich. It fits the grammatical pattern and could be a valid\ncontinuation.\nE. (...) This sentence introduces a different subject ”they” and doesn’t follow the established grammatical pattern. It\ndoesn’t fit the context.\nF. (...) This sentence maintains the conditional structure and aligns with the previous context sentences. It continues the\npattern of discussing the consequence of being good and being rich. It fits the grammatical pattern and could be a valid\ncontinuation.\nBased on the analysis, the correct answers could be A. Se sarete state buone, e con un po’ di fortuna, allora sarete ricche. or\nF. Se sarete state buone, allora sarete ricche. These sentences maintain the grammatical pattern and align with the context\nby discussing the consequence of being good and being rich.\n8148\nD.2 Interaction 2\nwhy not D?\nChatGPT\nTo solve the grammatical problem and determine the next sentence in the given context, let’s analyze the context and\nconsider the grammatical pattern.\nContext: (...)\nApologies for the oversight. You’re right, answer D. Se sarete stati buoni, allora sarete ricchi. is indeed a valid option\nbased on the grammatical pattern and context.\nThe sentence D maintains the conditional structure and follows the established pattern of discussing the consequence of\nbeing good and being rich, which is consistent with the context sentences. Therefore, D. Se sarete stati buoni, allora sarete\nricchi can also be considered as a correct continuation of the context.\nD.3 Interaction 3\nThere is only one correct answer. So between A and D which one is the correct one?\nChatGPT\nTo solve the grammatical problem and determine the next sentence in the given context, let’s analyze the context and\nconsider the grammatical pattern.\nContext: (...)\nApologies for the confusion. Based on the given context and the grammatical pattern, the correct answer is D. Se sarete\nstati buoni, allora sarete ricchi. (If you (masculine plural) will have been good, then you (masculine plural) will be rich.)\nThis sentence aligns with the established pattern of conditional sentences and maintains the grammatical structure used in\nthe context. It correctly conveys the consequence of being good, which is being rich. Therefore, D. Se sarete stati buoni,\nallora sarete ricchi is the correct answer.\n8149\nE Quantitative Analysis\nE.1 Prompts for data creation\nAgrI Create one version of these two sets of sentences, with exactly the same syntactic structure for all of them.\nContext\nLa discussione sulla scienza `e iniziata pi`u tardi del previsto.\nLe discussioni sulla scienza sono iniziate pi`u tardi del previsto.\nLa discussione sulle scienze `e iniziata pi`u tardi del previsto.\nLe discussioni sulle scienze sono iniziate pi`u tardi del previsto.\nLa discussione sulla scienza della vita `e iniziata pi`u tardi del previsto.\nLe discussioni sulla scienza della vita sono iniziate pi`u tardi del previsto.\nLa discussione sulle scienze della vita `e iniziata pi`u tardi del previsto.\nAnswers\nA: Le discussioni sulla scienza e la vita sono iniziate pi`u tardi del previsto.\nB: Le discussioni sulle scienze della vita sono iniziate pi`u tardi del previsto.\nC: Le discussioni sulle scienze sono iniziate pi`u tardi del previsto.\nD: Le discussioni sulle scienze della vita `e iniziata pi`u tardi del previsto.\nE: La discussione sulla scienza della vite `e iniziata pi`u tardi del previsto.\nF: Le discussioni sulla scienza della vita sono iniziate pi`u tardi del previsto.\nCausE Create one version of these two sets of sentences, with exactly the same syntactic structure for all of them. The verbs\nyou use must belong to the following list: abate, advance, age, air, alter, atrophy, awake, balance, blast, blur, bum, burst, capsize,\nchange, char, chill, clog, close, collapse, collect, compress, condense, contract, corrode, crumble, decompose, decrease, deflate,\ndefrost, degrade, diminish, dissolve, distend, divide, double, drain, ease, enlarge, expand, . explode, fade, fill, flood, fray, freeze,\nfrost, fuse, grow, halt, heal, heat, hush, ignite, improve, increase, inflate, kindle, light, loop, mature, melt, multiply, overturn, pop,\nquadruple, rekindle, reopen, reproduce, rupture, scorch, sear, short, short-circuit, shrink, shrivel, singe, sink, soak, splay, sprout,\nsteep, stretch, submerge, subside, taper, thaw, tilt, tire, topple, triple, unfold, vary, warp.\nContext\n1 The boy opened the door voluntarily.\n2 The door opened suddenly.\n3 The door was closed.\n4 The door is open.\n5 The cook melted the butter voluntarily.\n6 The butter melted slowly.\n7 The butter was hard.\nAnswers\nA The butter is melted.\nB The boy is open.\nC The door was open.\nD The cook is melted.\nE The butter was melted.\nMixI Create a version of this set of sentences, with exactly the same syntactic structure for all of them, but where the two\nadjectives before and after the comma, are always the same, for each version.\nContext\n1 Se fossi ricco, allora sarei felice.\n2 Se fossero buoni, allora non sarebbero ricchi.\n3 Se fossi stata ricca, allora non saresti stata felice.\n4 Se foste state buone, allora sareste state ricche.\n5 Se sarai bravo, indipendentemente dalle circostanze, allora sarai ricco.\n6 Se sarete stati bravi, nonostante tutto, allora sarete ricchi.\n7 Se sarai buona, tenendo conto di tanti altri fattori, allora sarai ricca.\nAnswers\nA Se sarete state buone, e con un po’ di fortuna, allora sarete ricche.\nB Se sarai buona, allora sarai felice.\nC Se fossi stato buono, allora fossi felice.\nD Se sarete stati buoni, allora sarete ricchi.\nE Se fossi stata buona, tenendo conto di tanti altri fattori, allora fossero stati felici.\nF Se sarete state buone, allora sarete ricche.\nE.2 Prompts requesting solution of task\nAgrI I am going to ask you to solve a grammatical problem called BLM-AgrI. I will give you a list of sentences (numbered\nfrom 1 to 7), that I will call the context, and I will also give you a set of sentences (identified by capital letters) that I will call the\nanswers. I will ask you to choose among the answer sentences the sentence that could be the next sentence in the context list of\nsentences.\n8150\nI am asking you to give me the correct answer, but also to describe step by step your reasoning and the hypotheses you are\nentertaining while you are solving the problem. Please notice this is a grammatical problem. Please provide your answer in\nItalian.\nCausE I am going to ask you to solve a grammatical problem called BLM-CsE. I will give you a list of English sentences\n(numbered from 1 to 7), that I will call the context, and I will also give you a set of English sentences (identified by capital\nletters) that I will call the answers. I will ask you to choose among the answer sentences the one sentence that could be the next\nsentence in the context list of sentences. The sentences have been generated in a rule-based manner.\nI am asking you to give me the correct answer, but also to describe step by step the hypotheses you are entertaining while you\nare solving the problem. Please notice this is a grammatical problem.\nMixI I am going to ask you to solve a grammatical problem called BLM-MixI. I will give you a list of Italian sentences\n(numbered from 1 to 7), that I will call the context, and I will also give you a set of Italian sentences (identified by capital letters)\nthat I will call the answers. I will ask you to choose among the answer sentences the one sentence that could be the next sentence\nin the context list of sentences. The sentences have been generated in a rule-based manner.\nI am asking you to give me the correct answer, but also to describe step by step the hypotheses you are entertaining while you\nare solving the problem. I am also giving you a hint: This is a grammatical problem, not a logical problem. The solution does\nnot lie in finding a logical continuation, but a continuation that follows the underlying grammatical patterns.\nE.3 Quantitative results\nTable 2: Quantitative results AgrI\nCoding of Italian Agreement problem.\nLegend of coding:\nItemId:a;\nProperties of dataset: b:Lexical Type c:Simple/Mixed d:Repeat/Not R e:Language;\nSolutions: f:Correct Answer g:Id’d Pattern;\nCorrectly identified elements: h:NP1 i:NP2 j:NP3 k:V;\nCorrectly identified attributes: l:Singular m:Plural n:Match o:Mismatch;\nOrganisation of Mentions: p:One-at-a-Time q:Pairwise/Grouped r:Row/Col-wise s:Unordered;\nFinding Answers: t: Rule-b generation u: Answer elimination;\nComments.\na b c d e f g h i j k l m n o p q r s t u\ne1 I S NR It 1 1 1 1 0 1 1 1 0 0 1 0 0 0 1 1\ne2 I S NR It 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 Amazingly good reasoning.\ne3 I S NR It 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1\ne4 I S NR It 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1\ne5 I S NR It 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 Last three solutions are identical.\ne5’ I S NR It 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 Recognises changed pattern pl-sg-pl.\ne1 III S NR It 0 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1\ne2 III S NR It 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 if NP3 not identified, majority answer\ne3 III S NR It 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1\ne3’ III S NR It 1 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 Changed prompt a bit.\ne4 III S NR It 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1\ne5 III S NR It 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1\n8151\nTable 3: Quantitative results CausE\nCoding of English causative alternation problem.\nLegend of coding:\na:ItemId;\nProperties of dataset: b:Lexical Type c:Simple/Mixed d:Repeat/Not R e:Language;\nSolutions: f: Correct Answer g: Correct Pattern h:Causative Pattern;\nCorrectly identified elements: i: Subject Trans1 j: Object Trans1 k: Subj Intr 1 l: Subject Trans2 m: Object Trans2 ;\nCorrectly identified attributes: n: Subj Intr2 o: V olition p: External Agent q: CoS: Initial r: CoS: Current s: Agent t:\nPatient;\nOrganisation of Mentions: u:One-at-a-Time v:Pairwise/Grouped w:Row/Col-wise x:Unordered;\nFinding Answers: y: Rule-b generation z: Answer elimination;\nComments.\na b c d e f g h i j k l m n o p q r s t u v w x y z\ne1 I S R E 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 0 1 1 This is a grammatical problem at end\nof instructions, very ’grammatical’ solu-\ntion.\ne1’ I S R E 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1 1 No ’this is a grammatical problem’ at\nthe end of instructions more semantic\nsolution.\ne2 I S R E 1 0 0 1 1 1 1 1 1 0 0 1 1 0 0 0 1 0 0 1 1\ne3 I S R E 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 1\ne4 I S R E 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 1\ne5 I S R E 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 1\ne1 III S R E 1 0 0 0 1 1 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 Makes a mistake in the analysis, thinks\nit’s a passive active alternation\ne2 III S R E 1 1 0 0 1 1 0 1 1 0 0 1 1 0 0 0 1 1 0 1 1 Again some grammatical analysis mis-\ntakes but pretty cool analysis\ne3 III S R E 1 0 0 0 1 1 0 1 1 0 0 1 1 0 0 0 1 1 0 1 1 Again rules are not correct\ne4 III S R E 1 0 0 0 1 1 0 1 1 1 0 1 1 0 0 0 1 1 0 1 1 Same as above, exactly same reasoning.\ne5 III S R E 1 0 0 0 1 1 0 1 1 0 0 1 1 0 0 0 1 1 0 1 1 Same, attempt rules but not correct, very\nsuperficial.\nTable 4: Quantitative results MixI\nCoding of Italian Mixed Agreement and Sequence of Tense problem.\nLegend of coding:\na:ItemId;\nProperties of dataset: b:Lexical Type c:Simple/Mixed d:Repeat/Not R e:Language;\nSolutions: f: Correct Answer g: Id’d Pattern;\nCorrectly identified elements: h: NP1 i: NP2 j: Incidental k: V l: premisse m: consequent;\nCorrectly identified attributes: n:Singular o:Plural p:Match q:Mismatch r:Tense s:Person t:Gender u:Match\nv:Mismatch;\nOrganisation of Mentions: w:One-at-a-Time x:Pairwise/Grouped y:Row/Col-wise z:Unordered;\nFinding Answers: aa: Rule-b generation ab: Answer elimination;\nComments.\na b c d e f g h i j k l m n o p q r s t u v w x y z aa ab\ne1 I M NR It 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1\ne2 I M NR It 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 Gets good answer by a strangely\nincorrect reasoning.\ne3 I M NR It 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1\ne4 I M NR It 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\ne5 I M NR It 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 Despite making mistakes in\ngrammatical analysis of sing,\nplural, it sees the pattern.\ne1 III M NR It 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 1 0 1 0 0 1\ne2 III M NR It 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1\ne3 III M NR It 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 Marvellous, understood all un-\nderlying elements.\ne4 III M NR It 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 1\ne5 III M NR It 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1 Very good, like 3.\n8152"
}