{
  "title": "Paragraph-level Commonsense Transformers with Recurrent Memory",
  "url": "https://openalex.org/W3089988449",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2946817508",
      "name": "Saadia, Gabriel",
      "affiliations": [
        "Allen Institute for Artificial Intelligence",
        "University of Washington"
      ]
    },
    {
      "id": "https://openalex.org/A2071644166",
      "name": "Chandra Bhagavatula",
      "affiliations": [
        "Allen Institute for Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A2250686552",
      "name": "Vered Shwartz",
      "affiliations": [
        "University of Washington",
        "Allen Institute for Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A1967926312",
      "name": "Ronan Le Bras",
      "affiliations": [
        "Allen Institute for Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A2126150186",
      "name": "Maxwell Forbes",
      "affiliations": [
        "University of Washington",
        "Allen Institute for Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A2133417374",
      "name": "Yejin Choi",
      "affiliations": [
        "Allen Institute for Artificial Intelligence",
        "University of Washington"
      ]
    },
    {
      "id": "https://openalex.org/A2946817508",
      "name": "Saadia, Gabriel",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2071644166",
      "name": "Chandra Bhagavatula",
      "affiliations": [
        "Allen Institute for Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A2250686552",
      "name": "Vered Shwartz",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1967926312",
      "name": "Ronan Le Bras",
      "affiliations": [
        "Allen Institute for Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A2126150186",
      "name": "Maxwell Forbes",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2133417374",
      "name": "Yejin Choi",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3082243760",
    "https://openalex.org/W2950339735",
    "https://openalex.org/W3023342553",
    "https://openalex.org/W2151295812",
    "https://openalex.org/W6674756934",
    "https://openalex.org/W2154474435",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2971600926",
    "https://openalex.org/W1975879668",
    "https://openalex.org/W2578412240",
    "https://openalex.org/W2999854190",
    "https://openalex.org/W2054125330",
    "https://openalex.org/W6844082943",
    "https://openalex.org/W2970780738",
    "https://openalex.org/W1702669762",
    "https://openalex.org/W2799031186",
    "https://openalex.org/W3032773829",
    "https://openalex.org/W6631190155",
    "https://openalex.org/W2056891043",
    "https://openalex.org/W2799313190",
    "https://openalex.org/W6682631176",
    "https://openalex.org/W2466175319",
    "https://openalex.org/W6898505805",
    "https://openalex.org/W2361543908",
    "https://openalex.org/W2145374219",
    "https://openalex.org/W6767116873",
    "https://openalex.org/W2798589784",
    "https://openalex.org/W2145755360",
    "https://openalex.org/W6691454618",
    "https://openalex.org/W6755519508",
    "https://openalex.org/W2335559472",
    "https://openalex.org/W6648982606",
    "https://openalex.org/W2786583363",
    "https://openalex.org/W6651937562",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W6729591817",
    "https://openalex.org/W6767869522",
    "https://openalex.org/W2971236147",
    "https://openalex.org/W2154652894",
    "https://openalex.org/W3034998021",
    "https://openalex.org/W2099531122",
    "https://openalex.org/W2963101081",
    "https://openalex.org/W2561529111",
    "https://openalex.org/W3041214984",
    "https://openalex.org/W2041404167",
    "https://openalex.org/W2963429207",
    "https://openalex.org/W2548036585",
    "https://openalex.org/W2968629361",
    "https://openalex.org/W2005814556",
    "https://openalex.org/W2998230451",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W4211148418",
    "https://openalex.org/W3034937117",
    "https://openalex.org/W2964207259",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3014521650",
    "https://openalex.org/W2964121744",
    "https://openalex.org/W2250506749",
    "https://openalex.org/W4293547730",
    "https://openalex.org/W3098824823",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W4298185589",
    "https://openalex.org/W2995643077",
    "https://openalex.org/W2970453125",
    "https://openalex.org/W2993383518",
    "https://openalex.org/W4288243162",
    "https://openalex.org/W2964080504",
    "https://openalex.org/W2963219906",
    "https://openalex.org/W2970161131",
    "https://openalex.org/W4288262459",
    "https://openalex.org/W1986936900",
    "https://openalex.org/W2000900121",
    "https://openalex.org/W3174202502"
  ],
  "abstract": "Human understanding of narrative texts requires making commonsense inferences beyond what is stated in the text explicitly. A recent model, COMET, can generate such inferences along several dimensions such as pre- and post-conditions, motivations, and mental states of the participants. However, COMET was trained on short phrases, and is therefore discourse-agnostic. When presented with each sentence of a multi-sentence narrative, it might generate inferences that are inconsistent with the rest of the narrative. We present the task of discourse-aware commonsense inference. Given a sentence within a narrative, the goal is to generate commonsense inferences along predefined dimensions, while maintaining coherence with the rest of the narrative. Such large-scale paragraph-level annotation is hard to get and costly, so we use available sentence-level annotations to efficiently and automatically construct a distantly supervised corpus. Using this corpus, we train PARA-COMET, a discourse-aware model that incorporates paragraph-level information to generate coherent commonsense inferences from narratives. PARA-COMET captures both semantic knowledge pertaining to prior world knowledge, and episodic knowledge involving how current events relate to prior and future events in a narrative. Our results confirm that PARA-COMET outperforms the sentence-level baselines, particularly in generating inferences that are both coherent and novel.",
  "full_text": "Paragraph-level Commonsense Transformers with Recurrent Memory\nSaadia Gabriel12, Chandra Bhagavatula2, Vered Shwartz12, Ronan Le Bras2,\nMaxwell Forbes12, and Yejin Choi12\n1Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle, USA\n2Allen Institute for Artiﬁcial Intelligence, Seattle, USA\nfskgabrie, mbforbes, yejing@cs.washington.edu , fchandrab, vereds, ronanlbg@allenai.org\nAbstract\nHuman understanding of narrative texts requires making\ncommonsense inferences beyond what is stated explicitly in\nthe text. A recent model, COMET, can generate such im-\nplicit commonsense inferences along several dimensions such\nas pre- and post-conditions, motivations, and mental states of\nthe participants. However, COMET was trained on common-\nsense inferences of short phrases, and is therefore discourse-\nagnostic. When presented with each sentence of a multi-\nsentence narrative, it might generate inferences that are in-\nconsistent with the rest of the narrative.\nWe present the task of discourse-aware commonsense infer-\nence. Given a sentence within a narrative, the goal is to gen-\nerate commonsense inferences along predeﬁned dimensions,\nwhile maintaining coherence with the rest of the narrative.\nSuch large-scale paragraph-level annotation is hard to get and\ncostly, so we use available sentence-level annotations to ef-\nﬁciently and automatically construct a distantly supervised\ncorpus.\nUsing this corpus, we train PARA-COMET, a discourse-\naware model that incorporates paragraph-level information to\ngenerate coherent commonsense inferences from narratives.\nPARA-COMET captures both semantic knowledge pertain-\ning to prior world knowledge, and episodic knowledge in-\nvolving how current events relate to prior and future events\nin a narrative. Our results show that PARA-COMET outper-\nforms the sentence-level baselines, particularly in generating\ninferences that are both coherent and novel.\nIntroduction\nNarrative understanding is a long-standing challenge in the\nﬁeld of natural language processing (NLP) (Charniak 1972;\nWinograd 1972). Arguably, the most crucial aspect of nar-\nrative understanding is the ability to make implicit com-\nmonsense inferences about entities and events in a story and\nreﬁning them as the story unfolds (Pettijohn and Radvan-\nsky 2016; Williams, Lieberman, and Winston 2017; Rashkin\net al. 2018; Qin et al. 2019). This ability in humans is seam-\nless, yet essential for coherent understanding of narrative\ntext. Can NLP systems explicitly generate commonsense in-\nferences, that a human might implicitly make while reading\na narrative?\nCopyright © 2021, Association for the Advancement of Artiﬁcial\nIntelligence (www.aaai.org). All rights reserved.\nWhat would someone\nwith a high water bill do?\nHigh water bill.\nfind a leak.\nget exercise\nmore\nlikely\nless\n likely\nReasons for\ngoing around\nproperty\nFigure 1: Discourse-agnostic models generate inferences\nrelevant to the local context, but these generations can of-\nten be generic or incorrect at the narrative-level. Discourse-\naware models take the rest of the context into account to\nmake globally coherent inferences.\nBeing able to generate commonsense inferences has im-\nportant practical implications. Commonsense Transformer\n(COMET, Bosselut et al. 2019), proposed recently, gener-\nates commonsense inferences for a given phrase or sentence,\ncapturing pre- and post-conditions along nine inferential di-\nmensions found in the ATOMIC (Sap et al. 2019) knowledge\nbase.1 The commonsense inferences generated by COMET\nhave been effectively applied to downstream applications\nsuch as sarcastic comment generation (Chakrabarty et al.\n1See Table 2 for a full list of inferential dimensions in ATOMIC.\nTheThi rty-Fi fth AAA ICon ferenceon A rti fi ci al Intellig ence(AAAI-21)\n12857\n2020), therapy chatbots (Kearns et al. 2020), abductive nat-\nural language generation (Bhagavatula et al. 2019), and au-\ntomated story plot generation (Ammanabrolu et al. 2021).\nHowever, the COMET inferences suffer from a major\nshortcoming – they are generated for a sentence in isola-\ntion and fail to account for the fullparagraph-level narrative\ncontext. This often results in the generation of inferences\nthat are inconsistent or unlikely when considering the pre-\nvious narrative context. For example in Figure 1, given only\nthe sentence “Ella walked around the property, ”one might\ninfer that she did this because she wanted to “get exercise”\nor “admire the view”. While such an inference is reasonable\nfor the sentence in isolation, it is inconsistent given the full\ncontext – e.g.,“The water bill at Ella’s house had been high.\nElla walked around the property. ” Instead, a more reason-\nable inference in light of the full context is that“She wanted\nto ﬁx a leak. ”\nWe introduce the task of generating implicit discourse-\naware commonsense inferences for narrative text, and\npresent PARA-COMET, a transformer-based, controlled\ngeneration model for the task. Instead of collecting crowd-\nsourced annotated data as direct supervision for this task,\nwhich is potentially expensive and challenging to scale,\nPARA-COMET is distantly supervised through sentence-\nlevel inferences obtained either from the COMET model or\nby heuristically matching a sentence to events found in the\nATOMIC knowledge base. We deﬁne and use a coherence\nmetric that measures the likelihood of each candidate infer-\nence in the context of the story to improve their paragraph-\nlevel consistency.\nWe show that PARA-COMET generates coherent\ndiscourse-aware inferences and performs better than\ndiscourse-agnostic baselines in both automated and manual\nevaluation. Yet, even the best model generates implausible\ninferences (23% of the inferences), and inferences that con-\ntradict the paragraph-level context (in 44% of the stories).\nThis stresses the difﬁculty of the task and calls for further\nresearch. We release our models and data as an initial step to-\nwards advancing paragraph-level commonsense understand-\ning.2\nBackground\nSentence-level commonsense inferences. A key compo-\nnent of our distant supervision approach is the availability\nof sentence-level commonsense inferences. The ATOMIC\nknowledge base (Sap et al. 2019) consists of such if-then\nknowledge about causes and effects, agents and themes of\nevents, and their actions and mental states. An ATOMIC\nentry is encoded as a triplet < e1;d;e 2 >, where e1 is an\nevent phrase, dis an inferential dimension and e2 is the in-\nference along the given dimension. ATOMIC deﬁnes nine\ninferential dimensions such as xIntent: the agent’s intent,\noEffect: the effect on the patient(s) etc. (See Table 2).\nThe event e1 and the inference e2 are natural language tem-\nplates consisting of variables PersonX for the agent and\n2Code and data is available at https://github.com/skgabriel/\nparacomet.\nPersonY for the (possibly unknown) patient(s).3\nWhile ATOMIC contains nearly 880K triplets, it is not\nnearly enough to capture the full range and generality of\npossible events, which is immeasurably vast and impos-\nsible to manually enumerate. Furthermore, due to lexi-\ncal variability, events are rarely found as-is in ATOMIC.\nTo that end, COMET (Bosselut et al. 2019) was devel-\noped as a transformer-based knowledge model trained on\nATOMIC to generate commonsense inferences for a given\nphrase/sentence. Thus, both ATOMIC and COMET are nat-\nural candidates to obtainsentence-level commonsense infer-\nences.\nReasoning about narratives. A related line of work to\nours is script learning, that deﬁnes a structured represen-\ntation for prototypical series of events (Schank and Abelson\n1977). An event (e.g., going to a restaurant) is decomposed\ninto components such as the participants (customer, waiter,\ncook, etc.), subevents (sitting down, asking for menus, etc.),\nand their various pre- and post-conditions. In later work,\nscripts were also referred to as “narrative event chains”, and\nmultiple methods to learn the narrative chains from raw text\nwere developed (Chambers and Jurafsky 2008; Jans et al.\n2012; Pichotta and Mooney 2014; Rudinger et al. 2015).\nSimilarly, the Choice of Plausible Alternatives (COPA) task\n(Roemmele, Bejan, and Gordon 2011) proposes a bench-\nmark for commonsense causal reasoning. It asks which of\ntwo alternatives has a causal relationship (either cause or ef-\nfect) with a given premise. Finally, the temporal ordering\nof events is often studied along with typical times and dura-\ntion (Kozareva and Hovy 2011; Granroth-Wilding and Clark\n2016; Li, Ding, and Liu 2018; Zhou et al. 2019).\nTypes of commonsense inferences. While most common-\nsense work only pertains to non-situational semantic knowl-\nedge such as that captured by ConceptNet (Speer, Chin, and\nHavasi 2017), in this paper we focus on commonsense based\non naive psychology, a core human ability that allows people\nto reason about mental states such as reactions, intents, goals\nand beliefs (Heider 1958) in particular situations. ATOMIC\nis speciﬁcally designed to capture such knowledge and we\nfocus on such socially motivated commonsense, though our\ndistant supervision approach and our proposed model are ex-\ntensible to other knowledge bases and forms of common-\nsense.\nCommonsense Inference with Discourse\nOur work is motivated by the question: can NLP systems\nexplicitly generate commonsense inferences, that a human\nmight implicitly make while reading a narrative? To tackle\nthis question, we formalize and introduce the discourse-\naware commonsense inference task.4\n3We refer to PersonY in ATOMIC as patient, one or more\npeople who are affected or acted upon by the action of the verb. We\ndon’t make the semantic distinction between patient and theme.\n4We use the term discourse-aware to refer to data/systems that\nuse paragraph-level information. Similarly,discourse-agnostic sys-\ntems only use sentence-level information.\n12858\nNarrative Dimension w/o Discourse w/ Discourse\nLenny was digging a hole in his yard to plant a tree.\nPersonX needed to be in a pool 7 have a shovel 3\n...\nHe jammed the shovel harder into the ground.\nAll of a sudden water started spurting out of the hole.\nCarla worked at the mall.\nPersonX needed to be hungry 3 drive to the foodcourt 3\nFor her lunch break she ate at the food court.\n...\nCarla’s co-worker bought her lunch.\nSports day was always Emma’s favourite day at school.\nPersonX wants to practice more 7 to win 3\n...\nA girl who moved to the school entered the 100m sprint.\nEmma had never seen her ... thought she would be ﬁne.\nThe water bill at Ella’s house had been high.\nPersonX wanted to admire the view 7 ﬁnd a leak 3\n...\nElla walked around the property.\nTable 1: Examples generated from the models in this paper: a discourse-agnostic (sentence-level) baseline, vs. our discourse-\naware PARA-COMET. We highlight the sentence that each inference was generated for in bold. Inferences are marked as\nplausible (3) or implausible (7).\nType Dimension Template\nCauses\nxIntent PersonX wanted e2\nxNeed PersonX needed e2\nxAttr PersonX is seen as e2\nEffects\nxWant PersonX wants e2\nxEffect PersonX is likely e2\nxReact PersonX then feels e2\noWant PersonY wants e2\noEffect PersonY is likely e2\noReact Others then feel e2\nTable 2: Natural language templates for ATOMIC dimen-\nsions.\nFormally, given a narrative with T sentences\nfS1;S2:::ST g, the goal is to generate a set of com-\nmonsense inferences for the nine inferential dimensions\n(Table 2) for each sentence Si. This set of inferences\ngenerated for Si must also be consistent with the entire\nnarrative. Maintaining consistency with the full narrative\ncontext requires reasoning about the relationship between\npast and future events.\nTable 1 shows some examples of discourse-aware\n(paragraph-level) and discourse-agnostic (sentence-level)\ninferences. Sentence-level inferences are often inconsistent\nwith the narrative. For example, the inference that a charac-\nter needed “to be in a pool” when the earlier context shows\nthey are gardening (ﬁrst row in Table 1) or that a character\nwants to “practice more” when it has been established they\nare conﬁdent in their own abilities (third row).\nDistant Supervision Approach\nSentence-level inferences (e.g. those obtained from\nCOMET) are inadequate to train models for our proposed\ntask and obtaining direct supervision of discourse-aware\ninferences may be prohibitively expensive or infeasible to\ncollect in large quantities at an effective quality standard\nlevel. Therefore, we use distant supervision to loosely\nalign sentences in a narrative to their discourse-aware com-\nmonsense inferences. First, we obtain discourse-agnostic\ninferences from either the COMET model or the ATOMIC\nknowledge base. Next, we ﬁlter out inferences that are\ninconsistent with the rest of the narrative (described in\nSection ). Thus, we obtain silver standard training data\nfor training models for our task. Additionally, we create a\nsmaller-scale validation set by manually validating infer-\nences through a crowdsourcing annotation task (Section ).\nSource of Narratives\nThe basis for our dataset are English stories from the ROC-\nStories corpus (Mostafazadeh et al. 2016), which consists\nof 98K ﬁve-sentence stories authored by workers on Ama-\nzon Mechanical Turk. Understanding these stories requires\ncommonsense and temporal inferences that we aim to cap-\nture. We split the original ROCStories train set into train,\ndev, and test sets in a 90/5/5 ratio.\nDiscourse-agnostic Inferences\nWe aim to generate the types of commonsense inferences\ndeﬁned by the ATOMIC knowledge base (Sap et al. 2019).\nWe obtain discourse-agnostic inferences using either of the\nfollowing approaches.\nHeuristic: For each sentence Si in the story, we get an\ninitial set of candidate inferences Ri by extracting ATOMIC\n12859\nNarrative Inference Relevant?\nNatalie’s favorite movie is The Wizard of Oz... PersonX wanted: to see the ﬁlm 3\nI was at the grocery store...I see the lines were very long... PersonX then feels: relieved 7\nJim wanted to learn Spanish. He tried taking a class... PersonY/Others want: to catch up 7\nOur building had a summer bbq party today. The manager took photos... PersonX wants: to enjoy the party 3\nChris realizes that he rarely watches cable TV anymore. He calls...to cancel... PersonX wanted: to be a good customer 7\nMy grandparents lived in Alabama...I miss traveling there... PersonX is seen as: sad 3\nTable 3: Examples from the distantly supervised dataset. We highlight the most relevant (i.e. potentially contradictory or sup-\nporting) sections in the story for each inference being considered.\ntuples, < e1;d;e 2 >, in which e1 and Si share either noun\nphrases or verb phrases. We repurpose the ROUGE metric\n(Lin 2004) to measure the surface-level relevance of a partic-\nular event e1 to a sentence Si. Speciﬁcally, we compute the\nROUGE-1 F1 score, which considers unigrams, and keep\nthe top 10 inferences with respect to the score for each sen-\ntence and dimension.\nModel-based: We use COMET to generate common-\nsense inferences for each sentence Si in the story. We use\nbeam search with a beam size of 10 to obtain a set of infer-\nences for each sentence and dimension combination.\nMore details on the distant supervision data curation pro-\ncess are given in the Appendix.\nFrom Discourse-agnostic to Discourse-aware\nInferences\nThe inferences obtained by both heuristic and model-based\nmethods (Section ) only consider one sentence at a time.\nTo improve coherence with the rest of the narrative, we\nﬁlter the inferences that have a low coherence with the\ngiven narrative. Speciﬁcally, inspired by information the-\nory (Shannon 1948; Hale 2001), we deﬁne coherence as\na measure based on the cross entropy of the story tokens\nconditioned on a particular candidate knowledge inference.\nFor a tuple < e1;d;e 2 >2Ri matched to a sentence Si,\nand a language model \u0002, we compute the cross entropy\nloss of the tokens in the story, where < d;e2 > follow\nSi: CE(S1;:::Si;< d;e2 >;:::S5).5 We use a transformer-\nbased language model, and convert<d;e 2 >to natural lan-\nguage using hand-crafted templates shown in Table 2.\nIn practice, we divide the dimensions into causes (xNeed,\nxIntent, xAttr) and effects (xWant, xEffect,\nxReact, oWant, oEffect, oReact). For cause infer-\nences, we compute coherence with the previous and current\nsentences in the story. For effect inferences we use the full\nstory. This allows us to effectively measure how well the\nextracted inferences may follow from past or predict future\nstory events.\nTo ensure an equal distribution of inferences across di-\nmensions, we order inferences by coherence score and keep\nthe top 5 inferences for each sentence and dimension type.\n5Here we deﬁne cross entropy loss as CE(t1;:::;t n) =\n\u00001\nn\nPn\ni=1 log2p\u0002(tijt1;:::;t i\u00001):\nThis ﬁltering step is designed to reduce the number of con-\ntradicting inferences in our distant supervision corpus.\nValidation Set\nWe validate a subset of the development set through crowd-\nsourcing to obtain a gold evaluation set. We used Amazon\nMechanical Turk and asked workers to judge the relevance\nof inferences for a given sentence within a story, leaving the\ninterpretation of relevance to the best judgement of annota-\ntors.6 Generally, we found that annotators adhered to a strict\ndeﬁnition of relevance in which ambiguous inferences that\nmay still be relevant to the story context at some point in\nthe story timeline are labeled as irrelevant. See Table 3 for\nexamples.\nWe randomly sampled 542 stories from the development\nset, and for each story we randomly selected a sentence and\na dimension, and annotated the 5 inferences associated with\nthem. We had 3 annotators judge each example, and used\nthe majority vote to obtain a gold label. We ﬁltered out low\nquality annotations by manually checking for workers with\nlow inter-annotator agreement and frequently incorrect la-\nbeling.7\nOur annotations yielded fair inter-annotator agreement of\nFleiss’ \u0014 = 0 :338 (Fleiss 1971) (p-value < .001). Despite\nthe challenges of this task, this value is higher or comparable\nto prior work achieved for the evaluation of commonsense\nknowledge.8 The ﬁnal evaluation subset consists of 607 in-\nferences, across all different dimensions, from 313 unique\nstories that were found to be relevant by multiple human an-\nnotators (34.29% of the inferences judged).\nModel\nWe draw inspiration from the distinction between seman-\ntic and episodic memory (Tulving and Donaldson 1972),\nand consider implicit commonsense knowledge in two ways:\n1) semantic knowledge, grounded in world knowledge and\nculture-speciﬁc social knowledge (e.g., “leaks lead to high\nwater bills”), and 2)episodic knowledge, grounded in causal\nunderstanding and epistemic reasoning—i.e. reasoning that\n6We restrict annotators to US only.\n7These were done primarily by workers who spent less than 20\nseconds on a HIT.\n8\u0014 = 0 :23 in judging commonsense knowledge triplets in\n(Feldman, Davison, and Rush 2019) and between \u0014 = 0:289 and\n\u0014= 0:483 in commonsense story generation in (Guan et al. 2020).\n12860\nAs a result, PersonX wants \nto finish the chapter. \nJordan was writing\n a new novel.\nShe was facing a block on\nthe next chapter. \nJordan decided to take a\nbreak from writing. \nShe went outside and took \na nice walk. \nAfter the walk, Jordan was able to write the next chapter.  \nS1 S2\nS3 S4\nS5\nInput Narrative\nOutput \nInference\nInference \nModel\nUpdate Co:\nCo + proj(Mo) \nAveraged\nretrieved\ninferences Mo\nTop k\ninferences Mo\nRetrieve \nMo\nUpdate\nmemory after\ninference\ngeneration\nDim ID\nATOMIC\nxWant\n2\nInput \nTokens\nTransformer\nOutput \nInference\nCurrent\ntoken \nto generate\n(ti)\nUpdate Co\nRetrieve top k inferences Mo\nCosine similarity\nAverage \ninference \nvectors\nCo\nMoContext\nContext Inference\nFigure 2: An illustration of PARA-COMET with a memory component. The model predicts an inference for a given sentence\nin the narrative (e.g., the second) and a requested ATOMIC dimension.\nrelates past events to current events (e.g., “if a person gets a\nhigh water bill, they will want to ﬁnd out why”). We intro-\nduce two variants of the PARA-COMET controlled gener-\nation model: a memory-less model that focuses on semantic\nknowledge drawn from the context, and a model augmented\nwith recurrent memory that allows us to explicitly incorpo-\nrate episodic knowledge.\nFigure 2 demonstrates generating inferences for a narra-\ntive using PARA-COMET with recurrent memory.\nMemory-less model. Given a story context c =\nfS1;S2;:::;S T gof T sentences and a selected sentenceSi,\nwe set the input to:\nx= S1 jjS2 ::: ST jjsjjd (1)\nwhere sand dare special tokens. srepresents the index of\nthe selected sentence, whiledrepresents the required dimen-\nsion in ATOMIC. jjdenotes concatenation. In the example\nin Figure 2, the input provided to the model is:\nx= Jordan was writing... <jsent2j> < jxWantj>\nWe ﬁne-tuned the base GPT and GPT2 transformer mod-\nels (Radford et al. 2019; Radford 2018) to generate the ex-\npected output, which is an inference for the dimensiondand\nsentence Si.\nMemory-augmented model. To incorporate inferences\ngenerated for other sentences in the story while generating\ninferences for a given sentence, we extend the model with a\nrecurrent memory component, inspired by episodic memory.\nMm 2RRm\u0002Lr\u0002H is the external memory, whereRm is ei-\nther the maximum number of inferences per instance to store\nin memory (during training time) or the current number of\ninstances (during decoding time), Lr is the maximum infer-\nence sequence length,9 and His the hidden state dimension.\nThe memory-augmented model takes as input a memory\nupdate matrix Mu 2 RRu\u0002Lr\u0002H, where Ru is the num-\nber of inferences used to update memory, and incorporates\nit into the memory matrix:\nMm = Mm \bfemb(Mu) (2)\n\bstands for matrix concatenation, and femb is an embed-\nding layer trained jointly with the rest of the model. After\nthe memory is updated, we average Mm across the token\ndimension to get \u0012mem 2RRm\u0002H:\n\u0012mem = 1\nLr \u0001\nLr\nX\nl=1\nMml (3)\nWe denote the context representation obtained from GPT\nor GPT2’s hidden state as Co 2RLc\u0002H, where Lc is the\ncontext sequence length. We average it across all tokens,\nobtaining \u0012ctx 2 RH. We then prune the memory to the\ntop-k most relevant inferences, measured by cosine similar-\nity between the memory\u0012mem and context vectors\u0012ctx. The\nmemory output Mo 2RH is the average of the top-k infer-\nences.\nFinally, we reweigh the context representationCo to con-\nsider the memory:\nCo = Co + proj(Mo) (4)\n9We use a maximum memory size (Rm) of 45 inferences and a\nmaximum sequence length of 100 tokens during training time. Dur-\ning decoding, we dynamically resize memory based on the number\nof inferences previously generated.\n12861\nWhere proj is a linear projection layer used to project the\nmemory output into the same hidden dimensional space as\nthe context representation.\nAt training time, the memory consists of previously ex-\ntracted relations from our distant supervision, while at test\ntime, it consists of previously generated inferences, recall-\ning the model’s prior decisions. For both PARA-COMET\nmodel variants, we minimize the cross entropy loss of the\nentire sequence (input and output).\nExperimental Setup\nTraining Setup\nAll models are implemented using the Transformers pack-\nage (Wolf et al. 2020), and trained for a maximum of 20\nepochs. Training is performed using an Adam optimizer\nwith linear warmup (Kingma and Ba 2015). We also sim-\nulate a batch size of 16 using gradient accumulation and an\nactual batch size of 4. The learning rate is2\u000310\u00005 for GPT2.\nFor GPT we use a learning rate of6:25 \u000310\u00005. All other hy-\nperparameters follow (Radford et al. 2019; Radford 2018).\nWe retrieve the top k = 1 inferences from memory.10 We\nuse the 124M parameter version of the GPT2 model.\nDecoding Setup\nFor decoding, we use beam search with a beam size of\nb 2f1;10g. The maximum decoding length is 50 tokens.\nUnlike at training time, where we take a single dimension\nfor each sentence in each story, at decoding time we gener-\nate inferences from every dimension for every sentence. For\nboth training and decoding, all experiments are run using 64\nIntel(R) Xeon(R) Gold 6130 x86-64 CPUs at 2.10GHz and\na Quadro RTX 8000 GPU.\nBaselines\nAs a baseline, we use the COMET model, pre-trained on\nATOMIC, to generate sentence-level inferences for each\nsentence in the story. 11 As an additional baseline, we use\na retrieval model (BERT-KNN) based on the K-Nearest\nNeighbor search algorithm (k=1). We embed ATOMIC\nevents using BERT (Devlin et al. 2019), then ﬁnd the closest\nATOMIC event node for each story sentence to get a set of\nmatching inferences.\nEvaluation\nWe report the performance of all models for automatic eval-\nuation and the top 6 model variations (two COMET varia-\ntions and four PARA-COMET variations) for human evalu-\nation. For PARA-COMET, we report the variants with and\nwithout memory, trained on either the heuristic matching ap-\nproach (PARA-H) or the model-based approach (PARA-M),\nas described in Section .\n10For GPT2 we use memory during training and decoding. For\nGPT, we report results using training-only memory.\n11See the original paper for details.\nHuman Evaluation\nWe follow a similar crowdsourcing setup to the validation\npresented in Section to measure the quality of generated\ninferences. We sampled 336 inferences from 56 unique sto-\nries. We show crowdworkers the full story, a speciﬁed di-\nmension, and a generated inference. We specify the assign-\nment of PersonX to the syntactic subject of the sentence.12\nFollowing Zhang et al. (2017), we ask workers to judge\nthe likelihood of inferences based on a 5-point Likert scale:\nobviously true (5), generally true (4), plausible (3), neutral\nor unclear (2), and doesn’t make sense (1). Table 4 displays\nthe percent of inferences judged as plausible or true (3-5),\nand plausible (3), and the average rating per inference (using\nmajority voting).\nOverall, PARA-COMET generations are scored with\nhigher average ratings, between 3.05 and 3.44 points com-\npared to 2.57 and 2.93 points for the COMET baseline vari-\nants. Speciﬁcally, the memory-augmented variants produced\nnotably more plausible inferences than any other model. We\nobserved that inferences in this category tend to be less\nobvious—e.g. restating information from the context, pro-\nducing generic inferences—and recover plausible implicit\ninferences.\nAutomatic Evaluation\nSimilarity to the gold inferences. We follow the\nATOMIC and COMET automatic evaluation setup using\nBLEU (Papineni et al. 2001), which measures the n-gram\noverlap between the generated and gold inferences.\nNovelty. Following Jastrzebski et al. (2018), we compute\nnovelty by measuring the percentage of generated inferences\nthat do not appear verbatim in ATOMIC. We account for\nslight paraphrases by counting as novel the generated infer-\nences that have an edit distance ratio of less than 0.95 with\nall ATOMIC events.\nDiscourse-level coherence. We use natural language\ninference (NLI; Dagan et al. 2013) as a proxy for measuring\nthe narrative-level coherence of the predicted inferences.\nWe deﬁne coherence as follows - at the very least, the\nstory must not contradict any of the predictions, and it\nmay possibly entail some of the predictions. We use the\npretrained SemBERT model (Zhang et al. 2020), a variant\nof BERT augmented with explicit semantic role labels, to\ncompute NLI labels (entailment, neutral, contradiction).\nTable 5 provides a summary of the automatic evalua-\ntion results on the gold subset. The PARA-COMET\nvariants outperform the sentence-level baselines across all\nmetrics. The novelty results show that PARA-COMET\nmodels are capable of generating inferences that did not\nappear in the original ATOMIC knowledge graph. The\nmemory-augmented models generated inferences that were\n12We manually corrected incorrect parses such as those in which\nthe subject of the sentence is not a person.\n12862\nModel Decoding True or Plausible (3-5) (%) Plausible (3) (%) Avg. Rating\nCOMET greedy 49.41 17.86 2.57\nbeam-10 63.69 26.19 2.93\nPARA-H beam-10 68.45 22.62 3.21\nPARA-H+mem beam-10 66.67 27.98 3.05\nPARA-M beam-10 74.40 23.81 3.44\nPARA-M+mem beam-10 77.38 31.55 3.42\nTable 4: Human evaluation results. We highlight the overall best performing model in bold. All PARA-COMET results are\nusing GPT2 models.\nModel Decoding BLEU-1 BLEU-2 Novelty NLI\nBERT-KNN - 79.99 69.14 - 44.84\nCOMET greedy 85.78 80.87 3.03 53.85\nbeam-10 87.91 80.10 18.87 51.44\nPARA-H (GPT) beam-10 91.00 83.14 17.09 54.63\nPARA-H+mem (GPT) beam-10 90.99 83.43 16.09 56.23\nPARA-M (GPT) beam-10 91.03 83.06 12.56 52.72\nPARA-M+mem (GPT) beam-10 91.09\n82.88 12.54 59.42\nPARA-H (GPT2) beam-10 91.03 83.43 15.99 54.95\nPARA-H+mem (GPT2) beam-10 91.24 83.57 14.39 56.23\nPARA-M (GPT2) beam-10 89.44 81.89 20.96 54.63\nPARA-M+mem (GPT2) beam-10 89.68 82.18 20.06 54.95\nTable 5: Performance according to the automatic evaluation metrics. The best performing model for a speciﬁc PARA-COMET\nvariant (GPT or GPT2) is underlined. We highlight the overall best performing model in bold. The NLI score is the percent of\nstories for which the model predicted entail or neutral.\nmore coherent with the story, reducing the percents of con-\ntradicting inferences from 46.15% (in COMET) to 40.58%.\nWe ﬁnd the GPT models generally have comparable or\nbetter performance to GPT2 models on automatic metrics,\nwhich we hypothesize is due to the fact GPT was pretrained\non story text and has speciﬁc knowledge pertaining to\nimplicit knowledge underlying narratives. Overall, we\nﬁnd that incorporating narrative coherence through either\nepisodic knowledge from the recurrent memory mechanism\nand/or context from other story events improves BLEU-1\nby up to 3.33 points and BLEU-2 by up to 2.70 points.\nCase Study: Personal Narratives\nTo test the ability of the model to generalize to more com-\nplex narratives requiring further pragmatic reasoning (Sap\net al. 2020), we sampled and manually evaluated a set of 111\nstory/sentence/dimension triplets from personal blog posts\nin the COSMOSQA machine reading comprehension test\nset (Huang et al. 2019). While these narratives tend to be\nof a similar or shorter length than ROCStories, they require\nmore real-world understanding. They also contain nuanced\ndescriptions of social interactions.\nWe found that our model is effective at predicting infer-\nences in an unsupervised setting with 49.55 % of relations\nlabeled as true and 20.72% of relations labeled as plausible\n(vs. 20.72% and 27.03% for COMET). We noticed that our\nmodel more frequently overcomes two major plausibility er-\nrors in unsupervised commonsense inference - off-topic and\nStory: Almost a month ago now, the radio station got struck\nby lightning. It fried the router and the cable modem.\n[Before /bolt, PersonX wanted]\nWe got the new equipment right away.\nCOMET (beam-10): to be a good cook, to eat\nPARA-M: to have better internet, to not be bothered\nStory: I posted a moment ago regarding a girl I asked out...\nshe said she would like to do something,\nbut work made it difﬁcult. That was a couple of weeks back...\n[Next, PersonX will]\nCOMET (beam-10): get married, get a divorce\nPARA-M: be asked out, get rejected\nTable 6: Examples of personal blog posts with commonsense\nmodel predictions. Here we assume PersonX to be the nar-\nrator of the blog post.\ntemporarily inappropriate predictions (see Table 6).\nFor example, our model is able to correctly predict the\nlikely intentions of someone owning a router and cable mo-\ndem (example 1), while COMET predictions incorrectly fo-\ncus on meal preparation. COMET also sometimes makes\nrelevant but farfetched predictions while our model’s infer-\nences are better situated within a narrative timeline (example\n2).\n12863\nConclusion\nWe introduced a new task of discourse-aware commonsense\ninference over narratives. To target this task, we proposed a\nnew model, PARA-COMET, trained using distant supervi-\nsion, that captures narrative discourse.\nDespite the challenges of the task, we demonstrated the\neffectiveness of our approach using both automatic and hu-\nman evaluations. In particular, our models were able to gen-\nerate more implicit and novel discourse-aware inferences. In\nthe future, we are interested in exploring further extensions\nof our work to downstream paragraph- and narrative-level\ntasks that may beneﬁt from access to commonsense knowl-\nedge.\nAcknowledgments\nWe thank the anonymous reviewers for helpful feedback,\nas well as Maarten Sap, Hannah Rashkin, Eunsol Choi and\nmembers of the UW and AI2 communities for helpful dis-\ncussions. This research was supported in part by DARPA\nunder the CwC program through the ARO (W911NF-15-1-\n0543) and DARPA under the MCS program through NIWC\nPaciﬁc (N66001-19-2-4031).\nEthics Statement\nWe note that the knowledge represented by current resources\ncaptures a mix of general commonsense which the majority\nof readers would ﬁnd likely regardless of background (in-\ncluding factual commonsense) and culturally-speciﬁc com-\nmonsense which is only likely to some readers (i.e. is not the\nmost logical conclusion for all readers). One likely contribu-\ntor to this speciﬁcity of commonsense is the dependency on\nonline crowdsourcing for annotation and generation of com-\nmonsense knowledge. A 2016 report from Pew Research 13\nfound that a sample of MTurk crowd-sourcing workers was\nheavily skewed demographically. This has an unintended\nside effect of enforcing a potentially harmful assumption\nthat “commonsense knowledge” is only knowledge agreed\nupon by a speciﬁc demographic or cultural majority. Pro-\nposed steps for future work on discourse-aware common-\nsense inference include:\n• Multicultural and multilingual commonsense datasets that\ncapture a more distributional view of commonsense, al-\nlowing for both sociocultural overlap and disagreement\nabout likelihood of relevant inferences.\n• New evaluation metrics and frameworks for common-\nsense that consider likelihood rather than hard labels of\nrelevancy. We begin to explore this with our categorical\nlabeling of extracted commonsense knowledge.\n• Social commonsense inference models that consider mul-\ntiple audience points-of-view.\nReferences\nAmmanabrolu, P.; Cheung, W.; Broniec, W.; and Riedl,\nM. O. 2021. Automated Storytelling via Causal, Common-\nsense Plot Ordering. In AAAI.\n13https://www.pewresearch.org/internet/2016/07/11/turkers-in-\nthis-canvassing-young-well-educated-and-frequent-users/\nBhagavatula, C.; Le Bras, R.; Malaviya, C.; Sakaguchi, K.;\nHoltzman, A.; Rashkin, H.; Downey, D.; Yih, W.-t.; and\nChoi, Y . 2019. Abductive Commonsense Reasoning. In\nICLR.\nBosselut, A.; Rashkin, H.; Sap, M.; Malaviya, C.; Celikyil-\nmaz, A.; and Choi, Y . 2019. COMET: Commonsense Trans-\nformers for Automatic Knowledge Graph Construction. In\nACL.\nChakrabarty, T.; Ghosh, D.; Muresan, S.; and Peng, N. 2020.\nRˆ3: Reverse, Retrieve, and Rank for Sarcasm Generation\nwith Commonsense Knowledge. In ACL, pg. 7976–7986.\nChambers, N.; and Jurafsky, D. 2008. Unsupervised learning\nof narrative event chains. In Proceedings of ACL-08: HLT,\npg. 789–797.\nCharniak, E. 1972. Toward a model of children’s story com-\nprehension. Ph.D. thesis, Massachusetts Institute of Tech-\nnology.\nDagan, I.; Roth, D.; Zanzotto, F.; and Sammons, M. 2013.\nRecognizing textual entailment: Models and applications .\nMorgan & Claypool Publishers.\nDevlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2019.\nBERT: Pre-training of Deep Bidirectional Transformers for\nLanguage Understanding. In NAACL-HLT.\nFeldman, J.; Davison, J.; and Rush, A. M. 2019. Com-\nmonsense Knowledge Mining from Pretrained Models. In\nEMNLP/IJCNLP.\nFleiss, J. L. 1971. Measuring nominal scale agreement\namong many raters. Psychological bulletin 76(5): 378.\nGranroth-Wilding, M.; and Clark, S. 2016. What happens\nnext? event prediction using a compositional neural network\nmodel. In AAAI.\nGuan, J.; Huang, F.; Zhao, Z.; Zhu, X.; and Huang, M. 2020.\nA Knowledge-Enhanced Pretraining Model for Common-\nsense Story Generation. In TACL, volume 8, 93–108.\nHale, J. 2001. A Probabilistic Earley Parser as a Psycholin-\nguistic Model. In NAACL.\nHeider, F. 1958. The Psychology of Interpersonal Relations.\nJohn Wiley & Sons Inc.\nHuang, L.; Le Bras, R.; Bhagavatula, C.; and Choi, Y . 2019.\nCosmos QA: Machine Reading Comprehension with Con-\ntextual Commonsense Reasoning. In EMNLP/IJCNLP.\nJans, B.; Bethard, S.; Vuli´c, I.; and Moens, M. F. 2012. Skip\nn-grams and ranking functions for predicting script events.\nIn EACL, 336–344. Association for Computational Linguis-\ntics.\nJastrzebski, S.; Bahdanau, D.; Hosseini, S.; Noukhovitch,\nM.; Bengio, Y .; and Cheung, J. C. K. 2018. Commonsense\nmining as knowledge base completion? A study on the im-\npact of novelty. In Proceedings of the Workshop on Gener-\nalization in the Age of Deep Learning. Association for Com-\nputational Linguistics.\nKearns, W. R.; Kaura, N.; Divina, M.; V o, C. V .; Si, D.;\nWard, T. M.; and Yuwen, W. 2020. A Wizard-of-Oz Inter-\nface and Persona-based Methodology for Collecting Health\n12864\nCounseling Dialog. Extended Abstracts of the 2020 CHI\nConference on Human Factors in Computing Systems .\nKingma, D. P.; and Ba, J. 2015. Adam: A Method for\nStochastic Optimization. In ICLR.\nKozareva, Z.; and Hovy, E. 2011. Learning Temporal Infor-\nmation for States and Events. In 2011 IEEE Fifth Interna-\ntional Conference on Semantic Computing, 424–429.\nLi, Z.; Ding, X.; and Liu, T. 2018. Constructing Narrative\nEvent Evolutionary Graph for Script Event Prediction. In\nIJCAI.\nLin, C.-Y . 2004. ROUGE: A Package for Automatic Evalu-\nation of Summaries. In Text Summarization Branches Out,\n74–81. Barcelona, Spain: Association for Computational\nLinguistics. URL https://www.aclweb.org/anthology/W04-\n1013.\nMostafazadeh, N.; Chambers, N.; He, X.; Parikh, D.; Ba-\ntra, D.; Vanderwende, L.; Kohli, P.; and Allen, J. 2016. A\nCorpus and Cloze Evaluation for Deeper Understanding of\nCommonsense Stories. In Proceedings of the 2016 Con-\nference of the North American Chapter of the Association\nfor Computational Linguistics: Human Language Technolo-\ngies, 839–849. San Diego, California: Association for Com-\nputational Linguistics. doi:10.18653/v1/N16-1098. URL\nhttps://www.aclweb.org/anthology/N16-1098.\nPapineni, K.; Roukos, S.; Ward, T.; and Zhu, W.-J. 2001.\nBleu: a Method for Automatic Evaluation of Machine Trans-\nlation. In ACL.\nPettijohn, K.; and Radvansky, G. 2016. Narrative event\nboundaries, reading times, and expectation. In Mem Cogn\n44, 1064–1075.\nPichotta, K.; and Mooney, R. 2014. Statistical Script Learn-\ning with Multi-Argument Events. In EACL, 220–229.\nQin, L.; Bosselut, A.; Holtzman, A.; Bhagavatula, C.; Clark,\nE.; and Choi, Y . 2019. Counterfactual Story Reasoning and\nGeneration. In EMNLP.\nRadford, A. 2018. Improving Language Understanding by\nGenerative Pre-Training. OpenAI technical report .\nRadford, A.; Wu, J.; Child, R.; Luan, D.; Amodei, D.; and\nSutskever, I. 2019. Language Models are Unsupervised\nMultitask Learners. OpenAI technical report .\nRashkin, H.; Bosselut, A.; Sap, M.; Knight, K.; and Choi, Y .\n2018. Modeling Naive Psychology of Characters in Simple\nCommonsense Stories. In ACL.\nRoemmele, M.; Bejan, C. A.; and Gordon, A. S. 2011.\nChoice of plausible alternatives: An evaluation of common-\nsense causal reasoning. In 2011 AAAI Spring Symposium\nSeries.\nRudinger, R.; Rastogi, P.; Ferraro, F.; and Van Durme, B.\n2015. Script induction as language modeling. In Proceed-\nings of the 2015 Conference on Empirical Methods in Natu-\nral Language Processing, 1681–1686.\nSap, M.; Gabriel, S.; Qin, L.; Jurafsky, D.; Smith, N. A.;\nand Choi, Y . 2020. Social Bias Frames: Reasoning about\nSocial and Power Implications of Language. In Proceed-\nings of the 58th Annual Meeting of the Association for\nComputational Linguistics, 5477–5490. Online: Association\nfor Computational Linguistics. doi:10.18653/v1/2020.acl-\nmain.486. URL https://www.aclweb.org/anthology/2020.\nacl-main.486.\nSap, M.; Le Bras, R.; Allaway, E.; Bhagavatula, C.; Lourie,\nN.; Rashkin, H.; Roof, B.; Smith, N. A.; and Choi, Y . 2019.\nATOMIC: An Atlas of Machine Commonsense for If-Then\nReasoning. In AAAI.\nSchank, R. C.; and Abelson, R. P. 1977.Scripts, plans, goals\nand understanding: An inquiry into human knowledge struc-\ntures. Published by Psychology Press.\nShannon, C. E. 1948. The Mathematical Theory of Commu-\nnication. The Bell System Technical Journal27(3).\nSpeer, R.; Chin, J.; and Havasi, C. 2017. Conceptnet 5.5: An\nopen multilingual graph of general knowledge. In Thirty-\nFirst AAAI Conference on Artiﬁcial Intelligence.\nTulving, E.; and Donaldson, W. 1972. Episodic and seman-\ntic memory. Organization of memory .\nWilliams, B.; Lieberman, H.; and Winston, P. H. 2017. Un-\nderstanding Stories with Large-Scale Common Sense. In\nCOMMONSENSE.\nWinograd, T. 1972. Understanding natural language. Cog-\nnitive psychology 3(1): 1–191.\nWolf, T.; Debut, L.; Sanh, V .; Chaumond, J.; Delangue, C.;\nMoi, A.; Cistac, P.; Rault, T.; Louf, R.; Funtowicz, M.; Davi-\nson, J.; Shleifer, S.; von Platen, P.; Ma, C.; Jernite, Y .; Plu, J.;\nXu, C.; Le Scao, T.; Gugger, S.; Drame, M.; Lhoest, Q.; and\nRush, A. 2020. Transformers: State-of-the-Art Natural Lan-\nguage Processing. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Processing: Sys-\ntem Demonstrations, 38–45. Association for Computational\nLinguistics.\nZhang, S.; Rudinger, R.; Duh, K.; and Durme, B. V . 2017.\nOrdinal Common-sense Inference. Transactions of the As-\nsociation for Computational Linguistics 5: 379–395.\nZhang, Z.; Wu, Y .-W.; Hai, Z.; Li, Z.; Zhang, S.; Zhou, X.;\nand Zhou, X. 2020. Semantics-aware BERT for Language\nUnderstanding. Thirty-Fourth AAAI Conference on Artiﬁcial\nIntelligence (AAAI-20) .\nZhou, B.; Khashabi, D.; Ning, Q.; and Roth, D. 2019. Going\non a vacation takes longer than Going for a walk: A Study of\nTemporal Commonsense Understanding. In Proceedings of\nthe 2019 Conference on Empirical Methods in Natural Lan-\nguage Processing and the 9th International Joint Confer-\nence on Natural Language Processing (EMNLP-IJCNLP) ,\n3354–3360.\n12865",
  "topic": "Paragraph",
  "concepts": [
    {
      "name": "Paragraph",
      "score": 0.8036744594573975
    },
    {
      "name": "Narrative",
      "score": 0.7222797274589539
    },
    {
      "name": "Sentence",
      "score": 0.7214972376823425
    },
    {
      "name": "Computer science",
      "score": 0.7176996469497681
    },
    {
      "name": "Commonsense knowledge",
      "score": 0.6744945049285889
    },
    {
      "name": "Natural language processing",
      "score": 0.5794801115989685
    },
    {
      "name": "Automatic summarization",
      "score": 0.5256458520889282
    },
    {
      "name": "Inference",
      "score": 0.5207364559173584
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5177571177482605
    },
    {
      "name": "Comet",
      "score": 0.5004549026489258
    },
    {
      "name": "Construct (python library)",
      "score": 0.43505728244781494
    },
    {
      "name": "Linguistics",
      "score": 0.3325577974319458
    },
    {
      "name": "Knowledge base",
      "score": 0.12864571809768677
    },
    {
      "name": "Philosophy",
      "score": 0.09367263317108154
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "World Wide Web",
      "score": 0.0
    },
    {
      "name": "Astrophysics",
      "score": 0.0
    }
  ]
}