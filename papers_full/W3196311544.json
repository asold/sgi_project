{
  "title": "GapPredict – A Language Model for Resolving Gaps in Draft Genome Assemblies",
  "url": "https://openalex.org/W3196311544",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2099995848",
      "name": "Eric Chen",
      "affiliations": [
        "Canada's Michael Smith Genome Sciences Centre"
      ]
    },
    {
      "id": "https://openalex.org/A2143375318",
      "name": "Justin Chu",
      "affiliations": [
        "Canada's Michael Smith Genome Sciences Centre"
      ]
    },
    {
      "id": "https://openalex.org/A2105918414",
      "name": "Jessica Zhang",
      "affiliations": [
        "Canada's Michael Smith Genome Sciences Centre"
      ]
    },
    {
      "id": "https://openalex.org/A2149438968",
      "name": "René L. Warren",
      "affiliations": [
        "Canada's Michael Smith Genome Sciences Centre"
      ]
    },
    {
      "id": "https://openalex.org/A736109251",
      "name": "Inanc Birol",
      "affiliations": [
        "Canada's Michael Smith Genome Sciences Centre"
      ]
    },
    {
      "id": "https://openalex.org/A2099995848",
      "name": "Eric Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2143375318",
      "name": "Justin Chu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2105918414",
      "name": "Jessica Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2149438968",
      "name": "René L. Warren",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A736109251",
      "name": "Inanc Birol",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W6682132143",
    "https://openalex.org/W2118020555",
    "https://openalex.org/W2054211501",
    "https://openalex.org/W2021630037",
    "https://openalex.org/W2949791539",
    "https://openalex.org/W2790102940",
    "https://openalex.org/W2046192291",
    "https://openalex.org/W2156798505",
    "https://openalex.org/W2336509392",
    "https://openalex.org/W2198606573",
    "https://openalex.org/W3022783334",
    "https://openalex.org/W179875071",
    "https://openalex.org/W6713134421",
    "https://openalex.org/W1767772592",
    "https://openalex.org/W2589379462",
    "https://openalex.org/W2107772251",
    "https://openalex.org/W6674561012",
    "https://openalex.org/W1793987388",
    "https://openalex.org/W6679436768",
    "https://openalex.org/W2120902911",
    "https://openalex.org/W2132546867",
    "https://openalex.org/W1255676896",
    "https://openalex.org/W2105067980",
    "https://openalex.org/W2051039710",
    "https://openalex.org/W1994568187",
    "https://openalex.org/W2156226201",
    "https://openalex.org/W6631190155",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2108234281",
    "https://openalex.org/W6638749077",
    "https://openalex.org/W3041800561",
    "https://openalex.org/W2102619694",
    "https://openalex.org/W2953384591",
    "https://openalex.org/W2130942839",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W4394666350",
    "https://openalex.org/W4299518610",
    "https://openalex.org/W1828163288"
  ],
  "abstract": "Short-read DNA sequencing instruments can yield over 10<sup>12</sup> bases per run, typically composed of reads 150 bases long. Despite this high throughput, de novo assembly algorithms have difficulty reconstructing contiguous genome sequences using short reads due to both repetitive and difficult-to-sequence regions in these genomes. Some of the short read assembly challenges are mitigated by scaffolding assembled sequences using paired-end reads. However, unresolved sequences in these scaffolds appear as \"gaps\". Here, we introduce GapPredict - An implementation of a proof of concept that uses a character-level language model to predict unresolved nucleotides in scaffold gaps. We benchmarked GapPredict against the state-of-the-art gap-filling tool Sealer, and observed that the former can fill 65.6% of the sampled gaps that were left unfilled by the latter with high similarity to the reference genome, demonstrating the practical utility of deep learning approaches to the gap-filling problem in genome assembly.",
  "full_text": "GapPredict – A Language Model for\nResolving Gaps in Draft Genome\nAssemblies\nEric Chen , Justin Chu, Jessica Zhang,\nRen/C19e L. Warren , and Inanc Birol\nAbstract— Short-read DNA sequencing instruments can yield over 1012 bases per\nrun, typically composed of reads 150 bases long. Despite this high throughput,de\nnovo assembly algorithms have difﬁculty reconstructing contiguous genome\nsequences using short reads due to both repetitive and difﬁcult-to-sequence\nregions in these genomes. Some of the short read assembly challenges are\nmitigated by scaffolding assembled sequences using paired-end reads. However,\nunresolved sequences in these scaffolds appear as “gaps”. Here, we introduce\nGapPredict – An implementation of a proof of concept that uses a character-level\nlanguage model to predict unresolved nucleotides in scaffold gaps. We\nbenchmarked GapPredict against the state-of-the-art gap-ﬁlling tool Sealer, and\nobserved that the former can ﬁll 65.6% of the sampled gaps that were left unﬁlled\nby the latter with high similarity to the reference genome, demonstrating the\npractical utility of deep learning approaches to the gap-ﬁlling problem in genome\nassembly.\nIndex Terms— Biology and genomics, draft genome, language models, deep\nlearning, NLP, neural networks\nÇ\n1I NTRODUCTION\nTHE emergence of next-generation, high-throughput genome\nsequencing technologies has revolutionized life sciences. In next-\ngeneration sequencing, state-of-the-art instruments read genomes\nat high-depth, but yield relatively short (Illumina, /C24150 bp) indi-\nvidual sequence segments “reads”, providing unprecedented vol-\numes of sequencing data [1]. In order to reconstruct the input\ngenomes, these short sequencing reads need to be assembled\ntogether and unbiased genome assemblies are performed de novo –\nwithout the use of a reference genome [2]. De novo genome assem-\nbly remains an open problem, with leading algorithms in the ﬁeld\nusually yielding partial and incomplete genome sequences [3].\nDe novo assembly algorithms identify partial and unambiguous\nread-to-read overlaps to merge and extend the reads into contigu-\nous sequences, or contigs. Many tools, such as ABySS [4] and\nSPAdes [5], are designed to perform de novo assembly on a set of\nshort paired-end reads. Typically, paired-end reads are short\nsequences ( < 250 bp) generated from the two ends of a DNA frag-\nment several hundred bases in length.\nFor complex genomes such as the human genome, although de\nnovo assemblers have successfully produced draft genome assem-\nblies, they are incomplete [4]. Often, these de novo assemblies con-\ntain many gaps, which are regions of unknown nucleotide\nsequence [3], [4]. De novo assemblers generate gaps during the pro-\ncess of scaffolding, where ﬂanking sequences are inferred to follow\neach other. Still, precise sequence content between the ﬂanking\nregions may remain undetermined. Gaps are caused by factors\nsuch as local depressions in the read coverage depth resulting in\nmissed read-to-read overlaps and are often also caused by the\ninability of short reads to resolve repetitive sequences in these\nregions [6]. Filling gaps in de novo assemblies improves the quality\nof draft genomes, which has implications for downstream analyses\nsuch as structural variation identiﬁcation [7], [8], [9], [10] and gene\nannotation [6].\nGap-ﬁlling is a well-studied problem, and there are established\ntools, such as Sealer [6] and GAPPadder [11], that provide solutions,\nalbeit with varied performance, which are inﬂuenced by many of the\nintrinsic factors noted above and limitations associated with their\nimplementation. For example, Sealer is reported to ﬁll 50.8% of about\n240,000 gaps in a human genome assembly, and 13.8% of about 3 mil-\nlion gaps in a white spruce genome assembly draft [6]. Gap-ﬁlling\ntools tend to use greedy algorithms to solve the gap-ﬁlling problem\n[6], [11]. Greedy algorithms are limited by their rigid heuristics, and\nmay be unable to fully exploit all the information contained in short\nread sequencing data. As a result, these state-of-the-art tools still leave\nmany gaps unﬁlled during assembly of complex genomes. To better\nexploit short read data, we investigated a different paradigm to the\ngap-ﬁlling problem, using a deep learning approach.\nDeep learning is the use of neural networks – data-driven, tun-\nable functions – to allow computers to extract features from a data-\nset and make predictions on similar data [12]. Deep learning has\nalready seen successful application in computational biology, espe-\ncially in sequence classiﬁcation tasks [13], [14], [15], [16]. However,\nfew applications of deep learning in computational biology seem\nto exist for sequence prediction. One such application, HELEN\n[17], uses a single recurrent neural network trained on read-to-\nassembly alignment summary statistics obtained from MarginPol-\nish [17] to ﬁx base assembly errors in long read assembly drafts.\nThe gap-ﬁlling problem can be framed as a sequence prediction\nproblem, as the sequence preceding the gap may provide sufﬁcient\ncontext to predict the gap sequence itself. We note that the gap-ﬁll-\ning problem typically utilizes large volumes of data to represent the\nsequence content of gaps - an ideal condition to leverage deep learn-\ning approaches [12].\nOur objective with this study is to assess the suitability of super-\nvised deep learning algorithms for the gap-ﬁlling problem, with\nrespect to how accurately gaps are ﬁlled, and establish a baseline\naccuracy. To explore this paradigm, we introduce GapPredict, a\nproof of concept character-level language model for ﬁlling gaps in\ndraft genome assemblies. Character level language models predict\nthe most likely character from a corpus of characters after receiving\na sequence of characters from that corpus as context [18].\nIn this study, we benchmarked the gap-ﬁlling performance of\nGapPredict against Sealer [6] and GAPPadder [11] – two scalable,\nheuristics-based gap-ﬁlling tools. We observed that GapPredict com-\npares favorably to both Sealer and GAPPadder with respect to the\nquality of ﬁlled gaps, but could not scale to efﬁciency for a genome-\nwide application. This demonstrates that deep learning may be a via-\nble approach to at least complement the gap-ﬁlling task in genome\nassembly.\n2I MPLEMENTATION\n2.1 Overview\nGapPredict takes two ﬁles as input – a FASTA ﬁle containing the\ntwo sequences ﬂanking a given gap (henceforth referred to as\nﬂanks or ﬂanking sequences), and a FASTQ ﬁle containing paired-\nend reads mapping to the ﬂanks of the gap. Note that we imposed\nno constraints on input ﬂank length, gap length, or read length.\nThe reads and their reverse-complements are used to train a lan-\nguage model. Provided that the gap is shorter than the fragment\nlength of the reads, the reads in the FASTQ ﬁle collectively span\nboth the gap ﬂanks and the gap completely. Thus, after training on\n/C15 The authors are with the Canada’s Michael Smith Genome Sciences Centre, BC Can-\ncer, Vancouver, BC V5Z 4S6, Canada. E-mail: {ericchen, jczhang97}@alumni.ubc.\nca, {cjustin, rwarren, ibirol}@bcgsc.ca.\nManuscript received 17 Jan. 2021; revised 26 Aug. 2021; accepted 30 Aug. 2021. Date of\npublication 3 Sept. 2021; date of current version 8 Dec. 2021.\n(Corresponding Author: Ren /C19e Warren.)\nDigital Object Identiﬁer no. 10.1109/TCBB.2021.3109557\n2802 IEEE/ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS, VOL. 18, NO. 6, NOVEMBER/DECEMBER 2021\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nthe reads, GapPredict should have sufﬁcient data to ﬁll the gap in\neither the forward or reverse-complement direction if given a ﬂank\nas context. On the other hand, for gaps noticeably longer than the\nsequence fragment length, GapPredict is not expected to make\naccurate predictions.\nFollowing training, GapPredict uses its language model to\nrecursively predict the sequence in a given gap using one of the\nﬂank sequences as its initial context. Both the forward and reverse-\ncomplement of the gap can be predicted by GapPredict, as the\nmodel may predict one direction better than the other (Fig. 1).\n2.2 Language Model Architecture\nWe implemented the GapPredict model using the Keras framework\n(v2.2.4; Chollet F; [https://github.com/keras-team/keras]) and Ten-\nsorﬂow [19]. The GapPredict model architecture consists of three\nsequential layers (Fig. S1, which can be found on the Computer Society\nDigital Library at http://doi.ieeecomputersociety.org/10.1109/\nTCBB.2021.3109557.). First, each base in the input sequence, repre-\nsented as a one-hot vector, is encoded as a word vector by an embed-\nding layer. Next, the resulting sequence of word vectors is fed into a\nlong short-term memory (LSTM). An LSTM was chosen as this archi-\ntecture has been shown to offer good performance on tasks involving\nlong sequences [20], [21], which we consider gap-ﬁlling to be. Finally,\nthe LSTM state is fed into a fully connected layer of neurons (a “dense\nlayer” [19]). The output of this layer is a vector of length 4, which is\nnormalized by the softmax function. Each value in this output vector\ncan be interpreted as the probability that the next base is one of the\nfour corresponding deoxyribonucleotides (A, C, G, T). We optimized\nthis model using Adam [22], which is known to be a good out-of-the-\nbox function. Our loss function was categorical cross-entropy, as each\niteration of our sequence prediction algorithm is a multi-class classiﬁca-\ntion task.\n2.3 Language Model Training\nThe training protocol for the GapPredict language model follows a\nfour-step cycle. At each training iteration, we ﬁrst randomly sam-\nple a batch of reads with replacement (Fig. S2, available online).\nNext, we randomly choose a length k between klow and khigh, two\nhyperparameters, and extract a random k þ 1-mer from each read\nin the batch (Fig. S3, available online). We then compute the cate-\ngorical cross-entropy loss for predicting the k þ 1st base, given the\nﬁrst k bases and adjusts the model parameters accordingly (Fig. S4,\navailable online).\nAt the end of every epoch, to inform early stopping, we com-\npute the validation loss as follows. For a given ﬂank of length f,\nwe take the ﬁrst x bases (for all x 2½ klow;f /C0 1/C138 ) and compute the\ncategorical cross-entropy loss for predicting the x þ 1st base given\nthe ﬁrst x bases (Fig. S5, available online). In essence, x increases\niteratively from klow to f /C0 1. The validation loss is the sum of the\nloss for predicting the bases of every ﬂank divided by the sum of\nthe ﬂank lengths.\nOur validation loss metric measures a model’s ability to predict\neach ﬂank and its reverse-complement. We rationalized that if our\nmodel was capable of correctly predicting the next base along each\nﬂank and on both DNA strands, then it is likely to have encoded\ninformation to predict the gap as well.\n2.4 Gap Sequence Prediction\nAfter training the model for a given gap, we predict the nucleotide\nsequence of the associated gap. Each gap is predicted with beam\nsearch using both the ﬂanking sequence in the forward direction\nand the ﬂanking sequence in the reverse-complement direction\n[23] (Fig. S6, available online).\nAs described above, each base prediction has an associated\nprobability score for how likely the next base is. Thus, taking the\nlog-sum of these probabilities gives us a metric for how conﬁdent\nour model is for the entire sequence it outputs. Beam search pro-\nvides a scalable and robust, albeit greedy, method of searching for\nthe output sequence with minimal magnitude of log-sum\nprobability.\nAvailability: Source code is available at: https://github.com/\nbcgsc/GapPredict/releases/tag/v1.0b.\n3M ETHODS\nRefer to Fig. S7, available online, for an overview of our pipeline.\n3.1 Gap Data Acquisition\nWe used the de novo assembler ABySS (abyss-pe v2.1.5) [4] to\nassemble the NA12878 human genome (Paired-end 250bp sequenc-\ning data downloaded from https://basespace.illumina.com, ﬂow\ncell H00DDBCXX), using a k-mer length of 144 bp. Then, we ran\nFig. 1.Overview of the GapPredict training and prediction process. During training (left panel), reads mapping to the ﬂanks of a gap are used to train a model capable of\npredicting the next base given an arbitrarily long input sequence. During prediction (right panel), one of the ﬂanks of a gap (in this case, the left ﬂank) is fed into the model\nto predict the ﬁrst base of the gap, providing more context for the model to predict subsequent bases. Notice that if the gap is sufﬁciently small, paired-end reads aligning\nto the ﬂanks should cover the entire gap when the coverage depth is high enough.\nIEEE/ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS, VOL. 18, NO. 6, NOVEMBER/DECEMBER 2021 2803\nSealer (abyss-sealer v2.1.5) [6] on our draft assembly to close its\ngaps. From the Sealer output, we randomly selected 900 gaps that\nit ﬁlled (set 1) and 900 gaps that it failed to ﬁll (set 2). In our tests,\nwe required the gap ﬂanks to be represented by 500 bp sequences,\nhave unambiguous alignments in the reference human genome,\nand represent bona ﬁde gaps as assessed with respect to the refer-\nence genome. The gap ﬂank lengths were chosen to be 500 bp\nbecause in most cases, this length should be sufﬁcient to uniquely\nidentify the gap associated with each ﬂank pair. After ﬁltering out\nfalse gaps and gaps with shorter or ambiguously aligned ﬂanks,\nwe were left with 434 gaps in set 1 and 416 gaps in set 2.\nFrom each gap, we extracted 500 bp ﬂanks from both sides to\nconstruct a FASTA ﬁle using a combination of in-house scripts,\nSAMtools (v1.9) [24], and BEDtools (v2.27.1) [25]. Finally, we used\nthe BioBloomMIMaker utility from BioBloom Tools (v2.3.2) [26] to\nconstruct a multi-index Bloom ﬁlter for each ﬂank. Next, using Bio-\nBloomMICategorizer [26] we built a FASTQ ﬁle by selecting any\nread, along with its mate, that mapped to a gap ﬂank sequence. For\neach gap, this pair of FASTA and FASTQ ﬁles was the input used\nto run GapPredict.\n3.2 GapPredict Conﬁgurations\nIn our tests, we initialized our GapPredict models with an embed-\nding vector length of 128 and 512 LSTM units. Our models were\ntrained over at most 1000 epochs with a batch size of 128. Early\nstopping was employed on validation loss with a patience of 200\nepochs. klow was set to 52 bp and khigh was set to the length of the\nshortest read of each training batch.\nTo predict the sequence of a given gap, our model selected each\nof the 500 bp ﬂanks as input and predicted the next 750 bases using\na beam size of 64. Since gaps in our assembly were estimated to be\nno longer than 200 bp by ABySS, the prediction length of 750 bp\nwas chosen as it accounts for both the gap and most of the recipro-\ncal ﬂank. The beam size of 64 was chosen as we observed it pro-\nvided a large enough search space. Both parameters can be freely\nreconﬁgured. We deﬁne the reciprocal ﬂank as the ﬂank on the\nopposite side of the input ﬂank.\n3.3 Reference Gap Sequence Acquisition\nIn order to quantify the performance of the tools we benchmarked\n– GapPredict, Sealer, and GAPPadder – we compared the sequen-\nces they predicted to sequences we extracted from the human\ngenome reference HG38. To build this “ground truth” from HG38,\nfor each gap in our benchmarks, we aligned its ﬂanking sequences\nto HG38 using BWA-MEM (v0.7.17) [27] and SAMtools [24]. We\nthen used BEDtools bamtobed and BEDtools getfasta [25] to obtain\nthe sequence of both the gap and its ﬂanks in HG38. Sequences\nfrom HG38 were used solely to evaluate the performance of each\ngap-ﬁlling tool and were not used for the gap-ﬁlling process.\n3.4 GapPredict Output Validation\nUsing Exonerate (v2.2.0) [28] we aligned GapPredict predictions to\nthe reference gap sequence and 100 bp of the reference reciprocal\nﬂank. We evaluated these alignments with four metrics deﬁned in\nSection 3.5: sequence percent identity, target sequence percent cov-\nerage, query sequence percent coverage, and sequence percent cor-\nrectness, where “query” refers to GapPredict predictions and\n“target” refers to the reference sequence for alignment.\nOf course, in a typical use case, one would not have a reference\nfor evaluating ﬁlled gaps. Thus, we needed a heuristic for deciding\nif a gap is likely to be correctly ﬁlled (“pass”). We reasoned that an\naccurately predicted gap sequence is the most likely sequence con-\ntext to yield an accurate prediction of the reciprocal ﬂank [29].\nSince we know the sequence of both gap ﬂanks, we deﬁne a predic-\ntion to be a “pass” if the ﬁrst 100 bp of the reciprocal ﬂank sequence\naligns to GapPredict’s prediction for the gap with a sequence\npercent correctness over a threshold (default: 70%), and a “fail”\notherwise. This sequence percent correctness may be used in place\nof a conﬁdence score.\nThe reciprocal ﬂank alignment start position also determines\nthe stop position of the gap itself. We can thus use the start of\nGapPredict’s prediction and the start of reciprocal ﬂank alignments\nto extract gap sequences predicted by GapPredict. In addition,\nsince GapPredict outputs one prediction for each of the two ﬂank-\ning sequences, the best and likely more accurate prediction can be\nchosen based on the alignment with the highest sequence identity\nto its respective reciprocal ﬂank.\nUsing Seaborn (v0.9.0; Waskom M et al. ; [https://github.com/\nmwaskom/seaborn]), we compared target sequence percent cor-\nrectness against query sequence percent coverage for each gap we\npredicted. We also determined the probability density for these\ntwo variables.\n3.5 Gap Prediction Validation Metrics\nSequence percent identity is the percentage of matches in the align-\nment to the total number of aligned positions, including gaps, from\na given sequence (deﬁnition L2 in [30]).\nTarget sequence coverage is the quotient between the number of\nreference sequence bases aligned to the prediction and the total ref-\nerence sequence length. Query sequence coverage is the quotient\nbetween the number of bases from the prediction aligned to the ref-\nerence sequence and the number of bases from the start of our pre-\ndicted gap to the end of our predicted gap. Our predicted gap is\ndeﬁned to end at the maximum reference base index among where\nthe gap alignment ends and the reciprocal ﬂank alignment begins.\nIn essence, target sequence coverage provides a measure of how\nmuch of the reference sequence is covered by GapPredict’s predic-\ntion, whereas query sequence coverage provides a measure of how\nmany bases predicted by GapPredict are actually related to the ref-\nerence sequence.\nLastly, sequence percent correctness is the product of sequence\npercent identity and sequence percent coverage. This metric was\ncomputed to aggregate sequence percent identity and sequence\ncoverage.\nThe combination of target sequence correctness and query\nsequence coverage characterizes the ﬁll status of gaps. For exam-\nple, high target sequence correctness and high query sequence cov-\nerage indicates that GapPredict closely matched the reference gap\nin both sequence accuracy and completeness. On the other hand,\nhigh target sequence correctness but low query sequence coverage\ndenotes that GapPredict’s gap closely aligns with that of the refer-\nence in accuracy but may be incomplete.\n3.6 Sealer Output Validation\nAlthough Sealer can be run on the whole NA12878 assembly and\nassociated read set, we ran Sealer on each gap from sets 1 and 2\nindividually using only the reads GapPredict utilized as input for\nits gap predictions. This was done to conﬁrm that using only reads\nmapping to the gap (to be consistent with GapPredict’s workﬂow),\nrather than all reads in the NA12878 dataset, had negligible effect\non Sealer’s gap-ﬁlling performance.\nWe looked at the target percent correctness of Sealer’s output\ngaps when compared to the reference, as reported by Exonerate\n[28]. This was done to benchmark the performance of heuristic\nalgorithms. Finally, we compared the target percent correctness of\nboth GapPredict and Sealer for each gap we predicted, and deter-\nmined the probability density for these two variables.\n3.7 GAPPadder Output Validation\nWe ran GAPPadder (base version on https://github.com/simonc-\nchu/GAPPadder commit a359750) [11] using the entire NA12878\nassembly and reads, rather than on each gap from sets 1 and 2\n2804 IEEE/ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS, VOL. 18, NO. 6, NOVEMBER/DECEMBER 2021\nindividually. This is because GAPPadder searches for discordant\nreads [11], which would not be present for gaps taken in isolation.\nAfter GAPPadder ﬁlled all gaps it identiﬁed in the draft assembly,\nwe used BWA-MEM [27] to map GAPPadder’s output to HG38 ref-\nerence sequences for gaps in sets 1 and 2. We chose the best align-\nment when a gap ﬁlled by GAPPadder mapped ambiguously to\nthe reference genome.\nSimilar to Sealer, we looked at the target percent correctness of\nGAPPadder’s output gaps when compared to the reference. We\nalso compared the target percent correctness of GapPredict and\nGAPPadder’s outputs and determined the probability density for\nthese two variables. Query coverage was not computed for either\nSealer or GAPPadder because the metric was expected to be high\nfor both tools.\n3.8 QUAST Evaluation\nWe ran the sequence quality assessment tool QUAST [3] (v5.0.2 -m\n0 -t 8) separately on predicted sequence outputs from gaps closed\nin common between Sealer, GAPPadder, and GapPredict using\nHG38 gap sequences as a reference.\n4R ESULTS AND DISCUSSION\n4.1 GapPredict Output Validation\nBecause GapPredict makes two predictions per gap, one in the for-\nward and one in the reverse-complement direction, running the\ntool on 434 gaps in set 1 and 416 gaps in set 2 resulted in 868 and\n832 predictions for the two sets, respectively. Regardless of how\ngood the prediction is, GapPredict will always output a candidate\nsequence for each gap. Of these predictions, 78.7% in set 1 and\n65.2% in set 2 were classiﬁed as a “pass”. In addition, for the 434\ngaps in set 1, 87.3% had at least one pass in the prediction pair and\n70.0% had two passes. For the 416 gaps in set 2, 78.4% had at least\none pass in the prediction pair and 52.2% had two passes. The pro-\nportion of passes being lower in set 2 reinforces the notion that\nthese gaps may be more challenging to ﬁll.\nFor gap predictions classiﬁed as a “pass” in both set 1 (Fig. 2a)\nand set 2 (Fig. 3a), there was a signiﬁcant number of predictions\nwith high target percent correctness and query percent coverage\n(top right corner). Gap predictions classiﬁed as a “fail” in both set\n1 (Fig. 2b) and set 2 (Fig. 3b), on the other hand, formed two types\nof clusters – clusters of high target percent correctness (right side),\nand clusters of both low target percent correctness and low query\npercent coverage (bottom left corner). Set 2 also contained a third\ncluster at high target percent correctness and low query percent\ncoverage. Metrics for target percent correctness only are summa-\nrized in Fig. S8, available online, and Table S1, available online.\nNote that Figs. 2b and 3b both have multi-layered contours at\nthe bottom left corner, despite the scatter plot being highly concen-\ntrated at this location. 56.8% of points for Fig. 2b and 54.3% of\npoints for Fig. 3b are located at these corners. Because kernel den-\nsity estimations provide a probability density for our scatter plot\nFig. 2.Comparison between query percent coverage and target percent correctness for gaps which Sealer was able to ﬁll (set 1). (a) Passing predictions. (b) Failing pre-\ndictions. Overall, 78.7% of 868 predictions passed. Colour bars show the density at each level of the contour plot. Kernel density estimation was plotted using default\nparameters. The ﬁgures were generated using Seaborn (v0.9.0).\nFig. 3.Comparison between query percent coverage and target percent correctness for gaps which Sealer was not able to ﬁll (set 2). (a) Passing predictions. (b) Failing predic-\ntions. Overall, 65.2% of 832 predictions passed. Colour bars show the density at each level of the contour plot. Kernel density estimation was plottedusing default parameters.\nIEEE/ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS, VOL. 18, NO. 6, NOVEMBER/DECEMBER 2021 2805\n[31], the multi-layered contours reﬂect the high probability of gaps\nclassiﬁed as a “fail” being predicted with target percent correctness\nand query percent coverage close to 0.\nWhen gap predictions are categorized as a “pass”, they tend to\nhave high target percent correctness and high query percent cover-\nage (Table S1, available online). This demonstrates that models\nthat manage to predict the reciprocal ﬂank are also likely to predict\nthe gap itself. Thus, our heuristic for good predictions is valuable\nfor identifying low quality gap predictions. However, because it is\npossible that our models predict the gap correctly but the recipro-\ncal ﬂank incorrectly, we may miss some high-quality gap predic-\ntions. The clusters of “failed” predictions with high target percent\ncorrectness and high query percent coverage in Figs. 2b and 3b\nillustrate this.\n4.2 Performance Against Other Tools\nSealer’s ability to ﬁll gaps did not particularly change when Sealer\nwas executed on gaps using only reads mapping to the gap and its\nﬂanks, instead of all reads in the NA12878 dataset (Fig. 4). Rather\nthan ﬁlling all 434 gaps from set 1 and none of the 416 gaps from\nset 2, as with the latter approach, Sealer ﬁlled 430 gaps (99.1%)\nfrom set 1 and 13 gaps (3.1%) from set 2 with the former approach.\nGaps ﬁlled by Sealer had over 90% target correctness (Fig. 4). We\nthink the few outliers with low target percent correctness may be\ndue to low target percent coverage from abnormally large reference\ngap sequences. These erroneous gap sequences may have been due\nto differences between the HG38 consensus genome and the\nNA12878 genome, which resulted in the gap ﬂanking sequences\naligning incorrectly.\nGAPPadder ﬁlled 425 and 411 gaps from sets 1 and 2 (97.9%\nand 98.8%), but with higher variance on target percent correctness\n(Fig. 5). The difference in the number of gaps ﬁlled, particularly in\nset 2, and the difference in percent correctness may be explained\nby GAPPadder using a different gap-ﬁlling algorithm than Sealer\n[6], [11]. However, the overall lower accuracy of set 2 gaps reinfor-\nces the notion that gaps in set 2 are more difﬁcult to resolve.\nFor each gap, we also compared the target percent correctness\nbetween the ﬁlled gap sequences from Sealer and GapPredict\n(Fig. 6), and from GAPPadder and GapPredict (Fig. 7). In both\nFigs. 6 and 7, we assigned a target percent correctness of 0% to\ngaps which Sealer or GAPPadder were unable to determine. We\nsummarize the target percent correctness for all tools in Table S1,\navailable online.\nWe note that for gaps in set 1, there is a cluster at high target\npercent correctness for both GapPredict and Sealer, and a cluster at\nlow target percent correctness for both tools (Fig. 6). For gaps in set\n2, there is a cluster at low target percent correctness for both tools\nand a cluster at high target percent correctness for GapPredict only.\nFrom Fig. 7, we note that for both gaps in sets 1 and 2, there is a\ncluster at high target percent correctness for both GapPredict and\nGAPPadder, and a cluster at low target percent correctness for\nboth tools. In addition, both ﬁgures show outlier gaps where one\ntool outperformed the other in percent correctness (Figs. 6a, 7a,\nand 7b).\nOverall, for 78.9% of the 434 gaps that Sealer originally could ﬁll\n(set 1) and 65.6% of the 416 gaps that Sealer originally could not ﬁll\n(set 2), GapPredict produced at least one prediction with a target\npercent correctness of at least 90%, a query percent coverage of at\nleast 90%, and a classiﬁcation of “pass”. Generally, we ﬁnd the gap\nsequences predicted by GapPredict to be ( /C241.6 to 1.8x) less accu-\nrate compared to those resolved by Sealer and GAPPadder, with\nthe latter two heuristic-based methods yielding sequences having\nless than 1% base error (Table S2, available online). This is in con-\ntrast with the /C241.5% base error on those same predictions gener-\nated with the former, machine-learning based method. This is\nperhaps not unexpected given the GapPredict’s paradigm to\nresolving gap sequences. We expect the sequence accuracy to\nimprove in the future, as machine learning algorithms and models\nimprove.\n4.3 Model Performance Optimization\nWith GapPredict, we demonstrate that a deep learning approach\nshows promise for de novo assembly gap predictions. Our analyses\nshowed that GapPredict could predict at least 60% of gap sequen-\nces with over 90% target percent correctness and query percent\ncoverage.\nSome of GapPredict’s model hyperparameters, such as batch\nsize and embedding vector length, were chosen without optimiza-\ntion. Other hyperparameters, such as the number of LSTM cells\nand the minimum and maximum training k-mer lengths were\nexplored by comparing validation loss and validation accuracy\nbetween models trained with different values of these hyperpara-\nmeters (data not shown). The GapPredict model architecture was\nbased on a simple character-level language model [32]. Further\ntuning of hyperparameters and exploration of model architectures\nmay produce a better performing model, but be more expensive to\ncompute. We did not investigate the impact of such changes on\nmodel performance, however.\nLastly, within each training iteration (but not among every\ntraining iteration), the sequences GapPredict trains on are of uni-\nform length. It is possible that allowing these sequences to have\nvariable length could improve training, provided that the length\nis within the minimum and maximum length hyperparameters.\nFig. 4. Target percent correctness for gaps in set 1 (ﬁlled, n¼ 430) and set 2\n(unﬁlled, n¼ 13) that were ﬁlled by Sealer when run on each individual gap using\nonly read pairs anchored to the ﬂanks. From either set, gaps that Sealer did not ﬁll\nare excluded from the ﬁgure.\nFig. 5. Target percent correctness for gaps in set 1 (ﬁlled, n¼ 425) and set 2\n(unﬁlled, n¼ 411) that were ﬁlled by GAPPadder when run using the full NA12878\ndraft assembly and all reads in the NA12878 dataset.From either set, gaps that\nGAPPadder did not ﬁll are excluded from the ﬁgure.\n2806 IEEE/ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS, VOL. 18, NO. 6, NOVEMBER/DECEMBER 2021\nThis would prevent each iteration from being biased to a speciﬁc\ninput length.\n4.4 Model Scalability\nWe trained GapPredict models and ﬁlled gaps using these models\non a system with two Xeon Silver 4116’s, 256 GB RAM, and eight\nNVIDIA 1080Ti’s. Each model used a single GPU for training. Gap-\nPredict models take approximately three minutes to predict a gap\nsequence using beam search with a beam width of 64. In compari-\nson, it takes approximately 50 minutes to train a model on a gap\nwith about 500 reads mapping to its ﬂanks. At most 10 GB of GPU\nRAM was used. Table S3, available online, shows more detailed\nperformance metrics for the three tools used. Although we can par-\nallelize model training by training different models on different\nGPUs, the lengthy model training time makes it difﬁcult for Gap-\nPredict to scale to the large number of gaps typically present in the\ndraft assembly of larger genomes.\nIn order to improve runtime, we could employ a stricter\npatience. With our current patience of 200 epochs, model training\noften extends past 500 epochs for only a slight improvement in vali-\ndation loss. We think that the robustness of beam search with a\nlarger beam width can compensate for shorter training. In addition,\nwe could begin training using weights from a pre-trained GapPre-\ndict model [33].\nOne ﬁnal improvement to our model may be to redesign it to\ntrain on the entire read set. Such a model could consider any gap\nsequence from the source assembly as it encodes data from the\nentire assembly. This would improve model reusability as a single\nmodel could be used to predict any set of gaps for the assembly in\nparallel, similar in idea to HELEN [17]. In addition, this design\nwould remove the need for obtaining read data for each gap indi-\nvidually, which takes several hours.\n5C ONCLUSION\nWith GapPredict, we demonstrate that deep learning is applicable\nto the de novo genome assembly gap-ﬁlling problem. Character-\nlevel language models indeed seem capable of encoding the infor-\nmation of a gap sequence and its ﬂanks solely by training models\non sequence short read data, and use contextual sequencing infor-\nmation for predictions. Further, when such models manage to pre-\ndict the sequence from the reverse DNA strand, they tend to\npredict the gap with good accuracy. This provides a simple way of\nﬁltering out potentially low-quality gap predictions.\nAlthough GapPredict may scale poorly to the high volume of\ngaps in assemblies for large genomes ( >100k gaps for >3Gbp\ngenomes [6]), we think further improvements to speed it up and\nimprove its prediction performance are possible. In addition, Gap-\nPredict was able to provide accurate output (with respect to HG38)\nfor both gaps that Sealer or GAPPadder could ﬁll and gaps that\nthose tools could not ﬁll well or could not ﬁll at all. Deep learning\nmay therefore serve at least as a method to ﬁll gaps that heuristic\nmethods are unable to ﬁll, rather than being employed as the ﬁrst\nFig. 6.Comparison between percent correctness for gaps ﬁlled by GapPredict and percent correctness for gaps that Sealer ﬁlled when run on each individual gap. (a) Per-\ncent correctness for gaps in set 1. (b) Percent correctness for gaps in set 2. Gaps that Sealer did not ﬁll were assigned a percent correctness of 0%. Colour bars show the\ndensity at each level of the contour plot. Kernel density estimation was plotted using default parameters.\nFig. 7.Comparison between percent correctness for gaps ﬁlled by GapPredict and percent correctness for gaps ﬁlled by GAPPadder. (a) Percent correctness for gaps in\nset 1. (b) Percent correctness for gaps in set 2.Gaps that GAPPadder did not ﬁll were assigned a percent correctness of 0%. Colour bars show the density at each level\nof the contour plot. Kernel density estimation was plotted using default parameters.\nIEEE/ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS, VOL. 18, NO. 6, NOVEMBER/DECEMBER 2021 2807\nand foremost gap closing method. This may lessen the burden of\nrunning deep learning tools by decreasing the number of gaps that\nneed to be predicted. In the future, deep learning algorithms may\ncomplement the current arsenal of gap prediction utilities.\nACKNOWLEDGMENTS\nThe authors would like to thank Zhuyi Xue and the Birol lab for\ntheir support and ideas during development. This work was sup-\nported by the National Institutes of Health under Grant\n2R01HG007182-04A1. The content of this paper is solely the\nresponsibility of the authors, and does not necessarily represent\nthe ofﬁcial views of the National Institutes of Health or other fund-\ning organizations.\nREFERENCES\n[1] C. S. Pareek, R. Smoczynski, and A. Tretyn, “Sequencing technologies and\ngenome sequencing,” J. Appl. Genet., vol. 52, no. 4, pp. 413–435, Nov. 2011.\n[2] N. Nagarajan and M. Pop, “Sequence assembly demystiﬁed,” Nat. Rev.\nGenet., vol. 14, pp. 157–167, Mar. 2013.\n[3] A. Gurevich, V. Saveliev, N. Vyahhi, and G. Tesler, “QUAST: Quality\nassessment tool for genome assemblies,” Bioinformatics, vol. 29, no. 8,\npp. 1072–1075, Apr. 2013.\n[4] S. D. Jackman et al. , “ABySS 2.0: Resource-efﬁcient assembly of large\ngenomes using a bloom ﬁlter,” Genome Res., vol. 27, no. 5, pp. 768–777, May\n2017.\n[5] A. Bankevich et al. , “SPAdes: A new genome assembly algorithm and its\napplications to single-cell sequencing,” J. Comput. Biol., vol. 19, no. 5,\npp. 455–477, May 2012.\n[6] D. Paulino, R. L. Warren, B. P. Vandervalk, A. Raymond, S. D. Jackman,\nand I. Birol, “Sealer: A scalable gap-closing application for ﬁnishing draft\ngenomes,” BMC Bioinf., vol. 16, Jul. 2015, Art, no. 230.\n[7] D. Stoll et al. , “Genomic and epigenomic landscapes of adult de novo acute\nmyeloid leukemia,” N. Enl. J. Med., vol. 368, no. 22, pp. 2059–2074, May\n2013.\n[8] T. J. Pugh et al. , “The genetic landscape of high-risk neuroblastoma,” Nat.\nGenet., vol. 45, no. 3, pp. 279–284, Mar. 2013.\n[9] K. G. Roberts et al. , “Genetic alterations activating kinase and cytokine\nreceptor signaling in high-risk acute lymphoblastic leukemia,” Cancer Cell,\nvol. 22, no. 2, pp. 153–166, Aug. 2014.\n[10] S. Yip et al. , “Concurrent CIC mutations, IDH mutations, and 1p/19q loss\ndistinguish oligodendrogliomas from other cancers,” J. Pathol., vol. 226,\nno. 1, pp. 7–16, Jan. 2012.\n[11] C. Chu, X. Li, and Y. Wu, “GAPPadder: A sensitive approach for closing\ngaps on draft genomes with short sequence reads,” BMC Genom., vol. 20,\nJun. 2019, Art. no. 426.\n[12] S. Webb, “Deep learning for biology,” Nature, vol. 554, pp. 555–557, Feb.\n2018.\n[13] G. Pollastri and A. McLysaght, “Porter: A new, accurate server for protein\nsecondary structure prediction,” Bioinformatics, vol. 21, no. 8, pp. 1719–\n1720, Apr. 2005.\n[14] G. Pollastri, D. Przybylski, B. Rost, and P. Baldi, “Improving the prediction\nof protein secondary structure in three and eight classes using recurrent\nneural networks and proﬁles,” Proteins, vol. 47, no. 2, pp. 228–235, Mar.\n2002.\n[15] D. Quang and X. Xie, “DanQ: A hybrid convolutional and recurrent deep\nneural network for quantifying the function of DNA sequences,” Nucleic\nAcids Res., vol. 44, no. 11, Jun. 2016, Art. no. e107.\n[16] J. Zhou and O. G. Troyanskaya, “Predicting effects of noncoding variants\nwith deep learning–based sequence model,” Nat. Methods, vol. 12, no. 10,\npp. 931–934, Oct. 2015.\n[17] K. Shaﬁn et al. , “Nanopore sequencing and the shasta toolkit enable efﬁ-\ncient de novo assembly of eleven human genomes,” Nat. Biotechnol.,\nvol. 38, pp. 1044–1053, May 2020.\n[18] T. Mikolov, M. Karaﬁat, L. Burget, J. H. Cernocky, and S. Khudanpur,\n“Recurrent neural network based language model,” in Proc. Interspeech ,\nChiba, 2010, pp. 1045–1048.\n[19] M. Abadi et al. , “TensorFlow: A system for large-scale machine learning,”\nin Proc. 12th USENIX Symp. Oper. Syst. Des. Implementation , Savannah, 2016,\npp. 265–283.\n[20] S. Hochreiter, M. Heusel, and K. Obermayer, “Fast model-based protein\nhomology detection without alignment,” Bioinformatics, vol. 23, no. 14,\npp. 1728–1736, Jul. 2007.\n[21] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural Com-\nput., vol. 23, no. 14, pp. 1735–1780, Nov. 1997.\n[22] D. P. Kingma and J. L. Ba, “Adam: A method for stochastic optimization,”\n2014, arXiv:1412.6980.\n[23] A. Graves, “Sequence transduction with recurrent neural networks,” 2012,\narXiv:1211.3711.\n[24] H. Li et al. , “The sequence alignment/map format and SAMtools,” Bioinfor-\nmatics, vol. 25, no. 16, pp. 2078–2079, Jun. 2009.\n[25] A. R. Quinlan and I. M. Hall, “BEDTools: A ﬂexible suite of utilities for\ncomparing genomic features,” Bioinformatics, vol. 26, no. 6, pp. 841–842,\nMar. 2010.\n[26] J. Chu, H. Mohamadi, E. Erhan, J. Tse, R. Y. S. Chiu, and I. Birol,\n“Mismatch-tolerant, alignment-free sequence classiﬁcation using multiple\nspaced seeds and multiindex bloom ﬁlters,” in Proc. Nat. Acad. Sci. USA,\nvol. 117, no. 29, pp. 16961–16968, Jul. 2020.\n[27] H. Li, “Aligning sequence reads, clone sequences, and assembly contigs\nwith BWA-MEM,” 2013, arXiv:1303.3997.\n[28] G. S. C. Slater and E. Birney, “Automated generation of heuristics for bio-\nlogical sequence comparison,” BMC Bioinform., vol. 6, no. 31, Feb. 2005.\n[29] I. Sutskever, O. Vinyals, and Q. V. Le, “Sequence to sequence learning with\nneural networks,” in Proc. 27th Int. Conf. Neural Inf. Process. Syst. (NIPS’14) ,\nMontreal, vol. 2, 2014, pp. 3104–3112.\n[30] A. C. W. May, “Percent sequence identity; the need to be explicit,” Struc-\nture, vol. 12, no. 5, pp. 737–738, May 2004.\n[31] E. Parzen, “On estimation of a probability density function and mode,”\nAnn. Math. Statist., vol. 33, no. 3, pp. 1065–1076, Sep. 1962.\n[32] J. Brownlee, “How to develop word-based neural language models in\npython with keras,” Accessed: Jul. 14, 2019. [Online]. Available: https://\nmachinelearningmastery.com\n[33] J. Yosinski, J. Clune, Y. Bengio, and H. Lipson, “How transferable are fea-\ntures in deep neural networks?,” in Proc. 27th Int. Conf. Neural Inf. Process.\nSyst. (NIPS’14), Montreal, vol. 2, 2014, pp. 3320–3328.\n\" For more information on this or any other computing topic,\nplease visit our Digital Library at www.computer.org/csdl.\n2808 IEEE/ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS, VOL. 18, NO. 6, NOVEMBER/DECEMBER 2021",
  "topic": "Genome",
  "concepts": [
    {
      "name": "Genome",
      "score": 0.7008438110351562
    },
    {
      "name": "Sequence assembly",
      "score": 0.6586242318153381
    },
    {
      "name": "Computer science",
      "score": 0.5837213397026062
    },
    {
      "name": "Similarity (geometry)",
      "score": 0.5364482998847961
    },
    {
      "name": "Character (mathematics)",
      "score": 0.5321915149688721
    },
    {
      "name": "Scaffold",
      "score": 0.517233669757843
    },
    {
      "name": "Sequence (biology)",
      "score": 0.4969830811023712
    },
    {
      "name": "k-mer",
      "score": 0.4844219982624054
    },
    {
      "name": "State (computer science)",
      "score": 0.46808797121047974
    },
    {
      "name": "Computational biology",
      "score": 0.45736536383628845
    },
    {
      "name": "DNA sequencing",
      "score": 0.45142167806625366
    },
    {
      "name": "Reference genome",
      "score": 0.41187000274658203
    },
    {
      "name": "Artificial intelligence",
      "score": 0.34133589267730713
    },
    {
      "name": "Theoretical computer science",
      "score": 0.32756704092025757
    },
    {
      "name": "Algorithm",
      "score": 0.2896290421485901
    },
    {
      "name": "Biology",
      "score": 0.28267186880111694
    },
    {
      "name": "DNA",
      "score": 0.26483285427093506
    },
    {
      "name": "Programming language",
      "score": 0.2250766158103943
    },
    {
      "name": "Genetics",
      "score": 0.21239537000656128
    },
    {
      "name": "Gene",
      "score": 0.16161346435546875
    },
    {
      "name": "Image (mathematics)",
      "score": 0.12737995386123657
    },
    {
      "name": "Mathematics",
      "score": 0.10966488718986511
    },
    {
      "name": "Geometry",
      "score": 0.0
    },
    {
      "name": "Transcriptome",
      "score": 0.0
    },
    {
      "name": "Gene expression",
      "score": 0.0
    }
  ]
}