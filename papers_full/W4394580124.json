{
  "title": "Large language models in cryptocurrency securities cases: can a GPT model meaningfully assist lawyers?",
  "url": "https://openalex.org/W4394580124",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A4208843232",
      "name": "Arianna Trozze",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2284247414",
      "name": "Toby Davies",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2063875431",
      "name": "Bennett Kleinberg",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4284897027",
    "https://openalex.org/W4320854391",
    "https://openalex.org/W4320854235",
    "https://openalex.org/W4313445468",
    "https://openalex.org/W2966983573",
    "https://openalex.org/W1974991592",
    "https://openalex.org/W4320009668",
    "https://openalex.org/W4385067052",
    "https://openalex.org/W4376142582",
    "https://openalex.org/W4318977924",
    "https://openalex.org/W4389546930",
    "https://openalex.org/W3123590105",
    "https://openalex.org/W3011505293",
    "https://openalex.org/W4281557260",
    "https://openalex.org/W3139580003",
    "https://openalex.org/W2804807303",
    "https://openalex.org/W4380558781",
    "https://openalex.org/W4312341782",
    "https://openalex.org/W4375958664",
    "https://openalex.org/W3201100205",
    "https://openalex.org/W4232705161",
    "https://openalex.org/W4287327402",
    "https://openalex.org/W2795610411",
    "https://openalex.org/W4311253308",
    "https://openalex.org/W6600445788"
  ],
  "abstract": "Abstract Large Language Models (LLMs) could be a useful tool for lawyers. However, empirical research on their effectiveness in conducting legal tasks is scant. We study securities cases involving cryptocurrencies as one of numerous contexts where AI could support the legal process, studying GPT-3.5’s legal reasoning and ChatGPT’s legal drafting capabilities. We examine whether a) GPT-3.5 can accurately determine which laws are potentially being violated from a fact pattern, and b) whether there is a difference in juror decision-making based on complaints written by a lawyer compared to ChatGPT. We feed fact patterns from real-life cases to GPT-3.5 and evaluate its ability to determine correct potential violations from the scenario and exclude spurious violations. Second, we had mock jurors assess complaints written by ChatGPT and lawyers. GPT-3.5’s legal reasoning skills proved weak, though we expect improvement in future models, particularly given the violations it suggested tended to be correct (it merely missed additional, correct violations). ChatGPT performed better at legal drafting, and jurors’ decisions were not statistically significantly associated with the author of the document upon which they based their decisions. Because GPT-3.5 cannot satisfactorily conduct legal reasoning tasks, it would be unlikely to be able to help lawyers in a meaningful way at this stage. However, ChatGPT’s drafting skills (though, perhaps, still inferior to lawyers) could assist lawyers in providing legal services. Our research is the first to systematically study an LLM’s legal drafting and reasoning capabilities in litigation, as well as in securities law and cryptocurrency-related misconduct.",
  "full_text": "Vol.:(0123456789)\nArtificial Intelligence and Law (2025) 33:691–737\nhttps://doi.org/10.1007/s10506-024-09399-6\nORIGINAL RESEARCH\nLarge language models in cryptocurrency securities cases: \ncan a GPT model meaningfully assist lawyers?\nArianna Trozze1,2  · Toby Davies2,3 · Bennett Kleinberg2,4\nAccepted: 3 March 2024 / Published online: 8 April 2024 \n© The Author(s) 2024\nAbstract\nLarge Language Models (LLMs) could be a useful tool for lawyers. However, \nempirical research on their effectiveness in conducting legal tasks is scant. We \nstudy securities cases involving cryptocurrencies as one of numerous contexts \nwhere AI could support the legal process, studying GPT-3.5’s legal reasoning \nand ChatGPT’s legal drafting capabilities. We examine whether a) GPT-3.5 can \naccurately determine which laws are potentially being violated from a fact pattern, \nand b) whether there is a difference in juror decision-making based on complaints \nwritten by a lawyer compared to ChatGPT. We feed fact patterns from real-life cases \nto GPT-3.5 and evaluate its ability to determine correct potential violations from \nthe scenario and exclude spurious violations. Second, we had mock jurors assess \ncomplaints written by ChatGPT and lawyers. GPT-3.5’s legal reasoning skills \nproved weak, though we expect improvement in future models, particularly given \nthe violations it suggested tended to be correct (it merely missed additional, correct \nviolations). ChatGPT performed better at legal drafting, and jurors’ decisions were \nnot statistically significantly associated with the author of the document upon which \nthey based their decisions. Because GPT-3.5 cannot satisfactorily conduct legal \nreasoning tasks, it would be unlikely to be able to help lawyers in a meaningful way \nat this stage. However, ChatGPT’s drafting skills (though, perhaps, still inferior to \nlawyers) could assist lawyers in providing legal services. Our research is the first to \nsystematically study an LLM’s legal drafting and reasoning capabilities in litigation, \nas well as in securities law and cryptocurrency-related misconduct.\nKeywords Cryptocurrency · Securities law · Artificial intelligence (AI) · Large \nlanguage models (LLMs) · ChatGPT\nExtended author information available on the last page of the article\n692 A. Trozze et al.\n1 Introduction\nOne of the most promising advances in the field of AI in recent months has been \nimprovements in Large Language Models (LLMs), and one potential application \nof these is in conducting legal tasks. The public release of a user-friendly LLM in \nthe form of ChatGPT in November 2022 has amplified discussions surrounding \nsuch applications. Already, companies have sought to use AI-based tools to draft \nand file class action or other lawsuits (Kahana 2023). Similarly, attorneys have \nexperimented with using AI-based tools to automate some of their work (with mixed \nsuccess, with one attorney submitting a ChatGPT-generated brief citing fictitious \ncases Martinson 2023). While the potential for using existing AI tools in the legal \nfield has been documented (see, for example, Perlman 2022; Nay et  al. 2023), so \nfar, empirical research on its usefulness in practice is sparse. This study fills this \ngap by systematically testing GPT-3.5’s legal reasoning and ChatGPT’s drafting \ncapabilities.\nThe arguments about the potential of legal AI apply to various areas of law. \nHowever, in this study, we focus on securities cases involving cryptocurrencies \nas an example of the many possible contexts where AI might assist in the legal \nprocess. We focus on this area as it is one where enforcement attorneys face \nsignificant resource constraints that have been chronicled in both the academic and \ngovernmental literature (Kedia and Rajgopal 2011; Bonsall et  al. 2019; Holzman \net  al. 2023; U.S. Securities and Exchange Commission 2017; U.S. Department of \nJustice 2022). This suggests cases in this area could be well-served by AI-based \nassistance. In the absence of government enforcement as a result of these resource \nlimitations, some victims of cryptocurrency securities violations have also sought \njustice through securities class action cases; 1 as of March 1, 2023, there had been \nsuch cases filed (Stanford Law School and Cornerstone Research 2023).\nAgainst this background, we seek to answer the following research questions: \n1. Given a fact pattern from a securities case involving cryptocurrencies, can GPT-\n3.5 accurately discern which laws are potentially being violated?\n2. Is there a difference in juror decision-making between complaints written by a \nlawyer and those written by ChatGPT in the context of cryptocurrency securities \nclass action lawsuits?\nWe conduct our research using the popular, publicly available LLM from OpenAI, \nGPT-3.5, as an operalization of an LLM, evaluating its ability to identify laws \npotentially being violated from fact patterns in real-life cases (while not alleging \nerroneous violations). For our second research question, we had mock jurors assess \npleadings written by ChatGPT (the May 27, 2023 version, based on GPT-3.5 and \nfurther-fined tuned using human feedback) and lawyers. The current study is the first \nto evaluate an LLM ’s legal drafting capabilities in a systematic way and to explore \nits legal reasoning skills in litigation (and, more specifically, the first to test it in \n1 A class action case is a lawsuit brought by someone on behalf of a larger group of plaintiffs who have \nsuffered the same damage as the “lead plaintiff” who represents them and their interests.\n693\nLarge language models in cryptocurrency securities cases:…\nthe areas of securities law or wrongdoing involving cryptocurrencies). We evaluate \nthese LLMs’ capabilities in two basic parts of the legal process—legal drafting \n(specifically the first document filed in a case) and legal reasoning in a litigation \ncontext—to gain insight into whether LLMs have any potential to meaningfully \nassist human lawyers. Lawyers spend up to 60% of their time on legal drafting \nand legal reasoning and drafting are inextricably linked (Litera 2024; Gale 1979). \nThis suggests that LLMs assisting with these tasks would be particularly useful to \nlawyers. Furthermore, if the LLMs cannot handle these fundamental tasks, they are \nunlikely to be able to conduct any of the more advanced tasks required of lawyers.\n1.1  Large language models and their use in legal contexts\n1.1.1  Introduction to LLMs\nLLMs are advanced AI systems that process human language (referred to as “natural \nlanguage” in this context). This means they can generate and respond to human text, \nwith recent systems appearing to be capable of doing this in a manner that is near-\nimperceptibly distinct from humans. The state of the art employs a deep learning \ntechnique called the Transformer architecture to accomplish this (Topal et al. 2021). \nLLMs have advanced rapidly in recent months, most prominently with OpenAI’s \nrelease of GPT-3 in November 2022 (Choi et al. 2023). GPT stands for “Generative \nPre-trained Transformer”, and was first introduced by Brown et  al. (2020). What \ndifferentiates LLMs from other natural language processing (NLP) models is the \nmassive amount of data on which they are pre-trained to conduct these tasks and the \ncomplexity of this Transformer architecture; GPT-3, for example, has 175 billion \nparameters (Choi et  al. 2023). LLMs’ colossal amount of training data (though it \nshould be noted that OpenAI’s training data is proprietary) means they perform well \nat natural language tasks in a variety of contexts, whether or not they have been \ntrained on a particular task specifically. For a more detailed introduction to LLMs \nsee (Zhao et al. 2023) and (Hadi et al. 2023).\n1.1.2  OpenAI’s LLMs\nAlongside GPT-3, OpenAI also released a user-friendly public interface based on the \nmodel, called ChatGPT , which was further fine-tuned using Reinforcement Learn-\ning with Human Feedback (Choi et al. 2023) . This gave users the opportunity to \nexperiment with an LLM in various contexts, without the technical expertise previ-\nously required. Since November 2022, OpenAI has released several variations of the \nGPT-3 model, as well as of the subsequent iterations, GPT-3.5 and GPT-4. In addi-\ntion to interacting with the latest fine-tuned version of GPT-n through the user inter-\nface, more tech-savvy users can access specific models using OpenAI’s API. These \nvary by the period over which training data was collected, the amount of input and \noutput they can handle, and some are optimized for more specific tasks like writing \ncomputer code. Full details of the current, most recent releases can be found here: \nhttps:// platf orm. openai. com/ docs/ models. In this study, we use GPT-3.5 models \n694 A. Trozze et al.\navailable publicly at the time of data collection, namely, gpt-3.5-turbo-0301  \n(the basis of ChatGPT at the time) and text-davinci-003.\n1.1.3  Using OpenAI’s LLMs\nTo use any of OpenAI’s LLMs, the user must provide what is called a “prompt” \nfrom which the model will generate natural language. An example of such a prompt \ncould be “Please identify five plants native to New Mexico.” The nature of LLMs \nand their proprietary training data means it is far from clear which prompts will \nbe most effective in accomplishing a given task or producing a desired output; the \nrange of possible prompts is as broad as language itself, and there is no established \nformula for composing them. The process of developing a suitable prompt for an \nLLM is referred to as “prompt engineering”.\nDevelopers have the option of fine-tuning the model by training it on additional \ndata relevant for a specific, desired task. Not doing this is referred to as “zero-shot” \nlearning, i.e., using the model as pre-trained (Allingham et  al. 2023). “Few-shot” \nlearning refers to providing the model with some examples in the prompt (OpenAI \n2023b). In the example provided above, a few-shot prompt could be:2\nTask instructions:\n1. Flora native to California (provided): [California native plant 1], [California \nnative plant 2], [California native plant 3]\n2. Flora native to Texas (provided): [Texas native plant 1], [Texas native plant \n2]\nNew task: New Mexico native flora\nPlease use your knowledge of native plants of California and Texas to provide \nfive distinct native plant species in New Mexico.\nDesired New Mexico plant species (to be filled in by model): [Plant name], \n[Plant name], [Plant name], [Plant name], [Plant name]\nWhen using OpenAI’s models through their API, users have several additional \nparameters they can specify. All of these settings can be found at https:// platf \norm. openai. com/ docs/ api- refer ence, however, we highlight two. The first is the \ntemperature, which determines how random (as opposed to deterministic) the \noutput of the model is. Possible temperature values range from 0 to 2, with higher \nvalues adding more randomness to the outputs. Users must also set the maximum \nnumber of “tokens”—a term used in natural language processing (NLP) to refer to \nelements of text (e.g., words or characters)—they will allow the model to use in its \noutput. OpenAI charges users of its API based on the amount of tokens used in the \ninput and output of a prompt, with different models allowing different volumes of \ntokens to be used (OpenAI 2023a).\n2 We asked ChatGPT to generate a few-shot prompt for this task, which we adapted and present here.\n695\nLarge language models in cryptocurrency securities cases:…\n1.2  LLMs’ use in legal tasks\nGiven GPT-3’s fairly recent release, there is limited empirical research on its use \nin the legal context, and that which does exist is generally not yet peer-reviewed. \nPrior research has explored comparatively simpler NLP models’ usefulness in law, \nexploring tasks like judgment extraction or indexing large bodies of case law (Yu \net al. 2022). Given the magnitude of recent advancements in this field, however, we \nreview here only research involving GPT-3 or higher.\n1.2.1  Legal tasks\nExisting research in the field of legal applications of LLMs does not necessarily \nfocus on litigation (let alone government enforcement), but rather LLMs’ general \nknowledge of the law and their ability to apply it. Where tasks related to litigation \nare included (for example, in Iu and Wong 2023), the focus has been more general, \nrather than applied to a particular aspect of U.S. civil or criminal procedure. Most \ncommonly, research in this field has involved testing LLMs’ performance on legal \nexams, for example, in taking a bar or law school exam. Bommarito  II and Katz \n(2022) had GPT-3.5 take the multi-state multiple choice U.S. bar exam, on which \nit earned a 40.3% score, compared with a 25% baseline score for guessing. Yu et al. \n(2022) asked GPT-3 to conduct legal reasoning tasks that are part of the Japanese \nBar exam. They wrote prompts corresponding to existing legal reasoning techniques \nfor a task that requires the lawyer to determine whether a hypothesis is true or false \nbased on a given premise. Finally, Choi et al. (2023) asked ChatGPT to complete \nvarious law school exams involving both essay and multiple choice questions; it \nearned a C+ score.\nSimilarly to our research, Nay et al. (2023) and Blair-Stanek et al. (2023) gave \nversions of the text-davinci-003  model legal reasoning tasks outside of an \nexamination setting, asking it to apply statutes to answer questions and evaluating its \nperformance systematically. Nay et al. (2023) used multiple choice questions for this \ntask. Blair-Stanek et al. (2023) used the StAtutory Reasoning Assessment (SARA) \ndata set for their task, finding that GPT-3 performed significantly better than \nBERT,3 but “performed at chance (0.5) or worse in the zero-shot tests where there \nwas no statute included.” They noted that, in particular, GPT-3 displayed incorrect \nknowledge of U.S. tax code. When given synthetic statutes, GPT-3 performed even \nworse, which they claim raises “doubts about GPT-3’s ability to handle basic legal \nwork” (Blair-Stanek et al. 2023).\nSavelka (2023) employed GPT-3.5 in a task involving the semantic annotation of \nlegal documents. They found that it performed well—and, in fact, better than fine-\ntuned versions of BERT and a Random Forest Model—with scores of F1 = 0.73 in \nidentifying key topics in court opinions, F1 = 0.86 for the same in contracts, and \nF1 = 0.54 in statutes and regulations.\nIu and Wong (2023) and Perlman (2022) conducted preliminary exploration of \nChatGPT’s general drafting and legal analytical capabilities. For example, Iu and \n3 BERT is a less advanced LLM. For a full introduction to BERT, see (Koroteev 2021).\n696 A. Trozze et al.\nWong (2023) asked ChatGPT to prepare cross-examination questions for a case and \ndraft a skeleton argument based on analysis of a complex fact pattern, among other \ntasks. They did not prompt the model or evaluate their results in a systematic way. \nThey did, however, suggest ChatGPT performed well at this task, though not as well \nas a lawyer. These authors also used ChatGPT to assist them in drafting their papers.\n1.2.2  Models\nIn terms of the particular LLMs tested, three studies (Bommarito II and Katz 2022; \nSavelka 2023; Blair-Stanek et al. 2023) used text-davinci-003 , as we do in \nanswering our first research question. Nay et al. (2023) used various models, noting \nthat GPT-4 (the state of the art at the time) performed best and that they actually \nused GPT-4 to help grade their answers. Yu et al. (2022) used GPT-3.\n1.2.3  Areas of law\nThe most common area of law on which prior research focused is tax law. Nay et al. \n(2023), Blair-Stanek et al. (2023), and Choi et al. (2023) all included tax law in their \nstudies. Bommarito II and Katz (2022) note that GPT-3.5 passed the evidence and \ntorts section of the bar exam, and Choi et al. (2023) also included an examination \npaper on torts in their work. In addition to these two subjects, Choi et al. (2023) also \nexamined ChatGPT on constitutional law, federalism and separation of powers, and \nemployee benefits. Savelka (2023) researched GPT-3.5’s capabilities in relation to \nveterans’ affairs cases, public health cases, and general commercial legal contracts.\n1.2.4  Prompt engineering and parameter selection\nMuch previous research (though we note most had not been released at the time \nof our study design) focused on prompt engineering in legal contexts. Yu et  al. \n(2022) found that using the legal reasoning technique “Issue, Rule, Application, and \nConclusion” (IRAC) in their prompts performed best. Some research (Bommarito II \nand Katz 2022; Savelka 2023) found that zero-shot prompting proved more effective \ncompared to fine-tuned models, and Choi et al. (2023) determined that, generally, \nthe simplest prompts performed best.\nHowever, this is contradictory to other findings, such as those of Nay et al. (2023) \nand Blair-Stanek et  al. (2023), which used zero-shot performance as a baseline. \nNay et  al. (2023) also explored chain-of-thought (CoT) prompting and few-shot \nprompting, and combined these approaches. CoT prompting involves asking an \nLLM to “think step-by-step”, which Kojima et  al. (2023) previously found to \nimprove performance (though not specifically in legal tasks). Nay et al. (2023) found \nthat CoT only improved the results for GPT-4 and that providing relevant legal texts \nin the prompts moderately improved the results. Few-shot prompting led to better \nresults for GPT-4 but not for other models.\nBlair-Stanek et al. (2023) used up to 10-shot CoT prompting and also found, again \ncontrary to Kojima et al. (2023)’s results, this was unhelpful in their experimental \n697\nLarge language models in cryptocurrency securities cases:…\ncontext. In general, their prompts were much more complex: for example, in their \n“4-shot dynamic prompting” context, they included the four most similar training \ncases and labelled the text of the case (which they also provided in full) with the \n“premise”, the “hypothesis”, and the “answer”. Having to prepare prompts in this \nway may not actually save lawyers time. Notably, Choi et  al. (2023) specifically \nasked ChatGPT not to “fabricate” any facts, and it followed this instruction. Overall, \nthese findings suggest prompt engineering is much more of an art than an exact \nscience.\nPerlman’s(2022) was the only study to ask ChatGPT to draft a complaint, which, \nunsurprisingly, resulted in a very short complaint being drafted. We note that neither \nthey, nor Iu and Wong (2023), engaged in any documented attempts to refine their \nprompts. Perlman (2022) used the following prompt:\n“Draft a legal complaint for a Massachusetts state court by John Doe against \nJane Smith for injuries arising out of a car accident on January 1, 2022 caused \nby Jane Smith at the intersection of Tremont Street and Park Street in Boston. \nThe complaint should specify that Jane Smith failed to stop at a red light and \ncaused John Smith serious injuries.”\nFor drafting essays, Choi et  al. (2023) asked ChatGPT to write essays section by \nsection; we use a similar prompting approach in this study.\n1.2.5  Consideration of LLMs’ training data\nSince LLMs have been trained on large corpora of real-world text data, it is possible \nthat some legal sources are present in the training data and therefore have previously \nbeen “seen” by the models, which the literature considers at length. 4 As noted in \nsome studies (Bommarito  II and Katz 2022; Nay et  al. 2023; Blair-Stanek et  al. \n2023), this represents a potential threat to the validity of research of this nature \nsince a model may successfully complete a task simply by reproducing known \nmaterial, rather than by “interpreting” its meaning. Bommarito II and Katz (2022) \nidentified behavior which appeared to indicate that there were some legal sources \nin its training. In their research, Nay et  al. (2023) and Blair-Stanek et  al. (2023) \nspecifically used synthetic cases to ensure the LLM had not been been trained on \nthem. Notably, Blair-Stanek et  al. (2023) found that GPT-3 was unlikely to have \nbeen trained on the complete U.S. tax code because it showed incorrect knowledge \nthereof. They note that, “given a U.S. Code citation, GPT-3 can recite plausible but \nincorrect statutory language” (Blair-Stanek et al. 2023).\n1.3  Cryptocurrency securities violations and related law\nAs discussed above, the use of LLMs might be particularly useful to lawyers in the \ncryptocurrency securities context due to documented resource limitations faced by \n4 Since the training data for most LLMs, including ChatGPT, is proprietary, this cannot be confirmed \ndirectly.\n698 A. Trozze et al.\nenforcement attorneys in this area of law. We use examples from this domain to \nperform our study. In this section, we provide a brief outline of the legal context for \ncryptocurrency securities violations.\n1.3.1  U.S. securities laws and securities class action lawsuits\nA security is “an investment of money in a commercial, financial, or other business \nenterprise, with the expectation of profit or other gain produced by the efforts of \nothers” (Ninth Circuit Jury Instructions Committee 2023). Specific types of \nsecurities include stocks, bonds, and investment contracts (Ninth Circuit Jury \nInstructions Committee 2023). In the U.S., at the federal level, the offer, sale, and \npurchase of securities is governed by the following laws: Securities Act of 1933 \n(“Securities Act”); Securities Exchange Act of 1934 (“Exchange Act”); Investment \nCompany Act of 1940; Investment Advisers Act of 1940; Sarbanes-Oxley Act of \n2002 (“Sarbanes-Oxley”); and Dodd-Frank Wall Street Reform and Consumer \nProtection Act of 2010 (“Dodd Frank”) (Practical Law Securities Litigation & \nWhite Collar Crime 2023).\nThe U.S. Securities and Exchange Commission (SEC) and the Financial Industry \nRegulatory Authority (FINRA) are responsible for civil securities law enforcement \nin the U.S.5\nIn addition to violations of the aforementioned regulations, the SEC has the \npower to charge “securities fraud based on negligent conduct” and “aiding and \nabetting securities fraud” (Practical Law Securities Litigation & White Collar Crime \n2023).\nPrivate securities cases usually take the form of class actions. Private plaintiffs \nenjoy rights of action under the Securities Act, the Exchange Act, and Sarbanes-\nOxley. The most common bases for such suits when they involve cryptocurrencies \nare are Section 10(b) of the Exchange Act and SEC Rule 10b-5 (securities fraud) \nand Sections 5(a), 5(c), and 12(a)(1) of the Securities Act (unregistered securities \noffering, and liability of the offerer or seller thereof) (Practical Law Securities \nLitigation & White Collar Crime 2023, noa, n.d.a,n) For a full overview of U.S. \ncivil procedure and the procedure for class action suits as set out in the PSLRA, see \n“Appendix 1”.\n1.3.2  Introduction to cryptocurrencies\nCryptocurrencies are a store of value initially conceived in 2008 by a developer \n(or group) using the pseudonym Satoshi Nakamoto (Home Office 2023; Nakamoto \n2008). Nakamoto proposed the first cryptocurrency, Bitcoin, as a peer-to-peer \n“digital representation of value” which would enable direct transactions between \nindividuals without the need for an intermediary financial institution (Home Office \n699\nLarge language models in cryptocurrency securities cases:…\n2023). Bitcoin uses a novel combination of existing cryptographic 5 concepts \ncalled a blockchain, which serves as a decentralized ledger of all transactions \n(Narayanan 2018; Moffett 2022). Transactions are secured through cryptography, \nwith participants verifying transactions by solving computationally complex \ncryptographic problems in a process called “mining”. As part of this mining process, \nvalid transactions are combined into “blocks” which are added to the blockchain. \nThey are “chained” to previous blocks in a way that can be cryptographically \nverified, meaning that nefarious actors cannot alter this digital ledger, thereby \nensuring the system’s security (Nakamoto 2008). For a more complete introduction \nto Bitcoin and cryptocurrencies, see Narayanan et al. (2016).\n1.3.3  Cryptocurrencies as securities\nSince Bitcoin was first made available in 2009, the cryptocurrency ecosystem \nhas greatly expanded, with more than 26,000 cryptocurrencies in existence today \n(CoinMarketCap 2023). These may exist on their own blockchains (or other forms \nof decentralized ledger technology) or can be created on existing blockchains, such \nas the Ethereum blockchain. In the U.S., both the Commodity Futures Trading \nCommission (CFTC) and the SEC have claimed to have regulatory control over \ncryptocurrencies in certain situations. In many cases, certain cryptocurrencies’ \nprimary purpose has been determined to be as an investment contract, thereby \nclassifying them as securities (Moffett 2022). As discussed above, the SEC is \nresponsible for securities regulation and enforcement. Though a full discussion of \nthe SEC’s reasons for considering certain cryptocurrencies as securities is outside \nof the scope of this paper, we give a brief overview. For a full consideration thereof, \nsee Moffett (2022).\nThe SEC and the U.S. federal courts have traditionally based their analysis \nas to whether a cryptocurrency constitutes a security on SEC v. W.J. Howey Co. \n(now colloquially referred to as the “Howey test”). In this Supreme Court case, \nan investment contract needed to meet the following criteria: it had to be “(1) an \ninvestment of money, (2) in a common enterprise, (3) with the expectation of profits, \n(4) to be derived from the entrepreneurial or managerial efforts of others” (Moffett \n2022).\nBased on the Howey test, Bitcoin is not a security (specifically because it does \nnot satisfy requirements two and four discussed above), but one could argue that \nmany other cryptocurrencies (such as those featured in the cases we explore below) \nare. Notably, it is possible that a cryptocurrency’s status as a security can change \nover time (Moffett 2022).\n5 Cryptography refers to the science of secure communications, namely ways to ensure communications \nremain confidential, authentic, tamper-resistant, and only comprehensible by intended participants. It is \nused for securing various types of information and permeates several facets of everyday life, from send-\ning encrypted text messages to online banking.\n700 A. Trozze et al.\n2  Methods\nThis study seeks to discover whether (1) when presented with a fact pattern from \na securities enforcement case involving cryptocurrencies, GPT-3.5 can determine \nwhich laws are potentially being violated, and (2) whether, for securities class action \nlawsuits involving cryptocurrencies, there is a difference in juror decision-making \nbased on complaints written by a lawyer compared with those written by ChatGPT.\nWe used versions of OpenAI’s GPT-3.5 models to answer both questions. For the \nfirst, we prompted GPT-3.5 to discern which laws were potentially being violated, \nwhen presented with fact patterns from real-life cases. We then calculated various \nevaluation metrics to test its performance, using the allegations in the cases from \nwhich we extracted the fact patterns as our “ground truth” for correctly identified \nviolations. The closer GPT-3.5 got to identifying all of the counts in the actual \ncomplaint (and without alleging erroneous charges), the better we considered its \nperformance at this task.\nTo answer our second research question, we presented mock jurors with pleading \ndocuments written by either ChatGPT or a human lawyer and asked them to answer \nvarious questions. The performance of ChatGPT in legal drafting was considered \nto be adequate if jurors reached the same decisions when presented with the \nAI-drafted complaint as they did for that written by a human lawyer. Ordinarily, \njurors would not evaluate complaints, but rather would make a decision based on \nlawyers’ arguments and evidence presented (mostly verbally) at trial. However, in \nthis study, we asked jurors to evaluate the complaint directly, assuming the facts \npresented therein are true. In legal procedure, complaints would typically be read \nand evaluated by judges and lawyers, and so, it would be useful for lawyers to review \nsuch complaints that were generated; however, in this study, we did not have access \nto a sufficient number of lawyers to produce a robust evaluation of ChatGPT’s legal \ndrafting skills. Ultimately, we opted to provide detailed jury instructions to a larger \nnumber of laypeople to make decisions based on a legal document.\nIn our study, we used zero-shot transfer. 6 In developing prompts to explore each \nresearch question, we tested them on a general securities enforcement case, SEC v. \nKaplan, et al., case number 2:23-cv-01648, in the U.S. District Court for the Eastern \nDistrict of New York.\n2.1  GPT‑3.5’s ability to discern violations of U.S. law\nWe examined GPT-3.5’s ability to determine, when given a fact pattern \ncorresponding to a case, and prompted with a particular legal reasoning technique, \nwhich U.S. laws were potentially being violated. Civil complaints contain a section \ndetailing the facts of the case and describing the defendants’ alleged conduct. For \n6 Zero-shot transfer means that the LLM has neither been given relevant examples in the prompt, nor \nfurther fine-tuned (i.e., trained on many examples to produce a model which will accept either zero-shot \nor multi-shot prompts). However, because large-scale pre-trained models could happen to incorporate \nsome relevant examples in their training data, this is distinct from zero-shot learning (Allingham et al. \n2023).\n701\nLarge language models in cryptocurrency securities cases:…\neach case we study, we provided the information (verbatim) in the factual allegations \nsection to GPT-3.5. For a more detailed introduction to legal complaints, see \n“Appendix 1”.\n2.1.1  Choice of model\nTo answer this research question, we used the GPT-3.5 text-davinci-003 \nmodel, which is trained on data collected prior to June 2021. Aside from newer \nmodels being more expensive to run, their training data sets are more recent. For \nthis research question, we wanted to ensure that the model had no prior knowledge \nof our cases (i.e., that these cases could not be present in its training data). We used \nOpenAI’s native Python wrapper to execute our API calls.\n2.1.2  Case selection\nIn selecting our cases, we first identified all cryptocurrency securities class action \nand SEC enforcement cases which were filed after June 2021 (and before our data \ncollection date, on March 24, 2023) . We included all SEC cases under the heading \n“Crypto Assets” on the SEC’s Crypto Assets and Cyber Enforcement Actions \npage (U.S. Securities and Exchange Commission 2023). This list includes all SEC \nenforcement actions that involve cryptocurrencies. For the class action cases, we \ncollected all cases included in the Stanford Securities Class Action Clearinghouse \nFilings Database listed under “Cryptocurrency Litigation” in their “Current Trends” \nsection (Stanford Law School and Cornerstone Research 2023). Again, these are \nsecurities class action cases that involve cryptocurrencies. This gave us an initial set \nof 34 class action cases and 43 enforcement actions. Next, we extracted the factual \nallegations sections of the cases’ respective complaints. Because the maximum \nnumber of tokens for the text-davinci-003  model is 4,097, we excluded \nall cases whose facts sections exceeded this number of tokens (using OpenAI’s \nTokenizer tool to calculate the number of tokens) (OpenAI 2023c). This resulted in \nthe exclusion of 50 cases. We also excluded any administrative SEC cases ( n = 9).\nThere were two pairs of cases which were filed separately, but with nearly \nidentical facts sections, due to lawyers having chosen not to join the defendants. For \neach of the two pairs, we chose to include whichever case had a more detailed facts \nsection in our final data set and excluded the other.\nThis left us with a final set of 20 cases, eight of which are class action cases. \nMore details of our case selection process, including reasons for excluding specific \ncases, can be found in “Appendix 2.1”.\n2.1.3  Prompt design\nTo craft our prompt for this aspect of our study, we used ChatGPT’s online user \ninterface. Our full prompt design process-tested on our sample case, SEC v. Kaplan, \net  al.-is detailed in “Appendix 3.1”, though we highlight selected considerations \nhere. Following Yu et al.’s (2022) research, we requested ChatGPT use a specific \nlegal reasoning technique (IRAC). Second, as we conducted our prompt engineering, \n702 A. Trozze et al.\nit was clear we needed to be as specific as possible in our prompt. Our final prompt, \ntherefore, defined the jurisdiction in which the facts occurred or were connected \n(based on where the real complaint was filed; this also communicates to the LLM \nthat we are interested in U.S. law for this task), indicated that the violations should \nbe federal and civil (as opposed to state or criminal laws), and that the LLM should \nstate the specific section of any statute potentially violated.\nWe arrived at the following, final prompt:\n“The following text is from the \\“factual allegations\\” section of a complaint \nfiled in the [jurisdiction; in the sample case, Eastern District of New York]. \nBased on the facts in this text, please identify which federal civil law(s) and \nsection thereof the defendant(s) violated. Please use the following method \nof legal reasoning to come up with the allegations: Issue, Rule (including \nthe specific statute and section thereof), Application, Conclusion: [text from \nfactual allegations section]”\n2.1.4  Input pre‑processing and cleaning\nBefore running our prompt on our chosen cases, we pre-processed and cleaned our \ninput text. We manually removed the following from the complaint text: paragraph \nnumbers; footnotes; references; pictures; indications that emphasis was added; \nbackground information (for example, an introduction to cryptocurrency); and extra \nspaces. We also added the appropriate escape character (“\\”) before quotation marks \nand apostrophes.\n2.1.5  Parameters and execution\nBefore applying our prompt to our final set of cases, we considered the appropriate \ntemperature setting for our model. Ultimately, we wanted the model to follow our \ninstructions closely, so we chose 0.2 as our temperature. 7 We also experimented \nwith a temperature of 1 (for a more random output), however, we found that this \nresulted in little change in the output. We used the same temperature of 0.2 as we \nsought to identify the baseline performance of ChatGPT for a task of this kind \n(rather than exploring how we can fine-tune its parameters for better performance). \nFor each case, we ran the model five times (each with the same temperature of 0.2).\nThe max_tokens parameter specifies the maximum length of text to be \ngenerated: we set this to the total number of tokens this model accepts (4,097) minus \nthe number of tokens provided in the prompt for each case, thereby allowing the \nmaximum possible size for each output. We also recorded the number of tokens used \nfor completion in each output for each of our cases; this can be found in “Appendix \n4”.\n7 We chose 0.2 instead of 0 because, while we wanted a highly deterministic output, we wanted some \nrandomness to allow for some variability in our output. During our prompt engineering process, when we \nset the temperature to 0, each iteration yielded the exact same output.\n703\nLarge language models in cryptocurrency securities cases:…\n2.1.6  Evaluation\nTo evaluate GPT-3.5’s performance, we measured the extent to which the violations \nit identified matched those in real cases. For this purpose, we used the allegations \nin the real-life complaint as our “ground truth”. For each case, multiple violations \napply in the real case, and GPT-3.5 can also identify multiple violations, but the \nnumber of violations may not be equal. Therefore, we employed performance \nmetrics to measure the extent to which GPT-3.5 identified the correct violations \nor identified incorrect ones. We note that there is some limitation to automatically \nconsidering any additional charges suggested by GPT-3.5 as “incorrect”, as lawyers \nsometimes make mistakes or decide not to include certain charges for other, strategic \nreasons. However, for the purposes of this study, we consider the lawyers’ charges as \n“correct” based on the facts in question.\nWith that in mind, we adapted the definitions of true positives, false positives, \nand false negatives for our context to calculate performance metrics. In this case, \nthe number of true positives (TP) was the number of claims GPT-3.5 correctly \nidentified. The number of false positives (FP) was the number of incorrect, additional \nviolations suggested. The number of violations GPT-3.5 missed constituted the false \nnegatives (FN). The number of true negatives was not applicable in our analysis \nbecause it would not be meaningful to count every possible law that does not apply \nin this context.\nWe use adapted definitions because we allow for partial counts of these scores to \ncapture the nuance of the legal context. To be considered “correct”, GPT-3.5 needed \nto identify all elements of each legal claim. Otherwise, it would receive a partial \nscore, as per the following rules:\n• Rule 1: In cases where violations are almost always alleged together (for \nexample, Section  10(b) of the Exchange Act and Rule 10b-5 thereunder), we \ncounted this as a single violation and scored accordingly. However, GPT-\n3.5 only identified, for example, a Rule 10b-5 violation, but not a violation of \nSection 10(b), we would score this as 0.5.8\n• Rule 2: We also awarded 0.5 points if the output included the correct law, but \nfailed to include the specific section the defendants violated. So, for example, \nif the output suggested violations of the Securities Act, but did not specify \nthat the allegations were of Sections 5(a) and 5(c) thereof, 0.5 points would \n8 There is some further nuance to this in our sample case (see Fig.  1) because we do not specify in our \nprompt whether the case in question would be a government enforcement or private matter and there \nis no private right to action under Section 10(b) unless the company is publicly listed. However, while \nsome courts have ruled there is a private right of action under Section 17(a), the generally accepted view \nis that this is not the case (and, besides, GPT-3.5 did not specify any part of Section 17 in its output for \nour sample case) (Legal Information Institute, n.d.a). This implies that GPT-3.5 either a) assumed this \nwould be a government enforcement case and, therefore, charging only 10b-5 without 10(b) is unusual, \nor b) it assumed this was a private case and the Section 17 finding was wrong. Our scoring system, there-\nfore, better captures these nuances. While it is, of course, not infallible and still assumes the charges in \nthe real complaint are the ground truth, it would be impractical to have several lawyers analyze each out-\nput from GPT-3.5 to assign it a score.\n704 A. Trozze et al.\nbe awarded. However, if the output merely stated that violations of “federal \nsecurities laws” occurred, it was given a score of 0.\n• Rule 3: In cases where the complaint charged Sections  5(a) and 5(c) of the \nSecurities Act and the output only included Section  5 thereof (overall), we \nconsidered this as a true positive (because Section  5 overall would include \nSections 5(a) and 5(c)).\n• Rule 4: For the purpose of calculating true positives and false negatives, \nwhere the complaint charged different counts of the exact same allegations \nin the complaint (usually just for different defendants), we counted them as a \nsingle violation. That being said, there was one case (Securities and Exchange \nCommission v. Arbitrade Ltd., et  al., 1:22-cv-23171, S.D. Fla.), where one \nclaim was for Rule 10b-5 under the Exchange Act and another for 10b-5(c) \n(against a different defendant). However, since one of the charges did include \nall of Rule 10b-5, we counted these both as a single violation.\nFig. 1  Scoring GPT-3.5 output for one run of test case\n705\nLarge language models in cryptocurrency securities cases:…\n• Rule 5: We did not infer any charges if the output failed to reference the \nappropriate statute (i.e., if it included only “unregistered securities”, we \ndid not assume it meant a violation of Section  5 or Section  12(a)(1) of the \nSecurities Act).\n• Rule 6: Finally, the prompt specifically requested violations of federal laws. \nSome outputs included state law violations. Because this was contrary to the \nprompt’s instructions, these were automatically considered as false positives for \nthe sake of scoring.\nFigure 1 depicts our scoring process for the output for one run of our test case.\nAfter applying these rules manually to the output, we evaluate GPT-3.5’s perfor -\nmance at this legal reasoning task. We used our previously defined, adapted concepts \nof true positives, false positives, and false negatives to calculate precision and recall \n(similarly to how Ting (2010) applied such metrics to a document retrieval system, \nas we were, essentially, asking GPT-3.5 to retrieve relevant laws from a finite set of \nlaws). Precision (P) is the total number of correct charges identified (true positives), \ndivided by the total number of charges GPT-3.5 identified (true positives plus false \npositives):\nRecall (R) is total number of correct charges identified (true positives) divided by \nthe total number of possible correct charges (true positives plus the false negatives).\nWe then use the output of these measures to calculate an F-1 score that balances the \nprecision and recall based on our adapted versions of TP, FP, and FN, as our final \nscore, calculated as follows:\nWe calculate the average scores for each metric across the five outputs for each of \nour 20 cases, as well as for all of our outputs ( n = 100).\nThe full outputs of the prompts for each of our cases, as well as our calculated \nscores, are in “Appendix 4”.\n2.2  Differences in juror decision‑making based on human vs. AI‑written legal \ncomplaints\nTo answer our second research question, we sought to abstract the legal process \nto discern whether jurors made different decisions when presented with legal \nallegations and factual scenarios written by ChatGPT versus those written by human \nlawyers. We explored this using real-world securities class action cases.\nP = TP\nTP + FP\nR = TP\nTP + FN\nF-1= 2 ⋅ P ⋅ R\nP+R\n706 A. Trozze et al.\n2.2.1  Case selection\nIn order to more fulsomely evaluate ChatGPT’s legal drafting skills, we included \ncases of varying quality. We wanted to evaluate ChatGPT’s drafting ability not only \nfor high quality cases (i.e., those a judge decided had merit to continue through \nthe legal process), but also those of lower quality (i.e., that a judge dismissed). \nWe used class action cases because, overwhelmingly, cases brought by the SEC \nare successful: in 2022, for example, it won 12 of its 15 trials (U.S. Securities and \nExchange Commission 2022). The sample of such cases that are “without merit” is, \ntherefore, extremely small, potentially limiting the insight that could be gained.\nTo select our cases, we first identified all cryptocurrency class action cases, \nagain, using the Stanford Securities Class Action Clearinghouse Filings Database, \nspecifically collecting cases listed under “Cryptocurrency Litigation” in their \n“Current Trends” section (Stanford Law School and Cornerstone Research 2023). \nInitially, we examined cases which had been filed between ChatGPT’s June 2021 \ntraining cut-off date and the date of our research (March 24, 2023). This gave us 34 \ncases. We sought cases which met the following criteria: \n1. For “valid” cases, the class action cases had to have had a motion to dismiss filed, \nconsidered, and, ultimately, denied by the judge.\n2. For our “meritless” cases, the class action cases had to have a motion to dismiss \nfiled, considered, and, ultimately, ordered affirmatively by the judge.\nFrom our initial set of cases, only one case from each category met these criteria, \nwhich would not allow us to evaluate ChatGPT’s pleading drafting abilities in a \nparticularly robust way. Therefore, we expanded the temporal range of our search to \ninclude all cryptocurrency securities class action cases, the first of which was filed \nin 2016 (Stanford Law School and Cornerstone Research 2023). This increased the \ntotal number of cases to evaluate to 77. We analyzed these cases (based on their \nprogress as of May 22, 2023), excluding ones which did not meet the criteria. We \ndid not include cases which involved voluntary dismissal or where the motion to \ndismiss was granted in part. This gave us a set of 30 cases.\nIn order to draft our AI-generated complaints, we provided ChatGPT with the \nfacts as presented in Law360 9 articles about the filing of a particular complaint. \nLaw360, a subsidiary of LexisNexis, is a reputable source of legal news that writes \nstories on major cases summarizing the facts from the complaint when it was filed \n(see Sect. 2.2.2 below). Prior legal research (see Ahmad et al. 2022; Kacperczyk and \nPagnotta 2024) has utilized Law360 databases. While these articles are unlikely to \nbe completely representative of the facts that would have been available to plaintiffs \nand their lawyers when the complaints were originally drafted, these types of legal \nnews articles are the best approximation we have thereof. We excluded any cases \nfor which there was either (a) no Law360 article, or (b) the only articles were about \nanother filing (rather than the complaint). After doing this, nine cases remained in \n9 https:// www. law360. com/.\n707\nLarge language models in cryptocurrency securities cases:…\nour data set. We note that, in cases where an amended complaint was filed, we used \nwhichever complaint was referenced in the Law360 article as our lawyer-drafted \ncomplaint.\nFor full details on the selection process, including the reasons for exclusion for \neach of the cases in the set, see “Appendix 2.2”. Our final nine cases can be found in \nTable 1 below.\n2.2.2  ChatGPT‑drafted complaints\nWe prompted ChatGPT to draft complaints using a series of zero-shot prompts. For \nfurther details on the conventions for drafting a legal complaint, see “Appendix 1”. \nIt is impossible to give ChatGPT the exact same set of facts that the lawyer had \nto draft the original complaint because we do not have access to that information. \nHowever, we are not testing ChatGPT’s ability to discern which facts, from a set of \nfacts, are most relevant legally, but rather its ability to draft a convincing complaint \nfrom a given set of facts.\nWith that in mind, rather than manually extracting the facts of the case from \nthe complaint, we used the facts as presented in the Law360 summary of the case \nwhen it was filed. We gave the Law360 article (verbatim, excluding the case num-\nber and counsel information) to ChatGPT and asked it to write each section of \na complaint for a particular United States District Court (the one where the real \ncomplaint was filed). We found that asking ChatGPT for each section of the com-\nplaint individually resulted in more detailed and higher quality outputs (as Choi \net al. (2023) also found in asking it to draft essays). When we simply asked Chat-\nGPT to draft the whole complaint (even when the sections and suggested length \nwere specified), it produced a short, sparse complaint. We tested our prompts on \nour sample case, SEC v. Kaplan, et al. The Law360 articles used in our prompts \nwere the following: Perera (2023), Guarnaccia (2019), Ruscoe (2019), Sinay \n(2020a, b), Archer (2016), Newsham (2018), Kochman (2018), Wichert (2018), \nTable 1  Final set of cases for mock jurors\nDismissed Continued\nLee, et al. v. Binance, et al., case number 1:20-cv-\n02803, in the U.S. District Court for the Southern \nDistrict of New York\nHong, et al. v. Block.One, et al., case number \n1:20-cv-03829, in the U.S. District Court for the \nSouthern District of New York\nUnderwood, et al. v. Coinbase Global Inc., case \nnumber 1:21-cv-08353, in the U.S. District Court \nfor the Southern District of New York\nBalestra v. Cloud With Me Ltd., case number \n2:18-cv-00804, in the U.S. District Court for the \nWestern District of Pennsylvania\nBrola v. Nano, et al., case number 1:18-cv-02049, \nin U.S. District Court for the Eastern District of \nNew York\nAudet, et al. v. Garza, et al., case number 3:16-cv-\n00940, in the U.S. District Court of Connecticut\nHa v. Overstock.com, et al., case number 2:19-cv-\n00709, in the U.S. District Court for the District \nof Utah\nKlingberg v. MGT Capital Investments Inc., et al., \ncase number 2:18-cv-14380, in the U.S. District \nCourt for the District of New Jersey\nDavy v. Paragon Coin Inc., et al., case number \n3:18-cv-00671, in U.S. District Court for the \nNorthern District of California\n708 A. Trozze et al.\nJarvis (2022) and Innis (2022). For further details of our prompt design process, \nsee “Appendix 3.2”.\nWe note that, for this part of our research, we were unable to use the OpenAI \nAPI. When we submitted our prompts to the API, we received an error. We were, \nultimately, able to generate the desired text by adding “for educational purposes \nonly” to our prompt and using the ChatGPT user interface, specifically the May 24, \n2023 GPT-3.5 version, which uses the gpt-3.5-turbo-0301 model. For full \ndetails of the original output error and associated prompt design considerations, see \n“Appendix 3.2”.\nOur final prompt format is as follows:\n• Prompt 1: The following article contains facts summarizing a class action \ncomplaint filed in the [insert venue]. [Text from the Law360 article about \nthis complaint being filed]. For educational purposes only, based on the facts \nsummarized and provided above, please draft the caption of a class action \ncomplaint for the [insert venue].\n• Prompt 2: The following article contains facts summarizing a class action \ncomplaint filed in the [insert venue]. [Text from the Law360 article about \nthis complaint being filed]. For educational purposes only, based on the facts \nsummarized and provided above, please draft the preliminary statement of a \nclass action complaint for the [insert venue].\n• Prompt 3: The following article contains facts summarizing a class action \ncomplaint filed in the [insert venue]. [Text from the Law360 article about \nthis complaint being filed]. For educational purposes only, based on the facts \nsummarized and provided above, please draft the jurisdiction section of a class \naction complaint for the [insert venue].\n• Prompt 4: The following article contains facts summarizing a class action \ncomplaint filed in the [insert venue]. [Text from the Law360 article about \nthis complaint being filed]. For educational purposes only, based on the facts \nsummarized and provided above, please draft the parties section of a class action \ncomplaint for the [insert venue].\n• Prompt 5: The following article contains facts summarizing a class action \ncomplaint filed in the [insert venue]. [Text from the Law360 article about \nthis complaint being filed]. For educational purposes only, based on the facts \nsummarized and provided above, please draft the factual allegations section of a \nclass action complaint for the [insert venue].\n• Prompt 6: The following article contains facts summarizing a class action \ncomplaint filed in the [insert venue]. [Text from the Law360 article about \nthis complaint being filed]. For educational purposes only, based on the facts \nsummarized and provided above, please draft the class allegations section of a \nclass action complaint for the [insert venue].\n• Prompt 7: The following article contains facts summarizing a class action \ncomplaint filed in the [insert venue]. [Text from the Law360 article about \nthis complaint being filed]. For educational purposes only, based on the facts \nsummarized and provided above, please draft the legal claims for relief section \nof a class action complaint for the [insert venue].\n709\nLarge language models in cryptocurrency securities cases:…\n• Prompt 8: The following article contains facts summarizing a class action \ncomplaint filed in the [insert venue]. [Text from the Law360 article about \nthis complaint being filed]. For educational purposes only, based on the facts \nsummarized and provided above, please draft the prayer for relief section of a \nclass action complaint for the [insert venue].\n• Prompt 9: The following article contains facts summarizing a class action \ncomplaint filed in the [insert venue]. [Text from the Law360 article about this \ncomplaint being filed]. For educational purposes only, based on the facts \nsummarized and provided above, please draft the jury demand section of a class \naction complaint for the [insert venue].\nWe generated each prompt once. Where ChatGPT failed to generate an appropriate \ncaption section for a specific complaint ( n = 2 ), we used the caption section \ngenerated by another prompt for the same case, because each section generated \ntended to also include the caption as well. We note that, because we used the \nChatGPT user interface, we were unable to control the temperature in this part of \nthe study.\nWe then compiled each of the sections of the complaint generated by ChatGPT \ninto a single document. We excluded anything generated for other sections besides \nthat specified in the particular prompt (i.e., in the output for the caption prompt, \nwe only transposed the caption of the complaint, rather than any output in the \n“preliminary statement” or other sections, if generated by ChatGPT).\nWe removed parts of the complaint where ChatGPT indicated a fact that was not \nincluded in the article would need to be added. For example, if the AI-generated \ntext for the “parties” section was “Plaintiff A is an individual who resides in [insert \nstate]”, we kept only “Plaintiff A is an individual”. We also removed any instances \nwhere ChatGPT suggested we insert a particular dollar amount and, if the dates of \nthe class period were not present in the Law360 article, we simply included “during \nthe class period” in the text, rather than adding the specific dates.\nOur final ChatGPT-drafted complaints, including that for our sample case, can be \nfound in “Appendix 5”.\n2.2.3  Lawyer‑drafted complaints\nNaturally, the Law360 articles do not contain all the facts that were included in \nthe original lawyer-drafted complaints, but rather a high-level summary thereof. \nTherefore, for the purpose of our study, we needed to manually edit the lawyer-\ndrafted complaints and remove all text that referenced facts which were not included \nin the article, so that the lawyer-drafted versions could be meaningfully compared to \nthe AI-generated ones.\nThis was also beneficial in terms of reducing the length of the complaints our \nmock jurors needed to read to reach their decisions; some of the original com-\nplaints were more than 200 pages long, which would be impractical for jurors in \nthis study to read in their entirety. We also removed the following: any charges \noutside of those on which we asked our mock jurors to make decisions (see \n710 A. Trozze et al.\nSect.  2.2.5 below); footnotes; indications that emphasis was added; background \ninformation on cryptocurrencies; and the case number.\nWillmott et al. (2018) similarly reduced the length of the case document they \nused in their mock jury study (in their case, a trial transcript). Though it was \na concern, this process did not seem to harm the quality of the lawyer-drafted \ncomplaints. For each complaint, we confirmed the document still read well after \nour deletions and we found we did not need to make any additional amendments. \nThough we acknowledge that these exclusions pose a risk of reducing the \npersuasiveness of the lawyer-drafted complaints, given that our mock jurors \nultimately considered the charges in the lawyer-drafted complaints to be proven \n88% of the time, this did not seem to be the case.\nWe note that, in one case, Audet, et  al. v. Garza, et  al., case number 3:16-\ncv-00940, in the U.S. District Court of Connecticut, there was an error in the \nLaw360 article, which wrongly referred to “Hashstakers” as “Hashstalkers”. \nTherefore, we changed all instances of the word “Hashstakers” to “Hashstalkers” \nin the lawyer-generated complaint to facilitate comparison with the AI-generated \none based on the article.\nWe also changed the formatting of these complaints, so all the complaints \npresented to our mock jurors were formatted consistently. See “Appendix 5 ” for \nthe final versions of our lawyer-drafted complaints, including for our sample case.\n2.2.4  Mock juror decision‑making\n2.2.5  Selecting overlapping charges\nBased on the contents of the cases, we selected the particular violations on which \nto ask our participants to make judgements. For the sake of comparability, we \nneeded to look at the same charge for both the ChatGPT-generated version of the \ncomplaint and the original, lawyer-drafted one for each case. To avoid introducing \nfurther variables into our analysis, we sought to choose the smallest number of \ncharges possible which covered all our cases. As discussed above, we excluded \nany state-based allegations.\nSection  5 and 12(a)(1) Violations of the Securities Act (“the Securities Act \nviolations”, 15 U.S. Code §77e and 15 U.S. Code §77  l (noa, n.d.a,n)) were \ncharged in both versions of the complaints for six of our cases, and Violations of \nSection 10(b) of the Exchange Act and Rule 10b-5 thereunder (“the Exchange Act \nviolations”, 15 U.S. Code §78j (Legal Information Institute, n.d.b)) were included \nin both versions of the complaints for four cases. One case (Hong, et al. v. Block.\nOne, et al.) included both charges, so we asked one set of participants to evaluate it \nfor the Securities Act violations and another for the Exchange Act violations. This, \neffectively, gave us a set of 10 cases (considering Hong, et al. v. Block.One, et al. \n711\nLarge language models in cryptocurrency securities cases:…\nwas included in the set twice). For full details of the charge selection process, see \n“Appendix 6”.\n2.2.6  Jury instructions\nWe drafted jury instructions for each of our violations to determine the criteria \nupon which our mock jurors would decide if the relevant violations were proven \nin the complaint. We aligned the jury instructions for each of the violations we \nstudied very closely with jury instructions for the same charges in real cases.\nWe based our jury instructions for the Securities Act violations on Dalton \n(2013) and Ninth Circuit Jury Instructions Committee (2023). For the Exchange \nAct violations, we modeled our jury instructions on (Martin 2013). The jury \ninstructions each began with an introduction to securities laws and the claims \nin question. A series of five legal questions followed, each prefaced by relevant \nlegal definitions and context. Each of the first four questions corresponds to one \nelement of the charge that must be proven for the charge to be proven. The fifth \nquestion asked whether the juror answered the first four questions affirmatively \n(indicating a violation was proven). If they answered “no” to any of the questions, \nthe allegation was not proven. In our study, we instructed the jury members to \nassume that the facts presented in the complaints were true. The legal questions \nwere all binary (with “yes” or “no” answers).\nIn a court case, the jury would need to decide on the legal elements of the case \nfor each defendant individually. However, to simplify the process, because we are \nmerely testing whether ChatGPT could write a convincing complaint based on \ncertain facts, and because we abridged the amended complaints, we asked the jurors \nif they were satisfied that a particular element was supported-assuming all the facts \nalleged were true-for one or more defendants.\nFollowing Willmott et al. (2018) and Stevens et al. (2022), the final question of \nour jury instructions asked the jurors to rate their confidence in their final decision \nin the case on a scale of 1–5, with 5 meaning extremely confident and 1 meaning not \nat all confident.\nOnce we had drafts of our jury instructions, we piloted the survey for our sample \ncomplaint (which contained the Securities Act charges) on an individual without \nlegal knowledge, noting the amount of time it took him to complete the survey and \nany confusion during the process. This led us to amend the instructions slightly: for \nexample, they were edited to specify, in question four, that the plaintiff needed to \nhave suffered financial damages specifically.\nTable 2 includes questions for each of our charges (excluding the background \ninformation). Our complete, final jury instructions can be found in “Appendix 7”.\n2.2.7  Survey\nWe used Qualtrics to host our survey and Prolific to recruit our participants. Pro-\nlific provides pre-vetted candidates for research surveys (noa, 2014). Each respond-\nent received one of the 20 total complaints and the corresponding jury survey for \n712 A. Trozze et al.\nthe charge in that complaint. Our final data set included 88 respondents. For further \ndetails on our pre-screening, execution, demographic data, and quality control pro-\ncess, see “Appendix 8”.\n3  Results\n3.1  GPT‑3.5’s ability to discern violations of federal U.S. law\nOverall, GPT-3.5’s ability to determine violations of U.S. federal law from a \nset of facts was poor, with an average final score across all cases and all runs \n( n = 100 ) of 0.324 ( SD = 0.317 ) with a 95% confidence interval around the mean \nof [0.262 −− 0.386] . The full performance metrics are reported in Table  3. For five \nTable 2  Abridged jury instructions\nSecurities act Exchange act violations\n1. Assuming the facts alleged in the complaint \nyou read are true, and noting the definitions of a \nsecurity and sale thereof provided above, do you \nfind that one or more of the defendants directly or \nindirectly sold securities to the plaintiff?\n1. Assuming the facts alleged in the complaint you \nread are true, and noting the definitions provided \nabove, do you find that one or more defendants \n(a) used a device, scheme or artifice to defraud, \n(b) made an untrue statement of material fact or \nmade a statement that was misleading because \na material fact was omitted, OR (c) engaged in \nany act, practice, or course of business which \noperated as a fraud or deceit upon any person?\n2. Assuming the facts alleged in the complaint \nyou read are true, and noting the definitions \nof “interstate commerce” and “instrument of \ntransportation or communication” provided \nabove, do you find that one or more defendants \nused an instrument of transportation or \ncommunication in interstate commerce in \nconnection with the offer or sale of a security?\n2. Assuming the facts alleged in the complaint \nyou read are true, do you find that one or more \ndefendants engaged in fraudulent conduct “in \nconnection with” the purchase or sale of a \nsecurity?\n3. Assuming the facts alleged in the complaint you \nread are true, do you find that “the securities at \nissue weren’t registered” (Dalton 2013)?\n3. Assuming the facts alleged in the complaint you \nread are true, do you find that one or more of \nthe defendants acted knowingly or with severe \nrecklessness?\n4. Do you find that the plaintiff suffered financial \ndamages?\n4. Assuming the facts alleged in the complaint \nyou read are true, do you find that one or more \nof the defendants’ conduct involved interstate \ncommerce, the use of the mails, or a national \nsecurities exchange?\n5. Did you answer “yes” to all of questions 1, 2, 3, \nand 4?\n5. Did you answer “yes” to all of questions 1, 2, 3, \nand 4?\n6. Thinking about your answers to questions \n1–5, how confident are you, overall, that you \nhave made the correct decision? Please rate \nyour confidence on a scale of 1–5, with 5 being \nextremely confident and 1 being not confident at \nall\n6. Thinking about your answers to questions \n1–5, how confident are you, overall, that you \nhave made the correct decision? Please rate \nyour confidence on a scale of 1–5, with 5 being \nextremely confident and 1 being not confident \nat all\n713\nLarge language models in cryptocurrency securities cases:…\ncases (Mark Winter, et al. v. Stronghold Digital Mining, Inc., et al., 1:22-CV-03088, \nSDNY; Philip Golubowski, et  al. v. Robinhood Markets, Inc., et  al., 5: 21-CV-\n09767, N.D. Ca.; Underwood, et al. v. Coinbase Global Inc., 1:21-cv-08353, SDNY; \nSecurities and Exchange Commission v. Green United, LLC, et al., 2:23-cv-00159, \nD. Utah; Securities and Exchange Commission v. Paul A. Garcia, 1:22-cv-00118, D. \nColo.), the LLM did not determine any of the charges correctly in any of the outputs.\nWe note that, in general, precision (with a mean value of 0.66) tended to be \nhigher than recall (which had a mean value of 0.25). This reflects the fact that the \noutputs were particularly prone to false negatives: when violations were identified, \nthey tended to be correct, but the main shortcoming was the failure to identify \nviolations. In Securities and Exchange Commission v. Arbitrade Ltd., et  al., for \nexample, GPT-3.5 produced false negatives between 8 and 8.5 of the 9 total charges, \nonly identifying between 0.5 and 1 correct charge. This is more promising in terms \nof LLMs’ usefulness as a tool to assist lawyers; it is much better for a case to exclude \npotentially relevant allegations, than to include entirely incorrect ones.\n3.2  ChatGPT’s pleading drafting ability\nThe raw data from our surveys can be found in “Appendix 9”. Demographic data on \nthe respondents can be found in “Appendix 8”.\n3.2.1  Respondent agreement\nTo answer our question of whether jurors’ decisions on complaints differed depend-\ning on their authors (AI versus a human lawyer), we first examined the levels of \nagreement among the reviewers for each of our cases. We examined this for the final \ndecision as to whether or not the charge in question was proven (based on question 5, \n“Did you answer “yes” to all of questions 1, 2, 3, and 4?”). The participants decided \nthat the cases were proven in almost all instances ( n = 74 ), regardless of the author \n(84.1%). Since we only sought to evaluate agreement based on this final (binary) \nquestion, we simply calculated the percentage of the total participants who agreed \nthat the charge in question was proven.10 Therefore, a percentage closer to either 0% \nor 100% (i.e., no jurors thought the charge was proven (0%) or all the jurors agreed \nit was (100%)) would indicate high levels of agreement, while a percentage closer to \nTable 3  GPT-3.5’s ability \nto discern violations of U.S. \nsecurities laws, average metrics \nacross all outputs ( n = 100)\nMetric Mean SD\nRecall 0.252 0.304\nPrecision 0.658 0.459\nFinal score 0.324 0.317\n10 We acknowledge that there are various statistical measures used to calculate coder agreement, such as \nCohen’s Kappa. However, because the conclusion of each of our mock jurors was the answer to a single, \nbinary question, using such a metric was not necessary in this case.\n714 A. Trozze et al.\n50% would indicate less agreement. As reported in Table  4, the level of agreement \nwas moderate, overall, for most of our cases. The level of agreement was at chance \n(50%) for three of our cases, two of which were drafted by ChatGPT and one of \nwhich was drafted by a lawyer.\n3.2.2  Juror confidence\nWe sought to examine whether juror confidence (on a scale of 1–5, with 1 being not \nconfident at all and 5 being extremely confident) was different for complaints drafted \nby ChatGPT compared to those drafted by lawyers. To test this, we compared the \nmean confidences using a Mann Whitney U-test. 11 The mean juror confidence for \nChatGPT-generated complaints was 3.78, which a standard deviation of 0.99. For \nlawyer-drafted complaints, our jurors’ mean confidence was 3.98, with a standard \ndeviation of 0.84. There was no evidence that our jurors’ confidence scores differed \nbetween the two categories of authors ( U = 1060 , p = 0.371 , eﬀect size = 0.095 \nTable 4  Respondent agreement on decisions\nCase Number of \nparticipants\n% Yes\nLee, et al. v. Binance, et al., GPT-drafted complaint 4 75\nLee, et al. v. Binance, et al., lawyer-drafted complaint 4 100\nUnderwood, et al. v. Coinbase, et al., GPT-drafted complaint 6 83.3\nUnderwood, et al. v. Coinbase, et al., lawyer-drafted complaint 5 80\nBrola v. Nano, et al., GPT-drafted complaint 4 100\nBrola v. Nano, et al., lawyer-drafted complaint 4 75\nHa v. Overstock.com, et al., GPT-drafted complaint 4 75\nHa v. Overstock.com, et al., lawyer-drafted complaint 5 100\nHong, et al. v. Block.One, et al., GPT-drafted complaint, Securities Act charge 4 100\nHong, et al. v. Block.One, et al., lawyer-drafted complaint, Securities Act Charge 4 100\nHong, et al. v. Block.One, et al., GPT-drafted complaint, Exchange Act charge 6 83.3\nHong, et al. v. Block.One, et al., lawyer-drafted complaint, Exchange Act charge 4 50\nBalestra v. Cloud With Me Ltd., GPT-drafted complaint 4 100\nBalestra v. Cloud With Me Ltd., lawyer-drafted complaint 4 100\nAudet, et al. v. Garza, et al., GPT-drafted complaint 5 50\nAudet, et al. v. Garza, et al., lawyer-drafted complaint 4 75\nKlingberg v. MGT Capital Investments Inc., et al., GPT-drafted complaint 4 50\nKlingberg v. MGT Capital Investments Inc., et al., lawyer-drafted complaint 4 100\nDavy v. Paragon Coin Inc., et al., GPT-drafted complaint 5 80\nDavy v. Paragon Coin Inc., et al., lawyer-drafted complaint 4 100\n11 We used this non-parametric test because our data were not normally distributed, as per the Shap-\niro-Wilk test, the results of which are reported in “Appendix 10”. We used the Mann–Whitney U test \nbecause our samples were still independent.\n715\nLarge language models in cryptocurrency securities cases:…\n(Karadimitriou and Marshall, n.d.)). This suggests that ChatGPT performed well at \nthis legal drafting task.\n3.2.3  Association between author and juror decision\nNext, we looked at whether the author (human vs. ChatGPT) and the ultimate \ndecision were associated in our cases using Fisher’s Exact test. Table  5 reports the \ntwo-way table for our data.\nFisher’s Exact test indicated that the author was not statistically significantly \nassociated with the decision made by the respondents ( p = 0.39 ). This, again, \nsuggests that ChatGPT’s performance at this legal drafting task was as good as that \nof a lawyer.\n3.2.4  Qualitative analysis of complaints\nWe qualitatively compared the complaints ChatGPT produced with those written by \nlawyers. Overall, it was difficult to distinguish the complaints based on the author. \nThe primary difference between the complaints drafted by each category of author \nwas that the AI-generated versions were slightly more concise and less detailed. In \ngeneral, we observed that the AI-drafted complaints were more straightforward, an \neffect we report linguistic analyses and quantitative findings on in Sect. 3.2.5.\nSomewhat notably, ChatGPT performed the worst at drafting captions for \ncomplaints, and this section needed to be regenerated more often than other sections \n(though, still, seldom, in only the Lee, et al. v. Binance, et al., Underwood, et al. v. \nCoinbase Global Inc. and Hong, et al. v. Block.One, et al. cases). For all sections, \nChatGPT tended to include some sections of the complaint outside of that specified \nin the prompt (including, sometimes, an entire, very short complaint, similar to that \nin Perlman 2022). However, it appeared to focus primarily on the section included in \nthe prompt.\nIn one case, Hong, et al. v. Block.One, et al., we noted the different sections of \nthe complaint generated were slightly inconsistent. For example, in the jurisdiction \nsection, the complaint refers to violations of Section 12(a)(2) of the Securities Act, \nwhile the actual charge included in the legal claims for relief was Section 12(a)(1) \nthereof. Furthermore, in another cased, Audet, et al. v. Garza, et al., the complaint \nincludes different locations for one of the parties in different sections.\nTable 5  Two-way table for \nauthor and juror decision ChatGPT Lawyer Total\nProven\n  No 9 (19.6%) 5 (11.9%) 14 (15.9%)\n  Yes 37 (80.4%) 37 (88.1%) 74 (84.1%)\nTotal 46 42 88\n716 A. Trozze et al.\nOne of the key issues with using ChatGPT for legal tasks that others have noted \nas a risk (for example, Choi et al. 2023), is its tendency to hallucinate or “fabricate” \nfacts or statutes. We did notice this in two instances, namely that ChatGPT added \n“John Doe” defendants in two complaints (Hong, et  al. v. Block.One, et  al., \nKlingberg v. MGT Capital Investments Inc., et  al.). Our finding that ChatGPT \nhallucinated defendants in these two cases is consistent with our observation that \nChatGPT was least successful in generating the output for the caption section.\nWe noticed that the complaint quality varied slightly among different jurisdictions \n(for example, the Klingberg v. MGT Capital Investments Inc., et al. complaint in the \nDistrict of New Jersey was of slightly poorer quality than the Underwood et al. v. \nCoinbase Global Inc. one in the SDNY), though we did not quantify this effect. \nFurthermore, the ChatGPT-generated complaint for the Lee, et al. v. Binance, et al. \ncase was of slightly lower quality than some of the others. We hypothesized that this \nwas because the article for the case was less focused (at least, as per our qualitative \nevaluation), and included facts from several other cases. We test this hypothesis in \nSect. 3.2.5 below.\nFinally, an important consideration in terms of ChatGPT’s legal drafting ability is \nthe level of human intervention required to produce the final complaint. In our study, \npost-editing the lawyer-drafted complaints to exclude facts that were not present \nin the Law360 article was more labor-intensive than post-editing the ChatGPT-\ngenerated complaints. Aside from the two cases where we needed to remove the \nadditional “John Doe” defendants ChatGPT hallucinated, and where we needed to \nrevise one reference to the specific section of the Securities Act that was violated, \nthe remainder of the deletions occurred where ChatGPT had inserted placeholder \ntext, the need for specific details should be inserted (such as the Plaintiff’s residence \nor the dates of the class period), which were absent from the Law360 article. \nThe only other time we needed to remove information ChatGPT included was in \nthe Audet, et  al. v. Garza, et  al. complaint, where we excluded the specific (and \ndifferent) locations it generated for a party in different sections of the complaint.\nFinally, we noticed a few stylistic differences between ChatGPT- and lawyer-\ndrafted complaints. ChatGPT did not include any sub-headings in its sections, \nthough these are quite common in lawyer-drafted complaints. Furthermore, \nChatGPT frequently (and without any seeming purpose) added “wherefore” before \nsentences.\n3.2.5  Quantifying complaint concreteness\nOur primary qualitative finding that the ChatGPT-drafted complaints were more \nstraightforward than the lawyer-drafted ones motivated us to quantify this effect. We \nused the concept of concreteness, from the field of computational linguistics, to test \nthis (Kleinberg et al. 2019). In language, concreteness means “the degree to which \nthe concept denoted by a word refers to a perceptible entity” (Brysbaert et al. 2014). \nWe measure concreteness using Brysbaert et  al.’s (2014) concreteness dictionary. \nIn developing this data set, the researchers asked 4000 human participants to score \nalmost 40,000 words on a scale of 1–5, with 1 meaning abstract and 5 meaning \nconcrete. Abstract words have “meanings that cannot be experienced directly \n717\nLarge language models in cryptocurrency securities cases:…\nbut which we know because the meanings can be defined by other words”, while \nconcrete ones are those which one “can experience directly through one of the five \nsenses” (Brysbaert et al. 2014).\nTo calculate the concreteness of our complaints, we tokenized the text from each \ncomplaint. For each token within each text, we obtained the average concreteness \nscore therefor from the Brysbaert et  al. (2014) data set. We used code published \nby Kleinberg et al. (2019) for this task. The average concreteness score of all the \ntokens for each complaint constituted our final concreteness score. We used a \nt-test to determine whether the concreteness scores for the complaints written by \nChatGPT were significantly different from those written by lawyers. 12 The average \nconcreteness score for the ChatGPT-drafted complaints was 2.30 ( SD = 0.06 ). For \nlawyer-drafted complaints, the average concreteness was lower, at 2.25 ( SD = 0.06 ). \nThe concreteness scores for each complaint are reported in “Appendix 11”.\nAccording to our t-test, the average concreteness scores were significantly \ndifferent between the two authorship categories, with a large effect size ( t(8)= 3.25 , \np = 0.012 , Cohen �sd = 1.08, 99% CI = [−0.02, 2.18]).\nNext, we explored whether the level of concreteness in the Law360 article \npresented to ChatGPT was associated with the level of concreteness in the complaint \nultimately drafted by ChatGPT. To do this, we calculated the concreteness score for \nthe text of each Law360 article ( M = 2.38,SD= 0.09 ) fed to ChatGPT and used the \ncorrelation between the Law360 article’s concreteness and the resulting complaint’s \nconcreteness ( M = 2.30,SD= 0.06 ) to measure this effect. The Pearson correlation \ncoefficient between the Law360 article’s concreteness and the concreteness of the \nAI-generated complaint was r = 0.78 ( 95% CI =[ 0.24, 0.95] , p = 0.01 ). This \nshows a statistically significant positive correlation between the Law360 article’s \nconcreteness and the concreteness of the resulting ChatGPT-generated complaint. \nThe higher the concreteness of the Law360 article, the higher the concreteness of \nthe complaint generated therefrom.\n4  Discussion\n4.1  GPT‑3.5’s ability to discern violations of U.S. law\nThis paper tests whether GPT-3.5 can correctly determine which federal U.S. laws \nare potentially being violated from a given fact pattern. Overall, GPT-3.5’s ability \nto determine potential violations of U.S. law from a given set of facts was poor. The \nprimary reason for the low overall performance metrics was the high number of false \nnegatives (i.e., violations it missed which were charged in the complaint). Because \nof this, the precision scores tended to be much higher than the other performance \nmetrics.\n12 The distribution for our two samples was normal ( Shapiro-Wilk = 0.901 , p = 0.256 for GPT-gener-\nated complaints, and Shapiro-Wilk = 0.850  , p = 0.074 for lawyer-generated ones). The variances for \nboth of our samples were the same.\n718 A. Trozze et al.\nThis shows more promise in terms of LLMs’ ability to conduct legal \nreasoning tasks on behalf of lawyers, at least in a preliminary capacity. It would \nbe preferable for fewer, but correct, charges to be identified, as opposed to the \ninclusion of erroneous charges, at least from a malpractice perspective. However, \nthe trade-off of minimizing the number of false positives is that more manual \nanalysis is, then, required to “fill out” the appropriate violations. Therefore, using \nan LLM to assist in legal reasoning of this nature would only be even somewhat \nuseful at a preliminary stage. In an ideal world, an LLM would be most useful to \nlawyers as a “sense check” to make sure they were not missing any violations, \nbut the observed tendency towards minimizing false positives means it would \nnot be useful, at present, in this regard. Further to this, however, the charging \ndecision-making process ordinarily goes through several iterations involving \nmany lawyers. In this sense, the benchmark to which we compare GPT-3.5’s \nperformance may be unreasonably high.\nDespite GPT-3.5 missing several of the violations included in the complaint, its \noverall analysis of the facts for the charges it determined correctly was good (though \nwe can only evaluate this qualitatively), using the legal reasoning framework \nprovided. This is consistent with Yu et al.’s (2022) findings that prompts including \nthe IRAC legal reasoning framework produced good results. Finally, we expect these \nmodels’ performance to improve as they incorporate more data.\nMoreover, securities class action cases, in particular, are often dismissed. In a \nstudy of 652 such cases filed between 2006 and 2010, 32% were dismissed with \nprejudice. After the first complaint was filed, of 533 cases completed before the \nstudy and filed during the study period, 25% were dismissed with prejudice and 34% \nwere dismissed without prejudice (Klausner et  al. 2013). Therefore, it is possible \nthat several of the charges GPT-3.5 failed to identify could have later been dismissed \nor not proven at trial—in this sense, such charges could in fact be considered to be \ntrue, rather than false, negatives. In that case, if GPT-3.5 only charged violations \nlater confirmed by a judge or jury, its performance would be considered as good as \nthat of a lawyer (notwithstanding the potential strategic reasons for including charges \nthat are subsequently dismissed). We were unable to test this because the cases were \nongoing, however, it would be a fruitful avenue for future studies to explore.\nWe note that there could be other variables that account for GPT-3.5’s overall \nexclusion of many of the relevant violations in the complaint. Overall, it may simply \nbe more conservative in estimating violations of law than the lawyers who drafted \nthe complaint. This is something with which future research could experiment in \nterms of prompt engineering, for example, by instructing an LLM to “include all \ncharges for which there is any possibility they might be viable.” Generally, GPT-\n3.5 cited far fewer violations of law, with many outputs only suggesting a single \nviolation. This could also relate to lawyers’ occasional tendency to “stack” charges, \noften to inspire defendants to settle more readily. This means our ground truth is not \nnecessarily objectively consistent either. This is consistent with the high number of \nfalse negatives we saw across our data set.\nFurthermore, it could be the case that the facts sections from some of these \ncomplaints were written more clearly than others, or at least written in a way that is \nmore conducive to helping the LLM identify relevant violations of law.\n719\nLarge language models in cryptocurrency securities cases:…\nAt times, GPT-3.5 did not follow the instructions in the prompt. For example, \ndespite asking the model to be specific about the sections of statutes which were \nviolated, sometimes it did not even include the name of a statute at all, let alone \nthe sections violated. Furthermore, the instructions requested it provide violations of \nfederal law only; however, at times, it included violations of state law as well. This \nwas somewhat surprising, particularly compared to other research (such as Choi \net al. 2023), which found it followed instructions well.\nAside from this, our results are generally consistent with previous research. For \nexample, Blair-Stanek et  al. (2023) also found that GPT-3 ’s statutory reasoning \nskills are lacking. Similarly, Choi et  al. (2023), noted an example of an “issue \nspotter” question (which refers to a similar task as in our study) in their test; \nChatGPT only spotted one of the five correct issues correctly.\n4.2  ChatGPT’s pleading drafting ability\nThis study also examined whether mock jurors made different legal decisions \nbased on pleadings written by ChatGPT compared with those written by a lawyer. \nOverwhelmingly, ChatGPT drafted convincing complaints, which performed \nonly slightly worse than the lawyer-drafted ones in terms of convincing jurors the \nallegations were proven (80% of AI-drafted complaints were proven according to \nour jurors, compared to 88% of lawyer-drafted ones). Our data, specifically our \nfindings that complaint author was not associated with juror decision, and that the \ndistribution of juror confidence did not differ between different authors, support \nthese conclusions.\nWe found the lawyer-generated complaints were less concrete than the \nAI-generated ones (though we note that, while statistically significant, the difference \nis minimal in absolute terms). This supports our qualitative findings that the \nAI-generated complaints were less abstract and more “to the point” than the lawyer-\ndrafted ones. In practice, a lawyer using ChatGPT as a drafting assistant would add \nmore abstraction (as per accepted legal drafting style) to the skeleton version the \nAI drafted. If lawyers increasingly use AI tools as drafting assistants, we could, \nhowever, see a future stylistic change in the industry, with less linguistic abstraction \noverall.\nNotably, ChatGPT (and, indeed, lawyers), were able to write convincing \ncomplaints even for cases which were ultimately dismissed. In the case of the \nlawyer-drafted complaints, abridging these complaints (particularly removing \nspecific charges) may have removed the sections upon which the judge’s ultimate \ndismissal decision hinged. This could explain, in part, why so many cases were \nproven according to our jurors. Furthermore, jurors do not reason the same way as \njudges, and, indeed, the criteria for dismissal are different than those required to \nprove a violation. Finally, the mock jurors in this study did not act like real-world \njurors in that we instructed them to assume all facts in the complaint were true.\nOur finding of a positive, statistically significant linear correlation between \nthe level of concreteness in the Law360 article on which our ChatGPT-generated \ncomplaint was based, and the concreteness score of the resulting complaint, supports \n720 A. Trozze et al.\nthe conclusion that some of the complaint quality was likely associated with the \nlevel of detail in the Law360 articles which were provided as source material.\nOther scholars have noted the possibility of ChatGPT having been trained \non some legal sources (Bommarito  II and Katz 2022). We were concerned about \nthis in answering our second research question, because we had to include cases \nwhich were filed before our model’s training period, due to a lack of cases filed \nonly afterwards which met our selection criteria. However, consistently with Blair-\nStanek et  al.’s (2023) results, there was no indication (in our qualitative analysis \nof the complaints drafted) that made us suspicious that this was the case in our \ncontext (i.e., the ChatGPT-drafted complaint did not generally include facts which \nwere not part of the article in the prompt). Hallucinations only occurred in three, \nminor instances. In two complaints (Hong, et al. v. Block.One, et al., Klingberg v. \nMGT Capital Investments Inc., et al.), this took the form of ChatGPT inaccurately \nadding “John Doe” defendants, rather than devising specific, fictitious facts. In the \nthird case (Audet, et al. v. Garza, et al.), the location of a company involved was \ninconsistent across different sections of the complaint ChatGPT generated. This was \na large, multinational company, and it may be the case that ChatGPT’s training data \nincluded information about multiple of its locations (but, not likely about this case).\nOur finding that complaints written for the SDNY were of a higher standard \nthan those in the District of New Jersey, is intuitive, since more civil securities and \ncommodity suits tend to be filed in the SDNY than any other jurisdiction, so the \ntraining data set likely would have included more cases from this jurisdiction, if \nit included any at all. For example, in March 2021, 36.8% of suits of this nature \nwere filed in the SDNY, compared to only 11.9% for the next most popular filing \njurisdiction (TRAC 2021).\nOverall, our results are consistent with prior research that qualitatively \ndetermined that ChatGPT showed some skill in drafting legal documents (Iu and \nWong 2023; Perlman 2022). Similarly, Choi et  al. (2023)’s finding that ChatGPT \nperformed better on essay questions than multiple choice ones is consistent with our \nfinding that ChatGPT performed better in drafting than in statutory reasoning.\n4.3  Limitations and future research\nNormally, jurors do not evaluate complaints, and, before a jury decides a case, they \nare presented with manifold evidence (and corroborating witness testimony) and \nsummative arguments of the facts and legal issues from lawyers. They also have the \nopportunity to deliberate with their fellow jurors. In our study, we sought to obtain a \nbaseline for juror decision-making based on a single document, assuming the facts, \nas presented, are true. Future research could explore conducting an entire mock \ntrial using ChatGPT, rather than abstracting a specific element of the legal process \nas we have done, or employ lawyers to evaluate ChatGPT- and lawyer-generated \ncomplaints rather than laypeople.\nFurthermore, there is no way to access all of the facts that the lawyers had when \nthey were drafting the original complaints. We concluded that the best way to, \ntherefore, “feed” ChatGPT the facts of each case would be to provide a summary \n721\nLarge language models in cryptocurrency securities cases:…\nof the facts and allegations from a reputable news outlet (in this case, we used \nLaw360). One of the primary concerns with this is that the facts espoused in the \narticle were pulled from the original complaint itself. However, since in this part \nof our research we are were merely testing ChatGPT’s legal writing ability (i.e., its \ncapacity to, given a set of facts and allegations, draft a pleading), we proceeded in \nthis manner.\nThe lawyer-drafted complaints, also, naturally, frame the facts in a manner \nthat supports the charges they assert. Assuming these framing choices are \nreflected in the Law360 article, it is possible that ChatGPT could produce \nconvincing complaints by merely paraphrasing the article. Put simply, the input \ngiven to ChatGPT is already (indirectly) the product of some evaluation by a \nhuman lawyer, and so does not entirely reflect the “raw” form of the facts of the \ncase. Again, since our aim is to obtain a baseline of ChatGPT’s legal drafting \ncapabilities, this input still allows this to be established; however, future research \ncould explore performance when provided with more basic input. Finally, \nLaw360 does require a subscription, which could hinder the reproducibility of \nresults. However, they offer free trials which would be sufficient for this purpose.\nIn the first part of our study, we decided not to test any cases that were filed \nbefore our model’s training cut-off date in June 2021. Due to the lengthy nature \nof the legal process, these cases had generally not yet been decided. Therefore, \nwe needed to use the charges in the complaints as our ground truth, though \nlawyers’ judgments are not infallible—nor indeed are they always based purely \non the factual “correctness” of charges. Lawyers may choose to file, or not to \nfile, charges for other strategic reasons, and so the goals of lawyers may not \nbe perfectly aligned with the task that an LLM is seeking to carry out. Future \nresearch could employ a set of lawyers to evaluate the LLM-generated charges, \nwithout considering strategic factors. Similarly, in the second part of our study, \na judge’s decision to deny or grant a motion to dismiss is subjective, and some \ncould consider the decision incorrect. However, in this study, we sought to \nevaluate ChatGPT’s drafting and decision-making, not that of lawyers and judges.\nAdditionally, all our complaints required human intervention, whether \ndrafted by ChatGPT or a lawyer. Overall, the post-edits for the lawyer-generated \ncomplaints were much more extensive than for the ChatGPT-generated ones. \nWith a few, minor exceptions (discussed in detail in Sect.  3.2.4), our amendments \ngenerally involved removing placeholder text ChatGPT provided. This level of \nintervention is consistent with our goal of evaluating ChatGPT’s ability to assist \nlawyers in the legal drafting process. Future research could experiment with \nproviding pure facts to ChatGPT and prompting the model to generate complaints \nin the same manner as we did—without any additional alterations—to determine \nif ChatGPT could perform satisfactorily as a lawyer on its own.\nFinally, there are some limitations associated with using participants from \nProlific in a study. First, some participants completed our survey very quickly \n(median = 12:49:59 for all participants, including those whose entries were, \nultimately, rejected), though we accounted for this in our quality control \nprocedures, the details of which can be found in “Appendix 8 ”. In any case, this \nkind of variability would be normal on a real-life jury as well. Furthermore, the \n722 A. Trozze et al.\nhigh cost of using this platform meant we could not recruit more jury participants. \nThis is somewhat exacerbated by the fact that few cases existed overall which met \nour inclusion criteria, making it slightly more difficult to generalise based on our \nresults.\nFuture research could use longer factual texts to determine whether the length \naffects the output, test these prompts on more powerful models, use different \nparameters to test these or related prompts, or test these prompt formats on other \ntypes of cases. Future research could also explore LLMs’ legal reasoning and \ndrafting capabilities in other jurisdictions. This may be particularly interesting in \njurisdictions where case documents are not available online (and, therefore, they \nwould be unlikely to have been trained on relevant examples thereof).\n4.4  Conclusions: do LLMs have the potential to meaningfully assist lawyers?\nIn this study, we systematically evaluated GPT-3.5’s and ChatGPT’s potential \nusefulness in assisting with key elements of the legal process, namely legal \nreasoning and drafting. To this end, we used cryptocurrency securities cases as an \nexample of the many potential areas of law where such support could be useful. \nOurs is the first study to systematically examine LLMs’ legal drafting and reasoning \ncapabilities in a) litigation, b) the context of securities law, or c) in cases involving \ncryptocurrencies. We conducted two investigations-one involving asking GPT-\n3.5 an open-ended legal reasoning question, and the other a mock jury exercise \nrequiring jurors to make decisions based on documents drafted by either ChatGPT \nor a human lawyer. Consistently with previous research, we found that the LLM was \nable to determine some federal civil laws which were potentially being violated in a \ngiven fact pattern from a real-world case; however, it tended to miss several salient \nviolations. Nevertheless, we expect LLMs’ capabilities in this regard to improve \nas the models advance further. In contrast, again similarly to other preliminary \nempirical research and anecdotal evidence, ChatGPT performed well at the legal \ndrafting task, namely drafting a complaint in a securities cryptocurrency class action \nlawsuit using facts from real-life cases. While GPT-3.5’s current inability to perform \na legal task as basic as legal reasoning means that it is unlikely to replace lawyers \nany time soon, ChatGPT’s legal drafting skills may be able to support lawyers by \nreducing drafting time for key legal documents.\nAppendix 1: Securities class action suit procedures\nAppendix 1.1: U.S. civil procedure\nTo commence a civil case in a U.S. federal court, 13 the plaintiff (the party bringing \nthe case) files what is called a complaint. This pleading is a legal document that \n13 Federal courts have jurisdiction over violations of federal law (Practical Law 2023). Federal Courts \ncan also exercise diversity jurisdiction where the amount in controversy exceeds $5 million and on the \nbasis of geographic diversity between plaintiffs and defendants (Lender et al. 2023).\n723\nLarge language models in cryptocurrency securities cases:…\nincludes the basis of the court’s jurisdiction, the claims being brought, and what \nis referred to as a “prayer for the relief” that the plaintiff seeks in response to the \ndefendant’s alleged wrongdoing (McRae et al. 2023). A complaint must include the \nfollowing required elements:\n• A “caption” at the top, which is a heading that includes the court’s name, the \ndocket number (this is the case number, which the court assigns), the names of \nthe parties, and “Complaint” as the document title. If the case is a class action \nmatter (described below), this must also be included in the caption (Practical \nLaw Litigation 2023a).\n• A jury demand if the plaintiff wants a jury to decide the case (Practical Law \nLitigation 2023a).\n• Various, specific sections in the body of the complaint:\n– Preliminary statement, which provides an overview of the case, “identifies \nthe main parties, important facts, legal causes of action, and relief sought” \n(Practical Law Litigation 2023a).\n– Jurisdiction, which briefly explains why the court has jurisdiction over this \ncase.\n– Venue, which describes why this district court is the correct one to hear this \ncase. District courts are federal trial courts in the U.S.\n– Parties, which describes the plaintiffs and the defendants in the case, \nincluding why the court has jurisdiction over the defendants and the subject \nmatter in question.\n– Facts, which lays out the events and defendant’s actions, on which the \nplaintiff’s legal claims are based.\n– Legal claims, each of which is one “Count” against the defendant. Each count \nis a separate section and explains why the facts of the case support each \nallegation. At the end of each section, the plaintiff requests the appropriate \nrelief from the court (Practical Law Litigation 2023a).\n– Prayer for Relief, “reiterating the remedies sought for each count in the \ncomplaint” (Practical Law Litigation 2023a).\n– Signature block, with the plaintiff’s attorneys’ information and a signature.\nAll paragraphs in the complaint are numbered and there may be sub-headings \nwithin each section. Certain exhibits can be attached to the complaint to verify the \nallegations contained therein. “If the plaintiff does not know all of the facts at the \ntime it files the complaint, it may allege certain facts are true based on “information \nand belief”” (Practical Law Litigation 2023a).\nOnce filed with the court with the appropriate filing fee, the plaintiffs must serve \nthis complaint on the defendant. The defendant must then respond to the complaint \nwithin a set period of time, either with an “answer” to the complaint, or a pre-\nanswer motion, the most common of which is a motion to dismiss (MTD). An \nanswer responds to the allegations in the complaint, offers general legal defenses \nto the allegations, and may include counterclaims against the plaintiff (McRae et al. \n2023). A MTD includes legal arguments as to why a case is not valid and should be \nthrown out by the judge. “In ruling on a motion to dismiss, the court must accept \n724 A. Trozze et al.\nthe nonmoving party’s allegations as true and usually may not consider extrinsic \nevidence” (McRae et al. 2023).\nNext, the parties begin gathering facts about the case, preserve the necessary \nevidence, etc. (McRae et al. 2023). What is called “motion practice” begins (these \nare called “pre-trial” motions if a trial is demanded by the plaintiff), whereby \neach party files various motions with the court (and legal memoranda or briefs \nthat support these motions as well as relevant evidence) (Practical Law Litigation \n2023d). Motions are, essentially, lawyers’ requests to the court for decisions on legal \nor procedural issues in connection with the case. There are various categories of \nmotions. The first category is nondispositive motions, which include motions for \nother parties (not named in the case) to intervene, motions to amend pleadings, and \nmotions for attorneys to be admitted pro hac vice (meaning they wish to appear \nbefore a court in which they are not already formally admitted to practice) (Practical \nLaw Litigation 2023e).\nDiscovery motions, which deal with evidence, are also filed. These include, for \nexample, motions to compel discovery, quash or modify a subpoena, sanction parties \nfor failure to preserve evidence, and other motions (Practical Law Litigation 2023b). \nDispositive motions are also common, such as a motion for summary judgment, a \nMTD (if not already filed and decided), or a motion for default judgment (Practical \nLaw Litigation 2023c).\nFinally, attorneys may file evidentiary pre-trial motions, such as motions in \nlimine, which concern evidence to be presented to the jury, and Daubert motions \nwhich relate to expert testimony (Weinberger et al. 2023). The judge decides on all \nmotions, sometimes at pre-trial hearings (United States Courts 2022).\nOnce pre-trial motions are all decided, the jury selection process begins for \nfederal trials and jury instructions are submitted. Jury instructions include the legal \nstandards for the case (i.e., the burden of proof), the laws that must be applied, \nhow the jury should use the evidence presented at trial and what evidence they can \nconsider, as well as other legal and practical information (Weinberger et al. 2023). \nIn general, the burden of proof in civil trials is the “preponderance of evidence” \n(United States Courts 2022). This means that the plaintiff must prove that it is more \nlikely than not that violation of the law occurred.\nDuring the trial, each side presents their opening statements, introduces evidence \n(through witnesses and exhibits), and presents a closing statement. Unless otherwise \ndecided, the civil jury will contain at least six members and their decision must be \nunanimous (Weinberger et al. 2023).14\nAppendix 1.2: Securities class action procedures under the PSLRA\nA securities class action case begins when a plaintiff files a securities class action \ncomplaint. If similar actions have already been brought, the plaintiffs may decide \nto consolidate them. The court appoints a “lead plaintiff” for the class action. The \ndefendant(s) then respond, usually with a MTD. Because of the requirements set \n14 If the jury does not reach a unanimous decision, the judge may instruct them to deliberate further or \norder a new trial (noa, 2020).\n725\nLarge language models in cryptocurrency securities cases:…\nforth in the PSLRA, many securities class actions do get dismissed. Cases may be \ndismissed for any of the following reasons:\n• Lack of jurisdiction of the court (either subject matter or personal);\n• Improper process or service thereof;\n• “Improper venue” (Practical Law Securities Litigation & White Collar Crime \n2023);\n• “Failure to state a claim” (most commonly claimed in securities class action \nMTDs, as this reflects the underlying weakness of the case) (Practical Law \nSecurities Litigation & White Collar Crime 2023); or\n• “Failure to join a party” (Practical Law Securities Litigation & White Collar \nCrime 2023).\nIf the case survives dismissal, the next step is for the plaintiffs to request class \ncertification by the judge. The general requirements for class certification are: \n1. “Commonality, meaning there are questions of law or fact common to the class” \n(Practical Law Securities Litigation & White Collar Crime 2023);\n2. “Typicality, meaning that the claims or defenses of the named plaintiff are typical \nof the class” (Practical Law Securities Litigation & White Collar Crime 2023); \nand\n3. “Adequacy, meaning that the named plaintiff must fairly and adequately protect \nthe interests of the class” (Practical Law Securities Litigation & White Collar \nCrime 2023).\nThe Federal Rules of Civil Procedure specify three categories of cases which can \nbe brought as class actions. Every class action case must fit into one of these three \ncategories. Securities class action suits generally fall under one of the following \ntwo categories: \n1. “Common questions predominate over those affecting only individual members” \n(Practical Law Securities Litigation & White Collar Crime 2023); or\n2. A class action lawsuit is the most efficient and fair way of resolving the case \n(Practical Law Securities Litigation & White Collar Crime 2023).\nThe judge decides whether or not to certify the class and the discovery process \nensues. In securities cases, in particular, the discovery process can be quite \ncumbersome due to the volume of documents involved and may last several \nyears. This is one reason so many securities class actions settle. While the \njudge considers a MTD in a securities class action, discovery is automatically \nstayed; this is not true in a government enforcement case. At this stage, parties \ntend to file various motions, such as motions for summary judgment and \nDaubert motions. The results of such motions tend to be leveraged in settlement \ndiscussions, which are ongoing throughout this process. If no settlement is \n726 A. Trozze et al.\nreached, the case then proceeds to trial (Practical Law Securities Litigation & \nWhite Collar Crime 2023).\nAppendix 2: Case selection\nAppendix 2.1: ChatGPT’s ability to discern violations of U.S. law\nDetails on our reasons for inclusion or exclusion for each cryptocurrency securities \nclass action lawsuit and cryptocurrency-based SEC case filed before our model’s \ntraining cutoff date (June 2021) can be found here: https:// osf. io/ ecqas? view_ only= \n68c96 93fa3 99406 8b20d 1be94 1b9db 0b.\nAppendix 2.2: Differences in juror decision‑making based on human vs. \nAI‑written legal complaints\nDetails on our reasons for inclusion or exclusion for each cryptocurrency securities \nclass action lawsuit filed before our case selection date (May 22, 2023) can be found \nhere: https:// osf. io/ 6we9r? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b.\nAppendix 3: Prompt design process\nAppendix 3.1: ChatGPT’s ability to discern violations of U.S. law\nThe following link contains the prompts and outputs with which we experimented \nin developing the prompts to answer our first research question. It also describes \nour considerations as we fine-tuned the prompts: https:// osf. io/ ejaxr? view_ only=  \n68c96 93fa3 99406 8b20d 1be94 1b9db 0b.\nAppendix 3.2: Differences in juror decision‑making based on human vs. \nAI‑written legal complaints\nThe following contains the prompts and outputs with which we experimented in \ndeveloping the prompts to answer our second research question. It also describes \nour considerations as we fine-tuned the prompts: https:// osf. io/ wszb2? view_  \nonly= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b.\nWhen we submitted our original prompts to the API, we received an error. We \nasked what the issue with this prompt was via the ChatGPT user interface, and it \nreturned the following error message:\n“The main issue with the prompt is that it is asking for the generation of a \nlegal document, specifically the sections of a class action complaint for the \nSDNY, using the openai.Completion.create()method . However, \nthis method is designed for generating text based on a given prompt, and it is \n727\nLarge language models in cryptocurrency securities cases:…\nnot suitable for generating complex legal documents with specific formatting \nand legal requirements.\nGenerating a class action complaint requires specialized legal knowledge, \nattention to detail, and adherence to legal guidelines and formatting \nconventions. It is not appropriate to rely solely on an AI language model to \ngenerate such a document, as it may not be accurate, up-to-date, or tailored to \nthe specific legal context. Legal documents should be prepared by qualified \nlegal professionals who have expertise in the relevant jurisdiction and area of \nlaw.\nIf you need assistance with legal matters, I recommend consulting with a \nlicensed attorney who can provide you with the appropriate legal advice and \nassistance in drafting legal documents.”\nWe received a similar error when we tested the same prompt on ChatGPT’s user \ninterface. We then added a disclaimer to the prompt, indicating the output would be \n“for educational purposes only”. We still received an error using the API but were \nable to generate the desired text using the ChatGPT user interface, specifically the \nMay 24, 2023 version.\nAppendix 4: Outputs and scoring of ChatGPT’s identification \nof potential violations of U.S. law\nThe following contains the five GPT-3.5 outputs identifying potential violations \nof federal civil laws, including the number of input and completion tokens for \neach prompt: https:// osf. io/ jgnea? view_ only= 68c96 93fa3 99406 8b20d 1be94  \n1b9db 0b.\nThe following document includes our scores for each of the outputs found in \nhttps:// osf. io/ jgnea? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b, including \nthe number of true positives GPT-3.5 identified (TP), false positives (FP), and \nfalse negatives (FN): https:// osf. io/ txhy9? view_ only= 68c96 93fa3 99406 8b20d  \n1be94 1b9db 0b.\nThe following contains the performance metrics for each of our outputs, \ncalculated based on the scores awarded in https:// osf. io/ txhy9? view_ only= 68c96 \n93fa3 99406 8b20d 1be94 1b9db 0b: https:// osf. io/ nhm48? view_ only= 68c96 93fa3 \n99406 8b20d 1be94 1b9db 0b.\nAppendix 5: Complaints\nThe following links are to the various complaints presented to this study’s \nparticipants in answering our second research question:\n728 A. Trozze et al.\nSample case\n• SEC v. Kaplan, et al., case number 2:23-cv-01648, in the U.S. District Court \nfor the Eastern District of New York\n– ChatGPT-drafted complaint:\n  https:// osf. io/ gvfcn? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b\n– Abridged, lawyer-drafted complaint:\n  https:// osf. io/ 2gp8f? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b\nAppendix 5.1: Dismissed cases\n• Lee, et al. v. Binance, et al., case number 1:20-cv-02803, in the U.S. District \nCourt for the Southern District of New York\n– ChatGPT-drafted complaint:\n  https:// osf. io/ 8vmjs? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b\n– Abridged, lawyer-drafted complaint:\n  https:// osf. io/ v796f? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b\n• Underwood, et al. v. Coinbase Global Inc., case number 1:21-cv-08353, in the \nU.S. District Court for the Southern District of New York\n– ChatGPT-drafted complaint:\n  https:// osf. io/ 8p5e3? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b\n– Abridged, lawyer-drafted complaint:\n  https:// osf. io/ d4t9b? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b\n• Brola v. Nano, et al., case number 1:18-cv-02049, in U.S. District Court for \nthe Eastern District of New York\n– ChatGPT-drafted complaint:\n  https:// osf. io/ jxwu5? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b\n– Abridged, lawyer-drafted complaint:\n  https:// osf. io/ zetrw? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b\n• Ha v. Overstock.com, et al., case number 2:19-cv-00709, in the U.S. District \nCourt for the District of Utah\n– ChatGPT-drafted complaint:\n  https:// osf. io/ 572mq? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b\n– Abridged, lawyer-drafted complaint:\n  https:// osf. io/ qwgzt? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b\n729\nLarge language models in cryptocurrency securities cases:…\nAppendix 5.2: Continued cases\n• Hong, et  al. v. Block.One, et  al., case number 1:20-cv-03829, in the U.S. \nDistrict Court for the Southern District of New York\n– ChatGPT-drafted complaint:\n  https:// osf. io/ ze6cv? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b\n– Abridged, lawyer-drafted complaint:\n  https:// osf. io/ 7bxfh? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b\n• Balestra v. Cloud With Me Ltd., case number 2:18-cv-00804, in the U.S. District \nCourt for the Western District of Pennsylvania\n– ChatGPT-drafted complaint:\n  https:// osf. io/ yjqsw? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b\n– Abridged, lawyer-drafted complaint:\n  https:// osf. io/ v6gu3? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b\n• Audet, et  al. v. Garza, et  al., case number 3:16-cv-00940, in the U.S. District \nCourt of Connecticut\n– ChatGPT-drafted complaint:\n  https:// osf. io/ 7h2n8? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b\n– Abridged, lawyer-drafted complaint:\n  https:// osf. io/ ptz69? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b\n• Klingberg v. MGT Capital Investments Inc., et al., case number 2:18-cv-14380, \nin the U.S. District Court for the District of New Jersey\n– ChatGPT-drafted complaint:\n  https:// osf. io/ 4tzju? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b\n– Abridged, lawyer-drafted complaint:\n  https:// osf. io/ g3nqc? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b\n• Davy v. Paragon Coin Inc., et al., case number 3:18-cv-00671, in U.S. District \nCourt for the Northern District of California\n– ChatGPT-drafted complaint:\n  https:// osf. io/ tkm95? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b\n– Abridged, lawyer-drafted complaint:\n  https:// osf. io/ 8wq6m? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b\nAppendix 6: Selecting overlapping charges\nFor each case, we listed the allegations present in the ChatGPT-generated complaint \nalongside the allegations from the original complaint. We then examined the \noverlapping charges between the two complaints for each case. One case (Aurelien \nBeranger, et al. v. Clifford “T.I.” Joseph Harris, et al., 1:18-cv-05054, N.D. Ga.) did \n730 A. Trozze et al.\nnot have any overlapping charges between the two complaints, so we excluded it at \nthis stage.\nNotably, in some cases (for example, Balestra v. Cloud With Me Ltd., in both the \nlawyer and the GPT version), only 12(a)(1) was charged but a finding of applicability \nof Section 5 is required for this charge.\nA couple of cases included Section 20(a) control person liability violations, but \nthese were less prevalent ( n = 3 ). Because each of those cases also included at least \none of the other charges we identified, we chose not to include this additional charge.\nIn a couple of cases ( n = 2 ), the ChatGPT-drafted version of the complaint \ndid not state the specific statutory violation, but rather a description thereof. \nFor example, in one case, the relevant count was merely “offering and sale of \nunregistered securities”. In this case, we inferred the violation of Sections 5(a), 5(c), \nand 12(a)(1) of the Securities Act.\nAppendix 7: Jury instructions\nIn the following documents, we indicate where language was used from existing case \ndocuments (as is common practice). However, in providing these jury instructions to \nour mock jurors, we excluded this information to improve readability.\nAppendix 7.1: Section 5 and Section 12(a)(1) violations\nThe following link contains the jury instructions for cases alleging violations of \nthe Securities Act: https:// osf. io/ m9shg? view_ only= 68c96 93fa3 99406 8b20d 1be94 \n1b9db 0b.\nAppendix 7.2: Section 10(b) and Rule 10b‑5 violations\nThe following link contains the jury instructions for cases alleging violations of the \nExchange Act: https:// osf. io/ u2fn8? view_ only= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b.\nAppendix 8: Survey execution and quality control\nWe required all potential participants to have English as their first language, a \nminimum approval rate of 95%, and to be U.S. citizens (since they would need to \nbe eligible for jury duty). This gave us a set of 35,541 potential participants from \nProlific’s pool of 120,471.\nWe implemented a strict quality control process to determine our final \nparticipants, ultimately excluding 40 of the total 128 participants who completed our \nsurvey. Participants’ survey response times varied greatly, from 8 min and 51 s at the \nlow end (of those accepted) to 2 h and 30 min at the high end. We note that some of \nthis variability can likely be explained by the differing lengths of our complaints, as \nwell as participants’ level of familiarity with legal concepts. We suspect that those \n731\nLarge language models in cryptocurrency securities cases:…\nwho complete mock jury studies frequently (which several participants indicated to \nus by message), would be able to complete our survey more quickly.\nBased on our piloting process (of 4 participants), we expected someone who carefully \nread our study to take up to an hour and a half to complete it, and initially accounted \nfor this amount of time in our budget. However, we soon noticed that many participants \nwere much faster than this. We then adjusted the expected time of our survey slightly.\nFor participants who finished the survey in under 20  min, we manually calculated \nthe amount of time it would take to read the survey in its entirety at various reading \nspeeds. Based on the results of Brysbaert (2019), we used 238 wpm as our “average” \nreading speed, and 500 wpm as a very fast reading speed. We excluded anyone who was \ncompleting the survey in less time than it would take to read it at between 400 and 500 \nwpm.\nFinally, we excluded any participants who sent us messages from whose messages \nit was clear that English was not their first language ( n = 2).\nTable 6  Study participants’ \ndemographic data Demographic marker Makeup of approved participants\nAge Participants aged 23–73\n15% Under 30\n38% Aged 30–39\n20% Aged 40–49\n13% Aged 50–59\n9% Aged 60–69\n5% Aged 70–73\nSex 37% Female\n63% Male\nEthnicity 1% Asian\n13% Black\n9% Mixed race\n5% Other\n73% White\nCountry of birth 1% Ghana\n1% New Zealand\n1% Nigeria\n1% South Africa\n95% United States of America\nNationality 100% United States of America\nStudent status 11% Yes\n89% No\nEmployment status 56% Full-time\n20% Not in paid employment (e.g. \nhomemaker, retired, or disabled)\n11% Part-time\n6% Unemployed (and job-seeking)\n7% Other\n732 A. Trozze et al.\nAppendix 8.1: Participant’s demographic data\nIn Table  6 we report the demographic data for the participants whose responses \nwe approved and included in the results of this study (and who consented to the \nsharing of this information and for whom said data had not expired).\nIn Fig. 2 we also include a map of our accepted participants’ locations.\nAppendix 9: Survey data\nThe data from our Prolific survey can be found here: https:// osf. io/ 7xnmj? view_  \nonly= 68c96 93fa3 99406 8b20d 1be94 1b9db 0b.\nAppendix 10: Data distribution\nTable  7 reports the results of Shapiro-Wilk tests on our data, showing that the \ndata were not normally distributed.\nFig. 2  Accepted participants’ locations\nTable 7  Data distribution: juror \nconfidence scores Shapiro-Wilk (p)\nChatGPT-authored Lawyer-authored\nAll cases 0.771 (< 0.001) 0.772 (< 0.001)\n733\nLarge language models in cryptocurrency securities cases:…\nAppendix 11: Concreteness scores\nSee Tables 8 , 9 and 10.\nTable 8  Concreteness scores for \nChatGPT-generated complaints Case Concreteness\nLee, et al. v. Binance, et al. 2.28\nHong, et al. v. Block.One, et al. 2.26\nBalestra v. Cloud With Me Ltd. 2.43\nUnderwood, et al. v. Coinbase, et al. 2.32\nAudet, et al. v. Garza, et al. 2.25\nKlingberg v. MGT Capital Investments Inc., et al. 2.33\nHa v. Overstock.com, et al. 2.23\nBrola v. Nano, et al. 2.35\nDavy v. Paragon Coin Inc., et al. 2.25\nTable 9  Concreteness scores for \nlawyer-generated complaints Case Concreteness\nLee, et al. v. Binance, et al. 2.20\nHong, et al. v. Block.One, et al. 2.22\nBalestra v. Cloud With Me Ltd. 2.32\nUnderwood, et al. v. Coinbase, et al. 2.22\nAudet, et al. v. Garza, et al. 2.24\nKlingberg v. MGT Capital Investments Inc., et al. 2.28\nHa v. Overstock.com, et al. 2.23\nBrola v. Nano, et al. 2.36\nDavy v. Paragon Coin Inc., et al. 2.20\nTable 10  Concreteness scores \nfor Law360 articles Case Concreteness\nLee, et al. v. Binance, et al. 2.29\nHong, et al. v. Block.One, et al. 2.35\nBalestra v. Cloud With Me Ltd. 2.49\nUnderwood, et al. v. Coinbase, et al. 2.34\nAudet, et al. v. Garza, et al. 2.32\nKlingberg v. MGT Capital Investments Inc., et al. 2.49\nHa v. Overstock.com, et al. 2.25\nBrola v. Nano, et al. 2.51\nDavy v. Paragon Coin Inc., et al. 2.39\n734 A. Trozze et al.\nAcknowledgements The authors would like to thank Antonis Papasavva for participating in the pilot \nphase of our study and his valuable feedback. We would also like to thank Anne Coventry for her assis-\ntance in conceptualizing our study and review of the legal concepts presented in this paper.\nAuthor contributions All authors contributed to the study conception and design. Material preparation, \ndata collection and analysis were performed by AT. The first draft of the manuscript was written by AT \nand all authors commented on previous versions of the manuscript. All authors read and approved the \nfinal manuscript.\nFunding This project was funded by Engineering and Physical Sciences Research Council Grant No. EP/\nS022503/1.\nDeclarations \nConflict of interest The authors declare that they have no Conflict of interest.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, \nwhich permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, provide a link to the Creative \nCommons licence, and indicate if changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line \nto the material. If material is not included in the article’s Creative Commons licence and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permis-\nsion directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/\nlicenses/by/4.0/.\nReferences\nAhmad Y, Wadhwa V, Funaki B et al (2022) Outcomes of bellwether cases related to inferior vena \ncava filters in multidistrict litigations. J Vasc Surg Venous Lymphat Disord 10(6):1378–1384\nAllingham JU, Ren J, Dusenberry MW et al (2023) A simple zero-shot prompt weighting technique \nto improve prompt ensembling in text-image models. https:// doi. org/ 10. 48550/ arXiv. 2302. 06235. \narXiv: 2302. 06235 [cs, stat]\nArcher R (2016) Cantor Fitzgerald Exec Named In Virtual Currency Ponzi Suit. https:// www. law360.  \ncom/ artic les/ 807687/ cantor- fitzg erald- exec- named- in- virtu al- curre ncy- ponzi- suit\nBlair-Stanek A, Holzenberger N, Van  Durme B (2023) Can GPT-3 perform statutory reasoning? \nhttps:// doi. org/ 10. 48550/ arXiv. 2302. 06100. arXiv: 2302. 06100 [cs]\nBommarito  II M, Katz DM (2022) GPT takes the bar exam. https:// doi. org/ 10. 48550/ arXiv. 2212.  \n14402. arXiv: 2212. 14402 [cs]\nBonsall S, Holzman E, Miller B (2019) Wearing out the watchdog: SEC case backlog and investiga-\ntion likelihood. ScholarSpace http:// hdl. handle. net/ 10125/ 64802\nBrown T, Mann B, Ryder N et al (2020) Language models are few-shot learners. In: Larochelle H, \nRanzato M, Hadsell R et al (eds) Advances in neural information processing systems, vol 33. \nCurran Associates, Inc., pp 1877–1901. https:// proce edings. neuri ps. cc/ paper_ files/ paper/ 2020/ \nfile/ 1457c 0d6bf cb496 7418b fb8ac 142f6 4a- Paper. pdf\nBrysbaert M (2019) How many words do we read per minute? A review and meta-analysis of reading \nrate. J Memory Lang 109:104047. https:// doi. org/ 10. 1016/j. jml. 2019. 104047\nBrysbaert M, Warriner AB, Kuperman V (2014) Concreteness ratings for 40 thousand generally \nknown English word lemmas. Behav Res Methods 46(3):904–911. https:// doi. org/ 10. 3758/  \ns13428- 013- 0403-5\nChoi JH, Hickman KE, Monahan A et al (2023). ChatGPT goes to law school. https:// doi. org/ 10. 2139/ \nssrn. 43359 05. https:// papers. ssrn. com/ abstr act= 43359 05\nCoinMarketCap (2023) Cryptocurrency prices, charts and market capitalizations. https:// coinm arket  \ncap. com/\n735\nLarge language models in cryptocurrency securities cases:…\nCornell Law School (n.d.a) Civil liabilities arising in connection with prospectuses and communica-\ntions. https:// www. law. corne ll. edu/ uscode/ text/ 15/ 77l\nCornell Law School (n.d.b) Prohibitions relating to interstate commerce and the mails. https:// www.  \nlaw. corne ll. edu/ uscode/ text/ 15/ 77e\nDalton DL (2013) Sector 10 defendants’ proposed supplemental jury instructions. https:// www. westl  \naw. com/ Docum ent/ Ief1a 97900 68211 e4aca 7d288 9c73d 40f/ View/ FullT ext. html? trans ition Type= \nDefau lt& conte xtData= (sc. Defau lt) & VR=3. 0& RS= cblt1.0\nFederal Rules of Civil Procedure (2020) Rule 48\nGale ME (1979) Legal writing: the impossible takes a little longer symposium on teaching legal writ-\ning. Albany Law Rev 44(2):298–343\nGuarnaccia M (2019) Rapper T.I. Faces 2nd ICO Suit, Parallel Suit Names Kevin Hart. https:// www.  \nlaw360. com/ artic les/ 11586 76/ rapper- t-i- faces- 2nd- ico- suit- paral lel- suit- names- kevin- hart\nHadi MU, Tashi QA, Qureshi R et al (2023) Large language models: a comprehensive survey of its \napplications, challenges, limitations, and future prospects. https:// doi. org/ 10. 36227/ techr  xiv. \n23589 741. v2. https:// www. techr xiv. org/ artic les/ prepr int/A_ Survey_ on_ Large_ Langu age_ Mod-\nels_ Appli catio ns_ Chall enges_ Limit ations_ and_ Pract ical_ Usage/ 23589 741/2\nHolzman ER, Marshall NT, Schmidt BA (2023) When are firms on the hot seat? An analysis of SEC \ninvestigation preferences. J Account Econ. https:// doi. org/ 10. 1016/j. jacce co. 2023. 101610\nHome Office (2023) Factsheet: cryptoassets technical. Technical report. https:// www. gov. uk/ gover  \nnment/ publi catio ns/ econo mic- crime- and- corpo rate- trans paren cy- bill- 2022- facts heets/ fact- sheet- \ncrypt oasse ts- techn ical\nInnis CI (2022) Coinbase is an unregistered securities exchange, suit says. https:// www. law360. com/  \nartic les/ 14733 39/ coinb ase- is- an- unreg ister ed- secur ities- excha nge- suit- says\nIu KY, Wong VMY (2023) ChatGPT by OpenAI: the end of litigation lawyers? https:// doi. org/ 10. \n2139/ ssrn. 43398 39. https:// papers. ssrn. com/ abstr act= 43398 39\nJarvis S (2022) NBA-highlight NFTs count as securities, purchasers say. https:// www. law360. com/  \nartic les/ 15454 61/ nba- highl ight- nfts- count- as- secur ities- purch asers- say\nKacperczyk M, Pagnotta ES (2024) Legal risk and insider trading. J Finance 79(1):305–355. https://  \ndoi. org/ 10. 1111/ jofi. 13299\nKahana E (2023) ChatGPT Is A Cool Trick, But AI Won’t Replace Lawyers. https:// www. law360.  \ncom/ pulse/ artic les/ 15731 78\nKaradimitriou SM, Marshall E (n.d.) Mann–Whitney in SPSS. http:// maths. shu. ac. uk/ maths help/  \nStats% 20sup port% 20res ources/ Resou rces/ Nonpa ramet ric/ Compa ring% 20gro ups/ Mann- Whitn ey/ \nSPSS/ stcp- marsh all- MannW hitS. pdf\nKedia S, Rajgopal S (2011) Do the SEC’s enforcement preferences affect corporate misconduct? J \nAccount Econ 51(3):259–278. https:// doi. org/ 10. 1016/j. jacce co. 2011. 01. 004\nKlausner M, Hegland J, Goforth M (2013) When are securities class actions dismissed, when do they \nsettle, and for how much? An update. Professional Liability Underwriting Society 26(4)\nKleinberg B, Vegt Ivd, Arntz A et al (2019) Detecting deceptive communication through linguistic \nconcreteness. https:// doi. org/ 10. 31234/ osf. io/ p3qjh. https:// psyar xiv. com/ p3qjh/\nKochman B (2018) Irish Cloud Coin Co. Breached US Securities Law, Suit Says. https:// www. law360.  \ncom/ artic les/ 10553 23/ irish- cloud- coin- co- breac hed- us- secur ities- law- suit- says\nKojima T, Gu SS, Reid M et al (2023) Large language models are zero-shot reasoners. https:// doi. org/  \n10. 48550/ arXiv. 2205. 11916. arXiv: 2205. 11916 [cs]\nKoroteev MV (2021) BERT: a review of applications in natural language processing and understand-\ning. https:// doi. org/ 10. 48550/ arXiv. 2103. 11943. arXiv: 2103. 11943 [cs]\nLegal Information Institute (n.d.a) Securities Act of 1933. https:// www. law. corne ll. edu/ wex/ secur  \nities_ act_ of_ 1933\nLegal Information Institute (n.d.b) Securities Exchange Act of 1934. https:// www. law. corne ll. edu/  \nwex/ secur ities_ excha nge_ act_ of_ 1934\nLender DJ, Friedman JR, Barrow J et al (2023) Class Action Fairness Act of 2005 (CAFA): overview. \nhttps:// us. pract icall aw. thoms onreu ters. com/6- 527- 3431\nLitera (2024) The Litera ecosystem. https:// www. litera. com/ produ cts/ legal\nMartin CE (2013) Plaintiff securities and exchange commission’s notice of filing proposed jury instruc-\ntions and verdict form. https:// www. westl aw. com/ Docum ent/ Iab1f 425e9 c7711 e2a16 0cacff  1482 23f/ \nView/ FullT ext. html? ransi tionT ype= Defau lt& conte xtData= (sc. Defau lt) & VR=3. 0& RS= cblt1.0\nMartinson S (2023) ChatGPT Mishap Attys ‘Truly Mortified,’ ask for no sanctions. https:// www. law360. \ncom/ artic les/ 16862 37/ chatg pt- mishap- attys- truly- morti fied- ask- for- no- sanct ions\n736 A. Trozze et al.\nMcRae M, Biondo HB, Richardson-Royer E (2023) Initial stages of general litigation: overview. https:// \nus. pract icall aw. thoms onreu ters. com/0- 503- 1906\nMoffett TA (2022) CFTC & SEC: the wild west of cryptocurrency regulation comments. Univ Richmond \nLaw Rev 57(2):i–762. https:// heino nline. org/ HOL/P? h= hein. journ als/ urich 57&i= 737\nNakamoto S (2008) Bitcoin: a peer-to-peer electronic cash system\nNarayanan A (2018) Blockchains: past, present, and future. In: Proceedings of the 37th ACM SIGMOD-\nSIGACT-SIGAI symposium on principles of database systems. Association for Computing Machin-\nery, New York, NY, USA, PODS ’18, p 193. https:// doi. org/ 10. 1145/ 31969 59. 31975 45\nNarayanan A, Bonneau J, Felten E et al (2016) Bitcoin and cryptocurrency technologies\nNay JJ, Karamardian D, Lawsky SB et al (2023) Large language models as tax attorneys: a case study \nin legal capabilities emergence. https:// doi. org/ 10. 48550/ arXiv. 2306. 07075. arXiv: 2306. 07075 [cs]\nNewsham J (2018) \\$70M weed cryptocurrency offering was illegal, suit says. www. law360. com/ artic les/ \n10075 41/ 70m- weed- crypt ocurr ency- offer ing- was- illeg al- suit- says\nNinth Circuit Jury Instructions Committee (2023) Manual of model civil jury instructions for the district \ncourts of the ninth circuit. https:// www. ce9. uscou rts. gov/ jury- instr uctio ns/ model- civil\nOpenAI (2023a) Api reference. https:// platf orm. openai. com/ docs/ guides/ fine- tuning\nOpenAI (2023b) Fine-tuning. https:// platf orm. openai. com/ docs/ guides/ fine- tuning\nOpenAI (2023c) Tokenizer. https:// platf orm. openai. com/ token izer\nPerera K (2023) Identical twins defrauded \\$5M from 60 clients, SEC claims. https:// www. law360. com/ \nartic les/ 15823 12/ ident ical- twins- defra uded- 5m- from- 60- clien ts- sec- claims\nPerlman AM (2022) The implications of ChatGPT for legal services and society. https:// doi. org/ 10. 2139/ \nssrn. 42941 97. https:// papers. ssrn. com/ abstr act= 42941 97\nPractical Law (2023) Federal question jurisdiction. https:// us. pract icall aw. thoms onreu ters. \ncom/0- 502- 3299\nPractical Law Litigation (2023a) Commencing a federal lawsuit: drafting the complaint. https:// us. pract \nicall aw. thoms onreu ters. com/5- 506- 8600\nPractical Law Litigation (2023b) Discovery motions in federal court toolkit. https:// us. pract icall aw. thoms \nonreu ters. com/w- 009- 0479\nPractical Law Litigation (2023c) Dispositive motions in federal court toolkit. https:// us. pract icall aw. \nthoms onreu ters. com/w- 009- 0405\nPractical Law Litigation (2023d) Motion practice in federal courts: overview. https:// us. pract icall aw. \nthoms onreu ters. com/w- 000- 1571\nPractical Law Litigation (2023e) Nondispositive motions in federal court. https:// us. pract icall aw. thoms \nonreu ters. com/w- 009- 0422\nPractical Law Securities Litigation & White Collar Crime (2023) Securities litigation and enforcement: \noverview. https:// us. pract icall aw. thoms onreu ters. com/w- 009- 8817\nProlific (2014). https:// www. proli fic. co\nRuscoe E (2019) ‘Erratic’ Overstock.com CEO Punished Short Sellers, Suit Says. https:// www. law360. \ncom/ artic les/ 12039 09/ errat ic- overs tock- com- ceo- punis hed- short- selle rs- suit- says\nSavelka J (2023) Unlocking practical applications in legal domain: evaluation of GPT for zero-shot \nsemantic annotation of legal texts. https:// doi. org/ 10. 1145/ 35945 36. 35951 61. arXiv: 2305. 04417 [cs]\nSinay R (2020a) Investors accuse crypto firms of illicit token sales. https:// www. law360. com/ artic les/ \n12605 69/ inves tors- accuse- crypto- firms- of- illic it- token- sales\nSinay R (2020b) Investors sue Block.one over unregistered \\$4B ICO. https:// www. law360. com/ artic les/ \n12745 76/ inves tors- sue- block- one- over- unreg ister ed- 4b- ico\nStanford Law School, Cornerstone Research (2023) Securities class action clearinghouse: filings data-\nbase. https:// secur ities. stanf ord. edu/ curre nt- trends. html# colla pse1\nStevens KL, Austin A, Wheeler D et  al (2022) The role of defendant gender on juror decision-mak -\ning within a mock sex trafficking case among a jury-eligible community sample. J Sex Aggress \n28(2):218–230. https:// doi. org/ 10. 1080/ 13552 600. 2021. 19731 27\nTing KM (2010) Precision and recall. In: Sammut C, Webb GI (eds) Encyclopedia of machine learning. \nSpringer US, Boston, MA, pp 781–781. https:// doi. org/ 10. 1007/ 978-0- 387- 30164-8_ 652\nTopal MO, Bas A, van Heerden I (2021) Exploring transformers in natural language generation: GPT, \nBERT, and XLNet. https:// doi. org/ 10. 48550/ arXiv. 2102. 08036. arXiv: 2102. 08036 [cs]\nTRAC (2021) Securities and commodities exchange litigation reaches new high in March 2021. Techni-\ncal report, Syracuse University. https:// trac. syr. edu/ tracr eports/ civil/ 645/\nUnited States Courts (2022) Civil cases. https:// www. uscou rts. gov/ about- feder  al- courts/ types- cases/ \ncivil- cases\n737\nLarge language models in cryptocurrency securities cases:…\nU.S. Department of Justice (2022) The report of the attorney general pursuant to section 5(b)iii of execu-\ntive order 14067: the role of law enforcement in detecting, investigating, and prosecuting criminal \nactivity related to digital assets. Technical report, Washington, D.C\nU.S. Securities and Exchange Commission (2017) Enforcement manual\nU.S. Securities and Exchange Commission (2022) SEC announces enforcement results for FY22. https:// \nwww. sec. gov/ news/ press- relea se/ 2022- 206\nU.S. Securities and Exchange Commission (2023) Crypto assets and cyber enforcement actions. https:// \nwww. sec. gov/ spotl ight/ cyber secur ity- enfor cement- actio ns\nWeinberger HP, Simon NC, Ettari SV et al (2023) Civil jury trials (federal). https:// us. pract icall aw. thoms \nonreu ters. com/w- 020- 5711\nWichert B (2018) McAfee-linked bitcoin biz hit with pump-and-dump suit. https:// www. law360. com/ \nartic les/ 10873 72/ mcafee- linked- bitco in- biz- hit- with- pump- and- dump- suit\nWillmott D, Boduszek D, Debowska A et  al (2018) Introduction and validation of the Juror Decision \nScale (JDS): an empirical investigation of the Story model. J Crim Justice 57:26–34. https:// doi. org/ \n10. 1016/j. jcrim jus. 2018. 03. 004\nYu F, Quartey L, Schilder F (2022) Legal prompting: teaching a language model to think like a lawyer. \nhttps:// doi. org/ 10. 48550/ arXiv. 2212. 01326. arXiv: 2212. 01326 [cs]\nZhao WX, Zhou K, Li J et al (2023) A survey of large language models. arxiv: 2303. 18223\nPublisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps \nand institutional affiliations.\nAuthors and Affiliations\nArianna Trozze1,2  · Toby Davies2,3 · Bennett Kleinberg2,4\n * Arianna Trozze \n arianna.trozze@ucl.ac.uk\n1 Department of Computer Science, University College London, Gower Street, \nLondon WC1E 6EA, UK\n2 Department of Security and Crime Science, University College London, 35 Tavistock Square, \nLondon WC1H 9EZ, UK\n3 School of Law, The Liberty Building, University of Leeds, Leeds LS2 9JT, UK\n4 Department of Methodology and Statistics, Tilburg University, Warandelaan 2, \n5037 AB Tilburg, The Netherlands",
  "topic": "Cryptocurrency",
  "concepts": [
    {
      "name": "Cryptocurrency",
      "score": 0.9144724607467651
    },
    {
      "name": "Legal aspects of computing",
      "score": 0.5043011903762817
    },
    {
      "name": "Computer security",
      "score": 0.43845176696777344
    },
    {
      "name": "Computer science",
      "score": 0.4203832447528839
    },
    {
      "name": "Philosophy of law",
      "score": 0.4197283387184143
    },
    {
      "name": "Law and economics",
      "score": 0.3739287257194519
    },
    {
      "name": "Business",
      "score": 0.36428117752075195
    },
    {
      "name": "Law",
      "score": 0.27546384930610657
    },
    {
      "name": "The Internet",
      "score": 0.23857465386390686
    },
    {
      "name": "World Wide Web",
      "score": 0.2322767972946167
    },
    {
      "name": "Economics",
      "score": 0.20982429385185242
    },
    {
      "name": "Political science",
      "score": 0.1742326319217682
    },
    {
      "name": "Public law",
      "score": 0.12285366654396057
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I45129253",
      "name": "University College London",
      "country": "GB"
    }
  ]
}