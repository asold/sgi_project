{
  "title": "Predicting the formation of NADES using a transformer-based model",
  "url": "https://openalex.org/W4392058082",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5001447854",
      "name": "Lucas B. Ayres",
      "affiliations": [
        "Clemson University"
      ]
    },
    {
      "id": "https://openalex.org/A4209328854",
      "name": "Federico J.V. Gomez",
      "affiliations": [
        "Consejo Nacional de Investigaciones Científicas y Técnicas",
        "Universidad Nacional de Cuyo",
        "Instituto de Biología Agrícola de Mendoza"
      ]
    },
    {
      "id": "https://openalex.org/A2235481106",
      "name": "Maria Fernanda Silva",
      "affiliations": [
        "Consejo Nacional de Investigaciones Científicas y Técnicas",
        "Universidad Nacional de Cuyo",
        "Instituto de Biología Agrícola de Mendoza"
      ]
    },
    {
      "id": "https://openalex.org/A2168936401",
      "name": "Jeb R. Linton",
      "affiliations": [
        "Clemson University"
      ]
    },
    {
      "id": "https://openalex.org/A2105712667",
      "name": "Carlos D. Garcia",
      "affiliations": [
        "Clemson University"
      ]
    },
    {
      "id": "https://openalex.org/A5001447854",
      "name": "Lucas B. Ayres",
      "affiliations": [
        "Clemson University"
      ]
    },
    {
      "id": "https://openalex.org/A4209328854",
      "name": "Federico J.V. Gomez",
      "affiliations": [
        "Instituto de Biología Agrícola de Mendoza"
      ]
    },
    {
      "id": "https://openalex.org/A2235481106",
      "name": "Maria Fernanda Silva",
      "affiliations": [
        "Instituto de Biología Agrícola de Mendoza"
      ]
    },
    {
      "id": "https://openalex.org/A2168936401",
      "name": "Jeb R. Linton",
      "affiliations": [
        "Clemson University",
        "IBM (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2105712667",
      "name": "Carlos D. Garcia",
      "affiliations": [
        "Clemson University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2988414776",
    "https://openalex.org/W2321005010",
    "https://openalex.org/W2065820312",
    "https://openalex.org/W3124148799",
    "https://openalex.org/W3183439856",
    "https://openalex.org/W3113345144",
    "https://openalex.org/W3112240081",
    "https://openalex.org/W4211170706",
    "https://openalex.org/W3198017865",
    "https://openalex.org/W2327103653",
    "https://openalex.org/W2784963050",
    "https://openalex.org/W2887019939",
    "https://openalex.org/W3153277884",
    "https://openalex.org/W3047864728",
    "https://openalex.org/W2935975288",
    "https://openalex.org/W2925565054",
    "https://openalex.org/W3215889822",
    "https://openalex.org/W3091773500",
    "https://openalex.org/W3011992421",
    "https://openalex.org/W2239571928",
    "https://openalex.org/W2968532052",
    "https://openalex.org/W3019555125",
    "https://openalex.org/W2909309818",
    "https://openalex.org/W2978507795",
    "https://openalex.org/W3207100389",
    "https://openalex.org/W2584271473",
    "https://openalex.org/W4220963028",
    "https://openalex.org/W2804391467",
    "https://openalex.org/W2619724116",
    "https://openalex.org/W3035841717",
    "https://openalex.org/W2178769718",
    "https://openalex.org/W3182143730",
    "https://openalex.org/W3080094541",
    "https://openalex.org/W2946664205",
    "https://openalex.org/W2989567579",
    "https://openalex.org/W2023059436",
    "https://openalex.org/W4224444615",
    "https://openalex.org/W2807958703",
    "https://openalex.org/W3158410177",
    "https://openalex.org/W2191703368",
    "https://openalex.org/W4280557059",
    "https://openalex.org/W2939735092",
    "https://openalex.org/W4225636581",
    "https://openalex.org/W2994473698",
    "https://openalex.org/W3120086782",
    "https://openalex.org/W3200225210",
    "https://openalex.org/W3138986876",
    "https://openalex.org/W2095336127",
    "https://openalex.org/W2087998776",
    "https://openalex.org/W4220952750",
    "https://openalex.org/W1975147762",
    "https://openalex.org/W2947423323",
    "https://openalex.org/W3088265803",
    "https://openalex.org/W2972608805",
    "https://openalex.org/W3158543275",
    "https://openalex.org/W3186326839",
    "https://openalex.org/W3214740101",
    "https://openalex.org/W3088999551",
    "https://openalex.org/W3140854437",
    "https://openalex.org/W2107432340",
    "https://openalex.org/W2948365897",
    "https://openalex.org/W2755779374",
    "https://openalex.org/W2036329916",
    "https://openalex.org/W4242121546",
    "https://openalex.org/W2999309192",
    "https://openalex.org/W2793497086",
    "https://openalex.org/W1532059671",
    "https://openalex.org/W2985886213",
    "https://openalex.org/W1993555413",
    "https://openalex.org/W2969718743",
    "https://openalex.org/W3008859330",
    "https://openalex.org/W2762813876",
    "https://openalex.org/W3214704577",
    "https://openalex.org/W1996891718",
    "https://openalex.org/W4280651481",
    "https://openalex.org/W3099486764",
    "https://openalex.org/W3118695441",
    "https://openalex.org/W1994139775",
    "https://openalex.org/W3172433574",
    "https://openalex.org/W4200555936",
    "https://openalex.org/W3087325092",
    "https://openalex.org/W4225263913",
    "https://openalex.org/W3200846851",
    "https://openalex.org/W3112091577",
    "https://openalex.org/W4205469346",
    "https://openalex.org/W3006462044",
    "https://openalex.org/W796146865",
    "https://openalex.org/W3098769136",
    "https://openalex.org/W3182207208",
    "https://openalex.org/W4200371263",
    "https://openalex.org/W4281619372",
    "https://openalex.org/W2937064326",
    "https://openalex.org/W3103092523",
    "https://openalex.org/W3094771832",
    "https://openalex.org/W2970940067",
    "https://openalex.org/W4207037378"
  ],
  "abstract": "Abstract The application of natural deep eutectic solvents (NADES) in the pharmaceutical, agricultural, and food industries represents one of the fastest growing fields of green chemistry, as these mixtures can potentially replace traditional organic solvents. These advances are, however, limited by the development of new NADES which is today, almost exclusively empirically driven and often derivative from known mixtures. To overcome this limitation, we propose the use of a transformer-based machine learning approach. Here, the transformer-based neural network model was first pre-trained to recognize chemical patterns from SMILES representations (unlabeled general chemical data) and then fine-tuned to recognize the patterns in strings that lead to the formation of either stable NADES or simple mixtures of compounds not leading to the formation of stable NADES (binary classification). Because this strategy was adapted from language learning, it allows the use of relatively small datasets and relatively low computational resources. The resulting algorithm is capable of predicting the formation of multiple new stable eutectic mixtures (n = 337) from a general database of natural compounds. More importantly, the system is also able to predict the components and molar ratios needed to render NADES with new molecules (not present in the training database), an aspect that was validated using previously reported NADES as well as by developing multiple novel solvents containing ibuprofen. We believe this strategy has the potential to transform the screening process for NADES as well as the pharmaceutical industry, streamlining the use of bioactive compounds as functional components of liquid formulations, rather than simple solutes.",
  "full_text": "1\nVol.:(0123456789)Scientific Reports |         (2024) 14:2715  | https://doi.org/10.1038/s41598-022-27106-w\nwww.nature.com/scientificreports\nPredicting the formation of NADES \nusing a transformer‑based model\nLucas B. Ayres 1, Federico J. V. Gomez 2, Maria Fernanda Silva 2, Jeb R. Linton 1,3 & \nCarlos D. Garcia 1*\nThe application of natural deep eutectic solvents (NADES) in the pharmaceutical, agricultural, and \nfood industries represents one of the fastest growing fields of green chemistry, as these mixtures \ncan potentially replace traditional organic solvents. These advances are, however, limited by the \ndevelopment of new NADES which is today, almost exclusively empirically driven and often derivative \nfrom known mixtures. To overcome this limitation, we propose the use of a transformer‑based \nmachine learning approach. Here, the transformer‑based neural network model was first pre‑trained \nto recognize chemical patterns from SMILES representations (unlabeled general chemical data) and \nthen fine‑tuned to recognize the patterns in strings that lead to the formation of either stable NADES \nor simple mixtures of compounds not leading to the formation of stable NADES (binary classification). \nBecause this strategy was adapted from language learning, it allows the use of relatively small \ndatasets and relatively low computational resources. The resulting algorithm is capable of predicting \nthe formation of multiple new stable eutectic mixtures (n = 337) from a general database of natural \ncompounds. More importantly, the system is also able to predict the components and molar ratios \nneeded to render NADES with new molecules (not present in the training database), an aspect that \nwas validated using previously reported NADES as well as by developing multiple novel solvents \ncontaining ibuprofen. We believe this strategy has the potential to transform the screening process \nfor NADES as well as the pharmaceutical industry, streamlining the use of bioactive compounds as \nfunctional components of liquid formulations, rather than simple solutes.\nOver the past two decades, eutectic mixtures such as ionic liquids (IL) 1, deep eutectic solvents (DES) 2, and \nNADES (DES formed using natural compounds) 3 have been extensively explored as green alternative liquid \nmedia to traditional organic  solvents4–9, and are applicable in a wide variety of industries targeting sustainable \n chemistry10–12. These new materials are composed of specific ratios of two or three components, often in solid \nstate, that lead to a material featuring a melting point that is significantly lower than the melting points of the \nindividual components; often below room  temperature13. Among those, mixtures leading to the formation of \nliquids that are stable at room temperature are the most important. A careful selection of the physico-chemical \ncharacteristics of the components (molecular weight, hydrogen bonding, pKa, etc.) enables the formation of \nsolvents with different properties (e.g., stability, viscosity, polarity, pH, conductivity, permittivity, and den-\nsity)14. This aspect is of great interest in tailoring solvents towards several applications including  biocatalysis15–18, \n chromatography19–22, extraction  media23–28,  electrochemistry29–31, as well as pharmaceutical ingredients to \nenhance availability and/or therapeutic  properties32–35. It is also important to note that among these solvents, \nDES and NADES are considered more environmentally friendly than IL due to their intrinsic properties such as \n biodegradability36, low or non-toxicity37, easy preparation with no purification  steps38, and inexpensive starting \n materials39.\nWhile NADES represent one of the most promising and fastest-growing DES, their development is (until now) \nalmost exclusively empirically driven. Because there exist only general guidelines to explain (but not predict) their \nformation, new NADES are often derived from structurally similar components considering general properties \nof the precursors such as hydrophobicity, number of functional groups, and number of donors or acceptors of \nhydrogen bonds. Examples of these include families of NADES based on choline  chloride40,  carbohydrates41,42, or \norganic  acids43. A second drawback, broadly limiting the development of new NADES is that bench-top trials of \nnew mixtures are time-consuming, labor-intensive, and expensive even at a laboratory scale. Aiming to provide \ninsights into the relationship between chemical structure and properties of NADES/DES and guide the applica-\ntion of these mixtures, computational  simulations44,45 have recently gained popularity. Generally speaking, these \nOPEN\n1Department of Chemistry, Clemson University, 211 S. Palmetto Blvd, Clemson, SC 29634, USA. 2Facultad de \nCiencias Agrarias, Instituto de Biología Agrícola de Mendoza (IBAM-CONICET), Universidad Nacional de Cuyo, \nMendoza, Argentina. 3IBM Cloud, Armonk, NY 10504, USA. *email: cdgarci@clemson.edu\n2\nVol:.(1234567890)Scientific Reports |         (2024) 14:2715  | https://doi.org/10.1038/s41598-022-27106-w\nwww.nature.com/scientificreports/\napproaches vary from thermodynamic modeling such as Perturbed Chain—Statical Associating Fluid Theory \n(PC-SAFT)46 to atomistic modeling methods including Density Functional Theory (DFT) at the quantum  level47. \nAlthough these models are certainly capable of explaining several properties of eutectic mixtures, they require \nspecialized knowledge to build and are not yet able to make statistically-validated predictions of new mixtures. \nIn parallel to the methods cited above, machine learning approaches based on artificial neural networks (ANN)48 \ncan also be used as an auxiliary tool to predict physicochemical features of  solvents49–52. However, due to the \ncomplexity of these deep learning architectures, a substantial volume of data would be required to create such \na model from scratch, to properly train the parameters of the neural network (i.e., weights and biases), and to \nextract meaningful information from the chemical space. As of today, the development of a database containing \nenough chemical information seems to be an insurmountable task, at least from the experimental point of view.\nIn this context, we propose a much simpler solution to predict the mixtures of natural compounds that would \nlead to the formation of stable NADES. The approach is based on the use of a transformer-based53 neural network \nmodel by means of Simplified Molecular-Input Line-Entry System (SMILES) 54 representations, rather than an \nextensive set of physicochemical parameters as input. This strategy—adapted from language learning—allows \nthe use of relatively small datasets; which also reduces training time, model complexity, and computational cost. \nIt is important to mention that similar transformer-based approaches have been successfully applied for other \nsubfields of chemistry including prediction of organic  synthesis55 and  retrosynthesis56,57, conversion of chemical \n notation58,59, molecular geometry  learning60, and prediction of regio- and stereoselective  reactions61. However, \nto best of our knowledge, this is the first report describing the use of machine learning (and more specifically, \ntransformers) towards the guided design and screening of new deep eutectic solvents. Briefly, the approach con-\nsists of pre-training a transformer model by using unlabeled general chemical data, and then fine-tuning the last \nlayer of neurons in the model to perform a binary classification using labeled chemical data related to NADES. \nOur results demonstrated satisfactory performance (F1-score = 0.82), allowing the prediction of multiple stable \neutectic mixtures (n  = 337) from a general database. The validity of such predictions was verified by compar -\ning the stability those NADES against those reported in previous publications as well as by the development of \nnew solvents containing ibuprofen, a compound that despite being one of the most important over-the-counter \nanalgesics, displays limited therapeutic potential due to its poor solubility in water.\nResults\nAiming to facilitate the discussion, we present a general overview of the rational design to predict the stability \nof eutectic mixtures. The first step consists in training a neural network model using general unlabeled chemical \ndata from a large corpus of organic reactions using the “SMILES” text-based representation; the specific train-\ning task at this stage is the ELECTRA variant of Masked Language Modeling (MLM) (https:// huggi ngface. co/ \ndocs/ trans forme rs/ model_ doc/ elect ra# trans forme rs. Elect raFor Maske dLM). Next, the task of the Neural Net is \nchanged from MLM by swapping the last layer of neurons for a freshly-initiated Binary Classifier layer; then the \nmodel is fine-tuned using the labeled NADES/DES dataset, also using the SMILES format but with the addition \nof special characters to represent the stoichiometric ratios (which are not present in the pre-training dataset). \nAdditionally, an auxiliary program (uACL software) is used to infer the probability of any mixture to form a \nstable NADES/DES and then export the results (e.g., mixture composition, stoichiometric ratio, and probability \nof stability) in CSV tabular format. Figure 1 schematically shows the modules and the work sequence.\nThe performance metrics for evaluating each step described in Fig.  1 will be also discussed in this section; \nour primary goal is to use those metrics in conjunction with chemical knowledge to statistically support the \ndevelopment of the proposed strategy.\nPre‑training a general chemistry model from scratch\nIn this first step, approximately one million unlabeled organic chemical reactions (Molecular Transformer MIT \nMixed  Augmented55) SMILES notation canonicalized by  RDKit62 were used as text dataset to pre-train the trans-\nformer model. Typically, this process requires a large amount of unlabeled data since the neural network will \ntry to model a language based on text sequences within specific contexts, continuously adjusting their intrinsic \nparameters (weights and biases) to minimize the output of the loss function (i.e. the “loss”) 63. The loss versus \nepoch graph for the pre-training step is shown in Fig. 2.\nFigure 1.  Rational design implemented to predict the stability of NADES.\n3\nVol.:(0123456789)Scientific Reports |         (2024) 14:2715  | https://doi.org/10.1038/s41598-022-27106-w\nwww.nature.com/scientificreports/\nUnder the experimental conditions previously described, the training process was completed in approximately \n12 h (18 min per epoch) using the MIT augmented database. As a point of reference, the same training process \nwould take 21 days in a medium tier desktop computer equipped with a GTX 1050 Ti GPU.\nIt is important to note that the loss function dramatically decreases from epochs 0 to 10 and then remains \nrelatively constant until the end of the training process. The average loss for the training dataset was 3.87 while \nthe average loss for the test dataset was 4.00, suggesting that the performance of the neural network using both \ndatasets reached a convergence point where more training is unlikely to lead to an improvement in the general \nchemistry model. At this point, the training process was stopped, and the generated model was tuned under \nseveral augmented data conditions.\nFine‑tuning a general chemistry model into a binary classifier for NADES and DES mixtures\nThe fine-tuning step was carried out by using the uACL DB developed and curated by our research group which \ncontains approximately 1000 labeled mixtures of DES and NADES reported in the literature. While these mixtures \nmay not represent the best ratios (leading to the absolute lowest possible melting point), they have all been clas-\nsified as DES/NADES in peer-reviewed publications. Within these, 800 mixtures are stable (labeled as 1), and \n200 mixtures are not stable (labeled as 0). While this reflects what is normally published (mostly positive results), \nthe imbalance is likely to have undesirable effects on the model such as classification  bias64, impacting the per-\nformance of the classifier (e.g., overoptimistic estimation). Aiming to overcome this issue, a data augmentation \nstrategy was devised by generating random compound mixtures in the training dataset, which were labeled as \nzero (unstable). This approach is supported by the idea that the probability of generating a stable eutectic solvent \nby randomly mixing chemicals at random stoichiometric coefficients, is simply very low. For example, varying \nthe stoichiometric coefficient between 1 and 10 for the 198 compounds in our database, leading to approximately \n40 million possible ternary combinations \n(\n618!\n3!×615!\n)\n . In this sense, the effectiveness of this strategy was mainly \nassessed by evaluating two parameters: Matthews correlation coefficient (MCC) 65 and loss function. For both \ncases, the training dataset was augmented by adding synthetic data (1, 5, 10, 25, 50, 100, and 500 random mix -\ntures) while the test dataset remained constant with 200 mixtures.\nAssessing the Matthews correlation coefficient\nThe Matthews correlation coefficient has been successfully applied as a reliable metric for binary classification \nproblems where the dataset available for training as well as fine tuning is  unbalanced66–68, as in our application. \nThis metric takes into consideration all of the categories in the confusion  matrix69 (true positive, false negative, \ntrue negative, and false positive) to compute the correlation between the predicted value by the classifier with the \ntrue one. This correlation ranges from − 1 to + 1, where − 1 indicates total disagreement, 0 indicates no correla-\ntion, and + 1 indicates total agreement. A detailed explanation of the advantages of using MCC over traditional \nmetrics for machine learning such as F1-score and accuracy can be found  elsewhere 70. The effect of several \ntraining data augmentation on the MCC metric versus number of epochs is shown in Fig. 3.\nFor the testing dataset (Fig. 3A), the MCC rises as the epoch number increases, reaching a plateau in the itera-\ntion number 15 for all augmented data scenarios. Additionally, it is interesting to note that the MCC is improved \nas the training synthetic data is incremented, accomplishing a satisfactory performance (MCC higher than 0.40) \nby using 100 and 500 augmented data after the iteration number 15. On other hand, the model’s performance \nevaluating the training dataset (Fig.  3B) is already satisfactory even without implementing any synthetic data \n01 02 03 04 0\n0\n5\n10\n15\n20\n25Loss\nepoch #\nFigure 2.  Dependence of the loss function as a function of epoch number obtained during training process for \nMasked Language Modeling (MLM) and using the MIT mixed augmented database.\n4\nVol:.(1234567890)Scientific Reports |         (2024) 14:2715  | https://doi.org/10.1038/s41598-022-27106-w\nwww.nature.com/scientificreports/\n(black line). This is expected since the same dataset was already seen by the deep neural network during the \nfine-tuning process. Additional information related to the confusion matrix used for calculating the test MCC \nat 15 epochs for both 100 and 500 synthetic data can be found in the supplementary information (Table SI 1 \nand Table SI 2).\nAssessing the loss Function\nThe measurement of the loss function was performed aiming to elucidate the effect of the implemented data \naugmentation strategy on the classifier’s performance in terms of underfitting as well as overfitting. The results \nare shown in Fig. 4.\nThe results presented above suggest that the classifier starts to overfit after iteration 15 regardless of the \namount of data augmentation (Fig. 4A). As expected, this issue is not apparent upon assessment of the training \ndataset (Fig.  4B), where the loss decreases as the number of synthetic data is added. The overfitting problem \nis clearly evidenced when the loss for the test and training dataset is plotted together for the same number of \nsynthetic data (100), as summarized in Fig. 5.\n01 02 03 04 05 0\n0.00\n0.15\n0.30\n0.45\n0.60\nMCC\nepoch #\n 0\n 1\n 5\n 10\n 25\n 50\n 100\n 500\nA\n01 02 03 04 05 0\n0.0\n0.2\n0.4\n0.6\n0.8\nBMCC\nepoch #\n 0\n 1\n 5\n 10\n 25\n 50\n 100\n 500\nFigure 3.  Effect of training data augmentation (1, 5, 10, 25, 50, 100, and 500) on MCC versus number of epochs \nnumber for test dataset (A) and training dataset (B). The MCC value represents the agreement between the \npredicted value and the true class, where: + 0.01 to + 0.19 indicates no or negligible relationship, + 0.20 to + 0.29 \nindicates weak positive relationship, + 0.30 to + 0.39 indicates moderate positive relationship, + 0.40 to + 0.69 \nindicates strong positive relationship, and + 0.70 or higher indicates very strong positive relationship.\n01 02 03 04 05 0\n0.4\n0.5\n0.6\n0.7\n0.8A\nLoss\nepoch #\n0\n1\n5\n10\n25\n50\n100\n500\n01 02 03 04 05 0\n0.2\n0.4\n0.6\n0.8B\nLoss\nepoch #\n0\n1\n5\n10\n25\n50\n100\n500\nFigure 4.  Dependence of the loss function as a function of epoch number obtained during the evaluation \nprocess for the binary classifier using the test dataset (A) or the training dataset (B). Series in each figure \ncorresponds to the number of datapoints in the augmentation dataset.\n5\nVol.:(0123456789)Scientific Reports |         (2024) 14:2715  | https://doi.org/10.1038/s41598-022-27106-w\nwww.nature.com/scientificreports/\nInitially, both losses were at same point (approximately 0.67) and then they start to diverge as the epoch \nnumber increases, reaching the maximum difference at epoch #40. At this point, the model was considered to \nbe overfitted and thus provided a rather poor generalization of unseen data. In contrast, the classifier trained \nonly with 5 epochs was underfitted. In this case, the training time was too short, and the model was not able to \nget meaningful information from the chemical space. In this context, an optimum classifier should be trained \nwith the number of epochs in between these two extremes, where the number of interactions is enough to learn \nimportant information from the dataset but not enough to overfit by \"memorizing” noise and other un-useful \ninformation in the training data.\nPredicting the stability of mixtures containing Ibuprofen\nIbuprofen [2-(4-isobutylphenyl)propionic acid] is a relatively  safe71, well-known non-steroidal anti-inflammatory \ndrug (NSAID) that is sold world-wide to treat mild to moderate pain, inflammation, and fever. Since its introduc-\ntion in the market back in 1970s, ibuprofen has become one of the most commonly used  NSAIDs72 and represents \na global market of more than $7500 M per year. Its effects are due to the inhibitory actions on cyclo-oxygenases, \nwhich mediate the synthesis of  prostaglandins73. Despite these advantages, ibuprofen is poorly soluble in water \nand therefore its bioavailability is limited by the dissolution of the solid form(s). Aiming to address this prob -\nlem, various formulations of ibuprofen have been proposed including the use of prodrugs, inclusion complexes, \nmicroencapsulation and dispersion in various  solvents74–76. Despite these advances, the solubility of ibuprofen is \ntoday a limiting factor that hinders the development and applicability of oral, injectable, and topical preparations \nof this  drug77,78. Considering that a liquid form of ibuprofen could potentially improve the bioavailability of the \ndrug while exhibiting fewer side-effects than some current formulations, we propose the use of our algorithm to \ndevelop a set of NADES based on ibuprofen. While as of today there are three reports describing the formation \nof ibuprofen-based DES/ILs in the  literature79–81, it is important to note that those strategies are derivative from \npreviously-reported DES and that none of those systems can be directly translated to other pharmaceuticals.\nToward these ends and based on the results described in Sect. 3.2, a classifier (designated as classifier Alpha) \nwas designed to represent an ideal model for our application. This classifier was fine-tuned by using the training \ndata set augmented with 100 synthetic data and the number of epochs was fixed at 15. For comparison purposes, \nanother classifier (designated as classifier Gamma) was also fine-tuned by using the same augmented dataset \nbut with the number of epochs set to 40. Both classifiers were used to predict the stability of 1 million unlabeled \ncandidate mixtures (collectively labeled the NADES/DES Universe) which were randomly generated by the \nuACL software. It is important to state that those mixtures present in the NADES/DES Universe were randomly \ngenerated, rather than fixing their constituents to a specific component such as ibuprofen or any other chemical. \nPosterior the predictions, only the results (compound mixture in SMILES format, predicted stability score, and \nlabel) for mixtures containing ibuprofen were post-processed and then exported in the CSV format. The distri-\nbution of stability scores for mixtures containing ibuprofen as predicted by both classifiers are shown in Fig. 6.\nUsing this strategy, approximately 2% out of the NADES/DES Universe presented ibuprofen in its composi-\ntion. Within these, 9% of those mixtures were predicted to be stable by classifier Alpha; while this percentage \ndropped to 7% by using classifier Gamma. It is important to mention that we defined stable mixtures as the ones \nwhere the score of the “Stable” classification—a rough approximation of predicted probability—was higher \nthan 50%. Therefore, the number of stable mixtures could be considerably smaller if this cut-off was set to 70%, \nfor example. Additionally, the database used for generating those random mixtures is biased with compounds \nknown to produce eutectic solvents (e.g., hydrogen bond donors and acceptors). As a point of reference, the \n01 02 03 04 0\n0.30\n0.45\n0.60\n0.75\nTraining\nLoss\nepoch #\nTest\nFigure 5.  Dependence of the loss function as a function of epoch number obtained during the evaluation \nprocess for the binary classifier using the test dataset (blue square boxes) or the training dataset (orange circles), \nboth considering 100 datapoints in the augmentation dataset. Line included to guide the eye.\n6\nVol:.(1234567890)Scientific Reports |         (2024) 14:2715  | https://doi.org/10.1038/s41598-022-27106-w\nwww.nature.com/scientificreports/\nsame strategy was implemented by using an open-source database of natural  compounds82 and the percent of \nmixtures predicted to be stable was less than 1%.\nIt is important to note that classifier Alpha predicts a decreasing stability distribution, presenting only 24 \nmixtures at range of predicted stability score between 80.1 and 85%. On the contrary, classifier Gamma has an \nincreasing distribution for that probability, presenting more than 600 mixtures with the probability of forming \na stable NADES between 90.1 and 95%. This difference was somewhat expected since this classifier was trained \nto be overfitted although it’s MCC has been the same as the classifier Alpha (0.42), indicating that the number \nof training iterations plays an important role during the development of an optimal classifier. Moreover, from \na statistical point of view, it is more likely that the number of eutectic mixtures decreases as the probability of \nbeing stable increases as exhibited by the classifier Alpha. Out of those mixtures containing ibuprofen predicted \nby this classifier, we decided to further consider the 10 most likely to form stable NADES (highest probability \nof rendering a stability of 1). These mixtures and the respective probability to form a stable NADES are sum -\nmarized in Table 1.\nThe number of mixtures selected to demonstrate the applicability of the approach (10 most likely out of the 24 \npredicted using a threshold of > 80.1%) was selected as a balance between the number of cases and the resources \nneeded to synthetize the NADES. All the solvents presented in Table  1 are ternary mixtures with well-known \nhydrogen bond acceptors as well as hydrogen bond donors on it is a composition such as chloride  derivates83, \n alcohols84,  acids85, and polyethylene  glycol86. In contrast, most of the unstable solvents predicted by this classi-\nfier (Table SI 3) are quaternary and/or quinary mixtures with a high number of molar ratios. These trends were \nsomewhat expected due to the chemical complexity of NADES formed by 10 molecules or more.\nExperimental validation of the predicted eutectic mixtures\nIn order to demonstrate the validity of the predictions provided by the proposed approach, the 10 combinations \nmost likely to form stable NADES (Table 1) were prepared in the laboratory. In cases, the corresponding amount \nof the pure constituents were mixed in a sealed glass vial and incubated at 80 °C (in a water bath), under gentle \nstirring, for approximately two hours. This process rendered liquid mixtures that were then removed from the \nwater bath and placed on the bench, where they were kept at room temperature for (at least) a week. It is also \nimportant to note that those mixtures formed with methanol (marked as * in Table 1) are not strictly considered \nnatural and would not be applicable towards pharmaceutical preparations. However, those mixtures were still \nexperimentally evaluated with the purpose of validating the predictions from the algorithm.\nAs shown in Fig.  7, eight out of the ten mixtures (80%) rendered stable NADES, remaining in clear liquid \nform at room temperature for at least one week. As this is very close to the average predicted stability score of \nthese mixtures (82.8%), this provides some indication that the predicted stability scores may be a good proxy for \nFigure 6.  Stability score distribution of mixtures containing ibuprofen predicted by Classifier Alpha (top) and \nby Classifier Gamma (bottom). The mixtures included in the most likely group of the histogram (80.1–85%) \nobtained with classifier Alpha are further discussed and experimentally validated in this work.\n7\nVol.:(0123456789)Scientific Reports |         (2024) 14:2715  | https://doi.org/10.1038/s41598-022-27106-w\nwww.nature.com/scientificreports/\nthe actual probability of forming a stable NADES. In ideal training conditions—neither under-nor overfitting \nand with a relatively unbiased training dataset—a classifier’s prediction scores should be a good approximation \nof true probability. This finding also suggests that while this paper only explored the top 10 mixtures, a more \nextensive list including all 24 mixtures at range of probability for a stable NADES between 80.1% and 85% could \nprovide additional stable formulations.\nFurthermore, when classifier Alpha’s performance was tested on the test dataset (see Sect. 3.5 below), its \noverall accuracy was calculated at 82%: a strong suggestion that the performance on the held-back test dataset \ncorresponds very well to the model’s true predictive power. More extensive testing would be required to verify \nthe model’s predictive power with certainty, both with regard to its overall accuracy (approximately 82% of its \npredictions are correct when a threshold of 0.5 is used) and its confidence in specific individual predictions of \nstability (averaging 82.8%) but these results are strongly suggestive of a good correspondence on both counts.\nAlthough the melting points of many of the constituents are well above room temperature, the correspond-\ning mixtures do not render crystals in the NADES; this is attributed to their participation in hydrogen bonding, \nleading to the eutectic mixture. For example, the melting point of sodium acetate (in mixture #8) is 324 °C so \nit would normally remain solid at room temperature. The stable liquid form of the NADES suggests that the \ncombination of ibuprofen and methanol hinders the formation of crystals through this  mechanism87. Moreover, \nwhile an equimolar mixture of ibuprofen and sodium acetate without methanol also rendered a stable NADES, \nthis mixture also featured high viscosity. This observation supports the hypothesis that protic solvents such as \nmethanol can be used to adjust the viscosity of NADES as well as  DES88–90. Additional information about the \nphysicochemical properties (e.g., number of hydrogen bond donor and acceptor) of ibuprofen, sodium acetate, \nand methanol can be found in the supplementary material (Table SI 4). It is also worth noting that while mixture \n#4 rendered a stable NADES, mixtures containing substantially different amounts of methanol, either in excess \nor defecit, were not stable: 1:1:1 mixtures crystalized as soon as the vial reached room temperature and 4:1:1 \nmixtures crystalized within a few hours at room temperature. This simple experiment illustrates the value of the \nproposed approach that is not only able to identify the compounds required to form a NADES but also the most \nlikely ratios to render stable mixtures.\nTable 1.  Composition for the 10 mixtures (containing ibuprofen) most likely to form a stable NADES, as \ncomputed by classifier Alpha. Mixtures containing methanol (neurotoxic) and diethanolamine (not natural) \nare included but marked with *, as these mixtures were only considered to demonstrate the applicability of the \nproposed approach.\nMixture # Component 1 Component 2 Component 3 Molar ratio Probability (%)\n1* Diethanolamine Ibuprofen Glycol 1:2:1 84.5\n2* 1,2-Butanediol Ibuprofen Methanol 1:1:3 83.8\n3 Ibuprofen Glycol 1,2-Butanediol 1:1:2 83.6\n4* Methanol Undecanoic Acid Ibuprofen 2:1:1 83.4\n5 Proline Choline Chloride Ibuprofen 2:2:1 83.3\n6 Undecanoic acid Ibuprofen Glycol 1:1:5 82.5\n7* Proline Ibuprofen Diethanolamine 1:3:3 82.3\n8* Sodium acetate Methanol Ibuprofen 1:2:1 82.0\n9 Choline Chloride Ibuprofen Glycol 1:3:4 81.2\n10 Mannitol Choline Chloride Ibuprofen 2:1:3 80.8\nFigure 7.  Experimental validation of the formation of the NADES predicted by classifier Alpha. The \ncomposition of each mixture is described in Table 1.\n8\nVol:.(1234567890)Scientific Reports |         (2024) 14:2715  | https://doi.org/10.1038/s41598-022-27106-w\nwww.nature.com/scientificreports/\nMoreover, one could imagine that given the appropriate resourses (funding and time), the treshhold could be \ndecreased from the currently 80.1% to render still more useful mixtures. In addition, it is worth mentioning that \nthe formation and physicochemical properties of the NADES formed depend not only on the chemical nature \nof its components but also on the strength of the intermolecular interactions formed at specific molar ratios. \nConsidering that NADES are formed only when these intermolecular interactions are dominant, one could \nenvision that a further optimization of mixtures #5 and #10 (slightly adjusting molar ratios and/or tailoring the \npreparation conditions) could lead to the formation of stable mixtures.\nPerformance of the optimum classifier on testing dataset\nThe performance of classifier Alpha was also investigated by means of the test dataset. This dataset is composed \nof 145 mixtures containing stable and unstable eutectic mixtures reported from the literature. The results are \nshown in Table 2.\nTaking in consideration all the parameters described above, classifier Alpha presented a satisfactory perfor-\nmance evaluating a dataset never seen before by the model. This performance could be improved by increasing \nthe quality as well as the amount of the data present in either the large general chemistry pre-training dataset or \nthe much smaller NADES-specific fine-tuning dataset. The training time would increase in either case, but much \nmore in the case of the large general chemistry dataset—possibly to the point that this strategy would be less \nattractive even for high end personal computers. Of these two possibilities to further improve the performance \nof the model, enriching the general-chemistry dataset would be far more costly and in-all-likelihood unneces -\nsary, given the initial success of the model so far. Accordingly, the evidence strongly suggests that growing the \nNADES-specific dataset used for the fine-tuning process would render a larger impact and enable much more effi-\ncient improvement of the algorithm without the need for costly and energy-inefficient computational resources.\nAs a further note; the predictive power of this model can be improved through the accumulation of more \ndata, and the model itself can be used to optimize the process. Through the process of bench-testing the model’s \npredictions and thereby increasing the amount of available training data, the model will inevitably become more \naccurate through subsequent rounds of training. Techniques to optimize this process, known as Active Learning, \ntypically rely on bench testing either the least-confident predictions (i.e. those predictions that lie very close to \nthe chosen 0.5 threshold for stability), on a maximally diverse group of test cases, or a combination of these. The \nresult of this process, if good balance is maintained in the bias of the dataset and care is taken to avoid under- or \noverfitting, could be the overall accuracy of prediction as well as the confidence in individual predictions rising \nfrom around 82–90% or higher.\nIn summary, the current work was motivated by the need to develop a computationally and energy efficient \napproach for formulating new natural deep eutectic solvents (NADES). Forming these solvents would be the \nfirst step towards their application in the pharmaceutical, agricultural, and food industries. Towards that goal, \na transformer-based neural network model was first pre-trained to recognize chemical reaction patterns from \nSMILES representations (unlabeled general chemical data) and then fine-tuned to recognize the labelled patterns \nof mixtures known to lead to the formation of either stable or unstable eutectic solvents using binary classifica-\ntion. This strategy, using a comparatively small database (1000 inputs) and a data augmentation strategy, enabled \nthe prediction of multiple new stable eutectic mixtures (n = 337) from a general database of natural compounds. \nWe present a critical assessment of the training process as well as the results of the prediction (components and \nmolar ratios) needed to render NADES with ibuprofen, a molecule that was not present in the original database. \nExamining the results, the 10 mixtures with the highest predicted likelihood of forming stable NADES were \nprepared, rendering a success rate of 80%; a figure which strongly validates both the overall accuracy of the \nmodel (calculated at 82% on the test dataset) and the model’s confidence that individual mixtures will be stable \n(a predicted mean of 82.8% for the tested mixtures). While further experiments are needed, it is reasonable to \nexpect that such liquid preparations of ibuprofen and other bioactive compounds could significantly impact the \npharmaceutical and nutraceutical industries, as the absorption of many drugs and natural bioactive compounds \nhave been historically hindered by solubility issues. More importantly, this strategy has the potential to provide \ntransformative solutions to the pharmaceutical and nutraceutical industries, where bioactive compounds can \nbecome functional components of liquid formulations, rather than simple solutes dispersed in a NADES  matrix91. \nWe also believe that, with the appropriate databases, the approach could be expanded to predict additional infor-\nmation related to the formation of NADES. That said, this report represents a leap forward towards the efficient \ndevelopment of the newest class of DES: therapeutic DES or  THEDES81,92,93.\nMethods\nHardware configuration\nAll the results presented in this manuscript were generated using the Palmetto cluster, from Clemson Univer -\nsity (palmetto.clemson.edu). A NVIDIA Tesla V100 was used as graphical processing unit (GPU) to train and \nTable 2.  Comparison of the performance parameters for the Alpha and Gamma classifiers. These parameters \nwere calculated using the same test dataset.\nClassifier MCC Accuracy F1-score Loss\nAlpha (optimum) 0.42 0.82 0.82 0.56\nGamma (overfitted) 0.42 0.73 0.73 0.70\n9\nVol.:(0123456789)Scientific Reports |         (2024) 14:2715  | https://doi.org/10.1038/s41598-022-27106-w\nwww.nature.com/scientificreports/\nfine-tune the deep learning model. The Palmetto computer node was set to 16 cores (ncpus) and the amount of \nmemory was set to 125 Gb. It is important to state that while access to the cluster was critical to speed up the \ninitial training process, the trained algorithm can be executed in a standard computer.\nDeep learning model\nThe Hugging Face open-source version of Google Research’s ELECTRA  94 deep learning transformer was used \nto train a general chemistry model from scratch and subsequently to fine-tune the model to enable performing \ndownstream tasks such as binary classification. The rational design behind ELECTRA consists of pretraining \na discriminator transformer model that predicts tokens either replaced or not from another neural network \ncalled the generator. This strategy allows the development of small models that still perform well compared to \ntraditional state-of-the-art natural language processing models such as GPT, BERT-Base, and RoBERTa, given \nthe same dataset. This unique feature also allows the use of relatively small datasets and less computational power \nto train accurate models. The installation steps and the required packages can be found elsewhere (https:// huggi \nngface. co/ docs/ trans forme rs/ insta llati on).\nChemical databases for AI\nMIT mixed augmented\nThe Molecular Transformer MIT Mixed Augmented  database55 was used to train the general chemistry model \nfrom scratch. This database consists of approximately  106 organic reactions, represented using the  SMILES54 \nnotation. Each line of the source database that contains reactants (src-train.txt) is linked to its correspond-\ning products on the target database (tgt-train.txt). These two text files were merged into a single raw database \n(raw_MIT.txt) where the reactants are separated from the products by the non-SMILES character “ > ” . The same \nstrategy was used for the test dataset and the resulting file (raw_MIT_test.txt) was used for the proposed general \nchemistry model.\nuACL NADES/DES non-augmented\nThe database developed in-house for this project (referred to as uACL DB) contains approximately  103 previ-\nously reported examples of NADES/DES, where the components are represented using the canonical SMILES \nnotation. Those combinations leading to stable mixtures (e.g., synthesized NADES and/or DES in the liquid state \nthat are stable for more than one week at room temperature) were labelled as “1” . On the contrary, combinations \nof components not leading to liquid mixtures, or those that crystalize soon after the synthesis (non-stable) were \nlabelled as “0” . A fraction (20%) of the raw uACL database was randomly sampled out from the original database \nto constitute the test dataset. The remaining 80% was then saved in a different file (the training dataset) and \nused to fine-tune the general chemistry model into a binary classifier, capable of classifying mixtures as stable \n(1) or non-stable (0). Additionally, both datasets were algorithmically compared to delete any duplicate entries.\nuACL NADES/DES augmented\nIn preliminary experiments, we found that the limited size of the database, containing  ~  103 examples of previ-\nously-reported (most of them stable) NADES, led to significant overfitting. In this case, the algorithm was able \nto obtain relatively high scores, even if predicting “stable” for non-stable mixtures. To address this problem, \nthe uACL database was augmented by a script called Mixture Generator Alpha (uACl_mix_gen_alfa.py). The \nscript is responsible for generating mixtures by randomly varying the number of components (from 3 to 5), \nvarying each individual chemical component (among 198 possibilities), as well as the stoichiometric coefficient \nfor each component (from 1 to 10). The mixtures generated by this strategy were labeled as “0” (unstable) and \nthen added to the uACL database according to the number of data augmented (e.g. 1, 10, 25, 100, 500). It is \nalso worth mentioning that the number of components was adjusted (from 3 to 5) to increase the likelihood \nof forming new NADES rather than commonly reported binary DES systems based on choline  chloride40,83 or \nammonium  salts49–52.\nPre-training method\nWith the recent emergence of transformer-type architectures as a dominant form of Neural Network in the Natu-\nral Language Processing space, it has become a standard practice to pre-train these neural nets as Foundation \nModels of one or more human language(s), using Self-Supervised Learning. State-of-the-art transformer language \nmodels are often trained on hundreds of millions or billions of lines of text, at great cost in computer time and \nenergy. This costly pre-training on a general language task instills the model with a broad general “understand-\ning” (i.e. statistical characterization) of the language(s), which makes it possible to much more quickly and \nefficiently fine-tune the model for many potential “downstream” specific tasks such as sentence classification, \nquestion answering, etc. In a similar way, the team’s intention here was to use a large general corpus of chemi -\ncal reaction information in the form of sequences of characters, to pre-train a general chemistry model which \ncould then be fine-tuned on a much smaller dataset for a very specific task. Recent  work95–97 has demonstrated \nthat such AI approaches can outperform both traditional Force Field and Quantum Mechanical simulations of \nreaction chemistry for a given amount of computation and reaction complexity. However, unlike the practice \nof natural language processing, AI Foundation Models for general chemistry are not yet readily available: hence \nthe necessity of the chemistry-specific pre-training effort. The number of hidden layers for the generator as well \nas discriminator for the ELECTRA deep learning model were 4 and 16, respectively. The vocabulary size was set \nto 30,000 and the number of training epochs (the number of rounds of training on the full training dataset) to \n40. The train_MIT.txt file was used as training dataset while test_MIT_.txt  was used as test dataset. The output \n10\nVol:.(1234567890)Scientific Reports |         (2024) 14:2715  | https://doi.org/10.1038/s41598-022-27106-w\nwww.nature.com/scientificreports/\nmodel containing all the trained parameters (e.g., discriminator, generator, and vocabulary) was archived in a \nsingle directory denominated as model_001.\nFine-tuning method\nIn order to fine-tune the general chemistry model and use it as a binary classifier a custom script was used \n(binary_model.py), developed following stablished procedures (https:// simpl etran sform ers. ai/ docs/ binary- class \nifica tion/). The last layer of neurons of the model_001 was fine tuned into a binary classifier by using the train_\nuACL_non_aug.txt database as training dataset and the test_uACL_non_aug.txt file as test dataset. Additionally, \nall the augmented test datasets described in item 2.3.3 were used to investigate the performance of those models \ngiven the same test dataset (test_uACL_non_aug.txt). Regarding the neural network architecture, the param-\neters “max_seq_lenght” , ”train_batch_size” , and “learning_rate” were adjusted to 128, 32, and  4E-5, respectively.\nuACL software\nTo predict the stability of previously-unseen potential DES mixtures, the uACL software was developed. The \nsoftware is composed by three main modules: Mixture Generator Beta, Classifier, and Compound Finder. As the \nname suggests, the Mixture Generator is responsible for generating mixtures with a random number of com-\nponents, random component compounds, and random stoichiometric numbers. Differently from the Mixture \nGenerator Alpha described in item 2.3.3, the Beta version will not assign any label to the combination generated \nand all the results are saved in a text file (NADES/DES_universe.txt). This text file is then sent to the Classifier, \nwhich infers the probability of each mixture to be stable or not. This is accomplished by implementing a SoftMax \n function98 on the raw output of the last layer from the deep neural network model. All the predictions with their \nrespective stability scores are postprocessed in the Compound Finder module. This module allows the user to \nanalyze and predict the eutectic stability of large numbers of mixtures, optionally including a single specified \ncompound (e.g., only mixtures that contain Ibuprofen) in the CSV format. A summary of the proposed strategy \nis shown in Fig. 8.\nChemical reagents\nSolid ibuprofen was purchased from Spectrum Chemical Mfg. Corp. (New Brunswick, NJ, USA). Sodium acetate, \nundecanoic acid, 1,2 butanediol, propionic acid, 1,6 hexanediol, proline, diethanolamine, and ethylene glycol \nwere purchased from Sigma-Aldrich (Burlington, WI, USA). Methanol was purchased from Thermo-Fischer \nScientific (Fischer Chemical, NJ, USA). These reagents were of analytical grade (or better) and used as received.\nNADES/DES preparation\nPrior the preparation of NADES/DES mixtures, the individual solid samples were heated at 80 °C for several \nhours to remove water molecules. NADES and/or DES with molar ratio compositions predicted by the artificial \nneural network model were prepared by the traditional heating method (80 °C) under magnetic stirring (350 \nRPM) for 2 h and then allowed to cool down to room temperature.\nData availability\nThe datasets used and/or analysed during the current study available from the corresponding author upon \nreasonable requests.\nReceived: 25 October 2022; Accepted: 26 December 2022\nReferences\n 1. Singh, S. K. & Savoy, A. W . Ionic liquids synthesis and applications: An overview. J. Mol. Liq. 297, 112038. https:// doi. org/ 10. 1016/j. \nmolliq. 2019. 112038 (2020).\n 2. Smith, E. L., Abbott, A. P . & Ryder, K. S. Deep eutectic solvents (DESs) and their applications. Chem. Rev. 114, 11060–11082. \nhttps:// doi. org/ 10. 1021/ cr300 162p (2014).\n 3. Paiva, A. et al. Natural deep eutectic solvents: Solvents for the 21st century. ACS Sustain. Chem. Eng. 2, 1063–1071. https://  doi. \norg/ 10. 1021/ sc500 096j (2014).\n 4. Santana-Mayor, Á., Herrera-Herrera, A. V ., Rodríguez-Ramos, R., Socas-Rodríguez, B. & Rodríguez-Delgado, M. Á. Development \nof a green alternative vortex-assisted dispersive liquid-liquid microextraction based on natural hydrophobic deep eutectic solvents \nFigure 8.  Summary of the proposed strategy for predicting the formation of stable NADES.\n11\nVol.:(0123456789)Scientific Reports |         (2024) 14:2715  | https://doi.org/10.1038/s41598-022-27106-w\nwww.nature.com/scientificreports/\nfor the analysis of phthalate esters in soft drinks. ACS Sustain. Chem. Eng. 9, 2161–2170. https:// doi. org/ 10. 1021/ acssu schem eng. \n0c076 86 (2021).\n 5. Tahir, S. et al. Deep eutectic solvents as alternative green solvents for the efficient desulfurization of liquid fuel: A comprehensive \nreview. Fuel 305, 121502. https:// doi. org/ 10. 1016/j. fuel. 2021. 121502 (2021).\n 6. Aslan Türker, D. & Doğan, M. Application of deep eutectic solvents as a green and biodegradable media for extraction of antho-\ncyanin from black carrots. LW T 138, 110775. https:// doi. org/ 10. 1016/j. lwt. 2020. 110775 (2021).\n 7. Cheong, L.-Z. et al. in Recent Advances in Edible Fats and Oils Technology: Processing, Health Implications, Economic and Environ-\nmental Impact (eds Y ee- Ying Lee, Teck-Kim Tang, Eng-Tong Phuah, & Oi-Ming Lai) 235–247 (Springer, 2022).\n 8. Xia, G.-H., Li, X.-H. & Jiang, Y .-H. Deep eutectic solvents as green media for flavonoids extraction from the rhizomes of Polygo-\nnatum odoratum. Alex. Eng. J. 60, 1991–2000. https:// doi. org/ 10. 1016/j. aej. 2020. 12. 008 (2021).\n 9. Ramezani, A. M., Ahmadi, R. & Y amini, Y . Homogeneous liquid-liquid microextraction based on deep eutectic solvents. Trends \nAnal. Chem. 149, 116566. https:// doi. org/ 10. 1016/j. trac. 2022. 116566 (2022).\n 10. Nanda, B., Sailaja, M., Mohapatra, P ., Pradhan, R. K. & Nanda, B. B. Green solvents: A suitable alternative for sustainable chemistry. \nMater. Today 47, 1234–1240. https:// doi. org/ 10. 1016/j. matpr. 2021. 06. 458 (2021).\n 11. Welton, T. Solvents and sustainable chemistry. Proc. Math. Phys. Eng. Sci. 471, 20150502. https:// doi. org/ 10. 1098/ rspa. 2015. 0502 \n(2015).\n 12. Horváth, I. T. Introduction: Sustainable chemistry. Chem. Rev. 118, 369–371. https:// doi. org/ 10. 1021/ acs. chemr ev. 7b007 21 (2018).\n 13. Martins, M. A. R., Pinho, S. P . & Coutinho, J. A. P . Insights into the nature of eutectic and deep eutectic mixtures. J. Solut. Chem. \n48, 962–982. https:// doi. org/ 10. 1007/ s10953- 018- 0793-1 (2019).\n 14. El Achkar, T., Greige-Gerges, H. & Fourmentin, S. Basics and properties of deep eutectic solvents: A review. Environ. Chem. Lett. \n19, 3397–3408. https:// doi. org/ 10. 1007/ s10311- 021- 01225-8 (2021).\n 15. Panić, M., Cvjetko Bubalo, M. & Radojčić Redovniković, I. Designing a biocatalytic process involving deep eutectic solvents. J. \nChem. Technol. Biotechnol. 96, 14–30. https:// doi. org/ 10. 1002/ jctb. 6545 (2021).\n 16. Pätzold, M. et al. Deep eutectic solvents as efficient solvents in biocatalysis. Trends Biotechnol. 37, 943–959. https:// doi. org/ 10. \n1016/j. tibte ch. 2019. 03. 007 (2019).\n 17. Pätzold, M., Weimer, A., Liese, A. & Holtmann, D. Optimization of solvent-free enzymatic esterification in eutectic substrate \nreaction mixture. Biotechnol. Rep. 22, e00333. https:// doi. org/ 10. 1016/j. btre. 2019. e00333 (2019).\n 18. Dudu, A. I., Bencze, L. C., Paizs, C. & Toşa, M. I. Deep eutectic solvents: A new additive in the encapsulation of lipase B from \nCandida antarctica: biocatalytic applications. React. Chem. Eng. 7, 442–449. https:// doi. org/ 10. 1039/ D1RE0 0469G (2022).\n 19. Farooq, M. Q., Abbasi, N. M. & Anderson, J. L. Deep eutectic solvents in separations: Methods of preparation, polarity, and applica-\ntions in extractions and capillary electrochromatography. J. Chromatogr. A 1633, 461613. https:// doi. org/ 10. 1016/j. chroma. 2020. \n461613 (2020).\n 20. Raj, D. Thin-layer chromatography with eutectic mobile phases—preliminary results. J. Chromatogr. A 1621, 461044. https:// doi. \norg/ 10. 1016/j. chroma. 2020. 461044 (2020).\n 21. Roehrer, S., Bezold, F ., García, E. & Minceva, M. Deep eutectic solvents in countercurrent and centrifugal partition chromatography. \nJ. Chromatogr. A https:// doi. org/ 10. 1016/j. chroma. 2016. 01. 024 (2016).\n 22. Cai, T. & Qiu, H. Application of deep eutectic solvents in chromatography: A review. Trends Anal. Chem. 120, 115623. https:// doi. \norg/ 10. 1016/j. trac. 2019. 115623 (2019).\n 23. Cen, P ., Spahiu, K., Tyumentsev, M. S. & Foreman, M. R. S. J. Metal extraction from a deep eutectic solvent, an insight into activi-\nties. Phys. Chem. Chem. Phys. 22, 11012–11024. https:// doi. org/ 10. 1039/ C9CP0 5982B (2020).\n 24. Osowska, N. & Ruzik, L. New potentials in the extraction of trace metal using natural deep eutectic solvents (NADES). Food Anal. \nMethods 12, 926–935. https:// doi. org/ 10. 1007/ s12161- 018- 01426-y (2019).\n 25. Skarpalezos, D. & Detsi, A. Deep eutectic solvents as extraction media for valuable flavonoids from natural sources. Appl. Sci.  \nhttps:// doi. org/ 10. 3390/ app91 94169 (2019).\n 26. Dheyab, A. S. et al. Deep eutectic solvents (DESs) as green extraction media of beneficial bioactive phytochemicals. Separations. \nhttps:// doi. org/ 10. 3390/ separ ation s8100 176 (2021).\n 27. Owczarek, K. et al. Natural deep eutectic solvents in extraction process. Chem. Chem. Technol. 10, 601–606. https:// doi. org/ 10. \n23939/ chcht 10. 04si. 601 (2016).\n 28. Rachmaniah, O., Wilson, E., Choi, Y . H., Witkamp, G. J. & Verpoorte, R. Pressurized natural deep eutectic solvent extraction of \ngalanthamine and related alkaloids from narcissus pseudonarcissus. Planta Med. https:// doi. org/ 10. 1055/a- 1803- 3259 (2022).\n 29. Brett, C. M. A. Deep eutectic solvents and applications in electrochemical sensing. Curr. Opin. Electrochem. 10, 143–148. https:// \ndoi. org/ 10. 1016/j. coelec. 2018. 05. 016 (2018).\n 30. Lee, J. H. Q., Koh, Y . R. & Webster, R. D. The electrochemical oxidation of diethylstilbestrol (DES) in acetonitrile. J. Electroanal. \nChem 799, 92–101. https:// doi. org/ 10. 1016/j. jelec hem. 2017. 05. 044 (2017).\n 31. Cruz, H. et al. Alkaline iodide-based deep eutectic solvents for electrochemical applications. ACS Sustain. Chem. Eng. 8, 10653–\n10663. https:// doi. org/ 10. 1021/ acssu schem eng. 9b067 33 (2020).\n 32. Aroso, I. M. et al. Dissolution enhancement of active pharmaceutical ingredients by therapeutic deep eutectic systems. Eur. J. \nPharm. Biopharm. 98, 57–66. https:// doi. org/ 10. 1016/j. ejpb. 2015. 11. 002 (2016).\n 33. Liu, M. et al. Novel amorphous solid dispersion based on natural deep eutectic solvent for enhancing delivery of anti-tumor RA-\nXII by oral administration in rats. Eur. J. Pharm. Sci. 166, 105931. https:// doi. org/ 10. 1016/j. ejps. 2021. 105931 (2021).\n 34. Ling, J. K. U., Chan, Y . S., Nandong, J., Chin, S. F . & Ho, B. K. Formulation of choline chloride/ascorbic acid natural deep eutectic \nsolvent: Characterization, solubilization capacity and antioxidant property. LW T 133, 110096. https:// doi. org/ 10. 1016/j. lwt. 2020. \n110096 (2020).\n 35. Pradeepkumar, P ., Subbiah, A. & Rajan, M. Synthesis of bio-degradable poly(2-hydroxyethyl methacrylate) using natural deep \neutectic solvents for sustainable cancer drug delivery. SN Appl. Sci. 1, 568. https:// doi. org/ 10. 1007/ s42452- 019- 0591-4 (2019).\n 36. Y ang, Z. in Deep Eutectic Solvents, Synthesis, Properties, and Applications (ed D.J. Ramón and G. Guillena) Ch. 3, 43–60 (2019).\n 37. Wen, Q., Chen, J.-X., Tang, Y .-L., Wang, J. & Y ang, Z. Assessing the toxicity and biodegradability of deep eutectic solvents. Chem-\nosphere 132, 63–69. https:// doi. org/ 10. 1016/j. chemo sphere. 2015. 02. 061 (2015).\n 38. Dazat, R. E. et al. On-site preparation of natural deep eutectic solvents using solar energy. ChemistrySelect 7, e202104362. https:// \ndoi. org/ 10. 1002/ slct. 20210 4362 (2022).\n 39. Gomez, F . J. V ., Espino, M., Fernández, M. A. & Silva, M. F . A greener approach to prepare natural deep eutectic solvents. Chem-\nistrySelect 3, 6122–6125. https:// doi. org/ 10. 1002/ slct. 20180 0713 (2018).\n 40. Fanali, C. et al. Choline chloride-lactic acid-based NADES as an extraction medium in a response surface methodology-optimized \nmethod for the extraction of phenolic compounds from hazelnut skin. Molecules 26, 2652. https:// doi. org/ 10. 3390/ molec ules2 \n60926 52 (2021).\n 41. Espino, M., Fernández, M., Gomez, F . & Silva, M. Natural designer solvents for greening analytical chemistry. Trends Anal. Chem. \nhttps:// doi. org/ 10. 1016/j. trac. 2015. 11. 006 (2015).\n 42. Jesus, A. R., Duarte, A. R. C. & Paiva, A. Use of natural deep eutectic systems as new cryoprotectant agents in the vitrification of \nmammalian cells. Sci. Rep. 12, 8095. https:// doi. org/ 10. 1038/ s41598- 022- 12365-4 (2022).\n 43. Mitar, A. et al. Physicochemical properties, cytotoxicity, and antioxidative activity of natural deep eutectic solvents containing \norganic acid. Chem. Biochem. Eng. Q. 33, 1–18. https:// doi. org/ 10. 15255/ CABEQ. 2018. 1454 (2019).\n12\nVol:.(1234567890)Scientific Reports |         (2024) 14:2715  | https://doi.org/10.1038/s41598-022-27106-w\nwww.nature.com/scientificreports/\n 44. Tolmachev, D. et al. Computer simulations of deep eutectic solvents: Challenges, solutions, and perspectives. Int. J. Mol. Sci. 23, \n645 (2022).\n 45. Alkhatib, I. I. I., Bahamon, D., Llovell, F ., Abu-Zahra, M. R. M. & Vega, L. F . Perspectives and guidelines on thermodynamic \nmodelling of deep eutectic solvents. J. Mol. Liq. 298, 112183. https:// doi. org/ 10. 1016/j. molliq. 2019. 112183 (2020).\n 46. Bergua, F ., Castro, M., Muñoz-Embid, J., Lafuente, C. & Artal, M. Hydrophobic eutectic solvents: Thermophysical study and appli-\ncation in removal of pharmaceutical products from water. Chem. Eng. J. 411, 128472. https:// doi. org/ 10. 1016/j. cej. 2021. 128472 \n(2021).\n 47. Shakourian-Fard, M., Reza Ghenaatian, H., Alizadeh, V ., Kamath, G. & Khalili, B. Density functional theory investigation into \nthe interaction of deep eutectic solvents with amino acids. J. Mol. Liq. 343, 117624. https:// doi. org/ 10. 1016/j. molliq. 2021. 117624 \n(2021).\n 48. Ayres, L. B., Gomez, F . J. V ., Linton, J. R., Silva, M. F . & Garcia, C. D. Taking the leap between analytical chemistry and artificial \nintelligence: A tutorial review. Anal. Chim. Acta 1161, 338403. https:// doi. org/ 10. 1016/j. aca. 2021. 338403 (2021).\n 49. Shahbaz, K., Baroutian, S., Mjalli, F . S., Hashim, M. A. & AlNashef, I. M. Densities of ammonium and phosphonium based deep \neutectic solvents: Prediction using artificial intelligence and group contribution techniques. Thermochim. Acta 527, 59–66. https:// \ndoi. org/ 10. 1016/j. tca. 2011. 10. 010 (2012).\n 50. Shahbaz, K., Baroutian, S., Mjalli, F . S., Hashim, M. A. & AlNashef, I. M. Prediction of glycerol removal from biodiesel using \nammonium and phosphunium based deep eutectic solvents using artificial intelligence techniques. Chemometr. Intell. Lab. Syst.  \n118, 193–199. https:// doi. org/ 10. 1016/j. chemo lab. 2012. 06. 005 (2012).\n 51. Abdollahzadeh, M. et al. Estimating the density of deep eutectic solvents applying supervised machine learning techniques. Sci. \nRep. 12, 4954. https:// doi. org/ 10. 1038/ s41598- 022- 08842-5 (2022).\n 52. Fiyadh, S. S. et al. Artificial neural network approach for modelling of mercury ions removal from water using functionalized \nCNTs with deep eutectic solvent. Int. J. Mol. Sci. https:// doi. org/ 10. 33909/ ijms2 01742 06 (2019).\n 53. Vaswani, A. et al. Attention Is All Y ou Need. https:// arxiv. org/ abs/ 1706. 03762 (2017). https:// ui. adsabs. harva rd. edu/ abs/ 2017a \nrXiv1 70603 762V.\n 54. Weininger, D. SMILES, a chemical language and information system: 1: Introduction to methodology and encoding rules. J. Chem. \nInf. Comput. Sci. 28, 31–36. https:// doi. org/ 10. 1021/ ci000 57a005 (1988).\n 55. Schwaller, P . et al. Molecular transformer: A model for uncertainty-calibrated chemical reaction prediction. ACS Cent. Sci.  5, \n1572–1583. https:// doi. org/ 10. 1021/ acsce ntsci. 9b005 76 (2019).\n 56. Tetko, I. V ., Karpov, P ., Van Deursen, R. & Godin, G. State-of-the-art augmented NLP transformer models for direct and single-\nstep retrosynthesis. Nat. Commun. 11, 5575. https:// doi. org/ 10. 1038/ s41467- 020- 19266-y (2020).\n 57. Karpov, P ., Godin, G. & Tetko, I. V . A Transformer Model for Retrosynthesis. In Artificial Neural Networks and Machine Learning – \nICANN 2019: Workshop and Special Sessions. (eds Igor V . Tetko, Věra Kůrková, Pavel Karpov, & Fabian Theis) 817–830 (Springer).\n 58. Rajan, K., Zielesny, A. & Steinbeck, C. STOUT: SMILES to IUPAC names using neural machine translation. J. Cheminform.  13, \n34. https:// doi. org/ 10. 1186/ s13321- 021- 00512-4 (2021).\n 59. Krasnov, L., Khokhlov, I., Fedorov, M. V . & Sosnin, S. Transformer-based artificial neural networks for the conversion between \nchemical notations. Sci. Rep. 11, 14798. https:// doi. org/ 10. 1038/ s41598- 021- 94082-y (2021).\n 60. Kim, H., Na, J. & Lee, W . B. Generative chemical transformer: Neural machine learning of molecular geometric structures from \nchemical language via attention. J. Chem. Inf. Model 61, 5804–5814. https:// doi. org/ 10. 1021/ acs. jcim. 1c012 89 (2021).\n 61. Pesciullesi, G., Schwaller, P ., Laino, T. & Reymond, J.-L. Transfer learning enables the molecular transformer to predict regio- and \nstereoselective reactions on carbohydrates. Nat. Commun. 11, 4874. https:// doi. org/ 10. 1038/ s41467- 020- 18671-7 (2020).\n 62. rdkit/rdkit: 2022_03_4 (Q1 2022) Release (Zenodo, 2022).\n 63. Roberts, D. A., Y aida, S. & Hanin, B. The Principles of Deep Learning Theory. https:// arxiv. org/ abs/ 2106. 10165 (2021). https:// ui. \nadsabs. harva rd. edu/ abs/ 2021a rXiv2 10610 165R.\n 64. Alzubaidi, L. et al. Review of deep learning: Concepts, CNN architectures, challenges, applications, future directions. J. Big Data  \n8, 53. https:// doi. org/ 10. 1186/ s40537- 021- 00444-8 (2021).\n 65. Baldi, P ., Brunak, S., Chauvin, Y ., Andersen, C. A. F . & Nielsen, H. Assessing the accuracy of prediction algorithms for classifica-\ntion: An overview. Bioinformatics 16, 412–424. https:// doi. org/ 10. 1093/ bioin forma tics/ 16.5. 412 (2000).\n 66. Terrada, O., Cherradi, B., Raihani, A. & Bouattane, O. Classification and Prediction of atherosclerosis diseases using machine \nlearning algorithms. in 2019 5th International Conference on Optimization and Applications (ICOA). 1–5.\n 67. Naulaerts, S., Dang, C. C. & Ballester, P . J. Precision and recall oncology: Combining multiple gene mutations for improved iden-\ntification of drug-sensitive tumours. Oncotarget 8, 97025–97040. https:// doi. org/ 10. 18632/ oncot arget. 20923 (2017).\n 68. Mohabatkar, H., Beigi, M. M., Abdolahi, K. & Mohsenzadeh, S. Prediction of allergenic proteins by means of the concept of Chou’s \npseudo amino acid composition and a machine learning approach. Med. Chem. 9, 133–137. https:// doi. org/ 10. 2174/ 15734 06138 \n04488 341 (2013).\n 69. Ting, K. M. in Encyclopedia of Machine Learning and Data Mining (eds Claude Sammut & Geoffrey I. Webb) 260–260 (Springer, \n2017).\n 70. Chicco, D. & Jurman, G. The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary \nclassification evaluation. BMC Genomics 21, 6. https:// doi. org/ 10. 1186/ s12864- 019- 6413-7 (2020).\n 71. Kaufman, D. W . et al. Exceeding the daily dosing limit of nonsteroidal anti-inflammatory drugs among ibuprofen users. Pharma-\ncoepidemiol. Drug Saf. 27, 322–331. https:// doi. org/ 10. 1002/ pds. 4391 (2018).\n 72. Rainsford, K. D. in Ibuprofen 313–345 (2015).\n 73. Varrassi, G., Pergolizzi, J. V ., Dowling, P . & Paladini, A. Ibuprofen safety at the golden anniversary: Are all NSAIDs the same? A \nNarrative Review. Adv. Ther. 37, 61–82. https:// doi. org/ 10. 1007/ s12325- 019- 01144-9 (2020).\n 74. Y ong, C. S. et al. Preparation of ibuprofen-loaded liquid suppository using eutectic mixture system with menthol. Eur. J. Pharm. \nSci. 23, 347–353. https:// doi. org/ 10. 1016/j. ejps. 2004. 08. 008 (2004).\n 75. Celebioglu, A. & Uyar, T. Fast dissolving oral drug delivery system based on electrospun nanofibrous webs of cyclodextrin/ibuprofen \ninclusion complex nanofibers. Mol. Pharm. 16, 4387–4398. https:// doi. org/ 10. 1021/ acs. molph armac eut. 9b007 98 (2019).\n 76. Janus, E. et al. Enhancement of ibuprofen solubility and skin permeation by conjugation with l-valine alkyl esters. RSC Adv.  10, \n7570–7584. https:// doi. org/ 10. 1039/ D0RA0 0100G (2020).\n 77. Irvine, J., Afrose, A. & Islam, N. Formulation and delivery strategies of ibuprofen: Challenges and opportunities. Drug Dev. Ind. \nPharm. 44, 173–183. https:// doi. org/ 10. 1080/ 03639 045. 2017. 13918 38 (2018).\n 78. Li, C., Wang, K. & Xie, D. Green Fabrication and Release Mechanisms of pH-Sensitive Chitosan–Ibuprofen Aerogels for Controlled \nTransdermal Delivery of Ibuprofen. Front. Chem. 9 (2021).\n 79. Stott, P . W ., Williams, A. C. & Barry, B. W . Transdermal delivery from eutectic systems: Enhanced permeation of a model drug, \nibuprofen. J. Control. Release 50, 297–308. https:// doi. org/ 10. 1016/ S0168- 3659(97) 00153-3 (1998).\n 80. Ossowicz-Rupniewska, P . et al. Binding behavior of ibuprofen-based ionic liquids with bovine serum albumin: Thermodynamic \nand molecular modeling studies. J. Mol. Liq. 360, 119367. https:// doi. org/ 10. 1016/j. molliq. 2022. 119367 (2022).\n 81. Silva, E. et al. Optimal design of THEDES based on perillyl alcohol and ibuprofen. Pharmaceutics. https:// doi. org/ 10. 3390/ pharm \naceut ics12 111121 (2020).\n 82. Sorokina, M., Merseburger, P ., Rajan, K., Yirik, M. A. & Steinbeck, C. COCONUT online: Collection of open natural products \ndatabase. J. Cheminform. 13, 2. https:// doi. org/ 10. 1186/ s13321- 020- 00478-9 (2021).\n13\nVol.:(0123456789)Scientific Reports |         (2024) 14:2715  | https://doi.org/10.1038/s41598-022-27106-w\nwww.nature.com/scientificreports/\n 83. Abbott, A. P ., Boothby, D., Capper, G., Davies, D. L. & Rasheed, R. K. Deep eutectic solvents formed between choline chloride \nand carboxylic acids: Versatile alternatives to ionic liquids. J. Am. Chem. Soc. 126, 9142–9147. https:// doi. org/ 10. 1021/ ja048 266j \n(2004).\n 84. Fan, Y . et al. Hydrophobic natural alcohols based deep eutectic solvents: Effective solvents for the extraction of quinine. Sep. Purif. \nTechnol 275, 119112. https:// doi. org/ 10. 1016/j. seppur. 2021. 119112 (2021).\n 85. Shan, Y ., Han, Y ., Fan, C., Liu, Y . & Cao, X. New natural deep eutectic solvents based on aromatic organic acids. Green Chem. Lett. \nRev. 14, 713–719. https:// doi. org/ 10. 1080/ 17518 253. 2021. 20095 79 (2021).\n 86. Aldawsari, J. N. et al. Polyethylene glycol-based deep eutectic solvents as a novel agent for natural gas sweetening. PLoS ONE 15, \ne0239493. https:// doi. org/ 10. 1371/ journ al. pone. 02394 93 (2020).\n 87. Alioui, O. et al. Theoretical and experimental evidence for the use of natural deep eutectic solvents to increase the solubility and \nextractability of curcumin. J. Mol. Liq. 359, 119149. https:// doi. org/ 10. 1016/j. molliq. 2022. 119149 (2022).\n 88. Haghbakhsh, R., Duarte, A. R. C. & Raeissi, S. Viscosity investigations on the binary systems of (1 ChCl:2 Ethylene Glycol) DES \nand methanol or ethanol. Molecules https:// doi. org/ 10. 3390/ molec ules2 61855 13 (2021).\n 89. Gygli, G., Xu, X. & Pleiss, J. Meta-analysis of viscosity of aqueous deep eutectic solvents and their components. Sci. Rep. 10, 21395. \nhttps:// doi. org/ 10. 1038/ s41598- 020- 78101-y (2020).\n 90. Kivelä, H. et al. Effect of water on a hydrophobic deep eutectic solvent. J. Phys. Chem. B. 126, 513–527. https:// doi. org/ 10. 1021/ \nacs. jpcb. 1c081 70 (2022).\n 91. Gutiérrez, A., Atilhan, M. & Aparicio, S. Theoretical study on deep eutectic solvents as vehicles for the delivery of anesthetics. J. \nPhys. Chem. B. 124, 1794–1805. https:// doi. org/ 10. 1021/ acs. jpcb. 9b117 56 (2020).\n 92. Aroso, I. M. et al. Design of controlled release systems for THEDES—Therapeutic deep eutectic solvents, using supercritical fluid \ntechnology. Int. J. Pharm. 492, 73–79. https:// doi. org/ 10. 1016/j. ijpha rm. 2015. 06. 038 (2015).\n 93. Rahman, M. S. et al. Formulation, structure, and applications of therapeutic and amino acid-based deep eutectic solvents: An \noverview. J. Mol. Liq. 321, 114745. https:// doi. org/ 10. 1016/j. molliq. 2020. 114745 (2021).\n 94. Clark, K., Luong, M.-T., Le, Q. V . & Manning, C. D. ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Genera-\ntors. https:// arxiv. org/ abs/ 2003. 10555 (2020). https:// ui. adsabs. harva rd. edu/ abs/ 2020a rXiv2 00310 555C.\n 95. Baum, Z. J. et al. Artificial intelligence in chemistry: Current trends and future directions. J. Chem. Inf. Model 61, 3197–3212. \nhttps:// doi. org/ 10. 1021/ acs. jcim. 1c006 19 (2021).\n 96. Kirkpatrick, J. et al. Pushing the frontiers of density functionals by solving the fractional electron problem. Science 374, 1385–1389. \nhttps:// doi. org/ 10. 1126/ scien ce. abj65 11 (2021).\n 97. Flam-Shepherd, D., Zhu, K. & Aspuru-Guzik, A. Language models can learn complex molecular distributions. Nat. Commun. 13, \n3293. https:// doi. org/ 10. 1038/ s41467- 022- 30839-x (2022).\n 98. Li, Z. et al. Efficient FPGA Implementation of Softmax Function for DNN Applications. in 2018 12th IEEE International Conference \non Anti-counterfeiting, Security, and Identification (ASID). 212–216.\nAcknowledgements\nFinancial support for this project has been provided by the Department of Chemistry at Clemson University, \nthe South Carolina Department of Agriculture ACRE Competitive Grant Program, the Consejo Nacional de \nInvestigaciones Científicas y Técnicas (CONICET), the Fondo para la Investigación Científica y Tecnológica \n(FONCYT), and the Facultad de Ciencias Agrarias, Universidad Nacional de Cuyo (Mendoza, Argentina).\nAuthor contributions\nL.B.A.: Conceptualization, Formal analysis, Investigation, Writing—original draft. F .J.V .G.: Formal analysis, \nInvestigation, Writing—review & editing. M.F .S.: Writing—review & editing. J.R.L.: Writing—review & edit-\ning, Supervision. C.D.G.: Conceptualization, Methodology, Writing—original draft, Writing—review & editing, \nSupervision, Project administration, Funding acquisition.\nCompeting interests \nThe authors declare that they are bound by confidentiality agreements that prevent them from disclosing their \ncompeting interests in this work, which are not significant and have not influenced the outcomes of this research. \nParts of this report, including some described in this paper, are the subject of one or more patent disclosures \nmanaged by Clemson University Research Foundation.\nAdditional information\nSupplementary Information The online version contains supplementary material available at https:// doi. org/ \n10. 1038/ s41598- 022- 27106-w.\nCorrespondence and requests for materials should be addressed to C.D.G.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\nOpen Access  This article is licensed under a Creative Commons Attribution 4.0 International \nLicense, which permits use, sharing, adaptation, distribution and reproduction in any medium or \nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the \nCreative Commons licence, and indicate if changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the \nmaterial. If material is not included in the article’s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from \nthe copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\n© The Author(s) 2024",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6301067471504211
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5811039209365845
    },
    {
      "name": "Transformer",
      "score": 0.5692704916000366
    },
    {
      "name": "Artificial neural network",
      "score": 0.5291032195091248
    },
    {
      "name": "Eutectic system",
      "score": 0.4699955880641937
    },
    {
      "name": "Machine learning",
      "score": 0.4356878995895386
    },
    {
      "name": "Deep learning",
      "score": 0.4137054681777954
    },
    {
      "name": "Biochemical engineering",
      "score": 0.4042148292064667
    },
    {
      "name": "Chemistry",
      "score": 0.3301347494125366
    },
    {
      "name": "Organic chemistry",
      "score": 0.18713977932929993
    },
    {
      "name": "Engineering",
      "score": 0.11010682582855225
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Alloy",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I8078737",
      "name": "Clemson University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I151201029",
      "name": "Consejo Nacional de Investigaciones Científicas y Técnicas",
      "country": "AR"
    },
    {
      "id": "https://openalex.org/I4210147236",
      "name": "Instituto de Biología Agrícola de Mendoza",
      "country": "AR"
    },
    {
      "id": "https://openalex.org/I15881080",
      "name": "Universidad Nacional de Cuyo",
      "country": "AR"
    }
  ]
}