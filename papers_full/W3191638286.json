{
  "title": "VITALITY: Promoting Serendipitous Discovery of Academic Literature with Transformers &amp; Visual Analytics",
  "url": "https://openalex.org/W3191638286",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A4283973401",
      "name": "Narechania, Arpit",
      "affiliations": [
        "Atlanta Technical College",
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A4289056692",
      "name": "Karduni, Alireza",
      "affiliations": [
        "University of North Carolina at Charlotte"
      ]
    },
    {
      "id": "https://openalex.org/A4304936714",
      "name": "Wesslen, Ryan",
      "affiliations": [
        "University of North Carolina at Charlotte"
      ]
    },
    {
      "id": null,
      "name": "Wall, Emily",
      "affiliations": [
        "Emory University",
        "Northwestern University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3021799889",
    "https://openalex.org/W4254450265",
    "https://openalex.org/W2957959844",
    "https://openalex.org/W2967581294",
    "https://openalex.org/W2081280292",
    "https://openalex.org/W6629028937",
    "https://openalex.org/W2103484089",
    "https://openalex.org/W2969788738",
    "https://openalex.org/W1918833844",
    "https://openalex.org/W3032168557",
    "https://openalex.org/W6734897383",
    "https://openalex.org/W2159201721",
    "https://openalex.org/W2528997906",
    "https://openalex.org/W2292312835",
    "https://openalex.org/W2121854318",
    "https://openalex.org/W2751787250",
    "https://openalex.org/W4292157289",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W2300753645",
    "https://openalex.org/W2996667268",
    "https://openalex.org/W2318229606",
    "https://openalex.org/W6767394201",
    "https://openalex.org/W6757119458",
    "https://openalex.org/W1928454594",
    "https://openalex.org/W2894490168",
    "https://openalex.org/W6811326269",
    "https://openalex.org/W2081459780",
    "https://openalex.org/W2994650581",
    "https://openalex.org/W2283896450",
    "https://openalex.org/W1990995255",
    "https://openalex.org/W2051088039",
    "https://openalex.org/W2753907577",
    "https://openalex.org/W2602814102",
    "https://openalex.org/W2037133710",
    "https://openalex.org/W1992523994",
    "https://openalex.org/W2753137392",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W2962739339",
    "https://openalex.org/W2792416149",
    "https://openalex.org/W2085781384",
    "https://openalex.org/W2964523010",
    "https://openalex.org/W2338791867",
    "https://openalex.org/W2901188679",
    "https://openalex.org/W2970641574",
    "https://openalex.org/W4238591974",
    "https://openalex.org/W6757613135",
    "https://openalex.org/W4253081539",
    "https://openalex.org/W2166103069",
    "https://openalex.org/W4242646851",
    "https://openalex.org/W3035324702",
    "https://openalex.org/W2905265346",
    "https://openalex.org/W6755207826",
    "https://openalex.org/W2888349491",
    "https://openalex.org/W2513374982",
    "https://openalex.org/W6755049740",
    "https://openalex.org/W2159538290",
    "https://openalex.org/W6743384090",
    "https://openalex.org/W2970771982",
    "https://openalex.org/W2171892642",
    "https://openalex.org/W2493916176",
    "https://openalex.org/W3128980039",
    "https://openalex.org/W2753044861",
    "https://openalex.org/W2057718781",
    "https://openalex.org/W2791643790",
    "https://openalex.org/W4294215472",
    "https://openalex.org/W6902061466",
    "https://openalex.org/W6799522712",
    "https://openalex.org/W2801605877",
    "https://openalex.org/W2018915698",
    "https://openalex.org/W6636510571",
    "https://openalex.org/W6780303548",
    "https://openalex.org/W2950726992",
    "https://openalex.org/W2752172973",
    "https://openalex.org/W2906640975",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3191638286",
    "https://openalex.org/W2991792334",
    "https://openalex.org/W3144795237",
    "https://openalex.org/W3116869072",
    "https://openalex.org/W2906194767",
    "https://openalex.org/W4229690380",
    "https://openalex.org/W4226294211",
    "https://openalex.org/W4210490915",
    "https://openalex.org/W1974930421",
    "https://openalex.org/W2593864460",
    "https://openalex.org/W4299585995",
    "https://openalex.org/W2626778328",
    "https://openalex.org/W3083297930",
    "https://openalex.org/W4231720051",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2484578616",
    "https://openalex.org/W1614298861",
    "https://openalex.org/W2950577311",
    "https://openalex.org/W3124418332",
    "https://openalex.org/W3037620288",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4226182549",
    "https://openalex.org/W2043976122",
    "https://openalex.org/W2969860996",
    "https://openalex.org/W2894294331",
    "https://openalex.org/W158727920",
    "https://openalex.org/W3037961895",
    "https://openalex.org/W3116874729",
    "https://openalex.org/W2787560479",
    "https://openalex.org/W2604700393",
    "https://openalex.org/W2941610467",
    "https://openalex.org/W1579838312",
    "https://openalex.org/W4302400662"
  ],
  "abstract": "There are a few prominent practices for conducting reviews of academic literature, including searching for specific keywords on Google Scholar or checking citations from some initial seed paper(s). These approaches serve a critical purpose for academic literature reviews, yet there remain challenges in identifying relevant literature when similar work may utilize different terminology (e.g., mixed-initiative visual analytics papers may not use the same terminology as papers on model-steering, yet the two topics are relevant to one another). In this paper, we introduce a system, VitaLITy, intended to complement existing practices. In particular, VitaLITy promotes serendipitous discovery of relevant literature using transformer language models, allowing users to find semantically similar papers in a word embedding space given (1) a list of input paper(s) or (2) a working abstract. VitaLITy visualizes this document-level embedding space in an interactive 2-D scatterplot using dimension reduction. VitaLITy also summarizes meta information about the document corpus or search query, including keywords and co-authors, and allows users to save and export papers for use in a literature review. We present qualitative findings from an evaluation of VitaLITy, suggesting it can be a promising complementary technique for conducting academic literature reviews. Furthermore, we contribute data from 38 popular data visualization publication venues in VitaLITy, and we provide scrapers for the open-source community to continue to grow the list of supported venues.",
  "full_text": "© 2021 IEEE. This is the author’s version of the article that has been published in IEEE Transactions on Visualization and\nComputer Graphics. The ﬁnal version of this record is available at: 10.1109/TVCG.2021.3114820\nVITA LIT Y: Promoting Serendipitous Discovery of Academic\nLiterature with Transformers & Visual Analytics\nArpit Narechania, Alireza Karduni, Ryan Wesslen, and Emily Wall\nA\nB C D\n2\n3\n1\nE\nFig. 1. The VITA LIT Y User Interface. (A) Paper Collection View shows the entire corpus of publications, (B) Similarity Search View\nshows options to look-up publications that are similar to another list of publications or by a work-in-progress title and abstract, (C)\nVisualization Canvas shows an interactive 2-D UMAP projection of the embedding space of the entire paper collection, (D)Meta View\nshows summaries of certain attributes with respect to the Paper Collection View (A), (E) Opens a Saved Papers View from where the\nsaved papers can be exported as JSON. Within the Paper Collection View (A), (1) shows an overview with global UI controls (e.g.,\nﬁlters), (2) shows attribute-level UI ﬁlters (range sliders, multiselect dropdowns), and (3) shows an interactive table of all publications.\nAbstract—There are a few prominent practices for conducting reviews of academic literature, including searching for speciﬁc keywords\non Google Scholar or checking citations from some initial seed paper(s). These approaches serve a critical purpose for academic\nliterature reviews, yet there remain challenges in identifying relevant literature when similar work may utilize different terminology (e.g.,\nmixed-initiative visual analytics papers may not use the same terminology as papers on model-steering, yet the two topics are relevant\nto one another). In this paper, we introduce a system, VITA LIT Y, intended to complement existing practices. In particular, VITA LIT Y\npromotes serendipitous discovery of relevant literature using transformer language models, allowing users to ﬁnd semantically similar\npapers in a word embedding space given (1) a list of input paper(s) or (2) a working abstract. VITA LIT Y visualizes this document-level\nembedding space in an interactive 2-D scatterplot using dimension reduction. VITA LIT Y also summarizes meta information about\nthe document corpus or search query, including keywords and co-authors, and allows users to save and export papers for use in a\nliterature review. We present qualitative ﬁndings from an evaluation ofVITA LIT Y, suggesting it can be a promising complementary\ntechnique for conducting academic literature reviews. Furthermore, we contribute data from 38 popular data visualization publication\nvenues in VITA LIT Y, and we provide scrapers for the open-source community to continue to grow the list of supported venues.\nIndex Terms—transformers, word embeddings, literature review, web scraper, dataset, visual analytics\n1 I NTRODUCTION\n• Arpit Narechania is with Georgia Tech. E-mail:\narpitnarechania@gatech.edu.\n• Alireza Karduni and Ryan Wesslen are with UNC-Charlotte. E-mails:\n{akarduni, rwesslen}@uncc.edu.\n• Emily Wall is with Emory University. Email: emily.wall@emory.edu *work\nperformed while at Northwestern University.\nManuscript received xx xxx. 201x; accepted xx xxx. 201x. Date of Publication\nxx xxx. 201x; date of current version xx xxx. 201x. For information on\nVisualization research is inherently interdisciplinary, borne out of ﬁelds\nsuch as Computer Graphics and Human-Computer Interaction, with\nheavy inﬂuence from ﬁelds outside of computing such as Perceptual\nPsychology and Cognitive Science. Furthermore, visualization is ap-\nplied to explore data and support data-driven decision making problems\nin domains ranging from enterprise analytics to medicine. As a result\nobtaining reprints of this article, please send e-mail to: reprints@ieee.org.\nDigital Object Identiﬁer: xx.xxxx/TVCG.201x.xxxxxxx\n1\narXiv:2108.03366v3  [cs.HC]  30 Sep 2021\nof the multi-faceted nature of the ﬁeld, there may be parallel research\nefforts that can be difﬁcult to become aware of, even with a compre-\nhensive methodology for conducting literature reviews.\nOne challenge of interdisciplinary research is when different ﬁelds\nuse similar terminology to study different problems. For instance,trans-\nformer in electronics refers to a device that transfers energy between\ncircuits [40]; while in computing, transformer refers to a type of neural\nnetwork based on attention mechanisms, commonly applied to unstruc-\ntured text data [63]. As a result, keyword searches often yield irrelevant\nwork. Further, sifting through all hits from a keyword search may still\nmiss critical work. For instance, the recent wave of work on bias in\nvisualization (e.g., [11, 17, 18, 47, 62, 66–68]) seldom mentions uncer-\ntainty (e.g., [32, 34]). Yet, as the seminal work on bias in Cognitive\nScience points out, bias emerges when people make decisions under\nuncertainty [61]; hence, there is a critical need to examine uncertainty\nliterature that may fundamentally address similar problems using dif-\nferent terminology. As a result, conducting a simple keyword search\nfor “bias” (i.e., matching tokens in a paper title or abstract) to identify\nrelevant work may neglect pockets of inﬂuential research. However,\nthese challenges are not unique to data visualization research or even\ncomputing. They extend to virtually all interdisciplinary research.\nCurrent prevalent practices for conducting literature reviews tend\nto utilize two common search strategies: (1) keyword search and (2)\nexamination of back-references from a snowballing set of seed papers,\nusually through searching Google Scholar or DBLP. These approaches\ncan successfully identify a large number of relevant citations, but can\nsuffer from at least two key limitations: thoroughness and efﬁciency.\nThat is, they may fail to unearth related papers that use different termi-\nnology, and they require signiﬁcant manual effort to gauge relevancy\nof potentially thousands of hits. In other words, a prominent challenge,\nthen, in conducting literature reviews or surveys is to effectively iden-\ntify research of signiﬁcance to a given topic based on similarity of\ntopics, irrespective of matching exact keywords.\nTo address these challenges, we introduce VITA LIT Y, an open-\nsource visualization system designed to support a ﬂexible exploration\nof research articles. Inspired by work on insight in visualization (i.e.,\n“eureka” or “aha” moments [9]), we similarly aim to supportserendipity\nwith VITA LIT Y, operationally intended to describe the goal that users\nmay “stumble upon” relevant literature, when other search approaches\nmight otherwise fail. VITA LIT Y incorporates SPECTER [14], a state-\nof-the-art document-level contextual embedding model for scientiﬁc\ndocument recommendation. Unlike many pre-trained language models\nthat use a general corpus like Wikipedia or the Common Crawl [16, 44,\n50], SPECTER was pre-trained on academic literature (sciBERT [6])\nand ﬁne-tuned with citations which provides out-of-the-box state-of-\nthe-art performance for academic literature recommendations and topic\nclassiﬁcation.\nIn summary, this work presents the following contributions:\n1. results of a formative interview study in which visualization re-\nsearchers identiﬁed key challenges in current literature review\npractices (Section 3),\n2. a dataset of scraped metadata from 59,232 academic articles\n(https://figshare.com/articles/dataset/VitaLITy_\nA_Dataset_of_Academic_Articles/14329151 [48], CC0\nLicense), including paper titles, keywords, and abstracts from 38\npopular venues for visualization research (Section 4.1),\n3. an open-source tool, VITA LIT Y (http://vitality-vis.\ngithub.io, MIT License), for supporting discovery of relevant\narticles while conducting literature reviews (Section 4.2),\n4. usage scenarios describing potential workﬂows in which VITA L-\nITY might be used in different ways to support serendipitous\ndiscovery of relevant academic literature (Section 5), and\n5. results of a summative evaluation of VITA LIT Y (Section 6).\n2 R ELATED WORK\n2.1 Literature Review Methodologies\nLiterature reviews and surveys are an essential part of scientiﬁc disci-\nplines. They are broadly deﬁned as systematic ways of collecting and\nsynthesizing research on a speciﬁc topic [4, 56]. There are a variety of\ndifferent guidelines and methodologies, such as systematic reviews [45],\nnarrative reviews [4], and integrative reviews [60]. These guidelines\nand methods mostly vary in how they organize, synthesize, and analyze\na set of selected articles through a combination of quantitative and\nqualitative methods [56]. These methodologies often include multiple\nstages, the ﬁrst of which is related to identifying a strategy for searching\nand selecting a set of related literature. For example, Hannah Snyder\nstates that “a search strategy for identifying relevant literature must\nbe developed. This includes selecting search terms and appropriate\ndatabases and deciding on inclusion and exclusion criteria. Here, a\nnumber of important decisions must be made that are crucial and will\neventually determine the quality and rigor of the review” [56].\nSimilarly, within the visualization community, deﬁning search strate-\ngies and keywords are described as the primary step for conducting\nliterature reviews [43]. Many visualization survey papers include ex-\nplicit excerpts about their selection criteria that describe keywords,\ndatabases, and the search process of each survey paper [27, 54, 59]. For\nexample, in their survey of glyph visualization techniques, Fusch et\nal. employ a “snow ball” sampling technique in which they start by\nsearching the keyword “glyph” within various libraries, select all the\nﬁndings, ﬁlter based on their exclusion criteria, and then look at the\nrelated work of the selected papers to ﬁnd more papers [27].\nAlthough keyword search is the most prevalent method for searching\nliterature, it comes with some limitations:\n• Often it won’t yield papers that do not include a speciﬁc keyword\nbut might be very related to the topic at hand.\n• Within different communities, different keywords are used to\nrepresent a common concept.\nAs a result, selecting sufﬁciently broad yet relevant keywords\ncan be a challenge. VITA LIT Y offers a visual system that comple-\nments traditional keyword search-based methods to enhance literature\nsearches.VITA LIT Y implements a state-of-the-art transformer-based\ndocument similarity search that can ﬁnd semantically similar docu-\nments that may not always share the same set of keywords.\n2.2 Visualization of Academic Articles\nVisual analytics research has been effective in incorporating many\nmachine learning and natural language processing models (e.g., topic\nmodeling or word embeddings) into vis systems for exploratory analy-\nsis of large corpora of text documents [20–22, 42]. A common task is\nidentifying similar documents [24]. Early visualization papers on doc-\nument similarities used representations of a corpus’ similarity matrix\nthrough dot plots [13] or histograms [26]. More recent vis systems have\nconsidered more author assigned keyword-based approaches like con-\nstructive text similarity [1] and GlassViz [7]. Alternative approaches\nhave considered word embeddings including for iterative lexicon con-\nstruction [49] that provide related ability to query documents.\nOne key application area for incorporating visual techniques to help\nusers ﬁnd similar and relevant documents is in searches for academic\narticles. Several prominent article databases have implemented such\nsystems to ﬁnd relevant articles. Text Analyzer by JSTOR extracts the\nmost important topics and keywords from entered papers and recom-\nmends other relevant documents to users (https://www.jstor.org/\nanalyze/). Pubmed uses a word-based technique to help users retrieve\nthe most similar papers ( https://pubmed.ncbi.nlm.nih.gov/\nhelp/#pubmedhelp.Computation_of_Weighted_Relev). Open\nKnowledge graph uses similarity scores provided by Pubmed and\ndevelops a circle packing visualization to help users understand\ngroups of related research relevant to their search terms ( https:\n//openknowledgemaps.org/).\nWithin the visualization community, several works highlight the\nimportance of understanding and visualizing academic literature. Felix\net al., introduce a design space and highlight how different keyword\nsummarization techniques might impact users’ understanding of related\nliterature [25]. Using the open source vis literature dataset (VisPub-\nData), Isenberg et al. introduce KeyVis and analyze keywords utilized\nin the visualization community [35, 36]. Others introduce relevant\nsystems for supporting dissemination of curated survey results [5], vi-\nsualization of lead-lag analysis of text corpora [41], analysis of the\n2\n© 2021 IEEE. This is the author’s version of the article that has been published in IEEE Transactions on Visualization and\nComputer Graphics. The ﬁnal version of this record is available at: 10.1109/TVCG.2021.3114820\ncontextual reasons for citations [73], and an emergent design space\nfor considering visualizations of literature collections [31]. In general,\nwithin visualization systems on academic literature we can observe\nthree themes: (1) visualization systems that focus on citation networks\n(e.g., [12, 15, 29, 72]), systems that focus on clustering or similarity\n(typically by matching keywords, e.g., [70], or using topic modeling,\ne.g., [2, 36]), and (3) systems that focus on both citation networks and\nsimilarity measures (e.g., [10, 46]). In the latter category, CiteSpace II\nintroduces a technique to computationally deﬁne co-citation clusters.\nInspired by these works, our paper introduces (1) a more comprehen-\nsive public dataset of visualization literature, and (2) utilizes state-of-\nthe-art document embedding techniques using transformers to enable\nserendipitous discovery of articles.\n2.3 Word Embeddings and Transformers\nDocument similarity is a classic problem in natural language processing\nand information retrieval [38]. Word embeddings provide an approach\nin which words (or documents) that have similar meanings have similar\n(vector) representations. Recent advances in word embeddings have\nyielded signiﬁcant improvements in standard similarity benchmarks\nlike STS or SentEval [3, 14, 52]. Beginning with word2vec [44], many\nextensions of learned dense representations of word vectors have fol-\nlowed including GloVe [50], fasttext [8], skipthought [39], ELMo [51],\nand BERT [16]. More recently, specialized transformer models like\nSPECTER [14] have been developed to specialize in domains like aca-\ndemic literature. SPECTER combines self-supervised pre-training on\ntransformer architectures (e.g., BERT-like) on academic abstracts and\nis “citation-informed” to enhance performance for tasks like academic\nliterature recommendation and topic classiﬁcation.\nSPECTER provides four advantages over past word embedding\napproaches for VITA LIT Y’s task. First, it incorporates contextual em-\nbeddings (via BERT/transformer architecture) that enable different\nvector representations depending on the context (e.g., “bias” in differ-\nent contexts). Second, the model was pre-trained on academic titles\nand abstracts (sciBERT [6]). This enables the model to have transfer\nlearning gains from pre-training with a BERT-like [16] transformer\narchitecture but with specialization for academic literature recommen-\ndation. Third, it incorporates a triplet-loss pre-training objective that\nenables it to use citations as an inter-document incidental supervision\nsignal for ﬁne-tuning. By incorporating both text pre-training with\ncitation ﬁne-tuning, the model achieved state-of-the-art performance\nfor academic literature recommendations as well as six additional tasks\nlike citation prediction, user activity (view or read), and topic classiﬁ-\ncation. Tasks like citation prediction or user activity were out of scope\nof VITA LIT Y’s design due to data limitations, but future work could\neasily incorporate such tasks with additional citation or activity data.\nFourth, the model is available out-of-the-box without ﬁne-tuning as\nwell as in model deployment through a publicly released API. This API\nenables fast and efﬁcient real time scoring in VITA LIT Y.\n3 F ORMATIVE STUDY\nWe conducted a formative study to better understand the needs of\nresearchers as they perform literature reviews. Participants were 4\nComputer Science PhD students (3 female, 1 male; avg. 2.75 yrs. into\nPhD program) who had prior experience conducting literature reviews\nin the ﬁeld of visualization. Sessions lasted approximately 45 minutes.\nParticipation was voluntary with no compensation.\nWe presented the ﬁrst two participants with an initial version of the\nliterature review tool. After incorporating feedback in the next iteration\nof the system, we worked with the next two participants using the\nupdated system. Finally, we incorporated feedback from all formative\nstudy participants in VITA LIT Y, presented in the next section.\n3.1 Current Workﬂow\nAfter obtaining informed consent, we asked participants to describe\ntheir typical workﬂow for conducting literature reviews via a semi-\nstructured interview. Participants expressed some haphazard nature to\nthe beginning of their processes, e.g., “someone tells [them] about a\npaper, and [they] look up the citations and branch out from there”(P1)\nor “use a starting point from an advisor” (P2). From there, there are\nsome commonalities in processes.\nParticipants all utilized keyword searches on Google Scholar (P1-4).\nAs a fairly comprehensive database, participants did not worry whether\na venue or paper would be present, and they appreciated the “cited by”\nfeature to identify more recent relevant papers. However, participants\nalso expressed that keyword searches on Google Scholar result in many\nirrelevant papers that require a lot of manual ﬁltering for relevance.\nFor instance, P4 viewed Google Scholar as a last resort, expressing\nthey really only use it “if [they] don’t have a better starting point seed\npaper. ”Echoing some of the motivation for this work, P1 indicated, “if\na keyword is used differently in different ﬁelds, [they] have to read a lot\nof abstracts to determine whether it’s relevant or not. ”\nWhile Google Scholar seems to be the default search tool, there are\nothers that participants integrate in various parts of their workﬂow when\nconducting literature reviews. For instance, P4 indicated regular use\nof bibliography management tools like Mendeley and Zotero. Among\nour relatively small sample in this formative study, participants did not\nmention some other elements in their workﬂow that we anticipated,\ne.g., DBLP, manual scripting / web scraping, etc.\n3.2 Preliminary Feedback\nNext, participants used a preliminary version of our literature review\ntool. The preliminary tool included 17,926 papers from the follow-\ning venues over the past 39 years (1982-2020): {CGA, CGF , EuroVis,\nGraphics Interface, Information Visualization, Interact, Journal of Vi-\nsualization, PaciﬁcVis, SciVis, TVCG, VAST, VIS} and supported two\nmain mechanisms for searching the corpus: keyword search and simi-\nlarity search (described in greater detail in the next section). After using\nthe tool, we asked participants for additional feedback about the current\nimplementation, possible improvements, and any new capabilities that\nthey could envision to better support their literature review process.\nParticipants appreciated the ability to start their search with a seed\npaper or papers (P1 said they got “pages and pages of results which is\nwhat [they] would get on Google Scholar, but these are actually more\nrelevant”). P2 searched based on the seminal paper on hypothetical\noutcome plots (HOPs) [34] and observed “it pulled up lots of uncer-\ntainty vis papers, which were not in the title – cool!” but expressed that\nthere was still a lot of noise when searching by keywords.\nParticipants suggested several new features: being able to visualize\nconnections between papers (e.g., by citations, co-authors, etc. - P1),\nadding critical information on citation count as a mechanism for deter-\nmining importance of a paper (P1), making the overview interactive\n(with brushing and linking, summarizing dynamic regions, etc. - P2),\nand being able to type in a custom abstract or paper idea as the basis of\nthe similarity search (e.g., to identify relevant literature for a paper idea\nthat hasn’t been fully ﬂeshed out yet - P2). Participants also steered\naway from one of the features in the tool: the word cloud. P4 indicated\n“it wasn’t clear how it was related to what [they] had selected. ”\nOverall, participants indicated that a tool like this in their workﬂow\ncould supplement tools like Google Scholar for serendipitous explo-\nration. P4 suggested it would be beneﬁcial in the early “discovery”\nphases of literature review, with the caveat that the data on included\nvenues needed to be sufﬁciently comprehensive. As a result of this feed-\nback, we updated the system to address these ideas, including scraping\ndata from additional venues, adding citation counts, adding brushing\nand linking between views, and searching by a custom abstract. We did\nnot add features based on citation networks in our system; instead, we\nfocused on leveraging transformer models to serve as a complementary\nliterature search technique to existing tools that address these needs.\n3.3 Design Goals\nCollectively, these interviews led us to the following set of four design\ngoals for our literature review system.\nDG 1. Serendipity: Enable serendipitous identiﬁcation of semantically\nrelated articles that do not necessarily have shared keywords through\nvisual exploration.\nDG 2. Familiarity: Facilitate a familiar search functionality to what\nusers are currently accustomed to, such as keyword and author search.\n3\nDG 3. Novelty: Afford users to ﬁnd semantically related articles by\nsearching based on the author’s own ideas in the form of unpublished\nsentences / abstract.\nDG 4. Overview: Enable users to interact with a visual overview of a\ngroup of papers.\n4 VITA LIT Y\nWe present VITA LIT Y, a system designed to complement existing tool-\ning for conducting academic literature reviews by supporting serendipi-\ntous discovery of relevant literature.\n4.1 Data\nFigure 2 outlines the pipeline for curating the paper corpus.\n1. Filter: We conducted an open-ended crowd-sourced survey on\nTwitter asking visualization researchers about venues (e.g., journals,\nconferences, workshops) where they publish. We received responses\nfrom 24 users (current roles: 17 Ph.D. students, 4 Faculty, 2 Industry\nresearchers, and 1 Postdoctoral scholar; self-reported visualization\nliteracy out of 5: µ=4, σ=1.142, median=4). We supplemented the\nlist with six additional venues based on our own knowledge that were\nnot captured in the survey. Figure 3 outlines the ﬁnal list of 38 venues\nwithin our corpus. Next, we downloaded the November 2020 release 1\nof DBLP [58] and ﬁltered it for the aforementioned 38 venues. From\nthe resultant subset, we chose theTitle, Authors, Source (venue), Year\n(published), and URL attributes and added a unique ID for tracking.\nNote that the VITA LIT Y dataset and hence the UI show more than\n38 venues because DBLP (a) utilizes multiple descriptors to represent\ndifferent tracks at the same venue (e.g., Eurographics (Area Papers),\nEurographics (State of the Art Papers), Eurographics (Short Papers),\netc.) and (b) splits some venues across different versions (e.g., Interact,\nInteract (1), Interact (2), etc.).\n2. Scrape: The DBLP dataset does not include abstracts, keywords,\nand number of citations for papers. Thus, we developed a scraper\nmodule that, given a list of publication URLs, scrapes the corresponding\npublisher’s webpage (e.g., IEEE Xplore, ACM Digital Library) and\nextracts the Abstract, Keywords, and CitationCounts from it.\n3. Clean: We performed data cleaning and transformation operations.\nTo aid search, we encoded all text attributes to ASCII and converted\nAuthors and Keywords into a JSON array from a comma separated list.\nWe de-duplicated Keywords by matching their lowercase forms; we\ncombined similar keywords (e.g., HCI & Human-Computer Interaction,\nVisualization & Visualisation) through manual inspection. We dropped\n1497 papers with null {Title, Authors, Abstract} values, and very\nshort or very long Title (<5, >250 characters) and Abstract (<50,\n>2500 characters) to create effective word embeddings. We retained\nDBLP’s strategy in disambiguating author names (e.g.,J. Thompson\nand J. Thompson 001 ). At the end of this step, the dataset has 8\nattributes (columns) and 59,232 papers (rows).\n4. Embed: We next curated a dataframe of Title, Abstract, Au-\nthors, Source, Year, and Keywords and created the GloVe [50] and\nSpecter [14] document embeddings. To create the document embed-\ndings for GloVe, we used TF-IDF weightings (instead of mean vectors)\nand SIF weightings that have been shown to remove noise through\nPCA reduction [3]. We used the public API to create the Specter em-\nbeddings [14]. With these document embeddings, we used UMAP\nto construct 2-D document representations used in the Visualization\nCanvas (see Figure 4).\n5. Export: We export the consolidated dataset as JSON and a Mon-\ngoDB dump for different open-source use.\n6. Serve: We also developed a server that exposes a RESTful API to (a)\nload the VITA LIT Y document corpus, (b) perform similarity search by\na list of seed papers as input, (c) perform similarity search by a working\ntitle and abstract as input, and (d) download metadata of (saved) papers\nas a JSON array. The similarity search by seed papers (b) supports\nquerying by 2-D UMAP as well as n-D document embeddings for both\nGloVe and Specter. We used MongoDB to maintain the 2-D indexes\nand Facebook Research’s faiss library [37] to maintain the n-D indexes.\n1https://dblp.org/xml/release/dblp-2020-11-01.xml.gz\nFor one seed paper as input, we utilize existing APIs to compute the\nEuclidean (2-D; MongoDB) and L2 (n-D; Faiss) distances between the\ninput paper and other papers, compute their reciprocals, and normalize\nthem between 0-1 for use as the similarity scores (1 = most similar).\nFor more than one seed paper as input, we ﬁrst compute the average\nvector from all input papers and then follow the same procedure as\nabove to compute the similarity scores. The VITA LIT Y UI interfaces\nwith this server, described next.\n4.2 System Overview\nThe system, shown in Figure 1, is comprised of a Paper Collection\nView (A), Similarity Search View(B), Visualization Canvas (C), Meta\nView (D), and Saved Papers View(E), described in turn below.\nPaper Collection View shows the entire corpus of papers in an inter-\nactive tabular layout. (1) shows an overview (number of visible papers)\nand UI controls to perform a global search (/search), show hidden columns\n([Column +]), add all papers to the input list of papers in the Similarity\nSearch table ([/plus_signAll]), and save all papers to the “cart” in the Saved\nPapers View([/saveAll]). (2) shows the attributes along with UI controls\nto ﬁlter (range sliders for Quantitative attributes, multiselect dropdowns\nfor Nominal attributes), hide a column ( /eye_close), and deﬁne a column on\nhover (/question_sign). (3) shows an interactive table of all papers with options to\nsee detail (/info_sign), locate in the UMAP (/map_marker), add to the input list of papers\nfor similarity search (/plus_sign), and save to the “cart” (/save). Search and ﬁlter\ncapabilities are designed to be an intuitive entry-point into the dataset\nof academic articles (DG 2).\nSimilarity Search View shows options to ﬁnd papers similar to (a)\none or more input papers (Figure 6, DG 1) or (b) a work-in-progress\ntitle and abstract (Figure 7, DG 3). VITA LIT Y supports setting the\ndimensions (2-Dimensional, n-Dimensional), number of similar papers\nto return, and the word embedding approach (e.g., Specter) to compute\nsimilarity.\nVisualization Canvas shows a 2-D UMAP projection of the embed-\nding space of the entire paper collection (Figure 4, DG 4): hovering\non a point highlights it, shows the corresponding title in a ﬁxed tooltip\nbelow, and automatically scrolls the collection (table) to bring the corre-\nsponding paper (row) into the viewport; clicking on a point (de)selects\nit and shows it in the tooltip below with additional options to /info_sign, /plus_sign,\n/save; clicking on /removedeselects all selected points; pressing Shift enables\nlasso-mode to select multiple points using a free-form lasso operation;\nzooming and panning support helps navigate the UMAP to speciﬁc\nregions; clicking on /dot_circle_altre-centers and ﬁts the UMAP in the viewport.\nBy default, each point in the UMAP is colored based on the state of the\ncorresponding paper (“Default”): Unﬁltered (unﬁltered and visible in\nthe main paper collection table; dark-grey), Filtered (ﬁltered out and\nnot visible in the paper collection table; light-grey), Similarity Input\n(added to the By Papers section in the Similarity Search View; pink),\nSimilarity Output (in the Output Similar table; orange), and Saved\n(added to the Saved Papers table; red). Other options to color include\nSource, Year, CitationCounts, and Similarity Score.\nMeta View shows aggregated summaries of Keywords, Authors,\nSource, Year with respect to the Paper Collection View(A). Figure 5\nshows how a ﬁlter in the main table (Authors=John T. Stasko) updates\nthe Meta Views with the distribution of keywords (a) associated with\ntheir research, their co-authors (b), venues where they have published\n(c), and in which years (d).\nSaved Papers View shows a table with the papers added to the “cart”\nwith an additional option to export them as a JSON (Figure 6d).\n4.3 Implementation\nThe ﬁlter, scrape, clean, embed, export, and serve modules are all\nimplemented in Python. The UI is developed in React and uses the\nregl-based WebGL library2 to render the UMAP. MongoDB provides\nthe document corpus to the UI and maintains the 2-D indexes while\nfaiss [37] maintains the n-D indexes for efﬁcient similarity search.\n2https://github.com/ﬂekschas/regl-scatterplot\n4\n© 2021 IEEE. This is the author’s version of the article that has been published in IEEE Transactions on Visualization and\nComputer Graphics. The ﬁnal version of this record is available at: 10.1109/TVCG.2021.3114820\nfilter\nZ\nembed servescrape\nID Title Authors Source Year URL Abstract Keywords CitationCounts GloVe_2D GloVe_nD Specter_2D Specter_nD\n1 Warning, \nBias May…\n[E. Wall, L. \nBlaha, …]\nVAST 2017 doi.org/10.\n1…\nVisual analytic \ntools combine...\n[Human Biases, …] 11 [300, 140] [291, 529, …] [290, 291] [110, 702, …]\nACM Digital Library\nIEEE Xplore\n…\nSpecter API\nGloVe Batch\n…\nDBLP\naugment \nmetadata, e.g., \nAbstract\nchoose popular \nVIS venues, \ne.g., CHI\nCreate document \nembeddings, e.g.\nSpecter\nexport data, \ne.g., JSON\nexpose a RESTful \nAPI, e.g., for \nsimilarity search\ninteractive UI\n59,232 papers38 venues 47 years 82,391 authors\nclean\nprocess text, e.g., \nde-duplicate \nkeywords\n21 3 4 export\n5 6\nFig. 2. The VITA LIT Y architecture. (1) DBLP data is ﬁltered by relevant venues. (2) Author and title metadata from DBLP is augmented with abstracts,\nkeywords, and citations from custom scrapers. (3) Data is cleaned (e.g., to resolve duplicate keywords, etc). (4) GloVe and Specter document\nembeddings are created. (5) Data is exported to a variety of formats for subsequent open-source use. (6) The server exposes a RESTful API that\ncan ultimately be called upon in rendering the interactive system.\nCHI (24) TVCG (22) VIS (18) EuroVis (18) PacificVis (10) IUI (6)\nAVI (6) SIGGRAPH (6) CGF (6) CSCW (3) DIS (2) CGA (2)\nUIST (2) VAST (2) BELIV (2) BioVis (2) ICDM (1)IVAPP (1)\nSIGGRAPH Asia (1)Graphics Interface (1) Interact (1)Diagrams (1)\nSIBGRAPI (1) UbiComp (1)Information Vis. (1) Supercomputing (1)\nKDD (1)\nVMV (1)\nVCBM (1)Pacific Graphics (1)\nDagstuhl (1)\nCognitive Biases in Vis.*\nDHQ (1) Distill (1)\nCognitive Science*\nSIGMOD* BCS HCI*Journal of Vis.*\nTOCHI*\nThe Visual Computer (1)\nIntelligent Vehicles (1)\nFig. 3. Results from a Twitter survey with 24 users on venues where VIS\nresearchers publish; (numbers in parentheses) are aggregated counts of\nthe 24 responses; struckthrough venues were not in DBLP and hence\ncurrently not available inVITA LIT Y; * venues were added as also-relevant\nvenues by the authors after the survey; “Vis.” is short for Visualization.\nFig. 4. Interactive 2-D scatterplot of the UMAP projection.\n5 U SAGE SCENARIOS\nA common thread among the authors’ prior research deals withhuman\nbias in data visualization, and in particular, the authors have focused\non deﬁning [67], detecting [11, 64 –66], and mitigating [47, 68, 69]\ncognitive biases. Thus, we ﬁnd it ﬁtting to demonstrate the usage\nof VITA LIT Y through a series of usage scenarios in the context of a\nliterature review on bias in visualization.\n5.1 Usage Scenario 1: Identifying Missing Papers\nMaya is a data visualization PhD student working on their dissertation\non the topic of “Mitigating Bias in Data Visualization.” They are\nwrapping up the related work and preparing to submit their thesis.\nBefore submitting, Maya wants to check for potential gaps in the\nliterature review and ensure there is no critical missing work. Maya\ndecides to use VITA LIT Y to explore the visualization literature.\nMaya wants to be systematic about their search. They begin by\ntaking some of the key papers related to bias in visualization, including\nthe following [11, 17–19, 28, 66, 69, 71]. Maya has already examined\nthe papers cited from these works and written about the relevant ones\nin their dissertation. They locate these key papers in VITA LIT Y and\n“select” them [add them as input to Similarity Search] (Figure 6a), then\nmap them in the Visualization (Figure 6b).\nStarting with N-Dimensional Specter embedding, Maya searches for\nsimilar papers (Figure 6c). The ﬁrst result, “A Formative Study of In-\nteractive Bias Metrics in Visual Analytics Using Anchoring Bias” [65]\n(similarity score 0.4355), is cited in one of the papers [69] so Maya was\nalready aware. Scanning down the list, the fourth result is “CogTool-\nExplorer: A Model of Goal-Directed User Exploration That Considers\nInformation Layout” [57], a paper Maya is not aware of. Published at\nCHI in 2012, this paper describes a method for modeling and predicting\nuser interactive behavior. Intrigued by the relevance of precursory work\nin HCI to predict interactive behavior [57] to work on modeling user\nbias [66], Maya saves this paper to the “cart”.\nContinuing to examine the list of output papers, the next result also\nproves relevant with a similarity score of 0.2593: a BELIV paper\ntitled “Just the Other Side of the Coin? From Error to Insight Anal-\nysis” [55] which models errors and insights in cognitive processing.\nSeveral others also catch Maya’s eye relevant to the design of bias mit-\nigation strategies, including research about introducing visualization\n“difﬁculties” in design to aid comprehension and recall [33] and even\nuse of so-called “transparent deception” in visualization if and when it\nis aligned with certain user goals [53]. Maya saves these papers and\n5\na b c d\nFig. 5. The Meta View showing aggregated summaries of (a) Keywords, (b) Co-authors, (c) Source, and (d) Year associated with John T. Stasko.\nexports them for further review (Figure 6d).\nFurthermore, Maya notices a particularly relevant paper, “Priming\nand Anchoring Effects in Visualization” [62], which they forgot about,\nso adds it to the input similarity search and re-computes the output.\nThey ﬁnd “Pushing the (Visual) Narrative: the Effects of Prior Knowl-\nedge Elicitation in Provocative Topics” [30], discussing persuasive\nvisualization designs, which again Maya ﬁnds relevant for designing\nbias mitigation interventions. Maya continues iterating on their ex-\nploration of the literature, augmenting their dissertation related work\nsection and ﬁlling in gaps, especially from the CHI community.\n5.2 Usage Scenario 2: Analysis of Keyword Quality\nKatherine is a visualization researcher who focuses on topics related to\nbias and decision making. She has primarily relied on keyword searches\nsupported by IEEE Xplore, ACM Digital Library, etc. for identifying\nrelevant literature in the past. Beginning with a set of known papers\nabout bias in visualization (i.e., the same set from the previous sce-\nnario [11,17–19,28,66,69,71]), she identiﬁes several relevant keywords,\nincluding human biases, bias mitigation, bias mitigation strategies, bias\nalleviation, debiasing, cognition, cognitive bias, cognitive biases, cog-\nnitive heuristics, heuristics, decision making, decision-making, human\ndecision-making, sensemaking capabilities, uncertainty, anchoring\nbias, and attraction effect. She disregards several others that she be-\nlieves are too broad, e.g., visualization, information visualization, data\nvisualization, human-centered computing, visual analytics, etc. She\nnotes the multiplicity of some keywords deﬁned by authors.\nKatherine conducts a similarity search usingVITA LIT Y (yielding the\nsame output as the previous scenario for Maya’s literature review). She\nnotes a number of papers that she would have been unable to identify\ngiven only these keyword searches. For instance, “Designing Informa-\ntion for Remediating Cognitive Biases in Decision-Making” [74] con-\ntains keywordsHuman Computer Interaction (hci)and Human-centered\nComputing and would have been missed by targeted bias-related key-\nwords and likely lost among a sea of other papers by searching for more\ngeneric HCI keywords. Similarly, “A Lie Reveals the Truth: Quasi-\nmodes for Task-Aligned Data Presentation” [53] contains very broad\nkeywords, including Visualization, Empirical Studies In Visualization,\nand Human-centered Computing. Other papers not directly related to\nbias, but still relevant, are even less likely to contain keyword matches.\nFor instance, “Observation-Level Interaction with Statistical Models\nfor Visual Analytics” [23] describes data- or “observation”-level inter-\nactions users perform with data based on perceived relationships and\ninterests in the data, a topic of precursory relevance to bias research\nin data visualization. However, it contains keywords with no overlap\nto the bias-related search terms: Principal Component Analysis, Data\nModels, Data Visualization, Visual Analytics, Analytical Models, and\nLayout.\nNotably, Katherine observes that some venues expose only index\nterms from e.g., IEEE or ACM, while others also expose author-deﬁned\nkeywords. This provides different levels of granularity in the ability to\nsearch for literature by keyword. Hence, Katherine ﬁnds that alternative\napproaches based on document-level embeddings can be a fruitful\nway to identify literature when keyword searches prove insufﬁcient or\ninconsistent across venues.\n5.3 Usage Scenario 3: Beginning a New Project\nIn this scenario, we showcase how VITA LIT Y facilitated our own liter-\nature review for the present work. After using traditional approaches\nbased on keyword searches or citations from known papers, we found\nVITA LIT Y helped us identify a plethora of additional literature we\nwere previously unaware of. We used the Similarity Search by Abstract\nfeature of VITA LIT Y with our paper title and abstract (Figure 7a).\nThe ﬁrst returned result is a 2011 Computer Graphics Forum paper\ntitled “PaperVis: Literature Review Made Easy” [12] that utilizes a\nnode-link visualization approach to support literature review and creates\na topic hierarchy based on semantically meaningful topics (Figure 7b).\nThe next paper similarly focuses on creating iterative citation networks\nto facilitate creation and sharing of bibliographies [15]. In general, after\nsearching the output, a few themes emerge: (1) visualization systems\nthat focus on citation networks (e.g., [29, 72]), systems that focus on\nclustering or similarity (typically by matching keywords, e.g., [70], or\nusing topic modeling, e.g., [2]), and (3) systems that focus on both\ncitation networks and similarity measures (e.g., [46]). Other notable\ntopics also surfaced, including a design space [25] and analyses of\nkeywords utilized in the visualization community [36], a system for\nsupporting dissemination of curated survey results [5], analysis of the\ncontextual reasons for citations [73], and an emergent design space for\nconsidering visualizations of literature collections [31].\nReﬂecting on these ﬁndings, we believe traditional methods for\nsearching literature left many gaps in our literature review for two\nprimary reasons: (1) many of these works are distributed across several\npublication venues (e.g., IV , PaciﬁcVis, Interact, V AST, TVCG), and\n(2) many of these papers received relatively little traction since their\noriginal publication 5-10 years ago.\n5.4 Usage Scenario 4: Getting to Know VIS\nRosa is a new PhD student joining a lab that conducts research in data\nvisualization. To become acquainted with the ﬁeld, her advisor suggests\nthat Rosa browse through some of the prominent literature in VITA L-\nITY. Upon loading the system, Rosa observes that it contains 59,232\npapers in the Paper Collection View. Inspecting the Meta View, she\nobserves those papers are described by 49,278 keywords, written by\n82,391 authors from 55 different venues, across 47 years. Among the\ntop keywords are Human-centered Computing and Human Computer\nInteraction (hci), describing 13,833 and 8,365 papers respectively.\nThe lineage of data visualization becomes apparent to Rosa when she\nnotices that the ﬁfth most common keyword is Computer Graphics,\nfollowed by Data Visualization. Other common keywords that catch\nRosa’s eye describe topics such as Machine Learning, Information\n6\n© 2021 IEEE. This is the author’s version of the article that has been published in IEEE Transactions on Visualization and\nComputer Graphics. The ﬁnal version of this record is available at: 10.1109/TVCG.2021.3114820\nRetrieval, Artiﬁcial Intelligence, Interaction Design, and Animation,\namong others.\nRosa enters Data Visualization as a ﬁlter in the Keywords column\nof the Paper Collection View, then ﬁlters to show only papers in the\npast 10 years to focus on the 2,032 most relevant recent works in the\nﬁeld. Interestingly, these papers appear in a fairly dense area near the\ncenter of the Visualization. In the Meta View, she notes a few authors\nwhose names she recognizes, including Kwan-liu Ma who authored 58\nof the papers with the keyword Data Visualization since 2010. She also\nnotices Daniel Keim, John T. Stasko, Niklas Elmqvist, and Hanspeter\nPﬁster, among others. She next ﬁlters the Paper Collection View to\nsee only John T. Stasko’s papers ( 80) and removes the other ﬁlters\n(Figure 5a-d). The Meta View reveals that his work is associated\nwith the following keywords: data visualization, visualization, human-\ncenter computing, visual analytics, human computer interaction (hci)\n(a). Some of his common co-authors include Zhicheng Liu, Carsten\nGorg, and Youn Ah Kang (b). He publishes primarily at TVCG (21) and\nV AST (15) (c), with 2007 his most productive year (11 publications)\nfollowed by 2008 (10 publications) then 2011, 2012, and 2014 each\nwith 6 publications (d).\n6 E VALUATION\nBased on the ﬁnal form of VITA LIT Y, developed from formative feed-\nback with visualization researchers, we next describe the summative\nevaluation of VITA LIT Y in a qualitative study. We recruited 6 Com-\nputer Science PhD students (1 female, 5 male; avg. 3.3 yrs. into PhD\nprogram) whose primary research area is within the ﬁeld of visualiza-\ntion. None of the participants were involved in the formative study.\nSessions lasted approximately 45 minutes. Participation was voluntary\nwith no compensation.\n6.1 Task & Procedures\nAfter obtaining informed consent, participants were asked to reﬂect\non a topic for which they had recently or were currently conducting\na literature review. VITA LIT Y was loaded with all 59,232 papers,\ndescribed in Section 4.1, running locally on the study investigator’s\nmachine. Participants connected to the study virtually via Microsoft\nTeams. They were asked to recreate or continue their literature re-\nview using VITA LIT Y, which they interacted with by using Microsoft\nTeams’s “Request Control” feature on the study investigator’s machine.\nWe utilized a think aloud protocol to capture users’ impressions and\nqualitative feedback on the system. Sessions were screen-recorded for\nsubsequent analysis.\nParticipants chose the following topics for their literature reviews:\nmultiple comparisons problem, interpretable machine learning, mis-\ninformation, network visualization, scrollytelling visualization, and\ntransformation / similarity between two visualizations.\n6.2 Findings\nIn this section, we discuss qualitative ﬁndings from our evaluation\nof VITA LIT Y for each of its primary features (Figure 8), and lastly\nsummarize participants’ general impressions of the system (Figure 9).\n6.2.1 Paper Collection View\nParticipants felt that the Paper Collection View was a good “entry\npoint” into the paper corpus in VITA LIT Y, containing familiar data that\nusers expected to see, e.g., authors, abstracts, etc (S02). Searching by\nkeyword was familiar and produced expected outcomes. For instance,\nS03 identiﬁed some papers previously read as well as an interesting\nnew one, which led them to iterate on their search query to ﬁnd other\npapers by the same author.\nHowever, some users expressed the desire for the keyword search\nfeatures to support more robust or customizable queries. As a case\nin point, S01 conducted a global search for multiple keyword varia-\ntions “uncertainty visualisations” → “uncertainty visualizations” →\n“uncertainty visualization”, which returned 0, 8, and 49 hits respectively.\nFuzzy string matching would be a useful feature to support in subse-\nquent iterations of VITA LIT Y (S06). Another small usability issue that\narose was lack of feedback upon clearing ﬁlters. For instance, some\nparticipants would backspace to delete text; however, the system would\nonly remove ﬁlters by selecting the ‘x’ icon next to the ﬁlter (S01,\nS05). Furthermore, S06 suggested it would be useful for VITA LIT Y\nto expand the searchable text beyond titles and abstracts: “Google\nScholar searches body text too. ”\n6.2.2 Similarity Search\nBy Paper. The ability to start with a seed paper(s) and identify other\nrelevant literature was appreciated, with varying opinions about the\nquality and relevance of results. Many participants were able to identify\ninteresting and relevant papers; e.g., S04 identiﬁed a relevant paper\nfrom two key authors that they were not aware had collaborated. S05\nindicated a signiﬁcant ﬁnding of a paper that “did something similar\nto what [they] were considering doing. ” Compared to searching by\nkeywords, S05 said “the papers [they are] seeing now are a lot more\nrelevant. Some of these papers [they have] been reviewing. Some\nof them are kind of new. ” S05 later acknowledged the utility of the\nsimilarity score: “It seems reasonable. . . Those on top tended to be\nmore relevant to what [they were] looking for. ”S06 commented that\nthe similarity score was good feedback on the precision and quality of\nthe search itself: “some would return like 0.0001 and [they] could see\nthat [their] search was wrong. ”\nNot all feedback about the similarity search was positive, however.\nS01 was uncertain about the quality of the results, stating they “could\nﬁnd a few papers that came up that slipped [their] mind, but [they]\ndidn’t ﬁnd any new papers that [they] hadn’t already cited. [...] [they]\nhave some conﬁdence that it would work, but for this particular context,\n[they] did not ﬁnd anything new. ”In response to some search queries,\nparticipants expressed disappointment with the results. For instance,\nusing a single seed paper as input to similarity search, S02 indicated\n“these do not seem to be good results. The 2-D search does not seem\nto be good with GloVe. The N-D results were much better. ”S02 then\nadded additional papers as input to the similarity search and again noted\n“some match, but some do not. [...] [they] could have expected better\nsearch results. ”S02 ultimately suggested to explore other transformer\nembeddings, e.g., BERT.\nBy Abstract. While not all participants had an abstract prepared to\nutilize the Similarity Search by Abstract feature, they nonetheless saw\nvalue in it. S01, for instance, indicated that if they are “starting a new\nproject [...] [they] can write up some words in the form of an abstract\nto see if this has been done. ”\nS06 interestingly appropriated the abstract search in response to\nperceived shortcomings of traditional search features. For instance,\nafter searching by keyword, applying ﬁlters, and iteratively revising\nqueries to try to capture multiple keywords, S06 felt dissatisﬁed with\nthe limitations of searching by keyword in VITA LIT Y: “Maybe [they]\nshould use word embeddings because it might have more ﬂexibility,\nand [they] can pass more information in [their] search. ”They wrote a\nquick abstract paragraph during the study session and observed that the\nresults showed “a lot of foundational literature. ”They iterated, adding\nadditional details to the abstract and expressed “Wow, this shows much\nbetter results now than the short abstract. ” By the end of the study\nsession, S06 identiﬁed several papers they had already cited as well as\na few key new ones: “For 15 minutes, [they] found two papers [they]\nmight be interested in. It’s a really useful process. Otherwise [they]\nmight spend a lot of time scanning PDFs, which is not a very pleasant\nexperience. ”\n6.2.3 Visualization Canvas\nMany participants found the projection visualization of the embedded\nspace to be a useful way to identify conceptually “nearby” relevant\npapers. S05 suggested the visualization “provides a nice overview of\nthe selected papers, and [they] could see to drill down into more details\nor look for clusters. ”S01 appreciated the ability to select nearby papers\nin the embedded space via lasso, indicating “It’s like a mystery. [They]\nfeel like if [they] spent some time on this, [they] might stumble upon a\npaper that was relevant that was published in a different domain [...]\nIt might be especially useful if [they] worked on a different topic that\n[they] had not worked on in the past. ”S04 echoed this sentiment and\n7\na\nc\nb\nd\nFig. 6. Search by a list of seed papers: Scenario 1. Based on a list of known relevant bias papers (a), Maya observes the clustering of similar\npapers in the Visualization (b). She examines the similar papers more closely to gauge their relevance (c) and exports relevant saved papers (d).\nb\na\nFig. 7. Search by Abstract: VITA LIT Y’s own Literature Review.The\nauthors using VITA LIT Y’s working title and abstract (a) to ﬁnd similar\npapers (b) to assist in its own literature review.\nadded that the feature to locate a given paper on the visualization was\nhelpful for orienting.\nHowever, this impression was not universal. While S06 appreciated\nsearching by abstract, they preferred to examine results in tabular\nformat, because “personally [they are] not super familiar with these\nvisualizations, dimensionality reduction, so it’s harder to interpret how\nto assess this information. ”S03 was skeptical about the accuracy of\nthe projection, stating “the algorithm might be bad, or the projection.\nIt doesn’t accurately depict similarity between papers. ”\nSome participants suggested variations, such as spacing out papers\nin the visualization and connecting them by edges where the weight\nreﬂects the similarity with other papers in the visualization (S04). S06\nsuggested for lasso selection, it would be useful to see “factors that\ncan cluster similar papers. ” Furthermore, S04 suggested additional\ninteractivity to ﬁlter out papers on different “layers” in the visualization,\ne.g., those that are part of similarity search, saved papers, etc. S02\nsuggested a minor tweak: “when [they] do this similarity search, it\nshould automatically zoom to show the paper(s) that were the beginning\nsearch point and the papers that it found, rather than this zoomed out\n−100 −50 0 50 100\nPercentage\nI was able to ﬁnd the relevant papers I was seeking.\nI would use a system like vitaLITy in my literature review process.\nI found the Main table view to be useful\nI found the Saved Papers 'cart' view to be useful\nI found the Similarity Search by Paper to be useful\nI found the Similarity Search by Abstract to be useful\nI found the Scatterplot (umap) to be useful\nI found the Meta Info (keyword, author, source, year lists) to be useful\nStrongly disagree Disagree Neutral Agree Strongly agree\nFig. 8. Usability scores of VITA LIT Y features.\nview where [they] have to look for the orange or red dots. ”\n6.2.4 Meta View\nThe Meta View went relatively unused compared to other features of\nVITA LIT Y. However, some participants did express ideas to improve\nits utility. For instance, S03 expressed that they would have preferred if\nthe Meta View “[did not display] keywords for the stuff above [Paper\nCollection View], but for what [they] have selected [Similarity Search\ninput, Saved papers]. ”S05 suggested that the Meta View could offer\nadditional keyword recommendations based on semantically similar\nkeywords, to help users identify other potential search terms. Others\nindicated a desire for further integration of the Meta View such that\nselecting a keyword could highlight papers in the visualization (S04)\nor ﬁlter the Paper Collection View (S06).\n6.2.5 Saved Papers Cart\nThe Saved Papers Cart was also not used as often as some of the other\nviews. Some preferred their existing workﬂow of downloading PDFs\ndirectly (S06), while others appreciated the “cart” analogy and the\naccompanying mindfulness to “ﬁll the cart with relevant papers” (S02)\nas an alternative to manually maintaining “a word document to keep\ntrack of the titles” (S03).\n6.2.6 Summary & Workﬂow\nOverall Impressions. Users believed that VITA LIT Y would be useful\nin a variety of contexts. Several users believed VITA LIT Y would be\nhelpful in identifying gaps in their literature review (S01, S04). For\ninstance, S04 indicated “it’s very helpful to actually ﬁnd a set of papers\n8\n© 2021 IEEE. This is the author’s version of the article that has been published in IEEE Transactions on Visualization and\nComputer Graphics. The ﬁnal version of this record is available at: 10.1109/TVCG.2021.3114820\n−100 −50 0 50 100\nPercentage\nI think that I would like to use vitaLITy frequently.\nI found vitaLITy unnecessarily complex.\nI thought vitaLITy was easy to use.\nI think that I would need the support of a technical person to use vitaLITy.\nI found the various functions of vitaLITy were well integrated.\nI thought there was too much inconsistency in vitaLITy.\nI imagine that most people would learn to use vitaLITy very quickly.\nI found vitaLITy very awkward to use.\nI felt very conﬁdent using vitaLITy.\nI needed to learn a lot of things before I could get going with vitaLITy.\nStrongly disagree Disagree Neutral Agree Strongly agree\nFig. 9. Overall SUS scores of VITA LIT Y.\nthat are semantically relevant to one paper. If [they] identify a paper\nthat [they] missed in the lit review, [they] can ﬁnd other papers similar\nto that one to be sure [they] don’t miss anything else. ” Participants\nfelt that it could help avoid “embarassment” of reviewers pointing out\nmissing related work (S01, S06).\nThe individual SUS scores per participant were S01=72.5, S02=77.5,\nS03=45, S04=72.5, S05=70, S06=92.5 for an overall average SUS\nscore=72.5 (Figure 9). While participants generally liked using VI-\nTALIT Y, several expressed that, given the large number of features,\ncustomization of the screen real estate would have been beneﬁcial (S02,\nS04, S06). For instance, S02 indicated “when [they] had already ﬁl-\ntered by keywords, [they are] only focusing on this view [Visualization\nCanvas]. It’s very small in the screen space. [They] want to hide the\nMeta View and maybe even the [Paper Collection View], so [they] can\neasily zoom and pan and lasso. The Similarity Search panel could\nalso be bigger. ” Others echoed formative feedback, wanting to see\nthe citation network in VITA LIT Y, e.g., which papers cite others (S01,\nS06).\nWorkﬂow. Some participants viewed VITA LIT Y as a complementary\ncomponent to their existing literature review workﬂow. For instance,\nS01 indicated they would“interleave this with a Google Scholar search.\nIf [they] found a few relevant papers, [they] would go to Google Scholar\nto see the references in that paper and who has cited that paper. ”S06\nindicated preference to continue their existing approach of beginning\na literature review with Google Scholar and use VITA LIT Y at a later\nstage of the research, e.g., “when [they] want to do some sanity checks\n[...] [after they] have [their] abstract, papers [they] have already cited,\nand based on that [they] can do a more narrow search for papers [they]\nmight be missing, ”while others preferred to use VITA LIT Y as early in\nthe lit review process that you are able to “structure the related work\nsections [...] and [identify] those 2-3 themes” (S05).\nOthers felt that VITA LIT Y suffered from many of the same problems\nthat existing tooling has. For instance, S01 said “[The] target is one\nunknown paper among hundreds. A lot of the papers [they] ﬁnd because\ncoauthors tell [them] about them. ”S03 indicated they would use the\ntool primarily in the same ways as Google Scholar, e.g., “[they] would\njust search for keywords. ”\n7 D ISCUSSION\nQuality of Search Results. Across our (relatively small) sample\nof participants, there was variability in terms of perceived relevance\nof Similarity Search results. Some participants felt that, like Google\nScholar, relevant results were lost among a sea of irrelevant papers,\nwhile others felt that the results were highly relevant. In general,\nparticipants perceived results from SPECTER embeddings to be more\nrelevant than GloVe, suggesting that further exploration of alternative\ntransformer-based approaches (e.g., BERT [16], or training a custom\nmodel on the target document corpus) could yield better search results.\nFurthermore, given the disparity in perceived quality and disparity\nin participants’ perception of when this approach could be useful in\ntheir literature review process, future work could develop additional\nguidelines that assess the speciﬁc role of document retrieval based on\nsemantic similarity.\nRelevance & Space. Presuming VITA LIT Y is able to provide\nserendipitous discovery of relevant literature, the process doesn’t\nabruptly come to a successful end. Authors still need to manage goals\nin their writing that may be at odds with one another: i.e., the tradeoff\nof relevance or salience of related work and the commodity of space.\nFrom this perspective, VITA LIT Y is best viewed as a way to identify\ncritical gaps or serve as kindling for a new literature review. In its\ncurrent form, VITA LIT Y shows (1) similarity score, and (2) citation\ncounts as the primary cues of relevance or salience of a given paper.\nIt still requires substantial knowledge from the author to (1) read an\nabstract or paper and determine its actual relevance to a given topic, and\n(2) assess the credibility of the work, author(s), and venue. Subsequent\nversions of VITA LIT Y could focus on innovating solutions to support\nthese and other parts of the literature review process.\nFuture Work. Based on our use of VITA LIT Y and participant feed-\nback, we identify a number of potential future directions. First, as\nmentioned in the Related Work, with citation and user activity data,\nVITA LIT Y could expand its functionality to citation or read/view rec-\nommendation using SPECTER. Second, current similarity scores in the\nprojected 2-D space (UMAP) are based on the reciprocal of the distance\nmeasure and might yield different results compared to distances in the\nN-D embedding space. These scores and their context may not be espe-\ncially intuitive for users. Hence, future work could reﬁne the similarity\nscore formulation and / or presentation in VITA LIT Y to provide users\nan accessible framework to interpret results. Third, the Saved Papers\nCart currently exports a ﬁle in JSON format with the papers. At least\ntwo improvements could be made within this view, including exporting\nﬁles in .bibtex format for easy incorporation in LATEX bibliographies.\nFurthermore, it could be useful to users to provide a meta analysis\nof the saved papers, e.g., via topic modeling. How can these papers\nbe summarized? Fourth, while our research prototype of VITA LIT Y\nis intended to be complementary to existing search strategies, future\nwork could expand VITA LIT Y to a more comprehensive search tool,\nincorporating the beneﬁts of e.g., citation networks. Lastly, VITA LIT Y\nis modular, scalable, and extensible: it applies the virtual scrolling\nprinciple in the UI table views (preventing unnecessary rendering of\nobjects not visible in the viewport), renders the UMAP using WebGL,\nand uses a library (faiss) that performs efﬁcient similarity search of\ndense vectors with an option to leverage GPUs. The scraper module\ncurrently uses DBLP as the source of raw data but can be extended\nto support other digital libraries, e.g., JSTOR (https://www.jstor.org/).\nHence, augmenting the system with additional venues (and allowing\nusers to deﬁne which venues are relevant to load in their speciﬁc lit-\nerature review) is a feasible next step to expand VITA LIT Y to other\nresearch domains.\n8 C ONCLUSION\nWe introduced a visualization system, VITA LIT Y, designed to promote\nserendipitous discovery of relevant academic literature. Designed and\ndeveloped with formative input from data visualization researchers,\nVITA LIT Y allows users to search and explore academic literature using\na document-level transformer-based approach to identify semantically\nsimilar literature. In addition, we contributed a dataset about 59,232\nacademic articles with metadata (titles, abstracts, authors, keywords,\ncitation counts, etc.) across 38 venues common in data visualization\nresearch, along with open-source scrapers to expand and customize\nthe corpus of literature searchable in VITA LIT Y. We demonstrated\nhow VITA LIT Y can complement existing academic literature review\npractices through a series of usage scenarios and shared feedback from\n6 data visualization researchers from a qualitative study. Participants\nexpressed excitement to incorporate VITA LIT Y in their workﬂow, to\nidentify gaps in their academic literature searches or to kickstart the\nliterature review of a new topic. While our initial prototype and evalua-\ntion focused on the data visualization ﬁeld, we have open-sourced our\nsystem and scraper framework to enable expansion of the VITA LIT Y\napproach to other venues and academic communities. We invite those\nwho are interested to augment the VITA LIT Y system and data for their\nacademic interests.\n9\nREFERENCES\n[1] A. Abdul-Rahman, G. Roe, M. Olsen, C. Gladstone, R. Whaling, N. Cronk,\nR. Morrissey, and M. Chen. Constructive visual analytics for text similarity\ndetection. In Computer Graphics Forum, vol. 36, pp. 237–248. Wiley\nOnline Library, 2017.\n[2] E. Alexander, J. Kohlmann, R. Valenza, M. Witmore, and M. Gleicher.\nSerendip: Topic model-driven visual exploration of text corpora. In 2014\nIEEE Conference on Visual Analytics Science and Technology (VAST), pp.\n173–182. IEEE, 2014.\n[3] S. Arora, Y . Liang, and T. Ma. A simple but tough-to-beat baseline\nfor sentence embeddings. In 5th International Conference on Learning\nRepresentations, ICLR 2017, 2017.\n[4] R. F. Baumeister and M. R. Leary. Writing narrative literature reviews.\nReview of general psychology, 1(3):311–320, 1997.\n[5] F. Beck, S. Koch, and D. Weiskopf. Visual analysis and dissemination\nof scientiﬁc literature collections with survis. IEEE Transactions on\nVisualization and Computer Graphics, 22(1):180–189, 2015.\n[6] I. Beltagy, K. Lo, and A. Cohan. Scibert: A pretrained language model\nfor scientiﬁc text. In Proceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the 9th International Joint\nConference on Natural Language Processing (EMNLP-IJCNLP), pp. 3606–\n3611, 2019.\n[7] A. Benito-Santos and R. Ther ´on. Glassviz: Visualizing automatically-\nextracted entry points for exploring scientiﬁc corpora in problem-driven\nvisualization research. arXiv preprint arXiv:2009.02094, 2020.\n[8] P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov. Enriching word\nvectors with subword information. Transactions of the Association for\nComputational Linguistics, 5:135–146, 2017.\n[9] R. Chang, C. Ziemkiewicz, T. M. Green, and W. Ribarsky. Deﬁning\ninsight for visual analytics. IEEE Computer Graphics and Applications,\n29(2):14–17, 2009.\n[10] C. Chen. Citespace ii: Detecting and visualizing emerging trends and\ntransient patterns in scientiﬁc literature. Journal of the American Society\nfor information Science and Technology, 57(3):359–377, 2006.\n[11] I. Cho, R. Wesslen, A. Karduni, S. Santhanam, S. Shaikh, and W. Dou.\nThe anchoring effect in decision-making with visual analytics. IEEE\nConference on Visual Analytics Science and Technology (VAST), 2017.\n[12] J.-K. Chou and C.-K. Yang. Papervis: Literature review made easy. In\nComputer Graphics Forum, vol. 30, pp. 721–730. Wiley Online Library,\n2011.\n[13] K. W. Church and J. I. Helfman. Dotplot: A program for exploring self-\nsimilarity in millions of lines of text and code. Journal of Computational\nand Graphical Statistics, 2(2):153–174, 1993.\n[14] A. Cohan, S. Feldman, I. Beltagy, D. Downey, and D. S. Weld. Specter:\nDocument-level representation learning using citation-informed transform-\ners. In Proceedings of the 58th Annual Meeting of the Association for\nComputational Linguistics, pp. 2270–2282, 2020.\n[15] A. Dattolo and M. Corbatto. Visualbib: narrative views for customized\nbibliographies. In 2018 22nd International Conference Information Visu-\nalisation (IV), pp. 133–138. IEEE, 2018.\n[16] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. Bert: Pre-training of\ndeep bidirectional transformers for language understanding.arXiv preprint\narXiv:1810.04805, 2018.\n[17] E. Dimara, G. Bailly, A. Bezerianos, and S. Franconeri. Mitigating the\nattraction effect with visualizations. IEEE transactions on visualization\nand computer graphics, 25(1):850–860, 2019.\n[18] E. Dimara, A. Bezerianos, and P. Dragicevic. The attraction effect in in-\nformation visualization. IEEE transactions on visualization and computer\ngraphics, 23(1):471–480, 2017.\n[19] E. Dimara, S. Franconeri, C. Plaisant, A. Bezerianos, and P. Dragicevic.\nA task-based taxonomy of cognitive biases for information visualization.\nIEEE transactions on visualization and computer graphics, 2018.\n[20] W. Dou, L. Yu, X. Wang, Z. Ma, and W. Ribarsky. Hierarchicaltopics:\nVisually exploring large text collections using topic hierarchies. IEEE\nTransactions on Visualization and Computer Graphics, 19(12):2002–2011,\n2013.\n[21] M. El-Assady, R. Sevastjanova, F. Sperrle, D. Keim, and C. Collins.\nProgressive learning of topic modeling parameters: A visual analytics\nframework. IEEE transactions on visualization and computer graphics,\n24(1):382–391, 2017.\n[22] A. Endert, P. Fiaux, and C. North. Semantic interaction for visual text\nanalytics. Proceedings of the 2012 ACM annual conference on Human\nFactors in Computing Systems - CHI ’12, pp. 473–482, 2012.\n[23] A. Endert, C. Han, D. Maiti, L. House, S. Leman, and C. North.\nObservation-level interaction with statistical models for visual analyt-\nics. IEEE Conference on Visual Analytics Science and Technology (VAST),\npp. 121–130, 2011. doi: 10.1109/V AST.2011.6102449\n[24] A. Endert, W. Ribarsky, C. Turkay, B. W. Wong, I. Nabney, I. D. Blanco,\nand F. Rossi. The state of the art in integrating machine learning into\nvisual analytics. In Computer Graphics Forum, vol. 36, pp. 458–486.\nWiley Online Library, 2017.\n[25] C. Felix, S. Franconeri, and E. Bertini. Taking word clouds apart: An\nempirical investigation of the design space for keyword summaries. IEEE\ntransactions on visualization and computer graphics , 24(1):657–666,\n2017.\n[26] M. Freire. Visualizing program similarity in the ac plagiarism detection\nsystem. In Proceedings of the working conference on Advanced visual\ninterfaces, pp. 404–407, 2008.\n[27] J. Fuchs, P. Isenberg, A. Bezerianos, and D. Keim. A systematic review of\nexperimental studies on data glyphs. IEEE transactions on visualization\nand computer graphics, 23(7):1863–1879, 2016.\n[28] D. Gotz, S. Sun, and N. Cao. Adaptive contextualization: Combating bias\nduring high-dimensional visualization and data selection. In Proceedings\nof the 21st International Conference on Intelligent User Interfaces , pp.\n85–95. ACM, 2016.\n[29] F. Heimerl, Q. Han, S. Koch, and T. Ertl. Citerivers: Visual analytics\nof citation patterns. IEEE transactions on visualization and computer\ngraphics, 22(1):190–199, 2015.\n[30] J. Heyer, N. K. Raveendranath, and K. Reda. Pushing the (visual) narra-\ntive: the effects of prior knowledge elicitation in provocative topics. In\nProceedings of the 2020 CHI Conference on Human Factors in Computing\nSystems, pp. 1–14, 2020.\n[31] U. Hinrichs, S. Forlini, and B. Moynihan. Speculative practices: Utilizing\ninfovis to explore untapped literary collections. IEEE transactions on\nvisualization and computer graphics, 22(1):429–438, 2015.\n[32] J. Hullman. Why authors don’t visualize uncertainty. IEEE transactions\non visualization and computer graphics, 26(1):130–139, 2019.\n[33] J. Hullman, E. Adar, and P. Shah. Beneﬁtting infovis with visual dif-\nﬁculties. IEEE Transactions on Visualization and Computer Graphics,\n17(12):2213–2222, 2011.\n[34] J. Hullman, P. Resnick, and E. Adar. Hypothetical outcome plots outper-\nform error bars and violin plots for inferences about reliability of variable\nordering. PloS one, 10(11), 2015.\n[35] P. Isenberg, F. Heimerl, S. Koch, T. Isenberg, P. Xu, C. Stolper, M. Sedl-\nmair, J. Chen, T. M ¨oller, and J. Stasko. vispubdata.org: A metadata\ncollection about IEEE visualization (VIS) publications. IEEE Transac-\ntions on Visualization and Computer Graphics, 23(9):2199–2206, Sept.\n2017. doi: 10.1109/TVCG.2016.2615308\n[36] P. Isenberg, T. Isenberg, M. Sedlmair, J. Chen, and T. M¨oller. Visualization\nas seen through its research paper keywords. IEEE Transactions on\nVisualization and Computer Graphics, 23(1):771–780, 2016.\n[37] J. Johnson, M. Douze, and H. J´egou. Billion-scale similarity search with\ngpus. arXiv preprint arXiv:1702.08734, 2017.\n[38] D. Jurafsky and J. H. Martin. Speech and language processing : an\nintroduction to natural language processing, computational linguistics,\nand speech recognition. Pearson Prentice Hall, 2021.\n[39] R. Kiros, Y . Zhu, R. Salakhutdinov, R. S. Zemel, A. Torralba, R. Urtasun,\nand S. Fidler. Skip-thought vectors. arXiv preprint arXiv:1506.06726,\n2015.\n[40] S. V . Kulkarni and S. A. Khaparde. Transformer engineering: design,\ntechnology, and diagnostics. CRC press, 2017.\n[41] S. Liu, Y . Chen, H. Wei, J. Yang, K. Zhou, and S. M. Drucker. Exploring\ntopical lead-lag across corpora. IEEE Transactions on Knowledge and\nData Engineering, 27(1):115–129, 2014.\n[42] S. Liu, X. Wang, C. Collins, W. Dou, F. Ouyang, M. El-Assady, L. Jiang,\nand D. A. Keim. Bridging text visualization and mining: A task-driven\nsurvey. IEEE transactions on visualization and computer graphics ,\n25(7):2482–2504, 2018.\n[43] L. McNabb and R. S. Laramee. How to write a visualization survey\npaper: A starting point. In Eurographics 2019-Education Papers. The\nEurographics Association, 2019.\n[44] T. Mikolov, K. Chen, G. Corrado, and J. Dean. Efﬁcient estimation of\nword representations in vector space. arXiv preprint arXiv:1301.3781,\n2013.\n[45] D. Moher, A. Liberati, J. Tetzlaff, D. G. Altman, P. Group, et al. Preferred\n10\n© 2021 IEEE. This is the author’s version of the article that has been published in IEEE Transactions on Visualization and\nComputer Graphics. The ﬁnal version of this record is available at: 10.1109/TVCG.2021.3114820\nreporting items for systematic reviews and meta-analyses: the prisma\nstatement. PLoS medicine, 6(7):e1000097, 2009.\n[46] R. Nakazawa, T. Itoh, and T. Saito. Analytics and visualization of cita-\ntion network applying topic-based clustering. Journal of Visualization,\n21(4):681–693, 2018.\n[47] A. Narechania, A. Coscia, E. Wall, and A. Endert. Lumos: Increasing\nawareness of analytic behavior during visual data analysis. IEEE Transac-\ntions on Visualization and Computer Graphics, 2021. To appear.\n[48] A. Narechania, A. Karduni, R. Wesslen, and E. Wall. VitaLITy: A Dataset\nof Academic Articles. 3 2021. doi: 10.6084/m9.ﬁgshare.14329151.v1\n[49] D. Park, S. Kim, J. Lee, J. Choo, N. Diakopoulos, and N. Elmqvist. Con-\nceptvector: text visual analytics via interactive lexicon building using word\nembedding. IEEE transactions on visualization and computer graphics,\n24(1):361–370, 2017.\n[50] J. Pennington, R. Socher, and C. D. Manning. Glove: Global vectors for\nword representation. In Proceedings of the 2014 conference on empirical\nmethods in natural language processing (EMNLP), pp. 1532–1543, 2014.\n[51] M. E. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee, and\nL. Zettlemoyer. Deep contextualized word representations. arXiv preprint\narXiv:1802.05365, 2018.\n[52] N. Reimers and I. Gurevych. Sentence-BERT: Sentence embeddings using\nSiamese BERT-networks. In Proceedings of the 2019 Conference on Em-\npirical Methods in Natural Language Processing and the 9th International\nJoint Conference on Natural Language Processing (EMNLP-IJCNLP) ,\npp. 3982–3992. Association for Computational Linguistics, Hong Kong,\nChina, Nov. 2019. doi: 10.18653/v1/D19-1410\n[53] J. Ritchie, D. Wigdor, and F. Chevalier. A lie reveals the truth: Quasi-\nmodes for task-aligned data presentation. In Proceedings of the 2019 CHI\nConference on Human Factors in Computing Systems, pp. 1–13, 2019.\n[54] R. C. Roberts and R. S. Laramee. Visualising business data: A survey.\nInformation, 9(11):285, 2018.\n[55] M. Smuc. Just the other side of the coin? from error to insight analysis.\nInformation Visualization, 15(4):312–324, 2016.\n[56] H. Snyder. Literature review as a research methodology: An overview and\nguidelines. Journal of Business Research, 104:333–339, 2019.\n[57] L.-H. Teo, B. John, and M. Blackmon. Cogtool-explorer: A model of goal-\ndirected user exploration that considers information layout. InProceedings\nof the SIGCHI conference on human factors in computing systems , pp.\n2479–2488, 2012.\n[58] The dblp team. dblp computer science bibliography. Monthly snapshot\nrelease of November 2020.\n[59] C. Tong, R. Roberts, R. Borgo, S. Walton, R. S. Laramee, K. Wegba,\nA. Lu, Y . Wang, H. Qu, Q. Luo, et al. Storytelling and visualization: An\nextended survey. Information, 9(3):65, 2018.\n[60] R. J. Torraco. Writing integrative literature reviews: Guidelines and\nexamples. Human resource development review, 4(3):356–367, 2005.\n[61] A. Tversky and D. Kahneman. Judgment under uncertainty: Heuristics\nand biases. Science, 185:1124–1131, 1974.\n[62] A. C. Valdez, M. Zieﬂe, and M. Sedlmair. Priming and anchoring effects in\nvisualization. IEEE Transactions on Visualization and Computer Graphics,\n24(1):584–594, 2018.\n[63] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nL. Kaiser, and I. Polosukhin. Attention is all you need. arXiv preprint\narXiv:1706.03762, 2017.\n[64] E. Wall, A. Arcalgud, K. Gupta, and A. Jo. A markov model of users’\ninteractive behavior in scatterplots. In2019 IEEE Visualization Conference\n(VIS), pp. 81–85. IEEE, 2019.\n[65] E. Wall, L. Blaha, C. Paul, and A. Endert. A formative study of interactive\nbias metrics in visual analytics using anchoring bias. In IFIP Conference\non Human-Computer Interaction, pp. 555–575. Springer, 2019.\n[66] E. Wall, L. M. Blaha, L. Franklin, and A. Endert. Warning, bias may\noccur: A proposed approach to detecting cognitive bias in interactive\nvisual analytics. In 2017 IEEE Conference on Visual Analytics Science\nand Technology (VAST), pp. 104–115. IEEE, 2017.\n[67] E. Wall, L. M. Blaha, C. L. Paul, K. Cook, and A. Endert. Four perspectives\non human bias in visual analytics. In Cognitive biases in visualizations,\npp. 29–42. Springer, 2018.\n[68] E. Wall, A. Narechania, A. Coscia, J. Paden, and A. Endert. Left, right,\nand gender: Exploring interaction traces to mitigate human biases. IEEE\nTransactions on Visualization and Computer Graphics, 2021. To appear.\n[69] E. Wall, J. Stasko, and A. Endert. Toward a design space for mitigating\ncognitive bias in vis. In 2019 IEEE Visualization Conference (VIS), pp.\n111–115. IEEE, 2019.\n[70] Y . Wang, M. Yu, G. Shan, H.-W. Shen, and Z. Lu. Vispubcompas: a\ncomparative analytical system for visualization publication data. Journal\nof Visualization, 22(5):941–953, 2019.\n[71] R. Wesslen, S. Santhanam, A. Karduni, I. Cho, S. Shaikh, and W. Dou.\nInvestigating effects of visual anchors on decision-making about misin-\nformation. In Computer Graphics Forum, vol. 38, pp. 161–171. Wiley\nOnline Library, 2019.\n[72] J. Wilkins, J. J¨arvi, A. Jain, G. Kejriwal, A. Kerne, and V . Gumudavelly.\nEvolutionworks. In IFIP Conference on Human-Computer Interaction, pp.\n213–230. Springer, 2015.\n[73] T. Yoon, H. Han, H. Ha, J. Hong, and K. Lee. A conference paper\nexploring system based on citing motivation and topic. In 2020 IEEE\nPaciﬁc Visualization Symposium (PaciﬁcVis), pp. 231–235. IEEE, 2020.\n[74] Y . Zhang, R. K. Bellamy, and W. A. Kellogg. Designing information for\nremediating cognitive biases in decision-making. In Proceedings of the\n33rd annual ACM conference on human factors in computing systems, pp.\n2211–2220, 2015.\n11",
  "topic": "Vitality",
  "concepts": [
    {
      "name": "Vitality",
      "score": 0.7692092657089233
    },
    {
      "name": "Computer science",
      "score": 0.7676292657852173
    },
    {
      "name": "Terminology",
      "score": 0.7500119209289551
    },
    {
      "name": "Data science",
      "score": 0.5961796641349792
    },
    {
      "name": "Visualization",
      "score": 0.5464242696762085
    },
    {
      "name": "Information retrieval",
      "score": 0.48714372515678406
    },
    {
      "name": "Data visualization",
      "score": 0.47891080379486084
    },
    {
      "name": "Dimension (graph theory)",
      "score": 0.44704440236091614
    },
    {
      "name": "Analytics",
      "score": 0.43643251061439514
    },
    {
      "name": "World Wide Web",
      "score": 0.4120393395423889
    },
    {
      "name": "Data mining",
      "score": 0.24098262190818787
    },
    {
      "name": "Linguistics",
      "score": 0.10855293273925781
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Pure mathematics",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Theology",
      "score": 0.0
    }
  ]
}