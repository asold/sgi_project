{
    "title": "ExDoRA: enhancing the transferability of large language models for depression detection using free-text explanations",
    "url": "https://openalex.org/W4410571380",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A2574655617",
            "name": "Y. H. P. P Priyadarshana",
            "affiliations": [
                "Kyoto University of Advanced Science"
            ]
        },
        {
            "id": "https://openalex.org/A2663137796",
            "name": "Zilu Liang",
            "affiliations": [
                "Kyoto University of Advanced Science"
            ]
        },
        {
            "id": "https://openalex.org/A25095945",
            "name": "Ian Piumarta",
            "affiliations": [
                "Kyoto University of Advanced Science"
            ]
        },
        {
            "id": "https://openalex.org/A2574655617",
            "name": "Y. H. P. P Priyadarshana",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2663137796",
            "name": "Zilu Liang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A25095945",
            "name": "Ian Piumarta",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2096431694",
        "https://openalex.org/W6855279210",
        "https://openalex.org/W4402301607",
        "https://openalex.org/W6778883912",
        "https://openalex.org/W6775348966",
        "https://openalex.org/W4236654575",
        "https://openalex.org/W6754655096",
        "https://openalex.org/W6671387458",
        "https://openalex.org/W4296701495",
        "https://openalex.org/W6677166381",
        "https://openalex.org/W4224308101",
        "https://openalex.org/W6803842174",
        "https://openalex.org/W6790003725",
        "https://openalex.org/W3171376656",
        "https://openalex.org/W6775841899",
        "https://openalex.org/W6796322357",
        "https://openalex.org/W6702325253",
        "https://openalex.org/W6728622933",
        "https://openalex.org/W3043194795",
        "https://openalex.org/W6802958121",
        "https://openalex.org/W4297499142",
        "https://openalex.org/W6754182907",
        "https://openalex.org/W6631190155",
        "https://openalex.org/W4385574286",
        "https://openalex.org/W6859088706",
        "https://openalex.org/W6793601707",
        "https://openalex.org/W6852285453",
        "https://openalex.org/W6857382437",
        "https://openalex.org/W4390929481",
        "https://openalex.org/W6857007385",
        "https://openalex.org/W4386187806",
        "https://openalex.org/W6742835619",
        "https://openalex.org/W6753299086",
        "https://openalex.org/W4362586953",
        "https://openalex.org/W6851880220",
        "https://openalex.org/W6860909576",
        "https://openalex.org/W4388798253",
        "https://openalex.org/W3212748247",
        "https://openalex.org/W6810583604",
        "https://openalex.org/W6796282661",
        "https://openalex.org/W6764538468",
        "https://openalex.org/W4388860745",
        "https://openalex.org/W6871883216",
        "https://openalex.org/W6852563089",
        "https://openalex.org/W6795770965",
        "https://openalex.org/W6763646573",
        "https://openalex.org/W2000594564",
        "https://openalex.org/W6773357711",
        "https://openalex.org/W6863595348",
        "https://openalex.org/W6776227417",
        "https://openalex.org/W6870730853",
        "https://openalex.org/W6811546821",
        "https://openalex.org/W6850183316",
        "https://openalex.org/W6839320708",
        "https://openalex.org/W6854866820",
        "https://openalex.org/W6846339732",
        "https://openalex.org/W6810975449",
        "https://openalex.org/W6784569371",
        "https://openalex.org/W6854476938",
        "https://openalex.org/W6856527969",
        "https://openalex.org/W6744180508",
        "https://openalex.org/W4306294746",
        "https://openalex.org/W4385571505",
        "https://openalex.org/W6849901376",
        "https://openalex.org/W6761205521",
        "https://openalex.org/W6794425615",
        "https://openalex.org/W3138773240",
        "https://openalex.org/W2962833140",
        "https://openalex.org/W3153427360",
        "https://openalex.org/W2951936329",
        "https://openalex.org/W3154219437",
        "https://openalex.org/W3209409148",
        "https://openalex.org/W2531327146",
        "https://openalex.org/W2963261455",
        "https://openalex.org/W2885138528",
        "https://openalex.org/W4308243058",
        "https://openalex.org/W3164896303",
        "https://openalex.org/W4391211792",
        "https://openalex.org/W4402352050",
        "https://openalex.org/W4287891024",
        "https://openalex.org/W1522301498",
        "https://openalex.org/W3177271673",
        "https://openalex.org/W4320839455",
        "https://openalex.org/W4224326626",
        "https://openalex.org/W4385572526",
        "https://openalex.org/W4396723505",
        "https://openalex.org/W2113640060",
        "https://openalex.org/W3094612274",
        "https://openalex.org/W2936695845",
        "https://openalex.org/W4389524211",
        "https://openalex.org/W4392822465",
        "https://openalex.org/W3173777717",
        "https://openalex.org/W4385570201",
        "https://openalex.org/W4385567059",
        "https://openalex.org/W4385373745",
        "https://openalex.org/W3104499181",
        "https://openalex.org/W4389366246",
        "https://openalex.org/W4394711951",
        "https://openalex.org/W4205991051",
        "https://openalex.org/W4385570045",
        "https://openalex.org/W2748108713",
        "https://openalex.org/W2885726350",
        "https://openalex.org/W3212191244",
        "https://openalex.org/W4287854450",
        "https://openalex.org/W2953413710",
        "https://openalex.org/W4401042585",
        "https://openalex.org/W3210129272",
        "https://openalex.org/W2332488709",
        "https://openalex.org/W3173566921"
    ],
    "abstract": "Few-shot prompting in large language models (LLMs) significantly improves performance across various tasks, including both in-domain and previously unseen natural language tasks, by learning from limited in-context examples. How these examples enhance transferability and contribute to achieving state-of-the-art (SOTA) performance in downstream tasks remains unclear. To address this, we propose ExDoRA , a novel LLM transferability framework designed to clarify the selection of the most relevant examples using synthetic free-text explanations. Our novel hybrid method ranks LLM-generated explanations by selecting the most semantically relevant examples closest to the input query while balancing diversity. The top-ranked explanations, along with few-shot examples, are then used to enhance LLMs‚Äô knowledge transfer in multi-party conversational modeling for previously unseen depression detection tasks. Evaluations using the IMHI corpus demonstrate that ExDoRA consistently produces high-quality free-text explanations. Extensive experiments on depression detection tasks, including depressed utterance classification (DUC) and depressed speaker identification (DSI), show that ExDoRA achieves SOTA performance. The evaluation results indicate significant improvements, with up to 20.59% in recall for DUC and 21.58% in F1 scores for DSI, using 5-shot examples with top-ranked explanations in the RSDD and eRisk 18 T2 corpora. These findings underscore ExDoRA ‚Äôs potential as an effective screening tool for digital mental health applications.",
    "full_text": "Frontiers in Artificial Intelligence 01 frontiersin.org\nExDoRA: enhancing the \ntransferability of large language \nmodels for depression detection \nusing free-text explanations\nY.¬†H.¬†P.¬†P.¬†Priyadarshana *, Zilu¬†Liang  and Ian¬†Piumarta \nKyoto University of Advanced Science (KUAS), Kyoto, Japan\nFew-shot prompting in large language models (LLMs) significantly improves \nperformance across various tasks, including both in-domain and previously \nunseen natural language tasks, by learning from limited in-context examples. \nHow these examples enhance transferability and contribute to achieving state-\nof-the-art (SOTA) performance in downstream tasks remains unclear. To address \nthis, we¬†propose ExDoRA, a novel LLM transferability framework designed to clarify \nthe selection of the most relevant examples using synthetic free-text explanations. \nOur novel hybrid method ranks LLM-generated explanations by selecting the \nmost semantically relevant examples closest to the input query while balancing \ndiversity. The top-ranked explanations, along with few-shot examples, are then \nused to enhance LLMs‚Äô knowledge transfer in multi-party conversational modeling \nfor previously unseen depression detection tasks. Evaluations using the IMHI \ncorpus demonstrate that ExDoRA consistently produces high-quality free-text \nexplanations. Extensive experiments on depression detection tasks, including \ndepressed utterance classification (DUC) and depressed speaker identification \n(DSI), show that ExDoRA achieves SOTA performance. The evaluation results \nindicate significant improvements, with up to 20.59% in recall for DUC and 21.58% \nin F1 scores for DSI, using 5-shot examples with top-ranked explanations in the \nRSDD and eRisk 18 T2 corpora. These findings underscore ExDoRA‚Äôs potential as \nan effective screening tool for digital mental health applications.\nKEYWORDS\nLLM transferability, in-context learning, free-text explanations, prompt engineering, \ndigital mental health, natural language processing\n1 Introduction\nFew-shot prompting of large language models (LLMs), which involves learning from a small \nnumber of in-context examples within prompts, has led to significant improvements across \nvarious natural language processing (NLP) tasks, including classification, generation, multi-step \nreasoning, and summarization (Brown et¬†al., 2020; Chowdhery et¬†al., 2023). These in-context \nexamples, also called demonstrations, cast downstream tasks together with task-specific \nprompts into a frozen LLM format to achieve state-of-the-art (SOTA) in-context learning (ICL) \nperformance for both in-domain, contextually similar tasks and previously unseen, contextually \ndissimilar ones (Qin et¬†al., 2022; Gao et¬†al., 2021; Li et¬†al., 2023). However, the quality of the \nretrieved demonstrations and how they contribute to SOTA ICL downstream performance \nremain unclear. Free-text explanations, on the other hand, have received increasing attention \nby providing detailed reasoning behind an LLM‚Äôs decisions over extractive methods such as \nSHapley Additive exPlanations (SHAP) Local Interpretable Model Agnostic Explanation \n(LIME), which focus on input tokens (Wiegreffe et¬†al., 2022). Inspired by the critical role that \nOPEN ACCESS\nEDITED BY\nBj√∂rn Gamb√§ck,  \nNorwegian University of Science and \nTechnology, Norway\nREVIEWED BY\nKausik Basak,  \nJIS Institute of Advanced Studies and \nResearch, India\nClaudio Crema,  \nSan Giovanni di Dio Fatebenefratelli Center \n(IRCCS), Italy\nJoe Hasei,  \nOkayama University, Japan\n*CORRESPONDENCE\nY. H. P. P. Priyadarshana  \n 2022md05@kuas.ac.jp\nRECEIVED 27 January 2025\nACCEPTED 28 April 2025\nPUBLISHED 21 May 2025\nCITATION\nPriyadarshana YHPP, Liang Z and \nPiumarta I (2025) ExDoRA: enhancing the \ntransferability of large language models for \ndepression detection using free-text \nexplanations.\nFront. Artif. Intell. 8:1564828.\ndoi: 10.3389/frai.2025.1564828\nCOPYRIGHT\n¬© 2025 Priyadarshana, Liang and Piumarta. \nThis is an open-access article distributed \nunder the terms of the Creative Commons \nAttribution License (CC BY). The use, \ndistribution or reproduction in other forums is \npermitted, provided the original author(s) and \nthe copyright owner(s) are credited and that \nthe original publication in this journal is cited, \nin accordance with accepted academic \npractice. No use, distribution or reproduction \nis permitted which does not comply with \nthese terms.\nTYPE Original Research\nPUBLISHED 21 May 2025\nDOI 10.3389/frai.2025.1564828\nPriyadarshana et al. 10.3389/frai.2025.1564828\nFrontiers in Artificial Intelligence 02 frontiersin.org\nexplanations play in human learning to adapt knowledge to new tasks \n(Ahn et¬†al., 1992), there is a pressing need to enhance the quality and \nconsistency of demonstrations in ICL, thereby improving the \ndownstream performance of previously unseen tasks through the most \nsuitable free-text explanations (Lampinen et¬†al., 2022).\nLinguistic-based detection of depression on social media offers \nnotable benefits over clinical and vision-based methods, particularly \nin early identification by analyzing shifts in language patterns, mood, \nor behavior (Le-Hinh et¬†al., 2023). Detecting depressive language in \nsocial media posts using a model trained on social media text data \ntagged for depressive symptoms is considered an in-domain task. \nMulti-party conversations (MPCs), on the other hand, involve a wide \nrange of language use, including emotions, thoughts, and social \ninteractions, making them crucial for detecting depression as a \ncomplex, contextually dissimilar task ( Lu et¬† al., 2023). While it is \nfeasible to use top-ranked demonstrations for depression detection in \nMPCs, the reasoning behind the model‚Äôs outcome remains uncertain. \nImproving an LLM itself to understand previously unseen depression \ndetection in MPCs as an ICL downstream task using free-text \nexplanations is currently unexplored.\nIn this article, we¬†propose ExDoRA, a novel LLM transferability \nframework designed to elucidate the most appropriate demonstrations \nusing synthetic free-text explanations generated by multiple LLMs, \nincluding Mistral-7B-Instruct, which is known for reliable explanation \ngeneration in emotion discovery (Siino, 2024), to improve the quality \nof demonstrations for depression detection tasks. Our objective is to \nenhance LLM knowledge transfer in MPC structure and semantic \nmodeling for previously unseen depression detection tasks by utilizing \na reason-then-predict approach (Y e and Durrett, 2022). We¬†evaluate \nthe factuality of generated explanations by examining their alignment \nwith the intended context and assess their consistency by analyzing \nthe impact of these explanations on the final prediction.\nAs shown in Figure¬†1, ExDoRA comprises three key phases. First, \nthe demonstration retriever selects the most semantically relevant \ndemonstrations from a depression corpus closest to the input MPC \nquery. Next, the top-ranked demonstrations are used to generate free-\ntext explanations for the query. Finally, these generated explanations \nare ranked to identify the best ones by validating them externally \nusing the interpretable mental health instruction (IMHI) corpus \n(Y ang et¬†al., 2024). The selected demonstrations and explanations are \nthen used for few-shot prompting, employing soft prompt templates \nand soft verbalizers specifically designed to support the core logic of \nthe prompt manager for MPC modeling knowledge transfer, enabling \nthe classification of depressed utterances and the identification of \ndepressed speakers. Our main contributions include:\n 1 Designing a novel framework for selecting top-ranked \nexplanations through a hybrid selection strategy that combines \nexpected reciprocal rank (ERR) ( Chapelle et¬† al., 2009) and \nmaximum marginal relevance (MMR) ( Carbonell and \nGoldstein, 1998). ERR considers the probability of a user \nfinding a relevant demonstration at each rank position, which \ncan be¬† used to prioritize the most relevant explanations \nefficiently. MMR, on the other hand, balances relevance with \ndiversity, aiming to ensure that the selected explanations are \nnot only relevant but also cover different aspects of the content, \nincluding context shifts of MPCs. To the best of our knowledge, \nwe¬†are the first to ensure the selection of the most relevant \nexplanations for out-of-domain (OOD) tasks, both for \ndemonstrations and the input query, while promoting diversity \nin the outputs to prevent redundancy.\n 2 Evaluating the factuality and consistency of the synthetic free-\ntext explanations using the IMHI corpus.\n 3 Employing multiple downstream depression detection tasks to \nevaluate the generalization of our methods, incorporating ExDoRA \nas a component into the ProDepDet framework (Priyadarshana \net¬†al., 2024) established for OOD knowledge transfer.\n 4 Conducting ablation studies to evaluate the robustness of the \nproposed framework concerning the number, order, and \ndiversity of the top-ranked explanations.\nThe overall organization of this article is as follows: Section 2 \nreviews related work and Section 3 elaborates the proposed \narchitecture and methodology. The experiments are presented in \nSection 4 and then discussed in Section 5.\n2 Related work\n2.1 Free-text explanation generation\nThe generation of suitable free-text explanations plays a crucial \nrole in enabling few-shot demonstrations in previously unseen \ndepression detection tasks. Research has shown that combining \nFIGURE¬†1\nThe proposed ExDoRA will select top-ranked explanations for depression detection in text-based MPCs.\nPriyadarshana et al. 10.3389/frai.2025.1564828\nFrontiers in Artificial Intelligence 03 frontiersin.org\nfew-shot demonstrations with appropriate explanations improves \ndownstream performance across multiple in-domain tasks. The \nearliest neural models for generating free-text explanations were \ndeveloped for computer vision tasks (Hendricks et¬†al., 2016; Kim et¬†al., \n2018) and natural language inference (NLI) (Camburu et¬†al., 2018), \nrelying on supervised corpora. Rajani et¬†al. (2019) and Shwartz et¬†al. \n(2020) further advanced these methods by enhancing both supervised \nand unsupervised approaches to improve the performance of \nin-domain question and answering (QA) downstream tasks. Wiegreffe \net¬†al. (2021) were the first to introduce a pipeline for generating free-\ntext natural language explanations to improve reasoning rather than \nsolely focusing on task-specific performance. Paranjape et¬†al. (2021) \nand Marasoviƒá et¬†al. (2022) utilized prompt engineering techniques \nover LLMs to generate explanations for commonsense reasoning tasks \nusing human-written explanations, but the downstream performance \nfell short of expectation. Inspired by previous work on human-assisted \nfew-shot LLM explanation generation, studies such as those by Sun \net¬† al. (2022), Y e and Durrett (2022), and Wiegreffe et¬† al. (2022)  \nexplored QA and NLI tasks, while Wang et¬†al. (n.d.) introduced a \ncounterfactual reasoning framework for generating choice-specific \nexplanations in multiple-choice QA, although this was limited to \ncontextually similar tasks. To address the challenge of poor \ngeneralization to unseen tasks, Ludan et¬†al. (2023) used non-human-\ngenerated free-text explanations from LLMs for classification tasks, \nalthough this approach was limited to unseen scenarios within the \nsame domain. Liu et¬† al. (2024)  recently introduced a free-text \nexplanations-based interpretability framework that achieved SOTA \nperformance for QA tasks. However, its performance declined \nsignificantly when applied to OOD unseen scenarios. While various \nstudies have focused on improving in-domain downstream tasks using \nfree-text explanations, the transfer of knowledge to OOD tasks \nremains an area for further exploration.\n2.2 Linguistic-based depression detection\nDue to the limitations of clinical diagnosis, linguistic-based \ndepression detection on social media data has emerged as a rapidly \nevolving research area. The initial effort to uncover the link between \nnatural language use and depression detection was made in 2017 \n(Losada et¬†al., 2017), followed by early exploration of linguistic patterns \nfor identifying depression ( Burdisso et¬† al., 2019). A few machine \nlearning-based approaches, such as those by Burdisso et¬†al. (2021) and \nthe DEPTWEET model by Kabir et¬†al. (2023), have contributed to \nimproving depression identification by leveraging linguistic patterns. \nTo overcome the limitations of these earlier methods, neural-based \ntechniques were developed, such as the ordinal classification technique \nintroduced by Naseem et¬†al. (2022) for early depression detection and \na recurrent neural network-based method by Ghosh and Anwar (2021) \nthat estimates depression severity using self-supervised data. These \nmethods were further enhanced by ICL LLM-based approaches, \nincluding text summarization-based depression detection (Zogan et¬†al., \n2021), mental health prediction tasks (Xu et¬†al., 2024), multi-modal \ntasks (Sharma et¬†al., 2024), and explainable LLM-augmented chatbots \n(Liu et¬†al., 2023). However, these methods failed to gain end-user trust \ndue to concerns regarding the explainability of their outcomes. To \nimprove the explainability of black-box depression detection models, \nseveral strategies have been proposed. These include a text-to-text \nexplainable pipeline (Bao et¬†al., 2024), integration of LIME and SHAP \nextractive explanations (Malhotra and Jindal, 2024), treating mental \nhealth analysis as a text-generation task (Liu et¬†al., 2023), and human-\nassisted prompt-based explanation generation as a predict-then-explain \napproach ( Qin et¬† al., 2023 ). Despite these advances, none has \ndemonstrated satisfactory performance in contextually dissimilar cases, \nsuch as depression detection in MPC analysis using task-specific \nfew-shot demonstrations and free-text explanations.\n3 Methods\n3.1 Approach\nOur aim is to model previously unseen depression detection as an \nOOD task by leveraging an LLM‚Äôs knowledge of MPC modeling. This \ninvolves incorporating carefully selected demonstrations and their \ncorresponding free-text explanations. As shown in Figure¬† 1, the \ndemonstration retriever Dr is responsible for retrieving the most \nrelevant top-ranked demonstrations, D = {d1, d2, ‚Ä¶, dn}, for the input \nMPC utterance xq, where (xq, yq) ‚àà D is a pair of MPC utterance and \nits ground truth, sourced from the expert-annotated Reddit Self-\nreported Depression Diagnosis (RSDD) corpus (Y ates et¬†al., 2017). \nGiven its effectiveness in retrieving demonstrations from unseen \ndatasets across multiple ICL tasks, we¬†selected a unified demonstration \nretriever (UDR) (Li et¬†al., 2023) as our primary retrieval mechanism. \nThese demonstrations are then used to generate explanations E, \nconsidering both D and each utterance in xq, with the help of multiple \nfoundational LLMs, including Mistral-7B-Instruct. The generated E is \nranked, validated, and then paired with MPC source prompt \nembeddings P = {p1, ‚Ä¶, pk} and D for OOD depression detection. In \nthe following sections, we¬†present the design, E generation, E ranking, \nE validation, the components of the prompt manager, and the \nformation of the depression detection tasks.\n3.2 System design\nFigure¬† 2 shows the design of the proposed system. At its core, \nwe¬†employ a pre-trained LLM capable of modeling MPCs as the ‚Äúfrozen‚Äù \nLLM. This LLM has acquired knowledge in processing contextualized \nrepresentations of MPCs, including token embeddings, segment \nembeddings, speaker embeddings, and positional embeddings, to model \nMPC behaviors such as response utterance selection and exact speaker \nidentification. Following the approach by Lester et¬† al. (2021), most \nparameters of the LLM are kept unchanged, with only minor adjustments \nmade to train the prepended embeddings for MPC modeling within P \nto detect depression. Our objective is to generalize a specific LLM to \nhandle multiple tasks rather than creating separate instances for each \ntask. Once the prompt embeddings P are paired with the demonstrations \nD and the corresponding E from ExDoRA, the prompt manager M‚±∞ of \nProDepDet processes the embedded P using mandatory soft prompt \ntemplates ‚Ç∏ and optional soft verbalizers ∆î created from the OpenPrompt \nPython library. Inspired by Su et¬†al. (2022) on the transferability of soft \nprompts for in-domain tasks, we¬†empirically investigate the ICL-based \ntransferability of these soft prompts and verbalizers for OOD tasks. \nThese components use the frozen LLM M to determine the \ncontextualized representations for downstream depression detection, \nPriyadarshana et al. 10.3389/frai.2025.1564828\nFrontiers in Artificial Intelligence 04 frontiersin.org\nincluding depressed utterance classification and depressed speaker \nidentification, applying non-linear transformation and layer \nnormalization. A detailed version of Figure¬†2 is provided in Appendix.\n3.3 Explanation generation\nThe generation of E is crucial for determining the most appropriate \nfree-text explanations based on the demonstrations retrieved from \nUDR for each utterance (U1, U2, U3, and U4) in an MPC.\n { }== 1:i iKEe  (1)\nIn Equation 1, each ei ‚àà —¥ represents a free-text explanation \ngenerated using the context vocabulary —¥ of the generative LLM. In \nthis process, we¬†used Mistral-7B-Instruct and Gemma-7B to generate \nE. These models, trained on instruction-based data, can respond to \ndetailed prompts by producing natural language outputs that enhance \nvarious decision support systems. Furthermore, Mistral-7B-Instruct‚Äôs \ninstruction tuning enables it to handle structured tasks and generate \nexplanations that are coherent and contextually relevant, enhancing an \nLLM‚Äôs ability to interpret and clarify subtle features, such as language \npatterns in depression detection. The prompt, shown in Figure¬†3, is \nadjusted to emphasize the depressive elements of both D and the input \nutterances. This helps guide the LLM in focusing on recognizing and \nexplaining depressive content. Given the resource constraints, we¬†limit \nthe generation to a maximum of three explanations for each D.\n3.4 Explanation ranking\nThe ranking of explanations Erank is conducted using a novel \nselection strategy that combines ERR and MMR. This approach \nincorporates two key components, such as depression diagnosis \ncriteria and a similarity model. To rank the generated explanations \nbased on their semantic relevance to D and the input utterances, \nwe¬†utilize a semantic similarity measure. One effective way to do this \nis by using sentence embeddings and calculating cosine similarity \nbetween the generated E and both D and the query (Y e et¬†al., 2023). \nWe¬†use a pre-trained model from the sentence-transformers library1 as \nthe similarity model MS to compute sentence embeddings and then \norganize the explanations based on their average semantic similarity. \nThe choice of sentence embedding models significantly impacts the \neffectiveness of MMR, considering the diversity of the generated \nexplanations. Advanced models such as all-MiniLM-L6-v22 offer \nrobustness, which is evaluated through experiments to ensure \nSOTA performance.\nThe depression diagnostic criteria play a crucial role in ensuring \nthat the generated explanations are clinically accurate and contextually \nrelevant. Although our method is intended as a screening tool for \ndepression detection, adhering to clinical guidelines is vital for ethical \nand responsible use in mental health contexts. To ensure the \nexplanations reflect real-world clinical scenarios, we¬† use DSM-5 \ncriteria (Regier et¬†al., 2013) as the depression diagnostic criteria. The \nDSM embeddings are generated using M S and integrated into the \nsame embedding space with the embeddings of D, E, and the input \nutterances. These contextualized representations are used to determine \nrelevance scores for each generated explanation by evaluating the \naverage semantic similarity. The scores are normalized to produce \nrelevance probabilities Íùí‚±§, which serve as input for ERR- and \nMMR-based ranking as presented in Algorithm 1.\n1 https://huggingface.co/sentence-transformers\n2 https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\nFIGURE¬†2\nThe system design for transferability of LLMs for depression detection using ExDoRA.\nPriyadarshana et al. 10.3389/frai.2025.1564828\nFrontiers in Artificial Intelligence 05 frontiersin.org\nTo achieve a balance of semantic relevance and diversity in \nranking the generated explanations, we¬† use a hybrid approach \ncombining ERR and MMR. ERR uses relevance probabilities at each \nrank to calculate a cumulative score as in Equation 2\n \n( )Œ≥Œ≥\n‚àí\n= =\n= ‚àí‚àë‚àè\n1\n11\n1 1\nnk\nik\nki\nERR p pk  \n(2)\nwhere pi represents the probability of relevance for the i-th \nexplanation and ùõæ denotes the decay factor (often set between 0 and \n1) that simulates a user selecting the exact explanation among a few \noptions by reducing the influence of each subsequent explanation. \nMMR promotes diversity by balancing the trade-off between relevance \nand redundancy when ranking explanations. It selects the next \nexplanation based on both its similarity to the query q for relevance \nand its dissimilarity to already selected items es for as Equation 3,\n \n( ) ( ) ( ) ( )ŒªŒª\n‚àà\n=√ó ‚àí‚àí√ó ,1 ,\nje s\nmaxSim\ni i ijxMMR e Sim e q e e\n \n(3)\nwhere ei represents the candidate explanation and Œª denotes the \ntrade-off between relevance and redundancy. The values of \nEquations 2, 3  are then aggregated as Scomb to determine the \nexplanations with the highest combined scores Stop as Equation 4\n \n( )Ô£ÆÔ£π= Ô£ÆÔ£πÔ£∞Ô£ªÔ£∞Ô£ª‚àë\ncomb\ntop s j comb\nS\nS e argmax S j\n \n(4)\nwhere argmaxj finds the index j of the maximum value in the \naggregated scores.\nERR and MMR offer dynamic trade-offs between relevance and \ndiversity, unlike alternatives such as precision at k and mean average \nprecision, which focus on only one dimension (Chapelle et¬†al., 2009; \nCarbonell and Goldstein, 1998).\n3.5 Explanation validation\nThe top-ranked explanations are then validated using the IMHI \nbenchmark, which serves as the evaluation corpus for mental health-\nrelated reasoning tasks. Note that we¬† used 100 expert-written \nexplanations from the IMHI benchmark to evaluate the generated E, \nas it is currently the only available benchmark for mental health-\nrelated reasoning tasks. The top two validated explanations are then \nused for few-shot prompting to facilitate depression detection. Given \nthe input embeddings X = {x1, ‚Ä¶, xm} for m contextual representations \nof xq, P, D, and Erank, the maximum probability of obtaining y, the \ndepression ground truth corresponding to X, is formulated as (y | P, \nD, Erank, x1, ‚Ä¶, xm).\n3.6 Prompt manager\nAs shown Figure¬†2, the prompt manager M‚±∞ is developed using \nthe ProDepDet framework (Priyadarshana et¬†al., 2024). It integrates \nP, D, and Erank to facilitate the LLM knowledge transfer in MPC \nmodeling for previously unseen depression detection tasks. This is \nachieved using the most appropriate prompt templates ‚Ç∏ a n d  s o ft \nverbalizers ∆î. We¬†employ the soft template class of the OpenPrompt \nlibrary ( Ding et¬† al., 2022 ) to generate ‚Ç∏, leveraging its ability to \nencapsulate the input for ICL tasks compared to manually crafted \ntemplates. Task-specific prompt templates for depression detection \ntasks, such as depressed utterance classification, are derived from the \nMPC modeling source task P. For a given input utterance x ‚àà xq, the \ntemplate text T is structured as in Equation 5.\n ( )= ‚äïÔ£Æ Ô£π Ô£Æ Ô£πÔ£Æ Ô£πÔ£∞ Ô£ª Ô£∞ Ô£ªÔ£∞ Ô£ª12x CLS x p SEP p EOSÔÅî  (5)\nThe [CLS], [SEP], and [EOS] tokens are critical components in \nLLM ICL classification-based tasks. [CLS] is added at the beginning \nof xq to gather the overall context. [SEP] is used to separate distinct \nsegments within xq, allowing it to understand the individual and \ncombined context. [EOS] marks the end of a sequence, signaling the \nLLM to stop processing further tokens. Inspired by Sun et¬†al. (2024) \nin ICL for contextually dissimilar tasks, p1, p2 ‚àà P are concatenated at \nthe end of each X in x and the end of xq. This can be¬†illustrated using \nan MPC example, ‚ÄúT(x) = [CLS] where have you¬†been? | he¬†was in the \nhospital | Oh! I¬†wanted to hurt myself. | he¬†was feeling unwell [SEP] \nhe¬†was experiencing symptoms of depression [EOS]‚Äù where the bold \ntext presents samples for T. The length of T is considered a key design \nfactor, and several ablation studies were performed to assess the \nimpact of varying prompt lengths.\n∆î is considered as an optional component in vanilla ICL that maps \noriginal classes (such as positive) c ‚àà C to label words v ‚àà V (such as \n‚Äúgood, ‚Äù ‚Äúgreat, ‚Äù or ‚Äúwonderful‚Äù), as shown in Table¬†1. While ∆î has not \nsignificantly contributed to in-domain LLM tasks, we¬† empirically \nevaluate its contribution to OOD unseen tasks. Previous methods \noften relied on manual verbalizers, which could introduce biases, or \nautomatic verbalizers that required explicit training to achieve better \nperformance (Schick and Sch√ºtze, 2021; Liu et¬†al., 2024). As illustrated \nFIGURE¬†3\nExample of a prompt used to generate free-text explanations. The prompt is designed to highlight the depressive elements within the demonstrations \nand input utterances, guiding the LLM to focus on recognizing and articulating relevant depressive content.\nPriyadarshana et al. 10.3389/frai.2025.1564828\nFrontiers in Artificial Intelligence 06 frontiersin.org\nin Figure¬† 2, we¬† use frozen M as the tokenizer, C, V, and the \nOpenPrompt library to determine ∆î. Here, V = {v1, v2, ‚Ä¶, vn} identifies \nthe depressive content, such as hurt, broken, and shocking, within xq. \n∆î is defined as a mapping function f, utilizing the LLM probability of \neach v being identified as a [MASK] token, to map content probabilities \nin x onto class probabilities of p(c|x) as shown in Equation 6.\n ( ) ( )( )= = ‚ààÔ£ÆÔ£πÔ£∞Ô£ª| ||p c x f p MASK v x v VÔÅç  (6)\nFinally, M ‚±∞ integrates P, D, Erank, ‚Ç∏, and ∆î to classify each x ‚àà \nxq as ‚Äúdepressive‚Äù or ‚Äúnormal. ‚Äù Consequently, we¬† enhance the \nexisting ProDepDet framework by incorporating ExDoRA  to \nimprove the reasoning of transferring the MPC modeling \nknowledge of an LLM M to depression detection. Two specific \nhyper-parameters, Œ∏1 and Œ∏2, are used to freeze M and to disable its \ndropout, maintaining the fundamentals of ICL ( Priyadarshana et¬†al., \n2024). The contextual embeddings of the classified xq are then \nprocessed through a non-linear transformation and normalized to \nfacilitate the formation of downstream tasks. The results are shown \nin Table¬†2.\n3.7 Downstream task formation\nTwo downstream tasks, Depressed Utterance Classification \n(DUC) and Depressed Speaker Identification (DSI), are formed \nconsidering the downstream tasks established for MPC modeling, \nincluding Reply Utterance Selection (RUS) and Speaker Identification \n(SI) (Lu et¬†al., 2023; Priyadarshana et¬†al., 2024). Here, we¬†evaluate the \ntransferability of the proposed framework using top-ranked \nexplanations for previously unseen DUC and DSI. DUC, specialized \nfrom RUS, identifies specific x ‚àà xq that are classified as containing \ndepressive content Ud and determines the exact speaker Sd. This can \nbe¬†presented as Equation 7.\n ( ){ } =1,\nxq\ndd nS U xq ÔÇÇ  (7)\nThe contextualized representations from the frozen model M  \nundergo a non-linear transformation to derive matching probabilities \nUDUC for the depressive context in xq. The loss value LDUC, related to \nthe probability scores obtained and their ground truth labels, is \ncalculated as Equation 8\n ( ) ( ) ( )Ô£ÆÔ£π= ‚àí +‚àí ‚àíÔ£∞Ô£ªlog 1 log 1DUC DUC DUCUUÔÅå zz  (8)\nwhere ‚±¨ = 1 when x ‚àà xq is an exact match for the depressive \ncontext and ‚±¨ = 0 otherwise.\nALGORITHM 1\nERR and MMR-based explanations ranking.\nTABLE¬†1 Sample of classes and label words.\nLabel Normal Depression\nLabel words Joy, happy, elation, \ncontentment\nHurt, anger, moody, bored, \nsadness\nPriyadarshana et al. 10.3389/frai.2025.1564828\nFrontiers in Artificial Intelligence 07 frontiersin.org\nDSI, specialized from SI, identifies the exact speaker Sd of an \nutterance. Since the speakers vary across multiple utterances within \nxq, DSI is designed to determine the exact speaker shared by multiple \nutterances classified as depressed. The speaker embeddings derived \nfrom M are further processed through a non-linear transformation \nlayer and then normalized to obtain the matching probability values \nUDSI for depressive x ‚àà xq. The cross-entropy loss LDSI, related to UDSI \nand the ground truth labels, is calculated as Equation 9\n \n( )\n‚àí\n=\n=‚àí ‚àë\n1\n1\n. log\nN\nDSI i DSI\nj\nUÔÅå z\n \n(9)\nwhere ‚±¨i = 1 when both Ui and Uj share the same speaker and \n‚±¨i = 0 otherwise.\n4 Experiments\nWe conducted experiments to answer the following \nresearch questions.\nRQ1: How does incorporating ERR- and MMR-based ranking \nimprove both diversity and semantic relevance in ranking \nLLM-generated free-text explanations?\nRQ2: How does leveraging free-text explanations of the retrieved \nICL demonstrations contribute to LLM transferability for contextually \ndifferent depression detection tasks?\nRQ3: How do the number, order, and diversity of the top-ranked \nexplanations enhance the robustness of the proposed framework?\n4.1 Datasets\nAs shown in Table¬†3, the proposed methods for explanation \ngeneration and depression detection are evaluated on five \nbenchmark datasets derived from MPC data, including human-\nannotated posts, comments, and chats from Twitter and Reddit. \nThe IMHI corpus for the depression detection sub-task ( Pirina and \n√á√∂ltekin, 2018 ) is used to validate the generated top-ranked \nsynthetic explanations. The RSDD corpus is used to generate D and \nevaluate the DUC task. Twitter Depression 2022 ( Cha et¬†al., 2022 ) \nis used to create classes and labels for ∆î and evaluate DUC. For the \nDSI task, the eRisk 18 T2 ( Losada et¬†al., 2018 ) and eRisk 22 T2 \n(Losada et¬†al., 2019 ) datasets are used, with a particular focus on \ncapturing speaker characteristics in the context of MPC modeling. \nTable¬†4 shows a summary of depressed and normal speakers across \nthese datasets.\nTo ensure consistency, data balancing techniques, such as \nNearMiss (Jeon and Lim, 2020) undersampling, were employed.\n4.2 Baselines\nWe used 7B-parameter LLMs, such as Mistral-7B-Instruct, \nGemma-7B (Team et¬†al., 2024), LLaMA-2-7B-chat (Touvron et¬†al., \n2023), and MentaLLaMA-chat-7B (Y ang et¬†al., 2024), to evaluate the \nexplanation generation capabilities of ExDoRA. These models excel at \ngenerating detailed, relevant, and context-sensitive free-text \nexplanations and are well-suited for processing long-form, multi-turn \nMPC data while simulating model reasoning processes. To evaluate \nexplanation ranking, we¬†used several similarity models: all-MiniLM-\nL6-v2, optimized for processing longer MPCs in large corpora without \nperformance bottlenecks; all-mpnet-base-v2, adept at detecting subtle \ncontext shifts between different speakers; and all-distilroberta-v1, fine-\ntuned to capture semantic continuity and identify speaker roles across \nconversation threads against similar ranking methods, including \nEGLR by Liu et¬†al. (2024), ExplRank by Y e and Durrett (2022), and a \nGPT-3-based method by Wiegreffe et¬†al. (2021).\nFor the evaluations of DUC, we¬†used WSW (Priyadarshana et¬†al., \n2023), MentalBERT (Ji et¬†al., 2022), and DisorBERT (Aragon et¬†al., \n2023) as 100 M-300 M-parameter LLMs aware of MPC semantic \nmodeling, with MentalBERT and DisorBERT being particularly used \nto detect mental disorders. For the evaluations of DSI, we¬†used WSW , \nSA-BERT (Gu et¬† al., 2020 ), and MPC-BERT ( Gu et¬† al., 2021 ) as \nspeaker-aware MPC modeling LLMs. Additionally, LLaMA 2-7B \n(Touvron et¬†al., 2023) and MentaLLaMA-7B (Y ang et¬†al., 2024) were \nused as open-source 7B-parameter LLMs and ChatGPT ( OpenAI, \n2022) and GPT-4 ( Achiam et¬† al., 2023 ) were adopted as 175B-\n1.76 T-parameter LLMs to evaluate both DUC and DSI.\n4.3 Implementation details\nThe explanation ranking logic of ExDoRA and the OOD task \ntransfer logic for depression detection were implemented using \nPython libraries, specifically PyTorch 2.0 3 and Hugging Face \nTransformers.4 We¬† used UDR 5 as the demonstration retriever. \nWe¬† divided the MPC data into three categories based on session \nlength, Len-5, Len-10, and Len-15, and experimented with two \ndifferent prompt lengths (l) of 70 and 90. Two hyper-parameters, such \nas a maximum length of 3,000 and the number of generated \nexplanations of 3, were used to generate explanations for each D. The \n3 https://pytorch.org/\n4 https://github.com/huggingface/transformers\n5 https://github.com/KaiLv69/UDR\nTABLE¬†2 Classification results.\nUtterance Label\nWhere have you¬†been? Normal\nOh! I¬†wanted to hurt myself. Depression\nWhat happened to you? Normal\nI was broken, it‚Äôs shocking. Depression\nTABLE¬†3 Statistical summary of datasets.\nBenchmarks Train Validation Test\nReddit IMHI Corpus 2024 1,003 430 405\nReddit SDD Corpus 2017 609,471 684,788 599,573\nReddit eRisk 18 T2 2018 49,557 20,332 20,333\nReddit eRisk 22 T2 2022 40,242 32,264 35,332\nTwitter Depression 2022 35,586 15,000 15,000\nPriyadarshana et al. 10.3389/frai.2025.1564828\nFrontiers in Artificial Intelligence 08 frontiersin.org\nlambda diversity and the decay factor were kept at 0.5 and 0.85, \nrespectively, to obtain the top two explanations. We¬†used other hyper-\nparameters for downstream tasks, such as GELU activations \n(Hendrycks and Gimpel, 2022) for non-linear transformations, Adam \noptimizer (Kingma, 2014) with a learning rate of 0.0005, a warmup \nproportion of 0.1, and enabled parameters Œ∏1 and Œ∏2. The training was \nconducted over 30 epochs for 900 h (30 h per epoch) using dual \nNVIDIA RTX 3090 Ti 24GB GPUs with a batch size of 16. We¬†used \nApplication Programming Interface endpoints provided by OpenAI \nfor evaluating closed-source LLMs. To ensure a fair comparison, all \nLLMs and similarity models used for explanation generation were \nevaluated under the same data and hyperparameter settings. ExDoRA \nhas been made open-source to facilitate the replication of our results.6\n4.4 Metrics and results\nThe generated explanations were evaluated based on two primary \ncriteria: factuality and consistency. Factuality assessment focuses on \nensuring that the generated explanations are contextually relevant and \nfaithfully grounded. Inspired by Y e and Durrett (2022), we¬†evaluated \nfactuality using the lexical overlap between top-ranked explanations \nand ground truth explanations from IMHI. Considering ei as the \ncandidate explanation and sg as the ground truth, the factuality \nestimation is defined as Equation 10.\n \n( )\n‚à©=max\ni\nig\nie\ni\nesfactuality e e\n‚õÇ‚õÇ\n‚õÇ‚õÇ  \n(10)\nWe used the top three explanations generated for 100 queries and \nvalidated them against the expert-written explanations from the IMHI \ncorpus, sourced from multiple corpora, including DR and CAMS.7\nTo evaluate the consistency of the generated explanations, \nwe¬† used BERTScore ( Zhang et¬† al., 2020 ) to assess how well the \nexplanations align with consistent reasoning across various examples, \nbuilding on Y e et¬† al. (2023), who empirically demonstrated the \nimpact of LLM-generated explanations on downstream performance. \nThe consistency is reformulated in terms of an alignment between the \ndemonstration sample, its ground truth label, and the generated \nexplanation. We¬†selected 200 human-annotated depression samples \nfrom the RSDD corpus and then generated explanations to evaluate \n6 https://github.com/KUAS-ubicomp-lab/ExDoRA\n7 https://github.com/SteveKGYang/MentalLLaMA/tree/\nmain?tab=readme-ov-file#expert-written-golden-explanations\nthe consistency. Factuality and consistency together ensure that the \ngenerated explanations align with the context and contribute to the \nmodel‚Äôs reasoning for the final prediction. Table¬†5 shows the factuality \ncomparison of the explanations using multiple similarity models \nagainst explanation ranking methods. Figure¬†4 shows the consistency \ncomparison Figure¬†4a with and Figure¬†4b without (w/o) the proposed \nhybrid ranking.\nTo evaluate the DUC task, we¬†used R 10@1, an enhanced recall \nmetric commonly applied in SOTA models for MPC-based response \nselection tasks, such as RUS. This metric measures the rate at which \nthe first correctly classified depressed utterances are identified among \n10 candidates from RSDD and Twitter Depression 2022 corpora. \nTable¬†6 shows the results of the LLM‚Äôs OOD transferability for DUC \nusing zero-shot (ZS), 2-shot (2S), and 5-shot (5S) D, both with and \nwithout (w/o) the top two explanations. To evaluate DSI, the F1 score \nwas selected as the metric for the eRisk 18 T2 and eRisk 22 T2 \nbenchmarks. Table¬†7 shows LLM OOD transferability results using \nZS, 2S, and 5S D, both with and without (w/o) the top \ntwo explanations.\n4.5 Ablation studies\nA series of ablation studies were conducted on random 5S D \nsplits of the Twitter Depression corpus and eRisk 22 T2 corpus to \nvalidate the generalizability of the proposed methods. These studies \nfocused on evaluating the number, order, and diversity of top-ranked \nexplanations with and without (w/o) the hybrid ranking component \nof ExDoRA.\nThe number of top-ranked explanations from the Twitter \nDepression corpus was used to compare ExDoRA‚Äôs performance in \nDUC. Figure¬†5 shows the evaluation results of the best-performing \nLLMs for DUC in terms of R10@1 using the top-1, top-2, and top-3 \nranked explanations.\nThe order of top-ranked explanations from the RSDD and Twitter \nDepression 2022 corpora was used to evaluate ExDoRA‚Äôs \nperformance. Figure¬† 6 shows the evaluation results for the best-\nperforming LLMs in DUC in terms of R10@1 using the least-to-most \nand most-to-least ordering of the top three explanations. The most-\nto-least prioritizes explanations with the highest semantic relevance, \nplacing them at the beginning, while the least-to-most ordering \npositions the least relevant explanations first.\nThe diversity of top-ranked explanations from the RSDD corpus \nwas used to compare ExDoRA‚Äôs performance in DUC. Two sets of Erank \nwere generated using Mistral-7B-Instruct and Gemma-7B LLMs to \ncreate a diverse range of the top three explanations. Figure¬†7 shows the \nevaluation results of the best-performing LLMs in DUC in terms of \nR10@1 using the two different explanation sets.\nTABLE¬†4 Statistical summary of users and posts.\nBenchmarks # User # Post\nDepressed Normal Depressed Normal\nReddit SDD Corpus 2017 9, 000 107,000 920,184 960,487\nReddit eRisk 18 T2 2018 134 354 25,138 64,274\nReddit eRisk 22 T2 2022 98 658 35,332 153,436\nTwitter Depression 2022 38 2,457 30,497 35,089\nPriyadarshana et al. 10.3389/frai.2025.1564828\nFrontiers in Artificial Intelligence 09 frontiersin.org\n5 Discussion\n5.1 ExDoRA performance\nThe evaluation results in Table¬†5 indicate that the combination of \nMistral-7B-Instruct with all-MiniLM-L6-v2 effectively generates \nhighly factual free-text explanations using the proposed ERR- and \nMMR-based ranking method. Mistral-7B-Instruct, fine-tuned on \ninstruction-based data to enhance understanding of nuanced text \nfeatures, outperformed other open-source LLMs in generating the \nmost appropriate and context-sensitive free-text explanations, \nparticularly when paired with all-MiniLM-L6-v2 as M S. The \ngenerated explanations are then ranked using multiple ranking \nmethods, and the results show that our proposed ERR- and \nMMR-based methods perform well compared to other alternative \nranking methods. Particularly, Mistral-7B-Instruct with all-MiniLM-\nL6-v2 demonstrated significant performance improvements, \nachieving 8.42 and 2.96% gains in lexical overlap when ranking \nexplanations using the ERR- and MMR-based ranking method, \ncompared to all-mpnet-base-v2 and all-distilroberta-v1. This \nhighlights the superiority of both M S and the proposed ranking \nmethod in processing longer MPCs within large corpora. The method \naccounts for both diversity and semantic relevance in ranking \nmultiple generated explanations while avoiding performance \nbottlenecks. Therefore, RQ1‚Äî How does incorporating ERR- and \nMMR-based ranking improve both diversity and semantic relevance in \nranking LLM-generated free-text explanations?‚Äîcan be¬†considered \nanswered. Figure¬†4a shows that Mistral-7B-Instruct outperformed \nother open-source LLMs paired with all-MiniLM-L6-v2 by a \nmaximum margin of 2.81% in BERTScore, aligning the top three \ngenerated explanations with consistent reasoning across various \nexamples. However, the performance dropped substantially by up to \n11.17% in BERTScore, as shown in Figure¬†4b, when the top-ranked \nexplanations were excluded.\n5.2 Performance on DUC and DSI\nExperiments on DUC and DSI showed that ExDoRA enhanced the \nadaptation of acquired knowledge of the source LLM to modeling \ncontextually different depression detection tasks by leveraging the free-\ntext explanations of the retrieved ICL demonstrations. Table¬†6 shows that \nWSW , the SOTA LLM for MPC modeling, outperformed both open-\nsource and closed-source LLMs for DUC in 2S and 5S demonstration \nsettings. While MentaLLaMA-7B, the second best-performing LLM, \nshowed some effectiveness without demonstrations and explanations in \ncertain test cases, WSW achieved SOTA performance in DUC when \ndemonstrations and their top-ranked explanations were available. This \nhighlights ExDoRA‚Äôs effectiveness in transferring MPC modeling \nknowledge of LLMs for depression detection. The performance of WSW \nin DUC was improved by significant margins of 20.59 and 20.22% in \nterms of R 10@1 when using 5S demonstrations with the top two \nexplanations, compared to ZS examples without explanations for MPC \ndata split with Len-5 and l = 90¬†in RSDD and Twitter Depression 2022 \ncorpora. However, the performance slightly dropped by margins of up \nto 1.44 and 1.83% in terms of R 10@1 when using 2S and 5S \ndemonstrations without the top-ranked explanations, highlighting the \nimportance of ExDoRA for LLM OOD knowledge transfer. The overall \nperformance marginally dropped as the MPC session length increased, \nalthough longer prompt lengths contributed to integrating richer \ncontextual representations with demonstrations and explanations. The \nZS demonstration performance of LLMs such as GPT-4 fell short \ncompared to the 100 M-300 M-parameter LLMs due to the absence of \nexplicit information related to MPC understanding. However, LLM \nperformance on DUC improved to near-SOTA levels with the inclusion \nof MPC explicit data in 2S and 5S demonstration settings with the top \ntwo explanations.\nFor the DSI task, determining the exact speaker of an utterance \nclassified as depressed presents a challenge when speaker details are \nnot available. Table¬†7 shows that WSW performed better than both the \nTABLE¬†5 Results on the factuality of the generated explanations in terms of lexical overlap (%).\n‚Üì LLM / Ranking method ‚Üí EGLR ExplRank GPT-3-based ERR-MMR\nAll-distilroberta-v1 as MS\nMistral-7B-Instruct 40.21¬†¬± 0.16 47.12¬†¬± 0.12 52.14 ¬± 0.13 61.27¬†¬± 0.13\nGemma-7B 39.34 ¬± 0.21 43.17 ¬± 0.12 54.28¬†¬± 0.11 57.31 ¬± 0.21\nLLaMA-2-7B-chat 37.24 ¬± 0.12 41.37 ¬± 0.14 52.19 ¬± 0.17 52.73 ¬± 0.22\nMentaLLaMA-chat-7B 38.53 ¬± 0.23 42.28 ¬± 0.12 53.07 ¬± 0.12 54.71 ¬± 0.12\nAll-mpnet-base-v2 as MS\nMistral-7B-Instruct 39.08¬†¬± 0.13 43.58¬†¬± 0.21 49.71¬†¬± 0.11 55.81¬†¬± 0.16\nGemma-7B 38.31 ¬± 0.17 41.16 ¬± 0.22 48.83 ¬± 0.12 52.37 ¬± 0.21\nLLaMA-2-7B-chat 36.47 ¬± 0.21 38.23 ¬± 0.11 45.37 ¬± 0.12 49.93 ¬± 0.17\nMentaLLaMA-chat-7B 37.38 ¬± 0.13 39.14 ¬± 0.21 46.57 ¬± 0.21 50.07 ¬± 0.24\nAll-MiniLM-L6-v2 as MS\nMistral-7B-Instruct 44.51¬†¬± 0.21 49.62¬†¬± 0.34 56.81¬†¬± 0.33 64.23¬†¬± 0.31\nGemma-7B 42.41 ¬± 0.32 46.37 ¬± 0.22 53.27 ¬± 0.31 59.34 ¬± 0.28\nLLaMA-2-7B-chat 39.71 ¬± 0.24 43.82 ¬± 0.17 51.21 ¬± 0.28 56.72 ¬± 0.17\nMentaLLaMA-chat-7B 41.52 ¬± 0.18 44.27 ¬± 0.23 53.13 ¬± 0.21 58.21 ¬± 0.26\nSOTA performance is shown in bold.\nPriyadarshana et al. 10.3389/frai.2025.1564828\nFrontiers in Artificial Intelligence 10 frontiersin.org\nFIGURE¬†4\nConsistency comparison in terms of BERTScore for three explanations.\nTABLE¬†6 Evaluation results of DUC.\nSetting Model RSDD Corpus Twitter Depression 2022 Corpus\nLen-5 Len-10 Len-15 Len-5 Len-10 Len-15\nl¬†= 70 l¬†= 90 l¬†= 70 l¬†= 90 l¬†= 70 l¬†= 90 l¬†= 70 l¬†= 90 l¬†= 70 l¬†= 90 l¬†= 70 l¬†= 90\nZS D \n(w/o E)\nMentalBERT 70.04 71.24 67.81 69.62 62.83 64.41 67.81 68.54 65.07 67.93 64.59 65.97\nDisorBERT 68.73 69.93 65.48 65.02 63.27 64.11 66.83 68.07 64.37 66.71 64.13 65.86\nWSW 72.61 74.08 69.37 70.14 65.81 67.08 71.03 72.95 69.02 71.87 66.81 68.01\nLLaMA 2-7B 69.02 71.27 68.83 70.09 64.04 66.19 70.09 72.04 68.27 70.24 65.19 67.14\nMentaLLaMA 72.86 74.27 70.08 71.38 66.29 68.64 72.26 73.57 70.11 72.27 68.18 70.07\nChatGPT 55.21 57.12 53.29 54.83 52.04 53.87 49.72 51.04 48.01 50.27 46.87 48.31\nGPT-4 59.34 62.28 58.06 60.17 55.67 57.34 57.81 59.37 55.82 57.08 54.05 56.27\n2S D \n(with E)\nMentalBERT 84.67 85.49 80.37 82.93 79.67 81.63 81.69 83.61 80.37 81.64 79.67 80.38\nDisorBERT 83.06 84.69 81.64 82.69 79.33 81.17 81.08 82.68 79.61 80.37 78.05 79.61\nWSW 87.28 88.93 84.06 86.28 82.27 84.07 84.67 86.08 82.46 84.06 81.93 82.28\nLLaMA 2-7B 82.27 83.97 81.06 82.37 79.67 81.36 80.39 82.64 79.38 81.28 78.19 80.34\nMentaLLaMA 84.93 86.73 82.48 84.61 80.35 82.97 82.67 84.05 80.88 82.06 80.24 81.09\nChatGPT 72.04 74.43 70.11 72.27 69.91 70.03 68.81 70.26 66.30 68.03 64.55 66.21\nGPT-4 74.39 76.68 72.13 74.44 70.12 72.61 72.39 74.47 70.29 72.34 68.51 70.63\n2S D \n(w/o E)\nWSW 85.73 87.49 82.64 84.08 80.39 81.72 82.93 84.76 80.34 82.07 79.77 80.21\nMentaLLaMA 82.53 84.67 81.87 83.73 79.61 81.89 81.76 83.54 79.82 81.94 79.37 80.28\nGPT-4 72.03 74.88 70.63 69.51 68.51 69.21 69.47 71.31 67.54 68.91 65.04 67.53\n5S D \n(with E)\nMentalBERT 90.52 92.24 89.61 91.16 87.89 89.31 89.92 90.28 87.35 88.68 85.61 86.53\nDisorBERT 90.67 91.28 88.62 89.32 86.62 87.93 89.21 90.01 88.28 89.65 86.24 87.68\nWSW 92.57 94.67 90.55 92.64 88.59 90.51 91.21 93.17 89.64 91.34 87.62 89.52\nLLaMA 2-7B 89.03 90.56 87.38 88.55 85.57 86.69 87.08 88.61 85.61 86.39 83.81 85.28\nMentaLLaMA 91.28 93.67 89.80 91.28 87.96 89.62 90.08 91.37 88.76 90.21 86.57 88.09\nChatGPT 81.28 83.24 79.51 82.27 77.81 79.20 78.27 80.11 76.59 78.21 75.12 76.58\nGPT-4 86.91 89.14 85.27 88.16 83.21 86.34 84.18 86.34 82.61 84.63 81.37 83.62\n5S D \n(w/o E)\nWSW 91.24 92.84 89.31 91.22 86.21 88.51 89.01 91.26 87.61 88.61 85.72 87.31\nMentaLLaMA 88.97 89.76 87.89 89.73 85.97 87.29 88.94 90.73 87.04 88.13 84.39 86.73\nGPT-4 84.52 86.81 83.46 84.24 81.34 82.51 82.84 84.26 80.24 82.44 79.92 81.31\nSOTA performance is shown in bold. The second-best performance is shown with underlining. ZS, 2S, and 5S stand for zero-shot, 2-shot, and 5-shot, respectively; D and E stand for \ndemonstrations and explanations.\nPriyadarshana et al. 10.3389/frai.2025.1564828\nFrontiers in Artificial Intelligence 11 frontiersin.org\nTABLE¬†7 Evaluation results of DSI.\nSetting Model Reddit eRisk 18 T2 Corpus Reddit eRisk 22 T2 Corpus\nLen-5 Len-10 Len-15 Len-5 Len-10 Len-15\nl¬†= 70 l¬†= 90 l¬†= 70 l¬†= 90 l¬†= 70 l¬†= 90 l¬†= 70 l¬†= 90 l¬†= 70 l¬†= 90 l¬†= 70 l¬†= 90\nZS D \n(w/o E)\nSA-BERT 59.18 63.27 58.31 61.63 56.34 59.61 54.73 57.76 52.08 54.63 50.33 52.74\nMPC-BERT 63.52 65.61 61.04 63.37 59.48 61.21 58.61 60.27 56.83 58.81 55.07 57.96\nWSW 65.89 67.04 62.84 64.34 59.97 62.27 61.05 63.26 59.34 61.11 57.89 59.06\nLLaMA 2-7B 58.27 60.01 55.59 57.04 53.59 55.04 52.24 54.49 50.07 52.67 48.97 50.14\nMentaLLaMA 62.28 64.33 60.04 62.57 58.67 60.31 57.89 59.34 55.27 57.75 53.04 55.79\nChatGPT 46.58 48.21 43.58 45.37 40.27 42.26 44.71 46.92 42.58 44.24 39.61 41.16\nGPT-4 49.67 52.24 45.59 47.47 42.64 44.07 46.84 48.39 44.91 46.37 41.38 43.64\n2S D \n(with E)\nSA-BERT 76.27 78.28 74.61 76.68 72.31 74.06 72.81 74.28 70.06 72.34 68.34 70.13\nMPC-BERT 79.02 81.24 77.62 79.28 75.53 77.01 76.34 78.19 74.62 76.29 72.61 74.03\nWSW 82.06 84.52 80.17 82.26 78.61 80.31 79.61 81.61 77.64 79.34 75.24 77.18\nLLaMA 2-7B 77.28 79.34 75.06 77.29 73.61 75.39 73.28 75.61 71.05 73.64 69.28 70.38\nMentaLLaMA 80.38 82.34 78.59 80.14 76.64 78.67 77.82 79.64 75.94 77.51 73.39 75.06\nChatGPT 66.27 68.61 64.59 66.07 62.37 64.58 62.04 64.37 60.72 62.46 58.22 59.67\nGPT-4 72.57 74.46 70.06 72.31 68.15 70.34 68.34 70.16 66.91 68.32 64.43 66.33\n2S D \n(w/o E)\nWSW 79.05 81.26 76.61 78.11 73.25 75.21 75.37 77.51 72.27 74.61 70.11 72.06\nMentaLLaMA 76.27 78.12 74.06 76.34 72.18 74.34 72.34 74.58 70.31 72.19 68.22 70.32\nGPT-4 68.24 70.06 66.37 68.31 64.72 66.32 63.28 65.66 61.34 63.61 59.82 61.04\n5S D \n(with E)\nSA-BERT 79.34 81.04 77.64 79.81 75.32 76.68 75.57 77.08 72.92 75.38 71.05 73.64\nMPC-BERT 82.26 84.05 80.06 82.11 78.09 80.24 78.61 80.62 76.24 78.16 74.28 76.08\nWSW 86.62 88.62 84.59 86.31 82.66 84.51 82.27 84.05 80.22 82.36 78.61 80.61\nLLaMA 2-7B 80.36 82.64 78.68 80.15 76.64 78.37 77.62 79.38 75.25 77.68 73.91 75.57\nMentaLLaMA 84.68 86.24 82.14 84.35 80.06 82.11 79.89 81.24 77.67 79.34 75.69 77.51\nChatGPT 76.37 77.83 74.55 76.06 72.01 74.68 72.25 74.64 70.06 72.64 68.83 70.23\nGPT-4 81.05 83.68 79.64 81.05 77.69 79.34 77.68 79.73 75.25 77.61 73.61 75.38\n5S D \n(w/o E)\nWSW 84.36 86.62 82.19 84.67 80.67 81.29 79.68 81.16 77.25 79.61 75.61 77.62\nMentaLLaMA 82.21 84.59 80.11 82.64 78.93 79.21 76.39 78.21 74.59 76.31 72.83 74.39\nGPT-4 78.28 80.34 76.59 78.37 74.32 76.11 74.24 76.13 72.28 74.05 70.37 72.13\nSOTA performance is shown in bold. The second-best performance is shown with underlining. ZS, 2S, and 5S stand for zero-shot, 2-shot, and 5-shot, respectively; D and E stand for \ndemonstrations and explanations.\nFIGURE¬†5\nThe effect of the number of top-ranked explanations with and w/o the hybrid ranking.\nPriyadarshana et al. 10.3389/frai.2025.1564828\nFrontiers in Artificial Intelligence 12 frontiersin.org\nclinical-based LLMs, such as MentaLLaMA-7B, and generative LLMs, \nsuch as GPT-4, in shifting MPC speaker identification to DSI due to \nthe lack of explicit speaker information in those LLMs. The \nperformance of WSW for DSI significantly improved by margins of \n21.58 and 20.79% in terms of F1 score using 5S demonstrations with \nthe top two explanations, compared to ZS demonstrations without \nexplanations for MPC data split with Len-5 and l = 90¬†in eRisk 18 T2 \nand eRisk 22 T2 corpora. This is because speaker-aware MPC \nmodeling LLMs, including SA-BERT, MPC-BERT, and WSW , can \nincorporate implicit speaker details into MPC discourse structures of \nwhich other LLMs are not aware. WSW , in particular, is the SOTA \nLLM to process speaker details in complex discourse structures, such \nas root-level and sub-level utterances classified as depressed. \nConversely, the performance slightly dropped by maximum margins \nof 3.26 and 2% in terms of F1 score when using 2S and 5S examples, \nrespectively, without the top-ranked explanations, highlighting the \nsignificance of ExDoRA‚Äôs reason-then-predict approach for previously \nunseen DSI. Compared to DUC, the ZS performance of LLMs was \ninferior to that of 100 M-300 M-parameter LLMs, such as WSW and \nMPC-BERT, for speaker identification in MPC modeling due to the \nabsence of explicit speaker information. However, LLM performance \non DSI improved to near-SOTA levels with MPC explicit data in 2S \nand 5S demonstration settings with the top-ranked explanations. \nAlthough the overall DSI performance slightly dropped with increased \nMPC session length, it improved with increased prompt length, \nleading to WSW , MentaLLaMA-7B, and GPT-4 being the top \nperformers. It can be¬† concluded that selecting in-context \ndemonstrations with their top-ranked explanations for few-shot \nprompting offers SOTA performance in OOD tasks. Therefore, \nRQ2‚ÄîHow does leveraging free-text explanations of the retrieved ICL \ndemonstrations contribute to LLM transferability for contextually \ndifferent depression detection tasks?‚Äîcan be¬†considered answered.\n5.3 Impact of ablation studies\nWe conducted several ablation studies using the best-performing \nmodels in 100 M-300 M-parameter LLMs, open-source 7B-parameter \nLLMs, and closed-source 175B-1.76 T-parameter LLMs for DUC and \nDSI. The results on the effect of the number of top-ranked explanations, \npresented in Figures¬† 5a,b, revealed that the performance of DUC \nsignificantly decreased by margins of 16.54, 15.43, and 17.73% in terms \nof R10@1 when using three explanations for WSW , MentaLLaMA-7B, \nand GPT-4, after removing the hybrid ranking component of \nExDoRA. This decline can be¬†attributed to the diminished quality of the \nselected demonstrations and the reduced reasoning capability of LLMs \nfor depression detection tasks when their accompanying explanations \nwere absent. Furthermore, we¬†observed that the performance of DUC \nFIGURE¬†6\nThe effect of the order of top-ranked explanations with and w/o the hybrid ranking.\nFIGURE¬†7\nThe effect of the diversity of top-ranked explanations with and w/o the hybrid ranking.\nPriyadarshana et al. 10.3389/frai.2025.1564828\nFrontiers in Artificial Intelligence 13 frontiersin.org\ndecreased as the number of ranked explanations increased beyond the \ntop two. This reduction in performance can be¬†attributed to the fact that \nwhile the number of contextual representations of demonstrations and \nthe top explanations for the previously unseen depression detection \ntasks increased, the LLMs‚Äô ability to capture and integrate this clinical \ncontext with the contextual representations of the MPC modeling task \ndiminished due to scalability issues.\nMoreover, we¬†conducted a few ablation studies on the order of the \ntop-ranked explanations. Figure¬†6 reveals that the LLMs performed \nbetter for DUC with the most-to-least ordering of explanations on the \nTwitter Depression 2022 corpus, whereas the opposite was observed \non the RSDD corpus. Similar to the behavior for the number of \nexplanations, the performance of WSW for DUC significantly \ndecreased by margins of 24.97 and 24.01% in terms of R10@1 for the \nmost-to-least ordering of explanations on Twitter Depression 2022 \nand RSDD corpus, respectively, after removing the hybrid ranking \ncomponent. Despite some improvements with the least-to-most \nordering on the RSDD corpus, these gains were smaller compared to \nthe most-to-least ordering on Twitter Depression 2022. This indicates \nthat the order of explanations is data-dependent, and the most-to-least \nordering contributes more significantly to ExDoRA‚Äôs performance.\nThe diversity of explanations is rarely explored, particularly in \nICL-based in-domain task transfer, largely due to its complexity (Luo \net¬†al., 2024). Having a variety of explanations ensures that the model \ncaptures different reasoning paths, offering multiple perspectives on \nthe same depression cues while reducing the risk of overfitting specific \nexamples. Figure¬†7 shows that LLMs performed notably well for DUC \nwhen using the free-text explanations generated by Mistral-7B-\nInstruct as the benchmark for the diversity of demonstrations over the \nexplanations generated by Gemma-7B. However, compared to \nFigures¬† 7a,b, the downstream performance of WSW for DUC \nsignificantly decreased after removing the hybrid ranking component, \nwith reductions of 17.73 and 18.69% in terms of R10@1 for explanations \ngenerated by Mistral-7B-Instruct and Gemma-7B, respectively. This \ndecline can be¬†attributed to the high-quality explanations generated \nby Mistral-7B-Instruct, when paired with all-MiniLM-L6-v2, \ncontributing more significantly to downstream performance than \nother alternatives. The broader coverage of reasoning patterns through \na variety of explanations enhances overall downstream performance, \nas demonstrated by evaluations where the explanations were ranked \nby relevance, thereby improving transferability without compromising \npredictive accuracy. Therefore, RQ3‚ÄîHow do the number, order, and \ndiversity of the top-ranked explanations enhance the robustness of the \nproposed framework?‚Äîcan be¬†considered answered.\n5.4 Challenges, ethical considerations, and \nlimitations\nThere are a few challenges and limitations to our approach. A \nsignificant challenge is mitigating LLM bias in generating and \nselecting the top-ranked explanations. Although we¬†applied several \ntechniques such as ERR- and MMR-based ranking and cross-entropy \nloss to reduce LLM bias in the preference of explanations, careful \nattention must be¬† paid to the source prompts and the selected \nin-context examples. To address bias in social media data, strategies \nsuch as data augmentation and adversarial debiasing can help. Data \naugmentation techniques, such as synonym replacement and style \ntransfer, can introduce variation when generating synthetic \nexplanations. In addition, incorporating an adversarial network to \ndetect and mitigate bias in the generated explanations can improve \nthe balance, accuracy, and generalizability of both the explanation \ngeneration and the downstream depression classification across \ndifferent groups and contexts. Incorporating datasets from a wide \nvariety of sources other than Twitter and Reddit will better capture \npopulation diversity. Expert evaluations, including human-in-the-\nloop feedback and reinforcement learning from human feedback, \ncan further ensure unbiased explanation selection, model \ngeneralization, and robustness. Additionally, employing data \nanonymization is crucial to avoid confidentiality and accountability \nissues. Another significant challenge is preventing overfitting due to \nbiases inherent in soft prompts and verbalizers, which must \nbe¬†managed to avoid scalability issues. Carefully designed mixed \nprompt templates that combine both soft and manual templates may \nhelp mitigate overfitting. However, this approach falls outside the \nscope of the current study and still requires validation through \nempirical testing and expert review. Avoiding manipulations that \nlead LLMs to generate erroneous results in depression classification \nusing crafted prompts remains a difficult task. Although ExDoRA \nenhances transferability for OOD few-shot prompting, the \ndifferences between LLM reasoning mechanisms and human \nlearning in adapting knowledge to new tasks require \nfurther exploration.\nIncorporating LLM-generated explanations to work with sensitive \nmental health data raises several ethical concerns that must \nbe¬†carefully addressed. Bias and fairness in LLMs may result in biased \nexplanations if the in-context examples reflect stereotypes, impacting \nvulnerable groups. Despite their advanced natural language \nunderstanding for mental health screening, LLMs, like other models, \nare trained on vast amounts of human-generated content and \ninherently reflect human biases. Models trained on MPC data risk \ninadvertent privacy violations if user content is not anonymized. It is \nimportant to handle mental health-related data with care and ensure \nanonymity in future analyses. LLMs process sensitive user data, such \nas personal conversations and mental health disclosures, which poses \nrisks related to data breaches and misuse. Without robust privacy \nmeasures, including data encryption, secure storage, and access \ncontrols, confidential information could be¬† exposed, leading to \npotential harm to individuals. Accountability is another key concern. \nIf an LLM-generated explanation or classification leads to inaccurate \nmental health assessments or inappropriate recommendations, \ndetermining responsibility becomes difficult, especially when the \nmodel operates as a ‚Äúblack-box. ‚Äù Carefully designed prompt templates \nand verbalizers should be¬† used to mitigate uncertainty, user \naccountability, and confidentiality-related issues in ICL-based \ndepression detection tasks. Accountability and explainability demand \nthat explanations align with clinical standards to avoid misleading \nhealthcare decisions. The psychological effects and clinical relevance \nshould be¬†thoughtfully evaluated to determine the quality of generated \nexplanations, in-context examples, and prompt designs utilized in \ndownstream tasks.\nThe present study is limited to generating free-text explanations, \nand the proposed ranking needs to be¬†evaluated alongside explanations \ngenerated by other techniques, such as structured explanations. \nAlthough we¬†limited the demonstration retriever to UDR due to its \neffectiveness in retrieving demonstrations from unseen datasets across \nPriyadarshana et al. 10.3389/frai.2025.1564828\nFrontiers in Artificial Intelligence 14 frontiersin.org\nmultiple ICL tasks, incorporating other retrieval techniques could \nimprove the system‚Äôs robustness. The validation of ExDoRA was \nconducted using the IMHI corpus, which is currently the only dataset \nfor interpretable mental health analysis in social media, highlighting \na significant limitation. To ensure the generalizability of our findings, \nadditional evaluations should be¬†conducted on relevant benchmarks \nin other fields, including in the clinical domain. Additionally, the \ngenerated free-text explanations should be¬†externally validated by \nhuman experts, incorporating their feedback to enhance plausibility \nand informativeness, as our study relied solely on automatic \nevaluations. In this study, we¬†focused on transferring LLM‚Äôs knowledge \nof MPC modeling to depression detection as a reason-then-predict \napproach. Future evaluations should explore alternative methods, \nsuch as predict-then-reason techniques like chain-of-thought \nreasoning, which may yield more promising results. Although task-\nspecific instructions are critical for certain few-shot reasoning tasks, \nthis study did not consider such instructions alongside in-context \nexamples and their explanations. Our approach was limited to open-\nsource 7B-parameter foundational LLMs for explanation generation. \nAlthough LLM quantization enables hosting much larger models, \nwe¬†restricted its use to avoid vulnerabilities such as jailbreaking and \nprompt injection. Further evaluations should include larger models, \nsuch as LLaMA-2-70B and LLaMA 3, with greater computational \nresources to assess how the proposed methods improve performance \nwith increased scale. Furthermore, designing multiple soft prompt \ntemplates and verbalizers tailored to the characteristics of the target \ntask could potentially impact the scalability of the proposed methods.\n6 Conclusion and future research\nIn this article, we¬†proposed ExDoRA, a novel framework designed \nto identify the most appropriate in-context examples using free-text \nexplanations for depression detection in MPC data using LLM OOD \ntask transferability. An ERR- and MMR-based hybrid method was \nintroduced as the key contribution of the study, designed to rank \nLLM-generated explanations by selecting the most semantically \nrelevant in-context examples closest to the input MPC query while \nbalancing diversity and semantic relevance. To achieve the previously \nunseen depression detection tasks, we¬† combined the in-context \nexamples and their explanations from unseen data with soft  \nembeddings of MPC input prompts using soft prompt templates and \nverbalizers. Evaluations on the IMHI corpus showed that ExDoRA \ngenerates highly factual and consistent free-text explanations. \nExtensive experiments were conducted using multiple LLMs for \ndownstream tasks, including depressed utterance classification and \ndepressed speaker identification. Evaluation results, including ablation \nstudies, demonstrated that ExDoRA achieves SOTA performance in \nLLM OOD knowledge transfer for depression detection by leveraging \nin-context explanations.\nEmploying reinforcement learning agents to enhance user \ninteractivity presents a promising avenue for ensuring unbiased, \ninterpretable explanation selection by refining the process as \nclinician-in-the-loop and enhancing LLM generalization. Improving \nthe domain-specific knowledge of ExDoRA with large-scale \ninterpretable mental health corpora could further enhance the \ngeneralization of our methods across diverse domains. Generating \nsynthetic explanations based on medical history and lifestyle data for \ndisease prediction would further validate the present findings and \ncontribute to developing universal clinical decision support systems. \nOur future studies will extend this framework to develop a multi-\nmodal screening tool for depression detection in MPC data, \nintegrating emotion-based approaches. Designing various \ndownstream tasks that utilize prompt intelligence and automation is \nan encouraging direction to further improve the interpretability and \nscalability of LLMs, potentially addressing a wider array of mental \nhealth issues.\nData availability statement\nThe original contributions presented in the study are included in \nthe article/supplementary material, further inquiries can be¬†directed \nto the corresponding author.\nAuthor contributions\nYP: Conceptualization, Formal analysis, Investigation, \nMethodology, Software, Validation, Writing¬†‚Äì original draft, Writing¬†‚Äì \nreview & editing. ZL: Supervision, Writing¬†‚Äì review & editing. IP: \nSupervision, Writing¬†‚Äì review & editing.\nFunding\nThe author(s) declare that no financial support was received for \nthe research and/or publication of this article.\nAcknowledgments\nWe sincerely thank the researchers who generously shared their \ndatasets, enabling and enriching the advancement of our research.\nConflict of interest\nThe authors declare that the research was conducted in the \nabsence of any commercial or financial relationships that could \nbe¬†construed as a potential conflicts of interest.\nGenerative AI statement\nThe authors declare that no Gen AI was used in the creation of \nthis manuscript.\nPublisher‚Äôs note\nAll claims expressed in this article are solely those of the authors \nand do not necessarily represent those of their affiliated organizations, \nor those of the publisher, the editors and the reviewers. Any product \nthat may be¬†evaluated in this article, or claim that may be¬†made by its \nmanufacturer, is not guaranteed or endorsed by the publisher.\nPriyadarshana et al. 10.3389/frai.2025.1564828\nFrontiers in Artificial Intelligence 15 frontiersin.org\nReferences\nAchiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F . L., et al. Gpt-4 \ntechnical report. Arxiv [Preprint] doi: 10.48550/arXiv.2303.08774 (2023).\nAhn, W . K., Brewer, W . F ., and Mooney, R. J. (1992). Schema acquisition from a single \nexample. J. Exp. Psychol. Learn. Mem. Cogn.  18, 391‚Äì412. doi: \n10.1037/0278-7393.18.2.391\nAragon, M., Monroy, A. P ., Gonzalez, L., Losada, D. E., and Montes, M.. DisorBERT: \na double domain adaptation model for detecting signs of mental disorders in social \nmedia. In Proceeding. of the 61st annual meeting of the Association for Computational \nLinguistics (Volume 1: Long Papers) (2023) pp. 15305‚Äì15318.\nBao, E., P√©rez, A., and Parapar, J. (2024). Explainable depression symptom detection \nin social media. Health Inf. Sci. Syst. 12:47. doi: 10.1007/s13755-024-00303-9\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P ., et al. (2020). \nLanguage models are few-shot learners. Adv. Neural Inf. Process. Syst. 33, 1877‚Äì1901. \ndoi: 10.5555/3495724.3495883\nBurdisso, S., Errecalde, M. L., Montes, Y ., and G√≥mez, M. (2019). ‚ÄúTowards measuring \nthe severity of depression in social media via text classification‚Äù in XXV Congreso \nArgentino de Ciencias de la Computaci√≥ n (CACIC). Universidad Nacional de \nR¬¥ƒ±o Cuarto.\nBurdisso, S. G., Errecalde, M. L., and Montes y G√≥mez, M. (2021). Using text \nclassification to estimate the depression level of reddit users. J. Comput. Sci. Technol. \n21:e1. doi: 10.24215/16666038.21.e1\nCamburu, O. M., Rockt√§schel, T., Lukasiewicz, T., and Blunsom, P .. e-snli: Natural \nlanguage inference with natural language explanations. NIPS'18: Proceedings of the \n32nd International Conference on Neural Information Processing Systems (2018).\nCarbonell, J., and Goldstein, J.. The use of MMR, diversity-based reranking for \nreordering documents and producing summaries. In Proceeding of the 21st annual \ninternational ACM SIGIR conference on research and development in information \nretrieval (1998) pp. 335‚Äì336.\nCha, J., Kim, S., and Park, E. (2022). A lexicon-based approach to examine depression \ndetection in social media: the case of twitter and university community. Hum. Soc. Sci. \nCommun. 9:325. doi: 10.1057/s41599-022-01313-2\nChapelle, O., Metlzer, D., Zhang, Y ., and Grinspan, P .. Expected reciprocal rank for \ngraded relevance. In Proceeding of the 18th ACM conf. On information and knowledge \nmanagement (2009) pp. 621‚Äì630.\nChowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., et al. (2023). \nPalm: scaling language modeling with pathways. J. Mach. Learn. Res.  24, 1‚Äì13. doi: \n10.48550/arXiv.2204.02311\nDing, N., Hu, S., Zhao, W ., Chen, Y ., Liu, Z., Zheng, H., et al. OpenPrompt: an open-\nsource framework for prompt-learning. In Proceeding of the 60th annual meeting of the \nAssociation for Computational Linguistics: System demonstrations (2022) pp. 105‚Äì113.\nGao, T., Fisch, A., and Chen, D.. Making pre-trained language models better few-shot \nlearners. In Proceeding. of the 59th Annual Meeting of the Association for \nComputational Linguistics and the 11th International Joint Conference on Natural \nLanguage Processing (2021) pp. 3816‚Äì3830.\nGhosh, S., and Anwar, T. (2021). Depression intensity estimation via social media: a \ndeep learning approach. IEEE Trans. Comput. Soc. Syst.  8, 1465‚Äì1474. doi: \n10.1109/TCSS.2021.3084154\nGu, J. C., Li, T., Liu, Q., Ling, Z. H., Su, Z., Wei, S., et al. Speaker-aware BERT for \nmulti-turn response selection in retrieval-based chatbots. In Proceeding. of the 29th \nACM international conference on Information & Knowledge Management (2020) pp. \n2041‚Äì2044.\nGu, J. C., Tao, C., Ling, Z., Xu, C., Geng, X., and Jiang, D.. MPC-BERT: a pre-trained \nlanguage model for multi-party conversation understanding. In Proceeding. of the 59th \nannual meeting of the Association for Computational Linguistics and the 11th \ninternational joint conference on natural language processing (volume 1: Long Papers) \n(2021) pp. 3682‚Äì3692.\nHendricks, L. A., Akata, Z., Rohrbach, M., Donahue, J., Schiele, B., and Darrell, T.. \nGenerating visual explanations. In 14th European Conference On computer vision \n(2016) pp. 3‚Äì19. Springer.\nHendrycks, D., and Gimpel, K.. A baseline for detecting misclassified and out-of-\ndistribution examples in neural networks. In International Conference on Learning \nRepresentations (2022).\nJeon, Y . S., and Lim, D. J. (2020). Psu: particle stacking undersampling method for highly \nimbalanced big data. IEEE Access. 8, 131920‚Äì131927. doi: 10.1109/ACCESS.2020.3009753\nJi, S., Zhang, T., Ansari, L., Fu, J., Tiwari, P ., and Cambria, E.. MentalBERT: publicly \navailable Pretrained language models for mental healthcare. In Proceeding of the 13th \nlanguage resources and evaluation conference (2022) pp. 7184‚Äì7190.\nKabir, M., Ahmed, T., Hasan, M. B., Laskar, M. T., Joarder, T. K., Mahmud, H., et al. \n(2023). DEPTWEET: a typology for social media texts to detect depression severities. \nComput. Hum. Behav. 139:107503. doi: 10.1016/j.chb.2022.107503\nKim, J., Rohrbach, A., Darrell, T., Canny, J., and Akata, Z.. Textual explanations for \nself-driving vehicles. In Proceeding of the European conference on computer vision \n(ECCV) (2018) pp. 563‚Äì578.\nKingma, D. P .. Adam: a method for stochastic optimization. In Proceeding of the \nInternational Conference on Learning Representations (2014).\nLampinen, A., Dasgupta, I., Chan, S., Mathewson, K., Tessler, M., Creswell, A., et al. \n(2022). Can language models learn from explanations in context? EMNLP 2022, \n537‚Äì563. doi: 10.18653/v1/2022.findings-emnlp.38\nLe-Hinh, N. T., Vo-Hoang, H. V ., Tran, T. N., and Cao, X. N.. Improving depression \nclassification in social media text with transformer ensembles. In Proceeding of the 12th \ninternational symposium on information and communication technology (2023) pp. \n554‚Äì561.\nLester, B., Al-Rfou, R., and Constant, N.. The power of scale for parameter-efficient \nprompt tuning. In Proceeding of the Conference on Empirical Methods in Natural \nLanguage Processing (2021) pp. 3045‚Äì3059.\nLi, X., Lv, K., Y an, H., Lin, T., Zhu, W ., Ni, Y ., et al. Unified demonstration retriever for \nin-context learning. In Proceeding of the 61st annual meeting of the Association for \nComputational Linguistics. (2023) pp. 4644‚Äì4668.\nLiu, S., Deng, N., Sabour, S., Jia, Y ., Huang, M., and Mihalcea, R.. Task-adaptive \ntokenization: enhancing long-form text generation efficacy in mental health and beyond. \nIn Proceeding of the 2023 Conference on Empirical Methods in Natural Language \nProcessing (2023) pp. 15264‚Äì15281.\nLiu, W ., Huang, Z., Wang, C., Peng, Y ., and Xie, S. (2024). EGLR: two-staged \nexplanation generation and language reasoning framework for commonsense question \nanswering. Knowl.-Based Syst. 286:111411. doi: 10.1016/j.knosys.2024.111411\nLiu, J. M., Li, D., Cao, H., Ren, T., Liao, Z., and Wu, J.. Chatcounselor: a large language \nmodels for mental health support. Arxiv [Preprint] sdoi: 10.48550/arXiv.2309.15461. (2023).\nLiu, X., Zheng, Y ., Du, Z., Ding, M., Qian, Y ., Y ang, Z., et al. (2024). GPT understands, \ntoo. AI Open 5, 208‚Äì215. doi: 10.1016/j.aiopen.2023.08.012\nLosada, D. E., Crestani, F ., and Parapar, J.. eRISK 2017: CLEF lab on early risk \nprediction on the internet: experimental foundations. In Expert IR Meets Multilinguality, \nMultimodality, and Interaction: 8th Intel Conference of the CLEF Association (2017) \npp. 346‚Äì360. Springer International Publishing.\nLosada, D. E., Crestani, F ., and Parapar, J.. Overview of eRisk: early risk prediction on \nthe internet. In Experimental IR meets Multilinguality, multimodality, and interaction: \n9th international conference of the CLEF association, (2018) pp. 343‚Äì361. Springer \nInternational Publishing.\nLosada, D. E., Crestani, F ., and Parapar, J.. Overview of erisk 2019 early risk prediction \non the internet. In Experimental IR meets Multilinguality, multimodality, and \ninteraction: 10th international conference of the CLEF association, (2019) \n11696:340‚Äì357. Springer International Publishing.\nLu, K. C., Thamrin, S. A., and Chen, A. L. (2023). Depression detection via \nconversation turn classification. Multimed. Tools Appl.  82, 39393‚Äì39413. doi: \n10.1007/s11042-023-15103-8\nLudan, J. M., Meng, Y ., Nguyen, T., Shah, S., Lyu, Q., Apidianaki, M., et al. Explanation-\nbased Finetuning makes models more robust to spurious cues. In Proceeding of the 61st \nannual meeting of the Association for Computational Linguistics (Volume 1: Long \nPapers) (2023) pp. 4420‚Äì4441.\nLuo, M., Xu, X., Liu, Y ., Pasupat, P ., and Kazemi, M. (2024). In-context learning with \nretrieved demonstrations for language models: a survey. Trans. Mach. Learn. Res. 2024, \n2835‚Äì8856.\nMalhotra, A., and Jindal, R. (2024). Xai transformer based approach for interpreting \ndepressed and suicidal user behavior on online social networks. Cog. Syst. Res.  \n84:101186. doi: 10.1016/j.cogsys.2023.101186\nMarasoviƒá, A., Beltagy, I., Downey, D., and Peters, M. E.. Few-shot self-rationalization \nwith natural language prompts. In Findings of the Assocation. for Computational \nLinguistics:(2022) pp. 410‚Äì424.\nNaseem, U., Dunn, A. G., Kim, J., and Khushi, M.. Early identification of depression \nseverity levels on reddit using ordinal classification. In Proceeding of the ACM web \nconference (2022) pp. 2563‚Äì2572.\nOpenAI. Introducing chatgpt. (2022) Available online at: https://openai.com/index/\nchatgpt/ (Accessed December 21, 2024).\nParanjape, B., Michael, J., Ghazvininejad, M., Hajishirzi, H., and Zettlemoyer, L.. \nPrompting contrastive explanations for commonsense reasoning tasks. In Findings of \nthe Association for Computational Linguistics: ACL-IJCNLP (2021) pp. 4179‚Äì4192.\nPirina, I., and √á√∂ltekin, √á.. Identifying depression on reddit: the effect of training data. \nIn Proceeding of the EMNLP workshop SMM4H: the 3rd social media mining for health \napplications workshop & shared task (2018) pp. 9‚Äì12.\nPriyadarshana, Y . H., Liang, Z., and Piumarta, I. (2023). Who says what (WSW): a \nnovel model for utterance-aware speaker identification in text-based multi-party \nconversations. WEBIST, 26‚Äì36. doi: 10.5220/0012164400003584\nPriyadarshana et al. 10.3389/frai.2025.1564828\nFrontiers in Artificial Intelligence 16 frontiersin.org\nPriyadarshana, Y . H., Liang, Z., and Piumarta, I. (2024). ProDepDet: out-of-domain \nknowledge transfer of pre-trained large language models for depression detection in \ntext-based multi-party conversations. In 2024 Intel joint Conference. On neural \nnetworks (IJCNN) pp. 1‚Äì8.\nQin, W ., Chen, Z., Wang, L., Lan, Y ., Ren, W ., and Hong, R.. Read, diagnose and chat: \ntowards explainable and interactive LLMs-augmented depression detection in social \nmedia. Arxiv [Preprint] doi: 10.48550/arXiv.2305.05138. (2023).\nQin, Y ., Lin, Y ., Yi, J., Zhang, J., Han, X., Zhang, Z., et al. Knowledge inheritance for \npre-trained language models. In Proceeding of the 2022 conference of the north \nAmerican chapter of the Association for Computational Linguistics: Human language \ntechnologies (2022) pp. 3921‚Äì3937.\nRajani, N. F ., Mc Cann, B., Xiong, C., and Socher, R.. Explain yourself! Leveraging \nlanguage models for commonsense reasoning. In Proceeding of the 57th annual meeting \nof the Association for Computational Linguistics (2019) pp. 4932‚Äì4942.\nRegier, D. A., Kuhl, E. A., and Kupfer, D. J. (2013). The DSM-5: classification and \ncriteria changes. World Psychiatry 12, 92‚Äì98. doi: 10.1002/wps.20050\nSchick, T., and Sch√ºtze, H.. Exploiting cloze-questions for few-shot text classification and \nnatural language inference. In Proceeding of the 16th Conf. Of the European chapter of the \nAssociation for Computational Linguistics: Main Volume (2021) pp. 255‚Äì269.\nSharma, A., Saxena, A., Kumar, A., and Singh, D.. Depression detection using \nmultimodal analysis with Chatbot support. In 2nd international conference on \ndisruptive technologies (ICDT) (2024) pp. 328‚Äì334. IEEE.\nShwartz, V ., West, P ., Le Bras, R., Bhagavatula, C., and Choi, Y .. Unsupervised \ncommonsense question answering with self-talk. In Proceeding of the 2020 conference \non empirical methods in natural language processing (EMNLP) (2020) pp. 4615‚Äì4629.\nSiino, M. Transmistral at semeval-2024 task 10: using mistral 7b for emotion discovery \nand reasoning its flip in conversation. In Proceeding of the 18th international workshop \non semantic evaluation (SemEval-2024) (2024) pp. 298‚Äì304.\nSu, Y ., Wang, X., Qin, Y ., Chan, C. M., Lin, Y ., Wang, H., et al. On transferability of \nprompt tuning for natural language processing. In Proceeding of the conference of the \nnorth American chapter of the Association for Computational Linguistics: Human \nlanguage technologies (2022) pp. 3949‚Äì3969.\nSun, S., Liu, Y ., Iter, D., Zhu, C., and Iyyer, M. (2024). ‚ÄúHow does in-context learning \nhelp prompt tuning?‚Äù in Findings of the Association for Computational Linguistics \n(EACL). eds. Y . Graham, and M. Purver, editors. Association for Computational \nLinguistics, 156‚Äì165.\nSun, J., Swayamdipta, S., May, J., and Ma, X.. Investigating the benefits of free-form \nrationales. In Findings of the Association for Computational Linguistics (2022) pp. \n5867‚Äì5882.\nTeam, G., Mesnard, T., Hardin, C., Dadashi, R., Bhupatiraju, S., Pathak, S., et al. \n(2024). Gemma: open models based on gemini research and technology.\nTouvron, H., Martin, L., Stone, K., Albert, P ., Almahairi, A., Babaei, Y ., et al. Llama 2: \nopen foundation and fine-tuned chat models. Arxiv [Preprint] doi: \n10.48550/arXiv.2307.09288 (2023).\nWang, P ., Chan, A., Ilievski, F ., Chen, M., and Ren, X.. PINTO: Faithful Language \nReasoning Using Prompt-Generated Rationales. In The Eleventh International \nConference on Learning Representations.\nWiegreffe, S., Hessel, J., Swayamdipta, S., Riedl, M., and Choi, Y .. Reframing human-\nAI collaboration for generating free-text explanations. In Proceeding of the 2022 \nconference of the north American chapter of the Association for Computational \nLinguistics: Human language technologies (2022) pp. 632‚Äì658.\nWiegreffe, S, Marasoviƒá, A, and Smith, NA. Measuring association between labels and \nfree-text rationales. In Proceeding of the 2021 conference on empirical methods in \nnatural language processing (2021) pp. 10266‚Äì10284.\nXu, X., Y ao, B., Dong, Y ., Gabriel, S., Yu, H., Hendler, J., et al. Mental-llm: \nleveraging large language models for mental health prediction via online text data. \nProceeding of the ACM on interactive, Mobile, wearable and ubiquitous \ntechnologies. (2024):1‚Äì32.\nY ang, K., Zhang, T., Kuang, Z., Xie, Q., Huang, J., and Ananiadou, S.. \nMentaLLaMA: interpretable mental health analysis on social media with large \nlanguage models. In Proceeding of the ACM on web conference (2024) pp. \n4489‚Äì4500.\nY ates, A., Cohan, A., and Goharian, N.. Depression and self-harm risk assessment in \nonline forums. In Proceeding of the 2017 Conference on Empirical Methods in Natural \nLanguage Processing (2017) (pp. 2968‚Äì2978).\nY e, X., and Durrett, G. (2022). The unreliability of explanations in few-shot prompting \nfor textual reasoning. Adv. Neural Inf. Proces. Syst.  6, 30378‚Äì30392. doi: 10.48550/\narXiv.2205.03401\nY e, X., Iyer, S., Celikyilmaz, A., Stoyanov, V ., Durrett, G., and Pasunuru, R. (2023). \nComplementary explanations for effective in-context learning. ACL 2023, 4469‚Äì4484. \ndoi: 10.18653/v1/2023.findings-acl.273\nY e, J., Wu, Z., Feng, J., Yu, T., and Kong, L.. Compositional exemplars for in-context \nlearning. In Proceeding of the 40th International Conference on Machine Learning \n(2023) pp. 39818‚Äì39833.\nZhang, T., Kishore, V ., Wu, F ., Weinberger, K. Q., and Artzi, Y . (2020). BERTScore: \nEvaluating Text Generation with BERT. In International Conference on Learning \nRepresentations.\nZogan, H., Razzak, I., Jameel, S., and Xu, G.. Depressionnet: learning multi-modalities \nwith user post summarization for depression detection on social media. In Proceeding \nof the 44th international ACM SIGIR conference on research and development in \ninformation retrieval (2021) pp. 133‚Äì142.\nPriyadarshana et al. 10.3389/frai.2025.1564828\nFrontiers in Artificial Intelligence 17 frontiersin.org\nAppendix\nFIGURE A1\nThe LLM, with its knowledge of processing contextualized representations of MPCs, produces contextual embeddings for each utterance in the MPC \nquery. The demonstration retriever selects the most semantically relevant demonstrations from the RSDD depression corpus that are closest to the \ninput MPC query. These demonstrations are used to generate and rank free-text explanations for the query 1, U2, using ExDoRA in the Explanation \nGeneration and Ranking phase. Once the prompt embeddings P are paired with the demonstrations and explanations, the prompt manager of \nProDepDet processes the embedded P using mandatory prompt templates and optional verbalizers created from OpenPrompt Python library for \ndownstream depression detection, including depressed utterance classification and depressed speaker identification."
}