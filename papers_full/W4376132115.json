{
  "title": "FUTURE OF THE LANGUAGE MODELS IN HEALTHCARE: THE ROLE OF CHATGPT",
  "url": "https://openalex.org/W4376132115",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A1974446747",
      "name": "Francisco Tustumi",
      "affiliations": [
        "Universidade de São Paulo"
      ]
    },
    {
      "id": "https://openalex.org/A49197836",
      "name": "Nelson Adami Andreollo",
      "affiliations": [
        "Universidade Estadual de Campinas (UNICAMP)"
      ]
    },
    {
      "id": "https://openalex.org/A2266500478",
      "name": "José Eduardo de Aguilar Nascimento",
      "affiliations": [
        "Universidade Federal de Mato Grosso"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3103891289",
    "https://openalex.org/W2981634144",
    "https://openalex.org/W3089673203",
    "https://openalex.org/W2911049278",
    "https://openalex.org/W2953602385",
    "https://openalex.org/W1978209044",
    "https://openalex.org/W4206335521",
    "https://openalex.org/W2022496558",
    "https://openalex.org/W4313451803",
    "https://openalex.org/W6757079273",
    "https://openalex.org/W4320011332",
    "https://openalex.org/W2475260156",
    "https://openalex.org/W2969468266",
    "https://openalex.org/W3004493409",
    "https://openalex.org/W1533050673",
    "https://openalex.org/W2983879675",
    "https://openalex.org/W1511524925",
    "https://openalex.org/W4318263917",
    "https://openalex.org/W2046509978",
    "https://openalex.org/W2056439589",
    "https://openalex.org/W2108349766",
    "https://openalex.org/W3015685437",
    "https://openalex.org/W2895763047",
    "https://openalex.org/W4320495408",
    "https://openalex.org/W2903739847",
    "https://openalex.org/W1976410857",
    "https://openalex.org/W4300187744",
    "https://openalex.org/W4319662928"
  ],
  "abstract": "ABSTRACT The field of medicine has always been at the forefront of technological innovation, constantly seeking new strategies to diagnose, treat, and prevent diseases. Guidelines for clinical practice to orientate medical teams regarding diagnosis, treatment, and prevention measures have increased over the years. The purpose is to gather the most medical knowledge to construct an orientation for practice. Evidence-based guidelines follow several main characteristics of a systematic review, including systematic and unbiased search, selection, and extraction of the source of evidence. In recent years, the rapid advancement of artificial intelligence has provided clinicians and patients with access to personalized, data-driven insights, support and new opportunities for healthcare professionals to improve patient outcomes, increase efficiency, and reduce costs. One of the most exciting developments in Artificial Intelligence has been the emergence of chatbots. A chatbot is a computer program used to simulate conversations with human users. Recently, OpenAI, a research organization focused on machine learning, developed ChatGPT, a large language model that generates human-like text. ChatGPT uses a type of AI known as a deep learning model. ChatGPT can quickly search and select pieces of evidence through numerous databases to provide answers to complex questions, reducing the time and effort required to research a particular topic manually. Consequently, language models can accelerate the creation of clinical practice guidelines. While there is no doubt that ChatGPT has the potential to revolutionize the way healthcare is delivered, it is essential to note that it should not be used as a substitute for human healthcare professionals. Instead, ChatGPT should be considered a tool that can be used to augment and support the work of healthcare professionals, helping them to provide better care to their patients.",
  "full_text": "From 1Universidade de São Paulo, Faculty of Medicine,  Department of Gastroenterology – São Paulo (SP), Brazil;  2Universidade Estadual de Campinas, Faculty \nof Medical Sciences, Department of Surgery, Digestive Disease Surgical Unit – Campinas (SP), Brazil; 3Universidade Federal de Mato Grosso, Medical School,  \nDepartment of Surgery – Cuiabá (MT), Brazil.\nHow to cite this article: Tustumi F, Andreollo NA, Aguilar-Nascimento JE. ABCD Arq Bras Cir Dig. 2023;36e1727. https://doi.org/10.1590/0102-672020230002e1727\nABSTRACT – The field of medicine has always been at the forefront of technological innovation, \nconstantly seeking new strategies to diagnose, treat, and prevent diseases. Guidelines for clinical \npractice to orientate medical teams regarding diagnosis, treatment, and prevention measures have \nincreased over the years. The purpose is to gather the most medical knowledge to construct an \norientation for practice. Evidence-based guidelines follow several main characteristics of a systematic \nreview, including systematic and unbiased search, selection, and extraction of the source of evidence. \nIn recent years, the rapid advancement of artificial intelligence has provided clinicians and patients \nwith access to personalized, data-driven insights, support and new opportunities for healthcare \nprofessionals to improve patient outcomes, increase efficiency, and reduce costs. One of the most \nexciting developments in Artificial Intelligence has been the emergence of chatbots. A chatbot is a \ncomputer program used to simulate conversations with human users. Recently, OpenAI, a research \norganization focused on machine learning, developed ChatGPT, a large language model that \ngenerates human-like text. ChatGPT uses a type of AI known as a deep learning model. ChatGPT \ncan quickly search and select pieces of evidence through numerous databases to provide answers \nto complex questions, reducing the time and effort required to research a particular topic manually. \nConsequently, language models can accelerate the creation of clinical practice guidelines. While \nthere is no doubt that ChatGPT has the potential to revolutionize the way healthcare is delivered, \nit is essential to note that it should not be used as a substitute for human healthcare professionals. \nInstead, ChatGPT should be considered a tool that can be used to augment and support the work of \nhealthcare professionals, helping them to provide better care to their patients.\nHEADINGS: Guidelines as topic. Artificial intelligence. Diagnosis. Costs and cost analysis. Delivery of \nhealth care.\nReview Article\nFUTURE OF THE LANGUAGE MODELS IN HEALTHCARE: THE ROLE OF CHATGPT\nFUTURO DOS MODELOS DE LINGUAGEM NOS CUIDADOS EM SAÚDE: O PAPEL DO CHATGPT\nFrancisco TUSTUMI1 , Nelson Adami ANDREOLLO2 , José Eduardo de AGUILAR-NASCIMENTO3 \nFinancial Source: None\nConflicts of Interest: None\nReceived: 02/16/2023\nAccepted: 02/20/2023\nCorrespondence:\nFrancisco Tustumi.\nEmail: franciscotustumi@gmail.com.\nABCD Arq Bras Cir Dig\n2023;36:e1727\nhttps://doi.org/10.1590/0102-672020230002e1727\nRESUMO – A área da medicina sempre esteve na vanguarda da inovação tecnológica, buscando \nconstantemente novas estratégias para diagnosticar, tratar e prevenir doenças. As diretrizes para a \nprática clínica são para orientar as equipes médicas quanto ao diagnóstico, tratamento e medidas de \nprevenção aumentaram ao longo dos anos. O objetivo é reunir o máximo de conhecimento médico \npara construir uma orientação para a prática. As diretrizes baseadas em evidências seguem várias das \nprincipais características de uma revisão sistemática, incluindo busca sistemática e imparcial, seleção \ne extração da fonte de evidência. Nos últimos anos, o rápido avanço da inteligência artificial forneceu \naos médicos e pacientes acesso a informações personalizadas e baseadas em dados, suporte e novas \noportunidades para os profissionais de saúde melhorarem os resultados dos pacientes, aumentarem \na eficiência e reduzirem custos. Um dos desenvolvimentos mais empolgantes da Inteligência \nArtificial foi o surgimento dos chatbots. Um chatbot  é um programa de computador para simular \nconversas com usuários humanos. Recentemente, a OpenAI, uma organização de pesquisa focada \nem aprendizado de máquina, desenvolveu o ChatGPT, um grande modelo de linguagem que gera \ntexto semelhante ao humano. O ChatGPT usa um tipo de inteligência artificial conhecido como \nmodelo de aprendizado profundo. O ChatGPT pode pesquisar e selecionar rapidamente evidências \nem vários bancos de dados para fornecer respostas a perguntas complexas, reduzindo o tempo e \no esforço necessários para pesquisar um tópico específico manualmente. Consequentemente, os \nmodelos de linguagem podem acelerar a criação de diretrizes de prática clínica. Embora não haja \ndúvida de que o ChatGPT tem potencial para revolucionar a forma como os cuidados de saúde são \nprestados, é essencial observar que não deve ser usado como substituto de profissionais de saúde \nhumanos. Em vez disso, o ChatGPT deve ser visto como uma ferramenta que pode ser usada para \naumentar e apoiar o trabalho dos profissionais de saúde, ajudando-os a prestar melhores cuidados \naos seus pacientes.\nDESCRITORES: Guias como assunto. Inteligência artificial. Diagnóstico. Custos e análise de custos. \nAtenção à saúde.\nTrabalho realizado no 1Serviço de Cirurgia Geral e Aparelho Digestivo, Departamento de Clínica Cirúrgica, Faculdade de Medicina, Universidade Federal de Goiás, Goiânia, GO, \nBrasil; 2Serviço de Endoscopia, Hospital das Clínicas e Departamento de Gastroenterologia, Faculdade de Medicina, Universidade de São Paulo, São Paulo, SP, Brasil; 3Serviço de \nCirurgia do Fígado, Hospital das Clínicas e Departamento de Gastroenterologia, Faculdade de Medicina, Universidade de São Paulo, São Paulo, SP, Brasil \nComo citar esse artigo: de Biase Silva-Neto WB, Quirese C, De Moura EGH, Coelho FF, Herman P. A queda da pressão portal após desvascularização esofagogástrica e esplenectomia \n/10.1590/0102-672020210001e1581\nA QUEDA DA PRESSÃO PORTAL APÓS DESVASCULARIZAÇÃO \nESOFAGOGÁSTRICA E ESPLENECTOMIA INFLUENCIA A VARIAÇÃO \nDO CALIBRE DAS VARIZES E AS TAXAS DE RESSANGRAMENTO NA \nESQUISTOSSOMOSE NO SEGUIMENTO EM LONGO PRAZO?\nDoes the drop in portal pressure after esophagogastric devascularization and splenectomy \nvariation of variceal calibers and the rebleeding rates in schistosomiasis in late follow-up?\nWalter de Biase SILVA-NETO1 , Claudemiro QUIRESE1 , Eduardo Guimarães Horneaux de MOURA2 , \nFabricio Ferreira COELHO3 , Paulo HERMAN3\nRecebido para publicação: 17/09/2020\nAceito para publicação: 14/12/2020\nCorrespondência:\nWalter De Biase da Silva Neto\nE-mail: wbiase123@gmail.com; \nbiase@terra.com.br\nwww.instagram.com/abcdrevista www.facebook.com/abcdrevista www.twitter.com/abcdrevista\nABSTRACT - Background: The treatment of choice for patients with schistosomiasis with \nprevious episode of varices is bleeding esophagogastric devascularization and splenectomy \n(EGDS) in association with postoperative endoscopic therapy. However, studies have shown \nvarices recurrence especially after long-term follow-up. Aim: To assess the impact on \nbehavior of esophageal varices and bleeding recurrence after post-operative endoscopic \ntreatment of patients submitted to EGDS. Methods: Thirty-six patients submitted to EGDS \nportal pressure drop, more or less than 30%, and compared with the behavior of esophageal \nvarices and the rate of bleeding recurrence. Results\nlate post-operative varices caliber when compared the pre-operative data was observed \ndespite an increase in diameter during follow-up that was controlled by endoscopic therapy. \nConclusion\nvariceal calibers when comparing pre-operative and early or late post-operative diameters. \nThe comparison between the portal pressure drop and the rebleeding rates was also not \nHEADINGS: Schistosomiasis mansoni. Portal hypertension. Surgery. Portal pressure. \nEsophageal and gastric varices.\nRESUMO - Racional: O tratamento de escolha para pacientes com hipertensão portal \nesquistossomótica com sangramento de varizes é a desconexão ázigo-portal mais \nesplenectomia (DAPE) associada à terapia endoscópica. Porém, estudos mostram aumento \ndo calibre das varizes em alguns pacientes durante o seguimento em longo prazo. Objetivo: \nAvaliar o impacto da DAPE e tratamento endoscópico pós-operatório no comportamento \ndas varizes esofágicas e recidiva hemorrágica, de pacientes esquistossomóticos. Métodos: \nForam estudados 36 pacientes com seguimento superior a cinco anos, distribuídos em \ndois grupos: queda da pressão portal abaixo de 30% e acima de 30% comparados com o \ncalibre das varizes esofágicas no pós-operatório precoce e tardio além do índice de recidiva \nhemorrágica. Resultados\nesofágicas que, durante o seguimento aumentaram de calibre e foram controladas com \no comportamento do calibre das varizes no pós-operatório precoce nem tardio nem os \níndices de recidiva hemorrágica. Conclusão\noperatórios precoces ou tardios. A comparação entre a queda de pressão do portal e as \nDESCRITORES: Esquistossomose mansoni. Hipertensão portal. Cirurgia. Pressão na veia porta. Varizes esofágicas \ne gástricas.\n1/4ABCD Arq Bras Cir Dig 2021;34(2):e1581\nPerspectiva\nEste estudo avaliou o impacto tardio no índice \nde ressangramento de pacientes submetidos ao \ntratamento cirúrgico e endoscópico. A queda na \nvariação do calibre das varizes quando comparado \no seu diâmetro no pré e pós-operatório precoce e \ntardio. A comparação entre a queda de pressão \nportal e as taxas de ressangramento, também \nevidenciar se apenas a terapia endoscópica, ou \noperações menos complexas poderão controlar o \nsangramento das varizes.\nEvolução do calibre das varizes no período pré e pós-\noperatório precoce  e tardio\nMensagem central\nA desconexão ázigo-portal e esplenectomia \napresenta importante impacto na diminuição \nprecoce do calibre das varizes esofágicas na \nesquistossomose; entretanto, parece que a \nassociação com a terapia endoscópica é a maior \nresponsável pelo controle da recidiva hemorrágica.\ninstagram.com/revistaabcd/\n twitter.com/revista_abcd\n facebook.com/Revista-ABCD-109005301640367\n linkedin.com/company/revista-abcd\nEditorial Support: National Council for Scientific and Technological Development (CNPq).\n1/5\nABCD Arq Bras Cir Dig 2023;36:e1727\nPerspectives\nThe use of ChatGPT in medicine is a promising \ndevelopment that has the potential to \nsignificantly improve patient outcomes and \nincrease the efficiency of healthcare delivery. \nHowever, it is important to consider this \ntechnology’s limitations carefully and ensure that \nit is used responsibly and in conjunction with \nhuman healthcare professionals.\nCentral Message\nIn recent years, the rapid advancement of \nartificial intelligence (AI) has provided clinicians \nand patients with access to personalized, data-\ndriven insights, support and new opportunities \nfor healthcare professionals to improve patient \noutcomes, increase efficiency, and reduce \ncosts. One of the most exciting developments \nin AI has been the emergence of chatbots. A \nchatbot is a computer program used to simulate \nconversations with human users.\nFigure 4 - Language models in medicine are \npromising and have the potential to significantly \nimprove patient outcomes and increase the \nefficiency of healthcare delivery. However, it \nis crucial to consider the limitations of this \ntechnology carefully. AI: Artificial intelligence.\nAnother relevant issue in evidence-based guidelines and \nsystematic reviews refers to the risk of selection bias10,22,23. Some \nauthors may make a poor selection of the pieces of evidence \nfor supporting guidelines for some reasons which may be due \nto quite restricted eligibility criteria, such as period, language, \nor databases searched, or even due to human failure during \nthe process of search, selection, and extraction of the source \nof evidence 17. Besides, poor selection can also be due to \nimproper manipulation of outcomes, influenced by personal \nbeliefs or opinions8.\nIn this context, in recent years, the rapid advancement \nof artificial intelligence (AI) has provided new opportunities \nfor healthcare professionals to improve patient outcomes, \nincrease efficiency, and reduce costs25. In the medical field, AI \nhas the potential to provide clinicians and patients with access \nto personalized, data-driven insights and support.\nOne of the most exciting developments in AI has been the \nemergence of chatbots, which have the potential to revolutionize \nthe way healthcare is delivered1. A chatbot is a computer program \nused to simulate conversations with human users. Recently, \nOpenAI, a research organization focused on machine learning, \ndeveloped ChatGPT, a large language model that generates \nhuman-like text. The initial version of Generative Pre-Trained \nTransformer (GPT) was first introduced in 2018. Since then, \nseveral improved versions of GPT have been released. ChatGPT \nis a variant of the GPT models that have been specifically fine-\ntuned and optimized for chat-based applications13.\nChatGPT uses a type of AI known as a deep learning \nmodel (Figure 3). Specifically, it is a type of transformer-based \nlanguage model that uses a neural network architecture known \nas the Transformer. This architecture was first introduced \nin 2017 and has since become a popular choice for natural \nlanguage processing tasks, such as language translation, \nlanguage generation, and text classification. The Transformer \narchitecture uses multiple layers of neurons, or “transformer \nblocks,” that allow it to process and extract features from \ninput data hierarchically. This architecture has proven to \nbe very effective for natural language processing tasks, \nand it forms the basis of many of the most advanced \nlanguage models, including ChatGPT. ChatGPT is designed \nto understand and respond to text-based inputs from users \nin order to provide helpful and informative responses to \ntheir questions and comments 4,11,12 . \nThere are different categories of chatbots, and a chatbot \ncan belong to more than one category: Knowledge Domain \n(generic, open domain, and closed domain); Service Provided \n(interpersonal, intrapersonal, and inter-agent); Goals (informative, \nchat-based/conversational, and task-based); Response Generation \nMethod (rule based, retrieval based, and generative); Human-Aid \n(human-mediated and autonomous); Permissions (open-source \nand commercial); and Communication Channel (text, voice, and \nimage)1. Therefore, there are many applications of chatbots, \nlike education environments, customer service, medicine and \nhealth, robotics, industrial, and others1.\nThe chatbots, AI, and telemedicine are increasingly being \nused in healthcare services with good acceptance, such as \neducation, diagnostic imaging and genetic diagnosis, as well as \nclinical laboratory, screening, and health communications9,15,25. \nOne of the key benefits of using ChatGPT in medicine is \nthe ability to provide fast, accurate, and up-to-date information \nto healthcare professionals and patients. ChatGPT can quickly \nsearch and select pieces of evidence through numerous databases \nto provide answers to complex questions, reducing the time \nand effort required to research a particular topic manually. \nConsequently, language models can accelerate the creation \nof clinical practice guidelines. AI may help screen numerous \ndatabases quickly, saving time and accelerating the finishing \nof the guidelines11,20. \nINTRODUCTION\nT\nhe field of medicine has always been at the forefront \nof technological innovation, constantly seeking new \nstrategies to diagnose, treat, and prevent diseases. \nThe number of publications in the main medical databases, such \nas PubMed and Embase, has been increasing steadily over the \nyears due to the contributions from authors worldwide, the \nexpansion of research areas, the rise of open-access publishing, \nand advancements in technology2. This growth in biomedical \nliterature provides a wealth of information that can be used \nto advance research and improve patient care7. However, this \nfast science production in the medical field has boosted a \nnew problem: how can clinical practice follow the constantly \nupdated improvement of science? \nGuidelines for clinical practice to orientate medical teams \nregarding diagnosis, treatment, and prevention measures have \nincreased over the years6. The purpose is to gather the most \nmedical knowledge to construct an orientation for practice. \nGuidelines help standardize care, improve patient outcomes, \npromote efficient use of resources, and reduce the risk of \nadverse events. In this sense, evidence-based reviews and \nguidelines are located at the top of the pyramid in the level \nof evidence (Figure 1)14 and in the last stages of translational \nmedicine (Figure 2)18. \nEvidence-based guidelines follow several main characteristics \nof a systematic review, including systematic and unbiased \nsearch, selection, and extraction of the source of evidence21,24. \nHowever, there are numerous obstacles to constructing \nevidence-based guidelines. Search, selection, and extraction \ntake many efforts and a long time5. Consequently, evidence-\nbased guidelines are usually published with a long-time \ndelay. An evidenced-based guideline can take anywhere from \nseveral months to more than a year to complete, depending \non the scope and complexity of the review. Conducting a \ncomprehensive search for relevant studies can take several \nmonths, depending on the literature database’s size and the \nsearch terms’ complexity. Screening studies for inclusion \nbased on pre-specified criteria can take another couple of \nmonths, depending on the number of studies identified \nand the number of reviewers involved. Updates of these \nguidelines may take years or even never be performed, and \nhealthcare professionals may take their diagnosis, treatment, \nand prevention measures based on guidelines out of step with \nthe current technological and scientific level.\nFigure 1 - Pyramid of the level of evidence. Systematic reviews \nand evidence-based guidelines are usually considered \nthe top evidence, gathering all the current evidence \nfor clinical practice14.\nREVIEW ARTICLE\n2/5\nABCD Arq Bras Cir Dig 2023;36:e1727\nIn addition to providing information, ChatGPT can also \nassist healthcare professionals with making diagnoses by \nanalyzing symptoms and recommending tests or treatments. \nThis can help to improve the accuracy of diagnoses and \nreduce the number of misdiagnoses. ChatGPT can also be \nused to help manage patients with chronic conditions by \nproviding information about medications, lifestyle changes, \nand treatment options 3,15.\nBesides, the use of AI might reduce the risk of selection \nbias. The dataset used to train ChatGPT is typically chosen to \nFigure 2 - Translational medicine stages. Evidence-based guidelines and healthcare policies are the endpoints of any research \nline. These guidelines and policies orientate healthcare professionals for patient management18.\nFigure 3 - Modern language models use artificial intelligence to create a human-like text.\nMODELOS DE LINGUAGEM EM SAÚDE: PAPEL DO CHATGPT\n3/5\nABCD Arq Bras Cir Dig 2023;36:e1727\nFigure 4 - Language models in medicine are promising and have the potential to significantly improve patient outcomes and \nincrease the efficiency of healthcare delivery. However, it is crucial to consider the limitations of this technology \ncarefully. AI: Artificial intelligence.\nbe as inclusive as possible, including a broad range of sources \nand perspectives. ChatGPT is not influenced by individual \ncognitive biases, which can affect human decision-making. \nAs an AI, ChatGPT uses a purely algorithmic approach to \ngenerate responses without being influenced by personal \nbeliefs or opinions. This can reduce the risk of selection bias, \nas the responses are based solely on the data used to train \nthe algorithm16.\nHowever, ChatGPT is trained on large amounts of data, \nwhich may contain biases or inaccuracies that the system \ncould inadvertently propagate. This information bias could \nresult in inaccurate or discriminatory recommendations \nor treatment options 15,16 . ChatGPT is trained based on \nweb data, and several web information sources may be \neasily wrong. Besides, ChatGPT may not always have a \nfull understanding of the context of the data in which \na question or prompt is being asked. This could lead to \ninaccurate or inappropriate responses, particularly in \ncomplex medical situations or situations comprehending \npatients’ preferences or feelings.\nFor evidence-based guidelines with quantitative synthesis \n(meta-analysis), despite AI potentially detecting statistical \nheterogeneity, clinical heterogeneity depends on the critical \nanalysis of the included articles19. Without the human critical \nanalysis capacity, language models may gather information in \na review based on articles whose data cannot be pooled due \nto their methodological differences!  \nWhile there is no doubt that ChatGPT has the potential \nto revolutionize the way healthcare is delivered, it is essential \nto note that it should not be used as a substitute for human \nhealthcare professionals. Instead, ChatGPT should be considered \na tool that can be used to augment and support the work of \nhealthcare professionals, helping them to provide better care \nto their patients (Figure 4).\nCONCLUSION\nThe use of ChatGPT in medicine is a promising development \nthat has the potential to significantly improve patient outcomes \nand increase the efficiency of healthcare delivery. However, it \nis important to consider this technology’s limitations carefully \nand ensure that it is used responsibly and in conjunction with \nhuman healthcare professionals. \nREFERENCES\n1. Adamopoulou E, Moussiades L. Chatbots: history, technology, \nand applications. Mach Learn Appl. 2020;2:100006. https://doi.\norg/10.1016/j.mlwa.2020.100006\n2. AlRyalat SAS, Malkawi LW, Momani SM. Comparing bibliometric \nanalysis using PubMed, scopus, and web of science databases. J \nVis Exp. 2019;(152). https://doi.org/10.3791/58494\n3. Athota L, Shukla VK, Pandey N, Rana A. Chatbot for healthcare \nsystem using artificial intelligence. IEEE. 2020:619-22. https://doi.\norg/10.1109/ICRITO48877.2020.9197833\n4. Aydın Ö, Karaarslan E. OpenAI ChatGPT generated literature review: \ndigital twin in healthcare. In: Ö. Aydın, editors. Emerging computer \ntechnologies. Tire: İzmir Akademi Dernegi; 2022. p. 22-31.\nREVIEW ARTICLE\n4/5\nABCD Arq Bras Cir Dig 2023;36:e1727\n5. Boland A, Dickson R, Cherry G. Doing a systematic review: a \nstudent’s guide. Doing a systematic review. 2nd edition. SAGE \nPublications 2017:1-304.\n6. Brouwers MC, Florez ID, McNair SA, Vella ET, Yao X. Clinical \npractice guidelines: tools to support high quality patient care. \nSemin Nucl Med. 2019;49(2):145-52. https://doi.org/10.1053/j.\nsemnuclmed.2018.11.001\n7. Engle RL, Mohr DC, Holmes SK, Seibert MN, Afable M, Leyson J, \nMeterko M. Evidence-based practice and patient-centered care: \ndoing both well. Health Care Manage Rev. 2021;46(3):174-84. \nhttps://doi.org/10.1097/HMR.0000000000000254\n8. Hernán MA, Hernández-Díaz S, Robins JM. A structural approach \nto selection bias. Epidemiology. 2004;15(5):615-25. https://doi.\norg/10.1097/01.ede.0000135174.63482.43\n9. Isolan G, Malafaia O. How does telemedicine fit into healthcare today? \nArq Bras Cir Dig. 2022;34(3):e1584. https://doi.org/10.1590/0102-\n672020210003e1584\n10. Kho ME, Duffett M, Willison DJ, Cook DJ, Brouwers MC. Written \ninformed consent and selection bias in observational studies using \nmedical records: systematic review. BMJ. 2009;338:b866. https://\ndoi.org/10.1136/bmj.b866\n11. Kung TH, Cheatham M, Medenilla A, Sillos C, De Leon L, Elepaño \nC, et al. Performance of ChatGPT on USMLE: potential for AI-\nassisted medical education using large language models. PLOS \nDigital Health. 2023;2(2):e0000198. https://doi.org/10.1371/journal.\npdig.0000198\n12. Li N, Liu S, Liu Y, Zhao S, Liu M. Neural speech synthesis with \ntransformer network. Arxiv. 2019;33(1):6706-13. https://doi.\norg/10.1609/aaai.v33i01.33016706.\n13. Lund BD, Wang T. Chatting about ChatGPT: how may AI and GPT \nimpact academia and libraries? Library Hi Tech News. 2023. https://\ndoi.org/10.1108/LHTN-01-2023-0009\n14. Murad MH, Asi N, Alsawas M, Alahdab F. New evidence pyramid. \nEvid Based Med. 2016;21(4):125-7. https://doi.org/10.1136/ebmed-\n2016-110401\n15. Nadarzynski T, Miles O, Cowie A, Ridge D. Acceptability of artificial \nintelligence (AI)-led chatbot services in healthcare: a mixed-\nmethods study. Digit Health. 2019;5:2055207619871808. https://\ndoi.org/10.1177/2055207619871808.\n16. Ntoutsi E, Fafalios P, Gadiraju U, Iosifidis V, Nejdl W, Vidal ME, et al. \nBias in data-driven artificial intelligence systems—An introductory \nsurvey. WIREs Data Mining Knowl Discov. 2020;10(3):e1356. https://\ndoi.org/10.1002/widm.1356\n17. Rother ET. Systematic literature review X narrative review. Acta Paul \nEnferm. 2007;20:v-i. https://doi.org/10.1590/S0103-21002007000200001.\n18. Seyhan AA. Lost in translation: the valley of death across preclinical \nand clinical divide–identification of problems and overcoming \nobstacles. Transl Med Commun. 2019;4:18. https://doi.org/10.1186/\ns41231-019-0050-7\n19. Thompson SG. Why sources of heterogeneity in meta-analysis \nshould be investigated. BMJ. 1994;309(6965):1351-5. https://doi.\norg/10.1136/bmj.309.6965.1351\n20. Thorp HH. ChatGPT is fun, but not an author. Science. 2023;379(6630):313. \nhttps://doi.org/10.1126/science.adg7879\n21. Urra Medina E, Barría Pailaquilén RM. Systematic review and its relationship \nwith evidence-based practice in health. Rev Latino-am Enfermagem. \n2010;18:824-31. https://doi.org/10.1590/S0104-11692010000400023\n22. Williamson PR, Gamble C, Altman DG, Hutton JL. Outcome selection \nbias in meta-analysis. Stat Methods Med Res. 2005;14(5):515-24. \nhttps://doi.org/10.1191/0962280205sm415oa\n23. Williamson PR, Gamble C. Identification and impact of outcome \nselection bias in meta-analysis. Stat Med. 2005;24(10):1547-61. \nhttps://doi.org/10.1002/sim.2025\n24. Yao X, Vella ET, Sussman J. More thoughts than answers: what \ndistinguishes evidence-based clinical practice guidelines from \nnon-evidence-based clinical practice guidelines? J Gen Intern Med. \n2021;36(1):207-8. https://doi.org/10.1007/s11606-020-05825-y\n25. Yu KH, Beam AL, Kohane IS. Artificial intelligence in healthcare. \nNat Biomed Eng. 2018;2(10):719-31. https://doi.org/10.1038/\ns41551-018-0305-z\nMODELOS DE LINGUAGEM EM SAÚDE: PAPEL DO CHATGPT\n5/5\nABCD Arq Bras Cir Dig 2023;36:e1727",
  "topic": "Health care",
  "concepts": [
    {
      "name": "Health care",
      "score": 0.5792841911315918
    },
    {
      "name": "Computer science",
      "score": 0.38465389609336853
    },
    {
      "name": "Linguistics",
      "score": 0.37580376863479614
    },
    {
      "name": "Business",
      "score": 0.3709014058113098
    },
    {
      "name": "Political science",
      "score": 0.250800758600235
    },
    {
      "name": "Philosophy",
      "score": 0.09295108914375305
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I17974374",
      "name": "Universidade de São Paulo",
      "country": "BR"
    },
    {
      "id": "https://openalex.org/I181391015",
      "name": "Universidade Estadual de Campinas (UNICAMP)",
      "country": "BR"
    },
    {
      "id": "https://openalex.org/I32725510",
      "name": "Universidade Federal de Mato Grosso",
      "country": "BR"
    }
  ],
  "cited_by": 79
}