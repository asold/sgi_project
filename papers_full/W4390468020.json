{
    "title": "Explainability and Evaluation of Vision Transformers: An In-Depth Experimental Study",
    "url": "https://openalex.org/W4390468020",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A3197316540",
            "name": "SÃ©drick Stassin",
            "affiliations": [
                "University of Mons"
            ]
        },
        {
            "id": "https://openalex.org/A5093626941",
            "name": "Valentin Corduant",
            "affiliations": [
                "University of Mons"
            ]
        },
        {
            "id": "https://openalex.org/A2097395340",
            "name": "Sidi Ahmed Mahmoudi",
            "affiliations": [
                "University of Mons"
            ]
        },
        {
            "id": "https://openalex.org/A97555410",
            "name": "Xavier Siebert",
            "affiliations": [
                "University of Mons"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2040870580",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W4226512186",
        "https://openalex.org/W3214586131",
        "https://openalex.org/W3168649818",
        "https://openalex.org/W3096609285",
        "https://openalex.org/W3035563045",
        "https://openalex.org/W2950768109",
        "https://openalex.org/W1979354511",
        "https://openalex.org/W4283159491",
        "https://openalex.org/W3000716014",
        "https://openalex.org/W2981731882",
        "https://openalex.org/W3195947859",
        "https://openalex.org/W4230590011",
        "https://openalex.org/W2117539524",
        "https://openalex.org/W2531409750",
        "https://openalex.org/W2946948417",
        "https://openalex.org/W2194775991",
        "https://openalex.org/W3212386989",
        "https://openalex.org/W6734194636",
        "https://openalex.org/W1849277567",
        "https://openalex.org/W2809136100",
        "https://openalex.org/W2295107390",
        "https://openalex.org/W2962858109",
        "https://openalex.org/W2765793020",
        "https://openalex.org/W3035253074",
        "https://openalex.org/W1514535095",
        "https://openalex.org/W6762945437",
        "https://openalex.org/W3035422918",
        "https://openalex.org/W1787224781",
        "https://openalex.org/W2946794439",
        "https://openalex.org/W3176196997",
        "https://openalex.org/W4230405732",
        "https://openalex.org/W4385768130",
        "https://openalex.org/W4390189844",
        "https://openalex.org/W6800217721",
        "https://openalex.org/W6767229288",
        "https://openalex.org/W2240067561",
        "https://openalex.org/W3035264434",
        "https://openalex.org/W2809671526",
        "https://openalex.org/W4221159886",
        "https://openalex.org/W2657631929",
        "https://openalex.org/W4296848610",
        "https://openalex.org/W2979494945",
        "https://openalex.org/W6754669440",
        "https://openalex.org/W3006874766",
        "https://openalex.org/W6762929394",
        "https://openalex.org/W2776207810",
        "https://openalex.org/W1686810756",
        "https://openalex.org/W4287022992",
        "https://openalex.org/W2971201880",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W2970447476"
    ],
    "abstract": "In the era of artificial intelligence (AI), the deployment of intelligent systems for autonomous decision making has surged across diverse fields. However, the widespread adoption of AI technology is hindered by the risks associated with ceding control to autonomous systems, particularly in critical domains. Explainable artificial intelligence (XAI) has emerged as a critical subdomain fostering human understanding and trust. It addresses the opacity of complex models such as vision transformers (ViTs), which have gained prominence lately. With the expanding landscape of XAI methods, selecting the most effective method remains an open question, due to the lack of a ground-truth label for explainability. To avoid subjective human judgment, numerous metrics have been developed, with each aiming to fulfill certain properties required for a valid explanation. This study conducts a detailed evaluation of various XAI methods applied to the ViT architecture, thereby exploring metrics criteria like faithfulness, coherence, robustness, and complexity. We especially study the metric convergence, correlation, discriminative power, and inference time of both XAI methods and metrics. Contrary to expectations, the metrics of each criterion reveal minimal convergence and correlation. This study not only challenges the conventional practice of metric-based ranking of XAI methods but also underscores the dependence of explanations on the experimental environment, thereby presenting crucial considerations for the future development and adoption of XAI methods in real-world applications.",
    "full_text": null
}