{
  "title": "Human-AI Collaboration in Large Language Model-Assisted Brain MRI Differential Diagnosis: A Usability Study",
  "url": "https://openalex.org/W4391579871",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2231255994",
      "name": "Su Hwan Kim",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    },
    {
      "id": "https://openalex.org/A2896924034",
      "name": "Severin Schramm",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    },
    {
      "id": "https://openalex.org/A4323142266",
      "name": "Cornelius Berberich",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    },
    {
      "id": "https://openalex.org/A4309106382",
      "name": "Enrike Rosenkranz",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    },
    {
      "id": "https://openalex.org/A3168105521",
      "name": "Lena Schmitzer",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    },
    {
      "id": "https://openalex.org/A5093873523",
      "name": "Kerem Serguen",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    },
    {
      "id": "https://openalex.org/A2109268714",
      "name": "Christopher Klenk",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    },
    {
      "id": "https://openalex.org/A4295776629",
      "name": "Nicolas Lenhart",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    },
    {
      "id": "https://openalex.org/A2097639162",
      "name": "Claus Zimmer",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    },
    {
      "id": "https://openalex.org/A2055711268",
      "name": "Benedikt Wiestler",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    },
    {
      "id": "https://openalex.org/A2573095400",
      "name": "Dennis M. Hedderich",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    },
    {
      "id": "https://openalex.org/A2231255994",
      "name": "Su Hwan Kim",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    },
    {
      "id": "https://openalex.org/A2896924034",
      "name": "Severin Schramm",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    },
    {
      "id": "https://openalex.org/A4323142266",
      "name": "Cornelius Berberich",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    },
    {
      "id": "https://openalex.org/A4309106382",
      "name": "Enrike Rosenkranz",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    },
    {
      "id": "https://openalex.org/A3168105521",
      "name": "Lena Schmitzer",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    },
    {
      "id": "https://openalex.org/A5093873523",
      "name": "Kerem Serguen",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    },
    {
      "id": "https://openalex.org/A2109268714",
      "name": "Christopher Klenk",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    },
    {
      "id": "https://openalex.org/A4295776629",
      "name": "Nicolas Lenhart",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    },
    {
      "id": "https://openalex.org/A2097639162",
      "name": "Claus Zimmer",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    },
    {
      "id": "https://openalex.org/A2055711268",
      "name": "Benedikt Wiestler",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    },
    {
      "id": "https://openalex.org/A2573095400",
      "name": "Dennis M. Hedderich",
      "affiliations": [
        "Klinikum rechts der Isar"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4390314481",
    "https://openalex.org/W4388931647",
    "https://openalex.org/W4384626331",
    "https://openalex.org/W4383186888",
    "https://openalex.org/W4376640706",
    "https://openalex.org/W4367668513",
    "https://openalex.org/W4379095447",
    "https://openalex.org/W3131191101",
    "https://openalex.org/W4385620388",
    "https://openalex.org/W4389519219",
    "https://openalex.org/W4353015365",
    "https://openalex.org/W4387973771",
    "https://openalex.org/W4383501206",
    "https://openalex.org/W4377009978",
    "https://openalex.org/W4381930847",
    "https://openalex.org/W4282983782",
    "https://openalex.org/W4386722137",
    "https://openalex.org/W4387642400"
  ],
  "abstract": "Abstract Background Prior studies have shown the potential of large language models (LLMs) to support in differential diagnosis in radiology. However, the interaction of human users with LLMs in this context has not been evaluated. Purpose To investigate the impact of human-LLM collaboration on accuracy and efficiency of brain MRI differential diagnosis. Methods In this retrospective study, twenty brain MRI cases with a challenging but definitive diagnosis were selected and randomized into two groups. Six inexperienced radiology residents were instructed to determine the three most likely differential diagnoses for each of these cases via conventional internet search or utilizing an LLM-based search engine (© Perplexity AI, powered by GPT-4). Accuracy of suggested differential diagnoses was analyzed using the chi-square test and Mann-Whitney U test. Interpretation times were analyzed using the student’s t-test. Benefits and challenges in human-LLM interaction were derived from observations and participant feedback. Results LLM-assisted brain MRI differential diagnosis yielded superior accuracy (38/59 [LLM-assisted] vs 25/59 [conventional] correct diagnoses, p = 0.03). No difference in interpretation time (8.12 +/- 3.22 min [LLM-assisted] vs 7.96 +/- 2.65 min [conventional], p = 0.76) or level of confidence (median of 2.5 [LLM-assisted] vs 3.0 [conventional], p = 0.96) was observed. Several challenges related to human errors and technical limitations were identified. Conclusion Human-LLM collaboration has the potential to improve brain MRI differential diagnosis. Yet, several challenges must be addressed to ensure effective adoption and user acceptance.",
  "full_text": "Human-AI Collaboration in Large \nLanguage Model -Assisted Brain MRI \nDifferential Diagnosis: A Usability Study \n \n \nSu Hwan Kim  1, Severin Schramm  1, Cornelius Berberic h 1, Enrike Rosenkranz  1, Lena \nSchmitzer 1, Kerem Serguen  1, Christopher Klenk  2, Nicolas Lenhart  2, Claus Zimmer  1, \nBenedikt Wiestler 1, Dennis M. Hedderich 1 \n \n1Department of Diagnostic and Interventional Neuroradiology, Klinikum rechts der Isar, School \nof Medicine, Technical University Munich, Munich, Germany \n2Department of Diagnostic and Interventional Radiology, Klinikum rechts der Isar, School of \nMedicine, Technical University Munich, Munich, Germany \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nAbbreviations \n \nMRI   Magnetic Resonance Imaging \nLLM  Large Language Model  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\nAbstract \n \nBackground \nPrior studies have shown the potential of large language models (LLMs) to support in \ndifferential diagnosis in radiology. However, the interaction of human users with LLMs \nin this context has not been evaluated. \n \nPurpose \nTo investigate the impact of human -LLM collaboration on accuracy and efficiency of \nbrain MRI differential diagnosis. \n \nMethods \nIn this retrospective study, t wenty brain MRI cases with a challenging but definitive \ndiagnosis were selected and randomized into two groups. Six inexperienced radiology \nresidents were instructed to determine the three most likely differential diagnoses for \neach of these cases via conventional internet search or utilizing an LLM-based search \nengine ( © Perplexity AI, powered by  GPT-4). Accuracy of suggested differential \ndiagnoses was analyzed using the chi -square test and Mann -Whitney U test . \nInterpretation times were analyzed using the student’s t-test. Benefits and challenges \nin human-LLM interaction were derived from observations and participant feedback. \n \nResults \nLLM-assisted brain MRI differential diagnosis yielded superior accuracy (38/59 [LLM-\nassisted] vs 25/59 [conventional] correct diagnoses, p = 0.0 3). No difference in \ninterpretation time (8.12 +/ - 3.22 min [LLM-assisted] vs 7.96 +/ - 2.65 min \n[conventional], p = 0.76) or level of confidence  (median of 2.5 [LLM -assisted] vs 3.0 \n[conventional], p = 0.96)  was observed. Several challenges related to human errors \nand technical limitations were identified. \n \nConclusion \nHuman-LLM collaboration has the potential to improve brain MRI differential diagnosis. \nYet, several challenges must be addressed to ensure effective adoption and user \nacceptance.  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint \nIntroduction \nRadiological differential diagnosis plays a crucial role in clinical care, profoundly \ninfluencing diagnostic and therapeutic decisions. Accurate determination of relevant \ndifferential diagnoses from image findings demands highly specialized knowledge of \nanatomy and pathophysiology along with proficiency in recognizing visual patterns and \nsynthesizing comprehensive clinical information. \nRecent studies suggest the emerging potential of large language models (LLMs) to \nexecute radiological differential diagnosis based on case presentations (1–5). These \nstudies compared the diagnostic suggestions of an LLM to expert assessments or \nconfirmed diagnoses. Yet, the intricate interactions between human users and LLM \nsystems in this context have not been explored.  \nPrevious literature  reveals the critical impact of human -AI interaction on diagnostic \nperformance in radiology  (6–8). One study  employing an AI -based mammogram \nclassification system demonstrated that inexperienced and experienced readers alike \nare susceptible to automation bias, which describes the inclination of human users to \nadhere to incorrect recommendations from automated decision-making systems (6). \nSimilarly, incorrect AI results were shown to negatively impact radiologist performance \nin lung cancer detection based on chest radiography (7). Yet another study highlighted \nthe significance of establishing effective human -AI collaboration protocols in AI -\nassisted knee MRI reading (8). Analogously, elements of human-AI collaboration could \naffect the outcomes of LLM-assisted differential diagnosis. In real-world practice, it is \nplausible that radiologists or radiology residents would use LLMs as an adjunct tool to \nsupport diagnostic reasoning rather than for fully autonomous differential diagnosis (9). \nUnder these circumstances , the human medical professional  assumes a pivotal \nposition in contextualizing the available clinical and visual information, formulating the \nprompt, critically reviewing the LLM response , and conducting further research  to \neventually derive a conclusion. Particularly considering the well-known propensity of \nLLM systems to generate factually incorrect information (so -called hallucinations) \n(10,11), a comprehensive evaluation of how users realistically interact with these \nsystems is imperative. Therefore, this study aimed to investigate the impact of human-\nLLM collaboration on accuracy and efficiency of brain MRI differential diagnosis.   \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint \nMethods \nEthical approval was waived by the institutional review board. \n \nStudy Sample \nSix radiology residents with less than 6 months of experience in neuroradiology were \nrecruited from the local departments of radiology and neuroradiology  as participants \nof the usability study  and randomized into two groups . All participants provided \ninformed consent. A total of twenty brain MRI exams obtained between 01/01/2016 \nand 12/31/2023 were selected from the local imaging database  and randomized into \ntwo sets (Figure 1). In each brain MRI scan, the image finding in question was denoted \nby an arrow. Selection criteria for participants and MRI scans are shown in Table 1. \n \nLarge Language Model (LLM) and Chatbot Interface \nPerplexityAI (© Perplexity AI Inc., San Francisco, USA) was chosen as chatbot \ninterface, given its ability to access real-time web content and to indicate its sources \nof information. GPT-4 (Generative Pre-trained Transformer 4), OpenAI’s most up -to-\ndate LLM, was selected as the model powering the search queries. \n \nStudy Design \nInitially, the LLM system was introduced to participants in a 10–15-minute training \nsession to ensure familiarity with its operation and functionality.  During this training, \nparticipants were presented several sample prompts and explored the tool using a \nselection of sample brain MRI cases. Then, each participant was tasked to determine \nthe most likely differential diagnoses of the annotated image finding in the brain MRI \nscans via conventional internet search for half  (n = 10) and via LLM-assisted search \n(© PerplexityAI) for the other half (n = 10) (Figure 1). Cases were excluded from the \nanalysis if participants were familiar with the case, or the image finding was not \nrecognized despite the annotation. Importantly, participants performing LLM-assisted \nsearch were allowed to conduct additional conventional internet search to validate \nLLM suggestions.  Participants were allowed to submit u p to three differential \ndiagnoses, ranked by relevance.  Alongside the MRI scan, participants received \ndemographic and clinical details of the patient case . All prompts were phrased in \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint \nEnglish. Interpretation times were measured using a time tracking software (To ggl \nTrack, © Toggl OÜ, Talinn, Estonia). Level of confidence was recorded for each case \non a Likert scale from 1-5 (1: very low confidence, 5: very high confidence). During the \nusability sessions, notes of relevant observations and comments were taken  by SHK \nand SS . Before and after the sessions, participants completed a questionnaire to \nevaluate the LLM -assisted search workflow and capture concerns, benefits, and \nlimitations. \n \nAnalysis \nTo determine accuracy of differential diagnoses, two different scoring systems were \napplied. In the first approach, participant responses were classified as “correct” if the \ncorrect diagnosis was included among the submitted differential diagnoses and \n“incorrect” if it was not (binary scoring system). In the second approach, participant \nresponses were assigned a score from 0 – 3, depending on the rank of the correct \ndiagnosis within the response (numeric scoring system) (Table 2). Inferential statistics \nwere performed using the chi -square test for binary scores and the Mann -Whitney U \ntest for numeric scores  and level of confidence . Interpretation times were analyzed \nusing the student’s t-test. The level of significance was set at p < 0.05.  \nLikert-scale questions of the questionnaires were analyzed by descriptive statistics. \nQualitative data from observation notes, comments and questionnaire responses were \nsummarized in tables categorizing data by relevant topics. Data manipulation, analysis \nand visualization were performed using Python (version 3.9.7). \n \n \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint \n Criteria Rationale \nBrain MRI \nScans \nAdult patient (at least 18 years \nold at time of exam) \nTo exclude conditions highly specific to a \npediatric subpopulation \nFocal image finding To define a clearly delimited finding for \nthe participants to interpret \nConfirmed diagnosis Confirmed diagnosis served as reference \nstandard for comparison \nInitial diagnosis at time of exam To simulate a more realistic scenario \nrequiring differential diagnosis \nNon-trivial, less common \nconditions \nTo ensure cases were challenging \nenough to require further research \nRadiology \nResidents \nLess than 6 months of dedicated \nexperience in neuroradiology \nInexperienced readers were \nhypothesized to benefit more from LLM -\nassistance than experienced ones \nTable 1: Inclusion Criteria \n \n  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint \n \nFigure 1: Study Design.  \n \n  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint \nScore Condition \n3 Correct diagnosis ranked first \n2 Correct diagnosis ranked second \n1 Correct diagnosis ranked third \n0 Correct diagnosis was not included in the response \nTable 2: Numeric scoring system for evaluating differential diagnoses.  \n \n  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint \nResults \nTwo responses were excluded from the analysis due to the participant’s familiarity with \nthe MRI scan  or inability to recognize the annotated image finding. An overview of \nselected clinical cases is provided in Supplement 1. \n \nQuantitative Findings \nLLM-assisted brain MRI differential diagnosis yielded superior accuracy, as evaluated \nby both binary ( 38/59 [LLM-assisted] vs 25/59 [conventional] correct diagnoses, p = \n0.03) and numeric scoring approach (median score of 2 [LLM -assisted] vs 0 \n[conventional], p = 0.04) (Figure 2). No difference in interpretation time (8.12 +/- 3.22 \nmin [LLM-assisted] vs 7.96 +/- 2.65 min [conventional], p = 0.76) was observed (Figure \n3). Similarly, the level of confidence did not differ significantly  (median of 2.5 [LLM -\nassisted] vs 3.0 [conventional], p = 0.96).  A screenshot of a sample LLM response is \nshown in Figure 4. Questionnaire results revealed a moderately positive evaluation of \nthe LLM-assisted workflow. Participants showed a slight tendency in favor of using the \nLLM tool in clinical practice  (median: 4). Quality of LLM responses were rated rather \npositively (median: 4) . The LLM system was easily adopted into the diagnostic \nworkflow by most participants (median: 4). The overall experience of the LLM-assisted \nsearch workflow was mixed (median: 3.5) (Figure 5).  \n \nQualitative Findings \nSeveral challenges in human -LLM interaction related to both human errors and \ntechnical limitations were observed (Table 3). Misleading or inaccurate search results \nattributable to human errors included inaccurate descriptions of image findings (e.g. \ndescribing the location of a cerebral cavernous venous malformation as “extra-axial”) \nor an omission of relevant imaging features (e.g. omission of multinodular morphology \nof a multinodular and vacuolating neuronal tumor; MVNT ). LLM search, in contrast, \nexhibited bias based on clinical information irrelevant to the diagnosis (e.g. history of \nkidney transplantation in a patient with posterior reversible encephalopathy syndrome; \nPRES) or connotative terminology (e.g. the term “juxtacortic al” was strongly \nassociated with multiple sclerosis). Participant feedback on LLM -assisted differential \ndiagnosis is illustrated in Table 4. Prior to the usability sessions, several participants \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint \nexpressed concerns about excessive reliance on the LLM system and consecutive \nimpairment of their own radiological training. Following the testing, participants pointed \nout the ability to give flexible instructions regarding scope (e.g. quantity of differential \ndiagnoses) and format (e.g. bullet points, table, sample images) of the search result \nas a key advantage over conventional internet search. Participants believed that \nusability of the LLM system for differential diagnosis could be enhanced by enabling \nvoice-based interactions and improving the accuracy of returned sample images. \n  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint \n \n \nFigure 2: Accuracy of differential diagnoses by workflow. A: Binary scoring system. Participant \nresponses were classified as either correct or incorrect.  LLM-assisted workflow yielded \nsuperior scores (p = 0.03). B: Numeric scoring system. A participant's response was assigned \na score between 0 and 3, depending on the rank of the correct diagnosis within the response \n(3: correct diagnosis ranked first, 0: correct diagnosis not included in response). LLM-assisted \nworkflow yielded superior scores (p = 0.04). \nA\nB\nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint \n \nFigure 3: Interpretation time. Interpretation times did not exhibit any statistically significant \ndifference (p = 0.76). \n \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint \n \nFigure 4: Screenshot of a sample LLM query (PerplexityAI). The correct diagnosis sought in \nthis case was hemangioblastoma.  \n  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint \n \nFigure 5: Post-testing questionnaire results (1: very low, 5: very high).  \n  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint \nChallenges Examples \nOmission of relevant \nclinical information \n- Omitting the age in a patient with spinocerebellar ataxia (resulted \nin misleading suggestions such as atypical Parkinson syndrome) \nInclusion of clinical \ninformation irrelevant to \nthe diagnosis \n- Indicating recent history of head trauma in a patient with an \nincidental finding (benign enhancing foramen magnum lesion) \n- Indicating a history of kidney transplantation in a patient with \nposterior reversible encephalopathy syndrome (PRES) \nInaccurate description of \nimaging findings \n- Describing the location of a cerebral cavernous venous \nmalformation as “subarachnoid” or “extra-axial” \n- Searching for differential diagnoses of global brain atrophy in a \npatient with focal atrophy of the caudate head \nOmission of relevant \nimaging features \n- Omitting the bubbly or multinodular appearance of a multinodular \nand vacuolating neuronal tumor  (MVNT) resulted in highly \nunspecific suggestions \nUsage of connotative \nterminology \n- Describing the location of a lesion as “juxtacortical” in a patient \nwith MVNT (was strongly associated with multiple sclerosis) \nLLM returning c ompletely \nunrelated content (very \nfew) \n- Upon a request for sample images of progressive multifocal \nleukoencephalopathy (PML), images of the prime minister of India \nwere returned \nTable 3: Challenges during human-LLM interaction derived from observations and participant \ncomments.  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint \nTable 4: Participant comments on LLM-assisted differential diagnosis. \nTheme Comments \nConcerns  \n(pre-testing) \nResidents might develop a strong dependence on the tool , educational effect \ncould be impaired \nExcessive reliance on LLM tool can promote intellectual laziness and \ncarelessness in image interpretation \nLLMs are known to create hallucinations, source of information is not always \nclear \nThe role of the radiologist might become obsolete as core tasks are increasingly \novertaken by AI tools including LLMs \nBenefits  \n \nPossibility to phrase open questions rather than rigid keyword searches is \nliberating \nLinks to information sources are embedded in the response \nInstructions can be given regarding the scope (e.g. quantity of differential \ndiagnoses suggested) and format of the response (e.g. table, bullet points) \nThe context of prior queries is retained so that follow-up questions can be posed \nUseful to obtain a quick overview of a broad range of differential diagnoses \nSuggestions for \nimprovement \nInteraction with the LLM system via voice \nImproved search of relevant sample images \nQuantitative data regarding the probability of certain diagnoses in the presence \nof specific imaging features \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint \nDiscussion \nIn this study, we conducted usability experiments to explore the role of human -LLM \ncollaboration in brain MRI differential diagnosis . Our results suggest that an LLM -\nassisted workflow has the potential to increase diagnostic accuracy as compared to \nconventional internet search . Yet, no clear effect on interpretation times and reader \nconfidence was observed. Participant ratings of the LLM-assisted workflow were only \nneutral to slightly positive. These findings are consistent with the observed frustration \nand delays caused by misleading LLM outputs. These were frequently due to irrelevant \nor omitted information in prompts , highlighting the critical role of human readers to \ncontextualize and filter available information. In addition, effective differential diagnosis \nwas contingent on critical evaluation and validation of initial LLM recommendations. \nReaders typically conducted further research to correlate image finding s with sample \nimages of suggested diagnoses. Focused internet search on trusted websites (e.g. \nRadiopaedia) proved more effective  for this purpose , indicating that  the joint use of \nLLMs and conventional internet search might outperform the exclusive use of LLMs . \nA conceptual model illustrating the role of the human agent in LLM-assisted differential \ndiagnosis and potential sources of error is shown in Figure 6 . Altogether, our results \nunderline the necessity to study collaborative efforts between humans and LLMs over \nLLMs in isolation to better reflect real -world conditions.  While LLMs can augment \nhuman capabilities, traditional neuroradiological expertise remains indispensable for \ntheir effective utilization. \nNotably, rapid advancements in  LLM technology demand continuous evaluations . \nRecent innovations, such as voice assistants enabling conversational interactions (e.g. \nas featured in OpenAI’s ChatGPT ), are transforming LLM usability . Earlier, the \nintroduction of speech recognition dictation systems has enhanced  productivity in \nradiology departments (12). It is yet to be determined whether voice interaction with \nLLMs can yield similar benefits. The emergence of multimodal LLMs capable of \nprocessing image inputs is expected to create new possibilities. Few recent studies \nhave demonstrated their potential to generate chest x -ray reports (13), and answer \nUSMLE questions involving radiological images  (14). In radiological differential \ndiagnosis, direct image processing by LLMs could significantly alter human -LLM \ninteractions by  eliminating the need for human image descriptions . Seamless \nintegration of LLMs into established health information systems could further boost \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint \nproductivity. For instance, prompt generation could be streamlined by directly \nimporting clinical information from a RIS or selecting a key image from a PACS system \nas input.  \nThis study has several limitations. First, only radiology residents with less than six \nmonths of experience in neuroradiology were included, based on the assumption that \nthis group would be most likely to require additional research for differential diagnosis. \nIt is unclear whether our findings would apply to more experienced readers. Second, \nhuman-LLM interactions were evaluated in a controlled environment but not in a real-\nworld clinical setting, where frequent interruptions and intense workload might alter \nreader behavior. Third, the participants’ familiarity with the LLM system was limited, \ncompared to their extensive experience with conventional internet search. Additional \nexposure and training could help users formulate more effective prompts , thereby \nreducing frustration and inefficiencies. Finally, a general-purpose LLM (GPT-4) was \nused. Models specifically trained for medicine (e.g. MED-PALM, GlassAI) (15–17) or \nradiology (18–20) are anticipated to further enhance clinical utility. \nIn conclusion, our study  shows that human -LLM collaboration has the potential to \nenhance differential diagnosis of brain MRI but recognizes the necessity to mitigate  \nboth human and technical errors to maximize effectiveness. \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint \n \nFigure 6: Conceptual model of human-LLM-Interaction for radiological differential diagnosis. \nWarning icons indicate potential sources of error in human-LLM collaboration. \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint \nReferences \n \n1.  Kumar Sarangi P, Irodi A, Panda S, Swapnesh Kumar Nayak D, Mondal H. \nRadiological Differential Diagnoses Based on Cardiovascular and Thoracic \nImaging Patterns: Perspectives of Four Large Language Models. Indian Journal \nof Radiology and Imaging. 2023; doi: 10.1055/s-0043-1777289. \n2.  Horiuchi D, Tatekawa H, Shimono T, et al. Accuracy of ChatGPT generated \ndiagnosis from patient’s medical history and imaging findings in neuroradiology \ncases. Neuroradiology. Neuroradiology; 2024;66(1). doi: 10.1007/S00234 -023-\n03252-4. \n3.  Ueda D, Mitsuyama Y, Takita H, et al. ChatGPT’s Diagnostic Performance from \nPatient History and Imaging Findings on the Diagnosis Please Quizzes. \nRadiology. Radiological Society of North America Inc.; 2023;308(1). doi: \n10.1148/RADIOL.231040. \n4.  Kottlors J, Bratke G, Rauen P, et al. Feasibility of Differential Diagnosis Based \non Imaging Patterns Using a Large Language Model. Radiology. Radiological \nSociety of North America Inc.; 2023;308(1). doi: 10.1148/radiol.231167. \n5.  Bhayana R, Bleakney RR, Krishna S. GPT -4 in Radiology: Improvements in \nAdvanced Reasoning. Radiology. Radiological Society of North America Inc.; \n2023;307(5). doi: 10.1148/RADIOL.230987. \n6.  Dratsch T, Chen X, Mehrizi MR, et al. Automation Bias in Mammography: The \nImpact of Artificial Intelligence BI -RADS Suggestions on Reader Performance. \nRadiology. Radiological Society of North America Inc.; 2023;307(4). doi: \n10.1148/RADIOL.222176. \n7.  Bernstein MH, Atalay MK, Dibble EH, et al. Can incorrect artificial intelligence \n(AI) results impact radiologists, and if so, what can we do about it? A multi-reader \npilot study of lung cancer detection with chest radiography. Eur Radiol. Springer \nScience and Business Media Deutschland GmbH; 2023;33(11):8263–8269. doi: \n10.1007/S00330-023-09747-1. \n8.  Cabitza F, Campagner A, Sconfienza LM. Studying human -AI collaboration \nprotocols: the case of the Kasparov’s law in radiological double reading. Health \nInf Sci Syst. Springer Science and Business Media Deutschland GmbH; \n2021;9(1):1–20. doi: 10.1007/S13755-021-00138-8. \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint \n9.  Shah NH, Entwistle D, Pfeffer MA. Creation and Adoption of Large Language \nModels in Medicine. JAMA. American Medical Association; 2023;330(9):866 –\n869. doi: 10.1001/JAMA.2023.14217. \n10.  Pal A, Umapathi LK, Sankarasubbu M. Med -HALT: Medical Domain \nHallucination Test for Large Language Models. arXiv preprint. Association for \nComputational Linguistics (ACL); 2023;314 –334. doi: 10.18653/v1/2023.conll -\n1.21. \n11.  Azamfirei R, Kudchadkar SR, Fackler J. Large language models and the perils \nof their hallucinations. Crit Care. BioMed Central Ltd; 2023;27(1):1 –2. doi: \n10.1186/S13054-023-04393-X. \n12.  Al-Aiad A, Momani AK, Alnsour Y, Alsharo M. The Impact of Speech Recognition \nSystems on The Productivity and The Workflow in Radiology Departments: A \nSystematic Review. AMCIS 2020 TREOs. 2020; \nhttps://aisel.aisnet.org/treos_amcis2020/62. Accessed January 14, 2024. \n13.  Hyland SL, Bannur S, Bouzid K, et al. MAIRA-1: A specialised large multimodal \nmodel for radiology report generation. arXiv preprint. 2023; \nhttps://arxiv.org/abs/2311.13668v1. Accessed January 14, 2024. \n14.  Yang Z, Yao Z, Tasmin M, et al. Performance of Multimodal GPT-4V on USMLE \nwith Image: Potential for Imaging Diagnostic Support with Explanations. \nmedRxiv. Cold Spring Harbor Laboratory Press; 2023;2023.10.26.23297629. \ndoi: 10.1101/2023.10.26.23297629. \n15.  Nazario-Johnson L, Zaki HA, Tung GA. Use of Large Language Models to \nPredict Neuroimaging. Journal of the American College of Radiology. Elsevier; \n2023;20(10):1004–1009. doi: 10.1016/J.JACR.2023.06.008. \n16.  Singhal K, Tu T, Gottweis J, et al. Towards Expert-Level Medical Question \nAnswering with Large Language Models. 2023; \nhttps://arxiv.org/abs/2305.09617v1. Accessed January 15, 2024. \n17.  Li Y, Li Z, Zhang K, Dan R, Jiang S, Zhang Y. ChatDoctor: A Medical Chat Model \nFine-Tuned on a Large Language Model Meta -AI (LLaMA) Using Medical \nDomain Knowledge. Cureus. Springer Science and Business Media LLC; 2023; \ndoi: 10.7759/cureus.40895. \n18.  Yan A, McAuley J, Lu X, et al. RadBERT: Adapting Transformer-based Language \nModels to Radiology. Radiol Artif Intell. Radiological Society of North America \nInc.; 2022;4(4):210258. doi: 10.1148/ryai.210258. \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint \n19.  Liu Z, Li Y, Shu P, et al. Radiology-Llama2: Best-in-Class Large Language Model \nfor Radiology. 2023; https://arxiv.org/abs/2309.06419v1. Accessed January 15, \n2024. \n20.  Liu Z, Zhong A, Li Y, et al. Tailoring Large Language Models to  Radiology: A \nPreliminary Approach to  LLM Adaptation for  a Highly Specialized Domain. \nLecture Notes in Computer Science (including subseries Lecture Notes in \nArtificial Intelligence and Lecture Notes in Bioinformatics). Springer Science and \nBusiness Media Deutschland GmbH; 2024;14348 LNCS:464 –473. doi: \n10.1007/978-3-031-45673-2_46. \n  \nAll rights reserved. No reuse allowed without permission. \nperpetuity. \npreprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in \nThe copyright holder for thisthis version posted February 6, 2024. ; https://doi.org/10.1101/2024.02.05.24302099doi: medRxiv preprint ",
  "topic": "Usability",
  "concepts": [
    {
      "name": "Usability",
      "score": 0.7028595805168152
    },
    {
      "name": "Medical diagnosis",
      "score": 0.7026044130325317
    },
    {
      "name": "Differential diagnosis",
      "score": 0.6616103649139404
    },
    {
      "name": "Context (archaeology)",
      "score": 0.583100438117981
    },
    {
      "name": "Medicine",
      "score": 0.5074805617332458
    },
    {
      "name": "Medical physics",
      "score": 0.4380805492401123
    },
    {
      "name": "Test (biology)",
      "score": 0.43715745210647583
    },
    {
      "name": "Psychology",
      "score": 0.36744606494903564
    },
    {
      "name": "Computer science",
      "score": 0.34641802310943604
    },
    {
      "name": "Radiology",
      "score": 0.2898164987564087
    },
    {
      "name": "Pathology",
      "score": 0.21944335103034973
    },
    {
      "name": "Human–computer interaction",
      "score": 0.12526798248291016
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I2802619606",
      "name": "Klinikum rechts der Isar",
      "country": "DE"
    }
  ],
  "cited_by": 8
}