{
  "title": "Use of large language models to identify pseudo‐information: Implications for health information",
  "url": "https://openalex.org/W4408672002",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2138823097",
      "name": "Boris Schmitz",
      "affiliations": [
        "Witten/Herdecke University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4406152291",
    "https://openalex.org/W2046866325",
    "https://openalex.org/W4211108457",
    "https://openalex.org/W4383226706",
    "https://openalex.org/W4399320026",
    "https://openalex.org/W4396894256",
    "https://openalex.org/W4386022860",
    "https://openalex.org/W4382786691",
    "https://openalex.org/W4310086997",
    "https://openalex.org/W4393191744",
    "https://openalex.org/W4321277158",
    "https://openalex.org/W4366816003",
    "https://openalex.org/W2891877139",
    "https://openalex.org/W2921120375",
    "https://openalex.org/W4366447635"
  ],
  "abstract": "Abstract Background Open‐access scientific research is an essential source of health‐related information and self‐education. Artificial intelligence‐based large language models (LMMs) may be used to identify erroneous health information. Objective To investigate to what extent LMMs can be used to identify pseudo‐information. Methods Four common LMM applications (ChatGPT‐4o, Claude 3.5 Sonnet, Gemini and Copilot) were used to investigate their capability to indicate erroneous information provided in an open‐access article. Results Initially, ChatGPT‐4o and Claude were able to mark the provided article as an unreliable information source, identifying most of the inaccuracy problems. The assessments provided by Gemini and Copilot were inaccurate, as several critical aspects were not identified or were misinterpreted. During the validation phase, the initially accurate assessment of ChatGPT‐4o was not reproducible, and only Claude was able to detect several critical issues in this phase. The verdicts of Copilot and Gemini remained largely unaltered. Discussion Large heterogeneity exists between LMMs in identifying inaccurate pseudo‐information. Replication in LMM output may constitute a significant hurdle in their application. Conclusion The accuracy of LMMs needs to be further improved until they can be reliably used by patients for health‐related online information and as assistant tools for health information and library services workers without restriction.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6745395064353943
    },
    {
      "name": "Replication (statistics)",
      "score": 0.4243672788143158
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4215801954269409
    },
    {
      "name": "Machine learning",
      "score": 0.3773605227470398
    },
    {
      "name": "Data science",
      "score": 0.3630076050758362
    },
    {
      "name": "Statistics",
      "score": 0.1804259717464447
    },
    {
      "name": "Mathematics",
      "score": 0.1508978307247162
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I155976169",
      "name": "Witten/Herdecke University",
      "country": "DE"
    }
  ]
}