{
  "title": "Multi-view Intent Learning and Alignment with Large Language Models for Session-based Recommendation",
  "url": "https://openalex.org/W4409309502",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5059123504",
      "name": "Shutong Qiao",
      "affiliations": [
        "Chongqing University"
      ]
    },
    {
      "id": "https://openalex.org/A5101568954",
      "name": "Wei Zhou",
      "affiliations": [
        "Chongqing University"
      ]
    },
    {
      "id": "https://openalex.org/A5024416196",
      "name": "Junhao Wen",
      "affiliations": [
        "Chongqing University"
      ]
    },
    {
      "id": "https://openalex.org/A5078622343",
      "name": "Chen Gao",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A5100311711",
      "name": "Qun Luo",
      "affiliations": [
        "Tencent (China)"
      ]
    },
    {
      "id": "https://openalex.org/A5057713388",
      "name": "Peixuan Chen",
      "affiliations": [
        "Tencent (China)"
      ]
    },
    {
      "id": "https://openalex.org/A5100355277",
      "name": "Yong Li",
      "affiliations": [
        "Tsinghua University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2171960770",
    "https://openalex.org/W4386728933",
    "https://openalex.org/W4406263938",
    "https://openalex.org/W4384641232",
    "https://openalex.org/W4396812190",
    "https://openalex.org/W2040367556",
    "https://openalex.org/W4296591867",
    "https://openalex.org/W4389520443",
    "https://openalex.org/W4386729952",
    "https://openalex.org/W4367046963",
    "https://openalex.org/W2963367478",
    "https://openalex.org/W3027879771",
    "https://openalex.org/W4387848745",
    "https://openalex.org/W2030808931",
    "https://openalex.org/W2489292218",
    "https://openalex.org/W4387846600",
    "https://openalex.org/W2171279286",
    "https://openalex.org/W2116341502",
    "https://openalex.org/W4283702870",
    "https://openalex.org/W4377138220",
    "https://openalex.org/W2953586472",
    "https://openalex.org/W3190939583",
    "https://openalex.org/W3034329572",
    "https://openalex.org/W4392367398",
    "https://openalex.org/W4399554739",
    "https://openalex.org/W4405674754",
    "https://openalex.org/W4384648324",
    "https://openalex.org/W4399061921",
    "https://openalex.org/W1802825888",
    "https://openalex.org/W3101707147",
    "https://openalex.org/W3173365306",
    "https://openalex.org/W3206932362",
    "https://openalex.org/W4400531852",
    "https://openalex.org/W3177063776",
    "https://openalex.org/W3170767867",
    "https://openalex.org/W4284686273",
    "https://openalex.org/W2809307135",
    "https://openalex.org/W2964926209",
    "https://openalex.org/W3106433415",
    "https://openalex.org/W4396843692",
    "https://openalex.org/W2964044287",
    "https://openalex.org/W2892880750",
    "https://openalex.org/W2605350416"
  ],
  "abstract": "Session-based recommendation (SBR) methods often rely on user behavior data, which can struggle with the sparsity of session data, limiting performance. Researchers have identified that beyond behavioral signals, rich semantic information in item descriptions is crucial for capturing hidden user intent. While Large Language Models (LLMs) offer new ways to leverage this semantic data, the challenges of session anonymity, short-sequence nature, and high LLM training costs have hindered the development of a lightweight, efficient LLM framework for SBR. To address the above challenges, we propose an LLM-enhanced SBR framework that integrates semantic and behavioral signals from multiple views. This two-stage framework leverages the strengths of both LLMs and traditional SBR models while minimizing training costs. In the first stage, we use multi-view prompts to infer latent user intentions at the session semantic level, supported by an intent localization module to alleviate LLM hallucinations. In the second stage, we align and unify these semantic inferences with behavioral representations, effectively merging insights from both large and small models. Extensive experiments on two real datasets demonstrate that the LLM4SBR framework can effectively improve model performance. We release our codes along with the baselines at https://github.com/tsinghua-fib-lab/LLM4SBR .",
  "full_text": null,
  "topic": "Session (web analytics)",
  "concepts": [
    {
      "name": "Session (web analytics)",
      "score": 0.8532490730285645
    },
    {
      "name": "Computer science",
      "score": 0.6654281616210938
    },
    {
      "name": "Natural language processing",
      "score": 0.36747485399246216
    },
    {
      "name": "Artificial intelligence",
      "score": 0.36662915349006653
    },
    {
      "name": "World Wide Web",
      "score": 0.23472890257835388
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I158842170",
      "name": "Chongqing University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I99065089",
      "name": "Tsinghua University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I2250653659",
      "name": "Tencent (China)",
      "country": "CN"
    }
  ],
  "cited_by": 1
}