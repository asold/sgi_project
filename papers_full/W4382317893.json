{
  "title": "Build-a-Bot: Teaching Conversational AI Using a Transformer-Based Intent Recognition and Question Answering Architecture",
  "url": "https://openalex.org/W4382317893",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5042515229",
      "name": "Kate Pearce",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5004847166",
      "name": "Sharifa Alghowinem",
      "affiliations": [
        "Human Media"
      ]
    },
    {
      "id": "https://openalex.org/A5108541589",
      "name": "Cynthia Breazeal",
      "affiliations": [
        "Human Media"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6778883912",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W6795749201",
    "https://openalex.org/W2792245983",
    "https://openalex.org/W6809207687",
    "https://openalex.org/W6685265195",
    "https://openalex.org/W4292429913",
    "https://openalex.org/W6797141053",
    "https://openalex.org/W2301095666",
    "https://openalex.org/W3174929835",
    "https://openalex.org/W6638194910",
    "https://openalex.org/W6679802028",
    "https://openalex.org/W2981852735",
    "https://openalex.org/W6718053083",
    "https://openalex.org/W3033552209",
    "https://openalex.org/W2978017171",
    "https://openalex.org/W2284660317",
    "https://openalex.org/W1996988972",
    "https://openalex.org/W3188331065",
    "https://openalex.org/W6772984392",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W2799054028",
    "https://openalex.org/W4289342549",
    "https://openalex.org/W3174307976",
    "https://openalex.org/W2134512579",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2923014074",
    "https://openalex.org/W2963748441",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4230776473",
    "https://openalex.org/W3174828871",
    "https://openalex.org/W2963216553",
    "https://openalex.org/W2965058023",
    "https://openalex.org/W4214663417"
  ],
  "abstract": "As artificial intelligence (AI) becomes a prominent part of modern life, AI literacy is becoming important for all citizens, not just those in technology careers. Previous research in AI education materials has largely focused on the introduction of terminology as well as AI use cases and ethics, but few allow students to learn by creating their own machine learning models. Therefore, there is a need for enriching AI educational tools with more adaptable and flexible platforms for interested educators with any level of technical experience to utilize within their teaching material. As such, we propose the development of an open-source tool (Build-A-Bot) for students and teachers to not only create their own transformer-based chatbots based on their own course material but also learn the fundamentals of AI through the model creation process. The primary concern of this paper is the creation of an interface for students to learn the principles of artificial intelligence by using a natural language pipeline to train a customized model to answer questions based on their own school curriculums. The model uses contexts given by their instructor, such as chapters of a textbook, to answer questions and is deployed on an interactive chatbot/voice agent. The pipeline teaches students data collection, data augmentation, intent recognition, and question answering by having them work through each of these processes while creating their AI agent, diverging from previous chatbot work where students and teachers use the bots as black-boxes with no abilities for customization or the bots lack AI capabilities, with the majority of dialogue scripts being rule-based. In addition, our tool is designed to make each step of this pipeline intuitive for students at a middle-school level. Further work primarily lies in providing our tool to schools and seeking student and teacher evaluations.",
  "full_text": "Build-a-Bot: Teaching Conversational AI Using a Transformer-Based Intent\nRecognition and Question Answering Architecture\nKate Pearce1, Sharifa Alghowinem2, Cynthia Breazeal2\n1 Massachusetts Institute of Technology\n2 MIT Media Lab\nk8pearce@mit.edu, sharifah@media.mit.edu, cynthiab@media.mit.edu\nAbstract\nAs artificial intelligence (AI) becomes a prominent part of\nmodern life, AI literacy is becoming important for all citi-\nzens, not just those in technology careers. Previous research\nin AI education materials has largely focused on the intro-\nduction of terminology as well as AI use cases and ethics,\nbut few allow students to learn by creating their own machine\nlearning models. Therefore, there is a need for enriching AI\neducational tools with more adaptable and flexible platforms\nfor interested educators with any level of technical experience\nto utilize within their teaching material. As such, we propose\nthe development of an open-source tool (Build-a-Bot) for stu-\ndents and teachers to not only create their own transformer-\nbased chatbots based on their own course material, but also\nlearn the fundamentals of AI through the model creation pro-\ncess. The primary concern of this paper is the creation of\nan interface for students to learn the principles of artificial\nintelligence by using a natural language pipeline to train a\ncustomized model to answer questions based on their own\nschool curriculums. The model uses contexts given by their\ninstructor, such as chapters of a textbook, to answer questions\nand is deployed on an interactive chatbot/voice agent. The\npipeline teaches students data collection, data augmentation,\nintent recognition, and question answering by having them\nwork through each of these processes while creating their AI\nagent, diverging from previous chatbot work where students\nand teachers use the bots as black-boxes with no abilities for\ncustomization or the bots lack AI capabilities, with the major-\nity of dialogue scripts being rule-based. In addition, our tool\nis designed to make each step of this pipeline intuitive for stu-\ndents at a middle-school level. Further work primarily lies in\nproviding our tool to schools and seeking student and teacher\nevaluations.\nIntroduction\nWithin the past few years, quality STEM education has be-\ncome an ever-pressing issue, especially in regards to increas-\ning the representation of racial and gender minorities within\nSTEM fields (Fry, Kennedy, and Funk 2021). Artificial intel-\nligence (AI) education, in particular, has become necessary\nnot only for prospective computer scientists and engineers,\nbut for everyone: as AI technologies become facets of daily\nlife, AI literacy becomes a crucial skill for the next genera-\ntion.\nCopyright © 2023, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\nMuch of the current work in AI education centers around\ncurriculum design and classroom implementation – for ex-\nample, MIT’s AI Ethics for Middle School curriculum fo-\ncuses on showing students examples of AI that most of them\nregularly use, developing their programmatic thinking skills,\nand raising their awareness of ethical issues concerning AI\nlike algorithmic bias (Williams et al. 2022). Current liter-\nature is primarily focused on lesson and activity design to\nintroduce students to AI terminology and the computational\nmindset (Kim et al. 2021) as well as broad perspective and\nethical issues related to AI (Wollowski et al. 2016).\nWhile previous research has focused on curriculum de-\nvelopment, this paper proposes a tool for AI education that\nwould allow students to explore the supervised learning pro-\ncess by creating their own chatbots using a transformer-\nbased language pipeline. Our proposed tool explores the fol-\nlowing:\n• The use of multiple transformer models to create a sus-\ntainable and scalable pipeline for human-AI educational\ninteraction, utilizing the following:\n– Data augmentation methods for question-based dia-\nlogue.\n– An intent recognition model to classify student ques-\ntions by topic.\n– Extractive and generative question answering models\nfor answering student questions given a context about\nthe topic the question is labeled as.\n• Providing an open-source tool to facilitate constructivist\nlearning of AI in the classroom, which enables the fol-\nlowing:\n– AI education by instructors of any level of technical\nexpertise.\n– Student development of problem-solving skills by hav-\ning them understand and engage with a complex sys-\ntem.\nEducational Background\nAI Education\nAs artificial intelligence (AI) becomes increasingly power-\nful, and its applications grow to span almost every field, the\ndevelopment of an AI education curriculum grows increas-\ningly relevant. Previous works (Kim et al. 2021) have sought\nThe Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI-23)\n16025\nFigure 1: Sample elementary school AI curriculum based\non core competencies of knowledge, skill, and attitude (Kim\net al. 2021).\nto create an educational framework for AI and have estab-\nlished three AI competencies for primary and secondary stu-\ndents: knowledge, skill, and attitude. While AI knowledge is\ndescribed as knowing the definition and types of AI, AI skill\nrevolves around knowing how to use AI tools and AI atti-\ntude around describing the impact of and collaborating with\nAI. The goal of their framework is to develop student’s AI\nliteracy: even students who don’t pursue careers as technol-\nogists should have a basic understanding of how AI works\nand how it is engaged with.\nExisting curriculums to build AI literacy at the elemen-\ntary and middle school level largely focus on programmatic\nthinking and applications of AI: Google’s Teachable Ma-\nchine is a popular tool to demonstrate the process of learn-\ning from a dataset, and students may be more directly in-\nstructed on examples of AI seen in daily life, like YouTube’s\nrecommendation system (Sabuncuoglu 2020). While these\nmethods do well in enhancing student awareness of AI, gaps\nexist between what is being taught by educators and what\nis desired by AI practitioners; for example, while educators\noften focus on puzzles and games to illustrate AI, practition-\ners largely cite understanding and engineering systems as a\nnecessary learning objective (Wollowski et al. 2016).\nThe AI4K12 initiative has developed AI curriculum based\non ”big ideas” that every K12 students should know about\nAI based on consultations with both AI experts and K-12\neducators. These themes are broad guidelines for AI educa-\ntion and include ”Perception”, ”Representation and Reason-\ning”, ”Learning”, ”Natural Interaction”, and ”Societal Im-\npact”. Build-a-Bot primarily serves an an educational tool\nfor ”Learning” and ”Natural Interaction”, detailed in Figure\n2, as students learn the process of how models can be trained\nto answer questions and develop a chatbot that they can\ndirectly interact with using those models (Touretzky et al.\n2019b).\nConstructivist Educational Model\nConstructivism refers to a theory of learning in which stu-\ndents construct unique conceptual understandings for them-\nselves, rather than simply being ”handed” these understand-\nFigure 2: The AI4K12 initiative’s Big Ideas of AI. Build-a-\nBot allows students to ”tinker” with AI models in order to\nunderstand these concepts (Touretzky et al. 2019a).\nings by a teacher (Piaget 1955). Constructivists typically\nview traditional lecture modes of instruction as promoting\nrigid and simplified knowledge structures that hinder future\nlearning and preventing students from engaging with the full\nnuance of topics. Moreover, social constructivism, a variant\nof constructivism, is a framework that has risen in popu-\nlarity in recent educational history in which students con-\nstruct conceptual understandings through interactions with\neach other, including discussion and collaborative problem-\nsolving (Li, Lund, and Nordsteien 2021).\nMuch recent work in educational methodology has cen-\ntered around approaches to augment the constructivist model\nin the classroom. Student-centered learning environments,\nfor example, tailor instruction to each student’s individual\nneeds and perspectives; students are to take full responsibil-\nity for their learning and are engaged by connecting the cur-\nriculum to their interests in the world at large (J. Bancifra\n2022). While active learning has been rather loosely defined\nin current literature, it serves to complement the responsibil-\nity aspect of student-centered approaches by having students\nlearn by solving problems and engaging in other creative ac-\ntivities in order to build knowledge, as opposed to passive\nlecture-based instruction (Foster and Stagl 2018). There is a\nsubstantial body of literature proving the efficacy of active\nlearning, including increased content retention as well as im-\nprovements in student self-esteem and engagement in learn-\ning (Prince 2004). Transformational teaching, meanwhile, is\nan approach to implementing the social constructivist model\nin which instructors promote dynamic relationships between\nstudents and themselves in order to help students master\ncourse concepts while also improving their attitudes towards\n16026\nlearning itself (Slavich and Zimbardo 2012).\nBuild-a-Bot implements these methodologies in its de-\nsign; students learn by studying and modifying a complex\nlanguage system, rather than being directly instructed on AI\nprinciples. Students are able to make chatbots on any topic\nof interest and develop a new understanding of how AI is\nused and why it is useful throughout the chatbot’s creation.\nTechnical Background\nConversational AI\nThe purpose of conversational AI is to develop an agent that\ncan engage in human-like conversation that is both infor-\nmative and controllable, meaning that answers should be\ngrounded in external knowledge and generated in a speci-\nfied style (Fu et al. 2022). Models should be able to both\nunderstand questions and generate appropriate responses, as\nwell as understand conversational history in order to engage\nin multi-turn dialogue effectively (Tao et al. 2021).\nTransformers\nThough recurrent neural networks and long short-term mem-\nory have been established as language modeling approaches,\nthese models factor computation along symbol positions of\ninput and output sequences, which precludes paralleliza-\ntion among training samples. Bidirectional versions of these\nmodels, which encode sentences from both start to end\nand end to start, have been used to mitigate this problem,\nthough this doesn’t substantially increase performance for\nlong dependencies (Kiperwasser and Goldberg 2016). At-\ntention mechanisms, which allow modeling of dependencies\nwithout consideration of their distance within input and out-\nput sequences, have been introduced to combat this problem;\nthe transformer is the first model to rely entirely on the use\nof attention mechanisms without being used alongside a re-\ncurrent neural network (Vaswani et al. 2017).\nVarious transformer models have been developed, typi-\ncally intended to increase performance on GLUE benchmark\ntests, which tests natural language understanding based on\nten different tasks, such as sentiment analysis and ques-\ntion answering (Wang et al. 2018). Additionally, while some\ntransformers like GPT-3 are trained on large datasets like\nCommon Crawl and with hundreds of billions of parameters\n(Brown et al. 2020), others like DistilBERT are designed on\nthe smaller scale and are easier to implement in practical\ncontexts (Sanh et al. 2019).\nBERT\nBERT (Bidirectional Encoder Representations from Trans-\nformers) is a transformer language model which uses trans-\nfer learning to learn unsupervised from a corpus on unla-\nbeled data; the size of the dataset allows BERT to overcome\ncommon model weaknesses like overfitting and underfit-\nting. When BERT is fine-tuned with a smaller set of labeled\ndata, it can be used for a variety of natural language tasks\nlike question answering and sentiment analysis. BERT’s ar-\nchitecture is largely similar across different tasks, making\nit an effective model for less common language tasks like\nintent recognition. BERT has achieved novel performance\non GLUE benchmark testing, a test of model performance\nbased on ten natural language understanding tasks (Wang\net al. 2018), with a base score of 79.6 for BERT BASE and\n82.1 for BERT LARGE (Devlin et al. 2018). When using\nBuild-a-Bot, students train their own BERT model for intent\nrecognition based on questions that they write and label.\nDistilBERT\nDistilBERT is a model with the same general architecture as\nBERT, but that uses distillation during pretraining in order\nto reduce the number of layers and make the model more\nlightweight. DistilBERT reduces BERT’s size by forty per-\ncent while increasing speed by sixty percent and retaining\nninety-seven percent of BERT’s language understanding ca-\npacities, making it an effective transformer for practical ap-\nplications, like training with fewer computational resources\n(Sanh et al. 2019). DistilBERT is used for the extractive\nquestion answering step in Build-a-Bot. Students use a Dis-\ntilBERT model pretrained on the Stanford Question Answer-\ning Dataset, seen in Figure 5, a dataset consisting of over one\nhundred thousands questions about Wikipedia articles where\nthe answer is a segment of text from the corresponding ar-\nticle (Rajpurkar et al. 2016), rather than training the model\nthemselves.\nT5\nT5 (Text-To-Text Transfer Transformer) is a transformer\nmodel that converts all downstream language tasks, such\nas question answering, sentence completion, and sentiment\nanalysis, to a text-to-text format (demonstrated in Figure 6),\nin contrast with BERT models that can only output a span\nof the input or a class label. T5 achieved a state-of-the-art\nGLUE score of 85.97 in 2019 (Raffel et al. 2022). A pre-\ntrained T5 model is used for the generative question answer-\ning step in Build-a-Bot.\nIntent Recognition and Question Answering\nModel Architecture\nPipeline Overview\nThe language modeling pipeline is used to generate answers\nto student questions and consists of data labeling and col-\nlection, data augmentation, filtering, intent recognition, and\nquestion answering. The purpose of applying the pipeline\ndesign is to develop a sustainable architecture for student\nquestion answering and interaction that allows easy retrain-\ning as new data is added as students add more labeled ques-\ntions to their dataset; pipeline designs are popular in the NLP\ncommunity due to their ease of scalability, modifiability, and\ncomplexity (Gorton et al. 2011). Moreover, this design al-\nlows students to dissect and modify a system of multiple\ntransformers and data processes, providing both a compre-\nhensive overview of the supervised learning process and am-\nple opportunity for students to actively tinker and explore.\nData Collection and Labeling\nData is collected by the students in the form of questions;\nthese questions are then labeled by students with an intent\n16027\nFigure 3: Tree diagram depicting the types and goals of conversational AI; retrieval-based methods evaluate the relevancy of\npre-written responses, while generative approaches generate new responses. (Fu et al. 2022).\nFigure 4: Transformer model architecture. The encoder is\ncomposed of six identical layers; in each layer, there are\ntwo sublayers, one of which is the multi-head self-attention\nmechanism (Vaswani et al. 2017).\nFigure 5: Question-and-answer pairs with corresponding\nSQuAD context (Rajpurkar et al. 2016). Note that most an-\nswers are a few words at most – students are encouraged to\ncompare results with the generative T5 model and learn to\nuse policy to make the resulting answers more conversation-\nlike.\nFigure 6: Text-to-text framework. All tasks are converted\nto an input text to output text format, including tasks like\nmachine translation, summarization, and sentiment analysis\n(Raffel et al. 2022).\npreviously set by their instructor. For example, an instructor\nmight set six intents based on each chapter from a textbook,\nand, as students asked questions about the textbook material,\n16028\nFigure 7: Diagram of the pipeline. The orange boxes show\nthe five steps of the process, the green boxes show the\nmethodology for each step, and the blue boxes show the\noutput for each step. Data collection and augmentation are\ndone before model training, while a student question will go\nthrough the three remaining steps.\nthey would upload these questions with a label correspond-\ning to the chapter of the textbook where the answer would\nbe found.\nData Augmentation\nData augmentation is the practice of creating synthetic data\nto add samples to a limited dataset (Feng et al. 2021). It is\nnecessary in this context due to the small size of the natu-\nral language dataset; students would find it difficult to col-\nlect hundreds of questions for each intent. Backtranslation\nis used in order to generate synthetic data; machine transla-\ntion is used to translate questions into another language and\nthen back to the original language, creating utterances with\nsimilar semantic meaning but different syntactic structures\n(Feng et al. 2021). The NLPAug library is used to implement\nthis technique on the student-created question dataset; the\nBacktranslationAug method is used in order to seamlessly\nleverage two translation models to create synthetic data (Ma\n2019). Moreover, the inclusion of this functionality pushes\nstudents to consider the importance of the size of their train-\ning datasets, and a high-level explanation of the technique\nfurther engages learners.\nPreliminary Filters\nKeyword filters can be added as a policy to precisely an-\nswer general technical questions, sway from distractors, and\nimprove user experience; for example, for a class requiring\nstudents to enter a certain username and password to use\ndigital course materials, a prewritten response specifying the\nformat of the login could be given to any question contain-\ning the keyword ”login”, or if a student asks for the location\nof the classroom, a prewritten response giving the classroom\nnumber could be given. Questions that contain keywords do\nnot enter the intent recognition and question answering parts\nFigure 8: General example of machine translation used to\ncreate synthetic data; in this case, sample sequences are\ntranslated from English, to French, then back to English.\n(Sennrich, Haddow, and Birch 2016)\nof the pipeline. This step is also used to help students distin-\nguished between AI and rule-based algorithms, as well as\nthe importance of policy.\nIntent Recognition\nIntent recognition is used to classify which context should\nbe used to answer a question; this helps the model give more\nrelevant answers by using more relevant contexts. Labels for\ncontexts are set by the instructor at the beginning of the ses-\nsion – use cases might include a history class teacher speci-\nfying each intent as a different historical figure, and using a\nshort biography of the corresponding figure as each intent’s\ncontext, or a biology teacher setting each intent as a chapter\nof the textbook and using the text from that chapter as the\ncontext. A BERT-based architecture trained on the student\nquestion dataset is used for the intent recognition model,\nwith the number of epochs set by the students while they\nlearn about model training.\nQuestion Answering\nThe final phase of the pipeline is used to answer stu-\ndent questions using a context based on the previously-\nrecognized intent. Two transformer models were tested for\nthis task: DistilBERT and T5. These models are extractive\nand generative, respectively; while DistilBERT answers are\nexclusively comprised of spans of tokens from the context,\nT5 answers are generated based on the given context. Distil-\nBERT’s lightweight nature makes it ideal for practical appli-\ncation in the classroom context; answer generation is speedy\nand not computationally taxing. Unlike the intent recog-\nnition model, which is customized to the students’ ques-\ntions, the question answering models are general models\npretrained on the Stanford Question Answering dataset, so\nstudents only use, rather than train, these models. Students\nare encouraged to try training with both transformers and\ncompare results.\nBuild-a-Bot Tool Interface\nBuild-a-Bot will be deployed as an open-source tool avail-\nable on GitHub; a PySimpleGUI is used to present Python\ncode from Jupyter notebooks accompanied by visuals, ex-\nplanations, and interaction opportunities. The use of this\n16029\ninterface allows the program to be downloaded as an ex-\necutable file, making setup easy even for instructors with\nlittle technical experience. The first notebook contains intro-\nductory notes and steps for the instructor to define intents\nand contexts alongside students; afterwards, each step of the\npipeline has its own devoted notebook for students to input\ndata before moving onto the next step. In order to keep the\ntool middle-school appropriate, students are not required to\nmodify code; rather, the main tasks revolve around upload-\ning data and other inputs through a separate PySimpleGUI\ninterface. The students’ final chatbots are deployed in a new\nwindow using the chatbotAI library, which inputs model re-\nsponses into a texting-style interface. Each notebook is also\naccompanied by slides that heavily incorporate images to\nkeep student interest.\nFigure 9: Demo of the interface that serves as the students’\nhome page; they return here after completing each step to\naccess the next one. Documentation is downloaded along-\nside the executable to provide information about Build-a-\nBot and how to use it. Step 1 is data collection, Step 2 is\ndata augmentation, Step 3 is policy filtering, Step 4 is intent\nrecognition, Step 5 is extractive question answering, Step 6\nis generative question answering, and Step 7 is final deploy-\nment of the models as a chatbot in a new window.\nFigure 10: Example of instruction from the augmentation\nstep. Metaphors are used to make the material suitable for a\nmiddle school audience.\nFigure 11: A student interaction from the testing phase in the\ngenerative question answering step. The chatbot’s topic was\nsupervised learning, and the recognizing intent, in this case,\nwas model training.\nFigure 12: A student interaction with a final deployed chat-\nbot, where the recognized intent is ”model testing” and the\ngenerative T5 question answering model is used to generate\nan answer from a context about model testing. The chatbot\nis deployed in a new window using the chatbotAI library.\nFigure 13: File structure of the tool; the interface sec-\ntion contains code to make all of the notebooks accessible\nthrough a PySimpleGUI interface, which is downloaded by\ninstructors as an executable file.\nTesting Suite\nTwo testing suites have been developed to use with Build-a-\nBot; the first is a machine learning suite with contexts about\neach step of the machine learning process (e.g. data labeling,\ntraining). This suite was used in the interface images above.\nThe second is based off of the Utah State Board of Educa-\ntion’s open-source fifth grade science textbook (Utah State\nBoard of Education OER 2022), with seventy-five questions\nlabeled with one of five intents – Patterns in Earth’s Fea-\ntures, Earth’s Water, Weathering and Erosion, Interactions\nbetween Systems, and Impact on Humans – which are based\non earth science chapters on the textbooks. Contexts for each\nintent are also provided as the corresponding chapters of the\ntextbook. This suite is provided as a sample for students and\nteachers to see what a good dataset for the tool looks like,\nand the model can also be used with the questions, contexts,\nand intents provided to use the tool without making an entire\ndataset from scratch.\nConclusion\nIn this paper, we created a pipeline with multiple transform-\ners to generate natural language answers to student ques-\ntions; moreover, we used this pipeline to make an open-\nsource tool to enable students to learn the supervised learn-\n16030\nFigure 14: Some of the labeled questions given as part of the earth science testing suite. These questions can be found in\nthe sampleQuestions.csv file seen in Figure 13. The sample intent file (which lists each intent a question can be labeled as)\nand context file (corresponding textbook passages for each intent) are also shown as sampleIntents.txt and sampleContexts.txt,\nrespectively.\ning process by training the models in the pipeline. The tool\nis inexpensive to use and practical for a classroom envi-\nronment, as instructors can download the tool as an exe-\ncutable file and deploy it without any programming knowl-\nedge. This enables educators of any level of technical expe-\nrience to build their students’ AI literacy with a curriculum\nbased around constructivist learning theory. Students also\nbuild system engineering and analysis skills by engaging\nwith and modifying the multi-step language pipeline. Fur-\nther work involves presenting results of the efficacy of the\nlanguage modeling used and piloting the tool in classroom\nsettings. We also hope to expand access by making our tool\nusable by all operating systems and improving documenta-\ntion.\nReferences\nBrown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.;\nDhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell,\nA.; Agarwal, S.; Herbert-V oss, A.; Krueger, G.; Henighan,\nT.; Child, R.; Ramesh, A.; Ziegler, D.; Wu, J.; Winter,\nC.; Hesse, C.; Chen, M.; Sigler, E.; Litwin, M.; Gray, S.;\nChess, B.; Clark, J.; Berner, C.; McCandlish, S.; Radford,\nA.; Sutskever, I.; and Amodei, D. 2020. Language Mod-\nels are Few-Shot Learners. In Larochelle, H.; Ranzato, M.;\nHadsell, R.; Balcan, M.; and Lin, H., eds.,Advances in Neu-\nral Information Processing Systems, volume 33, 1877–1901.\nCurran Associates, Inc.\nDevlin, J.; Chang, M.; Lee, K.; and Toutanova, K. 2018.\nBERT: Pre-training of Deep Bidirectional Transformers for\nLanguage Understanding. CoRR, abs/1810.04805.\nFeng, S. Y .; Gangal, V .; Wei, J.; Chandar, S.; V osoughi, S.;\nMitamura, T.; and Hovy, E. H. 2021. A Survey of Data Aug-\nmentation Approaches for NLP. CoRR, abs/2105.03075.\nFoster, G.; and Stagl, S. 2018. Design, implementation,\nand evaluation of an inverted (flipped) classroom model eco-\nnomics for sustainable education course. Journal of Cleaner\nProduction, 183: 1323–1336.\nFry, R.; Kennedy, B.; and Funk, C. 2021. STEM jobs see\nuneven progress in increasing gender, racial and ethnic di-\nversity. Pew Research Center.\nFu, T.; Gao, S.; Zhao, X.; rong Wen, J.; and Yan, R. 2022.\nLearning towards conversational AI: A survey. AI Open, 3:\n14–28.\nGorton, I.; Wynne, A.; Liu, Y .; and Yin, J. 2011. Compo-\nnents in the Pipeline. IEEE Software, 28(3): 34–40.\nJ. Bancifra, J. 2022. Supervisory practices of Department\nHeads and teachers’ performance: Towards A proposed En-\nhancement Program. APJAET - Journal ay Asia Pacific\nJournal of Advanced Education and Technology, 25–33.\nKim, S.; Jang, Y .; Kim, W.; Choi, S.; Jung, H.; Kim, S.; and\nKim, H. 2021. Why and What to Teach: AI Curriculum for\nElementary School. Proceedings of the AAAI Conference on\nArtificial Intelligence, 35(17): 15569–15576.\nKiperwasser, E.; and Goldberg, Y . 2016. Simple and Accu-\nrate Dependency Parsing Using Bidirectional LSTM Feature\nRepresentations. Transactions of the Association for Com-\nputational Linguistics, 4: 313–327.\nLi, R.; Lund, A.; and Nordsteien, A. 2021. The link between\nflipped and active learning: a scoping review. Teaching in\nHigher Education, 0(0): 1–35.\nMa, E. 2019. NLPAug Python Library. https://github.com/\nmakcedward/nlpaug. Accessed: 2022-10-10.\nPiaget, J. 1955. The Construction of Reality in the Child.\nRoutledge amp; Kegan Paul.\nPrince, M. 2004. Does active learning work? A review of\nthe research. J. Eng. Educ., 93(3): 223–231.\nRaffel, C.; Shazeer, N.; Roberts, A.; Lee, K.; Narang, S.;\nMatena, M.; Zhou, Y .; Li, W.; and Liu, P. J. 2022. Exploring\nthe Limits of Transfer Learning with a Unified Text-to-Text\nTransformer. J. Mach. Learn. Res., 21(1).\nRajpurkar, P.; Zhang, J.; Lopyrev, K.; and Liang, P. 2016.\nSQuAD: 100, 000+ Questions for Machine Comprehension\nof Text. CoRR, abs/1606.05250.\nSabuncuoglu, A. 2020. Designing One Year Curriculum to\nTeach Artificial Intelligence for Middle School. In Pro-\nceedings of the 2020 ACM Conference on Innovation and\nTechnology in Computer Science Education, ITiCSE ’20,\n96–102. New York, NY , USA: Association for Computing\nMachinery. ISBN 9781450368742.\nSanh, V .; Debut, L.; Chaumond, J.; and Wolf, T. 2019. Dis-\ntilBERT, a distilled version of BERT: smaller, faster, cheaper\nand lighter. CoRR, abs/1910.01108.\nSennrich, R.; Haddow, B.; and Birch, A. 2016. Improv-\ning Neural Machine Translation Models with Monolingual\nData. In Proceedings of the 54th Annual Meeting of the\n16031\nAssociation for Computational Linguistics (Volume 1: Long\nPapers), 86–96. Berlin, Germany: Association for Compu-\ntational Linguistics.\nSlavich, G. M.; and Zimbardo, P. G. 2012. Transformational\nteaching: Theoretical underpinnings, basic principles, and\ncore methods. Educ. Psychol. Rev., 24(4): 569–608.\nTao, C.; Feng, J.; Yan, R.; Wu, W.; and Jiang, D. 2021.\nA Survey on Response Selection for Retrieval-based Di-\nalogues. In Zhou, Z.-H., ed., Proceedings of the Thirti-\neth International Joint Conference on Artificial Intelligence,\nIJCAI-21, 4619–4626. International Joint Conferences on\nArtificial Intelligence Organization. Survey Track.\nTouretzky, D.; Gardner-McCune, C.; Breazeal, C.; Martin,\nF.; and Seehorn, D. 2019a. A Year in K-12 AI Education.AI\nMagazine, 40(4): 88–90.\nTouretzky, D. S.; Gardner-Mccune, C.; Martin, F. G.; and\nSeehorn, D. W. 2019b. Envisioning AI for K-12: What\nShould Every Child Know about AI? In AAAI Conference\non Artificial Intelligence.\nUtah State Board of Education OER. 2022. 5th Grade for\nUtah SEEd Standards. CK-12 Foundation.\nVaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones,\nL.; Gomez, A. N.; Kaiser, L.; and Polosukhin, I. 2017. At-\ntention Is All You Need. CoRR, abs/1706.03762.\nWang, A.; Singh, A.; Michael, J.; Hill, F.; Levy, O.; and\nBowman, S. 2018. GLUE: A Multi-Task Benchmark and\nAnalysis Platform for Natural Language Understanding. In\nProceedings of the 2018 EMNLP Workshop BlackboxNLP:\nAnalyzing and Interpreting Neural Networks for NLP, 353–\n355. Brussels, Belgium: Association for Computational Lin-\nguistics.\nWilliams, R.; Ali, S.; Devasia, N.; DiPaola, D.; Hong, J.;\nKaputsos, S. P.; Jordan, B.; and Breazeal, C. 2022. AI +\nethics curricula for middle school youth: Lessons learned\nfrom three project-based curricula. Int. J. Artif. Intell. Educ.,\n1–59.\nWollowski, M.; Selkowitz, R.; Brown, L.; Goel, A.; Luger,\nG.; Marshall, J.; Neel, A.; Neller, T.; and Norvig, P. 2016.\nProceedings of the AAAI Conference on Artificial Intelli-\ngence, 30(1).\n16032",
  "topic": "Chatbot",
  "concepts": [
    {
      "name": "Chatbot",
      "score": 0.7895802855491638
    },
    {
      "name": "Computer science",
      "score": 0.66090327501297
    },
    {
      "name": "Question answering",
      "score": 0.5545793175697327
    },
    {
      "name": "Personalization",
      "score": 0.533865749835968
    },
    {
      "name": "Terminology",
      "score": 0.4790705144405365
    },
    {
      "name": "Artificial intelligence",
      "score": 0.42407095432281494
    },
    {
      "name": "Curriculum",
      "score": 0.4237586557865143
    },
    {
      "name": "World Wide Web",
      "score": 0.41567230224609375
    },
    {
      "name": "Multimedia",
      "score": 0.32580748200416565
    },
    {
      "name": "Pedagogy",
      "score": 0.15185895562171936
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Linguistics",
      "score": 0.0
    },
    {
      "name": "Psychology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I63966007",
      "name": "Massachusetts Institute of Technology",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210142372",
      "name": "Human Media",
      "country": "US"
    }
  ],
  "cited_by": 20
}