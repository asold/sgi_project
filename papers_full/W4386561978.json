{
  "title": "A novel hybrid framework based on temporal convolution network and transformer for network traffic prediction",
  "url": "https://openalex.org/W4386561978",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2111466427",
      "name": "Zhiwei Zhang",
      "affiliations": [
        "China University of Geosciences (Beijing)"
      ]
    },
    {
      "id": "https://openalex.org/A2324416354",
      "name": "Shu-hui Gong",
      "affiliations": [
        "China University of Geosciences (Beijing)"
      ]
    },
    {
      "id": "https://openalex.org/A2102348877",
      "name": "Zhaoyu Liu",
      "affiliations": [
        "China University of Geosciences (Beijing)"
      ]
    },
    {
      "id": "https://openalex.org/A2096642888",
      "name": "Da Chen",
      "affiliations": [
        "China University of Geosciences (Beijing)"
      ]
    },
    {
      "id": "https://openalex.org/A2111466427",
      "name": "Zhiwei Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2324416354",
      "name": "Shu-hui Gong",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2102348877",
      "name": "Zhaoyu Liu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2096642888",
      "name": "Da Chen",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2321564642",
    "https://openalex.org/W1482956286",
    "https://openalex.org/W3194762314",
    "https://openalex.org/W2900749811",
    "https://openalex.org/W3089354057",
    "https://openalex.org/W3005623292",
    "https://openalex.org/W4224242856",
    "https://openalex.org/W2118023920",
    "https://openalex.org/W3189556250",
    "https://openalex.org/W4292262737",
    "https://openalex.org/W2909976513",
    "https://openalex.org/W4297423466",
    "https://openalex.org/W4313004671",
    "https://openalex.org/W6679436768",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W3160936371",
    "https://openalex.org/W2884585870",
    "https://openalex.org/W2954731415",
    "https://openalex.org/W2017807084",
    "https://openalex.org/W2962949934",
    "https://openalex.org/W2194775991",
    "https://openalex.org/W2078099808",
    "https://openalex.org/W3097294131",
    "https://openalex.org/W3131500599",
    "https://openalex.org/W3038091703",
    "https://openalex.org/W2190432600",
    "https://openalex.org/W2130942839",
    "https://openalex.org/W4256305391",
    "https://openalex.org/W3112139896",
    "https://openalex.org/W4313855753"
  ],
  "abstract": "Background Accurately predicting mobile network traffic can help mobile network operators allocate resources more rationally and can facilitate stable and fast network services to users. However, due to burstiness and uncertainty, it is difficult to accurately predict network traffic. Methodology Considering the spatio-temporal correlation of network traffic, we proposed a deep-learning model, Convolutional Block Attention Module (CBAM) Spatio-Temporal Convolution Network-Transformer, for time-series prediction based on a CBAM attention mechanism, a Temporal Convolutional Network (TCN), and Transformer with a sparse self-attention mechanism. The model can be used to extract the spatio-temporal features of network traffic for prediction. First, we used the improved TCN for spatial information and added the CBAM attention mechanism, which we named CSTCN. This model dealt with important temporal and spatial features in network traffic. Second, Transformer was used to extract spatio-temporal features based on the sparse self-attention mechanism. The experiments in comparison with the baseline showed that the above work helped significantly to improve the prediction accuracy. We conducted experiments on a real network traffic dataset in the city of Milan. Results The results showed that CSTCN-Transformer reduced the mean square error and the mean average error of prediction results by 65.16%, 64.97%, and 60.26%, and by 51.36%, 53.10%, and 38.24%, respectively, compared to CSTCN, a Long Short-Term Memory network, and Transformer on test sets, which justified the model design in this paper.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7167954444885254
    },
    {
      "name": "Transformer",
      "score": 0.5114415884017944
    },
    {
      "name": "Artificial intelligence",
      "score": 0.47346583008766174
    },
    {
      "name": "Data mining",
      "score": 0.4324910044670105
    },
    {
      "name": "Mean squared error",
      "score": 0.42686909437179565
    },
    {
      "name": "Real-time computing",
      "score": 0.3320404589176178
    },
    {
      "name": "Statistics",
      "score": 0.1359233558177948
    },
    {
      "name": "Engineering",
      "score": 0.11493039131164551
    },
    {
      "name": "Mathematics",
      "score": 0.11038646101951599
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I3125743391",
      "name": "China University of Geosciences (Beijing)",
      "country": "CN"
    }
  ],
  "cited_by": 14
}