{
  "title": "Introduction to Foundation Models",
  "url": "https://openalex.org/W4411249471",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2892897794",
      "name": "Pin-Yu Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2114576281",
      "name": "Sijia Liu",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4411249889",
    "https://openalex.org/W4411250119",
    "https://openalex.org/W4411249849",
    "https://openalex.org/W4411249315",
    "https://openalex.org/W4411249851"
  ],
  "abstract": null,
  "full_text": "Introduction to Foundation Models\nPin-Yu Chen • Sijia Liu \nIntroduction to Foundation \nModels\nPin-Yu Chen \nIBM Research \nYorktown Heights, NY , USA \nSijia Liu \nCollege of Engineering \nMichigan State University \nSunnyvale, CA, USA \nISBN 978-3-031-76769-2 ISBN 978-3-031-76770-8 (eBook) \nhttps://doi.org/10.1007/978-3-031-76770-8 \n© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland \nAG 2025 \nThis work is subject to copyright. All rights are solely and exclusively licensed by the Publisher, whether \nthe whole or part of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse \nof illustrations, recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and \ntransmission or information storage and retrieval, electronic adaptation, computer software, or by similar \nor dissimilar methodology now known or hereafter developed. \nThe use of general descriptive names, registered names, trademarks, service marks, etc. in this publication \ndoes not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant \nprotective laws and regulations and therefore free for general use. \nThe publisher, the authors and the editors are safe to assume that the advice and information in this book \nare believed to be true and accurate at the date of publication. Neither the publisher nor the authors or \nthe editors give a warranty, expressed or implied, with respect to the material contained herein or for any \nerrors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional \nclaims in published maps and institutional afﬁliations. \nThis Springer imprint is published by the registered company Springer Nature Switzerland AG \nThe registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland \nIf disposing of this product, please recycle the paper.\nTo a better future and technology where AGI \nmeans Artiﬁcial Good Intelligence\nPreface \nBack in June 2022, we (Pin-Yu Chen, Sijia Liu, and Sayak Paul) sensed that \nfoundational models and generative AI were about to bring unprecedented and \nrevolutionary changes to our technology and society, and we decided to propose \na tutorial at NeurIPS to educate researchers and practitioners about this emerging \nAI research and technology and its implications for robustness and safety. Two \nmonths later, our tutorial, “ Foundational Robustness of Foundation Models ,” was \naccepted and to be presented on December 5, 2022. At that time, the world was \nstill recovering from the Covid crisis, and NeurIPS 2022 was the ﬁrst NeurIPS \nconference to allow physical attendance after Covid. To accommodate the hybrid \nconference mode, we were asked to record our tutorial by October 2022. In our \nmaterials, we correctly predicted that the proliferation of foundation models would \nbring increased risks and challenges in robustness, security, and safety, later known \nas part of the broad topic of AI safety, governance, and risk assessment. \nAbout a week before the ofﬁcial release of our tutorial and the start date of \nNeurIPS 2022, ChatGPT was launched by OpenAI on November 30, 2022. At the \nconference, we heard only a few whispers and genuine inquiries about “Have you \nheard of ChatGPT?” Who would have thought that in August 2024, the number of \nChatGPT users worldwide would be more than 180 million? \nWith such a coincidence in mind, we felt compelled to expand our tutorial \ninto a book, summarizing the basics of foundation models and generative AI, and \nemphasizing the robustness and safety of these frontier models and AI technology. \nThis book consists of three parts. Part I (Chaps. 1 to 4) provides the fundamentals \nof foundation models, Part II (Chaps. 5 to 11) includes advanced topics in founda-\ntion modes, and Part III (Chaps. 12 to 18) presents safety and trust in foundation \nmodels. The mathematical notations will be deﬁned and explained in each chapter. \nWe provide an overview of each part as follows:\n In Part I, Chap. 1 provides an overview of foundation models and generative AI. \nChapter 2 presents the technical background of neural networks. Chapter 3 delves \ninto the learning and generalization of transformers. Chapter 4 formalizes in-\ncontext learning with transformers.\nvii\nviii Preface\n In Part II, Chap. 5 introduces automated visual prompting techniques. Chapter 6 \nintroduces prompting LLMs with privacy. Chapter 7 elucidates memory-efﬁcient \nﬁne-tuning \nmethods. Chapter 8 shows how LLMs can be reprogrammed for \ntime-series \nmachine learning tasks. Chapter 9 shows how LLMs can be reused \nfor \nspeech tasks. Chapter 10 introduces how synthetic datasets can be used to \nbenchmark \nfoundation models. Chapter 11 elucidates machine unlearning for \nfoundation \nmodels.\n In Part III, Chap. 12 provides a comprehensive evaluation of the trustworthiness \nof \nLLMs. Chapter 13 introduces jailbreak attacks and defenses for LLMs. \nChapter 14 presents safety risks when ﬁne-tuning LLMs. Chapter 15 introduces \nw\natermarking techniques for LLMs. Chapter 16 presents robust detection of \nAI-generated \ntext. Chapter 17 elucidates backdoor risks in diffusion models. \nChapter 18 presents red-teaming methods for diffusion models. \nThe authors would especially like to thank Paul Drougas at Springer for his \nencouragement and patience in allowing us to publish a book in such a rapidly \nchanging and growing ﬁeld. Some parts of the book are based on publications co-\nauthored by the authors of this book. We would like to express our gratitude to our \nresearch collaborators. Finally, we would like to thank our families, colleagues, and \nfriends, for their support. \nYorktown Heights, NY , USA Pin-Yu Chen \nSunnyvale, CA, USA Sijia Liu \nSeptember 2024 \nContents \nPart I Fundamentals of Foundation Models \n1 Foundation Models and Generative AI .................................. 3 \n1.1 What Are Foundation Models and Generative AI? ................. 3 \n1.2 Foundations Models at Scale ........................................ 5 \n1.2.1 Neural Scaling Laws ....................................... 5 \n1.2.2 Emerging Abilities .......................................... 6 \n1.3 Lifecycle of Foundation Models ..................................... 7 \n1.3.1 Data Preparation ............................................ 8 \n1.3.2 Model Training ............................................. 8 \n1.3.3 Model Deployment ......................................... 9 \n1.4 Canonical Examples of Foundation Models ........................ 10 \n1.5 Our Perspective on Foundation Models ............................. 11 \n2 Neural Networks ............................................................ 13 \n2.1 Introduction ........................................................... 13 \n2.2 Basic Neural Network Modules ..................................... 14 \n2.3 Transformers .......................................................... 16 \n2.3.1 Token Embedding and Position Encoding ................. 16 \n2.3.2 Attention .................................................... 17 \n2.3.3 Transformer Types .......................................... 19 \n2.4 Large Language Models ............................................. 20 \n2.4.1 Next-Token Prediction ..................................... 20 \n2.4.2 Decoding Strategies ........................................ 21 \n2.4.3 Alignment Strategies ....................................... 22 \n2.4.4 Parameter-Efﬁcient Fine-Tuning ........................... 23 \n3 Learning and Generalization of Vision Transformers .................. 25 \n3.1 Introduction ........................................................... 25 \n3.2 Background and Related Work ...................................... 26 \n3.2.1 Problem Formulation and Learning Algorithm ........... 27 \n3.3 Theoretical Characterization of Transformers ...................... 29\nix\nx Contents\n3.3.1 Main Theoretical Insights .................................. 29 \n3.3.2 Data Model .................................................. 30 \n3.3.3 Formal Theoretical Results ................................. 31 \n3.4 Performance Evaluation .............................................. 33 \n4 Formalizing In-Context Learning in Transformers ..................... 37 \n4.1 Introduction ........................................................... 37 \n4.2 Background and Related Work ...................................... 39 \n4.2.1 Formalizing In-Context Learning with Transformers ..... 40 \n4.3 Theoretical Characterization of In-Context Learning .............. 43 \n4.3.1 Main Theoretical Insights .................................. 43 \n4.3.2 The Modeling of Training Data and Tasks ................ 43 \n4.3.3 In-Domain and Out-of-Domain Generalization \nwith \nSample Complexity Analysis......................... 45 \n4.3.4 ICL With Magnitude-Based Model Pruning .............. 47 \n4.3.5 The Mechanism of ICL by the Trained Transformer ..... 48 \n4.4 Performance Evaluation .............................................. 50 \nPart II Advanced Topics in Foundation Models \n5 Automated Visual Prompting ............................................. 55 \n5.1 Introduction ........................................................... 55 \n5.2 Background and Related Work ...................................... 57 \n5.3 AutoVP Framework .................................................. 59 \n5.3.1 Input Scaling ................................................ 60 \n5.3.2 Visual Prompt ............................................... 60 \n5.3.3 Pre-trained Classiﬁer ....................................... 61 \n5.3.4 Output Label Mapping ..................................... 61 \n5.3.5 End-to-End Hyper-Parameter Tuning ..................... 63 \n5.4 Performance Evaluation .............................................. 64 \n6 Prompting Large Language Models with Privacy ...................... 67 \n6.1 Introduction ........................................................... 67 \n6.2 Background and Related Work ...................................... 68 \n6.2.1 Diffential Privacy (DP) ..................................... 68 \n6.2.2 Document Processing with Privacy ........................ 70 \n6.3 DP-Prompt ............................................................ 71 \n6.4 Performance Evaluation .............................................. 73 \n7 Memory-Efﬁcient Fine-Tuning for Foundation Models ................ 77 \n7.1 Introduction ........................................................... 77 \n7.2 Algorithmic Foundations of ZO Optimization ...................... 78 \n7.3 Applying ZO Optimization for Memory-Efﬁcient Fine-Tuning ... 81 \n8 Large Language Models Meet Time Series .............................. 87 \n8.1 Introduction ........................................................... 87 \n8.2 Background and Related Work ...................................... 89\nContents xi\n8.3 Time-LLM ............................................................ 90 \n8.3.1 Model Structure ............................................. 91 \n8.4 Performance Evaluation .............................................. 94 \n9 Large Language Models Meet Speech Recognition ..................... 99 \n9.1 Introduction ........................................................... 99 \n9.2 Background and Related Work ...................................... 101 \n9.2.1 ASR Rescoring and Error Correction ...................... 101 \n9.2.2 Noise-Robust ASR ......................................... 102 \n9.2.3 HyPoradise (HP) Benchmarks ............................. 102 \n9.3 Noise-Aware Generative Error Correction .......................... 103 \n9.3.1 Language-Space Noise Embedding ........................ 104 \n9.3.2 Audio Noise Distillation ................................... 105 \n9.4 Performance Evaluation .............................................. 106 \n10 Benchmarking Foundation Models Using Synthetic Datasets ......... 109 \n10.1 Introduction ........................................................... 109 \n10.2 Background and Related Work ...................................... 112 \n10.3 SynBench ............................................................. 113 \n10.3.1 Synthetic Data .............................................. 113 \n10.3.2 Main Theorem .............................................. 114 \n10.3.3 Objective .................................................... 116 \n10.3.4 Robustness-Accuracy Quantiﬁcation ...................... 117 \n10.4 Performance Evaluation .............................................. 118 \n11 Machine Unlearning for Foundation Models ............................ 123 \n11.1 Introduction ........................................................... 123 \n11.2 Research Objective, Formulation, and Related Work .............. 124 \n11.3 Sparse Optimization for MU: Leveraging Model Sparsity \nfor \nEfﬁcient and Effective Unlearning .............................. 129 \n11.4 Second-Order Optimization for MU: Iterative \nInﬂuence-Guided \nUnlearning ........................................ 134 \n11.5 Adversarial Evaluation of MU ....................................... 137 \nPart III Trust and Safety in Foundation Models \n12 Trustworthiness Evaluation of Large Language Models ............... 149 \n12.1 Introduction ........................................................... 149 \n12.2 Background and Related Work ...................................... 152 \n12.2.1 Large Language Models (LLMs) .......................... 152 \n12.2.2 Evaluation on LLMs ........................................ 154 \n12.2.3 Trustworthiness-Related Benchmarks ..................... 155 \n12.3 Guidelines and Principles for Trustworthiness \nAssessment \nof LLMs................................................. 155 \n12.3.1 Truthfulness ................................................. 156 \n12.3.2 Safety ........................................................ 157 \n12.3.3 Fairness ..................................................... 158\nxii Contents\n12.3.4 Robustnesss ................................................. 158 \n12.3.5 Privacy ...................................................... 159 \n12.3.6 Machine Ethics ............................................. 160 \n12.3.7 Transparency ................................................ 160 \n12.3.8 Accountability .............................................. 161 \n12.4 Main Insights from TrustLLM Evaluation .......................... 162 \n12.4.1 Overall Observations ....................................... 162 \n12.4.2 Novel Insights into Individual Dimensions of \nT\nrustworthiness ............................................. 164 \n13 Attacks and Defenses on Aligned Large Language Models ............ 167 \n13.1 Introduction ........................................................... 167 \n13.2 Background and Related Work ...................................... 169 \n13.3 Gradient Cuff ......................................................... 170 \n13.3.1 Refusal Loss Function and Landscape Exploration ....... 170 \n13.3.2 Gradient Norm Estimation ................................. 172 \n13.3.3 Gradient Cuff: Two-Step Jailbreak Detection ............. 173 \n13.3.4 Performance Evaluation .................................... 174 \n13.4 Defensive Prompt Patch .............................................. 176 \n13.4.1 Preliminaries ................................................ 176 \n13.4.2 Score Evaluation ............................................ 177 \n13.4.3 DPP Training Algorithm ................................... 178 \n13.4.4 Performance Evaluation .................................... 182 \n14 Safety Risks in Fine-Tuning Large Language Models .................. 185 \n14.1 Introduction ........................................................... 185 \n14.2 Background and Related Work ...................................... 187 \n14.3 Performance Evaluation .............................................. 189 \n14.3.1 Experiment Setup ........................................... 189 \n14.3.2 Numerical Results .......................................... 190 \n15 Watermarks for Large Language Models ............................... 195 \n15.1 Introduction ........................................................... 195 \n15.2 Background and Related Work ...................................... 196 \n15.3 Duwak: Dual Watermarking for LLMs .............................. 198 \n15.3.1 Token Probability Watermark .............................. 199 \n15.3.2 Contrastive Search Watermark ............................. 199 \n15.3.3 Watermark Detection in Duwak ............................ 200 \n15.4 Performance Evaluation .............................................. 202 \n15.4.1 Experiment Setup ........................................... 202 \n15.4.2 Numerical Results .......................................... 203 \n16 AI-Generated Text Detection .............................................. 209 \n16.1 Introduction ........................................................... 209 \n16.2 Background and Related Work ...................................... 210 \n16.3 RADAR: Robust AI-Text Detection Using Adversarial \nLearning .............................................................. 212\nContents xiii\n16.3.1 Training Paraphraser via Clipped PPO with \nEntropy Penalty ............................................. 213 \n16.3.2 Training Detector via Reweighted Logistic Loss ......... 214 \n16.3.3 RADAR Algorithm ......................................... 215 \n16.4 Performance Evaluation .............................................. 215 \n16.4.1 Experimen Setup ............................................ 215 \n16.4.2 Performance Evaluation and Comparison with \nExisting \nMethods ........................................... 218 \n16.4.3 AI-Text Detection Transferability of RADAR ............ 219 \n17 Backdoor Risks in Diffusion Models ..................................... 221 \n17.1 Introduction ........................................................... 221 \n17.2 Background and Related Work ...................................... 223 \n17.3 VillanDiffusion: A Uniﬁed Backdoor Attack Framework .......... 224 \n17.3.1 Backdoor Unconditional Diffusion Models as a \nDistrib\nution Mapping Problem............................. 224 \n17.3.2 Generalization to Various Schedulers ...................... 225 \n17.3.3 Generalization to ODE and SDE Samplers ................ 227 \n17.3.4 Uniﬁed Loss Function for Unconditional \nGeneration \nwith Image Triggers ........................... 228 \n17.3.5 Generalization to Conditional Generation ................. 229 \n17.4 Backdoor Detection and Mitigation for Diffusion Models ......... 230 \n17.5 Performance Evaluation .............................................. 231 \n17.5.1 Experiment Setup ........................................... 231 \n17.5.2 Caption-Trigger Backdoor Attacks on \nT\next-to-Image DMs......................................... 232 \n17.5.3 Image-Trigger Backdoor Attacks on \nUnconditional \nDMs......................................... 234 \n18 Prompt Engineering for Safety Red-Teaming: A Case Study \non \nText-to-Image Diffusion Models ....................................... 237 \n18.1 Introduction ........................................................... 237 \n18.2 Background and Related Work ...................................... 238 \n18.3 Prompting4Debugging (P4D) ........................................ 241 \n18.4 Ring-A-Bell .......................................................... 243 \n18.5 Performance Evaluation .............................................. 245 \n18.5.1 P4D Results ................................................. 246 \n18.5.2 Ring-A-Bell Results ........................................ 249 \nReferences......................................................................... 255 \nIndex ............................................................................... 309",
  "topic": "Foundation (evidence)",
  "concepts": [
    {
      "name": "Foundation (evidence)",
      "score": 0.8203243017196655
    },
    {
      "name": "Computer science",
      "score": 0.3857910633087158
    },
    {
      "name": "History",
      "score": 0.1644819974899292
    },
    {
      "name": "Archaeology",
      "score": 0.07263609766960144
    }
  ]
}