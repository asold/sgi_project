{
    "title": "A Transformer-Based Approach Combining Deep Learning Network and Spatial-Temporal Information for Raw EEG Classification",
    "url": "https://openalex.org/W4289538860",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2100862001",
            "name": "Jin Xie",
            "affiliations": [
                "Shenzhen Institutes of Advanced Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2082197670",
            "name": "Jie Zhang",
            "affiliations": [
                "Shenzhen Institutes of Advanced Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2138571865",
            "name": "Jiayao Sun",
            "affiliations": [
                "Shenzhen Institutes of Advanced Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2096559838",
            "name": "Zheng Ma",
            "affiliations": [
                "Shenzhen Institutes of Advanced Technology"
            ]
        },
        {
            "id": "https://openalex.org/A3136371348",
            "name": "Liuni Qin",
            "affiliations": [
                "Shenzhen Institutes of Advanced Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2096143289",
            "name": "Guanglin Li",
            "affiliations": [
                "Shenzhen Institutes of Advanced Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2107288650",
            "name": "Huihui Zhou",
            "affiliations": [
                "Shenzhen Institutes of Advanced Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2039016067",
            "name": "Yang Zhan",
            "affiliations": [
                "Shenzhen Institutes of Advanced Technology"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4205558134",
        "https://openalex.org/W2950784811",
        "https://openalex.org/W3170476868",
        "https://openalex.org/W2982056272",
        "https://openalex.org/W6763868836",
        "https://openalex.org/W6784333009",
        "https://openalex.org/W6743889581",
        "https://openalex.org/W3006715241",
        "https://openalex.org/W2312147435",
        "https://openalex.org/W2944559085",
        "https://openalex.org/W3083693766",
        "https://openalex.org/W3167319107",
        "https://openalex.org/W3000231660",
        "https://openalex.org/W2010371409",
        "https://openalex.org/W3085334857",
        "https://openalex.org/W6755207826",
        "https://openalex.org/W6778485988",
        "https://openalex.org/W2915893085",
        "https://openalex.org/W2128909182",
        "https://openalex.org/W2972694220",
        "https://openalex.org/W2954214015",
        "https://openalex.org/W3012410088",
        "https://openalex.org/W6797185979",
        "https://openalex.org/W3015898934",
        "https://openalex.org/W2965485674",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W6794838607",
        "https://openalex.org/W3004893606",
        "https://openalex.org/W2181552298",
        "https://openalex.org/W2782702411",
        "https://openalex.org/W2611482981",
        "https://openalex.org/W2883269930",
        "https://openalex.org/W6779488579",
        "https://openalex.org/W2906152891",
        "https://openalex.org/W2502597670",
        "https://openalex.org/W1997433666",
        "https://openalex.org/W2081559086",
        "https://openalex.org/W4206239953",
        "https://openalex.org/W2534599926",
        "https://openalex.org/W3041051645",
        "https://openalex.org/W2574833558",
        "https://openalex.org/W2896120927",
        "https://openalex.org/W2893192409",
        "https://openalex.org/W2557301950",
        "https://openalex.org/W2894424125",
        "https://openalex.org/W2772472921",
        "https://openalex.org/W2585506822",
        "https://openalex.org/W2790471600",
        "https://openalex.org/W2999200800",
        "https://openalex.org/W2888355470",
        "https://openalex.org/W2055603681",
        "https://openalex.org/W2994900993",
        "https://openalex.org/W3169774297",
        "https://openalex.org/W2802663007",
        "https://openalex.org/W3201991715",
        "https://openalex.org/W3177342940",
        "https://openalex.org/W2767460367",
        "https://openalex.org/W2162800060",
        "https://openalex.org/W4220904310",
        "https://openalex.org/W4229068725",
        "https://openalex.org/W4205466227",
        "https://openalex.org/W3009259306",
        "https://openalex.org/W3094502228",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W3096609285",
        "https://openalex.org/W3173912422",
        "https://openalex.org/W2951433247",
        "https://openalex.org/W3160553073",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W2753247993",
        "https://openalex.org/W3034528964"
    ],
    "abstract": "The attention mechanism of the Transformer has the advantage of extracting feature correlation in the long-sequence data and visualizing the model. As time-series data, the spatial and temporal dependencies of the EEG signals between the time points and the different channels contain important information for accurate classification. So far, Transformer-based approaches have not been widely explored in motor-imagery EEG classification and visualization, especially lacking general models based on cross-individual validation. Taking advantage of the Transformer model and the spatial-temporal characteristics of the EEG signals, we designed Transformer-based models for classifications of motor imagery EEG based on the PhysioNet dataset. With 3s EEG data, our models obtained the best classification accuracy of 83.31%, 74.44%, and 64.22% on two-, three-, and four-class motor-imagery tasks in cross-individual validation, which outperformed other state-of-the-art models by 0.88%, 2.11%, and 1.06%. The inclusion of the positional embedding modules in the Transformer could improve the EEG classification performance. Furthermore, the visualization results of attention weights provided insights into the working mechanism of the Transformer-based networks during motor imagery tasks. The topography of the attention weights revealed a pattern of event-related desynchronization (ERD) which was consistent with the results from the spectral analysis of Mu and beta rhythm over the sensorimotor areas. Together, our deep learning methods not only provide novel and powerful tools for classifying and understanding EEG data but also have broad applications for brain-computer interface (BCI) systems.",
    "full_text": null
}