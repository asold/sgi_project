{
  "title": "Evaluating Prompt Injection Safety in Large Language Models Using the PromptBench Dataset",
  "url": "https://openalex.org/W4398196388",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5098751119",
      "name": "Xiatong Sang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2107930201",
      "name": "Min Gu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2980945330",
      "name": "Hao-Jun Chi",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4386420753",
    "https://openalex.org/W4392781192",
    "https://openalex.org/W4389768226",
    "https://openalex.org/W2277863734",
    "https://openalex.org/W4391912673",
    "https://openalex.org/W4393319504",
    "https://openalex.org/W4383605161",
    "https://openalex.org/W4388886073",
    "https://openalex.org/W4392366668",
    "https://openalex.org/W4392891144",
    "https://openalex.org/W4394581225",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W4392449489",
    "https://openalex.org/W4382491840",
    "https://openalex.org/W4402263677",
    "https://openalex.org/W4392502007",
    "https://openalex.org/W4392908117"
  ],
  "abstract": "The safety evaluation of large language models against adversarial prompt injections introduces a novel and significant concept that addresses the critical need for robust AI systems. The research presented offers a comprehensive analysis of Anthropic Claude and Mistral Large, utilizing the Microsoft PromptBench dataset to assess their resilience to adversarial manipulations. Anthropic Claude demonstrated superior performance across multiple metrics, including response accuracy, context preservation, and semantic consistency, highlighting the effectiveness of advanced safety mechanisms. Conversely, Mistral Large exhibited areas for improvement, particularly in handling context and semantic manipulations. The findings show the importance of integrating sophisticated safety protocols in AI development, providing valuable insights for creating secure and reliable AI systems. By systematically comparing the models' robustness to various adversarial scenarios, the study contributes to the broader understanding of AI safety and paves the way for future advancements in the field.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.4914737939834595
    },
    {
      "name": "Natural language processing",
      "score": 0.3635736405849457
    }
  ]
}