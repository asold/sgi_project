{
    "title": "Large Language Models and Low-Resource Languages: An Examination of Armenian NLP",
    "url": "https://openalex.org/W4392637283",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A4320605275",
            "name": "Hayastan Avetisyan",
            "affiliations": [
                "German Centre for Higher Education Research and Science Studies"
            ]
        },
        {
            "id": "https://openalex.org/A2134819571",
            "name": "David Broneske",
            "affiliations": [
                "German Centre for Higher Education Research and Science Studies"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2897565768",
        "https://openalex.org/W3120219703",
        "https://openalex.org/W1512634710",
        "https://openalex.org/W2515218431",
        "https://openalex.org/W4313067245",
        "https://openalex.org/W585078330",
        "https://openalex.org/W3102425047",
        "https://openalex.org/W2805659884",
        "https://openalex.org/W4313346705",
        "https://openalex.org/W2963461172",
        "https://openalex.org/W2251651951",
        "https://openalex.org/W2398648391",
        "https://openalex.org/W4256657488",
        "https://openalex.org/W3196966746",
        "https://openalex.org/W4288334727",
        "https://openalex.org/W3032808228",
        "https://openalex.org/W4310362699",
        "https://openalex.org/W3210189645",
        "https://openalex.org/W2564362733",
        "https://openalex.org/W2970849641",
        "https://openalex.org/W3132357981",
        "https://openalex.org/W4380480948",
        "https://openalex.org/W4312608305",
        "https://openalex.org/W3207602763",
        "https://openalex.org/W4362707350",
        "https://openalex.org/W4285242026",
        "https://openalex.org/W2792932389",
        "https://openalex.org/W3088721552",
        "https://openalex.org/W4312386909"
    ],
    "abstract": "This paper presents a comprehensive review of Natural Language Processing (NLP) research on Armenian, a language that, despite its rich history and unique linguistic characteristics, is currently low-resource in the field of NLP.We critically synthesize and evaluate various studies in Armenian NLP, highlighting key advancements, challenges, and areas for improvement.A notable aspect of our work is the underlined lack of application of Large Language Models (LLMs) in Armenian NLP, signifying an area of potential exploration and development.Identifying and discussing these challenges and opportunities lays the groundwork for future research directions in Armenian NLP.The emphasis on Armenian also advocates for increased attention to low-resource languages in NLP research, stressing the importance of linguistic diversity and equity.To the best of our knowledge, this is the first paper providing such an extensive review of Armenian NLP, marking a significant contribution to the field.",
    "full_text": "Findings of the Association for Computational Linguistics: IJCNLP-AACL 2023, pages 199–210\nNovember 1–4, 2023. ©2023 Asian Federation of Natural Language Processing\n199\nLarge Language Models and Low-Resource Languages: An Examination of\nArmenian NLP\nHayastan Avetisyan and David Broneske\nThe German Centre for Higher Education Research and Science Studies (DZHW), Germany\navetisyan@dzhw.eu\nbroneske@dzhw.eu\nAbstract\nThis paper presents a comprehensive review of\nNatural Language Processing (NLP) research\non Armenian, a language that, despite its rich\nhistory and unique linguistic characteristics, is\ncurrently low-resource in the field of NLP. We\ncritically synthesize and evaluate various stud-\nies in Armenian NLP, highlighting key advance-\nments, challenges, and areas for improvement.\nA notable aspect of our work is the underlined\nlack of application of Large Language Mod-\nels (LLMs) in Armenian NLP, signifying an\narea of potential exploration and development.\nIdentifying and discussing these challenges and\nopportunities lays the groundwork for future re-\nsearch directions in Armenian NLP. The empha-\nsis on Armenian also advocates for increased\nattention to low-resource languages in NLP re-\nsearch, stressing the importance of linguistic\ndiversity and equity. To the best of our knowl-\nedge, this is the first paper providing such an\nextensive review of Armenian NLP, marking a\nsignificant contribution to the field.\n1 Introduction\nThe evolution of Natural Language Processing\n(NLP) technologies has revolutionized our interac-\ntions with digital systems, paving the way for more\nhuman-like dialogues with artificial intelligence.\nDespite these advancements, a significant number\nof the world’s languages are still considered low-\nresource in terms of NLP tools and technologies.\nOne such language is Armenian, an Indo-European\nlanguage with unique complexities and limited digi-\ntal resources. To address these issues and shed light\non the Armenian language in the context of NLP,\nwe present a comprehensive study that contributes\nto the field in several ways:\n1. Comprehensive Overview of Armenian\nNLP: We provide a thorough review of the\ncurrent state of Armenian Natural Language\nProcessing (NLP), identifying key research,\nsignificant advancements, and areas of im-\nprovement within the field. We synthesize\nand critically evaluate the findings from var-\nious studies, providing valuable insights for\nresearchers and practitioners alike.\n2. Identifying Challenges and Opportunities:\nOur paper highlights the challenges of devel-\noping NLP technologies for Armenian, a low-\nresource language. It elucidates the issues\nrelated to the lack of linguistic resources and\ntools, gaps in machine learning methodolo-\ngies, and the specific challenges associated\nwith Armenian. This knowledge is essential\nfor future research and resource allocation.\n3. Emphasis on Large Language Models\n(LLMs): Our paper underscores the under-\nutilization of LLMs in Armenian NLP. It ex-\namines the potential benefits and challenges\nof deploying these models in low-resource set-\ntings and suggests avenues for future research.\n4. Future Directions: We present an informed\nand thorough projection of potential future\nwork in Armenian NLP, covering various as-\npects such as the development of linguistic\nresources, the application of machine learning\ntechniques, and the need for multilingual and\ncross-lingual models. This helps set a clear\nroadmap for other researchers in the field.\n5. Encouragement of NLP Research for Low-\nResource Languages and Promotion of Lan-\nguage Diversity: By focusing on Armenian,\na low-resource language, our paper advocates\nfor more attention to be given to similar lan-\nguages in NLP research. It stresses the impor-\ntance of these languages in ensuring linguistic\ndiversity and equity in NLP.\nTo the best of our knowledge, this is the first\ncomprehensive review focusing specifically on the\n200\nadvancements, challenges, and opportunities in Ar-\nmenian Natural Language Processing. Therefore,\nour paper fills a crucial gap in the literature, pro-\nviding a much-needed foundation for further ex-\nploration and development in Armenian NLP. This\nadded context further emphasizes the value and\nnovelty of our contributions to the field.\n2 Exploration of Armenian Natural\nLanguage Processing: Key Domains\nand Literature Review\nIn the forthcoming chapter, we will present an\noverview of the current state of Armenian NLP\nbased on the findings of our review. Given the\nscope limitations, a detailed discussion of the find-\nings cannot be provided. However, for a com-\nprehensive understanding of the literature search\nprocess, including the specific databases searched\nand the keywords employed, and to ensure trans-\nparency, please refer to Section A in the appendix.\n2.1 Linguistic Resources and Tools\nThe rapid growth of Natural Language Processing\n(NLP) has primarily been geared toward resource-\nrich languages such as English, Spanish, and Chi-\nnese, overlooking lower-resource languages like\nArmenian. This oversight results in a scarcity of\nlinguistic resources and tools, which is detrimen-\ntal to language preservation, linguistic research,\nand the development of NLP applications for such\nlanguages (Silberztein, 2007; Baghdasaryan, 2022;\nMalajyan et al., 2020; Kindt and Van Elverdinghe,\n2022; Megerdoomian, 2009; Vidal-Gorène and\nDecours-Perez, 2020; Khurshudyan et al., 2022;\nSaini and Rakholia, 2016).\nNLP Development Platforms : NooJ, for ex-\nample, allows users to create grammars and dic-\ntionaries while providing parsing capabilities for\ntokenization, morphology, syntax, and semantics.\nHowever, its resources are still insufficient for full-\nscale Armenian language processing, indicating\na need for more comprehensive platforms (Sil-\nberztein, 2007).\nSpeech Corpora : The ArmSpeech corpus\npresents a collection of Armenian speech data,\nwhich is essential for speech recognition, synthesis,\nand spoken language identification systems. Nev-\nertheless, the necessity for similar large-scale re-\nsources in other aspects of the Armenian language\nremains (Baghdasaryan, 2022).\nSemantic and Paraphrase Corpora : The\nARPA corpus, a paraphrase dataset generated using\nback translation, forms a foundation for paraphrase\ndetection in Armenian. However, the small scale\nof this corpus (2360 paraphrases) underscores the\nneed for more diverse datasets to enhance NLP\ntasks (Malajyan et al., 2020).\nHistorical Language Resources: Efforts like\nthe GREgORI Project, which processes historical\nArmenian manuscripts, are crucial for enhancing\nArmenian linguistic resources. However, a broader\nrange of Armenian language variations and con-\ntexts needs to be included for comprehensive re-\nsource development (Kindt and Van Elverdinghe,\n2022).\nLanguage-specific Features and Bootstrap-\nping: Techniques such as related language boot-\nstrapping can help develop language resources.\nHowever, Armenian’s unique linguistic features ne-\ncessitate a language-specific approach rather than\na generalized strategy (Megerdoomian, 2009).\nResource Compilation Platforms: Calfa com-\npiles and updates existing resources for Classical\nArmenian, showcasing promising advancements\nin Armenian NLP. However, the need for larger,\ninteroperable databases persists, indicating the ne-\ncessity for more systematic efforts (Vidal-Gorène\nand Decours-Perez, 2020).\nComprehensive Corpora: The Eastern Arme-\nnian National Corpus (EANC) provides a valu-\nable resource for linguistic studies and various re-\nsearch fields. However, the need for more compre-\nhensive databases covering different time frames,\nstyles, and registers is apparent (Khurshudyan et al.,\n2022).\nFoundational Resources: Specific stop-word\nlists for Armenian are notably lacking, despite\nbeing foundational resources in NLP (Saini and\nRakholia, 2016).\nIn conclusion, while progress has been made, fur-\nther efforts are required to enrich Armenian NLP.\nThis necessitates the creation of more comprehen-\nsive resources, the development of tools for diverse\nNLP tasks, and the promotion of multilingual or\ncross-lingual learning methods to counterbalance\ndata scarcity. Moreover, it highlights the need for\ncollaboration among researchers, data scientists,\nand the Armenian community worldwide to create\nculturally sensitive, community-driven resources.\n201\n2.2 Evolution of Speech Processing and\nRecognition\nArmenian speech processing and recognition has\nwitnessed transformative advancements across var-\nious key sub-domains, primarily automated speech\nrecognition (ASR), speech recognition thresholds\n(SRT), dialect identification, and evaluation of\nASR systems (Davit and Tigran, 2022; Bagh-\ndasaryan; Sargsyan and Rahne, 2021; Avetisyan,\n2022; Aslanyan et al., 2015; Chakmakjian and\nWang, 2022).\nAutomated Speech Recognition (ASR) Mod-\nels: A dual strategy has marked Progress in this\nrealm. Davit and Tigran (2022) fine-tuned a pre-\ntrained Conformer model yielding notable Arme-\nnian ASR outcomes, while Baghdasaryan devised\nan efficient real-time speech-to-text system using\nBaidu’s Deep Speech and KenLM toolkit. These\ninitiatives signal the feasible extension of ASR ap-\nplications to languages with limited resources.\nSpeech Recognition Thresholds: Sargsyan and\nRahne (2021) innovated a multisyllabic speech au-\ndiometry test capable of measuring SRT in Ar-\nmenian speakers. The results corroborated with\nequivalent studies in other languages, signifying a\nuniversal scope for this approach.\nDialect Identification: The work of Avetisyan\n(2022) illustrated the superiority of neural network\nmodels over statistical approaches in Armenian\ndialect identification. The successful utilization of\npre-trained word vectors, even with scarce training\ndata, added to the novelty of their work.\nEvaluation and Future Directions for ASR :\nAslanyan et al. (2015) meticulously assessed cur-\nrent ASR technologies and suggested alternatives\nto Hidden Markov Models, like Artificial Neural\nNetworks and Sequence Data Mining, to enhance\nrecognition accuracy.\nChallenges of ASR for Bivariant Languages:\nThe complexities of developing ASR for Armenian,\na language with two diverse standard variants, were\nhighlighted by Chakmakjian and Wang (2022). A\npractical methodology emphasizing the need for\na comprehensive understanding of both language\nvariants was proposed for future ASR research.\nThese studies underscore the advances in Arme-\nnian speech processing and recognition, mapping\nout promising future directions for low-resource\nlanguages like Armenian. The collective contribu-\ntion of these researchers forms a robust foundation\nfor further advancements in the field, highlighting\nthe necessity for continuous exploration and inno-\nvation in speech recognition technology.\n2.3 Progress in Morphology and Syntax\nThe development of NLP resources for under-\ndocumented languages like Armenian has seen\nnoteworthy progress in morphological and syntac-\ntic analysis, as highlighted by several key studies\n(Dolatian et al., 2022; Kindt and Kepeklian, 2022;\nVidal-Gorène and Kindt, 2020; Vidal-Gorène et al.,\n2020; Ghukasyan and Avetisyan, 2021; Arkhangel-\nskiy et al., 2012; Chiarcos et al., 2018).\nMorphological Analysis: A wide spectrum of\ntools has been developed, including a morphologi-\ncal transducer by Dolatian et al. (2022) for Western\nArmenian, and a reusable RNN model by Vidal-\nGorène et al. (2020) for various Armenian dialects.\nThe latter indicates the possibility of rapid cor-\npus processing in languages with limited NLP re-\nsources.\nLexical Analysis: Kindt and Kepeklian (2022)\nsuccessfully applied a hybrid method combining\ndigital dictionaries and RNN methodologies for an-\nalyzing ancient Armenian text, underscoring the\nutility of traditional and machine learning tech-\nniques.\nLemmatization and POS-Tagging: There have\nbeen advancements in the development of lemma-\ntization and POS-tagging resources for Classical\nArmenian (Vidal-Gorène and Kindt, 2020), includ-\ning the creation of a lightweight yet highly accurate\nlemmatizer (Ghukasyan and Avetisyan, 2021).\nCorpus Creation: Corpus construction tools,\nlike UniParser and the EANC platform, were uti-\nlized by Arkhangelskiy et al. (2012) to construct a\nmorphologically annotated corpus for a minority\nlanguage, demonstrating the potential for similar\ninitiatives in other low-resource languages.\nExtensions to Universal Morphologies: Chiar-\ncos et al. (2018) aimed at enhancing the coverage\nof Universal Morphologies (UniMorph) for the lan-\nguages of the Caucasus region, pointing towards\nthe potential for further improvement and adapt-\nability of existing tools.\nIn summary, there is promising progress in the\nmorphological and syntactic analysis of Armenian,\nwith studies indicating the potential of machine\nlearning methodologies and the need for larger,\nmore representative datasets. However, further re-\nsearch is needed to augment the adaptability of\nthese tools across different Armenian dialects and\n202\nimprove their accuracy.\n2.4 Advancements in Semantics and Named\nEntity Recognition (NER)\nDevelopments in semantics and Named Entity\nRecognition (NER) for Armenian have been note-\nworthy, as exhibited by the research conducted by\nMkhitaryan and Madatyan (2022); Podolak and\nZeinert (2020); Jain et al. (2019); Tambuscio and\nAndrews (2021); Vachagan and Tigran (2015);\nGhukasyan et al. (2018).\nSemantics: Exploring temporal expressions in\nArmenian fairy tales, Mkhitaryan and Madatyan\n(2022) identified shared schemas with English, thus\nguiding the future semantic analysis of Armenian\ntexts. Additionally, Vachagan and Tigran (2015) de-\nveloped algorithms for advanced sentence-level se-\nmantic analysis, addressing issues like homonyms.\nCross-Lingual NER: Multilingual transformer\nmodels were investigated by Podolak and Zeinert\n(2020) to understand the influence of language-\nspecific features on performance. Meanwhile, Jain\net al. (2019) leveraged machine translation to en-\nhance NER in languages with sparsely annotated\ncorpora, exhibiting superior performance for Ar-\nmenian NER compared to a monolingual model.\nGeolocation NER : Tambuscio and Andrews\n(2021) enhanced the detection of geographical en-\ntities from historical Armenian text by combining\nthe output of multiple NER tools and utilizing geo-\ngraphical clustering, overcoming the limitations of\ntraditional NER tools for older texts.\nResources for Armenian NER : Ghukasyan\net al. (2018) made a significant contribution by pro-\nviding a silver- and gold-standard dataset, setting\nbaseline results for popular models, and sharing\nArmenian word embeddings, all of which can aid\nin the development of Armenian NER systems.\nIn summary, the progress made in Armenian se-\nmantics and NER is considerable. However, the\npotential for improvement is vast, with future di-\nrections including refining models, creating more\nrepresentative datasets, leveraging machine transla-\ntion for cross-lingual NER, and enhancing seman-\ntic analysis techniques. These advancements are\nessential for fully understanding and preserving the\nrichness of the Armenian language.\n2.5 Innovations in Document Analysis and\nOptical Character Recognition\nPioneering developments in document analysis and\noptical character recognition (OCR) have signifi-\ncantly benefited the preservation and accessibility\nof low-resource languages, such as Armenian. The\nworks by Vidal-Gorène et al. (2021); Hovakimyan\net al.; Islam and Dundua (2015); Tigranyan and\nGhukasyan (2020) illustrate this trend:\nMultilevel Annotation Platform: Vidal-Gorène\net al. (2021) created an online, modular interface to\nannotate handwritten and printed documents. By\ndeveloping an Armenian manuscript database, they\nshowed the utility of such platforms in automating\ntasks and managing data. Their tool demonstrates\nthe potential to enrich digital humanities resources,\nparticularly for lesser-documented languages.\nText Recognition: Hovakimyan et al. intro-\nduced a novel two-layer neural network approach\nfor Armenian text recognition. By outperforming\nsingle-layer networks, their work significantly ad-\nvances the digitization of Armenian texts, expand-\ning the possible applications of complex networks\nin text recognition.\nOrigin Tracing: Islam and Dundua (2015) em-\nployed supervised machine learning to identify\nthe origins of the Georgian Gospel. Their clas-\nsifier, based on lexical and classical information-\ntheoretic features, distinguishes original from trans-\nlated documents, underscoring the potential of ma-\nchine learning in document analysis and multilin-\ngual data handling.\nError Reduction: The challenge of OCR errors\nin Armenian texts was addressed by Tigranyan and\nGhukasyan (2020). Through a two-step method\ninvolving a multilayer perceptron and a convolu-\ntional neural network-based sequence transducer,\nthey reduced the word error rate in OCR output,\nemphasizing the importance of post-processing in\nOCR tasks.\nIn summary, these studies signify considerable\nprogress in document analysis and OCR for Ar-\nmenian, revealing the power of innovative meth-\nods and collaborative platforms. However, further\nresearch is needed to continue enhancing these\nresources’ quality, accuracy, and breadth, ensur-\ning the preservation and accessibility of Armenian\ntexts.\n2.6 Emerging Trends in Armenian Text\nSimilarity and Plagiarism Detection\nRecent studies in text similarity and plagiarism\ndetection have introduced promising methodolo-\ngies, particularly for low-resource languages like\nArmenian. The works by Avetisyan et al. (2023);\n203\nYeshilbashian et al. (2022); Ter-Hovhannisyan and\nAvetisyan (2022); Margarov et al. (2017) contribute\nto this growing field:\nCross-Lingual Plagiarism Detection :\nAvetisyan et al. (2023) introduced a cross-\nlingual plagiarism detection method leveraging\nmultilingual thesauri and pre-trained BERT-based\nlanguage models. The method’s effectiveness\nacross languages and its independence from\nmachine translation or word sense disambiguation\nmake it a fitting solution for less-resourced\nlanguages.\nStylometric Techniques: Yeshilbashian et al.\n(2022) used intrinsic stylometric techniques for\nArmenian text plagiarism detection. They imple-\nmented hierarchical clustering models, thereby in-\ndicating areas for improvement for longer docu-\nments and suggesting refinements for feature sets\nand parsers.\nCross-Lingual Sentence Alignment: The value\nof pre-trained Transformer-based language models\nfor cross-lingual sentence alignment was under-\nscored by Ter-Hovhannisyan and Avetisyan (2022).\nThey found the XLM-RoBERTa model outper-\nformed others across multiple languages, reinforc-\ning the advantage of a single model trained on vari-\nous languages in a multilingual context.\nMulti-Layered Analysis : Margarov et al.\n(2017) introduced an Armenian text similarity anal-\nysis system. By conducting a multi-layered analy-\nsis and facilitating user interaction, their approach\ncomprehensively detects plagiarism, including syn-\nonym replacement and translation-based plagia-\nrism.\nThese studies highlight the potential of advanced\nlanguage models, stylometric techniques, and user-\ninteractive systems for enhancing text similarity\nand plagiarism detection in Armenian and other\nlow-resource languages. They lay out directions\nfor future research, including refining feature sets,\ndevising efficient model training strategies, and\ncreating more user-interactive systems.\n2.7 Evolution of Language Modeling for\nArmenian Language\nThe field of language modeling has seen significant\ngrowth, with research focusing on creating custom\nmodels for the Armenian language and enhancing\nthe cross-lingual capabilities of multilingual mod-\nels.\nCompact Language Modeling: In Karamyan\nand Karamyan (2022), a compact and efficient\nN-gram language model was developed specifi-\ncally for Armenian. The researchers optimized\nthe model’s size and performance using pruning,\nquantization, and Byte Pair Encoding (BPE) tech-\nniques. This research resulted in a compact, high-\nperforming language model for Armenian.\nCross-lingual Transfer: In an endeavor to en-\nhance the cross-lingual transfer abilities of Multi-\nlingual BERT (mBERT), Kulshreshtha et al. (2020)\nmanaged to improve its performance. The re-\nsearchers achieved this by aligning mBERT with\ncross-lingual signals, employing parallel corpora\nsupervision, and fine-tuning the alignment. Their\nstudy provides valuable insights into strengthening\nlanguage transfer in multilingual models.\nWord Embedding Models: On a different track,\nAvetisyan and Ghukasyan (2019) tested existing\nArmenian word embedding models and introduced\nnew ones. They employed intrinsic and extrinsic\nevaluation methods involving a variety of language\ntasks for comprehensive analysis. The researchers\nfound that different models excelled at different\ntasks, highlighting the inadequacy of a \"one-size-\nfits-all\" approach in choosing an embedding model.\nThey also provided new embeddings that outper-\nformed existing ones in several tasks, contributing\nto more effective Armenian language processing\ntools.\nIn conclusion, efforts in Armenian language\nmodeling are shaping the landscape of language-\nspecific models, enhancing multilingual models’\ncross-lingual capabilities, and refining word em-\nbeddings. These research endeavors contribute to\na richer understanding and processing of the Ar-\nmenian language, driving progress toward more\neffective natural language processing tools.\n3 Trends Over Time in Armenian NLP\nResearch\nResearch on Armenian Natural Language Process-\ning (NLP) has evolved significantly, showcasing\nnotable trends in methods and techniques employed\nfor addressing NLP tasks in the Armenian lan-\nguage.\nInitially, Armenian NLP research focused on de-\nveloping basic tools and methods, such as keyword\nidentification and stemming, to handle specific\ntasks like plagiarism detection (Margarov et al.,\n2017). These early studies aimed to overcome the\nlanguage’s unique challenges and lay the founda-\n204\ntion for further advancements.\nAs research progressed, more advanced tech-\nniques and algorithms were adopted. Stylomet-\nric approaches emerged, enabling the detection\nof style changes and breaches in Armenian texts\n(Yeshilbashian et al., 2022). These findings\nhighlighted the potential for more sophisticated\nlanguage-specific tasks.\nRecently, there has been a shift towards utilizing\ntransformer-based models in Armenian NLP. Pre-\ntrained multilingual models like BERT and XLM-\nRoBERTa have shown promising results in tasks\nrequiring a deeper understanding of text semantics\nand cross-lingual alignment (Avetisyan et al., 2023;\nTer-Hovhannisyan and Avetisyan, 2022). However,\nthe application of large language models in Arme-\nnian NLP remains relatively unexplored.\nIn conclusion, Armenian NLP research has tran-\nsitioned from basic text processing techniques\nto embracing complex transformer-based models.\nWhile significant progress has been made, explor-\ning large language models in Armenian NLP is\nstill in its early stages. This trend emphasizes the\nneed for further research, particularly in applying\nlarge language models, to address the unique chal-\nlenges of the Armenian language and drive the field\nforward.\n4 Identification of Gaps, Limitations, and\nChallenges in Current Research\nBased on our review, the main challenges in Ar-\nmenian Natural Language Processing (NLP) are as\nfollows:\n1. Limited Availability of Large, Labeled\nDatasets: Armenian NLP is considerably con-\nstrained by the scarcity of large and diverse\nlabeled datasets (Khurshudyan et al., 2022).\nThese datasets are essential for training and\nevaluating machine learning models, includ-\ning large language models (LLMs). The lack\nof such resources limits the capacity to lever-\nage the full potential of LLMs for Armenian\nNLP tasks.\n2. Shortage of Linguistic Resources and Tools:\nThe lack of comprehensive linguistic tools,\nsuch as parsers, lemmatizers, and tokeniz-\ners, poses significant challenges for Armenian\nNLP. This lack becomes particularly evident\nin tasks requiring complex linguistic analysis,\nlike stylometry (Yeshilbashian et al., 2022)\nand plagiarism detection (Avetisyan et al.,\n2023). Additionally, the absence of resources\nlike a robust Armenian WordNet counterpart\nconstrains the development of applications\nsuch as semantic analysis and machine trans-\nlation.\n3. Less Prevalent Use of Advanced Mod-\nels: While studies are leveraging advanced\nmachine learning models such as BERT-\nbased and transformer models for Arme-\nnian NLP tasks (Avetisyan et al., 2023; Ter-\nHovhannisyan and Avetisyan, 2022), the over-\nall application of such models, especially\nlarge language models (LLMs), is still limited.\nThis restricts the understanding and potential\nbenefits of using LLMs in the Armenian NLP.\n4. Handling Dialectal Variations : Dialectal\nvariations of Armenian (Weitenberg, 2002)\ncan significantly impact the performance of\nlanguage models if not accounted for during\ntheir development and training.\n5. Challenges in Adapting Armenian for NLP\nApplications: Armenian, as a unique Indo-\nEuropean language with a rich history, faces\nseveral linguistic challenges integral to its\nspeakers and the broader linguistic landscape.\nOne of the distinctive features of Armenian is\nits alphabetic script (Sanjian, 1996), which\nhas its own set of characters and symbols,\nmaking it distinct from the Roman or Cyril-\nlic scripts. While culturally significant, this\nuniqueness can pose difficulties regarding dig-\nital representation and compatibility with in-\nternational standards. Adapting Armenian to\nmodern technological applications often re-\nquires accurate font development and encod-\ning to ensure proper rendering and function-\nality. Moreover, the Armenian language has\nundergone various historical shifts and linguis-\ntic influences due to its location at the cross-\nroads of Eastern Europe and Western Asia.\nThese influences, including Persian, Arabic,\nand Russian, have left their mark on Armenian\nvocabulary and grammar. Navigating this lin-\nguistic history and preserving the purity of\nthe language can be a complex undertaking.\nEconomic factors and government policies are\nalso crucial in shaping the language’s trajec-\ntory, impacting its promotion, preservation,\nand accessibility.\n205\nFurthermore, handling inflections, word or-\nder flexibility, and the rich morphological sys-\ntem of Armenian (Dum-Tragut, 2009) could\npresent unique challenges in developing prac-\ntical NLP tools and models. These issues\nrequire in-depth research to create NLP so-\nlutions that accurately capture and process\nthe complexities of the Armenian language.\nThus, the intersection of linguistic uniqueness,\nhistorical influences, and complex linguistic\nfeatures necessitates a multidimensional ap-\nproach to address the challenges of adapting\nArmenian for modern NLP applications.\n6. Low Commercial Interest: Due to the lim-\nited population of Armenian speakers com-\npared to other languages, there may be less\ncommercial incentive to invest in Armenian\nNLP research and development. This can slow\ndown progress in this field.\n5 The utilization of LLMs in Armenian\nNLP tasks\nThe recent advancements in natural language pro-\ncessing (NLP) have been significantly driven by the\nadvent and development of large language models\n(LLMs), such as BERT, GPT-3, and T5. How-\never, despite their evident success, the adoption\nof LLMs in Armenian NLP tasks has been some-\nwhat limited, as reflected in the current literature\n(Avetisyan et al., 2023; Yeshilbashian et al., 2022;\nTer-Hovhannisyan and Avetisyan, 2022; Margarov\net al., 2017).\nOnly a handful of studies in Armenian NLP\nhave explored the use of Large Language Mod-\nels (LLMs). For instance, Avetisyan et al.\n(2023) employed a BERT-based model for cross-\nlingual plagiarism detection, showcasing its versa-\ntility. In a related effort, Ter-Hovhannisyan and\nAvetisyan (2022) utilized the transformer-based\nXLM-RoBERTa model for cross-lingual sentence\nalignment, highlighting its effectiveness in multi-\nlingual contexts. Additionally, Kulshreshtha et al.\n(2020) augmented the cross-lingual transfer abil-\nities of Multilingual BERT (mBERT) to achieve\nsuperior performance in language transfer tasks.\nDespite the proven efficacy of Large Language\nModels (LLMs) in various language processing\ntasks for well-resourced languages, their utilization\nin Armenian NLP remains limited. The prevailing\napproaches in Armenian NLP lean towards tradi-\ntional methods, such as clustering, bag-of-words,\nand rule-based techniques (Yeshilbashian et al.,\n2022; Margarov et al., 2017). While these methods\nhave shown relative success, the underutilization\nof LLMs highlights a research gap and the poten-\ntial to enhance the performance of Armenian NLP\nsystems.\nGiven the transformative effect of LLMs on NLP\ntasks in other languages, the underutilization of\nLLMs in Armenian NLP calls for future research.\nExploring the reasons behind this limited appli-\ncation and identifying potential solutions could\ngreatly benefit Armenian NLP. Therefore, future\nstudies on Armenian NLP should consider the fol-\nlowing directions:\n1. Expanding Data Resources: One of the main\nchallenges in Armenian NLP is the shortage of\nhigh-quality and diverse language resources.\nFuture work should prioritize developing and\naugmenting Armenian language corpora, in-\ncluding web scraping of Armenian text, tran-\nscription of spoken language, and translation\nof existing datasets from other languages. Ef-\nforts should be made to ensure these datasets\nspan multiple domains and genres, such as\nnews, academic literature, fiction, and social\nmedia posts (Avetisyan et al., 2023).\n2. Fine-tuning of Pre-trained Models :\nAs demonstrated in studies (Ghukasyan\net al., 2018; Avetisyan et al., 2023; Ter-\nHovhannisyan and Avetisyan, 2022),\nfine-tuning pre-trained language models on\nArmenian-specific tasks can yield impressive\nresults. However, this approach could be\nextended to other NLP tasks that have not\nbeen extensively explored in the Armenian\ncontext, such as sentiment analysis, topic\nmodeling, text summarization, and dialogue\nsystems.\n3. Investigating Language-specific Challenges:\nArmenian, like any other language, possesses\nunique linguistic characteristics that can pose\nchallenges for NLP. These characteristics may\ninclude complex morphology, dialects, or\nhistorical language changes. Understanding\nthese features and how they affect the perfor-\nmance of LLMs is crucial. Future work could\nexplore these challenges and devise strategies\nto mitigate their effects (Yeshilbashian et al.,\n2022).\n206\n4. Developing Armenian NLP Applications :\nOnce sufficient resources and fine-tuned mod-\nels are in place, efforts should build practi-\ncal applications for Armenian NLP. These\napplications could include Armenian senti-\nment analysis systems, named entity recogniz-\ners, chatbots, and machine translation systems\n(Margarov et al., 2017).\n5. Benchmarking and Evaluation: Establish-\ning benchmarks for various Armenian NLP\ntasks is crucial. These benchmarks will pro-\nvide a clear direction for the research commu-\nnity and enable comparing different models\nand approaches.\n6. Developing an Armenian-specific Lan-\nguage Model : While multilingual models\nhave succeeded, creating a large pre-trained\nlanguage model specifically for Armenian\ncould lead to even better performance. This\nwould require collecting and preprocessing a\nlarge Armenian corpus, which could benefit\nthe wider Armenian NLP community.\n7. Cross-lingual Transfer Learning : While\nAvetisyan et al. (2023) have successfully used\nmultilingual models, there is a need for more\nresearch on techniques for transferring learn-\ning from high-resource languages to Arme-\nnian. This can help achieve higher accu-\nracy in NLP tasks without requiring extensive\nArmenian-specific datasets.\n8. Exploration of Smaller Models: Large lan-\nguage models require significant computa-\ntional resources due to their size. Exploring\nthe application and performance of smaller\nmodels or efficient training methods could en-\nable the broader use of language models in\nArmenian NLP.\nThe potential benefits of these efforts are wide-\nreaching. From a research perspective, they can im-\nprove performance across various NLP tasks, deep-\nening our understanding of Armenian language pro-\ncessing. For users, these advancements could lead\nto more accurate and helpful language technology\napplications, including better machine translation\nsystems, more effective information retrieval tools,\nmore engaging dialogue systems, and more robust\ntext analysis tools.\nIn conclusion, by leveraging the potential of\nLLMs and addressing the unique challenges of Ar-\nmenian NLP, researchers and practitioners can pave\nthe way for significant advancements in language\ntechnology for Armenian. The proposed directions\nand future work outlined in this paper aim to stim-\nulate further research and collaboration in the field,\nultimately contributing to the growth and develop-\nment of Armenian NLP.\n6 Conclusion\nIn conclusion, this paper has taken significant\nstrides in illuminating the state of Natural Lan-\nguage Processing (NLP) research in the Armenian\nlanguage context, a low-resource language that has\nbeen relatively under-explored in the computational\nlinguistics landscape.\nOur analysis highlights a substantial gap in de-\nploying Large Language Models (LLMs) in Arme-\nnian NLP tasks, despite their proven effectiveness\nacross various NLP tasks for well-resourced lan-\nguages. This finding underscores the potential of\nharnessing the power of LLMs to boost Armenian\nlanguage processing tasks. However, it simultane-\nously reveals formidable challenges, such as the\nscarcity of training data, substantial computational\nresource requirements, and the peculiarities of the\nArmenian language.\nWith the rapid advancements in NLP and the\ngrowing focus on low-resource languages, our\nstudy articulates the imperative and the potential\nfor further exploration of Armenian NLP, armed\nwith the power of LLMs. Our work catalyzes such\nexploration, setting the stage for what we anticipate\nwill be a future filled with robust development in\nthis area. As part of our contributions, we have\nalso suggested several directions for future work,\nincluding training LLMs specifically on Armenian\ndata or fine-tuning existing multilingual models.\nMoreover, our paper makes a critical contribu-\ntion by situating the discourse on Armenian NLP\nwithin the broader NLP landscape and emphasizing\nthe need for the NLP community to give equal at-\ntention to low-resource languages. This can lead to\ndevelopment of more sophisticated NLP tools for\nthese languages and contribute to a more compre-\nhensive understanding of language diversity—an\naspect crucial for the holistic advancement of NLP.\nWe would like to encourage our fellow re-\nsearchers and practitioners in NLP to explore low-\nresource languages, such as Armenian. Investigat-\n207\ning such languages holds immense potential for\nrevealing novel approaches and techniques in NLP\nthat can serve a broader range of languages and\ncultures. This enriches the diversity in the NLP\nfield and presents a unique opportunity to refine\nand innovate our methodologies.\nEngaging with low-resource languages can also\nsignificantly reduce the digital divide and promote\ndiversity, ensuring all languages find representa-\ntion in the digital space. So, let us collectively\nembrace the challenges of low-resource languages\nand uncover the vast, untapped potential they offer\nto advance NLP.\nLastly, it is crucial to acknowledge that the devel-\nopment of Armenian NLP goes beyond technologi-\ncal advancements. It encompasses the preservation\nof language and cultural heritage. In today’s digital\nworld, languages lacking essential NLP resources\nface the risk of being marginalized. Hence, invest-\ning in Armenian NLP ensures the longevity and\nvitality of the Armenian language in the digital\nage.\nLimitations\nWhile providing a thorough review of Armenian\nNLP research, our study has several limitations\nthat should be noted. Primarily, the scope of our\nreview is confined to the set of studies and papers\nwe have access to, which might not encompass the\nfull breadth of relevant work in this area. Further,\nexploring Armenian as a low-resource language,\nwith its associated challenges, is a broad and mul-\ntifaceted issue. Although we strive to cover this\ntopic comprehensively, there could be facets that\nwere not fully captured in our discussion.\nIt is also essential to underscore that our review\nfundamentally relies on the accuracy and thorough-\nness of the original papers incorporated into our\nanalysis. Consequently, any inaccuracies or mis-\ninterpretations within those works could inadver-\ntently impact the findings of our review.\nMoreover, while we endeavored to present a rich\nsnapshot of the current state of Armenian NLP re-\nsearch, the inherently static nature of a review such\nas this cannot entirely keep pace with the rapid ad-\nvancements within the field. As such, certain parts\nof our analysis could potentially become outdated\nin a relatively short period.\nFinally, our paper primarily emphasizes using\nlarge language models in Armenian NLP. In fo-\ncusing on this aspect, there is a chance that other\npotentially effective approaches, including more\ntraditional linguistic methods, may not have been\nas extensively explored.\nOur suggestions for future work in Armenian\nNLP represent a projection of potential research\ndirections. Nonetheless, the feasibility and effec-\ntiveness of these suggestions would ultimately need\nto be empirically validated in subsequent research.\nEthics Statement\nWe recognize the importance of ethical consider-\nations in research and the broader impact of our\nwork. Throughout the process of conducting this\nliterature review, we have taken into account rele-\nvant ethical aspects.\nThis paper is solely focused on analyzing and\nsynthesizing existing literature without involving\nhuman subjects, data collection, or experimenta-\ntion. As a result, it does not require specific ethical\napprovals or considerations regarding human sub-\njects, privacy, or data protection.\nHowever, we are dedicated to promoting ethical\npractices and responsible information use. We have\nexercised caution to appropriately cite and attribute\nall the sources used in this review, respecting the\nintellectual property rights of authors and organiza-\ntions. We have aimed to accurately and objectively\nrepresent the content of the literature, ensuring that\nno biases or misinterpretations are introduced.\nAdditionally, we understand the significance of\ninclusivity and diversity within the field of NLP. In\nour review, we have deliberately covered a broad\nrange of studies and perspectives to provide a com-\nprehensive and balanced overview of the literature\non Armenian NLP. We have consciously tried to\naccurately represent the Armenian language and its\nspeakers, actively avoiding biases or stereotypes.\nOur methodologies and models have been devel-\noped with fairness and equity in mind, striving to\nminimize potential biases or discriminatory effects.\nFurthermore, we acknowledge the potential soci-\netal implications of our work. Our research aims\nto positively contribute to the Armenian language\ncommunity by supporting language preservation,\nlinguistic research, and application development\nfor Armenian speakers.\nReferences\nTimofey Arkhangelskiy, Oleg Belyaev, and Arseniy Vy-\ndrin. 2012. The creation of large-scale annotated\ncorpora of minority languages using uniparser and\n208\nthe eanc platform. In Proceedings of COLING 2012:\nPosters, pages 83–92.\nLevon Aslanyan, Minoosh Heidari, Hasmik Sahakyan,\nDaryoush Alipour, Jorge Fernández, Angel Castel-\nlanos, Juan Castellanos, Leonid Hulianytsky, Anna\nPavlenko, Mariam Haroutunian, et al. 2015. On\nstring mining speech recognition.\nKaren Avetisyan. 2022. Dialects identification of arme-\nnian language. In Proceedings of the Workshop on\nProcessing Language Variation: Digital Armenian\n(DigitAm) within the 13th Language Resources and\nEvaluation Conference, pages 8–12.\nKaren Avetisyan and Tsolak Ghukasyan. 2019. Word\nembeddings for the armenian language: intrin-\nsic and extrinsic evaluation. arXiv preprint\narXiv:1906.03134.\nKaren Avetisyan, Arthur Malajyan, and Tsolak\nGhukasyan. 2023. A simple and effective method\nof cross-lingual plagiarism detection. arXiv preprint\narXiv:2304.01352.\nVaruzhan H Baghdasaryan. Armenian speech recogni-\ntion system: Acoustic and language models.\nVaruzhan H Baghdasaryan. 2022. Armspeech: Arme-\nnian spoken language corpus. International Journal\nof Scientific Advances (IJSCIA), 3(3):454–459.\nSamuel Chakmakjian and Ilaine Wang. 2022. Towards a\nunified asr system for the armenian standards. In Pro-\nceedings of the Workshop on Processing Language\nVariation: Digital Armenian (DigitAm) within the\n13th Language Resources and Evaluation Confer-\nence, pages 38–42.\nChristian Chiarcos, Kathrin Donandt, Maxim Ionov,\nMonika Rind-Pawlowski, Hasmik Sargsian,\nJesse Wichers Schreur, Frank Abromeit, and\nChristian Fäth. 2018. Universal morphologies for\nthe caucasus region. In Proceedings of the Eleventh\nInternational Conference on Language Resources\nand Evaluation (LREC 2018).\nKaramyan Davit and Karamyan Tigran. 2022. A con-\nformer based automated speech recognition for arme-\nnian language. / /Scientific Artsakh, (2 (13)):224–\n229.\nHossep Dolatian, Daniel Swanson, and Jonathan Wash-\nington. 2022. A free/open-source morphological\ntransducer for western armenian. In Proceedings\nof the Workshop on Processing Language Variation:\nDigital Armenian (DigitAm) within the 13th Lan-\nguage Resources and Evaluation Conference, pages\n1–7.\nJasmine Dum-Tragut. 2009. Armenian: Modern eastern\narmenian, volume 14. John Benjamins Publishing.\nT Ghukasyan and K Avetisyan. 2021. Research and\ndevelopment of a deep learning-based lemmatizer for\nthe armenian language. - , page 92.\nTsolak Ghukasyan, Garnik Davtyan, Karen Avetisyan,\nand Ivan Andrianov. 2018. pioner: Datasets and\nbaselines for armenian named entity recognition. In\n2018 Ivannikov Ispras Open Conference (ISPRAS),\npages 56–61. IEEE.\nAnna Hovakimyan, Narine Ispiryan, and Gevorg Na-\nrimanyan. Armenian texts recognition via neural\nnetworks.\nZahurul Islam and Natia Dundua. 2015. Finding the\norigin of a translated historical document. In Pro-\nceedings of the 29th Pacific Asia Conference on Lan-\nguage, Information and Computation: Posters, pages\n96–105.\nAlankar Jain, Bhargavi Paranjape, and Zachary C\nLipton. 2019. Entity projection via machine\ntranslation for cross-lingual ner. arXiv preprint\narXiv:1909.05356.\nDavit S Karamyan and Tigran S Karamyan. 2022. Com-\npact n-gram language models for armenian. Mathe-\nmatical Problems of Computer Science, 57:30–38.\nVictoria Khurshudyan, Timofey Arkhangelskiy, Misha\nDaniel, Vladimir Plungian, Dmitri Levonian, Alex\nPolyakov, and Sergei Rubakov. 2022. Eastern arme-\nnian national corpus: State of the art and perspectives.\nIn Proceedings of the Workshop on Processing Lan-\nguage Variation: Digital Armenian (DigitAm) within\nthe 13th Language Resources and Evaluation Con-\nference, pages 28–37.\nBastien Kindt and Gabriel Kepeklian. 2022. Analyse\nautomatique de l’ancien arménien. évaluation d’une\nméthode hybride «dictionnaire» et «réseau de neu-\nrones» sur un extrait de l’adversus haereses d’irénée\nde lyon. In Proceedings of the Workshop on Process-\ning Language Variation: Digital Armenian (DigitAm)\nwithin the 13th Language Resources and Evaluation\nConference, pages 13–20.\nBastien Kindt and Emmanuel Van Elverdinghe. 2022.\nDescribing language variation in the colophons of ar-\nmenian manuscripts. In Proceedings of the Workshop\non Processing Language Variation: Digital Arme-\nnian (DigitAm) within the 13th Language Resources\nand Evaluation Conference, pages 21–27.\nSaurabh Kulshreshtha, José Luis Redondo-García, and\nChing-Yun Chang. 2020. Cross-lingual alignment\nmethods for multilingual bert: A comparative study.\narXiv preprint arXiv:2009.14304.\nArthur Malajyan, Karen Avetisyan, and Tsolak\nGhukasyan. 2020. Arpa: Armenian paraphrase detec-\ntion corpus and models. In 2020 Ivannikov Memorial\nWorkshop (IVMEM), pages 35–39. IEEE.\nGevorg Margarov, Gohar Tomeyan, and Maria\nJoão Varanda Pereira. 2017. Plagiarism detection\nsystem for armenian language. In 2017 Computer\nScience and Information Technologies (CSIT), pages\n185–189. IEEE.\n209\nKarine Megerdoomian. 2009. Low-density language\nstrategies for persian and armenian. In Language\nEngineering for Lesser-Studied Languages , pages\n291–312. IOS Press.\nYelena Mkhitaryan and Lusine Madatyan. 2022. A\nspatial model of conceptualization of time: With\nspecial reference to english and armenian fairy tales.\nInternational Journal of Language and Culture.\nJowita Podolak and Philine Zeinert. 2020. Master thesis:\nDeveloping a cross-lingual named entity recognition\nmodel.\nJatinderkumar R Saini and Rajnish M Rakholia. 2016.\nOn continent and script-wise divisions-based statis-\ntical measures for stop-words lists of international\nlanguages. Procedia Computer Science, 89:313–319.\nAvedis K Sanjian. 1996. The armenian alphabet. The\nworld’s writing systems, pages 356–357.\nSona Sargsyan and Torsten Rahne. 2021. Development\nof speech material for an armenian speech recogni-\ntion threshold test. Russian Open Medical Journal,\n10(3):321.\nMax Silberztein. 2007. An alternative approach to tag-\nging. In Natural Language Processing and Infor-\nmation Systems: 12th International Conference on\nApplications of Natural Language to Information Sys-\ntems, NLDB 2007, Paris, France, June 27-29, 2007.\nProceedings 12, pages 1–11. Springer.\nMarcella Tambuscio and Tara Lee Andrews. 2021. Ge-\nolocation and named entity recognition in ancient\ntexts: A case study about ghewond’s armenian his-\ntory. In CHR, pages 136–148.\nTatevik Ter-Hovhannisyan and Karen Avetisyan. 2022.\nTransformer-based multilingual language models in\ncross-lingual plagiarism detection. In 2022 Ivannikov\nMemorial Workshop (IVMEM), pages 72–80. IEEE.\nS Tigranyan and T Ghukasyan. 2020. Post-ocr correc-\ntion of armenian texts using neural networks. Vest-\nnik” Scientific Journal of Russian-Armenian Univer-\nsity.—2020.\nVahradyan Vachagan and Apozyan Tigran. 2015. On\nmeanings of words, sentences and texts interpreted\nfor chess and literary eastern armenian.\nChahan Vidal-Gorène and Aliénor Decours-Perez. 2020.\nLanguages resources for poorly endowed languages:\nThe case study of classical armenian. In Proceed-\nings of The 12th Language Resources and Evaluation\nConference, pages 3145–3152.\nChahan Vidal-Gorène, Boris Dupin, Aliénor Decours-\nPerez, and Thomas Riccioli. 2021. A modular and au-\ntomated annotation platform for handwritings: eval-\nuation on under-resourced languages. In Document\nAnalysis and Recognition–ICDAR 2021: 16th Inter-\nnational Conference, Lausanne, Switzerland, Septem-\nber 5–10, 2021, Proceedings, Part III 16, pages 507–\n522. Springer.\nChahan Vidal-Gorène, Victoria Khurshudyan, and\nAnaïd Donabédian-Demopoulos. 2020. Recycling\nand comparing morphological annotation models for\narmenian diachronic-variational corpus processing.\nIn Proceedings of the 7th Workshop on NLP for Simi-\nlar Languages, Varieties and Dialects, pages 90–101.\nChahan Vidal-Gorène and Bastien Kindt. 2020. Lemma-\ntization and pos-tagging process by using joint learn-\ning approach. experimental results on classical ar-\nmenian, old georgian, and syriac. In Proceedings\nof LT4HALA 2020-1st Workshop on Language Tech-\nnologies for Historical and Ancient Languages, pages\n22–27.\nJos JS Weitenberg. 2002. Aspects of armenian dialec-\ntology. TRENDS IN LINGUISTICS STUDIES AND\nMONOGRAPHS, 137:141–158.\nYe M Yeshilbashian, AA Asatryan, and Ts G\nGhukasyan. 2022. Plagiarism detection in armenian\ntexts using intrinsic stylometric analysis. Program-\nming and Computer Software, 48(7):435–444.\nA Literature Search and Keywords\nThe literature search was conducted in promi-\nnent academic databases such as the ACL An-\nthology, IEEE Xplore, Google Scholar, Semantic\nScholar, ACM Digital Library, SpringerLink, and\nScienceDirect. These databases were chosen due to\ntheir extensive coverage of relevant research papers\nin the field of Natural Language Processing (NLP).\nTo retrieve relevant literature, we employed a\ncomprehensive set of keywords. These keywords\nwere carefully selected to encompass various as-\npects of NLP research, including methodologies,\ntechniques, applications, and specific subdomains\nwithin NLP. The chosen keywords aimed to capture\na broad range of literature pertinent to our research\nobjectives.\nBy combining general and specific keywords, we\nsought to cast a wide net to ensure the inclusivity of\nrelevant publications. This approach enabled us to\nexplore diverse perspectives and comprehensively\nunderstand the current state of research in NLP.\nThe selected keywords were rigorously reviewed\nand refined iteratively to optimize their effective-\nness in retrieving relevant literature. The process\ninvolved considering synonymous terms, related\nconcepts, and variations in terminology commonly\nused in the NLP community. This ensured that our\nsearch strategy was comprehensive and accounted\nfor different linguistic expressions and terminolo-\ngies used across the literature.\nThe selected keywords are as follows: \"Ar-\nmenian language\" AND \"Natural Language Pro-\n210\ncessing\" \"Armenian\" AND \"NLP\" \"Armenian lan-\nguage\" AND \"Machine Learning\" \"Large Lan-\nguage Models\" AND \"Armenian\" \"Low-resource\"\nAND \"NLP\" AND \"Armenian\" \"Armenian lan-\nguage\" AND \"deep learning\" \"Transfer learning\"\nAND \"Armenian\" \"Armenian\" AND \"BERT\" \"Ar-\nmenian\" AND \"Transformer models\" \"Armenian\nlanguage\" AND \"AI\" \"Neural Networks\" AND \"Ar-\nmenian language\" \"Armenian\" AND \"Language\nModels\" \"Armenian\" AND \"Text classification\"\n\"Armenian\" AND \"Named Entity Recognition\"\n\"Armenian\" AND \"Sentiment Analysis\" \"Arme-\nnian\" AND \"Speech Recognition\" \"Armenian\"\nAND \"Language Generation\" \"Armenian\" AND\n\"Text-to-Speech\"."
}