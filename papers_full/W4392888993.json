{
    "title": "Arabic sarcasm detection: An enhanced fine-tuned language model approach",
    "url": "https://openalex.org/W4392888993",
    "year": 2024,
    "authors": [
        {
            "id": null,
            "name": "Mohamed A. Galal",
            "affiliations": [
                "Nile University"
            ]
        },
        {
            "id": "https://openalex.org/A2990558527",
            "name": "Ahmed Hassan Yousef",
            "affiliations": [
                "Egypt University of Informatics",
                "Ain Shams University",
                "Cairo University"
            ]
        },
        {
            "id": "https://openalex.org/A2147245550",
            "name": "Hala H. Zayed",
            "affiliations": [
                "Benha University",
                "Cairo University",
                "Egypt University of Informatics"
            ]
        },
        {
            "id": "https://openalex.org/A1863664594",
            "name": "Walaa Medhat",
            "affiliations": [
                "Benha University",
                "Nile University"
            ]
        },
        {
            "id": null,
            "name": "Mohamed A. Galal",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2990558527",
            "name": "Ahmed Hassan Yousef",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2147245550",
            "name": "Hala H. Zayed",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1863664594",
            "name": "Walaa Medhat",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2792216068",
        "https://openalex.org/W6745760545",
        "https://openalex.org/W3158586872",
        "https://openalex.org/W4205200841",
        "https://openalex.org/W2964996521",
        "https://openalex.org/W6807416921",
        "https://openalex.org/W2974273066",
        "https://openalex.org/W2493916176",
        "https://openalex.org/W2767784948",
        "https://openalex.org/W2962739339",
        "https://openalex.org/W2963026768",
        "https://openalex.org/W3176169354",
        "https://openalex.org/W4287888944",
        "https://openalex.org/W3153540814",
        "https://openalex.org/W4316657687",
        "https://openalex.org/W3155561744",
        "https://openalex.org/W4322008210",
        "https://openalex.org/W6674448969",
        "https://openalex.org/W2250710744",
        "https://openalex.org/W2251379416",
        "https://openalex.org/W2251920663",
        "https://openalex.org/W6693552132",
        "https://openalex.org/W6732295346",
        "https://openalex.org/W2512532697",
        "https://openalex.org/W6720310788",
        "https://openalex.org/W6778866975",
        "https://openalex.org/W3046029109",
        "https://openalex.org/W3138407803",
        "https://openalex.org/W4323042015",
        "https://openalex.org/W2786781024",
        "https://openalex.org/W2767481019",
        "https://openalex.org/W6772433836",
        "https://openalex.org/W3004285271",
        "https://openalex.org/W6841721130",
        "https://openalex.org/W6638532356",
        "https://openalex.org/W6691253234",
        "https://openalex.org/W2908540075",
        "https://openalex.org/W2009578396",
        "https://openalex.org/W2889609628",
        "https://openalex.org/W6660600547",
        "https://openalex.org/W6773135019",
        "https://openalex.org/W6773403819",
        "https://openalex.org/W2915002815",
        "https://openalex.org/W4318832809",
        "https://openalex.org/W6602766900",
        "https://openalex.org/W2964066928",
        "https://openalex.org/W3045509595",
        "https://openalex.org/W3046075181",
        "https://openalex.org/W4220922805",
        "https://openalex.org/W3153742268",
        "https://openalex.org/W2991568321",
        "https://openalex.org/W4287887212",
        "https://openalex.org/W4287854812",
        "https://openalex.org/W4210295555",
        "https://openalex.org/W4376654193",
        "https://openalex.org/W1842080548",
        "https://openalex.org/W3003370095",
        "https://openalex.org/W2398936787",
        "https://openalex.org/W3004199609",
        "https://openalex.org/W4291208003",
        "https://openalex.org/W2041400887",
        "https://openalex.org/W3003537538",
        "https://openalex.org/W2268623141",
        "https://openalex.org/W4245635803",
        "https://openalex.org/W3103593657"
    ],
    "abstract": "Sarcasm is a complex linguistic phenomenon involving humor, criticism, or phrases that convey the opposite meaning, mask true feelings, and play pivotal roles in various aspects of communication. Therefore, identifying sarcasm is essential for sentiment analysis, social media monitoring, and customer service, as it enables a better understanding of public sentiment. Moreover, social media has become a primary platform for people to express their feelings and opinions and provide feedback to businesses and service providers. Misinterpreting sarcasm in customer feedback can lead to incorrect responses and actions. However, accurately detecting sarcasm is challenging because it depends on context, cultural factors, and inherent ambiguity. Despite the plenty of research and resources in Machine Learning (ML) for detecting sarcasm in English, including Deep Learning (DL) techniques, there is still a shortage of research in sarcasm detection in Arabic, particularly in DL methodologies and available sarcastic datasets. This paper constructed a new Arabic sarcastic corpus and fine-tuned three pre-trained Arabic transformer-based Language Models (LM) for Arabic sarcasm detection. We also proposed a hybrid DL approach for sarcasm detection that combines static and contextualized representations using pre-trained LM, such as Word2Vec word embeddings and Bidirectional Encoder Representations from Transformers (BERT) models pretrained on Arabic resources. The proposed enhanced hybrid deep learning approach outperforms state-of-the-art models by 8% on a shared benchmark dataset and achieves a 5% improvement in F1-score on another.",
    "full_text": null
}