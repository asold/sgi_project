{
  "title": "A Novel Approach to Nursing Clinical Intelligent Decision-Making: Integration of Large Language Models and Local Knowledge Bases",
  "url": "https://openalex.org/W4390046444",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2099960391",
      "name": "Liping Xiong",
      "affiliations": [
        "ShenZhen People’s Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A3001019768",
      "name": "Qiqiao Zeng",
      "affiliations": [
        "ShenZhen People’s Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2793276333",
      "name": "Wuhong Deng",
      "affiliations": [
        "ShenZhen People’s Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2257861279",
      "name": "Weixiang Luo",
      "affiliations": [
        "ShenZhen People’s Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2099557669",
      "name": "Ronghui Liu",
      "affiliations": [
        "South China University of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4367183588",
    "https://openalex.org/W3207360334",
    "https://openalex.org/W4319662928",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4288949490",
    "https://openalex.org/W4379197332",
    "https://openalex.org/W4298147439"
  ],
  "abstract": "Abstract Objective: The purpose of this study is to develop a novel method for nursing clinical intelligent decision-making that integrates Large Language Models (LLMs) with local knowledge bases, aiming to enhance the accuracy and reliability of clinical decisions in nursing. Methods: Initially, we established a multi-level classified nursing knowledge base by collecting textual knowledge from public knowledge platforms and integrating selected contents from peer-reviewed nursing journals, academic papers, textbooks, and nursing standards. Subsequently, data knowledge was collected from clinical records and normalized to form a data knowledge base. Additionally, we proposed a nursing clinical decision-making system paradigm based on prompt learning in “LLMs + professional knowledge bases”, addressing the issue of catastrophic forgetting common in domain-specific question-answering systems due to the “data + fine-tuning” paradigm. Results: Utilizing the aforementioned methodology, we successfully constructed a nursing knowledge base and developed a decision-making system. The evaluation results demonstrate that this system possesses high accuracy, logical coherence, completeness, and readability in clinical nursing decisions. It enhances the convenience and efficiency of medical staff in clinical decision-making and effectively improves the applicability of LLMs in the field of nursing. Conclusion: This study validates the effectiveness of the approach that combines LLMs with local knowledge bases in nursing clinical decision-making. This method not only enhances the accuracy of decisions but also provides efficient decision support in resource-limited scenarios. In the future, this approach is expected to be applied in a broader range of nursing settings, offering new perspectives and tools for clinical nursing practice and research.",
  "full_text": "Page 1/20\nA Novel Approach to Nursing Clinical Intelligent\nDecision-Making: Integration of Large Language\nModels and Local Knowledge Bases\nLiping Xiong \nShenzhen People's Hospital\nQiqiao Zeng \nShenzhen People's Hospital\nWuhong Deng \nShenzhen People's Hospital\nWeixiang Luo \nShenzhen People's Hospital\nRonghui Liu  (  liurh@pcl.ac.cn )\nSouth China University of Technology\nResearch Article\nKeywords: Large Language Models, Nursing Knowledge Base, Nursing Clinical Decision System,\nIntelligent Decision-Making\nPosted Date: December 21st, 2023\nDOI: https://doi.org/10.21203/rs.3.rs-3756467/v1\nLicense:     This work is licensed under a Creative Commons Attribution 4.0 International License.  \nRead Full License\nAdditional Declarations: No competing interests reported.\nPage 2/20\nAbstract\nObjective: The purpose of this study is to develop a novel method for nursing clinical intelligent decision-\nmaking that integrates Large Language Models (LLMs) with local knowledge bases, aiming to enhance\nthe accuracy and reliability of clinical decisions in nursing.\nMethods: Initially, we established a multi-level classi\u0000ed nursing knowledge base by collecting textual\nknowledge from public knowledge platforms and integrating selected contents from peer-reviewed\nnursing journals, academic papers, textbooks, and nursing standards. Subsequently, data knowledge was\ncollected from clinical records and normalized to form a data knowledge base. Additionally, we proposed\na nursing clinical decision-making system paradigm based on prompt learning in “LLMs + professional\nknowledge bases”, addressing the issue of catastrophic forgetting common in domain-speci\u0000c question-\nanswering systems due to the “data + \u0000ne-tuning” paradigm.\nResults: Utilizing the aforementioned methodology, we successfully constructed a nursing knowledge\nbase and developed a decision-making system. The evaluation results demonstrate that this system\npossesses high accuracy, logical coherence, completeness, and readability in clinical nursing decisions. It\nenhances the convenience and e\u0000ciency of medical staff in clinical decision-making and effectively\nimproves the applicability of LLMs in the \u0000eld of nursing.\nConclusion: This study validates the effectiveness of the approach that combines LLMs with local\nknowledge bases in nursing clinical decision-making. This method not only enhances the accuracy of\ndecisions but also provides e\u0000cient decision support in resource-limited scenarios. In the future, this\napproach is expected to be applied in a broader range of nursing settings, offering new perspectives and\ntools for clinical nursing practice and research.\n1. Introduction\nNursing clinical decision-making is a process integral to nursing care, involving the analysis, evaluation,\nand selection of optimal nursing interventions. These decisions are based on a comprehensive\nconsideration of the patient's medical condition, physiological state, psychological needs, and social\ncontext, underpinned by a foundation of professional knowledge and experience [1]. As a core aspect of\nnursing practice, decision-making is pivotal in enhancing nursing care quality, ensuring patient safety,\nand facilitating patient recovery. However, the current landscape of nursing clinical decision systems\nconfronts several challenges: Firstly, the exponential growth of medical information often overwhelms\nhealthcare professionals, leading to the potential omission of critical details. Secondly, the evolution\ntowards personalized nursing care necessitates tailor-made care plans based on individual patient\nconditions and requirements, which can be challenging due to the limited breadth of medical knowledge\ntypically accessible to nursing staff. Thirdly, the rapid advancement in medical research and practice\nmakes it challenging for clinical decisions to stay abreast of the latest evidence and guidelines [2]. Thus,\nPage 3/20\nensuring the accuracy, practicality, and e\u0000ciency of nursing clinical decision-making remains a\nprominent research focus.\nRecent advancements in LLMs have yielded signi\u0000cant breakthroughs in various natural language\nprocessing tasks [3–4], demonstrating emergent capabilities in models such as InstructGPT [6], ChatGPT\n(https://openai.com/blog/chatgpt/), and GPT4 [7]. These autoregressive LLMs [8] have shown\npro\u0000ciency in comprehending and adhering to human instructions through sophisticated techniques like\npre-training and \u0000ne-tuning, enabling them to effectively process and respond to complex queries. Despite\ntheir remarkable performance across diverse NLP tasks and their demonstrated capacity to handle\npreviously unseen tasks, these models are not without inherent limitations. These include challenges in\nprocessing Chinese language, deployment complexities, an inability to access up-to-date information on\nrecent events, and the generation of misleading or hallucinatory facts [9]. These constraints pose\nsigni\u0000cant barriers to the direct application of LLMs in specialized domain-speci\u0000c question-answering\ncontexts. On one hand, there are formidable hardware resource requirements for large models; on the\nother, the pro\u0000ciency of LLMs in handling domain-speci\u0000c queries remains suboptimal.\nIn professional domains, outputs generated by LLMs might lack authenticity and precision, occasionally\nleading to the propagation of 'hallucinatory facts.' To augment the capacity of LLMs in addressing\ndomain-speci\u0000c queries, many initiatives have adopted data \u0000ne-tuning techniques to modify model\nparameters, thereby enhancing the models' domain-speci\u0000c pro\u0000ciency. However, literature indicates that\nsuch data \u0000ne-tuning approaches can result in catastrophic forgetting [10], thereby diminishing the\nmodel's intrinsic conversational abilities and causing disarrayed outputs when processing un-\u0000ne-tuned\ndata. Our experiments involving the input of common nursing clinical cases into ChatGPT3.5 revealed\nthat the model lacked a comprehensive understanding of the posed nursing clinical decision-making\nqueries, particularly failing to grasp the signi\u0000cance of numerical values such as 'Morse score of 60;\nBADL score of 40', thus demonstrating a shortfall in delivering expert-level responses due to a de\u0000ciency\nin nursing-speci\u0000c knowledge.\nTo mitigate these challenges, this study synergizes LLMs with nursing knowledge bases to design a\nspecialized intelligent decision system for the nursing domain. This system integrates textual and data\nknowledge from the knowledge bases with the parameterized knowledge inherent in LLMs. Such\nintegration facilitates the understanding of user semantics and the answering of domain-speci\u0000c queries\nwithout resorting to data \u0000ne-tuning. Moreover, by employing models like LLAMA-7B, which are less\ndemanding in terms of hardware resources, we effectively mitigate system constraints imposed by\nhardware requirements. Additionally, in light of the ongoing evolution in large language model technology,\na paradigm shift towards cognitive intelligence is emerging as a focal point for future research. The\neffective amalgamation of LLMs with localized knowledge represents a research avenue of considerable\ninterest. Consequently, this paper, taking inspiration from the study of nursing decision systems, delves\ndeeper into the new paradigm of \"large language model + nursing knowledge base\" for intelligent\ninformation systems. It explores the profound integration of nursing knowledge with LLMs, leveraging\ndomain-speci\u0000c expertise to enhance the outputs of LLMs and deliver precise nursing clinical decisions.\nPage 4/20\nThe primary contributions of this study are twofold:\nThe establishment of a multi-tiered, categorized nursing knowledge base addresses issues related to\nknowledge management disarray and the lack of professionalism in the nursing domain. Textual\nknowledge, sourced from public knowledge platforms and meticulously \u0000ltered content from peer-\nreviewed nursing journals, academic papers, textbooks, and nursing standards, form the textual\nknowledge base. Concurrently, data knowledge, derived from nursing clinical records and standardized\nclinical time-series data points and indicators, constitutes the data knowledge base. This knowledge base\nis then structured and categorized based on professional domains (e.g., pediatrics, geriatrics, obstetrics,\nand gynecology) and disease types, with a scoring system based on knowledge quality, ultimately\nculminating in a comprehensive and accurate nursing knowledge repository.\nThe proposition of a nursing clinical decision-making system paradigm, grounded in prompt learning with\nLLMs and professional knowledge bases, effectively addresses the issue of catastrophic forgetting\nassociated with the data + \u0000ne-tuning paradigm in domain-speci\u0000c question-answering systems. This\napproach not only enhances the professional capabilities of large models but also retains their general\nquestion-answering pro\u0000ciency. In scenarios of limited hardware resources, deploying smaller large\nmodels in professional domains achieves results comparable to or even surpassing those of larger\nmodels in specialized \u0000elds.\n2. Related Work\nSince the release of ChatGPT in December 2022, large-scale generative language models (GLMs), often\nreferred to as \"large models\" or \"big language models,\" have garnered signi\u0000cant attention in both\nacademia and the industry. This has stimulated rapid advancements in a series of arti\u0000cial general\nintelligence (AGI) technologies, including image-text generation models and embodied multimodal\nlanguage models. As a conversational large-scale language model, ChatGPT offers open-ended human-\ncomputer dialogue capabilities, demonstrating text comprehension skills and the ability to provide\naccurate question-answering services. It also exhibits strong text generation abilities, attracting a vast\nuser base in a short period. As a prominent representative of generative AI in LLMs, ChatGPT has shown\nastonishing capabilities in addressing knowledge-based questions across various domains. It has\nsuccessfully passed tests that require professional knowledge and human-like thinking, such as the\nTuring Test [11], the Wharton School of Business's MBA course test [12], the University of Minnesota's law\nexam [13], the United States Medical Licensing Examination [14], and even the technical interview for the\nposition of a Google L3-level software engineer with an average annual salary of $180,000 [15].\nSimultaneously, major technology companies and research institutions worldwide have been launching\nLLMs and applications to compete with ChatGPT. For instance, Google introduced Bard, based on the\nLaMDA and PaLM models; Anthropic, founded by former OpenAI employees, released Claude, based on a\nGPT-like model; Meta open-sourced the LLaMA model, which led to the creation of a series of derivative\nmodels, including Stanford's Alpaca, LMSYS Org (a research organization led by UC Berkeley)’s Vicuna,\nPage 5/20\nand UC Berkeley's Koala. In China, Baidu launched ERNIE Bot based on the ERNIE and PLATO series\nmodels; Alibaba unveiled Tongyi Qianwen, based on the PLUG model; iFlytek released the Xinghuo\nCognitive Large Model; and Tsinghua University open-sourced the ChatGLM-6B large language model.\nHowever, it is crucial to acknowledge that the majority of these generative large models are primarily\ndesigned for general domains. Moreover, LLMs often exhibit weaker adaptability in specialized vertical\ndomains and may produce “hallucinatory” phenomena due to the lack of su\u0000cient domain-speci\u0000c\nknowledge.\nConsidering the constraints of cost and hardware, the current dominant method in the application of\nlarge models in specialized domains still adheres to the data + \u0000ne-tuning paradigm. This involves using\ndifferent specialized datasets to \u0000ne-tune pre-trained language models, such as P-tuning [16], Ptuning v2\n[17], to acquire specialized capabilities in respective \u0000elds. This method updates a minimal number of\nparameters, thus reducing hardware requirements, although the problem of catastrophic forgetting\nassociated with \u0000ne-tuning still exists to some extent. PMC-LLaMA [18] introduces a pre-trained language\nmodel based on biomedical literature, which \u0000ne-tunes the LLaMA model to incorporate medical\nknowledge, thereby enhancing its pro\u0000ciency in the medical \u0000eld and improving its performance in\nmedical question-answering benchmarks. MedPaLM [19] focuses on the medical domain, introducing the\nMultiMedOA medical question-answering benchmark, which includes medical exams, medical research,\nand consumer health questions. It employs instruction tuning on Flan-PaLM, narrowing the gap with\nclinical practitioners in multiple aspects and demonstrating the effectiveness of instructional prompt\nadjustments. ChatDoctor [20] \u0000ne-tunes the LLaMA model with medical domain knowledge to develop a\nmedical chat model. It re\u0000nes the model using real-world dialogues from patient-doctor consultations on\nonline medical consultation websites, adding autonomous knowledge retrieval capabilities and enabling\nspeci\u0000c retrieval functions in large language models through appropriate prompts. HuaTuo (Ben Cao)[21],\na LLaMA \u0000ne-tuning model based on Chinese medical knowledge, utilizes both public and proprietary\nChinese medical databases, primarily referencing the Chinese Medical Knowledge Graph CMeKG.\nDoctorGLM [22], based on the ChatGLM-6B Chinese inter-diagnostic model, generates training data by\ncreating questions related to medical knowledge content and logic, and then prompts ChatGPT to\ngenerate responses containing medical guideline information, ensuring the accuracy of the answers.\nFrom these works, it is clear that the paradigm in specialized domains still involves \u0000ne-tuning with\nvarious data sources and model bases, and the inherent \u0000aws of \u0000ne-tuning cannot be completely\navoided. However, our approach, using specialized knowledge bases combined with large language\nmodels, can address this issue.\nIn nursing clinical decision-making research, arti\u0000cial intelligence can effectively assist nurses in clinical\ndecision-making, improving the quality and e\u0000ciency of care. For example, machine learning algorithms\ncan analyze patients' physiological parameters and medical records to predict risks and needs, thereby\nassisting nurses in creating personalized care plans [23]. Additionally, AI can be used for monitoring\npatients' vital signs, identifying abnormal situations and providing real-time alerts, as well as automating\nmedication management and reminding nurses of necessary actions [24]. Although signi\u0000cant progress\nPage 6/20\nhas been made in applying AI in nursing clinical decision-making, challenges such as underutilization of\nclinical knowledge, data privacy and security issues still exist. Most importantly, the lack of a real-time\ninteractive platform makes these technologies di\u0000cult to be directly utilized by frontline clinical staff [25].\nOur approach, using specialized knowledge bases combined with LLMs, fully utilizes nursing clinical data\nand provides an interactive interface for real-time question-answering.\n3. Research Methodology\nThis paper introduces a novel approach to nursing clinical decision-making that capitalizes on the\nexpertise of local knowledge bases and the advanced semantic understanding and text generation\ncapabilities of LLMs. This method aims to achieve intelligent, professional, and e\u0000cient decision-making\nin nursing. Crucially, both the knowledge base and the LLMs are locally deployed, ensuring the privacy\nand security of industrial data.\nThe combination of a local knowledge base with a LLM as a decision-making framework helps prevent\nthe \"hallucination\" phenomena and random fabrications often associated with large models. This\napproach ensures the reliability of decision-making solutions and reduces reliance on human experience.\nAs illustrated in Fig. 2, our research methodology primarily consists of three components: categorization\nof decision-making problems, construction of a local nursing knowledge base, and the development of a\nnursing clinical decision-making platform that integrates the local knowledge bases with LLMs.\n3.1. Decision Problem Categorization\nDecision problem categorization refers to the process of \u0000ltering information from the input text related to\nnursing clinical questions, which is essentially text classi\u0000cation. This step determines whether the\nquestion is nursing-related or not. Questions that are not related are deemed unanswerable, while related\nones are further categorized to identify the speci\u0000c department they pertain to.\nOther LLMs often generate subtle hallucinations and erroneous texts when faced with boundary or\ninterdisciplinary professional questions. While \u0000ne-tuning can endow large models with some problem\ndiscernment ability, this ability can still be confounded by questions similar to those in the \u0000ne-tuning\ndataset, leading to incorrect answers even for questions that could have been correctly addressed initially.\nTherefore, a dedicated text \u0000lter is designed to re\u0000ne information processing.\nIn professional domain Q&A, large language models do not need to answer questions outside their \u0000eld.\nTo address this, our system incorporates a text \u0000lter based on BERT (Bidirectional Encoder\nRepresentations from Transformers) to limit the range of questions answerable by the model.\nAssuming that the entire set of questions that can be input into the large model is Q, and the subset that\nthe model can answer within a speci\u0000c professional domain is R. The subset of questions that can\ngenerate professional answers is D, where it's evident that Q > R > D. Using \u0000ne-tuning to restrict the model\nwould lead to R approaching D, weakening the model's answering capability. Conversely, using a \u0000lter\nPage 7/20\ntransforms Q into R, ensuring that the questions asked fall within the domain of R. While some data\noutside R might still enter the model, our professionally enhanced Q&A system retains some general\ncapabilities, allowing for non-professionally veri\u0000ed answers to questions outside R.\nInformation \u0000ltering ensures that the system answers questions within its capability range, reducing the\nlikelihood of generating hallucinatory facts. The training process, as shown in Fig. 3, involves inputting\ntraining data into BERT and then feeding BERT's output into a fully connected layer (FCL) to obtain the\nclassi\u0000cation results for the paper. During training, only the parameters of the FCL need updating, based\non the dataset's labels.\nTypically, BERT-based text classi\u0000cation tasks use the classi\u0000cation token vector H from BERT's output,\nwith a softmax-based simple classi\u0000er to predict the probability of category labels L.\n1\nHere, W is the parameter matrix for the classi\u0000cation task, and the goal is to \u0000ne-tune all parameters in\nBERT and W by maximizing the log probability of the correct labels. This is modi\u0000ed to use the FCL to\nobtain the probability of each label:\n2\nDuring training, the input vector to the FCL has a dimension of 768, with two hidden layers of dimensions\n384 and 768, respectively, and an output dimension equal to the number of categories. In this case, a\nbinary classi\u0000cation task leads to an output dimension of 2. The label with the higher probability is\nselected as the result of the classi\u0000cation. In the \u0000eld of nursing, the classi\u0000cation result determines\nwhether a question is nursing-related. By \u0000ltering questions, the likelihood of generating hallucinatory\nfacts is reduced, and the ability to provide professional answers in conjunction with search results is\nenhanced.\n3.2. Development of the Local Nursing Knowledge Base\nThe construction phase of the local nursing knowledge base initially involves the classi\u0000cation of local\nknowledge sources into two primary categories: textual data, represented by domain-speci\u0000c literature\nand operational guidelines, and temporal data, typi\u0000ed by nursing records. The treatment of textual data\nbegins with the conversion of PDF documents into editable text formats. This process includes\nemploying regular expressions to eliminate non-essential components such as indexes, images,\nannotations, and blank spaces. Following this, a thorough data cleaning process is undertaken to\neliminate duplications, resulting in a more comprehensive text corpus. Subsequent steps include the\nremoval of irrelevant words and special symbols, informed by a stopword list, to re\u0000ne the content.\nP(L|H)=softmax(WH)\nP(L|H)=FC(H)\nPage 8/20\nAdditionally, word segmentation tools are utilized to discretize the text while maintaining the coherence of\nsentence meanings.\nFor the time-series data, the initial focus is again on data cleansing and deduplication. This is followed\nby a methodical feature extraction process, where key terms and numerical values are identi\u0000ed and\nformatted into a Python dictionary structure, adhering to a 'Name: Value Unit' format. An example from\ngeriatric data might look like: ('Admission Time': '2023.10.8'; 'Temperature': '37.1°C'; 'Blood Pressure':\n'80/120 mmHg', and so on). The culmination of this process is the integration of both data types to form\na comprehensive local knowledge base for nursing.\nAddressing the challenge of processing extensive industrial texts, it becomes imperative to segment these\ntexts into manageable blocks while ensuring semantic coherence within these blocks. In segmenting\ntexts within the local knowledge base, textual divisions are identi\u0000ed using \"\\n\\n\" and \"\\n\" markers, with a\nfocus on maintaining professional terminology and concise sentence structure. The segmentation\nprocess is con\u0000gured to create blocks with a maximum length of 256 characters, incorporating an\noverlap of up to 32 characters between blocks to preserve semantic continuity and the integrity of the\nmeaning in the segmented text chunks.\nIn the \u0000nal step, the knowledge base is methodically categorized into thirteen speci\u0000c subdomains\naligned with clinical departments, such as geriatrics, pediatrics, etc. This granular classi\u0000cation not only\nstreamlines the process of aligning decision-making queries with relevant knowledge base segments but\nalso enhances the e\u0000ciency of information retrieval. Moreover, it narrows the scope of potential decision-\nmaking responses, thereby minimizing the occurrence of erroneous or hallucinatory information\ngeneration in the decision-making process.\n3.3 Construction of the Nursing Intelligent Decision-Making\nPlatform\nSections 3.1 and 3.2 provide the foundation for decision-making questions and the corresponding local\nnursing knowledge base. The next step involves constructing an intelligent nursing decision-making\nsystem that integrates LLMs with the local knowledge base. As depicted in Fig. 4, the process begins with\nthe vectorization of decision-making question texts and knowledge base texts through Word2vec\nembeddings. Word2vec effectively maps words into a vector space by learning the semantic relationships\nbetween words, resulting in a vectorized representation of both the decision-making questions and the\nknowledge base.\nSubsequently, the generated vectorized representations are fed into Faiss (Facebook AI Similarity Search)\nfor vector database retrieval. This process identi\u0000es knowledge base content relevant to the decision-\nmaking questions, which is then concatenated to form the basis of the decision content. Finally, the\ndecision-making question and content are compiled into a prompt template, which is then input into a\nLLM to generate a coherent and accurate industrial \u0000eld decision-making plan.\nPage 9/20\nFaiss, an open-source library developed by Facebook's AI team, is employed for clustering and similarity\nsearches of dense vectors. It facilitates e\u0000cient similarity searches and clustering for up to billions of\nvectors, making it a mature library for approximate nearest neighbor searches. Once the Faiss index is\nestablished, similarity searches can be executed on the decision question vectors. We utilize the\nSymmetric Distance Computation (SDC) method to calculate the Euclidean distance between query\nvectors and candidate vectors, as illustrated in Eq. 3.\n3\nHere, qj(x) represents the quantization of the j-th sub-vector, i.e., the cluster center vector of the j-th sub-\nvector. The derived Euclidean distances help identify which texts from the knowledge base are relevant to\nthe decision-making question.\nHowever, the nursing intelligent decision-making platform established through the aforementioned\nprocess lacks a visual interface. To address this, we incorporate the LangChain framework for LLMs.\nLangChain (https://www.langchain.com/) is a robust framework designed to assist developers in\nbuilding end-to-end applications using LLMs. It supports the development and utilization of LLMs by\nproviding a suite of tools, components, and interfaces to simplify the creation of applications supported\nby LLMs or chat models. LangChain e\u0000ciently manages interactions with LLMs, linking multiple\ncomponents, and integrating additional resources. Utilizing LangChain, our designed nursing intelligent\ndecision-making system can effortlessly establish links between the knowledge base and the LLM,\ninjecting knowledge into the large language model for enhanced decision-making.\n4. Experimental results and analyses\nThis chapter provides empirical evidence for the effectiveness of the nursing intelligent decision-making\nsystem, divided into two parts: (1) an introduction to the system's visual interactive platform, and (2) a\nperformance evaluation of clinical decision-making. The foundational large language models used in this\nexperiment are LLaMA2-7B, ChatGLM2-6B, and Baichuan2-7B. The system is deployed on a local server,\nwith an environment consisting of Ubuntu 20.04 LTS, Pytorch 2.0, Python 3.8.13, langchain 0.0.344,\nCUDA Toolkit cuda11.8, and an NVIDIA GeForce RTX 3090 GPU.\n4.1 Introduction of Visual Interactive Platform\nThe nursing clinical intelligent decision-making system developed in this paper is deployed on a local\nserver. The large language model's weight \u0000les are pre-downloaded and stored on the server, and the\nentire system is encapsulated in a local Docker container. This container, accessible via its IP address,\nprovides intelligent decision-making services externally. Since the large language models are pre-\n^d(x,y)=d(q(x), q(y))=√∑\nj\nd(qj(x), qj(x))2\nPage 10/20\ndownloaded open-source \u0000les and the system operates on a local server, the privacy and security of\nnursing data are ensured. The Docker container's IP web page is only accessible via the hospital's internal\nLAN and supports concurrent services (i.e., multiple simultaneous question-and-answer sessions).\nAs illustrated in Fig. 5, the visual interactive platform of the nursing intelligent decision-making system\nfeatures two buttons at the top left: \"Decision-Making Dialogue\" and \"Knowledge Base Management.\"\n\"Dialogue\" refers to providing decision-making services through real-time question-and-answer sessions,\nwhile \"Knowledge Base Management\" allows for the online uploading of \u0000les to establish a private\nknowledge base. The \"Select Dialogue Mode\" in the middle-left part of the platform currently offers\noptions like \"LLM-based Dialogue,\" \"Knowledge Base + LLM Dialogue,\" \"Search Engine Dialogue,\" and\n\"Custom Agent Q&A,\" ensuring diverse decision-making approaches. The \"Select LLM Model\" at the\nbottom center provides options among LLaMA2-7B, ChatGLM2-6B, and Baichuan2-7B. LLaMA2-7B\nfocuses on understanding and answering English questions, while ChatGLM2-6B and Baichuan2-7B\nemphasize Chinese question understanding and answering. Selecting an LLM model caters to different\nlinguistic conditions in decision-making scenarios. On the left is the real-time Q&A platform where nurses\ncan input decision-making questions into the dialogue box and choose the appropriate dialogue model to\nreceive corresponding decision plans.\nIn terms of constructing the local nursing knowledge base, we have established a centralized knowledge\nbase management platform, as shown in Fig. 6. Medical staff can access this platform via the local area\nnetwork and use the \"Browse Files\" option to upload local documents to create their department-speci\u0000c\nknowledge base. We invited head nurses from 13 departments of our hospital, including emergency,\nintensive care, geriatrics, and obstetrics and gynecology, to extensively collect materials and establish\nknowledge bases for their respective departments. The requirement was for each knowledge base to\ncontain no fewer than 100 pieces of domain literature and at least 50 sets of clinical texts, such as\nnursing manuals. These knowledge bases were then uploaded to our nursing clinical decision-making\nsystem according to their respective departments.\n4.2 Performance Evaluation\n(1) Setting of Decision-Making Questions for Evaluation\nWe invited head nurses from six departments, including emergency, intensive care, geriatrics, and\nobstetrics, to formulate 10 relevant decision-making questions each, drawing upon real clinical nursing\nscenarios.\n(2) Evaluation Method\nGiven the inherent openness and unpredictability of LLM outputs, the same question can yield different\nanswers or be answered in various forms across multiple sessions. The randomness of these answers\nsigni\u0000cantly impacts the evaluation, hence this study involved asking each question in three different\nsessions to obtain three corresponding answers from each model.\nPage 11/20\nEighteen head nurses from departments like emergency, intensive care, geriatrics, and obstetrics were\ninvited to participate in the scoring task. They meticulously assessed each answer for accuracy and\nrelevance of the knowledge points, logic of the analysis and explanation process, completeness of the\ninformation in the answer, and readability and layout, with a full score of 100 for each criterion.\nAdditionally, each answer was summarized, highlighting its strengths and areas for improvement to\nfacilitate deeper discussion.\n(3) Evaluation Results\nAfter collecting all scores and summary descriptions, the study analyzed the answers to gauge the basic\ncapability level of the decision-making system, starting from the six prede\u0000ned departments. The\nanalysis involved calculating (a) the average scores for accuracy, logic, completeness, and readability of\nthe decision-making system's responses to each department's questions; (b) the maximum range of\naverage scores for accuracy, logic, completeness, and readability for each question within each\ndepartment. These metrics respectively re\u0000ected (1) the average performance level of the decision-\nmaking system in handling various questions, and (2) a certain degree of instability in the system's\nhandling of these questions. The statistical results are illustrated in Figs. 7 and 8.\nFigure 7 displays the average scores of the nursing clinical intelligent decision-making system in\nanswering questions from departments like pediatrics, geriatrics, ophthalmology, and oncology. The\nsystem demonstrated notable accuracy and completeness, scoring around 90 in these departments,\nindicating its effectiveness and reliability in handling questions from these \u0000elds. In contrast, the system\nscored lower in accuracy and completeness when dealing with questions from intensive care and\nemergency departments. This may be attributed to the broader and more variable clinical scenarios in\nthese departments, which possibly exceeded the coverage of the current nursing knowledge base and the\nsystem's capacity to handle complex variations. Despite these challenges, it's commendable that the\nsystem exhibited good logic and readability across all departments, largely due to the integration of LLMs\ntrained on extensive data. These models not only understand and generate coherent language structures\nbut also continually learn and optimize to effectively handle complex information and provide accurate\nanswers, particularly enhancing the logicality and readability of responses.\nData analysis from Fig. 8 indicates smaller \u0000uctuations in scores for questions related to pediatrics,\ngeriatrics, ophthalmology, and oncology, re\u0000ecting higher stability in accuracy, logic, completeness, and\nreadability. However, there were signi\u0000cant score \u0000uctuations in responses to intensive care and\nemergency department questions, suggesting variability in performance. This discrepancy may stem\nfrom the complex and dynamic clinical environments of these departments, posing greater challenges to\nthe system. Although the system excelled in most areas, this \u0000nding underscores the need for further\noptimization in handling speci\u0000c and complex clinical scenarios, adapting to the diversity and uncertainty\nof the clinical environment.\nIn summary, the nursing clinical decision-making system, integrating LLMs and a local knowledge bases,\nhas proven effective and stable in providing accurate and \u0000uent responses to real clinical nursing\nPage 12/20\nquestions.\n5. Discussion and Conclusion\nThis study successfully established a highly accurate and reliable nursing clinical intelligent decision-\nmaking system through three steps: decision problem categorization, construction of a local nursing\nknowledge base, and the development of a nursing clinical decision-making platform integrating the local\nknowledge base with large models. This system combines large language models with a local knowledge\nbase, effectively leveraging the strengths of both to provide robust support for nursing clinical decision-\nmaking.\nFirstly, by categorizing decision-making questions, we gained a better understanding of various issues in\nnursing practice, which guided the subsequent construction of the knowledge base and model\nintegration. Secondly, in building the local nursing knowledge base, we amassed a wealth of practical\nnursing knowledge and experience, enriching the information source for the decision-making system.\nLastly, the integration of the local knowledge base and large language models enabled effective support\nfor nursing clinical decision-making, enhancing both accuracy and reliability. Our results demonstrate\nthat combining advanced large language model technologies with a professional local nursing\nknowledge base signi\u0000cantly improves the e\u0000ciency and quality of nursing decisions. This hybrid\napproach not only provides diverse, multifaceted clinical nursing information but also offers customized\nrecommendations based on speci\u0000c circumstances, which is vital for improving patient care quality and\nnursing e\u0000ciency.\nLooking forward, we aim to further optimize and re\u0000ne the system. On one hand, we plan to enrich the\nlocal knowledge base with more clinical data to cover a broader range of clinical scenarios. On the other\nhand, we intend to enhance the processing capability and decision-making precision of the large\nlanguage models using more advanced algorithms. Additionally, considering the diversity and complexity\nof the medical \u0000eld, we will explore possibilities for interdisciplinary collaboration to apply the system in a\nwider range of nursing scenarios.\nUltimately, our aspiration is for this system to play a crucial role in clinical nursing, as well as support\nnursing education and research, thereby advancing the overall development of the nursing discipline and\nbetter serving patients and medical institutions.\nDeclarations\na. Ethics approval and consent to participate \nNot applicable.\nb. Consent for publication \nPage 13/20\nNot applicable.\nc. Availability of data and materials \nWe have made our code and databases openly accessible through the link:\nhttps://github.com/XiongLP208/NursingKnowledgePN .\nd. Funding \nThis research was supported by the National Natural Science Foundation of China Young Scientist Fund\n(81902751). The funding source had no role in the study design, data collection, data analysis, data\nexplanation, or manuscript writing.\ne. Authors' information (optional)\nWe are members of the Precision Nursing Research Team at Shenzhen People's Hospital in Shenzhen,\nChina. Our team is dedicated to advancing the \u0000eld of nursing through innovative research and\ndevelopment in digital healthcare and virtual health care. Our primary areas of focus include the\ndigitization of nursing practices and the application of virtual technologies to improve patient outcomes\nand enhance the quality of care.\nAs a team, we are committed to exploring new frontiers in nursing research and translating our \u0000ndings\ninto practical solutions that bene\u0000t patients, healthcare providers, and the broader community. We believe\nthat by leveraging the power of technology and data analytics, we can create more personalized, e\u0000cient,\nand effective healthcare experiences for all.\nReferences\n1. Ho KF, Chou PH, Chung MH. Comparison of nursing diagnostic accuracy when aided by Knowledge-\nBased Clinical Decision Support Systems with Clinical Diagnostic Validity and Bayesian Decision\nModels for psychiatric care plan formulation among nursing students: a quasi-experimental study.\nBMC Nurs. 2023;22(1):142. Published 2023 Apr 27. doi:10.1186/s12912-023-01292-y.\n2. Seibert K, Domhoff D, Bruch D, et al. Application Scenarios for Arti\u0000cial Intelligence in Nursing Care:\nRapid Review. J Med Internet Res. 2021;23(11):e26522. Published 2021 Nov 29. doi:10.2196/26522.\n3. Guu K, Lee K, Tung Z, et al. Retrieval augmented language model pre-training[C]//International\nconference on machine learning. PMLR, 2020: 3929-3938.\n4. Chowdhery A, Narang S, Devlin J, et al. Palm: Scaling language modeling with pathways[J]. Journal\nof Machine Learning Research, 2023, 24(240): 1-113.\n5. Wei J, Tay Y, Bommasani R, et al. Emergent abilities of large language models[J]. arXiv preprint\narXiv:2206.07682, 2022.\n\u0000. Ouyang L, Wu J, Jiang X, et al. Training language models to follow instructions with human\nfeedback[J]. Advances in Neural Information Processing Systems, 2022, 35: 27730-27744.\nPage 14/20\n7. Koubaa A. GPT-4 vs. GPT-3.5: A concise showdown[J]. 2023.\n\u0000. Wang Y, Kordi Y, Mishra S, et al. Self-instruct: Aligning language model with self generated\ninstructions[J]. arXiv preprint arXiv:2212.10560, 2022.\n9. Maynez J, Narayan S, Bohnet B, et al. On faithfulness and factuality in abstractive summarization[J].\narXiv preprint arXiv:2005.00661, 2020.\n10. Toneva M, Sordoni A, Combes R T, et al. An empirical study of example forgetting during deep neural\nnetwork learning[J]. arXiv preprint arXiv:1812.05159, 2018.\n11. Yalalov D. ChatGPT Passes the Turing Test[EB/OL]. [2023-04-06]. https://mpost.io/chatgptpasses-\nthe-turing-test/.\n12. Terwiesch C. Would chat GPT3 get a Wharton MBA[J]. A prediction based on its performance in the\noperations management course. Wharton: Mack Institute for Innovation Management/University of\nPennsylvania/School Wharton, 2023.\n13. Choi J H, Hickman K E, Monahan A, et al. Chatgpt goes to law school[J]. Available at SSRN, 2023.\n14. Kung T H, Cheatham M, Medenilla A, et al. Performance of ChatGPT on USMLE: Potential for AI-\nassisted medical education using large language models[J]. PLoS digital health, 2023, 2(2):\ne0000198.\n15. Dreibelbis E. ChatGPT Passes Google Coding Interview for Level 3 Engineer With $183 K Salary[J].\n2023.\n1\u0000. Liu X, Zheng Y, Du Z, et al. GPT understands, too[J]. AI Open, 2023.\n17. Liu X, Ji K, Fu Y, et al. P-tuning v2: Prompt tuning can be comparable to \u0000ne-tuning universally across\nscales and tasks[J]. arXiv preprint arXiv:2110.07602, 2021.\n1\u0000. Wu C, Zhang X, Zhang Y, et al. Pmc-llama: Further \u0000netuning llama on medical papers[J]. arXiv\npreprint arXiv:2304.14454, 2023.\n19. Singhal K, Azizi S, Tu T, et al. Large language models encode clinical knowledge[J]. Nature, 2023,\n620(7972): 172-180.\n20. Yunxiang L, Zihan L, Kai Z, et al. Chatdoctor: A medical chat model \u0000ne-tuned on llama model using\nmedical domain knowledge[J]. arXiv preprint arXiv:2303.14070, 2023.\n21. Wang H, Liu C, Xi N, et al. Huatuo: Tuning llama model with chinese medical knowledge[J]. arXiv\npreprint arXiv:2304.06975, 2023.\n22. Xiong H, Wang S, Zhu Y, et al. Doctorglm: Fine-tuning your chinese doctor is not a herculean task[J].\narXiv preprint arXiv:2304.01097, 2023.\n23. O'Connor S, Yan Y, Thilo FJS, Felzmann H, Dowding D, Lee JJ. Arti\u0000cial intelligence in nursing and\nmidwifery: A systematic review. J Clin Nurs. 2023;32(13-14):2951-2968. doi:10.1111/jocn.16478\n24. Irwin P, Jones D, Fealy S. What is ChatGPT and what do we do with it? Implications of the age of AI\nfor nursing and midwifery practice and education: An editorial. Nurse Educ Today. 2023;127:105835.\ndoi:10.1016/j.nedt.2023.105835\nPage 15/20\n25. Kwak Y, Ahn JW, Seo YH. In\u0000uence of AI ethics awareness, attitude, anxiety, and self-e\u0000cacy on\nnursing students' behavioral intentions. BMC Nurs. 2022;21(1):267. Published 2022 Sep 30.\ndoi:10.1186/s12912-022-01048-0\n2\u0000. Devlin J, Chang M W, Lee K, et al. Bert: Pre-training of deep bidirectional transformers for language\nunderstanding[J]. arXiv preprint arXiv:1810.04805, 2018.\nFigures\nFigure 1\nLacking of nursing expertise makes it di\u0000cult for ChatGPT to give a response with professional depth\nFigure 2\nOverview of the Research Methodology\nPage 16/20\nFigure 3\nAlgorithm for classi\u0000cation of decision problems\nFigure 4\nNursing Clinical Intelligent Decision Making System Construction Process\nPage 17/20\nFigure 5\nNursing Clinical Intelligent Decision System Interaction Platform\nPage 18/20\nFigure 6\nNursing Clinical Knowledge Base Management Platform\nPage 19/20\nFigure 7\nMean scores for the Nursing Clinical Intelligence Decision System answering questions in each\ndepartment\n\nPage 20/20\nFigure 8\nMaximum score gradation for the Nursing Clinical Intelligent Decision System answering the questions\nfor each department",
  "topic": "Readability",
  "concepts": [
    {
      "name": "Readability",
      "score": 0.5968604683876038
    },
    {
      "name": "Knowledge base",
      "score": 0.5645474791526794
    },
    {
      "name": "Computer science",
      "score": 0.46211838722229004
    },
    {
      "name": "Clinical decision support system",
      "score": 0.4147527813911438
    },
    {
      "name": "Nursing",
      "score": 0.4037943482398987
    },
    {
      "name": "Knowledge management",
      "score": 0.38885438442230225
    },
    {
      "name": "Decision support system",
      "score": 0.3657833933830261
    },
    {
      "name": "Medicine",
      "score": 0.2730717062950134
    },
    {
      "name": "Artificial intelligence",
      "score": 0.264583945274353
    },
    {
      "name": "Programming language",
      "score": 0.0
    }
  ]
}