{
  "title": "Encoder-Decoder Models Can Benefit from Pre-trained Masked Language Models in Grammatical Error Correction",
  "url": "https://openalex.org/W3113146152",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A2000996583",
      "name": "Masahiro Kaneko",
      "affiliations": [
        "Tokyo Metropolitan University",
        "RIKEN"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2970294904",
    "https://openalex.org/W2970429618",
    "https://openalex.org/W2970868759",
    "https://openalex.org/W2741494657",
    "https://openalex.org/W2950737607",
    "https://openalex.org/W2153013403",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2948335087",
    "https://openalex.org/W2970592413",
    "https://openalex.org/W3035010485",
    "https://openalex.org/W2971332944",
    "https://openalex.org/W2970521905",
    "https://openalex.org/W6759455113",
    "https://openalex.org/W2936597270",
    "https://openalex.org/W2589277916",
    "https://openalex.org/W2098297786",
    "https://openalex.org/W3037230882",
    "https://openalex.org/W2803237843",
    "https://openalex.org/W2963881719",
    "https://openalex.org/W2994928925"
  ],
  "abstract": "This paper investigates how to effectively incorporate a pre-trained masked language model (MLM), such as BERT, into an encoder-decoder (EncDec) model for grammatical error correction (GEC). The answer to this question is not as straightforward as one might expect because the previous common methods for incorporating a MLM into an EncDec model have potential drawbacks when applied to GEC. For example, the distribution of the inputs to a GEC model can be considerably different (erroneous, clumsy, etc.) from that of the corpora used for pre-training MLMs; however, this issue is not addressed in the previous methods. Our experiments show that our proposed method, where we first fine-tune a MLM with a given GEC corpus and then use the output of the fine-tuned MLM as additional features in the GEC model, maximizes the benefit of the MLM. The best-performing model achieves state-of-the-art performances on the BEA-2019 and CoNLL-2014 benchmarks. Our code is publicly available at: https://github.com/kanekomasahiro/bert-gec.",
  "full_text": "IA0235_12kaneko (2020-08-19 14:47)\nࣄه\nΘͤͨ\nΓగਖ਼Ϟσϧ\n߂†,††\n1 ͸͡Ίʹ\nͰ͸ ACL2020୒͞Εͨ “Encoder-Decoder Models Can Beneﬁt from Pre-trained\nMasked Language Models in Grammatical Error Correction” (Kaneko, Mita, Kiyono, Suzuki,\nand Inui 2020)ͬͯ\n͸2019 ೥11Ͱ͋Δɽ\n2ܠ\nΓగਖ਼ (Grammatical Error Correction: GEC)ʹ\n͏ɽGECจʣ͕ೖྗͱͯ͠༩͑ΒΕɼ\nจ๏తʹਖ਼͍͠จʢਖ਼จʣʹగਖ਼͢ΔλεΫͰ͋ΔɽGECज़͸Grammarly1ޠݴ\n֎Ͱ͸ACL2019 ͷซઃϫʔΫγϣοϓ\nʹ͓͍ͯ24௨λεΫ2େձ2020 ʹ͓͍\nͯ13ΘΕΔͳͲɼ͜͜਺೥GEC͍ͤͯΔɽ\n೥ͷ GEC੒͠ GEC Ϟσϧ\nश͢Δख๏͕ओྲྀͱͳ͍ͬͯΔɽҰൠతʹ GECशʹ༻͍ΒΕ͍ͯΔσʔλ͸ 100 ສ\nతʹగਖ਼ੑೳΛվળ͢Δ͜\nͱ͕ՄೳͱͳΔɽGEC͸େ͖͘෼͚ͯ2 ͭ͋Δɽ(1)ٯ\nσʔλΛੜ੒͢Δख๏ (Xie, Genthial,\nXie, Ng, and Jurafsky 2018; Kiyono, Suzuki, Mita, Mizumoto, and Inui 2019) ΍ (2)আɼૠ\n੒͢Δख๏(Zhao, Wang, Shen, Jia,\nand Liu 2019; Grundkiewicz, Junczys-Dowmunt, and Heaﬁeld 2019; Takahashi, Katsumata, and\nKomachi 2020)श͢Δ͜ͱ\n†ֶ\n††ॴ\n1 https://www.grammarly.com/\n2 https://www.cl.cam.ac.uk/research/nl/bea2019st/\nIA0235_12kaneko (2020-08-19 14:47)\nॲཧɹ Vol. 27 No. 3 September 2020\nͰ͋Δ͜ͱ͕Θ͔͍ͬͯΔ (Kiyono et al. 2019) ɽ\nͱͯ͠ଞʹ΋ɼBERT (Devlin, Chang, Lee, and Toutanova 2019)\nϞσϧ (Masked Language Model: MLM)͏ख๏͕\nఏҊ͞Ε͍ͯΔɽMLM͏ख๏ (Kaneko, Hotate, Katsumata, and\nKomachi 2019; Chollampatt, Wang, and Ng 2019)લʹ MLM ʹΑΓਖ਼จΛϑΟϧλϦϯά\n͢Δख๏ (Asano, Mita, Mizumoto, and Suzuki 2019) ΍ MLMମΛ GEC Ϟσϧͱͯ͠༻͍\nڀݚKantor, Katz, Choshen, Cohen-Karlik, Liberman, Toledo, Menczel, and Slonim 2019;\nAwasthi, Sarawagi, Goyal, Ghosh, and Piratla 2019) ͳͲ͕͋Δɽ\n3Γగਖ਼\n͜ͷষ͔ΒACL2020Ͱ͸GEC ʹ͓͚\nश͞Εͨ MLMͬͨɽMLMྻ\nͰ͸ MLM\nλ\nΛऩΊ͍ͯΔɽGEC࠷\nԽϞσϧʹΑΓୡ੒͞Ε͍ͯΔ(Lichtarge, Alberti, Kumar,\nShazeer, Parmar, and Tong 2019; Kiyono et al. 2019)ʹরΒͯ͠ɼGECԽ෮\nλεΫͱಉ༷ʹ MLMΛड͚Δ͜ͱ͕Ͱ͖Δͷ͔ʁͱ͍͏ 1\n໰͕ੜ͡ΔɽGECΓ΍ྲྀெͰ͸ͳ͍ද\n·Ε͍ͯΔɽMLMश͞Ε͍ͯΔ\nଘख๏Λͦͷ··దԠ͠GEC Ͱ͏·͍͔͘͘͸໌Β͔Ͱ͸ͳ͍ɽ\nMLMԽख๏(init) ͱૉੑख๏ (fuse)\nͷ2 ͕ͭ͋Δɽinit:श͞ΕͨMLMԽ͠ɼର\n৅λεΫͷσʔλͰϑΝΠϯνϡʔχϯά͢Δ (Lample and Conneau 2019) ɽ͜ͷख๏ͷ໰୊\n఺͸ɼGECԽ͞Εͨ৘\n༻͢Δ͜ͱ͕Ͱ͖ͳ͍Մ\nೳੑ͕͋Δ͜ͱͰ͋Δɽͦͯ͠ɼ͜ͷख๏͸ 2शख๏ͱ\nԽ͢Δඞཁ͕͋ΔͨΊซ༻Ͱ͖ͳ͍ɽfuse:จΛೖྗͱ͢Δ MLM ͷग़ྗΛ௥\nԽϞσϧʹ༩͑Δ (Zhu, Xia, Wu, He, Qin, Zhou, Li,\nand Liu 2020) ɽ͜ͷख๏͸init ͱ͸ҧ͍MLMश͞Εͨ৘ใ\n͸ൃੜ͠ͳ͍ɽҰํͰɼMLMΓ΍ඇྲྀெͳς\nΩετͳͲͷGECྀ͢Δ͜ͱ͕Ͱ͖ͳ͍͜ͱ͕໰୊Ͱ͋Δɽ\nग़͢Δ\n684\nIA0235_12kaneko (2020-08-19 14:47)\nΓగਖ਼Ϟσϧ\nग़ (Grammatical Error Detection: GED) λεΫʹΑΓϑΝΠϯνϡʔχϯά͞Ε\nͨMLM Λ༻͍Δૉੑख๏(fuse GED) ΛఏҊͨ͠ɽfuse GEDश͞ΕͨMLM Λ\nGED ͰϑΝΠϯνϡʔχϯά͢Δɽͦͯ͠ɼGED ͰϑΝΠϯνϡʔχϯά͞Εͨ MLM ͷग़\nྗΛfuse ख๏ͱಉ͡Α͏ʹૉੑͱͯ͠༻͍ΔɽGED ͸GECΓ΍ྲྀ\nश͢Δ͜ͱ͕Ͱ͖Δɽ͞ΒʹɼGEDྻϥϕϦϯάλεΫͰ͋Δͨ\n͜͢Մೳੑ͕௿͍ɽͦͯ͠ɼ\nश͞ΕͨGEC Ϟσϧͱซ༻͢Δ͜ͱ͕ՄೳͰ͋Δɽ\n4Ռ\nද1ଘख๏ͱఏҊख๏ͷGEC͍ͯ͠ΔɽMLM ͱͯ͠BERT\n(Devlin et al. 2019)शɾ։ൃσʔλͱͯ͠ BEA σʔλ (Bryant,\nFelice, Andersen, and Briscoe 2019) Λ༻͍ͨɽධՁσʔλͱͯ͠BEA-test, CoNLL-14 (Ng, Wu,\nBriscoe, Hadiwinoto, Susanto, and Bryant 2014) ͱ JFLEG (Napoles, Sakaguchi, and Tetreault\n2017)ඪͱͯ͠͸ ERRANT (Bryant, Felice, and Briscoe 2017), M 2 (Dahlmeier\nand Ng 2012) ͱ GLEU (Napoles, Sakaguchi, Post, and Tetreault 2015) Λ༻͍ͨɽ1 ͭ໨ͷά\nՌɼ2σʔλΛ༻͍ͨ୯\nՌɼ3ՌͰ͋Δɽ\n·ͣɼ1σʔλΛ༻͍ͳ͍άϧʔϓͰ͸ɼMLM Λ༻͍ΔͲͷख๏΋MLMΘ\nͯ͠ੑೳ͕େ෯ʹվળ͞Ε͍ͯΔɽಛʹఏҊख๏Ͱ͋Δ BERT-fuse GED ͸શ\nද 1Ϟσϧͷ GECՌ\nBEA-test (ERRANT) CoNLL-14 (M 2) JFLEG\nP R F 0.5 P R F 0.5 GLEU\nw/o BERT 51.5 43.2 49.6 59.2 31.2 50.2 52.7\nBERT-init 55.1 43.7 52.4 61.3 31.5 51.4 53.0\nBERT-fuse 57.5 44.9 54.4 62.3 31.3 52.0 54.1\nBERT-fuse GED 58.1 44.8 54.8 63.6 33.0 53.6 54.4\nw/o BERT 66.1 59.9 64.8 68.5 44.8 61.9 61.0\nBERT-fuse 66.6 60.0 65.2 68.3 45.7 62.1 61.2\nBERT-fuse GED 67.1 60.1 65.6 69.2 45.6 62.6 61.3\nLichtarge et al. 2019 — — — 65.5 37.1 56.8 61.6\nKiyono et al. 2019 65.5 59.4 64.2 67.9 44.1 61.3 59.7\nBERT-fuse GED + R2L 72.3 61.4 69.8 72.6 46.4 65.2 62.0\nLichtarge et al. 2019 — — — 66.7 43.9 60.4 63.3\nKiyono et al. 2019 74.7 56.7 70.2 72.4 46.1 65.0 61.4\n͍ͯ͠Δɽ (Kaneko et al. 2020)\n685\nIA0235_12kaneko (2020-08-19 14:47)\nॲཧɹ Vol. 27 No. 3 September 2020\n͍ͯ͠Δɽ2σʔλΛ༻\nͰ΋ MLM্͢Δ͜ͱ͕Θ͔Δɽͦͯ͠ɼ୯ҰϞσϧ\nͰBEA-test ͱCoNLL-14 ͷ2ਫ਼౓Λୡ੒͍ͯ͠Δɽ3 ͭ໨ͷάϧʔϓͰ͸\n͏͜ͱͰCoNLL-14ਫ਼౓Λୡ੒͍ͯ͠Δɽ͜Ε\nՌ͔ΒɼGEC ʹ͓͍ͯMLMͰ͋ΓɼಛʹGEC ͷαϒλεΫͰ͋Δ\nGEDՌతʹMLM༻Ͱ͖Δ͜ͱΛ໌Β͔ʹͨ͠ɽ\n5 ͓ΘΓʹ\nͰ͸MLM ΛGECΘͤΔख๏ΛఏҊ͠ACL2020୒\nͬͨɽ\nݙ\nAsano, H., Mita, M., Mizumoto, T., and Suzuki, J. (2019). “The AIP-Tohoku System at the\nBEA-2019 Shared Task.” In BEA, pp. 176–182.\nAwasthi, A., Sarawagi, S., Goyal, R., Ghosh, S., and Piratla, V. (2019). “Parallel Iterative Edit\nModels for Local Sequence Transduction.” In EMNLP-IJCNLP, pp. 4260–4270.\nBryant, C., Felice, M., Andersen, Ø. E., and Briscoe, T. (2019). “The BEA-2019 Shared Task on\nGrammatical Error Correction.” In BEA, pp. 52–75.\nBryant, C., Felice, M., and Briscoe, T. (2017). “Automatic Annotation and Evaluation of Error\nTypes for Grammatical Error Correction.” In ACL, pp. 793–805.\nChollampatt, S., Wang, W., and Ng, H. T. (2019). “Cross-Sentence Grammatical Error Correc-\ntion.” In ACL, pp. 435–445.\nDahlmeier, D. and Ng, H. T. (2012). “Better Evaluation for Grammatical Error Correction.” In\nNAACL, pp. 568–572.\nDevlin, J., Chang, M., Lee, K., and Toutanova, K. (2019). “BERT: Pre-training of Deep Bidi-\nrectional Transformers for Language Understanding.” In NAACL, pp. 4171–4186.\nGrundkiewicz, R., Junczys-Dowmunt, M., and Heaﬁeld, K. (2019). “Neural Grammatical Er-\nror Correction Systems with Unsupervised Pre-training on Synthetic Data.” In BEA,\npp. 252–263.\nKaneko, M., Hotate, K., Katsumata, S., and Komachi, M. (2019). “TMU Transformer System\nUsing BERT for Re-ranking at BEA 2019 Grammatical Error Correction on Restricted\nTrack.” In BEA, pp. 207–212.\n686\nIA0235_12kaneko (2020-08-19 14:47)\nΓగਖ਼Ϟσϧ\nKaneko, M., Mita, M., Kiyono, S., Suzuki, J., and Inui, K. (2020). “Encoder-Decoder Models\nCan Beneﬁt from Pre-trained Masked Language Models in Grammatical Error Correction.”\nIn ACL, pp. 4248–4254.\nKantor, Y., Katz, Y., Choshen, L., Cohen-Karlik, E., Liberman, N., Toledo, A., Menczel, A.,\nand Slonim, N. (2019). “Learning to combine Grammatical Error Corrections.” In BEA,\npp. 139–148.\nKiyono, S., Suzuki, J., Mita, M., Mizumoto, T., and Inui, K. (2019). “An Empirical Study\nof Incorporating Pseudo Data into Grammatical Error Correction.” In EMNLP-IJCNLP,\npp. 1236–1242.\nLample, G. and Conneau, A. (2019). “Cross-lingual Language Model Pretraining.” In NeurIPS,\npp. 7059–7069.\nLichtarge, J., Alberti, C., Kumar, S., Shazeer, N., Parmar, N., and Tong, S. (2019). “Corpora\nGeneration for Grammatical Error Correction.” In NAACL, pp. 3291–3301.\nNapoles, C., Sakaguchi, K., Post, M., and Tetreault, J. (2015). “Ground Truth for Grammatical\nError Correction Metrics.” In NAACL, pp. 588–593.\nNapoles, C., Sakaguchi, K., and Tetreault, J. (2017). “JFLEG: A Fluency Corpus and Benchmark\nfor Grammatical Error Correction.” In EACL, pp. 229–234.\nNg, H. T., Wu, S. M., Briscoe, T., Hadiwinoto, C., Susanto, R. H., and Bryant, C. (2014). “The\nCoNLL-2014 Shared Task on Grammatical Error Correction.” In CoNLL, pp. 1–14.\nTakahashi, Y., Katsumata, S., and Komachi, M. (2020). “Grammatical Error Correction Using\nPseudo Learner Corpus Considering Learner’s Error Tendency.” In ACL SRW, pp. 27–32.\nXie, Z., Genthial, G., Xie, S., Ng, A., and Jurafsky, D. (2018). “Noising and Denoising Natural\nLanguage: Diverse Backtranslation for Grammar Correction.” In NAACL, pp. 619–628.\nZhao, W., Wang, L., Shen, K., Jia, R., and Liu, J. (2019). “Improving Grammatical Error\nCorrection via Pre-Training a Copy-Augmented Architecture with Unlabeled Data.” In\nNAACL, pp. 156–165.\nZhu, J., Xia, Y., Wu, L., He, D., Qin, T., Zhou, W., Li, H., and Liu, T. (2020). “Incorporating\nBERT into Neural Machine Translation.” In ICLR.\nུྺ\nɹ߂ɿ2016ɽ 2018 ೥ट\n՝ఔमྃɽಉ\nࡏݱ\nΔɽ\n687",
  "topic": "Encoder",
  "concepts": [
    {
      "name": "Encoder",
      "score": 0.7826326489448547
    },
    {
      "name": "Computer science",
      "score": 0.6781169176101685
    },
    {
      "name": "Error detection and correction",
      "score": 0.4198746681213379
    },
    {
      "name": "Speech recognition",
      "score": 0.41340363025665283
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3911522328853607
    },
    {
      "name": "Natural language processing",
      "score": 0.3894878029823303
    },
    {
      "name": "Algorithm",
      "score": 0.18837970495224
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ]
}