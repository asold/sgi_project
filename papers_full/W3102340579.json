{
  "title": "On the Branching Bias of Syntax Extracted from Pre-trained Language Models",
  "url": "https://openalex.org/W3102340579",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A5101425369",
      "name": "Huayang Li",
      "affiliations": [
        "Tencent (China)"
      ]
    },
    {
      "id": "https://openalex.org/A5005411806",
      "name": "Lemao Liu",
      "affiliations": [
        "Tencent (China)"
      ]
    },
    {
      "id": "https://openalex.org/A5089546589",
      "name": "Guoping Huang",
      "affiliations": [
        "Tencent (China)"
      ]
    },
    {
      "id": "https://openalex.org/A5087920747",
      "name": "Shuming Shi",
      "affiliations": [
        "Tencent (China)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2963411763",
    "https://openalex.org/W2995856824",
    "https://openalex.org/W4289373464",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2972342261",
    "https://openalex.org/W2980282514",
    "https://openalex.org/W2972324944",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2946359678",
    "https://openalex.org/W2251088156",
    "https://openalex.org/W3004117589",
    "https://openalex.org/W2912206855",
    "https://openalex.org/W2973723395",
    "https://openalex.org/W2948947170",
    "https://openalex.org/W2962832505",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2962739339",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4299838440",
    "https://openalex.org/W2493000960",
    "https://openalex.org/W2096204319",
    "https://openalex.org/W1632114991",
    "https://openalex.org/W4288351520",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W4288104054",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W3034503989"
  ],
  "abstract": "Many efforts have been devoted to extracting constituency trees from pre-trained language models, often proceeding in two stages: feature definition and parsing. However, this kind of methods may suffer from the branching bias issue, which will inflate the performances on languages with the same branch it biases to. In this work, we propose quantitatively measuring the branching bias by comparing the performance gap on a language and its reversed language, which is agnostic to both language models and extracting methods. Furthermore, we analyze the impacts of three factors on the branching bias, namely feature definitions, parsing algorithms, and language models. Experiments show that several existing works exhibit branching biases, and some implementations of these three factors can introduce the branching bias.",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 4473–4478\nNovember 16 - 20, 2020.c⃝2020 Association for Computational Linguistics\n4473\nOn the Branching Bias of Syntax\nExtracted from Pre-trained Language Models\nHuayang Li Lemao Liu Guoping Huang Shuming Shi\nTencent AI Lab\n{alanili,redmondliu,donkeyhuang,shumingshi}@tencent.com\nAbstract\nMany efforts have been devoted to extracting\nconstituency trees from pre-trained language\nmodels, often proceeding in two stages: fea-\nture deﬁnition and parsing. However, this kind\nof methods may suffer from the branching bias\nissue, which will inﬂate the performances on\nlanguages with the same branch it biases to. In\nthis work, we propose quantitatively measur-\ning the branching bias by comparing the per-\nformance gap on a language and its reversed\nlanguage, which is agnostic to both language\nmodels and extracting methods. Furthermore,\nwe analyze the impacts of three factors on\nthe branching bias, namely parsing algorithms,\nfeature deﬁnitions, and language models. Ex-\nperiments show that several existing works ex-\nhibit branching biases, and some implementa-\ntions of these three factors can introduce the\nbranching bias.\n1 Introduction\nNeural language models such as LSTM (Merity\net al., 2018; Peters et al., 2018), GPT2 (Radford\net al., 2019), and BERT (Devlin et al., 2019; Liu\net al., 2019) have achieved state-of-the-art perfor-\nmance in various downstream NLP tasks. Many\nrecent works try to interpret their success by reveal-\ning the linguistic properties captured by these lan-\nguage models (Hewitt and Manning, 2019; Clark\net al., 2019; Jawahar et al., 2019; Tenney et al.,\n2019). One interesting line of these works tries to\nextract discrete constituency trees from pre-trained\nlanguage models (Mareˇcek and Rosa, 2018, 2019;\nKim et al., 2020; Wu et al., 2020). The core of these\nworks is to extract syntax in two stages. Firstly,\nit deﬁnes the feature scores based on a language\nmodel, namely, the feature deﬁnition stage. Sec-\nondly, it leverages the feature scores to build a\nconstituency tree, namely, the parsing stage.\nHowever, the degree to which the extracted con-\nstituency trees match gold constituency annotations\nThe test maycometoday\nThetestmaycometoday\nFigure 1: Constituency trees of a right-branching lan-\nguage and its reversed (left-branching) language. The\ntree at the bottom is obtained by reversing the tree at\nthe top.\nmay imprecisely reﬂect the model’s competence\nof capturing syntax, since their ﬁnal performance\nmay beneﬁt from the branching bias. For exam-\nple, as pointed out by Dyer et al. (2019), the syn-\ntax extracted from the ordered neuron based lan-\nguage model (Shen et al., 2019) is biased to right-\nbranching languages 1 (e.g., English). Nevertheless,\nthe approach to measuring the bias in Dyer et al.\n(2019) is highly dependent on the architecture of\nordered neuron and its parsing algorithm. There-\nfore, it is far from trivial to be applied to general\npre-trained language models.\nThis paper proposes a new approach to reveal the\nbranching bias of syntax from pre-trained language\nmodels, which is agnostic to model architectures\nand parsing algorithms. The key idea of our ap-\nproach is based on the following observation: We\ncan construct a left-branching language by revers-\ning a right-branching language and vice versa. An\nillustration is given in Figure 1. If a syntax ex-\ntracting method has no branching bias, the parsing\nperformances on the original language and the re-\n1Right-branching language is considered to be head-initial,\nwhich means the head (e.g., the verb is the head in a verb\nphrase) always precedes its complements. In contrast, left-\nbranching language is head-ﬁnal, where the head follows its\ncomplements (Kiparsky, 1996; Kroch, 2001).\n4474\nversed language should have little or no difference.\nTherefore, the performance gap can be used as an\nindicator of branching bias. Using our approach,\nwe ﬁnd that some recent works on pre-trained lan-\nguage models suffer from the branching bias (Kim\net al., 2020; Wu et al., 2020; Mare ˇcek and Rosa,\n2018). We further investigate on an in-depth ques-\ntion: Does the bias come from language models?\nOr the extraction methods (feature deﬁnition and\nparsing algorithm)? We propose a simple approach\nto quantitatively analyze the bias in them, which\ntries to control the impacts of other factors while\nstudying a speciﬁc part in the pipeline.\n2 Methodology\n2.1 Measuring branching bias\nIntuitively, branching bias means that the induced\nsyntax tends a speciﬁc branching structure, such\nas the right-branching in Shen et al. (2019), as\npointed out by Dyer et al. (2019). For example, a\nright-branching bias will exaggerate the method’s\nperformance on a right-branching language and\nundermine its performance on a left-branching lan-\nguage. Therefore, a natural way to quantify the\nbranching bias in syntax is to compare the perfor-\nmance gap between two natural languages with\ndifferent branches (e.g., English and Japanese).\nUnfortunately, due to the intrinsic differences be-\ntween the two natural languages, it may be unfair\nto compare their performances directly. Therefore,\nfor a language L, we build a synthetic language L′\nby reversing the word order in the way of right-to-\nleft, rather than the left-to-right order in language\nL. If language L is right-branching, then language\nL′ will be left-branching, as shown in Figure 1.\nBased on this observation, we use a natural lan-\nguage L and a synthetic language L′ to measure\nthe performance gap.\nMore concretely, the performance gap between\nlanguage L and L′, namely the branching gap, is\ndeﬁned as follows:\nB = m(t, g) −m(t′, g′), (1)\nwhere m is a metric function to measure the quality\nof the parsing tree (e.g., f1-score); t is a tree ex-\ntracted by a syntax extracting method on language\nL, and g is its golden truth; t′ and g′ are deﬁned\nsimilarly but on the reversed language L′. To make\nthe comparison in Eq.(1) fairer, we guarantee that\ntraining and testing datasets for both languages are\nthe same except for the word order.\nIf a syntax extracting method is unbiased, the\nbranching gap would be nearly 0. 2 The sign of\nindicates the direction of the branching bias. It is\nworth noting that the proposed approach to measure\nbranching bias is independent of the model archi-\ntecture and the syntax extracting method, unlike\nthe approach used in Dyer et al. (2019). There-\nfore, our approach can be naturally applied to any\npre-trained language models and syntax extracting\nmethods. Besides, Dyer et al. (2019) mainly focus\non the branching bias in a speciﬁc parsing algo-\nrithm (Shen et al., 2019). In our work, we further\nanalyze the branching bias in feature deﬁnitions\nand language models, besides parsing algorithms.\n2.2 Factors affecting branching bias\nSince constituency trees are extracted from a pre-\ntrained language model using a syntax extracting\nmethod, the branching bias may owe to both the\nsyntax extracting method and the language model.\nMore precisely, the branching bias may be affected\nby parsing algorithms, deﬁnitions of feature scores,\nand language models. In the rest of this section, we\nwill investigate the branching bias in each of the\nthree factors one-by-one.\nBias in parsing algorithm Since the parsing al-\ngorithm is on the top of the language model and\nfeature deﬁnition, To analyze the bias in a parsing\nalgorithm alone, we need to exclude the inﬂuences\nof these two factors. To this end, we propose to\nassign a sequence of random scores as the feature\nscores and then run the parsing algorithm using\nthese random scores to obtain the constituency tree.\nThe random feature scores are generated accord-\ning to a uniform distribution 3. Since the feature\nscores are independent of both the language model\nand the feature deﬁnition, the branching bias can\nbe introduced solely by the parsing algorithm if a\nnoticeable branching gap is observed.\nBias in feature deﬁnition Feature deﬁnition is\nthe type of information (e.g., hidden vectors or at-\ntention matrix) from a language model, converted\ninto feature scores, and then fed into a parsing al-\ngorithm. Some feature deﬁnitions may also intrin-\nsically contain branching bias. To reveal the bias\nsolely dependent on a speciﬁc feature deﬁnition,\ninstead of using the original weights (e.g., hidden\n2Though we deﬁned the branching gap on the sentence\nlevel, it can be easily applied to the corpus level.\n3For feature scores that need to be normalized, and we will\nassign the random value before the normalizing operation.\n4475\n# Syntax Extracting Method Model Parsing Alg. L L′ Gap\n1 (Mareˇcek and Rosa, 2018) BERT ATTN SPAN 27.81 29.60 −1.79\n2 GPT2 ATTN SPAN 27.90 23.49 +4.41\n3 (Kim et al., 2020) BERT DIST 24.93 25.23 −0.30\n4 GPT2 DIST 31.09 36.29 −5.20\n5 (Wu et al., 2020) BERT MART 35.82 19.52 +16.30\n6 GPT2 MART 32.39 21.99 +10.40\nTable 1: The branching gaps of some syntax extracting methods. The results are corpus-level F1 scores on English.\nL is the original language and L′ is its reversed version.\nrepresentations and attention weights) outputted\nby a pre-trained language model, we propose ran-\ndomly initializing them and using them to compute\nfeature scores. Then we run an unbiased parsing\nalgorithm on the feature scores generated in this\nway. Therefore, if there is a noticeable branching\ngap, the branching bias will be attributed to the\nfeature deﬁnition. The pipeline to extract syntax is\nindependent of the language model, and the ﬁxed\nparsing algorithm is unbiased.\nBias in language model The pre-trained lan-\nguage model is the input of a syntax extracting\nmethod. We further analyze the branching bias in a\nlanguage model. To analyze the branching bias in\nit, we ﬁrstly choose an unbiased syntax extracting\npipeline (i.e., both the feature deﬁnition and parsing\nalgorithm are fair) and then calculate the branching\ngap using the well-trained language models on lan-\nguages L and L′. Since there is no branching bias\nwithin our selected extracting method, the branch-\ning bias can be attributed to the input itself, if a\nbranching gap is observed.\n3 Experiments\n3.1 Settings\nData We choose English as the main language in\nour experiments. The English data used for training\nlanguage models is the concatenation of 1M lines\nof Wikipedia data (Devlin et al., 2019) and the Penn\nTreeBank (PTB) (Marcus et al., 1993) training data.\nWe use PTB-22 and PTB-23 for validation and test,\nrespectively. Besides, to rule out the impact of\nother linguistic properties, we also conduct part of\nour experiments on German and Chinese. We use\nthe German Treebank from the SPMRL (Seddah\net al., 2014) and Penn Chinese TreeBank (CTB)\n(Xue et al., 2005) with their provided test sets to\nevaluate previous methods on those two languages,\nrespectively.\nLanguage Models In our experiments, we train\nthree different language models (i.e., BERT,\nGPT2 , LSTM ) for English and its reversed lan-\nguage 4. The BERT and GPT2 models are trained\nusing Huggingface’s Transformers (Wolf et al.,\n2019) and we use the default parameters of their\nbase settings (Devlin et al., 2019; Radford et al.,\n2019; Wolf et al., 2019). The LSTM model is\ntrained using awd-lstm-lm 5, and we use the pa-\nrameters similar to Merity et al. (2018). Models\nused for extracting syntax are selected according\nto the PPL on validation set. The tokenizers for\nBERT and GPT2 are trained using the toolkit hug-\ngingface/tokenizers6, and their vocabulary sizes are\n22000 and 35000 respectively. The tokenizer of\nGPT2 is shared with LSTM.\nSyntax Extracting Methods To evaluate the\nbranching bias, we use the codes 7 of Kim et al.\n(2020) and Wu et al. (2020), and re-implement the\nalgorithm in Mareˇcek and Rosa (2018). The pars-\ning algorithms proposed by them are referred to as\nDIST , MART, and ATTN SPAN respectively. Note\nthat Kim et al. (2020) propose a trick to explic-\nitly inject right-branching bias to their method, and\nwe set the weight of this injected external bias to\nzero in our experiments. For feature deﬁnitions, we\nmainly focus on three types of feature deﬁnitions,\nwhich are hidden representation (Kim et al., 2020),\nfull attention (Mare ˇcek and Rosa, 2018), and preﬁx\nattention (Kim et al., 2020; Wu et al., 2020). 8 The\n4We train a language model on the reversed language by\nreversing the entire training corpus\n5https://github.com/salesforce/\nawd-lstm-lm\n6https://github.com/huggingface/\ntokenizers\n7https://github.com/galsang/trees_\nfrom_transformers and https://github.com/\nLividWo/Perturbed-Masking\n8Preﬁx-attention means the attention is performed over the\npreﬁx words as in GPT2 whereas full-attention is over all\nwords in a sentence as in BERT.\n4476\n# Parsing Alg. EN ZH DE\nL L ′ Gap L L ′ Gap L L ′ Gap\n1 ATTNSPAN 21.37 21 .45 −0.08 17 .15 16 .98 +0 .17 17 .79 17 .78 +0 .01\n2 DIST 18.30 18 .27 +0 .03 15 .28 15 .76 −0.48 17 .01 16 .94 −0.07\n3 MART 26.11 15 .41 +10 .70 19 .90 9 .51 +10 .39 8 .95 17 .07 −8.12\n4 RANDOM 18.31 18 .37 −0.06 15 .33 15 .03 +0 .30 16 .99 16 .98 +0 .01\n5 RIGHT-B 35.82 10 .40 +25 .42 19 .77 8 .11 +11 .66 7 .99 16 .54 −8.55\nTable 2: The branching gaps of parsing algorithms with random feature scores. Feature scores are generated\naccording to a uniform distribution [−1, 1]. The results are averaged corpus-level F1 scores with 10 random seeds.\nL is the original language and L′ is its reversed version.\n# Feature Def. EN ZH DE\nL L ′ Gap L L ′ Gap L L ′ Gap\n1 HIDDEN 18.39 18 .29 −0.10 15 .32 15 .30 +0 .02 16 .88 17 .10 +0 .28\n2 PREFIX-ATTN 20.44 13 .17 +7 .27 16 .78 12 .66 +4 .12 14 .93 18 .83 −3.90\n3 FULL-ATTN 18.33 18 .38 −0.05 15 .12 15 .04 +0 .08 16 .84 16 .79 +0 .05\nTable 3: The branching gaps while applying D IST to different randomized feature deﬁnitions. The uniform\ndistribution [−1, 1] is used to randomize the weights of feature deﬁnitions. The results are averaged corpus-level\nF1 scores with 10 random seeds.\nhyper-parameters (e.g., choices of attention head\nand hidden layer) of syntax extracting methods are\ntuned on the validation set.\n3.2 Main Results\nAs shown in Table 1, the behaviors of differ-\nent approaches are widely divergent. We ﬁnd\nthat the branching bias in BERT+ATTN SPAN\nand BERT+DIST are relatively lower than\nother approaches. However, the results of\nGPT2 +ATTN SPAN and BERT/GPT2 +MART\ndemonstrate signiﬁcant right-branching biases.\nGPT2 +DIST shows a tendency towards left-\nbranching. Since these approaches are pipelined,\nwhich part of their methods has an impact on the\nbranching bias is still unclear.\nThe results reported in Table 1 is a little worse\nthan those reported in Kim et al. (2020); Wu et al.\n(2020). One reason is that we evaluate the results\non the corpus-level F1 score following the standard,\nrather than sentence-level (Kim et al., 2020). The\nother reason is that our training data is small, since\nit is too expensive to train reversed language mod-\nels on a huge dataset. However, these results are\nobtained by running the released codes of Kim et al.\n(2020); Wu et al. (2020), and thus, we think it will\nnot affect our ﬁndings.\n3.3 Factors affecting branching bias\nBranching Bias in Parsing Algorithm The\nbranching gaps of different parsing algorithms are\nshown in Table 2. Observing from the experiment\nresults in English, The branching gaps of MART is\nsigniﬁcantly larger than 0, which means it has a ten-\ndency to right-branching. In contrast, the branching\ngaps of parsing algorithm ATTN SPAN and DIST\nare nearly 0, which means they do not bias to left-\nbranching or right-branching. Although DIST is\ninspired by the parsing algorithm in Shen et al.\n(2019), it is an unbiased, which is consistent with\nthe claim in Kim et al. (2020). We also evaluate\nthe parsing algorithm of Shen et al. (2019), and\nits branching gap is +3.22 on English, which is\nconsistent with the ﬁnding in Dyer et al. (2019).\nTo examine whether some other language prop-\nerties might play a role in this process, we also\nconduct experiments on different languages, which\ncan help rule out the impact of speciﬁc language\nproperties. The results in Table 2 show that MART\nhas the same trend as RIGHT -B baseline (row 5)\non both Chinese and German datasets, which is\nconsistent with the ﬁnding on the English dataset.\nIt is also worth noting that the branching gap for\nMART is positive on Chinese and English datasets,\nwhereas it is negative on German. The reason is\nthat both Chinese and English are right-branching\nlanguages, while German is inclined to be left-\nbranching. However, both head-initial and head-\nﬁnal structures occur in the German language from\nthe viewpoint of linguistics. In addition, one in-\nteresting observation is that, the performances of\nATTN SPAN are always higher than the RANDOM\n4477\n# Language Model L L′ Gap\n1 BERT 24.93 25.23 −0.30\n2 GPT2 23.85 26.09 −2.24\n3 LSTM 28.72 26.22 +2.50\n4 RANDOM 18.31 18.37 −0.06\nTable 4: The branching gaps of different language\nmodels using an unbiased pipeline H IDDEN + D IST .\nThe results are corpus-level F1 scores on English.\nbaseline. We hypothesize that ATTN SPAN may\nhave a bias towards the balance tree, due to its way\nto compute weights of splitting points.\nBranching Bias in Feature Deﬁnition As\nshown in Table 3, we choose the unbiased parsing\nalgorithm DIST to further analyze the branching\nbias in feature deﬁnitions. It is worth noting that,\nafter normalization, the attention matrix ofPREFIX -\nATTN is lower triangular, and that of FULL -ATTN\nis fully ﬁlled. We ﬁnd that the feature deﬁnitions\nbased on HIDDEN and FULL -ATTN are unbiased.\nHowever, PREFIX -ATTN tends to generate right-\nbranching trees, where the branching gap is +7.27\non English. This ﬁnding is consistent with that on\nChinese and German. One possible explanation\nabout PREFIX -ATTN is that the attention scores\nwill become distracted with the preﬁx grows, such\nthat the feature scores in the front of the sequence,\nwhich has a larger value, would be picked at ﬁrst.\nBranching Bias in Language Models After the\nanalyses in previous steps, we will use the unbiased\nparsing algorithm and feature deﬁnition, DIST and\nHIDDEN , to evaluate the branching bias in language\nmodels. Note that the results in this section is\ndifferent from those in Table 1, since other feature\ndeﬁnitions are prohibited except for HIDDEN .\nOur experiments conducted on language mod-\nels are shown in Table 4. The performances of\nBERT on both branching are nearly the same,\nwhere the branching gap is just −0.30. In contrast,\nslight branching gap is observed on both GPT2\nand LSTM . The branching gap of GPT2 is −2.24.\nWith the same left-to-right paradigm, LSTM be-\nhaviors a positive branching gap +2.50. The op-\nposite branching gap may be caused by the differ-\nence between model architectures, where GPT2\nis based on self-attention (Vaswani et al., 2017)\nand LSTM is based on gating mechanism (Hochre-\niter and Schmidhuber, 1997). However, the ran-\ndom noises may also play a role in this observa-\ntion, since the performance range of GPT2 models\ntrained on the original English dataset with differ-\nent random seed can also reach around 1.50. We\nwill investigate it in future works.\n4 Conclusion\nIn this paper, we propose an approach to quanti-\ntatively analyze the branching bias in extracting\nsyntax from pre-trained language models. Unlike\nprevious work, our approach is more general to\nbe applied to any pre-trained language models and\nsyntax extracting methods. Furthermore, we sys-\ntematically analyze three factors in depth that may\naffect the branching bias: the language model, fea-\nture deﬁnition, and parsing algorithm. Our experi-\nments show that branching biases are in many re-\ncent works. In addition, these biases can be brought\nby each of the three factors. We appeal that re-\nsearchers should carefully design their syntax ex-\ntracting method to reveal the real competence of\nsyntax from a pre-trained language model.\nReferences\nKevin Clark, Urvashi Khandelwal, Omer Levy, and\nChristopher D. Manning. 2019. What does BERT\nlook at? an analysis of BERT’s attention. In Pro-\nceedings of the 2019 ACL Workshop BlackboxNLP:\nAnalyzing and Interpreting Neural Networks for\nNLP, pages 276–286, Florence, Italy. Association\nfor Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186.\nChris Dyer, G ´abor Melis, and Phil Blunsom. 2019. A\ncritical analysis of biased parsers in unsupervised\nparsing. arXiv preprint arXiv:1909.09428.\nJohn Hewitt and Christopher D Manning. 2019. A\nstructural probe for ﬁnding syntax in word represen-\ntations. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4129–4138.\nSepp Hochreiter and J ¨urgen Schmidhuber. 1997.\nLong short-term memory. Neural computation ,\n9(8):1735–1780.\nGanesh Jawahar, Benoˆıt Sagot, Djam´e Seddah, Samuel\nUnicomb, Gerardo I˜niguez, M´arton Karsai, Yannick\n4478\nL´eo, M ´arton Karsai, Carlos Sarraute, ´Eric Fleury,\net al. 2019. What does bert learn about the structure\nof language? In 57th Annual Meeting of the Associa-\ntion for Computational Linguistics (ACL), Florence,\nItaly.\nTaeuk Kim, Jihun Choi, Daniel Edmiston, and Sang-\ngoo Lee. 2020. Are pre-trained language models\naware of phrases? simple but strong baselines for\ngrammar induction. In 8th International Confer-\nence on Learning Representations, ICLR 2020, Ad-\ndis Ababa, Ethiopia, April 26-30, 2020 . OpenRe-\nview.net.\nPaul Kiparsky. 1996. The shift to head-initial vp in\ngermanic. Studies in comparative Germanic syntax,\n2:140–179.\nAnthony S Kroch. 2001. Syntactic change. na.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nMitchell P. Marcus, Mary Ann Marcinkiewicz, and\nBeatrice Santorini. 1993. Building a large annotated\ncorpus of english: The penn treebank. Comput. Lin-\nguist., 19(2):313–330.\nDavid Mareˇcek and Rudolf Rosa. 2018. Extracting syn-\ntactic trees from transformer encoder self-attentions.\nIn Proceedings of the 2018 EMNLP Workshop Black-\nboxNLP: Analyzing and Interpreting Neural Net-\nworks for NLP, pages 347–349.\nDavid Mare ˇcek and Rudolf Rosa. 2019. From\nbalustrades to pierre vinken: Looking for syntax in\ntransformer self-attentions. In Proceedings of the\n2019 ACL Workshop BlackboxNLP: Analyzing and\nInterpreting Neural Networks for NLP , pages 263–\n275, Florence, Italy. Association for Computational\nLinguistics.\nStephen Merity, Nitish Shirish Keskar, and Richard\nSocher. 2018. Regularizing and optimizing LSTM\nlanguage models. In 6th International Conference\non Learning Representations, ICLR 2018, Vancou-\nver, BC, Canada, April 30 - May 3, 2018, Confer-\nence Track Proceedings. OpenReview.net.\nMatthew E Peters, Mark Neumann, Mohit Iyyer, Matt\nGardner, Christopher Clark, Kenton Lee, and Luke\nZettlemoyer. 2018. Deep contextualized word rep-\nresentations. In Proceedings of NAACL-HLT, pages\n2227–2237.\nAlec Radford, Jeff Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners.\nDjam´e Seddah, Sandra K¨ubler, and Reut Tsarfaty. 2014.\nIntroducing the SPMRL 2014 shared task on pars-\ning morphologically-rich languages. In Proceedings\nof the First Joint Workshop on Statistical Parsing\nof Morphologically Rich Languages and Syntactic\nAnalysis of Non-Canonical Languages , pages 103–\n109, Dublin, Ireland. Dublin City University.\nYikang Shen, Shawn Tan, Alessandro Sordoni, and\nAaron C. Courville. 2019. Ordered neurons: Inte-\ngrating tree structures into recurrent neural networks.\nIn 7th International Conference on Learning Repre-\nsentations, ICLR 2019, New Orleans, LA, USA, May\n6-9, 2019. OpenReview.net.\nIan Tenney, Patrick Xia, Berlin Chen, Alex Wang,\nAdam Poliak, R. Thomas McCoy, Najoung Kim,\nBenjamin Van Durme, Samuel R. Bowman, Dipan-\njan Das, and Ellie Pavlick. 2019. What do you\nlearn from context? probing for sentence structure\nin contextualized word representations. In 7th Inter-\nnational Conference on Learning Representations,\nICLR 2019, New Orleans, LA, USA, May 6-9, 2019 .\nOpenReview.net.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in neural information pro-\ncessing systems, pages 5998–6008.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, R’emi Louf, Morgan Funtow-\nicz, and Jamie Brew. 2019. Huggingface’s trans-\nformers: State-of-the-art natural language process-\ning. ArXiv, abs/1910.03771.\nZhiyong Wu, Yun Chen, Ben Kao, and Qun Liu. 2020.\nPerturbed masking: Parameter-free probing for ana-\nlyzing and interpreting BERT. In Proceedings of the\n58th Annual Meeting of the Association for Compu-\ntational Linguistics, pages 4166–4176, Online. As-\nsociation for Computational Linguistics.\nNaiwen Xue, Fei Xia, Fu-Dong Chiou, and Marta\nPalmer. 2005. The penn chinese treebank: Phrase\nstructure annotation of a large corpus. Natural lan-\nguage engineering, 11(2):207.",
  "topic": "Branching (polymer chemistry)",
  "concepts": [
    {
      "name": "Branching (polymer chemistry)",
      "score": 0.8512982130050659
    },
    {
      "name": "Computer science",
      "score": 0.7824254035949707
    },
    {
      "name": "Parsing",
      "score": 0.7010911107063293
    },
    {
      "name": "Natural language processing",
      "score": 0.6104203462600708
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6035300493240356
    },
    {
      "name": "Syntax",
      "score": 0.563637375831604
    },
    {
      "name": "Feature (linguistics)",
      "score": 0.5374565124511719
    },
    {
      "name": "Inductive bias",
      "score": 0.48364341259002686
    },
    {
      "name": "Linguistics",
      "score": 0.17753762006759644
    },
    {
      "name": "Materials science",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Multi-task learning",
      "score": 0.0
    },
    {
      "name": "Composite material",
      "score": 0.0
    },
    {
      "name": "Task (project management)",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I2250653659",
      "name": "Tencent (China)",
      "country": "CN"
    }
  ],
  "cited_by": 5
}